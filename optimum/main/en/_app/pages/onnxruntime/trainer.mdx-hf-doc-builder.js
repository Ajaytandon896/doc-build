import{S as On,i as Rn,s as Nn,e as r,k as l,w as h,t as i,M as qn,c as a,d as n,m,a as o,x as g,h as s,b as d,G as e,g as k,y as f,q as v,o as _,B as b,v as Dn}from"../../chunks/vendor-hf-doc-builder.js";import{T as En}from"../../chunks/Tip-hf-doc-builder.js";import{D as T}from"../../chunks/Docstring-hf-doc-builder.js";import{I as rn}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Sn(Pe){let y;return{c(){y=i(`If your predictions or labels have different sequence lengths (for instance because you're doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},l(O){y=s(O,`If your predictions or labels have different sequence lengths (for instance because you're doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},m(O,$){k(O,y,$)},d(O){O&&n(y)}}}function Pn(Pe){let y,O,$,E,ge,W,tt,fe,nt,Le,R,S,ve,B,rt,_e,at,Ae,c,X,ot,P,j,it,be,st,lt,L,Y,mt,G,dt,ye,ct,pt,ut,A,J,ht,K,gt,Te,ft,vt,_t,z,Q,bt,N,yt,$e,Tt,$t,xe,xt,wt,kt,I,Z,Ot,we,Rt,Nt,C,ee,qt,te,Dt,ke,Et,St,Pt,V,ne,Lt,q,At,Oe,zt,It,Re,Ct,Vt,Mt,M,re,Ut,Ne,Ft,ze,D,U,qe,ae,Ht,De,Wt,Ie,x,oe,Bt,F,ie,Xt,se,jt,Ee,Yt,Gt,Jt,w,le,Kt,me,Qt,Se,Zt,en,tn,H,nn,Ce;return W=new rn({}),B=new rn({}),X=new T({props:{name:"class optimum.onnxruntime.ORTTrainer",anchor:"optimum.onnxruntime.ORTTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"preprocess_logits_for_metrics",val:": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L153"}}),j=new T({props:{name:"compute_loss_ort",anchor:"optimum.onnxruntime.ORTTrainer.compute_loss_ort",parameters:[{name:"model",val:""},{name:"inputs",val:""},{name:"return_outputs",val:" = False"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L1231"}}),Y=new T({props:{name:"create_optimizer",anchor:"optimum.onnxruntime.ORTTrainer.create_optimizer",parameters:[],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L1385"}}),J=new T({props:{name:"evaluate",anchor:"optimum.onnxruntime.ORTTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L658"}}),Q=new T({props:{name:"evaluation_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.evaluation_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L780"}}),Z=new T({props:{name:"get_ort_optimizer_cls_and_kwargs",anchor:"optimum.onnxruntime.ORTTrainer.get_ort_optimizer_cls_and_kwargs",parameters:[{name:"args",val:": TrainingArguments"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTTrainer.get_ort_optimizer_cls_and_kwargs.args",description:`<strong>args</strong> (<code>optimum.onnxruntime.training_args.ORTTrainingArguments</code>) &#x2014;
The training arguments for the training session.`,name:"args"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L1437"}}),ee=new T({props:{name:"predict",anchor:"optimum.onnxruntime.ORTTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'test'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L725"}}),ne=new T({props:{name:"prediction_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.prediction_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L1004"}}),re=new T({props:{name:"train",anchor:"optimum.onnxruntime.ORTTrainer.train",parameters:[{name:"resume_from_checkpoint",val:": typing.Union[str, bool, NoneType] = None"},{name:"trial",val:": typing.Union[ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"},{name:"ignore_keys_for_eval",val:": typing.Optional[typing.List[str]] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTTrainer.train.resume_from_checkpoint",description:`<strong>resume_from_checkpoint</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
If a <code>str</code>, local path to a saved checkpoint as saved by a previous instance of <code>Trainer</code>. If a
<code>bool</code> and equals <code>True</code>, load the last checkpoint in <em>args.output_dir</em> as saved by a previous instance
of <code>Trainer</code>. If present, training will resume from the model/optimizer/scheduler states loaded here.`,name:"resume_from_checkpoint"},{anchor:"optimum.onnxruntime.ORTTrainer.train.trial",description:`<strong>trial</strong> (<code>optuna.Trial</code> or <code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The trial run or the hyperparameter dictionary for hyperparameter search.`,name:"trial"},{anchor:"optimum.onnxruntime.ORTTrainer.train.ignore_keys_for_eval",description:`<strong>ignore_keys_for_eval</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions for evaluation during the training.
kwargs &#x2014;
Additional keyword arguments used to hide deprecated arguments`,name:"ignore_keys_for_eval"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer.py#L191"}}),ae=new rn({}),oe=new T({props:{name:"class optimum.onnxruntime.ORTSeq2SeqTrainer",anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"preprocess_logits_for_metrics",val:": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer_seq2seq.py#L72"}}),ie=new T({props:{name:"evaluate",anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"inference_with_ort",val:": bool = False"},{name:"**gen_kwargs",val:""}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.eval_dataset",description:`<strong>eval_dataset</strong> (<code>Dataset</code>, <em>optional</em>) &#x2014;
Pass a dataset if you wish to override <code>self.eval_dataset</code>. If it is an <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset" rel="nofollow">Dataset</a>, columns
not accepted by the <code>model.forward()</code> method are automatically removed. It must implement the <code>__len__</code>
method.`,name:"eval_dataset"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.
gen_kwargs &#x2014;
Additional <code>generate</code> specific kwargs.`,name:"num_beams"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer_seq2seq.py#L73",returnDescription:`
<p>A dictionary containing the evaluation loss and the potential metrics computed from the predictions. The
dictionary also contains the epoch number which comes from the training state.</p>
`}}),le=new T({props:{name:"predict",anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"inference_with_ort",val:": bool = False"},{name:"**gen_kwargs",val:""}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.test_dataset",description:`<strong>test_dataset</strong> (<code>Dataset</code>) &#x2014;
Dataset to run the predictions on. If it is a <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset" rel="nofollow">Dataset</a>, columns not accepted by the
<code>model.forward()</code> method are automatically removed. Has to implement the method <code>__len__</code>`,name:"test_dataset"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.
gen_kwargs &#x2014;
Additional <code>generate</code> specific kwargs.`,name:"num_beams"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/trainer_seq2seq.py#L125"}}),H=new En({props:{$$slots:{default:[Sn]},$$scope:{ctx:Pe}}}),{c(){y=r("meta"),O=l(),$=r("h1"),E=r("a"),ge=r("span"),h(W.$$.fragment),tt=l(),fe=r("span"),nt=i("Trainer"),Le=l(),R=r("h2"),S=r("a"),ve=r("span"),h(B.$$.fragment),rt=l(),_e=r("span"),at=i("ORTTrainer"),Ae=l(),c=r("div"),h(X.$$.fragment),ot=l(),P=r("div"),h(j.$$.fragment),it=l(),be=r("p"),st=i(`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),lt=l(),L=r("div"),h(Y.$$.fragment),mt=l(),G=r("p"),dt=i(`Setup the optimizer.
We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
ORTTrainer\u2019s init through `),ye=r("code"),ct=i("optimizers"),pt=i(", or subclass and override this method in a subclass."),ut=l(),A=r("div"),h(J.$$.fragment),ht=l(),K=r("p"),gt=i("Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),Te=r("code"),ft=i("Trainer.evaluate()"),vt=i(")"),_t=l(),z=r("div"),h(Q.$$.fragment),bt=l(),N=r("p"),yt=i("Prediction/evaluation loop, shared by "),$e=r("code"),Tt=i("ORTTrainer.evaluate()"),$t=i(" and "),xe=r("code"),xt=i("ORTTrainer.predict()"),wt=i(`.
Works both with or without labels.`),kt=l(),I=r("div"),h(Z.$$.fragment),Ot=l(),we=r("p"),Rt=i("Returns the optimizer class and optimizer parameters based on the ORT training arguments."),Nt=l(),C=r("div"),h(ee.$$.fragment),qt=l(),te=r("p"),Dt=i(`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),ke=r("code"),Et=i("Trainer.predict()"),St=i(")"),Pt=l(),V=r("div"),h(ne.$$.fragment),Lt=l(),q=r("p"),At=i("Prediction/evaluation loop, shared by "),Oe=r("code"),zt=i("Trainer.evaluate()"),It=i(" and "),Re=r("code"),Ct=i("Trainer.predict()"),Vt=i(`.
Works both with or without labels.`),Mt=l(),M=r("div"),h(re.$$.fragment),Ut=l(),Ne=r("p"),Ft=i("Main onnxruntime training entry point."),ze=l(),D=r("h2"),U=r("a"),qe=r("span"),h(ae.$$.fragment),Ht=l(),De=r("span"),Wt=i("ORTSeq2SeqTrainer"),Ie=l(),x=r("div"),h(oe.$$.fragment),Bt=l(),F=r("div"),h(ie.$$.fragment),Xt=l(),se=r("p"),jt=i(`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Ee=r("code"),Yt=i("compute_metrics"),Gt=i(` argument).
You can also subclass and override this method to inject custom behavior.`),Jt=l(),w=r("div"),h(le.$$.fragment),Kt=l(),me=r("p"),Qt=i(`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Se=r("code"),Zt=i("evaluate()"),en=i("."),tn=l(),h(H.$$.fragment),nn=i("\nReturns: *NamedTuple* A namedtuple with the following keys:\n- predictions (`np.ndarray`): The predictions on `test_dataset`.\n- label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).\n- metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained\n  labels)."),this.h()},l(t){const u=qn('[data-svelte="svelte-1phssyn"]',document.head);y=a(u,"META",{name:!0,content:!0}),u.forEach(n),O=m(t),$=a(t,"H1",{class:!0});var de=o($);E=a(de,"A",{id:!0,class:!0,href:!0});var an=o(E);ge=a(an,"SPAN",{});var on=o(ge);g(W.$$.fragment,on),on.forEach(n),an.forEach(n),tt=m(de),fe=a(de,"SPAN",{});var sn=o(fe);nt=s(sn,"Trainer"),sn.forEach(n),de.forEach(n),Le=m(t),R=a(t,"H2",{class:!0});var Ve=o(R);S=a(Ve,"A",{id:!0,class:!0,href:!0});var ln=o(S);ve=a(ln,"SPAN",{});var mn=o(ve);g(B.$$.fragment,mn),mn.forEach(n),ln.forEach(n),rt=m(Ve),_e=a(Ve,"SPAN",{});var dn=o(_e);at=s(dn,"ORTTrainer"),dn.forEach(n),Ve.forEach(n),Ae=m(t),c=a(t,"DIV",{class:!0});var p=o(c);g(X.$$.fragment,p),ot=m(p),P=a(p,"DIV",{class:!0});var Me=o(P);g(j.$$.fragment,Me),it=m(Me),be=a(Me,"P",{});var cn=o(be);st=s(cn,`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),cn.forEach(n),Me.forEach(n),lt=m(p),L=a(p,"DIV",{class:!0});var Ue=o(L);g(Y.$$.fragment,Ue),mt=m(Ue),G=a(Ue,"P",{});var Fe=o(G);dt=s(Fe,`Setup the optimizer.
We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
ORTTrainer\u2019s init through `),ye=a(Fe,"CODE",{});var pn=o(ye);ct=s(pn,"optimizers"),pn.forEach(n),pt=s(Fe,", or subclass and override this method in a subclass."),Fe.forEach(n),Ue.forEach(n),ut=m(p),A=a(p,"DIV",{class:!0});var He=o(A);g(J.$$.fragment,He),ht=m(He),K=a(He,"P",{});var We=o(K);gt=s(We,"Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),Te=a(We,"CODE",{});var un=o(Te);ft=s(un,"Trainer.evaluate()"),un.forEach(n),vt=s(We,")"),We.forEach(n),He.forEach(n),_t=m(p),z=a(p,"DIV",{class:!0});var Be=o(z);g(Q.$$.fragment,Be),bt=m(Be),N=a(Be,"P",{});var pe=o(N);yt=s(pe,"Prediction/evaluation loop, shared by "),$e=a(pe,"CODE",{});var hn=o($e);Tt=s(hn,"ORTTrainer.evaluate()"),hn.forEach(n),$t=s(pe," and "),xe=a(pe,"CODE",{});var gn=o(xe);xt=s(gn,"ORTTrainer.predict()"),gn.forEach(n),wt=s(pe,`.
Works both with or without labels.`),pe.forEach(n),Be.forEach(n),kt=m(p),I=a(p,"DIV",{class:!0});var Xe=o(I);g(Z.$$.fragment,Xe),Ot=m(Xe),we=a(Xe,"P",{});var fn=o(we);Rt=s(fn,"Returns the optimizer class and optimizer parameters based on the ORT training arguments."),fn.forEach(n),Xe.forEach(n),Nt=m(p),C=a(p,"DIV",{class:!0});var je=o(C);g(ee.$$.fragment,je),qt=m(je),te=a(je,"P",{});var Ye=o(te);Dt=s(Ye,`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),ke=a(Ye,"CODE",{});var vn=o(ke);Et=s(vn,"Trainer.predict()"),vn.forEach(n),St=s(Ye,")"),Ye.forEach(n),je.forEach(n),Pt=m(p),V=a(p,"DIV",{class:!0});var Ge=o(V);g(ne.$$.fragment,Ge),Lt=m(Ge),q=a(Ge,"P",{});var ue=o(q);At=s(ue,"Prediction/evaluation loop, shared by "),Oe=a(ue,"CODE",{});var _n=o(Oe);zt=s(_n,"Trainer.evaluate()"),_n.forEach(n),It=s(ue," and "),Re=a(ue,"CODE",{});var bn=o(Re);Ct=s(bn,"Trainer.predict()"),bn.forEach(n),Vt=s(ue,`.
Works both with or without labels.`),ue.forEach(n),Ge.forEach(n),Mt=m(p),M=a(p,"DIV",{class:!0});var Je=o(M);g(re.$$.fragment,Je),Ut=m(Je),Ne=a(Je,"P",{});var yn=o(Ne);Ft=s(yn,"Main onnxruntime training entry point."),yn.forEach(n),Je.forEach(n),p.forEach(n),ze=m(t),D=a(t,"H2",{class:!0});var Ke=o(D);U=a(Ke,"A",{id:!0,class:!0,href:!0});var Tn=o(U);qe=a(Tn,"SPAN",{});var $n=o(qe);g(ae.$$.fragment,$n),$n.forEach(n),Tn.forEach(n),Ht=m(Ke),De=a(Ke,"SPAN",{});var xn=o(De);Wt=s(xn,"ORTSeq2SeqTrainer"),xn.forEach(n),Ke.forEach(n),Ie=m(t),x=a(t,"DIV",{class:!0});var he=o(x);g(oe.$$.fragment,he),Bt=m(he),F=a(he,"DIV",{class:!0});var Qe=o(F);g(ie.$$.fragment,Qe),Xt=m(Qe),se=a(Qe,"P",{});var Ze=o(se);jt=s(Ze,`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Ee=a(Ze,"CODE",{});var wn=o(Ee);Yt=s(wn,"compute_metrics"),wn.forEach(n),Gt=s(Ze,` argument).
You can also subclass and override this method to inject custom behavior.`),Ze.forEach(n),Qe.forEach(n),Jt=m(he),w=a(he,"DIV",{class:!0});var ce=o(w);g(le.$$.fragment,ce),Kt=m(ce),me=a(ce,"P",{});var et=o(me);Qt=s(et,`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Se=a(et,"CODE",{});var kn=o(Se);Zt=s(kn,"evaluate()"),kn.forEach(n),en=s(et,"."),et.forEach(n),tn=m(ce),g(H.$$.fragment,ce),nn=s(ce,"\nReturns: *NamedTuple* A namedtuple with the following keys:\n- predictions (`np.ndarray`): The predictions on `test_dataset`.\n- label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).\n- metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained\n  labels)."),ce.forEach(n),he.forEach(n),this.h()},h(){d(y,"name","hf:doc:metadata"),d(y,"content",JSON.stringify(Ln)),d(E,"id","trainer"),d(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(E,"href","#trainer"),d($,"class","relative group"),d(S,"id","optimum.onnxruntime.ORTTrainer"),d(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S,"href","#optimum.onnxruntime.ORTTrainer"),d(R,"class","relative group"),d(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(c,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U,"id","optimum.onnxruntime.ORTSeq2SeqTrainer"),d(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U,"href","#optimum.onnxruntime.ORTSeq2SeqTrainer"),d(D,"class","relative group"),d(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,u){e(document.head,y),k(t,O,u),k(t,$,u),e($,E),e(E,ge),f(W,ge,null),e($,tt),e($,fe),e(fe,nt),k(t,Le,u),k(t,R,u),e(R,S),e(S,ve),f(B,ve,null),e(R,rt),e(R,_e),e(_e,at),k(t,Ae,u),k(t,c,u),f(X,c,null),e(c,ot),e(c,P),f(j,P,null),e(P,it),e(P,be),e(be,st),e(c,lt),e(c,L),f(Y,L,null),e(L,mt),e(L,G),e(G,dt),e(G,ye),e(ye,ct),e(G,pt),e(c,ut),e(c,A),f(J,A,null),e(A,ht),e(A,K),e(K,gt),e(K,Te),e(Te,ft),e(K,vt),e(c,_t),e(c,z),f(Q,z,null),e(z,bt),e(z,N),e(N,yt),e(N,$e),e($e,Tt),e(N,$t),e(N,xe),e(xe,xt),e(N,wt),e(c,kt),e(c,I),f(Z,I,null),e(I,Ot),e(I,we),e(we,Rt),e(c,Nt),e(c,C),f(ee,C,null),e(C,qt),e(C,te),e(te,Dt),e(te,ke),e(ke,Et),e(te,St),e(c,Pt),e(c,V),f(ne,V,null),e(V,Lt),e(V,q),e(q,At),e(q,Oe),e(Oe,zt),e(q,It),e(q,Re),e(Re,Ct),e(q,Vt),e(c,Mt),e(c,M),f(re,M,null),e(M,Ut),e(M,Ne),e(Ne,Ft),k(t,ze,u),k(t,D,u),e(D,U),e(U,qe),f(ae,qe,null),e(D,Ht),e(D,De),e(De,Wt),k(t,Ie,u),k(t,x,u),f(oe,x,null),e(x,Bt),e(x,F),f(ie,F,null),e(F,Xt),e(F,se),e(se,jt),e(se,Ee),e(Ee,Yt),e(se,Gt),e(x,Jt),e(x,w),f(le,w,null),e(w,Kt),e(w,me),e(me,Qt),e(me,Se),e(Se,Zt),e(me,en),e(w,tn),f(H,w,null),e(w,nn),Ce=!0},p(t,[u]){const de={};u&2&&(de.$$scope={dirty:u,ctx:t}),H.$set(de)},i(t){Ce||(v(W.$$.fragment,t),v(B.$$.fragment,t),v(X.$$.fragment,t),v(j.$$.fragment,t),v(Y.$$.fragment,t),v(J.$$.fragment,t),v(Q.$$.fragment,t),v(Z.$$.fragment,t),v(ee.$$.fragment,t),v(ne.$$.fragment,t),v(re.$$.fragment,t),v(ae.$$.fragment,t),v(oe.$$.fragment,t),v(ie.$$.fragment,t),v(le.$$.fragment,t),v(H.$$.fragment,t),Ce=!0)},o(t){_(W.$$.fragment,t),_(B.$$.fragment,t),_(X.$$.fragment,t),_(j.$$.fragment,t),_(Y.$$.fragment,t),_(J.$$.fragment,t),_(Q.$$.fragment,t),_(Z.$$.fragment,t),_(ee.$$.fragment,t),_(ne.$$.fragment,t),_(re.$$.fragment,t),_(ae.$$.fragment,t),_(oe.$$.fragment,t),_(ie.$$.fragment,t),_(le.$$.fragment,t),_(H.$$.fragment,t),Ce=!1},d(t){n(y),t&&n(O),t&&n($),b(W),t&&n(Le),t&&n(R),b(B),t&&n(Ae),t&&n(c),b(X),b(j),b(Y),b(J),b(Q),b(Z),b(ee),b(ne),b(re),t&&n(ze),t&&n(D),b(ae),t&&n(Ie),t&&n(x),b(oe),b(ie),b(le),b(H)}}}const Ln={local:"trainer",sections:[{local:"optimum.onnxruntime.ORTTrainer",title:"ORTTrainer"},{local:"optimum.onnxruntime.ORTSeq2SeqTrainer",title:"ORTSeq2SeqTrainer"}],title:"Trainer"};function An(Pe){return Dn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Mn extends On{constructor(y){super();Rn(this,y,An,Pn,Nn,{})}}export{Mn as default,Ln as metadata};
