import{S as _e,i as fe,s as xe,e as a,k as u,w as x,t as s,M as ze,c as o,d as n,m as p,a as i,x as z,h as m,b as c,F as t,g as E,y as v,L as ve,q as b,o as T,B as O,v as be}from"../../chunks/vendor-4918fc3c.js";import{D as V}from"../../chunks/Docstring-1b707a93.js";import{I as ge}from"../../chunks/IconCopyLink-21d338b1.js";function Te(Zt){let g,it,_,$,B,N,vt,J,bt,rt,h,Tt,j,Ot,$t,D,yt,qt,st,f,y,K,k,Rt,Y,Qt,mt,r,L,wt,Z,Pt,Et,G,C,Nt,q,I,Dt,F,kt,tt,Lt,Ct,It,R,U,Ft,et,Ut,At,Q,A,Wt,W,Xt,nt,Ht,St,Vt,w,X,Gt,H,Mt,at,Bt,Jt,jt,P,S,Kt,ot,Yt,ct;return N=new ge({}),k=new ge({}),L=new V({props:{name:"class optimum.onnxruntime.ORTQuantizer",anchor:"optimum.onnxruntime.ORTQuantizer",parameters:[{name:"tokenizer",val:": PreTrainedTokenizer"},{name:"model",val:": PreTrainedModel"},{name:"feature",val:": str = 'default'"},{name:"opset",val:": typing.Optional[int] = None"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L78"}}),C=new V({props:{name:"compute_ranges",anchor:"optimum.onnxruntime.ORTQuantizer.compute_ranges",parameters:[],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L261",returnDescription:`
<p>The dictionary mapping the nodes name to their quantization ranges.</p>
`}}),I=new V({props:{name:"export",anchor:"optimum.onnxruntime.ORTQuantizer.export",parameters:[{name:"onnx_model_path",val:": typing.Union[str, os.PathLike]"},{name:"onnx_quantized_model_output_path",val:": typing.Union[str, os.PathLike]"},{name:"quantization_config",val:": QuantizationConfig"},{name:"calibration_tensors_range",val:": typing.Union[typing.Dict[str, typing.Tuple[float, float]], NoneType] = None"},{name:"use_external_data_format",val:": bool = False"},{name:"preprocessor",val:": typing.Optional[optimum.onnxruntime.preprocessors.quantization.QuantizationPreprocessor] = None"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L274",parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.export.onnx_model_path",description:`<strong>onnx_model_path</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the model exported to an ONNX Intermediate Representation (IR).`,name:"onnx_model_path"},{anchor:"optimum.onnxruntime.ORTQuantizer.export.onnx_quantized_model_output_path",description:`<strong>onnx_quantized_model_output_path</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the quantized model exported to an ONNX Intermediate Representation (IR).`,name:"onnx_quantized_model_output_path"},{anchor:"optimum.onnxruntime.ORTQuantizer.export.quantization_config",description:`<strong>quantization_config</strong> (<code>QuantizationConfig</code>) &#x2014;
The configuration containing the parameters related to quantization.`,name:"quantization_config"},{anchor:"optimum.onnxruntime.ORTQuantizer.export.calibration_tensors_range",description:`<strong>calibration_tensors_range</strong> (<code>Dict[NodeName, Tuple[float, float]]</code>, <em>optional</em>) &#x2014;
The dictionary mapping the nodes name to their quantization ranges, used and required only when applying
static quantization.`,name:"calibration_tensors_range"},{anchor:"optimum.onnxruntime.ORTQuantizer.export.use_external_data_format",description:`<strong>use_external_data_format</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether uto se external data format to store model which size is &gt;= 2Gb.`,name:"use_external_data_format"},{anchor:"optimum.onnxruntime.ORTQuantizer.export.preprocessor",description:`<strong>preprocessor</strong> (<code>QuantizationPreprocessor</code>, <em>optional</em>) &#x2014;
The preprocessor to use to collect the nodes to include or exclude from quantization.`,name:"preprocessor"}],returnDescription:`
<p>The path of the resulting quantized model.</p>
`}}),U=new V({props:{name:"fit",anchor:"optimum.onnxruntime.ORTQuantizer.fit",parameters:[{name:"dataset",val:": Dataset"},{name:"calibration_config",val:": CalibrationConfig"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike, pathlib.Path]"},{name:"onnx_augmented_model_name",val:": str = 'augmented_model.onnx'"},{name:"operators_to_quantize",val:": typing.Optional[typing.List[str]] = None"},{name:"batch_size",val:": int = 1"},{name:"use_external_data_format",val:": bool = False"},{name:"use_gpu",val:": bool = False"},{name:"force_symmetric_range",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L138",parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.fit.dataset",description:`<strong>dataset</strong> (<code>Dataset</code>) &#x2014;
The dataset to use when performing the calibration step.`,name:"dataset"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.calibration_config",description:`<strong>calibration_config</strong> (<code>CalibrationConfig</code>) &#x2014;
The configuration containing the parameters related to the calibration step.`,name:"calibration_config"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.onnx_model_path",description:`<strong>onnx_model_path</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the model exported to an ONNX Intermediate Representation (IR).`,name:"onnx_model_path"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.onnx_augmented_model_name",description:`<strong>onnx_augmented_model_name</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the augmented model used to collect the quantization ranges.`,name:"onnx_augmented_model_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.operators_to_quantize",description:`<strong>operators_to_quantize</strong> (<code>list</code>, <em>optional</em>) &#x2014;
List of the operators types to quantize.`,name:"operators_to_quantize"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, defaults to 1) &#x2014;
The batch size to use when collecting the quantization ranges values.`,name:"batch_size"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.use_external_data_format",description:`<strong>use_external_data_format</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether uto se external data format to store model which size is &gt;= 2Gb.`,name:"use_external_data_format"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.use_gpu",description:`<strong>use_gpu</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to use the GPU when collecting the quantization ranges values.`,name:"use_gpu"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.force_symmetric_range",description:`<strong>force_symmetric_range</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to make the quantization ranges symmetric.`,name:"force_symmetric_range"}],returnDescription:`
<p>The dictionary mapping the nodes name to their quantization ranges.</p>
`}}),A=new V({props:{name:"from_pretrained",anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained",parameters:[{name:"model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"feature",val:": str"},{name:"opset",val:": typing.Optional[int] = None"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L83",parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained.model_name_or_path",description:`<strong>model_name_or_path</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
Repository name in the Hugging Face Hub or path to a local directory hosting the model.`,name:"model_name_or_path"},{anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
Feature to use when exporting the model.`,name:"feature"},{anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained.opset",description:`<strong>opset</strong> (<code>int</code>, <em>optional</em>) &#x2014;
ONNX opset version to export the model with.`,name:"opset"}],returnDescription:`
<p>An instance of <code>ORTQuantizer</code>.</p>
`}}),X=new V({props:{name:"get_calibration_dataset",anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset",parameters:[{name:"dataset_name",val:": str"},{name:"num_samples",val:": int = 100"},{name:"dataset_config_name",val:": typing.Optional[str] = None"},{name:"dataset_split",val:": typing.Optional[str] = None"},{name:"preprocess_function",val:": typing.Optional[typing.Callable] = None"},{name:"preprocess_batch",val:": bool = True"},{name:"seed",val:": int = 2016"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L375",parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.dataset_name",description:`<strong>dataset_name</strong> (<code>str</code>) &#x2014;
The dataset repository name on the Hugging Face Hub or path to a local directory containing data files
to load to use for the calibration step.`,name:"dataset_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.num_samples",description:`<strong>num_samples</strong> (<code>int</code>, defaults to 100) &#x2014;
The maximum number of samples composing the calibration dataset.`,name:"num_samples"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.dataset_config_name",description:`<strong>dataset_config_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the dataset configuration.`,name:"dataset_config_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.dataset_split",description:`<strong>dataset_split</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Which split of the dataset to use to perform the calibration step.`,name:"dataset_split"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.preprocess_function",description:`<strong>preprocess_function</strong> (<code>Callable</code>, <em>optional</em>) &#x2014;
Processing function to apply to each example after loading dataset.`,name:"preprocess_function"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.preprocess_batch",description:`<strong>preprocess_batch</strong> (<code>int</code>, defaults to <code>True</code>) &#x2014;
Whether the <code>preprocess_function</code> should be batched.`,name:"preprocess_batch"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.seed",description:`<strong>seed</strong> (<code>int</code>, defaults to 2016) &#x2014;
The random seed to use when shuffling the calibration dataset.`,name:"seed"}],returnDescription:`
<p>The calibration <code>datasets.Dataset</code> to use for the post-training static quantization calibration
step.</p>
`}}),S=new V({props:{name:"partial_fit",anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit",parameters:[{name:"dataset",val:": Dataset"},{name:"calibration_config",val:": CalibrationConfig"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike]"},{name:"onnx_augmented_model_name",val:": str = 'augmented_model.onnx'"},{name:"operators_to_quantize",val:": typing.Optional[typing.List[str]] = None"},{name:"batch_size",val:": int = 1"},{name:"use_external_data_format",val:": bool = False"},{name:"use_gpu",val:": bool = False"},{name:"force_symmetric_range",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/main/src/optimum/onnxruntime/quantization.py#L196",parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.dataset",description:`<strong>dataset</strong> (<code>Dataset</code>) &#x2014;
The dataset to use when performing the calibration step.`,name:"dataset"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.calibration_config",description:`<strong>calibration_config</strong> (<code>CalibrationConfig</code>) &#x2014;
The configuration containing the parameters related to the calibration step.`,name:"calibration_config"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.onnx_model_path",description:`<strong>onnx_model_path</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the model exported to an ONNX Intermediate Representation (IR).`,name:"onnx_model_path"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.onnx_augmented_model_name",description:`<strong>onnx_augmented_model_name</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the augmented model used to collect the quantization ranges.`,name:"onnx_augmented_model_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.operators_to_quantize",description:`<strong>operators_to_quantize</strong> (<code>list</code>, <em>optional</em>) &#x2014;
List of the operators types to quantize.`,name:"operators_to_quantize"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, defaults to 1) &#x2014;
The batch size to use when collecting the quantization ranges values.`,name:"batch_size"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.use_external_data_format",description:`<strong>use_external_data_format</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether uto se external data format to store model which size is &gt;= 2Gb.`,name:"use_external_data_format"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.use_gpu",description:`<strong>use_gpu</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to use the GPU when collecting the quantization ranges values.`,name:"use_gpu"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.force_symmetric_range",description:`<strong>force_symmetric_range</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to make the quantization ranges symmetric.`,name:"force_symmetric_range"}],returnDescription:`
<p>The dictionary mapping the nodes name to their quantization ranges.</p>
`}}),{c(){g=a("meta"),it=u(),_=a("h1"),$=a("a"),B=a("span"),x(N.$$.fragment),vt=u(),J=a("span"),bt=s("Quantization"),rt=u(),h=a("p"),Tt=s("\u{1F917} Optimum provides an "),j=a("code"),Ot=s("optimum.onnxruntime"),$t=s(" package that enables you to apply quantization on many model hosted on the \u{1F917} hub using the "),D=a("a"),yt=s("ONNX Runtime"),qt=s(" quantization tool."),st=u(),f=a("h2"),y=a("a"),K=a("span"),x(k.$$.fragment),Rt=u(),Y=a("span"),Qt=s("ORTQuantizer"),mt=u(),r=a("div"),x(L.$$.fragment),wt=u(),Z=a("p"),Pt=s("Handles the ONNX Runtime quantization process for models shared on huggingface.co/models."),Et=u(),G=a("div"),x(C.$$.fragment),Nt=u(),q=a("div"),x(I.$$.fragment),Dt=u(),F=a("p"),kt=s("Quantize a model given the optimization specifications defined in "),tt=a("code"),Lt=s("quantization_config"),Ct=s("."),It=u(),R=a("div"),x(U.$$.fragment),Ft=u(),et=a("p"),Ut=s("Perform the calibration step and collect the quantization ranges."),At=u(),Q=a("div"),x(A.$$.fragment),Wt=u(),W=a("p"),Xt=s("Instantiate a "),nt=a("code"),Ht=s("ORTQuantizer"),St=s(" from a pretrained pytorch model and tokenizer."),Vt=u(),w=a("div"),x(X.$$.fragment),Gt=u(),H=a("p"),Mt=s("Create the calibration "),at=a("code"),Bt=s("datasets.Dataset"),Jt=s(" to use for the post-training static quantization calibration step"),jt=u(),P=a("div"),x(S.$$.fragment),Kt=u(),ot=a("p"),Yt=s("Perform the calibration step and collect the quantization ranges."),this.h()},l(e){const d=ze('[data-svelte="svelte-1phssyn"]',document.head);g=o(d,"META",{name:!0,content:!0}),d.forEach(n),it=p(e),_=o(e,"H1",{class:!0});var ut=i(_);$=o(ut,"A",{id:!0,class:!0,href:!0});var te=i($);B=o(te,"SPAN",{});var ee=i(B);z(N.$$.fragment,ee),ee.forEach(n),te.forEach(n),vt=p(ut),J=o(ut,"SPAN",{});var ne=i(J);bt=m(ne,"Quantization"),ne.forEach(n),ut.forEach(n),rt=p(e),h=o(e,"P",{});var M=i(h);Tt=m(M,"\u{1F917} Optimum provides an "),j=o(M,"CODE",{});var ae=i(j);Ot=m(ae,"optimum.onnxruntime"),ae.forEach(n),$t=m(M," package that enables you to apply quantization on many model hosted on the \u{1F917} hub using the "),D=o(M,"A",{href:!0,rel:!0});var oe=i(D);yt=m(oe,"ONNX Runtime"),oe.forEach(n),qt=m(M," quantization tool."),M.forEach(n),st=p(e),f=o(e,"H2",{class:!0});var pt=i(f);y=o(pt,"A",{id:!0,class:!0,href:!0});var ie=i(y);K=o(ie,"SPAN",{});var re=i(K);z(k.$$.fragment,re),re.forEach(n),ie.forEach(n),Rt=p(pt),Y=o(pt,"SPAN",{});var se=i(Y);Qt=m(se,"ORTQuantizer"),se.forEach(n),pt.forEach(n),mt=p(e),r=o(e,"DIV",{class:!0});var l=i(r);z(L.$$.fragment,l),wt=p(l),Z=o(l,"P",{});var me=i(Z);Pt=m(me,"Handles the ONNX Runtime quantization process for models shared on huggingface.co/models."),me.forEach(n),Et=p(l),G=o(l,"DIV",{class:!0});var ce=i(G);z(C.$$.fragment,ce),ce.forEach(n),Nt=p(l),q=o(l,"DIV",{class:!0});var lt=i(q);z(I.$$.fragment,lt),Dt=p(lt),F=o(lt,"P",{});var dt=i(F);kt=m(dt,"Quantize a model given the optimization specifications defined in "),tt=o(dt,"CODE",{});var ue=i(tt);Lt=m(ue,"quantization_config"),ue.forEach(n),Ct=m(dt,"."),dt.forEach(n),lt.forEach(n),It=p(l),R=o(l,"DIV",{class:!0});var ht=i(R);z(U.$$.fragment,ht),Ft=p(ht),et=o(ht,"P",{});var pe=i(et);Ut=m(pe,"Perform the calibration step and collect the quantization ranges."),pe.forEach(n),ht.forEach(n),At=p(l),Q=o(l,"DIV",{class:!0});var gt=i(Q);z(A.$$.fragment,gt),Wt=p(gt),W=o(gt,"P",{});var _t=i(W);Xt=m(_t,"Instantiate a "),nt=o(_t,"CODE",{});var le=i(nt);Ht=m(le,"ORTQuantizer"),le.forEach(n),St=m(_t," from a pretrained pytorch model and tokenizer."),_t.forEach(n),gt.forEach(n),Vt=p(l),w=o(l,"DIV",{class:!0});var ft=i(w);z(X.$$.fragment,ft),Gt=p(ft),H=o(ft,"P",{});var xt=i(H);Mt=m(xt,"Create the calibration "),at=o(xt,"CODE",{});var de=i(at);Bt=m(de,"datasets.Dataset"),de.forEach(n),Jt=m(xt," to use for the post-training static quantization calibration step"),xt.forEach(n),ft.forEach(n),jt=p(l),P=o(l,"DIV",{class:!0});var zt=i(P);z(S.$$.fragment,zt),Kt=p(zt),ot=o(zt,"P",{});var he=i(ot);Yt=m(he,"Perform the calibration step and collect the quantization ranges."),he.forEach(n),zt.forEach(n),l.forEach(n),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Oe)),c($,"id","quantization"),c($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($,"href","#quantization"),c(_,"class","relative group"),c(D,"href","https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/quantization/README.md"),c(D,"rel","nofollow"),c(y,"id","optimum.onnxruntime.ORTQuantizer"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#optimum.onnxruntime.ORTQuantizer"),c(f,"class","relative group"),c(G,"class","docstring"),c(q,"class","docstring"),c(R,"class","docstring"),c(Q,"class","docstring"),c(w,"class","docstring"),c(P,"class","docstring"),c(r,"class","docstring")},m(e,d){t(document.head,g),E(e,it,d),E(e,_,d),t(_,$),t($,B),v(N,B,null),t(_,vt),t(_,J),t(J,bt),E(e,rt,d),E(e,h,d),t(h,Tt),t(h,j),t(j,Ot),t(h,$t),t(h,D),t(D,yt),t(h,qt),E(e,st,d),E(e,f,d),t(f,y),t(y,K),v(k,K,null),t(f,Rt),t(f,Y),t(Y,Qt),E(e,mt,d),E(e,r,d),v(L,r,null),t(r,wt),t(r,Z),t(Z,Pt),t(r,Et),t(r,G),v(C,G,null),t(r,Nt),t(r,q),v(I,q,null),t(q,Dt),t(q,F),t(F,kt),t(F,tt),t(tt,Lt),t(F,Ct),t(r,It),t(r,R),v(U,R,null),t(R,Ft),t(R,et),t(et,Ut),t(r,At),t(r,Q),v(A,Q,null),t(Q,Wt),t(Q,W),t(W,Xt),t(W,nt),t(nt,Ht),t(W,St),t(r,Vt),t(r,w),v(X,w,null),t(w,Gt),t(w,H),t(H,Mt),t(H,at),t(at,Bt),t(H,Jt),t(r,jt),t(r,P),v(S,P,null),t(P,Kt),t(P,ot),t(ot,Yt),ct=!0},p:ve,i(e){ct||(b(N.$$.fragment,e),b(k.$$.fragment,e),b(L.$$.fragment,e),b(C.$$.fragment,e),b(I.$$.fragment,e),b(U.$$.fragment,e),b(A.$$.fragment,e),b(X.$$.fragment,e),b(S.$$.fragment,e),ct=!0)},o(e){T(N.$$.fragment,e),T(k.$$.fragment,e),T(L.$$.fragment,e),T(C.$$.fragment,e),T(I.$$.fragment,e),T(U.$$.fragment,e),T(A.$$.fragment,e),T(X.$$.fragment,e),T(S.$$.fragment,e),ct=!1},d(e){n(g),e&&n(it),e&&n(_),O(N),e&&n(rt),e&&n(h),e&&n(st),e&&n(f),O(k),e&&n(mt),e&&n(r),O(L),O(C),O(I),O(U),O(A),O(X),O(S)}}}const Oe={local:"quantization",sections:[{local:"optimum.onnxruntime.ORTQuantizer",title:"ORTQuantizer"}],title:"Quantization"};function $e(Zt){return be(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Qe extends _e{constructor(g){super();fe(this,g,$e,Te,xe,{})}}export{Qe as default,Oe as metadata};
