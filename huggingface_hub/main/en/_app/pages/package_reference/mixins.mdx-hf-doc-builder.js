import{S as Gn,i as Jn,s as Qn,e as n,k as d,w,t as i,M as Xn,c as a,d as t,m as l,a as r,x,h as s,b as g,G as e,g as m,y as $,q as k,o as E,B as M,v as Zn}from"../../chunks/vendor-hf-doc-builder.js";import{T as cn}from"../../chunks/Tip-hf-doc-builder.js";import{D as q}from"../../chunks/Docstring-hf-doc-builder.js";import{I as po}from"../../chunks/IconCopyLink-hf-doc-builder.js";function ea(G){let h,T,u,f,v;return{c(){h=n("p"),T=i("Passing "),u=n("code"),f=i("use_auth_token=True"),v=i(` is required when you want to use a
private model.`)},l(p){h=a(p,"P",{});var _=r(h);T=s(_,"Passing "),u=a(_,"CODE",{});var O=r(u);f=s(O,"use_auth_token=True"),O.forEach(t),v=s(_,` is required when you want to use a
private model.`),_.forEach(t)},m(p,_){m(p,h,_),e(h,T),e(h,u),e(u,f),e(h,v)},d(p){p&&t(h)}}}function oa(G){let h,T,u,f,v;return{c(){h=n("p"),T=i("Passing "),u=n("code"),f=i("use_auth_token=True"),v=i(` is required when you want to use a private
model.`)},l(p){h=a(p,"P",{});var _=r(h);T=s(_,"Passing "),u=a(_,"CODE",{});var O=r(u);f=s(O,"use_auth_token=True"),O.forEach(t),v=s(_,` is required when you want to use a private
model.`),_.forEach(t)},m(p,_){m(p,h,_),e(h,T),e(h,u),e(u,f),e(h,v)},d(p){p&&t(h)}}}function ta(G){let h,T,u,f,v,p,_,O,de;return{c(){h=n("p"),T=i("Raises the following error:"),u=d(),f=n("ul"),v=n("li"),p=n("a"),_=n("em"),O=i("ValueError"),de=i(`
if the user is not log on to the Hugging Face Hub.`),this.h()},l(H){h=a(H,"P",{});var P=r(h);T=s(P,"Raises the following error:"),P.forEach(t),u=l(H),f=a(H,"UL",{});var z=r(f);v=a(z,"LI",{});var W=r(v);p=a(W,"A",{href:!0,rel:!0});var L=r(p);_=a(L,"EM",{});var Me=r(_);O=s(Me,"ValueError"),Me.forEach(t),L.forEach(t),de=s(W,`
if the user is not log on to the Hugging Face Hub.`),W.forEach(t),z.forEach(t),this.h()},h(){g(p,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),g(p,"rel","nofollow")},m(H,P){m(H,h,P),e(h,T),m(H,u,P),m(H,f,P),e(f,v),e(v,p),e(p,_),e(_,O),e(v,de)},d(H){H&&t(h),H&&t(u),H&&t(f)}}}function na(G){let h,T,u,f,v,p,_,O,de,H,P,z,W,L,Me,De,qo,uo,J,Wo,ze,Uo,Ko,fo,U,Q,Ae,le,Vo,Se,Ro,_o,N,ce,jo,A,Bo,Ie,Yo,Go,Le,Jo,Qo,Fe,Xo,Zo,et,F,he,ot,K,tt,Ce,nt,at,qe,rt,it,st,X,dt,Z,ge,lt,We,ct,ht,ee,me,gt,Ue,mt,bo,V,oe,Ke,pe,pt,Ve,ut,vo,S,ue,ft,Re,_t,bt,te,yo,R,fe,vt,_e,yt,je,wt,xt,wo,j,be,$t,Be,kt,xo,I,ve,Et,Ye,Mt,Tt,ye,Te,Ge,Ht,Pt,Ot,ne,Je,Nt,Dt,Qe,zt,At,$o,B,ae,Xe,we,St,Ze,It,ko,Y,xe,Lt,eo,Ft,Eo,D,$e,Ct,ke,qt,oo,Wt,Ut,Kt,b,Vt,to,Rt,jt,no,Bt,Yt,ao,Gt,Jt,ro,Qt,Xt,io,Zt,en,so,on,tn,lo,nn,an,co,rn,sn,dn,re,Mo;return p=new po({}),L=new po({}),le=new po({}),ce=new q({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L24"}}),he=new q({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<a href="https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" rel="nofollow">save_pretrained</a>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L100"}}),X=new cn({props:{$$slots:{default:[ea]},$$scope:{ctx:G}}}),ge=new q({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"skip_lfs_files",val:": bool = False"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Repository name to which push.`,name:"repo_id"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If not set, will use the token set when logging in with
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.branch",description:`<strong>branch</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <code>&quot;main&quot;</code>.`,name:"branch"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>boolean</code>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <code>branch</code> with that commit.
Defaults to <code>False</code>.`,name:"create_pr"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L238",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),me=new q({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your model to the Hugging Face model hub after
saving it. You can specify the repository you want to push to with
<code>repo_id</code> (will default to the name of <code>save_directory</code> in your
namespace).
kwargs &#x2014;
Additional key word arguments passed along to the
<code>push_to_hub</code> method.`,name:"push_to_hub"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L32"}}),pe=new po({}),ue=new q({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<a href="https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" rel="nofollow">save_pretrained</a>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L238"}}),te=new cn({props:{$$slots:{default:[oa]},$$scope:{ctx:G}}}),fe=new q({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"token",val:": typing.Optional[str] = True"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
Repository name to which push`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
not set, will use the token set when logging in with
<code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.push_to_hub_keras.branch",description:`<strong>branch</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <code>&quot;main&quot;</code>.`,name:"branch"},{anchor:"huggingface_hub.push_to_hub_keras.create_pr",description:`<strong>create_pr</strong> (<code>boolean</code>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <code>branch</code> with that commit.
Defaults to <code>False</code>.`,name:"create_pr"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.tags",description:`<strong>tags</strong> (Union[<code>list</code>, <code>str</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L297",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),be=new q({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.tags",description:`<strong>tags</strong> (Union[<code>str</code>,<code>list</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L146"}}),ve=new q({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L526"}}),we=new po({}),xe=new q({props:{name:"huggingface_hub.from_pretrained_fastai",anchor:"huggingface_hub.from_pretrained_fastai",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_fastai.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The location where the pickled fastai.Learner is. It can be either of the two:<ul>
<li>Hosted on the Hugging Face Hub. E.g.: &#x2018;espejelomar/fatai-pet-breeds-classification&#x2019; or &#x2018;distilgpt2&#x2019;.
You can add a <code>revision</code> by appending <code>@</code> at the end of <code>repo_id</code>. E.g.: <code>dbmdz/bert-base-german-cased@main</code>.
Revision is the specific model version to use. Since we use a git-based system for storing models and other
artifacts on the Hugging Face Hub, it can be a branch name, a tag name, or a commit id.</li>
<li>Hosted locally. <code>repo_id</code> would be a directory containing the pickle and a pyproject.toml
indicating the fastai and fastcore versions used to build the <code>fastai.Learner</code>. E.g.: <code>./my_model_directory/</code>.</li>
</ul>`,name:"repo_id"},{anchor:"huggingface_hub.from_pretrained_fastai.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Revision at which the repo&#x2019;s files are downloaded. See documentation of <code>snapshot_download</code>.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/fastai_utils.py#L308",returnDescription:`
<p>The <code>fastai.Learner</code> model in the <code>repo_id</code> repo.</p>
`}}),$e=new q({props:{name:"huggingface_hub.push_to_hub_fastai",anchor:"huggingface_hub.push_to_hub_fastai",parameters:[{name:"learner",val:""},{name:"repo_id",val:": str"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": typing.Optional[bool] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_fastai.learner",description:`<strong>learner</strong> (<em>Learner</em>) &#x2014;
The *fastai.Learner&#x2019; you&#x2019;d like to push to the Hub.`,name:"learner"},{anchor:"huggingface_hub.push_to_hub_fastai.repo_id",description:`<strong>repo_id</strong> (<em>str</em>) &#x2014;
The repository id for your model in Hub in the format of &#x201C;namespace/repo_name&#x201D;. The namespace can be your individual account or an organization to which you have write access (for example, &#x2018;stanfordnlp/stanza-de&#x2019;).`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_fastai.commit_message",description:"<strong>commit_message</strong> (<em>str`, </em>optional*) &#x2014; Message to commit while pushing. Will default to <code>&quot;add model&quot;</code>.",name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_fastai.private",description:`<strong>private</strong> (<em>bool</em>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_fastai.token",description:`<strong>token</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The Hugging Face account token to use as HTTP bearer authorization for remote files. If <code>None</code>, the token will be asked by a prompt.`,name:"token"},{anchor:"huggingface_hub.push_to_hub_fastai.config",description:`<strong>config</strong> (<em>dict</em>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/fastai_utils.py#L352",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),re=new cn({props:{$$slots:{default:[ta]},$$scope:{ctx:G}}}),{c(){h=n("meta"),T=d(),u=n("h1"),f=n("a"),v=n("span"),w(p.$$.fragment),_=d(),O=n("span"),de=i("Mixins & serialization methods"),H=d(),P=n("h2"),z=n("a"),W=n("span"),w(L.$$.fragment),Me=d(),De=n("span"),qo=i("Mixins"),uo=d(),J=n("p"),Wo=i("The "),ze=n("code"),Uo=i("huggingface_hub"),Ko=i(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),fo=d(),U=n("h3"),Q=n("a"),Ae=n("span"),w(le.$$.fragment),Vo=d(),Se=n("span"),Ro=i("PyTorch"),_o=d(),N=n("div"),w(ce.$$.fragment),jo=d(),A=n("p"),Bo=i(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Ie=n("code"),Yo=i("_from_pretrained"),Go=i(` and
`),Le=n("code"),Jo=i("_save_pretrained"),Qo=i(` to define custom logic for saving/loading your classes.
See `),Fe=n("code"),Xo=i("huggingface_hub.PyTorchModelHubMixin"),Zo=i(" for an example."),et=d(),F=n("div"),w(he.$$.fragment),ot=d(),K=n("p"),tt=i(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),Ce=n("code"),nt=i("model.eval()"),at=i(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),qe=n("code"),rt=i("model.train()"),it=i("."),st=d(),w(X.$$.fragment),dt=d(),Z=n("div"),w(ge.$$.fragment),lt=d(),We=n("p"),ct=i("Upload model checkpoint to the Hub."),ht=d(),ee=n("div"),w(me.$$.fragment),gt=d(),Ue=n("p"),mt=i("Save weights in local directory."),bo=d(),V=n("h3"),oe=n("a"),Ke=n("span"),w(pe.$$.fragment),pt=d(),Ve=n("span"),ut=i("Keras"),vo=d(),S=n("div"),w(ue.$$.fragment),ft=d(),Re=n("p"),_t=i("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),bt=d(),w(te.$$.fragment),yo=d(),R=n("div"),w(fe.$$.fragment),vt=d(),_e=n("p"),yt=i(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),je=n("code"),wt=i("repo_path_or_name"),xt=i("."),wo=d(),j=n("div"),w(be.$$.fragment),$t=d(),Be=n("p"),kt=i(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),xo=d(),I=n("div"),w(ve.$$.fragment),Et=d(),Ye=n("p"),Mt=i(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Tt=d(),ye=n("ul"),Te=n("li"),Ge=n("code"),Ht=i("_from_pretrained"),Pt=i(", to load a model from the Hub or from local files."),Ot=d(),ne=n("li"),Je=n("code"),Nt=i("_save_pretrained"),Dt=i(", to save a model in the "),Qe=n("code"),zt=i("SavedModel"),At=i(" format."),$o=d(),B=n("h3"),ae=n("a"),Xe=n("span"),w(we.$$.fragment),St=d(),Ze=n("span"),It=i("Fastai"),ko=d(),Y=n("div"),w(xe.$$.fragment),Lt=d(),eo=n("p"),Ft=i("Load pretrained fastai model from the Hub or from a local directory."),Eo=d(),D=n("div"),w($e.$$.fragment),Ct=d(),ke=n("p"),qt=i(`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),oo=n("code"),Wt=i("repo_id"),Ut=i("."),Kt=d(),b=n("p"),Vt=i(`Keyword Args:
api_endpoint (`),to=n("em"),Rt=i("str"),jt=i(", "),no=n("em"),Bt=i("optional"),Yt=i(`):
The API endpoint to use when pushing the model to the hub.
git_user (`),ao=n("em"),Gt=i("str"),Jt=i(", "),ro=n("em"),Qt=i("optional"),Xt=i(`):
Will override the `),io=n("code"),Zt=i("git config user.name"),en=i(` for committing and pushing files to the hub.
git_email (`),so=n("em"),on=i("str"),tn=i(", "),lo=n("em"),nn=i("optional"),an=i(`):
Will override the `),co=n("code"),rn=i("git config user.email"),sn=i(" for committing and pushing files to the hub."),dn=d(),w(re.$$.fragment),this.h()},l(o){const c=Xn('[data-svelte="svelte-1phssyn"]',document.head);h=a(c,"META",{name:!0,content:!0}),c.forEach(t),T=l(o),u=a(o,"H1",{class:!0});var Ee=r(u);f=a(Ee,"A",{id:!0,class:!0,href:!0});var ho=r(f);v=a(ho,"SPAN",{});var go=r(v);x(p.$$.fragment,go),go.forEach(t),ho.forEach(t),_=l(Ee),O=a(Ee,"SPAN",{});var hn=r(O);de=s(hn,"Mixins & serialization methods"),hn.forEach(t),Ee.forEach(t),H=l(o),P=a(o,"H2",{class:!0});var To=r(P);z=a(To,"A",{id:!0,class:!0,href:!0});var gn=r(z);W=a(gn,"SPAN",{});var mn=r(W);x(L.$$.fragment,mn),mn.forEach(t),gn.forEach(t),Me=l(To),De=a(To,"SPAN",{});var pn=r(De);qo=s(pn,"Mixins"),pn.forEach(t),To.forEach(t),uo=l(o),J=a(o,"P",{});var Ho=r(J);Wo=s(Ho,"The "),ze=a(Ho,"CODE",{});var un=r(ze);Uo=s(un,"huggingface_hub"),un.forEach(t),Ko=s(Ho,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Ho.forEach(t),fo=l(o),U=a(o,"H3",{class:!0});var Po=r(U);Q=a(Po,"A",{id:!0,class:!0,href:!0});var fn=r(Q);Ae=a(fn,"SPAN",{});var _n=r(Ae);x(le.$$.fragment,_n),_n.forEach(t),fn.forEach(t),Vo=l(Po),Se=a(Po,"SPAN",{});var bn=r(Se);Ro=s(bn,"PyTorch"),bn.forEach(t),Po.forEach(t),_o=l(o),N=a(o,"DIV",{class:!0});var C=r(N);x(ce.$$.fragment,C),jo=l(C),A=a(C,"P",{});var ie=r(A);Bo=s(ie,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Ie=a(ie,"CODE",{});var vn=r(Ie);Yo=s(vn,"_from_pretrained"),vn.forEach(t),Go=s(ie,` and
`),Le=a(ie,"CODE",{});var yn=r(Le);Jo=s(yn,"_save_pretrained"),yn.forEach(t),Qo=s(ie,` to define custom logic for saving/loading your classes.
See `),Fe=a(ie,"CODE",{});var wn=r(Fe);Xo=s(wn,"huggingface_hub.PyTorchModelHubMixin"),wn.forEach(t),Zo=s(ie," for an example."),ie.forEach(t),et=l(C),F=a(C,"DIV",{class:!0});var He=r(F);x(he.$$.fragment,He),ot=l(He),K=a(He,"P",{});var Pe=r(K);tt=s(Pe,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),Ce=a(Pe,"CODE",{});var xn=r(Ce);nt=s(xn,"model.eval()"),xn.forEach(t),at=s(Pe,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),qe=a(Pe,"CODE",{});var $n=r(qe);rt=s($n,"model.train()"),$n.forEach(t),it=s(Pe,"."),Pe.forEach(t),st=l(He),x(X.$$.fragment,He),He.forEach(t),dt=l(C),Z=a(C,"DIV",{class:!0});var Oo=r(Z);x(ge.$$.fragment,Oo),lt=l(Oo),We=a(Oo,"P",{});var kn=r(We);ct=s(kn,"Upload model checkpoint to the Hub."),kn.forEach(t),Oo.forEach(t),ht=l(C),ee=a(C,"DIV",{class:!0});var No=r(ee);x(me.$$.fragment,No),gt=l(No),Ue=a(No,"P",{});var En=r(Ue);mt=s(En,"Save weights in local directory."),En.forEach(t),No.forEach(t),C.forEach(t),bo=l(o),V=a(o,"H3",{class:!0});var Do=r(V);oe=a(Do,"A",{id:!0,class:!0,href:!0});var Mn=r(oe);Ke=a(Mn,"SPAN",{});var Tn=r(Ke);x(pe.$$.fragment,Tn),Tn.forEach(t),Mn.forEach(t),pt=l(Do),Ve=a(Do,"SPAN",{});var Hn=r(Ve);ut=s(Hn,"Keras"),Hn.forEach(t),Do.forEach(t),vo=l(o),S=a(o,"DIV",{class:!0});var Oe=r(S);x(ue.$$.fragment,Oe),ft=l(Oe),Re=a(Oe,"P",{});var Pn=r(Re);_t=s(Pn,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Pn.forEach(t),bt=l(Oe),x(te.$$.fragment,Oe),Oe.forEach(t),yo=l(o),R=a(o,"DIV",{class:!0});var zo=r(R);x(fe.$$.fragment,zo),vt=l(zo),_e=a(zo,"P",{});var Ao=r(_e);yt=s(Ao,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),je=a(Ao,"CODE",{});var On=r(je);wt=s(On,"repo_path_or_name"),On.forEach(t),xt=s(Ao,"."),Ao.forEach(t),zo.forEach(t),wo=l(o),j=a(o,"DIV",{class:!0});var So=r(j);x(be.$$.fragment,So),$t=l(So),Be=a(So,"P",{});var Nn=r(Be);kt=s(Nn,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Nn.forEach(t),So.forEach(t),xo=l(o),I=a(o,"DIV",{class:!0});var Ne=r(I);x(ve.$$.fragment,Ne),Et=l(Ne),Ye=a(Ne,"P",{});var Dn=r(Ye);Mt=s(Dn,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Dn.forEach(t),Tt=l(Ne),ye=a(Ne,"UL",{});var Io=r(ye);Te=a(Io,"LI",{});var ln=r(Te);Ge=a(ln,"CODE",{});var zn=r(Ge);Ht=s(zn,"_from_pretrained"),zn.forEach(t),Pt=s(ln,", to load a model from the Hub or from local files."),ln.forEach(t),Ot=l(Io),ne=a(Io,"LI",{});var mo=r(ne);Je=a(mo,"CODE",{});var An=r(Je);Nt=s(An,"_save_pretrained"),An.forEach(t),Dt=s(mo,", to save a model in the "),Qe=a(mo,"CODE",{});var Sn=r(Qe);zt=s(Sn,"SavedModel"),Sn.forEach(t),At=s(mo," format."),mo.forEach(t),Io.forEach(t),Ne.forEach(t),$o=l(o),B=a(o,"H3",{class:!0});var Lo=r(B);ae=a(Lo,"A",{id:!0,class:!0,href:!0});var In=r(ae);Xe=a(In,"SPAN",{});var Ln=r(Xe);x(we.$$.fragment,Ln),Ln.forEach(t),In.forEach(t),St=l(Lo),Ze=a(Lo,"SPAN",{});var Fn=r(Ze);It=s(Fn,"Fastai"),Fn.forEach(t),Lo.forEach(t),ko=l(o),Y=a(o,"DIV",{class:!0});var Fo=r(Y);x(xe.$$.fragment,Fo),Lt=l(Fo),eo=a(Fo,"P",{});var Cn=r(eo);Ft=s(Cn,"Load pretrained fastai model from the Hub or from a local directory."),Cn.forEach(t),Fo.forEach(t),Eo=l(o),D=a(o,"DIV",{class:!0});var se=r(D);x($e.$$.fragment,se),Ct=l(se),ke=a(se,"P",{});var Co=r(ke);qt=s(Co,`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),oo=a(Co,"CODE",{});var qn=r(oo);Wt=s(qn,"repo_id"),qn.forEach(t),Ut=s(Co,"."),Co.forEach(t),Kt=l(se),b=a(se,"P",{});var y=r(b);Vt=s(y,`Keyword Args:
api_endpoint (`),to=a(y,"EM",{});var Wn=r(to);Rt=s(Wn,"str"),Wn.forEach(t),jt=s(y,", "),no=a(y,"EM",{});var Un=r(no);Bt=s(Un,"optional"),Un.forEach(t),Yt=s(y,`):
The API endpoint to use when pushing the model to the hub.
git_user (`),ao=a(y,"EM",{});var Kn=r(ao);Gt=s(Kn,"str"),Kn.forEach(t),Jt=s(y,", "),ro=a(y,"EM",{});var Vn=r(ro);Qt=s(Vn,"optional"),Vn.forEach(t),Xt=s(y,`):
Will override the `),io=a(y,"CODE",{});var Rn=r(io);Zt=s(Rn,"git config user.name"),Rn.forEach(t),en=s(y,` for committing and pushing files to the hub.
git_email (`),so=a(y,"EM",{});var jn=r(so);on=s(jn,"str"),jn.forEach(t),tn=s(y,", "),lo=a(y,"EM",{});var Bn=r(lo);nn=s(Bn,"optional"),Bn.forEach(t),an=s(y,`):
Will override the `),co=a(y,"CODE",{});var Yn=r(co);rn=s(Yn,"git config user.email"),Yn.forEach(t),sn=s(y," for committing and pushing files to the hub."),y.forEach(t),dn=l(se),x(re.$$.fragment,se),se.forEach(t),this.h()},h(){g(h,"name","hf:doc:metadata"),g(h,"content",JSON.stringify(aa)),g(f,"id","mixins-serialization-methods"),g(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(f,"href","#mixins-serialization-methods"),g(u,"class","relative group"),g(z,"id","mixins"),g(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(z,"href","#mixins"),g(P,"class","relative group"),g(Q,"id","huggingface_hub.ModelHubMixin"),g(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Q,"href","#huggingface_hub.ModelHubMixin"),g(U,"class","relative group"),g(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(oe,"id","huggingface_hub.from_pretrained_keras"),g(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(oe,"href","#huggingface_hub.from_pretrained_keras"),g(V,"class","relative group"),g(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(ae,"id","huggingface_hub.from_pretrained_fastai"),g(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ae,"href","#huggingface_hub.from_pretrained_fastai"),g(B,"class","relative group"),g(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,c){e(document.head,h),m(o,T,c),m(o,u,c),e(u,f),e(f,v),$(p,v,null),e(u,_),e(u,O),e(O,de),m(o,H,c),m(o,P,c),e(P,z),e(z,W),$(L,W,null),e(P,Me),e(P,De),e(De,qo),m(o,uo,c),m(o,J,c),e(J,Wo),e(J,ze),e(ze,Uo),e(J,Ko),m(o,fo,c),m(o,U,c),e(U,Q),e(Q,Ae),$(le,Ae,null),e(U,Vo),e(U,Se),e(Se,Ro),m(o,_o,c),m(o,N,c),$(ce,N,null),e(N,jo),e(N,A),e(A,Bo),e(A,Ie),e(Ie,Yo),e(A,Go),e(A,Le),e(Le,Jo),e(A,Qo),e(A,Fe),e(Fe,Xo),e(A,Zo),e(N,et),e(N,F),$(he,F,null),e(F,ot),e(F,K),e(K,tt),e(K,Ce),e(Ce,nt),e(K,at),e(K,qe),e(qe,rt),e(K,it),e(F,st),$(X,F,null),e(N,dt),e(N,Z),$(ge,Z,null),e(Z,lt),e(Z,We),e(We,ct),e(N,ht),e(N,ee),$(me,ee,null),e(ee,gt),e(ee,Ue),e(Ue,mt),m(o,bo,c),m(o,V,c),e(V,oe),e(oe,Ke),$(pe,Ke,null),e(V,pt),e(V,Ve),e(Ve,ut),m(o,vo,c),m(o,S,c),$(ue,S,null),e(S,ft),e(S,Re),e(Re,_t),e(S,bt),$(te,S,null),m(o,yo,c),m(o,R,c),$(fe,R,null),e(R,vt),e(R,_e),e(_e,yt),e(_e,je),e(je,wt),e(_e,xt),m(o,wo,c),m(o,j,c),$(be,j,null),e(j,$t),e(j,Be),e(Be,kt),m(o,xo,c),m(o,I,c),$(ve,I,null),e(I,Et),e(I,Ye),e(Ye,Mt),e(I,Tt),e(I,ye),e(ye,Te),e(Te,Ge),e(Ge,Ht),e(Te,Pt),e(ye,Ot),e(ye,ne),e(ne,Je),e(Je,Nt),e(ne,Dt),e(ne,Qe),e(Qe,zt),e(ne,At),m(o,$o,c),m(o,B,c),e(B,ae),e(ae,Xe),$(we,Xe,null),e(B,St),e(B,Ze),e(Ze,It),m(o,ko,c),m(o,Y,c),$(xe,Y,null),e(Y,Lt),e(Y,eo),e(eo,Ft),m(o,Eo,c),m(o,D,c),$($e,D,null),e(D,Ct),e(D,ke),e(ke,qt),e(ke,oo),e(oo,Wt),e(ke,Ut),e(D,Kt),e(D,b),e(b,Vt),e(b,to),e(to,Rt),e(b,jt),e(b,no),e(no,Bt),e(b,Yt),e(b,ao),e(ao,Gt),e(b,Jt),e(b,ro),e(ro,Qt),e(b,Xt),e(b,io),e(io,Zt),e(b,en),e(b,so),e(so,on),e(b,tn),e(b,lo),e(lo,nn),e(b,an),e(b,co),e(co,rn),e(b,sn),e(D,dn),$(re,D,null),Mo=!0},p(o,[c]){const Ee={};c&2&&(Ee.$$scope={dirty:c,ctx:o}),X.$set(Ee);const ho={};c&2&&(ho.$$scope={dirty:c,ctx:o}),te.$set(ho);const go={};c&2&&(go.$$scope={dirty:c,ctx:o}),re.$set(go)},i(o){Mo||(k(p.$$.fragment,o),k(L.$$.fragment,o),k(le.$$.fragment,o),k(ce.$$.fragment,o),k(he.$$.fragment,o),k(X.$$.fragment,o),k(ge.$$.fragment,o),k(me.$$.fragment,o),k(pe.$$.fragment,o),k(ue.$$.fragment,o),k(te.$$.fragment,o),k(fe.$$.fragment,o),k(be.$$.fragment,o),k(ve.$$.fragment,o),k(we.$$.fragment,o),k(xe.$$.fragment,o),k($e.$$.fragment,o),k(re.$$.fragment,o),Mo=!0)},o(o){E(p.$$.fragment,o),E(L.$$.fragment,o),E(le.$$.fragment,o),E(ce.$$.fragment,o),E(he.$$.fragment,o),E(X.$$.fragment,o),E(ge.$$.fragment,o),E(me.$$.fragment,o),E(pe.$$.fragment,o),E(ue.$$.fragment,o),E(te.$$.fragment,o),E(fe.$$.fragment,o),E(be.$$.fragment,o),E(ve.$$.fragment,o),E(we.$$.fragment,o),E(xe.$$.fragment,o),E($e.$$.fragment,o),E(re.$$.fragment,o),Mo=!1},d(o){t(h),o&&t(T),o&&t(u),M(p),o&&t(H),o&&t(P),M(L),o&&t(uo),o&&t(J),o&&t(fo),o&&t(U),M(le),o&&t(_o),o&&t(N),M(ce),M(he),M(X),M(ge),M(me),o&&t(bo),o&&t(V),M(pe),o&&t(vo),o&&t(S),M(ue),M(te),o&&t(yo),o&&t(R),M(fe),o&&t(wo),o&&t(j),M(be),o&&t(xo),o&&t(I),M(ve),o&&t($o),o&&t(B),M(we),o&&t(ko),o&&t(Y),M(xe),o&&t(Eo),o&&t(D),M($e),M(re)}}}const aa={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"},{local:"huggingface_hub.from_pretrained_fastai",title:"Fastai"}],title:"Mixins"}],title:"Mixins & serialization methods"};function ra(G){return Zn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ca extends Gn{constructor(h){super();Jn(this,h,ra,na,Qn,{})}}export{ca as default,aa as metadata};
