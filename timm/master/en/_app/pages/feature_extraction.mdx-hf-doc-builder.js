import{S as Ul,i as ql,s as Hl,e as r,k as i,w as m,t as h,M as Ll,c as l,d as t,m as p,a as n,x as u,h as c,b as f,G as s,g as o,y as d,L as Ml,q as v,o as g,B as $,v as Bl}from"../chunks/vendor-hf-doc-builder.js";import{I as _}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as w}from"../chunks/CodeBlock-hf-doc-builder.js";function Rl(yr){let k,qt,E,H,Ve,se,Zs,Xe,ea,Ht,L,ta,Ye,sa,aa,Lt,x,M,Ze,ae,ra,et,la,Mt,Ce,na,Bt,S,B,tt,re,oa,st,ia,Rt,Fe,pa,It,j,ha,at,ca,fa,rt,ma,ua,Wt,Ne,da,Qt,P,R,lt,le,va,nt,ga,Gt,ne,Jt,De,$a,Kt,oe,Vt,O,I,ot,ie,wa,it,_a,Xt,pe,Yt,Ue,ba,Zt,he,es,A,W,pt,ce,ja,ht,ya,ts,fe,ss,qe,ka,as,me,rs,T,Q,ct,ue,Ea,ft,xa,ls,G,Sa,mt,Pa,Oa,ns,z,J,ut,de,Aa,dt,Ta,os,ve,is,He,za,ps,ge,hs,C,K,vt,$e,Ca,gt,Fa,cs,we,fs,Le,Na,ms,_e,us,F,V,$t,be,Da,wt,Ua,ds,Me,qa,vs,je,_t,Ha,La,gs,y,Ma,bt,Ba,Ra,jt,Ia,Wa,$s,N,X,yt,ye,Qa,kt,Ga,ws,ke,_s,Be,Ja,bs,Ee,js,D,Y,Et,xe,Ka,xt,Va,ys,Z,Xa,St,Ya,Za,ks,Se,Es,Re,er,xs,Pe,Ss,U,ee,Pt,Oe,tr,Ot,sr,Ps,Ie,ar,Os,te,We,At,rr,lr,nr,Qe,Tt,or,ir,As,b,zt,pr,hr,Ct,cr,fr,Ft,mr,ur,Ts,q,Nt,dr,vr,Dt,gr,$r,zs,Ae,Cs,Ge,wr,Fs,Te,Ns;return se=new _({}),ae=new _({}),re=new _({}),le=new _({}),ne=new w({props:{code:`import torch
import timm
m = timm.create_model('xception41', pretrained=True)
o = m(torch.randn(2, 3, 299, 299))
print(f'Original shape: {o.shape}')
o = m.forward_features(torch.randn(2, 3, 299, 299))
print(f'Unpooled shape: {o.shape}')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;xception41&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">299</span>, <span class="hljs-number">299</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Original shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m.forward_features(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">299</span>, <span class="hljs-number">299</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Unpooled shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)`}}),oe=new w({props:{code:`Original shape: torch.Size([2, 1000])
Unpooled shape: torch.Size([2, 2048, 10, 10])`,highlighted:`Original shape: torch.Size([2, 1000])
Unpooled shape: torch.Size([2, 2048, 10, 10])`}}),ie=new _({}),pe=new w({props:{code:`import torch
import timm
m = timm.create_model('resnet50', pretrained=True, num_classes=0, global_pool='')
o = m(torch.randn(2, 3, 224, 224))
print(f'Unpooled shape: {o.shape}')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;resnet50&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=<span class="hljs-number">0</span>, global_pool=<span class="hljs-string">&#x27;&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Unpooled shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)`}}),he=new w({props:{code:"Unpooled shape: torch.Size([2, 2048, 7, 7])",highlighted:"Unpooled shape: torch.Size([2, 2048, 7, 7])"}}),ce=new _({}),fe=new w({props:{code:`import torch
import timm
m = timm.create_model('densenet121', pretrained=True)
o = m(torch.randn(2, 3, 224, 224))
print(f'Original shape: {o.shape}')
m.reset_classifier(0, '')
o = m(torch.randn(2, 3, 224, 224))
print(f'Unpooled shape: {o.shape}')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;densenet121&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Original shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m.reset_classifier(<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Unpooled shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)`}}),me=new w({props:{code:`Original shape: torch.Size([2, 1000])
Unpooled shape: torch.Size([2, 1024, 7, 7])`,highlighted:`Original shape: torch.Size([2, 1000])
Unpooled shape: torch.Size([2, 1024, 7, 7])`}}),ue=new _({}),de=new _({}),ve=new w({props:{code:`import torch
import timm
m = timm.create_model('resnet50', pretrained=True, num_classes=0)
o = m(torch.randn(2, 3, 224, 224))
print(f'Pooled shape: {o.shape}')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;resnet50&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Pooled shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)`}}),ge=new w({props:{code:"Pooled shape: torch.Size([2, 2048])",highlighted:"Pooled shape: torch.Size([2, 2048])"}}),$e=new _({}),we=new w({props:{code:`import torch
import timm
m = timm.create_model('ese_vovnet19b_dw', pretrained=True)
o = m(torch.randn(2, 3, 224, 224))
print(f'Original shape: {o.shape}')
m.reset_classifier(0)
o = m(torch.randn(2, 3, 224, 224))
print(f'Pooled shape: {o.shape}')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;ese_vovnet19b_dw&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Original shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m.reset_classifier(<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Pooled shape: <span class="hljs-subst">{o.shape}</span>&#x27;</span>)`}}),_e=new w({props:{code:`Original shape: torch.Size([2, 1000])
Pooled shape: torch.Size([2, 1024])`,highlighted:`Original shape: torch.Size([2, 1000])
Pooled shape: torch.Size([2, 1024])`}}),be=new _({}),ye=new _({}),ke=new w({props:{code:`import torch
import timm
m = timm.create_model('resnest26d', features_only=True, pretrained=True)
o = m(torch.randn(2, 3, 224, 224))
for x in o:
    print(x.shape)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;resnest26d&#x27;</span>, features_only=<span class="hljs-literal">True</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> o:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(x.shape)`}}),Ee=new w({props:{code:`torch.Size([2, 64, 112, 112])
torch.Size([2, 256, 56, 56])
torch.Size([2, 512, 28, 28])
torch.Size([2, 1024, 14, 14])
torch.Size([2, 2048, 7, 7])`,highlighted:`torch.Size([2, 64, 112, 112])
torch.Size([2, 256, 56, 56])
torch.Size([2, 512, 28, 28])
torch.Size([2, 1024, 14, 14])
torch.Size([2, 2048, 7, 7])`}}),xe=new _({}),Se=new w({props:{code:`import torch
import timm
m = timm.create_model('regnety_032', features_only=True, pretrained=True)
print(f'Feature channels: {m.feature_info.channels()}')
o = m(torch.randn(2, 3, 224, 224))
for x in o:
    print(x.shape)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;regnety_032&#x27;</span>, features_only=<span class="hljs-literal">True</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Feature channels: <span class="hljs-subst">{m.feature_info.channels()}</span>&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> o:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(x.shape)`}}),Pe=new w({props:{code:`Feature channels: [32, 72, 216, 576, 1512]
torch.Size([2, 32, 112, 112])
torch.Size([2, 72, 56, 56])
torch.Size([2, 216, 28, 28])
torch.Size([2, 576, 14, 14])
torch.Size([2, 1512, 7, 7])`,highlighted:`Feature channels: [32, 72, 216, 576, 1512]
torch.Size([2, 32, 112, 112])
torch.Size([2, 72, 56, 56])
torch.Size([2, 216, 28, 28])
torch.Size([2, 576, 14, 14])
torch.Size([2, 1512, 7, 7])`}}),Oe=new _({}),Ae=new w({props:{code:`import torch
import timm
m = timm.create_model('ecaresnet101d', features_only=True, output_stride=8, out_indices=(2, 4), pretrained=True)
print(f'Feature channels: {m.feature_info.channels()}')
print(f'Feature reduction: {m.feature_info.reduction()}')
o = m(torch.randn(2, 3, 320, 320))
for x in o:
    print(x.shape)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>m = timm.create_model(<span class="hljs-string">&#x27;ecaresnet101d&#x27;</span>, features_only=<span class="hljs-literal">True</span>, output_stride=<span class="hljs-number">8</span>, out_indices=(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>), pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Feature channels: <span class="hljs-subst">{m.feature_info.channels()}</span>&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Feature reduction: <span class="hljs-subst">{m.feature_info.reduction()}</span>&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>o = m(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">320</span>, <span class="hljs-number">320</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> o:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(x.shape)`}}),Te=new w({props:{code:`Feature channels: [512, 2048]
Feature reduction: [8, 8]
torch.Size([2, 512, 40, 40])
torch.Size([2, 2048, 40, 40])`,highlighted:`Feature channels: [512, 2048]
Feature reduction: [8, 8]
torch.Size([2, 512, 40, 40])
torch.Size([2, 2048, 40, 40])`}}),{c(){k=r("meta"),qt=i(),E=r("h1"),H=r("a"),Ve=r("span"),m(se.$$.fragment),Zs=i(),Xe=r("span"),ea=h("Feature Extraction"),Ht=i(),L=r("p"),ta=h("All of the models in "),Ye=r("code"),sa=h("timm"),aa=h(" have consistent mechanisms for obtaining various types of features from the model for tasks besides classification."),Lt=i(),x=r("h2"),M=r("a"),Ze=r("span"),m(ae.$$.fragment),ra=i(),et=r("span"),la=h("Penultimate Layer Features (Pre-Classifier Features)"),Mt=i(),Ce=r("p"),na=h("The features from the penultimate model layer can be obtained in several ways without requiring model surgery (although feel free to do surgery). One must first decide if they want pooled or un-pooled features."),Bt=i(),S=r("h3"),B=r("a"),tt=r("span"),m(re.$$.fragment),oa=i(),st=r("span"),ia=h("Unpooled"),Rt=i(),Fe=r("p"),pa=h("There are three ways to obtain unpooled features."),It=i(),j=r("p"),ha=h("Without modifying the network, one can call "),at=r("code"),ca=h("model.forward_features(input)"),fa=h(" on any model instead of the usual "),rt=r("code"),ma=h("model(input)"),ua=h(". This will bypass the head classifier and global pooling for networks."),Wt=i(),Ne=r("p"),da=h("If one wants to explicitly modify the network to return unpooled features, they can either create the model without a classifier and pooling, or remove it later. Both paths remove the parameters associated with the classifier from the network."),Qt=i(),P=r("h4"),R=r("a"),lt=r("span"),m(le.$$.fragment),va=i(),nt=r("span"),ga=h("forward_features()"),Gt=i(),m(ne.$$.fragment),Jt=i(),De=r("p"),$a=h("Output:"),Kt=i(),m(oe.$$.fragment),Vt=i(),O=r("h4"),I=r("a"),ot=r("span"),m(ie.$$.fragment),wa=i(),it=r("span"),_a=h("Create with no classifier and pooling"),Xt=i(),m(pe.$$.fragment),Yt=i(),Ue=r("p"),ba=h("Output:"),Zt=i(),m(he.$$.fragment),es=i(),A=r("h4"),W=r("a"),pt=r("span"),m(ce.$$.fragment),ja=i(),ht=r("span"),ya=h("Remove it later"),ts=i(),m(fe.$$.fragment),ss=i(),qe=r("p"),ka=h("Output:"),as=i(),m(me.$$.fragment),rs=i(),T=r("h3"),Q=r("a"),ct=r("span"),m(ue.$$.fragment),Ea=i(),ft=r("span"),xa=h("Pooled"),ls=i(),G=r("p"),Sa=h("To modify the network to return pooled features, one can use "),mt=r("code"),Pa=h("forward_features()"),Oa=h(" and pool/flatten the result themselves, or modify the network like above but keep pooling intact."),ns=i(),z=r("h4"),J=r("a"),ut=r("span"),m(de.$$.fragment),Aa=i(),dt=r("span"),Ta=h("Create with no classifier"),os=i(),m(ve.$$.fragment),is=i(),He=r("p"),za=h("Output:"),ps=i(),m(ge.$$.fragment),hs=i(),C=r("h4"),K=r("a"),vt=r("span"),m($e.$$.fragment),Ca=i(),gt=r("span"),Fa=h("Remove it later"),cs=i(),m(we.$$.fragment),fs=i(),Le=r("p"),Na=h("Output:"),ms=i(),m(_e.$$.fragment),us=i(),F=r("h2"),V=r("a"),$t=r("span"),m(be.$$.fragment),Da=i(),wt=r("span"),Ua=h("Multi-scale Feature Maps (Feature Pyramid)"),ds=i(),Me=r("p"),qa=h("Object detection, segmentation, keypoint, and a variety of dense pixel tasks require access to feature maps from the backbone network at multiple scales. This is often done by modifying the original classification network. Since each network varies quite a bit in structure, it\u2019s not uncommon to see only a few backbones supported in any given obj detection or segmentation library."),vs=i(),je=r("p"),_t=r("code"),Ha=h("timm"),La=h(" allows a consistent interface for creating any of the included models as feature backbones that output feature maps for selected levels."),gs=i(),y=r("p"),Ma=h("A feature backbone can be created by adding the argument "),bt=r("code"),Ba=h("features_only=True"),Ra=h(" to any "),jt=r("code"),Ia=h("create_model"),Wa=h(" call. By default 5 strides will be output from most models (not all have that many), with the first starting at 2 (some start at 1 or 4)."),$s=i(),N=r("h3"),X=r("a"),yt=r("span"),m(ye.$$.fragment),Qa=i(),kt=r("span"),Ga=h("Create a feature map extraction model"),ws=i(),m(ke.$$.fragment),_s=i(),Be=r("p"),Ja=h("Output:"),bs=i(),m(Ee.$$.fragment),js=i(),D=r("h3"),Y=r("a"),Et=r("span"),m(xe.$$.fragment),Ka=i(),xt=r("span"),Va=h("Query the feature information"),ys=i(),Z=r("p"),Xa=h("After a feature backbone has been created, it can be queried to provide channel or resolution reduction information to the downstream heads without requiring static config or hardcoded constants. The "),St=r("code"),Ya=h(".feature_info"),Za=h(" attribute is a class encapsulating the information about the feature extraction points."),ks=i(),m(Se.$$.fragment),Es=i(),Re=r("p"),er=h("Output:"),xs=i(),m(Pe.$$.fragment),Ss=i(),U=r("h3"),ee=r("a"),Pt=r("span"),m(Oe.$$.fragment),tr=i(),Ot=r("span"),sr=h("Select specific feature levels or limit the stride"),Ps=i(),Ie=r("p"),ar=h("There are two additional creation arguments impacting the output features."),Os=i(),te=r("ul"),We=r("li"),At=r("code"),rr=h("out_indices"),lr=h(" selects which indices to output"),nr=i(),Qe=r("li"),Tt=r("code"),or=h("output_stride"),ir=h(" limits the feature output stride of the network (also works in classification mode BTW)"),As=i(),b=r("p"),zt=r("code"),pr=h("out_indices"),hr=h(" is supported by all models, but not all models have the same index to feature stride mapping. Look at the code or check feature_info to compare. The out indices generally correspond to the "),Ct=r("code"),cr=h("C(i+1)th"),fr=h(" feature level (a "),Ft=r("code"),mr=h("2^(i+1)"),ur=h(" reduction). For most models, index 0 is the stride 2 features, and index 4 is stride 32."),Ts=i(),q=r("p"),Nt=r("code"),dr=h("output_stride"),vr=h(" is achieved by converting layers to use dilated convolutions. Doing so is not always straightforward, some networks only support "),Dt=r("code"),gr=h("output_stride=32"),$r=h("."),zs=i(),m(Ae.$$.fragment),Cs=i(),Ge=r("p"),wr=h("Output:"),Fs=i(),m(Te.$$.fragment),this.h()},l(e){const a=Ll('[data-svelte="svelte-1phssyn"]',document.head);k=l(a,"META",{name:!0,content:!0}),a.forEach(t),qt=p(e),E=l(e,"H1",{class:!0});var Ds=n(E);H=l(Ds,"A",{id:!0,class:!0,href:!0});var kr=n(H);Ve=l(kr,"SPAN",{});var Er=n(Ve);u(se.$$.fragment,Er),Er.forEach(t),kr.forEach(t),Zs=p(Ds),Xe=l(Ds,"SPAN",{});var xr=n(Xe);ea=c(xr,"Feature Extraction"),xr.forEach(t),Ds.forEach(t),Ht=p(e),L=l(e,"P",{});var Us=n(L);ta=c(Us,"All of the models in "),Ye=l(Us,"CODE",{});var Sr=n(Ye);sa=c(Sr,"timm"),Sr.forEach(t),aa=c(Us," have consistent mechanisms for obtaining various types of features from the model for tasks besides classification."),Us.forEach(t),Lt=p(e),x=l(e,"H2",{class:!0});var qs=n(x);M=l(qs,"A",{id:!0,class:!0,href:!0});var Pr=n(M);Ze=l(Pr,"SPAN",{});var Or=n(Ze);u(ae.$$.fragment,Or),Or.forEach(t),Pr.forEach(t),ra=p(qs),et=l(qs,"SPAN",{});var Ar=n(et);la=c(Ar,"Penultimate Layer Features (Pre-Classifier Features)"),Ar.forEach(t),qs.forEach(t),Mt=p(e),Ce=l(e,"P",{});var Tr=n(Ce);na=c(Tr,"The features from the penultimate model layer can be obtained in several ways without requiring model surgery (although feel free to do surgery). One must first decide if they want pooled or un-pooled features."),Tr.forEach(t),Bt=p(e),S=l(e,"H3",{class:!0});var Hs=n(S);B=l(Hs,"A",{id:!0,class:!0,href:!0});var zr=n(B);tt=l(zr,"SPAN",{});var Cr=n(tt);u(re.$$.fragment,Cr),Cr.forEach(t),zr.forEach(t),oa=p(Hs),st=l(Hs,"SPAN",{});var Fr=n(st);ia=c(Fr,"Unpooled"),Fr.forEach(t),Hs.forEach(t),Rt=p(e),Fe=l(e,"P",{});var Nr=n(Fe);pa=c(Nr,"There are three ways to obtain unpooled features."),Nr.forEach(t),It=p(e),j=l(e,"P",{});var Je=n(j);ha=c(Je,"Without modifying the network, one can call "),at=l(Je,"CODE",{});var Dr=n(at);ca=c(Dr,"model.forward_features(input)"),Dr.forEach(t),fa=c(Je," on any model instead of the usual "),rt=l(Je,"CODE",{});var Ur=n(rt);ma=c(Ur,"model(input)"),Ur.forEach(t),ua=c(Je,". This will bypass the head classifier and global pooling for networks."),Je.forEach(t),Wt=p(e),Ne=l(e,"P",{});var qr=n(Ne);da=c(qr,"If one wants to explicitly modify the network to return unpooled features, they can either create the model without a classifier and pooling, or remove it later. Both paths remove the parameters associated with the classifier from the network."),qr.forEach(t),Qt=p(e),P=l(e,"H4",{class:!0});var Ls=n(P);R=l(Ls,"A",{id:!0,class:!0,href:!0});var Hr=n(R);lt=l(Hr,"SPAN",{});var Lr=n(lt);u(le.$$.fragment,Lr),Lr.forEach(t),Hr.forEach(t),va=p(Ls),nt=l(Ls,"SPAN",{});var Mr=n(nt);ga=c(Mr,"forward_features()"),Mr.forEach(t),Ls.forEach(t),Gt=p(e),u(ne.$$.fragment,e),Jt=p(e),De=l(e,"P",{});var Br=n(De);$a=c(Br,"Output:"),Br.forEach(t),Kt=p(e),u(oe.$$.fragment,e),Vt=p(e),O=l(e,"H4",{class:!0});var Ms=n(O);I=l(Ms,"A",{id:!0,class:!0,href:!0});var Rr=n(I);ot=l(Rr,"SPAN",{});var Ir=n(ot);u(ie.$$.fragment,Ir),Ir.forEach(t),Rr.forEach(t),wa=p(Ms),it=l(Ms,"SPAN",{});var Wr=n(it);_a=c(Wr,"Create with no classifier and pooling"),Wr.forEach(t),Ms.forEach(t),Xt=p(e),u(pe.$$.fragment,e),Yt=p(e),Ue=l(e,"P",{});var Qr=n(Ue);ba=c(Qr,"Output:"),Qr.forEach(t),Zt=p(e),u(he.$$.fragment,e),es=p(e),A=l(e,"H4",{class:!0});var Bs=n(A);W=l(Bs,"A",{id:!0,class:!0,href:!0});var Gr=n(W);pt=l(Gr,"SPAN",{});var Jr=n(pt);u(ce.$$.fragment,Jr),Jr.forEach(t),Gr.forEach(t),ja=p(Bs),ht=l(Bs,"SPAN",{});var Kr=n(ht);ya=c(Kr,"Remove it later"),Kr.forEach(t),Bs.forEach(t),ts=p(e),u(fe.$$.fragment,e),ss=p(e),qe=l(e,"P",{});var Vr=n(qe);ka=c(Vr,"Output:"),Vr.forEach(t),as=p(e),u(me.$$.fragment,e),rs=p(e),T=l(e,"H3",{class:!0});var Rs=n(T);Q=l(Rs,"A",{id:!0,class:!0,href:!0});var Xr=n(Q);ct=l(Xr,"SPAN",{});var Yr=n(ct);u(ue.$$.fragment,Yr),Yr.forEach(t),Xr.forEach(t),Ea=p(Rs),ft=l(Rs,"SPAN",{});var Zr=n(ft);xa=c(Zr,"Pooled"),Zr.forEach(t),Rs.forEach(t),ls=p(e),G=l(e,"P",{});var Is=n(G);Sa=c(Is,"To modify the network to return pooled features, one can use "),mt=l(Is,"CODE",{});var el=n(mt);Pa=c(el,"forward_features()"),el.forEach(t),Oa=c(Is," and pool/flatten the result themselves, or modify the network like above but keep pooling intact."),Is.forEach(t),ns=p(e),z=l(e,"H4",{class:!0});var Ws=n(z);J=l(Ws,"A",{id:!0,class:!0,href:!0});var tl=n(J);ut=l(tl,"SPAN",{});var sl=n(ut);u(de.$$.fragment,sl),sl.forEach(t),tl.forEach(t),Aa=p(Ws),dt=l(Ws,"SPAN",{});var al=n(dt);Ta=c(al,"Create with no classifier"),al.forEach(t),Ws.forEach(t),os=p(e),u(ve.$$.fragment,e),is=p(e),He=l(e,"P",{});var rl=n(He);za=c(rl,"Output:"),rl.forEach(t),ps=p(e),u(ge.$$.fragment,e),hs=p(e),C=l(e,"H4",{class:!0});var Qs=n(C);K=l(Qs,"A",{id:!0,class:!0,href:!0});var ll=n(K);vt=l(ll,"SPAN",{});var nl=n(vt);u($e.$$.fragment,nl),nl.forEach(t),ll.forEach(t),Ca=p(Qs),gt=l(Qs,"SPAN",{});var ol=n(gt);Fa=c(ol,"Remove it later"),ol.forEach(t),Qs.forEach(t),cs=p(e),u(we.$$.fragment,e),fs=p(e),Le=l(e,"P",{});var il=n(Le);Na=c(il,"Output:"),il.forEach(t),ms=p(e),u(_e.$$.fragment,e),us=p(e),F=l(e,"H2",{class:!0});var Gs=n(F);V=l(Gs,"A",{id:!0,class:!0,href:!0});var pl=n(V);$t=l(pl,"SPAN",{});var hl=n($t);u(be.$$.fragment,hl),hl.forEach(t),pl.forEach(t),Da=p(Gs),wt=l(Gs,"SPAN",{});var cl=n(wt);Ua=c(cl,"Multi-scale Feature Maps (Feature Pyramid)"),cl.forEach(t),Gs.forEach(t),ds=p(e),Me=l(e,"P",{});var fl=n(Me);qa=c(fl,"Object detection, segmentation, keypoint, and a variety of dense pixel tasks require access to feature maps from the backbone network at multiple scales. This is often done by modifying the original classification network. Since each network varies quite a bit in structure, it\u2019s not uncommon to see only a few backbones supported in any given obj detection or segmentation library."),fl.forEach(t),vs=p(e),je=l(e,"P",{});var _r=n(je);_t=l(_r,"CODE",{});var ml=n(_t);Ha=c(ml,"timm"),ml.forEach(t),La=c(_r," allows a consistent interface for creating any of the included models as feature backbones that output feature maps for selected levels."),_r.forEach(t),gs=p(e),y=l(e,"P",{});var Ke=n(y);Ma=c(Ke,"A feature backbone can be created by adding the argument "),bt=l(Ke,"CODE",{});var ul=n(bt);Ba=c(ul,"features_only=True"),ul.forEach(t),Ra=c(Ke," to any "),jt=l(Ke,"CODE",{});var dl=n(jt);Ia=c(dl,"create_model"),dl.forEach(t),Wa=c(Ke," call. By default 5 strides will be output from most models (not all have that many), with the first starting at 2 (some start at 1 or 4)."),Ke.forEach(t),$s=p(e),N=l(e,"H3",{class:!0});var Js=n(N);X=l(Js,"A",{id:!0,class:!0,href:!0});var vl=n(X);yt=l(vl,"SPAN",{});var gl=n(yt);u(ye.$$.fragment,gl),gl.forEach(t),vl.forEach(t),Qa=p(Js),kt=l(Js,"SPAN",{});var $l=n(kt);Ga=c($l,"Create a feature map extraction model"),$l.forEach(t),Js.forEach(t),ws=p(e),u(ke.$$.fragment,e),_s=p(e),Be=l(e,"P",{});var wl=n(Be);Ja=c(wl,"Output:"),wl.forEach(t),bs=p(e),u(Ee.$$.fragment,e),js=p(e),D=l(e,"H3",{class:!0});var Ks=n(D);Y=l(Ks,"A",{id:!0,class:!0,href:!0});var _l=n(Y);Et=l(_l,"SPAN",{});var bl=n(Et);u(xe.$$.fragment,bl),bl.forEach(t),_l.forEach(t),Ka=p(Ks),xt=l(Ks,"SPAN",{});var jl=n(xt);Va=c(jl,"Query the feature information"),jl.forEach(t),Ks.forEach(t),ys=p(e),Z=l(e,"P",{});var Vs=n(Z);Xa=c(Vs,"After a feature backbone has been created, it can be queried to provide channel or resolution reduction information to the downstream heads without requiring static config or hardcoded constants. The "),St=l(Vs,"CODE",{});var yl=n(St);Ya=c(yl,".feature_info"),yl.forEach(t),Za=c(Vs," attribute is a class encapsulating the information about the feature extraction points."),Vs.forEach(t),ks=p(e),u(Se.$$.fragment,e),Es=p(e),Re=l(e,"P",{});var kl=n(Re);er=c(kl,"Output:"),kl.forEach(t),xs=p(e),u(Pe.$$.fragment,e),Ss=p(e),U=l(e,"H3",{class:!0});var Xs=n(U);ee=l(Xs,"A",{id:!0,class:!0,href:!0});var El=n(ee);Pt=l(El,"SPAN",{});var xl=n(Pt);u(Oe.$$.fragment,xl),xl.forEach(t),El.forEach(t),tr=p(Xs),Ot=l(Xs,"SPAN",{});var Sl=n(Ot);sr=c(Sl,"Select specific feature levels or limit the stride"),Sl.forEach(t),Xs.forEach(t),Ps=p(e),Ie=l(e,"P",{});var Pl=n(Ie);ar=c(Pl,"There are two additional creation arguments impacting the output features."),Pl.forEach(t),Os=p(e),te=l(e,"UL",{});var Ys=n(te);We=l(Ys,"LI",{});var br=n(We);At=l(br,"CODE",{});var Ol=n(At);rr=c(Ol,"out_indices"),Ol.forEach(t),lr=c(br," selects which indices to output"),br.forEach(t),nr=p(Ys),Qe=l(Ys,"LI",{});var jr=n(Qe);Tt=l(jr,"CODE",{});var Al=n(Tt);or=c(Al,"output_stride"),Al.forEach(t),ir=c(jr," limits the feature output stride of the network (also works in classification mode BTW)"),jr.forEach(t),Ys.forEach(t),As=p(e),b=l(e,"P",{});var ze=n(b);zt=l(ze,"CODE",{});var Tl=n(zt);pr=c(Tl,"out_indices"),Tl.forEach(t),hr=c(ze," is supported by all models, but not all models have the same index to feature stride mapping. Look at the code or check feature_info to compare. The out indices generally correspond to the "),Ct=l(ze,"CODE",{});var zl=n(Ct);cr=c(zl,"C(i+1)th"),zl.forEach(t),fr=c(ze," feature level (a "),Ft=l(ze,"CODE",{});var Cl=n(Ft);mr=c(Cl,"2^(i+1)"),Cl.forEach(t),ur=c(ze," reduction). For most models, index 0 is the stride 2 features, and index 4 is stride 32."),ze.forEach(t),Ts=p(e),q=l(e,"P",{});var Ut=n(q);Nt=l(Ut,"CODE",{});var Fl=n(Nt);dr=c(Fl,"output_stride"),Fl.forEach(t),vr=c(Ut," is achieved by converting layers to use dilated convolutions. Doing so is not always straightforward, some networks only support "),Dt=l(Ut,"CODE",{});var Nl=n(Dt);gr=c(Nl,"output_stride=32"),Nl.forEach(t),$r=c(Ut,"."),Ut.forEach(t),zs=p(e),u(Ae.$$.fragment,e),Cs=p(e),Ge=l(e,"P",{});var Dl=n(Ge);wr=c(Dl,"Output:"),Dl.forEach(t),Fs=p(e),u(Te.$$.fragment,e),this.h()},h(){f(k,"name","hf:doc:metadata"),f(k,"content",JSON.stringify(Il)),f(H,"id","feature-extraction"),f(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(H,"href","#feature-extraction"),f(E,"class","relative group"),f(M,"id","penultimate-layer-features-preclassifier-features"),f(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(M,"href","#penultimate-layer-features-preclassifier-features"),f(x,"class","relative group"),f(B,"id","unpooled"),f(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(B,"href","#unpooled"),f(S,"class","relative group"),f(R,"id","forwardfeatures"),f(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(R,"href","#forwardfeatures"),f(P,"class","relative group"),f(I,"id","create-with-no-classifier-and-pooling"),f(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(I,"href","#create-with-no-classifier-and-pooling"),f(O,"class","relative group"),f(W,"id","remove-it-later"),f(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(W,"href","#remove-it-later"),f(A,"class","relative group"),f(Q,"id","pooled"),f(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Q,"href","#pooled"),f(T,"class","relative group"),f(J,"id","create-with-no-classifier"),f(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(J,"href","#create-with-no-classifier"),f(z,"class","relative group"),f(K,"id","remove-it-later"),f(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(K,"href","#remove-it-later"),f(C,"class","relative group"),f(V,"id","multiscale-feature-maps-feature-pyramid"),f(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(V,"href","#multiscale-feature-maps-feature-pyramid"),f(F,"class","relative group"),f(X,"id","create-a-feature-map-extraction-model"),f(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(X,"href","#create-a-feature-map-extraction-model"),f(N,"class","relative group"),f(Y,"id","query-the-feature-information"),f(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Y,"href","#query-the-feature-information"),f(D,"class","relative group"),f(ee,"id","select-specific-feature-levels-or-limit-the-stride"),f(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ee,"href","#select-specific-feature-levels-or-limit-the-stride"),f(U,"class","relative group")},m(e,a){s(document.head,k),o(e,qt,a),o(e,E,a),s(E,H),s(H,Ve),d(se,Ve,null),s(E,Zs),s(E,Xe),s(Xe,ea),o(e,Ht,a),o(e,L,a),s(L,ta),s(L,Ye),s(Ye,sa),s(L,aa),o(e,Lt,a),o(e,x,a),s(x,M),s(M,Ze),d(ae,Ze,null),s(x,ra),s(x,et),s(et,la),o(e,Mt,a),o(e,Ce,a),s(Ce,na),o(e,Bt,a),o(e,S,a),s(S,B),s(B,tt),d(re,tt,null),s(S,oa),s(S,st),s(st,ia),o(e,Rt,a),o(e,Fe,a),s(Fe,pa),o(e,It,a),o(e,j,a),s(j,ha),s(j,at),s(at,ca),s(j,fa),s(j,rt),s(rt,ma),s(j,ua),o(e,Wt,a),o(e,Ne,a),s(Ne,da),o(e,Qt,a),o(e,P,a),s(P,R),s(R,lt),d(le,lt,null),s(P,va),s(P,nt),s(nt,ga),o(e,Gt,a),d(ne,e,a),o(e,Jt,a),o(e,De,a),s(De,$a),o(e,Kt,a),d(oe,e,a),o(e,Vt,a),o(e,O,a),s(O,I),s(I,ot),d(ie,ot,null),s(O,wa),s(O,it),s(it,_a),o(e,Xt,a),d(pe,e,a),o(e,Yt,a),o(e,Ue,a),s(Ue,ba),o(e,Zt,a),d(he,e,a),o(e,es,a),o(e,A,a),s(A,W),s(W,pt),d(ce,pt,null),s(A,ja),s(A,ht),s(ht,ya),o(e,ts,a),d(fe,e,a),o(e,ss,a),o(e,qe,a),s(qe,ka),o(e,as,a),d(me,e,a),o(e,rs,a),o(e,T,a),s(T,Q),s(Q,ct),d(ue,ct,null),s(T,Ea),s(T,ft),s(ft,xa),o(e,ls,a),o(e,G,a),s(G,Sa),s(G,mt),s(mt,Pa),s(G,Oa),o(e,ns,a),o(e,z,a),s(z,J),s(J,ut),d(de,ut,null),s(z,Aa),s(z,dt),s(dt,Ta),o(e,os,a),d(ve,e,a),o(e,is,a),o(e,He,a),s(He,za),o(e,ps,a),d(ge,e,a),o(e,hs,a),o(e,C,a),s(C,K),s(K,vt),d($e,vt,null),s(C,Ca),s(C,gt),s(gt,Fa),o(e,cs,a),d(we,e,a),o(e,fs,a),o(e,Le,a),s(Le,Na),o(e,ms,a),d(_e,e,a),o(e,us,a),o(e,F,a),s(F,V),s(V,$t),d(be,$t,null),s(F,Da),s(F,wt),s(wt,Ua),o(e,ds,a),o(e,Me,a),s(Me,qa),o(e,vs,a),o(e,je,a),s(je,_t),s(_t,Ha),s(je,La),o(e,gs,a),o(e,y,a),s(y,Ma),s(y,bt),s(bt,Ba),s(y,Ra),s(y,jt),s(jt,Ia),s(y,Wa),o(e,$s,a),o(e,N,a),s(N,X),s(X,yt),d(ye,yt,null),s(N,Qa),s(N,kt),s(kt,Ga),o(e,ws,a),d(ke,e,a),o(e,_s,a),o(e,Be,a),s(Be,Ja),o(e,bs,a),d(Ee,e,a),o(e,js,a),o(e,D,a),s(D,Y),s(Y,Et),d(xe,Et,null),s(D,Ka),s(D,xt),s(xt,Va),o(e,ys,a),o(e,Z,a),s(Z,Xa),s(Z,St),s(St,Ya),s(Z,Za),o(e,ks,a),d(Se,e,a),o(e,Es,a),o(e,Re,a),s(Re,er),o(e,xs,a),d(Pe,e,a),o(e,Ss,a),o(e,U,a),s(U,ee),s(ee,Pt),d(Oe,Pt,null),s(U,tr),s(U,Ot),s(Ot,sr),o(e,Ps,a),o(e,Ie,a),s(Ie,ar),o(e,Os,a),o(e,te,a),s(te,We),s(We,At),s(At,rr),s(We,lr),s(te,nr),s(te,Qe),s(Qe,Tt),s(Tt,or),s(Qe,ir),o(e,As,a),o(e,b,a),s(b,zt),s(zt,pr),s(b,hr),s(b,Ct),s(Ct,cr),s(b,fr),s(b,Ft),s(Ft,mr),s(b,ur),o(e,Ts,a),o(e,q,a),s(q,Nt),s(Nt,dr),s(q,vr),s(q,Dt),s(Dt,gr),s(q,$r),o(e,zs,a),d(Ae,e,a),o(e,Cs,a),o(e,Ge,a),s(Ge,wr),o(e,Fs,a),d(Te,e,a),Ns=!0},p:Ml,i(e){Ns||(v(se.$$.fragment,e),v(ae.$$.fragment,e),v(re.$$.fragment,e),v(le.$$.fragment,e),v(ne.$$.fragment,e),v(oe.$$.fragment,e),v(ie.$$.fragment,e),v(pe.$$.fragment,e),v(he.$$.fragment,e),v(ce.$$.fragment,e),v(fe.$$.fragment,e),v(me.$$.fragment,e),v(ue.$$.fragment,e),v(de.$$.fragment,e),v(ve.$$.fragment,e),v(ge.$$.fragment,e),v($e.$$.fragment,e),v(we.$$.fragment,e),v(_e.$$.fragment,e),v(be.$$.fragment,e),v(ye.$$.fragment,e),v(ke.$$.fragment,e),v(Ee.$$.fragment,e),v(xe.$$.fragment,e),v(Se.$$.fragment,e),v(Pe.$$.fragment,e),v(Oe.$$.fragment,e),v(Ae.$$.fragment,e),v(Te.$$.fragment,e),Ns=!0)},o(e){g(se.$$.fragment,e),g(ae.$$.fragment,e),g(re.$$.fragment,e),g(le.$$.fragment,e),g(ne.$$.fragment,e),g(oe.$$.fragment,e),g(ie.$$.fragment,e),g(pe.$$.fragment,e),g(he.$$.fragment,e),g(ce.$$.fragment,e),g(fe.$$.fragment,e),g(me.$$.fragment,e),g(ue.$$.fragment,e),g(de.$$.fragment,e),g(ve.$$.fragment,e),g(ge.$$.fragment,e),g($e.$$.fragment,e),g(we.$$.fragment,e),g(_e.$$.fragment,e),g(be.$$.fragment,e),g(ye.$$.fragment,e),g(ke.$$.fragment,e),g(Ee.$$.fragment,e),g(xe.$$.fragment,e),g(Se.$$.fragment,e),g(Pe.$$.fragment,e),g(Oe.$$.fragment,e),g(Ae.$$.fragment,e),g(Te.$$.fragment,e),Ns=!1},d(e){t(k),e&&t(qt),e&&t(E),$(se),e&&t(Ht),e&&t(L),e&&t(Lt),e&&t(x),$(ae),e&&t(Mt),e&&t(Ce),e&&t(Bt),e&&t(S),$(re),e&&t(Rt),e&&t(Fe),e&&t(It),e&&t(j),e&&t(Wt),e&&t(Ne),e&&t(Qt),e&&t(P),$(le),e&&t(Gt),$(ne,e),e&&t(Jt),e&&t(De),e&&t(Kt),$(oe,e),e&&t(Vt),e&&t(O),$(ie),e&&t(Xt),$(pe,e),e&&t(Yt),e&&t(Ue),e&&t(Zt),$(he,e),e&&t(es),e&&t(A),$(ce),e&&t(ts),$(fe,e),e&&t(ss),e&&t(qe),e&&t(as),$(me,e),e&&t(rs),e&&t(T),$(ue),e&&t(ls),e&&t(G),e&&t(ns),e&&t(z),$(de),e&&t(os),$(ve,e),e&&t(is),e&&t(He),e&&t(ps),$(ge,e),e&&t(hs),e&&t(C),$($e),e&&t(cs),$(we,e),e&&t(fs),e&&t(Le),e&&t(ms),$(_e,e),e&&t(us),e&&t(F),$(be),e&&t(ds),e&&t(Me),e&&t(vs),e&&t(je),e&&t(gs),e&&t(y),e&&t($s),e&&t(N),$(ye),e&&t(ws),$(ke,e),e&&t(_s),e&&t(Be),e&&t(bs),$(Ee,e),e&&t(js),e&&t(D),$(xe),e&&t(ys),e&&t(Z),e&&t(ks),$(Se,e),e&&t(Es),e&&t(Re),e&&t(xs),$(Pe,e),e&&t(Ss),e&&t(U),$(Oe),e&&t(Ps),e&&t(Ie),e&&t(Os),e&&t(te),e&&t(As),e&&t(b),e&&t(Ts),e&&t(q),e&&t(zs),$(Ae,e),e&&t(Cs),e&&t(Ge),e&&t(Fs),$(Te,e)}}}const Il={local:"feature-extraction",sections:[{local:"penultimate-layer-features-preclassifier-features",sections:[{local:"unpooled",sections:[{local:"forwardfeatures",title:"forward_features()"},{local:"create-with-no-classifier-and-pooling",title:"Create with no classifier and pooling"},{local:"remove-it-later",title:"Remove it later"}],title:"Unpooled"},{local:"pooled",sections:[{local:"create-with-no-classifier",title:"Create with no classifier"},{local:"remove-it-later",title:"Remove it later"}],title:"Pooled"}],title:"Penultimate Layer Features (Pre-Classifier Features)"},{local:"multiscale-feature-maps-feature-pyramid",sections:[{local:"create-a-feature-map-extraction-model",title:"Create a feature map extraction model"},{local:"query-the-feature-information",title:"Query the feature information"},{local:"select-specific-feature-levels-or-limit-the-stride",title:"Select specific feature levels or limit the stride"}],title:"Multi-scale Feature Maps (Feature Pyramid)"}],title:"Feature Extraction"};function Wl(yr){return Bl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Kl extends Ul{constructor(k){super();ql(this,k,Wl,Rl,Hl,{})}}export{Kl as default,Il as metadata};
