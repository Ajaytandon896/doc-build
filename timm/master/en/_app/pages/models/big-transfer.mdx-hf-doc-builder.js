import{S as Xs,i as Ds,s as Os,e as n,k as i,w as f,t as h,M as Ks,c as r,d as s,m as p,a as o,x as u,h as c,b as m,G as t,g as l,y as d,L as Zs,q as g,o as w,B as v,v as Qs}from"../../chunks/vendor-hf-doc-builder.js";import{I as fe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ee}from"../../chunks/CodeBlock-hf-doc-builder.js";function Ws(bs){let _,ue,j,x,se,B,Fe,te,Ve,de,H,ae,Xe,De,ge,b,E,ne,C,Oe,re,Ke,we,X,Ze,ve,L,_e,D,Qe,je,G,be,O,We,ye,M,$e,K,es,ke,R,xe,T,ss,le,ts,as,Ee,P,ns,Z,rs,ls,Te,y,S,oe,Y,os,ie,is,Pe,Q,ps,Se,J,Ae,A,ms,z,hs,cs,Ie,$,I,pe,U,fs,me,us,Ne,N,ds,W,gs,ws,qe,k,q,he,F,vs,ce,_s,Be,V,He;return B=new fe({}),C=new fe({}),L=new ee({props:{code:`import timm
model = timm.create_model('resnetv2_101x1_bitm', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;resnetv2_101x1_bitm&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),G=new ee({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),M=new ee({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),R=new ee({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),Y=new fe({}),J=new ee({props:{code:"model = timm.create_model('resnetv2_101x1_bitm', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;resnetv2_101x1_bitm&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),U=new fe({}),F=new fe({}),V=new ee({props:{code:`@misc{kolesnikov2020big,
      title={Big Transfer (BiT): General Visual Representation Learning}, 
      author={Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Joan Puigcerver and Jessica Yung and Sylvain Gelly and Neil Houlsby},
      year={2020},
      eprint={1912.11370},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`@misc{kolesnikov<span class="hljs-symbol">2020b</span>ig,
      title={<span class="hljs-keyword">Big </span>Transfer (<span class="hljs-keyword">BiT): </span>General Visual Representation Learning}, 
      author={Alexander Kolesnikov <span class="hljs-keyword">and </span>Lucas <span class="hljs-keyword">Beyer </span><span class="hljs-keyword">and </span>Xiaohua Zhai <span class="hljs-keyword">and </span><span class="hljs-keyword">Joan </span>Puigcerver <span class="hljs-keyword">and </span><span class="hljs-keyword">Jessica </span>Yung <span class="hljs-keyword">and </span>Sylvain Gelly <span class="hljs-keyword">and </span>Neil Houlsby},
      year={<span class="hljs-number">2020</span>},
      eprint={<span class="hljs-number">1912</span>.<span class="hljs-number">11370</span>},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`}}),{c(){_=n("meta"),ue=i(),j=n("h1"),x=n("a"),se=n("span"),f(B.$$.fragment),Fe=i(),te=n("span"),Ve=h("Big Transfer (BiT)"),de=i(),H=n("p"),ae=n("strong"),Xe=h("Big Transfer (BiT)"),De=h(" is a type of pretraining recipe that pre-trains  on a large supervised source dataset, and fine-tunes the weights on the target task. Models are trained on the JFT-300M dataset. The finetuned models contained in this collection are finetuned on ImageNet."),ge=i(),b=n("h2"),E=n("a"),ne=n("span"),f(C.$$.fragment),Oe=i(),re=n("span"),Ke=h("How do I use this model on an image?"),we=i(),X=n("p"),Ze=h("To load a pretrained model:"),ve=i(),f(L.$$.fragment),_e=i(),D=n("p"),Qe=h("To load and preprocess the image:"),je=i(),f(G.$$.fragment),be=i(),O=n("p"),We=h("To get the model predictions:"),ye=i(),f(M.$$.fragment),$e=i(),K=n("p"),es=h("To get the top-5 predictions class names:"),ke=i(),f(R.$$.fragment),xe=i(),T=n("p"),ss=h("Replace the model name with the variant you want to use, e.g. "),le=n("code"),ts=h("resnetv2_101x1_bitm"),as=h(". You can find the IDs in the model summaries at the top of this page."),Ee=i(),P=n("p"),ns=h("To extract image features with this model, follow the "),Z=n("a"),rs=h("timm feature extraction examples"),ls=h(", just change the name of the model you want to use."),Te=i(),y=n("h2"),S=n("a"),oe=n("span"),f(Y.$$.fragment),os=i(),ie=n("span"),is=h("How do I finetune this model?"),Pe=i(),Q=n("p"),ps=h("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Se=i(),f(J.$$.fragment),Ae=i(),A=n("p"),ms=h("To finetune on your own dataset, you have to write a training loop or adapt "),z=n("a"),hs=h(`timm\u2019s training
script`),cs=h(" to use your dataset."),Ie=i(),$=n("h2"),I=n("a"),pe=n("span"),f(U.$$.fragment),fs=i(),me=n("span"),us=h("How do I train this model?"),Ne=i(),N=n("p"),ds=h("You can follow the "),W=n("a"),gs=h("timm recipe scripts"),ws=h(" for training a new model afresh."),qe=i(),k=n("h2"),q=n("a"),he=n("span"),f(F.$$.fragment),vs=i(),ce=n("span"),_s=h("Citation"),Be=i(),f(V.$$.fragment),this.h()},l(e){const a=Ks('[data-svelte="svelte-1phssyn"]',document.head);_=r(a,"META",{name:!0,content:!0}),a.forEach(s),ue=p(e),j=r(e,"H1",{class:!0});var Ce=o(j);x=r(Ce,"A",{id:!0,class:!0,href:!0});var ys=o(x);se=r(ys,"SPAN",{});var $s=o(se);u(B.$$.fragment,$s),$s.forEach(s),ys.forEach(s),Fe=p(Ce),te=r(Ce,"SPAN",{});var ks=o(te);Ve=c(ks,"Big Transfer (BiT)"),ks.forEach(s),Ce.forEach(s),de=p(e),H=r(e,"P",{});var js=o(H);ae=r(js,"STRONG",{});var xs=o(ae);Xe=c(xs,"Big Transfer (BiT)"),xs.forEach(s),De=c(js," is a type of pretraining recipe that pre-trains  on a large supervised source dataset, and fine-tunes the weights on the target task. Models are trained on the JFT-300M dataset. The finetuned models contained in this collection are finetuned on ImageNet."),js.forEach(s),ge=p(e),b=r(e,"H2",{class:!0});var Le=o(b);E=r(Le,"A",{id:!0,class:!0,href:!0});var Es=o(E);ne=r(Es,"SPAN",{});var Ts=o(ne);u(C.$$.fragment,Ts),Ts.forEach(s),Es.forEach(s),Oe=p(Le),re=r(Le,"SPAN",{});var Ps=o(re);Ke=c(Ps,"How do I use this model on an image?"),Ps.forEach(s),Le.forEach(s),we=p(e),X=r(e,"P",{});var Ss=o(X);Ze=c(Ss,"To load a pretrained model:"),Ss.forEach(s),ve=p(e),u(L.$$.fragment,e),_e=p(e),D=r(e,"P",{});var As=o(D);Qe=c(As,"To load and preprocess the image:"),As.forEach(s),je=p(e),u(G.$$.fragment,e),be=p(e),O=r(e,"P",{});var Is=o(O);We=c(Is,"To get the model predictions:"),Is.forEach(s),ye=p(e),u(M.$$.fragment,e),$e=p(e),K=r(e,"P",{});var Ns=o(K);es=c(Ns,"To get the top-5 predictions class names:"),Ns.forEach(s),ke=p(e),u(R.$$.fragment,e),xe=p(e),T=r(e,"P",{});var Ge=o(T);ss=c(Ge,"Replace the model name with the variant you want to use, e.g. "),le=r(Ge,"CODE",{});var qs=o(le);ts=c(qs,"resnetv2_101x1_bitm"),qs.forEach(s),as=c(Ge,". You can find the IDs in the model summaries at the top of this page."),Ge.forEach(s),Ee=p(e),P=r(e,"P",{});var Me=o(P);ns=c(Me,"To extract image features with this model, follow the "),Z=r(Me,"A",{href:!0});var Bs=o(Z);rs=c(Bs,"timm feature extraction examples"),Bs.forEach(s),ls=c(Me,", just change the name of the model you want to use."),Me.forEach(s),Te=p(e),y=r(e,"H2",{class:!0});var Re=o(y);S=r(Re,"A",{id:!0,class:!0,href:!0});var Hs=o(S);oe=r(Hs,"SPAN",{});var Cs=o(oe);u(Y.$$.fragment,Cs),Cs.forEach(s),Hs.forEach(s),os=p(Re),ie=r(Re,"SPAN",{});var Ls=o(ie);is=c(Ls,"How do I finetune this model?"),Ls.forEach(s),Re.forEach(s),Pe=p(e),Q=r(e,"P",{});var Gs=o(Q);ps=c(Gs,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Gs.forEach(s),Se=p(e),u(J.$$.fragment,e),Ae=p(e),A=r(e,"P",{});var Ye=o(A);ms=c(Ye,"To finetune on your own dataset, you have to write a training loop or adapt "),z=r(Ye,"A",{href:!0,rel:!0});var Ms=o(z);hs=c(Ms,`timm\u2019s training
script`),Ms.forEach(s),cs=c(Ye," to use your dataset."),Ye.forEach(s),Ie=p(e),$=r(e,"H2",{class:!0});var Je=o($);I=r(Je,"A",{id:!0,class:!0,href:!0});var Rs=o(I);pe=r(Rs,"SPAN",{});var Ys=o(pe);u(U.$$.fragment,Ys),Ys.forEach(s),Rs.forEach(s),fs=p(Je),me=r(Je,"SPAN",{});var Js=o(me);us=c(Js,"How do I train this model?"),Js.forEach(s),Je.forEach(s),Ne=p(e),N=r(e,"P",{});var ze=o(N);ds=c(ze,"You can follow the "),W=r(ze,"A",{href:!0});var zs=o(W);gs=c(zs,"timm recipe scripts"),zs.forEach(s),ws=c(ze," for training a new model afresh."),ze.forEach(s),qe=p(e),k=r(e,"H2",{class:!0});var Ue=o(k);q=r(Ue,"A",{id:!0,class:!0,href:!0});var Us=o(q);he=r(Us,"SPAN",{});var Fs=o(he);u(F.$$.fragment,Fs),Fs.forEach(s),Us.forEach(s),vs=p(Ue),ce=r(Ue,"SPAN",{});var Vs=o(ce);_s=c(Vs,"Citation"),Vs.forEach(s),Ue.forEach(s),Be=p(e),u(V.$$.fragment,e),this.h()},h(){m(_,"name","hf:doc:metadata"),m(_,"content",JSON.stringify(et)),m(x,"id","big-transfer-bit"),m(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x,"href","#big-transfer-bit"),m(j,"class","relative group"),m(E,"id","how-do-i-use-this-model-on-an-image"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#how-do-i-use-this-model-on-an-image"),m(b,"class","relative group"),m(Z,"href","../feature_extraction"),m(S,"id","how-do-i-finetune-this-model"),m(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S,"href","#how-do-i-finetune-this-model"),m(y,"class","relative group"),m(z,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),m(z,"rel","nofollow"),m(I,"id","how-do-i-train-this-model"),m(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I,"href","#how-do-i-train-this-model"),m($,"class","relative group"),m(W,"href","../scripts"),m(q,"id","citation"),m(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(q,"href","#citation"),m(k,"class","relative group")},m(e,a){t(document.head,_),l(e,ue,a),l(e,j,a),t(j,x),t(x,se),d(B,se,null),t(j,Fe),t(j,te),t(te,Ve),l(e,de,a),l(e,H,a),t(H,ae),t(ae,Xe),t(H,De),l(e,ge,a),l(e,b,a),t(b,E),t(E,ne),d(C,ne,null),t(b,Oe),t(b,re),t(re,Ke),l(e,we,a),l(e,X,a),t(X,Ze),l(e,ve,a),d(L,e,a),l(e,_e,a),l(e,D,a),t(D,Qe),l(e,je,a),d(G,e,a),l(e,be,a),l(e,O,a),t(O,We),l(e,ye,a),d(M,e,a),l(e,$e,a),l(e,K,a),t(K,es),l(e,ke,a),d(R,e,a),l(e,xe,a),l(e,T,a),t(T,ss),t(T,le),t(le,ts),t(T,as),l(e,Ee,a),l(e,P,a),t(P,ns),t(P,Z),t(Z,rs),t(P,ls),l(e,Te,a),l(e,y,a),t(y,S),t(S,oe),d(Y,oe,null),t(y,os),t(y,ie),t(ie,is),l(e,Pe,a),l(e,Q,a),t(Q,ps),l(e,Se,a),d(J,e,a),l(e,Ae,a),l(e,A,a),t(A,ms),t(A,z),t(z,hs),t(A,cs),l(e,Ie,a),l(e,$,a),t($,I),t(I,pe),d(U,pe,null),t($,fs),t($,me),t(me,us),l(e,Ne,a),l(e,N,a),t(N,ds),t(N,W),t(W,gs),t(N,ws),l(e,qe,a),l(e,k,a),t(k,q),t(q,he),d(F,he,null),t(k,vs),t(k,ce),t(ce,_s),l(e,Be,a),d(V,e,a),He=!0},p:Zs,i(e){He||(g(B.$$.fragment,e),g(C.$$.fragment,e),g(L.$$.fragment,e),g(G.$$.fragment,e),g(M.$$.fragment,e),g(R.$$.fragment,e),g(Y.$$.fragment,e),g(J.$$.fragment,e),g(U.$$.fragment,e),g(F.$$.fragment,e),g(V.$$.fragment,e),He=!0)},o(e){w(B.$$.fragment,e),w(C.$$.fragment,e),w(L.$$.fragment,e),w(G.$$.fragment,e),w(M.$$.fragment,e),w(R.$$.fragment,e),w(Y.$$.fragment,e),w(J.$$.fragment,e),w(U.$$.fragment,e),w(F.$$.fragment,e),w(V.$$.fragment,e),He=!1},d(e){s(_),e&&s(ue),e&&s(j),v(B),e&&s(de),e&&s(H),e&&s(ge),e&&s(b),v(C),e&&s(we),e&&s(X),e&&s(ve),v(L,e),e&&s(_e),e&&s(D),e&&s(je),v(G,e),e&&s(be),e&&s(O),e&&s(ye),v(M,e),e&&s($e),e&&s(K),e&&s(ke),v(R,e),e&&s(xe),e&&s(T),e&&s(Ee),e&&s(P),e&&s(Te),e&&s(y),v(Y),e&&s(Pe),e&&s(Q),e&&s(Se),v(J,e),e&&s(Ae),e&&s(A),e&&s(Ie),e&&s($),v(U),e&&s(Ne),e&&s(N),e&&s(qe),e&&s(k),v(F),e&&s(Be),v(V,e)}}}const et={local:"big-transfer-bit",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"Big Transfer (BiT)"};function st(bs){return Qs(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rt extends Xs{constructor(_){super();Ds(this,_,st,Ws,Os,{})}}export{rt as default,et as metadata};
