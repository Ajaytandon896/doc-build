import{S as Xa,i as Ja,s as Wa,e as l,k as i,w as f,t as h,M as Ka,c as n,d as a,m as p,a as r,x as u,h as c,b as m,G as e,g as o,y as g,L as Qa,q as d,o as w,B as v,v as Va}from"../../chunks/vendor-hf-doc-builder.js";import{I as fs}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ss}from"../../chunks/CodeBlock-hf-doc-builder.js";function Za(ja){let _,us,b,x,as,M,Us,es,Bs,gs,C,ts,Xs,Js,ds,j,S,ls,H,Ws,ns,Ks,ws,X,Qs,vs,L,_s,J,Vs,bs,G,js,W,Zs,$s,z,ys,K,sa,ks,R,xs,E,aa,os,ea,ta,Ss,P,la,Q,na,oa,Es,$,A,rs,D,ra,is,ia,Ps,V,pa,As,O,Is,I,ma,F,ha,ca,Ts,y,T,ps,Y,fa,ms,ua,Ns,N,ga,Z,da,wa,qs,k,q,hs,U,va,cs,_a,Ms,B,Cs;return M=new fs({}),H=new fs({}),L=new ss({props:{code:`import timm
model = timm.create_model('selecsls42b', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;selecsls42b&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),G=new ss({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),z=new ss({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),R=new ss({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),D=new fs({}),O=new ss({props:{code:"model = timm.create_model('selecsls42b', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;selecsls42b&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),Y=new fs({}),U=new fs({}),B=new ss({props:{code:`@article{Mehta_2020,
   title={XNect},
   volume={39},
   ISSN={1557-7368},
   url={http://dx.doi.org/10.1145/3386569.3392410},
   DOI={10.1145/3386569.3392410},
   number={4},
   journal={ACM Transactions on Graphics},
   publisher={Association for Computing Machinery (ACM)},
   author={Mehta, Dushyant and Sotnychenko, Oleksandr and Mueller, Franziska and Xu, Weipeng and Elgharib, Mohamed and Fua, Pascal and Seidel, Hans-Peter and Rhodin, Helge and Pons-Moll, Gerard and Theobalt, Christian},
   year={2020},
   month={Jul}
}`,highlighted:`<span class="language-xml">@article</span><span class="hljs-template-variable">{Mehta_2020,
   title={XNect}</span><span class="language-xml">,
   volume=</span><span class="hljs-template-variable">{39}</span><span class="language-xml">,
   ISSN=</span><span class="hljs-template-variable">{1557-7368}</span><span class="language-xml">,
   url=</span><span class="hljs-template-variable">{http://dx.doi.org/10.1145/3386569.3392410}</span><span class="language-xml">,
   DOI=</span><span class="hljs-template-variable">{10.1145/3386569.3392410}</span><span class="language-xml">,
   number=</span><span class="hljs-template-variable">{4}</span><span class="language-xml">,
   journal=</span><span class="hljs-template-variable">{ACM Transactions on Graphics}</span><span class="language-xml">,
   publisher=</span><span class="hljs-template-variable">{Association for Computing Machinery (ACM)}</span><span class="language-xml">,
   author=</span><span class="hljs-template-variable">{Mehta, Dushyant and Sotnychenko, Oleksandr and Mueller, Franziska and Xu, Weipeng and Elgharib, Mohamed and Fua, Pascal and Seidel, Hans-Peter and Rhodin, Helge and Pons-Moll, Gerard and Theobalt, Christian}</span><span class="language-xml">,
   year=</span><span class="hljs-template-variable">{2020}</span><span class="language-xml">,
   month=</span><span class="hljs-template-variable">{Jul}</span><span class="language-xml">
}</span>`}}),{c(){_=l("meta"),us=i(),b=l("h1"),x=l("a"),as=l("span"),f(M.$$.fragment),Us=i(),es=l("span"),Bs=h("SelecSLS"),gs=i(),C=l("p"),ts=l("strong"),Xs=h("SelecSLS"),Js=h(" uses novel selective long and short range skip connections to improve the information flow allowing for a drastically faster network without compromising accuracy."),ds=i(),j=l("h2"),S=l("a"),ls=l("span"),f(H.$$.fragment),Ws=i(),ns=l("span"),Ks=h("How do I use this model on an image?"),ws=i(),X=l("p"),Qs=h("To load a pretrained model:"),vs=i(),f(L.$$.fragment),_s=i(),J=l("p"),Vs=h("To load and preprocess the image:"),bs=i(),f(G.$$.fragment),js=i(),W=l("p"),Zs=h("To get the model predictions:"),$s=i(),f(z.$$.fragment),ys=i(),K=l("p"),sa=h("To get the top-5 predictions class names:"),ks=i(),f(R.$$.fragment),xs=i(),E=l("p"),aa=h("Replace the model name with the variant you want to use, e.g. "),os=l("code"),ea=h("selecsls42b"),ta=h(". You can find the IDs in the model summaries at the top of this page."),Ss=i(),P=l("p"),la=h("To extract image features with this model, follow the "),Q=l("a"),na=h("timm feature extraction examples"),oa=h(", just change the name of the model you want to use."),Es=i(),$=l("h2"),A=l("a"),rs=l("span"),f(D.$$.fragment),ra=i(),is=l("span"),ia=h("How do I finetune this model?"),Ps=i(),V=l("p"),pa=h("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),As=i(),f(O.$$.fragment),Is=i(),I=l("p"),ma=h("To finetune on your own dataset, you have to write a training loop or adapt "),F=l("a"),ha=h(`timm\u2019s training
script`),ca=h(" to use your dataset."),Ts=i(),y=l("h2"),T=l("a"),ps=l("span"),f(Y.$$.fragment),fa=i(),ms=l("span"),ua=h("How do I train this model?"),Ns=i(),N=l("p"),ga=h("You can follow the "),Z=l("a"),da=h("timm recipe scripts"),wa=h(" for training a new model afresh."),qs=i(),k=l("h2"),q=l("a"),hs=l("span"),f(U.$$.fragment),va=i(),cs=l("span"),_a=h("Citation"),Ms=i(),f(B.$$.fragment),this.h()},l(s){const t=Ka('[data-svelte="svelte-1phssyn"]',document.head);_=n(t,"META",{name:!0,content:!0}),t.forEach(a),us=p(s),b=n(s,"H1",{class:!0});var Hs=r(b);x=n(Hs,"A",{id:!0,class:!0,href:!0});var $a=r(x);as=n($a,"SPAN",{});var ya=r(as);u(M.$$.fragment,ya),ya.forEach(a),$a.forEach(a),Us=p(Hs),es=n(Hs,"SPAN",{});var ka=r(es);Bs=c(ka,"SelecSLS"),ka.forEach(a),Hs.forEach(a),gs=p(s),C=n(s,"P",{});var ba=r(C);ts=n(ba,"STRONG",{});var xa=r(ts);Xs=c(xa,"SelecSLS"),xa.forEach(a),Js=c(ba," uses novel selective long and short range skip connections to improve the information flow allowing for a drastically faster network without compromising accuracy."),ba.forEach(a),ds=p(s),j=n(s,"H2",{class:!0});var Ls=r(j);S=n(Ls,"A",{id:!0,class:!0,href:!0});var Sa=r(S);ls=n(Sa,"SPAN",{});var Ea=r(ls);u(H.$$.fragment,Ea),Ea.forEach(a),Sa.forEach(a),Ws=p(Ls),ns=n(Ls,"SPAN",{});var Pa=r(ns);Ks=c(Pa,"How do I use this model on an image?"),Pa.forEach(a),Ls.forEach(a),ws=p(s),X=n(s,"P",{});var Aa=r(X);Qs=c(Aa,"To load a pretrained model:"),Aa.forEach(a),vs=p(s),u(L.$$.fragment,s),_s=p(s),J=n(s,"P",{});var Ia=r(J);Vs=c(Ia,"To load and preprocess the image:"),Ia.forEach(a),bs=p(s),u(G.$$.fragment,s),js=p(s),W=n(s,"P",{});var Ta=r(W);Zs=c(Ta,"To get the model predictions:"),Ta.forEach(a),$s=p(s),u(z.$$.fragment,s),ys=p(s),K=n(s,"P",{});var Na=r(K);sa=c(Na,"To get the top-5 predictions class names:"),Na.forEach(a),ks=p(s),u(R.$$.fragment,s),xs=p(s),E=n(s,"P",{});var Gs=r(E);aa=c(Gs,"Replace the model name with the variant you want to use, e.g. "),os=n(Gs,"CODE",{});var qa=r(os);ea=c(qa,"selecsls42b"),qa.forEach(a),ta=c(Gs,". You can find the IDs in the model summaries at the top of this page."),Gs.forEach(a),Ss=p(s),P=n(s,"P",{});var zs=r(P);la=c(zs,"To extract image features with this model, follow the "),Q=n(zs,"A",{href:!0});var Ma=r(Q);na=c(Ma,"timm feature extraction examples"),Ma.forEach(a),oa=c(zs,", just change the name of the model you want to use."),zs.forEach(a),Es=p(s),$=n(s,"H2",{class:!0});var Rs=r($);A=n(Rs,"A",{id:!0,class:!0,href:!0});var Ca=r(A);rs=n(Ca,"SPAN",{});var Ha=r(rs);u(D.$$.fragment,Ha),Ha.forEach(a),Ca.forEach(a),ra=p(Rs),is=n(Rs,"SPAN",{});var La=r(is);ia=c(La,"How do I finetune this model?"),La.forEach(a),Rs.forEach(a),Ps=p(s),V=n(s,"P",{});var Ga=r(V);pa=c(Ga,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ga.forEach(a),As=p(s),u(O.$$.fragment,s),Is=p(s),I=n(s,"P",{});var Ds=r(I);ma=c(Ds,"To finetune on your own dataset, you have to write a training loop or adapt "),F=n(Ds,"A",{href:!0,rel:!0});var za=r(F);ha=c(za,`timm\u2019s training
script`),za.forEach(a),ca=c(Ds," to use your dataset."),Ds.forEach(a),Ts=p(s),y=n(s,"H2",{class:!0});var Os=r(y);T=n(Os,"A",{id:!0,class:!0,href:!0});var Ra=r(T);ps=n(Ra,"SPAN",{});var Da=r(ps);u(Y.$$.fragment,Da),Da.forEach(a),Ra.forEach(a),fa=p(Os),ms=n(Os,"SPAN",{});var Oa=r(ms);ua=c(Oa,"How do I train this model?"),Oa.forEach(a),Os.forEach(a),Ns=p(s),N=n(s,"P",{});var Fs=r(N);ga=c(Fs,"You can follow the "),Z=n(Fs,"A",{href:!0});var Fa=r(Z);da=c(Fa,"timm recipe scripts"),Fa.forEach(a),wa=c(Fs," for training a new model afresh."),Fs.forEach(a),qs=p(s),k=n(s,"H2",{class:!0});var Ys=r(k);q=n(Ys,"A",{id:!0,class:!0,href:!0});var Ya=r(q);hs=n(Ya,"SPAN",{});var Ua=r(hs);u(U.$$.fragment,Ua),Ua.forEach(a),Ya.forEach(a),va=p(Ys),cs=n(Ys,"SPAN",{});var Ba=r(cs);_a=c(Ba,"Citation"),Ba.forEach(a),Ys.forEach(a),Ms=p(s),u(B.$$.fragment,s),this.h()},h(){m(_,"name","hf:doc:metadata"),m(_,"content",JSON.stringify(se)),m(x,"id","selecsls"),m(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x,"href","#selecsls"),m(b,"class","relative group"),m(S,"id","how-do-i-use-this-model-on-an-image"),m(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S,"href","#how-do-i-use-this-model-on-an-image"),m(j,"class","relative group"),m(Q,"href","../feature_extraction"),m(A,"id","how-do-i-finetune-this-model"),m(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(A,"href","#how-do-i-finetune-this-model"),m($,"class","relative group"),m(F,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),m(F,"rel","nofollow"),m(T,"id","how-do-i-train-this-model"),m(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(T,"href","#how-do-i-train-this-model"),m(y,"class","relative group"),m(Z,"href","../scripts"),m(q,"id","citation"),m(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(q,"href","#citation"),m(k,"class","relative group")},m(s,t){e(document.head,_),o(s,us,t),o(s,b,t),e(b,x),e(x,as),g(M,as,null),e(b,Us),e(b,es),e(es,Bs),o(s,gs,t),o(s,C,t),e(C,ts),e(ts,Xs),e(C,Js),o(s,ds,t),o(s,j,t),e(j,S),e(S,ls),g(H,ls,null),e(j,Ws),e(j,ns),e(ns,Ks),o(s,ws,t),o(s,X,t),e(X,Qs),o(s,vs,t),g(L,s,t),o(s,_s,t),o(s,J,t),e(J,Vs),o(s,bs,t),g(G,s,t),o(s,js,t),o(s,W,t),e(W,Zs),o(s,$s,t),g(z,s,t),o(s,ys,t),o(s,K,t),e(K,sa),o(s,ks,t),g(R,s,t),o(s,xs,t),o(s,E,t),e(E,aa),e(E,os),e(os,ea),e(E,ta),o(s,Ss,t),o(s,P,t),e(P,la),e(P,Q),e(Q,na),e(P,oa),o(s,Es,t),o(s,$,t),e($,A),e(A,rs),g(D,rs,null),e($,ra),e($,is),e(is,ia),o(s,Ps,t),o(s,V,t),e(V,pa),o(s,As,t),g(O,s,t),o(s,Is,t),o(s,I,t),e(I,ma),e(I,F),e(F,ha),e(I,ca),o(s,Ts,t),o(s,y,t),e(y,T),e(T,ps),g(Y,ps,null),e(y,fa),e(y,ms),e(ms,ua),o(s,Ns,t),o(s,N,t),e(N,ga),e(N,Z),e(Z,da),e(N,wa),o(s,qs,t),o(s,k,t),e(k,q),e(q,hs),g(U,hs,null),e(k,va),e(k,cs),e(cs,_a),o(s,Ms,t),g(B,s,t),Cs=!0},p:Qa,i(s){Cs||(d(M.$$.fragment,s),d(H.$$.fragment,s),d(L.$$.fragment,s),d(G.$$.fragment,s),d(z.$$.fragment,s),d(R.$$.fragment,s),d(D.$$.fragment,s),d(O.$$.fragment,s),d(Y.$$.fragment,s),d(U.$$.fragment,s),d(B.$$.fragment,s),Cs=!0)},o(s){w(M.$$.fragment,s),w(H.$$.fragment,s),w(L.$$.fragment,s),w(G.$$.fragment,s),w(z.$$.fragment,s),w(R.$$.fragment,s),w(D.$$.fragment,s),w(O.$$.fragment,s),w(Y.$$.fragment,s),w(U.$$.fragment,s),w(B.$$.fragment,s),Cs=!1},d(s){a(_),s&&a(us),s&&a(b),v(M),s&&a(gs),s&&a(C),s&&a(ds),s&&a(j),v(H),s&&a(ws),s&&a(X),s&&a(vs),v(L,s),s&&a(_s),s&&a(J),s&&a(bs),v(G,s),s&&a(js),s&&a(W),s&&a($s),v(z,s),s&&a(ys),s&&a(K),s&&a(ks),v(R,s),s&&a(xs),s&&a(E),s&&a(Ss),s&&a(P),s&&a(Es),s&&a($),v(D),s&&a(Ps),s&&a(V),s&&a(As),v(O,s),s&&a(Is),s&&a(I),s&&a(Ts),s&&a(y),v(Y),s&&a(Ns),s&&a(N),s&&a(qs),s&&a(k),v(U),s&&a(Ms),v(B,s)}}}const se={local:"selecsls",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"SelecSLS"};function ae(ja){return Va(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ne extends Xa{constructor(_){super();Ja(this,_,ae,Za,Wa,{})}}export{ne as default,se as metadata};
