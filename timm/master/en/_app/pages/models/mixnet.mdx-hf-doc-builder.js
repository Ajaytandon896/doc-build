import{S as es,i as ss,s as as,e as l,k as h,w as u,t as p,M as ls,c as n,d as e,m as c,a as o,x as g,h as m,b as i,G as s,g as r,y as d,L as ns,q as v,o as w,B as _,v as os}from"../../chunks/vendor-hf-doc-builder.js";import{I as dt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as at}from"../../chunks/CodeBlock-hf-doc-builder.js";function rs(Pe){let $,vt,j,E,lt,C,Kt,nt,Qt,wt,f,ot,Xt,Jt,H,Wt,Zt,L,te,ee,_t,b,P,rt,z,se,it,ae,$t,X,le,jt,G,bt,J,ne,xt,R,yt,W,oe,kt,Y,Et,Z,re,Pt,D,At,A,ie,pt,pe,me,St,S,he,tt,ce,fe,Nt,x,N,mt,U,ue,ht,ge,Tt,et,de,qt,B,It,T,ve,V,we,_e,Mt,y,q,ct,O,$e,ft,je,Ct,I,be,st,xe,ye,Ht,k,M,ut,F,ke,gt,Ee,Lt,K,zt;return C=new dt({}),z=new dt({}),G=new at({props:{code:`import timm
model = timm.create_model('mixnet_l', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;mixnet_l&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),R=new at({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),Y=new at({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),D=new at({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),U=new dt({}),B=new at({props:{code:"model = timm.create_model('mixnet_l', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;mixnet_l&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),O=new dt({}),F=new dt({}),K=new at({props:{code:`@misc{tan2019mixconv,
      title={MixConv: Mixed Depthwise Convolutional Kernels}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2019},
      eprint={1907.09595},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`<span class="language-xml">@misc</span><span class="hljs-template-variable">{tan2019mixconv,
      title={MixConv: Mixed Depthwise Convolutional Kernels}</span><span class="language-xml">, 
      author=</span><span class="hljs-template-variable">{Mingxing Tan and Quoc V. Le}</span><span class="language-xml">,
      year=</span><span class="hljs-template-variable">{2019}</span><span class="language-xml">,
      eprint=</span><span class="hljs-template-variable">{1907.09595}</span><span class="language-xml">,
      archivePrefix=</span><span class="hljs-template-variable">{arXiv}</span><span class="language-xml">,
      primaryClass=</span><span class="hljs-template-variable">{cs.CV}</span><span class="language-xml">
}</span>`}}),{c(){$=l("meta"),vt=h(),j=l("h1"),E=l("a"),lt=l("span"),u(C.$$.fragment),Kt=h(),nt=l("span"),Qt=p("MixNet"),wt=h(),f=l("p"),ot=l("strong"),Xt=p("MixNet"),Jt=p(" is a type of convolutional neural network discovered via AutoML that utilises "),H=l("a"),Wt=p("MixConvs"),Zt=p(" instead of regular "),L=l("a"),te=p("depthwise convolutions"),ee=p("."),_t=h(),b=l("h2"),P=l("a"),rt=l("span"),u(z.$$.fragment),se=h(),it=l("span"),ae=p("How do I use this model on an image?"),$t=h(),X=l("p"),le=p("To load a pretrained model:"),jt=h(),u(G.$$.fragment),bt=h(),J=l("p"),ne=p("To load and preprocess the image:"),xt=h(),u(R.$$.fragment),yt=h(),W=l("p"),oe=p("To get the model predictions:"),kt=h(),u(Y.$$.fragment),Et=h(),Z=l("p"),re=p("To get the top-5 predictions class names:"),Pt=h(),u(D.$$.fragment),At=h(),A=l("p"),ie=p("Replace the model name with the variant you want to use, e.g. "),pt=l("code"),pe=p("mixnet_l"),me=p(". You can find the IDs in the model summaries at the top of this page."),St=h(),S=l("p"),he=p("To extract image features with this model, follow the "),tt=l("a"),ce=p("timm feature extraction examples"),fe=p(", just change the name of the model you want to use."),Nt=h(),x=l("h2"),N=l("a"),mt=l("span"),u(U.$$.fragment),ue=h(),ht=l("span"),ge=p("How do I finetune this model?"),Tt=h(),et=l("p"),de=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),qt=h(),u(B.$$.fragment),It=h(),T=l("p"),ve=p("To finetune on your own dataset, you have to write a training loop or adapt "),V=l("a"),we=p(`timm\u2019s training
script`),_e=p(" to use your dataset."),Mt=h(),y=l("h2"),q=l("a"),ct=l("span"),u(O.$$.fragment),$e=h(),ft=l("span"),je=p("How do I train this model?"),Ct=h(),I=l("p"),be=p("You can follow the "),st=l("a"),xe=p("timm recipe scripts"),ye=p(" for training a new model afresh."),Ht=h(),k=l("h2"),M=l("a"),ut=l("span"),u(F.$$.fragment),ke=h(),gt=l("span"),Ee=p("Citation"),Lt=h(),u(K.$$.fragment),this.h()},l(t){const a=ls('[data-svelte="svelte-1phssyn"]',document.head);$=n(a,"META",{name:!0,content:!0}),a.forEach(e),vt=c(t),j=n(t,"H1",{class:!0});var Gt=o(j);E=n(Gt,"A",{id:!0,class:!0,href:!0});var Ae=o(E);lt=n(Ae,"SPAN",{});var Se=o(lt);g(C.$$.fragment,Se),Se.forEach(e),Ae.forEach(e),Kt=c(Gt),nt=n(Gt,"SPAN",{});var Ne=o(nt);Qt=m(Ne,"MixNet"),Ne.forEach(e),Gt.forEach(e),wt=c(t),f=n(t,"P",{});var Q=o(f);ot=n(Q,"STRONG",{});var Te=o(ot);Xt=m(Te,"MixNet"),Te.forEach(e),Jt=m(Q," is a type of convolutional neural network discovered via AutoML that utilises "),H=n(Q,"A",{href:!0,rel:!0});var qe=o(H);Wt=m(qe,"MixConvs"),qe.forEach(e),Zt=m(Q," instead of regular "),L=n(Q,"A",{href:!0,rel:!0});var Ie=o(L);te=m(Ie,"depthwise convolutions"),Ie.forEach(e),ee=m(Q,"."),Q.forEach(e),_t=c(t),b=n(t,"H2",{class:!0});var Rt=o(b);P=n(Rt,"A",{id:!0,class:!0,href:!0});var Me=o(P);rt=n(Me,"SPAN",{});var Ce=o(rt);g(z.$$.fragment,Ce),Ce.forEach(e),Me.forEach(e),se=c(Rt),it=n(Rt,"SPAN",{});var He=o(it);ae=m(He,"How do I use this model on an image?"),He.forEach(e),Rt.forEach(e),$t=c(t),X=n(t,"P",{});var Le=o(X);le=m(Le,"To load a pretrained model:"),Le.forEach(e),jt=c(t),g(G.$$.fragment,t),bt=c(t),J=n(t,"P",{});var ze=o(J);ne=m(ze,"To load and preprocess the image:"),ze.forEach(e),xt=c(t),g(R.$$.fragment,t),yt=c(t),W=n(t,"P",{});var Ge=o(W);oe=m(Ge,"To get the model predictions:"),Ge.forEach(e),kt=c(t),g(Y.$$.fragment,t),Et=c(t),Z=n(t,"P",{});var Re=o(Z);re=m(Re,"To get the top-5 predictions class names:"),Re.forEach(e),Pt=c(t),g(D.$$.fragment,t),At=c(t),A=n(t,"P",{});var Yt=o(A);ie=m(Yt,"Replace the model name with the variant you want to use, e.g. "),pt=n(Yt,"CODE",{});var Ye=o(pt);pe=m(Ye,"mixnet_l"),Ye.forEach(e),me=m(Yt,". You can find the IDs in the model summaries at the top of this page."),Yt.forEach(e),St=c(t),S=n(t,"P",{});var Dt=o(S);he=m(Dt,"To extract image features with this model, follow the "),tt=n(Dt,"A",{href:!0});var De=o(tt);ce=m(De,"timm feature extraction examples"),De.forEach(e),fe=m(Dt,", just change the name of the model you want to use."),Dt.forEach(e),Nt=c(t),x=n(t,"H2",{class:!0});var Ut=o(x);N=n(Ut,"A",{id:!0,class:!0,href:!0});var Ue=o(N);mt=n(Ue,"SPAN",{});var Be=o(mt);g(U.$$.fragment,Be),Be.forEach(e),Ue.forEach(e),ue=c(Ut),ht=n(Ut,"SPAN",{});var Ve=o(ht);ge=m(Ve,"How do I finetune this model?"),Ve.forEach(e),Ut.forEach(e),Tt=c(t),et=n(t,"P",{});var Oe=o(et);de=m(Oe,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Oe.forEach(e),qt=c(t),g(B.$$.fragment,t),It=c(t),T=n(t,"P",{});var Bt=o(T);ve=m(Bt,"To finetune on your own dataset, you have to write a training loop or adapt "),V=n(Bt,"A",{href:!0,rel:!0});var Fe=o(V);we=m(Fe,`timm\u2019s training
script`),Fe.forEach(e),_e=m(Bt," to use your dataset."),Bt.forEach(e),Mt=c(t),y=n(t,"H2",{class:!0});var Vt=o(y);q=n(Vt,"A",{id:!0,class:!0,href:!0});var Ke=o(q);ct=n(Ke,"SPAN",{});var Qe=o(ct);g(O.$$.fragment,Qe),Qe.forEach(e),Ke.forEach(e),$e=c(Vt),ft=n(Vt,"SPAN",{});var Xe=o(ft);je=m(Xe,"How do I train this model?"),Xe.forEach(e),Vt.forEach(e),Ct=c(t),I=n(t,"P",{});var Ot=o(I);be=m(Ot,"You can follow the "),st=n(Ot,"A",{href:!0});var Je=o(st);xe=m(Je,"timm recipe scripts"),Je.forEach(e),ye=m(Ot," for training a new model afresh."),Ot.forEach(e),Ht=c(t),k=n(t,"H2",{class:!0});var Ft=o(k);M=n(Ft,"A",{id:!0,class:!0,href:!0});var We=o(M);ut=n(We,"SPAN",{});var Ze=o(ut);g(F.$$.fragment,Ze),Ze.forEach(e),We.forEach(e),ke=c(Ft),gt=n(Ft,"SPAN",{});var ts=o(gt);Ee=m(ts,"Citation"),ts.forEach(e),Ft.forEach(e),Lt=c(t),g(K.$$.fragment,t),this.h()},h(){i($,"name","hf:doc:metadata"),i($,"content",JSON.stringify(is)),i(E,"id","mixnet"),i(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(E,"href","#mixnet"),i(j,"class","relative group"),i(H,"href","https://paperswithcode.com/method/mixconv"),i(H,"rel","nofollow"),i(L,"href","https://paperswithcode.com/method/depthwise-convolution"),i(L,"rel","nofollow"),i(P,"id","how-do-i-use-this-model-on-an-image"),i(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(P,"href","#how-do-i-use-this-model-on-an-image"),i(b,"class","relative group"),i(tt,"href","../feature_extraction"),i(N,"id","how-do-i-finetune-this-model"),i(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(N,"href","#how-do-i-finetune-this-model"),i(x,"class","relative group"),i(V,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(V,"rel","nofollow"),i(q,"id","how-do-i-train-this-model"),i(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(q,"href","#how-do-i-train-this-model"),i(y,"class","relative group"),i(st,"href","../scripts"),i(M,"id","citation"),i(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(M,"href","#citation"),i(k,"class","relative group")},m(t,a){s(document.head,$),r(t,vt,a),r(t,j,a),s(j,E),s(E,lt),d(C,lt,null),s(j,Kt),s(j,nt),s(nt,Qt),r(t,wt,a),r(t,f,a),s(f,ot),s(ot,Xt),s(f,Jt),s(f,H),s(H,Wt),s(f,Zt),s(f,L),s(L,te),s(f,ee),r(t,_t,a),r(t,b,a),s(b,P),s(P,rt),d(z,rt,null),s(b,se),s(b,it),s(it,ae),r(t,$t,a),r(t,X,a),s(X,le),r(t,jt,a),d(G,t,a),r(t,bt,a),r(t,J,a),s(J,ne),r(t,xt,a),d(R,t,a),r(t,yt,a),r(t,W,a),s(W,oe),r(t,kt,a),d(Y,t,a),r(t,Et,a),r(t,Z,a),s(Z,re),r(t,Pt,a),d(D,t,a),r(t,At,a),r(t,A,a),s(A,ie),s(A,pt),s(pt,pe),s(A,me),r(t,St,a),r(t,S,a),s(S,he),s(S,tt),s(tt,ce),s(S,fe),r(t,Nt,a),r(t,x,a),s(x,N),s(N,mt),d(U,mt,null),s(x,ue),s(x,ht),s(ht,ge),r(t,Tt,a),r(t,et,a),s(et,de),r(t,qt,a),d(B,t,a),r(t,It,a),r(t,T,a),s(T,ve),s(T,V),s(V,we),s(T,_e),r(t,Mt,a),r(t,y,a),s(y,q),s(q,ct),d(O,ct,null),s(y,$e),s(y,ft),s(ft,je),r(t,Ct,a),r(t,I,a),s(I,be),s(I,st),s(st,xe),s(I,ye),r(t,Ht,a),r(t,k,a),s(k,M),s(M,ut),d(F,ut,null),s(k,ke),s(k,gt),s(gt,Ee),r(t,Lt,a),d(K,t,a),zt=!0},p:ns,i(t){zt||(v(C.$$.fragment,t),v(z.$$.fragment,t),v(G.$$.fragment,t),v(R.$$.fragment,t),v(Y.$$.fragment,t),v(D.$$.fragment,t),v(U.$$.fragment,t),v(B.$$.fragment,t),v(O.$$.fragment,t),v(F.$$.fragment,t),v(K.$$.fragment,t),zt=!0)},o(t){w(C.$$.fragment,t),w(z.$$.fragment,t),w(G.$$.fragment,t),w(R.$$.fragment,t),w(Y.$$.fragment,t),w(D.$$.fragment,t),w(U.$$.fragment,t),w(B.$$.fragment,t),w(O.$$.fragment,t),w(F.$$.fragment,t),w(K.$$.fragment,t),zt=!1},d(t){e($),t&&e(vt),t&&e(j),_(C),t&&e(wt),t&&e(f),t&&e(_t),t&&e(b),_(z),t&&e($t),t&&e(X),t&&e(jt),_(G,t),t&&e(bt),t&&e(J),t&&e(xt),_(R,t),t&&e(yt),t&&e(W),t&&e(kt),_(Y,t),t&&e(Et),t&&e(Z),t&&e(Pt),_(D,t),t&&e(At),t&&e(A),t&&e(St),t&&e(S),t&&e(Nt),t&&e(x),_(U),t&&e(Tt),t&&e(et),t&&e(qt),_(B,t),t&&e(It),t&&e(T),t&&e(Mt),t&&e(y),_(O),t&&e(Ct),t&&e(I),t&&e(Ht),t&&e(k),_(F),t&&e(Lt),_(K,t)}}}const is={local:"mixnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"MixNet"};function ps(Pe){return os(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fs extends es{constructor($){super();ss(this,$,ps,rs,as,{})}}export{fs as default,is as metadata};
