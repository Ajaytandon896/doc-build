import{S as de,i as ue,s as we,e as n,k as m,w as g,t as o,T as _e,M as ve,c as l,d as a,m as h,a as r,x as f,h as p,U as $e,b as c,G as e,g as i,y as d,L as je,q as u,o as w,B as _,v as ye}from"../../chunks/vendor-hf-doc-builder.js";import{I as vs}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ns}from"../../chunks/CodeBlock-hf-doc-builder.js";function be(za){let $,$s,j,E,ls,Y,ea,rs,ta,js,P,is,na,la,ys,fe='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>u</mi><mi mathvariant="normal">_</mi><mi>j</mi><mo>=</mo><mi>w</mi><mi mathvariant="normal">_</mi><mn>0</mn><mo>+</mo><mi>w</mi><mi mathvariant="normal">_</mi><mi>a</mi><mo>\u22C5</mo><mi>j</mi></mrow><annotation encoding="application/x-tex"> u\\_{j} = w\\_{0} + w\\_{a}\\cdot{j} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695em;vertical-align:-0.31em;"></span><span class="mord mathnormal">u</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9544em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">0</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7545em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathnormal">a</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">\u22C5</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span></span></span>',bs,N,ra,os,ia,oa,ks,v,pa,ps,ma,ha,G,ca,ga,xs,y,S,ms,z,fa,hs,da,Es,J,ua,Ps,D,Ns,Q,wa,Ss,L,qs,W,_a,Rs,M,Ts,Z,va,Is,F,As,q,$a,cs,ja,ya,Hs,R,ba,ss,ka,xa,Cs,b,T,gs,U,Ea,fs,Pa,Ys,as,Na,Gs,O,zs,I,Sa,B,qa,Ra,Ds,k,A,ds,K,Ta,us,Ia,Ls,H,Aa,es,Ha,Ca,Ms,x,C,ws,X,Ya,_s,Ga,Fs,V,Us;return Y=new vs({}),z=new vs({}),D=new ns({props:{code:`import timm
model = timm.create_model('regnety_002', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;regnety_002&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),L=new ns({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),M=new ns({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),F=new ns({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),U=new vs({}),O=new ns({props:{code:"model = timm.create_model('regnety_002', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;regnety_002&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),K=new vs({}),X=new vs({}),V=new ns({props:{code:`@misc{radosavovic2020designing,
      title={Designing Network Design Spaces}, 
      author={Ilija Radosavovic and Raj Prateek Kosaraju and Ross Girshick and Kaiming He and Piotr Doll\xE1r},
      year={2020},
      eprint={2003.13678},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`<span class="language-xml">@misc</span><span class="hljs-template-variable">{radosavovic2020designing,
      title={Designing Network Design Spaces}</span><span class="language-xml">, 
      author=</span><span class="hljs-template-variable">{Ilija Radosavovic and Raj Prateek Kosaraju and Ross Girshick and Kaiming He and Piotr Doll\xE1r}</span><span class="language-xml">,
      year=</span><span class="hljs-template-variable">{2020}</span><span class="language-xml">,
      eprint=</span><span class="hljs-template-variable">{2003.13678}</span><span class="language-xml">,
      archivePrefix=</span><span class="hljs-template-variable">{arXiv}</span><span class="language-xml">,
      primaryClass=</span><span class="hljs-template-variable">{cs.CV}</span><span class="language-xml">
}</span>`}}),{c(){$=n("meta"),$s=m(),j=n("h1"),E=n("a"),ls=n("span"),g(Y.$$.fragment),ea=m(),rs=n("span"),ta=o("RegNetY"),js=m(),P=n("p"),is=n("strong"),na=o("RegNetY"),la=o(` is a convolutional network design space with simple, regular models with parameters: depth $d$, initial width $w_{0} > 0$, and slope $w_{a} > 0$, and generates a different block width $u_{j}$ for each block $j < d$. The key restriction for the RegNet types of model is that there is a linear parameterisation of block widths (the design space only contains models with this linear structure):
`),ys=new _e,bs=m(),N=n("p"),ra=o("For "),os=n("strong"),ia=o("RegNetX"),oa=o(" authors have additional restrictions: we set $b = 1$ (the bottleneck ratio), $12 \\leq d \\leq 28$, and $w_{m} \\geq 2$ (the width multiplier)."),ks=m(),v=n("p"),pa=o("For "),ps=n("strong"),ma=o("RegNetY"),ha=o(" authors make one change, which is to include "),G=n("a"),ca=o("Squeeze-and-Excitation blocks"),ga=o("."),xs=m(),y=n("h2"),S=n("a"),ms=n("span"),g(z.$$.fragment),fa=m(),hs=n("span"),da=o("How do I use this model on an image?"),Es=m(),J=n("p"),ua=o("To load a pretrained model:"),Ps=m(),g(D.$$.fragment),Ns=m(),Q=n("p"),wa=o("To load and preprocess the image:"),Ss=m(),g(L.$$.fragment),qs=m(),W=n("p"),_a=o("To get the model predictions:"),Rs=m(),g(M.$$.fragment),Ts=m(),Z=n("p"),va=o("To get the top-5 predictions class names:"),Is=m(),g(F.$$.fragment),As=m(),q=n("p"),$a=o("Replace the model name with the variant you want to use, e.g. "),cs=n("code"),ja=o("regnety_002"),ya=o(". You can find the IDs in the model summaries at the top of this page."),Hs=m(),R=n("p"),ba=o("To extract image features with this model, follow the "),ss=n("a"),ka=o("timm feature extraction examples"),xa=o(", just change the name of the model you want to use."),Cs=m(),b=n("h2"),T=n("a"),gs=n("span"),g(U.$$.fragment),Ea=m(),fs=n("span"),Pa=o("How do I finetune this model?"),Ys=m(),as=n("p"),Na=o("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Gs=m(),g(O.$$.fragment),zs=m(),I=n("p"),Sa=o("To finetune on your own dataset, you have to write a training loop or adapt "),B=n("a"),qa=o(`timm\u2019s training
script`),Ra=o(" to use your dataset."),Ds=m(),k=n("h2"),A=n("a"),ds=n("span"),g(K.$$.fragment),Ta=m(),us=n("span"),Ia=o("How do I train this model?"),Ls=m(),H=n("p"),Aa=o("You can follow the "),es=n("a"),Ha=o("timm recipe scripts"),Ca=o(" for training a new model afresh."),Ms=m(),x=n("h2"),C=n("a"),ws=n("span"),g(X.$$.fragment),Ya=m(),_s=n("span"),Ga=o("Citation"),Fs=m(),g(V.$$.fragment),this.h()},l(s){const t=ve('[data-svelte="svelte-1phssyn"]',document.head);$=l(t,"META",{name:!0,content:!0}),t.forEach(a),$s=h(s),j=l(s,"H1",{class:!0});var Os=r(j);E=l(Os,"A",{id:!0,class:!0,href:!0});var Da=r(E);ls=l(Da,"SPAN",{});var La=r(ls);f(Y.$$.fragment,La),La.forEach(a),Da.forEach(a),ea=h(Os),rs=l(Os,"SPAN",{});var Ma=r(rs);ta=p(Ma,"RegNetY"),Ma.forEach(a),Os.forEach(a),js=h(s),P=l(s,"P",{});var Bs=r(P);is=l(Bs,"STRONG",{});var Fa=r(is);na=p(Fa,"RegNetY"),Fa.forEach(a),la=p(Bs,` is a convolutional network design space with simple, regular models with parameters: depth $d$, initial width $w_{0} > 0$, and slope $w_{a} > 0$, and generates a different block width $u_{j}$ for each block $j < d$. The key restriction for the RegNet types of model is that there is a linear parameterisation of block widths (the design space only contains models with this linear structure):
`),ys=$e(Bs),Bs.forEach(a),bs=h(s),N=l(s,"P",{});var Ks=r(N);ra=p(Ks,"For "),os=l(Ks,"STRONG",{});var Ua=r(os);ia=p(Ua,"RegNetX"),Ua.forEach(a),oa=p(Ks," authors have additional restrictions: we set $b = 1$ (the bottleneck ratio), $12 \\leq d \\leq 28$, and $w_{m} \\geq 2$ (the width multiplier)."),Ks.forEach(a),ks=h(s),v=l(s,"P",{});var ts=r(v);pa=p(ts,"For "),ps=l(ts,"STRONG",{});var Oa=r(ps);ma=p(Oa,"RegNetY"),Oa.forEach(a),ha=p(ts," authors make one change, which is to include "),G=l(ts,"A",{href:!0,rel:!0});var Ba=r(G);ca=p(Ba,"Squeeze-and-Excitation blocks"),Ba.forEach(a),ga=p(ts,"."),ts.forEach(a),xs=h(s),y=l(s,"H2",{class:!0});var Xs=r(y);S=l(Xs,"A",{id:!0,class:!0,href:!0});var Ka=r(S);ms=l(Ka,"SPAN",{});var Xa=r(ms);f(z.$$.fragment,Xa),Xa.forEach(a),Ka.forEach(a),fa=h(Xs),hs=l(Xs,"SPAN",{});var Va=r(hs);da=p(Va,"How do I use this model on an image?"),Va.forEach(a),Xs.forEach(a),Es=h(s),J=l(s,"P",{});var Ja=r(J);ua=p(Ja,"To load a pretrained model:"),Ja.forEach(a),Ps=h(s),f(D.$$.fragment,s),Ns=h(s),Q=l(s,"P",{});var Qa=r(Q);wa=p(Qa,"To load and preprocess the image:"),Qa.forEach(a),Ss=h(s),f(L.$$.fragment,s),qs=h(s),W=l(s,"P",{});var Wa=r(W);_a=p(Wa,"To get the model predictions:"),Wa.forEach(a),Rs=h(s),f(M.$$.fragment,s),Ts=h(s),Z=l(s,"P",{});var Za=r(Z);va=p(Za,"To get the top-5 predictions class names:"),Za.forEach(a),Is=h(s),f(F.$$.fragment,s),As=h(s),q=l(s,"P",{});var Vs=r(q);$a=p(Vs,"Replace the model name with the variant you want to use, e.g. "),cs=l(Vs,"CODE",{});var se=r(cs);ja=p(se,"regnety_002"),se.forEach(a),ya=p(Vs,". You can find the IDs in the model summaries at the top of this page."),Vs.forEach(a),Hs=h(s),R=l(s,"P",{});var Js=r(R);ba=p(Js,"To extract image features with this model, follow the "),ss=l(Js,"A",{href:!0});var ae=r(ss);ka=p(ae,"timm feature extraction examples"),ae.forEach(a),xa=p(Js,", just change the name of the model you want to use."),Js.forEach(a),Cs=h(s),b=l(s,"H2",{class:!0});var Qs=r(b);T=l(Qs,"A",{id:!0,class:!0,href:!0});var ee=r(T);gs=l(ee,"SPAN",{});var te=r(gs);f(U.$$.fragment,te),te.forEach(a),ee.forEach(a),Ea=h(Qs),fs=l(Qs,"SPAN",{});var ne=r(fs);Pa=p(ne,"How do I finetune this model?"),ne.forEach(a),Qs.forEach(a),Ys=h(s),as=l(s,"P",{});var le=r(as);Na=p(le,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),le.forEach(a),Gs=h(s),f(O.$$.fragment,s),zs=h(s),I=l(s,"P",{});var Ws=r(I);Sa=p(Ws,"To finetune on your own dataset, you have to write a training loop or adapt "),B=l(Ws,"A",{href:!0,rel:!0});var re=r(B);qa=p(re,`timm\u2019s training
script`),re.forEach(a),Ra=p(Ws," to use your dataset."),Ws.forEach(a),Ds=h(s),k=l(s,"H2",{class:!0});var Zs=r(k);A=l(Zs,"A",{id:!0,class:!0,href:!0});var ie=r(A);ds=l(ie,"SPAN",{});var oe=r(ds);f(K.$$.fragment,oe),oe.forEach(a),ie.forEach(a),Ta=h(Zs),us=l(Zs,"SPAN",{});var pe=r(us);Ia=p(pe,"How do I train this model?"),pe.forEach(a),Zs.forEach(a),Ls=h(s),H=l(s,"P",{});var sa=r(H);Aa=p(sa,"You can follow the "),es=l(sa,"A",{href:!0});var me=r(es);Ha=p(me,"timm recipe scripts"),me.forEach(a),Ca=p(sa," for training a new model afresh."),sa.forEach(a),Ms=h(s),x=l(s,"H2",{class:!0});var aa=r(x);C=l(aa,"A",{id:!0,class:!0,href:!0});var he=r(C);ws=l(he,"SPAN",{});var ce=r(ws);f(X.$$.fragment,ce),ce.forEach(a),he.forEach(a),Ya=h(aa),_s=l(aa,"SPAN",{});var ge=r(_s);Ga=p(ge,"Citation"),ge.forEach(a),aa.forEach(a),Fs=h(s),f(V.$$.fragment,s),this.h()},h(){c($,"name","hf:doc:metadata"),c($,"content",JSON.stringify(ke)),c(E,"id","regnety"),c(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E,"href","#regnety"),c(j,"class","relative group"),ys.a=null,c(G,"href","https://paperswithcode.com/method/squeeze-and-excitation-block"),c(G,"rel","nofollow"),c(S,"id","how-do-i-use-this-model-on-an-image"),c(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S,"href","#how-do-i-use-this-model-on-an-image"),c(y,"class","relative group"),c(ss,"href","../feature_extraction"),c(T,"id","how-do-i-finetune-this-model"),c(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T,"href","#how-do-i-finetune-this-model"),c(b,"class","relative group"),c(B,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),c(B,"rel","nofollow"),c(A,"id","how-do-i-train-this-model"),c(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A,"href","#how-do-i-train-this-model"),c(k,"class","relative group"),c(es,"href","../scripts"),c(C,"id","citation"),c(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C,"href","#citation"),c(x,"class","relative group")},m(s,t){e(document.head,$),i(s,$s,t),i(s,j,t),e(j,E),e(E,ls),d(Y,ls,null),e(j,ea),e(j,rs),e(rs,ta),i(s,js,t),i(s,P,t),e(P,is),e(is,na),e(P,la),ys.m(fe,P),i(s,bs,t),i(s,N,t),e(N,ra),e(N,os),e(os,ia),e(N,oa),i(s,ks,t),i(s,v,t),e(v,pa),e(v,ps),e(ps,ma),e(v,ha),e(v,G),e(G,ca),e(v,ga),i(s,xs,t),i(s,y,t),e(y,S),e(S,ms),d(z,ms,null),e(y,fa),e(y,hs),e(hs,da),i(s,Es,t),i(s,J,t),e(J,ua),i(s,Ps,t),d(D,s,t),i(s,Ns,t),i(s,Q,t),e(Q,wa),i(s,Ss,t),d(L,s,t),i(s,qs,t),i(s,W,t),e(W,_a),i(s,Rs,t),d(M,s,t),i(s,Ts,t),i(s,Z,t),e(Z,va),i(s,Is,t),d(F,s,t),i(s,As,t),i(s,q,t),e(q,$a),e(q,cs),e(cs,ja),e(q,ya),i(s,Hs,t),i(s,R,t),e(R,ba),e(R,ss),e(ss,ka),e(R,xa),i(s,Cs,t),i(s,b,t),e(b,T),e(T,gs),d(U,gs,null),e(b,Ea),e(b,fs),e(fs,Pa),i(s,Ys,t),i(s,as,t),e(as,Na),i(s,Gs,t),d(O,s,t),i(s,zs,t),i(s,I,t),e(I,Sa),e(I,B),e(B,qa),e(I,Ra),i(s,Ds,t),i(s,k,t),e(k,A),e(A,ds),d(K,ds,null),e(k,Ta),e(k,us),e(us,Ia),i(s,Ls,t),i(s,H,t),e(H,Aa),e(H,es),e(es,Ha),e(H,Ca),i(s,Ms,t),i(s,x,t),e(x,C),e(C,ws),d(X,ws,null),e(x,Ya),e(x,_s),e(_s,Ga),i(s,Fs,t),d(V,s,t),Us=!0},p:je,i(s){Us||(u(Y.$$.fragment,s),u(z.$$.fragment,s),u(D.$$.fragment,s),u(L.$$.fragment,s),u(M.$$.fragment,s),u(F.$$.fragment,s),u(U.$$.fragment,s),u(O.$$.fragment,s),u(K.$$.fragment,s),u(X.$$.fragment,s),u(V.$$.fragment,s),Us=!0)},o(s){w(Y.$$.fragment,s),w(z.$$.fragment,s),w(D.$$.fragment,s),w(L.$$.fragment,s),w(M.$$.fragment,s),w(F.$$.fragment,s),w(U.$$.fragment,s),w(O.$$.fragment,s),w(K.$$.fragment,s),w(X.$$.fragment,s),w(V.$$.fragment,s),Us=!1},d(s){a($),s&&a($s),s&&a(j),_(Y),s&&a(js),s&&a(P),s&&a(bs),s&&a(N),s&&a(ks),s&&a(v),s&&a(xs),s&&a(y),_(z),s&&a(Es),s&&a(J),s&&a(Ps),_(D,s),s&&a(Ns),s&&a(Q),s&&a(Ss),_(L,s),s&&a(qs),s&&a(W),s&&a(Rs),_(M,s),s&&a(Ts),s&&a(Z),s&&a(Is),_(F,s),s&&a(As),s&&a(q),s&&a(Hs),s&&a(R),s&&a(Cs),s&&a(b),_(U),s&&a(Ys),s&&a(as),s&&a(Gs),_(O,s),s&&a(zs),s&&a(I),s&&a(Ds),s&&a(k),_(K),s&&a(Ls),s&&a(H),s&&a(Ms),s&&a(x),_(X),s&&a(Fs),_(V,s)}}}const ke={local:"regnety",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"RegNetY"};function xe(za){return ye(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Se extends de{constructor($){super();ue(this,$,xe,be,we,{})}}export{Se as default,ke as metadata};
