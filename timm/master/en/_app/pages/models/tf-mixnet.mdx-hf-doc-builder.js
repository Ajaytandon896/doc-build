import{S as ps,i as ms,s as hs,e as l,k as h,w as u,t as p,M as fs,c as o,d as e,m as f,a as n,x as g,h as m,b as i,G as s,g as r,y as d,L as cs,q as w,o as v,B as _,v as us}from"../../chunks/vendor-hf-doc-builder.js";import{I as vt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ot}from"../../chunks/CodeBlock-hf-doc-builder.js";function gs(Ce){let $,_t,j,E,nt,H,Wt,rt,Zt,$t,c,it,te,ee,L,se,ae,U,le,oe,jt,P,ne,z,re,ie,bt,b,T,pt,G,pe,mt,me,xt,W,he,yt,R,kt,Z,fe,Et,Y,Pt,tt,ce,Tt,D,At,et,ue,St,B,Nt,A,ge,ht,de,we,qt,S,ve,st,_e,$e,It,x,N,ft,V,je,ct,be,Ct,at,xe,Mt,O,Ht,q,ye,F,ke,Ee,Lt,y,I,ut,K,Pe,gt,Te,Ut,C,Ae,lt,Se,Ne,zt,k,M,dt,Q,qe,wt,Ie,Gt,X,Rt;return H=new vt({}),G=new vt({}),R=new ot({props:{code:`import timm
model = timm.create_model('tf_mixnet_l', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;tf_mixnet_l&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),Y=new ot({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),D=new ot({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),B=new ot({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),V=new vt({}),O=new ot({props:{code:"model = timm.create_model('tf_mixnet_l', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;tf_mixnet_l&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),K=new vt({}),Q=new vt({}),X=new ot({props:{code:`@misc{tan2019mixconv,
      title={MixConv: Mixed Depthwise Convolutional Kernels}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2019},
      eprint={1907.09595},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`<span class="language-xml">@misc</span><span class="hljs-template-variable">{tan2019mixconv,
      title={MixConv: Mixed Depthwise Convolutional Kernels}</span><span class="language-xml">, 
      author=</span><span class="hljs-template-variable">{Mingxing Tan and Quoc V. Le}</span><span class="language-xml">,
      year=</span><span class="hljs-template-variable">{2019}</span><span class="language-xml">,
      eprint=</span><span class="hljs-template-variable">{1907.09595}</span><span class="language-xml">,
      archivePrefix=</span><span class="hljs-template-variable">{arXiv}</span><span class="language-xml">,
      primaryClass=</span><span class="hljs-template-variable">{cs.CV}</span><span class="language-xml">
}</span>`}}),{c(){$=l("meta"),_t=h(),j=l("h1"),E=l("a"),nt=l("span"),u(H.$$.fragment),Wt=h(),rt=l("span"),Zt=p("(Tensorflow) MixNet"),$t=h(),c=l("p"),it=l("strong"),te=p("MixNet"),ee=p(" is a type of convolutional neural network discovered via AutoML that utilises "),L=l("a"),se=p("MixConvs"),ae=p(" instead of regular "),U=l("a"),le=p("depthwise convolutions"),oe=p("."),jt=h(),P=l("p"),ne=p("The weights from this model were ported from "),z=l("a"),re=p("Tensorflow/TPU"),ie=p("."),bt=h(),b=l("h2"),T=l("a"),pt=l("span"),u(G.$$.fragment),pe=h(),mt=l("span"),me=p("How do I use this model on an image?"),xt=h(),W=l("p"),he=p("To load a pretrained model:"),yt=h(),u(R.$$.fragment),kt=h(),Z=l("p"),fe=p("To load and preprocess the image:"),Et=h(),u(Y.$$.fragment),Pt=h(),tt=l("p"),ce=p("To get the model predictions:"),Tt=h(),u(D.$$.fragment),At=h(),et=l("p"),ue=p("To get the top-5 predictions class names:"),St=h(),u(B.$$.fragment),Nt=h(),A=l("p"),ge=p("Replace the model name with the variant you want to use, e.g. "),ht=l("code"),de=p("tf_mixnet_l"),we=p(". You can find the IDs in the model summaries at the top of this page."),qt=h(),S=l("p"),ve=p("To extract image features with this model, follow the "),st=l("a"),_e=p("timm feature extraction examples"),$e=p(", just change the name of the model you want to use."),It=h(),x=l("h2"),N=l("a"),ft=l("span"),u(V.$$.fragment),je=h(),ct=l("span"),be=p("How do I finetune this model?"),Ct=h(),at=l("p"),xe=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Mt=h(),u(O.$$.fragment),Ht=h(),q=l("p"),ye=p("To finetune on your own dataset, you have to write a training loop or adapt "),F=l("a"),ke=p(`timm\u2019s training
script`),Ee=p(" to use your dataset."),Lt=h(),y=l("h2"),I=l("a"),ut=l("span"),u(K.$$.fragment),Pe=h(),gt=l("span"),Te=p("How do I train this model?"),Ut=h(),C=l("p"),Ae=p("You can follow the "),lt=l("a"),Se=p("timm recipe scripts"),Ne=p(" for training a new model afresh."),zt=h(),k=l("h2"),M=l("a"),dt=l("span"),u(Q.$$.fragment),qe=h(),wt=l("span"),Ie=p("Citation"),Gt=h(),u(X.$$.fragment),this.h()},l(t){const a=fs('[data-svelte="svelte-1phssyn"]',document.head);$=o(a,"META",{name:!0,content:!0}),a.forEach(e),_t=f(t),j=o(t,"H1",{class:!0});var Yt=n(j);E=o(Yt,"A",{id:!0,class:!0,href:!0});var Me=n(E);nt=o(Me,"SPAN",{});var He=n(nt);g(H.$$.fragment,He),He.forEach(e),Me.forEach(e),Wt=f(Yt),rt=o(Yt,"SPAN",{});var Le=n(rt);Zt=m(Le,"(Tensorflow) MixNet"),Le.forEach(e),Yt.forEach(e),$t=f(t),c=o(t,"P",{});var J=n(c);it=o(J,"STRONG",{});var Ue=n(it);te=m(Ue,"MixNet"),Ue.forEach(e),ee=m(J," is a type of convolutional neural network discovered via AutoML that utilises "),L=o(J,"A",{href:!0,rel:!0});var ze=n(L);se=m(ze,"MixConvs"),ze.forEach(e),ae=m(J," instead of regular "),U=o(J,"A",{href:!0,rel:!0});var Ge=n(U);le=m(Ge,"depthwise convolutions"),Ge.forEach(e),oe=m(J,"."),J.forEach(e),jt=f(t),P=o(t,"P",{});var Dt=n(P);ne=m(Dt,"The weights from this model were ported from "),z=o(Dt,"A",{href:!0,rel:!0});var Re=n(z);re=m(Re,"Tensorflow/TPU"),Re.forEach(e),ie=m(Dt,"."),Dt.forEach(e),bt=f(t),b=o(t,"H2",{class:!0});var Bt=n(b);T=o(Bt,"A",{id:!0,class:!0,href:!0});var Ye=n(T);pt=o(Ye,"SPAN",{});var De=n(pt);g(G.$$.fragment,De),De.forEach(e),Ye.forEach(e),pe=f(Bt),mt=o(Bt,"SPAN",{});var Be=n(mt);me=m(Be,"How do I use this model on an image?"),Be.forEach(e),Bt.forEach(e),xt=f(t),W=o(t,"P",{});var Ve=n(W);he=m(Ve,"To load a pretrained model:"),Ve.forEach(e),yt=f(t),g(R.$$.fragment,t),kt=f(t),Z=o(t,"P",{});var Oe=n(Z);fe=m(Oe,"To load and preprocess the image:"),Oe.forEach(e),Et=f(t),g(Y.$$.fragment,t),Pt=f(t),tt=o(t,"P",{});var Fe=n(tt);ce=m(Fe,"To get the model predictions:"),Fe.forEach(e),Tt=f(t),g(D.$$.fragment,t),At=f(t),et=o(t,"P",{});var Ke=n(et);ue=m(Ke,"To get the top-5 predictions class names:"),Ke.forEach(e),St=f(t),g(B.$$.fragment,t),Nt=f(t),A=o(t,"P",{});var Vt=n(A);ge=m(Vt,"Replace the model name with the variant you want to use, e.g. "),ht=o(Vt,"CODE",{});var Qe=n(ht);de=m(Qe,"tf_mixnet_l"),Qe.forEach(e),we=m(Vt,". You can find the IDs in the model summaries at the top of this page."),Vt.forEach(e),qt=f(t),S=o(t,"P",{});var Ot=n(S);ve=m(Ot,"To extract image features with this model, follow the "),st=o(Ot,"A",{href:!0});var Xe=n(st);_e=m(Xe,"timm feature extraction examples"),Xe.forEach(e),$e=m(Ot,", just change the name of the model you want to use."),Ot.forEach(e),It=f(t),x=o(t,"H2",{class:!0});var Ft=n(x);N=o(Ft,"A",{id:!0,class:!0,href:!0});var Je=n(N);ft=o(Je,"SPAN",{});var We=n(ft);g(V.$$.fragment,We),We.forEach(e),Je.forEach(e),je=f(Ft),ct=o(Ft,"SPAN",{});var Ze=n(ct);be=m(Ze,"How do I finetune this model?"),Ze.forEach(e),Ft.forEach(e),Ct=f(t),at=o(t,"P",{});var ts=n(at);xe=m(ts,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),ts.forEach(e),Mt=f(t),g(O.$$.fragment,t),Ht=f(t),q=o(t,"P",{});var Kt=n(q);ye=m(Kt,"To finetune on your own dataset, you have to write a training loop or adapt "),F=o(Kt,"A",{href:!0,rel:!0});var es=n(F);ke=m(es,`timm\u2019s training
script`),es.forEach(e),Ee=m(Kt," to use your dataset."),Kt.forEach(e),Lt=f(t),y=o(t,"H2",{class:!0});var Qt=n(y);I=o(Qt,"A",{id:!0,class:!0,href:!0});var ss=n(I);ut=o(ss,"SPAN",{});var as=n(ut);g(K.$$.fragment,as),as.forEach(e),ss.forEach(e),Pe=f(Qt),gt=o(Qt,"SPAN",{});var ls=n(gt);Te=m(ls,"How do I train this model?"),ls.forEach(e),Qt.forEach(e),Ut=f(t),C=o(t,"P",{});var Xt=n(C);Ae=m(Xt,"You can follow the "),lt=o(Xt,"A",{href:!0});var os=n(lt);Se=m(os,"timm recipe scripts"),os.forEach(e),Ne=m(Xt," for training a new model afresh."),Xt.forEach(e),zt=f(t),k=o(t,"H2",{class:!0});var Jt=n(k);M=o(Jt,"A",{id:!0,class:!0,href:!0});var ns=n(M);dt=o(ns,"SPAN",{});var rs=n(dt);g(Q.$$.fragment,rs),rs.forEach(e),ns.forEach(e),qe=f(Jt),wt=o(Jt,"SPAN",{});var is=n(wt);Ie=m(is,"Citation"),is.forEach(e),Jt.forEach(e),Gt=f(t),g(X.$$.fragment,t),this.h()},h(){i($,"name","hf:doc:metadata"),i($,"content",JSON.stringify(ds)),i(E,"id","tensorflow-mixnet"),i(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(E,"href","#tensorflow-mixnet"),i(j,"class","relative group"),i(L,"href","https://paperswithcode.com/method/mixconv"),i(L,"rel","nofollow"),i(U,"href","https://paperswithcode.com/method/depthwise-convolution"),i(U,"rel","nofollow"),i(z,"href","https://github.com/tensorflow/tpu"),i(z,"rel","nofollow"),i(T,"id","how-do-i-use-this-model-on-an-image"),i(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(T,"href","#how-do-i-use-this-model-on-an-image"),i(b,"class","relative group"),i(st,"href","../feature_extraction"),i(N,"id","how-do-i-finetune-this-model"),i(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(N,"href","#how-do-i-finetune-this-model"),i(x,"class","relative group"),i(F,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(F,"rel","nofollow"),i(I,"id","how-do-i-train-this-model"),i(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(I,"href","#how-do-i-train-this-model"),i(y,"class","relative group"),i(lt,"href","../scripts"),i(M,"id","citation"),i(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(M,"href","#citation"),i(k,"class","relative group")},m(t,a){s(document.head,$),r(t,_t,a),r(t,j,a),s(j,E),s(E,nt),d(H,nt,null),s(j,Wt),s(j,rt),s(rt,Zt),r(t,$t,a),r(t,c,a),s(c,it),s(it,te),s(c,ee),s(c,L),s(L,se),s(c,ae),s(c,U),s(U,le),s(c,oe),r(t,jt,a),r(t,P,a),s(P,ne),s(P,z),s(z,re),s(P,ie),r(t,bt,a),r(t,b,a),s(b,T),s(T,pt),d(G,pt,null),s(b,pe),s(b,mt),s(mt,me),r(t,xt,a),r(t,W,a),s(W,he),r(t,yt,a),d(R,t,a),r(t,kt,a),r(t,Z,a),s(Z,fe),r(t,Et,a),d(Y,t,a),r(t,Pt,a),r(t,tt,a),s(tt,ce),r(t,Tt,a),d(D,t,a),r(t,At,a),r(t,et,a),s(et,ue),r(t,St,a),d(B,t,a),r(t,Nt,a),r(t,A,a),s(A,ge),s(A,ht),s(ht,de),s(A,we),r(t,qt,a),r(t,S,a),s(S,ve),s(S,st),s(st,_e),s(S,$e),r(t,It,a),r(t,x,a),s(x,N),s(N,ft),d(V,ft,null),s(x,je),s(x,ct),s(ct,be),r(t,Ct,a),r(t,at,a),s(at,xe),r(t,Mt,a),d(O,t,a),r(t,Ht,a),r(t,q,a),s(q,ye),s(q,F),s(F,ke),s(q,Ee),r(t,Lt,a),r(t,y,a),s(y,I),s(I,ut),d(K,ut,null),s(y,Pe),s(y,gt),s(gt,Te),r(t,Ut,a),r(t,C,a),s(C,Ae),s(C,lt),s(lt,Se),s(C,Ne),r(t,zt,a),r(t,k,a),s(k,M),s(M,dt),d(Q,dt,null),s(k,qe),s(k,wt),s(wt,Ie),r(t,Gt,a),d(X,t,a),Rt=!0},p:cs,i(t){Rt||(w(H.$$.fragment,t),w(G.$$.fragment,t),w(R.$$.fragment,t),w(Y.$$.fragment,t),w(D.$$.fragment,t),w(B.$$.fragment,t),w(V.$$.fragment,t),w(O.$$.fragment,t),w(K.$$.fragment,t),w(Q.$$.fragment,t),w(X.$$.fragment,t),Rt=!0)},o(t){v(H.$$.fragment,t),v(G.$$.fragment,t),v(R.$$.fragment,t),v(Y.$$.fragment,t),v(D.$$.fragment,t),v(B.$$.fragment,t),v(V.$$.fragment,t),v(O.$$.fragment,t),v(K.$$.fragment,t),v(Q.$$.fragment,t),v(X.$$.fragment,t),Rt=!1},d(t){e($),t&&e(_t),t&&e(j),_(H),t&&e($t),t&&e(c),t&&e(jt),t&&e(P),t&&e(bt),t&&e(b),_(G),t&&e(xt),t&&e(W),t&&e(yt),_(R,t),t&&e(kt),t&&e(Z),t&&e(Et),_(Y,t),t&&e(Pt),t&&e(tt),t&&e(Tt),_(D,t),t&&e(At),t&&e(et),t&&e(St),_(B,t),t&&e(Nt),t&&e(A),t&&e(qt),t&&e(S),t&&e(It),t&&e(x),_(V),t&&e(Ct),t&&e(at),t&&e(Mt),_(O,t),t&&e(Ht),t&&e(q),t&&e(Lt),t&&e(y),_(K),t&&e(Ut),t&&e(C),t&&e(zt),t&&e(k),_(Q),t&&e(Gt),_(X,t)}}}const ds={local:"tensorflow-mixnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"(Tensorflow) MixNet"};function ws(Ce){return us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class js extends ps{constructor($){super();ms(this,$,ws,gs,hs,{})}}export{js as default,ds as metadata};
