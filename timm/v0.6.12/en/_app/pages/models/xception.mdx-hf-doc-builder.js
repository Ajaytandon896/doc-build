import{S as ls,i as rs,s as ns,e as o,k as h,w as f,t as p,M as is,c as l,d as e,m as c,a as r,x as u,h as m,b as i,G as s,g as n,y as g,L as ps,q as d,o as w,B as v,v as ms}from"../../chunks/vendor-hf-doc-builder.js";import{I as wt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as at}from"../../chunks/CodeBlock-hf-doc-builder.js";function hs(qe){let _,vt,j,E,ot,L,Jt,lt,Qt,_t,$,rt,Wt,te,X,ee,se,jt,P,ae,D,oe,le,$t,b,S,nt,M,re,it,ne,bt,Z,ie,yt,z,xt,J,pe,kt,B,Et,Q,me,Pt,G,St,W,he,Tt,R,At,T,ce,pt,fe,ue,qt,A,ge,tt,de,we,It,y,q,mt,Y,ve,ht,_e,Ct,et,je,Nt,U,Ht,I,$e,F,be,ye,Lt,x,C,ct,O,xe,ft,ke,Xt,N,Ee,st,Pe,Se,Dt,k,H,ut,K,Te,gt,Ae,Mt,V,zt;return L=new wt({}),M=new wt({}),z=new at({props:{code:`import timm
model = timm.create_model('xception', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;xception&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),B=new at({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),G=new at({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),R=new at({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),Y=new wt({}),U=new at({props:{code:"model = timm.create_model('xception', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;xception&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),O=new wt({}),K=new wt({}),V=new at({props:{code:`@article{DBLP:journals/corr/ZagoruykoK16,
@misc{chollet2017xception,
      title={Xception: Deep Learning with Depthwise Separable Convolutions}, 
      author={Fran\xE7ois Chollet},
      year={2017},
      eprint={1610.02357},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`@article{DBLP:journals/corr/ZagoruykoK16,
@misc{chollet2017xception,
      <span class="hljs-attr">title={Xception:</span> Deep Learning <span class="hljs-keyword">with</span> Depthwise Separable Convolutions}, 
      <span class="hljs-attr">author={Fran\xE7ois</span> Chollet},
      <span class="hljs-attr">year={2017},</span>
      <span class="hljs-attr">eprint={1610.02357},</span>
      <span class="hljs-attr">archivePrefix={arXiv},</span>
      <span class="hljs-attr">primaryClass={cs.CV}</span>
}`}}),{c(){_=o("meta"),vt=h(),j=o("h1"),E=o("a"),ot=o("span"),f(L.$$.fragment),Jt=h(),lt=o("span"),Qt=p("Xception"),_t=h(),$=o("p"),rt=o("strong"),Wt=p("Xception"),te=p(" is a convolutional neural network architecture that relies solely on "),X=o("a"),ee=p("depthwise separable convolution layers"),se=p("."),jt=h(),P=o("p"),ae=p("The weights from this model were ported from "),D=o("a"),oe=p("Tensorflow/Models"),le=p("."),$t=h(),b=o("h2"),S=o("a"),nt=o("span"),f(M.$$.fragment),re=h(),it=o("span"),ne=p("How do I use this model on an image?"),bt=h(),Z=o("p"),ie=p("To load a pretrained model:"),yt=h(),f(z.$$.fragment),xt=h(),J=o("p"),pe=p("To load and preprocess the image:"),kt=h(),f(B.$$.fragment),Et=h(),Q=o("p"),me=p("To get the model predictions:"),Pt=h(),f(G.$$.fragment),St=h(),W=o("p"),he=p("To get the top-5 predictions class names:"),Tt=h(),f(R.$$.fragment),At=h(),T=o("p"),ce=p("Replace the model name with the variant you want to use, e.g. "),pt=o("code"),fe=p("xception"),ue=p(". You can find the IDs in the model summaries at the top of this page."),qt=h(),A=o("p"),ge=p("To extract image features with this model, follow the "),tt=o("a"),de=p("timm feature extraction examples"),we=p(", just change the name of the model you want to use."),It=h(),y=o("h2"),q=o("a"),mt=o("span"),f(Y.$$.fragment),ve=h(),ht=o("span"),_e=p("How do I finetune this model?"),Ct=h(),et=o("p"),je=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Nt=h(),f(U.$$.fragment),Ht=h(),I=o("p"),$e=p("To finetune on your own dataset, you have to write a training loop or adapt "),F=o("a"),be=p(`timm\u2019s training
script`),ye=p(" to use your dataset."),Lt=h(),x=o("h2"),C=o("a"),ct=o("span"),f(O.$$.fragment),xe=h(),ft=o("span"),ke=p("How do I train this model?"),Xt=h(),N=o("p"),Ee=p("You can follow the "),st=o("a"),Pe=p("timm recipe scripts"),Se=p(" for training a new model afresh."),Dt=h(),k=o("h2"),H=o("a"),ut=o("span"),f(K.$$.fragment),Te=h(),gt=o("span"),Ae=p("Citation"),Mt=h(),f(V.$$.fragment),this.h()},l(t){const a=is('[data-svelte="svelte-1phssyn"]',document.head);_=l(a,"META",{name:!0,content:!0}),a.forEach(e),vt=c(t),j=l(t,"H1",{class:!0});var Bt=r(j);E=l(Bt,"A",{id:!0,class:!0,href:!0});var Ie=r(E);ot=l(Ie,"SPAN",{});var Ce=r(ot);u(L.$$.fragment,Ce),Ce.forEach(e),Ie.forEach(e),Jt=c(Bt),lt=l(Bt,"SPAN",{});var Ne=r(lt);Qt=m(Ne,"Xception"),Ne.forEach(e),Bt.forEach(e),_t=c(t),$=l(t,"P",{});var dt=r($);rt=l(dt,"STRONG",{});var He=r(rt);Wt=m(He,"Xception"),He.forEach(e),te=m(dt," is a convolutional neural network architecture that relies solely on "),X=l(dt,"A",{href:!0,rel:!0});var Le=r(X);ee=m(Le,"depthwise separable convolution layers"),Le.forEach(e),se=m(dt,"."),dt.forEach(e),jt=c(t),P=l(t,"P",{});var Gt=r(P);ae=m(Gt,"The weights from this model were ported from "),D=l(Gt,"A",{href:!0,rel:!0});var Xe=r(D);oe=m(Xe,"Tensorflow/Models"),Xe.forEach(e),le=m(Gt,"."),Gt.forEach(e),$t=c(t),b=l(t,"H2",{class:!0});var Rt=r(b);S=l(Rt,"A",{id:!0,class:!0,href:!0});var De=r(S);nt=l(De,"SPAN",{});var Me=r(nt);u(M.$$.fragment,Me),Me.forEach(e),De.forEach(e),re=c(Rt),it=l(Rt,"SPAN",{});var ze=r(it);ne=m(ze,"How do I use this model on an image?"),ze.forEach(e),Rt.forEach(e),bt=c(t),Z=l(t,"P",{});var Be=r(Z);ie=m(Be,"To load a pretrained model:"),Be.forEach(e),yt=c(t),u(z.$$.fragment,t),xt=c(t),J=l(t,"P",{});var Ge=r(J);pe=m(Ge,"To load and preprocess the image:"),Ge.forEach(e),kt=c(t),u(B.$$.fragment,t),Et=c(t),Q=l(t,"P",{});var Re=r(Q);me=m(Re,"To get the model predictions:"),Re.forEach(e),Pt=c(t),u(G.$$.fragment,t),St=c(t),W=l(t,"P",{});var Ye=r(W);he=m(Ye,"To get the top-5 predictions class names:"),Ye.forEach(e),Tt=c(t),u(R.$$.fragment,t),At=c(t),T=l(t,"P",{});var Yt=r(T);ce=m(Yt,"Replace the model name with the variant you want to use, e.g. "),pt=l(Yt,"CODE",{});var Ue=r(pt);fe=m(Ue,"xception"),Ue.forEach(e),ue=m(Yt,". You can find the IDs in the model summaries at the top of this page."),Yt.forEach(e),qt=c(t),A=l(t,"P",{});var Ut=r(A);ge=m(Ut,"To extract image features with this model, follow the "),tt=l(Ut,"A",{href:!0});var Fe=r(tt);de=m(Fe,"timm feature extraction examples"),Fe.forEach(e),we=m(Ut,", just change the name of the model you want to use."),Ut.forEach(e),It=c(t),y=l(t,"H2",{class:!0});var Ft=r(y);q=l(Ft,"A",{id:!0,class:!0,href:!0});var Oe=r(q);mt=l(Oe,"SPAN",{});var Ke=r(mt);u(Y.$$.fragment,Ke),Ke.forEach(e),Oe.forEach(e),ve=c(Ft),ht=l(Ft,"SPAN",{});var Ve=r(ht);_e=m(Ve,"How do I finetune this model?"),Ve.forEach(e),Ft.forEach(e),Ct=c(t),et=l(t,"P",{});var Ze=r(et);je=m(Ze,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ze.forEach(e),Nt=c(t),u(U.$$.fragment,t),Ht=c(t),I=l(t,"P",{});var Ot=r(I);$e=m(Ot,"To finetune on your own dataset, you have to write a training loop or adapt "),F=l(Ot,"A",{href:!0,rel:!0});var Je=r(F);be=m(Je,`timm\u2019s training
script`),Je.forEach(e),ye=m(Ot," to use your dataset."),Ot.forEach(e),Lt=c(t),x=l(t,"H2",{class:!0});var Kt=r(x);C=l(Kt,"A",{id:!0,class:!0,href:!0});var Qe=r(C);ct=l(Qe,"SPAN",{});var We=r(ct);u(O.$$.fragment,We),We.forEach(e),Qe.forEach(e),xe=c(Kt),ft=l(Kt,"SPAN",{});var ts=r(ft);ke=m(ts,"How do I train this model?"),ts.forEach(e),Kt.forEach(e),Xt=c(t),N=l(t,"P",{});var Vt=r(N);Ee=m(Vt,"You can follow the "),st=l(Vt,"A",{href:!0});var es=r(st);Pe=m(es,"timm recipe scripts"),es.forEach(e),Se=m(Vt," for training a new model afresh."),Vt.forEach(e),Dt=c(t),k=l(t,"H2",{class:!0});var Zt=r(k);H=l(Zt,"A",{id:!0,class:!0,href:!0});var ss=r(H);ut=l(ss,"SPAN",{});var as=r(ut);u(K.$$.fragment,as),as.forEach(e),ss.forEach(e),Te=c(Zt),gt=l(Zt,"SPAN",{});var os=r(gt);Ae=m(os,"Citation"),os.forEach(e),Zt.forEach(e),Mt=c(t),u(V.$$.fragment,t),this.h()},h(){i(_,"name","hf:doc:metadata"),i(_,"content",JSON.stringify(cs)),i(E,"id","xception"),i(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(E,"href","#xception"),i(j,"class","relative group"),i(X,"href","https://paperswithcode.com/method/depthwise-separable-convolution"),i(X,"rel","nofollow"),i(D,"href","https://github.com/tensorflow/models"),i(D,"rel","nofollow"),i(S,"id","how-do-i-use-this-model-on-an-image"),i(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(S,"href","#how-do-i-use-this-model-on-an-image"),i(b,"class","relative group"),i(tt,"href","../feature_extraction"),i(q,"id","how-do-i-finetune-this-model"),i(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(q,"href","#how-do-i-finetune-this-model"),i(y,"class","relative group"),i(F,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(F,"rel","nofollow"),i(C,"id","how-do-i-train-this-model"),i(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(C,"href","#how-do-i-train-this-model"),i(x,"class","relative group"),i(st,"href","../scripts"),i(H,"id","citation"),i(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(H,"href","#citation"),i(k,"class","relative group")},m(t,a){s(document.head,_),n(t,vt,a),n(t,j,a),s(j,E),s(E,ot),g(L,ot,null),s(j,Jt),s(j,lt),s(lt,Qt),n(t,_t,a),n(t,$,a),s($,rt),s(rt,Wt),s($,te),s($,X),s(X,ee),s($,se),n(t,jt,a),n(t,P,a),s(P,ae),s(P,D),s(D,oe),s(P,le),n(t,$t,a),n(t,b,a),s(b,S),s(S,nt),g(M,nt,null),s(b,re),s(b,it),s(it,ne),n(t,bt,a),n(t,Z,a),s(Z,ie),n(t,yt,a),g(z,t,a),n(t,xt,a),n(t,J,a),s(J,pe),n(t,kt,a),g(B,t,a),n(t,Et,a),n(t,Q,a),s(Q,me),n(t,Pt,a),g(G,t,a),n(t,St,a),n(t,W,a),s(W,he),n(t,Tt,a),g(R,t,a),n(t,At,a),n(t,T,a),s(T,ce),s(T,pt),s(pt,fe),s(T,ue),n(t,qt,a),n(t,A,a),s(A,ge),s(A,tt),s(tt,de),s(A,we),n(t,It,a),n(t,y,a),s(y,q),s(q,mt),g(Y,mt,null),s(y,ve),s(y,ht),s(ht,_e),n(t,Ct,a),n(t,et,a),s(et,je),n(t,Nt,a),g(U,t,a),n(t,Ht,a),n(t,I,a),s(I,$e),s(I,F),s(F,be),s(I,ye),n(t,Lt,a),n(t,x,a),s(x,C),s(C,ct),g(O,ct,null),s(x,xe),s(x,ft),s(ft,ke),n(t,Xt,a),n(t,N,a),s(N,Ee),s(N,st),s(st,Pe),s(N,Se),n(t,Dt,a),n(t,k,a),s(k,H),s(H,ut),g(K,ut,null),s(k,Te),s(k,gt),s(gt,Ae),n(t,Mt,a),g(V,t,a),zt=!0},p:ps,i(t){zt||(d(L.$$.fragment,t),d(M.$$.fragment,t),d(z.$$.fragment,t),d(B.$$.fragment,t),d(G.$$.fragment,t),d(R.$$.fragment,t),d(Y.$$.fragment,t),d(U.$$.fragment,t),d(O.$$.fragment,t),d(K.$$.fragment,t),d(V.$$.fragment,t),zt=!0)},o(t){w(L.$$.fragment,t),w(M.$$.fragment,t),w(z.$$.fragment,t),w(B.$$.fragment,t),w(G.$$.fragment,t),w(R.$$.fragment,t),w(Y.$$.fragment,t),w(U.$$.fragment,t),w(O.$$.fragment,t),w(K.$$.fragment,t),w(V.$$.fragment,t),zt=!1},d(t){e(_),t&&e(vt),t&&e(j),v(L),t&&e(_t),t&&e($),t&&e(jt),t&&e(P),t&&e($t),t&&e(b),v(M),t&&e(bt),t&&e(Z),t&&e(yt),v(z,t),t&&e(xt),t&&e(J),t&&e(kt),v(B,t),t&&e(Et),t&&e(Q),t&&e(Pt),v(G,t),t&&e(St),t&&e(W),t&&e(Tt),v(R,t),t&&e(At),t&&e(T),t&&e(qt),t&&e(A),t&&e(It),t&&e(y),v(Y),t&&e(Ct),t&&e(et),t&&e(Nt),v(U,t),t&&e(Ht),t&&e(I),t&&e(Lt),t&&e(x),v(O),t&&e(Xt),t&&e(N),t&&e(Dt),t&&e(k),v(K),t&&e(Mt),v(V,t)}}}const cs={local:"xception",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"Xception"};function fs(qe){return ms(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ws extends ls{constructor(_){super();rs(this,_,fs,hs,ns,{})}}export{ws as default,cs as metadata};
