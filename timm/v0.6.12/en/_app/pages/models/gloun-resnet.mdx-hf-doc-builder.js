import{S as pt,i as mt,s as ht,e as n,k as h,w as u,t as i,M as ct,c as l,d as s,m as c,a as r,x as g,h as p,b as m,G as t,g as o,y as d,L as ft,q as w,o as _,B as b,v as ut}from"../../chunks/vendor-hf-doc-builder.js";import{I as _e}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ne}from"../../chunks/CodeBlock-hf-doc-builder.js";function gt(qs){let v,be,j,E,le,G,Qe,re,Ve,ve,f,oe,es,ss,ie,ts,as,C,ns,ls,je,P,rs,L,os,is,$e,$,S,pe,z,ps,me,ms,ye,W,hs,ke,D,xe,Q,cs,Ee,B,Pe,V,fs,Se,Y,Re,ee,us,Ne,Z,Ae,R,gs,he,ds,ws,Ie,N,_s,se,bs,vs,Te,y,A,ce,M,js,fe,$s,qe,te,ys,He,U,Ge,I,ks,O,xs,Es,Ce,k,T,ue,X,Ps,ge,Ss,Le,q,Rs,ae,Ns,As,ze,x,H,de,J,Is,we,Ts,De,F,Be;return G=new _e({}),z=new _e({}),D=new ne({props:{code:`import timm
model = timm.create_model('gluon_resnet101_v1b', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;gluon_resnet101_v1b&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),B=new ne({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),Y=new ne({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),Z=new ne({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),M=new _e({}),U=new ne({props:{code:"model = timm.create_model('gluon_resnet101_v1b', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;gluon_resnet101_v1b&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),X=new _e({}),J=new _e({}),F=new ne({props:{code:`@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}`,highlighted:`@article{DBLP:journals<span class="hljs-regexp">/corr/</span>HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning <span class="hljs-keyword">for</span> Image Recognition},
  journal   = {CoRR},
  volume    = {abs/<span class="hljs-number">1512.03385</span>},
  year      = {<span class="hljs-number">2015</span>},
  url       = {http:<span class="hljs-regexp">//</span>arxiv.org<span class="hljs-regexp">/abs/</span><span class="hljs-number">1512.03385</span>},
  archivePrefix = {arXiv},
  eprint    = {<span class="hljs-number">1512.03385</span>},
  timestamp = {Wed, <span class="hljs-number">17</span> Apr <span class="hljs-number">2019</span> <span class="hljs-number">17</span>:<span class="hljs-number">23</span>:<span class="hljs-number">45</span> +<span class="hljs-number">0200</span>},
  biburl    = {https:<span class="hljs-regexp">//</span>dblp.org<span class="hljs-regexp">/rec/</span>journals<span class="hljs-regexp">/corr/</span>HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https:<span class="hljs-regexp">//</span>dblp.org}
}`}}),{c(){v=n("meta"),be=h(),j=n("h1"),E=n("a"),le=n("span"),u(G.$$.fragment),Qe=h(),re=n("span"),Ve=i("(Gluon) ResNet"),ve=h(),f=n("p"),oe=n("strong"),es=i("Residual Networks"),ss=i(", or "),ie=n("strong"),ts=i("ResNets"),as=i(", learn residual functions with reference to the layer inputs, instead of learning unreferenced functions. Instead of hoping each few stacked layers directly fit a desired underlying mapping, residual nets let these layers fit a residual mapping. They stack "),C=n("a"),ns=i("residual blocks"),ls=i(" ontop of each other to form network: e.g. a ResNet-50 has fifty layers using these blocks."),je=h(),P=n("p"),rs=i("The weights from this model were ported from "),L=n("a"),os=i("Gluon"),is=i("."),$e=h(),$=n("h2"),S=n("a"),pe=n("span"),u(z.$$.fragment),ps=h(),me=n("span"),ms=i("How do I use this model on an image?"),ye=h(),W=n("p"),hs=i("To load a pretrained model:"),ke=h(),u(D.$$.fragment),xe=h(),Q=n("p"),cs=i("To load and preprocess the image:"),Ee=h(),u(B.$$.fragment),Pe=h(),V=n("p"),fs=i("To get the model predictions:"),Se=h(),u(Y.$$.fragment),Re=h(),ee=n("p"),us=i("To get the top-5 predictions class names:"),Ne=h(),u(Z.$$.fragment),Ae=h(),R=n("p"),gs=i("Replace the model name with the variant you want to use, e.g. "),he=n("code"),ds=i("gluon_resnet101_v1b"),ws=i(". You can find the IDs in the model summaries at the top of this page."),Ie=h(),N=n("p"),_s=i("To extract image features with this model, follow the "),se=n("a"),bs=i("timm feature extraction examples"),vs=i(", just change the name of the model you want to use."),Te=h(),y=n("h2"),A=n("a"),ce=n("span"),u(M.$$.fragment),js=h(),fe=n("span"),$s=i("How do I finetune this model?"),qe=h(),te=n("p"),ys=i("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),He=h(),u(U.$$.fragment),Ge=h(),I=n("p"),ks=i("To finetune on your own dataset, you have to write a training loop or adapt "),O=n("a"),xs=i(`timm\u2019s training
script`),Es=i(" to use your dataset."),Ce=h(),k=n("h2"),T=n("a"),ue=n("span"),u(X.$$.fragment),Ps=h(),ge=n("span"),Ss=i("How do I train this model?"),Le=h(),q=n("p"),Rs=i("You can follow the "),ae=n("a"),Ns=i("timm recipe scripts"),As=i(" for training a new model afresh."),ze=h(),x=n("h2"),H=n("a"),de=n("span"),u(J.$$.fragment),Is=h(),we=n("span"),Ts=i("Citation"),De=h(),u(F.$$.fragment),this.h()},l(e){const a=ct('[data-svelte="svelte-1phssyn"]',document.head);v=l(a,"META",{name:!0,content:!0}),a.forEach(s),be=c(e),j=l(e,"H1",{class:!0});var Ye=r(j);E=l(Ye,"A",{id:!0,class:!0,href:!0});var Hs=r(E);le=l(Hs,"SPAN",{});var Gs=r(le);g(G.$$.fragment,Gs),Gs.forEach(s),Hs.forEach(s),Qe=c(Ye),re=l(Ye,"SPAN",{});var Cs=r(re);Ve=p(Cs,"(Gluon) ResNet"),Cs.forEach(s),Ye.forEach(s),ve=c(e),f=l(e,"P",{});var K=r(f);oe=l(K,"STRONG",{});var Ls=r(oe);es=p(Ls,"Residual Networks"),Ls.forEach(s),ss=p(K,", or "),ie=l(K,"STRONG",{});var zs=r(ie);ts=p(zs,"ResNets"),zs.forEach(s),as=p(K,", learn residual functions with reference to the layer inputs, instead of learning unreferenced functions. Instead of hoping each few stacked layers directly fit a desired underlying mapping, residual nets let these layers fit a residual mapping. They stack "),C=l(K,"A",{href:!0,rel:!0});var Ds=r(C);ns=p(Ds,"residual blocks"),Ds.forEach(s),ls=p(K," ontop of each other to form network: e.g. a ResNet-50 has fifty layers using these blocks."),K.forEach(s),je=c(e),P=l(e,"P",{});var Ze=r(P);rs=p(Ze,"The weights from this model were ported from "),L=l(Ze,"A",{href:!0,rel:!0});var Bs=r(L);os=p(Bs,"Gluon"),Bs.forEach(s),is=p(Ze,"."),Ze.forEach(s),$e=c(e),$=l(e,"H2",{class:!0});var Me=r($);S=l(Me,"A",{id:!0,class:!0,href:!0});var Ys=r(S);pe=l(Ys,"SPAN",{});var Zs=r(pe);g(z.$$.fragment,Zs),Zs.forEach(s),Ys.forEach(s),ps=c(Me),me=l(Me,"SPAN",{});var Ms=r(me);ms=p(Ms,"How do I use this model on an image?"),Ms.forEach(s),Me.forEach(s),ye=c(e),W=l(e,"P",{});var Us=r(W);hs=p(Us,"To load a pretrained model:"),Us.forEach(s),ke=c(e),g(D.$$.fragment,e),xe=c(e),Q=l(e,"P",{});var Os=r(Q);cs=p(Os,"To load and preprocess the image:"),Os.forEach(s),Ee=c(e),g(B.$$.fragment,e),Pe=c(e),V=l(e,"P",{});var Xs=r(V);fs=p(Xs,"To get the model predictions:"),Xs.forEach(s),Se=c(e),g(Y.$$.fragment,e),Re=c(e),ee=l(e,"P",{});var Js=r(ee);us=p(Js,"To get the top-5 predictions class names:"),Js.forEach(s),Ne=c(e),g(Z.$$.fragment,e),Ae=c(e),R=l(e,"P",{});var Ue=r(R);gs=p(Ue,"Replace the model name with the variant you want to use, e.g. "),he=l(Ue,"CODE",{});var Fs=r(he);ds=p(Fs,"gluon_resnet101_v1b"),Fs.forEach(s),ws=p(Ue,". You can find the IDs in the model summaries at the top of this page."),Ue.forEach(s),Ie=c(e),N=l(e,"P",{});var Oe=r(N);_s=p(Oe,"To extract image features with this model, follow the "),se=l(Oe,"A",{href:!0});var Ks=r(se);bs=p(Ks,"timm feature extraction examples"),Ks.forEach(s),vs=p(Oe,", just change the name of the model you want to use."),Oe.forEach(s),Te=c(e),y=l(e,"H2",{class:!0});var Xe=r(y);A=l(Xe,"A",{id:!0,class:!0,href:!0});var Ws=r(A);ce=l(Ws,"SPAN",{});var Qs=r(ce);g(M.$$.fragment,Qs),Qs.forEach(s),Ws.forEach(s),js=c(Xe),fe=l(Xe,"SPAN",{});var Vs=r(fe);$s=p(Vs,"How do I finetune this model?"),Vs.forEach(s),Xe.forEach(s),qe=c(e),te=l(e,"P",{});var et=r(te);ys=p(et,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),et.forEach(s),He=c(e),g(U.$$.fragment,e),Ge=c(e),I=l(e,"P",{});var Je=r(I);ks=p(Je,"To finetune on your own dataset, you have to write a training loop or adapt "),O=l(Je,"A",{href:!0,rel:!0});var st=r(O);xs=p(st,`timm\u2019s training
script`),st.forEach(s),Es=p(Je," to use your dataset."),Je.forEach(s),Ce=c(e),k=l(e,"H2",{class:!0});var Fe=r(k);T=l(Fe,"A",{id:!0,class:!0,href:!0});var tt=r(T);ue=l(tt,"SPAN",{});var at=r(ue);g(X.$$.fragment,at),at.forEach(s),tt.forEach(s),Ps=c(Fe),ge=l(Fe,"SPAN",{});var nt=r(ge);Ss=p(nt,"How do I train this model?"),nt.forEach(s),Fe.forEach(s),Le=c(e),q=l(e,"P",{});var Ke=r(q);Rs=p(Ke,"You can follow the "),ae=l(Ke,"A",{href:!0});var lt=r(ae);Ns=p(lt,"timm recipe scripts"),lt.forEach(s),As=p(Ke," for training a new model afresh."),Ke.forEach(s),ze=c(e),x=l(e,"H2",{class:!0});var We=r(x);H=l(We,"A",{id:!0,class:!0,href:!0});var rt=r(H);de=l(rt,"SPAN",{});var ot=r(de);g(J.$$.fragment,ot),ot.forEach(s),rt.forEach(s),Is=c(We),we=l(We,"SPAN",{});var it=r(we);Ts=p(it,"Citation"),it.forEach(s),We.forEach(s),De=c(e),g(F.$$.fragment,e),this.h()},h(){m(v,"name","hf:doc:metadata"),m(v,"content",JSON.stringify(dt)),m(E,"id","gluon-resnet"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#gluon-resnet"),m(j,"class","relative group"),m(C,"href","https://paperswithcode.com/method/residual-block"),m(C,"rel","nofollow"),m(L,"href","https://cv.gluon.ai/model_zoo/classification.html"),m(L,"rel","nofollow"),m(S,"id","how-do-i-use-this-model-on-an-image"),m(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S,"href","#how-do-i-use-this-model-on-an-image"),m($,"class","relative group"),m(se,"href","../feature_extraction"),m(A,"id","how-do-i-finetune-this-model"),m(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(A,"href","#how-do-i-finetune-this-model"),m(y,"class","relative group"),m(O,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),m(O,"rel","nofollow"),m(T,"id","how-do-i-train-this-model"),m(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(T,"href","#how-do-i-train-this-model"),m(k,"class","relative group"),m(ae,"href","../scripts"),m(H,"id","citation"),m(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(H,"href","#citation"),m(x,"class","relative group")},m(e,a){t(document.head,v),o(e,be,a),o(e,j,a),t(j,E),t(E,le),d(G,le,null),t(j,Qe),t(j,re),t(re,Ve),o(e,ve,a),o(e,f,a),t(f,oe),t(oe,es),t(f,ss),t(f,ie),t(ie,ts),t(f,as),t(f,C),t(C,ns),t(f,ls),o(e,je,a),o(e,P,a),t(P,rs),t(P,L),t(L,os),t(P,is),o(e,$e,a),o(e,$,a),t($,S),t(S,pe),d(z,pe,null),t($,ps),t($,me),t(me,ms),o(e,ye,a),o(e,W,a),t(W,hs),o(e,ke,a),d(D,e,a),o(e,xe,a),o(e,Q,a),t(Q,cs),o(e,Ee,a),d(B,e,a),o(e,Pe,a),o(e,V,a),t(V,fs),o(e,Se,a),d(Y,e,a),o(e,Re,a),o(e,ee,a),t(ee,us),o(e,Ne,a),d(Z,e,a),o(e,Ae,a),o(e,R,a),t(R,gs),t(R,he),t(he,ds),t(R,ws),o(e,Ie,a),o(e,N,a),t(N,_s),t(N,se),t(se,bs),t(N,vs),o(e,Te,a),o(e,y,a),t(y,A),t(A,ce),d(M,ce,null),t(y,js),t(y,fe),t(fe,$s),o(e,qe,a),o(e,te,a),t(te,ys),o(e,He,a),d(U,e,a),o(e,Ge,a),o(e,I,a),t(I,ks),t(I,O),t(O,xs),t(I,Es),o(e,Ce,a),o(e,k,a),t(k,T),t(T,ue),d(X,ue,null),t(k,Ps),t(k,ge),t(ge,Ss),o(e,Le,a),o(e,q,a),t(q,Rs),t(q,ae),t(ae,Ns),t(q,As),o(e,ze,a),o(e,x,a),t(x,H),t(H,de),d(J,de,null),t(x,Is),t(x,we),t(we,Ts),o(e,De,a),d(F,e,a),Be=!0},p:ft,i(e){Be||(w(G.$$.fragment,e),w(z.$$.fragment,e),w(D.$$.fragment,e),w(B.$$.fragment,e),w(Y.$$.fragment,e),w(Z.$$.fragment,e),w(M.$$.fragment,e),w(U.$$.fragment,e),w(X.$$.fragment,e),w(J.$$.fragment,e),w(F.$$.fragment,e),Be=!0)},o(e){_(G.$$.fragment,e),_(z.$$.fragment,e),_(D.$$.fragment,e),_(B.$$.fragment,e),_(Y.$$.fragment,e),_(Z.$$.fragment,e),_(M.$$.fragment,e),_(U.$$.fragment,e),_(X.$$.fragment,e),_(J.$$.fragment,e),_(F.$$.fragment,e),Be=!1},d(e){s(v),e&&s(be),e&&s(j),b(G),e&&s(ve),e&&s(f),e&&s(je),e&&s(P),e&&s($e),e&&s($),b(z),e&&s(ye),e&&s(W),e&&s(ke),b(D,e),e&&s(xe),e&&s(Q),e&&s(Ee),b(B,e),e&&s(Pe),e&&s(V),e&&s(Se),b(Y,e),e&&s(Re),e&&s(ee),e&&s(Ne),b(Z,e),e&&s(Ae),e&&s(R),e&&s(Ie),e&&s(N),e&&s(Te),e&&s(y),b(M),e&&s(qe),e&&s(te),e&&s(He),b(U,e),e&&s(Ge),e&&s(I),e&&s(Ce),e&&s(k),b(X),e&&s(Le),e&&s(q),e&&s(ze),e&&s(x),b(J),e&&s(De),b(F,e)}}}const dt={local:"gluon-resnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"(Gluon) ResNet"};function wt(qs){return ut(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class jt extends pt{constructor(v){super();mt(this,v,wt,gt,ht,{})}}export{jt as default,dt as metadata};
