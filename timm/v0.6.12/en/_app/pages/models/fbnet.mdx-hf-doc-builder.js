import{S as ps,i as hs,s as ms,e as n,k as m,w as u,t as p,M as cs,c as l,d as t,m as c,a as r,x as d,h,b as i,G as s,g as o,y as g,L as fs,q as w,o as v,B as _,v as us}from"../../chunks/vendor-hf-doc-builder.js";import{I as ve}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as le}from"../../chunks/CodeBlock-hf-doc-builder.js";function ds(Bt){let b,_e,j,x,re,H,Ze,oe,Qe,be,f,ie,et,tt,F,st,at,Y,nt,lt,je,P,rt,D,ot,it,$e,$,N,pe,z,pt,he,ht,ye,Z,mt,ke,L,Ee,Q,ct,xe,M,Pe,ee,ft,Ne,G,Se,te,ut,Ae,R,Te,S,dt,me,gt,wt,qe,A,vt,se,_t,bt,Ie,y,T,ce,W,jt,fe,$t,Be,ae,yt,Ce,U,He,q,kt,K,Et,xt,Fe,k,I,ue,V,Pt,de,Nt,Ye,B,St,ne,At,Tt,De,E,C,ge,X,qt,we,It,ze,J,Le;return H=new ve({}),z=new ve({}),L=new le({props:{code:`import timm
model = timm.create_model('fbnetc_100', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;fbnetc_100&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),M=new le({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),G=new le({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),R=new le({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),W=new ve({}),U=new le({props:{code:"model = timm.create_model('fbnetc_100', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;fbnetc_100&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),V=new ve({}),X=new ve({}),J=new le({props:{code:`@misc{wu2019fbnet,
      title={FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search}, 
      author={Bichen Wu and Xiaoliang Dai and Peizhao Zhang and Yanghan Wang and Fei Sun and Yiming Wu and Yuandong Tian and Peter Vajda and Yangqing Jia and Kurt Keutzer},
      year={2019},
      eprint={1812.03443},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`@misc{wu<span class="hljs-symbol">2019f</span>bnet,
      title={FBNet: Hardware-Aware Efficient ConvNet Design via <span class="hljs-keyword">Differentiable </span>Neural Architecture Search}, 
      author={<span class="hljs-keyword">Bichen </span>Wu <span class="hljs-keyword">and </span>Xiaoliang Dai <span class="hljs-keyword">and </span>Peizhao Zhang <span class="hljs-keyword">and </span>Yanghan Wang <span class="hljs-keyword">and </span>Fei Sun <span class="hljs-keyword">and </span>Yiming Wu <span class="hljs-keyword">and </span>Yuandong Tian <span class="hljs-keyword">and </span>Peter Vajda <span class="hljs-keyword">and </span>Yangqing <span class="hljs-keyword">Jia </span><span class="hljs-keyword">and </span>Kurt Keutzer},
      year={<span class="hljs-number">2019</span>},
      eprint={<span class="hljs-number">1812</span>.<span class="hljs-number">03443</span>},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`}}),{c(){b=n("meta"),_e=m(),j=n("h1"),x=n("a"),re=n("span"),u(H.$$.fragment),Ze=m(),oe=n("span"),Qe=p("FBNet"),be=m(),f=n("p"),ie=n("strong"),et=p("FBNet"),tt=p(" is a type of convolutional neural architectures discovered through "),F=n("a"),st=p("DNAS"),at=p(" neural architecture search. It utilises a basic type of image model block inspired by "),Y=n("a"),nt=p("MobileNetv2"),lt=p(" that utilises depthwise convolutions and an inverted residual structure (see components)."),je=m(),P=n("p"),rt=p("The principal building block is the "),D=n("a"),ot=p("FBNet Block"),it=p("."),$e=m(),$=n("h2"),N=n("a"),pe=n("span"),u(z.$$.fragment),pt=m(),he=n("span"),ht=p("How do I use this model on an image?"),ye=m(),Z=n("p"),mt=p("To load a pretrained model:"),ke=m(),u(L.$$.fragment),Ee=m(),Q=n("p"),ct=p("To load and preprocess the image:"),xe=m(),u(M.$$.fragment),Pe=m(),ee=n("p"),ft=p("To get the model predictions:"),Ne=m(),u(G.$$.fragment),Se=m(),te=n("p"),ut=p("To get the top-5 predictions class names:"),Ae=m(),u(R.$$.fragment),Te=m(),S=n("p"),dt=p("Replace the model name with the variant you want to use, e.g. "),me=n("code"),gt=p("fbnetc_100"),wt=p(". You can find the IDs in the model summaries at the top of this page."),qe=m(),A=n("p"),vt=p("To extract image features with this model, follow the "),se=n("a"),_t=p("timm feature extraction examples"),bt=p(", just change the name of the model you want to use."),Ie=m(),y=n("h2"),T=n("a"),ce=n("span"),u(W.$$.fragment),jt=m(),fe=n("span"),$t=p("How do I finetune this model?"),Be=m(),ae=n("p"),yt=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ce=m(),u(U.$$.fragment),He=m(),q=n("p"),kt=p("To finetune on your own dataset, you have to write a training loop or adapt "),K=n("a"),Et=p(`timm\u2019s training
script`),xt=p(" to use your dataset."),Fe=m(),k=n("h2"),I=n("a"),ue=n("span"),u(V.$$.fragment),Pt=m(),de=n("span"),Nt=p("How do I train this model?"),Ye=m(),B=n("p"),St=p("You can follow the "),ne=n("a"),At=p("timm recipe scripts"),Tt=p(" for training a new model afresh."),De=m(),E=n("h2"),C=n("a"),ge=n("span"),u(X.$$.fragment),qt=m(),we=n("span"),It=p("Citation"),ze=m(),u(J.$$.fragment),this.h()},l(e){const a=cs('[data-svelte="svelte-1phssyn"]',document.head);b=l(a,"META",{name:!0,content:!0}),a.forEach(t),_e=c(e),j=l(e,"H1",{class:!0});var Me=r(j);x=l(Me,"A",{id:!0,class:!0,href:!0});var Ct=r(x);re=l(Ct,"SPAN",{});var Ht=r(re);d(H.$$.fragment,Ht),Ht.forEach(t),Ct.forEach(t),Ze=c(Me),oe=l(Me,"SPAN",{});var Ft=r(oe);Qe=h(Ft,"FBNet"),Ft.forEach(t),Me.forEach(t),be=c(e),f=l(e,"P",{});var O=r(f);ie=l(O,"STRONG",{});var Yt=r(ie);et=h(Yt,"FBNet"),Yt.forEach(t),tt=h(O," is a type of convolutional neural architectures discovered through "),F=l(O,"A",{href:!0,rel:!0});var Dt=r(F);st=h(Dt,"DNAS"),Dt.forEach(t),at=h(O," neural architecture search. It utilises a basic type of image model block inspired by "),Y=l(O,"A",{href:!0,rel:!0});var zt=r(Y);nt=h(zt,"MobileNetv2"),zt.forEach(t),lt=h(O," that utilises depthwise convolutions and an inverted residual structure (see components)."),O.forEach(t),je=c(e),P=l(e,"P",{});var Ge=r(P);rt=h(Ge,"The principal building block is the "),D=l(Ge,"A",{href:!0,rel:!0});var Lt=r(D);ot=h(Lt,"FBNet Block"),Lt.forEach(t),it=h(Ge,"."),Ge.forEach(t),$e=c(e),$=l(e,"H2",{class:!0});var Re=r($);N=l(Re,"A",{id:!0,class:!0,href:!0});var Mt=r(N);pe=l(Mt,"SPAN",{});var Gt=r(pe);d(z.$$.fragment,Gt),Gt.forEach(t),Mt.forEach(t),pt=c(Re),he=l(Re,"SPAN",{});var Rt=r(he);ht=h(Rt,"How do I use this model on an image?"),Rt.forEach(t),Re.forEach(t),ye=c(e),Z=l(e,"P",{});var Wt=r(Z);mt=h(Wt,"To load a pretrained model:"),Wt.forEach(t),ke=c(e),d(L.$$.fragment,e),Ee=c(e),Q=l(e,"P",{});var Ut=r(Q);ct=h(Ut,"To load and preprocess the image:"),Ut.forEach(t),xe=c(e),d(M.$$.fragment,e),Pe=c(e),ee=l(e,"P",{});var Kt=r(ee);ft=h(Kt,"To get the model predictions:"),Kt.forEach(t),Ne=c(e),d(G.$$.fragment,e),Se=c(e),te=l(e,"P",{});var Vt=r(te);ut=h(Vt,"To get the top-5 predictions class names:"),Vt.forEach(t),Ae=c(e),d(R.$$.fragment,e),Te=c(e),S=l(e,"P",{});var We=r(S);dt=h(We,"Replace the model name with the variant you want to use, e.g. "),me=l(We,"CODE",{});var Xt=r(me);gt=h(Xt,"fbnetc_100"),Xt.forEach(t),wt=h(We,". You can find the IDs in the model summaries at the top of this page."),We.forEach(t),qe=c(e),A=l(e,"P",{});var Ue=r(A);vt=h(Ue,"To extract image features with this model, follow the "),se=l(Ue,"A",{href:!0});var Jt=r(se);_t=h(Jt,"timm feature extraction examples"),Jt.forEach(t),bt=h(Ue,", just change the name of the model you want to use."),Ue.forEach(t),Ie=c(e),y=l(e,"H2",{class:!0});var Ke=r(y);T=l(Ke,"A",{id:!0,class:!0,href:!0});var Ot=r(T);ce=l(Ot,"SPAN",{});var Zt=r(ce);d(W.$$.fragment,Zt),Zt.forEach(t),Ot.forEach(t),jt=c(Ke),fe=l(Ke,"SPAN",{});var Qt=r(fe);$t=h(Qt,"How do I finetune this model?"),Qt.forEach(t),Ke.forEach(t),Be=c(e),ae=l(e,"P",{});var es=r(ae);yt=h(es,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),es.forEach(t),Ce=c(e),d(U.$$.fragment,e),He=c(e),q=l(e,"P",{});var Ve=r(q);kt=h(Ve,"To finetune on your own dataset, you have to write a training loop or adapt "),K=l(Ve,"A",{href:!0,rel:!0});var ts=r(K);Et=h(ts,`timm\u2019s training
script`),ts.forEach(t),xt=h(Ve," to use your dataset."),Ve.forEach(t),Fe=c(e),k=l(e,"H2",{class:!0});var Xe=r(k);I=l(Xe,"A",{id:!0,class:!0,href:!0});var ss=r(I);ue=l(ss,"SPAN",{});var as=r(ue);d(V.$$.fragment,as),as.forEach(t),ss.forEach(t),Pt=c(Xe),de=l(Xe,"SPAN",{});var ns=r(de);Nt=h(ns,"How do I train this model?"),ns.forEach(t),Xe.forEach(t),Ye=c(e),B=l(e,"P",{});var Je=r(B);St=h(Je,"You can follow the "),ne=l(Je,"A",{href:!0});var ls=r(ne);At=h(ls,"timm recipe scripts"),ls.forEach(t),Tt=h(Je," for training a new model afresh."),Je.forEach(t),De=c(e),E=l(e,"H2",{class:!0});var Oe=r(E);C=l(Oe,"A",{id:!0,class:!0,href:!0});var rs=r(C);ge=l(rs,"SPAN",{});var os=r(ge);d(X.$$.fragment,os),os.forEach(t),rs.forEach(t),qt=c(Oe),we=l(Oe,"SPAN",{});var is=r(we);It=h(is,"Citation"),is.forEach(t),Oe.forEach(t),ze=c(e),d(J.$$.fragment,e),this.h()},h(){i(b,"name","hf:doc:metadata"),i(b,"content",JSON.stringify(gs)),i(x,"id","fbnet"),i(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(x,"href","#fbnet"),i(j,"class","relative group"),i(F,"href","https://paperswithcode.com/method/dnas"),i(F,"rel","nofollow"),i(Y,"href","https://paperswithcode.com/method/mobilenetv2"),i(Y,"rel","nofollow"),i(D,"href","https://paperswithcode.com/method/fbnet-block"),i(D,"rel","nofollow"),i(N,"id","how-do-i-use-this-model-on-an-image"),i(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(N,"href","#how-do-i-use-this-model-on-an-image"),i($,"class","relative group"),i(se,"href","../feature_extraction"),i(T,"id","how-do-i-finetune-this-model"),i(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(T,"href","#how-do-i-finetune-this-model"),i(y,"class","relative group"),i(K,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(K,"rel","nofollow"),i(I,"id","how-do-i-train-this-model"),i(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(I,"href","#how-do-i-train-this-model"),i(k,"class","relative group"),i(ne,"href","../scripts"),i(C,"id","citation"),i(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(C,"href","#citation"),i(E,"class","relative group")},m(e,a){s(document.head,b),o(e,_e,a),o(e,j,a),s(j,x),s(x,re),g(H,re,null),s(j,Ze),s(j,oe),s(oe,Qe),o(e,be,a),o(e,f,a),s(f,ie),s(ie,et),s(f,tt),s(f,F),s(F,st),s(f,at),s(f,Y),s(Y,nt),s(f,lt),o(e,je,a),o(e,P,a),s(P,rt),s(P,D),s(D,ot),s(P,it),o(e,$e,a),o(e,$,a),s($,N),s(N,pe),g(z,pe,null),s($,pt),s($,he),s(he,ht),o(e,ye,a),o(e,Z,a),s(Z,mt),o(e,ke,a),g(L,e,a),o(e,Ee,a),o(e,Q,a),s(Q,ct),o(e,xe,a),g(M,e,a),o(e,Pe,a),o(e,ee,a),s(ee,ft),o(e,Ne,a),g(G,e,a),o(e,Se,a),o(e,te,a),s(te,ut),o(e,Ae,a),g(R,e,a),o(e,Te,a),o(e,S,a),s(S,dt),s(S,me),s(me,gt),s(S,wt),o(e,qe,a),o(e,A,a),s(A,vt),s(A,se),s(se,_t),s(A,bt),o(e,Ie,a),o(e,y,a),s(y,T),s(T,ce),g(W,ce,null),s(y,jt),s(y,fe),s(fe,$t),o(e,Be,a),o(e,ae,a),s(ae,yt),o(e,Ce,a),g(U,e,a),o(e,He,a),o(e,q,a),s(q,kt),s(q,K),s(K,Et),s(q,xt),o(e,Fe,a),o(e,k,a),s(k,I),s(I,ue),g(V,ue,null),s(k,Pt),s(k,de),s(de,Nt),o(e,Ye,a),o(e,B,a),s(B,St),s(B,ne),s(ne,At),s(B,Tt),o(e,De,a),o(e,E,a),s(E,C),s(C,ge),g(X,ge,null),s(E,qt),s(E,we),s(we,It),o(e,ze,a),g(J,e,a),Le=!0},p:fs,i(e){Le||(w(H.$$.fragment,e),w(z.$$.fragment,e),w(L.$$.fragment,e),w(M.$$.fragment,e),w(G.$$.fragment,e),w(R.$$.fragment,e),w(W.$$.fragment,e),w(U.$$.fragment,e),w(V.$$.fragment,e),w(X.$$.fragment,e),w(J.$$.fragment,e),Le=!0)},o(e){v(H.$$.fragment,e),v(z.$$.fragment,e),v(L.$$.fragment,e),v(M.$$.fragment,e),v(G.$$.fragment,e),v(R.$$.fragment,e),v(W.$$.fragment,e),v(U.$$.fragment,e),v(V.$$.fragment,e),v(X.$$.fragment,e),v(J.$$.fragment,e),Le=!1},d(e){t(b),e&&t(_e),e&&t(j),_(H),e&&t(be),e&&t(f),e&&t(je),e&&t(P),e&&t($e),e&&t($),_(z),e&&t(ye),e&&t(Z),e&&t(ke),_(L,e),e&&t(Ee),e&&t(Q),e&&t(xe),_(M,e),e&&t(Pe),e&&t(ee),e&&t(Ne),_(G,e),e&&t(Se),e&&t(te),e&&t(Ae),_(R,e),e&&t(Te),e&&t(S),e&&t(qe),e&&t(A),e&&t(Ie),e&&t(y),_(W),e&&t(Be),e&&t(ae),e&&t(Ce),_(U,e),e&&t(He),e&&t(q),e&&t(Fe),e&&t(k),_(V),e&&t(Ye),e&&t(B),e&&t(De),e&&t(E),_(X),e&&t(ze),_(J,e)}}}const gs={local:"fbnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"FBNet"};function ws(Bt){return us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class js extends ps{constructor(b){super();hs(this,b,ws,ds,ms,{})}}export{js as default,gs as metadata};
