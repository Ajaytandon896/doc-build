import{S as ps,i as ms,s as hs,e as n,k as h,w as u,t as p,M as cs,c as o,d as t,m as c,a as l,x as d,h as m,b as i,G as s,g as r,y as g,L as fs,q as w,o as _,B as v,v as us}from"../../chunks/vendor-hf-doc-builder.js";import{I as _e}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as oe}from"../../chunks/CodeBlock-hf-doc-builder.js";function ds(Ht){let j,ve,$,E,le,C,Qe,re,Ze,je,f,ie,et,tt,G,st,at,R,nt,ot,$e,S,lt,L,rt,it,be,b,P,pe,X,pt,me,mt,ye,Q,ht,xe,Y,ke,Z,ct,Ee,M,Se,ee,ft,Pe,U,qe,te,ut,Ne,B,Ae,q,dt,he,gt,wt,Te,N,_t,se,vt,jt,Ie,y,A,ce,D,$t,fe,bt,He,ae,yt,ze,J,Ce,T,xt,O,kt,Et,Ge,x,I,ue,F,St,de,Pt,Re,H,qt,ne,Nt,At,Le,k,z,ge,V,Tt,we,It,Xe,W,Ye;return C=new _e({}),X=new _e({}),Y=new oe({props:{code:`import timm
model = timm.create_model('gluon_seresnext101_32x4d', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;gluon_seresnext101_32x4d&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),M=new oe({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),U=new oe({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),B=new oe({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),D=new _e({}),J=new oe({props:{code:"model = timm.create_model('gluon_seresnext101_32x4d', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;gluon_seresnext101_32x4d&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),F=new _e({}),V=new _e({}),W=new oe({props:{code:`@misc{hu2019squeezeandexcitation,
      title={Squeeze-and-Excitation Networks}, 
      author={Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},
      year={2019},
      eprint={1709.01507},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`@misc{hu2019squeezeandexcitation,
      title={Squeeze-<span class="hljs-keyword">and-Excitation </span>Networks}, 
      author={<span class="hljs-keyword">Jie </span>Hu <span class="hljs-keyword">and </span>Li <span class="hljs-keyword">Shen </span><span class="hljs-keyword">and </span>Samuel Albanie <span class="hljs-keyword">and </span>Gang Sun <span class="hljs-keyword">and </span>Enhua Wu},
      year={<span class="hljs-number">2019</span>},
      eprint={<span class="hljs-number">1709</span>.<span class="hljs-number">01507</span>},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`}}),{c(){j=n("meta"),ve=h(),$=n("h1"),E=n("a"),le=n("span"),u(C.$$.fragment),Qe=h(),re=n("span"),Ze=p("(Gluon) SE-ResNeXt"),je=h(),f=n("p"),ie=n("strong"),et=p("SE ResNeXt"),tt=p(" is a variant of a "),G=n("a"),st=p("ResNext"),at=p(" that employs "),R=n("a"),nt=p("squeeze-and-excitation blocks"),ot=p(" to enable the network to perform dynamic channel-wise feature recalibration."),$e=h(),S=n("p"),lt=p("The weights from this model were ported from "),L=n("a"),rt=p("Gluon"),it=p("."),be=h(),b=n("h2"),P=n("a"),pe=n("span"),u(X.$$.fragment),pt=h(),me=n("span"),mt=p("How do I use this model on an image?"),ye=h(),Q=n("p"),ht=p("To load a pretrained model:"),xe=h(),u(Y.$$.fragment),ke=h(),Z=n("p"),ct=p("To load and preprocess the image:"),Ee=h(),u(M.$$.fragment),Se=h(),ee=n("p"),ft=p("To get the model predictions:"),Pe=h(),u(U.$$.fragment),qe=h(),te=n("p"),ut=p("To get the top-5 predictions class names:"),Ne=h(),u(B.$$.fragment),Ae=h(),q=n("p"),dt=p("Replace the model name with the variant you want to use, e.g. "),he=n("code"),gt=p("gluon_seresnext101_32x4d"),wt=p(". You can find the IDs in the model summaries at the top of this page."),Te=h(),N=n("p"),_t=p("To extract image features with this model, follow the "),se=n("a"),vt=p("timm feature extraction examples"),jt=p(", just change the name of the model you want to use."),Ie=h(),y=n("h2"),A=n("a"),ce=n("span"),u(D.$$.fragment),$t=h(),fe=n("span"),bt=p("How do I finetune this model?"),He=h(),ae=n("p"),yt=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),ze=h(),u(J.$$.fragment),Ce=h(),T=n("p"),xt=p("To finetune on your own dataset, you have to write a training loop or adapt "),O=n("a"),kt=p(`timm\u2019s training
script`),Et=p(" to use your dataset."),Ge=h(),x=n("h2"),I=n("a"),ue=n("span"),u(F.$$.fragment),St=h(),de=n("span"),Pt=p("How do I train this model?"),Re=h(),H=n("p"),qt=p("You can follow the "),ne=n("a"),Nt=p("timm recipe scripts"),At=p(" for training a new model afresh."),Le=h(),k=n("h2"),z=n("a"),ge=n("span"),u(V.$$.fragment),Tt=h(),we=n("span"),It=p("Citation"),Xe=h(),u(W.$$.fragment),this.h()},l(e){const a=cs('[data-svelte="svelte-1phssyn"]',document.head);j=o(a,"META",{name:!0,content:!0}),a.forEach(t),ve=c(e),$=o(e,"H1",{class:!0});var Me=l($);E=o(Me,"A",{id:!0,class:!0,href:!0});var zt=l(E);le=o(zt,"SPAN",{});var Ct=l(le);d(C.$$.fragment,Ct),Ct.forEach(t),zt.forEach(t),Qe=c(Me),re=o(Me,"SPAN",{});var Gt=l(re);Ze=m(Gt,"(Gluon) SE-ResNeXt"),Gt.forEach(t),Me.forEach(t),je=c(e),f=o(e,"P",{});var K=l(f);ie=o(K,"STRONG",{});var Rt=l(ie);et=m(Rt,"SE ResNeXt"),Rt.forEach(t),tt=m(K," is a variant of a "),G=o(K,"A",{href:!0,rel:!0});var Lt=l(G);st=m(Lt,"ResNext"),Lt.forEach(t),at=m(K," that employs "),R=o(K,"A",{href:!0,rel:!0});var Xt=l(R);nt=m(Xt,"squeeze-and-excitation blocks"),Xt.forEach(t),ot=m(K," to enable the network to perform dynamic channel-wise feature recalibration."),K.forEach(t),$e=c(e),S=o(e,"P",{});var Ue=l(S);lt=m(Ue,"The weights from this model were ported from "),L=o(Ue,"A",{href:!0,rel:!0});var Yt=l(L);rt=m(Yt,"Gluon"),Yt.forEach(t),it=m(Ue,"."),Ue.forEach(t),be=c(e),b=o(e,"H2",{class:!0});var Be=l(b);P=o(Be,"A",{id:!0,class:!0,href:!0});var Mt=l(P);pe=o(Mt,"SPAN",{});var Ut=l(pe);d(X.$$.fragment,Ut),Ut.forEach(t),Mt.forEach(t),pt=c(Be),me=o(Be,"SPAN",{});var Bt=l(me);mt=m(Bt,"How do I use this model on an image?"),Bt.forEach(t),Be.forEach(t),ye=c(e),Q=o(e,"P",{});var Dt=l(Q);ht=m(Dt,"To load a pretrained model:"),Dt.forEach(t),xe=c(e),d(Y.$$.fragment,e),ke=c(e),Z=o(e,"P",{});var Jt=l(Z);ct=m(Jt,"To load and preprocess the image:"),Jt.forEach(t),Ee=c(e),d(M.$$.fragment,e),Se=c(e),ee=o(e,"P",{});var Ot=l(ee);ft=m(Ot,"To get the model predictions:"),Ot.forEach(t),Pe=c(e),d(U.$$.fragment,e),qe=c(e),te=o(e,"P",{});var Ft=l(te);ut=m(Ft,"To get the top-5 predictions class names:"),Ft.forEach(t),Ne=c(e),d(B.$$.fragment,e),Ae=c(e),q=o(e,"P",{});var De=l(q);dt=m(De,"Replace the model name with the variant you want to use, e.g. "),he=o(De,"CODE",{});var Vt=l(he);gt=m(Vt,"gluon_seresnext101_32x4d"),Vt.forEach(t),wt=m(De,". You can find the IDs in the model summaries at the top of this page."),De.forEach(t),Te=c(e),N=o(e,"P",{});var Je=l(N);_t=m(Je,"To extract image features with this model, follow the "),se=o(Je,"A",{href:!0});var Wt=l(se);vt=m(Wt,"timm feature extraction examples"),Wt.forEach(t),jt=m(Je,", just change the name of the model you want to use."),Je.forEach(t),Ie=c(e),y=o(e,"H2",{class:!0});var Oe=l(y);A=o(Oe,"A",{id:!0,class:!0,href:!0});var Kt=l(A);ce=o(Kt,"SPAN",{});var Qt=l(ce);d(D.$$.fragment,Qt),Qt.forEach(t),Kt.forEach(t),$t=c(Oe),fe=o(Oe,"SPAN",{});var Zt=l(fe);bt=m(Zt,"How do I finetune this model?"),Zt.forEach(t),Oe.forEach(t),He=c(e),ae=o(e,"P",{});var es=l(ae);yt=m(es,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),es.forEach(t),ze=c(e),d(J.$$.fragment,e),Ce=c(e),T=o(e,"P",{});var Fe=l(T);xt=m(Fe,"To finetune on your own dataset, you have to write a training loop or adapt "),O=o(Fe,"A",{href:!0,rel:!0});var ts=l(O);kt=m(ts,`timm\u2019s training
script`),ts.forEach(t),Et=m(Fe," to use your dataset."),Fe.forEach(t),Ge=c(e),x=o(e,"H2",{class:!0});var Ve=l(x);I=o(Ve,"A",{id:!0,class:!0,href:!0});var ss=l(I);ue=o(ss,"SPAN",{});var as=l(ue);d(F.$$.fragment,as),as.forEach(t),ss.forEach(t),St=c(Ve),de=o(Ve,"SPAN",{});var ns=l(de);Pt=m(ns,"How do I train this model?"),ns.forEach(t),Ve.forEach(t),Re=c(e),H=o(e,"P",{});var We=l(H);qt=m(We,"You can follow the "),ne=o(We,"A",{href:!0});var os=l(ne);Nt=m(os,"timm recipe scripts"),os.forEach(t),At=m(We," for training a new model afresh."),We.forEach(t),Le=c(e),k=o(e,"H2",{class:!0});var Ke=l(k);z=o(Ke,"A",{id:!0,class:!0,href:!0});var ls=l(z);ge=o(ls,"SPAN",{});var rs=l(ge);d(V.$$.fragment,rs),rs.forEach(t),ls.forEach(t),Tt=c(Ke),we=o(Ke,"SPAN",{});var is=l(we);It=m(is,"Citation"),is.forEach(t),Ke.forEach(t),Xe=c(e),d(W.$$.fragment,e),this.h()},h(){i(j,"name","hf:doc:metadata"),i(j,"content",JSON.stringify(gs)),i(E,"id","gluon-seresnext"),i(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(E,"href","#gluon-seresnext"),i($,"class","relative group"),i(G,"href","https://www.paperswithcode.com/method/resnext"),i(G,"rel","nofollow"),i(R,"href","https://paperswithcode.com/method/squeeze-and-excitation-block"),i(R,"rel","nofollow"),i(L,"href","https://cv.gluon.ai/model_zoo/classification.html"),i(L,"rel","nofollow"),i(P,"id","how-do-i-use-this-model-on-an-image"),i(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(P,"href","#how-do-i-use-this-model-on-an-image"),i(b,"class","relative group"),i(se,"href","../feature_extraction"),i(A,"id","how-do-i-finetune-this-model"),i(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(A,"href","#how-do-i-finetune-this-model"),i(y,"class","relative group"),i(O,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(O,"rel","nofollow"),i(I,"id","how-do-i-train-this-model"),i(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(I,"href","#how-do-i-train-this-model"),i(x,"class","relative group"),i(ne,"href","../scripts"),i(z,"id","citation"),i(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(z,"href","#citation"),i(k,"class","relative group")},m(e,a){s(document.head,j),r(e,ve,a),r(e,$,a),s($,E),s(E,le),g(C,le,null),s($,Qe),s($,re),s(re,Ze),r(e,je,a),r(e,f,a),s(f,ie),s(ie,et),s(f,tt),s(f,G),s(G,st),s(f,at),s(f,R),s(R,nt),s(f,ot),r(e,$e,a),r(e,S,a),s(S,lt),s(S,L),s(L,rt),s(S,it),r(e,be,a),r(e,b,a),s(b,P),s(P,pe),g(X,pe,null),s(b,pt),s(b,me),s(me,mt),r(e,ye,a),r(e,Q,a),s(Q,ht),r(e,xe,a),g(Y,e,a),r(e,ke,a),r(e,Z,a),s(Z,ct),r(e,Ee,a),g(M,e,a),r(e,Se,a),r(e,ee,a),s(ee,ft),r(e,Pe,a),g(U,e,a),r(e,qe,a),r(e,te,a),s(te,ut),r(e,Ne,a),g(B,e,a),r(e,Ae,a),r(e,q,a),s(q,dt),s(q,he),s(he,gt),s(q,wt),r(e,Te,a),r(e,N,a),s(N,_t),s(N,se),s(se,vt),s(N,jt),r(e,Ie,a),r(e,y,a),s(y,A),s(A,ce),g(D,ce,null),s(y,$t),s(y,fe),s(fe,bt),r(e,He,a),r(e,ae,a),s(ae,yt),r(e,ze,a),g(J,e,a),r(e,Ce,a),r(e,T,a),s(T,xt),s(T,O),s(O,kt),s(T,Et),r(e,Ge,a),r(e,x,a),s(x,I),s(I,ue),g(F,ue,null),s(x,St),s(x,de),s(de,Pt),r(e,Re,a),r(e,H,a),s(H,qt),s(H,ne),s(ne,Nt),s(H,At),r(e,Le,a),r(e,k,a),s(k,z),s(z,ge),g(V,ge,null),s(k,Tt),s(k,we),s(we,It),r(e,Xe,a),g(W,e,a),Ye=!0},p:fs,i(e){Ye||(w(C.$$.fragment,e),w(X.$$.fragment,e),w(Y.$$.fragment,e),w(M.$$.fragment,e),w(U.$$.fragment,e),w(B.$$.fragment,e),w(D.$$.fragment,e),w(J.$$.fragment,e),w(F.$$.fragment,e),w(V.$$.fragment,e),w(W.$$.fragment,e),Ye=!0)},o(e){_(C.$$.fragment,e),_(X.$$.fragment,e),_(Y.$$.fragment,e),_(M.$$.fragment,e),_(U.$$.fragment,e),_(B.$$.fragment,e),_(D.$$.fragment,e),_(J.$$.fragment,e),_(F.$$.fragment,e),_(V.$$.fragment,e),_(W.$$.fragment,e),Ye=!1},d(e){t(j),e&&t(ve),e&&t($),v(C),e&&t(je),e&&t(f),e&&t($e),e&&t(S),e&&t(be),e&&t(b),v(X),e&&t(ye),e&&t(Q),e&&t(xe),v(Y,e),e&&t(ke),e&&t(Z),e&&t(Ee),v(M,e),e&&t(Se),e&&t(ee),e&&t(Pe),v(U,e),e&&t(qe),e&&t(te),e&&t(Ne),v(B,e),e&&t(Ae),e&&t(q),e&&t(Te),e&&t(N),e&&t(Ie),e&&t(y),v(D),e&&t(He),e&&t(ae),e&&t(ze),v(J,e),e&&t(Ce),e&&t(T),e&&t(Ge),e&&t(x),v(F),e&&t(Re),e&&t(H),e&&t(Le),e&&t(k),v(V),e&&t(Xe),v(W,e)}}}const gs={local:"gluon-seresnext",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"(Gluon) SE-ResNeXt"};function ws(Ht){return us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $s extends ps{constructor(j){super();ms(this,j,ws,ds,hs,{})}}export{$s as default,gs as metadata};
