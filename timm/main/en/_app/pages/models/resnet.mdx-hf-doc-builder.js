import{S as st,i as tt,s as at,e as n,k as h,w as u,t as i,M as nt,c as r,d as s,m as c,a as l,x as g,h as p,b as m,G as t,g as o,y as d,L as rt,q as w,o as b,B as j,v as lt}from"../../chunks/vendor-hf-doc-builder.js";import{I as de}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as te}from"../../chunks/CodeBlock-hf-doc-builder.js";function ot(Ss){let v,we,_,E,ae,H,Je,ne,Fe,be,f,re,Ke,We,le,Qe,Ve,C,es,ss,je,$,S,oe,L,ts,ie,as,ve,F,ns,_e,D,$e,K,rs,ye,G,ke,W,ls,xe,z,Ee,Q,os,Se,B,Pe,P,is,pe,ps,ms,Re,R,hs,V,cs,fs,Ne,y,N,me,Y,us,he,gs,Ie,ee,ds,Ae,Z,qe,I,ws,M,bs,js,Te,k,A,ce,U,vs,fe,_s,He,q,$s,se,ys,ks,Ce,x,T,ue,O,xs,ge,Es,Le,X,De;return H=new de({}),L=new de({}),D=new te({props:{code:`import timm
model = timm.create_model('resnet18', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;resnet18&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),G=new te({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),z=new te({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),B=new te({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),Y=new de({}),Z=new te({props:{code:"model = timm.create_model('resnet18', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;resnet18&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),U=new de({}),O=new de({}),X=new te({props:{code:`@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}`,highlighted:`@article{DBLP:journals<span class="hljs-regexp">/corr/</span>HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning <span class="hljs-keyword">for</span> Image Recognition},
  journal   = {CoRR},
  volume    = {abs/<span class="hljs-number">1512.03385</span>},
  year      = {<span class="hljs-number">2015</span>},
  url       = {http:<span class="hljs-regexp">//</span>arxiv.org<span class="hljs-regexp">/abs/</span><span class="hljs-number">1512.03385</span>},
  archivePrefix = {arXiv},
  eprint    = {<span class="hljs-number">1512.03385</span>},
  timestamp = {Wed, <span class="hljs-number">17</span> Apr <span class="hljs-number">2019</span> <span class="hljs-number">17</span>:<span class="hljs-number">23</span>:<span class="hljs-number">45</span> +<span class="hljs-number">0200</span>},
  biburl    = {https:<span class="hljs-regexp">//</span>dblp.org<span class="hljs-regexp">/rec/</span>journals<span class="hljs-regexp">/corr/</span>HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https:<span class="hljs-regexp">//</span>dblp.org}
}`}}),{c(){v=n("meta"),we=h(),_=n("h1"),E=n("a"),ae=n("span"),u(H.$$.fragment),Je=h(),ne=n("span"),Fe=i("ResNet"),be=h(),f=n("p"),re=n("strong"),Ke=i("Residual Networks"),We=i(", or "),le=n("strong"),Qe=i("ResNets"),Ve=i(", learn residual functions with reference to the layer inputs, instead of learning unreferenced functions. Instead of hoping each few stacked layers directly fit a desired underlying mapping, residual nets let these layers fit a residual mapping. They stack "),C=n("a"),es=i("residual blocks"),ss=i(" ontop of each other to form network: e.g. a ResNet-50 has fifty layers using these blocks."),je=h(),$=n("h2"),S=n("a"),oe=n("span"),u(L.$$.fragment),ts=h(),ie=n("span"),as=i("How do I use this model on an image?"),ve=h(),F=n("p"),ns=i("To load a pretrained model:"),_e=h(),u(D.$$.fragment),$e=h(),K=n("p"),rs=i("To load and preprocess the image:"),ye=h(),u(G.$$.fragment),ke=h(),W=n("p"),ls=i("To get the model predictions:"),xe=h(),u(z.$$.fragment),Ee=h(),Q=n("p"),os=i("To get the top-5 predictions class names:"),Se=h(),u(B.$$.fragment),Pe=h(),P=n("p"),is=i("Replace the model name with the variant you want to use, e.g. "),pe=n("code"),ps=i("resnet18"),ms=i(". You can find the IDs in the model summaries at the top of this page."),Re=h(),R=n("p"),hs=i("To extract image features with this model, follow the "),V=n("a"),cs=i("timm feature extraction examples"),fs=i(", just change the name of the model you want to use."),Ne=h(),y=n("h2"),N=n("a"),me=n("span"),u(Y.$$.fragment),us=h(),he=n("span"),gs=i("How do I finetune this model?"),Ie=h(),ee=n("p"),ds=i("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ae=h(),u(Z.$$.fragment),qe=h(),I=n("p"),ws=i("To finetune on your own dataset, you have to write a training loop or adapt "),M=n("a"),bs=i(`timm\u2019s training
script`),js=i(" to use your dataset."),Te=h(),k=n("h2"),A=n("a"),ce=n("span"),u(U.$$.fragment),vs=h(),fe=n("span"),_s=i("How do I train this model?"),He=h(),q=n("p"),$s=i("You can follow the "),se=n("a"),ys=i("timm recipe scripts"),ks=i(" for training a new model afresh."),Ce=h(),x=n("h2"),T=n("a"),ue=n("span"),u(O.$$.fragment),xs=h(),ge=n("span"),Es=i("Citation"),Le=h(),u(X.$$.fragment),this.h()},l(e){const a=nt('[data-svelte="svelte-1phssyn"]',document.head);v=r(a,"META",{name:!0,content:!0}),a.forEach(s),we=c(e),_=r(e,"H1",{class:!0});var Ge=l(_);E=r(Ge,"A",{id:!0,class:!0,href:!0});var Ps=l(E);ae=r(Ps,"SPAN",{});var Rs=l(ae);g(H.$$.fragment,Rs),Rs.forEach(s),Ps.forEach(s),Je=c(Ge),ne=r(Ge,"SPAN",{});var Ns=l(ne);Fe=p(Ns,"ResNet"),Ns.forEach(s),Ge.forEach(s),be=c(e),f=r(e,"P",{});var J=l(f);re=r(J,"STRONG",{});var Is=l(re);Ke=p(Is,"Residual Networks"),Is.forEach(s),We=p(J,", or "),le=r(J,"STRONG",{});var As=l(le);Qe=p(As,"ResNets"),As.forEach(s),Ve=p(J,", learn residual functions with reference to the layer inputs, instead of learning unreferenced functions. Instead of hoping each few stacked layers directly fit a desired underlying mapping, residual nets let these layers fit a residual mapping. They stack "),C=r(J,"A",{href:!0,rel:!0});var qs=l(C);es=p(qs,"residual blocks"),qs.forEach(s),ss=p(J," ontop of each other to form network: e.g. a ResNet-50 has fifty layers using these blocks."),J.forEach(s),je=c(e),$=r(e,"H2",{class:!0});var ze=l($);S=r(ze,"A",{id:!0,class:!0,href:!0});var Ts=l(S);oe=r(Ts,"SPAN",{});var Hs=l(oe);g(L.$$.fragment,Hs),Hs.forEach(s),Ts.forEach(s),ts=c(ze),ie=r(ze,"SPAN",{});var Cs=l(ie);as=p(Cs,"How do I use this model on an image?"),Cs.forEach(s),ze.forEach(s),ve=c(e),F=r(e,"P",{});var Ls=l(F);ns=p(Ls,"To load a pretrained model:"),Ls.forEach(s),_e=c(e),g(D.$$.fragment,e),$e=c(e),K=r(e,"P",{});var Ds=l(K);rs=p(Ds,"To load and preprocess the image:"),Ds.forEach(s),ye=c(e),g(G.$$.fragment,e),ke=c(e),W=r(e,"P",{});var Gs=l(W);ls=p(Gs,"To get the model predictions:"),Gs.forEach(s),xe=c(e),g(z.$$.fragment,e),Ee=c(e),Q=r(e,"P",{});var zs=l(Q);os=p(zs,"To get the top-5 predictions class names:"),zs.forEach(s),Se=c(e),g(B.$$.fragment,e),Pe=c(e),P=r(e,"P",{});var Be=l(P);is=p(Be,"Replace the model name with the variant you want to use, e.g. "),pe=r(Be,"CODE",{});var Bs=l(pe);ps=p(Bs,"resnet18"),Bs.forEach(s),ms=p(Be,". You can find the IDs in the model summaries at the top of this page."),Be.forEach(s),Re=c(e),R=r(e,"P",{});var Ye=l(R);hs=p(Ye,"To extract image features with this model, follow the "),V=r(Ye,"A",{href:!0});var Ys=l(V);cs=p(Ys,"timm feature extraction examples"),Ys.forEach(s),fs=p(Ye,", just change the name of the model you want to use."),Ye.forEach(s),Ne=c(e),y=r(e,"H2",{class:!0});var Ze=l(y);N=r(Ze,"A",{id:!0,class:!0,href:!0});var Zs=l(N);me=r(Zs,"SPAN",{});var Ms=l(me);g(Y.$$.fragment,Ms),Ms.forEach(s),Zs.forEach(s),us=c(Ze),he=r(Ze,"SPAN",{});var Us=l(he);gs=p(Us,"How do I finetune this model?"),Us.forEach(s),Ze.forEach(s),Ie=c(e),ee=r(e,"P",{});var Os=l(ee);ds=p(Os,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Os.forEach(s),Ae=c(e),g(Z.$$.fragment,e),qe=c(e),I=r(e,"P",{});var Me=l(I);ws=p(Me,"To finetune on your own dataset, you have to write a training loop or adapt "),M=r(Me,"A",{href:!0,rel:!0});var Xs=l(M);bs=p(Xs,`timm\u2019s training
script`),Xs.forEach(s),js=p(Me," to use your dataset."),Me.forEach(s),Te=c(e),k=r(e,"H2",{class:!0});var Ue=l(k);A=r(Ue,"A",{id:!0,class:!0,href:!0});var Js=l(A);ce=r(Js,"SPAN",{});var Fs=l(ce);g(U.$$.fragment,Fs),Fs.forEach(s),Js.forEach(s),vs=c(Ue),fe=r(Ue,"SPAN",{});var Ks=l(fe);_s=p(Ks,"How do I train this model?"),Ks.forEach(s),Ue.forEach(s),He=c(e),q=r(e,"P",{});var Oe=l(q);$s=p(Oe,"You can follow the "),se=r(Oe,"A",{href:!0});var Ws=l(se);ys=p(Ws,"timm recipe scripts"),Ws.forEach(s),ks=p(Oe," for training a new model afresh."),Oe.forEach(s),Ce=c(e),x=r(e,"H2",{class:!0});var Xe=l(x);T=r(Xe,"A",{id:!0,class:!0,href:!0});var Qs=l(T);ue=r(Qs,"SPAN",{});var Vs=l(ue);g(O.$$.fragment,Vs),Vs.forEach(s),Qs.forEach(s),xs=c(Xe),ge=r(Xe,"SPAN",{});var et=l(ge);Es=p(et,"Citation"),et.forEach(s),Xe.forEach(s),Le=c(e),g(X.$$.fragment,e),this.h()},h(){m(v,"name","hf:doc:metadata"),m(v,"content",JSON.stringify(it)),m(E,"id","resnet"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#resnet"),m(_,"class","relative group"),m(C,"href","https://paperswithcode.com/method/residual-block"),m(C,"rel","nofollow"),m(S,"id","how-do-i-use-this-model-on-an-image"),m(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S,"href","#how-do-i-use-this-model-on-an-image"),m($,"class","relative group"),m(V,"href","../feature_extraction"),m(N,"id","how-do-i-finetune-this-model"),m(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N,"href","#how-do-i-finetune-this-model"),m(y,"class","relative group"),m(M,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),m(M,"rel","nofollow"),m(A,"id","how-do-i-train-this-model"),m(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(A,"href","#how-do-i-train-this-model"),m(k,"class","relative group"),m(se,"href","../scripts"),m(T,"id","citation"),m(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(T,"href","#citation"),m(x,"class","relative group")},m(e,a){t(document.head,v),o(e,we,a),o(e,_,a),t(_,E),t(E,ae),d(H,ae,null),t(_,Je),t(_,ne),t(ne,Fe),o(e,be,a),o(e,f,a),t(f,re),t(re,Ke),t(f,We),t(f,le),t(le,Qe),t(f,Ve),t(f,C),t(C,es),t(f,ss),o(e,je,a),o(e,$,a),t($,S),t(S,oe),d(L,oe,null),t($,ts),t($,ie),t(ie,as),o(e,ve,a),o(e,F,a),t(F,ns),o(e,_e,a),d(D,e,a),o(e,$e,a),o(e,K,a),t(K,rs),o(e,ye,a),d(G,e,a),o(e,ke,a),o(e,W,a),t(W,ls),o(e,xe,a),d(z,e,a),o(e,Ee,a),o(e,Q,a),t(Q,os),o(e,Se,a),d(B,e,a),o(e,Pe,a),o(e,P,a),t(P,is),t(P,pe),t(pe,ps),t(P,ms),o(e,Re,a),o(e,R,a),t(R,hs),t(R,V),t(V,cs),t(R,fs),o(e,Ne,a),o(e,y,a),t(y,N),t(N,me),d(Y,me,null),t(y,us),t(y,he),t(he,gs),o(e,Ie,a),o(e,ee,a),t(ee,ds),o(e,Ae,a),d(Z,e,a),o(e,qe,a),o(e,I,a),t(I,ws),t(I,M),t(M,bs),t(I,js),o(e,Te,a),o(e,k,a),t(k,A),t(A,ce),d(U,ce,null),t(k,vs),t(k,fe),t(fe,_s),o(e,He,a),o(e,q,a),t(q,$s),t(q,se),t(se,ys),t(q,ks),o(e,Ce,a),o(e,x,a),t(x,T),t(T,ue),d(O,ue,null),t(x,xs),t(x,ge),t(ge,Es),o(e,Le,a),d(X,e,a),De=!0},p:rt,i(e){De||(w(H.$$.fragment,e),w(L.$$.fragment,e),w(D.$$.fragment,e),w(G.$$.fragment,e),w(z.$$.fragment,e),w(B.$$.fragment,e),w(Y.$$.fragment,e),w(Z.$$.fragment,e),w(U.$$.fragment,e),w(O.$$.fragment,e),w(X.$$.fragment,e),De=!0)},o(e){b(H.$$.fragment,e),b(L.$$.fragment,e),b(D.$$.fragment,e),b(G.$$.fragment,e),b(z.$$.fragment,e),b(B.$$.fragment,e),b(Y.$$.fragment,e),b(Z.$$.fragment,e),b(U.$$.fragment,e),b(O.$$.fragment,e),b(X.$$.fragment,e),De=!1},d(e){s(v),e&&s(we),e&&s(_),j(H),e&&s(be),e&&s(f),e&&s(je),e&&s($),j(L),e&&s(ve),e&&s(F),e&&s(_e),j(D,e),e&&s($e),e&&s(K),e&&s(ye),j(G,e),e&&s(ke),e&&s(W),e&&s(xe),j(z,e),e&&s(Ee),e&&s(Q),e&&s(Se),j(B,e),e&&s(Pe),e&&s(P),e&&s(Re),e&&s(R),e&&s(Ne),e&&s(y),j(Y),e&&s(Ie),e&&s(ee),e&&s(Ae),j(Z,e),e&&s(qe),e&&s(I),e&&s(Te),e&&s(k),j(U),e&&s(He),e&&s(q),e&&s(Ce),e&&s(x),j(O),e&&s(Le),j(X,e)}}}const it={local:"resnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"ResNet"};function pt(Ss){return lt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ft extends st{constructor(v){super();tt(this,v,pt,ot,at,{})}}export{ft as default,it as metadata};
