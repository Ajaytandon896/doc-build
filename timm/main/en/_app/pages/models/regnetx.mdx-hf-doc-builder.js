import{S as te,i as ne,s as le,e as n,k as o,w as g,t as p,T as re,M as ie,c as l,d as a,m,a as i,x as f,h,U as oe,b as c,G as e,g as r,y as d,L as pe,q as u,o as w,B as _,v as me}from"../../chunks/vendor-hf-doc-builder.js";import{I as ds}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as as}from"../../chunks/CodeBlock-hf-doc-builder.js";function he(Sa){let v,us,$,x,es,C,Qs,ts,Ws,ws,E,ns,Zs,sa,_s,ee='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>u</mi><mi mathvariant="normal">_</mi><mi>j</mi><mo>=</mo><mi>w</mi><mi mathvariant="normal">_</mi><mn>0</mn><mo>+</mo><mi>w</mi><mi mathvariant="normal">_</mi><mi>a</mi><mo>\u22C5</mo><mi>j</mi></mrow><annotation encoding="application/x-tex"> u\\_{j} = w\\_{0} + w\\_{a}\\cdot{j} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695em;vertical-align:-0.31em;"></span><span class="mord mathnormal">u</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9544em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">0</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7545em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathnormal">a</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">\u22C5</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span></span></span>',vs,P,aa,ls,ea,ta,$s,j,N,rs,D,na,is,la,js,O,ra,ys,G,bs,V,ia,ks,X,xs,J,oa,Es,L,Ps,Q,pa,Ns,M,Ss,S,ma,os,ha,ca,qs,q,ga,W,fa,da,Ts,y,T,ps,z,ua,ms,wa,Is,Z,_a,Rs,U,As,I,va,Y,$a,ja,Hs,b,R,hs,B,ya,cs,ba,Cs,A,ka,ss,xa,Ea,Ds,k,H,gs,F,Pa,fs,Na,Gs,K,Xs;return C=new ds({}),D=new ds({}),G=new as({props:{code:`import timm
model = timm.create_model('regnetx_002', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;regnetx_002&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),X=new as({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),L=new as({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),M=new as({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),z=new ds({}),U=new as({props:{code:"model = timm.create_model('regnetx_002', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;regnetx_002&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),B=new ds({}),F=new ds({}),K=new as({props:{code:`@misc{radosavovic2020designing,
      title={Designing Network Design Spaces}, 
      author={Ilija Radosavovic and Raj Prateek Kosaraju and Ross Girshick and Kaiming He and Piotr Doll\xE1r},
      year={2020},
      eprint={2003.13678},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`<span class="language-xml">@misc</span><span class="hljs-template-variable">{radosavovic2020designing,
      title={Designing Network Design Spaces}</span><span class="language-xml">, 
      author=</span><span class="hljs-template-variable">{Ilija Radosavovic and Raj Prateek Kosaraju and Ross Girshick and Kaiming He and Piotr Doll\xE1r}</span><span class="language-xml">,
      year=</span><span class="hljs-template-variable">{2020}</span><span class="language-xml">,
      eprint=</span><span class="hljs-template-variable">{2003.13678}</span><span class="language-xml">,
      archivePrefix=</span><span class="hljs-template-variable">{arXiv}</span><span class="language-xml">,
      primaryClass=</span><span class="hljs-template-variable">{cs.CV}</span><span class="language-xml">
}</span>`}}),{c(){v=n("meta"),us=o(),$=n("h1"),x=n("a"),es=n("span"),g(C.$$.fragment),Qs=o(),ts=n("span"),Ws=p("RegNetX"),ws=o(),E=n("p"),ns=n("strong"),Zs=p("RegNetX"),sa=p(` is a convolutional network design space with simple, regular models with parameters: depth $d$, initial width $w_{0} > 0$, and slope $w_{a} > 0$, and generates a different block width $u_{j}$ for each block $j < d$. The key restriction for the RegNet types of model is that there is a linear parameterisation of block widths (the design space only contains models with this linear structure):
`),_s=new re,vs=o(),P=n("p"),aa=p("For "),ls=n("strong"),ea=p("RegNetX"),ta=p(" we have additional restrictions: we set $b = 1$ (the bottleneck ratio), $12 \\leq d \\leq 28$, and $w_{m} \\geq 2$ (the width multiplier)."),$s=o(),j=n("h2"),N=n("a"),rs=n("span"),g(D.$$.fragment),na=o(),is=n("span"),la=p("How do I use this model on an image?"),js=o(),O=n("p"),ra=p("To load a pretrained model:"),ys=o(),g(G.$$.fragment),bs=o(),V=n("p"),ia=p("To load and preprocess the image:"),ks=o(),g(X.$$.fragment),xs=o(),J=n("p"),oa=p("To get the model predictions:"),Es=o(),g(L.$$.fragment),Ps=o(),Q=n("p"),pa=p("To get the top-5 predictions class names:"),Ns=o(),g(M.$$.fragment),Ss=o(),S=n("p"),ma=p("Replace the model name with the variant you want to use, e.g. "),os=n("code"),ha=p("regnetx_002"),ca=p(". You can find the IDs in the model summaries at the top of this page."),qs=o(),q=n("p"),ga=p("To extract image features with this model, follow the "),W=n("a"),fa=p("timm feature extraction examples"),da=p(", just change the name of the model you want to use."),Ts=o(),y=n("h2"),T=n("a"),ps=n("span"),g(z.$$.fragment),ua=o(),ms=n("span"),wa=p("How do I finetune this model?"),Is=o(),Z=n("p"),_a=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Rs=o(),g(U.$$.fragment),As=o(),I=n("p"),va=p("To finetune on your own dataset, you have to write a training loop or adapt "),Y=n("a"),$a=p(`timm\u2019s training
script`),ja=p(" to use your dataset."),Hs=o(),b=n("h2"),R=n("a"),hs=n("span"),g(B.$$.fragment),ya=o(),cs=n("span"),ba=p("How do I train this model?"),Cs=o(),A=n("p"),ka=p("You can follow the "),ss=n("a"),xa=p("timm recipe scripts"),Ea=p(" for training a new model afresh."),Ds=o(),k=n("h2"),H=n("a"),gs=n("span"),g(F.$$.fragment),Pa=o(),fs=n("span"),Na=p("Citation"),Gs=o(),g(K.$$.fragment),this.h()},l(s){const t=ie('[data-svelte="svelte-1phssyn"]',document.head);v=l(t,"META",{name:!0,content:!0}),t.forEach(a),us=m(s),$=l(s,"H1",{class:!0});var Ls=i($);x=l(Ls,"A",{id:!0,class:!0,href:!0});var qa=i(x);es=l(qa,"SPAN",{});var Ta=i(es);f(C.$$.fragment,Ta),Ta.forEach(a),qa.forEach(a),Qs=m(Ls),ts=l(Ls,"SPAN",{});var Ia=i(ts);Ws=h(Ia,"RegNetX"),Ia.forEach(a),Ls.forEach(a),ws=m(s),E=l(s,"P",{});var Ms=i(E);ns=l(Ms,"STRONG",{});var Ra=i(ns);Zs=h(Ra,"RegNetX"),Ra.forEach(a),sa=h(Ms,` is a convolutional network design space with simple, regular models with parameters: depth $d$, initial width $w_{0} > 0$, and slope $w_{a} > 0$, and generates a different block width $u_{j}$ for each block $j < d$. The key restriction for the RegNet types of model is that there is a linear parameterisation of block widths (the design space only contains models with this linear structure):
`),_s=oe(Ms),Ms.forEach(a),vs=m(s),P=l(s,"P",{});var zs=i(P);aa=h(zs,"For "),ls=l(zs,"STRONG",{});var Aa=i(ls);ea=h(Aa,"RegNetX"),Aa.forEach(a),ta=h(zs," we have additional restrictions: we set $b = 1$ (the bottleneck ratio), $12 \\leq d \\leq 28$, and $w_{m} \\geq 2$ (the width multiplier)."),zs.forEach(a),$s=m(s),j=l(s,"H2",{class:!0});var Us=i(j);N=l(Us,"A",{id:!0,class:!0,href:!0});var Ha=i(N);rs=l(Ha,"SPAN",{});var Ca=i(rs);f(D.$$.fragment,Ca),Ca.forEach(a),Ha.forEach(a),na=m(Us),is=l(Us,"SPAN",{});var Da=i(is);la=h(Da,"How do I use this model on an image?"),Da.forEach(a),Us.forEach(a),js=m(s),O=l(s,"P",{});var Ga=i(O);ra=h(Ga,"To load a pretrained model:"),Ga.forEach(a),ys=m(s),f(G.$$.fragment,s),bs=m(s),V=l(s,"P",{});var Xa=i(V);ia=h(Xa,"To load and preprocess the image:"),Xa.forEach(a),ks=m(s),f(X.$$.fragment,s),xs=m(s),J=l(s,"P",{});var La=i(J);oa=h(La,"To get the model predictions:"),La.forEach(a),Es=m(s),f(L.$$.fragment,s),Ps=m(s),Q=l(s,"P",{});var Ma=i(Q);pa=h(Ma,"To get the top-5 predictions class names:"),Ma.forEach(a),Ns=m(s),f(M.$$.fragment,s),Ss=m(s),S=l(s,"P",{});var Ys=i(S);ma=h(Ys,"Replace the model name with the variant you want to use, e.g. "),os=l(Ys,"CODE",{});var za=i(os);ha=h(za,"regnetx_002"),za.forEach(a),ca=h(Ys,". You can find the IDs in the model summaries at the top of this page."),Ys.forEach(a),qs=m(s),q=l(s,"P",{});var Bs=i(q);ga=h(Bs,"To extract image features with this model, follow the "),W=l(Bs,"A",{href:!0});var Ua=i(W);fa=h(Ua,"timm feature extraction examples"),Ua.forEach(a),da=h(Bs,", just change the name of the model you want to use."),Bs.forEach(a),Ts=m(s),y=l(s,"H2",{class:!0});var Fs=i(y);T=l(Fs,"A",{id:!0,class:!0,href:!0});var Ya=i(T);ps=l(Ya,"SPAN",{});var Ba=i(ps);f(z.$$.fragment,Ba),Ba.forEach(a),Ya.forEach(a),ua=m(Fs),ms=l(Fs,"SPAN",{});var Fa=i(ms);wa=h(Fa,"How do I finetune this model?"),Fa.forEach(a),Fs.forEach(a),Is=m(s),Z=l(s,"P",{});var Ka=i(Z);_a=h(Ka,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ka.forEach(a),Rs=m(s),f(U.$$.fragment,s),As=m(s),I=l(s,"P",{});var Ks=i(I);va=h(Ks,"To finetune on your own dataset, you have to write a training loop or adapt "),Y=l(Ks,"A",{href:!0,rel:!0});var Oa=i(Y);$a=h(Oa,`timm\u2019s training
script`),Oa.forEach(a),ja=h(Ks," to use your dataset."),Ks.forEach(a),Hs=m(s),b=l(s,"H2",{class:!0});var Os=i(b);R=l(Os,"A",{id:!0,class:!0,href:!0});var Va=i(R);hs=l(Va,"SPAN",{});var Ja=i(hs);f(B.$$.fragment,Ja),Ja.forEach(a),Va.forEach(a),ya=m(Os),cs=l(Os,"SPAN",{});var Qa=i(cs);ba=h(Qa,"How do I train this model?"),Qa.forEach(a),Os.forEach(a),Cs=m(s),A=l(s,"P",{});var Vs=i(A);ka=h(Vs,"You can follow the "),ss=l(Vs,"A",{href:!0});var Wa=i(ss);xa=h(Wa,"timm recipe scripts"),Wa.forEach(a),Ea=h(Vs," for training a new model afresh."),Vs.forEach(a),Ds=m(s),k=l(s,"H2",{class:!0});var Js=i(k);H=l(Js,"A",{id:!0,class:!0,href:!0});var Za=i(H);gs=l(Za,"SPAN",{});var se=i(gs);f(F.$$.fragment,se),se.forEach(a),Za.forEach(a),Pa=m(Js),fs=l(Js,"SPAN",{});var ae=i(fs);Na=h(ae,"Citation"),ae.forEach(a),Js.forEach(a),Gs=m(s),f(K.$$.fragment,s),this.h()},h(){c(v,"name","hf:doc:metadata"),c(v,"content",JSON.stringify(ce)),c(x,"id","regnetx"),c(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x,"href","#regnetx"),c($,"class","relative group"),_s.a=null,c(N,"id","how-do-i-use-this-model-on-an-image"),c(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N,"href","#how-do-i-use-this-model-on-an-image"),c(j,"class","relative group"),c(W,"href","../feature_extraction"),c(T,"id","how-do-i-finetune-this-model"),c(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T,"href","#how-do-i-finetune-this-model"),c(y,"class","relative group"),c(Y,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),c(Y,"rel","nofollow"),c(R,"id","how-do-i-train-this-model"),c(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R,"href","#how-do-i-train-this-model"),c(b,"class","relative group"),c(ss,"href","../scripts"),c(H,"id","citation"),c(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H,"href","#citation"),c(k,"class","relative group")},m(s,t){e(document.head,v),r(s,us,t),r(s,$,t),e($,x),e(x,es),d(C,es,null),e($,Qs),e($,ts),e(ts,Ws),r(s,ws,t),r(s,E,t),e(E,ns),e(ns,Zs),e(E,sa),_s.m(ee,E),r(s,vs,t),r(s,P,t),e(P,aa),e(P,ls),e(ls,ea),e(P,ta),r(s,$s,t),r(s,j,t),e(j,N),e(N,rs),d(D,rs,null),e(j,na),e(j,is),e(is,la),r(s,js,t),r(s,O,t),e(O,ra),r(s,ys,t),d(G,s,t),r(s,bs,t),r(s,V,t),e(V,ia),r(s,ks,t),d(X,s,t),r(s,xs,t),r(s,J,t),e(J,oa),r(s,Es,t),d(L,s,t),r(s,Ps,t),r(s,Q,t),e(Q,pa),r(s,Ns,t),d(M,s,t),r(s,Ss,t),r(s,S,t),e(S,ma),e(S,os),e(os,ha),e(S,ca),r(s,qs,t),r(s,q,t),e(q,ga),e(q,W),e(W,fa),e(q,da),r(s,Ts,t),r(s,y,t),e(y,T),e(T,ps),d(z,ps,null),e(y,ua),e(y,ms),e(ms,wa),r(s,Is,t),r(s,Z,t),e(Z,_a),r(s,Rs,t),d(U,s,t),r(s,As,t),r(s,I,t),e(I,va),e(I,Y),e(Y,$a),e(I,ja),r(s,Hs,t),r(s,b,t),e(b,R),e(R,hs),d(B,hs,null),e(b,ya),e(b,cs),e(cs,ba),r(s,Cs,t),r(s,A,t),e(A,ka),e(A,ss),e(ss,xa),e(A,Ea),r(s,Ds,t),r(s,k,t),e(k,H),e(H,gs),d(F,gs,null),e(k,Pa),e(k,fs),e(fs,Na),r(s,Gs,t),d(K,s,t),Xs=!0},p:pe,i(s){Xs||(u(C.$$.fragment,s),u(D.$$.fragment,s),u(G.$$.fragment,s),u(X.$$.fragment,s),u(L.$$.fragment,s),u(M.$$.fragment,s),u(z.$$.fragment,s),u(U.$$.fragment,s),u(B.$$.fragment,s),u(F.$$.fragment,s),u(K.$$.fragment,s),Xs=!0)},o(s){w(C.$$.fragment,s),w(D.$$.fragment,s),w(G.$$.fragment,s),w(X.$$.fragment,s),w(L.$$.fragment,s),w(M.$$.fragment,s),w(z.$$.fragment,s),w(U.$$.fragment,s),w(B.$$.fragment,s),w(F.$$.fragment,s),w(K.$$.fragment,s),Xs=!1},d(s){a(v),s&&a(us),s&&a($),_(C),s&&a(ws),s&&a(E),s&&a(vs),s&&a(P),s&&a($s),s&&a(j),_(D),s&&a(js),s&&a(O),s&&a(ys),_(G,s),s&&a(bs),s&&a(V),s&&a(ks),_(X,s),s&&a(xs),s&&a(J),s&&a(Es),_(L,s),s&&a(Ps),s&&a(Q),s&&a(Ns),_(M,s),s&&a(Ss),s&&a(S),s&&a(qs),s&&a(q),s&&a(Ts),s&&a(y),_(z),s&&a(Is),s&&a(Z),s&&a(Rs),_(U,s),s&&a(As),s&&a(I),s&&a(Hs),s&&a(b),_(B),s&&a(Cs),s&&a(A),s&&a(Ds),s&&a(k),_(F),s&&a(Gs),_(K,s)}}}const ce={local:"regnetx",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"RegNetX"};function ge(Sa){return me(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class we extends te{constructor(v){super();ne(this,v,ge,he,le,{})}}export{we as default,ce as metadata};
