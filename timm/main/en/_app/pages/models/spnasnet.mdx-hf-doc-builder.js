import{S as Ft,i as Wt,s as Xt,e as n,k as i,w as f,t as h,M as Kt,c as l,d as t,m as p,a as r,x as u,h as c,b as m,G as e,g as o,y as d,L as Qt,q as g,o as w,B as _,v as Vt}from"../../chunks/vendor-hf-doc-builder.js";import{I as fs}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ss}from"../../chunks/CodeBlock-hf-doc-builder.js";function Zt($t){let v,us,j,E,ts,H,Js,es,Os,ds,C,as,Fs,Ws,gs,$,x,ns,D,Xs,ls,Ks,ws,F,Qs,_s,L,vs,W,Vs,js,z,$s,X,Zs,ys,G,bs,K,st,ks,R,Es,S,tt,os,et,at,xs,P,nt,Q,lt,ot,Ss,y,N,rs,M,rt,is,it,Ps,V,pt,Ns,B,As,A,mt,Y,ht,ct,qs,b,q,ps,U,ft,ms,ut,Is,I,dt,Z,gt,wt,Ts,k,T,hs,J,_t,cs,vt,Hs,O,Cs;return H=new fs({}),D=new fs({}),L=new ss({props:{code:`import timm
model = timm.create_model('spnasnet_100', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;spnasnet_100&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),z=new ss({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),G=new ss({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),R=new ss({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),M=new fs({}),B=new ss({props:{code:"model = timm.create_model('spnasnet_100', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;spnasnet_100&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),U=new fs({}),J=new fs({}),O=new ss({props:{code:`@misc{stamoulis2019singlepath,
      title={Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours}, 
      author={Dimitrios Stamoulis and Ruizhou Ding and Di Wang and Dimitrios Lymberopoulos and Bodhi Priyantha and Jie Liu and Diana Marculescu},
      year={2019},
      eprint={1904.02877},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`,highlighted:`@misc{stamoulis2019singlepath,
      title={Single-Path NAS: Designing Hardware-Efficient ConvNets in less than <span class="hljs-number">4</span> Hours}, 
      author={<span class="hljs-keyword">Dimitrios </span>Stamoulis <span class="hljs-keyword">and </span>Ruizhou <span class="hljs-keyword">Ding </span><span class="hljs-keyword">and </span><span class="hljs-keyword">Di </span>Wang <span class="hljs-keyword">and </span><span class="hljs-keyword">Dimitrios </span>Lymberopoulos <span class="hljs-keyword">and </span><span class="hljs-keyword">Bodhi </span>Priyantha <span class="hljs-keyword">and </span><span class="hljs-keyword">Jie </span>Liu <span class="hljs-keyword">and </span><span class="hljs-keyword">Diana </span>Marculescu},
      year={<span class="hljs-number">2019</span>},
      eprint={<span class="hljs-number">1904</span>.<span class="hljs-number">02877</span>},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`}}),{c(){v=n("meta"),us=i(),j=n("h1"),E=n("a"),ts=n("span"),f(H.$$.fragment),Js=i(),es=n("span"),Os=h("SPNASNet"),ds=i(),C=n("p"),as=n("strong"),Fs=h("Single-Path NAS"),Ws=h(" is a novel differentiable NAS method for designing hardware-efficient ConvNets in less than 4 hours."),gs=i(),$=n("h2"),x=n("a"),ns=n("span"),f(D.$$.fragment),Xs=i(),ls=n("span"),Ks=h("How do I use this model on an image?"),ws=i(),F=n("p"),Qs=h("To load a pretrained model:"),_s=i(),f(L.$$.fragment),vs=i(),W=n("p"),Vs=h("To load and preprocess the image:"),js=i(),f(z.$$.fragment),$s=i(),X=n("p"),Zs=h("To get the model predictions:"),ys=i(),f(G.$$.fragment),bs=i(),K=n("p"),st=h("To get the top-5 predictions class names:"),ks=i(),f(R.$$.fragment),Es=i(),S=n("p"),tt=h("Replace the model name with the variant you want to use, e.g. "),os=n("code"),et=h("spnasnet_100"),at=h(". You can find the IDs in the model summaries at the top of this page."),xs=i(),P=n("p"),nt=h("To extract image features with this model, follow the "),Q=n("a"),lt=h("timm feature extraction examples"),ot=h(", just change the name of the model you want to use."),Ss=i(),y=n("h2"),N=n("a"),rs=n("span"),f(M.$$.fragment),rt=i(),is=n("span"),it=h("How do I finetune this model?"),Ps=i(),V=n("p"),pt=h("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ns=i(),f(B.$$.fragment),As=i(),A=n("p"),mt=h("To finetune on your own dataset, you have to write a training loop or adapt "),Y=n("a"),ht=h(`timm\u2019s training
script`),ct=h(" to use your dataset."),qs=i(),b=n("h2"),q=n("a"),ps=n("span"),f(U.$$.fragment),ft=i(),ms=n("span"),ut=h("How do I train this model?"),Is=i(),I=n("p"),dt=h("You can follow the "),Z=n("a"),gt=h("timm recipe scripts"),wt=h(" for training a new model afresh."),Ts=i(),k=n("h2"),T=n("a"),hs=n("span"),f(J.$$.fragment),_t=i(),cs=n("span"),vt=h("Citation"),Hs=i(),f(O.$$.fragment),this.h()},l(s){const a=Kt('[data-svelte="svelte-1phssyn"]',document.head);v=l(a,"META",{name:!0,content:!0}),a.forEach(t),us=p(s),j=l(s,"H1",{class:!0});var Ds=r(j);E=l(Ds,"A",{id:!0,class:!0,href:!0});var yt=r(E);ts=l(yt,"SPAN",{});var bt=r(ts);u(H.$$.fragment,bt),bt.forEach(t),yt.forEach(t),Js=p(Ds),es=l(Ds,"SPAN",{});var kt=r(es);Os=c(kt,"SPNASNet"),kt.forEach(t),Ds.forEach(t),ds=p(s),C=l(s,"P",{});var jt=r(C);as=l(jt,"STRONG",{});var Et=r(as);Fs=c(Et,"Single-Path NAS"),Et.forEach(t),Ws=c(jt," is a novel differentiable NAS method for designing hardware-efficient ConvNets in less than 4 hours."),jt.forEach(t),gs=p(s),$=l(s,"H2",{class:!0});var Ls=r($);x=l(Ls,"A",{id:!0,class:!0,href:!0});var xt=r(x);ns=l(xt,"SPAN",{});var St=r(ns);u(D.$$.fragment,St),St.forEach(t),xt.forEach(t),Xs=p(Ls),ls=l(Ls,"SPAN",{});var Pt=r(ls);Ks=c(Pt,"How do I use this model on an image?"),Pt.forEach(t),Ls.forEach(t),ws=p(s),F=l(s,"P",{});var Nt=r(F);Qs=c(Nt,"To load a pretrained model:"),Nt.forEach(t),_s=p(s),u(L.$$.fragment,s),vs=p(s),W=l(s,"P",{});var At=r(W);Vs=c(At,"To load and preprocess the image:"),At.forEach(t),js=p(s),u(z.$$.fragment,s),$s=p(s),X=l(s,"P",{});var qt=r(X);Zs=c(qt,"To get the model predictions:"),qt.forEach(t),ys=p(s),u(G.$$.fragment,s),bs=p(s),K=l(s,"P",{});var It=r(K);st=c(It,"To get the top-5 predictions class names:"),It.forEach(t),ks=p(s),u(R.$$.fragment,s),Es=p(s),S=l(s,"P",{});var zs=r(S);tt=c(zs,"Replace the model name with the variant you want to use, e.g. "),os=l(zs,"CODE",{});var Tt=r(os);et=c(Tt,"spnasnet_100"),Tt.forEach(t),at=c(zs,". You can find the IDs in the model summaries at the top of this page."),zs.forEach(t),xs=p(s),P=l(s,"P",{});var Gs=r(P);nt=c(Gs,"To extract image features with this model, follow the "),Q=l(Gs,"A",{href:!0});var Ht=r(Q);lt=c(Ht,"timm feature extraction examples"),Ht.forEach(t),ot=c(Gs,", just change the name of the model you want to use."),Gs.forEach(t),Ss=p(s),y=l(s,"H2",{class:!0});var Rs=r(y);N=l(Rs,"A",{id:!0,class:!0,href:!0});var Ct=r(N);rs=l(Ct,"SPAN",{});var Dt=r(rs);u(M.$$.fragment,Dt),Dt.forEach(t),Ct.forEach(t),rt=p(Rs),is=l(Rs,"SPAN",{});var Lt=r(is);it=c(Lt,"How do I finetune this model?"),Lt.forEach(t),Rs.forEach(t),Ps=p(s),V=l(s,"P",{});var zt=r(V);pt=c(zt,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),zt.forEach(t),Ns=p(s),u(B.$$.fragment,s),As=p(s),A=l(s,"P",{});var Ms=r(A);mt=c(Ms,"To finetune on your own dataset, you have to write a training loop or adapt "),Y=l(Ms,"A",{href:!0,rel:!0});var Gt=r(Y);ht=c(Gt,`timm\u2019s training
script`),Gt.forEach(t),ct=c(Ms," to use your dataset."),Ms.forEach(t),qs=p(s),b=l(s,"H2",{class:!0});var Bs=r(b);q=l(Bs,"A",{id:!0,class:!0,href:!0});var Rt=r(q);ps=l(Rt,"SPAN",{});var Mt=r(ps);u(U.$$.fragment,Mt),Mt.forEach(t),Rt.forEach(t),ft=p(Bs),ms=l(Bs,"SPAN",{});var Bt=r(ms);ut=c(Bt,"How do I train this model?"),Bt.forEach(t),Bs.forEach(t),Is=p(s),I=l(s,"P",{});var Ys=r(I);dt=c(Ys,"You can follow the "),Z=l(Ys,"A",{href:!0});var Yt=r(Z);gt=c(Yt,"timm recipe scripts"),Yt.forEach(t),wt=c(Ys," for training a new model afresh."),Ys.forEach(t),Ts=p(s),k=l(s,"H2",{class:!0});var Us=r(k);T=l(Us,"A",{id:!0,class:!0,href:!0});var Ut=r(T);hs=l(Ut,"SPAN",{});var Jt=r(hs);u(J.$$.fragment,Jt),Jt.forEach(t),Ut.forEach(t),_t=p(Us),cs=l(Us,"SPAN",{});var Ot=r(cs);vt=c(Ot,"Citation"),Ot.forEach(t),Us.forEach(t),Hs=p(s),u(O.$$.fragment,s),this.h()},h(){m(v,"name","hf:doc:metadata"),m(v,"content",JSON.stringify(se)),m(E,"id","spnasnet"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#spnasnet"),m(j,"class","relative group"),m(x,"id","how-do-i-use-this-model-on-an-image"),m(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x,"href","#how-do-i-use-this-model-on-an-image"),m($,"class","relative group"),m(Q,"href","../feature_extraction"),m(N,"id","how-do-i-finetune-this-model"),m(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N,"href","#how-do-i-finetune-this-model"),m(y,"class","relative group"),m(Y,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),m(Y,"rel","nofollow"),m(q,"id","how-do-i-train-this-model"),m(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(q,"href","#how-do-i-train-this-model"),m(b,"class","relative group"),m(Z,"href","../scripts"),m(T,"id","citation"),m(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(T,"href","#citation"),m(k,"class","relative group")},m(s,a){e(document.head,v),o(s,us,a),o(s,j,a),e(j,E),e(E,ts),d(H,ts,null),e(j,Js),e(j,es),e(es,Os),o(s,ds,a),o(s,C,a),e(C,as),e(as,Fs),e(C,Ws),o(s,gs,a),o(s,$,a),e($,x),e(x,ns),d(D,ns,null),e($,Xs),e($,ls),e(ls,Ks),o(s,ws,a),o(s,F,a),e(F,Qs),o(s,_s,a),d(L,s,a),o(s,vs,a),o(s,W,a),e(W,Vs),o(s,js,a),d(z,s,a),o(s,$s,a),o(s,X,a),e(X,Zs),o(s,ys,a),d(G,s,a),o(s,bs,a),o(s,K,a),e(K,st),o(s,ks,a),d(R,s,a),o(s,Es,a),o(s,S,a),e(S,tt),e(S,os),e(os,et),e(S,at),o(s,xs,a),o(s,P,a),e(P,nt),e(P,Q),e(Q,lt),e(P,ot),o(s,Ss,a),o(s,y,a),e(y,N),e(N,rs),d(M,rs,null),e(y,rt),e(y,is),e(is,it),o(s,Ps,a),o(s,V,a),e(V,pt),o(s,Ns,a),d(B,s,a),o(s,As,a),o(s,A,a),e(A,mt),e(A,Y),e(Y,ht),e(A,ct),o(s,qs,a),o(s,b,a),e(b,q),e(q,ps),d(U,ps,null),e(b,ft),e(b,ms),e(ms,ut),o(s,Is,a),o(s,I,a),e(I,dt),e(I,Z),e(Z,gt),e(I,wt),o(s,Ts,a),o(s,k,a),e(k,T),e(T,hs),d(J,hs,null),e(k,_t),e(k,cs),e(cs,vt),o(s,Hs,a),d(O,s,a),Cs=!0},p:Qt,i(s){Cs||(g(H.$$.fragment,s),g(D.$$.fragment,s),g(L.$$.fragment,s),g(z.$$.fragment,s),g(G.$$.fragment,s),g(R.$$.fragment,s),g(M.$$.fragment,s),g(B.$$.fragment,s),g(U.$$.fragment,s),g(J.$$.fragment,s),g(O.$$.fragment,s),Cs=!0)},o(s){w(H.$$.fragment,s),w(D.$$.fragment,s),w(L.$$.fragment,s),w(z.$$.fragment,s),w(G.$$.fragment,s),w(R.$$.fragment,s),w(M.$$.fragment,s),w(B.$$.fragment,s),w(U.$$.fragment,s),w(J.$$.fragment,s),w(O.$$.fragment,s),Cs=!1},d(s){t(v),s&&t(us),s&&t(j),_(H),s&&t(ds),s&&t(C),s&&t(gs),s&&t($),_(D),s&&t(ws),s&&t(F),s&&t(_s),_(L,s),s&&t(vs),s&&t(W),s&&t(js),_(z,s),s&&t($s),s&&t(X),s&&t(ys),_(G,s),s&&t(bs),s&&t(K),s&&t(ks),_(R,s),s&&t(Es),s&&t(S),s&&t(xs),s&&t(P),s&&t(Ss),s&&t(y),_(M),s&&t(Ps),s&&t(V),s&&t(Ns),_(B,s),s&&t(As),s&&t(A),s&&t(qs),s&&t(b),_(U),s&&t(Is),s&&t(I),s&&t(Ts),s&&t(k),_(J),s&&t(Hs),_(O,s)}}}const se={local:"spnasnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"SPNASNet"};function te($t){return Vt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class le extends Ft{constructor(v){super();Wt(this,v,te,Zt,Xt,{})}}export{le as default,se as metadata};
