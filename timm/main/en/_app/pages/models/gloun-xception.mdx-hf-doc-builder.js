import{S as ls,i as ns,s as rs,e as o,k as h,w as f,t as p,M as is,c as l,d as e,m as c,a as n,x as u,h as m,b as i,G as s,g as r,y as g,L as ps,q as d,o as w,B as _,v as ms}from"../../chunks/vendor-hf-doc-builder.js";import{I as wt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as at}from"../../chunks/CodeBlock-hf-doc-builder.js";function hs(qe){let v,_t,j,E,ot,G,Qt,lt,Wt,vt,$,nt,Zt,te,L,ee,se,jt,P,ae,X,oe,le,$t,b,S,rt,z,ne,it,re,bt,K,ie,yt,D,xt,Q,pe,kt,R,Et,W,me,Pt,Y,St,Z,he,At,M,Tt,A,ce,pt,fe,ue,qt,T,ge,tt,de,we,It,y,q,mt,U,_e,ht,ve,Ct,et,je,Nt,B,Ht,I,$e,F,be,ye,Gt,x,C,ct,O,xe,ft,ke,Lt,N,Ee,st,Pe,Se,Xt,k,H,ut,V,Ae,gt,Te,zt,J,Dt;return G=new wt({}),z=new wt({}),D=new at({props:{code:`import timm
model = timm.create_model('gluon_xception65', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;gluon_xception65&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),R=new at({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),Y=new at({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),M=new at({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),U=new wt({}),B=new at({props:{code:"model = timm.create_model('gluon_xception65', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;gluon_xception65&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),O=new wt({}),V=new wt({}),J=new at({props:{code:`@misc{chollet2017xception,
      title={Xception: Deep Learning with Depthwise Separable Convolutions}, 
      author={Fran\xE7ois Chollet},
      year={2017},
      eprint={1610.02357},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`@misc{chollet2017xception,
      <span class="hljs-attr">title={Xception:</span> Deep Learning <span class="hljs-keyword">with</span> Depthwise Separable Convolutions}, 
      <span class="hljs-attr">author={Fran\xE7ois</span> Chollet},
      <span class="hljs-attr">year={2017},</span>
      <span class="hljs-attr">eprint={1610.02357},</span>
      <span class="hljs-attr">archivePrefix={arXiv},</span>
      <span class="hljs-attr">primaryClass={cs.CV}</span>
}`}}),{c(){v=o("meta"),_t=h(),j=o("h1"),E=o("a"),ot=o("span"),f(G.$$.fragment),Qt=h(),lt=o("span"),Wt=p("(Gluon) Xception"),vt=h(),$=o("p"),nt=o("strong"),Zt=p("Xception"),te=p(" is a convolutional neural network architecture that relies solely on "),L=o("a"),ee=p("depthwise separable convolution"),se=p(" layers."),jt=h(),P=o("p"),ae=p("The weights from this model were ported from "),X=o("a"),oe=p("Gluon"),le=p("."),$t=h(),b=o("h2"),S=o("a"),rt=o("span"),f(z.$$.fragment),ne=h(),it=o("span"),re=p("How do I use this model on an image?"),bt=h(),K=o("p"),ie=p("To load a pretrained model:"),yt=h(),f(D.$$.fragment),xt=h(),Q=o("p"),pe=p("To load and preprocess the image:"),kt=h(),f(R.$$.fragment),Et=h(),W=o("p"),me=p("To get the model predictions:"),Pt=h(),f(Y.$$.fragment),St=h(),Z=o("p"),he=p("To get the top-5 predictions class names:"),At=h(),f(M.$$.fragment),Tt=h(),A=o("p"),ce=p("Replace the model name with the variant you want to use, e.g. "),pt=o("code"),fe=p("gluon_xception65"),ue=p(". You can find the IDs in the model summaries at the top of this page."),qt=h(),T=o("p"),ge=p("To extract image features with this model, follow the "),tt=o("a"),de=p("timm feature extraction examples"),we=p(", just change the name of the model you want to use."),It=h(),y=o("h2"),q=o("a"),mt=o("span"),f(U.$$.fragment),_e=h(),ht=o("span"),ve=p("How do I finetune this model?"),Ct=h(),et=o("p"),je=p("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Nt=h(),f(B.$$.fragment),Ht=h(),I=o("p"),$e=p("To finetune on your own dataset, you have to write a training loop or adapt "),F=o("a"),be=p(`timm\u2019s training
script`),ye=p(" to use your dataset."),Gt=h(),x=o("h2"),C=o("a"),ct=o("span"),f(O.$$.fragment),xe=h(),ft=o("span"),ke=p("How do I train this model?"),Lt=h(),N=o("p"),Ee=p("You can follow the "),st=o("a"),Pe=p("timm recipe scripts"),Se=p(" for training a new model afresh."),Xt=h(),k=o("h2"),H=o("a"),ut=o("span"),f(V.$$.fragment),Ae=h(),gt=o("span"),Te=p("Citation"),zt=h(),f(J.$$.fragment),this.h()},l(t){const a=is('[data-svelte="svelte-1phssyn"]',document.head);v=l(a,"META",{name:!0,content:!0}),a.forEach(e),_t=c(t),j=l(t,"H1",{class:!0});var Rt=n(j);E=l(Rt,"A",{id:!0,class:!0,href:!0});var Ie=n(E);ot=l(Ie,"SPAN",{});var Ce=n(ot);u(G.$$.fragment,Ce),Ce.forEach(e),Ie.forEach(e),Qt=c(Rt),lt=l(Rt,"SPAN",{});var Ne=n(lt);Wt=m(Ne,"(Gluon) Xception"),Ne.forEach(e),Rt.forEach(e),vt=c(t),$=l(t,"P",{});var dt=n($);nt=l(dt,"STRONG",{});var He=n(nt);Zt=m(He,"Xception"),He.forEach(e),te=m(dt," is a convolutional neural network architecture that relies solely on "),L=l(dt,"A",{href:!0,rel:!0});var Ge=n(L);ee=m(Ge,"depthwise separable convolution"),Ge.forEach(e),se=m(dt," layers."),dt.forEach(e),jt=c(t),P=l(t,"P",{});var Yt=n(P);ae=m(Yt,"The weights from this model were ported from "),X=l(Yt,"A",{href:!0,rel:!0});var Le=n(X);oe=m(Le,"Gluon"),Le.forEach(e),le=m(Yt,"."),Yt.forEach(e),$t=c(t),b=l(t,"H2",{class:!0});var Mt=n(b);S=l(Mt,"A",{id:!0,class:!0,href:!0});var Xe=n(S);rt=l(Xe,"SPAN",{});var ze=n(rt);u(z.$$.fragment,ze),ze.forEach(e),Xe.forEach(e),ne=c(Mt),it=l(Mt,"SPAN",{});var De=n(it);re=m(De,"How do I use this model on an image?"),De.forEach(e),Mt.forEach(e),bt=c(t),K=l(t,"P",{});var Re=n(K);ie=m(Re,"To load a pretrained model:"),Re.forEach(e),yt=c(t),u(D.$$.fragment,t),xt=c(t),Q=l(t,"P",{});var Ye=n(Q);pe=m(Ye,"To load and preprocess the image:"),Ye.forEach(e),kt=c(t),u(R.$$.fragment,t),Et=c(t),W=l(t,"P",{});var Me=n(W);me=m(Me,"To get the model predictions:"),Me.forEach(e),Pt=c(t),u(Y.$$.fragment,t),St=c(t),Z=l(t,"P",{});var Ue=n(Z);he=m(Ue,"To get the top-5 predictions class names:"),Ue.forEach(e),At=c(t),u(M.$$.fragment,t),Tt=c(t),A=l(t,"P",{});var Ut=n(A);ce=m(Ut,"Replace the model name with the variant you want to use, e.g. "),pt=l(Ut,"CODE",{});var Be=n(pt);fe=m(Be,"gluon_xception65"),Be.forEach(e),ue=m(Ut,". You can find the IDs in the model summaries at the top of this page."),Ut.forEach(e),qt=c(t),T=l(t,"P",{});var Bt=n(T);ge=m(Bt,"To extract image features with this model, follow the "),tt=l(Bt,"A",{href:!0});var Fe=n(tt);de=m(Fe,"timm feature extraction examples"),Fe.forEach(e),we=m(Bt,", just change the name of the model you want to use."),Bt.forEach(e),It=c(t),y=l(t,"H2",{class:!0});var Ft=n(y);q=l(Ft,"A",{id:!0,class:!0,href:!0});var Oe=n(q);mt=l(Oe,"SPAN",{});var Ve=n(mt);u(U.$$.fragment,Ve),Ve.forEach(e),Oe.forEach(e),_e=c(Ft),ht=l(Ft,"SPAN",{});var Je=n(ht);ve=m(Je,"How do I finetune this model?"),Je.forEach(e),Ft.forEach(e),Ct=c(t),et=l(t,"P",{});var Ke=n(et);je=m(Ke,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ke.forEach(e),Nt=c(t),u(B.$$.fragment,t),Ht=c(t),I=l(t,"P",{});var Ot=n(I);$e=m(Ot,"To finetune on your own dataset, you have to write a training loop or adapt "),F=l(Ot,"A",{href:!0,rel:!0});var Qe=n(F);be=m(Qe,`timm\u2019s training
script`),Qe.forEach(e),ye=m(Ot," to use your dataset."),Ot.forEach(e),Gt=c(t),x=l(t,"H2",{class:!0});var Vt=n(x);C=l(Vt,"A",{id:!0,class:!0,href:!0});var We=n(C);ct=l(We,"SPAN",{});var Ze=n(ct);u(O.$$.fragment,Ze),Ze.forEach(e),We.forEach(e),xe=c(Vt),ft=l(Vt,"SPAN",{});var ts=n(ft);ke=m(ts,"How do I train this model?"),ts.forEach(e),Vt.forEach(e),Lt=c(t),N=l(t,"P",{});var Jt=n(N);Ee=m(Jt,"You can follow the "),st=l(Jt,"A",{href:!0});var es=n(st);Pe=m(es,"timm recipe scripts"),es.forEach(e),Se=m(Jt," for training a new model afresh."),Jt.forEach(e),Xt=c(t),k=l(t,"H2",{class:!0});var Kt=n(k);H=l(Kt,"A",{id:!0,class:!0,href:!0});var ss=n(H);ut=l(ss,"SPAN",{});var as=n(ut);u(V.$$.fragment,as),as.forEach(e),ss.forEach(e),Ae=c(Kt),gt=l(Kt,"SPAN",{});var os=n(gt);Te=m(os,"Citation"),os.forEach(e),Kt.forEach(e),zt=c(t),u(J.$$.fragment,t),this.h()},h(){i(v,"name","hf:doc:metadata"),i(v,"content",JSON.stringify(cs)),i(E,"id","gluon-xception"),i(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(E,"href","#gluon-xception"),i(j,"class","relative group"),i(L,"href","https://paperswithcode.com/method/depthwise-separable-convolution"),i(L,"rel","nofollow"),i(X,"href","https://cv.gluon.ai/model_zoo/classification.html"),i(X,"rel","nofollow"),i(S,"id","how-do-i-use-this-model-on-an-image"),i(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(S,"href","#how-do-i-use-this-model-on-an-image"),i(b,"class","relative group"),i(tt,"href","../feature_extraction"),i(q,"id","how-do-i-finetune-this-model"),i(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(q,"href","#how-do-i-finetune-this-model"),i(y,"class","relative group"),i(F,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(F,"rel","nofollow"),i(C,"id","how-do-i-train-this-model"),i(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(C,"href","#how-do-i-train-this-model"),i(x,"class","relative group"),i(st,"href","../scripts"),i(H,"id","citation"),i(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(H,"href","#citation"),i(k,"class","relative group")},m(t,a){s(document.head,v),r(t,_t,a),r(t,j,a),s(j,E),s(E,ot),g(G,ot,null),s(j,Qt),s(j,lt),s(lt,Wt),r(t,vt,a),r(t,$,a),s($,nt),s(nt,Zt),s($,te),s($,L),s(L,ee),s($,se),r(t,jt,a),r(t,P,a),s(P,ae),s(P,X),s(X,oe),s(P,le),r(t,$t,a),r(t,b,a),s(b,S),s(S,rt),g(z,rt,null),s(b,ne),s(b,it),s(it,re),r(t,bt,a),r(t,K,a),s(K,ie),r(t,yt,a),g(D,t,a),r(t,xt,a),r(t,Q,a),s(Q,pe),r(t,kt,a),g(R,t,a),r(t,Et,a),r(t,W,a),s(W,me),r(t,Pt,a),g(Y,t,a),r(t,St,a),r(t,Z,a),s(Z,he),r(t,At,a),g(M,t,a),r(t,Tt,a),r(t,A,a),s(A,ce),s(A,pt),s(pt,fe),s(A,ue),r(t,qt,a),r(t,T,a),s(T,ge),s(T,tt),s(tt,de),s(T,we),r(t,It,a),r(t,y,a),s(y,q),s(q,mt),g(U,mt,null),s(y,_e),s(y,ht),s(ht,ve),r(t,Ct,a),r(t,et,a),s(et,je),r(t,Nt,a),g(B,t,a),r(t,Ht,a),r(t,I,a),s(I,$e),s(I,F),s(F,be),s(I,ye),r(t,Gt,a),r(t,x,a),s(x,C),s(C,ct),g(O,ct,null),s(x,xe),s(x,ft),s(ft,ke),r(t,Lt,a),r(t,N,a),s(N,Ee),s(N,st),s(st,Pe),s(N,Se),r(t,Xt,a),r(t,k,a),s(k,H),s(H,ut),g(V,ut,null),s(k,Ae),s(k,gt),s(gt,Te),r(t,zt,a),g(J,t,a),Dt=!0},p:ps,i(t){Dt||(d(G.$$.fragment,t),d(z.$$.fragment,t),d(D.$$.fragment,t),d(R.$$.fragment,t),d(Y.$$.fragment,t),d(M.$$.fragment,t),d(U.$$.fragment,t),d(B.$$.fragment,t),d(O.$$.fragment,t),d(V.$$.fragment,t),d(J.$$.fragment,t),Dt=!0)},o(t){w(G.$$.fragment,t),w(z.$$.fragment,t),w(D.$$.fragment,t),w(R.$$.fragment,t),w(Y.$$.fragment,t),w(M.$$.fragment,t),w(U.$$.fragment,t),w(B.$$.fragment,t),w(O.$$.fragment,t),w(V.$$.fragment,t),w(J.$$.fragment,t),Dt=!1},d(t){e(v),t&&e(_t),t&&e(j),_(G),t&&e(vt),t&&e($),t&&e(jt),t&&e(P),t&&e($t),t&&e(b),_(z),t&&e(bt),t&&e(K),t&&e(yt),_(D,t),t&&e(xt),t&&e(Q),t&&e(kt),_(R,t),t&&e(Et),t&&e(W),t&&e(Pt),_(Y,t),t&&e(St),t&&e(Z),t&&e(At),_(M,t),t&&e(Tt),t&&e(A),t&&e(qt),t&&e(T),t&&e(It),t&&e(y),_(U),t&&e(Ct),t&&e(et),t&&e(Nt),_(B,t),t&&e(Ht),t&&e(I),t&&e(Gt),t&&e(x),_(O),t&&e(Lt),t&&e(N),t&&e(Xt),t&&e(k),_(V),t&&e(zt),_(J,t)}}}const cs={local:"gluon-xception",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"(Gluon) Xception"};function fs(qe){return ms(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ws extends ls{constructor(v){super();ns(this,v,fs,hs,rs,{})}}export{ws as default,cs as metadata};
