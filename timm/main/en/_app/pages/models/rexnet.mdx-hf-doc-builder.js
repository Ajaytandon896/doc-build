import{S as Qt,i as Wt,s as Zt,e as n,k as p,w as f,t as m,M as es,c as l,d as t,m as h,a as o,x as u,h as c,b as i,G as s,g as r,y as g,L as ts,q as d,o as w,B as v,v as ss}from"../../chunks/vendor-hf-doc-builder.js";import{I as ge}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as te}from"../../chunks/CodeBlock-hf-doc-builder.js";function as(xt){let _,de,$,E,se,H,Oe,ae,Fe,we,j,ne,Ve,Ke,C,Qe,We,ve,b,N,le,Y,Ze,oe,et,_e,F,tt,$e,L,je,V,st,be,z,ye,K,at,xe,B,ke,Q,nt,Ee,D,Ne,P,lt,re,ot,rt,Pe,S,it,W,pt,mt,Se,y,A,ie,U,ht,pe,ct,Ae,Z,ft,qe,G,Ie,q,ut,X,gt,dt,Re,x,I,me,M,wt,he,vt,Te,R,_t,ee,$t,jt,He,k,T,ce,J,bt,fe,yt,Ce,O,Ye;return H=new ge({}),Y=new ge({}),L=new te({props:{code:`import timm
model = timm.create_model('rexnet_100', pretrained=True)
model.eval()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> timm
<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;rexnet_100&#x27;</span>, pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()`}}),z=new te({props:{code:`import urllib
from PIL import Image
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

config = resolve_data_config({}, model=model)
transform = create_transform(**config)

url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
urllib.request.urlretrieve(url, filename)
img = Image.open(filename).convert('RGB')
tensor = transform(img).unsqueeze(0) # transform and add batch dimension`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> urllib
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> resolve_data_config
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> timm.data.transforms_factory <span class="hljs-keyword">import</span> create_transform

<span class="hljs-meta">&gt;&gt;&gt; </span>config = resolve_data_config({}, model=model)
<span class="hljs-meta">&gt;&gt;&gt; </span>transform = create_transform(**config)

<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>, <span class="hljs-string">&quot;dog.jpg&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename)
<span class="hljs-meta">&gt;&gt;&gt; </span>img = Image.<span class="hljs-built_in">open</span>(filename).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tensor = transform(img).unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># transform and add batch dimension</span>`}}),B=new te({props:{code:`import torch
with torch.no_grad():
    out = model(tensor)
probabilities = torch.nn.functional.softmax(out[0], dim=0)
print(probabilities.shape)
# prints: torch.Size([1000])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    out = model(tensor)
<span class="hljs-meta">&gt;&gt;&gt; </span>probabilities = torch.nn.functional.softmax(out[<span class="hljs-number">0</span>], dim=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(probabilities.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints: torch.Size([1000])</span>`}}),D=new te({props:{code:`# Get imagenet class mappings
url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")
urllib.request.urlretrieve(url, filename) 
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

# Print top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
# prints class names and probabilities like:
# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get imagenet class mappings</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>url, filename = (<span class="hljs-string">&quot;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>urllib.request.urlretrieve(url, filename) 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;imagenet_classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>    categories = [s.strip() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> f.readlines()]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Print top categories per image</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>top5_prob, top5_catid = torch.topk(probabilities, <span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top5_prob.size(<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(categories[top5_catid[i]], top5_prob[i].item())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># prints class names and probabilities like:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [(&#x27;Samoyed&#x27;, 0.6425196528434753), (&#x27;Pomeranian&#x27;, 0.04062102362513542), (&#x27;keeshond&#x27;, 0.03186424449086189), (&#x27;white wolf&#x27;, 0.01739676296710968), (&#x27;Eskimo dog&#x27;, 0.011717947199940681)]</span>`}}),U=new ge({}),G=new te({props:{code:"model = timm.create_model('rexnet_100', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = timm.create_model(<span class="hljs-string">&#x27;rexnet_100&#x27;</span>, pretrained=<span class="hljs-literal">True</span>, num_classes=NUM_FINETUNE_CLASSES)'}}),M=new ge({}),J=new ge({}),O=new te({props:{code:`@misc{han2020rexnet,
      title={ReXNet: Diminishing Representational Bottleneck on Convolutional Neural Network}, 
      author={Dongyoon Han and Sangdoo Yun and Byeongho Heo and YoungJoon Yoo},
      year={2020},
      eprint={2007.00992},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}`,highlighted:`<span class="language-xml">@misc</span><span class="hljs-template-variable">{han2020rexnet,
      title={ReXNet: Diminishing Representational Bottleneck on Convolutional Neural Network}</span><span class="language-xml">, 
      author=</span><span class="hljs-template-variable">{Dongyoon Han and Sangdoo Yun and Byeongho Heo and YoungJoon Yoo}</span><span class="language-xml">,
      year=</span><span class="hljs-template-variable">{2020}</span><span class="language-xml">,
      eprint=</span><span class="hljs-template-variable">{2007.00992}</span><span class="language-xml">,
      archivePrefix=</span><span class="hljs-template-variable">{arXiv}</span><span class="language-xml">,
      primaryClass=</span><span class="hljs-template-variable">{cs.CV}</span><span class="language-xml">
}</span>`}}),{c(){_=n("meta"),de=p(),$=n("h1"),E=n("a"),se=n("span"),f(H.$$.fragment),Oe=p(),ae=n("span"),Fe=m("RexNet"),we=p(),j=n("p"),ne=n("strong"),Ve=m("Rank Expansion Networks"),Ke=m(" (ReXNets) follow a set of new design principles for designing bottlenecks in image classification models. Authors refine each layer by 1) expanding the input channel size of the convolution layer and 2) replacing the "),C=n("a"),Qe=m("ReLU6s"),We=m("."),ve=p(),b=n("h2"),N=n("a"),le=n("span"),f(Y.$$.fragment),Ze=p(),oe=n("span"),et=m("How do I use this model on an image?"),_e=p(),F=n("p"),tt=m("To load a pretrained model:"),$e=p(),f(L.$$.fragment),je=p(),V=n("p"),st=m("To load and preprocess the image:"),be=p(),f(z.$$.fragment),ye=p(),K=n("p"),at=m("To get the model predictions:"),xe=p(),f(B.$$.fragment),ke=p(),Q=n("p"),nt=m("To get the top-5 predictions class names:"),Ee=p(),f(D.$$.fragment),Ne=p(),P=n("p"),lt=m("Replace the model name with the variant you want to use, e.g. "),re=n("code"),ot=m("rexnet_100"),rt=m(". You can find the IDs in the model summaries at the top of this page."),Pe=p(),S=n("p"),it=m("To extract image features with this model, follow the "),W=n("a"),pt=m("timm feature extraction examples"),mt=m(", just change the name of the model you want to use."),Se=p(),y=n("h2"),A=n("a"),ie=n("span"),f(U.$$.fragment),ht=p(),pe=n("span"),ct=m("How do I finetune this model?"),Ae=p(),Z=n("p"),ft=m("You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),qe=p(),f(G.$$.fragment),Ie=p(),q=n("p"),ut=m("To finetune on your own dataset, you have to write a training loop or adapt "),X=n("a"),gt=m(`timm\u2019s training
script`),dt=m(" to use your dataset."),Re=p(),x=n("h2"),I=n("a"),me=n("span"),f(M.$$.fragment),wt=p(),he=n("span"),vt=m("How do I train this model?"),Te=p(),R=n("p"),_t=m("You can follow the "),ee=n("a"),$t=m("timm recipe scripts"),jt=m(" for training a new model afresh."),He=p(),k=n("h2"),T=n("a"),ce=n("span"),f(J.$$.fragment),bt=p(),fe=n("span"),yt=m("Citation"),Ce=p(),f(O.$$.fragment),this.h()},l(e){const a=es('[data-svelte="svelte-1phssyn"]',document.head);_=l(a,"META",{name:!0,content:!0}),a.forEach(t),de=h(e),$=l(e,"H1",{class:!0});var Le=o($);E=l(Le,"A",{id:!0,class:!0,href:!0});var kt=o(E);se=l(kt,"SPAN",{});var Et=o(se);u(H.$$.fragment,Et),Et.forEach(t),kt.forEach(t),Oe=h(Le),ae=l(Le,"SPAN",{});var Nt=o(ae);Fe=c(Nt,"RexNet"),Nt.forEach(t),Le.forEach(t),we=h(e),j=l(e,"P",{});var ue=o(j);ne=l(ue,"STRONG",{});var Pt=o(ne);Ve=c(Pt,"Rank Expansion Networks"),Pt.forEach(t),Ke=c(ue," (ReXNets) follow a set of new design principles for designing bottlenecks in image classification models. Authors refine each layer by 1) expanding the input channel size of the convolution layer and 2) replacing the "),C=l(ue,"A",{href:!0,rel:!0});var St=o(C);Qe=c(St,"ReLU6s"),St.forEach(t),We=c(ue,"."),ue.forEach(t),ve=h(e),b=l(e,"H2",{class:!0});var ze=o(b);N=l(ze,"A",{id:!0,class:!0,href:!0});var At=o(N);le=l(At,"SPAN",{});var qt=o(le);u(Y.$$.fragment,qt),qt.forEach(t),At.forEach(t),Ze=h(ze),oe=l(ze,"SPAN",{});var It=o(oe);et=c(It,"How do I use this model on an image?"),It.forEach(t),ze.forEach(t),_e=h(e),F=l(e,"P",{});var Rt=o(F);tt=c(Rt,"To load a pretrained model:"),Rt.forEach(t),$e=h(e),u(L.$$.fragment,e),je=h(e),V=l(e,"P",{});var Tt=o(V);st=c(Tt,"To load and preprocess the image:"),Tt.forEach(t),be=h(e),u(z.$$.fragment,e),ye=h(e),K=l(e,"P",{});var Ht=o(K);at=c(Ht,"To get the model predictions:"),Ht.forEach(t),xe=h(e),u(B.$$.fragment,e),ke=h(e),Q=l(e,"P",{});var Ct=o(Q);nt=c(Ct,"To get the top-5 predictions class names:"),Ct.forEach(t),Ee=h(e),u(D.$$.fragment,e),Ne=h(e),P=l(e,"P",{});var Be=o(P);lt=c(Be,"Replace the model name with the variant you want to use, e.g. "),re=l(Be,"CODE",{});var Yt=o(re);ot=c(Yt,"rexnet_100"),Yt.forEach(t),rt=c(Be,". You can find the IDs in the model summaries at the top of this page."),Be.forEach(t),Pe=h(e),S=l(e,"P",{});var De=o(S);it=c(De,"To extract image features with this model, follow the "),W=l(De,"A",{href:!0});var Lt=o(W);pt=c(Lt,"timm feature extraction examples"),Lt.forEach(t),mt=c(De,", just change the name of the model you want to use."),De.forEach(t),Se=h(e),y=l(e,"H2",{class:!0});var Ue=o(y);A=l(Ue,"A",{id:!0,class:!0,href:!0});var zt=o(A);ie=l(zt,"SPAN",{});var Bt=o(ie);u(U.$$.fragment,Bt),Bt.forEach(t),zt.forEach(t),ht=h(Ue),pe=l(Ue,"SPAN",{});var Dt=o(pe);ct=c(Dt,"How do I finetune this model?"),Dt.forEach(t),Ue.forEach(t),Ae=h(e),Z=l(e,"P",{});var Ut=o(Z);ft=c(Ut,"You can finetune any of the pre-trained models just by changing the classifier (the last layer)."),Ut.forEach(t),qe=h(e),u(G.$$.fragment,e),Ie=h(e),q=l(e,"P",{});var Ge=o(q);ut=c(Ge,"To finetune on your own dataset, you have to write a training loop or adapt "),X=l(Ge,"A",{href:!0,rel:!0});var Gt=o(X);gt=c(Gt,`timm\u2019s training
script`),Gt.forEach(t),dt=c(Ge," to use your dataset."),Ge.forEach(t),Re=h(e),x=l(e,"H2",{class:!0});var Xe=o(x);I=l(Xe,"A",{id:!0,class:!0,href:!0});var Xt=o(I);me=l(Xt,"SPAN",{});var Mt=o(me);u(M.$$.fragment,Mt),Mt.forEach(t),Xt.forEach(t),wt=h(Xe),he=l(Xe,"SPAN",{});var Jt=o(he);vt=c(Jt,"How do I train this model?"),Jt.forEach(t),Xe.forEach(t),Te=h(e),R=l(e,"P",{});var Me=o(R);_t=c(Me,"You can follow the "),ee=l(Me,"A",{href:!0});var Ot=o(ee);$t=c(Ot,"timm recipe scripts"),Ot.forEach(t),jt=c(Me," for training a new model afresh."),Me.forEach(t),He=h(e),k=l(e,"H2",{class:!0});var Je=o(k);T=l(Je,"A",{id:!0,class:!0,href:!0});var Ft=o(T);ce=l(Ft,"SPAN",{});var Vt=o(ce);u(J.$$.fragment,Vt),Vt.forEach(t),Ft.forEach(t),bt=h(Je),fe=l(Je,"SPAN",{});var Kt=o(fe);yt=c(Kt,"Citation"),Kt.forEach(t),Je.forEach(t),Ce=h(e),u(O.$$.fragment,e),this.h()},h(){i(_,"name","hf:doc:metadata"),i(_,"content",JSON.stringify(ns)),i(E,"id","rexnet"),i(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(E,"href","#rexnet"),i($,"class","relative group"),i(C,"href","https://www.paperswithcode.com/method/relu6"),i(C,"rel","nofollow"),i(N,"id","how-do-i-use-this-model-on-an-image"),i(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(N,"href","#how-do-i-use-this-model-on-an-image"),i(b,"class","relative group"),i(W,"href","../feature_extraction"),i(A,"id","how-do-i-finetune-this-model"),i(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(A,"href","#how-do-i-finetune-this-model"),i(y,"class","relative group"),i(X,"href","https://github.com/rwightman/pytorch-image-models/blob/master/train.py"),i(X,"rel","nofollow"),i(I,"id","how-do-i-train-this-model"),i(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(I,"href","#how-do-i-train-this-model"),i(x,"class","relative group"),i(ee,"href","../scripts"),i(T,"id","citation"),i(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(T,"href","#citation"),i(k,"class","relative group")},m(e,a){s(document.head,_),r(e,de,a),r(e,$,a),s($,E),s(E,se),g(H,se,null),s($,Oe),s($,ae),s(ae,Fe),r(e,we,a),r(e,j,a),s(j,ne),s(ne,Ve),s(j,Ke),s(j,C),s(C,Qe),s(j,We),r(e,ve,a),r(e,b,a),s(b,N),s(N,le),g(Y,le,null),s(b,Ze),s(b,oe),s(oe,et),r(e,_e,a),r(e,F,a),s(F,tt),r(e,$e,a),g(L,e,a),r(e,je,a),r(e,V,a),s(V,st),r(e,be,a),g(z,e,a),r(e,ye,a),r(e,K,a),s(K,at),r(e,xe,a),g(B,e,a),r(e,ke,a),r(e,Q,a),s(Q,nt),r(e,Ee,a),g(D,e,a),r(e,Ne,a),r(e,P,a),s(P,lt),s(P,re),s(re,ot),s(P,rt),r(e,Pe,a),r(e,S,a),s(S,it),s(S,W),s(W,pt),s(S,mt),r(e,Se,a),r(e,y,a),s(y,A),s(A,ie),g(U,ie,null),s(y,ht),s(y,pe),s(pe,ct),r(e,Ae,a),r(e,Z,a),s(Z,ft),r(e,qe,a),g(G,e,a),r(e,Ie,a),r(e,q,a),s(q,ut),s(q,X),s(X,gt),s(q,dt),r(e,Re,a),r(e,x,a),s(x,I),s(I,me),g(M,me,null),s(x,wt),s(x,he),s(he,vt),r(e,Te,a),r(e,R,a),s(R,_t),s(R,ee),s(ee,$t),s(R,jt),r(e,He,a),r(e,k,a),s(k,T),s(T,ce),g(J,ce,null),s(k,bt),s(k,fe),s(fe,yt),r(e,Ce,a),g(O,e,a),Ye=!0},p:ts,i(e){Ye||(d(H.$$.fragment,e),d(Y.$$.fragment,e),d(L.$$.fragment,e),d(z.$$.fragment,e),d(B.$$.fragment,e),d(D.$$.fragment,e),d(U.$$.fragment,e),d(G.$$.fragment,e),d(M.$$.fragment,e),d(J.$$.fragment,e),d(O.$$.fragment,e),Ye=!0)},o(e){w(H.$$.fragment,e),w(Y.$$.fragment,e),w(L.$$.fragment,e),w(z.$$.fragment,e),w(B.$$.fragment,e),w(D.$$.fragment,e),w(U.$$.fragment,e),w(G.$$.fragment,e),w(M.$$.fragment,e),w(J.$$.fragment,e),w(O.$$.fragment,e),Ye=!1},d(e){t(_),e&&t(de),e&&t($),v(H),e&&t(we),e&&t(j),e&&t(ve),e&&t(b),v(Y),e&&t(_e),e&&t(F),e&&t($e),v(L,e),e&&t(je),e&&t(V),e&&t(be),v(z,e),e&&t(ye),e&&t(K),e&&t(xe),v(B,e),e&&t(ke),e&&t(Q),e&&t(Ee),v(D,e),e&&t(Ne),e&&t(P),e&&t(Pe),e&&t(S),e&&t(Se),e&&t(y),v(U),e&&t(Ae),e&&t(Z),e&&t(qe),v(G,e),e&&t(Ie),e&&t(q),e&&t(Re),e&&t(x),v(M),e&&t(Te),e&&t(R),e&&t(He),e&&t(k),v(J),e&&t(Ce),v(O,e)}}}const ns={local:"rexnet",sections:[{local:"how-do-i-use-this-model-on-an-image",title:"How do I use this model on an image?"},{local:"how-do-i-finetune-this-model",title:"How do I finetune this model?"},{local:"how-do-i-train-this-model",title:"How do I train this model?"},{local:"citation",title:"Citation"}],title:"RexNet"};function ls(xt){return ss(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ps extends Qt{constructor(_){super();Wt(this,_,ls,as,Zt,{})}}export{ps as default,ns as metadata};
