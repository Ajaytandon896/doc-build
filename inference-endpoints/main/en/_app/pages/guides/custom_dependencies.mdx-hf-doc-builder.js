import{S as Ue,i as We,s as Je,e as o,k as _,w as Me,t as s,M as je,c as r,d as n,m as y,a,x as Ne,h as i,b as c,G as t,g as u,y as Re,L as Ke,q as ze,o as Ge,B as Be,v as Qe}from"../../chunks/vendor-hf-doc-builder.js";import{I as Ve}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Xe}from"../../chunks/CodeBlock-hf-doc-builder.js";function Ye(we){let p,R,h,E,C,g,X,O,Y,z,d,Z,q,ee,te,S,ne,oe,D,re,ae,H,se,ie,G,f,le,T,b,de,ce,F,ue,fe,B,x,U,A,L,me,W,v,M,$,pe,he,N,k,_e,J,w,ye,P,Ee,ve,j;return g=new Ve({}),x=new Xe({props:{code:`optimum[onnxruntime]==1.2.3
mkl-include
mkl`,highlighted:`optimum[onnxruntime]==1.2.3
mkl-include
mkl`}}),{c(){p=o("meta"),R=_(),h=o("h1"),E=o("a"),C=o("span"),Me(g.$$.fragment),X=_(),O=o("span"),Y=s("Add custom Dependencies"),z=_(),d=o("p"),Z=s("Hugging Face Endpoints\u2019 base image includes all required libraries to run inference on transformers models, but sometimes that can be too limited. For example, you want to "),q=o("a"),ee=s("customize your inference pipeline"),te=s(" and need additional python dependencies or you want to run a model which requires special dependencies or the newest/a fixed version of a library, e.g. "),S=o("code"),ne=s("tapas"),oe=s(" ("),D=o("code"),re=s("torch-scatter"),ae=s("). Therefore Endpoints support "),H=o("strong"),se=s("custom dependencies"),ie=s("."),G=_(),f=o("p"),le=s("To add custom dependencies add a "),T=o("code"),b=o("a"),de=s("requirements.txt"),ce=s(" file to your model repository on the Hugging Face Hub with the Python dependencies you want to install. When your Endpoint and Image artifacts are created, Inference Endpoints will check if the Model Repository contains a "),F=o("code"),ue=s("requirements.txt "),fe=s("file and installs the dependencies."),B=_(),Me(x.$$.fragment),U=_(),A=o("p"),L=o("strong"),me=s("Examples:"),W=_(),v=o("ul"),M=o("li"),$=o("a"),pe=s("Optimum and onnxruntime"),he=_(),N=o("li"),k=o("a"),_e=s("diffusers"),J=_(),w=o("p"),ye=s("If you need further customization you can "),P=o("a"),Ee=s("use your own custom container"),ve=s(" for inference."),this.h()},l(e){const l=je('[data-svelte="svelte-1phssyn"]',document.head);p=r(l,"META",{name:!0,content:!0}),l.forEach(n),R=y(e),h=r(e,"H1",{class:!0});var K=a(h);E=r(K,"A",{id:!0,class:!0,href:!0});var ge=a(E);C=r(ge,"SPAN",{});var be=a(C);Ne(g.$$.fragment,be),be.forEach(n),ge.forEach(n),X=y(K),O=r(K,"SPAN",{});var xe=a(O);Y=i(xe,"Add custom Dependencies"),xe.forEach(n),K.forEach(n),z=y(e),d=r(e,"P",{});var m=a(d);Z=i(m,"Hugging Face Endpoints\u2019 base image includes all required libraries to run inference on transformers models, but sometimes that can be too limited. For example, you want to "),q=r(m,"A",{href:!0});var $e=a(q);ee=i($e,"customize your inference pipeline"),$e.forEach(n),te=i(m," and need additional python dependencies or you want to run a model which requires special dependencies or the newest/a fixed version of a library, e.g. "),S=r(m,"CODE",{});var ke=a(S);ne=i(ke,"tapas"),ke.forEach(n),oe=i(m," ("),D=r(m,"CODE",{});var qe=a(D);re=i(qe,"torch-scatter"),qe.forEach(n),ae=i(m,"). Therefore Endpoints support "),H=r(m,"STRONG",{});var Ae=a(H);se=i(Ae,"custom dependencies"),Ae.forEach(n),ie=i(m,"."),m.forEach(n),G=y(e),f=r(e,"P",{});var I=a(f);le=i(I,"To add custom dependencies add a "),T=r(I,"CODE",{});var Pe=a(T);b=r(Pe,"A",{href:!0,rel:!0});var Ie=a(b);de=i(Ie,"requirements.txt"),Ie.forEach(n),Pe.forEach(n),ce=i(I," file to your model repository on the Hugging Face Hub with the Python dependencies you want to install. When your Endpoint and Image artifacts are created, Inference Endpoints will check if the Model Repository contains a "),F=r(I,"CODE",{});var Ce=a(F);ue=i(Ce,"requirements.txt "),Ce.forEach(n),fe=i(I,"file and installs the dependencies."),I.forEach(n),B=y(e),Ne(x.$$.fragment,e),U=y(e),A=r(e,"P",{});var Oe=a(A);L=r(Oe,"STRONG",{});var Se=a(L);me=i(Se,"Examples:"),Se.forEach(n),Oe.forEach(n),W=y(e),v=r(e,"UL",{});var Q=a(v);M=r(Q,"LI",{});var De=a(M);$=r(De,"A",{href:!0,rel:!0});var He=a($);pe=i(He,"Optimum and onnxruntime"),He.forEach(n),De.forEach(n),he=y(Q),N=r(Q,"LI",{});var Te=a(N);k=r(Te,"A",{href:!0,rel:!0});var Fe=a(k);_e=i(Fe,"diffusers"),Fe.forEach(n),Te.forEach(n),Q.forEach(n),J=y(e),w=r(e,"P",{});var V=a(w);ye=i(V,"If you need further customization you can "),P=r(V,"A",{href:!0});var Le=a(P);Ee=i(Le,"use your own custom container"),Le.forEach(n),ve=i(V," for inference."),V.forEach(n),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(Ze)),c(E,"id","add-custom-dependencies"),c(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E,"href","#add-custom-dependencies"),c(h,"class","relative group"),c(q,"href","/docs/inference-endpoints/guides/custom_handler"),c(b,"href","https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/requirements.txt"),c(b,"rel","nofollow"),c($,"href","https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/requirements.txt"),c($,"rel","nofollow"),c(k,"href","https://huggingface.co/philschmid/stable-diffusion-v1-4-endpoints/blob/main/requirements.txt"),c(k,"rel","nofollow"),c(P,"href","/docs/inference-endpoints/guides/custom_handler")},m(e,l){t(document.head,p),u(e,R,l),u(e,h,l),t(h,E),t(E,C),Re(g,C,null),t(h,X),t(h,O),t(O,Y),u(e,z,l),u(e,d,l),t(d,Z),t(d,q),t(q,ee),t(d,te),t(d,S),t(S,ne),t(d,oe),t(d,D),t(D,re),t(d,ae),t(d,H),t(H,se),t(d,ie),u(e,G,l),u(e,f,l),t(f,le),t(f,T),t(T,b),t(b,de),t(f,ce),t(f,F),t(F,ue),t(f,fe),u(e,B,l),Re(x,e,l),u(e,U,l),u(e,A,l),t(A,L),t(L,me),u(e,W,l),u(e,v,l),t(v,M),t(M,$),t($,pe),t(v,he),t(v,N),t(N,k),t(k,_e),u(e,J,l),u(e,w,l),t(w,ye),t(w,P),t(P,Ee),t(w,ve),j=!0},p:Ke,i(e){j||(ze(g.$$.fragment,e),ze(x.$$.fragment,e),j=!0)},o(e){Ge(g.$$.fragment,e),Ge(x.$$.fragment,e),j=!1},d(e){n(p),e&&n(R),e&&n(h),Be(g),e&&n(z),e&&n(d),e&&n(G),e&&n(f),e&&n(B),Be(x,e),e&&n(U),e&&n(A),e&&n(W),e&&n(v),e&&n(J),e&&n(w)}}}const Ze={local:"add-custom-dependencies",title:"Add custom Dependencies"};function et(we){return Qe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rt extends Ue{constructor(p){super();We(this,p,et,Ye,Je,{})}}export{rt as default,Ze as metadata};
