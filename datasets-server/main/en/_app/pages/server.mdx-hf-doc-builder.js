import{S as sr,i as ar,s as or,e as s,k as u,w as De,t as i,M as nr,c as a,d as t,m as c,a as o,x as Ce,h as l,b as f,G as r,g as h,y as Oe,L as ir,q as Le,o as Ne,B as We,v as lr}from"../chunks/vendor-hf-doc-builder.js";import{I as Me}from"../chunks/IconCopyLink-hf-doc-builder.js";function hr(jt){let m,he,v,E,F,A,He,Y,Je,ue,C,Ue,ce,y,B,Fe,Ye,G,Be,fe,O,Ge,pe,L,Re,de,b,k,R,S,ze,z,Ke,me,N,Qe,ve,W,Ve,be,$,g,K,Xe,Ze,Q,et,tt,rt,q,V,st,at,X,ot,nt,we,p,it,Z,lt,ht,ee,ut,ct,_e,w,j,te,x,ft,re,pt,Ee,M,dt,ye,P,mt,I,vt,bt,ke,_,T,se,D,wt,ae,_t,$e,d,Et,oe,yt,kt,ne,$t,gt,ge,H,qt,qe;return A=new Me({}),S=new Me({}),x=new Me({}),D=new Me({}),{c(){m=s("meta"),he=u(),v=s("h1"),E=s("a"),F=s("span"),De(A.$$.fragment),He=u(),Y=s("span"),Je=i("Server infrastructure"),ue=u(),C=s("p"),Ue=i("The Datasets Server has two main components that work together to return queries about a dataset instantly:"),ce=u(),y=s("ul"),B=s("li"),Fe=i("a user-facing web API for exploring and returning information about a dataset"),Ye=u(),G=s("li"),Be=i("a server runs the queries ahead of time and caches them in a database"),fe=u(),O=s("p"),Ge=i("While most of the documentation is focused on the web API, the server is crucial because it performs all the time-consuming preprocessing and stores the results so the web API can retrieve and serve them to the user. This saves a user time because instead of generating the response every time it gets requested, Datasets Server can return the preprocessed results instantly from the cache."),pe=u(),L=s("p"),Re=i("There are three elements that keep the server running: the job queue, workers, and the cache."),de=u(),b=s("h2"),k=s("a"),R=s("span"),De(S.$$.fragment),ze=u(),z=s("span"),Ke=i("Job queue"),me=u(),N=s("p"),Qe=i("The job queue is a list of jobs stored in a Mongo database that should be completed by the workers. The jobs are practically identical to the endpoints the user uses; only the server runs the jobs ahead of time, and the user gets the results when they use the endpoint."),ve=u(),W=s("p"),Ve=i("There are two jobs:"),be=u(),$=s("ul"),g=s("li"),K=s("code"),Xe=i("splits"),Ze=i(" corresponds to the "),Q=s("code"),et=i("/splits"),tt=i(" endpoint. It refreshes a dataset and then returns that dataset\u2019s splits and configurations. For every split in the dataset, it\u2019ll create a new job."),rt=u(),q=s("li"),V=s("code"),st=i("first-rows"),at=i(" corresponds to the "),X=s("code"),ot=i("/first-rows"),nt=i(" endpoint. It gets the first 100 rows and columns of a dataset split."),we=u(),p=s("p"),it=i("You might\u2019ve noticed the "),Z=s("code"),lt=i("/valid"),ht=i(" and "),ee=s("code"),ut=i("/is-valid"),ct=i(" endpoints don\u2019t have a job in the queue. The responses from these endpoints are generated on demand."),_e=u(),w=s("h2"),j=s("a"),te=s("span"),De(x.$$.fragment),ft=u(),re=s("span"),pt=i("Workers"),Ee=u(),M=s("p"),dt=i("Workers are responsible for executing the jobs in the queue. They complete the actual preprocessing requests, such as getting a list of splits and configurations. The workers can be controlled by configurable environment variables, like the minimum or the maximum number of rows returned by a worker or the maximum number of jobs to start per dataset."),ye=u(),P=s("p"),mt=i("Take a look at the "),I=s("a"),vt=i("worker configuration"),bt=i(" for a complete list of the environment variables if you\u2019re interested in learning more."),ke=u(),_=s("h2"),T=s("a"),se=s("span"),De(D.$$.fragment),wt=u(),ae=s("span"),_t=i("Cache"),$e=u(),d=s("p"),Et=i("Once the workers complete a job, the results are stored - or "),oe=s("em"),yt=i("cached"),kt=i(" - in a Mongo database. When a user makes a request with an endpoint like "),ne=s("code"),$t=i("/first-rows"),gt=i(", Datasets Server retrieves the preprocessed response from the cache, and serves it to the user. This eliminates the time a user would\u2019ve waited if the server hadn\u2019t already completed the job and stored the response."),ge=u(),H=s("p"),qt=i("As a result, users can get their requested information about a dataset (even large ones) nearly instantaneously!"),this.h()},l(e){const n=nr('[data-svelte="svelte-1phssyn"]',document.head);m=a(n,"META",{name:!0,content:!0}),n.forEach(t),he=c(e),v=a(e,"H1",{class:!0});var je=o(v);E=a(je,"A",{id:!0,class:!0,href:!0});var Pt=o(E);F=a(Pt,"SPAN",{});var Tt=o(F);Ce(A.$$.fragment,Tt),Tt.forEach(t),Pt.forEach(t),He=c(je),Y=a(je,"SPAN",{});var At=o(Y);Je=l(At,"Server infrastructure"),At.forEach(t),je.forEach(t),ue=c(e),C=a(e,"P",{});var St=o(C);Ue=l(St,"The Datasets Server has two main components that work together to return queries about a dataset instantly:"),St.forEach(t),ce=c(e),y=a(e,"UL",{});var Pe=o(y);B=a(Pe,"LI",{});var xt=o(B);Fe=l(xt,"a user-facing web API for exploring and returning information about a dataset"),xt.forEach(t),Ye=c(Pe),G=a(Pe,"LI",{});var It=o(G);Be=l(It,"a server runs the queries ahead of time and caches them in a database"),It.forEach(t),Pe.forEach(t),fe=c(e),O=a(e,"P",{});var Dt=o(O);Ge=l(Dt,"While most of the documentation is focused on the web API, the server is crucial because it performs all the time-consuming preprocessing and stores the results so the web API can retrieve and serve them to the user. This saves a user time because instead of generating the response every time it gets requested, Datasets Server can return the preprocessed results instantly from the cache."),Dt.forEach(t),pe=c(e),L=a(e,"P",{});var Ct=o(L);Re=l(Ct,"There are three elements that keep the server running: the job queue, workers, and the cache."),Ct.forEach(t),de=c(e),b=a(e,"H2",{class:!0});var Te=o(b);k=a(Te,"A",{id:!0,class:!0,href:!0});var Ot=o(k);R=a(Ot,"SPAN",{});var Lt=o(R);Ce(S.$$.fragment,Lt),Lt.forEach(t),Ot.forEach(t),ze=c(Te),z=a(Te,"SPAN",{});var Nt=o(z);Ke=l(Nt,"Job queue"),Nt.forEach(t),Te.forEach(t),me=c(e),N=a(e,"P",{});var Wt=o(N);Qe=l(Wt,"The job queue is a list of jobs stored in a Mongo database that should be completed by the workers. The jobs are practically identical to the endpoints the user uses; only the server runs the jobs ahead of time, and the user gets the results when they use the endpoint."),Wt.forEach(t),ve=c(e),W=a(e,"P",{});var Mt=o(W);Ve=l(Mt,"There are two jobs:"),Mt.forEach(t),be=c(e),$=a(e,"UL",{});var Ae=o($);g=a(Ae,"LI",{});var ie=o(g);K=a(ie,"CODE",{});var Ht=o(K);Xe=l(Ht,"splits"),Ht.forEach(t),Ze=l(ie," corresponds to the "),Q=a(ie,"CODE",{});var Jt=o(Q);et=l(Jt,"/splits"),Jt.forEach(t),tt=l(ie," endpoint. It refreshes a dataset and then returns that dataset\u2019s splits and configurations. For every split in the dataset, it\u2019ll create a new job."),ie.forEach(t),rt=c(Ae),q=a(Ae,"LI",{});var le=o(q);V=a(le,"CODE",{});var Ut=o(V);st=l(Ut,"first-rows"),Ut.forEach(t),at=l(le," corresponds to the "),X=a(le,"CODE",{});var Ft=o(X);ot=l(Ft,"/first-rows"),Ft.forEach(t),nt=l(le," endpoint. It gets the first 100 rows and columns of a dataset split."),le.forEach(t),Ae.forEach(t),we=c(e),p=a(e,"P",{});var J=o(p);it=l(J,"You might\u2019ve noticed the "),Z=a(J,"CODE",{});var Yt=o(Z);lt=l(Yt,"/valid"),Yt.forEach(t),ht=l(J," and "),ee=a(J,"CODE",{});var Bt=o(ee);ut=l(Bt,"/is-valid"),Bt.forEach(t),ct=l(J," endpoints don\u2019t have a job in the queue. The responses from these endpoints are generated on demand."),J.forEach(t),_e=c(e),w=a(e,"H2",{class:!0});var Se=o(w);j=a(Se,"A",{id:!0,class:!0,href:!0});var Gt=o(j);te=a(Gt,"SPAN",{});var Rt=o(te);Ce(x.$$.fragment,Rt),Rt.forEach(t),Gt.forEach(t),ft=c(Se),re=a(Se,"SPAN",{});var zt=o(re);pt=l(zt,"Workers"),zt.forEach(t),Se.forEach(t),Ee=c(e),M=a(e,"P",{});var Kt=o(M);dt=l(Kt,"Workers are responsible for executing the jobs in the queue. They complete the actual preprocessing requests, such as getting a list of splits and configurations. The workers can be controlled by configurable environment variables, like the minimum or the maximum number of rows returned by a worker or the maximum number of jobs to start per dataset."),Kt.forEach(t),ye=c(e),P=a(e,"P",{});var xe=o(P);mt=l(xe,"Take a look at the "),I=a(xe,"A",{href:!0,rel:!0});var Qt=o(I);vt=l(Qt,"worker configuration"),Qt.forEach(t),bt=l(xe," for a complete list of the environment variables if you\u2019re interested in learning more."),xe.forEach(t),ke=c(e),_=a(e,"H2",{class:!0});var Ie=o(_);T=a(Ie,"A",{id:!0,class:!0,href:!0});var Vt=o(T);se=a(Vt,"SPAN",{});var Xt=o(se);Ce(D.$$.fragment,Xt),Xt.forEach(t),Vt.forEach(t),wt=c(Ie),ae=a(Ie,"SPAN",{});var Zt=o(ae);_t=l(Zt,"Cache"),Zt.forEach(t),Ie.forEach(t),$e=c(e),d=a(e,"P",{});var U=o(d);Et=l(U,"Once the workers complete a job, the results are stored - or "),oe=a(U,"EM",{});var er=o(oe);yt=l(er,"cached"),er.forEach(t),kt=l(U," - in a Mongo database. When a user makes a request with an endpoint like "),ne=a(U,"CODE",{});var tr=o(ne);$t=l(tr,"/first-rows"),tr.forEach(t),gt=l(U,", Datasets Server retrieves the preprocessed response from the cache, and serves it to the user. This eliminates the time a user would\u2019ve waited if the server hadn\u2019t already completed the job and stored the response."),U.forEach(t),ge=c(e),H=a(e,"P",{});var rr=o(H);qt=l(rr,"As a result, users can get their requested information about a dataset (even large ones) nearly instantaneously!"),rr.forEach(t),this.h()},h(){f(m,"name","hf:doc:metadata"),f(m,"content",JSON.stringify(ur)),f(E,"id","server-infrastructure"),f(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(E,"href","#server-infrastructure"),f(v,"class","relative group"),f(k,"id","job-queue"),f(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(k,"href","#job-queue"),f(b,"class","relative group"),f(j,"id","workers"),f(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(j,"href","#workers"),f(w,"class","relative group"),f(I,"href","https://github.com/huggingface/datasets-server/tree/main/services/worker#configuration"),f(I,"rel","nofollow"),f(T,"id","cache"),f(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(T,"href","#cache"),f(_,"class","relative group")},m(e,n){r(document.head,m),h(e,he,n),h(e,v,n),r(v,E),r(E,F),Oe(A,F,null),r(v,He),r(v,Y),r(Y,Je),h(e,ue,n),h(e,C,n),r(C,Ue),h(e,ce,n),h(e,y,n),r(y,B),r(B,Fe),r(y,Ye),r(y,G),r(G,Be),h(e,fe,n),h(e,O,n),r(O,Ge),h(e,pe,n),h(e,L,n),r(L,Re),h(e,de,n),h(e,b,n),r(b,k),r(k,R),Oe(S,R,null),r(b,ze),r(b,z),r(z,Ke),h(e,me,n),h(e,N,n),r(N,Qe),h(e,ve,n),h(e,W,n),r(W,Ve),h(e,be,n),h(e,$,n),r($,g),r(g,K),r(K,Xe),r(g,Ze),r(g,Q),r(Q,et),r(g,tt),r($,rt),r($,q),r(q,V),r(V,st),r(q,at),r(q,X),r(X,ot),r(q,nt),h(e,we,n),h(e,p,n),r(p,it),r(p,Z),r(Z,lt),r(p,ht),r(p,ee),r(ee,ut),r(p,ct),h(e,_e,n),h(e,w,n),r(w,j),r(j,te),Oe(x,te,null),r(w,ft),r(w,re),r(re,pt),h(e,Ee,n),h(e,M,n),r(M,dt),h(e,ye,n),h(e,P,n),r(P,mt),r(P,I),r(I,vt),r(P,bt),h(e,ke,n),h(e,_,n),r(_,T),r(T,se),Oe(D,se,null),r(_,wt),r(_,ae),r(ae,_t),h(e,$e,n),h(e,d,n),r(d,Et),r(d,oe),r(oe,yt),r(d,kt),r(d,ne),r(ne,$t),r(d,gt),h(e,ge,n),h(e,H,n),r(H,qt),qe=!0},p:ir,i(e){qe||(Le(A.$$.fragment,e),Le(S.$$.fragment,e),Le(x.$$.fragment,e),Le(D.$$.fragment,e),qe=!0)},o(e){Ne(A.$$.fragment,e),Ne(S.$$.fragment,e),Ne(x.$$.fragment,e),Ne(D.$$.fragment,e),qe=!1},d(e){t(m),e&&t(he),e&&t(v),We(A),e&&t(ue),e&&t(C),e&&t(ce),e&&t(y),e&&t(fe),e&&t(O),e&&t(pe),e&&t(L),e&&t(de),e&&t(b),We(S),e&&t(me),e&&t(N),e&&t(ve),e&&t(W),e&&t(be),e&&t($),e&&t(we),e&&t(p),e&&t(_e),e&&t(w),We(x),e&&t(Ee),e&&t(M),e&&t(ye),e&&t(P),e&&t(ke),e&&t(_),We(D),e&&t($e),e&&t(d),e&&t(ge),e&&t(H)}}}const ur={local:"server-infrastructure",sections:[{local:"job-queue",title:"Job queue"},{local:"workers",title:"Workers"},{local:"cache",title:"Cache"}],title:"Server infrastructure"};function cr(jt){return lr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class dr extends sr{constructor(m){super();ar(this,m,cr,hr,or,{})}}export{dr as default,ur as metadata};
