import{S as Wg,i as Bg,s as Gg,e as s,k as l,w as p,t as a,M as Yg,c as n,d as r,m as c,a as o,x as h,h as i,b as d,G as e,g as f,y as m,q as g,o as _,B as v,v as Jg}from"../../chunks/vendor-hf-doc-builder.js";import{T as zg}from"../../chunks/Tip-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as Y}from"../../chunks/IconCopyLink-hf-doc-builder.js";function jg(To){let F,Ee;return{c(){F=s("p"),Ee=a("Score SDE-VP is under construction.")},l(I){F=n(I,"P",{});var X=o(F);Ee=i(X,"Score SDE-VP is under construction."),X.forEach(r)},m(I,X){f(I,F,X),e(F,Ee)},d(I){I&&r(F)}}}function Qg(To){let F,Ee,I,X,Os,bt,gi,ks,_i,Oo,Nr,vi,ko,oe,xe,Vs,St,bi,Cs,Si,Vo,ye,$i,As,Di,Ei,Co,we,Lr,xi,$t,Ns,yi,wi,Ls,Mi,Pi,ae,Ti,Fs,Oi,ki,Is,Vi,Ci,Ao,ie,Me,Ks,Dt,Ai,qs,Ni,No,M,Li,Us,Fi,Ii,Fr,Ki,qi,Ir,Ui,Hi,Hs,Ri,Wi,Kr,Bi,Gi,Rs,Yi,Ji,Lo,de,Pe,Ws,Et,zi,Bs,ji,Fo,qr,Qi,Io,Te,Gs,Xi,Zi,Ys,ed,Ko,le,Oe,Js,xt,td,zs,rd,qo,Ur,sd,Uo,ee,yt,nd,js,od,ad,id,wt,dd,Qs,ld,cd,ud,Xs,fd,Ho,ke,pd,Hr,hd,md,Ro,ce,Ve,Zs,Mt,gd,en,_d,Wo,ue,Pt,vd,tn,bd,Bo,fe,Ce,rn,Tt,Sd,sn,$d,Go,pe,Ot,Dd,nn,Ed,Yo,he,Ae,on,kt,xd,an,yd,Jo,me,Ne,dn,Vt,wd,ln,Md,zo,Rr,Pd,jo,x,Ct,Td,cn,Od,kd,P,Wr,Vd,Cd,un,Ad,Nd,fn,Ld,Fd,pn,Id,Kd,Br,qd,Ud,Gr,Hd,Rd,Yr,Wd,Bd,Gd,Jr,Yd,At,Jd,zd,Le,Nt,jd,hn,Qd,Xd,Fe,Lt,Zd,mn,el,tl,Ie,Ft,rl,gn,sl,Qo,ge,Ke,_n,It,nl,vn,ol,Xo,qe,al,Kt,il,dl,Zo,y,qt,ll,bn,cl,ul,T,zr,fl,pl,Sn,hl,ml,$n,gl,_l,Dn,vl,bl,jr,Sl,$l,Qr,Dl,El,Xr,xl,yl,wl,Zr,Ml,Ut,Pl,Tl,Ue,Ht,Ol,En,kl,Vl,He,Rt,Cl,xn,Al,Nl,Re,Wt,Ll,yn,Fl,ea,_e,We,wn,Bt,Il,Mn,Kl,ta,Be,ql,Gt,Ul,Hl,ra,S,Yt,Rl,Pn,Wl,Bl,Ge,Gl,Jt,Yl,Jl,zt,zl,jl,O,es,Ql,Xl,Tn,Zl,ec,On,tc,rc,kn,sc,nc,ts,oc,ac,rs,ic,dc,ss,lc,cc,uc,jt,fc,Qt,pc,hc,mc,te,Xt,gc,Vn,_c,vc,Cn,bc,Sc,Ye,Zt,$c,An,Dc,Ec,Je,er,xc,Nn,yc,wc,ze,tr,Mc,Ln,Pc,Tc,je,rr,Oc,Fn,kc,sa,ve,Qe,In,sr,Vc,Kn,Cc,na,Xe,Ac,nr,Nc,Lc,oa,w,or,Fc,ns,Ic,ar,Kc,qc,k,os,Uc,Hc,qn,Rc,Wc,Un,Bc,Gc,Hn,Yc,Jc,as,zc,jc,is,Qc,Xc,ds,Zc,eu,tu,Ze,ir,ru,Rn,su,nu,et,dr,ou,lr,au,Wn,iu,du,lu,tt,cr,cu,Bn,uu,fu,rt,ur,pu,Gn,hu,aa,be,st,Yn,fr,mu,Jn,gu,ia,nt,_u,pr,vu,bu,da,$,hr,Su,zn,$u,Du,V,ls,Eu,xu,jn,yu,wu,Qn,Mu,Pu,Xn,Tu,Ou,cs,ku,Vu,us,Cu,Au,fs,Nu,Lu,Fu,ps,Iu,mr,Ku,qu,ot,gr,Uu,Zn,Hu,Ru,at,_r,Wu,eo,Bu,Gu,re,vr,Yu,to,Ju,zu,Z,ju,ro,Qu,Xu,so,Zu,ef,no,tf,rf,sf,it,br,nf,oo,of,af,dt,Sr,df,ao,lf,la,Se,lt,io,$r,cf,lo,uf,ca,ct,ff,Dr,pf,hf,ua,D,Er,mf,co,gf,_f,hs,vf,xr,bf,Sf,C,ms,$f,Df,uo,Ef,xf,fo,yf,wf,po,Mf,Pf,gs,Tf,Of,_s,kf,Vf,vs,Cf,Af,Nf,ut,yr,Lf,ho,Ff,If,se,wr,Kf,mo,qf,Uf,$e,Hf,go,Rf,Wf,_o,Bf,Gf,Yf,ft,Mr,Jf,vo,zf,jf,pt,Pr,Qf,bo,Xf,Zf,ht,Tr,ep,So,tp,fa,De,mt,$o,Or,rp,Do,sp,pa,gt,np,kr,op,ap,ha,_t,ma,K,Vr,ip,Eo,dp,lp,A,bs,cp,up,xo,fp,pp,yo,hp,mp,wo,gp,_p,Ss,vp,bp,$s,Sp,$p,Ds,Dp,Ep,xp,Es,yp,Cr,wp,Mp,Mo,Pp,ga;return bt=new Y({}),St=new Y({}),Dt=new Y({}),Et=new Y({}),xt=new Y({}),Mt=new Y({}),Pt=new b({props:{name:"class diffusers.SchedulerMixin",anchor:"diffusers.SchedulerMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L38"}}),Tt=new Y({}),Ot=new b({props:{name:"class diffusers.schedulers.scheduling_utils.SchedulerOutput",anchor:"diffusers.schedulers.scheduling_utils.SchedulerOutput",parameters:[{name:"prev_sample",val:": FloatTensor"}],parametersDescription:[{anchor:"diffusers.schedulers.scheduling_utils.SchedulerOutput.prev_sample",description:`<strong>prev_sample</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_channels, height, width)</code> for images) &#x2014;
Computed sample (x_{t-1}) of previous timestep. <code>prev_sample</code> should be used as next model input in the
denoising loop.`,name:"prev_sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L25"}}),kt=new Y({}),Vt=new Y({}),Ct=new b({props:{name:"class diffusers.DDIMScheduler",anchor:"diffusers.DDIMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"clip_sample",val:": bool = True"},{name:"set_alpha_to_one",val:": bool = True"},{name:"steps_offset",val:": int = 0"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.DDIMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.DDIMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.DDIMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.DDIMScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"},{anchor:"diffusers.DDIMScheduler.clip_sample",description:`<strong>clip_sample</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
option to clip predicted sample between -1 and 1 for numerical stability.`,name:"clip_sample"},{anchor:"diffusers.DDIMScheduler.set_alpha_to_one",description:`<strong>set_alpha_to_one</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
each diffusion step uses the value of alphas product at that step and at the previous one. For the final
step there is no previous alpha. When this option is <code>True</code> the previous alpha product is fixed to <code>1</code>,
otherwise it uses the value of alpha at step 0.`,name:"set_alpha_to_one"},{anchor:"diffusers.DDIMScheduler.steps_offset",description:`<strong>steps_offset</strong> (<code>int</code>, default <code>0</code>) &#x2014;
an offset added to the inference steps. You can use a combination of <code>offset=1</code> and
<code>set_alpha_to_one=False</code>, to make the last step use step 0 for the previous alpha product, as done in
stable diffusion.`,name:"steps_offset"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L77"}}),Nt=new b({props:{name:"scale_model_input",anchor:"diffusers.DDIMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.DDIMScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L162",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Lt=new b({props:{name:"set_timesteps",anchor:"diffusers.DDIMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L186"}}),Ft=new b({props:{name:"step",anchor:"diffusers.DDIMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"eta",val:": float = 0.0"},{name:"use_clipped_model_output",val:": bool = False"},{name:"generator",val:" = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.DDIMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.DDIMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.DDIMScheduler.step.eta",description:"<strong>eta</strong> (<code>float</code>) &#x2014; weight of noise for added noise in diffusion step.",name:"eta"},{anchor:"diffusers.DDIMScheduler.step.use_clipped_model_output",description:`<strong>use_clipped_model_output</strong> (<code>bool</code>) &#x2014; TODO
generator &#x2014; random number generator.`,name:"use_clipped_model_output"},{anchor:"diffusers.DDIMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than DDIMSchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L207",returnDescription:`
<p><code>DDIMSchedulerOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>DDIMSchedulerOutput</code> or <code>tuple</code></p>
`}}),It=new Y({}),qt=new b({props:{name:"class diffusers.DDPMScheduler",anchor:"diffusers.DDPMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"variance_type",val:": str = 'fixed_small'"},{name:"clip_sample",val:": bool = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.DDPMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.DDPMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.DDPMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.DDPMScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"},{anchor:"diffusers.DDPMScheduler.variance_type",description:`<strong>variance_type</strong> (<code>str</code>) &#x2014;
options to clip the variance used when adding noise to the denoised sample. Choose from <code>fixed_small</code>,
<code>fixed_small_log</code>, <code>fixed_large</code>, <code>fixed_large_log</code>, <code>learned</code> or <code>learned_range</code>.`,name:"variance_type"},{anchor:"diffusers.DDPMScheduler.clip_sample",description:`<strong>clip_sample</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
option to clip predicted sample between -1 and 1 for numerical stability.`,name:"clip_sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L76"}}),Ht=new b({props:{name:"scale_model_input",anchor:"diffusers.DDPMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.DDPMScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L152",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Rt=new b({props:{name:"set_timesteps",anchor:"diffusers.DDPMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L166"}}),Wt=new b({props:{name:"step",anchor:"diffusers.DDPMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"predict_epsilon",val:" = True"},{name:"generator",val:" = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.DDPMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.DDPMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.DDPMScheduler.step.predict_epsilon",description:`<strong>predict_epsilon</strong> (<code>bool</code>) &#x2014;
optional flag to use when model predicts the samples directly instead of the noise, epsilon.
generator &#x2014; random number generator.`,name:"predict_epsilon"},{anchor:"diffusers.DDPMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than DDPMSchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L214",returnDescription:`
<p><code>DDPMSchedulerOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>DDPMSchedulerOutput</code> or <code>tuple</code></p>
`}}),Bt=new Y({}),Yt=new b({props:{name:"class diffusers.KarrasVeScheduler",anchor:"diffusers.KarrasVeScheduler",parameters:[{name:"sigma_min",val:": float = 0.02"},{name:"sigma_max",val:": float = 100"},{name:"s_noise",val:": float = 1.007"},{name:"s_churn",val:": float = 80"},{name:"s_min",val:": float = 0.05"},{name:"s_max",val:": float = 50"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.sigma_min",description:"<strong>sigma_min</strong> (<code>float</code>) &#x2014; minimum noise magnitude",name:"sigma_min"},{anchor:"diffusers.KarrasVeScheduler.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>) &#x2014; maximum noise magnitude",name:"sigma_max"},{anchor:"diffusers.KarrasVeScheduler.s_noise",description:`<strong>s_noise</strong> (<code>float</code>) &#x2014; the amount of additional noise to counteract loss of detail during sampling.
A reasonable range is [1.000, 1.011].`,name:"s_noise"},{anchor:"diffusers.KarrasVeScheduler.s_churn",description:`<strong>s_churn</strong> (<code>float</code>) &#x2014; the parameter controlling the overall amount of stochasticity.
A reasonable range is [0, 100].`,name:"s_churn"},{anchor:"diffusers.KarrasVeScheduler.s_min",description:`<strong>s_min</strong> (<code>float</code>) &#x2014; the start value of the sigma range where we add noise (enable stochasticity).
A reasonable range is [0, 10].`,name:"s_min"},{anchor:"diffusers.KarrasVeScheduler.s_max",description:`<strong>s_max</strong> (<code>float</code>) &#x2014; the end value of the sigma range where we add noise.
A reasonable range is [0.2, 80].`,name:"s_max"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L48"}}),Xt=new b({props:{name:"add_noise_to_input",anchor:"diffusers.KarrasVeScheduler.add_noise_to_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"sigma",val:": float"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L141"}}),Zt=new b({props:{name:"scale_model_input",anchor:"diffusers.KarrasVeScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.KarrasVeScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L106",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),er=new b({props:{name:"set_timesteps",anchor:"diffusers.KarrasVeScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L120"}}),tr=new b({props:{name:"step",anchor:"diffusers.KarrasVeScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"sigma_hat",val:": float"},{name:"sigma_prev",val:": float"},{name:"sample_hat",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.KarrasVeScheduler.step.sigma_hat",description:"<strong>sigma_hat</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_hat"},{anchor:"diffusers.KarrasVeScheduler.step.sigma_prev",description:"<strong>sigma_prev</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_prev"},{anchor:"diffusers.KarrasVeScheduler.step.sample_hat",description:"<strong>sample_hat</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"sample_hat"},{anchor:"diffusers.KarrasVeScheduler.step.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than KarrasVeOutput class</p>
<p>KarrasVeOutput &#x2014; updated sample in the diffusion chain and derivative (TODO double check).`,name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L162",returnDescription:`
<p><code>KarrasVeOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>KarrasVeOutput</code> or <code>tuple</code></p>
`}}),rr=new b({props:{name:"step_correct",anchor:"diffusers.KarrasVeScheduler.step_correct",parameters:[{name:"model_output",val:": FloatTensor"},{name:"sigma_hat",val:": float"},{name:"sigma_prev",val:": float"},{name:"sample_hat",val:": FloatTensor"},{name:"sample_prev",val:": FloatTensor"},{name:"derivative",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.step_correct.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sigma_hat",description:"<strong>sigma_hat</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_hat"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sigma_prev",description:"<strong>sigma_prev</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_prev"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sample_hat",description:"<strong>sample_hat</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"sample_hat"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sample_prev",description:"<strong>sample_prev</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"sample_prev"},{anchor:"diffusers.KarrasVeScheduler.step_correct.derivative",description:"<strong>derivative</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"derivative"},{anchor:"diffusers.KarrasVeScheduler.step_correct.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than KarrasVeOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L200",returnDescription:`
<p>updated sample in the diffusion chain. derivative (TODO): TODO</p>
`,returnType:`
<p>prev_sample (TODO)</p>
`}}),sr=new Y({}),or=new b({props:{name:"class diffusers.LMSDiscreteScheduler",anchor:"diffusers.LMSDiscreteScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.LMSDiscreteScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.LMSDiscreteScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.LMSDiscreteScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code> or <code>scaled_linear</code>.`,name:"beta_schedule"},{anchor:"diffusers.LMSDiscreteScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L46"}}),ir=new b({props:{name:"get_lms_coefficient",anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient",parameters:[{name:"order",val:""},{name:"t",val:""},{name:"current_order",val:""}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.order",description:"<strong>order</strong> (TODO) &#x2014;",name:"order"},{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.t",description:"<strong>t</strong> (TODO) &#x2014;",name:"t"},{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.current_order",description:"<strong>current_order</strong> (TODO) &#x2014;",name:"current_order"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L136"}}),dr=new b({props:{name:"scale_model_input",anchor:"diffusers.LMSDiscreteScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Union[float, torch.FloatTensor]"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.LMSDiscreteScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>float</code> or <code>torch.FloatTensor</code>) &#x2014; the current timestep in the diffusion chain",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L115",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),cr=new b({props:{name:"set_timesteps",anchor:"diffusers.LMSDiscreteScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.LMSDiscreteScheduler.set_timesteps.device",description:`<strong>device</strong> (<code>str</code> or <code>torch.device</code>, optional) &#x2014;
the device to which the timesteps should be moved to. If <code>None</code>, the timesteps are not moved.`,name:"device"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L158"}}),ur=new b({props:{name:"step",anchor:"diffusers.LMSDiscreteScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": typing.Union[float, torch.FloatTensor]"},{name:"sample",val:": FloatTensor"},{name:"order",val:": int = 4"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.LMSDiscreteScheduler.step.timestep",description:"<strong>timestep</strong> (<code>float</code>) &#x2014; current timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.LMSDiscreteScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.
order &#x2014; coefficient for multi-step inference.`,name:"sample"},{anchor:"diffusers.LMSDiscreteScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than LMSDiscreteSchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L179",returnDescription:`
<p><code>LMSDiscreteSchedulerOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>.
When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>LMSDiscreteSchedulerOutput</code> or <code>tuple</code></p>
`}}),fr=new Y({}),hr=new b({props:{name:"class diffusers.PNDMScheduler",anchor:"diffusers.PNDMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"skip_prk_steps",val:": bool = False"},{name:"set_alpha_to_one",val:": bool = False"},{name:"steps_offset",val:": int = 0"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.PNDMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.PNDMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.PNDMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.PNDMScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"},{anchor:"diffusers.PNDMScheduler.skip_prk_steps",description:`<strong>skip_prk_steps</strong> (<code>bool</code>) &#x2014;
allows the scheduler to skip the Runge-Kutta steps that are defined in the original paper as being required
before plms steps; defaults to <code>False</code>.`,name:"skip_prk_steps"},{anchor:"diffusers.PNDMScheduler.set_alpha_to_one",description:`<strong>set_alpha_to_one</strong> (<code>bool</code>, default <code>False</code>) &#x2014;
each diffusion step uses the value of alphas product at that step and at the previous one. For the final
step there is no previous alpha. When this option is <code>True</code> the previous alpha product is fixed to <code>1</code>,
otherwise it uses the value of alpha at step 0.`,name:"set_alpha_to_one"},{anchor:"diffusers.PNDMScheduler.steps_offset",description:`<strong>steps_offset</strong> (<code>int</code>, default <code>0</code>) &#x2014;
an offset added to the inference steps. You can use a combination of <code>offset=1</code> and
<code>set_alpha_to_one=False</code>, to make the last step use step 0 for the previous alpha product, as done in
stable diffusion.`,name:"steps_offset"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L57"}}),gr=new b({props:{name:"scale_model_input",anchor:"diffusers.PNDMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L348",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),_r=new b({props:{name:"set_timesteps",anchor:"diffusers.PNDMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L153"}}),vr=new b({props:{name:"step",anchor:"diffusers.PNDMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L196",returnDescription:`
<p><a
  href="/docs/diffusers/main/en/api/schedulers#diffusers.schedulers.scheduling_utils.SchedulerOutput"
>SchedulerOutput</a> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><a
  href="/docs/diffusers/main/en/api/schedulers#diffusers.schedulers.scheduling_utils.SchedulerOutput"
>SchedulerOutput</a> or <code>tuple</code></p>
`}}),br=new b({props:{name:"step_plms",anchor:"diffusers.PNDMScheduler.step_plms",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step_plms.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step_plms.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step_plms.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step_plms.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L282",returnDescription:`
<p><code>SchedulerOutput</code> if <code>return_dict</code> is
True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>SchedulerOutput</code> or <code>tuple</code></p>
`}}),Sr=new b({props:{name:"step_prk",anchor:"diffusers.PNDMScheduler.step_prk",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step_prk.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step_prk.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step_prk.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step_prk.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L227",returnDescription:`
<p><code>SchedulerOutput</code> if <code>return_dict</code> is
True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>SchedulerOutput</code> or <code>tuple</code></p>
`}}),$r=new Y({}),Er=new b({props:{name:"class diffusers.ScoreSdeVeScheduler",anchor:"diffusers.ScoreSdeVeScheduler",parameters:[{name:"num_train_timesteps",val:": int = 2000"},{name:"snr",val:": float = 0.15"},{name:"sigma_min",val:": float = 0.01"},{name:"sigma_max",val:": float = 1348.0"},{name:"sampling_eps",val:": float = 1e-05"},{name:"correct_steps",val:": int = 1"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.ScoreSdeVeScheduler.snr",description:`<strong>snr</strong> (<code>float</code>) &#x2014;
coefficient weighting the step from the model_output sample (from the network) to the random noise.`,name:"snr"},{anchor:"diffusers.ScoreSdeVeScheduler.sigma_min",description:`<strong>sigma_min</strong> (<code>float</code>) &#x2014;
initial noise scale for sigma sequence in sampling procedure. The minimum sigma should mirror the
distribution of the data.`,name:"sigma_min"},{anchor:"diffusers.ScoreSdeVeScheduler.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>) &#x2014; maximum value used for the range of continuous timesteps passed into the model.",name:"sigma_max"},{anchor:"diffusers.ScoreSdeVeScheduler.sampling_eps",description:`<strong>sampling_eps</strong> (<code>float</code>) &#x2014; the end value of sampling, where timesteps decrease progressively from 1 to
epsilon. &#x2014;`,name:"sampling_eps"},{anchor:"diffusers.ScoreSdeVeScheduler.correct_steps",description:"<strong>correct_steps</strong> (<code>int</code>) &#x2014; number of correction steps performed on a produced sample.",name:"correct_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L45"}}),yr=new b({props:{name:"scale_model_input",anchor:"diffusers.ScoreSdeVeScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L95",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),wr=new b({props:{name:"set_sigmas",anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas",parameters:[{name:"num_inference_steps",val:": int"},{name:"sigma_min",val:": float = None"},{name:"sigma_max",val:": float = None"},{name:"sampling_eps",val:": float = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sigma_min",description:`<strong>sigma_min</strong> (<code>float</code>, optional) &#x2014;
initial noise scale value (overrides value given at Scheduler instantiation).`,name:"sigma_min"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>, optional) &#x2014; final noise scale value (overrides value given at Scheduler instantiation).",name:"sigma_max"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sampling_eps",description:"<strong>sampling_eps</strong> (<code>float</code>, optional) &#x2014; final timestep value (overrides value given at Scheduler instantiation).",name:"sampling_eps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L125"}}),Mr=new b({props:{name:"set_timesteps",anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"sampling_eps",val:": float = None"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps.sampling_eps",description:"<strong>sampling_eps</strong> (<code>float</code>, optional) &#x2014; final timestep value (overrides value given at Scheduler instantiation).",name:"sampling_eps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L109"}}),Pr=new b({props:{name:"step_correct",anchor:"diffusers.ScoreSdeVeScheduler.step_correct",parameters:[{name:"model_output",val:": FloatTensor"},{name:"sample",val:": FloatTensor"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"},{name:"return_dict",val:": bool = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.
generator &#x2014; random number generator.`,name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L228",returnDescription:`
<p><code>SdeVeOutput</code> if
<code>return_dict</code> is True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>SdeVeOutput</code> or <code>tuple</code></p>
`}}),Tr=new b({props:{name:"step_pred",anchor:"diffusers.ScoreSdeVeScheduler.step_pred",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"},{name:"return_dict",val:": bool = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.
generator &#x2014; random number generator.`,name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L163",returnDescription:`
<p><code>SdeVeOutput</code> if
<code>return_dict</code> is True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>SdeVeOutput</code> or <code>tuple</code></p>
`}}),Or=new Y({}),_t=new zg({props:{warning:!0,$$slots:{default:[jg]},$$scope:{ctx:To}}}),Vr=new b({props:{name:"class diffusers.schedulers.ScoreSdeVpScheduler",anchor:"diffusers.schedulers.ScoreSdeVpScheduler",parameters:[{name:"num_train_timesteps",val:" = 2000"},{name:"beta_min",val:" = 0.1"},{name:"beta_max",val:" = 20"},{name:"sampling_eps",val:" = 0.001"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_vp.py#L27"}}),{c(){F=s("meta"),Ee=l(),I=s("h1"),X=s("a"),Os=s("span"),p(bt.$$.fragment),gi=l(),ks=s("span"),_i=a("Schedulers"),Oo=l(),Nr=s("p"),vi=a("Diffusers contains multiple pre-built schedule functions for the diffusion process."),ko=l(),oe=s("h2"),xe=s("a"),Vs=s("span"),p(St.$$.fragment),bi=l(),Cs=s("span"),Si=a("What is a scheduler?"),Vo=l(),ye=s("p"),$i=a("The schedule functions, denoted "),As=s("em"),Di=a("Schedulers"),Ei=a(" in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample."),Co=l(),we=s("ul"),Lr=s("li"),xi=a("Schedulers define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs."),$t=s("ul"),Ns=s("li"),yi=a("adding noise in different manners represent the algorithmic processes to train a diffusion model by adding noise to images."),wi=l(),Ls=s("li"),Mi=a("for inference, the scheduler defines how to update a sample based on an output from a pretrained model."),Pi=l(),ae=s("li"),Ti=a("Schedulers are often defined by a "),Fs=s("em"),Oi=a("noise schedule"),ki=a(" and an "),Is=s("em"),Vi=a("update rule"),Ci=a(" to solve the differential equation solution."),Ao=l(),ie=s("h3"),Me=s("a"),Ks=s("span"),p(Dt.$$.fragment),Ai=l(),qs=s("span"),Ni=a("Discrete versus continuous schedulers"),No=l(),M=s("p"),Li=a(`All schedulers take in a timestep to predict the updated version of the sample being diffused.
The timesteps dictate where in the diffusion process the step is, where data is generated by iterating forward in time and inference is executed by propagating backwards through timesteps.
Different algorithms use timesteps that both discrete (accepting `),Us=s("code"),Fi=a("int"),Ii=a(" inputs), such as the "),Fr=s("a"),Ki=a("DDPMScheduler"),qi=a(" or "),Ir=s("a"),Ui=a("PNDMScheduler"),Hi=a(", and continuous (accepting "),Hs=s("code"),Ri=a("float"),Wi=a(" inputs), such as the score-based schedulers "),Kr=s("a"),Bi=a("ScoreSdeVeScheduler"),Gi=a(" or "),Rs=s("code"),Yi=a("ScoreSdeVpScheduler"),Ji=a("."),Lo=l(),de=s("h2"),Pe=s("a"),Ws=s("span"),p(Et.$$.fragment),zi=l(),Bs=s("span"),ji=a("Designing Re-usable schedulers"),Fo=l(),qr=s("p"),Qi=a(`The core design principle between the schedule functions is to be model, system, and framework independent.
This allows for rapid experimentation and cleaner abstractions in the code, where the model prediction is separated from the sample update.
To this end, the design of schedulers is such that:`),Io=l(),Te=s("ul"),Gs=s("li"),Xi=a("Schedulers can be used interchangeably between diffusion models in inference to find the preferred trade-off between speed and generation quality."),Zi=l(),Ys=s("li"),ed=a("Schedulers are currently by default in PyTorch, but are designed to be framework independent (partial Jax support currently exists)."),Ko=l(),le=s("h2"),Oe=s("a"),Js=s("span"),p(xt.$$.fragment),td=l(),zs=s("span"),rd=a("API"),qo=l(),Ur=s("p"),sd=a("The core API for any new scheduler must follow a limited structure."),Uo=l(),ee=s("ul"),yt=s("li"),nd=a("Schedulers should provide one or more "),js=s("code"),od=a("def step(...)"),ad=a(" functions that should be called to update the generated sample iteratively."),id=l(),wt=s("li"),dd=a("Schedulers should provide a "),Qs=s("code"),ld=a("set_timesteps(...)"),cd=a(" method that configures the parameters of a schedule function for a specific inference task."),ud=l(),Xs=s("li"),fd=a("Schedulers should be framework-specific."),Ho=l(),ke=s("p"),pd=a("The base class "),Hr=s("a"),hd=a("SchedulerMixin"),md=a(" implements low level utilities used by multiple schedulers."),Ro=l(),ce=s("h3"),Ve=s("a"),Zs=s("span"),p(Mt.$$.fragment),gd=l(),en=s("span"),_d=a("SchedulerMixin"),Wo=l(),ue=s("div"),p(Pt.$$.fragment),vd=l(),tn=s("p"),bd=a("Mixin containing common functions for the schedulers."),Bo=l(),fe=s("h3"),Ce=s("a"),rn=s("span"),p(Tt.$$.fragment),Sd=l(),sn=s("span"),$d=a("SchedulerOutput"),Go=a("\n\nThe class `SchedulerOutput` contains the outputs from any schedulers `step(...)` call.\n"),pe=s("div"),p(Ot.$$.fragment),Dd=l(),nn=s("p"),Ed=a("Base class for the scheduler\u2019s step function output."),Yo=l(),he=s("h3"),Ae=s("a"),on=s("span"),p(kt.$$.fragment),xd=l(),an=s("span"),yd=a("Implemented Schedulers"),Jo=l(),me=s("h4"),Ne=s("a"),dn=s("span"),p(Vt.$$.fragment),wd=l(),ln=s("span"),Md=a("Denoising diffusion implicit models (DDIM)"),zo=l(),Rr=s("p"),Pd=a("Original paper can be found here."),jo=l(),x=s("div"),p(Ct.$$.fragment),Td=l(),cn=s("p"),Od=a(`Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising
diffusion probabilistic models (DDPMs) with non-Markovian guidance.`),kd=l(),P=s("p"),Wr=s("a"),Vd=a("~ConfigMixin"),Cd=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),un=s("code"),Ad=a("__init__"),Nd=a(`
function, such as `),fn=s("code"),Ld=a("num_train_timesteps"),Fd=a(". They can be accessed via "),pn=s("code"),Id=a("scheduler.config.num_train_timesteps"),Kd=a(`.
`),Br=s("a"),qd=a("~ConfigMixin"),Ud=a(" also provides general loading and saving functionality via the "),Gr=s("a"),Hd=a("save_config()"),Rd=a(` and
`),Yr=s("a"),Wd=a("from_config()"),Bd=a(" functions."),Gd=l(),Jr=s("p"),Yd=a("For more details, see the original paper: "),At=s("a"),Jd=a("https://arxiv.org/abs/2010.02502"),zd=l(),Le=s("div"),p(Nt.$$.fragment),jd=l(),hn=s("p"),Qd=a(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Xd=l(),Fe=s("div"),p(Lt.$$.fragment),Zd=l(),mn=s("p"),el=a("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),tl=l(),Ie=s("div"),p(Ft.$$.fragment),rl=l(),gn=s("p"),sl=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Qo=l(),ge=s("h4"),Ke=s("a"),_n=s("span"),p(It.$$.fragment),nl=l(),vn=s("span"),ol=a("Denoising diffusion probabilistic models (DDPM)"),Xo=l(),qe=s("p"),al=a("Original paper can be found "),Kt=s("a"),il=a("here"),dl=a("."),Zo=l(),y=s("div"),p(qt.$$.fragment),ll=l(),bn=s("p"),cl=a(`Denoising diffusion probabilistic models (DDPMs) explores the connections between denoising score matching and
Langevin dynamics sampling.`),ul=l(),T=s("p"),zr=s("a"),fl=a("~ConfigMixin"),pl=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),Sn=s("code"),hl=a("__init__"),ml=a(`
function, such as `),$n=s("code"),gl=a("num_train_timesteps"),_l=a(". They can be accessed via "),Dn=s("code"),vl=a("scheduler.config.num_train_timesteps"),bl=a(`.
`),jr=s("a"),Sl=a("~ConfigMixin"),$l=a(" also provides general loading and saving functionality via the "),Qr=s("a"),Dl=a("save_config()"),El=a(` and
`),Xr=s("a"),xl=a("from_config()"),yl=a(" functions."),wl=l(),Zr=s("p"),Ml=a("For more details, see the original paper: "),Ut=s("a"),Pl=a("https://arxiv.org/abs/2006.11239"),Tl=l(),Ue=s("div"),p(Ht.$$.fragment),Ol=l(),En=s("p"),kl=a(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Vl=l(),He=s("div"),p(Rt.$$.fragment),Cl=l(),xn=s("p"),Al=a("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Nl=l(),Re=s("div"),p(Wt.$$.fragment),Ll=l(),yn=s("p"),Fl=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),ea=l(),_e=s("h4"),We=s("a"),wn=s("span"),p(Bt.$$.fragment),Il=l(),Mn=s("span"),Kl=a("Variance exploding, stochastic sampling from Karras et. al"),ta=l(),Be=s("p"),ql=a("Original paper can be found "),Gt=s("a"),Ul=a("here"),Hl=a("."),ra=l(),S=s("div"),p(Yt.$$.fragment),Rl=l(),Pn=s("p"),Wl=a(`Stochastic sampling from Karras et al. [1] tailored to the Variance-Expanding (VE) models [2]. Use Algorithm 2 and
the VE column of Table 1 from [1] for reference.`),Bl=l(),Ge=s("p"),Gl=a(`[1] Karras, Tero, et al. \u201CElucidating the Design Space of Diffusion-Based Generative Models.\u201D
`),Jt=s("a"),Yl=a("https://arxiv.org/abs/2206.00364"),Jl=a(` [2] Song, Yang, et al. \u201CScore-based generative modeling through stochastic
differential equations.\u201D `),zt=s("a"),zl=a("https://arxiv.org/abs/2011.13456"),jl=l(),O=s("p"),es=s("a"),Ql=a("~ConfigMixin"),Xl=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),Tn=s("code"),Zl=a("__init__"),ec=a(`
function, such as `),On=s("code"),tc=a("num_train_timesteps"),rc=a(". They can be accessed via "),kn=s("code"),sc=a("scheduler.config.num_train_timesteps"),nc=a(`.
`),ts=s("a"),oc=a("~ConfigMixin"),ac=a(" also provides general loading and saving functionality via the "),rs=s("a"),ic=a("save_config()"),dc=a(` and
`),ss=s("a"),lc=a("from_config()"),cc=a(" functions."),uc=l(),jt=s("p"),fc=a(`For more details on the parameters, see the original paper\u2019s Appendix E.: \u201CElucidating the Design Space of
Diffusion-Based Generative Models.\u201D `),Qt=s("a"),pc=a("https://arxiv.org/abs/2206.00364"),hc=a(`. The grid search values used to find the
optimal {s_noise, s_churn, s_min, s_max} for a specific model are described in Table 5 of the paper.`),mc=l(),te=s("div"),p(Xt.$$.fragment),gc=l(),Vn=s("p"),_c=a(`Explicit Langevin-like \u201Cchurn\u201D step of adding noise to the sample according to a factor gamma_i \u2265 0 to reach a
higher noise level sigma_hat = sigma_i + gamma_i*sigma_i.`),vc=l(),Cn=s("p"),bc=a("TODO Args:"),Sc=l(),Ye=s("div"),p(Zt.$$.fragment),$c=l(),An=s("p"),Dc=a(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Ec=l(),Je=s("div"),p(er.$$.fragment),xc=l(),Nn=s("p"),yc=a("Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),wc=l(),ze=s("div"),p(tr.$$.fragment),Mc=l(),Ln=s("p"),Pc=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Tc=l(),je=s("div"),p(rr.$$.fragment),Oc=l(),Fn=s("p"),kc=a("Correct the predicted sample based on the output model_output of the network. TODO complete description"),sa=l(),ve=s("h4"),Qe=s("a"),In=s("span"),p(sr.$$.fragment),Vc=l(),Kn=s("span"),Cc=a("Linear multistep scheduler for discrete beta schedules"),na=l(),Xe=s("p"),Ac=a("Original implementation can be found "),nr=s("a"),Nc=a("here"),Lc=a("."),oa=l(),w=s("div"),p(or.$$.fragment),Fc=l(),ns=s("p"),Ic=a(`Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by
Katherine Crowson:
`),ar=s("a"),Kc=a("https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),qc=l(),k=s("p"),os=s("a"),Uc=a("~ConfigMixin"),Hc=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),qn=s("code"),Rc=a("__init__"),Wc=a(`
function, such as `),Un=s("code"),Bc=a("num_train_timesteps"),Gc=a(". They can be accessed via "),Hn=s("code"),Yc=a("scheduler.config.num_train_timesteps"),Jc=a(`.
`),as=s("a"),zc=a("~ConfigMixin"),jc=a(" also provides general loading and saving functionality via the "),is=s("a"),Qc=a("save_config()"),Xc=a(` and
`),ds=s("a"),Zc=a("from_config()"),eu=a(" functions."),tu=l(),Ze=s("div"),p(ir.$$.fragment),ru=l(),Rn=s("p"),su=a("Compute a linear multistep coefficient."),nu=l(),et=s("div"),p(dr.$$.fragment),ou=l(),lr=s("p"),au=a("Scales the denoising model input by "),Wn=s("code"),iu=a("(sigma**2 + 1) ** 0.5"),du=a(" to match the K-LMS algorithm."),lu=l(),tt=s("div"),p(cr.$$.fragment),cu=l(),Bn=s("p"),uu=a("Sets the timesteps used for the diffusion chain. Supporting function to be run before inference."),fu=l(),rt=s("div"),p(ur.$$.fragment),pu=l(),Gn=s("p"),hu=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),aa=l(),be=s("h4"),st=s("a"),Yn=s("span"),p(fr.$$.fragment),mu=l(),Jn=s("span"),gu=a("Pseudo numerical methods for diffusion models (PNDM)"),ia=l(),nt=s("p"),_u=a("Original implementation can be found "),pr=s("a"),vu=a("here"),bu=a("."),da=l(),$=s("div"),p(hr.$$.fragment),Su=l(),zn=s("p"),$u=a(`Pseudo numerical methods for diffusion models (PNDM) proposes using more advanced ODE integration techniques,
namely Runge-Kutta method and a linear multi-step method.`),Du=l(),V=s("p"),ls=s("a"),Eu=a("~ConfigMixin"),xu=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),jn=s("code"),yu=a("__init__"),wu=a(`
function, such as `),Qn=s("code"),Mu=a("num_train_timesteps"),Pu=a(". They can be accessed via "),Xn=s("code"),Tu=a("scheduler.config.num_train_timesteps"),Ou=a(`.
`),cs=s("a"),ku=a("~ConfigMixin"),Vu=a(" also provides general loading and saving functionality via the "),us=s("a"),Cu=a("save_config()"),Au=a(` and
`),fs=s("a"),Nu=a("from_config()"),Lu=a(" functions."),Fu=l(),ps=s("p"),Iu=a("For more details, see the original paper: "),mr=s("a"),Ku=a("https://arxiv.org/abs/2202.09778"),qu=l(),ot=s("div"),p(gr.$$.fragment),Uu=l(),Zn=s("p"),Hu=a(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Ru=l(),at=s("div"),p(_r.$$.fragment),Wu=l(),eo=s("p"),Bu=a("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Gu=l(),re=s("div"),p(vr.$$.fragment),Yu=l(),to=s("p"),Ju=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),zu=l(),Z=s("p"),ju=a("This function calls "),ro=s("code"),Qu=a("step_prk()"),Xu=a(" or "),so=s("code"),Zu=a("step_plms()"),ef=a(" depending on the internal variable "),no=s("code"),tf=a("counter"),rf=a("."),sf=l(),it=s("div"),p(br.$$.fragment),nf=l(),oo=s("p"),of=a(`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),af=l(),dt=s("div"),p(Sr.$$.fragment),df=l(),ao=s("p"),lf=a(`Step function propagating the sample with the Runge-Kutta method. RK takes 4 forward passes to approximate the
solution to the differential equation.`),la=l(),Se=s("h4"),lt=s("a"),io=s("span"),p($r.$$.fragment),cf=l(),lo=s("span"),uf=a("variance exploding stochastic differential equation (SDE) scheduler"),ca=l(),ct=s("p"),ff=a("Original paper can be found "),Dr=s("a"),pf=a("here"),hf=a("."),ua=l(),D=s("div"),p(Er.$$.fragment),mf=l(),co=s("p"),gf=a("The variance exploding stochastic differential equation (SDE) scheduler."),_f=l(),hs=s("p"),vf=a("For more information, see the original paper: "),xr=s("a"),bf=a("https://arxiv.org/abs/2011.13456"),Sf=l(),C=s("p"),ms=s("a"),$f=a("~ConfigMixin"),Df=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),uo=s("code"),Ef=a("__init__"),xf=a(`
function, such as `),fo=s("code"),yf=a("num_train_timesteps"),wf=a(". They can be accessed via "),po=s("code"),Mf=a("scheduler.config.num_train_timesteps"),Pf=a(`.
`),gs=s("a"),Tf=a("~ConfigMixin"),Of=a(" also provides general loading and saving functionality via the "),_s=s("a"),kf=a("save_config()"),Vf=a(` and
`),vs=s("a"),Cf=a("from_config()"),Af=a(" functions."),Nf=l(),ut=s("div"),p(yr.$$.fragment),Lf=l(),ho=s("p"),Ff=a(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),If=l(),se=s("div"),p(wr.$$.fragment),Kf=l(),mo=s("p"),qf=a("Sets the noise scales used for the diffusion chain. Supporting function to be run before inference."),Uf=l(),$e=s("p"),Hf=a("The sigmas control the weight of the "),go=s("code"),Rf=a("drift"),Wf=a(" and "),_o=s("code"),Bf=a("diffusion"),Gf=a(" components of sample update."),Yf=l(),ft=s("div"),p(Mr.$$.fragment),Jf=l(),vo=s("p"),zf=a("Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),jf=l(),pt=s("div"),p(Pr.$$.fragment),Qf=l(),bo=s("p"),Xf=a(`Correct the predicted sample based on the output model_output of the network. This is often run repeatedly
after making the prediction for the previous timestep.`),Zf=l(),ht=s("div"),p(Tr.$$.fragment),ep=l(),So=s("p"),tp=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),fa=l(),De=s("h4"),mt=s("a"),$o=s("span"),p(Or.$$.fragment),rp=l(),Do=s("span"),sp=a("variance preserving stochastic differential equation (SDE) scheduler"),pa=l(),gt=s("p"),np=a("Original paper can be found "),kr=s("a"),op=a("here"),ap=a("."),ha=l(),p(_t.$$.fragment),ma=l(),K=s("div"),p(Vr.$$.fragment),ip=l(),Eo=s("p"),dp=a("The variance preserving stochastic differential equation (SDE) scheduler."),lp=l(),A=s("p"),bs=s("a"),cp=a("~ConfigMixin"),up=a(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),xo=s("code"),fp=a("__init__"),pp=a(`
function, such as `),yo=s("code"),hp=a("num_train_timesteps"),mp=a(". They can be accessed via "),wo=s("code"),gp=a("scheduler.config.num_train_timesteps"),_p=a(`.
`),Ss=s("a"),vp=a("~ConfigMixin"),bp=a(" also provides general loading and saving functionality via the "),$s=s("a"),Sp=a("save_config()"),$p=a(` and
`),Ds=s("a"),Dp=a("from_config()"),Ep=a(" functions."),xp=l(),Es=s("p"),yp=a("For more information, see the original paper: "),Cr=s("a"),wp=a("https://arxiv.org/abs/2011.13456"),Mp=l(),Mo=s("p"),Pp=a("UNDER CONSTRUCTION"),this.h()},l(t){const u=Yg('[data-svelte="svelte-1phssyn"]',document.head);F=n(u,"META",{name:!0,content:!0}),u.forEach(r),Ee=c(t),I=n(t,"H1",{class:!0});var Ar=o(I);X=n(Ar,"A",{id:!0,class:!0,href:!0});var Lp=o(X);Os=n(Lp,"SPAN",{});var Fp=o(Os);h(bt.$$.fragment,Fp),Fp.forEach(r),Lp.forEach(r),gi=c(Ar),ks=n(Ar,"SPAN",{});var Ip=o(ks);_i=i(Ip,"Schedulers"),Ip.forEach(r),Ar.forEach(r),Oo=c(t),Nr=n(t,"P",{});var Kp=o(Nr);vi=i(Kp,"Diffusers contains multiple pre-built schedule functions for the diffusion process."),Kp.forEach(r),ko=c(t),oe=n(t,"H2",{class:!0});var _a=o(oe);xe=n(_a,"A",{id:!0,class:!0,href:!0});var qp=o(xe);Vs=n(qp,"SPAN",{});var Up=o(Vs);h(St.$$.fragment,Up),Up.forEach(r),qp.forEach(r),bi=c(_a),Cs=n(_a,"SPAN",{});var Hp=o(Cs);Si=i(Hp,"What is a scheduler?"),Hp.forEach(r),_a.forEach(r),Vo=c(t),ye=n(t,"P",{});var va=o(ye);$i=i(va,"The schedule functions, denoted "),As=n(va,"EM",{});var Rp=o(As);Di=i(Rp,"Schedulers"),Rp.forEach(r),Ei=i(va," in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample."),va.forEach(r),Co=c(t),we=n(t,"UL",{});var ba=o(we);Lr=n(ba,"LI",{});var Tp=o(Lr);xi=i(Tp,"Schedulers define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs."),$t=n(Tp,"UL",{});var Sa=o($t);Ns=n(Sa,"LI",{});var Wp=o(Ns);yi=i(Wp,"adding noise in different manners represent the algorithmic processes to train a diffusion model by adding noise to images."),Wp.forEach(r),wi=c(Sa),Ls=n(Sa,"LI",{});var Bp=o(Ls);Mi=i(Bp,"for inference, the scheduler defines how to update a sample based on an output from a pretrained model."),Bp.forEach(r),Sa.forEach(r),Tp.forEach(r),Pi=c(ba),ae=n(ba,"LI",{});var xs=o(ae);Ti=i(xs,"Schedulers are often defined by a "),Fs=n(xs,"EM",{});var Gp=o(Fs);Oi=i(Gp,"noise schedule"),Gp.forEach(r),ki=i(xs," and an "),Is=n(xs,"EM",{});var Yp=o(Is);Vi=i(Yp,"update rule"),Yp.forEach(r),Ci=i(xs," to solve the differential equation solution."),xs.forEach(r),ba.forEach(r),Ao=c(t),ie=n(t,"H3",{class:!0});var $a=o(ie);Me=n($a,"A",{id:!0,class:!0,href:!0});var Jp=o(Me);Ks=n(Jp,"SPAN",{});var zp=o(Ks);h(Dt.$$.fragment,zp),zp.forEach(r),Jp.forEach(r),Ai=c($a),qs=n($a,"SPAN",{});var jp=o(qs);Ni=i(jp,"Discrete versus continuous schedulers"),jp.forEach(r),$a.forEach(r),No=c(t),M=n(t,"P",{});var J=o(M);Li=i(J,`All schedulers take in a timestep to predict the updated version of the sample being diffused.
The timesteps dictate where in the diffusion process the step is, where data is generated by iterating forward in time and inference is executed by propagating backwards through timesteps.
Different algorithms use timesteps that both discrete (accepting `),Us=n(J,"CODE",{});var Qp=o(Us);Fi=i(Qp,"int"),Qp.forEach(r),Ii=i(J," inputs), such as the "),Fr=n(J,"A",{href:!0});var Xp=o(Fr);Ki=i(Xp,"DDPMScheduler"),Xp.forEach(r),qi=i(J," or "),Ir=n(J,"A",{href:!0});var Zp=o(Ir);Ui=i(Zp,"PNDMScheduler"),Zp.forEach(r),Hi=i(J,", and continuous (accepting "),Hs=n(J,"CODE",{});var eh=o(Hs);Ri=i(eh,"float"),eh.forEach(r),Wi=i(J," inputs), such as the score-based schedulers "),Kr=n(J,"A",{href:!0});var th=o(Kr);Bi=i(th,"ScoreSdeVeScheduler"),th.forEach(r),Gi=i(J," or "),Rs=n(J,"CODE",{});var rh=o(Rs);Yi=i(rh,"ScoreSdeVpScheduler"),rh.forEach(r),Ji=i(J,"."),J.forEach(r),Lo=c(t),de=n(t,"H2",{class:!0});var Da=o(de);Pe=n(Da,"A",{id:!0,class:!0,href:!0});var sh=o(Pe);Ws=n(sh,"SPAN",{});var nh=o(Ws);h(Et.$$.fragment,nh),nh.forEach(r),sh.forEach(r),zi=c(Da),Bs=n(Da,"SPAN",{});var oh=o(Bs);ji=i(oh,"Designing Re-usable schedulers"),oh.forEach(r),Da.forEach(r),Fo=c(t),qr=n(t,"P",{});var ah=o(qr);Qi=i(ah,`The core design principle between the schedule functions is to be model, system, and framework independent.
This allows for rapid experimentation and cleaner abstractions in the code, where the model prediction is separated from the sample update.
To this end, the design of schedulers is such that:`),ah.forEach(r),Io=c(t),Te=n(t,"UL",{});var Ea=o(Te);Gs=n(Ea,"LI",{});var ih=o(Gs);Xi=i(ih,"Schedulers can be used interchangeably between diffusion models in inference to find the preferred trade-off between speed and generation quality."),ih.forEach(r),Zi=c(Ea),Ys=n(Ea,"LI",{});var dh=o(Ys);ed=i(dh,"Schedulers are currently by default in PyTorch, but are designed to be framework independent (partial Jax support currently exists)."),dh.forEach(r),Ea.forEach(r),Ko=c(t),le=n(t,"H2",{class:!0});var xa=o(le);Oe=n(xa,"A",{id:!0,class:!0,href:!0});var lh=o(Oe);Js=n(lh,"SPAN",{});var ch=o(Js);h(xt.$$.fragment,ch),ch.forEach(r),lh.forEach(r),td=c(xa),zs=n(xa,"SPAN",{});var uh=o(zs);rd=i(uh,"API"),uh.forEach(r),xa.forEach(r),qo=c(t),Ur=n(t,"P",{});var fh=o(Ur);sd=i(fh,"The core API for any new scheduler must follow a limited structure."),fh.forEach(r),Uo=c(t),ee=n(t,"UL",{});var ys=o(ee);yt=n(ys,"LI",{});var ya=o(yt);nd=i(ya,"Schedulers should provide one or more "),js=n(ya,"CODE",{});var ph=o(js);od=i(ph,"def step(...)"),ph.forEach(r),ad=i(ya," functions that should be called to update the generated sample iteratively."),ya.forEach(r),id=c(ys),wt=n(ys,"LI",{});var wa=o(wt);dd=i(wa,"Schedulers should provide a "),Qs=n(wa,"CODE",{});var hh=o(Qs);ld=i(hh,"set_timesteps(...)"),hh.forEach(r),cd=i(wa," method that configures the parameters of a schedule function for a specific inference task."),wa.forEach(r),ud=c(ys),Xs=n(ys,"LI",{});var mh=o(Xs);fd=i(mh,"Schedulers should be framework-specific."),mh.forEach(r),ys.forEach(r),Ho=c(t),ke=n(t,"P",{});var Ma=o(ke);pd=i(Ma,"The base class "),Hr=n(Ma,"A",{href:!0});var gh=o(Hr);hd=i(gh,"SchedulerMixin"),gh.forEach(r),md=i(Ma," implements low level utilities used by multiple schedulers."),Ma.forEach(r),Ro=c(t),ce=n(t,"H3",{class:!0});var Pa=o(ce);Ve=n(Pa,"A",{id:!0,class:!0,href:!0});var _h=o(Ve);Zs=n(_h,"SPAN",{});var vh=o(Zs);h(Mt.$$.fragment,vh),vh.forEach(r),_h.forEach(r),gd=c(Pa),en=n(Pa,"SPAN",{});var bh=o(en);_d=i(bh,"SchedulerMixin"),bh.forEach(r),Pa.forEach(r),Wo=c(t),ue=n(t,"DIV",{class:!0});var Ta=o(ue);h(Pt.$$.fragment,Ta),vd=c(Ta),tn=n(Ta,"P",{});var Sh=o(tn);bd=i(Sh,"Mixin containing common functions for the schedulers."),Sh.forEach(r),Ta.forEach(r),Bo=c(t),fe=n(t,"H3",{class:!0});var Oa=o(fe);Ce=n(Oa,"A",{id:!0,class:!0,href:!0});var $h=o(Ce);rn=n($h,"SPAN",{});var Dh=o(rn);h(Tt.$$.fragment,Dh),Dh.forEach(r),$h.forEach(r),Sd=c(Oa),sn=n(Oa,"SPAN",{});var Eh=o(sn);$d=i(Eh,"SchedulerOutput"),Eh.forEach(r),Oa.forEach(r),Go=i(t,"\n\nThe class `SchedulerOutput` contains the outputs from any schedulers `step(...)` call.\n"),pe=n(t,"DIV",{class:!0});var ka=o(pe);h(Ot.$$.fragment,ka),Dd=c(ka),nn=n(ka,"P",{});var xh=o(nn);Ed=i(xh,"Base class for the scheduler\u2019s step function output."),xh.forEach(r),ka.forEach(r),Yo=c(t),he=n(t,"H3",{class:!0});var Va=o(he);Ae=n(Va,"A",{id:!0,class:!0,href:!0});var yh=o(Ae);on=n(yh,"SPAN",{});var wh=o(on);h(kt.$$.fragment,wh),wh.forEach(r),yh.forEach(r),xd=c(Va),an=n(Va,"SPAN",{});var Mh=o(an);yd=i(Mh,"Implemented Schedulers"),Mh.forEach(r),Va.forEach(r),Jo=c(t),me=n(t,"H4",{class:!0});var Ca=o(me);Ne=n(Ca,"A",{id:!0,class:!0,href:!0});var Ph=o(Ne);dn=n(Ph,"SPAN",{});var Th=o(dn);h(Vt.$$.fragment,Th),Th.forEach(r),Ph.forEach(r),wd=c(Ca),ln=n(Ca,"SPAN",{});var Oh=o(ln);Md=i(Oh,"Denoising diffusion implicit models (DDIM)"),Oh.forEach(r),Ca.forEach(r),zo=c(t),Rr=n(t,"P",{});var kh=o(Rr);Pd=i(kh,"Original paper can be found here."),kh.forEach(r),jo=c(t),x=n(t,"DIV",{class:!0});var z=o(x);h(Ct.$$.fragment,z),Td=c(z),cn=n(z,"P",{});var Vh=o(cn);Od=i(Vh,`Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising
diffusion probabilistic models (DDPMs) with non-Markovian guidance.`),Vh.forEach(r),kd=c(z),P=n(z,"P",{});var q=o(P);Wr=n(q,"A",{href:!0});var Ch=o(Wr);Vd=i(Ch,"~ConfigMixin"),Ch.forEach(r),Cd=i(q," takes care of storing all config attributes that are passed in the scheduler\u2019s "),un=n(q,"CODE",{});var Ah=o(un);Ad=i(Ah,"__init__"),Ah.forEach(r),Nd=i(q,`
function, such as `),fn=n(q,"CODE",{});var Nh=o(fn);Ld=i(Nh,"num_train_timesteps"),Nh.forEach(r),Fd=i(q,". They can be accessed via "),pn=n(q,"CODE",{});var Lh=o(pn);Id=i(Lh,"scheduler.config.num_train_timesteps"),Lh.forEach(r),Kd=i(q,`.
`),Br=n(q,"A",{href:!0});var Fh=o(Br);qd=i(Fh,"~ConfigMixin"),Fh.forEach(r),Ud=i(q," also provides general loading and saving functionality via the "),Gr=n(q,"A",{href:!0});var Ih=o(Gr);Hd=i(Ih,"save_config()"),Ih.forEach(r),Rd=i(q,` and
`),Yr=n(q,"A",{href:!0});var Kh=o(Yr);Wd=i(Kh,"from_config()"),Kh.forEach(r),Bd=i(q," functions."),q.forEach(r),Gd=c(z),Jr=n(z,"P",{});var Op=o(Jr);Yd=i(Op,"For more details, see the original paper: "),At=n(Op,"A",{href:!0,rel:!0});var qh=o(At);Jd=i(qh,"https://arxiv.org/abs/2010.02502"),qh.forEach(r),Op.forEach(r),zd=c(z),Le=n(z,"DIV",{class:!0});var Aa=o(Le);h(Nt.$$.fragment,Aa),jd=c(Aa),hn=n(Aa,"P",{});var Uh=o(hn);Qd=i(Uh,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Uh.forEach(r),Aa.forEach(r),Xd=c(z),Fe=n(z,"DIV",{class:!0});var Na=o(Fe);h(Lt.$$.fragment,Na),Zd=c(Na),mn=n(Na,"P",{});var Hh=o(mn);el=i(Hh,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Hh.forEach(r),Na.forEach(r),tl=c(z),Ie=n(z,"DIV",{class:!0});var La=o(Ie);h(Ft.$$.fragment,La),rl=c(La),gn=n(La,"P",{});var Rh=o(gn);sl=i(Rh,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Rh.forEach(r),La.forEach(r),z.forEach(r),Qo=c(t),ge=n(t,"H4",{class:!0});var Fa=o(ge);Ke=n(Fa,"A",{id:!0,class:!0,href:!0});var Wh=o(Ke);_n=n(Wh,"SPAN",{});var Bh=o(_n);h(It.$$.fragment,Bh),Bh.forEach(r),Wh.forEach(r),nl=c(Fa),vn=n(Fa,"SPAN",{});var Gh=o(vn);ol=i(Gh,"Denoising diffusion probabilistic models (DDPM)"),Gh.forEach(r),Fa.forEach(r),Xo=c(t),qe=n(t,"P",{});var Ia=o(qe);al=i(Ia,"Original paper can be found "),Kt=n(Ia,"A",{href:!0,rel:!0});var Yh=o(Kt);il=i(Yh,"here"),Yh.forEach(r),dl=i(Ia,"."),Ia.forEach(r),Zo=c(t),y=n(t,"DIV",{class:!0});var j=o(y);h(qt.$$.fragment,j),ll=c(j),bn=n(j,"P",{});var Jh=o(bn);cl=i(Jh,`Denoising diffusion probabilistic models (DDPMs) explores the connections between denoising score matching and
Langevin dynamics sampling.`),Jh.forEach(r),ul=c(j),T=n(j,"P",{});var U=o(T);zr=n(U,"A",{href:!0});var zh=o(zr);fl=i(zh,"~ConfigMixin"),zh.forEach(r),pl=i(U," takes care of storing all config attributes that are passed in the scheduler\u2019s "),Sn=n(U,"CODE",{});var jh=o(Sn);hl=i(jh,"__init__"),jh.forEach(r),ml=i(U,`
function, such as `),$n=n(U,"CODE",{});var Qh=o($n);gl=i(Qh,"num_train_timesteps"),Qh.forEach(r),_l=i(U,". They can be accessed via "),Dn=n(U,"CODE",{});var Xh=o(Dn);vl=i(Xh,"scheduler.config.num_train_timesteps"),Xh.forEach(r),bl=i(U,`.
`),jr=n(U,"A",{href:!0});var Zh=o(jr);Sl=i(Zh,"~ConfigMixin"),Zh.forEach(r),$l=i(U," also provides general loading and saving functionality via the "),Qr=n(U,"A",{href:!0});var em=o(Qr);Dl=i(em,"save_config()"),em.forEach(r),El=i(U,` and
`),Xr=n(U,"A",{href:!0});var tm=o(Xr);xl=i(tm,"from_config()"),tm.forEach(r),yl=i(U," functions."),U.forEach(r),wl=c(j),Zr=n(j,"P",{});var kp=o(Zr);Ml=i(kp,"For more details, see the original paper: "),Ut=n(kp,"A",{href:!0,rel:!0});var rm=o(Ut);Pl=i(rm,"https://arxiv.org/abs/2006.11239"),rm.forEach(r),kp.forEach(r),Tl=c(j),Ue=n(j,"DIV",{class:!0});var Ka=o(Ue);h(Ht.$$.fragment,Ka),Ol=c(Ka),En=n(Ka,"P",{});var sm=o(En);kl=i(sm,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),sm.forEach(r),Ka.forEach(r),Vl=c(j),He=n(j,"DIV",{class:!0});var qa=o(He);h(Rt.$$.fragment,qa),Cl=c(qa),xn=n(qa,"P",{});var nm=o(xn);Al=i(nm,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),nm.forEach(r),qa.forEach(r),Nl=c(j),Re=n(j,"DIV",{class:!0});var Ua=o(Re);h(Wt.$$.fragment,Ua),Ll=c(Ua),yn=n(Ua,"P",{});var om=o(yn);Fl=i(om,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),om.forEach(r),Ua.forEach(r),j.forEach(r),ea=c(t),_e=n(t,"H4",{class:!0});var Ha=o(_e);We=n(Ha,"A",{id:!0,class:!0,href:!0});var am=o(We);wn=n(am,"SPAN",{});var im=o(wn);h(Bt.$$.fragment,im),im.forEach(r),am.forEach(r),Il=c(Ha),Mn=n(Ha,"SPAN",{});var dm=o(Mn);Kl=i(dm,"Variance exploding, stochastic sampling from Karras et. al"),dm.forEach(r),Ha.forEach(r),ta=c(t),Be=n(t,"P",{});var Ra=o(Be);ql=i(Ra,"Original paper can be found "),Gt=n(Ra,"A",{href:!0,rel:!0});var lm=o(Gt);Ul=i(lm,"here"),lm.forEach(r),Hl=i(Ra,"."),Ra.forEach(r),ra=c(t),S=n(t,"DIV",{class:!0});var E=o(S);h(Yt.$$.fragment,E),Rl=c(E),Pn=n(E,"P",{});var cm=o(Pn);Wl=i(cm,`Stochastic sampling from Karras et al. [1] tailored to the Variance-Expanding (VE) models [2]. Use Algorithm 2 and
the VE column of Table 1 from [1] for reference.`),cm.forEach(r),Bl=c(E),Ge=n(E,"P",{});var Po=o(Ge);Gl=i(Po,`[1] Karras, Tero, et al. \u201CElucidating the Design Space of Diffusion-Based Generative Models.\u201D
`),Jt=n(Po,"A",{href:!0,rel:!0});var um=o(Jt);Yl=i(um,"https://arxiv.org/abs/2206.00364"),um.forEach(r),Jl=i(Po,` [2] Song, Yang, et al. \u201CScore-based generative modeling through stochastic
differential equations.\u201D `),zt=n(Po,"A",{href:!0,rel:!0});var fm=o(zt);zl=i(fm,"https://arxiv.org/abs/2011.13456"),fm.forEach(r),Po.forEach(r),jl=c(E),O=n(E,"P",{});var H=o(O);es=n(H,"A",{href:!0});var pm=o(es);Ql=i(pm,"~ConfigMixin"),pm.forEach(r),Xl=i(H," takes care of storing all config attributes that are passed in the scheduler\u2019s "),Tn=n(H,"CODE",{});var hm=o(Tn);Zl=i(hm,"__init__"),hm.forEach(r),ec=i(H,`
function, such as `),On=n(H,"CODE",{});var mm=o(On);tc=i(mm,"num_train_timesteps"),mm.forEach(r),rc=i(H,". They can be accessed via "),kn=n(H,"CODE",{});var gm=o(kn);sc=i(gm,"scheduler.config.num_train_timesteps"),gm.forEach(r),nc=i(H,`.
`),ts=n(H,"A",{href:!0});var _m=o(ts);oc=i(_m,"~ConfigMixin"),_m.forEach(r),ac=i(H," also provides general loading and saving functionality via the "),rs=n(H,"A",{href:!0});var vm=o(rs);ic=i(vm,"save_config()"),vm.forEach(r),dc=i(H,` and
`),ss=n(H,"A",{href:!0});var bm=o(ss);lc=i(bm,"from_config()"),bm.forEach(r),cc=i(H," functions."),H.forEach(r),uc=c(E),jt=n(E,"P",{});var Wa=o(jt);fc=i(Wa,`For more details on the parameters, see the original paper\u2019s Appendix E.: \u201CElucidating the Design Space of
Diffusion-Based Generative Models.\u201D `),Qt=n(Wa,"A",{href:!0,rel:!0});var Sm=o(Qt);pc=i(Sm,"https://arxiv.org/abs/2206.00364"),Sm.forEach(r),hc=i(Wa,`. The grid search values used to find the
optimal {s_noise, s_churn, s_min, s_max} for a specific model are described in Table 5 of the paper.`),Wa.forEach(r),mc=c(E),te=n(E,"DIV",{class:!0});var ws=o(te);h(Xt.$$.fragment,ws),gc=c(ws),Vn=n(ws,"P",{});var $m=o(Vn);_c=i($m,`Explicit Langevin-like \u201Cchurn\u201D step of adding noise to the sample according to a factor gamma_i \u2265 0 to reach a
higher noise level sigma_hat = sigma_i + gamma_i*sigma_i.`),$m.forEach(r),vc=c(ws),Cn=n(ws,"P",{});var Dm=o(Cn);bc=i(Dm,"TODO Args:"),Dm.forEach(r),ws.forEach(r),Sc=c(E),Ye=n(E,"DIV",{class:!0});var Ba=o(Ye);h(Zt.$$.fragment,Ba),$c=c(Ba),An=n(Ba,"P",{});var Em=o(An);Dc=i(Em,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Em.forEach(r),Ba.forEach(r),Ec=c(E),Je=n(E,"DIV",{class:!0});var Ga=o(Je);h(er.$$.fragment,Ga),xc=c(Ga),Nn=n(Ga,"P",{});var xm=o(Nn);yc=i(xm,"Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),xm.forEach(r),Ga.forEach(r),wc=c(E),ze=n(E,"DIV",{class:!0});var Ya=o(ze);h(tr.$$.fragment,Ya),Mc=c(Ya),Ln=n(Ya,"P",{});var ym=o(Ln);Pc=i(ym,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),ym.forEach(r),Ya.forEach(r),Tc=c(E),je=n(E,"DIV",{class:!0});var Ja=o(je);h(rr.$$.fragment,Ja),Oc=c(Ja),Fn=n(Ja,"P",{});var wm=o(Fn);kc=i(wm,"Correct the predicted sample based on the output model_output of the network. TODO complete description"),wm.forEach(r),Ja.forEach(r),E.forEach(r),sa=c(t),ve=n(t,"H4",{class:!0});var za=o(ve);Qe=n(za,"A",{id:!0,class:!0,href:!0});var Mm=o(Qe);In=n(Mm,"SPAN",{});var Pm=o(In);h(sr.$$.fragment,Pm),Pm.forEach(r),Mm.forEach(r),Vc=c(za),Kn=n(za,"SPAN",{});var Tm=o(Kn);Cc=i(Tm,"Linear multistep scheduler for discrete beta schedules"),Tm.forEach(r),za.forEach(r),na=c(t),Xe=n(t,"P",{});var ja=o(Xe);Ac=i(ja,"Original implementation can be found "),nr=n(ja,"A",{href:!0,rel:!0});var Om=o(nr);Nc=i(Om,"here"),Om.forEach(r),Lc=i(ja,"."),ja.forEach(r),oa=c(t),w=n(t,"DIV",{class:!0});var Q=o(w);h(or.$$.fragment,Q),Fc=c(Q),ns=n(Q,"P",{});var Vp=o(ns);Ic=i(Vp,`Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by
Katherine Crowson:
`),ar=n(Vp,"A",{href:!0,rel:!0});var km=o(ar);Kc=i(km,"https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),km.forEach(r),Vp.forEach(r),qc=c(Q),k=n(Q,"P",{});var R=o(k);os=n(R,"A",{href:!0});var Vm=o(os);Uc=i(Vm,"~ConfigMixin"),Vm.forEach(r),Hc=i(R," takes care of storing all config attributes that are passed in the scheduler\u2019s "),qn=n(R,"CODE",{});var Cm=o(qn);Rc=i(Cm,"__init__"),Cm.forEach(r),Wc=i(R,`
function, such as `),Un=n(R,"CODE",{});var Am=o(Un);Bc=i(Am,"num_train_timesteps"),Am.forEach(r),Gc=i(R,". They can be accessed via "),Hn=n(R,"CODE",{});var Nm=o(Hn);Yc=i(Nm,"scheduler.config.num_train_timesteps"),Nm.forEach(r),Jc=i(R,`.
`),as=n(R,"A",{href:!0});var Lm=o(as);zc=i(Lm,"~ConfigMixin"),Lm.forEach(r),jc=i(R," also provides general loading and saving functionality via the "),is=n(R,"A",{href:!0});var Fm=o(is);Qc=i(Fm,"save_config()"),Fm.forEach(r),Xc=i(R,` and
`),ds=n(R,"A",{href:!0});var Im=o(ds);Zc=i(Im,"from_config()"),Im.forEach(r),eu=i(R," functions."),R.forEach(r),tu=c(Q),Ze=n(Q,"DIV",{class:!0});var Qa=o(Ze);h(ir.$$.fragment,Qa),ru=c(Qa),Rn=n(Qa,"P",{});var Km=o(Rn);su=i(Km,"Compute a linear multistep coefficient."),Km.forEach(r),Qa.forEach(r),nu=c(Q),et=n(Q,"DIV",{class:!0});var Xa=o(et);h(dr.$$.fragment,Xa),ou=c(Xa),lr=n(Xa,"P",{});var Za=o(lr);au=i(Za,"Scales the denoising model input by "),Wn=n(Za,"CODE",{});var qm=o(Wn);iu=i(qm,"(sigma**2 + 1) ** 0.5"),qm.forEach(r),du=i(Za," to match the K-LMS algorithm."),Za.forEach(r),Xa.forEach(r),lu=c(Q),tt=n(Q,"DIV",{class:!0});var ei=o(tt);h(cr.$$.fragment,ei),cu=c(ei),Bn=n(ei,"P",{});var Um=o(Bn);uu=i(Um,"Sets the timesteps used for the diffusion chain. Supporting function to be run before inference."),Um.forEach(r),ei.forEach(r),fu=c(Q),rt=n(Q,"DIV",{class:!0});var ti=o(rt);h(ur.$$.fragment,ti),pu=c(ti),Gn=n(ti,"P",{});var Hm=o(Gn);hu=i(Hm,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Hm.forEach(r),ti.forEach(r),Q.forEach(r),aa=c(t),be=n(t,"H4",{class:!0});var ri=o(be);st=n(ri,"A",{id:!0,class:!0,href:!0});var Rm=o(st);Yn=n(Rm,"SPAN",{});var Wm=o(Yn);h(fr.$$.fragment,Wm),Wm.forEach(r),Rm.forEach(r),mu=c(ri),Jn=n(ri,"SPAN",{});var Bm=o(Jn);gu=i(Bm,"Pseudo numerical methods for diffusion models (PNDM)"),Bm.forEach(r),ri.forEach(r),ia=c(t),nt=n(t,"P",{});var si=o(nt);_u=i(si,"Original implementation can be found "),pr=n(si,"A",{href:!0,rel:!0});var Gm=o(pr);vu=i(Gm,"here"),Gm.forEach(r),bu=i(si,"."),si.forEach(r),da=c(t),$=n(t,"DIV",{class:!0});var N=o($);h(hr.$$.fragment,N),Su=c(N),zn=n(N,"P",{});var Ym=o(zn);$u=i(Ym,`Pseudo numerical methods for diffusion models (PNDM) proposes using more advanced ODE integration techniques,
namely Runge-Kutta method and a linear multi-step method.`),Ym.forEach(r),Du=c(N),V=n(N,"P",{});var W=o(V);ls=n(W,"A",{href:!0});var Jm=o(ls);Eu=i(Jm,"~ConfigMixin"),Jm.forEach(r),xu=i(W," takes care of storing all config attributes that are passed in the scheduler\u2019s "),jn=n(W,"CODE",{});var zm=o(jn);yu=i(zm,"__init__"),zm.forEach(r),wu=i(W,`
function, such as `),Qn=n(W,"CODE",{});var jm=o(Qn);Mu=i(jm,"num_train_timesteps"),jm.forEach(r),Pu=i(W,". They can be accessed via "),Xn=n(W,"CODE",{});var Qm=o(Xn);Tu=i(Qm,"scheduler.config.num_train_timesteps"),Qm.forEach(r),Ou=i(W,`.
`),cs=n(W,"A",{href:!0});var Xm=o(cs);ku=i(Xm,"~ConfigMixin"),Xm.forEach(r),Vu=i(W," also provides general loading and saving functionality via the "),us=n(W,"A",{href:!0});var Zm=o(us);Cu=i(Zm,"save_config()"),Zm.forEach(r),Au=i(W,` and
`),fs=n(W,"A",{href:!0});var eg=o(fs);Nu=i(eg,"from_config()"),eg.forEach(r),Lu=i(W," functions."),W.forEach(r),Fu=c(N),ps=n(N,"P",{});var Cp=o(ps);Iu=i(Cp,"For more details, see the original paper: "),mr=n(Cp,"A",{href:!0,rel:!0});var tg=o(mr);Ku=i(tg,"https://arxiv.org/abs/2202.09778"),tg.forEach(r),Cp.forEach(r),qu=c(N),ot=n(N,"DIV",{class:!0});var ni=o(ot);h(gr.$$.fragment,ni),Uu=c(ni),Zn=n(ni,"P",{});var rg=o(Zn);Hu=i(rg,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),rg.forEach(r),ni.forEach(r),Ru=c(N),at=n(N,"DIV",{class:!0});var oi=o(at);h(_r.$$.fragment,oi),Wu=c(oi),eo=n(oi,"P",{});var sg=o(eo);Bu=i(sg,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),sg.forEach(r),oi.forEach(r),Gu=c(N),re=n(N,"DIV",{class:!0});var Ms=o(re);h(vr.$$.fragment,Ms),Yu=c(Ms),to=n(Ms,"P",{});var ng=o(to);Ju=i(ng,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),ng.forEach(r),zu=c(Ms),Z=n(Ms,"P",{});var vt=o(Z);ju=i(vt,"This function calls "),ro=n(vt,"CODE",{});var og=o(ro);Qu=i(og,"step_prk()"),og.forEach(r),Xu=i(vt," or "),so=n(vt,"CODE",{});var ag=o(so);Zu=i(ag,"step_plms()"),ag.forEach(r),ef=i(vt," depending on the internal variable "),no=n(vt,"CODE",{});var ig=o(no);tf=i(ig,"counter"),ig.forEach(r),rf=i(vt,"."),vt.forEach(r),Ms.forEach(r),sf=c(N),it=n(N,"DIV",{class:!0});var ai=o(it);h(br.$$.fragment,ai),nf=c(ai),oo=n(ai,"P",{});var dg=o(oo);of=i(dg,`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),dg.forEach(r),ai.forEach(r),af=c(N),dt=n(N,"DIV",{class:!0});var ii=o(dt);h(Sr.$$.fragment,ii),df=c(ii),ao=n(ii,"P",{});var lg=o(ao);lf=i(lg,`Step function propagating the sample with the Runge-Kutta method. RK takes 4 forward passes to approximate the
solution to the differential equation.`),lg.forEach(r),ii.forEach(r),N.forEach(r),la=c(t),Se=n(t,"H4",{class:!0});var di=o(Se);lt=n(di,"A",{id:!0,class:!0,href:!0});var cg=o(lt);io=n(cg,"SPAN",{});var ug=o(io);h($r.$$.fragment,ug),ug.forEach(r),cg.forEach(r),cf=c(di),lo=n(di,"SPAN",{});var fg=o(lo);uf=i(fg,"variance exploding stochastic differential equation (SDE) scheduler"),fg.forEach(r),di.forEach(r),ca=c(t),ct=n(t,"P",{});var li=o(ct);ff=i(li,"Original paper can be found "),Dr=n(li,"A",{href:!0,rel:!0});var pg=o(Dr);pf=i(pg,"here"),pg.forEach(r),hf=i(li,"."),li.forEach(r),ua=c(t),D=n(t,"DIV",{class:!0});var L=o(D);h(Er.$$.fragment,L),mf=c(L),co=n(L,"P",{});var hg=o(co);gf=i(hg,"The variance exploding stochastic differential equation (SDE) scheduler."),hg.forEach(r),_f=c(L),hs=n(L,"P",{});var Ap=o(hs);vf=i(Ap,"For more information, see the original paper: "),xr=n(Ap,"A",{href:!0,rel:!0});var mg=o(xr);bf=i(mg,"https://arxiv.org/abs/2011.13456"),mg.forEach(r),Ap.forEach(r),Sf=c(L),C=n(L,"P",{});var B=o(C);ms=n(B,"A",{href:!0});var gg=o(ms);$f=i(gg,"~ConfigMixin"),gg.forEach(r),Df=i(B," takes care of storing all config attributes that are passed in the scheduler\u2019s "),uo=n(B,"CODE",{});var _g=o(uo);Ef=i(_g,"__init__"),_g.forEach(r),xf=i(B,`
function, such as `),fo=n(B,"CODE",{});var vg=o(fo);yf=i(vg,"num_train_timesteps"),vg.forEach(r),wf=i(B,". They can be accessed via "),po=n(B,"CODE",{});var bg=o(po);Mf=i(bg,"scheduler.config.num_train_timesteps"),bg.forEach(r),Pf=i(B,`.
`),gs=n(B,"A",{href:!0});var Sg=o(gs);Tf=i(Sg,"~ConfigMixin"),Sg.forEach(r),Of=i(B," also provides general loading and saving functionality via the "),_s=n(B,"A",{href:!0});var $g=o(_s);kf=i($g,"save_config()"),$g.forEach(r),Vf=i(B,` and
`),vs=n(B,"A",{href:!0});var Dg=o(vs);Cf=i(Dg,"from_config()"),Dg.forEach(r),Af=i(B," functions."),B.forEach(r),Nf=c(L),ut=n(L,"DIV",{class:!0});var ci=o(ut);h(yr.$$.fragment,ci),Lf=c(ci),ho=n(ci,"P",{});var Eg=o(ho);Ff=i(Eg,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Eg.forEach(r),ci.forEach(r),If=c(L),se=n(L,"DIV",{class:!0});var Ps=o(se);h(wr.$$.fragment,Ps),Kf=c(Ps),mo=n(Ps,"P",{});var xg=o(mo);qf=i(xg,"Sets the noise scales used for the diffusion chain. Supporting function to be run before inference."),xg.forEach(r),Uf=c(Ps),$e=n(Ps,"P",{});var Ts=o($e);Hf=i(Ts,"The sigmas control the weight of the "),go=n(Ts,"CODE",{});var yg=o(go);Rf=i(yg,"drift"),yg.forEach(r),Wf=i(Ts," and "),_o=n(Ts,"CODE",{});var wg=o(_o);Bf=i(wg,"diffusion"),wg.forEach(r),Gf=i(Ts," components of sample update."),Ts.forEach(r),Ps.forEach(r),Yf=c(L),ft=n(L,"DIV",{class:!0});var ui=o(ft);h(Mr.$$.fragment,ui),Jf=c(ui),vo=n(ui,"P",{});var Mg=o(vo);zf=i(Mg,"Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),Mg.forEach(r),ui.forEach(r),jf=c(L),pt=n(L,"DIV",{class:!0});var fi=o(pt);h(Pr.$$.fragment,fi),Qf=c(fi),bo=n(fi,"P",{});var Pg=o(bo);Xf=i(Pg,`Correct the predicted sample based on the output model_output of the network. This is often run repeatedly
after making the prediction for the previous timestep.`),Pg.forEach(r),fi.forEach(r),Zf=c(L),ht=n(L,"DIV",{class:!0});var pi=o(ht);h(Tr.$$.fragment,pi),ep=c(pi),So=n(pi,"P",{});var Tg=o(So);tp=i(Tg,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Tg.forEach(r),pi.forEach(r),L.forEach(r),fa=c(t),De=n(t,"H4",{class:!0});var hi=o(De);mt=n(hi,"A",{id:!0,class:!0,href:!0});var Og=o(mt);$o=n(Og,"SPAN",{});var kg=o($o);h(Or.$$.fragment,kg),kg.forEach(r),Og.forEach(r),rp=c(hi),Do=n(hi,"SPAN",{});var Vg=o(Do);sp=i(Vg,"variance preserving stochastic differential equation (SDE) scheduler"),Vg.forEach(r),hi.forEach(r),pa=c(t),gt=n(t,"P",{});var mi=o(gt);np=i(mi,"Original paper can be found "),kr=n(mi,"A",{href:!0,rel:!0});var Cg=o(kr);op=i(Cg,"here"),Cg.forEach(r),ap=i(mi,"."),mi.forEach(r),ha=c(t),h(_t.$$.fragment,t),ma=c(t),K=n(t,"DIV",{class:!0});var ne=o(K);h(Vr.$$.fragment,ne),ip=c(ne),Eo=n(ne,"P",{});var Ag=o(Eo);dp=i(Ag,"The variance preserving stochastic differential equation (SDE) scheduler."),Ag.forEach(r),lp=c(ne),A=n(ne,"P",{});var G=o(A);bs=n(G,"A",{href:!0});var Ng=o(bs);cp=i(Ng,"~ConfigMixin"),Ng.forEach(r),up=i(G," takes care of storing all config attributes that are passed in the scheduler\u2019s "),xo=n(G,"CODE",{});var Lg=o(xo);fp=i(Lg,"__init__"),Lg.forEach(r),pp=i(G,`
function, such as `),yo=n(G,"CODE",{});var Fg=o(yo);hp=i(Fg,"num_train_timesteps"),Fg.forEach(r),mp=i(G,". They can be accessed via "),wo=n(G,"CODE",{});var Ig=o(wo);gp=i(Ig,"scheduler.config.num_train_timesteps"),Ig.forEach(r),_p=i(G,`.
`),Ss=n(G,"A",{href:!0});var Kg=o(Ss);vp=i(Kg,"~ConfigMixin"),Kg.forEach(r),bp=i(G," also provides general loading and saving functionality via the "),$s=n(G,"A",{href:!0});var qg=o($s);Sp=i(qg,"save_config()"),qg.forEach(r),$p=i(G,` and
`),Ds=n(G,"A",{href:!0});var Ug=o(Ds);Dp=i(Ug,"from_config()"),Ug.forEach(r),Ep=i(G," functions."),G.forEach(r),xp=c(ne),Es=n(ne,"P",{});var Np=o(Es);yp=i(Np,"For more information, see the original paper: "),Cr=n(Np,"A",{href:!0,rel:!0});var Hg=o(Cr);wp=i(Hg,"https://arxiv.org/abs/2011.13456"),Hg.forEach(r),Np.forEach(r),Mp=c(ne),Mo=n(ne,"P",{});var Rg=o(Mo);Pp=i(Rg,"UNDER CONSTRUCTION"),Rg.forEach(r),ne.forEach(r),this.h()},h(){d(F,"name","hf:doc:metadata"),d(F,"content",JSON.stringify(Xg)),d(X,"id","schedulers"),d(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X,"href","#schedulers"),d(I,"class","relative group"),d(xe,"id","what-is-a-scheduler"),d(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xe,"href","#what-is-a-scheduler"),d(oe,"class","relative group"),d(Me,"id","discrete-versus-continuous-schedulers"),d(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Me,"href","#discrete-versus-continuous-schedulers"),d(ie,"class","relative group"),d(Fr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DDPMScheduler"),d(Ir,"href","/docs/diffusers/main/en/api/schedulers#diffusers.PNDMScheduler"),d(Kr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.ScoreSdeVeScheduler"),d(Pe,"id","designing-reusable-schedulers"),d(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Pe,"href","#designing-reusable-schedulers"),d(de,"class","relative group"),d(Oe,"id","api"),d(Oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Oe,"href","#api"),d(le,"class","relative group"),d(Hr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.SchedulerMixin"),d(Ve,"id","diffusers.SchedulerMixin"),d(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ve,"href","#diffusers.SchedulerMixin"),d(ce,"class","relative group"),d(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ce,"id","diffusers.schedulers.scheduling_utils.SchedulerOutput"),d(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ce,"href","#diffusers.schedulers.scheduling_utils.SchedulerOutput"),d(fe,"class","relative group"),d(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ae,"id","implemented-schedulers"),d(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ae,"href","#implemented-schedulers"),d(he,"class","relative group"),d(Ne,"id","diffusers.DDIMScheduler"),d(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ne,"href","#diffusers.DDIMScheduler"),d(me,"class","relative group"),d(Wr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(Br,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(Gr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(Yr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(At,"href","https://arxiv.org/abs/2010.02502"),d(At,"rel","nofollow"),d(Le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ke,"id","diffusers.DDPMScheduler"),d(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ke,"href","#diffusers.DDPMScheduler"),d(ge,"class","relative group"),d(Kt,"href","https://arxiv.org/abs/2010.02502"),d(Kt,"rel","nofollow"),d(zr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(jr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(Qr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(Xr,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(Ut,"href","https://arxiv.org/abs/2006.11239"),d(Ut,"rel","nofollow"),d(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(We,"id","diffusers.KarrasVeScheduler"),d(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(We,"href","#diffusers.KarrasVeScheduler"),d(_e,"class","relative group"),d(Gt,"href","https://arxiv.org/abs/2006.11239"),d(Gt,"rel","nofollow"),d(Jt,"href","https://arxiv.org/abs/2206.00364"),d(Jt,"rel","nofollow"),d(zt,"href","https://arxiv.org/abs/2011.13456"),d(zt,"rel","nofollow"),d(es,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(ts,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(rs,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(ss,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(Qt,"href","https://arxiv.org/abs/2206.00364"),d(Qt,"rel","nofollow"),d(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qe,"id","diffusers.LMSDiscreteScheduler"),d(Qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Qe,"href","#diffusers.LMSDiscreteScheduler"),d(ve,"class","relative group"),d(nr,"href","https://arxiv.org/abs/2206.00364"),d(nr,"rel","nofollow"),d(ar,"href","https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),d(ar,"rel","nofollow"),d(os,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(as,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(is,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(ds,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(st,"id","diffusers.PNDMScheduler"),d(st,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(st,"href","#diffusers.PNDMScheduler"),d(be,"class","relative group"),d(pr,"href","https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),d(pr,"rel","nofollow"),d(ls,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(cs,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(us,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(fs,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(mr,"href","https://arxiv.org/abs/2202.09778"),d(mr,"rel","nofollow"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lt,"id","diffusers.ScoreSdeVeScheduler"),d(lt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(lt,"href","#diffusers.ScoreSdeVeScheduler"),d(Se,"class","relative group"),d(Dr,"href","https://arxiv.org/abs/2011.13456"),d(Dr,"rel","nofollow"),d(xr,"href","https://arxiv.org/abs/2011.13456"),d(xr,"rel","nofollow"),d(ms,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(gs,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(_s,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(vs,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(se,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mt,"id","diffusers.schedulers.ScoreSdeVpScheduler"),d(mt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(mt,"href","#diffusers.schedulers.ScoreSdeVpScheduler"),d(De,"class","relative group"),d(kr,"href","https://arxiv.org/abs/2011.13456"),d(kr,"rel","nofollow"),d(bs,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d(Ss,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin"),d($s,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.save_config"),d(Ds,"href","/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config"),d(Cr,"href","https://arxiv.org/abs/2011.13456"),d(Cr,"rel","nofollow"),d(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,u){e(document.head,F),f(t,Ee,u),f(t,I,u),e(I,X),e(X,Os),m(bt,Os,null),e(I,gi),e(I,ks),e(ks,_i),f(t,Oo,u),f(t,Nr,u),e(Nr,vi),f(t,ko,u),f(t,oe,u),e(oe,xe),e(xe,Vs),m(St,Vs,null),e(oe,bi),e(oe,Cs),e(Cs,Si),f(t,Vo,u),f(t,ye,u),e(ye,$i),e(ye,As),e(As,Di),e(ye,Ei),f(t,Co,u),f(t,we,u),e(we,Lr),e(Lr,xi),e(Lr,$t),e($t,Ns),e(Ns,yi),e($t,wi),e($t,Ls),e(Ls,Mi),e(we,Pi),e(we,ae),e(ae,Ti),e(ae,Fs),e(Fs,Oi),e(ae,ki),e(ae,Is),e(Is,Vi),e(ae,Ci),f(t,Ao,u),f(t,ie,u),e(ie,Me),e(Me,Ks),m(Dt,Ks,null),e(ie,Ai),e(ie,qs),e(qs,Ni),f(t,No,u),f(t,M,u),e(M,Li),e(M,Us),e(Us,Fi),e(M,Ii),e(M,Fr),e(Fr,Ki),e(M,qi),e(M,Ir),e(Ir,Ui),e(M,Hi),e(M,Hs),e(Hs,Ri),e(M,Wi),e(M,Kr),e(Kr,Bi),e(M,Gi),e(M,Rs),e(Rs,Yi),e(M,Ji),f(t,Lo,u),f(t,de,u),e(de,Pe),e(Pe,Ws),m(Et,Ws,null),e(de,zi),e(de,Bs),e(Bs,ji),f(t,Fo,u),f(t,qr,u),e(qr,Qi),f(t,Io,u),f(t,Te,u),e(Te,Gs),e(Gs,Xi),e(Te,Zi),e(Te,Ys),e(Ys,ed),f(t,Ko,u),f(t,le,u),e(le,Oe),e(Oe,Js),m(xt,Js,null),e(le,td),e(le,zs),e(zs,rd),f(t,qo,u),f(t,Ur,u),e(Ur,sd),f(t,Uo,u),f(t,ee,u),e(ee,yt),e(yt,nd),e(yt,js),e(js,od),e(yt,ad),e(ee,id),e(ee,wt),e(wt,dd),e(wt,Qs),e(Qs,ld),e(wt,cd),e(ee,ud),e(ee,Xs),e(Xs,fd),f(t,Ho,u),f(t,ke,u),e(ke,pd),e(ke,Hr),e(Hr,hd),e(ke,md),f(t,Ro,u),f(t,ce,u),e(ce,Ve),e(Ve,Zs),m(Mt,Zs,null),e(ce,gd),e(ce,en),e(en,_d),f(t,Wo,u),f(t,ue,u),m(Pt,ue,null),e(ue,vd),e(ue,tn),e(tn,bd),f(t,Bo,u),f(t,fe,u),e(fe,Ce),e(Ce,rn),m(Tt,rn,null),e(fe,Sd),e(fe,sn),e(sn,$d),f(t,Go,u),f(t,pe,u),m(Ot,pe,null),e(pe,Dd),e(pe,nn),e(nn,Ed),f(t,Yo,u),f(t,he,u),e(he,Ae),e(Ae,on),m(kt,on,null),e(he,xd),e(he,an),e(an,yd),f(t,Jo,u),f(t,me,u),e(me,Ne),e(Ne,dn),m(Vt,dn,null),e(me,wd),e(me,ln),e(ln,Md),f(t,zo,u),f(t,Rr,u),e(Rr,Pd),f(t,jo,u),f(t,x,u),m(Ct,x,null),e(x,Td),e(x,cn),e(cn,Od),e(x,kd),e(x,P),e(P,Wr),e(Wr,Vd),e(P,Cd),e(P,un),e(un,Ad),e(P,Nd),e(P,fn),e(fn,Ld),e(P,Fd),e(P,pn),e(pn,Id),e(P,Kd),e(P,Br),e(Br,qd),e(P,Ud),e(P,Gr),e(Gr,Hd),e(P,Rd),e(P,Yr),e(Yr,Wd),e(P,Bd),e(x,Gd),e(x,Jr),e(Jr,Yd),e(Jr,At),e(At,Jd),e(x,zd),e(x,Le),m(Nt,Le,null),e(Le,jd),e(Le,hn),e(hn,Qd),e(x,Xd),e(x,Fe),m(Lt,Fe,null),e(Fe,Zd),e(Fe,mn),e(mn,el),e(x,tl),e(x,Ie),m(Ft,Ie,null),e(Ie,rl),e(Ie,gn),e(gn,sl),f(t,Qo,u),f(t,ge,u),e(ge,Ke),e(Ke,_n),m(It,_n,null),e(ge,nl),e(ge,vn),e(vn,ol),f(t,Xo,u),f(t,qe,u),e(qe,al),e(qe,Kt),e(Kt,il),e(qe,dl),f(t,Zo,u),f(t,y,u),m(qt,y,null),e(y,ll),e(y,bn),e(bn,cl),e(y,ul),e(y,T),e(T,zr),e(zr,fl),e(T,pl),e(T,Sn),e(Sn,hl),e(T,ml),e(T,$n),e($n,gl),e(T,_l),e(T,Dn),e(Dn,vl),e(T,bl),e(T,jr),e(jr,Sl),e(T,$l),e(T,Qr),e(Qr,Dl),e(T,El),e(T,Xr),e(Xr,xl),e(T,yl),e(y,wl),e(y,Zr),e(Zr,Ml),e(Zr,Ut),e(Ut,Pl),e(y,Tl),e(y,Ue),m(Ht,Ue,null),e(Ue,Ol),e(Ue,En),e(En,kl),e(y,Vl),e(y,He),m(Rt,He,null),e(He,Cl),e(He,xn),e(xn,Al),e(y,Nl),e(y,Re),m(Wt,Re,null),e(Re,Ll),e(Re,yn),e(yn,Fl),f(t,ea,u),f(t,_e,u),e(_e,We),e(We,wn),m(Bt,wn,null),e(_e,Il),e(_e,Mn),e(Mn,Kl),f(t,ta,u),f(t,Be,u),e(Be,ql),e(Be,Gt),e(Gt,Ul),e(Be,Hl),f(t,ra,u),f(t,S,u),m(Yt,S,null),e(S,Rl),e(S,Pn),e(Pn,Wl),e(S,Bl),e(S,Ge),e(Ge,Gl),e(Ge,Jt),e(Jt,Yl),e(Ge,Jl),e(Ge,zt),e(zt,zl),e(S,jl),e(S,O),e(O,es),e(es,Ql),e(O,Xl),e(O,Tn),e(Tn,Zl),e(O,ec),e(O,On),e(On,tc),e(O,rc),e(O,kn),e(kn,sc),e(O,nc),e(O,ts),e(ts,oc),e(O,ac),e(O,rs),e(rs,ic),e(O,dc),e(O,ss),e(ss,lc),e(O,cc),e(S,uc),e(S,jt),e(jt,fc),e(jt,Qt),e(Qt,pc),e(jt,hc),e(S,mc),e(S,te),m(Xt,te,null),e(te,gc),e(te,Vn),e(Vn,_c),e(te,vc),e(te,Cn),e(Cn,bc),e(S,Sc),e(S,Ye),m(Zt,Ye,null),e(Ye,$c),e(Ye,An),e(An,Dc),e(S,Ec),e(S,Je),m(er,Je,null),e(Je,xc),e(Je,Nn),e(Nn,yc),e(S,wc),e(S,ze),m(tr,ze,null),e(ze,Mc),e(ze,Ln),e(Ln,Pc),e(S,Tc),e(S,je),m(rr,je,null),e(je,Oc),e(je,Fn),e(Fn,kc),f(t,sa,u),f(t,ve,u),e(ve,Qe),e(Qe,In),m(sr,In,null),e(ve,Vc),e(ve,Kn),e(Kn,Cc),f(t,na,u),f(t,Xe,u),e(Xe,Ac),e(Xe,nr),e(nr,Nc),e(Xe,Lc),f(t,oa,u),f(t,w,u),m(or,w,null),e(w,Fc),e(w,ns),e(ns,Ic),e(ns,ar),e(ar,Kc),e(w,qc),e(w,k),e(k,os),e(os,Uc),e(k,Hc),e(k,qn),e(qn,Rc),e(k,Wc),e(k,Un),e(Un,Bc),e(k,Gc),e(k,Hn),e(Hn,Yc),e(k,Jc),e(k,as),e(as,zc),e(k,jc),e(k,is),e(is,Qc),e(k,Xc),e(k,ds),e(ds,Zc),e(k,eu),e(w,tu),e(w,Ze),m(ir,Ze,null),e(Ze,ru),e(Ze,Rn),e(Rn,su),e(w,nu),e(w,et),m(dr,et,null),e(et,ou),e(et,lr),e(lr,au),e(lr,Wn),e(Wn,iu),e(lr,du),e(w,lu),e(w,tt),m(cr,tt,null),e(tt,cu),e(tt,Bn),e(Bn,uu),e(w,fu),e(w,rt),m(ur,rt,null),e(rt,pu),e(rt,Gn),e(Gn,hu),f(t,aa,u),f(t,be,u),e(be,st),e(st,Yn),m(fr,Yn,null),e(be,mu),e(be,Jn),e(Jn,gu),f(t,ia,u),f(t,nt,u),e(nt,_u),e(nt,pr),e(pr,vu),e(nt,bu),f(t,da,u),f(t,$,u),m(hr,$,null),e($,Su),e($,zn),e(zn,$u),e($,Du),e($,V),e(V,ls),e(ls,Eu),e(V,xu),e(V,jn),e(jn,yu),e(V,wu),e(V,Qn),e(Qn,Mu),e(V,Pu),e(V,Xn),e(Xn,Tu),e(V,Ou),e(V,cs),e(cs,ku),e(V,Vu),e(V,us),e(us,Cu),e(V,Au),e(V,fs),e(fs,Nu),e(V,Lu),e($,Fu),e($,ps),e(ps,Iu),e(ps,mr),e(mr,Ku),e($,qu),e($,ot),m(gr,ot,null),e(ot,Uu),e(ot,Zn),e(Zn,Hu),e($,Ru),e($,at),m(_r,at,null),e(at,Wu),e(at,eo),e(eo,Bu),e($,Gu),e($,re),m(vr,re,null),e(re,Yu),e(re,to),e(to,Ju),e(re,zu),e(re,Z),e(Z,ju),e(Z,ro),e(ro,Qu),e(Z,Xu),e(Z,so),e(so,Zu),e(Z,ef),e(Z,no),e(no,tf),e(Z,rf),e($,sf),e($,it),m(br,it,null),e(it,nf),e(it,oo),e(oo,of),e($,af),e($,dt),m(Sr,dt,null),e(dt,df),e(dt,ao),e(ao,lf),f(t,la,u),f(t,Se,u),e(Se,lt),e(lt,io),m($r,io,null),e(Se,cf),e(Se,lo),e(lo,uf),f(t,ca,u),f(t,ct,u),e(ct,ff),e(ct,Dr),e(Dr,pf),e(ct,hf),f(t,ua,u),f(t,D,u),m(Er,D,null),e(D,mf),e(D,co),e(co,gf),e(D,_f),e(D,hs),e(hs,vf),e(hs,xr),e(xr,bf),e(D,Sf),e(D,C),e(C,ms),e(ms,$f),e(C,Df),e(C,uo),e(uo,Ef),e(C,xf),e(C,fo),e(fo,yf),e(C,wf),e(C,po),e(po,Mf),e(C,Pf),e(C,gs),e(gs,Tf),e(C,Of),e(C,_s),e(_s,kf),e(C,Vf),e(C,vs),e(vs,Cf),e(C,Af),e(D,Nf),e(D,ut),m(yr,ut,null),e(ut,Lf),e(ut,ho),e(ho,Ff),e(D,If),e(D,se),m(wr,se,null),e(se,Kf),e(se,mo),e(mo,qf),e(se,Uf),e(se,$e),e($e,Hf),e($e,go),e(go,Rf),e($e,Wf),e($e,_o),e(_o,Bf),e($e,Gf),e(D,Yf),e(D,ft),m(Mr,ft,null),e(ft,Jf),e(ft,vo),e(vo,zf),e(D,jf),e(D,pt),m(Pr,pt,null),e(pt,Qf),e(pt,bo),e(bo,Xf),e(D,Zf),e(D,ht),m(Tr,ht,null),e(ht,ep),e(ht,So),e(So,tp),f(t,fa,u),f(t,De,u),e(De,mt),e(mt,$o),m(Or,$o,null),e(De,rp),e(De,Do),e(Do,sp),f(t,pa,u),f(t,gt,u),e(gt,np),e(gt,kr),e(kr,op),e(gt,ap),f(t,ha,u),m(_t,t,u),f(t,ma,u),f(t,K,u),m(Vr,K,null),e(K,ip),e(K,Eo),e(Eo,dp),e(K,lp),e(K,A),e(A,bs),e(bs,cp),e(A,up),e(A,xo),e(xo,fp),e(A,pp),e(A,yo),e(yo,hp),e(A,mp),e(A,wo),e(wo,gp),e(A,_p),e(A,Ss),e(Ss,vp),e(A,bp),e(A,$s),e($s,Sp),e(A,$p),e(A,Ds),e(Ds,Dp),e(A,Ep),e(K,xp),e(K,Es),e(Es,yp),e(Es,Cr),e(Cr,wp),e(K,Mp),e(K,Mo),e(Mo,Pp),ga=!0},p(t,[u]){const Ar={};u&2&&(Ar.$$scope={dirty:u,ctx:t}),_t.$set(Ar)},i(t){ga||(g(bt.$$.fragment,t),g(St.$$.fragment,t),g(Dt.$$.fragment,t),g(Et.$$.fragment,t),g(xt.$$.fragment,t),g(Mt.$$.fragment,t),g(Pt.$$.fragment,t),g(Tt.$$.fragment,t),g(Ot.$$.fragment,t),g(kt.$$.fragment,t),g(Vt.$$.fragment,t),g(Ct.$$.fragment,t),g(Nt.$$.fragment,t),g(Lt.$$.fragment,t),g(Ft.$$.fragment,t),g(It.$$.fragment,t),g(qt.$$.fragment,t),g(Ht.$$.fragment,t),g(Rt.$$.fragment,t),g(Wt.$$.fragment,t),g(Bt.$$.fragment,t),g(Yt.$$.fragment,t),g(Xt.$$.fragment,t),g(Zt.$$.fragment,t),g(er.$$.fragment,t),g(tr.$$.fragment,t),g(rr.$$.fragment,t),g(sr.$$.fragment,t),g(or.$$.fragment,t),g(ir.$$.fragment,t),g(dr.$$.fragment,t),g(cr.$$.fragment,t),g(ur.$$.fragment,t),g(fr.$$.fragment,t),g(hr.$$.fragment,t),g(gr.$$.fragment,t),g(_r.$$.fragment,t),g(vr.$$.fragment,t),g(br.$$.fragment,t),g(Sr.$$.fragment,t),g($r.$$.fragment,t),g(Er.$$.fragment,t),g(yr.$$.fragment,t),g(wr.$$.fragment,t),g(Mr.$$.fragment,t),g(Pr.$$.fragment,t),g(Tr.$$.fragment,t),g(Or.$$.fragment,t),g(_t.$$.fragment,t),g(Vr.$$.fragment,t),ga=!0)},o(t){_(bt.$$.fragment,t),_(St.$$.fragment,t),_(Dt.$$.fragment,t),_(Et.$$.fragment,t),_(xt.$$.fragment,t),_(Mt.$$.fragment,t),_(Pt.$$.fragment,t),_(Tt.$$.fragment,t),_(Ot.$$.fragment,t),_(kt.$$.fragment,t),_(Vt.$$.fragment,t),_(Ct.$$.fragment,t),_(Nt.$$.fragment,t),_(Lt.$$.fragment,t),_(Ft.$$.fragment,t),_(It.$$.fragment,t),_(qt.$$.fragment,t),_(Ht.$$.fragment,t),_(Rt.$$.fragment,t),_(Wt.$$.fragment,t),_(Bt.$$.fragment,t),_(Yt.$$.fragment,t),_(Xt.$$.fragment,t),_(Zt.$$.fragment,t),_(er.$$.fragment,t),_(tr.$$.fragment,t),_(rr.$$.fragment,t),_(sr.$$.fragment,t),_(or.$$.fragment,t),_(ir.$$.fragment,t),_(dr.$$.fragment,t),_(cr.$$.fragment,t),_(ur.$$.fragment,t),_(fr.$$.fragment,t),_(hr.$$.fragment,t),_(gr.$$.fragment,t),_(_r.$$.fragment,t),_(vr.$$.fragment,t),_(br.$$.fragment,t),_(Sr.$$.fragment,t),_($r.$$.fragment,t),_(Er.$$.fragment,t),_(yr.$$.fragment,t),_(wr.$$.fragment,t),_(Mr.$$.fragment,t),_(Pr.$$.fragment,t),_(Tr.$$.fragment,t),_(Or.$$.fragment,t),_(_t.$$.fragment,t),_(Vr.$$.fragment,t),ga=!1},d(t){r(F),t&&r(Ee),t&&r(I),v(bt),t&&r(Oo),t&&r(Nr),t&&r(ko),t&&r(oe),v(St),t&&r(Vo),t&&r(ye),t&&r(Co),t&&r(we),t&&r(Ao),t&&r(ie),v(Dt),t&&r(No),t&&r(M),t&&r(Lo),t&&r(de),v(Et),t&&r(Fo),t&&r(qr),t&&r(Io),t&&r(Te),t&&r(Ko),t&&r(le),v(xt),t&&r(qo),t&&r(Ur),t&&r(Uo),t&&r(ee),t&&r(Ho),t&&r(ke),t&&r(Ro),t&&r(ce),v(Mt),t&&r(Wo),t&&r(ue),v(Pt),t&&r(Bo),t&&r(fe),v(Tt),t&&r(Go),t&&r(pe),v(Ot),t&&r(Yo),t&&r(he),v(kt),t&&r(Jo),t&&r(me),v(Vt),t&&r(zo),t&&r(Rr),t&&r(jo),t&&r(x),v(Ct),v(Nt),v(Lt),v(Ft),t&&r(Qo),t&&r(ge),v(It),t&&r(Xo),t&&r(qe),t&&r(Zo),t&&r(y),v(qt),v(Ht),v(Rt),v(Wt),t&&r(ea),t&&r(_e),v(Bt),t&&r(ta),t&&r(Be),t&&r(ra),t&&r(S),v(Yt),v(Xt),v(Zt),v(er),v(tr),v(rr),t&&r(sa),t&&r(ve),v(sr),t&&r(na),t&&r(Xe),t&&r(oa),t&&r(w),v(or),v(ir),v(dr),v(cr),v(ur),t&&r(aa),t&&r(be),v(fr),t&&r(ia),t&&r(nt),t&&r(da),t&&r($),v(hr),v(gr),v(_r),v(vr),v(br),v(Sr),t&&r(la),t&&r(Se),v($r),t&&r(ca),t&&r(ct),t&&r(ua),t&&r(D),v(Er),v(yr),v(wr),v(Mr),v(Pr),v(Tr),t&&r(fa),t&&r(De),v(Or),t&&r(pa),t&&r(gt),t&&r(ha),v(_t,t),t&&r(ma),t&&r(K),v(Vr)}}}const Xg={local:"schedulers",sections:[{local:"what-is-a-scheduler",sections:[{local:"discrete-versus-continuous-schedulers",title:"Discrete versus continuous schedulers"}],title:"What is a scheduler?"},{local:"designing-reusable-schedulers",title:"Designing Re-usable schedulers"},{local:"api",sections:[{local:"diffusers.SchedulerMixin",title:"SchedulerMixin"},{local:"diffusers.schedulers.scheduling_utils.SchedulerOutput",title:"SchedulerOutput"},{local:"implemented-schedulers",sections:[{local:"diffusers.DDIMScheduler",title:"Denoising diffusion implicit models (DDIM)"},{local:"diffusers.DDPMScheduler",title:"Denoising diffusion probabilistic models (DDPM)"},{local:"diffusers.KarrasVeScheduler",title:"Variance exploding, stochastic sampling from Karras et. al"},{local:"diffusers.LMSDiscreteScheduler",title:"Linear multistep scheduler for discrete beta schedules"},{local:"diffusers.PNDMScheduler",title:"Pseudo numerical methods for diffusion models (PNDM)"},{local:"diffusers.ScoreSdeVeScheduler",title:"variance exploding stochastic differential equation (SDE) scheduler"},{local:"diffusers.schedulers.ScoreSdeVpScheduler",title:"variance preserving stochastic differential equation (SDE) scheduler"}],title:"Implemented Schedulers"}],title:"API"}],title:"Schedulers"};function Zg(To){return Jg(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class n_ extends Wg{constructor(F){super();Bg(this,F,Zg,Qg,Gg,{})}}export{n_ as default,Xg as metadata};
