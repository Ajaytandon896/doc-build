import{S as ru,i as su,s as ou,e as s,k as l,w as f,t as a,M as nu,c as o,d as r,m as c,a as n,x as h,h as i,b as d,G as e,g as u,y as m,q as g,o as _,B as v,v as au}from"../../chunks/vendor-hf-doc-builder.js";import{T as iu}from"../../chunks/Tip-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as O}from"../../chunks/IconCopyLink-hf-doc-builder.js";function du(oo){let x,de;return{c(){x=s("p"),de=a("Score SDE-VP is under construction.")},l(E){x=o(E,"P",{});var A=n(x);de=i(A,"Score SDE-VP is under construction."),A.forEach(r)},m(E,A){u(E,x,A),e(x,de)},d(E){E&&r(x)}}}function lu(oo){let x,de,E,A,Nr,et,qn,Ar,Hn,no,pr,Rn,ao,G,le,Lr,tt,Bn,Ir,Gn,io,ce,Wn,Fr,zn,Yn,lo,pe,ur,Jn,rt,Cr,jn,Qn,Kr,Xn,Zn,W,ea,Ur,ta,ra,qr,sa,oa,co,z,ue,Hr,st,na,Rr,aa,po,D,ia,Br,da,la,fr,ca,pa,hr,ua,fa,Gr,ha,ma,mr,ga,_a,Wr,va,ba,uo,Y,fe,zr,ot,Sa,Yr,$a,fo,gr,ya,ho,he,Jr,Da,xa,jr,wa,mo,J,me,Qr,nt,Ea,Xr,Pa,go,_r,Ta,_o,C,at,Ma,Zr,Oa,ka,Va,it,Na,es,Aa,La,Ia,dt,Fa,ts,Ca,Ka,vo,ge,Ua,vr,qa,Ha,bo,j,_e,rs,lt,Ra,ss,Ba,So,I,ct,Ga,os,Wa,za,ve,pt,Ya,ns,Ja,$o,Q,be,as,ut,ja,is,Qa,yo,X,ft,Xa,ds,Za,Do,Z,Se,ls,ht,ei,cs,ti,xo,ee,$e,ps,mt,ri,us,si,wo,br,oi,Eo,P,gt,ni,fs,ai,ii,Sr,di,_t,li,ci,ye,vt,pi,hs,ui,fi,De,bt,hi,ms,mi,Po,te,xe,gs,St,gi,_s,_i,To,we,vi,$t,bi,Si,Mo,T,yt,$i,vs,yi,Di,$r,xi,Dt,wi,Ei,Ee,xt,Pi,bs,Ti,Mi,Pe,wt,Oi,Ss,ki,Oo,re,Te,$s,Et,Vi,ys,Ni,ko,Me,Ai,Pt,Li,Ii,Vo,S,Tt,Fi,Ds,Ci,Ki,Oe,Ui,Mt,qi,Hi,Ot,Ri,Bi,kt,Gi,Vt,Wi,zi,Yi,K,Nt,Ji,xs,ji,Qi,ws,Xi,Zi,ke,At,ed,Es,td,rd,Ve,Lt,sd,Ps,od,nd,Ne,It,ad,Ts,id,No,se,Ae,Ms,Ft,dd,Os,ld,Ao,Le,cd,Ct,pd,ud,Lo,M,Kt,fd,yr,hd,Ut,md,gd,Ie,qt,_d,ks,vd,bd,Fe,Ht,Sd,Vs,$d,yd,Ce,Rt,Dd,Ns,xd,Io,oe,Ke,As,Bt,wd,Ls,Ed,Fo,Ue,Pd,Gt,Td,Md,Co,$,Wt,Od,Is,kd,Vd,Dr,Nd,zt,Ad,Ld,qe,Yt,Id,Fs,Fd,Cd,U,Jt,Kd,Cs,Ud,qd,F,Hd,Ks,Rd,Bd,Us,Gd,Wd,qs,zd,Yd,Jd,He,jt,jd,Hs,Qd,Xd,Re,Qt,Zd,Rs,el,Ko,ne,Be,Bs,Xt,tl,Gs,rl,Uo,Ge,sl,Zt,ol,nl,qo,y,er,al,Ws,il,dl,xr,ll,tr,cl,pl,q,rr,ul,zs,fl,hl,ae,ml,Ys,gl,_l,Js,vl,bl,Sl,We,sr,$l,js,yl,Dl,ze,or,xl,Qs,wl,El,Ye,nr,Pl,Xs,Tl,Ho,ie,Je,Zs,ar,Ml,eo,Ol,Ro,je,kl,ir,Vl,Nl,Bo,Qe,Go,L,dr,Al,to,Ll,Il,wr,Fl,lr,Cl,Kl,ro,Ul,Wo;return et=new O({}),tt=new O({}),st=new O({}),ot=new O({}),nt=new O({}),lt=new O({}),ct=new b({props:{name:"class diffusers.SchedulerMixin",anchor:"diffusers.SchedulerMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L40"}}),pt=new b({props:{name:"match_shape",anchor:"diffusers.SchedulerMixin.match_shape",parameters:[{name:"values",val:": typing.Union[numpy.ndarray, torch.Tensor]"},{name:"broadcast_array",val:": typing.Union[numpy.ndarray, torch.Tensor]"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L77",returnDescription:`
<p>a tensor of shape [batch_size, 1, \u2026] where the shape has K dims.</p>
`}}),ut=new O({}),ft=new b({props:{name:"class diffusers.schedulers.scheduling_utils.SchedulerOutput",anchor:"diffusers.schedulers.scheduling_utils.SchedulerOutput",parameters:[{name:"prev_sample",val:": FloatTensor"}],parametersDescription:[{anchor:"diffusers.schedulers.scheduling_utils.SchedulerOutput.prev_sample",description:`<strong>prev_sample</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_channels, height, width)</code> for images) &#x2014;
Computed sample (x_{t-1}) of previous timestep. <code>prev_sample</code> should be used as next model input in the
denoising loop.`,name:"prev_sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L27"}}),ht=new O({}),mt=new O({}),gt=new b({props:{name:"class diffusers.DDIMScheduler",anchor:"diffusers.DDIMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"timestep_values",val:": typing.Optional[numpy.ndarray] = None"},{name:"clip_sample",val:": bool = True"},{name:"set_alpha_to_one",val:": bool = True"},{name:"tensor_format",val:": str = 'pt'"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.DDIMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.DDIMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.DDIMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.DDIMScheduler.trained_betas",description:"<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014; TODO",name:"trained_betas"},{anchor:"diffusers.DDIMScheduler.timestep_values",description:"<strong>timestep_values</strong> (<code>np.ndarray</code>, optional) &#x2014; TODO",name:"timestep_values"},{anchor:"diffusers.DDIMScheduler.clip_sample",description:`<strong>clip_sample</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
option to clip predicted sample between -1 and 1 for numerical stability.`,name:"clip_sample"},{anchor:"diffusers.DDIMScheduler.set_alpha_to_one",description:`<strong>set_alpha_to_one</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
if alpha for final step is 1 or the final alpha of the &#x201C;non-previous&#x201D; one.`,name:"set_alpha_to_one"},{anchor:"diffusers.DDIMScheduler.tensor_format",description:"<strong>tensor_format</strong> (<code>str</code>) &#x2014; whether the scheduler expects pytorch or numpy arrays.",name:"tensor_format"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L57"}}),vt=new b({props:{name:"set_timesteps",anchor:"diffusers.DDIMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"offset",val:": int = 0"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.DDIMScheduler.set_timesteps.offset",description:"<strong>offset</strong> (<code>int</code>) &#x2014; TODO",name:"offset"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L133"}}),bt=new b({props:{name:"step",anchor:"diffusers.DDIMScheduler.step",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"eta",val:": float = 0.0"},{name:"use_clipped_model_output",val:": bool = False"},{name:"generator",val:" = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.DDIMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.DDIMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.DDIMScheduler.step.eta",description:"<strong>eta</strong> (<code>float</code>) &#x2014; weight of noise for added noise in diffusion step.",name:"eta"},{anchor:"diffusers.DDIMScheduler.step.use_clipped_model_output",description:`<strong>use_clipped_model_output</strong> (<code>bool</code>) &#x2014; TODO
generator &#x2014; random number generator.`,name:"use_clipped_model_output"},{anchor:"diffusers.DDIMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L149",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p><code>SchedulerOutput</code></p>
`}}),St=new O({}),yt=new b({props:{name:"class diffusers.DDPMScheduler",anchor:"diffusers.DDPMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"variance_type",val:": str = 'fixed_small'"},{name:"clip_sample",val:": bool = True"},{name:"tensor_format",val:": str = 'pt'"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.DDPMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.DDPMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.DDPMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.DDPMScheduler.trained_betas",description:"<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014; TODO",name:"trained_betas"},{anchor:"diffusers.DDPMScheduler.variance_type",description:`<strong>variance_type</strong> (<code>str</code>) &#x2014;
options to clip the variance used when adding noise to the denoised sample. Choose from <code>fixed_small</code>,
<code>fixed_small_log</code>, <code>fixed_large</code>, <code>fixed_large_log</code>, <code>learned</code> or <code>learned_range</code>.`,name:"variance_type"},{anchor:"diffusers.DDPMScheduler.clip_sample",description:`<strong>clip_sample</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
option to clip predicted sample between -1 and 1 for numerical stability.`,name:"clip_sample"},{anchor:"diffusers.DDPMScheduler.tensor_format",description:"<strong>tensor_format</strong> (<code>str</code>) &#x2014; whether the scheduler expects pytorch or numpy arrays.",name:"tensor_format"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L56"}}),xt=new b({props:{name:"set_timesteps",anchor:"diffusers.DDPMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L119"}}),wt=new b({props:{name:"step",anchor:"diffusers.DDPMScheduler.step",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"predict_epsilon",val:" = True"},{name:"generator",val:" = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.DDPMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.DDPMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.DDPMScheduler.step.eta",description:"<strong>eta</strong> (<code>float</code>) &#x2014; weight of noise for added noise in diffusion step.",name:"eta"},{anchor:"diffusers.DDPMScheduler.step.predict_epsilon",description:`<strong>predict_epsilon</strong> (<code>bool</code>) &#x2014;
optional flag to use when model predicts the samples directly instead of the noise, epsilon.
generator &#x2014; random number generator.`,name:"predict_epsilon"},{anchor:"diffusers.DDPMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L167",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p><code>SchedulerOutput</code></p>
`}}),Et=new O({}),Tt=new b({props:{name:"class diffusers.KarrasVeScheduler",anchor:"diffusers.KarrasVeScheduler",parameters:[{name:"sigma_min",val:": float = 0.02"},{name:"sigma_max",val:": float = 100"},{name:"s_noise",val:": float = 1.007"},{name:"s_churn",val:": float = 80"},{name:"s_min",val:": float = 0.05"},{name:"s_max",val:": float = 50"},{name:"tensor_format",val:": str = 'pt'"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.sigma_min",description:"<strong>sigma_min</strong> (<code>float</code>) &#x2014; minimum noise magnitude",name:"sigma_min"},{anchor:"diffusers.KarrasVeScheduler.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>) &#x2014; maximum noise magnitude",name:"sigma_max"},{anchor:"diffusers.KarrasVeScheduler.s_noise",description:`<strong>s_noise</strong> (<code>float</code>) &#x2014; the amount of additional noise to counteract loss of detail during sampling.
A reasonable range is [1.000, 1.011].`,name:"s_noise"},{anchor:"diffusers.KarrasVeScheduler.s_churn",description:`<strong>s_churn</strong> (<code>float</code>) &#x2014; the parameter controlling the overall amount of stochasticity.
A reasonable range is [0, 100].`,name:"s_churn"},{anchor:"diffusers.KarrasVeScheduler.s_min",description:`<strong>s_min</strong> (<code>float</code>) &#x2014; the start value of the sigma range where we add noise (enable stochasticity).
A reasonable range is [0, 10].`,name:"s_min"},{anchor:"diffusers.KarrasVeScheduler.s_max",description:`<strong>s_max</strong> (<code>float</code>) &#x2014; the end value of the sigma range where we add noise.
A reasonable range is [0.2, 80].`,name:"s_max"},{anchor:"diffusers.KarrasVeScheduler.tensor_format",description:"<strong>tensor_format</strong> (<code>str</code>) &#x2014; whether the scheduler expects pytorch or numpy arrays.",name:"tensor_format"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L44"}}),Nt=new b({props:{name:"add_noise_to_input",anchor:"diffusers.KarrasVeScheduler.add_noise_to_input",parameters:[{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"sigma",val:": float"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L110"}}),At=new b({props:{name:"set_timesteps",anchor:"diffusers.KarrasVeScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L91"}}),Lt=new b({props:{name:"step",anchor:"diffusers.KarrasVeScheduler.step",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"sigma_hat",val:": float"},{name:"sigma_prev",val:": float"},{name:"sample_hat",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.KarrasVeScheduler.step.sigma_hat",description:"<strong>sigma_hat</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_hat"},{anchor:"diffusers.KarrasVeScheduler.step.sigma_prev",description:"<strong>sigma_prev</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_prev"},{anchor:"diffusers.KarrasVeScheduler.step.sample_hat",description:"<strong>sample_hat</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; TODO",name:"sample_hat"},{anchor:"diffusers.KarrasVeScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L131",returnDescription:`
<p>updated sample in the diffusion chain and derivative (TODO double check).</p>
`,returnType:`
<p>KarrasVeOutput</p>
`}}),It=new b({props:{name:"step_correct",anchor:"diffusers.KarrasVeScheduler.step_correct",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"sigma_hat",val:": float"},{name:"sigma_prev",val:": float"},{name:"sample_hat",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"sample_prev",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"derivative",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.step_correct.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sigma_hat",description:"<strong>sigma_hat</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_hat"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sigma_prev",description:"<strong>sigma_prev</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_prev"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sample_hat",description:"<strong>sample_hat</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; TODO",name:"sample_hat"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sample_prev",description:"<strong>sample_prev</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; TODO",name:"sample_prev"},{anchor:"diffusers.KarrasVeScheduler.step_correct.derivative",description:"<strong>derivative</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; TODO",name:"derivative"},{anchor:"diffusers.KarrasVeScheduler.step_correct.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L164",returnDescription:`
<p>updated sample in the diffusion chain. derivative (TODO): TODO</p>
`,returnType:`
<p>prev_sample (TODO)</p>
`}}),Ft=new O({}),Kt=new b({props:{name:"class diffusers.LMSDiscreteScheduler",anchor:"diffusers.LMSDiscreteScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"timestep_values",val:": typing.Optional[numpy.ndarray] = None"},{name:"tensor_format",val:": str = 'pt'"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.LMSDiscreteScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.LMSDiscreteScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.LMSDiscreteScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code> or <code>scaled_linear</code>.`,name:"beta_schedule"},{anchor:"diffusers.LMSDiscreteScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014; TODO
options to clip the variance used when adding noise to the denoised sample. Choose from <code>fixed_small</code>,
<code>fixed_small_log</code>, <code>fixed_large</code>, <code>fixed_large_log</code>, <code>learned</code> or <code>learned_range</code>.`,name:"trained_betas"},{anchor:"diffusers.LMSDiscreteScheduler.timestep_values",description:"<strong>timestep_values</strong> (<code>np.ndarry</code>, optional) &#x2014; TODO",name:"timestep_values"},{anchor:"diffusers.LMSDiscreteScheduler.tensor_format",description:"<strong>tensor_format</strong> (<code>str</code>) &#x2014; whether the scheduler expects pytorch or numpy arrays.",name:"tensor_format"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L26"}}),qt=new b({props:{name:"get_lms_coefficient",anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient",parameters:[{name:"order",val:""},{name:"t",val:""},{name:"current_order",val:""}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.order",description:"<strong>order</strong> (TODO) &#x2014;",name:"order"},{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.t",description:"<strong>t</strong> (TODO) &#x2014;",name:"t"},{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.current_order",description:"<strong>current_order</strong> (TODO) &#x2014;",name:"current_order"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L81"}}),Ht=new b({props:{name:"set_timesteps",anchor:"diffusers.LMSDiscreteScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L103"}}),Rt=new b({props:{name:"step",anchor:"diffusers.LMSDiscreteScheduler.step",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"order",val:": int = 4"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.LMSDiscreteScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.LMSDiscreteScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.
order &#x2014; coefficient for multi-step inference.`,name:"sample"},{anchor:"diffusers.LMSDiscreteScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L125",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p>prev_sample (<code>SchedulerOutput</code> or <code>Tuple</code>)</p>
`}}),Bt=new O({}),Wt=new b({props:{name:"class diffusers.PNDMScheduler",anchor:"diffusers.PNDMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"tensor_format",val:": str = 'pt'"},{name:"skip_prk_steps",val:": bool = False"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.PNDMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.PNDMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.PNDMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.PNDMScheduler.trained_betas",description:"<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014; TODO",name:"trained_betas"},{anchor:"diffusers.PNDMScheduler.tensor_format",description:"<strong>tensor_format</strong> (<code>str</code>) &#x2014; whether the scheduler expects pytorch or numpy arrays",name:"tensor_format"},{anchor:"diffusers.PNDMScheduler.skip_prk_steps",description:`<strong>skip_prk_steps</strong> (<code>bool</code>) &#x2014;
allows the scheduler to skip the Runge-Kutta steps that are defined in the original paper as being required
before plms steps; defaults to <code>False</code>.`,name:"skip_prk_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L56"}}),Yt=new b({props:{name:"set_timesteps",anchor:"diffusers.PNDMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"offset",val:": int = 0"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.PNDMScheduler.set_timesteps.offset",description:"<strong>offset</strong> (<code>int</code>) &#x2014; TODO",name:"offset"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L129"}}),Jt=new b({props:{name:"step",anchor:"diffusers.PNDMScheduler.step",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L168",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p><code>SchedulerOutput</code></p>
`}}),jt=new b({props:{name:"step_plms",anchor:"diffusers.PNDMScheduler.step_plms",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step_plms.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step_plms.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step_plms.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step_plms.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L251",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p>prev_sample (<code>SchedulerOutput</code> or <code>Tuple</code>)</p>
`}}),Qt=new b({props:{name:"step_prk",anchor:"diffusers.PNDMScheduler.step_prk",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step_prk.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step_prk.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step_prk.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step_prk.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L197",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p>prev_sample (<code>SchedulerOutput</code> or <code>Tuple</code>)</p>
`}}),Xt=new O({}),er=new b({props:{name:"class diffusers.ScoreSdeVeScheduler",anchor:"diffusers.ScoreSdeVeScheduler",parameters:[{name:"num_train_timesteps",val:": int = 2000"},{name:"snr",val:": float = 0.15"},{name:"sigma_min",val:": float = 0.01"},{name:"sigma_max",val:": float = 1348.0"},{name:"sampling_eps",val:": float = 1e-05"},{name:"correct_steps",val:": int = 1"},{name:"tensor_format",val:": str = 'pt'"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.snr",description:`<strong>snr</strong> (<code>float</code>) &#x2014;
coefficient weighting the step from the model_output sample (from the network) to the random noise.`,name:"snr"},{anchor:"diffusers.ScoreSdeVeScheduler.sigma_min",description:`<strong>sigma_min</strong> (<code>float</code>) &#x2014;
initial noise scale for sigma sequence in sampling procedure. The minimum sigma should mirror the
distribution of the data.`,name:"sigma_min"},{anchor:"diffusers.ScoreSdeVeScheduler.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>) &#x2014; maximum value used for the range of continuous timesteps passed into the model.",name:"sigma_max"},{anchor:"diffusers.ScoreSdeVeScheduler.sampling_eps",description:`<strong>sampling_eps</strong> (<code>float</code>) &#x2014; the end value of sampling, where timesteps decrease progessively from 1 to
epsilon. &#x2014;`,name:"sampling_eps"},{anchor:"diffusers.ScoreSdeVeScheduler.correct_steps",description:"<strong>correct_steps</strong> (<code>int</code>) &#x2014; number of correction steps performed on a produced sample.",name:"correct_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.tensor_format",description:"<strong>tensor_format</strong> (<code>str</code>) &#x2014; &#x201C;np&#x201D; or &#x201C;pt&#x201D; for the expected format of samples passed to the Scheduler.",name:"tensor_format"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L46"}}),rr=new b({props:{name:"set_sigmas",anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas",parameters:[{name:"num_inference_steps",val:": int"},{name:"sigma_min",val:": float = None"},{name:"sigma_max",val:": float = None"},{name:"sampling_eps",val:": float = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sigma_min",description:`<strong>sigma_min</strong> (<code>float</code>, optional) &#x2014;
initial noise scale value (overrides value given at Scheduler instantiation).`,name:"sigma_min"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>, optional) &#x2014; final noise scale value (overrides value given at Scheduler instantiation).",name:"sigma_max"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sampling_eps",description:"<strong>sampling_eps</strong> (<code>float</code>, optional) &#x2014; final timestep value (overrides value given at Scheduler instantiation).",name:"sampling_eps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L103"}}),sr=new b({props:{name:"set_timesteps",anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"sampling_eps",val:": float = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps.sampling_eps",description:"<strong>sampling_eps</strong> (<code>float</code>, optional) &#x2014; final timestep value (overrides value given at Scheduler instantiation).",name:"sampling_eps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L84"}}),or=new b({props:{name:"step_correct",anchor:"diffusers.ScoreSdeVeScheduler.step_correct",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"},{name:"return_dict",val:": bool = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.
generator &#x2014; random number generator.`,name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L224",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p>prev_sample (<code>SchedulerOutput</code> or <code>Tuple</code>)</p>
`}}),nr=new b({props:{name:"step_pred",anchor:"diffusers.ScoreSdeVeScheduler.step_pred",parameters:[{name:"model_output",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"timestep",val:": int"},{name:"sample",val:": typing.Union[torch.FloatTensor, numpy.ndarray]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"},{name:"return_dict",val:": bool = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code> or <code>np.ndarray</code>) &#x2014;
current instance of sample being created by diffusion process.
generator &#x2014; random number generator.`,name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L163",returnDescription:`
<p>updated sample in the diffusion chain.</p>
`,returnType:`
<p>prev_sample (<code>SchedulerOutput</code> or <code>Tuple</code>)</p>
`}}),ar=new O({}),Qe=new iu({props:{warning:!0,$$slots:{default:[du]},$$scope:{ctx:oo}}}),dr=new b({props:{name:"class diffusers.schedulers.ScoreSdeVpScheduler",anchor:"diffusers.schedulers.ScoreSdeVpScheduler",parameters:[{name:"num_train_timesteps",val:" = 2000"},{name:"beta_min",val:" = 0.1"},{name:"beta_max",val:" = 20"},{name:"sampling_eps",val:" = 0.001"},{name:"tensor_format",val:" = 'np'"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_vp.py#L26"}}),{c(){x=s("meta"),de=l(),E=s("h1"),A=s("a"),Nr=s("span"),f(et.$$.fragment),qn=l(),Ar=s("span"),Hn=a("Schedulers"),no=l(),pr=s("p"),Rn=a("Diffusers contains multiple pre-built schedule functions for the diffusion process."),ao=l(),G=s("h2"),le=s("a"),Lr=s("span"),f(tt.$$.fragment),Bn=l(),Ir=s("span"),Gn=a("What is a scheduler?"),io=l(),ce=s("p"),Wn=a("The schedule functions, denoted "),Fr=s("em"),zn=a("Schedulers"),Yn=a(" in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample."),lo=l(),pe=s("ul"),ur=s("li"),Jn=a("Schedulers define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs."),rt=s("ul"),Cr=s("li"),jn=a("adding noise in different manners represent the algorithmic processes to train a diffusion model by adding noise to images."),Qn=l(),Kr=s("li"),Xn=a("for inference, the scheduler defines how to update a sample based on an output from a pretrained model."),Zn=l(),W=s("li"),ea=a("Schedulers are often defined by a "),Ur=s("em"),ta=a("noise schedule"),ra=a(" and an "),qr=s("em"),sa=a("update rule"),oa=a(" to solve the differential equation solution."),co=l(),z=s("h3"),ue=s("a"),Hr=s("span"),f(st.$$.fragment),na=l(),Rr=s("span"),aa=a("Discrete versus continuous schedulers"),po=l(),D=s("p"),ia=a(`All schedulers take in a timestep to predict the updated version of the sample being diffused.
The timesteps dictate where in the diffusion process the step is, where data is generated by iterating forward in time and inference is executed by propagating backwards through timesteps.
Different algorithms use timesteps that both discrete (accepting `),Br=s("code"),da=a("int"),la=a(" inputs), such as the "),fr=s("a"),ca=a("DDPMScheduler"),pa=a(" or "),hr=s("a"),ua=a("PNDMScheduler"),fa=a(", and continuous (accepting "),Gr=s("code"),ha=a("float"),ma=a(" inputs), such as the score-based schedulers "),mr=s("a"),ga=a("ScoreSdeVeScheduler"),_a=a(" or "),Wr=s("code"),va=a("ScoreSdeVpScheduler"),ba=a("."),uo=l(),Y=s("h2"),fe=s("a"),zr=s("span"),f(ot.$$.fragment),Sa=l(),Yr=s("span"),$a=a("Designing Re-usable schedulers"),fo=l(),gr=s("p"),ya=a(`The core design principle between the schedule functions is to be model, system, and framework independent.
This allows for rapid experimentation and cleaner abstractions in the code, where the model prediction is separated from the sample update.
To this end, the design of schedulers is such that:`),ho=l(),he=s("ul"),Jr=s("li"),Da=a("Schedulers can be used interchangeably between diffusion models in inference to find the preferred trade-off between speed and generation quality."),xa=l(),jr=s("li"),wa=a("Schedulers are currently by default in PyTorch, but are designed to be framework independent (partial Numpy support currently exists)."),mo=l(),J=s("h2"),me=s("a"),Qr=s("span"),f(nt.$$.fragment),Ea=l(),Xr=s("span"),Pa=a("API"),go=l(),_r=s("p"),Ta=a("The core API for any new scheduler must follow a limited structure."),_o=l(),C=s("ul"),at=s("li"),Ma=a("Schedulers should provide one or more "),Zr=s("code"),Oa=a("def step(...)"),ka=a(" functions that should be called to update the generated sample iteratively."),Va=l(),it=s("li"),Na=a("Schedulers should provide a "),es=s("code"),Aa=a("set_timesteps(...)"),La=a(" method that configures the parameters of a schedule function for a specific inference task."),Ia=l(),dt=s("li"),Fa=a(`Schedulers should be framework-agonstic, but provide a simple functionality to convert the scheduler into a specific framework, such as PyTorch
with a `),ts=s("code"),Ca=a("set_format(...)"),Ka=a(" method."),vo=l(),ge=s("p"),Ua=a("The base class "),vr=s("a"),qa=a("SchedulerMixin"),Ha=a(" implements low level utilities used by multiple schedulers."),bo=l(),j=s("h3"),_e=s("a"),rs=s("span"),f(lt.$$.fragment),Ra=l(),ss=s("span"),Ba=a("SchedulerMixin"),So=l(),I=s("div"),f(ct.$$.fragment),Ga=l(),os=s("p"),Wa=a("Mixin containing common functions for the schedulers."),za=l(),ve=s("div"),f(pt.$$.fragment),Ya=l(),ns=s("p"),Ja=a("Turns a 1-D array into an array or tensor with len(broadcast_array.shape) dims."),$o=l(),Q=s("h3"),be=s("a"),as=s("span"),f(ut.$$.fragment),ja=l(),is=s("span"),Qa=a("SchedulerOutput"),yo=a("\n\nThe class `SchedulerOutput` contains the ouputs from any schedulers `step(...)` call.\n"),X=s("div"),f(ft.$$.fragment),Xa=l(),ds=s("p"),Za=a("Base class for the scheduler\u2019s step function output."),Do=l(),Z=s("h3"),Se=s("a"),ls=s("span"),f(ht.$$.fragment),ei=l(),cs=s("span"),ti=a("Implemented Schedulers"),xo=l(),ee=s("h4"),$e=s("a"),ps=s("span"),f(mt.$$.fragment),ri=l(),us=s("span"),si=a("Denoising diffusion implicit models (DDIM)"),wo=l(),br=s("p"),oi=a("Original paper can be found here."),Eo=l(),P=s("div"),f(gt.$$.fragment),ni=l(),fs=s("p"),ai=a(`Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising
diffusion probabilistic models (DDPMs) with non-Markovian guidance.`),ii=l(),Sr=s("p"),di=a("For more details, see the original paper: "),_t=s("a"),li=a("https://arxiv.org/abs/2010.02502"),ci=l(),ye=s("div"),f(vt.$$.fragment),pi=l(),hs=s("p"),ui=a("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),fi=l(),De=s("div"),f(bt.$$.fragment),hi=l(),ms=s("p"),mi=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Po=l(),te=s("h4"),xe=s("a"),gs=s("span"),f(St.$$.fragment),gi=l(),_s=s("span"),_i=a("Denoising diffusion probabilistic models (DDPM)"),To=l(),we=s("p"),vi=a("Original paper can be found "),$t=s("a"),bi=a("here"),Si=a("."),Mo=l(),T=s("div"),f(yt.$$.fragment),$i=l(),vs=s("p"),yi=a(`Denoising diffusion probabilistic models (DDPMs) explores the connections between denoising score matching and
Langevin dynamics sampling.`),Di=l(),$r=s("p"),xi=a("For more details, see the original paper: "),Dt=s("a"),wi=a("https://arxiv.org/abs/2006.11239"),Ei=l(),Ee=s("div"),f(xt.$$.fragment),Pi=l(),bs=s("p"),Ti=a("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Mi=l(),Pe=s("div"),f(wt.$$.fragment),Oi=l(),Ss=s("p"),ki=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Oo=l(),re=s("h4"),Te=s("a"),$s=s("span"),f(Et.$$.fragment),Vi=l(),ys=s("span"),Ni=a("Varience exploding, stochastic sampling from Karras et. al"),ko=l(),Me=s("p"),Ai=a("Original paper can be found "),Pt=s("a"),Li=a("here"),Ii=a("."),Vo=l(),S=s("div"),f(Tt.$$.fragment),Fi=l(),Ds=s("p"),Ci=a(`Stochastic sampling from Karras et al. [1] tailored to the Variance-Expanding (VE) models [2]. Use Algorithm 2 and
the VE column of Table 1 from [1] for reference.`),Ki=l(),Oe=s("p"),Ui=a(`[1] Karras, Tero, et al. \u201CElucidating the Design Space of Diffusion-Based Generative Models.\u201D
`),Mt=s("a"),qi=a("https://arxiv.org/abs/2206.00364"),Hi=a(` [2] Song, Yang, et al. \u201CScore-based generative modeling through stochastic
differential equations.\u201D `),Ot=s("a"),Ri=a("https://arxiv.org/abs/2011.13456"),Bi=l(),kt=s("p"),Gi=a(`For more details on the parameters, see the original paper\u2019s Appendix E.: \u201CElucidating the Design Space of
Diffusion-Based Generative Models.\u201D `),Vt=s("a"),Wi=a("https://arxiv.org/abs/2206.00364"),zi=a(`. The grid search values used to find the
optimal {s_noise, s_churn, s_min, s_max} for a specific model are described in Table 5 of the paper.`),Yi=l(),K=s("div"),f(Nt.$$.fragment),Ji=l(),xs=s("p"),ji=a(`Explicit Langevin-like \u201Cchurn\u201D step of adding noise to the sample according to a factor gamma_i \u2265 0 to reach a
higher noise level sigma_hat = sigma_i + gamma_i*sigma_i.`),Qi=l(),ws=s("p"),Xi=a("TODO Args:"),Zi=l(),ke=s("div"),f(At.$$.fragment),ed=l(),Es=s("p"),td=a("Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),rd=l(),Ve=s("div"),f(Lt.$$.fragment),sd=l(),Ps=s("p"),od=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),nd=l(),Ne=s("div"),f(It.$$.fragment),ad=l(),Ts=s("p"),id=a("Correct the predicted sample based on the output model_output of the network. TODO complete description"),No=l(),se=s("h4"),Ae=s("a"),Ms=s("span"),f(Ft.$$.fragment),dd=l(),Os=s("span"),ld=a("Linear multistep scheduler for discrete beta schedules"),Ao=l(),Le=s("p"),cd=a("Original implementation can be found "),Ct=s("a"),pd=a("here"),ud=a("."),Lo=l(),M=s("div"),f(Kt.$$.fragment),fd=l(),yr=s("p"),hd=a(`Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by
Katherine Crowson:
`),Ut=s("a"),md=a("https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),gd=l(),Ie=s("div"),f(qt.$$.fragment),_d=l(),ks=s("p"),vd=a("Compute a linear multistep coefficient."),bd=l(),Fe=s("div"),f(Ht.$$.fragment),Sd=l(),Vs=s("p"),$d=a("Sets the timesteps used for the diffusion chain. Supporting function to be run before inference."),yd=l(),Ce=s("div"),f(Rt.$$.fragment),Dd=l(),Ns=s("p"),xd=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Io=l(),oe=s("h4"),Ke=s("a"),As=s("span"),f(Bt.$$.fragment),wd=l(),Ls=s("span"),Ed=a("Pseudo numerical methods for diffusion models (PNDM)"),Fo=l(),Ue=s("p"),Pd=a("Original implementation can be found "),Gt=s("a"),Td=a("here"),Md=a("."),Co=l(),$=s("div"),f(Wt.$$.fragment),Od=l(),Is=s("p"),kd=a(`Pseudo numerical methods for diffusion models (PNDM) proposes using more advanced ODE integration techniques,
namely Runge-Kutta method and a linear multi-step method.`),Vd=l(),Dr=s("p"),Nd=a("For more details, see the original paper: "),zt=s("a"),Ad=a("https://arxiv.org/abs/2202.09778"),Ld=l(),qe=s("div"),f(Yt.$$.fragment),Id=l(),Fs=s("p"),Fd=a("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Cd=l(),U=s("div"),f(Jt.$$.fragment),Kd=l(),Cs=s("p"),Ud=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),qd=l(),F=s("p"),Hd=a("This function calls "),Ks=s("code"),Rd=a("step_prk()"),Bd=a(" or "),Us=s("code"),Gd=a("step_plms()"),Wd=a(" depending on the internal variable "),qs=s("code"),zd=a("counter"),Yd=a("."),Jd=l(),He=s("div"),f(jt.$$.fragment),jd=l(),Hs=s("p"),Qd=a(`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),Xd=l(),Re=s("div"),f(Qt.$$.fragment),Zd=l(),Rs=s("p"),el=a(`Step function propagating the sample with the Runge-Kutta method. RK takes 4 forward passes to approximate the
solution to the differential equation.`),Ko=l(),ne=s("h4"),Be=s("a"),Bs=s("span"),f(Xt.$$.fragment),tl=l(),Gs=s("span"),rl=a("variance exploding stochastic differential equation (SDE) scheduler"),Uo=l(),Ge=s("p"),sl=a("Original paper can be found "),Zt=s("a"),ol=a("here"),nl=a("."),qo=l(),y=s("div"),f(er.$$.fragment),al=l(),Ws=s("p"),il=a("The variance exploding stochastic differential equation (SDE) scheduler."),dl=l(),xr=s("p"),ll=a("For more information, see the original paper: "),tr=s("a"),cl=a("https://arxiv.org/abs/2011.13456"),pl=l(),q=s("div"),f(rr.$$.fragment),ul=l(),zs=s("p"),fl=a("Sets the noise scales used for the diffusion chain. Supporting function to be run before inference."),hl=l(),ae=s("p"),ml=a("The sigmas control the weight of the "),Ys=s("code"),gl=a("drift"),_l=a(" and "),Js=s("code"),vl=a("diffusion"),bl=a(" components of sample update."),Sl=l(),We=s("div"),f(sr.$$.fragment),$l=l(),js=s("p"),yl=a("Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),Dl=l(),ze=s("div"),f(or.$$.fragment),xl=l(),Qs=s("p"),wl=a(`Correct the predicted sample based on the output model_output of the network. This is often run repeatedly
after making the prediction for the previous timestep.`),El=l(),Ye=s("div"),f(nr.$$.fragment),Pl=l(),Xs=s("p"),Tl=a(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Ho=l(),ie=s("h4"),Je=s("a"),Zs=s("span"),f(ar.$$.fragment),Ml=l(),eo=s("span"),Ol=a("variance preserving stochastic differential equation (SDE) scheduler"),Ro=l(),je=s("p"),kl=a("Original paper can be found "),ir=s("a"),Vl=a("here"),Nl=a("."),Bo=l(),f(Qe.$$.fragment),Go=l(),L=s("div"),f(dr.$$.fragment),Al=l(),to=s("p"),Ll=a("The variance preserving stochastic differential equation (SDE) scheduler."),Il=l(),wr=s("p"),Fl=a("For more information, see the original paper: "),lr=s("a"),Cl=a("https://arxiv.org/abs/2011.13456"),Kl=l(),ro=s("p"),Ul=a("UNDER CONSTRUCTION"),this.h()},l(t){const p=nu('[data-svelte="svelte-1phssyn"]',document.head);x=o(p,"META",{name:!0,content:!0}),p.forEach(r),de=c(t),E=o(t,"H1",{class:!0});var cr=n(E);A=o(cr,"A",{id:!0,class:!0,href:!0});var Yl=n(A);Nr=o(Yl,"SPAN",{});var Jl=n(Nr);h(et.$$.fragment,Jl),Jl.forEach(r),Yl.forEach(r),qn=c(cr),Ar=o(cr,"SPAN",{});var jl=n(Ar);Hn=i(jl,"Schedulers"),jl.forEach(r),cr.forEach(r),no=c(t),pr=o(t,"P",{});var Ql=n(pr);Rn=i(Ql,"Diffusers contains multiple pre-built schedule functions for the diffusion process."),Ql.forEach(r),ao=c(t),G=o(t,"H2",{class:!0});var zo=n(G);le=o(zo,"A",{id:!0,class:!0,href:!0});var Xl=n(le);Lr=o(Xl,"SPAN",{});var Zl=n(Lr);h(tt.$$.fragment,Zl),Zl.forEach(r),Xl.forEach(r),Bn=c(zo),Ir=o(zo,"SPAN",{});var ec=n(Ir);Gn=i(ec,"What is a scheduler?"),ec.forEach(r),zo.forEach(r),io=c(t),ce=o(t,"P",{});var Yo=n(ce);Wn=i(Yo,"The schedule functions, denoted "),Fr=o(Yo,"EM",{});var tc=n(Fr);zn=i(tc,"Schedulers"),tc.forEach(r),Yn=i(Yo," in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample."),Yo.forEach(r),lo=c(t),pe=o(t,"UL",{});var Jo=n(pe);ur=o(Jo,"LI",{});var ql=n(ur);Jn=i(ql,"Schedulers define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs."),rt=o(ql,"UL",{});var jo=n(rt);Cr=o(jo,"LI",{});var rc=n(Cr);jn=i(rc,"adding noise in different manners represent the algorithmic processes to train a diffusion model by adding noise to images."),rc.forEach(r),Qn=c(jo),Kr=o(jo,"LI",{});var sc=n(Kr);Xn=i(sc,"for inference, the scheduler defines how to update a sample based on an output from a pretrained model."),sc.forEach(r),jo.forEach(r),ql.forEach(r),Zn=c(Jo),W=o(Jo,"LI",{});var Er=n(W);ea=i(Er,"Schedulers are often defined by a "),Ur=o(Er,"EM",{});var oc=n(Ur);ta=i(oc,"noise schedule"),oc.forEach(r),ra=i(Er," and an "),qr=o(Er,"EM",{});var nc=n(qr);sa=i(nc,"update rule"),nc.forEach(r),oa=i(Er," to solve the differential equation solution."),Er.forEach(r),Jo.forEach(r),co=c(t),z=o(t,"H3",{class:!0});var Qo=n(z);ue=o(Qo,"A",{id:!0,class:!0,href:!0});var ac=n(ue);Hr=o(ac,"SPAN",{});var ic=n(Hr);h(st.$$.fragment,ic),ic.forEach(r),ac.forEach(r),na=c(Qo),Rr=o(Qo,"SPAN",{});var dc=n(Rr);aa=i(dc,"Discrete versus continuous schedulers"),dc.forEach(r),Qo.forEach(r),po=c(t),D=o(t,"P",{});var k=n(D);ia=i(k,`All schedulers take in a timestep to predict the updated version of the sample being diffused.
The timesteps dictate where in the diffusion process the step is, where data is generated by iterating forward in time and inference is executed by propagating backwards through timesteps.
Different algorithms use timesteps that both discrete (accepting `),Br=o(k,"CODE",{});var lc=n(Br);da=i(lc,"int"),lc.forEach(r),la=i(k," inputs), such as the "),fr=o(k,"A",{href:!0});var cc=n(fr);ca=i(cc,"DDPMScheduler"),cc.forEach(r),pa=i(k," or "),hr=o(k,"A",{href:!0});var pc=n(hr);ua=i(pc,"PNDMScheduler"),pc.forEach(r),fa=i(k,", and continuous (accepting "),Gr=o(k,"CODE",{});var uc=n(Gr);ha=i(uc,"float"),uc.forEach(r),ma=i(k," inputs), such as the score-based schedulers "),mr=o(k,"A",{href:!0});var fc=n(mr);ga=i(fc,"ScoreSdeVeScheduler"),fc.forEach(r),_a=i(k," or "),Wr=o(k,"CODE",{});var hc=n(Wr);va=i(hc,"ScoreSdeVpScheduler"),hc.forEach(r),ba=i(k,"."),k.forEach(r),uo=c(t),Y=o(t,"H2",{class:!0});var Xo=n(Y);fe=o(Xo,"A",{id:!0,class:!0,href:!0});var mc=n(fe);zr=o(mc,"SPAN",{});var gc=n(zr);h(ot.$$.fragment,gc),gc.forEach(r),mc.forEach(r),Sa=c(Xo),Yr=o(Xo,"SPAN",{});var _c=n(Yr);$a=i(_c,"Designing Re-usable schedulers"),_c.forEach(r),Xo.forEach(r),fo=c(t),gr=o(t,"P",{});var vc=n(gr);ya=i(vc,`The core design principle between the schedule functions is to be model, system, and framework independent.
This allows for rapid experimentation and cleaner abstractions in the code, where the model prediction is separated from the sample update.
To this end, the design of schedulers is such that:`),vc.forEach(r),ho=c(t),he=o(t,"UL",{});var Zo=n(he);Jr=o(Zo,"LI",{});var bc=n(Jr);Da=i(bc,"Schedulers can be used interchangeably between diffusion models in inference to find the preferred trade-off between speed and generation quality."),bc.forEach(r),xa=c(Zo),jr=o(Zo,"LI",{});var Sc=n(jr);wa=i(Sc,"Schedulers are currently by default in PyTorch, but are designed to be framework independent (partial Numpy support currently exists)."),Sc.forEach(r),Zo.forEach(r),mo=c(t),J=o(t,"H2",{class:!0});var en=n(J);me=o(en,"A",{id:!0,class:!0,href:!0});var $c=n(me);Qr=o($c,"SPAN",{});var yc=n(Qr);h(nt.$$.fragment,yc),yc.forEach(r),$c.forEach(r),Ea=c(en),Xr=o(en,"SPAN",{});var Dc=n(Xr);Pa=i(Dc,"API"),Dc.forEach(r),en.forEach(r),go=c(t),_r=o(t,"P",{});var xc=n(_r);Ta=i(xc,"The core API for any new scheduler must follow a limited structure."),xc.forEach(r),_o=c(t),C=o(t,"UL",{});var Pr=n(C);at=o(Pr,"LI",{});var tn=n(at);Ma=i(tn,"Schedulers should provide one or more "),Zr=o(tn,"CODE",{});var wc=n(Zr);Oa=i(wc,"def step(...)"),wc.forEach(r),ka=i(tn," functions that should be called to update the generated sample iteratively."),tn.forEach(r),Va=c(Pr),it=o(Pr,"LI",{});var rn=n(it);Na=i(rn,"Schedulers should provide a "),es=o(rn,"CODE",{});var Ec=n(es);Aa=i(Ec,"set_timesteps(...)"),Ec.forEach(r),La=i(rn," method that configures the parameters of a schedule function for a specific inference task."),rn.forEach(r),Ia=c(Pr),dt=o(Pr,"LI",{});var sn=n(dt);Fa=i(sn,`Schedulers should be framework-agonstic, but provide a simple functionality to convert the scheduler into a specific framework, such as PyTorch
with a `),ts=o(sn,"CODE",{});var Pc=n(ts);Ca=i(Pc,"set_format(...)"),Pc.forEach(r),Ka=i(sn," method."),sn.forEach(r),Pr.forEach(r),vo=c(t),ge=o(t,"P",{});var on=n(ge);Ua=i(on,"The base class "),vr=o(on,"A",{href:!0});var Tc=n(vr);qa=i(Tc,"SchedulerMixin"),Tc.forEach(r),Ha=i(on," implements low level utilities used by multiple schedulers."),on.forEach(r),bo=c(t),j=o(t,"H3",{class:!0});var nn=n(j);_e=o(nn,"A",{id:!0,class:!0,href:!0});var Mc=n(_e);rs=o(Mc,"SPAN",{});var Oc=n(rs);h(lt.$$.fragment,Oc),Oc.forEach(r),Mc.forEach(r),Ra=c(nn),ss=o(nn,"SPAN",{});var kc=n(ss);Ba=i(kc,"SchedulerMixin"),kc.forEach(r),nn.forEach(r),So=c(t),I=o(t,"DIV",{class:!0});var Tr=n(I);h(ct.$$.fragment,Tr),Ga=c(Tr),os=o(Tr,"P",{});var Vc=n(os);Wa=i(Vc,"Mixin containing common functions for the schedulers."),Vc.forEach(r),za=c(Tr),ve=o(Tr,"DIV",{class:!0});var an=n(ve);h(pt.$$.fragment,an),Ya=c(an),ns=o(an,"P",{});var Nc=n(ns);Ja=i(Nc,"Turns a 1-D array into an array or tensor with len(broadcast_array.shape) dims."),Nc.forEach(r),an.forEach(r),Tr.forEach(r),$o=c(t),Q=o(t,"H3",{class:!0});var dn=n(Q);be=o(dn,"A",{id:!0,class:!0,href:!0});var Ac=n(be);as=o(Ac,"SPAN",{});var Lc=n(as);h(ut.$$.fragment,Lc),Lc.forEach(r),Ac.forEach(r),ja=c(dn),is=o(dn,"SPAN",{});var Ic=n(is);Qa=i(Ic,"SchedulerOutput"),Ic.forEach(r),dn.forEach(r),yo=i(t,"\n\nThe class `SchedulerOutput` contains the ouputs from any schedulers `step(...)` call.\n"),X=o(t,"DIV",{class:!0});var ln=n(X);h(ft.$$.fragment,ln),Xa=c(ln),ds=o(ln,"P",{});var Fc=n(ds);Za=i(Fc,"Base class for the scheduler\u2019s step function output."),Fc.forEach(r),ln.forEach(r),Do=c(t),Z=o(t,"H3",{class:!0});var cn=n(Z);Se=o(cn,"A",{id:!0,class:!0,href:!0});var Cc=n(Se);ls=o(Cc,"SPAN",{});var Kc=n(ls);h(ht.$$.fragment,Kc),Kc.forEach(r),Cc.forEach(r),ei=c(cn),cs=o(cn,"SPAN",{});var Uc=n(cs);ti=i(Uc,"Implemented Schedulers"),Uc.forEach(r),cn.forEach(r),xo=c(t),ee=o(t,"H4",{class:!0});var pn=n(ee);$e=o(pn,"A",{id:!0,class:!0,href:!0});var qc=n($e);ps=o(qc,"SPAN",{});var Hc=n(ps);h(mt.$$.fragment,Hc),Hc.forEach(r),qc.forEach(r),ri=c(pn),us=o(pn,"SPAN",{});var Rc=n(us);si=i(Rc,"Denoising diffusion implicit models (DDIM)"),Rc.forEach(r),pn.forEach(r),wo=c(t),br=o(t,"P",{});var Bc=n(br);oi=i(Bc,"Original paper can be found here."),Bc.forEach(r),Eo=c(t),P=o(t,"DIV",{class:!0});var H=n(P);h(gt.$$.fragment,H),ni=c(H),fs=o(H,"P",{});var Gc=n(fs);ai=i(Gc,`Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising
diffusion probabilistic models (DDPMs) with non-Markovian guidance.`),Gc.forEach(r),ii=c(H),Sr=o(H,"P",{});var Hl=n(Sr);di=i(Hl,"For more details, see the original paper: "),_t=o(Hl,"A",{href:!0,rel:!0});var Wc=n(_t);li=i(Wc,"https://arxiv.org/abs/2010.02502"),Wc.forEach(r),Hl.forEach(r),ci=c(H),ye=o(H,"DIV",{class:!0});var un=n(ye);h(vt.$$.fragment,un),pi=c(un),hs=o(un,"P",{});var zc=n(hs);ui=i(zc,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),zc.forEach(r),un.forEach(r),fi=c(H),De=o(H,"DIV",{class:!0});var fn=n(De);h(bt.$$.fragment,fn),hi=c(fn),ms=o(fn,"P",{});var Yc=n(ms);mi=i(Yc,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Yc.forEach(r),fn.forEach(r),H.forEach(r),Po=c(t),te=o(t,"H4",{class:!0});var hn=n(te);xe=o(hn,"A",{id:!0,class:!0,href:!0});var Jc=n(xe);gs=o(Jc,"SPAN",{});var jc=n(gs);h(St.$$.fragment,jc),jc.forEach(r),Jc.forEach(r),gi=c(hn),_s=o(hn,"SPAN",{});var Qc=n(_s);_i=i(Qc,"Denoising diffusion probabilistic models (DDPM)"),Qc.forEach(r),hn.forEach(r),To=c(t),we=o(t,"P",{});var mn=n(we);vi=i(mn,"Original paper can be found "),$t=o(mn,"A",{href:!0,rel:!0});var Xc=n($t);bi=i(Xc,"here"),Xc.forEach(r),Si=i(mn,"."),mn.forEach(r),Mo=c(t),T=o(t,"DIV",{class:!0});var R=n(T);h(yt.$$.fragment,R),$i=c(R),vs=o(R,"P",{});var Zc=n(vs);yi=i(Zc,`Denoising diffusion probabilistic models (DDPMs) explores the connections between denoising score matching and
Langevin dynamics sampling.`),Zc.forEach(r),Di=c(R),$r=o(R,"P",{});var Rl=n($r);xi=i(Rl,"For more details, see the original paper: "),Dt=o(Rl,"A",{href:!0,rel:!0});var ep=n(Dt);wi=i(ep,"https://arxiv.org/abs/2006.11239"),ep.forEach(r),Rl.forEach(r),Ei=c(R),Ee=o(R,"DIV",{class:!0});var gn=n(Ee);h(xt.$$.fragment,gn),Pi=c(gn),bs=o(gn,"P",{});var tp=n(bs);Ti=i(tp,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),tp.forEach(r),gn.forEach(r),Mi=c(R),Pe=o(R,"DIV",{class:!0});var _n=n(Pe);h(wt.$$.fragment,_n),Oi=c(_n),Ss=o(_n,"P",{});var rp=n(Ss);ki=i(rp,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),rp.forEach(r),_n.forEach(r),R.forEach(r),Oo=c(t),re=o(t,"H4",{class:!0});var vn=n(re);Te=o(vn,"A",{id:!0,class:!0,href:!0});var sp=n(Te);$s=o(sp,"SPAN",{});var op=n($s);h(Et.$$.fragment,op),op.forEach(r),sp.forEach(r),Vi=c(vn),ys=o(vn,"SPAN",{});var np=n(ys);Ni=i(np,"Varience exploding, stochastic sampling from Karras et. al"),np.forEach(r),vn.forEach(r),ko=c(t),Me=o(t,"P",{});var bn=n(Me);Ai=i(bn,"Original paper can be found "),Pt=o(bn,"A",{href:!0,rel:!0});var ap=n(Pt);Li=i(ap,"here"),ap.forEach(r),Ii=i(bn,"."),bn.forEach(r),Vo=c(t),S=o(t,"DIV",{class:!0});var w=n(S);h(Tt.$$.fragment,w),Fi=c(w),Ds=o(w,"P",{});var ip=n(Ds);Ci=i(ip,`Stochastic sampling from Karras et al. [1] tailored to the Variance-Expanding (VE) models [2]. Use Algorithm 2 and
the VE column of Table 1 from [1] for reference.`),ip.forEach(r),Ki=c(w),Oe=o(w,"P",{});var so=n(Oe);Ui=i(so,`[1] Karras, Tero, et al. \u201CElucidating the Design Space of Diffusion-Based Generative Models.\u201D
`),Mt=o(so,"A",{href:!0,rel:!0});var dp=n(Mt);qi=i(dp,"https://arxiv.org/abs/2206.00364"),dp.forEach(r),Hi=i(so,` [2] Song, Yang, et al. \u201CScore-based generative modeling through stochastic
differential equations.\u201D `),Ot=o(so,"A",{href:!0,rel:!0});var lp=n(Ot);Ri=i(lp,"https://arxiv.org/abs/2011.13456"),lp.forEach(r),so.forEach(r),Bi=c(w),kt=o(w,"P",{});var Sn=n(kt);Gi=i(Sn,`For more details on the parameters, see the original paper\u2019s Appendix E.: \u201CElucidating the Design Space of
Diffusion-Based Generative Models.\u201D `),Vt=o(Sn,"A",{href:!0,rel:!0});var cp=n(Vt);Wi=i(cp,"https://arxiv.org/abs/2206.00364"),cp.forEach(r),zi=i(Sn,`. The grid search values used to find the
optimal {s_noise, s_churn, s_min, s_max} for a specific model are described in Table 5 of the paper.`),Sn.forEach(r),Yi=c(w),K=o(w,"DIV",{class:!0});var Mr=n(K);h(Nt.$$.fragment,Mr),Ji=c(Mr),xs=o(Mr,"P",{});var pp=n(xs);ji=i(pp,`Explicit Langevin-like \u201Cchurn\u201D step of adding noise to the sample according to a factor gamma_i \u2265 0 to reach a
higher noise level sigma_hat = sigma_i + gamma_i*sigma_i.`),pp.forEach(r),Qi=c(Mr),ws=o(Mr,"P",{});var up=n(ws);Xi=i(up,"TODO Args:"),up.forEach(r),Mr.forEach(r),Zi=c(w),ke=o(w,"DIV",{class:!0});var $n=n(ke);h(At.$$.fragment,$n),ed=c($n),Es=o($n,"P",{});var fp=n(Es);td=i(fp,"Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),fp.forEach(r),$n.forEach(r),rd=c(w),Ve=o(w,"DIV",{class:!0});var yn=n(Ve);h(Lt.$$.fragment,yn),sd=c(yn),Ps=o(yn,"P",{});var hp=n(Ps);od=i(hp,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),hp.forEach(r),yn.forEach(r),nd=c(w),Ne=o(w,"DIV",{class:!0});var Dn=n(Ne);h(It.$$.fragment,Dn),ad=c(Dn),Ts=o(Dn,"P",{});var mp=n(Ts);id=i(mp,"Correct the predicted sample based on the output model_output of the network. TODO complete description"),mp.forEach(r),Dn.forEach(r),w.forEach(r),No=c(t),se=o(t,"H4",{class:!0});var xn=n(se);Ae=o(xn,"A",{id:!0,class:!0,href:!0});var gp=n(Ae);Ms=o(gp,"SPAN",{});var _p=n(Ms);h(Ft.$$.fragment,_p),_p.forEach(r),gp.forEach(r),dd=c(xn),Os=o(xn,"SPAN",{});var vp=n(Os);ld=i(vp,"Linear multistep scheduler for discrete beta schedules"),vp.forEach(r),xn.forEach(r),Ao=c(t),Le=o(t,"P",{});var wn=n(Le);cd=i(wn,"Original implementation can be found "),Ct=o(wn,"A",{href:!0,rel:!0});var bp=n(Ct);pd=i(bp,"here"),bp.forEach(r),ud=i(wn,"."),wn.forEach(r),Lo=c(t),M=o(t,"DIV",{class:!0});var B=n(M);h(Kt.$$.fragment,B),fd=c(B),yr=o(B,"P",{});var Bl=n(yr);hd=i(Bl,`Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by
Katherine Crowson:
`),Ut=o(Bl,"A",{href:!0,rel:!0});var Sp=n(Ut);md=i(Sp,"https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),Sp.forEach(r),Bl.forEach(r),gd=c(B),Ie=o(B,"DIV",{class:!0});var En=n(Ie);h(qt.$$.fragment,En),_d=c(En),ks=o(En,"P",{});var $p=n(ks);vd=i($p,"Compute a linear multistep coefficient."),$p.forEach(r),En.forEach(r),bd=c(B),Fe=o(B,"DIV",{class:!0});var Pn=n(Fe);h(Ht.$$.fragment,Pn),Sd=c(Pn),Vs=o(Pn,"P",{});var yp=n(Vs);$d=i(yp,"Sets the timesteps used for the diffusion chain. Supporting function to be run before inference."),yp.forEach(r),Pn.forEach(r),yd=c(B),Ce=o(B,"DIV",{class:!0});var Tn=n(Ce);h(Rt.$$.fragment,Tn),Dd=c(Tn),Ns=o(Tn,"P",{});var Dp=n(Ns);xd=i(Dp,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Dp.forEach(r),Tn.forEach(r),B.forEach(r),Io=c(t),oe=o(t,"H4",{class:!0});var Mn=n(oe);Ke=o(Mn,"A",{id:!0,class:!0,href:!0});var xp=n(Ke);As=o(xp,"SPAN",{});var wp=n(As);h(Bt.$$.fragment,wp),wp.forEach(r),xp.forEach(r),wd=c(Mn),Ls=o(Mn,"SPAN",{});var Ep=n(Ls);Ed=i(Ep,"Pseudo numerical methods for diffusion models (PNDM)"),Ep.forEach(r),Mn.forEach(r),Fo=c(t),Ue=o(t,"P",{});var On=n(Ue);Pd=i(On,"Original implementation can be found "),Gt=o(On,"A",{href:!0,rel:!0});var Pp=n(Gt);Td=i(Pp,"here"),Pp.forEach(r),Md=i(On,"."),On.forEach(r),Co=c(t),$=o(t,"DIV",{class:!0});var V=n($);h(Wt.$$.fragment,V),Od=c(V),Is=o(V,"P",{});var Tp=n(Is);kd=i(Tp,`Pseudo numerical methods for diffusion models (PNDM) proposes using more advanced ODE integration techniques,
namely Runge-Kutta method and a linear multi-step method.`),Tp.forEach(r),Vd=c(V),Dr=o(V,"P",{});var Gl=n(Dr);Nd=i(Gl,"For more details, see the original paper: "),zt=o(Gl,"A",{href:!0,rel:!0});var Mp=n(zt);Ad=i(Mp,"https://arxiv.org/abs/2202.09778"),Mp.forEach(r),Gl.forEach(r),Ld=c(V),qe=o(V,"DIV",{class:!0});var kn=n(qe);h(Yt.$$.fragment,kn),Id=c(kn),Fs=o(kn,"P",{});var Op=n(Fs);Fd=i(Op,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Op.forEach(r),kn.forEach(r),Cd=c(V),U=o(V,"DIV",{class:!0});var Or=n(U);h(Jt.$$.fragment,Or),Kd=c(Or),Cs=o(Or,"P",{});var kp=n(Cs);Ud=i(kp,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),kp.forEach(r),qd=c(Or),F=o(Or,"P",{});var Xe=n(F);Hd=i(Xe,"This function calls "),Ks=o(Xe,"CODE",{});var Vp=n(Ks);Rd=i(Vp,"step_prk()"),Vp.forEach(r),Bd=i(Xe," or "),Us=o(Xe,"CODE",{});var Np=n(Us);Gd=i(Np,"step_plms()"),Np.forEach(r),Wd=i(Xe," depending on the internal variable "),qs=o(Xe,"CODE",{});var Ap=n(qs);zd=i(Ap,"counter"),Ap.forEach(r),Yd=i(Xe,"."),Xe.forEach(r),Or.forEach(r),Jd=c(V),He=o(V,"DIV",{class:!0});var Vn=n(He);h(jt.$$.fragment,Vn),jd=c(Vn),Hs=o(Vn,"P",{});var Lp=n(Hs);Qd=i(Lp,`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),Lp.forEach(r),Vn.forEach(r),Xd=c(V),Re=o(V,"DIV",{class:!0});var Nn=n(Re);h(Qt.$$.fragment,Nn),Zd=c(Nn),Rs=o(Nn,"P",{});var Ip=n(Rs);el=i(Ip,`Step function propagating the sample with the Runge-Kutta method. RK takes 4 forward passes to approximate the
solution to the differential equation.`),Ip.forEach(r),Nn.forEach(r),V.forEach(r),Ko=c(t),ne=o(t,"H4",{class:!0});var An=n(ne);Be=o(An,"A",{id:!0,class:!0,href:!0});var Fp=n(Be);Bs=o(Fp,"SPAN",{});var Cp=n(Bs);h(Xt.$$.fragment,Cp),Cp.forEach(r),Fp.forEach(r),tl=c(An),Gs=o(An,"SPAN",{});var Kp=n(Gs);rl=i(Kp,"variance exploding stochastic differential equation (SDE) scheduler"),Kp.forEach(r),An.forEach(r),Uo=c(t),Ge=o(t,"P",{});var Ln=n(Ge);sl=i(Ln,"Original paper can be found "),Zt=o(Ln,"A",{href:!0,rel:!0});var Up=n(Zt);ol=i(Up,"here"),Up.forEach(r),nl=i(Ln,"."),Ln.forEach(r),qo=c(t),y=o(t,"DIV",{class:!0});var N=n(y);h(er.$$.fragment,N),al=c(N),Ws=o(N,"P",{});var qp=n(Ws);il=i(qp,"The variance exploding stochastic differential equation (SDE) scheduler."),qp.forEach(r),dl=c(N),xr=o(N,"P",{});var Wl=n(xr);ll=i(Wl,"For more information, see the original paper: "),tr=o(Wl,"A",{href:!0,rel:!0});var Hp=n(tr);cl=i(Hp,"https://arxiv.org/abs/2011.13456"),Hp.forEach(r),Wl.forEach(r),pl=c(N),q=o(N,"DIV",{class:!0});var kr=n(q);h(rr.$$.fragment,kr),ul=c(kr),zs=o(kr,"P",{});var Rp=n(zs);fl=i(Rp,"Sets the noise scales used for the diffusion chain. Supporting function to be run before inference."),Rp.forEach(r),hl=c(kr),ae=o(kr,"P",{});var Vr=n(ae);ml=i(Vr,"The sigmas control the weight of the "),Ys=o(Vr,"CODE",{});var Bp=n(Ys);gl=i(Bp,"drift"),Bp.forEach(r),_l=i(Vr," and "),Js=o(Vr,"CODE",{});var Gp=n(Js);vl=i(Gp,"diffusion"),Gp.forEach(r),bl=i(Vr," components of sample update."),Vr.forEach(r),kr.forEach(r),Sl=c(N),We=o(N,"DIV",{class:!0});var In=n(We);h(sr.$$.fragment,In),$l=c(In),js=o(In,"P",{});var Wp=n(js);yl=i(Wp,"Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),Wp.forEach(r),In.forEach(r),Dl=c(N),ze=o(N,"DIV",{class:!0});var Fn=n(ze);h(or.$$.fragment,Fn),xl=c(Fn),Qs=o(Fn,"P",{});var zp=n(Qs);wl=i(zp,`Correct the predicted sample based on the output model_output of the network. This is often run repeatedly
after making the prediction for the previous timestep.`),zp.forEach(r),Fn.forEach(r),El=c(N),Ye=o(N,"DIV",{class:!0});var Cn=n(Ye);h(nr.$$.fragment,Cn),Pl=c(Cn),Xs=o(Cn,"P",{});var Yp=n(Xs);Tl=i(Yp,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Yp.forEach(r),Cn.forEach(r),N.forEach(r),Ho=c(t),ie=o(t,"H4",{class:!0});var Kn=n(ie);Je=o(Kn,"A",{id:!0,class:!0,href:!0});var Jp=n(Je);Zs=o(Jp,"SPAN",{});var jp=n(Zs);h(ar.$$.fragment,jp),jp.forEach(r),Jp.forEach(r),Ml=c(Kn),eo=o(Kn,"SPAN",{});var Qp=n(eo);Ol=i(Qp,"variance preserving stochastic differential equation (SDE) scheduler"),Qp.forEach(r),Kn.forEach(r),Ro=c(t),je=o(t,"P",{});var Un=n(je);kl=i(Un,"Original paper can be found "),ir=o(Un,"A",{href:!0,rel:!0});var Xp=n(ir);Vl=i(Xp,"here"),Xp.forEach(r),Nl=i(Un,"."),Un.forEach(r),Bo=c(t),h(Qe.$$.fragment,t),Go=c(t),L=o(t,"DIV",{class:!0});var Ze=n(L);h(dr.$$.fragment,Ze),Al=c(Ze),to=o(Ze,"P",{});var Zp=n(to);Ll=i(Zp,"The variance preserving stochastic differential equation (SDE) scheduler."),Zp.forEach(r),Il=c(Ze),wr=o(Ze,"P",{});var zl=n(wr);Fl=i(zl,"For more information, see the original paper: "),lr=o(zl,"A",{href:!0,rel:!0});var eu=n(lr);Cl=i(eu,"https://arxiv.org/abs/2011.13456"),eu.forEach(r),zl.forEach(r),Kl=c(Ze),ro=o(Ze,"P",{});var tu=n(ro);Ul=i(tu,"UNDER CONSTRUCTION"),tu.forEach(r),Ze.forEach(r),this.h()},h(){d(x,"name","hf:doc:metadata"),d(x,"content",JSON.stringify(cu)),d(A,"id","schedulers"),d(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A,"href","#schedulers"),d(E,"class","relative group"),d(le,"id","what-is-a-scheduler"),d(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(le,"href","#what-is-a-scheduler"),d(G,"class","relative group"),d(ue,"id","discrete-versus-continuous-schedulers"),d(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ue,"href","#discrete-versus-continuous-schedulers"),d(z,"class","relative group"),d(fr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DDPMScheduler"),d(hr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.PNDMScheduler"),d(mr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.ScoreSdeVeScheduler"),d(fe,"id","designing-reusable-schedulers"),d(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(fe,"href","#designing-reusable-schedulers"),d(Y,"class","relative group"),d(me,"id","api"),d(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(me,"href","#api"),d(J,"class","relative group"),d(vr,"href","/docs/diffusers/main/en/api/schedulers#diffusers.SchedulerMixin"),d(_e,"id","diffusers.SchedulerMixin"),d(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_e,"href","#diffusers.SchedulerMixin"),d(j,"class","relative group"),d(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(be,"id","diffusers.schedulers.scheduling_utils.SchedulerOutput"),d(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(be,"href","#diffusers.schedulers.scheduling_utils.SchedulerOutput"),d(Q,"class","relative group"),d(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Se,"id","implemented-schedulers"),d(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Se,"href","#implemented-schedulers"),d(Z,"class","relative group"),d($e,"id","diffusers.DDIMScheduler"),d($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($e,"href","#diffusers.DDIMScheduler"),d(ee,"class","relative group"),d(_t,"href","https://arxiv.org/abs/2010.02502"),d(_t,"rel","nofollow"),d(ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(De,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xe,"id","diffusers.DDPMScheduler"),d(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xe,"href","#diffusers.DDPMScheduler"),d(te,"class","relative group"),d($t,"href","https://arxiv.org/abs/2010.02502"),d($t,"rel","nofollow"),d(Dt,"href","https://arxiv.org/abs/2006.11239"),d(Dt,"rel","nofollow"),d(Ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Te,"id","diffusers.KarrasVeScheduler"),d(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Te,"href","#diffusers.KarrasVeScheduler"),d(re,"class","relative group"),d(Pt,"href","https://arxiv.org/abs/2006.11239"),d(Pt,"rel","nofollow"),d(Mt,"href","https://arxiv.org/abs/2206.00364"),d(Mt,"rel","nofollow"),d(Ot,"href","https://arxiv.org/abs/2011.13456"),d(Ot,"rel","nofollow"),d(Vt,"href","https://arxiv.org/abs/2206.00364"),d(Vt,"rel","nofollow"),d(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ae,"id","diffusers.LMSDiscreteScheduler"),d(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ae,"href","#diffusers.LMSDiscreteScheduler"),d(se,"class","relative group"),d(Ct,"href","https://arxiv.org/abs/2206.00364"),d(Ct,"rel","nofollow"),d(Ut,"href","https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),d(Ut,"rel","nofollow"),d(Ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ke,"id","diffusers.PNDMScheduler"),d(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ke,"href","#diffusers.PNDMScheduler"),d(oe,"class","relative group"),d(Gt,"href","https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),d(Gt,"rel","nofollow"),d(zt,"href","https://arxiv.org/abs/2202.09778"),d(zt,"rel","nofollow"),d(qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Be,"id","diffusers.ScoreSdeVeScheduler"),d(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Be,"href","#diffusers.ScoreSdeVeScheduler"),d(ne,"class","relative group"),d(Zt,"href","https://arxiv.org/abs/2011.13456"),d(Zt,"rel","nofollow"),d(tr,"href","https://arxiv.org/abs/2011.13456"),d(tr,"rel","nofollow"),d(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Je,"id","diffusers.schedulers.ScoreSdeVpScheduler"),d(Je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Je,"href","#diffusers.schedulers.ScoreSdeVpScheduler"),d(ie,"class","relative group"),d(ir,"href","https://arxiv.org/abs/2011.13456"),d(ir,"rel","nofollow"),d(lr,"href","https://arxiv.org/abs/2011.13456"),d(lr,"rel","nofollow"),d(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,p){e(document.head,x),u(t,de,p),u(t,E,p),e(E,A),e(A,Nr),m(et,Nr,null),e(E,qn),e(E,Ar),e(Ar,Hn),u(t,no,p),u(t,pr,p),e(pr,Rn),u(t,ao,p),u(t,G,p),e(G,le),e(le,Lr),m(tt,Lr,null),e(G,Bn),e(G,Ir),e(Ir,Gn),u(t,io,p),u(t,ce,p),e(ce,Wn),e(ce,Fr),e(Fr,zn),e(ce,Yn),u(t,lo,p),u(t,pe,p),e(pe,ur),e(ur,Jn),e(ur,rt),e(rt,Cr),e(Cr,jn),e(rt,Qn),e(rt,Kr),e(Kr,Xn),e(pe,Zn),e(pe,W),e(W,ea),e(W,Ur),e(Ur,ta),e(W,ra),e(W,qr),e(qr,sa),e(W,oa),u(t,co,p),u(t,z,p),e(z,ue),e(ue,Hr),m(st,Hr,null),e(z,na),e(z,Rr),e(Rr,aa),u(t,po,p),u(t,D,p),e(D,ia),e(D,Br),e(Br,da),e(D,la),e(D,fr),e(fr,ca),e(D,pa),e(D,hr),e(hr,ua),e(D,fa),e(D,Gr),e(Gr,ha),e(D,ma),e(D,mr),e(mr,ga),e(D,_a),e(D,Wr),e(Wr,va),e(D,ba),u(t,uo,p),u(t,Y,p),e(Y,fe),e(fe,zr),m(ot,zr,null),e(Y,Sa),e(Y,Yr),e(Yr,$a),u(t,fo,p),u(t,gr,p),e(gr,ya),u(t,ho,p),u(t,he,p),e(he,Jr),e(Jr,Da),e(he,xa),e(he,jr),e(jr,wa),u(t,mo,p),u(t,J,p),e(J,me),e(me,Qr),m(nt,Qr,null),e(J,Ea),e(J,Xr),e(Xr,Pa),u(t,go,p),u(t,_r,p),e(_r,Ta),u(t,_o,p),u(t,C,p),e(C,at),e(at,Ma),e(at,Zr),e(Zr,Oa),e(at,ka),e(C,Va),e(C,it),e(it,Na),e(it,es),e(es,Aa),e(it,La),e(C,Ia),e(C,dt),e(dt,Fa),e(dt,ts),e(ts,Ca),e(dt,Ka),u(t,vo,p),u(t,ge,p),e(ge,Ua),e(ge,vr),e(vr,qa),e(ge,Ha),u(t,bo,p),u(t,j,p),e(j,_e),e(_e,rs),m(lt,rs,null),e(j,Ra),e(j,ss),e(ss,Ba),u(t,So,p),u(t,I,p),m(ct,I,null),e(I,Ga),e(I,os),e(os,Wa),e(I,za),e(I,ve),m(pt,ve,null),e(ve,Ya),e(ve,ns),e(ns,Ja),u(t,$o,p),u(t,Q,p),e(Q,be),e(be,as),m(ut,as,null),e(Q,ja),e(Q,is),e(is,Qa),u(t,yo,p),u(t,X,p),m(ft,X,null),e(X,Xa),e(X,ds),e(ds,Za),u(t,Do,p),u(t,Z,p),e(Z,Se),e(Se,ls),m(ht,ls,null),e(Z,ei),e(Z,cs),e(cs,ti),u(t,xo,p),u(t,ee,p),e(ee,$e),e($e,ps),m(mt,ps,null),e(ee,ri),e(ee,us),e(us,si),u(t,wo,p),u(t,br,p),e(br,oi),u(t,Eo,p),u(t,P,p),m(gt,P,null),e(P,ni),e(P,fs),e(fs,ai),e(P,ii),e(P,Sr),e(Sr,di),e(Sr,_t),e(_t,li),e(P,ci),e(P,ye),m(vt,ye,null),e(ye,pi),e(ye,hs),e(hs,ui),e(P,fi),e(P,De),m(bt,De,null),e(De,hi),e(De,ms),e(ms,mi),u(t,Po,p),u(t,te,p),e(te,xe),e(xe,gs),m(St,gs,null),e(te,gi),e(te,_s),e(_s,_i),u(t,To,p),u(t,we,p),e(we,vi),e(we,$t),e($t,bi),e(we,Si),u(t,Mo,p),u(t,T,p),m(yt,T,null),e(T,$i),e(T,vs),e(vs,yi),e(T,Di),e(T,$r),e($r,xi),e($r,Dt),e(Dt,wi),e(T,Ei),e(T,Ee),m(xt,Ee,null),e(Ee,Pi),e(Ee,bs),e(bs,Ti),e(T,Mi),e(T,Pe),m(wt,Pe,null),e(Pe,Oi),e(Pe,Ss),e(Ss,ki),u(t,Oo,p),u(t,re,p),e(re,Te),e(Te,$s),m(Et,$s,null),e(re,Vi),e(re,ys),e(ys,Ni),u(t,ko,p),u(t,Me,p),e(Me,Ai),e(Me,Pt),e(Pt,Li),e(Me,Ii),u(t,Vo,p),u(t,S,p),m(Tt,S,null),e(S,Fi),e(S,Ds),e(Ds,Ci),e(S,Ki),e(S,Oe),e(Oe,Ui),e(Oe,Mt),e(Mt,qi),e(Oe,Hi),e(Oe,Ot),e(Ot,Ri),e(S,Bi),e(S,kt),e(kt,Gi),e(kt,Vt),e(Vt,Wi),e(kt,zi),e(S,Yi),e(S,K),m(Nt,K,null),e(K,Ji),e(K,xs),e(xs,ji),e(K,Qi),e(K,ws),e(ws,Xi),e(S,Zi),e(S,ke),m(At,ke,null),e(ke,ed),e(ke,Es),e(Es,td),e(S,rd),e(S,Ve),m(Lt,Ve,null),e(Ve,sd),e(Ve,Ps),e(Ps,od),e(S,nd),e(S,Ne),m(It,Ne,null),e(Ne,ad),e(Ne,Ts),e(Ts,id),u(t,No,p),u(t,se,p),e(se,Ae),e(Ae,Ms),m(Ft,Ms,null),e(se,dd),e(se,Os),e(Os,ld),u(t,Ao,p),u(t,Le,p),e(Le,cd),e(Le,Ct),e(Ct,pd),e(Le,ud),u(t,Lo,p),u(t,M,p),m(Kt,M,null),e(M,fd),e(M,yr),e(yr,hd),e(yr,Ut),e(Ut,md),e(M,gd),e(M,Ie),m(qt,Ie,null),e(Ie,_d),e(Ie,ks),e(ks,vd),e(M,bd),e(M,Fe),m(Ht,Fe,null),e(Fe,Sd),e(Fe,Vs),e(Vs,$d),e(M,yd),e(M,Ce),m(Rt,Ce,null),e(Ce,Dd),e(Ce,Ns),e(Ns,xd),u(t,Io,p),u(t,oe,p),e(oe,Ke),e(Ke,As),m(Bt,As,null),e(oe,wd),e(oe,Ls),e(Ls,Ed),u(t,Fo,p),u(t,Ue,p),e(Ue,Pd),e(Ue,Gt),e(Gt,Td),e(Ue,Md),u(t,Co,p),u(t,$,p),m(Wt,$,null),e($,Od),e($,Is),e(Is,kd),e($,Vd),e($,Dr),e(Dr,Nd),e(Dr,zt),e(zt,Ad),e($,Ld),e($,qe),m(Yt,qe,null),e(qe,Id),e(qe,Fs),e(Fs,Fd),e($,Cd),e($,U),m(Jt,U,null),e(U,Kd),e(U,Cs),e(Cs,Ud),e(U,qd),e(U,F),e(F,Hd),e(F,Ks),e(Ks,Rd),e(F,Bd),e(F,Us),e(Us,Gd),e(F,Wd),e(F,qs),e(qs,zd),e(F,Yd),e($,Jd),e($,He),m(jt,He,null),e(He,jd),e(He,Hs),e(Hs,Qd),e($,Xd),e($,Re),m(Qt,Re,null),e(Re,Zd),e(Re,Rs),e(Rs,el),u(t,Ko,p),u(t,ne,p),e(ne,Be),e(Be,Bs),m(Xt,Bs,null),e(ne,tl),e(ne,Gs),e(Gs,rl),u(t,Uo,p),u(t,Ge,p),e(Ge,sl),e(Ge,Zt),e(Zt,ol),e(Ge,nl),u(t,qo,p),u(t,y,p),m(er,y,null),e(y,al),e(y,Ws),e(Ws,il),e(y,dl),e(y,xr),e(xr,ll),e(xr,tr),e(tr,cl),e(y,pl),e(y,q),m(rr,q,null),e(q,ul),e(q,zs),e(zs,fl),e(q,hl),e(q,ae),e(ae,ml),e(ae,Ys),e(Ys,gl),e(ae,_l),e(ae,Js),e(Js,vl),e(ae,bl),e(y,Sl),e(y,We),m(sr,We,null),e(We,$l),e(We,js),e(js,yl),e(y,Dl),e(y,ze),m(or,ze,null),e(ze,xl),e(ze,Qs),e(Qs,wl),e(y,El),e(y,Ye),m(nr,Ye,null),e(Ye,Pl),e(Ye,Xs),e(Xs,Tl),u(t,Ho,p),u(t,ie,p),e(ie,Je),e(Je,Zs),m(ar,Zs,null),e(ie,Ml),e(ie,eo),e(eo,Ol),u(t,Ro,p),u(t,je,p),e(je,kl),e(je,ir),e(ir,Vl),e(je,Nl),u(t,Bo,p),m(Qe,t,p),u(t,Go,p),u(t,L,p),m(dr,L,null),e(L,Al),e(L,to),e(to,Ll),e(L,Il),e(L,wr),e(wr,Fl),e(wr,lr),e(lr,Cl),e(L,Kl),e(L,ro),e(ro,Ul),Wo=!0},p(t,[p]){const cr={};p&2&&(cr.$$scope={dirty:p,ctx:t}),Qe.$set(cr)},i(t){Wo||(g(et.$$.fragment,t),g(tt.$$.fragment,t),g(st.$$.fragment,t),g(ot.$$.fragment,t),g(nt.$$.fragment,t),g(lt.$$.fragment,t),g(ct.$$.fragment,t),g(pt.$$.fragment,t),g(ut.$$.fragment,t),g(ft.$$.fragment,t),g(ht.$$.fragment,t),g(mt.$$.fragment,t),g(gt.$$.fragment,t),g(vt.$$.fragment,t),g(bt.$$.fragment,t),g(St.$$.fragment,t),g(yt.$$.fragment,t),g(xt.$$.fragment,t),g(wt.$$.fragment,t),g(Et.$$.fragment,t),g(Tt.$$.fragment,t),g(Nt.$$.fragment,t),g(At.$$.fragment,t),g(Lt.$$.fragment,t),g(It.$$.fragment,t),g(Ft.$$.fragment,t),g(Kt.$$.fragment,t),g(qt.$$.fragment,t),g(Ht.$$.fragment,t),g(Rt.$$.fragment,t),g(Bt.$$.fragment,t),g(Wt.$$.fragment,t),g(Yt.$$.fragment,t),g(Jt.$$.fragment,t),g(jt.$$.fragment,t),g(Qt.$$.fragment,t),g(Xt.$$.fragment,t),g(er.$$.fragment,t),g(rr.$$.fragment,t),g(sr.$$.fragment,t),g(or.$$.fragment,t),g(nr.$$.fragment,t),g(ar.$$.fragment,t),g(Qe.$$.fragment,t),g(dr.$$.fragment,t),Wo=!0)},o(t){_(et.$$.fragment,t),_(tt.$$.fragment,t),_(st.$$.fragment,t),_(ot.$$.fragment,t),_(nt.$$.fragment,t),_(lt.$$.fragment,t),_(ct.$$.fragment,t),_(pt.$$.fragment,t),_(ut.$$.fragment,t),_(ft.$$.fragment,t),_(ht.$$.fragment,t),_(mt.$$.fragment,t),_(gt.$$.fragment,t),_(vt.$$.fragment,t),_(bt.$$.fragment,t),_(St.$$.fragment,t),_(yt.$$.fragment,t),_(xt.$$.fragment,t),_(wt.$$.fragment,t),_(Et.$$.fragment,t),_(Tt.$$.fragment,t),_(Nt.$$.fragment,t),_(At.$$.fragment,t),_(Lt.$$.fragment,t),_(It.$$.fragment,t),_(Ft.$$.fragment,t),_(Kt.$$.fragment,t),_(qt.$$.fragment,t),_(Ht.$$.fragment,t),_(Rt.$$.fragment,t),_(Bt.$$.fragment,t),_(Wt.$$.fragment,t),_(Yt.$$.fragment,t),_(Jt.$$.fragment,t),_(jt.$$.fragment,t),_(Qt.$$.fragment,t),_(Xt.$$.fragment,t),_(er.$$.fragment,t),_(rr.$$.fragment,t),_(sr.$$.fragment,t),_(or.$$.fragment,t),_(nr.$$.fragment,t),_(ar.$$.fragment,t),_(Qe.$$.fragment,t),_(dr.$$.fragment,t),Wo=!1},d(t){r(x),t&&r(de),t&&r(E),v(et),t&&r(no),t&&r(pr),t&&r(ao),t&&r(G),v(tt),t&&r(io),t&&r(ce),t&&r(lo),t&&r(pe),t&&r(co),t&&r(z),v(st),t&&r(po),t&&r(D),t&&r(uo),t&&r(Y),v(ot),t&&r(fo),t&&r(gr),t&&r(ho),t&&r(he),t&&r(mo),t&&r(J),v(nt),t&&r(go),t&&r(_r),t&&r(_o),t&&r(C),t&&r(vo),t&&r(ge),t&&r(bo),t&&r(j),v(lt),t&&r(So),t&&r(I),v(ct),v(pt),t&&r($o),t&&r(Q),v(ut),t&&r(yo),t&&r(X),v(ft),t&&r(Do),t&&r(Z),v(ht),t&&r(xo),t&&r(ee),v(mt),t&&r(wo),t&&r(br),t&&r(Eo),t&&r(P),v(gt),v(vt),v(bt),t&&r(Po),t&&r(te),v(St),t&&r(To),t&&r(we),t&&r(Mo),t&&r(T),v(yt),v(xt),v(wt),t&&r(Oo),t&&r(re),v(Et),t&&r(ko),t&&r(Me),t&&r(Vo),t&&r(S),v(Tt),v(Nt),v(At),v(Lt),v(It),t&&r(No),t&&r(se),v(Ft),t&&r(Ao),t&&r(Le),t&&r(Lo),t&&r(M),v(Kt),v(qt),v(Ht),v(Rt),t&&r(Io),t&&r(oe),v(Bt),t&&r(Fo),t&&r(Ue),t&&r(Co),t&&r($),v(Wt),v(Yt),v(Jt),v(jt),v(Qt),t&&r(Ko),t&&r(ne),v(Xt),t&&r(Uo),t&&r(Ge),t&&r(qo),t&&r(y),v(er),v(rr),v(sr),v(or),v(nr),t&&r(Ho),t&&r(ie),v(ar),t&&r(Ro),t&&r(je),t&&r(Bo),v(Qe,t),t&&r(Go),t&&r(L),v(dr)}}}const cu={local:"schedulers",sections:[{local:"what-is-a-scheduler",sections:[{local:"discrete-versus-continuous-schedulers",title:"Discrete versus continuous schedulers"}],title:"What is a scheduler?"},{local:"designing-reusable-schedulers",title:"Designing Re-usable schedulers"},{local:"api",sections:[{local:"diffusers.SchedulerMixin",title:"SchedulerMixin"},{local:"diffusers.schedulers.scheduling_utils.SchedulerOutput",title:"SchedulerOutput"},{local:"implemented-schedulers",sections:[{local:"diffusers.DDIMScheduler",title:"Denoising diffusion implicit models (DDIM)"},{local:"diffusers.DDPMScheduler",title:"Denoising diffusion probabilistic models (DDPM)"},{local:"diffusers.KarrasVeScheduler",title:"Varience exploding, stochastic sampling from Karras et. al"},{local:"diffusers.LMSDiscreteScheduler",title:"Linear multistep scheduler for discrete beta schedules"},{local:"diffusers.PNDMScheduler",title:"Pseudo numerical methods for diffusion models (PNDM)"},{local:"diffusers.ScoreSdeVeScheduler",title:"variance exploding stochastic differential equation (SDE) scheduler"},{local:"diffusers.schedulers.ScoreSdeVpScheduler",title:"variance preserving stochastic differential equation (SDE) scheduler"}],title:"Implemented Schedulers"}],title:"API"}],title:"Schedulers"};function pu(oo){return au(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class gu extends ru{constructor(x){super();su(this,x,pu,lu,ou,{})}}export{gu as default,cu as metadata};
