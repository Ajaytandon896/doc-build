import{S as Yr,i as Zr,s as es,e as n,k as l,w as p,t as s,M as ts,c as o,d as a,m as c,a as r,x as f,h as i,b as m,G as e,g as u,y as v,L as as,q as h,o as g,B as _,v as ns}from"../../chunks/vendor-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as wa}from"../../chunks/IconCopyLink-hf-doc-builder.js";function os(zo){let U,Kt,V,Q,Be,de,Ma,Je,ka,zt,q,j,Ke,me,Na,ze,Ia,Ht,x,Ca,He,Oa,Da,Qe,Pa,Aa,je,Ta,La,We,Sa,Fa,Qt,y,ue,Ua,P,Va,Ge,qa,Ra,Xe,Ba,Ja,Ye,Ka,za,Ha,Le,Ze,Qa,ja,Wa,et,Ga,Xa,W,pe,Ya,fe,Za,tt,en,tn,an,G,ve,nn,R,on,at,rn,sn,nt,ln,cn,jt,M,he,dn,ot,mn,un,Se,rt,pn,fn,vn,st,hn,Wt,k,ge,gn,it,_n,bn,Fe,lt,yn,En,$n,ct,xn,Gt,N,_e,wn,dt,Mn,kn,Ue,mt,Nn,In,Cn,ut,On,Xt,B,X,pt,be,Dn,ft,Pn,Yt,w,An,vt,Tn,Ln,ht,Sn,Fn,gt,Un,Vn,_t,qn,Rn,Zt,E,ye,Bn,bt,Jn,Kn,Y,Ee,zn,yt,Hn,Qn,Z,$e,jn,Et,Wn,Gn,A,xe,Xn,$t,Yn,Zn,xt,eo,to,ee,we,ao,wt,no,ea,J,Me,oo,Mt,ro,ta,K,ke,so,kt,io,aa,z,Ne,lo,Nt,co,na,H,te,It,Ie,mo,Ct,uo,oa,C,po,Ot,fo,vo,Dt,ho,go,Pt,_o,bo,ra,$,Ce,yo,Oe,Eo,At,$o,xo,wo,Tt,Mo,ko,Lt,No,Io,St,Ft,Ut,Vt,Co,sa,I,De,Oo,ae,Pe,Do,qt,Po,Ao,ne,Ae,To,Rt,Lo,So,T,Te,Fo,Bt,Uo,Vo,Jt,qo,ia;return de=new wa({}),me=new wa({}),ue=new b({props:{name:"class evaluate.EvaluationModuleInfo",anchor:"evaluate.EvaluationModuleInfo",parameters:[{name:"description",val:": str"},{name:"citation",val:": str"},{name:"features",val:": typing.Union[datasets.features.features.Features, typing.List[datasets.features.features.Features]]"},{name:"inputs_description",val:": str = <factory>"},{name:"homepage",val:": str = <factory>"},{name:"license",val:": str = <factory>"},{name:"codebase_urls",val:": typing.List[str] = <factory>"},{name:"reference_urls",val:": typing.List[str] = <factory>"},{name:"streamable",val:": bool = False"},{name:"format",val:": typing.Optional[str] = None"},{name:"module_type",val:": str = 'metric'"},{name:"module_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/info.py#L35"}}),pe=new b({props:{name:"from_directory",anchor:"evaluate.EvaluationModuleInfo.from_directory",parameters:[{name:"metric_info_dir",val:""}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/info.py#L82"}}),ve=new b({props:{name:"write_to_directory",anchor:"evaluate.EvaluationModuleInfo.write_to_directory",parameters:[{name:"metric_info_dir",val:""}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/info.py#L72"}}),he=new b({props:{name:"class evaluate.MetricInfo",anchor:"evaluate.MetricInfo",parameters:[{name:"description",val:": str"},{name:"citation",val:": str"},{name:"features",val:": typing.Union[datasets.features.features.Features, typing.List[datasets.features.features.Features]]"},{name:"inputs_description",val:": str = <factory>"},{name:"homepage",val:": str = <factory>"},{name:"license",val:": str = <factory>"},{name:"codebase_urls",val:": typing.List[str] = <factory>"},{name:"reference_urls",val:": typing.List[str] = <factory>"},{name:"streamable",val:": bool = False"},{name:"format",val:": typing.Optional[str] = None"},{name:"module_type",val:": str = 'metric'"},{name:"module_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/info.py#L105"}}),ge=new b({props:{name:"class evaluate.ComparisonInfo",anchor:"evaluate.ComparisonInfo",parameters:[{name:"description",val:": str"},{name:"citation",val:": str"},{name:"features",val:": typing.Union[datasets.features.features.Features, typing.List[datasets.features.features.Features]]"},{name:"inputs_description",val:": str = <factory>"},{name:"homepage",val:": str = <factory>"},{name:"license",val:": str = <factory>"},{name:"codebase_urls",val:": typing.List[str] = <factory>"},{name:"reference_urls",val:": typing.List[str] = <factory>"},{name:"streamable",val:": bool = False"},{name:"format",val:": typing.Optional[str] = None"},{name:"module_type",val:": str = 'comparison'"},{name:"module_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/info.py#L118"}}),_e=new b({props:{name:"class evaluate.MeasurementInfo",anchor:"evaluate.MeasurementInfo",parameters:[{name:"description",val:": str"},{name:"citation",val:": str"},{name:"features",val:": typing.Union[datasets.features.features.Features, typing.List[datasets.features.features.Features]]"},{name:"inputs_description",val:": str = <factory>"},{name:"homepage",val:": str = <factory>"},{name:"license",val:": str = <factory>"},{name:"codebase_urls",val:": typing.List[str] = <factory>"},{name:"reference_urls",val:": typing.List[str] = <factory>"},{name:"streamable",val:": bool = False"},{name:"format",val:": typing.Optional[str] = None"},{name:"module_type",val:": str = 'measurement'"},{name:"module_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/info.py#L131"}}),be=new wa({}),ye=new b({props:{name:"class evaluate.EvaluationModule",anchor:"evaluate.EvaluationModule",parameters:[{name:"config_name",val:": typing.Optional[str] = None"},{name:"keep_in_memory",val:": bool = False"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"num_process",val:": int = 1"},{name:"process_id",val:": int = 0"},{name:"seed",val:": typing.Optional[int] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"},{name:"hash",val:": str = None"},{name:"max_concurrent_cache_files",val:": int = 10000"},{name:"timeout",val:": typing.Union[int, float] = 100"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.EvaluationModule.config_name",description:`<strong>config_name</strong> (<code>str</code>) &#x2014; This is used to define a hash specific to a module computation script and prevents the module&#x2019;s data
to be overridden when the module loading script is modified.`,name:"config_name"},{anchor:"evaluate.EvaluationModule.keep_in_memory",description:"<strong>keep_in_memory</strong> (<code>bool</code>) &#x2014; keep all predictions and references in memory. Not possible in distributed settings.",name:"keep_in_memory"},{anchor:"evaluate.EvaluationModule.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>) &#x2014; Path to a directory in which temporary prediction/references data will be stored.
The data directory should be located on a shared file-system in distributed setups.`,name:"cache_dir"},{anchor:"evaluate.EvaluationModule.num_process",description:`<strong>num_process</strong> (<code>int</code>) &#x2014; specify the total number of nodes in a distributed settings.
This is useful to compute module in distributed setups (in particular non-additive modules like F1).`,name:"num_process"},{anchor:"evaluate.EvaluationModule.process_id",description:`<strong>process_id</strong> (<code>int</code>) &#x2014; specify the id of the current process in a distributed setup (between 0 and num_process-1)
This is useful to compute module in distributed setups (in particular non-additive metrics like F1).`,name:"process_id"},{anchor:"evaluate.EvaluationModule.seed",description:'<strong>seed</strong> (<code>int</code>, optional) &#x2014; If specified, this will temporarily set numpy&#x2019;s random seed when <a href="/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute">evaluate.EvaluationModule.compute()</a> is run.',name:"seed"},{anchor:"evaluate.EvaluationModule.experiment_id",description:`<strong>experiment_id</strong> (<code>str</code>) &#x2014; A specific experiment id. This is used if several distributed evaluations share the same file system.
This is useful to compute module in distributed setups (in particular non-additive metrics like F1).`,name:"experiment_id"},{anchor:"evaluate.EvaluationModule.hash",description:"<strong>hash</strong> (<code>str</code>) &#x2014; Used to identify the evaluation module according to the hashed file contents.",name:"hash"},{anchor:"evaluate.EvaluationModule.max_concurrent_cache_files",description:"<strong>max_concurrent_cache_files</strong> (<code>int</code>) &#x2014; Max number of concurrent module cache files (default 10000).",name:"max_concurrent_cache_files"},{anchor:"evaluate.EvaluationModule.timeout",description:"<strong>timeout</strong> (<code>Union[int, float]</code>) &#x2014; Timeout in second for distributed setting synchronization.",name:"timeout"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L145"}}),Ee=new b({props:{name:"add",anchor:"evaluate.EvaluationModule.add",parameters:[{name:"prediction",val:" = None"},{name:"reference",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.EvaluationModule.add.prediction",description:"<strong>prediction</strong> (list/array/tensor, optional) &#x2014; Predictions.",name:"prediction"},{anchor:"evaluate.EvaluationModule.add.reference",description:"<strong>reference</strong> (list/array/tensor, optional) &#x2014; References.",name:"reference"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L514"}}),$e=new b({props:{name:"add_batch",anchor:"evaluate.EvaluationModule.add_batch",parameters:[{name:"predictions",val:" = None"},{name:"references",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.EvaluationModule.add_batch.predictions",description:"<strong>predictions</strong> (list/array/tensor, optional) &#x2014; Predictions.",name:"predictions"},{anchor:"evaluate.EvaluationModule.add_batch.references",description:"<strong>references</strong> (list/array/tensor, optional) &#x2014; References.",name:"references"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L465"}}),xe=new b({props:{name:"compute",anchor:"evaluate.EvaluationModule.compute",parameters:[{name:"predictions",val:" = None"},{name:"references",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.EvaluationModule.compute.predictions",description:"<strong>predictions</strong> (list/array/tensor, optional) &#x2014; Predictions.",name:"predictions"},{anchor:"evaluate.EvaluationModule.compute.references",description:"<strong>references</strong> (list/array/tensor, optional) &#x2014; References.",name:"references"},{anchor:"evaluate.EvaluationModule.compute.*kwargs",description:`*<strong>*kwargs</strong> (optional) &#x2014; Keyword arguments that will be forwarded to the evaluation module <code>_compute</code>
method (see details in the docstring).`,name:"*kwargs"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L401",returnDescription:`
<p>dict or None</p>
<ul>
<li>Dictionary with the results if this evaluation module is run on the main process (<code>process_id == 0</code>).</li>
<li>None if the evaluation module is not run on the main process (<code>process_id != 0</code>).</li>
</ul>
`}}),we=new b({props:{name:"download_and_prepare",anchor:"evaluate.EvaluationModule.download_and_prepare",parameters:[{name:"download_config",val:": typing.Optional[evaluate.utils.file_utils.DownloadConfig] = None"},{name:"dl_manager",val:": typing.Optional[datasets.download.download_manager.DownloadManager] = None"}],parametersDescription:[{anchor:"evaluate.EvaluationModule.download_and_prepare.download_config",description:"<strong>download_config</strong> (<code>DownloadConfig</code>, optional) &#x2014; Specific download configuration parameters.",name:"download_config"},{anchor:"evaluate.EvaluationModule.download_and_prepare.dl_manager",description:"<strong>dl_manager</strong> (<code>DownloadManager</code>, optional) &#x2014; Specific download manager to use.",name:"dl_manager"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L633"}}),Me=new b({props:{name:"class evaluate.Metric",anchor:"evaluate.Metric",parameters:[{name:"config_name",val:": typing.Optional[str] = None"},{name:"keep_in_memory",val:": bool = False"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"num_process",val:": int = 1"},{name:"process_id",val:": int = 0"},{name:"seed",val:": typing.Optional[int] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"},{name:"hash",val:": str = None"},{name:"max_concurrent_cache_files",val:": int = 10000"},{name:"timeout",val:": typing.Union[int, float] = 100"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.Metric.config_name",description:`<strong>config_name</strong> (<code>str</code>) &#x2014; This is used to define a hash specific to a metric computation script and prevents the metric&#x2019;s data
to be overridden when the metric loading script is modified.`,name:"config_name"},{anchor:"evaluate.Metric.keep_in_memory",description:"<strong>keep_in_memory</strong> (<code>bool</code>) &#x2014; keep all predictions and references in memory. Not possible in distributed settings.",name:"keep_in_memory"},{anchor:"evaluate.Metric.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>) &#x2014; Path to a directory in which temporary prediction/references data will be stored.
The data directory should be located on a shared file-system in distributed setups.`,name:"cache_dir"},{anchor:"evaluate.Metric.num_process",description:`<strong>num_process</strong> (<code>int</code>) &#x2014; specify the total number of nodes in a distributed settings.
This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).`,name:"num_process"},{anchor:"evaluate.Metric.process_id",description:`<strong>process_id</strong> (<code>int</code>) &#x2014; specify the id of the current process in a distributed setup (between 0 and num_process-1)
This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).`,name:"process_id"},{anchor:"evaluate.Metric.seed",description:'<strong>seed</strong> (<code>int</code>, optional) &#x2014; If specified, this will temporarily set numpy&#x2019;s random seed when <a href="/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute">evaluate.Metric.compute()</a> is run.',name:"seed"},{anchor:"evaluate.Metric.experiment_id",description:`<strong>experiment_id</strong> (<code>str</code>) &#x2014; A specific experiment id. This is used if several distributed evaluations share the same file system.
This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).`,name:"experiment_id"},{anchor:"evaluate.Metric.max_concurrent_cache_files",description:"<strong>max_concurrent_cache_files</strong> (<code>int</code>) &#x2014; Max number of concurrent metric cache files (default 10000).",name:"max_concurrent_cache_files"},{anchor:"evaluate.Metric.timeout",description:"<strong>timeout</strong> (<code>Union[int, float]</code>) &#x2014; Timeout in second for distributed setting synchronization.",name:"timeout"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L730"}}),ke=new b({props:{name:"class evaluate.Comparison",anchor:"evaluate.Comparison",parameters:[{name:"config_name",val:": typing.Optional[str] = None"},{name:"keep_in_memory",val:": bool = False"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"num_process",val:": int = 1"},{name:"process_id",val:": int = 0"},{name:"seed",val:": typing.Optional[int] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"},{name:"hash",val:": str = None"},{name:"max_concurrent_cache_files",val:": int = 10000"},{name:"timeout",val:": typing.Union[int, float] = 100"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.Comparison.config_name",description:`<strong>config_name</strong> (<code>str</code>) &#x2014; This is used to define a hash specific to a comparison computation script and prevents the comparison&#x2019;s data
to be overridden when the  comparison loading script is modified.`,name:"config_name"},{anchor:"evaluate.Comparison.keep_in_memory",description:"<strong>keep_in_memory</strong> (<code>bool</code>) &#x2014; keep all predictions and references in memory. Not possible in distributed settings.",name:"keep_in_memory"},{anchor:"evaluate.Comparison.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>) &#x2014; Path to a directory in which temporary prediction/references data will be stored.
The data directory should be located on a shared file-system in distributed setups.`,name:"cache_dir"},{anchor:"evaluate.Comparison.num_process",description:`<strong>num_process</strong> (<code>int</code>) &#x2014; specify the total number of nodes in a distributed settings.
This is useful to compute  comparisons in distributed setups (in particular non-additive comparisons).`,name:"num_process"},{anchor:"evaluate.Comparison.process_id",description:`<strong>process_id</strong> (<code>int</code>) &#x2014; specify the id of the current process in a distributed setup (between 0 and num_process-1)
This is useful to compute  comparisons in distributed setups (in particular non-additive comparisons).`,name:"process_id"},{anchor:"evaluate.Comparison.seed",description:'<strong>seed</strong> (<code>int</code>, optional) &#x2014; If specified, this will temporarily set numpy&#x2019;s random seed when <a href="/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute">evaluate.Comparison.compute()</a> is run.',name:"seed"},{anchor:"evaluate.Comparison.experiment_id",description:`<strong>experiment_id</strong> (<code>str</code>) &#x2014; A specific experiment id. This is used if several distributed evaluations share the same file system.
This is useful to compute  comparisons in distributed setups (in particular non-additive comparisons).`,name:"experiment_id"},{anchor:"evaluate.Comparison.max_concurrent_cache_files",description:"<strong>max_concurrent_cache_files</strong> (<code>int</code>) &#x2014; Max number of concurrent comparison cache files (default 10000).",name:"max_concurrent_cache_files"},{anchor:"evaluate.Comparison.timeout",description:"<strong>timeout</strong> (<code>Union[int, float]</code>) &#x2014; Timeout in second for distributed setting synchronization.",name:"timeout"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L751"}}),Ne=new b({props:{name:"class evaluate.Measurement",anchor:"evaluate.Measurement",parameters:[{name:"config_name",val:": typing.Optional[str] = None"},{name:"keep_in_memory",val:": bool = False"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"num_process",val:": int = 1"},{name:"process_id",val:": int = 0"},{name:"seed",val:": typing.Optional[int] = None"},{name:"experiment_id",val:": typing.Optional[str] = None"},{name:"hash",val:": str = None"},{name:"max_concurrent_cache_files",val:": int = 10000"},{name:"timeout",val:": typing.Union[int, float] = 100"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.Measurement.config_name",description:`<strong>config_name</strong> (<code>str</code>) &#x2014; This is used to define a hash specific to a measurement computation script and prevents the measurement&#x2019;s data
to be overridden when the measurement loading script is modified.`,name:"config_name"},{anchor:"evaluate.Measurement.keep_in_memory",description:"<strong>keep_in_memory</strong> (<code>bool</code>) &#x2014; keep all predictions and references in memory. Not possible in distributed settings.",name:"keep_in_memory"},{anchor:"evaluate.Measurement.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>) &#x2014; Path to a directory in which temporary prediction/references data will be stored.
The data directory should be located on a shared file-system in distributed setups.`,name:"cache_dir"},{anchor:"evaluate.Measurement.num_process",description:`<strong>num_process</strong> (<code>int</code>) &#x2014; specify the total number of nodes in a distributed settings.
This is useful to compute measurements in distributed setups (in particular non-additive measurements).`,name:"num_process"},{anchor:"evaluate.Measurement.process_id",description:`<strong>process_id</strong> (<code>int</code>) &#x2014; specify the id of the current process in a distributed setup (between 0 and num_process-1)
This is useful to compute measurements in distributed setups (in particular non-additive measurements).`,name:"process_id"},{anchor:"evaluate.Measurement.seed",description:'<strong>seed</strong> (<code>int</code>, optional) &#x2014; If specified, this will temporarily set numpy&#x2019;s random seed when <a href="/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute">evaluate.Measurement.compute()</a> is run.',name:"seed"},{anchor:"evaluate.Measurement.experiment_id",description:`<strong>experiment_id</strong> (<code>str</code>) &#x2014; A specific experiment id. This is used if several distributed evaluations share the same file system.
This is useful to compute measurements in distributed setups (in particular non-additive measurements).`,name:"experiment_id"},{anchor:"evaluate.Measurement.max_concurrent_cache_files",description:"<strong>max_concurrent_cache_files</strong> (<code>int</code>) &#x2014; Max number of concurrent measurement cache files (default 10000).",name:"max_concurrent_cache_files"},{anchor:"evaluate.Measurement.timeout",description:"<strong>timeout</strong> (<code>Union[int, float]</code>) &#x2014; Timeout in second for distributed setting synchronization.",name:"timeout"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L772"}}),Ie=new wa({}),Ce=new b({props:{name:"evaluate.combine",anchor:"evaluate.combine",parameters:[{name:"evaluations",val:""},{name:"force_prefix",val:" = False"}],parametersDescription:[{anchor:"evaluate.combine.evaluations",description:`<strong>evaluations</strong> (<code>Union[list, dict]</code>) &#x2014; A list or dictionary of evaluation modules. The modules can either be passed
as strings or loaded <em>EvaluationModule</em>s. If a dictionary is passed its keys are the names used and the values the modules.
The names are used as prefix in case there are name overlaps in the returned results of each module or if <em>force_prefix=True</em>.`,name:"evaluations"},{anchor:"evaluate.combine.force_prefix",description:`<strong>force_prefix</strong> (<code>bool</code>, optional, defaults to <em>False</em>) &#x2014; If <em>True</em> all scores from the modules are prefixed with their name. If
a dictionary is passed the keys are used as name otherwise the module&#x2019;s name.`,name:"force_prefix"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L891"}}),De=new b({props:{name:"class evaluate.CombinedEvaluations",anchor:"evaluate.CombinedEvaluations",parameters:[{name:"evaluation_modules",val:""},{name:"force_prefix",val:" = False"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L793"}}),Pe=new b({props:{name:"add",anchor:"evaluate.CombinedEvaluations.add",parameters:[{name:"prediction",val:" = None"},{name:"reference",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.CombinedEvaluations.add.prediction",description:"<strong>prediction</strong> (list/array/tensor, optional) &#x2014; Predictions.",name:"prediction"},{anchor:"evaluate.CombinedEvaluations.add.reference",description:"<strong>reference</strong> (list/array/tensor, optional) &#x2014; References.",name:"reference"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L816"}}),Ae=new b({props:{name:"add_batch",anchor:"evaluate.CombinedEvaluations.add_batch",parameters:[{name:"predictions",val:" = None"},{name:"references",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.CombinedEvaluations.add_batch.predictions",description:"<strong>predictions</strong> (list/array/tensor, optional) &#x2014; Predictions.",name:"predictions"},{anchor:"evaluate.CombinedEvaluations.add_batch.references",description:"<strong>references</strong> (list/array/tensor, optional) &#x2014; References.",name:"references"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L828"}}),Te=new b({props:{name:"compute",anchor:"evaluate.CombinedEvaluations.compute",parameters:[{name:"predictions",val:" = None"},{name:"references",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"evaluate.CombinedEvaluations.compute.predictions",description:"<strong>predictions</strong> (list/array/tensor, optional) &#x2014; Predictions.",name:"predictions"},{anchor:"evaluate.CombinedEvaluations.compute.references",description:"<strong>references</strong> (list/array/tensor, optional) &#x2014; References.",name:"references"},{anchor:"evaluate.CombinedEvaluations.compute.*kwargs",description:`*<strong>*kwargs</strong> (optional) &#x2014; Keyword arguments that will be forwarded to the evaluation module <code>_compute</code>
method (see details in the docstring).`,name:"*kwargs"}],source:"https://github.com/huggingface/evaluate/blob/main/src/evaluate/module.py#L840",returnDescription:`
<p>dict or None</p>
<ul>
<li>Dictionary with the results if this evaluation module is run on the main process (<code>process_id == 0</code>).</li>
<li>None if the evaluation module is not run on the main process (<code>process_id != 0</code>).</li>
</ul>
`}}),{c(){U=n("meta"),Kt=l(),V=n("h1"),Q=n("a"),Be=n("span"),p(de.$$.fragment),Ma=l(),Je=n("span"),ka=s("Main classes"),zt=l(),q=n("h2"),j=n("a"),Ke=n("span"),p(me.$$.fragment),Na=l(),ze=n("span"),Ia=s("EvaluationModuleInfo"),Ht=l(),x=n("p"),Ca=s("The base class "),He=n("code"),Oa=s("EvaluationModuleInfo"),Da=s(" implements a the logic for the subclasses "),Qe=n("code"),Pa=s("MetricInfo"),Aa=s(", "),je=n("code"),Ta=s("ComparisonInfo"),La=s(", and "),We=n("code"),Sa=s("MeasurementInfo"),Fa=s("."),Qt=l(),y=n("div"),p(ue.$$.fragment),Ua=l(),P=n("p"),Va=s("Base class to store fnformation about an evaluation used for "),Ge=n("code"),qa=s("MetricInfo"),Ra=s(", "),Xe=n("code"),Ba=s("ComparisonInfo"),Ja=s(`,
and `),Ye=n("code"),Ka=s("MeasurementInfo"),za=s("."),Ha=l(),Le=n("p"),Ze=n("code"),Qa=s("EvaluationModuleInfo"),ja=s(` documents an evaluation, including its name, version, and features.
See the constructor arguments and properties for a full list.`),Wa=l(),et=n("p"),Ga=s("Note: Not all fields are known on construction and may be updated later."),Xa=l(),W=n("div"),p(pe.$$.fragment),Ya=l(),fe=n("p"),Za=s("Create EvaluationModuleInfo from the JSON file in "),tt=n("code"),en=s("metric_info_dir"),tn=s("."),an=l(),G=n("div"),p(ve.$$.fragment),nn=l(),R=n("p"),on=s("Write "),at=n("code"),rn=s("EvaluationModuleInfo"),sn=s(" as JSON to "),nt=n("code"),ln=s("metric_info_dir"),cn=s(`.
Also save the license separately in LICENCE.`),jt=l(),M=n("div"),p(he.$$.fragment),dn=l(),ot=n("p"),mn=s("Information about a metric."),un=l(),Se=n("p"),rt=n("code"),pn=s("EvaluationModuleInfo"),fn=s(` documents a metric, including its name, version, and features.
See the constructor arguments and properties for a full list.`),vn=l(),st=n("p"),hn=s("Note: Not all fields are known on construction and may be updated later."),Wt=l(),k=n("div"),p(ge.$$.fragment),gn=l(),it=n("p"),_n=s("Information about a comparison."),bn=l(),Fe=n("p"),lt=n("code"),yn=s("EvaluationModuleInfo"),En=s(` documents a comparison, including its name, version, and features.
See the constructor arguments and properties for a full list.`),$n=l(),ct=n("p"),xn=s("Note: Not all fields are known on construction and may be updated later."),Gt=l(),N=n("div"),p(_e.$$.fragment),wn=l(),dt=n("p"),Mn=s("Information about a measurement."),kn=l(),Ue=n("p"),mt=n("code"),Nn=s("EvaluationModuleInfo"),In=s(` documents a measurement, including its name, version, and features.
See the constructor arguments and properties for a full list.`),Cn=l(),ut=n("p"),On=s("Note: Not all fields are known on construction and may be updated later."),Xt=l(),B=n("h2"),X=n("a"),pt=n("span"),p(be.$$.fragment),Dn=l(),ft=n("span"),Pn=s("EvaluationModule"),Yt=l(),w=n("p"),An=s("The base class "),vt=n("code"),Tn=s("EvaluationModule"),Ln=s(" implements a the logic for the subclasses "),ht=n("code"),Sn=s("Metric"),Fn=s(", "),gt=n("code"),Un=s("Comparison"),Vn=s(", and "),_t=n("code"),qn=s("Measurement"),Rn=s("."),Zt=l(),E=n("div"),p(ye.$$.fragment),Bn=l(),bt=n("p"),Jn=s("A EvaluationModule is the base class and common API for metrics, comparisons, and measurements."),Kn=l(),Y=n("div"),p(Ee.$$.fragment),zn=l(),yt=n("p"),Hn=s("Add one prediction and reference for the evaluation module\u2019s stack."),Qn=l(),Z=n("div"),p($e.$$.fragment),jn=l(),Et=n("p"),Wn=s("Add a batch of predictions and references for the evaluation module\u2019s stack."),Gn=l(),A=n("div"),p(xe.$$.fragment),Xn=l(),$t=n("p"),Yn=s("Compute the evaluation module."),Zn=l(),xt=n("p"),eo=s("Usage of positional arguments is not allowed to prevent mistakes."),to=l(),ee=n("div"),p(we.$$.fragment),ao=l(),wt=n("p"),no=s("Downloads and prepares dataset for reading."),ea=l(),J=n("div"),p(Me.$$.fragment),oo=l(),Mt=n("p"),ro=s("A Metric is the base class and common API for all metrics."),ta=l(),K=n("div"),p(ke.$$.fragment),so=l(),kt=n("p"),io=s("A Comparison is the base class and common API for all comparisons."),aa=l(),z=n("div"),p(Ne.$$.fragment),lo=l(),Nt=n("p"),co=s("A Measurement is the base class and common API for all measurements."),na=l(),H=n("h2"),te=n("a"),It=n("span"),p(Ie.$$.fragment),mo=l(),Ct=n("span"),uo=s("CombinedEvaluations"),oa=l(),C=n("p"),po=s("The "),Ot=n("code"),fo=s("combine"),vo=s(" function allows to combine multiple "),Dt=n("code"),ho=s("EvaluationModule"),go=s("s into a single "),Pt=n("code"),_o=s("CombinedEvaluations"),bo=s("."),ra=l(),$=n("div"),p(Ce.$$.fragment),yo=l(),Oe=n("p"),Eo=s("Combines several metrics, comparisons, or measurements into a single "),At=n("em"),$o=s("CombinedEvaluations"),xo=s(` object that
can be used like a single evaluation module.`),wo=l(),Tt=n("p"),Mo=s(`If two scores have the same name, then they are prefixed with their module names.
And if two modules have the same name, please use a dictionary to give them different names, otherwise an integer id is appended to the prefix.`),ko=l(),Lt=n("p"),No=s("Examples:"),Io=l(),St=n("blockquote"),Ft=n("blockquote"),Ut=n("blockquote"),Vt=n("p"),Co=s(`clf_metrics = combine([\u201Caccuracy\u201D, \u201Cf1\u201D, \u201Cprecision\u201D,\u201Crecall\u201D])
clf_metrics.compute(predictions=[0,1], references=[1,1])
{\u2018accuracy\u2019: 0.5, \u2018f1\u2019: 0.66, \u2018precision\u2019: 1.0, \u2018recall\u2019: 0.5}`),sa=l(),I=n("div"),p(De.$$.fragment),Oo=l(),ae=n("div"),p(Pe.$$.fragment),Do=l(),qt=n("p"),Po=s("Add one prediction and reference for each evaluation module\u2019s stack."),Ao=l(),ne=n("div"),p(Ae.$$.fragment),To=l(),Rt=n("p"),Lo=s("Add a batch of predictions and references for each evaluation module\u2019s stack."),So=l(),T=n("div"),p(Te.$$.fragment),Fo=l(),Bt=n("p"),Uo=s("Compute each evaluation module."),Vo=l(),Jt=n("p"),qo=s("Usage of positional arguments is not allowed to prevent mistakes."),this.h()},l(t){const d=ts('[data-svelte="svelte-1phssyn"]',document.head);U=o(d,"META",{name:!0,content:!0}),d.forEach(a),Kt=c(t),V=o(t,"H1",{class:!0});var la=r(V);Q=o(la,"A",{id:!0,class:!0,href:!0});var Ho=r(Q);Be=o(Ho,"SPAN",{});var Qo=r(Be);f(de.$$.fragment,Qo),Qo.forEach(a),Ho.forEach(a),Ma=c(la),Je=o(la,"SPAN",{});var jo=r(Je);ka=i(jo,"Main classes"),jo.forEach(a),la.forEach(a),zt=c(t),q=o(t,"H2",{class:!0});var ca=r(q);j=o(ca,"A",{id:!0,class:!0,href:!0});var Wo=r(j);Ke=o(Wo,"SPAN",{});var Go=r(Ke);f(me.$$.fragment,Go),Go.forEach(a),Wo.forEach(a),Na=c(ca),ze=o(ca,"SPAN",{});var Xo=r(ze);Ia=i(Xo,"EvaluationModuleInfo"),Xo.forEach(a),ca.forEach(a),Ht=c(t),x=o(t,"P",{});var L=r(x);Ca=i(L,"The base class "),He=o(L,"CODE",{});var Yo=r(He);Oa=i(Yo,"EvaluationModuleInfo"),Yo.forEach(a),Da=i(L," implements a the logic for the subclasses "),Qe=o(L,"CODE",{});var Zo=r(Qe);Pa=i(Zo,"MetricInfo"),Zo.forEach(a),Aa=i(L,", "),je=o(L,"CODE",{});var er=r(je);Ta=i(er,"ComparisonInfo"),er.forEach(a),La=i(L,", and "),We=o(L,"CODE",{});var tr=r(We);Sa=i(tr,"MeasurementInfo"),tr.forEach(a),Fa=i(L,"."),L.forEach(a),Qt=c(t),y=o(t,"DIV",{class:!0});var O=r(y);f(ue.$$.fragment,O),Ua=c(O),P=o(O,"P",{});var oe=r(P);Va=i(oe,"Base class to store fnformation about an evaluation used for "),Ge=o(oe,"CODE",{});var ar=r(Ge);qa=i(ar,"MetricInfo"),ar.forEach(a),Ra=i(oe,", "),Xe=o(oe,"CODE",{});var nr=r(Xe);Ba=i(nr,"ComparisonInfo"),nr.forEach(a),Ja=i(oe,`,
and `),Ye=o(oe,"CODE",{});var or=r(Ye);Ka=i(or,"MeasurementInfo"),or.forEach(a),za=i(oe,"."),oe.forEach(a),Ha=c(O),Le=o(O,"P",{});var Ro=r(Le);Ze=o(Ro,"CODE",{});var rr=r(Ze);Qa=i(rr,"EvaluationModuleInfo"),rr.forEach(a),ja=i(Ro,` documents an evaluation, including its name, version, and features.
See the constructor arguments and properties for a full list.`),Ro.forEach(a),Wa=c(O),et=o(O,"P",{});var sr=r(et);Ga=i(sr,"Note: Not all fields are known on construction and may be updated later."),sr.forEach(a),Xa=c(O),W=o(O,"DIV",{class:!0});var da=r(W);f(pe.$$.fragment,da),Ya=c(da),fe=o(da,"P",{});var ma=r(fe);Za=i(ma,"Create EvaluationModuleInfo from the JSON file in "),tt=o(ma,"CODE",{});var ir=r(tt);en=i(ir,"metric_info_dir"),ir.forEach(a),tn=i(ma,"."),ma.forEach(a),da.forEach(a),an=c(O),G=o(O,"DIV",{class:!0});var ua=r(G);f(ve.$$.fragment,ua),nn=c(ua),R=o(ua,"P",{});var Ve=r(R);on=i(Ve,"Write "),at=o(Ve,"CODE",{});var lr=r(at);rn=i(lr,"EvaluationModuleInfo"),lr.forEach(a),sn=i(Ve," as JSON to "),nt=o(Ve,"CODE",{});var cr=r(nt);ln=i(cr,"metric_info_dir"),cr.forEach(a),cn=i(Ve,`.
Also save the license separately in LICENCE.`),Ve.forEach(a),ua.forEach(a),O.forEach(a),jt=c(t),M=o(t,"DIV",{class:!0});var re=r(M);f(he.$$.fragment,re),dn=c(re),ot=o(re,"P",{});var dr=r(ot);mn=i(dr,"Information about a metric."),dr.forEach(a),un=c(re),Se=o(re,"P",{});var Bo=r(Se);rt=o(Bo,"CODE",{});var mr=r(rt);pn=i(mr,"EvaluationModuleInfo"),mr.forEach(a),fn=i(Bo,` documents a metric, including its name, version, and features.
See the constructor arguments and properties for a full list.`),Bo.forEach(a),vn=c(re),st=o(re,"P",{});var ur=r(st);hn=i(ur,"Note: Not all fields are known on construction and may be updated later."),ur.forEach(a),re.forEach(a),Wt=c(t),k=o(t,"DIV",{class:!0});var se=r(k);f(ge.$$.fragment,se),gn=c(se),it=o(se,"P",{});var pr=r(it);_n=i(pr,"Information about a comparison."),pr.forEach(a),bn=c(se),Fe=o(se,"P",{});var Jo=r(Fe);lt=o(Jo,"CODE",{});var fr=r(lt);yn=i(fr,"EvaluationModuleInfo"),fr.forEach(a),En=i(Jo,` documents a comparison, including its name, version, and features.
See the constructor arguments and properties for a full list.`),Jo.forEach(a),$n=c(se),ct=o(se,"P",{});var vr=r(ct);xn=i(vr,"Note: Not all fields are known on construction and may be updated later."),vr.forEach(a),se.forEach(a),Gt=c(t),N=o(t,"DIV",{class:!0});var ie=r(N);f(_e.$$.fragment,ie),wn=c(ie),dt=o(ie,"P",{});var hr=r(dt);Mn=i(hr,"Information about a measurement."),hr.forEach(a),kn=c(ie),Ue=o(ie,"P",{});var Ko=r(Ue);mt=o(Ko,"CODE",{});var gr=r(mt);Nn=i(gr,"EvaluationModuleInfo"),gr.forEach(a),In=i(Ko,` documents a measurement, including its name, version, and features.
See the constructor arguments and properties for a full list.`),Ko.forEach(a),Cn=c(ie),ut=o(ie,"P",{});var _r=r(ut);On=i(_r,"Note: Not all fields are known on construction and may be updated later."),_r.forEach(a),ie.forEach(a),Xt=c(t),B=o(t,"H2",{class:!0});var pa=r(B);X=o(pa,"A",{id:!0,class:!0,href:!0});var br=r(X);pt=o(br,"SPAN",{});var yr=r(pt);f(be.$$.fragment,yr),yr.forEach(a),br.forEach(a),Dn=c(pa),ft=o(pa,"SPAN",{});var Er=r(ft);Pn=i(Er,"EvaluationModule"),Er.forEach(a),pa.forEach(a),Yt=c(t),w=o(t,"P",{});var S=r(w);An=i(S,"The base class "),vt=o(S,"CODE",{});var $r=r(vt);Tn=i($r,"EvaluationModule"),$r.forEach(a),Ln=i(S," implements a the logic for the subclasses "),ht=o(S,"CODE",{});var xr=r(ht);Sn=i(xr,"Metric"),xr.forEach(a),Fn=i(S,", "),gt=o(S,"CODE",{});var wr=r(gt);Un=i(wr,"Comparison"),wr.forEach(a),Vn=i(S,", and "),_t=o(S,"CODE",{});var Mr=r(_t);qn=i(Mr,"Measurement"),Mr.forEach(a),Rn=i(S,"."),S.forEach(a),Zt=c(t),E=o(t,"DIV",{class:!0});var D=r(E);f(ye.$$.fragment,D),Bn=c(D),bt=o(D,"P",{});var kr=r(bt);Jn=i(kr,"A EvaluationModule is the base class and common API for metrics, comparisons, and measurements."),kr.forEach(a),Kn=c(D),Y=o(D,"DIV",{class:!0});var fa=r(Y);f(Ee.$$.fragment,fa),zn=c(fa),yt=o(fa,"P",{});var Nr=r(yt);Hn=i(Nr,"Add one prediction and reference for the evaluation module\u2019s stack."),Nr.forEach(a),fa.forEach(a),Qn=c(D),Z=o(D,"DIV",{class:!0});var va=r(Z);f($e.$$.fragment,va),jn=c(va),Et=o(va,"P",{});var Ir=r(Et);Wn=i(Ir,"Add a batch of predictions and references for the evaluation module\u2019s stack."),Ir.forEach(a),va.forEach(a),Gn=c(D),A=o(D,"DIV",{class:!0});var qe=r(A);f(xe.$$.fragment,qe),Xn=c(qe),$t=o(qe,"P",{});var Cr=r($t);Yn=i(Cr,"Compute the evaluation module."),Cr.forEach(a),Zn=c(qe),xt=o(qe,"P",{});var Or=r(xt);eo=i(Or,"Usage of positional arguments is not allowed to prevent mistakes."),Or.forEach(a),qe.forEach(a),to=c(D),ee=o(D,"DIV",{class:!0});var ha=r(ee);f(we.$$.fragment,ha),ao=c(ha),wt=o(ha,"P",{});var Dr=r(wt);no=i(Dr,"Downloads and prepares dataset for reading."),Dr.forEach(a),ha.forEach(a),D.forEach(a),ea=c(t),J=o(t,"DIV",{class:!0});var ga=r(J);f(Me.$$.fragment,ga),oo=c(ga),Mt=o(ga,"P",{});var Pr=r(Mt);ro=i(Pr,"A Metric is the base class and common API for all metrics."),Pr.forEach(a),ga.forEach(a),ta=c(t),K=o(t,"DIV",{class:!0});var _a=r(K);f(ke.$$.fragment,_a),so=c(_a),kt=o(_a,"P",{});var Ar=r(kt);io=i(Ar,"A Comparison is the base class and common API for all comparisons."),Ar.forEach(a),_a.forEach(a),aa=c(t),z=o(t,"DIV",{class:!0});var ba=r(z);f(Ne.$$.fragment,ba),lo=c(ba),Nt=o(ba,"P",{});var Tr=r(Nt);co=i(Tr,"A Measurement is the base class and common API for all measurements."),Tr.forEach(a),ba.forEach(a),na=c(t),H=o(t,"H2",{class:!0});var ya=r(H);te=o(ya,"A",{id:!0,class:!0,href:!0});var Lr=r(te);It=o(Lr,"SPAN",{});var Sr=r(It);f(Ie.$$.fragment,Sr),Sr.forEach(a),Lr.forEach(a),mo=c(ya),Ct=o(ya,"SPAN",{});var Fr=r(Ct);uo=i(Fr,"CombinedEvaluations"),Fr.forEach(a),ya.forEach(a),oa=c(t),C=o(t,"P",{});var le=r(C);po=i(le,"The "),Ot=o(le,"CODE",{});var Ur=r(Ot);fo=i(Ur,"combine"),Ur.forEach(a),vo=i(le," function allows to combine multiple "),Dt=o(le,"CODE",{});var Vr=r(Dt);ho=i(Vr,"EvaluationModule"),Vr.forEach(a),go=i(le,"s into a single "),Pt=o(le,"CODE",{});var qr=r(Pt);_o=i(qr,"CombinedEvaluations"),qr.forEach(a),bo=i(le,"."),le.forEach(a),ra=c(t),$=o(t,"DIV",{class:!0});var F=r($);f(Ce.$$.fragment,F),yo=c(F),Oe=o(F,"P",{});var Ea=r(Oe);Eo=i(Ea,"Combines several metrics, comparisons, or measurements into a single "),At=o(Ea,"EM",{});var Rr=r(At);$o=i(Rr,"CombinedEvaluations"),Rr.forEach(a),xo=i(Ea,` object that
can be used like a single evaluation module.`),Ea.forEach(a),wo=c(F),Tt=o(F,"P",{});var Br=r(Tt);Mo=i(Br,`If two scores have the same name, then they are prefixed with their module names.
And if two modules have the same name, please use a dictionary to give them different names, otherwise an integer id is appended to the prefix.`),Br.forEach(a),ko=c(F),Lt=o(F,"P",{});var Jr=r(Lt);No=i(Jr,"Examples:"),Jr.forEach(a),Io=c(F),St=o(F,"BLOCKQUOTE",{});var Kr=r(St);Ft=o(Kr,"BLOCKQUOTE",{});var zr=r(Ft);Ut=o(zr,"BLOCKQUOTE",{});var Hr=r(Ut);Vt=o(Hr,"P",{});var Qr=r(Vt);Co=i(Qr,`clf_metrics = combine([\u201Caccuracy\u201D, \u201Cf1\u201D, \u201Cprecision\u201D,\u201Crecall\u201D])
clf_metrics.compute(predictions=[0,1], references=[1,1])
{\u2018accuracy\u2019: 0.5, \u2018f1\u2019: 0.66, \u2018precision\u2019: 1.0, \u2018recall\u2019: 0.5}`),Qr.forEach(a),Hr.forEach(a),zr.forEach(a),Kr.forEach(a),F.forEach(a),sa=c(t),I=o(t,"DIV",{class:!0});var ce=r(I);f(De.$$.fragment,ce),Oo=c(ce),ae=o(ce,"DIV",{class:!0});var $a=r(ae);f(Pe.$$.fragment,$a),Do=c($a),qt=o($a,"P",{});var jr=r(qt);Po=i(jr,"Add one prediction and reference for each evaluation module\u2019s stack."),jr.forEach(a),$a.forEach(a),Ao=c(ce),ne=o(ce,"DIV",{class:!0});var xa=r(ne);f(Ae.$$.fragment,xa),To=c(xa),Rt=o(xa,"P",{});var Wr=r(Rt);Lo=i(Wr,"Add a batch of predictions and references for each evaluation module\u2019s stack."),Wr.forEach(a),xa.forEach(a),So=c(ce),T=o(ce,"DIV",{class:!0});var Re=r(T);f(Te.$$.fragment,Re),Fo=c(Re),Bt=o(Re,"P",{});var Gr=r(Bt);Uo=i(Gr,"Compute each evaluation module."),Gr.forEach(a),Vo=c(Re),Jt=o(Re,"P",{});var Xr=r(Jt);qo=i(Xr,"Usage of positional arguments is not allowed to prevent mistakes."),Xr.forEach(a),Re.forEach(a),ce.forEach(a),this.h()},h(){m(U,"name","hf:doc:metadata"),m(U,"content",JSON.stringify(rs)),m(Q,"id","main-classes"),m(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Q,"href","#main-classes"),m(V,"class","relative group"),m(j,"id","evaluate.EvaluationModuleInfo"),m(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(j,"href","#evaluate.EvaluationModuleInfo"),m(q,"class","relative group"),m(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(X,"id","evaluate.EvaluationModule"),m(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(X,"href","#evaluate.EvaluationModule"),m(B,"class","relative group"),m(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(te,"id","evaluate.combine"),m(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(te,"href","#evaluate.combine"),m(H,"class","relative group"),m($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,d){e(document.head,U),u(t,Kt,d),u(t,V,d),e(V,Q),e(Q,Be),v(de,Be,null),e(V,Ma),e(V,Je),e(Je,ka),u(t,zt,d),u(t,q,d),e(q,j),e(j,Ke),v(me,Ke,null),e(q,Na),e(q,ze),e(ze,Ia),u(t,Ht,d),u(t,x,d),e(x,Ca),e(x,He),e(He,Oa),e(x,Da),e(x,Qe),e(Qe,Pa),e(x,Aa),e(x,je),e(je,Ta),e(x,La),e(x,We),e(We,Sa),e(x,Fa),u(t,Qt,d),u(t,y,d),v(ue,y,null),e(y,Ua),e(y,P),e(P,Va),e(P,Ge),e(Ge,qa),e(P,Ra),e(P,Xe),e(Xe,Ba),e(P,Ja),e(P,Ye),e(Ye,Ka),e(P,za),e(y,Ha),e(y,Le),e(Le,Ze),e(Ze,Qa),e(Le,ja),e(y,Wa),e(y,et),e(et,Ga),e(y,Xa),e(y,W),v(pe,W,null),e(W,Ya),e(W,fe),e(fe,Za),e(fe,tt),e(tt,en),e(fe,tn),e(y,an),e(y,G),v(ve,G,null),e(G,nn),e(G,R),e(R,on),e(R,at),e(at,rn),e(R,sn),e(R,nt),e(nt,ln),e(R,cn),u(t,jt,d),u(t,M,d),v(he,M,null),e(M,dn),e(M,ot),e(ot,mn),e(M,un),e(M,Se),e(Se,rt),e(rt,pn),e(Se,fn),e(M,vn),e(M,st),e(st,hn),u(t,Wt,d),u(t,k,d),v(ge,k,null),e(k,gn),e(k,it),e(it,_n),e(k,bn),e(k,Fe),e(Fe,lt),e(lt,yn),e(Fe,En),e(k,$n),e(k,ct),e(ct,xn),u(t,Gt,d),u(t,N,d),v(_e,N,null),e(N,wn),e(N,dt),e(dt,Mn),e(N,kn),e(N,Ue),e(Ue,mt),e(mt,Nn),e(Ue,In),e(N,Cn),e(N,ut),e(ut,On),u(t,Xt,d),u(t,B,d),e(B,X),e(X,pt),v(be,pt,null),e(B,Dn),e(B,ft),e(ft,Pn),u(t,Yt,d),u(t,w,d),e(w,An),e(w,vt),e(vt,Tn),e(w,Ln),e(w,ht),e(ht,Sn),e(w,Fn),e(w,gt),e(gt,Un),e(w,Vn),e(w,_t),e(_t,qn),e(w,Rn),u(t,Zt,d),u(t,E,d),v(ye,E,null),e(E,Bn),e(E,bt),e(bt,Jn),e(E,Kn),e(E,Y),v(Ee,Y,null),e(Y,zn),e(Y,yt),e(yt,Hn),e(E,Qn),e(E,Z),v($e,Z,null),e(Z,jn),e(Z,Et),e(Et,Wn),e(E,Gn),e(E,A),v(xe,A,null),e(A,Xn),e(A,$t),e($t,Yn),e(A,Zn),e(A,xt),e(xt,eo),e(E,to),e(E,ee),v(we,ee,null),e(ee,ao),e(ee,wt),e(wt,no),u(t,ea,d),u(t,J,d),v(Me,J,null),e(J,oo),e(J,Mt),e(Mt,ro),u(t,ta,d),u(t,K,d),v(ke,K,null),e(K,so),e(K,kt),e(kt,io),u(t,aa,d),u(t,z,d),v(Ne,z,null),e(z,lo),e(z,Nt),e(Nt,co),u(t,na,d),u(t,H,d),e(H,te),e(te,It),v(Ie,It,null),e(H,mo),e(H,Ct),e(Ct,uo),u(t,oa,d),u(t,C,d),e(C,po),e(C,Ot),e(Ot,fo),e(C,vo),e(C,Dt),e(Dt,ho),e(C,go),e(C,Pt),e(Pt,_o),e(C,bo),u(t,ra,d),u(t,$,d),v(Ce,$,null),e($,yo),e($,Oe),e(Oe,Eo),e(Oe,At),e(At,$o),e(Oe,xo),e($,wo),e($,Tt),e(Tt,Mo),e($,ko),e($,Lt),e(Lt,No),e($,Io),e($,St),e(St,Ft),e(Ft,Ut),e(Ut,Vt),e(Vt,Co),u(t,sa,d),u(t,I,d),v(De,I,null),e(I,Oo),e(I,ae),v(Pe,ae,null),e(ae,Do),e(ae,qt),e(qt,Po),e(I,Ao),e(I,ne),v(Ae,ne,null),e(ne,To),e(ne,Rt),e(Rt,Lo),e(I,So),e(I,T),v(Te,T,null),e(T,Fo),e(T,Bt),e(Bt,Uo),e(T,Vo),e(T,Jt),e(Jt,qo),ia=!0},p:as,i(t){ia||(h(de.$$.fragment,t),h(me.$$.fragment,t),h(ue.$$.fragment,t),h(pe.$$.fragment,t),h(ve.$$.fragment,t),h(he.$$.fragment,t),h(ge.$$.fragment,t),h(_e.$$.fragment,t),h(be.$$.fragment,t),h(ye.$$.fragment,t),h(Ee.$$.fragment,t),h($e.$$.fragment,t),h(xe.$$.fragment,t),h(we.$$.fragment,t),h(Me.$$.fragment,t),h(ke.$$.fragment,t),h(Ne.$$.fragment,t),h(Ie.$$.fragment,t),h(Ce.$$.fragment,t),h(De.$$.fragment,t),h(Pe.$$.fragment,t),h(Ae.$$.fragment,t),h(Te.$$.fragment,t),ia=!0)},o(t){g(de.$$.fragment,t),g(me.$$.fragment,t),g(ue.$$.fragment,t),g(pe.$$.fragment,t),g(ve.$$.fragment,t),g(he.$$.fragment,t),g(ge.$$.fragment,t),g(_e.$$.fragment,t),g(be.$$.fragment,t),g(ye.$$.fragment,t),g(Ee.$$.fragment,t),g($e.$$.fragment,t),g(xe.$$.fragment,t),g(we.$$.fragment,t),g(Me.$$.fragment,t),g(ke.$$.fragment,t),g(Ne.$$.fragment,t),g(Ie.$$.fragment,t),g(Ce.$$.fragment,t),g(De.$$.fragment,t),g(Pe.$$.fragment,t),g(Ae.$$.fragment,t),g(Te.$$.fragment,t),ia=!1},d(t){a(U),t&&a(Kt),t&&a(V),_(de),t&&a(zt),t&&a(q),_(me),t&&a(Ht),t&&a(x),t&&a(Qt),t&&a(y),_(ue),_(pe),_(ve),t&&a(jt),t&&a(M),_(he),t&&a(Wt),t&&a(k),_(ge),t&&a(Gt),t&&a(N),_(_e),t&&a(Xt),t&&a(B),_(be),t&&a(Yt),t&&a(w),t&&a(Zt),t&&a(E),_(ye),_(Ee),_($e),_(xe),_(we),t&&a(ea),t&&a(J),_(Me),t&&a(ta),t&&a(K),_(ke),t&&a(aa),t&&a(z),_(Ne),t&&a(na),t&&a(H),_(Ie),t&&a(oa),t&&a(C),t&&a(ra),t&&a($),_(Ce),t&&a(sa),t&&a(I),_(De),_(Pe),_(Ae),_(Te)}}}const rs={local:"main-classes",sections:[{local:"evaluate.EvaluationModuleInfo",title:"EvaluationModuleInfo"},{local:"evaluate.EvaluationModule",title:"EvaluationModule"},{local:"evaluate.combine",title:"CombinedEvaluations"}],title:"Main classes"};function ss(zo){return ns(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ds extends Yr{constructor(U){super();Zr(this,U,ss,os,es,{})}}export{ds as default,rs as metadata};
