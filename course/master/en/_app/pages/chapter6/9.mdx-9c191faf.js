import{S as se,i as ie,s as re,e as n,k as f,w as le,t as m,M as ce,c as s,d as t,m as p,a as i,x as he,h as u,b as y,F as o,g as k,y as fe,L as pe,q as de,o as me,B as ue,v as ke,O as _e}from"../../chunks/vendor-e7c81d8a.js";import{I as ve}from"../../chunks/WidgetTextarea.svelte_svelte_type_style_lang-08e92eaf.js";const{document:ne}=_e;function be(R){let c,P,h,d,w,_,S,z,q,T,v,M,g,b,N,I,a,E,j,C,x,G,K,$,O,W,B,F,H,L,J,A;return _=new ve({}),{c(){c=n("meta"),P=f(),h=n("h1"),d=n("a"),w=n("span"),le(_.$$.fragment),S=f(),z=n("span"),q=m("Tokenizers, check!"),T=f(),v=n("p"),M=m("Great job finishing this chapter!"),g=f(),b=n("p"),N=m("After this deep dive into tokenizers, you should:"),I=f(),a=n("ul"),E=n("li"),j=m("Be able to train a new tokenizer using an old one as a template"),C=f(),x=n("li"),G=m("Understand how to use offsets to map tokens\u2019 positions to their original span of text"),K=f(),$=n("li"),O=m("Know the differences between BPE, WordPiece, and Unigram"),W=f(),B=n("li"),F=m("Be able to mix and match the blocks provided by the \u{1F917} Tokenizers library to build your own tokenizer"),H=f(),L=n("li"),J=m("Be able to use that tokenizer inside the \u{1F917} Transformers library"),this.h()},l(e){const r=ce('[data-svelte="svelte-1phssyn"]',ne.head);c=s(r,"META",{name:!0,content:!0}),r.forEach(t),P=p(e),h=s(e,"H1",{class:!0});var U=i(h);d=s(U,"A",{id:!0,class:!0,href:!0});var D=i(d);w=s(D,"SPAN",{});var Q=i(w);he(_.$$.fragment,Q),Q.forEach(t),D.forEach(t),S=p(U),z=s(U,"SPAN",{});var V=i(z);q=u(V,"Tokenizers, check!"),V.forEach(t),U.forEach(t),T=p(e),v=s(e,"P",{});var X=i(v);M=u(X,"Great job finishing this chapter!"),X.forEach(t),g=p(e),b=s(e,"P",{});var Y=i(b);N=u(Y,"After this deep dive into tokenizers, you should:"),Y.forEach(t),I=p(e),a=s(e,"UL",{});var l=i(a);E=s(l,"LI",{});var Z=i(E);j=u(Z,"Be able to train a new tokenizer using an old one as a template"),Z.forEach(t),C=p(l),x=s(l,"LI",{});var ee=i(x);G=u(ee,"Understand how to use offsets to map tokens\u2019 positions to their original span of text"),ee.forEach(t),K=p(l),$=s(l,"LI",{});var te=i($);O=u(te,"Know the differences between BPE, WordPiece, and Unigram"),te.forEach(t),W=p(l),B=s(l,"LI",{});var oe=i(B);F=u(oe,"Be able to mix and match the blocks provided by the \u{1F917} Tokenizers library to build your own tokenizer"),oe.forEach(t),H=p(l),L=s(l,"LI",{});var ae=i(L);J=u(ae,"Be able to use that tokenizer inside the \u{1F917} Transformers library"),ae.forEach(t),l.forEach(t),this.h()},h(){y(c,"name","hf:doc:metadata"),y(c,"content",JSON.stringify(ye)),y(d,"id","tokenizers-check"),y(d,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),y(d,"href","#tokenizers-check"),y(h,"class","relative group")},m(e,r){o(ne.head,c),k(e,P,r),k(e,h,r),o(h,d),o(d,w),fe(_,w,null),o(h,S),o(h,z),o(z,q),k(e,T,r),k(e,v,r),o(v,M),k(e,g,r),k(e,b,r),o(b,N),k(e,I,r),k(e,a,r),o(a,E),o(E,j),o(a,C),o(a,x),o(x,G),o(a,K),o(a,$),o($,O),o(a,W),o(a,B),o(B,F),o(a,H),o(a,L),o(L,J),A=!0},p:pe,i(e){A||(de(_.$$.fragment,e),A=!0)},o(e){me(_.$$.fragment,e),A=!1},d(e){t(c),e&&t(P),e&&t(h),ue(_),e&&t(T),e&&t(v),e&&t(g),e&&t(b),e&&t(I),e&&t(a)}}}const ye={local:"tokenizers-check",title:"Tokenizers, check!"};function we(R){return ke(()=>{new URL(document.location).searchParams.get("fw")}),[]}class xe extends se{constructor(c){super();ie(this,c,we,be,re,{})}}export{xe as default,ye as metadata};
