import{S as jt,i as Kt,s as Qt,e as o,k as i,w as Vt,t as s,M as Zt,c as r,d as e,m as d,a as n,x as te,h as l,b as L,F as t,g as w,y as ee,L as ae,q as oe,o as re,B as ne,v as se,O as le}from"../../chunks/vendor-e7c81d8a.js";import{I as ie}from"../../chunks/WidgetTextarea.svelte_svelte_type_style_lang-08e92eaf.js";const{document:Ut}=le;function de(Lt){let h,F,f,v,x,g,tt,P,et,J,_,at,S,ot,rt,U,R,nt,j,y,$,m,I,st,lt,q,it,dt,C,ct,ht,u,p,H,ft,mt,M,ut,pt,N,Tt,Et,T,z,vt,_t,G,yt,wt,O,gt,Rt,E,Y,kt,bt,W,At,Dt,X,Bt,K;return g=new ie({}),{c(){h=o("meta"),F=i(),f=o("h1"),v=o("a"),x=o("span"),Vt(g.$$.fragment),tt=i(),P=o("span"),et=s("Summary"),J=i(),_=o("p"),at=s("In this chapter, you saw how to approach different NLP tasks using the high-level "),S=o("code"),ot=s("pipeline()"),rt=s(" function from \u{1F917} Transformers. You also saw how to search for and use models in the Hub, as well as how to use the Inference API to test the models directly in your browser."),U=i(),R=o("p"),nt=s("We discussed how Transformer models work at a high level, and talked about the importance of transfer learning and fine-tuning. A key aspect is that you can use the full architecture or only the encoder or decoder, depending on what kind of task you aim to solve. The following table summarizes this:"),j=i(),y=o("table"),$=o("thead"),m=o("tr"),I=o("th"),st=s("Model"),lt=i(),q=o("th"),it=s("Examples"),dt=i(),C=o("th"),ct=s("Tasks"),ht=i(),u=o("tbody"),p=o("tr"),H=o("td"),ft=s("Encoder"),mt=i(),M=o("td"),ut=s("ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa"),pt=i(),N=o("td"),Tt=s("Sentence classification, named entity recognition, extractive question answering"),Et=i(),T=o("tr"),z=o("td"),vt=s("Decoder"),_t=i(),G=o("td"),yt=s("CTRL, GPT, GPT-2, Transformer XL"),wt=i(),O=o("td"),gt=s("Text generation"),Rt=i(),E=o("tr"),Y=o("td"),kt=s("Encoder-decoder"),bt=i(),W=o("td"),At=s("BART, T5, Marian, mBART"),Dt=i(),X=o("td"),Bt=s("Summarization, translation, generative question answering"),this.h()},l(a){const c=Zt('[data-svelte="svelte-1phssyn"]',Ut.head);h=r(c,"META",{name:!0,content:!0}),c.forEach(e),F=d(a),f=r(a,"H1",{class:!0});var Q=n(f);v=r(Q,"A",{id:!0,class:!0,href:!0});var xt=n(v);x=r(xt,"SPAN",{});var Pt=n(x);te(g.$$.fragment,Pt),Pt.forEach(e),xt.forEach(e),tt=d(Q),P=r(Q,"SPAN",{});var St=n(P);et=l(St,"Summary"),St.forEach(e),Q.forEach(e),J=d(a),_=r(a,"P",{});var V=n(_);at=l(V,"In this chapter, you saw how to approach different NLP tasks using the high-level "),S=r(V,"CODE",{});var $t=n(S);ot=l($t,"pipeline()"),$t.forEach(e),rt=l(V," function from \u{1F917} Transformers. You also saw how to search for and use models in the Hub, as well as how to use the Inference API to test the models directly in your browser."),V.forEach(e),U=d(a),R=r(a,"P",{});var It=n(R);nt=l(It,"We discussed how Transformer models work at a high level, and talked about the importance of transfer learning and fine-tuning. A key aspect is that you can use the full architecture or only the encoder or decoder, depending on what kind of task you aim to solve. The following table summarizes this:"),It.forEach(e),j=d(a),y=r(a,"TABLE",{});var Z=n(y);$=r(Z,"THEAD",{});var qt=n($);m=r(qt,"TR",{});var k=n(m);I=r(k,"TH",{});var Ct=n(I);st=l(Ct,"Model"),Ct.forEach(e),lt=d(k),q=r(k,"TH",{});var Ht=n(q);it=l(Ht,"Examples"),Ht.forEach(e),dt=d(k),C=r(k,"TH",{});var Mt=n(C);ct=l(Mt,"Tasks"),Mt.forEach(e),k.forEach(e),qt.forEach(e),ht=d(Z),u=r(Z,"TBODY",{});var b=n(u);p=r(b,"TR",{});var A=n(p);H=r(A,"TD",{});var Nt=n(H);ft=l(Nt,"Encoder"),Nt.forEach(e),mt=d(A),M=r(A,"TD",{});var zt=n(M);ut=l(zt,"ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa"),zt.forEach(e),pt=d(A),N=r(A,"TD",{});var Gt=n(N);Tt=l(Gt,"Sentence classification, named entity recognition, extractive question answering"),Gt.forEach(e),A.forEach(e),Et=d(b),T=r(b,"TR",{});var D=n(T);z=r(D,"TD",{});var Ot=n(z);vt=l(Ot,"Decoder"),Ot.forEach(e),_t=d(D),G=r(D,"TD",{});var Yt=n(G);yt=l(Yt,"CTRL, GPT, GPT-2, Transformer XL"),Yt.forEach(e),wt=d(D),O=r(D,"TD",{});var Wt=n(O);gt=l(Wt,"Text generation"),Wt.forEach(e),D.forEach(e),Rt=d(b),E=r(b,"TR",{});var B=n(E);Y=r(B,"TD",{});var Xt=n(Y);kt=l(Xt,"Encoder-decoder"),Xt.forEach(e),bt=d(B),W=r(B,"TD",{});var Ft=n(W);At=l(Ft,"BART, T5, Marian, mBART"),Ft.forEach(e),Dt=d(B),X=r(B,"TD",{});var Jt=n(X);Bt=l(Jt,"Summarization, translation, generative question answering"),Jt.forEach(e),B.forEach(e),b.forEach(e),Z.forEach(e),this.h()},h(){L(h,"name","hf:doc:metadata"),L(h,"content",JSON.stringify(ce)),L(v,"id","summary"),L(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),L(v,"href","#summary"),L(f,"class","relative group")},m(a,c){t(Ut.head,h),w(a,F,c),w(a,f,c),t(f,v),t(v,x),ee(g,x,null),t(f,tt),t(f,P),t(P,et),w(a,J,c),w(a,_,c),t(_,at),t(_,S),t(S,ot),t(_,rt),w(a,U,c),w(a,R,c),t(R,nt),w(a,j,c),w(a,y,c),t(y,$),t($,m),t(m,I),t(I,st),t(m,lt),t(m,q),t(q,it),t(m,dt),t(m,C),t(C,ct),t(y,ht),t(y,u),t(u,p),t(p,H),t(H,ft),t(p,mt),t(p,M),t(M,ut),t(p,pt),t(p,N),t(N,Tt),t(u,Et),t(u,T),t(T,z),t(z,vt),t(T,_t),t(T,G),t(G,yt),t(T,wt),t(T,O),t(O,gt),t(u,Rt),t(u,E),t(E,Y),t(Y,kt),t(E,bt),t(E,W),t(W,At),t(E,Dt),t(E,X),t(X,Bt),K=!0},p:ae,i(a){K||(oe(g.$$.fragment,a),K=!0)},o(a){re(g.$$.fragment,a),K=!1},d(a){e(h),a&&e(F),a&&e(f),ne(g),a&&e(J),a&&e(_),a&&e(U),a&&e(R),a&&e(j),a&&e(y)}}}const ce={local:"summary",title:"Summary"};function he(Lt){return se(()=>{new URL(document.location).searchParams.get("fw")}),[]}class ue extends jt{constructor(h){super();Kt(this,h,he,de,Qt,{})}}export{ue as default,ce as metadata};
