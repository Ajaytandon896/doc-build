import{S as ke,i as Ie,s as Ce,e as r,k as d,w as $e,t as m,M as De,c as l,d as t,m as c,a as s,x as Te,h,b as n,F as o,g as i,y as xe,L as Re,q as Le,o as be,B as Pe,v as Se,O as qe}from"../../chunks/vendor-e7c81d8a.js";import{Y as Ge}from"../../chunks/Youtube-365ea064.js";import{I as Me}from"../../chunks/WidgetTextarea.svelte_svelte_type_style_lang-08e92eaf.js";const{document:Ae}=qe;function Ne(ae){let u,q,p,v,A,w,H,k,J,G,E,M,_,Q,I,j,z,N,L,K,O,b,V,U,P,W,X,f,C,g,Z,ee,D,$,te,oe,R,T,re,le,S,x,se,Y;return w=new Me({}),E=new Ge({props:{id:"d_ixlCubqQw"}}),{c(){u=r("meta"),q=d(),p=r("h1"),v=r("a"),A=r("span"),$e(w.$$.fragment),H=d(),k=r("span"),J=m("Decoder models"),G=d(),$e(E.$$.fragment),M=d(),_=r("p"),Q=m("Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. These models are often called "),I=r("em"),j=m("auto-regressive models"),z=m("."),N=d(),L=r("p"),K=m("The pretraining of decoder models usually revolves around predicting the next word in the sentence."),O=d(),b=r("p"),V=m("These models are best suited for tasks involving text generation."),U=d(),P=r("p"),W=m("Representatives of this family of models include:"),X=d(),f=r("ul"),C=r("li"),g=r("a"),Z=m("CTRL"),ee=d(),D=r("li"),$=r("a"),te=m("GPT"),oe=d(),R=r("li"),T=r("a"),re=m("GPT-2"),le=d(),S=r("li"),x=r("a"),se=m("Transformer XL"),this.h()},l(e){const a=De('[data-svelte="svelte-1phssyn"]',Ae.head);u=l(a,"META",{name:!0,content:!0}),a.forEach(t),q=c(e),p=l(e,"H1",{class:!0});var B=s(p);v=l(B,"A",{id:!0,class:!0,href:!0});var ne=s(v);A=l(ne,"SPAN",{});var ie=s(A);Te(w.$$.fragment,ie),ie.forEach(t),ne.forEach(t),H=c(B),k=l(B,"SPAN",{});var fe=s(k);J=h(fe,"Decoder models"),fe.forEach(t),B.forEach(t),G=c(e),Te(E.$$.fragment,e),M=c(e),_=l(e,"P",{});var F=s(_);Q=h(F,"Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. These models are often called "),I=l(F,"EM",{});var de=s(I);j=h(de,"auto-regressive models"),de.forEach(t),z=h(F,"."),F.forEach(t),N=c(e),L=l(e,"P",{});var me=s(L);K=h(me,"The pretraining of decoder models usually revolves around predicting the next word in the sentence."),me.forEach(t),O=c(e),b=l(e,"P",{});var ce=s(b);V=h(ce,"These models are best suited for tasks involving text generation."),ce.forEach(t),U=c(e),P=l(e,"P",{});var he=s(P);W=h(he,"Representatives of this family of models include:"),he.forEach(t),X=c(e),f=l(e,"UL",{});var y=s(f);C=l(y,"LI",{});var ue=s(C);g=l(ue,"A",{href:!0,rel:!0});var pe=s(g);Z=h(pe,"CTRL"),pe.forEach(t),ue.forEach(t),ee=c(y),D=l(y,"LI",{});var ve=s(D);$=l(ve,"A",{href:!0,rel:!0});var _e=s($);te=h(_e,"GPT"),_e.forEach(t),ve.forEach(t),oe=c(y),R=l(y,"LI",{});var ye=s(R);T=l(ye,"A",{href:!0,rel:!0});var we=s(T);re=h(we,"GPT-2"),we.forEach(t),ye.forEach(t),le=c(y),S=l(y,"LI",{});var Ee=s(S);x=l(Ee,"A",{href:!0,rel:!0});var ge=s(x);se=h(ge,"Transformer XL"),ge.forEach(t),Ee.forEach(t),y.forEach(t),this.h()},h(){n(u,"name","hf:doc:metadata"),n(u,"content",JSON.stringify(Oe)),n(v,"id","decoder-models"),n(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(v,"href","#decoder-models"),n(p,"class","relative group"),n(g,"href","https://huggingface.co/transformers/model_doc/ctrl.html"),n(g,"rel","nofollow"),n($,"href","https://huggingface.co/transformers/model_doc/gpt.html"),n($,"rel","nofollow"),n(T,"href","https://huggingface.co/transformers/model_doc/gpt2.html"),n(T,"rel","nofollow"),n(x,"href","https://huggingface.co/transformers/model_doc/transformerxl.html"),n(x,"rel","nofollow")},m(e,a){o(Ae.head,u),i(e,q,a),i(e,p,a),o(p,v),o(v,A),xe(w,A,null),o(p,H),o(p,k),o(k,J),i(e,G,a),xe(E,e,a),i(e,M,a),i(e,_,a),o(_,Q),o(_,I),o(I,j),o(_,z),i(e,N,a),i(e,L,a),o(L,K),i(e,O,a),i(e,b,a),o(b,V),i(e,U,a),i(e,P,a),o(P,W),i(e,X,a),i(e,f,a),o(f,C),o(C,g),o(g,Z),o(f,ee),o(f,D),o(D,$),o($,te),o(f,oe),o(f,R),o(R,T),o(T,re),o(f,le),o(f,S),o(S,x),o(x,se),Y=!0},p:Re,i(e){Y||(Le(w.$$.fragment,e),Le(E.$$.fragment,e),Y=!0)},o(e){be(w.$$.fragment,e),be(E.$$.fragment,e),Y=!1},d(e){t(u),e&&t(q),e&&t(p),Pe(w),e&&t(G),Pe(E,e),e&&t(M),e&&t(_),e&&t(N),e&&t(L),e&&t(O),e&&t(b),e&&t(U),e&&t(P),e&&t(X),e&&t(f)}}}const Oe={local:"decoder-models",title:"Decoder models"};function Ue(ae){return Se(()=>{new URL(document.location).searchParams.get("fw")}),[]}class Fe extends ke{constructor(u){super();Ie(this,u,Ue,Ne,Ce,{})}}export{Fe as default,Oe as metadata};
