import{S as dh,i as ch,s as mh,e as r,t as n,k as d,c as l,a as o,h as a,d as t,m as c,b as _,g as i,G as s,w as E,x as j,y as k,q as b,o as $,B as x,M as fh,N as Ho,p as Nr,v as hh,n as Lr,L as oh}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ca}from"../../chunks/Tip-hf-doc-builder.js";import{Y as wu}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ut}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as U}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as ph}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{F as _h}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function vh(Z){let u,q;return u=new ph({props:{chapter:7,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter7/section4_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter7/section4_tf.ipynb"}]}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,w){k(u,h,w),q=!0},i(h){q||(b(u.$$.fragment,h),q=!0)},o(h){$(u.$$.fragment,h),q=!1},d(h){x(u,h)}}}function bh(Z){let u,q;return u=new ph({props:{chapter:7,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter7/section4_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter7/section4_pt.ipynb"}]}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,w){k(u,h,w),q=!0},i(h){q||(b(u.$$.fragment,h),q=!0)},o(h){$(u.$$.fragment,h),q=!1},d(h){x(u,h)}}}function $h(Z){let u,q,h,w,A,v,T,S;return{c(){u=r("p"),q=n("\u270F\uFE0F "),h=r("strong"),w=n("A votre tour !"),A=n(" Un autre mot anglais souvent utilis\xE9 en fran\xE7ais est \xAB "),v=r("em"),T=n("email"),S=n(" \xBB. Trouvez le premier \xE9chantillon dans l\u2019\xE9chantillon d\u2019entra\xEEnement qui utilise ce mot. Comment est-il traduit ? Comment le mod\xE8le pr\xE9-entra\xEEn\xE9 traduit-il cette m\xEAme phrase ?")},l(z){u=l(z,"P",{});var C=o(u);q=a(C,"\u270F\uFE0F "),h=l(C,"STRONG",{});var F=o(h);w=a(F,"A votre tour !"),F.forEach(t),A=a(C," Un autre mot anglais souvent utilis\xE9 en fran\xE7ais est \xAB "),v=l(C,"EM",{});var D=o(v);T=a(D,"email"),D.forEach(t),S=a(C," \xBB. Trouvez le premier \xE9chantillon dans l\u2019\xE9chantillon d\u2019entra\xEEnement qui utilise ce mot. Comment est-il traduit ? Comment le mod\xE8le pr\xE9-entra\xEEn\xE9 traduit-il cette m\xEAme phrase ?"),C.forEach(t)},m(z,C){i(z,u,C),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S)},d(z){z&&t(u)}}}function gh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R;return{c(){u=r("p"),q=n("\u{1F4A1} Si vous utilisez un "),h=r("em"),w=n("tokenizer"),A=n(" multilingue tel que mBART, mBART-50 ou M2M100, vous devrez d\xE9finir les codes de langue de vos entr\xE9es et cibles dans le "),v=r("em"),T=n("tokenizer"),S=n(" en d\xE9finissant "),z=r("code"),C=n("tokenizer.src_lang"),F=n(" et "),D=r("code"),y=n("tokenizer.tgt_lang"),R=n(" aux bonnes valeurs.")},l(H){u=l(H,"P",{});var L=o(u);q=a(L,"\u{1F4A1} Si vous utilisez un "),h=l(L,"EM",{});var Y=o(h);w=a(Y,"tokenizer"),Y.forEach(t),A=a(L," multilingue tel que mBART, mBART-50 ou M2M100, vous devrez d\xE9finir les codes de langue de vos entr\xE9es et cibles dans le "),v=l(L,"EM",{});var O=o(v);T=a(O,"tokenizer"),O.forEach(t),S=a(L," en d\xE9finissant "),z=l(L,"CODE",{});var V=o(z);C=a(V,"tokenizer.src_lang"),V.forEach(t),F=a(L," et "),D=l(L,"CODE",{});var W=o(D);y=a(W,"tokenizer.tgt_lang"),W.forEach(t),R=a(L," aux bonnes valeurs."),L.forEach(t)},m(H,L){i(H,u,L),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R)},d(H){H&&t(u)}}}function qh(Z){let u,q,h,w,A,v,T,S,z,C,F;return{c(){u=r("p"),q=n("\u{1F4A1} Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des "),h=r("em"),w=n("checkpoints"),A=d(),v=r("code"),T=n("t5-xxx"),S=n("), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme "),z=r("code"),C=n("translate: English to French:"),F=n(".")},l(D){u=l(D,"P",{});var y=o(u);q=a(y,"\u{1F4A1} Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des "),h=l(y,"EM",{});var R=o(h);w=a(R,"checkpoints"),R.forEach(t),A=c(y),v=l(y,"CODE",{});var H=o(v);T=a(H,"t5-xxx"),H.forEach(t),S=a(y,"), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme "),z=l(y,"CODE",{});var L=o(z);C=a(L,"translate: English to French:"),L.forEach(t),F=a(y,"."),y.forEach(t)},m(D,y){i(D,u,y),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F)},d(D){D&&t(u)}}}function Eh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q;return{c(){u=r("p"),q=n("\u26A0\uFE0F Nous ne faisons pas attention au masque d\u2019attention des cibles car le mod\xE8le ne s\u2019y attend pas. Au lieu de cela, les \xE9tiquettes correspondant \xE0 un "),h=r("em"),w=n("token"),A=n(" de "),v=r("em"),T=n("padding"),S=n(" doivent \xEAtre mises \xE0 "),z=r("code"),C=n("-100"),F=n(" afin qu\u2019elles soient ignor\xE9es dans le calcul de la perte. Cela sera fait par notre assembleur de donn\xE9es plus tard puisque nous appliquons le "),D=r("em"),y=n("padding"),R=n(" dynamique, mais si vous utilisez le "),H=r("em"),L=n("padding"),Y=n(" ici, vous devriez adapter la fonction de pr\xE9traitement pour mettre toutes les \xE9tiquettes qui correspondent au "),O=r("em"),V=n("token"),W=n(" de "),M=r("em"),P=n("padding"),se=n(" \xE0 "),N=r("code"),I=n("-100"),Q=n(".")},l(ee){u=l(ee,"P",{});var X=o(u);q=a(X,"\u26A0\uFE0F Nous ne faisons pas attention au masque d\u2019attention des cibles car le mod\xE8le ne s\u2019y attend pas. Au lieu de cela, les \xE9tiquettes correspondant \xE0 un "),h=l(X,"EM",{});var ie=o(h);w=a(ie,"token"),ie.forEach(t),A=a(X," de "),v=l(X,"EM",{});var re=o(v);T=a(re,"padding"),re.forEach(t),S=a(X," doivent \xEAtre mises \xE0 "),z=l(X,"CODE",{});var te=o(z);C=a(te,"-100"),te.forEach(t),F=a(X," afin qu\u2019elles soient ignor\xE9es dans le calcul de la perte. Cela sera fait par notre assembleur de donn\xE9es plus tard puisque nous appliquons le "),D=l(X,"EM",{});var me=o(D);y=a(me,"padding"),me.forEach(t),R=a(X," dynamique, mais si vous utilisez le "),H=l(X,"EM",{});var le=o(H);L=a(le,"padding"),le.forEach(t),Y=a(X," ici, vous devriez adapter la fonction de pr\xE9traitement pour mettre toutes les \xE9tiquettes qui correspondent au "),O=l(X,"EM",{});var de=o(O);V=a(de,"token"),de.forEach(t),W=a(X," de "),M=l(X,"EM",{});var ue=o(M);P=a(ue,"padding"),ue.forEach(t),se=a(X," \xE0 "),N=l(X,"CODE",{});var ve=o(N);I=a(ve,"-100"),ve.forEach(t),Q=a(X,"."),X.forEach(t)},m(ee,X){i(ee,u,X),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),s(u,O),s(O,V),s(u,W),s(u,M),s(M,P),s(u,se),s(u,N),s(N,I),s(u,Q)},d(ee){ee&&t(u)}}}function jh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se;return w=new Ut({}),W=new U({props:{code:`from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=<span class="hljs-literal">True</span>)`}}),P=new Ca({props:{warning:!1,$$slots:{default:[xh]},$$scope:{ctx:Z}}}),{c(){u=r("h2"),q=r("a"),h=r("span"),E(w.$$.fragment),A=d(),v=r("span"),T=r("i"),S=n("Finetuner"),z=n(" du mod\xE8le avec Keras"),C=d(),F=r("p"),D=n("Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),y=r("em"),R=n("finetuner"),H=n(". Nous allons utiliser l\u2019API habituelle "),L=r("code"),Y=n("AutoModel"),O=n(" :"),V=d(),E(W.$$.fragment),M=d(),E(P.$$.fragment),this.h()},l(N){u=l(N,"H2",{class:!0});var I=o(u);q=l(I,"A",{id:!0,class:!0,href:!0});var Q=o(q);h=l(Q,"SPAN",{});var ee=o(h);j(w.$$.fragment,ee),ee.forEach(t),Q.forEach(t),A=c(I),v=l(I,"SPAN",{});var X=o(v);T=l(X,"I",{});var ie=o(T);S=a(ie,"Finetuner"),ie.forEach(t),z=a(X," du mod\xE8le avec Keras"),X.forEach(t),I.forEach(t),C=c(N),F=l(N,"P",{});var re=o(F);D=a(re,"Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),y=l(re,"EM",{});var te=o(y);R=a(te,"finetuner"),te.forEach(t),H=a(re,". Nous allons utiliser l\u2019API habituelle "),L=l(re,"CODE",{});var me=o(L);Y=a(me,"AutoModel"),me.forEach(t),O=a(re," :"),re.forEach(t),V=c(N),j(W.$$.fragment,N),M=c(N),j(P.$$.fragment,N),this.h()},h(){_(q,"id","ifinetuneri-du-modle-avec-keras"),_(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(q,"href","#ifinetuneri-du-modle-avec-keras"),_(u,"class","relative group")},m(N,I){i(N,u,I),s(u,q),s(q,h),k(w,h,null),s(u,A),s(u,v),s(v,T),s(T,S),s(v,z),i(N,C,I),i(N,F,I),s(F,D),s(F,y),s(y,R),s(F,H),s(F,L),s(L,Y),s(F,O),i(N,V,I),k(W,N,I),i(N,M,I),k(P,N,I),se=!0},i(N){se||(b(w.$$.fragment,N),b(W.$$.fragment,N),b(P.$$.fragment,N),se=!0)},o(N){$(w.$$.fragment,N),$(W.$$.fragment,N),$(P.$$.fragment,N),se=!1},d(N){N&&t(u),x(w),N&&t(C),N&&t(F),N&&t(V),x(W,N),N&&t(M),x(P,N)}}}function kh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,he;return w=new Ut({}),$e=new U({props:{code:`from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`}}),{c(){u=r("h2"),q=r("a"),h=r("span"),E(w.$$.fragment),A=d(),v=r("span"),T=r("i"),S=n("Finetuner"),z=n(" le mod\xE8le avec l'API "),C=r("code"),F=n("Trainer"),D=d(),y=r("p"),R=n("Le code actuel utilisant "),H=r("code"),L=n("Trainer"),Y=n(" sera le m\xEAme que pr\xE9c\xE9demment, avec juste un petit changement : nous utilisons ici "),O=r("a"),V=r("code"),W=n("Seq2SeqTrainer"),M=n(" qui est une sous-classe de "),P=r("code"),se=n("Trainer"),N=n(" qui nous permet de traiter correctement l\u2019\xE9valuation, en utilisant la m\xE9thode "),I=r("code"),Q=n("generate()"),ee=n(" pour pr\xE9dire les sorties \xE0 partir des entr\xE9es. Nous y reviendrons plus en d\xE9tail lorsque nous parlerons du calcul de la m\xE9trique."),X=d(),ie=r("p"),re=n("Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),te=r("em"),me=n("finetuner"),le=n(". Nous allons utiliser l\u2019API habituelle "),de=r("code"),ue=n("AutoModel"),ve=n(" :"),be=d(),E($e.$$.fragment),this.h()},l(J){u=l(J,"H2",{class:!0});var pe=o(u);q=l(pe,"A",{id:!0,class:!0,href:!0});var ce=o(q);h=l(ce,"SPAN",{});var G=o(h);j(w.$$.fragment,G),G.forEach(t),ce.forEach(t),A=c(pe),v=l(pe,"SPAN",{});var Ae=o(v);T=l(Ae,"I",{});var ge=o(T);S=a(ge,"Finetuner"),ge.forEach(t),z=a(Ae," le mod\xE8le avec l'API "),C=l(Ae,"CODE",{});var Qe=o(C);F=a(Qe,"Trainer"),Qe.forEach(t),Ae.forEach(t),pe.forEach(t),D=c(J),y=l(J,"P",{});var Ee=o(y);R=a(Ee,"Le code actuel utilisant "),H=l(Ee,"CODE",{});var fe=o(H);L=a(fe,"Trainer"),fe.forEach(t),Y=a(Ee," sera le m\xEAme que pr\xE9c\xE9demment, avec juste un petit changement : nous utilisons ici "),O=l(Ee,"A",{href:!0,rel:!0});var Me=o(O);V=l(Me,"CODE",{});var ne=o(V);W=a(ne,"Seq2SeqTrainer"),ne.forEach(t),Me.forEach(t),M=a(Ee," qui est une sous-classe de "),P=l(Ee,"CODE",{});var Oe=o(P);se=a(Oe,"Trainer"),Oe.forEach(t),N=a(Ee," qui nous permet de traiter correctement l\u2019\xE9valuation, en utilisant la m\xE9thode "),I=l(Ee,"CODE",{});var ae=o(I);Q=a(ae,"generate()"),ae.forEach(t),ee=a(Ee," pour pr\xE9dire les sorties \xE0 partir des entr\xE9es. Nous y reviendrons plus en d\xE9tail lorsque nous parlerons du calcul de la m\xE9trique."),Ee.forEach(t),X=c(J),ie=l(J,"P",{});var ze=o(ie);re=a(ze,"Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),te=l(ze,"EM",{});var ye=o(te);me=a(ye,"finetuner"),ye.forEach(t),le=a(ze,". Nous allons utiliser l\u2019API habituelle "),de=l(ze,"CODE",{});var De=o(de);ue=a(De,"AutoModel"),De.forEach(t),ve=a(ze," :"),ze.forEach(t),be=c(J),j($e.$$.fragment,J),this.h()},h(){_(q,"id","ifinetuneri-le-modle-avec-lapi-trainer"),_(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(q,"href","#ifinetuneri-le-modle-avec-lapi-trainer"),_(u,"class","relative group"),_(O,"href","https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainer"),_(O,"rel","nofollow")},m(J,pe){i(J,u,pe),s(u,q),s(q,h),k(w,h,null),s(u,A),s(u,v),s(v,T),s(T,S),s(v,z),s(v,C),s(C,F),i(J,D,pe),i(J,y,pe),s(y,R),s(y,H),s(H,L),s(y,Y),s(y,O),s(O,V),s(V,W),s(y,M),s(y,P),s(P,se),s(y,N),s(y,I),s(I,Q),s(y,ee),i(J,X,pe),i(J,ie,pe),s(ie,re),s(ie,te),s(te,me),s(ie,le),s(ie,de),s(de,ue),s(ie,ve),i(J,be,pe),k($e,J,pe),he=!0},i(J){he||(b(w.$$.fragment,J),b($e.$$.fragment,J),he=!0)},o(J){$(w.$$.fragment,J),$($e.$$.fragment,J),he=!1},d(J){J&&t(u),x(w),J&&t(D),J&&t(y),J&&t(X),J&&t(ie),J&&t(be),x($e,J)}}}function xh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se;return{c(){u=r("p"),q=n("\u{1F4A1} Le "),h=r("em"),w=n("checkpoint"),A=d(),v=r("code"),T=n("Helsinki-NLP/opus-mt-en-fr"),S=n(" ne dispose que de poids PyTorch, vous aurez donc une erreur si vous essayez de charger le mod\xE8le sans utiliser l\u2019argument "),z=r("code"),C=n("from_pt=True"),F=n(" dans la m\xE9thode "),D=r("code"),y=n("from_pretrained()"),R=n(". Lorsque vous sp\xE9cifiez "),H=r("code"),L=n("from_pt=True"),Y=n(", la biblioth\xE8que t\xE9l\xE9chargera et convertira automatiquement les poids PyTorch pour vous. Comme vous pouvez le constater, c\u2019est tr\xE8s simple de passer d\u2019un "),O=r("em"),V=n("framework"),W=n(" \xE0 l\u2019autre dans \u{1F917} "),M=r("em"),P=n("Transformers"),se=n(" !")},l(N){u=l(N,"P",{});var I=o(u);q=a(I,"\u{1F4A1} Le "),h=l(I,"EM",{});var Q=o(h);w=a(Q,"checkpoint"),Q.forEach(t),A=c(I),v=l(I,"CODE",{});var ee=o(v);T=a(ee,"Helsinki-NLP/opus-mt-en-fr"),ee.forEach(t),S=a(I," ne dispose que de poids PyTorch, vous aurez donc une erreur si vous essayez de charger le mod\xE8le sans utiliser l\u2019argument "),z=l(I,"CODE",{});var X=o(z);C=a(X,"from_pt=True"),X.forEach(t),F=a(I," dans la m\xE9thode "),D=l(I,"CODE",{});var ie=o(D);y=a(ie,"from_pretrained()"),ie.forEach(t),R=a(I,". Lorsque vous sp\xE9cifiez "),H=l(I,"CODE",{});var re=o(H);L=a(re,"from_pt=True"),re.forEach(t),Y=a(I,", la biblioth\xE8que t\xE9l\xE9chargera et convertira automatiquement les poids PyTorch pour vous. Comme vous pouvez le constater, c\u2019est tr\xE8s simple de passer d\u2019un "),O=l(I,"EM",{});var te=o(O);V=a(te,"framework"),te.forEach(t),W=a(I," \xE0 l\u2019autre dans \u{1F917} "),M=l(I,"EM",{});var me=o(M);P=a(me,"Transformers"),me.forEach(t),se=a(I," !"),I.forEach(t)},m(N,I){i(N,u,I),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),s(u,O),s(O,V),s(u,W),s(u,M),s(M,P),s(u,se)},d(N){N&&t(u)}}}function wh(Z){let u,q;return u=new U({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,w){k(u,h,w),q=!0},i(h){q||(b(u.$$.fragment,h),q=!0)},o(h){$(u.$$.fragment,h),q=!1},d(h){x(u,h)}}}function zh(Z){let u,q;return u=new U({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,w){k(u,h,w),q=!0},i(h){q||(b(u.$$.fragment,h),q=!0)},o(h){$(u.$$.fragment,h),q=!1},d(h){x(u,h)}}}function yh(Z){let u,q,h,w,A,v,T,S,z,C,F;return C=new U({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=32,
)
tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">32</span>,
)
tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),{c(){u=r("p"),q=n("Nous pouvons maintenant utiliser ce "),h=r("code"),w=n("data_collator"),A=n(" pour convertir chacun de nos jeux de donn\xE9es en un "),v=r("code"),T=n("tf.data.Dataset"),S=n(", pr\xEAt pour l\u2019entra\xEEnement :"),z=d(),E(C.$$.fragment)},l(D){u=l(D,"P",{});var y=o(u);q=a(y,"Nous pouvons maintenant utiliser ce "),h=l(y,"CODE",{});var R=o(h);w=a(R,"data_collator"),R.forEach(t),A=a(y," pour convertir chacun de nos jeux de donn\xE9es en un "),v=l(y,"CODE",{});var H=o(v);T=a(H,"tf.data.Dataset"),H.forEach(t),S=a(y,", pr\xEAt pour l\u2019entra\xEEnement :"),y.forEach(t),z=c(D),j(C.$$.fragment,D)},m(D,y){i(D,u,y),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),i(D,z,y),k(C,D,y),F=!0},i(D){F||(b(C.$$.fragment,D),F=!0)},o(D){$(C.$$.fragment,D),F=!1},d(D){D&&t(u),D&&t(z),x(C,D)}}}function Ph(Z){let u,q,h,w,A,v,T,S;return{c(){u=r("p"),q=n("Nous allons transmettre ce "),h=r("code"),w=n("data_collator"),A=n(" au "),v=r("code"),T=n("Seq2SeqTrainer"),S=n(". Ensuite, jetons un coup d\u2019oeil \xE0 la m\xE9trique.")},l(z){u=l(z,"P",{});var C=o(u);q=a(C,"Nous allons transmettre ce "),h=l(C,"CODE",{});var F=o(h);w=a(F,"data_collator"),F.forEach(t),A=a(C," au "),v=l(C,"CODE",{});var D=o(v);T=a(D,"Seq2SeqTrainer"),D.forEach(t),S=a(C,". Ensuite, jetons un coup d\u2019oeil \xE0 la m\xE9trique."),C.forEach(t)},m(z,C){i(z,u,C),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S)},i:oh,o:oh,d(z){z&&t(u)}}}function ih(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,he,J,pe;return{c(){u=r("p"),q=n("La fonctionnalit\xE9 que "),h=r("code"),w=n("Seq2SeqTrainer"),A=n(" ajoute \xE0 sa superclasse "),v=r("code"),T=n("Trainer"),S=n(" est la possibilit\xE9 d\u2019utiliser la m\xE9thode "),z=r("code"),C=n("generate()"),F=n(" pendant l\u2019\xE9valuation ou la pr\xE9diction. Pendant l\u2019entra\xEEnement, le mod\xE8le utilisera les "),D=r("code"),y=n("decoder_input_ids"),R=n(" avec un masque d\u2019attention assurant qu\u2019il n\u2019utilise pas les "),H=r("em"),L=n("tokens"),Y=n(" apr\xE8s le "),O=r("em"),V=n("token"),W=n(" qu\u2019il essaie de pr\xE9dire, pour acc\xE9l\xE9rer l\u2019entra\xEEnement. Pendant l\u2019inf\xE9rence, nous ne pourrons pas les utiliser puisque nous n\u2019aurons pas d\u2019\xE9tiquettes. Ainsi c\u2019est une bonne id\xE9e d\u2019\xE9valuer notre mod\xE8le avec la m\xEAme configuration."),M=d(),P=r("p"),se=n("Comme nous l\u2019avons vu dans le "),N=r("a"),I=n("chapitre 1"),Q=n(", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les "),ee=r("em"),X=n("tokens"),ie=n(" un par un. C\u2019est quelque chose qui est impl\xE9ment\xE9 en coulisses dans \u{1F917} "),re=r("em"),te=n("Transformers"),me=n(" par la m\xE9thode "),le=r("code"),de=n("generate()"),ue=n(". Le "),ve=r("code"),be=n("Seq2SeqTrainer"),$e=n(" nous laissera utiliser cette m\xE9thode pour l\u2019\xE9valuation si nous indiquons "),he=r("code"),J=n("predict_with_generate=True"),pe=n("."),this.h()},l(ce){u=l(ce,"P",{});var G=o(u);q=a(G,"La fonctionnalit\xE9 que "),h=l(G,"CODE",{});var Ae=o(h);w=a(Ae,"Seq2SeqTrainer"),Ae.forEach(t),A=a(G," ajoute \xE0 sa superclasse "),v=l(G,"CODE",{});var ge=o(v);T=a(ge,"Trainer"),ge.forEach(t),S=a(G," est la possibilit\xE9 d\u2019utiliser la m\xE9thode "),z=l(G,"CODE",{});var Qe=o(z);C=a(Qe,"generate()"),Qe.forEach(t),F=a(G," pendant l\u2019\xE9valuation ou la pr\xE9diction. Pendant l\u2019entra\xEEnement, le mod\xE8le utilisera les "),D=l(G,"CODE",{});var Ee=o(D);y=a(Ee,"decoder_input_ids"),Ee.forEach(t),R=a(G," avec un masque d\u2019attention assurant qu\u2019il n\u2019utilise pas les "),H=l(G,"EM",{});var fe=o(H);L=a(fe,"tokens"),fe.forEach(t),Y=a(G," apr\xE8s le "),O=l(G,"EM",{});var Me=o(O);V=a(Me,"token"),Me.forEach(t),W=a(G," qu\u2019il essaie de pr\xE9dire, pour acc\xE9l\xE9rer l\u2019entra\xEEnement. Pendant l\u2019inf\xE9rence, nous ne pourrons pas les utiliser puisque nous n\u2019aurons pas d\u2019\xE9tiquettes. Ainsi c\u2019est une bonne id\xE9e d\u2019\xE9valuer notre mod\xE8le avec la m\xEAme configuration."),G.forEach(t),M=c(ce),P=l(ce,"P",{});var ne=o(P);se=a(ne,"Comme nous l\u2019avons vu dans le "),N=l(ne,"A",{href:!0});var Oe=o(N);I=a(Oe,"chapitre 1"),Oe.forEach(t),Q=a(ne,", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les "),ee=l(ne,"EM",{});var ae=o(ee);X=a(ae,"tokens"),ae.forEach(t),ie=a(ne," un par un. C\u2019est quelque chose qui est impl\xE9ment\xE9 en coulisses dans \u{1F917} "),re=l(ne,"EM",{});var ze=o(re);te=a(ze,"Transformers"),ze.forEach(t),me=a(ne," par la m\xE9thode "),le=l(ne,"CODE",{});var ye=o(le);de=a(ye,"generate()"),ye.forEach(t),ue=a(ne,". Le "),ve=l(ne,"CODE",{});var De=o(ve);be=a(De,"Seq2SeqTrainer"),De.forEach(t),$e=a(ne," nous laissera utiliser cette m\xE9thode pour l\u2019\xE9valuation si nous indiquons "),he=l(ne,"CODE",{});var ds=o(he);J=a(ds,"predict_with_generate=True"),ds.forEach(t),pe=a(ne,"."),ne.forEach(t),this.h()},h(){_(N,"href","/course/fr/chapter1/6")},m(ce,G){i(ce,u,G),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),s(u,O),s(O,V),s(u,W),i(ce,M,G),i(ce,P,G),s(P,se),s(P,N),s(N,I),s(P,Q),s(P,ee),s(ee,X),s(P,ie),s(P,re),s(re,te),s(P,me),s(P,le),s(le,de),s(P,ue),s(P,ve),s(ve,be),s(P,$e),s(P,he),s(he,J),s(P,pe)},d(ce){ce&&t(u),ce&&t(M),ce&&t(P)}}}function Ch(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W;return V=new U({props:{code:`import numpy as np


def compute_metrics(eval_preds):
    preds, labels = eval_preds
    # Dans le cas o\xF9 le mod\xE8le retourne plus que les logits de pr\xE9diction
    if isinstance(preds, tuple):
        preds = preds[0]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

    # Remplacer les -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Quelques post-traitements simples
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    return {"bleu": result["score"]}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    preds, labels = eval_preds
    <span class="hljs-comment"># Dans le cas o\xF9 le mod\xE8le retourne plus que les logits de pr\xE9diction</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds, <span class="hljs-built_in">tuple</span>):
        preds = preds[<span class="hljs-number">0</span>]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Remplacer les -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Quelques post-traitements simples</span>
    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]}`}}),{c(){u=r("p"),q=n("Pour passer des sorties du mod\xE8le aux textes utilisables par la m\xE9trique, nous allons utiliser la m\xE9thode "),h=r("code"),w=n("tokenizer.batch_decode()"),A=n(". Nous devons juste nettoyer tous les "),v=r("code"),T=n("-100"),S=n(" dans les \xE9tiquettes. Le "),z=r("em"),C=n("tokenizer"),F=n(" fera automatiquement la m\xEAme chose pour le "),D=r("em"),y=n("token"),R=n(" de "),H=r("em"),L=n("padding"),Y=n(" :"),O=d(),E(V.$$.fragment)},l(M){u=l(M,"P",{});var P=o(u);q=a(P,"Pour passer des sorties du mod\xE8le aux textes utilisables par la m\xE9trique, nous allons utiliser la m\xE9thode "),h=l(P,"CODE",{});var se=o(h);w=a(se,"tokenizer.batch_decode()"),se.forEach(t),A=a(P,". Nous devons juste nettoyer tous les "),v=l(P,"CODE",{});var N=o(v);T=a(N,"-100"),N.forEach(t),S=a(P," dans les \xE9tiquettes. Le "),z=l(P,"EM",{});var I=o(z);C=a(I,"tokenizer"),I.forEach(t),F=a(P," fera automatiquement la m\xEAme chose pour le "),D=l(P,"EM",{});var Q=o(D);y=a(Q,"token"),Q.forEach(t),R=a(P," de "),H=l(P,"EM",{});var ee=o(H);L=a(ee,"padding"),ee.forEach(t),Y=a(P," :"),P.forEach(t),O=c(M),j(V.$$.fragment,M)},m(M,P){i(M,u,P),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),i(M,O,P),k(V,M,P),W=!0},i(M){W||(b(V.$$.fragment,M),W=!0)},o(M){$(V.$$.fragment,M),W=!1},d(M){M&&t(u),M&&t(O),x(V,M)}}}function Dh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W;return V=new U({props:{code:`import numpy as np


def compute_metrics():
    all_preds = []
    all_labels = []
    sampled_dataset = tokenized_datasets["validation"].shuffle().select(range(200))
    tf_generate_dataset = sampled_dataset.to_tf_dataset(
        columns=["input_ids", "attention_mask", "labels"],
        collate_fn=data_collator,
        shuffle=False,
        batch_size=4,
    )
    for batch in tf_generate_dataset:
        predictions = model.generate(
            input_ids=batch["input_ids"], attention_mask=batch["attention_mask"]
        )
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
        labels = batch["labels"].numpy()
        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
        decoded_preds = [pred.strip() for pred in decoded_preds]
        decoded_labels = [[label.strip()] for label in decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    return {"bleu": result["score"]}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>():
    all_preds = []
    all_labels = []
    sampled_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].shuffle().select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))
    tf_generate_dataset = sampled_dataset.to_tf_dataset(
        columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
        collate_fn=data_collator,
        shuffle=<span class="hljs-literal">False</span>,
        batch_size=<span class="hljs-number">4</span>,
    )
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tf_generate_dataset:
        predictions = model.generate(
            input_ids=batch[<span class="hljs-string">&quot;input_ids&quot;</span>], attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>]
        )
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>].numpy()
        labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)
        decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
        decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]}`}}),{c(){u=r("p"),q=n("Pour passer des sorties du mod\xE8le aux textes que la m\xE9trique peut utiliser, nous allons utiliser la m\xE9thode "),h=r("code"),w=n("tokenizer.batch_decode()"),A=n(". Nous devons juste nettoyer tous les "),v=r("code"),T=n("-100"),S=n(" dans les \xE9tiquettes. Le "),z=r("em"),C=n("tokenizer"),F=n(" fera automatiquement la m\xEAme chose pour le "),D=r("em"),y=n("token"),R=n(" de "),H=r("em"),L=n("padding"),Y=n(". D\xE9finissons une fonction qui prend notre mod\xE8le et un jeu de donn\xE9es et calcule des m\xE9triques sur ceux-ci. Comme la g\xE9n\xE9ration de longues s\xE9quences peut \xEAtre lente, nous sous-\xE9chantillonnons l\u2019ensemble de validation pour nous assurer que cela ne prend pas une \xE9ternit\xE9 :"),O=d(),E(V.$$.fragment)},l(M){u=l(M,"P",{});var P=o(u);q=a(P,"Pour passer des sorties du mod\xE8le aux textes que la m\xE9trique peut utiliser, nous allons utiliser la m\xE9thode "),h=l(P,"CODE",{});var se=o(h);w=a(se,"tokenizer.batch_decode()"),se.forEach(t),A=a(P,". Nous devons juste nettoyer tous les "),v=l(P,"CODE",{});var N=o(v);T=a(N,"-100"),N.forEach(t),S=a(P," dans les \xE9tiquettes. Le "),z=l(P,"EM",{});var I=o(z);C=a(I,"tokenizer"),I.forEach(t),F=a(P," fera automatiquement la m\xEAme chose pour le "),D=l(P,"EM",{});var Q=o(D);y=a(Q,"token"),Q.forEach(t),R=a(P," de "),H=l(P,"EM",{});var ee=o(H);L=a(ee,"padding"),ee.forEach(t),Y=a(P,". D\xE9finissons une fonction qui prend notre mod\xE8le et un jeu de donn\xE9es et calcule des m\xE9triques sur ceux-ci. Comme la g\xE9n\xE9ration de longues s\xE9quences peut \xEAtre lente, nous sous-\xE9chantillonnons l\u2019ensemble de validation pour nous assurer que cela ne prend pas une \xE9ternit\xE9 :"),P.forEach(t),O=c(M),j(V.$$.fragment,M)},m(M,P){i(M,u,P),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),i(M,O,P),k(V,M,P),W=!0},i(M){W||(b(V.$$.fragment,M),W=!0)},o(M){$(V.$$.fragment,M),W=!1},d(M){M&&t(u),M&&t(O),x(V,M)}}}function Th(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,he,J,pe,ce,G,Ae,ge,Qe,Ee,fe,Me,ne,Oe,ae,ze,ye,De,ds,Ue,ss,cs,ts,Pe,Fe,He,je,Qs,Ie,Js,Ys,Je,Re,Ns,Ne,g,oe,js,ke,Be,_e,Ke,Le,ot,we,ns,it,ks,Ye,Zs,Ve,ms,Te,ut,fs,as,Ls,et,Ge,Ft,xs,Os,Us,Ce,Et,rs,Ht,hs,xe,jt,kt,pt,xt,wt,zt,It,_s,zs,vs,Xe,yt,ys,Pt,dt,ws,Ct,We,Bt,Fs,Dt,Rt,Hs,Ps,Se,Cs,ls,st,ct,Tt,Kt,bs,Vt,Gt,tt,$s,Ds,Ts,mt,nt,ft,Ze;return y=new U({props:{code:`from transformers import Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    f"marian-finetuned-kde4-en-to-fr",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=3,
    predict_with_generate=True,
    fp16=True,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">32</span>,
    per_device_eval_batch_size=<span class="hljs-number">64</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    save_total_limit=<span class="hljs-number">3</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    predict_with_generate=<span class="hljs-literal">True</span>,
    fp16=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),Fe=new Ca({props:{$$slots:{default:[Ah]},$$scope:{ctx:Z}}}),Re=new U({props:{code:`from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`}}),_e=new U({props:{code:"trainer.evaluate(max_length=max_target_length)",highlighted:"trainer.evaluate(max_length=max_target_length)"}}),Le=new U({props:{code:`{'eval_loss': 1.6964408159255981,
 'eval_bleu': 39.26865061007616,
 'eval_runtime': 965.8884,
 'eval_samples_per_second': 21.76,
 'eval_steps_per_second': 0.341}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">1.6964408159255981</span>,
 <span class="hljs-string">&#x27;eval_bleu&#x27;</span>: <span class="hljs-number">39.26865061007616</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">965.8884</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">21.76</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">0.341</span>}`}}),Ve=new U({props:{code:"trainer.train()",highlighted:"trainer.train()"}}),Os=new U({props:{code:"trainer.evaluate(max_length=max_target_length)",highlighted:"trainer.evaluate(max_length=max_target_length)"}}),Ce=new U({props:{code:`{'eval_loss': 0.8558505773544312,
 'eval_bleu': 52.94161337775576,
 'eval_runtime': 714.2576,
 'eval_samples_per_second': 29.426,
 'eval_steps_per_second': 0.461,
 'epoch': 3.0}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">0.8558505773544312</span>,
 <span class="hljs-string">&#x27;eval_bleu&#x27;</span>: <span class="hljs-number">52.94161337775576</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">714.2576</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">29.426</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">0.461</span>,
 <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-number">3.0</span>}`}}),We=new U({props:{code:'trainer.push_to_hub(tags="translation", commit_message="Training complete")',highlighted:'trainer.push_to_hub(tags=<span class="hljs-string">&quot;translation&quot;</span>, commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),Hs=new U({props:{code:"'https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3&#x27;</span>'}}),{c(){u=r("p"),q=n("Une fois ceci fait, nous pouvons d\xE9finir notre "),h=r("code"),w=n("Seq2SeqTrainingArguments"),A=n(". Comme pour le "),v=r("code"),T=n("Trainer"),S=n(", nous utilisons une sous-classe de "),z=r("code"),C=n("TrainingArguments"),F=n(" qui contient quelques champs suppl\xE9mentaires :"),D=d(),E(y.$$.fragment),R=d(),H=r("p"),L=n("En dehors des hyperparam\xE8tres habituels (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, la taille des batchs et une le taux de d\xE9croissance des poids), voici quelques changements par rapport \xE0 ce que nous avons vu dans les sections pr\xE9c\xE9dentes :"),Y=d(),O=r("ul"),V=r("li"),W=n("Nous ne d\xE9finissons pas d\u2019\xE9valuation car elle prend du temps. Nous allons juste \xE9valuer une fois notre mod\xE8le avant l\u2019entra\xEEnement et apr\xE8s."),M=d(),P=r("li"),se=n("Nous avons mis "),N=r("code"),I=n("fp16=True"),Q=n(", ce qui acc\xE9l\xE8re l\u2019entra\xEEnement sur les GPUs modernes."),ee=d(),X=r("li"),ie=n("Nous d\xE9finissons "),re=r("code"),te=n("predict_with_generate=True"),me=n(", comme discut\xE9 ci-dessus."),le=d(),de=r("li"),ue=n("Nous utilisons "),ve=r("code"),be=n("push_to_hub=True"),$e=n(" pour t\xE9l\xE9charger le mod\xE8le sur le "),he=r("em"),J=n("Hub"),pe=n(" \xE0 la fin de chaque \xE9poque."),ce=d(),G=r("p"),Ae=n("Notez que vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),ge=r("code"),Qe=n("hub_model_id"),Ee=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),fe=r("a"),Me=r("code"),ne=n("huggingface-course"),Oe=n(", nous avons ajout\xE9 "),ae=r("code"),ze=n('hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),ye=n(" \xE0 "),De=r("code"),ds=n("Seq2SeqTrainingArguments"),Ue=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Dans notre cas ce sera "),ss=r("code"),cs=n('"sgugger/marian-finetuned-kde4-en-to-fr"'),ts=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),Pe=d(),E(Fe.$$.fragment),He=d(),je=r("p"),Qs=n("Enfin, nous passons tout au "),Ie=r("code"),Js=n("Seq2SeqTrainer"),Ys=n(" :"),Je=d(),E(Re.$$.fragment),Ns=d(),Ne=r("p"),g=n("Avant d\u2019entra\xEEner, nous allons d\u2019abord regarder le score obtenu par notre mod\xE8le, pour v\xE9rifier que nous n\u2019aggravons pas les choses avec notre "),oe=r("em"),js=n("finetuning"),ke=n(". Cette commande va prendre un peu de temps, vous pouvez donc prendre un caf\xE9 pendant qu\u2019elle s\u2019ex\xE9cute :"),Be=d(),E(_e.$$.fragment),Ke=d(),E(Le.$$.fragment),ot=d(),we=r("p"),ns=n("Un score BLEU de 39 n\u2019est pas trop mauvais, ce qui refl\xE8te le fait que notre mod\xE8le est d\xE9j\xE0 bon pour traduire des phrases anglaises en phrases fran\xE7aises."),it=d(),ks=r("p"),Ye=n("Vient ensuite l\u2019entra\xEEnement, qui prendra \xE9galement un peu de temps :"),Zs=d(),E(Ve.$$.fragment),ms=d(),Te=r("p"),ut=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),fs=r("em"),as=n("Hub"),Ls=n(" en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),et=d(),Ge=r("p"),Ft=n("Une fois l\u2019entra\xEEnement termin\xE9, nous \xE9valuons \xE0 nouveau notre mod\xE8le. Avec un peu de chance, nous verrons une am\xE9lioration du score BLEU !"),xs=d(),E(Os.$$.fragment),Us=d(),E(Ce.$$.fragment),Et=d(),rs=r("p"),Ht=n("C\u2019est une am\xE9lioration de pr\xE8s de 14 points, ce qui est formidable."),hs=d(),xe=r("p"),jt=n("Enfin, nous utilisons la m\xE9thode "),kt=r("code"),pt=n("push_to_hub()"),xt=n(" pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le. "),wt=r("code"),zt=n("Trainer"),It=n(" r\xE9dige \xE9galement une carte de mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. Cette carte de mod\xE8le contient des m\xE9tadonn\xE9es qui aident le "),_s=r("em"),zs=n("Hub"),vs=n(" \xE0 choisir le "),Xe=r("em"),yt=n("widget"),ys=n(" pour l\u2019inf\xE9rence. Habituellement, il n\u2019y a pas besoin de dire quoi que ce soit car il peut inf\xE9rer le bon "),Pt=r("em"),dt=n("widget"),ws=n(" \xE0 partir de la classe du mod\xE8le, mais dans ce cas, la m\xEAme classe de mod\xE8le peut \xEAtre utilis\xE9e pour toutes sortes de probl\xE8mes de s\xE9quence \xE0 s\xE9quence. Ainsi nous sp\xE9cifions que c\u2019est un mod\xE8le de traduction :"),Ct=d(),E(We.$$.fragment),Bt=d(),Fs=r("p"),Dt=n("Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),Rt=d(),E(Hs.$$.fragment),Ps=d(),Se=r("p"),Cs=n("\xC0 ce stade, vous pouvez utiliser le "),ls=r("em"),st=n("widget"),ct=n(" d\u2019inf\xE9rence sur le "),Tt=r("em"),Kt=n("Hub"),bs=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Vt=r("em"),Gt=n("finetuner"),tt=n(" un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),$s=d(),Ds=r("p"),Ts=n("Si vous souhaitez vous plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),mt=r("em"),nt=n("Accelerate"),ft=n("."),this.h()},l(f){u=l(f,"P",{});var B=o(u);q=a(B,"Une fois ceci fait, nous pouvons d\xE9finir notre "),h=l(B,"CODE",{});var gs=o(h);w=a(gs,"Seq2SeqTrainingArguments"),gs.forEach(t),A=a(B,". Comme pour le "),v=l(B,"CODE",{});var Dn=o(v);T=a(Dn,"Trainer"),Dn.forEach(t),S=a(B,", nous utilisons une sous-classe de "),z=l(B,"CODE",{});var at=o(z);C=a(at,"TrainingArguments"),at.forEach(t),F=a(B," qui contient quelques champs suppl\xE9mentaires :"),B.forEach(t),D=c(f),j(y.$$.fragment,f),R=c(f),H=l(f,"P",{});var Xt=o(H);L=a(Xt,"En dehors des hyperparam\xE8tres habituels (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, la taille des batchs et une le taux de d\xE9croissance des poids), voici quelques changements par rapport \xE0 ce que nous avons vu dans les sections pr\xE9c\xE9dentes :"),Xt.forEach(t),Y=c(f),O=l(f,"UL",{});var Is=o(O);V=l(Is,"LI",{});var Wt=o(V);W=a(Wt,"Nous ne d\xE9finissons pas d\u2019\xE9valuation car elle prend du temps. Nous allons juste \xE9valuer une fois notre mod\xE8le avant l\u2019entra\xEEnement et apr\xE8s."),Wt.forEach(t),M=c(Is),P=l(Is,"LI",{});var ht=o(P);se=a(ht,"Nous avons mis "),N=l(ht,"CODE",{});var Tn=o(N);I=a(Tn,"fp16=True"),Tn.forEach(t),Q=a(ht,", ce qui acc\xE9l\xE8re l\u2019entra\xEEnement sur les GPUs modernes."),ht.forEach(t),ee=c(Is),X=l(Is,"LI",{});var St=o(X);ie=a(St,"Nous d\xE9finissons "),re=l(St,"CODE",{});var Bs=o(re);te=a(Bs,"predict_with_generate=True"),Bs.forEach(t),me=a(St,", comme discut\xE9 ci-dessus."),St.forEach(t),le=c(Is),de=l(Is,"LI",{});var rt=o(de);ue=a(rt,"Nous utilisons "),ve=l(rt,"CODE",{});var _t=o(ve);be=a(_t,"push_to_hub=True"),_t.forEach(t),$e=a(rt," pour t\xE9l\xE9charger le mod\xE8le sur le "),he=l(rt,"EM",{});var Qt=o(he);J=a(Qt,"Hub"),Qt.forEach(t),pe=a(rt," \xE0 la fin de chaque \xE9poque."),rt.forEach(t),Is.forEach(t),ce=c(f),G=l(f,"P",{});var qe=o(G);Ae=a(qe,"Notez que vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),ge=l(qe,"CODE",{});var cn=o(ge);Qe=a(cn,"hub_model_id"),cn.forEach(t),Ee=a(qe," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),fe=l(qe,"A",{href:!0,rel:!0});var Rs=o(fe);Me=l(Rs,"CODE",{});var mn=o(Me);ne=a(mn,"huggingface-course"),mn.forEach(t),Rs.forEach(t),Oe=a(qe,", nous avons ajout\xE9 "),ae=l(qe,"CODE",{});var Ss=o(ae);ze=a(Ss,'hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),Ss.forEach(t),ye=a(qe," \xE0 "),De=l(qe,"CODE",{});var Jt=o(De);ds=a(Jt,"Seq2SeqTrainingArguments"),Jt.forEach(t),Ue=a(qe,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Dans notre cas ce sera "),ss=l(qe,"CODE",{});var Yt=o(ss);cs=a(Yt,'"sgugger/marian-finetuned-kde4-en-to-fr"'),Yt.forEach(t),ts=a(qe," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),qe.forEach(t),Pe=c(f),j(Fe.$$.fragment,f),He=c(f),je=l(f,"P",{});var Zt=o(je);Qs=a(Zt,"Enfin, nous passons tout au "),Ie=l(Zt,"CODE",{});var fn=o(Ie);Js=a(fn,"Seq2SeqTrainer"),fn.forEach(t),Ys=a(Zt," :"),Zt.forEach(t),Je=c(f),j(Re.$$.fragment,f),Ns=c(f),Ne=l(f,"P",{});var os=o(Ne);g=a(os,"Avant d\u2019entra\xEEner, nous allons d\u2019abord regarder le score obtenu par notre mod\xE8le, pour v\xE9rifier que nous n\u2019aggravons pas les choses avec notre "),oe=l(os,"EM",{});var At=o(oe);js=a(At,"finetuning"),At.forEach(t),ke=a(os,". Cette commande va prendre un peu de temps, vous pouvez donc prendre un caf\xE9 pendant qu\u2019elle s\u2019ex\xE9cute :"),os.forEach(t),Be=c(f),j(_e.$$.fragment,f),Ke=c(f),j(Le.$$.fragment,f),ot=c(f),we=l(f,"P",{});var Mt=o(we);ns=a(Mt,"Un score BLEU de 39 n\u2019est pas trop mauvais, ce qui refl\xE8te le fait que notre mod\xE8le est d\xE9j\xE0 bon pour traduire des phrases anglaises en phrases fran\xE7aises."),Mt.forEach(t),it=c(f),ks=l(f,"P",{});var Sn=o(ks);Ye=a(Sn,"Vient ensuite l\u2019entra\xEEnement, qui prendra \xE9galement un peu de temps :"),Sn.forEach(t),Zs=c(f),j(Ve.$$.fragment,f),ms=c(f),Te=l(f,"P",{});var vt=o(Te);ut=a(vt,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),fs=l(vt,"EM",{});var m=o(fs);as=a(m,"Hub"),m.forEach(t),Ls=a(vt," en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),vt.forEach(t),et=c(f),Ge=l(f,"P",{});var K=o(Ge);Ft=a(K,"Une fois l\u2019entra\xEEnement termin\xE9, nous \xE9valuons \xE0 nouveau notre mod\xE8le. Avec un peu de chance, nous verrons une am\xE9lioration du score BLEU !"),K.forEach(t),xs=c(f),j(Os.$$.fragment,f),Us=c(f),j(Ce.$$.fragment,f),Et=c(f),rs=l(f,"P",{});var Nt=o(rs);Ht=a(Nt,"C\u2019est une am\xE9lioration de pr\xE8s de 14 points, ce qui est formidable."),Nt.forEach(t),hs=c(f),xe=l(f,"P",{});var is=o(xe);jt=a(is,"Enfin, nous utilisons la m\xE9thode "),kt=l(is,"CODE",{});var bt=o(kt);pt=a(bt,"push_to_hub()"),bt.forEach(t),xt=a(is," pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le. "),wt=l(is,"CODE",{});var Lt=o(wt);zt=a(Lt,"Trainer"),Lt.forEach(t),It=a(is," r\xE9dige \xE9galement une carte de mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. Cette carte de mod\xE8le contient des m\xE9tadonn\xE9es qui aident le "),_s=l(is,"EM",{});var hn=o(_s);zs=a(hn,"Hub"),hn.forEach(t),vs=a(is," \xE0 choisir le "),Xe=l(is,"EM",{});var Zn=o(Xe);yt=a(Zn,"widget"),Zn.forEach(t),ys=a(is," pour l\u2019inf\xE9rence. Habituellement, il n\u2019y a pas besoin de dire quoi que ce soit car il peut inf\xE9rer le bon "),Pt=l(is,"EM",{});var _n=o(Pt);dt=a(_n,"widget"),_n.forEach(t),ws=a(is," \xE0 partir de la classe du mod\xE8le, mais dans ce cas, la m\xEAme classe de mod\xE8le peut \xEAtre utilis\xE9e pour toutes sortes de probl\xE8mes de s\xE9quence \xE0 s\xE9quence. Ainsi nous sp\xE9cifions que c\u2019est un mod\xE8le de traduction :"),is.forEach(t),Ct=c(f),j(We.$$.fragment,f),Bt=c(f),Fs=l(f,"P",{});var An=o(Fs);Dt=a(An,"Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),An.forEach(t),Rt=c(f),j(Hs.$$.fragment,f),Ps=c(f),Se=l(f,"P",{});var qs=o(Se);Cs=a(qs,"\xC0 ce stade, vous pouvez utiliser le "),ls=l(qs,"EM",{});var Mn=o(ls);st=a(Mn,"widget"),Mn.forEach(t),ct=a(qs," d\u2019inf\xE9rence sur le "),Tt=l(qs,"EM",{});var As=o(Tt);Kt=a(As,"Hub"),As.forEach(t),bs=a(qs," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Vt=l(qs,"EM",{});var Nn=o(Vt);Gt=a(Nn,"finetuner"),Nn.forEach(t),tt=a(qs," un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),qs.forEach(t),$s=c(f),Ds=l(f,"P",{});var Ks=o(Ds);Ts=a(Ks,"Si vous souhaitez vous plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),mt=l(Ks,"EM",{});var vn=o(mt);nt=a(vn,"Accelerate"),vn.forEach(t),ft=a(Ks,"."),Ks.forEach(t),this.h()},h(){_(fe,"href","https://huggingface.co/huggingface-course"),_(fe,"rel","nofollow")},m(f,B){i(f,u,B),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),i(f,D,B),k(y,f,B),i(f,R,B),i(f,H,B),s(H,L),i(f,Y,B),i(f,O,B),s(O,V),s(V,W),s(O,M),s(O,P),s(P,se),s(P,N),s(N,I),s(P,Q),s(O,ee),s(O,X),s(X,ie),s(X,re),s(re,te),s(X,me),s(O,le),s(O,de),s(de,ue),s(de,ve),s(ve,be),s(de,$e),s(de,he),s(he,J),s(de,pe),i(f,ce,B),i(f,G,B),s(G,Ae),s(G,ge),s(ge,Qe),s(G,Ee),s(G,fe),s(fe,Me),s(Me,ne),s(G,Oe),s(G,ae),s(ae,ze),s(G,ye),s(G,De),s(De,ds),s(G,Ue),s(G,ss),s(ss,cs),s(G,ts),i(f,Pe,B),k(Fe,f,B),i(f,He,B),i(f,je,B),s(je,Qs),s(je,Ie),s(Ie,Js),s(je,Ys),i(f,Je,B),k(Re,f,B),i(f,Ns,B),i(f,Ne,B),s(Ne,g),s(Ne,oe),s(oe,js),s(Ne,ke),i(f,Be,B),k(_e,f,B),i(f,Ke,B),k(Le,f,B),i(f,ot,B),i(f,we,B),s(we,ns),i(f,it,B),i(f,ks,B),s(ks,Ye),i(f,Zs,B),k(Ve,f,B),i(f,ms,B),i(f,Te,B),s(Te,ut),s(Te,fs),s(fs,as),s(Te,Ls),i(f,et,B),i(f,Ge,B),s(Ge,Ft),i(f,xs,B),k(Os,f,B),i(f,Us,B),k(Ce,f,B),i(f,Et,B),i(f,rs,B),s(rs,Ht),i(f,hs,B),i(f,xe,B),s(xe,jt),s(xe,kt),s(kt,pt),s(xe,xt),s(xe,wt),s(wt,zt),s(xe,It),s(xe,_s),s(_s,zs),s(xe,vs),s(xe,Xe),s(Xe,yt),s(xe,ys),s(xe,Pt),s(Pt,dt),s(xe,ws),i(f,Ct,B),k(We,f,B),i(f,Bt,B),i(f,Fs,B),s(Fs,Dt),i(f,Rt,B),k(Hs,f,B),i(f,Ps,B),i(f,Se,B),s(Se,Cs),s(Se,ls),s(ls,st),s(Se,ct),s(Se,Tt),s(Tt,Kt),s(Se,bs),s(Se,Vt),s(Vt,Gt),s(Se,tt),i(f,$s,B),i(f,Ds,B),s(Ds,Ts),s(Ds,mt),s(mt,nt),s(Ds,ft),Ze=!0},i(f){Ze||(b(y.$$.fragment,f),b(Fe.$$.fragment,f),b(Re.$$.fragment,f),b(_e.$$.fragment,f),b(Le.$$.fragment,f),b(Ve.$$.fragment,f),b(Os.$$.fragment,f),b(Ce.$$.fragment,f),b(We.$$.fragment,f),b(Hs.$$.fragment,f),Ze=!0)},o(f){$(y.$$.fragment,f),$(Fe.$$.fragment,f),$(Re.$$.fragment,f),$(_e.$$.fragment,f),$(Le.$$.fragment,f),$(Ve.$$.fragment,f),$(Os.$$.fragment,f),$(Ce.$$.fragment,f),$(We.$$.fragment,f),$(Hs.$$.fragment,f),Ze=!1},d(f){f&&t(u),f&&t(D),x(y,f),f&&t(R),f&&t(H),f&&t(Y),f&&t(O),f&&t(ce),f&&t(G),f&&t(Pe),x(Fe,f),f&&t(He),f&&t(je),f&&t(Je),x(Re,f),f&&t(Ns),f&&t(Ne),f&&t(Be),x(_e,f),f&&t(Ke),x(Le,f),f&&t(ot),f&&t(we),f&&t(it),f&&t(ks),f&&t(Zs),x(Ve,f),f&&t(ms),f&&t(Te),f&&t(et),f&&t(Ge),f&&t(xs),x(Os,f),f&&t(Us),x(Ce,f),f&&t(Et),f&&t(rs),f&&t(hs),f&&t(xe),f&&t(Ct),x(We,f),f&&t(Bt),f&&t(Fs),f&&t(Rt),x(Hs,f),f&&t(Ps),f&&t(Se),f&&t($s),f&&t(Ds)}}}function Sh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,he,J,pe,ce,G,Ae,ge,Qe,Ee,fe,Me,ne,Oe,ae,ze,ye,De,ds,Ue,ss,cs,ts,Pe,Fe,He,je,Qs,Ie,Js,Ys,Je,Re,Ns,Ne;return w=new U({props:{code:"print(compute_metrics())",highlighted:'<span class="hljs-built_in">print</span>(compute_metrics())'}}),v=new U({props:{code:"{'bleu': 33.26983701454733}",highlighted:'{&#x27;bleu&#x27;: <span class="hljs-number">33.26983701454733</span>}'}}),R=new U({props:{code:`from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans le jeu de donn\xE9es, divis\xE9 par la taille du batch,
# puis multipli\xE9 par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un tf.data.Dataset,
# et non le jeu de donn\xE9es original donc son len() est d\xE9j\xE0 num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=5e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# Entra\xEEner en mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans le jeu de donn\xE9es, divis\xE9 par la taille du batch,</span>
<span class="hljs-comment"># puis multipli\xE9 par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un tf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original donc son len() est d\xE9j\xE0 num_samples // batch_size.</span>
num_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">5e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)`}}),te=new U({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
    output_dir="marian-finetuned-kde4-en-to-fr", tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(
    output_dir=<span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr&quot;</span>, tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`}}),ae=new Ca({props:{$$slots:{default:[Mh]},$$scope:{ctx:Z}}}),Ue=new U({props:{code:"print(compute_metrics())",highlighted:'<span class="hljs-built_in">print</span>(compute_metrics())'}}),cs=new U({props:{code:"{'bleu': 57.334066271545865}",highlighted:'{&#x27;bleu&#x27;: <span class="hljs-number">57.334066271545865</span>}'}}),{c(){u=r("p"),q=n("Avant de commencer, voyons quel type de r\xE9sultats nous obtenons avec notre mod\xE8le sans entra\xEEnement :"),h=d(),E(w.$$.fragment),A=d(),E(v.$$.fragment),T=d(),S=r("p"),z=n("Une fois ceci fait, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler et entra\xEEner notre mod\xE8le. Notez l\u2019utilisation de "),C=r("code"),F=n('tf.keras.mixed_precision.set_global_policy("mixed_float16")'),D=n(". Ceci indiquera \xE0 Keras de s\u2019entra\xEEner en utilisant float16, ce qui peut donner un gain de vitesse significatif sur les GPUs qui le supportent (Nvidia 20xx/V100 ou plus r\xE9cent)."),y=d(),E(R.$$.fragment),H=d(),L=r("p"),Y=n("Ensuite, nous d\xE9finissons un "),O=r("code"),V=n("PushToHubCallback"),W=n(" pour t\xE9l\xE9charger notre mod\xE8le sur le "),M=r("em"),P=n("Hub"),se=n(" pendant l\u2019entra\xEEnement, comme nous l\u2019avons vu dans la "),N=r("a"),I=n("section 2"),Q=n(", puis nous entra\xEEnons simplement le mod\xE8le avec ce "),ee=r("em"),X=n("callback"),ie=n(" :"),re=d(),E(te.$$.fragment),me=d(),le=r("p"),de=n("Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser le mod\xE8le avec l\u2019argument "),ue=r("code"),ve=n("hub_model_id"),be=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),$e=r("a"),he=r("code"),J=n("huggingface-course"),pe=n(", nous avons ajout\xE9 "),ce=r("code"),G=n('hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),Ae=n(" dans "),ge=r("code"),Qe=n("Seq2SeqTrainingArguments"),Ee=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Ici ce sera "),fe=r("code"),Me=n('"sgugger/marian-finetuned-kde4-en-to-fr"'),ne=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),Oe=d(),E(ae.$$.fragment),ze=d(),ye=r("p"),De=n("Enfin, voyons \xE0 quoi ressemblent nos m\xE9triques maintenant que l\u2019entra\xEEnement est termin\xE9 :"),ds=d(),E(Ue.$$.fragment),ss=d(),E(cs.$$.fragment),ts=d(),Pe=r("p"),Fe=n("\xC0 ce stade, vous pouvez utiliser le "),He=r("em"),je=n("widget"),Qs=n(" d\u2019inf\xE9rence sur le "),Ie=r("em"),Js=n("Hub"),Ys=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Je=r("em"),Re=n("finetuner"),Ns=n(" un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),this.h()},l(g){u=l(g,"P",{});var oe=o(u);q=a(oe,"Avant de commencer, voyons quel type de r\xE9sultats nous obtenons avec notre mod\xE8le sans entra\xEEnement :"),oe.forEach(t),h=c(g),j(w.$$.fragment,g),A=c(g),j(v.$$.fragment,g),T=c(g),S=l(g,"P",{});var js=o(S);z=a(js,"Une fois ceci fait, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler et entra\xEEner notre mod\xE8le. Notez l\u2019utilisation de "),C=l(js,"CODE",{});var ke=o(C);F=a(ke,'tf.keras.mixed_precision.set_global_policy("mixed_float16")'),ke.forEach(t),D=a(js,". Ceci indiquera \xE0 Keras de s\u2019entra\xEEner en utilisant float16, ce qui peut donner un gain de vitesse significatif sur les GPUs qui le supportent (Nvidia 20xx/V100 ou plus r\xE9cent)."),js.forEach(t),y=c(g),j(R.$$.fragment,g),H=c(g),L=l(g,"P",{});var Be=o(L);Y=a(Be,"Ensuite, nous d\xE9finissons un "),O=l(Be,"CODE",{});var _e=o(O);V=a(_e,"PushToHubCallback"),_e.forEach(t),W=a(Be," pour t\xE9l\xE9charger notre mod\xE8le sur le "),M=l(Be,"EM",{});var Ke=o(M);P=a(Ke,"Hub"),Ke.forEach(t),se=a(Be," pendant l\u2019entra\xEEnement, comme nous l\u2019avons vu dans la "),N=l(Be,"A",{href:!0});var Le=o(N);I=a(Le,"section 2"),Le.forEach(t),Q=a(Be,", puis nous entra\xEEnons simplement le mod\xE8le avec ce "),ee=l(Be,"EM",{});var ot=o(ee);X=a(ot,"callback"),ot.forEach(t),ie=a(Be," :"),Be.forEach(t),re=c(g),j(te.$$.fragment,g),me=c(g),le=l(g,"P",{});var we=o(le);de=a(we,"Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser le mod\xE8le avec l\u2019argument "),ue=l(we,"CODE",{});var ns=o(ue);ve=a(ns,"hub_model_id"),ns.forEach(t),be=a(we," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),$e=l(we,"A",{href:!0,rel:!0});var it=o($e);he=l(it,"CODE",{});var ks=o(he);J=a(ks,"huggingface-course"),ks.forEach(t),it.forEach(t),pe=a(we,", nous avons ajout\xE9 "),ce=l(we,"CODE",{});var Ye=o(ce);G=a(Ye,'hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),Ye.forEach(t),Ae=a(we," dans "),ge=l(we,"CODE",{});var Zs=o(ge);Qe=a(Zs,"Seq2SeqTrainingArguments"),Zs.forEach(t),Ee=a(we,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Ici ce sera "),fe=l(we,"CODE",{});var Ve=o(fe);Me=a(Ve,'"sgugger/marian-finetuned-kde4-en-to-fr"'),Ve.forEach(t),ne=a(we," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),we.forEach(t),Oe=c(g),j(ae.$$.fragment,g),ze=c(g),ye=l(g,"P",{});var ms=o(ye);De=a(ms,"Enfin, voyons \xE0 quoi ressemblent nos m\xE9triques maintenant que l\u2019entra\xEEnement est termin\xE9 :"),ms.forEach(t),ds=c(g),j(Ue.$$.fragment,g),ss=c(g),j(cs.$$.fragment,g),ts=c(g),Pe=l(g,"P",{});var Te=o(Pe);Fe=a(Te,"\xC0 ce stade, vous pouvez utiliser le "),He=l(Te,"EM",{});var ut=o(He);je=a(ut,"widget"),ut.forEach(t),Qs=a(Te," d\u2019inf\xE9rence sur le "),Ie=l(Te,"EM",{});var fs=o(Ie);Js=a(fs,"Hub"),fs.forEach(t),Ys=a(Te," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Je=l(Te,"EM",{});var as=o(Je);Re=a(as,"finetuner"),as.forEach(t),Ns=a(Te," un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),Te.forEach(t),this.h()},h(){_(N,"href","/course/fr/chapter7/2"),_($e,"href","https://huggingface.co/huggingface-course"),_($e,"rel","nofollow")},m(g,oe){i(g,u,oe),s(u,q),i(g,h,oe),k(w,g,oe),i(g,A,oe),k(v,g,oe),i(g,T,oe),i(g,S,oe),s(S,z),s(S,C),s(C,F),s(S,D),i(g,y,oe),k(R,g,oe),i(g,H,oe),i(g,L,oe),s(L,Y),s(L,O),s(O,V),s(L,W),s(L,M),s(M,P),s(L,se),s(L,N),s(N,I),s(L,Q),s(L,ee),s(ee,X),s(L,ie),i(g,re,oe),k(te,g,oe),i(g,me,oe),i(g,le,oe),s(le,de),s(le,ue),s(ue,ve),s(le,be),s(le,$e),s($e,he),s(he,J),s(le,pe),s(le,ce),s(ce,G),s(le,Ae),s(le,ge),s(ge,Qe),s(le,Ee),s(le,fe),s(fe,Me),s(le,ne),i(g,Oe,oe),k(ae,g,oe),i(g,ze,oe),i(g,ye,oe),s(ye,De),i(g,ds,oe),k(Ue,g,oe),i(g,ss,oe),k(cs,g,oe),i(g,ts,oe),i(g,Pe,oe),s(Pe,Fe),s(Pe,He),s(He,je),s(Pe,Qs),s(Pe,Ie),s(Ie,Js),s(Pe,Ys),s(Pe,Je),s(Je,Re),s(Pe,Ns),Ne=!0},i(g){Ne||(b(w.$$.fragment,g),b(v.$$.fragment,g),b(R.$$.fragment,g),b(te.$$.fragment,g),b(ae.$$.fragment,g),b(Ue.$$.fragment,g),b(cs.$$.fragment,g),Ne=!0)},o(g){$(w.$$.fragment,g),$(v.$$.fragment,g),$(R.$$.fragment,g),$(te.$$.fragment,g),$(ae.$$.fragment,g),$(Ue.$$.fragment,g),$(cs.$$.fragment,g),Ne=!1},d(g){g&&t(u),g&&t(h),x(w,g),g&&t(A),x(v,g),g&&t(T),g&&t(S),g&&t(y),x(R,g),g&&t(H),g&&t(L),g&&t(re),x(te,g),g&&t(me),g&&t(le),g&&t(Oe),x(ae,g),g&&t(ze),g&&t(ye),g&&t(ds),x(Ue,g),g&&t(ss),x(cs,g),g&&t(ts),g&&t(Pe)}}}function Ah(Z){let u,q,h,w,A;return{c(){u=r("p"),q=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),h=r("code"),w=n("Seq2SeqTrainer"),A=n(" et devrez d\xE9finir un nouveau nom.")},l(v){u=l(v,"P",{});var T=o(u);q=a(T,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),h=l(T,"CODE",{});var S=o(h);w=a(S,"Seq2SeqTrainer"),S.forEach(t),A=a(T," et devrez d\xE9finir un nouveau nom."),T.forEach(t)},m(v,T){i(v,u,T),s(u,q),s(u,h),s(h,w),s(u,A)},d(v){v&&t(u)}}}function Mh(Z){let u,q,h,w,A;return{c(){u=r("p"),q=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),h=r("code"),w=n("model.fit()"),A=n(" et devrez d\xE9finir un nouveau nom.")},l(v){u=l(v,"P",{});var T=o(u);q=a(T,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),h=l(T,"CODE",{});var S=o(h);w=a(S,"model.fit()"),S.forEach(t),A=a(T," et devrez d\xE9finir un nouveau nom."),T.forEach(t)},m(v,T){i(v,u,T),s(u,q),s(u,h),s(h,w),s(u,A)},d(v){v&&t(u)}}}function uh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,he,J,pe,ce,G,Ae,ge,Qe,Ee,fe,Me,ne,Oe,ae,ze,ye,De,ds,Ue,ss,cs,ts,Pe,Fe,He,je,Qs,Ie,Js,Ys,Je,Re,Ns,Ne,g,oe,js,ke,Be,_e,Ke,Le,ot,we,ns,it,ks,Ye,Zs,Ve,ms,Te,ut,fs,as,Ls,et,Ge,Ft,xs,Os,Us,Ce,Et,rs,Ht,hs,xe,jt,kt,pt,xt,wt,zt,It,_s,zs,vs,Xe,yt,ys,Pt,dt,ws,Ct,We,Bt,Fs,Dt,Rt,Hs,Ps,Se,Cs,ls,st,ct,Tt,Kt,bs,Vt,Gt,tt,$s,Ds,Ts,mt,nt,ft,Ze,f,B,gs,Dn,at,Xt,Is,Wt,ht,Tn,St,Bs,rt,_t,Qt,qe,cn,Rs,mn,Ss,Jt,Yt,Zt,fn,os,At,Mt,Sn,vt;return w=new Ut({}),M=new Ut({}),ue=new U({props:{code:`from torch.utils.data import DataLoader

tokenized_datasets.set_format("torch")
train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)
train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),G=new U({props:{code:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)",highlighted:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"}}),fe=new U({props:{code:`from transformers import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),Fe=new U({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),ke=new U({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),Ge=new U({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "marian-finetuned-kde4-en-to-fr-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),xs=new U({props:{code:"'sgugger/marian-finetuned-kde4-en-to-fr-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/marian-finetuned-kde4-en-to-fr-accelerate&#x27;</span>'}}),rs=new U({props:{code:`output_dir = "marian-finetuned-kde4-en-to-fr-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Xe=new Ut({}),Se=new U({props:{code:`def postprocess(predictions, labels):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # Remplace -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Quelques post-traitements simples
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]
    return decoded_preds, decoded_labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions, labels</span>):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Remplace -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Quelques post-traitements simples</span>
    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
    <span class="hljs-keyword">return</span> decoded_preds, decoded_labels`}}),qe=new U({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
                max_length=128,
            )
        labels = batch["labels"]

        # N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    print(f"epoch {epoch}, BLEU score: {results['score']:.2f}")

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(eval_dataloader):
        <span class="hljs-keyword">with</span> torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch[<span class="hljs-string">&quot;input_ids&quot;</span>],
                attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>],
                max_length=<span class="hljs-number">128</span>,
            )
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

        <span class="hljs-comment"># N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler</span>
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=<span class="hljs-number">1</span>, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>, BLEU score: <span class="hljs-subst">{results[<span class="hljs-string">&#x27;score&#x27;</span>]:<span class="hljs-number">.2</span>f}</span>&quot;</span>)

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),Rs=new U({props:{code:`epoch 0, BLEU score: 53.47
epoch 1, BLEU score: 54.24
epoch 2, BLEU score: 54.44`,highlighted:`epoch <span class="hljs-number">0</span>, BLEU score: <span class="hljs-number">53.47</span>
epoch <span class="hljs-number">1</span>, BLEU score: <span class="hljs-number">54.24</span>
epoch <span class="hljs-number">2</span>, BLEU score: <span class="hljs-number">54.44</span>`}}),{c(){u=r("h2"),q=r("a"),h=r("span"),E(w.$$.fragment),A=d(),v=r("span"),T=n("Une boucle d'entra\xEEnement personnalis\xE9e"),S=d(),z=r("p"),C=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans la "),F=r("a"),D=n("section 2"),y=n(" et dans le "),R=r("a"),H=n("chapitre 3"),L=n("."),Y=d(),O=r("h3"),V=r("a"),W=r("span"),E(M.$$.fragment),P=d(),se=r("span"),N=n("Pr\xE9parer le tout pour l'entra\xEEnement"),I=d(),Q=r("p"),ee=n("Vous avez vu tout cela plusieurs fois maintenant, donc nous allons passer en revue le code assez rapidement. D\u2019abord, nous allons construire le "),X=r("code"),ie=n("DataLoader"),re=n(" \xE0 partir de nos jeux de donn\xE9es, apr\xE8s avoir configur\xE9 les jeux de donn\xE9es au format "),te=r("code"),me=n('"torch"'),le=n(" pour obtenir les tenseurs PyTorch :"),de=d(),E(ue.$$.fragment),ve=d(),be=r("p"),$e=n("Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne poursuivons pas le "),he=r("em"),J=n("finetuning"),pe=n(" pr\xE9c\xE9dent et que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 :"),ce=d(),E(G.$$.fragment),Ae=d(),ge=r("p"),Qe=n("Nous aurons alors besoin d\u2019un optimiseur :"),Ee=d(),E(fe.$$.fragment),Me=d(),ne=r("p"),Oe=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),ae=r("code"),ze=n("accelerator.prepare()"),ye=n(". Rappelez-vous que si vous voulez entra\xEEner sur des TPUs dans un "),De=r("em"),ds=n("notebook"),Ue=n(" de Colab, vous devez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement et ne devrait pas ex\xE9cuter une cellule qui instancie un "),ss=r("code"),cs=n("Accelerator"),ts=n("."),Pe=d(),E(Fe.$$.fragment),He=d(),je=r("p"),Qs=n("Maintenant que nous avons envoy\xE9 notre "),Ie=r("code"),Js=n("train_dataloader"),Ys=n(" \xE0 "),Je=r("code"),Re=n("accelerator.prepare()"),Ns=n(", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le chargeur de donn\xE9es car cette m\xE9thode va changer la longueur du "),Ne=r("code"),g=n("DataLoader"),oe=n(". Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),js=d(),E(ke.$$.fragment),Be=d(),_e=r("p"),Ke=n("Enfin, pour pousser notre mod\xE8le vers le "),Le=r("em"),ot=n("Hub"),we=n(", nous aurons besoin de cr\xE9er un objet "),ns=r("code"),it=n("Repository"),ks=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous au "),Ye=r("em"),Zs=n("Hub"),Ve=n(" si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ms=r("code"),Te=n("repo_name"),ut=n(" par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),fs=r("code"),as=n("get_full_repo_name()"),Ls=n(") :"),et=d(),E(Ge.$$.fragment),Ft=d(),E(xs.$$.fragment),Os=d(),Us=r("p"),Ce=n("Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du d\xE9p\xF4t avec lequel nous travaillons :"),Et=d(),E(rs.$$.fragment),Ht=d(),hs=r("p"),xe=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),jt=r("code"),kt=n("output_dir"),pt=n(" en appelant la m\xE9thode "),xt=r("code"),wt=n("repo.push_to_hub()"),zt=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),It=d(),_s=r("h3"),zs=r("a"),vs=r("span"),E(Xe.$$.fragment),yt=d(),ys=r("span"),Pt=n("Boucle d'entra\xEEnement"),dt=d(),ws=r("p"),Ct=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),We=r("code"),Bt=n("postprocess()"),Fs=n(" qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res que notre objet "),Dt=r("code"),Rt=n("metric"),Hs=n(" attend :"),Ps=d(),E(Se.$$.fragment),Cs=d(),ls=r("p"),st=n("La boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celles de la "),ct=r("a"),Tt=n("section 2"),Kt=n(" et du "),bs=r("a"),Vt=n("chapitre 3"),Gt=n(", avec quelques diff\xE9rences dans la partie \xE9valuation. Donc concentrons-nous sur cela !"),tt=d(),$s=r("p"),Ds=n("La premi\xE8re chose \xE0 noter est que nous utilisons la m\xE9thode "),Ts=r("code"),mt=n("generate()"),nt=n(" pour calculer les pr\xE9dictions. C\u2019est une m\xE9thode sur notre mod\xE8le de base et non pas le mod\xE8le envelopp\xE9 cr\xE9\xE9 dans la m\xE9thode "),ft=r("code"),Ze=n("prepare()"),f=n(". C\u2019est pourquoi nous d\xE9ballons d\u2019abord le mod\xE8le, puis nous appelons cette m\xE9thode."),B=d(),gs=r("p"),Dn=n("La deuxi\xE8me chose est que, comme avec la classification de "),at=r("a"),Xt=r("em"),Is=n("token"),Wt=n(", deux processus peuvent avoir rembourr\xE9s les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes. Ainsi nous utilisons "),ht=r("code"),Tn=n("accelerator.pad_across_processes()"),St=n(" pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Bs=r("code"),rt=n("gather()"),_t=n(". Si nous ne faisons pas cela, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours."),Qt=d(),E(qe.$$.fragment),cn=d(),E(Rs.$$.fragment),mn=d(),Ss=r("p"),Jt=n("Une fois que c\u2019est fait, vous devriez avoir un mod\xE8le qui a des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec "),Yt=r("code"),Zt=n("Seq2SeqTrainer"),fn=n(". Vous pouvez v\xE9rifier celui que nous avons entra\xEEn\xE9 en utilisant ce code sur "),os=r("a"),At=r("em"),Mt=n("huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),Sn=n(". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les mettre en \u0153uvre directement en modifiant le code ci-dessus !"),this.h()},l(m){u=l(m,"H2",{class:!0});var K=o(u);q=l(K,"A",{id:!0,class:!0,href:!0});var Nt=o(q);h=l(Nt,"SPAN",{});var is=o(h);j(w.$$.fragment,is),is.forEach(t),Nt.forEach(t),A=c(K),v=l(K,"SPAN",{});var bt=o(v);T=a(bt,"Une boucle d'entra\xEEnement personnalis\xE9e"),bt.forEach(t),K.forEach(t),S=c(m),z=l(m,"P",{});var Lt=o(z);C=a(Lt,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans la "),F=l(Lt,"A",{href:!0});var hn=o(F);D=a(hn,"section 2"),hn.forEach(t),y=a(Lt," et dans le "),R=l(Lt,"A",{href:!0});var Zn=o(R);H=a(Zn,"chapitre 3"),Zn.forEach(t),L=a(Lt,"."),Lt.forEach(t),Y=c(m),O=l(m,"H3",{class:!0});var _n=o(O);V=l(_n,"A",{id:!0,class:!0,href:!0});var An=o(V);W=l(An,"SPAN",{});var qs=o(W);j(M.$$.fragment,qs),qs.forEach(t),An.forEach(t),P=c(_n),se=l(_n,"SPAN",{});var Mn=o(se);N=a(Mn,"Pr\xE9parer le tout pour l'entra\xEEnement"),Mn.forEach(t),_n.forEach(t),I=c(m),Q=l(m,"P",{});var As=o(Q);ee=a(As,"Vous avez vu tout cela plusieurs fois maintenant, donc nous allons passer en revue le code assez rapidement. D\u2019abord, nous allons construire le "),X=l(As,"CODE",{});var Nn=o(X);ie=a(Nn,"DataLoader"),Nn.forEach(t),re=a(As," \xE0 partir de nos jeux de donn\xE9es, apr\xE8s avoir configur\xE9 les jeux de donn\xE9es au format "),te=l(As,"CODE",{});var Ks=o(te);me=a(Ks,'"torch"'),Ks.forEach(t),le=a(As," pour obtenir les tenseurs PyTorch :"),As.forEach(t),de=c(m),j(ue.$$.fragment,m),ve=c(m),be=l(m,"P",{});var vn=o(be);$e=a(vn,"Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne poursuivons pas le "),he=l(vn,"EM",{});var la=o(he);J=a(la,"finetuning"),la.forEach(t),pe=a(vn," pr\xE9c\xE9dent et que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 :"),vn.forEach(t),ce=c(m),j(G.$$.fragment,m),Ae=c(m),ge=l(m,"P",{});var Or=o(ge);Qe=a(Or,"Nous aurons alors besoin d\u2019un optimiseur :"),Or.forEach(t),Ee=c(m),j(fe.$$.fragment,m),Me=c(m),ne=l(m,"P",{});var en=o(ne);Oe=a(en,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),ae=l(en,"CODE",{});var Da=o(ae);ze=a(Da,"accelerator.prepare()"),Da.forEach(t),ye=a(en,". Rappelez-vous que si vous voulez entra\xEEner sur des TPUs dans un "),De=l(en,"EM",{});var Ln=o(De);ds=a(Ln,"notebook"),Ln.forEach(t),Ue=a(en," de Colab, vous devez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement et ne devrait pas ex\xE9cuter une cellule qui instancie un "),ss=l(en,"CODE",{});var Ta=o(ss);cs=a(Ta,"Accelerator"),Ta.forEach(t),ts=a(en,"."),en.forEach(t),Pe=c(m),j(Fe.$$.fragment,m),He=c(m),je=l(m,"P",{});var Vs=o(je);Qs=a(Vs,"Maintenant que nous avons envoy\xE9 notre "),Ie=l(Vs,"CODE",{});var Sa=o(Ie);Js=a(Sa,"train_dataloader"),Sa.forEach(t),Ys=a(Vs," \xE0 "),Je=l(Vs,"CODE",{});var ea=o(Je);Re=a(ea,"accelerator.prepare()"),ea.forEach(t),Ns=a(Vs,", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le chargeur de donn\xE9es car cette m\xE9thode va changer la longueur du "),Ne=l(Vs,"CODE",{});var Ur=o(Ne);g=a(Ur,"DataLoader"),Ur.forEach(t),oe=a(Vs,". Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),Vs.forEach(t),js=c(m),j(ke.$$.fragment,m),Be=c(m),_e=l(m,"P",{});var Ms=o(_e);Ke=a(Ms,"Enfin, pour pousser notre mod\xE8le vers le "),Le=l(Ms,"EM",{});var On=o(Le);ot=a(On,"Hub"),On.forEach(t),we=a(Ms,", nous aurons besoin de cr\xE9er un objet "),ns=l(Ms,"CODE",{});var Aa=o(ns);it=a(Aa,"Repository"),Aa.forEach(t),ks=a(Ms," dans un dossier de travail. Tout d\u2019abord, connectez-vous au "),Ye=l(Ms,"EM",{});var Un=o(Ye);Zs=a(Un,"Hub"),Un.forEach(t),Ve=a(Ms," si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ms=l(Ms,"CODE",{});var Ma=o(ms);Te=a(Ma,"repo_name"),Ma.forEach(t),ut=a(Ms," par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),fs=l(Ms,"CODE",{});var Ot=o(fs);as=a(Ot,"get_full_repo_name()"),Ot.forEach(t),Ls=a(Ms,") :"),Ms.forEach(t),et=c(m),j(Ge.$$.fragment,m),Ft=c(m),j(xs.$$.fragment,m),Os=c(m),Us=l(m,"P",{});var Fr=o(Us);Ce=a(Fr,"Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du d\xE9p\xF4t avec lequel nous travaillons :"),Fr.forEach(t),Et=c(m),j(rs.$$.fragment,m),Ht=c(m),hs=l(m,"P",{});var sn=o(hs);xe=a(sn,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),jt=l(sn,"CODE",{});var Hr=o(jt);kt=a(Hr,"output_dir"),Hr.forEach(t),pt=a(sn," en appelant la m\xE9thode "),xt=l(sn,"CODE",{});var Ir=o(xt);wt=a(Ir,"repo.push_to_hub()"),Ir.forEach(t),zt=a(sn,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),sn.forEach(t),It=c(m),_s=l(m,"H3",{class:!0});var Fn=o(_s);zs=l(Fn,"A",{id:!0,class:!0,href:!0});var Br=o(zs);vs=l(Br,"SPAN",{});var Rr=o(vs);j(Xe.$$.fragment,Rr),Rr.forEach(t),Br.forEach(t),yt=c(Fn),ys=l(Fn,"SPAN",{});var Na=o(ys);Pt=a(Na,"Boucle d'entra\xEEnement"),Na.forEach(t),Fn.forEach(t),dt=c(m),ws=l(m,"P",{});var $t=o(ws);Ct=a($t,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),We=l($t,"CODE",{});var La=o(We);Bt=a(La,"postprocess()"),La.forEach(t),Fs=a($t," qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res que notre objet "),Dt=l($t,"CODE",{});var bn=o(Dt);Rt=a(bn,"metric"),bn.forEach(t),Hs=a($t," attend :"),$t.forEach(t),Ps=c(m),j(Se.$$.fragment,m),Cs=c(m),ls=l(m,"P",{});var $n=o(ls);st=a($n,"La boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celles de la "),ct=l($n,"A",{href:!0});var tn=o(ct);Tt=a(tn,"section 2"),tn.forEach(t),Kt=a($n," et du "),bs=l($n,"A",{href:!0});var gn=o(bs);Vt=a(gn,"chapitre 3"),gn.forEach(t),Gt=a($n,", avec quelques diff\xE9rences dans la partie \xE9valuation. Donc concentrons-nous sur cela !"),$n.forEach(t),tt=c(m),$s=l(m,"P",{});var nn=o($s);Ds=a(nn,"La premi\xE8re chose \xE0 noter est que nous utilisons la m\xE9thode "),Ts=l(nn,"CODE",{});var Hn=o(Ts);mt=a(Hn,"generate()"),Hn.forEach(t),nt=a(nn," pour calculer les pr\xE9dictions. C\u2019est une m\xE9thode sur notre mod\xE8le de base et non pas le mod\xE8le envelopp\xE9 cr\xE9\xE9 dans la m\xE9thode "),ft=l(nn,"CODE",{});var Kr=o(ft);Ze=a(Kr,"prepare()"),Kr.forEach(t),f=a(nn,". C\u2019est pourquoi nous d\xE9ballons d\u2019abord le mod\xE8le, puis nous appelons cette m\xE9thode."),nn.forEach(t),B=c(m),gs=l(m,"P",{});var gt=o(gs);Dn=a(gt,"La deuxi\xE8me chose est que, comme avec la classification de "),at=l(gt,"A",{href:!0});var Vr=o(at);Xt=l(Vr,"EM",{});var Oa=o(Xt);Is=a(Oa,"token"),Oa.forEach(t),Vr.forEach(t),Wt=a(gt,", deux processus peuvent avoir rembourr\xE9s les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes. Ainsi nous utilisons "),ht=l(gt,"CODE",{});var In=o(ht);Tn=a(In,"accelerator.pad_across_processes()"),In.forEach(t),St=a(gt," pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Bs=l(gt,"CODE",{});var Ua=o(Bs);rt=a(Ua,"gather()"),Ua.forEach(t),_t=a(gt,". Si nous ne faisons pas cela, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours."),gt.forEach(t),Qt=c(m),j(qe.$$.fragment,m),cn=c(m),j(Rs.$$.fragment,m),mn=c(m),Ss=l(m,"P",{});var es=o(Ss);Jt=a(es,"Une fois que c\u2019est fait, vous devriez avoir un mod\xE8le qui a des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec "),Yt=l(es,"CODE",{});var Gr=o(Yt);Zt=a(Gr,"Seq2SeqTrainer"),Gr.forEach(t),fn=a(es,". Vous pouvez v\xE9rifier celui que nous avons entra\xEEn\xE9 en utilisant ce code sur "),os=l(es,"A",{href:!0,rel:!0});var oa=o(os);At=l(oa,"EM",{});var Xr=o(At);Mt=a(Xr,"huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),Xr.forEach(t),oa.forEach(t),Sn=a(es,". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les mettre en \u0153uvre directement en modifiant le code ci-dessus !"),es.forEach(t),this.h()},h(){_(q,"id","une-boucle-dentranement-personnalise"),_(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(q,"href","#une-boucle-dentranement-personnalise"),_(u,"class","relative group"),_(F,"href","/course/fr/chapter7/2"),_(R,"href","/course/fr/chapter3/4"),_(V,"id","prparer-le-tout-pour-lentranement"),_(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(V,"href","#prparer-le-tout-pour-lentranement"),_(O,"class","relative group"),_(zs,"id","boucle-dentranement"),_(zs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(zs,"href","#boucle-dentranement"),_(_s,"class","relative group"),_(ct,"href","/course/fr/chapter7/2"),_(bs,"href","/course/fr/chapter3"),_(at,"href","/course/fr/chapter7/2"),_(os,"href","https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),_(os,"rel","nofollow")},m(m,K){i(m,u,K),s(u,q),s(q,h),k(w,h,null),s(u,A),s(u,v),s(v,T),i(m,S,K),i(m,z,K),s(z,C),s(z,F),s(F,D),s(z,y),s(z,R),s(R,H),s(z,L),i(m,Y,K),i(m,O,K),s(O,V),s(V,W),k(M,W,null),s(O,P),s(O,se),s(se,N),i(m,I,K),i(m,Q,K),s(Q,ee),s(Q,X),s(X,ie),s(Q,re),s(Q,te),s(te,me),s(Q,le),i(m,de,K),k(ue,m,K),i(m,ve,K),i(m,be,K),s(be,$e),s(be,he),s(he,J),s(be,pe),i(m,ce,K),k(G,m,K),i(m,Ae,K),i(m,ge,K),s(ge,Qe),i(m,Ee,K),k(fe,m,K),i(m,Me,K),i(m,ne,K),s(ne,Oe),s(ne,ae),s(ae,ze),s(ne,ye),s(ne,De),s(De,ds),s(ne,Ue),s(ne,ss),s(ss,cs),s(ne,ts),i(m,Pe,K),k(Fe,m,K),i(m,He,K),i(m,je,K),s(je,Qs),s(je,Ie),s(Ie,Js),s(je,Ys),s(je,Je),s(Je,Re),s(je,Ns),s(je,Ne),s(Ne,g),s(je,oe),i(m,js,K),k(ke,m,K),i(m,Be,K),i(m,_e,K),s(_e,Ke),s(_e,Le),s(Le,ot),s(_e,we),s(_e,ns),s(ns,it),s(_e,ks),s(_e,Ye),s(Ye,Zs),s(_e,Ve),s(_e,ms),s(ms,Te),s(_e,ut),s(_e,fs),s(fs,as),s(_e,Ls),i(m,et,K),k(Ge,m,K),i(m,Ft,K),k(xs,m,K),i(m,Os,K),i(m,Us,K),s(Us,Ce),i(m,Et,K),k(rs,m,K),i(m,Ht,K),i(m,hs,K),s(hs,xe),s(hs,jt),s(jt,kt),s(hs,pt),s(hs,xt),s(xt,wt),s(hs,zt),i(m,It,K),i(m,_s,K),s(_s,zs),s(zs,vs),k(Xe,vs,null),s(_s,yt),s(_s,ys),s(ys,Pt),i(m,dt,K),i(m,ws,K),s(ws,Ct),s(ws,We),s(We,Bt),s(ws,Fs),s(ws,Dt),s(Dt,Rt),s(ws,Hs),i(m,Ps,K),k(Se,m,K),i(m,Cs,K),i(m,ls,K),s(ls,st),s(ls,ct),s(ct,Tt),s(ls,Kt),s(ls,bs),s(bs,Vt),s(ls,Gt),i(m,tt,K),i(m,$s,K),s($s,Ds),s($s,Ts),s(Ts,mt),s($s,nt),s($s,ft),s(ft,Ze),s($s,f),i(m,B,K),i(m,gs,K),s(gs,Dn),s(gs,at),s(at,Xt),s(Xt,Is),s(gs,Wt),s(gs,ht),s(ht,Tn),s(gs,St),s(gs,Bs),s(Bs,rt),s(gs,_t),i(m,Qt,K),k(qe,m,K),i(m,cn,K),k(Rs,m,K),i(m,mn,K),i(m,Ss,K),s(Ss,Jt),s(Ss,Yt),s(Yt,Zt),s(Ss,fn),s(Ss,os),s(os,At),s(At,Mt),s(Ss,Sn),vt=!0},i(m){vt||(b(w.$$.fragment,m),b(M.$$.fragment,m),b(ue.$$.fragment,m),b(G.$$.fragment,m),b(fe.$$.fragment,m),b(Fe.$$.fragment,m),b(ke.$$.fragment,m),b(Ge.$$.fragment,m),b(xs.$$.fragment,m),b(rs.$$.fragment,m),b(Xe.$$.fragment,m),b(Se.$$.fragment,m),b(qe.$$.fragment,m),b(Rs.$$.fragment,m),vt=!0)},o(m){$(w.$$.fragment,m),$(M.$$.fragment,m),$(ue.$$.fragment,m),$(G.$$.fragment,m),$(fe.$$.fragment,m),$(Fe.$$.fragment,m),$(ke.$$.fragment,m),$(Ge.$$.fragment,m),$(xs.$$.fragment,m),$(rs.$$.fragment,m),$(Xe.$$.fragment,m),$(Se.$$.fragment,m),$(qe.$$.fragment,m),$(Rs.$$.fragment,m),vt=!1},d(m){m&&t(u),x(w),m&&t(S),m&&t(z),m&&t(Y),m&&t(O),x(M),m&&t(I),m&&t(Q),m&&t(de),x(ue,m),m&&t(ve),m&&t(be),m&&t(ce),x(G,m),m&&t(Ae),m&&t(ge),m&&t(Ee),x(fe,m),m&&t(Me),m&&t(ne),m&&t(Pe),x(Fe,m),m&&t(He),m&&t(je),m&&t(js),x(ke,m),m&&t(Be),m&&t(_e),m&&t(et),x(Ge,m),m&&t(Ft),x(xs,m),m&&t(Os),m&&t(Us),m&&t(Et),x(rs,m),m&&t(Ht),m&&t(hs),m&&t(It),m&&t(_s),x(Xe),m&&t(dt),m&&t(ws),m&&t(Ps),x(Se,m),m&&t(Cs),m&&t(ls),m&&t(tt),m&&t($s),m&&t(B),m&&t(gs),m&&t(Qt),x(qe,m),m&&t(cn),x(Rs,m),m&&t(mn),m&&t(Ss)}}}function Nh(Z){let u,q,h,w,A,v,T,S;return{c(){u=r("p"),q=n("\u270F\uFE0F "),h=r("strong"),w=n("A votre tour !"),A=n(" Que retourne le mod\xE8le sur l\u2019\xE9chantillon avec le mot \xAB "),v=r("em"),T=n("email"),S=n(" \xBB que vous avez identifi\xE9 plus t\xF4t ?")},l(z){u=l(z,"P",{});var C=o(u);q=a(C,"\u270F\uFE0F "),h=l(C,"STRONG",{});var F=o(h);w=a(F,"A votre tour !"),F.forEach(t),A=a(C," Que retourne le mod\xE8le sur l\u2019\xE9chantillon avec le mot \xAB "),v=l(C,"EM",{});var D=o(v);T=a(D,"email"),D.forEach(t),S=a(C," \xBB que vous avez identifi\xE9 plus t\xF4t ?"),C.forEach(t)},m(z,C){i(z,u,C),s(u,q),s(u,h),s(h,w),s(u,A),s(u,v),s(v,T),s(u,S)},d(z){z&&t(u)}}}function Lh(Z){let u,q,h,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,he,J,pe,ce,G,Ae,ge,Qe,Ee,fe,Me,ne,Oe,ae,ze,ye,De,ds,Ue,ss,cs,ts,Pe,Fe,He,je,Qs,Ie,Js,Ys,Je,Re,Ns,Ne,g,oe,js,ke,Be,_e,Ke,Le,ot,we,ns,it,ks,Ye,Zs,Ve,ms,Te,ut,fs,as,Ls,et,Ge,Ft,xs,Os,Us,Ce,Et,rs,Ht,hs,xe,jt,kt,pt,xt,wt,zt,It,_s,zs,vs,Xe,yt,ys,Pt,dt,ws,Ct,We,Bt,Fs,Dt,Rt,Hs,Ps,Se,Cs,ls,st,ct,Tt,Kt,bs,Vt,Gt,tt,$s,Ds,Ts,mt,nt,ft,Ze,f,B,gs,Dn,at,Xt,Is,Wt,ht,Tn,St,Bs,rt,_t,Qt,qe,cn,Rs,mn,Ss,Jt,Yt,Zt,fn,os,At,Mt,Sn,vt,m,K,Nt,is,bt,Lt,hn,Zn,_n,An,qs,Mn,As,Nn,Ks,vn,la,Or,en,Da,Ln,Ta,Vs,Sa,ea,Ur,Ms,On,Aa,Un,Ma,Ot,Fr,sn,Hr,Ir,Fn,Br,Rr,Na,$t,La,bn,$n,tn,gn,nn,Hn,Kr,gt,Vr,Oa,In,Ua,es,Gr,oa,Xr,zu,Cl,yu,Pu,Dl,Cu,Du,Fa,Tu,Su,Io,Ha,Bo,an,Au,Tl,Mu,Nu,Ia,Sl,Lu,Ou,Al,Uu,Fu,Ro,ia,Ko,Bn,Hu,Ml,Iu,Bu,Nl,Ru,Ku,Vo,ua,Vu,Ll,Gu,Xu,Go,Ba,Xo,Rn,Wu,Ol,Qu,Ju,Ul,Yu,Zu,Wo,Kn,ep,Fl,sp,tp,Hl,np,ap,Qo,Wr,rp,Jo,Ra,Yo,pa,lp,Il,op,ip,Zo,Ka,ei,Va,si,rn,up,Bl,pp,dp,Rl,cp,mp,Kl,fp,hp,ti,ln,_p,Vl,vp,bp,Gl,$p,gp,Xl,qp,Ep,ni,Ga,ai,Qr,jp,ri,da,li,ca,oi,Jr,kp,ii,Xa,ui,ma,xp,Wl,wp,zp,pi,qn,En,Yr,Zr,yp,di,sa,fa,Ql,Wa,Pp,Jl,Cp,ci,us,Dp,Yl,Tp,Sp,el,Ap,Mp,Zl,Np,Lp,eo,Op,Up,so,Fp,Hp,to,Ip,Bp,no,Rp,Kp,mi,ps,Vp,Qa,ao,Gp,Xp,ro,Wp,Qp,lo,Jp,Yp,oo,Zp,ed,io,sd,td,uo,nd,ad,po,rd,ld,fi,jn,kn,sl,tl,od,hi,Ja,_i,Ya,vi,ha,id,co,ud,pd,bi,Za,$i,er,gi,nl,dd,qi,sr,Ei,tr,ji,al,cd,ki,nr,xi,ar,wi,xn,wn,rl,ta,_a,mo,rr,md,fo,fd,zi,lr,yi,ll,Vn,hd,or,_d,vd,ir,bd,$d,Pi,on,gd,ho,qd,Ed,ur,jd,kd,_o,xd,wd,Ci,pr,Di,Gn,zd,vo,yd,Pd,ol,Cd,Dd,Ti,dr,Si,il,Td,Ai,ul,Sd,Mi,cr,Ni,mr,Li,Gs,Ad,bo,Md,Nd,fr,$o,Ld,Od,go,Ud,Fd,qo,Hd,Id,hr,Bd,Rd,Oi,_r,Ui,vr,Fi,br,Hi,$r,Ii,pl,Kd,Bi,zn,yn,dl,va,Vd,Eo,Gd,Xd,Ri,na,ba,jo,gr,Wd,cl,ko,Qd,Jd,Ki,Xn,Yd,xo,Zd,ec,wo,sc,tc,Vi,qr,Gi,$a,nc,zo,ac,rc,Xi,ga,lc,yo,oc,ic,Wi,Er,Qi,Pn,Cn,ml,fl,aa,qa,Po,jr,uc,hl,pc,Co,dc,Ji,qt,cc,Do,mc,fc,To,hc,_c,So,vc,bc,Ao,$c,gc,Yi,kr,Zi,xr,eu,un,qc,Mo,Ec,jc,No,kc,xc,Lo,wc,zc,su,wr,tu,zr,nu,_l,yc,au,Ea,ru;h=new _h({props:{fw:Z[0]}}),S=new Ut({});const Dc=[bh,vh],yr=[];function Tc(e,p){return e[0]==="pt"?0:1}y=Tc(Z),R=yr[y]=Dc[y](Z),pe=new wu({props:{id:"1JvfrvZgi6c"}}),Ge=new Ut({}),ys=new Ut({}),Ps=new U({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("kde4", lang1="en", lang2="fr")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;kde4&quot;</span>, lang1=<span class="hljs-string">&quot;en&quot;</span>, lang2=<span class="hljs-string">&quot;fr&quot;</span>)`}}),Ts=new U({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),nt=new U({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 210173
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">210173</span>
    })
})`}}),Bs=new U({props:{code:`split_datasets = raw_datasets["train"].train_test_split(train_size=0.9, seed=20)
split_datasets`,highlighted:`split_datasets = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.9</span>, seed=<span class="hljs-number">20</span>)
split_datasets`}}),_t=new U({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 189155
    })
    test: Dataset({
        features: ['id', 'translation'],
        num_rows: 21018
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">189155</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">21018</span>
    })
})`}}),os=new U({props:{code:'split_datasets["validation"] = split_datasets.pop("test")',highlighted:'split_datasets[<span class="hljs-string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="hljs-string">&quot;test&quot;</span>)'}}),m=new U({props:{code:'split_datasets["train"][1]["translation"]',highlighted:'split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>]'}}),Nt=new U({props:{code:`{'en': 'Default to expanded threads',
 'fr': 'Par d\xE9faut, d\xE9velopper les fils de discussion'}`,highlighted:`{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-string">&#x27;Default to expanded threads&#x27;</span>,
 <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut, d\xE9velopper les fils de discussion&#x27;</span>}`}}),qs=new U({props:{code:`from transformers import pipeline

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span>
translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)
translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)`}}),As=new U({props:{code:"[{'translation_text': 'Par d\xE9faut pour les threads \xE9largis'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut pour les threads \xE9largis&#x27;</span>}]'}}),Ln=new U({props:{code:'split_datasets["train"][172]["translation"]',highlighted:'split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">172</span>][<span class="hljs-string">&quot;translation&quot;</span>]'}}),Vs=new U({props:{code:`{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',
 'fr': "Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct."}`,highlighted:`{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-string">&#x27;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&#x27;</span>,
 <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le module d&#x27;extension d&#x27;importation OFX. Ce fichier n&#x27;a pas un format correct.&quot;</span>}`}}),On=new U({props:{code:`translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)`,highlighted:`translator(
    <span class="hljs-string">&quot;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&quot;</span>
)`}}),Un=new U({props:{code:`[{'translation_text': "Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format."}]`,highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le plugin d&#x27;importateur OFX. Ce fichier n&#x27;est pas le bon format.&quot;</span>}]'}}),$t=new wu({props:{id:"0Oxphw4Q9fo"}}),bn=new Ca({props:{$$slots:{default:[$h]},$$scope:{ctx:Z}}}),Hn=new Ut({}),In=new wu({props:{id:"XAR8jnZZuUs"}}),Ha=new U({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),ia=new Ca({props:{$$slots:{default:[gh]},$$scope:{ctx:Z}}}),Ba=new U({props:{code:`with open(file_path) as f:
    content = f.read()`,highlighted:`<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path) <span class="hljs-keyword">as</span> f:
    content = f.<span class="hljs-built_in">read</span>()`}}),Ra=new U({props:{code:`en_sentence = split_datasets["train"][1]["translation"]["en"]
fr_sentence = split_datasets["train"][1]["translation"]["fr"]

inputs = tokenizer(en_sentence)
with tokenizer.as_target_tokenizer():
    targets = tokenizer(fr_sentence)`,highlighted:`en_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;en&quot;</span>]
fr_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;fr&quot;</span>]

inputs = tokenizer(en_sentence)
<span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
    targets = tokenizer(fr_sentence)`}}),Ka=new U({props:{code:`wrong_targets = tokenizer(fr_sentence)
print(tokenizer.convert_ids_to_tokens(wrong_targets["input_ids"]))
print(tokenizer.convert_ids_to_tokens(targets["input_ids"]))`,highlighted:`wrong_targets = tokenizer(fr_sentence)
<span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(wrong_targets[<span class="hljs-string">&quot;input_ids&quot;</span>]))
<span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(targets[<span class="hljs-string">&quot;input_ids&quot;</span>]))`}}),Va=new U({props:{code:`['\u2581Par', '\u2581d\xE9', 'f', 'aut', ',', '\u2581d\xE9', 've', 'lop', 'per', '\u2581les', '\u2581fil', 's', '\u2581de', '\u2581discussion', '</s>']
['\u2581Par', '\u2581d\xE9faut', ',', '\u2581d\xE9velopper', '\u2581les', '\u2581fils', '\u2581de', '\u2581discussion', '</s>']`,highlighted:`[<span class="hljs-string">&#x27;\u2581Par&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9&#x27;</span>, <span class="hljs-string">&#x27;f&#x27;</span>, <span class="hljs-string">&#x27;aut&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9&#x27;</span>, <span class="hljs-string">&#x27;ve&#x27;</span>, <span class="hljs-string">&#x27;lop&#x27;</span>, <span class="hljs-string">&#x27;per&#x27;</span>, <span class="hljs-string">&#x27;\u2581les&#x27;</span>, <span class="hljs-string">&#x27;\u2581fil&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;\u2581de&#x27;</span>, <span class="hljs-string">&#x27;\u2581discussion&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]
[<span class="hljs-string">&#x27;\u2581Par&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9faut&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9velopper&#x27;</span>, <span class="hljs-string">&#x27;\u2581les&#x27;</span>, <span class="hljs-string">&#x27;\u2581fils&#x27;</span>, <span class="hljs-string">&#x27;\u2581de&#x27;</span>, <span class="hljs-string">&#x27;\u2581discussion&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]`}}),Ga=new U({props:{code:`max_input_length = 128
max_target_length = 128


def preprocess_function(examples):
    inputs = [ex["en"] for ex in examples["translation"]]
    targets = [ex["fr"] for ex in examples["translation"]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)

    # Configurer le tokenizer pour les cibles.
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=True)

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs`,highlighted:`max_input_length = <span class="hljs-number">128</span>
max_target_length = <span class="hljs-number">128</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    inputs = [ex[<span class="hljs-string">&quot;en&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]
    targets = [ex[<span class="hljs-string">&quot;fr&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Configurer le tokenizer pour les cibles.</span>
    <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=<span class="hljs-literal">True</span>)

    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]
    <span class="hljs-keyword">return</span> model_inputs`}}),da=new Ca({props:{$$slots:{default:[qh]},$$scope:{ctx:Z}}}),ca=new Ca({props:{warning:!0,$$slots:{default:[Eh]},$$scope:{ctx:Z}}}),Xa=new U({props:{code:`tokenized_datasets = split_datasets.map(
    preprocess_function,
    batched=True,
    remove_columns=split_datasets["train"].column_names,
)`,highlighted:`tokenized_datasets = split_datasets.<span class="hljs-built_in">map</span>(
    preprocess_function,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=split_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)`}});const Sc=[kh,jh],Pr=[];function Ac(e,p){return e[0]==="pt"?0:1}qn=Ac(Z),En=Pr[qn]=Sc[qn](Z),Wa=new Ut({});const Mc=[zh,wh],Cr=[];function Nc(e,p){return e[0]==="pt"?0:1}jn=Nc(Z),kn=Cr[jn]=Mc[jn](Z),Ja=new U({props:{code:`batch = data_collator([tokenized_datasets["train"][i] for i in range(1, 3)])
batch.keys()`,highlighted:`batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)])
batch.keys()`}}),Ya=new U({props:{code:"dict_keys(['attention_mask', 'input_ids', 'labels', 'decoder_input_ids'])",highlighted:'dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])'}}),Za=new U({props:{code:'batch["labels"]',highlighted:'batch[<span class="hljs-string">&quot;labels&quot;</span>]'}}),er=new U({props:{code:`tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,
          -100,  -100,  -100,  -100,  -100,  -100],
        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,
           550,  7032,  5821,  7907, 12649,     0]])`,highlighted:`tensor([[  <span class="hljs-number">577</span>,  <span class="hljs-number">5891</span>,     <span class="hljs-number">2</span>,  <span class="hljs-number">3184</span>,    <span class="hljs-number">16</span>,  <span class="hljs-number">2542</span>,     <span class="hljs-number">5</span>,  <span class="hljs-number">1710</span>,     <span class="hljs-number">0</span>,  -<span class="hljs-number">100</span>,
          -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>],
        [ <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">9409</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>,   <span class="hljs-number">817</span>,  <span class="hljs-number">3124</span>,   <span class="hljs-number">817</span>,
           <span class="hljs-number">550</span>,  <span class="hljs-number">7032</span>,  <span class="hljs-number">5821</span>,  <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>,     <span class="hljs-number">0</span>]])`}}),sr=new U({props:{code:'batch["decoder_input_ids"]',highlighted:'batch[<span class="hljs-string">&quot;decoder_input_ids&quot;</span>]'}}),tr=new U({props:{code:`tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,
         59513, 59513, 59513, 59513, 59513, 59513],
        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,
           817,   550,  7032,  5821,  7907, 12649]])`,highlighted:`tensor([[<span class="hljs-number">59513</span>,   <span class="hljs-number">577</span>,  <span class="hljs-number">5891</span>,     <span class="hljs-number">2</span>,  <span class="hljs-number">3184</span>,    <span class="hljs-number">16</span>,  <span class="hljs-number">2542</span>,     <span class="hljs-number">5</span>,  <span class="hljs-number">1710</span>,     <span class="hljs-number">0</span>,
         <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>],
        [<span class="hljs-number">59513</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">9409</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>,   <span class="hljs-number">817</span>,  <span class="hljs-number">3124</span>,
           <span class="hljs-number">817</span>,   <span class="hljs-number">550</span>,  <span class="hljs-number">7032</span>,  <span class="hljs-number">5821</span>,  <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>]])`}}),nr=new U({props:{code:`for i in range(1, 3):
    print(tokenized_datasets["train"][i]["labels"])`,highlighted:`<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>):
    <span class="hljs-built_in">print</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i][<span class="hljs-string">&quot;labels&quot;</span>])`}}),ar=new U({props:{code:`[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]
[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]`,highlighted:`[<span class="hljs-number">577</span>, <span class="hljs-number">5891</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3184</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2542</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1710</span>, <span class="hljs-number">0</span>]
[<span class="hljs-number">1211</span>, <span class="hljs-number">3</span>, <span class="hljs-number">49</span>, <span class="hljs-number">9409</span>, <span class="hljs-number">1211</span>, <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>, <span class="hljs-number">817</span>, <span class="hljs-number">3124</span>, <span class="hljs-number">817</span>, <span class="hljs-number">550</span>, <span class="hljs-number">7032</span>, <span class="hljs-number">5821</span>, <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>, <span class="hljs-number">0</span>]`}});const Lc=[Ph,yh],Dr=[];function Oc(e,p){return e[0]==="pt"?0:1}xn=Oc(Z),wn=Dr[xn]=Lc[xn](Z),rr=new Ut({}),lr=new wu({props:{id:"M05L1DhFqcw"}});let lt=Z[0]==="pt"&&ih();pr=new U({props:{code:"!pip install sacrebleu",highlighted:"!pip install sacrebleu"}}),dr=new U({props:{code:`import evaluate

metric = evaluate.load("sacrebleu")`,highlighted:`<span class="hljs-keyword">import</span> evaluate

metric = evaluate.load(<span class="hljs-string">&quot;sacrebleu&quot;</span>)`}}),cr=new U({props:{code:`predictions = [
    "This plugin lets you translate web pages between several languages automatically."
]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [
    <span class="hljs-string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span>
]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),mr=new U({props:{code:`{'score': 46.750469682990165,
 'counts': [11, 6, 4, 3],
 'totals': [12, 11, 10, 9],
 'precisions': [91.67, 54.54, 40.0, 33.33],
 'bp': 0.9200444146293233,
 'sys_len': 12,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">46.750469682990165</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">11</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">12</span>, <span class="hljs-number">11</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">91.67</span>, <span class="hljs-number">54.54</span>, <span class="hljs-number">40.0</span>, <span class="hljs-number">33.33</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.9200444146293233</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">12</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}}),_r=new U({props:{code:`predictions = ["This This This This"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [<span class="hljs-string">&quot;This This This This&quot;</span>]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),vr=new U({props:{code:`{'score': 1.683602693167689,
 'counts': [1, 0, 0, 0],
 'totals': [4, 3, 2, 1],
 'precisions': [25.0, 16.67, 12.5, 12.5],
 'bp': 0.10539922456186433,
 'sys_len': 4,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">1.683602693167689</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">25.0</span>, <span class="hljs-number">16.67</span>, <span class="hljs-number">12.5</span>, <span class="hljs-number">12.5</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.10539922456186433</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">4</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}}),br=new U({props:{code:`predictions = ["This plugin"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [<span class="hljs-string">&quot;This plugin&quot;</span>]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),$r=new U({props:{code:`{'score': 0.0,
 'counts': [2, 1, 0, 0],
 'totals': [2, 1, 0, 0],
 'precisions': [100.0, 100.0, 0.0, 0.0],
 'bp': 0.004086771438464067,
 'sys_len': 2,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">100.0</span>, <span class="hljs-number">100.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.004086771438464067</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">2</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}});const Uc=[Dh,Ch],Tr=[];function Fc(e,p){return e[0]==="tf"?0:1}zn=Fc(Z),yn=Tr[zn]=Uc[zn](Z),gr=new Ut({}),qr=new U({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Er=new U({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}});const Hc=[Sh,Th],Sr=[];function Ic(e,p){return e[0]==="tf"?0:1}Pn=Ic(Z),Cn=Sr[Pn]=Hc[Pn](Z);let Es=Z[0]==="pt"&&uh();return jr=new Ut({}),kr=new U({props:{code:`from transformers import pipeline

# Remplacez ceci par votre propre checkpoint
model_checkpoint = "huggingface-course/marian-finetuned-kde4-en-to-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Remplacez ceci par votre propre checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/marian-finetuned-kde4-en-to-fr&quot;</span>
translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)
translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)`}}),xr=new U({props:{code:"[{'translation_text': 'Par d\xE9faut, d\xE9velopper les fils de discussion'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut, d\xE9velopper les fils de discussion&#x27;</span>}]'}}),wr=new U({props:{code:`translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)`,highlighted:`translator(
    <span class="hljs-string">&quot;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&quot;</span>
)`}}),zr=new U({props:{code:`[{'translation_text': "Impossible d'importer %1 en utilisant le module externe d'importation OFX. Ce fichier n'est pas le bon format."}]`,highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le module externe d&#x27;importation OFX. Ce fichier n&#x27;est pas le bon format.&quot;</span>}]'}}),Ea=new Ca({props:{$$slots:{default:[Nh]},$$scope:{ctx:Z}}}),{c(){u=r("meta"),q=d(),E(h.$$.fragment),w=d(),A=r("h1"),v=r("a"),T=r("span"),E(S.$$.fragment),z=d(),C=r("span"),F=n("Traduction"),D=d(),R.c(),H=d(),L=r("p"),Y=n("Plongeons maintenant dans la traduction. Il s\u2019agit d\u2019une autre "),O=r("a"),V=n("t\xE2che de s\xE9quence \xE0 s\xE9quence"),W=n(", ce qui signifie que c\u2019est un probl\xE8me qui peut \xEAtre formul\xE9 comme le passage d\u2019une s\xE9quence \xE0 une autre. En ce sens, le probl\xE8me est assez proche de la t\xE2che de "),M=r("a"),P=n("r\xE9sum\xE9"),se=n(" et vous pouvez adapter ce que nous allons voir ici \xE0 d\u2019autres probl\xE8mes de s\xE9quence \xE0 s\xE9quence tels que :"),N=d(),I=r("ul"),Q=r("li"),ee=n("Le "),X=r("strong"),ie=n("transfert de style"),re=n(" ? c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui "),te=r("em"),me=n("traduit"),le=n(" des textes \xE9crits dans un certain style vers un autre (par exemple, du formel au d\xE9contract\xE9 ou de l\u2019anglais shakespearien \xE0 l\u2019anglais moderne)."),de=d(),ue=r("li"),ve=n("La "),be=r("strong"),$e=n("g\xE9n\xE9ration de r\xE9ponse \xE0 des questions"),he=n(" c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui g\xE9n\xE8re des r\xE9ponses \xE0 des questions compte tenu d\u2019un contexte."),J=d(),E(pe.$$.fragment),ce=d(),G=r("p"),Ae=n("Si vous disposez d\u2019un corpus de textes suffisamment important en deux langues diff\xE9rentes (ou plus), vous pouvez entra\xEEner un nouveau mod\xE8le de traduction \xE0 partir de z\xE9ro, comme nous le ferons dans la section sur la "),ge=r("a"),Qe=n("mod\xE9lisation causale du langage"),Ee=n(". Il est toutefois plus rapide de "),fe=r("em"),Me=n("finetuner"),ne=n(" un mod\xE8le de traduction existant, qu\u2019il s\u2019agisse d\u2019un mod\xE8le multilingue comme mT5 ou mBART que vous souhaitez adapter \xE0 une paire de langues sp\xE9cifique, ou m\xEAme d\u2019un mod\xE8le sp\xE9cialis\xE9 dans la traduction d\u2019une langue vers une autre que vous souhaitez adapter \xE0 votre corpus sp\xE9cifique."),Oe=d(),ae=r("p"),ze=n("Dans cette section, nous allons "),ye=r("em"),De=n("finetuner"),ds=n(" un mod\xE8le Marian pr\xE9-entra\xEEn\xE9 pour traduire de l\u2019anglais au fran\xE7ais (puisque de nombreux employ\xE9s de Hugging Face parlent ces deux langues) sur le jeu de donn\xE9es "),Ue=r("a"),ss=n("KDE4"),cs=n(" qui est un jeu de donn\xE9es de fichiers localis\xE9s pour les applications "),ts=r("a"),Pe=n("KDE"),Fe=n(". Le mod\xE8le que nous utiliserons a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un large corpus de textes fran\xE7ais et anglais provenant du jeu de donn\xE9es "),He=r("a"),je=n("Opus"),Qs=n(" qui contient en fait le jeu de donn\xE9es KDE4. A noter que m\xEAme si le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons a vu ces donn\xE9es pendant son pr\xE9-entra\xEEnement, nous verrons que nous pouvons obtenir une meilleure version de ce mod\xE8le apr\xE8s un "),Ie=r("em"),Js=n("finetuning"),Ys=n("."),Je=d(),Re=r("p"),Ns=n("Une fois que nous aurons termin\xE9, nous aurons un mod\xE8le capable de faire des pr\xE9dictions comme celle-ci :"),Ne=d(),g=r("iframe"),js=d(),ke=r("iframe"),_e=d(),Ke=r("a"),Le=r("img"),we=d(),ns=r("img"),ks=d(),Ye=r("p"),Zs=n("Comme dans les sections pr\xE9c\xE9dentes, vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),Ve=r("a"),ms=r("em"),Te=n("Hub"),ut=n("."),fs=d(),as=r("h2"),Ls=r("a"),et=r("span"),E(Ge.$$.fragment),Ft=d(),xs=r("span"),Os=n("Pr\xE9paration des donn\xE9es"),Us=d(),Ce=r("p"),Et=n("Pour "),rs=r("em"),Ht=n("finetuner"),hs=n(" ou entra\xEEner un mod\xE8le de traduction \xE0 partir de z\xE9ro, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 cette t\xE2che. Comme mentionn\xE9 pr\xE9c\xE9demment, nous utiliserons le jeu de donn\xE9es "),xe=r("a"),jt=n("KDE4"),kt=n(" dans cette section. Notez que vous pouvez adapter assez facilement le code pour utiliser vos propres donn\xE9es du moment que vous disposez de paires de phrases dans les deux langues que vous voulez traduire. Reportez-vous au "),pt=r("a"),xt=n("chapitre 5"),wt=n(" si vous avez besoin d\u2019un rappel sur la fa\xE7on de charger vos donn\xE9es personnalis\xE9es dans un "),zt=r("code"),It=n("Dataset"),_s=n("."),zs=d(),vs=r("h3"),Xe=r("a"),yt=r("span"),E(ys.$$.fragment),Pt=d(),dt=r("span"),ws=n("Le jeu de donn\xE9es KDE4"),Ct=d(),We=r("p"),Bt=n("Comme d\u2019habitude, nous t\xE9l\xE9chargeons notre jeu de donn\xE9es en utilisant la fonction "),Fs=r("code"),Dt=n("load_dataset()"),Rt=n(" :"),Hs=d(),E(Ps.$$.fragment),Se=d(),Cs=r("p"),ls=n("Si vous souhaitez travailler avec une autre paire de langues, 92 langues sont disponibles au total pour ce jeu de donn\xE9es. Vous pouvez les voir dans la "),st=r("a"),ct=n("carte du jeu de donn\xE9es"),Tt=n("."),Kt=d(),bs=r("img"),Gt=d(),tt=r("p"),$s=n("Jetons un coup d\u2019\u0153il au jeu de donn\xE9es :"),Ds=d(),E(Ts.$$.fragment),mt=d(),E(nt.$$.fragment),ft=d(),Ze=r("p"),f=n("Nous avons 210 173 paires de phrases. Cependant regroup\xE9es dans un seul \xE9chantillon. Nous devrons donc cr\xE9er notre propre jeu de validation. Comme nous l\u2019avons vu dans le "),B=r("a"),gs=n("chapitre 5"),Dn=n(", un "),at=r("code"),Xt=n("Dataset"),Is=n(" poss\xE8de une m\xE9thode "),Wt=r("code"),ht=n("train_test_split()"),Tn=n(" qui peut nous aider. Nous allons fournir une graine pour la reproductibilit\xE9 :"),St=d(),E(Bs.$$.fragment),rt=d(),E(_t.$$.fragment),Qt=d(),qe=r("p"),cn=n("Nous pouvons renommer la cl\xE9 "),Rs=r("code"),mn=n("test"),Ss=n(" en "),Jt=r("code"),Yt=n("validation"),Zt=n(" comme ceci :"),fn=d(),E(os.$$.fragment),At=d(),Mt=r("p"),Sn=n("Examinons maintenant un \xE9l\xE9ment de ce jeu de donn\xE9es :"),vt=d(),E(m.$$.fragment),K=d(),E(Nt.$$.fragment),is=d(),bt=r("p"),Lt=n(`Nous obtenons un dictionnaire contenant deux phrases dans la paire de langues qui nous int\xE9resse.
Une particularit\xE9 de ce jeu de donn\xE9es rempli de termes techniques informatiques est qu\u2019ils sont tous enti\xE8rement traduits en fran\xE7ais. Cependant, les ing\xE9nieurs fran\xE7ais sont souvent paresseux et laissent la plupart des mots sp\xE9cifiques \xE0 l\u2019informatique en anglais lorsqu\u2019ils parlent. Ici, par exemple, le mot \xAB `),hn=r("em"),Zn=n("threads"),_n=n(" \xBB pourrait tr\xE8s bien appara\xEEtre dans une phrase fran\xE7aise, surtout dans une conversation technique. Mais dans ce jeu de donn\xE9es, il a \xE9t\xE9 traduit en \xAB fils de discussion \xBB. Le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons (qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un plus grand corpus de phrases fran\xE7aises et anglaises) prend l\u2019option de laisser le mot tel quel :"),An=d(),E(qs.$$.fragment),Mn=d(),E(As.$$.fragment),Nn=d(),Ks=r("p"),vn=n("Un autre exemple de ce comportement peut \xEAtre observ\xE9 avec le mot  \xAB "),la=r("em"),Or=n("plugin"),en=n(` \xBB qui n\u2019est pas officiellement un mot fran\xE7ais mais que la plupart des francophones comprendront et ne prendront pas la peine de traduire.
Dans le jeu de donn\xE9es KDE4, ce mot a \xE9t\xE9 traduit en fran\xE7ais par le plus officiel \xAB module d\u2019extension \xBB :`),Da=d(),E(Ln.$$.fragment),Ta=d(),E(Vs.$$.fragment),Sa=d(),ea=r("p"),Ur=n("Notre mod\xE8le pr\xE9-entra\xEEn\xE9, lui, s\u2019en tient au mot anglais :"),Ms=d(),E(On.$$.fragment),Aa=d(),E(Un.$$.fragment),Ma=d(),Ot=r("p"),Fr=n("Il sera int\xE9ressant de voir si notre mod\xE8le "),sn=r("em"),Hr=n("finetun\xE9"),Ir=n(" tient compte de ces particularit\xE9s (alerte "),Fn=r("em"),Br=n("spoiler"),Rr=n(" : il le fera)."),Na=d(),E($t.$$.fragment),La=d(),E(bn.$$.fragment),$n=d(),tn=r("h3"),gn=r("a"),nn=r("span"),E(Hn.$$.fragment),Kr=d(),gt=r("span"),Vr=n("Traitement des donn\xE9es"),Oa=d(),E(In.$$.fragment),Ua=d(),es=r("p"),Gr=n("Vous devriez maintenant conna\xEEtre le principe : les textes doivent tous \xEAtre convertis en ensembles d\u2019ID de "),oa=r("em"),Xr=n("tokens"),zu=n(" pour que le mod\xE8le puisse leur donner un sens. Pour cette t\xE2che, nous aurons besoin de tokeniser les entr\xE9es et les cibles. Notre premi\xE8re t\xE2che est de cr\xE9er notre objet "),Cl=r("code"),yu=n("tokenizer"),Pu=n(". Comme indiqu\xE9 pr\xE9c\xE9demment, nous utiliserons un mod\xE8le pr\xE9-entra\xEEn\xE9 Marian English to French. Si vous essayez ce code avec une autre paire de langues, assurez-vous d\u2019adapter le "),Dl=r("em"),Cu=n("checkpoint"),Du=n(" du mod\xE8le. L\u2019organisation "),Fa=r("a"),Tu=n("Helsinki-NLP"),Su=n(" fournit plus de mille mod\xE8les dans plusieurs langues."),Io=d(),E(Ha.$$.fragment),Bo=d(),an=r("p"),Au=n("Vous pouvez remplacer le "),Tl=r("code"),Mu=n("model_checkpoint"),Nu=n(" par un tout autre mod\xE8le disponible sur le "),Ia=r("a"),Sl=r("em"),Lu=n("Hub"),Ou=n(" qui aurait votre pr\xE9f\xE9rence, ou par un dossier en local o\xF9 vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),Al=r("em"),Uu=n("tokenizer"),Fu=n("."),Ro=d(),E(ia.$$.fragment),Ko=d(),Bn=r("p"),Hu=n("La pr\xE9paration de nos donn\xE9es est assez simple. Il y a juste une chose \xE0 retenir : vous traitez les entr\xE9es comme d\u2019habitude, mais pour les cibles, vous devez envelopper le "),Ml=r("em"),Iu=n("tokenizer"),Bu=n(" dans le gestionnaire de contexte "),Nl=r("code"),Ru=n("as_target_tokenizer()"),Ku=n("."),Vo=d(),ua=r("p"),Vu=n("Un gestionnaire de contexte en Python est introduit avec l\u2019instruction "),Ll=r("code"),Gu=n("with"),Xu=n(" et est utile lorsque vous avez deux op\xE9rations li\xE9es \xE0 ex\xE9cuter en paire. L\u2019exemple le plus courant est lorsque vous \xE9crivez ou lisez un fichier, ce qui est souvent fait dans une instruction comme :"),Go=d(),E(Ba.$$.fragment),Xo=d(),Rn=r("p"),Wu=n("Ici, les deux op\xE9rations connexes qui sont ex\xE9cut\xE9es en paire sont les actions d\u2019ouverture et de fermeture du fichier. L\u2019objet correspondant au fichier ouvert "),Ol=r("code"),Qu=n("f"),Ju=n(" n\u2019existe qu\u2019\xE0 l\u2019int\xE9rieur du bloc indent\xE9 sous le "),Ul=r("code"),Yu=n("with"),Zu=n(". L\u2019ouverture se produit avant ce bloc et la fermeture \xE0 la fin du bloc."),Wo=d(),Kn=r("p"),ep=n("Dans le cas pr\xE9sent, le gestionnaire de contexte "),Fl=r("code"),sp=n("as_target_tokenizer()"),tp=n(" va d\xE9finir le "),Hl=r("em"),np=n("tokenizer"),ap=n(" dans la langue de sortie (ici, le fran\xE7ais) avant l\u2019ex\xE9cution du bloc indent\xE9, puis le red\xE9finir dans la langue d\u2019entr\xE9e (ici, l\u2019anglais)."),Qo=d(),Wr=r("p"),rp=n("Ainsi, le pr\xE9traitement d\u2019un \xE9chantillon ressemble \xE0 ceci :"),Jo=d(),E(Ra.$$.fragment),Yo=d(),pa=r("p"),lp=n("Si nous oublions de tokeniser les cibles dans le gestionnaire de contexte, elles seront tokenis\xE9es par le "),Il=r("em"),op=n("tokenizer"),ip=n(" d\u2019entr\xE9e, ce qui dans le cas d\u2019un mod\xE8le Marian, ne va pas du tout bien se passer :"),Zo=d(),E(Ka.$$.fragment),ei=d(),E(Va.$$.fragment),si=d(),rn=r("p"),up=n("Comme on peut le voir, utiliser le "),Bl=r("em"),pp=n("tokenizer"),dp=n(" anglais pour pr\xE9traiter une phrase fran\xE7aise donne un batch de "),Rl=r("em"),cp=n("tokens"),mp=n(" plus important, puisque le "),Kl=r("em"),fp=n("tokenizer"),hp=n(" ne conna\xEEt aucun mot fran\xE7ais (sauf ceux qui apparaissent aussi en anglais, comme \xAB discussion \xBB)."),ti=d(),ln=r("p"),_p=n("Les "),Vl=r("code"),vp=n("inputs"),bp=n(" et les "),Gl=r("code"),$p=n("targets"),gp=n(" sont des dictionnaires avec nos cl\xE9s habituelles (identifiants d\u2019entr\xE9e, masque d\u2019attention, etc.). La derni\xE8re \xE9tape est de d\xE9finir une cl\xE9 "),Xl=r("code"),qp=n('"labels"'),Ep=n(" dans les entr\xE9es. Nous faisons cela dans la fonction de pr\xE9traitement que nous allons appliquer sur les jeux de donn\xE9es :"),ni=d(),E(Ga.$$.fragment),ai=d(),Qr=r("p"),jp=n("Notez que nous avons fix\xE9 des longueurs maximales similaires pour nos entr\xE9es et nos sorties. Comme les textes que nous traitons semblent assez courts, nous utilisons 128."),ri=d(),E(da.$$.fragment),li=d(),E(ca.$$.fragment),oi=d(),Jr=r("p"),kp=n("Nous pouvons maintenant appliquer ce pr\xE9traitement en une seule fois sur toutes les \xE9chantillons de notre jeu de donn\xE9es :"),ii=d(),E(Xa.$$.fragment),ui=d(),ma=r("p"),xp=n("Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, nous sommes pr\xEAts \xE0 "),Wl=r("em"),wp=n("finetuner"),zp=n(" notre mod\xE8le pr\xE9-entra\xEEn\xE9 !"),pi=d(),En.c(),Yr=d(),Zr=r("p"),yp=n("Notez que cette fois-ci, nous utilisons un mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 sur une t\xE2che de traduction et qui peut d\xE9j\xE0 \xEAtre utilis\xE9, donc il n\u2019y a pas d\u2019avertissement concernant les poids manquants ou ceux nouvellement initialis\xE9s."),di=d(),sa=r("h3"),fa=r("a"),Ql=r("span"),E(Wa.$$.fragment),Pp=d(),Jl=r("span"),Cp=n("Assemblage des donn\xE9es"),ci=d(),us=r("p"),Dp=n("Nous aurons besoin d\u2019un assembleur de donn\xE9es pour g\xE9rer le rembourrage pour la mise en batchs dynamique. Ici, nous ne pouvons pas simplement utiliser un "),Yl=r("code"),Tp=n("DataCollatorWithPadding"),Sp=n(" comme dans le "),el=r("a"),Ap=n("chapitre 3"),Mp=n(" car cela ne rembourre que les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention, et "),Zl=r("em"),Np=n("token"),Lp=n(" de type identifiants). Nos \xE9tiquettes doivent \xE9galement \xEAtre rembourr\xE9es \xE0 la longueur maximale rencontr\xE9e dans les \xE9tiquettes. Et, comme mentionn\xE9 pr\xE9c\xE9demment, la valeur de remplissage utilis\xE9e pour remplir les \xE9tiquettes doit \xEAtre "),eo=r("code"),Op=n("-100"),Up=n(" et non le "),so=r("em"),Fp=n("token"),Hp=n(" de "),to=r("em"),Ip=n("padding"),Bp=n(" du "),no=r("em"),Rp=n("tokenizer"),Kp=n(" afin de s\u2019assurer que ces valeurs soient ignor\xE9es dans le calcul de la perte."),mi=d(),ps=r("p"),Vp=n("Tout ceci est r\xE9alis\xE9 par un "),Qa=r("a"),ao=r("code"),Gp=n("DataCollatorForSeq2Seq"),Xp=n(". Comme le "),ro=r("code"),Wp=n("DataCollatorWithPadding"),Qp=n(", il prend le "),lo=r("code"),Jp=n("tokenizer"),Yp=n(" utilis\xE9 pour pr\xE9traiter les entr\xE9es, mais \xE9galement le "),oo=r("code"),Zp=n("model"),ed=n(". C\u2019est parce que cet assembleur de donn\xE9es est \xE9galement responsable de la pr\xE9paration des identifiants d\u2019entr\xE9e du d\xE9codeur, qui sont des versions d\xE9cal\xE9es des \xE9tiquettes avec un "),io=r("em"),sd=n("token"),td=n(" sp\xE9cial au d\xE9but. Comme ce d\xE9calage est effectu\xE9 de mani\xE8re l\xE9g\xE8rement diff\xE9rente selon les architectures, le "),uo=r("code"),nd=n("DataCollatorForSeq2Seq"),ad=n(" a besoin de conna\xEEtre l\u2019objet "),po=r("code"),rd=n("model"),ld=n(" :"),fi=d(),kn.c(),sl=d(),tl=r("p"),od=n("Pour le tester sur quelques \xE9chantillons, nous l\u2019appelons simplement sur une liste d\u2019exemples de notre \xE9chantillon d\u2019entrainement tok\xE9nis\xE9 :"),hi=d(),E(Ja.$$.fragment),_i=d(),E(Ya.$$.fragment),vi=d(),ha=r("p"),id=n("Nous pouvons v\xE9rifier que nos \xE9tiquettes ont \xE9t\xE9 rembourr\xE9es \xE0 la longueur maximale du batch, en utilisant "),co=r("code"),ud=n("-100"),pd=n(" :"),bi=d(),E(Za.$$.fragment),$i=d(),E(er.$$.fragment),gi=d(),nl=r("p"),dd=n("Nous pouvons aussi jeter un coup d\u2019\u0153il aux identifiants d\u2019entr\xE9e du d\xE9codeur, pour voir qu\u2019il s\u2019agit de versions d\xE9cal\xE9es des \xE9tiquettes :"),qi=d(),E(sr.$$.fragment),Ei=d(),E(tr.$$.fragment),ji=d(),al=r("p"),cd=n("Voici les \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),ki=d(),E(nr.$$.fragment),xi=d(),E(ar.$$.fragment),wi=d(),wn.c(),rl=d(),ta=r("h3"),_a=r("a"),mo=r("span"),E(rr.$$.fragment),md=d(),fo=r("span"),fd=n("M\xE9triques"),zi=d(),E(lr.$$.fragment),yi=d(),lt&&lt.c(),ll=d(),Vn=r("p"),hd=n("La m\xE9trique traditionnelle utilis\xE9e pour la traduction est le "),or=r("a"),_d=n("score BLEU"),vd=n(", introduit dans "),ir=r("a"),bd=n("un article de 2002"),$d=n(" par Kishore Papineni et al. Le score BLEU \xE9value dans quelle mesure les traductions sont proches de leurs \xE9tiquettes. Il ne mesure pas l\u2019intelligibilit\xE9 ou l\u2019exactitude grammaticale des r\xE9sultats g\xE9n\xE9r\xE9s par le mod\xE8le, mais utilise des r\xE8gles statistiques pour garantir que tous les mots des r\xE9sultats g\xE9n\xE9r\xE9s apparaissent \xE9galement dans les cibles. En outre, il existe des r\xE8gles qui p\xE9nalisent les r\xE9p\xE9titions des m\xEAmes mots s\u2019ils ne sont pas \xE9galement r\xE9p\xE9t\xE9s dans les cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the the the the the the the \xBB) et les phrases produites qui sont plus courtes que celles des cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the \xBB)."),Pi=d(),on=r("p"),gd=n("L\u2019une des faiblesses de BLEU est qu\u2019il s\u2019attend \xE0 ce que le texte soit d\xE9j\xE0 tokenis\xE9, ce qui rend difficile la comparaison des scores entre les mod\xE8les qui utilisent diff\xE9rents "),ho=r("em"),qd=n("tokenizers"),Ed=n(". Par cons\xE9quent, la mesure la plus couramment utilis\xE9e aujourd\u2019hui pour \xE9valuer les mod\xE8les de traduction est "),ur=r("a"),jd=n("SacreBLEU"),kd=n(" qui rem\xE9die \xE0 cette faiblesse (et \xE0 d\u2019autres) en standardisant l\u2019\xE9tape de tokenisation. Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),_o=r("em"),xd=n("SacreBLEU"),wd=n(" :"),Ci=d(),E(pr.$$.fragment),Di=d(),Gn=r("p"),zd=n("Nous pouvons ensuite charger ce score via "),vo=r("code"),yd=n("evaluate.load()"),Pd=n(" comme nous l\u2019avons fait dans le "),ol=r("a"),Cd=n("chapitre 3"),Dd=n(" :"),Ti=d(),E(dr.$$.fragment),Si=d(),il=r("p"),Td=n("Cette m\xE9trique prend des textes comme entr\xE9es et cibles. Elle est con\xE7ue pour accepter plusieurs cibles acceptables car il y a souvent plusieurs traductions possibles d\u2019une m\xEAme phrase. Le jeu de donn\xE9es que nous utilisons n\u2019en fournit qu\u2019une seule, mais en NLP, il n\u2019est pas rare de trouver des jeux de donn\xE9es ayant plusieurs phrases comme \xE9tiquettes. Ainsi, les pr\xE9dictions doivent \xEAtre une liste de phrases mais les r\xE9f\xE9rences doivent \xEAtre une liste de listes de phrases."),Ai=d(),ul=r("p"),Sd=n("Essayons un exemple :"),Mi=d(),E(cr.$$.fragment),Ni=d(),E(mr.$$.fragment),Li=d(),Gs=r("p"),Ad=n("Cela donne un score BLEU de 46.75, ce qui est plut\xF4t bon. A titre de comparaison, le "),bo=r("em"),Md=n("Transformer"),Nd=n(" original dans l\u2019article "),fr=r("a"),$o=r("em"),Ld=n("Attention Is All You Need"),Od=n(" a obtenu un score BLEU de 41.8 sur une t\xE2che de traduction similaire entre l\u2019anglais et le fran\xE7ais ! (Pour plus d\u2019informations sur les m\xE9triques individuelles, comme "),go=r("code"),Ud=n("counts"),Fd=n(" et "),qo=r("code"),Hd=n("bp"),Id=n(", voir le "),hr=r("a"),Bd=n("d\xE9p\xF4t SacreBLEU"),Rd=n(". D\u2019autre part, si nous essayons avec les deux mauvais types de pr\xE9dictions (r\xE9p\xE9titions ou pr\xE9diction trop courte) qui sortent souvent des mod\xE8les de traduction, nous obtiendrons des scores BLEU plut\xF4t mauvais :"),Oi=d(),E(_r.$$.fragment),Ui=d(),E(vr.$$.fragment),Fi=d(),E(br.$$.fragment),Hi=d(),E($r.$$.fragment),Ii=d(),pl=r("p"),Kd=n("Le score peut aller de 0 \xE0 100. Plus il est \xE9lev\xE9, mieux c\u2019est."),Bi=d(),yn.c(),dl=d(),va=r("p"),Vd=n("Maintenant que c\u2019est fait, nous sommes pr\xEAts \xE0 "),Eo=r("em"),Gd=n("finetuner"),Xd=n(" notre mod\xE8le !"),Ri=d(),na=r("h3"),ba=r("a"),jo=r("span"),E(gr.$$.fragment),Wd=d(),cl=r("span"),ko=r("i"),Qd=n("Finetuner"),Jd=n(" le mod\xE8le"),Ki=d(),Xn=r("p"),Yd=n("La premi\xE8re \xE9tape consiste \xE0 se connecter \xE0 Hugging Face, afin de pouvoir t\xE9l\xE9charger vos r\xE9sultats sur le "),xo=r("em"),Zd=n("Hub"),ec=n(". Il y a une fonction pratique pour vous aider \xE0 le faire dans un "),wo=r("em"),sc=n("notebook"),tc=n(" :"),Vi=d(),E(qr.$$.fragment),Gi=d(),$a=r("p"),nc=n("Cela affichera un "),zo=r("em"),ac=n("widget"),rc=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Xi=d(),ga=r("p"),lc=n("Si vous ne travaillez pas dans un "),yo=r("em"),oc=n("notebook"),ic=n(", tapez simplement la ligne suivante dans votre terminal :"),Wi=d(),E(Er.$$.fragment),Qi=d(),Cn.c(),ml=d(),Es&&Es.c(),fl=d(),aa=r("h3"),qa=r("a"),Po=r("span"),E(jr.$$.fragment),uc=d(),hl=r("span"),pc=n("Utilisation du mod\xE8le "),Co=r("i"),dc=n("finetun\xE9"),Ji=d(),qt=r("p"),cc=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),Do=r("em"),mc=n("finetun\xE9"),fc=n(" sur le "),To=r("em"),hc=n("Hub"),_c=n(" avec le "),So=r("em"),vc=n("widget"),bc=n(" d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Ao=r("code"),$c=n("pipeline"),gc=n(", nous devons juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Yi=d(),E(kr.$$.fragment),Zi=d(),E(xr.$$.fragment),eu=d(),un=r("p"),qc=n("Comme pr\xE9vu, notre mod\xE8le pr\xE9-entra\xEEn\xE9 a adapt\xE9 ses connaissances au corpus sur lequel nous l\u2019avons "),Mo=r("em"),Ec=n("finetun\xE9"),jc=n(". Et au lieu de laisser le mot anglais \xAB "),No=r("em"),kc=n("threads"),xc=n(" \xBB, le mod\xE8le le traduit maintenant par la version fran\xE7aise officielle. Il en va de m\xEAme pour \xAB "),Lo=r("em"),wc=n("plugin"),zc=n(" \xBB :"),su=d(),E(wr.$$.fragment),tu=d(),E(zr.$$.fragment),nu=d(),_l=r("p"),yc=n("Un autre excellent exemple d\u2019adaptation au domaine !"),au=d(),E(Ea.$$.fragment),this.h()},l(e){const p=fh('[data-svelte="svelte-1phssyn"]',document.head);u=l(p,"META",{name:!0,content:!0}),p.forEach(t),q=c(e),j(h.$$.fragment,e),w=c(e),A=l(e,"H1",{class:!0});var Ar=o(A);v=l(Ar,"A",{id:!0,class:!0,href:!0});var vl=o(v);T=l(vl,"SPAN",{});var Oo=o(T);j(S.$$.fragment,Oo),Oo.forEach(t),vl.forEach(t),z=c(Ar),C=l(Ar,"SPAN",{});var Uo=o(C);F=a(Uo,"Traduction"),Uo.forEach(t),Ar.forEach(t),D=c(e),R.l(e),H=c(e),L=l(e,"P",{});var ra=o(L);Y=a(ra,"Plongeons maintenant dans la traduction. Il s\u2019agit d\u2019une autre "),O=l(ra,"A",{href:!0});var Fo=o(O);V=a(Fo,"t\xE2che de s\xE9quence \xE0 s\xE9quence"),Fo.forEach(t),W=a(ra,", ce qui signifie que c\u2019est un probl\xE8me qui peut \xEAtre formul\xE9 comme le passage d\u2019une s\xE9quence \xE0 une autre. En ce sens, le probl\xE8me est assez proche de la t\xE2che de "),M=l(ra,"A",{href:!0});var bl=o(M);P=a(bl,"r\xE9sum\xE9"),bl.forEach(t),se=a(ra," et vous pouvez adapter ce que nous allons voir ici \xE0 d\u2019autres probl\xE8mes de s\xE9quence \xE0 s\xE9quence tels que :"),ra.forEach(t),N=c(e),I=l(e,"UL",{});var ja=o(I);Q=l(ja,"LI",{});var Wn=o(Q);ee=a(Wn,"Le "),X=l(Wn,"STRONG",{});var $l=o(X);ie=a($l,"transfert de style"),$l.forEach(t),re=a(Wn," ? c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui "),te=l(Wn,"EM",{});var gl=o(te);me=a(gl,"traduit"),gl.forEach(t),le=a(Wn," des textes \xE9crits dans un certain style vers un autre (par exemple, du formel au d\xE9contract\xE9 ou de l\u2019anglais shakespearien \xE0 l\u2019anglais moderne)."),Wn.forEach(t),de=c(ja),ue=l(ja,"LI",{});var Mr=o(ue);ve=a(Mr,"La "),be=l(Mr,"STRONG",{});var Bc=o(be);$e=a(Bc,"g\xE9n\xE9ration de r\xE9ponse \xE0 des questions"),Bc.forEach(t),he=a(Mr," c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui g\xE9n\xE8re des r\xE9ponses \xE0 des questions compte tenu d\u2019un contexte."),Mr.forEach(t),ja.forEach(t),J=c(e),j(pe.$$.fragment,e),ce=c(e),G=l(e,"P",{});var ql=o(G);Ae=a(ql,"Si vous disposez d\u2019un corpus de textes suffisamment important en deux langues diff\xE9rentes (ou plus), vous pouvez entra\xEEner un nouveau mod\xE8le de traduction \xE0 partir de z\xE9ro, comme nous le ferons dans la section sur la "),ge=l(ql,"A",{href:!0});var Rc=o(ge);Qe=a(Rc,"mod\xE9lisation causale du langage"),Rc.forEach(t),Ee=a(ql,". Il est toutefois plus rapide de "),fe=l(ql,"EM",{});var Kc=o(fe);Me=a(Kc,"finetuner"),Kc.forEach(t),ne=a(ql," un mod\xE8le de traduction existant, qu\u2019il s\u2019agisse d\u2019un mod\xE8le multilingue comme mT5 ou mBART que vous souhaitez adapter \xE0 une paire de langues sp\xE9cifique, ou m\xEAme d\u2019un mod\xE8le sp\xE9cialis\xE9 dans la traduction d\u2019une langue vers une autre que vous souhaitez adapter \xE0 votre corpus sp\xE9cifique."),ql.forEach(t),Oe=c(e),ae=l(e,"P",{});var pn=o(ae);ze=a(pn,"Dans cette section, nous allons "),ye=l(pn,"EM",{});var Vc=o(ye);De=a(Vc,"finetuner"),Vc.forEach(t),ds=a(pn," un mod\xE8le Marian pr\xE9-entra\xEEn\xE9 pour traduire de l\u2019anglais au fran\xE7ais (puisque de nombreux employ\xE9s de Hugging Face parlent ces deux langues) sur le jeu de donn\xE9es "),Ue=l(pn,"A",{href:!0,rel:!0});var Gc=o(Ue);ss=a(Gc,"KDE4"),Gc.forEach(t),cs=a(pn," qui est un jeu de donn\xE9es de fichiers localis\xE9s pour les applications "),ts=l(pn,"A",{href:!0,rel:!0});var Xc=o(ts);Pe=a(Xc,"KDE"),Xc.forEach(t),Fe=a(pn,". Le mod\xE8le que nous utiliserons a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un large corpus de textes fran\xE7ais et anglais provenant du jeu de donn\xE9es "),He=l(pn,"A",{href:!0,rel:!0});var Wc=o(He);je=a(Wc,"Opus"),Wc.forEach(t),Qs=a(pn," qui contient en fait le jeu de donn\xE9es KDE4. A noter que m\xEAme si le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons a vu ces donn\xE9es pendant son pr\xE9-entra\xEEnement, nous verrons que nous pouvons obtenir une meilleure version de ce mod\xE8le apr\xE8s un "),Ie=l(pn,"EM",{});var Qc=o(Ie);Js=a(Qc,"finetuning"),Qc.forEach(t),Ys=a(pn,"."),pn.forEach(t),Je=c(e),Re=l(e,"P",{});var Jc=o(Re);Ns=a(Jc,"Une fois que nous aurons termin\xE9, nous aurons un mod\xE8le capable de faire des pr\xE9dictions comme celle-ci :"),Jc.forEach(t),Ne=c(e),g=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(g).forEach(t),js=c(e),ke=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(ke).forEach(t),_e=c(e),Ke=l(e,"A",{class:!0,href:!0});var lu=o(Ke);Le=l(lu,"IMG",{class:!0,src:!0,alt:!0}),we=c(lu),ns=l(lu,"IMG",{class:!0,src:!0,alt:!0}),lu.forEach(t),ks=c(e),Ye=l(e,"P",{});var ou=o(Ye);Zs=a(ou,"Comme dans les sections pr\xE9c\xE9dentes, vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),Ve=l(ou,"A",{href:!0,rel:!0});var Yc=o(Ve);ms=l(Yc,"EM",{});var Zc=o(ms);Te=a(Zc,"Hub"),Zc.forEach(t),Yc.forEach(t),ut=a(ou,"."),ou.forEach(t),fs=c(e),as=l(e,"H2",{class:!0});var iu=o(as);Ls=l(iu,"A",{id:!0,class:!0,href:!0});var em=o(Ls);et=l(em,"SPAN",{});var sm=o(et);j(Ge.$$.fragment,sm),sm.forEach(t),em.forEach(t),Ft=c(iu),xs=l(iu,"SPAN",{});var tm=o(xs);Os=a(tm,"Pr\xE9paration des donn\xE9es"),tm.forEach(t),iu.forEach(t),Us=c(e),Ce=l(e,"P",{});var Qn=o(Ce);Et=a(Qn,"Pour "),rs=l(Qn,"EM",{});var nm=o(rs);Ht=a(nm,"finetuner"),nm.forEach(t),hs=a(Qn," ou entra\xEEner un mod\xE8le de traduction \xE0 partir de z\xE9ro, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 cette t\xE2che. Comme mentionn\xE9 pr\xE9c\xE9demment, nous utiliserons le jeu de donn\xE9es "),xe=l(Qn,"A",{href:!0,rel:!0});var am=o(xe);jt=a(am,"KDE4"),am.forEach(t),kt=a(Qn," dans cette section. Notez que vous pouvez adapter assez facilement le code pour utiliser vos propres donn\xE9es du moment que vous disposez de paires de phrases dans les deux langues que vous voulez traduire. Reportez-vous au "),pt=l(Qn,"A",{href:!0});var rm=o(pt);xt=a(rm,"chapitre 5"),rm.forEach(t),wt=a(Qn," si vous avez besoin d\u2019un rappel sur la fa\xE7on de charger vos donn\xE9es personnalis\xE9es dans un "),zt=l(Qn,"CODE",{});var lm=o(zt);It=a(lm,"Dataset"),lm.forEach(t),_s=a(Qn,"."),Qn.forEach(t),zs=c(e),vs=l(e,"H3",{class:!0});var uu=o(vs);Xe=l(uu,"A",{id:!0,class:!0,href:!0});var om=o(Xe);yt=l(om,"SPAN",{});var im=o(yt);j(ys.$$.fragment,im),im.forEach(t),om.forEach(t),Pt=c(uu),dt=l(uu,"SPAN",{});var um=o(dt);ws=a(um,"Le jeu de donn\xE9es KDE4"),um.forEach(t),uu.forEach(t),Ct=c(e),We=l(e,"P",{});var pu=o(We);Bt=a(pu,"Comme d\u2019habitude, nous t\xE9l\xE9chargeons notre jeu de donn\xE9es en utilisant la fonction "),Fs=l(pu,"CODE",{});var pm=o(Fs);Dt=a(pm,"load_dataset()"),pm.forEach(t),Rt=a(pu," :"),pu.forEach(t),Hs=c(e),j(Ps.$$.fragment,e),Se=c(e),Cs=l(e,"P",{});var du=o(Cs);ls=a(du,"Si vous souhaitez travailler avec une autre paire de langues, 92 langues sont disponibles au total pour ce jeu de donn\xE9es. Vous pouvez les voir dans la "),st=l(du,"A",{href:!0,rel:!0});var dm=o(st);ct=a(dm,"carte du jeu de donn\xE9es"),dm.forEach(t),Tt=a(du,"."),du.forEach(t),Kt=c(e),bs=l(e,"IMG",{src:!0,alt:!0,width:!0}),Gt=c(e),tt=l(e,"P",{});var cm=o(tt);$s=a(cm,"Jetons un coup d\u2019\u0153il au jeu de donn\xE9es :"),cm.forEach(t),Ds=c(e),j(Ts.$$.fragment,e),mt=c(e),j(nt.$$.fragment,e),ft=c(e),Ze=l(e,"P",{});var ka=o(Ze);f=a(ka,"Nous avons 210 173 paires de phrases. Cependant regroup\xE9es dans un seul \xE9chantillon. Nous devrons donc cr\xE9er notre propre jeu de validation. Comme nous l\u2019avons vu dans le "),B=l(ka,"A",{href:!0});var mm=o(B);gs=a(mm,"chapitre 5"),mm.forEach(t),Dn=a(ka,", un "),at=l(ka,"CODE",{});var fm=o(at);Xt=a(fm,"Dataset"),fm.forEach(t),Is=a(ka," poss\xE8de une m\xE9thode "),Wt=l(ka,"CODE",{});var hm=o(Wt);ht=a(hm,"train_test_split()"),hm.forEach(t),Tn=a(ka," qui peut nous aider. Nous allons fournir une graine pour la reproductibilit\xE9 :"),ka.forEach(t),St=c(e),j(Bs.$$.fragment,e),rt=c(e),j(_t.$$.fragment,e),Qt=c(e),qe=l(e,"P",{});var El=o(qe);cn=a(El,"Nous pouvons renommer la cl\xE9 "),Rs=l(El,"CODE",{});var _m=o(Rs);mn=a(_m,"test"),_m.forEach(t),Ss=a(El," en "),Jt=l(El,"CODE",{});var vm=o(Jt);Yt=a(vm,"validation"),vm.forEach(t),Zt=a(El," comme ceci :"),El.forEach(t),fn=c(e),j(os.$$.fragment,e),At=c(e),Mt=l(e,"P",{});var bm=o(Mt);Sn=a(bm,"Examinons maintenant un \xE9l\xE9ment de ce jeu de donn\xE9es :"),bm.forEach(t),vt=c(e),j(m.$$.fragment,e),K=c(e),j(Nt.$$.fragment,e),is=c(e),bt=l(e,"P",{});var cu=o(bt);Lt=a(cu,`Nous obtenons un dictionnaire contenant deux phrases dans la paire de langues qui nous int\xE9resse.
Une particularit\xE9 de ce jeu de donn\xE9es rempli de termes techniques informatiques est qu\u2019ils sont tous enti\xE8rement traduits en fran\xE7ais. Cependant, les ing\xE9nieurs fran\xE7ais sont souvent paresseux et laissent la plupart des mots sp\xE9cifiques \xE0 l\u2019informatique en anglais lorsqu\u2019ils parlent. Ici, par exemple, le mot \xAB `),hn=l(cu,"EM",{});var $m=o(hn);Zn=a($m,"threads"),$m.forEach(t),_n=a(cu," \xBB pourrait tr\xE8s bien appara\xEEtre dans une phrase fran\xE7aise, surtout dans une conversation technique. Mais dans ce jeu de donn\xE9es, il a \xE9t\xE9 traduit en \xAB fils de discussion \xBB. Le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons (qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un plus grand corpus de phrases fran\xE7aises et anglaises) prend l\u2019option de laisser le mot tel quel :"),cu.forEach(t),An=c(e),j(qs.$$.fragment,e),Mn=c(e),j(As.$$.fragment,e),Nn=c(e),Ks=l(e,"P",{});var mu=o(Ks);vn=a(mu,"Un autre exemple de ce comportement peut \xEAtre observ\xE9 avec le mot  \xAB "),la=l(mu,"EM",{});var gm=o(la);Or=a(gm,"plugin"),gm.forEach(t),en=a(mu,` \xBB qui n\u2019est pas officiellement un mot fran\xE7ais mais que la plupart des francophones comprendront et ne prendront pas la peine de traduire.
Dans le jeu de donn\xE9es KDE4, ce mot a \xE9t\xE9 traduit en fran\xE7ais par le plus officiel \xAB module d\u2019extension \xBB :`),mu.forEach(t),Da=c(e),j(Ln.$$.fragment,e),Ta=c(e),j(Vs.$$.fragment,e),Sa=c(e),ea=l(e,"P",{});var qm=o(ea);Ur=a(qm,"Notre mod\xE8le pr\xE9-entra\xEEn\xE9, lui, s\u2019en tient au mot anglais :"),qm.forEach(t),Ms=c(e),j(On.$$.fragment,e),Aa=c(e),j(Un.$$.fragment,e),Ma=c(e),Ot=l(e,"P",{});var jl=o(Ot);Fr=a(jl,"Il sera int\xE9ressant de voir si notre mod\xE8le "),sn=l(jl,"EM",{});var Em=o(sn);Hr=a(Em,"finetun\xE9"),Em.forEach(t),Ir=a(jl," tient compte de ces particularit\xE9s (alerte "),Fn=l(jl,"EM",{});var jm=o(Fn);Br=a(jm,"spoiler"),jm.forEach(t),Rr=a(jl," : il le fera)."),jl.forEach(t),Na=c(e),j($t.$$.fragment,e),La=c(e),j(bn.$$.fragment,e),$n=c(e),tn=l(e,"H3",{class:!0});var fu=o(tn);gn=l(fu,"A",{id:!0,class:!0,href:!0});var km=o(gn);nn=l(km,"SPAN",{});var xm=o(nn);j(Hn.$$.fragment,xm),xm.forEach(t),km.forEach(t),Kr=c(fu),gt=l(fu,"SPAN",{});var wm=o(gt);Vr=a(wm,"Traitement des donn\xE9es"),wm.forEach(t),fu.forEach(t),Oa=c(e),j(In.$$.fragment,e),Ua=c(e),es=l(e,"P",{});var Jn=o(es);Gr=a(Jn,"Vous devriez maintenant conna\xEEtre le principe : les textes doivent tous \xEAtre convertis en ensembles d\u2019ID de "),oa=l(Jn,"EM",{});var zm=o(oa);Xr=a(zm,"tokens"),zm.forEach(t),zu=a(Jn," pour que le mod\xE8le puisse leur donner un sens. Pour cette t\xE2che, nous aurons besoin de tokeniser les entr\xE9es et les cibles. Notre premi\xE8re t\xE2che est de cr\xE9er notre objet "),Cl=l(Jn,"CODE",{});var ym=o(Cl);yu=a(ym,"tokenizer"),ym.forEach(t),Pu=a(Jn,". Comme indiqu\xE9 pr\xE9c\xE9demment, nous utiliserons un mod\xE8le pr\xE9-entra\xEEn\xE9 Marian English to French. Si vous essayez ce code avec une autre paire de langues, assurez-vous d\u2019adapter le "),Dl=l(Jn,"EM",{});var Pm=o(Dl);Cu=a(Pm,"checkpoint"),Pm.forEach(t),Du=a(Jn," du mod\xE8le. L\u2019organisation "),Fa=l(Jn,"A",{href:!0,rel:!0});var Cm=o(Fa);Tu=a(Cm,"Helsinki-NLP"),Cm.forEach(t),Su=a(Jn," fournit plus de mille mod\xE8les dans plusieurs langues."),Jn.forEach(t),Io=c(e),j(Ha.$$.fragment,e),Bo=c(e),an=l(e,"P",{});var xa=o(an);Au=a(xa,"Vous pouvez remplacer le "),Tl=l(xa,"CODE",{});var Dm=o(Tl);Mu=a(Dm,"model_checkpoint"),Dm.forEach(t),Nu=a(xa," par un tout autre mod\xE8le disponible sur le "),Ia=l(xa,"A",{href:!0,rel:!0});var Tm=o(Ia);Sl=l(Tm,"EM",{});var Sm=o(Sl);Lu=a(Sm,"Hub"),Sm.forEach(t),Tm.forEach(t),Ou=a(xa," qui aurait votre pr\xE9f\xE9rence, ou par un dossier en local o\xF9 vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),Al=l(xa,"EM",{});var Am=o(Al);Uu=a(Am,"tokenizer"),Am.forEach(t),Fu=a(xa,"."),xa.forEach(t),Ro=c(e),j(ia.$$.fragment,e),Ko=c(e),Bn=l(e,"P",{});var kl=o(Bn);Hu=a(kl,"La pr\xE9paration de nos donn\xE9es est assez simple. Il y a juste une chose \xE0 retenir : vous traitez les entr\xE9es comme d\u2019habitude, mais pour les cibles, vous devez envelopper le "),Ml=l(kl,"EM",{});var Mm=o(Ml);Iu=a(Mm,"tokenizer"),Mm.forEach(t),Bu=a(kl," dans le gestionnaire de contexte "),Nl=l(kl,"CODE",{});var Nm=o(Nl);Ru=a(Nm,"as_target_tokenizer()"),Nm.forEach(t),Ku=a(kl,"."),kl.forEach(t),Vo=c(e),ua=l(e,"P",{});var hu=o(ua);Vu=a(hu,"Un gestionnaire de contexte en Python est introduit avec l\u2019instruction "),Ll=l(hu,"CODE",{});var Lm=o(Ll);Gu=a(Lm,"with"),Lm.forEach(t),Xu=a(hu," et est utile lorsque vous avez deux op\xE9rations li\xE9es \xE0 ex\xE9cuter en paire. L\u2019exemple le plus courant est lorsque vous \xE9crivez ou lisez un fichier, ce qui est souvent fait dans une instruction comme :"),hu.forEach(t),Go=c(e),j(Ba.$$.fragment,e),Xo=c(e),Rn=l(e,"P",{});var xl=o(Rn);Wu=a(xl,"Ici, les deux op\xE9rations connexes qui sont ex\xE9cut\xE9es en paire sont les actions d\u2019ouverture et de fermeture du fichier. L\u2019objet correspondant au fichier ouvert "),Ol=l(xl,"CODE",{});var Om=o(Ol);Qu=a(Om,"f"),Om.forEach(t),Ju=a(xl," n\u2019existe qu\u2019\xE0 l\u2019int\xE9rieur du bloc indent\xE9 sous le "),Ul=l(xl,"CODE",{});var Um=o(Ul);Yu=a(Um,"with"),Um.forEach(t),Zu=a(xl,". L\u2019ouverture se produit avant ce bloc et la fermeture \xE0 la fin du bloc."),xl.forEach(t),Wo=c(e),Kn=l(e,"P",{});var wl=o(Kn);ep=a(wl,"Dans le cas pr\xE9sent, le gestionnaire de contexte "),Fl=l(wl,"CODE",{});var Fm=o(Fl);sp=a(Fm,"as_target_tokenizer()"),Fm.forEach(t),tp=a(wl," va d\xE9finir le "),Hl=l(wl,"EM",{});var Hm=o(Hl);np=a(Hm,"tokenizer"),Hm.forEach(t),ap=a(wl," dans la langue de sortie (ici, le fran\xE7ais) avant l\u2019ex\xE9cution du bloc indent\xE9, puis le red\xE9finir dans la langue d\u2019entr\xE9e (ici, l\u2019anglais)."),wl.forEach(t),Qo=c(e),Wr=l(e,"P",{});var Im=o(Wr);rp=a(Im,"Ainsi, le pr\xE9traitement d\u2019un \xE9chantillon ressemble \xE0 ceci :"),Im.forEach(t),Jo=c(e),j(Ra.$$.fragment,e),Yo=c(e),pa=l(e,"P",{});var _u=o(pa);lp=a(_u,"Si nous oublions de tokeniser les cibles dans le gestionnaire de contexte, elles seront tokenis\xE9es par le "),Il=l(_u,"EM",{});var Bm=o(Il);op=a(Bm,"tokenizer"),Bm.forEach(t),ip=a(_u," d\u2019entr\xE9e, ce qui dans le cas d\u2019un mod\xE8le Marian, ne va pas du tout bien se passer :"),_u.forEach(t),Zo=c(e),j(Ka.$$.fragment,e),ei=c(e),j(Va.$$.fragment,e),si=c(e),rn=l(e,"P",{});var wa=o(rn);up=a(wa,"Comme on peut le voir, utiliser le "),Bl=l(wa,"EM",{});var Rm=o(Bl);pp=a(Rm,"tokenizer"),Rm.forEach(t),dp=a(wa," anglais pour pr\xE9traiter une phrase fran\xE7aise donne un batch de "),Rl=l(wa,"EM",{});var Km=o(Rl);cp=a(Km,"tokens"),Km.forEach(t),mp=a(wa," plus important, puisque le "),Kl=l(wa,"EM",{});var Vm=o(Kl);fp=a(Vm,"tokenizer"),Vm.forEach(t),hp=a(wa," ne conna\xEEt aucun mot fran\xE7ais (sauf ceux qui apparaissent aussi en anglais, comme \xAB discussion \xBB)."),wa.forEach(t),ti=c(e),ln=l(e,"P",{});var za=o(ln);_p=a(za,"Les "),Vl=l(za,"CODE",{});var Gm=o(Vl);vp=a(Gm,"inputs"),Gm.forEach(t),bp=a(za," et les "),Gl=l(za,"CODE",{});var Xm=o(Gl);$p=a(Xm,"targets"),Xm.forEach(t),gp=a(za," sont des dictionnaires avec nos cl\xE9s habituelles (identifiants d\u2019entr\xE9e, masque d\u2019attention, etc.). La derni\xE8re \xE9tape est de d\xE9finir une cl\xE9 "),Xl=l(za,"CODE",{});var Wm=o(Xl);qp=a(Wm,'"labels"'),Wm.forEach(t),Ep=a(za," dans les entr\xE9es. Nous faisons cela dans la fonction de pr\xE9traitement que nous allons appliquer sur les jeux de donn\xE9es :"),za.forEach(t),ni=c(e),j(Ga.$$.fragment,e),ai=c(e),Qr=l(e,"P",{});var Qm=o(Qr);jp=a(Qm,"Notez que nous avons fix\xE9 des longueurs maximales similaires pour nos entr\xE9es et nos sorties. Comme les textes que nous traitons semblent assez courts, nous utilisons 128."),Qm.forEach(t),ri=c(e),j(da.$$.fragment,e),li=c(e),j(ca.$$.fragment,e),oi=c(e),Jr=l(e,"P",{});var Jm=o(Jr);kp=a(Jm,"Nous pouvons maintenant appliquer ce pr\xE9traitement en une seule fois sur toutes les \xE9chantillons de notre jeu de donn\xE9es :"),Jm.forEach(t),ii=c(e),j(Xa.$$.fragment,e),ui=c(e),ma=l(e,"P",{});var vu=o(ma);xp=a(vu,"Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, nous sommes pr\xEAts \xE0 "),Wl=l(vu,"EM",{});var Ym=o(Wl);wp=a(Ym,"finetuner"),Ym.forEach(t),zp=a(vu," notre mod\xE8le pr\xE9-entra\xEEn\xE9 !"),vu.forEach(t),pi=c(e),En.l(e),Yr=c(e),Zr=l(e,"P",{});var Zm=o(Zr);yp=a(Zm,"Notez que cette fois-ci, nous utilisons un mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 sur une t\xE2che de traduction et qui peut d\xE9j\xE0 \xEAtre utilis\xE9, donc il n\u2019y a pas d\u2019avertissement concernant les poids manquants ou ceux nouvellement initialis\xE9s."),Zm.forEach(t),di=c(e),sa=l(e,"H3",{class:!0});var bu=o(sa);fa=l(bu,"A",{id:!0,class:!0,href:!0});var ef=o(fa);Ql=l(ef,"SPAN",{});var sf=o(Ql);j(Wa.$$.fragment,sf),sf.forEach(t),ef.forEach(t),Pp=c(bu),Jl=l(bu,"SPAN",{});var tf=o(Jl);Cp=a(tf,"Assemblage des donn\xE9es"),tf.forEach(t),bu.forEach(t),ci=c(e),us=l(e,"P",{});var Xs=o(us);Dp=a(Xs,"Nous aurons besoin d\u2019un assembleur de donn\xE9es pour g\xE9rer le rembourrage pour la mise en batchs dynamique. Ici, nous ne pouvons pas simplement utiliser un "),Yl=l(Xs,"CODE",{});var nf=o(Yl);Tp=a(nf,"DataCollatorWithPadding"),nf.forEach(t),Sp=a(Xs," comme dans le "),el=l(Xs,"A",{href:!0});var af=o(el);Ap=a(af,"chapitre 3"),af.forEach(t),Mp=a(Xs," car cela ne rembourre que les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention, et "),Zl=l(Xs,"EM",{});var rf=o(Zl);Np=a(rf,"token"),rf.forEach(t),Lp=a(Xs," de type identifiants). Nos \xE9tiquettes doivent \xE9galement \xEAtre rembourr\xE9es \xE0 la longueur maximale rencontr\xE9e dans les \xE9tiquettes. Et, comme mentionn\xE9 pr\xE9c\xE9demment, la valeur de remplissage utilis\xE9e pour remplir les \xE9tiquettes doit \xEAtre "),eo=l(Xs,"CODE",{});var lf=o(eo);Op=a(lf,"-100"),lf.forEach(t),Up=a(Xs," et non le "),so=l(Xs,"EM",{});var of=o(so);Fp=a(of,"token"),of.forEach(t),Hp=a(Xs," de "),to=l(Xs,"EM",{});var uf=o(to);Ip=a(uf,"padding"),uf.forEach(t),Bp=a(Xs," du "),no=l(Xs,"EM",{});var pf=o(no);Rp=a(pf,"tokenizer"),pf.forEach(t),Kp=a(Xs," afin de s\u2019assurer que ces valeurs soient ignor\xE9es dans le calcul de la perte."),Xs.forEach(t),mi=c(e),ps=l(e,"P",{});var Ws=o(ps);Vp=a(Ws,"Tout ceci est r\xE9alis\xE9 par un "),Qa=l(Ws,"A",{href:!0,rel:!0});var df=o(Qa);ao=l(df,"CODE",{});var cf=o(ao);Gp=a(cf,"DataCollatorForSeq2Seq"),cf.forEach(t),df.forEach(t),Xp=a(Ws,". Comme le "),ro=l(Ws,"CODE",{});var mf=o(ro);Wp=a(mf,"DataCollatorWithPadding"),mf.forEach(t),Qp=a(Ws,", il prend le "),lo=l(Ws,"CODE",{});var ff=o(lo);Jp=a(ff,"tokenizer"),ff.forEach(t),Yp=a(Ws," utilis\xE9 pour pr\xE9traiter les entr\xE9es, mais \xE9galement le "),oo=l(Ws,"CODE",{});var hf=o(oo);Zp=a(hf,"model"),hf.forEach(t),ed=a(Ws,". C\u2019est parce que cet assembleur de donn\xE9es est \xE9galement responsable de la pr\xE9paration des identifiants d\u2019entr\xE9e du d\xE9codeur, qui sont des versions d\xE9cal\xE9es des \xE9tiquettes avec un "),io=l(Ws,"EM",{});var _f=o(io);sd=a(_f,"token"),_f.forEach(t),td=a(Ws," sp\xE9cial au d\xE9but. Comme ce d\xE9calage est effectu\xE9 de mani\xE8re l\xE9g\xE8rement diff\xE9rente selon les architectures, le "),uo=l(Ws,"CODE",{});var vf=o(uo);nd=a(vf,"DataCollatorForSeq2Seq"),vf.forEach(t),ad=a(Ws," a besoin de conna\xEEtre l\u2019objet "),po=l(Ws,"CODE",{});var bf=o(po);rd=a(bf,"model"),bf.forEach(t),ld=a(Ws," :"),Ws.forEach(t),fi=c(e),kn.l(e),sl=c(e),tl=l(e,"P",{});var $f=o(tl);od=a($f,"Pour le tester sur quelques \xE9chantillons, nous l\u2019appelons simplement sur une liste d\u2019exemples de notre \xE9chantillon d\u2019entrainement tok\xE9nis\xE9 :"),$f.forEach(t),hi=c(e),j(Ja.$$.fragment,e),_i=c(e),j(Ya.$$.fragment,e),vi=c(e),ha=l(e,"P",{});var $u=o(ha);id=a($u,"Nous pouvons v\xE9rifier que nos \xE9tiquettes ont \xE9t\xE9 rembourr\xE9es \xE0 la longueur maximale du batch, en utilisant "),co=l($u,"CODE",{});var gf=o(co);ud=a(gf,"-100"),gf.forEach(t),pd=a($u," :"),$u.forEach(t),bi=c(e),j(Za.$$.fragment,e),$i=c(e),j(er.$$.fragment,e),gi=c(e),nl=l(e,"P",{});var qf=o(nl);dd=a(qf,"Nous pouvons aussi jeter un coup d\u2019\u0153il aux identifiants d\u2019entr\xE9e du d\xE9codeur, pour voir qu\u2019il s\u2019agit de versions d\xE9cal\xE9es des \xE9tiquettes :"),qf.forEach(t),qi=c(e),j(sr.$$.fragment,e),Ei=c(e),j(tr.$$.fragment,e),ji=c(e),al=l(e,"P",{});var Ef=o(al);cd=a(Ef,"Voici les \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),Ef.forEach(t),ki=c(e),j(nr.$$.fragment,e),xi=c(e),j(ar.$$.fragment,e),wi=c(e),wn.l(e),rl=c(e),ta=l(e,"H3",{class:!0});var gu=o(ta);_a=l(gu,"A",{id:!0,class:!0,href:!0});var jf=o(_a);mo=l(jf,"SPAN",{});var kf=o(mo);j(rr.$$.fragment,kf),kf.forEach(t),jf.forEach(t),md=c(gu),fo=l(gu,"SPAN",{});var xf=o(fo);fd=a(xf,"M\xE9triques"),xf.forEach(t),gu.forEach(t),zi=c(e),j(lr.$$.fragment,e),yi=c(e),lt&&lt.l(e),ll=c(e),Vn=l(e,"P",{});var zl=o(Vn);hd=a(zl,"La m\xE9trique traditionnelle utilis\xE9e pour la traduction est le "),or=l(zl,"A",{href:!0,rel:!0});var wf=o(or);_d=a(wf,"score BLEU"),wf.forEach(t),vd=a(zl,", introduit dans "),ir=l(zl,"A",{href:!0,rel:!0});var zf=o(ir);bd=a(zf,"un article de 2002"),zf.forEach(t),$d=a(zl," par Kishore Papineni et al. Le score BLEU \xE9value dans quelle mesure les traductions sont proches de leurs \xE9tiquettes. Il ne mesure pas l\u2019intelligibilit\xE9 ou l\u2019exactitude grammaticale des r\xE9sultats g\xE9n\xE9r\xE9s par le mod\xE8le, mais utilise des r\xE8gles statistiques pour garantir que tous les mots des r\xE9sultats g\xE9n\xE9r\xE9s apparaissent \xE9galement dans les cibles. En outre, il existe des r\xE8gles qui p\xE9nalisent les r\xE9p\xE9titions des m\xEAmes mots s\u2019ils ne sont pas \xE9galement r\xE9p\xE9t\xE9s dans les cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the the the the the the the \xBB) et les phrases produites qui sont plus courtes que celles des cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the \xBB)."),zl.forEach(t),Pi=c(e),on=l(e,"P",{});var ya=o(on);gd=a(ya,"L\u2019une des faiblesses de BLEU est qu\u2019il s\u2019attend \xE0 ce que le texte soit d\xE9j\xE0 tokenis\xE9, ce qui rend difficile la comparaison des scores entre les mod\xE8les qui utilisent diff\xE9rents "),ho=l(ya,"EM",{});var yf=o(ho);qd=a(yf,"tokenizers"),yf.forEach(t),Ed=a(ya,". Par cons\xE9quent, la mesure la plus couramment utilis\xE9e aujourd\u2019hui pour \xE9valuer les mod\xE8les de traduction est "),ur=l(ya,"A",{href:!0,rel:!0});var Pf=o(ur);jd=a(Pf,"SacreBLEU"),Pf.forEach(t),kd=a(ya," qui rem\xE9die \xE0 cette faiblesse (et \xE0 d\u2019autres) en standardisant l\u2019\xE9tape de tokenisation. Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),_o=l(ya,"EM",{});var Cf=o(_o);xd=a(Cf,"SacreBLEU"),Cf.forEach(t),wd=a(ya," :"),ya.forEach(t),Ci=c(e),j(pr.$$.fragment,e),Di=c(e),Gn=l(e,"P",{});var yl=o(Gn);zd=a(yl,"Nous pouvons ensuite charger ce score via "),vo=l(yl,"CODE",{});var Df=o(vo);yd=a(Df,"evaluate.load()"),Df.forEach(t),Pd=a(yl," comme nous l\u2019avons fait dans le "),ol=l(yl,"A",{href:!0});var Tf=o(ol);Cd=a(Tf,"chapitre 3"),Tf.forEach(t),Dd=a(yl," :"),yl.forEach(t),Ti=c(e),j(dr.$$.fragment,e),Si=c(e),il=l(e,"P",{});var Sf=o(il);Td=a(Sf,"Cette m\xE9trique prend des textes comme entr\xE9es et cibles. Elle est con\xE7ue pour accepter plusieurs cibles acceptables car il y a souvent plusieurs traductions possibles d\u2019une m\xEAme phrase. Le jeu de donn\xE9es que nous utilisons n\u2019en fournit qu\u2019une seule, mais en NLP, il n\u2019est pas rare de trouver des jeux de donn\xE9es ayant plusieurs phrases comme \xE9tiquettes. Ainsi, les pr\xE9dictions doivent \xEAtre une liste de phrases mais les r\xE9f\xE9rences doivent \xEAtre une liste de listes de phrases."),Sf.forEach(t),Ai=c(e),ul=l(e,"P",{});var Af=o(ul);Sd=a(Af,"Essayons un exemple :"),Af.forEach(t),Mi=c(e),j(cr.$$.fragment,e),Ni=c(e),j(mr.$$.fragment,e),Li=c(e),Gs=l(e,"P",{});var dn=o(Gs);Ad=a(dn,"Cela donne un score BLEU de 46.75, ce qui est plut\xF4t bon. A titre de comparaison, le "),bo=l(dn,"EM",{});var Mf=o(bo);Md=a(Mf,"Transformer"),Mf.forEach(t),Nd=a(dn," original dans l\u2019article "),fr=l(dn,"A",{href:!0,rel:!0});var Nf=o(fr);$o=l(Nf,"EM",{});var Lf=o($o);Ld=a(Lf,"Attention Is All You Need"),Lf.forEach(t),Nf.forEach(t),Od=a(dn," a obtenu un score BLEU de 41.8 sur une t\xE2che de traduction similaire entre l\u2019anglais et le fran\xE7ais ! (Pour plus d\u2019informations sur les m\xE9triques individuelles, comme "),go=l(dn,"CODE",{});var Of=o(go);Ud=a(Of,"counts"),Of.forEach(t),Fd=a(dn," et "),qo=l(dn,"CODE",{});var Uf=o(qo);Hd=a(Uf,"bp"),Uf.forEach(t),Id=a(dn,", voir le "),hr=l(dn,"A",{href:!0,rel:!0});var Ff=o(hr);Bd=a(Ff,"d\xE9p\xF4t SacreBLEU"),Ff.forEach(t),Rd=a(dn,". D\u2019autre part, si nous essayons avec les deux mauvais types de pr\xE9dictions (r\xE9p\xE9titions ou pr\xE9diction trop courte) qui sortent souvent des mod\xE8les de traduction, nous obtiendrons des scores BLEU plut\xF4t mauvais :"),dn.forEach(t),Oi=c(e),j(_r.$$.fragment,e),Ui=c(e),j(vr.$$.fragment,e),Fi=c(e),j(br.$$.fragment,e),Hi=c(e),j($r.$$.fragment,e),Ii=c(e),pl=l(e,"P",{});var Hf=o(pl);Kd=a(Hf,"Le score peut aller de 0 \xE0 100. Plus il est \xE9lev\xE9, mieux c\u2019est."),Hf.forEach(t),Bi=c(e),yn.l(e),dl=c(e),va=l(e,"P",{});var qu=o(va);Vd=a(qu,"Maintenant que c\u2019est fait, nous sommes pr\xEAts \xE0 "),Eo=l(qu,"EM",{});var If=o(Eo);Gd=a(If,"finetuner"),If.forEach(t),Xd=a(qu," notre mod\xE8le !"),qu.forEach(t),Ri=c(e),na=l(e,"H3",{class:!0});var Eu=o(na);ba=l(Eu,"A",{id:!0,class:!0,href:!0});var Bf=o(ba);jo=l(Bf,"SPAN",{});var Rf=o(jo);j(gr.$$.fragment,Rf),Rf.forEach(t),Bf.forEach(t),Wd=c(Eu),cl=l(Eu,"SPAN",{});var Pc=o(cl);ko=l(Pc,"I",{});var Kf=o(ko);Qd=a(Kf,"Finetuner"),Kf.forEach(t),Jd=a(Pc," le mod\xE8le"),Pc.forEach(t),Eu.forEach(t),Ki=c(e),Xn=l(e,"P",{});var Pl=o(Xn);Yd=a(Pl,"La premi\xE8re \xE9tape consiste \xE0 se connecter \xE0 Hugging Face, afin de pouvoir t\xE9l\xE9charger vos r\xE9sultats sur le "),xo=l(Pl,"EM",{});var Vf=o(xo);Zd=a(Vf,"Hub"),Vf.forEach(t),ec=a(Pl,". Il y a une fonction pratique pour vous aider \xE0 le faire dans un "),wo=l(Pl,"EM",{});var Gf=o(wo);sc=a(Gf,"notebook"),Gf.forEach(t),tc=a(Pl," :"),Pl.forEach(t),Vi=c(e),j(qr.$$.fragment,e),Gi=c(e),$a=l(e,"P",{});var ju=o($a);nc=a(ju,"Cela affichera un "),zo=l(ju,"EM",{});var Xf=o(zo);ac=a(Xf,"widget"),Xf.forEach(t),rc=a(ju," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),ju.forEach(t),Xi=c(e),ga=l(e,"P",{});var ku=o(ga);lc=a(ku,"Si vous ne travaillez pas dans un "),yo=l(ku,"EM",{});var Wf=o(yo);oc=a(Wf,"notebook"),Wf.forEach(t),ic=a(ku,", tapez simplement la ligne suivante dans votre terminal :"),ku.forEach(t),Wi=c(e),j(Er.$$.fragment,e),Qi=c(e),Cn.l(e),ml=c(e),Es&&Es.l(e),fl=c(e),aa=l(e,"H3",{class:!0});var xu=o(aa);qa=l(xu,"A",{id:!0,class:!0,href:!0});var Qf=o(qa);Po=l(Qf,"SPAN",{});var Jf=o(Po);j(jr.$$.fragment,Jf),Jf.forEach(t),Qf.forEach(t),uc=c(xu),hl=l(xu,"SPAN",{});var Cc=o(hl);pc=a(Cc,"Utilisation du mod\xE8le "),Co=l(Cc,"I",{});var Yf=o(Co);dc=a(Yf,"finetun\xE9"),Yf.forEach(t),Cc.forEach(t),xu.forEach(t),Ji=c(e),qt=l(e,"P",{});var Yn=o(qt);cc=a(Yn,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),Do=l(Yn,"EM",{});var Zf=o(Do);mc=a(Zf,"finetun\xE9"),Zf.forEach(t),fc=a(Yn," sur le "),To=l(Yn,"EM",{});var eh=o(To);hc=a(eh,"Hub"),eh.forEach(t),_c=a(Yn," avec le "),So=l(Yn,"EM",{});var sh=o(So);vc=a(sh,"widget"),sh.forEach(t),bc=a(Yn," d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Ao=l(Yn,"CODE",{});var th=o(Ao);$c=a(th,"pipeline"),th.forEach(t),gc=a(Yn,", nous devons juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Yn.forEach(t),Yi=c(e),j(kr.$$.fragment,e),Zi=c(e),j(xr.$$.fragment,e),eu=c(e),un=l(e,"P",{});var Pa=o(un);qc=a(Pa,"Comme pr\xE9vu, notre mod\xE8le pr\xE9-entra\xEEn\xE9 a adapt\xE9 ses connaissances au corpus sur lequel nous l\u2019avons "),Mo=l(Pa,"EM",{});var nh=o(Mo);Ec=a(nh,"finetun\xE9"),nh.forEach(t),jc=a(Pa,". Et au lieu de laisser le mot anglais \xAB "),No=l(Pa,"EM",{});var ah=o(No);kc=a(ah,"threads"),ah.forEach(t),xc=a(Pa," \xBB, le mod\xE8le le traduit maintenant par la version fran\xE7aise officielle. Il en va de m\xEAme pour \xAB "),Lo=l(Pa,"EM",{});var rh=o(Lo);wc=a(rh,"plugin"),rh.forEach(t),zc=a(Pa," \xBB :"),Pa.forEach(t),su=c(e),j(wr.$$.fragment,e),tu=c(e),j(zr.$$.fragment,e),nu=c(e),_l=l(e,"P",{});var lh=o(_l);yc=a(lh,"Un autre excellent exemple d\u2019adaptation au domaine !"),lh.forEach(t),au=c(e),j(Ea.$$.fragment,e),this.h()},h(){_(u,"name","hf:doc:metadata"),_(u,"content",JSON.stringify(Oh)),_(v,"id","traduction"),_(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(v,"href","#traduction"),_(A,"class","relative group"),_(O,"href","/course/fr/chapitre1/7"),_(M,"href","/course/fr/chapitre7/6"),_(ge,"href","/course/fr/chapitre7/6"),_(Ue,"href","https://huggingface.co/datasets/kde4"),_(Ue,"rel","nofollow"),_(ts,"href","https://apps.kde.org/"),_(ts,"rel","nofollow"),_(He,"href","https://opus.nlpl.eu/"),_(He,"rel","nofollow"),Ho(g.src,oe="https://hf.space/gradioiframe/course-demos/marian-finetuned-kde4-en-to-fr/+")||_(g,"src",oe),_(g,"frameborder","0"),_(g,"height","350"),_(g,"title","Gradio app"),_(g,"class","block dark:hidden container p-0 flex-grow space-iframe"),_(g,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(g,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),Ho(ke.src,Be="https://hf.space/gradioiframe/course-demos/marian-finetuned-kde4-en-to-fr-darkmode/+")||_(ke,"src",Be),_(ke,"frameborder","0"),_(ke,"height","350"),_(ke,"title","Gradio app"),_(ke,"class","hidden dark:block container p-0 flex-grow space-iframe"),_(ke,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(ke,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),_(Le,"class","block dark:hidden lg:w-3/5"),Ho(Le.src,ot="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr.png")||_(Le,"src",ot),_(Le,"alt","One-hot encoded labels for question answering."),_(ns,"class","hidden dark:block lg:w-3/5"),Ho(ns.src,it="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr-dark.png")||_(ns,"src",it),_(ns,"alt","One-hot encoded labels for question answering."),_(Ke,"class","flex justify-center"),_(Ke,"href","/huggingface-course/marian-finetuned-kde4-en-to-fr"),_(Ve,"href","https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr?text=This+plugin+allows+you+to+automatically+translate+web+pages+between+several+languages."),_(Ve,"rel","nofollow"),_(Ls,"id","prparation-des-donnes"),_(Ls,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ls,"href","#prparation-des-donnes"),_(as,"class","relative group"),_(xe,"href","https://huggingface.co/datasets/kde4"),_(xe,"rel","nofollow"),_(pt,"href","/course/fr/chapter5"),_(Xe,"id","le-jeu-de-donnes-kde4"),_(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Xe,"href","#le-jeu-de-donnes-kde4"),_(vs,"class","relative group"),_(st,"href","https://huggingface.co/datasets/kde4"),_(st,"rel","nofollow"),Ho(bs.src,Vt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/language_tags.png")||_(bs,"src",Vt),_(bs,"alt","Language available for the KDE4 dataset."),_(bs,"width","100%"),_(B,"href","/course/fr/chapter5"),_(gn,"id","traitement-des-donnes"),_(gn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(gn,"href","#traitement-des-donnes"),_(tn,"class","relative group"),_(Fa,"href","https://huggingface.co/Helsinki-NLP"),_(Fa,"rel","nofollow"),_(Ia,"href","https://huggingface.co/models"),_(Ia,"rel","nofollow"),_(fa,"id","assemblage-des-donnes"),_(fa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(fa,"href","#assemblage-des-donnes"),_(sa,"class","relative group"),_(el,"href","/course/fr/chapter3"),_(Qa,"href","https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq"),_(Qa,"rel","nofollow"),_(_a,"id","mtriques"),_(_a,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(_a,"href","#mtriques"),_(ta,"class","relative group"),_(or,"href","https://en.wikipedia.org/wiki/BLEU"),_(or,"rel","nofollow"),_(ir,"href","https://aclanthology.org/P02-1040.pdf"),_(ir,"rel","nofollow"),_(ur,"href","https://github.com/mjpost/sacrebleu"),_(ur,"rel","nofollow"),_(ol,"href","/course/fr/chapter3"),_(fr,"href","https://arxiv.org/pdf/1706.03762.pdf"),_(fr,"rel","nofollow"),_(hr,"href","https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74"),_(hr,"rel","nofollow"),_(ba,"id","ifinetuneri-le-modle"),_(ba,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ba,"href","#ifinetuneri-le-modle"),_(na,"class","relative group"),_(qa,"id","utilisation-du-modle-ifinetuni"),_(qa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(qa,"href","#utilisation-du-modle-ifinetuni"),_(aa,"class","relative group")},m(e,p){s(document.head,u),i(e,q,p),k(h,e,p),i(e,w,p),i(e,A,p),s(A,v),s(v,T),k(S,T,null),s(A,z),s(A,C),s(C,F),i(e,D,p),yr[y].m(e,p),i(e,H,p),i(e,L,p),s(L,Y),s(L,O),s(O,V),s(L,W),s(L,M),s(M,P),s(L,se),i(e,N,p),i(e,I,p),s(I,Q),s(Q,ee),s(Q,X),s(X,ie),s(Q,re),s(Q,te),s(te,me),s(Q,le),s(I,de),s(I,ue),s(ue,ve),s(ue,be),s(be,$e),s(ue,he),i(e,J,p),k(pe,e,p),i(e,ce,p),i(e,G,p),s(G,Ae),s(G,ge),s(ge,Qe),s(G,Ee),s(G,fe),s(fe,Me),s(G,ne),i(e,Oe,p),i(e,ae,p),s(ae,ze),s(ae,ye),s(ye,De),s(ae,ds),s(ae,Ue),s(Ue,ss),s(ae,cs),s(ae,ts),s(ts,Pe),s(ae,Fe),s(ae,He),s(He,je),s(ae,Qs),s(ae,Ie),s(Ie,Js),s(ae,Ys),i(e,Je,p),i(e,Re,p),s(Re,Ns),i(e,Ne,p),i(e,g,p),i(e,js,p),i(e,ke,p),i(e,_e,p),i(e,Ke,p),s(Ke,Le),s(Ke,we),s(Ke,ns),i(e,ks,p),i(e,Ye,p),s(Ye,Zs),s(Ye,Ve),s(Ve,ms),s(ms,Te),s(Ye,ut),i(e,fs,p),i(e,as,p),s(as,Ls),s(Ls,et),k(Ge,et,null),s(as,Ft),s(as,xs),s(xs,Os),i(e,Us,p),i(e,Ce,p),s(Ce,Et),s(Ce,rs),s(rs,Ht),s(Ce,hs),s(Ce,xe),s(xe,jt),s(Ce,kt),s(Ce,pt),s(pt,xt),s(Ce,wt),s(Ce,zt),s(zt,It),s(Ce,_s),i(e,zs,p),i(e,vs,p),s(vs,Xe),s(Xe,yt),k(ys,yt,null),s(vs,Pt),s(vs,dt),s(dt,ws),i(e,Ct,p),i(e,We,p),s(We,Bt),s(We,Fs),s(Fs,Dt),s(We,Rt),i(e,Hs,p),k(Ps,e,p),i(e,Se,p),i(e,Cs,p),s(Cs,ls),s(Cs,st),s(st,ct),s(Cs,Tt),i(e,Kt,p),i(e,bs,p),i(e,Gt,p),i(e,tt,p),s(tt,$s),i(e,Ds,p),k(Ts,e,p),i(e,mt,p),k(nt,e,p),i(e,ft,p),i(e,Ze,p),s(Ze,f),s(Ze,B),s(B,gs),s(Ze,Dn),s(Ze,at),s(at,Xt),s(Ze,Is),s(Ze,Wt),s(Wt,ht),s(Ze,Tn),i(e,St,p),k(Bs,e,p),i(e,rt,p),k(_t,e,p),i(e,Qt,p),i(e,qe,p),s(qe,cn),s(qe,Rs),s(Rs,mn),s(qe,Ss),s(qe,Jt),s(Jt,Yt),s(qe,Zt),i(e,fn,p),k(os,e,p),i(e,At,p),i(e,Mt,p),s(Mt,Sn),i(e,vt,p),k(m,e,p),i(e,K,p),k(Nt,e,p),i(e,is,p),i(e,bt,p),s(bt,Lt),s(bt,hn),s(hn,Zn),s(bt,_n),i(e,An,p),k(qs,e,p),i(e,Mn,p),k(As,e,p),i(e,Nn,p),i(e,Ks,p),s(Ks,vn),s(Ks,la),s(la,Or),s(Ks,en),i(e,Da,p),k(Ln,e,p),i(e,Ta,p),k(Vs,e,p),i(e,Sa,p),i(e,ea,p),s(ea,Ur),i(e,Ms,p),k(On,e,p),i(e,Aa,p),k(Un,e,p),i(e,Ma,p),i(e,Ot,p),s(Ot,Fr),s(Ot,sn),s(sn,Hr),s(Ot,Ir),s(Ot,Fn),s(Fn,Br),s(Ot,Rr),i(e,Na,p),k($t,e,p),i(e,La,p),k(bn,e,p),i(e,$n,p),i(e,tn,p),s(tn,gn),s(gn,nn),k(Hn,nn,null),s(tn,Kr),s(tn,gt),s(gt,Vr),i(e,Oa,p),k(In,e,p),i(e,Ua,p),i(e,es,p),s(es,Gr),s(es,oa),s(oa,Xr),s(es,zu),s(es,Cl),s(Cl,yu),s(es,Pu),s(es,Dl),s(Dl,Cu),s(es,Du),s(es,Fa),s(Fa,Tu),s(es,Su),i(e,Io,p),k(Ha,e,p),i(e,Bo,p),i(e,an,p),s(an,Au),s(an,Tl),s(Tl,Mu),s(an,Nu),s(an,Ia),s(Ia,Sl),s(Sl,Lu),s(an,Ou),s(an,Al),s(Al,Uu),s(an,Fu),i(e,Ro,p),k(ia,e,p),i(e,Ko,p),i(e,Bn,p),s(Bn,Hu),s(Bn,Ml),s(Ml,Iu),s(Bn,Bu),s(Bn,Nl),s(Nl,Ru),s(Bn,Ku),i(e,Vo,p),i(e,ua,p),s(ua,Vu),s(ua,Ll),s(Ll,Gu),s(ua,Xu),i(e,Go,p),k(Ba,e,p),i(e,Xo,p),i(e,Rn,p),s(Rn,Wu),s(Rn,Ol),s(Ol,Qu),s(Rn,Ju),s(Rn,Ul),s(Ul,Yu),s(Rn,Zu),i(e,Wo,p),i(e,Kn,p),s(Kn,ep),s(Kn,Fl),s(Fl,sp),s(Kn,tp),s(Kn,Hl),s(Hl,np),s(Kn,ap),i(e,Qo,p),i(e,Wr,p),s(Wr,rp),i(e,Jo,p),k(Ra,e,p),i(e,Yo,p),i(e,pa,p),s(pa,lp),s(pa,Il),s(Il,op),s(pa,ip),i(e,Zo,p),k(Ka,e,p),i(e,ei,p),k(Va,e,p),i(e,si,p),i(e,rn,p),s(rn,up),s(rn,Bl),s(Bl,pp),s(rn,dp),s(rn,Rl),s(Rl,cp),s(rn,mp),s(rn,Kl),s(Kl,fp),s(rn,hp),i(e,ti,p),i(e,ln,p),s(ln,_p),s(ln,Vl),s(Vl,vp),s(ln,bp),s(ln,Gl),s(Gl,$p),s(ln,gp),s(ln,Xl),s(Xl,qp),s(ln,Ep),i(e,ni,p),k(Ga,e,p),i(e,ai,p),i(e,Qr,p),s(Qr,jp),i(e,ri,p),k(da,e,p),i(e,li,p),k(ca,e,p),i(e,oi,p),i(e,Jr,p),s(Jr,kp),i(e,ii,p),k(Xa,e,p),i(e,ui,p),i(e,ma,p),s(ma,xp),s(ma,Wl),s(Wl,wp),s(ma,zp),i(e,pi,p),Pr[qn].m(e,p),i(e,Yr,p),i(e,Zr,p),s(Zr,yp),i(e,di,p),i(e,sa,p),s(sa,fa),s(fa,Ql),k(Wa,Ql,null),s(sa,Pp),s(sa,Jl),s(Jl,Cp),i(e,ci,p),i(e,us,p),s(us,Dp),s(us,Yl),s(Yl,Tp),s(us,Sp),s(us,el),s(el,Ap),s(us,Mp),s(us,Zl),s(Zl,Np),s(us,Lp),s(us,eo),s(eo,Op),s(us,Up),s(us,so),s(so,Fp),s(us,Hp),s(us,to),s(to,Ip),s(us,Bp),s(us,no),s(no,Rp),s(us,Kp),i(e,mi,p),i(e,ps,p),s(ps,Vp),s(ps,Qa),s(Qa,ao),s(ao,Gp),s(ps,Xp),s(ps,ro),s(ro,Wp),s(ps,Qp),s(ps,lo),s(lo,Jp),s(ps,Yp),s(ps,oo),s(oo,Zp),s(ps,ed),s(ps,io),s(io,sd),s(ps,td),s(ps,uo),s(uo,nd),s(ps,ad),s(ps,po),s(po,rd),s(ps,ld),i(e,fi,p),Cr[jn].m(e,p),i(e,sl,p),i(e,tl,p),s(tl,od),i(e,hi,p),k(Ja,e,p),i(e,_i,p),k(Ya,e,p),i(e,vi,p),i(e,ha,p),s(ha,id),s(ha,co),s(co,ud),s(ha,pd),i(e,bi,p),k(Za,e,p),i(e,$i,p),k(er,e,p),i(e,gi,p),i(e,nl,p),s(nl,dd),i(e,qi,p),k(sr,e,p),i(e,Ei,p),k(tr,e,p),i(e,ji,p),i(e,al,p),s(al,cd),i(e,ki,p),k(nr,e,p),i(e,xi,p),k(ar,e,p),i(e,wi,p),Dr[xn].m(e,p),i(e,rl,p),i(e,ta,p),s(ta,_a),s(_a,mo),k(rr,mo,null),s(ta,md),s(ta,fo),s(fo,fd),i(e,zi,p),k(lr,e,p),i(e,yi,p),lt&&lt.m(e,p),i(e,ll,p),i(e,Vn,p),s(Vn,hd),s(Vn,or),s(or,_d),s(Vn,vd),s(Vn,ir),s(ir,bd),s(Vn,$d),i(e,Pi,p),i(e,on,p),s(on,gd),s(on,ho),s(ho,qd),s(on,Ed),s(on,ur),s(ur,jd),s(on,kd),s(on,_o),s(_o,xd),s(on,wd),i(e,Ci,p),k(pr,e,p),i(e,Di,p),i(e,Gn,p),s(Gn,zd),s(Gn,vo),s(vo,yd),s(Gn,Pd),s(Gn,ol),s(ol,Cd),s(Gn,Dd),i(e,Ti,p),k(dr,e,p),i(e,Si,p),i(e,il,p),s(il,Td),i(e,Ai,p),i(e,ul,p),s(ul,Sd),i(e,Mi,p),k(cr,e,p),i(e,Ni,p),k(mr,e,p),i(e,Li,p),i(e,Gs,p),s(Gs,Ad),s(Gs,bo),s(bo,Md),s(Gs,Nd),s(Gs,fr),s(fr,$o),s($o,Ld),s(Gs,Od),s(Gs,go),s(go,Ud),s(Gs,Fd),s(Gs,qo),s(qo,Hd),s(Gs,Id),s(Gs,hr),s(hr,Bd),s(Gs,Rd),i(e,Oi,p),k(_r,e,p),i(e,Ui,p),k(vr,e,p),i(e,Fi,p),k(br,e,p),i(e,Hi,p),k($r,e,p),i(e,Ii,p),i(e,pl,p),s(pl,Kd),i(e,Bi,p),Tr[zn].m(e,p),i(e,dl,p),i(e,va,p),s(va,Vd),s(va,Eo),s(Eo,Gd),s(va,Xd),i(e,Ri,p),i(e,na,p),s(na,ba),s(ba,jo),k(gr,jo,null),s(na,Wd),s(na,cl),s(cl,ko),s(ko,Qd),s(cl,Jd),i(e,Ki,p),i(e,Xn,p),s(Xn,Yd),s(Xn,xo),s(xo,Zd),s(Xn,ec),s(Xn,wo),s(wo,sc),s(Xn,tc),i(e,Vi,p),k(qr,e,p),i(e,Gi,p),i(e,$a,p),s($a,nc),s($a,zo),s(zo,ac),s($a,rc),i(e,Xi,p),i(e,ga,p),s(ga,lc),s(ga,yo),s(yo,oc),s(ga,ic),i(e,Wi,p),k(Er,e,p),i(e,Qi,p),Sr[Pn].m(e,p),i(e,ml,p),Es&&Es.m(e,p),i(e,fl,p),i(e,aa,p),s(aa,qa),s(qa,Po),k(jr,Po,null),s(aa,uc),s(aa,hl),s(hl,pc),s(hl,Co),s(Co,dc),i(e,Ji,p),i(e,qt,p),s(qt,cc),s(qt,Do),s(Do,mc),s(qt,fc),s(qt,To),s(To,hc),s(qt,_c),s(qt,So),s(So,vc),s(qt,bc),s(qt,Ao),s(Ao,$c),s(qt,gc),i(e,Yi,p),k(kr,e,p),i(e,Zi,p),k(xr,e,p),i(e,eu,p),i(e,un,p),s(un,qc),s(un,Mo),s(Mo,Ec),s(un,jc),s(un,No),s(No,kc),s(un,xc),s(un,Lo),s(Lo,wc),s(un,zc),i(e,su,p),k(wr,e,p),i(e,tu,p),k(zr,e,p),i(e,nu,p),i(e,_l,p),s(_l,yc),i(e,au,p),k(Ea,e,p),ru=!0},p(e,[p]){const Ar={};p&1&&(Ar.fw=e[0]),h.$set(Ar);let vl=y;y=Tc(e),y!==vl&&(Lr(),$(yr[vl],1,1,()=>{yr[vl]=null}),Nr(),R=yr[y],R||(R=yr[y]=Dc[y](e),R.c()),b(R,1),R.m(H.parentNode,H));const Oo={};p&2&&(Oo.$$scope={dirty:p,ctx:e}),bn.$set(Oo);const Uo={};p&2&&(Uo.$$scope={dirty:p,ctx:e}),ia.$set(Uo);const ra={};p&2&&(ra.$$scope={dirty:p,ctx:e}),da.$set(ra);const Fo={};p&2&&(Fo.$$scope={dirty:p,ctx:e}),ca.$set(Fo);let bl=qn;qn=Ac(e),qn!==bl&&(Lr(),$(Pr[bl],1,1,()=>{Pr[bl]=null}),Nr(),En=Pr[qn],En||(En=Pr[qn]=Sc[qn](e),En.c()),b(En,1),En.m(Yr.parentNode,Yr));let ja=jn;jn=Nc(e),jn!==ja&&(Lr(),$(Cr[ja],1,1,()=>{Cr[ja]=null}),Nr(),kn=Cr[jn],kn||(kn=Cr[jn]=Mc[jn](e),kn.c()),b(kn,1),kn.m(sl.parentNode,sl));let Wn=xn;xn=Oc(e),xn!==Wn&&(Lr(),$(Dr[Wn],1,1,()=>{Dr[Wn]=null}),Nr(),wn=Dr[xn],wn||(wn=Dr[xn]=Lc[xn](e),wn.c()),b(wn,1),wn.m(rl.parentNode,rl)),e[0]==="pt"?lt||(lt=ih(),lt.c(),lt.m(ll.parentNode,ll)):lt&&(lt.d(1),lt=null);let $l=zn;zn=Fc(e),zn!==$l&&(Lr(),$(Tr[$l],1,1,()=>{Tr[$l]=null}),Nr(),yn=Tr[zn],yn||(yn=Tr[zn]=Uc[zn](e),yn.c()),b(yn,1),yn.m(dl.parentNode,dl));let gl=Pn;Pn=Ic(e),Pn!==gl&&(Lr(),$(Sr[gl],1,1,()=>{Sr[gl]=null}),Nr(),Cn=Sr[Pn],Cn||(Cn=Sr[Pn]=Hc[Pn](e),Cn.c()),b(Cn,1),Cn.m(ml.parentNode,ml)),e[0]==="pt"?Es?p&1&&b(Es,1):(Es=uh(),Es.c(),b(Es,1),Es.m(fl.parentNode,fl)):Es&&(Lr(),$(Es,1,1,()=>{Es=null}),Nr());const Mr={};p&2&&(Mr.$$scope={dirty:p,ctx:e}),Ea.$set(Mr)},i(e){ru||(b(h.$$.fragment,e),b(S.$$.fragment,e),b(R),b(pe.$$.fragment,e),b(Ge.$$.fragment,e),b(ys.$$.fragment,e),b(Ps.$$.fragment,e),b(Ts.$$.fragment,e),b(nt.$$.fragment,e),b(Bs.$$.fragment,e),b(_t.$$.fragment,e),b(os.$$.fragment,e),b(m.$$.fragment,e),b(Nt.$$.fragment,e),b(qs.$$.fragment,e),b(As.$$.fragment,e),b(Ln.$$.fragment,e),b(Vs.$$.fragment,e),b(On.$$.fragment,e),b(Un.$$.fragment,e),b($t.$$.fragment,e),b(bn.$$.fragment,e),b(Hn.$$.fragment,e),b(In.$$.fragment,e),b(Ha.$$.fragment,e),b(ia.$$.fragment,e),b(Ba.$$.fragment,e),b(Ra.$$.fragment,e),b(Ka.$$.fragment,e),b(Va.$$.fragment,e),b(Ga.$$.fragment,e),b(da.$$.fragment,e),b(ca.$$.fragment,e),b(Xa.$$.fragment,e),b(En),b(Wa.$$.fragment,e),b(kn),b(Ja.$$.fragment,e),b(Ya.$$.fragment,e),b(Za.$$.fragment,e),b(er.$$.fragment,e),b(sr.$$.fragment,e),b(tr.$$.fragment,e),b(nr.$$.fragment,e),b(ar.$$.fragment,e),b(wn),b(rr.$$.fragment,e),b(lr.$$.fragment,e),b(pr.$$.fragment,e),b(dr.$$.fragment,e),b(cr.$$.fragment,e),b(mr.$$.fragment,e),b(_r.$$.fragment,e),b(vr.$$.fragment,e),b(br.$$.fragment,e),b($r.$$.fragment,e),b(yn),b(gr.$$.fragment,e),b(qr.$$.fragment,e),b(Er.$$.fragment,e),b(Cn),b(Es),b(jr.$$.fragment,e),b(kr.$$.fragment,e),b(xr.$$.fragment,e),b(wr.$$.fragment,e),b(zr.$$.fragment,e),b(Ea.$$.fragment,e),ru=!0)},o(e){$(h.$$.fragment,e),$(S.$$.fragment,e),$(R),$(pe.$$.fragment,e),$(Ge.$$.fragment,e),$(ys.$$.fragment,e),$(Ps.$$.fragment,e),$(Ts.$$.fragment,e),$(nt.$$.fragment,e),$(Bs.$$.fragment,e),$(_t.$$.fragment,e),$(os.$$.fragment,e),$(m.$$.fragment,e),$(Nt.$$.fragment,e),$(qs.$$.fragment,e),$(As.$$.fragment,e),$(Ln.$$.fragment,e),$(Vs.$$.fragment,e),$(On.$$.fragment,e),$(Un.$$.fragment,e),$($t.$$.fragment,e),$(bn.$$.fragment,e),$(Hn.$$.fragment,e),$(In.$$.fragment,e),$(Ha.$$.fragment,e),$(ia.$$.fragment,e),$(Ba.$$.fragment,e),$(Ra.$$.fragment,e),$(Ka.$$.fragment,e),$(Va.$$.fragment,e),$(Ga.$$.fragment,e),$(da.$$.fragment,e),$(ca.$$.fragment,e),$(Xa.$$.fragment,e),$(En),$(Wa.$$.fragment,e),$(kn),$(Ja.$$.fragment,e),$(Ya.$$.fragment,e),$(Za.$$.fragment,e),$(er.$$.fragment,e),$(sr.$$.fragment,e),$(tr.$$.fragment,e),$(nr.$$.fragment,e),$(ar.$$.fragment,e),$(wn),$(rr.$$.fragment,e),$(lr.$$.fragment,e),$(pr.$$.fragment,e),$(dr.$$.fragment,e),$(cr.$$.fragment,e),$(mr.$$.fragment,e),$(_r.$$.fragment,e),$(vr.$$.fragment,e),$(br.$$.fragment,e),$($r.$$.fragment,e),$(yn),$(gr.$$.fragment,e),$(qr.$$.fragment,e),$(Er.$$.fragment,e),$(Cn),$(Es),$(jr.$$.fragment,e),$(kr.$$.fragment,e),$(xr.$$.fragment,e),$(wr.$$.fragment,e),$(zr.$$.fragment,e),$(Ea.$$.fragment,e),ru=!1},d(e){t(u),e&&t(q),x(h,e),e&&t(w),e&&t(A),x(S),e&&t(D),yr[y].d(e),e&&t(H),e&&t(L),e&&t(N),e&&t(I),e&&t(J),x(pe,e),e&&t(ce),e&&t(G),e&&t(Oe),e&&t(ae),e&&t(Je),e&&t(Re),e&&t(Ne),e&&t(g),e&&t(js),e&&t(ke),e&&t(_e),e&&t(Ke),e&&t(ks),e&&t(Ye),e&&t(fs),e&&t(as),x(Ge),e&&t(Us),e&&t(Ce),e&&t(zs),e&&t(vs),x(ys),e&&t(Ct),e&&t(We),e&&t(Hs),x(Ps,e),e&&t(Se),e&&t(Cs),e&&t(Kt),e&&t(bs),e&&t(Gt),e&&t(tt),e&&t(Ds),x(Ts,e),e&&t(mt),x(nt,e),e&&t(ft),e&&t(Ze),e&&t(St),x(Bs,e),e&&t(rt),x(_t,e),e&&t(Qt),e&&t(qe),e&&t(fn),x(os,e),e&&t(At),e&&t(Mt),e&&t(vt),x(m,e),e&&t(K),x(Nt,e),e&&t(is),e&&t(bt),e&&t(An),x(qs,e),e&&t(Mn),x(As,e),e&&t(Nn),e&&t(Ks),e&&t(Da),x(Ln,e),e&&t(Ta),x(Vs,e),e&&t(Sa),e&&t(ea),e&&t(Ms),x(On,e),e&&t(Aa),x(Un,e),e&&t(Ma),e&&t(Ot),e&&t(Na),x($t,e),e&&t(La),x(bn,e),e&&t($n),e&&t(tn),x(Hn),e&&t(Oa),x(In,e),e&&t(Ua),e&&t(es),e&&t(Io),x(Ha,e),e&&t(Bo),e&&t(an),e&&t(Ro),x(ia,e),e&&t(Ko),e&&t(Bn),e&&t(Vo),e&&t(ua),e&&t(Go),x(Ba,e),e&&t(Xo),e&&t(Rn),e&&t(Wo),e&&t(Kn),e&&t(Qo),e&&t(Wr),e&&t(Jo),x(Ra,e),e&&t(Yo),e&&t(pa),e&&t(Zo),x(Ka,e),e&&t(ei),x(Va,e),e&&t(si),e&&t(rn),e&&t(ti),e&&t(ln),e&&t(ni),x(Ga,e),e&&t(ai),e&&t(Qr),e&&t(ri),x(da,e),e&&t(li),x(ca,e),e&&t(oi),e&&t(Jr),e&&t(ii),x(Xa,e),e&&t(ui),e&&t(ma),e&&t(pi),Pr[qn].d(e),e&&t(Yr),e&&t(Zr),e&&t(di),e&&t(sa),x(Wa),e&&t(ci),e&&t(us),e&&t(mi),e&&t(ps),e&&t(fi),Cr[jn].d(e),e&&t(sl),e&&t(tl),e&&t(hi),x(Ja,e),e&&t(_i),x(Ya,e),e&&t(vi),e&&t(ha),e&&t(bi),x(Za,e),e&&t($i),x(er,e),e&&t(gi),e&&t(nl),e&&t(qi),x(sr,e),e&&t(Ei),x(tr,e),e&&t(ji),e&&t(al),e&&t(ki),x(nr,e),e&&t(xi),x(ar,e),e&&t(wi),Dr[xn].d(e),e&&t(rl),e&&t(ta),x(rr),e&&t(zi),x(lr,e),e&&t(yi),lt&&lt.d(e),e&&t(ll),e&&t(Vn),e&&t(Pi),e&&t(on),e&&t(Ci),x(pr,e),e&&t(Di),e&&t(Gn),e&&t(Ti),x(dr,e),e&&t(Si),e&&t(il),e&&t(Ai),e&&t(ul),e&&t(Mi),x(cr,e),e&&t(Ni),x(mr,e),e&&t(Li),e&&t(Gs),e&&t(Oi),x(_r,e),e&&t(Ui),x(vr,e),e&&t(Fi),x(br,e),e&&t(Hi),x($r,e),e&&t(Ii),e&&t(pl),e&&t(Bi),Tr[zn].d(e),e&&t(dl),e&&t(va),e&&t(Ri),e&&t(na),x(gr),e&&t(Ki),e&&t(Xn),e&&t(Vi),x(qr,e),e&&t(Gi),e&&t($a),e&&t(Xi),e&&t(ga),e&&t(Wi),x(Er,e),e&&t(Qi),Sr[Pn].d(e),e&&t(ml),Es&&Es.d(e),e&&t(fl),e&&t(aa),x(jr),e&&t(Ji),e&&t(qt),e&&t(Yi),x(kr,e),e&&t(Zi),x(xr,e),e&&t(eu),e&&t(un),e&&t(su),x(wr,e),e&&t(tu),x(zr,e),e&&t(nu),e&&t(_l),e&&t(au),x(Ea,e)}}}const Oh={local:"traduction",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-kde4",title:"Le jeu de donn\xE9es KDE4"},{local:"traitement-des-donnes",title:"Traitement des donn\xE9es"}],title:"Pr\xE9paration des donn\xE9es"},{local:"ifinetuneri-le-modle-avec-lapi-trainer",title:"<i>Finetuner</i> le mod\xE8le avec l'API `Trainer`"},{local:"ifinetuneri-du-modle-avec-keras",sections:[{local:"assemblage-des-donnes",title:"Assemblage des donn\xE9es"},{local:"mtriques",title:"M\xE9triques"},{local:"ifinetuneri-le-modle",title:"<i>Finetuner</i> le mod\xE8le"}],title:"<i>Finetuner</i> du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-le-tout-pour-lentranement",title:"Pr\xE9parer le tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"},{local:"utilisation-du-modle-ifinetuni",title:"Utilisation du mod\xE8le <i>finetun\xE9</i>"}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"}],title:"Traduction"};function Uh(Z,u,q){let h="pt";return hh(()=>{const w=new URLSearchParams(window.location.search);q(0,h=w.get("fw")||"pt")}),[h]}class Gh extends dh{constructor(u){super();ch(this,u,Uh,Lh,mh,{})}}export{Gh as default,Oh as metadata};
