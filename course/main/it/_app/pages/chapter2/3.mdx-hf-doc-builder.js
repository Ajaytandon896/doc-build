import{S as Vr,i as Jr,s as Yr,e as d,k as _,w as M,t as s,M as Kr,c as p,d as t,m as h,x as B,a as u,h as n,b as C,G as r,g as c,y as P,o as b,p as Le,q as $,B as T,v as Wr,n as He}from"../../chunks/vendor-hf-doc-builder.js";import{Y as xr}from"../../chunks/Youtube-hf-doc-builder.js";import{I as bo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as N}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Gr}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Xr}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Zr(g){let i,l;return i=new Gr({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section3_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section3_tf.ipynb"}]}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ea(g){let i,l;return i=new Gr({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section3_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section3_pt.ipynb"}]}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function oa(g){let i,l;return i=new xr({props:{id:"d3JVgghSOew"}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ta(g){let i,l;return i=new xr({props:{id:"AhChOFRegn4"}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ia(g){let i,l,o,f,y,E,k,w,q,z,j;return{c(){i=d("p"),l=s("In questa sezione vedremo da vicino come creare e usare un modello. Utilizzeremo la classe "),o=d("code"),f=s("TFAutoModel"),y=s(", utile quando si vuole istanziare qualsiasi modello da un checkpoint."),E=_(),k=d("p"),w=s("La classe "),q=d("code"),z=s("TFAutoModel"),j=s(" e tutti i suoi derivati sono in realt\xE0 semplici involucri dell\u2019ampia variet\xE0 di modelli disponibili nella libreria. Si tratta di un involucro intelligente, in quanto \xE8 in grado di indovinare automaticamente l\u2019architettura del modello appropriata per il checkpoint e successivamente di istanziare un modello con questa architettura.")},l(m){i=p(m,"P",{});var v=u(i);l=n(v,"In questa sezione vedremo da vicino come creare e usare un modello. Utilizzeremo la classe "),o=p(v,"CODE",{});var A=u(o);f=n(A,"TFAutoModel"),A.forEach(t),y=n(v,", utile quando si vuole istanziare qualsiasi modello da un checkpoint."),v.forEach(t),E=h(m),k=p(m,"P",{});var I=u(k);w=n(I,"La classe "),q=p(I,"CODE",{});var S=u(q);z=n(S,"TFAutoModel"),S.forEach(t),j=n(I," e tutti i suoi derivati sono in realt\xE0 semplici involucri dell\u2019ampia variet\xE0 di modelli disponibili nella libreria. Si tratta di un involucro intelligente, in quanto \xE8 in grado di indovinare automaticamente l\u2019architettura del modello appropriata per il checkpoint e successivamente di istanziare un modello con questa architettura."),I.forEach(t)},m(m,v){c(m,i,v),r(i,l),r(i,o),r(o,f),r(i,y),c(m,E,v),c(m,k,v),r(k,w),r(k,q),r(q,z),r(k,j)},d(m){m&&t(i),m&&t(E),m&&t(k)}}}function ra(g){let i,l,o,f,y,E,k,w,q,z,j;return{c(){i=d("p"),l=s("In questa sezione vedremo da vicino come creare e usare un modello. Utilizzeremo la classe "),o=d("code"),f=s("AutoModel"),y=s(", utile quando si vuole istanziare qualsiasi modello da un checkpoint."),E=_(),k=d("p"),w=s("La classe "),q=d("code"),z=s("AutoModel"),j=s(" e tutti i suoi derivati sono in realt\xE0 semplici involucri dell\u2019ampia variet\xE0 di modelli disponibili nella libreria. Si tratta di un involucro intelligente, in quanto \xE8 in grado di indovinare automaticamente l\u2019architettura del modello appropriata per il checkpoint e successivamente di istanziare un modello con questa architettura.")},l(m){i=p(m,"P",{});var v=u(i);l=n(v,"In questa sezione vedremo da vicino come creare e usare un modello. Utilizzeremo la classe "),o=p(v,"CODE",{});var A=u(o);f=n(A,"AutoModel"),A.forEach(t),y=n(v,", utile quando si vuole istanziare qualsiasi modello da un checkpoint."),v.forEach(t),E=h(m),k=p(m,"P",{});var I=u(k);w=n(I,"La classe "),q=p(I,"CODE",{});var S=u(q);z=n(S,"AutoModel"),S.forEach(t),j=n(I," e tutti i suoi derivati sono in realt\xE0 semplici involucri dell\u2019ampia variet\xE0 di modelli disponibili nella libreria. Si tratta di un involucro intelligente, in quanto \xE8 in grado di indovinare automaticamente l\u2019architettura del modello appropriata per il checkpoint e successivamente di istanziare un modello con questa architettura."),I.forEach(t)},m(m,v){c(m,i,v),r(i,l),r(i,o),r(o,f),r(i,y),c(m,E,v),c(m,k,v),r(k,w),r(k,q),r(q,z),r(k,j)},d(m){m&&t(i),m&&t(E),m&&t(k)}}}function aa(g){let i,l;return i=new N({props:{code:`from transformers import BertConfig, TFBertModel

# Creazione della configurazione
config = BertConfig()

# Creare il modello dalla configurazione
model = TFBertModel(config)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

<span class="hljs-comment"># Creazione della configurazione</span>
config = BertConfig()

<span class="hljs-comment"># Creare il modello dalla configurazione</span>
model = TFBertModel(config)`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function la(g){let i,l;return i=new N({props:{code:`from transformers import BertConfig, BertModel

# Creazione della configurazione
config = BertConfig()

# Creare il modello dalla configurazione
model = BertModel(config)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

<span class="hljs-comment"># Creazione della configurazione</span>
config = BertConfig()

<span class="hljs-comment"># Creare il modello dalla configurazione</span>
model = BertModel(config)`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function sa(g){let i,l;return i=new N({props:{code:`from transformers import BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

# Il modello \xE8 inizializzato in modo casuale!`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

<span class="hljs-comment"># Il modello \xE8 inizializzato in modo casuale!</span>`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function na(g){let i,l;return i=new N({props:{code:`from transformers import BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

# Il modello \xE8 inizializzato in modo casuale!`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

<span class="hljs-comment"># Il modello \xE8 inizializzato in modo casuale!</span>`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ca(g){let i,l,o,f,y,E,k,w,q,z,j;return i=new N({props:{code:`from transformers import TFBertModel

model = TFBertModel.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFBertModel

model = TFBertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),{c(){M(i.$$.fragment),l=_(),o=d("p"),f=s("Come abbiamo visto in precedenza, possiamo sostituire "),y=d("code"),E=s("TFBertModel"),k=s(" con la classe equivalente "),w=d("code"),q=s("TFAutoModel"),z=s(". Lo faremo d\u2019ora in poi, perch\xE9 in questo modo si ottiene un codice cosiddetto \u201Ccheckpoint-agnostic\u201D; se il codice funziona per un checkpoint, dovrebbe funzionare senza problemi anche con un altro. Questo vale anche se l\u2019architettura \xE8 diversa, purch\xE9 il checkpoint sia stato addestrato per un compito simile (per esempio, un compito di sentiment analysis).")},l(m){B(i.$$.fragment,m),l=h(m),o=p(m,"P",{});var v=u(o);f=n(v,"Come abbiamo visto in precedenza, possiamo sostituire "),y=p(v,"CODE",{});var A=u(y);E=n(A,"TFBertModel"),A.forEach(t),k=n(v," con la classe equivalente "),w=p(v,"CODE",{});var I=u(w);q=n(I,"TFAutoModel"),I.forEach(t),z=n(v,". Lo faremo d\u2019ora in poi, perch\xE9 in questo modo si ottiene un codice cosiddetto \u201Ccheckpoint-agnostic\u201D; se il codice funziona per un checkpoint, dovrebbe funzionare senza problemi anche con un altro. Questo vale anche se l\u2019architettura \xE8 diversa, purch\xE9 il checkpoint sia stato addestrato per un compito simile (per esempio, un compito di sentiment analysis)."),v.forEach(t)},m(m,v){P(i,m,v),c(m,l,v),c(m,o,v),r(o,f),r(o,y),r(y,E),r(o,k),r(o,w),r(w,q),r(o,z),j=!0},i(m){j||($(i.$$.fragment,m),j=!0)},o(m){b(i.$$.fragment,m),j=!1},d(m){T(i,m),m&&t(l),m&&t(o)}}}function da(g){let i,l,o,f,y,E,k,w,q,z,j;return i=new N({props:{code:`from transformers import BertModel

model = BertModel.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel

model = BertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),{c(){M(i.$$.fragment),l=_(),o=d("p"),f=s("Come abbiamo visto in precedenza, possiamo sostituire "),y=d("code"),E=s("BertModel"),k=s(" con la classe equivalente "),w=d("code"),q=s("AutoModel"),z=s(". Lo faremo d\u2019ora in poi, perch\xE9 in questo modo si ottiene un codice cosiddetto \u201Ccheckpoint-agnostic\u201D; se il codice funziona per un checkpoint, dovrebbe funzionare senza problemi anche con un altro. Questo vale anche se l\u2019architettura \xE8 diversa, purch\xE9 il checkpoint sia stato addestrato per un compito simile (per esempio, un compito di sentiment analysis).")},l(m){B(i.$$.fragment,m),l=h(m),o=p(m,"P",{});var v=u(o);f=n(v,"Come abbiamo visto in precedenza, possiamo sostituire "),y=p(v,"CODE",{});var A=u(y);E=n(A,"BertModel"),A.forEach(t),k=n(v," con la classe equivalente "),w=p(v,"CODE",{});var I=u(w);q=n(I,"AutoModel"),I.forEach(t),z=n(v,". Lo faremo d\u2019ora in poi, perch\xE9 in questo modo si ottiene un codice cosiddetto \u201Ccheckpoint-agnostic\u201D; se il codice funziona per un checkpoint, dovrebbe funzionare senza problemi anche con un altro. Questo vale anche se l\u2019architettura \xE8 diversa, purch\xE9 il checkpoint sia stato addestrato per un compito simile (per esempio, un compito di sentiment analysis)."),v.forEach(t)},m(m,v){P(i,m,v),c(m,l,v),c(m,o,v),r(o,f),r(o,y),r(y,E),r(o,k),r(o,w),r(w,q),r(o,z),j=!0},i(m){j||($(i.$$.fragment,m),j=!0)},o(m){b(i.$$.fragment,m),j=!1},d(m){T(i,m),m&&t(l),m&&t(o)}}}function pa(g){let i,l;return i=new N({props:{code:`ls directory_on_my_computer

config.json tf_model.h5`,highlighted:`ls <span class="hljs-keyword">directory_on_my_computer
</span>
<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>tf_model.h5`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ua(g){let i,l;return i=new N({props:{code:`ls directory_on_my_computer

config.json pytorch_model.bin`,highlighted:`ls <span class="hljs-keyword">directory_on_my_computer
</span>
<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>pytorch_model.<span class="hljs-keyword">bin</span>`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ma(g){let i,l,o,f,y,E,k,w;return{c(){i=d("p"),l=s("Il file "),o=d("em"),f=s("tf_model.h5"),y=s(" \xE8 noto come "),E=d("em"),k=s("state dictionary"),w=s("; contiene tutti i pesi del modello. I due file vanno di pari passo: la configurazione \xE8 necessaria per conoscere l\u2019architettura del modello, mentre i pesi del modello sono i suoi parametri.")},l(q){i=p(q,"P",{});var z=u(i);l=n(z,"Il file "),o=p(z,"EM",{});var j=u(o);f=n(j,"tf_model.h5"),j.forEach(t),y=n(z," \xE8 noto come "),E=p(z,"EM",{});var m=u(E);k=n(m,"state dictionary"),m.forEach(t),w=n(z,"; contiene tutti i pesi del modello. I due file vanno di pari passo: la configurazione \xE8 necessaria per conoscere l\u2019architettura del modello, mentre i pesi del modello sono i suoi parametri."),z.forEach(t)},m(q,z){c(q,i,z),r(i,l),r(i,o),r(o,f),r(i,y),r(i,E),r(E,k),r(i,w)},d(q){q&&t(i)}}}function fa(g){let i,l,o,f,y,E,k,w;return{c(){i=d("p"),l=s("Il file "),o=d("em"),f=s("pytorch_model.bin"),y=s(" \xE8 noto come "),E=d("em"),k=s("state dictionary"),w=s("; contiene tutti i pesi del modello. I due file vanno di pari passo: la configurazione \xE8 necessaria per conoscere l\u2019architettura del modello, mentre i pesi del modello sono i suoi parametri.")},l(q){i=p(q,"P",{});var z=u(i);l=n(z,"Il file "),o=p(z,"EM",{});var j=u(o);f=n(j,"pytorch_model.bin"),j.forEach(t),y=n(z," \xE8 noto come "),E=p(z,"EM",{});var m=u(E);k=n(m,"state dictionary"),m.forEach(t),w=n(z,"; contiene tutti i pesi del modello. I due file vanno di pari passo: la configurazione \xE8 necessaria per conoscere l\u2019architettura del modello, mentre i pesi del modello sono i suoi parametri."),z.forEach(t)},m(q,z){c(q,i,z),r(i,l),r(i,o),r(o,f),r(i,y),r(i,E),r(E,k),r(i,w)},d(q){q&&t(i)}}}function _a(g){let i,l;return i=new N({props:{code:`import tensorflow as tf

model_inputs = tf.constant(encoded_sequences)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

model_inputs = tf.constant(encoded_sequences)`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function ha(g){let i,l;return i=new N({props:{code:`import torch

model_inputs = torch.tensor(encoded_sequences)`,highlighted:`<span class="hljs-keyword">import</span> torch

model_inputs = torch.tensor(encoded_sequences)`}}),{c(){M(i.$$.fragment)},l(o){B(i.$$.fragment,o)},m(o,f){P(i,o,f),l=!0},i(o){l||($(i.$$.fragment,o),l=!0)},o(o){b(i.$$.fragment,o),l=!1},d(o){T(i,o)}}}function va(g){let i,l,o,f,y,E,k,w,q,z,j,m,v,A,I,S,L,Ue,Re,Qe,Tt,Uo,X,ae,$o,$e,At,go,It,Ro,xe,St,Qo,H,U,Ge,Ve,Nt,xo,ge,Go,ke,Vo,D,Dt,ko,Ft,Ot,zo,Lt,Ht,Eo,Ut,Rt,Jo,Z,le,yo,ze,Qt,wo,xt,Yo,Je,Gt,Ko,R,Q,Ye,Ke,Vt,Wo,se,Jt,We,Yt,Kt,Xo,ne,Wt,qo,Xt,Zt,Zo,x,G,Xe,F,ei,Co,oi,ti,jo,ii,ri,Ee,ai,li,et,Ze,si,ot,O,ni,Mo,ci,di,Bo,pi,ui,Po,mi,fi,tt,ce,_i,ye,hi,vi,it,ee,de,To,we,bi,Ao,$i,rt,W,gi,Io,ki,zi,So,Ei,yi,at,qe,lt,eo,wi,st,V,J,oo,pe,qi,No,Ci,ji,nt,to,oe,ue,Do,Ce,Mi,Fo,Bi,ct,io,Pi,dt,ro,Ti,pt,ao,Ai,ut,je,mt,me,Ii,Oo,Si,Ni,ft,Me,_t,lo,Di,ht,Y,K,so,te,fe,Lo,Be,Fi,Ho,Oi,vt,no,Li,bt,Pe,$t,co,Hi,gt;o=new Xr({props:{fw:g[0]}}),w=new bo({});const Ui=[ea,Zr],Te=[];function Ri(e,a){return e[0]==="pt"?0:1}v=Ri(g),A=Te[v]=Ui[v](g);const Qi=[ta,oa],Ae=[];function xi(e,a){return e[0]==="pt"?0:1}S=xi(g),L=Ae[S]=Qi[S](g);function Gi(e,a){return e[0]==="pt"?ra:ia}let kt=Gi(g),ie=kt(g);$e=new bo({});const Vi=[la,aa],Ie=[];function Ji(e,a){return e[0]==="pt"?0:1}H=Ji(g),U=Ie[H]=Vi[H](g),ge=new N({props:{code:"print(config)",highlighted:'<span class="hljs-built_in">print</span>(config)'}}),ke=new N({props:{code:`BertConfig {
  [...]
  "hidden_size": 768,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  [...]
}`,highlighted:`BertConfig {
  [...]
  <span class="hljs-string">&quot;hidden_size&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;intermediate_size&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;num_attention_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;num_hidden_layers&quot;</span>: <span class="hljs-number">12</span>,
  [...]
}`}}),ze=new bo({});const Yi=[na,sa],Se=[];function Ki(e,a){return e[0]==="pt"?0:1}R=Ki(g),Q=Se[R]=Yi[R](g);const Wi=[da,ca],Ne=[];function Xi(e,a){return e[0]==="pt"?0:1}x=Xi(g),G=Ne[x]=Wi[x](g),we=new bo({}),qe=new N({props:{code:'model.save_pretrained("directory_on_my_computer")',highlighted:'model.save_pretrained(<span class="hljs-string">&quot;directory_on_my_computer&quot;</span>)'}});const Zi=[ua,pa],De=[];function er(e,a){return e[0]==="pt"?0:1}V=er(g),J=De[V]=Zi[V](g);function or(e,a){return e[0]==="pt"?fa:ma}let zt=or(g),re=zt(g);Ce=new bo({}),je=new N({props:{code:'sequences = ["Hello!", "Cool.", "Nice!"]',highlighted:'sequences = [<span class="hljs-string">&quot;Hello!&quot;</span>, <span class="hljs-string">&quot;Cool.&quot;</span>, <span class="hljs-string">&quot;Nice!&quot;</span>]'}}),Me=new N({props:{code:`encoded_sequences = [
    [101, 7592, 999, 102],
    [101, 4658, 1012, 102],
    [101, 3835, 999, 102],
]`,highlighted:`encoded_sequences = [
    [<span class="hljs-number">101</span>, <span class="hljs-number">7592</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">4658</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">3835</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
]`}});const tr=[ha,_a],Fe=[];function ir(e,a){return e[0]==="pt"?0:1}return Y=ir(g),K=Fe[Y]=tr[Y](g),Be=new bo({}),Pe=new N({props:{code:"output = model(model_inputs)",highlighted:"output = model(model_inputs)"}}),{c(){i=d("meta"),l=_(),M(o.$$.fragment),f=_(),y=d("h1"),E=d("a"),k=d("span"),M(w.$$.fragment),q=_(),z=d("span"),j=s("Models"),m=_(),A.c(),I=_(),L.c(),Ue=_(),ie.c(),Re=_(),Qe=d("p"),Tt=s("Tuttavia, se si conosce il tipo di modello che si vuole utilizzare, si pu\xF2 usare direttamente la classe che ne definisce l\u2019architettura. Vediamo come funziona con un modello BERT."),Uo=_(),X=d("h2"),ae=d("a"),$o=d("span"),M($e.$$.fragment),At=_(),go=d("span"),It=s("Creare un trasformatore"),Ro=_(),xe=d("p"),St=s("La prima cosa da fare per inizializzare un modello BERT \xE8 caricare un oggetto di configurazione:"),Qo=_(),U.c(),Ge=_(),Ve=d("p"),Nt=s("La configurazione contiene molti attributi che vengono utilizzati per costruire il modello:"),xo=_(),M(ge.$$.fragment),Go=_(),M(ke.$$.fragment),Vo=_(),D=d("p"),Dt=s("Anche se non si \xE8 ancora visto cosa fanno tutti questi attributi, se ne dovrebbero riconoscere alcuni: l\u2019attributo "),ko=d("code"),Ft=s("hidden_size"),Ot=s(" definisce la dimensione del vettore "),zo=d("code"),Lt=s("hidden_states"),Ht=s(", e l\u2019attributo "),Eo=d("code"),Ut=s("num_hidden_layers"),Rt=s(" definisce il numero di livelli del modello Transformer."),Jo=_(),Z=d("h3"),le=d("a"),yo=d("span"),M(ze.$$.fragment),Qt=_(),wo=d("span"),xt=s("Diversi metodi di caricamento"),Yo=_(),Je=d("p"),Gt=s("La creazione di un modello dalla configurazione predefinita lo inizializza con valori casuali:"),Ko=_(),Q.c(),Ye=_(),Ke=d("p"),Vt=s("Il modello pu\xF2 essere utilizzato in questo stato, ma produrr\xE0 risultati incomprensibili; \xE8 necessario addestrarlo prima."),Wo=_(),se=d("p"),Jt=s("Potremmo addestrare il modello da zero sul compito da svolgere, ma come si \xE8 visto in "),We=d("a"),Yt=s("Capitolo 1"),Kt=s(", questo richiederebbe molto tempo e molti dati, oltre ad avere un impatto ambientale non trascurabile. Per evitare sforzi inutili, \xE8 indispensabile poter condividere e riutilizzare modelli gi\xE0 addestrati."),Xo=_(),ne=d("p"),Wt=s("Caricare un modello Transformer gi\xE0 addestrato \xE8 semplice: lo si pu\xF2 fare usando il metodo "),qo=d("code"),Xt=s("from_pretrained()"),Zt=s(":"),Zo=_(),G.c(),Xe=_(),F=d("p"),ei=s("Nell\u2019esempio di codice precedente non abbiamo usato "),Co=d("code"),oi=s("BertConfig"),ti=s(" e abbiamo invece caricato un modello pre-addestrato tramite l\u2019identificatore "),jo=d("code"),ii=s("bert-base-cased"),ri=s(". Si tratta di un checkpoint che \xE8 stato addestrato dagli stessi autori di BERT; si possono trovare maggiori dettagli su di esso nella sua "),Ee=d("a"),ai=s("scheda modello"),li=s("."),et=_(),Ze=d("p"),si=s("Questo modello \xE8 ora inizializzato con tutti i pesi del checkpoint. Pu\xF2 essere utilizzato direttamente per effettuare inferenza sui compiti su cui \xE8 stato addestrato e pu\xF2 anche essere messo adattato ad un nuovo compito, tramite il fine tuning. Allenandosi con i pesi pre-addestrati piuttosto che partendo da zero, si possono ottenere rapidamente buoni risultati."),ot=_(),O=d("p"),ni=s("I pesi sono stati scaricati e messi in cache (in modo che le future chiamate al metodo "),Mo=d("code"),ci=s("from_pretrained()"),di=s(" non li scarichino di nuovo) nella cartella della cache, che per impostazione predefinita \xE8 "),Bo=d("em"),pi=s("~/.cache/huggingface/transformers"),ui=s(". \xC8 possibile personalizzare la cartella della cache impostando la variabile d\u2019ambiente "),Po=d("code"),mi=s("HF_HOME"),fi=s("."),tt=_(),ce=d("p"),_i=s("L\u2019identificatore usato per caricare il modello pu\xF2 essere l\u2019identificatore di qualsiasi modello presente nel Model Hub, purch\xE9 sia compatibile con l\u2019architettura del BERT. L\u2019elenco completo dei checkpoint BERT disponibili \xE8 disponibile "),ye=d("a"),hi=s("qui"),vi=s("."),it=_(),ee=d("h3"),de=d("a"),To=d("span"),M(we.$$.fragment),bi=_(),Ao=d("span"),$i=s("Metodi di salvataggio"),rt=_(),W=d("p"),gi=s("Saving a model is as easy as loading one \u2014 we use the "),Io=d("code"),ki=s("save_pretrained()"),zi=s(" method, which is analogous to the "),So=d("code"),Ei=s("from_pretrained()"),yi=s(" method:"),at=_(),M(qe.$$.fragment),lt=_(),eo=d("p"),wi=s("In questo modo si salvano due file sul disco:"),st=_(),J.c(),oo=_(),pe=d("p"),qi=s("Se si d\xE0 un\u2019occhiata al file "),No=d("em"),Ci=s("config.json"),ji=s(", si riconoscono gli attributi necessari per costruire l\u2019architettura del modello. Questo file contiene anche alcuni metadati, come l\u2019origine del checkpoint e la versione di \u{1F917} Transformers utilizzata al momento dell\u2019ultimo salvataggio del checkpoint."),nt=_(),re.c(),to=_(),oe=d("h2"),ue=d("a"),Do=d("span"),M(Ce.$$.fragment),Mi=_(),Fo=d("span"),Bi=s("Using a Transformer model for inference"),ct=_(),io=d("p"),Pi=s("Ora che si sa come caricare e salvare un modello, proviamo a usarlo per fare delle previsioni. I modelli di trasformatori possono elaborare solo numeri - numeri generati dal tokenizer. Ma prima di parlare dei tokenizer, analizziamo quali sono gli input accettati dal modello."),dt=_(),ro=d("p"),Ti=s("I tokenizer possono occuparsi di effettuare il casting degli input nei tensori del framework appropriato, ma per aiutarti a capire cosa sta succedendo, daremo una rapida occhiata a ci\xF2 che deve essere fatto prima di inviare gli input al modello."),pt=_(),ao=d("p"),Ai=s("Supponiamo di avere un paio di sequenze:"),ut=_(),M(je.$$.fragment),mt=_(),me=d("p"),Ii=s("The tokenizer converts these to vocabulary indices which are typically called "),Oo=d("em"),Si=s("input IDs"),Ni=s(". Each sequence is now a list of numbers! The resulting output is:"),ft=_(),M(Me.$$.fragment),_t=_(),lo=d("p"),Di=s("Si tratta di una lista di sequenze codificate: una lista di liste. I tensori accettano solo forme rettangolari (si pensi alle matrici). Questo \u201Carray\u201D \xE8 gi\xE0 di forma rettangolare, quindi convertirlo in un tensore \xE8 facile:"),ht=_(),K.c(),so=_(),te=d("h3"),fe=d("a"),Lo=d("span"),M(Be.$$.fragment),Fi=_(),Ho=d("span"),Oi=s("Uso dei tensori come input del modello"),vt=_(),no=d("p"),Li=s("Utilizzare i tensori con il modello \xE8 estremamente semplice: basta chiamare il modello con gli input:"),bt=_(),M(Pe.$$.fragment),$t=_(),co=d("p"),Hi=s("Il modello accetta molti argomenti diversi, ma solo gli ID degli ingressi sono necessari. Spiegheremo in seguito cosa fanno gli altri argomenti e quando sono necessari, ma prima dobbiamo dare un\u2019occhiata pi\xF9 da vicino ai tokenizer che costruiscono gli input che un modello Transformer pu\xF2 comprendere."),this.h()},l(e){const a=Kr('[data-svelte="svelte-1phssyn"]',document.head);i=p(a,"META",{name:!0,content:!0}),a.forEach(t),l=h(e),B(o.$$.fragment,e),f=h(e),y=p(e,"H1",{class:!0});var Oe=u(y);E=p(Oe,"A",{id:!0,class:!0,href:!0});var po=u(E);k=p(po,"SPAN",{});var uo=u(k);B(w.$$.fragment,uo),uo.forEach(t),po.forEach(t),q=h(Oe),z=p(Oe,"SPAN",{});var mo=u(z);j=n(mo,"Models"),mo.forEach(t),Oe.forEach(t),m=h(e),A.l(e),I=h(e),L.l(e),Ue=h(e),ie.l(e),Re=h(e),Qe=p(e,"P",{});var fo=u(Qe);Tt=n(fo,"Tuttavia, se si conosce il tipo di modello che si vuole utilizzare, si pu\xF2 usare direttamente la classe che ne definisce l\u2019architettura. Vediamo come funziona con un modello BERT."),fo.forEach(t),Uo=h(e),X=p(e,"H2",{class:!0});var _e=u(X);ae=p(_e,"A",{id:!0,class:!0,href:!0});var _o=u(ae);$o=p(_o,"SPAN",{});var ho=u($o);B($e.$$.fragment,ho),ho.forEach(t),_o.forEach(t),At=h(_e),go=p(_e,"SPAN",{});var rr=u(go);It=n(rr,"Creare un trasformatore"),rr.forEach(t),_e.forEach(t),Ro=h(e),xe=p(e,"P",{});var ar=u(xe);St=n(ar,"La prima cosa da fare per inizializzare un modello BERT \xE8 caricare un oggetto di configurazione:"),ar.forEach(t),Qo=h(e),U.l(e),Ge=h(e),Ve=p(e,"P",{});var lr=u(Ve);Nt=n(lr,"La configurazione contiene molti attributi che vengono utilizzati per costruire il modello:"),lr.forEach(t),xo=h(e),B(ge.$$.fragment,e),Go=h(e),B(ke.$$.fragment,e),Vo=h(e),D=p(e,"P",{});var he=u(D);Dt=n(he,"Anche se non si \xE8 ancora visto cosa fanno tutti questi attributi, se ne dovrebbero riconoscere alcuni: l\u2019attributo "),ko=p(he,"CODE",{});var sr=u(ko);Ft=n(sr,"hidden_size"),sr.forEach(t),Ot=n(he," definisce la dimensione del vettore "),zo=p(he,"CODE",{});var nr=u(zo);Lt=n(nr,"hidden_states"),nr.forEach(t),Ht=n(he,", e l\u2019attributo "),Eo=p(he,"CODE",{});var cr=u(Eo);Ut=n(cr,"num_hidden_layers"),cr.forEach(t),Rt=n(he," definisce il numero di livelli del modello Transformer."),he.forEach(t),Jo=h(e),Z=p(e,"H3",{class:!0});var Et=u(Z);le=p(Et,"A",{id:!0,class:!0,href:!0});var dr=u(le);yo=p(dr,"SPAN",{});var pr=u(yo);B(ze.$$.fragment,pr),pr.forEach(t),dr.forEach(t),Qt=h(Et),wo=p(Et,"SPAN",{});var ur=u(wo);xt=n(ur,"Diversi metodi di caricamento"),ur.forEach(t),Et.forEach(t),Yo=h(e),Je=p(e,"P",{});var mr=u(Je);Gt=n(mr,"La creazione di un modello dalla configurazione predefinita lo inizializza con valori casuali:"),mr.forEach(t),Ko=h(e),Q.l(e),Ye=h(e),Ke=p(e,"P",{});var fr=u(Ke);Vt=n(fr,"Il modello pu\xF2 essere utilizzato in questo stato, ma produrr\xE0 risultati incomprensibili; \xE8 necessario addestrarlo prima."),fr.forEach(t),Wo=h(e),se=p(e,"P",{});var yt=u(se);Jt=n(yt,"Potremmo addestrare il modello da zero sul compito da svolgere, ma come si \xE8 visto in "),We=p(yt,"A",{href:!0});var _r=u(We);Yt=n(_r,"Capitolo 1"),_r.forEach(t),Kt=n(yt,", questo richiederebbe molto tempo e molti dati, oltre ad avere un impatto ambientale non trascurabile. Per evitare sforzi inutili, \xE8 indispensabile poter condividere e riutilizzare modelli gi\xE0 addestrati."),yt.forEach(t),Xo=h(e),ne=p(e,"P",{});var wt=u(ne);Wt=n(wt,"Caricare un modello Transformer gi\xE0 addestrato \xE8 semplice: lo si pu\xF2 fare usando il metodo "),qo=p(wt,"CODE",{});var hr=u(qo);Xt=n(hr,"from_pretrained()"),hr.forEach(t),Zt=n(wt,":"),wt.forEach(t),Zo=h(e),G.l(e),Xe=h(e),F=p(e,"P",{});var ve=u(F);ei=n(ve,"Nell\u2019esempio di codice precedente non abbiamo usato "),Co=p(ve,"CODE",{});var vr=u(Co);oi=n(vr,"BertConfig"),vr.forEach(t),ti=n(ve," e abbiamo invece caricato un modello pre-addestrato tramite l\u2019identificatore "),jo=p(ve,"CODE",{});var br=u(jo);ii=n(br,"bert-base-cased"),br.forEach(t),ri=n(ve,". Si tratta di un checkpoint che \xE8 stato addestrato dagli stessi autori di BERT; si possono trovare maggiori dettagli su di esso nella sua "),Ee=p(ve,"A",{href:!0,rel:!0});var $r=u(Ee);ai=n($r,"scheda modello"),$r.forEach(t),li=n(ve,"."),ve.forEach(t),et=h(e),Ze=p(e,"P",{});var gr=u(Ze);si=n(gr,"Questo modello \xE8 ora inizializzato con tutti i pesi del checkpoint. Pu\xF2 essere utilizzato direttamente per effettuare inferenza sui compiti su cui \xE8 stato addestrato e pu\xF2 anche essere messo adattato ad un nuovo compito, tramite il fine tuning. Allenandosi con i pesi pre-addestrati piuttosto che partendo da zero, si possono ottenere rapidamente buoni risultati."),gr.forEach(t),ot=h(e),O=p(e,"P",{});var be=u(O);ni=n(be,"I pesi sono stati scaricati e messi in cache (in modo che le future chiamate al metodo "),Mo=p(be,"CODE",{});var kr=u(Mo);ci=n(kr,"from_pretrained()"),kr.forEach(t),di=n(be," non li scarichino di nuovo) nella cartella della cache, che per impostazione predefinita \xE8 "),Bo=p(be,"EM",{});var zr=u(Bo);pi=n(zr,"~/.cache/huggingface/transformers"),zr.forEach(t),ui=n(be,". \xC8 possibile personalizzare la cartella della cache impostando la variabile d\u2019ambiente "),Po=p(be,"CODE",{});var Er=u(Po);mi=n(Er,"HF_HOME"),Er.forEach(t),fi=n(be,"."),be.forEach(t),tt=h(e),ce=p(e,"P",{});var qt=u(ce);_i=n(qt,"L\u2019identificatore usato per caricare il modello pu\xF2 essere l\u2019identificatore di qualsiasi modello presente nel Model Hub, purch\xE9 sia compatibile con l\u2019architettura del BERT. L\u2019elenco completo dei checkpoint BERT disponibili \xE8 disponibile "),ye=p(qt,"A",{href:!0,rel:!0});var yr=u(ye);hi=n(yr,"qui"),yr.forEach(t),vi=n(qt,"."),qt.forEach(t),it=h(e),ee=p(e,"H3",{class:!0});var Ct=u(ee);de=p(Ct,"A",{id:!0,class:!0,href:!0});var wr=u(de);To=p(wr,"SPAN",{});var qr=u(To);B(we.$$.fragment,qr),qr.forEach(t),wr.forEach(t),bi=h(Ct),Ao=p(Ct,"SPAN",{});var Cr=u(Ao);$i=n(Cr,"Metodi di salvataggio"),Cr.forEach(t),Ct.forEach(t),rt=h(e),W=p(e,"P",{});var vo=u(W);gi=n(vo,"Saving a model is as easy as loading one \u2014 we use the "),Io=p(vo,"CODE",{});var jr=u(Io);ki=n(jr,"save_pretrained()"),jr.forEach(t),zi=n(vo," method, which is analogous to the "),So=p(vo,"CODE",{});var Mr=u(So);Ei=n(Mr,"from_pretrained()"),Mr.forEach(t),yi=n(vo," method:"),vo.forEach(t),at=h(e),B(qe.$$.fragment,e),lt=h(e),eo=p(e,"P",{});var Br=u(eo);wi=n(Br,"In questo modo si salvano due file sul disco:"),Br.forEach(t),st=h(e),J.l(e),oo=h(e),pe=p(e,"P",{});var jt=u(pe);qi=n(jt,"Se si d\xE0 un\u2019occhiata al file "),No=p(jt,"EM",{});var Pr=u(No);Ci=n(Pr,"config.json"),Pr.forEach(t),ji=n(jt,", si riconoscono gli attributi necessari per costruire l\u2019architettura del modello. Questo file contiene anche alcuni metadati, come l\u2019origine del checkpoint e la versione di \u{1F917} Transformers utilizzata al momento dell\u2019ultimo salvataggio del checkpoint."),jt.forEach(t),nt=h(e),re.l(e),to=h(e),oe=p(e,"H2",{class:!0});var Mt=u(oe);ue=p(Mt,"A",{id:!0,class:!0,href:!0});var Tr=u(ue);Do=p(Tr,"SPAN",{});var Ar=u(Do);B(Ce.$$.fragment,Ar),Ar.forEach(t),Tr.forEach(t),Mi=h(Mt),Fo=p(Mt,"SPAN",{});var Ir=u(Fo);Bi=n(Ir,"Using a Transformer model for inference"),Ir.forEach(t),Mt.forEach(t),ct=h(e),io=p(e,"P",{});var Sr=u(io);Pi=n(Sr,"Ora che si sa come caricare e salvare un modello, proviamo a usarlo per fare delle previsioni. I modelli di trasformatori possono elaborare solo numeri - numeri generati dal tokenizer. Ma prima di parlare dei tokenizer, analizziamo quali sono gli input accettati dal modello."),Sr.forEach(t),dt=h(e),ro=p(e,"P",{});var Nr=u(ro);Ti=n(Nr,"I tokenizer possono occuparsi di effettuare il casting degli input nei tensori del framework appropriato, ma per aiutarti a capire cosa sta succedendo, daremo una rapida occhiata a ci\xF2 che deve essere fatto prima di inviare gli input al modello."),Nr.forEach(t),pt=h(e),ao=p(e,"P",{});var Dr=u(ao);Ai=n(Dr,"Supponiamo di avere un paio di sequenze:"),Dr.forEach(t),ut=h(e),B(je.$$.fragment,e),mt=h(e),me=p(e,"P",{});var Bt=u(me);Ii=n(Bt,"The tokenizer converts these to vocabulary indices which are typically called "),Oo=p(Bt,"EM",{});var Fr=u(Oo);Si=n(Fr,"input IDs"),Fr.forEach(t),Ni=n(Bt,". Each sequence is now a list of numbers! The resulting output is:"),Bt.forEach(t),ft=h(e),B(Me.$$.fragment,e),_t=h(e),lo=p(e,"P",{});var Or=u(lo);Di=n(Or,"Si tratta di una lista di sequenze codificate: una lista di liste. I tensori accettano solo forme rettangolari (si pensi alle matrici). Questo \u201Carray\u201D \xE8 gi\xE0 di forma rettangolare, quindi convertirlo in un tensore \xE8 facile:"),Or.forEach(t),ht=h(e),K.l(e),so=h(e),te=p(e,"H3",{class:!0});var Pt=u(te);fe=p(Pt,"A",{id:!0,class:!0,href:!0});var Lr=u(fe);Lo=p(Lr,"SPAN",{});var Hr=u(Lo);B(Be.$$.fragment,Hr),Hr.forEach(t),Lr.forEach(t),Fi=h(Pt),Ho=p(Pt,"SPAN",{});var Ur=u(Ho);Oi=n(Ur,"Uso dei tensori come input del modello"),Ur.forEach(t),Pt.forEach(t),vt=h(e),no=p(e,"P",{});var Rr=u(no);Li=n(Rr,"Utilizzare i tensori con il modello \xE8 estremamente semplice: basta chiamare il modello con gli input:"),Rr.forEach(t),bt=h(e),B(Pe.$$.fragment,e),$t=h(e),co=p(e,"P",{});var Qr=u(co);Hi=n(Qr,"Il modello accetta molti argomenti diversi, ma solo gli ID degli ingressi sono necessari. Spiegheremo in seguito cosa fanno gli altri argomenti e quando sono necessari, ma prima dobbiamo dare un\u2019occhiata pi\xF9 da vicino ai tokenizer che costruiscono gli input che un modello Transformer pu\xF2 comprendere."),Qr.forEach(t),this.h()},h(){C(i,"name","hf:doc:metadata"),C(i,"content",JSON.stringify(ba)),C(E,"id","models"),C(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(E,"href","#models"),C(y,"class","relative group"),C(ae,"id","creare-un-trasformatore"),C(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(ae,"href","#creare-un-trasformatore"),C(X,"class","relative group"),C(le,"id","diversi-metodi-di-caricamento"),C(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(le,"href","#diversi-metodi-di-caricamento"),C(Z,"class","relative group"),C(We,"href","/course/chapter1"),C(Ee,"href","https://huggingface.co/bert-base-cased"),C(Ee,"rel","nofollow"),C(ye,"href","https://huggingface.co/models?filter=bert"),C(ye,"rel","nofollow"),C(de,"id","metodi-di-salvataggio"),C(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(de,"href","#metodi-di-salvataggio"),C(ee,"class","relative group"),C(ue,"id","using-a-transformer-model-for-inference"),C(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(ue,"href","#using-a-transformer-model-for-inference"),C(oe,"class","relative group"),C(fe,"id","uso-dei-tensori-come-input-del-modello"),C(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(fe,"href","#uso-dei-tensori-come-input-del-modello"),C(te,"class","relative group")},m(e,a){r(document.head,i),c(e,l,a),P(o,e,a),c(e,f,a),c(e,y,a),r(y,E),r(E,k),P(w,k,null),r(y,q),r(y,z),r(z,j),c(e,m,a),Te[v].m(e,a),c(e,I,a),Ae[S].m(e,a),c(e,Ue,a),ie.m(e,a),c(e,Re,a),c(e,Qe,a),r(Qe,Tt),c(e,Uo,a),c(e,X,a),r(X,ae),r(ae,$o),P($e,$o,null),r(X,At),r(X,go),r(go,It),c(e,Ro,a),c(e,xe,a),r(xe,St),c(e,Qo,a),Ie[H].m(e,a),c(e,Ge,a),c(e,Ve,a),r(Ve,Nt),c(e,xo,a),P(ge,e,a),c(e,Go,a),P(ke,e,a),c(e,Vo,a),c(e,D,a),r(D,Dt),r(D,ko),r(ko,Ft),r(D,Ot),r(D,zo),r(zo,Lt),r(D,Ht),r(D,Eo),r(Eo,Ut),r(D,Rt),c(e,Jo,a),c(e,Z,a),r(Z,le),r(le,yo),P(ze,yo,null),r(Z,Qt),r(Z,wo),r(wo,xt),c(e,Yo,a),c(e,Je,a),r(Je,Gt),c(e,Ko,a),Se[R].m(e,a),c(e,Ye,a),c(e,Ke,a),r(Ke,Vt),c(e,Wo,a),c(e,se,a),r(se,Jt),r(se,We),r(We,Yt),r(se,Kt),c(e,Xo,a),c(e,ne,a),r(ne,Wt),r(ne,qo),r(qo,Xt),r(ne,Zt),c(e,Zo,a),Ne[x].m(e,a),c(e,Xe,a),c(e,F,a),r(F,ei),r(F,Co),r(Co,oi),r(F,ti),r(F,jo),r(jo,ii),r(F,ri),r(F,Ee),r(Ee,ai),r(F,li),c(e,et,a),c(e,Ze,a),r(Ze,si),c(e,ot,a),c(e,O,a),r(O,ni),r(O,Mo),r(Mo,ci),r(O,di),r(O,Bo),r(Bo,pi),r(O,ui),r(O,Po),r(Po,mi),r(O,fi),c(e,tt,a),c(e,ce,a),r(ce,_i),r(ce,ye),r(ye,hi),r(ce,vi),c(e,it,a),c(e,ee,a),r(ee,de),r(de,To),P(we,To,null),r(ee,bi),r(ee,Ao),r(Ao,$i),c(e,rt,a),c(e,W,a),r(W,gi),r(W,Io),r(Io,ki),r(W,zi),r(W,So),r(So,Ei),r(W,yi),c(e,at,a),P(qe,e,a),c(e,lt,a),c(e,eo,a),r(eo,wi),c(e,st,a),De[V].m(e,a),c(e,oo,a),c(e,pe,a),r(pe,qi),r(pe,No),r(No,Ci),r(pe,ji),c(e,nt,a),re.m(e,a),c(e,to,a),c(e,oe,a),r(oe,ue),r(ue,Do),P(Ce,Do,null),r(oe,Mi),r(oe,Fo),r(Fo,Bi),c(e,ct,a),c(e,io,a),r(io,Pi),c(e,dt,a),c(e,ro,a),r(ro,Ti),c(e,pt,a),c(e,ao,a),r(ao,Ai),c(e,ut,a),P(je,e,a),c(e,mt,a),c(e,me,a),r(me,Ii),r(me,Oo),r(Oo,Si),r(me,Ni),c(e,ft,a),P(Me,e,a),c(e,_t,a),c(e,lo,a),r(lo,Di),c(e,ht,a),Fe[Y].m(e,a),c(e,so,a),c(e,te,a),r(te,fe),r(fe,Lo),P(Be,Lo,null),r(te,Fi),r(te,Ho),r(Ho,Oi),c(e,vt,a),c(e,no,a),r(no,Li),c(e,bt,a),P(Pe,e,a),c(e,$t,a),c(e,co,a),r(co,Hi),gt=!0},p(e,[a]){const Oe={};a&1&&(Oe.fw=e[0]),o.$set(Oe);let po=v;v=Ri(e),v!==po&&(He(),b(Te[po],1,1,()=>{Te[po]=null}),Le(),A=Te[v],A||(A=Te[v]=Ui[v](e),A.c()),$(A,1),A.m(I.parentNode,I));let uo=S;S=xi(e),S!==uo&&(He(),b(Ae[uo],1,1,()=>{Ae[uo]=null}),Le(),L=Ae[S],L||(L=Ae[S]=Qi[S](e),L.c()),$(L,1),L.m(Ue.parentNode,Ue)),kt!==(kt=Gi(e))&&(ie.d(1),ie=kt(e),ie&&(ie.c(),ie.m(Re.parentNode,Re)));let mo=H;H=Ji(e),H!==mo&&(He(),b(Ie[mo],1,1,()=>{Ie[mo]=null}),Le(),U=Ie[H],U||(U=Ie[H]=Vi[H](e),U.c()),$(U,1),U.m(Ge.parentNode,Ge));let fo=R;R=Ki(e),R!==fo&&(He(),b(Se[fo],1,1,()=>{Se[fo]=null}),Le(),Q=Se[R],Q||(Q=Se[R]=Yi[R](e),Q.c()),$(Q,1),Q.m(Ye.parentNode,Ye));let _e=x;x=Xi(e),x!==_e&&(He(),b(Ne[_e],1,1,()=>{Ne[_e]=null}),Le(),G=Ne[x],G||(G=Ne[x]=Wi[x](e),G.c()),$(G,1),G.m(Xe.parentNode,Xe));let _o=V;V=er(e),V!==_o&&(He(),b(De[_o],1,1,()=>{De[_o]=null}),Le(),J=De[V],J||(J=De[V]=Zi[V](e),J.c()),$(J,1),J.m(oo.parentNode,oo)),zt!==(zt=or(e))&&(re.d(1),re=zt(e),re&&(re.c(),re.m(to.parentNode,to)));let ho=Y;Y=ir(e),Y!==ho&&(He(),b(Fe[ho],1,1,()=>{Fe[ho]=null}),Le(),K=Fe[Y],K||(K=Fe[Y]=tr[Y](e),K.c()),$(K,1),K.m(so.parentNode,so))},i(e){gt||($(o.$$.fragment,e),$(w.$$.fragment,e),$(A),$(L),$($e.$$.fragment,e),$(U),$(ge.$$.fragment,e),$(ke.$$.fragment,e),$(ze.$$.fragment,e),$(Q),$(G),$(we.$$.fragment,e),$(qe.$$.fragment,e),$(J),$(Ce.$$.fragment,e),$(je.$$.fragment,e),$(Me.$$.fragment,e),$(K),$(Be.$$.fragment,e),$(Pe.$$.fragment,e),gt=!0)},o(e){b(o.$$.fragment,e),b(w.$$.fragment,e),b(A),b(L),b($e.$$.fragment,e),b(U),b(ge.$$.fragment,e),b(ke.$$.fragment,e),b(ze.$$.fragment,e),b(Q),b(G),b(we.$$.fragment,e),b(qe.$$.fragment,e),b(J),b(Ce.$$.fragment,e),b(je.$$.fragment,e),b(Me.$$.fragment,e),b(K),b(Be.$$.fragment,e),b(Pe.$$.fragment,e),gt=!1},d(e){t(i),e&&t(l),T(o,e),e&&t(f),e&&t(y),T(w),e&&t(m),Te[v].d(e),e&&t(I),Ae[S].d(e),e&&t(Ue),ie.d(e),e&&t(Re),e&&t(Qe),e&&t(Uo),e&&t(X),T($e),e&&t(Ro),e&&t(xe),e&&t(Qo),Ie[H].d(e),e&&t(Ge),e&&t(Ve),e&&t(xo),T(ge,e),e&&t(Go),T(ke,e),e&&t(Vo),e&&t(D),e&&t(Jo),e&&t(Z),T(ze),e&&t(Yo),e&&t(Je),e&&t(Ko),Se[R].d(e),e&&t(Ye),e&&t(Ke),e&&t(Wo),e&&t(se),e&&t(Xo),e&&t(ne),e&&t(Zo),Ne[x].d(e),e&&t(Xe),e&&t(F),e&&t(et),e&&t(Ze),e&&t(ot),e&&t(O),e&&t(tt),e&&t(ce),e&&t(it),e&&t(ee),T(we),e&&t(rt),e&&t(W),e&&t(at),T(qe,e),e&&t(lt),e&&t(eo),e&&t(st),De[V].d(e),e&&t(oo),e&&t(pe),e&&t(nt),re.d(e),e&&t(to),e&&t(oe),T(Ce),e&&t(ct),e&&t(io),e&&t(dt),e&&t(ro),e&&t(pt),e&&t(ao),e&&t(ut),T(je,e),e&&t(mt),e&&t(me),e&&t(ft),T(Me,e),e&&t(_t),e&&t(lo),e&&t(ht),Fe[Y].d(e),e&&t(so),e&&t(te),T(Be),e&&t(vt),e&&t(no),e&&t(bt),T(Pe,e),e&&t($t),e&&t(co)}}}const ba={local:"models",sections:[{local:"creare-un-trasformatore",sections:[{local:"diversi-metodi-di-caricamento",title:"Diversi metodi di caricamento"},{local:"metodi-di-salvataggio",title:"Metodi di salvataggio"}],title:"Creare un trasformatore"},{local:"using-a-transformer-model-for-inference",sections:[{local:"uso-dei-tensori-come-input-del-modello",title:"Uso dei tensori come input del modello"}],title:"Using a Transformer model for inference"}],title:"Models"};function $a(g,i,l){let o="pt";return Wr(()=>{const f=new URLSearchParams(window.location.search);l(0,o=f.get("fw")||"pt")}),[o]}class qa extends Vr{constructor(i){super();Jr(this,i,$a,va,Yr,{})}}export{qa as default,ba as metadata};
