import{S as z_,i as F_,s as S_,e as r,k as l,w as u,t as a,L as O_,c as n,d as o,m as d,a as s,x as m,h as i,b as c,J as t,g as f,y as h,K as q_,q as g,o as _,B as v}from"../../../chunks/vendor-b1433968.js";import{D as b}from"../../../chunks/Docstring-ff504c58.js";import{C as D_}from"../../../chunks/CodeBlock-a320dbd7.js";import{I as $e}from"../../../chunks/IconCopyLink-7029626d.js";import"../../../chunks/CopyButton-f65cb278.js";function B_(wc){let ge,Wo,O,N,Wn,ut,Ec,Vn,Lc,Ba,T,Pc,Vo,Dc,zc,Mo,Fc,Sc,Co,Oc,qc,Go,Bc,Ic,Ho,Ac,Nc,jo,Wc,Vc,Ia,Ro,Mc,Aa,ke,Ce,Mn,mt,Cc,Cn,Gc,Na,q,Hc,Ko,jc,Rc,Uo,Kc,Uc,Yo,Yc,Xc,Wa,Xo,Jc,Va,ht,Ma,_e,Qc,Gn,Zc,el,Jo,tl,ol,Ca,B,Qo,Hn,rl,nl,sl,Zo,jn,al,il,cl,er,Rn,ll,dl,pl,tr,Kn,fl,ul,Ga,y,ml,Un,hl,gl,Yn,_l,vl,Xn,bl,Tl,Jn,yl,$l,Qn,kl,xl,Zn,wl,El,Ha,w,Ll,es,Pl,Dl,ts,zl,Fl,os,Sl,Ol,rs,ql,Bl,ja,E,Il,ns,Al,Nl,ss,Wl,Vl,as,Ml,Cl,is,Gl,Hl,Ra,gt,Ka,Ge,jl,cs,Rl,Kl,Ua,L,Ul,ls,Yl,Xl,ds,Jl,Ql,ps,Zl,ed,fs,td,od,Ya,or,rd,Xa,xe,He,us,_t,nd,ms,sd,Ja,we,vt,ad,hs,id,Qa,Ee,bt,cd,gs,ld,Za,W,Tt,dd,_s,pd,fd,je,yt,ud,vs,md,ei,Le,Re,bs,$t,hd,Ts,gd,ti,Pe,kt,_d,ys,vd,oi,De,xt,bd,$s,Td,ri,V,wt,yd,ks,$d,kd,Ke,Et,xd,xs,wd,ni,ze,Ue,ws,Lt,Ed,Es,Ld,si,Fe,Pt,Pd,Ls,Dd,ai,Se,Dt,zd,Ps,Fd,ii,Oe,Ye,Ds,zt,Sd,zs,Od,ci,qe,Ft,qd,Fs,Bd,li,Be,St,Id,Ss,Ad,di,Ie,Xe,Os,Ot,Nd,qs,Wd,pi,Je,Vd,rr,Md,Cd,fi,M,qt,Gd,Bs,Hd,jd,Qe,Bt,Rd,Is,Kd,ui,C,It,Ud,$,Yd,nr,Xd,Jd,sr,Qd,Zd,As,ep,tp,Ns,Ws,op,rp,ar,np,sp,ir,ap,ip,cp,cr,At,mi,G,Nt,lp,Vs,dp,pp,Ze,Wt,fp,Ms,up,hi,H,Vt,mp,lr,dr,hp,gp,_p,Cs,gi,j,Mt,vp,pr,fr,bp,Tp,yp,Gs,_i,R,Ct,$p,ur,mr,kp,xp,wp,Hs,vi,K,Gt,Ep,hr,gr,Lp,Pp,Dp,js,bi,U,Ht,zp,_r,vr,Fp,Sp,Op,Rs,Ti,Y,jt,qp,et,br,Bp,Ip,Rt,Ap,Np,Wp,Ks,yi,X,Kt,Vp,Tr,yr,Mp,Cp,Gp,Us,$i,J,Ut,Hp,tt,$r,jp,Rp,Yt,Kp,Up,Yp,Ys,ki,Q,Xt,Xp,ve,kr,Jp,Qp,xr,Zp,ef,Jt,tf,of,rf,Xs,xi,Z,Qt,nf,wr,Er,sf,af,cf,Js,wi,ee,Zt,lf,ot,Lr,df,pf,Qs,ff,uf,mf,Zs,Ei,te,eo,hf,I,Pr,gf,_f,ea,vf,bf,ta,Tf,yf,oa,$f,kf,xf,ra,Li,oe,to,wf,na,Ef,Lf,rt,oo,Pf,sa,Df,Pi,re,ro,zf,k,Ff,Dr,Sf,Of,zr,qf,Bf,aa,If,Af,ia,ca,Nf,Wf,Fr,Vf,Mf,Sr,Cf,Gf,Hf,Or,no,Di,ne,so,jf,la,Rf,Kf,nt,ao,Uf,da,Yf,zi,se,io,Xf,qr,Br,Jf,Qf,Zf,pa,Fi,ae,co,eu,Ir,Ar,tu,ou,ru,fa,Si,ie,lo,nu,Nr,Wr,su,au,iu,ua,Oi,ce,po,cu,Vr,Mr,lu,du,pu,ma,qi,le,fo,fu,st,Cr,uu,mu,ha,hu,gu,_u,ga,Bi,de,uo,vu,Gr,Hr,bu,Tu,yu,_a,Ii,Ae,at,va,mo,$u,ba,ku,Ai,it,xu,jr,wu,Eu,Ni,pe,ho,Lu,Ta,Pu,Du,Rr,go,Wi,_o,Kr,vo,Vi,fe,bo,zu,To,Fu,ya,Su,Ou,qu,Ur,yo,Mi,ue,$o,Bu,ko,Iu,$a,Au,Nu,Wu,Yr,xo,Ci,Ne,ct,ka,wo,Vu,xa,Mu,Gi,S,Eo,Cu,We,Gu,Xr,Hu,ju,Jr,Ru,Ku,Uu,Qr,Lo,Yu,Zr,Po,Hi,x,Do,Xu,en,tn,Ju,Qu,Zu,zo,em,Fo,tm,om,rm,on,nm,So,sm,am,wa,im,Ea,ji,Ve,lt,La,Oo,cm,Pa,lm,Ri,me,qo,dm,Da,pm,fm,rn,um,Bo,mm,Ki,he,Io,hm,za,gm,_m,nn,vm,Ao,bm,Ui;return ut=new $e({}),mt=new $e({}),ht=new D_({props:{code:`from transformers import GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

inputs = tokenizer("Hello, my dog is cute and ", return_tensors="pt")
generation_output = model.generate(**inputs, return_dict_in_generate=True, output_scores=True),`,highlighted:`<span class="hljs-keyword">from</span> transformers import GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained(<span class="hljs-string">&#x27;gpt2&#x27;</span>)
model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&#x27;gpt2&#x27;</span>)

inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute and &quot;</span>, <span class="hljs-attribute">return_tensors</span>=<span class="hljs-string">&quot;pt&quot;</span>)
generation_output = model.generate(**inputs, <span class="hljs-attribute">return_dict_in_generate</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">output_scores</span>=<span class="hljs-literal">True</span>)`}}),gt=new D_({props:{code:"generation_output[:2],",highlighted:'<span class="hljs-attribute">generation_output</span>[:<span class="hljs-number">2</span>]'}}),_t=new $e({}),vt=new b({props:{name:"class transformers.generation_utils.GreedySearchDecoderOnlyOutput",anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L56",parametersDescription:[{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code>
with each tensor of shape <code>(batch_size, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),bt=new b({props:{name:"class transformers.generation_utils.GreedySearchEncoderDecoderOutput",anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L84",parametersDescription:[{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor
of shape <code>(batch_size, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer)
of shape <code>(batch_size, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),Tt=new b({props:{name:"class transformers.generation_flax_utils.FlaxGreedySearchOutput",anchor:"transformers.generation_flax_utils.FlaxGreedySearchOutput",parameters:[{name:"sequences",val:": ndarray = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_utils.py#L45",parametersDescription:[{anchor:"transformers.generation_flax_utils.FlaxGreedySearchOutput.sequences",description:`<strong>sequences</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, max_length)</code>) &#x2014;
The generated sequences.`,name:"sequences"}]}}),yt=new b({props:{name:"replace",anchor:"None",parameters:[{name:"**updates",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/flax/struct.py#L120"}}),$t=new $e({}),kt=new b({props:{name:"class transformers.generation_utils.SampleDecoderOnlyOutput",anchor:"transformers.generation_utils.SampleDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L126",parametersDescription:[{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code>
with each tensor of shape <code>(batch_size*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(num_return_sequences*batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(num_return_sequences*batch_size, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),xt=new b({props:{name:"class transformers.generation_utils.SampleEncoderDecoderOutput",anchor:"transformers.generation_utils.SampleEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L155",parametersDescription:[{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor
of shape <code>(batch_size*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape
<code>(batch_size*num_return_sequences, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer)
of shape <code>(batch_size*num_return_sequences, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),wt=new b({props:{name:"class transformers.generation_flax_utils.FlaxSampleOutput",anchor:"transformers.generation_flax_utils.FlaxSampleOutput",parameters:[{name:"sequences",val:": ndarray = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_utils.py#L59",parametersDescription:[{anchor:"transformers.generation_flax_utils.FlaxSampleOutput.sequences",description:`<strong>sequences</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, max_length)</code>) &#x2014;
The generated sequences.`,name:"sequences"}]}}),Et=new b({props:{name:"replace",anchor:"None",parameters:[{name:"**updates",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/flax/struct.py#L120"}}),Lt=new $e({}),Pt=new b({props:{name:"class transformers.generation_utils.BeamSearchDecoderOnlyOutput",anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L198",parametersDescription:[{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of
shape <code>(batch_size*num_beams*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams*num_return_sequences, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),Dt=new b({props:{name:"class transformers.generation_utils.BeamSearchEncoderDecoderOutput",anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L231",parametersDescription:[{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape
<code>(batch_size*num_beams, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.attentions",description:"<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;",name:"attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer)
of shape <code>(batch_size*num_beams*num_return_sequences, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams*num_return_sequences, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams*num_return_sequences, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),zt=new $e({}),Ft=new b({props:{name:"class transformers.generation_utils.BeamSampleDecoderOnlyOutput",anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L279",parametersDescription:[{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_return_sequence)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of
shape <code>(batch_size*num_beams*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),St=new b({props:{name:"class transformers.generation_utils.BeamSampleEncoderDecoderOutput",anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L311",parametersDescription:[{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_beams, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or
shorter if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_return_sequence)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of log
softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam
. <code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape
<code>(batch_size*num_beams, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer)
of shape <code>(batch_size*num_beams, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),Ot=new $e({}),qt=new b({props:{name:"class transformers.LogitsProcessor",anchor:"transformers.LogitsProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L53"}}),Bt=new b({props:{name:"__call__",anchor:"transformers.LogitsProcessor.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L56",parametersDescription:[{anchor:"transformers.LogitsProcessor.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.LogitsProcessor.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),It=new b({props:{name:"class transformers.LogitsProcessorList",anchor:"transformers.LogitsProcessorList",parameters:[{name:"iterable",val:" = ()"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L75"}}),At=new b({props:{name:"__call__",anchor:"transformers.LogitsProcessorList.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L83",parametersDescription:[{anchor:"transformers.LogitsProcessorList.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.LogitsProcessorList.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),Nt=new b({props:{name:"class transformers.LogitsWarper",anchor:"transformers.LogitsWarper",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L64"}}),Wt=new b({props:{name:"__call__",anchor:"transformers.LogitsWarper.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L67",parametersDescription:[{anchor:"transformers.LogitsWarper.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.LogitsWarper.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),Vt=new b({props:{name:"class transformers.MinLengthLogitsProcessor",anchor:"transformers.MinLengthLogitsProcessor",parameters:[{name:"min_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L99",parametersDescription:[{anchor:"transformers.MinLengthLogitsProcessor.min_length",description:`<strong>min_length</strong> (<code>int</code>) &#x2014;
The minimum length below which the score of <code>eos_token_id</code> is set to <code>-float(&quot;Inf&quot;)</code>.`,name:"min_length"},{anchor:"transformers.MinLengthLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}]}}),Mt=new b({props:{name:"class transformers.TemperatureLogitsWarper",anchor:"transformers.TemperatureLogitsWarper",parameters:[{name:"temperature",val:": float"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L127",parametersDescription:[{anchor:"transformers.TemperatureLogitsWarper.temperature",description:`<strong>temperature</strong> (<code>float</code>) &#x2014;
The value used to module the logits distribution.`,name:"temperature"}]}}),Ct=new b({props:{name:"class transformers.RepetitionPenaltyLogitsProcessor",anchor:"transformers.RepetitionPenaltyLogitsProcessor",parameters:[{name:"penalty",val:": float"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L147",parametersDescription:[{anchor:"transformers.RepetitionPenaltyLogitsProcessor.repetition_penalty",description:`<strong>repetition_penalty</strong> (<code>float</code>) &#x2014;
The parameter for repetition penalty. 1.0 means no penalty. See <a href="https://arxiv.org/pdf/1909.05858.pdf" rel="nofollow">this paper</a> for more details.`,name:"repetition_penalty"}]}}),Gt=new b({props:{name:"class transformers.TopPLogitsWarper",anchor:"transformers.TopPLogitsWarper",parameters:[{name:"top_p",val:": float"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L173",parametersDescription:[{anchor:"transformers.TopPLogitsWarper.top_p",description:`<strong>top_p</strong> (<code>float</code>) &#x2014;
If set to &lt; 1, only the most probable tokens with probabilities that add up to <code>top_p</code> or higher are
kept for generation.`,name:"top_p"},{anchor:"transformers.TopPLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.TopPLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),Ht=new b({props:{name:"class transformers.TopKLogitsWarper",anchor:"transformers.TopKLogitsWarper",parameters:[{name:"top_k",val:": int"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L216",parametersDescription:[{anchor:"transformers.TopKLogitsWarper.top_k",description:`<strong>top_k</strong> (<code>int</code>) &#x2014;
The number of highest probability vocabulary tokens to keep for top-k-filtering.`,name:"top_k"},{anchor:"transformers.TopKLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.TopKLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),jt=new b({props:{name:"class transformers.NoRepeatNGramLogitsProcessor",anchor:"transformers.NoRepeatNGramLogitsProcessor",parameters:[{name:"ngram_size",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L280",parametersDescription:[{anchor:"transformers.NoRepeatNGramLogitsProcessor.ngram_size",description:`<strong>ngram_size</strong> (<code>int</code>) &#x2014;
All ngrams of size <code>ngram_size</code> can only occur once.`,name:"ngram_size"}]}}),Kt=new b({props:{name:"class transformers.NoBadWordsLogitsProcessor",anchor:"transformers.NoBadWordsLogitsProcessor",parameters:[{name:"bad_words_ids",val:": typing.List[typing.List[int]]"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L347",parametersDescription:[{anchor:"transformers.NoBadWordsLogitsProcessor.bad_words_ids",description:`<strong>bad_words_ids</strong> (<code>List[List[int]]</code>) &#x2014;
List of list of token ids that are not allowed to be generated. In order to get the tokens of the words
that should not appear in the generated text, use <code>tokenizer(bad_word, add_prefix_space=True).input_ids</code>.`,name:"bad_words_ids"},{anchor:"transformers.NoBadWordsLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}]}}),Ut=new b({props:{name:"class transformers.PrefixConstrainedLogitsProcessor",anchor:"transformers.PrefixConstrainedLogitsProcessor",parameters:[{name:"prefix_allowed_tokens_fn",val:": typing.Callable[[int, torch.Tensor], typing.List[int]]"},{name:"num_beams",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L475"}}),Xt=new b({props:{name:"class transformers.HammingDiversityLogitsProcessor",anchor:"transformers.HammingDiversityLogitsProcessor",parameters:[{name:"diversity_penalty",val:": float"},{name:"num_beams",val:": int"},{name:"num_beam_groups",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L502",parametersDescription:[{anchor:"transformers.HammingDiversityLogitsProcessor.diversity_penalty",description:`<strong>diversity_penalty</strong> (<code>float</code>) &#x2014;
This value is subtracted from a beam&#x2019;s score if it generates a token same as any beam from other group at a
particular time. Note that <code>diversity_penalty</code> is only effective if <code>group beam search</code> is enabled.`,name:"diversity_penalty"},{anchor:"transformers.HammingDiversityLogitsProcessor.num_beams",description:`<strong>num_beams</strong> (<code>int</code>) &#x2014;
Number of beams used for group beam search. See <a href="https://arxiv.org/pdf/1610.02424.pdf" rel="nofollow">this paper</a> for
more details.`,name:"num_beams"},{anchor:"transformers.HammingDiversityLogitsProcessor.num_beam_groups",description:`<strong>num_beam_groups</strong> (<code>int</code>) &#x2014;
Number of groups to divide <code>num_beams</code> into in order to ensure diversity among different groups of
beams. See <a href="https://arxiv.org/pdf/1610.02424.pdf" rel="nofollow">this paper</a> for more details.`,name:"num_beam_groups"}]}}),Qt=new b({props:{name:"class transformers.ForcedBOSTokenLogitsProcessor",anchor:"transformers.ForcedBOSTokenLogitsProcessor",parameters:[{name:"bos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L562",parametersDescription:[{anchor:"transformers.ForcedBOSTokenLogitsProcessor.bos_token_id",description:`<strong>bos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the first generated token.`,name:"bos_token_id"}]}}),Zt=new b({props:{name:"class transformers.ForcedEOSTokenLogitsProcessor",anchor:"transformers.ForcedEOSTokenLogitsProcessor",parameters:[{name:"max_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L583",parametersDescription:[{anchor:"transformers.ForcedEOSTokenLogitsProcessor.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length of the sequence to be generated.`,name:"max_length"},{anchor:"transformers.ForcedEOSTokenLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the last generated token when <code>max_length</code> is reached.`,name:"eos_token_id"}]}}),eo=new b({props:{name:"class transformers.InfNanRemoveLogitsProcessor",anchor:"transformers.InfNanRemoveLogitsProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_logits_process.py#L608"}}),to=new b({props:{name:"class transformers.FlaxLogitsProcessor",anchor:"transformers.FlaxLogitsProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L52"}}),oo=new b({props:{name:"__call__",anchor:"transformers.FlaxLogitsProcessor.__call__",parameters:[{name:"input_ids",val:": ndarray"},{name:"scores",val:": ndarray"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L55",parametersDescription:[{anchor:"transformers.FlaxLogitsProcessor.__call__.input_ids",description:`<strong>input_ids</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FlaxLogitsProcessor.__call__.scores",description:`<strong>scores</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),ro=new b({props:{name:"class transformers.FlaxLogitsProcessorList",anchor:"transformers.FlaxLogitsProcessorList",parameters:[{name:"iterable",val:" = ()"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L74"}}),no=new b({props:{name:"__call__",anchor:"transformers.FlaxLogitsProcessorList.__call__",parameters:[{name:"input_ids",val:": ndarray"},{name:"scores",val:": ndarray"},{name:"cur_len",val:": int"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L82",parametersDescription:[{anchor:"transformers.FlaxLogitsProcessorList.__call__.input_ids",description:`<strong>input_ids</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FlaxLogitsProcessorList.__call__.scores",description:`<strong>scores</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),so=new b({props:{name:"class transformers.FlaxLogitsWarper",anchor:"transformers.FlaxLogitsWarper",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L63"}}),ao=new b({props:{name:"__call__",anchor:"transformers.FlaxLogitsWarper.__call__",parameters:[{name:"input_ids",val:": ndarray"},{name:"scores",val:": ndarray"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L66",parametersDescription:[{anchor:"transformers.FlaxLogitsWarper.__call__.input_ids",description:`<strong>input_ids</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FlaxLogitsWarper.__call__.scores",description:`<strong>scores</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),io=new b({props:{name:"class transformers.FlaxTemperatureLogitsWarper",anchor:"transformers.FlaxTemperatureLogitsWarper",parameters:[{name:"temperature",val:": float"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L98",parametersDescription:[{anchor:"transformers.FlaxTemperatureLogitsWarper.temperature",description:`<strong>temperature</strong> (<code>float</code>) &#x2014;
The value used to module the logits distribution.`,name:"temperature"}]}}),co=new b({props:{name:"class transformers.FlaxTopPLogitsWarper",anchor:"transformers.FlaxTopPLogitsWarper",parameters:[{name:"top_p",val:": float"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L118",parametersDescription:[{anchor:"transformers.FlaxTopPLogitsWarper.top_p",description:`<strong>top_p</strong> (<code>float</code>) &#x2014;
If set to &lt; 1, only the most probable tokens with probabilities that add up to <code>top_p</code> or higher are
kept for generation.`,name:"top_p"},{anchor:"transformers.FlaxTopPLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.FlaxTopPLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),lo=new b({props:{name:"class transformers.FlaxTopKLogitsWarper",anchor:"transformers.FlaxTopKLogitsWarper",parameters:[{name:"top_k",val:": int"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L160",parametersDescription:[{anchor:"transformers.FlaxTopKLogitsWarper.top_k",description:`<strong>top_k</strong> (<code>int</code>) &#x2014;
The number of highest probability vocabulary tokens to keep for top-k-filtering.`,name:"top_k"},{anchor:"transformers.FlaxTopKLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.FlaxTopKLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),po=new b({props:{name:"class transformers.FlaxForcedBOSTokenLogitsProcessor",anchor:"transformers.FlaxForcedBOSTokenLogitsProcessor",parameters:[{name:"bos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L196",parametersDescription:[{anchor:"transformers.FlaxForcedBOSTokenLogitsProcessor.bos_token_id",description:`<strong>bos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the first generated token.`,name:"bos_token_id"}]}}),fo=new b({props:{name:"class transformers.FlaxForcedEOSTokenLogitsProcessor",anchor:"transformers.FlaxForcedEOSTokenLogitsProcessor",parameters:[{name:"max_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L220",parametersDescription:[{anchor:"transformers.FlaxForcedEOSTokenLogitsProcessor.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length of the sequence to be generated.`,name:"max_length"},{anchor:"transformers.FlaxForcedEOSTokenLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the last generated token when <code>max_length</code> is reached.`,name:"eos_token_id"}]}}),uo=new b({props:{name:"class transformers.FlaxMinLengthLogitsProcessor",anchor:"transformers.FlaxMinLengthLogitsProcessor",parameters:[{name:"min_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_flax_logits_process.py#L248",parametersDescription:[{anchor:"transformers.FlaxMinLengthLogitsProcessor.min_length",description:`<strong>min_length</strong> (<code>int</code>) &#x2014;
The minimum length below which the score of <code>eos_token_id</code> is set to <code>-float(&quot;Inf&quot;)</code>.`,name:"min_length"},{anchor:"transformers.FlaxMinLengthLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}]}}),mo=new $e({}),ho=new b({props:{name:"class transformers.StoppingCriteria",anchor:"transformers.StoppingCriteria",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L34"}}),go=new b({props:{name:"__call__",anchor:"transformers.StoppingCriteria.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L37",parametersDescription:[{anchor:"transformers.StoppingCriteria.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.StoppingCriteria.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),vo=new b({props:{name:"__call__",anchor:"transformers.StoppingCriteriaList.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L112",parametersDescription:[{anchor:"transformers.StoppingCriteriaList.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.StoppingCriteriaList.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),bo=new b({props:{name:"class transformers.MaxLengthCriteria",anchor:"transformers.MaxLengthCriteria",parameters:[{name:"max_length",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L42",parametersDescription:[{anchor:"transformers.MaxLengthCriteria.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length that the output sequence can have in number of tokens.`,name:"max_length"}]}}),yo=new b({props:{name:"__call__",anchor:"transformers.MaxLengthCriteria.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L55",parametersDescription:[{anchor:"transformers.MaxLengthCriteria.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.MaxLengthCriteria.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),$o=new b({props:{name:"class transformers.MaxTimeCriteria",anchor:"transformers.MaxTimeCriteria",parameters:[{name:"max_time",val:": float"},{name:"initial_timestamp",val:": typing.Optional[float] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L89",parametersDescription:[{anchor:"transformers.MaxTimeCriteria.max_time",description:`<strong>max_time</strong> (<code>float</code>) &#x2014;
The maximum allowed time in seconds for the generation.`,name:"max_time"},{anchor:"transformers.MaxTimeCriteria.initial_time",description:`<strong>initial_time</strong> (<code>float</code>, <em>optional</em>, defaults to <code>time.time()</code>) &#x2014;
The start of the generation allowed time.`,name:"initial_time"}]}}),xo=new b({props:{name:"__call__",anchor:"transformers.MaxTimeCriteria.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_stopping_criteria.py#L106",parametersDescription:[{anchor:"transformers.MaxTimeCriteria.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.14.1/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.MaxTimeCriteria.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),wo=new $e({}),Eo=new b({props:{name:"class transformers.BeamScorer",anchor:"transformers.BeamScorer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_beam_search.py#L88"}}),Lo=new b({props:{name:"process",anchor:"transformers.BeamScorer.process",parameters:[{name:"input_ids",val:": LongTensor"},{name:"next_scores",val:": FloatTensor"},{name:"next_tokens",val:": LongTensor"},{name:"next_indices",val:": LongTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_beam_search.py#L94",parametersDescription:[{anchor:"transformers.BeamScorer.process.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size * num_beams, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <a href="/docs/transformers/v4.14.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.BeamScorer.process.next_scores",description:`<strong>next_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, 2 * num_beams)</code>) &#x2014;
Current scores of the top <code>2 * num_beams</code> non-finished beam hypotheses.`,name:"next_scores"},{anchor:"transformers.BeamScorer.process.next_tokens",description:`<strong>next_tokens</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, 2 * num_beams)</code>) &#x2014;
<code>input_ids</code> of the tokens corresponding to the top <code>2 * num_beams</code> non-finished beam hypotheses.`,name:"next_tokens"},{anchor:"transformers.BeamScorer.process.next_indices",description:`<strong>next_indices</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, 2 * num_beams)</code>) &#x2014;
Beam indices indicating to which beam hypothesis the <code>next_tokens</code> correspond.`,name:"next_indices"},{anchor:"transformers.BeamScorer.process.pad_token_id",description:`<strong>pad_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>padding</em> token.`,name:"pad_token_id"},{anchor:"transformers.BeamScorer.process.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}],returnDescription:`
<p>A dictionary composed of the fields as defined above:</p>
<ul>
<li><strong>next_beam_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) \u2014 Updated
scores of all non-finished beams.</li>
<li><strong>next_beam_tokens</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) \u2014 Next tokens
to be added to the non-finished beam_hypotheses.</li>
<li><strong>next_beam_indices</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) \u2014 Beam indices
indicating to which beam the next tokens shall be added.</li>
</ul>
`,returnType:`
<p><code>UserDict</code></p>
`}}),Po=new b({props:{name:"finalize",anchor:"transformers.BeamScorer.finalize",parameters:[{name:"input_ids",val:": LongTensor"},{name:"next_scores",val:": FloatTensor"},{name:"next_tokens",val:": LongTensor"},{name:"next_indices",val:": LongTensor"},{name:"max_length",val:": int"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_beam_search.py#L106",parametersDescription:[{anchor:"transformers.BeamScorer.finalize.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size * num_beams, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <a href="/docs/transformers/v4.14.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">transformers.PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.14.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">transformers.PreTrainedTokenizer.<strong>call</strong>()</a> for
details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.BeamScorer.finalize.final_beam_scores",description:`<strong>final_beam_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) &#x2014;
The final scores of all non-finished beams.`,name:"final_beam_scores"},{anchor:"transformers.BeamScorer.finalize.final_beam_tokens",description:`<strong>final_beam_tokens</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) &#x2014;
The last tokens to be added to the non-finished beam_hypotheses.`,name:"final_beam_tokens"},{anchor:"transformers.BeamScorer.finalize.final_beam_indices",description:`<strong>final_beam_indices</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) &#x2014;
The beam indices indicating to which beam the <code>final_beam_tokens</code> shall be added.`,name:"final_beam_indices"},{anchor:"transformers.BeamScorer.finalize.pad_token_id",description:`<strong>pad_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>padding</em> token.`,name:"pad_token_id"},{anchor:"transformers.BeamScorer.finalize.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}],returnDescription:`
<p>The generated
sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter if all
batches finished early due to the <code>eos_token_id</code>.</p>
`,returnType:`
<p><code>torch.LongTensor</code> of shape <code>(batch_size * num_return_sequences, sequence_length)</code></p>
`}}),Do=new b({props:{name:"class transformers.BeamSearchScorer",anchor:"transformers.BeamSearchScorer",parameters:[{name:"batch_size",val:": int"},{name:"num_beams",val:": int"},{name:"device",val:": device"},{name:"length_penalty",val:": typing.Optional[float] = 1.0"},{name:"do_early_stopping",val:": typing.Optional[bool] = False"},{name:"num_beam_hyps_to_keep",val:": typing.Optional[int] = 1"},{name:"num_beam_groups",val:": typing.Optional[int] = 1"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_beam_search.py#L120",parametersDescription:[{anchor:"transformers.BeamSearchScorer.batch_size",description:`<strong>batch_size</strong> (<code>int</code>) &#x2014;
Batch Size of <code>input_ids</code> for which standard beam search decoding is run in parallel.`,name:"batch_size"},{anchor:"transformers.BeamSearchScorer.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length of the sequence to be generated.`,name:"max_length"},{anchor:"transformers.BeamSearchScorer.num_beams",description:`<strong>num_beams</strong> (<code>int</code>) &#x2014;
Number of beams for beam search.`,name:"num_beams"},{anchor:"transformers.BeamSearchScorer.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
Defines the device type (<em>e.g.</em>, <code>&quot;cpu&quot;</code> or <code>&quot;cuda&quot;</code>) on which this instance of
<code>BeamSearchScorer</code> will be allocated.`,name:"device"},{anchor:"transformers.BeamSearchScorer.length_penalty",description:`<strong>length_penalty</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
Exponential penalty to the length. 1.0 means no penalty. Set to values &lt; 1.0 in order to encourage the
model to generate shorter sequences, to a value &gt; 1.0 in order to encourage the model to produce longer
sequences.`,name:"length_penalty"},{anchor:"transformers.BeamSearchScorer.do_early_stopping",description:`<strong>do_early_stopping</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to stop the beam search when at least <code>num_beams</code> sentences are finished per batch or not.`,name:"do_early_stopping"},{anchor:"transformers.BeamSearchScorer.num_beam_hyps_to_keep",description:`<strong>num_beam_hyps_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of beam hypotheses that shall be returned upon calling
<code>finalize</code>.`,name:"num_beam_hyps_to_keep"},{anchor:"transformers.BeamSearchScorer.num_beam_groups",description:`<strong>num_beam_groups</strong> (<code>int</code>) &#x2014;
Number of groups to divide <code>num_beams</code> into in order to ensure diversity among different groups of
beams. See <a href="https://arxiv.org/pdf/1610.02424.pdf" rel="nofollow">this paper</a> for more details.`,name:"num_beam_groups"}]}}),Oo=new $e({}),qo=new b({props:{name:"transformers.top_k_top_p_filtering",anchor:"transformers.top_k_top_p_filtering",parameters:[{name:"logits",val:": FloatTensor"},{name:"top_k",val:": int = 0"},{name:"top_p",val:": float = 1.0"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_utils.py#L2569",parametersDescription:[{anchor:"transformers.top_k_top_p_filtering.top_k",description:`<strong>top_k</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
If &gt; 0, only keep the top k tokens with highest probability (top-k filtering)`,name:"top_k"},{anchor:"transformers.top_k_top_p_filtering.top_p",description:`<strong>top_p</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
If &lt; 1.0, only keep the top tokens with cumulative probability &gt;= top_p (nucleus filtering). Nucleus
filtering is described in Holtzman et al. (<a href="http://arxiv.org/abs/1904.09751" rel="nofollow">http://arxiv.org/abs/1904.09751</a>)`,name:"top_p"},{anchor:"transformers.top_k_top_p_filtering.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimumber of tokens we keep per batch example in the output.`,name:"min_tokens_to_keep"}]}}),Io=new b({props:{name:"transformers.tf_top_k_top_p_filtering",anchor:"transformers.tf_top_k_top_p_filtering",parameters:[{name:"logits",val:""},{name:"top_k",val:" = 0"},{name:"top_p",val:" = 1.0"},{name:"filter_value",val:" = -inf"},{name:"min_tokens_to_keep",val:" = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/generation_tf_utils.py#L1543",parametersDescription:[{anchor:"transformers.tf_top_k_top_p_filtering.top_k",description:`<strong>top_k</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
If &gt; 0, only keep the top k tokens with highest probability (top-k filtering)`,name:"top_k"},{anchor:"transformers.tf_top_k_top_p_filtering.top_p",description:`<strong>top_p</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
If &lt; 1.0, only keep the top tokens with cumulative probability &gt;= top_p (nucleus filtering). Nucleus
filtering is described in Holtzman et al. (<a href="http://arxiv.org/abs/1904.09751" rel="nofollow">http://arxiv.org/abs/1904.09751</a>)`,name:"top_p"},{anchor:"transformers.tf_top_k_top_p_filtering.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimumber of tokens we keep per batch example in the output.`,name:"min_tokens_to_keep"}]}}),{c(){ge=r("meta"),Wo=l(),O=r("h1"),N=r("a"),Wn=r("span"),u(ut.$$.fragment),Ec=l(),Vn=r("span"),Lc=a("Utilities for Generation"),Ba=l(),T=r("p"),Pc=a("This page lists all the utility functions used by "),Vo=r("a"),Dc=a("generate()"),zc=a(`,
`),Mo=r("a"),Fc=a("greedy_search()"),Sc=a(`,
`),Co=r("a"),Oc=a("sample()"),qc=a(`,
`),Go=r("a"),Bc=a("beam_search()"),Ic=a(`,
`),Ho=r("a"),Ac=a("beam_sample()"),Nc=a(`, and
`),jo=r("a"),Wc=a("group_beam_search()"),Vc=a("."),Ia=l(),Ro=r("p"),Mc=a("Most of those are only useful if you are studying the code of the generate methods in the library."),Aa=l(),ke=r("h2"),Ce=r("a"),Mn=r("span"),u(mt.$$.fragment),Cc=l(),Cn=r("span"),Gc=a("Generate Outputs"),Na=l(),q=r("p"),Hc=a("The output of "),Ko=r("a"),jc=a("generate()"),Rc=a(` is an instance of a subclass of
`),Uo=r("a"),Kc=a("ModelOutput"),Uc=a(`. This output is a data structure containing all the information returned
by `),Yo=r("a"),Yc=a("generate()"),Xc=a(", but that can also be used as tuple or dictionary."),Wa=l(),Xo=r("p"),Jc=a("Here\u2019s an example:"),Va=l(),u(ht.$$.fragment),Ma=l(),_e=r("p"),Qc=a("The "),Gn=r("code"),Zc=a("generation_output"),el=a(" object is a "),Jo=r("a"),tl=a("GreedySearchDecoderOnlyOutput"),ol=a(`, as we can
see in the documentation of that class below, it means it has the following attributes:`),Ca=l(),B=r("ul"),Qo=r("li"),Hn=r("code"),rl=a("sequences"),nl=a(": the generated sequences of tokens"),sl=l(),Zo=r("li"),jn=r("code"),al=a("scores"),il=a(" (optional): the prediction scores of the language modelling head, for each generation step"),cl=l(),er=r("li"),Rn=r("code"),ll=a("hidden_states"),dl=a(" (optional): the hidden states of the model, for each generation step"),pl=l(),tr=r("li"),Kn=r("code"),fl=a("attentions"),ul=a(" (optional): the attention weights of the model, for each generation step"),Ga=l(),y=r("p"),ml=a("Here we have the "),Un=r("code"),hl=a("scores"),gl=a(" since we passed along "),Yn=r("code"),_l=a("output_scores=True"),vl=a(", but we don\u2019t have "),Xn=r("code"),bl=a("hidden_states"),Tl=a(` and
`),Jn=r("code"),yl=a("attentions"),$l=a(" because we didn\u2019t pass "),Qn=r("code"),kl=a("output_hidden_states=True"),xl=a(" or "),Zn=r("code"),wl=a("output_attentions=True"),El=a("."),Ha=l(),w=r("p"),Ll=a(`You can access each attribute as you would usually do, and if that attribute has not been returned by the model, you
will get `),es=r("code"),Pl=a("None"),Dl=a(". Here for instance "),ts=r("code"),zl=a("generation_output.scores"),Fl=a(` are all the generated prediction scores of the
language modeling head, and `),os=r("code"),Sl=a("generation_output.attentions"),Ol=a(" is "),rs=r("code"),ql=a("None"),Bl=a("."),ja=l(),E=r("p"),Il=a("When using our "),ns=r("code"),Al=a("generation_output"),Nl=a(" object as a tuple, it only keeps the attributes that don\u2019t have "),ss=r("code"),Wl=a("None"),Vl=a(` values.
Here, for instance, it has two elements, `),as=r("code"),Ml=a("loss"),Cl=a(" then "),is=r("code"),Gl=a("logits"),Hl=a(", so"),Ra=l(),u(gt.$$.fragment),Ka=l(),Ge=r("p"),jl=a("will return the tuple "),cs=r("code"),Rl=a("(generation_output.sequences, generation_output.scores)"),Kl=a(" for instance."),Ua=l(),L=r("p"),Ul=a("When using our "),ls=r("code"),Yl=a("generation_output"),Xl=a(" object as a dictionary, it only keeps the attributes that don\u2019t have "),ds=r("code"),Jl=a("None"),Ql=a(`
values. Here, for instance, it has two keys that are `),ps=r("code"),Zl=a("sequences"),ed=a(" and "),fs=r("code"),td=a("scores"),od=a("."),Ya=l(),or=r("p"),rd=a("We document here all output types."),Xa=l(),xe=r("h3"),He=r("a"),us=r("span"),u(_t.$$.fragment),nd=l(),ms=r("span"),sd=a("GreedySearchOutput"),Ja=l(),we=r("div"),u(vt.$$.fragment),ad=l(),hs=r("p"),id=a("Base class for outputs of decoder-only generation models using greedy search."),Qa=l(),Ee=r("div"),u(bt.$$.fragment),cd=l(),gs=r("p"),ld=a(`Base class for outputs of encoder-decoder generation models using greedy search. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Za=l(),W=r("div"),u(Tt.$$.fragment),dd=l(),_s=r("p"),pd=a("Flax Base class for outputs of decoder-only generation models using greedy search."),fd=l(),je=r("div"),u(yt.$$.fragment),ud=l(),vs=r("p"),md=a("\u201CReturns a new object replacing the specified fields with new values."),ei=l(),Le=r("h3"),Re=r("a"),bs=r("span"),u($t.$$.fragment),hd=l(),Ts=r("span"),gd=a("SampleOutput"),ti=l(),Pe=r("div"),u(kt.$$.fragment),_d=l(),ys=r("p"),vd=a("Base class for outputs of decoder-only generation models using sampling."),oi=l(),De=r("div"),u(xt.$$.fragment),bd=l(),$s=r("p"),Td=a(`Base class for outputs of encoder-decoder generation models using sampling. Hidden states and attention weights of
the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),ri=l(),V=r("div"),u(wt.$$.fragment),yd=l(),ks=r("p"),$d=a("Flax Base class for outputs of decoder-only generation models using sampling."),kd=l(),Ke=r("div"),u(Et.$$.fragment),xd=l(),xs=r("p"),wd=a("\u201CReturns a new object replacing the specified fields with new values."),ni=l(),ze=r("h3"),Ue=r("a"),ws=r("span"),u(Lt.$$.fragment),Ed=l(),Es=r("span"),Ld=a("BeamSearchOutput"),si=l(),Fe=r("div"),u(Pt.$$.fragment),Pd=l(),Ls=r("p"),Dd=a("Base class for outputs of decoder-only generation models using beam search."),ai=l(),Se=r("div"),u(Dt.$$.fragment),zd=l(),Ps=r("p"),Fd=a(`Base class for outputs of encoder-decoder generation models using beam search. Hidden states and attention weights
of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),ii=l(),Oe=r("h3"),Ye=r("a"),Ds=r("span"),u(zt.$$.fragment),Sd=l(),zs=r("span"),Od=a("BeamSampleOutput"),ci=l(),qe=r("div"),u(Ft.$$.fragment),qd=l(),Fs=r("p"),Bd=a("Base class for outputs of decoder-only generation models using beam sample."),li=l(),Be=r("div"),u(St.$$.fragment),Id=l(),Ss=r("p"),Ad=a(`Base class for outputs of encoder-decoder generation models using beam sampling. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),di=l(),Ie=r("h2"),Xe=r("a"),Os=r("span"),u(Ot.$$.fragment),Nd=l(),qs=r("span"),Wd=a("LogitsProcessor"),pi=l(),Je=r("p"),Vd=a("A "),rr=r("a"),Md=a("LogitsProcessor"),Cd=a(` can be used to modify the prediction scores of a language model head for
generation.`),fi=l(),M=r("div"),u(qt.$$.fragment),Gd=l(),Bs=r("p"),Hd=a("Abstract base class for all logit processors that can be applied during generation."),jd=l(),Qe=r("div"),u(Bt.$$.fragment),Rd=l(),Is=r("p"),Kd=a("Torch method for processing logits."),ui=l(),C=r("div"),u(It.$$.fragment),Ud=l(),$=r("p"),Yd=a("This class can be used to create a list of "),nr=r("a"),Xd=a("LogitsProcessor"),Jd=a(` or
`),sr=r("a"),Qd=a("LogitsWarper"),Zd=a(" to subsequently process a "),As=r("code"),ep=a("scores"),tp=a(` input tensor. This class inherits from
list and adds a specific `),Ns=r("strong"),Ws=r("em"),op=a("call"),rp=a(" method to apply each "),ar=r("a"),np=a("LogitsProcessor"),sp=a(` or
`),ir=r("a"),ap=a("LogitsWarper"),ip=a(" to the inputs."),cp=l(),cr=r("div"),u(At.$$.fragment),mi=l(),G=r("div"),u(Nt.$$.fragment),lp=l(),Vs=r("p"),dp=a("Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),pp=l(),Ze=r("div"),u(Wt.$$.fragment),fp=l(),Ms=r("p"),up=a("Torch method for warping logits."),hi=l(),H=r("div"),u(Vt.$$.fragment),mp=l(),lr=r("p"),dr=r("a"),hp=a("transformers.LogitsProcessor"),gp=a(" enforcing a min-length by setting EOS probability to 0."),_p=l(),Cs=r("div"),gi=l(),j=r("div"),u(Mt.$$.fragment),vp=l(),pr=r("p"),fr=r("a"),bp=a("transformers.LogitsWarper"),Tp=a(" for temperature (exponential scaling output probability distribution)."),yp=l(),Gs=r("div"),_i=l(),R=r("div"),u(Ct.$$.fragment),$p=l(),ur=r("p"),mr=r("a"),kp=a("transformers.LogitsProcessor"),xp=a(" enforcing an exponential penalty on repeated sequences."),wp=l(),Hs=r("div"),vi=l(),K=r("div"),u(Gt.$$.fragment),Ep=l(),hr=r("p"),gr=r("a"),Lp=a("transformers.LogitsWarper"),Pp=a(` that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <=
prob_cut_off.`),Dp=l(),js=r("div"),bi=l(),U=r("div"),u(Ht.$$.fragment),zp=l(),_r=r("p"),vr=r("a"),Fp=a("transformers.LogitsWarper"),Sp=a(" that performs top-k, i.e. restricting to the k highest probability elements."),Op=l(),Rs=r("div"),Ti=l(),Y=r("div"),u(jt.$$.fragment),qp=l(),et=r("p"),br=r("a"),Bp=a("transformers.LogitsProcessor"),Ip=a(" that enforces no repetition of n-grams. See "),Rt=r("a"),Ap=a("Fairseq"),Np=a("."),Wp=l(),Ks=r("div"),yi=l(),X=r("div"),u(Kt.$$.fragment),Vp=l(),Tr=r("p"),yr=r("a"),Mp=a("transformers.LogitsProcessor"),Cp=a(" that enforces that specified sequences will never be sampled."),Gp=l(),Us=r("div"),$i=l(),J=r("div"),u(Ut.$$.fragment),Hp=l(),tt=r("p"),$r=r("a"),jp=a("transformers.LogitsProcessor"),Rp=a(` that enforces constrained generation and is useful for prefix-conditioned
constrained generation. See `),Yt=r("a"),Kp=a("Autoregressive Entity Retrieval"),Up=a(` for more
information.`),Yp=l(),Ys=r("div"),ki=l(),Q=r("div"),u(Xt.$$.fragment),Xp=l(),ve=r("p"),kr=r("a"),Jp=a("transformers.LogitsProcessor"),Qp=a(` that enforces diverse beam search. Note that this logits processor is only
effective for `),xr=r("a"),Zp=a("transformers.PreTrainedModel.group_beam_search()"),ef=a(". See "),Jt=r("a"),tf=a(`Diverse Beam Search: Decoding Diverse
Solutions from Neural Sequence Models`),of=a(" for more details."),rf=l(),Xs=r("div"),xi=l(),Z=r("div"),u(Qt.$$.fragment),nf=l(),wr=r("p"),Er=r("a"),sf=a("LogitsProcessor"),af=a(" that enforces the specified token as the first generated token."),cf=l(),Js=r("div"),wi=l(),ee=r("div"),u(Zt.$$.fragment),lf=l(),ot=r("p"),Lr=r("a"),df=a("LogitsProcessor"),pf=a(` that enforces the specified token as the last generated token when
`),Qs=r("code"),ff=a("max_length"),uf=a(" is reached."),mf=l(),Zs=r("div"),Ei=l(),te=r("div"),u(eo.$$.fragment),hf=l(),I=r("p"),Pr=r("a"),gf=a("LogitsProcessor"),_f=a(" that removes all "),ea=r("code"),vf=a("nan"),bf=a(" and "),ta=r("code"),Tf=a("inf"),yf=a(` values to avoid the generation
method to fail. Note that using the logits processor should only be used if necessary since it can slow down the
generation method. `),oa=r("code"),$f=a("max_length"),kf=a(" is reached."),xf=l(),ra=r("div"),Li=l(),oe=r("div"),u(to.$$.fragment),wf=l(),na=r("p"),Ef=a("Abstract base class for all logit processors that can be applied during generation."),Lf=l(),rt=r("div"),u(oo.$$.fragment),Pf=l(),sa=r("p"),Df=a("Flax method for processing logits."),Pi=l(),re=r("div"),u(ro.$$.fragment),zf=l(),k=r("p"),Ff=a("This class can be used to create a list of "),Dr=r("a"),Sf=a("FlaxLogitsProcessor"),Of=a(` or
`),zr=r("a"),qf=a("FlaxLogitsWarper"),Bf=a(" to subsequently process a "),aa=r("code"),If=a("scores"),Af=a(` input tensor. This class inherits
from list and adds a specific `),ia=r("strong"),ca=r("em"),Nf=a("call"),Wf=a(" method to apply each "),Fr=r("a"),Vf=a("FlaxLogitsProcessor"),Mf=a(` or
`),Sr=r("a"),Cf=a("FlaxLogitsWarper"),Gf=a(" to the inputs."),Hf=l(),Or=r("div"),u(no.$$.fragment),Di=l(),ne=r("div"),u(so.$$.fragment),jf=l(),la=r("p"),Rf=a("Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),Kf=l(),nt=r("div"),u(ao.$$.fragment),Uf=l(),da=r("p"),Yf=a("Flax method for warping logits."),zi=l(),se=r("div"),u(io.$$.fragment),Xf=l(),qr=r("p"),Br=r("a"),Jf=a("transformers.LogitsWarper"),Qf=a(" for temperature (exponential scaling output probability distribution)."),Zf=l(),pa=r("div"),Fi=l(),ae=r("div"),u(co.$$.fragment),eu=l(),Ir=r("p"),Ar=r("a"),tu=a("transformers.LogitsWarper"),ou=a(` that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <=
prob_cut_off.`),ru=l(),fa=r("div"),Si=l(),ie=r("div"),u(lo.$$.fragment),nu=l(),Nr=r("p"),Wr=r("a"),su=a("transformers.LogitsWarper"),au=a(" that performs top-k, i.e. restricting to the k highest probability elements."),iu=l(),ua=r("div"),Oi=l(),ce=r("div"),u(po.$$.fragment),cu=l(),Vr=r("p"),Mr=r("a"),lu=a("FlaxLogitsProcessor"),du=a(" that enforces the specified token as the first generated token."),pu=l(),ma=r("div"),qi=l(),le=r("div"),u(fo.$$.fragment),fu=l(),st=r("p"),Cr=r("a"),uu=a("FlaxLogitsProcessor"),mu=a(` that enforces the specified token as the last generated token when
`),ha=r("code"),hu=a("max_length"),gu=a(" is reached."),_u=l(),ga=r("div"),Bi=l(),de=r("div"),u(uo.$$.fragment),vu=l(),Gr=r("p"),Hr=r("a"),bu=a("transformers.FlaxLogitsProcessor"),Tu=a(" enforcing a min-length by setting EOS probability to 0."),yu=l(),_a=r("div"),Ii=l(),Ae=r("h2"),at=r("a"),va=r("span"),u(mo.$$.fragment),$u=l(),ba=r("span"),ku=a("StoppingCriteria"),Ai=l(),it=r("p"),xu=a("A "),jr=r("a"),wu=a("StoppingCriteria"),Eu=a(" can be used to change when to stop generation (other than EOS token)."),Ni=l(),pe=r("div"),u(ho.$$.fragment),Lu=l(),Ta=r("p"),Pu=a("Abstract base class for all stopping criteria that can be applied during generation."),Du=l(),Rr=r("div"),u(go.$$.fragment),Wi=l(),_o=r("div"),Kr=r("div"),u(vo.$$.fragment),Vi=l(),fe=r("div"),u(bo.$$.fragment),zu=l(),To=r("p"),Fu=a("This class can be used to stop generation whenever the full generated number of tokens exceeds "),ya=r("code"),Su=a("max_length"),Ou=a(`.
Keep in mind for decoder-only type of transformers, this will include the initial prompted tokens.`),qu=l(),Ur=r("div"),u(yo.$$.fragment),Mi=l(),ue=r("div"),u($o.$$.fragment),Bu=l(),ko=r("p"),Iu=a(`This class can be used to stop generation whenever the full generation exceeds some amount of time. By default, the
time will start being counted when you initialize this function. You can override this by passing an
`),$a=r("code"),Au=a("initial_time"),Nu=a("."),Wu=l(),Yr=r("div"),u(xo.$$.fragment),Ci=l(),Ne=r("h2"),ct=r("a"),ka=r("span"),u(wo.$$.fragment),Vu=l(),xa=r("span"),Mu=a("BeamSearch"),Gi=l(),S=r("div"),u(Eo.$$.fragment),Cu=l(),We=r("p"),Gu=a("Abstract base class for all beam scorers that are used for "),Xr=r("a"),Hu=a("beam_search()"),ju=a(` and
`),Jr=r("a"),Ru=a("beam_sample()"),Ku=a("."),Uu=l(),Qr=r("div"),u(Lo.$$.fragment),Yu=l(),Zr=r("div"),u(Po.$$.fragment),Hi=l(),x=r("div"),u(Do.$$.fragment),Xu=l(),en=r("p"),tn=r("a"),Ju=a("transformers.BeamScorer"),Qu=a(" implementing standard beam search decoding."),Zu=l(),zo=r("p"),em=a("Adapted in part from "),Fo=r("a"),tm=a("Facebook\u2019s XLM beam search code"),om=a("."),rm=l(),on=r("p"),nm=a("Reference for the diverse beam search algorithm and implementation "),So=r("a"),sm=a("Ashwin Kalyan\u2019s DBS implementation"),am=l(),wa=r("div"),im=l(),Ea=r("div"),ji=l(),Ve=r("h2"),lt=r("a"),La=r("span"),u(Oo.$$.fragment),cm=l(),Pa=r("span"),lm=a("Utilities"),Ri=l(),me=r("div"),u(qo.$$.fragment),dm=l(),Da=r("p"),pm=a("Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),fm=l(),rn=r("p"),um=a("From: "),Bo=r("a"),mm=a("https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),Ki=l(),he=r("div"),u(Io.$$.fragment),hm=l(),za=r("p"),gm=a("Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),_m=l(),nn=r("p"),vm=a("From: "),Ao=r("a"),bm=a("https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),this.h()},l(e){const p=O_('[data-svelte="svelte-1phssyn"]',document.head);ge=n(p,"META",{name:!0,content:!0}),p.forEach(o),Wo=d(e),O=n(e,"H1",{class:!0});var Yi=s(O);N=n(Yi,"A",{id:!0,class:!0,href:!0});var Vm=s(N);Wn=n(Vm,"SPAN",{});var Mm=s(Wn);m(ut.$$.fragment,Mm),Mm.forEach(o),Vm.forEach(o),Ec=d(Yi),Vn=n(Yi,"SPAN",{});var Cm=s(Vn);Lc=i(Cm,"Utilities for Generation"),Cm.forEach(o),Yi.forEach(o),Ba=d(e),T=n(e,"P",{});var P=s(T);Pc=i(P,"This page lists all the utility functions used by "),Vo=n(P,"A",{href:!0});var Gm=s(Vo);Dc=i(Gm,"generate()"),Gm.forEach(o),zc=i(P,`,
`),Mo=n(P,"A",{href:!0});var Hm=s(Mo);Fc=i(Hm,"greedy_search()"),Hm.forEach(o),Sc=i(P,`,
`),Co=n(P,"A",{href:!0});var jm=s(Co);Oc=i(jm,"sample()"),jm.forEach(o),qc=i(P,`,
`),Go=n(P,"A",{href:!0});var Rm=s(Go);Bc=i(Rm,"beam_search()"),Rm.forEach(o),Ic=i(P,`,
`),Ho=n(P,"A",{href:!0});var Km=s(Ho);Ac=i(Km,"beam_sample()"),Km.forEach(o),Nc=i(P,`, and
`),jo=n(P,"A",{href:!0});var Um=s(jo);Wc=i(Um,"group_beam_search()"),Um.forEach(o),Vc=i(P,"."),P.forEach(o),Ia=d(e),Ro=n(e,"P",{});var Ym=s(Ro);Mc=i(Ym,"Most of those are only useful if you are studying the code of the generate methods in the library."),Ym.forEach(o),Aa=d(e),ke=n(e,"H2",{class:!0});var Xi=s(ke);Ce=n(Xi,"A",{id:!0,class:!0,href:!0});var Xm=s(Ce);Mn=n(Xm,"SPAN",{});var Jm=s(Mn);m(mt.$$.fragment,Jm),Jm.forEach(o),Xm.forEach(o),Cc=d(Xi),Cn=n(Xi,"SPAN",{});var Qm=s(Cn);Gc=i(Qm,"Generate Outputs"),Qm.forEach(o),Xi.forEach(o),Na=d(e),q=n(e,"P",{});var dt=s(q);Hc=i(dt,"The output of "),Ko=n(dt,"A",{href:!0});var Zm=s(Ko);jc=i(Zm,"generate()"),Zm.forEach(o),Rc=i(dt,` is an instance of a subclass of
`),Uo=n(dt,"A",{href:!0});var eh=s(Uo);Kc=i(eh,"ModelOutput"),eh.forEach(o),Uc=i(dt,`. This output is a data structure containing all the information returned
by `),Yo=n(dt,"A",{href:!0});var th=s(Yo);Yc=i(th,"generate()"),th.forEach(o),Xc=i(dt,", but that can also be used as tuple or dictionary."),dt.forEach(o),Wa=d(e),Xo=n(e,"P",{});var oh=s(Xo);Jc=i(oh,"Here\u2019s an example:"),oh.forEach(o),Va=d(e),m(ht.$$.fragment,e),Ma=d(e),_e=n(e,"P",{});var sn=s(_e);Qc=i(sn,"The "),Gn=n(sn,"CODE",{});var rh=s(Gn);Zc=i(rh,"generation_output"),rh.forEach(o),el=i(sn," object is a "),Jo=n(sn,"A",{href:!0});var nh=s(Jo);tl=i(nh,"GreedySearchDecoderOnlyOutput"),nh.forEach(o),ol=i(sn,`, as we can
see in the documentation of that class below, it means it has the following attributes:`),sn.forEach(o),Ca=d(e),B=n(e,"UL",{});var pt=s(B);Qo=n(pt,"LI",{});var Tm=s(Qo);Hn=n(Tm,"CODE",{});var sh=s(Hn);rl=i(sh,"sequences"),sh.forEach(o),nl=i(Tm,": the generated sequences of tokens"),Tm.forEach(o),sl=d(pt),Zo=n(pt,"LI",{});var ym=s(Zo);jn=n(ym,"CODE",{});var ah=s(jn);al=i(ah,"scores"),ah.forEach(o),il=i(ym," (optional): the prediction scores of the language modelling head, for each generation step"),ym.forEach(o),cl=d(pt),er=n(pt,"LI",{});var $m=s(er);Rn=n($m,"CODE",{});var ih=s(Rn);ll=i(ih,"hidden_states"),ih.forEach(o),dl=i($m," (optional): the hidden states of the model, for each generation step"),$m.forEach(o),pl=d(pt),tr=n(pt,"LI",{});var km=s(tr);Kn=n(km,"CODE",{});var ch=s(Kn);fl=i(ch,"attentions"),ch.forEach(o),ul=i(km," (optional): the attention weights of the model, for each generation step"),km.forEach(o),pt.forEach(o),Ga=d(e),y=n(e,"P",{});var D=s(y);ml=i(D,"Here we have the "),Un=n(D,"CODE",{});var lh=s(Un);hl=i(lh,"scores"),lh.forEach(o),gl=i(D," since we passed along "),Yn=n(D,"CODE",{});var dh=s(Yn);_l=i(dh,"output_scores=True"),dh.forEach(o),vl=i(D,", but we don\u2019t have "),Xn=n(D,"CODE",{});var ph=s(Xn);bl=i(ph,"hidden_states"),ph.forEach(o),Tl=i(D,` and
`),Jn=n(D,"CODE",{});var fh=s(Jn);yl=i(fh,"attentions"),fh.forEach(o),$l=i(D," because we didn\u2019t pass "),Qn=n(D,"CODE",{});var uh=s(Qn);kl=i(uh,"output_hidden_states=True"),uh.forEach(o),xl=i(D," or "),Zn=n(D,"CODE",{});var mh=s(Zn);wl=i(mh,"output_attentions=True"),mh.forEach(o),El=i(D,"."),D.forEach(o),Ha=d(e),w=n(e,"P",{});var be=s(w);Ll=i(be,`You can access each attribute as you would usually do, and if that attribute has not been returned by the model, you
will get `),es=n(be,"CODE",{});var hh=s(es);Pl=i(hh,"None"),hh.forEach(o),Dl=i(be,". Here for instance "),ts=n(be,"CODE",{});var gh=s(ts);zl=i(gh,"generation_output.scores"),gh.forEach(o),Fl=i(be,` are all the generated prediction scores of the
language modeling head, and `),os=n(be,"CODE",{});var _h=s(os);Sl=i(_h,"generation_output.attentions"),_h.forEach(o),Ol=i(be," is "),rs=n(be,"CODE",{});var vh=s(rs);ql=i(vh,"None"),vh.forEach(o),Bl=i(be,"."),be.forEach(o),ja=d(e),E=n(e,"P",{});var Te=s(E);Il=i(Te,"When using our "),ns=n(Te,"CODE",{});var bh=s(ns);Al=i(bh,"generation_output"),bh.forEach(o),Nl=i(Te," object as a tuple, it only keeps the attributes that don\u2019t have "),ss=n(Te,"CODE",{});var Th=s(ss);Wl=i(Th,"None"),Th.forEach(o),Vl=i(Te,` values.
Here, for instance, it has two elements, `),as=n(Te,"CODE",{});var yh=s(as);Ml=i(yh,"loss"),yh.forEach(o),Cl=i(Te," then "),is=n(Te,"CODE",{});var $h=s(is);Gl=i($h,"logits"),$h.forEach(o),Hl=i(Te,", so"),Te.forEach(o),Ra=d(e),m(gt.$$.fragment,e),Ka=d(e),Ge=n(e,"P",{});var Ji=s(Ge);jl=i(Ji,"will return the tuple "),cs=n(Ji,"CODE",{});var kh=s(cs);Rl=i(kh,"(generation_output.sequences, generation_output.scores)"),kh.forEach(o),Kl=i(Ji," for instance."),Ji.forEach(o),Ua=d(e),L=n(e,"P",{});var ye=s(L);Ul=i(ye,"When using our "),ls=n(ye,"CODE",{});var xh=s(ls);Yl=i(xh,"generation_output"),xh.forEach(o),Xl=i(ye," object as a dictionary, it only keeps the attributes that don\u2019t have "),ds=n(ye,"CODE",{});var wh=s(ds);Jl=i(wh,"None"),wh.forEach(o),Ql=i(ye,`
values. Here, for instance, it has two keys that are `),ps=n(ye,"CODE",{});var Eh=s(ps);Zl=i(Eh,"sequences"),Eh.forEach(o),ed=i(ye," and "),fs=n(ye,"CODE",{});var Lh=s(fs);td=i(Lh,"scores"),Lh.forEach(o),od=i(ye,"."),ye.forEach(o),Ya=d(e),or=n(e,"P",{});var Ph=s(or);rd=i(Ph,"We document here all output types."),Ph.forEach(o),Xa=d(e),xe=n(e,"H3",{class:!0});var Qi=s(xe);He=n(Qi,"A",{id:!0,class:!0,href:!0});var Dh=s(He);us=n(Dh,"SPAN",{});var zh=s(us);m(_t.$$.fragment,zh),zh.forEach(o),Dh.forEach(o),nd=d(Qi),ms=n(Qi,"SPAN",{});var Fh=s(ms);sd=i(Fh,"GreedySearchOutput"),Fh.forEach(o),Qi.forEach(o),Ja=d(e),we=n(e,"DIV",{class:!0});var Zi=s(we);m(vt.$$.fragment,Zi),ad=d(Zi),hs=n(Zi,"P",{});var Sh=s(hs);id=i(Sh,"Base class for outputs of decoder-only generation models using greedy search."),Sh.forEach(o),Zi.forEach(o),Qa=d(e),Ee=n(e,"DIV",{class:!0});var ec=s(Ee);m(bt.$$.fragment,ec),cd=d(ec),gs=n(ec,"P",{});var Oh=s(gs);ld=i(Oh,`Base class for outputs of encoder-decoder generation models using greedy search. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Oh.forEach(o),ec.forEach(o),Za=d(e),W=n(e,"DIV",{class:!0});var an=s(W);m(Tt.$$.fragment,an),dd=d(an),_s=n(an,"P",{});var qh=s(_s);pd=i(qh,"Flax Base class for outputs of decoder-only generation models using greedy search."),qh.forEach(o),fd=d(an),je=n(an,"DIV",{class:!0});var tc=s(je);m(yt.$$.fragment,tc),ud=d(tc),vs=n(tc,"P",{});var Bh=s(vs);md=i(Bh,"\u201CReturns a new object replacing the specified fields with new values."),Bh.forEach(o),tc.forEach(o),an.forEach(o),ei=d(e),Le=n(e,"H3",{class:!0});var oc=s(Le);Re=n(oc,"A",{id:!0,class:!0,href:!0});var Ih=s(Re);bs=n(Ih,"SPAN",{});var Ah=s(bs);m($t.$$.fragment,Ah),Ah.forEach(o),Ih.forEach(o),hd=d(oc),Ts=n(oc,"SPAN",{});var Nh=s(Ts);gd=i(Nh,"SampleOutput"),Nh.forEach(o),oc.forEach(o),ti=d(e),Pe=n(e,"DIV",{class:!0});var rc=s(Pe);m(kt.$$.fragment,rc),_d=d(rc),ys=n(rc,"P",{});var Wh=s(ys);vd=i(Wh,"Base class for outputs of decoder-only generation models using sampling."),Wh.forEach(o),rc.forEach(o),oi=d(e),De=n(e,"DIV",{class:!0});var nc=s(De);m(xt.$$.fragment,nc),bd=d(nc),$s=n(nc,"P",{});var Vh=s($s);Td=i(Vh,`Base class for outputs of encoder-decoder generation models using sampling. Hidden states and attention weights of
the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Vh.forEach(o),nc.forEach(o),ri=d(e),V=n(e,"DIV",{class:!0});var cn=s(V);m(wt.$$.fragment,cn),yd=d(cn),ks=n(cn,"P",{});var Mh=s(ks);$d=i(Mh,"Flax Base class for outputs of decoder-only generation models using sampling."),Mh.forEach(o),kd=d(cn),Ke=n(cn,"DIV",{class:!0});var sc=s(Ke);m(Et.$$.fragment,sc),xd=d(sc),xs=n(sc,"P",{});var Ch=s(xs);wd=i(Ch,"\u201CReturns a new object replacing the specified fields with new values."),Ch.forEach(o),sc.forEach(o),cn.forEach(o),ni=d(e),ze=n(e,"H3",{class:!0});var ac=s(ze);Ue=n(ac,"A",{id:!0,class:!0,href:!0});var Gh=s(Ue);ws=n(Gh,"SPAN",{});var Hh=s(ws);m(Lt.$$.fragment,Hh),Hh.forEach(o),Gh.forEach(o),Ed=d(ac),Es=n(ac,"SPAN",{});var jh=s(Es);Ld=i(jh,"BeamSearchOutput"),jh.forEach(o),ac.forEach(o),si=d(e),Fe=n(e,"DIV",{class:!0});var ic=s(Fe);m(Pt.$$.fragment,ic),Pd=d(ic),Ls=n(ic,"P",{});var Rh=s(Ls);Dd=i(Rh,"Base class for outputs of decoder-only generation models using beam search."),Rh.forEach(o),ic.forEach(o),ai=d(e),Se=n(e,"DIV",{class:!0});var cc=s(Se);m(Dt.$$.fragment,cc),zd=d(cc),Ps=n(cc,"P",{});var Kh=s(Ps);Fd=i(Kh,`Base class for outputs of encoder-decoder generation models using beam search. Hidden states and attention weights
of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Kh.forEach(o),cc.forEach(o),ii=d(e),Oe=n(e,"H3",{class:!0});var lc=s(Oe);Ye=n(lc,"A",{id:!0,class:!0,href:!0});var Uh=s(Ye);Ds=n(Uh,"SPAN",{});var Yh=s(Ds);m(zt.$$.fragment,Yh),Yh.forEach(o),Uh.forEach(o),Sd=d(lc),zs=n(lc,"SPAN",{});var Xh=s(zs);Od=i(Xh,"BeamSampleOutput"),Xh.forEach(o),lc.forEach(o),ci=d(e),qe=n(e,"DIV",{class:!0});var dc=s(qe);m(Ft.$$.fragment,dc),qd=d(dc),Fs=n(dc,"P",{});var Jh=s(Fs);Bd=i(Jh,"Base class for outputs of decoder-only generation models using beam sample."),Jh.forEach(o),dc.forEach(o),li=d(e),Be=n(e,"DIV",{class:!0});var pc=s(Be);m(St.$$.fragment,pc),Id=d(pc),Ss=n(pc,"P",{});var Qh=s(Ss);Ad=i(Qh,`Base class for outputs of encoder-decoder generation models using beam sampling. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Qh.forEach(o),pc.forEach(o),di=d(e),Ie=n(e,"H2",{class:!0});var fc=s(Ie);Xe=n(fc,"A",{id:!0,class:!0,href:!0});var Zh=s(Xe);Os=n(Zh,"SPAN",{});var eg=s(Os);m(Ot.$$.fragment,eg),eg.forEach(o),Zh.forEach(o),Nd=d(fc),qs=n(fc,"SPAN",{});var tg=s(qs);Wd=i(tg,"LogitsProcessor"),tg.forEach(o),fc.forEach(o),pi=d(e),Je=n(e,"P",{});var uc=s(Je);Vd=i(uc,"A "),rr=n(uc,"A",{href:!0});var og=s(rr);Md=i(og,"LogitsProcessor"),og.forEach(o),Cd=i(uc,` can be used to modify the prediction scores of a language model head for
generation.`),uc.forEach(o),fi=d(e),M=n(e,"DIV",{class:!0});var ln=s(M);m(qt.$$.fragment,ln),Gd=d(ln),Bs=n(ln,"P",{});var rg=s(Bs);Hd=i(rg,"Abstract base class for all logit processors that can be applied during generation."),rg.forEach(o),jd=d(ln),Qe=n(ln,"DIV",{class:!0});var mc=s(Qe);m(Bt.$$.fragment,mc),Rd=d(mc),Is=n(mc,"P",{});var ng=s(Is);Kd=i(ng,"Torch method for processing logits."),ng.forEach(o),mc.forEach(o),ln.forEach(o),ui=d(e),C=n(e,"DIV",{class:!0});var dn=s(C);m(It.$$.fragment,dn),Ud=d(dn),$=n(dn,"P",{});var z=s($);Yd=i(z,"This class can be used to create a list of "),nr=n(z,"A",{href:!0});var sg=s(nr);Xd=i(sg,"LogitsProcessor"),sg.forEach(o),Jd=i(z,` or
`),sr=n(z,"A",{href:!0});var ag=s(sr);Qd=i(ag,"LogitsWarper"),ag.forEach(o),Zd=i(z," to subsequently process a "),As=n(z,"CODE",{});var ig=s(As);ep=i(ig,"scores"),ig.forEach(o),tp=i(z,` input tensor. This class inherits from
list and adds a specific `),Ns=n(z,"STRONG",{});var cg=s(Ns);Ws=n(cg,"EM",{});var lg=s(Ws);op=i(lg,"call"),lg.forEach(o),cg.forEach(o),rp=i(z," method to apply each "),ar=n(z,"A",{href:!0});var dg=s(ar);np=i(dg,"LogitsProcessor"),dg.forEach(o),sp=i(z,` or
`),ir=n(z,"A",{href:!0});var pg=s(ir);ap=i(pg,"LogitsWarper"),pg.forEach(o),ip=i(z," to the inputs."),z.forEach(o),cp=d(dn),cr=n(dn,"DIV",{class:!0});var fg=s(cr);m(At.$$.fragment,fg),fg.forEach(o),dn.forEach(o),mi=d(e),G=n(e,"DIV",{class:!0});var pn=s(G);m(Nt.$$.fragment,pn),lp=d(pn),Vs=n(pn,"P",{});var ug=s(Vs);dp=i(ug,"Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),ug.forEach(o),pp=d(pn),Ze=n(pn,"DIV",{class:!0});var hc=s(Ze);m(Wt.$$.fragment,hc),fp=d(hc),Ms=n(hc,"P",{});var mg=s(Ms);up=i(mg,"Torch method for warping logits."),mg.forEach(o),hc.forEach(o),pn.forEach(o),hi=d(e),H=n(e,"DIV",{class:!0});var fn=s(H);m(Vt.$$.fragment,fn),mp=d(fn),lr=n(fn,"P",{});var xm=s(lr);dr=n(xm,"A",{href:!0});var hg=s(dr);hp=i(hg,"transformers.LogitsProcessor"),hg.forEach(o),gp=i(xm," enforcing a min-length by setting EOS probability to 0."),xm.forEach(o),_p=d(fn),Cs=n(fn,"DIV",{class:!0}),s(Cs).forEach(o),fn.forEach(o),gi=d(e),j=n(e,"DIV",{class:!0});var un=s(j);m(Mt.$$.fragment,un),vp=d(un),pr=n(un,"P",{});var wm=s(pr);fr=n(wm,"A",{href:!0});var gg=s(fr);bp=i(gg,"transformers.LogitsWarper"),gg.forEach(o),Tp=i(wm," for temperature (exponential scaling output probability distribution)."),wm.forEach(o),yp=d(un),Gs=n(un,"DIV",{class:!0}),s(Gs).forEach(o),un.forEach(o),_i=d(e),R=n(e,"DIV",{class:!0});var mn=s(R);m(Ct.$$.fragment,mn),$p=d(mn),ur=n(mn,"P",{});var Em=s(ur);mr=n(Em,"A",{href:!0});var _g=s(mr);kp=i(_g,"transformers.LogitsProcessor"),_g.forEach(o),xp=i(Em," enforcing an exponential penalty on repeated sequences."),Em.forEach(o),wp=d(mn),Hs=n(mn,"DIV",{class:!0}),s(Hs).forEach(o),mn.forEach(o),vi=d(e),K=n(e,"DIV",{class:!0});var hn=s(K);m(Gt.$$.fragment,hn),Ep=d(hn),hr=n(hn,"P",{});var Lm=s(hr);gr=n(Lm,"A",{href:!0});var vg=s(gr);Lp=i(vg,"transformers.LogitsWarper"),vg.forEach(o),Pp=i(Lm,` that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <=
prob_cut_off.`),Lm.forEach(o),Dp=d(hn),js=n(hn,"DIV",{class:!0}),s(js).forEach(o),hn.forEach(o),bi=d(e),U=n(e,"DIV",{class:!0});var gn=s(U);m(Ht.$$.fragment,gn),zp=d(gn),_r=n(gn,"P",{});var Pm=s(_r);vr=n(Pm,"A",{href:!0});var bg=s(vr);Fp=i(bg,"transformers.LogitsWarper"),bg.forEach(o),Sp=i(Pm," that performs top-k, i.e. restricting to the k highest probability elements."),Pm.forEach(o),Op=d(gn),Rs=n(gn,"DIV",{class:!0}),s(Rs).forEach(o),gn.forEach(o),Ti=d(e),Y=n(e,"DIV",{class:!0});var _n=s(Y);m(jt.$$.fragment,_n),qp=d(_n),et=n(_n,"P",{});var Fa=s(et);br=n(Fa,"A",{href:!0});var Tg=s(br);Bp=i(Tg,"transformers.LogitsProcessor"),Tg.forEach(o),Ip=i(Fa," that enforces no repetition of n-grams. See "),Rt=n(Fa,"A",{href:!0,rel:!0});var yg=s(Rt);Ap=i(yg,"Fairseq"),yg.forEach(o),Np=i(Fa,"."),Fa.forEach(o),Wp=d(_n),Ks=n(_n,"DIV",{class:!0}),s(Ks).forEach(o),_n.forEach(o),yi=d(e),X=n(e,"DIV",{class:!0});var vn=s(X);m(Kt.$$.fragment,vn),Vp=d(vn),Tr=n(vn,"P",{});var Dm=s(Tr);yr=n(Dm,"A",{href:!0});var $g=s(yr);Mp=i($g,"transformers.LogitsProcessor"),$g.forEach(o),Cp=i(Dm," that enforces that specified sequences will never be sampled."),Dm.forEach(o),Gp=d(vn),Us=n(vn,"DIV",{class:!0}),s(Us).forEach(o),vn.forEach(o),$i=d(e),J=n(e,"DIV",{class:!0});var bn=s(J);m(Ut.$$.fragment,bn),Hp=d(bn),tt=n(bn,"P",{});var Sa=s(tt);$r=n(Sa,"A",{href:!0});var kg=s($r);jp=i(kg,"transformers.LogitsProcessor"),kg.forEach(o),Rp=i(Sa,` that enforces constrained generation and is useful for prefix-conditioned
constrained generation. See `),Yt=n(Sa,"A",{href:!0,rel:!0});var xg=s(Yt);Kp=i(xg,"Autoregressive Entity Retrieval"),xg.forEach(o),Up=i(Sa,` for more
information.`),Sa.forEach(o),Yp=d(bn),Ys=n(bn,"DIV",{class:!0}),s(Ys).forEach(o),bn.forEach(o),ki=d(e),Q=n(e,"DIV",{class:!0});var Tn=s(Q);m(Xt.$$.fragment,Tn),Xp=d(Tn),ve=n(Tn,"P",{});var No=s(ve);kr=n(No,"A",{href:!0});var wg=s(kr);Jp=i(wg,"transformers.LogitsProcessor"),wg.forEach(o),Qp=i(No,` that enforces diverse beam search. Note that this logits processor is only
effective for `),xr=n(No,"A",{href:!0});var Eg=s(xr);Zp=i(Eg,"transformers.PreTrainedModel.group_beam_search()"),Eg.forEach(o),ef=i(No,". See "),Jt=n(No,"A",{href:!0,rel:!0});var Lg=s(Jt);tf=i(Lg,`Diverse Beam Search: Decoding Diverse
Solutions from Neural Sequence Models`),Lg.forEach(o),of=i(No," for more details."),No.forEach(o),rf=d(Tn),Xs=n(Tn,"DIV",{class:!0}),s(Xs).forEach(o),Tn.forEach(o),xi=d(e),Z=n(e,"DIV",{class:!0});var yn=s(Z);m(Qt.$$.fragment,yn),nf=d(yn),wr=n(yn,"P",{});var zm=s(wr);Er=n(zm,"A",{href:!0});var Pg=s(Er);sf=i(Pg,"LogitsProcessor"),Pg.forEach(o),af=i(zm," that enforces the specified token as the first generated token."),zm.forEach(o),cf=d(yn),Js=n(yn,"DIV",{class:!0}),s(Js).forEach(o),yn.forEach(o),wi=d(e),ee=n(e,"DIV",{class:!0});var $n=s(ee);m(Zt.$$.fragment,$n),lf=d($n),ot=n($n,"P",{});var Oa=s(ot);Lr=n(Oa,"A",{href:!0});var Dg=s(Lr);df=i(Dg,"LogitsProcessor"),Dg.forEach(o),pf=i(Oa,` that enforces the specified token as the last generated token when
`),Qs=n(Oa,"CODE",{});var zg=s(Qs);ff=i(zg,"max_length"),zg.forEach(o),uf=i(Oa," is reached."),Oa.forEach(o),mf=d($n),Zs=n($n,"DIV",{class:!0}),s(Zs).forEach(o),$n.forEach(o),Ei=d(e),te=n(e,"DIV",{class:!0});var kn=s(te);m(eo.$$.fragment,kn),hf=d(kn),I=n(kn,"P",{});var Me=s(I);Pr=n(Me,"A",{href:!0});var Fg=s(Pr);gf=i(Fg,"LogitsProcessor"),Fg.forEach(o),_f=i(Me," that removes all "),ea=n(Me,"CODE",{});var Sg=s(ea);vf=i(Sg,"nan"),Sg.forEach(o),bf=i(Me," and "),ta=n(Me,"CODE",{});var Og=s(ta);Tf=i(Og,"inf"),Og.forEach(o),yf=i(Me,` values to avoid the generation
method to fail. Note that using the logits processor should only be used if necessary since it can slow down the
generation method. `),oa=n(Me,"CODE",{});var qg=s(oa);$f=i(qg,"max_length"),qg.forEach(o),kf=i(Me," is reached."),Me.forEach(o),xf=d(kn),ra=n(kn,"DIV",{class:!0}),s(ra).forEach(o),kn.forEach(o),Li=d(e),oe=n(e,"DIV",{class:!0});var xn=s(oe);m(to.$$.fragment,xn),wf=d(xn),na=n(xn,"P",{});var Bg=s(na);Ef=i(Bg,"Abstract base class for all logit processors that can be applied during generation."),Bg.forEach(o),Lf=d(xn),rt=n(xn,"DIV",{class:!0});var gc=s(rt);m(oo.$$.fragment,gc),Pf=d(gc),sa=n(gc,"P",{});var Ig=s(sa);Df=i(Ig,"Flax method for processing logits."),Ig.forEach(o),gc.forEach(o),xn.forEach(o),Pi=d(e),re=n(e,"DIV",{class:!0});var wn=s(re);m(ro.$$.fragment,wn),zf=d(wn),k=n(wn,"P",{});var F=s(k);Ff=i(F,"This class can be used to create a list of "),Dr=n(F,"A",{href:!0});var Ag=s(Dr);Sf=i(Ag,"FlaxLogitsProcessor"),Ag.forEach(o),Of=i(F,` or
`),zr=n(F,"A",{href:!0});var Ng=s(zr);qf=i(Ng,"FlaxLogitsWarper"),Ng.forEach(o),Bf=i(F," to subsequently process a "),aa=n(F,"CODE",{});var Wg=s(aa);If=i(Wg,"scores"),Wg.forEach(o),Af=i(F,` input tensor. This class inherits
from list and adds a specific `),ia=n(F,"STRONG",{});var Vg=s(ia);ca=n(Vg,"EM",{});var Mg=s(ca);Nf=i(Mg,"call"),Mg.forEach(o),Vg.forEach(o),Wf=i(F," method to apply each "),Fr=n(F,"A",{href:!0});var Cg=s(Fr);Vf=i(Cg,"FlaxLogitsProcessor"),Cg.forEach(o),Mf=i(F,` or
`),Sr=n(F,"A",{href:!0});var Gg=s(Sr);Cf=i(Gg,"FlaxLogitsWarper"),Gg.forEach(o),Gf=i(F," to the inputs."),F.forEach(o),Hf=d(wn),Or=n(wn,"DIV",{class:!0});var Hg=s(Or);m(no.$$.fragment,Hg),Hg.forEach(o),wn.forEach(o),Di=d(e),ne=n(e,"DIV",{class:!0});var En=s(ne);m(so.$$.fragment,En),jf=d(En),la=n(En,"P",{});var jg=s(la);Rf=i(jg,"Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),jg.forEach(o),Kf=d(En),nt=n(En,"DIV",{class:!0});var _c=s(nt);m(ao.$$.fragment,_c),Uf=d(_c),da=n(_c,"P",{});var Rg=s(da);Yf=i(Rg,"Flax method for warping logits."),Rg.forEach(o),_c.forEach(o),En.forEach(o),zi=d(e),se=n(e,"DIV",{class:!0});var Ln=s(se);m(io.$$.fragment,Ln),Xf=d(Ln),qr=n(Ln,"P",{});var Fm=s(qr);Br=n(Fm,"A",{href:!0});var Kg=s(Br);Jf=i(Kg,"transformers.LogitsWarper"),Kg.forEach(o),Qf=i(Fm," for temperature (exponential scaling output probability distribution)."),Fm.forEach(o),Zf=d(Ln),pa=n(Ln,"DIV",{class:!0}),s(pa).forEach(o),Ln.forEach(o),Fi=d(e),ae=n(e,"DIV",{class:!0});var Pn=s(ae);m(co.$$.fragment,Pn),eu=d(Pn),Ir=n(Pn,"P",{});var Sm=s(Ir);Ar=n(Sm,"A",{href:!0});var Ug=s(Ar);tu=i(Ug,"transformers.LogitsWarper"),Ug.forEach(o),ou=i(Sm,` that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <=
prob_cut_off.`),Sm.forEach(o),ru=d(Pn),fa=n(Pn,"DIV",{class:!0}),s(fa).forEach(o),Pn.forEach(o),Si=d(e),ie=n(e,"DIV",{class:!0});var Dn=s(ie);m(lo.$$.fragment,Dn),nu=d(Dn),Nr=n(Dn,"P",{});var Om=s(Nr);Wr=n(Om,"A",{href:!0});var Yg=s(Wr);su=i(Yg,"transformers.LogitsWarper"),Yg.forEach(o),au=i(Om," that performs top-k, i.e. restricting to the k highest probability elements."),Om.forEach(o),iu=d(Dn),ua=n(Dn,"DIV",{class:!0}),s(ua).forEach(o),Dn.forEach(o),Oi=d(e),ce=n(e,"DIV",{class:!0});var zn=s(ce);m(po.$$.fragment,zn),cu=d(zn),Vr=n(zn,"P",{});var qm=s(Vr);Mr=n(qm,"A",{href:!0});var Xg=s(Mr);lu=i(Xg,"FlaxLogitsProcessor"),Xg.forEach(o),du=i(qm," that enforces the specified token as the first generated token."),qm.forEach(o),pu=d(zn),ma=n(zn,"DIV",{class:!0}),s(ma).forEach(o),zn.forEach(o),qi=d(e),le=n(e,"DIV",{class:!0});var Fn=s(le);m(fo.$$.fragment,Fn),fu=d(Fn),st=n(Fn,"P",{});var qa=s(st);Cr=n(qa,"A",{href:!0});var Jg=s(Cr);uu=i(Jg,"FlaxLogitsProcessor"),Jg.forEach(o),mu=i(qa,` that enforces the specified token as the last generated token when
`),ha=n(qa,"CODE",{});var Qg=s(ha);hu=i(Qg,"max_length"),Qg.forEach(o),gu=i(qa," is reached."),qa.forEach(o),_u=d(Fn),ga=n(Fn,"DIV",{class:!0}),s(ga).forEach(o),Fn.forEach(o),Bi=d(e),de=n(e,"DIV",{class:!0});var Sn=s(de);m(uo.$$.fragment,Sn),vu=d(Sn),Gr=n(Sn,"P",{});var Bm=s(Gr);Hr=n(Bm,"A",{href:!0});var Zg=s(Hr);bu=i(Zg,"transformers.FlaxLogitsProcessor"),Zg.forEach(o),Tu=i(Bm," enforcing a min-length by setting EOS probability to 0."),Bm.forEach(o),yu=d(Sn),_a=n(Sn,"DIV",{class:!0}),s(_a).forEach(o),Sn.forEach(o),Ii=d(e),Ae=n(e,"H2",{class:!0});var vc=s(Ae);at=n(vc,"A",{id:!0,class:!0,href:!0});var e_=s(at);va=n(e_,"SPAN",{});var t_=s(va);m(mo.$$.fragment,t_),t_.forEach(o),e_.forEach(o),$u=d(vc),ba=n(vc,"SPAN",{});var o_=s(ba);ku=i(o_,"StoppingCriteria"),o_.forEach(o),vc.forEach(o),Ai=d(e),it=n(e,"P",{});var bc=s(it);xu=i(bc,"A "),jr=n(bc,"A",{href:!0});var r_=s(jr);wu=i(r_,"StoppingCriteria"),r_.forEach(o),Eu=i(bc," can be used to change when to stop generation (other than EOS token)."),bc.forEach(o),Ni=d(e),pe=n(e,"DIV",{class:!0});var On=s(pe);m(ho.$$.fragment,On),Lu=d(On),Ta=n(On,"P",{});var n_=s(Ta);Pu=i(n_,"Abstract base class for all stopping criteria that can be applied during generation."),n_.forEach(o),Du=d(On),Rr=n(On,"DIV",{class:!0});var s_=s(Rr);m(go.$$.fragment,s_),s_.forEach(o),On.forEach(o),Wi=d(e),_o=n(e,"DIV",{class:!0});var a_=s(_o);Kr=n(a_,"DIV",{class:!0});var i_=s(Kr);m(vo.$$.fragment,i_),i_.forEach(o),a_.forEach(o),Vi=d(e),fe=n(e,"DIV",{class:!0});var qn=s(fe);m(bo.$$.fragment,qn),zu=d(qn),To=n(qn,"P",{});var Tc=s(To);Fu=i(Tc,"This class can be used to stop generation whenever the full generated number of tokens exceeds "),ya=n(Tc,"CODE",{});var c_=s(ya);Su=i(c_,"max_length"),c_.forEach(o),Ou=i(Tc,`.
Keep in mind for decoder-only type of transformers, this will include the initial prompted tokens.`),Tc.forEach(o),qu=d(qn),Ur=n(qn,"DIV",{class:!0});var l_=s(Ur);m(yo.$$.fragment,l_),l_.forEach(o),qn.forEach(o),Mi=d(e),ue=n(e,"DIV",{class:!0});var Bn=s(ue);m($o.$$.fragment,Bn),Bu=d(Bn),ko=n(Bn,"P",{});var yc=s(ko);Iu=i(yc,`This class can be used to stop generation whenever the full generation exceeds some amount of time. By default, the
time will start being counted when you initialize this function. You can override this by passing an
`),$a=n(yc,"CODE",{});var d_=s($a);Au=i(d_,"initial_time"),d_.forEach(o),Nu=i(yc,"."),yc.forEach(o),Wu=d(Bn),Yr=n(Bn,"DIV",{class:!0});var p_=s(Yr);m(xo.$$.fragment,p_),p_.forEach(o),Bn.forEach(o),Ci=d(e),Ne=n(e,"H2",{class:!0});var $c=s(Ne);ct=n($c,"A",{id:!0,class:!0,href:!0});var f_=s(ct);ka=n(f_,"SPAN",{});var u_=s(ka);m(wo.$$.fragment,u_),u_.forEach(o),f_.forEach(o),Vu=d($c),xa=n($c,"SPAN",{});var m_=s(xa);Mu=i(m_,"BeamSearch"),m_.forEach(o),$c.forEach(o),Gi=d(e),S=n(e,"DIV",{class:!0});var ft=s(S);m(Eo.$$.fragment,ft),Cu=d(ft),We=n(ft,"P",{});var In=s(We);Gu=i(In,"Abstract base class for all beam scorers that are used for "),Xr=n(In,"A",{href:!0});var h_=s(Xr);Hu=i(h_,"beam_search()"),h_.forEach(o),ju=i(In,` and
`),Jr=n(In,"A",{href:!0});var g_=s(Jr);Ru=i(g_,"beam_sample()"),g_.forEach(o),Ku=i(In,"."),In.forEach(o),Uu=d(ft),Qr=n(ft,"DIV",{class:!0});var __=s(Qr);m(Lo.$$.fragment,__),__.forEach(o),Yu=d(ft),Zr=n(ft,"DIV",{class:!0});var v_=s(Zr);m(Po.$$.fragment,v_),v_.forEach(o),ft.forEach(o),Hi=d(e),x=n(e,"DIV",{class:!0});var A=s(x);m(Do.$$.fragment,A),Xu=d(A),en=n(A,"P",{});var Im=s(en);tn=n(Im,"A",{href:!0});var b_=s(tn);Ju=i(b_,"transformers.BeamScorer"),b_.forEach(o),Qu=i(Im," implementing standard beam search decoding."),Im.forEach(o),Zu=d(A),zo=n(A,"P",{});var kc=s(zo);em=i(kc,"Adapted in part from "),Fo=n(kc,"A",{href:!0,rel:!0});var T_=s(Fo);tm=i(T_,"Facebook\u2019s XLM beam search code"),T_.forEach(o),om=i(kc,"."),kc.forEach(o),rm=d(A),on=n(A,"P",{});var Am=s(on);nm=i(Am,"Reference for the diverse beam search algorithm and implementation "),So=n(Am,"A",{href:!0,rel:!0});var y_=s(So);sm=i(y_,"Ashwin Kalyan\u2019s DBS implementation"),y_.forEach(o),Am.forEach(o),am=d(A),wa=n(A,"DIV",{class:!0}),s(wa).forEach(o),im=d(A),Ea=n(A,"DIV",{class:!0}),s(Ea).forEach(o),A.forEach(o),ji=d(e),Ve=n(e,"H2",{class:!0});var xc=s(Ve);lt=n(xc,"A",{id:!0,class:!0,href:!0});var $_=s(lt);La=n($_,"SPAN",{});var k_=s(La);m(Oo.$$.fragment,k_),k_.forEach(o),$_.forEach(o),cm=d(xc),Pa=n(xc,"SPAN",{});var x_=s(Pa);lm=i(x_,"Utilities"),x_.forEach(o),xc.forEach(o),Ri=d(e),me=n(e,"DIV",{class:!0});var An=s(me);m(qo.$$.fragment,An),dm=d(An),Da=n(An,"P",{});var w_=s(Da);pm=i(w_,"Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),w_.forEach(o),fm=d(An),rn=n(An,"P",{});var Nm=s(rn);um=i(Nm,"From: "),Bo=n(Nm,"A",{href:!0,rel:!0});var E_=s(Bo);mm=i(E_,"https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),E_.forEach(o),Nm.forEach(o),An.forEach(o),Ki=d(e),he=n(e,"DIV",{class:!0});var Nn=s(he);m(Io.$$.fragment,Nn),hm=d(Nn),za=n(Nn,"P",{});var L_=s(za);gm=i(L_,"Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),L_.forEach(o),_m=d(Nn),nn=n(Nn,"P",{});var Wm=s(nn);vm=i(Wm,"From: "),Ao=n(Wm,"A",{href:!0,rel:!0});var P_=s(Ao);bm=i(P_,"https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),P_.forEach(o),Wm.forEach(o),Nn.forEach(o),this.h()},h(){c(ge,"name","hf:doc:metadata"),c(ge,"content",JSON.stringify(I_)),c(N,"id","utilities-for-generation"),c(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N,"href","#utilities-for-generation"),c(O,"class","relative group"),c(Vo,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),c(Mo,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.greedy_search"),c(Co,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.sample"),c(Go,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_search"),c(Ho,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_sample"),c(jo,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.group_beam_search"),c(Ce,"id","generate-outputs"),c(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ce,"href","#generate-outputs"),c(ke,"class","relative group"),c(Ko,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),c(Uo,"href","/docs/transformers/v4.14.1/en/main_classes/output#transformers.file_utils.ModelOutput"),c(Yo,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),c(Jo,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.generation_utils.GreedySearchDecoderOnlyOutput"),c(He,"id","transformers.generation_utils.GreedySearchDecoderOnlyOutput"),c(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(He,"href","#transformers.generation_utils.GreedySearchDecoderOnlyOutput"),c(xe,"class","relative group"),c(we,"class","docstring"),c(Ee,"class","docstring"),c(je,"class","docstring"),c(W,"class","docstring"),c(Re,"id","transformers.generation_utils.SampleDecoderOnlyOutput"),c(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Re,"href","#transformers.generation_utils.SampleDecoderOnlyOutput"),c(Le,"class","relative group"),c(Pe,"class","docstring"),c(De,"class","docstring"),c(Ke,"class","docstring"),c(V,"class","docstring"),c(Ue,"id","transformers.generation_utils.BeamSearchDecoderOnlyOutput"),c(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ue,"href","#transformers.generation_utils.BeamSearchDecoderOnlyOutput"),c(ze,"class","relative group"),c(Fe,"class","docstring"),c(Se,"class","docstring"),c(Ye,"id","transformers.generation_utils.BeamSampleDecoderOnlyOutput"),c(Ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ye,"href","#transformers.generation_utils.BeamSampleDecoderOnlyOutput"),c(Oe,"class","relative group"),c(qe,"class","docstring"),c(Be,"class","docstring"),c(Xe,"id","transformers.LogitsProcessor"),c(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xe,"href","#transformers.LogitsProcessor"),c(Ie,"class","relative group"),c(rr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Qe,"class","docstring"),c(M,"class","docstring"),c(nr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(sr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(ar,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(ir,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(cr,"class","docstring"),c(C,"class","docstring"),c(Ze,"class","docstring"),c(G,"class","docstring"),c(dr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Cs,"class","docstring"),c(H,"class","docstring"),c(fr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(Gs,"class","docstring"),c(j,"class","docstring"),c(mr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Hs,"class","docstring"),c(R,"class","docstring"),c(gr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(js,"class","docstring"),c(K,"class","docstring"),c(vr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(Rs,"class","docstring"),c(U,"class","docstring"),c(br,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Rt,"href","https://github.com/pytorch/fairseq/blob/a07cb6f40480928c9e0548b737aadd36ee66ac76/fairseq/sequence_generator.py#L345"),c(Rt,"rel","nofollow"),c(Ks,"class","docstring"),c(Y,"class","docstring"),c(yr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Us,"class","docstring"),c(X,"class","docstring"),c($r,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Yt,"href","https://arxiv.org/abs/2010.00904"),c(Yt,"rel","nofollow"),c(Ys,"class","docstring"),c(J,"class","docstring"),c(kr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(xr,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.group_beam_search"),c(Jt,"href","https://arxiv.org/pdf/1610.02424.pdf"),c(Jt,"rel","nofollow"),c(Xs,"class","docstring"),c(Q,"class","docstring"),c(Er,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Js,"class","docstring"),c(Z,"class","docstring"),c(Lr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(Zs,"class","docstring"),c(ee,"class","docstring"),c(Pr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsProcessor"),c(ra,"class","docstring"),c(te,"class","docstring"),c(rt,"class","docstring"),c(oe,"class","docstring"),c(Dr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(zr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsWarper"),c(Fr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(Sr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsWarper"),c(Or,"class","docstring"),c(re,"class","docstring"),c(nt,"class","docstring"),c(ne,"class","docstring"),c(Br,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(pa,"class","docstring"),c(se,"class","docstring"),c(Ar,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(fa,"class","docstring"),c(ae,"class","docstring"),c(Wr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.LogitsWarper"),c(ua,"class","docstring"),c(ie,"class","docstring"),c(Mr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(ma,"class","docstring"),c(ce,"class","docstring"),c(Cr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(ga,"class","docstring"),c(le,"class","docstring"),c(Hr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(_a,"class","docstring"),c(de,"class","docstring"),c(at,"id","transformers.StoppingCriteria"),c(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(at,"href","#transformers.StoppingCriteria"),c(Ae,"class","relative group"),c(jr,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.StoppingCriteria"),c(Rr,"class","docstring"),c(pe,"class","docstring"),c(Kr,"class","docstring"),c(_o,"class","docstring"),c(Ur,"class","docstring"),c(fe,"class","docstring"),c(Yr,"class","docstring"),c(ue,"class","docstring"),c(ct,"id","transformers.BeamScorer"),c(ct,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ct,"href","#transformers.BeamScorer"),c(Ne,"class","relative group"),c(Xr,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_search"),c(Jr,"href","/docs/transformers/v4.14.1/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_sample"),c(Qr,"class","docstring"),c(Zr,"class","docstring"),c(S,"class","docstring"),c(tn,"href","/docs/transformers/v4.14.1/en/internal/generation_utils#transformers.BeamScorer"),c(Fo,"href","https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529"),c(Fo,"rel","nofollow"),c(So,"href","https://github.com/ashwinkalyan/dbs/blob/master/dbs/beam_utils.lua"),c(So,"rel","nofollow"),c(wa,"class","docstring"),c(Ea,"class","docstring"),c(x,"class","docstring"),c(lt,"id","transformers.top_k_top_p_filtering"),c(lt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lt,"href","#transformers.top_k_top_p_filtering"),c(Ve,"class","relative group"),c(Bo,"href","https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),c(Bo,"rel","nofollow"),c(me,"class","docstring"),c(Ao,"href","https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),c(Ao,"rel","nofollow"),c(he,"class","docstring")},m(e,p){t(document.head,ge),f(e,Wo,p),f(e,O,p),t(O,N),t(N,Wn),h(ut,Wn,null),t(O,Ec),t(O,Vn),t(Vn,Lc),f(e,Ba,p),f(e,T,p),t(T,Pc),t(T,Vo),t(Vo,Dc),t(T,zc),t(T,Mo),t(Mo,Fc),t(T,Sc),t(T,Co),t(Co,Oc),t(T,qc),t(T,Go),t(Go,Bc),t(T,Ic),t(T,Ho),t(Ho,Ac),t(T,Nc),t(T,jo),t(jo,Wc),t(T,Vc),f(e,Ia,p),f(e,Ro,p),t(Ro,Mc),f(e,Aa,p),f(e,ke,p),t(ke,Ce),t(Ce,Mn),h(mt,Mn,null),t(ke,Cc),t(ke,Cn),t(Cn,Gc),f(e,Na,p),f(e,q,p),t(q,Hc),t(q,Ko),t(Ko,jc),t(q,Rc),t(q,Uo),t(Uo,Kc),t(q,Uc),t(q,Yo),t(Yo,Yc),t(q,Xc),f(e,Wa,p),f(e,Xo,p),t(Xo,Jc),f(e,Va,p),h(ht,e,p),f(e,Ma,p),f(e,_e,p),t(_e,Qc),t(_e,Gn),t(Gn,Zc),t(_e,el),t(_e,Jo),t(Jo,tl),t(_e,ol),f(e,Ca,p),f(e,B,p),t(B,Qo),t(Qo,Hn),t(Hn,rl),t(Qo,nl),t(B,sl),t(B,Zo),t(Zo,jn),t(jn,al),t(Zo,il),t(B,cl),t(B,er),t(er,Rn),t(Rn,ll),t(er,dl),t(B,pl),t(B,tr),t(tr,Kn),t(Kn,fl),t(tr,ul),f(e,Ga,p),f(e,y,p),t(y,ml),t(y,Un),t(Un,hl),t(y,gl),t(y,Yn),t(Yn,_l),t(y,vl),t(y,Xn),t(Xn,bl),t(y,Tl),t(y,Jn),t(Jn,yl),t(y,$l),t(y,Qn),t(Qn,kl),t(y,xl),t(y,Zn),t(Zn,wl),t(y,El),f(e,Ha,p),f(e,w,p),t(w,Ll),t(w,es),t(es,Pl),t(w,Dl),t(w,ts),t(ts,zl),t(w,Fl),t(w,os),t(os,Sl),t(w,Ol),t(w,rs),t(rs,ql),t(w,Bl),f(e,ja,p),f(e,E,p),t(E,Il),t(E,ns),t(ns,Al),t(E,Nl),t(E,ss),t(ss,Wl),t(E,Vl),t(E,as),t(as,Ml),t(E,Cl),t(E,is),t(is,Gl),t(E,Hl),f(e,Ra,p),h(gt,e,p),f(e,Ka,p),f(e,Ge,p),t(Ge,jl),t(Ge,cs),t(cs,Rl),t(Ge,Kl),f(e,Ua,p),f(e,L,p),t(L,Ul),t(L,ls),t(ls,Yl),t(L,Xl),t(L,ds),t(ds,Jl),t(L,Ql),t(L,ps),t(ps,Zl),t(L,ed),t(L,fs),t(fs,td),t(L,od),f(e,Ya,p),f(e,or,p),t(or,rd),f(e,Xa,p),f(e,xe,p),t(xe,He),t(He,us),h(_t,us,null),t(xe,nd),t(xe,ms),t(ms,sd),f(e,Ja,p),f(e,we,p),h(vt,we,null),t(we,ad),t(we,hs),t(hs,id),f(e,Qa,p),f(e,Ee,p),h(bt,Ee,null),t(Ee,cd),t(Ee,gs),t(gs,ld),f(e,Za,p),f(e,W,p),h(Tt,W,null),t(W,dd),t(W,_s),t(_s,pd),t(W,fd),t(W,je),h(yt,je,null),t(je,ud),t(je,vs),t(vs,md),f(e,ei,p),f(e,Le,p),t(Le,Re),t(Re,bs),h($t,bs,null),t(Le,hd),t(Le,Ts),t(Ts,gd),f(e,ti,p),f(e,Pe,p),h(kt,Pe,null),t(Pe,_d),t(Pe,ys),t(ys,vd),f(e,oi,p),f(e,De,p),h(xt,De,null),t(De,bd),t(De,$s),t($s,Td),f(e,ri,p),f(e,V,p),h(wt,V,null),t(V,yd),t(V,ks),t(ks,$d),t(V,kd),t(V,Ke),h(Et,Ke,null),t(Ke,xd),t(Ke,xs),t(xs,wd),f(e,ni,p),f(e,ze,p),t(ze,Ue),t(Ue,ws),h(Lt,ws,null),t(ze,Ed),t(ze,Es),t(Es,Ld),f(e,si,p),f(e,Fe,p),h(Pt,Fe,null),t(Fe,Pd),t(Fe,Ls),t(Ls,Dd),f(e,ai,p),f(e,Se,p),h(Dt,Se,null),t(Se,zd),t(Se,Ps),t(Ps,Fd),f(e,ii,p),f(e,Oe,p),t(Oe,Ye),t(Ye,Ds),h(zt,Ds,null),t(Oe,Sd),t(Oe,zs),t(zs,Od),f(e,ci,p),f(e,qe,p),h(Ft,qe,null),t(qe,qd),t(qe,Fs),t(Fs,Bd),f(e,li,p),f(e,Be,p),h(St,Be,null),t(Be,Id),t(Be,Ss),t(Ss,Ad),f(e,di,p),f(e,Ie,p),t(Ie,Xe),t(Xe,Os),h(Ot,Os,null),t(Ie,Nd),t(Ie,qs),t(qs,Wd),f(e,pi,p),f(e,Je,p),t(Je,Vd),t(Je,rr),t(rr,Md),t(Je,Cd),f(e,fi,p),f(e,M,p),h(qt,M,null),t(M,Gd),t(M,Bs),t(Bs,Hd),t(M,jd),t(M,Qe),h(Bt,Qe,null),t(Qe,Rd),t(Qe,Is),t(Is,Kd),f(e,ui,p),f(e,C,p),h(It,C,null),t(C,Ud),t(C,$),t($,Yd),t($,nr),t(nr,Xd),t($,Jd),t($,sr),t(sr,Qd),t($,Zd),t($,As),t(As,ep),t($,tp),t($,Ns),t(Ns,Ws),t(Ws,op),t($,rp),t($,ar),t(ar,np),t($,sp),t($,ir),t(ir,ap),t($,ip),t(C,cp),t(C,cr),h(At,cr,null),f(e,mi,p),f(e,G,p),h(Nt,G,null),t(G,lp),t(G,Vs),t(Vs,dp),t(G,pp),t(G,Ze),h(Wt,Ze,null),t(Ze,fp),t(Ze,Ms),t(Ms,up),f(e,hi,p),f(e,H,p),h(Vt,H,null),t(H,mp),t(H,lr),t(lr,dr),t(dr,hp),t(lr,gp),t(H,_p),t(H,Cs),f(e,gi,p),f(e,j,p),h(Mt,j,null),t(j,vp),t(j,pr),t(pr,fr),t(fr,bp),t(pr,Tp),t(j,yp),t(j,Gs),f(e,_i,p),f(e,R,p),h(Ct,R,null),t(R,$p),t(R,ur),t(ur,mr),t(mr,kp),t(ur,xp),t(R,wp),t(R,Hs),f(e,vi,p),f(e,K,p),h(Gt,K,null),t(K,Ep),t(K,hr),t(hr,gr),t(gr,Lp),t(hr,Pp),t(K,Dp),t(K,js),f(e,bi,p),f(e,U,p),h(Ht,U,null),t(U,zp),t(U,_r),t(_r,vr),t(vr,Fp),t(_r,Sp),t(U,Op),t(U,Rs),f(e,Ti,p),f(e,Y,p),h(jt,Y,null),t(Y,qp),t(Y,et),t(et,br),t(br,Bp),t(et,Ip),t(et,Rt),t(Rt,Ap),t(et,Np),t(Y,Wp),t(Y,Ks),f(e,yi,p),f(e,X,p),h(Kt,X,null),t(X,Vp),t(X,Tr),t(Tr,yr),t(yr,Mp),t(Tr,Cp),t(X,Gp),t(X,Us),f(e,$i,p),f(e,J,p),h(Ut,J,null),t(J,Hp),t(J,tt),t(tt,$r),t($r,jp),t(tt,Rp),t(tt,Yt),t(Yt,Kp),t(tt,Up),t(J,Yp),t(J,Ys),f(e,ki,p),f(e,Q,p),h(Xt,Q,null),t(Q,Xp),t(Q,ve),t(ve,kr),t(kr,Jp),t(ve,Qp),t(ve,xr),t(xr,Zp),t(ve,ef),t(ve,Jt),t(Jt,tf),t(ve,of),t(Q,rf),t(Q,Xs),f(e,xi,p),f(e,Z,p),h(Qt,Z,null),t(Z,nf),t(Z,wr),t(wr,Er),t(Er,sf),t(wr,af),t(Z,cf),t(Z,Js),f(e,wi,p),f(e,ee,p),h(Zt,ee,null),t(ee,lf),t(ee,ot),t(ot,Lr),t(Lr,df),t(ot,pf),t(ot,Qs),t(Qs,ff),t(ot,uf),t(ee,mf),t(ee,Zs),f(e,Ei,p),f(e,te,p),h(eo,te,null),t(te,hf),t(te,I),t(I,Pr),t(Pr,gf),t(I,_f),t(I,ea),t(ea,vf),t(I,bf),t(I,ta),t(ta,Tf),t(I,yf),t(I,oa),t(oa,$f),t(I,kf),t(te,xf),t(te,ra),f(e,Li,p),f(e,oe,p),h(to,oe,null),t(oe,wf),t(oe,na),t(na,Ef),t(oe,Lf),t(oe,rt),h(oo,rt,null),t(rt,Pf),t(rt,sa),t(sa,Df),f(e,Pi,p),f(e,re,p),h(ro,re,null),t(re,zf),t(re,k),t(k,Ff),t(k,Dr),t(Dr,Sf),t(k,Of),t(k,zr),t(zr,qf),t(k,Bf),t(k,aa),t(aa,If),t(k,Af),t(k,ia),t(ia,ca),t(ca,Nf),t(k,Wf),t(k,Fr),t(Fr,Vf),t(k,Mf),t(k,Sr),t(Sr,Cf),t(k,Gf),t(re,Hf),t(re,Or),h(no,Or,null),f(e,Di,p),f(e,ne,p),h(so,ne,null),t(ne,jf),t(ne,la),t(la,Rf),t(ne,Kf),t(ne,nt),h(ao,nt,null),t(nt,Uf),t(nt,da),t(da,Yf),f(e,zi,p),f(e,se,p),h(io,se,null),t(se,Xf),t(se,qr),t(qr,Br),t(Br,Jf),t(qr,Qf),t(se,Zf),t(se,pa),f(e,Fi,p),f(e,ae,p),h(co,ae,null),t(ae,eu),t(ae,Ir),t(Ir,Ar),t(Ar,tu),t(Ir,ou),t(ae,ru),t(ae,fa),f(e,Si,p),f(e,ie,p),h(lo,ie,null),t(ie,nu),t(ie,Nr),t(Nr,Wr),t(Wr,su),t(Nr,au),t(ie,iu),t(ie,ua),f(e,Oi,p),f(e,ce,p),h(po,ce,null),t(ce,cu),t(ce,Vr),t(Vr,Mr),t(Mr,lu),t(Vr,du),t(ce,pu),t(ce,ma),f(e,qi,p),f(e,le,p),h(fo,le,null),t(le,fu),t(le,st),t(st,Cr),t(Cr,uu),t(st,mu),t(st,ha),t(ha,hu),t(st,gu),t(le,_u),t(le,ga),f(e,Bi,p),f(e,de,p),h(uo,de,null),t(de,vu),t(de,Gr),t(Gr,Hr),t(Hr,bu),t(Gr,Tu),t(de,yu),t(de,_a),f(e,Ii,p),f(e,Ae,p),t(Ae,at),t(at,va),h(mo,va,null),t(Ae,$u),t(Ae,ba),t(ba,ku),f(e,Ai,p),f(e,it,p),t(it,xu),t(it,jr),t(jr,wu),t(it,Eu),f(e,Ni,p),f(e,pe,p),h(ho,pe,null),t(pe,Lu),t(pe,Ta),t(Ta,Pu),t(pe,Du),t(pe,Rr),h(go,Rr,null),f(e,Wi,p),f(e,_o,p),t(_o,Kr),h(vo,Kr,null),f(e,Vi,p),f(e,fe,p),h(bo,fe,null),t(fe,zu),t(fe,To),t(To,Fu),t(To,ya),t(ya,Su),t(To,Ou),t(fe,qu),t(fe,Ur),h(yo,Ur,null),f(e,Mi,p),f(e,ue,p),h($o,ue,null),t(ue,Bu),t(ue,ko),t(ko,Iu),t(ko,$a),t($a,Au),t(ko,Nu),t(ue,Wu),t(ue,Yr),h(xo,Yr,null),f(e,Ci,p),f(e,Ne,p),t(Ne,ct),t(ct,ka),h(wo,ka,null),t(Ne,Vu),t(Ne,xa),t(xa,Mu),f(e,Gi,p),f(e,S,p),h(Eo,S,null),t(S,Cu),t(S,We),t(We,Gu),t(We,Xr),t(Xr,Hu),t(We,ju),t(We,Jr),t(Jr,Ru),t(We,Ku),t(S,Uu),t(S,Qr),h(Lo,Qr,null),t(S,Yu),t(S,Zr),h(Po,Zr,null),f(e,Hi,p),f(e,x,p),h(Do,x,null),t(x,Xu),t(x,en),t(en,tn),t(tn,Ju),t(en,Qu),t(x,Zu),t(x,zo),t(zo,em),t(zo,Fo),t(Fo,tm),t(zo,om),t(x,rm),t(x,on),t(on,nm),t(on,So),t(So,sm),t(x,am),t(x,wa),t(x,im),t(x,Ea),f(e,ji,p),f(e,Ve,p),t(Ve,lt),t(lt,La),h(Oo,La,null),t(Ve,cm),t(Ve,Pa),t(Pa,lm),f(e,Ri,p),f(e,me,p),h(qo,me,null),t(me,dm),t(me,Da),t(Da,pm),t(me,fm),t(me,rn),t(rn,um),t(rn,Bo),t(Bo,mm),f(e,Ki,p),f(e,he,p),h(Io,he,null),t(he,hm),t(he,za),t(za,gm),t(he,_m),t(he,nn),t(nn,vm),t(nn,Ao),t(Ao,bm),Ui=!0},p:q_,i(e){Ui||(g(ut.$$.fragment,e),g(mt.$$.fragment,e),g(ht.$$.fragment,e),g(gt.$$.fragment,e),g(_t.$$.fragment,e),g(vt.$$.fragment,e),g(bt.$$.fragment,e),g(Tt.$$.fragment,e),g(yt.$$.fragment,e),g($t.$$.fragment,e),g(kt.$$.fragment,e),g(xt.$$.fragment,e),g(wt.$$.fragment,e),g(Et.$$.fragment,e),g(Lt.$$.fragment,e),g(Pt.$$.fragment,e),g(Dt.$$.fragment,e),g(zt.$$.fragment,e),g(Ft.$$.fragment,e),g(St.$$.fragment,e),g(Ot.$$.fragment,e),g(qt.$$.fragment,e),g(Bt.$$.fragment,e),g(It.$$.fragment,e),g(At.$$.fragment,e),g(Nt.$$.fragment,e),g(Wt.$$.fragment,e),g(Vt.$$.fragment,e),g(Mt.$$.fragment,e),g(Ct.$$.fragment,e),g(Gt.$$.fragment,e),g(Ht.$$.fragment,e),g(jt.$$.fragment,e),g(Kt.$$.fragment,e),g(Ut.$$.fragment,e),g(Xt.$$.fragment,e),g(Qt.$$.fragment,e),g(Zt.$$.fragment,e),g(eo.$$.fragment,e),g(to.$$.fragment,e),g(oo.$$.fragment,e),g(ro.$$.fragment,e),g(no.$$.fragment,e),g(so.$$.fragment,e),g(ao.$$.fragment,e),g(io.$$.fragment,e),g(co.$$.fragment,e),g(lo.$$.fragment,e),g(po.$$.fragment,e),g(fo.$$.fragment,e),g(uo.$$.fragment,e),g(mo.$$.fragment,e),g(ho.$$.fragment,e),g(go.$$.fragment,e),g(vo.$$.fragment,e),g(bo.$$.fragment,e),g(yo.$$.fragment,e),g($o.$$.fragment,e),g(xo.$$.fragment,e),g(wo.$$.fragment,e),g(Eo.$$.fragment,e),g(Lo.$$.fragment,e),g(Po.$$.fragment,e),g(Do.$$.fragment,e),g(Oo.$$.fragment,e),g(qo.$$.fragment,e),g(Io.$$.fragment,e),Ui=!0)},o(e){_(ut.$$.fragment,e),_(mt.$$.fragment,e),_(ht.$$.fragment,e),_(gt.$$.fragment,e),_(_t.$$.fragment,e),_(vt.$$.fragment,e),_(bt.$$.fragment,e),_(Tt.$$.fragment,e),_(yt.$$.fragment,e),_($t.$$.fragment,e),_(kt.$$.fragment,e),_(xt.$$.fragment,e),_(wt.$$.fragment,e),_(Et.$$.fragment,e),_(Lt.$$.fragment,e),_(Pt.$$.fragment,e),_(Dt.$$.fragment,e),_(zt.$$.fragment,e),_(Ft.$$.fragment,e),_(St.$$.fragment,e),_(Ot.$$.fragment,e),_(qt.$$.fragment,e),_(Bt.$$.fragment,e),_(It.$$.fragment,e),_(At.$$.fragment,e),_(Nt.$$.fragment,e),_(Wt.$$.fragment,e),_(Vt.$$.fragment,e),_(Mt.$$.fragment,e),_(Ct.$$.fragment,e),_(Gt.$$.fragment,e),_(Ht.$$.fragment,e),_(jt.$$.fragment,e),_(Kt.$$.fragment,e),_(Ut.$$.fragment,e),_(Xt.$$.fragment,e),_(Qt.$$.fragment,e),_(Zt.$$.fragment,e),_(eo.$$.fragment,e),_(to.$$.fragment,e),_(oo.$$.fragment,e),_(ro.$$.fragment,e),_(no.$$.fragment,e),_(so.$$.fragment,e),_(ao.$$.fragment,e),_(io.$$.fragment,e),_(co.$$.fragment,e),_(lo.$$.fragment,e),_(po.$$.fragment,e),_(fo.$$.fragment,e),_(uo.$$.fragment,e),_(mo.$$.fragment,e),_(ho.$$.fragment,e),_(go.$$.fragment,e),_(vo.$$.fragment,e),_(bo.$$.fragment,e),_(yo.$$.fragment,e),_($o.$$.fragment,e),_(xo.$$.fragment,e),_(wo.$$.fragment,e),_(Eo.$$.fragment,e),_(Lo.$$.fragment,e),_(Po.$$.fragment,e),_(Do.$$.fragment,e),_(Oo.$$.fragment,e),_(qo.$$.fragment,e),_(Io.$$.fragment,e),Ui=!1},d(e){o(ge),e&&o(Wo),e&&o(O),v(ut),e&&o(Ba),e&&o(T),e&&o(Ia),e&&o(Ro),e&&o(Aa),e&&o(ke),v(mt),e&&o(Na),e&&o(q),e&&o(Wa),e&&o(Xo),e&&o(Va),v(ht,e),e&&o(Ma),e&&o(_e),e&&o(Ca),e&&o(B),e&&o(Ga),e&&o(y),e&&o(Ha),e&&o(w),e&&o(ja),e&&o(E),e&&o(Ra),v(gt,e),e&&o(Ka),e&&o(Ge),e&&o(Ua),e&&o(L),e&&o(Ya),e&&o(or),e&&o(Xa),e&&o(xe),v(_t),e&&o(Ja),e&&o(we),v(vt),e&&o(Qa),e&&o(Ee),v(bt),e&&o(Za),e&&o(W),v(Tt),v(yt),e&&o(ei),e&&o(Le),v($t),e&&o(ti),e&&o(Pe),v(kt),e&&o(oi),e&&o(De),v(xt),e&&o(ri),e&&o(V),v(wt),v(Et),e&&o(ni),e&&o(ze),v(Lt),e&&o(si),e&&o(Fe),v(Pt),e&&o(ai),e&&o(Se),v(Dt),e&&o(ii),e&&o(Oe),v(zt),e&&o(ci),e&&o(qe),v(Ft),e&&o(li),e&&o(Be),v(St),e&&o(di),e&&o(Ie),v(Ot),e&&o(pi),e&&o(Je),e&&o(fi),e&&o(M),v(qt),v(Bt),e&&o(ui),e&&o(C),v(It),v(At),e&&o(mi),e&&o(G),v(Nt),v(Wt),e&&o(hi),e&&o(H),v(Vt),e&&o(gi),e&&o(j),v(Mt),e&&o(_i),e&&o(R),v(Ct),e&&o(vi),e&&o(K),v(Gt),e&&o(bi),e&&o(U),v(Ht),e&&o(Ti),e&&o(Y),v(jt),e&&o(yi),e&&o(X),v(Kt),e&&o($i),e&&o(J),v(Ut),e&&o(ki),e&&o(Q),v(Xt),e&&o(xi),e&&o(Z),v(Qt),e&&o(wi),e&&o(ee),v(Zt),e&&o(Ei),e&&o(te),v(eo),e&&o(Li),e&&o(oe),v(to),v(oo),e&&o(Pi),e&&o(re),v(ro),v(no),e&&o(Di),e&&o(ne),v(so),v(ao),e&&o(zi),e&&o(se),v(io),e&&o(Fi),e&&o(ae),v(co),e&&o(Si),e&&o(ie),v(lo),e&&o(Oi),e&&o(ce),v(po),e&&o(qi),e&&o(le),v(fo),e&&o(Bi),e&&o(de),v(uo),e&&o(Ii),e&&o(Ae),v(mo),e&&o(Ai),e&&o(it),e&&o(Ni),e&&o(pe),v(ho),v(go),e&&o(Wi),e&&o(_o),v(vo),e&&o(Vi),e&&o(fe),v(bo),v(yo),e&&o(Mi),e&&o(ue),v($o),v(xo),e&&o(Ci),e&&o(Ne),v(wo),e&&o(Gi),e&&o(S),v(Eo),v(Lo),v(Po),e&&o(Hi),e&&o(x),v(Do),e&&o(ji),e&&o(Ve),v(Oo),e&&o(Ri),e&&o(me),v(qo),e&&o(Ki),e&&o(he),v(Io)}}}const I_={local:"utilities-for-generation",sections:[{local:"generate-outputs",sections:[{local:"transformers.generation_utils.GreedySearchDecoderOnlyOutput",title:"GreedySearchOutput"},{local:"transformers.generation_utils.SampleDecoderOnlyOutput",title:"SampleOutput"},{local:"transformers.generation_utils.BeamSearchDecoderOnlyOutput",title:"BeamSearchOutput"},{local:"transformers.generation_utils.BeamSampleDecoderOnlyOutput",title:"BeamSampleOutput"}],title:"Generate Outputs"},{local:"transformers.LogitsProcessor",title:"LogitsProcessor"},{local:"transformers.StoppingCriteria",title:"StoppingCriteria"},{local:"transformers.BeamScorer",title:"BeamSearch"},{local:"transformers.top_k_top_p_filtering",title:"Utilities"}],title:"Utilities for Generation"};function A_(wc,ge,Wo){let{fw:O}=ge;return wc.$$set=N=>{"fw"in N&&Wo(0,O=N.fw)},[O]}class G_ extends z_{constructor(ge){super();F_(this,ge,A_,B_,S_,{fw:0})}}export{G_ as default,I_ as metadata};
