import{S as ul,i as cl,s as ml,e as i,k as p,w as g,t as a,L as dl,c as n,d as s,m as u,a as l,x as _,h as r,b as c,J as t,g as f,y as v,q as b,o as y,B as $}from"../../chunks/vendor-9e2b328e.js";import{T as nr}from"../../chunks/Tip-76f97a76.js";import{I as it}from"../../chunks/IconCopyLink-fd0e58fd.js";import{C}from"../../chunks/CodeBlock-b9ff96e9.js";import{C as xs}from"../../chunks/CodeBlockFw-0c398fb3.js";import"../../chunks/CopyButton-4b97cbf7.js";function hl(M){let m,j,d,k,q;return{c(){m=i("p"),j=a("You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),d=i("a"),k=a("configuration"),q=a(" documentation for more details."),this.h()},l(h){m=n(h,"P",{});var w=l(m);j=r(w,"You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),d=n(w,"A",{href:!0});var E=l(d);k=r(E,"configuration"),E.forEach(s),q=r(w," documentation for more details."),w.forEach(s),this.h()},h(){c(d,"href","main_classes/configuration")},m(h,w){f(h,m,w),t(m,j),t(m,d),t(d,k),t(m,q)},d(h){h&&s(m)}}}function gl(M){let m,j,d,k,q;return{c(){m=i("p"),j=a("Not every model supports a fast tokenizer. Take a look at this "),d=i("a"),k=a("table"),q=a(" to check if a model has fast tokenizer support."),this.h()},l(h){m=n(h,"P",{});var w=l(m);j=r(w,"Not every model supports a fast tokenizer. Take a look at this "),d=n(w,"A",{href:!0});var E=l(d);k=r(E,"table"),E.forEach(s),q=r(w," to check if a model has fast tokenizer support."),w.forEach(s),this.h()},h(){c(d,"href","index#supported-frameworks")},m(h,w){f(h,m,w),t(m,j),t(m,d),t(d,k),t(m,q)},d(h){h&&s(m)}}}function _l(M){let m,j,d,k,q,h,w,E,L,J,z;return{c(){m=i("p"),j=a("By default, "),d=i("a"),k=a("AutoTokenizer"),q=a(" will try to load a fast tokenizer. You can disable this behavior by setting "),h=i("code"),w=a("use_fast=False"),E=a(" in "),L=i("code"),J=a("from_pretrained"),z=a("."),this.h()},l(O){m=n(O,"P",{});var x=l(m);j=r(x,"By default, "),d=n(x,"A",{href:!0});var X=l(d);k=r(X,"AutoTokenizer"),X.forEach(s),q=r(x," will try to load a fast tokenizer. You can disable this behavior by setting "),h=n(x,"CODE",{});var nt=l(h);w=r(nt,"use_fast=False"),nt.forEach(s),E=r(x," in "),L=n(x,"CODE",{});var lt=l(L);J=r(lt,"from_pretrained"),lt.forEach(s),z=r(x,"."),x.forEach(s),this.h()},h(){c(d,"href","/docs/transformers/doc-build-test/en/model_doc/auto#transformers.AutoTokenizer")},m(O,x){f(O,m,x),t(m,j),t(m,d),t(d,k),t(m,q),t(m,h),t(h,w),t(m,E),t(m,L),t(L,J),t(m,z)},d(O){O&&s(m)}}}function vl(M){let m,j,d,k,q;return{c(){m=i("p"),j=a("If you aren\u2019t looking for any customization, just use the "),d=i("code"),k=a("from_pretrained"),q=a(" method to load a model\u2019s default feature extractor parameters.")},l(h){m=n(h,"P",{});var w=l(m);j=r(w,"If you aren\u2019t looking for any customization, just use the "),d=n(w,"CODE",{});var E=l(d);k=r(E,"from_pretrained"),E.forEach(s),q=r(w," method to load a model\u2019s default feature extractor parameters."),w.forEach(s)},m(h,w){f(h,m,w),t(m,j),t(m,d),t(d,k),t(m,q)},d(h){h&&s(m)}}}function bl(M){let m,j,d,k,q,h,w,E,L,J,z,O,x,X,nt,lt,Qt,lr,fr,Ht,pr,ur,zs,D,Ut,cr,mr,Gt,dr,hr,Jt,gr,_r,Xt,vr,br,Kt,yr,Fs,N,K,Zt,Te,$r,es,wr,Ds,F,kr,ft,jr,qr,ts,Er,Tr,ss,xr,zr,as,Fr,Dr,rs,Br,Cr,Bs,V,Ar,pt,Pr,Mr,ut,Vr,Sr,Cs,xe,As,R,ct,Ir,Wr,mt,Lr,Or,Ps,Z,ze,Nr,os,Rr,Yr,Qr,Fe,Hr,is,Ur,Gr,Ms,De,Vs,ee,Jr,dt,Xr,Kr,Ss,Be,Is,te,Zr,ht,eo,to,Ws,Ce,Ls,se,so,gt,ao,ro,Os,Ae,Ns,ae,Rs,Y,re,ns,Pe,oo,ls,io,Ys,T,no,_t,lo,fo,fs,po,uo,vt,co,mo,Me,ps,ho,go,Ve,us,_o,vo,Se,cs,bo,yo,Qs,bt,$o,Hs,Ie,Us,yt,wo,Gs,oe,ko,$t,jo,qo,Js,We,Xs,wt,Eo,Ks,Le,Zs,Q,ie,ms,Oe,To,ds,xo,ea,ne,zo,hs,Fo,Do,ta,le,Bo,kt,Co,Ao,sa,Ne,aa,fe,Po,jt,Mo,Vo,ra,Re,oa,H,pe,gs,Ye,So,_s,Io,ia,ue,Wo,qt,Lo,Oo,na,ce,Et,Tt,No,Ro,Yo,S,xt,Qo,Ho,Qe,Uo,Go,vs,Jo,Xo,la,zt,Ko,fa,me,pa,de,Zo,bs,ei,ti,ua,He,ca,he,si,Ft,ai,ri,ma,Ue,da,ge,oi,Dt,ii,ni,ha,Ge,ga,_e,_a,U,ve,ys,Je,li,$s,fi,va,A,pi,Bt,ui,ci,Ct,mi,di,At,hi,gi,ba,I,_i,Pt,vi,bi,Mt,yi,$i,ya,Xe,$a,be,wa,ye,wi,Vt,ki,ji,ka,Ke,ja,$e,qi,St,Ei,Ti,qa,Ze,Ea,G,we,ws,et,xi,ks,zi,Ta,ke,Fi,It,Di,Bi,xa,Wt,Ci,za,tt,Fa,Lt,Ai,Da,st,Ba,je,Pi,Ot,Mi,Vi,Ca,at,Aa,Nt,Si,Pa;return h=new it({}),Te=new it({}),xe=new C({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),De=new C({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Be=new C({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4),',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),Ce=new C({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path"),',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),Ae=new C({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json"),',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),ae=new nr({props:{$$slots:{default:[hl]},$$scope:{ctx:M}}}),Pe=new it({}),Ie=new xs({props:{pt:{code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`},tf:{code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}}),We=new xs({props:{pt:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'},tf:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}}),Le=new xs({props:{pt:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'},tf:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}}),Oe=new it({}),Ne=new xs({props:{pt:{code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`},tf:{code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}}),Re=new xs({props:{pt:{code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`},tf:{code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}}),Ye=new it({}),me=new nr({props:{warning:"&lcub;true}",$$slots:{default:[gl]},$$scope:{ctx:M}}}),He=new C({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),Ue=new C({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),Ge=new C({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),_e=new nr({props:{$$slots:{default:[_l]},$$scope:{ctx:M}}}),Je=new it({}),Xe=new C({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),be=new nr({props:{$$slots:{default:[vl]},$$scope:{ctx:M}}}),Ke=new C({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),Ze=new C({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),et=new it({}),tt=new C({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),st=new C({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),at=new C({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){m=i("meta"),j=p(),d=i("h1"),k=i("a"),q=i("span"),g(h.$$.fragment),w=p(),E=i("span"),L=a("Create a custom model"),J=p(),z=i("p"),O=a("An "),x=i("a"),X=i("code"),nt=a("AutoClass"),lt=a(" automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),Qt=i("code"),lr=a("AutoClass"),fr=a(" to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),Ht=i("code"),pr=a("AutoClass"),ur=a(". Learn how to:"),zs=p(),D=i("ul"),Ut=i("li"),cr=a("Load and customize a model configuration."),mr=p(),Gt=i("li"),dr=a("Create a model architecture."),hr=p(),Jt=i("li"),gr=a("Create a slow and fast tokenizer for text."),_r=p(),Xt=i("li"),vr=a("Create a feature extractor for audio or image tasks."),br=p(),Kt=i("li"),yr=a("Create a processor for multimodal tasks."),Fs=p(),N=i("h2"),K=i("a"),Zt=i("span"),g(Te.$$.fragment),$r=p(),es=i("span"),wr=a("Configuration"),Ds=p(),F=i("p"),kr=a("A "),ft=i("a"),jr=a("configuration"),qr=a(" refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),ts=i("code"),Er=a("hidden_size"),Tr=a(", "),ss=i("code"),xr=a("num_attention_heads"),zr=a(", "),as=i("code"),Fr=a("num_hidden_layers"),Dr=a(" and "),rs=i("code"),Br=a("vocab_size"),Cr=a(" attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),Bs=p(),V=i("p"),Ar=a("Get a closer look at "),pt=i("a"),Pr=a("DistilBERT"),Mr=a(" by accessing "),ut=i("a"),Vr=a("DistilBertConfig"),Sr=a(" to inspect it\u2019s attributes:"),Cs=p(),g(xe.$$.fragment),As=p(),R=i("p"),ct=i("a"),Ir=a("DistilBertConfig"),Wr=a(" displays all the default attributes used to build a base "),mt=i("a"),Lr=a("DistilBertModel"),Or=a(". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),Ps=p(),Z=i("ul"),ze=i("li"),Nr=a("Try a different activation function with the "),os=i("code"),Rr=a("activation"),Yr=a(" parameter."),Qr=p(),Fe=i("li"),Hr=a("Use a higher dropout ratio for the attention probabilities with the "),is=i("code"),Ur=a("attention_dropout"),Gr=a(" parameter."),Ms=p(),g(De.$$.fragment),Vs=p(),ee=i("p"),Jr=a("Pretrained model attributes can be modified in the "),dt=i("a"),Xr=a("from_pretrained()"),Kr=a(" function:"),Ss=p(),g(Be.$$.fragment),Is=p(),te=i("p"),Zr=a("Once you are satisfied with your model configuration, you can save it with "),ht=i("a"),eo=a("save_pretrained()"),to=a(". Your configuration file is stored as a JSON file in the specified save directory:"),Ws=p(),g(Ce.$$.fragment),Ls=p(),se=i("p"),so=a("To reuse the configuration file, load it with "),gt=i("a"),ao=a("from_pretrained()"),ro=a(":"),Os=p(),g(Ae.$$.fragment),Ns=p(),g(ae.$$.fragment),Rs=p(),Y=i("h2"),re=i("a"),ns=i("span"),g(Pe.$$.fragment),oo=p(),ls=i("span"),io=a("Model"),Ys=p(),T=i("p"),no=a("The next step is to create a "),_t=i("a"),lo=a("model"),fo=a(". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),fs=i("code"),po=a("num_hidden_layers"),uo=a(" from the configuration are used to define the architecture. Every model shares the base class "),vt=i("a"),co=a("PreTrainedModel"),mo=a(" and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),Me=i("a"),ps=i("code"),ho=a("torch.nn.Module"),go=a(", "),Ve=i("a"),us=i("code"),_o=a("tf.keras.Model"),vo=a(" or "),Se=i("a"),cs=i("code"),bo=a("flax.linen.Module"),yo=a(" subclass. This means models are compatible with each of their respective framework\u2019s usage."),Qs=p(),bt=i("p"),$o=a("Load your custom configuration attributes into the model:"),Hs=p(),g(Ie.$$.fragment),Us=p(),yt=i("p"),wo=a("This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),Gs=p(),oe=i("p"),ko=a("Create a pretrained model with "),$t=i("a"),jo=a("from_pretrained()"),qo=a(":"),Js=p(),g(We.$$.fragment),Xs=p(),wt=i("p"),Eo=a("When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),Ks=p(),g(Le.$$.fragment),Zs=p(),Q=i("h3"),ie=i("a"),ms=i("span"),g(Oe.$$.fragment),To=p(),ds=i("span"),xo=a("Model heads"),ea=p(),ne=i("p"),zo=a("At this point, you have a base DistilBERT model which outputs the "),hs=i("em"),Fo=a("hidden states"),Do=a(". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),ta=p(),le=i("p"),Bo=a("For example, "),kt=i("a"),Co=a("DistilBertForSequenceClassification"),Ao=a(" is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),sa=p(),g(Ne.$$.fragment),aa=p(),fe=i("p"),Po=a("Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),jt=i("a"),Mo=a("DistilBertForQuestionAnswering"),Vo=a(" model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),ra=p(),g(Re.$$.fragment),oa=p(),H=i("h2"),pe=i("a"),gs=i("span"),g(Ye.$$.fragment),So=p(),_s=i("span"),Io=a("Tokenizer"),ia=p(),ue=i("p"),Wo=a("The last base class you need before using a model for textual data is a "),qt=i("a"),Lo=a("tokenizer"),Oo=a(" to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),na=p(),ce=i("ul"),Et=i("li"),Tt=i("a"),No=a("PreTrainedTokenizer"),Ro=a(": a Python implementation of a tokenizer."),Yo=p(),S=i("li"),xt=i("a"),Qo=a("PreTrainedTokenizerFast"),Ho=a(": a tokenizer from our Rust-based "),Qe=i("a"),Uo=a("\u{1F917} Tokenizer"),Go=a(" library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),vs=i("em"),Jo=a("offset mapping"),Xo=a(" which maps tokens to their original words or characters."),la=p(),zt=i("p"),Ko=a("Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),fa=p(),g(me.$$.fragment),pa=p(),de=i("p"),Zo=a("If you trained your own tokenizer, you can create one from your "),bs=i("em"),ei=a("vocabulary"),ti=a(" file:"),ua=p(),g(He.$$.fragment),ca=p(),he=i("p"),si=a("It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),Ft=i("a"),ai=a("DistilBertTokenizer"),ri=a(" class:"),ma=p(),g(Ue.$$.fragment),da=p(),ge=i("p"),oi=a("Create a fast tokenizer with the "),Dt=i("a"),ii=a("DistilBertTokenizerFast"),ni=a(" class:"),ha=p(),g(Ge.$$.fragment),ga=p(),g(_e.$$.fragment),_a=p(),U=i("h2"),ve=i("a"),ys=i("span"),g(Je.$$.fragment),li=p(),$s=i("span"),fi=a("Feature Extractor"),va=p(),A=i("p"),pi=a("A feature extractor processes audio or image inputs. It inherits from the base "),Bt=i("a"),ui=a("FeatureExtractionMixin"),ci=a(" class, and may also inherit from the "),Ct=i("a"),mi=a("ImageFeatureExtractionMixin"),di=a(" class for processing image features or the "),At=i("a"),hi=a("SequenceFeatureExtractor"),gi=a(" class for processing audio inputs."),ba=p(),I=i("p"),_i=a("Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Pt=i("a"),vi=a("ViTFeatureExtractor"),bi=a(" if you are using "),Mt=i("a"),yi=a("ViT"),$i=a(" for image classification:"),ya=p(),g(Xe.$$.fragment),$a=p(),g(be.$$.fragment),wa=p(),ye=i("p"),wi=a("Modify any of the "),Vt=i("a"),ki=a("ViTFeatureExtractor"),ji=a(" parameters to create your custom feature extractor:"),ka=p(),g(Ke.$$.fragment),ja=p(),$e=i("p"),qi=a("For audio inputs, you can create a "),St=i("a"),Ei=a("Wav2Vec2FeatureExtractor"),Ti=a(" and customize the parameters in a similar way:"),qa=p(),g(Ze.$$.fragment),Ea=p(),G=i("h2"),we=i("a"),ws=i("span"),g(et.$$.fragment),xi=p(),ks=i("span"),zi=a("Processor"),Ta=p(),ke=i("p"),Fi=a("For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),It=i("a"),Di=a("Wav2Vec2Processor"),Bi=a(" for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),xa=p(),Wt=i("p"),Ci=a("Create a feature extractor to handle the audio inputs:"),za=p(),g(tt.$$.fragment),Fa=p(),Lt=i("p"),Ai=a("Create a tokenizer to handle the text inputs:"),Da=p(),g(st.$$.fragment),Ba=p(),je=i("p"),Pi=a("Combine the feature extractor and tokenizer in "),Ot=i("a"),Mi=a("Wav2Vec2Processor"),Vi=a(":"),Ca=p(),g(at.$$.fragment),Aa=p(),Nt=i("p"),Si=a("With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),this.h()},l(e){const o=dl('[data-svelte="svelte-1phssyn"]',document.head);m=n(o,"META",{name:!0,content:!0}),o.forEach(s),j=u(e),d=n(e,"H1",{class:!0});var rt=l(d);k=n(rt,"A",{id:!0,class:!0,href:!0});var js=l(k);q=n(js,"SPAN",{});var qs=l(q);_(h.$$.fragment,qs),qs.forEach(s),js.forEach(s),w=u(rt),E=n(rt,"SPAN",{});var Es=l(E);L=r(Es,"Create a custom model"),Es.forEach(s),rt.forEach(s),J=u(e),z=n(e,"P",{});var qe=l(z);O=r(qe,"An "),x=n(qe,"A",{href:!0});var Wi=l(x);X=n(Wi,"CODE",{});var Li=l(X);nt=r(Li,"AutoClass"),Li.forEach(s),Wi.forEach(s),lt=r(qe," automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),Qt=n(qe,"CODE",{});var Oi=l(Qt);lr=r(Oi,"AutoClass"),Oi.forEach(s),fr=r(qe," to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),Ht=n(qe,"CODE",{});var Ni=l(Ht);pr=r(Ni,"AutoClass"),Ni.forEach(s),ur=r(qe,". Learn how to:"),qe.forEach(s),zs=u(e),D=n(e,"UL",{});var W=l(D);Ut=n(W,"LI",{});var Ri=l(Ut);cr=r(Ri,"Load and customize a model configuration."),Ri.forEach(s),mr=u(W),Gt=n(W,"LI",{});var Yi=l(Gt);dr=r(Yi,"Create a model architecture."),Yi.forEach(s),hr=u(W),Jt=n(W,"LI",{});var Qi=l(Jt);gr=r(Qi,"Create a slow and fast tokenizer for text."),Qi.forEach(s),_r=u(W),Xt=n(W,"LI",{});var Hi=l(Xt);vr=r(Hi,"Create a feature extractor for audio or image tasks."),Hi.forEach(s),br=u(W),Kt=n(W,"LI",{});var Ui=l(Kt);yr=r(Ui,"Create a processor for multimodal tasks."),Ui.forEach(s),W.forEach(s),Fs=u(e),N=n(e,"H2",{class:!0});var Ma=l(N);K=n(Ma,"A",{id:!0,class:!0,href:!0});var Gi=l(K);Zt=n(Gi,"SPAN",{});var Ji=l(Zt);_(Te.$$.fragment,Ji),Ji.forEach(s),Gi.forEach(s),$r=u(Ma),es=n(Ma,"SPAN",{});var Xi=l(es);wr=r(Xi,"Configuration"),Xi.forEach(s),Ma.forEach(s),Ds=u(e),F=n(e,"P",{});var P=l(F);kr=r(P,"A "),ft=n(P,"A",{href:!0});var Ki=l(ft);jr=r(Ki,"configuration"),Ki.forEach(s),qr=r(P," refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),ts=n(P,"CODE",{});var Zi=l(ts);Er=r(Zi,"hidden_size"),Zi.forEach(s),Tr=r(P,", "),ss=n(P,"CODE",{});var en=l(ss);xr=r(en,"num_attention_heads"),en.forEach(s),zr=r(P,", "),as=n(P,"CODE",{});var tn=l(as);Fr=r(tn,"num_hidden_layers"),tn.forEach(s),Dr=r(P," and "),rs=n(P,"CODE",{});var sn=l(rs);Br=r(sn,"vocab_size"),sn.forEach(s),Cr=r(P," attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),P.forEach(s),Bs=u(e),V=n(e,"P",{});var Rt=l(V);Ar=r(Rt,"Get a closer look at "),pt=n(Rt,"A",{href:!0});var an=l(pt);Pr=r(an,"DistilBERT"),an.forEach(s),Mr=r(Rt," by accessing "),ut=n(Rt,"A",{href:!0});var rn=l(ut);Vr=r(rn,"DistilBertConfig"),rn.forEach(s),Sr=r(Rt," to inspect it\u2019s attributes:"),Rt.forEach(s),Cs=u(e),_(xe.$$.fragment,e),As=u(e),R=n(e,"P",{});var Ts=l(R);ct=n(Ts,"A",{href:!0});var on=l(ct);Ir=r(on,"DistilBertConfig"),on.forEach(s),Wr=r(Ts," displays all the default attributes used to build a base "),mt=n(Ts,"A",{href:!0});var nn=l(mt);Lr=r(nn,"DistilBertModel"),nn.forEach(s),Or=r(Ts,". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),Ts.forEach(s),Ps=u(e),Z=n(e,"UL",{});var Va=l(Z);ze=n(Va,"LI",{});var Sa=l(ze);Nr=r(Sa,"Try a different activation function with the "),os=n(Sa,"CODE",{});var ln=l(os);Rr=r(ln,"activation"),ln.forEach(s),Yr=r(Sa," parameter."),Sa.forEach(s),Qr=u(Va),Fe=n(Va,"LI",{});var Ia=l(Fe);Hr=r(Ia,"Use a higher dropout ratio for the attention probabilities with the "),is=n(Ia,"CODE",{});var fn=l(is);Ur=r(fn,"attention_dropout"),fn.forEach(s),Gr=r(Ia," parameter."),Ia.forEach(s),Va.forEach(s),Ms=u(e),_(De.$$.fragment,e),Vs=u(e),ee=n(e,"P",{});var Wa=l(ee);Jr=r(Wa,"Pretrained model attributes can be modified in the "),dt=n(Wa,"A",{href:!0});var pn=l(dt);Xr=r(pn,"from_pretrained()"),pn.forEach(s),Kr=r(Wa," function:"),Wa.forEach(s),Ss=u(e),_(Be.$$.fragment,e),Is=u(e),te=n(e,"P",{});var La=l(te);Zr=r(La,"Once you are satisfied with your model configuration, you can save it with "),ht=n(La,"A",{href:!0});var un=l(ht);eo=r(un,"save_pretrained()"),un.forEach(s),to=r(La,". Your configuration file is stored as a JSON file in the specified save directory:"),La.forEach(s),Ws=u(e),_(Ce.$$.fragment,e),Ls=u(e),se=n(e,"P",{});var Oa=l(se);so=r(Oa,"To reuse the configuration file, load it with "),gt=n(Oa,"A",{href:!0});var cn=l(gt);ao=r(cn,"from_pretrained()"),cn.forEach(s),ro=r(Oa,":"),Oa.forEach(s),Os=u(e),_(Ae.$$.fragment,e),Ns=u(e),_(ae.$$.fragment,e),Rs=u(e),Y=n(e,"H2",{class:!0});var Na=l(Y);re=n(Na,"A",{id:!0,class:!0,href:!0});var mn=l(re);ns=n(mn,"SPAN",{});var dn=l(ns);_(Pe.$$.fragment,dn),dn.forEach(s),mn.forEach(s),oo=u(Na),ls=n(Na,"SPAN",{});var hn=l(ls);io=r(hn,"Model"),hn.forEach(s),Na.forEach(s),Ys=u(e),T=n(e,"P",{});var B=l(T);no=r(B,"The next step is to create a "),_t=n(B,"A",{href:!0});var gn=l(_t);lo=r(gn,"model"),gn.forEach(s),fo=r(B,". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),fs=n(B,"CODE",{});var _n=l(fs);po=r(_n,"num_hidden_layers"),_n.forEach(s),uo=r(B," from the configuration are used to define the architecture. Every model shares the base class "),vt=n(B,"A",{href:!0});var vn=l(vt);co=r(vn,"PreTrainedModel"),vn.forEach(s),mo=r(B," and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),Me=n(B,"A",{href:!0,rel:!0});var bn=l(Me);ps=n(bn,"CODE",{});var yn=l(ps);ho=r(yn,"torch.nn.Module"),yn.forEach(s),bn.forEach(s),go=r(B,", "),Ve=n(B,"A",{href:!0,rel:!0});var $n=l(Ve);us=n($n,"CODE",{});var wn=l(us);_o=r(wn,"tf.keras.Model"),wn.forEach(s),$n.forEach(s),vo=r(B," or "),Se=n(B,"A",{href:!0,rel:!0});var kn=l(Se);cs=n(kn,"CODE",{});var jn=l(cs);bo=r(jn,"flax.linen.Module"),jn.forEach(s),kn.forEach(s),yo=r(B," subclass. This means models are compatible with each of their respective framework\u2019s usage."),B.forEach(s),Qs=u(e),bt=n(e,"P",{});var qn=l(bt);$o=r(qn,"Load your custom configuration attributes into the model:"),qn.forEach(s),Hs=u(e),_(Ie.$$.fragment,e),Us=u(e),yt=n(e,"P",{});var En=l(yt);wo=r(En,"This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),En.forEach(s),Gs=u(e),oe=n(e,"P",{});var Ra=l(oe);ko=r(Ra,"Create a pretrained model with "),$t=n(Ra,"A",{href:!0});var Tn=l($t);jo=r(Tn,"from_pretrained()"),Tn.forEach(s),qo=r(Ra,":"),Ra.forEach(s),Js=u(e),_(We.$$.fragment,e),Xs=u(e),wt=n(e,"P",{});var xn=l(wt);Eo=r(xn,"When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),xn.forEach(s),Ks=u(e),_(Le.$$.fragment,e),Zs=u(e),Q=n(e,"H3",{class:!0});var Ya=l(Q);ie=n(Ya,"A",{id:!0,class:!0,href:!0});var zn=l(ie);ms=n(zn,"SPAN",{});var Fn=l(ms);_(Oe.$$.fragment,Fn),Fn.forEach(s),zn.forEach(s),To=u(Ya),ds=n(Ya,"SPAN",{});var Dn=l(ds);xo=r(Dn,"Model heads"),Dn.forEach(s),Ya.forEach(s),ea=u(e),ne=n(e,"P",{});var Qa=l(ne);zo=r(Qa,"At this point, you have a base DistilBERT model which outputs the "),hs=n(Qa,"EM",{});var Bn=l(hs);Fo=r(Bn,"hidden states"),Bn.forEach(s),Do=r(Qa,". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),Qa.forEach(s),ta=u(e),le=n(e,"P",{});var Ha=l(le);Bo=r(Ha,"For example, "),kt=n(Ha,"A",{href:!0});var Cn=l(kt);Co=r(Cn,"DistilBertForSequenceClassification"),Cn.forEach(s),Ao=r(Ha," is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),Ha.forEach(s),sa=u(e),_(Ne.$$.fragment,e),aa=u(e),fe=n(e,"P",{});var Ua=l(fe);Po=r(Ua,"Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),jt=n(Ua,"A",{href:!0});var An=l(jt);Mo=r(An,"DistilBertForQuestionAnswering"),An.forEach(s),Vo=r(Ua," model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),Ua.forEach(s),ra=u(e),_(Re.$$.fragment,e),oa=u(e),H=n(e,"H2",{class:!0});var Ga=l(H);pe=n(Ga,"A",{id:!0,class:!0,href:!0});var Pn=l(pe);gs=n(Pn,"SPAN",{});var Mn=l(gs);_(Ye.$$.fragment,Mn),Mn.forEach(s),Pn.forEach(s),So=u(Ga),_s=n(Ga,"SPAN",{});var Vn=l(_s);Io=r(Vn,"Tokenizer"),Vn.forEach(s),Ga.forEach(s),ia=u(e),ue=n(e,"P",{});var Ja=l(ue);Wo=r(Ja,"The last base class you need before using a model for textual data is a "),qt=n(Ja,"A",{href:!0});var Sn=l(qt);Lo=r(Sn,"tokenizer"),Sn.forEach(s),Oo=r(Ja," to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),Ja.forEach(s),na=u(e),ce=n(e,"UL",{});var Xa=l(ce);Et=n(Xa,"LI",{});var Ii=l(Et);Tt=n(Ii,"A",{href:!0});var In=l(Tt);No=r(In,"PreTrainedTokenizer"),In.forEach(s),Ro=r(Ii,": a Python implementation of a tokenizer."),Ii.forEach(s),Yo=u(Xa),S=n(Xa,"LI",{});var ot=l(S);xt=n(ot,"A",{href:!0});var Wn=l(xt);Qo=r(Wn,"PreTrainedTokenizerFast"),Wn.forEach(s),Ho=r(ot,": a tokenizer from our Rust-based "),Qe=n(ot,"A",{href:!0,rel:!0});var Ln=l(Qe);Uo=r(Ln,"\u{1F917} Tokenizer"),Ln.forEach(s),Go=r(ot," library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),vs=n(ot,"EM",{});var On=l(vs);Jo=r(On,"offset mapping"),On.forEach(s),Xo=r(ot," which maps tokens to their original words or characters."),ot.forEach(s),Xa.forEach(s),la=u(e),zt=n(e,"P",{});var Nn=l(zt);Ko=r(Nn,"Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),Nn.forEach(s),fa=u(e),_(me.$$.fragment,e),pa=u(e),de=n(e,"P",{});var Ka=l(de);Zo=r(Ka,"If you trained your own tokenizer, you can create one from your "),bs=n(Ka,"EM",{});var Rn=l(bs);ei=r(Rn,"vocabulary"),Rn.forEach(s),ti=r(Ka," file:"),Ka.forEach(s),ua=u(e),_(He.$$.fragment,e),ca=u(e),he=n(e,"P",{});var Za=l(he);si=r(Za,"It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),Ft=n(Za,"A",{href:!0});var Yn=l(Ft);ai=r(Yn,"DistilBertTokenizer"),Yn.forEach(s),ri=r(Za," class:"),Za.forEach(s),ma=u(e),_(Ue.$$.fragment,e),da=u(e),ge=n(e,"P",{});var er=l(ge);oi=r(er,"Create a fast tokenizer with the "),Dt=n(er,"A",{href:!0});var Qn=l(Dt);ii=r(Qn,"DistilBertTokenizerFast"),Qn.forEach(s),ni=r(er," class:"),er.forEach(s),ha=u(e),_(Ge.$$.fragment,e),ga=u(e),_(_e.$$.fragment,e),_a=u(e),U=n(e,"H2",{class:!0});var tr=l(U);ve=n(tr,"A",{id:!0,class:!0,href:!0});var Hn=l(ve);ys=n(Hn,"SPAN",{});var Un=l(ys);_(Je.$$.fragment,Un),Un.forEach(s),Hn.forEach(s),li=u(tr),$s=n(tr,"SPAN",{});var Gn=l($s);fi=r(Gn,"Feature Extractor"),Gn.forEach(s),tr.forEach(s),va=u(e),A=n(e,"P",{});var Ee=l(A);pi=r(Ee,"A feature extractor processes audio or image inputs. It inherits from the base "),Bt=n(Ee,"A",{href:!0});var Jn=l(Bt);ui=r(Jn,"FeatureExtractionMixin"),Jn.forEach(s),ci=r(Ee," class, and may also inherit from the "),Ct=n(Ee,"A",{href:!0});var Xn=l(Ct);mi=r(Xn,"ImageFeatureExtractionMixin"),Xn.forEach(s),di=r(Ee," class for processing image features or the "),At=n(Ee,"A",{href:!0});var Kn=l(At);hi=r(Kn,"SequenceFeatureExtractor"),Kn.forEach(s),gi=r(Ee," class for processing audio inputs."),Ee.forEach(s),ba=u(e),I=n(e,"P",{});var Yt=l(I);_i=r(Yt,"Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Pt=n(Yt,"A",{href:!0});var Zn=l(Pt);vi=r(Zn,"ViTFeatureExtractor"),Zn.forEach(s),bi=r(Yt," if you are using "),Mt=n(Yt,"A",{href:!0});var el=l(Mt);yi=r(el,"ViT"),el.forEach(s),$i=r(Yt," for image classification:"),Yt.forEach(s),ya=u(e),_(Xe.$$.fragment,e),$a=u(e),_(be.$$.fragment,e),wa=u(e),ye=n(e,"P",{});var sr=l(ye);wi=r(sr,"Modify any of the "),Vt=n(sr,"A",{href:!0});var tl=l(Vt);ki=r(tl,"ViTFeatureExtractor"),tl.forEach(s),ji=r(sr," parameters to create your custom feature extractor:"),sr.forEach(s),ka=u(e),_(Ke.$$.fragment,e),ja=u(e),$e=n(e,"P",{});var ar=l($e);qi=r(ar,"For audio inputs, you can create a "),St=n(ar,"A",{href:!0});var sl=l(St);Ei=r(sl,"Wav2Vec2FeatureExtractor"),sl.forEach(s),Ti=r(ar," and customize the parameters in a similar way:"),ar.forEach(s),qa=u(e),_(Ze.$$.fragment,e),Ea=u(e),G=n(e,"H2",{class:!0});var rr=l(G);we=n(rr,"A",{id:!0,class:!0,href:!0});var al=l(we);ws=n(al,"SPAN",{});var rl=l(ws);_(et.$$.fragment,rl),rl.forEach(s),al.forEach(s),xi=u(rr),ks=n(rr,"SPAN",{});var ol=l(ks);zi=r(ol,"Processor"),ol.forEach(s),rr.forEach(s),Ta=u(e),ke=n(e,"P",{});var or=l(ke);Fi=r(or,"For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),It=n(or,"A",{href:!0});var il=l(It);Di=r(il,"Wav2Vec2Processor"),il.forEach(s),Bi=r(or," for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),or.forEach(s),xa=u(e),Wt=n(e,"P",{});var nl=l(Wt);Ci=r(nl,"Create a feature extractor to handle the audio inputs:"),nl.forEach(s),za=u(e),_(tt.$$.fragment,e),Fa=u(e),Lt=n(e,"P",{});var ll=l(Lt);Ai=r(ll,"Create a tokenizer to handle the text inputs:"),ll.forEach(s),Da=u(e),_(st.$$.fragment,e),Ba=u(e),je=n(e,"P",{});var ir=l(je);Pi=r(ir,"Combine the feature extractor and tokenizer in "),Ot=n(ir,"A",{href:!0});var fl=l(Ot);Mi=r(fl,"Wav2Vec2Processor"),fl.forEach(s),Vi=r(ir,":"),ir.forEach(s),Ca=u(e),_(at.$$.fragment,e),Aa=u(e),Nt=n(e,"P",{});var pl=l(Nt);Si=r(pl,"With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),pl.forEach(s),this.h()},h(){c(m,"name","hf:doc:metadata"),c(m,"content",JSON.stringify(yl)),c(k,"id","create-a-custom-model"),c(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k,"href","#create-a-custom-model"),c(d,"class","relative group"),c(x,"href","model_doc/auto"),c(K,"id","configuration"),c(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K,"href","#configuration"),c(N,"class","relative group"),c(ft,"href","main_classes/configuration"),c(pt,"href","model_doc/distilbert"),c(ut,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertConfig"),c(ct,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertConfig"),c(mt,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertModel"),c(dt,"href","/docs/transformers/doc-build-test/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),c(ht,"href","/docs/transformers/doc-build-test/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained"),c(gt,"href","/docs/transformers/doc-build-test/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),c(re,"id","model"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#model"),c(Y,"class","relative group"),c(_t,"href","main_classes/models"),c(vt,"href","/docs/transformers/doc-build-test/en/main_classes/model#transformers.PreTrainedModel"),c(Me,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),c(Me,"rel","nofollow"),c(Ve,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Ve,"rel","nofollow"),c(Se,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),c(Se,"rel","nofollow"),c($t,"href","/docs/transformers/doc-build-test/en/main_classes/model#transformers.PreTrainedModel.from_pretrained"),c(ie,"id","model-heads"),c(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ie,"href","#model-heads"),c(Q,"class","relative group"),c(kt,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(jt,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(pe,"id","tokenizer"),c(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pe,"href","#tokenizer"),c(H,"class","relative group"),c(qt,"href","main_classes/tokenizer"),c(Tt,"href","/docs/transformers/doc-build-test/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),c(xt,"href","/docs/transformers/doc-build-test/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"),c(Qe,"href","https://huggingface.co/docs/tokenizers/python/latest/"),c(Qe,"rel","nofollow"),c(Ft,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Dt,"href","/docs/transformers/doc-build-test/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(ve,"id","feature-extractor"),c(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ve,"href","#feature-extractor"),c(U,"class","relative group"),c(Bt,"href","/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),c(Ct,"href","/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.ImageFeatureExtractionMixin"),c(At,"href","/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor"),c(Pt,"href","/docs/transformers/doc-build-test/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Mt,"href","model_doc/vit"),c(Vt,"href","/docs/transformers/doc-build-test/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(St,"href","/docs/transformers/doc-build-test/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(we,"id","processor"),c(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(we,"href","#processor"),c(G,"class","relative group"),c(It,"href","/docs/transformers/doc-build-test/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ot,"href","/docs/transformers/doc-build-test/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor")},m(e,o){t(document.head,m),f(e,j,o),f(e,d,o),t(d,k),t(k,q),v(h,q,null),t(d,w),t(d,E),t(E,L),f(e,J,o),f(e,z,o),t(z,O),t(z,x),t(x,X),t(X,nt),t(z,lt),t(z,Qt),t(Qt,lr),t(z,fr),t(z,Ht),t(Ht,pr),t(z,ur),f(e,zs,o),f(e,D,o),t(D,Ut),t(Ut,cr),t(D,mr),t(D,Gt),t(Gt,dr),t(D,hr),t(D,Jt),t(Jt,gr),t(D,_r),t(D,Xt),t(Xt,vr),t(D,br),t(D,Kt),t(Kt,yr),f(e,Fs,o),f(e,N,o),t(N,K),t(K,Zt),v(Te,Zt,null),t(N,$r),t(N,es),t(es,wr),f(e,Ds,o),f(e,F,o),t(F,kr),t(F,ft),t(ft,jr),t(F,qr),t(F,ts),t(ts,Er),t(F,Tr),t(F,ss),t(ss,xr),t(F,zr),t(F,as),t(as,Fr),t(F,Dr),t(F,rs),t(rs,Br),t(F,Cr),f(e,Bs,o),f(e,V,o),t(V,Ar),t(V,pt),t(pt,Pr),t(V,Mr),t(V,ut),t(ut,Vr),t(V,Sr),f(e,Cs,o),v(xe,e,o),f(e,As,o),f(e,R,o),t(R,ct),t(ct,Ir),t(R,Wr),t(R,mt),t(mt,Lr),t(R,Or),f(e,Ps,o),f(e,Z,o),t(Z,ze),t(ze,Nr),t(ze,os),t(os,Rr),t(ze,Yr),t(Z,Qr),t(Z,Fe),t(Fe,Hr),t(Fe,is),t(is,Ur),t(Fe,Gr),f(e,Ms,o),v(De,e,o),f(e,Vs,o),f(e,ee,o),t(ee,Jr),t(ee,dt),t(dt,Xr),t(ee,Kr),f(e,Ss,o),v(Be,e,o),f(e,Is,o),f(e,te,o),t(te,Zr),t(te,ht),t(ht,eo),t(te,to),f(e,Ws,o),v(Ce,e,o),f(e,Ls,o),f(e,se,o),t(se,so),t(se,gt),t(gt,ao),t(se,ro),f(e,Os,o),v(Ae,e,o),f(e,Ns,o),v(ae,e,o),f(e,Rs,o),f(e,Y,o),t(Y,re),t(re,ns),v(Pe,ns,null),t(Y,oo),t(Y,ls),t(ls,io),f(e,Ys,o),f(e,T,o),t(T,no),t(T,_t),t(_t,lo),t(T,fo),t(T,fs),t(fs,po),t(T,uo),t(T,vt),t(vt,co),t(T,mo),t(T,Me),t(Me,ps),t(ps,ho),t(T,go),t(T,Ve),t(Ve,us),t(us,_o),t(T,vo),t(T,Se),t(Se,cs),t(cs,bo),t(T,yo),f(e,Qs,o),f(e,bt,o),t(bt,$o),f(e,Hs,o),v(Ie,e,o),f(e,Us,o),f(e,yt,o),t(yt,wo),f(e,Gs,o),f(e,oe,o),t(oe,ko),t(oe,$t),t($t,jo),t(oe,qo),f(e,Js,o),v(We,e,o),f(e,Xs,o),f(e,wt,o),t(wt,Eo),f(e,Ks,o),v(Le,e,o),f(e,Zs,o),f(e,Q,o),t(Q,ie),t(ie,ms),v(Oe,ms,null),t(Q,To),t(Q,ds),t(ds,xo),f(e,ea,o),f(e,ne,o),t(ne,zo),t(ne,hs),t(hs,Fo),t(ne,Do),f(e,ta,o),f(e,le,o),t(le,Bo),t(le,kt),t(kt,Co),t(le,Ao),f(e,sa,o),v(Ne,e,o),f(e,aa,o),f(e,fe,o),t(fe,Po),t(fe,jt),t(jt,Mo),t(fe,Vo),f(e,ra,o),v(Re,e,o),f(e,oa,o),f(e,H,o),t(H,pe),t(pe,gs),v(Ye,gs,null),t(H,So),t(H,_s),t(_s,Io),f(e,ia,o),f(e,ue,o),t(ue,Wo),t(ue,qt),t(qt,Lo),t(ue,Oo),f(e,na,o),f(e,ce,o),t(ce,Et),t(Et,Tt),t(Tt,No),t(Et,Ro),t(ce,Yo),t(ce,S),t(S,xt),t(xt,Qo),t(S,Ho),t(S,Qe),t(Qe,Uo),t(S,Go),t(S,vs),t(vs,Jo),t(S,Xo),f(e,la,o),f(e,zt,o),t(zt,Ko),f(e,fa,o),v(me,e,o),f(e,pa,o),f(e,de,o),t(de,Zo),t(de,bs),t(bs,ei),t(de,ti),f(e,ua,o),v(He,e,o),f(e,ca,o),f(e,he,o),t(he,si),t(he,Ft),t(Ft,ai),t(he,ri),f(e,ma,o),v(Ue,e,o),f(e,da,o),f(e,ge,o),t(ge,oi),t(ge,Dt),t(Dt,ii),t(ge,ni),f(e,ha,o),v(Ge,e,o),f(e,ga,o),v(_e,e,o),f(e,_a,o),f(e,U,o),t(U,ve),t(ve,ys),v(Je,ys,null),t(U,li),t(U,$s),t($s,fi),f(e,va,o),f(e,A,o),t(A,pi),t(A,Bt),t(Bt,ui),t(A,ci),t(A,Ct),t(Ct,mi),t(A,di),t(A,At),t(At,hi),t(A,gi),f(e,ba,o),f(e,I,o),t(I,_i),t(I,Pt),t(Pt,vi),t(I,bi),t(I,Mt),t(Mt,yi),t(I,$i),f(e,ya,o),v(Xe,e,o),f(e,$a,o),v(be,e,o),f(e,wa,o),f(e,ye,o),t(ye,wi),t(ye,Vt),t(Vt,ki),t(ye,ji),f(e,ka,o),v(Ke,e,o),f(e,ja,o),f(e,$e,o),t($e,qi),t($e,St),t(St,Ei),t($e,Ti),f(e,qa,o),v(Ze,e,o),f(e,Ea,o),f(e,G,o),t(G,we),t(we,ws),v(et,ws,null),t(G,xi),t(G,ks),t(ks,zi),f(e,Ta,o),f(e,ke,o),t(ke,Fi),t(ke,It),t(It,Di),t(ke,Bi),f(e,xa,o),f(e,Wt,o),t(Wt,Ci),f(e,za,o),v(tt,e,o),f(e,Fa,o),f(e,Lt,o),t(Lt,Ai),f(e,Da,o),v(st,e,o),f(e,Ba,o),f(e,je,o),t(je,Pi),t(je,Ot),t(Ot,Mi),t(je,Vi),f(e,Ca,o),v(at,e,o),f(e,Aa,o),f(e,Nt,o),t(Nt,Si),Pa=!0},p(e,[o]){const rt={};o&2&&(rt.$$scope={dirty:o,ctx:e}),ae.$set(rt);const js={};o&2&&(js.$$scope={dirty:o,ctx:e}),me.$set(js);const qs={};o&2&&(qs.$$scope={dirty:o,ctx:e}),_e.$set(qs);const Es={};o&2&&(Es.$$scope={dirty:o,ctx:e}),be.$set(Es)},i(e){Pa||(b(h.$$.fragment,e),b(Te.$$.fragment,e),b(xe.$$.fragment,e),b(De.$$.fragment,e),b(Be.$$.fragment,e),b(Ce.$$.fragment,e),b(Ae.$$.fragment,e),b(ae.$$.fragment,e),b(Pe.$$.fragment,e),b(Ie.$$.fragment,e),b(We.$$.fragment,e),b(Le.$$.fragment,e),b(Oe.$$.fragment,e),b(Ne.$$.fragment,e),b(Re.$$.fragment,e),b(Ye.$$.fragment,e),b(me.$$.fragment,e),b(He.$$.fragment,e),b(Ue.$$.fragment,e),b(Ge.$$.fragment,e),b(_e.$$.fragment,e),b(Je.$$.fragment,e),b(Xe.$$.fragment,e),b(be.$$.fragment,e),b(Ke.$$.fragment,e),b(Ze.$$.fragment,e),b(et.$$.fragment,e),b(tt.$$.fragment,e),b(st.$$.fragment,e),b(at.$$.fragment,e),Pa=!0)},o(e){y(h.$$.fragment,e),y(Te.$$.fragment,e),y(xe.$$.fragment,e),y(De.$$.fragment,e),y(Be.$$.fragment,e),y(Ce.$$.fragment,e),y(Ae.$$.fragment,e),y(ae.$$.fragment,e),y(Pe.$$.fragment,e),y(Ie.$$.fragment,e),y(We.$$.fragment,e),y(Le.$$.fragment,e),y(Oe.$$.fragment,e),y(Ne.$$.fragment,e),y(Re.$$.fragment,e),y(Ye.$$.fragment,e),y(me.$$.fragment,e),y(He.$$.fragment,e),y(Ue.$$.fragment,e),y(Ge.$$.fragment,e),y(_e.$$.fragment,e),y(Je.$$.fragment,e),y(Xe.$$.fragment,e),y(be.$$.fragment,e),y(Ke.$$.fragment,e),y(Ze.$$.fragment,e),y(et.$$.fragment,e),y(tt.$$.fragment,e),y(st.$$.fragment,e),y(at.$$.fragment,e),Pa=!1},d(e){s(m),e&&s(j),e&&s(d),$(h),e&&s(J),e&&s(z),e&&s(zs),e&&s(D),e&&s(Fs),e&&s(N),$(Te),e&&s(Ds),e&&s(F),e&&s(Bs),e&&s(V),e&&s(Cs),$(xe,e),e&&s(As),e&&s(R),e&&s(Ps),e&&s(Z),e&&s(Ms),$(De,e),e&&s(Vs),e&&s(ee),e&&s(Ss),$(Be,e),e&&s(Is),e&&s(te),e&&s(Ws),$(Ce,e),e&&s(Ls),e&&s(se),e&&s(Os),$(Ae,e),e&&s(Ns),$(ae,e),e&&s(Rs),e&&s(Y),$(Pe),e&&s(Ys),e&&s(T),e&&s(Qs),e&&s(bt),e&&s(Hs),$(Ie,e),e&&s(Us),e&&s(yt),e&&s(Gs),e&&s(oe),e&&s(Js),$(We,e),e&&s(Xs),e&&s(wt),e&&s(Ks),$(Le,e),e&&s(Zs),e&&s(Q),$(Oe),e&&s(ea),e&&s(ne),e&&s(ta),e&&s(le),e&&s(sa),$(Ne,e),e&&s(aa),e&&s(fe),e&&s(ra),$(Re,e),e&&s(oa),e&&s(H),$(Ye),e&&s(ia),e&&s(ue),e&&s(na),e&&s(ce),e&&s(la),e&&s(zt),e&&s(fa),$(me,e),e&&s(pa),e&&s(de),e&&s(ua),$(He,e),e&&s(ca),e&&s(he),e&&s(ma),$(Ue,e),e&&s(da),e&&s(ge),e&&s(ha),$(Ge,e),e&&s(ga),$(_e,e),e&&s(_a),e&&s(U),$(Je),e&&s(va),e&&s(A),e&&s(ba),e&&s(I),e&&s(ya),$(Xe,e),e&&s($a),$(be,e),e&&s(wa),e&&s(ye),e&&s(ka),$(Ke,e),e&&s(ja),e&&s($e),e&&s(qa),$(Ze,e),e&&s(Ea),e&&s(G),$(et),e&&s(Ta),e&&s(ke),e&&s(xa),e&&s(Wt),e&&s(za),$(tt,e),e&&s(Fa),e&&s(Lt),e&&s(Da),$(st,e),e&&s(Ba),e&&s(je),e&&s(Ca),$(at,e),e&&s(Aa),e&&s(Nt)}}}const yl={local:"create-a-custom-model",sections:[{local:"configuration",title:"Configuration"},{local:"model",sections:[{local:"model-heads",title:"Model heads"}],title:"Model"},{local:"tokenizer",title:"Tokenizer"},{local:"feature-extractor",title:"Feature Extractor"},{local:"processor",title:"Processor"}],title:"Create a custom model"};function $l(M,m,j){let{fw:d}=m;return M.$$set=k=>{"fw"in k&&j(0,d=k.fw)},[d]}class xl extends ul{constructor(m){super();cl(this,m,$l,bl,ml,{fw:0})}}export{xl as default,yl as metadata};
