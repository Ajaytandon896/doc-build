import{S as yp,i as Pp,s as qp,e as r,k as i,w as u,t as n,L as Ap,c as a,d as s,m as c,a as o,x as m,h as l,b as d,J as t,g as f,y as _,q as g,o as v,B as b}from"../../../chunks/vendor-9e2b328e.js";import{T as wi}from"../../../chunks/Tip-76f97a76.js";import{D as P}from"../../../chunks/Docstring-50fd6873.js";import{C as eo}from"../../../chunks/CodeBlock-b9ff96e9.js";import{I as le}from"../../../chunks/IconCopyLink-fd0e58fd.js";import"../../../chunks/CopyButton-4b97cbf7.js";function kp(J){let h,A,$,x,N,q,O,M;return{c(){h=r("p"),A=n(`This class method is simply calling the feature extractor
`),$=r("a"),x=n("from_pretrained()"),N=n(` and the tokenizer
`),q=r("code"),O=n("from_pretrained"),M=n(` methods. Please refer to the docstrings of the
methods above for more information.`),this.h()},l(L){h=a(L,"P",{});var E=o(h);A=l(E,`This class method is simply calling the feature extractor
`),$=a(E,"A",{href:!0});var j=o($);x=l(j,"from_pretrained()"),j.forEach(s),N=l(E,` and the tokenizer
`),q=a(E,"CODE",{});var B=o(q);O=l(B,"from_pretrained"),B.forEach(s),M=l(E,` methods. Please refer to the docstrings of the
methods above for more information.`),E.forEach(s),this.h()},h(){d($,"href","/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained")},m(L,E){f(L,h,E),t(h,A),t(h,$),t($,x),t(h,N),t(h,q),t(q,O),t(h,M)},d(L){L&&s(h)}}}function Sp(J){let h,A;return{c(){h=r("p"),A=n("This API is experimental and may have some slight breaking changes in the next releases.")},l($){h=a($,"P",{});var x=o(h);A=l(x,"This API is experimental and may have some slight breaking changes in the next releases."),x.forEach(s)},m($,x){f($,h,x),t(h,A)},d($){$&&s(h)}}}function Ip(J){let h,A,$,x,N,q,O,M;return{c(){h=r("p"),A=n("This class method is simply calling "),$=r("a"),x=n("save_pretrained()"),N=n(` and
`),q=r("code"),O=n("save_pretrained"),M=n(`. Please refer to the docstrings of the methods
above for more information.`),this.h()},l(L){h=a(L,"P",{});var E=o(h);A=l(E,"This class method is simply calling "),$=a(E,"A",{href:!0});var j=o($);x=l(j,"save_pretrained()"),j.forEach(s),N=l(E,` and
`),q=a(E,"CODE",{});var B=o(q);O=l(B,"save_pretrained"),B.forEach(s),M=l(E,`. Please refer to the docstrings of the methods
above for more information.`),E.forEach(s),this.h()},h(){d($,"href","/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained")},m(L,E){f(L,h,E),t(h,A),t(h,$),t($,x),t(h,N),t(h,q),t(q,O),t(h,M)},d(L){L&&s(h)}}}function Lp(J){let h,A,$,x,N,q,O,M,L,E,j,B,Sr,ie,K,to,Qt,so,ro,Ut,ao,oo,no,_s,lo,Ir,Y,ce,gs,Qe,io,vs,co,Lr,Ht,po,Dr,Gt,fo,Tr,S,Ue,ho,bs,uo,mo,G,He,_o,$s,go,vo,pe,bo,V,Ge,$o,Fe,xo,xs,Eo,wo,yo,Es,Po,qo,Re,Ao,F,We,ko,Xe,So,ws,Io,Lo,Do,de,To,R,Je,No,Be,Mo,Ft,jo,Vo,Co,fe,Nr,Z,he,ys,Ke,zo,Ps,Oo,Mr,T,Qo,Rt,Uo,Ho,Wt,Go,Fo,Xt,Ro,Wo,Jt,Xo,Jo,jr,y,Ye,Bo,qs,Ko,Yo,ue,Ze,Zo,et,en,Bt,tn,sn,rn,me,tt,an,As,on,nn,_e,st,ln,ks,cn,pn,ge,rt,dn,at,fn,Kt,hn,un,mn,ve,ot,_n,nt,gn,Yt,vn,bn,$n,be,lt,xn,Ss,En,Vr,Q,it,wn,Is,yn,Pn,$e,ct,qn,Ls,An,Cr,U,pt,kn,Ds,Sn,In,xe,dt,Ln,Ts,Dn,zr,ee,Ee,Ns,ft,Tn,Ms,Nn,Or,we,ht,Mn,jn,ut,Vn,Qr,Zt,Cn,Ur,es,zn,Hr,w,js,Vs,On,Qn,Cs,zs,Un,Hn,Os,Qs,Gn,Fn,Us,Hs,Rn,Wn,Gs,Fs,Xn,Jn,Rs,Ws,Bn,Kn,Xs,Js,Yn,Zn,Bs,Ks,el,tl,Ys,Zs,sl,Gr,ye,rl,ts,al,ol,Fr,ss,nl,Rr,te,Pe,er,mt,ll,tr,il,Wr,qe,cl,_t,pl,dl,Xr,se,Ae,sr,gt,fl,rr,hl,Jr,re,vt,ul,ml,bt,ar,_l,gl,Br,$t,vl,xt,bl,Kr,rs,$l,Yr,as,or,nr,xl,Zr,os,El,ea,ke,wl,Et,yl,Pl,ta,ae,Se,lr,wt,ql,ir,Al,sa,H,yt,kl,Sl,Pt,Il,Ll,qt,Dl,Tl,ra,ns,Nl,aa,oe,Ie,cr,At,Ml,pr,jl,oa,ls,Vl,na,Le,dr,fr,Cl,zl,hr,ur,Ol,la,kt,Ql,mr,Ul,ia,D,St,Hl,_r,Gl,Fl,De,It,Rl,gr,Wl,Xl,C,Lt,Jl,Dt,Bl,vr,Kl,Yl,Zl,br,ei,ti,Tt,si,Te,Nt,ri,$r,ai,ca,Ne,oi,xr,ni,li,pa,is,ii,da,Me,ci,Er,pi,di,fa,ne,je,wr,Mt,fi,yr,hi,ha,cs,ui,ua,jt,ma,Ve,mi,Pr,_i,gi,_a,Vt,ga,Ce,vi,Ct,bi,$i,va;return q=new le({}),Qe=new le({}),Ue=new P({props:{name:"class transformers.ProcessorMixin",anchor:"transformers.ProcessorMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/processing_utils.py#L44"}}),He=new P({props:{name:"from\\_pretrained",anchor:"transformers.ProcessorMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/processing_utils.py#L157",parametersDescription:[{anchor:"transformers.ProcessorMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.
**kwargs &#x2014;
Additional keyword arguments passed along to both
<a href="/docs/transformers/doc-build-test/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained">from_pretrained()</a> and
<code>from_pretrained</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"}]}}),pe=new wi({props:{$$slots:{default:[kp]},$$scope:{ctx:J}}}),Ge=new P({props:{name:"push\\_to\\_hub",anchor:"transformers.file_utils.PushToHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"use_temp_dir",val:": bool = False"},{name:"commit_message",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"**model_card_kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/file_utils.py#L2810",parametersDescription:[{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your processor in the Hub or a path to a local folder (in which case
the repository will have the name of that local folder). If not specified, will default to the name
given by <code>repo_url</code> and a local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <code>organization</code>) with <code>repo_name</code>.`,name:"repo_url"},{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.use_temp_dir",description:`<strong>use_temp_dir</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to clone the distant repo in a temporary directory or in <code>repo_path_or_name</code> inside the
current working directory. This will slow things down if you are making changes in an existing repo
since you will need to clone the repo before every push.`,name:"use_temp_dir"},{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add processor&quot;</code>.`,name:"commit_message"},{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your processor (you must be a member of this organization).`,name:"organization"},{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private (requires a paying subscription).`,name:"private"},{anchor:"transformers.file_utils.PushToHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code> if
<code>repo_url</code> is not specified.`,name:"use_auth_token"}],returnDescription:`
<p>The url of the commit of your processor in the given repository.</p>
`,returnType:`
<p><code>str</code></p>
`}}),Re=new eo({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("bert-base-cased")

# Push the processor to your namespace with the name "my-finetuned-bert" and have a local clone in the
# *my-finetuned-bert* folder.
processor.push_to_hub("my-finetuned-bert")

# Push the processor to your namespace with the name "my-finetuned-bert" with no local clone.
processor.push_to_hub("my-finetuned-bert", use_temp_dir=True)

# Push the processor to an organization with the name "my-finetuned-bert" and have a local clone in the
# *my-finetuned-bert* folder.
processor.push_to_hub("my-finetuned-bert", organization="huggingface")

# Make a change to an existing repo that has been cloned locally in *my-finetuned-bert*.
processor.push_to_hub("my-finetuned-bert", repo_url="https://huggingface.co/sgugger/my-finetuned-bert"),`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-comment"># Push the processor to your namespace with the name &quot;my-finetuned-bert&quot; and have a local clone in the</span>
<span class="hljs-comment"># *my-finetuned-bert* folder.</span>
processor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>)

<span class="hljs-comment"># Push the processor to your namespace with the name &quot;my-finetuned-bert&quot; with no local clone.</span>
processor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>, use_temp_dir=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Push the processor to an organization with the name &quot;my-finetuned-bert&quot; and have a local clone in the</span>
<span class="hljs-comment"># *my-finetuned-bert* folder.</span>
processor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>, organization=<span class="hljs-string">&quot;huggingface&quot;</span>)

<span class="hljs-comment"># Make a change to an existing repo that has been cloned locally in *my-finetuned-bert*.</span>
processor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>, repo_url=<span class="hljs-string">&quot;https://huggingface.co/sgugger/my-finetuned-bert&quot;</span>)`}}),We=new P({props:{name:"register\\_for\\_auto\\_class",anchor:"transformers.ProcessorMixin.register_for_auto_class",parameters:[{name:"auto_class",val:" = 'AutoProcessor'"}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/processing_utils.py#L190",parametersDescription:[{anchor:"transformers.ProcessorMixin.register_for_auto_class.auto_class",description:`<strong>auto_class</strong> (<code>str</code> or <code>type</code>, <em>optional</em>, defaults to <code>&quot;AutoProcessor&quot;</code>) &#x2014;
The auto class to register this new feature extractor with.`,name:"auto_class"}]}}),de=new wi({props:{warning:"&lcub;true}",$$slots:{default:[Sp]},$$scope:{ctx:J}}}),Je=new P({props:{name:"save\\_pretrained",anchor:"transformers.ProcessorMixin.save_pretrained",parameters:[{name:"save_directory",val:""},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/processing_utils.py#L95",parametersDescription:[{anchor:"transformers.ProcessorMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory where the feature extractor JSON file and the tokenizer files will be saved (directory will
be created if it does not exist).`,name:"save_directory"},{anchor:"transformers.ProcessorMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your processor to the Hugging Face model hub after saving it.</p>
<div class="course-tip course-tip-orange bg-gradient-to-br dark:bg-gradient-to-r before:border-orange-500 dark:before:border-orange-800 from-orange-50 dark:from-gray-900 to-white dark:to-gray-950 border border-orange-50 text-orange-700 dark:text-gray-400">
						
<p>Using <code>push_to_hub=True</code> will synchronize the repository you are pushing to with <code>save_directory</code>,
which requires <code>save_directory</code> to be a local clone of the repo you are pushing to if it&#x2019;s an existing
folder. Pass along <code>temp_dir=True</code> to use a temporary directory instead.</p>

					</div>
<p>kwargs &#x2014;
Additional key word arguments passed along to the <a href="/docs/transformers/doc-build-test/en/main_classes/model#transformers.file_utils.PushToHubMixin.push_to_hub">push_to_hub()</a> method.`,name:"push_to_hub"}]}}),fe=new wi({props:{$$slots:{default:[Ip]},$$scope:{ctx:J}}}),Ke=new le({}),Ye=new P({props:{name:"class transformers.DataProcessor",anchor:"transformers.DataProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L81"}}),Ze=new P({props:{name:"get\\_dev\\_examples",anchor:"transformers.DataProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L98"}}),tt=new P({props:{name:"get\\_example\\_from\\_tensor\\_dict",anchor:"transformers.DataProcessor.get_example_from_tensor_dict",parameters:[{name:"tensor_dict",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L84"}}),st=new P({props:{name:"get\\_labels",anchor:"transformers.DataProcessor.get_labels",parameters:[],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L106"}}),rt=new P({props:{name:"get\\_test\\_examples",anchor:"transformers.DataProcessor.get_test_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L102"}}),ot=new P({props:{name:"get\\_train\\_examples",anchor:"transformers.DataProcessor.get_train_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L94"}}),lt=new P({props:{name:"tfds\\_map",anchor:"transformers.DataProcessor.tfds_map",parameters:[{name:"example",val:""}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L110"}}),it=new P({props:{name:"class transformers.InputExample",anchor:"transformers.InputExample",parameters:[{name:"guid",val:": str"},{name:"text_a",val:": str"},{name:"text_b",val:": typing.Optional[str] = None"},{name:"label",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L31"}}),ct=new P({props:{name:"to\\_json\\_string",anchor:"transformers.InputExample.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L50"}}),pt=new P({props:{name:"class transformers.InputFeatures",anchor:"transformers.InputFeatures",parameters:[{name:"input_ids",val:": typing.List[int]"},{name:"attention_mask",val:": typing.Optional[typing.List[int]] = None"},{name:"token_type_ids",val:": typing.Optional[typing.List[int]] = None"},{name:"label",val:": typing.Union[int, float, NoneType] = None"}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L56"}}),dt=new P({props:{name:"to\\_json\\_string",anchor:"transformers.InputFeatures.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/utils.py#L76"}}),ft=new le({}),mt=new le({}),gt=new le({}),wt=new le({}),At=new le({}),St=new P({props:{name:"class transformers.data.processors.squad.SquadProcessor",anchor:"transformers.data.processors.squad.SquadProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/squad.py#L543"}}),It=new P({props:{name:"get\\_dev\\_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/squad.py#L631"}}),Lt=new P({props:{name:"get\\_examples\\_from\\_dataset",anchor:"transformers.data.processors.squad.SquadProcessor.get_examples_from_dataset",parameters:[{name:"dataset",val:""},{name:"evaluate",val:" = False"}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/squad.py#L576",returnDescription:`
<p>List of SquadExample</p>
`}}),Tt=new eo({props:{code:`import tensorflow_datasets as tfds

dataset = tfds.load("squad")

training_examples = get_examples_from_dataset(dataset, evaluate=False)
evaluation_examples = get_examples_from_dataset(dataset, evaluate=True),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>training_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">True</span>)`}}),Nt=new P({props:{name:"get\\_train\\_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_train_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/doc-build-test/src/transformers/data/processors/squad.py#L609"}}),Mt=new le({}),jt=new eo({props:{code:`# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># Loading a V2 processor</span>
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

<span class="hljs-comment"># Loading a V1 processor</span>
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),Vt=new eo({props:{code:`# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># tensorflow_datasets only handle Squad V1.</span>
tfds_examples = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),{c(){h=r("meta"),A=i(),$=r("h1"),x=r("a"),N=r("span"),u(q.$$.fragment),O=i(),M=r("span"),L=n("Processors"),E=i(),j=r("p"),B=n("Processors can mean two different things in the Transformers library:"),Sr=i(),ie=r("ul"),K=r("li"),to=n("the objects that pre-process inputs for multi-modal models such as "),Qt=r("a"),so=n("Wav2Vec2"),ro=n(` (speech and text)
or `),Ut=r("a"),ao=n("CLIP"),oo=n(" (text and vision)"),no=i(),_s=r("li"),lo=n("deprecated objects that were used in older versions of the library to preprocess data for GLUE or SQUAD."),Ir=i(),Y=r("h2"),ce=r("a"),gs=r("span"),u(Qe.$$.fragment),io=i(),vs=r("span"),co=n("Multi-modal processors"),Lr=i(),Ht=r("p"),po=n(`Any multi-modal model will require an object to encode or decode the data that groups several modalities (among text,
vision and audio). This is handled by objects called processors, which group tokenizers (for the text modality) and
feature extractors (for vision and audio).`),Dr=i(),Gt=r("p"),fo=n("Those processors inherit from the following base class that implements the saving and loading functionality:"),Tr=i(),S=r("div"),u(Ue.$$.fragment),ho=i(),bs=r("p"),uo=n("This is a mixin used to provide saving/loading functionality for all processor classes."),mo=i(),G=r("div"),u(He.$$.fragment),_o=i(),$s=r("p"),go=n("Instantiate a processor associated with a pretrained model."),vo=i(),u(pe.$$.fragment),bo=i(),V=r("div"),u(Ge.$$.fragment),$o=i(),Fe=r("p"),xo=n(`Upload the processor files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),xs=r("code"),Eo=n("repo_path_or_name"),wo=n("."),yo=i(),Es=r("p"),Po=n("Examples:"),qo=i(),u(Re.$$.fragment),Ao=i(),F=r("div"),u(We.$$.fragment),ko=i(),Xe=r("p"),So=n(`Register this class with a given auto class. This should only be used for custom feature extractors as the ones
in the library are already mapped with `),ws=r("code"),Io=n("AutoProcessor"),Lo=n("."),Do=i(),u(de.$$.fragment),To=i(),R=r("div"),u(Je.$$.fragment),No=i(),Be=r("p"),Mo=n(`Saves the attributes of this processor (feature extractor, tokenizer\u2026) in the specified directory so that it
can be reloaded using the `),Ft=r("a"),jo=n("from_pretrained()"),Vo=n(" method."),Co=i(),u(fe.$$.fragment),Nr=i(),Z=r("h2"),he=r("a"),ys=r("span"),u(Ke.$$.fragment),zo=i(),Ps=r("span"),Oo=n("Deprecated processors"),Mr=i(),T=r("p"),Qo=n(`All processors follow the same architecture which is that of the
`),Rt=r("a"),Uo=n("DataProcessor"),Ho=n(`. The processor returns a list of
`),Wt=r("a"),Go=n("InputExample"),Fo=n(`. These
`),Xt=r("a"),Ro=n("InputExample"),Wo=n(` can be converted to
`),Jt=r("a"),Xo=n("InputFeatures"),Jo=n(" in order to be fed to the model."),jr=i(),y=r("div"),u(Ye.$$.fragment),Bo=i(),qs=r("p"),Ko=n("Base class for data converters for sequence classification data sets."),Yo=i(),ue=r("div"),u(Ze.$$.fragment),Zo=i(),et=r("p"),en=n("Gets a collection of "),Bt=r("a"),tn=n("InputExample"),sn=n(" for the dev set."),rn=i(),me=r("div"),u(tt.$$.fragment),an=i(),As=r("p"),on=n("Gets an example from a dict with tensorflow tensors."),nn=i(),_e=r("div"),u(st.$$.fragment),ln=i(),ks=r("p"),cn=n("Gets the list of labels for this data set."),pn=i(),ge=r("div"),u(rt.$$.fragment),dn=i(),at=r("p"),fn=n("Gets a collection of "),Kt=r("a"),hn=n("InputExample"),un=n(" for the test set."),mn=i(),ve=r("div"),u(ot.$$.fragment),_n=i(),nt=r("p"),gn=n("Gets a collection of "),Yt=r("a"),vn=n("InputExample"),bn=n(" for the train set."),$n=i(),be=r("div"),u(lt.$$.fragment),xn=i(),Ss=r("p"),En=n(`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),Vr=i(),Q=r("div"),u(it.$$.fragment),wn=i(),Is=r("p"),yn=n("A single training/test example for simple sequence classification."),Pn=i(),$e=r("div"),u(ct.$$.fragment),qn=i(),Ls=r("p"),An=n("Serializes this instance to a JSON string."),Cr=i(),U=r("div"),u(pt.$$.fragment),kn=i(),Ds=r("p"),Sn=n("A single set of features of data. Property names are the same names as the corresponding inputs to a model."),In=i(),xe=r("div"),u(dt.$$.fragment),Ln=i(),Ts=r("p"),Dn=n("Serializes this instance to a JSON string."),zr=i(),ee=r("h2"),Ee=r("a"),Ns=r("span"),u(ft.$$.fragment),Tn=i(),Ms=r("span"),Nn=n("GLUE"),Or=i(),we=r("p"),ht=r("a"),Mn=n("General Language Understanding Evaluation (GLUE)"),jn=n(` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),ut=r("a"),Vn=n(`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),Qr=i(),Zt=r("p"),Cn=n(`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),Ur=i(),es=r("p"),zn=n("Those processors are:"),Hr=i(),w=r("ul"),js=r("li"),Vs=r("code"),On=n("MrpcProcessor"),Qn=i(),Cs=r("li"),zs=r("code"),Un=n("MnliProcessor"),Hn=i(),Os=r("li"),Qs=r("code"),Gn=n("MnliMismatchedProcessor"),Fn=i(),Us=r("li"),Hs=r("code"),Rn=n("Sst2Processor"),Wn=i(),Gs=r("li"),Fs=r("code"),Xn=n("StsbProcessor"),Jn=i(),Rs=r("li"),Ws=r("code"),Bn=n("QqpProcessor"),Kn=i(),Xs=r("li"),Js=r("code"),Yn=n("QnliProcessor"),Zn=i(),Bs=r("li"),Ks=r("code"),el=n("RteProcessor"),tl=i(),Ys=r("li"),Zs=r("code"),sl=n("WnliProcessor"),Gr=i(),ye=r("p"),rl=n(`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),ts=r("a"),al=n("InputExample"),ol=n("."),Fr=i(),ss=r("p"),nl=n("automethod,transformers.data.processors.glue.glue_convert_examples_to_features"),Rr=i(),te=r("h3"),Pe=r("a"),er=r("span"),u(mt.$$.fragment),ll=i(),tr=r("span"),il=n("Example usage"),Wr=i(),qe=r("p"),cl=n("An example using these processors is given in the "),_t=r("a"),pl=n("run_glue.py"),dl=n(" script."),Xr=i(),se=r("h2"),Ae=r("a"),sr=r("span"),u(gt.$$.fragment),fl=i(),rr=r("span"),hl=n("XNLI"),Jr=i(),re=r("p"),vt=r("a"),ul=n("The Cross-Lingual NLI Corpus (XNLI)"),ml=n(` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),bt=r("a"),ar=r("em"),_l=n("MultiNLI"),gl=n(`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Br=i(),$t=r("p"),vl=n("It was released together with the paper "),xt=r("a"),bl=n("XNLI: Evaluating Cross-lingual Sentence Representations"),Kr=i(),rs=r("p"),$l=n("This library hosts the processor to load the XNLI data:"),Yr=i(),as=r("ul"),or=r("li"),nr=r("code"),xl=n("XnliProcessor"),Zr=i(),os=r("p"),El=n("Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),ea=i(),ke=r("p"),wl=n("An example using these processors is given in the "),Et=r("a"),yl=n("run_xnli.py"),Pl=n(" script."),ta=i(),ae=r("h2"),Se=r("a"),lr=r("span"),u(wt.$$.fragment),ql=i(),ir=r("span"),Al=n("SQuAD"),sa=i(),H=r("p"),yt=r("a"),kl=n("The Stanford Question Answering Dataset (SQuAD)"),Sl=n(` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),Pt=r("a"),Il=n("SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Ll=n(". The second version (v2.0) was released alongside the paper "),qt=r("a"),Dl=n(`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Tl=n("."),ra=i(),ns=r("p"),Nl=n("This library hosts a processor for each of the two versions:"),aa=i(),oe=r("h3"),Ie=r("a"),cr=r("span"),u(At.$$.fragment),Ml=i(),pr=r("span"),jl=n("Processors"),oa=i(),ls=r("p"),Vl=n("Those processors are:"),na=i(),Le=r("ul"),dr=r("li"),fr=r("code"),Cl=n("SquadV1Processor"),zl=i(),hr=r("li"),ur=r("code"),Ol=n("SquadV2Processor"),la=i(),kt=r("p"),Ql=n("They both inherit from the abstract class "),mr=r("code"),Ul=n("SquadProcessor"),ia=i(),D=r("div"),u(St.$$.fragment),Hl=i(),_r=r("p"),Gl=n(`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),Fl=i(),De=r("div"),u(It.$$.fragment),Rl=i(),gr=r("p"),Wl=n("Returns the evaluation example from the data directory."),Xl=i(),C=r("div"),u(Lt.$$.fragment),Jl=i(),Dt=r("p"),Bl=n("Creates a list of "),vr=r("code"),Kl=n("SquadExample"),Yl=n("using a TFDS dataset."),Zl=i(),br=r("p"),ei=n("Examples:"),ti=i(),u(Tt.$$.fragment),si=i(),Te=r("div"),u(Nt.$$.fragment),ri=i(),$r=r("p"),ai=n("Returns the training examples from the data directory."),ca=i(),Ne=r("p"),oi=n(`Additionally, the following method can be used to convert SQuAD examples into
`),xr=r("code"),ni=n("SquadFeatures"),li=n(" that can be used as model inputs."),pa=i(),is=r("p"),ii=n("automethod,transformers.data.processors.squad.squad_convert_examples_to_features"),da=i(),Me=r("p"),ci=n(`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),Er=r("em"),pi=n("tensorflow_datasets"),di=n(" package. Examples are given below."),fa=i(),ne=r("h3"),je=r("a"),wr=r("span"),u(Mt.$$.fragment),fi=i(),yr=r("span"),hi=n("Example usage"),ha=i(),cs=r("p"),ui=n("Here is an example using the processors as well as the conversion method using data files:"),ua=i(),u(jt.$$.fragment),ma=i(),Ve=r("p"),mi=n("Using "),Pr=r("em"),_i=n("tensorflow_datasets"),gi=n(" is as easy as using a data file:"),_a=i(),u(Vt.$$.fragment),ga=i(),Ce=r("p"),vi=n("Another example using these processors is given in the "),Ct=r("a"),bi=n("run_squad.py"),$i=n(" script."),this.h()},l(e){const p=Ap('[data-svelte="svelte-1phssyn"]',document.head);h=a(p,"META",{name:!0,content:!0}),p.forEach(s),A=c(e),$=a(e,"H1",{class:!0});var zt=o($);x=a(zt,"A",{id:!0,class:!0,href:!0});var qr=o(x);N=a(qr,"SPAN",{});var Ar=o(N);m(q.$$.fragment,Ar),Ar.forEach(s),qr.forEach(s),O=c(zt),M=a(zt,"SPAN",{});var yi=o(M);L=l(yi,"Processors"),yi.forEach(s),zt.forEach(s),E=c(e),j=a(e,"P",{});var Pi=o(j);B=l(Pi,"Processors can mean two different things in the Transformers library:"),Pi.forEach(s),Sr=c(e),ie=a(e,"UL",{});var ba=o(ie);K=a(ba,"LI",{});var ps=o(K);to=l(ps,"the objects that pre-process inputs for multi-modal models such as "),Qt=a(ps,"A",{href:!0});var qi=o(Qt);so=l(qi,"Wav2Vec2"),qi.forEach(s),ro=l(ps,` (speech and text)
or `),Ut=a(ps,"A",{href:!0});var Ai=o(Ut);ao=l(Ai,"CLIP"),Ai.forEach(s),oo=l(ps," (text and vision)"),ps.forEach(s),no=c(ba),_s=a(ba,"LI",{});var ki=o(_s);lo=l(ki,"deprecated objects that were used in older versions of the library to preprocess data for GLUE or SQUAD."),ki.forEach(s),ba.forEach(s),Ir=c(e),Y=a(e,"H2",{class:!0});var $a=o(Y);ce=a($a,"A",{id:!0,class:!0,href:!0});var Si=o(ce);gs=a(Si,"SPAN",{});var Ii=o(gs);m(Qe.$$.fragment,Ii),Ii.forEach(s),Si.forEach(s),io=c($a),vs=a($a,"SPAN",{});var Li=o(vs);co=l(Li,"Multi-modal processors"),Li.forEach(s),$a.forEach(s),Lr=c(e),Ht=a(e,"P",{});var Di=o(Ht);po=l(Di,`Any multi-modal model will require an object to encode or decode the data that groups several modalities (among text,
vision and audio). This is handled by objects called processors, which group tokenizers (for the text modality) and
feature extractors (for vision and audio).`),Di.forEach(s),Dr=c(e),Gt=a(e,"P",{});var Ti=o(Gt);fo=l(Ti,"Those processors inherit from the following base class that implements the saving and loading functionality:"),Ti.forEach(s),Tr=c(e),S=a(e,"DIV",{class:!0});var z=o(S);m(Ue.$$.fragment,z),ho=c(z),bs=a(z,"P",{});var Ni=o(bs);uo=l(Ni,"This is a mixin used to provide saving/loading functionality for all processor classes."),Ni.forEach(s),mo=c(z),G=a(z,"DIV",{class:!0});var ds=o(G);m(He.$$.fragment,ds),_o=c(ds),$s=a(ds,"P",{});var Mi=o($s);go=l(Mi,"Instantiate a processor associated with a pretrained model."),Mi.forEach(s),vo=c(ds),m(pe.$$.fragment,ds),ds.forEach(s),bo=c(z),V=a(z,"DIV",{class:!0});var ze=o(V);m(Ge.$$.fragment,ze),$o=c(ze),Fe=a(ze,"P",{});var xa=o(Fe);xo=l(xa,`Upload the processor files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),xs=a(xa,"CODE",{});var ji=o(xs);Eo=l(ji,"repo_path_or_name"),ji.forEach(s),wo=l(xa,"."),xa.forEach(s),yo=c(ze),Es=a(ze,"P",{});var Vi=o(Es);Po=l(Vi,"Examples:"),Vi.forEach(s),qo=c(ze),m(Re.$$.fragment,ze),ze.forEach(s),Ao=c(z),F=a(z,"DIV",{class:!0});var fs=o(F);m(We.$$.fragment,fs),ko=c(fs),Xe=a(fs,"P",{});var Ea=o(Xe);So=l(Ea,`Register this class with a given auto class. This should only be used for custom feature extractors as the ones
in the library are already mapped with `),ws=a(Ea,"CODE",{});var Ci=o(ws);Io=l(Ci,"AutoProcessor"),Ci.forEach(s),Lo=l(Ea,"."),Ea.forEach(s),Do=c(fs),m(de.$$.fragment,fs),fs.forEach(s),To=c(z),R=a(z,"DIV",{class:!0});var hs=o(R);m(Je.$$.fragment,hs),No=c(hs),Be=a(hs,"P",{});var wa=o(Be);Mo=l(wa,`Saves the attributes of this processor (feature extractor, tokenizer\u2026) in the specified directory so that it
can be reloaded using the `),Ft=a(wa,"A",{href:!0});var zi=o(Ft);jo=l(zi,"from_pretrained()"),zi.forEach(s),Vo=l(wa," method."),wa.forEach(s),Co=c(hs),m(fe.$$.fragment,hs),hs.forEach(s),z.forEach(s),Nr=c(e),Z=a(e,"H2",{class:!0});var ya=o(Z);he=a(ya,"A",{id:!0,class:!0,href:!0});var Oi=o(he);ys=a(Oi,"SPAN",{});var Qi=o(ys);m(Ke.$$.fragment,Qi),Qi.forEach(s),Oi.forEach(s),zo=c(ya),Ps=a(ya,"SPAN",{});var Ui=o(Ps);Oo=l(Ui,"Deprecated processors"),Ui.forEach(s),ya.forEach(s),Mr=c(e),T=a(e,"P",{});var W=o(T);Qo=l(W,`All processors follow the same architecture which is that of the
`),Rt=a(W,"A",{href:!0});var Hi=o(Rt);Uo=l(Hi,"DataProcessor"),Hi.forEach(s),Ho=l(W,`. The processor returns a list of
`),Wt=a(W,"A",{href:!0});var Gi=o(Wt);Go=l(Gi,"InputExample"),Gi.forEach(s),Fo=l(W,`. These
`),Xt=a(W,"A",{href:!0});var Fi=o(Xt);Ro=l(Fi,"InputExample"),Fi.forEach(s),Wo=l(W,` can be converted to
`),Jt=a(W,"A",{href:!0});var Ri=o(Jt);Xo=l(Ri,"InputFeatures"),Ri.forEach(s),Jo=l(W," in order to be fed to the model."),W.forEach(s),jr=c(e),y=a(e,"DIV",{class:!0});var I=o(y);m(Ye.$$.fragment,I),Bo=c(I),qs=a(I,"P",{});var Wi=o(qs);Ko=l(Wi,"Base class for data converters for sequence classification data sets."),Wi.forEach(s),Yo=c(I),ue=a(I,"DIV",{class:!0});var Pa=o(ue);m(Ze.$$.fragment,Pa),Zo=c(Pa),et=a(Pa,"P",{});var qa=o(et);en=l(qa,"Gets a collection of "),Bt=a(qa,"A",{href:!0});var Xi=o(Bt);tn=l(Xi,"InputExample"),Xi.forEach(s),sn=l(qa," for the dev set."),qa.forEach(s),Pa.forEach(s),rn=c(I),me=a(I,"DIV",{class:!0});var Aa=o(me);m(tt.$$.fragment,Aa),an=c(Aa),As=a(Aa,"P",{});var Ji=o(As);on=l(Ji,"Gets an example from a dict with tensorflow tensors."),Ji.forEach(s),Aa.forEach(s),nn=c(I),_e=a(I,"DIV",{class:!0});var ka=o(_e);m(st.$$.fragment,ka),ln=c(ka),ks=a(ka,"P",{});var Bi=o(ks);cn=l(Bi,"Gets the list of labels for this data set."),Bi.forEach(s),ka.forEach(s),pn=c(I),ge=a(I,"DIV",{class:!0});var Sa=o(ge);m(rt.$$.fragment,Sa),dn=c(Sa),at=a(Sa,"P",{});var Ia=o(at);fn=l(Ia,"Gets a collection of "),Kt=a(Ia,"A",{href:!0});var Ki=o(Kt);hn=l(Ki,"InputExample"),Ki.forEach(s),un=l(Ia," for the test set."),Ia.forEach(s),Sa.forEach(s),mn=c(I),ve=a(I,"DIV",{class:!0});var La=o(ve);m(ot.$$.fragment,La),_n=c(La),nt=a(La,"P",{});var Da=o(nt);gn=l(Da,"Gets a collection of "),Yt=a(Da,"A",{href:!0});var Yi=o(Yt);vn=l(Yi,"InputExample"),Yi.forEach(s),bn=l(Da," for the train set."),Da.forEach(s),La.forEach(s),$n=c(I),be=a(I,"DIV",{class:!0});var Ta=o(be);m(lt.$$.fragment,Ta),xn=c(Ta),Ss=a(Ta,"P",{});var Zi=o(Ss);En=l(Zi,`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),Zi.forEach(s),Ta.forEach(s),I.forEach(s),Vr=c(e),Q=a(e,"DIV",{class:!0});var us=o(Q);m(it.$$.fragment,us),wn=c(us),Is=a(us,"P",{});var ec=o(Is);yn=l(ec,"A single training/test example for simple sequence classification."),ec.forEach(s),Pn=c(us),$e=a(us,"DIV",{class:!0});var Na=o($e);m(ct.$$.fragment,Na),qn=c(Na),Ls=a(Na,"P",{});var tc=o(Ls);An=l(tc,"Serializes this instance to a JSON string."),tc.forEach(s),Na.forEach(s),us.forEach(s),Cr=c(e),U=a(e,"DIV",{class:!0});var ms=o(U);m(pt.$$.fragment,ms),kn=c(ms),Ds=a(ms,"P",{});var sc=o(Ds);Sn=l(sc,"A single set of features of data. Property names are the same names as the corresponding inputs to a model."),sc.forEach(s),In=c(ms),xe=a(ms,"DIV",{class:!0});var Ma=o(xe);m(dt.$$.fragment,Ma),Ln=c(Ma),Ts=a(Ma,"P",{});var rc=o(Ts);Dn=l(rc,"Serializes this instance to a JSON string."),rc.forEach(s),Ma.forEach(s),ms.forEach(s),zr=c(e),ee=a(e,"H2",{class:!0});var ja=o(ee);Ee=a(ja,"A",{id:!0,class:!0,href:!0});var ac=o(Ee);Ns=a(ac,"SPAN",{});var oc=o(Ns);m(ft.$$.fragment,oc),oc.forEach(s),ac.forEach(s),Tn=c(ja),Ms=a(ja,"SPAN",{});var nc=o(Ms);Nn=l(nc,"GLUE"),nc.forEach(s),ja.forEach(s),Or=c(e),we=a(e,"P",{});var Va=o(we);ht=a(Va,"A",{href:!0,rel:!0});var lc=o(ht);Mn=l(lc,"General Language Understanding Evaluation (GLUE)"),lc.forEach(s),jn=l(Va,` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),ut=a(Va,"A",{href:!0,rel:!0});var ic=o(ut);Vn=l(ic,`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),ic.forEach(s),Va.forEach(s),Qr=c(e),Zt=a(e,"P",{});var cc=o(Zt);Cn=l(cc,`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),cc.forEach(s),Ur=c(e),es=a(e,"P",{});var pc=o(es);zn=l(pc,"Those processors are:"),pc.forEach(s),Hr=c(e),w=a(e,"UL",{});var k=o(w);js=a(k,"LI",{});var dc=o(js);Vs=a(dc,"CODE",{});var fc=o(Vs);On=l(fc,"MrpcProcessor"),fc.forEach(s),dc.forEach(s),Qn=c(k),Cs=a(k,"LI",{});var hc=o(Cs);zs=a(hc,"CODE",{});var uc=o(zs);Un=l(uc,"MnliProcessor"),uc.forEach(s),hc.forEach(s),Hn=c(k),Os=a(k,"LI",{});var mc=o(Os);Qs=a(mc,"CODE",{});var _c=o(Qs);Gn=l(_c,"MnliMismatchedProcessor"),_c.forEach(s),mc.forEach(s),Fn=c(k),Us=a(k,"LI",{});var gc=o(Us);Hs=a(gc,"CODE",{});var vc=o(Hs);Rn=l(vc,"Sst2Processor"),vc.forEach(s),gc.forEach(s),Wn=c(k),Gs=a(k,"LI",{});var bc=o(Gs);Fs=a(bc,"CODE",{});var $c=o(Fs);Xn=l($c,"StsbProcessor"),$c.forEach(s),bc.forEach(s),Jn=c(k),Rs=a(k,"LI",{});var xc=o(Rs);Ws=a(xc,"CODE",{});var Ec=o(Ws);Bn=l(Ec,"QqpProcessor"),Ec.forEach(s),xc.forEach(s),Kn=c(k),Xs=a(k,"LI",{});var wc=o(Xs);Js=a(wc,"CODE",{});var yc=o(Js);Yn=l(yc,"QnliProcessor"),yc.forEach(s),wc.forEach(s),Zn=c(k),Bs=a(k,"LI",{});var Pc=o(Bs);Ks=a(Pc,"CODE",{});var qc=o(Ks);el=l(qc,"RteProcessor"),qc.forEach(s),Pc.forEach(s),tl=c(k),Ys=a(k,"LI",{});var Ac=o(Ys);Zs=a(Ac,"CODE",{});var kc=o(Zs);sl=l(kc,"WnliProcessor"),kc.forEach(s),Ac.forEach(s),k.forEach(s),Gr=c(e),ye=a(e,"P",{});var Ca=o(ye);rl=l(Ca,`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),ts=a(Ca,"A",{href:!0});var Sc=o(ts);al=l(Sc,"InputExample"),Sc.forEach(s),ol=l(Ca,"."),Ca.forEach(s),Fr=c(e),ss=a(e,"P",{});var Ic=o(ss);nl=l(Ic,"automethod,transformers.data.processors.glue.glue_convert_examples_to_features"),Ic.forEach(s),Rr=c(e),te=a(e,"H3",{class:!0});var za=o(te);Pe=a(za,"A",{id:!0,class:!0,href:!0});var Lc=o(Pe);er=a(Lc,"SPAN",{});var Dc=o(er);m(mt.$$.fragment,Dc),Dc.forEach(s),Lc.forEach(s),ll=c(za),tr=a(za,"SPAN",{});var Tc=o(tr);il=l(Tc,"Example usage"),Tc.forEach(s),za.forEach(s),Wr=c(e),qe=a(e,"P",{});var Oa=o(qe);cl=l(Oa,"An example using these processors is given in the "),_t=a(Oa,"A",{href:!0,rel:!0});var Nc=o(_t);pl=l(Nc,"run_glue.py"),Nc.forEach(s),dl=l(Oa," script."),Oa.forEach(s),Xr=c(e),se=a(e,"H2",{class:!0});var Qa=o(se);Ae=a(Qa,"A",{id:!0,class:!0,href:!0});var Mc=o(Ae);sr=a(Mc,"SPAN",{});var jc=o(sr);m(gt.$$.fragment,jc),jc.forEach(s),Mc.forEach(s),fl=c(Qa),rr=a(Qa,"SPAN",{});var Vc=o(rr);hl=l(Vc,"XNLI"),Vc.forEach(s),Qa.forEach(s),Jr=c(e),re=a(e,"P",{});var kr=o(re);vt=a(kr,"A",{href:!0,rel:!0});var Cc=o(vt);ul=l(Cc,"The Cross-Lingual NLI Corpus (XNLI)"),Cc.forEach(s),ml=l(kr,` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),bt=a(kr,"A",{href:!0,rel:!0});var zc=o(bt);ar=a(zc,"EM",{});var Oc=o(ar);_l=l(Oc,"MultiNLI"),Oc.forEach(s),zc.forEach(s),gl=l(kr,`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),kr.forEach(s),Br=c(e),$t=a(e,"P",{});var xi=o($t);vl=l(xi,"It was released together with the paper "),xt=a(xi,"A",{href:!0,rel:!0});var Qc=o(xt);bl=l(Qc,"XNLI: Evaluating Cross-lingual Sentence Representations"),Qc.forEach(s),xi.forEach(s),Kr=c(e),rs=a(e,"P",{});var Uc=o(rs);$l=l(Uc,"This library hosts the processor to load the XNLI data:"),Uc.forEach(s),Yr=c(e),as=a(e,"UL",{});var Hc=o(as);or=a(Hc,"LI",{});var Gc=o(or);nr=a(Gc,"CODE",{});var Fc=o(nr);xl=l(Fc,"XnliProcessor"),Fc.forEach(s),Gc.forEach(s),Hc.forEach(s),Zr=c(e),os=a(e,"P",{});var Rc=o(os);El=l(Rc,"Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),Rc.forEach(s),ea=c(e),ke=a(e,"P",{});var Ua=o(ke);wl=l(Ua,"An example using these processors is given in the "),Et=a(Ua,"A",{href:!0,rel:!0});var Wc=o(Et);yl=l(Wc,"run_xnli.py"),Wc.forEach(s),Pl=l(Ua," script."),Ua.forEach(s),ta=c(e),ae=a(e,"H2",{class:!0});var Ha=o(ae);Se=a(Ha,"A",{id:!0,class:!0,href:!0});var Xc=o(Se);lr=a(Xc,"SPAN",{});var Jc=o(lr);m(wt.$$.fragment,Jc),Jc.forEach(s),Xc.forEach(s),ql=c(Ha),ir=a(Ha,"SPAN",{});var Bc=o(ir);Al=l(Bc,"SQuAD"),Bc.forEach(s),Ha.forEach(s),sa=c(e),H=a(e,"P",{});var Ot=o(H);yt=a(Ot,"A",{href:!0,rel:!0});var Kc=o(yt);kl=l(Kc,"The Stanford Question Answering Dataset (SQuAD)"),Kc.forEach(s),Sl=l(Ot,` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),Pt=a(Ot,"A",{href:!0,rel:!0});var Yc=o(Pt);Il=l(Yc,"SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Yc.forEach(s),Ll=l(Ot,". The second version (v2.0) was released alongside the paper "),qt=a(Ot,"A",{href:!0,rel:!0});var Zc=o(qt);Dl=l(Zc,`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Zc.forEach(s),Tl=l(Ot,"."),Ot.forEach(s),ra=c(e),ns=a(e,"P",{});var ep=o(ns);Nl=l(ep,"This library hosts a processor for each of the two versions:"),ep.forEach(s),aa=c(e),oe=a(e,"H3",{class:!0});var Ga=o(oe);Ie=a(Ga,"A",{id:!0,class:!0,href:!0});var tp=o(Ie);cr=a(tp,"SPAN",{});var sp=o(cr);m(At.$$.fragment,sp),sp.forEach(s),tp.forEach(s),Ml=c(Ga),pr=a(Ga,"SPAN",{});var rp=o(pr);jl=l(rp,"Processors"),rp.forEach(s),Ga.forEach(s),oa=c(e),ls=a(e,"P",{});var ap=o(ls);Vl=l(ap,"Those processors are:"),ap.forEach(s),na=c(e),Le=a(e,"UL",{});var Fa=o(Le);dr=a(Fa,"LI",{});var op=o(dr);fr=a(op,"CODE",{});var np=o(fr);Cl=l(np,"SquadV1Processor"),np.forEach(s),op.forEach(s),zl=c(Fa),hr=a(Fa,"LI",{});var lp=o(hr);ur=a(lp,"CODE",{});var ip=o(ur);Ol=l(ip,"SquadV2Processor"),ip.forEach(s),lp.forEach(s),Fa.forEach(s),la=c(e),kt=a(e,"P",{});var Ei=o(kt);Ql=l(Ei,"They both inherit from the abstract class "),mr=a(Ei,"CODE",{});var cp=o(mr);Ul=l(cp,"SquadProcessor"),cp.forEach(s),Ei.forEach(s),ia=c(e),D=a(e,"DIV",{class:!0});var X=o(D);m(St.$$.fragment,X),Hl=c(X),_r=a(X,"P",{});var pp=o(_r);Gl=l(pp,`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),pp.forEach(s),Fl=c(X),De=a(X,"DIV",{class:!0});var Ra=o(De);m(It.$$.fragment,Ra),Rl=c(Ra),gr=a(Ra,"P",{});var dp=o(gr);Wl=l(dp,"Returns the evaluation example from the data directory."),dp.forEach(s),Ra.forEach(s),Xl=c(X),C=a(X,"DIV",{class:!0});var Oe=o(C);m(Lt.$$.fragment,Oe),Jl=c(Oe),Dt=a(Oe,"P",{});var Wa=o(Dt);Bl=l(Wa,"Creates a list of "),vr=a(Wa,"CODE",{});var fp=o(vr);Kl=l(fp,"SquadExample"),fp.forEach(s),Yl=l(Wa,"using a TFDS dataset."),Wa.forEach(s),Zl=c(Oe),br=a(Oe,"P",{});var hp=o(br);ei=l(hp,"Examples:"),hp.forEach(s),ti=c(Oe),m(Tt.$$.fragment,Oe),Oe.forEach(s),si=c(X),Te=a(X,"DIV",{class:!0});var Xa=o(Te);m(Nt.$$.fragment,Xa),ri=c(Xa),$r=a(Xa,"P",{});var up=o($r);ai=l(up,"Returns the training examples from the data directory."),up.forEach(s),Xa.forEach(s),X.forEach(s),ca=c(e),Ne=a(e,"P",{});var Ja=o(Ne);oi=l(Ja,`Additionally, the following method can be used to convert SQuAD examples into
`),xr=a(Ja,"CODE",{});var mp=o(xr);ni=l(mp,"SquadFeatures"),mp.forEach(s),li=l(Ja," that can be used as model inputs."),Ja.forEach(s),pa=c(e),is=a(e,"P",{});var _p=o(is);ii=l(_p,"automethod,transformers.data.processors.squad.squad_convert_examples_to_features"),_p.forEach(s),da=c(e),Me=a(e,"P",{});var Ba=o(Me);ci=l(Ba,`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),Er=a(Ba,"EM",{});var gp=o(Er);pi=l(gp,"tensorflow_datasets"),gp.forEach(s),di=l(Ba," package. Examples are given below."),Ba.forEach(s),fa=c(e),ne=a(e,"H3",{class:!0});var Ka=o(ne);je=a(Ka,"A",{id:!0,class:!0,href:!0});var vp=o(je);wr=a(vp,"SPAN",{});var bp=o(wr);m(Mt.$$.fragment,bp),bp.forEach(s),vp.forEach(s),fi=c(Ka),yr=a(Ka,"SPAN",{});var $p=o(yr);hi=l($p,"Example usage"),$p.forEach(s),Ka.forEach(s),ha=c(e),cs=a(e,"P",{});var xp=o(cs);ui=l(xp,"Here is an example using the processors as well as the conversion method using data files:"),xp.forEach(s),ua=c(e),m(jt.$$.fragment,e),ma=c(e),Ve=a(e,"P",{});var Ya=o(Ve);mi=l(Ya,"Using "),Pr=a(Ya,"EM",{});var Ep=o(Pr);_i=l(Ep,"tensorflow_datasets"),Ep.forEach(s),gi=l(Ya," is as easy as using a data file:"),Ya.forEach(s),_a=c(e),m(Vt.$$.fragment,e),ga=c(e),Ce=a(e,"P",{});var Za=o(Ce);vi=l(Za,"Another example using these processors is given in the "),Ct=a(Za,"A",{href:!0,rel:!0});var wp=o(Ct);bi=l(wp,"run_squad.py"),wp.forEach(s),$i=l(Za," script."),Za.forEach(s),this.h()},h(){d(h,"name","hf:doc:metadata"),d(h,"content",JSON.stringify(Dp)),d(x,"id","processors"),d(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x,"href","#processors"),d($,"class","relative group"),d(Qt,"href","../model_doc/wav2vec2"),d(Ut,"href","../model_doc/clip"),d(ce,"id","transformers.ProcessorMixin"),d(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ce,"href","#transformers.ProcessorMixin"),d(Y,"class","relative group"),d(G,"class","docstring"),d(V,"class","docstring"),d(F,"class","docstring"),d(Ft,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained"),d(R,"class","docstring"),d(S,"class","docstring"),d(he,"id","transformers.DataProcessor"),d(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(he,"href","#transformers.DataProcessor"),d(Z,"class","relative group"),d(Rt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.DataProcessor"),d(Wt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputExample"),d(Xt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputExample"),d(Jt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputFeatures"),d(Bt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputExample"),d(ue,"class","docstring"),d(me,"class","docstring"),d(_e,"class","docstring"),d(Kt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputExample"),d(ge,"class","docstring"),d(Yt,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputExample"),d(ve,"class","docstring"),d(be,"class","docstring"),d(y,"class","docstring"),d($e,"class","docstring"),d(Q,"class","docstring"),d(xe,"class","docstring"),d(U,"class","docstring"),d(Ee,"id","glue"),d(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ee,"href","#glue"),d(ee,"class","relative group"),d(ht,"href","https://gluebenchmark.com/"),d(ht,"rel","nofollow"),d(ut,"href","https://openreview.net/pdf?id=rJ4km2R5t7"),d(ut,"rel","nofollow"),d(ts,"href","/docs/transformers/doc-build-test/en/main_classes/processors#transformers.InputExample"),d(Pe,"id","example-usage"),d(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Pe,"href","#example-usage"),d(te,"class","relative group"),d(_t,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_glue.py"),d(_t,"rel","nofollow"),d(Ae,"id","xnli"),d(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ae,"href","#xnli"),d(se,"class","relative group"),d(vt,"href","https://www.nyu.edu/projects/bowman/xnli/"),d(vt,"rel","nofollow"),d(bt,"href","http://www.nyu.edu/projects/bowman/multinli/"),d(bt,"rel","nofollow"),d(xt,"href","https://arxiv.org/abs/1809.05053"),d(xt,"rel","nofollow"),d(Et,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_xnli.py"),d(Et,"rel","nofollow"),d(Se,"id","squad"),d(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Se,"href","#squad"),d(ae,"class","relative group"),d(yt,"href","https://rajpurkar.github.io/SQuAD-explorer//"),d(yt,"rel","nofollow"),d(Pt,"href","https://arxiv.org/abs/1606.05250"),d(Pt,"rel","nofollow"),d(qt,"href","https://arxiv.org/abs/1806.03822"),d(qt,"rel","nofollow"),d(Ie,"id","transformers.data.processors.squad.SquadProcessor"),d(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ie,"href","#transformers.data.processors.squad.SquadProcessor"),d(oe,"class","relative group"),d(De,"class","docstring"),d(C,"class","docstring"),d(Te,"class","docstring"),d(D,"class","docstring"),d(je,"id","example-usage"),d(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(je,"href","#example-usage"),d(ne,"class","relative group"),d(Ct,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/question-answering/run_squad.py"),d(Ct,"rel","nofollow")},m(e,p){t(document.head,h),f(e,A,p),f(e,$,p),t($,x),t(x,N),_(q,N,null),t($,O),t($,M),t(M,L),f(e,E,p),f(e,j,p),t(j,B),f(e,Sr,p),f(e,ie,p),t(ie,K),t(K,to),t(K,Qt),t(Qt,so),t(K,ro),t(K,Ut),t(Ut,ao),t(K,oo),t(ie,no),t(ie,_s),t(_s,lo),f(e,Ir,p),f(e,Y,p),t(Y,ce),t(ce,gs),_(Qe,gs,null),t(Y,io),t(Y,vs),t(vs,co),f(e,Lr,p),f(e,Ht,p),t(Ht,po),f(e,Dr,p),f(e,Gt,p),t(Gt,fo),f(e,Tr,p),f(e,S,p),_(Ue,S,null),t(S,ho),t(S,bs),t(bs,uo),t(S,mo),t(S,G),_(He,G,null),t(G,_o),t(G,$s),t($s,go),t(G,vo),_(pe,G,null),t(S,bo),t(S,V),_(Ge,V,null),t(V,$o),t(V,Fe),t(Fe,xo),t(Fe,xs),t(xs,Eo),t(Fe,wo),t(V,yo),t(V,Es),t(Es,Po),t(V,qo),_(Re,V,null),t(S,Ao),t(S,F),_(We,F,null),t(F,ko),t(F,Xe),t(Xe,So),t(Xe,ws),t(ws,Io),t(Xe,Lo),t(F,Do),_(de,F,null),t(S,To),t(S,R),_(Je,R,null),t(R,No),t(R,Be),t(Be,Mo),t(Be,Ft),t(Ft,jo),t(Be,Vo),t(R,Co),_(fe,R,null),f(e,Nr,p),f(e,Z,p),t(Z,he),t(he,ys),_(Ke,ys,null),t(Z,zo),t(Z,Ps),t(Ps,Oo),f(e,Mr,p),f(e,T,p),t(T,Qo),t(T,Rt),t(Rt,Uo),t(T,Ho),t(T,Wt),t(Wt,Go),t(T,Fo),t(T,Xt),t(Xt,Ro),t(T,Wo),t(T,Jt),t(Jt,Xo),t(T,Jo),f(e,jr,p),f(e,y,p),_(Ye,y,null),t(y,Bo),t(y,qs),t(qs,Ko),t(y,Yo),t(y,ue),_(Ze,ue,null),t(ue,Zo),t(ue,et),t(et,en),t(et,Bt),t(Bt,tn),t(et,sn),t(y,rn),t(y,me),_(tt,me,null),t(me,an),t(me,As),t(As,on),t(y,nn),t(y,_e),_(st,_e,null),t(_e,ln),t(_e,ks),t(ks,cn),t(y,pn),t(y,ge),_(rt,ge,null),t(ge,dn),t(ge,at),t(at,fn),t(at,Kt),t(Kt,hn),t(at,un),t(y,mn),t(y,ve),_(ot,ve,null),t(ve,_n),t(ve,nt),t(nt,gn),t(nt,Yt),t(Yt,vn),t(nt,bn),t(y,$n),t(y,be),_(lt,be,null),t(be,xn),t(be,Ss),t(Ss,En),f(e,Vr,p),f(e,Q,p),_(it,Q,null),t(Q,wn),t(Q,Is),t(Is,yn),t(Q,Pn),t(Q,$e),_(ct,$e,null),t($e,qn),t($e,Ls),t(Ls,An),f(e,Cr,p),f(e,U,p),_(pt,U,null),t(U,kn),t(U,Ds),t(Ds,Sn),t(U,In),t(U,xe),_(dt,xe,null),t(xe,Ln),t(xe,Ts),t(Ts,Dn),f(e,zr,p),f(e,ee,p),t(ee,Ee),t(Ee,Ns),_(ft,Ns,null),t(ee,Tn),t(ee,Ms),t(Ms,Nn),f(e,Or,p),f(e,we,p),t(we,ht),t(ht,Mn),t(we,jn),t(we,ut),t(ut,Vn),f(e,Qr,p),f(e,Zt,p),t(Zt,Cn),f(e,Ur,p),f(e,es,p),t(es,zn),f(e,Hr,p),f(e,w,p),t(w,js),t(js,Vs),t(Vs,On),t(w,Qn),t(w,Cs),t(Cs,zs),t(zs,Un),t(w,Hn),t(w,Os),t(Os,Qs),t(Qs,Gn),t(w,Fn),t(w,Us),t(Us,Hs),t(Hs,Rn),t(w,Wn),t(w,Gs),t(Gs,Fs),t(Fs,Xn),t(w,Jn),t(w,Rs),t(Rs,Ws),t(Ws,Bn),t(w,Kn),t(w,Xs),t(Xs,Js),t(Js,Yn),t(w,Zn),t(w,Bs),t(Bs,Ks),t(Ks,el),t(w,tl),t(w,Ys),t(Ys,Zs),t(Zs,sl),f(e,Gr,p),f(e,ye,p),t(ye,rl),t(ye,ts),t(ts,al),t(ye,ol),f(e,Fr,p),f(e,ss,p),t(ss,nl),f(e,Rr,p),f(e,te,p),t(te,Pe),t(Pe,er),_(mt,er,null),t(te,ll),t(te,tr),t(tr,il),f(e,Wr,p),f(e,qe,p),t(qe,cl),t(qe,_t),t(_t,pl),t(qe,dl),f(e,Xr,p),f(e,se,p),t(se,Ae),t(Ae,sr),_(gt,sr,null),t(se,fl),t(se,rr),t(rr,hl),f(e,Jr,p),f(e,re,p),t(re,vt),t(vt,ul),t(re,ml),t(re,bt),t(bt,ar),t(ar,_l),t(re,gl),f(e,Br,p),f(e,$t,p),t($t,vl),t($t,xt),t(xt,bl),f(e,Kr,p),f(e,rs,p),t(rs,$l),f(e,Yr,p),f(e,as,p),t(as,or),t(or,nr),t(nr,xl),f(e,Zr,p),f(e,os,p),t(os,El),f(e,ea,p),f(e,ke,p),t(ke,wl),t(ke,Et),t(Et,yl),t(ke,Pl),f(e,ta,p),f(e,ae,p),t(ae,Se),t(Se,lr),_(wt,lr,null),t(ae,ql),t(ae,ir),t(ir,Al),f(e,sa,p),f(e,H,p),t(H,yt),t(yt,kl),t(H,Sl),t(H,Pt),t(Pt,Il),t(H,Ll),t(H,qt),t(qt,Dl),t(H,Tl),f(e,ra,p),f(e,ns,p),t(ns,Nl),f(e,aa,p),f(e,oe,p),t(oe,Ie),t(Ie,cr),_(At,cr,null),t(oe,Ml),t(oe,pr),t(pr,jl),f(e,oa,p),f(e,ls,p),t(ls,Vl),f(e,na,p),f(e,Le,p),t(Le,dr),t(dr,fr),t(fr,Cl),t(Le,zl),t(Le,hr),t(hr,ur),t(ur,Ol),f(e,la,p),f(e,kt,p),t(kt,Ql),t(kt,mr),t(mr,Ul),f(e,ia,p),f(e,D,p),_(St,D,null),t(D,Hl),t(D,_r),t(_r,Gl),t(D,Fl),t(D,De),_(It,De,null),t(De,Rl),t(De,gr),t(gr,Wl),t(D,Xl),t(D,C),_(Lt,C,null),t(C,Jl),t(C,Dt),t(Dt,Bl),t(Dt,vr),t(vr,Kl),t(Dt,Yl),t(C,Zl),t(C,br),t(br,ei),t(C,ti),_(Tt,C,null),t(D,si),t(D,Te),_(Nt,Te,null),t(Te,ri),t(Te,$r),t($r,ai),f(e,ca,p),f(e,Ne,p),t(Ne,oi),t(Ne,xr),t(xr,ni),t(Ne,li),f(e,pa,p),f(e,is,p),t(is,ii),f(e,da,p),f(e,Me,p),t(Me,ci),t(Me,Er),t(Er,pi),t(Me,di),f(e,fa,p),f(e,ne,p),t(ne,je),t(je,wr),_(Mt,wr,null),t(ne,fi),t(ne,yr),t(yr,hi),f(e,ha,p),f(e,cs,p),t(cs,ui),f(e,ua,p),_(jt,e,p),f(e,ma,p),f(e,Ve,p),t(Ve,mi),t(Ve,Pr),t(Pr,_i),t(Ve,gi),f(e,_a,p),_(Vt,e,p),f(e,ga,p),f(e,Ce,p),t(Ce,vi),t(Ce,Ct),t(Ct,bi),t(Ce,$i),va=!0},p(e,[p]){const zt={};p&2&&(zt.$$scope={dirty:p,ctx:e}),pe.$set(zt);const qr={};p&2&&(qr.$$scope={dirty:p,ctx:e}),de.$set(qr);const Ar={};p&2&&(Ar.$$scope={dirty:p,ctx:e}),fe.$set(Ar)},i(e){va||(g(q.$$.fragment,e),g(Qe.$$.fragment,e),g(Ue.$$.fragment,e),g(He.$$.fragment,e),g(pe.$$.fragment,e),g(Ge.$$.fragment,e),g(Re.$$.fragment,e),g(We.$$.fragment,e),g(de.$$.fragment,e),g(Je.$$.fragment,e),g(fe.$$.fragment,e),g(Ke.$$.fragment,e),g(Ye.$$.fragment,e),g(Ze.$$.fragment,e),g(tt.$$.fragment,e),g(st.$$.fragment,e),g(rt.$$.fragment,e),g(ot.$$.fragment,e),g(lt.$$.fragment,e),g(it.$$.fragment,e),g(ct.$$.fragment,e),g(pt.$$.fragment,e),g(dt.$$.fragment,e),g(ft.$$.fragment,e),g(mt.$$.fragment,e),g(gt.$$.fragment,e),g(wt.$$.fragment,e),g(At.$$.fragment,e),g(St.$$.fragment,e),g(It.$$.fragment,e),g(Lt.$$.fragment,e),g(Tt.$$.fragment,e),g(Nt.$$.fragment,e),g(Mt.$$.fragment,e),g(jt.$$.fragment,e),g(Vt.$$.fragment,e),va=!0)},o(e){v(q.$$.fragment,e),v(Qe.$$.fragment,e),v(Ue.$$.fragment,e),v(He.$$.fragment,e),v(pe.$$.fragment,e),v(Ge.$$.fragment,e),v(Re.$$.fragment,e),v(We.$$.fragment,e),v(de.$$.fragment,e),v(Je.$$.fragment,e),v(fe.$$.fragment,e),v(Ke.$$.fragment,e),v(Ye.$$.fragment,e),v(Ze.$$.fragment,e),v(tt.$$.fragment,e),v(st.$$.fragment,e),v(rt.$$.fragment,e),v(ot.$$.fragment,e),v(lt.$$.fragment,e),v(it.$$.fragment,e),v(ct.$$.fragment,e),v(pt.$$.fragment,e),v(dt.$$.fragment,e),v(ft.$$.fragment,e),v(mt.$$.fragment,e),v(gt.$$.fragment,e),v(wt.$$.fragment,e),v(At.$$.fragment,e),v(St.$$.fragment,e),v(It.$$.fragment,e),v(Lt.$$.fragment,e),v(Tt.$$.fragment,e),v(Nt.$$.fragment,e),v(Mt.$$.fragment,e),v(jt.$$.fragment,e),v(Vt.$$.fragment,e),va=!1},d(e){s(h),e&&s(A),e&&s($),b(q),e&&s(E),e&&s(j),e&&s(Sr),e&&s(ie),e&&s(Ir),e&&s(Y),b(Qe),e&&s(Lr),e&&s(Ht),e&&s(Dr),e&&s(Gt),e&&s(Tr),e&&s(S),b(Ue),b(He),b(pe),b(Ge),b(Re),b(We),b(de),b(Je),b(fe),e&&s(Nr),e&&s(Z),b(Ke),e&&s(Mr),e&&s(T),e&&s(jr),e&&s(y),b(Ye),b(Ze),b(tt),b(st),b(rt),b(ot),b(lt),e&&s(Vr),e&&s(Q),b(it),b(ct),e&&s(Cr),e&&s(U),b(pt),b(dt),e&&s(zr),e&&s(ee),b(ft),e&&s(Or),e&&s(we),e&&s(Qr),e&&s(Zt),e&&s(Ur),e&&s(es),e&&s(Hr),e&&s(w),e&&s(Gr),e&&s(ye),e&&s(Fr),e&&s(ss),e&&s(Rr),e&&s(te),b(mt),e&&s(Wr),e&&s(qe),e&&s(Xr),e&&s(se),b(gt),e&&s(Jr),e&&s(re),e&&s(Br),e&&s($t),e&&s(Kr),e&&s(rs),e&&s(Yr),e&&s(as),e&&s(Zr),e&&s(os),e&&s(ea),e&&s(ke),e&&s(ta),e&&s(ae),b(wt),e&&s(sa),e&&s(H),e&&s(ra),e&&s(ns),e&&s(aa),e&&s(oe),b(At),e&&s(oa),e&&s(ls),e&&s(na),e&&s(Le),e&&s(la),e&&s(kt),e&&s(ia),e&&s(D),b(St),b(It),b(Lt),b(Tt),b(Nt),e&&s(ca),e&&s(Ne),e&&s(pa),e&&s(is),e&&s(da),e&&s(Me),e&&s(fa),e&&s(ne),b(Mt),e&&s(ha),e&&s(cs),e&&s(ua),b(jt,e),e&&s(ma),e&&s(Ve),e&&s(_a),b(Vt,e),e&&s(ga),e&&s(Ce)}}}const Dp={local:"processors",sections:[{local:"transformers.ProcessorMixin",title:"Multi-modal processors"},{local:"transformers.DataProcessor",title:"Deprecated processors"},{local:"glue",sections:[{local:"example-usage",title:"Example usage"}],title:"GLUE"},{local:"xnli",title:"XNLI"},{local:"squad",sections:[{local:"transformers.data.processors.squad.SquadProcessor",title:"Processors"},{local:"example-usage",title:"Example usage"}],title:"SQuAD"}],title:"Processors"};function Tp(J,h,A){let{fw:$}=h;return J.$$set=x=>{"fw"in x&&A(0,$=x.fw)},[$]}class Op extends yp{constructor(h){super();Pp(this,h,Tp,Lp,qp,{fw:0})}}export{Op as default,Dp as metadata};
