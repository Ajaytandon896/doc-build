import{S as $n,i as xn,s as yn,e as l,k as h,w as d,t as a,L as wn,c as r,d as t,m as c,a as i,x as g,h as n,b as f,M as jn,J as s,g as p,y as v,q as _,o as k,B as $}from"../../chunks/vendor-9e2b328e.js";import{T as bn}from"../../chunks/Tip-76f97a76.js";import{I as os}from"../../chunks/IconCopyLink-fd0e58fd.js";import{C as z}from"../../chunks/CodeBlock-b9ff96e9.js";import"../../chunks/CopyButton-4b97cbf7.js";function En(Be){let m,P,u,x,F;return{c(){m=l("p"),P=a("Take a look at the "),u=l("a"),x=a("pipeline()"),F=a(" documentation for a complete list of supported taska."),this.h()},l(j){m=r(j,"P",{});var T=i(m);P=n(T,"Take a look at the "),u=r(T,"A",{href:!0});var N=i(u);x=n(N,"pipeline()"),N.forEach(t),F=n(T," documentation for a complete list of supported taska."),T.forEach(t),this.h()},h(){f(u,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline")},m(j,T){p(j,m,T),s(m,P),s(m,u),s(u,x),s(m,F)},d(j){j&&t(m)}}}function An(Be){let m,P,u,x,F,j,T,N,Zs,is,b,et,we,st,tt,Z,at,nt,je,lt,rt,ps,q,ee,ot,be,it,pt,ft,Ge,ht,ct,se,mt,Ee,ut,dt,fs,I,hs,L,O,Qe,te,gt,Xe,vt,cs,E,_t,Ae,kt,$t,Pe,xt,yt,Te,wt,jt,ms,qe,ae,bt,Me,Et,At,us,ne,ds,le,re,Pt,Se,Tt,qt,gs,oe,vs,ze,Mt,_s,ie,ks,y,St,Fe,zt,Ft,Ye,Lt,Ct,Le,Dt,Ht,Ze,Nt,It,$s,pe,xs,C,R,es,fe,Ot,ss,Rt,ys,w,Ut,Ce,Wt,Jt,he,Kt,Vt,ts,Bt,Gt,De,Qt,Xt,ws,ce,js,U,Yt,He,Zt,ea,bs,me,Es,W,sa,Ne,ta,aa,As,ue,Ps,D,J,as,de,na,ns,la,Ts,K,ra,Ie,oa,ia,qs,A,pa,ge,fa,ha,ve,ca,ma,Oe,ua,da,Ms,_e,Ss,V,ga,Re,va,_a,zs,ke,Fs,H,B,ls,$e,ka,rs,$a,Ls,G,xa,Ue,ya,wa,Cs,We,ja,Ds,Je,Ke,ba,Hs,xe,Ns;return j=new os({}),I=new bn({props:{$$slots:{default:[En]},$$scope:{ctx:Be}}}),te=new os({}),ne=new z({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>)`}}),oe=new z({props:{code:'generator("Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"),',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(<span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>)
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain&#x27;</span>}]`}}),ie=new z({props:{code:`generator(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ]
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne&quot;</span>,
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)`}}),pe=new z({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
    num_return_sequences=2,
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>    num_return_sequences=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)`}}),fe=new os({}),ce=new z({props:{code:`from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2"),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),me=new z({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation", model=model, tokenizer=tokenizer),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=model, tokenizer=tokenizer)`}}),ue=new z({props:{code:'generator("Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"),',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(<span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>)
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Dragon-lords (for them to rule in a world ruled by their rulers, and all who live within the realm&#x27;</span>}]`}}),de=new os({}),_e=new z({props:{code:`from transformers import pipeline

audio_classifier = pipeline(
    task="audio-classification", model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier = pipeline(
<span class="hljs-meta">... </span>    task=<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),ke=new z({props:{code:'audio_classifier("jfk_moon_speech.wav"),',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier(<span class="hljs-string">&quot;jfk_moon_speech.wav&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;calm&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.13856211304664612</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;disgust&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.13148026168346405</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;happy&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.12635163962841034</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;angry&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.12439591437578201</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;fearful&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.12404385954141617</span>}]`}}),$e=new os({}),xe=new z({props:{code:`from transformers import pipeline

vision_classifier = pipeline(task="image-classification")
vision_classifier(
    images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier = pipeline(task=<span class="hljs-string">&quot;image-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier(
<span class="hljs-meta">... </span>    images=<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">... </span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;lynx, catamount&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4403027892112732</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cougar, puma, catamount, mountain lion, painter, panther, Felis concolor&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.03433405980467796</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;snow leopard, ounce, Panthera uncia&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.032148055732250214</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;Egyptian cat&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.02353910356760025</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;tiger cat&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.023034192621707916</span>}]`}}),{c(){m=l("meta"),P=h(),u=l("h1"),x=l("a"),F=l("span"),d(j.$$.fragment),T=h(),N=l("span"),Zs=a("Pipelines for inference"),is=h(),b=l("p"),et=a("The "),we=l("a"),st=a("pipeline()"),tt=a(" makes it simple to use any model from the "),Z=l("a"),at=a("Model Hub"),nt=a(" for inference on a variety of tasks such as text generation, image segmentation and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),je=l("a"),lt=a("pipeline()"),rt=a("! This tutorial will teach you to:"),ps=h(),q=l("ul"),ee=l("li"),ot=a("Use a "),be=l("a"),it=a("pipeline()"),pt=a(" for inference."),ft=h(),Ge=l("li"),ht=a("Use a specific tokenizer or model."),ct=h(),se=l("li"),mt=a("Use a "),Ee=l("a"),ut=a("pipeline()"),dt=a(" for audio and vision tasks."),fs=h(),d(I.$$.fragment),hs=h(),L=l("h2"),O=l("a"),Qe=l("span"),d(te.$$.fragment),gt=h(),Xe=l("span"),vt=a("Pipeline usage"),cs=h(),E=l("p"),_t=a("While each task has an associated "),Ae=l("a"),kt=a("pipeline()"),$t=a(", it is simpler to use the general "),Pe=l("a"),xt=a("pipeline()"),yt=a(" abstraction which contains all the specific task pipelines. The "),Te=l("a"),wt=a("pipeline()"),jt=a(" automatically loads a default model and tokenizer capable of inference for your task."),ms=h(),qe=l("ol"),ae=l("li"),bt=a("Start by creating a "),Me=l("a"),Et=a("pipeline()"),At=a(" and specify an inference task:"),us=h(),d(ne.$$.fragment),ds=h(),le=l("ol"),re=l("li"),Pt=a("Pass your input text to the "),Se=l("a"),Tt=a("pipeline()"),qt=a(":"),gs=h(),d(oe.$$.fragment),vs=h(),ze=l("p"),Mt=a("If you have more than one input, pass your input as a list:"),_s=h(),d(ie.$$.fragment),ks=h(),y=l("p"),St=a("Any additional parameters for your task can also be included in the "),Fe=l("a"),zt=a("pipeline()"),Ft=a(". The "),Ye=l("code"),Lt=a("text-generation"),Ct=a(" task has a "),Le=l("a"),Dt=a("generate()"),Ht=a(" method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),Ze=l("code"),Nt=a("num_return_sequences"),It=a(" parameter:"),$s=h(),d(pe.$$.fragment),xs=h(),C=l("h3"),R=l("a"),es=l("span"),d(fe.$$.fragment),Ot=h(),ss=l("span"),Rt=a("Choose a model and tokenizer"),ys=h(),w=l("p"),Ut=a("The "),Ce=l("a"),Wt=a("pipeline()"),Jt=a(" accepts any model from the "),he=l("a"),Kt=a("Model Hub"),Vt=a(". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),ts=l("code"),Bt=a("AutoModelFor"),Gt=a(" and [`AutoTokenizer\u2019] class. For example, load the "),De=l("a"),Qt=a("AutoModelForCausalLM"),Xt=a(" class for a causal language modeling task:"),ws=h(),d(ce.$$.fragment),js=h(),U=l("p"),Yt=a("Create a "),He=l("a"),Zt=a("pipeline()"),ea=a(" for your task, and specify the model and tokenizer you\u2019ve loaded:"),bs=h(),d(me.$$.fragment),Es=h(),W=l("p"),sa=a("Pass your input text to the "),Ne=l("a"),ta=a("pipeline()"),aa=a(" to generate some text:"),As=h(),d(ue.$$.fragment),Ps=h(),D=l("h2"),J=l("a"),as=l("span"),d(de.$$.fragment),na=h(),ns=l("span"),la=a("Audio pipeline"),Ts=h(),K=l("p"),ra=a("The flexibility of the "),Ie=l("a"),oa=a("pipeline()"),ia=a(" means it can also be extended to audio tasks."),qs=h(),A=l("p"),pa=a("For example, let\u2019s classify the emotion from a short clip of John F. Kennedy\u2019s famous "),ge=l("a"),fa=a("\u201CWe choose to go to the Moon\u201D"),ha=a(" speech. Find an "),ve=l("a"),ca=a("audio classification"),ma=a(" model on the Model Hub for emotion recognition and load it in the "),Oe=l("a"),ua=a("pipeline()"),da=a(":"),Ms=h(),d(_e.$$.fragment),Ss=h(),V=l("p"),ga=a("Pass the audio file to the "),Re=l("a"),va=a("pipeline()"),_a=a(":"),zs=h(),d(ke.$$.fragment),Fs=h(),H=l("h2"),B=l("a"),ls=l("span"),d($e.$$.fragment),ka=h(),rs=l("span"),$a=a("Vision pipeline"),Ls=h(),G=l("p"),xa=a("Finally, using a "),Ue=l("a"),ya=a("pipeline()"),wa=a(" for vision tasks is practically identical."),Cs=h(),We=l("p"),ja=a("Specify your vision task and pass your image to the classifier. The imaage can be a link or a local path to the image. For example, what species of cat is shown below?"),Ds=h(),Je=l("p"),Ke=l("img"),Hs=h(),d(xe.$$.fragment),this.h()},l(e){const o=wn('[data-svelte="svelte-1phssyn"]',document.head);m=r(o,"META",{name:!0,content:!0}),o.forEach(t),P=c(e),u=r(e,"H1",{class:!0});var ye=i(u);x=r(ye,"A",{id:!0,class:!0,href:!0});var Ea=i(x);F=r(Ea,"SPAN",{});var Aa=i(F);g(j.$$.fragment,Aa),Aa.forEach(t),Ea.forEach(t),T=c(ye),N=r(ye,"SPAN",{});var Pa=i(N);Zs=n(Pa,"Pipelines for inference"),Pa.forEach(t),ye.forEach(t),is=c(e),b=r(e,"P",{});var Q=i(b);et=n(Q,"The "),we=r(Q,"A",{href:!0});var Ta=i(we);st=n(Ta,"pipeline()"),Ta.forEach(t),tt=n(Q," makes it simple to use any model from the "),Z=r(Q,"A",{href:!0,rel:!0});var qa=i(Z);at=n(qa,"Model Hub"),qa.forEach(t),nt=n(Q," for inference on a variety of tasks such as text generation, image segmentation and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),je=r(Q,"A",{href:!0});var Ma=i(je);lt=n(Ma,"pipeline()"),Ma.forEach(t),rt=n(Q,"! This tutorial will teach you to:"),Q.forEach(t),ps=c(e),q=r(e,"UL",{});var Ve=i(q);ee=r(Ve,"LI",{});var Is=i(ee);ot=n(Is,"Use a "),be=r(Is,"A",{href:!0});var Sa=i(be);it=n(Sa,"pipeline()"),Sa.forEach(t),pt=n(Is," for inference."),Is.forEach(t),ft=c(Ve),Ge=r(Ve,"LI",{});var za=i(Ge);ht=n(za,"Use a specific tokenizer or model."),za.forEach(t),ct=c(Ve),se=r(Ve,"LI",{});var Os=i(se);mt=n(Os,"Use a "),Ee=r(Os,"A",{href:!0});var Fa=i(Ee);ut=n(Fa,"pipeline()"),Fa.forEach(t),dt=n(Os," for audio and vision tasks."),Os.forEach(t),Ve.forEach(t),fs=c(e),g(I.$$.fragment,e),hs=c(e),L=r(e,"H2",{class:!0});var Rs=i(L);O=r(Rs,"A",{id:!0,class:!0,href:!0});var La=i(O);Qe=r(La,"SPAN",{});var Ca=i(Qe);g(te.$$.fragment,Ca),Ca.forEach(t),La.forEach(t),gt=c(Rs),Xe=r(Rs,"SPAN",{});var Da=i(Xe);vt=n(Da,"Pipeline usage"),Da.forEach(t),Rs.forEach(t),cs=c(e),E=r(e,"P",{});var X=i(E);_t=n(X,"While each task has an associated "),Ae=r(X,"A",{href:!0});var Ha=i(Ae);kt=n(Ha,"pipeline()"),Ha.forEach(t),$t=n(X,", it is simpler to use the general "),Pe=r(X,"A",{href:!0});var Na=i(Pe);xt=n(Na,"pipeline()"),Na.forEach(t),yt=n(X," abstraction which contains all the specific task pipelines. The "),Te=r(X,"A",{href:!0});var Ia=i(Te);wt=n(Ia,"pipeline()"),Ia.forEach(t),jt=n(X," automatically loads a default model and tokenizer capable of inference for your task."),X.forEach(t),ms=c(e),qe=r(e,"OL",{});var Oa=i(qe);ae=r(Oa,"LI",{});var Us=i(ae);bt=n(Us,"Start by creating a "),Me=r(Us,"A",{href:!0});var Ra=i(Me);Et=n(Ra,"pipeline()"),Ra.forEach(t),At=n(Us," and specify an inference task:"),Us.forEach(t),Oa.forEach(t),us=c(e),g(ne.$$.fragment,e),ds=c(e),le=r(e,"OL",{start:!0});var Ua=i(le);re=r(Ua,"LI",{});var Ws=i(re);Pt=n(Ws,"Pass your input text to the "),Se=r(Ws,"A",{href:!0});var Wa=i(Se);Tt=n(Wa,"pipeline()"),Wa.forEach(t),qt=n(Ws,":"),Ws.forEach(t),Ua.forEach(t),gs=c(e),g(oe.$$.fragment,e),vs=c(e),ze=r(e,"P",{});var Ja=i(ze);Mt=n(Ja,"If you have more than one input, pass your input as a list:"),Ja.forEach(t),_s=c(e),g(ie.$$.fragment,e),ks=c(e),y=r(e,"P",{});var M=i(y);St=n(M,"Any additional parameters for your task can also be included in the "),Fe=r(M,"A",{href:!0});var Ka=i(Fe);zt=n(Ka,"pipeline()"),Ka.forEach(t),Ft=n(M,". The "),Ye=r(M,"CODE",{});var Va=i(Ye);Lt=n(Va,"text-generation"),Va.forEach(t),Ct=n(M," task has a "),Le=r(M,"A",{href:!0});var Ba=i(Le);Dt=n(Ba,"generate()"),Ba.forEach(t),Ht=n(M," method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),Ze=r(M,"CODE",{});var Ga=i(Ze);Nt=n(Ga,"num_return_sequences"),Ga.forEach(t),It=n(M," parameter:"),M.forEach(t),$s=c(e),g(pe.$$.fragment,e),xs=c(e),C=r(e,"H3",{class:!0});var Js=i(C);R=r(Js,"A",{id:!0,class:!0,href:!0});var Qa=i(R);es=r(Qa,"SPAN",{});var Xa=i(es);g(fe.$$.fragment,Xa),Xa.forEach(t),Qa.forEach(t),Ot=c(Js),ss=r(Js,"SPAN",{});var Ya=i(ss);Rt=n(Ya,"Choose a model and tokenizer"),Ya.forEach(t),Js.forEach(t),ys=c(e),w=r(e,"P",{});var S=i(w);Ut=n(S,"The "),Ce=r(S,"A",{href:!0});var Za=i(Ce);Wt=n(Za,"pipeline()"),Za.forEach(t),Jt=n(S," accepts any model from the "),he=r(S,"A",{href:!0,rel:!0});var en=i(he);Kt=n(en,"Model Hub"),en.forEach(t),Vt=n(S,". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),ts=r(S,"CODE",{});var sn=i(ts);Bt=n(sn,"AutoModelFor"),sn.forEach(t),Gt=n(S," and [`AutoTokenizer\u2019] class. For example, load the "),De=r(S,"A",{href:!0});var tn=i(De);Qt=n(tn,"AutoModelForCausalLM"),tn.forEach(t),Xt=n(S," class for a causal language modeling task:"),S.forEach(t),ws=c(e),g(ce.$$.fragment,e),js=c(e),U=r(e,"P",{});var Ks=i(U);Yt=n(Ks,"Create a "),He=r(Ks,"A",{href:!0});var an=i(He);Zt=n(an,"pipeline()"),an.forEach(t),ea=n(Ks," for your task, and specify the model and tokenizer you\u2019ve loaded:"),Ks.forEach(t),bs=c(e),g(me.$$.fragment,e),Es=c(e),W=r(e,"P",{});var Vs=i(W);sa=n(Vs,"Pass your input text to the "),Ne=r(Vs,"A",{href:!0});var nn=i(Ne);ta=n(nn,"pipeline()"),nn.forEach(t),aa=n(Vs," to generate some text:"),Vs.forEach(t),As=c(e),g(ue.$$.fragment,e),Ps=c(e),D=r(e,"H2",{class:!0});var Bs=i(D);J=r(Bs,"A",{id:!0,class:!0,href:!0});var ln=i(J);as=r(ln,"SPAN",{});var rn=i(as);g(de.$$.fragment,rn),rn.forEach(t),ln.forEach(t),na=c(Bs),ns=r(Bs,"SPAN",{});var on=i(ns);la=n(on,"Audio pipeline"),on.forEach(t),Bs.forEach(t),Ts=c(e),K=r(e,"P",{});var Gs=i(K);ra=n(Gs,"The flexibility of the "),Ie=r(Gs,"A",{href:!0});var pn=i(Ie);oa=n(pn,"pipeline()"),pn.forEach(t),ia=n(Gs," means it can also be extended to audio tasks."),Gs.forEach(t),qs=c(e),A=r(e,"P",{});var Y=i(A);pa=n(Y,"For example, let\u2019s classify the emotion from a short clip of John F. Kennedy\u2019s famous "),ge=r(Y,"A",{href:!0,rel:!0});var fn=i(ge);fa=n(fn,"\u201CWe choose to go to the Moon\u201D"),fn.forEach(t),ha=n(Y," speech. Find an "),ve=r(Y,"A",{href:!0,rel:!0});var hn=i(ve);ca=n(hn,"audio classification"),hn.forEach(t),ma=n(Y," model on the Model Hub for emotion recognition and load it in the "),Oe=r(Y,"A",{href:!0});var cn=i(Oe);ua=n(cn,"pipeline()"),cn.forEach(t),da=n(Y,":"),Y.forEach(t),Ms=c(e),g(_e.$$.fragment,e),Ss=c(e),V=r(e,"P",{});var Qs=i(V);ga=n(Qs,"Pass the audio file to the "),Re=r(Qs,"A",{href:!0});var mn=i(Re);va=n(mn,"pipeline()"),mn.forEach(t),_a=n(Qs,":"),Qs.forEach(t),zs=c(e),g(ke.$$.fragment,e),Fs=c(e),H=r(e,"H2",{class:!0});var Xs=i(H);B=r(Xs,"A",{id:!0,class:!0,href:!0});var un=i(B);ls=r(un,"SPAN",{});var dn=i(ls);g($e.$$.fragment,dn),dn.forEach(t),un.forEach(t),ka=c(Xs),rs=r(Xs,"SPAN",{});var gn=i(rs);$a=n(gn,"Vision pipeline"),gn.forEach(t),Xs.forEach(t),Ls=c(e),G=r(e,"P",{});var Ys=i(G);xa=n(Ys,"Finally, using a "),Ue=r(Ys,"A",{href:!0});var vn=i(Ue);ya=n(vn,"pipeline()"),vn.forEach(t),wa=n(Ys," for vision tasks is practically identical."),Ys.forEach(t),Cs=c(e),We=r(e,"P",{});var _n=i(We);ja=n(_n,"Specify your vision task and pass your image to the classifier. The imaage can be a link or a local path to the image. For example, what species of cat is shown below?"),_n.forEach(t),Ds=c(e),Je=r(e,"P",{});var kn=i(Je);Ke=r(kn,"IMG",{src:!0,alt:!0}),kn.forEach(t),Hs=c(e),g(xe.$$.fragment,e),this.h()},h(){f(m,"name","hf:doc:metadata"),f(m,"content",JSON.stringify(Pn)),f(x,"id","pipelines-for-inference"),f(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(x,"href","#pipelines-for-inference"),f(u,"class","relative group"),f(we,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Z,"href","https://huggingface.co/models"),f(Z,"rel","nofollow"),f(je,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(be,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Ee,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(O,"id","pipeline-usage"),f(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(O,"href","#pipeline-usage"),f(L,"class","relative group"),f(Ae,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Pe,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Te,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Me,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Se,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(le,"start","2"),f(Fe,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Le,"href","/docs/transformers/doc-build-test/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),f(R,"id","choose-a-model-and-tokenizer"),f(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(R,"href","#choose-a-model-and-tokenizer"),f(C,"class","relative group"),f(Ce,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(he,"href","https://huggingface.co/models"),f(he,"rel","nofollow"),f(De,"href","/docs/transformers/doc-build-test/en/model_doc/auto#transformers.AutoModelForCausalLM"),f(He,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Ne,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(J,"id","audio-pipeline"),f(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(J,"href","#audio-pipeline"),f(D,"class","relative group"),f(Ie,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(ge,"href","https://en.wikipedia.org/wiki/We_choose_to_go_to_the_Moon"),f(ge,"rel","nofollow"),f(ve,"href","https://huggingface.co/models?pipeline_tag=audio-classification"),f(ve,"rel","nofollow"),f(Oe,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(Re,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),f(B,"id","vision-pipeline"),f(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(B,"href","#vision-pipeline"),f(H,"class","relative group"),f(Ue,"href","/docs/transformers/doc-build-test/en/main_classes/pipelines#transformers.pipeline"),jn(Ke.src,ba="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg")||f(Ke,"src",ba),f(Ke,"alt","pipeline-cat-chonk")},m(e,o){s(document.head,m),p(e,P,o),p(e,u,o),s(u,x),s(x,F),v(j,F,null),s(u,T),s(u,N),s(N,Zs),p(e,is,o),p(e,b,o),s(b,et),s(b,we),s(we,st),s(b,tt),s(b,Z),s(Z,at),s(b,nt),s(b,je),s(je,lt),s(b,rt),p(e,ps,o),p(e,q,o),s(q,ee),s(ee,ot),s(ee,be),s(be,it),s(ee,pt),s(q,ft),s(q,Ge),s(Ge,ht),s(q,ct),s(q,se),s(se,mt),s(se,Ee),s(Ee,ut),s(se,dt),p(e,fs,o),v(I,e,o),p(e,hs,o),p(e,L,o),s(L,O),s(O,Qe),v(te,Qe,null),s(L,gt),s(L,Xe),s(Xe,vt),p(e,cs,o),p(e,E,o),s(E,_t),s(E,Ae),s(Ae,kt),s(E,$t),s(E,Pe),s(Pe,xt),s(E,yt),s(E,Te),s(Te,wt),s(E,jt),p(e,ms,o),p(e,qe,o),s(qe,ae),s(ae,bt),s(ae,Me),s(Me,Et),s(ae,At),p(e,us,o),v(ne,e,o),p(e,ds,o),p(e,le,o),s(le,re),s(re,Pt),s(re,Se),s(Se,Tt),s(re,qt),p(e,gs,o),v(oe,e,o),p(e,vs,o),p(e,ze,o),s(ze,Mt),p(e,_s,o),v(ie,e,o),p(e,ks,o),p(e,y,o),s(y,St),s(y,Fe),s(Fe,zt),s(y,Ft),s(y,Ye),s(Ye,Lt),s(y,Ct),s(y,Le),s(Le,Dt),s(y,Ht),s(y,Ze),s(Ze,Nt),s(y,It),p(e,$s,o),v(pe,e,o),p(e,xs,o),p(e,C,o),s(C,R),s(R,es),v(fe,es,null),s(C,Ot),s(C,ss),s(ss,Rt),p(e,ys,o),p(e,w,o),s(w,Ut),s(w,Ce),s(Ce,Wt),s(w,Jt),s(w,he),s(he,Kt),s(w,Vt),s(w,ts),s(ts,Bt),s(w,Gt),s(w,De),s(De,Qt),s(w,Xt),p(e,ws,o),v(ce,e,o),p(e,js,o),p(e,U,o),s(U,Yt),s(U,He),s(He,Zt),s(U,ea),p(e,bs,o),v(me,e,o),p(e,Es,o),p(e,W,o),s(W,sa),s(W,Ne),s(Ne,ta),s(W,aa),p(e,As,o),v(ue,e,o),p(e,Ps,o),p(e,D,o),s(D,J),s(J,as),v(de,as,null),s(D,na),s(D,ns),s(ns,la),p(e,Ts,o),p(e,K,o),s(K,ra),s(K,Ie),s(Ie,oa),s(K,ia),p(e,qs,o),p(e,A,o),s(A,pa),s(A,ge),s(ge,fa),s(A,ha),s(A,ve),s(ve,ca),s(A,ma),s(A,Oe),s(Oe,ua),s(A,da),p(e,Ms,o),v(_e,e,o),p(e,Ss,o),p(e,V,o),s(V,ga),s(V,Re),s(Re,va),s(V,_a),p(e,zs,o),v(ke,e,o),p(e,Fs,o),p(e,H,o),s(H,B),s(B,ls),v($e,ls,null),s(H,ka),s(H,rs),s(rs,$a),p(e,Ls,o),p(e,G,o),s(G,xa),s(G,Ue),s(Ue,ya),s(G,wa),p(e,Cs,o),p(e,We,o),s(We,ja),p(e,Ds,o),p(e,Je,o),s(Je,Ke),p(e,Hs,o),v(xe,e,o),Ns=!0},p(e,[o]){const ye={};o&2&&(ye.$$scope={dirty:o,ctx:e}),I.$set(ye)},i(e){Ns||(_(j.$$.fragment,e),_(I.$$.fragment,e),_(te.$$.fragment,e),_(ne.$$.fragment,e),_(oe.$$.fragment,e),_(ie.$$.fragment,e),_(pe.$$.fragment,e),_(fe.$$.fragment,e),_(ce.$$.fragment,e),_(me.$$.fragment,e),_(ue.$$.fragment,e),_(de.$$.fragment,e),_(_e.$$.fragment,e),_(ke.$$.fragment,e),_($e.$$.fragment,e),_(xe.$$.fragment,e),Ns=!0)},o(e){k(j.$$.fragment,e),k(I.$$.fragment,e),k(te.$$.fragment,e),k(ne.$$.fragment,e),k(oe.$$.fragment,e),k(ie.$$.fragment,e),k(pe.$$.fragment,e),k(fe.$$.fragment,e),k(ce.$$.fragment,e),k(me.$$.fragment,e),k(ue.$$.fragment,e),k(de.$$.fragment,e),k(_e.$$.fragment,e),k(ke.$$.fragment,e),k($e.$$.fragment,e),k(xe.$$.fragment,e),Ns=!1},d(e){t(m),e&&t(P),e&&t(u),$(j),e&&t(is),e&&t(b),e&&t(ps),e&&t(q),e&&t(fs),$(I,e),e&&t(hs),e&&t(L),$(te),e&&t(cs),e&&t(E),e&&t(ms),e&&t(qe),e&&t(us),$(ne,e),e&&t(ds),e&&t(le),e&&t(gs),$(oe,e),e&&t(vs),e&&t(ze),e&&t(_s),$(ie,e),e&&t(ks),e&&t(y),e&&t($s),$(pe,e),e&&t(xs),e&&t(C),$(fe),e&&t(ys),e&&t(w),e&&t(ws),$(ce,e),e&&t(js),e&&t(U),e&&t(bs),$(me,e),e&&t(Es),e&&t(W),e&&t(As),$(ue,e),e&&t(Ps),e&&t(D),$(de),e&&t(Ts),e&&t(K),e&&t(qs),e&&t(A),e&&t(Ms),$(_e,e),e&&t(Ss),e&&t(V),e&&t(zs),$(ke,e),e&&t(Fs),e&&t(H),$($e),e&&t(Ls),e&&t(G),e&&t(Cs),e&&t(We),e&&t(Ds),e&&t(Je),e&&t(Hs),$(xe,e)}}}const Pn={local:"pipelines-for-inference",sections:[{local:"pipeline-usage",sections:[{local:"choose-a-model-and-tokenizer",title:"Choose a model and tokenizer"}],title:"Pipeline usage"},{local:"audio-pipeline",title:"Audio pipeline"},{local:"vision-pipeline",title:"Vision pipeline"}],title:"Pipelines for inference"};function Tn(Be,m,P){let{fw:u}=m;return Be.$$set=x=>{"fw"in x&&P(0,u=x.fw)},[u]}class Ln extends $n{constructor(m){super();xn(this,m,Tn,An,yn,{fw:0})}}export{Ln as default,Pn as metadata};
