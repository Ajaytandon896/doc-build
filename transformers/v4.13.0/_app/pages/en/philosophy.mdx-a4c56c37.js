import{S as Va,i as Xa,s as Za,e as a,k as i,w as Ka,t as l,L as er,c as r,d as t,m as d,a as s,x as Da,h as n,b as h,J as e,g as f,y as Ga,K as tr,q as Ra,o as Ja,B as Ya}from"../../chunks/vendor-e859c359.js";import{I as Qa}from"../../chunks/IconCopyLink-5fae3b20.js";function or(vt){let g,Y,u,p,pe,B,yt,ve,wt,Ge,Q,gt,Re,_,ye,_t,bt,we,Et,kt,ge,Tt,Je,V,Pt,Ye,L,O,_e,Lt,It,v,y,At,X,zt,xt,Z,Mt,$t,ee,Nt,St,qt,k,Bt,be,Ot,Ct,C,Ft,Ut,jt,w,Ht,te,Wt,Kt,oe,Dt,Gt,ae,Rt,Jt,Yt,Ee,Qt,Vt,F,ke,Xt,Zt,U,Te,eo,to,j,oo,Pe,ao,ro,Qe,re,so,Ve,b,H,Le,lo,no,W,Ie,io,co,Ae,ho,fo,K,ze,uo,mo,D,xe,po,vo,Me,yo,wo,$e,Ne,go,Xe,T,I,Se,G,_o,qe,bo,Ze,se,Eo,et,E,m,Be,ko,To,le,Po,Lo,R,Io,Ao,J,zo,xo,Mo,A,Oe,$o,No,ne,So,qo,Bo,z,Ce,Oo,Co,ie,Fo,Uo,tt,de,jo,ot,x,M,Fe,Ho,Wo,ce,Ko,Do,Go,$,Ue,Ro,Jo,je,Yo,Qo,at;return B=new Qa({}),G=new Qa({}),{c(){g=a("meta"),Y=i(),u=a("h1"),p=a("a"),pe=a("span"),Ka(B.$$.fragment),yt=i(),ve=a("span"),wt=l("Philosophy"),Ge=i(),Q=a("p"),gt=l("\u{1F917} Transformers is an opinionated library built for:"),Re=i(),_=a("ul"),ye=a("li"),_t=l("NLP researchers and educators seeking to use/study/extend large-scale transformers models"),bt=i(),we=a("li"),Et=l("hands-on practitioners who want to fine-tune those models and/or serve them in production"),kt=i(),ge=a("li"),Tt=l("engineers who just want to download a pretrained model and use it to solve a given NLP task."),Je=i(),V=a("p"),Pt=l("The library was designed with two strong goals in mind:"),Ye=i(),L=a("ul"),O=a("li"),_e=a("p"),Lt=l("Be as easy and fast to use as possible:"),It=i(),v=a("ul"),y=a("li"),At=l(`We strongly limited the number of user-facing abstractions to learn, in fact, there are almost no abstractions,
just three standard classes required to use each model: `),X=a("a"),zt=l("configuration"),xt=l(`,
`),Z=a("a"),Mt=l("models"),$t=l(" and "),ee=a("a"),Nt=l("tokenizer"),St=l("."),qt=i(),k=a("li"),Bt=l(`All of these classes can be initialized in a simple and unified way from pretrained instances by using a common
`),be=a("code"),Ot=l("from_pretrained()"),Ct=l(` instantiation method which will take care of downloading (if needed), caching and
loading the related class instance and associated data (configurations\u2019 hyper-parameters, tokenizers\u2019 vocabulary,
and models\u2019 weights) from a pretrained checkpoint provided on `),C=a("a"),Ft=l("Hugging Face Hub"),Ut=l(" or your own saved checkpoint."),jt=i(),w=a("li"),Ht=l("On top of those three base classes, the library provides two APIs: "),te=a("a"),Wt=l("pipeline()"),Kt=l(` for quickly
using a model (plus its associated tokenizer and configuration) on a given task and
`),oe=a("a"),Dt=l("Trainer"),Gt=l("/"),ae=a("a"),Rt=l("TFTrainer"),Jt=l(" to quickly train or fine-tune a given model."),Yt=i(),Ee=a("li"),Qt=l(`As a consequence, this library is NOT a modular toolbox of building blocks for neural nets. If you want to
extend/build-upon the library, just use regular Python/PyTorch/TensorFlow/Keras modules and inherit from the base
classes of the library to reuse functionalities like model loading/saving.`),Vt=i(),F=a("li"),ke=a("p"),Xt=l("Provide state-of-the-art models with performances as close as possible to the original models:"),Zt=i(),U=a("ul"),Te=a("li"),eo=l(`We provide at least one example for each architecture which reproduces a result provided by the official authors
of said architecture.`),to=i(),j=a("li"),oo=l(`The code is usually as close to the original code base as possible which means some PyTorch code may be not as
`),Pe=a("em"),ao=l("pytorchic"),ro=l(" as it could be as a result of being converted TensorFlow code and vice versa."),Qe=i(),re=a("p"),so=l("A few other goals:"),Ve=i(),b=a("ul"),H=a("li"),Le=a("p"),lo=l("Expose the models\u2019 internals as consistently as possible:"),no=i(),W=a("ul"),Ie=a("li"),io=l("We give access, using a single API, to the full hidden-states and attention weights."),co=i(),Ae=a("li"),ho=l("Tokenizer and base model\u2019s API are standardized to easily switch between models."),fo=i(),K=a("li"),ze=a("p"),uo=l("Incorporate a subjective selection of promising tools for fine-tuning/investigating these models:"),mo=i(),D=a("ul"),xe=a("li"),po=l("A simple/consistent way to add new tokens to the vocabulary and embeddings for fine-tuning."),vo=i(),Me=a("li"),yo=l("Simple ways to mask and prune transformer heads."),wo=i(),$e=a("li"),Ne=a("p"),go=l("Switch easily between PyTorch and TensorFlow 2.0, allowing training using one framework and inference using another."),Xe=i(),T=a("h2"),I=a("a"),Se=a("span"),Ka(G.$$.fragment),_o=i(),qe=a("span"),bo=l("Main concepts"),Ze=i(),se=a("p"),Eo=l("The library is built around three types of classes for each model:"),et=i(),E=a("ul"),m=a("li"),Be=a("strong"),ko=l("Model classes"),To=l(" such as "),le=a("a"),Po=l("BertModel"),Lo=l(", which are 30+ PyTorch models ("),R=a("a"),Io=l("torch.nn.Module"),Ao=l(") or Keras models ("),J=a("a"),zo=l("tf.keras.Model"),xo=l(`) that work with the pretrained weights provided in the
library.`),Mo=i(),A=a("li"),Oe=a("strong"),$o=l("Configuration classes"),No=l(" such as "),ne=a("a"),So=l("BertConfig"),qo=l(`, which store all the parameters required to build
a model. You don\u2019t always need to instantiate these yourself. In particular, if you are using a pretrained model
without any modification, creating the model will automatically take care of instantiating the configuration (which
is part of the model).`),Bo=i(),z=a("li"),Ce=a("strong"),Oo=l("Tokenizer classes"),Co=l(" such as "),ie=a("a"),Fo=l("BertTokenizer"),Uo=l(`, which store the vocabulary for each model and
provide methods for encoding/decoding strings in a list of token embeddings indices to be fed to a model.`),tt=i(),de=a("p"),jo=l("All these classes can be instantiated from pretrained instances and saved locally using two methods:"),ot=i(),x=a("ul"),M=a("li"),Fe=a("code"),Ho=l("from_pretrained()"),Wo=l(` lets you instantiate a model/configuration/tokenizer from a pretrained version either
provided by the library itself (the supported models are provided in the list `),ce=a("a"),Ko=l("here"),Do=l(`) or
stored locally (or on a server) by the user,`),Go=i(),$=a("li"),Ue=a("code"),Ro=l("save_pretrained()"),Jo=l(` lets you save a model/configuration/tokenizer locally so that it can be reloaded using
`),je=a("code"),Yo=l("from_pretrained()"),Qo=l("."),this.h()},l(o){const c=er('[data-svelte="svelte-1phssyn"]',document.head);g=r(c,"META",{name:!0,content:!0}),c.forEach(t),Y=d(o),u=r(o,"H1",{class:!0});var rt=s(u);p=r(rt,"A",{id:!0,class:!0,href:!0});var Vo=s(p);pe=r(Vo,"SPAN",{});var Xo=s(pe);Da(B.$$.fragment,Xo),Xo.forEach(t),Vo.forEach(t),yt=d(rt),ve=r(rt,"SPAN",{});var Zo=s(ve);wt=n(Zo,"Philosophy"),Zo.forEach(t),rt.forEach(t),Ge=d(o),Q=r(o,"P",{});var ea=s(Q);gt=n(ea,"\u{1F917} Transformers is an opinionated library built for:"),ea.forEach(t),Re=d(o),_=r(o,"UL",{});var he=s(_);ye=r(he,"LI",{});var ta=s(ye);_t=n(ta,"NLP researchers and educators seeking to use/study/extend large-scale transformers models"),ta.forEach(t),bt=d(he),we=r(he,"LI",{});var oa=s(we);Et=n(oa,"hands-on practitioners who want to fine-tune those models and/or serve them in production"),oa.forEach(t),kt=d(he),ge=r(he,"LI",{});var aa=s(ge);Tt=n(aa,"engineers who just want to download a pretrained model and use it to solve a given NLP task."),aa.forEach(t),he.forEach(t),Je=d(o),V=r(o,"P",{});var ra=s(V);Pt=n(ra,"The library was designed with two strong goals in mind:"),ra.forEach(t),Ye=d(o),L=r(o,"UL",{});var st=s(L);O=r(st,"LI",{});var lt=s(O);_e=r(lt,"P",{});var sa=s(_e);Lt=n(sa,"Be as easy and fast to use as possible:"),sa.forEach(t),It=d(lt),v=r(lt,"UL",{});var N=s(v);y=r(N,"LI",{});var S=s(y);At=n(S,`We strongly limited the number of user-facing abstractions to learn, in fact, there are almost no abstractions,
just three standard classes required to use each model: `),X=r(S,"A",{href:!0});var la=s(X);zt=n(la,"configuration"),la.forEach(t),xt=n(S,`,
`),Z=r(S,"A",{href:!0});var na=s(Z);Mt=n(na,"models"),na.forEach(t),$t=n(S," and "),ee=r(S,"A",{href:!0});var ia=s(ee);Nt=n(ia,"tokenizer"),ia.forEach(t),St=n(S,"."),S.forEach(t),qt=d(N),k=r(N,"LI",{});var fe=s(k);Bt=n(fe,`All of these classes can be initialized in a simple and unified way from pretrained instances by using a common
`),be=r(fe,"CODE",{});var da=s(be);Ot=n(da,"from_pretrained()"),da.forEach(t),Ct=n(fe,` instantiation method which will take care of downloading (if needed), caching and
loading the related class instance and associated data (configurations\u2019 hyper-parameters, tokenizers\u2019 vocabulary,
and models\u2019 weights) from a pretrained checkpoint provided on `),C=r(fe,"A",{href:!0,rel:!0});var ca=s(C);Ft=n(ca,"Hugging Face Hub"),ca.forEach(t),Ut=n(fe," or your own saved checkpoint."),fe.forEach(t),jt=d(N),w=r(N,"LI",{});var q=s(w);Ht=n(q,"On top of those three base classes, the library provides two APIs: "),te=r(q,"A",{href:!0});var ha=s(te);Wt=n(ha,"pipeline()"),ha.forEach(t),Kt=n(q,` for quickly
using a model (plus its associated tokenizer and configuration) on a given task and
`),oe=r(q,"A",{href:!0});var fa=s(oe);Dt=n(fa,"Trainer"),fa.forEach(t),Gt=n(q,"/"),ae=r(q,"A",{href:!0});var ua=s(ae);Rt=n(ua,"TFTrainer"),ua.forEach(t),Jt=n(q," to quickly train or fine-tune a given model."),q.forEach(t),Yt=d(N),Ee=r(N,"LI",{});var ma=s(Ee);Qt=n(ma,`As a consequence, this library is NOT a modular toolbox of building blocks for neural nets. If you want to
extend/build-upon the library, just use regular Python/PyTorch/TensorFlow/Keras modules and inherit from the base
classes of the library to reuse functionalities like model loading/saving.`),ma.forEach(t),N.forEach(t),lt.forEach(t),Vt=d(st),F=r(st,"LI",{});var nt=s(F);ke=r(nt,"P",{});var pa=s(ke);Xt=n(pa,"Provide state-of-the-art models with performances as close as possible to the original models:"),pa.forEach(t),Zt=d(nt),U=r(nt,"UL",{});var it=s(U);Te=r(it,"LI",{});var va=s(Te);eo=n(va,`We provide at least one example for each architecture which reproduces a result provided by the official authors
of said architecture.`),va.forEach(t),to=d(it),j=r(it,"LI",{});var dt=s(j);oo=n(dt,`The code is usually as close to the original code base as possible which means some PyTorch code may be not as
`),Pe=r(dt,"EM",{});var ya=s(Pe);ao=n(ya,"pytorchic"),ya.forEach(t),ro=n(dt," as it could be as a result of being converted TensorFlow code and vice versa."),dt.forEach(t),it.forEach(t),nt.forEach(t),st.forEach(t),Qe=d(o),re=r(o,"P",{});var wa=s(re);so=n(wa,"A few other goals:"),wa.forEach(t),Ve=d(o),b=r(o,"UL",{});var ue=s(b);H=r(ue,"LI",{});var ct=s(H);Le=r(ct,"P",{});var ga=s(Le);lo=n(ga,"Expose the models\u2019 internals as consistently as possible:"),ga.forEach(t),no=d(ct),W=r(ct,"UL",{});var ht=s(W);Ie=r(ht,"LI",{});var _a=s(Ie);io=n(_a,"We give access, using a single API, to the full hidden-states and attention weights."),_a.forEach(t),co=d(ht),Ae=r(ht,"LI",{});var ba=s(Ae);ho=n(ba,"Tokenizer and base model\u2019s API are standardized to easily switch between models."),ba.forEach(t),ht.forEach(t),ct.forEach(t),fo=d(ue),K=r(ue,"LI",{});var ft=s(K);ze=r(ft,"P",{});var Ea=s(ze);uo=n(Ea,"Incorporate a subjective selection of promising tools for fine-tuning/investigating these models:"),Ea.forEach(t),mo=d(ft),D=r(ft,"UL",{});var ut=s(D);xe=r(ut,"LI",{});var ka=s(xe);po=n(ka,"A simple/consistent way to add new tokens to the vocabulary and embeddings for fine-tuning."),ka.forEach(t),vo=d(ut),Me=r(ut,"LI",{});var Ta=s(Me);yo=n(Ta,"Simple ways to mask and prune transformer heads."),Ta.forEach(t),ut.forEach(t),ft.forEach(t),wo=d(ue),$e=r(ue,"LI",{});var Pa=s($e);Ne=r(Pa,"P",{});var La=s(Ne);go=n(La,"Switch easily between PyTorch and TensorFlow 2.0, allowing training using one framework and inference using another."),La.forEach(t),Pa.forEach(t),ue.forEach(t),Xe=d(o),T=r(o,"H2",{class:!0});var mt=s(T);I=r(mt,"A",{id:!0,class:!0,href:!0});var Ia=s(I);Se=r(Ia,"SPAN",{});var Aa=s(Se);Da(G.$$.fragment,Aa),Aa.forEach(t),Ia.forEach(t),_o=d(mt),qe=r(mt,"SPAN",{});var za=s(qe);bo=n(za,"Main concepts"),za.forEach(t),mt.forEach(t),Ze=d(o),se=r(o,"P",{});var xa=s(se);Eo=n(xa,"The library is built around three types of classes for each model:"),xa.forEach(t),et=d(o),E=r(o,"UL",{});var me=s(E);m=r(me,"LI",{});var P=s(m);Be=r(P,"STRONG",{});var Ma=s(Be);ko=n(Ma,"Model classes"),Ma.forEach(t),To=n(P," such as "),le=r(P,"A",{href:!0});var $a=s(le);Po=n($a,"BertModel"),$a.forEach(t),Lo=n(P,", which are 30+ PyTorch models ("),R=r(P,"A",{href:!0,rel:!0});var Na=s(R);Io=n(Na,"torch.nn.Module"),Na.forEach(t),Ao=n(P,") or Keras models ("),J=r(P,"A",{href:!0,rel:!0});var Sa=s(J);zo=n(Sa,"tf.keras.Model"),Sa.forEach(t),xo=n(P,`) that work with the pretrained weights provided in the
library.`),P.forEach(t),Mo=d(me),A=r(me,"LI",{});var He=s(A);Oe=r(He,"STRONG",{});var qa=s(Oe);$o=n(qa,"Configuration classes"),qa.forEach(t),No=n(He," such as "),ne=r(He,"A",{href:!0});var Ba=s(ne);So=n(Ba,"BertConfig"),Ba.forEach(t),qo=n(He,`, which store all the parameters required to build
a model. You don\u2019t always need to instantiate these yourself. In particular, if you are using a pretrained model
without any modification, creating the model will automatically take care of instantiating the configuration (which
is part of the model).`),He.forEach(t),Bo=d(me),z=r(me,"LI",{});var We=s(z);Ce=r(We,"STRONG",{});var Oa=s(Ce);Oo=n(Oa,"Tokenizer classes"),Oa.forEach(t),Co=n(We," such as "),ie=r(We,"A",{href:!0});var Ca=s(ie);Fo=n(Ca,"BertTokenizer"),Ca.forEach(t),Uo=n(We,`, which store the vocabulary for each model and
provide methods for encoding/decoding strings in a list of token embeddings indices to be fed to a model.`),We.forEach(t),me.forEach(t),tt=d(o),de=r(o,"P",{});var Fa=s(de);jo=n(Fa,"All these classes can be instantiated from pretrained instances and saved locally using two methods:"),Fa.forEach(t),ot=d(o),x=r(o,"UL",{});var pt=s(x);M=r(pt,"LI",{});var Ke=s(M);Fe=r(Ke,"CODE",{});var Ua=s(Fe);Ho=n(Ua,"from_pretrained()"),Ua.forEach(t),Wo=n(Ke,` lets you instantiate a model/configuration/tokenizer from a pretrained version either
provided by the library itself (the supported models are provided in the list `),ce=r(Ke,"A",{href:!0});var ja=s(ce);Ko=n(ja,"here"),ja.forEach(t),Do=n(Ke,`) or
stored locally (or on a server) by the user,`),Ke.forEach(t),Go=d(pt),$=r(pt,"LI",{});var De=s($);Ue=r(De,"CODE",{});var Ha=s(Ue);Ro=n(Ha,"save_pretrained()"),Ha.forEach(t),Jo=n(De,` lets you save a model/configuration/tokenizer locally so that it can be reloaded using
`),je=r(De,"CODE",{});var Wa=s(je);Yo=n(Wa,"from_pretrained()"),Wa.forEach(t),Qo=n(De,"."),De.forEach(t),pt.forEach(t),this.h()},h(){h(g,"name","hf:doc:metadata"),h(g,"content",JSON.stringify(ar)),h(p,"id","philosophy"),h(p,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(p,"href","#philosophy"),h(u,"class","relative group"),h(X,"href","/docs/transformers/master/en/main_classes/configuration"),h(Z,"href","/docs/transformers/master/en/main_classes/model"),h(ee,"href","/docs/transformers/master/en/main_classes/tokenizer"),h(C,"href","https://huggingface.co/models"),h(C,"rel","nofollow"),h(te,"href","/docs/transformers/master/en/main_classes/pipelines#transformers.pipeline"),h(oe,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer"),h(ae,"href","/docs/transformers/master/en/main_classes/trainer#transformers.TFTrainer"),h(I,"id","main-concepts"),h(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(I,"href","#main-concepts"),h(T,"class","relative group"),h(le,"href","/docs/transformers/master/en/model_doc/bert#transformers.BertModel"),h(R,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(R,"rel","nofollow"),h(J,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(J,"rel","nofollow"),h(ne,"href","/docs/transformers/master/en/model_doc/bert#transformers.BertConfig"),h(ie,"href","/docs/transformers/master/en/model_doc/bert#transformers.BertTokenizer"),h(ce,"href","/docs/transformers/master/en/pretrained_models")},m(o,c){e(document.head,g),f(o,Y,c),f(o,u,c),e(u,p),e(p,pe),Ga(B,pe,null),e(u,yt),e(u,ve),e(ve,wt),f(o,Ge,c),f(o,Q,c),e(Q,gt),f(o,Re,c),f(o,_,c),e(_,ye),e(ye,_t),e(_,bt),e(_,we),e(we,Et),e(_,kt),e(_,ge),e(ge,Tt),f(o,Je,c),f(o,V,c),e(V,Pt),f(o,Ye,c),f(o,L,c),e(L,O),e(O,_e),e(_e,Lt),e(O,It),e(O,v),e(v,y),e(y,At),e(y,X),e(X,zt),e(y,xt),e(y,Z),e(Z,Mt),e(y,$t),e(y,ee),e(ee,Nt),e(y,St),e(v,qt),e(v,k),e(k,Bt),e(k,be),e(be,Ot),e(k,Ct),e(k,C),e(C,Ft),e(k,Ut),e(v,jt),e(v,w),e(w,Ht),e(w,te),e(te,Wt),e(w,Kt),e(w,oe),e(oe,Dt),e(w,Gt),e(w,ae),e(ae,Rt),e(w,Jt),e(v,Yt),e(v,Ee),e(Ee,Qt),e(L,Vt),e(L,F),e(F,ke),e(ke,Xt),e(F,Zt),e(F,U),e(U,Te),e(Te,eo),e(U,to),e(U,j),e(j,oo),e(j,Pe),e(Pe,ao),e(j,ro),f(o,Qe,c),f(o,re,c),e(re,so),f(o,Ve,c),f(o,b,c),e(b,H),e(H,Le),e(Le,lo),e(H,no),e(H,W),e(W,Ie),e(Ie,io),e(W,co),e(W,Ae),e(Ae,ho),e(b,fo),e(b,K),e(K,ze),e(ze,uo),e(K,mo),e(K,D),e(D,xe),e(xe,po),e(D,vo),e(D,Me),e(Me,yo),e(b,wo),e(b,$e),e($e,Ne),e(Ne,go),f(o,Xe,c),f(o,T,c),e(T,I),e(I,Se),Ga(G,Se,null),e(T,_o),e(T,qe),e(qe,bo),f(o,Ze,c),f(o,se,c),e(se,Eo),f(o,et,c),f(o,E,c),e(E,m),e(m,Be),e(Be,ko),e(m,To),e(m,le),e(le,Po),e(m,Lo),e(m,R),e(R,Io),e(m,Ao),e(m,J),e(J,zo),e(m,xo),e(E,Mo),e(E,A),e(A,Oe),e(Oe,$o),e(A,No),e(A,ne),e(ne,So),e(A,qo),e(E,Bo),e(E,z),e(z,Ce),e(Ce,Oo),e(z,Co),e(z,ie),e(ie,Fo),e(z,Uo),f(o,tt,c),f(o,de,c),e(de,jo),f(o,ot,c),f(o,x,c),e(x,M),e(M,Fe),e(Fe,Ho),e(M,Wo),e(M,ce),e(ce,Ko),e(M,Do),e(x,Go),e(x,$),e($,Ue),e(Ue,Ro),e($,Jo),e($,je),e(je,Yo),e($,Qo),at=!0},p:tr,i(o){at||(Ra(B.$$.fragment,o),Ra(G.$$.fragment,o),at=!0)},o(o){Ja(B.$$.fragment,o),Ja(G.$$.fragment,o),at=!1},d(o){t(g),o&&t(Y),o&&t(u),Ya(B),o&&t(Ge),o&&t(Q),o&&t(Re),o&&t(_),o&&t(Je),o&&t(V),o&&t(Ye),o&&t(L),o&&t(Qe),o&&t(re),o&&t(Ve),o&&t(b),o&&t(Xe),o&&t(T),Ya(G),o&&t(Ze),o&&t(se),o&&t(et),o&&t(E),o&&t(tt),o&&t(de),o&&t(ot),o&&t(x)}}}const ar={local:"philosophy",sections:[{local:"main-concepts",title:"Main concepts"}],title:"Philosophy"};function rr(vt,g,Y){let{fw:u}=g;return vt.$$set=p=>{"fw"in p&&Y(0,u=p.fw)},[u]}class nr extends Va{constructor(g){super();Xa(this,g,rr,or,Za,{fw:0})}}export{nr as default,ar as metadata};
