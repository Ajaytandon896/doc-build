import{S as zr,i as jr,s as Tr,e as s,k as d,w as v,t as i,M as Cr,c as n,d as o,m as c,a as r,x as b,h as l,b as p,G as t,g as m,y as P,q as $,o as N,B as w,v as Dr,L as Yt}from"../../chunks/vendor-hf-doc-builder.js";import{D}from"../../chunks/Docstring-hf-doc-builder.js";import{C as Jt}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Y}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as Ut}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Ar(x){let u,L,_,f,k;return f=new Jt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetModel

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetModel.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")

input_ids = tokenizer(
    "Studies have been shown that owning a dog is good for you", return_tensors="pt"
).input_ids  # Batch size 1
decoder_input_ids = tokenizer("Studies show that", return_tensors="pt").input_ids  # Batch size 1
outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

last_hidden_states = outputs.last_hidden_state  # main stream hidden states
last_hidden_states_ngram = outputs.last_hidden_state_ngram  # predict hidden states`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetModel.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = tokenizer(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Studies have been shown that owning a dog is good for you&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">... </span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>decoder_input_ids = tokenizer(<span class="hljs-string">&quot;Studies show that&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state  <span class="hljs-comment"># main stream hidden states</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states_ngram = outputs.last_hidden_state_ngram  <span class="hljs-comment"># predict hidden states</span>`}}),{c(){u=s("p"),L=i("Example:"),_=d(),v(f.$$.fragment)},l(a){u=n(a,"P",{});var g=r(u);L=l(g,"Example:"),g.forEach(o),_=c(a),b(f.$$.fragment,a)},m(a,g){m(a,u,g),t(u,L),m(a,_,g),P(f,a,g),k=!0},p:Yt,i(a){k||($(f.$$.fragment,a),k=!0)},o(a){N(f.$$.fragment,a),k=!1},d(a){a&&o(u),a&&o(_),w(f,a)}}}function Sr(x){let u,L,_,f,k;return f=new Jt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetEncoder
import torch

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetEncoder.from_pretrained("patrickvonplaten/xprophetnet-large-uncased-standalone")
assert model.config.is_decoder, f"{model.__class__} has to be configured as a decoder."
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetEncoder
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetEncoder.from_pretrained(<span class="hljs-string">&quot;patrickvonplaten/xprophetnet-large-uncased-standalone&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">assert</span> model.config.is_decoder, <span class="hljs-string">f&quot;<span class="hljs-subst">{model.__class__}</span> has to be configured as a decoder.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),{c(){u=s("p"),L=i("Example:"),_=d(),v(f.$$.fragment)},l(a){u=n(a,"P",{});var g=r(u);L=l(g,"Example:"),g.forEach(o),_=c(a),b(f.$$.fragment,a)},m(a,g){m(a,u,g),t(u,L),m(a,_,g),P(f,a,g),k=!0},p:Yt,i(a){k||($(f.$$.fragment,a),k=!0)},o(a){N(f.$$.fragment,a),k=!1},d(a){a&&o(u),a&&o(_),w(f,a)}}}function Ir(x){let u,L,_,f,k;return f=new Jt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetDecoder
import torch

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetDecoder.from_pretrained(
    "patrickvonplaten/xprophetnet-large-uncased-standalone", add_cross_attention=False
)
assert model.config.is_decoder, f"{model.__class__} has to be configured as a decoder."
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetDecoder
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetDecoder.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;patrickvonplaten/xprophetnet-large-uncased-standalone&quot;</span>, add_cross_attention=<span class="hljs-literal">False</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">assert</span> model.config.is_decoder, <span class="hljs-string">f&quot;<span class="hljs-subst">{model.__class__}</span> has to be configured as a decoder.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),{c(){u=s("p"),L=i("Example:"),_=d(),v(f.$$.fragment)},l(a){u=n(a,"P",{});var g=r(u);L=l(g,"Example:"),g.forEach(o),_=c(a),b(f.$$.fragment,a)},m(a,g){m(a,u,g),t(u,L),m(a,_,g),P(f,a,g),k=!0},p:Yt,i(a){k||($(f.$$.fragment,a),k=!0)},o(a){N(f.$$.fragment,a),k=!1},d(a){a&&o(u),a&&o(_),w(f,a)}}}function Or(x){let u,L,_,f,k;return f=new Jt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetForConditionalGeneration

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetForConditionalGeneration.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")

input_ids = tokenizer(
    "Studies have been shown that owning a dog is good for you", return_tensors="pt"
).input_ids  # Batch size 1
decoder_input_ids = tokenizer("Studies show that", return_tensors="pt").input_ids  # Batch size 1
outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

logits_next_token = outputs.logits  # logits to predict next token as usual
logits_ngram_next_tokens = outputs.logits_ngram  # logits to predict 2nd, 3rd, ... next tokens`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetForConditionalGeneration

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetForConditionalGeneration.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = tokenizer(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Studies have been shown that owning a dog is good for you&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">... </span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>decoder_input_ids = tokenizer(<span class="hljs-string">&quot;Studies show that&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids  <span class="hljs-comment"># Batch size 1</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)

<span class="hljs-meta">&gt;&gt;&gt; </span>logits_next_token = outputs.logits  <span class="hljs-comment"># logits to predict next token as usual</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>logits_ngram_next_tokens = outputs.logits_ngram  <span class="hljs-comment"># logits to predict 2nd, 3rd, ... next tokens</span>`}}),{c(){u=s("p"),L=i("Example:"),_=d(),v(f.$$.fragment)},l(a){u=n(a,"P",{});var g=r(u);L=l(g,"Example:"),g.forEach(o),_=c(a),b(f.$$.fragment,a)},m(a,g){m(a,u,g),t(u,L),m(a,_,g),P(f,a,g),k=!0},p:Yt,i(a){k||($(f.$$.fragment,a),k=!0)},o(a){N(f.$$.fragment,a),k=!1},d(a){a&&o(u),a&&o(_),w(f,a)}}}function Fr(x){let u,L,_,f,k;return f=new Jt({props:{code:`from transformers import XLMProphetNetTokenizer, XLMProphetNetForCausalLM
import torch

tokenizer = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = XLMProphetNetForCausalLM.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
assert model.config.is_decoder, f"{model.__class__} has to be configured as a decoder."
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

logits = outputs.logits

# Model can also be used with EncoderDecoder framework
from transformers import EncoderDecoderModel, XLMProphetNetTokenizer, XLMRobertaTokenizer
import torch

tokenizer_enc = XLMRobertaTokenizer.from_pretrained("xlm-roberta-large")
tokenizer_dec = XLMProphetNetTokenizer.from_pretrained("microsoft/xprophetnet-large-wiki100-cased")
model = EncoderDecoderModel.from_encoder_decoder_pretrained(
    "xlm-roberta-large", "microsoft/xprophetnet-large-wiki100-cased"
)

ARTICLE = (
    "the us state department said wednesday it had received no "
    "formal word from bolivia that it was expelling the us ambassador there "
    "but said the charges made against him are \`\` baseless ."
)
input_ids = tokenizer_enc(ARTICLE, return_tensors="pt").input_ids
labels = tokenizer_dec("us rejects charges against its ambassador in bolivia", return_tensors="pt").input_ids
outputs = model(input_ids=input_ids, decoder_input_ids=labels[:, :-1], labels=labels[:, 1:])

loss = outputs.loss`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMProphetNetTokenizer, XLMProphetNetForCausalLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMProphetNetForCausalLM.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">assert</span> model.config.is_decoder, <span class="hljs-string">f&quot;<span class="hljs-subst">{model.__class__}</span> has to be configured as a decoder.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Model can also be used with EncoderDecoder framework</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> EncoderDecoderModel, XLMProphetNetTokenizer, XLMRobertaTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer_enc = XLMRobertaTokenizer.from_pretrained(<span class="hljs-string">&quot;xlm-roberta-large&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer_dec = XLMProphetNetTokenizer.from_pretrained(<span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = EncoderDecoderModel.from_encoder_decoder_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;xlm-roberta-large&quot;</span>, <span class="hljs-string">&quot;microsoft/xprophetnet-large-wiki100-cased&quot;</span>
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>ARTICLE = (
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;the us state department said wednesday it had received no &quot;</span>
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;formal word from bolivia that it was expelling the us ambassador there &quot;</span>
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;but said the charges made against him are \`\` baseless .&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = tokenizer_enc(ARTICLE, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = tokenizer_dec(<span class="hljs-string">&quot;us rejects charges against its ambassador in bolivia&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=labels[:, :-<span class="hljs-number">1</span>], labels=labels[:, <span class="hljs-number">1</span>:])

<span class="hljs-meta">&gt;&gt;&gt; </span>loss = outputs.loss`}}),{c(){u=s("p"),L=i("Example:"),_=d(),v(f.$$.fragment)},l(a){u=n(a,"P",{});var g=r(u);L=l(g,"Example:"),g.forEach(o),_=c(a),b(f.$$.fragment,a)},m(a,g){m(a,u,g),t(u,L),m(a,_,g),P(f,a,g),k=!0},p:Yt,i(a){k||($(f.$$.fragment,a),k=!0)},o(a){N(f.$$.fragment,a),k=!1},d(a){a&&o(u),a&&o(_),w(f,a)}}}function Gr(x){let u,L,_,f,k,a,g,bt,Fo,Qt,S,Pt,Go,Bo,ge,Ro,Ho,Zt,I,J,$t,_e,Wo,Nt,Vo,Kt,Q,Uo,ke,Yo,Jo,eo,Ye,Qo,to,Je,Zo,oo,Qe,wt,Ko,so,Z,es,ve,ts,os,no,O,K,Lt,be,ss,Mt,ns,ro,X,Pe,rs,F,as,Ze,is,ls,$e,ps,ds,cs,G,hs,Ke,ms,fs,et,us,gs,ao,B,ee,yt,Ne,_s,xt,ks,io,M,we,vs,q,bs,tt,Ps,$s,ot,Ns,ws,Le,Ls,Ms,ys,Me,xs,st,Xs,qs,Es,A,ye,zs,Xt,js,Ts,xe,nt,Cs,qt,Ds,As,rt,Ss,Et,Is,Os,te,Xe,Fs,zt,Gs,Bs,oe,qe,Rs,jt,Hs,Ws,se,Ee,Vs,ze,Us,Tt,Ys,Js,lo,R,ne,Ct,je,Qs,Dt,Zs,po,E,Te,Ks,Ce,en,at,tn,on,sn,re,co,H,ae,At,De,nn,St,rn,ho,z,Ae,an,Se,ln,it,pn,dn,cn,ie,mo,W,le,It,Ie,hn,Ot,mn,fo,j,Oe,fn,Fe,un,lt,gn,_n,kn,pe,uo,V,de,Ft,Ge,vn,Gt,bn,go,T,Be,Pn,Re,$n,pt,Nn,wn,Ln,ce,_o,U,he,Bt,He,Mn,Rt,yn,ko,C,We,xn,Ve,Xn,dt,qn,En,zn,me,vo;return a=new Y({}),_e=new Y({}),be=new Y({}),Pe=new D({props:{name:"class transformers.XLMProphetNetConfig",anchor:"transformers.XLMProphetNetConfig",parameters:[{name:"activation_dropout",val:": typing.Optional[float] = 0.1"},{name:"activation_function",val:": typing.Union[str, typing.Callable, NoneType] = 'gelu'"},{name:"vocab_size",val:": typing.Optional[int] = 30522"},{name:"hidden_size",val:": typing.Optional[int] = 1024"},{name:"encoder_ffn_dim",val:": typing.Optional[int] = 4096"},{name:"num_encoder_layers",val:": typing.Optional[int] = 12"},{name:"num_encoder_attention_heads",val:": typing.Optional[int] = 16"},{name:"decoder_ffn_dim",val:": typing.Optional[int] = 4096"},{name:"num_decoder_layers",val:": typing.Optional[int] = 12"},{name:"num_decoder_attention_heads",val:": typing.Optional[int] = 16"},{name:"attention_dropout",val:": typing.Optional[float] = 0.1"},{name:"dropout",val:": typing.Optional[float] = 0.1"},{name:"max_position_embeddings",val:": typing.Optional[int] = 512"},{name:"init_std",val:": typing.Optional[float] = 0.02"},{name:"is_encoder_decoder",val:": typing.Optional[bool] = True"},{name:"add_cross_attention",val:": typing.Optional[bool] = True"},{name:"decoder_start_token_id",val:": typing.Optional[int] = 0"},{name:"ngram",val:": typing.Optional[int] = 2"},{name:"num_buckets",val:": typing.Optional[int] = 32"},{name:"relative_max_distance",val:": typing.Optional[int] = 128"},{name:"disable_ngram_loss",val:": typing.Optional[bool] = False"},{name:"eps",val:": typing.Optional[float] = 0.0"},{name:"use_cache",val:": typing.Optional[bool] = True"},{name:"pad_token_id",val:": typing.Optional[int] = 0"},{name:"bos_token_id",val:": typing.Optional[int] = 1"},{name:"eos_token_id",val:": typing.Optional[int] = 2"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.XLMProphetNetConfig.activation_dropout",description:`<strong>activation_dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The dropout ratio for activations inside the fully connected layer.`,name:"activation_dropout"},{anchor:"transformers.XLMProphetNetConfig.activation_function",description:`<strong>activation_function</strong> (<code>str</code> or <code>function</code>, <em>optional</em>, defaults to <code>&quot;gelu&quot;</code>) &#x2014;
The non-linear activation function (function or string) in the encoder and pooler. If string, <code>&quot;gelu&quot;</code>,
<code>&quot;relu&quot;</code>, <code>&quot;silu&quot;</code> and <code>&quot;gelu_new&quot;</code> are supported.`,name:"activation_function"},{anchor:"transformers.XLMProphetNetConfig.vocab_size",description:`<strong>vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 30522) &#x2014;
Vocabulary size of the ProphetNET model. Defines the number of different tokens that can be represented by
the <code>inputs_ids</code> passed when calling <a href="/docs/transformers/v4.23.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a>.`,name:"vocab_size"},{anchor:"transformers.XLMProphetNetConfig.hidden_size",description:`<strong>hidden_size</strong> (<code>int</code>, <em>optional</em>, defaults to 1024) &#x2014;
Dimensionality of the layers and the pooler layer.`,name:"hidden_size"},{anchor:"transformers.XLMProphetNetConfig.encoder_ffn_dim",description:`<strong>encoder_ffn_dim</strong> (<code>int</code>, <em>optional</em>, defaults to 4096) &#x2014;
Dimensionality of the &#x201C;intermediate&#x201D; (often named feed-forward) layer in decoder.`,name:"encoder_ffn_dim"},{anchor:"transformers.XLMProphetNetConfig.num_encoder_layers",description:`<strong>num_encoder_layers</strong> (<code>int</code>, <em>optional</em>, defaults to 12) &#x2014;
Number of encoder layers.`,name:"num_encoder_layers"},{anchor:"transformers.XLMProphetNetConfig.num_encoder_attention_heads",description:`<strong>num_encoder_attention_heads</strong> (<code>int</code>, <em>optional</em>, defaults to 16) &#x2014;
Number of attention heads for each attention layer in the Transformer encoder.`,name:"num_encoder_attention_heads"},{anchor:"transformers.XLMProphetNetConfig.decoder_ffn_dim",description:`<strong>decoder_ffn_dim</strong> (<code>int</code>, <em>optional</em>, defaults to 4096) &#x2014;
Dimensionality of the <code>intermediate</code> (often named feed-forward) layer in decoder.`,name:"decoder_ffn_dim"},{anchor:"transformers.XLMProphetNetConfig.num_decoder_layers",description:`<strong>num_decoder_layers</strong> (<code>int</code>, <em>optional</em>, defaults to 12) &#x2014;
Number of decoder layers.`,name:"num_decoder_layers"},{anchor:"transformers.XLMProphetNetConfig.num_decoder_attention_heads",description:`<strong>num_decoder_attention_heads</strong> (<code>int</code>, <em>optional</em>, defaults to 16) &#x2014;
Number of attention heads for each attention layer in the Transformer decoder.`,name:"num_decoder_attention_heads"},{anchor:"transformers.XLMProphetNetConfig.attention_dropout",description:`<strong>attention_dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The dropout ratio for the attention probabilities.`,name:"attention_dropout"},{anchor:"transformers.XLMProphetNetConfig.dropout",description:`<strong>dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.`,name:"dropout"},{anchor:"transformers.XLMProphetNetConfig.max_position_embeddings",description:`<strong>max_position_embeddings</strong> (<code>int</code>, <em>optional</em>, defaults to 512) &#x2014;
The maximum sequence length that this model might ever be used with. Typically set this to something large
just in case (e.g., 512 or 1024 or 2048).`,name:"max_position_embeddings"},{anchor:"transformers.XLMProphetNetConfig.init_std",description:`<strong>init_std</strong> (<code>float</code>, <em>optional</em>, defaults to 0.02) &#x2014;
The standard deviation of the truncated_normal_initializer for initializing all weight matrices.`,name:"init_std"},{anchor:"transformers.XLMProphetNetConfig.add_cross_attention",description:`<strong>add_cross_attention</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether cross-attention layers should be added to the model.`,name:"add_cross_attention"},{anchor:"transformers.XLMProphetNetConfig.is_encoder_decoder",description:`<strong>is_encoder_decoder</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether this is an encoder/decoder model.`,name:"is_encoder_decoder"},{anchor:"transformers.XLMProphetNetConfig.pad_token_id",description:`<strong>pad_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Padding token id.`,name:"pad_token_id"},{anchor:"transformers.XLMProphetNetConfig.bos_token_id",description:`<strong>bos_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
Beginning of stream token id.`,name:"bos_token_id"},{anchor:"transformers.XLMProphetNetConfig.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to 2) &#x2014;
End of stream token id.`,name:"eos_token_id"},{anchor:"transformers.XLMProphetNetConfig.ngram",description:`<strong>ngram</strong> (<code>int</code>, <em>optional</em>, defaults to 2) &#x2014;
Number of future tokens to predict. Set to 1 to be same as traditional Language model to predict next first
token.`,name:"ngram"},{anchor:"transformers.XLMProphetNetConfig.num_buckets",description:`<strong>num_buckets</strong> (<code>int</code>, <em>optional</em>, defaults to 32) &#x2014;
The number of buckets to use for each attention layer. This is for relative position calculation. See the
[T5 paper](see <a href="https://arxiv.org/abs/1910.10683" rel="nofollow">https://arxiv.org/abs/1910.10683</a>) for more details.`,name:"num_buckets"},{anchor:"transformers.XLMProphetNetConfig.relative_max_distance",description:`<strong>relative_max_distance</strong> (<code>int</code>, <em>optional</em>, defaults to 128) &#x2014;
Relative distances greater than this number will be put into the last same bucket. This is for relative
position calculation. See the [T5 paper](see <a href="https://arxiv.org/abs/1910.10683" rel="nofollow">https://arxiv.org/abs/1910.10683</a>) for more details.`,name:"relative_max_distance"},{anchor:"transformers.XLMProphetNetConfig.disable_ngram_loss",description:`<strong>disable_ngram_loss</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether be trained predicting only the next first token.`,name:"disable_ngram_loss"},{anchor:"transformers.XLMProphetNetConfig.eps",description:`<strong>eps</strong> (<code>float</code>, <em>optional</em>, defaults to 0.0) &#x2014;
Controls the <code>epsilon</code> parameter value for label smoothing in the loss calculation. If set to 0, no label
smoothing is performed.`,name:"eps"},{anchor:"transformers.XLMProphetNetConfig.use_cache",description:`<strong>use_cache</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not the model should return the last key/values attentions (not used by all models).`,name:"use_cache"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/configuration_xlm_prophetnet.py#L33"}}),Ne=new Y({}),we=new D({props:{name:"class transformers.XLMProphetNetTokenizer",anchor:"transformers.XLMProphetNetTokenizer",parameters:[{name:"vocab_file",val:""},{name:"bos_token",val:" = '[SEP]'"},{name:"eos_token",val:" = '[SEP]'"},{name:"sep_token",val:" = '[SEP]'"},{name:"unk_token",val:" = '[UNK]'"},{name:"pad_token",val:" = '[PAD]'"},{name:"cls_token",val:" = '[CLS]'"},{name:"mask_token",val:" = '[MASK]'"},{name:"sp_model_kwargs",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.vocab_file",description:`<strong>vocab_file</strong> (<code>str</code>) &#x2014;
Path to the vocabulary file.`,name:"vocab_file"},{anchor:"transformers.XLMProphetNetTokenizer.bos_token",description:`<strong>bos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The beginning of sequence token that was used during pretraining. Can be used a sequence classifier token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the beginning of
sequence. The token used is the <code>cls_token</code>.</p>

					</div>`,name:"bos_token"},{anchor:"transformers.XLMProphetNetTokenizer.eos_token",description:`<strong>eos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The end of sequence token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the end of sequence.
The token used is the <code>sep_token</code>.</p>

					</div>`,name:"eos_token"},{anchor:"transformers.XLMProphetNetTokenizer.sep_token",description:`<strong>sep_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for
sequence classification or for a text and a question for question answering. It is also used as the last
token of a sequence built with special tokens.`,name:"sep_token"},{anchor:"transformers.XLMProphetNetTokenizer.cls_token",description:`<strong>cls_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The classifier token which is used when doing sequence classification (classification of the whole sequence
instead of per-token classification). It is the first token of the sequence when built with special tokens.`,name:"cls_token"},{anchor:"transformers.XLMProphetNetTokenizer.unk_token",description:`<strong>unk_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;unk&gt;&quot;</code>) &#x2014;
The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.`,name:"unk_token"},{anchor:"transformers.XLMProphetNetTokenizer.pad_token",description:`<strong>pad_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;pad&gt;&quot;</code>) &#x2014;
The token used for padding, for example when batching sequences of different lengths.`,name:"pad_token"},{anchor:"transformers.XLMProphetNetTokenizer.mask_token",description:`<strong>mask_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;mask&gt;&quot;</code>) &#x2014;
The token used for masking values. This is the token used when training this model with masked language
modeling. This is the token which the model will try to predict.`,name:"mask_token"},{anchor:"transformers.XLMProphetNetTokenizer.additional_special_tokens",description:`<strong>additional_special_tokens</strong> (<code>List[str]</code>, <em>optional</em>, defaults to <code>[&quot;&lt;s&gt;NOTUSED&quot;, &quot;&lt;/s&gt;NOTUSED&quot;]</code>) &#x2014;
Additional special tokens used by the tokenizer.`,name:"additional_special_tokens"},{anchor:"transformers.XLMProphetNetTokenizer.sp_model_kwargs",description:`<strong>sp_model_kwargs</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Will be passed to the <code>SentencePieceProcessor.__init__()</code> method. The <a href="https://github.com/google/sentencepiece/tree/master/python" rel="nofollow">Python wrapper for
SentencePiece</a> can be used, among other things,
to set:</p>
<ul>
<li>
<p><code>enable_sampling</code>: Enable subword regularization.</p>
</li>
<li>
<p><code>nbest_size</code>: Sampling parameters for unigram. Invalid for BPE-Dropout.</p>
<ul>
<li><code>nbest_size = {0,1}</code>: No sampling is performed.</li>
<li><code>nbest_size &gt; 1</code>: samples from the nbest_size results.</li>
<li><code>nbest_size &lt; 0</code>: assuming that nbest_size is infinite and samples from the all hypothesis (lattice)
using forward-filtering-and-backward-sampling algorithm.</li>
</ul>
</li>
<li>
<p><code>alpha</code>: Smoothing parameter for unigram sampling, and dropout probability of merge operations for
BPE-dropout.</p>
</li>
</ul>`,name:"sp_model_kwargs"},{anchor:"transformers.XLMProphetNetTokenizer.sp_model",description:`<strong>sp_model</strong> (<code>SentencePieceProcessor</code>) &#x2014;
The <em>SentencePiece</em> processor that is used for every conversion (string, tokens and IDs).`,name:"sp_model"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L59"}}),ye=new D({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.XLMProphetNetTokenizer.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added`,name:"token_ids_0"},{anchor:"transformers.XLMProphetNetTokenizer.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L316",returnDescription:`
<p>list of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Xe=new D({props:{name:"convert_tokens_to_string",anchor:"transformers.XLMProphetNetTokenizer.convert_tokens_to_string",parameters:[{name:"tokens",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L294"}}),qe=new D({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.XLMProphetNetTokenizer.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.XLMProphetNetTokenizer.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L243",returnDescription:`
<p>List of zeros.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Ee=new D({props:{name:"get_special_tokens_mask",anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"},{name:"already_has_special_tokens",val:": bool = False"}],parametersDescription:[{anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"},{anchor:"transformers.XLMProphetNetTokenizer.get_special_tokens_mask.already_has_special_tokens",description:`<strong>already_has_special_tokens</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the token list is already formatted with special tokens for the model.`,name:"already_has_special_tokens"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L215",returnDescription:`
<p>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),je=new Y({}),Te=new D({props:{name:"class transformers.XLMProphetNetModel",anchor:"transformers.XLMProphetNetModel",parameters:[{name:"config",val:": ProphetNetConfig"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L86"}}),re=new Ut({props:{anchor:"transformers.XLMProphetNetModel.example",$$slots:{default:[Ar]},$$scope:{ctx:x}}}),De=new Y({}),Ae=new D({props:{name:"class transformers.XLMProphetNetEncoder",anchor:"transformers.XLMProphetNetEncoder",parameters:[{name:"config",val:": ProphetNetConfig"},{name:"word_embeddings",val:": Embedding = None"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L38"}}),ie=new Ut({props:{anchor:"transformers.XLMProphetNetEncoder.example",$$slots:{default:[Sr]},$$scope:{ctx:x}}}),Ie=new Y({}),Oe=new D({props:{name:"class transformers.XLMProphetNetDecoder",anchor:"transformers.XLMProphetNetDecoder",parameters:[{name:"config",val:": ProphetNetConfig"},{name:"word_embeddings",val:": typing.Optional[torch.nn.modules.sparse.Embedding] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L61"}}),pe=new Ut({props:{anchor:"transformers.XLMProphetNetDecoder.example",$$slots:{default:[Ir]},$$scope:{ctx:x}}}),Ge=new Y({}),Be=new D({props:{name:"class transformers.XLMProphetNetForConditionalGeneration",anchor:"transformers.XLMProphetNetForConditionalGeneration",parameters:[{name:"config",val:": ProphetNetConfig"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L112"}}),ce=new Ut({props:{anchor:"transformers.XLMProphetNetForConditionalGeneration.example",$$slots:{default:[Or]},$$scope:{ctx:x}}}),He=new Y({}),We=new D({props:{name:"class transformers.XLMProphetNetForCausalLM",anchor:"transformers.XLMProphetNetForCausalLM",parameters:[{name:"config",val:": ProphetNetConfig"}],source:"https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L138"}}),me=new Ut({props:{anchor:"transformers.XLMProphetNetForCausalLM.example",$$slots:{default:[Fr]},$$scope:{ctx:x}}}),{c(){u=s("meta"),L=d(),_=s("h1"),f=s("a"),k=s("span"),v(a.$$.fragment),g=d(),bt=s("span"),Fo=i("XLM-ProphetNet"),Qt=d(),S=s("p"),Pt=s("strong"),Go=i("DISCLAIMER:"),Bo=i(" If you see something strange, file a "),ge=s("a"),Ro=i("Github Issue"),Ho=i(` and assign
@patrickvonplaten`),Zt=d(),I=s("h2"),J=s("a"),$t=s("span"),v(_e.$$.fragment),Wo=d(),Nt=s("span"),Vo=i("Overview"),Kt=d(),Q=s("p"),Uo=i("The XLM-ProphetNet model was proposed in "),ke=s("a"),Yo=i("ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training,"),Jo=i(` by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei
Zhang, Ming Zhou on 13 Jan, 2020.`),eo=d(),Ye=s("p"),Qo=i(`XLM-ProphetNet is an encoder-decoder model and can predict n-future tokens for \u201Cngram\u201D language modeling instead of
just the next token. Its architecture is identical to ProhpetNet, but the model was trained on the multi-lingual
\u201Cwiki100\u201D Wikipedia dump.`),to=d(),Je=s("p"),Zo=i("The abstract from the paper is the following:"),oo=d(),Qe=s("p"),wt=s("em"),Ko=i(`In this paper, we present a new sequence-to-sequence pretraining model called ProphetNet, which introduces a novel
self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism. Instead of
the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by
n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time
step. The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent
overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale
dataset (160GB) respectively. Then we conduct experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks for
abstractive summarization and question generation tasks. Experimental results show that ProphetNet achieves new
state-of-the-art results on all these datasets compared to the models using the same scale pretraining corpus.`),so=d(),Z=s("p"),es=i("The Authors\u2019 code can be found "),ve=s("a"),ts=i("here"),os=i("."),no=d(),O=s("h2"),K=s("a"),Lt=s("span"),v(be.$$.fragment),ss=d(),Mt=s("span"),ns=i("XLMProphetNetConfig"),ro=d(),X=s("div"),v(Pe.$$.fragment),rs=d(),F=s("p"),as=i("This is the configuration class to store the configuration of a "),Ze=s("a"),is=i("XLMProphetNetModel"),ls=i(`. It is used to instantiate a
XLMProphetNet model according to the specified arguments, defining the model architecture. Instantiating a
configuration with the defaults will yield a similar configuration to that of the XLMProphetNet
`),$e=s("a"),ps=i("microsoft/xprophetnet-large-wiki100-cased"),ds=i(`
architecture.`),cs=d(),G=s("p"),hs=i("Configuration objects inherit from "),Ke=s("a"),ms=i("PretrainedConfig"),fs=i(` and can be used to control the model outputs. Read the
documentation from `),et=s("a"),us=i("PretrainedConfig"),gs=i(" for more information."),ao=d(),B=s("h2"),ee=s("a"),yt=s("span"),v(Ne.$$.fragment),_s=d(),xt=s("span"),ks=i("XLMProphetNetTokenizer"),io=d(),M=s("div"),v(we.$$.fragment),vs=d(),q=s("p"),bs=i("Adapted from "),tt=s("a"),Ps=i("RobertaTokenizer"),$s=i(" and "),ot=s("a"),Ns=i("XLNetTokenizer"),ws=i(`. Based on
`),Le=s("a"),Ls=i("SentencePiece"),Ms=i("."),ys=d(),Me=s("p"),xs=i("This tokenizer inherits from "),st=s("a"),Xs=i("PreTrainedTokenizer"),qs=i(` which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.`),Es=d(),A=s("div"),v(ye.$$.fragment),zs=d(),Xt=s("p"),js=i(`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A XLMProphetNet sequence has the following format:`),Ts=d(),xe=s("ul"),nt=s("li"),Cs=i("single sequence: "),qt=s("code"),Ds=i("X [SEP]"),As=d(),rt=s("li"),Ss=i("pair of sequences: "),Et=s("code"),Is=i("A [SEP] B [SEP]"),Os=d(),te=s("div"),v(Xe.$$.fragment),Fs=d(),zt=s("p"),Gs=i("Converts a sequence of tokens (strings for sub-words) in a single string."),Bs=d(),oe=s("div"),v(qe.$$.fragment),Rs=d(),jt=s("p"),Hs=i(`Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLMProphetNet
does not make use of token type ids, therefore a list of zeros is returned.`),Ws=d(),se=s("div"),v(Ee.$$.fragment),Vs=d(),ze=s("p"),Us=i(`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),Tt=s("code"),Ys=i("prepare_for_model"),Js=i(" method."),lo=d(),R=s("h2"),ne=s("a"),Ct=s("span"),v(je.$$.fragment),Qs=d(),Dt=s("span"),Zs=i("XLMProphetNetModel"),po=d(),E=s("div"),v(Te.$$.fragment),Ks=d(),Ce=s("p"),en=i("This class overrides "),at=s("a"),tn=i("ProphetNetModel"),on=i(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),sn=d(),v(re.$$.fragment),co=d(),H=s("h2"),ae=s("a"),At=s("span"),v(De.$$.fragment),nn=d(),St=s("span"),rn=i("XLMProphetNetEncoder"),ho=d(),z=s("div"),v(Ae.$$.fragment),an=d(),Se=s("p"),ln=i("This class overrides "),it=s("a"),pn=i("ProphetNetEncoder"),dn=i(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),cn=d(),v(ie.$$.fragment),mo=d(),W=s("h2"),le=s("a"),It=s("span"),v(Ie.$$.fragment),hn=d(),Ot=s("span"),mn=i("XLMProphetNetDecoder"),fo=d(),j=s("div"),v(Oe.$$.fragment),fn=d(),Fe=s("p"),un=i("This class overrides "),lt=s("a"),gn=i("ProphetNetDecoder"),_n=i(`. Please check the superclass for the appropriate documentation alongside
usage examples.`),kn=d(),v(pe.$$.fragment),uo=d(),V=s("h2"),de=s("a"),Ft=s("span"),v(Ge.$$.fragment),vn=d(),Gt=s("span"),bn=i("XLMProphetNetForConditionalGeneration"),go=d(),T=s("div"),v(Be.$$.fragment),Pn=d(),Re=s("p"),$n=i("This class overrides "),pt=s("a"),Nn=i("ProphetNetForConditionalGeneration"),wn=i(`. Please check the superclass for the appropriate
documentation alongside usage examples.`),Ln=d(),v(ce.$$.fragment),_o=d(),U=s("h2"),he=s("a"),Bt=s("span"),v(He.$$.fragment),Mn=d(),Rt=s("span"),yn=i("XLMProphetNetForCausalLM"),ko=d(),C=s("div"),v(We.$$.fragment),xn=d(),Ve=s("p"),Xn=i("This class overrides "),dt=s("a"),qn=i("ProphetNetForCausalLM"),En=i(`. Please check the superclass for the appropriate documentation
alongside usage examples.`),zn=d(),v(me.$$.fragment),this.h()},l(e){const h=Cr('[data-svelte="svelte-1phssyn"]',document.head);u=n(h,"META",{name:!0,content:!0}),h.forEach(o),L=c(e),_=n(e,"H1",{class:!0});var Ue=r(_);f=n(Ue,"A",{id:!0,class:!0,href:!0});var Ht=r(f);k=n(Ht,"SPAN",{});var Wt=r(k);b(a.$$.fragment,Wt),Wt.forEach(o),Ht.forEach(o),g=c(Ue),bt=n(Ue,"SPAN",{});var Vt=r(bt);Fo=l(Vt,"XLM-ProphetNet"),Vt.forEach(o),Ue.forEach(o),Qt=c(e),S=n(e,"P",{});var fe=r(S);Pt=n(fe,"STRONG",{});var Cn=r(Pt);Go=l(Cn,"DISCLAIMER:"),Cn.forEach(o),Bo=l(fe," If you see something strange, file a "),ge=n(fe,"A",{href:!0,rel:!0});var Dn=r(ge);Ro=l(Dn,"Github Issue"),Dn.forEach(o),Ho=l(fe,` and assign
@patrickvonplaten`),fe.forEach(o),Zt=c(e),I=n(e,"H2",{class:!0});var bo=r(I);J=n(bo,"A",{id:!0,class:!0,href:!0});var An=r(J);$t=n(An,"SPAN",{});var Sn=r($t);b(_e.$$.fragment,Sn),Sn.forEach(o),An.forEach(o),Wo=c(bo),Nt=n(bo,"SPAN",{});var In=r(Nt);Vo=l(In,"Overview"),In.forEach(o),bo.forEach(o),Kt=c(e),Q=n(e,"P",{});var Po=r(Q);Uo=l(Po,"The XLM-ProphetNet model was proposed in "),ke=n(Po,"A",{href:!0,rel:!0});var On=r(ke);Yo=l(On,"ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training,"),On.forEach(o),Jo=l(Po,` by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei
Zhang, Ming Zhou on 13 Jan, 2020.`),Po.forEach(o),eo=c(e),Ye=n(e,"P",{});var Fn=r(Ye);Qo=l(Fn,`XLM-ProphetNet is an encoder-decoder model and can predict n-future tokens for \u201Cngram\u201D language modeling instead of
just the next token. Its architecture is identical to ProhpetNet, but the model was trained on the multi-lingual
\u201Cwiki100\u201D Wikipedia dump.`),Fn.forEach(o),to=c(e),Je=n(e,"P",{});var Gn=r(Je);Zo=l(Gn,"The abstract from the paper is the following:"),Gn.forEach(o),oo=c(e),Qe=n(e,"P",{});var Bn=r(Qe);wt=n(Bn,"EM",{});var Rn=r(wt);Ko=l(Rn,`In this paper, we present a new sequence-to-sequence pretraining model called ProphetNet, which introduces a novel
self-supervised objective named future n-gram prediction and the proposed n-stream self-attention mechanism. Instead of
the optimization of one-step ahead prediction in traditional sequence-to-sequence model, the ProphetNet is optimized by
n-step ahead prediction which predicts the next n tokens simultaneously based on previous context tokens at each time
step. The future n-gram prediction explicitly encourages the model to plan for the future tokens and prevent
overfitting on strong local correlations. We pre-train ProphetNet using a base scale dataset (16GB) and a large scale
dataset (160GB) respectively. Then we conduct experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks for
abstractive summarization and question generation tasks. Experimental results show that ProphetNet achieves new
state-of-the-art results on all these datasets compared to the models using the same scale pretraining corpus.`),Rn.forEach(o),Bn.forEach(o),so=c(e),Z=n(e,"P",{});var $o=r(Z);es=l($o,"The Authors\u2019 code can be found "),ve=n($o,"A",{href:!0,rel:!0});var Hn=r(ve);ts=l(Hn,"here"),Hn.forEach(o),os=l($o,"."),$o.forEach(o),no=c(e),O=n(e,"H2",{class:!0});var No=r(O);K=n(No,"A",{id:!0,class:!0,href:!0});var Wn=r(K);Lt=n(Wn,"SPAN",{});var Vn=r(Lt);b(be.$$.fragment,Vn),Vn.forEach(o),Wn.forEach(o),ss=c(No),Mt=n(No,"SPAN",{});var Un=r(Mt);ns=l(Un,"XLMProphetNetConfig"),Un.forEach(o),No.forEach(o),ro=c(e),X=n(e,"DIV",{class:!0});var ct=r(X);b(Pe.$$.fragment,ct),rs=c(ct),F=n(ct,"P",{});var ht=r(F);as=l(ht,"This is the configuration class to store the configuration of a "),Ze=n(ht,"A",{href:!0});var Yn=r(Ze);is=l(Yn,"XLMProphetNetModel"),Yn.forEach(o),ls=l(ht,`. It is used to instantiate a
XLMProphetNet model according to the specified arguments, defining the model architecture. Instantiating a
configuration with the defaults will yield a similar configuration to that of the XLMProphetNet
`),$e=n(ht,"A",{href:!0,rel:!0});var Jn=r($e);ps=l(Jn,"microsoft/xprophetnet-large-wiki100-cased"),Jn.forEach(o),ds=l(ht,`
architecture.`),ht.forEach(o),cs=c(ct),G=n(ct,"P",{});var mt=r(G);hs=l(mt,"Configuration objects inherit from "),Ke=n(mt,"A",{href:!0});var Qn=r(Ke);ms=l(Qn,"PretrainedConfig"),Qn.forEach(o),fs=l(mt,` and can be used to control the model outputs. Read the
documentation from `),et=n(mt,"A",{href:!0});var Zn=r(et);us=l(Zn,"PretrainedConfig"),Zn.forEach(o),gs=l(mt," for more information."),mt.forEach(o),ct.forEach(o),ao=c(e),B=n(e,"H2",{class:!0});var wo=r(B);ee=n(wo,"A",{id:!0,class:!0,href:!0});var Kn=r(ee);yt=n(Kn,"SPAN",{});var er=r(yt);b(Ne.$$.fragment,er),er.forEach(o),Kn.forEach(o),_s=c(wo),xt=n(wo,"SPAN",{});var tr=r(xt);ks=l(tr,"XLMProphetNetTokenizer"),tr.forEach(o),wo.forEach(o),io=c(e),M=n(e,"DIV",{class:!0});var y=r(M);b(we.$$.fragment,y),vs=c(y),q=n(y,"P",{});var ue=r(q);bs=l(ue,"Adapted from "),tt=n(ue,"A",{href:!0});var or=r(tt);Ps=l(or,"RobertaTokenizer"),or.forEach(o),$s=l(ue," and "),ot=n(ue,"A",{href:!0});var sr=r(ot);Ns=l(sr,"XLNetTokenizer"),sr.forEach(o),ws=l(ue,`. Based on
`),Le=n(ue,"A",{href:!0,rel:!0});var nr=r(Le);Ls=l(nr,"SentencePiece"),nr.forEach(o),Ms=l(ue,"."),ue.forEach(o),ys=c(y),Me=n(y,"P",{});var Lo=r(Me);xs=l(Lo,"This tokenizer inherits from "),st=n(Lo,"A",{href:!0});var rr=r(st);Xs=l(rr,"PreTrainedTokenizer"),rr.forEach(o),qs=l(Lo,` which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.`),Lo.forEach(o),Es=c(y),A=n(y,"DIV",{class:!0});var ft=r(A);b(ye.$$.fragment,ft),zs=c(ft),Xt=n(ft,"P",{});var ar=r(Xt);js=l(ar,`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A XLMProphetNet sequence has the following format:`),ar.forEach(o),Ts=c(ft),xe=n(ft,"UL",{});var Mo=r(xe);nt=n(Mo,"LI",{});var jn=r(nt);Cs=l(jn,"single sequence: "),qt=n(jn,"CODE",{});var ir=r(qt);Ds=l(ir,"X [SEP]"),ir.forEach(o),jn.forEach(o),As=c(Mo),rt=n(Mo,"LI",{});var Tn=r(rt);Ss=l(Tn,"pair of sequences: "),Et=n(Tn,"CODE",{});var lr=r(Et);Is=l(lr,"A [SEP] B [SEP]"),lr.forEach(o),Tn.forEach(o),Mo.forEach(o),ft.forEach(o),Os=c(y),te=n(y,"DIV",{class:!0});var yo=r(te);b(Xe.$$.fragment,yo),Fs=c(yo),zt=n(yo,"P",{});var pr=r(zt);Gs=l(pr,"Converts a sequence of tokens (strings for sub-words) in a single string."),pr.forEach(o),yo.forEach(o),Bs=c(y),oe=n(y,"DIV",{class:!0});var xo=r(oe);b(qe.$$.fragment,xo),Rs=c(xo),jt=n(xo,"P",{});var dr=r(jt);Hs=l(dr,`Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLMProphetNet
does not make use of token type ids, therefore a list of zeros is returned.`),dr.forEach(o),xo.forEach(o),Ws=c(y),se=n(y,"DIV",{class:!0});var Xo=r(se);b(Ee.$$.fragment,Xo),Vs=c(Xo),ze=n(Xo,"P",{});var qo=r(ze);Us=l(qo,`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),Tt=n(qo,"CODE",{});var cr=r(Tt);Ys=l(cr,"prepare_for_model"),cr.forEach(o),Js=l(qo," method."),qo.forEach(o),Xo.forEach(o),y.forEach(o),lo=c(e),R=n(e,"H2",{class:!0});var Eo=r(R);ne=n(Eo,"A",{id:!0,class:!0,href:!0});var hr=r(ne);Ct=n(hr,"SPAN",{});var mr=r(Ct);b(je.$$.fragment,mr),mr.forEach(o),hr.forEach(o),Qs=c(Eo),Dt=n(Eo,"SPAN",{});var fr=r(Dt);Zs=l(fr,"XLMProphetNetModel"),fr.forEach(o),Eo.forEach(o),po=c(e),E=n(e,"DIV",{class:!0});var ut=r(E);b(Te.$$.fragment,ut),Ks=c(ut),Ce=n(ut,"P",{});var zo=r(Ce);en=l(zo,"This class overrides "),at=n(zo,"A",{href:!0});var ur=r(at);tn=l(ur,"ProphetNetModel"),ur.forEach(o),on=l(zo,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),zo.forEach(o),sn=c(ut),b(re.$$.fragment,ut),ut.forEach(o),co=c(e),H=n(e,"H2",{class:!0});var jo=r(H);ae=n(jo,"A",{id:!0,class:!0,href:!0});var gr=r(ae);At=n(gr,"SPAN",{});var _r=r(At);b(De.$$.fragment,_r),_r.forEach(o),gr.forEach(o),nn=c(jo),St=n(jo,"SPAN",{});var kr=r(St);rn=l(kr,"XLMProphetNetEncoder"),kr.forEach(o),jo.forEach(o),ho=c(e),z=n(e,"DIV",{class:!0});var gt=r(z);b(Ae.$$.fragment,gt),an=c(gt),Se=n(gt,"P",{});var To=r(Se);ln=l(To,"This class overrides "),it=n(To,"A",{href:!0});var vr=r(it);pn=l(vr,"ProphetNetEncoder"),vr.forEach(o),dn=l(To,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),To.forEach(o),cn=c(gt),b(ie.$$.fragment,gt),gt.forEach(o),mo=c(e),W=n(e,"H2",{class:!0});var Co=r(W);le=n(Co,"A",{id:!0,class:!0,href:!0});var br=r(le);It=n(br,"SPAN",{});var Pr=r(It);b(Ie.$$.fragment,Pr),Pr.forEach(o),br.forEach(o),hn=c(Co),Ot=n(Co,"SPAN",{});var $r=r(Ot);mn=l($r,"XLMProphetNetDecoder"),$r.forEach(o),Co.forEach(o),fo=c(e),j=n(e,"DIV",{class:!0});var _t=r(j);b(Oe.$$.fragment,_t),fn=c(_t),Fe=n(_t,"P",{});var Do=r(Fe);un=l(Do,"This class overrides "),lt=n(Do,"A",{href:!0});var Nr=r(lt);gn=l(Nr,"ProphetNetDecoder"),Nr.forEach(o),_n=l(Do,`. Please check the superclass for the appropriate documentation alongside
usage examples.`),Do.forEach(o),kn=c(_t),b(pe.$$.fragment,_t),_t.forEach(o),uo=c(e),V=n(e,"H2",{class:!0});var Ao=r(V);de=n(Ao,"A",{id:!0,class:!0,href:!0});var wr=r(de);Ft=n(wr,"SPAN",{});var Lr=r(Ft);b(Ge.$$.fragment,Lr),Lr.forEach(o),wr.forEach(o),vn=c(Ao),Gt=n(Ao,"SPAN",{});var Mr=r(Gt);bn=l(Mr,"XLMProphetNetForConditionalGeneration"),Mr.forEach(o),Ao.forEach(o),go=c(e),T=n(e,"DIV",{class:!0});var kt=r(T);b(Be.$$.fragment,kt),Pn=c(kt),Re=n(kt,"P",{});var So=r(Re);$n=l(So,"This class overrides "),pt=n(So,"A",{href:!0});var yr=r(pt);Nn=l(yr,"ProphetNetForConditionalGeneration"),yr.forEach(o),wn=l(So,`. Please check the superclass for the appropriate
documentation alongside usage examples.`),So.forEach(o),Ln=c(kt),b(ce.$$.fragment,kt),kt.forEach(o),_o=c(e),U=n(e,"H2",{class:!0});var Io=r(U);he=n(Io,"A",{id:!0,class:!0,href:!0});var xr=r(he);Bt=n(xr,"SPAN",{});var Xr=r(Bt);b(He.$$.fragment,Xr),Xr.forEach(o),xr.forEach(o),Mn=c(Io),Rt=n(Io,"SPAN",{});var qr=r(Rt);yn=l(qr,"XLMProphetNetForCausalLM"),qr.forEach(o),Io.forEach(o),ko=c(e),C=n(e,"DIV",{class:!0});var vt=r(C);b(We.$$.fragment,vt),xn=c(vt),Ve=n(vt,"P",{});var Oo=r(Ve);Xn=l(Oo,"This class overrides "),dt=n(Oo,"A",{href:!0});var Er=r(dt);qn=l(Er,"ProphetNetForCausalLM"),Er.forEach(o),En=l(Oo,`. Please check the superclass for the appropriate documentation
alongside usage examples.`),Oo.forEach(o),zn=c(vt),b(me.$$.fragment,vt),vt.forEach(o),this.h()},h(){p(u,"name","hf:doc:metadata"),p(u,"content",JSON.stringify(Br)),p(f,"id","xlmprophetnet"),p(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(f,"href","#xlmprophetnet"),p(_,"class","relative group"),p(ge,"href","https://github.com/huggingface/transformers/issues/new?assignees=&labels=&template=bug-report.md&title"),p(ge,"rel","nofollow"),p(J,"id","overview"),p(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(J,"href","#overview"),p(I,"class","relative group"),p(ke,"href","https://arxiv.org/abs/2001.04063"),p(ke,"rel","nofollow"),p(ve,"href","https://github.com/microsoft/ProphetNet"),p(ve,"rel","nofollow"),p(K,"id","transformers.XLMProphetNetConfig"),p(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(K,"href","#transformers.XLMProphetNetConfig"),p(O,"class","relative group"),p(Ze,"href","/docs/transformers/v4.23.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),p($e,"href","https://huggingface.co/microsoft/xprophetnet-large-wiki100-cased"),p($e,"rel","nofollow"),p(Ke,"href","/docs/transformers/v4.23.1/en/main_classes/configuration#transformers.PretrainedConfig"),p(et,"href","/docs/transformers/v4.23.1/en/main_classes/configuration#transformers.PretrainedConfig"),p(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(ee,"id","transformers.XLMProphetNetTokenizer"),p(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ee,"href","#transformers.XLMProphetNetTokenizer"),p(B,"class","relative group"),p(tt,"href","/docs/transformers/v4.23.1/en/model_doc/roberta#transformers.RobertaTokenizer"),p(ot,"href","/docs/transformers/v4.23.1/en/model_doc/xlnet#transformers.XLNetTokenizer"),p(Le,"href","https://github.com/google/sentencepiece"),p(Le,"rel","nofollow"),p(st,"href","/docs/transformers/v4.23.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),p(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(se,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(ne,"id","transformers.XLMProphetNetModel"),p(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ne,"href","#transformers.XLMProphetNetModel"),p(R,"class","relative group"),p(at,"href","/docs/transformers/v4.23.1/en/model_doc/prophetnet#transformers.ProphetNetModel"),p(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(ae,"id","transformers.XLMProphetNetEncoder"),p(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ae,"href","#transformers.XLMProphetNetEncoder"),p(H,"class","relative group"),p(it,"href","/docs/transformers/v4.23.1/en/model_doc/prophetnet#transformers.ProphetNetEncoder"),p(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(le,"id","transformers.XLMProphetNetDecoder"),p(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(le,"href","#transformers.XLMProphetNetDecoder"),p(W,"class","relative group"),p(lt,"href","/docs/transformers/v4.23.1/en/model_doc/prophetnet#transformers.ProphetNetDecoder"),p(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(de,"id","transformers.XLMProphetNetForConditionalGeneration"),p(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(de,"href","#transformers.XLMProphetNetForConditionalGeneration"),p(V,"class","relative group"),p(pt,"href","/docs/transformers/v4.23.1/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),p(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(he,"id","transformers.XLMProphetNetForCausalLM"),p(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(he,"href","#transformers.XLMProphetNetForCausalLM"),p(U,"class","relative group"),p(dt,"href","/docs/transformers/v4.23.1/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),p(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,h){t(document.head,u),m(e,L,h),m(e,_,h),t(_,f),t(f,k),P(a,k,null),t(_,g),t(_,bt),t(bt,Fo),m(e,Qt,h),m(e,S,h),t(S,Pt),t(Pt,Go),t(S,Bo),t(S,ge),t(ge,Ro),t(S,Ho),m(e,Zt,h),m(e,I,h),t(I,J),t(J,$t),P(_e,$t,null),t(I,Wo),t(I,Nt),t(Nt,Vo),m(e,Kt,h),m(e,Q,h),t(Q,Uo),t(Q,ke),t(ke,Yo),t(Q,Jo),m(e,eo,h),m(e,Ye,h),t(Ye,Qo),m(e,to,h),m(e,Je,h),t(Je,Zo),m(e,oo,h),m(e,Qe,h),t(Qe,wt),t(wt,Ko),m(e,so,h),m(e,Z,h),t(Z,es),t(Z,ve),t(ve,ts),t(Z,os),m(e,no,h),m(e,O,h),t(O,K),t(K,Lt),P(be,Lt,null),t(O,ss),t(O,Mt),t(Mt,ns),m(e,ro,h),m(e,X,h),P(Pe,X,null),t(X,rs),t(X,F),t(F,as),t(F,Ze),t(Ze,is),t(F,ls),t(F,$e),t($e,ps),t(F,ds),t(X,cs),t(X,G),t(G,hs),t(G,Ke),t(Ke,ms),t(G,fs),t(G,et),t(et,us),t(G,gs),m(e,ao,h),m(e,B,h),t(B,ee),t(ee,yt),P(Ne,yt,null),t(B,_s),t(B,xt),t(xt,ks),m(e,io,h),m(e,M,h),P(we,M,null),t(M,vs),t(M,q),t(q,bs),t(q,tt),t(tt,Ps),t(q,$s),t(q,ot),t(ot,Ns),t(q,ws),t(q,Le),t(Le,Ls),t(q,Ms),t(M,ys),t(M,Me),t(Me,xs),t(Me,st),t(st,Xs),t(Me,qs),t(M,Es),t(M,A),P(ye,A,null),t(A,zs),t(A,Xt),t(Xt,js),t(A,Ts),t(A,xe),t(xe,nt),t(nt,Cs),t(nt,qt),t(qt,Ds),t(xe,As),t(xe,rt),t(rt,Ss),t(rt,Et),t(Et,Is),t(M,Os),t(M,te),P(Xe,te,null),t(te,Fs),t(te,zt),t(zt,Gs),t(M,Bs),t(M,oe),P(qe,oe,null),t(oe,Rs),t(oe,jt),t(jt,Hs),t(M,Ws),t(M,se),P(Ee,se,null),t(se,Vs),t(se,ze),t(ze,Us),t(ze,Tt),t(Tt,Ys),t(ze,Js),m(e,lo,h),m(e,R,h),t(R,ne),t(ne,Ct),P(je,Ct,null),t(R,Qs),t(R,Dt),t(Dt,Zs),m(e,po,h),m(e,E,h),P(Te,E,null),t(E,Ks),t(E,Ce),t(Ce,en),t(Ce,at),t(at,tn),t(Ce,on),t(E,sn),P(re,E,null),m(e,co,h),m(e,H,h),t(H,ae),t(ae,At),P(De,At,null),t(H,nn),t(H,St),t(St,rn),m(e,ho,h),m(e,z,h),P(Ae,z,null),t(z,an),t(z,Se),t(Se,ln),t(Se,it),t(it,pn),t(Se,dn),t(z,cn),P(ie,z,null),m(e,mo,h),m(e,W,h),t(W,le),t(le,It),P(Ie,It,null),t(W,hn),t(W,Ot),t(Ot,mn),m(e,fo,h),m(e,j,h),P(Oe,j,null),t(j,fn),t(j,Fe),t(Fe,un),t(Fe,lt),t(lt,gn),t(Fe,_n),t(j,kn),P(pe,j,null),m(e,uo,h),m(e,V,h),t(V,de),t(de,Ft),P(Ge,Ft,null),t(V,vn),t(V,Gt),t(Gt,bn),m(e,go,h),m(e,T,h),P(Be,T,null),t(T,Pn),t(T,Re),t(Re,$n),t(Re,pt),t(pt,Nn),t(Re,wn),t(T,Ln),P(ce,T,null),m(e,_o,h),m(e,U,h),t(U,he),t(he,Bt),P(He,Bt,null),t(U,Mn),t(U,Rt),t(Rt,yn),m(e,ko,h),m(e,C,h),P(We,C,null),t(C,xn),t(C,Ve),t(Ve,Xn),t(Ve,dt),t(dt,qn),t(Ve,En),t(C,zn),P(me,C,null),vo=!0},p(e,[h]){const Ue={};h&2&&(Ue.$$scope={dirty:h,ctx:e}),re.$set(Ue);const Ht={};h&2&&(Ht.$$scope={dirty:h,ctx:e}),ie.$set(Ht);const Wt={};h&2&&(Wt.$$scope={dirty:h,ctx:e}),pe.$set(Wt);const Vt={};h&2&&(Vt.$$scope={dirty:h,ctx:e}),ce.$set(Vt);const fe={};h&2&&(fe.$$scope={dirty:h,ctx:e}),me.$set(fe)},i(e){vo||($(a.$$.fragment,e),$(_e.$$.fragment,e),$(be.$$.fragment,e),$(Pe.$$.fragment,e),$(Ne.$$.fragment,e),$(we.$$.fragment,e),$(ye.$$.fragment,e),$(Xe.$$.fragment,e),$(qe.$$.fragment,e),$(Ee.$$.fragment,e),$(je.$$.fragment,e),$(Te.$$.fragment,e),$(re.$$.fragment,e),$(De.$$.fragment,e),$(Ae.$$.fragment,e),$(ie.$$.fragment,e),$(Ie.$$.fragment,e),$(Oe.$$.fragment,e),$(pe.$$.fragment,e),$(Ge.$$.fragment,e),$(Be.$$.fragment,e),$(ce.$$.fragment,e),$(He.$$.fragment,e),$(We.$$.fragment,e),$(me.$$.fragment,e),vo=!0)},o(e){N(a.$$.fragment,e),N(_e.$$.fragment,e),N(be.$$.fragment,e),N(Pe.$$.fragment,e),N(Ne.$$.fragment,e),N(we.$$.fragment,e),N(ye.$$.fragment,e),N(Xe.$$.fragment,e),N(qe.$$.fragment,e),N(Ee.$$.fragment,e),N(je.$$.fragment,e),N(Te.$$.fragment,e),N(re.$$.fragment,e),N(De.$$.fragment,e),N(Ae.$$.fragment,e),N(ie.$$.fragment,e),N(Ie.$$.fragment,e),N(Oe.$$.fragment,e),N(pe.$$.fragment,e),N(Ge.$$.fragment,e),N(Be.$$.fragment,e),N(ce.$$.fragment,e),N(He.$$.fragment,e),N(We.$$.fragment,e),N(me.$$.fragment,e),vo=!1},d(e){o(u),e&&o(L),e&&o(_),w(a),e&&o(Qt),e&&o(S),e&&o(Zt),e&&o(I),w(_e),e&&o(Kt),e&&o(Q),e&&o(eo),e&&o(Ye),e&&o(to),e&&o(Je),e&&o(oo),e&&o(Qe),e&&o(so),e&&o(Z),e&&o(no),e&&o(O),w(be),e&&o(ro),e&&o(X),w(Pe),e&&o(ao),e&&o(B),w(Ne),e&&o(io),e&&o(M),w(we),w(ye),w(Xe),w(qe),w(Ee),e&&o(lo),e&&o(R),w(je),e&&o(po),e&&o(E),w(Te),w(re),e&&o(co),e&&o(H),w(De),e&&o(ho),e&&o(z),w(Ae),w(ie),e&&o(mo),e&&o(W),w(Ie),e&&o(fo),e&&o(j),w(Oe),w(pe),e&&o(uo),e&&o(V),w(Ge),e&&o(go),e&&o(T),w(Be),w(ce),e&&o(_o),e&&o(U),w(He),e&&o(ko),e&&o(C),w(We),w(me)}}}const Br={local:"xlmprophetnet",sections:[{local:"overview",title:"Overview"},{local:"transformers.XLMProphetNetConfig",title:"XLMProphetNetConfig"},{local:"transformers.XLMProphetNetTokenizer",title:"XLMProphetNetTokenizer"},{local:"transformers.XLMProphetNetModel",title:"XLMProphetNetModel"},{local:"transformers.XLMProphetNetEncoder",title:"XLMProphetNetEncoder"},{local:"transformers.XLMProphetNetDecoder",title:"XLMProphetNetDecoder"},{local:"transformers.XLMProphetNetForConditionalGeneration",title:"XLMProphetNetForConditionalGeneration"},{local:"transformers.XLMProphetNetForCausalLM",title:"XLMProphetNetForCausalLM"}],title:"XLM-ProphetNet"};function Rr(x){return Dr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Jr extends zr{constructor(u){super();jr(this,u,Rr,Gr,Tr,{})}}export{Jr as default,Br as metadata};
