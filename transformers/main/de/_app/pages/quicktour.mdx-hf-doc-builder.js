import{S as sn,i as rn,s as ln,e as c,c as m,a as p,d as r,b as w,N as Nn,g,L as x,F as Fe,G as a,Q as Dl,Y as Qu,H as qe,I as Oe,J as We,q as E,o as T,v as Ko,X as Ho,O as Iu,P as Pu,f as rd,w as y,x as P,y as C,B as D,k,m as v,n as Ae,p as Te,Z as Xu,l as ze,t as u,h as d,j as ed,W as ld,K as td,M as ad}from"../chunks/vendor-hf-doc-builder.js";import{T as Pn,C as V}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as Ee}from"../chunks/IconCopyLink-hf-doc-builder.js";import{F as nn,M as fe}from"../chunks/Markdown-hf-doc-builder.js";function id(o){let e,l;return{c(){e=c("iframe"),this.h()},l(t){e=m(t,"IFRAME",{class:!0,src:!0,title:!0,frameborder:!0,allow:!0}),p(e).forEach(r),this.h()},h(){w(e,"class","w-full xl:w-4/6 h-80"),Nn(e.src,l="https://www.youtube-nocookie.com/embed/"+o[0])||w(e,"src",l),w(e,"title","YouTube video player"),w(e,"frameborder","0"),w(e,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),e.allowFullscreen=!0},m(t,s){g(t,e,s)},p(t,[s]){s&1&&!Nn(e.src,l="https://www.youtube-nocookie.com/embed/"+t[0])&&w(e,"src",l)},i:x,o:x,d(t){t&&r(e)}}}function od(o,e,l){let{id:t}=e;return o.$$set=s=>{"id"in s&&l(0,t=s.id)},[t]}class Nu extends sn{constructor(e){super();rn(this,e,od,id,ln,{id:0})}}function fd(o){let e,l,t,s,i,f;const h=o[7].default,_=Fe(h,o,o[6],null);return{c(){e=c("div"),l=c("ul"),_&&_.c(),this.h()},l($){e=m($,"DIV",{class:!0});var M=p(e);l=m(M,"UL",{class:!0});var F=p(l);_&&_.l(F),F.forEach(r),M.forEach(r),this.h()},h(){w(l,"class","min-w-full w-auto"),w(e,"class",t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(o[2]==="right"?"right-0":"left-0")+" "+o[0])},m($,M){g($,e,M),a(e,l),_&&_.m(l,null),o[8](e),s=!0,i||(f=Dl(e,"click",function(){Qu(o[1])&&o[1].apply(this,arguments)}),i=!0)},p($,[M]){o=$,_&&_.p&&(!s||M&64)&&qe(_,h,o,o[6],s?We(h,o[6],M,null):Oe(o[6]),null),(!s||M&5&&t!==(t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(o[2]==="right"?"right-0":"left-0")+" "+o[0]))&&w(e,"class",t)},i($){s||(E(_,$),s=!0)},o($){T(_,$),s=!1},d($){$&&r(e),_&&_.d($),o[8](null),i=!1,f()}}}function ud(o,e,l){let{$$slots:t={},$$scope:s}=e,{classNames:i=""}=e,{dropdownElement:f=void 0}=e,{forceAlignement:h=void 0}=e,{onClose:_}=e,$=h!=null?h:"left",M;Ko(()=>{var j,I;if(document.addEventListener("click",F),!h){const A=document.documentElement.clientWidth,S=(M==null?void 0:M.getBoundingClientRect())||{},z=(j=S.left)!=null?j:0,N=(I=S.width)!=null?I:0;l(2,$=z+N>A?"right":"left")}return()=>{document.removeEventListener("click",F)}});function F(j){const I=j.target;I!==f&&!(f==null?void 0:f.contains(I))&&_()}function q(j){Ho[j?"unshift":"push"](()=>{M=j,l(3,M)})}return o.$$set=j=>{"classNames"in j&&l(0,i=j.classNames),"dropdownElement"in j&&l(4,f=j.dropdownElement),"forceAlignement"in j&&l(5,h=j.forceAlignement),"onClose"in j&&l(1,_=j.onClose),"$$scope"in j&&l(6,s=j.$$scope)},[i,_,$,M,f,h,s,t,q]}class dd extends sn{constructor(e){super();rn(this,e,ud,fd,ln,{classNames:0,dropdownElement:4,forceAlignement:5,onClose:1})}}function cd(o){let e,l;return{c(){e=Iu("svg"),l=Iu("path"),this.h()},l(t){e=Pu(t,"svg",{class:!0,xmlns:!0,"xmlns:xlink":!0,"aria-hidden":!0,focusable:!0,role:!0,width:!0,height:!0,preserveAspectRatio:!0,viewBox:!0,style:!0});var s=p(e);l=Pu(s,"path",{d:!0,fill:!0}),p(l).forEach(r),s.forEach(r),this.h()},h(){w(l,"d","M7 10l5 5l5-5z"),w(l,"fill","currentColor"),w(e,"class",o[0]),w(e,"xmlns","http://www.w3.org/2000/svg"),w(e,"xmlns:xlink","http://www.w3.org/1999/xlink"),w(e,"aria-hidden","true"),w(e,"focusable","false"),w(e,"role","img"),w(e,"width","1em"),w(e,"height","1em"),w(e,"preserveAspectRatio","xMidYMid meet"),w(e,"viewBox","0 0 24 24"),rd(e,"transform","rotate(360deg)")},m(t,s){g(t,e,s),a(e,l)},p(t,[s]){s&1&&w(e,"class",t[0])},i:x,o:x,d(t){t&&r(e)}}}function md(o,e,l){let{classNames:t=""}=e;return o.$$set=s=>{"classNames"in s&&l(0,t=s.classNames)},[t]}class pd extends sn{constructor(e){super();rn(this,e,md,cd,ln,{classNames:0})}}const hd=o=>({}),Fu=o=>({}),gd=o=>({}),qu=o=>({});function _d(o){let e,l,t,s,i,f=o[2]&&Ou(o),h=o[10]&&Wu();return{c(){f&&f.c(),e=k(),l=u(o[4]),t=k(),h&&h.c(),s=ze()},l(_){f&&f.l(_),e=v(_),l=d(_,o[4]),t=v(_),h&&h.l(_),s=ze()},m(_,$){f&&f.m(_,$),g(_,e,$),g(_,l,$),g(_,t,$),h&&h.m(_,$),g(_,s,$),i=!0},p(_,$){_[2]?f?(f.p(_,$),$&4&&E(f,1)):(f=Ou(_),f.c(),E(f,1),f.m(e.parentNode,e)):f&&(Ae(),T(f,1,1,()=>{f=null}),Te()),(!i||$&16)&&ed(l,_[4]),_[10]?h?$&1024&&E(h,1):(h=Wu(),h.c(),E(h,1),h.m(s.parentNode,s)):h&&(Ae(),T(h,1,1,()=>{h=null}),Te())},i(_){i||(E(f),E(h),i=!0)},o(_){T(f),T(h),i=!1},d(_){f&&f.d(_),_&&r(e),_&&r(l),_&&r(t),h&&h.d(_),_&&r(s)}}}function bd(o){let e;const l=o[14].button,t=Fe(l,o,o[18],qu);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,i){t&&t.m(s,i),e=!0},p(s,i){t&&t.p&&(!e||i&262144)&&qe(t,l,s,s[18],e?We(l,s[18],i,gd):Oe(s[18]),qu)},i(s){e||(E(t,s),e=!0)},o(s){T(t,s),e=!1},d(s){t&&t.d(s)}}}function Ou(o){let e,l,t;var s=o[2];function i(f){return{props:{classNames:"mr-1.5 "+f[3]}}}return s&&(e=new s(i(o))),{c(){e&&y(e.$$.fragment),l=ze()},l(f){e&&P(e.$$.fragment,f),l=ze()},m(f,h){e&&C(e,f,h),g(f,l,h),t=!0},p(f,h){const _={};if(h&8&&(_.classNames="mr-1.5 "+f[3]),s!==(s=f[2])){if(e){Ae();const $=e;T($.$$.fragment,1,0,()=>{D($,1)}),Te()}s?(e=new s(i(f)),y(e.$$.fragment),E(e.$$.fragment,1),C(e,l.parentNode,l)):e=null}else s&&e.$set(_)},i(f){t||(e&&E(e.$$.fragment,f),t=!0)},o(f){e&&T(e.$$.fragment,f),t=!1},d(f){f&&r(l),e&&D(e,f)}}}function Wu(o){let e,l;return e=new pd({props:{classNames:"-mr-1 text-gray-500"}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Bu(o){let e,l;return e=new dd({props:{classNames:o[6]+" "+(o[9]?"v2-dropdown-menu hidden":""),dropdownElement:o[11],forceAlignement:o[5],onClose:o[16],$$slots:{default:[$d]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&576&&(i.classNames=t[6]+" "+(t[9]?"v2-dropdown-menu hidden":"")),s&2048&&(i.dropdownElement=t[11]),s&32&&(i.forceAlignement=t[5]),s&4096&&(i.onClose=t[16]),s&262144&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function $d(o){let e;const l=o[14].menu,t=Fe(l,o,o[18],Fu);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,i){t&&t.m(s,i),e=!0},p(s,i){t&&t.p&&(!e||i&262144)&&qe(t,l,s,s[18],e?We(l,s[18],i,hd):Oe(s[18]),Fu)},i(s){e||(E(t,s),e=!0)},o(s){T(t,s),e=!1},d(s){t&&t.d(s)}}}function wd(o){let e,l,t,s,i,f,h,_,$,M,F;const q=[bd,_d],j=[];function I(S,z){return S[13].button?0:1}t=I(o),s=j[t]=q[t](o);let A=(o[12]||o[9])&&Bu(o);return{c(){e=c("div"),l=c("button"),s.c(),f=k(),A&&A.c(),this.h()},l(S){e=m(S,"DIV",{class:!0,"selected-value":!0});var z=p(e);l=m(z,"BUTTON",{class:!0,type:!0});var N=p(l);s.l(N),N.forEach(r),f=v(z),A&&A.l(z),z.forEach(r),this.h()},h(){w(l,"class",i=""+o[1]+" "+(o[7]?"":"cursor-pointer w-full btn text-sm")+" "+(o[9]?"v2-dropdown-button":"")),w(l,"type","button"),w(e,"class",h="relative "+o[0]+" "+(o[9]?"v2-dropdown":"")),w(e,"selected-value",_=o[8]||void 0)},m(S,z){g(S,e,z),a(e,l),j[t].m(l,null),a(e,f),A&&A.m(e,null),o[17](e),$=!0,M||(F=Dl(l,"click",o[15]),M=!0)},p(S,[z]){let N=t;t=I(S),t===N?j[t].p(S,z):(Ae(),T(j[N],1,1,()=>{j[N]=null}),Te(),s=j[t],s?s.p(S,z):(s=j[t]=q[t](S),s.c()),E(s,1),s.m(l,null)),(!$||z&642&&i!==(i=""+S[1]+" "+(S[7]?"":"cursor-pointer w-full btn text-sm")+" "+(S[9]?"v2-dropdown-button":"")))&&w(l,"class",i),S[12]||S[9]?A?(A.p(S,z),z&4608&&E(A,1)):(A=Bu(S),A.c(),E(A,1),A.m(e,null)):A&&(Ae(),T(A,1,1,()=>{A=null}),Te()),(!$||z&513&&h!==(h="relative "+S[0]+" "+(S[9]?"v2-dropdown":"")))&&w(e,"class",h),(!$||z&256&&_!==(_=S[8]||void 0))&&w(e,"selected-value",_)},i(S){$||(E(s),E(A),$=!0)},o(S){T(s),T(A),$=!1},d(S){S&&r(e),j[t].d(),A&&A.d(),o[17](null),M=!1,F()}}}function kd(o,e,l){let{$$slots:t={},$$scope:s}=e;const i=Xu(t);let{classNames:f=""}=e,{btnClassNames:h=""}=e,{btnIcon:_=void 0}=e,{btnIconClassNames:$=""}=e,{btnLabel:M=""}=e,{forceMenuAlignement:F=void 0}=e,{menuClassNames:q=""}=e,{noBtnClass:j=void 0}=e,{selectedValue:I=void 0}=e,{useDeprecatedJS:A=!0}=e,{withBtnCaret:S=!1}=e,z,N=!1;const B=()=>l(12,N=!N),L=()=>l(12,N=!1);function U(K){Ho[K?"unshift":"push"](()=>{z=K,l(11,z)})}return o.$$set=K=>{"classNames"in K&&l(0,f=K.classNames),"btnClassNames"in K&&l(1,h=K.btnClassNames),"btnIcon"in K&&l(2,_=K.btnIcon),"btnIconClassNames"in K&&l(3,$=K.btnIconClassNames),"btnLabel"in K&&l(4,M=K.btnLabel),"forceMenuAlignement"in K&&l(5,F=K.forceMenuAlignement),"menuClassNames"in K&&l(6,q=K.menuClassNames),"noBtnClass"in K&&l(7,j=K.noBtnClass),"selectedValue"in K&&l(8,I=K.selectedValue),"useDeprecatedJS"in K&&l(9,A=K.useDeprecatedJS),"withBtnCaret"in K&&l(10,S=K.withBtnCaret),"$$scope"in K&&l(18,s=K.$$scope)},[f,h,_,$,M,F,q,j,I,A,S,z,N,i,t,B,L,U,s]}class nd extends sn{constructor(e){super();rn(this,e,kd,wd,ln,{classNames:0,btnClassNames:1,btnIcon:2,btnIconClassNames:3,btnLabel:4,forceMenuAlignement:5,menuClassNames:6,noBtnClass:7,selectedValue:8,useDeprecatedJS:9,withBtnCaret:10})}}function vd(o){let e,l,t,s=o[5]&&Lu(o);return{c(){s&&s.c(),e=k(),l=u(o[7])},l(i){s&&s.l(i),e=v(i),l=d(i,o[7])},m(i,f){s&&s.m(i,f),g(i,e,f),g(i,l,f),t=!0},p(i,f){i[5]?s?(s.p(i,f),f&32&&E(s,1)):(s=Lu(i),s.c(),E(s,1),s.m(e.parentNode,e)):s&&(Ae(),T(s,1,1,()=>{s=null}),Te()),(!t||f&128)&&ed(l,i[7])},i(i){t||(E(s),t=!0)},o(i){T(s),t=!1},d(i){s&&s.d(i),i&&r(e),i&&r(l)}}}function Ed(o){let e;const l=o[15].default,t=Fe(l,o,o[14],null);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,i){t&&t.m(s,i),e=!0},p(s,i){t&&t.p&&(!e||i&16384)&&qe(t,l,s,s[14],e?We(l,s[14],i,null):Oe(s[14]),null)},i(s){e||(E(t,s),e=!0)},o(s){T(t,s),e=!1},d(s){t&&t.d(s)}}}function Lu(o){let e,l,t;var s=o[5];function i(f){return{props:{classNames:"mr-1.5 "+f[6]}}}return s&&(e=new s(i(o))),{c(){e&&y(e.$$.fragment),l=ze()},l(f){e&&P(e.$$.fragment,f),l=ze()},m(f,h){e&&C(e,f,h),g(f,l,h),t=!0},p(f,h){const _={};if(h&64&&(_.classNames="mr-1.5 "+f[6]),s!==(s=f[5])){if(e){Ae();const $=e;T($.$$.fragment,1,0,()=>{D($,1)}),Te()}s?(e=new s(i(f)),y(e.$$.fragment),E(e.$$.fragment,1),C(e,l.parentNode,l)):e=null}else s&&e.$set(_)},i(f){t||(e&&E(e.$$.fragment,f),t=!0)},o(f){e&&T(e.$$.fragment,f),t=!1},d(f){f&&r(l),e&&D(e,f)}}}function Ad(o){let e,l,t,s,i,f,h,_,$,M;const F=[Ed,vd],q=[];function j(I,A){return I[13].default?0:1}return t=j(o),s=q[t]=F[t](o),{c(){e=c("li"),l=c("a"),s.c(),this.h()},l(I){e=m(I,"LI",{});var A=p(e);l=m(A,"A",{class:!0,"data-label":!0,"data-url":!0,"data-value":!0,href:!0,rel:!0,target:!0});var S=p(l);s.l(S),S.forEach(r),A.forEach(r),this.h()},h(){w(l,"class",i="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+o[0]+" "+(o[9]?"hover:underline":"")+" "+(o[12]?"v2-dropdown-entry":"")),w(l,"data-label",o[1]),w(l,"data-url",o[2]),w(l,"data-value",o[3]),w(l,"href",o[4]),w(l,"rel",f=o[8]?"nofollow":void 0),w(l,"target",h=o[11]?"_blank":void 0)},m(I,A){g(I,e,A),a(e,l),q[t].m(l,null),_=!0,$||(M=Dl(l,"click",function(){Qu(o[10])&&o[10].apply(this,arguments)}),$=!0)},p(I,[A]){o=I;let S=t;t=j(o),t===S?q[t].p(o,A):(Ae(),T(q[S],1,1,()=>{q[S]=null}),Te(),s=q[t],s?s.p(o,A):(s=q[t]=F[t](o),s.c()),E(s,1),s.m(l,null)),(!_||A&4609&&i!==(i="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+o[0]+" "+(o[9]?"hover:underline":"")+" "+(o[12]?"v2-dropdown-entry":"")))&&w(l,"class",i),(!_||A&2)&&w(l,"data-label",o[1]),(!_||A&4)&&w(l,"data-url",o[2]),(!_||A&8)&&w(l,"data-value",o[3]),(!_||A&16)&&w(l,"href",o[4]),(!_||A&256&&f!==(f=o[8]?"nofollow":void 0))&&w(l,"rel",f),(!_||A&2048&&h!==(h=o[11]?"_blank":void 0))&&w(l,"target",h)},i(I){_||(E(s),_=!0)},o(I){T(s),_=!1},d(I){I&&r(e),q[t].d(),$=!1,M()}}}function Td(o,e,l){let{$$slots:t={},$$scope:s}=e;const i=Xu(t);let{classNames:f=""}=e,{dataLabel:h=void 0}=e,{dataUrl:_=void 0}=e,{dataValue:$=void 0}=e,{href:M=void 0}=e,{icon:F=void 0}=e,{iconClassNames:q=""}=e,{label:j=""}=e,{noFollow:I=!1}=e,{underline:A=!1}=e,{onClick:S=()=>{}}=e,{targetBlank:z=!1}=e,{useDeprecatedJS:N=!0}=e;return o.$$set=B=>{"classNames"in B&&l(0,f=B.classNames),"dataLabel"in B&&l(1,h=B.dataLabel),"dataUrl"in B&&l(2,_=B.dataUrl),"dataValue"in B&&l(3,$=B.dataValue),"href"in B&&l(4,M=B.href),"icon"in B&&l(5,F=B.icon),"iconClassNames"in B&&l(6,q=B.iconClassNames),"label"in B&&l(7,j=B.label),"noFollow"in B&&l(8,I=B.noFollow),"underline"in B&&l(9,A=B.underline),"onClick"in B&&l(10,S=B.onClick),"targetBlank"in B&&l(11,z=B.targetBlank),"useDeprecatedJS"in B&&l(12,N=B.useDeprecatedJS),"$$scope"in B&&l(14,s=B.$$scope)},[f,h,_,$,M,F,q,j,I,A,S,z,N,i,s,t]}class sd extends sn{constructor(e){super();rn(this,e,Td,Ad,ln,{classNames:0,dataLabel:1,dataUrl:2,dataValue:3,href:4,icon:5,iconClassNames:6,label:7,noFollow:8,underline:9,onClick:10,targetBlank:11,useDeprecatedJS:12})}}const{window:zd}=ld,Sd=o=>({}),Ku=o=>({slot:"button"});function Hu(o,e,l){const t=o.slice();return t[11]=e[l].label,t[12]=e[l].value,t}const jd=o=>({}),Uu=o=>({slot:"menu"}),Md=o=>({}),Ru=o=>({slot:"button"});function Vu(o,e,l){const t=o.slice();return t[11]=e[l].label,t[12]=e[l].value,t}const yd=o=>({}),xu=o=>({slot:"menu"}),Cd=o=>({}),Gu=o=>({slot:"menu"});function Dd(o){let e,l;return e=new nd({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[qd],button:[Nd]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&1024&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Id(o){let e,l,t;return{c(){e=c("a"),l=c("img"),this.h()},l(s){e=m(s,"A",{href:!0,target:!0});var i=p(e);l=m(i,"IMG",{alt:!0,class:!0,src:!0}),i.forEach(r),this.h()},h(){w(l,"alt","Open In Colab"),w(l,"class","!m-0"),Nn(l.src,t="https://colab.research.google.com/assets/colab-badge.svg")||w(l,"src",t),w(e,"href",o[2][0].value),w(e,"target","_blank")},m(s,i){g(s,e,i),a(e,l)},p:x,i:x,o:x,d(s){s&&r(e)}}}function Pd(o){let e,l;return{c(){e=c("img"),this.h()},l(t){e=m(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){w(e,"alt","Open In Colab"),w(e,"class","!m-0"),Nn(e.src,l="https://colab.research.google.com/assets/colab-badge.svg")||w(e,"src",l)},m(t,s){g(t,e,s)},d(t){t&&r(e)}}}function Nd(o){let e;const l=o[6].default,t=Fe(l,o,o[10],Ru),s=t||Pd();return{c(){s&&s.c()},l(i){s&&s.l(i)},m(i,f){s&&s.m(i,f),e=!0},p(i,f){t&&t.p&&(!e||f&1024)&&qe(t,l,i,i[10],e?We(l,i[10],f,Md):Oe(i[10]),Ru)},i(i){e||(E(s,i),e=!0)},o(i){T(s,i),e=!1},d(i){s&&s.d(i)}}}function Ju(o){let e,l;function t(){return o[7](o[12])}return e=new sd({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:o[11],onClick:t,useDeprecatedJS:!1}}),{c(){y(e.$$.fragment)},l(s){P(e.$$.fragment,s)},m(s,i){C(e,s,i),l=!0},p(s,i){o=s},i(s){l||(E(e.$$.fragment,s),l=!0)},o(s){T(e.$$.fragment,s),l=!1},d(s){D(e,s)}}}function Fd(o){let e,l,t=o[2],s=[];for(let f=0;f<t.length;f+=1)s[f]=Ju(Vu(o,t,f));const i=f=>T(s[f],1,1,()=>{s[f]=null});return{c(){for(let f=0;f<s.length;f+=1)s[f].c();e=ze()},l(f){for(let h=0;h<s.length;h+=1)s[h].l(f);e=ze()},m(f,h){for(let _=0;_<s.length;_+=1)s[_].m(f,h);g(f,e,h),l=!0},p(f,h){if(h&4){t=f[2];let _;for(_=0;_<t.length;_+=1){const $=Vu(f,t,_);s[_]?(s[_].p($,h),E(s[_],1)):(s[_]=Ju($),s[_].c(),E(s[_],1),s[_].m(e.parentNode,e))}for(Ae(),_=t.length;_<s.length;_+=1)i(_);Te()}},i(f){if(!l){for(let h=0;h<t.length;h+=1)E(s[h]);l=!0}},o(f){s=s.filter(Boolean);for(let h=0;h<s.length;h+=1)T(s[h]);l=!1},d(f){td(s,f),f&&r(e)}}}function qd(o){let e;const l=o[6].default,t=Fe(l,o,o[10],xu),s=t||Fd(o);return{c(){s&&s.c()},l(i){s&&s.l(i)},m(i,f){s&&s.m(i,f),e=!0},p(i,f){t&&t.p&&(!e||f&1024)&&qe(t,l,i,i[10],e?We(l,i[10],f,yd):Oe(i[10]),xu)},i(i){e||(E(s,i),e=!0)},o(i){T(s,i),e=!1},d(i){s&&s.d(i)}}}function Od(o){let e,l;return e=new nd({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[Hd],button:[Ld]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&1024&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Wd(o){let e,l,t;return{c(){e=c("a"),l=c("img"),this.h()},l(s){e=m(s,"A",{href:!0,target:!0});var i=p(e);l=m(i,"IMG",{alt:!0,class:!0,src:!0}),i.forEach(r),this.h()},h(){w(l,"alt","Open In Studio Lab"),w(l,"class","!m-0"),Nn(l.src,t="https://studiolab.sagemaker.aws/studiolab.svg")||w(l,"src",t),w(e,"href",o[3][0].value),w(e,"target","_blank")},m(s,i){g(s,e,i),a(e,l)},p:x,i:x,o:x,d(s){s&&r(e)}}}function Bd(o){let e,l;return{c(){e=c("img"),this.h()},l(t){e=m(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){w(e,"alt","Open In Studio Lab"),w(e,"class","!m-0"),Nn(e.src,l="https://studiolab.sagemaker.aws/studiolab.svg")||w(e,"src",l)},m(t,s){g(t,e,s)},d(t){t&&r(e)}}}function Ld(o){let e;const l=o[6].default,t=Fe(l,o,o[10],Ku),s=t||Bd();return{c(){s&&s.c()},l(i){s&&s.l(i)},m(i,f){s&&s.m(i,f),e=!0},p(i,f){t&&t.p&&(!e||f&1024)&&qe(t,l,i,i[10],e?We(l,i[10],f,Sd):Oe(i[10]),Ku)},i(i){e||(E(s,i),e=!0)},o(i){T(s,i),e=!1},d(i){s&&s.d(i)}}}function Zu(o){let e,l;function t(){return o[8](o[12])}return e=new sd({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:o[11],onClick:t,useDeprecatedJS:!1}}),{c(){y(e.$$.fragment)},l(s){P(e.$$.fragment,s)},m(s,i){C(e,s,i),l=!0},p(s,i){o=s},i(s){l||(E(e.$$.fragment,s),l=!0)},o(s){T(e.$$.fragment,s),l=!1},d(s){D(e,s)}}}function Kd(o){let e,l,t=o[3],s=[];for(let f=0;f<t.length;f+=1)s[f]=Zu(Hu(o,t,f));const i=f=>T(s[f],1,1,()=>{s[f]=null});return{c(){for(let f=0;f<s.length;f+=1)s[f].c();e=ze()},l(f){for(let h=0;h<s.length;h+=1)s[h].l(f);e=ze()},m(f,h){for(let _=0;_<s.length;_+=1)s[_].m(f,h);g(f,e,h),l=!0},p(f,h){if(h&8){t=f[3];let _;for(_=0;_<t.length;_+=1){const $=Hu(f,t,_);s[_]?(s[_].p($,h),E(s[_],1)):(s[_]=Zu($),s[_].c(),E(s[_],1),s[_].m(e.parentNode,e))}for(Ae(),_=t.length;_<s.length;_+=1)i(_);Te()}},i(f){if(!l){for(let h=0;h<t.length;h+=1)E(s[h]);l=!0}},o(f){s=s.filter(Boolean);for(let h=0;h<s.length;h+=1)T(s[h]);l=!1},d(f){td(s,f),f&&r(e)}}}function Hd(o){let e;const l=o[6].default,t=Fe(l,o,o[10],Uu),s=t||Kd(o);return{c(){s&&s.c()},l(i){s&&s.l(i)},m(i,f){s&&s.m(i,f),e=!0},p(i,f){t&&t.p&&(!e||f&1024)&&qe(t,l,i,i[10],e?We(l,i[10],f,jd):Oe(i[10]),Uu)},i(i){e||(E(s,i),e=!0)},o(i){T(s,i),e=!1},d(i){s&&s.d(i)}}}function Ud(o){let e,l,t,s,i,f,h,_,$,M,F;const q=o[6].alwaysVisible,j=Fe(q,o,o[10],Gu),I=[Id,Dd],A=[];function S(L,U){return L[2].length===1?0:L[2].length>1?1:-1}~(t=S(o))&&(s=A[t]=I[t](o));const z=[Wd,Od],N=[];function B(L,U){return L[3].length===1?0:L[3].length>1?1:-1}return~(f=B(o))&&(h=N[f]=z[f](o)),{c(){e=c("div"),j&&j.c(),l=k(),s&&s.c(),i=k(),h&&h.c(),this.h()},l(L){e=m(L,"DIV",{class:!0});var U=p(e);j&&j.l(U),l=v(U),s&&s.l(U),i=v(U),h&&h.l(U),U.forEach(r),this.h()},h(){w(e,"class",_="flex space-x-1 "+o[0])},m(L,U){g(L,e,U),j&&j.m(e,null),a(e,l),~t&&A[t].m(e,null),a(e,i),~f&&N[f].m(e,null),o[9](e),$=!0,M||(F=Dl(zd,"resize",o[4]),M=!0)},p(L,[U]){j&&j.p&&(!$||U&1024)&&qe(j,q,L,L[10],$?We(q,L[10],U,Cd):Oe(L[10]),Gu),s&&s.p(L,U),h&&h.p(L,U),(!$||U&1&&_!==(_="flex space-x-1 "+L[0]))&&w(e,"class",_)},i(L){$||(E(j,L),E(s),E(h),$=!0)},o(L){T(j,L),T(s),T(h),$=!1},d(L){L&&r(e),j&&j.d(L),~t&&A[t].d(),~f&&N[f].d(),o[9](null),M=!1,F()}}}function Yu(o){window.open(o)}function Rd(o,e,l){let{$$slots:t={},$$scope:s}=e,{options:i=[]}=e,{classNames:f=""}=e,h;const _=i.filter(I=>I.value.includes("colab.research.google.com")),$=i.filter(I=>I.value.includes("studiolab.sagemaker.aws"));function M(){const I=document.querySelector(".prose-doc h1"),A=document.querySelector(".prose-doc h1 > span");if(I&&A){const{width:S}=I.getBoundingClientRect(),{width:z}=A.getBoundingClientRect();let N=0;for(let L=0;L<h.children.length;L++)N+=h.children.item(L).clientWidth;const B=20;S-z<N+B?h.classList.remove("absolute"):h.classList.add("absolute")}}Ko(()=>{M()});const F=I=>Yu(I),q=I=>Yu(I);function j(I){Ho[I?"unshift":"push"](()=>{h=I,l(1,h)})}return o.$$set=I=>{"options"in I&&l(5,i=I.options),"classNames"in I&&l(0,f=I.classNames),"$$scope"in I&&l(10,s=I.$$scope)},[f,h,_,$,M,i,t,F,q,j,s]}class Vd extends sn{constructor(e){super();rn(this,e,Rd,Ud,ln,{options:5,classNames:0})}}function xd(o){let e,l;return{c(){e=c("p"),l=u(`Alle in der Dokumentation vorgestellten Codebeispiele haben oben links einen Umschalter f\xFCr PyTorch und TensorFlow. Wenn
nicht, wird erwartet, dass der Code f\xFCr beide Backends ohne \xC4nderungen funktioniert.`)},l(t){e=m(t,"P",{});var s=p(e);l=d(s,`Alle in der Dokumentation vorgestellten Codebeispiele haben oben links einen Umschalter f\xFCr PyTorch und TensorFlow. Wenn
nicht, wird erwartet, dass der Code f\xFCr beide Backends ohne \xC4nderungen funktioniert.`),s.forEach(r)},m(t,s){g(t,e,s),a(e,l)},d(t){t&&r(e)}}}function Gd(o){let e,l,t,s,i,f,h,_;return{c(){e=c("p"),l=u("F\xFCr mehr Details \xFCber die "),t=c("code"),s=u("pipeline()"),i=u(" und assoziierte Aufgaben, schauen Sie in die Dokumentation "),f=c("a"),h=u("hier"),_=u("."),this.h()},l($){e=m($,"P",{});var M=p(e);l=d(M,"F\xFCr mehr Details \xFCber die "),t=m(M,"CODE",{});var F=p(t);s=d(F,"pipeline()"),F.forEach(r),i=d(M," und assoziierte Aufgaben, schauen Sie in die Dokumentation "),f=m(M,"A",{href:!0});var q=p(f);h=d(q,"hier"),q.forEach(r),_=d(M,"."),M.forEach(r),this.h()},h(){w(f,"href","./main_classes/pipelines")},m($,M){g($,e,M),a(e,l),a(e,t),a(t,s),a(e,i),a(e,f),a(f,h),a(e,_)},d($){$&&r(e)}}}function Jd(o){let e,l;return e=new V({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p:x,i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Zd(o){let e,l;return e=new fe({props:{$$slots:{default:[Jd]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Yd(o){let e,l;return e=new V({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p:x,i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Qd(o){let e,l;return e=new fe({props:{$$slots:{default:[Yd]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Xd(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I;return j=new V({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=c("p"),l=u("Use the "),t=c("code"),s=u("AutoModelForSequenceClassification"),i=u(" and "),f=c("code"),h=u("AutoTokenizer"),_=u(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=c("code"),M=u("AutoClass"),F=u(" below):"),q=k(),y(j.$$.fragment)},l(A){e=m(A,"P",{});var S=p(e);l=d(S,"Use the "),t=m(S,"CODE",{});var z=p(t);s=d(z,"AutoModelForSequenceClassification"),z.forEach(r),i=d(S," and "),f=m(S,"CODE",{});var N=p(f);h=d(N,"AutoTokenizer"),N.forEach(r),_=d(S," to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=m(S,"CODE",{});var B=p($);M=d(B,"AutoClass"),B.forEach(r),F=d(S," below):"),S.forEach(r),q=v(A),P(j.$$.fragment,A)},m(A,S){g(A,e,S),a(e,l),a(e,t),a(t,s),a(e,i),a(e,f),a(f,h),a(e,_),a(e,$),a($,M),a(e,F),g(A,q,S),C(j,A,S),I=!0},p:x,i(A){I||(E(j.$$.fragment,A),I=!0)},o(A){T(j.$$.fragment,A),I=!1},d(A){A&&r(e),A&&r(q),D(j,A)}}}function ec(o){let e,l;return e=new fe({props:{$$slots:{default:[Xd]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function tc(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I;return j=new V({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=c("p"),l=u("Use the "),t=c("code"),s=u("TFAutoModelForSequenceClassification"),i=u(" and "),f=c("code"),h=u("AutoTokenizer"),_=u(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=c("code"),M=u("TFAutoClass"),F=u(" below):"),q=k(),y(j.$$.fragment)},l(A){e=m(A,"P",{});var S=p(e);l=d(S,"Use the "),t=m(S,"CODE",{});var z=p(t);s=d(z,"TFAutoModelForSequenceClassification"),z.forEach(r),i=d(S," and "),f=m(S,"CODE",{});var N=p(f);h=d(N,"AutoTokenizer"),N.forEach(r),_=d(S," to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=m(S,"CODE",{});var B=p($);M=d(B,"TFAutoClass"),B.forEach(r),F=d(S," below):"),S.forEach(r),q=v(A),P(j.$$.fragment,A)},m(A,S){g(A,e,S),a(e,l),a(e,t),a(t,s),a(e,i),a(e,f),a(f,h),a(e,_),a(e,$),a($,M),a(e,F),g(A,q,S),C(j,A,S),I=!0},p:x,i(A){I||(E(j.$$.fragment,A),I=!0)},o(A){T(j.$$.fragment,A),I=!1},d(A){A&&r(e),A&&r(q),D(j,A)}}}function nc(o){let e,l;return e=new fe({props:{$$slots:{default:[tc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function sc(o){let e,l;return e=new V({props:{code:`pt_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p:x,i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function rc(o){let e,l;return e=new fe({props:{$$slots:{default:[sc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function lc(o){let e,l;return e=new V({props:{code:`tf_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p:x,i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function ac(o){let e,l;return e=new fe({props:{$$slots:{default:[lc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function ic(o){let e,l,t,s,i;return{c(){e=c("p"),l=u("In der "),t=c("a"),s=u("Aufgabenzusammenfassung"),i=u(" steht, welche [AutoModel]-Klasse f\xFCr welche Aufgabe zu verwenden ist."),this.h()},l(f){e=m(f,"P",{});var h=p(e);l=d(h,"In der "),t=m(h,"A",{href:!0});var _=p(t);s=d(_,"Aufgabenzusammenfassung"),_.forEach(r),i=d(h," steht, welche [AutoModel]-Klasse f\xFCr welche Aufgabe zu verwenden ist."),h.forEach(r),this.h()},h(){w(t,"href","./task_summary")},m(f,h){g(f,e,h),a(e,l),a(e,t),a(t,s),a(e,i)},d(f){f&&r(e)}}}function oc(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I,A,S,z,N,B,L,U,K,se,Z,G,te,ne,Y,le,O,H,Q;return S=new V({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),N=new Pn({props:{$$slots:{default:[ic]},$$scope:{ctx:o}}}),te=new V({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),H=new V({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){e=c("p"),l=u("\u{1F917} Transformers bietet eine einfache und einheitliche M\xF6glichkeit, vortrainierte Instanzen zu laden. Das bedeutet, dass Sie ein "),t=c("code"),s=u("AutoModel"),i=u(" laden k\xF6nnen, wie Sie einen "),f=c("code"),h=u("AutoTokenizer"),_=u(" laden w\xFCrden. Der einzige Unterschied ist die Auswahl des richtigen "),$=c("code"),M=u("AutoModel"),F=u(" f\xFCr die Aufgabe. Da Sie eine Text- oder Sequenzklassifizierung vornehmen, laden Sie "),q=c("code"),j=u("AutoModelForSequenceClassification"),I=u(":"),A=k(),y(S.$$.fragment),z=k(),y(N.$$.fragment),B=k(),L=c("p"),U=u("Jetzt k\xF6nnen Sie Ihren vorverarbeiteten Stapel von Eingaben direkt an das Modell \xFCbergeben. Sie m\xFCssen nur das W\xF6rterbuch entpacken, indem Sie "),K=c("code"),se=u("**"),Z=u(" hinzuf\xFCgen:"),G=k(),y(te.$$.fragment),ne=k(),Y=c("p"),le=u("Das Modell gibt die endg\xFCltigen Aktivierungen in dem Attribut \u201Clogits\u201D aus. Wenden Sie die Softmax-Funktion auf die \u201Clogits\u201D an, um die Wahrscheinlichkeiten zu erhalten:"),O=k(),y(H.$$.fragment)},l(W){e=m(W,"P",{});var R=p(e);l=d(R,"\u{1F917} Transformers bietet eine einfache und einheitliche M\xF6glichkeit, vortrainierte Instanzen zu laden. Das bedeutet, dass Sie ein "),t=m(R,"CODE",{});var ce=p(t);s=d(ce,"AutoModel"),ce.forEach(r),i=d(R," laden k\xF6nnen, wie Sie einen "),f=m(R,"CODE",{});var pe=p(f);h=d(pe,"AutoTokenizer"),pe.forEach(r),_=d(R," laden w\xFCrden. Der einzige Unterschied ist die Auswahl des richtigen "),$=m(R,"CODE",{});var ue=p($);M=d(ue,"AutoModel"),ue.forEach(r),F=d(R," f\xFCr die Aufgabe. Da Sie eine Text- oder Sequenzklassifizierung vornehmen, laden Sie "),q=m(R,"CODE",{});var $t=p(q);j=d($t,"AutoModelForSequenceClassification"),$t.forEach(r),I=d(R,":"),R.forEach(r),A=v(W),P(S.$$.fragment,W),z=v(W),P(N.$$.fragment,W),B=v(W),L=m(W,"P",{});var de=p(L);U=d(de,"Jetzt k\xF6nnen Sie Ihren vorverarbeiteten Stapel von Eingaben direkt an das Modell \xFCbergeben. Sie m\xFCssen nur das W\xF6rterbuch entpacken, indem Sie "),K=m(de,"CODE",{});var an=p(K);se=d(an,"**"),an.forEach(r),Z=d(de," hinzuf\xFCgen:"),de.forEach(r),G=v(W),P(te.$$.fragment,W),ne=v(W),Y=m(W,"P",{});var Be=p(Y);le=d(Be,"Das Modell gibt die endg\xFCltigen Aktivierungen in dem Attribut \u201Clogits\u201D aus. Wenden Sie die Softmax-Funktion auf die \u201Clogits\u201D an, um die Wahrscheinlichkeiten zu erhalten:"),Be.forEach(r),O=v(W),P(H.$$.fragment,W)},m(W,R){g(W,e,R),a(e,l),a(e,t),a(t,s),a(e,i),a(e,f),a(f,h),a(e,_),a(e,$),a($,M),a(e,F),a(e,q),a(q,j),a(e,I),g(W,A,R),C(S,W,R),g(W,z,R),C(N,W,R),g(W,B,R),g(W,L,R),a(L,U),a(L,K),a(K,se),a(L,Z),g(W,G,R),C(te,W,R),g(W,ne,R),g(W,Y,R),a(Y,le),g(W,O,R),C(H,W,R),Q=!0},p(W,R){const ce={};R&2&&(ce.$$scope={dirty:R,ctx:W}),N.$set(ce)},i(W){Q||(E(S.$$.fragment,W),E(N.$$.fragment,W),E(te.$$.fragment,W),E(H.$$.fragment,W),Q=!0)},o(W){T(S.$$.fragment,W),T(N.$$.fragment,W),T(te.$$.fragment,W),T(H.$$.fragment,W),Q=!1},d(W){W&&r(e),W&&r(A),D(S,W),W&&r(z),D(N,W),W&&r(B),W&&r(L),W&&r(G),D(te,W),W&&r(ne),W&&r(Y),W&&r(O),D(H,W)}}}function fc(o){let e,l;return e=new fe({props:{$$slots:{default:[oc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function uc(o){let e,l,t,s,i;return{c(){e=c("p"),l=u("In der "),t=c("a"),s=u("Aufgabenzusammenfassung"),i=u(" steht, welche [AutoModel]-Klasse f\xFCr welche Aufgabe zu verwenden ist."),this.h()},l(f){e=m(f,"P",{});var h=p(e);l=d(h,"In der "),t=m(h,"A",{href:!0});var _=p(t);s=d(_,"Aufgabenzusammenfassung"),_.forEach(r),i=d(h," steht, welche [AutoModel]-Klasse f\xFCr welche Aufgabe zu verwenden ist."),h.forEach(r),this.h()},h(){w(t,"href","./task_summary")},m(f,h){g(f,e,h),a(e,l),a(e,t),a(t,s),a(e,i)},d(f){f&&r(e)}}}function dc(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I,A,S,z,N,B,L,U,K,se,Z,G,te,ne,Y,le;return S=new V({props:{code:`from transformers import TFAutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`}}),N=new Pn({props:{$$slots:{default:[uc]},$$scope:{ctx:o}}}),se=new V({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),Y=new V({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){e=c("p"),l=u("\u{1F917} Transformers bietet eine einfache und einheitliche Methode zum Laden von vortrainierten Instanzen. Das bedeutet, dass Sie ein "),t=c("code"),s=u("TFAutoModel"),i=u(" genauso laden k\xF6nnen, wie Sie einen "),f=c("code"),h=u("AutoTokenizer"),_=u(" laden w\xFCrden. Der einzige Unterschied ist die Auswahl des richtigen "),$=c("code"),M=u("TFAutoModel"),F=u(" f\xFCr die Aufgabe. Da Sie Text - oder Sequenz - Klassifizierung machen, laden Sie "),q=c("code"),j=u("TFAutoModelForSequenceClassification"),I=u(":"),A=k(),y(S.$$.fragment),z=k(),y(N.$$.fragment),B=k(),L=c("p"),U=u("Jetzt k\xF6nnen Sie Ihren vorverarbeiteten Stapel von Eingaben direkt an das Modell \xFCbergeben, indem Sie die W\xF6rterbuchschl\xFCssel direkt an die Tensoren \xFCbergeben:"),K=k(),y(se.$$.fragment),Z=k(),G=c("p"),te=u("Das Modell gibt die endg\xFCltigen Aktivierungen in dem Attribut \u201Clogits\u201D aus. Wenden Sie die Softmax-Funktion auf die \u201Clogits\u201D an, um die Wahrscheinlichkeiten zu erhalten:"),ne=k(),y(Y.$$.fragment)},l(O){e=m(O,"P",{});var H=p(e);l=d(H,"\u{1F917} Transformers bietet eine einfache und einheitliche Methode zum Laden von vortrainierten Instanzen. Das bedeutet, dass Sie ein "),t=m(H,"CODE",{});var Q=p(t);s=d(Q,"TFAutoModel"),Q.forEach(r),i=d(H," genauso laden k\xF6nnen, wie Sie einen "),f=m(H,"CODE",{});var W=p(f);h=d(W,"AutoTokenizer"),W.forEach(r),_=d(H," laden w\xFCrden. Der einzige Unterschied ist die Auswahl des richtigen "),$=m(H,"CODE",{});var R=p($);M=d(R,"TFAutoModel"),R.forEach(r),F=d(H," f\xFCr die Aufgabe. Da Sie Text - oder Sequenz - Klassifizierung machen, laden Sie "),q=m(H,"CODE",{});var ce=p(q);j=d(ce,"TFAutoModelForSequenceClassification"),ce.forEach(r),I=d(H,":"),H.forEach(r),A=v(O),P(S.$$.fragment,O),z=v(O),P(N.$$.fragment,O),B=v(O),L=m(O,"P",{});var pe=p(L);U=d(pe,"Jetzt k\xF6nnen Sie Ihren vorverarbeiteten Stapel von Eingaben direkt an das Modell \xFCbergeben, indem Sie die W\xF6rterbuchschl\xFCssel direkt an die Tensoren \xFCbergeben:"),pe.forEach(r),K=v(O),P(se.$$.fragment,O),Z=v(O),G=m(O,"P",{});var ue=p(G);te=d(ue,"Das Modell gibt die endg\xFCltigen Aktivierungen in dem Attribut \u201Clogits\u201D aus. Wenden Sie die Softmax-Funktion auf die \u201Clogits\u201D an, um die Wahrscheinlichkeiten zu erhalten:"),ue.forEach(r),ne=v(O),P(Y.$$.fragment,O)},m(O,H){g(O,e,H),a(e,l),a(e,t),a(t,s),a(e,i),a(e,f),a(f,h),a(e,_),a(e,$),a($,M),a(e,F),a(e,q),a(q,j),a(e,I),g(O,A,H),C(S,O,H),g(O,z,H),C(N,O,H),g(O,B,H),g(O,L,H),a(L,U),g(O,K,H),C(se,O,H),g(O,Z,H),g(O,G,H),a(G,te),g(O,ne,H),C(Y,O,H),le=!0},p(O,H){const Q={};H&2&&(Q.$$scope={dirty:H,ctx:O}),N.$set(Q)},i(O){le||(E(S.$$.fragment,O),E(N.$$.fragment,O),E(se.$$.fragment,O),E(Y.$$.fragment,O),le=!0)},o(O){T(S.$$.fragment,O),T(N.$$.fragment,O),T(se.$$.fragment,O),T(Y.$$.fragment,O),le=!1},d(O){O&&r(e),O&&r(A),D(S,O),O&&r(z),D(N,O),O&&r(B),O&&r(L),O&&r(K),D(se,O),O&&r(Z),O&&r(G),O&&r(ne),D(Y,O)}}}function cc(o){let e,l;return e=new fe({props:{$$slots:{default:[dc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function mc(o){let e,l,t,s,i;return{c(){e=c("p"),l=u("Alle \u{1F917} Transformers-Modelle (PyTorch oder TensorFlow) geben die Tensoren "),t=c("em"),s=u("vor"),i=u(` der endg\xFCltigen Aktivierungsfunktion
Funktion (wie Softmax) aus, da die endg\xFCltige Aktivierungsfunktion oft mit dem Verlusten verschmolzen ist.`)},l(f){e=m(f,"P",{});var h=p(e);l=d(h,"Alle \u{1F917} Transformers-Modelle (PyTorch oder TensorFlow) geben die Tensoren "),t=m(h,"EM",{});var _=p(t);s=d(_,"vor"),_.forEach(r),i=d(h,` der endg\xFCltigen Aktivierungsfunktion
Funktion (wie Softmax) aus, da die endg\xFCltige Aktivierungsfunktion oft mit dem Verlusten verschmolzen ist.`),h.forEach(r)},m(f,h){g(f,e,h),a(e,l),a(e,t),a(t,s),a(e,i)},d(f){f&&r(e)}}}function pc(o){let e,l;return{c(){e=c("p"),l=u(`Transformers-Modellausgaben sind spezielle Datenklassen, so dass ihre Attribute in einer IDE automatisch vervollst\xE4ndigt werden.
Die Modellausg\xE4nge verhalten sich auch wie ein Tupel oder ein W\xF6rterbuch (z.B. k\xF6nnen Sie mit einem Integer, einem Slice oder einem String indexieren), wobei die Attribute, die \u201CNone\u201D sind, ignoriert werden.`)},l(t){e=m(t,"P",{});var s=p(e);l=d(s,`Transformers-Modellausgaben sind spezielle Datenklassen, so dass ihre Attribute in einer IDE automatisch vervollst\xE4ndigt werden.
Die Modellausg\xE4nge verhalten sich auch wie ein Tupel oder ein W\xF6rterbuch (z.B. k\xF6nnen Sie mit einem Integer, einem Slice oder einem String indexieren), wobei die Attribute, die \u201CNone\u201D sind, ignoriert werden.`),s.forEach(r)},m(t,s){g(t,e,s),a(e,l)},d(t){t&&r(e)}}}function hc(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I,A,S;return h=new V({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),A=new V({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){e=c("p"),l=u("Sobald Ihr Modell feinabgestimmt ist, k\xF6nnen Sie es mit seinem Tokenizer speichern, indem Sie "),t=c("code"),s=u("PreTrainedModel.save_pretrained()"),i=u(" verwenden:"),f=k(),y(h.$$.fragment),_=k(),$=c("p"),M=u("Wenn Sie bereit sind, das Modell erneut zu verwenden, laden Sie es mit "),F=c("code"),q=u("PreTrainedModel.from_pretrained()"),j=u(":"),I=k(),y(A.$$.fragment)},l(z){e=m(z,"P",{});var N=p(e);l=d(N,"Sobald Ihr Modell feinabgestimmt ist, k\xF6nnen Sie es mit seinem Tokenizer speichern, indem Sie "),t=m(N,"CODE",{});var B=p(t);s=d(B,"PreTrainedModel.save_pretrained()"),B.forEach(r),i=d(N," verwenden:"),N.forEach(r),f=v(z),P(h.$$.fragment,z),_=v(z),$=m(z,"P",{});var L=p($);M=d(L,"Wenn Sie bereit sind, das Modell erneut zu verwenden, laden Sie es mit "),F=m(L,"CODE",{});var U=p(F);q=d(U,"PreTrainedModel.from_pretrained()"),U.forEach(r),j=d(L,":"),L.forEach(r),I=v(z),P(A.$$.fragment,z)},m(z,N){g(z,e,N),a(e,l),a(e,t),a(t,s),a(e,i),g(z,f,N),C(h,z,N),g(z,_,N),g(z,$,N),a($,M),a($,F),a(F,q),a($,j),g(z,I,N),C(A,z,N),S=!0},p:x,i(z){S||(E(h.$$.fragment,z),E(A.$$.fragment,z),S=!0)},o(z){T(h.$$.fragment,z),T(A.$$.fragment,z),S=!1},d(z){z&&r(e),z&&r(f),D(h,z),z&&r(_),z&&r($),z&&r(I),D(A,z)}}}function gc(o){let e,l;return e=new fe({props:{$$slots:{default:[hc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function _c(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I,A,S;return h=new V({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),A=new V({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){e=c("p"),l=u("Sobald Ihr Modell feinabgestimmt ist, k\xF6nnen Sie es mit seinem Tokenizer unter Verwendung von "),t=c("code"),s=u("TFPreTrainedModel.save_pretrained()"),i=u(" speichern:"),f=k(),y(h.$$.fragment),_=k(),$=c("p"),M=u("Wenn Sie bereit sind, das Modell wieder zu verwenden, laden Sie es mit "),F=c("code"),q=u("TFPreTrainedModel.from_pretrained()"),j=u(":"),I=k(),y(A.$$.fragment)},l(z){e=m(z,"P",{});var N=p(e);l=d(N,"Sobald Ihr Modell feinabgestimmt ist, k\xF6nnen Sie es mit seinem Tokenizer unter Verwendung von "),t=m(N,"CODE",{});var B=p(t);s=d(B,"TFPreTrainedModel.save_pretrained()"),B.forEach(r),i=d(N," speichern:"),N.forEach(r),f=v(z),P(h.$$.fragment,z),_=v(z),$=m(z,"P",{});var L=p($);M=d(L,"Wenn Sie bereit sind, das Modell wieder zu verwenden, laden Sie es mit "),F=m(L,"CODE",{});var U=p(F);q=d(U,"TFPreTrainedModel.from_pretrained()"),U.forEach(r),j=d(L,":"),L.forEach(r),I=v(z),P(A.$$.fragment,z)},m(z,N){g(z,e,N),a(e,l),a(e,t),a(t,s),a(e,i),g(z,f,N),C(h,z,N),g(z,_,N),g(z,$,N),a($,M),a($,F),a(F,q),a($,j),g(z,I,N),C(A,z,N),S=!0},p:x,i(z){S||(E(h.$$.fragment,z),E(A.$$.fragment,z),S=!0)},o(z){T(h.$$.fragment,z),T(A.$$.fragment,z),S=!1},d(z){z&&r(e),z&&r(f),D(h,z),z&&r(_),z&&r($),z&&r(I),D(A,z)}}}function bc(o){let e,l;return e=new fe({props:{$$slots:{default:[_c]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function $c(o){let e,l;return e=new V({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p:x,i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function wc(o){let e,l;return e=new fe({props:{$$slots:{default:[$c]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function kc(o){let e,l;return e=new V({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p:x,i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function vc(o){let e,l;return e=new fe({props:{$$slots:{default:[kc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Ec(o){let e,l,t,s,i,f,h,_;return h=new V({props:{code:`from transformers import AutoModel

my_model = AutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = AutoModel.from_config(my_config)`}}),{c(){e=c("p"),l=u("Create a model from your custom configuration with "),t=c("code"),s=u("AutoModel.from_config()"),i=u(":"),f=k(),y(h.$$.fragment)},l($){e=m($,"P",{});var M=p(e);l=d(M,"Create a model from your custom configuration with "),t=m(M,"CODE",{});var F=p(t);s=d(F,"AutoModel.from_config()"),F.forEach(r),i=d(M,":"),M.forEach(r),f=v($),P(h.$$.fragment,$)},m($,M){g($,e,M),a(e,l),a(e,t),a(t,s),a(e,i),g($,f,M),C(h,$,M),_=!0},p:x,i($){_||(E(h.$$.fragment,$),_=!0)},o($){T(h.$$.fragment,$),_=!1},d($){$&&r(e),$&&r(f),D(h,$)}}}function Ac(o){let e,l;return e=new fe({props:{$$slots:{default:[Ec]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Tc(o){let e,l,t,s,i,f,h,_;return h=new V({props:{code:`from transformers import TFAutoModel

my_model = TFAutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = TFAutoModel.from_config(my_config)`}}),{c(){e=c("p"),l=u("Create a model from your custom configuration with "),t=c("code"),s=u("TFAutoModel.from_config()"),i=u(":"),f=k(),y(h.$$.fragment)},l($){e=m($,"P",{});var M=p(e);l=d(M,"Create a model from your custom configuration with "),t=m(M,"CODE",{});var F=p(t);s=d(F,"TFAutoModel.from_config()"),F.forEach(r),i=d(M,":"),M.forEach(r),f=v($),P(h.$$.fragment,$)},m($,M){g($,e,M),a(e,l),a(e,t),a(t,s),a(e,i),g($,f,M),C(h,$,M),_=!0},p:x,i($){_||(E(h.$$.fragment,$),_=!0)},o($){T(h.$$.fragment,$),_=!1},d($){$&&r(e),$&&r(f),D(h,$)}}}function zc(o){let e,l;return e=new fe({props:{$$slots:{default:[Tc]},$$scope:{ctx:o}}}),{c(){y(e.$$.fragment)},l(t){P(e.$$.fragment,t)},m(t,s){C(e,t,s),l=!0},p(t,s){const i={};s&2&&(i.$$scope={dirty:s,ctx:t}),e.$set(i)},i(t){l||(E(e.$$.fragment,t),l=!0)},o(t){T(e.$$.fragment,t),l=!1},d(t){D(e,t)}}}function Sc(o){let e,l,t,s,i,f,h,_,$,M,F,q,j,I,A,S,z,N,B,L,U,K,se,Z,G,te,ne,Y,le,O,H,Q,W,R,ce,pe,ue,$t,de,an,Be,Il,Pl,Zs,wt,Fn,Nl,Fl,Ys,J,qn,ql,Ol,On,Wl,Bl,Wn,Ll,Kl,Bn,Hl,Ul,Ln,Rl,Vl,Kn,xl,Gl,Hn,Jl,Zl,Un,Yl,Qs,kt,Rn,Ql,Xl,Xs,he,Vn,ea,ta,xn,na,sa,Gn,ra,er,vt,Jn,la,aa,tr,Le,Zn,ia,oa,Yn,fa,nr,Ke,sr,Se,He,Qn,Et,ua,Xn,da,rr,Ue,ca,es,ma,pa,lr,on,ha,ar,Re,ir,Ve,ga,ts,_a,ba,or,At,fr,xe,$a,Tt,wa,ka,ur,zt,dr,Ge,va,ns,Ea,Aa,cr,St,mr,ge,Ta,ss,za,Sa,jt,ja,Ma,pr,Mt,hr,Je,ya,rs,Ca,Da,gr,yt,_r,_e,Ia,Ct,Pa,Na,Dt,Fa,qa,br,It,$r,Ze,Oa,ls,Wa,Ba,wr,Pt,kr,fn,La,vr,Nt,Er,Ye,Ka,un,Ha,Ua,Ar,je,Qe,as,Ft,Ra,is,Va,Tr,ae,xa,os,Ga,Ja,qt,Za,Ya,fs,Qa,Xa,Ot,ei,ti,zr,Wt,Sr,Xe,jr,be,ni,us,si,ri,ds,li,ai,Mr,Bt,yr,$e,ii,dn,oi,fi,cn,ui,di,Cr,Me,et,cs,Lt,ci,ms,mi,Dr,Kt,Ir,X,pi,ps,hi,gi,hs,_i,bi,gs,$i,wi,mn,_s,ki,vi,bs,Ei,Ai,$s,Ti,zi,Pr,we,Si,ws,ji,Mi,ks,yi,Ci,Nr,ye,tt,vs,Ht,Di,Es,Ii,Fr,me,Pi,As,Ni,Fi,pn,qi,Oi,Ts,Wi,Bi,qr,Ut,Or,nt,Li,zs,Ki,Hi,Wr,hn,Ui,Br,Rt,Lr,gn,Ri,Kr,st,_n,bn,Vi,xi,Gi,$n,wn,Ji,Zi,Hr,rt,Yi,Ss,Qi,Xi,Ur,lt,Rr,at,eo,kn,to,no,Vr,Ce,it,js,Vt,so,Ms,ro,xr,ot,Gr,ft,Jr,ee,lo,xt,ys,ao,io,Gt,Cs,oo,fo,Ds,uo,co,Is,mo,po,Jt,ho,go,vn,_o,bo,Zr,ut,Yr,De,dt,Ps,Zt,$o,Ns,wo,Qr,ct,Xr,En,ko,el,mt,tl,Ie,pt,Fs,Yt,vo,qs,Eo,nl,An,Ao,sl,ke,To,Os,zo,So,Ws,jo,Mo,rl,Qt,ll,ht,al,gt,yo,Tn,Co,Do,il,Pe,_t,Bs,Xt,Io,Ls,Po,ol,zn,No,fl;return f=new Ee({}),F=new Vd({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/de/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/de/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/de/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/de/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/de/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/de/tensorflow/quicktour.ipynb"}]}}),K=new Pn({props:{$$slots:{default:[xd]},$$scope:{ctx:o}}}),ne=new Ee({}),ue=new Nu({props:{id:"tiZFewofSLM"}}),Ke=new Pn({props:{$$slots:{default:[Gd]},$$scope:{ctx:o}}}),Et=new Ee({}),Re=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Qd],pytorch:[Zd]},$$scope:{ctx:o}}}),At=new V({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`}}),zt=new V({props:{code:'classifier("We are very happy to show you the \u{1F917} Transformers library.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`}}),St=new V({props:{code:`results = classifier(["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`}}),Mt=new V({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),yt=new V({props:{code:`import torch
from transformers import pipeline

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),It=new V({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Pt=new V({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))'}}),Nt=new V({props:{code:`result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FODING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I THURN A JOIN A COUNT&#x27;</span>]`}}),Ft=new Ee({}),Wt=new V({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),Xe=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[nc],pytorch:[ec]},$$scope:{ctx:o}}}),Bt=new V({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Lt=new Ee({}),Kt=new Nu({props:{id:"AhChOFRegn4"}}),Ht=new Ee({}),Ut=new V({props:{code:`from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),Rt=new V({props:{code:`encoding = tokenizer("We are very happy to show you the \u{1F917} Transformers library.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),lt=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ac],pytorch:[rc]},$$scope:{ctx:o}}}),Vt=new Ee({}),ot=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[cc],pytorch:[fc]},$$scope:{ctx:o}}}),ft=new Pn({props:{$$slots:{default:[mc]},$$scope:{ctx:o}}}),ut=new Pn({props:{$$slots:{default:[pc]},$$scope:{ctx:o}}}),Zt=new Ee({}),ct=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[bc],pytorch:[gc]},$$scope:{ctx:o}}}),mt=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[vc],pytorch:[wc]},$$scope:{ctx:o}}}),Yt=new Ee({}),Qt=new V({props:{code:`from transformers import AutoConfig

my_config = AutoConfig.from_pretrained("distilbert-base-uncased", n_heads=12)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, n_heads=<span class="hljs-number">12</span>)`}}),ht=new nn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[zc],pytorch:[Ac]},$$scope:{ctx:o}}}),Xt=new Ee({}),{c(){e=c("meta"),l=k(),t=c("h1"),s=c("a"),i=c("span"),y(f.$$.fragment),h=k(),_=c("span"),$=u("Schnellstart"),M=k(),y(F.$$.fragment),q=k(),j=c("p"),I=u("Mit \u{1F917} Transformers k\xF6nnen Sie sofort loslegen! Verwenden Sie die "),A=c("code"),S=u("pipeline()"),z=u(" f\xFCr schnelle Inferenz und laden Sie schnell ein vortrainiertes Modell und einen Tokenizer mit einer "),N=c("a"),B=u("AutoClass"),L=u(", um Ihre Text-, Bild- oder Audioaufgabe zu l\xF6sen."),U=k(),y(K.$$.fragment),se=k(),Z=c("h2"),G=c("a"),te=c("span"),y(ne.$$.fragment),Y=k(),le=c("span"),O=u("Pipeline"),H=k(),Q=c("p"),W=c("code"),R=u("pipeline()"),ce=u(" ist der einfachste Weg, ein vortrainiertes Modell f\xFCr eine bestimmte Aufgabe zu verwenden."),pe=k(),y(ue.$$.fragment),$t=k(),de=c("p"),an=u("Die "),Be=c("code"),Il=u("pipeline()"),Pl=u(" unterst\xFCtzt viele g\xE4ngige Aufgaben:"),Zs=k(),wt=c("p"),Fn=c("strong"),Nl=u("Text"),Fl=u(":"),Ys=k(),J=c("ul"),qn=c("li"),ql=u("Stimmungsanalyse: Klassifizierung der Polarit\xE4t eines gegebenen Textes."),Ol=k(),On=c("li"),Wl=u("Textgenerierung (auf Englisch): Generierung von Text aus einer gegebenen Eingabe."),Bl=k(),Wn=c("li"),Ll=u("Name-Entity-Recognition (NER): Kennzeichnung jedes Worts mit der Entit\xE4t, die es repr\xE4sentiert (Person, Datum, Ort usw.)."),Kl=k(),Bn=c("li"),Hl=u("Beantwortung von Fragen: Extrahieren der Antwort aus dem Kontext, wenn ein gewisser Kontext und eine Frage gegeben sind."),Ul=k(),Ln=c("li"),Rl=u("Fill-mask: Ausf\xFCllen von L\xFCcken in einem Text mit maskierten W\xF6rtern."),Vl=k(),Kn=c("li"),xl=u("Zusammenfassung: Erstellung einer Zusammenfassung einer langen Text- oder Dokumentensequenz."),Gl=k(),Hn=c("li"),Jl=u("\xDCbersetzung: \xDCbersetzen eines Textes in eine andere Sprache."),Zl=k(),Un=c("li"),Yl=u("Merkmalsextraktion: Erstellen einer Tensordarstellung des Textes."),Qs=k(),kt=c("p"),Rn=c("strong"),Ql=u("Bild"),Xl=u(":"),Xs=k(),he=c("ul"),Vn=c("li"),ea=u("Bildklassifizierung: Klassifizierung eines Bildes."),ta=k(),xn=c("li"),na=u("Bildsegmentierung: Klassifizierung jedes Pixels in einem Bild."),sa=k(),Gn=c("li"),ra=u("Objekterkennung: Erkennen von Objekten innerhalb eines Bildes."),er=k(),vt=c("p"),Jn=c("strong"),la=u("Audio"),aa=u(":"),tr=k(),Le=c("ul"),Zn=c("li"),ia=u("Audioklassifizierung: Zuweisung eines Labels zu einem bestimmten Audiosegment."),oa=k(),Yn=c("li"),fa=u("Automatische Spracherkennung (ASR): Transkription von Audiodaten in Text."),nr=k(),y(Ke.$$.fragment),sr=k(),Se=c("h3"),He=c("a"),Qn=c("span"),y(Et.$$.fragment),ua=k(),Xn=c("span"),da=u("Verwendung der Pipeline"),rr=k(),Ue=c("p"),ca=u("Im folgenden Beispiel werden Sie die "),es=c("code"),ma=u("pipeline()"),pa=u(" f\xFCr die Stimmungsanalyse verwenden."),lr=k(),on=c("p"),ha=u("Installieren Sie die folgenden Abh\xE4ngigkeiten, falls Sie dies nicht bereits getan haben:"),ar=k(),y(Re.$$.fragment),ir=k(),Ve=c("p"),ga=u("Importieren sie die "),ts=c("code"),_a=u("pipeline()"),ba=u(" und spezifizieren sie die Aufgabe, welche sie l\xF6sen m\xF6chten:"),or=k(),y(At.$$.fragment),fr=k(),xe=c("p"),$a=u("Die Pipeline l\xE4dt ein standardm\xE4\xDFiges [vortrainiertes Modell] ("),Tt=c("a"),wa=u("https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),ka=u(") und einen Tokenizer f\xFCr die Stimmungs-Analyse herunter und speichert sie. Jetzt k\xF6nnen Sie den \u201CKlassifikator\u201D auf Ihren Zieltext anwenden:"),ur=k(),y(zt.$$.fragment),dr=k(),Ge=c("p"),va=u("For more than one sentence, pass a list of sentences to the "),ns=c("code"),Ea=u("pipeline()"),Aa=u(" which returns a list of dictionaries:"),cr=k(),y(St.$$.fragment),mr=k(),ge=c("p"),Ta=u("Die "),ss=c("code"),za=u("pipeline()"),Sa=u(" kann auch \xFCber einen ganzen Datensatz iterieren. Starten wir mit der Installation der "),jt=c("a"),ja=u("\u{1F917} Datasets"),Ma=u(" Bibliothek:"),pr=k(),y(Mt.$$.fragment),hr=k(),Je=c("p"),ya=u("Erstellen wir eine "),rs=c("code"),Ca=u("pipeline()"),Da=u(" mit der Aufgabe die wir l\xF6sen und dem Modell welches wir nutzen m\xF6chten."),gr=k(),y(yt.$$.fragment),_r=k(),_e=c("p"),Ia=u("Als n\xE4chstes laden wir den Datensatz (siehe \u{1F917} Datasets "),Ct=c("a"),Pa=u("Quick Start"),Na=u(" f\xFCr mehr Details) welches wir nutzen m\xF6chten. Zum Beispiel laden wir den "),Dt=c("a"),Fa=u("MInDS-14"),qa=u(" Datensatz:"),br=k(),y(It.$$.fragment),$r=k(),Ze=c("p"),Oa=u("Wir m\xFCssen sicherstellen, dass die Abtastrate des Datensatzes der Abtastrate entspricht, mit der "),ls=c("code"),Wa=u("facebook/wav2vec2-base-960h"),Ba=u(" trainiert wurde."),wr=k(),y(Pt.$$.fragment),kr=k(),fn=c("p"),La=u(`Audiodateien werden automatisch geladen und neu abgetastet, wenn die Spalte \u201Caudio\u201D aufgerufen wird.
Extrahieren wir die rohen Wellenform-Arrays der ersten 4 Beispiele und \xFCbergeben wir sie als Liste an die Pipeline:`),vr=k(),y(Nt.$$.fragment),Er=k(),Ye=c("p"),Ka=u("Bei einem gr\xF6\xDFeren Datensatz mit vielen Eingaben (wie bei Sprache oder Bildverarbeitung) sollten Sie einen Generator anstelle einer Liste \xFCbergeben, der alle Eingaben in den Speicher l\xE4dt. Weitere Informationen finden Sie in der "),un=c("a"),Ha=u("Pipeline-Dokumentation"),Ua=u("."),Ar=k(),je=c("h3"),Qe=c("a"),as=c("span"),y(Ft.$$.fragment),Ra=k(),is=c("span"),Va=u("Ein anderes Modell und einen anderen Tokenizer in der Pipeline verwenden"),Tr=k(),ae=c("p"),xa=u("Die "),os=c("code"),Ga=u("pipeline()"),Ja=u(" kann jedes Modell aus dem [Model Hub] ("),qt=c("a"),Za=u("https://huggingface.co/models"),Ya=u(") verwenden, wodurch es einfach ist, die "),fs=c("code"),Qa=u("pipeline()"),Xa=u(" f\xFCr andere Anwendungsf\xE4lle anzupassen. Wenn Sie beispielsweise ein Modell w\xFCnschen, das franz\xF6sischen Text verarbeiten kann, verwenden Sie die Tags im Model Hub, um nach einem geeigneten Modell zu filtern. Das oberste gefilterte Ergebnis liefert ein mehrsprachiges "),Ot=c("a"),ei=u("BERT-Modell"),ti=u(", das auf die Stimmungsanalyse abgestimmt ist. Gro\xDFartig, verwenden wir dieses Modell!"),zr=k(),y(Wt.$$.fragment),Sr=k(),y(Xe.$$.fragment),jr=k(),be=c("p"),ni=u("Dann k\xF6nnen Sie das Modell und den Tokenizer in der "),us=c("code"),si=u("pipeline()"),ri=u(" angeben und den "),ds=c("code"),li=u("Klassifikator"),ai=u(" auf Ihren Zieltext anwenden:"),Mr=k(),y(Bt.$$.fragment),yr=k(),$e=c("p"),ii=u("Wenn Sie kein Modell f\xFCr Ihren Anwendungsfall finden k\xF6nnen, m\xFCssen Sie ein vortrainiertes Modell auf Ihren Daten feinabstimmen. Schauen Sie sich unser "),dn=c("a"),oi=u("Feinabstimmungs-Tutorial"),fi=u(" an, um zu erfahren, wie das geht. Und schlie\xDFlich, nachdem Sie Ihr trainiertes Modell verfeinert haben, sollten Sie es mit der Community im Model Hub teilen (siehe Tutorial "),cn=c("a"),ui=u("hier"),di=u("), um NLP f\xFCr alle zu demokratisieren! \u{1F917}"),Cr=k(),Me=c("h2"),et=c("a"),cs=c("span"),y(Lt.$$.fragment),ci=k(),ms=c("span"),mi=u("AutoClass"),Dr=k(),y(Kt.$$.fragment),Ir=k(),X=c("p"),pi=u("Unter der Haube arbeiten die Klassen "),ps=c("code"),hi=u("AutoModelForSequenceClassification"),gi=u(" und "),hs=c("code"),_i=u("AutoTokenizer"),bi=u(" zusammen, um die "),gs=c("code"),$i=u("pipeline()"),wi=u(" zu betreiben. Eine "),mn=c("a"),_s=c("code"),ki=u("AutoClass"),vi=u(" ist eine Abk\xFCrzung, die automatisch die Architektur eines trainierten Modells aus dessen Namen oder Pfad abruft. Sie m\xFCssen nur die passende "),bs=c("code"),Ei=u("AutoClass"),Ai=u(" f\xFCr Ihre Aufgabe und den zugeh\xF6rigen Tokenizer mit "),$s=c("code"),Ti=u("AutoTokenizer"),zi=u(" ausw\xE4hlen."),Pr=k(),we=c("p"),Si=u("Kehren wir zu unserem Beispiel zur\xFCck und sehen wir uns an, wie Sie die "),ws=c("code"),ji=u("AutoClass"),Mi=u(" verwenden k\xF6nnen, um die Ergebnisse der "),ks=c("code"),yi=u("pipeline()"),Ci=u(" zu replizieren."),Nr=k(),ye=c("h3"),tt=c("a"),vs=c("span"),y(Ht.$$.fragment),Di=k(),Es=c("span"),Ii=u("AutoTokenizer"),Fr=k(),me=c("p"),Pi=u("Ein Tokenizer ist f\xFCr die Vorverarbeitung von Text in ein f\xFCr das Modell verst\xE4ndliches Format zust\xE4ndig. Zun\xE4chst zerlegt der Tokenisierer den Text in W\xF6rter, die "),As=c("em"),Ni=u("Token"),Fi=u(" genannt werden. Es gibt mehrere Regeln f\xFCr den Tokenisierungsprozess, z. B. wie und auf welcher Ebene ein Wort aufgespalten wird (weitere Informationen \xFCber Tokenisierung "),pn=c("a"),qi=u("hier"),Oi=u(`). Das Wichtigste ist jedoch, dass Sie den Tokenizer mit demselben Modellnamen instanziieren m\xFCssen, um sicherzustellen, dass Sie dieselben Tokenisierungsregeln verwenden, mit denen ein Modell zuvor trainiert wurde.
Laden sie einen Tokenizer mit `),Ts=c("code"),Wi=u("AutoTokenizer"),Bi=u(":"),qr=k(),y(Ut.$$.fragment),Or=k(),nt=c("p"),Li=u("Anschlie\xDFend wandelt der Tokenizer die Token in Zahlen um, um einen Tensor als Eingabe f\xFCr das Modell zu konstruieren. Dieser wird als "),zs=c("em"),Ki=u("Vokabular"),Hi=u(" des Modells bezeichnet."),Wr=k(),hn=c("p"),Ui=u("\xDCbergeben Sie Ihren Text an den Tokenizer:"),Br=k(),y(Rt.$$.fragment),Lr=k(),gn=c("p"),Ri=u("Der Tokenizer gibt ein W\xF6rterbuch zur\xFCck, das Folgendes enth\xE4lt:"),Kr=k(),st=c("ul"),_n=c("li"),bn=c("a"),Vi=u("input_ids"),xi=u(": numerische Repr\xE4sentationen Ihrer Token."),Gi=k(),$n=c("li"),wn=c("a"),Ji=u("atttention_mask"),Zi=u(": gibt an, welche Token beachtet werden sollen."),Hr=k(),rt=c("p"),Yi=u("Genau wie die "),Ss=c("code"),Qi=u("pipeline()"),Xi=u(" akzeptiert der Tokenizer eine Liste von Eingaben. Dar\xFCber hinaus kann der Tokenizer den Text auch auff\xFCllen und k\xFCrzen, um einen Stapel mit einheitlicher L\xE4nge zur\xFCckzugeben:"),Ur=k(),y(lt.$$.fragment),Rr=k(),at=c("p"),eo=u("Lesen Sie das Tutorial "),kn=c("a"),to=u("preprocessing"),no=u(" f\xFCr weitere Details zur Tokenisierung."),Vr=k(),Ce=c("h3"),it=c("a"),js=c("span"),y(Vt.$$.fragment),so=k(),Ms=c("span"),ro=u("AutoModel"),xr=k(),y(ot.$$.fragment),Gr=k(),y(ft.$$.fragment),Jr=k(),ee=c("p"),lo=u("Modelle sind ein standardm\xE4\xDFiges "),xt=c("a"),ys=c("code"),ao=u("torch.nn.Module"),io=u(" oder ein "),Gt=c("a"),Cs=c("code"),oo=u("tf.keras.Model"),fo=u(", sodass Sie sie in Ihrer \xFCblichen Trainingsschleife verwenden k\xF6nnen. Um jedoch die Dinge einfacher zu machen, bietet \u{1F917} Transformers eine "),Ds=c("code"),uo=u("Trainer"),co=u("-Klasse f\xFCr PyTorch, die Funktionalit\xE4t f\xFCr verteiltes Training, gemischte Pr\xE4zision und mehr bietet. F\xFCr TensorFlow k\xF6nnen Sie die Methode "),Is=c("code"),mo=u("fit"),po=u(" aus "),Jt=c("a"),ho=u("Keras"),go=u(" verwenden. Siehe das "),vn=c("a"),_o=u("training tutorial"),bo=u(" f\xFCr weitere Details."),Zr=k(),y(ut.$$.fragment),Yr=k(),De=c("h3"),dt=c("a"),Ps=c("span"),y(Zt.$$.fragment),$o=k(),Ns=c("span"),wo=u("Modell speichern"),Qr=k(),y(ct.$$.fragment),Xr=k(),En=c("p"),ko=u("Ein besonders cooles \u{1F917} Transformers-Feature ist die M\xF6glichkeit, ein Modell zu speichern und es entweder als PyTorch- oder TensorFlow-Modell wieder zu laden. Der Parameter \u201Cfrom_pt\u201D oder \u201Cfrom_tf\u201D kann das Modell von einem Framework in das andere konvertieren:"),el=k(),y(mt.$$.fragment),tl=k(),Ie=c("h2"),pt=c("a"),Fs=c("span"),y(Yt.$$.fragment),vo=k(),qs=c("span"),Eo=u("Custom model builds"),nl=k(),An=c("p"),Ao=u("Sie k\xF6nnen die Konfigurationsklasse des Modells \xE4ndern, um zu bestimmen, wie ein Modell aufgebaut ist. Die Konfiguration legt die Attribute eines Modells fest, z. B. die Anzahl der verborgenen Schichten oder der Aufmerksamkeitsk\xF6pfe. Wenn Sie ein Modell aus einer benutzerdefinierten Konfigurationsklasse initialisieren, beginnen Sie bei Null. Die Modellattribute werden zuf\xE4llig initialisiert, und Sie m\xFCssen das Modell trainieren, bevor Sie es verwenden k\xF6nnen, um aussagekr\xE4ftige Ergebnisse zu erhalten."),sl=k(),ke=c("p"),To=u("Beginnen Sie mit dem Import von "),Os=c("code"),zo=u("AutoConfig"),So=u(" und laden Sie dann das trainierte Modell, das Sie \xE4ndern m\xF6chten. Innerhalb von "),Ws=c("code"),jo=u("AutoConfig.from_pretrained()"),Mo=u(" k\xF6nnen Sie das Attribut angeben, das Sie \xE4ndern m\xF6chten, z. B. die Anzahl der Aufmerksamkeitsk\xF6pfe:"),rl=k(),y(Qt.$$.fragment),ll=k(),y(ht.$$.fragment),al=k(),gt=c("p"),yo=u("Weitere Informationen zur Erstellung von benutzerdefinierten Konfigurationen finden Sie in der Anleitung "),Tn=c("a"),Co=u("Erstellen einer benutzerdefinierten Architektur"),Do=u("."),il=k(),Pe=c("h2"),_t=c("a"),Bs=c("span"),y(Xt.$$.fragment),Io=k(),Ls=c("span"),Po=u("Wie geht es weiter?"),ol=k(),zn=c("p"),No=u("Nachdem Sie nun die \u{1F917} Transformers-Kurztour abgeschlossen haben, schauen Sie sich unsere Anleitungen an und erfahren Sie, wie Sie spezifischere Dinge tun k\xF6nnen, wie das Schreiben eines benutzerdefinierten Modells, die Feinabstimmung eines Modells f\xFCr eine Aufgabe und wie man ein Modell mit einem Skript trainiert. Wenn Sie mehr \xFCber die Kernkonzepte von \u{1F917} Transformers erfahren m\xF6chten, nehmen Sie sich eine Tasse Kaffee und werfen Sie einen Blick auf unsere konzeptionellen Leitf\xE4den!"),this.h()},l(n){const b=ad('[data-svelte="svelte-1phssyn"]',document.head);e=m(b,"META",{name:!0,content:!0}),b.forEach(r),l=v(n),t=m(n,"H1",{class:!0});var en=p(t);s=m(en,"A",{id:!0,class:!0,href:!0});var Ks=p(s);i=m(Ks,"SPAN",{});var Hs=p(i);P(f.$$.fragment,Hs),Hs.forEach(r),Ks.forEach(r),h=v(en),_=m(en,"SPAN",{});var Us=p(_);$=d(Us,"Schnellstart"),Us.forEach(r),en.forEach(r),M=v(n),P(F.$$.fragment,n),q=v(n),j=m(n,"P",{});var Ne=p(j);I=d(Ne,"Mit \u{1F917} Transformers k\xF6nnen Sie sofort loslegen! Verwenden Sie die "),A=m(Ne,"CODE",{});var Rs=p(A);S=d(Rs,"pipeline()"),Rs.forEach(r),z=d(Ne," f\xFCr schnelle Inferenz und laden Sie schnell ein vortrainiertes Modell und einen Tokenizer mit einer "),N=m(Ne,"A",{href:!0});var Vs=p(N);B=d(Vs,"AutoClass"),Vs.forEach(r),L=d(Ne,", um Ihre Text-, Bild- oder Audioaufgabe zu l\xF6sen."),Ne.forEach(r),U=v(n),P(K.$$.fragment,n),se=v(n),Z=m(n,"H2",{class:!0});var tn=p(Z);G=m(tn,"A",{id:!0,class:!0,href:!0});var xs=p(G);te=m(xs,"SPAN",{});var Gs=p(te);P(ne.$$.fragment,Gs),Gs.forEach(r),xs.forEach(r),Y=v(tn),le=m(tn,"SPAN",{});var Js=p(le);O=d(Js,"Pipeline"),Js.forEach(r),tn.forEach(r),H=v(n),Q=m(n,"P",{});var Fo=p(Q);W=m(Fo,"CODE",{});var Uo=p(W);R=d(Uo,"pipeline()"),Uo.forEach(r),ce=d(Fo," ist der einfachste Weg, ein vortrainiertes Modell f\xFCr eine bestimmte Aufgabe zu verwenden."),Fo.forEach(r),pe=v(n),P(ue.$$.fragment,n),$t=v(n),de=m(n,"P",{});var ul=p(de);an=d(ul,"Die "),Be=m(ul,"CODE",{});var Ro=p(Be);Il=d(Ro,"pipeline()"),Ro.forEach(r),Pl=d(ul," unterst\xFCtzt viele g\xE4ngige Aufgaben:"),ul.forEach(r),Zs=v(n),wt=m(n,"P",{});var qo=p(wt);Fn=m(qo,"STRONG",{});var Vo=p(Fn);Nl=d(Vo,"Text"),Vo.forEach(r),Fl=d(qo,":"),qo.forEach(r),Ys=v(n),J=m(n,"UL",{});var re=p(J);qn=m(re,"LI",{});var xo=p(qn);ql=d(xo,"Stimmungsanalyse: Klassifizierung der Polarit\xE4t eines gegebenen Textes."),xo.forEach(r),Ol=v(re),On=m(re,"LI",{});var Go=p(On);Wl=d(Go,"Textgenerierung (auf Englisch): Generierung von Text aus einer gegebenen Eingabe."),Go.forEach(r),Bl=v(re),Wn=m(re,"LI",{});var Jo=p(Wn);Ll=d(Jo,"Name-Entity-Recognition (NER): Kennzeichnung jedes Worts mit der Entit\xE4t, die es repr\xE4sentiert (Person, Datum, Ort usw.)."),Jo.forEach(r),Kl=v(re),Bn=m(re,"LI",{});var Zo=p(Bn);Hl=d(Zo,"Beantwortung von Fragen: Extrahieren der Antwort aus dem Kontext, wenn ein gewisser Kontext und eine Frage gegeben sind."),Zo.forEach(r),Ul=v(re),Ln=m(re,"LI",{});var Yo=p(Ln);Rl=d(Yo,"Fill-mask: Ausf\xFCllen von L\xFCcken in einem Text mit maskierten W\xF6rtern."),Yo.forEach(r),Vl=v(re),Kn=m(re,"LI",{});var Qo=p(Kn);xl=d(Qo,"Zusammenfassung: Erstellung einer Zusammenfassung einer langen Text- oder Dokumentensequenz."),Qo.forEach(r),Gl=v(re),Hn=m(re,"LI",{});var Xo=p(Hn);Jl=d(Xo,"\xDCbersetzung: \xDCbersetzen eines Textes in eine andere Sprache."),Xo.forEach(r),Zl=v(re),Un=m(re,"LI",{});var ef=p(Un);Yl=d(ef,"Merkmalsextraktion: Erstellen einer Tensordarstellung des Textes."),ef.forEach(r),re.forEach(r),Qs=v(n),kt=m(n,"P",{});var Oo=p(kt);Rn=m(Oo,"STRONG",{});var tf=p(Rn);Ql=d(tf,"Bild"),tf.forEach(r),Xl=d(Oo,":"),Oo.forEach(r),Xs=v(n),he=m(n,"UL",{});var Sn=p(he);Vn=m(Sn,"LI",{});var nf=p(Vn);ea=d(nf,"Bildklassifizierung: Klassifizierung eines Bildes."),nf.forEach(r),ta=v(Sn),xn=m(Sn,"LI",{});var sf=p(xn);na=d(sf,"Bildsegmentierung: Klassifizierung jedes Pixels in einem Bild."),sf.forEach(r),sa=v(Sn),Gn=m(Sn,"LI",{});var rf=p(Gn);ra=d(rf,"Objekterkennung: Erkennen von Objekten innerhalb eines Bildes."),rf.forEach(r),Sn.forEach(r),er=v(n),vt=m(n,"P",{});var Wo=p(vt);Jn=m(Wo,"STRONG",{});var lf=p(Jn);la=d(lf,"Audio"),lf.forEach(r),aa=d(Wo,":"),Wo.forEach(r),tr=v(n),Le=m(n,"UL",{});var dl=p(Le);Zn=m(dl,"LI",{});var af=p(Zn);ia=d(af,"Audioklassifizierung: Zuweisung eines Labels zu einem bestimmten Audiosegment."),af.forEach(r),oa=v(dl),Yn=m(dl,"LI",{});var of=p(Yn);fa=d(of,"Automatische Spracherkennung (ASR): Transkription von Audiodaten in Text."),of.forEach(r),dl.forEach(r),nr=v(n),P(Ke.$$.fragment,n),sr=v(n),Se=m(n,"H3",{class:!0});var cl=p(Se);He=m(cl,"A",{id:!0,class:!0,href:!0});var ff=p(He);Qn=m(ff,"SPAN",{});var uf=p(Qn);P(Et.$$.fragment,uf),uf.forEach(r),ff.forEach(r),ua=v(cl),Xn=m(cl,"SPAN",{});var df=p(Xn);da=d(df,"Verwendung der Pipeline"),df.forEach(r),cl.forEach(r),rr=v(n),Ue=m(n,"P",{});var ml=p(Ue);ca=d(ml,"Im folgenden Beispiel werden Sie die "),es=m(ml,"CODE",{});var cf=p(es);ma=d(cf,"pipeline()"),cf.forEach(r),pa=d(ml," f\xFCr die Stimmungsanalyse verwenden."),ml.forEach(r),lr=v(n),on=m(n,"P",{});var mf=p(on);ha=d(mf,"Installieren Sie die folgenden Abh\xE4ngigkeiten, falls Sie dies nicht bereits getan haben:"),mf.forEach(r),ar=v(n),P(Re.$$.fragment,n),ir=v(n),Ve=m(n,"P",{});var pl=p(Ve);ga=d(pl,"Importieren sie die "),ts=m(pl,"CODE",{});var pf=p(ts);_a=d(pf,"pipeline()"),pf.forEach(r),ba=d(pl," und spezifizieren sie die Aufgabe, welche sie l\xF6sen m\xF6chten:"),pl.forEach(r),or=v(n),P(At.$$.fragment,n),fr=v(n),xe=m(n,"P",{});var hl=p(xe);$a=d(hl,"Die Pipeline l\xE4dt ein standardm\xE4\xDFiges [vortrainiertes Modell] ("),Tt=m(hl,"A",{href:!0,rel:!0});var hf=p(Tt);wa=d(hf,"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),hf.forEach(r),ka=d(hl,") und einen Tokenizer f\xFCr die Stimmungs-Analyse herunter und speichert sie. Jetzt k\xF6nnen Sie den \u201CKlassifikator\u201D auf Ihren Zieltext anwenden:"),hl.forEach(r),ur=v(n),P(zt.$$.fragment,n),dr=v(n),Ge=m(n,"P",{});var gl=p(Ge);va=d(gl,"For more than one sentence, pass a list of sentences to the "),ns=m(gl,"CODE",{});var gf=p(ns);Ea=d(gf,"pipeline()"),gf.forEach(r),Aa=d(gl," which returns a list of dictionaries:"),gl.forEach(r),cr=v(n),P(St.$$.fragment,n),mr=v(n),ge=m(n,"P",{});var jn=p(ge);Ta=d(jn,"Die "),ss=m(jn,"CODE",{});var _f=p(ss);za=d(_f,"pipeline()"),_f.forEach(r),Sa=d(jn," kann auch \xFCber einen ganzen Datensatz iterieren. Starten wir mit der Installation der "),jt=m(jn,"A",{href:!0,rel:!0});var bf=p(jt);ja=d(bf,"\u{1F917} Datasets"),bf.forEach(r),Ma=d(jn," Bibliothek:"),jn.forEach(r),pr=v(n),P(Mt.$$.fragment,n),hr=v(n),Je=m(n,"P",{});var _l=p(Je);ya=d(_l,"Erstellen wir eine "),rs=m(_l,"CODE",{});var $f=p(rs);Ca=d($f,"pipeline()"),$f.forEach(r),Da=d(_l," mit der Aufgabe die wir l\xF6sen und dem Modell welches wir nutzen m\xF6chten."),_l.forEach(r),gr=v(n),P(yt.$$.fragment,n),_r=v(n),_e=m(n,"P",{});var Mn=p(_e);Ia=d(Mn,"Als n\xE4chstes laden wir den Datensatz (siehe \u{1F917} Datasets "),Ct=m(Mn,"A",{href:!0,rel:!0});var wf=p(Ct);Pa=d(wf,"Quick Start"),wf.forEach(r),Na=d(Mn," f\xFCr mehr Details) welches wir nutzen m\xF6chten. Zum Beispiel laden wir den "),Dt=m(Mn,"A",{href:!0,rel:!0});var kf=p(Dt);Fa=d(kf,"MInDS-14"),kf.forEach(r),qa=d(Mn," Datensatz:"),Mn.forEach(r),br=v(n),P(It.$$.fragment,n),$r=v(n),Ze=m(n,"P",{});var bl=p(Ze);Oa=d(bl,"Wir m\xFCssen sicherstellen, dass die Abtastrate des Datensatzes der Abtastrate entspricht, mit der "),ls=m(bl,"CODE",{});var vf=p(ls);Wa=d(vf,"facebook/wav2vec2-base-960h"),vf.forEach(r),Ba=d(bl," trainiert wurde."),bl.forEach(r),wr=v(n),P(Pt.$$.fragment,n),kr=v(n),fn=m(n,"P",{});var Ef=p(fn);La=d(Ef,`Audiodateien werden automatisch geladen und neu abgetastet, wenn die Spalte \u201Caudio\u201D aufgerufen wird.
Extrahieren wir die rohen Wellenform-Arrays der ersten 4 Beispiele und \xFCbergeben wir sie als Liste an die Pipeline:`),Ef.forEach(r),vr=v(n),P(Nt.$$.fragment,n),Er=v(n),Ye=m(n,"P",{});var $l=p(Ye);Ka=d($l,"Bei einem gr\xF6\xDFeren Datensatz mit vielen Eingaben (wie bei Sprache oder Bildverarbeitung) sollten Sie einen Generator anstelle einer Liste \xFCbergeben, der alle Eingaben in den Speicher l\xE4dt. Weitere Informationen finden Sie in der "),un=m($l,"A",{href:!0});var Af=p(un);Ha=d(Af,"Pipeline-Dokumentation"),Af.forEach(r),Ua=d($l,"."),$l.forEach(r),Ar=v(n),je=m(n,"H3",{class:!0});var wl=p(je);Qe=m(wl,"A",{id:!0,class:!0,href:!0});var Tf=p(Qe);as=m(Tf,"SPAN",{});var zf=p(as);P(Ft.$$.fragment,zf),zf.forEach(r),Tf.forEach(r),Ra=v(wl),is=m(wl,"SPAN",{});var Sf=p(is);Va=d(Sf,"Ein anderes Modell und einen anderen Tokenizer in der Pipeline verwenden"),Sf.forEach(r),wl.forEach(r),Tr=v(n),ae=m(n,"P",{});var ve=p(ae);xa=d(ve,"Die "),os=m(ve,"CODE",{});var jf=p(os);Ga=d(jf,"pipeline()"),jf.forEach(r),Ja=d(ve," kann jedes Modell aus dem [Model Hub] ("),qt=m(ve,"A",{href:!0,rel:!0});var Mf=p(qt);Za=d(Mf,"https://huggingface.co/models"),Mf.forEach(r),Ya=d(ve,") verwenden, wodurch es einfach ist, die "),fs=m(ve,"CODE",{});var yf=p(fs);Qa=d(yf,"pipeline()"),yf.forEach(r),Xa=d(ve," f\xFCr andere Anwendungsf\xE4lle anzupassen. Wenn Sie beispielsweise ein Modell w\xFCnschen, das franz\xF6sischen Text verarbeiten kann, verwenden Sie die Tags im Model Hub, um nach einem geeigneten Modell zu filtern. Das oberste gefilterte Ergebnis liefert ein mehrsprachiges "),Ot=m(ve,"A",{href:!0,rel:!0});var Cf=p(Ot);ei=d(Cf,"BERT-Modell"),Cf.forEach(r),ti=d(ve,", das auf die Stimmungsanalyse abgestimmt ist. Gro\xDFartig, verwenden wir dieses Modell!"),ve.forEach(r),zr=v(n),P(Wt.$$.fragment,n),Sr=v(n),P(Xe.$$.fragment,n),jr=v(n),be=m(n,"P",{});var yn=p(be);ni=d(yn,"Dann k\xF6nnen Sie das Modell und den Tokenizer in der "),us=m(yn,"CODE",{});var Df=p(us);si=d(Df,"pipeline()"),Df.forEach(r),ri=d(yn," angeben und den "),ds=m(yn,"CODE",{});var If=p(ds);li=d(If,"Klassifikator"),If.forEach(r),ai=d(yn," auf Ihren Zieltext anwenden:"),yn.forEach(r),Mr=v(n),P(Bt.$$.fragment,n),yr=v(n),$e=m(n,"P",{});var Cn=p($e);ii=d(Cn,"Wenn Sie kein Modell f\xFCr Ihren Anwendungsfall finden k\xF6nnen, m\xFCssen Sie ein vortrainiertes Modell auf Ihren Daten feinabstimmen. Schauen Sie sich unser "),dn=m(Cn,"A",{href:!0});var Pf=p(dn);oi=d(Pf,"Feinabstimmungs-Tutorial"),Pf.forEach(r),fi=d(Cn," an, um zu erfahren, wie das geht. Und schlie\xDFlich, nachdem Sie Ihr trainiertes Modell verfeinert haben, sollten Sie es mit der Community im Model Hub teilen (siehe Tutorial "),cn=m(Cn,"A",{href:!0});var Nf=p(cn);ui=d(Nf,"hier"),Nf.forEach(r),di=d(Cn,"), um NLP f\xFCr alle zu demokratisieren! \u{1F917}"),Cn.forEach(r),Cr=v(n),Me=m(n,"H2",{class:!0});var kl=p(Me);et=m(kl,"A",{id:!0,class:!0,href:!0});var Ff=p(et);cs=m(Ff,"SPAN",{});var qf=p(cs);P(Lt.$$.fragment,qf),qf.forEach(r),Ff.forEach(r),ci=v(kl),ms=m(kl,"SPAN",{});var Of=p(ms);mi=d(Of,"AutoClass"),Of.forEach(r),kl.forEach(r),Dr=v(n),P(Kt.$$.fragment,n),Ir=v(n),X=m(n,"P",{});var ie=p(X);pi=d(ie,"Unter der Haube arbeiten die Klassen "),ps=m(ie,"CODE",{});var Wf=p(ps);hi=d(Wf,"AutoModelForSequenceClassification"),Wf.forEach(r),gi=d(ie," und "),hs=m(ie,"CODE",{});var Bf=p(hs);_i=d(Bf,"AutoTokenizer"),Bf.forEach(r),bi=d(ie," zusammen, um die "),gs=m(ie,"CODE",{});var Lf=p(gs);$i=d(Lf,"pipeline()"),Lf.forEach(r),wi=d(ie," zu betreiben. Eine "),mn=m(ie,"A",{href:!0});var Kf=p(mn);_s=m(Kf,"CODE",{});var Hf=p(_s);ki=d(Hf,"AutoClass"),Hf.forEach(r),Kf.forEach(r),vi=d(ie," ist eine Abk\xFCrzung, die automatisch die Architektur eines trainierten Modells aus dessen Namen oder Pfad abruft. Sie m\xFCssen nur die passende "),bs=m(ie,"CODE",{});var Uf=p(bs);Ei=d(Uf,"AutoClass"),Uf.forEach(r),Ai=d(ie," f\xFCr Ihre Aufgabe und den zugeh\xF6rigen Tokenizer mit "),$s=m(ie,"CODE",{});var Rf=p($s);Ti=d(Rf,"AutoTokenizer"),Rf.forEach(r),zi=d(ie," ausw\xE4hlen."),ie.forEach(r),Pr=v(n),we=m(n,"P",{});var Dn=p(we);Si=d(Dn,"Kehren wir zu unserem Beispiel zur\xFCck und sehen wir uns an, wie Sie die "),ws=m(Dn,"CODE",{});var Vf=p(ws);ji=d(Vf,"AutoClass"),Vf.forEach(r),Mi=d(Dn," verwenden k\xF6nnen, um die Ergebnisse der "),ks=m(Dn,"CODE",{});var xf=p(ks);yi=d(xf,"pipeline()"),xf.forEach(r),Ci=d(Dn," zu replizieren."),Dn.forEach(r),Nr=v(n),ye=m(n,"H3",{class:!0});var vl=p(ye);tt=m(vl,"A",{id:!0,class:!0,href:!0});var Gf=p(tt);vs=m(Gf,"SPAN",{});var Jf=p(vs);P(Ht.$$.fragment,Jf),Jf.forEach(r),Gf.forEach(r),Di=v(vl),Es=m(vl,"SPAN",{});var Zf=p(Es);Ii=d(Zf,"AutoTokenizer"),Zf.forEach(r),vl.forEach(r),Fr=v(n),me=m(n,"P",{});var bt=p(me);Pi=d(bt,"Ein Tokenizer ist f\xFCr die Vorverarbeitung von Text in ein f\xFCr das Modell verst\xE4ndliches Format zust\xE4ndig. Zun\xE4chst zerlegt der Tokenisierer den Text in W\xF6rter, die "),As=m(bt,"EM",{});var Yf=p(As);Ni=d(Yf,"Token"),Yf.forEach(r),Fi=d(bt," genannt werden. Es gibt mehrere Regeln f\xFCr den Tokenisierungsprozess, z. B. wie und auf welcher Ebene ein Wort aufgespalten wird (weitere Informationen \xFCber Tokenisierung "),pn=m(bt,"A",{href:!0});var Qf=p(pn);qi=d(Qf,"hier"),Qf.forEach(r),Oi=d(bt,`). Das Wichtigste ist jedoch, dass Sie den Tokenizer mit demselben Modellnamen instanziieren m\xFCssen, um sicherzustellen, dass Sie dieselben Tokenisierungsregeln verwenden, mit denen ein Modell zuvor trainiert wurde.
Laden sie einen Tokenizer mit `),Ts=m(bt,"CODE",{});var Xf=p(Ts);Wi=d(Xf,"AutoTokenizer"),Xf.forEach(r),Bi=d(bt,":"),bt.forEach(r),qr=v(n),P(Ut.$$.fragment,n),Or=v(n),nt=m(n,"P",{});var El=p(nt);Li=d(El,"Anschlie\xDFend wandelt der Tokenizer die Token in Zahlen um, um einen Tensor als Eingabe f\xFCr das Modell zu konstruieren. Dieser wird als "),zs=m(El,"EM",{});var eu=p(zs);Ki=d(eu,"Vokabular"),eu.forEach(r),Hi=d(El," des Modells bezeichnet."),El.forEach(r),Wr=v(n),hn=m(n,"P",{});var tu=p(hn);Ui=d(tu,"\xDCbergeben Sie Ihren Text an den Tokenizer:"),tu.forEach(r),Br=v(n),P(Rt.$$.fragment,n),Lr=v(n),gn=m(n,"P",{});var nu=p(gn);Ri=d(nu,"Der Tokenizer gibt ein W\xF6rterbuch zur\xFCck, das Folgendes enth\xE4lt:"),nu.forEach(r),Kr=v(n),st=m(n,"UL",{});var Al=p(st);_n=m(Al,"LI",{});var Bo=p(_n);bn=m(Bo,"A",{href:!0});var su=p(bn);Vi=d(su,"input_ids"),su.forEach(r),xi=d(Bo,": numerische Repr\xE4sentationen Ihrer Token."),Bo.forEach(r),Gi=v(Al),$n=m(Al,"LI",{});var Lo=p($n);wn=m(Lo,"A",{href:!0});var ru=p(wn);Ji=d(ru,"atttention_mask"),ru.forEach(r),Zi=d(Lo,": gibt an, welche Token beachtet werden sollen."),Lo.forEach(r),Al.forEach(r),Hr=v(n),rt=m(n,"P",{});var Tl=p(rt);Yi=d(Tl,"Genau wie die "),Ss=m(Tl,"CODE",{});var lu=p(Ss);Qi=d(lu,"pipeline()"),lu.forEach(r),Xi=d(Tl," akzeptiert der Tokenizer eine Liste von Eingaben. Dar\xFCber hinaus kann der Tokenizer den Text auch auff\xFCllen und k\xFCrzen, um einen Stapel mit einheitlicher L\xE4nge zur\xFCckzugeben:"),Tl.forEach(r),Ur=v(n),P(lt.$$.fragment,n),Rr=v(n),at=m(n,"P",{});var zl=p(at);eo=d(zl,"Lesen Sie das Tutorial "),kn=m(zl,"A",{href:!0});var au=p(kn);to=d(au,"preprocessing"),au.forEach(r),no=d(zl," f\xFCr weitere Details zur Tokenisierung."),zl.forEach(r),Vr=v(n),Ce=m(n,"H3",{class:!0});var Sl=p(Ce);it=m(Sl,"A",{id:!0,class:!0,href:!0});var iu=p(it);js=m(iu,"SPAN",{});var ou=p(js);P(Vt.$$.fragment,ou),ou.forEach(r),iu.forEach(r),so=v(Sl),Ms=m(Sl,"SPAN",{});var fu=p(Ms);ro=d(fu,"AutoModel"),fu.forEach(r),Sl.forEach(r),xr=v(n),P(ot.$$.fragment,n),Gr=v(n),P(ft.$$.fragment,n),Jr=v(n),ee=m(n,"P",{});var oe=p(ee);lo=d(oe,"Modelle sind ein standardm\xE4\xDFiges "),xt=m(oe,"A",{href:!0,rel:!0});var uu=p(xt);ys=m(uu,"CODE",{});var du=p(ys);ao=d(du,"torch.nn.Module"),du.forEach(r),uu.forEach(r),io=d(oe," oder ein "),Gt=m(oe,"A",{href:!0,rel:!0});var cu=p(Gt);Cs=m(cu,"CODE",{});var mu=p(Cs);oo=d(mu,"tf.keras.Model"),mu.forEach(r),cu.forEach(r),fo=d(oe,", sodass Sie sie in Ihrer \xFCblichen Trainingsschleife verwenden k\xF6nnen. Um jedoch die Dinge einfacher zu machen, bietet \u{1F917} Transformers eine "),Ds=m(oe,"CODE",{});var pu=p(Ds);uo=d(pu,"Trainer"),pu.forEach(r),co=d(oe,"-Klasse f\xFCr PyTorch, die Funktionalit\xE4t f\xFCr verteiltes Training, gemischte Pr\xE4zision und mehr bietet. F\xFCr TensorFlow k\xF6nnen Sie die Methode "),Is=m(oe,"CODE",{});var hu=p(Is);mo=d(hu,"fit"),hu.forEach(r),po=d(oe," aus "),Jt=m(oe,"A",{href:!0,rel:!0});var gu=p(Jt);ho=d(gu,"Keras"),gu.forEach(r),go=d(oe," verwenden. Siehe das "),vn=m(oe,"A",{href:!0});var _u=p(vn);_o=d(_u,"training tutorial"),_u.forEach(r),bo=d(oe," f\xFCr weitere Details."),oe.forEach(r),Zr=v(n),P(ut.$$.fragment,n),Yr=v(n),De=m(n,"H3",{class:!0});var jl=p(De);dt=m(jl,"A",{id:!0,class:!0,href:!0});var bu=p(dt);Ps=m(bu,"SPAN",{});var $u=p(Ps);P(Zt.$$.fragment,$u),$u.forEach(r),bu.forEach(r),$o=v(jl),Ns=m(jl,"SPAN",{});var wu=p(Ns);wo=d(wu,"Modell speichern"),wu.forEach(r),jl.forEach(r),Qr=v(n),P(ct.$$.fragment,n),Xr=v(n),En=m(n,"P",{});var ku=p(En);ko=d(ku,"Ein besonders cooles \u{1F917} Transformers-Feature ist die M\xF6glichkeit, ein Modell zu speichern und es entweder als PyTorch- oder TensorFlow-Modell wieder zu laden. Der Parameter \u201Cfrom_pt\u201D oder \u201Cfrom_tf\u201D kann das Modell von einem Framework in das andere konvertieren:"),ku.forEach(r),el=v(n),P(mt.$$.fragment,n),tl=v(n),Ie=m(n,"H2",{class:!0});var Ml=p(Ie);pt=m(Ml,"A",{id:!0,class:!0,href:!0});var vu=p(pt);Fs=m(vu,"SPAN",{});var Eu=p(Fs);P(Yt.$$.fragment,Eu),Eu.forEach(r),vu.forEach(r),vo=v(Ml),qs=m(Ml,"SPAN",{});var Au=p(qs);Eo=d(Au,"Custom model builds"),Au.forEach(r),Ml.forEach(r),nl=v(n),An=m(n,"P",{});var Tu=p(An);Ao=d(Tu,"Sie k\xF6nnen die Konfigurationsklasse des Modells \xE4ndern, um zu bestimmen, wie ein Modell aufgebaut ist. Die Konfiguration legt die Attribute eines Modells fest, z. B. die Anzahl der verborgenen Schichten oder der Aufmerksamkeitsk\xF6pfe. Wenn Sie ein Modell aus einer benutzerdefinierten Konfigurationsklasse initialisieren, beginnen Sie bei Null. Die Modellattribute werden zuf\xE4llig initialisiert, und Sie m\xFCssen das Modell trainieren, bevor Sie es verwenden k\xF6nnen, um aussagekr\xE4ftige Ergebnisse zu erhalten."),Tu.forEach(r),sl=v(n),ke=m(n,"P",{});var In=p(ke);To=d(In,"Beginnen Sie mit dem Import von "),Os=m(In,"CODE",{});var zu=p(Os);zo=d(zu,"AutoConfig"),zu.forEach(r),So=d(In," und laden Sie dann das trainierte Modell, das Sie \xE4ndern m\xF6chten. Innerhalb von "),Ws=m(In,"CODE",{});var Su=p(Ws);jo=d(Su,"AutoConfig.from_pretrained()"),Su.forEach(r),Mo=d(In," k\xF6nnen Sie das Attribut angeben, das Sie \xE4ndern m\xF6chten, z. B. die Anzahl der Aufmerksamkeitsk\xF6pfe:"),In.forEach(r),rl=v(n),P(Qt.$$.fragment,n),ll=v(n),P(ht.$$.fragment,n),al=v(n),gt=m(n,"P",{});var yl=p(gt);yo=d(yl,"Weitere Informationen zur Erstellung von benutzerdefinierten Konfigurationen finden Sie in der Anleitung "),Tn=m(yl,"A",{href:!0});var ju=p(Tn);Co=d(ju,"Erstellen einer benutzerdefinierten Architektur"),ju.forEach(r),Do=d(yl,"."),yl.forEach(r),il=v(n),Pe=m(n,"H2",{class:!0});var Cl=p(Pe);_t=m(Cl,"A",{id:!0,class:!0,href:!0});var Mu=p(_t);Bs=m(Mu,"SPAN",{});var yu=p(Bs);P(Xt.$$.fragment,yu),yu.forEach(r),Mu.forEach(r),Io=v(Cl),Ls=m(Cl,"SPAN",{});var Cu=p(Ls);Po=d(Cu,"Wie geht es weiter?"),Cu.forEach(r),Cl.forEach(r),ol=v(n),zn=m(n,"P",{});var Du=p(zn);No=d(Du,"Nachdem Sie nun die \u{1F917} Transformers-Kurztour abgeschlossen haben, schauen Sie sich unsere Anleitungen an und erfahren Sie, wie Sie spezifischere Dinge tun k\xF6nnen, wie das Schreiben eines benutzerdefinierten Modells, die Feinabstimmung eines Modells f\xFCr eine Aufgabe und wie man ein Modell mit einem Skript trainiert. Wenn Sie mehr \xFCber die Kernkonzepte von \u{1F917} Transformers erfahren m\xF6chten, nehmen Sie sich eine Tasse Kaffee und werfen Sie einen Blick auf unsere konzeptionellen Leitf\xE4den!"),Du.forEach(r),this.h()},h(){w(e,"name","hf:doc:metadata"),w(e,"content",JSON.stringify(jc)),w(s,"id","schnellstart"),w(s,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(s,"href","#schnellstart"),w(t,"class","relative group"),w(N,"href","./model_doc/auto"),w(G,"id","pipeline"),w(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(G,"href","#pipeline"),w(Z,"class","relative group"),w(He,"id","verwendung-der-pipeline"),w(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(He,"href","#verwendung-der-pipeline"),w(Se,"class","relative group"),w(Tt,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),w(Tt,"rel","nofollow"),w(jt,"href","https://huggingface.co/docs/datasets/"),w(jt,"rel","nofollow"),w(Ct,"href","https://huggingface.co/docs/datasets/quickstart.html"),w(Ct,"rel","nofollow"),w(Dt,"href","https://huggingface.co/datasets/PolyAI/minds14"),w(Dt,"rel","nofollow"),w(un,"href","./main_classes/pipelines"),w(Qe,"id","ein-anderes-modell-und-einen-anderen-tokenizer-in-der-pipeline-verwenden"),w(Qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(Qe,"href","#ein-anderes-modell-und-einen-anderen-tokenizer-in-der-pipeline-verwenden"),w(je,"class","relative group"),w(qt,"href","https://huggingface.co/models"),w(qt,"rel","nofollow"),w(Ot,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),w(Ot,"rel","nofollow"),w(dn,"href","./training"),w(cn,"href","./model_sharing"),w(et,"id","autoclass"),w(et,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(et,"href","#autoclass"),w(Me,"class","relative group"),w(mn,"href","./model_doc/auto"),w(tt,"id","autotokenizer"),w(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(tt,"href","#autotokenizer"),w(ye,"class","relative group"),w(pn,"href","./tokenizer_summary"),w(bn,"href","./glossary#input-ids"),w(wn,"href",".glossary#attention-mask"),w(kn,"href","./preprocessing"),w(it,"id","automodel"),w(it,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(it,"href","#automodel"),w(Ce,"class","relative group"),w(xt,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),w(xt,"rel","nofollow"),w(Gt,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),w(Gt,"rel","nofollow"),w(Jt,"href","https://keras.io/"),w(Jt,"rel","nofollow"),w(vn,"href","./training"),w(dt,"id","modell-speichern"),w(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(dt,"href","#modell-speichern"),w(De,"class","relative group"),w(pt,"id","custom-model-builds"),w(pt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(pt,"href","#custom-model-builds"),w(Ie,"class","relative group"),w(Tn,"href","./create_a_model"),w(_t,"id","wie-geht-es-weiter"),w(_t,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(_t,"href","#wie-geht-es-weiter"),w(Pe,"class","relative group")},m(n,b){a(document.head,e),g(n,l,b),g(n,t,b),a(t,s),a(s,i),C(f,i,null),a(t,h),a(t,_),a(_,$),g(n,M,b),C(F,n,b),g(n,q,b),g(n,j,b),a(j,I),a(j,A),a(A,S),a(j,z),a(j,N),a(N,B),a(j,L),g(n,U,b),C(K,n,b),g(n,se,b),g(n,Z,b),a(Z,G),a(G,te),C(ne,te,null),a(Z,Y),a(Z,le),a(le,O),g(n,H,b),g(n,Q,b),a(Q,W),a(W,R),a(Q,ce),g(n,pe,b),C(ue,n,b),g(n,$t,b),g(n,de,b),a(de,an),a(de,Be),a(Be,Il),a(de,Pl),g(n,Zs,b),g(n,wt,b),a(wt,Fn),a(Fn,Nl),a(wt,Fl),g(n,Ys,b),g(n,J,b),a(J,qn),a(qn,ql),a(J,Ol),a(J,On),a(On,Wl),a(J,Bl),a(J,Wn),a(Wn,Ll),a(J,Kl),a(J,Bn),a(Bn,Hl),a(J,Ul),a(J,Ln),a(Ln,Rl),a(J,Vl),a(J,Kn),a(Kn,xl),a(J,Gl),a(J,Hn),a(Hn,Jl),a(J,Zl),a(J,Un),a(Un,Yl),g(n,Qs,b),g(n,kt,b),a(kt,Rn),a(Rn,Ql),a(kt,Xl),g(n,Xs,b),g(n,he,b),a(he,Vn),a(Vn,ea),a(he,ta),a(he,xn),a(xn,na),a(he,sa),a(he,Gn),a(Gn,ra),g(n,er,b),g(n,vt,b),a(vt,Jn),a(Jn,la),a(vt,aa),g(n,tr,b),g(n,Le,b),a(Le,Zn),a(Zn,ia),a(Le,oa),a(Le,Yn),a(Yn,fa),g(n,nr,b),C(Ke,n,b),g(n,sr,b),g(n,Se,b),a(Se,He),a(He,Qn),C(Et,Qn,null),a(Se,ua),a(Se,Xn),a(Xn,da),g(n,rr,b),g(n,Ue,b),a(Ue,ca),a(Ue,es),a(es,ma),a(Ue,pa),g(n,lr,b),g(n,on,b),a(on,ha),g(n,ar,b),C(Re,n,b),g(n,ir,b),g(n,Ve,b),a(Ve,ga),a(Ve,ts),a(ts,_a),a(Ve,ba),g(n,or,b),C(At,n,b),g(n,fr,b),g(n,xe,b),a(xe,$a),a(xe,Tt),a(Tt,wa),a(xe,ka),g(n,ur,b),C(zt,n,b),g(n,dr,b),g(n,Ge,b),a(Ge,va),a(Ge,ns),a(ns,Ea),a(Ge,Aa),g(n,cr,b),C(St,n,b),g(n,mr,b),g(n,ge,b),a(ge,Ta),a(ge,ss),a(ss,za),a(ge,Sa),a(ge,jt),a(jt,ja),a(ge,Ma),g(n,pr,b),C(Mt,n,b),g(n,hr,b),g(n,Je,b),a(Je,ya),a(Je,rs),a(rs,Ca),a(Je,Da),g(n,gr,b),C(yt,n,b),g(n,_r,b),g(n,_e,b),a(_e,Ia),a(_e,Ct),a(Ct,Pa),a(_e,Na),a(_e,Dt),a(Dt,Fa),a(_e,qa),g(n,br,b),C(It,n,b),g(n,$r,b),g(n,Ze,b),a(Ze,Oa),a(Ze,ls),a(ls,Wa),a(Ze,Ba),g(n,wr,b),C(Pt,n,b),g(n,kr,b),g(n,fn,b),a(fn,La),g(n,vr,b),C(Nt,n,b),g(n,Er,b),g(n,Ye,b),a(Ye,Ka),a(Ye,un),a(un,Ha),a(Ye,Ua),g(n,Ar,b),g(n,je,b),a(je,Qe),a(Qe,as),C(Ft,as,null),a(je,Ra),a(je,is),a(is,Va),g(n,Tr,b),g(n,ae,b),a(ae,xa),a(ae,os),a(os,Ga),a(ae,Ja),a(ae,qt),a(qt,Za),a(ae,Ya),a(ae,fs),a(fs,Qa),a(ae,Xa),a(ae,Ot),a(Ot,ei),a(ae,ti),g(n,zr,b),C(Wt,n,b),g(n,Sr,b),C(Xe,n,b),g(n,jr,b),g(n,be,b),a(be,ni),a(be,us),a(us,si),a(be,ri),a(be,ds),a(ds,li),a(be,ai),g(n,Mr,b),C(Bt,n,b),g(n,yr,b),g(n,$e,b),a($e,ii),a($e,dn),a(dn,oi),a($e,fi),a($e,cn),a(cn,ui),a($e,di),g(n,Cr,b),g(n,Me,b),a(Me,et),a(et,cs),C(Lt,cs,null),a(Me,ci),a(Me,ms),a(ms,mi),g(n,Dr,b),C(Kt,n,b),g(n,Ir,b),g(n,X,b),a(X,pi),a(X,ps),a(ps,hi),a(X,gi),a(X,hs),a(hs,_i),a(X,bi),a(X,gs),a(gs,$i),a(X,wi),a(X,mn),a(mn,_s),a(_s,ki),a(X,vi),a(X,bs),a(bs,Ei),a(X,Ai),a(X,$s),a($s,Ti),a(X,zi),g(n,Pr,b),g(n,we,b),a(we,Si),a(we,ws),a(ws,ji),a(we,Mi),a(we,ks),a(ks,yi),a(we,Ci),g(n,Nr,b),g(n,ye,b),a(ye,tt),a(tt,vs),C(Ht,vs,null),a(ye,Di),a(ye,Es),a(Es,Ii),g(n,Fr,b),g(n,me,b),a(me,Pi),a(me,As),a(As,Ni),a(me,Fi),a(me,pn),a(pn,qi),a(me,Oi),a(me,Ts),a(Ts,Wi),a(me,Bi),g(n,qr,b),C(Ut,n,b),g(n,Or,b),g(n,nt,b),a(nt,Li),a(nt,zs),a(zs,Ki),a(nt,Hi),g(n,Wr,b),g(n,hn,b),a(hn,Ui),g(n,Br,b),C(Rt,n,b),g(n,Lr,b),g(n,gn,b),a(gn,Ri),g(n,Kr,b),g(n,st,b),a(st,_n),a(_n,bn),a(bn,Vi),a(_n,xi),a(st,Gi),a(st,$n),a($n,wn),a(wn,Ji),a($n,Zi),g(n,Hr,b),g(n,rt,b),a(rt,Yi),a(rt,Ss),a(Ss,Qi),a(rt,Xi),g(n,Ur,b),C(lt,n,b),g(n,Rr,b),g(n,at,b),a(at,eo),a(at,kn),a(kn,to),a(at,no),g(n,Vr,b),g(n,Ce,b),a(Ce,it),a(it,js),C(Vt,js,null),a(Ce,so),a(Ce,Ms),a(Ms,ro),g(n,xr,b),C(ot,n,b),g(n,Gr,b),C(ft,n,b),g(n,Jr,b),g(n,ee,b),a(ee,lo),a(ee,xt),a(xt,ys),a(ys,ao),a(ee,io),a(ee,Gt),a(Gt,Cs),a(Cs,oo),a(ee,fo),a(ee,Ds),a(Ds,uo),a(ee,co),a(ee,Is),a(Is,mo),a(ee,po),a(ee,Jt),a(Jt,ho),a(ee,go),a(ee,vn),a(vn,_o),a(ee,bo),g(n,Zr,b),C(ut,n,b),g(n,Yr,b),g(n,De,b),a(De,dt),a(dt,Ps),C(Zt,Ps,null),a(De,$o),a(De,Ns),a(Ns,wo),g(n,Qr,b),C(ct,n,b),g(n,Xr,b),g(n,En,b),a(En,ko),g(n,el,b),C(mt,n,b),g(n,tl,b),g(n,Ie,b),a(Ie,pt),a(pt,Fs),C(Yt,Fs,null),a(Ie,vo),a(Ie,qs),a(qs,Eo),g(n,nl,b),g(n,An,b),a(An,Ao),g(n,sl,b),g(n,ke,b),a(ke,To),a(ke,Os),a(Os,zo),a(ke,So),a(ke,Ws),a(Ws,jo),a(ke,Mo),g(n,rl,b),C(Qt,n,b),g(n,ll,b),C(ht,n,b),g(n,al,b),g(n,gt,b),a(gt,yo),a(gt,Tn),a(Tn,Co),a(gt,Do),g(n,il,b),g(n,Pe,b),a(Pe,_t),a(_t,Bs),C(Xt,Bs,null),a(Pe,Io),a(Pe,Ls),a(Ls,Po),g(n,ol,b),g(n,zn,b),a(zn,No),fl=!0},p(n,[b]){const en={};b&2&&(en.$$scope={dirty:b,ctx:n}),K.$set(en);const Ks={};b&2&&(Ks.$$scope={dirty:b,ctx:n}),Ke.$set(Ks);const Hs={};b&2&&(Hs.$$scope={dirty:b,ctx:n}),Re.$set(Hs);const Us={};b&2&&(Us.$$scope={dirty:b,ctx:n}),Xe.$set(Us);const Ne={};b&2&&(Ne.$$scope={dirty:b,ctx:n}),lt.$set(Ne);const Rs={};b&2&&(Rs.$$scope={dirty:b,ctx:n}),ot.$set(Rs);const Vs={};b&2&&(Vs.$$scope={dirty:b,ctx:n}),ft.$set(Vs);const tn={};b&2&&(tn.$$scope={dirty:b,ctx:n}),ut.$set(tn);const xs={};b&2&&(xs.$$scope={dirty:b,ctx:n}),ct.$set(xs);const Gs={};b&2&&(Gs.$$scope={dirty:b,ctx:n}),mt.$set(Gs);const Js={};b&2&&(Js.$$scope={dirty:b,ctx:n}),ht.$set(Js)},i(n){fl||(E(f.$$.fragment,n),E(F.$$.fragment,n),E(K.$$.fragment,n),E(ne.$$.fragment,n),E(ue.$$.fragment,n),E(Ke.$$.fragment,n),E(Et.$$.fragment,n),E(Re.$$.fragment,n),E(At.$$.fragment,n),E(zt.$$.fragment,n),E(St.$$.fragment,n),E(Mt.$$.fragment,n),E(yt.$$.fragment,n),E(It.$$.fragment,n),E(Pt.$$.fragment,n),E(Nt.$$.fragment,n),E(Ft.$$.fragment,n),E(Wt.$$.fragment,n),E(Xe.$$.fragment,n),E(Bt.$$.fragment,n),E(Lt.$$.fragment,n),E(Kt.$$.fragment,n),E(Ht.$$.fragment,n),E(Ut.$$.fragment,n),E(Rt.$$.fragment,n),E(lt.$$.fragment,n),E(Vt.$$.fragment,n),E(ot.$$.fragment,n),E(ft.$$.fragment,n),E(ut.$$.fragment,n),E(Zt.$$.fragment,n),E(ct.$$.fragment,n),E(mt.$$.fragment,n),E(Yt.$$.fragment,n),E(Qt.$$.fragment,n),E(ht.$$.fragment,n),E(Xt.$$.fragment,n),fl=!0)},o(n){T(f.$$.fragment,n),T(F.$$.fragment,n),T(K.$$.fragment,n),T(ne.$$.fragment,n),T(ue.$$.fragment,n),T(Ke.$$.fragment,n),T(Et.$$.fragment,n),T(Re.$$.fragment,n),T(At.$$.fragment,n),T(zt.$$.fragment,n),T(St.$$.fragment,n),T(Mt.$$.fragment,n),T(yt.$$.fragment,n),T(It.$$.fragment,n),T(Pt.$$.fragment,n),T(Nt.$$.fragment,n),T(Ft.$$.fragment,n),T(Wt.$$.fragment,n),T(Xe.$$.fragment,n),T(Bt.$$.fragment,n),T(Lt.$$.fragment,n),T(Kt.$$.fragment,n),T(Ht.$$.fragment,n),T(Ut.$$.fragment,n),T(Rt.$$.fragment,n),T(lt.$$.fragment,n),T(Vt.$$.fragment,n),T(ot.$$.fragment,n),T(ft.$$.fragment,n),T(ut.$$.fragment,n),T(Zt.$$.fragment,n),T(ct.$$.fragment,n),T(mt.$$.fragment,n),T(Yt.$$.fragment,n),T(Qt.$$.fragment,n),T(ht.$$.fragment,n),T(Xt.$$.fragment,n),fl=!1},d(n){r(e),n&&r(l),n&&r(t),D(f),n&&r(M),D(F,n),n&&r(q),n&&r(j),n&&r(U),D(K,n),n&&r(se),n&&r(Z),D(ne),n&&r(H),n&&r(Q),n&&r(pe),D(ue,n),n&&r($t),n&&r(de),n&&r(Zs),n&&r(wt),n&&r(Ys),n&&r(J),n&&r(Qs),n&&r(kt),n&&r(Xs),n&&r(he),n&&r(er),n&&r(vt),n&&r(tr),n&&r(Le),n&&r(nr),D(Ke,n),n&&r(sr),n&&r(Se),D(Et),n&&r(rr),n&&r(Ue),n&&r(lr),n&&r(on),n&&r(ar),D(Re,n),n&&r(ir),n&&r(Ve),n&&r(or),D(At,n),n&&r(fr),n&&r(xe),n&&r(ur),D(zt,n),n&&r(dr),n&&r(Ge),n&&r(cr),D(St,n),n&&r(mr),n&&r(ge),n&&r(pr),D(Mt,n),n&&r(hr),n&&r(Je),n&&r(gr),D(yt,n),n&&r(_r),n&&r(_e),n&&r(br),D(It,n),n&&r($r),n&&r(Ze),n&&r(wr),D(Pt,n),n&&r(kr),n&&r(fn),n&&r(vr),D(Nt,n),n&&r(Er),n&&r(Ye),n&&r(Ar),n&&r(je),D(Ft),n&&r(Tr),n&&r(ae),n&&r(zr),D(Wt,n),n&&r(Sr),D(Xe,n),n&&r(jr),n&&r(be),n&&r(Mr),D(Bt,n),n&&r(yr),n&&r($e),n&&r(Cr),n&&r(Me),D(Lt),n&&r(Dr),D(Kt,n),n&&r(Ir),n&&r(X),n&&r(Pr),n&&r(we),n&&r(Nr),n&&r(ye),D(Ht),n&&r(Fr),n&&r(me),n&&r(qr),D(Ut,n),n&&r(Or),n&&r(nt),n&&r(Wr),n&&r(hn),n&&r(Br),D(Rt,n),n&&r(Lr),n&&r(gn),n&&r(Kr),n&&r(st),n&&r(Hr),n&&r(rt),n&&r(Ur),D(lt,n),n&&r(Rr),n&&r(at),n&&r(Vr),n&&r(Ce),D(Vt),n&&r(xr),D(ot,n),n&&r(Gr),D(ft,n),n&&r(Jr),n&&r(ee),n&&r(Zr),D(ut,n),n&&r(Yr),n&&r(De),D(Zt),n&&r(Qr),D(ct,n),n&&r(Xr),n&&r(En),n&&r(el),D(mt,n),n&&r(tl),n&&r(Ie),D(Yt),n&&r(nl),n&&r(An),n&&r(sl),n&&r(ke),n&&r(rl),D(Qt,n),n&&r(ll),D(ht,n),n&&r(al),n&&r(gt),n&&r(il),n&&r(Pe),D(Xt),n&&r(ol),n&&r(zn)}}}const jc={local:"schnellstart",sections:[{local:"pipeline",sections:[{local:"verwendung-der-pipeline",title:"Verwendung der Pipeline"},{local:"ein-anderes-modell-und-einen-anderen-tokenizer-in-der-pipeline-verwenden",title:"Ein anderes Modell und einen anderen Tokenizer in der Pipeline verwenden"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"modell-speichern",title:"Modell speichern"}],title:"AutoClass"},{local:"custom-model-builds",title:"Custom model builds"},{local:"wie-geht-es-weiter",title:"Wie geht es weiter?"}],title:"Schnellstart"};function Mc(o){return Ko(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Pc extends sn{constructor(e){super();rn(this,e,Mc,Sc,ln,{})}}export{Pc as default,jc as metadata};
