import{S as ma,i as da,s as $a,e as l,k as m,w as C,t as r,M as ka,c as i,d as t,m as d,a as c,x as z,h as o,b as k,F as a,g as f,y as L,q as S,o as N,B as I,v as va,L as ua}from"../chunks/vendor-6b77c823.js";import{T as _a}from"../chunks/Tip-39098574.js";import{I as Ge}from"../chunks/IconCopyLink-7a11ce68.js";import{C as _e}from"../chunks/CodeBlock-3a8b25a8.js";import{F as wa,M as ha}from"../chunks/Markdown-9acf6d91.js";function ba(Y){let n,b,p,v,g,_,D,q;return{c(){n=l("p"),b=r("Remember, architecture refers to the skeleton of the model and checkpoints are the weights for a given architecture. For example, "),p=l("a"),v=r("BERT"),g=r(" is an architecture, while "),_=l("code"),D=r("bert-base-uncased"),q=r(" is a checkpoint. Model is a general term that can mean either architecture or checkpoint."),this.h()},l(A){n=i(A,"P",{});var j=c(n);b=o(j,"Remember, architecture refers to the skeleton of the model and checkpoints are the weights for a given architecture. For example, "),p=i(j,"A",{href:!0,rel:!0});var E=c(p);v=o(E,"BERT"),E.forEach(t),g=o(j," is an architecture, while "),_=i(j,"CODE",{});var O=c(_);D=o(O,"bert-base-uncased"),O.forEach(t),q=o(j," is a checkpoint. Model is a general term that can mean either architecture or checkpoint."),j.forEach(t),this.h()},h(){k(p,"href","https://huggingface.co/bert-base-uncased"),k(p,"rel","nofollow")},m(A,j){f(A,n,j),a(n,b),a(n,p),a(p,v),a(n,g),a(n,_),a(_,D),a(n,q)},d(A){A&&t(n)}}}function ya(Y){let n,b,p,v,g,_,D,q,A,j,E,O,F,B,M,G,V,x,H,$,Q,T,Z,X,y,U,ee,P,W,te,J;return F=new _e({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),x=new _e({props:{code:`from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){n=l("p"),b=r("Finally, the "),p=l("code"),v=r("AutoModelFor"),g=r(" classes let you load a pretrained model for a given task (see "),_=l("a"),D=r("here"),q=r(" for a complete list of available tasks). For example, load a model for sequence classification with "),A=l("a"),j=r("AutoModelForSequenceClassification.from_pretrained()"),E=r(":"),O=m(),C(F.$$.fragment),B=m(),M=l("p"),G=r("Easily reuse the same checkpoint to load an architecture for a different task:"),V=m(),C(x.$$.fragment),H=m(),$=l("p"),Q=r("Generally, we recommend using the "),T=l("code"),Z=r("AutoTokenizer"),X=r(" class and the "),y=l("code"),U=r("AutoModelFor"),ee=r(" class to load pretrained instances of models. This will ensure you load the correct architecture every time. In the next "),P=l("a"),W=r("tutorial"),te=r(", learn how to use your newly loaded tokenizer, feature extractor and processor to preprocess a dataset for fine-tuning."),this.h()},l(s){n=i(s,"P",{});var h=c(n);b=o(h,"Finally, the "),p=i(h,"CODE",{});var oe=c(p);v=o(oe,"AutoModelFor"),oe.forEach(t),g=o(h," classes let you load a pretrained model for a given task (see "),_=i(h,"A",{href:!0});var ae=c(_);D=o(ae,"here"),ae.forEach(t),q=o(h," for a complete list of available tasks). For example, load a model for sequence classification with "),A=i(h,"A",{href:!0});var ne=c(A);j=o(ne,"AutoModelForSequenceClassification.from_pretrained()"),ne.forEach(t),E=o(h,":"),h.forEach(t),O=d(s),z(F.$$.fragment,s),B=d(s),M=i(s,"P",{});var re=c(M);G=o(re,"Easily reuse the same checkpoint to load an architecture for a different task:"),re.forEach(t),V=d(s),z(x.$$.fragment,s),H=d(s),$=i(s,"P",{});var w=c($);Q=o(w,"Generally, we recommend using the "),T=i(w,"CODE",{});var R=c(T);Z=o(R,"AutoTokenizer"),R.forEach(t),X=o(w," class and the "),y=i(w,"CODE",{});var se=c(y);U=o(se,"AutoModelFor"),se.forEach(t),ee=o(w," class to load pretrained instances of models. This will ensure you load the correct architecture every time. In the next "),P=i(w,"A",{href:!0});var K=c(P);W=o(K,"tutorial"),K.forEach(t),te=o(w,", learn how to use your newly loaded tokenizer, feature extractor and processor to preprocess a dataset for fine-tuning."),w.forEach(t),this.h()},h(){k(_,"href","model_doc/auto"),k(A,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),k(P,"href","preprocessing")},m(s,h){f(s,n,h),a(n,b),a(n,p),a(p,v),a(n,g),a(n,_),a(_,D),a(n,q),a(n,A),a(A,j),a(n,E),f(s,O,h),L(F,s,h),f(s,B,h),f(s,M,h),a(M,G),f(s,V,h),L(x,s,h),f(s,H,h),f(s,$,h),a($,Q),a($,T),a(T,Z),a($,X),a($,y),a(y,U),a($,ee),a($,P),a(P,W),a($,te),J=!0},p:ua,i(s){J||(S(F.$$.fragment,s),S(x.$$.fragment,s),J=!0)},o(s){N(F.$$.fragment,s),N(x.$$.fragment,s),J=!1},d(s){s&&t(n),s&&t(O),I(F,s),s&&t(B),s&&t(M),s&&t(V),I(x,s),s&&t(H),s&&t($)}}}function ga(Y){let n,b;return n=new ha({props:{$$slots:{default:[ya]},$$scope:{ctx:Y}}}),{c(){C(n.$$.fragment)},l(p){z(n.$$.fragment,p)},m(p,v){L(n,p,v),b=!0},p(p,v){const g={};v&2&&(g.$$scope={dirty:v,ctx:p}),n.$set(g)},i(p){b||(S(n.$$.fragment,p),b=!0)},o(p){N(n.$$.fragment,p),b=!1},d(p){I(n,p)}}}function Aa(Y){let n,b,p,v,g,_,D,q,A,j,E,O,F,B,M,G,V,x,H,$,Q,T,Z,X,y,U,ee,P,W,te,J;return F=new _e({props:{code:`from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),x=new _e({props:{code:`from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){n=l("p"),b=r("Finally, the "),p=l("code"),v=r("TFAutoModelFor"),g=r(" classes let you load a pretrained model for a given task (see "),_=l("a"),D=r("here"),q=r(" for a complete list of available tasks). For example, load a model for sequence classification with "),A=l("a"),j=r("TFAutoModelForSequenceClassification.from_pretrained()"),E=r(":"),O=m(),C(F.$$.fragment),B=m(),M=l("p"),G=r("Easily reuse the same checkpoint to load an architecture for a different task:"),V=m(),C(x.$$.fragment),H=m(),$=l("p"),Q=r("Generally, we recommend using the "),T=l("code"),Z=r("AutoTokenizer"),X=r(" class and the "),y=l("code"),U=r("TFAutoModelFor"),ee=r(" class to load pretrained instances of models. This will ensure you load the correct architecture every time. In the next "),P=l("a"),W=r("tutorial"),te=r(", learn how to use your newly loaded tokenizer, feature extractor and processor to preprocess a dataset for fine-tuning."),this.h()},l(s){n=i(s,"P",{});var h=c(n);b=o(h,"Finally, the "),p=i(h,"CODE",{});var oe=c(p);v=o(oe,"TFAutoModelFor"),oe.forEach(t),g=o(h," classes let you load a pretrained model for a given task (see "),_=i(h,"A",{href:!0});var ae=c(_);D=o(ae,"here"),ae.forEach(t),q=o(h," for a complete list of available tasks). For example, load a model for sequence classification with "),A=i(h,"A",{href:!0});var ne=c(A);j=o(ne,"TFAutoModelForSequenceClassification.from_pretrained()"),ne.forEach(t),E=o(h,":"),h.forEach(t),O=d(s),z(F.$$.fragment,s),B=d(s),M=i(s,"P",{});var re=c(M);G=o(re,"Easily reuse the same checkpoint to load an architecture for a different task:"),re.forEach(t),V=d(s),z(x.$$.fragment,s),H=d(s),$=i(s,"P",{});var w=c($);Q=o(w,"Generally, we recommend using the "),T=i(w,"CODE",{});var R=c(T);Z=o(R,"AutoTokenizer"),R.forEach(t),X=o(w," class and the "),y=i(w,"CODE",{});var se=c(y);U=o(se,"TFAutoModelFor"),se.forEach(t),ee=o(w," class to load pretrained instances of models. This will ensure you load the correct architecture every time. In the next "),P=i(w,"A",{href:!0});var K=c(P);W=o(K,"tutorial"),K.forEach(t),te=o(w,", learn how to use your newly loaded tokenizer, feature extractor and processor to preprocess a dataset for fine-tuning."),w.forEach(t),this.h()},h(){k(_,"href","model_doc/auto"),k(A,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),k(P,"href","preprocessing")},m(s,h){f(s,n,h),a(n,b),a(n,p),a(p,v),a(n,g),a(n,_),a(_,D),a(n,q),a(n,A),a(A,j),a(n,E),f(s,O,h),L(F,s,h),f(s,B,h),f(s,M,h),a(M,G),f(s,V,h),L(x,s,h),f(s,H,h),f(s,$,h),a($,Q),a($,T),a(T,Z),a($,X),a($,y),a(y,U),a($,ee),a($,P),a(P,W),a($,te),J=!0},p:ua,i(s){J||(S(F.$$.fragment,s),S(x.$$.fragment,s),J=!0)},o(s){N(F.$$.fragment,s),N(x.$$.fragment,s),J=!1},d(s){s&&t(n),s&&t(O),I(F,s),s&&t(B),s&&t(M),s&&t(V),I(x,s),s&&t(H),s&&t($)}}}function ja(Y){let n,b;return n=new ha({props:{$$slots:{default:[Aa]},$$scope:{ctx:Y}}}),{c(){C(n.$$.fragment)},l(p){z(n.$$.fragment,p)},m(p,v){L(n,p,v),b=!0},p(p,v){const g={};v&2&&(g.$$scope={dirty:v,ctx:p}),n.$set(g)},i(p){b||(S(n.$$.fragment,p),b=!0)},o(p){N(n.$$.fragment,p),b=!1},d(p){I(n,p)}}}function Ea(Y){let n,b,p,v,g,_,D,q,A,j,E,O,F,B,M,G,V,x,H,$,Q,T,Z,X,y,U,ee,P,W,te,J,s,h,oe,ae,ne,re,w,R,se,K,dt,Se,$t,Ve,xe,kt,Ue,pe,vt,Te,_t,wt,We,we,Je,qe,bt,Ke,be,Qe,le,fe,Ne,ye,yt,Ie,gt,Xe,Me,At,Ye,ue,jt,Pe,Et,Ft,Ze,ge,et,ie,he,Oe,Ae,xt,De,Tt,tt,me,qt,Ce,Mt,Pt,at,de,Ct,ze,zt,Lt,st,je,rt,ce,$e,He,Ee,St,Re,Nt,ot,ke,nt;return _=new Ge({}),$=new _a({props:{$$slots:{default:[ba]},$$scope:{ctx:Y}}}),K=new Ge({}),we=new _e({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)`}}),be=new _e({props:{code:`sequence = "In a hole in the ground there lived a hobbit."
print(tokenizer(sequence))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),ye=new Ge({}),ge=new _e({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained(
    "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),Ae=new Ge({}),je=new _e({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`}}),Ee=new Ge({}),ke=new wa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ja],pytorch:[ga]},$$scope:{ctx:Y}}}),{c(){n=l("meta"),b=m(),p=l("h1"),v=l("a"),g=l("span"),C(_.$$.fragment),D=m(),q=l("span"),A=r("Load pretrained instances with an AutoClass"),j=m(),E=l("p"),O=r("With so many different Transformer architectures, it can be challenging to create one for your checkpoint. As a part of \u{1F917} Transformers core philosophy to make the library easy, simple and flexible to use, an "),F=l("code"),B=r("AutoClass"),M=r(" automatically infer and load the correct architecture from a given checkpoint. The "),G=l("code"),V=r("from_pretrained"),x=r(" method lets you quickly load a pretrained model for any architecture so you don\u2019t have to devote time and resources to train a model from scratch. Producing this type of checkpoint-agnostic code means if your code works for one checkpoint, it will work with another checkpoint - as long as it was trained for a similar task - even if the architecture is different."),H=m(),C($.$$.fragment),Q=m(),T=l("p"),Z=r("In this tutorial, learn to:"),X=m(),y=l("ul"),U=l("li"),ee=r("Load a pretrained tokenizer."),P=m(),W=l("li"),te=r("Load a pretrained feature extractor."),J=m(),s=l("li"),h=r("Load a pretrained processor."),oe=m(),ae=l("li"),ne=r("Load a pretrained model."),re=m(),w=l("h2"),R=l("a"),se=l("span"),C(K.$$.fragment),dt=m(),Se=l("span"),$t=r("AutoTokenizer"),Ve=m(),xe=l("p"),kt=r("Nearly every NLP task begins with a tokenizer. A tokenizer converts your input into a format that can be processed by the model."),Ue=m(),pe=l("p"),vt=r("Load a tokenizer with "),Te=l("a"),_t=r("AutoTokenizer.from_pretrained()"),wt=r(":"),We=m(),C(we.$$.fragment),Je=m(),qe=l("p"),bt=r("Then tokenize your input as shown below:"),Ke=m(),C(be.$$.fragment),Qe=m(),le=l("h2"),fe=l("a"),Ne=l("span"),C(ye.$$.fragment),yt=m(),Ie=l("span"),gt=r("AutoFeatureExtractor"),Xe=m(),Me=l("p"),At=r("For audio and vision tasks, a feature extractor processes the audio signal or image into the correct input format."),Ye=m(),ue=l("p"),jt=r("Load a feature extractor with "),Pe=l("a"),Et=r("AutoFeatureExtractor.from_pretrained()"),Ft=r(":"),Ze=m(),C(ge.$$.fragment),et=m(),ie=l("h2"),he=l("a"),Oe=l("span"),C(Ae.$$.fragment),xt=m(),De=l("span"),Tt=r("AutoProcessor"),tt=m(),me=l("p"),qt=r("Multimodal tasks require a processor that combines two types of preprocessing tools. For example, the "),Ce=l("a"),Mt=r("LayoutLMV2"),Pt=r(" model requires a feature extractor to handle images and a tokenizer to handle text; a processor combines both of them."),at=m(),de=l("p"),Ct=r("Load a processor with "),ze=l("a"),zt=r("AutoProcessor.from_pretrained()"),Lt=r(":"),st=m(),C(je.$$.fragment),rt=m(),ce=l("h2"),$e=l("a"),He=l("span"),C(Ee.$$.fragment),St=m(),Re=l("span"),Nt=r("AutoModel"),ot=m(),C(ke.$$.fragment),this.h()},l(e){const u=ka('[data-svelte="svelte-1phssyn"]',document.head);n=i(u,"META",{name:!0,content:!0}),u.forEach(t),b=d(e),p=i(e,"H1",{class:!0});var Fe=c(p);v=i(Fe,"A",{id:!0,class:!0,href:!0});var Be=c(v);g=i(Be,"SPAN",{});var It=c(g);z(_.$$.fragment,It),It.forEach(t),Be.forEach(t),D=d(Fe),q=i(Fe,"SPAN",{});var Ot=c(q);A=o(Ot,"Load pretrained instances with an AutoClass"),Ot.forEach(t),Fe.forEach(t),j=d(e),E=i(e,"P",{});var Le=c(E);O=o(Le,"With so many different Transformer architectures, it can be challenging to create one for your checkpoint. As a part of \u{1F917} Transformers core philosophy to make the library easy, simple and flexible to use, an "),F=i(Le,"CODE",{});var Dt=c(F);B=o(Dt,"AutoClass"),Dt.forEach(t),M=o(Le," automatically infer and load the correct architecture from a given checkpoint. The "),G=i(Le,"CODE",{});var Ht=c(G);V=o(Ht,"from_pretrained"),Ht.forEach(t),x=o(Le," method lets you quickly load a pretrained model for any architecture so you don\u2019t have to devote time and resources to train a model from scratch. Producing this type of checkpoint-agnostic code means if your code works for one checkpoint, it will work with another checkpoint - as long as it was trained for a similar task - even if the architecture is different."),Le.forEach(t),H=d(e),z($.$$.fragment,e),Q=d(e),T=i(e,"P",{});var Rt=c(T);Z=o(Rt,"In this tutorial, learn to:"),Rt.forEach(t),X=d(e),y=i(e,"UL",{});var ve=c(y);U=i(ve,"LI",{});var Bt=c(U);ee=o(Bt,"Load a pretrained tokenizer."),Bt.forEach(t),P=d(ve),W=i(ve,"LI",{});var Gt=c(W);te=o(Gt,"Load a pretrained feature extractor."),Gt.forEach(t),J=d(ve),s=i(ve,"LI",{});var Vt=c(s);h=o(Vt,"Load a pretrained processor."),Vt.forEach(t),oe=d(ve),ae=i(ve,"LI",{});var Ut=c(ae);ne=o(Ut,"Load a pretrained model."),Ut.forEach(t),ve.forEach(t),re=d(e),w=i(e,"H2",{class:!0});var lt=c(w);R=i(lt,"A",{id:!0,class:!0,href:!0});var Wt=c(R);se=i(Wt,"SPAN",{});var Jt=c(se);z(K.$$.fragment,Jt),Jt.forEach(t),Wt.forEach(t),dt=d(lt),Se=i(lt,"SPAN",{});var Kt=c(Se);$t=o(Kt,"AutoTokenizer"),Kt.forEach(t),lt.forEach(t),Ve=d(e),xe=i(e,"P",{});var Qt=c(xe);kt=o(Qt,"Nearly every NLP task begins with a tokenizer. A tokenizer converts your input into a format that can be processed by the model."),Qt.forEach(t),Ue=d(e),pe=i(e,"P",{});var it=c(pe);vt=o(it,"Load a tokenizer with "),Te=i(it,"A",{href:!0});var Xt=c(Te);_t=o(Xt,"AutoTokenizer.from_pretrained()"),Xt.forEach(t),wt=o(it,":"),it.forEach(t),We=d(e),z(we.$$.fragment,e),Je=d(e),qe=i(e,"P",{});var Yt=c(qe);bt=o(Yt,"Then tokenize your input as shown below:"),Yt.forEach(t),Ke=d(e),z(be.$$.fragment,e),Qe=d(e),le=i(e,"H2",{class:!0});var ct=c(le);fe=i(ct,"A",{id:!0,class:!0,href:!0});var Zt=c(fe);Ne=i(Zt,"SPAN",{});var ea=c(Ne);z(ye.$$.fragment,ea),ea.forEach(t),Zt.forEach(t),yt=d(ct),Ie=i(ct,"SPAN",{});var ta=c(Ie);gt=o(ta,"AutoFeatureExtractor"),ta.forEach(t),ct.forEach(t),Xe=d(e),Me=i(e,"P",{});var aa=c(Me);At=o(aa,"For audio and vision tasks, a feature extractor processes the audio signal or image into the correct input format."),aa.forEach(t),Ye=d(e),ue=i(e,"P",{});var pt=c(ue);jt=o(pt,"Load a feature extractor with "),Pe=i(pt,"A",{href:!0});var sa=c(Pe);Et=o(sa,"AutoFeatureExtractor.from_pretrained()"),sa.forEach(t),Ft=o(pt,":"),pt.forEach(t),Ze=d(e),z(ge.$$.fragment,e),et=d(e),ie=i(e,"H2",{class:!0});var ft=c(ie);he=i(ft,"A",{id:!0,class:!0,href:!0});var ra=c(he);Oe=i(ra,"SPAN",{});var oa=c(Oe);z(Ae.$$.fragment,oa),oa.forEach(t),ra.forEach(t),xt=d(ft),De=i(ft,"SPAN",{});var na=c(De);Tt=o(na,"AutoProcessor"),na.forEach(t),ft.forEach(t),tt=d(e),me=i(e,"P",{});var ut=c(me);qt=o(ut,"Multimodal tasks require a processor that combines two types of preprocessing tools. For example, the "),Ce=i(ut,"A",{href:!0});var la=c(Ce);Mt=o(la,"LayoutLMV2"),la.forEach(t),Pt=o(ut," model requires a feature extractor to handle images and a tokenizer to handle text; a processor combines both of them."),ut.forEach(t),at=d(e),de=i(e,"P",{});var ht=c(de);Ct=o(ht,"Load a processor with "),ze=i(ht,"A",{href:!0});var ia=c(ze);zt=o(ia,"AutoProcessor.from_pretrained()"),ia.forEach(t),Lt=o(ht,":"),ht.forEach(t),st=d(e),z(je.$$.fragment,e),rt=d(e),ce=i(e,"H2",{class:!0});var mt=c(ce);$e=i(mt,"A",{id:!0,class:!0,href:!0});var ca=c($e);He=i(ca,"SPAN",{});var pa=c(He);z(Ee.$$.fragment,pa),pa.forEach(t),ca.forEach(t),St=d(mt),Re=i(mt,"SPAN",{});var fa=c(Re);Nt=o(fa,"AutoModel"),fa.forEach(t),mt.forEach(t),ot=d(e),z(ke.$$.fragment,e),this.h()},h(){k(n,"name","hf:doc:metadata"),k(n,"content",JSON.stringify(Fa)),k(v,"id","load-pretrained-instances-with-an-autoclass"),k(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(v,"href","#load-pretrained-instances-with-an-autoclass"),k(p,"class","relative group"),k(R,"id","autotokenizer"),k(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(R,"href","#autotokenizer"),k(w,"class","relative group"),k(Te,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),k(fe,"id","autofeatureextractor"),k(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(fe,"href","#autofeatureextractor"),k(le,"class","relative group"),k(Pe,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),k(he,"id","autoprocessor"),k(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(he,"href","#autoprocessor"),k(ie,"class","relative group"),k(Ce,"href","model_doc/layoutlmv2"),k(ze,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),k($e,"id","automodel"),k($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k($e,"href","#automodel"),k(ce,"class","relative group")},m(e,u){a(document.head,n),f(e,b,u),f(e,p,u),a(p,v),a(v,g),L(_,g,null),a(p,D),a(p,q),a(q,A),f(e,j,u),f(e,E,u),a(E,O),a(E,F),a(F,B),a(E,M),a(E,G),a(G,V),a(E,x),f(e,H,u),L($,e,u),f(e,Q,u),f(e,T,u),a(T,Z),f(e,X,u),f(e,y,u),a(y,U),a(U,ee),a(y,P),a(y,W),a(W,te),a(y,J),a(y,s),a(s,h),a(y,oe),a(y,ae),a(ae,ne),f(e,re,u),f(e,w,u),a(w,R),a(R,se),L(K,se,null),a(w,dt),a(w,Se),a(Se,$t),f(e,Ve,u),f(e,xe,u),a(xe,kt),f(e,Ue,u),f(e,pe,u),a(pe,vt),a(pe,Te),a(Te,_t),a(pe,wt),f(e,We,u),L(we,e,u),f(e,Je,u),f(e,qe,u),a(qe,bt),f(e,Ke,u),L(be,e,u),f(e,Qe,u),f(e,le,u),a(le,fe),a(fe,Ne),L(ye,Ne,null),a(le,yt),a(le,Ie),a(Ie,gt),f(e,Xe,u),f(e,Me,u),a(Me,At),f(e,Ye,u),f(e,ue,u),a(ue,jt),a(ue,Pe),a(Pe,Et),a(ue,Ft),f(e,Ze,u),L(ge,e,u),f(e,et,u),f(e,ie,u),a(ie,he),a(he,Oe),L(Ae,Oe,null),a(ie,xt),a(ie,De),a(De,Tt),f(e,tt,u),f(e,me,u),a(me,qt),a(me,Ce),a(Ce,Mt),a(me,Pt),f(e,at,u),f(e,de,u),a(de,Ct),a(de,ze),a(ze,zt),a(de,Lt),f(e,st,u),L(je,e,u),f(e,rt,u),f(e,ce,u),a(ce,$e),a($e,He),L(Ee,He,null),a(ce,St),a(ce,Re),a(Re,Nt),f(e,ot,u),L(ke,e,u),nt=!0},p(e,[u]){const Fe={};u&2&&(Fe.$$scope={dirty:u,ctx:e}),$.$set(Fe);const Be={};u&2&&(Be.$$scope={dirty:u,ctx:e}),ke.$set(Be)},i(e){nt||(S(_.$$.fragment,e),S($.$$.fragment,e),S(K.$$.fragment,e),S(we.$$.fragment,e),S(be.$$.fragment,e),S(ye.$$.fragment,e),S(ge.$$.fragment,e),S(Ae.$$.fragment,e),S(je.$$.fragment,e),S(Ee.$$.fragment,e),S(ke.$$.fragment,e),nt=!0)},o(e){N(_.$$.fragment,e),N($.$$.fragment,e),N(K.$$.fragment,e),N(we.$$.fragment,e),N(be.$$.fragment,e),N(ye.$$.fragment,e),N(ge.$$.fragment,e),N(Ae.$$.fragment,e),N(je.$$.fragment,e),N(Ee.$$.fragment,e),N(ke.$$.fragment,e),nt=!1},d(e){t(n),e&&t(b),e&&t(p),I(_),e&&t(j),e&&t(E),e&&t(H),I($,e),e&&t(Q),e&&t(T),e&&t(X),e&&t(y),e&&t(re),e&&t(w),I(K),e&&t(Ve),e&&t(xe),e&&t(Ue),e&&t(pe),e&&t(We),I(we,e),e&&t(Je),e&&t(qe),e&&t(Ke),I(be,e),e&&t(Qe),e&&t(le),I(ye),e&&t(Xe),e&&t(Me),e&&t(Ye),e&&t(ue),e&&t(Ze),I(ge,e),e&&t(et),e&&t(ie),I(Ae),e&&t(tt),e&&t(me),e&&t(at),e&&t(de),e&&t(st),I(je,e),e&&t(rt),e&&t(ce),I(Ee),e&&t(ot),I(ke,e)}}}const Fa={local:"load-pretrained-instances-with-an-autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"autofeatureextractor",title:"AutoFeatureExtractor"},{local:"autoprocessor",title:"AutoProcessor"},{local:"automodel",title:"AutoModel"}],title:"Load pretrained instances with an AutoClass"};function xa(Y){return va(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class za extends ma{constructor(n){super();da(this,n,xa,Ea,$a,{})}}export{za as default,Fa as metadata};
