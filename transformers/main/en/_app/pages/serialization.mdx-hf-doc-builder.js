import{S as Lm,i as Am,s as Im,e as a,k as p,w as k,t as s,M as Pm,c as l,d as o,m as f,a as r,x as y,h as n,b as _,G as e,g as d,y as O,q as T,o as N,B as j,v as Bm,L as Dm}from"../chunks/vendor-hf-doc-builder.js";import{T as $o}from"../chunks/Tip-hf-doc-builder.js";import{I as ze}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as B}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as Mm,M as qm}from"../chunks/Markdown-hf-doc-builder.js";function Xm(M){let c,w,m,E,$;return{c(){c=a("p"),w=s(`Once exported, a model can be optimized for inference via techniques such as
quantization and pruning. If you are interested in optimizing your models to run with
maximum efficiency, check out the `),m=a("a"),E=s(`\u{1F917} Optimum
library`),$=s("."),this.h()},l(v){c=l(v,"P",{});var x=r(c);w=n(x,`Once exported, a model can be optimized for inference via techniques such as
quantization and pruning. If you are interested in optimizing your models to run with
maximum efficiency, check out the `),m=l(x,"A",{href:!0,rel:!0});var b=r(m);E=n(b,`\u{1F917} Optimum
library`),b.forEach(o),$=n(x,"."),x.forEach(o),this.h()},h(){_(m,"href","https://github.com/huggingface/optimum"),_(m,"rel","nofollow")},m(v,x){d(v,c,x),e(c,w),e(c,m),e(m,E),e(c,$)},d(v){v&&o(c)}}}function Rm(M){let c,w,m,E,$,v,x,b,q,C,A,L,I;return c=new B({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load tokenizer and PyTorch weights form the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
pt_model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-pt-checkpoint")
pt_model.save_pretrained("local-pt-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and PyTorch weights form the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)`}}),L=new B({props:{code:"python -m transformers.onnx --model=local-pt-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-pt-checkpoint onnx/"}}),{c(){k(c.$$.fragment),w=p(),m=a("p"),E=s("Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=a("code"),v=s("--model"),x=s(`
argument of the `),b=a("code"),q=s("transformers.onnx"),C=s(" package to the desired directory:"),A=p(),k(L.$$.fragment)},l(g){y(c.$$.fragment,g),w=f(g),m=l(g,"P",{});var D=r(m);E=n(D,"Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=l(D,"CODE",{});var R=r($);v=n(R,"--model"),R.forEach(o),x=n(D,`
argument of the `),b=l(D,"CODE",{});var X=r(b);q=n(X,"transformers.onnx"),X.forEach(o),C=n(D," package to the desired directory:"),D.forEach(o),A=f(g),y(L.$$.fragment,g)},m(g,D){O(c,g,D),d(g,w,D),d(g,m,D),e(m,E),e(m,$),e($,v),e(m,x),e(m,b),e(b,q),e(m,C),d(g,A,D),O(L,g,D),I=!0},p:Dm,i(g){I||(T(c.$$.fragment,g),T(L.$$.fragment,g),I=!0)},o(g){N(c.$$.fragment,g),N(L.$$.fragment,g),I=!1},d(g){j(c,g),g&&o(w),g&&o(m),g&&o(A),j(L,g)}}}function Fm(M){let c,w;return c=new qm({props:{$$slots:{default:[Rm]},$$scope:{ctx:M}}}),{c(){k(c.$$.fragment)},l(m){y(c.$$.fragment,m)},m(m,E){O(c,m,E),w=!0},p(m,E){const $={};E&2&&($.$$scope={dirty:E,ctx:m}),c.$set($)},i(m){w||(T(c.$$.fragment,m),w=!0)},o(m){N(c.$$.fragment,m),w=!1},d(m){j(c,m)}}}function Sm(M){let c,w,m,E,$,v,x,b,q,C,A,L,I;return c=new B({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

# Load tokenizer and TensorFlow weights from the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tf_model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-tf-checkpoint")
tf_model.save_pretrained("local-tf-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and TensorFlow weights from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)`}}),L=new B({props:{code:"python -m transformers.onnx --model=local-tf-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-tf-checkpoint onnx/"}}),{c(){k(c.$$.fragment),w=p(),m=a("p"),E=s("Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=a("code"),v=s("--model"),x=s(`
argument of the `),b=a("code"),q=s("transformers.onnx"),C=s(" package to the desired directory:"),A=p(),k(L.$$.fragment)},l(g){y(c.$$.fragment,g),w=f(g),m=l(g,"P",{});var D=r(m);E=n(D,"Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=l(D,"CODE",{});var R=r($);v=n(R,"--model"),R.forEach(o),x=n(D,`
argument of the `),b=l(D,"CODE",{});var X=r(b);q=n(X,"transformers.onnx"),X.forEach(o),C=n(D," package to the desired directory:"),D.forEach(o),A=f(g),y(L.$$.fragment,g)},m(g,D){O(c,g,D),d(g,w,D),d(g,m,D),e(m,E),e(m,$),e($,v),e(m,x),e(m,b),e(b,q),e(m,C),d(g,A,D),O(L,g,D),I=!0},p:Dm,i(g){I||(T(c.$$.fragment,g),T(L.$$.fragment,g),I=!0)},o(g){N(c.$$.fragment,g),N(L.$$.fragment,g),I=!1},d(g){j(c,g),g&&o(w),g&&o(m),g&&o(A),j(L,g)}}}function zm(M){let c,w;return c=new qm({props:{$$slots:{default:[Sm]},$$scope:{ctx:M}}}),{c(){k(c.$$.fragment)},l(m){y(c.$$.fragment,m)},m(m,E){O(c,m,E),w=!0},p(m,E){const $={};E&2&&($.$$scope={dirty:E,ctx:m}),c.$set($)},i(m){w||(T(c.$$.fragment,m),w=!0)},o(m){N(c.$$.fragment,m),w=!1},d(m){j(c,m)}}}function Hm(M){let c,w,m,E,$,v,x,b;return{c(){c=a("p"),w=s("The features that have a "),m=a("code"),E=s("with-past"),$=s(" suffix (like "),v=a("code"),x=s("causal-lm-with-past"),b=s(`) correspond to
model classes with precomputed hidden states (key and values in the attention blocks)
that can be used for fast autoregressive decoding.`)},l(q){c=l(q,"P",{});var C=r(c);w=n(C,"The features that have a "),m=l(C,"CODE",{});var A=r(m);E=n(A,"with-past"),A.forEach(o),$=n(C," suffix (like "),v=l(C,"CODE",{});var L=r(v);x=n(L,"causal-lm-with-past"),L.forEach(o),b=n(C,`) correspond to
model classes with precomputed hidden states (key and values in the attention blocks)
that can be used for fast autoregressive decoding.`),C.forEach(o)},m(q,C){d(q,c,C),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b)},d(q){q&&o(c)}}}function Vm(M){let c,w,m,E,$;return{c(){c=a("p"),w=s(`A good way to implement a custom ONNX configuration is to look at the existing
implementation in the `),m=a("code"),E=s("configuration_<model_name>.py"),$=s(" file of a similar architecture.")},l(v){c=l(v,"P",{});var x=r(c);w=n(x,`A good way to implement a custom ONNX configuration is to look at the existing
implementation in the `),m=l(x,"CODE",{});var b=r(m);E=n(b,"configuration_<model_name>.py"),b.forEach(o),$=n(x," file of a similar architecture."),x.forEach(o)},m(v,x){d(v,c,x),e(c,w),e(c,m),e(m,E),e(c,$)},d(v){v&&o(c)}}}function Wm(M){let c,w,m,E,$,v,x,b,q,C,A,L,I,g,D,R,X,Q,W,He,K,Ve,We;return{c(){c=a("p"),w=s("Notice that "),m=a("code"),E=s("inputs"),$=s(" property for "),v=a("code"),x=s("DistilBertOnnxConfig"),b=s(" returns an "),q=a("code"),C=s("OrderedDict"),A=s(`. This
ensures that the inputs are matched with their relative position within the
`),L=a("code"),I=s("PreTrainedModel.forward()"),g=s(` method when tracing the graph. We recommend using an
`),D=a("code"),R=s("OrderedDict"),X=s(" for the "),Q=a("code"),W=s("inputs"),He=s(" and "),K=a("code"),Ve=s("outputs"),We=s(` properties when implementing custom ONNX
configurations.`)},l(Z){c=l(Z,"P",{});var P=r(c);w=n(P,"Notice that "),m=l(P,"CODE",{});var Xt=r(m);E=n(Xt,"inputs"),Xt.forEach(o),$=n(P," property for "),v=l(P,"CODE",{});var Ge=r(v);x=n(Ge,"DistilBertOnnxConfig"),Ge.forEach(o),b=n(P," returns an "),q=l(P,"CODE",{});var J=r(q);C=n(J,"OrderedDict"),J.forEach(o),A=n(P,`. This
ensures that the inputs are matched with their relative position within the
`),L=l(P,"CODE",{});var Rt=r(L);I=n(Rt,"PreTrainedModel.forward()"),Rt.forEach(o),g=n(P,` method when tracing the graph. We recommend using an
`),D=l(P,"CODE",{});var fe=r(D);R=n(fe,"OrderedDict"),fe.forEach(o),X=n(P," for the "),Q=l(P,"CODE",{});var ve=r(Q);W=n(ve,"inputs"),ve.forEach(o),He=n(P," and "),K=l(P,"CODE",{});var Ft=r(K);Ve=n(Ft,"outputs"),Ft.forEach(o),We=n(P,` properties when implementing custom ONNX
configurations.`),P.forEach(o)},m(Z,P){d(Z,c,P),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b),e(c,q),e(q,C),e(c,A),e(c,L),e(L,I),e(c,g),e(c,D),e(D,R),e(c,X),e(c,Q),e(Q,W),e(c,He),e(c,K),e(K,Ve),e(c,We)},d(Z){Z&&o(c)}}}function Gm(M){let c,w,m,E,$,v,x,b;return{c(){c=a("p"),w=s("All of the base properties and methods associated with "),m=a("a"),E=s("OnnxConfig"),$=s(` and
the other configuration classes can be overriden if needed. Check out `),v=a("code"),x=s("BartOnnxConfig"),b=s(`
for an advanced example.`),this.h()},l(q){c=l(q,"P",{});var C=r(c);w=n(C,"All of the base properties and methods associated with "),m=l(C,"A",{href:!0});var A=r(m);E=n(A,"OnnxConfig"),A.forEach(o),$=n(C,` and
the other configuration classes can be overriden if needed. Check out `),v=l(C,"CODE",{});var L=r(v);x=n(L,"BartOnnxConfig"),L.forEach(o),b=n(C,`
for an advanced example.`),C.forEach(o),this.h()},h(){_(m,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig")},m(q,C){d(q,c,C),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b)},d(q){q&&o(c)}}}function Ym(M){let c,w,m,E,$,v,x,b,q,C,A;return{c(){c=a("p"),w=s(`If your model is larger than 2GB, you will see that many additional files are created
during the export. This is `),m=a("em"),E=s("expected"),$=s(" because ONNX uses "),v=a("a"),x=s(`Protocol
Buffers`),b=s(` to store the model and these
have a size limit of 2GB. See the `),q=a("a"),C=s(`ONNX
documentation`),A=s(` for
instructions on how to load models with external data.`),this.h()},l(L){c=l(L,"P",{});var I=r(c);w=n(I,`If your model is larger than 2GB, you will see that many additional files are created
during the export. This is `),m=l(I,"EM",{});var g=r(m);E=n(g,"expected"),g.forEach(o),$=n(I," because ONNX uses "),v=l(I,"A",{href:!0,rel:!0});var D=r(v);x=n(D,`Protocol
Buffers`),D.forEach(o),b=n(I,` to store the model and these
have a size limit of 2GB. See the `),q=l(I,"A",{href:!0,rel:!0});var R=r(q);C=n(R,`ONNX
documentation`),R.forEach(o),A=n(I,` for
instructions on how to load models with external data.`),I.forEach(o),this.h()},h(){_(v,"href","https://developers.google.com/protocol-buffers/"),_(v,"rel","nofollow"),_(q,"href","https://github.com/onnx/onnx/blob/master/docs/ExternalData.md"),_(q,"rel","nofollow")},m(L,I){d(L,c,I),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b),e(c,q),e(q,C),e(c,A)},d(L){L&&o(c)}}}function Um(M){let c,w,m,E,$,v,x,b,q,C,A,L,I,g,D,R,X,Q,W,He,K,Ve,We,Z,P,Xt,Ge,J,Rt,fe,ve,Ft,Yl,sa,St,Ul,na,h,xo,Kl,Jl,bo,Ql,Zl,ko,er,tr,yo,or,sr,Oo,nr,ar,To,lr,rr,No,ir,pr,jo,fr,dr,Co,cr,hr,Do,ur,mr,qo,gr,_r,Lo,vr,Er,Ao,wr,$r,Io,xr,br,Po,kr,yr,Bo,Or,Tr,Mo,Nr,jr,Xo,Cr,Dr,Ro,qr,Lr,Fo,Ar,Ir,So,Pr,Br,zo,Mr,Xr,Ho,Rr,Fr,Vo,Sr,zr,Wo,Hr,Vr,Go,Wr,Gr,Yo,Yr,Ur,Uo,Kr,Jr,Ko,Qr,Zr,Jo,ei,ti,Qo,oi,si,Zo,ni,ai,es,li,ri,ts,ii,pi,os,fi,di,ss,ci,hi,ns,ui,mi,as,gi,_i,ls,vi,Ei,rs,wi,$i,is,xi,bi,ps,ki,yi,fs,Oi,Ti,ds,Ni,ji,cs,Ci,Di,hs,qi,Li,us,Ai,Ii,ms,Pi,Bi,gs,Mi,Xi,_s,Ri,Fi,vs,Si,zi,Es,Hi,Vi,ws,Wi,Gi,$s,Yi,Ui,xs,Ki,aa,zt,Ji,la,Ee,Ye,Qi,bs,Zi,ep,tp,ks,op,ra,de,we,ys,Ue,sp,Os,np,ia,Ht,ap,pa,Ke,fa,$e,lp,Ts,rp,ip,da,Je,ca,Vt,pp,ha,Qe,ua,Wt,fp,ma,Ze,ga,ee,dp,Ns,cp,hp,js,up,mp,_a,G,gp,Cs,_p,vp,et,Ep,wp,tt,$p,xp,va,ot,Ea,xe,bp,Ds,kp,yp,wa,st,$a,be,Op,nt,Tp,Np,xa,at,ba,Gt,jp,ka,ke,ya,ce,ye,qs,lt,Cp,Ls,Dp,Oa,te,qp,As,Lp,Ap,Is,Ip,Pp,Ta,Oe,Ps,rt,Bs,Bp,Mp,Ms,Xp,Rp,F,it,pt,Xs,Fp,Sp,Rs,zp,Hp,Fs,Ss,Vp,Wp,ft,dt,zs,Gp,Yp,Hs,Up,Kp,Vs,Ws,Jp,Qp,ct,Gs,Ys,Zp,ef,Us,Ks,tf,of,ht,Js,Qs,sf,nf,Zs,en,af,lf,ut,mt,tn,rf,pf,on,ff,df,sn,nn,cf,hf,gt,an,ln,uf,mf,rn,pn,gf,_f,_t,fn,dn,vf,Ef,cn,hn,wf,Na,Te,$f,Yt,xf,bf,ja,vt,Ca,oe,kf,un,yf,Of,mn,Tf,Nf,Da,Et,qa,Ut,jf,La,wt,Aa,Y,Cf,gn,Df,qf,_n,Lf,Af,vn,If,Pf,Ia,Ne,Pa,he,je,En,$t,Bf,wn,Mf,Ba,Kt,Xf,Ma,se,$n,Rf,Ff,xn,Sf,zf,bn,Hf,Xa,Jt,Vf,Ra,ue,Ce,kn,xt,Wf,yn,Gf,Fa,Qt,Yf,Sa,ne,Zt,Uf,eo,Kf,Jf,to,Qf,oo,Zf,ed,so,td,no,od,za,De,Ha,qe,sd,On,nd,ad,Va,bt,Wa,z,ld,Tn,rd,id,Nn,pd,fd,jn,dd,cd,Cn,hd,ud,Ga,Le,Ya,ao,md,Ua,kt,Ka,lo,gd,Ja,yt,Qa,ro,_d,Za,Ot,el,H,vd,Dn,Ed,wd,qn,$d,xd,Ln,bd,kd,An,yd,Od,tl,Tt,ol,Ae,sl,me,Ie,In,Nt,Td,Pn,Nd,nl,ae,jd,Bn,Cd,Dd,Mn,qd,Ld,al,jt,ll,S,Ad,Xn,Id,Pd,Rn,Bd,Md,Fn,Xd,Rd,Sn,Fd,Sd,zn,zd,Hd,rl,Ct,il,Pe,pl,ge,Be,Hn,Dt,Vd,Vn,Wd,fl,le,Gd,Wn,Yd,Ud,Gn,Kd,Jd,dl,qt,cl,Me,Qd,io,Zd,ec,hl,_e,Xe,Yn,Lt,tc,Un,oc,ul,po,sc,ml,re,At,nc,Kn,ac,lc,rc,fo,ic,Jn,pc,fc,co,dc,Qn,cc,gl,Re,hc,It,uc,mc,_l;return v=new ze({}),X=new $o({props:{$$slots:{default:[Xm]},$$scope:{ctx:M}}}),Ue=new ze({}),Ke=new B({props:{code:"pip install transformers[onnx]",highlighted:"pip install transformers[onnx]"}}),Je=new B({props:{code:`python -m transformers.onnx --help

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating where to store generated ONNX model.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The type of features to export the model with.
  --opset OPSET         ONNX opset version to export the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`,highlighted:`python -m transformers.onnx --<span class="hljs-built_in">help</span>

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating <span class="hljs-built_in">where</span> to store generated ONNX model.

optional arguments:
  -h, --<span class="hljs-built_in">help</span>            show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span>
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The <span class="hljs-built_in">type</span> of features to <span class="hljs-built_in">export</span> the model with.
  --opset OPSET         ONNX opset version to <span class="hljs-built_in">export</span> the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`}}),Qe=new B({props:{code:"python -m transformers.onnx --model=distilbert-base-uncased onnx/",highlighted:"python -m transformers.onnx --model=distilbert-base-uncased onnx/"}}),Ze=new B({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'last_hidden_state'})
        - Validating ONNX Model output "last_hidden_state":
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;last_hidden_state&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;last_hidden_state&quot;</span>:
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),ot=new B({props:{code:`from transformers import AutoTokenizer
from onnxruntime import InferenceSession

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
session = InferenceSession("onnx/model.onnx")
# ONNX Runtime expects NumPy arrays as input
inputs = tokenizer("Using DistilBERT with ONNX Runtime!", return_tensors="np")
outputs = session.run(output_names=["last_hidden_state"], input_feed=dict(inputs))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> onnxruntime <span class="hljs-keyword">import</span> InferenceSession

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>session = InferenceSession(<span class="hljs-string">&quot;onnx/model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ONNX Runtime expects NumPy arrays as input</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = session.run(output_names=[<span class="hljs-string">&quot;last_hidden_state&quot;</span>], input_feed=<span class="hljs-built_in">dict</span>(inputs))`}}),st=new B({props:{code:`from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig

config = DistilBertConfig()
onnx_config = DistilBertOnnxConfig(config)
print(list(onnx_config.outputs.keys()))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.models.distilbert <span class="hljs-keyword">import</span> DistilBertConfig, DistilBertOnnxConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(onnx_config.outputs.keys()))
[<span class="hljs-string">&quot;last_hidden_state&quot;</span>]`}}),at=new B({props:{code:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/",highlighted:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/"}}),ke=new Mm({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[zm],pytorch:[Fm]},$$scope:{ctx:M}}}),lt=new ze({}),vt=new B({props:{code:`from transformers.onnx.features import FeaturesManager

distilbert_features = list(FeaturesManager.get_supported_features_for_model_type("distilbert").keys())
print(distilbert_features)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx.features <span class="hljs-keyword">import</span> FeaturesManager

<span class="hljs-meta">&gt;&gt;&gt; </span>distilbert_features = <span class="hljs-built_in">list</span>(FeaturesManager.get_supported_features_for_model_type(<span class="hljs-string">&quot;distilbert&quot;</span>).keys())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(distilbert_features)
[<span class="hljs-string">&quot;default&quot;</span>, <span class="hljs-string">&quot;masked-lm&quot;</span>, <span class="hljs-string">&quot;causal-lm&quot;</span>, <span class="hljs-string">&quot;sequence-classification&quot;</span>, <span class="hljs-string">&quot;token-classification&quot;</span>, <span class="hljs-string">&quot;question-answering&quot;</span>]`}}),Et=new B({props:{code:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`,highlighted:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`}}),wt=new B({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'logits'})
        - Validating ONNX Model output "logits":
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;logits&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;logits&quot;</span>:
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),Ne=new $o({props:{$$slots:{default:[Hm]},$$scope:{ctx:M}}}),$t=new ze({}),xt=new ze({}),De=new $o({props:{$$slots:{default:[Vm]},$$scope:{ctx:M}}}),bt=new B({props:{code:`from typing import Mapping, OrderedDict
from transformers.onnx import OnnxConfig


class DistilBertOnnxConfig(OnnxConfig):
    @property
    def inputs(self) -> Mapping[str, Mapping[int, str]]:
        return OrderedDict(
            [
                ("input_ids", {0: "batch", 1: "sequence"}),
                ("attention_mask", {0: "batch", 1: "sequence"}),
            ]
        )`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Mapping, OrderedDict
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> OnnxConfig


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistilBertOnnxConfig</span>(<span class="hljs-title class_ inherited__">OnnxConfig</span>):
<span class="hljs-meta">... </span>    @<span class="hljs-built_in">property</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inputs</span>(<span class="hljs-params">self</span>) -&gt; Mapping[<span class="hljs-built_in">str</span>, Mapping[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>]]:
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> OrderedDict(
<span class="hljs-meta">... </span>            [
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;input_ids&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;attention_mask&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>            ]
<span class="hljs-meta">... </span>        )`}}),Le=new $o({props:{$$slots:{default:[Wm]},$$scope:{ctx:M}}}),kt=new B({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config = DistilBertOnnxConfig(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)`}}),yt=new B({props:{code:"print(onnx_config.default_onnx_opset)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.default_onnx_opset)
<span class="hljs-number">11</span>`}}),Ot=new B({props:{code:"print(onnx_config.outputs)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.outputs)
OrderedDict([(<span class="hljs-string">&quot;last_hidden_state&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>})])`}}),Tt=new B({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task="sequence-classification")
print(onnx_config_for_seq_clf.outputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=<span class="hljs-string">&quot;sequence-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config_for_seq_clf.outputs)
OrderedDict([(<span class="hljs-string">&#x27;logits&#x27;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;batch&#x27;</span>})])`}}),Ae=new $o({props:{$$slots:{default:[Gm]},$$scope:{ctx:M}}}),Nt=new ze({}),jt=new B({props:{code:`from pathlib import Path
from transformers.onnx import export
from transformers import AutoTokenizer, AutoModel

onnx_path = Path("model.onnx")
model_ckpt = "distilbert-base-uncased"
base_model = AutoModel.from_pretrained(model_ckpt)
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> export
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_path = Path(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model_ckpt = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>base_model = AutoModel.from_pretrained(model_ckpt)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`}}),Ct=new B({props:{code:`import onnx

onnx_model = onnx.load("model.onnx")
onnx.checker.check_model(onnx_model)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> onnx

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_model = onnx.load(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx.checker.check_model(onnx_model)`}}),Pe=new $o({props:{$$slots:{default:[Ym]},$$scope:{ctx:M}}}),Dt=new ze({}),qt=new B({props:{code:`from transformers.onnx import validate_model_outputs

validate_model_outputs(
    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> validate_model_outputs

<span class="hljs-meta">&gt;&gt;&gt; </span>validate_model_outputs(
<span class="hljs-meta">... </span>    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
<span class="hljs-meta">... </span>)`}}),Lt=new ze({}),{c(){c=a("meta"),w=p(),m=a("h1"),E=a("a"),$=a("span"),k(v.$$.fragment),x=p(),b=a("span"),q=s("Export to ONNX"),C=p(),A=a("p"),L=s(`If you need to deploy \u{1F917} Transformers models in production environments, we recommend
exporting them to a serialized format that can be loaded and executed on specialized
runtimes and hardware. In this guide, we\u2019ll show you how to export \u{1F917} Transformers
models to `),I=a("a"),g=s("ONNX (Open Neural Network eXchange)"),D=s("."),R=p(),k(X.$$.fragment),Q=p(),W=a("p"),He=s(`ONNX is an open standard that defines a common set of operators and a common file format
to represent deep learning models in a wide variety of frameworks, including PyTorch and
TensorFlow. When a model is exported to the ONNX format, these operators are used to
construct a computational graph (often called an `),K=a("em"),Ve=s("intermediate representation"),We=s(`) which
represents the flow of data through the neural network.`),Z=p(),P=a("p"),Xt=s(`By exposing a graph with standardized operators and data types, ONNX makes it easy to
switch between frameworks. For example, a model trained in PyTorch can be exported to
ONNX format and then imported in TensorFlow (and vice versa).`),Ge=p(),J=a("p"),Rt=s("\u{1F917} Transformers provides a "),fe=a("a"),ve=a("code"),Ft=s("transformers.onnx"),Yl=s(` package that enables
you to convert model checkpoints to an ONNX graph by leveraging configuration objects.
These configuration objects come ready made for a number of model architectures, and are
designed to be easily extendable to other architectures.`),sa=p(),St=a("p"),Ul=s("Ready-made configurations include the following architectures:"),na=p(),h=a("ul"),xo=a("li"),Kl=s("ALBERT"),Jl=p(),bo=a("li"),Ql=s("BART"),Zl=p(),ko=a("li"),er=s("BEiT"),tr=p(),yo=a("li"),or=s("BERT"),sr=p(),Oo=a("li"),nr=s("BigBird"),ar=p(),To=a("li"),lr=s("BigBird-Pegasus"),rr=p(),No=a("li"),ir=s("Blenderbot"),pr=p(),jo=a("li"),fr=s("BlenderbotSmall"),dr=p(),Co=a("li"),cr=s("BLOOM"),hr=p(),Do=a("li"),ur=s("CamemBERT"),mr=p(),qo=a("li"),gr=s("CLIP"),_r=p(),Lo=a("li"),vr=s("CodeGen"),Er=p(),Ao=a("li"),wr=s("Conditional DETR"),$r=p(),Io=a("li"),xr=s("ConvBERT"),br=p(),Po=a("li"),kr=s("ConvNeXT"),yr=p(),Bo=a("li"),Or=s("Data2VecText"),Tr=p(),Mo=a("li"),Nr=s("Data2VecVision"),jr=p(),Xo=a("li"),Cr=s("DeBERTa"),Dr=p(),Ro=a("li"),qr=s("DeBERTa-v2"),Lr=p(),Fo=a("li"),Ar=s("DeiT"),Ir=p(),So=a("li"),Pr=s("DETR"),Br=p(),zo=a("li"),Mr=s("DistilBERT"),Xr=p(),Ho=a("li"),Rr=s("ELECTRA"),Fr=p(),Vo=a("li"),Sr=s("ERNIE"),zr=p(),Wo=a("li"),Hr=s("FlauBERT"),Vr=p(),Go=a("li"),Wr=s("GPT Neo"),Gr=p(),Yo=a("li"),Yr=s("GPT-J"),Ur=p(),Uo=a("li"),Kr=s("GroupViT"),Jr=p(),Ko=a("li"),Qr=s("I-BERT"),Zr=p(),Jo=a("li"),ei=s("LayoutLM"),ti=p(),Qo=a("li"),oi=s("LayoutLMv3"),si=p(),Zo=a("li"),ni=s("LeViT"),ai=p(),es=a("li"),li=s("Longformer"),ri=p(),ts=a("li"),ii=s("LongT5"),pi=p(),os=a("li"),fi=s("M2M100"),di=p(),ss=a("li"),ci=s("Marian"),hi=p(),ns=a("li"),ui=s("mBART"),mi=p(),as=a("li"),gi=s("MobileBERT"),_i=p(),ls=a("li"),vi=s("MobileViT"),Ei=p(),rs=a("li"),wi=s("MT5"),$i=p(),is=a("li"),xi=s("OpenAI GPT-2"),bi=p(),ps=a("li"),ki=s("OWL-ViT"),yi=p(),fs=a("li"),Oi=s("Perceiver"),Ti=p(),ds=a("li"),Ni=s("PLBart"),ji=p(),cs=a("li"),Ci=s("ResNet"),Di=p(),hs=a("li"),qi=s("RoBERTa"),Li=p(),us=a("li"),Ai=s("RoFormer"),Ii=p(),ms=a("li"),Pi=s("SegFormer"),Bi=p(),gs=a("li"),Mi=s("SqueezeBERT"),Xi=p(),_s=a("li"),Ri=s("T5"),Fi=p(),vs=a("li"),Si=s("ViT"),zi=p(),Es=a("li"),Hi=s("XLM"),Vi=p(),ws=a("li"),Wi=s("XLM-RoBERTa"),Gi=p(),$s=a("li"),Yi=s("XLM-RoBERTa-XL"),Ui=p(),xs=a("li"),Ki=s("YOLOS"),aa=p(),zt=a("p"),Ji=s("In the next two sections, we\u2019ll show you how to:"),la=p(),Ee=a("ul"),Ye=a("li"),Qi=s("Export a supported model using the "),bs=a("code"),Zi=s("transformers.onnx"),ep=s(" package."),tp=p(),ks=a("li"),op=s("Export a custom model for an unsupported architecture."),ra=p(),de=a("h2"),we=a("a"),ys=a("span"),k(Ue.$$.fragment),sp=p(),Os=a("span"),np=s("Exporting a model to ONNX"),ia=p(),Ht=a("p"),ap=s(`To export a \u{1F917} Transformers model to ONNX, you\u2019ll first need to install some extra
dependencies:`),pa=p(),k(Ke.$$.fragment),fa=p(),$e=a("p"),lp=s("The "),Ts=a("code"),rp=s("transformers.onnx"),ip=s(" package can then be used as a Python module:"),da=p(),k(Je.$$.fragment),ca=p(),Vt=a("p"),pp=s("Exporting a checkpoint using a ready-made configuration can be done as follows:"),ha=p(),k(Qe.$$.fragment),ua=p(),Wt=a("p"),fp=s("You should see the following logs:"),ma=p(),k(Ze.$$.fragment),ga=p(),ee=a("p"),dp=s("This exports an ONNX graph of the checkpoint defined by the "),Ns=a("code"),cp=s("--model"),hp=s(` argument. In this
example, it is `),js=a("code"),up=s("distilbert-base-uncased"),mp=s(`, but it can be any checkpoint on the Hugging
Face Hub or one that\u2019s stored locally.`),_a=p(),G=a("p"),gp=s("The resulting "),Cs=a("code"),_p=s("model.onnx"),vp=s(" file can then be run on one of the "),et=a("a"),Ep=s(`many
accelerators`),wp=s(` that support the ONNX
standard. For example, we can load and run the model with `),tt=a("a"),$p=s(`ONNX
Runtime`),xp=s(" as follows:"),va=p(),k(ot.$$.fragment),Ea=p(),xe=a("p"),bp=s("The required output names (like "),Ds=a("code"),kp=s('["last_hidden_state"]'),yp=s(`) can be obtained by taking a
look at the ONNX configuration of each model. For example, for DistilBERT we have:`),wa=p(),k(st.$$.fragment),$a=p(),be=a("p"),Op=s(`The process is identical for TensorFlow checkpoints on the Hub. For example, we can
export a pure TensorFlow checkpoint from the `),nt=a("a"),Tp=s(`Keras
organization`),Np=s(" as follows:"),xa=p(),k(at.$$.fragment),ba=p(),Gt=a("p"),jp=s(`To export a model that\u2019s stored locally, you\u2019ll need to have the model\u2019s weights and
tokenizer files stored in a directory. For example, we can load and save a checkpoint as
follows:`),ka=p(),k(ke.$$.fragment),ya=p(),ce=a("h2"),ye=a("a"),qs=a("span"),k(lt.$$.fragment),Cp=p(),Ls=a("span"),Dp=s("Selecting features for different model tasks"),Oa=p(),te=a("p"),qp=s("Each ready-made configuration comes with a set of "),As=a("em"),Lp=s("features"),Ap=s(` that enable you to export
models for different types of tasks. As shown in the table below, each feature is
associated with a different `),Is=a("code"),Ip=s("AutoClass"),Pp=s(":"),Ta=p(),Oe=a("table"),Ps=a("thead"),rt=a("tr"),Bs=a("th"),Bp=s("Feature"),Mp=p(),Ms=a("th"),Xp=s("Auto Class"),Rp=p(),F=a("tbody"),it=a("tr"),pt=a("td"),Xs=a("code"),Fp=s("causal-lm"),Sp=s(", "),Rs=a("code"),zp=s("causal-lm-with-past"),Hp=p(),Fs=a("td"),Ss=a("code"),Vp=s("AutoModelForCausalLM"),Wp=p(),ft=a("tr"),dt=a("td"),zs=a("code"),Gp=s("default"),Yp=s(", "),Hs=a("code"),Up=s("default-with-past"),Kp=p(),Vs=a("td"),Ws=a("code"),Jp=s("AutoModel"),Qp=p(),ct=a("tr"),Gs=a("td"),Ys=a("code"),Zp=s("masked-lm"),ef=p(),Us=a("td"),Ks=a("code"),tf=s("AutoModelForMaskedLM"),of=p(),ht=a("tr"),Js=a("td"),Qs=a("code"),sf=s("question-answering"),nf=p(),Zs=a("td"),en=a("code"),af=s("AutoModelForQuestionAnswering"),lf=p(),ut=a("tr"),mt=a("td"),tn=a("code"),rf=s("seq2seq-lm"),pf=s(", "),on=a("code"),ff=s("seq2seq-lm-with-past"),df=p(),sn=a("td"),nn=a("code"),cf=s("AutoModelForSeq2SeqLM"),hf=p(),gt=a("tr"),an=a("td"),ln=a("code"),uf=s("sequence-classification"),mf=p(),rn=a("td"),pn=a("code"),gf=s("AutoModelForSequenceClassification"),_f=p(),_t=a("tr"),fn=a("td"),dn=a("code"),vf=s("token-classification"),Ef=p(),cn=a("td"),hn=a("code"),wf=s("AutoModelForTokenClassification"),Na=p(),Te=a("p"),$f=s(`For each configuration, you can find the list of supported features via the
`),Yt=a("a"),xf=s("FeaturesManager"),bf=s(". For example, for DistilBERT we have:"),ja=p(),k(vt.$$.fragment),Ca=p(),oe=a("p"),kf=s("You can then pass one of these features to the "),un=a("code"),yf=s("--feature"),Of=s(` argument in the
`),mn=a("code"),Tf=s("transformers.onnx"),Nf=s(` package. For example, to export a text-classification model we can
pick a fine-tuned model from the Hub and run:`),Da=p(),k(Et.$$.fragment),qa=p(),Ut=a("p"),jf=s("This displays the following logs:"),La=p(),k(wt.$$.fragment),Aa=p(),Y=a("p"),Cf=s("Notice that in this case, the output names from the fine-tuned model are "),gn=a("code"),Df=s("logits"),qf=s(`
instead of the `),_n=a("code"),Lf=s("last_hidden_state"),Af=s(" we saw with the "),vn=a("code"),If=s("distilbert-base-uncased"),Pf=s(` checkpoint
earlier. This is expected since the fine-tuned model has a sequence classification head.`),Ia=p(),k(Ne.$$.fragment),Pa=p(),he=a("h2"),je=a("a"),En=a("span"),k($t.$$.fragment),Bf=p(),wn=a("span"),Mf=s("Exporting a model for an unsupported architecture"),Ba=p(),Kt=a("p"),Xf=s(`If you wish to export a model whose architecture is not natively supported by the
library, there are three main steps to follow:`),Ma=p(),se=a("ol"),$n=a("li"),Rf=s("Implement a custom ONNX configuration."),Ff=p(),xn=a("li"),Sf=s("Export the model to ONNX."),zf=p(),bn=a("li"),Hf=s("Validate the outputs of the PyTorch and exported models."),Xa=p(),Jt=a("p"),Vf=s(`In this section, we\u2019ll look at how DistilBERT was implemented to show what\u2019s involved
with each step.`),Ra=p(),ue=a("h3"),Ce=a("a"),kn=a("span"),k(xt.$$.fragment),Wf=p(),yn=a("span"),Gf=s("Implementing a custom ONNX configuration"),Fa=p(),Qt=a("p"),Yf=s(`Let\u2019s start with the ONNX configuration object. We provide three abstract classes that
you should inherit from, depending on the type of model architecture you wish to export:`),Sa=p(),ne=a("ul"),Zt=a("li"),Uf=s("Encoder-based models inherit from "),eo=a("a"),Kf=s("OnnxConfig"),Jf=p(),to=a("li"),Qf=s("Decoder-based models inherit from "),oo=a("a"),Zf=s("OnnxConfigWithPast"),ed=p(),so=a("li"),td=s("Encoder-decoder models inherit from "),no=a("a"),od=s("OnnxSeq2SeqConfigWithPast"),za=p(),k(De.$$.fragment),Ha=p(),qe=a("p"),sd=s(`Since DistilBERT is an encoder-based model, its configuration inherits from
`),On=a("code"),nd=s("OnnxConfig"),ad=s(":"),Va=p(),k(bt.$$.fragment),Wa=p(),z=a("p"),ld=s("Every configuration object must implement the "),Tn=a("code"),rd=s("inputs"),id=s(` property and return a mapping,
where each key corresponds to an expected input, and each value indicates the axis of
that input. For DistilBERT, we can see that two inputs are required: `),Nn=a("code"),pd=s("input_ids"),fd=s(` and
`),jn=a("code"),dd=s("attention_mask"),cd=s(". These inputs have the same shape of "),Cn=a("code"),hd=s("(batch_size, sequence_length)"),ud=s(`
which is why we see the same axes used in the configuration.`),Ga=p(),k(Le.$$.fragment),Ya=p(),ao=a("p"),md=s(`Once you have implemented an ONNX configuration, you can instantiate it by providing the
base model\u2019s configuration as follows:`),Ua=p(),k(kt.$$.fragment),Ka=p(),lo=a("p"),gd=s(`The resulting object has several useful properties. For example, you can view the ONNX
operator set that will be used during the export:`),Ja=p(),k(yt.$$.fragment),Qa=p(),ro=a("p"),_d=s("You can also view the outputs associated with the model as follows:"),Za=p(),k(Ot.$$.fragment),el=p(),H=a("p"),vd=s(`Notice that the outputs property follows the same structure as the inputs; it returns an
`),Dn=a("code"),Ed=s("OrderedDict"),wd=s(` of named outputs and their shapes. The output structure is linked to the
choice of feature that the configuration is initialised with. By default, the ONNX
configuration is initialized with the `),qn=a("code"),$d=s("default"),xd=s(` feature that corresponds to exporting a
model loaded with the `),Ln=a("code"),bd=s("AutoModel"),kd=s(` class. If you want to export a model for another task,
just provide a different feature to the `),An=a("code"),yd=s("task"),Od=s(` argument when you initialize the ONNX
configuration. For example, if we wished to export DistilBERT with a sequence
classification head, we could use:`),tl=p(),k(Tt.$$.fragment),ol=p(),k(Ae.$$.fragment),sl=p(),me=a("h3"),Ie=a("a"),In=a("span"),k(Nt.$$.fragment),Td=p(),Pn=a("span"),Nd=s("Exporting the model"),nl=p(),ae=a("p"),jd=s(`Once you have implemented the ONNX configuration, the next step is to export the model.
Here we can use the `),Bn=a("code"),Cd=s("export()"),Dd=s(" function provided by the "),Mn=a("code"),qd=s("transformers.onnx"),Ld=s(` package.
This function expects the ONNX configuration, along with the base model and tokenizer,
and the path to save the exported file:`),al=p(),k(jt.$$.fragment),ll=p(),S=a("p"),Ad=s("The "),Xn=a("code"),Id=s("onnx_inputs"),Pd=s(" and "),Rn=a("code"),Bd=s("onnx_outputs"),Md=s(" returned by the "),Fn=a("code"),Xd=s("export()"),Rd=s(` function are lists of
the keys defined in the `),Sn=a("code"),Fd=s("inputs"),Sd=s(" and "),zn=a("code"),zd=s("outputs"),Hd=s(` properties of the configuration. Once the
model is exported, you can test that the model is well formed as follows:`),rl=p(),k(Ct.$$.fragment),il=p(),k(Pe.$$.fragment),pl=p(),ge=a("h3"),Be=a("a"),Hn=a("span"),k(Dt.$$.fragment),Vd=p(),Vn=a("span"),Wd=s("Validating the model outputs"),fl=p(),le=a("p"),Gd=s(`The final step is to validate that the outputs from the base and exported model agree
within some absolute tolerance. Here we can use the `),Wn=a("code"),Yd=s("validate_model_outputs()"),Ud=s(` function
provided by the `),Gn=a("code"),Kd=s("transformers.onnx"),Jd=s(" package as follows:"),dl=p(),k(qt.$$.fragment),cl=p(),Me=a("p"),Qd=s("This function uses the "),io=a("a"),Zd=s("generate_dummy_inputs()"),ec=s(` method to
generate inputs for the base and exported model, and the absolute tolerance can be
defined in the configuration. We generally find numerical agreement in the 1e-6 to 1e-4
range, although anything smaller than 1e-3 is likely to be OK.`),hl=p(),_e=a("h2"),Xe=a("a"),Yn=a("span"),k(Lt.$$.fragment),tc=p(),Un=a("span"),oc=s("Contributing a new configuration to \u{1F917} Transformers"),ul=p(),po=a("p"),sc=s(`We are looking to expand the set of ready-made configurations and welcome contributions
from the community! If you would like to contribute your addition to the library, you
will need to:`),ml=p(),re=a("ul"),At=a("li"),nc=s("Implement the ONNX configuration in the corresponding "),Kn=a("code"),ac=s("configuration_<model_name>.py"),lc=s(`
file`),rc=p(),fo=a("li"),ic=s(`Include the model architecture and corresponding features in
`),Jn=a("code"),pc=s("FeatureManager"),fc=p(),co=a("li"),dc=s("Add your model architecture to the tests in "),Qn=a("code"),cc=s("test_onnx_v2.py"),gl=p(),Re=a("p"),hc=s("Check out how the configuration for "),It=a("a"),uc=s(`IBERT was
contributed`),mc=s(` to get an
idea of what\u2019s involved.`),this.h()},l(t){const i=Pm('[data-svelte="svelte-1phssyn"]',document.head);c=l(i,"META",{name:!0,content:!0}),i.forEach(o),w=f(t),m=l(t,"H1",{class:!0});var Pt=r(m);E=l(Pt,"A",{id:!0,class:!0,href:!0});var Zn=r(E);$=l(Zn,"SPAN",{});var ea=r($);y(v.$$.fragment,ea),ea.forEach(o),Zn.forEach(o),x=f(Pt),b=l(Pt,"SPAN",{});var ta=r(b);q=n(ta,"Export to ONNX"),ta.forEach(o),Pt.forEach(o),C=f(t),A=l(t,"P",{});var Bt=r(A);L=n(Bt,`If you need to deploy \u{1F917} Transformers models in production environments, we recommend
exporting them to a serialized format that can be loaded and executed on specialized
runtimes and hardware. In this guide, we\u2019ll show you how to export \u{1F917} Transformers
models to `),I=l(Bt,"A",{href:!0,rel:!0});var oa=r(I);g=n(oa,"ONNX (Open Neural Network eXchange)"),oa.forEach(o),D=n(Bt,"."),Bt.forEach(o),R=f(t),y(X.$$.fragment,t),Q=f(t),W=l(t,"P",{});var Mt=r(W);He=n(Mt,`ONNX is an open standard that defines a common set of operators and a common file format
to represent deep learning models in a wide variety of frameworks, including PyTorch and
TensorFlow. When a model is exported to the ONNX format, these operators are used to
construct a computational graph (often called an `),K=l(Mt,"EM",{});var $c=r(K);Ve=n($c,"intermediate representation"),$c.forEach(o),We=n(Mt,`) which
represents the flow of data through the neural network.`),Mt.forEach(o),Z=f(t),P=l(t,"P",{});var xc=r(P);Xt=n(xc,`By exposing a graph with standardized operators and data types, ONNX makes it easy to
switch between frameworks. For example, a model trained in PyTorch can be exported to
ONNX format and then imported in TensorFlow (and vice versa).`),xc.forEach(o),Ge=f(t),J=l(t,"P",{});var vl=r(J);Rt=n(vl,"\u{1F917} Transformers provides a "),fe=l(vl,"A",{href:!0});var bc=r(fe);ve=l(bc,"CODE",{});var kc=r(ve);Ft=n(kc,"transformers.onnx"),kc.forEach(o),bc.forEach(o),Yl=n(vl,` package that enables
you to convert model checkpoints to an ONNX graph by leveraging configuration objects.
These configuration objects come ready made for a number of model architectures, and are
designed to be easily extendable to other architectures.`),vl.forEach(o),sa=f(t),St=l(t,"P",{});var yc=r(St);Ul=n(yc,"Ready-made configurations include the following architectures:"),yc.forEach(o),na=f(t),h=l(t,"UL",{});var u=r(h);xo=l(u,"LI",{});var Oc=r(xo);Kl=n(Oc,"ALBERT"),Oc.forEach(o),Jl=f(u),bo=l(u,"LI",{});var Tc=r(bo);Ql=n(Tc,"BART"),Tc.forEach(o),Zl=f(u),ko=l(u,"LI",{});var Nc=r(ko);er=n(Nc,"BEiT"),Nc.forEach(o),tr=f(u),yo=l(u,"LI",{});var jc=r(yo);or=n(jc,"BERT"),jc.forEach(o),sr=f(u),Oo=l(u,"LI",{});var Cc=r(Oo);nr=n(Cc,"BigBird"),Cc.forEach(o),ar=f(u),To=l(u,"LI",{});var Dc=r(To);lr=n(Dc,"BigBird-Pegasus"),Dc.forEach(o),rr=f(u),No=l(u,"LI",{});var qc=r(No);ir=n(qc,"Blenderbot"),qc.forEach(o),pr=f(u),jo=l(u,"LI",{});var Lc=r(jo);fr=n(Lc,"BlenderbotSmall"),Lc.forEach(o),dr=f(u),Co=l(u,"LI",{});var Ac=r(Co);cr=n(Ac,"BLOOM"),Ac.forEach(o),hr=f(u),Do=l(u,"LI",{});var Ic=r(Do);ur=n(Ic,"CamemBERT"),Ic.forEach(o),mr=f(u),qo=l(u,"LI",{});var Pc=r(qo);gr=n(Pc,"CLIP"),Pc.forEach(o),_r=f(u),Lo=l(u,"LI",{});var Bc=r(Lo);vr=n(Bc,"CodeGen"),Bc.forEach(o),Er=f(u),Ao=l(u,"LI",{});var Mc=r(Ao);wr=n(Mc,"Conditional DETR"),Mc.forEach(o),$r=f(u),Io=l(u,"LI",{});var Xc=r(Io);xr=n(Xc,"ConvBERT"),Xc.forEach(o),br=f(u),Po=l(u,"LI",{});var Rc=r(Po);kr=n(Rc,"ConvNeXT"),Rc.forEach(o),yr=f(u),Bo=l(u,"LI",{});var Fc=r(Bo);Or=n(Fc,"Data2VecText"),Fc.forEach(o),Tr=f(u),Mo=l(u,"LI",{});var Sc=r(Mo);Nr=n(Sc,"Data2VecVision"),Sc.forEach(o),jr=f(u),Xo=l(u,"LI",{});var zc=r(Xo);Cr=n(zc,"DeBERTa"),zc.forEach(o),Dr=f(u),Ro=l(u,"LI",{});var Hc=r(Ro);qr=n(Hc,"DeBERTa-v2"),Hc.forEach(o),Lr=f(u),Fo=l(u,"LI",{});var Vc=r(Fo);Ar=n(Vc,"DeiT"),Vc.forEach(o),Ir=f(u),So=l(u,"LI",{});var Wc=r(So);Pr=n(Wc,"DETR"),Wc.forEach(o),Br=f(u),zo=l(u,"LI",{});var Gc=r(zo);Mr=n(Gc,"DistilBERT"),Gc.forEach(o),Xr=f(u),Ho=l(u,"LI",{});var Yc=r(Ho);Rr=n(Yc,"ELECTRA"),Yc.forEach(o),Fr=f(u),Vo=l(u,"LI",{});var Uc=r(Vo);Sr=n(Uc,"ERNIE"),Uc.forEach(o),zr=f(u),Wo=l(u,"LI",{});var Kc=r(Wo);Hr=n(Kc,"FlauBERT"),Kc.forEach(o),Vr=f(u),Go=l(u,"LI",{});var Jc=r(Go);Wr=n(Jc,"GPT Neo"),Jc.forEach(o),Gr=f(u),Yo=l(u,"LI",{});var Qc=r(Yo);Yr=n(Qc,"GPT-J"),Qc.forEach(o),Ur=f(u),Uo=l(u,"LI",{});var Zc=r(Uo);Kr=n(Zc,"GroupViT"),Zc.forEach(o),Jr=f(u),Ko=l(u,"LI",{});var eh=r(Ko);Qr=n(eh,"I-BERT"),eh.forEach(o),Zr=f(u),Jo=l(u,"LI",{});var th=r(Jo);ei=n(th,"LayoutLM"),th.forEach(o),ti=f(u),Qo=l(u,"LI",{});var oh=r(Qo);oi=n(oh,"LayoutLMv3"),oh.forEach(o),si=f(u),Zo=l(u,"LI",{});var sh=r(Zo);ni=n(sh,"LeViT"),sh.forEach(o),ai=f(u),es=l(u,"LI",{});var nh=r(es);li=n(nh,"Longformer"),nh.forEach(o),ri=f(u),ts=l(u,"LI",{});var ah=r(ts);ii=n(ah,"LongT5"),ah.forEach(o),pi=f(u),os=l(u,"LI",{});var lh=r(os);fi=n(lh,"M2M100"),lh.forEach(o),di=f(u),ss=l(u,"LI",{});var rh=r(ss);ci=n(rh,"Marian"),rh.forEach(o),hi=f(u),ns=l(u,"LI",{});var ih=r(ns);ui=n(ih,"mBART"),ih.forEach(o),mi=f(u),as=l(u,"LI",{});var ph=r(as);gi=n(ph,"MobileBERT"),ph.forEach(o),_i=f(u),ls=l(u,"LI",{});var fh=r(ls);vi=n(fh,"MobileViT"),fh.forEach(o),Ei=f(u),rs=l(u,"LI",{});var dh=r(rs);wi=n(dh,"MT5"),dh.forEach(o),$i=f(u),is=l(u,"LI",{});var ch=r(is);xi=n(ch,"OpenAI GPT-2"),ch.forEach(o),bi=f(u),ps=l(u,"LI",{});var hh=r(ps);ki=n(hh,"OWL-ViT"),hh.forEach(o),yi=f(u),fs=l(u,"LI",{});var uh=r(fs);Oi=n(uh,"Perceiver"),uh.forEach(o),Ti=f(u),ds=l(u,"LI",{});var mh=r(ds);Ni=n(mh,"PLBart"),mh.forEach(o),ji=f(u),cs=l(u,"LI",{});var gh=r(cs);Ci=n(gh,"ResNet"),gh.forEach(o),Di=f(u),hs=l(u,"LI",{});var _h=r(hs);qi=n(_h,"RoBERTa"),_h.forEach(o),Li=f(u),us=l(u,"LI",{});var vh=r(us);Ai=n(vh,"RoFormer"),vh.forEach(o),Ii=f(u),ms=l(u,"LI",{});var Eh=r(ms);Pi=n(Eh,"SegFormer"),Eh.forEach(o),Bi=f(u),gs=l(u,"LI",{});var wh=r(gs);Mi=n(wh,"SqueezeBERT"),wh.forEach(o),Xi=f(u),_s=l(u,"LI",{});var $h=r(_s);Ri=n($h,"T5"),$h.forEach(o),Fi=f(u),vs=l(u,"LI",{});var xh=r(vs);Si=n(xh,"ViT"),xh.forEach(o),zi=f(u),Es=l(u,"LI",{});var bh=r(Es);Hi=n(bh,"XLM"),bh.forEach(o),Vi=f(u),ws=l(u,"LI",{});var kh=r(ws);Wi=n(kh,"XLM-RoBERTa"),kh.forEach(o),Gi=f(u),$s=l(u,"LI",{});var yh=r($s);Yi=n(yh,"XLM-RoBERTa-XL"),yh.forEach(o),Ui=f(u),xs=l(u,"LI",{});var Oh=r(xs);Ki=n(Oh,"YOLOS"),Oh.forEach(o),u.forEach(o),aa=f(t),zt=l(t,"P",{});var Th=r(zt);Ji=n(Th,"In the next two sections, we\u2019ll show you how to:"),Th.forEach(o),la=f(t),Ee=l(t,"UL",{});var El=r(Ee);Ye=l(El,"LI",{});var wl=r(Ye);Qi=n(wl,"Export a supported model using the "),bs=l(wl,"CODE",{});var Nh=r(bs);Zi=n(Nh,"transformers.onnx"),Nh.forEach(o),ep=n(wl," package."),wl.forEach(o),tp=f(El),ks=l(El,"LI",{});var jh=r(ks);op=n(jh,"Export a custom model for an unsupported architecture."),jh.forEach(o),El.forEach(o),ra=f(t),de=l(t,"H2",{class:!0});var $l=r(de);we=l($l,"A",{id:!0,class:!0,href:!0});var Ch=r(we);ys=l(Ch,"SPAN",{});var Dh=r(ys);y(Ue.$$.fragment,Dh),Dh.forEach(o),Ch.forEach(o),sp=f($l),Os=l($l,"SPAN",{});var qh=r(Os);np=n(qh,"Exporting a model to ONNX"),qh.forEach(o),$l.forEach(o),ia=f(t),Ht=l(t,"P",{});var Lh=r(Ht);ap=n(Lh,`To export a \u{1F917} Transformers model to ONNX, you\u2019ll first need to install some extra
dependencies:`),Lh.forEach(o),pa=f(t),y(Ke.$$.fragment,t),fa=f(t),$e=l(t,"P",{});var xl=r($e);lp=n(xl,"The "),Ts=l(xl,"CODE",{});var Ah=r(Ts);rp=n(Ah,"transformers.onnx"),Ah.forEach(o),ip=n(xl," package can then be used as a Python module:"),xl.forEach(o),da=f(t),y(Je.$$.fragment,t),ca=f(t),Vt=l(t,"P",{});var Ih=r(Vt);pp=n(Ih,"Exporting a checkpoint using a ready-made configuration can be done as follows:"),Ih.forEach(o),ha=f(t),y(Qe.$$.fragment,t),ua=f(t),Wt=l(t,"P",{});var Ph=r(Wt);fp=n(Ph,"You should see the following logs:"),Ph.forEach(o),ma=f(t),y(Ze.$$.fragment,t),ga=f(t),ee=l(t,"P",{});var ho=r(ee);dp=n(ho,"This exports an ONNX graph of the checkpoint defined by the "),Ns=l(ho,"CODE",{});var Bh=r(Ns);cp=n(Bh,"--model"),Bh.forEach(o),hp=n(ho,` argument. In this
example, it is `),js=l(ho,"CODE",{});var Mh=r(js);up=n(Mh,"distilbert-base-uncased"),Mh.forEach(o),mp=n(ho,`, but it can be any checkpoint on the Hugging
Face Hub or one that\u2019s stored locally.`),ho.forEach(o),_a=f(t),G=l(t,"P",{});var Fe=r(G);gp=n(Fe,"The resulting "),Cs=l(Fe,"CODE",{});var Xh=r(Cs);_p=n(Xh,"model.onnx"),Xh.forEach(o),vp=n(Fe," file can then be run on one of the "),et=l(Fe,"A",{href:!0,rel:!0});var Rh=r(et);Ep=n(Rh,`many
accelerators`),Rh.forEach(o),wp=n(Fe,` that support the ONNX
standard. For example, we can load and run the model with `),tt=l(Fe,"A",{href:!0,rel:!0});var Fh=r(tt);$p=n(Fh,`ONNX
Runtime`),Fh.forEach(o),xp=n(Fe," as follows:"),Fe.forEach(o),va=f(t),y(ot.$$.fragment,t),Ea=f(t),xe=l(t,"P",{});var bl=r(xe);bp=n(bl,"The required output names (like "),Ds=l(bl,"CODE",{});var Sh=r(Ds);kp=n(Sh,'["last_hidden_state"]'),Sh.forEach(o),yp=n(bl,`) can be obtained by taking a
look at the ONNX configuration of each model. For example, for DistilBERT we have:`),bl.forEach(o),wa=f(t),y(st.$$.fragment,t),$a=f(t),be=l(t,"P",{});var kl=r(be);Op=n(kl,`The process is identical for TensorFlow checkpoints on the Hub. For example, we can
export a pure TensorFlow checkpoint from the `),nt=l(kl,"A",{href:!0,rel:!0});var zh=r(nt);Tp=n(zh,`Keras
organization`),zh.forEach(o),Np=n(kl," as follows:"),kl.forEach(o),xa=f(t),y(at.$$.fragment,t),ba=f(t),Gt=l(t,"P",{});var Hh=r(Gt);jp=n(Hh,`To export a model that\u2019s stored locally, you\u2019ll need to have the model\u2019s weights and
tokenizer files stored in a directory. For example, we can load and save a checkpoint as
follows:`),Hh.forEach(o),ka=f(t),y(ke.$$.fragment,t),ya=f(t),ce=l(t,"H2",{class:!0});var yl=r(ce);ye=l(yl,"A",{id:!0,class:!0,href:!0});var Vh=r(ye);qs=l(Vh,"SPAN",{});var Wh=r(qs);y(lt.$$.fragment,Wh),Wh.forEach(o),Vh.forEach(o),Cp=f(yl),Ls=l(yl,"SPAN",{});var Gh=r(Ls);Dp=n(Gh,"Selecting features for different model tasks"),Gh.forEach(o),yl.forEach(o),Oa=f(t),te=l(t,"P",{});var uo=r(te);qp=n(uo,"Each ready-made configuration comes with a set of "),As=l(uo,"EM",{});var Yh=r(As);Lp=n(Yh,"features"),Yh.forEach(o),Ap=n(uo,` that enable you to export
models for different types of tasks. As shown in the table below, each feature is
associated with a different `),Is=l(uo,"CODE",{});var Uh=r(Is);Ip=n(Uh,"AutoClass"),Uh.forEach(o),Pp=n(uo,":"),uo.forEach(o),Ta=f(t),Oe=l(t,"TABLE",{});var Ol=r(Oe);Ps=l(Ol,"THEAD",{});var Kh=r(Ps);rt=l(Kh,"TR",{});var Tl=r(rt);Bs=l(Tl,"TH",{});var Jh=r(Bs);Bp=n(Jh,"Feature"),Jh.forEach(o),Mp=f(Tl),Ms=l(Tl,"TH",{});var Qh=r(Ms);Xp=n(Qh,"Auto Class"),Qh.forEach(o),Tl.forEach(o),Kh.forEach(o),Rp=f(Ol),F=l(Ol,"TBODY",{});var V=r(F);it=l(V,"TR",{});var Nl=r(it);pt=l(Nl,"TD",{});var jl=r(pt);Xs=l(jl,"CODE",{});var Zh=r(Xs);Fp=n(Zh,"causal-lm"),Zh.forEach(o),Sp=n(jl,", "),Rs=l(jl,"CODE",{});var eu=r(Rs);zp=n(eu,"causal-lm-with-past"),eu.forEach(o),jl.forEach(o),Hp=f(Nl),Fs=l(Nl,"TD",{});var tu=r(Fs);Ss=l(tu,"CODE",{});var ou=r(Ss);Vp=n(ou,"AutoModelForCausalLM"),ou.forEach(o),tu.forEach(o),Nl.forEach(o),Wp=f(V),ft=l(V,"TR",{});var Cl=r(ft);dt=l(Cl,"TD",{});var Dl=r(dt);zs=l(Dl,"CODE",{});var su=r(zs);Gp=n(su,"default"),su.forEach(o),Yp=n(Dl,", "),Hs=l(Dl,"CODE",{});var nu=r(Hs);Up=n(nu,"default-with-past"),nu.forEach(o),Dl.forEach(o),Kp=f(Cl),Vs=l(Cl,"TD",{});var au=r(Vs);Ws=l(au,"CODE",{});var lu=r(Ws);Jp=n(lu,"AutoModel"),lu.forEach(o),au.forEach(o),Cl.forEach(o),Qp=f(V),ct=l(V,"TR",{});var ql=r(ct);Gs=l(ql,"TD",{});var ru=r(Gs);Ys=l(ru,"CODE",{});var iu=r(Ys);Zp=n(iu,"masked-lm"),iu.forEach(o),ru.forEach(o),ef=f(ql),Us=l(ql,"TD",{});var pu=r(Us);Ks=l(pu,"CODE",{});var fu=r(Ks);tf=n(fu,"AutoModelForMaskedLM"),fu.forEach(o),pu.forEach(o),ql.forEach(o),of=f(V),ht=l(V,"TR",{});var Ll=r(ht);Js=l(Ll,"TD",{});var du=r(Js);Qs=l(du,"CODE",{});var cu=r(Qs);sf=n(cu,"question-answering"),cu.forEach(o),du.forEach(o),nf=f(Ll),Zs=l(Ll,"TD",{});var hu=r(Zs);en=l(hu,"CODE",{});var uu=r(en);af=n(uu,"AutoModelForQuestionAnswering"),uu.forEach(o),hu.forEach(o),Ll.forEach(o),lf=f(V),ut=l(V,"TR",{});var Al=r(ut);mt=l(Al,"TD",{});var Il=r(mt);tn=l(Il,"CODE",{});var mu=r(tn);rf=n(mu,"seq2seq-lm"),mu.forEach(o),pf=n(Il,", "),on=l(Il,"CODE",{});var gu=r(on);ff=n(gu,"seq2seq-lm-with-past"),gu.forEach(o),Il.forEach(o),df=f(Al),sn=l(Al,"TD",{});var _u=r(sn);nn=l(_u,"CODE",{});var vu=r(nn);cf=n(vu,"AutoModelForSeq2SeqLM"),vu.forEach(o),_u.forEach(o),Al.forEach(o),hf=f(V),gt=l(V,"TR",{});var Pl=r(gt);an=l(Pl,"TD",{});var Eu=r(an);ln=l(Eu,"CODE",{});var wu=r(ln);uf=n(wu,"sequence-classification"),wu.forEach(o),Eu.forEach(o),mf=f(Pl),rn=l(Pl,"TD",{});var $u=r(rn);pn=l($u,"CODE",{});var xu=r(pn);gf=n(xu,"AutoModelForSequenceClassification"),xu.forEach(o),$u.forEach(o),Pl.forEach(o),_f=f(V),_t=l(V,"TR",{});var Bl=r(_t);fn=l(Bl,"TD",{});var bu=r(fn);dn=l(bu,"CODE",{});var ku=r(dn);vf=n(ku,"token-classification"),ku.forEach(o),bu.forEach(o),Ef=f(Bl),cn=l(Bl,"TD",{});var yu=r(cn);hn=l(yu,"CODE",{});var Ou=r(hn);wf=n(Ou,"AutoModelForTokenClassification"),Ou.forEach(o),yu.forEach(o),Bl.forEach(o),V.forEach(o),Ol.forEach(o),Na=f(t),Te=l(t,"P",{});var Ml=r(Te);$f=n(Ml,`For each configuration, you can find the list of supported features via the
`),Yt=l(Ml,"A",{href:!0});var Tu=r(Yt);xf=n(Tu,"FeaturesManager"),Tu.forEach(o),bf=n(Ml,". For example, for DistilBERT we have:"),Ml.forEach(o),ja=f(t),y(vt.$$.fragment,t),Ca=f(t),oe=l(t,"P",{});var mo=r(oe);kf=n(mo,"You can then pass one of these features to the "),un=l(mo,"CODE",{});var Nu=r(un);yf=n(Nu,"--feature"),Nu.forEach(o),Of=n(mo,` argument in the
`),mn=l(mo,"CODE",{});var ju=r(mn);Tf=n(ju,"transformers.onnx"),ju.forEach(o),Nf=n(mo,` package. For example, to export a text-classification model we can
pick a fine-tuned model from the Hub and run:`),mo.forEach(o),Da=f(t),y(Et.$$.fragment,t),qa=f(t),Ut=l(t,"P",{});var Cu=r(Ut);jf=n(Cu,"This displays the following logs:"),Cu.forEach(o),La=f(t),y(wt.$$.fragment,t),Aa=f(t),Y=l(t,"P",{});var Se=r(Y);Cf=n(Se,"Notice that in this case, the output names from the fine-tuned model are "),gn=l(Se,"CODE",{});var Du=r(gn);Df=n(Du,"logits"),Du.forEach(o),qf=n(Se,`
instead of the `),_n=l(Se,"CODE",{});var qu=r(_n);Lf=n(qu,"last_hidden_state"),qu.forEach(o),Af=n(Se," we saw with the "),vn=l(Se,"CODE",{});var Lu=r(vn);If=n(Lu,"distilbert-base-uncased"),Lu.forEach(o),Pf=n(Se,` checkpoint
earlier. This is expected since the fine-tuned model has a sequence classification head.`),Se.forEach(o),Ia=f(t),y(Ne.$$.fragment,t),Pa=f(t),he=l(t,"H2",{class:!0});var Xl=r(he);je=l(Xl,"A",{id:!0,class:!0,href:!0});var Au=r(je);En=l(Au,"SPAN",{});var Iu=r(En);y($t.$$.fragment,Iu),Iu.forEach(o),Au.forEach(o),Bf=f(Xl),wn=l(Xl,"SPAN",{});var Pu=r(wn);Mf=n(Pu,"Exporting a model for an unsupported architecture"),Pu.forEach(o),Xl.forEach(o),Ba=f(t),Kt=l(t,"P",{});var Bu=r(Kt);Xf=n(Bu,`If you wish to export a model whose architecture is not natively supported by the
library, there are three main steps to follow:`),Bu.forEach(o),Ma=f(t),se=l(t,"OL",{});var go=r(se);$n=l(go,"LI",{});var Mu=r($n);Rf=n(Mu,"Implement a custom ONNX configuration."),Mu.forEach(o),Ff=f(go),xn=l(go,"LI",{});var Xu=r(xn);Sf=n(Xu,"Export the model to ONNX."),Xu.forEach(o),zf=f(go),bn=l(go,"LI",{});var Ru=r(bn);Hf=n(Ru,"Validate the outputs of the PyTorch and exported models."),Ru.forEach(o),go.forEach(o),Xa=f(t),Jt=l(t,"P",{});var Fu=r(Jt);Vf=n(Fu,`In this section, we\u2019ll look at how DistilBERT was implemented to show what\u2019s involved
with each step.`),Fu.forEach(o),Ra=f(t),ue=l(t,"H3",{class:!0});var Rl=r(ue);Ce=l(Rl,"A",{id:!0,class:!0,href:!0});var Su=r(Ce);kn=l(Su,"SPAN",{});var zu=r(kn);y(xt.$$.fragment,zu),zu.forEach(o),Su.forEach(o),Wf=f(Rl),yn=l(Rl,"SPAN",{});var Hu=r(yn);Gf=n(Hu,"Implementing a custom ONNX configuration"),Hu.forEach(o),Rl.forEach(o),Fa=f(t),Qt=l(t,"P",{});var Vu=r(Qt);Yf=n(Vu,`Let\u2019s start with the ONNX configuration object. We provide three abstract classes that
you should inherit from, depending on the type of model architecture you wish to export:`),Vu.forEach(o),Sa=f(t),ne=l(t,"UL",{});var _o=r(ne);Zt=l(_o,"LI",{});var gc=r(Zt);Uf=n(gc,"Encoder-based models inherit from "),eo=l(gc,"A",{href:!0});var Wu=r(eo);Kf=n(Wu,"OnnxConfig"),Wu.forEach(o),gc.forEach(o),Jf=f(_o),to=l(_o,"LI",{});var _c=r(to);Qf=n(_c,"Decoder-based models inherit from "),oo=l(_c,"A",{href:!0});var Gu=r(oo);Zf=n(Gu,"OnnxConfigWithPast"),Gu.forEach(o),_c.forEach(o),ed=f(_o),so=l(_o,"LI",{});var vc=r(so);td=n(vc,"Encoder-decoder models inherit from "),no=l(vc,"A",{href:!0});var Yu=r(no);od=n(Yu,"OnnxSeq2SeqConfigWithPast"),Yu.forEach(o),vc.forEach(o),_o.forEach(o),za=f(t),y(De.$$.fragment,t),Ha=f(t),qe=l(t,"P",{});var Fl=r(qe);sd=n(Fl,`Since DistilBERT is an encoder-based model, its configuration inherits from
`),On=l(Fl,"CODE",{});var Uu=r(On);nd=n(Uu,"OnnxConfig"),Uu.forEach(o),ad=n(Fl,":"),Fl.forEach(o),Va=f(t),y(bt.$$.fragment,t),Wa=f(t),z=l(t,"P",{});var ie=r(z);ld=n(ie,"Every configuration object must implement the "),Tn=l(ie,"CODE",{});var Ku=r(Tn);rd=n(Ku,"inputs"),Ku.forEach(o),id=n(ie,` property and return a mapping,
where each key corresponds to an expected input, and each value indicates the axis of
that input. For DistilBERT, we can see that two inputs are required: `),Nn=l(ie,"CODE",{});var Ju=r(Nn);pd=n(Ju,"input_ids"),Ju.forEach(o),fd=n(ie,` and
`),jn=l(ie,"CODE",{});var Qu=r(jn);dd=n(Qu,"attention_mask"),Qu.forEach(o),cd=n(ie,". These inputs have the same shape of "),Cn=l(ie,"CODE",{});var Zu=r(Cn);hd=n(Zu,"(batch_size, sequence_length)"),Zu.forEach(o),ud=n(ie,`
which is why we see the same axes used in the configuration.`),ie.forEach(o),Ga=f(t),y(Le.$$.fragment,t),Ya=f(t),ao=l(t,"P",{});var em=r(ao);md=n(em,`Once you have implemented an ONNX configuration, you can instantiate it by providing the
base model\u2019s configuration as follows:`),em.forEach(o),Ua=f(t),y(kt.$$.fragment,t),Ka=f(t),lo=l(t,"P",{});var tm=r(lo);gd=n(tm,`The resulting object has several useful properties. For example, you can view the ONNX
operator set that will be used during the export:`),tm.forEach(o),Ja=f(t),y(yt.$$.fragment,t),Qa=f(t),ro=l(t,"P",{});var om=r(ro);_d=n(om,"You can also view the outputs associated with the model as follows:"),om.forEach(o),Za=f(t),y(Ot.$$.fragment,t),el=f(t),H=l(t,"P",{});var pe=r(H);vd=n(pe,`Notice that the outputs property follows the same structure as the inputs; it returns an
`),Dn=l(pe,"CODE",{});var sm=r(Dn);Ed=n(sm,"OrderedDict"),sm.forEach(o),wd=n(pe,` of named outputs and their shapes. The output structure is linked to the
choice of feature that the configuration is initialised with. By default, the ONNX
configuration is initialized with the `),qn=l(pe,"CODE",{});var nm=r(qn);$d=n(nm,"default"),nm.forEach(o),xd=n(pe,` feature that corresponds to exporting a
model loaded with the `),Ln=l(pe,"CODE",{});var am=r(Ln);bd=n(am,"AutoModel"),am.forEach(o),kd=n(pe,` class. If you want to export a model for another task,
just provide a different feature to the `),An=l(pe,"CODE",{});var lm=r(An);yd=n(lm,"task"),lm.forEach(o),Od=n(pe,` argument when you initialize the ONNX
configuration. For example, if we wished to export DistilBERT with a sequence
classification head, we could use:`),pe.forEach(o),tl=f(t),y(Tt.$$.fragment,t),ol=f(t),y(Ae.$$.fragment,t),sl=f(t),me=l(t,"H3",{class:!0});var Sl=r(me);Ie=l(Sl,"A",{id:!0,class:!0,href:!0});var rm=r(Ie);In=l(rm,"SPAN",{});var im=r(In);y(Nt.$$.fragment,im),im.forEach(o),rm.forEach(o),Td=f(Sl),Pn=l(Sl,"SPAN",{});var pm=r(Pn);Nd=n(pm,"Exporting the model"),pm.forEach(o),Sl.forEach(o),nl=f(t),ae=l(t,"P",{});var vo=r(ae);jd=n(vo,`Once you have implemented the ONNX configuration, the next step is to export the model.
Here we can use the `),Bn=l(vo,"CODE",{});var fm=r(Bn);Cd=n(fm,"export()"),fm.forEach(o),Dd=n(vo," function provided by the "),Mn=l(vo,"CODE",{});var dm=r(Mn);qd=n(dm,"transformers.onnx"),dm.forEach(o),Ld=n(vo,` package.
This function expects the ONNX configuration, along with the base model and tokenizer,
and the path to save the exported file:`),vo.forEach(o),al=f(t),y(jt.$$.fragment,t),ll=f(t),S=l(t,"P",{});var U=r(S);Ad=n(U,"The "),Xn=l(U,"CODE",{});var cm=r(Xn);Id=n(cm,"onnx_inputs"),cm.forEach(o),Pd=n(U," and "),Rn=l(U,"CODE",{});var hm=r(Rn);Bd=n(hm,"onnx_outputs"),hm.forEach(o),Md=n(U," returned by the "),Fn=l(U,"CODE",{});var um=r(Fn);Xd=n(um,"export()"),um.forEach(o),Rd=n(U,` function are lists of
the keys defined in the `),Sn=l(U,"CODE",{});var mm=r(Sn);Fd=n(mm,"inputs"),mm.forEach(o),Sd=n(U," and "),zn=l(U,"CODE",{});var gm=r(zn);zd=n(gm,"outputs"),gm.forEach(o),Hd=n(U,` properties of the configuration. Once the
model is exported, you can test that the model is well formed as follows:`),U.forEach(o),rl=f(t),y(Ct.$$.fragment,t),il=f(t),y(Pe.$$.fragment,t),pl=f(t),ge=l(t,"H3",{class:!0});var zl=r(ge);Be=l(zl,"A",{id:!0,class:!0,href:!0});var _m=r(Be);Hn=l(_m,"SPAN",{});var vm=r(Hn);y(Dt.$$.fragment,vm),vm.forEach(o),_m.forEach(o),Vd=f(zl),Vn=l(zl,"SPAN",{});var Em=r(Vn);Wd=n(Em,"Validating the model outputs"),Em.forEach(o),zl.forEach(o),fl=f(t),le=l(t,"P",{});var Eo=r(le);Gd=n(Eo,`The final step is to validate that the outputs from the base and exported model agree
within some absolute tolerance. Here we can use the `),Wn=l(Eo,"CODE",{});var wm=r(Wn);Yd=n(wm,"validate_model_outputs()"),wm.forEach(o),Ud=n(Eo,` function
provided by the `),Gn=l(Eo,"CODE",{});var $m=r(Gn);Kd=n($m,"transformers.onnx"),$m.forEach(o),Jd=n(Eo," package as follows:"),Eo.forEach(o),dl=f(t),y(qt.$$.fragment,t),cl=f(t),Me=l(t,"P",{});var Hl=r(Me);Qd=n(Hl,"This function uses the "),io=l(Hl,"A",{href:!0});var xm=r(io);Zd=n(xm,"generate_dummy_inputs()"),xm.forEach(o),ec=n(Hl,` method to
generate inputs for the base and exported model, and the absolute tolerance can be
defined in the configuration. We generally find numerical agreement in the 1e-6 to 1e-4
range, although anything smaller than 1e-3 is likely to be OK.`),Hl.forEach(o),hl=f(t),_e=l(t,"H2",{class:!0});var Vl=r(_e);Xe=l(Vl,"A",{id:!0,class:!0,href:!0});var bm=r(Xe);Yn=l(bm,"SPAN",{});var km=r(Yn);y(Lt.$$.fragment,km),km.forEach(o),bm.forEach(o),tc=f(Vl),Un=l(Vl,"SPAN",{});var ym=r(Un);oc=n(ym,"Contributing a new configuration to \u{1F917} Transformers"),ym.forEach(o),Vl.forEach(o),ul=f(t),po=l(t,"P",{});var Om=r(po);sc=n(Om,`We are looking to expand the set of ready-made configurations and welcome contributions
from the community! If you would like to contribute your addition to the library, you
will need to:`),Om.forEach(o),ml=f(t),re=l(t,"UL",{});var wo=r(re);At=l(wo,"LI",{});var Wl=r(At);nc=n(Wl,"Implement the ONNX configuration in the corresponding "),Kn=l(Wl,"CODE",{});var Tm=r(Kn);ac=n(Tm,"configuration_<model_name>.py"),Tm.forEach(o),lc=n(Wl,`
file`),Wl.forEach(o),rc=f(wo),fo=l(wo,"LI",{});var Ec=r(fo);ic=n(Ec,`Include the model architecture and corresponding features in
`),Jn=l(Ec,"CODE",{});var Nm=r(Jn);pc=n(Nm,"FeatureManager"),Nm.forEach(o),Ec.forEach(o),fc=f(wo),co=l(wo,"LI",{});var wc=r(co);dc=n(wc,"Add your model architecture to the tests in "),Qn=l(wc,"CODE",{});var jm=r(Qn);cc=n(jm,"test_onnx_v2.py"),jm.forEach(o),wc.forEach(o),wo.forEach(o),gl=f(t),Re=l(t,"P",{});var Gl=r(Re);hc=n(Gl,"Check out how the configuration for "),It=l(Gl,"A",{href:!0,rel:!0});var Cm=r(It);uc=n(Cm,`IBERT was
contributed`),Cm.forEach(o),mc=n(Gl,` to get an
idea of what\u2019s involved.`),Gl.forEach(o),this.h()},h(){_(c,"name","hf:doc:metadata"),_(c,"content",JSON.stringify(Km)),_(E,"id","export-to-onnx"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#export-to-onnx"),_(m,"class","relative group"),_(I,"href","http://onnx.ai"),_(I,"rel","nofollow"),_(fe,"href","main_classes/onnx"),_(we,"id","exporting-a-model-to-onnx"),_(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(we,"href","#exporting-a-model-to-onnx"),_(de,"class","relative group"),_(et,"href","https://onnx.ai/supported-tools.html#deployModel"),_(et,"rel","nofollow"),_(tt,"href","https://onnxruntime.ai/"),_(tt,"rel","nofollow"),_(nt,"href","https://huggingface.co/keras-io"),_(nt,"rel","nofollow"),_(ye,"id","selecting-features-for-different-model-tasks"),_(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ye,"href","#selecting-features-for-different-model-tasks"),_(ce,"class","relative group"),_(Yt,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.FeaturesManager"),_(je,"id","exporting-a-model-for-an-unsupported-architecture"),_(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(je,"href","#exporting-a-model-for-an-unsupported-architecture"),_(he,"class","relative group"),_(Ce,"id","implementing-a-custom-onnx-configuration"),_(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ce,"href","#implementing-a-custom-onnx-configuration"),_(ue,"class","relative group"),_(eo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig"),_(oo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfigWithPast"),_(no,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxSeq2SeqConfigWithPast"),_(Ie,"id","exporting-the-model"),_(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ie,"href","#exporting-the-model"),_(me,"class","relative group"),_(Be,"id","validating-the-model-outputs"),_(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Be,"href","#validating-the-model-outputs"),_(ge,"class","relative group"),_(io,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig.generate_dummy_inputs"),_(Xe,"id","contributing-a-new-configuration-to-transformers"),_(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Xe,"href","#contributing-a-new-configuration-to-transformers"),_(_e,"class","relative group"),_(It,"href","https://github.com/huggingface/transformers/pull/14868/files"),_(It,"rel","nofollow")},m(t,i){e(document.head,c),d(t,w,i),d(t,m,i),e(m,E),e(E,$),O(v,$,null),e(m,x),e(m,b),e(b,q),d(t,C,i),d(t,A,i),e(A,L),e(A,I),e(I,g),e(A,D),d(t,R,i),O(X,t,i),d(t,Q,i),d(t,W,i),e(W,He),e(W,K),e(K,Ve),e(W,We),d(t,Z,i),d(t,P,i),e(P,Xt),d(t,Ge,i),d(t,J,i),e(J,Rt),e(J,fe),e(fe,ve),e(ve,Ft),e(J,Yl),d(t,sa,i),d(t,St,i),e(St,Ul),d(t,na,i),d(t,h,i),e(h,xo),e(xo,Kl),e(h,Jl),e(h,bo),e(bo,Ql),e(h,Zl),e(h,ko),e(ko,er),e(h,tr),e(h,yo),e(yo,or),e(h,sr),e(h,Oo),e(Oo,nr),e(h,ar),e(h,To),e(To,lr),e(h,rr),e(h,No),e(No,ir),e(h,pr),e(h,jo),e(jo,fr),e(h,dr),e(h,Co),e(Co,cr),e(h,hr),e(h,Do),e(Do,ur),e(h,mr),e(h,qo),e(qo,gr),e(h,_r),e(h,Lo),e(Lo,vr),e(h,Er),e(h,Ao),e(Ao,wr),e(h,$r),e(h,Io),e(Io,xr),e(h,br),e(h,Po),e(Po,kr),e(h,yr),e(h,Bo),e(Bo,Or),e(h,Tr),e(h,Mo),e(Mo,Nr),e(h,jr),e(h,Xo),e(Xo,Cr),e(h,Dr),e(h,Ro),e(Ro,qr),e(h,Lr),e(h,Fo),e(Fo,Ar),e(h,Ir),e(h,So),e(So,Pr),e(h,Br),e(h,zo),e(zo,Mr),e(h,Xr),e(h,Ho),e(Ho,Rr),e(h,Fr),e(h,Vo),e(Vo,Sr),e(h,zr),e(h,Wo),e(Wo,Hr),e(h,Vr),e(h,Go),e(Go,Wr),e(h,Gr),e(h,Yo),e(Yo,Yr),e(h,Ur),e(h,Uo),e(Uo,Kr),e(h,Jr),e(h,Ko),e(Ko,Qr),e(h,Zr),e(h,Jo),e(Jo,ei),e(h,ti),e(h,Qo),e(Qo,oi),e(h,si),e(h,Zo),e(Zo,ni),e(h,ai),e(h,es),e(es,li),e(h,ri),e(h,ts),e(ts,ii),e(h,pi),e(h,os),e(os,fi),e(h,di),e(h,ss),e(ss,ci),e(h,hi),e(h,ns),e(ns,ui),e(h,mi),e(h,as),e(as,gi),e(h,_i),e(h,ls),e(ls,vi),e(h,Ei),e(h,rs),e(rs,wi),e(h,$i),e(h,is),e(is,xi),e(h,bi),e(h,ps),e(ps,ki),e(h,yi),e(h,fs),e(fs,Oi),e(h,Ti),e(h,ds),e(ds,Ni),e(h,ji),e(h,cs),e(cs,Ci),e(h,Di),e(h,hs),e(hs,qi),e(h,Li),e(h,us),e(us,Ai),e(h,Ii),e(h,ms),e(ms,Pi),e(h,Bi),e(h,gs),e(gs,Mi),e(h,Xi),e(h,_s),e(_s,Ri),e(h,Fi),e(h,vs),e(vs,Si),e(h,zi),e(h,Es),e(Es,Hi),e(h,Vi),e(h,ws),e(ws,Wi),e(h,Gi),e(h,$s),e($s,Yi),e(h,Ui),e(h,xs),e(xs,Ki),d(t,aa,i),d(t,zt,i),e(zt,Ji),d(t,la,i),d(t,Ee,i),e(Ee,Ye),e(Ye,Qi),e(Ye,bs),e(bs,Zi),e(Ye,ep),e(Ee,tp),e(Ee,ks),e(ks,op),d(t,ra,i),d(t,de,i),e(de,we),e(we,ys),O(Ue,ys,null),e(de,sp),e(de,Os),e(Os,np),d(t,ia,i),d(t,Ht,i),e(Ht,ap),d(t,pa,i),O(Ke,t,i),d(t,fa,i),d(t,$e,i),e($e,lp),e($e,Ts),e(Ts,rp),e($e,ip),d(t,da,i),O(Je,t,i),d(t,ca,i),d(t,Vt,i),e(Vt,pp),d(t,ha,i),O(Qe,t,i),d(t,ua,i),d(t,Wt,i),e(Wt,fp),d(t,ma,i),O(Ze,t,i),d(t,ga,i),d(t,ee,i),e(ee,dp),e(ee,Ns),e(Ns,cp),e(ee,hp),e(ee,js),e(js,up),e(ee,mp),d(t,_a,i),d(t,G,i),e(G,gp),e(G,Cs),e(Cs,_p),e(G,vp),e(G,et),e(et,Ep),e(G,wp),e(G,tt),e(tt,$p),e(G,xp),d(t,va,i),O(ot,t,i),d(t,Ea,i),d(t,xe,i),e(xe,bp),e(xe,Ds),e(Ds,kp),e(xe,yp),d(t,wa,i),O(st,t,i),d(t,$a,i),d(t,be,i),e(be,Op),e(be,nt),e(nt,Tp),e(be,Np),d(t,xa,i),O(at,t,i),d(t,ba,i),d(t,Gt,i),e(Gt,jp),d(t,ka,i),O(ke,t,i),d(t,ya,i),d(t,ce,i),e(ce,ye),e(ye,qs),O(lt,qs,null),e(ce,Cp),e(ce,Ls),e(Ls,Dp),d(t,Oa,i),d(t,te,i),e(te,qp),e(te,As),e(As,Lp),e(te,Ap),e(te,Is),e(Is,Ip),e(te,Pp),d(t,Ta,i),d(t,Oe,i),e(Oe,Ps),e(Ps,rt),e(rt,Bs),e(Bs,Bp),e(rt,Mp),e(rt,Ms),e(Ms,Xp),e(Oe,Rp),e(Oe,F),e(F,it),e(it,pt),e(pt,Xs),e(Xs,Fp),e(pt,Sp),e(pt,Rs),e(Rs,zp),e(it,Hp),e(it,Fs),e(Fs,Ss),e(Ss,Vp),e(F,Wp),e(F,ft),e(ft,dt),e(dt,zs),e(zs,Gp),e(dt,Yp),e(dt,Hs),e(Hs,Up),e(ft,Kp),e(ft,Vs),e(Vs,Ws),e(Ws,Jp),e(F,Qp),e(F,ct),e(ct,Gs),e(Gs,Ys),e(Ys,Zp),e(ct,ef),e(ct,Us),e(Us,Ks),e(Ks,tf),e(F,of),e(F,ht),e(ht,Js),e(Js,Qs),e(Qs,sf),e(ht,nf),e(ht,Zs),e(Zs,en),e(en,af),e(F,lf),e(F,ut),e(ut,mt),e(mt,tn),e(tn,rf),e(mt,pf),e(mt,on),e(on,ff),e(ut,df),e(ut,sn),e(sn,nn),e(nn,cf),e(F,hf),e(F,gt),e(gt,an),e(an,ln),e(ln,uf),e(gt,mf),e(gt,rn),e(rn,pn),e(pn,gf),e(F,_f),e(F,_t),e(_t,fn),e(fn,dn),e(dn,vf),e(_t,Ef),e(_t,cn),e(cn,hn),e(hn,wf),d(t,Na,i),d(t,Te,i),e(Te,$f),e(Te,Yt),e(Yt,xf),e(Te,bf),d(t,ja,i),O(vt,t,i),d(t,Ca,i),d(t,oe,i),e(oe,kf),e(oe,un),e(un,yf),e(oe,Of),e(oe,mn),e(mn,Tf),e(oe,Nf),d(t,Da,i),O(Et,t,i),d(t,qa,i),d(t,Ut,i),e(Ut,jf),d(t,La,i),O(wt,t,i),d(t,Aa,i),d(t,Y,i),e(Y,Cf),e(Y,gn),e(gn,Df),e(Y,qf),e(Y,_n),e(_n,Lf),e(Y,Af),e(Y,vn),e(vn,If),e(Y,Pf),d(t,Ia,i),O(Ne,t,i),d(t,Pa,i),d(t,he,i),e(he,je),e(je,En),O($t,En,null),e(he,Bf),e(he,wn),e(wn,Mf),d(t,Ba,i),d(t,Kt,i),e(Kt,Xf),d(t,Ma,i),d(t,se,i),e(se,$n),e($n,Rf),e(se,Ff),e(se,xn),e(xn,Sf),e(se,zf),e(se,bn),e(bn,Hf),d(t,Xa,i),d(t,Jt,i),e(Jt,Vf),d(t,Ra,i),d(t,ue,i),e(ue,Ce),e(Ce,kn),O(xt,kn,null),e(ue,Wf),e(ue,yn),e(yn,Gf),d(t,Fa,i),d(t,Qt,i),e(Qt,Yf),d(t,Sa,i),d(t,ne,i),e(ne,Zt),e(Zt,Uf),e(Zt,eo),e(eo,Kf),e(ne,Jf),e(ne,to),e(to,Qf),e(to,oo),e(oo,Zf),e(ne,ed),e(ne,so),e(so,td),e(so,no),e(no,od),d(t,za,i),O(De,t,i),d(t,Ha,i),d(t,qe,i),e(qe,sd),e(qe,On),e(On,nd),e(qe,ad),d(t,Va,i),O(bt,t,i),d(t,Wa,i),d(t,z,i),e(z,ld),e(z,Tn),e(Tn,rd),e(z,id),e(z,Nn),e(Nn,pd),e(z,fd),e(z,jn),e(jn,dd),e(z,cd),e(z,Cn),e(Cn,hd),e(z,ud),d(t,Ga,i),O(Le,t,i),d(t,Ya,i),d(t,ao,i),e(ao,md),d(t,Ua,i),O(kt,t,i),d(t,Ka,i),d(t,lo,i),e(lo,gd),d(t,Ja,i),O(yt,t,i),d(t,Qa,i),d(t,ro,i),e(ro,_d),d(t,Za,i),O(Ot,t,i),d(t,el,i),d(t,H,i),e(H,vd),e(H,Dn),e(Dn,Ed),e(H,wd),e(H,qn),e(qn,$d),e(H,xd),e(H,Ln),e(Ln,bd),e(H,kd),e(H,An),e(An,yd),e(H,Od),d(t,tl,i),O(Tt,t,i),d(t,ol,i),O(Ae,t,i),d(t,sl,i),d(t,me,i),e(me,Ie),e(Ie,In),O(Nt,In,null),e(me,Td),e(me,Pn),e(Pn,Nd),d(t,nl,i),d(t,ae,i),e(ae,jd),e(ae,Bn),e(Bn,Cd),e(ae,Dd),e(ae,Mn),e(Mn,qd),e(ae,Ld),d(t,al,i),O(jt,t,i),d(t,ll,i),d(t,S,i),e(S,Ad),e(S,Xn),e(Xn,Id),e(S,Pd),e(S,Rn),e(Rn,Bd),e(S,Md),e(S,Fn),e(Fn,Xd),e(S,Rd),e(S,Sn),e(Sn,Fd),e(S,Sd),e(S,zn),e(zn,zd),e(S,Hd),d(t,rl,i),O(Ct,t,i),d(t,il,i),O(Pe,t,i),d(t,pl,i),d(t,ge,i),e(ge,Be),e(Be,Hn),O(Dt,Hn,null),e(ge,Vd),e(ge,Vn),e(Vn,Wd),d(t,fl,i),d(t,le,i),e(le,Gd),e(le,Wn),e(Wn,Yd),e(le,Ud),e(le,Gn),e(Gn,Kd),e(le,Jd),d(t,dl,i),O(qt,t,i),d(t,cl,i),d(t,Me,i),e(Me,Qd),e(Me,io),e(io,Zd),e(Me,ec),d(t,hl,i),d(t,_e,i),e(_e,Xe),e(Xe,Yn),O(Lt,Yn,null),e(_e,tc),e(_e,Un),e(Un,oc),d(t,ul,i),d(t,po,i),e(po,sc),d(t,ml,i),d(t,re,i),e(re,At),e(At,nc),e(At,Kn),e(Kn,ac),e(At,lc),e(re,rc),e(re,fo),e(fo,ic),e(fo,Jn),e(Jn,pc),e(re,fc),e(re,co),e(co,dc),e(co,Qn),e(Qn,cc),d(t,gl,i),d(t,Re,i),e(Re,hc),e(Re,It),e(It,uc),e(Re,mc),_l=!0},p(t,[i]){const Pt={};i&2&&(Pt.$$scope={dirty:i,ctx:t}),X.$set(Pt);const Zn={};i&2&&(Zn.$$scope={dirty:i,ctx:t}),ke.$set(Zn);const ea={};i&2&&(ea.$$scope={dirty:i,ctx:t}),Ne.$set(ea);const ta={};i&2&&(ta.$$scope={dirty:i,ctx:t}),De.$set(ta);const Bt={};i&2&&(Bt.$$scope={dirty:i,ctx:t}),Le.$set(Bt);const oa={};i&2&&(oa.$$scope={dirty:i,ctx:t}),Ae.$set(oa);const Mt={};i&2&&(Mt.$$scope={dirty:i,ctx:t}),Pe.$set(Mt)},i(t){_l||(T(v.$$.fragment,t),T(X.$$.fragment,t),T(Ue.$$.fragment,t),T(Ke.$$.fragment,t),T(Je.$$.fragment,t),T(Qe.$$.fragment,t),T(Ze.$$.fragment,t),T(ot.$$.fragment,t),T(st.$$.fragment,t),T(at.$$.fragment,t),T(ke.$$.fragment,t),T(lt.$$.fragment,t),T(vt.$$.fragment,t),T(Et.$$.fragment,t),T(wt.$$.fragment,t),T(Ne.$$.fragment,t),T($t.$$.fragment,t),T(xt.$$.fragment,t),T(De.$$.fragment,t),T(bt.$$.fragment,t),T(Le.$$.fragment,t),T(kt.$$.fragment,t),T(yt.$$.fragment,t),T(Ot.$$.fragment,t),T(Tt.$$.fragment,t),T(Ae.$$.fragment,t),T(Nt.$$.fragment,t),T(jt.$$.fragment,t),T(Ct.$$.fragment,t),T(Pe.$$.fragment,t),T(Dt.$$.fragment,t),T(qt.$$.fragment,t),T(Lt.$$.fragment,t),_l=!0)},o(t){N(v.$$.fragment,t),N(X.$$.fragment,t),N(Ue.$$.fragment,t),N(Ke.$$.fragment,t),N(Je.$$.fragment,t),N(Qe.$$.fragment,t),N(Ze.$$.fragment,t),N(ot.$$.fragment,t),N(st.$$.fragment,t),N(at.$$.fragment,t),N(ke.$$.fragment,t),N(lt.$$.fragment,t),N(vt.$$.fragment,t),N(Et.$$.fragment,t),N(wt.$$.fragment,t),N(Ne.$$.fragment,t),N($t.$$.fragment,t),N(xt.$$.fragment,t),N(De.$$.fragment,t),N(bt.$$.fragment,t),N(Le.$$.fragment,t),N(kt.$$.fragment,t),N(yt.$$.fragment,t),N(Ot.$$.fragment,t),N(Tt.$$.fragment,t),N(Ae.$$.fragment,t),N(Nt.$$.fragment,t),N(jt.$$.fragment,t),N(Ct.$$.fragment,t),N(Pe.$$.fragment,t),N(Dt.$$.fragment,t),N(qt.$$.fragment,t),N(Lt.$$.fragment,t),_l=!1},d(t){o(c),t&&o(w),t&&o(m),j(v),t&&o(C),t&&o(A),t&&o(R),j(X,t),t&&o(Q),t&&o(W),t&&o(Z),t&&o(P),t&&o(Ge),t&&o(J),t&&o(sa),t&&o(St),t&&o(na),t&&o(h),t&&o(aa),t&&o(zt),t&&o(la),t&&o(Ee),t&&o(ra),t&&o(de),j(Ue),t&&o(ia),t&&o(Ht),t&&o(pa),j(Ke,t),t&&o(fa),t&&o($e),t&&o(da),j(Je,t),t&&o(ca),t&&o(Vt),t&&o(ha),j(Qe,t),t&&o(ua),t&&o(Wt),t&&o(ma),j(Ze,t),t&&o(ga),t&&o(ee),t&&o(_a),t&&o(G),t&&o(va),j(ot,t),t&&o(Ea),t&&o(xe),t&&o(wa),j(st,t),t&&o($a),t&&o(be),t&&o(xa),j(at,t),t&&o(ba),t&&o(Gt),t&&o(ka),j(ke,t),t&&o(ya),t&&o(ce),j(lt),t&&o(Oa),t&&o(te),t&&o(Ta),t&&o(Oe),t&&o(Na),t&&o(Te),t&&o(ja),j(vt,t),t&&o(Ca),t&&o(oe),t&&o(Da),j(Et,t),t&&o(qa),t&&o(Ut),t&&o(La),j(wt,t),t&&o(Aa),t&&o(Y),t&&o(Ia),j(Ne,t),t&&o(Pa),t&&o(he),j($t),t&&o(Ba),t&&o(Kt),t&&o(Ma),t&&o(se),t&&o(Xa),t&&o(Jt),t&&o(Ra),t&&o(ue),j(xt),t&&o(Fa),t&&o(Qt),t&&o(Sa),t&&o(ne),t&&o(za),j(De,t),t&&o(Ha),t&&o(qe),t&&o(Va),j(bt,t),t&&o(Wa),t&&o(z),t&&o(Ga),j(Le,t),t&&o(Ya),t&&o(ao),t&&o(Ua),j(kt,t),t&&o(Ka),t&&o(lo),t&&o(Ja),j(yt,t),t&&o(Qa),t&&o(ro),t&&o(Za),j(Ot,t),t&&o(el),t&&o(H),t&&o(tl),j(Tt,t),t&&o(ol),j(Ae,t),t&&o(sl),t&&o(me),j(Nt),t&&o(nl),t&&o(ae),t&&o(al),j(jt,t),t&&o(ll),t&&o(S),t&&o(rl),j(Ct,t),t&&o(il),j(Pe,t),t&&o(pl),t&&o(ge),j(Dt),t&&o(fl),t&&o(le),t&&o(dl),j(qt,t),t&&o(cl),t&&o(Me),t&&o(hl),t&&o(_e),j(Lt),t&&o(ul),t&&o(po),t&&o(ml),t&&o(re),t&&o(gl),t&&o(Re)}}}const Km={local:"export-to-onnx",sections:[{local:"exporting-a-model-to-onnx",title:"Exporting a model to ONNX"},{local:"selecting-features-for-different-model-tasks",title:"Selecting features for different model tasks"},{local:"exporting-a-model-for-an-unsupported-architecture",sections:[{local:"implementing-a-custom-onnx-configuration",title:"Implementing a custom ONNX configuration"},{local:"exporting-the-model",title:"Exporting the model"},{local:"validating-the-model-outputs",title:"Validating the model outputs"}],title:"Exporting a model for an unsupported architecture"},{local:"contributing-a-new-configuration-to-transformers",title:"Contributing a new configuration to \u{1F917} Transformers"}],title:"Export to ONNX"};function Jm(M){return Bm(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class sg extends Lm{constructor(c){super();Am(this,c,Jm,Um,Im,{})}}export{sg as default,Km as metadata};
