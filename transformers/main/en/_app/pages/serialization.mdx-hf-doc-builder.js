import{S as Bm,i as Mm,s as Xm,e as a,k as p,w as k,t as s,M as Rm,c as l,d as o,m as f,a as r,x as y,h as n,b as _,G as e,g as d,y as O,q as T,o as N,B as j,v as Fm,L as Im}from"../chunks/vendor-hf-doc-builder.js";import{T as $o}from"../chunks/Tip-hf-doc-builder.js";import{I as ze}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as B}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as Sm,M as Pm}from"../chunks/Markdown-hf-doc-builder.js";function zm(M){let c,w,m,E,$;return{c(){c=a("p"),w=s(`Once exported, a model can be optimized for inference via techniques such as
quantization and pruning. If you are interested in optimizing your models to run with
maximum efficiency, check out the `),m=a("a"),E=s(`\u{1F917} Optimum
library`),$=s("."),this.h()},l(v){c=l(v,"P",{});var x=r(c);w=n(x,`Once exported, a model can be optimized for inference via techniques such as
quantization and pruning. If you are interested in optimizing your models to run with
maximum efficiency, check out the `),m=l(x,"A",{href:!0,rel:!0});var b=r(m);E=n(b,`\u{1F917} Optimum
library`),b.forEach(o),$=n(x,"."),x.forEach(o),this.h()},h(){_(m,"href","https://github.com/huggingface/optimum"),_(m,"rel","nofollow")},m(v,x){d(v,c,x),e(c,w),e(c,m),e(m,E),e(c,$)},d(v){v&&o(c)}}}function Hm(M){let c,w,m,E,$,v,x,b,q,C,A,L,I;return c=new B({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load tokenizer and PyTorch weights form the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
pt_model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-pt-checkpoint")
pt_model.save_pretrained("local-pt-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and PyTorch weights form the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)`}}),L=new B({props:{code:"python -m transformers.onnx --model=local-pt-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-pt-checkpoint onnx/"}}),{c(){k(c.$$.fragment),w=p(),m=a("p"),E=s("Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=a("code"),v=s("--model"),x=s(`
argument of the `),b=a("code"),q=s("transformers.onnx"),C=s(" package to the desired directory:"),A=p(),k(L.$$.fragment)},l(g){y(c.$$.fragment,g),w=f(g),m=l(g,"P",{});var D=r(m);E=n(D,"Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=l(D,"CODE",{});var R=r($);v=n(R,"--model"),R.forEach(o),x=n(D,`
argument of the `),b=l(D,"CODE",{});var X=r(b);q=n(X,"transformers.onnx"),X.forEach(o),C=n(D," package to the desired directory:"),D.forEach(o),A=f(g),y(L.$$.fragment,g)},m(g,D){O(c,g,D),d(g,w,D),d(g,m,D),e(m,E),e(m,$),e($,v),e(m,x),e(m,b),e(b,q),e(m,C),d(g,A,D),O(L,g,D),I=!0},p:Im,i(g){I||(T(c.$$.fragment,g),T(L.$$.fragment,g),I=!0)},o(g){N(c.$$.fragment,g),N(L.$$.fragment,g),I=!1},d(g){j(c,g),g&&o(w),g&&o(m),g&&o(A),j(L,g)}}}function Vm(M){let c,w;return c=new Pm({props:{$$slots:{default:[Hm]},$$scope:{ctx:M}}}),{c(){k(c.$$.fragment)},l(m){y(c.$$.fragment,m)},m(m,E){O(c,m,E),w=!0},p(m,E){const $={};E&2&&($.$$scope={dirty:E,ctx:m}),c.$set($)},i(m){w||(T(c.$$.fragment,m),w=!0)},o(m){N(c.$$.fragment,m),w=!1},d(m){j(c,m)}}}function Wm(M){let c,w,m,E,$,v,x,b,q,C,A,L,I;return c=new B({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

# Load tokenizer and TensorFlow weights from the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tf_model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-tf-checkpoint")
tf_model.save_pretrained("local-tf-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and TensorFlow weights from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)`}}),L=new B({props:{code:"python -m transformers.onnx --model=local-tf-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-tf-checkpoint onnx/"}}),{c(){k(c.$$.fragment),w=p(),m=a("p"),E=s("Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=a("code"),v=s("--model"),x=s(`
argument of the `),b=a("code"),q=s("transformers.onnx"),C=s(" package to the desired directory:"),A=p(),k(L.$$.fragment)},l(g){y(c.$$.fragment,g),w=f(g),m=l(g,"P",{});var D=r(m);E=n(D,"Once the checkpoint is saved, we can export it to ONNX by pointing the "),$=l(D,"CODE",{});var R=r($);v=n(R,"--model"),R.forEach(o),x=n(D,`
argument of the `),b=l(D,"CODE",{});var X=r(b);q=n(X,"transformers.onnx"),X.forEach(o),C=n(D," package to the desired directory:"),D.forEach(o),A=f(g),y(L.$$.fragment,g)},m(g,D){O(c,g,D),d(g,w,D),d(g,m,D),e(m,E),e(m,$),e($,v),e(m,x),e(m,b),e(b,q),e(m,C),d(g,A,D),O(L,g,D),I=!0},p:Im,i(g){I||(T(c.$$.fragment,g),T(L.$$.fragment,g),I=!0)},o(g){N(c.$$.fragment,g),N(L.$$.fragment,g),I=!1},d(g){j(c,g),g&&o(w),g&&o(m),g&&o(A),j(L,g)}}}function Gm(M){let c,w;return c=new Pm({props:{$$slots:{default:[Wm]},$$scope:{ctx:M}}}),{c(){k(c.$$.fragment)},l(m){y(c.$$.fragment,m)},m(m,E){O(c,m,E),w=!0},p(m,E){const $={};E&2&&($.$$scope={dirty:E,ctx:m}),c.$set($)},i(m){w||(T(c.$$.fragment,m),w=!0)},o(m){N(c.$$.fragment,m),w=!1},d(m){j(c,m)}}}function Ym(M){let c,w,m,E,$,v,x,b;return{c(){c=a("p"),w=s("The features that have a "),m=a("code"),E=s("with-past"),$=s(" suffix (like "),v=a("code"),x=s("causal-lm-with-past"),b=s(`) correspond to
model classes with precomputed hidden states (key and values in the attention blocks)
that can be used for fast autoregressive decoding.`)},l(q){c=l(q,"P",{});var C=r(c);w=n(C,"The features that have a "),m=l(C,"CODE",{});var A=r(m);E=n(A,"with-past"),A.forEach(o),$=n(C," suffix (like "),v=l(C,"CODE",{});var L=r(v);x=n(L,"causal-lm-with-past"),L.forEach(o),b=n(C,`) correspond to
model classes with precomputed hidden states (key and values in the attention blocks)
that can be used for fast autoregressive decoding.`),C.forEach(o)},m(q,C){d(q,c,C),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b)},d(q){q&&o(c)}}}function Um(M){let c,w,m,E,$;return{c(){c=a("p"),w=s(`A good way to implement a custom ONNX configuration is to look at the existing
implementation in the `),m=a("code"),E=s("configuration_<model_name>.py"),$=s(" file of a similar architecture.")},l(v){c=l(v,"P",{});var x=r(c);w=n(x,`A good way to implement a custom ONNX configuration is to look at the existing
implementation in the `),m=l(x,"CODE",{});var b=r(m);E=n(b,"configuration_<model_name>.py"),b.forEach(o),$=n(x," file of a similar architecture."),x.forEach(o)},m(v,x){d(v,c,x),e(c,w),e(c,m),e(m,E),e(c,$)},d(v){v&&o(c)}}}function Km(M){let c,w,m,E,$,v,x,b,q,C,A,L,I,g,D,R,X,Q,W,He,K,Ve,We;return{c(){c=a("p"),w=s("Notice that "),m=a("code"),E=s("inputs"),$=s(" property for "),v=a("code"),x=s("DistilBertOnnxConfig"),b=s(" returns an "),q=a("code"),C=s("OrderedDict"),A=s(`. This
ensures that the inputs are matched with their relative position within the
`),L=a("code"),I=s("PreTrainedModel.forward()"),g=s(` method when tracing the graph. We recommend using an
`),D=a("code"),R=s("OrderedDict"),X=s(" for the "),Q=a("code"),W=s("inputs"),He=s(" and "),K=a("code"),Ve=s("outputs"),We=s(` properties when implementing custom ONNX
configurations.`)},l(Z){c=l(Z,"P",{});var P=r(c);w=n(P,"Notice that "),m=l(P,"CODE",{});var Xt=r(m);E=n(Xt,"inputs"),Xt.forEach(o),$=n(P," property for "),v=l(P,"CODE",{});var Ge=r(v);x=n(Ge,"DistilBertOnnxConfig"),Ge.forEach(o),b=n(P," returns an "),q=l(P,"CODE",{});var J=r(q);C=n(J,"OrderedDict"),J.forEach(o),A=n(P,`. This
ensures that the inputs are matched with their relative position within the
`),L=l(P,"CODE",{});var Rt=r(L);I=n(Rt,"PreTrainedModel.forward()"),Rt.forEach(o),g=n(P,` method when tracing the graph. We recommend using an
`),D=l(P,"CODE",{});var fe=r(D);R=n(fe,"OrderedDict"),fe.forEach(o),X=n(P," for the "),Q=l(P,"CODE",{});var ve=r(Q);W=n(ve,"inputs"),ve.forEach(o),He=n(P," and "),K=l(P,"CODE",{});var Ft=r(K);Ve=n(Ft,"outputs"),Ft.forEach(o),We=n(P,` properties when implementing custom ONNX
configurations.`),P.forEach(o)},m(Z,P){d(Z,c,P),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b),e(c,q),e(q,C),e(c,A),e(c,L),e(L,I),e(c,g),e(c,D),e(D,R),e(c,X),e(c,Q),e(Q,W),e(c,He),e(c,K),e(K,Ve),e(c,We)},d(Z){Z&&o(c)}}}function Jm(M){let c,w,m,E,$,v,x,b;return{c(){c=a("p"),w=s("All of the base properties and methods associated with "),m=a("a"),E=s("OnnxConfig"),$=s(` and
the other configuration classes can be overriden if needed. Check out `),v=a("code"),x=s("BartOnnxConfig"),b=s(`
for an advanced example.`),this.h()},l(q){c=l(q,"P",{});var C=r(c);w=n(C,"All of the base properties and methods associated with "),m=l(C,"A",{href:!0});var A=r(m);E=n(A,"OnnxConfig"),A.forEach(o),$=n(C,` and
the other configuration classes can be overriden if needed. Check out `),v=l(C,"CODE",{});var L=r(v);x=n(L,"BartOnnxConfig"),L.forEach(o),b=n(C,`
for an advanced example.`),C.forEach(o),this.h()},h(){_(m,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig")},m(q,C){d(q,c,C),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b)},d(q){q&&o(c)}}}function Qm(M){let c,w,m,E,$,v,x,b,q,C,A;return{c(){c=a("p"),w=s(`If your model is larger than 2GB, you will see that many additional files are created
during the export. This is `),m=a("em"),E=s("expected"),$=s(" because ONNX uses "),v=a("a"),x=s(`Protocol
Buffers`),b=s(` to store the model and these
have a size limit of 2GB. See the `),q=a("a"),C=s(`ONNX
documentation`),A=s(` for
instructions on how to load models with external data.`),this.h()},l(L){c=l(L,"P",{});var I=r(c);w=n(I,`If your model is larger than 2GB, you will see that many additional files are created
during the export. This is `),m=l(I,"EM",{});var g=r(m);E=n(g,"expected"),g.forEach(o),$=n(I," because ONNX uses "),v=l(I,"A",{href:!0,rel:!0});var D=r(v);x=n(D,`Protocol
Buffers`),D.forEach(o),b=n(I,` to store the model and these
have a size limit of 2GB. See the `),q=l(I,"A",{href:!0,rel:!0});var R=r(q);C=n(R,`ONNX
documentation`),R.forEach(o),A=n(I,` for
instructions on how to load models with external data.`),I.forEach(o),this.h()},h(){_(v,"href","https://developers.google.com/protocol-buffers/"),_(v,"rel","nofollow"),_(q,"href","https://github.com/onnx/onnx/blob/master/docs/ExternalData.md"),_(q,"rel","nofollow")},m(L,I){d(L,c,I),e(c,w),e(c,m),e(m,E),e(c,$),e(c,v),e(v,x),e(c,b),e(c,q),e(q,C),e(c,A)},d(L){L&&o(c)}}}function Zm(M){let c,w,m,E,$,v,x,b,q,C,A,L,I,g,D,R,X,Q,W,He,K,Ve,We,Z,P,Xt,Ge,J,Rt,fe,ve,Ft,Ul,na,St,Kl,aa,h,xo,Jl,Ql,bo,Zl,er,ko,tr,or,yo,sr,nr,Oo,ar,lr,To,rr,ir,No,pr,fr,jo,dr,cr,Co,hr,ur,Do,mr,gr,qo,_r,vr,Lo,Er,wr,Ao,$r,xr,Io,br,kr,Po,yr,Or,Bo,Tr,Nr,Mo,jr,Cr,Xo,Dr,qr,Ro,Lr,Ar,Fo,Ir,Pr,So,Br,Mr,zo,Xr,Rr,Ho,Fr,Sr,Vo,zr,Hr,Wo,Vr,Wr,Go,Gr,Yr,Yo,Ur,Kr,Uo,Jr,Qr,Ko,Zr,ei,Jo,ti,oi,Qo,si,ni,Zo,ai,li,es,ri,ii,ts,pi,fi,os,di,ci,ss,hi,ui,ns,mi,gi,as,_i,vi,ls,Ei,wi,rs,$i,xi,is,bi,ki,ps,yi,Oi,fs,Ti,Ni,ds,ji,Ci,cs,Di,qi,hs,Li,Ai,us,Ii,Pi,ms,Bi,Mi,gs,Xi,Ri,_s,Fi,Si,vs,zi,Hi,Es,Vi,Wi,ws,Gi,Yi,$s,Ui,Ki,xs,Ji,Qi,bs,Zi,la,zt,ep,ra,Ee,Ye,tp,ks,op,sp,np,ys,ap,ia,de,we,Os,Ue,lp,Ts,rp,pa,Ht,ip,fa,Ke,da,$e,pp,Ns,fp,dp,ca,Je,ha,Vt,cp,ua,Qe,ma,Wt,hp,ga,Ze,_a,ee,up,js,mp,gp,Cs,_p,vp,va,G,Ep,Ds,wp,$p,et,xp,bp,tt,kp,yp,Ea,ot,wa,xe,Op,qs,Tp,Np,$a,st,xa,be,jp,nt,Cp,Dp,ba,at,ka,Gt,qp,ya,ke,Oa,ce,ye,Ls,lt,Lp,As,Ap,Ta,te,Ip,Is,Pp,Bp,Ps,Mp,Xp,Na,Oe,Bs,rt,Ms,Rp,Fp,Xs,Sp,zp,F,it,pt,Rs,Hp,Vp,Fs,Wp,Gp,Ss,zs,Yp,Up,ft,dt,Hs,Kp,Jp,Vs,Qp,Zp,Ws,Gs,ef,tf,ct,Ys,Us,of,sf,Ks,Js,nf,af,ht,Qs,Zs,lf,rf,en,tn,pf,ff,ut,mt,on,df,cf,sn,hf,uf,nn,an,mf,gf,gt,ln,rn,_f,vf,pn,fn,Ef,wf,_t,dn,cn,$f,xf,hn,un,bf,ja,Te,kf,Yt,yf,Of,Ca,vt,Da,oe,Tf,mn,Nf,jf,gn,Cf,Df,qa,Et,La,Ut,qf,Aa,wt,Ia,Y,Lf,_n,Af,If,vn,Pf,Bf,En,Mf,Xf,Pa,Ne,Ba,he,je,wn,$t,Rf,$n,Ff,Ma,Kt,Sf,Xa,se,xn,zf,Hf,bn,Vf,Wf,kn,Gf,Ra,Jt,Yf,Fa,ue,Ce,yn,xt,Uf,On,Kf,Sa,Qt,Jf,za,ne,Zt,Qf,eo,Zf,ed,to,td,oo,od,sd,so,nd,no,ad,Ha,De,Va,qe,ld,Tn,rd,id,Wa,bt,Ga,z,pd,Nn,fd,dd,jn,cd,hd,Cn,ud,md,Dn,gd,_d,Ya,Le,Ua,ao,vd,Ka,kt,Ja,lo,Ed,Qa,yt,Za,ro,wd,el,Ot,tl,H,$d,qn,xd,bd,Ln,kd,yd,An,Od,Td,In,Nd,jd,ol,Tt,sl,Ae,nl,me,Ie,Pn,Nt,Cd,Bn,Dd,al,ae,qd,Mn,Ld,Ad,Xn,Id,Pd,ll,jt,rl,S,Bd,Rn,Md,Xd,Fn,Rd,Fd,Sn,Sd,zd,zn,Hd,Vd,Hn,Wd,Gd,il,Ct,pl,Pe,fl,ge,Be,Vn,Dt,Yd,Wn,Ud,dl,le,Kd,Gn,Jd,Qd,Yn,Zd,ec,cl,qt,hl,Me,tc,io,oc,sc,ul,_e,Xe,Un,Lt,nc,Kn,ac,ml,po,lc,gl,re,At,rc,Jn,ic,pc,fc,fo,dc,Qn,cc,hc,co,uc,Zn,mc,_l,Re,gc,It,_c,vc,vl;return v=new ze({}),X=new $o({props:{$$slots:{default:[zm]},$$scope:{ctx:M}}}),Ue=new ze({}),Ke=new B({props:{code:"pip install transformers[onnx]",highlighted:"pip install transformers[onnx]"}}),Je=new B({props:{code:`python -m transformers.onnx --help

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating where to store generated ONNX model.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The type of features to export the model with.
  --opset OPSET         ONNX opset version to export the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`,highlighted:`python -m transformers.onnx --<span class="hljs-built_in">help</span>

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating <span class="hljs-built_in">where</span> to store generated ONNX model.

optional arguments:
  -h, --<span class="hljs-built_in">help</span>            show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span>
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The <span class="hljs-built_in">type</span> of features to <span class="hljs-built_in">export</span> the model with.
  --opset OPSET         ONNX opset version to <span class="hljs-built_in">export</span> the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`}}),Qe=new B({props:{code:"python -m transformers.onnx --model=distilbert-base-uncased onnx/",highlighted:"python -m transformers.onnx --model=distilbert-base-uncased onnx/"}}),Ze=new B({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'last_hidden_state'})
        - Validating ONNX Model output "last_hidden_state":
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;last_hidden_state&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;last_hidden_state&quot;</span>:
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),ot=new B({props:{code:`from transformers import AutoTokenizer
from onnxruntime import InferenceSession

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
session = InferenceSession("onnx/model.onnx")
# ONNX Runtime expects NumPy arrays as input
inputs = tokenizer("Using DistilBERT with ONNX Runtime!", return_tensors="np")
outputs = session.run(output_names=["last_hidden_state"], input_feed=dict(inputs))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> onnxruntime <span class="hljs-keyword">import</span> InferenceSession

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>session = InferenceSession(<span class="hljs-string">&quot;onnx/model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ONNX Runtime expects NumPy arrays as input</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = session.run(output_names=[<span class="hljs-string">&quot;last_hidden_state&quot;</span>], input_feed=<span class="hljs-built_in">dict</span>(inputs))`}}),st=new B({props:{code:`from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig

config = DistilBertConfig()
onnx_config = DistilBertOnnxConfig(config)
print(list(onnx_config.outputs.keys()))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.models.distilbert <span class="hljs-keyword">import</span> DistilBertConfig, DistilBertOnnxConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(onnx_config.outputs.keys()))
[<span class="hljs-string">&quot;last_hidden_state&quot;</span>]`}}),at=new B({props:{code:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/",highlighted:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/"}}),ke=new Sm({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Gm],pytorch:[Vm]},$$scope:{ctx:M}}}),lt=new ze({}),vt=new B({props:{code:`from transformers.onnx.features import FeaturesManager

distilbert_features = list(FeaturesManager.get_supported_features_for_model_type("distilbert").keys())
print(distilbert_features)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx.features <span class="hljs-keyword">import</span> FeaturesManager

<span class="hljs-meta">&gt;&gt;&gt; </span>distilbert_features = <span class="hljs-built_in">list</span>(FeaturesManager.get_supported_features_for_model_type(<span class="hljs-string">&quot;distilbert&quot;</span>).keys())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(distilbert_features)
[<span class="hljs-string">&quot;default&quot;</span>, <span class="hljs-string">&quot;masked-lm&quot;</span>, <span class="hljs-string">&quot;causal-lm&quot;</span>, <span class="hljs-string">&quot;sequence-classification&quot;</span>, <span class="hljs-string">&quot;token-classification&quot;</span>, <span class="hljs-string">&quot;question-answering&quot;</span>]`}}),Et=new B({props:{code:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`,highlighted:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`}}),wt=new B({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'logits'})
        - Validating ONNX Model output "logits":
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;logits&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;logits&quot;</span>:
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),Ne=new $o({props:{$$slots:{default:[Ym]},$$scope:{ctx:M}}}),$t=new ze({}),xt=new ze({}),De=new $o({props:{$$slots:{default:[Um]},$$scope:{ctx:M}}}),bt=new B({props:{code:`from typing import Mapping, OrderedDict
from transformers.onnx import OnnxConfig


class DistilBertOnnxConfig(OnnxConfig):
    @property
    def inputs(self) -> Mapping[str, Mapping[int, str]]:
        return OrderedDict(
            [
                ("input_ids", {0: "batch", 1: "sequence"}),
                ("attention_mask", {0: "batch", 1: "sequence"}),
            ]
        )`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Mapping, OrderedDict
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> OnnxConfig


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistilBertOnnxConfig</span>(<span class="hljs-title class_ inherited__">OnnxConfig</span>):
<span class="hljs-meta">... </span>    @<span class="hljs-built_in">property</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inputs</span>(<span class="hljs-params">self</span>) -&gt; Mapping[<span class="hljs-built_in">str</span>, Mapping[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>]]:
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> OrderedDict(
<span class="hljs-meta">... </span>            [
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;input_ids&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;attention_mask&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>            ]
<span class="hljs-meta">... </span>        )`}}),Le=new $o({props:{$$slots:{default:[Km]},$$scope:{ctx:M}}}),kt=new B({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config = DistilBertOnnxConfig(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)`}}),yt=new B({props:{code:"print(onnx_config.default_onnx_opset)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.default_onnx_opset)
<span class="hljs-number">11</span>`}}),Ot=new B({props:{code:"print(onnx_config.outputs)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.outputs)
OrderedDict([(<span class="hljs-string">&quot;last_hidden_state&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>})])`}}),Tt=new B({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task="sequence-classification")
print(onnx_config_for_seq_clf.outputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=<span class="hljs-string">&quot;sequence-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config_for_seq_clf.outputs)
OrderedDict([(<span class="hljs-string">&#x27;logits&#x27;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;batch&#x27;</span>})])`}}),Ae=new $o({props:{$$slots:{default:[Jm]},$$scope:{ctx:M}}}),Nt=new ze({}),jt=new B({props:{code:`from pathlib import Path
from transformers.onnx import export
from transformers import AutoTokenizer, AutoModel

onnx_path = Path("model.onnx")
model_ckpt = "distilbert-base-uncased"
base_model = AutoModel.from_pretrained(model_ckpt)
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> export
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_path = Path(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model_ckpt = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>base_model = AutoModel.from_pretrained(model_ckpt)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`}}),Ct=new B({props:{code:`import onnx

onnx_model = onnx.load("model.onnx")
onnx.checker.check_model(onnx_model)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> onnx

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_model = onnx.load(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx.checker.check_model(onnx_model)`}}),Pe=new $o({props:{$$slots:{default:[Qm]},$$scope:{ctx:M}}}),Dt=new ze({}),qt=new B({props:{code:`from transformers.onnx import validate_model_outputs

validate_model_outputs(
    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> validate_model_outputs

<span class="hljs-meta">&gt;&gt;&gt; </span>validate_model_outputs(
<span class="hljs-meta">... </span>    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
<span class="hljs-meta">... </span>)`}}),Lt=new ze({}),{c(){c=a("meta"),w=p(),m=a("h1"),E=a("a"),$=a("span"),k(v.$$.fragment),x=p(),b=a("span"),q=s("Export to ONNX"),C=p(),A=a("p"),L=s(`If you need to deploy \u{1F917} Transformers models in production environments, we recommend
exporting them to a serialized format that can be loaded and executed on specialized
runtimes and hardware. In this guide, we\u2019ll show you how to export \u{1F917} Transformers
models to `),I=a("a"),g=s("ONNX (Open Neural Network eXchange)"),D=s("."),R=p(),k(X.$$.fragment),Q=p(),W=a("p"),He=s(`ONNX is an open standard that defines a common set of operators and a common file format
to represent deep learning models in a wide variety of frameworks, including PyTorch and
TensorFlow. When a model is exported to the ONNX format, these operators are used to
construct a computational graph (often called an `),K=a("em"),Ve=s("intermediate representation"),We=s(`) which
represents the flow of data through the neural network.`),Z=p(),P=a("p"),Xt=s(`By exposing a graph with standardized operators and data types, ONNX makes it easy to
switch between frameworks. For example, a model trained in PyTorch can be exported to
ONNX format and then imported in TensorFlow (and vice versa).`),Ge=p(),J=a("p"),Rt=s("\u{1F917} Transformers provides a "),fe=a("a"),ve=a("code"),Ft=s("transformers.onnx"),Ul=s(` package that enables
you to convert model checkpoints to an ONNX graph by leveraging configuration objects.
These configuration objects come ready made for a number of model architectures, and are
designed to be easily extendable to other architectures.`),na=p(),St=a("p"),Kl=s("Ready-made configurations include the following architectures:"),aa=p(),h=a("ul"),xo=a("li"),Jl=s("ALBERT"),Ql=p(),bo=a("li"),Zl=s("BART"),er=p(),ko=a("li"),tr=s("BEiT"),or=p(),yo=a("li"),sr=s("BERT"),nr=p(),Oo=a("li"),ar=s("BigBird"),lr=p(),To=a("li"),rr=s("BigBird-Pegasus"),ir=p(),No=a("li"),pr=s("Blenderbot"),fr=p(),jo=a("li"),dr=s("BlenderbotSmall"),cr=p(),Co=a("li"),hr=s("BLOOM"),ur=p(),Do=a("li"),mr=s("CamemBERT"),gr=p(),qo=a("li"),_r=s("CLIP"),vr=p(),Lo=a("li"),Er=s("CodeGen"),wr=p(),Ao=a("li"),$r=s("Conditional DETR"),xr=p(),Io=a("li"),br=s("ConvBERT"),kr=p(),Po=a("li"),yr=s("ConvNeXT"),Or=p(),Bo=a("li"),Tr=s("Data2VecText"),Nr=p(),Mo=a("li"),jr=s("Data2VecVision"),Cr=p(),Xo=a("li"),Dr=s("DeBERTa"),qr=p(),Ro=a("li"),Lr=s("DeBERTa-v2"),Ar=p(),Fo=a("li"),Ir=s("DeiT"),Pr=p(),So=a("li"),Br=s("DETR"),Mr=p(),zo=a("li"),Xr=s("DistilBERT"),Rr=p(),Ho=a("li"),Fr=s("ELECTRA"),Sr=p(),Vo=a("li"),zr=s("ERNIE"),Hr=p(),Wo=a("li"),Vr=s("FlauBERT"),Wr=p(),Go=a("li"),Gr=s("GPT Neo"),Yr=p(),Yo=a("li"),Ur=s("GPT-J"),Kr=p(),Uo=a("li"),Jr=s("GroupViT"),Qr=p(),Ko=a("li"),Zr=s("I-BERT"),ei=p(),Jo=a("li"),ti=s("LayoutLM"),oi=p(),Qo=a("li"),si=s("LayoutLMv3"),ni=p(),Zo=a("li"),ai=s("LeViT"),li=p(),es=a("li"),ri=s("Longformer"),ii=p(),ts=a("li"),pi=s("LongT5"),fi=p(),os=a("li"),di=s("M2M100"),ci=p(),ss=a("li"),hi=s("Marian"),ui=p(),ns=a("li"),mi=s("mBART"),gi=p(),as=a("li"),_i=s("MobileBERT"),vi=p(),ls=a("li"),Ei=s("MobileViT"),wi=p(),rs=a("li"),$i=s("MT5"),xi=p(),is=a("li"),bi=s("OpenAI GPT-2"),ki=p(),ps=a("li"),yi=s("OWL-ViT"),Oi=p(),fs=a("li"),Ti=s("Perceiver"),Ni=p(),ds=a("li"),ji=s("PLBart"),Ci=p(),cs=a("li"),Di=s("ResNet"),qi=p(),hs=a("li"),Li=s("RoBERTa"),Ai=p(),us=a("li"),Ii=s("RoFormer"),Pi=p(),ms=a("li"),Bi=s("SegFormer"),Mi=p(),gs=a("li"),Xi=s("SqueezeBERT"),Ri=p(),_s=a("li"),Fi=s("Swin Transformer"),Si=p(),vs=a("li"),zi=s("T5"),Hi=p(),Es=a("li"),Vi=s("ViT"),Wi=p(),ws=a("li"),Gi=s("XLM"),Yi=p(),$s=a("li"),Ui=s("XLM-RoBERTa"),Ki=p(),xs=a("li"),Ji=s("XLM-RoBERTa-XL"),Qi=p(),bs=a("li"),Zi=s("YOLOS"),la=p(),zt=a("p"),ep=s("In the next two sections, we\u2019ll show you how to:"),ra=p(),Ee=a("ul"),Ye=a("li"),tp=s("Export a supported model using the "),ks=a("code"),op=s("transformers.onnx"),sp=s(" package."),np=p(),ys=a("li"),ap=s("Export a custom model for an unsupported architecture."),ia=p(),de=a("h2"),we=a("a"),Os=a("span"),k(Ue.$$.fragment),lp=p(),Ts=a("span"),rp=s("Exporting a model to ONNX"),pa=p(),Ht=a("p"),ip=s(`To export a \u{1F917} Transformers model to ONNX, you\u2019ll first need to install some extra
dependencies:`),fa=p(),k(Ke.$$.fragment),da=p(),$e=a("p"),pp=s("The "),Ns=a("code"),fp=s("transformers.onnx"),dp=s(" package can then be used as a Python module:"),ca=p(),k(Je.$$.fragment),ha=p(),Vt=a("p"),cp=s("Exporting a checkpoint using a ready-made configuration can be done as follows:"),ua=p(),k(Qe.$$.fragment),ma=p(),Wt=a("p"),hp=s("You should see the following logs:"),ga=p(),k(Ze.$$.fragment),_a=p(),ee=a("p"),up=s("This exports an ONNX graph of the checkpoint defined by the "),js=a("code"),mp=s("--model"),gp=s(` argument. In this
example, it is `),Cs=a("code"),_p=s("distilbert-base-uncased"),vp=s(`, but it can be any checkpoint on the Hugging
Face Hub or one that\u2019s stored locally.`),va=p(),G=a("p"),Ep=s("The resulting "),Ds=a("code"),wp=s("model.onnx"),$p=s(" file can then be run on one of the "),et=a("a"),xp=s(`many
accelerators`),bp=s(` that support the ONNX
standard. For example, we can load and run the model with `),tt=a("a"),kp=s(`ONNX
Runtime`),yp=s(" as follows:"),Ea=p(),k(ot.$$.fragment),wa=p(),xe=a("p"),Op=s("The required output names (like "),qs=a("code"),Tp=s('["last_hidden_state"]'),Np=s(`) can be obtained by taking a
look at the ONNX configuration of each model. For example, for DistilBERT we have:`),$a=p(),k(st.$$.fragment),xa=p(),be=a("p"),jp=s(`The process is identical for TensorFlow checkpoints on the Hub. For example, we can
export a pure TensorFlow checkpoint from the `),nt=a("a"),Cp=s(`Keras
organization`),Dp=s(" as follows:"),ba=p(),k(at.$$.fragment),ka=p(),Gt=a("p"),qp=s(`To export a model that\u2019s stored locally, you\u2019ll need to have the model\u2019s weights and
tokenizer files stored in a directory. For example, we can load and save a checkpoint as
follows:`),ya=p(),k(ke.$$.fragment),Oa=p(),ce=a("h2"),ye=a("a"),Ls=a("span"),k(lt.$$.fragment),Lp=p(),As=a("span"),Ap=s("Selecting features for different model tasks"),Ta=p(),te=a("p"),Ip=s("Each ready-made configuration comes with a set of "),Is=a("em"),Pp=s("features"),Bp=s(` that enable you to export
models for different types of tasks. As shown in the table below, each feature is
associated with a different `),Ps=a("code"),Mp=s("AutoClass"),Xp=s(":"),Na=p(),Oe=a("table"),Bs=a("thead"),rt=a("tr"),Ms=a("th"),Rp=s("Feature"),Fp=p(),Xs=a("th"),Sp=s("Auto Class"),zp=p(),F=a("tbody"),it=a("tr"),pt=a("td"),Rs=a("code"),Hp=s("causal-lm"),Vp=s(", "),Fs=a("code"),Wp=s("causal-lm-with-past"),Gp=p(),Ss=a("td"),zs=a("code"),Yp=s("AutoModelForCausalLM"),Up=p(),ft=a("tr"),dt=a("td"),Hs=a("code"),Kp=s("default"),Jp=s(", "),Vs=a("code"),Qp=s("default-with-past"),Zp=p(),Ws=a("td"),Gs=a("code"),ef=s("AutoModel"),tf=p(),ct=a("tr"),Ys=a("td"),Us=a("code"),of=s("masked-lm"),sf=p(),Ks=a("td"),Js=a("code"),nf=s("AutoModelForMaskedLM"),af=p(),ht=a("tr"),Qs=a("td"),Zs=a("code"),lf=s("question-answering"),rf=p(),en=a("td"),tn=a("code"),pf=s("AutoModelForQuestionAnswering"),ff=p(),ut=a("tr"),mt=a("td"),on=a("code"),df=s("seq2seq-lm"),cf=s(", "),sn=a("code"),hf=s("seq2seq-lm-with-past"),uf=p(),nn=a("td"),an=a("code"),mf=s("AutoModelForSeq2SeqLM"),gf=p(),gt=a("tr"),ln=a("td"),rn=a("code"),_f=s("sequence-classification"),vf=p(),pn=a("td"),fn=a("code"),Ef=s("AutoModelForSequenceClassification"),wf=p(),_t=a("tr"),dn=a("td"),cn=a("code"),$f=s("token-classification"),xf=p(),hn=a("td"),un=a("code"),bf=s("AutoModelForTokenClassification"),ja=p(),Te=a("p"),kf=s(`For each configuration, you can find the list of supported features via the
`),Yt=a("a"),yf=s("FeaturesManager"),Of=s(". For example, for DistilBERT we have:"),Ca=p(),k(vt.$$.fragment),Da=p(),oe=a("p"),Tf=s("You can then pass one of these features to the "),mn=a("code"),Nf=s("--feature"),jf=s(` argument in the
`),gn=a("code"),Cf=s("transformers.onnx"),Df=s(` package. For example, to export a text-classification model we can
pick a fine-tuned model from the Hub and run:`),qa=p(),k(Et.$$.fragment),La=p(),Ut=a("p"),qf=s("This displays the following logs:"),Aa=p(),k(wt.$$.fragment),Ia=p(),Y=a("p"),Lf=s("Notice that in this case, the output names from the fine-tuned model are "),_n=a("code"),Af=s("logits"),If=s(`
instead of the `),vn=a("code"),Pf=s("last_hidden_state"),Bf=s(" we saw with the "),En=a("code"),Mf=s("distilbert-base-uncased"),Xf=s(` checkpoint
earlier. This is expected since the fine-tuned model has a sequence classification head.`),Pa=p(),k(Ne.$$.fragment),Ba=p(),he=a("h2"),je=a("a"),wn=a("span"),k($t.$$.fragment),Rf=p(),$n=a("span"),Ff=s("Exporting a model for an unsupported architecture"),Ma=p(),Kt=a("p"),Sf=s(`If you wish to export a model whose architecture is not natively supported by the
library, there are three main steps to follow:`),Xa=p(),se=a("ol"),xn=a("li"),zf=s("Implement a custom ONNX configuration."),Hf=p(),bn=a("li"),Vf=s("Export the model to ONNX."),Wf=p(),kn=a("li"),Gf=s("Validate the outputs of the PyTorch and exported models."),Ra=p(),Jt=a("p"),Yf=s(`In this section, we\u2019ll look at how DistilBERT was implemented to show what\u2019s involved
with each step.`),Fa=p(),ue=a("h3"),Ce=a("a"),yn=a("span"),k(xt.$$.fragment),Uf=p(),On=a("span"),Kf=s("Implementing a custom ONNX configuration"),Sa=p(),Qt=a("p"),Jf=s(`Let\u2019s start with the ONNX configuration object. We provide three abstract classes that
you should inherit from, depending on the type of model architecture you wish to export:`),za=p(),ne=a("ul"),Zt=a("li"),Qf=s("Encoder-based models inherit from "),eo=a("a"),Zf=s("OnnxConfig"),ed=p(),to=a("li"),td=s("Decoder-based models inherit from "),oo=a("a"),od=s("OnnxConfigWithPast"),sd=p(),so=a("li"),nd=s("Encoder-decoder models inherit from "),no=a("a"),ad=s("OnnxSeq2SeqConfigWithPast"),Ha=p(),k(De.$$.fragment),Va=p(),qe=a("p"),ld=s(`Since DistilBERT is an encoder-based model, its configuration inherits from
`),Tn=a("code"),rd=s("OnnxConfig"),id=s(":"),Wa=p(),k(bt.$$.fragment),Ga=p(),z=a("p"),pd=s("Every configuration object must implement the "),Nn=a("code"),fd=s("inputs"),dd=s(` property and return a mapping,
where each key corresponds to an expected input, and each value indicates the axis of
that input. For DistilBERT, we can see that two inputs are required: `),jn=a("code"),cd=s("input_ids"),hd=s(` and
`),Cn=a("code"),ud=s("attention_mask"),md=s(". These inputs have the same shape of "),Dn=a("code"),gd=s("(batch_size, sequence_length)"),_d=s(`
which is why we see the same axes used in the configuration.`),Ya=p(),k(Le.$$.fragment),Ua=p(),ao=a("p"),vd=s(`Once you have implemented an ONNX configuration, you can instantiate it by providing the
base model\u2019s configuration as follows:`),Ka=p(),k(kt.$$.fragment),Ja=p(),lo=a("p"),Ed=s(`The resulting object has several useful properties. For example, you can view the ONNX
operator set that will be used during the export:`),Qa=p(),k(yt.$$.fragment),Za=p(),ro=a("p"),wd=s("You can also view the outputs associated with the model as follows:"),el=p(),k(Ot.$$.fragment),tl=p(),H=a("p"),$d=s(`Notice that the outputs property follows the same structure as the inputs; it returns an
`),qn=a("code"),xd=s("OrderedDict"),bd=s(` of named outputs and their shapes. The output structure is linked to the
choice of feature that the configuration is initialised with. By default, the ONNX
configuration is initialized with the `),Ln=a("code"),kd=s("default"),yd=s(` feature that corresponds to exporting a
model loaded with the `),An=a("code"),Od=s("AutoModel"),Td=s(` class. If you want to export a model for another task,
just provide a different feature to the `),In=a("code"),Nd=s("task"),jd=s(` argument when you initialize the ONNX
configuration. For example, if we wished to export DistilBERT with a sequence
classification head, we could use:`),ol=p(),k(Tt.$$.fragment),sl=p(),k(Ae.$$.fragment),nl=p(),me=a("h3"),Ie=a("a"),Pn=a("span"),k(Nt.$$.fragment),Cd=p(),Bn=a("span"),Dd=s("Exporting the model"),al=p(),ae=a("p"),qd=s(`Once you have implemented the ONNX configuration, the next step is to export the model.
Here we can use the `),Mn=a("code"),Ld=s("export()"),Ad=s(" function provided by the "),Xn=a("code"),Id=s("transformers.onnx"),Pd=s(` package.
This function expects the ONNX configuration, along with the base model and tokenizer,
and the path to save the exported file:`),ll=p(),k(jt.$$.fragment),rl=p(),S=a("p"),Bd=s("The "),Rn=a("code"),Md=s("onnx_inputs"),Xd=s(" and "),Fn=a("code"),Rd=s("onnx_outputs"),Fd=s(" returned by the "),Sn=a("code"),Sd=s("export()"),zd=s(` function are lists of
the keys defined in the `),zn=a("code"),Hd=s("inputs"),Vd=s(" and "),Hn=a("code"),Wd=s("outputs"),Gd=s(` properties of the configuration. Once the
model is exported, you can test that the model is well formed as follows:`),il=p(),k(Ct.$$.fragment),pl=p(),k(Pe.$$.fragment),fl=p(),ge=a("h3"),Be=a("a"),Vn=a("span"),k(Dt.$$.fragment),Yd=p(),Wn=a("span"),Ud=s("Validating the model outputs"),dl=p(),le=a("p"),Kd=s(`The final step is to validate that the outputs from the base and exported model agree
within some absolute tolerance. Here we can use the `),Gn=a("code"),Jd=s("validate_model_outputs()"),Qd=s(` function
provided by the `),Yn=a("code"),Zd=s("transformers.onnx"),ec=s(" package as follows:"),cl=p(),k(qt.$$.fragment),hl=p(),Me=a("p"),tc=s("This function uses the "),io=a("a"),oc=s("generate_dummy_inputs()"),sc=s(` method to
generate inputs for the base and exported model, and the absolute tolerance can be
defined in the configuration. We generally find numerical agreement in the 1e-6 to 1e-4
range, although anything smaller than 1e-3 is likely to be OK.`),ul=p(),_e=a("h2"),Xe=a("a"),Un=a("span"),k(Lt.$$.fragment),nc=p(),Kn=a("span"),ac=s("Contributing a new configuration to \u{1F917} Transformers"),ml=p(),po=a("p"),lc=s(`We are looking to expand the set of ready-made configurations and welcome contributions
from the community! If you would like to contribute your addition to the library, you
will need to:`),gl=p(),re=a("ul"),At=a("li"),rc=s("Implement the ONNX configuration in the corresponding "),Jn=a("code"),ic=s("configuration_<model_name>.py"),pc=s(`
file`),fc=p(),fo=a("li"),dc=s(`Include the model architecture and corresponding features in
`),Qn=a("code"),cc=s("FeatureManager"),hc=p(),co=a("li"),uc=s("Add your model architecture to the tests in "),Zn=a("code"),mc=s("test_onnx_v2.py"),_l=p(),Re=a("p"),gc=s("Check out how the configuration for "),It=a("a"),_c=s(`IBERT was
contributed`),vc=s(` to get an
idea of what\u2019s involved.`),this.h()},l(t){const i=Rm('[data-svelte="svelte-1phssyn"]',document.head);c=l(i,"META",{name:!0,content:!0}),i.forEach(o),w=f(t),m=l(t,"H1",{class:!0});var Pt=r(m);E=l(Pt,"A",{id:!0,class:!0,href:!0});var ea=r(E);$=l(ea,"SPAN",{});var ta=r($);y(v.$$.fragment,ta),ta.forEach(o),ea.forEach(o),x=f(Pt),b=l(Pt,"SPAN",{});var oa=r(b);q=n(oa,"Export to ONNX"),oa.forEach(o),Pt.forEach(o),C=f(t),A=l(t,"P",{});var Bt=r(A);L=n(Bt,`If you need to deploy \u{1F917} Transformers models in production environments, we recommend
exporting them to a serialized format that can be loaded and executed on specialized
runtimes and hardware. In this guide, we\u2019ll show you how to export \u{1F917} Transformers
models to `),I=l(Bt,"A",{href:!0,rel:!0});var sa=r(I);g=n(sa,"ONNX (Open Neural Network eXchange)"),sa.forEach(o),D=n(Bt,"."),Bt.forEach(o),R=f(t),y(X.$$.fragment,t),Q=f(t),W=l(t,"P",{});var Mt=r(W);He=n(Mt,`ONNX is an open standard that defines a common set of operators and a common file format
to represent deep learning models in a wide variety of frameworks, including PyTorch and
TensorFlow. When a model is exported to the ONNX format, these operators are used to
construct a computational graph (often called an `),K=l(Mt,"EM",{});var kc=r(K);Ve=n(kc,"intermediate representation"),kc.forEach(o),We=n(Mt,`) which
represents the flow of data through the neural network.`),Mt.forEach(o),Z=f(t),P=l(t,"P",{});var yc=r(P);Xt=n(yc,`By exposing a graph with standardized operators and data types, ONNX makes it easy to
switch between frameworks. For example, a model trained in PyTorch can be exported to
ONNX format and then imported in TensorFlow (and vice versa).`),yc.forEach(o),Ge=f(t),J=l(t,"P",{});var El=r(J);Rt=n(El,"\u{1F917} Transformers provides a "),fe=l(El,"A",{href:!0});var Oc=r(fe);ve=l(Oc,"CODE",{});var Tc=r(ve);Ft=n(Tc,"transformers.onnx"),Tc.forEach(o),Oc.forEach(o),Ul=n(El,` package that enables
you to convert model checkpoints to an ONNX graph by leveraging configuration objects.
These configuration objects come ready made for a number of model architectures, and are
designed to be easily extendable to other architectures.`),El.forEach(o),na=f(t),St=l(t,"P",{});var Nc=r(St);Kl=n(Nc,"Ready-made configurations include the following architectures:"),Nc.forEach(o),aa=f(t),h=l(t,"UL",{});var u=r(h);xo=l(u,"LI",{});var jc=r(xo);Jl=n(jc,"ALBERT"),jc.forEach(o),Ql=f(u),bo=l(u,"LI",{});var Cc=r(bo);Zl=n(Cc,"BART"),Cc.forEach(o),er=f(u),ko=l(u,"LI",{});var Dc=r(ko);tr=n(Dc,"BEiT"),Dc.forEach(o),or=f(u),yo=l(u,"LI",{});var qc=r(yo);sr=n(qc,"BERT"),qc.forEach(o),nr=f(u),Oo=l(u,"LI",{});var Lc=r(Oo);ar=n(Lc,"BigBird"),Lc.forEach(o),lr=f(u),To=l(u,"LI",{});var Ac=r(To);rr=n(Ac,"BigBird-Pegasus"),Ac.forEach(o),ir=f(u),No=l(u,"LI",{});var Ic=r(No);pr=n(Ic,"Blenderbot"),Ic.forEach(o),fr=f(u),jo=l(u,"LI",{});var Pc=r(jo);dr=n(Pc,"BlenderbotSmall"),Pc.forEach(o),cr=f(u),Co=l(u,"LI",{});var Bc=r(Co);hr=n(Bc,"BLOOM"),Bc.forEach(o),ur=f(u),Do=l(u,"LI",{});var Mc=r(Do);mr=n(Mc,"CamemBERT"),Mc.forEach(o),gr=f(u),qo=l(u,"LI",{});var Xc=r(qo);_r=n(Xc,"CLIP"),Xc.forEach(o),vr=f(u),Lo=l(u,"LI",{});var Rc=r(Lo);Er=n(Rc,"CodeGen"),Rc.forEach(o),wr=f(u),Ao=l(u,"LI",{});var Fc=r(Ao);$r=n(Fc,"Conditional DETR"),Fc.forEach(o),xr=f(u),Io=l(u,"LI",{});var Sc=r(Io);br=n(Sc,"ConvBERT"),Sc.forEach(o),kr=f(u),Po=l(u,"LI",{});var zc=r(Po);yr=n(zc,"ConvNeXT"),zc.forEach(o),Or=f(u),Bo=l(u,"LI",{});var Hc=r(Bo);Tr=n(Hc,"Data2VecText"),Hc.forEach(o),Nr=f(u),Mo=l(u,"LI",{});var Vc=r(Mo);jr=n(Vc,"Data2VecVision"),Vc.forEach(o),Cr=f(u),Xo=l(u,"LI",{});var Wc=r(Xo);Dr=n(Wc,"DeBERTa"),Wc.forEach(o),qr=f(u),Ro=l(u,"LI",{});var Gc=r(Ro);Lr=n(Gc,"DeBERTa-v2"),Gc.forEach(o),Ar=f(u),Fo=l(u,"LI",{});var Yc=r(Fo);Ir=n(Yc,"DeiT"),Yc.forEach(o),Pr=f(u),So=l(u,"LI",{});var Uc=r(So);Br=n(Uc,"DETR"),Uc.forEach(o),Mr=f(u),zo=l(u,"LI",{});var Kc=r(zo);Xr=n(Kc,"DistilBERT"),Kc.forEach(o),Rr=f(u),Ho=l(u,"LI",{});var Jc=r(Ho);Fr=n(Jc,"ELECTRA"),Jc.forEach(o),Sr=f(u),Vo=l(u,"LI",{});var Qc=r(Vo);zr=n(Qc,"ERNIE"),Qc.forEach(o),Hr=f(u),Wo=l(u,"LI",{});var Zc=r(Wo);Vr=n(Zc,"FlauBERT"),Zc.forEach(o),Wr=f(u),Go=l(u,"LI",{});var eh=r(Go);Gr=n(eh,"GPT Neo"),eh.forEach(o),Yr=f(u),Yo=l(u,"LI",{});var th=r(Yo);Ur=n(th,"GPT-J"),th.forEach(o),Kr=f(u),Uo=l(u,"LI",{});var oh=r(Uo);Jr=n(oh,"GroupViT"),oh.forEach(o),Qr=f(u),Ko=l(u,"LI",{});var sh=r(Ko);Zr=n(sh,"I-BERT"),sh.forEach(o),ei=f(u),Jo=l(u,"LI",{});var nh=r(Jo);ti=n(nh,"LayoutLM"),nh.forEach(o),oi=f(u),Qo=l(u,"LI",{});var ah=r(Qo);si=n(ah,"LayoutLMv3"),ah.forEach(o),ni=f(u),Zo=l(u,"LI",{});var lh=r(Zo);ai=n(lh,"LeViT"),lh.forEach(o),li=f(u),es=l(u,"LI",{});var rh=r(es);ri=n(rh,"Longformer"),rh.forEach(o),ii=f(u),ts=l(u,"LI",{});var ih=r(ts);pi=n(ih,"LongT5"),ih.forEach(o),fi=f(u),os=l(u,"LI",{});var ph=r(os);di=n(ph,"M2M100"),ph.forEach(o),ci=f(u),ss=l(u,"LI",{});var fh=r(ss);hi=n(fh,"Marian"),fh.forEach(o),ui=f(u),ns=l(u,"LI",{});var dh=r(ns);mi=n(dh,"mBART"),dh.forEach(o),gi=f(u),as=l(u,"LI",{});var ch=r(as);_i=n(ch,"MobileBERT"),ch.forEach(o),vi=f(u),ls=l(u,"LI",{});var hh=r(ls);Ei=n(hh,"MobileViT"),hh.forEach(o),wi=f(u),rs=l(u,"LI",{});var uh=r(rs);$i=n(uh,"MT5"),uh.forEach(o),xi=f(u),is=l(u,"LI",{});var mh=r(is);bi=n(mh,"OpenAI GPT-2"),mh.forEach(o),ki=f(u),ps=l(u,"LI",{});var gh=r(ps);yi=n(gh,"OWL-ViT"),gh.forEach(o),Oi=f(u),fs=l(u,"LI",{});var _h=r(fs);Ti=n(_h,"Perceiver"),_h.forEach(o),Ni=f(u),ds=l(u,"LI",{});var vh=r(ds);ji=n(vh,"PLBart"),vh.forEach(o),Ci=f(u),cs=l(u,"LI",{});var Eh=r(cs);Di=n(Eh,"ResNet"),Eh.forEach(o),qi=f(u),hs=l(u,"LI",{});var wh=r(hs);Li=n(wh,"RoBERTa"),wh.forEach(o),Ai=f(u),us=l(u,"LI",{});var $h=r(us);Ii=n($h,"RoFormer"),$h.forEach(o),Pi=f(u),ms=l(u,"LI",{});var xh=r(ms);Bi=n(xh,"SegFormer"),xh.forEach(o),Mi=f(u),gs=l(u,"LI",{});var bh=r(gs);Xi=n(bh,"SqueezeBERT"),bh.forEach(o),Ri=f(u),_s=l(u,"LI",{});var kh=r(_s);Fi=n(kh,"Swin Transformer"),kh.forEach(o),Si=f(u),vs=l(u,"LI",{});var yh=r(vs);zi=n(yh,"T5"),yh.forEach(o),Hi=f(u),Es=l(u,"LI",{});var Oh=r(Es);Vi=n(Oh,"ViT"),Oh.forEach(o),Wi=f(u),ws=l(u,"LI",{});var Th=r(ws);Gi=n(Th,"XLM"),Th.forEach(o),Yi=f(u),$s=l(u,"LI",{});var Nh=r($s);Ui=n(Nh,"XLM-RoBERTa"),Nh.forEach(o),Ki=f(u),xs=l(u,"LI",{});var jh=r(xs);Ji=n(jh,"XLM-RoBERTa-XL"),jh.forEach(o),Qi=f(u),bs=l(u,"LI",{});var Ch=r(bs);Zi=n(Ch,"YOLOS"),Ch.forEach(o),u.forEach(o),la=f(t),zt=l(t,"P",{});var Dh=r(zt);ep=n(Dh,"In the next two sections, we\u2019ll show you how to:"),Dh.forEach(o),ra=f(t),Ee=l(t,"UL",{});var wl=r(Ee);Ye=l(wl,"LI",{});var $l=r(Ye);tp=n($l,"Export a supported model using the "),ks=l($l,"CODE",{});var qh=r(ks);op=n(qh,"transformers.onnx"),qh.forEach(o),sp=n($l," package."),$l.forEach(o),np=f(wl),ys=l(wl,"LI",{});var Lh=r(ys);ap=n(Lh,"Export a custom model for an unsupported architecture."),Lh.forEach(o),wl.forEach(o),ia=f(t),de=l(t,"H2",{class:!0});var xl=r(de);we=l(xl,"A",{id:!0,class:!0,href:!0});var Ah=r(we);Os=l(Ah,"SPAN",{});var Ih=r(Os);y(Ue.$$.fragment,Ih),Ih.forEach(o),Ah.forEach(o),lp=f(xl),Ts=l(xl,"SPAN",{});var Ph=r(Ts);rp=n(Ph,"Exporting a model to ONNX"),Ph.forEach(o),xl.forEach(o),pa=f(t),Ht=l(t,"P",{});var Bh=r(Ht);ip=n(Bh,`To export a \u{1F917} Transformers model to ONNX, you\u2019ll first need to install some extra
dependencies:`),Bh.forEach(o),fa=f(t),y(Ke.$$.fragment,t),da=f(t),$e=l(t,"P",{});var bl=r($e);pp=n(bl,"The "),Ns=l(bl,"CODE",{});var Mh=r(Ns);fp=n(Mh,"transformers.onnx"),Mh.forEach(o),dp=n(bl," package can then be used as a Python module:"),bl.forEach(o),ca=f(t),y(Je.$$.fragment,t),ha=f(t),Vt=l(t,"P",{});var Xh=r(Vt);cp=n(Xh,"Exporting a checkpoint using a ready-made configuration can be done as follows:"),Xh.forEach(o),ua=f(t),y(Qe.$$.fragment,t),ma=f(t),Wt=l(t,"P",{});var Rh=r(Wt);hp=n(Rh,"You should see the following logs:"),Rh.forEach(o),ga=f(t),y(Ze.$$.fragment,t),_a=f(t),ee=l(t,"P",{});var ho=r(ee);up=n(ho,"This exports an ONNX graph of the checkpoint defined by the "),js=l(ho,"CODE",{});var Fh=r(js);mp=n(Fh,"--model"),Fh.forEach(o),gp=n(ho,` argument. In this
example, it is `),Cs=l(ho,"CODE",{});var Sh=r(Cs);_p=n(Sh,"distilbert-base-uncased"),Sh.forEach(o),vp=n(ho,`, but it can be any checkpoint on the Hugging
Face Hub or one that\u2019s stored locally.`),ho.forEach(o),va=f(t),G=l(t,"P",{});var Fe=r(G);Ep=n(Fe,"The resulting "),Ds=l(Fe,"CODE",{});var zh=r(Ds);wp=n(zh,"model.onnx"),zh.forEach(o),$p=n(Fe," file can then be run on one of the "),et=l(Fe,"A",{href:!0,rel:!0});var Hh=r(et);xp=n(Hh,`many
accelerators`),Hh.forEach(o),bp=n(Fe,` that support the ONNX
standard. For example, we can load and run the model with `),tt=l(Fe,"A",{href:!0,rel:!0});var Vh=r(tt);kp=n(Vh,`ONNX
Runtime`),Vh.forEach(o),yp=n(Fe," as follows:"),Fe.forEach(o),Ea=f(t),y(ot.$$.fragment,t),wa=f(t),xe=l(t,"P",{});var kl=r(xe);Op=n(kl,"The required output names (like "),qs=l(kl,"CODE",{});var Wh=r(qs);Tp=n(Wh,'["last_hidden_state"]'),Wh.forEach(o),Np=n(kl,`) can be obtained by taking a
look at the ONNX configuration of each model. For example, for DistilBERT we have:`),kl.forEach(o),$a=f(t),y(st.$$.fragment,t),xa=f(t),be=l(t,"P",{});var yl=r(be);jp=n(yl,`The process is identical for TensorFlow checkpoints on the Hub. For example, we can
export a pure TensorFlow checkpoint from the `),nt=l(yl,"A",{href:!0,rel:!0});var Gh=r(nt);Cp=n(Gh,`Keras
organization`),Gh.forEach(o),Dp=n(yl," as follows:"),yl.forEach(o),ba=f(t),y(at.$$.fragment,t),ka=f(t),Gt=l(t,"P",{});var Yh=r(Gt);qp=n(Yh,`To export a model that\u2019s stored locally, you\u2019ll need to have the model\u2019s weights and
tokenizer files stored in a directory. For example, we can load and save a checkpoint as
follows:`),Yh.forEach(o),ya=f(t),y(ke.$$.fragment,t),Oa=f(t),ce=l(t,"H2",{class:!0});var Ol=r(ce);ye=l(Ol,"A",{id:!0,class:!0,href:!0});var Uh=r(ye);Ls=l(Uh,"SPAN",{});var Kh=r(Ls);y(lt.$$.fragment,Kh),Kh.forEach(o),Uh.forEach(o),Lp=f(Ol),As=l(Ol,"SPAN",{});var Jh=r(As);Ap=n(Jh,"Selecting features for different model tasks"),Jh.forEach(o),Ol.forEach(o),Ta=f(t),te=l(t,"P",{});var uo=r(te);Ip=n(uo,"Each ready-made configuration comes with a set of "),Is=l(uo,"EM",{});var Qh=r(Is);Pp=n(Qh,"features"),Qh.forEach(o),Bp=n(uo,` that enable you to export
models for different types of tasks. As shown in the table below, each feature is
associated with a different `),Ps=l(uo,"CODE",{});var Zh=r(Ps);Mp=n(Zh,"AutoClass"),Zh.forEach(o),Xp=n(uo,":"),uo.forEach(o),Na=f(t),Oe=l(t,"TABLE",{});var Tl=r(Oe);Bs=l(Tl,"THEAD",{});var eu=r(Bs);rt=l(eu,"TR",{});var Nl=r(rt);Ms=l(Nl,"TH",{});var tu=r(Ms);Rp=n(tu,"Feature"),tu.forEach(o),Fp=f(Nl),Xs=l(Nl,"TH",{});var ou=r(Xs);Sp=n(ou,"Auto Class"),ou.forEach(o),Nl.forEach(o),eu.forEach(o),zp=f(Tl),F=l(Tl,"TBODY",{});var V=r(F);it=l(V,"TR",{});var jl=r(it);pt=l(jl,"TD",{});var Cl=r(pt);Rs=l(Cl,"CODE",{});var su=r(Rs);Hp=n(su,"causal-lm"),su.forEach(o),Vp=n(Cl,", "),Fs=l(Cl,"CODE",{});var nu=r(Fs);Wp=n(nu,"causal-lm-with-past"),nu.forEach(o),Cl.forEach(o),Gp=f(jl),Ss=l(jl,"TD",{});var au=r(Ss);zs=l(au,"CODE",{});var lu=r(zs);Yp=n(lu,"AutoModelForCausalLM"),lu.forEach(o),au.forEach(o),jl.forEach(o),Up=f(V),ft=l(V,"TR",{});var Dl=r(ft);dt=l(Dl,"TD",{});var ql=r(dt);Hs=l(ql,"CODE",{});var ru=r(Hs);Kp=n(ru,"default"),ru.forEach(o),Jp=n(ql,", "),Vs=l(ql,"CODE",{});var iu=r(Vs);Qp=n(iu,"default-with-past"),iu.forEach(o),ql.forEach(o),Zp=f(Dl),Ws=l(Dl,"TD",{});var pu=r(Ws);Gs=l(pu,"CODE",{});var fu=r(Gs);ef=n(fu,"AutoModel"),fu.forEach(o),pu.forEach(o),Dl.forEach(o),tf=f(V),ct=l(V,"TR",{});var Ll=r(ct);Ys=l(Ll,"TD",{});var du=r(Ys);Us=l(du,"CODE",{});var cu=r(Us);of=n(cu,"masked-lm"),cu.forEach(o),du.forEach(o),sf=f(Ll),Ks=l(Ll,"TD",{});var hu=r(Ks);Js=l(hu,"CODE",{});var uu=r(Js);nf=n(uu,"AutoModelForMaskedLM"),uu.forEach(o),hu.forEach(o),Ll.forEach(o),af=f(V),ht=l(V,"TR",{});var Al=r(ht);Qs=l(Al,"TD",{});var mu=r(Qs);Zs=l(mu,"CODE",{});var gu=r(Zs);lf=n(gu,"question-answering"),gu.forEach(o),mu.forEach(o),rf=f(Al),en=l(Al,"TD",{});var _u=r(en);tn=l(_u,"CODE",{});var vu=r(tn);pf=n(vu,"AutoModelForQuestionAnswering"),vu.forEach(o),_u.forEach(o),Al.forEach(o),ff=f(V),ut=l(V,"TR",{});var Il=r(ut);mt=l(Il,"TD",{});var Pl=r(mt);on=l(Pl,"CODE",{});var Eu=r(on);df=n(Eu,"seq2seq-lm"),Eu.forEach(o),cf=n(Pl,", "),sn=l(Pl,"CODE",{});var wu=r(sn);hf=n(wu,"seq2seq-lm-with-past"),wu.forEach(o),Pl.forEach(o),uf=f(Il),nn=l(Il,"TD",{});var $u=r(nn);an=l($u,"CODE",{});var xu=r(an);mf=n(xu,"AutoModelForSeq2SeqLM"),xu.forEach(o),$u.forEach(o),Il.forEach(o),gf=f(V),gt=l(V,"TR",{});var Bl=r(gt);ln=l(Bl,"TD",{});var bu=r(ln);rn=l(bu,"CODE",{});var ku=r(rn);_f=n(ku,"sequence-classification"),ku.forEach(o),bu.forEach(o),vf=f(Bl),pn=l(Bl,"TD",{});var yu=r(pn);fn=l(yu,"CODE",{});var Ou=r(fn);Ef=n(Ou,"AutoModelForSequenceClassification"),Ou.forEach(o),yu.forEach(o),Bl.forEach(o),wf=f(V),_t=l(V,"TR",{});var Ml=r(_t);dn=l(Ml,"TD",{});var Tu=r(dn);cn=l(Tu,"CODE",{});var Nu=r(cn);$f=n(Nu,"token-classification"),Nu.forEach(o),Tu.forEach(o),xf=f(Ml),hn=l(Ml,"TD",{});var ju=r(hn);un=l(ju,"CODE",{});var Cu=r(un);bf=n(Cu,"AutoModelForTokenClassification"),Cu.forEach(o),ju.forEach(o),Ml.forEach(o),V.forEach(o),Tl.forEach(o),ja=f(t),Te=l(t,"P",{});var Xl=r(Te);kf=n(Xl,`For each configuration, you can find the list of supported features via the
`),Yt=l(Xl,"A",{href:!0});var Du=r(Yt);yf=n(Du,"FeaturesManager"),Du.forEach(o),Of=n(Xl,". For example, for DistilBERT we have:"),Xl.forEach(o),Ca=f(t),y(vt.$$.fragment,t),Da=f(t),oe=l(t,"P",{});var mo=r(oe);Tf=n(mo,"You can then pass one of these features to the "),mn=l(mo,"CODE",{});var qu=r(mn);Nf=n(qu,"--feature"),qu.forEach(o),jf=n(mo,` argument in the
`),gn=l(mo,"CODE",{});var Lu=r(gn);Cf=n(Lu,"transformers.onnx"),Lu.forEach(o),Df=n(mo,` package. For example, to export a text-classification model we can
pick a fine-tuned model from the Hub and run:`),mo.forEach(o),qa=f(t),y(Et.$$.fragment,t),La=f(t),Ut=l(t,"P",{});var Au=r(Ut);qf=n(Au,"This displays the following logs:"),Au.forEach(o),Aa=f(t),y(wt.$$.fragment,t),Ia=f(t),Y=l(t,"P",{});var Se=r(Y);Lf=n(Se,"Notice that in this case, the output names from the fine-tuned model are "),_n=l(Se,"CODE",{});var Iu=r(_n);Af=n(Iu,"logits"),Iu.forEach(o),If=n(Se,`
instead of the `),vn=l(Se,"CODE",{});var Pu=r(vn);Pf=n(Pu,"last_hidden_state"),Pu.forEach(o),Bf=n(Se," we saw with the "),En=l(Se,"CODE",{});var Bu=r(En);Mf=n(Bu,"distilbert-base-uncased"),Bu.forEach(o),Xf=n(Se,` checkpoint
earlier. This is expected since the fine-tuned model has a sequence classification head.`),Se.forEach(o),Pa=f(t),y(Ne.$$.fragment,t),Ba=f(t),he=l(t,"H2",{class:!0});var Rl=r(he);je=l(Rl,"A",{id:!0,class:!0,href:!0});var Mu=r(je);wn=l(Mu,"SPAN",{});var Xu=r(wn);y($t.$$.fragment,Xu),Xu.forEach(o),Mu.forEach(o),Rf=f(Rl),$n=l(Rl,"SPAN",{});var Ru=r($n);Ff=n(Ru,"Exporting a model for an unsupported architecture"),Ru.forEach(o),Rl.forEach(o),Ma=f(t),Kt=l(t,"P",{});var Fu=r(Kt);Sf=n(Fu,`If you wish to export a model whose architecture is not natively supported by the
library, there are three main steps to follow:`),Fu.forEach(o),Xa=f(t),se=l(t,"OL",{});var go=r(se);xn=l(go,"LI",{});var Su=r(xn);zf=n(Su,"Implement a custom ONNX configuration."),Su.forEach(o),Hf=f(go),bn=l(go,"LI",{});var zu=r(bn);Vf=n(zu,"Export the model to ONNX."),zu.forEach(o),Wf=f(go),kn=l(go,"LI",{});var Hu=r(kn);Gf=n(Hu,"Validate the outputs of the PyTorch and exported models."),Hu.forEach(o),go.forEach(o),Ra=f(t),Jt=l(t,"P",{});var Vu=r(Jt);Yf=n(Vu,`In this section, we\u2019ll look at how DistilBERT was implemented to show what\u2019s involved
with each step.`),Vu.forEach(o),Fa=f(t),ue=l(t,"H3",{class:!0});var Fl=r(ue);Ce=l(Fl,"A",{id:!0,class:!0,href:!0});var Wu=r(Ce);yn=l(Wu,"SPAN",{});var Gu=r(yn);y(xt.$$.fragment,Gu),Gu.forEach(o),Wu.forEach(o),Uf=f(Fl),On=l(Fl,"SPAN",{});var Yu=r(On);Kf=n(Yu,"Implementing a custom ONNX configuration"),Yu.forEach(o),Fl.forEach(o),Sa=f(t),Qt=l(t,"P",{});var Uu=r(Qt);Jf=n(Uu,`Let\u2019s start with the ONNX configuration object. We provide three abstract classes that
you should inherit from, depending on the type of model architecture you wish to export:`),Uu.forEach(o),za=f(t),ne=l(t,"UL",{});var _o=r(ne);Zt=l(_o,"LI",{});var Ec=r(Zt);Qf=n(Ec,"Encoder-based models inherit from "),eo=l(Ec,"A",{href:!0});var Ku=r(eo);Zf=n(Ku,"OnnxConfig"),Ku.forEach(o),Ec.forEach(o),ed=f(_o),to=l(_o,"LI",{});var wc=r(to);td=n(wc,"Decoder-based models inherit from "),oo=l(wc,"A",{href:!0});var Ju=r(oo);od=n(Ju,"OnnxConfigWithPast"),Ju.forEach(o),wc.forEach(o),sd=f(_o),so=l(_o,"LI",{});var $c=r(so);nd=n($c,"Encoder-decoder models inherit from "),no=l($c,"A",{href:!0});var Qu=r(no);ad=n(Qu,"OnnxSeq2SeqConfigWithPast"),Qu.forEach(o),$c.forEach(o),_o.forEach(o),Ha=f(t),y(De.$$.fragment,t),Va=f(t),qe=l(t,"P",{});var Sl=r(qe);ld=n(Sl,`Since DistilBERT is an encoder-based model, its configuration inherits from
`),Tn=l(Sl,"CODE",{});var Zu=r(Tn);rd=n(Zu,"OnnxConfig"),Zu.forEach(o),id=n(Sl,":"),Sl.forEach(o),Wa=f(t),y(bt.$$.fragment,t),Ga=f(t),z=l(t,"P",{});var ie=r(z);pd=n(ie,"Every configuration object must implement the "),Nn=l(ie,"CODE",{});var em=r(Nn);fd=n(em,"inputs"),em.forEach(o),dd=n(ie,` property and return a mapping,
where each key corresponds to an expected input, and each value indicates the axis of
that input. For DistilBERT, we can see that two inputs are required: `),jn=l(ie,"CODE",{});var tm=r(jn);cd=n(tm,"input_ids"),tm.forEach(o),hd=n(ie,` and
`),Cn=l(ie,"CODE",{});var om=r(Cn);ud=n(om,"attention_mask"),om.forEach(o),md=n(ie,". These inputs have the same shape of "),Dn=l(ie,"CODE",{});var sm=r(Dn);gd=n(sm,"(batch_size, sequence_length)"),sm.forEach(o),_d=n(ie,`
which is why we see the same axes used in the configuration.`),ie.forEach(o),Ya=f(t),y(Le.$$.fragment,t),Ua=f(t),ao=l(t,"P",{});var nm=r(ao);vd=n(nm,`Once you have implemented an ONNX configuration, you can instantiate it by providing the
base model\u2019s configuration as follows:`),nm.forEach(o),Ka=f(t),y(kt.$$.fragment,t),Ja=f(t),lo=l(t,"P",{});var am=r(lo);Ed=n(am,`The resulting object has several useful properties. For example, you can view the ONNX
operator set that will be used during the export:`),am.forEach(o),Qa=f(t),y(yt.$$.fragment,t),Za=f(t),ro=l(t,"P",{});var lm=r(ro);wd=n(lm,"You can also view the outputs associated with the model as follows:"),lm.forEach(o),el=f(t),y(Ot.$$.fragment,t),tl=f(t),H=l(t,"P",{});var pe=r(H);$d=n(pe,`Notice that the outputs property follows the same structure as the inputs; it returns an
`),qn=l(pe,"CODE",{});var rm=r(qn);xd=n(rm,"OrderedDict"),rm.forEach(o),bd=n(pe,` of named outputs and their shapes. The output structure is linked to the
choice of feature that the configuration is initialised with. By default, the ONNX
configuration is initialized with the `),Ln=l(pe,"CODE",{});var im=r(Ln);kd=n(im,"default"),im.forEach(o),yd=n(pe,` feature that corresponds to exporting a
model loaded with the `),An=l(pe,"CODE",{});var pm=r(An);Od=n(pm,"AutoModel"),pm.forEach(o),Td=n(pe,` class. If you want to export a model for another task,
just provide a different feature to the `),In=l(pe,"CODE",{});var fm=r(In);Nd=n(fm,"task"),fm.forEach(o),jd=n(pe,` argument when you initialize the ONNX
configuration. For example, if we wished to export DistilBERT with a sequence
classification head, we could use:`),pe.forEach(o),ol=f(t),y(Tt.$$.fragment,t),sl=f(t),y(Ae.$$.fragment,t),nl=f(t),me=l(t,"H3",{class:!0});var zl=r(me);Ie=l(zl,"A",{id:!0,class:!0,href:!0});var dm=r(Ie);Pn=l(dm,"SPAN",{});var cm=r(Pn);y(Nt.$$.fragment,cm),cm.forEach(o),dm.forEach(o),Cd=f(zl),Bn=l(zl,"SPAN",{});var hm=r(Bn);Dd=n(hm,"Exporting the model"),hm.forEach(o),zl.forEach(o),al=f(t),ae=l(t,"P",{});var vo=r(ae);qd=n(vo,`Once you have implemented the ONNX configuration, the next step is to export the model.
Here we can use the `),Mn=l(vo,"CODE",{});var um=r(Mn);Ld=n(um,"export()"),um.forEach(o),Ad=n(vo," function provided by the "),Xn=l(vo,"CODE",{});var mm=r(Xn);Id=n(mm,"transformers.onnx"),mm.forEach(o),Pd=n(vo,` package.
This function expects the ONNX configuration, along with the base model and tokenizer,
and the path to save the exported file:`),vo.forEach(o),ll=f(t),y(jt.$$.fragment,t),rl=f(t),S=l(t,"P",{});var U=r(S);Bd=n(U,"The "),Rn=l(U,"CODE",{});var gm=r(Rn);Md=n(gm,"onnx_inputs"),gm.forEach(o),Xd=n(U," and "),Fn=l(U,"CODE",{});var _m=r(Fn);Rd=n(_m,"onnx_outputs"),_m.forEach(o),Fd=n(U," returned by the "),Sn=l(U,"CODE",{});var vm=r(Sn);Sd=n(vm,"export()"),vm.forEach(o),zd=n(U,` function are lists of
the keys defined in the `),zn=l(U,"CODE",{});var Em=r(zn);Hd=n(Em,"inputs"),Em.forEach(o),Vd=n(U," and "),Hn=l(U,"CODE",{});var wm=r(Hn);Wd=n(wm,"outputs"),wm.forEach(o),Gd=n(U,` properties of the configuration. Once the
model is exported, you can test that the model is well formed as follows:`),U.forEach(o),il=f(t),y(Ct.$$.fragment,t),pl=f(t),y(Pe.$$.fragment,t),fl=f(t),ge=l(t,"H3",{class:!0});var Hl=r(ge);Be=l(Hl,"A",{id:!0,class:!0,href:!0});var $m=r(Be);Vn=l($m,"SPAN",{});var xm=r(Vn);y(Dt.$$.fragment,xm),xm.forEach(o),$m.forEach(o),Yd=f(Hl),Wn=l(Hl,"SPAN",{});var bm=r(Wn);Ud=n(bm,"Validating the model outputs"),bm.forEach(o),Hl.forEach(o),dl=f(t),le=l(t,"P",{});var Eo=r(le);Kd=n(Eo,`The final step is to validate that the outputs from the base and exported model agree
within some absolute tolerance. Here we can use the `),Gn=l(Eo,"CODE",{});var km=r(Gn);Jd=n(km,"validate_model_outputs()"),km.forEach(o),Qd=n(Eo,` function
provided by the `),Yn=l(Eo,"CODE",{});var ym=r(Yn);Zd=n(ym,"transformers.onnx"),ym.forEach(o),ec=n(Eo," package as follows:"),Eo.forEach(o),cl=f(t),y(qt.$$.fragment,t),hl=f(t),Me=l(t,"P",{});var Vl=r(Me);tc=n(Vl,"This function uses the "),io=l(Vl,"A",{href:!0});var Om=r(io);oc=n(Om,"generate_dummy_inputs()"),Om.forEach(o),sc=n(Vl,` method to
generate inputs for the base and exported model, and the absolute tolerance can be
defined in the configuration. We generally find numerical agreement in the 1e-6 to 1e-4
range, although anything smaller than 1e-3 is likely to be OK.`),Vl.forEach(o),ul=f(t),_e=l(t,"H2",{class:!0});var Wl=r(_e);Xe=l(Wl,"A",{id:!0,class:!0,href:!0});var Tm=r(Xe);Un=l(Tm,"SPAN",{});var Nm=r(Un);y(Lt.$$.fragment,Nm),Nm.forEach(o),Tm.forEach(o),nc=f(Wl),Kn=l(Wl,"SPAN",{});var jm=r(Kn);ac=n(jm,"Contributing a new configuration to \u{1F917} Transformers"),jm.forEach(o),Wl.forEach(o),ml=f(t),po=l(t,"P",{});var Cm=r(po);lc=n(Cm,`We are looking to expand the set of ready-made configurations and welcome contributions
from the community! If you would like to contribute your addition to the library, you
will need to:`),Cm.forEach(o),gl=f(t),re=l(t,"UL",{});var wo=r(re);At=l(wo,"LI",{});var Gl=r(At);rc=n(Gl,"Implement the ONNX configuration in the corresponding "),Jn=l(Gl,"CODE",{});var Dm=r(Jn);ic=n(Dm,"configuration_<model_name>.py"),Dm.forEach(o),pc=n(Gl,`
file`),Gl.forEach(o),fc=f(wo),fo=l(wo,"LI",{});var xc=r(fo);dc=n(xc,`Include the model architecture and corresponding features in
`),Qn=l(xc,"CODE",{});var qm=r(Qn);cc=n(qm,"FeatureManager"),qm.forEach(o),xc.forEach(o),hc=f(wo),co=l(wo,"LI",{});var bc=r(co);uc=n(bc,"Add your model architecture to the tests in "),Zn=l(bc,"CODE",{});var Lm=r(Zn);mc=n(Lm,"test_onnx_v2.py"),Lm.forEach(o),bc.forEach(o),wo.forEach(o),_l=f(t),Re=l(t,"P",{});var Yl=r(Re);gc=n(Yl,"Check out how the configuration for "),It=l(Yl,"A",{href:!0,rel:!0});var Am=r(It);_c=n(Am,`IBERT was
contributed`),Am.forEach(o),vc=n(Yl,` to get an
idea of what\u2019s involved.`),Yl.forEach(o),this.h()},h(){_(c,"name","hf:doc:metadata"),_(c,"content",JSON.stringify(eg)),_(E,"id","export-to-onnx"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#export-to-onnx"),_(m,"class","relative group"),_(I,"href","http://onnx.ai"),_(I,"rel","nofollow"),_(fe,"href","main_classes/onnx"),_(we,"id","exporting-a-model-to-onnx"),_(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(we,"href","#exporting-a-model-to-onnx"),_(de,"class","relative group"),_(et,"href","https://onnx.ai/supported-tools.html#deployModel"),_(et,"rel","nofollow"),_(tt,"href","https://onnxruntime.ai/"),_(tt,"rel","nofollow"),_(nt,"href","https://huggingface.co/keras-io"),_(nt,"rel","nofollow"),_(ye,"id","selecting-features-for-different-model-tasks"),_(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ye,"href","#selecting-features-for-different-model-tasks"),_(ce,"class","relative group"),_(Yt,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.FeaturesManager"),_(je,"id","exporting-a-model-for-an-unsupported-architecture"),_(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(je,"href","#exporting-a-model-for-an-unsupported-architecture"),_(he,"class","relative group"),_(Ce,"id","implementing-a-custom-onnx-configuration"),_(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ce,"href","#implementing-a-custom-onnx-configuration"),_(ue,"class","relative group"),_(eo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig"),_(oo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfigWithPast"),_(no,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxSeq2SeqConfigWithPast"),_(Ie,"id","exporting-the-model"),_(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ie,"href","#exporting-the-model"),_(me,"class","relative group"),_(Be,"id","validating-the-model-outputs"),_(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Be,"href","#validating-the-model-outputs"),_(ge,"class","relative group"),_(io,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig.generate_dummy_inputs"),_(Xe,"id","contributing-a-new-configuration-to-transformers"),_(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Xe,"href","#contributing-a-new-configuration-to-transformers"),_(_e,"class","relative group"),_(It,"href","https://github.com/huggingface/transformers/pull/14868/files"),_(It,"rel","nofollow")},m(t,i){e(document.head,c),d(t,w,i),d(t,m,i),e(m,E),e(E,$),O(v,$,null),e(m,x),e(m,b),e(b,q),d(t,C,i),d(t,A,i),e(A,L),e(A,I),e(I,g),e(A,D),d(t,R,i),O(X,t,i),d(t,Q,i),d(t,W,i),e(W,He),e(W,K),e(K,Ve),e(W,We),d(t,Z,i),d(t,P,i),e(P,Xt),d(t,Ge,i),d(t,J,i),e(J,Rt),e(J,fe),e(fe,ve),e(ve,Ft),e(J,Ul),d(t,na,i),d(t,St,i),e(St,Kl),d(t,aa,i),d(t,h,i),e(h,xo),e(xo,Jl),e(h,Ql),e(h,bo),e(bo,Zl),e(h,er),e(h,ko),e(ko,tr),e(h,or),e(h,yo),e(yo,sr),e(h,nr),e(h,Oo),e(Oo,ar),e(h,lr),e(h,To),e(To,rr),e(h,ir),e(h,No),e(No,pr),e(h,fr),e(h,jo),e(jo,dr),e(h,cr),e(h,Co),e(Co,hr),e(h,ur),e(h,Do),e(Do,mr),e(h,gr),e(h,qo),e(qo,_r),e(h,vr),e(h,Lo),e(Lo,Er),e(h,wr),e(h,Ao),e(Ao,$r),e(h,xr),e(h,Io),e(Io,br),e(h,kr),e(h,Po),e(Po,yr),e(h,Or),e(h,Bo),e(Bo,Tr),e(h,Nr),e(h,Mo),e(Mo,jr),e(h,Cr),e(h,Xo),e(Xo,Dr),e(h,qr),e(h,Ro),e(Ro,Lr),e(h,Ar),e(h,Fo),e(Fo,Ir),e(h,Pr),e(h,So),e(So,Br),e(h,Mr),e(h,zo),e(zo,Xr),e(h,Rr),e(h,Ho),e(Ho,Fr),e(h,Sr),e(h,Vo),e(Vo,zr),e(h,Hr),e(h,Wo),e(Wo,Vr),e(h,Wr),e(h,Go),e(Go,Gr),e(h,Yr),e(h,Yo),e(Yo,Ur),e(h,Kr),e(h,Uo),e(Uo,Jr),e(h,Qr),e(h,Ko),e(Ko,Zr),e(h,ei),e(h,Jo),e(Jo,ti),e(h,oi),e(h,Qo),e(Qo,si),e(h,ni),e(h,Zo),e(Zo,ai),e(h,li),e(h,es),e(es,ri),e(h,ii),e(h,ts),e(ts,pi),e(h,fi),e(h,os),e(os,di),e(h,ci),e(h,ss),e(ss,hi),e(h,ui),e(h,ns),e(ns,mi),e(h,gi),e(h,as),e(as,_i),e(h,vi),e(h,ls),e(ls,Ei),e(h,wi),e(h,rs),e(rs,$i),e(h,xi),e(h,is),e(is,bi),e(h,ki),e(h,ps),e(ps,yi),e(h,Oi),e(h,fs),e(fs,Ti),e(h,Ni),e(h,ds),e(ds,ji),e(h,Ci),e(h,cs),e(cs,Di),e(h,qi),e(h,hs),e(hs,Li),e(h,Ai),e(h,us),e(us,Ii),e(h,Pi),e(h,ms),e(ms,Bi),e(h,Mi),e(h,gs),e(gs,Xi),e(h,Ri),e(h,_s),e(_s,Fi),e(h,Si),e(h,vs),e(vs,zi),e(h,Hi),e(h,Es),e(Es,Vi),e(h,Wi),e(h,ws),e(ws,Gi),e(h,Yi),e(h,$s),e($s,Ui),e(h,Ki),e(h,xs),e(xs,Ji),e(h,Qi),e(h,bs),e(bs,Zi),d(t,la,i),d(t,zt,i),e(zt,ep),d(t,ra,i),d(t,Ee,i),e(Ee,Ye),e(Ye,tp),e(Ye,ks),e(ks,op),e(Ye,sp),e(Ee,np),e(Ee,ys),e(ys,ap),d(t,ia,i),d(t,de,i),e(de,we),e(we,Os),O(Ue,Os,null),e(de,lp),e(de,Ts),e(Ts,rp),d(t,pa,i),d(t,Ht,i),e(Ht,ip),d(t,fa,i),O(Ke,t,i),d(t,da,i),d(t,$e,i),e($e,pp),e($e,Ns),e(Ns,fp),e($e,dp),d(t,ca,i),O(Je,t,i),d(t,ha,i),d(t,Vt,i),e(Vt,cp),d(t,ua,i),O(Qe,t,i),d(t,ma,i),d(t,Wt,i),e(Wt,hp),d(t,ga,i),O(Ze,t,i),d(t,_a,i),d(t,ee,i),e(ee,up),e(ee,js),e(js,mp),e(ee,gp),e(ee,Cs),e(Cs,_p),e(ee,vp),d(t,va,i),d(t,G,i),e(G,Ep),e(G,Ds),e(Ds,wp),e(G,$p),e(G,et),e(et,xp),e(G,bp),e(G,tt),e(tt,kp),e(G,yp),d(t,Ea,i),O(ot,t,i),d(t,wa,i),d(t,xe,i),e(xe,Op),e(xe,qs),e(qs,Tp),e(xe,Np),d(t,$a,i),O(st,t,i),d(t,xa,i),d(t,be,i),e(be,jp),e(be,nt),e(nt,Cp),e(be,Dp),d(t,ba,i),O(at,t,i),d(t,ka,i),d(t,Gt,i),e(Gt,qp),d(t,ya,i),O(ke,t,i),d(t,Oa,i),d(t,ce,i),e(ce,ye),e(ye,Ls),O(lt,Ls,null),e(ce,Lp),e(ce,As),e(As,Ap),d(t,Ta,i),d(t,te,i),e(te,Ip),e(te,Is),e(Is,Pp),e(te,Bp),e(te,Ps),e(Ps,Mp),e(te,Xp),d(t,Na,i),d(t,Oe,i),e(Oe,Bs),e(Bs,rt),e(rt,Ms),e(Ms,Rp),e(rt,Fp),e(rt,Xs),e(Xs,Sp),e(Oe,zp),e(Oe,F),e(F,it),e(it,pt),e(pt,Rs),e(Rs,Hp),e(pt,Vp),e(pt,Fs),e(Fs,Wp),e(it,Gp),e(it,Ss),e(Ss,zs),e(zs,Yp),e(F,Up),e(F,ft),e(ft,dt),e(dt,Hs),e(Hs,Kp),e(dt,Jp),e(dt,Vs),e(Vs,Qp),e(ft,Zp),e(ft,Ws),e(Ws,Gs),e(Gs,ef),e(F,tf),e(F,ct),e(ct,Ys),e(Ys,Us),e(Us,of),e(ct,sf),e(ct,Ks),e(Ks,Js),e(Js,nf),e(F,af),e(F,ht),e(ht,Qs),e(Qs,Zs),e(Zs,lf),e(ht,rf),e(ht,en),e(en,tn),e(tn,pf),e(F,ff),e(F,ut),e(ut,mt),e(mt,on),e(on,df),e(mt,cf),e(mt,sn),e(sn,hf),e(ut,uf),e(ut,nn),e(nn,an),e(an,mf),e(F,gf),e(F,gt),e(gt,ln),e(ln,rn),e(rn,_f),e(gt,vf),e(gt,pn),e(pn,fn),e(fn,Ef),e(F,wf),e(F,_t),e(_t,dn),e(dn,cn),e(cn,$f),e(_t,xf),e(_t,hn),e(hn,un),e(un,bf),d(t,ja,i),d(t,Te,i),e(Te,kf),e(Te,Yt),e(Yt,yf),e(Te,Of),d(t,Ca,i),O(vt,t,i),d(t,Da,i),d(t,oe,i),e(oe,Tf),e(oe,mn),e(mn,Nf),e(oe,jf),e(oe,gn),e(gn,Cf),e(oe,Df),d(t,qa,i),O(Et,t,i),d(t,La,i),d(t,Ut,i),e(Ut,qf),d(t,Aa,i),O(wt,t,i),d(t,Ia,i),d(t,Y,i),e(Y,Lf),e(Y,_n),e(_n,Af),e(Y,If),e(Y,vn),e(vn,Pf),e(Y,Bf),e(Y,En),e(En,Mf),e(Y,Xf),d(t,Pa,i),O(Ne,t,i),d(t,Ba,i),d(t,he,i),e(he,je),e(je,wn),O($t,wn,null),e(he,Rf),e(he,$n),e($n,Ff),d(t,Ma,i),d(t,Kt,i),e(Kt,Sf),d(t,Xa,i),d(t,se,i),e(se,xn),e(xn,zf),e(se,Hf),e(se,bn),e(bn,Vf),e(se,Wf),e(se,kn),e(kn,Gf),d(t,Ra,i),d(t,Jt,i),e(Jt,Yf),d(t,Fa,i),d(t,ue,i),e(ue,Ce),e(Ce,yn),O(xt,yn,null),e(ue,Uf),e(ue,On),e(On,Kf),d(t,Sa,i),d(t,Qt,i),e(Qt,Jf),d(t,za,i),d(t,ne,i),e(ne,Zt),e(Zt,Qf),e(Zt,eo),e(eo,Zf),e(ne,ed),e(ne,to),e(to,td),e(to,oo),e(oo,od),e(ne,sd),e(ne,so),e(so,nd),e(so,no),e(no,ad),d(t,Ha,i),O(De,t,i),d(t,Va,i),d(t,qe,i),e(qe,ld),e(qe,Tn),e(Tn,rd),e(qe,id),d(t,Wa,i),O(bt,t,i),d(t,Ga,i),d(t,z,i),e(z,pd),e(z,Nn),e(Nn,fd),e(z,dd),e(z,jn),e(jn,cd),e(z,hd),e(z,Cn),e(Cn,ud),e(z,md),e(z,Dn),e(Dn,gd),e(z,_d),d(t,Ya,i),O(Le,t,i),d(t,Ua,i),d(t,ao,i),e(ao,vd),d(t,Ka,i),O(kt,t,i),d(t,Ja,i),d(t,lo,i),e(lo,Ed),d(t,Qa,i),O(yt,t,i),d(t,Za,i),d(t,ro,i),e(ro,wd),d(t,el,i),O(Ot,t,i),d(t,tl,i),d(t,H,i),e(H,$d),e(H,qn),e(qn,xd),e(H,bd),e(H,Ln),e(Ln,kd),e(H,yd),e(H,An),e(An,Od),e(H,Td),e(H,In),e(In,Nd),e(H,jd),d(t,ol,i),O(Tt,t,i),d(t,sl,i),O(Ae,t,i),d(t,nl,i),d(t,me,i),e(me,Ie),e(Ie,Pn),O(Nt,Pn,null),e(me,Cd),e(me,Bn),e(Bn,Dd),d(t,al,i),d(t,ae,i),e(ae,qd),e(ae,Mn),e(Mn,Ld),e(ae,Ad),e(ae,Xn),e(Xn,Id),e(ae,Pd),d(t,ll,i),O(jt,t,i),d(t,rl,i),d(t,S,i),e(S,Bd),e(S,Rn),e(Rn,Md),e(S,Xd),e(S,Fn),e(Fn,Rd),e(S,Fd),e(S,Sn),e(Sn,Sd),e(S,zd),e(S,zn),e(zn,Hd),e(S,Vd),e(S,Hn),e(Hn,Wd),e(S,Gd),d(t,il,i),O(Ct,t,i),d(t,pl,i),O(Pe,t,i),d(t,fl,i),d(t,ge,i),e(ge,Be),e(Be,Vn),O(Dt,Vn,null),e(ge,Yd),e(ge,Wn),e(Wn,Ud),d(t,dl,i),d(t,le,i),e(le,Kd),e(le,Gn),e(Gn,Jd),e(le,Qd),e(le,Yn),e(Yn,Zd),e(le,ec),d(t,cl,i),O(qt,t,i),d(t,hl,i),d(t,Me,i),e(Me,tc),e(Me,io),e(io,oc),e(Me,sc),d(t,ul,i),d(t,_e,i),e(_e,Xe),e(Xe,Un),O(Lt,Un,null),e(_e,nc),e(_e,Kn),e(Kn,ac),d(t,ml,i),d(t,po,i),e(po,lc),d(t,gl,i),d(t,re,i),e(re,At),e(At,rc),e(At,Jn),e(Jn,ic),e(At,pc),e(re,fc),e(re,fo),e(fo,dc),e(fo,Qn),e(Qn,cc),e(re,hc),e(re,co),e(co,uc),e(co,Zn),e(Zn,mc),d(t,_l,i),d(t,Re,i),e(Re,gc),e(Re,It),e(It,_c),e(Re,vc),vl=!0},p(t,[i]){const Pt={};i&2&&(Pt.$$scope={dirty:i,ctx:t}),X.$set(Pt);const ea={};i&2&&(ea.$$scope={dirty:i,ctx:t}),ke.$set(ea);const ta={};i&2&&(ta.$$scope={dirty:i,ctx:t}),Ne.$set(ta);const oa={};i&2&&(oa.$$scope={dirty:i,ctx:t}),De.$set(oa);const Bt={};i&2&&(Bt.$$scope={dirty:i,ctx:t}),Le.$set(Bt);const sa={};i&2&&(sa.$$scope={dirty:i,ctx:t}),Ae.$set(sa);const Mt={};i&2&&(Mt.$$scope={dirty:i,ctx:t}),Pe.$set(Mt)},i(t){vl||(T(v.$$.fragment,t),T(X.$$.fragment,t),T(Ue.$$.fragment,t),T(Ke.$$.fragment,t),T(Je.$$.fragment,t),T(Qe.$$.fragment,t),T(Ze.$$.fragment,t),T(ot.$$.fragment,t),T(st.$$.fragment,t),T(at.$$.fragment,t),T(ke.$$.fragment,t),T(lt.$$.fragment,t),T(vt.$$.fragment,t),T(Et.$$.fragment,t),T(wt.$$.fragment,t),T(Ne.$$.fragment,t),T($t.$$.fragment,t),T(xt.$$.fragment,t),T(De.$$.fragment,t),T(bt.$$.fragment,t),T(Le.$$.fragment,t),T(kt.$$.fragment,t),T(yt.$$.fragment,t),T(Ot.$$.fragment,t),T(Tt.$$.fragment,t),T(Ae.$$.fragment,t),T(Nt.$$.fragment,t),T(jt.$$.fragment,t),T(Ct.$$.fragment,t),T(Pe.$$.fragment,t),T(Dt.$$.fragment,t),T(qt.$$.fragment,t),T(Lt.$$.fragment,t),vl=!0)},o(t){N(v.$$.fragment,t),N(X.$$.fragment,t),N(Ue.$$.fragment,t),N(Ke.$$.fragment,t),N(Je.$$.fragment,t),N(Qe.$$.fragment,t),N(Ze.$$.fragment,t),N(ot.$$.fragment,t),N(st.$$.fragment,t),N(at.$$.fragment,t),N(ke.$$.fragment,t),N(lt.$$.fragment,t),N(vt.$$.fragment,t),N(Et.$$.fragment,t),N(wt.$$.fragment,t),N(Ne.$$.fragment,t),N($t.$$.fragment,t),N(xt.$$.fragment,t),N(De.$$.fragment,t),N(bt.$$.fragment,t),N(Le.$$.fragment,t),N(kt.$$.fragment,t),N(yt.$$.fragment,t),N(Ot.$$.fragment,t),N(Tt.$$.fragment,t),N(Ae.$$.fragment,t),N(Nt.$$.fragment,t),N(jt.$$.fragment,t),N(Ct.$$.fragment,t),N(Pe.$$.fragment,t),N(Dt.$$.fragment,t),N(qt.$$.fragment,t),N(Lt.$$.fragment,t),vl=!1},d(t){o(c),t&&o(w),t&&o(m),j(v),t&&o(C),t&&o(A),t&&o(R),j(X,t),t&&o(Q),t&&o(W),t&&o(Z),t&&o(P),t&&o(Ge),t&&o(J),t&&o(na),t&&o(St),t&&o(aa),t&&o(h),t&&o(la),t&&o(zt),t&&o(ra),t&&o(Ee),t&&o(ia),t&&o(de),j(Ue),t&&o(pa),t&&o(Ht),t&&o(fa),j(Ke,t),t&&o(da),t&&o($e),t&&o(ca),j(Je,t),t&&o(ha),t&&o(Vt),t&&o(ua),j(Qe,t),t&&o(ma),t&&o(Wt),t&&o(ga),j(Ze,t),t&&o(_a),t&&o(ee),t&&o(va),t&&o(G),t&&o(Ea),j(ot,t),t&&o(wa),t&&o(xe),t&&o($a),j(st,t),t&&o(xa),t&&o(be),t&&o(ba),j(at,t),t&&o(ka),t&&o(Gt),t&&o(ya),j(ke,t),t&&o(Oa),t&&o(ce),j(lt),t&&o(Ta),t&&o(te),t&&o(Na),t&&o(Oe),t&&o(ja),t&&o(Te),t&&o(Ca),j(vt,t),t&&o(Da),t&&o(oe),t&&o(qa),j(Et,t),t&&o(La),t&&o(Ut),t&&o(Aa),j(wt,t),t&&o(Ia),t&&o(Y),t&&o(Pa),j(Ne,t),t&&o(Ba),t&&o(he),j($t),t&&o(Ma),t&&o(Kt),t&&o(Xa),t&&o(se),t&&o(Ra),t&&o(Jt),t&&o(Fa),t&&o(ue),j(xt),t&&o(Sa),t&&o(Qt),t&&o(za),t&&o(ne),t&&o(Ha),j(De,t),t&&o(Va),t&&o(qe),t&&o(Wa),j(bt,t),t&&o(Ga),t&&o(z),t&&o(Ya),j(Le,t),t&&o(Ua),t&&o(ao),t&&o(Ka),j(kt,t),t&&o(Ja),t&&o(lo),t&&o(Qa),j(yt,t),t&&o(Za),t&&o(ro),t&&o(el),j(Ot,t),t&&o(tl),t&&o(H),t&&o(ol),j(Tt,t),t&&o(sl),j(Ae,t),t&&o(nl),t&&o(me),j(Nt),t&&o(al),t&&o(ae),t&&o(ll),j(jt,t),t&&o(rl),t&&o(S),t&&o(il),j(Ct,t),t&&o(pl),j(Pe,t),t&&o(fl),t&&o(ge),j(Dt),t&&o(dl),t&&o(le),t&&o(cl),j(qt,t),t&&o(hl),t&&o(Me),t&&o(ul),t&&o(_e),j(Lt),t&&o(ml),t&&o(po),t&&o(gl),t&&o(re),t&&o(_l),t&&o(Re)}}}const eg={local:"export-to-onnx",sections:[{local:"exporting-a-model-to-onnx",title:"Exporting a model to ONNX"},{local:"selecting-features-for-different-model-tasks",title:"Selecting features for different model tasks"},{local:"exporting-a-model-for-an-unsupported-architecture",sections:[{local:"implementing-a-custom-onnx-configuration",title:"Implementing a custom ONNX configuration"},{local:"exporting-the-model",title:"Exporting the model"},{local:"validating-the-model-outputs",title:"Validating the model outputs"}],title:"Exporting a model for an unsupported architecture"},{local:"contributing-a-new-configuration-to-transformers",title:"Contributing a new configuration to \u{1F917} Transformers"}],title:"Export to ONNX"};function tg(M){return Fm(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rg extends Bm{constructor(c){super();Mm(this,c,tg,Zm,Xm,{})}}export{rg as default,eg as metadata};
