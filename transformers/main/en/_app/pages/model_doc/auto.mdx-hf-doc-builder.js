import{S as vDt,i as FDt,s as TDt,e as a,k as l,w as F,t as o,M as MDt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as EDt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as KYr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function CDt(x){let g,v,u,f,p,d,h,Eo,Ti,Lm,at,Mi,Ei,wy,ym,Oe,Qe,Ci,Rn,Ay,Pn,Bn,Ly,wi,In,yy,Ai,xm,xa;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),Lm=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),wy=o(")."),ym=l(),Oe=a("p"),Qe=o("Likewise, if your "),Ci=a("code"),Rn=o("NewModel"),Ay=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),Ly=o(`, make sure its
`),wi=a("code"),In=o("config_class"),yy=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),xm=o("NewModelConfig"),xa=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var rS=s(u);f=r(rS,"NewModelConfig"),rS.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var tS=s(Ti);Lm=r(tS,"model_type"),tS.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var aS=s(Mi);Ei=r(aS,'"new-model"'),aS.forEach(t),wy=r(Ae,")."),Ae.forEach(t),ym=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var $a=s(Ci);Rn=r($a,"NewModel"),$a.forEach(t),Ay=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var nS=s(Pn);Bn=r(nS,"PreTrainedModel"),nS.forEach(t),Ly=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var $m=s(wi);In=r($m,"config_class"),$m.forEach(t),yy=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var sS=s(Ai);xm=r(sS,"NewModelConfig"),sS.forEach(t),xa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,Lm),e(g,at),e(g,Mi),e(Mi,Ei),e(g,wy),b(We,ym,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Ci),e(Ci,Rn),e(Oe,Ay),e(Oe,Pn),e(Pn,Bn),e(Oe,Ly),e(Oe,wi),e(wi,In),e(Oe,yy),e(Oe,Ai),e(Ai,xm),e(Oe,xa)},d(We){We&&t(g),We&&t(ym),We&&t(Oe)}}}function wDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ADt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LDt(x){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var Eo=s(u);f=r(Eo,"use_auth_token=True"),Eo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function yDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xDt(x){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var Eo=s(u);f=r(Eo,"use_auth_token=True"),Eo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function $Dt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function SDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function IDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ODt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZDt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Gt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function EGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function AGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $Gt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function SGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function IGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZGt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Ot(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MOt(x){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function EOt(x){let g,v,u,f,p,d,h,Eo,Ti,Lm,at,Mi,Ei,wy,ym,Oe,Qe,Ci,Rn,Ay,Pn,Bn,Ly,wi,In,yy,Ai,xm,xa,We,Ae,rS,Li,tS,aS,Co,$a,nS,$m,sS,eQe,jGe,yi,km,fte,xy,oQe,gte,rQe,DGe,Nn,tQe,hte,aQe,nQe,ute,sQe,lQe,GGe,$y,OGe,lS,iQe,VGe,Sm,XGe,xi,Rm,pte,ky,dQe,_te,cQe,zGe,wo,Sy,mQe,Ry,fQe,iS,gQe,hQe,uQe,Py,pQe,bte,_Qe,bQe,vQe,Ar,By,FQe,vte,TQe,MQe,$i,EQe,Fte,CQe,wQe,Tte,AQe,LQe,yQe,A,Pm,Mte,xQe,$Qe,dS,kQe,SQe,RQe,Bm,Ete,PQe,BQe,cS,IQe,NQe,qQe,Im,Cte,jQe,DQe,mS,GQe,OQe,VQe,Nm,wte,XQe,zQe,fS,QQe,WQe,HQe,qm,Ate,UQe,JQe,gS,YQe,KQe,ZQe,jm,Lte,eWe,oWe,hS,rWe,tWe,aWe,Dm,yte,nWe,sWe,uS,lWe,iWe,dWe,Gm,xte,cWe,mWe,pS,fWe,gWe,hWe,Om,$te,uWe,pWe,_S,_We,bWe,vWe,Vm,kte,FWe,TWe,bS,MWe,EWe,CWe,Xm,Ste,wWe,AWe,vS,LWe,yWe,xWe,zm,Rte,$We,kWe,FS,SWe,RWe,PWe,Qm,Pte,BWe,IWe,TS,NWe,qWe,jWe,Wm,Bte,DWe,GWe,MS,OWe,VWe,XWe,Hm,Ite,zWe,QWe,ES,WWe,HWe,UWe,Um,Nte,JWe,YWe,CS,KWe,ZWe,eHe,Jm,qte,oHe,rHe,wS,tHe,aHe,nHe,Ym,jte,sHe,lHe,AS,iHe,dHe,cHe,Km,Dte,mHe,fHe,LS,gHe,hHe,uHe,Zm,Gte,pHe,_He,yS,bHe,vHe,FHe,ef,Ote,THe,MHe,xS,EHe,CHe,wHe,of,Vte,AHe,LHe,$S,yHe,xHe,$He,rf,Xte,kHe,SHe,kS,RHe,PHe,BHe,tf,zte,IHe,NHe,SS,qHe,jHe,DHe,af,Qte,GHe,OHe,RS,VHe,XHe,zHe,nf,Wte,QHe,WHe,PS,HHe,UHe,JHe,sf,Hte,YHe,KHe,BS,ZHe,eUe,oUe,lf,Ute,rUe,tUe,IS,aUe,nUe,sUe,df,Jte,lUe,iUe,NS,dUe,cUe,mUe,cf,Yte,fUe,gUe,qS,hUe,uUe,pUe,mf,Kte,_Ue,bUe,jS,vUe,FUe,TUe,ff,Zte,MUe,EUe,DS,CUe,wUe,AUe,gf,eae,LUe,yUe,GS,xUe,$Ue,kUe,hf,oae,SUe,RUe,OS,PUe,BUe,IUe,uf,rae,NUe,qUe,VS,jUe,DUe,GUe,pf,tae,OUe,VUe,XS,XUe,zUe,QUe,_f,aae,WUe,HUe,zS,UUe,JUe,YUe,bf,nae,KUe,ZUe,QS,eJe,oJe,rJe,vf,sae,tJe,aJe,WS,nJe,sJe,lJe,Ff,lae,iJe,dJe,HS,cJe,mJe,fJe,Tf,iae,gJe,hJe,US,uJe,pJe,_Je,Mf,dae,bJe,vJe,JS,FJe,TJe,MJe,Ef,cae,EJe,CJe,YS,wJe,AJe,LJe,Cf,mae,yJe,xJe,KS,$Je,kJe,SJe,wf,fae,RJe,PJe,ZS,BJe,IJe,NJe,Af,gae,qJe,jJe,eR,DJe,GJe,OJe,Lf,hae,VJe,XJe,oR,zJe,QJe,WJe,yf,uae,HJe,UJe,rR,JJe,YJe,KJe,xf,pae,ZJe,eYe,tR,oYe,rYe,tYe,$f,_ae,aYe,nYe,aR,sYe,lYe,iYe,kf,bae,dYe,cYe,nR,mYe,fYe,gYe,Sf,vae,hYe,uYe,sR,pYe,_Ye,bYe,Rf,Fae,vYe,FYe,lR,TYe,MYe,EYe,Pf,Tae,CYe,wYe,iR,AYe,LYe,yYe,Bf,Mae,xYe,$Ye,dR,kYe,SYe,RYe,If,Eae,PYe,BYe,cR,IYe,NYe,qYe,Nf,Cae,jYe,DYe,mR,GYe,OYe,VYe,qf,wae,XYe,zYe,fR,QYe,WYe,HYe,jf,Aae,UYe,JYe,gR,YYe,KYe,ZYe,Df,Lae,eKe,oKe,hR,rKe,tKe,aKe,Gf,yae,nKe,sKe,uR,lKe,iKe,dKe,Of,xae,cKe,mKe,pR,fKe,gKe,hKe,Vf,$ae,uKe,pKe,_R,_Ke,bKe,vKe,Xf,kae,FKe,TKe,bR,MKe,EKe,CKe,zf,Sae,wKe,AKe,vR,LKe,yKe,xKe,Qf,Rae,$Ke,kKe,FR,SKe,RKe,PKe,Wf,Pae,BKe,IKe,TR,NKe,qKe,jKe,Hf,Bae,DKe,GKe,MR,OKe,VKe,XKe,Uf,Iae,zKe,QKe,ER,WKe,HKe,UKe,Jf,Nae,JKe,YKe,CR,KKe,ZKe,eZe,Yf,qae,oZe,rZe,wR,tZe,aZe,nZe,Kf,jae,sZe,lZe,AR,iZe,dZe,cZe,Zf,Dae,mZe,fZe,LR,gZe,hZe,uZe,eg,Gae,pZe,_Ze,yR,bZe,vZe,FZe,og,Oae,TZe,MZe,xR,EZe,CZe,wZe,rg,Vae,AZe,LZe,$R,yZe,xZe,$Ze,tg,Xae,kZe,SZe,kR,RZe,PZe,BZe,ag,zae,IZe,NZe,SR,qZe,jZe,DZe,ng,Qae,GZe,OZe,RR,VZe,XZe,zZe,sg,Wae,QZe,WZe,PR,HZe,UZe,JZe,lg,Hae,YZe,KZe,BR,ZZe,eeo,oeo,ig,Uae,reo,teo,IR,aeo,neo,seo,dg,Jae,leo,ieo,NR,deo,ceo,meo,cg,Yae,feo,geo,qR,heo,ueo,peo,mg,Kae,_eo,beo,jR,veo,Feo,Teo,fg,Zae,Meo,Eeo,DR,Ceo,weo,Aeo,gg,ene,Leo,yeo,GR,xeo,$eo,keo,hg,one,Seo,Reo,OR,Peo,Beo,Ieo,ug,rne,Neo,qeo,VR,jeo,Deo,Geo,pg,tne,Oeo,Veo,XR,Xeo,zeo,Qeo,_g,ane,Weo,Heo,zR,Ueo,Jeo,Yeo,bg,nne,Keo,Zeo,QR,eoo,ooo,roo,vg,sne,too,aoo,WR,noo,soo,loo,Fg,lne,ioo,doo,HR,coo,moo,foo,Tg,ine,goo,hoo,UR,uoo,poo,_oo,Mg,dne,boo,voo,JR,Foo,Too,Moo,Eg,cne,Eoo,Coo,YR,woo,Aoo,Loo,Cg,mne,yoo,xoo,KR,$oo,koo,Soo,wg,fne,Roo,Poo,ZR,Boo,Ioo,Noo,Ag,gne,qoo,joo,eP,Doo,Goo,Ooo,Lg,hne,Voo,Xoo,oP,zoo,Qoo,Woo,yg,une,Hoo,Uoo,rP,Joo,Yoo,Koo,xg,pne,Zoo,ero,tP,oro,rro,tro,$g,_ne,aro,nro,aP,sro,lro,iro,kg,bne,dro,cro,nP,mro,fro,gro,Sg,vne,hro,uro,sP,pro,_ro,bro,Rg,Fne,vro,Fro,lP,Tro,Mro,Ero,Pg,Tne,Cro,wro,iP,Aro,Lro,yro,Bg,Mne,xro,$ro,dP,kro,Sro,Rro,Ig,Ene,Pro,Bro,cP,Iro,Nro,qro,Ng,Cne,jro,Dro,mP,Gro,Oro,Vro,qg,wne,Xro,zro,fP,Qro,Wro,Hro,jg,Ane,Uro,Jro,gP,Yro,Kro,Zro,Dg,Lne,eto,oto,hP,rto,tto,ato,Gg,nto,Og,Iy,sto,yne,lto,QGe,ki,Vg,xne,Ny,ito,$ne,dto,WGe,Ao,qy,cto,jy,mto,uP,fto,gto,hto,Dy,uto,kne,pto,_to,bto,Lr,Gy,vto,Sne,Fto,Tto,ka,Mto,Rne,Eto,Cto,Pne,wto,Ato,Bne,Lto,yto,xto,k,qn,Ine,$to,kto,pP,Sto,Rto,_P,Pto,Bto,Ito,jn,Nne,Nto,qto,bP,jto,Dto,vP,Gto,Oto,Vto,Dn,qne,Xto,zto,FP,Qto,Wto,TP,Hto,Uto,Jto,Xg,jne,Yto,Kto,MP,Zto,eao,oao,Gn,Dne,rao,tao,EP,aao,nao,CP,sao,lao,iao,zg,Gne,dao,cao,wP,mao,fao,gao,Qg,One,hao,uao,AP,pao,_ao,bao,Wg,Vne,vao,Fao,LP,Tao,Mao,Eao,On,Xne,Cao,wao,yP,Aao,Lao,xP,yao,xao,$ao,Vn,zne,kao,Sao,$P,Rao,Pao,kP,Bao,Iao,Nao,Xn,Qne,qao,jao,SP,Dao,Gao,RP,Oao,Vao,Xao,Hg,Wne,zao,Qao,PP,Wao,Hao,Uao,Ug,Hne,Jao,Yao,BP,Kao,Zao,eno,Jg,Une,ono,rno,IP,tno,ano,nno,zn,Jne,sno,lno,NP,ino,dno,qP,cno,mno,fno,Yg,Yne,gno,hno,jP,uno,pno,_no,Qn,Kne,bno,vno,DP,Fno,Tno,GP,Mno,Eno,Cno,Wn,Zne,wno,Ano,OP,Lno,yno,VP,xno,$no,kno,Hn,ese,Sno,Rno,XP,Pno,Bno,zP,Ino,Nno,qno,Kg,ose,jno,Dno,QP,Gno,Ono,Vno,Un,rse,Xno,zno,WP,Qno,Wno,HP,Hno,Uno,Jno,Jn,tse,Yno,Kno,UP,Zno,eso,JP,oso,rso,tso,Yn,ase,aso,nso,YP,sso,lso,KP,iso,dso,cso,Kn,nse,mso,fso,ZP,gso,hso,eB,uso,pso,_so,Zn,sse,bso,vso,oB,Fso,Tso,rB,Mso,Eso,Cso,es,lse,wso,Aso,tB,Lso,yso,aB,xso,$so,kso,Zg,ise,Sso,Rso,nB,Pso,Bso,Iso,os,dse,Nso,qso,sB,jso,Dso,lB,Gso,Oso,Vso,eh,cse,Xso,zso,iB,Qso,Wso,Hso,rs,mse,Uso,Jso,dB,Yso,Kso,cB,Zso,elo,olo,ts,fse,rlo,tlo,mB,alo,nlo,fB,slo,llo,ilo,as,gse,dlo,clo,gB,mlo,flo,hB,glo,hlo,ulo,oh,hse,plo,_lo,uB,blo,vlo,Flo,ns,use,Tlo,Mlo,pB,Elo,Clo,_B,wlo,Alo,Llo,ss,pse,ylo,xlo,bB,$lo,klo,vB,Slo,Rlo,Plo,rh,_se,Blo,Ilo,FB,Nlo,qlo,jlo,ls,bse,Dlo,Glo,TB,Olo,Vlo,MB,Xlo,zlo,Qlo,is,vse,Wlo,Hlo,EB,Ulo,Jlo,CB,Ylo,Klo,Zlo,ds,Fse,eio,oio,wB,rio,tio,AB,aio,nio,sio,cs,Tse,lio,iio,LB,dio,cio,yB,mio,fio,gio,ms,Mse,hio,uio,xB,pio,_io,$B,bio,vio,Fio,fs,Ese,Tio,Mio,kB,Eio,Cio,SB,wio,Aio,Lio,gs,Cse,yio,xio,RB,$io,kio,PB,Sio,Rio,Pio,hs,wse,Bio,Iio,BB,Nio,qio,IB,jio,Dio,Gio,th,Ase,Oio,Vio,NB,Xio,zio,Qio,us,Lse,Wio,Hio,qB,Uio,Jio,jB,Yio,Kio,Zio,ah,yse,edo,odo,DB,rdo,tdo,ado,nh,xse,ndo,sdo,GB,ldo,ido,ddo,ps,$se,cdo,mdo,OB,fdo,gdo,VB,hdo,udo,pdo,_s,kse,_do,bdo,XB,vdo,Fdo,zB,Tdo,Mdo,Edo,bs,Sse,Cdo,wdo,QB,Ado,Ldo,WB,ydo,xdo,$do,sh,Rse,kdo,Sdo,HB,Rdo,Pdo,Bdo,vs,Pse,Ido,Ndo,UB,qdo,jdo,JB,Ddo,Gdo,Odo,Fs,Bse,Vdo,Xdo,YB,zdo,Qdo,KB,Wdo,Hdo,Udo,Ts,Ise,Jdo,Ydo,ZB,Kdo,Zdo,eI,eco,oco,rco,Ms,Nse,tco,aco,oI,nco,sco,rI,lco,ico,dco,Es,qse,cco,mco,tI,fco,gco,aI,hco,uco,pco,Cs,jse,_co,bco,nI,vco,Fco,sI,Tco,Mco,Eco,lh,Dse,Cco,wco,lI,Aco,Lco,yco,ws,Gse,xco,$co,iI,kco,Sco,dI,Rco,Pco,Bco,ih,Ose,Ico,Nco,cI,qco,jco,Dco,dh,Vse,Gco,Oco,mI,Vco,Xco,zco,ch,Xse,Qco,Wco,fI,Hco,Uco,Jco,mh,zse,Yco,Kco,gI,Zco,emo,omo,As,Qse,rmo,tmo,hI,amo,nmo,uI,smo,lmo,imo,fh,Wse,dmo,cmo,pI,mmo,fmo,gmo,Ls,Hse,hmo,umo,_I,pmo,_mo,bI,bmo,vmo,Fmo,ys,Use,Tmo,Mmo,vI,Emo,Cmo,FI,wmo,Amo,Lmo,xs,Jse,ymo,xmo,TI,$mo,kmo,MI,Smo,Rmo,Pmo,$s,Yse,Bmo,Imo,EI,Nmo,qmo,CI,jmo,Dmo,Gmo,ks,Kse,Omo,Vmo,wI,Xmo,zmo,AI,Qmo,Wmo,Hmo,Ss,Zse,Umo,Jmo,LI,Ymo,Kmo,yI,Zmo,efo,ofo,gh,ele,rfo,tfo,xI,afo,nfo,sfo,hh,ole,lfo,ifo,$I,dfo,cfo,mfo,Rs,rle,ffo,gfo,kI,hfo,ufo,SI,pfo,_fo,bfo,Ps,tle,vfo,Ffo,RI,Tfo,Mfo,PI,Efo,Cfo,wfo,Bs,ale,Afo,Lfo,BI,yfo,xfo,II,$fo,kfo,Sfo,uh,nle,Rfo,Pfo,NI,Bfo,Ifo,Nfo,ph,sle,qfo,jfo,qI,Dfo,Gfo,Ofo,_h,lle,Vfo,Xfo,jI,zfo,Qfo,Wfo,Is,ile,Hfo,Ufo,DI,Jfo,Yfo,GI,Kfo,Zfo,ego,Ns,dle,ogo,rgo,OI,tgo,ago,VI,ngo,sgo,lgo,bh,cle,igo,dgo,XI,cgo,mgo,fgo,vh,mle,ggo,hgo,zI,ugo,pgo,_go,Fh,fle,bgo,vgo,QI,Fgo,Tgo,Mgo,qs,gle,Ego,Cgo,WI,wgo,Ago,HI,Lgo,ygo,xgo,Th,hle,$go,kgo,UI,Sgo,Rgo,Pgo,Mh,ule,Bgo,Igo,JI,Ngo,qgo,jgo,js,ple,Dgo,Ggo,YI,Ogo,Vgo,KI,Xgo,zgo,Qgo,Ds,_le,Wgo,Hgo,ZI,Ugo,Jgo,eN,Ygo,Kgo,Zgo,Gs,ble,eho,oho,oN,rho,tho,rN,aho,nho,sho,Os,vle,lho,iho,tN,dho,cho,aN,mho,fho,gho,Eh,hho,Ch,Oy,uho,Fle,pho,HGe,Si,wh,Tle,Vy,_ho,Mle,bho,UGe,Lo,Xy,vho,zy,Fho,nN,Tho,Mho,Eho,Qy,Cho,Ele,who,Aho,Lho,He,Wy,yho,Cle,xho,$ho,Sa,kho,wle,Sho,Rho,Ale,Pho,Bho,Lle,Iho,Nho,qho,Y,Ah,yle,jho,Dho,sN,Gho,Oho,Vho,Lh,xle,Xho,zho,lN,Qho,Who,Hho,yh,$le,Uho,Jho,iN,Yho,Kho,Zho,xh,kle,euo,ouo,dN,ruo,tuo,auo,$h,Sle,nuo,suo,cN,luo,iuo,duo,kh,Rle,cuo,muo,mN,fuo,guo,huo,Sh,Ple,uuo,puo,fN,_uo,buo,vuo,Rh,Ble,Fuo,Tuo,gN,Muo,Euo,Cuo,Ph,Ile,wuo,Auo,hN,Luo,yuo,xuo,Bh,Nle,$uo,kuo,uN,Suo,Ruo,Puo,Ih,qle,Buo,Iuo,pN,Nuo,quo,juo,Nh,jle,Duo,Guo,_N,Ouo,Vuo,Xuo,qh,Dle,zuo,Quo,bN,Wuo,Huo,Uuo,jh,Gle,Juo,Yuo,vN,Kuo,Zuo,epo,Dh,Ole,opo,rpo,FN,tpo,apo,npo,Gh,Vle,spo,lpo,TN,ipo,dpo,cpo,Oh,Xle,mpo,fpo,MN,gpo,hpo,upo,Vh,zle,ppo,_po,EN,bpo,vpo,Fpo,Xh,Qle,Tpo,Mpo,CN,Epo,Cpo,wpo,zh,Wle,Apo,Lpo,wN,ypo,xpo,$po,Qh,Hle,kpo,Spo,AN,Rpo,Ppo,Bpo,Wh,Ule,Ipo,Npo,LN,qpo,jpo,Dpo,Hh,Jle,Gpo,Opo,yN,Vpo,Xpo,zpo,Uh,Yle,Qpo,Wpo,xN,Hpo,Upo,Jpo,Jh,Kle,Ypo,Kpo,$N,Zpo,e_o,o_o,Yh,Zle,r_o,t_o,kN,a_o,n_o,s_o,Kh,eie,l_o,i_o,SN,d_o,c_o,m_o,Zh,oie,f_o,g_o,RN,h_o,u_o,p_o,eu,rie,__o,b_o,PN,v_o,F_o,T_o,ou,tie,M_o,E_o,BN,C_o,w_o,A_o,ru,aie,L_o,y_o,IN,x_o,$_o,k_o,tu,nie,S_o,R_o,NN,P_o,B_o,I_o,au,N_o,nu,q_o,su,Hy,j_o,sie,D_o,JGe,Ri,lu,lie,Uy,G_o,iie,O_o,YGe,yo,Jy,V_o,Yy,X_o,qN,z_o,Q_o,W_o,Ky,H_o,die,U_o,J_o,Y_o,Ue,Zy,K_o,cie,Z_o,e2o,Pi,o2o,mie,r2o,t2o,fie,a2o,n2o,s2o,he,iu,gie,l2o,i2o,jN,d2o,c2o,m2o,du,hie,f2o,g2o,uie,h2o,u2o,p2o,cu,pie,_2o,b2o,DN,v2o,F2o,T2o,mu,_ie,M2o,E2o,GN,C2o,w2o,A2o,fu,bie,L2o,y2o,ON,x2o,$2o,k2o,gu,vie,S2o,R2o,VN,P2o,B2o,I2o,hu,Fie,N2o,q2o,XN,j2o,D2o,G2o,uu,Tie,O2o,V2o,zN,X2o,z2o,Q2o,pu,Mie,W2o,H2o,QN,U2o,J2o,Y2o,_u,Eie,K2o,Z2o,WN,ebo,obo,rbo,bu,Cie,tbo,abo,HN,nbo,sbo,lbo,vu,wie,ibo,dbo,UN,cbo,mbo,fbo,Fu,Aie,gbo,hbo,JN,ubo,pbo,_bo,Tu,Lie,bbo,vbo,YN,Fbo,Tbo,Mbo,Mu,yie,Ebo,Cbo,KN,wbo,Abo,Lbo,Eu,xie,ybo,xbo,ZN,$bo,kbo,Sbo,Cu,$ie,Rbo,Pbo,eq,Bbo,Ibo,Nbo,wu,qbo,Au,jbo,Lu,e7,Dbo,kie,Gbo,KGe,Bi,yu,Sie,o7,Obo,Rie,Vbo,ZGe,xo,r7,Xbo,Ii,zbo,oq,Qbo,Wbo,rq,Hbo,Ubo,Jbo,t7,Ybo,Pie,Kbo,Zbo,evo,nt,a7,ovo,Bie,rvo,tvo,Ni,avo,Iie,nvo,svo,tq,lvo,ivo,dvo,xu,cvo,Je,n7,mvo,Nie,fvo,gvo,Ra,hvo,qie,uvo,pvo,jie,_vo,bvo,Die,vvo,Fvo,Tvo,y,$u,Gie,Mvo,Evo,aq,Cvo,wvo,Avo,ku,Oie,Lvo,yvo,nq,xvo,$vo,kvo,Su,Vie,Svo,Rvo,sq,Pvo,Bvo,Ivo,Ru,Xie,Nvo,qvo,lq,jvo,Dvo,Gvo,Pu,zie,Ovo,Vvo,iq,Xvo,zvo,Qvo,Bu,Qie,Wvo,Hvo,dq,Uvo,Jvo,Yvo,Iu,Wie,Kvo,Zvo,cq,eFo,oFo,rFo,Nu,Hie,tFo,aFo,mq,nFo,sFo,lFo,qu,Uie,iFo,dFo,fq,cFo,mFo,fFo,ju,Jie,gFo,hFo,gq,uFo,pFo,_Fo,Du,Yie,bFo,vFo,hq,FFo,TFo,MFo,Gu,Kie,EFo,CFo,uq,wFo,AFo,LFo,Ou,Zie,yFo,xFo,pq,$Fo,kFo,SFo,Vu,ede,RFo,PFo,_q,BFo,IFo,NFo,Xu,ode,qFo,jFo,bq,DFo,GFo,OFo,zu,rde,VFo,XFo,vq,zFo,QFo,WFo,Qu,tde,HFo,UFo,Fq,JFo,YFo,KFo,Wu,ade,ZFo,e1o,Tq,o1o,r1o,t1o,Hu,nde,a1o,n1o,Mq,s1o,l1o,i1o,Uu,sde,d1o,c1o,Eq,m1o,f1o,g1o,Ju,lde,h1o,u1o,Cq,p1o,_1o,b1o,Yu,ide,v1o,F1o,wq,T1o,M1o,E1o,Ku,dde,C1o,w1o,Aq,A1o,L1o,y1o,Zu,cde,x1o,$1o,Lq,k1o,S1o,R1o,ep,mde,P1o,B1o,yq,I1o,N1o,q1o,op,fde,j1o,D1o,xq,G1o,O1o,V1o,rp,gde,X1o,z1o,$q,Q1o,W1o,H1o,tp,hde,U1o,J1o,kq,Y1o,K1o,Z1o,ap,ude,eTo,oTo,Sq,rTo,tTo,aTo,np,pde,nTo,sTo,Rq,lTo,iTo,dTo,sp,_de,cTo,mTo,Pq,fTo,gTo,hTo,lp,bde,uTo,pTo,Bq,_To,bTo,vTo,ip,vde,FTo,TTo,Iq,MTo,ETo,CTo,Vs,Fde,wTo,ATo,Nq,LTo,yTo,qq,xTo,$To,kTo,dp,Tde,STo,RTo,jq,PTo,BTo,ITo,cp,Mde,NTo,qTo,Dq,jTo,DTo,GTo,mp,Ede,OTo,VTo,Gq,XTo,zTo,QTo,fp,Cde,WTo,HTo,Oq,UTo,JTo,YTo,gp,wde,KTo,ZTo,Vq,eMo,oMo,rMo,hp,Ade,tMo,aMo,Xq,nMo,sMo,lMo,up,Lde,iMo,dMo,zq,cMo,mMo,fMo,pp,yde,gMo,hMo,Qq,uMo,pMo,_Mo,_p,xde,bMo,vMo,Wq,FMo,TMo,MMo,bp,$de,EMo,CMo,Hq,wMo,AMo,LMo,vp,kde,yMo,xMo,Uq,$Mo,kMo,SMo,Fp,Sde,RMo,PMo,Jq,BMo,IMo,NMo,Tp,Rde,qMo,jMo,Yq,DMo,GMo,OMo,Mp,Pde,VMo,XMo,Kq,zMo,QMo,WMo,Ep,Bde,HMo,UMo,Zq,JMo,YMo,KMo,Cp,Ide,ZMo,eEo,ej,oEo,rEo,tEo,wp,Nde,aEo,nEo,oj,sEo,lEo,iEo,Ap,qde,dEo,cEo,rj,mEo,fEo,gEo,Lp,jde,hEo,uEo,tj,pEo,_Eo,bEo,yp,Dde,vEo,FEo,aj,TEo,MEo,EEo,xp,Gde,CEo,wEo,nj,AEo,LEo,yEo,$p,Ode,xEo,$Eo,sj,kEo,SEo,REo,kp,Vde,PEo,BEo,lj,IEo,NEo,qEo,Sp,Xde,jEo,DEo,ij,GEo,OEo,VEo,Rp,zde,XEo,zEo,dj,QEo,WEo,HEo,Pp,Qde,UEo,JEo,cj,YEo,KEo,ZEo,Bp,Wde,e4o,o4o,mj,r4o,t4o,a4o,Ip,Hde,n4o,s4o,fj,l4o,i4o,d4o,Np,Ude,c4o,m4o,gj,f4o,g4o,h4o,qp,Jde,u4o,p4o,hj,_4o,b4o,v4o,jp,Yde,F4o,T4o,uj,M4o,E4o,C4o,Dp,Kde,w4o,A4o,pj,L4o,y4o,x4o,Gp,Zde,$4o,k4o,_j,S4o,R4o,P4o,Op,ece,B4o,I4o,bj,N4o,q4o,j4o,Vp,oce,D4o,G4o,vj,O4o,V4o,X4o,Xp,rce,z4o,Q4o,Fj,W4o,H4o,U4o,zp,tce,J4o,Y4o,Tj,K4o,Z4o,eCo,Qp,ace,oCo,rCo,Mj,tCo,aCo,nCo,Wp,nce,sCo,lCo,Ej,iCo,dCo,cCo,Hp,sce,mCo,fCo,Cj,gCo,hCo,uCo,Up,lce,pCo,_Co,wj,bCo,vCo,FCo,Jp,ice,TCo,MCo,Aj,ECo,CCo,wCo,Yp,dce,ACo,LCo,Lj,yCo,xCo,$Co,Kp,cce,kCo,SCo,yj,RCo,PCo,BCo,Zp,mce,ICo,NCo,xj,qCo,jCo,DCo,e_,fce,GCo,OCo,$j,VCo,XCo,zCo,o_,gce,QCo,WCo,kj,HCo,UCo,JCo,r_,hce,YCo,KCo,Sj,ZCo,e5o,o5o,t_,uce,r5o,t5o,Rj,a5o,n5o,s5o,a_,pce,l5o,i5o,Pj,d5o,c5o,m5o,n_,_ce,f5o,g5o,Bj,h5o,u5o,p5o,s_,bce,_5o,b5o,Ij,v5o,F5o,T5o,l_,vce,M5o,E5o,Nj,C5o,w5o,A5o,i_,Fce,L5o,y5o,qj,x5o,$5o,k5o,d_,Tce,S5o,R5o,jj,P5o,B5o,I5o,c_,Mce,N5o,q5o,Dj,j5o,D5o,G5o,m_,Ece,O5o,V5o,Gj,X5o,z5o,Q5o,f_,Cce,W5o,H5o,Oj,U5o,J5o,Y5o,g_,wce,K5o,Z5o,Vj,e3o,o3o,r3o,h_,Ace,t3o,a3o,Xj,n3o,s3o,l3o,u_,Lce,i3o,d3o,zj,c3o,m3o,f3o,p_,yce,g3o,h3o,Qj,u3o,p3o,_3o,__,xce,b3o,v3o,Wj,F3o,T3o,M3o,b_,$ce,E3o,C3o,Hj,w3o,A3o,L3o,v_,kce,y3o,x3o,Uj,$3o,k3o,S3o,F_,Sce,R3o,P3o,Jj,B3o,I3o,N3o,T_,Rce,q3o,j3o,Yj,D3o,G3o,O3o,M_,Pce,V3o,X3o,Kj,z3o,Q3o,W3o,E_,Bce,H3o,U3o,Zj,J3o,Y3o,K3o,C_,Ice,Z3o,e0o,eD,o0o,r0o,t0o,w_,Nce,a0o,n0o,oD,s0o,l0o,i0o,A_,qce,d0o,c0o,rD,m0o,f0o,g0o,L_,jce,h0o,u0o,tD,p0o,_0o,b0o,y_,v0o,Dce,F0o,T0o,Gce,M0o,E0o,x_,eOe,qi,$_,Oce,s7,C0o,Vce,w0o,oOe,$o,l7,A0o,ji,L0o,aD,y0o,x0o,nD,$0o,k0o,S0o,i7,R0o,Xce,P0o,B0o,I0o,st,d7,N0o,zce,q0o,j0o,Di,D0o,Qce,G0o,O0o,sD,V0o,X0o,z0o,k_,Q0o,Ye,c7,W0o,Wce,H0o,U0o,Pa,J0o,Hce,Y0o,K0o,Uce,Z0o,ewo,Jce,owo,rwo,two,G,S_,Yce,awo,nwo,lD,swo,lwo,iwo,R_,Kce,dwo,cwo,iD,mwo,fwo,gwo,P_,Zce,hwo,uwo,dD,pwo,_wo,bwo,B_,eme,vwo,Fwo,cD,Two,Mwo,Ewo,I_,ome,Cwo,wwo,mD,Awo,Lwo,ywo,N_,rme,xwo,$wo,fD,kwo,Swo,Rwo,q_,tme,Pwo,Bwo,gD,Iwo,Nwo,qwo,j_,ame,jwo,Dwo,hD,Gwo,Owo,Vwo,D_,nme,Xwo,zwo,uD,Qwo,Wwo,Hwo,G_,sme,Uwo,Jwo,pD,Ywo,Kwo,Zwo,O_,lme,eAo,oAo,_D,rAo,tAo,aAo,V_,ime,nAo,sAo,bD,lAo,iAo,dAo,X_,dme,cAo,mAo,vD,fAo,gAo,hAo,z_,cme,uAo,pAo,FD,_Ao,bAo,vAo,Q_,mme,FAo,TAo,TD,MAo,EAo,CAo,W_,fme,wAo,AAo,MD,LAo,yAo,xAo,H_,gme,$Ao,kAo,ED,SAo,RAo,PAo,U_,hme,BAo,IAo,CD,NAo,qAo,jAo,J_,ume,DAo,GAo,wD,OAo,VAo,XAo,Y_,pme,zAo,QAo,AD,WAo,HAo,UAo,K_,_me,JAo,YAo,LD,KAo,ZAo,e6o,Z_,bme,o6o,r6o,yD,t6o,a6o,n6o,e2,vme,s6o,l6o,xD,i6o,d6o,c6o,o2,Fme,m6o,f6o,$D,g6o,h6o,u6o,r2,Tme,p6o,_6o,kD,b6o,v6o,F6o,t2,Mme,T6o,M6o,SD,E6o,C6o,w6o,a2,Eme,A6o,L6o,RD,y6o,x6o,$6o,n2,Cme,k6o,S6o,PD,R6o,P6o,B6o,s2,wme,I6o,N6o,BD,q6o,j6o,D6o,l2,Ame,G6o,O6o,ID,V6o,X6o,z6o,i2,Lme,Q6o,W6o,ND,H6o,U6o,J6o,d2,yme,Y6o,K6o,qD,Z6o,eLo,oLo,c2,xme,rLo,tLo,jD,aLo,nLo,sLo,m2,$me,lLo,iLo,DD,dLo,cLo,mLo,f2,kme,fLo,gLo,GD,hLo,uLo,pLo,g2,Sme,_Lo,bLo,OD,vLo,FLo,TLo,h2,Rme,MLo,ELo,VD,CLo,wLo,ALo,u2,Pme,LLo,yLo,XD,xLo,$Lo,kLo,p2,Bme,SLo,RLo,zD,PLo,BLo,ILo,_2,Ime,NLo,qLo,QD,jLo,DLo,GLo,b2,Nme,OLo,VLo,WD,XLo,zLo,QLo,v2,qme,WLo,HLo,HD,ULo,JLo,YLo,F2,jme,KLo,ZLo,UD,eyo,oyo,ryo,T2,Dme,tyo,ayo,JD,nyo,syo,lyo,M2,iyo,Gme,dyo,cyo,Ome,myo,fyo,E2,rOe,Gi,C2,Vme,m7,gyo,Xme,hyo,tOe,ko,f7,uyo,Oi,pyo,YD,_yo,byo,KD,vyo,Fyo,Tyo,g7,Myo,zme,Eyo,Cyo,wyo,lt,h7,Ayo,Qme,Lyo,yyo,Vi,xyo,Wme,$yo,kyo,ZD,Syo,Ryo,Pyo,w2,Byo,Ke,u7,Iyo,Hme,Nyo,qyo,Ba,jyo,Ume,Dyo,Gyo,Jme,Oyo,Vyo,Yme,Xyo,zyo,Qyo,z,A2,Kme,Wyo,Hyo,eG,Uyo,Jyo,Yyo,L2,Zme,Kyo,Zyo,oG,e7o,o7o,r7o,y2,efe,t7o,a7o,rG,n7o,s7o,l7o,x2,ofe,i7o,d7o,tG,c7o,m7o,f7o,$2,rfe,g7o,h7o,aG,u7o,p7o,_7o,k2,tfe,b7o,v7o,nG,F7o,T7o,M7o,S2,afe,E7o,C7o,sG,w7o,A7o,L7o,R2,nfe,y7o,x7o,lG,$7o,k7o,S7o,P2,sfe,R7o,P7o,iG,B7o,I7o,N7o,B2,lfe,q7o,j7o,dG,D7o,G7o,O7o,I2,ife,V7o,X7o,cG,z7o,Q7o,W7o,N2,dfe,H7o,U7o,mG,J7o,Y7o,K7o,q2,cfe,Z7o,e8o,fG,o8o,r8o,t8o,j2,mfe,a8o,n8o,gG,s8o,l8o,i8o,D2,ffe,d8o,c8o,hG,m8o,f8o,g8o,G2,gfe,h8o,u8o,uG,p8o,_8o,b8o,O2,hfe,v8o,F8o,pG,T8o,M8o,E8o,V2,ufe,C8o,w8o,_G,A8o,L8o,y8o,X2,pfe,x8o,$8o,bG,k8o,S8o,R8o,z2,_fe,P8o,B8o,vG,I8o,N8o,q8o,Q2,bfe,j8o,D8o,FG,G8o,O8o,V8o,W2,vfe,X8o,z8o,TG,Q8o,W8o,H8o,H2,Ffe,U8o,J8o,MG,Y8o,K8o,Z8o,U2,Tfe,e9o,o9o,EG,r9o,t9o,a9o,J2,Mfe,n9o,s9o,CG,l9o,i9o,d9o,Y2,Efe,c9o,m9o,wG,f9o,g9o,h9o,K2,Cfe,u9o,p9o,AG,_9o,b9o,v9o,Z2,wfe,F9o,T9o,LG,M9o,E9o,C9o,eb,Afe,w9o,A9o,yG,L9o,y9o,x9o,ob,Lfe,$9o,k9o,xG,S9o,R9o,P9o,rb,yfe,B9o,I9o,$G,N9o,q9o,j9o,tb,xfe,D9o,G9o,kG,O9o,V9o,X9o,ab,$fe,z9o,Q9o,SG,W9o,H9o,U9o,nb,kfe,J9o,Y9o,RG,K9o,Z9o,exo,sb,Sfe,oxo,rxo,PG,txo,axo,nxo,lb,Rfe,sxo,lxo,BG,ixo,dxo,cxo,ib,Pfe,mxo,fxo,IG,gxo,hxo,uxo,db,Bfe,pxo,_xo,NG,bxo,vxo,Fxo,cb,Txo,Ife,Mxo,Exo,Nfe,Cxo,wxo,mb,aOe,Xi,fb,qfe,p7,Axo,jfe,Lxo,nOe,So,_7,yxo,zi,xxo,qG,$xo,kxo,jG,Sxo,Rxo,Pxo,b7,Bxo,Dfe,Ixo,Nxo,qxo,it,v7,jxo,Gfe,Dxo,Gxo,Qi,Oxo,Ofe,Vxo,Xxo,DG,zxo,Qxo,Wxo,gb,Hxo,Ze,F7,Uxo,Vfe,Jxo,Yxo,Ia,Kxo,Xfe,Zxo,e$o,zfe,o$o,r$o,Qfe,t$o,a$o,n$o,Q,hb,Wfe,s$o,l$o,GG,i$o,d$o,c$o,ub,Hfe,m$o,f$o,OG,g$o,h$o,u$o,pb,Ufe,p$o,_$o,VG,b$o,v$o,F$o,_b,Jfe,T$o,M$o,XG,E$o,C$o,w$o,bb,Yfe,A$o,L$o,zG,y$o,x$o,$$o,vb,Kfe,k$o,S$o,QG,R$o,P$o,B$o,Fb,Zfe,I$o,N$o,WG,q$o,j$o,D$o,Tb,ege,G$o,O$o,HG,V$o,X$o,z$o,Mb,oge,Q$o,W$o,UG,H$o,U$o,J$o,Eb,rge,Y$o,K$o,JG,Z$o,eko,oko,Cb,tge,rko,tko,YG,ako,nko,sko,wb,age,lko,iko,KG,dko,cko,mko,Ab,nge,fko,gko,ZG,hko,uko,pko,Lb,sge,_ko,bko,eO,vko,Fko,Tko,yb,lge,Mko,Eko,oO,Cko,wko,Ako,xb,ige,Lko,yko,rO,xko,$ko,kko,$b,dge,Sko,Rko,tO,Pko,Bko,Iko,kb,cge,Nko,qko,aO,jko,Dko,Gko,Sb,mge,Oko,Vko,nO,Xko,zko,Qko,Rb,fge,Wko,Hko,sO,Uko,Jko,Yko,Pb,gge,Kko,Zko,lO,eSo,oSo,rSo,Bb,hge,tSo,aSo,iO,nSo,sSo,lSo,Ib,uge,iSo,dSo,dO,cSo,mSo,fSo,Nb,pge,gSo,hSo,cO,uSo,pSo,_So,qb,_ge,bSo,vSo,mO,FSo,TSo,MSo,jb,bge,ESo,CSo,fO,wSo,ASo,LSo,Db,vge,ySo,xSo,gO,$So,kSo,SSo,Gb,Fge,RSo,PSo,hO,BSo,ISo,NSo,Ob,Tge,qSo,jSo,uO,DSo,GSo,OSo,Vb,Mge,VSo,XSo,pO,zSo,QSo,WSo,Xb,Ege,HSo,USo,_O,JSo,YSo,KSo,zb,Cge,ZSo,eRo,bO,oRo,rRo,tRo,Qb,wge,aRo,nRo,Age,sRo,lRo,iRo,Wb,Lge,dRo,cRo,vO,mRo,fRo,gRo,Hb,yge,hRo,uRo,FO,pRo,_Ro,bRo,Ub,xge,vRo,FRo,TO,TRo,MRo,ERo,Jb,$ge,CRo,wRo,MO,ARo,LRo,yRo,Yb,xRo,kge,$Ro,kRo,Sge,SRo,RRo,Kb,sOe,Wi,Zb,Rge,T7,PRo,Pge,BRo,lOe,Ro,M7,IRo,Hi,NRo,EO,qRo,jRo,CO,DRo,GRo,ORo,E7,VRo,Bge,XRo,zRo,QRo,dt,C7,WRo,Ige,HRo,URo,Ui,JRo,Nge,YRo,KRo,wO,ZRo,ePo,oPo,ev,rPo,eo,w7,tPo,qge,aPo,nPo,Na,sPo,jge,lPo,iPo,Dge,dPo,cPo,Gge,mPo,fPo,gPo,ue,ov,Oge,hPo,uPo,AO,pPo,_Po,bPo,rv,Vge,vPo,FPo,LO,TPo,MPo,EPo,tv,Xge,CPo,wPo,yO,APo,LPo,yPo,av,zge,xPo,$Po,xO,kPo,SPo,RPo,nv,Qge,PPo,BPo,$O,IPo,NPo,qPo,sv,Wge,jPo,DPo,kO,GPo,OPo,VPo,lv,Hge,XPo,zPo,SO,QPo,WPo,HPo,iv,Uge,UPo,JPo,RO,YPo,KPo,ZPo,dv,Jge,eBo,oBo,PO,rBo,tBo,aBo,cv,Yge,nBo,sBo,BO,lBo,iBo,dBo,mv,Kge,cBo,mBo,IO,fBo,gBo,hBo,fv,Zge,uBo,pBo,NO,_Bo,bBo,vBo,gv,ehe,FBo,TBo,qO,MBo,EBo,CBo,hv,ohe,wBo,ABo,jO,LBo,yBo,xBo,uv,rhe,$Bo,kBo,DO,SBo,RBo,PBo,pv,the,BBo,IBo,GO,NBo,qBo,jBo,_v,ahe,DBo,GBo,OO,OBo,VBo,XBo,bv,zBo,nhe,QBo,WBo,she,HBo,UBo,vv,iOe,Ji,Fv,lhe,A7,JBo,ihe,YBo,dOe,Po,L7,KBo,Yi,ZBo,VO,eIo,oIo,XO,rIo,tIo,aIo,y7,nIo,dhe,sIo,lIo,iIo,ct,x7,dIo,che,cIo,mIo,Ki,fIo,mhe,gIo,hIo,zO,uIo,pIo,_Io,Tv,bIo,oo,$7,vIo,fhe,FIo,TIo,qa,MIo,ghe,EIo,CIo,hhe,wIo,AIo,uhe,LIo,yIo,xIo,N,Mv,phe,$Io,kIo,QO,SIo,RIo,PIo,Ev,_he,BIo,IIo,WO,NIo,qIo,jIo,Cv,bhe,DIo,GIo,HO,OIo,VIo,XIo,wv,vhe,zIo,QIo,UO,WIo,HIo,UIo,Av,Fhe,JIo,YIo,JO,KIo,ZIo,eNo,Lv,The,oNo,rNo,YO,tNo,aNo,nNo,yv,Mhe,sNo,lNo,KO,iNo,dNo,cNo,xv,Ehe,mNo,fNo,ZO,gNo,hNo,uNo,$v,Che,pNo,_No,eV,bNo,vNo,FNo,kv,whe,TNo,MNo,oV,ENo,CNo,wNo,Sv,Ahe,ANo,LNo,rV,yNo,xNo,$No,Rv,Lhe,kNo,SNo,tV,RNo,PNo,BNo,Pv,yhe,INo,NNo,aV,qNo,jNo,DNo,Bv,xhe,GNo,ONo,nV,VNo,XNo,zNo,Iv,$he,QNo,WNo,sV,HNo,UNo,JNo,Nv,khe,YNo,KNo,lV,ZNo,eqo,oqo,qv,She,rqo,tqo,iV,aqo,nqo,sqo,jv,Rhe,lqo,iqo,dV,dqo,cqo,mqo,Dv,Phe,fqo,gqo,cV,hqo,uqo,pqo,Gv,Bhe,_qo,bqo,mV,vqo,Fqo,Tqo,Ov,Ihe,Mqo,Eqo,fV,Cqo,wqo,Aqo,Vv,Nhe,Lqo,yqo,gV,xqo,$qo,kqo,Xv,qhe,Sqo,Rqo,hV,Pqo,Bqo,Iqo,zv,jhe,Nqo,qqo,uV,jqo,Dqo,Gqo,Qv,Dhe,Oqo,Vqo,pV,Xqo,zqo,Qqo,Wv,Ghe,Wqo,Hqo,_V,Uqo,Jqo,Yqo,Hv,Ohe,Kqo,Zqo,bV,ejo,ojo,rjo,Uv,Vhe,tjo,ajo,vV,njo,sjo,ljo,Jv,Xhe,ijo,djo,FV,cjo,mjo,fjo,Yv,zhe,gjo,hjo,TV,ujo,pjo,_jo,Kv,Qhe,bjo,vjo,MV,Fjo,Tjo,Mjo,Zv,Whe,Ejo,Cjo,EV,wjo,Ajo,Ljo,eF,Hhe,yjo,xjo,CV,$jo,kjo,Sjo,oF,Uhe,Rjo,Pjo,wV,Bjo,Ijo,Njo,rF,Jhe,qjo,jjo,AV,Djo,Gjo,Ojo,tF,Yhe,Vjo,Xjo,LV,zjo,Qjo,Wjo,aF,Khe,Hjo,Ujo,yV,Jjo,Yjo,Kjo,nF,Zhe,Zjo,eDo,xV,oDo,rDo,tDo,sF,eue,aDo,nDo,$V,sDo,lDo,iDo,lF,oue,dDo,cDo,kV,mDo,fDo,gDo,iF,rue,hDo,uDo,SV,pDo,_Do,bDo,dF,tue,vDo,FDo,RV,TDo,MDo,EDo,cF,aue,CDo,wDo,PV,ADo,LDo,yDo,mF,nue,xDo,$Do,BV,kDo,SDo,RDo,fF,sue,PDo,BDo,IV,IDo,NDo,qDo,gF,lue,jDo,DDo,NV,GDo,ODo,VDo,hF,iue,XDo,zDo,qV,QDo,WDo,HDo,uF,due,UDo,JDo,jV,YDo,KDo,ZDo,pF,cue,eGo,oGo,DV,rGo,tGo,aGo,_F,nGo,mue,sGo,lGo,fue,iGo,dGo,bF,cOe,Zi,vF,gue,k7,cGo,hue,mGo,mOe,Bo,S7,fGo,ed,gGo,GV,hGo,uGo,OV,pGo,_Go,bGo,R7,vGo,uue,FGo,TGo,MGo,mt,P7,EGo,pue,CGo,wGo,od,AGo,_ue,LGo,yGo,VV,xGo,$Go,kGo,FF,SGo,ro,B7,RGo,bue,PGo,BGo,ja,IGo,vue,NGo,qGo,Fue,jGo,DGo,Tue,GGo,OGo,VGo,Z,TF,Mue,XGo,zGo,XV,QGo,WGo,HGo,MF,Eue,UGo,JGo,zV,YGo,KGo,ZGo,EF,Cue,eOo,oOo,QV,rOo,tOo,aOo,CF,wue,nOo,sOo,WV,lOo,iOo,dOo,wF,Aue,cOo,mOo,HV,fOo,gOo,hOo,AF,Lue,uOo,pOo,UV,_Oo,bOo,vOo,LF,yue,FOo,TOo,JV,MOo,EOo,COo,yF,xue,wOo,AOo,YV,LOo,yOo,xOo,xF,$ue,$Oo,kOo,KV,SOo,ROo,POo,$F,kue,BOo,IOo,ZV,NOo,qOo,jOo,kF,Sue,DOo,GOo,eX,OOo,VOo,XOo,SF,Rue,zOo,QOo,oX,WOo,HOo,UOo,RF,Pue,JOo,YOo,rX,KOo,ZOo,eVo,PF,Bue,oVo,rVo,tX,tVo,aVo,nVo,BF,Iue,sVo,lVo,aX,iVo,dVo,cVo,IF,Nue,mVo,fVo,nX,gVo,hVo,uVo,NF,que,pVo,_Vo,sX,bVo,vVo,FVo,qF,jue,TVo,MVo,lX,EVo,CVo,wVo,jF,Due,AVo,LVo,iX,yVo,xVo,$Vo,DF,Gue,kVo,SVo,dX,RVo,PVo,BVo,GF,Oue,IVo,NVo,cX,qVo,jVo,DVo,OF,Vue,GVo,OVo,mX,VVo,XVo,zVo,VF,Xue,QVo,WVo,fX,HVo,UVo,JVo,XF,zue,YVo,KVo,gX,ZVo,eXo,oXo,zF,Que,rXo,tXo,hX,aXo,nXo,sXo,QF,Wue,lXo,iXo,uX,dXo,cXo,mXo,WF,Hue,fXo,gXo,pX,hXo,uXo,pXo,HF,Uue,_Xo,bXo,_X,vXo,FXo,TXo,UF,Jue,MXo,EXo,bX,CXo,wXo,AXo,JF,Yue,LXo,yXo,vX,xXo,$Xo,kXo,YF,SXo,Kue,RXo,PXo,Zue,BXo,IXo,KF,fOe,rd,ZF,epe,I7,NXo,ope,qXo,gOe,Io,N7,jXo,td,DXo,FX,GXo,OXo,TX,VXo,XXo,zXo,q7,QXo,rpe,WXo,HXo,UXo,ft,j7,JXo,tpe,YXo,KXo,ad,ZXo,ape,ezo,ozo,MX,rzo,tzo,azo,e1,nzo,to,D7,szo,npe,lzo,izo,Da,dzo,spe,czo,mzo,lpe,fzo,gzo,ipe,hzo,uzo,pzo,No,o1,dpe,_zo,bzo,EX,vzo,Fzo,Tzo,r1,cpe,Mzo,Ezo,CX,Czo,wzo,Azo,t1,mpe,Lzo,yzo,wX,xzo,$zo,kzo,a1,fpe,Szo,Rzo,AX,Pzo,Bzo,Izo,n1,gpe,Nzo,qzo,LX,jzo,Dzo,Gzo,s1,hpe,Ozo,Vzo,yX,Xzo,zzo,Qzo,l1,Wzo,upe,Hzo,Uzo,ppe,Jzo,Yzo,i1,hOe,nd,d1,_pe,G7,Kzo,bpe,Zzo,uOe,qo,O7,eQo,sd,oQo,xX,rQo,tQo,$X,aQo,nQo,sQo,V7,lQo,vpe,iQo,dQo,cQo,gt,X7,mQo,Fpe,fQo,gQo,ld,hQo,Tpe,uQo,pQo,kX,_Qo,bQo,vQo,c1,FQo,ao,z7,TQo,Mpe,MQo,EQo,Ga,CQo,Epe,wQo,AQo,Cpe,LQo,yQo,wpe,xQo,$Qo,kQo,H,m1,Ape,SQo,RQo,SX,PQo,BQo,IQo,f1,Lpe,NQo,qQo,RX,jQo,DQo,GQo,g1,ype,OQo,VQo,PX,XQo,zQo,QQo,h1,xpe,WQo,HQo,BX,UQo,JQo,YQo,u1,$pe,KQo,ZQo,IX,eWo,oWo,rWo,p1,kpe,tWo,aWo,NX,nWo,sWo,lWo,_1,Spe,iWo,dWo,qX,cWo,mWo,fWo,b1,Rpe,gWo,hWo,jX,uWo,pWo,_Wo,v1,Ppe,bWo,vWo,DX,FWo,TWo,MWo,F1,Bpe,EWo,CWo,GX,wWo,AWo,LWo,T1,Ipe,yWo,xWo,OX,$Wo,kWo,SWo,M1,Npe,RWo,PWo,VX,BWo,IWo,NWo,E1,qpe,qWo,jWo,XX,DWo,GWo,OWo,C1,jpe,VWo,XWo,zX,zWo,QWo,WWo,w1,Dpe,HWo,UWo,QX,JWo,YWo,KWo,A1,Gpe,ZWo,eHo,WX,oHo,rHo,tHo,L1,Ope,aHo,nHo,HX,sHo,lHo,iHo,y1,Vpe,dHo,cHo,UX,mHo,fHo,gHo,x1,Xpe,hHo,uHo,JX,pHo,_Ho,bHo,$1,zpe,vHo,FHo,YX,THo,MHo,EHo,k1,Qpe,CHo,wHo,KX,AHo,LHo,yHo,S1,Wpe,xHo,$Ho,ZX,kHo,SHo,RHo,R1,Hpe,PHo,BHo,ez,IHo,NHo,qHo,P1,Upe,jHo,DHo,oz,GHo,OHo,VHo,B1,Jpe,XHo,zHo,rz,QHo,WHo,HHo,I1,Ype,UHo,JHo,tz,YHo,KHo,ZHo,N1,Kpe,eUo,oUo,az,rUo,tUo,aUo,q1,Zpe,nUo,sUo,nz,lUo,iUo,dUo,j1,e_e,cUo,mUo,sz,fUo,gUo,hUo,D1,o_e,uUo,pUo,lz,_Uo,bUo,vUo,G1,r_e,FUo,TUo,iz,MUo,EUo,CUo,O1,t_e,wUo,AUo,dz,LUo,yUo,xUo,V1,a_e,$Uo,kUo,cz,SUo,RUo,PUo,X1,n_e,BUo,IUo,mz,NUo,qUo,jUo,z1,s_e,DUo,GUo,fz,OUo,VUo,XUo,Q1,l_e,zUo,QUo,gz,WUo,HUo,UUo,W1,JUo,i_e,YUo,KUo,d_e,ZUo,eJo,H1,pOe,id,U1,c_e,Q7,oJo,m_e,rJo,_Oe,jo,W7,tJo,dd,aJo,hz,nJo,sJo,uz,lJo,iJo,dJo,H7,cJo,f_e,mJo,fJo,gJo,ht,U7,hJo,g_e,uJo,pJo,cd,_Jo,h_e,bJo,vJo,pz,FJo,TJo,MJo,J1,EJo,no,J7,CJo,u_e,wJo,AJo,Oa,LJo,p_e,yJo,xJo,__e,$Jo,kJo,b_e,SJo,RJo,PJo,V,Y1,v_e,BJo,IJo,_z,NJo,qJo,jJo,K1,F_e,DJo,GJo,bz,OJo,VJo,XJo,Z1,T_e,zJo,QJo,vz,WJo,HJo,UJo,eT,M_e,JJo,YJo,Fz,KJo,ZJo,eYo,oT,E_e,oYo,rYo,Tz,tYo,aYo,nYo,rT,C_e,sYo,lYo,Mz,iYo,dYo,cYo,tT,w_e,mYo,fYo,Ez,gYo,hYo,uYo,aT,A_e,pYo,_Yo,Cz,bYo,vYo,FYo,nT,L_e,TYo,MYo,wz,EYo,CYo,wYo,sT,y_e,AYo,LYo,Az,yYo,xYo,$Yo,lT,x_e,kYo,SYo,Lz,RYo,PYo,BYo,iT,$_e,IYo,NYo,yz,qYo,jYo,DYo,dT,k_e,GYo,OYo,xz,VYo,XYo,zYo,cT,S_e,QYo,WYo,$z,HYo,UYo,JYo,mT,R_e,YYo,KYo,kz,ZYo,eKo,oKo,fT,P_e,rKo,tKo,Sz,aKo,nKo,sKo,gT,B_e,lKo,iKo,Rz,dKo,cKo,mKo,hT,I_e,fKo,gKo,Pz,hKo,uKo,pKo,uT,N_e,_Ko,bKo,Bz,vKo,FKo,TKo,pT,q_e,MKo,EKo,Iz,CKo,wKo,AKo,_T,j_e,LKo,yKo,Nz,xKo,$Ko,kKo,bT,D_e,SKo,RKo,qz,PKo,BKo,IKo,vT,G_e,NKo,qKo,jz,jKo,DKo,GKo,FT,O_e,OKo,VKo,Dz,XKo,zKo,QKo,TT,V_e,WKo,HKo,Gz,UKo,JKo,YKo,MT,X_e,KKo,ZKo,Oz,eZo,oZo,rZo,ET,z_e,tZo,aZo,Vz,nZo,sZo,lZo,CT,Q_e,iZo,dZo,Xz,cZo,mZo,fZo,wT,W_e,gZo,hZo,zz,uZo,pZo,_Zo,AT,H_e,bZo,vZo,Qz,FZo,TZo,MZo,LT,U_e,EZo,CZo,Wz,wZo,AZo,LZo,yT,J_e,yZo,xZo,Hz,$Zo,kZo,SZo,xT,Y_e,RZo,PZo,Uz,BZo,IZo,NZo,$T,K_e,qZo,jZo,Jz,DZo,GZo,OZo,kT,Z_e,VZo,XZo,Yz,zZo,QZo,WZo,ST,e2e,HZo,UZo,Kz,JZo,YZo,KZo,RT,o2e,ZZo,eer,Zz,oer,rer,ter,PT,r2e,aer,ner,eQ,ser,ler,ier,BT,t2e,der,cer,oQ,mer,fer,ger,IT,a2e,her,uer,rQ,per,_er,ber,NT,n2e,ver,Fer,tQ,Ter,Mer,Eer,qT,Cer,s2e,wer,Aer,l2e,Ler,yer,jT,bOe,md,DT,i2e,Y7,xer,d2e,$er,vOe,Do,K7,ker,fd,Ser,aQ,Rer,Per,nQ,Ber,Ier,Ner,Z7,qer,c2e,jer,Der,Ger,ut,e8,Oer,m2e,Ver,Xer,gd,zer,f2e,Qer,Wer,sQ,Her,Uer,Jer,GT,Yer,so,o8,Ker,g2e,Zer,eor,Va,oor,h2e,ror,tor,u2e,aor,nor,p2e,sor,lor,ior,_2e,OT,b2e,dor,cor,lQ,mor,gor,hor,VT,uor,v2e,por,_or,F2e,bor,vor,XT,FOe,hd,zT,T2e,r8,For,M2e,Tor,TOe,Go,t8,Mor,ud,Eor,iQ,Cor,wor,dQ,Aor,Lor,yor,a8,xor,E2e,$or,kor,Sor,pt,n8,Ror,C2e,Por,Bor,pd,Ior,w2e,Nor,qor,cQ,jor,Dor,Gor,QT,Oor,lo,s8,Vor,A2e,Xor,zor,Xa,Qor,L2e,Wor,Hor,y2e,Uor,Jor,x2e,Yor,Kor,Zor,Fe,WT,$2e,err,orr,mQ,rrr,trr,arr,HT,k2e,nrr,srr,fQ,lrr,irr,drr,UT,S2e,crr,mrr,gQ,frr,grr,hrr,JT,R2e,urr,prr,hQ,_rr,brr,vrr,Xs,P2e,Frr,Trr,uQ,Mrr,Err,pQ,Crr,wrr,Arr,YT,B2e,Lrr,yrr,_Q,xrr,$rr,krr,zs,I2e,Srr,Rrr,bQ,Prr,Brr,vQ,Irr,Nrr,qrr,_t,N2e,jrr,Drr,FQ,Grr,Orr,TQ,Vrr,Xrr,MQ,zrr,Qrr,Wrr,KT,q2e,Hrr,Urr,EQ,Jrr,Yrr,Krr,ZT,j2e,Zrr,etr,CQ,otr,rtr,ttr,eM,D2e,atr,ntr,wQ,str,ltr,itr,oM,G2e,dtr,ctr,AQ,mtr,ftr,gtr,rM,O2e,htr,utr,LQ,ptr,_tr,btr,tM,V2e,vtr,Ftr,yQ,Ttr,Mtr,Etr,aM,X2e,Ctr,wtr,xQ,Atr,Ltr,ytr,nM,xtr,z2e,$tr,ktr,Q2e,Str,Rtr,sM,MOe,_d,lM,W2e,l8,Ptr,H2e,Btr,EOe,Oo,i8,Itr,bd,Ntr,$Q,qtr,jtr,kQ,Dtr,Gtr,Otr,d8,Vtr,U2e,Xtr,ztr,Qtr,bt,c8,Wtr,J2e,Htr,Utr,vd,Jtr,Y2e,Ytr,Ktr,SQ,Ztr,ear,oar,iM,rar,io,m8,tar,K2e,aar,nar,za,sar,Z2e,lar,iar,ebe,dar,car,obe,mar,far,gar,rbe,dM,tbe,har,uar,RQ,par,_ar,bar,cM,Far,abe,Tar,Mar,nbe,Ear,Car,mM,COe,Fd,fM,sbe,f8,war,lbe,Aar,wOe,Vo,g8,Lar,Td,yar,PQ,xar,$ar,BQ,kar,Sar,Rar,h8,Par,ibe,Bar,Iar,Nar,vt,u8,qar,dbe,jar,Dar,Md,Gar,cbe,Oar,Var,IQ,Xar,zar,Qar,gM,War,co,p8,Har,mbe,Uar,Jar,Qa,Yar,fbe,Kar,Zar,gbe,enr,onr,hbe,rnr,tnr,anr,ube,hM,pbe,nnr,snr,NQ,lnr,inr,dnr,uM,cnr,_be,mnr,fnr,bbe,gnr,hnr,pM,AOe,Ed,_M,vbe,_8,unr,Fbe,pnr,LOe,Xo,b8,_nr,Cd,bnr,qQ,vnr,Fnr,jQ,Tnr,Mnr,Enr,v8,Cnr,Tbe,wnr,Anr,Lnr,Ft,F8,ynr,Mbe,xnr,$nr,wd,knr,Ebe,Snr,Rnr,DQ,Pnr,Bnr,Inr,bM,Nnr,mo,T8,qnr,Cbe,jnr,Dnr,Wa,Gnr,wbe,Onr,Vnr,Abe,Xnr,znr,Lbe,Qnr,Wnr,Hnr,Pe,vM,ybe,Unr,Jnr,GQ,Ynr,Knr,Znr,FM,xbe,esr,osr,OQ,rsr,tsr,asr,TM,$be,nsr,ssr,VQ,lsr,isr,dsr,MM,kbe,csr,msr,XQ,fsr,gsr,hsr,EM,Sbe,usr,psr,zQ,_sr,bsr,vsr,CM,Rbe,Fsr,Tsr,QQ,Msr,Esr,Csr,wM,Pbe,wsr,Asr,WQ,Lsr,ysr,xsr,AM,Bbe,$sr,ksr,HQ,Ssr,Rsr,Psr,LM,Ibe,Bsr,Isr,UQ,Nsr,qsr,jsr,yM,Dsr,Nbe,Gsr,Osr,qbe,Vsr,Xsr,xM,yOe,Ad,$M,jbe,M8,zsr,Dbe,Qsr,xOe,zo,E8,Wsr,Ld,Hsr,JQ,Usr,Jsr,YQ,Ysr,Ksr,Zsr,C8,elr,Gbe,olr,rlr,tlr,Tt,w8,alr,Obe,nlr,slr,yd,llr,Vbe,ilr,dlr,KQ,clr,mlr,flr,kM,glr,fo,A8,hlr,Xbe,ulr,plr,Ha,_lr,zbe,blr,vlr,Qbe,Flr,Tlr,Wbe,Mlr,Elr,Clr,et,SM,Hbe,wlr,Alr,ZQ,Llr,ylr,xlr,RM,Ube,$lr,klr,eW,Slr,Rlr,Plr,PM,Jbe,Blr,Ilr,oW,Nlr,qlr,jlr,BM,Ybe,Dlr,Glr,rW,Olr,Vlr,Xlr,IM,Kbe,zlr,Qlr,tW,Wlr,Hlr,Ulr,NM,Jlr,Zbe,Ylr,Klr,eve,Zlr,eir,qM,$Oe,xd,jM,ove,L8,oir,rve,rir,kOe,Qo,y8,tir,$d,air,aW,nir,sir,nW,lir,iir,dir,x8,cir,tve,mir,fir,gir,Mt,$8,hir,ave,uir,pir,kd,_ir,nve,bir,vir,sW,Fir,Tir,Mir,DM,Eir,go,k8,Cir,sve,wir,Air,Ua,Lir,lve,yir,xir,ive,$ir,kir,dve,Sir,Rir,Pir,Le,GM,cve,Bir,Iir,lW,Nir,qir,jir,OM,mve,Dir,Gir,iW,Oir,Vir,Xir,VM,fve,zir,Qir,dW,Wir,Hir,Uir,XM,gve,Jir,Yir,cW,Kir,Zir,edr,zM,hve,odr,rdr,mW,tdr,adr,ndr,QM,uve,sdr,ldr,fW,idr,ddr,cdr,WM,pve,mdr,fdr,gW,gdr,hdr,udr,HM,_ve,pdr,_dr,hW,bdr,vdr,Fdr,UM,bve,Tdr,Mdr,uW,Edr,Cdr,wdr,JM,vve,Adr,Ldr,pW,ydr,xdr,$dr,YM,kdr,Fve,Sdr,Rdr,Tve,Pdr,Bdr,KM,SOe,Sd,ZM,Mve,S8,Idr,Eve,Ndr,ROe,Wo,R8,qdr,Rd,jdr,_W,Ddr,Gdr,bW,Odr,Vdr,Xdr,P8,zdr,Cve,Qdr,Wdr,Hdr,Et,B8,Udr,wve,Jdr,Ydr,Pd,Kdr,Ave,Zdr,ecr,vW,ocr,rcr,tcr,eE,acr,ho,I8,ncr,Lve,scr,lcr,Ja,icr,yve,dcr,ccr,xve,mcr,fcr,$ve,gcr,hcr,ucr,N8,oE,kve,pcr,_cr,FW,bcr,vcr,Fcr,rE,Sve,Tcr,Mcr,TW,Ecr,Ccr,wcr,tE,Acr,Rve,Lcr,ycr,Pve,xcr,$cr,aE,POe,Bd,nE,Bve,q8,kcr,Ive,Scr,BOe,Ho,j8,Rcr,Id,Pcr,MW,Bcr,Icr,EW,Ncr,qcr,jcr,D8,Dcr,Nve,Gcr,Ocr,Vcr,Ct,G8,Xcr,qve,zcr,Qcr,Nd,Wcr,jve,Hcr,Ucr,CW,Jcr,Ycr,Kcr,sE,Zcr,uo,O8,emr,Dve,omr,rmr,Ya,tmr,Gve,amr,nmr,Ove,smr,lmr,Vve,imr,dmr,cmr,ot,lE,Xve,mmr,fmr,wW,gmr,hmr,umr,iE,zve,pmr,_mr,AW,bmr,vmr,Fmr,dE,Qve,Tmr,Mmr,LW,Emr,Cmr,wmr,cE,Wve,Amr,Lmr,yW,ymr,xmr,$mr,mE,Hve,kmr,Smr,xW,Rmr,Pmr,Bmr,fE,Imr,Uve,Nmr,qmr,Jve,jmr,Dmr,gE,IOe,qd,hE,Yve,V8,Gmr,Kve,Omr,NOe,Uo,X8,Vmr,jd,Xmr,$W,zmr,Qmr,kW,Wmr,Hmr,Umr,z8,Jmr,Zve,Ymr,Kmr,Zmr,wt,Q8,efr,eFe,ofr,rfr,Dd,tfr,oFe,afr,nfr,SW,sfr,lfr,ifr,uE,dfr,po,W8,cfr,rFe,mfr,ffr,Ka,gfr,tFe,hfr,ufr,aFe,pfr,_fr,nFe,bfr,vfr,Ffr,Gd,pE,sFe,Tfr,Mfr,RW,Efr,Cfr,wfr,_E,lFe,Afr,Lfr,PW,yfr,xfr,$fr,bE,iFe,kfr,Sfr,BW,Rfr,Pfr,Bfr,vE,Ifr,dFe,Nfr,qfr,cFe,jfr,Dfr,FE,qOe,Od,TE,mFe,H8,Gfr,fFe,Ofr,jOe,Jo,U8,Vfr,Vd,Xfr,IW,zfr,Qfr,NW,Wfr,Hfr,Ufr,J8,Jfr,gFe,Yfr,Kfr,Zfr,At,Y8,egr,hFe,ogr,rgr,Xd,tgr,uFe,agr,ngr,qW,sgr,lgr,igr,ME,dgr,_o,K8,cgr,pFe,mgr,fgr,Za,ggr,_Fe,hgr,ugr,bFe,pgr,_gr,vFe,bgr,vgr,Fgr,Z8,EE,FFe,Tgr,Mgr,jW,Egr,Cgr,wgr,CE,TFe,Agr,Lgr,DW,ygr,xgr,$gr,wE,kgr,MFe,Sgr,Rgr,EFe,Pgr,Bgr,AE,DOe,zd,LE,CFe,e9,Igr,wFe,Ngr,GOe,Yo,o9,qgr,Qd,jgr,GW,Dgr,Ggr,OW,Ogr,Vgr,Xgr,r9,zgr,AFe,Qgr,Wgr,Hgr,Lt,t9,Ugr,LFe,Jgr,Ygr,Wd,Kgr,yFe,Zgr,ehr,VW,ohr,rhr,thr,yE,ahr,bo,a9,nhr,xFe,shr,lhr,en,ihr,$Fe,dhr,chr,kFe,mhr,fhr,SFe,ghr,hhr,uhr,RFe,xE,PFe,phr,_hr,XW,bhr,vhr,Fhr,$E,Thr,BFe,Mhr,Ehr,IFe,Chr,whr,kE,OOe,Hd,SE,NFe,n9,Ahr,qFe,Lhr,VOe,Ko,s9,yhr,Ud,xhr,zW,$hr,khr,QW,Shr,Rhr,Phr,l9,Bhr,jFe,Ihr,Nhr,qhr,yt,i9,jhr,DFe,Dhr,Ghr,Jd,Ohr,GFe,Vhr,Xhr,WW,zhr,Qhr,Whr,RE,Hhr,vo,d9,Uhr,OFe,Jhr,Yhr,on,Khr,VFe,Zhr,eur,XFe,our,rur,zFe,tur,aur,nur,rn,PE,QFe,sur,lur,HW,iur,dur,cur,BE,WFe,mur,fur,UW,gur,hur,uur,IE,HFe,pur,_ur,JW,bur,vur,Fur,NE,UFe,Tur,Mur,YW,Eur,Cur,wur,qE,Aur,JFe,Lur,yur,YFe,xur,$ur,jE,XOe,Yd,DE,KFe,c9,kur,ZFe,Sur,zOe,Zo,m9,Rur,Kd,Pur,KW,Bur,Iur,ZW,Nur,qur,jur,f9,Dur,e1e,Gur,Our,Vur,xt,g9,Xur,o1e,zur,Qur,Zd,Wur,r1e,Hur,Uur,eH,Jur,Yur,Kur,GE,Zur,Fo,h9,epr,t1e,opr,rpr,tn,tpr,a1e,apr,npr,n1e,spr,lpr,s1e,ipr,dpr,cpr,l1e,OE,i1e,mpr,fpr,oH,gpr,hpr,upr,VE,ppr,d1e,_pr,bpr,c1e,vpr,Fpr,XE,QOe,ec,zE,m1e,u9,Tpr,f1e,Mpr,WOe,er,p9,Epr,oc,Cpr,rH,wpr,Apr,tH,Lpr,ypr,xpr,_9,$pr,g1e,kpr,Spr,Rpr,$t,b9,Ppr,h1e,Bpr,Ipr,rc,Npr,u1e,qpr,jpr,aH,Dpr,Gpr,Opr,QE,Vpr,yr,v9,Xpr,p1e,zpr,Qpr,an,Wpr,_1e,Hpr,Upr,b1e,Jpr,Ypr,v1e,Kpr,Zpr,e_r,j,WE,F1e,o_r,r_r,nH,t_r,a_r,n_r,HE,T1e,s_r,l_r,sH,i_r,d_r,c_r,UE,M1e,m_r,f_r,lH,g_r,h_r,u_r,JE,E1e,p_r,__r,iH,b_r,v_r,F_r,YE,C1e,T_r,M_r,dH,E_r,C_r,w_r,KE,w1e,A_r,L_r,cH,y_r,x_r,$_r,ZE,A1e,k_r,S_r,mH,R_r,P_r,B_r,e4,L1e,I_r,N_r,fH,q_r,j_r,D_r,o4,y1e,G_r,O_r,gH,V_r,X_r,z_r,r4,x1e,Q_r,W_r,hH,H_r,U_r,J_r,t4,$1e,Y_r,K_r,uH,Z_r,e2r,o2r,a4,k1e,r2r,t2r,pH,a2r,n2r,s2r,n4,S1e,l2r,i2r,_H,d2r,c2r,m2r,s4,R1e,f2r,g2r,bH,h2r,u2r,p2r,l4,P1e,_2r,b2r,vH,v2r,F2r,T2r,i4,B1e,M2r,E2r,FH,C2r,w2r,A2r,d4,I1e,L2r,y2r,TH,x2r,$2r,k2r,Qs,N1e,S2r,R2r,MH,P2r,B2r,EH,I2r,N2r,q2r,c4,q1e,j2r,D2r,CH,G2r,O2r,V2r,m4,j1e,X2r,z2r,wH,Q2r,W2r,H2r,f4,D1e,U2r,J2r,AH,Y2r,K2r,Z2r,g4,G1e,ebr,obr,LH,rbr,tbr,abr,h4,O1e,nbr,sbr,yH,lbr,ibr,dbr,u4,V1e,cbr,mbr,xH,fbr,gbr,hbr,p4,X1e,ubr,pbr,$H,_br,bbr,vbr,_4,z1e,Fbr,Tbr,kH,Mbr,Ebr,Cbr,b4,Q1e,wbr,Abr,SH,Lbr,ybr,xbr,v4,W1e,$br,kbr,RH,Sbr,Rbr,Pbr,F4,H1e,Bbr,Ibr,PH,Nbr,qbr,jbr,T4,U1e,Dbr,Gbr,BH,Obr,Vbr,Xbr,M4,J1e,zbr,Qbr,IH,Wbr,Hbr,Ubr,E4,Y1e,Jbr,Ybr,NH,Kbr,Zbr,evr,C4,K1e,ovr,rvr,qH,tvr,avr,nvr,w4,Z1e,svr,lvr,jH,ivr,dvr,cvr,A4,eTe,mvr,fvr,DH,gvr,hvr,uvr,L4,oTe,pvr,_vr,GH,bvr,vvr,Fvr,y4,rTe,Tvr,Mvr,OH,Evr,Cvr,wvr,x4,tTe,Avr,Lvr,VH,yvr,xvr,$vr,$4,aTe,kvr,Svr,XH,Rvr,Pvr,Bvr,k4,nTe,Ivr,Nvr,zH,qvr,jvr,Dvr,S4,sTe,Gvr,Ovr,QH,Vvr,Xvr,zvr,R4,lTe,Qvr,Wvr,WH,Hvr,Uvr,Jvr,P4,iTe,Yvr,Kvr,HH,Zvr,eFr,oFr,B4,dTe,rFr,tFr,UH,aFr,nFr,sFr,I4,cTe,lFr,iFr,JH,dFr,cFr,mFr,N4,mTe,fFr,gFr,YH,hFr,uFr,pFr,q4,fTe,_Fr,bFr,KH,vFr,FFr,TFr,j4,HOe,tc,D4,gTe,F9,MFr,hTe,EFr,UOe,or,T9,CFr,ac,wFr,ZH,AFr,LFr,eU,yFr,xFr,$Fr,M9,kFr,uTe,SFr,RFr,PFr,kt,E9,BFr,pTe,IFr,NFr,nc,qFr,_Te,jFr,DFr,oU,GFr,OFr,VFr,G4,XFr,xr,C9,zFr,bTe,QFr,WFr,nn,HFr,vTe,UFr,JFr,FTe,YFr,KFr,TTe,ZFr,e1r,o1r,se,O4,MTe,r1r,t1r,rU,a1r,n1r,s1r,V4,ETe,l1r,i1r,tU,d1r,c1r,m1r,X4,CTe,f1r,g1r,aU,h1r,u1r,p1r,z4,wTe,_1r,b1r,nU,v1r,F1r,T1r,Q4,ATe,M1r,E1r,sU,C1r,w1r,A1r,W4,LTe,L1r,y1r,lU,x1r,$1r,k1r,H4,yTe,S1r,R1r,iU,P1r,B1r,I1r,U4,xTe,N1r,q1r,dU,j1r,D1r,G1r,J4,$Te,O1r,V1r,cU,X1r,z1r,Q1r,Y4,kTe,W1r,H1r,mU,U1r,J1r,Y1r,K4,STe,K1r,Z1r,fU,eTr,oTr,rTr,Z4,RTe,tTr,aTr,gU,nTr,sTr,lTr,eC,PTe,iTr,dTr,hU,cTr,mTr,fTr,oC,BTe,gTr,hTr,uU,uTr,pTr,_Tr,rC,ITe,bTr,vTr,pU,FTr,TTr,MTr,tC,NTe,ETr,CTr,_U,wTr,ATr,LTr,aC,qTe,yTr,xTr,bU,$Tr,kTr,STr,nC,jTe,RTr,PTr,vU,BTr,ITr,NTr,sC,DTe,qTr,jTr,FU,DTr,GTr,OTr,lC,GTe,VTr,XTr,TU,zTr,QTr,WTr,iC,OTe,HTr,UTr,MU,JTr,YTr,KTr,dC,VTe,ZTr,eMr,EU,oMr,rMr,tMr,cC,XTe,aMr,nMr,CU,sMr,lMr,iMr,mC,JOe,sc,fC,zTe,w9,dMr,QTe,cMr,YOe,rr,A9,mMr,lc,fMr,wU,gMr,hMr,AU,uMr,pMr,_Mr,L9,bMr,WTe,vMr,FMr,TMr,St,y9,MMr,HTe,EMr,CMr,ic,wMr,UTe,AMr,LMr,LU,yMr,xMr,$Mr,gC,kMr,$r,x9,SMr,JTe,RMr,PMr,sn,BMr,YTe,IMr,NMr,KTe,qMr,jMr,ZTe,DMr,GMr,OMr,Me,hC,eMe,VMr,XMr,yU,zMr,QMr,WMr,uC,oMe,HMr,UMr,xU,JMr,YMr,KMr,pC,rMe,ZMr,eEr,$U,oEr,rEr,tEr,_C,tMe,aEr,nEr,kU,sEr,lEr,iEr,bC,aMe,dEr,cEr,SU,mEr,fEr,gEr,vC,nMe,hEr,uEr,RU,pEr,_Er,bEr,FC,sMe,vEr,FEr,PU,TEr,MEr,EEr,TC,lMe,CEr,wEr,BU,AEr,LEr,yEr,MC,iMe,xEr,$Er,IU,kEr,SEr,REr,EC,dMe,PEr,BEr,NU,IEr,NEr,qEr,CC,cMe,jEr,DEr,qU,GEr,OEr,VEr,wC,mMe,XEr,zEr,jU,QEr,WEr,HEr,AC,fMe,UEr,JEr,DU,YEr,KEr,ZEr,LC,KOe,dc,yC,gMe,$9,e4r,hMe,o4r,ZOe,tr,k9,r4r,cc,t4r,GU,a4r,n4r,OU,s4r,l4r,i4r,S9,d4r,uMe,c4r,m4r,f4r,Rt,R9,g4r,pMe,h4r,u4r,mc,p4r,_Me,_4r,b4r,VU,v4r,F4r,T4r,xC,M4r,kr,P9,E4r,bMe,C4r,w4r,ln,A4r,vMe,L4r,y4r,FMe,x4r,$4r,TMe,k4r,S4r,R4r,dn,$C,MMe,P4r,B4r,XU,I4r,N4r,q4r,kC,EMe,j4r,D4r,zU,G4r,O4r,V4r,SC,CMe,X4r,z4r,QU,Q4r,W4r,H4r,RC,wMe,U4r,J4r,WU,Y4r,K4r,Z4r,PC,eVe,fc,BC,AMe,B9,eCr,LMe,oCr,oVe,ar,I9,rCr,gc,tCr,HU,aCr,nCr,UU,sCr,lCr,iCr,N9,dCr,yMe,cCr,mCr,fCr,Pt,q9,gCr,xMe,hCr,uCr,hc,pCr,$Me,_Cr,bCr,JU,vCr,FCr,TCr,IC,MCr,Sr,j9,ECr,kMe,CCr,wCr,cn,ACr,SMe,LCr,yCr,RMe,xCr,$Cr,PMe,kCr,SCr,RCr,ie,NC,BMe,PCr,BCr,YU,ICr,NCr,qCr,qC,IMe,jCr,DCr,KU,GCr,OCr,VCr,jC,NMe,XCr,zCr,ZU,QCr,WCr,HCr,DC,qMe,UCr,JCr,eJ,YCr,KCr,ZCr,GC,jMe,e5r,o5r,oJ,r5r,t5r,a5r,OC,DMe,n5r,s5r,rJ,l5r,i5r,d5r,VC,GMe,c5r,m5r,tJ,f5r,g5r,h5r,XC,OMe,u5r,p5r,aJ,_5r,b5r,v5r,zC,VMe,F5r,T5r,nJ,M5r,E5r,C5r,QC,XMe,w5r,A5r,sJ,L5r,y5r,x5r,WC,zMe,$5r,k5r,lJ,S5r,R5r,P5r,HC,QMe,B5r,I5r,iJ,N5r,q5r,j5r,UC,WMe,D5r,G5r,dJ,O5r,V5r,X5r,JC,HMe,z5r,Q5r,cJ,W5r,H5r,U5r,YC,UMe,J5r,Y5r,mJ,K5r,Z5r,e3r,KC,JMe,o3r,r3r,fJ,t3r,a3r,n3r,ZC,YMe,s3r,l3r,gJ,i3r,d3r,c3r,e5,KMe,m3r,f3r,hJ,g3r,h3r,u3r,o5,ZMe,p3r,_3r,uJ,b3r,v3r,F3r,r5,eEe,T3r,M3r,pJ,E3r,C3r,w3r,t5,rVe,uc,a5,oEe,D9,A3r,rEe,L3r,tVe,nr,G9,y3r,pc,x3r,_J,$3r,k3r,bJ,S3r,R3r,P3r,O9,B3r,tEe,I3r,N3r,q3r,Bt,V9,j3r,aEe,D3r,G3r,_c,O3r,nEe,V3r,X3r,vJ,z3r,Q3r,W3r,n5,H3r,Rr,X9,U3r,sEe,J3r,Y3r,mn,K3r,lEe,Z3r,e0r,iEe,o0r,r0r,dEe,t0r,a0r,n0r,ye,s5,cEe,s0r,l0r,FJ,i0r,d0r,c0r,l5,mEe,m0r,f0r,TJ,g0r,h0r,u0r,i5,fEe,p0r,_0r,MJ,b0r,v0r,F0r,d5,gEe,T0r,M0r,EJ,E0r,C0r,w0r,c5,hEe,A0r,L0r,CJ,y0r,x0r,$0r,m5,uEe,k0r,S0r,wJ,R0r,P0r,B0r,f5,pEe,I0r,N0r,AJ,q0r,j0r,D0r,g5,_Ee,G0r,O0r,LJ,V0r,X0r,z0r,h5,bEe,Q0r,W0r,yJ,H0r,U0r,J0r,u5,vEe,Y0r,K0r,xJ,Z0r,ewr,owr,p5,aVe,bc,_5,FEe,z9,rwr,TEe,twr,nVe,sr,Q9,awr,vc,nwr,$J,swr,lwr,kJ,iwr,dwr,cwr,W9,mwr,MEe,fwr,gwr,hwr,It,H9,uwr,EEe,pwr,_wr,Fc,bwr,CEe,vwr,Fwr,SJ,Twr,Mwr,Ewr,b5,Cwr,Pr,U9,wwr,wEe,Awr,Lwr,fn,ywr,AEe,xwr,$wr,LEe,kwr,Swr,yEe,Rwr,Pwr,Bwr,te,v5,xEe,Iwr,Nwr,RJ,qwr,jwr,Dwr,F5,$Ee,Gwr,Owr,PJ,Vwr,Xwr,zwr,T5,kEe,Qwr,Wwr,BJ,Hwr,Uwr,Jwr,M5,SEe,Ywr,Kwr,IJ,Zwr,eAr,oAr,E5,REe,rAr,tAr,NJ,aAr,nAr,sAr,C5,PEe,lAr,iAr,qJ,dAr,cAr,mAr,w5,BEe,fAr,gAr,jJ,hAr,uAr,pAr,A5,IEe,_Ar,bAr,DJ,vAr,FAr,TAr,L5,NEe,MAr,EAr,GJ,CAr,wAr,AAr,y5,qEe,LAr,yAr,OJ,xAr,$Ar,kAr,x5,jEe,SAr,RAr,VJ,PAr,BAr,IAr,$5,DEe,NAr,qAr,XJ,jAr,DAr,GAr,k5,GEe,OAr,VAr,zJ,XAr,zAr,QAr,S5,OEe,WAr,HAr,QJ,UAr,JAr,YAr,R5,VEe,KAr,ZAr,WJ,e6r,o6r,r6r,P5,XEe,t6r,a6r,HJ,n6r,s6r,l6r,B5,zEe,i6r,d6r,UJ,c6r,m6r,f6r,I5,QEe,g6r,h6r,JJ,u6r,p6r,_6r,N5,WEe,b6r,v6r,YJ,F6r,T6r,M6r,q5,HEe,E6r,C6r,KJ,w6r,A6r,L6r,j5,UEe,y6r,x6r,ZJ,$6r,k6r,S6r,D5,JEe,R6r,P6r,eY,B6r,I6r,N6r,G5,YEe,q6r,j6r,oY,D6r,G6r,O6r,O5,KEe,V6r,X6r,rY,z6r,Q6r,W6r,V5,ZEe,H6r,U6r,tY,J6r,Y6r,K6r,X5,e4e,Z6r,eLr,aY,oLr,rLr,tLr,z5,sVe,Tc,Q5,o4e,J9,aLr,r4e,nLr,lVe,lr,Y9,sLr,Mc,lLr,nY,iLr,dLr,sY,cLr,mLr,fLr,K9,gLr,t4e,hLr,uLr,pLr,Nt,Z9,_Lr,a4e,bLr,vLr,Ec,FLr,n4e,TLr,MLr,lY,ELr,CLr,wLr,W5,ALr,Br,ex,LLr,s4e,yLr,xLr,gn,$Lr,l4e,kLr,SLr,i4e,RLr,PLr,d4e,BLr,ILr,NLr,pe,H5,c4e,qLr,jLr,iY,DLr,GLr,OLr,U5,m4e,VLr,XLr,dY,zLr,QLr,WLr,J5,f4e,HLr,ULr,cY,JLr,YLr,KLr,Y5,g4e,ZLr,eyr,mY,oyr,ryr,tyr,K5,h4e,ayr,nyr,fY,syr,lyr,iyr,Z5,u4e,dyr,cyr,gY,myr,fyr,gyr,e3,p4e,hyr,uyr,hY,pyr,_yr,byr,o3,_4e,vyr,Fyr,uY,Tyr,Myr,Eyr,r3,b4e,Cyr,wyr,pY,Ayr,Lyr,yyr,t3,v4e,xyr,$yr,_Y,kyr,Syr,Ryr,a3,F4e,Pyr,Byr,bY,Iyr,Nyr,qyr,n3,T4e,jyr,Dyr,vY,Gyr,Oyr,Vyr,s3,M4e,Xyr,zyr,FY,Qyr,Wyr,Hyr,l3,E4e,Uyr,Jyr,TY,Yyr,Kyr,Zyr,i3,C4e,e7r,o7r,MY,r7r,t7r,a7r,d3,w4e,n7r,s7r,EY,l7r,i7r,d7r,c3,A4e,c7r,m7r,CY,f7r,g7r,h7r,m3,iVe,Cc,f3,L4e,ox,u7r,y4e,p7r,dVe,ir,rx,_7r,wc,b7r,wY,v7r,F7r,AY,T7r,M7r,E7r,tx,C7r,x4e,w7r,A7r,L7r,qt,ax,y7r,$4e,x7r,$7r,Ac,k7r,k4e,S7r,R7r,LY,P7r,B7r,I7r,g3,N7r,Ir,nx,q7r,S4e,j7r,D7r,hn,G7r,R4e,O7r,V7r,P4e,X7r,z7r,B4e,Q7r,W7r,H7r,sx,h3,I4e,U7r,J7r,yY,Y7r,K7r,Z7r,u3,N4e,e8r,o8r,xY,r8r,t8r,a8r,p3,cVe,Lc,_3,q4e,lx,n8r,j4e,s8r,mVe,dr,ix,l8r,yc,i8r,$Y,d8r,c8r,kY,m8r,f8r,g8r,dx,h8r,D4e,u8r,p8r,_8r,jt,cx,b8r,G4e,v8r,F8r,xc,T8r,O4e,M8r,E8r,SY,C8r,w8r,A8r,b3,L8r,Nr,mx,y8r,V4e,x8r,$8r,un,k8r,X4e,S8r,R8r,z4e,P8r,B8r,Q4e,I8r,N8r,q8r,W4e,v3,H4e,j8r,D8r,RY,G8r,O8r,V8r,F3,fVe,$c,T3,U4e,fx,X8r,J4e,z8r,gVe,cr,gx,Q8r,kc,W8r,PY,H8r,U8r,BY,J8r,Y8r,K8r,hx,Z8r,Y4e,e9r,o9r,r9r,Dt,ux,t9r,K4e,a9r,n9r,Sc,s9r,Z4e,l9r,i9r,IY,d9r,c9r,m9r,M3,f9r,qr,px,g9r,eCe,h9r,u9r,pn,p9r,oCe,_9r,b9r,rCe,v9r,F9r,tCe,T9r,M9r,E9r,de,E3,aCe,C9r,w9r,NY,A9r,L9r,y9r,C3,nCe,x9r,$9r,qY,k9r,S9r,R9r,w3,sCe,P9r,B9r,jY,I9r,N9r,q9r,A3,lCe,j9r,D9r,DY,G9r,O9r,V9r,L3,iCe,X9r,z9r,GY,Q9r,W9r,H9r,y3,dCe,U9r,J9r,OY,Y9r,K9r,Z9r,x3,cCe,exr,oxr,VY,rxr,txr,axr,$3,mCe,nxr,sxr,XY,lxr,ixr,dxr,k3,fCe,cxr,mxr,zY,fxr,gxr,hxr,S3,gCe,uxr,pxr,QY,_xr,bxr,vxr,R3,hCe,Fxr,Txr,WY,Mxr,Exr,Cxr,P3,uCe,wxr,Axr,HY,Lxr,yxr,xxr,B3,pCe,$xr,kxr,UY,Sxr,Rxr,Pxr,I3,_Ce,Bxr,Ixr,JY,Nxr,qxr,jxr,N3,bCe,Dxr,Gxr,YY,Oxr,Vxr,Xxr,q3,vCe,zxr,Qxr,KY,Wxr,Hxr,Uxr,j3,FCe,Jxr,Yxr,ZY,Kxr,Zxr,e$r,D3,TCe,o$r,r$r,eK,t$r,a$r,n$r,G3,MCe,s$r,l$r,oK,i$r,d$r,c$r,O3,ECe,m$r,f$r,rK,g$r,h$r,u$r,V3,hVe,Rc,X3,CCe,_x,p$r,wCe,_$r,uVe,mr,bx,b$r,Pc,v$r,tK,F$r,T$r,aK,M$r,E$r,C$r,vx,w$r,ACe,A$r,L$r,y$r,Gt,Fx,x$r,LCe,$$r,k$r,Bc,S$r,yCe,R$r,P$r,nK,B$r,I$r,N$r,z3,q$r,jr,Tx,j$r,xCe,D$r,G$r,_n,O$r,$Ce,V$r,X$r,kCe,z$r,Q$r,SCe,W$r,H$r,U$r,ce,Q3,RCe,J$r,Y$r,sK,K$r,Z$r,ekr,W3,PCe,okr,rkr,lK,tkr,akr,nkr,H3,BCe,skr,lkr,iK,ikr,dkr,ckr,U3,ICe,mkr,fkr,dK,gkr,hkr,ukr,J3,NCe,pkr,_kr,cK,bkr,vkr,Fkr,Y3,qCe,Tkr,Mkr,mK,Ekr,Ckr,wkr,K3,jCe,Akr,Lkr,fK,ykr,xkr,$kr,Z3,DCe,kkr,Skr,gK,Rkr,Pkr,Bkr,e0,GCe,Ikr,Nkr,hK,qkr,jkr,Dkr,o0,OCe,Gkr,Okr,uK,Vkr,Xkr,zkr,r0,VCe,Qkr,Wkr,pK,Hkr,Ukr,Jkr,t0,XCe,Ykr,Kkr,_K,Zkr,eSr,oSr,a0,zCe,rSr,tSr,bK,aSr,nSr,sSr,n0,QCe,lSr,iSr,vK,dSr,cSr,mSr,s0,WCe,fSr,gSr,FK,hSr,uSr,pSr,l0,HCe,_Sr,bSr,TK,vSr,FSr,TSr,i0,UCe,MSr,ESr,MK,CSr,wSr,ASr,d0,JCe,LSr,ySr,EK,xSr,$Sr,kSr,c0,YCe,SSr,RSr,CK,PSr,BSr,ISr,m0,KCe,NSr,qSr,wK,jSr,DSr,GSr,f0,pVe,Ic,g0,ZCe,Mx,OSr,e5e,VSr,_Ve,fr,Ex,XSr,Nc,zSr,AK,QSr,WSr,LK,HSr,USr,JSr,Cx,YSr,o5e,KSr,ZSr,eRr,Ot,wx,oRr,r5e,rRr,tRr,qc,aRr,t5e,nRr,sRr,yK,lRr,iRr,dRr,h0,cRr,Dr,Ax,mRr,a5e,fRr,gRr,bn,hRr,n5e,uRr,pRr,s5e,_Rr,bRr,l5e,vRr,FRr,TRr,i5e,u0,d5e,MRr,ERr,xK,CRr,wRr,ARr,p0,bVe,jc,_0,c5e,Lx,LRr,m5e,yRr,vVe,gr,yx,xRr,Dc,$Rr,$K,kRr,SRr,kK,RRr,PRr,BRr,xx,IRr,f5e,NRr,qRr,jRr,Vt,$x,DRr,g5e,GRr,ORr,Gc,VRr,h5e,XRr,zRr,SK,QRr,WRr,HRr,b0,URr,Gr,kx,JRr,u5e,YRr,KRr,vn,ZRr,p5e,ePr,oPr,_5e,rPr,tPr,b5e,aPr,nPr,sPr,v5e,v0,F5e,lPr,iPr,RK,dPr,cPr,mPr,F0,FVe,Oc,T0,T5e,Sx,fPr,M5e,gPr,TVe,hr,Rx,hPr,Vc,uPr,PK,pPr,_Pr,BK,bPr,vPr,FPr,Px,TPr,E5e,MPr,EPr,CPr,Xt,Bx,wPr,C5e,APr,LPr,Xc,yPr,w5e,xPr,$Pr,IK,kPr,SPr,RPr,M0,PPr,Or,Ix,BPr,A5e,IPr,NPr,Fn,qPr,L5e,jPr,DPr,y5e,GPr,OPr,x5e,VPr,XPr,zPr,oe,E0,$5e,QPr,WPr,NK,HPr,UPr,JPr,C0,k5e,YPr,KPr,qK,ZPr,eBr,oBr,w0,S5e,rBr,tBr,jK,aBr,nBr,sBr,A0,R5e,lBr,iBr,DK,dBr,cBr,mBr,L0,P5e,fBr,gBr,GK,hBr,uBr,pBr,y0,B5e,_Br,bBr,OK,vBr,FBr,TBr,x0,I5e,MBr,EBr,VK,CBr,wBr,ABr,$0,N5e,LBr,yBr,XK,xBr,$Br,kBr,k0,q5e,SBr,RBr,zK,PBr,BBr,IBr,S0,j5e,NBr,qBr,QK,jBr,DBr,GBr,R0,D5e,OBr,VBr,WK,XBr,zBr,QBr,P0,G5e,WBr,HBr,HK,UBr,JBr,YBr,B0,O5e,KBr,ZBr,UK,eIr,oIr,rIr,I0,V5e,tIr,aIr,JK,nIr,sIr,lIr,N0,X5e,iIr,dIr,YK,cIr,mIr,fIr,q0,z5e,gIr,hIr,KK,uIr,pIr,_Ir,j0,Q5e,bIr,vIr,ZK,FIr,TIr,MIr,D0,W5e,EIr,CIr,eZ,wIr,AIr,LIr,G0,H5e,yIr,xIr,oZ,$Ir,kIr,SIr,O0,U5e,RIr,PIr,rZ,BIr,IIr,NIr,V0,J5e,qIr,jIr,tZ,DIr,GIr,OIr,X0,Y5e,VIr,XIr,aZ,zIr,QIr,WIr,z0,K5e,HIr,UIr,nZ,JIr,YIr,KIr,Q0,Z5e,ZIr,eNr,sZ,oNr,rNr,tNr,W0,e3e,aNr,nNr,lZ,sNr,lNr,iNr,H0,o3e,dNr,cNr,iZ,mNr,fNr,gNr,U0,r3e,hNr,uNr,dZ,pNr,_Nr,bNr,J0,MVe,zc,Y0,t3e,Nx,vNr,a3e,FNr,EVe,ur,qx,TNr,Qc,MNr,cZ,ENr,CNr,mZ,wNr,ANr,LNr,jx,yNr,n3e,xNr,$Nr,kNr,zt,Dx,SNr,s3e,RNr,PNr,Wc,BNr,l3e,INr,NNr,fZ,qNr,jNr,DNr,K0,GNr,Vr,Gx,ONr,i3e,VNr,XNr,Tn,zNr,d3e,QNr,WNr,c3e,HNr,UNr,m3e,JNr,YNr,KNr,xe,Z0,f3e,ZNr,eqr,gZ,oqr,rqr,tqr,ew,g3e,aqr,nqr,hZ,sqr,lqr,iqr,ow,h3e,dqr,cqr,uZ,mqr,fqr,gqr,rw,u3e,hqr,uqr,pZ,pqr,_qr,bqr,tw,p3e,vqr,Fqr,_Z,Tqr,Mqr,Eqr,aw,_3e,Cqr,wqr,bZ,Aqr,Lqr,yqr,nw,b3e,xqr,$qr,vZ,kqr,Sqr,Rqr,sw,v3e,Pqr,Bqr,FZ,Iqr,Nqr,qqr,lw,F3e,jqr,Dqr,TZ,Gqr,Oqr,Vqr,iw,T3e,Xqr,zqr,MZ,Qqr,Wqr,Hqr,dw,CVe,Hc,cw,M3e,Ox,Uqr,E3e,Jqr,wVe,pr,Vx,Yqr,Uc,Kqr,EZ,Zqr,ejr,CZ,ojr,rjr,tjr,Xx,ajr,C3e,njr,sjr,ljr,Qt,zx,ijr,w3e,djr,cjr,Jc,mjr,A3e,fjr,gjr,wZ,hjr,ujr,pjr,mw,_jr,Xr,Qx,bjr,L3e,vjr,Fjr,Mn,Tjr,y3e,Mjr,Ejr,x3e,Cjr,wjr,$3e,Ajr,Ljr,yjr,Ee,fw,k3e,xjr,$jr,AZ,kjr,Sjr,Rjr,gw,S3e,Pjr,Bjr,LZ,Ijr,Njr,qjr,hw,R3e,jjr,Djr,yZ,Gjr,Ojr,Vjr,uw,P3e,Xjr,zjr,xZ,Qjr,Wjr,Hjr,pw,B3e,Ujr,Jjr,$Z,Yjr,Kjr,Zjr,_w,I3e,eDr,oDr,kZ,rDr,tDr,aDr,bw,N3e,nDr,sDr,SZ,lDr,iDr,dDr,vw,q3e,cDr,mDr,RZ,fDr,gDr,hDr,Fw,j3e,uDr,pDr,PZ,_Dr,bDr,vDr,Tw,D3e,FDr,TDr,BZ,MDr,EDr,CDr,Mw,G3e,wDr,ADr,IZ,LDr,yDr,xDr,Ew,O3e,$Dr,kDr,NZ,SDr,RDr,PDr,Cw,V3e,BDr,IDr,qZ,NDr,qDr,jDr,ww,AVe,Yc,Aw,X3e,Wx,DDr,z3e,GDr,LVe,_r,Hx,ODr,Kc,VDr,jZ,XDr,zDr,DZ,QDr,WDr,HDr,Ux,UDr,Q3e,JDr,YDr,KDr,Wt,Jx,ZDr,W3e,eGr,oGr,Zc,rGr,H3e,tGr,aGr,GZ,nGr,sGr,lGr,Lw,iGr,zr,Yx,dGr,U3e,cGr,mGr,En,fGr,J3e,gGr,hGr,Y3e,uGr,pGr,K3e,_Gr,bGr,vGr,$e,yw,Z3e,FGr,TGr,OZ,MGr,EGr,CGr,xw,e0e,wGr,AGr,VZ,LGr,yGr,xGr,$w,o0e,$Gr,kGr,XZ,SGr,RGr,PGr,kw,r0e,BGr,IGr,zZ,NGr,qGr,jGr,Sw,t0e,DGr,GGr,QZ,OGr,VGr,XGr,Rw,a0e,zGr,QGr,WZ,WGr,HGr,UGr,Pw,n0e,JGr,YGr,HZ,KGr,ZGr,eOr,Bw,s0e,oOr,rOr,UZ,tOr,aOr,nOr,Iw,l0e,sOr,lOr,JZ,iOr,dOr,cOr,Nw,i0e,mOr,fOr,YZ,gOr,hOr,uOr,qw,yVe,em,jw,d0e,Kx,pOr,c0e,_Or,xVe,br,Zx,bOr,om,vOr,KZ,FOr,TOr,ZZ,MOr,EOr,COr,e$,wOr,m0e,AOr,LOr,yOr,Ht,o$,xOr,f0e,$Or,kOr,rm,SOr,g0e,ROr,POr,eee,BOr,IOr,NOr,Dw,qOr,Qr,r$,jOr,h0e,DOr,GOr,Cn,OOr,u0e,VOr,XOr,p0e,zOr,QOr,_0e,WOr,HOr,UOr,ke,Gw,b0e,JOr,YOr,oee,KOr,ZOr,eVr,Ow,v0e,oVr,rVr,ree,tVr,aVr,nVr,Vw,F0e,sVr,lVr,tee,iVr,dVr,cVr,Xw,T0e,mVr,fVr,aee,gVr,hVr,uVr,zw,M0e,pVr,_Vr,nee,bVr,vVr,FVr,Qw,E0e,TVr,MVr,see,EVr,CVr,wVr,Ww,C0e,AVr,LVr,lee,yVr,xVr,$Vr,Hw,w0e,kVr,SVr,iee,RVr,PVr,BVr,Uw,A0e,IVr,NVr,dee,qVr,jVr,DVr,Jw,L0e,GVr,OVr,cee,VVr,XVr,zVr,Yw,$Ve,tm,Kw,y0e,t$,QVr,x0e,WVr,kVe,vr,a$,HVr,am,UVr,mee,JVr,YVr,fee,KVr,ZVr,eXr,n$,oXr,$0e,rXr,tXr,aXr,Ut,s$,nXr,k0e,sXr,lXr,nm,iXr,S0e,dXr,cXr,gee,mXr,fXr,gXr,Zw,hXr,Wr,l$,uXr,R0e,pXr,_Xr,wn,bXr,P0e,vXr,FXr,B0e,TXr,MXr,I0e,EXr,CXr,wXr,Se,eA,N0e,AXr,LXr,hee,yXr,xXr,$Xr,oA,q0e,kXr,SXr,uee,RXr,PXr,BXr,rA,j0e,IXr,NXr,pee,qXr,jXr,DXr,tA,D0e,GXr,OXr,_ee,VXr,XXr,zXr,aA,G0e,QXr,WXr,bee,HXr,UXr,JXr,nA,O0e,YXr,KXr,vee,ZXr,ezr,ozr,sA,V0e,rzr,tzr,Fee,azr,nzr,szr,lA,X0e,lzr,izr,Tee,dzr,czr,mzr,iA,z0e,fzr,gzr,Mee,hzr,uzr,pzr,dA,Q0e,_zr,bzr,Eee,vzr,Fzr,Tzr,cA,SVe,sm,mA,W0e,i$,Mzr,H0e,Ezr,RVe,Fr,d$,Czr,lm,wzr,Cee,Azr,Lzr,wee,yzr,xzr,$zr,c$,kzr,U0e,Szr,Rzr,Pzr,Jt,m$,Bzr,J0e,Izr,Nzr,im,qzr,Y0e,jzr,Dzr,Aee,Gzr,Ozr,Vzr,fA,Xzr,Hr,f$,zzr,K0e,Qzr,Wzr,An,Hzr,Z0e,Uzr,Jzr,ewe,Yzr,Kzr,owe,Zzr,eQr,oQr,Re,gA,rwe,rQr,tQr,Lee,aQr,nQr,sQr,hA,twe,lQr,iQr,yee,dQr,cQr,mQr,uA,awe,fQr,gQr,xee,hQr,uQr,pQr,pA,nwe,_Qr,bQr,$ee,vQr,FQr,TQr,_A,swe,MQr,EQr,kee,CQr,wQr,AQr,bA,lwe,LQr,yQr,See,xQr,$Qr,kQr,vA,iwe,SQr,RQr,Ree,PQr,BQr,IQr,FA,dwe,NQr,qQr,Pee,jQr,DQr,GQr,TA,cwe,OQr,VQr,Bee,XQr,zQr,QQr,MA,mwe,WQr,HQr,Iee,UQr,JQr,YQr,EA,PVe,dm,CA,fwe,g$,KQr,gwe,ZQr,BVe,Tr,h$,eWr,cm,oWr,Nee,rWr,tWr,qee,aWr,nWr,sWr,u$,lWr,hwe,iWr,dWr,cWr,Yt,p$,mWr,uwe,fWr,gWr,mm,hWr,pwe,uWr,pWr,jee,_Wr,bWr,vWr,wA,FWr,Ur,_$,TWr,_we,MWr,EWr,Ln,CWr,bwe,wWr,AWr,vwe,LWr,yWr,Fwe,xWr,$Wr,kWr,Ve,AA,Twe,SWr,RWr,Dee,PWr,BWr,IWr,LA,Mwe,NWr,qWr,Gee,jWr,DWr,GWr,yA,Ewe,OWr,VWr,Oee,XWr,zWr,QWr,xA,Cwe,WWr,HWr,Vee,UWr,JWr,YWr,$A,wwe,KWr,ZWr,Xee,eHr,oHr,rHr,kA,Awe,tHr,aHr,zee,nHr,sHr,lHr,SA,Lwe,iHr,dHr,Qee,cHr,mHr,fHr,RA,ywe,gHr,hHr,Wee,uHr,pHr,_Hr,PA,IVe,fm,BA,xwe,b$,bHr,$we,vHr,NVe,Mr,v$,FHr,gm,THr,Hee,MHr,EHr,Uee,CHr,wHr,AHr,F$,LHr,kwe,yHr,xHr,$Hr,Kt,T$,kHr,Swe,SHr,RHr,hm,PHr,Rwe,BHr,IHr,Jee,NHr,qHr,jHr,IA,DHr,Jr,M$,GHr,Pwe,OHr,VHr,yn,XHr,Bwe,zHr,QHr,Iwe,WHr,HHr,Nwe,UHr,JHr,YHr,Xe,NA,qwe,KHr,ZHr,Yee,eUr,oUr,rUr,qA,jwe,tUr,aUr,Kee,nUr,sUr,lUr,jA,Dwe,iUr,dUr,Zee,cUr,mUr,fUr,DA,Gwe,gUr,hUr,eoe,uUr,pUr,_Ur,GA,Owe,bUr,vUr,ooe,FUr,TUr,MUr,OA,Vwe,EUr,CUr,roe,wUr,AUr,LUr,VA,Xwe,yUr,xUr,toe,$Ur,kUr,SUr,XA,zwe,RUr,PUr,aoe,BUr,IUr,NUr,zA,qVe,um,QA,Qwe,E$,qUr,Wwe,jUr,jVe,Er,C$,DUr,pm,GUr,noe,OUr,VUr,soe,XUr,zUr,QUr,w$,WUr,Hwe,HUr,UUr,JUr,Zt,A$,YUr,Uwe,KUr,ZUr,_m,eJr,Jwe,oJr,rJr,loe,tJr,aJr,nJr,WA,sJr,Yr,L$,lJr,Ywe,iJr,dJr,xn,cJr,Kwe,mJr,fJr,Zwe,gJr,hJr,eAe,uJr,pJr,_Jr,oAe,HA,rAe,bJr,vJr,ioe,FJr,TJr,MJr,UA,DVe,bm,JA,tAe,y$,EJr,aAe,CJr,GVe,Cr,x$,wJr,vm,AJr,doe,LJr,yJr,coe,xJr,$Jr,kJr,$$,SJr,nAe,RJr,PJr,BJr,ea,k$,IJr,sAe,NJr,qJr,Fm,jJr,lAe,DJr,GJr,moe,OJr,VJr,XJr,YA,zJr,Kr,S$,QJr,iAe,WJr,HJr,$n,UJr,dAe,JJr,YJr,cAe,KJr,ZJr,mAe,eYr,oYr,rYr,R$,KA,fAe,tYr,aYr,foe,nYr,sYr,lYr,ZA,gAe,iYr,dYr,goe,cYr,mYr,fYr,e6,OVe,Tm,o6,hAe,P$,gYr,uAe,hYr,VVe,wr,B$,uYr,Mm,pYr,hoe,_Yr,bYr,uoe,vYr,FYr,TYr,I$,MYr,pAe,EYr,CYr,wYr,oa,N$,AYr,_Ae,LYr,yYr,Em,xYr,bAe,$Yr,kYr,poe,SYr,RYr,PYr,r6,BYr,Zr,q$,IYr,vAe,NYr,qYr,kn,jYr,FAe,DYr,GYr,TAe,OYr,VYr,MAe,XYr,zYr,QYr,EAe,t6,CAe,WYr,HYr,_oe,UYr,JYr,YYr,a6,XVe;return d=new re({}),xa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),xy=new re({}),$y=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Sm=new KYr({props:{warning:!0,$$slots:{default:[CDt]},$$scope:{ctx:x}}}),ky=new re({}),Sy=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L598"}}),By=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L621"}}),Gg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),Iy=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L744"}}),Ny=new re({}),qy=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L400"}}),Gy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L414"}}),Eh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),Oy=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L613"}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),Wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),au=new KYr({props:{$$slots:{default:[LDt]},$$scope:{ctx:x}}}),nu=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),Hy=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),Uy=new re({}),Jy=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L88"}}),Zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L102"}}),wu=new KYr({props:{$$slots:{default:[xDt]},$$scope:{ctx:x}}}),Au=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),e7=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L255"}}),o7=new re({}),r7=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L767"}}),a7=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xu=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),n7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x_=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),s7=new re({}),l7=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L774"}}),d7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),c7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E2=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),m7=new re({}),f7=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L789"}}),h7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),u7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mb=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),p7=new re({}),_7=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L796"}}),v7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gb=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),F7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Kb=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),T7=new re({}),M7=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L803"}}),C7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ev=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),w7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vv=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),A7=new re({}),L7=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L812"}}),x7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Tv=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),$7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bF=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),k7=new re({}),S7=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L857"}}),P7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),FF=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),B7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KF=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),I7=new re({}),N7=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L864"}}),j7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e1=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),D7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i1=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),G7=new re({}),O7=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L850"}}),X7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),c1=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),z7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H1=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),Q7=new re({}),W7=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L821"}}),U7=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J1=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),J7=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),Y7=new re({}),K7=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L828"}}),e8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),o8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XT=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),r8=new re({}),t8=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L873"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QT=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sM=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),l8=new re({}),i8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L912"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),iM=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),m8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mM=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),f8=new re({}),g8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L839"}}),u8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),p8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pM=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),_8=new re({}),b8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L919"}}),F8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xM=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),M8=new re({}),E8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L942"}}),w8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kM=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qM=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[iGt]},$$scope:{ctx:x}}}),L8=new re({}),y8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L926"}}),$8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),DM=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KM=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),S8=new re({}),R8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L933"}}),B8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eE=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aE=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),q8=new re({}),j8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L951"}}),G8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sE=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),O8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gE=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),V8=new re({}),X8=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L958"}}),Q8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uE=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FE=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),H8=new re({}),U8=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L905"}}),Y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ME=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),K8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AE=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L880"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yE=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),kE=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),n9=new re({}),s9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L887"}}),i9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),RE=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jE=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[MGt]},$$scope:{ctx:x}}}),c9=new re({}),m9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L896"}}),g9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GE=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[EGt]},$$scope:{ctx:x}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XE=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[CGt]},$$scope:{ctx:x}}}),u9=new re({}),p9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),b9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QE=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[wGt]},$$scope:{ctx:x}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j4=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[AGt]},$$scope:{ctx:x}}}),F9=new re({}),T9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),E9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G4=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[LGt]},$$scope:{ctx:x}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[yGt]},$$scope:{ctx:x}}}),w9=new re({}),A9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gC=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[xGt]},$$scope:{ctx:x}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),LC=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Gt]},$$scope:{ctx:x}}}),$9=new re({}),k9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),R9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xC=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[kGt]},$$scope:{ctx:x}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[SGt]},$$scope:{ctx:x}}}),B9=new re({}),I9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IC=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[RGt]},$$scope:{ctx:x}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t5=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PGt]},$$scope:{ctx:x}}}),D9=new re({}),G9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),V9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n5=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BGt]},$$scope:{ctx:x}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p5=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IGt]},$$scope:{ctx:x}}}),z9=new re({}),Q9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),H9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b5=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NGt]},$$scope:{ctx:x}}}),U9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z5=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qGt]},$$scope:{ctx:x}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W5=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[jGt]},$$scope:{ctx:x}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m3=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[DGt]},$$scope:{ctx:x}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g3=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[GGt]},$$scope:{ctx:x}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p3=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[OGt]},$$scope:{ctx:x}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b3=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VGt]},$$scope:{ctx:x}}}),mx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F3=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XGt]},$$scope:{ctx:x}}}),fx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),ux=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M3=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[zGt]},$$scope:{ctx:x}}}),px=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V3=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QGt]},$$scope:{ctx:x}}}),_x=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z3=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[WGt]},$$scope:{ctx:x}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f0=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[HGt]},$$scope:{ctx:x}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h0=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[UGt]},$$scope:{ctx:x}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p0=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JGt]},$$scope:{ctx:x}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b0=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[YGt]},$$scope:{ctx:x}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F0=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[KGt]},$$scope:{ctx:x}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M0=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[ZGt]},$$scope:{ctx:x}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J0=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[eOt]},$$scope:{ctx:x}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[oOt]},$$scope:{ctx:x}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dw=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[rOt]},$$scope:{ctx:x}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mw=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[tOt]},$$scope:{ctx:x}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ww=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[aOt]},$$scope:{ctx:x}}}),Wx=new re({}),Hx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Lw=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[nOt]},$$scope:{ctx:x}}}),Yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qw=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[sOt]},$$scope:{ctx:x}}}),Kx=new re({}),Zx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),o$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Dw=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[lOt]},$$scope:{ctx:x}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Yw=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[iOt]},$$scope:{ctx:x}}}),t$=new re({}),a$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),s$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Zw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[dOt]},$$scope:{ctx:x}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cA=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[cOt]},$$scope:{ctx:x}}}),i$=new re({}),d$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),m$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fA=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[mOt]},$$scope:{ctx:x}}}),f$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),EA=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[fOt]},$$scope:{ctx:x}}}),g$=new re({}),h$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),p$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),wA=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[gOt]},$$scope:{ctx:x}}}),_$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PA=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[hOt]},$$scope:{ctx:x}}}),b$=new re({}),v$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),T$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IA=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[uOt]},$$scope:{ctx:x}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zA=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[pOt]},$$scope:{ctx:x}}}),E$=new re({}),C$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),A$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),WA=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[_Ot]},$$scope:{ctx:x}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UA=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bOt]},$$scope:{ctx:x}}}),y$=new re({}),x$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),k$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YA=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[vOt]},$$scope:{ctx:x}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e6=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[FOt]},$$scope:{ctx:x}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r6=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[TOt]},$$scope:{ctx:x}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a6=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[MOt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),Lm=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),wy=o("from_pretrained()"),ym=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Ci=o("Instantiating one of "),Rn=a("a"),Ay=o("AutoConfig"),Pn=o(", "),Bn=a("a"),Ly=o("AutoModel"),wi=o(`, and
`),In=a("a"),yy=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),xm=l(),F(xa.$$.fragment),We=l(),Ae=a("p"),rS=o("will create a model that is an instance of "),Li=a("a"),tS=o("BertModel"),aS=o("."),Co=l(),$a=a("p"),nS=o("There is one class of "),$m=a("code"),sS=o("AutoModel"),eQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jGe=l(),yi=a("h2"),km=a("a"),fte=a("span"),F(xy.$$.fragment),oQe=l(),gte=a("span"),rQe=o("Extending the Auto Classes"),DGe=l(),Nn=a("p"),tQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=a("code"),aQe=o("NewModel"),nQe=o(", make sure you have a "),ute=a("code"),sQe=o("NewModelConfig"),lQe=o(` then you can add those to the auto
classes like this:`),GGe=l(),F($y.$$.fragment),OGe=l(),lS=a("p"),iQe=o("You will then be able to use the auto classes like you would usually do!"),VGe=l(),F(Sm.$$.fragment),XGe=l(),xi=a("h2"),Rm=a("a"),pte=a("span"),F(ky.$$.fragment),dQe=l(),_te=a("span"),cQe=o("AutoConfig"),zGe=l(),wo=a("div"),F(Sy.$$.fragment),mQe=l(),Ry=a("p"),fQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=a("a"),gQe=o("from_pretrained()"),hQe=o(" class method."),uQe=l(),Py=a("p"),pQe=o("This class cannot be instantiated directly using "),bte=a("code"),_Qe=o("__init__()"),bQe=o(" (throws an error)."),vQe=l(),Ar=a("div"),F(By.$$.fragment),FQe=l(),vte=a("p"),TQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),MQe=l(),$i=a("p"),EQe=o("The configuration class to instantiate is selected based on the "),Fte=a("code"),CQe=o("model_type"),wQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=a("code"),AQe=o("pretrained_model_name_or_path"),LQe=o(":"),yQe=l(),A=a("ul"),Pm=a("li"),Mte=a("strong"),xQe=o("albert"),$Qe=o(" \u2014 "),dS=a("a"),kQe=o("AlbertConfig"),SQe=o(" (ALBERT model)"),RQe=l(),Bm=a("li"),Ete=a("strong"),PQe=o("bart"),BQe=o(" \u2014 "),cS=a("a"),IQe=o("BartConfig"),NQe=o(" (BART model)"),qQe=l(),Im=a("li"),Cte=a("strong"),jQe=o("beit"),DQe=o(" \u2014 "),mS=a("a"),GQe=o("BeitConfig"),OQe=o(" (BEiT model)"),VQe=l(),Nm=a("li"),wte=a("strong"),XQe=o("bert"),zQe=o(" \u2014 "),fS=a("a"),QQe=o("BertConfig"),WQe=o(" (BERT model)"),HQe=l(),qm=a("li"),Ate=a("strong"),UQe=o("bert-generation"),JQe=o(" \u2014 "),gS=a("a"),YQe=o("BertGenerationConfig"),KQe=o(" (Bert Generation model)"),ZQe=l(),jm=a("li"),Lte=a("strong"),eWe=o("big_bird"),oWe=o(" \u2014 "),hS=a("a"),rWe=o("BigBirdConfig"),tWe=o(" (BigBird model)"),aWe=l(),Dm=a("li"),yte=a("strong"),nWe=o("bigbird_pegasus"),sWe=o(" \u2014 "),uS=a("a"),lWe=o("BigBirdPegasusConfig"),iWe=o(" (BigBird-Pegasus model)"),dWe=l(),Gm=a("li"),xte=a("strong"),cWe=o("blenderbot"),mWe=o(" \u2014 "),pS=a("a"),fWe=o("BlenderbotConfig"),gWe=o(" (Blenderbot model)"),hWe=l(),Om=a("li"),$te=a("strong"),uWe=o("blenderbot-small"),pWe=o(" \u2014 "),_S=a("a"),_We=o("BlenderbotSmallConfig"),bWe=o(" (BlenderbotSmall model)"),vWe=l(),Vm=a("li"),kte=a("strong"),FWe=o("bloom"),TWe=o(" \u2014 "),bS=a("a"),MWe=o("BloomConfig"),EWe=o(" (BLOOM model)"),CWe=l(),Xm=a("li"),Ste=a("strong"),wWe=o("camembert"),AWe=o(" \u2014 "),vS=a("a"),LWe=o("CamembertConfig"),yWe=o(" (CamemBERT model)"),xWe=l(),zm=a("li"),Rte=a("strong"),$We=o("canine"),kWe=o(" \u2014 "),FS=a("a"),SWe=o("CanineConfig"),RWe=o(" (CANINE model)"),PWe=l(),Qm=a("li"),Pte=a("strong"),BWe=o("clip"),IWe=o(" \u2014 "),TS=a("a"),NWe=o("CLIPConfig"),qWe=o(" (CLIP model)"),jWe=l(),Wm=a("li"),Bte=a("strong"),DWe=o("convbert"),GWe=o(" \u2014 "),MS=a("a"),OWe=o("ConvBertConfig"),VWe=o(" (ConvBERT model)"),XWe=l(),Hm=a("li"),Ite=a("strong"),zWe=o("convnext"),QWe=o(" \u2014 "),ES=a("a"),WWe=o("ConvNextConfig"),HWe=o(" (ConvNeXT model)"),UWe=l(),Um=a("li"),Nte=a("strong"),JWe=o("ctrl"),YWe=o(" \u2014 "),CS=a("a"),KWe=o("CTRLConfig"),ZWe=o(" (CTRL model)"),eHe=l(),Jm=a("li"),qte=a("strong"),oHe=o("cvt"),rHe=o(" \u2014 "),wS=a("a"),tHe=o("CvtConfig"),aHe=o(" (CvT model)"),nHe=l(),Ym=a("li"),jte=a("strong"),sHe=o("data2vec-audio"),lHe=o(" \u2014 "),AS=a("a"),iHe=o("Data2VecAudioConfig"),dHe=o(" (Data2VecAudio model)"),cHe=l(),Km=a("li"),Dte=a("strong"),mHe=o("data2vec-text"),fHe=o(" \u2014 "),LS=a("a"),gHe=o("Data2VecTextConfig"),hHe=o(" (Data2VecText model)"),uHe=l(),Zm=a("li"),Gte=a("strong"),pHe=o("data2vec-vision"),_He=o(" \u2014 "),yS=a("a"),bHe=o("Data2VecVisionConfig"),vHe=o(" (Data2VecVision model)"),FHe=l(),ef=a("li"),Ote=a("strong"),THe=o("deberta"),MHe=o(" \u2014 "),xS=a("a"),EHe=o("DebertaConfig"),CHe=o(" (DeBERTa model)"),wHe=l(),of=a("li"),Vte=a("strong"),AHe=o("deberta-v2"),LHe=o(" \u2014 "),$S=a("a"),yHe=o("DebertaV2Config"),xHe=o(" (DeBERTa-v2 model)"),$He=l(),rf=a("li"),Xte=a("strong"),kHe=o("decision_transformer"),SHe=o(" \u2014 "),kS=a("a"),RHe=o("DecisionTransformerConfig"),PHe=o(" (Decision Transformer model)"),BHe=l(),tf=a("li"),zte=a("strong"),IHe=o("deit"),NHe=o(" \u2014 "),SS=a("a"),qHe=o("DeiTConfig"),jHe=o(" (DeiT model)"),DHe=l(),af=a("li"),Qte=a("strong"),GHe=o("detr"),OHe=o(" \u2014 "),RS=a("a"),VHe=o("DetrConfig"),XHe=o(" (DETR model)"),zHe=l(),nf=a("li"),Wte=a("strong"),QHe=o("distilbert"),WHe=o(" \u2014 "),PS=a("a"),HHe=o("DistilBertConfig"),UHe=o(" (DistilBERT model)"),JHe=l(),sf=a("li"),Hte=a("strong"),YHe=o("dpr"),KHe=o(" \u2014 "),BS=a("a"),ZHe=o("DPRConfig"),eUe=o(" (DPR model)"),oUe=l(),lf=a("li"),Ute=a("strong"),rUe=o("dpt"),tUe=o(" \u2014 "),IS=a("a"),aUe=o("DPTConfig"),nUe=o(" (DPT model)"),sUe=l(),df=a("li"),Jte=a("strong"),lUe=o("electra"),iUe=o(" \u2014 "),NS=a("a"),dUe=o("ElectraConfig"),cUe=o(" (ELECTRA model)"),mUe=l(),cf=a("li"),Yte=a("strong"),fUe=o("encoder-decoder"),gUe=o(" \u2014 "),qS=a("a"),hUe=o("EncoderDecoderConfig"),uUe=o(" (Encoder decoder model)"),pUe=l(),mf=a("li"),Kte=a("strong"),_Ue=o("flaubert"),bUe=o(" \u2014 "),jS=a("a"),vUe=o("FlaubertConfig"),FUe=o(" (FlauBERT model)"),TUe=l(),ff=a("li"),Zte=a("strong"),MUe=o("flava"),EUe=o(" \u2014 "),DS=a("a"),CUe=o("FlavaConfig"),wUe=o(" (FLAVA model)"),AUe=l(),gf=a("li"),eae=a("strong"),LUe=o("fnet"),yUe=o(" \u2014 "),GS=a("a"),xUe=o("FNetConfig"),$Ue=o(" (FNet model)"),kUe=l(),hf=a("li"),oae=a("strong"),SUe=o("fsmt"),RUe=o(" \u2014 "),OS=a("a"),PUe=o("FSMTConfig"),BUe=o(" (FairSeq Machine-Translation model)"),IUe=l(),uf=a("li"),rae=a("strong"),NUe=o("funnel"),qUe=o(" \u2014 "),VS=a("a"),jUe=o("FunnelConfig"),DUe=o(" (Funnel Transformer model)"),GUe=l(),pf=a("li"),tae=a("strong"),OUe=o("glpn"),VUe=o(" \u2014 "),XS=a("a"),XUe=o("GLPNConfig"),zUe=o(" (GLPN model)"),QUe=l(),_f=a("li"),aae=a("strong"),WUe=o("gpt2"),HUe=o(" \u2014 "),zS=a("a"),UUe=o("GPT2Config"),JUe=o(" (OpenAI GPT-2 model)"),YUe=l(),bf=a("li"),nae=a("strong"),KUe=o("gpt_neo"),ZUe=o(" \u2014 "),QS=a("a"),eJe=o("GPTNeoConfig"),oJe=o(" (GPT Neo model)"),rJe=l(),vf=a("li"),sae=a("strong"),tJe=o("gpt_neox"),aJe=o(" \u2014 "),WS=a("a"),nJe=o("GPTNeoXConfig"),sJe=o(" (GPT NeoX model)"),lJe=l(),Ff=a("li"),lae=a("strong"),iJe=o("gptj"),dJe=o(" \u2014 "),HS=a("a"),cJe=o("GPTJConfig"),mJe=o(" (GPT-J model)"),fJe=l(),Tf=a("li"),iae=a("strong"),gJe=o("hubert"),hJe=o(" \u2014 "),US=a("a"),uJe=o("HubertConfig"),pJe=o(" (Hubert model)"),_Je=l(),Mf=a("li"),dae=a("strong"),bJe=o("ibert"),vJe=o(" \u2014 "),JS=a("a"),FJe=o("IBertConfig"),TJe=o(" (I-BERT model)"),MJe=l(),Ef=a("li"),cae=a("strong"),EJe=o("imagegpt"),CJe=o(" \u2014 "),YS=a("a"),wJe=o("ImageGPTConfig"),AJe=o(" (ImageGPT model)"),LJe=l(),Cf=a("li"),mae=a("strong"),yJe=o("layoutlm"),xJe=o(" \u2014 "),KS=a("a"),$Je=o("LayoutLMConfig"),kJe=o(" (LayoutLM model)"),SJe=l(),wf=a("li"),fae=a("strong"),RJe=o("layoutlmv2"),PJe=o(" \u2014 "),ZS=a("a"),BJe=o("LayoutLMv2Config"),IJe=o(" (LayoutLMv2 model)"),NJe=l(),Af=a("li"),gae=a("strong"),qJe=o("layoutlmv3"),jJe=o(" \u2014 "),eR=a("a"),DJe=o("LayoutLMv3Config"),GJe=o(" (LayoutLMv3 model)"),OJe=l(),Lf=a("li"),hae=a("strong"),VJe=o("led"),XJe=o(" \u2014 "),oR=a("a"),zJe=o("LEDConfig"),QJe=o(" (LED model)"),WJe=l(),yf=a("li"),uae=a("strong"),HJe=o("levit"),UJe=o(" \u2014 "),rR=a("a"),JJe=o("LevitConfig"),YJe=o(" (LeViT model)"),KJe=l(),xf=a("li"),pae=a("strong"),ZJe=o("longformer"),eYe=o(" \u2014 "),tR=a("a"),oYe=o("LongformerConfig"),rYe=o(" (Longformer model)"),tYe=l(),$f=a("li"),_ae=a("strong"),aYe=o("longt5"),nYe=o(" \u2014 "),aR=a("a"),sYe=o("LongT5Config"),lYe=o(" (LongT5 model)"),iYe=l(),kf=a("li"),bae=a("strong"),dYe=o("luke"),cYe=o(" \u2014 "),nR=a("a"),mYe=o("LukeConfig"),fYe=o(" (LUKE model)"),gYe=l(),Sf=a("li"),vae=a("strong"),hYe=o("lxmert"),uYe=o(" \u2014 "),sR=a("a"),pYe=o("LxmertConfig"),_Ye=o(" (LXMERT model)"),bYe=l(),Rf=a("li"),Fae=a("strong"),vYe=o("m2m_100"),FYe=o(" \u2014 "),lR=a("a"),TYe=o("M2M100Config"),MYe=o(" (M2M100 model)"),EYe=l(),Pf=a("li"),Tae=a("strong"),CYe=o("marian"),wYe=o(" \u2014 "),iR=a("a"),AYe=o("MarianConfig"),LYe=o(" (Marian model)"),yYe=l(),Bf=a("li"),Mae=a("strong"),xYe=o("maskformer"),$Ye=o(" \u2014 "),dR=a("a"),kYe=o("MaskFormerConfig"),SYe=o(" (MaskFormer model)"),RYe=l(),If=a("li"),Eae=a("strong"),PYe=o("mbart"),BYe=o(" \u2014 "),cR=a("a"),IYe=o("MBartConfig"),NYe=o(" (mBART model)"),qYe=l(),Nf=a("li"),Cae=a("strong"),jYe=o("mctct"),DYe=o(" \u2014 "),mR=a("a"),GYe=o("MCTCTConfig"),OYe=o(" (M-CTC-T model)"),VYe=l(),qf=a("li"),wae=a("strong"),XYe=o("megatron-bert"),zYe=o(" \u2014 "),fR=a("a"),QYe=o("MegatronBertConfig"),WYe=o(" (Megatron-BERT model)"),HYe=l(),jf=a("li"),Aae=a("strong"),UYe=o("mobilebert"),JYe=o(" \u2014 "),gR=a("a"),YYe=o("MobileBertConfig"),KYe=o(" (MobileBERT model)"),ZYe=l(),Df=a("li"),Lae=a("strong"),eKe=o("mpnet"),oKe=o(" \u2014 "),hR=a("a"),rKe=o("MPNetConfig"),tKe=o(" (MPNet model)"),aKe=l(),Gf=a("li"),yae=a("strong"),nKe=o("mt5"),sKe=o(" \u2014 "),uR=a("a"),lKe=o("MT5Config"),iKe=o(" (MT5 model)"),dKe=l(),Of=a("li"),xae=a("strong"),cKe=o("nezha"),mKe=o(" \u2014 "),pR=a("a"),fKe=o("NezhaConfig"),gKe=o(" (Nezha model)"),hKe=l(),Vf=a("li"),$ae=a("strong"),uKe=o("nystromformer"),pKe=o(" \u2014 "),_R=a("a"),_Ke=o("NystromformerConfig"),bKe=o(" (Nystr\xF6mformer model)"),vKe=l(),Xf=a("li"),kae=a("strong"),FKe=o("openai-gpt"),TKe=o(" \u2014 "),bR=a("a"),MKe=o("OpenAIGPTConfig"),EKe=o(" (OpenAI GPT model)"),CKe=l(),zf=a("li"),Sae=a("strong"),wKe=o("opt"),AKe=o(" \u2014 "),vR=a("a"),LKe=o("OPTConfig"),yKe=o(" (OPT model)"),xKe=l(),Qf=a("li"),Rae=a("strong"),$Ke=o("pegasus"),kKe=o(" \u2014 "),FR=a("a"),SKe=o("PegasusConfig"),RKe=o(" (Pegasus model)"),PKe=l(),Wf=a("li"),Pae=a("strong"),BKe=o("perceiver"),IKe=o(" \u2014 "),TR=a("a"),NKe=o("PerceiverConfig"),qKe=o(" (Perceiver model)"),jKe=l(),Hf=a("li"),Bae=a("strong"),DKe=o("plbart"),GKe=o(" \u2014 "),MR=a("a"),OKe=o("PLBartConfig"),VKe=o(" (PLBart model)"),XKe=l(),Uf=a("li"),Iae=a("strong"),zKe=o("poolformer"),QKe=o(" \u2014 "),ER=a("a"),WKe=o("PoolFormerConfig"),HKe=o(" (PoolFormer model)"),UKe=l(),Jf=a("li"),Nae=a("strong"),JKe=o("prophetnet"),YKe=o(" \u2014 "),CR=a("a"),KKe=o("ProphetNetConfig"),ZKe=o(" (ProphetNet model)"),eZe=l(),Yf=a("li"),qae=a("strong"),oZe=o("qdqbert"),rZe=o(" \u2014 "),wR=a("a"),tZe=o("QDQBertConfig"),aZe=o(" (QDQBert model)"),nZe=l(),Kf=a("li"),jae=a("strong"),sZe=o("rag"),lZe=o(" \u2014 "),AR=a("a"),iZe=o("RagConfig"),dZe=o(" (RAG model)"),cZe=l(),Zf=a("li"),Dae=a("strong"),mZe=o("realm"),fZe=o(" \u2014 "),LR=a("a"),gZe=o("RealmConfig"),hZe=o(" (REALM model)"),uZe=l(),eg=a("li"),Gae=a("strong"),pZe=o("reformer"),_Ze=o(" \u2014 "),yR=a("a"),bZe=o("ReformerConfig"),vZe=o(" (Reformer model)"),FZe=l(),og=a("li"),Oae=a("strong"),TZe=o("regnet"),MZe=o(" \u2014 "),xR=a("a"),EZe=o("RegNetConfig"),CZe=o(" (RegNet model)"),wZe=l(),rg=a("li"),Vae=a("strong"),AZe=o("rembert"),LZe=o(" \u2014 "),$R=a("a"),yZe=o("RemBertConfig"),xZe=o(" (RemBERT model)"),$Ze=l(),tg=a("li"),Xae=a("strong"),kZe=o("resnet"),SZe=o(" \u2014 "),kR=a("a"),RZe=o("ResNetConfig"),PZe=o(" (ResNet model)"),BZe=l(),ag=a("li"),zae=a("strong"),IZe=o("retribert"),NZe=o(" \u2014 "),SR=a("a"),qZe=o("RetriBertConfig"),jZe=o(" (RetriBERT model)"),DZe=l(),ng=a("li"),Qae=a("strong"),GZe=o("roberta"),OZe=o(" \u2014 "),RR=a("a"),VZe=o("RobertaConfig"),XZe=o(" (RoBERTa model)"),zZe=l(),sg=a("li"),Wae=a("strong"),QZe=o("roformer"),WZe=o(" \u2014 "),PR=a("a"),HZe=o("RoFormerConfig"),UZe=o(" (RoFormer model)"),JZe=l(),lg=a("li"),Hae=a("strong"),YZe=o("segformer"),KZe=o(" \u2014 "),BR=a("a"),ZZe=o("SegformerConfig"),eeo=o(" (SegFormer model)"),oeo=l(),ig=a("li"),Uae=a("strong"),reo=o("sew"),teo=o(" \u2014 "),IR=a("a"),aeo=o("SEWConfig"),neo=o(" (SEW model)"),seo=l(),dg=a("li"),Jae=a("strong"),leo=o("sew-d"),ieo=o(" \u2014 "),NR=a("a"),deo=o("SEWDConfig"),ceo=o(" (SEW-D model)"),meo=l(),cg=a("li"),Yae=a("strong"),feo=o("speech-encoder-decoder"),geo=o(" \u2014 "),qR=a("a"),heo=o("SpeechEncoderDecoderConfig"),ueo=o(" (Speech Encoder decoder model)"),peo=l(),mg=a("li"),Kae=a("strong"),_eo=o("speech_to_text"),beo=o(" \u2014 "),jR=a("a"),veo=o("Speech2TextConfig"),Feo=o(" (Speech2Text model)"),Teo=l(),fg=a("li"),Zae=a("strong"),Meo=o("speech_to_text_2"),Eeo=o(" \u2014 "),DR=a("a"),Ceo=o("Speech2Text2Config"),weo=o(" (Speech2Text2 model)"),Aeo=l(),gg=a("li"),ene=a("strong"),Leo=o("splinter"),yeo=o(" \u2014 "),GR=a("a"),xeo=o("SplinterConfig"),$eo=o(" (Splinter model)"),keo=l(),hg=a("li"),one=a("strong"),Seo=o("squeezebert"),Reo=o(" \u2014 "),OR=a("a"),Peo=o("SqueezeBertConfig"),Beo=o(" (SqueezeBERT model)"),Ieo=l(),ug=a("li"),rne=a("strong"),Neo=o("swin"),qeo=o(" \u2014 "),VR=a("a"),jeo=o("SwinConfig"),Deo=o(" (Swin Transformer model)"),Geo=l(),pg=a("li"),tne=a("strong"),Oeo=o("t5"),Veo=o(" \u2014 "),XR=a("a"),Xeo=o("T5Config"),zeo=o(" (T5 model)"),Qeo=l(),_g=a("li"),ane=a("strong"),Weo=o("tapas"),Heo=o(" \u2014 "),zR=a("a"),Ueo=o("TapasConfig"),Jeo=o(" (TAPAS model)"),Yeo=l(),bg=a("li"),nne=a("strong"),Keo=o("trajectory_transformer"),Zeo=o(" \u2014 "),QR=a("a"),eoo=o("TrajectoryTransformerConfig"),ooo=o(" (Trajectory Transformer model)"),roo=l(),vg=a("li"),sne=a("strong"),too=o("transfo-xl"),aoo=o(" \u2014 "),WR=a("a"),noo=o("TransfoXLConfig"),soo=o(" (Transformer-XL model)"),loo=l(),Fg=a("li"),lne=a("strong"),ioo=o("trocr"),doo=o(" \u2014 "),HR=a("a"),coo=o("TrOCRConfig"),moo=o(" (TrOCR model)"),foo=l(),Tg=a("li"),ine=a("strong"),goo=o("unispeech"),hoo=o(" \u2014 "),UR=a("a"),uoo=o("UniSpeechConfig"),poo=o(" (UniSpeech model)"),_oo=l(),Mg=a("li"),dne=a("strong"),boo=o("unispeech-sat"),voo=o(" \u2014 "),JR=a("a"),Foo=o("UniSpeechSatConfig"),Too=o(" (UniSpeechSat model)"),Moo=l(),Eg=a("li"),cne=a("strong"),Eoo=o("van"),Coo=o(" \u2014 "),YR=a("a"),woo=o("VanConfig"),Aoo=o(" (VAN model)"),Loo=l(),Cg=a("li"),mne=a("strong"),yoo=o("vilt"),xoo=o(" \u2014 "),KR=a("a"),$oo=o("ViltConfig"),koo=o(" (ViLT model)"),Soo=l(),wg=a("li"),fne=a("strong"),Roo=o("vision-encoder-decoder"),Poo=o(" \u2014 "),ZR=a("a"),Boo=o("VisionEncoderDecoderConfig"),Ioo=o(" (Vision Encoder decoder model)"),Noo=l(),Ag=a("li"),gne=a("strong"),qoo=o("vision-text-dual-encoder"),joo=o(" \u2014 "),eP=a("a"),Doo=o("VisionTextDualEncoderConfig"),Goo=o(" (VisionTextDualEncoder model)"),Ooo=l(),Lg=a("li"),hne=a("strong"),Voo=o("visual_bert"),Xoo=o(" \u2014 "),oP=a("a"),zoo=o("VisualBertConfig"),Qoo=o(" (VisualBERT model)"),Woo=l(),yg=a("li"),une=a("strong"),Hoo=o("vit"),Uoo=o(" \u2014 "),rP=a("a"),Joo=o("ViTConfig"),Yoo=o(" (ViT model)"),Koo=l(),xg=a("li"),pne=a("strong"),Zoo=o("vit_mae"),ero=o(" \u2014 "),tP=a("a"),oro=o("ViTMAEConfig"),rro=o(" (ViTMAE model)"),tro=l(),$g=a("li"),_ne=a("strong"),aro=o("wav2vec2"),nro=o(" \u2014 "),aP=a("a"),sro=o("Wav2Vec2Config"),lro=o(" (Wav2Vec2 model)"),iro=l(),kg=a("li"),bne=a("strong"),dro=o("wav2vec2-conformer"),cro=o(" \u2014 "),nP=a("a"),mro=o("Wav2Vec2ConformerConfig"),fro=o(" (Wav2Vec2-Conformer model)"),gro=l(),Sg=a("li"),vne=a("strong"),hro=o("wavlm"),uro=o(" \u2014 "),sP=a("a"),pro=o("WavLMConfig"),_ro=o(" (WavLM model)"),bro=l(),Rg=a("li"),Fne=a("strong"),vro=o("xglm"),Fro=o(" \u2014 "),lP=a("a"),Tro=o("XGLMConfig"),Mro=o(" (XGLM model)"),Ero=l(),Pg=a("li"),Tne=a("strong"),Cro=o("xlm"),wro=o(" \u2014 "),iP=a("a"),Aro=o("XLMConfig"),Lro=o(" (XLM model)"),yro=l(),Bg=a("li"),Mne=a("strong"),xro=o("xlm-prophetnet"),$ro=o(" \u2014 "),dP=a("a"),kro=o("XLMProphetNetConfig"),Sro=o(" (XLM-ProphetNet model)"),Rro=l(),Ig=a("li"),Ene=a("strong"),Pro=o("xlm-roberta"),Bro=o(" \u2014 "),cP=a("a"),Iro=o("XLMRobertaConfig"),Nro=o(" (XLM-RoBERTa model)"),qro=l(),Ng=a("li"),Cne=a("strong"),jro=o("xlm-roberta-xl"),Dro=o(" \u2014 "),mP=a("a"),Gro=o("XLMRobertaXLConfig"),Oro=o(" (XLM-RoBERTa-XL model)"),Vro=l(),qg=a("li"),wne=a("strong"),Xro=o("xlnet"),zro=o(" \u2014 "),fP=a("a"),Qro=o("XLNetConfig"),Wro=o(" (XLNet model)"),Hro=l(),jg=a("li"),Ane=a("strong"),Uro=o("yolos"),Jro=o(" \u2014 "),gP=a("a"),Yro=o("YolosConfig"),Kro=o(" (YOLOS model)"),Zro=l(),Dg=a("li"),Lne=a("strong"),eto=o("yoso"),oto=o(" \u2014 "),hP=a("a"),rto=o("YosoConfig"),tto=o(" (YOSO model)"),ato=l(),F(Gg.$$.fragment),nto=l(),Og=a("div"),F(Iy.$$.fragment),sto=l(),yne=a("p"),lto=o("Register a new configuration for this class."),QGe=l(),ki=a("h2"),Vg=a("a"),xne=a("span"),F(Ny.$$.fragment),ito=l(),$ne=a("span"),dto=o("AutoTokenizer"),WGe=l(),Ao=a("div"),F(qy.$$.fragment),cto=l(),jy=a("p"),mto=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),uP=a("a"),fto=o("AutoTokenizer.from_pretrained()"),gto=o(" class method."),hto=l(),Dy=a("p"),uto=o("This class cannot be instantiated directly using "),kne=a("code"),pto=o("__init__()"),_to=o(" (throws an error)."),bto=l(),Lr=a("div"),F(Gy.$$.fragment),vto=l(),Sne=a("p"),Fto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Tto=l(),ka=a("p"),Mto=o("The tokenizer class to instantiate is selected based on the "),Rne=a("code"),Eto=o("model_type"),Cto=o(` property of the config object (either
passed as an argument or loaded from `),Pne=a("code"),wto=o("pretrained_model_name_or_path"),Ato=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=a("code"),Lto=o("pretrained_model_name_or_path"),yto=o(":"),xto=l(),k=a("ul"),qn=a("li"),Ine=a("strong"),$to=o("albert"),kto=o(" \u2014 "),pP=a("a"),Sto=o("AlbertTokenizer"),Rto=o(" or "),_P=a("a"),Pto=o("AlbertTokenizerFast"),Bto=o(" (ALBERT model)"),Ito=l(),jn=a("li"),Nne=a("strong"),Nto=o("bart"),qto=o(" \u2014 "),bP=a("a"),jto=o("BartTokenizer"),Dto=o(" or "),vP=a("a"),Gto=o("BartTokenizerFast"),Oto=o(" (BART model)"),Vto=l(),Dn=a("li"),qne=a("strong"),Xto=o("barthez"),zto=o(" \u2014 "),FP=a("a"),Qto=o("BarthezTokenizer"),Wto=o(" or "),TP=a("a"),Hto=o("BarthezTokenizerFast"),Uto=o(" (BARThez model)"),Jto=l(),Xg=a("li"),jne=a("strong"),Yto=o("bartpho"),Kto=o(" \u2014 "),MP=a("a"),Zto=o("BartphoTokenizer"),eao=o(" (BARTpho model)"),oao=l(),Gn=a("li"),Dne=a("strong"),rao=o("bert"),tao=o(" \u2014 "),EP=a("a"),aao=o("BertTokenizer"),nao=o(" or "),CP=a("a"),sao=o("BertTokenizerFast"),lao=o(" (BERT model)"),iao=l(),zg=a("li"),Gne=a("strong"),dao=o("bert-generation"),cao=o(" \u2014 "),wP=a("a"),mao=o("BertGenerationTokenizer"),fao=o(" (Bert Generation model)"),gao=l(),Qg=a("li"),One=a("strong"),hao=o("bert-japanese"),uao=o(" \u2014 "),AP=a("a"),pao=o("BertJapaneseTokenizer"),_ao=o(" (BertJapanese model)"),bao=l(),Wg=a("li"),Vne=a("strong"),vao=o("bertweet"),Fao=o(" \u2014 "),LP=a("a"),Tao=o("BertweetTokenizer"),Mao=o(" (BERTweet model)"),Eao=l(),On=a("li"),Xne=a("strong"),Cao=o("big_bird"),wao=o(" \u2014 "),yP=a("a"),Aao=o("BigBirdTokenizer"),Lao=o(" or "),xP=a("a"),yao=o("BigBirdTokenizerFast"),xao=o(" (BigBird model)"),$ao=l(),Vn=a("li"),zne=a("strong"),kao=o("bigbird_pegasus"),Sao=o(" \u2014 "),$P=a("a"),Rao=o("PegasusTokenizer"),Pao=o(" or "),kP=a("a"),Bao=o("PegasusTokenizerFast"),Iao=o(" (BigBird-Pegasus model)"),Nao=l(),Xn=a("li"),Qne=a("strong"),qao=o("blenderbot"),jao=o(" \u2014 "),SP=a("a"),Dao=o("BlenderbotTokenizer"),Gao=o(" or "),RP=a("a"),Oao=o("BlenderbotTokenizerFast"),Vao=o(" (Blenderbot model)"),Xao=l(),Hg=a("li"),Wne=a("strong"),zao=o("blenderbot-small"),Qao=o(" \u2014 "),PP=a("a"),Wao=o("BlenderbotSmallTokenizer"),Hao=o(" (BlenderbotSmall model)"),Uao=l(),Ug=a("li"),Hne=a("strong"),Jao=o("bloom"),Yao=o(" \u2014 "),BP=a("a"),Kao=o("BloomTokenizerFast"),Zao=o(" (BLOOM model)"),eno=l(),Jg=a("li"),Une=a("strong"),ono=o("byt5"),rno=o(" \u2014 "),IP=a("a"),tno=o("ByT5Tokenizer"),ano=o(" (ByT5 model)"),nno=l(),zn=a("li"),Jne=a("strong"),sno=o("camembert"),lno=o(" \u2014 "),NP=a("a"),ino=o("CamembertTokenizer"),dno=o(" or "),qP=a("a"),cno=o("CamembertTokenizerFast"),mno=o(" (CamemBERT model)"),fno=l(),Yg=a("li"),Yne=a("strong"),gno=o("canine"),hno=o(" \u2014 "),jP=a("a"),uno=o("CanineTokenizer"),pno=o(" (CANINE model)"),_no=l(),Qn=a("li"),Kne=a("strong"),bno=o("clip"),vno=o(" \u2014 "),DP=a("a"),Fno=o("CLIPTokenizer"),Tno=o(" or "),GP=a("a"),Mno=o("CLIPTokenizerFast"),Eno=o(" (CLIP model)"),Cno=l(),Wn=a("li"),Zne=a("strong"),wno=o("convbert"),Ano=o(" \u2014 "),OP=a("a"),Lno=o("ConvBertTokenizer"),yno=o(" or "),VP=a("a"),xno=o("ConvBertTokenizerFast"),$no=o(" (ConvBERT model)"),kno=l(),Hn=a("li"),ese=a("strong"),Sno=o("cpm"),Rno=o(" \u2014 "),XP=a("a"),Pno=o("CpmTokenizer"),Bno=o(" or "),zP=a("a"),Ino=o("CpmTokenizerFast"),Nno=o(" (CPM model)"),qno=l(),Kg=a("li"),ose=a("strong"),jno=o("ctrl"),Dno=o(" \u2014 "),QP=a("a"),Gno=o("CTRLTokenizer"),Ono=o(" (CTRL model)"),Vno=l(),Un=a("li"),rse=a("strong"),Xno=o("data2vec-text"),zno=o(" \u2014 "),WP=a("a"),Qno=o("RobertaTokenizer"),Wno=o(" or "),HP=a("a"),Hno=o("RobertaTokenizerFast"),Uno=o(" (Data2VecText model)"),Jno=l(),Jn=a("li"),tse=a("strong"),Yno=o("deberta"),Kno=o(" \u2014 "),UP=a("a"),Zno=o("DebertaTokenizer"),eso=o(" or "),JP=a("a"),oso=o("DebertaTokenizerFast"),rso=o(" (DeBERTa model)"),tso=l(),Yn=a("li"),ase=a("strong"),aso=o("deberta-v2"),nso=o(" \u2014 "),YP=a("a"),sso=o("DebertaV2Tokenizer"),lso=o(" or "),KP=a("a"),iso=o("DebertaV2TokenizerFast"),dso=o(" (DeBERTa-v2 model)"),cso=l(),Kn=a("li"),nse=a("strong"),mso=o("distilbert"),fso=o(" \u2014 "),ZP=a("a"),gso=o("DistilBertTokenizer"),hso=o(" or "),eB=a("a"),uso=o("DistilBertTokenizerFast"),pso=o(" (DistilBERT model)"),_so=l(),Zn=a("li"),sse=a("strong"),bso=o("dpr"),vso=o(" \u2014 "),oB=a("a"),Fso=o("DPRQuestionEncoderTokenizer"),Tso=o(" or "),rB=a("a"),Mso=o("DPRQuestionEncoderTokenizerFast"),Eso=o(" (DPR model)"),Cso=l(),es=a("li"),lse=a("strong"),wso=o("electra"),Aso=o(" \u2014 "),tB=a("a"),Lso=o("ElectraTokenizer"),yso=o(" or "),aB=a("a"),xso=o("ElectraTokenizerFast"),$so=o(" (ELECTRA model)"),kso=l(),Zg=a("li"),ise=a("strong"),Sso=o("flaubert"),Rso=o(" \u2014 "),nB=a("a"),Pso=o("FlaubertTokenizer"),Bso=o(" (FlauBERT model)"),Iso=l(),os=a("li"),dse=a("strong"),Nso=o("fnet"),qso=o(" \u2014 "),sB=a("a"),jso=o("FNetTokenizer"),Dso=o(" or "),lB=a("a"),Gso=o("FNetTokenizerFast"),Oso=o(" (FNet model)"),Vso=l(),eh=a("li"),cse=a("strong"),Xso=o("fsmt"),zso=o(" \u2014 "),iB=a("a"),Qso=o("FSMTTokenizer"),Wso=o(" (FairSeq Machine-Translation model)"),Hso=l(),rs=a("li"),mse=a("strong"),Uso=o("funnel"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("FunnelTokenizer"),Kso=o(" or "),cB=a("a"),Zso=o("FunnelTokenizerFast"),elo=o(" (Funnel Transformer model)"),olo=l(),ts=a("li"),fse=a("strong"),rlo=o("gpt2"),tlo=o(" \u2014 "),mB=a("a"),alo=o("GPT2Tokenizer"),nlo=o(" or "),fB=a("a"),slo=o("GPT2TokenizerFast"),llo=o(" (OpenAI GPT-2 model)"),ilo=l(),as=a("li"),gse=a("strong"),dlo=o("gpt_neo"),clo=o(" \u2014 "),gB=a("a"),mlo=o("GPT2Tokenizer"),flo=o(" or "),hB=a("a"),glo=o("GPT2TokenizerFast"),hlo=o(" (GPT Neo model)"),ulo=l(),oh=a("li"),hse=a("strong"),plo=o("gpt_neox"),_lo=o(" \u2014 "),uB=a("a"),blo=o("GPTNeoXTokenizerFast"),vlo=o(" (GPT NeoX model)"),Flo=l(),ns=a("li"),use=a("strong"),Tlo=o("gptj"),Mlo=o(" \u2014 "),pB=a("a"),Elo=o("GPT2Tokenizer"),Clo=o(" or "),_B=a("a"),wlo=o("GPT2TokenizerFast"),Alo=o(" (GPT-J model)"),Llo=l(),ss=a("li"),pse=a("strong"),ylo=o("herbert"),xlo=o(" \u2014 "),bB=a("a"),$lo=o("HerbertTokenizer"),klo=o(" or "),vB=a("a"),Slo=o("HerbertTokenizerFast"),Rlo=o(" (HerBERT model)"),Plo=l(),rh=a("li"),_se=a("strong"),Blo=o("hubert"),Ilo=o(" \u2014 "),FB=a("a"),Nlo=o("Wav2Vec2CTCTokenizer"),qlo=o(" (Hubert model)"),jlo=l(),ls=a("li"),bse=a("strong"),Dlo=o("ibert"),Glo=o(" \u2014 "),TB=a("a"),Olo=o("RobertaTokenizer"),Vlo=o(" or "),MB=a("a"),Xlo=o("RobertaTokenizerFast"),zlo=o(" (I-BERT model)"),Qlo=l(),is=a("li"),vse=a("strong"),Wlo=o("layoutlm"),Hlo=o(" \u2014 "),EB=a("a"),Ulo=o("LayoutLMTokenizer"),Jlo=o(" or "),CB=a("a"),Ylo=o("LayoutLMTokenizerFast"),Klo=o(" (LayoutLM model)"),Zlo=l(),ds=a("li"),Fse=a("strong"),eio=o("layoutlmv2"),oio=o(" \u2014 "),wB=a("a"),rio=o("LayoutLMv2Tokenizer"),tio=o(" or "),AB=a("a"),aio=o("LayoutLMv2TokenizerFast"),nio=o(" (LayoutLMv2 model)"),sio=l(),cs=a("li"),Tse=a("strong"),lio=o("layoutlmv3"),iio=o(" \u2014 "),LB=a("a"),dio=o("LayoutLMv3Tokenizer"),cio=o(" or "),yB=a("a"),mio=o("LayoutLMv3TokenizerFast"),fio=o(" (LayoutLMv3 model)"),gio=l(),ms=a("li"),Mse=a("strong"),hio=o("layoutxlm"),uio=o(" \u2014 "),xB=a("a"),pio=o("LayoutXLMTokenizer"),_io=o(" or "),$B=a("a"),bio=o("LayoutXLMTokenizerFast"),vio=o(" (LayoutXLM model)"),Fio=l(),fs=a("li"),Ese=a("strong"),Tio=o("led"),Mio=o(" \u2014 "),kB=a("a"),Eio=o("LEDTokenizer"),Cio=o(" or "),SB=a("a"),wio=o("LEDTokenizerFast"),Aio=o(" (LED model)"),Lio=l(),gs=a("li"),Cse=a("strong"),yio=o("longformer"),xio=o(" \u2014 "),RB=a("a"),$io=o("LongformerTokenizer"),kio=o(" or "),PB=a("a"),Sio=o("LongformerTokenizerFast"),Rio=o(" (Longformer model)"),Pio=l(),hs=a("li"),wse=a("strong"),Bio=o("longt5"),Iio=o(" \u2014 "),BB=a("a"),Nio=o("T5Tokenizer"),qio=o(" or "),IB=a("a"),jio=o("T5TokenizerFast"),Dio=o(" (LongT5 model)"),Gio=l(),th=a("li"),Ase=a("strong"),Oio=o("luke"),Vio=o(" \u2014 "),NB=a("a"),Xio=o("LukeTokenizer"),zio=o(" (LUKE model)"),Qio=l(),us=a("li"),Lse=a("strong"),Wio=o("lxmert"),Hio=o(" \u2014 "),qB=a("a"),Uio=o("LxmertTokenizer"),Jio=o(" or "),jB=a("a"),Yio=o("LxmertTokenizerFast"),Kio=o(" (LXMERT model)"),Zio=l(),ah=a("li"),yse=a("strong"),edo=o("m2m_100"),odo=o(" \u2014 "),DB=a("a"),rdo=o("M2M100Tokenizer"),tdo=o(" (M2M100 model)"),ado=l(),nh=a("li"),xse=a("strong"),ndo=o("marian"),sdo=o(" \u2014 "),GB=a("a"),ldo=o("MarianTokenizer"),ido=o(" (Marian model)"),ddo=l(),ps=a("li"),$se=a("strong"),cdo=o("mbart"),mdo=o(" \u2014 "),OB=a("a"),fdo=o("MBartTokenizer"),gdo=o(" or "),VB=a("a"),hdo=o("MBartTokenizerFast"),udo=o(" (mBART model)"),pdo=l(),_s=a("li"),kse=a("strong"),_do=o("mbart50"),bdo=o(" \u2014 "),XB=a("a"),vdo=o("MBart50Tokenizer"),Fdo=o(" or "),zB=a("a"),Tdo=o("MBart50TokenizerFast"),Mdo=o(" (mBART-50 model)"),Edo=l(),bs=a("li"),Sse=a("strong"),Cdo=o("megatron-bert"),wdo=o(" \u2014 "),QB=a("a"),Ado=o("BertTokenizer"),Ldo=o(" or "),WB=a("a"),ydo=o("BertTokenizerFast"),xdo=o(" (Megatron-BERT model)"),$do=l(),sh=a("li"),Rse=a("strong"),kdo=o("mluke"),Sdo=o(" \u2014 "),HB=a("a"),Rdo=o("MLukeTokenizer"),Pdo=o(" (mLUKE model)"),Bdo=l(),vs=a("li"),Pse=a("strong"),Ido=o("mobilebert"),Ndo=o(" \u2014 "),UB=a("a"),qdo=o("MobileBertTokenizer"),jdo=o(" or "),JB=a("a"),Ddo=o("MobileBertTokenizerFast"),Gdo=o(" (MobileBERT model)"),Odo=l(),Fs=a("li"),Bse=a("strong"),Vdo=o("mpnet"),Xdo=o(" \u2014 "),YB=a("a"),zdo=o("MPNetTokenizer"),Qdo=o(" or "),KB=a("a"),Wdo=o("MPNetTokenizerFast"),Hdo=o(" (MPNet model)"),Udo=l(),Ts=a("li"),Ise=a("strong"),Jdo=o("mt5"),Ydo=o(" \u2014 "),ZB=a("a"),Kdo=o("MT5Tokenizer"),Zdo=o(" or "),eI=a("a"),eco=o("MT5TokenizerFast"),oco=o(" (MT5 model)"),rco=l(),Ms=a("li"),Nse=a("strong"),tco=o("nezha"),aco=o(" \u2014 "),oI=a("a"),nco=o("BertTokenizer"),sco=o(" or "),rI=a("a"),lco=o("BertTokenizerFast"),ico=o(" (Nezha model)"),dco=l(),Es=a("li"),qse=a("strong"),cco=o("nystromformer"),mco=o(" \u2014 "),tI=a("a"),fco=o("AlbertTokenizer"),gco=o(" or "),aI=a("a"),hco=o("AlbertTokenizerFast"),uco=o(" (Nystr\xF6mformer model)"),pco=l(),Cs=a("li"),jse=a("strong"),_co=o("openai-gpt"),bco=o(" \u2014 "),nI=a("a"),vco=o("OpenAIGPTTokenizer"),Fco=o(" or "),sI=a("a"),Tco=o("OpenAIGPTTokenizerFast"),Mco=o(" (OpenAI GPT model)"),Eco=l(),lh=a("li"),Dse=a("strong"),Cco=o("opt"),wco=o(" \u2014 "),lI=a("a"),Aco=o("GPT2Tokenizer"),Lco=o(" (OPT model)"),yco=l(),ws=a("li"),Gse=a("strong"),xco=o("pegasus"),$co=o(" \u2014 "),iI=a("a"),kco=o("PegasusTokenizer"),Sco=o(" or "),dI=a("a"),Rco=o("PegasusTokenizerFast"),Pco=o(" (Pegasus model)"),Bco=l(),ih=a("li"),Ose=a("strong"),Ico=o("perceiver"),Nco=o(" \u2014 "),cI=a("a"),qco=o("PerceiverTokenizer"),jco=o(" (Perceiver model)"),Dco=l(),dh=a("li"),Vse=a("strong"),Gco=o("phobert"),Oco=o(" \u2014 "),mI=a("a"),Vco=o("PhobertTokenizer"),Xco=o(" (PhoBERT model)"),zco=l(),ch=a("li"),Xse=a("strong"),Qco=o("plbart"),Wco=o(" \u2014 "),fI=a("a"),Hco=o("PLBartTokenizer"),Uco=o(" (PLBart model)"),Jco=l(),mh=a("li"),zse=a("strong"),Yco=o("prophetnet"),Kco=o(" \u2014 "),gI=a("a"),Zco=o("ProphetNetTokenizer"),emo=o(" (ProphetNet model)"),omo=l(),As=a("li"),Qse=a("strong"),rmo=o("qdqbert"),tmo=o(" \u2014 "),hI=a("a"),amo=o("BertTokenizer"),nmo=o(" or "),uI=a("a"),smo=o("BertTokenizerFast"),lmo=o(" (QDQBert model)"),imo=l(),fh=a("li"),Wse=a("strong"),dmo=o("rag"),cmo=o(" \u2014 "),pI=a("a"),mmo=o("RagTokenizer"),fmo=o(" (RAG model)"),gmo=l(),Ls=a("li"),Hse=a("strong"),hmo=o("realm"),umo=o(" \u2014 "),_I=a("a"),pmo=o("RealmTokenizer"),_mo=o(" or "),bI=a("a"),bmo=o("RealmTokenizerFast"),vmo=o(" (REALM model)"),Fmo=l(),ys=a("li"),Use=a("strong"),Tmo=o("reformer"),Mmo=o(" \u2014 "),vI=a("a"),Emo=o("ReformerTokenizer"),Cmo=o(" or "),FI=a("a"),wmo=o("ReformerTokenizerFast"),Amo=o(" (Reformer model)"),Lmo=l(),xs=a("li"),Jse=a("strong"),ymo=o("rembert"),xmo=o(" \u2014 "),TI=a("a"),$mo=o("RemBertTokenizer"),kmo=o(" or "),MI=a("a"),Smo=o("RemBertTokenizerFast"),Rmo=o(" (RemBERT model)"),Pmo=l(),$s=a("li"),Yse=a("strong"),Bmo=o("retribert"),Imo=o(" \u2014 "),EI=a("a"),Nmo=o("RetriBertTokenizer"),qmo=o(" or "),CI=a("a"),jmo=o("RetriBertTokenizerFast"),Dmo=o(" (RetriBERT model)"),Gmo=l(),ks=a("li"),Kse=a("strong"),Omo=o("roberta"),Vmo=o(" \u2014 "),wI=a("a"),Xmo=o("RobertaTokenizer"),zmo=o(" or "),AI=a("a"),Qmo=o("RobertaTokenizerFast"),Wmo=o(" (RoBERTa model)"),Hmo=l(),Ss=a("li"),Zse=a("strong"),Umo=o("roformer"),Jmo=o(" \u2014 "),LI=a("a"),Ymo=o("RoFormerTokenizer"),Kmo=o(" or "),yI=a("a"),Zmo=o("RoFormerTokenizerFast"),efo=o(" (RoFormer model)"),ofo=l(),gh=a("li"),ele=a("strong"),rfo=o("speech_to_text"),tfo=o(" \u2014 "),xI=a("a"),afo=o("Speech2TextTokenizer"),nfo=o(" (Speech2Text model)"),sfo=l(),hh=a("li"),ole=a("strong"),lfo=o("speech_to_text_2"),ifo=o(" \u2014 "),$I=a("a"),dfo=o("Speech2Text2Tokenizer"),cfo=o(" (Speech2Text2 model)"),mfo=l(),Rs=a("li"),rle=a("strong"),ffo=o("splinter"),gfo=o(" \u2014 "),kI=a("a"),hfo=o("SplinterTokenizer"),ufo=o(" or "),SI=a("a"),pfo=o("SplinterTokenizerFast"),_fo=o(" (Splinter model)"),bfo=l(),Ps=a("li"),tle=a("strong"),vfo=o("squeezebert"),Ffo=o(" \u2014 "),RI=a("a"),Tfo=o("SqueezeBertTokenizer"),Mfo=o(" or "),PI=a("a"),Efo=o("SqueezeBertTokenizerFast"),Cfo=o(" (SqueezeBERT model)"),wfo=l(),Bs=a("li"),ale=a("strong"),Afo=o("t5"),Lfo=o(" \u2014 "),BI=a("a"),yfo=o("T5Tokenizer"),xfo=o(" or "),II=a("a"),$fo=o("T5TokenizerFast"),kfo=o(" (T5 model)"),Sfo=l(),uh=a("li"),nle=a("strong"),Rfo=o("tapas"),Pfo=o(" \u2014 "),NI=a("a"),Bfo=o("TapasTokenizer"),Ifo=o(" (TAPAS model)"),Nfo=l(),ph=a("li"),sle=a("strong"),qfo=o("tapex"),jfo=o(" \u2014 "),qI=a("a"),Dfo=o("TapexTokenizer"),Gfo=o(" (TAPEX model)"),Ofo=l(),_h=a("li"),lle=a("strong"),Vfo=o("transfo-xl"),Xfo=o(" \u2014 "),jI=a("a"),zfo=o("TransfoXLTokenizer"),Qfo=o(" (Transformer-XL model)"),Wfo=l(),Is=a("li"),ile=a("strong"),Hfo=o("vilt"),Ufo=o(" \u2014 "),DI=a("a"),Jfo=o("BertTokenizer"),Yfo=o(" or "),GI=a("a"),Kfo=o("BertTokenizerFast"),Zfo=o(" (ViLT model)"),ego=l(),Ns=a("li"),dle=a("strong"),ogo=o("visual_bert"),rgo=o(" \u2014 "),OI=a("a"),tgo=o("BertTokenizer"),ago=o(" or "),VI=a("a"),ngo=o("BertTokenizerFast"),sgo=o(" (VisualBERT model)"),lgo=l(),bh=a("li"),cle=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),XI=a("a"),cgo=o("Wav2Vec2CTCTokenizer"),mgo=o(" (Wav2Vec2 model)"),fgo=l(),vh=a("li"),mle=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),zI=a("a"),ugo=o("Wav2Vec2CTCTokenizer"),pgo=o(" (Wav2Vec2-Conformer model)"),_go=l(),Fh=a("li"),fle=a("strong"),bgo=o("wav2vec2_phoneme"),vgo=o(" \u2014 "),QI=a("a"),Fgo=o("Wav2Vec2PhonemeCTCTokenizer"),Tgo=o(" (Wav2Vec2Phoneme model)"),Mgo=l(),qs=a("li"),gle=a("strong"),Ego=o("xglm"),Cgo=o(" \u2014 "),WI=a("a"),wgo=o("XGLMTokenizer"),Ago=o(" or "),HI=a("a"),Lgo=o("XGLMTokenizerFast"),ygo=o(" (XGLM model)"),xgo=l(),Th=a("li"),hle=a("strong"),$go=o("xlm"),kgo=o(" \u2014 "),UI=a("a"),Sgo=o("XLMTokenizer"),Rgo=o(" (XLM model)"),Pgo=l(),Mh=a("li"),ule=a("strong"),Bgo=o("xlm-prophetnet"),Igo=o(" \u2014 "),JI=a("a"),Ngo=o("XLMProphetNetTokenizer"),qgo=o(" (XLM-ProphetNet model)"),jgo=l(),js=a("li"),ple=a("strong"),Dgo=o("xlm-roberta"),Ggo=o(" \u2014 "),YI=a("a"),Ogo=o("XLMRobertaTokenizer"),Vgo=o(" or "),KI=a("a"),Xgo=o("XLMRobertaTokenizerFast"),zgo=o(" (XLM-RoBERTa model)"),Qgo=l(),Ds=a("li"),_le=a("strong"),Wgo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),ZI=a("a"),Ugo=o("RobertaTokenizer"),Jgo=o(" or "),eN=a("a"),Ygo=o("RobertaTokenizerFast"),Kgo=o(" (XLM-RoBERTa-XL model)"),Zgo=l(),Gs=a("li"),ble=a("strong"),eho=o("xlnet"),oho=o(" \u2014 "),oN=a("a"),rho=o("XLNetTokenizer"),tho=o(" or "),rN=a("a"),aho=o("XLNetTokenizerFast"),nho=o(" (XLNet model)"),sho=l(),Os=a("li"),vle=a("strong"),lho=o("yoso"),iho=o(" \u2014 "),tN=a("a"),dho=o("AlbertTokenizer"),cho=o(" or "),aN=a("a"),mho=o("AlbertTokenizerFast"),fho=o(" (YOSO model)"),gho=l(),F(Eh.$$.fragment),hho=l(),Ch=a("div"),F(Oy.$$.fragment),uho=l(),Fle=a("p"),pho=o("Register a new tokenizer in this mapping."),HGe=l(),Si=a("h2"),wh=a("a"),Tle=a("span"),F(Vy.$$.fragment),_ho=l(),Mle=a("span"),bho=o("AutoFeatureExtractor"),UGe=l(),Lo=a("div"),F(Xy.$$.fragment),vho=l(),zy=a("p"),Fho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=a("a"),Tho=o("AutoFeatureExtractor.from_pretrained()"),Mho=o(" class method."),Eho=l(),Qy=a("p"),Cho=o("This class cannot be instantiated directly using "),Ele=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),He=a("div"),F(Wy.$$.fragment),yho=l(),Cle=a("p"),xho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),$ho=l(),Sa=a("p"),kho=o("The feature extractor class to instantiate is selected based on the "),wle=a("code"),Sho=o("model_type"),Rho=o(` property of the config object
(either passed as an argument or loaded from `),Ale=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),Y=a("ul"),Ah=a("li"),yle=a("strong"),jho=o("beit"),Dho=o(" \u2014 "),sN=a("a"),Gho=o("BeitFeatureExtractor"),Oho=o(" (BEiT model)"),Vho=l(),Lh=a("li"),xle=a("strong"),Xho=o("clip"),zho=o(" \u2014 "),lN=a("a"),Qho=o("CLIPFeatureExtractor"),Who=o(" (CLIP model)"),Hho=l(),yh=a("li"),$le=a("strong"),Uho=o("convnext"),Jho=o(" \u2014 "),iN=a("a"),Yho=o("ConvNextFeatureExtractor"),Kho=o(" (ConvNeXT model)"),Zho=l(),xh=a("li"),kle=a("strong"),euo=o("cvt"),ouo=o(" \u2014 "),dN=a("a"),ruo=o("ConvNextFeatureExtractor"),tuo=o(" (CvT model)"),auo=l(),$h=a("li"),Sle=a("strong"),nuo=o("data2vec-audio"),suo=o(" \u2014 "),cN=a("a"),luo=o("Wav2Vec2FeatureExtractor"),iuo=o(" (Data2VecAudio model)"),duo=l(),kh=a("li"),Rle=a("strong"),cuo=o("data2vec-vision"),muo=o(" \u2014 "),mN=a("a"),fuo=o("BeitFeatureExtractor"),guo=o(" (Data2VecVision model)"),huo=l(),Sh=a("li"),Ple=a("strong"),uuo=o("deit"),puo=o(" \u2014 "),fN=a("a"),_uo=o("DeiTFeatureExtractor"),buo=o(" (DeiT model)"),vuo=l(),Rh=a("li"),Ble=a("strong"),Fuo=o("detr"),Tuo=o(" \u2014 "),gN=a("a"),Muo=o("DetrFeatureExtractor"),Euo=o(" (DETR model)"),Cuo=l(),Ph=a("li"),Ile=a("strong"),wuo=o("dpt"),Auo=o(" \u2014 "),hN=a("a"),Luo=o("DPTFeatureExtractor"),yuo=o(" (DPT model)"),xuo=l(),Bh=a("li"),Nle=a("strong"),$uo=o("flava"),kuo=o(" \u2014 "),uN=a("a"),Suo=o("FlavaFeatureExtractor"),Ruo=o(" (FLAVA model)"),Puo=l(),Ih=a("li"),qle=a("strong"),Buo=o("glpn"),Iuo=o(" \u2014 "),pN=a("a"),Nuo=o("GLPNFeatureExtractor"),quo=o(" (GLPN model)"),juo=l(),Nh=a("li"),jle=a("strong"),Duo=o("hubert"),Guo=o(" \u2014 "),_N=a("a"),Ouo=o("Wav2Vec2FeatureExtractor"),Vuo=o(" (Hubert model)"),Xuo=l(),qh=a("li"),Dle=a("strong"),zuo=o("imagegpt"),Quo=o(" \u2014 "),bN=a("a"),Wuo=o("ImageGPTFeatureExtractor"),Huo=o(" (ImageGPT model)"),Uuo=l(),jh=a("li"),Gle=a("strong"),Juo=o("layoutlmv2"),Yuo=o(" \u2014 "),vN=a("a"),Kuo=o("LayoutLMv2FeatureExtractor"),Zuo=o(" (LayoutLMv2 model)"),epo=l(),Dh=a("li"),Ole=a("strong"),opo=o("layoutlmv3"),rpo=o(" \u2014 "),FN=a("a"),tpo=o("LayoutLMv3FeatureExtractor"),apo=o(" (LayoutLMv3 model)"),npo=l(),Gh=a("li"),Vle=a("strong"),spo=o("levit"),lpo=o(" \u2014 "),TN=a("a"),ipo=o("LevitFeatureExtractor"),dpo=o(" (LeViT model)"),cpo=l(),Oh=a("li"),Xle=a("strong"),mpo=o("maskformer"),fpo=o(" \u2014 "),MN=a("a"),gpo=o("MaskFormerFeatureExtractor"),hpo=o(" (MaskFormer model)"),upo=l(),Vh=a("li"),zle=a("strong"),ppo=o("mctct"),_po=o(" \u2014 "),EN=a("a"),bpo=o("MCTCTFeatureExtractor"),vpo=o(" (M-CTC-T model)"),Fpo=l(),Xh=a("li"),Qle=a("strong"),Tpo=o("perceiver"),Mpo=o(" \u2014 "),CN=a("a"),Epo=o("PerceiverFeatureExtractor"),Cpo=o(" (Perceiver model)"),wpo=l(),zh=a("li"),Wle=a("strong"),Apo=o("poolformer"),Lpo=o(" \u2014 "),wN=a("a"),ypo=o("PoolFormerFeatureExtractor"),xpo=o(" (PoolFormer model)"),$po=l(),Qh=a("li"),Hle=a("strong"),kpo=o("regnet"),Spo=o(" \u2014 "),AN=a("a"),Rpo=o("ConvNextFeatureExtractor"),Ppo=o(" (RegNet model)"),Bpo=l(),Wh=a("li"),Ule=a("strong"),Ipo=o("resnet"),Npo=o(" \u2014 "),LN=a("a"),qpo=o("ConvNextFeatureExtractor"),jpo=o(" (ResNet model)"),Dpo=l(),Hh=a("li"),Jle=a("strong"),Gpo=o("segformer"),Opo=o(" \u2014 "),yN=a("a"),Vpo=o("SegformerFeatureExtractor"),Xpo=o(" (SegFormer model)"),zpo=l(),Uh=a("li"),Yle=a("strong"),Qpo=o("speech_to_text"),Wpo=o(" \u2014 "),xN=a("a"),Hpo=o("Speech2TextFeatureExtractor"),Upo=o(" (Speech2Text model)"),Jpo=l(),Jh=a("li"),Kle=a("strong"),Ypo=o("swin"),Kpo=o(" \u2014 "),$N=a("a"),Zpo=o("ViTFeatureExtractor"),e_o=o(" (Swin Transformer model)"),o_o=l(),Yh=a("li"),Zle=a("strong"),r_o=o("van"),t_o=o(" \u2014 "),kN=a("a"),a_o=o("ConvNextFeatureExtractor"),n_o=o(" (VAN model)"),s_o=l(),Kh=a("li"),eie=a("strong"),l_o=o("vilt"),i_o=o(" \u2014 "),SN=a("a"),d_o=o("ViltFeatureExtractor"),c_o=o(" (ViLT model)"),m_o=l(),Zh=a("li"),oie=a("strong"),f_o=o("vit"),g_o=o(" \u2014 "),RN=a("a"),h_o=o("ViTFeatureExtractor"),u_o=o(" (ViT model)"),p_o=l(),eu=a("li"),rie=a("strong"),__o=o("vit_mae"),b_o=o(" \u2014 "),PN=a("a"),v_o=o("ViTFeatureExtractor"),F_o=o(" (ViTMAE model)"),T_o=l(),ou=a("li"),tie=a("strong"),M_o=o("wav2vec2"),E_o=o(" \u2014 "),BN=a("a"),C_o=o("Wav2Vec2FeatureExtractor"),w_o=o(" (Wav2Vec2 model)"),A_o=l(),ru=a("li"),aie=a("strong"),L_o=o("wav2vec2-conformer"),y_o=o(" \u2014 "),IN=a("a"),x_o=o("Wav2Vec2FeatureExtractor"),$_o=o(" (Wav2Vec2-Conformer model)"),k_o=l(),tu=a("li"),nie=a("strong"),S_o=o("yolos"),R_o=o(" \u2014 "),NN=a("a"),P_o=o("YolosFeatureExtractor"),B_o=o(" (YOLOS model)"),I_o=l(),F(au.$$.fragment),N_o=l(),F(nu.$$.fragment),q_o=l(),su=a("div"),F(Hy.$$.fragment),j_o=l(),sie=a("p"),D_o=o("Register a new feature extractor for this class."),JGe=l(),Ri=a("h2"),lu=a("a"),lie=a("span"),F(Uy.$$.fragment),G_o=l(),iie=a("span"),O_o=o("AutoProcessor"),YGe=l(),yo=a("div"),F(Jy.$$.fragment),V_o=l(),Yy=a("p"),X_o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=a("a"),z_o=o("AutoProcessor.from_pretrained()"),Q_o=o(" class method."),W_o=l(),Ky=a("p"),H_o=o("This class cannot be instantiated directly using "),die=a("code"),U_o=o("__init__()"),J_o=o(" (throws an error)."),Y_o=l(),Ue=a("div"),F(Zy.$$.fragment),K_o=l(),cie=a("p"),Z_o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),e2o=l(),Pi=a("p"),o2o=o("The processor class to instantiate is selected based on the "),mie=a("code"),r2o=o("model_type"),t2o=o(` property of the config object (either
passed as an argument or loaded from `),fie=a("code"),a2o=o("pretrained_model_name_or_path"),n2o=o(" if possible):"),s2o=l(),he=a("ul"),iu=a("li"),gie=a("strong"),l2o=o("clip"),i2o=o(" \u2014 "),jN=a("a"),d2o=o("CLIPProcessor"),c2o=o(" (CLIP model)"),m2o=l(),du=a("li"),hie=a("strong"),f2o=o("flava"),g2o=o(" \u2014 "),uie=a("code"),h2o=o("FLAVAProcessor"),u2o=o(" (FLAVA model)"),p2o=l(),cu=a("li"),pie=a("strong"),_2o=o("layoutlmv2"),b2o=o(" \u2014 "),DN=a("a"),v2o=o("LayoutLMv2Processor"),F2o=o(" (LayoutLMv2 model)"),T2o=l(),mu=a("li"),_ie=a("strong"),M2o=o("layoutlmv3"),E2o=o(" \u2014 "),GN=a("a"),C2o=o("LayoutLMv3Processor"),w2o=o(" (LayoutLMv3 model)"),A2o=l(),fu=a("li"),bie=a("strong"),L2o=o("layoutxlm"),y2o=o(" \u2014 "),ON=a("a"),x2o=o("LayoutXLMProcessor"),$2o=o(" (LayoutXLM model)"),k2o=l(),gu=a("li"),vie=a("strong"),S2o=o("sew"),R2o=o(" \u2014 "),VN=a("a"),P2o=o("Wav2Vec2Processor"),B2o=o(" (SEW model)"),I2o=l(),hu=a("li"),Fie=a("strong"),N2o=o("sew-d"),q2o=o(" \u2014 "),XN=a("a"),j2o=o("Wav2Vec2Processor"),D2o=o(" (SEW-D model)"),G2o=l(),uu=a("li"),Tie=a("strong"),O2o=o("speech_to_text"),V2o=o(" \u2014 "),zN=a("a"),X2o=o("Speech2TextProcessor"),z2o=o(" (Speech2Text model)"),Q2o=l(),pu=a("li"),Mie=a("strong"),W2o=o("speech_to_text_2"),H2o=o(" \u2014 "),QN=a("a"),U2o=o("Speech2Text2Processor"),J2o=o(" (Speech2Text2 model)"),Y2o=l(),_u=a("li"),Eie=a("strong"),K2o=o("trocr"),Z2o=o(" \u2014 "),WN=a("a"),ebo=o("TrOCRProcessor"),obo=o(" (TrOCR model)"),rbo=l(),bu=a("li"),Cie=a("strong"),tbo=o("unispeech"),abo=o(" \u2014 "),HN=a("a"),nbo=o("Wav2Vec2Processor"),sbo=o(" (UniSpeech model)"),lbo=l(),vu=a("li"),wie=a("strong"),ibo=o("unispeech-sat"),dbo=o(" \u2014 "),UN=a("a"),cbo=o("Wav2Vec2Processor"),mbo=o(" (UniSpeechSat model)"),fbo=l(),Fu=a("li"),Aie=a("strong"),gbo=o("vilt"),hbo=o(" \u2014 "),JN=a("a"),ubo=o("ViltProcessor"),pbo=o(" (ViLT model)"),_bo=l(),Tu=a("li"),Lie=a("strong"),bbo=o("vision-text-dual-encoder"),vbo=o(" \u2014 "),YN=a("a"),Fbo=o("VisionTextDualEncoderProcessor"),Tbo=o(" (VisionTextDualEncoder model)"),Mbo=l(),Mu=a("li"),yie=a("strong"),Ebo=o("wav2vec2"),Cbo=o(" \u2014 "),KN=a("a"),wbo=o("Wav2Vec2Processor"),Abo=o(" (Wav2Vec2 model)"),Lbo=l(),Eu=a("li"),xie=a("strong"),ybo=o("wav2vec2-conformer"),xbo=o(" \u2014 "),ZN=a("a"),$bo=o("Wav2Vec2Processor"),kbo=o(" (Wav2Vec2-Conformer model)"),Sbo=l(),Cu=a("li"),$ie=a("strong"),Rbo=o("wavlm"),Pbo=o(" \u2014 "),eq=a("a"),Bbo=o("Wav2Vec2Processor"),Ibo=o(" (WavLM model)"),Nbo=l(),F(wu.$$.fragment),qbo=l(),F(Au.$$.fragment),jbo=l(),Lu=a("div"),F(e7.$$.fragment),Dbo=l(),kie=a("p"),Gbo=o("Register a new processor for this class."),KGe=l(),Bi=a("h2"),yu=a("a"),Sie=a("span"),F(o7.$$.fragment),Obo=l(),Rie=a("span"),Vbo=o("AutoModel"),ZGe=l(),xo=a("div"),F(r7.$$.fragment),Xbo=l(),Ii=a("p"),zbo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=a("a"),Qbo=o("from_pretrained()"),Wbo=o(" class method or the "),rq=a("a"),Hbo=o("from_config()"),Ubo=o(` class
method.`),Jbo=l(),t7=a("p"),Ybo=o("This class cannot be instantiated directly using "),Pie=a("code"),Kbo=o("__init__()"),Zbo=o(" (throws an error)."),evo=l(),nt=a("div"),F(a7.$$.fragment),ovo=l(),Bie=a("p"),rvo=o("Instantiates one of the base model classes of the library from a configuration."),tvo=l(),Ni=a("p"),avo=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),nvo=o("not"),svo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=a("a"),lvo=o("from_pretrained()"),ivo=o(" to load the model weights."),dvo=l(),F(xu.$$.fragment),cvo=l(),Je=a("div"),F(n7.$$.fragment),mvo=l(),Nie=a("p"),fvo=o("Instantiate one of the base model classes of the library from a pretrained model."),gvo=l(),Ra=a("p"),hvo=o("The model class to instantiate is selected based on the "),qie=a("code"),uvo=o("model_type"),pvo=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),_vo=o("pretrained_model_name_or_path"),bvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),vvo=o("pretrained_model_name_or_path"),Fvo=o(":"),Tvo=l(),y=a("ul"),$u=a("li"),Gie=a("strong"),Mvo=o("albert"),Evo=o(" \u2014 "),aq=a("a"),Cvo=o("AlbertModel"),wvo=o(" (ALBERT model)"),Avo=l(),ku=a("li"),Oie=a("strong"),Lvo=o("bart"),yvo=o(" \u2014 "),nq=a("a"),xvo=o("BartModel"),$vo=o(" (BART model)"),kvo=l(),Su=a("li"),Vie=a("strong"),Svo=o("beit"),Rvo=o(" \u2014 "),sq=a("a"),Pvo=o("BeitModel"),Bvo=o(" (BEiT model)"),Ivo=l(),Ru=a("li"),Xie=a("strong"),Nvo=o("bert"),qvo=o(" \u2014 "),lq=a("a"),jvo=o("BertModel"),Dvo=o(" (BERT model)"),Gvo=l(),Pu=a("li"),zie=a("strong"),Ovo=o("bert-generation"),Vvo=o(" \u2014 "),iq=a("a"),Xvo=o("BertGenerationEncoder"),zvo=o(" (Bert Generation model)"),Qvo=l(),Bu=a("li"),Qie=a("strong"),Wvo=o("big_bird"),Hvo=o(" \u2014 "),dq=a("a"),Uvo=o("BigBirdModel"),Jvo=o(" (BigBird model)"),Yvo=l(),Iu=a("li"),Wie=a("strong"),Kvo=o("bigbird_pegasus"),Zvo=o(" \u2014 "),cq=a("a"),eFo=o("BigBirdPegasusModel"),oFo=o(" (BigBird-Pegasus model)"),rFo=l(),Nu=a("li"),Hie=a("strong"),tFo=o("blenderbot"),aFo=o(" \u2014 "),mq=a("a"),nFo=o("BlenderbotModel"),sFo=o(" (Blenderbot model)"),lFo=l(),qu=a("li"),Uie=a("strong"),iFo=o("blenderbot-small"),dFo=o(" \u2014 "),fq=a("a"),cFo=o("BlenderbotSmallModel"),mFo=o(" (BlenderbotSmall model)"),fFo=l(),ju=a("li"),Jie=a("strong"),gFo=o("bloom"),hFo=o(" \u2014 "),gq=a("a"),uFo=o("BloomModel"),pFo=o(" (BLOOM model)"),_Fo=l(),Du=a("li"),Yie=a("strong"),bFo=o("camembert"),vFo=o(" \u2014 "),hq=a("a"),FFo=o("CamembertModel"),TFo=o(" (CamemBERT model)"),MFo=l(),Gu=a("li"),Kie=a("strong"),EFo=o("canine"),CFo=o(" \u2014 "),uq=a("a"),wFo=o("CanineModel"),AFo=o(" (CANINE model)"),LFo=l(),Ou=a("li"),Zie=a("strong"),yFo=o("clip"),xFo=o(" \u2014 "),pq=a("a"),$Fo=o("CLIPModel"),kFo=o(" (CLIP model)"),SFo=l(),Vu=a("li"),ede=a("strong"),RFo=o("convbert"),PFo=o(" \u2014 "),_q=a("a"),BFo=o("ConvBertModel"),IFo=o(" (ConvBERT model)"),NFo=l(),Xu=a("li"),ode=a("strong"),qFo=o("convnext"),jFo=o(" \u2014 "),bq=a("a"),DFo=o("ConvNextModel"),GFo=o(" (ConvNeXT model)"),OFo=l(),zu=a("li"),rde=a("strong"),VFo=o("ctrl"),XFo=o(" \u2014 "),vq=a("a"),zFo=o("CTRLModel"),QFo=o(" (CTRL model)"),WFo=l(),Qu=a("li"),tde=a("strong"),HFo=o("cvt"),UFo=o(" \u2014 "),Fq=a("a"),JFo=o("CvtModel"),YFo=o(" (CvT model)"),KFo=l(),Wu=a("li"),ade=a("strong"),ZFo=o("data2vec-audio"),e1o=o(" \u2014 "),Tq=a("a"),o1o=o("Data2VecAudioModel"),r1o=o(" (Data2VecAudio model)"),t1o=l(),Hu=a("li"),nde=a("strong"),a1o=o("data2vec-text"),n1o=o(" \u2014 "),Mq=a("a"),s1o=o("Data2VecTextModel"),l1o=o(" (Data2VecText model)"),i1o=l(),Uu=a("li"),sde=a("strong"),d1o=o("data2vec-vision"),c1o=o(" \u2014 "),Eq=a("a"),m1o=o("Data2VecVisionModel"),f1o=o(" (Data2VecVision model)"),g1o=l(),Ju=a("li"),lde=a("strong"),h1o=o("deberta"),u1o=o(" \u2014 "),Cq=a("a"),p1o=o("DebertaModel"),_1o=o(" (DeBERTa model)"),b1o=l(),Yu=a("li"),ide=a("strong"),v1o=o("deberta-v2"),F1o=o(" \u2014 "),wq=a("a"),T1o=o("DebertaV2Model"),M1o=o(" (DeBERTa-v2 model)"),E1o=l(),Ku=a("li"),dde=a("strong"),C1o=o("decision_transformer"),w1o=o(" \u2014 "),Aq=a("a"),A1o=o("DecisionTransformerModel"),L1o=o(" (Decision Transformer model)"),y1o=l(),Zu=a("li"),cde=a("strong"),x1o=o("deit"),$1o=o(" \u2014 "),Lq=a("a"),k1o=o("DeiTModel"),S1o=o(" (DeiT model)"),R1o=l(),ep=a("li"),mde=a("strong"),P1o=o("detr"),B1o=o(" \u2014 "),yq=a("a"),I1o=o("DetrModel"),N1o=o(" (DETR model)"),q1o=l(),op=a("li"),fde=a("strong"),j1o=o("distilbert"),D1o=o(" \u2014 "),xq=a("a"),G1o=o("DistilBertModel"),O1o=o(" (DistilBERT model)"),V1o=l(),rp=a("li"),gde=a("strong"),X1o=o("dpr"),z1o=o(" \u2014 "),$q=a("a"),Q1o=o("DPRQuestionEncoder"),W1o=o(" (DPR model)"),H1o=l(),tp=a("li"),hde=a("strong"),U1o=o("dpt"),J1o=o(" \u2014 "),kq=a("a"),Y1o=o("DPTModel"),K1o=o(" (DPT model)"),Z1o=l(),ap=a("li"),ude=a("strong"),eTo=o("electra"),oTo=o(" \u2014 "),Sq=a("a"),rTo=o("ElectraModel"),tTo=o(" (ELECTRA model)"),aTo=l(),np=a("li"),pde=a("strong"),nTo=o("flaubert"),sTo=o(" \u2014 "),Rq=a("a"),lTo=o("FlaubertModel"),iTo=o(" (FlauBERT model)"),dTo=l(),sp=a("li"),_de=a("strong"),cTo=o("flava"),mTo=o(" \u2014 "),Pq=a("a"),fTo=o("FlavaModel"),gTo=o(" (FLAVA model)"),hTo=l(),lp=a("li"),bde=a("strong"),uTo=o("fnet"),pTo=o(" \u2014 "),Bq=a("a"),_To=o("FNetModel"),bTo=o(" (FNet model)"),vTo=l(),ip=a("li"),vde=a("strong"),FTo=o("fsmt"),TTo=o(" \u2014 "),Iq=a("a"),MTo=o("FSMTModel"),ETo=o(" (FairSeq Machine-Translation model)"),CTo=l(),Vs=a("li"),Fde=a("strong"),wTo=o("funnel"),ATo=o(" \u2014 "),Nq=a("a"),LTo=o("FunnelModel"),yTo=o(" or "),qq=a("a"),xTo=o("FunnelBaseModel"),$To=o(" (Funnel Transformer model)"),kTo=l(),dp=a("li"),Tde=a("strong"),STo=o("glpn"),RTo=o(" \u2014 "),jq=a("a"),PTo=o("GLPNModel"),BTo=o(" (GLPN model)"),ITo=l(),cp=a("li"),Mde=a("strong"),NTo=o("gpt2"),qTo=o(" \u2014 "),Dq=a("a"),jTo=o("GPT2Model"),DTo=o(" (OpenAI GPT-2 model)"),GTo=l(),mp=a("li"),Ede=a("strong"),OTo=o("gpt_neo"),VTo=o(" \u2014 "),Gq=a("a"),XTo=o("GPTNeoModel"),zTo=o(" (GPT Neo model)"),QTo=l(),fp=a("li"),Cde=a("strong"),WTo=o("gpt_neox"),HTo=o(" \u2014 "),Oq=a("a"),UTo=o("GPTNeoXModel"),JTo=o(" (GPT NeoX model)"),YTo=l(),gp=a("li"),wde=a("strong"),KTo=o("gptj"),ZTo=o(" \u2014 "),Vq=a("a"),eMo=o("GPTJModel"),oMo=o(" (GPT-J model)"),rMo=l(),hp=a("li"),Ade=a("strong"),tMo=o("hubert"),aMo=o(" \u2014 "),Xq=a("a"),nMo=o("HubertModel"),sMo=o(" (Hubert model)"),lMo=l(),up=a("li"),Lde=a("strong"),iMo=o("ibert"),dMo=o(" \u2014 "),zq=a("a"),cMo=o("IBertModel"),mMo=o(" (I-BERT model)"),fMo=l(),pp=a("li"),yde=a("strong"),gMo=o("imagegpt"),hMo=o(" \u2014 "),Qq=a("a"),uMo=o("ImageGPTModel"),pMo=o(" (ImageGPT model)"),_Mo=l(),_p=a("li"),xde=a("strong"),bMo=o("layoutlm"),vMo=o(" \u2014 "),Wq=a("a"),FMo=o("LayoutLMModel"),TMo=o(" (LayoutLM model)"),MMo=l(),bp=a("li"),$de=a("strong"),EMo=o("layoutlmv2"),CMo=o(" \u2014 "),Hq=a("a"),wMo=o("LayoutLMv2Model"),AMo=o(" (LayoutLMv2 model)"),LMo=l(),vp=a("li"),kde=a("strong"),yMo=o("layoutlmv3"),xMo=o(" \u2014 "),Uq=a("a"),$Mo=o("LayoutLMv3Model"),kMo=o(" (LayoutLMv3 model)"),SMo=l(),Fp=a("li"),Sde=a("strong"),RMo=o("led"),PMo=o(" \u2014 "),Jq=a("a"),BMo=o("LEDModel"),IMo=o(" (LED model)"),NMo=l(),Tp=a("li"),Rde=a("strong"),qMo=o("levit"),jMo=o(" \u2014 "),Yq=a("a"),DMo=o("LevitModel"),GMo=o(" (LeViT model)"),OMo=l(),Mp=a("li"),Pde=a("strong"),VMo=o("longformer"),XMo=o(" \u2014 "),Kq=a("a"),zMo=o("LongformerModel"),QMo=o(" (Longformer model)"),WMo=l(),Ep=a("li"),Bde=a("strong"),HMo=o("longt5"),UMo=o(" \u2014 "),Zq=a("a"),JMo=o("LongT5Model"),YMo=o(" (LongT5 model)"),KMo=l(),Cp=a("li"),Ide=a("strong"),ZMo=o("luke"),eEo=o(" \u2014 "),ej=a("a"),oEo=o("LukeModel"),rEo=o(" (LUKE model)"),tEo=l(),wp=a("li"),Nde=a("strong"),aEo=o("lxmert"),nEo=o(" \u2014 "),oj=a("a"),sEo=o("LxmertModel"),lEo=o(" (LXMERT model)"),iEo=l(),Ap=a("li"),qde=a("strong"),dEo=o("m2m_100"),cEo=o(" \u2014 "),rj=a("a"),mEo=o("M2M100Model"),fEo=o(" (M2M100 model)"),gEo=l(),Lp=a("li"),jde=a("strong"),hEo=o("marian"),uEo=o(" \u2014 "),tj=a("a"),pEo=o("MarianModel"),_Eo=o(" (Marian model)"),bEo=l(),yp=a("li"),Dde=a("strong"),vEo=o("maskformer"),FEo=o(" \u2014 "),aj=a("a"),TEo=o("MaskFormerModel"),MEo=o(" (MaskFormer model)"),EEo=l(),xp=a("li"),Gde=a("strong"),CEo=o("mbart"),wEo=o(" \u2014 "),nj=a("a"),AEo=o("MBartModel"),LEo=o(" (mBART model)"),yEo=l(),$p=a("li"),Ode=a("strong"),xEo=o("mctct"),$Eo=o(" \u2014 "),sj=a("a"),kEo=o("MCTCTModel"),SEo=o(" (M-CTC-T model)"),REo=l(),kp=a("li"),Vde=a("strong"),PEo=o("megatron-bert"),BEo=o(" \u2014 "),lj=a("a"),IEo=o("MegatronBertModel"),NEo=o(" (Megatron-BERT model)"),qEo=l(),Sp=a("li"),Xde=a("strong"),jEo=o("mobilebert"),DEo=o(" \u2014 "),ij=a("a"),GEo=o("MobileBertModel"),OEo=o(" (MobileBERT model)"),VEo=l(),Rp=a("li"),zde=a("strong"),XEo=o("mpnet"),zEo=o(" \u2014 "),dj=a("a"),QEo=o("MPNetModel"),WEo=o(" (MPNet model)"),HEo=l(),Pp=a("li"),Qde=a("strong"),UEo=o("mt5"),JEo=o(" \u2014 "),cj=a("a"),YEo=o("MT5Model"),KEo=o(" (MT5 model)"),ZEo=l(),Bp=a("li"),Wde=a("strong"),e4o=o("nezha"),o4o=o(" \u2014 "),mj=a("a"),r4o=o("NezhaModel"),t4o=o(" (Nezha model)"),a4o=l(),Ip=a("li"),Hde=a("strong"),n4o=o("nystromformer"),s4o=o(" \u2014 "),fj=a("a"),l4o=o("NystromformerModel"),i4o=o(" (Nystr\xF6mformer model)"),d4o=l(),Np=a("li"),Ude=a("strong"),c4o=o("openai-gpt"),m4o=o(" \u2014 "),gj=a("a"),f4o=o("OpenAIGPTModel"),g4o=o(" (OpenAI GPT model)"),h4o=l(),qp=a("li"),Jde=a("strong"),u4o=o("opt"),p4o=o(" \u2014 "),hj=a("a"),_4o=o("OPTModel"),b4o=o(" (OPT model)"),v4o=l(),jp=a("li"),Yde=a("strong"),F4o=o("pegasus"),T4o=o(" \u2014 "),uj=a("a"),M4o=o("PegasusModel"),E4o=o(" (Pegasus model)"),C4o=l(),Dp=a("li"),Kde=a("strong"),w4o=o("perceiver"),A4o=o(" \u2014 "),pj=a("a"),L4o=o("PerceiverModel"),y4o=o(" (Perceiver model)"),x4o=l(),Gp=a("li"),Zde=a("strong"),$4o=o("plbart"),k4o=o(" \u2014 "),_j=a("a"),S4o=o("PLBartModel"),R4o=o(" (PLBart model)"),P4o=l(),Op=a("li"),ece=a("strong"),B4o=o("poolformer"),I4o=o(" \u2014 "),bj=a("a"),N4o=o("PoolFormerModel"),q4o=o(" (PoolFormer model)"),j4o=l(),Vp=a("li"),oce=a("strong"),D4o=o("prophetnet"),G4o=o(" \u2014 "),vj=a("a"),O4o=o("ProphetNetModel"),V4o=o(" (ProphetNet model)"),X4o=l(),Xp=a("li"),rce=a("strong"),z4o=o("qdqbert"),Q4o=o(" \u2014 "),Fj=a("a"),W4o=o("QDQBertModel"),H4o=o(" (QDQBert model)"),U4o=l(),zp=a("li"),tce=a("strong"),J4o=o("reformer"),Y4o=o(" \u2014 "),Tj=a("a"),K4o=o("ReformerModel"),Z4o=o(" (Reformer model)"),eCo=l(),Qp=a("li"),ace=a("strong"),oCo=o("regnet"),rCo=o(" \u2014 "),Mj=a("a"),tCo=o("RegNetModel"),aCo=o(" (RegNet model)"),nCo=l(),Wp=a("li"),nce=a("strong"),sCo=o("rembert"),lCo=o(" \u2014 "),Ej=a("a"),iCo=o("RemBertModel"),dCo=o(" (RemBERT model)"),cCo=l(),Hp=a("li"),sce=a("strong"),mCo=o("resnet"),fCo=o(" \u2014 "),Cj=a("a"),gCo=o("ResNetModel"),hCo=o(" (ResNet model)"),uCo=l(),Up=a("li"),lce=a("strong"),pCo=o("retribert"),_Co=o(" \u2014 "),wj=a("a"),bCo=o("RetriBertModel"),vCo=o(" (RetriBERT model)"),FCo=l(),Jp=a("li"),ice=a("strong"),TCo=o("roberta"),MCo=o(" \u2014 "),Aj=a("a"),ECo=o("RobertaModel"),CCo=o(" (RoBERTa model)"),wCo=l(),Yp=a("li"),dce=a("strong"),ACo=o("roformer"),LCo=o(" \u2014 "),Lj=a("a"),yCo=o("RoFormerModel"),xCo=o(" (RoFormer model)"),$Co=l(),Kp=a("li"),cce=a("strong"),kCo=o("segformer"),SCo=o(" \u2014 "),yj=a("a"),RCo=o("SegformerModel"),PCo=o(" (SegFormer model)"),BCo=l(),Zp=a("li"),mce=a("strong"),ICo=o("sew"),NCo=o(" \u2014 "),xj=a("a"),qCo=o("SEWModel"),jCo=o(" (SEW model)"),DCo=l(),e_=a("li"),fce=a("strong"),GCo=o("sew-d"),OCo=o(" \u2014 "),$j=a("a"),VCo=o("SEWDModel"),XCo=o(" (SEW-D model)"),zCo=l(),o_=a("li"),gce=a("strong"),QCo=o("speech_to_text"),WCo=o(" \u2014 "),kj=a("a"),HCo=o("Speech2TextModel"),UCo=o(" (Speech2Text model)"),JCo=l(),r_=a("li"),hce=a("strong"),YCo=o("splinter"),KCo=o(" \u2014 "),Sj=a("a"),ZCo=o("SplinterModel"),e5o=o(" (Splinter model)"),o5o=l(),t_=a("li"),uce=a("strong"),r5o=o("squeezebert"),t5o=o(" \u2014 "),Rj=a("a"),a5o=o("SqueezeBertModel"),n5o=o(" (SqueezeBERT model)"),s5o=l(),a_=a("li"),pce=a("strong"),l5o=o("swin"),i5o=o(" \u2014 "),Pj=a("a"),d5o=o("SwinModel"),c5o=o(" (Swin Transformer model)"),m5o=l(),n_=a("li"),_ce=a("strong"),f5o=o("t5"),g5o=o(" \u2014 "),Bj=a("a"),h5o=o("T5Model"),u5o=o(" (T5 model)"),p5o=l(),s_=a("li"),bce=a("strong"),_5o=o("tapas"),b5o=o(" \u2014 "),Ij=a("a"),v5o=o("TapasModel"),F5o=o(" (TAPAS model)"),T5o=l(),l_=a("li"),vce=a("strong"),M5o=o("trajectory_transformer"),E5o=o(" \u2014 "),Nj=a("a"),C5o=o("TrajectoryTransformerModel"),w5o=o(" (Trajectory Transformer model)"),A5o=l(),i_=a("li"),Fce=a("strong"),L5o=o("transfo-xl"),y5o=o(" \u2014 "),qj=a("a"),x5o=o("TransfoXLModel"),$5o=o(" (Transformer-XL model)"),k5o=l(),d_=a("li"),Tce=a("strong"),S5o=o("unispeech"),R5o=o(" \u2014 "),jj=a("a"),P5o=o("UniSpeechModel"),B5o=o(" (UniSpeech model)"),I5o=l(),c_=a("li"),Mce=a("strong"),N5o=o("unispeech-sat"),q5o=o(" \u2014 "),Dj=a("a"),j5o=o("UniSpeechSatModel"),D5o=o(" (UniSpeechSat model)"),G5o=l(),m_=a("li"),Ece=a("strong"),O5o=o("van"),V5o=o(" \u2014 "),Gj=a("a"),X5o=o("VanModel"),z5o=o(" (VAN model)"),Q5o=l(),f_=a("li"),Cce=a("strong"),W5o=o("vilt"),H5o=o(" \u2014 "),Oj=a("a"),U5o=o("ViltModel"),J5o=o(" (ViLT model)"),Y5o=l(),g_=a("li"),wce=a("strong"),K5o=o("vision-text-dual-encoder"),Z5o=o(" \u2014 "),Vj=a("a"),e3o=o("VisionTextDualEncoderModel"),o3o=o(" (VisionTextDualEncoder model)"),r3o=l(),h_=a("li"),Ace=a("strong"),t3o=o("visual_bert"),a3o=o(" \u2014 "),Xj=a("a"),n3o=o("VisualBertModel"),s3o=o(" (VisualBERT model)"),l3o=l(),u_=a("li"),Lce=a("strong"),i3o=o("vit"),d3o=o(" \u2014 "),zj=a("a"),c3o=o("ViTModel"),m3o=o(" (ViT model)"),f3o=l(),p_=a("li"),yce=a("strong"),g3o=o("vit_mae"),h3o=o(" \u2014 "),Qj=a("a"),u3o=o("ViTMAEModel"),p3o=o(" (ViTMAE model)"),_3o=l(),__=a("li"),xce=a("strong"),b3o=o("wav2vec2"),v3o=o(" \u2014 "),Wj=a("a"),F3o=o("Wav2Vec2Model"),T3o=o(" (Wav2Vec2 model)"),M3o=l(),b_=a("li"),$ce=a("strong"),E3o=o("wav2vec2-conformer"),C3o=o(" \u2014 "),Hj=a("a"),w3o=o("Wav2Vec2ConformerModel"),A3o=o(" (Wav2Vec2-Conformer model)"),L3o=l(),v_=a("li"),kce=a("strong"),y3o=o("wavlm"),x3o=o(" \u2014 "),Uj=a("a"),$3o=o("WavLMModel"),k3o=o(" (WavLM model)"),S3o=l(),F_=a("li"),Sce=a("strong"),R3o=o("xglm"),P3o=o(" \u2014 "),Jj=a("a"),B3o=o("XGLMModel"),I3o=o(" (XGLM model)"),N3o=l(),T_=a("li"),Rce=a("strong"),q3o=o("xlm"),j3o=o(" \u2014 "),Yj=a("a"),D3o=o("XLMModel"),G3o=o(" (XLM model)"),O3o=l(),M_=a("li"),Pce=a("strong"),V3o=o("xlm-prophetnet"),X3o=o(" \u2014 "),Kj=a("a"),z3o=o("XLMProphetNetModel"),Q3o=o(" (XLM-ProphetNet model)"),W3o=l(),E_=a("li"),Bce=a("strong"),H3o=o("xlm-roberta"),U3o=o(" \u2014 "),Zj=a("a"),J3o=o("XLMRobertaModel"),Y3o=o(" (XLM-RoBERTa model)"),K3o=l(),C_=a("li"),Ice=a("strong"),Z3o=o("xlm-roberta-xl"),e0o=o(" \u2014 "),eD=a("a"),o0o=o("XLMRobertaXLModel"),r0o=o(" (XLM-RoBERTa-XL model)"),t0o=l(),w_=a("li"),Nce=a("strong"),a0o=o("xlnet"),n0o=o(" \u2014 "),oD=a("a"),s0o=o("XLNetModel"),l0o=o(" (XLNet model)"),i0o=l(),A_=a("li"),qce=a("strong"),d0o=o("yolos"),c0o=o(" \u2014 "),rD=a("a"),m0o=o("YolosModel"),f0o=o(" (YOLOS model)"),g0o=l(),L_=a("li"),jce=a("strong"),h0o=o("yoso"),u0o=o(" \u2014 "),tD=a("a"),p0o=o("YosoModel"),_0o=o(" (YOSO model)"),b0o=l(),y_=a("p"),v0o=o("The model is set in evaluation mode by default using "),Dce=a("code"),F0o=o("model.eval()"),T0o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=a("code"),M0o=o("model.train()"),E0o=l(),F(x_.$$.fragment),eOe=l(),qi=a("h2"),$_=a("a"),Oce=a("span"),F(s7.$$.fragment),C0o=l(),Vce=a("span"),w0o=o("AutoModelForPreTraining"),oOe=l(),$o=a("div"),F(l7.$$.fragment),A0o=l(),ji=a("p"),L0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=a("a"),y0o=o("from_pretrained()"),x0o=o(" class method or the "),nD=a("a"),$0o=o("from_config()"),k0o=o(` class
method.`),S0o=l(),i7=a("p"),R0o=o("This class cannot be instantiated directly using "),Xce=a("code"),P0o=o("__init__()"),B0o=o(" (throws an error)."),I0o=l(),st=a("div"),F(d7.$$.fragment),N0o=l(),zce=a("p"),q0o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),j0o=l(),Di=a("p"),D0o=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),G0o=o("not"),O0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=a("a"),V0o=o("from_pretrained()"),X0o=o(" to load the model weights."),z0o=l(),F(k_.$$.fragment),Q0o=l(),Ye=a("div"),F(c7.$$.fragment),W0o=l(),Wce=a("p"),H0o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),U0o=l(),Pa=a("p"),J0o=o("The model class to instantiate is selected based on the "),Hce=a("code"),Y0o=o("model_type"),K0o=o(` property of the config object (either
passed as an argument or loaded from `),Uce=a("code"),Z0o=o("pretrained_model_name_or_path"),ewo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=a("code"),owo=o("pretrained_model_name_or_path"),rwo=o(":"),two=l(),G=a("ul"),S_=a("li"),Yce=a("strong"),awo=o("albert"),nwo=o(" \u2014 "),lD=a("a"),swo=o("AlbertForPreTraining"),lwo=o(" (ALBERT model)"),iwo=l(),R_=a("li"),Kce=a("strong"),dwo=o("bart"),cwo=o(" \u2014 "),iD=a("a"),mwo=o("BartForConditionalGeneration"),fwo=o(" (BART model)"),gwo=l(),P_=a("li"),Zce=a("strong"),hwo=o("bert"),uwo=o(" \u2014 "),dD=a("a"),pwo=o("BertForPreTraining"),_wo=o(" (BERT model)"),bwo=l(),B_=a("li"),eme=a("strong"),vwo=o("big_bird"),Fwo=o(" \u2014 "),cD=a("a"),Two=o("BigBirdForPreTraining"),Mwo=o(" (BigBird model)"),Ewo=l(),I_=a("li"),ome=a("strong"),Cwo=o("bloom"),wwo=o(" \u2014 "),mD=a("a"),Awo=o("BloomForCausalLM"),Lwo=o(" (BLOOM model)"),ywo=l(),N_=a("li"),rme=a("strong"),xwo=o("camembert"),$wo=o(" \u2014 "),fD=a("a"),kwo=o("CamembertForMaskedLM"),Swo=o(" (CamemBERT model)"),Rwo=l(),q_=a("li"),tme=a("strong"),Pwo=o("ctrl"),Bwo=o(" \u2014 "),gD=a("a"),Iwo=o("CTRLLMHeadModel"),Nwo=o(" (CTRL model)"),qwo=l(),j_=a("li"),ame=a("strong"),jwo=o("data2vec-text"),Dwo=o(" \u2014 "),hD=a("a"),Gwo=o("Data2VecTextForMaskedLM"),Owo=o(" (Data2VecText model)"),Vwo=l(),D_=a("li"),nme=a("strong"),Xwo=o("deberta"),zwo=o(" \u2014 "),uD=a("a"),Qwo=o("DebertaForMaskedLM"),Wwo=o(" (DeBERTa model)"),Hwo=l(),G_=a("li"),sme=a("strong"),Uwo=o("deberta-v2"),Jwo=o(" \u2014 "),pD=a("a"),Ywo=o("DebertaV2ForMaskedLM"),Kwo=o(" (DeBERTa-v2 model)"),Zwo=l(),O_=a("li"),lme=a("strong"),eAo=o("distilbert"),oAo=o(" \u2014 "),_D=a("a"),rAo=o("DistilBertForMaskedLM"),tAo=o(" (DistilBERT model)"),aAo=l(),V_=a("li"),ime=a("strong"),nAo=o("electra"),sAo=o(" \u2014 "),bD=a("a"),lAo=o("ElectraForPreTraining"),iAo=o(" (ELECTRA model)"),dAo=l(),X_=a("li"),dme=a("strong"),cAo=o("flaubert"),mAo=o(" \u2014 "),vD=a("a"),fAo=o("FlaubertWithLMHeadModel"),gAo=o(" (FlauBERT model)"),hAo=l(),z_=a("li"),cme=a("strong"),uAo=o("flava"),pAo=o(" \u2014 "),FD=a("a"),_Ao=o("FlavaForPreTraining"),bAo=o(" (FLAVA model)"),vAo=l(),Q_=a("li"),mme=a("strong"),FAo=o("fnet"),TAo=o(" \u2014 "),TD=a("a"),MAo=o("FNetForPreTraining"),EAo=o(" (FNet model)"),CAo=l(),W_=a("li"),fme=a("strong"),wAo=o("fsmt"),AAo=o(" \u2014 "),MD=a("a"),LAo=o("FSMTForConditionalGeneration"),yAo=o(" (FairSeq Machine-Translation model)"),xAo=l(),H_=a("li"),gme=a("strong"),$Ao=o("funnel"),kAo=o(" \u2014 "),ED=a("a"),SAo=o("FunnelForPreTraining"),RAo=o(" (Funnel Transformer model)"),PAo=l(),U_=a("li"),hme=a("strong"),BAo=o("gpt2"),IAo=o(" \u2014 "),CD=a("a"),NAo=o("GPT2LMHeadModel"),qAo=o(" (OpenAI GPT-2 model)"),jAo=l(),J_=a("li"),ume=a("strong"),DAo=o("ibert"),GAo=o(" \u2014 "),wD=a("a"),OAo=o("IBertForMaskedLM"),VAo=o(" (I-BERT model)"),XAo=l(),Y_=a("li"),pme=a("strong"),zAo=o("layoutlm"),QAo=o(" \u2014 "),AD=a("a"),WAo=o("LayoutLMForMaskedLM"),HAo=o(" (LayoutLM model)"),UAo=l(),K_=a("li"),_me=a("strong"),JAo=o("longformer"),YAo=o(" \u2014 "),LD=a("a"),KAo=o("LongformerForMaskedLM"),ZAo=o(" (Longformer model)"),e6o=l(),Z_=a("li"),bme=a("strong"),o6o=o("lxmert"),r6o=o(" \u2014 "),yD=a("a"),t6o=o("LxmertForPreTraining"),a6o=o(" (LXMERT model)"),n6o=l(),e2=a("li"),vme=a("strong"),s6o=o("megatron-bert"),l6o=o(" \u2014 "),xD=a("a"),i6o=o("MegatronBertForPreTraining"),d6o=o(" (Megatron-BERT model)"),c6o=l(),o2=a("li"),Fme=a("strong"),m6o=o("mobilebert"),f6o=o(" \u2014 "),$D=a("a"),g6o=o("MobileBertForPreTraining"),h6o=o(" (MobileBERT model)"),u6o=l(),r2=a("li"),Tme=a("strong"),p6o=o("mpnet"),_6o=o(" \u2014 "),kD=a("a"),b6o=o("MPNetForMaskedLM"),v6o=o(" (MPNet model)"),F6o=l(),t2=a("li"),Mme=a("strong"),T6o=o("nezha"),M6o=o(" \u2014 "),SD=a("a"),E6o=o("NezhaForPreTraining"),C6o=o(" (Nezha model)"),w6o=l(),a2=a("li"),Eme=a("strong"),A6o=o("openai-gpt"),L6o=o(" \u2014 "),RD=a("a"),y6o=o("OpenAIGPTLMHeadModel"),x6o=o(" (OpenAI GPT model)"),$6o=l(),n2=a("li"),Cme=a("strong"),k6o=o("retribert"),S6o=o(" \u2014 "),PD=a("a"),R6o=o("RetriBertModel"),P6o=o(" (RetriBERT model)"),B6o=l(),s2=a("li"),wme=a("strong"),I6o=o("roberta"),N6o=o(" \u2014 "),BD=a("a"),q6o=o("RobertaForMaskedLM"),j6o=o(" (RoBERTa model)"),D6o=l(),l2=a("li"),Ame=a("strong"),G6o=o("splinter"),O6o=o(" \u2014 "),ID=a("a"),V6o=o("SplinterForPreTraining"),X6o=o(" (Splinter model)"),z6o=l(),i2=a("li"),Lme=a("strong"),Q6o=o("squeezebert"),W6o=o(" \u2014 "),ND=a("a"),H6o=o("SqueezeBertForMaskedLM"),U6o=o(" (SqueezeBERT model)"),J6o=l(),d2=a("li"),yme=a("strong"),Y6o=o("t5"),K6o=o(" \u2014 "),qD=a("a"),Z6o=o("T5ForConditionalGeneration"),eLo=o(" (T5 model)"),oLo=l(),c2=a("li"),xme=a("strong"),rLo=o("tapas"),tLo=o(" \u2014 "),jD=a("a"),aLo=o("TapasForMaskedLM"),nLo=o(" (TAPAS model)"),sLo=l(),m2=a("li"),$me=a("strong"),lLo=o("transfo-xl"),iLo=o(" \u2014 "),DD=a("a"),dLo=o("TransfoXLLMHeadModel"),cLo=o(" (Transformer-XL model)"),mLo=l(),f2=a("li"),kme=a("strong"),fLo=o("unispeech"),gLo=o(" \u2014 "),GD=a("a"),hLo=o("UniSpeechForPreTraining"),uLo=o(" (UniSpeech model)"),pLo=l(),g2=a("li"),Sme=a("strong"),_Lo=o("unispeech-sat"),bLo=o(" \u2014 "),OD=a("a"),vLo=o("UniSpeechSatForPreTraining"),FLo=o(" (UniSpeechSat model)"),TLo=l(),h2=a("li"),Rme=a("strong"),MLo=o("visual_bert"),ELo=o(" \u2014 "),VD=a("a"),CLo=o("VisualBertForPreTraining"),wLo=o(" (VisualBERT model)"),ALo=l(),u2=a("li"),Pme=a("strong"),LLo=o("vit_mae"),yLo=o(" \u2014 "),XD=a("a"),xLo=o("ViTMAEForPreTraining"),$Lo=o(" (ViTMAE model)"),kLo=l(),p2=a("li"),Bme=a("strong"),SLo=o("wav2vec2"),RLo=o(" \u2014 "),zD=a("a"),PLo=o("Wav2Vec2ForPreTraining"),BLo=o(" (Wav2Vec2 model)"),ILo=l(),_2=a("li"),Ime=a("strong"),NLo=o("wav2vec2-conformer"),qLo=o(" \u2014 "),QD=a("a"),jLo=o("Wav2Vec2ConformerForPreTraining"),DLo=o(" (Wav2Vec2-Conformer model)"),GLo=l(),b2=a("li"),Nme=a("strong"),OLo=o("xlm"),VLo=o(" \u2014 "),WD=a("a"),XLo=o("XLMWithLMHeadModel"),zLo=o(" (XLM model)"),QLo=l(),v2=a("li"),qme=a("strong"),WLo=o("xlm-roberta"),HLo=o(" \u2014 "),HD=a("a"),ULo=o("XLMRobertaForMaskedLM"),JLo=o(" (XLM-RoBERTa model)"),YLo=l(),F2=a("li"),jme=a("strong"),KLo=o("xlm-roberta-xl"),ZLo=o(" \u2014 "),UD=a("a"),eyo=o("XLMRobertaXLForMaskedLM"),oyo=o(" (XLM-RoBERTa-XL model)"),ryo=l(),T2=a("li"),Dme=a("strong"),tyo=o("xlnet"),ayo=o(" \u2014 "),JD=a("a"),nyo=o("XLNetLMHeadModel"),syo=o(" (XLNet model)"),lyo=l(),M2=a("p"),iyo=o("The model is set in evaluation mode by default using "),Gme=a("code"),dyo=o("model.eval()"),cyo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ome=a("code"),myo=o("model.train()"),fyo=l(),F(E2.$$.fragment),rOe=l(),Gi=a("h2"),C2=a("a"),Vme=a("span"),F(m7.$$.fragment),gyo=l(),Xme=a("span"),hyo=o("AutoModelForCausalLM"),tOe=l(),ko=a("div"),F(f7.$$.fragment),uyo=l(),Oi=a("p"),pyo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=a("a"),_yo=o("from_pretrained()"),byo=o(" class method or the "),KD=a("a"),vyo=o("from_config()"),Fyo=o(` class
method.`),Tyo=l(),g7=a("p"),Myo=o("This class cannot be instantiated directly using "),zme=a("code"),Eyo=o("__init__()"),Cyo=o(" (throws an error)."),wyo=l(),lt=a("div"),F(h7.$$.fragment),Ayo=l(),Qme=a("p"),Lyo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yyo=l(),Vi=a("p"),xyo=o(`Note:
Loading a model from its configuration file does `),Wme=a("strong"),$yo=o("not"),kyo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),Syo=o("from_pretrained()"),Ryo=o(" to load the model weights."),Pyo=l(),F(w2.$$.fragment),Byo=l(),Ke=a("div"),F(u7.$$.fragment),Iyo=l(),Hme=a("p"),Nyo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),qyo=l(),Ba=a("p"),jyo=o("The model class to instantiate is selected based on the "),Ume=a("code"),Dyo=o("model_type"),Gyo=o(` property of the config object (either
passed as an argument or loaded from `),Jme=a("code"),Oyo=o("pretrained_model_name_or_path"),Vyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yme=a("code"),Xyo=o("pretrained_model_name_or_path"),zyo=o(":"),Qyo=l(),z=a("ul"),A2=a("li"),Kme=a("strong"),Wyo=o("bart"),Hyo=o(" \u2014 "),eG=a("a"),Uyo=o("BartForCausalLM"),Jyo=o(" (BART model)"),Yyo=l(),L2=a("li"),Zme=a("strong"),Kyo=o("bert"),Zyo=o(" \u2014 "),oG=a("a"),e7o=o("BertLMHeadModel"),o7o=o(" (BERT model)"),r7o=l(),y2=a("li"),efe=a("strong"),t7o=o("bert-generation"),a7o=o(" \u2014 "),rG=a("a"),n7o=o("BertGenerationDecoder"),s7o=o(" (Bert Generation model)"),l7o=l(),x2=a("li"),ofe=a("strong"),i7o=o("big_bird"),d7o=o(" \u2014 "),tG=a("a"),c7o=o("BigBirdForCausalLM"),m7o=o(" (BigBird model)"),f7o=l(),$2=a("li"),rfe=a("strong"),g7o=o("bigbird_pegasus"),h7o=o(" \u2014 "),aG=a("a"),u7o=o("BigBirdPegasusForCausalLM"),p7o=o(" (BigBird-Pegasus model)"),_7o=l(),k2=a("li"),tfe=a("strong"),b7o=o("blenderbot"),v7o=o(" \u2014 "),nG=a("a"),F7o=o("BlenderbotForCausalLM"),T7o=o(" (Blenderbot model)"),M7o=l(),S2=a("li"),afe=a("strong"),E7o=o("blenderbot-small"),C7o=o(" \u2014 "),sG=a("a"),w7o=o("BlenderbotSmallForCausalLM"),A7o=o(" (BlenderbotSmall model)"),L7o=l(),R2=a("li"),nfe=a("strong"),y7o=o("bloom"),x7o=o(" \u2014 "),lG=a("a"),$7o=o("BloomForCausalLM"),k7o=o(" (BLOOM model)"),S7o=l(),P2=a("li"),sfe=a("strong"),R7o=o("camembert"),P7o=o(" \u2014 "),iG=a("a"),B7o=o("CamembertForCausalLM"),I7o=o(" (CamemBERT model)"),N7o=l(),B2=a("li"),lfe=a("strong"),q7o=o("ctrl"),j7o=o(" \u2014 "),dG=a("a"),D7o=o("CTRLLMHeadModel"),G7o=o(" (CTRL model)"),O7o=l(),I2=a("li"),ife=a("strong"),V7o=o("data2vec-text"),X7o=o(" \u2014 "),cG=a("a"),z7o=o("Data2VecTextForCausalLM"),Q7o=o(" (Data2VecText model)"),W7o=l(),N2=a("li"),dfe=a("strong"),H7o=o("electra"),U7o=o(" \u2014 "),mG=a("a"),J7o=o("ElectraForCausalLM"),Y7o=o(" (ELECTRA model)"),K7o=l(),q2=a("li"),cfe=a("strong"),Z7o=o("gpt2"),e8o=o(" \u2014 "),fG=a("a"),o8o=o("GPT2LMHeadModel"),r8o=o(" (OpenAI GPT-2 model)"),t8o=l(),j2=a("li"),mfe=a("strong"),a8o=o("gpt_neo"),n8o=o(" \u2014 "),gG=a("a"),s8o=o("GPTNeoForCausalLM"),l8o=o(" (GPT Neo model)"),i8o=l(),D2=a("li"),ffe=a("strong"),d8o=o("gpt_neox"),c8o=o(" \u2014 "),hG=a("a"),m8o=o("GPTNeoXForCausalLM"),f8o=o(" (GPT NeoX model)"),g8o=l(),G2=a("li"),gfe=a("strong"),h8o=o("gptj"),u8o=o(" \u2014 "),uG=a("a"),p8o=o("GPTJForCausalLM"),_8o=o(" (GPT-J model)"),b8o=l(),O2=a("li"),hfe=a("strong"),v8o=o("marian"),F8o=o(" \u2014 "),pG=a("a"),T8o=o("MarianForCausalLM"),M8o=o(" (Marian model)"),E8o=l(),V2=a("li"),ufe=a("strong"),C8o=o("mbart"),w8o=o(" \u2014 "),_G=a("a"),A8o=o("MBartForCausalLM"),L8o=o(" (mBART model)"),y8o=l(),X2=a("li"),pfe=a("strong"),x8o=o("megatron-bert"),$8o=o(" \u2014 "),bG=a("a"),k8o=o("MegatronBertForCausalLM"),S8o=o(" (Megatron-BERT model)"),R8o=l(),z2=a("li"),_fe=a("strong"),P8o=o("openai-gpt"),B8o=o(" \u2014 "),vG=a("a"),I8o=o("OpenAIGPTLMHeadModel"),N8o=o(" (OpenAI GPT model)"),q8o=l(),Q2=a("li"),bfe=a("strong"),j8o=o("opt"),D8o=o(" \u2014 "),FG=a("a"),G8o=o("OPTForCausalLM"),O8o=o(" (OPT model)"),V8o=l(),W2=a("li"),vfe=a("strong"),X8o=o("pegasus"),z8o=o(" \u2014 "),TG=a("a"),Q8o=o("PegasusForCausalLM"),W8o=o(" (Pegasus model)"),H8o=l(),H2=a("li"),Ffe=a("strong"),U8o=o("plbart"),J8o=o(" \u2014 "),MG=a("a"),Y8o=o("PLBartForCausalLM"),K8o=o(" (PLBart model)"),Z8o=l(),U2=a("li"),Tfe=a("strong"),e9o=o("prophetnet"),o9o=o(" \u2014 "),EG=a("a"),r9o=o("ProphetNetForCausalLM"),t9o=o(" (ProphetNet model)"),a9o=l(),J2=a("li"),Mfe=a("strong"),n9o=o("qdqbert"),s9o=o(" \u2014 "),CG=a("a"),l9o=o("QDQBertLMHeadModel"),i9o=o(" (QDQBert model)"),d9o=l(),Y2=a("li"),Efe=a("strong"),c9o=o("reformer"),m9o=o(" \u2014 "),wG=a("a"),f9o=o("ReformerModelWithLMHead"),g9o=o(" (Reformer model)"),h9o=l(),K2=a("li"),Cfe=a("strong"),u9o=o("rembert"),p9o=o(" \u2014 "),AG=a("a"),_9o=o("RemBertForCausalLM"),b9o=o(" (RemBERT model)"),v9o=l(),Z2=a("li"),wfe=a("strong"),F9o=o("roberta"),T9o=o(" \u2014 "),LG=a("a"),M9o=o("RobertaForCausalLM"),E9o=o(" (RoBERTa model)"),C9o=l(),eb=a("li"),Afe=a("strong"),w9o=o("roformer"),A9o=o(" \u2014 "),yG=a("a"),L9o=o("RoFormerForCausalLM"),y9o=o(" (RoFormer model)"),x9o=l(),ob=a("li"),Lfe=a("strong"),$9o=o("speech_to_text_2"),k9o=o(" \u2014 "),xG=a("a"),S9o=o("Speech2Text2ForCausalLM"),R9o=o(" (Speech2Text2 model)"),P9o=l(),rb=a("li"),yfe=a("strong"),B9o=o("transfo-xl"),I9o=o(" \u2014 "),$G=a("a"),N9o=o("TransfoXLLMHeadModel"),q9o=o(" (Transformer-XL model)"),j9o=l(),tb=a("li"),xfe=a("strong"),D9o=o("trocr"),G9o=o(" \u2014 "),kG=a("a"),O9o=o("TrOCRForCausalLM"),V9o=o(" (TrOCR model)"),X9o=l(),ab=a("li"),$fe=a("strong"),z9o=o("xglm"),Q9o=o(" \u2014 "),SG=a("a"),W9o=o("XGLMForCausalLM"),H9o=o(" (XGLM model)"),U9o=l(),nb=a("li"),kfe=a("strong"),J9o=o("xlm"),Y9o=o(" \u2014 "),RG=a("a"),K9o=o("XLMWithLMHeadModel"),Z9o=o(" (XLM model)"),exo=l(),sb=a("li"),Sfe=a("strong"),oxo=o("xlm-prophetnet"),rxo=o(" \u2014 "),PG=a("a"),txo=o("XLMProphetNetForCausalLM"),axo=o(" (XLM-ProphetNet model)"),nxo=l(),lb=a("li"),Rfe=a("strong"),sxo=o("xlm-roberta"),lxo=o(" \u2014 "),BG=a("a"),ixo=o("XLMRobertaForCausalLM"),dxo=o(" (XLM-RoBERTa model)"),cxo=l(),ib=a("li"),Pfe=a("strong"),mxo=o("xlm-roberta-xl"),fxo=o(" \u2014 "),IG=a("a"),gxo=o("XLMRobertaXLForCausalLM"),hxo=o(" (XLM-RoBERTa-XL model)"),uxo=l(),db=a("li"),Bfe=a("strong"),pxo=o("xlnet"),_xo=o(" \u2014 "),NG=a("a"),bxo=o("XLNetLMHeadModel"),vxo=o(" (XLNet model)"),Fxo=l(),cb=a("p"),Txo=o("The model is set in evaluation mode by default using "),Ife=a("code"),Mxo=o("model.eval()"),Exo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nfe=a("code"),Cxo=o("model.train()"),wxo=l(),F(mb.$$.fragment),aOe=l(),Xi=a("h2"),fb=a("a"),qfe=a("span"),F(p7.$$.fragment),Axo=l(),jfe=a("span"),Lxo=o("AutoModelForMaskedLM"),nOe=l(),So=a("div"),F(_7.$$.fragment),yxo=l(),zi=a("p"),xxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=a("a"),$xo=o("from_pretrained()"),kxo=o(" class method or the "),jG=a("a"),Sxo=o("from_config()"),Rxo=o(` class
method.`),Pxo=l(),b7=a("p"),Bxo=o("This class cannot be instantiated directly using "),Dfe=a("code"),Ixo=o("__init__()"),Nxo=o(" (throws an error)."),qxo=l(),it=a("div"),F(v7.$$.fragment),jxo=l(),Gfe=a("p"),Dxo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxo=l(),Qi=a("p"),Oxo=o(`Note:
Loading a model from its configuration file does `),Ofe=a("strong"),Vxo=o("not"),Xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=a("a"),zxo=o("from_pretrained()"),Qxo=o(" to load the model weights."),Wxo=l(),F(gb.$$.fragment),Hxo=l(),Ze=a("div"),F(F7.$$.fragment),Uxo=l(),Vfe=a("p"),Jxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yxo=l(),Ia=a("p"),Kxo=o("The model class to instantiate is selected based on the "),Xfe=a("code"),Zxo=o("model_type"),e$o=o(` property of the config object (either
passed as an argument or loaded from `),zfe=a("code"),o$o=o("pretrained_model_name_or_path"),r$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qfe=a("code"),t$o=o("pretrained_model_name_or_path"),a$o=o(":"),n$o=l(),Q=a("ul"),hb=a("li"),Wfe=a("strong"),s$o=o("albert"),l$o=o(" \u2014 "),GG=a("a"),i$o=o("AlbertForMaskedLM"),d$o=o(" (ALBERT model)"),c$o=l(),ub=a("li"),Hfe=a("strong"),m$o=o("bart"),f$o=o(" \u2014 "),OG=a("a"),g$o=o("BartForConditionalGeneration"),h$o=o(" (BART model)"),u$o=l(),pb=a("li"),Ufe=a("strong"),p$o=o("bert"),_$o=o(" \u2014 "),VG=a("a"),b$o=o("BertForMaskedLM"),v$o=o(" (BERT model)"),F$o=l(),_b=a("li"),Jfe=a("strong"),T$o=o("big_bird"),M$o=o(" \u2014 "),XG=a("a"),E$o=o("BigBirdForMaskedLM"),C$o=o(" (BigBird model)"),w$o=l(),bb=a("li"),Yfe=a("strong"),A$o=o("camembert"),L$o=o(" \u2014 "),zG=a("a"),y$o=o("CamembertForMaskedLM"),x$o=o(" (CamemBERT model)"),$$o=l(),vb=a("li"),Kfe=a("strong"),k$o=o("convbert"),S$o=o(" \u2014 "),QG=a("a"),R$o=o("ConvBertForMaskedLM"),P$o=o(" (ConvBERT model)"),B$o=l(),Fb=a("li"),Zfe=a("strong"),I$o=o("data2vec-text"),N$o=o(" \u2014 "),WG=a("a"),q$o=o("Data2VecTextForMaskedLM"),j$o=o(" (Data2VecText model)"),D$o=l(),Tb=a("li"),ege=a("strong"),G$o=o("deberta"),O$o=o(" \u2014 "),HG=a("a"),V$o=o("DebertaForMaskedLM"),X$o=o(" (DeBERTa model)"),z$o=l(),Mb=a("li"),oge=a("strong"),Q$o=o("deberta-v2"),W$o=o(" \u2014 "),UG=a("a"),H$o=o("DebertaV2ForMaskedLM"),U$o=o(" (DeBERTa-v2 model)"),J$o=l(),Eb=a("li"),rge=a("strong"),Y$o=o("distilbert"),K$o=o(" \u2014 "),JG=a("a"),Z$o=o("DistilBertForMaskedLM"),eko=o(" (DistilBERT model)"),oko=l(),Cb=a("li"),tge=a("strong"),rko=o("electra"),tko=o(" \u2014 "),YG=a("a"),ako=o("ElectraForMaskedLM"),nko=o(" (ELECTRA model)"),sko=l(),wb=a("li"),age=a("strong"),lko=o("flaubert"),iko=o(" \u2014 "),KG=a("a"),dko=o("FlaubertWithLMHeadModel"),cko=o(" (FlauBERT model)"),mko=l(),Ab=a("li"),nge=a("strong"),fko=o("fnet"),gko=o(" \u2014 "),ZG=a("a"),hko=o("FNetForMaskedLM"),uko=o(" (FNet model)"),pko=l(),Lb=a("li"),sge=a("strong"),_ko=o("funnel"),bko=o(" \u2014 "),eO=a("a"),vko=o("FunnelForMaskedLM"),Fko=o(" (Funnel Transformer model)"),Tko=l(),yb=a("li"),lge=a("strong"),Mko=o("ibert"),Eko=o(" \u2014 "),oO=a("a"),Cko=o("IBertForMaskedLM"),wko=o(" (I-BERT model)"),Ako=l(),xb=a("li"),ige=a("strong"),Lko=o("layoutlm"),yko=o(" \u2014 "),rO=a("a"),xko=o("LayoutLMForMaskedLM"),$ko=o(" (LayoutLM model)"),kko=l(),$b=a("li"),dge=a("strong"),Sko=o("longformer"),Rko=o(" \u2014 "),tO=a("a"),Pko=o("LongformerForMaskedLM"),Bko=o(" (Longformer model)"),Iko=l(),kb=a("li"),cge=a("strong"),Nko=o("luke"),qko=o(" \u2014 "),aO=a("a"),jko=o("LukeForMaskedLM"),Dko=o(" (LUKE model)"),Gko=l(),Sb=a("li"),mge=a("strong"),Oko=o("mbart"),Vko=o(" \u2014 "),nO=a("a"),Xko=o("MBartForConditionalGeneration"),zko=o(" (mBART model)"),Qko=l(),Rb=a("li"),fge=a("strong"),Wko=o("megatron-bert"),Hko=o(" \u2014 "),sO=a("a"),Uko=o("MegatronBertForMaskedLM"),Jko=o(" (Megatron-BERT model)"),Yko=l(),Pb=a("li"),gge=a("strong"),Kko=o("mobilebert"),Zko=o(" \u2014 "),lO=a("a"),eSo=o("MobileBertForMaskedLM"),oSo=o(" (MobileBERT model)"),rSo=l(),Bb=a("li"),hge=a("strong"),tSo=o("mpnet"),aSo=o(" \u2014 "),iO=a("a"),nSo=o("MPNetForMaskedLM"),sSo=o(" (MPNet model)"),lSo=l(),Ib=a("li"),uge=a("strong"),iSo=o("nezha"),dSo=o(" \u2014 "),dO=a("a"),cSo=o("NezhaForMaskedLM"),mSo=o(" (Nezha model)"),fSo=l(),Nb=a("li"),pge=a("strong"),gSo=o("nystromformer"),hSo=o(" \u2014 "),cO=a("a"),uSo=o("NystromformerForMaskedLM"),pSo=o(" (Nystr\xF6mformer model)"),_So=l(),qb=a("li"),_ge=a("strong"),bSo=o("perceiver"),vSo=o(" \u2014 "),mO=a("a"),FSo=o("PerceiverForMaskedLM"),TSo=o(" (Perceiver model)"),MSo=l(),jb=a("li"),bge=a("strong"),ESo=o("qdqbert"),CSo=o(" \u2014 "),fO=a("a"),wSo=o("QDQBertForMaskedLM"),ASo=o(" (QDQBert model)"),LSo=l(),Db=a("li"),vge=a("strong"),ySo=o("reformer"),xSo=o(" \u2014 "),gO=a("a"),$So=o("ReformerForMaskedLM"),kSo=o(" (Reformer model)"),SSo=l(),Gb=a("li"),Fge=a("strong"),RSo=o("rembert"),PSo=o(" \u2014 "),hO=a("a"),BSo=o("RemBertForMaskedLM"),ISo=o(" (RemBERT model)"),NSo=l(),Ob=a("li"),Tge=a("strong"),qSo=o("roberta"),jSo=o(" \u2014 "),uO=a("a"),DSo=o("RobertaForMaskedLM"),GSo=o(" (RoBERTa model)"),OSo=l(),Vb=a("li"),Mge=a("strong"),VSo=o("roformer"),XSo=o(" \u2014 "),pO=a("a"),zSo=o("RoFormerForMaskedLM"),QSo=o(" (RoFormer model)"),WSo=l(),Xb=a("li"),Ege=a("strong"),HSo=o("squeezebert"),USo=o(" \u2014 "),_O=a("a"),JSo=o("SqueezeBertForMaskedLM"),YSo=o(" (SqueezeBERT model)"),KSo=l(),zb=a("li"),Cge=a("strong"),ZSo=o("tapas"),eRo=o(" \u2014 "),bO=a("a"),oRo=o("TapasForMaskedLM"),rRo=o(" (TAPAS model)"),tRo=l(),Qb=a("li"),wge=a("strong"),aRo=o("wav2vec2"),nRo=o(" \u2014 "),Age=a("code"),sRo=o("Wav2Vec2ForMaskedLM"),lRo=o(" (Wav2Vec2 model)"),iRo=l(),Wb=a("li"),Lge=a("strong"),dRo=o("xlm"),cRo=o(" \u2014 "),vO=a("a"),mRo=o("XLMWithLMHeadModel"),fRo=o(" (XLM model)"),gRo=l(),Hb=a("li"),yge=a("strong"),hRo=o("xlm-roberta"),uRo=o(" \u2014 "),FO=a("a"),pRo=o("XLMRobertaForMaskedLM"),_Ro=o(" (XLM-RoBERTa model)"),bRo=l(),Ub=a("li"),xge=a("strong"),vRo=o("xlm-roberta-xl"),FRo=o(" \u2014 "),TO=a("a"),TRo=o("XLMRobertaXLForMaskedLM"),MRo=o(" (XLM-RoBERTa-XL model)"),ERo=l(),Jb=a("li"),$ge=a("strong"),CRo=o("yoso"),wRo=o(" \u2014 "),MO=a("a"),ARo=o("YosoForMaskedLM"),LRo=o(" (YOSO model)"),yRo=l(),Yb=a("p"),xRo=o("The model is set in evaluation mode by default using "),kge=a("code"),$Ro=o("model.eval()"),kRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=a("code"),SRo=o("model.train()"),RRo=l(),F(Kb.$$.fragment),sOe=l(),Wi=a("h2"),Zb=a("a"),Rge=a("span"),F(T7.$$.fragment),PRo=l(),Pge=a("span"),BRo=o("AutoModelForSeq2SeqLM"),lOe=l(),Ro=a("div"),F(M7.$$.fragment),IRo=l(),Hi=a("p"),NRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=a("a"),qRo=o("from_pretrained()"),jRo=o(" class method or the "),CO=a("a"),DRo=o("from_config()"),GRo=o(` class
method.`),ORo=l(),E7=a("p"),VRo=o("This class cannot be instantiated directly using "),Bge=a("code"),XRo=o("__init__()"),zRo=o(" (throws an error)."),QRo=l(),dt=a("div"),F(C7.$$.fragment),WRo=l(),Ige=a("p"),HRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),URo=l(),Ui=a("p"),JRo=o(`Note:
Loading a model from its configuration file does `),Nge=a("strong"),YRo=o("not"),KRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=a("a"),ZRo=o("from_pretrained()"),ePo=o(" to load the model weights."),oPo=l(),F(ev.$$.fragment),rPo=l(),eo=a("div"),F(w7.$$.fragment),tPo=l(),qge=a("p"),aPo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nPo=l(),Na=a("p"),sPo=o("The model class to instantiate is selected based on the "),jge=a("code"),lPo=o("model_type"),iPo=o(` property of the config object (either
passed as an argument or loaded from `),Dge=a("code"),dPo=o("pretrained_model_name_or_path"),cPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=a("code"),mPo=o("pretrained_model_name_or_path"),fPo=o(":"),gPo=l(),ue=a("ul"),ov=a("li"),Oge=a("strong"),hPo=o("bart"),uPo=o(" \u2014 "),AO=a("a"),pPo=o("BartForConditionalGeneration"),_Po=o(" (BART model)"),bPo=l(),rv=a("li"),Vge=a("strong"),vPo=o("bigbird_pegasus"),FPo=o(" \u2014 "),LO=a("a"),TPo=o("BigBirdPegasusForConditionalGeneration"),MPo=o(" (BigBird-Pegasus model)"),EPo=l(),tv=a("li"),Xge=a("strong"),CPo=o("blenderbot"),wPo=o(" \u2014 "),yO=a("a"),APo=o("BlenderbotForConditionalGeneration"),LPo=o(" (Blenderbot model)"),yPo=l(),av=a("li"),zge=a("strong"),xPo=o("blenderbot-small"),$Po=o(" \u2014 "),xO=a("a"),kPo=o("BlenderbotSmallForConditionalGeneration"),SPo=o(" (BlenderbotSmall model)"),RPo=l(),nv=a("li"),Qge=a("strong"),PPo=o("encoder-decoder"),BPo=o(" \u2014 "),$O=a("a"),IPo=o("EncoderDecoderModel"),NPo=o(" (Encoder decoder model)"),qPo=l(),sv=a("li"),Wge=a("strong"),jPo=o("fsmt"),DPo=o(" \u2014 "),kO=a("a"),GPo=o("FSMTForConditionalGeneration"),OPo=o(" (FairSeq Machine-Translation model)"),VPo=l(),lv=a("li"),Hge=a("strong"),XPo=o("led"),zPo=o(" \u2014 "),SO=a("a"),QPo=o("LEDForConditionalGeneration"),WPo=o(" (LED model)"),HPo=l(),iv=a("li"),Uge=a("strong"),UPo=o("longt5"),JPo=o(" \u2014 "),RO=a("a"),YPo=o("LongT5ForConditionalGeneration"),KPo=o(" (LongT5 model)"),ZPo=l(),dv=a("li"),Jge=a("strong"),eBo=o("m2m_100"),oBo=o(" \u2014 "),PO=a("a"),rBo=o("M2M100ForConditionalGeneration"),tBo=o(" (M2M100 model)"),aBo=l(),cv=a("li"),Yge=a("strong"),nBo=o("marian"),sBo=o(" \u2014 "),BO=a("a"),lBo=o("MarianMTModel"),iBo=o(" (Marian model)"),dBo=l(),mv=a("li"),Kge=a("strong"),cBo=o("mbart"),mBo=o(" \u2014 "),IO=a("a"),fBo=o("MBartForConditionalGeneration"),gBo=o(" (mBART model)"),hBo=l(),fv=a("li"),Zge=a("strong"),uBo=o("mt5"),pBo=o(" \u2014 "),NO=a("a"),_Bo=o("MT5ForConditionalGeneration"),bBo=o(" (MT5 model)"),vBo=l(),gv=a("li"),ehe=a("strong"),FBo=o("pegasus"),TBo=o(" \u2014 "),qO=a("a"),MBo=o("PegasusForConditionalGeneration"),EBo=o(" (Pegasus model)"),CBo=l(),hv=a("li"),ohe=a("strong"),wBo=o("plbart"),ABo=o(" \u2014 "),jO=a("a"),LBo=o("PLBartForConditionalGeneration"),yBo=o(" (PLBart model)"),xBo=l(),uv=a("li"),rhe=a("strong"),$Bo=o("prophetnet"),kBo=o(" \u2014 "),DO=a("a"),SBo=o("ProphetNetForConditionalGeneration"),RBo=o(" (ProphetNet model)"),PBo=l(),pv=a("li"),the=a("strong"),BBo=o("t5"),IBo=o(" \u2014 "),GO=a("a"),NBo=o("T5ForConditionalGeneration"),qBo=o(" (T5 model)"),jBo=l(),_v=a("li"),ahe=a("strong"),DBo=o("xlm-prophetnet"),GBo=o(" \u2014 "),OO=a("a"),OBo=o("XLMProphetNetForConditionalGeneration"),VBo=o(" (XLM-ProphetNet model)"),XBo=l(),bv=a("p"),zBo=o("The model is set in evaluation mode by default using "),nhe=a("code"),QBo=o("model.eval()"),WBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=a("code"),HBo=o("model.train()"),UBo=l(),F(vv.$$.fragment),iOe=l(),Ji=a("h2"),Fv=a("a"),lhe=a("span"),F(A7.$$.fragment),JBo=l(),ihe=a("span"),YBo=o("AutoModelForSequenceClassification"),dOe=l(),Po=a("div"),F(L7.$$.fragment),KBo=l(),Yi=a("p"),ZBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=a("a"),eIo=o("from_pretrained()"),oIo=o(" class method or the "),XO=a("a"),rIo=o("from_config()"),tIo=o(` class
method.`),aIo=l(),y7=a("p"),nIo=o("This class cannot be instantiated directly using "),dhe=a("code"),sIo=o("__init__()"),lIo=o(" (throws an error)."),iIo=l(),ct=a("div"),F(x7.$$.fragment),dIo=l(),che=a("p"),cIo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),mIo=l(),Ki=a("p"),fIo=o(`Note:
Loading a model from its configuration file does `),mhe=a("strong"),gIo=o("not"),hIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=a("a"),uIo=o("from_pretrained()"),pIo=o(" to load the model weights."),_Io=l(),F(Tv.$$.fragment),bIo=l(),oo=a("div"),F($7.$$.fragment),vIo=l(),fhe=a("p"),FIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TIo=l(),qa=a("p"),MIo=o("The model class to instantiate is selected based on the "),ghe=a("code"),EIo=o("model_type"),CIo=o(` property of the config object (either
passed as an argument or loaded from `),hhe=a("code"),wIo=o("pretrained_model_name_or_path"),AIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uhe=a("code"),LIo=o("pretrained_model_name_or_path"),yIo=o(":"),xIo=l(),N=a("ul"),Mv=a("li"),phe=a("strong"),$Io=o("albert"),kIo=o(" \u2014 "),QO=a("a"),SIo=o("AlbertForSequenceClassification"),RIo=o(" (ALBERT model)"),PIo=l(),Ev=a("li"),_he=a("strong"),BIo=o("bart"),IIo=o(" \u2014 "),WO=a("a"),NIo=o("BartForSequenceClassification"),qIo=o(" (BART model)"),jIo=l(),Cv=a("li"),bhe=a("strong"),DIo=o("bert"),GIo=o(" \u2014 "),HO=a("a"),OIo=o("BertForSequenceClassification"),VIo=o(" (BERT model)"),XIo=l(),wv=a("li"),vhe=a("strong"),zIo=o("big_bird"),QIo=o(" \u2014 "),UO=a("a"),WIo=o("BigBirdForSequenceClassification"),HIo=o(" (BigBird model)"),UIo=l(),Av=a("li"),Fhe=a("strong"),JIo=o("bigbird_pegasus"),YIo=o(" \u2014 "),JO=a("a"),KIo=o("BigBirdPegasusForSequenceClassification"),ZIo=o(" (BigBird-Pegasus model)"),eNo=l(),Lv=a("li"),The=a("strong"),oNo=o("bloom"),rNo=o(" \u2014 "),YO=a("a"),tNo=o("BloomForSequenceClassification"),aNo=o(" (BLOOM model)"),nNo=l(),yv=a("li"),Mhe=a("strong"),sNo=o("camembert"),lNo=o(" \u2014 "),KO=a("a"),iNo=o("CamembertForSequenceClassification"),dNo=o(" (CamemBERT model)"),cNo=l(),xv=a("li"),Ehe=a("strong"),mNo=o("canine"),fNo=o(" \u2014 "),ZO=a("a"),gNo=o("CanineForSequenceClassification"),hNo=o(" (CANINE model)"),uNo=l(),$v=a("li"),Che=a("strong"),pNo=o("convbert"),_No=o(" \u2014 "),eV=a("a"),bNo=o("ConvBertForSequenceClassification"),vNo=o(" (ConvBERT model)"),FNo=l(),kv=a("li"),whe=a("strong"),TNo=o("ctrl"),MNo=o(" \u2014 "),oV=a("a"),ENo=o("CTRLForSequenceClassification"),CNo=o(" (CTRL model)"),wNo=l(),Sv=a("li"),Ahe=a("strong"),ANo=o("data2vec-text"),LNo=o(" \u2014 "),rV=a("a"),yNo=o("Data2VecTextForSequenceClassification"),xNo=o(" (Data2VecText model)"),$No=l(),Rv=a("li"),Lhe=a("strong"),kNo=o("deberta"),SNo=o(" \u2014 "),tV=a("a"),RNo=o("DebertaForSequenceClassification"),PNo=o(" (DeBERTa model)"),BNo=l(),Pv=a("li"),yhe=a("strong"),INo=o("deberta-v2"),NNo=o(" \u2014 "),aV=a("a"),qNo=o("DebertaV2ForSequenceClassification"),jNo=o(" (DeBERTa-v2 model)"),DNo=l(),Bv=a("li"),xhe=a("strong"),GNo=o("distilbert"),ONo=o(" \u2014 "),nV=a("a"),VNo=o("DistilBertForSequenceClassification"),XNo=o(" (DistilBERT model)"),zNo=l(),Iv=a("li"),$he=a("strong"),QNo=o("electra"),WNo=o(" \u2014 "),sV=a("a"),HNo=o("ElectraForSequenceClassification"),UNo=o(" (ELECTRA model)"),JNo=l(),Nv=a("li"),khe=a("strong"),YNo=o("flaubert"),KNo=o(" \u2014 "),lV=a("a"),ZNo=o("FlaubertForSequenceClassification"),eqo=o(" (FlauBERT model)"),oqo=l(),qv=a("li"),She=a("strong"),rqo=o("fnet"),tqo=o(" \u2014 "),iV=a("a"),aqo=o("FNetForSequenceClassification"),nqo=o(" (FNet model)"),sqo=l(),jv=a("li"),Rhe=a("strong"),lqo=o("funnel"),iqo=o(" \u2014 "),dV=a("a"),dqo=o("FunnelForSequenceClassification"),cqo=o(" (Funnel Transformer model)"),mqo=l(),Dv=a("li"),Phe=a("strong"),fqo=o("gpt2"),gqo=o(" \u2014 "),cV=a("a"),hqo=o("GPT2ForSequenceClassification"),uqo=o(" (OpenAI GPT-2 model)"),pqo=l(),Gv=a("li"),Bhe=a("strong"),_qo=o("gpt_neo"),bqo=o(" \u2014 "),mV=a("a"),vqo=o("GPTNeoForSequenceClassification"),Fqo=o(" (GPT Neo model)"),Tqo=l(),Ov=a("li"),Ihe=a("strong"),Mqo=o("gptj"),Eqo=o(" \u2014 "),fV=a("a"),Cqo=o("GPTJForSequenceClassification"),wqo=o(" (GPT-J model)"),Aqo=l(),Vv=a("li"),Nhe=a("strong"),Lqo=o("ibert"),yqo=o(" \u2014 "),gV=a("a"),xqo=o("IBertForSequenceClassification"),$qo=o(" (I-BERT model)"),kqo=l(),Xv=a("li"),qhe=a("strong"),Sqo=o("layoutlm"),Rqo=o(" \u2014 "),hV=a("a"),Pqo=o("LayoutLMForSequenceClassification"),Bqo=o(" (LayoutLM model)"),Iqo=l(),zv=a("li"),jhe=a("strong"),Nqo=o("layoutlmv2"),qqo=o(" \u2014 "),uV=a("a"),jqo=o("LayoutLMv2ForSequenceClassification"),Dqo=o(" (LayoutLMv2 model)"),Gqo=l(),Qv=a("li"),Dhe=a("strong"),Oqo=o("layoutlmv3"),Vqo=o(" \u2014 "),pV=a("a"),Xqo=o("LayoutLMv3ForSequenceClassification"),zqo=o(" (LayoutLMv3 model)"),Qqo=l(),Wv=a("li"),Ghe=a("strong"),Wqo=o("led"),Hqo=o(" \u2014 "),_V=a("a"),Uqo=o("LEDForSequenceClassification"),Jqo=o(" (LED model)"),Yqo=l(),Hv=a("li"),Ohe=a("strong"),Kqo=o("longformer"),Zqo=o(" \u2014 "),bV=a("a"),ejo=o("LongformerForSequenceClassification"),ojo=o(" (Longformer model)"),rjo=l(),Uv=a("li"),Vhe=a("strong"),tjo=o("mbart"),ajo=o(" \u2014 "),vV=a("a"),njo=o("MBartForSequenceClassification"),sjo=o(" (mBART model)"),ljo=l(),Jv=a("li"),Xhe=a("strong"),ijo=o("megatron-bert"),djo=o(" \u2014 "),FV=a("a"),cjo=o("MegatronBertForSequenceClassification"),mjo=o(" (Megatron-BERT model)"),fjo=l(),Yv=a("li"),zhe=a("strong"),gjo=o("mobilebert"),hjo=o(" \u2014 "),TV=a("a"),ujo=o("MobileBertForSequenceClassification"),pjo=o(" (MobileBERT model)"),_jo=l(),Kv=a("li"),Qhe=a("strong"),bjo=o("mpnet"),vjo=o(" \u2014 "),MV=a("a"),Fjo=o("MPNetForSequenceClassification"),Tjo=o(" (MPNet model)"),Mjo=l(),Zv=a("li"),Whe=a("strong"),Ejo=o("nezha"),Cjo=o(" \u2014 "),EV=a("a"),wjo=o("NezhaForSequenceClassification"),Ajo=o(" (Nezha model)"),Ljo=l(),eF=a("li"),Hhe=a("strong"),yjo=o("nystromformer"),xjo=o(" \u2014 "),CV=a("a"),$jo=o("NystromformerForSequenceClassification"),kjo=o(" (Nystr\xF6mformer model)"),Sjo=l(),oF=a("li"),Uhe=a("strong"),Rjo=o("openai-gpt"),Pjo=o(" \u2014 "),wV=a("a"),Bjo=o("OpenAIGPTForSequenceClassification"),Ijo=o(" (OpenAI GPT model)"),Njo=l(),rF=a("li"),Jhe=a("strong"),qjo=o("perceiver"),jjo=o(" \u2014 "),AV=a("a"),Djo=o("PerceiverForSequenceClassification"),Gjo=o(" (Perceiver model)"),Ojo=l(),tF=a("li"),Yhe=a("strong"),Vjo=o("plbart"),Xjo=o(" \u2014 "),LV=a("a"),zjo=o("PLBartForSequenceClassification"),Qjo=o(" (PLBart model)"),Wjo=l(),aF=a("li"),Khe=a("strong"),Hjo=o("qdqbert"),Ujo=o(" \u2014 "),yV=a("a"),Jjo=o("QDQBertForSequenceClassification"),Yjo=o(" (QDQBert model)"),Kjo=l(),nF=a("li"),Zhe=a("strong"),Zjo=o("reformer"),eDo=o(" \u2014 "),xV=a("a"),oDo=o("ReformerForSequenceClassification"),rDo=o(" (Reformer model)"),tDo=l(),sF=a("li"),eue=a("strong"),aDo=o("rembert"),nDo=o(" \u2014 "),$V=a("a"),sDo=o("RemBertForSequenceClassification"),lDo=o(" (RemBERT model)"),iDo=l(),lF=a("li"),oue=a("strong"),dDo=o("roberta"),cDo=o(" \u2014 "),kV=a("a"),mDo=o("RobertaForSequenceClassification"),fDo=o(" (RoBERTa model)"),gDo=l(),iF=a("li"),rue=a("strong"),hDo=o("roformer"),uDo=o(" \u2014 "),SV=a("a"),pDo=o("RoFormerForSequenceClassification"),_Do=o(" (RoFormer model)"),bDo=l(),dF=a("li"),tue=a("strong"),vDo=o("squeezebert"),FDo=o(" \u2014 "),RV=a("a"),TDo=o("SqueezeBertForSequenceClassification"),MDo=o(" (SqueezeBERT model)"),EDo=l(),cF=a("li"),aue=a("strong"),CDo=o("tapas"),wDo=o(" \u2014 "),PV=a("a"),ADo=o("TapasForSequenceClassification"),LDo=o(" (TAPAS model)"),yDo=l(),mF=a("li"),nue=a("strong"),xDo=o("transfo-xl"),$Do=o(" \u2014 "),BV=a("a"),kDo=o("TransfoXLForSequenceClassification"),SDo=o(" (Transformer-XL model)"),RDo=l(),fF=a("li"),sue=a("strong"),PDo=o("xlm"),BDo=o(" \u2014 "),IV=a("a"),IDo=o("XLMForSequenceClassification"),NDo=o(" (XLM model)"),qDo=l(),gF=a("li"),lue=a("strong"),jDo=o("xlm-roberta"),DDo=o(" \u2014 "),NV=a("a"),GDo=o("XLMRobertaForSequenceClassification"),ODo=o(" (XLM-RoBERTa model)"),VDo=l(),hF=a("li"),iue=a("strong"),XDo=o("xlm-roberta-xl"),zDo=o(" \u2014 "),qV=a("a"),QDo=o("XLMRobertaXLForSequenceClassification"),WDo=o(" (XLM-RoBERTa-XL model)"),HDo=l(),uF=a("li"),due=a("strong"),UDo=o("xlnet"),JDo=o(" \u2014 "),jV=a("a"),YDo=o("XLNetForSequenceClassification"),KDo=o(" (XLNet model)"),ZDo=l(),pF=a("li"),cue=a("strong"),eGo=o("yoso"),oGo=o(" \u2014 "),DV=a("a"),rGo=o("YosoForSequenceClassification"),tGo=o(" (YOSO model)"),aGo=l(),_F=a("p"),nGo=o("The model is set in evaluation mode by default using "),mue=a("code"),sGo=o("model.eval()"),lGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fue=a("code"),iGo=o("model.train()"),dGo=l(),F(bF.$$.fragment),cOe=l(),Zi=a("h2"),vF=a("a"),gue=a("span"),F(k7.$$.fragment),cGo=l(),hue=a("span"),mGo=o("AutoModelForMultipleChoice"),mOe=l(),Bo=a("div"),F(S7.$$.fragment),fGo=l(),ed=a("p"),gGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=a("a"),hGo=o("from_pretrained()"),uGo=o(" class method or the "),OV=a("a"),pGo=o("from_config()"),_Go=o(` class
method.`),bGo=l(),R7=a("p"),vGo=o("This class cannot be instantiated directly using "),uue=a("code"),FGo=o("__init__()"),TGo=o(" (throws an error)."),MGo=l(),mt=a("div"),F(P7.$$.fragment),EGo=l(),pue=a("p"),CGo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wGo=l(),od=a("p"),AGo=o(`Note:
Loading a model from its configuration file does `),_ue=a("strong"),LGo=o("not"),yGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),xGo=o("from_pretrained()"),$Go=o(" to load the model weights."),kGo=l(),F(FF.$$.fragment),SGo=l(),ro=a("div"),F(B7.$$.fragment),RGo=l(),bue=a("p"),PGo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BGo=l(),ja=a("p"),IGo=o("The model class to instantiate is selected based on the "),vue=a("code"),NGo=o("model_type"),qGo=o(` property of the config object (either
passed as an argument or loaded from `),Fue=a("code"),jGo=o("pretrained_model_name_or_path"),DGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tue=a("code"),GGo=o("pretrained_model_name_or_path"),OGo=o(":"),VGo=l(),Z=a("ul"),TF=a("li"),Mue=a("strong"),XGo=o("albert"),zGo=o(" \u2014 "),XV=a("a"),QGo=o("AlbertForMultipleChoice"),WGo=o(" (ALBERT model)"),HGo=l(),MF=a("li"),Eue=a("strong"),UGo=o("bert"),JGo=o(" \u2014 "),zV=a("a"),YGo=o("BertForMultipleChoice"),KGo=o(" (BERT model)"),ZGo=l(),EF=a("li"),Cue=a("strong"),eOo=o("big_bird"),oOo=o(" \u2014 "),QV=a("a"),rOo=o("BigBirdForMultipleChoice"),tOo=o(" (BigBird model)"),aOo=l(),CF=a("li"),wue=a("strong"),nOo=o("camembert"),sOo=o(" \u2014 "),WV=a("a"),lOo=o("CamembertForMultipleChoice"),iOo=o(" (CamemBERT model)"),dOo=l(),wF=a("li"),Aue=a("strong"),cOo=o("canine"),mOo=o(" \u2014 "),HV=a("a"),fOo=o("CanineForMultipleChoice"),gOo=o(" (CANINE model)"),hOo=l(),AF=a("li"),Lue=a("strong"),uOo=o("convbert"),pOo=o(" \u2014 "),UV=a("a"),_Oo=o("ConvBertForMultipleChoice"),bOo=o(" (ConvBERT model)"),vOo=l(),LF=a("li"),yue=a("strong"),FOo=o("data2vec-text"),TOo=o(" \u2014 "),JV=a("a"),MOo=o("Data2VecTextForMultipleChoice"),EOo=o(" (Data2VecText model)"),COo=l(),yF=a("li"),xue=a("strong"),wOo=o("deberta-v2"),AOo=o(" \u2014 "),YV=a("a"),LOo=o("DebertaV2ForMultipleChoice"),yOo=o(" (DeBERTa-v2 model)"),xOo=l(),xF=a("li"),$ue=a("strong"),$Oo=o("distilbert"),kOo=o(" \u2014 "),KV=a("a"),SOo=o("DistilBertForMultipleChoice"),ROo=o(" (DistilBERT model)"),POo=l(),$F=a("li"),kue=a("strong"),BOo=o("electra"),IOo=o(" \u2014 "),ZV=a("a"),NOo=o("ElectraForMultipleChoice"),qOo=o(" (ELECTRA model)"),jOo=l(),kF=a("li"),Sue=a("strong"),DOo=o("flaubert"),GOo=o(" \u2014 "),eX=a("a"),OOo=o("FlaubertForMultipleChoice"),VOo=o(" (FlauBERT model)"),XOo=l(),SF=a("li"),Rue=a("strong"),zOo=o("fnet"),QOo=o(" \u2014 "),oX=a("a"),WOo=o("FNetForMultipleChoice"),HOo=o(" (FNet model)"),UOo=l(),RF=a("li"),Pue=a("strong"),JOo=o("funnel"),YOo=o(" \u2014 "),rX=a("a"),KOo=o("FunnelForMultipleChoice"),ZOo=o(" (Funnel Transformer model)"),eVo=l(),PF=a("li"),Bue=a("strong"),oVo=o("ibert"),rVo=o(" \u2014 "),tX=a("a"),tVo=o("IBertForMultipleChoice"),aVo=o(" (I-BERT model)"),nVo=l(),BF=a("li"),Iue=a("strong"),sVo=o("longformer"),lVo=o(" \u2014 "),aX=a("a"),iVo=o("LongformerForMultipleChoice"),dVo=o(" (Longformer model)"),cVo=l(),IF=a("li"),Nue=a("strong"),mVo=o("megatron-bert"),fVo=o(" \u2014 "),nX=a("a"),gVo=o("MegatronBertForMultipleChoice"),hVo=o(" (Megatron-BERT model)"),uVo=l(),NF=a("li"),que=a("strong"),pVo=o("mobilebert"),_Vo=o(" \u2014 "),sX=a("a"),bVo=o("MobileBertForMultipleChoice"),vVo=o(" (MobileBERT model)"),FVo=l(),qF=a("li"),jue=a("strong"),TVo=o("mpnet"),MVo=o(" \u2014 "),lX=a("a"),EVo=o("MPNetForMultipleChoice"),CVo=o(" (MPNet model)"),wVo=l(),jF=a("li"),Due=a("strong"),AVo=o("nezha"),LVo=o(" \u2014 "),iX=a("a"),yVo=o("NezhaForMultipleChoice"),xVo=o(" (Nezha model)"),$Vo=l(),DF=a("li"),Gue=a("strong"),kVo=o("nystromformer"),SVo=o(" \u2014 "),dX=a("a"),RVo=o("NystromformerForMultipleChoice"),PVo=o(" (Nystr\xF6mformer model)"),BVo=l(),GF=a("li"),Oue=a("strong"),IVo=o("qdqbert"),NVo=o(" \u2014 "),cX=a("a"),qVo=o("QDQBertForMultipleChoice"),jVo=o(" (QDQBert model)"),DVo=l(),OF=a("li"),Vue=a("strong"),GVo=o("rembert"),OVo=o(" \u2014 "),mX=a("a"),VVo=o("RemBertForMultipleChoice"),XVo=o(" (RemBERT model)"),zVo=l(),VF=a("li"),Xue=a("strong"),QVo=o("roberta"),WVo=o(" \u2014 "),fX=a("a"),HVo=o("RobertaForMultipleChoice"),UVo=o(" (RoBERTa model)"),JVo=l(),XF=a("li"),zue=a("strong"),YVo=o("roformer"),KVo=o(" \u2014 "),gX=a("a"),ZVo=o("RoFormerForMultipleChoice"),eXo=o(" (RoFormer model)"),oXo=l(),zF=a("li"),Que=a("strong"),rXo=o("squeezebert"),tXo=o(" \u2014 "),hX=a("a"),aXo=o("SqueezeBertForMultipleChoice"),nXo=o(" (SqueezeBERT model)"),sXo=l(),QF=a("li"),Wue=a("strong"),lXo=o("xlm"),iXo=o(" \u2014 "),uX=a("a"),dXo=o("XLMForMultipleChoice"),cXo=o(" (XLM model)"),mXo=l(),WF=a("li"),Hue=a("strong"),fXo=o("xlm-roberta"),gXo=o(" \u2014 "),pX=a("a"),hXo=o("XLMRobertaForMultipleChoice"),uXo=o(" (XLM-RoBERTa model)"),pXo=l(),HF=a("li"),Uue=a("strong"),_Xo=o("xlm-roberta-xl"),bXo=o(" \u2014 "),_X=a("a"),vXo=o("XLMRobertaXLForMultipleChoice"),FXo=o(" (XLM-RoBERTa-XL model)"),TXo=l(),UF=a("li"),Jue=a("strong"),MXo=o("xlnet"),EXo=o(" \u2014 "),bX=a("a"),CXo=o("XLNetForMultipleChoice"),wXo=o(" (XLNet model)"),AXo=l(),JF=a("li"),Yue=a("strong"),LXo=o("yoso"),yXo=o(" \u2014 "),vX=a("a"),xXo=o("YosoForMultipleChoice"),$Xo=o(" (YOSO model)"),kXo=l(),YF=a("p"),SXo=o("The model is set in evaluation mode by default using "),Kue=a("code"),RXo=o("model.eval()"),PXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zue=a("code"),BXo=o("model.train()"),IXo=l(),F(KF.$$.fragment),fOe=l(),rd=a("h2"),ZF=a("a"),epe=a("span"),F(I7.$$.fragment),NXo=l(),ope=a("span"),qXo=o("AutoModelForNextSentencePrediction"),gOe=l(),Io=a("div"),F(N7.$$.fragment),jXo=l(),td=a("p"),DXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=a("a"),GXo=o("from_pretrained()"),OXo=o(" class method or the "),TX=a("a"),VXo=o("from_config()"),XXo=o(` class
method.`),zXo=l(),q7=a("p"),QXo=o("This class cannot be instantiated directly using "),rpe=a("code"),WXo=o("__init__()"),HXo=o(" (throws an error)."),UXo=l(),ft=a("div"),F(j7.$$.fragment),JXo=l(),tpe=a("p"),YXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),KXo=l(),ad=a("p"),ZXo=o(`Note:
Loading a model from its configuration file does `),ape=a("strong"),ezo=o("not"),ozo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),rzo=o("from_pretrained()"),tzo=o(" to load the model weights."),azo=l(),F(e1.$$.fragment),nzo=l(),to=a("div"),F(D7.$$.fragment),szo=l(),npe=a("p"),lzo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),izo=l(),Da=a("p"),dzo=o("The model class to instantiate is selected based on the "),spe=a("code"),czo=o("model_type"),mzo=o(` property of the config object (either
passed as an argument or loaded from `),lpe=a("code"),fzo=o("pretrained_model_name_or_path"),gzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ipe=a("code"),hzo=o("pretrained_model_name_or_path"),uzo=o(":"),pzo=l(),No=a("ul"),o1=a("li"),dpe=a("strong"),_zo=o("bert"),bzo=o(" \u2014 "),EX=a("a"),vzo=o("BertForNextSentencePrediction"),Fzo=o(" (BERT model)"),Tzo=l(),r1=a("li"),cpe=a("strong"),Mzo=o("fnet"),Ezo=o(" \u2014 "),CX=a("a"),Czo=o("FNetForNextSentencePrediction"),wzo=o(" (FNet model)"),Azo=l(),t1=a("li"),mpe=a("strong"),Lzo=o("megatron-bert"),yzo=o(" \u2014 "),wX=a("a"),xzo=o("MegatronBertForNextSentencePrediction"),$zo=o(" (Megatron-BERT model)"),kzo=l(),a1=a("li"),fpe=a("strong"),Szo=o("mobilebert"),Rzo=o(" \u2014 "),AX=a("a"),Pzo=o("MobileBertForNextSentencePrediction"),Bzo=o(" (MobileBERT model)"),Izo=l(),n1=a("li"),gpe=a("strong"),Nzo=o("nezha"),qzo=o(" \u2014 "),LX=a("a"),jzo=o("NezhaForNextSentencePrediction"),Dzo=o(" (Nezha model)"),Gzo=l(),s1=a("li"),hpe=a("strong"),Ozo=o("qdqbert"),Vzo=o(" \u2014 "),yX=a("a"),Xzo=o("QDQBertForNextSentencePrediction"),zzo=o(" (QDQBert model)"),Qzo=l(),l1=a("p"),Wzo=o("The model is set in evaluation mode by default using "),upe=a("code"),Hzo=o("model.eval()"),Uzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ppe=a("code"),Jzo=o("model.train()"),Yzo=l(),F(i1.$$.fragment),hOe=l(),nd=a("h2"),d1=a("a"),_pe=a("span"),F(G7.$$.fragment),Kzo=l(),bpe=a("span"),Zzo=o("AutoModelForTokenClassification"),uOe=l(),qo=a("div"),F(O7.$$.fragment),eQo=l(),sd=a("p"),oQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=a("a"),rQo=o("from_pretrained()"),tQo=o(" class method or the "),$X=a("a"),aQo=o("from_config()"),nQo=o(` class
method.`),sQo=l(),V7=a("p"),lQo=o("This class cannot be instantiated directly using "),vpe=a("code"),iQo=o("__init__()"),dQo=o(" (throws an error)."),cQo=l(),gt=a("div"),F(X7.$$.fragment),mQo=l(),Fpe=a("p"),fQo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gQo=l(),ld=a("p"),hQo=o(`Note:
Loading a model from its configuration file does `),Tpe=a("strong"),uQo=o("not"),pQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),_Qo=o("from_pretrained()"),bQo=o(" to load the model weights."),vQo=l(),F(c1.$$.fragment),FQo=l(),ao=a("div"),F(z7.$$.fragment),TQo=l(),Mpe=a("p"),MQo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EQo=l(),Ga=a("p"),CQo=o("The model class to instantiate is selected based on the "),Epe=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),Cpe=a("code"),LQo=o("pretrained_model_name_or_path"),yQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wpe=a("code"),xQo=o("pretrained_model_name_or_path"),$Qo=o(":"),kQo=l(),H=a("ul"),m1=a("li"),Ape=a("strong"),SQo=o("albert"),RQo=o(" \u2014 "),SX=a("a"),PQo=o("AlbertForTokenClassification"),BQo=o(" (ALBERT model)"),IQo=l(),f1=a("li"),Lpe=a("strong"),NQo=o("bert"),qQo=o(" \u2014 "),RX=a("a"),jQo=o("BertForTokenClassification"),DQo=o(" (BERT model)"),GQo=l(),g1=a("li"),ype=a("strong"),OQo=o("big_bird"),VQo=o(" \u2014 "),PX=a("a"),XQo=o("BigBirdForTokenClassification"),zQo=o(" (BigBird model)"),QQo=l(),h1=a("li"),xpe=a("strong"),WQo=o("bloom"),HQo=o(" \u2014 "),BX=a("a"),UQo=o("BloomForTokenClassification"),JQo=o(" (BLOOM model)"),YQo=l(),u1=a("li"),$pe=a("strong"),KQo=o("camembert"),ZQo=o(" \u2014 "),IX=a("a"),eWo=o("CamembertForTokenClassification"),oWo=o(" (CamemBERT model)"),rWo=l(),p1=a("li"),kpe=a("strong"),tWo=o("canine"),aWo=o(" \u2014 "),NX=a("a"),nWo=o("CanineForTokenClassification"),sWo=o(" (CANINE model)"),lWo=l(),_1=a("li"),Spe=a("strong"),iWo=o("convbert"),dWo=o(" \u2014 "),qX=a("a"),cWo=o("ConvBertForTokenClassification"),mWo=o(" (ConvBERT model)"),fWo=l(),b1=a("li"),Rpe=a("strong"),gWo=o("data2vec-text"),hWo=o(" \u2014 "),jX=a("a"),uWo=o("Data2VecTextForTokenClassification"),pWo=o(" (Data2VecText model)"),_Wo=l(),v1=a("li"),Ppe=a("strong"),bWo=o("deberta"),vWo=o(" \u2014 "),DX=a("a"),FWo=o("DebertaForTokenClassification"),TWo=o(" (DeBERTa model)"),MWo=l(),F1=a("li"),Bpe=a("strong"),EWo=o("deberta-v2"),CWo=o(" \u2014 "),GX=a("a"),wWo=o("DebertaV2ForTokenClassification"),AWo=o(" (DeBERTa-v2 model)"),LWo=l(),T1=a("li"),Ipe=a("strong"),yWo=o("distilbert"),xWo=o(" \u2014 "),OX=a("a"),$Wo=o("DistilBertForTokenClassification"),kWo=o(" (DistilBERT model)"),SWo=l(),M1=a("li"),Npe=a("strong"),RWo=o("electra"),PWo=o(" \u2014 "),VX=a("a"),BWo=o("ElectraForTokenClassification"),IWo=o(" (ELECTRA model)"),NWo=l(),E1=a("li"),qpe=a("strong"),qWo=o("flaubert"),jWo=o(" \u2014 "),XX=a("a"),DWo=o("FlaubertForTokenClassification"),GWo=o(" (FlauBERT model)"),OWo=l(),C1=a("li"),jpe=a("strong"),VWo=o("fnet"),XWo=o(" \u2014 "),zX=a("a"),zWo=o("FNetForTokenClassification"),QWo=o(" (FNet model)"),WWo=l(),w1=a("li"),Dpe=a("strong"),HWo=o("funnel"),UWo=o(" \u2014 "),QX=a("a"),JWo=o("FunnelForTokenClassification"),YWo=o(" (Funnel Transformer model)"),KWo=l(),A1=a("li"),Gpe=a("strong"),ZWo=o("gpt2"),eHo=o(" \u2014 "),WX=a("a"),oHo=o("GPT2ForTokenClassification"),rHo=o(" (OpenAI GPT-2 model)"),tHo=l(),L1=a("li"),Ope=a("strong"),aHo=o("ibert"),nHo=o(" \u2014 "),HX=a("a"),sHo=o("IBertForTokenClassification"),lHo=o(" (I-BERT model)"),iHo=l(),y1=a("li"),Vpe=a("strong"),dHo=o("layoutlm"),cHo=o(" \u2014 "),UX=a("a"),mHo=o("LayoutLMForTokenClassification"),fHo=o(" (LayoutLM model)"),gHo=l(),x1=a("li"),Xpe=a("strong"),hHo=o("layoutlmv2"),uHo=o(" \u2014 "),JX=a("a"),pHo=o("LayoutLMv2ForTokenClassification"),_Ho=o(" (LayoutLMv2 model)"),bHo=l(),$1=a("li"),zpe=a("strong"),vHo=o("layoutlmv3"),FHo=o(" \u2014 "),YX=a("a"),THo=o("LayoutLMv3ForTokenClassification"),MHo=o(" (LayoutLMv3 model)"),EHo=l(),k1=a("li"),Qpe=a("strong"),CHo=o("longformer"),wHo=o(" \u2014 "),KX=a("a"),AHo=o("LongformerForTokenClassification"),LHo=o(" (Longformer model)"),yHo=l(),S1=a("li"),Wpe=a("strong"),xHo=o("megatron-bert"),$Ho=o(" \u2014 "),ZX=a("a"),kHo=o("MegatronBertForTokenClassification"),SHo=o(" (Megatron-BERT model)"),RHo=l(),R1=a("li"),Hpe=a("strong"),PHo=o("mobilebert"),BHo=o(" \u2014 "),ez=a("a"),IHo=o("MobileBertForTokenClassification"),NHo=o(" (MobileBERT model)"),qHo=l(),P1=a("li"),Upe=a("strong"),jHo=o("mpnet"),DHo=o(" \u2014 "),oz=a("a"),GHo=o("MPNetForTokenClassification"),OHo=o(" (MPNet model)"),VHo=l(),B1=a("li"),Jpe=a("strong"),XHo=o("nezha"),zHo=o(" \u2014 "),rz=a("a"),QHo=o("NezhaForTokenClassification"),WHo=o(" (Nezha model)"),HHo=l(),I1=a("li"),Ype=a("strong"),UHo=o("nystromformer"),JHo=o(" \u2014 "),tz=a("a"),YHo=o("NystromformerForTokenClassification"),KHo=o(" (Nystr\xF6mformer model)"),ZHo=l(),N1=a("li"),Kpe=a("strong"),eUo=o("qdqbert"),oUo=o(" \u2014 "),az=a("a"),rUo=o("QDQBertForTokenClassification"),tUo=o(" (QDQBert model)"),aUo=l(),q1=a("li"),Zpe=a("strong"),nUo=o("rembert"),sUo=o(" \u2014 "),nz=a("a"),lUo=o("RemBertForTokenClassification"),iUo=o(" (RemBERT model)"),dUo=l(),j1=a("li"),e_e=a("strong"),cUo=o("roberta"),mUo=o(" \u2014 "),sz=a("a"),fUo=o("RobertaForTokenClassification"),gUo=o(" (RoBERTa model)"),hUo=l(),D1=a("li"),o_e=a("strong"),uUo=o("roformer"),pUo=o(" \u2014 "),lz=a("a"),_Uo=o("RoFormerForTokenClassification"),bUo=o(" (RoFormer model)"),vUo=l(),G1=a("li"),r_e=a("strong"),FUo=o("squeezebert"),TUo=o(" \u2014 "),iz=a("a"),MUo=o("SqueezeBertForTokenClassification"),EUo=o(" (SqueezeBERT model)"),CUo=l(),O1=a("li"),t_e=a("strong"),wUo=o("xlm"),AUo=o(" \u2014 "),dz=a("a"),LUo=o("XLMForTokenClassification"),yUo=o(" (XLM model)"),xUo=l(),V1=a("li"),a_e=a("strong"),$Uo=o("xlm-roberta"),kUo=o(" \u2014 "),cz=a("a"),SUo=o("XLMRobertaForTokenClassification"),RUo=o(" (XLM-RoBERTa model)"),PUo=l(),X1=a("li"),n_e=a("strong"),BUo=o("xlm-roberta-xl"),IUo=o(" \u2014 "),mz=a("a"),NUo=o("XLMRobertaXLForTokenClassification"),qUo=o(" (XLM-RoBERTa-XL model)"),jUo=l(),z1=a("li"),s_e=a("strong"),DUo=o("xlnet"),GUo=o(" \u2014 "),fz=a("a"),OUo=o("XLNetForTokenClassification"),VUo=o(" (XLNet model)"),XUo=l(),Q1=a("li"),l_e=a("strong"),zUo=o("yoso"),QUo=o(" \u2014 "),gz=a("a"),WUo=o("YosoForTokenClassification"),HUo=o(" (YOSO model)"),UUo=l(),W1=a("p"),JUo=o("The model is set in evaluation mode by default using "),i_e=a("code"),YUo=o("model.eval()"),KUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d_e=a("code"),ZUo=o("model.train()"),eJo=l(),F(H1.$$.fragment),pOe=l(),id=a("h2"),U1=a("a"),c_e=a("span"),F(Q7.$$.fragment),oJo=l(),m_e=a("span"),rJo=o("AutoModelForQuestionAnswering"),_Oe=l(),jo=a("div"),F(W7.$$.fragment),tJo=l(),dd=a("p"),aJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=a("a"),nJo=o("from_pretrained()"),sJo=o(" class method or the "),uz=a("a"),lJo=o("from_config()"),iJo=o(` class
method.`),dJo=l(),H7=a("p"),cJo=o("This class cannot be instantiated directly using "),f_e=a("code"),mJo=o("__init__()"),fJo=o(" (throws an error)."),gJo=l(),ht=a("div"),F(U7.$$.fragment),hJo=l(),g_e=a("p"),uJo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),pJo=l(),cd=a("p"),_Jo=o(`Note:
Loading a model from its configuration file does `),h_e=a("strong"),bJo=o("not"),vJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pz=a("a"),FJo=o("from_pretrained()"),TJo=o(" to load the model weights."),MJo=l(),F(J1.$$.fragment),EJo=l(),no=a("div"),F(J7.$$.fragment),CJo=l(),u_e=a("p"),wJo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),AJo=l(),Oa=a("p"),LJo=o("The model class to instantiate is selected based on the "),p_e=a("code"),yJo=o("model_type"),xJo=o(` property of the config object (either
passed as an argument or loaded from `),__e=a("code"),$Jo=o("pretrained_model_name_or_path"),kJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=a("code"),SJo=o("pretrained_model_name_or_path"),RJo=o(":"),PJo=l(),V=a("ul"),Y1=a("li"),v_e=a("strong"),BJo=o("albert"),IJo=o(" \u2014 "),_z=a("a"),NJo=o("AlbertForQuestionAnswering"),qJo=o(" (ALBERT model)"),jJo=l(),K1=a("li"),F_e=a("strong"),DJo=o("bart"),GJo=o(" \u2014 "),bz=a("a"),OJo=o("BartForQuestionAnswering"),VJo=o(" (BART model)"),XJo=l(),Z1=a("li"),T_e=a("strong"),zJo=o("bert"),QJo=o(" \u2014 "),vz=a("a"),WJo=o("BertForQuestionAnswering"),HJo=o(" (BERT model)"),UJo=l(),eT=a("li"),M_e=a("strong"),JJo=o("big_bird"),YJo=o(" \u2014 "),Fz=a("a"),KJo=o("BigBirdForQuestionAnswering"),ZJo=o(" (BigBird model)"),eYo=l(),oT=a("li"),E_e=a("strong"),oYo=o("bigbird_pegasus"),rYo=o(" \u2014 "),Tz=a("a"),tYo=o("BigBirdPegasusForQuestionAnswering"),aYo=o(" (BigBird-Pegasus model)"),nYo=l(),rT=a("li"),C_e=a("strong"),sYo=o("camembert"),lYo=o(" \u2014 "),Mz=a("a"),iYo=o("CamembertForQuestionAnswering"),dYo=o(" (CamemBERT model)"),cYo=l(),tT=a("li"),w_e=a("strong"),mYo=o("canine"),fYo=o(" \u2014 "),Ez=a("a"),gYo=o("CanineForQuestionAnswering"),hYo=o(" (CANINE model)"),uYo=l(),aT=a("li"),A_e=a("strong"),pYo=o("convbert"),_Yo=o(" \u2014 "),Cz=a("a"),bYo=o("ConvBertForQuestionAnswering"),vYo=o(" (ConvBERT model)"),FYo=l(),nT=a("li"),L_e=a("strong"),TYo=o("data2vec-text"),MYo=o(" \u2014 "),wz=a("a"),EYo=o("Data2VecTextForQuestionAnswering"),CYo=o(" (Data2VecText model)"),wYo=l(),sT=a("li"),y_e=a("strong"),AYo=o("deberta"),LYo=o(" \u2014 "),Az=a("a"),yYo=o("DebertaForQuestionAnswering"),xYo=o(" (DeBERTa model)"),$Yo=l(),lT=a("li"),x_e=a("strong"),kYo=o("deberta-v2"),SYo=o(" \u2014 "),Lz=a("a"),RYo=o("DebertaV2ForQuestionAnswering"),PYo=o(" (DeBERTa-v2 model)"),BYo=l(),iT=a("li"),$_e=a("strong"),IYo=o("distilbert"),NYo=o(" \u2014 "),yz=a("a"),qYo=o("DistilBertForQuestionAnswering"),jYo=o(" (DistilBERT model)"),DYo=l(),dT=a("li"),k_e=a("strong"),GYo=o("electra"),OYo=o(" \u2014 "),xz=a("a"),VYo=o("ElectraForQuestionAnswering"),XYo=o(" (ELECTRA model)"),zYo=l(),cT=a("li"),S_e=a("strong"),QYo=o("flaubert"),WYo=o(" \u2014 "),$z=a("a"),HYo=o("FlaubertForQuestionAnsweringSimple"),UYo=o(" (FlauBERT model)"),JYo=l(),mT=a("li"),R_e=a("strong"),YYo=o("fnet"),KYo=o(" \u2014 "),kz=a("a"),ZYo=o("FNetForQuestionAnswering"),eKo=o(" (FNet model)"),oKo=l(),fT=a("li"),P_e=a("strong"),rKo=o("funnel"),tKo=o(" \u2014 "),Sz=a("a"),aKo=o("FunnelForQuestionAnswering"),nKo=o(" (Funnel Transformer model)"),sKo=l(),gT=a("li"),B_e=a("strong"),lKo=o("gptj"),iKo=o(" \u2014 "),Rz=a("a"),dKo=o("GPTJForQuestionAnswering"),cKo=o(" (GPT-J model)"),mKo=l(),hT=a("li"),I_e=a("strong"),fKo=o("ibert"),gKo=o(" \u2014 "),Pz=a("a"),hKo=o("IBertForQuestionAnswering"),uKo=o(" (I-BERT model)"),pKo=l(),uT=a("li"),N_e=a("strong"),_Ko=o("layoutlmv2"),bKo=o(" \u2014 "),Bz=a("a"),vKo=o("LayoutLMv2ForQuestionAnswering"),FKo=o(" (LayoutLMv2 model)"),TKo=l(),pT=a("li"),q_e=a("strong"),MKo=o("layoutlmv3"),EKo=o(" \u2014 "),Iz=a("a"),CKo=o("LayoutLMv3ForQuestionAnswering"),wKo=o(" (LayoutLMv3 model)"),AKo=l(),_T=a("li"),j_e=a("strong"),LKo=o("led"),yKo=o(" \u2014 "),Nz=a("a"),xKo=o("LEDForQuestionAnswering"),$Ko=o(" (LED model)"),kKo=l(),bT=a("li"),D_e=a("strong"),SKo=o("longformer"),RKo=o(" \u2014 "),qz=a("a"),PKo=o("LongformerForQuestionAnswering"),BKo=o(" (Longformer model)"),IKo=l(),vT=a("li"),G_e=a("strong"),NKo=o("lxmert"),qKo=o(" \u2014 "),jz=a("a"),jKo=o("LxmertForQuestionAnswering"),DKo=o(" (LXMERT model)"),GKo=l(),FT=a("li"),O_e=a("strong"),OKo=o("mbart"),VKo=o(" \u2014 "),Dz=a("a"),XKo=o("MBartForQuestionAnswering"),zKo=o(" (mBART model)"),QKo=l(),TT=a("li"),V_e=a("strong"),WKo=o("megatron-bert"),HKo=o(" \u2014 "),Gz=a("a"),UKo=o("MegatronBertForQuestionAnswering"),JKo=o(" (Megatron-BERT model)"),YKo=l(),MT=a("li"),X_e=a("strong"),KKo=o("mobilebert"),ZKo=o(" \u2014 "),Oz=a("a"),eZo=o("MobileBertForQuestionAnswering"),oZo=o(" (MobileBERT model)"),rZo=l(),ET=a("li"),z_e=a("strong"),tZo=o("mpnet"),aZo=o(" \u2014 "),Vz=a("a"),nZo=o("MPNetForQuestionAnswering"),sZo=o(" (MPNet model)"),lZo=l(),CT=a("li"),Q_e=a("strong"),iZo=o("nezha"),dZo=o(" \u2014 "),Xz=a("a"),cZo=o("NezhaForQuestionAnswering"),mZo=o(" (Nezha model)"),fZo=l(),wT=a("li"),W_e=a("strong"),gZo=o("nystromformer"),hZo=o(" \u2014 "),zz=a("a"),uZo=o("NystromformerForQuestionAnswering"),pZo=o(" (Nystr\xF6mformer model)"),_Zo=l(),AT=a("li"),H_e=a("strong"),bZo=o("qdqbert"),vZo=o(" \u2014 "),Qz=a("a"),FZo=o("QDQBertForQuestionAnswering"),TZo=o(" (QDQBert model)"),MZo=l(),LT=a("li"),U_e=a("strong"),EZo=o("reformer"),CZo=o(" \u2014 "),Wz=a("a"),wZo=o("ReformerForQuestionAnswering"),AZo=o(" (Reformer model)"),LZo=l(),yT=a("li"),J_e=a("strong"),yZo=o("rembert"),xZo=o(" \u2014 "),Hz=a("a"),$Zo=o("RemBertForQuestionAnswering"),kZo=o(" (RemBERT model)"),SZo=l(),xT=a("li"),Y_e=a("strong"),RZo=o("roberta"),PZo=o(" \u2014 "),Uz=a("a"),BZo=o("RobertaForQuestionAnswering"),IZo=o(" (RoBERTa model)"),NZo=l(),$T=a("li"),K_e=a("strong"),qZo=o("roformer"),jZo=o(" \u2014 "),Jz=a("a"),DZo=o("RoFormerForQuestionAnswering"),GZo=o(" (RoFormer model)"),OZo=l(),kT=a("li"),Z_e=a("strong"),VZo=o("splinter"),XZo=o(" \u2014 "),Yz=a("a"),zZo=o("SplinterForQuestionAnswering"),QZo=o(" (Splinter model)"),WZo=l(),ST=a("li"),e2e=a("strong"),HZo=o("squeezebert"),UZo=o(" \u2014 "),Kz=a("a"),JZo=o("SqueezeBertForQuestionAnswering"),YZo=o(" (SqueezeBERT model)"),KZo=l(),RT=a("li"),o2e=a("strong"),ZZo=o("xlm"),eer=o(" \u2014 "),Zz=a("a"),oer=o("XLMForQuestionAnsweringSimple"),rer=o(" (XLM model)"),ter=l(),PT=a("li"),r2e=a("strong"),aer=o("xlm-roberta"),ner=o(" \u2014 "),eQ=a("a"),ser=o("XLMRobertaForQuestionAnswering"),ler=o(" (XLM-RoBERTa model)"),ier=l(),BT=a("li"),t2e=a("strong"),der=o("xlm-roberta-xl"),cer=o(" \u2014 "),oQ=a("a"),mer=o("XLMRobertaXLForQuestionAnswering"),fer=o(" (XLM-RoBERTa-XL model)"),ger=l(),IT=a("li"),a2e=a("strong"),her=o("xlnet"),uer=o(" \u2014 "),rQ=a("a"),per=o("XLNetForQuestionAnsweringSimple"),_er=o(" (XLNet model)"),ber=l(),NT=a("li"),n2e=a("strong"),ver=o("yoso"),Fer=o(" \u2014 "),tQ=a("a"),Ter=o("YosoForQuestionAnswering"),Mer=o(" (YOSO model)"),Eer=l(),qT=a("p"),Cer=o("The model is set in evaluation mode by default using "),s2e=a("code"),wer=o("model.eval()"),Aer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l2e=a("code"),Ler=o("model.train()"),yer=l(),F(jT.$$.fragment),bOe=l(),md=a("h2"),DT=a("a"),i2e=a("span"),F(Y7.$$.fragment),xer=l(),d2e=a("span"),$er=o("AutoModelForTableQuestionAnswering"),vOe=l(),Do=a("div"),F(K7.$$.fragment),ker=l(),fd=a("p"),Ser=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=a("a"),Rer=o("from_pretrained()"),Per=o(" class method or the "),nQ=a("a"),Ber=o("from_config()"),Ier=o(` class
method.`),Ner=l(),Z7=a("p"),qer=o("This class cannot be instantiated directly using "),c2e=a("code"),jer=o("__init__()"),Der=o(" (throws an error)."),Ger=l(),ut=a("div"),F(e8.$$.fragment),Oer=l(),m2e=a("p"),Ver=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Xer=l(),gd=a("p"),zer=o(`Note:
Loading a model from its configuration file does `),f2e=a("strong"),Qer=o("not"),Wer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=a("a"),Her=o("from_pretrained()"),Uer=o(" to load the model weights."),Jer=l(),F(GT.$$.fragment),Yer=l(),so=a("div"),F(o8.$$.fragment),Ker=l(),g2e=a("p"),Zer=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eor=l(),Va=a("p"),oor=o("The model class to instantiate is selected based on the "),h2e=a("code"),ror=o("model_type"),tor=o(` property of the config object (either
passed as an argument or loaded from `),u2e=a("code"),aor=o("pretrained_model_name_or_path"),nor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=a("code"),sor=o("pretrained_model_name_or_path"),lor=o(":"),ior=l(),_2e=a("ul"),OT=a("li"),b2e=a("strong"),dor=o("tapas"),cor=o(" \u2014 "),lQ=a("a"),mor=o("TapasForQuestionAnswering"),gor=o(" (TAPAS model)"),hor=l(),VT=a("p"),uor=o("The model is set in evaluation mode by default using "),v2e=a("code"),por=o("model.eval()"),_or=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F2e=a("code"),bor=o("model.train()"),vor=l(),F(XT.$$.fragment),FOe=l(),hd=a("h2"),zT=a("a"),T2e=a("span"),F(r8.$$.fragment),For=l(),M2e=a("span"),Tor=o("AutoModelForImageClassification"),TOe=l(),Go=a("div"),F(t8.$$.fragment),Mor=l(),ud=a("p"),Eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=a("a"),Cor=o("from_pretrained()"),wor=o(" class method or the "),dQ=a("a"),Aor=o("from_config()"),Lor=o(` class
method.`),yor=l(),a8=a("p"),xor=o("This class cannot be instantiated directly using "),E2e=a("code"),$or=o("__init__()"),kor=o(" (throws an error)."),Sor=l(),pt=a("div"),F(n8.$$.fragment),Ror=l(),C2e=a("p"),Por=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Bor=l(),pd=a("p"),Ior=o(`Note:
Loading a model from its configuration file does `),w2e=a("strong"),Nor=o("not"),qor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),jor=o("from_pretrained()"),Dor=o(" to load the model weights."),Gor=l(),F(QT.$$.fragment),Oor=l(),lo=a("div"),F(s8.$$.fragment),Vor=l(),A2e=a("p"),Xor=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),zor=l(),Xa=a("p"),Qor=o("The model class to instantiate is selected based on the "),L2e=a("code"),Wor=o("model_type"),Hor=o(` property of the config object (either
passed as an argument or loaded from `),y2e=a("code"),Uor=o("pretrained_model_name_or_path"),Jor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x2e=a("code"),Yor=o("pretrained_model_name_or_path"),Kor=o(":"),Zor=l(),Fe=a("ul"),WT=a("li"),$2e=a("strong"),err=o("beit"),orr=o(" \u2014 "),mQ=a("a"),rrr=o("BeitForImageClassification"),trr=o(" (BEiT model)"),arr=l(),HT=a("li"),k2e=a("strong"),nrr=o("convnext"),srr=o(" \u2014 "),fQ=a("a"),lrr=o("ConvNextForImageClassification"),irr=o(" (ConvNeXT model)"),drr=l(),UT=a("li"),S2e=a("strong"),crr=o("cvt"),mrr=o(" \u2014 "),gQ=a("a"),frr=o("CvtForImageClassification"),grr=o(" (CvT model)"),hrr=l(),JT=a("li"),R2e=a("strong"),urr=o("data2vec-vision"),prr=o(" \u2014 "),hQ=a("a"),_rr=o("Data2VecVisionForImageClassification"),brr=o(" (Data2VecVision model)"),vrr=l(),Xs=a("li"),P2e=a("strong"),Frr=o("deit"),Trr=o(" \u2014 "),uQ=a("a"),Mrr=o("DeiTForImageClassification"),Err=o(" or "),pQ=a("a"),Crr=o("DeiTForImageClassificationWithTeacher"),wrr=o(" (DeiT model)"),Arr=l(),YT=a("li"),B2e=a("strong"),Lrr=o("imagegpt"),yrr=o(" \u2014 "),_Q=a("a"),xrr=o("ImageGPTForImageClassification"),$rr=o(" (ImageGPT model)"),krr=l(),zs=a("li"),I2e=a("strong"),Srr=o("levit"),Rrr=o(" \u2014 "),bQ=a("a"),Prr=o("LevitForImageClassification"),Brr=o(" or "),vQ=a("a"),Irr=o("LevitForImageClassificationWithTeacher"),Nrr=o(" (LeViT model)"),qrr=l(),_t=a("li"),N2e=a("strong"),jrr=o("perceiver"),Drr=o(" \u2014 "),FQ=a("a"),Grr=o("PerceiverForImageClassificationLearned"),Orr=o(" or "),TQ=a("a"),Vrr=o("PerceiverForImageClassificationFourier"),Xrr=o(" or "),MQ=a("a"),zrr=o("PerceiverForImageClassificationConvProcessing"),Qrr=o(" (Perceiver model)"),Wrr=l(),KT=a("li"),q2e=a("strong"),Hrr=o("poolformer"),Urr=o(" \u2014 "),EQ=a("a"),Jrr=o("PoolFormerForImageClassification"),Yrr=o(" (PoolFormer model)"),Krr=l(),ZT=a("li"),j2e=a("strong"),Zrr=o("regnet"),etr=o(" \u2014 "),CQ=a("a"),otr=o("RegNetForImageClassification"),rtr=o(" (RegNet model)"),ttr=l(),eM=a("li"),D2e=a("strong"),atr=o("resnet"),ntr=o(" \u2014 "),wQ=a("a"),str=o("ResNetForImageClassification"),ltr=o(" (ResNet model)"),itr=l(),oM=a("li"),G2e=a("strong"),dtr=o("segformer"),ctr=o(" \u2014 "),AQ=a("a"),mtr=o("SegformerForImageClassification"),ftr=o(" (SegFormer model)"),gtr=l(),rM=a("li"),O2e=a("strong"),htr=o("swin"),utr=o(" \u2014 "),LQ=a("a"),ptr=o("SwinForImageClassification"),_tr=o(" (Swin Transformer model)"),btr=l(),tM=a("li"),V2e=a("strong"),vtr=o("van"),Ftr=o(" \u2014 "),yQ=a("a"),Ttr=o("VanForImageClassification"),Mtr=o(" (VAN model)"),Etr=l(),aM=a("li"),X2e=a("strong"),Ctr=o("vit"),wtr=o(" \u2014 "),xQ=a("a"),Atr=o("ViTForImageClassification"),Ltr=o(" (ViT model)"),ytr=l(),nM=a("p"),xtr=o("The model is set in evaluation mode by default using "),z2e=a("code"),$tr=o("model.eval()"),ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q2e=a("code"),Str=o("model.train()"),Rtr=l(),F(sM.$$.fragment),MOe=l(),_d=a("h2"),lM=a("a"),W2e=a("span"),F(l8.$$.fragment),Ptr=l(),H2e=a("span"),Btr=o("AutoModelForVision2Seq"),EOe=l(),Oo=a("div"),F(i8.$$.fragment),Itr=l(),bd=a("p"),Ntr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=a("a"),qtr=o("from_pretrained()"),jtr=o(" class method or the "),kQ=a("a"),Dtr=o("from_config()"),Gtr=o(` class
method.`),Otr=l(),d8=a("p"),Vtr=o("This class cannot be instantiated directly using "),U2e=a("code"),Xtr=o("__init__()"),ztr=o(" (throws an error)."),Qtr=l(),bt=a("div"),F(c8.$$.fragment),Wtr=l(),J2e=a("p"),Htr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Utr=l(),vd=a("p"),Jtr=o(`Note:
Loading a model from its configuration file does `),Y2e=a("strong"),Ytr=o("not"),Ktr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),Ztr=o("from_pretrained()"),ear=o(" to load the model weights."),oar=l(),F(iM.$$.fragment),rar=l(),io=a("div"),F(m8.$$.fragment),tar=l(),K2e=a("p"),aar=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nar=l(),za=a("p"),sar=o("The model class to instantiate is selected based on the "),Z2e=a("code"),lar=o("model_type"),iar=o(` property of the config object (either
passed as an argument or loaded from `),ebe=a("code"),dar=o("pretrained_model_name_or_path"),car=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),obe=a("code"),mar=o("pretrained_model_name_or_path"),far=o(":"),gar=l(),rbe=a("ul"),dM=a("li"),tbe=a("strong"),har=o("vision-encoder-decoder"),uar=o(" \u2014 "),RQ=a("a"),par=o("VisionEncoderDecoderModel"),_ar=o(" (Vision Encoder decoder model)"),bar=l(),cM=a("p"),Far=o("The model is set in evaluation mode by default using "),abe=a("code"),Tar=o("model.eval()"),Mar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nbe=a("code"),Ear=o("model.train()"),Car=l(),F(mM.$$.fragment),COe=l(),Fd=a("h2"),fM=a("a"),sbe=a("span"),F(f8.$$.fragment),war=l(),lbe=a("span"),Aar=o("AutoModelForVisualQuestionAnswering"),wOe=l(),Vo=a("div"),F(g8.$$.fragment),Lar=l(),Td=a("p"),yar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=a("a"),xar=o("from_pretrained()"),$ar=o(" class method or the "),BQ=a("a"),kar=o("from_config()"),Sar=o(` class
method.`),Rar=l(),h8=a("p"),Par=o("This class cannot be instantiated directly using "),ibe=a("code"),Bar=o("__init__()"),Iar=o(" (throws an error)."),Nar=l(),vt=a("div"),F(u8.$$.fragment),qar=l(),dbe=a("p"),jar=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Dar=l(),Md=a("p"),Gar=o(`Note:
Loading a model from its configuration file does `),cbe=a("strong"),Oar=o("not"),Var=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),Xar=o("from_pretrained()"),zar=o(" to load the model weights."),Qar=l(),F(gM.$$.fragment),War=l(),co=a("div"),F(p8.$$.fragment),Har=l(),mbe=a("p"),Uar=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Jar=l(),Qa=a("p"),Yar=o("The model class to instantiate is selected based on the "),fbe=a("code"),Kar=o("model_type"),Zar=o(` property of the config object (either
passed as an argument or loaded from `),gbe=a("code"),enr=o("pretrained_model_name_or_path"),onr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=a("code"),rnr=o("pretrained_model_name_or_path"),tnr=o(":"),anr=l(),ube=a("ul"),hM=a("li"),pbe=a("strong"),nnr=o("vilt"),snr=o(" \u2014 "),NQ=a("a"),lnr=o("ViltForQuestionAnswering"),inr=o(" (ViLT model)"),dnr=l(),uM=a("p"),cnr=o("The model is set in evaluation mode by default using "),_be=a("code"),mnr=o("model.eval()"),fnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bbe=a("code"),gnr=o("model.train()"),hnr=l(),F(pM.$$.fragment),AOe=l(),Ed=a("h2"),_M=a("a"),vbe=a("span"),F(_8.$$.fragment),unr=l(),Fbe=a("span"),pnr=o("AutoModelForAudioClassification"),LOe=l(),Xo=a("div"),F(b8.$$.fragment),_nr=l(),Cd=a("p"),bnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=a("a"),vnr=o("from_pretrained()"),Fnr=o(" class method or the "),jQ=a("a"),Tnr=o("from_config()"),Mnr=o(` class
method.`),Enr=l(),v8=a("p"),Cnr=o("This class cannot be instantiated directly using "),Tbe=a("code"),wnr=o("__init__()"),Anr=o(" (throws an error)."),Lnr=l(),Ft=a("div"),F(F8.$$.fragment),ynr=l(),Mbe=a("p"),xnr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$nr=l(),wd=a("p"),knr=o(`Note:
Loading a model from its configuration file does `),Ebe=a("strong"),Snr=o("not"),Rnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),Pnr=o("from_pretrained()"),Bnr=o(" to load the model weights."),Inr=l(),F(bM.$$.fragment),Nnr=l(),mo=a("div"),F(T8.$$.fragment),qnr=l(),Cbe=a("p"),jnr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Dnr=l(),Wa=a("p"),Gnr=o("The model class to instantiate is selected based on the "),wbe=a("code"),Onr=o("model_type"),Vnr=o(` property of the config object (either
passed as an argument or loaded from `),Abe=a("code"),Xnr=o("pretrained_model_name_or_path"),znr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lbe=a("code"),Qnr=o("pretrained_model_name_or_path"),Wnr=o(":"),Hnr=l(),Pe=a("ul"),vM=a("li"),ybe=a("strong"),Unr=o("data2vec-audio"),Jnr=o(" \u2014 "),GQ=a("a"),Ynr=o("Data2VecAudioForSequenceClassification"),Knr=o(" (Data2VecAudio model)"),Znr=l(),FM=a("li"),xbe=a("strong"),esr=o("hubert"),osr=o(" \u2014 "),OQ=a("a"),rsr=o("HubertForSequenceClassification"),tsr=o(" (Hubert model)"),asr=l(),TM=a("li"),$be=a("strong"),nsr=o("sew"),ssr=o(" \u2014 "),VQ=a("a"),lsr=o("SEWForSequenceClassification"),isr=o(" (SEW model)"),dsr=l(),MM=a("li"),kbe=a("strong"),csr=o("sew-d"),msr=o(" \u2014 "),XQ=a("a"),fsr=o("SEWDForSequenceClassification"),gsr=o(" (SEW-D model)"),hsr=l(),EM=a("li"),Sbe=a("strong"),usr=o("unispeech"),psr=o(" \u2014 "),zQ=a("a"),_sr=o("UniSpeechForSequenceClassification"),bsr=o(" (UniSpeech model)"),vsr=l(),CM=a("li"),Rbe=a("strong"),Fsr=o("unispeech-sat"),Tsr=o(" \u2014 "),QQ=a("a"),Msr=o("UniSpeechSatForSequenceClassification"),Esr=o(" (UniSpeechSat model)"),Csr=l(),wM=a("li"),Pbe=a("strong"),wsr=o("wav2vec2"),Asr=o(" \u2014 "),WQ=a("a"),Lsr=o("Wav2Vec2ForSequenceClassification"),ysr=o(" (Wav2Vec2 model)"),xsr=l(),AM=a("li"),Bbe=a("strong"),$sr=o("wav2vec2-conformer"),ksr=o(" \u2014 "),HQ=a("a"),Ssr=o("Wav2Vec2ConformerForSequenceClassification"),Rsr=o(" (Wav2Vec2-Conformer model)"),Psr=l(),LM=a("li"),Ibe=a("strong"),Bsr=o("wavlm"),Isr=o(" \u2014 "),UQ=a("a"),Nsr=o("WavLMForSequenceClassification"),qsr=o(" (WavLM model)"),jsr=l(),yM=a("p"),Dsr=o("The model is set in evaluation mode by default using "),Nbe=a("code"),Gsr=o("model.eval()"),Osr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qbe=a("code"),Vsr=o("model.train()"),Xsr=l(),F(xM.$$.fragment),yOe=l(),Ad=a("h2"),$M=a("a"),jbe=a("span"),F(M8.$$.fragment),zsr=l(),Dbe=a("span"),Qsr=o("AutoModelForAudioFrameClassification"),xOe=l(),zo=a("div"),F(E8.$$.fragment),Wsr=l(),Ld=a("p"),Hsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=a("a"),Usr=o("from_pretrained()"),Jsr=o(" class method or the "),YQ=a("a"),Ysr=o("from_config()"),Ksr=o(` class
method.`),Zsr=l(),C8=a("p"),elr=o("This class cannot be instantiated directly using "),Gbe=a("code"),olr=o("__init__()"),rlr=o(" (throws an error)."),tlr=l(),Tt=a("div"),F(w8.$$.fragment),alr=l(),Obe=a("p"),nlr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),slr=l(),yd=a("p"),llr=o(`Note:
Loading a model from its configuration file does `),Vbe=a("strong"),ilr=o("not"),dlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=a("a"),clr=o("from_pretrained()"),mlr=o(" to load the model weights."),flr=l(),F(kM.$$.fragment),glr=l(),fo=a("div"),F(A8.$$.fragment),hlr=l(),Xbe=a("p"),ulr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),plr=l(),Ha=a("p"),_lr=o("The model class to instantiate is selected based on the "),zbe=a("code"),blr=o("model_type"),vlr=o(` property of the config object (either
passed as an argument or loaded from `),Qbe=a("code"),Flr=o("pretrained_model_name_or_path"),Tlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wbe=a("code"),Mlr=o("pretrained_model_name_or_path"),Elr=o(":"),Clr=l(),et=a("ul"),SM=a("li"),Hbe=a("strong"),wlr=o("data2vec-audio"),Alr=o(" \u2014 "),ZQ=a("a"),Llr=o("Data2VecAudioForAudioFrameClassification"),ylr=o(" (Data2VecAudio model)"),xlr=l(),RM=a("li"),Ube=a("strong"),$lr=o("unispeech-sat"),klr=o(" \u2014 "),eW=a("a"),Slr=o("UniSpeechSatForAudioFrameClassification"),Rlr=o(" (UniSpeechSat model)"),Plr=l(),PM=a("li"),Jbe=a("strong"),Blr=o("wav2vec2"),Ilr=o(" \u2014 "),oW=a("a"),Nlr=o("Wav2Vec2ForAudioFrameClassification"),qlr=o(" (Wav2Vec2 model)"),jlr=l(),BM=a("li"),Ybe=a("strong"),Dlr=o("wav2vec2-conformer"),Glr=o(" \u2014 "),rW=a("a"),Olr=o("Wav2Vec2ConformerForAudioFrameClassification"),Vlr=o(" (Wav2Vec2-Conformer model)"),Xlr=l(),IM=a("li"),Kbe=a("strong"),zlr=o("wavlm"),Qlr=o(" \u2014 "),tW=a("a"),Wlr=o("WavLMForAudioFrameClassification"),Hlr=o(" (WavLM model)"),Ulr=l(),NM=a("p"),Jlr=o("The model is set in evaluation mode by default using "),Zbe=a("code"),Ylr=o("model.eval()"),Klr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eve=a("code"),Zlr=o("model.train()"),eir=l(),F(qM.$$.fragment),$Oe=l(),xd=a("h2"),jM=a("a"),ove=a("span"),F(L8.$$.fragment),oir=l(),rve=a("span"),rir=o("AutoModelForCTC"),kOe=l(),Qo=a("div"),F(y8.$$.fragment),tir=l(),$d=a("p"),air=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=a("a"),nir=o("from_pretrained()"),sir=o(" class method or the "),nW=a("a"),lir=o("from_config()"),iir=o(` class
method.`),dir=l(),x8=a("p"),cir=o("This class cannot be instantiated directly using "),tve=a("code"),mir=o("__init__()"),fir=o(" (throws an error)."),gir=l(),Mt=a("div"),F($8.$$.fragment),hir=l(),ave=a("p"),uir=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),pir=l(),kd=a("p"),_ir=o(`Note:
Loading a model from its configuration file does `),nve=a("strong"),bir=o("not"),vir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Fir=o("from_pretrained()"),Tir=o(" to load the model weights."),Mir=l(),F(DM.$$.fragment),Eir=l(),go=a("div"),F(k8.$$.fragment),Cir=l(),sve=a("p"),wir=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Air=l(),Ua=a("p"),Lir=o("The model class to instantiate is selected based on the "),lve=a("code"),yir=o("model_type"),xir=o(` property of the config object (either
passed as an argument or loaded from `),ive=a("code"),$ir=o("pretrained_model_name_or_path"),kir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dve=a("code"),Sir=o("pretrained_model_name_or_path"),Rir=o(":"),Pir=l(),Le=a("ul"),GM=a("li"),cve=a("strong"),Bir=o("data2vec-audio"),Iir=o(" \u2014 "),lW=a("a"),Nir=o("Data2VecAudioForCTC"),qir=o(" (Data2VecAudio model)"),jir=l(),OM=a("li"),mve=a("strong"),Dir=o("hubert"),Gir=o(" \u2014 "),iW=a("a"),Oir=o("HubertForCTC"),Vir=o(" (Hubert model)"),Xir=l(),VM=a("li"),fve=a("strong"),zir=o("mctct"),Qir=o(" \u2014 "),dW=a("a"),Wir=o("MCTCTForCTC"),Hir=o(" (M-CTC-T model)"),Uir=l(),XM=a("li"),gve=a("strong"),Jir=o("sew"),Yir=o(" \u2014 "),cW=a("a"),Kir=o("SEWForCTC"),Zir=o(" (SEW model)"),edr=l(),zM=a("li"),hve=a("strong"),odr=o("sew-d"),rdr=o(" \u2014 "),mW=a("a"),tdr=o("SEWDForCTC"),adr=o(" (SEW-D model)"),ndr=l(),QM=a("li"),uve=a("strong"),sdr=o("unispeech"),ldr=o(" \u2014 "),fW=a("a"),idr=o("UniSpeechForCTC"),ddr=o(" (UniSpeech model)"),cdr=l(),WM=a("li"),pve=a("strong"),mdr=o("unispeech-sat"),fdr=o(" \u2014 "),gW=a("a"),gdr=o("UniSpeechSatForCTC"),hdr=o(" (UniSpeechSat model)"),udr=l(),HM=a("li"),_ve=a("strong"),pdr=o("wav2vec2"),_dr=o(" \u2014 "),hW=a("a"),bdr=o("Wav2Vec2ForCTC"),vdr=o(" (Wav2Vec2 model)"),Fdr=l(),UM=a("li"),bve=a("strong"),Tdr=o("wav2vec2-conformer"),Mdr=o(" \u2014 "),uW=a("a"),Edr=o("Wav2Vec2ConformerForCTC"),Cdr=o(" (Wav2Vec2-Conformer model)"),wdr=l(),JM=a("li"),vve=a("strong"),Adr=o("wavlm"),Ldr=o(" \u2014 "),pW=a("a"),ydr=o("WavLMForCTC"),xdr=o(" (WavLM model)"),$dr=l(),YM=a("p"),kdr=o("The model is set in evaluation mode by default using "),Fve=a("code"),Sdr=o("model.eval()"),Rdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tve=a("code"),Pdr=o("model.train()"),Bdr=l(),F(KM.$$.fragment),SOe=l(),Sd=a("h2"),ZM=a("a"),Mve=a("span"),F(S8.$$.fragment),Idr=l(),Eve=a("span"),Ndr=o("AutoModelForSpeechSeq2Seq"),ROe=l(),Wo=a("div"),F(R8.$$.fragment),qdr=l(),Rd=a("p"),jdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),_W=a("a"),Ddr=o("from_pretrained()"),Gdr=o(" class method or the "),bW=a("a"),Odr=o("from_config()"),Vdr=o(` class
method.`),Xdr=l(),P8=a("p"),zdr=o("This class cannot be instantiated directly using "),Cve=a("code"),Qdr=o("__init__()"),Wdr=o(" (throws an error)."),Hdr=l(),Et=a("div"),F(B8.$$.fragment),Udr=l(),wve=a("p"),Jdr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ydr=l(),Pd=a("p"),Kdr=o(`Note:
Loading a model from its configuration file does `),Ave=a("strong"),Zdr=o("not"),ecr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=a("a"),ocr=o("from_pretrained()"),rcr=o(" to load the model weights."),tcr=l(),F(eE.$$.fragment),acr=l(),ho=a("div"),F(I8.$$.fragment),ncr=l(),Lve=a("p"),scr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),lcr=l(),Ja=a("p"),icr=o("The model class to instantiate is selected based on the "),yve=a("code"),dcr=o("model_type"),ccr=o(` property of the config object (either
passed as an argument or loaded from `),xve=a("code"),mcr=o("pretrained_model_name_or_path"),fcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ve=a("code"),gcr=o("pretrained_model_name_or_path"),hcr=o(":"),ucr=l(),N8=a("ul"),oE=a("li"),kve=a("strong"),pcr=o("speech-encoder-decoder"),_cr=o(" \u2014 "),FW=a("a"),bcr=o("SpeechEncoderDecoderModel"),vcr=o(" (Speech Encoder decoder model)"),Fcr=l(),rE=a("li"),Sve=a("strong"),Tcr=o("speech_to_text"),Mcr=o(" \u2014 "),TW=a("a"),Ecr=o("Speech2TextForConditionalGeneration"),Ccr=o(" (Speech2Text model)"),wcr=l(),tE=a("p"),Acr=o("The model is set in evaluation mode by default using "),Rve=a("code"),Lcr=o("model.eval()"),ycr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pve=a("code"),xcr=o("model.train()"),$cr=l(),F(aE.$$.fragment),POe=l(),Bd=a("h2"),nE=a("a"),Bve=a("span"),F(q8.$$.fragment),kcr=l(),Ive=a("span"),Scr=o("AutoModelForAudioXVector"),BOe=l(),Ho=a("div"),F(j8.$$.fragment),Rcr=l(),Id=a("p"),Pcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=a("a"),Bcr=o("from_pretrained()"),Icr=o(" class method or the "),EW=a("a"),Ncr=o("from_config()"),qcr=o(` class
method.`),jcr=l(),D8=a("p"),Dcr=o("This class cannot be instantiated directly using "),Nve=a("code"),Gcr=o("__init__()"),Ocr=o(" (throws an error)."),Vcr=l(),Ct=a("div"),F(G8.$$.fragment),Xcr=l(),qve=a("p"),zcr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Qcr=l(),Nd=a("p"),Wcr=o(`Note:
Loading a model from its configuration file does `),jve=a("strong"),Hcr=o("not"),Ucr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),Jcr=o("from_pretrained()"),Ycr=o(" to load the model weights."),Kcr=l(),F(sE.$$.fragment),Zcr=l(),uo=a("div"),F(O8.$$.fragment),emr=l(),Dve=a("p"),omr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rmr=l(),Ya=a("p"),tmr=o("The model class to instantiate is selected based on the "),Gve=a("code"),amr=o("model_type"),nmr=o(` property of the config object (either
passed as an argument or loaded from `),Ove=a("code"),smr=o("pretrained_model_name_or_path"),lmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=a("code"),imr=o("pretrained_model_name_or_path"),dmr=o(":"),cmr=l(),ot=a("ul"),lE=a("li"),Xve=a("strong"),mmr=o("data2vec-audio"),fmr=o(" \u2014 "),wW=a("a"),gmr=o("Data2VecAudioForXVector"),hmr=o(" (Data2VecAudio model)"),umr=l(),iE=a("li"),zve=a("strong"),pmr=o("unispeech-sat"),_mr=o(" \u2014 "),AW=a("a"),bmr=o("UniSpeechSatForXVector"),vmr=o(" (UniSpeechSat model)"),Fmr=l(),dE=a("li"),Qve=a("strong"),Tmr=o("wav2vec2"),Mmr=o(" \u2014 "),LW=a("a"),Emr=o("Wav2Vec2ForXVector"),Cmr=o(" (Wav2Vec2 model)"),wmr=l(),cE=a("li"),Wve=a("strong"),Amr=o("wav2vec2-conformer"),Lmr=o(" \u2014 "),yW=a("a"),ymr=o("Wav2Vec2ConformerForXVector"),xmr=o(" (Wav2Vec2-Conformer model)"),$mr=l(),mE=a("li"),Hve=a("strong"),kmr=o("wavlm"),Smr=o(" \u2014 "),xW=a("a"),Rmr=o("WavLMForXVector"),Pmr=o(" (WavLM model)"),Bmr=l(),fE=a("p"),Imr=o("The model is set in evaluation mode by default using "),Uve=a("code"),Nmr=o("model.eval()"),qmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jve=a("code"),jmr=o("model.train()"),Dmr=l(),F(gE.$$.fragment),IOe=l(),qd=a("h2"),hE=a("a"),Yve=a("span"),F(V8.$$.fragment),Gmr=l(),Kve=a("span"),Omr=o("AutoModelForMaskedImageModeling"),NOe=l(),Uo=a("div"),F(X8.$$.fragment),Vmr=l(),jd=a("p"),Xmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=a("a"),zmr=o("from_pretrained()"),Qmr=o(" class method or the "),kW=a("a"),Wmr=o("from_config()"),Hmr=o(` class
method.`),Umr=l(),z8=a("p"),Jmr=o("This class cannot be instantiated directly using "),Zve=a("code"),Ymr=o("__init__()"),Kmr=o(" (throws an error)."),Zmr=l(),wt=a("div"),F(Q8.$$.fragment),efr=l(),eFe=a("p"),ofr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rfr=l(),Dd=a("p"),tfr=o(`Note:
Loading a model from its configuration file does `),oFe=a("strong"),afr=o("not"),nfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),sfr=o("from_pretrained()"),lfr=o(" to load the model weights."),ifr=l(),F(uE.$$.fragment),dfr=l(),po=a("div"),F(W8.$$.fragment),cfr=l(),rFe=a("p"),mfr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),ffr=l(),Ka=a("p"),gfr=o("The model class to instantiate is selected based on the "),tFe=a("code"),hfr=o("model_type"),ufr=o(` property of the config object (either
passed as an argument or loaded from `),aFe=a("code"),pfr=o("pretrained_model_name_or_path"),_fr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nFe=a("code"),bfr=o("pretrained_model_name_or_path"),vfr=o(":"),Ffr=l(),Gd=a("ul"),pE=a("li"),sFe=a("strong"),Tfr=o("deit"),Mfr=o(" \u2014 "),RW=a("a"),Efr=o("DeiTForMaskedImageModeling"),Cfr=o(" (DeiT model)"),wfr=l(),_E=a("li"),lFe=a("strong"),Afr=o("swin"),Lfr=o(" \u2014 "),PW=a("a"),yfr=o("SwinForMaskedImageModeling"),xfr=o(" (Swin Transformer model)"),$fr=l(),bE=a("li"),iFe=a("strong"),kfr=o("vit"),Sfr=o(" \u2014 "),BW=a("a"),Rfr=o("ViTForMaskedImageModeling"),Pfr=o(" (ViT model)"),Bfr=l(),vE=a("p"),Ifr=o("The model is set in evaluation mode by default using "),dFe=a("code"),Nfr=o("model.eval()"),qfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=a("code"),jfr=o("model.train()"),Dfr=l(),F(FE.$$.fragment),qOe=l(),Od=a("h2"),TE=a("a"),mFe=a("span"),F(H8.$$.fragment),Gfr=l(),fFe=a("span"),Ofr=o("AutoModelForObjectDetection"),jOe=l(),Jo=a("div"),F(U8.$$.fragment),Vfr=l(),Vd=a("p"),Xfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=a("a"),zfr=o("from_pretrained()"),Qfr=o(" class method or the "),NW=a("a"),Wfr=o("from_config()"),Hfr=o(` class
method.`),Ufr=l(),J8=a("p"),Jfr=o("This class cannot be instantiated directly using "),gFe=a("code"),Yfr=o("__init__()"),Kfr=o(" (throws an error)."),Zfr=l(),At=a("div"),F(Y8.$$.fragment),egr=l(),hFe=a("p"),ogr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rgr=l(),Xd=a("p"),tgr=o(`Note:
Loading a model from its configuration file does `),uFe=a("strong"),agr=o("not"),ngr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),sgr=o("from_pretrained()"),lgr=o(" to load the model weights."),igr=l(),F(ME.$$.fragment),dgr=l(),_o=a("div"),F(K8.$$.fragment),cgr=l(),pFe=a("p"),mgr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),fgr=l(),Za=a("p"),ggr=o("The model class to instantiate is selected based on the "),_Fe=a("code"),hgr=o("model_type"),ugr=o(` property of the config object (either
passed as an argument or loaded from `),bFe=a("code"),pgr=o("pretrained_model_name_or_path"),_gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vFe=a("code"),bgr=o("pretrained_model_name_or_path"),vgr=o(":"),Fgr=l(),Z8=a("ul"),EE=a("li"),FFe=a("strong"),Tgr=o("detr"),Mgr=o(" \u2014 "),jW=a("a"),Egr=o("DetrForObjectDetection"),Cgr=o(" (DETR model)"),wgr=l(),CE=a("li"),TFe=a("strong"),Agr=o("yolos"),Lgr=o(" \u2014 "),DW=a("a"),ygr=o("YolosForObjectDetection"),xgr=o(" (YOLOS model)"),$gr=l(),wE=a("p"),kgr=o("The model is set in evaluation mode by default using "),MFe=a("code"),Sgr=o("model.eval()"),Rgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EFe=a("code"),Pgr=o("model.train()"),Bgr=l(),F(AE.$$.fragment),DOe=l(),zd=a("h2"),LE=a("a"),CFe=a("span"),F(e9.$$.fragment),Igr=l(),wFe=a("span"),Ngr=o("AutoModelForImageSegmentation"),GOe=l(),Yo=a("div"),F(o9.$$.fragment),qgr=l(),Qd=a("p"),jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=a("a"),Dgr=o("from_pretrained()"),Ggr=o(" class method or the "),OW=a("a"),Ogr=o("from_config()"),Vgr=o(` class
method.`),Xgr=l(),r9=a("p"),zgr=o("This class cannot be instantiated directly using "),AFe=a("code"),Qgr=o("__init__()"),Wgr=o(" (throws an error)."),Hgr=l(),Lt=a("div"),F(t9.$$.fragment),Ugr=l(),LFe=a("p"),Jgr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ygr=l(),Wd=a("p"),Kgr=o(`Note:
Loading a model from its configuration file does `),yFe=a("strong"),Zgr=o("not"),ehr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),ohr=o("from_pretrained()"),rhr=o(" to load the model weights."),thr=l(),F(yE.$$.fragment),ahr=l(),bo=a("div"),F(a9.$$.fragment),nhr=l(),xFe=a("p"),shr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),lhr=l(),en=a("p"),ihr=o("The model class to instantiate is selected based on the "),$Fe=a("code"),dhr=o("model_type"),chr=o(` property of the config object (either
passed as an argument or loaded from `),kFe=a("code"),mhr=o("pretrained_model_name_or_path"),fhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=a("code"),ghr=o("pretrained_model_name_or_path"),hhr=o(":"),uhr=l(),RFe=a("ul"),xE=a("li"),PFe=a("strong"),phr=o("detr"),_hr=o(" \u2014 "),XW=a("a"),bhr=o("DetrForSegmentation"),vhr=o(" (DETR model)"),Fhr=l(),$E=a("p"),Thr=o("The model is set in evaluation mode by default using "),BFe=a("code"),Mhr=o("model.eval()"),Ehr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),IFe=a("code"),Chr=o("model.train()"),whr=l(),F(kE.$$.fragment),OOe=l(),Hd=a("h2"),SE=a("a"),NFe=a("span"),F(n9.$$.fragment),Ahr=l(),qFe=a("span"),Lhr=o("AutoModelForSemanticSegmentation"),VOe=l(),Ko=a("div"),F(s9.$$.fragment),yhr=l(),Ud=a("p"),xhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=a("a"),$hr=o("from_pretrained()"),khr=o(" class method or the "),QW=a("a"),Shr=o("from_config()"),Rhr=o(` class
method.`),Phr=l(),l9=a("p"),Bhr=o("This class cannot be instantiated directly using "),jFe=a("code"),Ihr=o("__init__()"),Nhr=o(" (throws an error)."),qhr=l(),yt=a("div"),F(i9.$$.fragment),jhr=l(),DFe=a("p"),Dhr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Ghr=l(),Jd=a("p"),Ohr=o(`Note:
Loading a model from its configuration file does `),GFe=a("strong"),Vhr=o("not"),Xhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),zhr=o("from_pretrained()"),Qhr=o(" to load the model weights."),Whr=l(),F(RE.$$.fragment),Hhr=l(),vo=a("div"),F(d9.$$.fragment),Uhr=l(),OFe=a("p"),Jhr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Yhr=l(),on=a("p"),Khr=o("The model class to instantiate is selected based on the "),VFe=a("code"),Zhr=o("model_type"),eur=o(` property of the config object (either
passed as an argument or loaded from `),XFe=a("code"),our=o("pretrained_model_name_or_path"),rur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zFe=a("code"),tur=o("pretrained_model_name_or_path"),aur=o(":"),nur=l(),rn=a("ul"),PE=a("li"),QFe=a("strong"),sur=o("beit"),lur=o(" \u2014 "),HW=a("a"),iur=o("BeitForSemanticSegmentation"),dur=o(" (BEiT model)"),cur=l(),BE=a("li"),WFe=a("strong"),mur=o("data2vec-vision"),fur=o(" \u2014 "),UW=a("a"),gur=o("Data2VecVisionForSemanticSegmentation"),hur=o(" (Data2VecVision model)"),uur=l(),IE=a("li"),HFe=a("strong"),pur=o("dpt"),_ur=o(" \u2014 "),JW=a("a"),bur=o("DPTForSemanticSegmentation"),vur=o(" (DPT model)"),Fur=l(),NE=a("li"),UFe=a("strong"),Tur=o("segformer"),Mur=o(" \u2014 "),YW=a("a"),Eur=o("SegformerForSemanticSegmentation"),Cur=o(" (SegFormer model)"),wur=l(),qE=a("p"),Aur=o("The model is set in evaluation mode by default using "),JFe=a("code"),Lur=o("model.eval()"),yur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YFe=a("code"),xur=o("model.train()"),$ur=l(),F(jE.$$.fragment),XOe=l(),Yd=a("h2"),DE=a("a"),KFe=a("span"),F(c9.$$.fragment),kur=l(),ZFe=a("span"),Sur=o("AutoModelForInstanceSegmentation"),zOe=l(),Zo=a("div"),F(m9.$$.fragment),Rur=l(),Kd=a("p"),Pur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=a("a"),Bur=o("from_pretrained()"),Iur=o(" class method or the "),ZW=a("a"),Nur=o("from_config()"),qur=o(` class
method.`),jur=l(),f9=a("p"),Dur=o("This class cannot be instantiated directly using "),e1e=a("code"),Gur=o("__init__()"),Our=o(" (throws an error)."),Vur=l(),xt=a("div"),F(g9.$$.fragment),Xur=l(),o1e=a("p"),zur=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Qur=l(),Zd=a("p"),Wur=o(`Note:
Loading a model from its configuration file does `),r1e=a("strong"),Hur=o("not"),Uur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),Jur=o("from_pretrained()"),Yur=o(" to load the model weights."),Kur=l(),F(GE.$$.fragment),Zur=l(),Fo=a("div"),F(h9.$$.fragment),epr=l(),t1e=a("p"),opr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),rpr=l(),tn=a("p"),tpr=o("The model class to instantiate is selected based on the "),a1e=a("code"),apr=o("model_type"),npr=o(` property of the config object (either
passed as an argument or loaded from `),n1e=a("code"),spr=o("pretrained_model_name_or_path"),lpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s1e=a("code"),ipr=o("pretrained_model_name_or_path"),dpr=o(":"),cpr=l(),l1e=a("ul"),OE=a("li"),i1e=a("strong"),mpr=o("maskformer"),fpr=o(" \u2014 "),oH=a("a"),gpr=o("MaskFormerForInstanceSegmentation"),hpr=o(" (MaskFormer model)"),upr=l(),VE=a("p"),ppr=o("The model is set in evaluation mode by default using "),d1e=a("code"),_pr=o("model.eval()"),bpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c1e=a("code"),vpr=o("model.train()"),Fpr=l(),F(XE.$$.fragment),QOe=l(),ec=a("h2"),zE=a("a"),m1e=a("span"),F(u9.$$.fragment),Tpr=l(),f1e=a("span"),Mpr=o("TFAutoModel"),WOe=l(),er=a("div"),F(p9.$$.fragment),Epr=l(),oc=a("p"),Cpr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=a("a"),wpr=o("from_pretrained()"),Apr=o(" class method or the "),tH=a("a"),Lpr=o("from_config()"),ypr=o(` class
method.`),xpr=l(),_9=a("p"),$pr=o("This class cannot be instantiated directly using "),g1e=a("code"),kpr=o("__init__()"),Spr=o(" (throws an error)."),Rpr=l(),$t=a("div"),F(b9.$$.fragment),Ppr=l(),h1e=a("p"),Bpr=o("Instantiates one of the base model classes of the library from a configuration."),Ipr=l(),rc=a("p"),Npr=o(`Note:
Loading a model from its configuration file does `),u1e=a("strong"),qpr=o("not"),jpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),Dpr=o("from_pretrained()"),Gpr=o(" to load the model weights."),Opr=l(),F(QE.$$.fragment),Vpr=l(),yr=a("div"),F(v9.$$.fragment),Xpr=l(),p1e=a("p"),zpr=o("Instantiate one of the base model classes of the library from a pretrained model."),Qpr=l(),an=a("p"),Wpr=o("The model class to instantiate is selected based on the "),_1e=a("code"),Hpr=o("model_type"),Upr=o(` property of the config object (either
passed as an argument or loaded from `),b1e=a("code"),Jpr=o("pretrained_model_name_or_path"),Ypr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v1e=a("code"),Kpr=o("pretrained_model_name_or_path"),Zpr=o(":"),e_r=l(),j=a("ul"),WE=a("li"),F1e=a("strong"),o_r=o("albert"),r_r=o(" \u2014 "),nH=a("a"),t_r=o("TFAlbertModel"),a_r=o(" (ALBERT model)"),n_r=l(),HE=a("li"),T1e=a("strong"),s_r=o("bart"),l_r=o(" \u2014 "),sH=a("a"),i_r=o("TFBartModel"),d_r=o(" (BART model)"),c_r=l(),UE=a("li"),M1e=a("strong"),m_r=o("bert"),f_r=o(" \u2014 "),lH=a("a"),g_r=o("TFBertModel"),h_r=o(" (BERT model)"),u_r=l(),JE=a("li"),E1e=a("strong"),p_r=o("blenderbot"),__r=o(" \u2014 "),iH=a("a"),b_r=o("TFBlenderbotModel"),v_r=o(" (Blenderbot model)"),F_r=l(),YE=a("li"),C1e=a("strong"),T_r=o("blenderbot-small"),M_r=o(" \u2014 "),dH=a("a"),E_r=o("TFBlenderbotSmallModel"),C_r=o(" (BlenderbotSmall model)"),w_r=l(),KE=a("li"),w1e=a("strong"),A_r=o("camembert"),L_r=o(" \u2014 "),cH=a("a"),y_r=o("TFCamembertModel"),x_r=o(" (CamemBERT model)"),$_r=l(),ZE=a("li"),A1e=a("strong"),k_r=o("clip"),S_r=o(" \u2014 "),mH=a("a"),R_r=o("TFCLIPModel"),P_r=o(" (CLIP model)"),B_r=l(),e4=a("li"),L1e=a("strong"),I_r=o("convbert"),N_r=o(" \u2014 "),fH=a("a"),q_r=o("TFConvBertModel"),j_r=o(" (ConvBERT model)"),D_r=l(),o4=a("li"),y1e=a("strong"),G_r=o("convnext"),O_r=o(" \u2014 "),gH=a("a"),V_r=o("TFConvNextModel"),X_r=o(" (ConvNeXT model)"),z_r=l(),r4=a("li"),x1e=a("strong"),Q_r=o("ctrl"),W_r=o(" \u2014 "),hH=a("a"),H_r=o("TFCTRLModel"),U_r=o(" (CTRL model)"),J_r=l(),t4=a("li"),$1e=a("strong"),Y_r=o("data2vec-vision"),K_r=o(" \u2014 "),uH=a("a"),Z_r=o("TFData2VecVisionModel"),e2r=o(" (Data2VecVision model)"),o2r=l(),a4=a("li"),k1e=a("strong"),r2r=o("deberta"),t2r=o(" \u2014 "),pH=a("a"),a2r=o("TFDebertaModel"),n2r=o(" (DeBERTa model)"),s2r=l(),n4=a("li"),S1e=a("strong"),l2r=o("deberta-v2"),i2r=o(" \u2014 "),_H=a("a"),d2r=o("TFDebertaV2Model"),c2r=o(" (DeBERTa-v2 model)"),m2r=l(),s4=a("li"),R1e=a("strong"),f2r=o("distilbert"),g2r=o(" \u2014 "),bH=a("a"),h2r=o("TFDistilBertModel"),u2r=o(" (DistilBERT model)"),p2r=l(),l4=a("li"),P1e=a("strong"),_2r=o("dpr"),b2r=o(" \u2014 "),vH=a("a"),v2r=o("TFDPRQuestionEncoder"),F2r=o(" (DPR model)"),T2r=l(),i4=a("li"),B1e=a("strong"),M2r=o("electra"),E2r=o(" \u2014 "),FH=a("a"),C2r=o("TFElectraModel"),w2r=o(" (ELECTRA model)"),A2r=l(),d4=a("li"),I1e=a("strong"),L2r=o("flaubert"),y2r=o(" \u2014 "),TH=a("a"),x2r=o("TFFlaubertModel"),$2r=o(" (FlauBERT model)"),k2r=l(),Qs=a("li"),N1e=a("strong"),S2r=o("funnel"),R2r=o(" \u2014 "),MH=a("a"),P2r=o("TFFunnelModel"),B2r=o(" or "),EH=a("a"),I2r=o("TFFunnelBaseModel"),N2r=o(" (Funnel Transformer model)"),q2r=l(),c4=a("li"),q1e=a("strong"),j2r=o("gpt2"),D2r=o(" \u2014 "),CH=a("a"),G2r=o("TFGPT2Model"),O2r=o(" (OpenAI GPT-2 model)"),V2r=l(),m4=a("li"),j1e=a("strong"),X2r=o("gptj"),z2r=o(" \u2014 "),wH=a("a"),Q2r=o("TFGPTJModel"),W2r=o(" (GPT-J model)"),H2r=l(),f4=a("li"),D1e=a("strong"),U2r=o("hubert"),J2r=o(" \u2014 "),AH=a("a"),Y2r=o("TFHubertModel"),K2r=o(" (Hubert model)"),Z2r=l(),g4=a("li"),G1e=a("strong"),ebr=o("layoutlm"),obr=o(" \u2014 "),LH=a("a"),rbr=o("TFLayoutLMModel"),tbr=o(" (LayoutLM model)"),abr=l(),h4=a("li"),O1e=a("strong"),nbr=o("led"),sbr=o(" \u2014 "),yH=a("a"),lbr=o("TFLEDModel"),ibr=o(" (LED model)"),dbr=l(),u4=a("li"),V1e=a("strong"),cbr=o("longformer"),mbr=o(" \u2014 "),xH=a("a"),fbr=o("TFLongformerModel"),gbr=o(" (Longformer model)"),hbr=l(),p4=a("li"),X1e=a("strong"),ubr=o("lxmert"),pbr=o(" \u2014 "),$H=a("a"),_br=o("TFLxmertModel"),bbr=o(" (LXMERT model)"),vbr=l(),_4=a("li"),z1e=a("strong"),Fbr=o("marian"),Tbr=o(" \u2014 "),kH=a("a"),Mbr=o("TFMarianModel"),Ebr=o(" (Marian model)"),Cbr=l(),b4=a("li"),Q1e=a("strong"),wbr=o("mbart"),Abr=o(" \u2014 "),SH=a("a"),Lbr=o("TFMBartModel"),ybr=o(" (mBART model)"),xbr=l(),v4=a("li"),W1e=a("strong"),$br=o("mobilebert"),kbr=o(" \u2014 "),RH=a("a"),Sbr=o("TFMobileBertModel"),Rbr=o(" (MobileBERT model)"),Pbr=l(),F4=a("li"),H1e=a("strong"),Bbr=o("mpnet"),Ibr=o(" \u2014 "),PH=a("a"),Nbr=o("TFMPNetModel"),qbr=o(" (MPNet model)"),jbr=l(),T4=a("li"),U1e=a("strong"),Dbr=o("mt5"),Gbr=o(" \u2014 "),BH=a("a"),Obr=o("TFMT5Model"),Vbr=o(" (MT5 model)"),Xbr=l(),M4=a("li"),J1e=a("strong"),zbr=o("openai-gpt"),Qbr=o(" \u2014 "),IH=a("a"),Wbr=o("TFOpenAIGPTModel"),Hbr=o(" (OpenAI GPT model)"),Ubr=l(),E4=a("li"),Y1e=a("strong"),Jbr=o("opt"),Ybr=o(" \u2014 "),NH=a("a"),Kbr=o("TFOPTModel"),Zbr=o(" (OPT model)"),evr=l(),C4=a("li"),K1e=a("strong"),ovr=o("pegasus"),rvr=o(" \u2014 "),qH=a("a"),tvr=o("TFPegasusModel"),avr=o(" (Pegasus model)"),nvr=l(),w4=a("li"),Z1e=a("strong"),svr=o("rembert"),lvr=o(" \u2014 "),jH=a("a"),ivr=o("TFRemBertModel"),dvr=o(" (RemBERT model)"),cvr=l(),A4=a("li"),eTe=a("strong"),mvr=o("roberta"),fvr=o(" \u2014 "),DH=a("a"),gvr=o("TFRobertaModel"),hvr=o(" (RoBERTa model)"),uvr=l(),L4=a("li"),oTe=a("strong"),pvr=o("roformer"),_vr=o(" \u2014 "),GH=a("a"),bvr=o("TFRoFormerModel"),vvr=o(" (RoFormer model)"),Fvr=l(),y4=a("li"),rTe=a("strong"),Tvr=o("speech_to_text"),Mvr=o(" \u2014 "),OH=a("a"),Evr=o("TFSpeech2TextModel"),Cvr=o(" (Speech2Text model)"),wvr=l(),x4=a("li"),tTe=a("strong"),Avr=o("swin"),Lvr=o(" \u2014 "),VH=a("a"),yvr=o("TFSwinModel"),xvr=o(" (Swin Transformer model)"),$vr=l(),$4=a("li"),aTe=a("strong"),kvr=o("t5"),Svr=o(" \u2014 "),XH=a("a"),Rvr=o("TFT5Model"),Pvr=o(" (T5 model)"),Bvr=l(),k4=a("li"),nTe=a("strong"),Ivr=o("tapas"),Nvr=o(" \u2014 "),zH=a("a"),qvr=o("TFTapasModel"),jvr=o(" (TAPAS model)"),Dvr=l(),S4=a("li"),sTe=a("strong"),Gvr=o("transfo-xl"),Ovr=o(" \u2014 "),QH=a("a"),Vvr=o("TFTransfoXLModel"),Xvr=o(" (Transformer-XL model)"),zvr=l(),R4=a("li"),lTe=a("strong"),Qvr=o("vit"),Wvr=o(" \u2014 "),WH=a("a"),Hvr=o("TFViTModel"),Uvr=o(" (ViT model)"),Jvr=l(),P4=a("li"),iTe=a("strong"),Yvr=o("vit_mae"),Kvr=o(" \u2014 "),HH=a("a"),Zvr=o("TFViTMAEModel"),eFr=o(" (ViTMAE model)"),oFr=l(),B4=a("li"),dTe=a("strong"),rFr=o("wav2vec2"),tFr=o(" \u2014 "),UH=a("a"),aFr=o("TFWav2Vec2Model"),nFr=o(" (Wav2Vec2 model)"),sFr=l(),I4=a("li"),cTe=a("strong"),lFr=o("xlm"),iFr=o(" \u2014 "),JH=a("a"),dFr=o("TFXLMModel"),cFr=o(" (XLM model)"),mFr=l(),N4=a("li"),mTe=a("strong"),fFr=o("xlm-roberta"),gFr=o(" \u2014 "),YH=a("a"),hFr=o("TFXLMRobertaModel"),uFr=o(" (XLM-RoBERTa model)"),pFr=l(),q4=a("li"),fTe=a("strong"),_Fr=o("xlnet"),bFr=o(" \u2014 "),KH=a("a"),vFr=o("TFXLNetModel"),FFr=o(" (XLNet model)"),TFr=l(),F(j4.$$.fragment),HOe=l(),tc=a("h2"),D4=a("a"),gTe=a("span"),F(F9.$$.fragment),MFr=l(),hTe=a("span"),EFr=o("TFAutoModelForPreTraining"),UOe=l(),or=a("div"),F(T9.$$.fragment),CFr=l(),ac=a("p"),wFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=a("a"),AFr=o("from_pretrained()"),LFr=o(" class method or the "),eU=a("a"),yFr=o("from_config()"),xFr=o(` class
method.`),$Fr=l(),M9=a("p"),kFr=o("This class cannot be instantiated directly using "),uTe=a("code"),SFr=o("__init__()"),RFr=o(" (throws an error)."),PFr=l(),kt=a("div"),F(E9.$$.fragment),BFr=l(),pTe=a("p"),IFr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),NFr=l(),nc=a("p"),qFr=o(`Note:
Loading a model from its configuration file does `),_Te=a("strong"),jFr=o("not"),DFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=a("a"),GFr=o("from_pretrained()"),OFr=o(" to load the model weights."),VFr=l(),F(G4.$$.fragment),XFr=l(),xr=a("div"),F(C9.$$.fragment),zFr=l(),bTe=a("p"),QFr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),WFr=l(),nn=a("p"),HFr=o("The model class to instantiate is selected based on the "),vTe=a("code"),UFr=o("model_type"),JFr=o(` property of the config object (either
passed as an argument or loaded from `),FTe=a("code"),YFr=o("pretrained_model_name_or_path"),KFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TTe=a("code"),ZFr=o("pretrained_model_name_or_path"),e1r=o(":"),o1r=l(),se=a("ul"),O4=a("li"),MTe=a("strong"),r1r=o("albert"),t1r=o(" \u2014 "),rU=a("a"),a1r=o("TFAlbertForPreTraining"),n1r=o(" (ALBERT model)"),s1r=l(),V4=a("li"),ETe=a("strong"),l1r=o("bart"),i1r=o(" \u2014 "),tU=a("a"),d1r=o("TFBartForConditionalGeneration"),c1r=o(" (BART model)"),m1r=l(),X4=a("li"),CTe=a("strong"),f1r=o("bert"),g1r=o(" \u2014 "),aU=a("a"),h1r=o("TFBertForPreTraining"),u1r=o(" (BERT model)"),p1r=l(),z4=a("li"),wTe=a("strong"),_1r=o("camembert"),b1r=o(" \u2014 "),nU=a("a"),v1r=o("TFCamembertForMaskedLM"),F1r=o(" (CamemBERT model)"),T1r=l(),Q4=a("li"),ATe=a("strong"),M1r=o("ctrl"),E1r=o(" \u2014 "),sU=a("a"),C1r=o("TFCTRLLMHeadModel"),w1r=o(" (CTRL model)"),A1r=l(),W4=a("li"),LTe=a("strong"),L1r=o("distilbert"),y1r=o(" \u2014 "),lU=a("a"),x1r=o("TFDistilBertForMaskedLM"),$1r=o(" (DistilBERT model)"),k1r=l(),H4=a("li"),yTe=a("strong"),S1r=o("electra"),R1r=o(" \u2014 "),iU=a("a"),P1r=o("TFElectraForPreTraining"),B1r=o(" (ELECTRA model)"),I1r=l(),U4=a("li"),xTe=a("strong"),N1r=o("flaubert"),q1r=o(" \u2014 "),dU=a("a"),j1r=o("TFFlaubertWithLMHeadModel"),D1r=o(" (FlauBERT model)"),G1r=l(),J4=a("li"),$Te=a("strong"),O1r=o("funnel"),V1r=o(" \u2014 "),cU=a("a"),X1r=o("TFFunnelForPreTraining"),z1r=o(" (Funnel Transformer model)"),Q1r=l(),Y4=a("li"),kTe=a("strong"),W1r=o("gpt2"),H1r=o(" \u2014 "),mU=a("a"),U1r=o("TFGPT2LMHeadModel"),J1r=o(" (OpenAI GPT-2 model)"),Y1r=l(),K4=a("li"),STe=a("strong"),K1r=o("layoutlm"),Z1r=o(" \u2014 "),fU=a("a"),eTr=o("TFLayoutLMForMaskedLM"),oTr=o(" (LayoutLM model)"),rTr=l(),Z4=a("li"),RTe=a("strong"),tTr=o("lxmert"),aTr=o(" \u2014 "),gU=a("a"),nTr=o("TFLxmertForPreTraining"),sTr=o(" (LXMERT model)"),lTr=l(),eC=a("li"),PTe=a("strong"),iTr=o("mobilebert"),dTr=o(" \u2014 "),hU=a("a"),cTr=o("TFMobileBertForPreTraining"),mTr=o(" (MobileBERT model)"),fTr=l(),oC=a("li"),BTe=a("strong"),gTr=o("mpnet"),hTr=o(" \u2014 "),uU=a("a"),uTr=o("TFMPNetForMaskedLM"),pTr=o(" (MPNet model)"),_Tr=l(),rC=a("li"),ITe=a("strong"),bTr=o("openai-gpt"),vTr=o(" \u2014 "),pU=a("a"),FTr=o("TFOpenAIGPTLMHeadModel"),TTr=o(" (OpenAI GPT model)"),MTr=l(),tC=a("li"),NTe=a("strong"),ETr=o("roberta"),CTr=o(" \u2014 "),_U=a("a"),wTr=o("TFRobertaForMaskedLM"),ATr=o(" (RoBERTa model)"),LTr=l(),aC=a("li"),qTe=a("strong"),yTr=o("t5"),xTr=o(" \u2014 "),bU=a("a"),$Tr=o("TFT5ForConditionalGeneration"),kTr=o(" (T5 model)"),STr=l(),nC=a("li"),jTe=a("strong"),RTr=o("tapas"),PTr=o(" \u2014 "),vU=a("a"),BTr=o("TFTapasForMaskedLM"),ITr=o(" (TAPAS model)"),NTr=l(),sC=a("li"),DTe=a("strong"),qTr=o("transfo-xl"),jTr=o(" \u2014 "),FU=a("a"),DTr=o("TFTransfoXLLMHeadModel"),GTr=o(" (Transformer-XL model)"),OTr=l(),lC=a("li"),GTe=a("strong"),VTr=o("vit_mae"),XTr=o(" \u2014 "),TU=a("a"),zTr=o("TFViTMAEForPreTraining"),QTr=o(" (ViTMAE model)"),WTr=l(),iC=a("li"),OTe=a("strong"),HTr=o("xlm"),UTr=o(" \u2014 "),MU=a("a"),JTr=o("TFXLMWithLMHeadModel"),YTr=o(" (XLM model)"),KTr=l(),dC=a("li"),VTe=a("strong"),ZTr=o("xlm-roberta"),eMr=o(" \u2014 "),EU=a("a"),oMr=o("TFXLMRobertaForMaskedLM"),rMr=o(" (XLM-RoBERTa model)"),tMr=l(),cC=a("li"),XTe=a("strong"),aMr=o("xlnet"),nMr=o(" \u2014 "),CU=a("a"),sMr=o("TFXLNetLMHeadModel"),lMr=o(" (XLNet model)"),iMr=l(),F(mC.$$.fragment),JOe=l(),sc=a("h2"),fC=a("a"),zTe=a("span"),F(w9.$$.fragment),dMr=l(),QTe=a("span"),cMr=o("TFAutoModelForCausalLM"),YOe=l(),rr=a("div"),F(A9.$$.fragment),mMr=l(),lc=a("p"),fMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=a("a"),gMr=o("from_pretrained()"),hMr=o(" class method or the "),AU=a("a"),uMr=o("from_config()"),pMr=o(` class
method.`),_Mr=l(),L9=a("p"),bMr=o("This class cannot be instantiated directly using "),WTe=a("code"),vMr=o("__init__()"),FMr=o(" (throws an error)."),TMr=l(),St=a("div"),F(y9.$$.fragment),MMr=l(),HTe=a("p"),EMr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),CMr=l(),ic=a("p"),wMr=o(`Note:
Loading a model from its configuration file does `),UTe=a("strong"),AMr=o("not"),LMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),yMr=o("from_pretrained()"),xMr=o(" to load the model weights."),$Mr=l(),F(gC.$$.fragment),kMr=l(),$r=a("div"),F(x9.$$.fragment),SMr=l(),JTe=a("p"),RMr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),PMr=l(),sn=a("p"),BMr=o("The model class to instantiate is selected based on the "),YTe=a("code"),IMr=o("model_type"),NMr=o(` property of the config object (either
passed as an argument or loaded from `),KTe=a("code"),qMr=o("pretrained_model_name_or_path"),jMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZTe=a("code"),DMr=o("pretrained_model_name_or_path"),GMr=o(":"),OMr=l(),Me=a("ul"),hC=a("li"),eMe=a("strong"),VMr=o("bert"),XMr=o(" \u2014 "),yU=a("a"),zMr=o("TFBertLMHeadModel"),QMr=o(" (BERT model)"),WMr=l(),uC=a("li"),oMe=a("strong"),HMr=o("camembert"),UMr=o(" \u2014 "),xU=a("a"),JMr=o("TFCamembertForCausalLM"),YMr=o(" (CamemBERT model)"),KMr=l(),pC=a("li"),rMe=a("strong"),ZMr=o("ctrl"),eEr=o(" \u2014 "),$U=a("a"),oEr=o("TFCTRLLMHeadModel"),rEr=o(" (CTRL model)"),tEr=l(),_C=a("li"),tMe=a("strong"),aEr=o("gpt2"),nEr=o(" \u2014 "),kU=a("a"),sEr=o("TFGPT2LMHeadModel"),lEr=o(" (OpenAI GPT-2 model)"),iEr=l(),bC=a("li"),aMe=a("strong"),dEr=o("gptj"),cEr=o(" \u2014 "),SU=a("a"),mEr=o("TFGPTJForCausalLM"),fEr=o(" (GPT-J model)"),gEr=l(),vC=a("li"),nMe=a("strong"),hEr=o("openai-gpt"),uEr=o(" \u2014 "),RU=a("a"),pEr=o("TFOpenAIGPTLMHeadModel"),_Er=o(" (OpenAI GPT model)"),bEr=l(),FC=a("li"),sMe=a("strong"),vEr=o("opt"),FEr=o(" \u2014 "),PU=a("a"),TEr=o("TFOPTForCausalLM"),MEr=o(" (OPT model)"),EEr=l(),TC=a("li"),lMe=a("strong"),CEr=o("rembert"),wEr=o(" \u2014 "),BU=a("a"),AEr=o("TFRemBertForCausalLM"),LEr=o(" (RemBERT model)"),yEr=l(),MC=a("li"),iMe=a("strong"),xEr=o("roberta"),$Er=o(" \u2014 "),IU=a("a"),kEr=o("TFRobertaForCausalLM"),SEr=o(" (RoBERTa model)"),REr=l(),EC=a("li"),dMe=a("strong"),PEr=o("roformer"),BEr=o(" \u2014 "),NU=a("a"),IEr=o("TFRoFormerForCausalLM"),NEr=o(" (RoFormer model)"),qEr=l(),CC=a("li"),cMe=a("strong"),jEr=o("transfo-xl"),DEr=o(" \u2014 "),qU=a("a"),GEr=o("TFTransfoXLLMHeadModel"),OEr=o(" (Transformer-XL model)"),VEr=l(),wC=a("li"),mMe=a("strong"),XEr=o("xlm"),zEr=o(" \u2014 "),jU=a("a"),QEr=o("TFXLMWithLMHeadModel"),WEr=o(" (XLM model)"),HEr=l(),AC=a("li"),fMe=a("strong"),UEr=o("xlnet"),JEr=o(" \u2014 "),DU=a("a"),YEr=o("TFXLNetLMHeadModel"),KEr=o(" (XLNet model)"),ZEr=l(),F(LC.$$.fragment),KOe=l(),dc=a("h2"),yC=a("a"),gMe=a("span"),F($9.$$.fragment),e4r=l(),hMe=a("span"),o4r=o("TFAutoModelForImageClassification"),ZOe=l(),tr=a("div"),F(k9.$$.fragment),r4r=l(),cc=a("p"),t4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=a("a"),a4r=o("from_pretrained()"),n4r=o(" class method or the "),OU=a("a"),s4r=o("from_config()"),l4r=o(` class
method.`),i4r=l(),S9=a("p"),d4r=o("This class cannot be instantiated directly using "),uMe=a("code"),c4r=o("__init__()"),m4r=o(" (throws an error)."),f4r=l(),Rt=a("div"),F(R9.$$.fragment),g4r=l(),pMe=a("p"),h4r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),u4r=l(),mc=a("p"),p4r=o(`Note:
Loading a model from its configuration file does `),_Me=a("strong"),_4r=o("not"),b4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),v4r=o("from_pretrained()"),F4r=o(" to load the model weights."),T4r=l(),F(xC.$$.fragment),M4r=l(),kr=a("div"),F(P9.$$.fragment),E4r=l(),bMe=a("p"),C4r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),w4r=l(),ln=a("p"),A4r=o("The model class to instantiate is selected based on the "),vMe=a("code"),L4r=o("model_type"),y4r=o(` property of the config object (either
passed as an argument or loaded from `),FMe=a("code"),x4r=o("pretrained_model_name_or_path"),$4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TMe=a("code"),k4r=o("pretrained_model_name_or_path"),S4r=o(":"),R4r=l(),dn=a("ul"),$C=a("li"),MMe=a("strong"),P4r=o("convnext"),B4r=o(" \u2014 "),XU=a("a"),I4r=o("TFConvNextForImageClassification"),N4r=o(" (ConvNeXT model)"),q4r=l(),kC=a("li"),EMe=a("strong"),j4r=o("data2vec-vision"),D4r=o(" \u2014 "),zU=a("a"),G4r=o("TFData2VecVisionForImageClassification"),O4r=o(" (Data2VecVision model)"),V4r=l(),SC=a("li"),CMe=a("strong"),X4r=o("swin"),z4r=o(" \u2014 "),QU=a("a"),Q4r=o("TFSwinForImageClassification"),W4r=o(" (Swin Transformer model)"),H4r=l(),RC=a("li"),wMe=a("strong"),U4r=o("vit"),J4r=o(" \u2014 "),WU=a("a"),Y4r=o("TFViTForImageClassification"),K4r=o(" (ViT model)"),Z4r=l(),F(PC.$$.fragment),eVe=l(),fc=a("h2"),BC=a("a"),AMe=a("span"),F(B9.$$.fragment),eCr=l(),LMe=a("span"),oCr=o("TFAutoModelForMaskedLM"),oVe=l(),ar=a("div"),F(I9.$$.fragment),rCr=l(),gc=a("p"),tCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=a("a"),aCr=o("from_pretrained()"),nCr=o(" class method or the "),UU=a("a"),sCr=o("from_config()"),lCr=o(` class
method.`),iCr=l(),N9=a("p"),dCr=o("This class cannot be instantiated directly using "),yMe=a("code"),cCr=o("__init__()"),mCr=o(" (throws an error)."),fCr=l(),Pt=a("div"),F(q9.$$.fragment),gCr=l(),xMe=a("p"),hCr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uCr=l(),hc=a("p"),pCr=o(`Note:
Loading a model from its configuration file does `),$Me=a("strong"),_Cr=o("not"),bCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=a("a"),vCr=o("from_pretrained()"),FCr=o(" to load the model weights."),TCr=l(),F(IC.$$.fragment),MCr=l(),Sr=a("div"),F(j9.$$.fragment),ECr=l(),kMe=a("p"),CCr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wCr=l(),cn=a("p"),ACr=o("The model class to instantiate is selected based on the "),SMe=a("code"),LCr=o("model_type"),yCr=o(` property of the config object (either
passed as an argument or loaded from `),RMe=a("code"),xCr=o("pretrained_model_name_or_path"),$Cr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PMe=a("code"),kCr=o("pretrained_model_name_or_path"),SCr=o(":"),RCr=l(),ie=a("ul"),NC=a("li"),BMe=a("strong"),PCr=o("albert"),BCr=o(" \u2014 "),YU=a("a"),ICr=o("TFAlbertForMaskedLM"),NCr=o(" (ALBERT model)"),qCr=l(),qC=a("li"),IMe=a("strong"),jCr=o("bert"),DCr=o(" \u2014 "),KU=a("a"),GCr=o("TFBertForMaskedLM"),OCr=o(" (BERT model)"),VCr=l(),jC=a("li"),NMe=a("strong"),XCr=o("camembert"),zCr=o(" \u2014 "),ZU=a("a"),QCr=o("TFCamembertForMaskedLM"),WCr=o(" (CamemBERT model)"),HCr=l(),DC=a("li"),qMe=a("strong"),UCr=o("convbert"),JCr=o(" \u2014 "),eJ=a("a"),YCr=o("TFConvBertForMaskedLM"),KCr=o(" (ConvBERT model)"),ZCr=l(),GC=a("li"),jMe=a("strong"),e5r=o("deberta"),o5r=o(" \u2014 "),oJ=a("a"),r5r=o("TFDebertaForMaskedLM"),t5r=o(" (DeBERTa model)"),a5r=l(),OC=a("li"),DMe=a("strong"),n5r=o("deberta-v2"),s5r=o(" \u2014 "),rJ=a("a"),l5r=o("TFDebertaV2ForMaskedLM"),i5r=o(" (DeBERTa-v2 model)"),d5r=l(),VC=a("li"),GMe=a("strong"),c5r=o("distilbert"),m5r=o(" \u2014 "),tJ=a("a"),f5r=o("TFDistilBertForMaskedLM"),g5r=o(" (DistilBERT model)"),h5r=l(),XC=a("li"),OMe=a("strong"),u5r=o("electra"),p5r=o(" \u2014 "),aJ=a("a"),_5r=o("TFElectraForMaskedLM"),b5r=o(" (ELECTRA model)"),v5r=l(),zC=a("li"),VMe=a("strong"),F5r=o("flaubert"),T5r=o(" \u2014 "),nJ=a("a"),M5r=o("TFFlaubertWithLMHeadModel"),E5r=o(" (FlauBERT model)"),C5r=l(),QC=a("li"),XMe=a("strong"),w5r=o("funnel"),A5r=o(" \u2014 "),sJ=a("a"),L5r=o("TFFunnelForMaskedLM"),y5r=o(" (Funnel Transformer model)"),x5r=l(),WC=a("li"),zMe=a("strong"),$5r=o("layoutlm"),k5r=o(" \u2014 "),lJ=a("a"),S5r=o("TFLayoutLMForMaskedLM"),R5r=o(" (LayoutLM model)"),P5r=l(),HC=a("li"),QMe=a("strong"),B5r=o("longformer"),I5r=o(" \u2014 "),iJ=a("a"),N5r=o("TFLongformerForMaskedLM"),q5r=o(" (Longformer model)"),j5r=l(),UC=a("li"),WMe=a("strong"),D5r=o("mobilebert"),G5r=o(" \u2014 "),dJ=a("a"),O5r=o("TFMobileBertForMaskedLM"),V5r=o(" (MobileBERT model)"),X5r=l(),JC=a("li"),HMe=a("strong"),z5r=o("mpnet"),Q5r=o(" \u2014 "),cJ=a("a"),W5r=o("TFMPNetForMaskedLM"),H5r=o(" (MPNet model)"),U5r=l(),YC=a("li"),UMe=a("strong"),J5r=o("rembert"),Y5r=o(" \u2014 "),mJ=a("a"),K5r=o("TFRemBertForMaskedLM"),Z5r=o(" (RemBERT model)"),e3r=l(),KC=a("li"),JMe=a("strong"),o3r=o("roberta"),r3r=o(" \u2014 "),fJ=a("a"),t3r=o("TFRobertaForMaskedLM"),a3r=o(" (RoBERTa model)"),n3r=l(),ZC=a("li"),YMe=a("strong"),s3r=o("roformer"),l3r=o(" \u2014 "),gJ=a("a"),i3r=o("TFRoFormerForMaskedLM"),d3r=o(" (RoFormer model)"),c3r=l(),e5=a("li"),KMe=a("strong"),m3r=o("tapas"),f3r=o(" \u2014 "),hJ=a("a"),g3r=o("TFTapasForMaskedLM"),h3r=o(" (TAPAS model)"),u3r=l(),o5=a("li"),ZMe=a("strong"),p3r=o("xlm"),_3r=o(" \u2014 "),uJ=a("a"),b3r=o("TFXLMWithLMHeadModel"),v3r=o(" (XLM model)"),F3r=l(),r5=a("li"),eEe=a("strong"),T3r=o("xlm-roberta"),M3r=o(" \u2014 "),pJ=a("a"),E3r=o("TFXLMRobertaForMaskedLM"),C3r=o(" (XLM-RoBERTa model)"),w3r=l(),F(t5.$$.fragment),rVe=l(),uc=a("h2"),a5=a("a"),oEe=a("span"),F(D9.$$.fragment),A3r=l(),rEe=a("span"),L3r=o("TFAutoModelForSeq2SeqLM"),tVe=l(),nr=a("div"),F(G9.$$.fragment),y3r=l(),pc=a("p"),x3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_J=a("a"),$3r=o("from_pretrained()"),k3r=o(" class method or the "),bJ=a("a"),S3r=o("from_config()"),R3r=o(` class
method.`),P3r=l(),O9=a("p"),B3r=o("This class cannot be instantiated directly using "),tEe=a("code"),I3r=o("__init__()"),N3r=o(" (throws an error)."),q3r=l(),Bt=a("div"),F(V9.$$.fragment),j3r=l(),aEe=a("p"),D3r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),G3r=l(),_c=a("p"),O3r=o(`Note:
Loading a model from its configuration file does `),nEe=a("strong"),V3r=o("not"),X3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),z3r=o("from_pretrained()"),Q3r=o(" to load the model weights."),W3r=l(),F(n5.$$.fragment),H3r=l(),Rr=a("div"),F(X9.$$.fragment),U3r=l(),sEe=a("p"),J3r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Y3r=l(),mn=a("p"),K3r=o("The model class to instantiate is selected based on the "),lEe=a("code"),Z3r=o("model_type"),e0r=o(` property of the config object (either
passed as an argument or loaded from `),iEe=a("code"),o0r=o("pretrained_model_name_or_path"),r0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dEe=a("code"),t0r=o("pretrained_model_name_or_path"),a0r=o(":"),n0r=l(),ye=a("ul"),s5=a("li"),cEe=a("strong"),s0r=o("bart"),l0r=o(" \u2014 "),FJ=a("a"),i0r=o("TFBartForConditionalGeneration"),d0r=o(" (BART model)"),c0r=l(),l5=a("li"),mEe=a("strong"),m0r=o("blenderbot"),f0r=o(" \u2014 "),TJ=a("a"),g0r=o("TFBlenderbotForConditionalGeneration"),h0r=o(" (Blenderbot model)"),u0r=l(),i5=a("li"),fEe=a("strong"),p0r=o("blenderbot-small"),_0r=o(" \u2014 "),MJ=a("a"),b0r=o("TFBlenderbotSmallForConditionalGeneration"),v0r=o(" (BlenderbotSmall model)"),F0r=l(),d5=a("li"),gEe=a("strong"),T0r=o("encoder-decoder"),M0r=o(" \u2014 "),EJ=a("a"),E0r=o("TFEncoderDecoderModel"),C0r=o(" (Encoder decoder model)"),w0r=l(),c5=a("li"),hEe=a("strong"),A0r=o("led"),L0r=o(" \u2014 "),CJ=a("a"),y0r=o("TFLEDForConditionalGeneration"),x0r=o(" (LED model)"),$0r=l(),m5=a("li"),uEe=a("strong"),k0r=o("marian"),S0r=o(" \u2014 "),wJ=a("a"),R0r=o("TFMarianMTModel"),P0r=o(" (Marian model)"),B0r=l(),f5=a("li"),pEe=a("strong"),I0r=o("mbart"),N0r=o(" \u2014 "),AJ=a("a"),q0r=o("TFMBartForConditionalGeneration"),j0r=o(" (mBART model)"),D0r=l(),g5=a("li"),_Ee=a("strong"),G0r=o("mt5"),O0r=o(" \u2014 "),LJ=a("a"),V0r=o("TFMT5ForConditionalGeneration"),X0r=o(" (MT5 model)"),z0r=l(),h5=a("li"),bEe=a("strong"),Q0r=o("pegasus"),W0r=o(" \u2014 "),yJ=a("a"),H0r=o("TFPegasusForConditionalGeneration"),U0r=o(" (Pegasus model)"),J0r=l(),u5=a("li"),vEe=a("strong"),Y0r=o("t5"),K0r=o(" \u2014 "),xJ=a("a"),Z0r=o("TFT5ForConditionalGeneration"),ewr=o(" (T5 model)"),owr=l(),F(p5.$$.fragment),aVe=l(),bc=a("h2"),_5=a("a"),FEe=a("span"),F(z9.$$.fragment),rwr=l(),TEe=a("span"),twr=o("TFAutoModelForSequenceClassification"),nVe=l(),sr=a("div"),F(Q9.$$.fragment),awr=l(),vc=a("p"),nwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=a("a"),swr=o("from_pretrained()"),lwr=o(" class method or the "),kJ=a("a"),iwr=o("from_config()"),dwr=o(` class
method.`),cwr=l(),W9=a("p"),mwr=o("This class cannot be instantiated directly using "),MEe=a("code"),fwr=o("__init__()"),gwr=o(" (throws an error)."),hwr=l(),It=a("div"),F(H9.$$.fragment),uwr=l(),EEe=a("p"),pwr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),_wr=l(),Fc=a("p"),bwr=o(`Note:
Loading a model from its configuration file does `),CEe=a("strong"),vwr=o("not"),Fwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),Twr=o("from_pretrained()"),Mwr=o(" to load the model weights."),Ewr=l(),F(b5.$$.fragment),Cwr=l(),Pr=a("div"),F(U9.$$.fragment),wwr=l(),wEe=a("p"),Awr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Lwr=l(),fn=a("p"),ywr=o("The model class to instantiate is selected based on the "),AEe=a("code"),xwr=o("model_type"),$wr=o(` property of the config object (either
passed as an argument or loaded from `),LEe=a("code"),kwr=o("pretrained_model_name_or_path"),Swr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yEe=a("code"),Rwr=o("pretrained_model_name_or_path"),Pwr=o(":"),Bwr=l(),te=a("ul"),v5=a("li"),xEe=a("strong"),Iwr=o("albert"),Nwr=o(" \u2014 "),RJ=a("a"),qwr=o("TFAlbertForSequenceClassification"),jwr=o(" (ALBERT model)"),Dwr=l(),F5=a("li"),$Ee=a("strong"),Gwr=o("bert"),Owr=o(" \u2014 "),PJ=a("a"),Vwr=o("TFBertForSequenceClassification"),Xwr=o(" (BERT model)"),zwr=l(),T5=a("li"),kEe=a("strong"),Qwr=o("camembert"),Wwr=o(" \u2014 "),BJ=a("a"),Hwr=o("TFCamembertForSequenceClassification"),Uwr=o(" (CamemBERT model)"),Jwr=l(),M5=a("li"),SEe=a("strong"),Ywr=o("convbert"),Kwr=o(" \u2014 "),IJ=a("a"),Zwr=o("TFConvBertForSequenceClassification"),eAr=o(" (ConvBERT model)"),oAr=l(),E5=a("li"),REe=a("strong"),rAr=o("ctrl"),tAr=o(" \u2014 "),NJ=a("a"),aAr=o("TFCTRLForSequenceClassification"),nAr=o(" (CTRL model)"),sAr=l(),C5=a("li"),PEe=a("strong"),lAr=o("deberta"),iAr=o(" \u2014 "),qJ=a("a"),dAr=o("TFDebertaForSequenceClassification"),cAr=o(" (DeBERTa model)"),mAr=l(),w5=a("li"),BEe=a("strong"),fAr=o("deberta-v2"),gAr=o(" \u2014 "),jJ=a("a"),hAr=o("TFDebertaV2ForSequenceClassification"),uAr=o(" (DeBERTa-v2 model)"),pAr=l(),A5=a("li"),IEe=a("strong"),_Ar=o("distilbert"),bAr=o(" \u2014 "),DJ=a("a"),vAr=o("TFDistilBertForSequenceClassification"),FAr=o(" (DistilBERT model)"),TAr=l(),L5=a("li"),NEe=a("strong"),MAr=o("electra"),EAr=o(" \u2014 "),GJ=a("a"),CAr=o("TFElectraForSequenceClassification"),wAr=o(" (ELECTRA model)"),AAr=l(),y5=a("li"),qEe=a("strong"),LAr=o("flaubert"),yAr=o(" \u2014 "),OJ=a("a"),xAr=o("TFFlaubertForSequenceClassification"),$Ar=o(" (FlauBERT model)"),kAr=l(),x5=a("li"),jEe=a("strong"),SAr=o("funnel"),RAr=o(" \u2014 "),VJ=a("a"),PAr=o("TFFunnelForSequenceClassification"),BAr=o(" (Funnel Transformer model)"),IAr=l(),$5=a("li"),DEe=a("strong"),NAr=o("gpt2"),qAr=o(" \u2014 "),XJ=a("a"),jAr=o("TFGPT2ForSequenceClassification"),DAr=o(" (OpenAI GPT-2 model)"),GAr=l(),k5=a("li"),GEe=a("strong"),OAr=o("gptj"),VAr=o(" \u2014 "),zJ=a("a"),XAr=o("TFGPTJForSequenceClassification"),zAr=o(" (GPT-J model)"),QAr=l(),S5=a("li"),OEe=a("strong"),WAr=o("layoutlm"),HAr=o(" \u2014 "),QJ=a("a"),UAr=o("TFLayoutLMForSequenceClassification"),JAr=o(" (LayoutLM model)"),YAr=l(),R5=a("li"),VEe=a("strong"),KAr=o("longformer"),ZAr=o(" \u2014 "),WJ=a("a"),e6r=o("TFLongformerForSequenceClassification"),o6r=o(" (Longformer model)"),r6r=l(),P5=a("li"),XEe=a("strong"),t6r=o("mobilebert"),a6r=o(" \u2014 "),HJ=a("a"),n6r=o("TFMobileBertForSequenceClassification"),s6r=o(" (MobileBERT model)"),l6r=l(),B5=a("li"),zEe=a("strong"),i6r=o("mpnet"),d6r=o(" \u2014 "),UJ=a("a"),c6r=o("TFMPNetForSequenceClassification"),m6r=o(" (MPNet model)"),f6r=l(),I5=a("li"),QEe=a("strong"),g6r=o("openai-gpt"),h6r=o(" \u2014 "),JJ=a("a"),u6r=o("TFOpenAIGPTForSequenceClassification"),p6r=o(" (OpenAI GPT model)"),_6r=l(),N5=a("li"),WEe=a("strong"),b6r=o("rembert"),v6r=o(" \u2014 "),YJ=a("a"),F6r=o("TFRemBertForSequenceClassification"),T6r=o(" (RemBERT model)"),M6r=l(),q5=a("li"),HEe=a("strong"),E6r=o("roberta"),C6r=o(" \u2014 "),KJ=a("a"),w6r=o("TFRobertaForSequenceClassification"),A6r=o(" (RoBERTa model)"),L6r=l(),j5=a("li"),UEe=a("strong"),y6r=o("roformer"),x6r=o(" \u2014 "),ZJ=a("a"),$6r=o("TFRoFormerForSequenceClassification"),k6r=o(" (RoFormer model)"),S6r=l(),D5=a("li"),JEe=a("strong"),R6r=o("tapas"),P6r=o(" \u2014 "),eY=a("a"),B6r=o("TFTapasForSequenceClassification"),I6r=o(" (TAPAS model)"),N6r=l(),G5=a("li"),YEe=a("strong"),q6r=o("transfo-xl"),j6r=o(" \u2014 "),oY=a("a"),D6r=o("TFTransfoXLForSequenceClassification"),G6r=o(" (Transformer-XL model)"),O6r=l(),O5=a("li"),KEe=a("strong"),V6r=o("xlm"),X6r=o(" \u2014 "),rY=a("a"),z6r=o("TFXLMForSequenceClassification"),Q6r=o(" (XLM model)"),W6r=l(),V5=a("li"),ZEe=a("strong"),H6r=o("xlm-roberta"),U6r=o(" \u2014 "),tY=a("a"),J6r=o("TFXLMRobertaForSequenceClassification"),Y6r=o(" (XLM-RoBERTa model)"),K6r=l(),X5=a("li"),e4e=a("strong"),Z6r=o("xlnet"),eLr=o(" \u2014 "),aY=a("a"),oLr=o("TFXLNetForSequenceClassification"),rLr=o(" (XLNet model)"),tLr=l(),F(z5.$$.fragment),sVe=l(),Tc=a("h2"),Q5=a("a"),o4e=a("span"),F(J9.$$.fragment),aLr=l(),r4e=a("span"),nLr=o("TFAutoModelForMultipleChoice"),lVe=l(),lr=a("div"),F(Y9.$$.fragment),sLr=l(),Mc=a("p"),lLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=a("a"),iLr=o("from_pretrained()"),dLr=o(" class method or the "),sY=a("a"),cLr=o("from_config()"),mLr=o(` class
method.`),fLr=l(),K9=a("p"),gLr=o("This class cannot be instantiated directly using "),t4e=a("code"),hLr=o("__init__()"),uLr=o(" (throws an error)."),pLr=l(),Nt=a("div"),F(Z9.$$.fragment),_Lr=l(),a4e=a("p"),bLr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vLr=l(),Ec=a("p"),FLr=o(`Note:
Loading a model from its configuration file does `),n4e=a("strong"),TLr=o("not"),MLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=a("a"),ELr=o("from_pretrained()"),CLr=o(" to load the model weights."),wLr=l(),F(W5.$$.fragment),ALr=l(),Br=a("div"),F(ex.$$.fragment),LLr=l(),s4e=a("p"),yLr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xLr=l(),gn=a("p"),$Lr=o("The model class to instantiate is selected based on the "),l4e=a("code"),kLr=o("model_type"),SLr=o(` property of the config object (either
passed as an argument or loaded from `),i4e=a("code"),RLr=o("pretrained_model_name_or_path"),PLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d4e=a("code"),BLr=o("pretrained_model_name_or_path"),ILr=o(":"),NLr=l(),pe=a("ul"),H5=a("li"),c4e=a("strong"),qLr=o("albert"),jLr=o(" \u2014 "),iY=a("a"),DLr=o("TFAlbertForMultipleChoice"),GLr=o(" (ALBERT model)"),OLr=l(),U5=a("li"),m4e=a("strong"),VLr=o("bert"),XLr=o(" \u2014 "),dY=a("a"),zLr=o("TFBertForMultipleChoice"),QLr=o(" (BERT model)"),WLr=l(),J5=a("li"),f4e=a("strong"),HLr=o("camembert"),ULr=o(" \u2014 "),cY=a("a"),JLr=o("TFCamembertForMultipleChoice"),YLr=o(" (CamemBERT model)"),KLr=l(),Y5=a("li"),g4e=a("strong"),ZLr=o("convbert"),eyr=o(" \u2014 "),mY=a("a"),oyr=o("TFConvBertForMultipleChoice"),ryr=o(" (ConvBERT model)"),tyr=l(),K5=a("li"),h4e=a("strong"),ayr=o("distilbert"),nyr=o(" \u2014 "),fY=a("a"),syr=o("TFDistilBertForMultipleChoice"),lyr=o(" (DistilBERT model)"),iyr=l(),Z5=a("li"),u4e=a("strong"),dyr=o("electra"),cyr=o(" \u2014 "),gY=a("a"),myr=o("TFElectraForMultipleChoice"),fyr=o(" (ELECTRA model)"),gyr=l(),e3=a("li"),p4e=a("strong"),hyr=o("flaubert"),uyr=o(" \u2014 "),hY=a("a"),pyr=o("TFFlaubertForMultipleChoice"),_yr=o(" (FlauBERT model)"),byr=l(),o3=a("li"),_4e=a("strong"),vyr=o("funnel"),Fyr=o(" \u2014 "),uY=a("a"),Tyr=o("TFFunnelForMultipleChoice"),Myr=o(" (Funnel Transformer model)"),Eyr=l(),r3=a("li"),b4e=a("strong"),Cyr=o("longformer"),wyr=o(" \u2014 "),pY=a("a"),Ayr=o("TFLongformerForMultipleChoice"),Lyr=o(" (Longformer model)"),yyr=l(),t3=a("li"),v4e=a("strong"),xyr=o("mobilebert"),$yr=o(" \u2014 "),_Y=a("a"),kyr=o("TFMobileBertForMultipleChoice"),Syr=o(" (MobileBERT model)"),Ryr=l(),a3=a("li"),F4e=a("strong"),Pyr=o("mpnet"),Byr=o(" \u2014 "),bY=a("a"),Iyr=o("TFMPNetForMultipleChoice"),Nyr=o(" (MPNet model)"),qyr=l(),n3=a("li"),T4e=a("strong"),jyr=o("rembert"),Dyr=o(" \u2014 "),vY=a("a"),Gyr=o("TFRemBertForMultipleChoice"),Oyr=o(" (RemBERT model)"),Vyr=l(),s3=a("li"),M4e=a("strong"),Xyr=o("roberta"),zyr=o(" \u2014 "),FY=a("a"),Qyr=o("TFRobertaForMultipleChoice"),Wyr=o(" (RoBERTa model)"),Hyr=l(),l3=a("li"),E4e=a("strong"),Uyr=o("roformer"),Jyr=o(" \u2014 "),TY=a("a"),Yyr=o("TFRoFormerForMultipleChoice"),Kyr=o(" (RoFormer model)"),Zyr=l(),i3=a("li"),C4e=a("strong"),e7r=o("xlm"),o7r=o(" \u2014 "),MY=a("a"),r7r=o("TFXLMForMultipleChoice"),t7r=o(" (XLM model)"),a7r=l(),d3=a("li"),w4e=a("strong"),n7r=o("xlm-roberta"),s7r=o(" \u2014 "),EY=a("a"),l7r=o("TFXLMRobertaForMultipleChoice"),i7r=o(" (XLM-RoBERTa model)"),d7r=l(),c3=a("li"),A4e=a("strong"),c7r=o("xlnet"),m7r=o(" \u2014 "),CY=a("a"),f7r=o("TFXLNetForMultipleChoice"),g7r=o(" (XLNet model)"),h7r=l(),F(m3.$$.fragment),iVe=l(),Cc=a("h2"),f3=a("a"),L4e=a("span"),F(ox.$$.fragment),u7r=l(),y4e=a("span"),p7r=o("TFAutoModelForNextSentencePrediction"),dVe=l(),ir=a("div"),F(rx.$$.fragment),_7r=l(),wc=a("p"),b7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=a("a"),v7r=o("from_pretrained()"),F7r=o(" class method or the "),AY=a("a"),T7r=o("from_config()"),M7r=o(` class
method.`),E7r=l(),tx=a("p"),C7r=o("This class cannot be instantiated directly using "),x4e=a("code"),w7r=o("__init__()"),A7r=o(" (throws an error)."),L7r=l(),qt=a("div"),F(ax.$$.fragment),y7r=l(),$4e=a("p"),x7r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$7r=l(),Ac=a("p"),k7r=o(`Note:
Loading a model from its configuration file does `),k4e=a("strong"),S7r=o("not"),R7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),P7r=o("from_pretrained()"),B7r=o(" to load the model weights."),I7r=l(),F(g3.$$.fragment),N7r=l(),Ir=a("div"),F(nx.$$.fragment),q7r=l(),S4e=a("p"),j7r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),D7r=l(),hn=a("p"),G7r=o("The model class to instantiate is selected based on the "),R4e=a("code"),O7r=o("model_type"),V7r=o(` property of the config object (either
passed as an argument or loaded from `),P4e=a("code"),X7r=o("pretrained_model_name_or_path"),z7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=a("code"),Q7r=o("pretrained_model_name_or_path"),W7r=o(":"),H7r=l(),sx=a("ul"),h3=a("li"),I4e=a("strong"),U7r=o("bert"),J7r=o(" \u2014 "),yY=a("a"),Y7r=o("TFBertForNextSentencePrediction"),K7r=o(" (BERT model)"),Z7r=l(),u3=a("li"),N4e=a("strong"),e8r=o("mobilebert"),o8r=o(" \u2014 "),xY=a("a"),r8r=o("TFMobileBertForNextSentencePrediction"),t8r=o(" (MobileBERT model)"),a8r=l(),F(p3.$$.fragment),cVe=l(),Lc=a("h2"),_3=a("a"),q4e=a("span"),F(lx.$$.fragment),n8r=l(),j4e=a("span"),s8r=o("TFAutoModelForTableQuestionAnswering"),mVe=l(),dr=a("div"),F(ix.$$.fragment),l8r=l(),yc=a("p"),i8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=a("a"),d8r=o("from_pretrained()"),c8r=o(" class method or the "),kY=a("a"),m8r=o("from_config()"),f8r=o(` class
method.`),g8r=l(),dx=a("p"),h8r=o("This class cannot be instantiated directly using "),D4e=a("code"),u8r=o("__init__()"),p8r=o(" (throws an error)."),_8r=l(),jt=a("div"),F(cx.$$.fragment),b8r=l(),G4e=a("p"),v8r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),F8r=l(),xc=a("p"),T8r=o(`Note:
Loading a model from its configuration file does `),O4e=a("strong"),M8r=o("not"),E8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),C8r=o("from_pretrained()"),w8r=o(" to load the model weights."),A8r=l(),F(b3.$$.fragment),L8r=l(),Nr=a("div"),F(mx.$$.fragment),y8r=l(),V4e=a("p"),x8r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),$8r=l(),un=a("p"),k8r=o("The model class to instantiate is selected based on the "),X4e=a("code"),S8r=o("model_type"),R8r=o(` property of the config object (either
passed as an argument or loaded from `),z4e=a("code"),P8r=o("pretrained_model_name_or_path"),B8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q4e=a("code"),I8r=o("pretrained_model_name_or_path"),N8r=o(":"),q8r=l(),W4e=a("ul"),v3=a("li"),H4e=a("strong"),j8r=o("tapas"),D8r=o(" \u2014 "),RY=a("a"),G8r=o("TFTapasForQuestionAnswering"),O8r=o(" (TAPAS model)"),V8r=l(),F(F3.$$.fragment),fVe=l(),$c=a("h2"),T3=a("a"),U4e=a("span"),F(fx.$$.fragment),X8r=l(),J4e=a("span"),z8r=o("TFAutoModelForTokenClassification"),gVe=l(),cr=a("div"),F(gx.$$.fragment),Q8r=l(),kc=a("p"),W8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=a("a"),H8r=o("from_pretrained()"),U8r=o(" class method or the "),BY=a("a"),J8r=o("from_config()"),Y8r=o(` class
method.`),K8r=l(),hx=a("p"),Z8r=o("This class cannot be instantiated directly using "),Y4e=a("code"),e9r=o("__init__()"),o9r=o(" (throws an error)."),r9r=l(),Dt=a("div"),F(ux.$$.fragment),t9r=l(),K4e=a("p"),a9r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),n9r=l(),Sc=a("p"),s9r=o(`Note:
Loading a model from its configuration file does `),Z4e=a("strong"),l9r=o("not"),i9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),d9r=o("from_pretrained()"),c9r=o(" to load the model weights."),m9r=l(),F(M3.$$.fragment),f9r=l(),qr=a("div"),F(px.$$.fragment),g9r=l(),eCe=a("p"),h9r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),u9r=l(),pn=a("p"),p9r=o("The model class to instantiate is selected based on the "),oCe=a("code"),_9r=o("model_type"),b9r=o(` property of the config object (either
passed as an argument or loaded from `),rCe=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tCe=a("code"),T9r=o("pretrained_model_name_or_path"),M9r=o(":"),E9r=l(),de=a("ul"),E3=a("li"),aCe=a("strong"),C9r=o("albert"),w9r=o(" \u2014 "),NY=a("a"),A9r=o("TFAlbertForTokenClassification"),L9r=o(" (ALBERT model)"),y9r=l(),C3=a("li"),nCe=a("strong"),x9r=o("bert"),$9r=o(" \u2014 "),qY=a("a"),k9r=o("TFBertForTokenClassification"),S9r=o(" (BERT model)"),R9r=l(),w3=a("li"),sCe=a("strong"),P9r=o("camembert"),B9r=o(" \u2014 "),jY=a("a"),I9r=o("TFCamembertForTokenClassification"),N9r=o(" (CamemBERT model)"),q9r=l(),A3=a("li"),lCe=a("strong"),j9r=o("convbert"),D9r=o(" \u2014 "),DY=a("a"),G9r=o("TFConvBertForTokenClassification"),O9r=o(" (ConvBERT model)"),V9r=l(),L3=a("li"),iCe=a("strong"),X9r=o("deberta"),z9r=o(" \u2014 "),GY=a("a"),Q9r=o("TFDebertaForTokenClassification"),W9r=o(" (DeBERTa model)"),H9r=l(),y3=a("li"),dCe=a("strong"),U9r=o("deberta-v2"),J9r=o(" \u2014 "),OY=a("a"),Y9r=o("TFDebertaV2ForTokenClassification"),K9r=o(" (DeBERTa-v2 model)"),Z9r=l(),x3=a("li"),cCe=a("strong"),exr=o("distilbert"),oxr=o(" \u2014 "),VY=a("a"),rxr=o("TFDistilBertForTokenClassification"),txr=o(" (DistilBERT model)"),axr=l(),$3=a("li"),mCe=a("strong"),nxr=o("electra"),sxr=o(" \u2014 "),XY=a("a"),lxr=o("TFElectraForTokenClassification"),ixr=o(" (ELECTRA model)"),dxr=l(),k3=a("li"),fCe=a("strong"),cxr=o("flaubert"),mxr=o(" \u2014 "),zY=a("a"),fxr=o("TFFlaubertForTokenClassification"),gxr=o(" (FlauBERT model)"),hxr=l(),S3=a("li"),gCe=a("strong"),uxr=o("funnel"),pxr=o(" \u2014 "),QY=a("a"),_xr=o("TFFunnelForTokenClassification"),bxr=o(" (Funnel Transformer model)"),vxr=l(),R3=a("li"),hCe=a("strong"),Fxr=o("layoutlm"),Txr=o(" \u2014 "),WY=a("a"),Mxr=o("TFLayoutLMForTokenClassification"),Exr=o(" (LayoutLM model)"),Cxr=l(),P3=a("li"),uCe=a("strong"),wxr=o("longformer"),Axr=o(" \u2014 "),HY=a("a"),Lxr=o("TFLongformerForTokenClassification"),yxr=o(" (Longformer model)"),xxr=l(),B3=a("li"),pCe=a("strong"),$xr=o("mobilebert"),kxr=o(" \u2014 "),UY=a("a"),Sxr=o("TFMobileBertForTokenClassification"),Rxr=o(" (MobileBERT model)"),Pxr=l(),I3=a("li"),_Ce=a("strong"),Bxr=o("mpnet"),Ixr=o(" \u2014 "),JY=a("a"),Nxr=o("TFMPNetForTokenClassification"),qxr=o(" (MPNet model)"),jxr=l(),N3=a("li"),bCe=a("strong"),Dxr=o("rembert"),Gxr=o(" \u2014 "),YY=a("a"),Oxr=o("TFRemBertForTokenClassification"),Vxr=o(" (RemBERT model)"),Xxr=l(),q3=a("li"),vCe=a("strong"),zxr=o("roberta"),Qxr=o(" \u2014 "),KY=a("a"),Wxr=o("TFRobertaForTokenClassification"),Hxr=o(" (RoBERTa model)"),Uxr=l(),j3=a("li"),FCe=a("strong"),Jxr=o("roformer"),Yxr=o(" \u2014 "),ZY=a("a"),Kxr=o("TFRoFormerForTokenClassification"),Zxr=o(" (RoFormer model)"),e$r=l(),D3=a("li"),TCe=a("strong"),o$r=o("xlm"),r$r=o(" \u2014 "),eK=a("a"),t$r=o("TFXLMForTokenClassification"),a$r=o(" (XLM model)"),n$r=l(),G3=a("li"),MCe=a("strong"),s$r=o("xlm-roberta"),l$r=o(" \u2014 "),oK=a("a"),i$r=o("TFXLMRobertaForTokenClassification"),d$r=o(" (XLM-RoBERTa model)"),c$r=l(),O3=a("li"),ECe=a("strong"),m$r=o("xlnet"),f$r=o(" \u2014 "),rK=a("a"),g$r=o("TFXLNetForTokenClassification"),h$r=o(" (XLNet model)"),u$r=l(),F(V3.$$.fragment),hVe=l(),Rc=a("h2"),X3=a("a"),CCe=a("span"),F(_x.$$.fragment),p$r=l(),wCe=a("span"),_$r=o("TFAutoModelForQuestionAnswering"),uVe=l(),mr=a("div"),F(bx.$$.fragment),b$r=l(),Pc=a("p"),v$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=a("a"),F$r=o("from_pretrained()"),T$r=o(" class method or the "),aK=a("a"),M$r=o("from_config()"),E$r=o(` class
method.`),C$r=l(),vx=a("p"),w$r=o("This class cannot be instantiated directly using "),ACe=a("code"),A$r=o("__init__()"),L$r=o(" (throws an error)."),y$r=l(),Gt=a("div"),F(Fx.$$.fragment),x$r=l(),LCe=a("p"),$$r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k$r=l(),Bc=a("p"),S$r=o(`Note:
Loading a model from its configuration file does `),yCe=a("strong"),R$r=o("not"),P$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),B$r=o("from_pretrained()"),I$r=o(" to load the model weights."),N$r=l(),F(z3.$$.fragment),q$r=l(),jr=a("div"),F(Tx.$$.fragment),j$r=l(),xCe=a("p"),D$r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G$r=l(),_n=a("p"),O$r=o("The model class to instantiate is selected based on the "),$Ce=a("code"),V$r=o("model_type"),X$r=o(` property of the config object (either
passed as an argument or loaded from `),kCe=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SCe=a("code"),W$r=o("pretrained_model_name_or_path"),H$r=o(":"),U$r=l(),ce=a("ul"),Q3=a("li"),RCe=a("strong"),J$r=o("albert"),Y$r=o(" \u2014 "),sK=a("a"),K$r=o("TFAlbertForQuestionAnswering"),Z$r=o(" (ALBERT model)"),ekr=l(),W3=a("li"),PCe=a("strong"),okr=o("bert"),rkr=o(" \u2014 "),lK=a("a"),tkr=o("TFBertForQuestionAnswering"),akr=o(" (BERT model)"),nkr=l(),H3=a("li"),BCe=a("strong"),skr=o("camembert"),lkr=o(" \u2014 "),iK=a("a"),ikr=o("TFCamembertForQuestionAnswering"),dkr=o(" (CamemBERT model)"),ckr=l(),U3=a("li"),ICe=a("strong"),mkr=o("convbert"),fkr=o(" \u2014 "),dK=a("a"),gkr=o("TFConvBertForQuestionAnswering"),hkr=o(" (ConvBERT model)"),ukr=l(),J3=a("li"),NCe=a("strong"),pkr=o("deberta"),_kr=o(" \u2014 "),cK=a("a"),bkr=o("TFDebertaForQuestionAnswering"),vkr=o(" (DeBERTa model)"),Fkr=l(),Y3=a("li"),qCe=a("strong"),Tkr=o("deberta-v2"),Mkr=o(" \u2014 "),mK=a("a"),Ekr=o("TFDebertaV2ForQuestionAnswering"),Ckr=o(" (DeBERTa-v2 model)"),wkr=l(),K3=a("li"),jCe=a("strong"),Akr=o("distilbert"),Lkr=o(" \u2014 "),fK=a("a"),ykr=o("TFDistilBertForQuestionAnswering"),xkr=o(" (DistilBERT model)"),$kr=l(),Z3=a("li"),DCe=a("strong"),kkr=o("electra"),Skr=o(" \u2014 "),gK=a("a"),Rkr=o("TFElectraForQuestionAnswering"),Pkr=o(" (ELECTRA model)"),Bkr=l(),e0=a("li"),GCe=a("strong"),Ikr=o("flaubert"),Nkr=o(" \u2014 "),hK=a("a"),qkr=o("TFFlaubertForQuestionAnsweringSimple"),jkr=o(" (FlauBERT model)"),Dkr=l(),o0=a("li"),OCe=a("strong"),Gkr=o("funnel"),Okr=o(" \u2014 "),uK=a("a"),Vkr=o("TFFunnelForQuestionAnswering"),Xkr=o(" (Funnel Transformer model)"),zkr=l(),r0=a("li"),VCe=a("strong"),Qkr=o("gptj"),Wkr=o(" \u2014 "),pK=a("a"),Hkr=o("TFGPTJForQuestionAnswering"),Ukr=o(" (GPT-J model)"),Jkr=l(),t0=a("li"),XCe=a("strong"),Ykr=o("longformer"),Kkr=o(" \u2014 "),_K=a("a"),Zkr=o("TFLongformerForQuestionAnswering"),eSr=o(" (Longformer model)"),oSr=l(),a0=a("li"),zCe=a("strong"),rSr=o("mobilebert"),tSr=o(" \u2014 "),bK=a("a"),aSr=o("TFMobileBertForQuestionAnswering"),nSr=o(" (MobileBERT model)"),sSr=l(),n0=a("li"),QCe=a("strong"),lSr=o("mpnet"),iSr=o(" \u2014 "),vK=a("a"),dSr=o("TFMPNetForQuestionAnswering"),cSr=o(" (MPNet model)"),mSr=l(),s0=a("li"),WCe=a("strong"),fSr=o("rembert"),gSr=o(" \u2014 "),FK=a("a"),hSr=o("TFRemBertForQuestionAnswering"),uSr=o(" (RemBERT model)"),pSr=l(),l0=a("li"),HCe=a("strong"),_Sr=o("roberta"),bSr=o(" \u2014 "),TK=a("a"),vSr=o("TFRobertaForQuestionAnswering"),FSr=o(" (RoBERTa model)"),TSr=l(),i0=a("li"),UCe=a("strong"),MSr=o("roformer"),ESr=o(" \u2014 "),MK=a("a"),CSr=o("TFRoFormerForQuestionAnswering"),wSr=o(" (RoFormer model)"),ASr=l(),d0=a("li"),JCe=a("strong"),LSr=o("xlm"),ySr=o(" \u2014 "),EK=a("a"),xSr=o("TFXLMForQuestionAnsweringSimple"),$Sr=o(" (XLM model)"),kSr=l(),c0=a("li"),YCe=a("strong"),SSr=o("xlm-roberta"),RSr=o(" \u2014 "),CK=a("a"),PSr=o("TFXLMRobertaForQuestionAnswering"),BSr=o(" (XLM-RoBERTa model)"),ISr=l(),m0=a("li"),KCe=a("strong"),NSr=o("xlnet"),qSr=o(" \u2014 "),wK=a("a"),jSr=o("TFXLNetForQuestionAnsweringSimple"),DSr=o(" (XLNet model)"),GSr=l(),F(f0.$$.fragment),pVe=l(),Ic=a("h2"),g0=a("a"),ZCe=a("span"),F(Mx.$$.fragment),OSr=l(),e5e=a("span"),VSr=o("TFAutoModelForVision2Seq"),_Ve=l(),fr=a("div"),F(Ex.$$.fragment),XSr=l(),Nc=a("p"),zSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=a("a"),QSr=o("from_pretrained()"),WSr=o(" class method or the "),LK=a("a"),HSr=o("from_config()"),USr=o(` class
method.`),JSr=l(),Cx=a("p"),YSr=o("This class cannot be instantiated directly using "),o5e=a("code"),KSr=o("__init__()"),ZSr=o(" (throws an error)."),eRr=l(),Ot=a("div"),F(wx.$$.fragment),oRr=l(),r5e=a("p"),rRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tRr=l(),qc=a("p"),aRr=o(`Note:
Loading a model from its configuration file does `),t5e=a("strong"),nRr=o("not"),sRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),lRr=o("from_pretrained()"),iRr=o(" to load the model weights."),dRr=l(),F(h0.$$.fragment),cRr=l(),Dr=a("div"),F(Ax.$$.fragment),mRr=l(),a5e=a("p"),fRr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gRr=l(),bn=a("p"),hRr=o("The model class to instantiate is selected based on the "),n5e=a("code"),uRr=o("model_type"),pRr=o(` property of the config object (either
passed as an argument or loaded from `),s5e=a("code"),_Rr=o("pretrained_model_name_or_path"),bRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l5e=a("code"),vRr=o("pretrained_model_name_or_path"),FRr=o(":"),TRr=l(),i5e=a("ul"),u0=a("li"),d5e=a("strong"),MRr=o("vision-encoder-decoder"),ERr=o(" \u2014 "),xK=a("a"),CRr=o("TFVisionEncoderDecoderModel"),wRr=o(" (Vision Encoder decoder model)"),ARr=l(),F(p0.$$.fragment),bVe=l(),jc=a("h2"),_0=a("a"),c5e=a("span"),F(Lx.$$.fragment),LRr=l(),m5e=a("span"),yRr=o("TFAutoModelForSpeechSeq2Seq"),vVe=l(),gr=a("div"),F(yx.$$.fragment),xRr=l(),Dc=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),kK=a("a"),RRr=o("from_config()"),PRr=o(` class
method.`),BRr=l(),xx=a("p"),IRr=o("This class cannot be instantiated directly using "),f5e=a("code"),NRr=o("__init__()"),qRr=o(" (throws an error)."),jRr=l(),Vt=a("div"),F($x.$$.fragment),DRr=l(),g5e=a("p"),GRr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ORr=l(),Gc=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),h5e=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),HRr=l(),F(b0.$$.fragment),URr=l(),Gr=a("div"),F(kx.$$.fragment),JRr=l(),u5e=a("p"),YRr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),KRr=l(),vn=a("p"),ZRr=o("The model class to instantiate is selected based on the "),p5e=a("code"),ePr=o("model_type"),oPr=o(` property of the config object (either
passed as an argument or loaded from `),_5e=a("code"),rPr=o("pretrained_model_name_or_path"),tPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b5e=a("code"),aPr=o("pretrained_model_name_or_path"),nPr=o(":"),sPr=l(),v5e=a("ul"),v0=a("li"),F5e=a("strong"),lPr=o("speech_to_text"),iPr=o(" \u2014 "),RK=a("a"),dPr=o("TFSpeech2TextForConditionalGeneration"),cPr=o(" (Speech2Text model)"),mPr=l(),F(F0.$$.fragment),FVe=l(),Oc=a("h2"),T0=a("a"),T5e=a("span"),F(Sx.$$.fragment),fPr=l(),M5e=a("span"),gPr=o("FlaxAutoModel"),TVe=l(),hr=a("div"),F(Rx.$$.fragment),hPr=l(),Vc=a("p"),uPr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=a("a"),pPr=o("from_pretrained()"),_Pr=o(" class method or the "),BK=a("a"),bPr=o("from_config()"),vPr=o(` class
method.`),FPr=l(),Px=a("p"),TPr=o("This class cannot be instantiated directly using "),E5e=a("code"),MPr=o("__init__()"),EPr=o(" (throws an error)."),CPr=l(),Xt=a("div"),F(Bx.$$.fragment),wPr=l(),C5e=a("p"),APr=o("Instantiates one of the base model classes of the library from a configuration."),LPr=l(),Xc=a("p"),yPr=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),xPr=o("not"),$Pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),kPr=o("from_pretrained()"),SPr=o(" to load the model weights."),RPr=l(),F(M0.$$.fragment),PPr=l(),Or=a("div"),F(Ix.$$.fragment),BPr=l(),A5e=a("p"),IPr=o("Instantiate one of the base model classes of the library from a pretrained model."),NPr=l(),Fn=a("p"),qPr=o("The model class to instantiate is selected based on the "),L5e=a("code"),jPr=o("model_type"),DPr=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),GPr=o("pretrained_model_name_or_path"),OPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),VPr=o("pretrained_model_name_or_path"),XPr=o(":"),zPr=l(),oe=a("ul"),E0=a("li"),$5e=a("strong"),QPr=o("albert"),WPr=o(" \u2014 "),NK=a("a"),HPr=o("FlaxAlbertModel"),UPr=o(" (ALBERT model)"),JPr=l(),C0=a("li"),k5e=a("strong"),YPr=o("bart"),KPr=o(" \u2014 "),qK=a("a"),ZPr=o("FlaxBartModel"),eBr=o(" (BART model)"),oBr=l(),w0=a("li"),S5e=a("strong"),rBr=o("beit"),tBr=o(" \u2014 "),jK=a("a"),aBr=o("FlaxBeitModel"),nBr=o(" (BEiT model)"),sBr=l(),A0=a("li"),R5e=a("strong"),lBr=o("bert"),iBr=o(" \u2014 "),DK=a("a"),dBr=o("FlaxBertModel"),cBr=o(" (BERT model)"),mBr=l(),L0=a("li"),P5e=a("strong"),fBr=o("big_bird"),gBr=o(" \u2014 "),GK=a("a"),hBr=o("FlaxBigBirdModel"),uBr=o(" (BigBird model)"),pBr=l(),y0=a("li"),B5e=a("strong"),_Br=o("blenderbot"),bBr=o(" \u2014 "),OK=a("a"),vBr=o("FlaxBlenderbotModel"),FBr=o(" (Blenderbot model)"),TBr=l(),x0=a("li"),I5e=a("strong"),MBr=o("blenderbot-small"),EBr=o(" \u2014 "),VK=a("a"),CBr=o("FlaxBlenderbotSmallModel"),wBr=o(" (BlenderbotSmall model)"),ABr=l(),$0=a("li"),N5e=a("strong"),LBr=o("clip"),yBr=o(" \u2014 "),XK=a("a"),xBr=o("FlaxCLIPModel"),$Br=o(" (CLIP model)"),kBr=l(),k0=a("li"),q5e=a("strong"),SBr=o("distilbert"),RBr=o(" \u2014 "),zK=a("a"),PBr=o("FlaxDistilBertModel"),BBr=o(" (DistilBERT model)"),IBr=l(),S0=a("li"),j5e=a("strong"),NBr=o("electra"),qBr=o(" \u2014 "),QK=a("a"),jBr=o("FlaxElectraModel"),DBr=o(" (ELECTRA model)"),GBr=l(),R0=a("li"),D5e=a("strong"),OBr=o("gpt2"),VBr=o(" \u2014 "),WK=a("a"),XBr=o("FlaxGPT2Model"),zBr=o(" (OpenAI GPT-2 model)"),QBr=l(),P0=a("li"),G5e=a("strong"),WBr=o("gpt_neo"),HBr=o(" \u2014 "),HK=a("a"),UBr=o("FlaxGPTNeoModel"),JBr=o(" (GPT Neo model)"),YBr=l(),B0=a("li"),O5e=a("strong"),KBr=o("gptj"),ZBr=o(" \u2014 "),UK=a("a"),eIr=o("FlaxGPTJModel"),oIr=o(" (GPT-J model)"),rIr=l(),I0=a("li"),V5e=a("strong"),tIr=o("longt5"),aIr=o(" \u2014 "),JK=a("a"),nIr=o("FlaxLongT5Model"),sIr=o(" (LongT5 model)"),lIr=l(),N0=a("li"),X5e=a("strong"),iIr=o("marian"),dIr=o(" \u2014 "),YK=a("a"),cIr=o("FlaxMarianModel"),mIr=o(" (Marian model)"),fIr=l(),q0=a("li"),z5e=a("strong"),gIr=o("mbart"),hIr=o(" \u2014 "),KK=a("a"),uIr=o("FlaxMBartModel"),pIr=o(" (mBART model)"),_Ir=l(),j0=a("li"),Q5e=a("strong"),bIr=o("mt5"),vIr=o(" \u2014 "),ZK=a("a"),FIr=o("FlaxMT5Model"),TIr=o(" (MT5 model)"),MIr=l(),D0=a("li"),W5e=a("strong"),EIr=o("opt"),CIr=o(" \u2014 "),eZ=a("a"),wIr=o("FlaxOPTModel"),AIr=o(" (OPT model)"),LIr=l(),G0=a("li"),H5e=a("strong"),yIr=o("pegasus"),xIr=o(" \u2014 "),oZ=a("a"),$Ir=o("FlaxPegasusModel"),kIr=o(" (Pegasus model)"),SIr=l(),O0=a("li"),U5e=a("strong"),RIr=o("roberta"),PIr=o(" \u2014 "),rZ=a("a"),BIr=o("FlaxRobertaModel"),IIr=o(" (RoBERTa model)"),NIr=l(),V0=a("li"),J5e=a("strong"),qIr=o("roformer"),jIr=o(" \u2014 "),tZ=a("a"),DIr=o("FlaxRoFormerModel"),GIr=o(" (RoFormer model)"),OIr=l(),X0=a("li"),Y5e=a("strong"),VIr=o("t5"),XIr=o(" \u2014 "),aZ=a("a"),zIr=o("FlaxT5Model"),QIr=o(" (T5 model)"),WIr=l(),z0=a("li"),K5e=a("strong"),HIr=o("vision-text-dual-encoder"),UIr=o(" \u2014 "),nZ=a("a"),JIr=o("FlaxVisionTextDualEncoderModel"),YIr=o(" (VisionTextDualEncoder model)"),KIr=l(),Q0=a("li"),Z5e=a("strong"),ZIr=o("vit"),eNr=o(" \u2014 "),sZ=a("a"),oNr=o("FlaxViTModel"),rNr=o(" (ViT model)"),tNr=l(),W0=a("li"),e3e=a("strong"),aNr=o("wav2vec2"),nNr=o(" \u2014 "),lZ=a("a"),sNr=o("FlaxWav2Vec2Model"),lNr=o(" (Wav2Vec2 model)"),iNr=l(),H0=a("li"),o3e=a("strong"),dNr=o("xglm"),cNr=o(" \u2014 "),iZ=a("a"),mNr=o("FlaxXGLMModel"),fNr=o(" (XGLM model)"),gNr=l(),U0=a("li"),r3e=a("strong"),hNr=o("xlm-roberta"),uNr=o(" \u2014 "),dZ=a("a"),pNr=o("FlaxXLMRobertaModel"),_Nr=o(" (XLM-RoBERTa model)"),bNr=l(),F(J0.$$.fragment),MVe=l(),zc=a("h2"),Y0=a("a"),t3e=a("span"),F(Nx.$$.fragment),vNr=l(),a3e=a("span"),FNr=o("FlaxAutoModelForCausalLM"),EVe=l(),ur=a("div"),F(qx.$$.fragment),TNr=l(),Qc=a("p"),MNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=a("a"),ENr=o("from_pretrained()"),CNr=o(" class method or the "),mZ=a("a"),wNr=o("from_config()"),ANr=o(` class
method.`),LNr=l(),jx=a("p"),yNr=o("This class cannot be instantiated directly using "),n3e=a("code"),xNr=o("__init__()"),$Nr=o(" (throws an error)."),kNr=l(),zt=a("div"),F(Dx.$$.fragment),SNr=l(),s3e=a("p"),RNr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),PNr=l(),Wc=a("p"),BNr=o(`Note:
Loading a model from its configuration file does `),l3e=a("strong"),INr=o("not"),NNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=a("a"),qNr=o("from_pretrained()"),jNr=o(" to load the model weights."),DNr=l(),F(K0.$$.fragment),GNr=l(),Vr=a("div"),F(Gx.$$.fragment),ONr=l(),i3e=a("p"),VNr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XNr=l(),Tn=a("p"),zNr=o("The model class to instantiate is selected based on the "),d3e=a("code"),QNr=o("model_type"),WNr=o(` property of the config object (either
passed as an argument or loaded from `),c3e=a("code"),HNr=o("pretrained_model_name_or_path"),UNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m3e=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(":"),KNr=l(),xe=a("ul"),Z0=a("li"),f3e=a("strong"),ZNr=o("bart"),eqr=o(" \u2014 "),gZ=a("a"),oqr=o("FlaxBartForCausalLM"),rqr=o(" (BART model)"),tqr=l(),ew=a("li"),g3e=a("strong"),aqr=o("bert"),nqr=o(" \u2014 "),hZ=a("a"),sqr=o("FlaxBertForCausalLM"),lqr=o(" (BERT model)"),iqr=l(),ow=a("li"),h3e=a("strong"),dqr=o("big_bird"),cqr=o(" \u2014 "),uZ=a("a"),mqr=o("FlaxBigBirdForCausalLM"),fqr=o(" (BigBird model)"),gqr=l(),rw=a("li"),u3e=a("strong"),hqr=o("electra"),uqr=o(" \u2014 "),pZ=a("a"),pqr=o("FlaxElectraForCausalLM"),_qr=o(" (ELECTRA model)"),bqr=l(),tw=a("li"),p3e=a("strong"),vqr=o("gpt2"),Fqr=o(" \u2014 "),_Z=a("a"),Tqr=o("FlaxGPT2LMHeadModel"),Mqr=o(" (OpenAI GPT-2 model)"),Eqr=l(),aw=a("li"),_3e=a("strong"),Cqr=o("gpt_neo"),wqr=o(" \u2014 "),bZ=a("a"),Aqr=o("FlaxGPTNeoForCausalLM"),Lqr=o(" (GPT Neo model)"),yqr=l(),nw=a("li"),b3e=a("strong"),xqr=o("gptj"),$qr=o(" \u2014 "),vZ=a("a"),kqr=o("FlaxGPTJForCausalLM"),Sqr=o(" (GPT-J model)"),Rqr=l(),sw=a("li"),v3e=a("strong"),Pqr=o("opt"),Bqr=o(" \u2014 "),FZ=a("a"),Iqr=o("FlaxOPTForCausalLM"),Nqr=o(" (OPT model)"),qqr=l(),lw=a("li"),F3e=a("strong"),jqr=o("roberta"),Dqr=o(" \u2014 "),TZ=a("a"),Gqr=o("FlaxRobertaForCausalLM"),Oqr=o(" (RoBERTa model)"),Vqr=l(),iw=a("li"),T3e=a("strong"),Xqr=o("xglm"),zqr=o(" \u2014 "),MZ=a("a"),Qqr=o("FlaxXGLMForCausalLM"),Wqr=o(" (XGLM model)"),Hqr=l(),F(dw.$$.fragment),CVe=l(),Hc=a("h2"),cw=a("a"),M3e=a("span"),F(Ox.$$.fragment),Uqr=l(),E3e=a("span"),Jqr=o("FlaxAutoModelForPreTraining"),wVe=l(),pr=a("div"),F(Vx.$$.fragment),Yqr=l(),Uc=a("p"),Kqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=a("a"),Zqr=o("from_pretrained()"),ejr=o(" class method or the "),CZ=a("a"),ojr=o("from_config()"),rjr=o(` class
method.`),tjr=l(),Xx=a("p"),ajr=o("This class cannot be instantiated directly using "),C3e=a("code"),njr=o("__init__()"),sjr=o(" (throws an error)."),ljr=l(),Qt=a("div"),F(zx.$$.fragment),ijr=l(),w3e=a("p"),djr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cjr=l(),Jc=a("p"),mjr=o(`Note:
Loading a model from its configuration file does `),A3e=a("strong"),fjr=o("not"),gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),hjr=o("from_pretrained()"),ujr=o(" to load the model weights."),pjr=l(),F(mw.$$.fragment),_jr=l(),Xr=a("div"),F(Qx.$$.fragment),bjr=l(),L3e=a("p"),vjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Fjr=l(),Mn=a("p"),Tjr=o("The model class to instantiate is selected based on the "),y3e=a("code"),Mjr=o("model_type"),Ejr=o(` property of the config object (either
passed as an argument or loaded from `),x3e=a("code"),Cjr=o("pretrained_model_name_or_path"),wjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$3e=a("code"),Ajr=o("pretrained_model_name_or_path"),Ljr=o(":"),yjr=l(),Ee=a("ul"),fw=a("li"),k3e=a("strong"),xjr=o("albert"),$jr=o(" \u2014 "),AZ=a("a"),kjr=o("FlaxAlbertForPreTraining"),Sjr=o(" (ALBERT model)"),Rjr=l(),gw=a("li"),S3e=a("strong"),Pjr=o("bart"),Bjr=o(" \u2014 "),LZ=a("a"),Ijr=o("FlaxBartForConditionalGeneration"),Njr=o(" (BART model)"),qjr=l(),hw=a("li"),R3e=a("strong"),jjr=o("bert"),Djr=o(" \u2014 "),yZ=a("a"),Gjr=o("FlaxBertForPreTraining"),Ojr=o(" (BERT model)"),Vjr=l(),uw=a("li"),P3e=a("strong"),Xjr=o("big_bird"),zjr=o(" \u2014 "),xZ=a("a"),Qjr=o("FlaxBigBirdForPreTraining"),Wjr=o(" (BigBird model)"),Hjr=l(),pw=a("li"),B3e=a("strong"),Ujr=o("electra"),Jjr=o(" \u2014 "),$Z=a("a"),Yjr=o("FlaxElectraForPreTraining"),Kjr=o(" (ELECTRA model)"),Zjr=l(),_w=a("li"),I3e=a("strong"),eDr=o("longt5"),oDr=o(" \u2014 "),kZ=a("a"),rDr=o("FlaxLongT5ForConditionalGeneration"),tDr=o(" (LongT5 model)"),aDr=l(),bw=a("li"),N3e=a("strong"),nDr=o("mbart"),sDr=o(" \u2014 "),SZ=a("a"),lDr=o("FlaxMBartForConditionalGeneration"),iDr=o(" (mBART model)"),dDr=l(),vw=a("li"),q3e=a("strong"),cDr=o("mt5"),mDr=o(" \u2014 "),RZ=a("a"),fDr=o("FlaxMT5ForConditionalGeneration"),gDr=o(" (MT5 model)"),hDr=l(),Fw=a("li"),j3e=a("strong"),uDr=o("roberta"),pDr=o(" \u2014 "),PZ=a("a"),_Dr=o("FlaxRobertaForMaskedLM"),bDr=o(" (RoBERTa model)"),vDr=l(),Tw=a("li"),D3e=a("strong"),FDr=o("roformer"),TDr=o(" \u2014 "),BZ=a("a"),MDr=o("FlaxRoFormerForMaskedLM"),EDr=o(" (RoFormer model)"),CDr=l(),Mw=a("li"),G3e=a("strong"),wDr=o("t5"),ADr=o(" \u2014 "),IZ=a("a"),LDr=o("FlaxT5ForConditionalGeneration"),yDr=o(" (T5 model)"),xDr=l(),Ew=a("li"),O3e=a("strong"),$Dr=o("wav2vec2"),kDr=o(" \u2014 "),NZ=a("a"),SDr=o("FlaxWav2Vec2ForPreTraining"),RDr=o(" (Wav2Vec2 model)"),PDr=l(),Cw=a("li"),V3e=a("strong"),BDr=o("xlm-roberta"),IDr=o(" \u2014 "),qZ=a("a"),NDr=o("FlaxXLMRobertaForMaskedLM"),qDr=o(" (XLM-RoBERTa model)"),jDr=l(),F(ww.$$.fragment),AVe=l(),Yc=a("h2"),Aw=a("a"),X3e=a("span"),F(Wx.$$.fragment),DDr=l(),z3e=a("span"),GDr=o("FlaxAutoModelForMaskedLM"),LVe=l(),_r=a("div"),F(Hx.$$.fragment),ODr=l(),Kc=a("p"),VDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=a("a"),XDr=o("from_pretrained()"),zDr=o(" class method or the "),DZ=a("a"),QDr=o("from_config()"),WDr=o(` class
method.`),HDr=l(),Ux=a("p"),UDr=o("This class cannot be instantiated directly using "),Q3e=a("code"),JDr=o("__init__()"),YDr=o(" (throws an error)."),KDr=l(),Wt=a("div"),F(Jx.$$.fragment),ZDr=l(),W3e=a("p"),eGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),oGr=l(),Zc=a("p"),rGr=o(`Note:
Loading a model from its configuration file does `),H3e=a("strong"),tGr=o("not"),aGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),nGr=o("from_pretrained()"),sGr=o(" to load the model weights."),lGr=l(),F(Lw.$$.fragment),iGr=l(),zr=a("div"),F(Yx.$$.fragment),dGr=l(),U3e=a("p"),cGr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),mGr=l(),En=a("p"),fGr=o("The model class to instantiate is selected based on the "),J3e=a("code"),gGr=o("model_type"),hGr=o(` property of the config object (either
passed as an argument or loaded from `),Y3e=a("code"),uGr=o("pretrained_model_name_or_path"),pGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K3e=a("code"),_Gr=o("pretrained_model_name_or_path"),bGr=o(":"),vGr=l(),$e=a("ul"),yw=a("li"),Z3e=a("strong"),FGr=o("albert"),TGr=o(" \u2014 "),OZ=a("a"),MGr=o("FlaxAlbertForMaskedLM"),EGr=o(" (ALBERT model)"),CGr=l(),xw=a("li"),e0e=a("strong"),wGr=o("bart"),AGr=o(" \u2014 "),VZ=a("a"),LGr=o("FlaxBartForConditionalGeneration"),yGr=o(" (BART model)"),xGr=l(),$w=a("li"),o0e=a("strong"),$Gr=o("bert"),kGr=o(" \u2014 "),XZ=a("a"),SGr=o("FlaxBertForMaskedLM"),RGr=o(" (BERT model)"),PGr=l(),kw=a("li"),r0e=a("strong"),BGr=o("big_bird"),IGr=o(" \u2014 "),zZ=a("a"),NGr=o("FlaxBigBirdForMaskedLM"),qGr=o(" (BigBird model)"),jGr=l(),Sw=a("li"),t0e=a("strong"),DGr=o("distilbert"),GGr=o(" \u2014 "),QZ=a("a"),OGr=o("FlaxDistilBertForMaskedLM"),VGr=o(" (DistilBERT model)"),XGr=l(),Rw=a("li"),a0e=a("strong"),zGr=o("electra"),QGr=o(" \u2014 "),WZ=a("a"),WGr=o("FlaxElectraForMaskedLM"),HGr=o(" (ELECTRA model)"),UGr=l(),Pw=a("li"),n0e=a("strong"),JGr=o("mbart"),YGr=o(" \u2014 "),HZ=a("a"),KGr=o("FlaxMBartForConditionalGeneration"),ZGr=o(" (mBART model)"),eOr=l(),Bw=a("li"),s0e=a("strong"),oOr=o("roberta"),rOr=o(" \u2014 "),UZ=a("a"),tOr=o("FlaxRobertaForMaskedLM"),aOr=o(" (RoBERTa model)"),nOr=l(),Iw=a("li"),l0e=a("strong"),sOr=o("roformer"),lOr=o(" \u2014 "),JZ=a("a"),iOr=o("FlaxRoFormerForMaskedLM"),dOr=o(" (RoFormer model)"),cOr=l(),Nw=a("li"),i0e=a("strong"),mOr=o("xlm-roberta"),fOr=o(" \u2014 "),YZ=a("a"),gOr=o("FlaxXLMRobertaForMaskedLM"),hOr=o(" (XLM-RoBERTa model)"),uOr=l(),F(qw.$$.fragment),yVe=l(),em=a("h2"),jw=a("a"),d0e=a("span"),F(Kx.$$.fragment),pOr=l(),c0e=a("span"),_Or=o("FlaxAutoModelForSeq2SeqLM"),xVe=l(),br=a("div"),F(Zx.$$.fragment),bOr=l(),om=a("p"),vOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" class method or the "),ZZ=a("a"),MOr=o("from_config()"),EOr=o(` class
method.`),COr=l(),e$=a("p"),wOr=o("This class cannot be instantiated directly using "),m0e=a("code"),AOr=o("__init__()"),LOr=o(" (throws an error)."),yOr=l(),Ht=a("div"),F(o$.$$.fragment),xOr=l(),f0e=a("p"),$Or=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),kOr=l(),rm=a("p"),SOr=o(`Note:
Loading a model from its configuration file does `),g0e=a("strong"),ROr=o("not"),POr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=a("a"),BOr=o("from_pretrained()"),IOr=o(" to load the model weights."),NOr=l(),F(Dw.$$.fragment),qOr=l(),Qr=a("div"),F(r$.$$.fragment),jOr=l(),h0e=a("p"),DOr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),GOr=l(),Cn=a("p"),OOr=o("The model class to instantiate is selected based on the "),u0e=a("code"),VOr=o("model_type"),XOr=o(` property of the config object (either
passed as an argument or loaded from `),p0e=a("code"),zOr=o("pretrained_model_name_or_path"),QOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=a("code"),WOr=o("pretrained_model_name_or_path"),HOr=o(":"),UOr=l(),ke=a("ul"),Gw=a("li"),b0e=a("strong"),JOr=o("bart"),YOr=o(" \u2014 "),oee=a("a"),KOr=o("FlaxBartForConditionalGeneration"),ZOr=o(" (BART model)"),eVr=l(),Ow=a("li"),v0e=a("strong"),oVr=o("blenderbot"),rVr=o(" \u2014 "),ree=a("a"),tVr=o("FlaxBlenderbotForConditionalGeneration"),aVr=o(" (Blenderbot model)"),nVr=l(),Vw=a("li"),F0e=a("strong"),sVr=o("blenderbot-small"),lVr=o(" \u2014 "),tee=a("a"),iVr=o("FlaxBlenderbotSmallForConditionalGeneration"),dVr=o(" (BlenderbotSmall model)"),cVr=l(),Xw=a("li"),T0e=a("strong"),mVr=o("encoder-decoder"),fVr=o(" \u2014 "),aee=a("a"),gVr=o("FlaxEncoderDecoderModel"),hVr=o(" (Encoder decoder model)"),uVr=l(),zw=a("li"),M0e=a("strong"),pVr=o("longt5"),_Vr=o(" \u2014 "),nee=a("a"),bVr=o("FlaxLongT5ForConditionalGeneration"),vVr=o(" (LongT5 model)"),FVr=l(),Qw=a("li"),E0e=a("strong"),TVr=o("marian"),MVr=o(" \u2014 "),see=a("a"),EVr=o("FlaxMarianMTModel"),CVr=o(" (Marian model)"),wVr=l(),Ww=a("li"),C0e=a("strong"),AVr=o("mbart"),LVr=o(" \u2014 "),lee=a("a"),yVr=o("FlaxMBartForConditionalGeneration"),xVr=o(" (mBART model)"),$Vr=l(),Hw=a("li"),w0e=a("strong"),kVr=o("mt5"),SVr=o(" \u2014 "),iee=a("a"),RVr=o("FlaxMT5ForConditionalGeneration"),PVr=o(" (MT5 model)"),BVr=l(),Uw=a("li"),A0e=a("strong"),IVr=o("pegasus"),NVr=o(" \u2014 "),dee=a("a"),qVr=o("FlaxPegasusForConditionalGeneration"),jVr=o(" (Pegasus model)"),DVr=l(),Jw=a("li"),L0e=a("strong"),GVr=o("t5"),OVr=o(" \u2014 "),cee=a("a"),VVr=o("FlaxT5ForConditionalGeneration"),XVr=o(" (T5 model)"),zVr=l(),F(Yw.$$.fragment),$Ve=l(),tm=a("h2"),Kw=a("a"),y0e=a("span"),F(t$.$$.fragment),QVr=l(),x0e=a("span"),WVr=o("FlaxAutoModelForSequenceClassification"),kVe=l(),vr=a("div"),F(a$.$$.fragment),HVr=l(),am=a("p"),UVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),mee=a("a"),JVr=o("from_pretrained()"),YVr=o(" class method or the "),fee=a("a"),KVr=o("from_config()"),ZVr=o(` class
method.`),eXr=l(),n$=a("p"),oXr=o("This class cannot be instantiated directly using "),$0e=a("code"),rXr=o("__init__()"),tXr=o(" (throws an error)."),aXr=l(),Ut=a("div"),F(s$.$$.fragment),nXr=l(),k0e=a("p"),sXr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lXr=l(),nm=a("p"),iXr=o(`Note:
Loading a model from its configuration file does `),S0e=a("strong"),dXr=o("not"),cXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),mXr=o("from_pretrained()"),fXr=o(" to load the model weights."),gXr=l(),F(Zw.$$.fragment),hXr=l(),Wr=a("div"),F(l$.$$.fragment),uXr=l(),R0e=a("p"),pXr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_Xr=l(),wn=a("p"),bXr=o("The model class to instantiate is selected based on the "),P0e=a("code"),vXr=o("model_type"),FXr=o(` property of the config object (either
passed as an argument or loaded from `),B0e=a("code"),TXr=o("pretrained_model_name_or_path"),MXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I0e=a("code"),EXr=o("pretrained_model_name_or_path"),CXr=o(":"),wXr=l(),Se=a("ul"),eA=a("li"),N0e=a("strong"),AXr=o("albert"),LXr=o(" \u2014 "),hee=a("a"),yXr=o("FlaxAlbertForSequenceClassification"),xXr=o(" (ALBERT model)"),$Xr=l(),oA=a("li"),q0e=a("strong"),kXr=o("bart"),SXr=o(" \u2014 "),uee=a("a"),RXr=o("FlaxBartForSequenceClassification"),PXr=o(" (BART model)"),BXr=l(),rA=a("li"),j0e=a("strong"),IXr=o("bert"),NXr=o(" \u2014 "),pee=a("a"),qXr=o("FlaxBertForSequenceClassification"),jXr=o(" (BERT model)"),DXr=l(),tA=a("li"),D0e=a("strong"),GXr=o("big_bird"),OXr=o(" \u2014 "),_ee=a("a"),VXr=o("FlaxBigBirdForSequenceClassification"),XXr=o(" (BigBird model)"),zXr=l(),aA=a("li"),G0e=a("strong"),QXr=o("distilbert"),WXr=o(" \u2014 "),bee=a("a"),HXr=o("FlaxDistilBertForSequenceClassification"),UXr=o(" (DistilBERT model)"),JXr=l(),nA=a("li"),O0e=a("strong"),YXr=o("electra"),KXr=o(" \u2014 "),vee=a("a"),ZXr=o("FlaxElectraForSequenceClassification"),ezr=o(" (ELECTRA model)"),ozr=l(),sA=a("li"),V0e=a("strong"),rzr=o("mbart"),tzr=o(" \u2014 "),Fee=a("a"),azr=o("FlaxMBartForSequenceClassification"),nzr=o(" (mBART model)"),szr=l(),lA=a("li"),X0e=a("strong"),lzr=o("roberta"),izr=o(" \u2014 "),Tee=a("a"),dzr=o("FlaxRobertaForSequenceClassification"),czr=o(" (RoBERTa model)"),mzr=l(),iA=a("li"),z0e=a("strong"),fzr=o("roformer"),gzr=o(" \u2014 "),Mee=a("a"),hzr=o("FlaxRoFormerForSequenceClassification"),uzr=o(" (RoFormer model)"),pzr=l(),dA=a("li"),Q0e=a("strong"),_zr=o("xlm-roberta"),bzr=o(" \u2014 "),Eee=a("a"),vzr=o("FlaxXLMRobertaForSequenceClassification"),Fzr=o(" (XLM-RoBERTa model)"),Tzr=l(),F(cA.$$.fragment),SVe=l(),sm=a("h2"),mA=a("a"),W0e=a("span"),F(i$.$$.fragment),Mzr=l(),H0e=a("span"),Ezr=o("FlaxAutoModelForQuestionAnswering"),RVe=l(),Fr=a("div"),F(d$.$$.fragment),Czr=l(),lm=a("p"),wzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=a("a"),Azr=o("from_pretrained()"),Lzr=o(" class method or the "),wee=a("a"),yzr=o("from_config()"),xzr=o(` class
method.`),$zr=l(),c$=a("p"),kzr=o("This class cannot be instantiated directly using "),U0e=a("code"),Szr=o("__init__()"),Rzr=o(" (throws an error)."),Pzr=l(),Jt=a("div"),F(m$.$$.fragment),Bzr=l(),J0e=a("p"),Izr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Nzr=l(),im=a("p"),qzr=o(`Note:
Loading a model from its configuration file does `),Y0e=a("strong"),jzr=o("not"),Dzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=a("a"),Gzr=o("from_pretrained()"),Ozr=o(" to load the model weights."),Vzr=l(),F(fA.$$.fragment),Xzr=l(),Hr=a("div"),F(f$.$$.fragment),zzr=l(),K0e=a("p"),Qzr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Wzr=l(),An=a("p"),Hzr=o("The model class to instantiate is selected based on the "),Z0e=a("code"),Uzr=o("model_type"),Jzr=o(` property of the config object (either
passed as an argument or loaded from `),ewe=a("code"),Yzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),owe=a("code"),Zzr=o("pretrained_model_name_or_path"),eQr=o(":"),oQr=l(),Re=a("ul"),gA=a("li"),rwe=a("strong"),rQr=o("albert"),tQr=o(" \u2014 "),Lee=a("a"),aQr=o("FlaxAlbertForQuestionAnswering"),nQr=o(" (ALBERT model)"),sQr=l(),hA=a("li"),twe=a("strong"),lQr=o("bart"),iQr=o(" \u2014 "),yee=a("a"),dQr=o("FlaxBartForQuestionAnswering"),cQr=o(" (BART model)"),mQr=l(),uA=a("li"),awe=a("strong"),fQr=o("bert"),gQr=o(" \u2014 "),xee=a("a"),hQr=o("FlaxBertForQuestionAnswering"),uQr=o(" (BERT model)"),pQr=l(),pA=a("li"),nwe=a("strong"),_Qr=o("big_bird"),bQr=o(" \u2014 "),$ee=a("a"),vQr=o("FlaxBigBirdForQuestionAnswering"),FQr=o(" (BigBird model)"),TQr=l(),_A=a("li"),swe=a("strong"),MQr=o("distilbert"),EQr=o(" \u2014 "),kee=a("a"),CQr=o("FlaxDistilBertForQuestionAnswering"),wQr=o(" (DistilBERT model)"),AQr=l(),bA=a("li"),lwe=a("strong"),LQr=o("electra"),yQr=o(" \u2014 "),See=a("a"),xQr=o("FlaxElectraForQuestionAnswering"),$Qr=o(" (ELECTRA model)"),kQr=l(),vA=a("li"),iwe=a("strong"),SQr=o("mbart"),RQr=o(" \u2014 "),Ree=a("a"),PQr=o("FlaxMBartForQuestionAnswering"),BQr=o(" (mBART model)"),IQr=l(),FA=a("li"),dwe=a("strong"),NQr=o("roberta"),qQr=o(" \u2014 "),Pee=a("a"),jQr=o("FlaxRobertaForQuestionAnswering"),DQr=o(" (RoBERTa model)"),GQr=l(),TA=a("li"),cwe=a("strong"),OQr=o("roformer"),VQr=o(" \u2014 "),Bee=a("a"),XQr=o("FlaxRoFormerForQuestionAnswering"),zQr=o(" (RoFormer model)"),QQr=l(),MA=a("li"),mwe=a("strong"),WQr=o("xlm-roberta"),HQr=o(" \u2014 "),Iee=a("a"),UQr=o("FlaxXLMRobertaForQuestionAnswering"),JQr=o(" (XLM-RoBERTa model)"),YQr=l(),F(EA.$$.fragment),PVe=l(),dm=a("h2"),CA=a("a"),fwe=a("span"),F(g$.$$.fragment),KQr=l(),gwe=a("span"),ZQr=o("FlaxAutoModelForTokenClassification"),BVe=l(),Tr=a("div"),F(h$.$$.fragment),eWr=l(),cm=a("p"),oWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=a("a"),rWr=o("from_pretrained()"),tWr=o(" class method or the "),qee=a("a"),aWr=o("from_config()"),nWr=o(` class
method.`),sWr=l(),u$=a("p"),lWr=o("This class cannot be instantiated directly using "),hwe=a("code"),iWr=o("__init__()"),dWr=o(" (throws an error)."),cWr=l(),Yt=a("div"),F(p$.$$.fragment),mWr=l(),uwe=a("p"),fWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gWr=l(),mm=a("p"),hWr=o(`Note:
Loading a model from its configuration file does `),pwe=a("strong"),uWr=o("not"),pWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=a("a"),_Wr=o("from_pretrained()"),bWr=o(" to load the model weights."),vWr=l(),F(wA.$$.fragment),FWr=l(),Ur=a("div"),F(_$.$$.fragment),TWr=l(),_we=a("p"),MWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EWr=l(),Ln=a("p"),CWr=o("The model class to instantiate is selected based on the "),bwe=a("code"),wWr=o("model_type"),AWr=o(` property of the config object (either
passed as an argument or loaded from `),vwe=a("code"),LWr=o("pretrained_model_name_or_path"),yWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=a("code"),xWr=o("pretrained_model_name_or_path"),$Wr=o(":"),kWr=l(),Ve=a("ul"),AA=a("li"),Twe=a("strong"),SWr=o("albert"),RWr=o(" \u2014 "),Dee=a("a"),PWr=o("FlaxAlbertForTokenClassification"),BWr=o(" (ALBERT model)"),IWr=l(),LA=a("li"),Mwe=a("strong"),NWr=o("bert"),qWr=o(" \u2014 "),Gee=a("a"),jWr=o("FlaxBertForTokenClassification"),DWr=o(" (BERT model)"),GWr=l(),yA=a("li"),Ewe=a("strong"),OWr=o("big_bird"),VWr=o(" \u2014 "),Oee=a("a"),XWr=o("FlaxBigBirdForTokenClassification"),zWr=o(" (BigBird model)"),QWr=l(),xA=a("li"),Cwe=a("strong"),WWr=o("distilbert"),HWr=o(" \u2014 "),Vee=a("a"),UWr=o("FlaxDistilBertForTokenClassification"),JWr=o(" (DistilBERT model)"),YWr=l(),$A=a("li"),wwe=a("strong"),KWr=o("electra"),ZWr=o(" \u2014 "),Xee=a("a"),eHr=o("FlaxElectraForTokenClassification"),oHr=o(" (ELECTRA model)"),rHr=l(),kA=a("li"),Awe=a("strong"),tHr=o("roberta"),aHr=o(" \u2014 "),zee=a("a"),nHr=o("FlaxRobertaForTokenClassification"),sHr=o(" (RoBERTa model)"),lHr=l(),SA=a("li"),Lwe=a("strong"),iHr=o("roformer"),dHr=o(" \u2014 "),Qee=a("a"),cHr=o("FlaxRoFormerForTokenClassification"),mHr=o(" (RoFormer model)"),fHr=l(),RA=a("li"),ywe=a("strong"),gHr=o("xlm-roberta"),hHr=o(" \u2014 "),Wee=a("a"),uHr=o("FlaxXLMRobertaForTokenClassification"),pHr=o(" (XLM-RoBERTa model)"),_Hr=l(),F(PA.$$.fragment),IVe=l(),fm=a("h2"),BA=a("a"),xwe=a("span"),F(b$.$$.fragment),bHr=l(),$we=a("span"),vHr=o("FlaxAutoModelForMultipleChoice"),NVe=l(),Mr=a("div"),F(v$.$$.fragment),FHr=l(),gm=a("p"),THr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=a("a"),MHr=o("from_pretrained()"),EHr=o(" class method or the "),Uee=a("a"),CHr=o("from_config()"),wHr=o(` class
method.`),AHr=l(),F$=a("p"),LHr=o("This class cannot be instantiated directly using "),kwe=a("code"),yHr=o("__init__()"),xHr=o(" (throws an error)."),$Hr=l(),Kt=a("div"),F(T$.$$.fragment),kHr=l(),Swe=a("p"),SHr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RHr=l(),hm=a("p"),PHr=o(`Note:
Loading a model from its configuration file does `),Rwe=a("strong"),BHr=o("not"),IHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),NHr=o("from_pretrained()"),qHr=o(" to load the model weights."),jHr=l(),F(IA.$$.fragment),DHr=l(),Jr=a("div"),F(M$.$$.fragment),GHr=l(),Pwe=a("p"),OHr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VHr=l(),yn=a("p"),XHr=o("The model class to instantiate is selected based on the "),Bwe=a("code"),zHr=o("model_type"),QHr=o(` property of the config object (either
passed as an argument or loaded from `),Iwe=a("code"),WHr=o("pretrained_model_name_or_path"),HHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nwe=a("code"),UHr=o("pretrained_model_name_or_path"),JHr=o(":"),YHr=l(),Xe=a("ul"),NA=a("li"),qwe=a("strong"),KHr=o("albert"),ZHr=o(" \u2014 "),Yee=a("a"),eUr=o("FlaxAlbertForMultipleChoice"),oUr=o(" (ALBERT model)"),rUr=l(),qA=a("li"),jwe=a("strong"),tUr=o("bert"),aUr=o(" \u2014 "),Kee=a("a"),nUr=o("FlaxBertForMultipleChoice"),sUr=o(" (BERT model)"),lUr=l(),jA=a("li"),Dwe=a("strong"),iUr=o("big_bird"),dUr=o(" \u2014 "),Zee=a("a"),cUr=o("FlaxBigBirdForMultipleChoice"),mUr=o(" (BigBird model)"),fUr=l(),DA=a("li"),Gwe=a("strong"),gUr=o("distilbert"),hUr=o(" \u2014 "),eoe=a("a"),uUr=o("FlaxDistilBertForMultipleChoice"),pUr=o(" (DistilBERT model)"),_Ur=l(),GA=a("li"),Owe=a("strong"),bUr=o("electra"),vUr=o(" \u2014 "),ooe=a("a"),FUr=o("FlaxElectraForMultipleChoice"),TUr=o(" (ELECTRA model)"),MUr=l(),OA=a("li"),Vwe=a("strong"),EUr=o("roberta"),CUr=o(" \u2014 "),roe=a("a"),wUr=o("FlaxRobertaForMultipleChoice"),AUr=o(" (RoBERTa model)"),LUr=l(),VA=a("li"),Xwe=a("strong"),yUr=o("roformer"),xUr=o(" \u2014 "),toe=a("a"),$Ur=o("FlaxRoFormerForMultipleChoice"),kUr=o(" (RoFormer model)"),SUr=l(),XA=a("li"),zwe=a("strong"),RUr=o("xlm-roberta"),PUr=o(" \u2014 "),aoe=a("a"),BUr=o("FlaxXLMRobertaForMultipleChoice"),IUr=o(" (XLM-RoBERTa model)"),NUr=l(),F(zA.$$.fragment),qVe=l(),um=a("h2"),QA=a("a"),Qwe=a("span"),F(E$.$$.fragment),qUr=l(),Wwe=a("span"),jUr=o("FlaxAutoModelForNextSentencePrediction"),jVe=l(),Er=a("div"),F(C$.$$.fragment),DUr=l(),pm=a("p"),GUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=a("a"),OUr=o("from_pretrained()"),VUr=o(" class method or the "),soe=a("a"),XUr=o("from_config()"),zUr=o(` class
method.`),QUr=l(),w$=a("p"),WUr=o("This class cannot be instantiated directly using "),Hwe=a("code"),HUr=o("__init__()"),UUr=o(" (throws an error)."),JUr=l(),Zt=a("div"),F(A$.$$.fragment),YUr=l(),Uwe=a("p"),KUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZUr=l(),_m=a("p"),eJr=o(`Note:
Loading a model from its configuration file does `),Jwe=a("strong"),oJr=o("not"),rJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=a("a"),tJr=o("from_pretrained()"),aJr=o(" to load the model weights."),nJr=l(),F(WA.$$.fragment),sJr=l(),Yr=a("div"),F(L$.$$.fragment),lJr=l(),Ywe=a("p"),iJr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),dJr=l(),xn=a("p"),cJr=o("The model class to instantiate is selected based on the "),Kwe=a("code"),mJr=o("model_type"),fJr=o(` property of the config object (either
passed as an argument or loaded from `),Zwe=a("code"),gJr=o("pretrained_model_name_or_path"),hJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eAe=a("code"),uJr=o("pretrained_model_name_or_path"),pJr=o(":"),_Jr=l(),oAe=a("ul"),HA=a("li"),rAe=a("strong"),bJr=o("bert"),vJr=o(" \u2014 "),ioe=a("a"),FJr=o("FlaxBertForNextSentencePrediction"),TJr=o(" (BERT model)"),MJr=l(),F(UA.$$.fragment),DVe=l(),bm=a("h2"),JA=a("a"),tAe=a("span"),F(y$.$$.fragment),EJr=l(),aAe=a("span"),CJr=o("FlaxAutoModelForImageClassification"),GVe=l(),Cr=a("div"),F(x$.$$.fragment),wJr=l(),vm=a("p"),AJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=a("a"),LJr=o("from_pretrained()"),yJr=o(" class method or the "),coe=a("a"),xJr=o("from_config()"),$Jr=o(` class
method.`),kJr=l(),$$=a("p"),SJr=o("This class cannot be instantiated directly using "),nAe=a("code"),RJr=o("__init__()"),PJr=o(" (throws an error)."),BJr=l(),ea=a("div"),F(k$.$$.fragment),IJr=l(),sAe=a("p"),NJr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qJr=l(),Fm=a("p"),jJr=o(`Note:
Loading a model from its configuration file does `),lAe=a("strong"),DJr=o("not"),GJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=a("a"),OJr=o("from_pretrained()"),VJr=o(" to load the model weights."),XJr=l(),F(YA.$$.fragment),zJr=l(),Kr=a("div"),F(S$.$$.fragment),QJr=l(),iAe=a("p"),WJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),HJr=l(),$n=a("p"),UJr=o("The model class to instantiate is selected based on the "),dAe=a("code"),JJr=o("model_type"),YJr=o(` property of the config object (either
passed as an argument or loaded from `),cAe=a("code"),KJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mAe=a("code"),eYr=o("pretrained_model_name_or_path"),oYr=o(":"),rYr=l(),R$=a("ul"),KA=a("li"),fAe=a("strong"),tYr=o("beit"),aYr=o(" \u2014 "),foe=a("a"),nYr=o("FlaxBeitForImageClassification"),sYr=o(" (BEiT model)"),lYr=l(),ZA=a("li"),gAe=a("strong"),iYr=o("vit"),dYr=o(" \u2014 "),goe=a("a"),cYr=o("FlaxViTForImageClassification"),mYr=o(" (ViT model)"),fYr=l(),F(e6.$$.fragment),OVe=l(),Tm=a("h2"),o6=a("a"),hAe=a("span"),F(P$.$$.fragment),gYr=l(),uAe=a("span"),hYr=o("FlaxAutoModelForVision2Seq"),VVe=l(),wr=a("div"),F(B$.$$.fragment),uYr=l(),Mm=a("p"),pYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=a("a"),_Yr=o("from_pretrained()"),bYr=o(" class method or the "),uoe=a("a"),vYr=o("from_config()"),FYr=o(` class
method.`),TYr=l(),I$=a("p"),MYr=o("This class cannot be instantiated directly using "),pAe=a("code"),EYr=o("__init__()"),CYr=o(" (throws an error)."),wYr=l(),oa=a("div"),F(N$.$$.fragment),AYr=l(),_Ae=a("p"),LYr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yYr=l(),Em=a("p"),xYr=o(`Note:
Loading a model from its configuration file does `),bAe=a("strong"),$Yr=o("not"),kYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=a("a"),SYr=o("from_pretrained()"),RYr=o(" to load the model weights."),PYr=l(),F(r6.$$.fragment),BYr=l(),Zr=a("div"),F(q$.$$.fragment),IYr=l(),vAe=a("p"),NYr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qYr=l(),kn=a("p"),jYr=o("The model class to instantiate is selected based on the "),FAe=a("code"),DYr=o("model_type"),GYr=o(` property of the config object (either
passed as an argument or loaded from `),TAe=a("code"),OYr=o("pretrained_model_name_or_path"),VYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MAe=a("code"),XYr=o("pretrained_model_name_or_path"),zYr=o(":"),QYr=l(),EAe=a("ul"),t6=a("li"),CAe=a("strong"),WYr=o("vision-encoder-decoder"),HYr=o(" \u2014 "),_oe=a("a"),UYr=o("FlaxVisionEncoderDecoderModel"),JYr=o(" (Vision Encoder decoder model)"),YYr=l(),F(a6.$$.fragment),this.h()},l(m){const _=MDt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var j$=s(u);f=n(j$,"A",{id:!0,class:!0,href:!0});var wAe=s(f);p=n(wAe,"SPAN",{});var AAe=s(p);T(d.$$.fragment,AAe),AAe.forEach(t),wAe.forEach(t),h=i(j$),Eo=n(j$,"SPAN",{});var LAe=s(Eo);Ti=r(LAe,"Auto Classes"),LAe.forEach(t),j$.forEach(t),Lm=i(m),at=n(m,"P",{});var D$=s(at);Mi=r(D$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(D$,"CODE",{});var yAe=s(Ei);wy=r(yAe,"from_pretrained()"),yAe.forEach(t),ym=r(D$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),D$.forEach(t),Oe=i(m),Qe=n(m,"P",{});var Sn=s(Qe);Ci=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var xAe=s(Rn);Ay=r(xAe,"AutoConfig"),xAe.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var $Ae=s(Bn);Ly=r($Ae,"AutoModel"),$Ae.forEach(t),wi=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var kAe=s(In);yy=r(kAe,"AutoTokenizer"),kAe.forEach(t),Ai=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),xm=i(m),T(xa.$$.fragment,m),We=i(m),Ae=n(m,"P",{});var G$=s(Ae);rS=r(G$,"will create a model that is an instance of "),Li=n(G$,"A",{href:!0});var SAe=s(Li);tS=r(SAe,"BertModel"),SAe.forEach(t),aS=r(G$,"."),G$.forEach(t),Co=i(m),$a=n(m,"P",{});var O$=s($a);nS=r(O$,"There is one class of "),$m=n(O$,"CODE",{});var RAe=s($m);sS=r(RAe,"AutoModel"),RAe.forEach(t),eQe=r(O$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),O$.forEach(t),jGe=i(m),yi=n(m,"H2",{class:!0});var V$=s(yi);km=n(V$,"A",{id:!0,class:!0,href:!0});var PAe=s(km);fte=n(PAe,"SPAN",{});var BAe=s(fte);T(xy.$$.fragment,BAe),BAe.forEach(t),PAe.forEach(t),oQe=i(V$),gte=n(V$,"SPAN",{});var IAe=s(gte);rQe=r(IAe,"Extending the Auto Classes"),IAe.forEach(t),V$.forEach(t),DGe=i(m),Nn=n(m,"P",{});var Cm=s(Nn);tQe=r(Cm,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=n(Cm,"CODE",{});var NAe=s(hte);aQe=r(NAe,"NewModel"),NAe.forEach(t),nQe=r(Cm,", make sure you have a "),ute=n(Cm,"CODE",{});var qAe=s(ute);sQe=r(qAe,"NewModelConfig"),qAe.forEach(t),lQe=r(Cm,` then you can add those to the auto
classes like this:`),Cm.forEach(t),GGe=i(m),T($y.$$.fragment,m),OGe=i(m),lS=n(m,"P",{});var jAe=s(lS);iQe=r(jAe,"You will then be able to use the auto classes like you would usually do!"),jAe.forEach(t),VGe=i(m),T(Sm.$$.fragment,m),XGe=i(m),xi=n(m,"H2",{class:!0});var X$=s(xi);Rm=n(X$,"A",{id:!0,class:!0,href:!0});var DAe=s(Rm);pte=n(DAe,"SPAN",{});var GAe=s(pte);T(ky.$$.fragment,GAe),GAe.forEach(t),DAe.forEach(t),dQe=i(X$),_te=n(X$,"SPAN",{});var OAe=s(_te);cQe=r(OAe,"AutoConfig"),OAe.forEach(t),X$.forEach(t),zGe=i(m),wo=n(m,"DIV",{class:!0});var rt=s(wo);T(Sy.$$.fragment,rt),mQe=i(rt),Ry=n(rt,"P",{});var z$=s(Ry);fQe=r(z$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=n(z$,"A",{href:!0});var VAe=s(iS);gQe=r(VAe,"from_pretrained()"),VAe.forEach(t),hQe=r(z$," class method."),z$.forEach(t),uQe=i(rt),Py=n(rt,"P",{});var Q$=s(Py);pQe=r(Q$,"This class cannot be instantiated directly using "),bte=n(Q$,"CODE",{});var XAe=s(bte);_Qe=r(XAe,"__init__()"),XAe.forEach(t),bQe=r(Q$," (throws an error)."),Q$.forEach(t),vQe=i(rt),Ar=n(rt,"DIV",{class:!0});var tt=s(Ar);T(By.$$.fragment,tt),FQe=i(tt),vte=n(tt,"P",{});var zAe=s(vte);TQe=r(zAe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),zAe.forEach(t),MQe=i(tt),$i=n(tt,"P",{});var wm=s($i);EQe=r(wm,"The configuration class to instantiate is selected based on the "),Fte=n(wm,"CODE",{});var QAe=s(Fte);CQe=r(QAe,"model_type"),QAe.forEach(t),wQe=r(wm,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=n(wm,"CODE",{});var WAe=s(Tte);AQe=r(WAe,"pretrained_model_name_or_path"),WAe.forEach(t),LQe=r(wm,":"),wm.forEach(t),yQe=i(tt),A=n(tt,"UL",{});var L=s(A);Pm=n(L,"LI",{});var n6=s(Pm);Mte=n(n6,"STRONG",{});var HAe=s(Mte);xQe=r(HAe,"albert"),HAe.forEach(t),$Qe=r(n6," \u2014 "),dS=n(n6,"A",{href:!0});var UAe=s(dS);kQe=r(UAe,"AlbertConfig"),UAe.forEach(t),SQe=r(n6," (ALBERT model)"),n6.forEach(t),RQe=i(L),Bm=n(L,"LI",{});var s6=s(Bm);Ete=n(s6,"STRONG",{});var JAe=s(Ete);PQe=r(JAe,"bart"),JAe.forEach(t),BQe=r(s6," \u2014 "),cS=n(s6,"A",{href:!0});var YAe=s(cS);IQe=r(YAe,"BartConfig"),YAe.forEach(t),NQe=r(s6," (BART model)"),s6.forEach(t),qQe=i(L),Im=n(L,"LI",{});var l6=s(Im);Cte=n(l6,"STRONG",{});var KAe=s(Cte);jQe=r(KAe,"beit"),KAe.forEach(t),DQe=r(l6," \u2014 "),mS=n(l6,"A",{href:!0});var ZAe=s(mS);GQe=r(ZAe,"BeitConfig"),ZAe.forEach(t),OQe=r(l6," (BEiT model)"),l6.forEach(t),VQe=i(L),Nm=n(L,"LI",{});var i6=s(Nm);wte=n(i6,"STRONG",{});var e6e=s(wte);XQe=r(e6e,"bert"),e6e.forEach(t),zQe=r(i6," \u2014 "),fS=n(i6,"A",{href:!0});var o6e=s(fS);QQe=r(o6e,"BertConfig"),o6e.forEach(t),WQe=r(i6," (BERT model)"),i6.forEach(t),HQe=i(L),qm=n(L,"LI",{});var d6=s(qm);Ate=n(d6,"STRONG",{});var r6e=s(Ate);UQe=r(r6e,"bert-generation"),r6e.forEach(t),JQe=r(d6," \u2014 "),gS=n(d6,"A",{href:!0});var t6e=s(gS);YQe=r(t6e,"BertGenerationConfig"),t6e.forEach(t),KQe=r(d6," (Bert Generation model)"),d6.forEach(t),ZQe=i(L),jm=n(L,"LI",{});var c6=s(jm);Lte=n(c6,"STRONG",{});var a6e=s(Lte);eWe=r(a6e,"big_bird"),a6e.forEach(t),oWe=r(c6," \u2014 "),hS=n(c6,"A",{href:!0});var n6e=s(hS);rWe=r(n6e,"BigBirdConfig"),n6e.forEach(t),tWe=r(c6," (BigBird model)"),c6.forEach(t),aWe=i(L),Dm=n(L,"LI",{});var m6=s(Dm);yte=n(m6,"STRONG",{});var s6e=s(yte);nWe=r(s6e,"bigbird_pegasus"),s6e.forEach(t),sWe=r(m6," \u2014 "),uS=n(m6,"A",{href:!0});var l6e=s(uS);lWe=r(l6e,"BigBirdPegasusConfig"),l6e.forEach(t),iWe=r(m6," (BigBird-Pegasus model)"),m6.forEach(t),dWe=i(L),Gm=n(L,"LI",{});var f6=s(Gm);xte=n(f6,"STRONG",{});var i6e=s(xte);cWe=r(i6e,"blenderbot"),i6e.forEach(t),mWe=r(f6," \u2014 "),pS=n(f6,"A",{href:!0});var d6e=s(pS);fWe=r(d6e,"BlenderbotConfig"),d6e.forEach(t),gWe=r(f6," (Blenderbot model)"),f6.forEach(t),hWe=i(L),Om=n(L,"LI",{});var g6=s(Om);$te=n(g6,"STRONG",{});var c6e=s($te);uWe=r(c6e,"blenderbot-small"),c6e.forEach(t),pWe=r(g6," \u2014 "),_S=n(g6,"A",{href:!0});var m6e=s(_S);_We=r(m6e,"BlenderbotSmallConfig"),m6e.forEach(t),bWe=r(g6," (BlenderbotSmall model)"),g6.forEach(t),vWe=i(L),Vm=n(L,"LI",{});var h6=s(Vm);kte=n(h6,"STRONG",{});var f6e=s(kte);FWe=r(f6e,"bloom"),f6e.forEach(t),TWe=r(h6," \u2014 "),bS=n(h6,"A",{href:!0});var g6e=s(bS);MWe=r(g6e,"BloomConfig"),g6e.forEach(t),EWe=r(h6," (BLOOM model)"),h6.forEach(t),CWe=i(L),Xm=n(L,"LI",{});var u6=s(Xm);Ste=n(u6,"STRONG",{});var h6e=s(Ste);wWe=r(h6e,"camembert"),h6e.forEach(t),AWe=r(u6," \u2014 "),vS=n(u6,"A",{href:!0});var u6e=s(vS);LWe=r(u6e,"CamembertConfig"),u6e.forEach(t),yWe=r(u6," (CamemBERT model)"),u6.forEach(t),xWe=i(L),zm=n(L,"LI",{});var p6=s(zm);Rte=n(p6,"STRONG",{});var p6e=s(Rte);$We=r(p6e,"canine"),p6e.forEach(t),kWe=r(p6," \u2014 "),FS=n(p6,"A",{href:!0});var _6e=s(FS);SWe=r(_6e,"CanineConfig"),_6e.forEach(t),RWe=r(p6," (CANINE model)"),p6.forEach(t),PWe=i(L),Qm=n(L,"LI",{});var _6=s(Qm);Pte=n(_6,"STRONG",{});var b6e=s(Pte);BWe=r(b6e,"clip"),b6e.forEach(t),IWe=r(_6," \u2014 "),TS=n(_6,"A",{href:!0});var v6e=s(TS);NWe=r(v6e,"CLIPConfig"),v6e.forEach(t),qWe=r(_6," (CLIP model)"),_6.forEach(t),jWe=i(L),Wm=n(L,"LI",{});var b6=s(Wm);Bte=n(b6,"STRONG",{});var F6e=s(Bte);DWe=r(F6e,"convbert"),F6e.forEach(t),GWe=r(b6," \u2014 "),MS=n(b6,"A",{href:!0});var T6e=s(MS);OWe=r(T6e,"ConvBertConfig"),T6e.forEach(t),VWe=r(b6," (ConvBERT model)"),b6.forEach(t),XWe=i(L),Hm=n(L,"LI",{});var v6=s(Hm);Ite=n(v6,"STRONG",{});var M6e=s(Ite);zWe=r(M6e,"convnext"),M6e.forEach(t),QWe=r(v6," \u2014 "),ES=n(v6,"A",{href:!0});var E6e=s(ES);WWe=r(E6e,"ConvNextConfig"),E6e.forEach(t),HWe=r(v6," (ConvNeXT model)"),v6.forEach(t),UWe=i(L),Um=n(L,"LI",{});var F6=s(Um);Nte=n(F6,"STRONG",{});var C6e=s(Nte);JWe=r(C6e,"ctrl"),C6e.forEach(t),YWe=r(F6," \u2014 "),CS=n(F6,"A",{href:!0});var w6e=s(CS);KWe=r(w6e,"CTRLConfig"),w6e.forEach(t),ZWe=r(F6," (CTRL model)"),F6.forEach(t),eHe=i(L),Jm=n(L,"LI",{});var T6=s(Jm);qte=n(T6,"STRONG",{});var A6e=s(qte);oHe=r(A6e,"cvt"),A6e.forEach(t),rHe=r(T6," \u2014 "),wS=n(T6,"A",{href:!0});var L6e=s(wS);tHe=r(L6e,"CvtConfig"),L6e.forEach(t),aHe=r(T6," (CvT model)"),T6.forEach(t),nHe=i(L),Ym=n(L,"LI",{});var M6=s(Ym);jte=n(M6,"STRONG",{});var y6e=s(jte);sHe=r(y6e,"data2vec-audio"),y6e.forEach(t),lHe=r(M6," \u2014 "),AS=n(M6,"A",{href:!0});var x6e=s(AS);iHe=r(x6e,"Data2VecAudioConfig"),x6e.forEach(t),dHe=r(M6," (Data2VecAudio model)"),M6.forEach(t),cHe=i(L),Km=n(L,"LI",{});var E6=s(Km);Dte=n(E6,"STRONG",{});var $6e=s(Dte);mHe=r($6e,"data2vec-text"),$6e.forEach(t),fHe=r(E6," \u2014 "),LS=n(E6,"A",{href:!0});var k6e=s(LS);gHe=r(k6e,"Data2VecTextConfig"),k6e.forEach(t),hHe=r(E6," (Data2VecText model)"),E6.forEach(t),uHe=i(L),Zm=n(L,"LI",{});var C6=s(Zm);Gte=n(C6,"STRONG",{});var S6e=s(Gte);pHe=r(S6e,"data2vec-vision"),S6e.forEach(t),_He=r(C6," \u2014 "),yS=n(C6,"A",{href:!0});var R6e=s(yS);bHe=r(R6e,"Data2VecVisionConfig"),R6e.forEach(t),vHe=r(C6," (Data2VecVision model)"),C6.forEach(t),FHe=i(L),ef=n(L,"LI",{});var w6=s(ef);Ote=n(w6,"STRONG",{});var P6e=s(Ote);THe=r(P6e,"deberta"),P6e.forEach(t),MHe=r(w6," \u2014 "),xS=n(w6,"A",{href:!0});var B6e=s(xS);EHe=r(B6e,"DebertaConfig"),B6e.forEach(t),CHe=r(w6," (DeBERTa model)"),w6.forEach(t),wHe=i(L),of=n(L,"LI",{});var A6=s(of);Vte=n(A6,"STRONG",{});var I6e=s(Vte);AHe=r(I6e,"deberta-v2"),I6e.forEach(t),LHe=r(A6," \u2014 "),$S=n(A6,"A",{href:!0});var N6e=s($S);yHe=r(N6e,"DebertaV2Config"),N6e.forEach(t),xHe=r(A6," (DeBERTa-v2 model)"),A6.forEach(t),$He=i(L),rf=n(L,"LI",{});var L6=s(rf);Xte=n(L6,"STRONG",{});var q6e=s(Xte);kHe=r(q6e,"decision_transformer"),q6e.forEach(t),SHe=r(L6," \u2014 "),kS=n(L6,"A",{href:!0});var j6e=s(kS);RHe=r(j6e,"DecisionTransformerConfig"),j6e.forEach(t),PHe=r(L6," (Decision Transformer model)"),L6.forEach(t),BHe=i(L),tf=n(L,"LI",{});var y6=s(tf);zte=n(y6,"STRONG",{});var ZYr=s(zte);IHe=r(ZYr,"deit"),ZYr.forEach(t),NHe=r(y6," \u2014 "),SS=n(y6,"A",{href:!0});var eKr=s(SS);qHe=r(eKr,"DeiTConfig"),eKr.forEach(t),jHe=r(y6," (DeiT model)"),y6.forEach(t),DHe=i(L),af=n(L,"LI",{});var D6e=s(af);Qte=n(D6e,"STRONG",{});var oKr=s(Qte);GHe=r(oKr,"detr"),oKr.forEach(t),OHe=r(D6e," \u2014 "),RS=n(D6e,"A",{href:!0});var rKr=s(RS);VHe=r(rKr,"DetrConfig"),rKr.forEach(t),XHe=r(D6e," (DETR model)"),D6e.forEach(t),zHe=i(L),nf=n(L,"LI",{});var G6e=s(nf);Wte=n(G6e,"STRONG",{});var tKr=s(Wte);QHe=r(tKr,"distilbert"),tKr.forEach(t),WHe=r(G6e," \u2014 "),PS=n(G6e,"A",{href:!0});var aKr=s(PS);HHe=r(aKr,"DistilBertConfig"),aKr.forEach(t),UHe=r(G6e," (DistilBERT model)"),G6e.forEach(t),JHe=i(L),sf=n(L,"LI",{});var O6e=s(sf);Hte=n(O6e,"STRONG",{});var nKr=s(Hte);YHe=r(nKr,"dpr"),nKr.forEach(t),KHe=r(O6e," \u2014 "),BS=n(O6e,"A",{href:!0});var sKr=s(BS);ZHe=r(sKr,"DPRConfig"),sKr.forEach(t),eUe=r(O6e," (DPR model)"),O6e.forEach(t),oUe=i(L),lf=n(L,"LI",{});var V6e=s(lf);Ute=n(V6e,"STRONG",{});var lKr=s(Ute);rUe=r(lKr,"dpt"),lKr.forEach(t),tUe=r(V6e," \u2014 "),IS=n(V6e,"A",{href:!0});var iKr=s(IS);aUe=r(iKr,"DPTConfig"),iKr.forEach(t),nUe=r(V6e," (DPT model)"),V6e.forEach(t),sUe=i(L),df=n(L,"LI",{});var X6e=s(df);Jte=n(X6e,"STRONG",{});var dKr=s(Jte);lUe=r(dKr,"electra"),dKr.forEach(t),iUe=r(X6e," \u2014 "),NS=n(X6e,"A",{href:!0});var cKr=s(NS);dUe=r(cKr,"ElectraConfig"),cKr.forEach(t),cUe=r(X6e," (ELECTRA model)"),X6e.forEach(t),mUe=i(L),cf=n(L,"LI",{});var z6e=s(cf);Yte=n(z6e,"STRONG",{});var mKr=s(Yte);fUe=r(mKr,"encoder-decoder"),mKr.forEach(t),gUe=r(z6e," \u2014 "),qS=n(z6e,"A",{href:!0});var fKr=s(qS);hUe=r(fKr,"EncoderDecoderConfig"),fKr.forEach(t),uUe=r(z6e," (Encoder decoder model)"),z6e.forEach(t),pUe=i(L),mf=n(L,"LI",{});var Q6e=s(mf);Kte=n(Q6e,"STRONG",{});var gKr=s(Kte);_Ue=r(gKr,"flaubert"),gKr.forEach(t),bUe=r(Q6e," \u2014 "),jS=n(Q6e,"A",{href:!0});var hKr=s(jS);vUe=r(hKr,"FlaubertConfig"),hKr.forEach(t),FUe=r(Q6e," (FlauBERT model)"),Q6e.forEach(t),TUe=i(L),ff=n(L,"LI",{});var W6e=s(ff);Zte=n(W6e,"STRONG",{});var uKr=s(Zte);MUe=r(uKr,"flava"),uKr.forEach(t),EUe=r(W6e," \u2014 "),DS=n(W6e,"A",{href:!0});var pKr=s(DS);CUe=r(pKr,"FlavaConfig"),pKr.forEach(t),wUe=r(W6e," (FLAVA model)"),W6e.forEach(t),AUe=i(L),gf=n(L,"LI",{});var H6e=s(gf);eae=n(H6e,"STRONG",{});var _Kr=s(eae);LUe=r(_Kr,"fnet"),_Kr.forEach(t),yUe=r(H6e," \u2014 "),GS=n(H6e,"A",{href:!0});var bKr=s(GS);xUe=r(bKr,"FNetConfig"),bKr.forEach(t),$Ue=r(H6e," (FNet model)"),H6e.forEach(t),kUe=i(L),hf=n(L,"LI",{});var U6e=s(hf);oae=n(U6e,"STRONG",{});var vKr=s(oae);SUe=r(vKr,"fsmt"),vKr.forEach(t),RUe=r(U6e," \u2014 "),OS=n(U6e,"A",{href:!0});var FKr=s(OS);PUe=r(FKr,"FSMTConfig"),FKr.forEach(t),BUe=r(U6e," (FairSeq Machine-Translation model)"),U6e.forEach(t),IUe=i(L),uf=n(L,"LI",{});var J6e=s(uf);rae=n(J6e,"STRONG",{});var TKr=s(rae);NUe=r(TKr,"funnel"),TKr.forEach(t),qUe=r(J6e," \u2014 "),VS=n(J6e,"A",{href:!0});var MKr=s(VS);jUe=r(MKr,"FunnelConfig"),MKr.forEach(t),DUe=r(J6e," (Funnel Transformer model)"),J6e.forEach(t),GUe=i(L),pf=n(L,"LI",{});var Y6e=s(pf);tae=n(Y6e,"STRONG",{});var EKr=s(tae);OUe=r(EKr,"glpn"),EKr.forEach(t),VUe=r(Y6e," \u2014 "),XS=n(Y6e,"A",{href:!0});var CKr=s(XS);XUe=r(CKr,"GLPNConfig"),CKr.forEach(t),zUe=r(Y6e," (GLPN model)"),Y6e.forEach(t),QUe=i(L),_f=n(L,"LI",{});var K6e=s(_f);aae=n(K6e,"STRONG",{});var wKr=s(aae);WUe=r(wKr,"gpt2"),wKr.forEach(t),HUe=r(K6e," \u2014 "),zS=n(K6e,"A",{href:!0});var AKr=s(zS);UUe=r(AKr,"GPT2Config"),AKr.forEach(t),JUe=r(K6e," (OpenAI GPT-2 model)"),K6e.forEach(t),YUe=i(L),bf=n(L,"LI",{});var Z6e=s(bf);nae=n(Z6e,"STRONG",{});var LKr=s(nae);KUe=r(LKr,"gpt_neo"),LKr.forEach(t),ZUe=r(Z6e," \u2014 "),QS=n(Z6e,"A",{href:!0});var yKr=s(QS);eJe=r(yKr,"GPTNeoConfig"),yKr.forEach(t),oJe=r(Z6e," (GPT Neo model)"),Z6e.forEach(t),rJe=i(L),vf=n(L,"LI",{});var eLe=s(vf);sae=n(eLe,"STRONG",{});var xKr=s(sae);tJe=r(xKr,"gpt_neox"),xKr.forEach(t),aJe=r(eLe," \u2014 "),WS=n(eLe,"A",{href:!0});var $Kr=s(WS);nJe=r($Kr,"GPTNeoXConfig"),$Kr.forEach(t),sJe=r(eLe," (GPT NeoX model)"),eLe.forEach(t),lJe=i(L),Ff=n(L,"LI",{});var oLe=s(Ff);lae=n(oLe,"STRONG",{});var kKr=s(lae);iJe=r(kKr,"gptj"),kKr.forEach(t),dJe=r(oLe," \u2014 "),HS=n(oLe,"A",{href:!0});var SKr=s(HS);cJe=r(SKr,"GPTJConfig"),SKr.forEach(t),mJe=r(oLe," (GPT-J model)"),oLe.forEach(t),fJe=i(L),Tf=n(L,"LI",{});var rLe=s(Tf);iae=n(rLe,"STRONG",{});var RKr=s(iae);gJe=r(RKr,"hubert"),RKr.forEach(t),hJe=r(rLe," \u2014 "),US=n(rLe,"A",{href:!0});var PKr=s(US);uJe=r(PKr,"HubertConfig"),PKr.forEach(t),pJe=r(rLe," (Hubert model)"),rLe.forEach(t),_Je=i(L),Mf=n(L,"LI",{});var tLe=s(Mf);dae=n(tLe,"STRONG",{});var BKr=s(dae);bJe=r(BKr,"ibert"),BKr.forEach(t),vJe=r(tLe," \u2014 "),JS=n(tLe,"A",{href:!0});var IKr=s(JS);FJe=r(IKr,"IBertConfig"),IKr.forEach(t),TJe=r(tLe," (I-BERT model)"),tLe.forEach(t),MJe=i(L),Ef=n(L,"LI",{});var aLe=s(Ef);cae=n(aLe,"STRONG",{});var NKr=s(cae);EJe=r(NKr,"imagegpt"),NKr.forEach(t),CJe=r(aLe," \u2014 "),YS=n(aLe,"A",{href:!0});var qKr=s(YS);wJe=r(qKr,"ImageGPTConfig"),qKr.forEach(t),AJe=r(aLe," (ImageGPT model)"),aLe.forEach(t),LJe=i(L),Cf=n(L,"LI",{});var nLe=s(Cf);mae=n(nLe,"STRONG",{});var jKr=s(mae);yJe=r(jKr,"layoutlm"),jKr.forEach(t),xJe=r(nLe," \u2014 "),KS=n(nLe,"A",{href:!0});var DKr=s(KS);$Je=r(DKr,"LayoutLMConfig"),DKr.forEach(t),kJe=r(nLe," (LayoutLM model)"),nLe.forEach(t),SJe=i(L),wf=n(L,"LI",{});var sLe=s(wf);fae=n(sLe,"STRONG",{});var GKr=s(fae);RJe=r(GKr,"layoutlmv2"),GKr.forEach(t),PJe=r(sLe," \u2014 "),ZS=n(sLe,"A",{href:!0});var OKr=s(ZS);BJe=r(OKr,"LayoutLMv2Config"),OKr.forEach(t),IJe=r(sLe," (LayoutLMv2 model)"),sLe.forEach(t),NJe=i(L),Af=n(L,"LI",{});var lLe=s(Af);gae=n(lLe,"STRONG",{});var VKr=s(gae);qJe=r(VKr,"layoutlmv3"),VKr.forEach(t),jJe=r(lLe," \u2014 "),eR=n(lLe,"A",{href:!0});var XKr=s(eR);DJe=r(XKr,"LayoutLMv3Config"),XKr.forEach(t),GJe=r(lLe," (LayoutLMv3 model)"),lLe.forEach(t),OJe=i(L),Lf=n(L,"LI",{});var iLe=s(Lf);hae=n(iLe,"STRONG",{});var zKr=s(hae);VJe=r(zKr,"led"),zKr.forEach(t),XJe=r(iLe," \u2014 "),oR=n(iLe,"A",{href:!0});var QKr=s(oR);zJe=r(QKr,"LEDConfig"),QKr.forEach(t),QJe=r(iLe," (LED model)"),iLe.forEach(t),WJe=i(L),yf=n(L,"LI",{});var dLe=s(yf);uae=n(dLe,"STRONG",{});var WKr=s(uae);HJe=r(WKr,"levit"),WKr.forEach(t),UJe=r(dLe," \u2014 "),rR=n(dLe,"A",{href:!0});var HKr=s(rR);JJe=r(HKr,"LevitConfig"),HKr.forEach(t),YJe=r(dLe," (LeViT model)"),dLe.forEach(t),KJe=i(L),xf=n(L,"LI",{});var cLe=s(xf);pae=n(cLe,"STRONG",{});var UKr=s(pae);ZJe=r(UKr,"longformer"),UKr.forEach(t),eYe=r(cLe," \u2014 "),tR=n(cLe,"A",{href:!0});var JKr=s(tR);oYe=r(JKr,"LongformerConfig"),JKr.forEach(t),rYe=r(cLe," (Longformer model)"),cLe.forEach(t),tYe=i(L),$f=n(L,"LI",{});var mLe=s($f);_ae=n(mLe,"STRONG",{});var YKr=s(_ae);aYe=r(YKr,"longt5"),YKr.forEach(t),nYe=r(mLe," \u2014 "),aR=n(mLe,"A",{href:!0});var KKr=s(aR);sYe=r(KKr,"LongT5Config"),KKr.forEach(t),lYe=r(mLe," (LongT5 model)"),mLe.forEach(t),iYe=i(L),kf=n(L,"LI",{});var fLe=s(kf);bae=n(fLe,"STRONG",{});var ZKr=s(bae);dYe=r(ZKr,"luke"),ZKr.forEach(t),cYe=r(fLe," \u2014 "),nR=n(fLe,"A",{href:!0});var eZr=s(nR);mYe=r(eZr,"LukeConfig"),eZr.forEach(t),fYe=r(fLe," (LUKE model)"),fLe.forEach(t),gYe=i(L),Sf=n(L,"LI",{});var gLe=s(Sf);vae=n(gLe,"STRONG",{});var oZr=s(vae);hYe=r(oZr,"lxmert"),oZr.forEach(t),uYe=r(gLe," \u2014 "),sR=n(gLe,"A",{href:!0});var rZr=s(sR);pYe=r(rZr,"LxmertConfig"),rZr.forEach(t),_Ye=r(gLe," (LXMERT model)"),gLe.forEach(t),bYe=i(L),Rf=n(L,"LI",{});var hLe=s(Rf);Fae=n(hLe,"STRONG",{});var tZr=s(Fae);vYe=r(tZr,"m2m_100"),tZr.forEach(t),FYe=r(hLe," \u2014 "),lR=n(hLe,"A",{href:!0});var aZr=s(lR);TYe=r(aZr,"M2M100Config"),aZr.forEach(t),MYe=r(hLe," (M2M100 model)"),hLe.forEach(t),EYe=i(L),Pf=n(L,"LI",{});var uLe=s(Pf);Tae=n(uLe,"STRONG",{});var nZr=s(Tae);CYe=r(nZr,"marian"),nZr.forEach(t),wYe=r(uLe," \u2014 "),iR=n(uLe,"A",{href:!0});var sZr=s(iR);AYe=r(sZr,"MarianConfig"),sZr.forEach(t),LYe=r(uLe," (Marian model)"),uLe.forEach(t),yYe=i(L),Bf=n(L,"LI",{});var pLe=s(Bf);Mae=n(pLe,"STRONG",{});var lZr=s(Mae);xYe=r(lZr,"maskformer"),lZr.forEach(t),$Ye=r(pLe," \u2014 "),dR=n(pLe,"A",{href:!0});var iZr=s(dR);kYe=r(iZr,"MaskFormerConfig"),iZr.forEach(t),SYe=r(pLe," (MaskFormer model)"),pLe.forEach(t),RYe=i(L),If=n(L,"LI",{});var _Le=s(If);Eae=n(_Le,"STRONG",{});var dZr=s(Eae);PYe=r(dZr,"mbart"),dZr.forEach(t),BYe=r(_Le," \u2014 "),cR=n(_Le,"A",{href:!0});var cZr=s(cR);IYe=r(cZr,"MBartConfig"),cZr.forEach(t),NYe=r(_Le," (mBART model)"),_Le.forEach(t),qYe=i(L),Nf=n(L,"LI",{});var bLe=s(Nf);Cae=n(bLe,"STRONG",{});var mZr=s(Cae);jYe=r(mZr,"mctct"),mZr.forEach(t),DYe=r(bLe," \u2014 "),mR=n(bLe,"A",{href:!0});var fZr=s(mR);GYe=r(fZr,"MCTCTConfig"),fZr.forEach(t),OYe=r(bLe," (M-CTC-T model)"),bLe.forEach(t),VYe=i(L),qf=n(L,"LI",{});var vLe=s(qf);wae=n(vLe,"STRONG",{});var gZr=s(wae);XYe=r(gZr,"megatron-bert"),gZr.forEach(t),zYe=r(vLe," \u2014 "),fR=n(vLe,"A",{href:!0});var hZr=s(fR);QYe=r(hZr,"MegatronBertConfig"),hZr.forEach(t),WYe=r(vLe," (Megatron-BERT model)"),vLe.forEach(t),HYe=i(L),jf=n(L,"LI",{});var FLe=s(jf);Aae=n(FLe,"STRONG",{});var uZr=s(Aae);UYe=r(uZr,"mobilebert"),uZr.forEach(t),JYe=r(FLe," \u2014 "),gR=n(FLe,"A",{href:!0});var pZr=s(gR);YYe=r(pZr,"MobileBertConfig"),pZr.forEach(t),KYe=r(FLe," (MobileBERT model)"),FLe.forEach(t),ZYe=i(L),Df=n(L,"LI",{});var TLe=s(Df);Lae=n(TLe,"STRONG",{});var _Zr=s(Lae);eKe=r(_Zr,"mpnet"),_Zr.forEach(t),oKe=r(TLe," \u2014 "),hR=n(TLe,"A",{href:!0});var bZr=s(hR);rKe=r(bZr,"MPNetConfig"),bZr.forEach(t),tKe=r(TLe," (MPNet model)"),TLe.forEach(t),aKe=i(L),Gf=n(L,"LI",{});var MLe=s(Gf);yae=n(MLe,"STRONG",{});var vZr=s(yae);nKe=r(vZr,"mt5"),vZr.forEach(t),sKe=r(MLe," \u2014 "),uR=n(MLe,"A",{href:!0});var FZr=s(uR);lKe=r(FZr,"MT5Config"),FZr.forEach(t),iKe=r(MLe," (MT5 model)"),MLe.forEach(t),dKe=i(L),Of=n(L,"LI",{});var ELe=s(Of);xae=n(ELe,"STRONG",{});var TZr=s(xae);cKe=r(TZr,"nezha"),TZr.forEach(t),mKe=r(ELe," \u2014 "),pR=n(ELe,"A",{href:!0});var MZr=s(pR);fKe=r(MZr,"NezhaConfig"),MZr.forEach(t),gKe=r(ELe," (Nezha model)"),ELe.forEach(t),hKe=i(L),Vf=n(L,"LI",{});var CLe=s(Vf);$ae=n(CLe,"STRONG",{});var EZr=s($ae);uKe=r(EZr,"nystromformer"),EZr.forEach(t),pKe=r(CLe," \u2014 "),_R=n(CLe,"A",{href:!0});var CZr=s(_R);_Ke=r(CZr,"NystromformerConfig"),CZr.forEach(t),bKe=r(CLe," (Nystr\xF6mformer model)"),CLe.forEach(t),vKe=i(L),Xf=n(L,"LI",{});var wLe=s(Xf);kae=n(wLe,"STRONG",{});var wZr=s(kae);FKe=r(wZr,"openai-gpt"),wZr.forEach(t),TKe=r(wLe," \u2014 "),bR=n(wLe,"A",{href:!0});var AZr=s(bR);MKe=r(AZr,"OpenAIGPTConfig"),AZr.forEach(t),EKe=r(wLe," (OpenAI GPT model)"),wLe.forEach(t),CKe=i(L),zf=n(L,"LI",{});var ALe=s(zf);Sae=n(ALe,"STRONG",{});var LZr=s(Sae);wKe=r(LZr,"opt"),LZr.forEach(t),AKe=r(ALe," \u2014 "),vR=n(ALe,"A",{href:!0});var yZr=s(vR);LKe=r(yZr,"OPTConfig"),yZr.forEach(t),yKe=r(ALe," (OPT model)"),ALe.forEach(t),xKe=i(L),Qf=n(L,"LI",{});var LLe=s(Qf);Rae=n(LLe,"STRONG",{});var xZr=s(Rae);$Ke=r(xZr,"pegasus"),xZr.forEach(t),kKe=r(LLe," \u2014 "),FR=n(LLe,"A",{href:!0});var $Zr=s(FR);SKe=r($Zr,"PegasusConfig"),$Zr.forEach(t),RKe=r(LLe," (Pegasus model)"),LLe.forEach(t),PKe=i(L),Wf=n(L,"LI",{});var yLe=s(Wf);Pae=n(yLe,"STRONG",{});var kZr=s(Pae);BKe=r(kZr,"perceiver"),kZr.forEach(t),IKe=r(yLe," \u2014 "),TR=n(yLe,"A",{href:!0});var SZr=s(TR);NKe=r(SZr,"PerceiverConfig"),SZr.forEach(t),qKe=r(yLe," (Perceiver model)"),yLe.forEach(t),jKe=i(L),Hf=n(L,"LI",{});var xLe=s(Hf);Bae=n(xLe,"STRONG",{});var RZr=s(Bae);DKe=r(RZr,"plbart"),RZr.forEach(t),GKe=r(xLe," \u2014 "),MR=n(xLe,"A",{href:!0});var PZr=s(MR);OKe=r(PZr,"PLBartConfig"),PZr.forEach(t),VKe=r(xLe," (PLBart model)"),xLe.forEach(t),XKe=i(L),Uf=n(L,"LI",{});var $Le=s(Uf);Iae=n($Le,"STRONG",{});var BZr=s(Iae);zKe=r(BZr,"poolformer"),BZr.forEach(t),QKe=r($Le," \u2014 "),ER=n($Le,"A",{href:!0});var IZr=s(ER);WKe=r(IZr,"PoolFormerConfig"),IZr.forEach(t),HKe=r($Le," (PoolFormer model)"),$Le.forEach(t),UKe=i(L),Jf=n(L,"LI",{});var kLe=s(Jf);Nae=n(kLe,"STRONG",{});var NZr=s(Nae);JKe=r(NZr,"prophetnet"),NZr.forEach(t),YKe=r(kLe," \u2014 "),CR=n(kLe,"A",{href:!0});var qZr=s(CR);KKe=r(qZr,"ProphetNetConfig"),qZr.forEach(t),ZKe=r(kLe," (ProphetNet model)"),kLe.forEach(t),eZe=i(L),Yf=n(L,"LI",{});var SLe=s(Yf);qae=n(SLe,"STRONG",{});var jZr=s(qae);oZe=r(jZr,"qdqbert"),jZr.forEach(t),rZe=r(SLe," \u2014 "),wR=n(SLe,"A",{href:!0});var DZr=s(wR);tZe=r(DZr,"QDQBertConfig"),DZr.forEach(t),aZe=r(SLe," (QDQBert model)"),SLe.forEach(t),nZe=i(L),Kf=n(L,"LI",{});var RLe=s(Kf);jae=n(RLe,"STRONG",{});var GZr=s(jae);sZe=r(GZr,"rag"),GZr.forEach(t),lZe=r(RLe," \u2014 "),AR=n(RLe,"A",{href:!0});var OZr=s(AR);iZe=r(OZr,"RagConfig"),OZr.forEach(t),dZe=r(RLe," (RAG model)"),RLe.forEach(t),cZe=i(L),Zf=n(L,"LI",{});var PLe=s(Zf);Dae=n(PLe,"STRONG",{});var VZr=s(Dae);mZe=r(VZr,"realm"),VZr.forEach(t),fZe=r(PLe," \u2014 "),LR=n(PLe,"A",{href:!0});var XZr=s(LR);gZe=r(XZr,"RealmConfig"),XZr.forEach(t),hZe=r(PLe," (REALM model)"),PLe.forEach(t),uZe=i(L),eg=n(L,"LI",{});var BLe=s(eg);Gae=n(BLe,"STRONG",{});var zZr=s(Gae);pZe=r(zZr,"reformer"),zZr.forEach(t),_Ze=r(BLe," \u2014 "),yR=n(BLe,"A",{href:!0});var QZr=s(yR);bZe=r(QZr,"ReformerConfig"),QZr.forEach(t),vZe=r(BLe," (Reformer model)"),BLe.forEach(t),FZe=i(L),og=n(L,"LI",{});var ILe=s(og);Oae=n(ILe,"STRONG",{});var WZr=s(Oae);TZe=r(WZr,"regnet"),WZr.forEach(t),MZe=r(ILe," \u2014 "),xR=n(ILe,"A",{href:!0});var HZr=s(xR);EZe=r(HZr,"RegNetConfig"),HZr.forEach(t),CZe=r(ILe," (RegNet model)"),ILe.forEach(t),wZe=i(L),rg=n(L,"LI",{});var NLe=s(rg);Vae=n(NLe,"STRONG",{});var UZr=s(Vae);AZe=r(UZr,"rembert"),UZr.forEach(t),LZe=r(NLe," \u2014 "),$R=n(NLe,"A",{href:!0});var JZr=s($R);yZe=r(JZr,"RemBertConfig"),JZr.forEach(t),xZe=r(NLe," (RemBERT model)"),NLe.forEach(t),$Ze=i(L),tg=n(L,"LI",{});var qLe=s(tg);Xae=n(qLe,"STRONG",{});var YZr=s(Xae);kZe=r(YZr,"resnet"),YZr.forEach(t),SZe=r(qLe," \u2014 "),kR=n(qLe,"A",{href:!0});var KZr=s(kR);RZe=r(KZr,"ResNetConfig"),KZr.forEach(t),PZe=r(qLe," (ResNet model)"),qLe.forEach(t),BZe=i(L),ag=n(L,"LI",{});var jLe=s(ag);zae=n(jLe,"STRONG",{});var ZZr=s(zae);IZe=r(ZZr,"retribert"),ZZr.forEach(t),NZe=r(jLe," \u2014 "),SR=n(jLe,"A",{href:!0});var eet=s(SR);qZe=r(eet,"RetriBertConfig"),eet.forEach(t),jZe=r(jLe," (RetriBERT model)"),jLe.forEach(t),DZe=i(L),ng=n(L,"LI",{});var DLe=s(ng);Qae=n(DLe,"STRONG",{});var oet=s(Qae);GZe=r(oet,"roberta"),oet.forEach(t),OZe=r(DLe," \u2014 "),RR=n(DLe,"A",{href:!0});var ret=s(RR);VZe=r(ret,"RobertaConfig"),ret.forEach(t),XZe=r(DLe," (RoBERTa model)"),DLe.forEach(t),zZe=i(L),sg=n(L,"LI",{});var GLe=s(sg);Wae=n(GLe,"STRONG",{});var tet=s(Wae);QZe=r(tet,"roformer"),tet.forEach(t),WZe=r(GLe," \u2014 "),PR=n(GLe,"A",{href:!0});var aet=s(PR);HZe=r(aet,"RoFormerConfig"),aet.forEach(t),UZe=r(GLe," (RoFormer model)"),GLe.forEach(t),JZe=i(L),lg=n(L,"LI",{});var OLe=s(lg);Hae=n(OLe,"STRONG",{});var net=s(Hae);YZe=r(net,"segformer"),net.forEach(t),KZe=r(OLe," \u2014 "),BR=n(OLe,"A",{href:!0});var set=s(BR);ZZe=r(set,"SegformerConfig"),set.forEach(t),eeo=r(OLe," (SegFormer model)"),OLe.forEach(t),oeo=i(L),ig=n(L,"LI",{});var VLe=s(ig);Uae=n(VLe,"STRONG",{});var iet=s(Uae);reo=r(iet,"sew"),iet.forEach(t),teo=r(VLe," \u2014 "),IR=n(VLe,"A",{href:!0});var det=s(IR);aeo=r(det,"SEWConfig"),det.forEach(t),neo=r(VLe," (SEW model)"),VLe.forEach(t),seo=i(L),dg=n(L,"LI",{});var XLe=s(dg);Jae=n(XLe,"STRONG",{});var cet=s(Jae);leo=r(cet,"sew-d"),cet.forEach(t),ieo=r(XLe," \u2014 "),NR=n(XLe,"A",{href:!0});var met=s(NR);deo=r(met,"SEWDConfig"),met.forEach(t),ceo=r(XLe," (SEW-D model)"),XLe.forEach(t),meo=i(L),cg=n(L,"LI",{});var zLe=s(cg);Yae=n(zLe,"STRONG",{});var fet=s(Yae);feo=r(fet,"speech-encoder-decoder"),fet.forEach(t),geo=r(zLe," \u2014 "),qR=n(zLe,"A",{href:!0});var get=s(qR);heo=r(get,"SpeechEncoderDecoderConfig"),get.forEach(t),ueo=r(zLe," (Speech Encoder decoder model)"),zLe.forEach(t),peo=i(L),mg=n(L,"LI",{});var QLe=s(mg);Kae=n(QLe,"STRONG",{});var het=s(Kae);_eo=r(het,"speech_to_text"),het.forEach(t),beo=r(QLe," \u2014 "),jR=n(QLe,"A",{href:!0});var uet=s(jR);veo=r(uet,"Speech2TextConfig"),uet.forEach(t),Feo=r(QLe," (Speech2Text model)"),QLe.forEach(t),Teo=i(L),fg=n(L,"LI",{});var WLe=s(fg);Zae=n(WLe,"STRONG",{});var pet=s(Zae);Meo=r(pet,"speech_to_text_2"),pet.forEach(t),Eeo=r(WLe," \u2014 "),DR=n(WLe,"A",{href:!0});var _et=s(DR);Ceo=r(_et,"Speech2Text2Config"),_et.forEach(t),weo=r(WLe," (Speech2Text2 model)"),WLe.forEach(t),Aeo=i(L),gg=n(L,"LI",{});var HLe=s(gg);ene=n(HLe,"STRONG",{});var bet=s(ene);Leo=r(bet,"splinter"),bet.forEach(t),yeo=r(HLe," \u2014 "),GR=n(HLe,"A",{href:!0});var vet=s(GR);xeo=r(vet,"SplinterConfig"),vet.forEach(t),$eo=r(HLe," (Splinter model)"),HLe.forEach(t),keo=i(L),hg=n(L,"LI",{});var ULe=s(hg);one=n(ULe,"STRONG",{});var Fet=s(one);Seo=r(Fet,"squeezebert"),Fet.forEach(t),Reo=r(ULe," \u2014 "),OR=n(ULe,"A",{href:!0});var Tet=s(OR);Peo=r(Tet,"SqueezeBertConfig"),Tet.forEach(t),Beo=r(ULe," (SqueezeBERT model)"),ULe.forEach(t),Ieo=i(L),ug=n(L,"LI",{});var JLe=s(ug);rne=n(JLe,"STRONG",{});var Met=s(rne);Neo=r(Met,"swin"),Met.forEach(t),qeo=r(JLe," \u2014 "),VR=n(JLe,"A",{href:!0});var Eet=s(VR);jeo=r(Eet,"SwinConfig"),Eet.forEach(t),Deo=r(JLe," (Swin Transformer model)"),JLe.forEach(t),Geo=i(L),pg=n(L,"LI",{});var YLe=s(pg);tne=n(YLe,"STRONG",{});var Cet=s(tne);Oeo=r(Cet,"t5"),Cet.forEach(t),Veo=r(YLe," \u2014 "),XR=n(YLe,"A",{href:!0});var wet=s(XR);Xeo=r(wet,"T5Config"),wet.forEach(t),zeo=r(YLe," (T5 model)"),YLe.forEach(t),Qeo=i(L),_g=n(L,"LI",{});var KLe=s(_g);ane=n(KLe,"STRONG",{});var Aet=s(ane);Weo=r(Aet,"tapas"),Aet.forEach(t),Heo=r(KLe," \u2014 "),zR=n(KLe,"A",{href:!0});var Let=s(zR);Ueo=r(Let,"TapasConfig"),Let.forEach(t),Jeo=r(KLe," (TAPAS model)"),KLe.forEach(t),Yeo=i(L),bg=n(L,"LI",{});var ZLe=s(bg);nne=n(ZLe,"STRONG",{});var yet=s(nne);Keo=r(yet,"trajectory_transformer"),yet.forEach(t),Zeo=r(ZLe," \u2014 "),QR=n(ZLe,"A",{href:!0});var xet=s(QR);eoo=r(xet,"TrajectoryTransformerConfig"),xet.forEach(t),ooo=r(ZLe," (Trajectory Transformer model)"),ZLe.forEach(t),roo=i(L),vg=n(L,"LI",{});var eye=s(vg);sne=n(eye,"STRONG",{});var $et=s(sne);too=r($et,"transfo-xl"),$et.forEach(t),aoo=r(eye," \u2014 "),WR=n(eye,"A",{href:!0});var ket=s(WR);noo=r(ket,"TransfoXLConfig"),ket.forEach(t),soo=r(eye," (Transformer-XL model)"),eye.forEach(t),loo=i(L),Fg=n(L,"LI",{});var oye=s(Fg);lne=n(oye,"STRONG",{});var Set=s(lne);ioo=r(Set,"trocr"),Set.forEach(t),doo=r(oye," \u2014 "),HR=n(oye,"A",{href:!0});var Ret=s(HR);coo=r(Ret,"TrOCRConfig"),Ret.forEach(t),moo=r(oye," (TrOCR model)"),oye.forEach(t),foo=i(L),Tg=n(L,"LI",{});var rye=s(Tg);ine=n(rye,"STRONG",{});var Pet=s(ine);goo=r(Pet,"unispeech"),Pet.forEach(t),hoo=r(rye," \u2014 "),UR=n(rye,"A",{href:!0});var Bet=s(UR);uoo=r(Bet,"UniSpeechConfig"),Bet.forEach(t),poo=r(rye," (UniSpeech model)"),rye.forEach(t),_oo=i(L),Mg=n(L,"LI",{});var tye=s(Mg);dne=n(tye,"STRONG",{});var Iet=s(dne);boo=r(Iet,"unispeech-sat"),Iet.forEach(t),voo=r(tye," \u2014 "),JR=n(tye,"A",{href:!0});var Net=s(JR);Foo=r(Net,"UniSpeechSatConfig"),Net.forEach(t),Too=r(tye," (UniSpeechSat model)"),tye.forEach(t),Moo=i(L),Eg=n(L,"LI",{});var aye=s(Eg);cne=n(aye,"STRONG",{});var qet=s(cne);Eoo=r(qet,"van"),qet.forEach(t),Coo=r(aye," \u2014 "),YR=n(aye,"A",{href:!0});var jet=s(YR);woo=r(jet,"VanConfig"),jet.forEach(t),Aoo=r(aye," (VAN model)"),aye.forEach(t),Loo=i(L),Cg=n(L,"LI",{});var nye=s(Cg);mne=n(nye,"STRONG",{});var Det=s(mne);yoo=r(Det,"vilt"),Det.forEach(t),xoo=r(nye," \u2014 "),KR=n(nye,"A",{href:!0});var Get=s(KR);$oo=r(Get,"ViltConfig"),Get.forEach(t),koo=r(nye," (ViLT model)"),nye.forEach(t),Soo=i(L),wg=n(L,"LI",{});var sye=s(wg);fne=n(sye,"STRONG",{});var Oet=s(fne);Roo=r(Oet,"vision-encoder-decoder"),Oet.forEach(t),Poo=r(sye," \u2014 "),ZR=n(sye,"A",{href:!0});var Vet=s(ZR);Boo=r(Vet,"VisionEncoderDecoderConfig"),Vet.forEach(t),Ioo=r(sye," (Vision Encoder decoder model)"),sye.forEach(t),Noo=i(L),Ag=n(L,"LI",{});var lye=s(Ag);gne=n(lye,"STRONG",{});var Xet=s(gne);qoo=r(Xet,"vision-text-dual-encoder"),Xet.forEach(t),joo=r(lye," \u2014 "),eP=n(lye,"A",{href:!0});var zet=s(eP);Doo=r(zet,"VisionTextDualEncoderConfig"),zet.forEach(t),Goo=r(lye," (VisionTextDualEncoder model)"),lye.forEach(t),Ooo=i(L),Lg=n(L,"LI",{});var iye=s(Lg);hne=n(iye,"STRONG",{});var Qet=s(hne);Voo=r(Qet,"visual_bert"),Qet.forEach(t),Xoo=r(iye," \u2014 "),oP=n(iye,"A",{href:!0});var Wet=s(oP);zoo=r(Wet,"VisualBertConfig"),Wet.forEach(t),Qoo=r(iye," (VisualBERT model)"),iye.forEach(t),Woo=i(L),yg=n(L,"LI",{});var dye=s(yg);une=n(dye,"STRONG",{});var Het=s(une);Hoo=r(Het,"vit"),Het.forEach(t),Uoo=r(dye," \u2014 "),rP=n(dye,"A",{href:!0});var Uet=s(rP);Joo=r(Uet,"ViTConfig"),Uet.forEach(t),Yoo=r(dye," (ViT model)"),dye.forEach(t),Koo=i(L),xg=n(L,"LI",{});var cye=s(xg);pne=n(cye,"STRONG",{});var Jet=s(pne);Zoo=r(Jet,"vit_mae"),Jet.forEach(t),ero=r(cye," \u2014 "),tP=n(cye,"A",{href:!0});var Yet=s(tP);oro=r(Yet,"ViTMAEConfig"),Yet.forEach(t),rro=r(cye," (ViTMAE model)"),cye.forEach(t),tro=i(L),$g=n(L,"LI",{});var mye=s($g);_ne=n(mye,"STRONG",{});var Ket=s(_ne);aro=r(Ket,"wav2vec2"),Ket.forEach(t),nro=r(mye," \u2014 "),aP=n(mye,"A",{href:!0});var Zet=s(aP);sro=r(Zet,"Wav2Vec2Config"),Zet.forEach(t),lro=r(mye," (Wav2Vec2 model)"),mye.forEach(t),iro=i(L),kg=n(L,"LI",{});var fye=s(kg);bne=n(fye,"STRONG",{});var eot=s(bne);dro=r(eot,"wav2vec2-conformer"),eot.forEach(t),cro=r(fye," \u2014 "),nP=n(fye,"A",{href:!0});var oot=s(nP);mro=r(oot,"Wav2Vec2ConformerConfig"),oot.forEach(t),fro=r(fye," (Wav2Vec2-Conformer model)"),fye.forEach(t),gro=i(L),Sg=n(L,"LI",{});var gye=s(Sg);vne=n(gye,"STRONG",{});var rot=s(vne);hro=r(rot,"wavlm"),rot.forEach(t),uro=r(gye," \u2014 "),sP=n(gye,"A",{href:!0});var tot=s(sP);pro=r(tot,"WavLMConfig"),tot.forEach(t),_ro=r(gye," (WavLM model)"),gye.forEach(t),bro=i(L),Rg=n(L,"LI",{});var hye=s(Rg);Fne=n(hye,"STRONG",{});var aot=s(Fne);vro=r(aot,"xglm"),aot.forEach(t),Fro=r(hye," \u2014 "),lP=n(hye,"A",{href:!0});var not=s(lP);Tro=r(not,"XGLMConfig"),not.forEach(t),Mro=r(hye," (XGLM model)"),hye.forEach(t),Ero=i(L),Pg=n(L,"LI",{});var uye=s(Pg);Tne=n(uye,"STRONG",{});var sot=s(Tne);Cro=r(sot,"xlm"),sot.forEach(t),wro=r(uye," \u2014 "),iP=n(uye,"A",{href:!0});var lot=s(iP);Aro=r(lot,"XLMConfig"),lot.forEach(t),Lro=r(uye," (XLM model)"),uye.forEach(t),yro=i(L),Bg=n(L,"LI",{});var pye=s(Bg);Mne=n(pye,"STRONG",{});var iot=s(Mne);xro=r(iot,"xlm-prophetnet"),iot.forEach(t),$ro=r(pye," \u2014 "),dP=n(pye,"A",{href:!0});var dot=s(dP);kro=r(dot,"XLMProphetNetConfig"),dot.forEach(t),Sro=r(pye," (XLM-ProphetNet model)"),pye.forEach(t),Rro=i(L),Ig=n(L,"LI",{});var _ye=s(Ig);Ene=n(_ye,"STRONG",{});var cot=s(Ene);Pro=r(cot,"xlm-roberta"),cot.forEach(t),Bro=r(_ye," \u2014 "),cP=n(_ye,"A",{href:!0});var mot=s(cP);Iro=r(mot,"XLMRobertaConfig"),mot.forEach(t),Nro=r(_ye," (XLM-RoBERTa model)"),_ye.forEach(t),qro=i(L),Ng=n(L,"LI",{});var bye=s(Ng);Cne=n(bye,"STRONG",{});var fot=s(Cne);jro=r(fot,"xlm-roberta-xl"),fot.forEach(t),Dro=r(bye," \u2014 "),mP=n(bye,"A",{href:!0});var got=s(mP);Gro=r(got,"XLMRobertaXLConfig"),got.forEach(t),Oro=r(bye," (XLM-RoBERTa-XL model)"),bye.forEach(t),Vro=i(L),qg=n(L,"LI",{});var vye=s(qg);wne=n(vye,"STRONG",{});var hot=s(wne);Xro=r(hot,"xlnet"),hot.forEach(t),zro=r(vye," \u2014 "),fP=n(vye,"A",{href:!0});var uot=s(fP);Qro=r(uot,"XLNetConfig"),uot.forEach(t),Wro=r(vye," (XLNet model)"),vye.forEach(t),Hro=i(L),jg=n(L,"LI",{});var Fye=s(jg);Ane=n(Fye,"STRONG",{});var pot=s(Ane);Uro=r(pot,"yolos"),pot.forEach(t),Jro=r(Fye," \u2014 "),gP=n(Fye,"A",{href:!0});var _ot=s(gP);Yro=r(_ot,"YolosConfig"),_ot.forEach(t),Kro=r(Fye," (YOLOS model)"),Fye.forEach(t),Zro=i(L),Dg=n(L,"LI",{});var Tye=s(Dg);Lne=n(Tye,"STRONG",{});var bot=s(Lne);eto=r(bot,"yoso"),bot.forEach(t),oto=r(Tye," \u2014 "),hP=n(Tye,"A",{href:!0});var vot=s(hP);rto=r(vot,"YosoConfig"),vot.forEach(t),tto=r(Tye," (YOSO model)"),Tye.forEach(t),L.forEach(t),ato=i(tt),T(Gg.$$.fragment,tt),tt.forEach(t),nto=i(rt),Og=n(rt,"DIV",{class:!0});var zVe=s(Og);T(Iy.$$.fragment,zVe),sto=i(zVe),yne=n(zVe,"P",{});var Fot=s(yne);lto=r(Fot,"Register a new configuration for this class."),Fot.forEach(t),zVe.forEach(t),rt.forEach(t),QGe=i(m),ki=n(m,"H2",{class:!0});var QVe=s(ki);Vg=n(QVe,"A",{id:!0,class:!0,href:!0});var Tot=s(Vg);xne=n(Tot,"SPAN",{});var Mot=s(xne);T(Ny.$$.fragment,Mot),Mot.forEach(t),Tot.forEach(t),ito=i(QVe),$ne=n(QVe,"SPAN",{});var Eot=s($ne);dto=r(Eot,"AutoTokenizer"),Eot.forEach(t),QVe.forEach(t),WGe=i(m),Ao=n(m,"DIV",{class:!0});var Ws=s(Ao);T(qy.$$.fragment,Ws),cto=i(Ws),jy=n(Ws,"P",{});var WVe=s(jy);mto=r(WVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),uP=n(WVe,"A",{href:!0});var Cot=s(uP);fto=r(Cot,"AutoTokenizer.from_pretrained()"),Cot.forEach(t),gto=r(WVe," class method."),WVe.forEach(t),hto=i(Ws),Dy=n(Ws,"P",{});var HVe=s(Dy);uto=r(HVe,"This class cannot be instantiated directly using "),kne=n(HVe,"CODE",{});var wot=s(kne);pto=r(wot,"__init__()"),wot.forEach(t),_to=r(HVe," (throws an error)."),HVe.forEach(t),bto=i(Ws),Lr=n(Ws,"DIV",{class:!0});var Hs=s(Lr);T(Gy.$$.fragment,Hs),vto=i(Hs),Sne=n(Hs,"P",{});var Aot=s(Sne);Fto=r(Aot,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Aot.forEach(t),Tto=i(Hs),ka=n(Hs,"P",{});var x6=s(ka);Mto=r(x6,"The tokenizer class to instantiate is selected based on the "),Rne=n(x6,"CODE",{});var Lot=s(Rne);Eto=r(Lot,"model_type"),Lot.forEach(t),Cto=r(x6,` property of the config object (either
passed as an argument or loaded from `),Pne=n(x6,"CODE",{});var yot=s(Pne);wto=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),Ato=r(x6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=n(x6,"CODE",{});var xot=s(Bne);Lto=r(xot,"pretrained_model_name_or_path"),xot.forEach(t),yto=r(x6,":"),x6.forEach(t),xto=i(Hs),k=n(Hs,"UL",{});var S=s(k);qn=n(S,"LI",{});var W$=s(qn);Ine=n(W$,"STRONG",{});var $ot=s(Ine);$to=r($ot,"albert"),$ot.forEach(t),kto=r(W$," \u2014 "),pP=n(W$,"A",{href:!0});var kot=s(pP);Sto=r(kot,"AlbertTokenizer"),kot.forEach(t),Rto=r(W$," or "),_P=n(W$,"A",{href:!0});var Sot=s(_P);Pto=r(Sot,"AlbertTokenizerFast"),Sot.forEach(t),Bto=r(W$," (ALBERT model)"),W$.forEach(t),Ito=i(S),jn=n(S,"LI",{});var H$=s(jn);Nne=n(H$,"STRONG",{});var Rot=s(Nne);Nto=r(Rot,"bart"),Rot.forEach(t),qto=r(H$," \u2014 "),bP=n(H$,"A",{href:!0});var Pot=s(bP);jto=r(Pot,"BartTokenizer"),Pot.forEach(t),Dto=r(H$," or "),vP=n(H$,"A",{href:!0});var Bot=s(vP);Gto=r(Bot,"BartTokenizerFast"),Bot.forEach(t),Oto=r(H$," (BART model)"),H$.forEach(t),Vto=i(S),Dn=n(S,"LI",{});var U$=s(Dn);qne=n(U$,"STRONG",{});var Iot=s(qne);Xto=r(Iot,"barthez"),Iot.forEach(t),zto=r(U$," \u2014 "),FP=n(U$,"A",{href:!0});var Not=s(FP);Qto=r(Not,"BarthezTokenizer"),Not.forEach(t),Wto=r(U$," or "),TP=n(U$,"A",{href:!0});var qot=s(TP);Hto=r(qot,"BarthezTokenizerFast"),qot.forEach(t),Uto=r(U$," (BARThez model)"),U$.forEach(t),Jto=i(S),Xg=n(S,"LI",{});var Mye=s(Xg);jne=n(Mye,"STRONG",{});var jot=s(jne);Yto=r(jot,"bartpho"),jot.forEach(t),Kto=r(Mye," \u2014 "),MP=n(Mye,"A",{href:!0});var Dot=s(MP);Zto=r(Dot,"BartphoTokenizer"),Dot.forEach(t),eao=r(Mye," (BARTpho model)"),Mye.forEach(t),oao=i(S),Gn=n(S,"LI",{});var J$=s(Gn);Dne=n(J$,"STRONG",{});var Got=s(Dne);rao=r(Got,"bert"),Got.forEach(t),tao=r(J$," \u2014 "),EP=n(J$,"A",{href:!0});var Oot=s(EP);aao=r(Oot,"BertTokenizer"),Oot.forEach(t),nao=r(J$," or "),CP=n(J$,"A",{href:!0});var Vot=s(CP);sao=r(Vot,"BertTokenizerFast"),Vot.forEach(t),lao=r(J$," (BERT model)"),J$.forEach(t),iao=i(S),zg=n(S,"LI",{});var Eye=s(zg);Gne=n(Eye,"STRONG",{});var Xot=s(Gne);dao=r(Xot,"bert-generation"),Xot.forEach(t),cao=r(Eye," \u2014 "),wP=n(Eye,"A",{href:!0});var zot=s(wP);mao=r(zot,"BertGenerationTokenizer"),zot.forEach(t),fao=r(Eye," (Bert Generation model)"),Eye.forEach(t),gao=i(S),Qg=n(S,"LI",{});var Cye=s(Qg);One=n(Cye,"STRONG",{});var Qot=s(One);hao=r(Qot,"bert-japanese"),Qot.forEach(t),uao=r(Cye," \u2014 "),AP=n(Cye,"A",{href:!0});var Wot=s(AP);pao=r(Wot,"BertJapaneseTokenizer"),Wot.forEach(t),_ao=r(Cye," (BertJapanese model)"),Cye.forEach(t),bao=i(S),Wg=n(S,"LI",{});var wye=s(Wg);Vne=n(wye,"STRONG",{});var Hot=s(Vne);vao=r(Hot,"bertweet"),Hot.forEach(t),Fao=r(wye," \u2014 "),LP=n(wye,"A",{href:!0});var Uot=s(LP);Tao=r(Uot,"BertweetTokenizer"),Uot.forEach(t),Mao=r(wye," (BERTweet model)"),wye.forEach(t),Eao=i(S),On=n(S,"LI",{});var Y$=s(On);Xne=n(Y$,"STRONG",{});var Jot=s(Xne);Cao=r(Jot,"big_bird"),Jot.forEach(t),wao=r(Y$," \u2014 "),yP=n(Y$,"A",{href:!0});var Yot=s(yP);Aao=r(Yot,"BigBirdTokenizer"),Yot.forEach(t),Lao=r(Y$," or "),xP=n(Y$,"A",{href:!0});var Kot=s(xP);yao=r(Kot,"BigBirdTokenizerFast"),Kot.forEach(t),xao=r(Y$," (BigBird model)"),Y$.forEach(t),$ao=i(S),Vn=n(S,"LI",{});var K$=s(Vn);zne=n(K$,"STRONG",{});var Zot=s(zne);kao=r(Zot,"bigbird_pegasus"),Zot.forEach(t),Sao=r(K$," \u2014 "),$P=n(K$,"A",{href:!0});var ert=s($P);Rao=r(ert,"PegasusTokenizer"),ert.forEach(t),Pao=r(K$," or "),kP=n(K$,"A",{href:!0});var ort=s(kP);Bao=r(ort,"PegasusTokenizerFast"),ort.forEach(t),Iao=r(K$," (BigBird-Pegasus model)"),K$.forEach(t),Nao=i(S),Xn=n(S,"LI",{});var Z$=s(Xn);Qne=n(Z$,"STRONG",{});var rrt=s(Qne);qao=r(rrt,"blenderbot"),rrt.forEach(t),jao=r(Z$," \u2014 "),SP=n(Z$,"A",{href:!0});var trt=s(SP);Dao=r(trt,"BlenderbotTokenizer"),trt.forEach(t),Gao=r(Z$," or "),RP=n(Z$,"A",{href:!0});var art=s(RP);Oao=r(art,"BlenderbotTokenizerFast"),art.forEach(t),Vao=r(Z$," (Blenderbot model)"),Z$.forEach(t),Xao=i(S),Hg=n(S,"LI",{});var Aye=s(Hg);Wne=n(Aye,"STRONG",{});var nrt=s(Wne);zao=r(nrt,"blenderbot-small"),nrt.forEach(t),Qao=r(Aye," \u2014 "),PP=n(Aye,"A",{href:!0});var srt=s(PP);Wao=r(srt,"BlenderbotSmallTokenizer"),srt.forEach(t),Hao=r(Aye," (BlenderbotSmall model)"),Aye.forEach(t),Uao=i(S),Ug=n(S,"LI",{});var Lye=s(Ug);Hne=n(Lye,"STRONG",{});var lrt=s(Hne);Jao=r(lrt,"bloom"),lrt.forEach(t),Yao=r(Lye," \u2014 "),BP=n(Lye,"A",{href:!0});var irt=s(BP);Kao=r(irt,"BloomTokenizerFast"),irt.forEach(t),Zao=r(Lye," (BLOOM model)"),Lye.forEach(t),eno=i(S),Jg=n(S,"LI",{});var yye=s(Jg);Une=n(yye,"STRONG",{});var drt=s(Une);ono=r(drt,"byt5"),drt.forEach(t),rno=r(yye," \u2014 "),IP=n(yye,"A",{href:!0});var crt=s(IP);tno=r(crt,"ByT5Tokenizer"),crt.forEach(t),ano=r(yye," (ByT5 model)"),yye.forEach(t),nno=i(S),zn=n(S,"LI",{});var ek=s(zn);Jne=n(ek,"STRONG",{});var mrt=s(Jne);sno=r(mrt,"camembert"),mrt.forEach(t),lno=r(ek," \u2014 "),NP=n(ek,"A",{href:!0});var frt=s(NP);ino=r(frt,"CamembertTokenizer"),frt.forEach(t),dno=r(ek," or "),qP=n(ek,"A",{href:!0});var grt=s(qP);cno=r(grt,"CamembertTokenizerFast"),grt.forEach(t),mno=r(ek," (CamemBERT model)"),ek.forEach(t),fno=i(S),Yg=n(S,"LI",{});var xye=s(Yg);Yne=n(xye,"STRONG",{});var hrt=s(Yne);gno=r(hrt,"canine"),hrt.forEach(t),hno=r(xye," \u2014 "),jP=n(xye,"A",{href:!0});var urt=s(jP);uno=r(urt,"CanineTokenizer"),urt.forEach(t),pno=r(xye," (CANINE model)"),xye.forEach(t),_no=i(S),Qn=n(S,"LI",{});var ok=s(Qn);Kne=n(ok,"STRONG",{});var prt=s(Kne);bno=r(prt,"clip"),prt.forEach(t),vno=r(ok," \u2014 "),DP=n(ok,"A",{href:!0});var _rt=s(DP);Fno=r(_rt,"CLIPTokenizer"),_rt.forEach(t),Tno=r(ok," or "),GP=n(ok,"A",{href:!0});var brt=s(GP);Mno=r(brt,"CLIPTokenizerFast"),brt.forEach(t),Eno=r(ok," (CLIP model)"),ok.forEach(t),Cno=i(S),Wn=n(S,"LI",{});var rk=s(Wn);Zne=n(rk,"STRONG",{});var vrt=s(Zne);wno=r(vrt,"convbert"),vrt.forEach(t),Ano=r(rk," \u2014 "),OP=n(rk,"A",{href:!0});var Frt=s(OP);Lno=r(Frt,"ConvBertTokenizer"),Frt.forEach(t),yno=r(rk," or "),VP=n(rk,"A",{href:!0});var Trt=s(VP);xno=r(Trt,"ConvBertTokenizerFast"),Trt.forEach(t),$no=r(rk," (ConvBERT model)"),rk.forEach(t),kno=i(S),Hn=n(S,"LI",{});var tk=s(Hn);ese=n(tk,"STRONG",{});var Mrt=s(ese);Sno=r(Mrt,"cpm"),Mrt.forEach(t),Rno=r(tk," \u2014 "),XP=n(tk,"A",{href:!0});var Ert=s(XP);Pno=r(Ert,"CpmTokenizer"),Ert.forEach(t),Bno=r(tk," or "),zP=n(tk,"A",{href:!0});var Crt=s(zP);Ino=r(Crt,"CpmTokenizerFast"),Crt.forEach(t),Nno=r(tk," (CPM model)"),tk.forEach(t),qno=i(S),Kg=n(S,"LI",{});var $ye=s(Kg);ose=n($ye,"STRONG",{});var wrt=s(ose);jno=r(wrt,"ctrl"),wrt.forEach(t),Dno=r($ye," \u2014 "),QP=n($ye,"A",{href:!0});var Art=s(QP);Gno=r(Art,"CTRLTokenizer"),Art.forEach(t),Ono=r($ye," (CTRL model)"),$ye.forEach(t),Vno=i(S),Un=n(S,"LI",{});var ak=s(Un);rse=n(ak,"STRONG",{});var Lrt=s(rse);Xno=r(Lrt,"data2vec-text"),Lrt.forEach(t),zno=r(ak," \u2014 "),WP=n(ak,"A",{href:!0});var yrt=s(WP);Qno=r(yrt,"RobertaTokenizer"),yrt.forEach(t),Wno=r(ak," or "),HP=n(ak,"A",{href:!0});var xrt=s(HP);Hno=r(xrt,"RobertaTokenizerFast"),xrt.forEach(t),Uno=r(ak," (Data2VecText model)"),ak.forEach(t),Jno=i(S),Jn=n(S,"LI",{});var nk=s(Jn);tse=n(nk,"STRONG",{});var $rt=s(tse);Yno=r($rt,"deberta"),$rt.forEach(t),Kno=r(nk," \u2014 "),UP=n(nk,"A",{href:!0});var krt=s(UP);Zno=r(krt,"DebertaTokenizer"),krt.forEach(t),eso=r(nk," or "),JP=n(nk,"A",{href:!0});var Srt=s(JP);oso=r(Srt,"DebertaTokenizerFast"),Srt.forEach(t),rso=r(nk," (DeBERTa model)"),nk.forEach(t),tso=i(S),Yn=n(S,"LI",{});var sk=s(Yn);ase=n(sk,"STRONG",{});var Rrt=s(ase);aso=r(Rrt,"deberta-v2"),Rrt.forEach(t),nso=r(sk," \u2014 "),YP=n(sk,"A",{href:!0});var Prt=s(YP);sso=r(Prt,"DebertaV2Tokenizer"),Prt.forEach(t),lso=r(sk," or "),KP=n(sk,"A",{href:!0});var Brt=s(KP);iso=r(Brt,"DebertaV2TokenizerFast"),Brt.forEach(t),dso=r(sk," (DeBERTa-v2 model)"),sk.forEach(t),cso=i(S),Kn=n(S,"LI",{});var lk=s(Kn);nse=n(lk,"STRONG",{});var Irt=s(nse);mso=r(Irt,"distilbert"),Irt.forEach(t),fso=r(lk," \u2014 "),ZP=n(lk,"A",{href:!0});var Nrt=s(ZP);gso=r(Nrt,"DistilBertTokenizer"),Nrt.forEach(t),hso=r(lk," or "),eB=n(lk,"A",{href:!0});var qrt=s(eB);uso=r(qrt,"DistilBertTokenizerFast"),qrt.forEach(t),pso=r(lk," (DistilBERT model)"),lk.forEach(t),_so=i(S),Zn=n(S,"LI",{});var ik=s(Zn);sse=n(ik,"STRONG",{});var jrt=s(sse);bso=r(jrt,"dpr"),jrt.forEach(t),vso=r(ik," \u2014 "),oB=n(ik,"A",{href:!0});var Drt=s(oB);Fso=r(Drt,"DPRQuestionEncoderTokenizer"),Drt.forEach(t),Tso=r(ik," or "),rB=n(ik,"A",{href:!0});var Grt=s(rB);Mso=r(Grt,"DPRQuestionEncoderTokenizerFast"),Grt.forEach(t),Eso=r(ik," (DPR model)"),ik.forEach(t),Cso=i(S),es=n(S,"LI",{});var dk=s(es);lse=n(dk,"STRONG",{});var Ort=s(lse);wso=r(Ort,"electra"),Ort.forEach(t),Aso=r(dk," \u2014 "),tB=n(dk,"A",{href:!0});var Vrt=s(tB);Lso=r(Vrt,"ElectraTokenizer"),Vrt.forEach(t),yso=r(dk," or "),aB=n(dk,"A",{href:!0});var Xrt=s(aB);xso=r(Xrt,"ElectraTokenizerFast"),Xrt.forEach(t),$so=r(dk," (ELECTRA model)"),dk.forEach(t),kso=i(S),Zg=n(S,"LI",{});var kye=s(Zg);ise=n(kye,"STRONG",{});var zrt=s(ise);Sso=r(zrt,"flaubert"),zrt.forEach(t),Rso=r(kye," \u2014 "),nB=n(kye,"A",{href:!0});var Qrt=s(nB);Pso=r(Qrt,"FlaubertTokenizer"),Qrt.forEach(t),Bso=r(kye," (FlauBERT model)"),kye.forEach(t),Iso=i(S),os=n(S,"LI",{});var ck=s(os);dse=n(ck,"STRONG",{});var Wrt=s(dse);Nso=r(Wrt,"fnet"),Wrt.forEach(t),qso=r(ck," \u2014 "),sB=n(ck,"A",{href:!0});var Hrt=s(sB);jso=r(Hrt,"FNetTokenizer"),Hrt.forEach(t),Dso=r(ck," or "),lB=n(ck,"A",{href:!0});var Urt=s(lB);Gso=r(Urt,"FNetTokenizerFast"),Urt.forEach(t),Oso=r(ck," (FNet model)"),ck.forEach(t),Vso=i(S),eh=n(S,"LI",{});var Sye=s(eh);cse=n(Sye,"STRONG",{});var Jrt=s(cse);Xso=r(Jrt,"fsmt"),Jrt.forEach(t),zso=r(Sye," \u2014 "),iB=n(Sye,"A",{href:!0});var Yrt=s(iB);Qso=r(Yrt,"FSMTTokenizer"),Yrt.forEach(t),Wso=r(Sye," (FairSeq Machine-Translation model)"),Sye.forEach(t),Hso=i(S),rs=n(S,"LI",{});var mk=s(rs);mse=n(mk,"STRONG",{});var Krt=s(mse);Uso=r(Krt,"funnel"),Krt.forEach(t),Jso=r(mk," \u2014 "),dB=n(mk,"A",{href:!0});var Zrt=s(dB);Yso=r(Zrt,"FunnelTokenizer"),Zrt.forEach(t),Kso=r(mk," or "),cB=n(mk,"A",{href:!0});var ett=s(cB);Zso=r(ett,"FunnelTokenizerFast"),ett.forEach(t),elo=r(mk," (Funnel Transformer model)"),mk.forEach(t),olo=i(S),ts=n(S,"LI",{});var fk=s(ts);fse=n(fk,"STRONG",{});var ott=s(fse);rlo=r(ott,"gpt2"),ott.forEach(t),tlo=r(fk," \u2014 "),mB=n(fk,"A",{href:!0});var rtt=s(mB);alo=r(rtt,"GPT2Tokenizer"),rtt.forEach(t),nlo=r(fk," or "),fB=n(fk,"A",{href:!0});var ttt=s(fB);slo=r(ttt,"GPT2TokenizerFast"),ttt.forEach(t),llo=r(fk," (OpenAI GPT-2 model)"),fk.forEach(t),ilo=i(S),as=n(S,"LI",{});var gk=s(as);gse=n(gk,"STRONG",{});var att=s(gse);dlo=r(att,"gpt_neo"),att.forEach(t),clo=r(gk," \u2014 "),gB=n(gk,"A",{href:!0});var ntt=s(gB);mlo=r(ntt,"GPT2Tokenizer"),ntt.forEach(t),flo=r(gk," or "),hB=n(gk,"A",{href:!0});var stt=s(hB);glo=r(stt,"GPT2TokenizerFast"),stt.forEach(t),hlo=r(gk," (GPT Neo model)"),gk.forEach(t),ulo=i(S),oh=n(S,"LI",{});var Rye=s(oh);hse=n(Rye,"STRONG",{});var ltt=s(hse);plo=r(ltt,"gpt_neox"),ltt.forEach(t),_lo=r(Rye," \u2014 "),uB=n(Rye,"A",{href:!0});var itt=s(uB);blo=r(itt,"GPTNeoXTokenizerFast"),itt.forEach(t),vlo=r(Rye," (GPT NeoX model)"),Rye.forEach(t),Flo=i(S),ns=n(S,"LI",{});var hk=s(ns);use=n(hk,"STRONG",{});var dtt=s(use);Tlo=r(dtt,"gptj"),dtt.forEach(t),Mlo=r(hk," \u2014 "),pB=n(hk,"A",{href:!0});var ctt=s(pB);Elo=r(ctt,"GPT2Tokenizer"),ctt.forEach(t),Clo=r(hk," or "),_B=n(hk,"A",{href:!0});var mtt=s(_B);wlo=r(mtt,"GPT2TokenizerFast"),mtt.forEach(t),Alo=r(hk," (GPT-J model)"),hk.forEach(t),Llo=i(S),ss=n(S,"LI",{});var uk=s(ss);pse=n(uk,"STRONG",{});var ftt=s(pse);ylo=r(ftt,"herbert"),ftt.forEach(t),xlo=r(uk," \u2014 "),bB=n(uk,"A",{href:!0});var gtt=s(bB);$lo=r(gtt,"HerbertTokenizer"),gtt.forEach(t),klo=r(uk," or "),vB=n(uk,"A",{href:!0});var htt=s(vB);Slo=r(htt,"HerbertTokenizerFast"),htt.forEach(t),Rlo=r(uk," (HerBERT model)"),uk.forEach(t),Plo=i(S),rh=n(S,"LI",{});var Pye=s(rh);_se=n(Pye,"STRONG",{});var utt=s(_se);Blo=r(utt,"hubert"),utt.forEach(t),Ilo=r(Pye," \u2014 "),FB=n(Pye,"A",{href:!0});var ptt=s(FB);Nlo=r(ptt,"Wav2Vec2CTCTokenizer"),ptt.forEach(t),qlo=r(Pye," (Hubert model)"),Pye.forEach(t),jlo=i(S),ls=n(S,"LI",{});var pk=s(ls);bse=n(pk,"STRONG",{});var _tt=s(bse);Dlo=r(_tt,"ibert"),_tt.forEach(t),Glo=r(pk," \u2014 "),TB=n(pk,"A",{href:!0});var btt=s(TB);Olo=r(btt,"RobertaTokenizer"),btt.forEach(t),Vlo=r(pk," or "),MB=n(pk,"A",{href:!0});var vtt=s(MB);Xlo=r(vtt,"RobertaTokenizerFast"),vtt.forEach(t),zlo=r(pk," (I-BERT model)"),pk.forEach(t),Qlo=i(S),is=n(S,"LI",{});var _k=s(is);vse=n(_k,"STRONG",{});var Ftt=s(vse);Wlo=r(Ftt,"layoutlm"),Ftt.forEach(t),Hlo=r(_k," \u2014 "),EB=n(_k,"A",{href:!0});var Ttt=s(EB);Ulo=r(Ttt,"LayoutLMTokenizer"),Ttt.forEach(t),Jlo=r(_k," or "),CB=n(_k,"A",{href:!0});var Mtt=s(CB);Ylo=r(Mtt,"LayoutLMTokenizerFast"),Mtt.forEach(t),Klo=r(_k," (LayoutLM model)"),_k.forEach(t),Zlo=i(S),ds=n(S,"LI",{});var bk=s(ds);Fse=n(bk,"STRONG",{});var Ett=s(Fse);eio=r(Ett,"layoutlmv2"),Ett.forEach(t),oio=r(bk," \u2014 "),wB=n(bk,"A",{href:!0});var Ctt=s(wB);rio=r(Ctt,"LayoutLMv2Tokenizer"),Ctt.forEach(t),tio=r(bk," or "),AB=n(bk,"A",{href:!0});var wtt=s(AB);aio=r(wtt,"LayoutLMv2TokenizerFast"),wtt.forEach(t),nio=r(bk," (LayoutLMv2 model)"),bk.forEach(t),sio=i(S),cs=n(S,"LI",{});var vk=s(cs);Tse=n(vk,"STRONG",{});var Att=s(Tse);lio=r(Att,"layoutlmv3"),Att.forEach(t),iio=r(vk," \u2014 "),LB=n(vk,"A",{href:!0});var Ltt=s(LB);dio=r(Ltt,"LayoutLMv3Tokenizer"),Ltt.forEach(t),cio=r(vk," or "),yB=n(vk,"A",{href:!0});var ytt=s(yB);mio=r(ytt,"LayoutLMv3TokenizerFast"),ytt.forEach(t),fio=r(vk," (LayoutLMv3 model)"),vk.forEach(t),gio=i(S),ms=n(S,"LI",{});var Fk=s(ms);Mse=n(Fk,"STRONG",{});var xtt=s(Mse);hio=r(xtt,"layoutxlm"),xtt.forEach(t),uio=r(Fk," \u2014 "),xB=n(Fk,"A",{href:!0});var $tt=s(xB);pio=r($tt,"LayoutXLMTokenizer"),$tt.forEach(t),_io=r(Fk," or "),$B=n(Fk,"A",{href:!0});var ktt=s($B);bio=r(ktt,"LayoutXLMTokenizerFast"),ktt.forEach(t),vio=r(Fk," (LayoutXLM model)"),Fk.forEach(t),Fio=i(S),fs=n(S,"LI",{});var Tk=s(fs);Ese=n(Tk,"STRONG",{});var Stt=s(Ese);Tio=r(Stt,"led"),Stt.forEach(t),Mio=r(Tk," \u2014 "),kB=n(Tk,"A",{href:!0});var Rtt=s(kB);Eio=r(Rtt,"LEDTokenizer"),Rtt.forEach(t),Cio=r(Tk," or "),SB=n(Tk,"A",{href:!0});var Ptt=s(SB);wio=r(Ptt,"LEDTokenizerFast"),Ptt.forEach(t),Aio=r(Tk," (LED model)"),Tk.forEach(t),Lio=i(S),gs=n(S,"LI",{});var Mk=s(gs);Cse=n(Mk,"STRONG",{});var Btt=s(Cse);yio=r(Btt,"longformer"),Btt.forEach(t),xio=r(Mk," \u2014 "),RB=n(Mk,"A",{href:!0});var Itt=s(RB);$io=r(Itt,"LongformerTokenizer"),Itt.forEach(t),kio=r(Mk," or "),PB=n(Mk,"A",{href:!0});var Ntt=s(PB);Sio=r(Ntt,"LongformerTokenizerFast"),Ntt.forEach(t),Rio=r(Mk," (Longformer model)"),Mk.forEach(t),Pio=i(S),hs=n(S,"LI",{});var Ek=s(hs);wse=n(Ek,"STRONG",{});var qtt=s(wse);Bio=r(qtt,"longt5"),qtt.forEach(t),Iio=r(Ek," \u2014 "),BB=n(Ek,"A",{href:!0});var jtt=s(BB);Nio=r(jtt,"T5Tokenizer"),jtt.forEach(t),qio=r(Ek," or "),IB=n(Ek,"A",{href:!0});var Dtt=s(IB);jio=r(Dtt,"T5TokenizerFast"),Dtt.forEach(t),Dio=r(Ek," (LongT5 model)"),Ek.forEach(t),Gio=i(S),th=n(S,"LI",{});var Bye=s(th);Ase=n(Bye,"STRONG",{});var Gtt=s(Ase);Oio=r(Gtt,"luke"),Gtt.forEach(t),Vio=r(Bye," \u2014 "),NB=n(Bye,"A",{href:!0});var Ott=s(NB);Xio=r(Ott,"LukeTokenizer"),Ott.forEach(t),zio=r(Bye," (LUKE model)"),Bye.forEach(t),Qio=i(S),us=n(S,"LI",{});var Ck=s(us);Lse=n(Ck,"STRONG",{});var Vtt=s(Lse);Wio=r(Vtt,"lxmert"),Vtt.forEach(t),Hio=r(Ck," \u2014 "),qB=n(Ck,"A",{href:!0});var Xtt=s(qB);Uio=r(Xtt,"LxmertTokenizer"),Xtt.forEach(t),Jio=r(Ck," or "),jB=n(Ck,"A",{href:!0});var ztt=s(jB);Yio=r(ztt,"LxmertTokenizerFast"),ztt.forEach(t),Kio=r(Ck," (LXMERT model)"),Ck.forEach(t),Zio=i(S),ah=n(S,"LI",{});var Iye=s(ah);yse=n(Iye,"STRONG",{});var Qtt=s(yse);edo=r(Qtt,"m2m_100"),Qtt.forEach(t),odo=r(Iye," \u2014 "),DB=n(Iye,"A",{href:!0});var Wtt=s(DB);rdo=r(Wtt,"M2M100Tokenizer"),Wtt.forEach(t),tdo=r(Iye," (M2M100 model)"),Iye.forEach(t),ado=i(S),nh=n(S,"LI",{});var Nye=s(nh);xse=n(Nye,"STRONG",{});var Htt=s(xse);ndo=r(Htt,"marian"),Htt.forEach(t),sdo=r(Nye," \u2014 "),GB=n(Nye,"A",{href:!0});var Utt=s(GB);ldo=r(Utt,"MarianTokenizer"),Utt.forEach(t),ido=r(Nye," (Marian model)"),Nye.forEach(t),ddo=i(S),ps=n(S,"LI",{});var wk=s(ps);$se=n(wk,"STRONG",{});var Jtt=s($se);cdo=r(Jtt,"mbart"),Jtt.forEach(t),mdo=r(wk," \u2014 "),OB=n(wk,"A",{href:!0});var Ytt=s(OB);fdo=r(Ytt,"MBartTokenizer"),Ytt.forEach(t),gdo=r(wk," or "),VB=n(wk,"A",{href:!0});var Ktt=s(VB);hdo=r(Ktt,"MBartTokenizerFast"),Ktt.forEach(t),udo=r(wk," (mBART model)"),wk.forEach(t),pdo=i(S),_s=n(S,"LI",{});var Ak=s(_s);kse=n(Ak,"STRONG",{});var Ztt=s(kse);_do=r(Ztt,"mbart50"),Ztt.forEach(t),bdo=r(Ak," \u2014 "),XB=n(Ak,"A",{href:!0});var eat=s(XB);vdo=r(eat,"MBart50Tokenizer"),eat.forEach(t),Fdo=r(Ak," or "),zB=n(Ak,"A",{href:!0});var oat=s(zB);Tdo=r(oat,"MBart50TokenizerFast"),oat.forEach(t),Mdo=r(Ak," (mBART-50 model)"),Ak.forEach(t),Edo=i(S),bs=n(S,"LI",{});var Lk=s(bs);Sse=n(Lk,"STRONG",{});var rat=s(Sse);Cdo=r(rat,"megatron-bert"),rat.forEach(t),wdo=r(Lk," \u2014 "),QB=n(Lk,"A",{href:!0});var tat=s(QB);Ado=r(tat,"BertTokenizer"),tat.forEach(t),Ldo=r(Lk," or "),WB=n(Lk,"A",{href:!0});var aat=s(WB);ydo=r(aat,"BertTokenizerFast"),aat.forEach(t),xdo=r(Lk," (Megatron-BERT model)"),Lk.forEach(t),$do=i(S),sh=n(S,"LI",{});var qye=s(sh);Rse=n(qye,"STRONG",{});var nat=s(Rse);kdo=r(nat,"mluke"),nat.forEach(t),Sdo=r(qye," \u2014 "),HB=n(qye,"A",{href:!0});var sat=s(HB);Rdo=r(sat,"MLukeTokenizer"),sat.forEach(t),Pdo=r(qye," (mLUKE model)"),qye.forEach(t),Bdo=i(S),vs=n(S,"LI",{});var yk=s(vs);Pse=n(yk,"STRONG",{});var lat=s(Pse);Ido=r(lat,"mobilebert"),lat.forEach(t),Ndo=r(yk," \u2014 "),UB=n(yk,"A",{href:!0});var iat=s(UB);qdo=r(iat,"MobileBertTokenizer"),iat.forEach(t),jdo=r(yk," or "),JB=n(yk,"A",{href:!0});var dat=s(JB);Ddo=r(dat,"MobileBertTokenizerFast"),dat.forEach(t),Gdo=r(yk," (MobileBERT model)"),yk.forEach(t),Odo=i(S),Fs=n(S,"LI",{});var xk=s(Fs);Bse=n(xk,"STRONG",{});var cat=s(Bse);Vdo=r(cat,"mpnet"),cat.forEach(t),Xdo=r(xk," \u2014 "),YB=n(xk,"A",{href:!0});var mat=s(YB);zdo=r(mat,"MPNetTokenizer"),mat.forEach(t),Qdo=r(xk," or "),KB=n(xk,"A",{href:!0});var fat=s(KB);Wdo=r(fat,"MPNetTokenizerFast"),fat.forEach(t),Hdo=r(xk," (MPNet model)"),xk.forEach(t),Udo=i(S),Ts=n(S,"LI",{});var $k=s(Ts);Ise=n($k,"STRONG",{});var gat=s(Ise);Jdo=r(gat,"mt5"),gat.forEach(t),Ydo=r($k," \u2014 "),ZB=n($k,"A",{href:!0});var hat=s(ZB);Kdo=r(hat,"MT5Tokenizer"),hat.forEach(t),Zdo=r($k," or "),eI=n($k,"A",{href:!0});var uat=s(eI);eco=r(uat,"MT5TokenizerFast"),uat.forEach(t),oco=r($k," (MT5 model)"),$k.forEach(t),rco=i(S),Ms=n(S,"LI",{});var kk=s(Ms);Nse=n(kk,"STRONG",{});var pat=s(Nse);tco=r(pat,"nezha"),pat.forEach(t),aco=r(kk," \u2014 "),oI=n(kk,"A",{href:!0});var _at=s(oI);nco=r(_at,"BertTokenizer"),_at.forEach(t),sco=r(kk," or "),rI=n(kk,"A",{href:!0});var bat=s(rI);lco=r(bat,"BertTokenizerFast"),bat.forEach(t),ico=r(kk," (Nezha model)"),kk.forEach(t),dco=i(S),Es=n(S,"LI",{});var Sk=s(Es);qse=n(Sk,"STRONG",{});var vat=s(qse);cco=r(vat,"nystromformer"),vat.forEach(t),mco=r(Sk," \u2014 "),tI=n(Sk,"A",{href:!0});var Fat=s(tI);fco=r(Fat,"AlbertTokenizer"),Fat.forEach(t),gco=r(Sk," or "),aI=n(Sk,"A",{href:!0});var Tat=s(aI);hco=r(Tat,"AlbertTokenizerFast"),Tat.forEach(t),uco=r(Sk," (Nystr\xF6mformer model)"),Sk.forEach(t),pco=i(S),Cs=n(S,"LI",{});var Rk=s(Cs);jse=n(Rk,"STRONG",{});var Mat=s(jse);_co=r(Mat,"openai-gpt"),Mat.forEach(t),bco=r(Rk," \u2014 "),nI=n(Rk,"A",{href:!0});var Eat=s(nI);vco=r(Eat,"OpenAIGPTTokenizer"),Eat.forEach(t),Fco=r(Rk," or "),sI=n(Rk,"A",{href:!0});var Cat=s(sI);Tco=r(Cat,"OpenAIGPTTokenizerFast"),Cat.forEach(t),Mco=r(Rk," (OpenAI GPT model)"),Rk.forEach(t),Eco=i(S),lh=n(S,"LI",{});var jye=s(lh);Dse=n(jye,"STRONG",{});var wat=s(Dse);Cco=r(wat,"opt"),wat.forEach(t),wco=r(jye," \u2014 "),lI=n(jye,"A",{href:!0});var Aat=s(lI);Aco=r(Aat,"GPT2Tokenizer"),Aat.forEach(t),Lco=r(jye," (OPT model)"),jye.forEach(t),yco=i(S),ws=n(S,"LI",{});var Pk=s(ws);Gse=n(Pk,"STRONG",{});var Lat=s(Gse);xco=r(Lat,"pegasus"),Lat.forEach(t),$co=r(Pk," \u2014 "),iI=n(Pk,"A",{href:!0});var yat=s(iI);kco=r(yat,"PegasusTokenizer"),yat.forEach(t),Sco=r(Pk," or "),dI=n(Pk,"A",{href:!0});var xat=s(dI);Rco=r(xat,"PegasusTokenizerFast"),xat.forEach(t),Pco=r(Pk," (Pegasus model)"),Pk.forEach(t),Bco=i(S),ih=n(S,"LI",{});var Dye=s(ih);Ose=n(Dye,"STRONG",{});var $at=s(Ose);Ico=r($at,"perceiver"),$at.forEach(t),Nco=r(Dye," \u2014 "),cI=n(Dye,"A",{href:!0});var kat=s(cI);qco=r(kat,"PerceiverTokenizer"),kat.forEach(t),jco=r(Dye," (Perceiver model)"),Dye.forEach(t),Dco=i(S),dh=n(S,"LI",{});var Gye=s(dh);Vse=n(Gye,"STRONG",{});var Sat=s(Vse);Gco=r(Sat,"phobert"),Sat.forEach(t),Oco=r(Gye," \u2014 "),mI=n(Gye,"A",{href:!0});var Rat=s(mI);Vco=r(Rat,"PhobertTokenizer"),Rat.forEach(t),Xco=r(Gye," (PhoBERT model)"),Gye.forEach(t),zco=i(S),ch=n(S,"LI",{});var Oye=s(ch);Xse=n(Oye,"STRONG",{});var Pat=s(Xse);Qco=r(Pat,"plbart"),Pat.forEach(t),Wco=r(Oye," \u2014 "),fI=n(Oye,"A",{href:!0});var Bat=s(fI);Hco=r(Bat,"PLBartTokenizer"),Bat.forEach(t),Uco=r(Oye," (PLBart model)"),Oye.forEach(t),Jco=i(S),mh=n(S,"LI",{});var Vye=s(mh);zse=n(Vye,"STRONG",{});var Iat=s(zse);Yco=r(Iat,"prophetnet"),Iat.forEach(t),Kco=r(Vye," \u2014 "),gI=n(Vye,"A",{href:!0});var Nat=s(gI);Zco=r(Nat,"ProphetNetTokenizer"),Nat.forEach(t),emo=r(Vye," (ProphetNet model)"),Vye.forEach(t),omo=i(S),As=n(S,"LI",{});var Bk=s(As);Qse=n(Bk,"STRONG",{});var qat=s(Qse);rmo=r(qat,"qdqbert"),qat.forEach(t),tmo=r(Bk," \u2014 "),hI=n(Bk,"A",{href:!0});var jat=s(hI);amo=r(jat,"BertTokenizer"),jat.forEach(t),nmo=r(Bk," or "),uI=n(Bk,"A",{href:!0});var Dat=s(uI);smo=r(Dat,"BertTokenizerFast"),Dat.forEach(t),lmo=r(Bk," (QDQBert model)"),Bk.forEach(t),imo=i(S),fh=n(S,"LI",{});var Xye=s(fh);Wse=n(Xye,"STRONG",{});var Gat=s(Wse);dmo=r(Gat,"rag"),Gat.forEach(t),cmo=r(Xye," \u2014 "),pI=n(Xye,"A",{href:!0});var Oat=s(pI);mmo=r(Oat,"RagTokenizer"),Oat.forEach(t),fmo=r(Xye," (RAG model)"),Xye.forEach(t),gmo=i(S),Ls=n(S,"LI",{});var Ik=s(Ls);Hse=n(Ik,"STRONG",{});var Vat=s(Hse);hmo=r(Vat,"realm"),Vat.forEach(t),umo=r(Ik," \u2014 "),_I=n(Ik,"A",{href:!0});var Xat=s(_I);pmo=r(Xat,"RealmTokenizer"),Xat.forEach(t),_mo=r(Ik," or "),bI=n(Ik,"A",{href:!0});var zat=s(bI);bmo=r(zat,"RealmTokenizerFast"),zat.forEach(t),vmo=r(Ik," (REALM model)"),Ik.forEach(t),Fmo=i(S),ys=n(S,"LI",{});var Nk=s(ys);Use=n(Nk,"STRONG",{});var Qat=s(Use);Tmo=r(Qat,"reformer"),Qat.forEach(t),Mmo=r(Nk," \u2014 "),vI=n(Nk,"A",{href:!0});var Wat=s(vI);Emo=r(Wat,"ReformerTokenizer"),Wat.forEach(t),Cmo=r(Nk," or "),FI=n(Nk,"A",{href:!0});var Hat=s(FI);wmo=r(Hat,"ReformerTokenizerFast"),Hat.forEach(t),Amo=r(Nk," (Reformer model)"),Nk.forEach(t),Lmo=i(S),xs=n(S,"LI",{});var qk=s(xs);Jse=n(qk,"STRONG",{});var Uat=s(Jse);ymo=r(Uat,"rembert"),Uat.forEach(t),xmo=r(qk," \u2014 "),TI=n(qk,"A",{href:!0});var Jat=s(TI);$mo=r(Jat,"RemBertTokenizer"),Jat.forEach(t),kmo=r(qk," or "),MI=n(qk,"A",{href:!0});var Yat=s(MI);Smo=r(Yat,"RemBertTokenizerFast"),Yat.forEach(t),Rmo=r(qk," (RemBERT model)"),qk.forEach(t),Pmo=i(S),$s=n(S,"LI",{});var jk=s($s);Yse=n(jk,"STRONG",{});var Kat=s(Yse);Bmo=r(Kat,"retribert"),Kat.forEach(t),Imo=r(jk," \u2014 "),EI=n(jk,"A",{href:!0});var Zat=s(EI);Nmo=r(Zat,"RetriBertTokenizer"),Zat.forEach(t),qmo=r(jk," or "),CI=n(jk,"A",{href:!0});var ent=s(CI);jmo=r(ent,"RetriBertTokenizerFast"),ent.forEach(t),Dmo=r(jk," (RetriBERT model)"),jk.forEach(t),Gmo=i(S),ks=n(S,"LI",{});var Dk=s(ks);Kse=n(Dk,"STRONG",{});var ont=s(Kse);Omo=r(ont,"roberta"),ont.forEach(t),Vmo=r(Dk," \u2014 "),wI=n(Dk,"A",{href:!0});var rnt=s(wI);Xmo=r(rnt,"RobertaTokenizer"),rnt.forEach(t),zmo=r(Dk," or "),AI=n(Dk,"A",{href:!0});var tnt=s(AI);Qmo=r(tnt,"RobertaTokenizerFast"),tnt.forEach(t),Wmo=r(Dk," (RoBERTa model)"),Dk.forEach(t),Hmo=i(S),Ss=n(S,"LI",{});var Gk=s(Ss);Zse=n(Gk,"STRONG",{});var ant=s(Zse);Umo=r(ant,"roformer"),ant.forEach(t),Jmo=r(Gk," \u2014 "),LI=n(Gk,"A",{href:!0});var nnt=s(LI);Ymo=r(nnt,"RoFormerTokenizer"),nnt.forEach(t),Kmo=r(Gk," or "),yI=n(Gk,"A",{href:!0});var snt=s(yI);Zmo=r(snt,"RoFormerTokenizerFast"),snt.forEach(t),efo=r(Gk," (RoFormer model)"),Gk.forEach(t),ofo=i(S),gh=n(S,"LI",{});var zye=s(gh);ele=n(zye,"STRONG",{});var lnt=s(ele);rfo=r(lnt,"speech_to_text"),lnt.forEach(t),tfo=r(zye," \u2014 "),xI=n(zye,"A",{href:!0});var int=s(xI);afo=r(int,"Speech2TextTokenizer"),int.forEach(t),nfo=r(zye," (Speech2Text model)"),zye.forEach(t),sfo=i(S),hh=n(S,"LI",{});var Qye=s(hh);ole=n(Qye,"STRONG",{});var dnt=s(ole);lfo=r(dnt,"speech_to_text_2"),dnt.forEach(t),ifo=r(Qye," \u2014 "),$I=n(Qye,"A",{href:!0});var cnt=s($I);dfo=r(cnt,"Speech2Text2Tokenizer"),cnt.forEach(t),cfo=r(Qye," (Speech2Text2 model)"),Qye.forEach(t),mfo=i(S),Rs=n(S,"LI",{});var Ok=s(Rs);rle=n(Ok,"STRONG",{});var mnt=s(rle);ffo=r(mnt,"splinter"),mnt.forEach(t),gfo=r(Ok," \u2014 "),kI=n(Ok,"A",{href:!0});var fnt=s(kI);hfo=r(fnt,"SplinterTokenizer"),fnt.forEach(t),ufo=r(Ok," or "),SI=n(Ok,"A",{href:!0});var gnt=s(SI);pfo=r(gnt,"SplinterTokenizerFast"),gnt.forEach(t),_fo=r(Ok," (Splinter model)"),Ok.forEach(t),bfo=i(S),Ps=n(S,"LI",{});var Vk=s(Ps);tle=n(Vk,"STRONG",{});var hnt=s(tle);vfo=r(hnt,"squeezebert"),hnt.forEach(t),Ffo=r(Vk," \u2014 "),RI=n(Vk,"A",{href:!0});var unt=s(RI);Tfo=r(unt,"SqueezeBertTokenizer"),unt.forEach(t),Mfo=r(Vk," or "),PI=n(Vk,"A",{href:!0});var pnt=s(PI);Efo=r(pnt,"SqueezeBertTokenizerFast"),pnt.forEach(t),Cfo=r(Vk," (SqueezeBERT model)"),Vk.forEach(t),wfo=i(S),Bs=n(S,"LI",{});var Xk=s(Bs);ale=n(Xk,"STRONG",{});var _nt=s(ale);Afo=r(_nt,"t5"),_nt.forEach(t),Lfo=r(Xk," \u2014 "),BI=n(Xk,"A",{href:!0});var bnt=s(BI);yfo=r(bnt,"T5Tokenizer"),bnt.forEach(t),xfo=r(Xk," or "),II=n(Xk,"A",{href:!0});var vnt=s(II);$fo=r(vnt,"T5TokenizerFast"),vnt.forEach(t),kfo=r(Xk," (T5 model)"),Xk.forEach(t),Sfo=i(S),uh=n(S,"LI",{});var Wye=s(uh);nle=n(Wye,"STRONG",{});var Fnt=s(nle);Rfo=r(Fnt,"tapas"),Fnt.forEach(t),Pfo=r(Wye," \u2014 "),NI=n(Wye,"A",{href:!0});var Tnt=s(NI);Bfo=r(Tnt,"TapasTokenizer"),Tnt.forEach(t),Ifo=r(Wye," (TAPAS model)"),Wye.forEach(t),Nfo=i(S),ph=n(S,"LI",{});var Hye=s(ph);sle=n(Hye,"STRONG",{});var Mnt=s(sle);qfo=r(Mnt,"tapex"),Mnt.forEach(t),jfo=r(Hye," \u2014 "),qI=n(Hye,"A",{href:!0});var Ent=s(qI);Dfo=r(Ent,"TapexTokenizer"),Ent.forEach(t),Gfo=r(Hye," (TAPEX model)"),Hye.forEach(t),Ofo=i(S),_h=n(S,"LI",{});var Uye=s(_h);lle=n(Uye,"STRONG",{});var Cnt=s(lle);Vfo=r(Cnt,"transfo-xl"),Cnt.forEach(t),Xfo=r(Uye," \u2014 "),jI=n(Uye,"A",{href:!0});var wnt=s(jI);zfo=r(wnt,"TransfoXLTokenizer"),wnt.forEach(t),Qfo=r(Uye," (Transformer-XL model)"),Uye.forEach(t),Wfo=i(S),Is=n(S,"LI",{});var zk=s(Is);ile=n(zk,"STRONG",{});var Ant=s(ile);Hfo=r(Ant,"vilt"),Ant.forEach(t),Ufo=r(zk," \u2014 "),DI=n(zk,"A",{href:!0});var Lnt=s(DI);Jfo=r(Lnt,"BertTokenizer"),Lnt.forEach(t),Yfo=r(zk," or "),GI=n(zk,"A",{href:!0});var ynt=s(GI);Kfo=r(ynt,"BertTokenizerFast"),ynt.forEach(t),Zfo=r(zk," (ViLT model)"),zk.forEach(t),ego=i(S),Ns=n(S,"LI",{});var Qk=s(Ns);dle=n(Qk,"STRONG",{});var xnt=s(dle);ogo=r(xnt,"visual_bert"),xnt.forEach(t),rgo=r(Qk," \u2014 "),OI=n(Qk,"A",{href:!0});var $nt=s(OI);tgo=r($nt,"BertTokenizer"),$nt.forEach(t),ago=r(Qk," or "),VI=n(Qk,"A",{href:!0});var knt=s(VI);ngo=r(knt,"BertTokenizerFast"),knt.forEach(t),sgo=r(Qk," (VisualBERT model)"),Qk.forEach(t),lgo=i(S),bh=n(S,"LI",{});var Jye=s(bh);cle=n(Jye,"STRONG",{});var Snt=s(cle);igo=r(Snt,"wav2vec2"),Snt.forEach(t),dgo=r(Jye," \u2014 "),XI=n(Jye,"A",{href:!0});var Rnt=s(XI);cgo=r(Rnt,"Wav2Vec2CTCTokenizer"),Rnt.forEach(t),mgo=r(Jye," (Wav2Vec2 model)"),Jye.forEach(t),fgo=i(S),vh=n(S,"LI",{});var Yye=s(vh);mle=n(Yye,"STRONG",{});var Pnt=s(mle);ggo=r(Pnt,"wav2vec2-conformer"),Pnt.forEach(t),hgo=r(Yye," \u2014 "),zI=n(Yye,"A",{href:!0});var Bnt=s(zI);ugo=r(Bnt,"Wav2Vec2CTCTokenizer"),Bnt.forEach(t),pgo=r(Yye," (Wav2Vec2-Conformer model)"),Yye.forEach(t),_go=i(S),Fh=n(S,"LI",{});var Kye=s(Fh);fle=n(Kye,"STRONG",{});var Int=s(fle);bgo=r(Int,"wav2vec2_phoneme"),Int.forEach(t),vgo=r(Kye," \u2014 "),QI=n(Kye,"A",{href:!0});var Nnt=s(QI);Fgo=r(Nnt,"Wav2Vec2PhonemeCTCTokenizer"),Nnt.forEach(t),Tgo=r(Kye," (Wav2Vec2Phoneme model)"),Kye.forEach(t),Mgo=i(S),qs=n(S,"LI",{});var Wk=s(qs);gle=n(Wk,"STRONG",{});var qnt=s(gle);Ego=r(qnt,"xglm"),qnt.forEach(t),Cgo=r(Wk," \u2014 "),WI=n(Wk,"A",{href:!0});var jnt=s(WI);wgo=r(jnt,"XGLMTokenizer"),jnt.forEach(t),Ago=r(Wk," or "),HI=n(Wk,"A",{href:!0});var Dnt=s(HI);Lgo=r(Dnt,"XGLMTokenizerFast"),Dnt.forEach(t),ygo=r(Wk," (XGLM model)"),Wk.forEach(t),xgo=i(S),Th=n(S,"LI",{});var Zye=s(Th);hle=n(Zye,"STRONG",{});var Gnt=s(hle);$go=r(Gnt,"xlm"),Gnt.forEach(t),kgo=r(Zye," \u2014 "),UI=n(Zye,"A",{href:!0});var Ont=s(UI);Sgo=r(Ont,"XLMTokenizer"),Ont.forEach(t),Rgo=r(Zye," (XLM model)"),Zye.forEach(t),Pgo=i(S),Mh=n(S,"LI",{});var e7e=s(Mh);ule=n(e7e,"STRONG",{});var Vnt=s(ule);Bgo=r(Vnt,"xlm-prophetnet"),Vnt.forEach(t),Igo=r(e7e," \u2014 "),JI=n(e7e,"A",{href:!0});var Xnt=s(JI);Ngo=r(Xnt,"XLMProphetNetTokenizer"),Xnt.forEach(t),qgo=r(e7e," (XLM-ProphetNet model)"),e7e.forEach(t),jgo=i(S),js=n(S,"LI",{});var Hk=s(js);ple=n(Hk,"STRONG",{});var znt=s(ple);Dgo=r(znt,"xlm-roberta"),znt.forEach(t),Ggo=r(Hk," \u2014 "),YI=n(Hk,"A",{href:!0});var Qnt=s(YI);Ogo=r(Qnt,"XLMRobertaTokenizer"),Qnt.forEach(t),Vgo=r(Hk," or "),KI=n(Hk,"A",{href:!0});var Wnt=s(KI);Xgo=r(Wnt,"XLMRobertaTokenizerFast"),Wnt.forEach(t),zgo=r(Hk," (XLM-RoBERTa model)"),Hk.forEach(t),Qgo=i(S),Ds=n(S,"LI",{});var Uk=s(Ds);_le=n(Uk,"STRONG",{});var Hnt=s(_le);Wgo=r(Hnt,"xlm-roberta-xl"),Hnt.forEach(t),Hgo=r(Uk," \u2014 "),ZI=n(Uk,"A",{href:!0});var Unt=s(ZI);Ugo=r(Unt,"RobertaTokenizer"),Unt.forEach(t),Jgo=r(Uk," or "),eN=n(Uk,"A",{href:!0});var Jnt=s(eN);Ygo=r(Jnt,"RobertaTokenizerFast"),Jnt.forEach(t),Kgo=r(Uk," (XLM-RoBERTa-XL model)"),Uk.forEach(t),Zgo=i(S),Gs=n(S,"LI",{});var Jk=s(Gs);ble=n(Jk,"STRONG",{});var Ynt=s(ble);eho=r(Ynt,"xlnet"),Ynt.forEach(t),oho=r(Jk," \u2014 "),oN=n(Jk,"A",{href:!0});var Knt=s(oN);rho=r(Knt,"XLNetTokenizer"),Knt.forEach(t),tho=r(Jk," or "),rN=n(Jk,"A",{href:!0});var Znt=s(rN);aho=r(Znt,"XLNetTokenizerFast"),Znt.forEach(t),nho=r(Jk," (XLNet model)"),Jk.forEach(t),sho=i(S),Os=n(S,"LI",{});var Yk=s(Os);vle=n(Yk,"STRONG",{});var est=s(vle);lho=r(est,"yoso"),est.forEach(t),iho=r(Yk," \u2014 "),tN=n(Yk,"A",{href:!0});var ost=s(tN);dho=r(ost,"AlbertTokenizer"),ost.forEach(t),cho=r(Yk," or "),aN=n(Yk,"A",{href:!0});var rst=s(aN);mho=r(rst,"AlbertTokenizerFast"),rst.forEach(t),fho=r(Yk," (YOSO model)"),Yk.forEach(t),S.forEach(t),gho=i(Hs),T(Eh.$$.fragment,Hs),Hs.forEach(t),hho=i(Ws),Ch=n(Ws,"DIV",{class:!0});var UVe=s(Ch);T(Oy.$$.fragment,UVe),uho=i(UVe),Fle=n(UVe,"P",{});var tst=s(Fle);pho=r(tst,"Register a new tokenizer in this mapping."),tst.forEach(t),UVe.forEach(t),Ws.forEach(t),HGe=i(m),Si=n(m,"H2",{class:!0});var JVe=s(Si);wh=n(JVe,"A",{id:!0,class:!0,href:!0});var ast=s(wh);Tle=n(ast,"SPAN",{});var nst=s(Tle);T(Vy.$$.fragment,nst),nst.forEach(t),ast.forEach(t),_ho=i(JVe),Mle=n(JVe,"SPAN",{});var sst=s(Mle);bho=r(sst,"AutoFeatureExtractor"),sst.forEach(t),JVe.forEach(t),UGe=i(m),Lo=n(m,"DIV",{class:!0});var Us=s(Lo);T(Xy.$$.fragment,Us),vho=i(Us),zy=n(Us,"P",{});var YVe=s(zy);Fho=r(YVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=n(YVe,"A",{href:!0});var lst=s(nN);Tho=r(lst,"AutoFeatureExtractor.from_pretrained()"),lst.forEach(t),Mho=r(YVe," class method."),YVe.forEach(t),Eho=i(Us),Qy=n(Us,"P",{});var KVe=s(Qy);Cho=r(KVe,"This class cannot be instantiated directly using "),Ele=n(KVe,"CODE",{});var ist=s(Ele);who=r(ist,"__init__()"),ist.forEach(t),Aho=r(KVe," (throws an error)."),KVe.forEach(t),Lho=i(Us),He=n(Us,"DIV",{class:!0});var ra=s(He);T(Wy.$$.fragment,ra),yho=i(ra),Cle=n(ra,"P",{});var dst=s(Cle);xho=r(dst,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dst.forEach(t),$ho=i(ra),Sa=n(ra,"P",{});var $6=s(Sa);kho=r($6,"The feature extractor class to instantiate is selected based on the "),wle=n($6,"CODE",{});var cst=s(wle);Sho=r(cst,"model_type"),cst.forEach(t),Rho=r($6,` property of the config object
(either passed as an argument or loaded from `),Ale=n($6,"CODE",{});var mst=s(Ale);Pho=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),Bho=r($6,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=n($6,"CODE",{});var fst=s(Lle);Iho=r(fst,"pretrained_model_name_or_path"),fst.forEach(t),Nho=r($6,":"),$6.forEach(t),qho=i(ra),Y=n(ra,"UL",{});var K=s(Y);Ah=n(K,"LI",{});var o7e=s(Ah);yle=n(o7e,"STRONG",{});var gst=s(yle);jho=r(gst,"beit"),gst.forEach(t),Dho=r(o7e," \u2014 "),sN=n(o7e,"A",{href:!0});var hst=s(sN);Gho=r(hst,"BeitFeatureExtractor"),hst.forEach(t),Oho=r(o7e," (BEiT model)"),o7e.forEach(t),Vho=i(K),Lh=n(K,"LI",{});var r7e=s(Lh);xle=n(r7e,"STRONG",{});var ust=s(xle);Xho=r(ust,"clip"),ust.forEach(t),zho=r(r7e," \u2014 "),lN=n(r7e,"A",{href:!0});var pst=s(lN);Qho=r(pst,"CLIPFeatureExtractor"),pst.forEach(t),Who=r(r7e," (CLIP model)"),r7e.forEach(t),Hho=i(K),yh=n(K,"LI",{});var t7e=s(yh);$le=n(t7e,"STRONG",{});var _st=s($le);Uho=r(_st,"convnext"),_st.forEach(t),Jho=r(t7e," \u2014 "),iN=n(t7e,"A",{href:!0});var bst=s(iN);Yho=r(bst,"ConvNextFeatureExtractor"),bst.forEach(t),Kho=r(t7e," (ConvNeXT model)"),t7e.forEach(t),Zho=i(K),xh=n(K,"LI",{});var a7e=s(xh);kle=n(a7e,"STRONG",{});var vst=s(kle);euo=r(vst,"cvt"),vst.forEach(t),ouo=r(a7e," \u2014 "),dN=n(a7e,"A",{href:!0});var Fst=s(dN);ruo=r(Fst,"ConvNextFeatureExtractor"),Fst.forEach(t),tuo=r(a7e," (CvT model)"),a7e.forEach(t),auo=i(K),$h=n(K,"LI",{});var n7e=s($h);Sle=n(n7e,"STRONG",{});var Tst=s(Sle);nuo=r(Tst,"data2vec-audio"),Tst.forEach(t),suo=r(n7e," \u2014 "),cN=n(n7e,"A",{href:!0});var Mst=s(cN);luo=r(Mst,"Wav2Vec2FeatureExtractor"),Mst.forEach(t),iuo=r(n7e," (Data2VecAudio model)"),n7e.forEach(t),duo=i(K),kh=n(K,"LI",{});var s7e=s(kh);Rle=n(s7e,"STRONG",{});var Est=s(Rle);cuo=r(Est,"data2vec-vision"),Est.forEach(t),muo=r(s7e," \u2014 "),mN=n(s7e,"A",{href:!0});var Cst=s(mN);fuo=r(Cst,"BeitFeatureExtractor"),Cst.forEach(t),guo=r(s7e," (Data2VecVision model)"),s7e.forEach(t),huo=i(K),Sh=n(K,"LI",{});var l7e=s(Sh);Ple=n(l7e,"STRONG",{});var wst=s(Ple);uuo=r(wst,"deit"),wst.forEach(t),puo=r(l7e," \u2014 "),fN=n(l7e,"A",{href:!0});var Ast=s(fN);_uo=r(Ast,"DeiTFeatureExtractor"),Ast.forEach(t),buo=r(l7e," (DeiT model)"),l7e.forEach(t),vuo=i(K),Rh=n(K,"LI",{});var i7e=s(Rh);Ble=n(i7e,"STRONG",{});var Lst=s(Ble);Fuo=r(Lst,"detr"),Lst.forEach(t),Tuo=r(i7e," \u2014 "),gN=n(i7e,"A",{href:!0});var yst=s(gN);Muo=r(yst,"DetrFeatureExtractor"),yst.forEach(t),Euo=r(i7e," (DETR model)"),i7e.forEach(t),Cuo=i(K),Ph=n(K,"LI",{});var d7e=s(Ph);Ile=n(d7e,"STRONG",{});var xst=s(Ile);wuo=r(xst,"dpt"),xst.forEach(t),Auo=r(d7e," \u2014 "),hN=n(d7e,"A",{href:!0});var $st=s(hN);Luo=r($st,"DPTFeatureExtractor"),$st.forEach(t),yuo=r(d7e," (DPT model)"),d7e.forEach(t),xuo=i(K),Bh=n(K,"LI",{});var c7e=s(Bh);Nle=n(c7e,"STRONG",{});var kst=s(Nle);$uo=r(kst,"flava"),kst.forEach(t),kuo=r(c7e," \u2014 "),uN=n(c7e,"A",{href:!0});var Sst=s(uN);Suo=r(Sst,"FlavaFeatureExtractor"),Sst.forEach(t),Ruo=r(c7e," (FLAVA model)"),c7e.forEach(t),Puo=i(K),Ih=n(K,"LI",{});var m7e=s(Ih);qle=n(m7e,"STRONG",{});var Rst=s(qle);Buo=r(Rst,"glpn"),Rst.forEach(t),Iuo=r(m7e," \u2014 "),pN=n(m7e,"A",{href:!0});var Pst=s(pN);Nuo=r(Pst,"GLPNFeatureExtractor"),Pst.forEach(t),quo=r(m7e," (GLPN model)"),m7e.forEach(t),juo=i(K),Nh=n(K,"LI",{});var f7e=s(Nh);jle=n(f7e,"STRONG",{});var Bst=s(jle);Duo=r(Bst,"hubert"),Bst.forEach(t),Guo=r(f7e," \u2014 "),_N=n(f7e,"A",{href:!0});var Ist=s(_N);Ouo=r(Ist,"Wav2Vec2FeatureExtractor"),Ist.forEach(t),Vuo=r(f7e," (Hubert model)"),f7e.forEach(t),Xuo=i(K),qh=n(K,"LI",{});var g7e=s(qh);Dle=n(g7e,"STRONG",{});var Nst=s(Dle);zuo=r(Nst,"imagegpt"),Nst.forEach(t),Quo=r(g7e," \u2014 "),bN=n(g7e,"A",{href:!0});var qst=s(bN);Wuo=r(qst,"ImageGPTFeatureExtractor"),qst.forEach(t),Huo=r(g7e," (ImageGPT model)"),g7e.forEach(t),Uuo=i(K),jh=n(K,"LI",{});var h7e=s(jh);Gle=n(h7e,"STRONG",{});var jst=s(Gle);Juo=r(jst,"layoutlmv2"),jst.forEach(t),Yuo=r(h7e," \u2014 "),vN=n(h7e,"A",{href:!0});var Dst=s(vN);Kuo=r(Dst,"LayoutLMv2FeatureExtractor"),Dst.forEach(t),Zuo=r(h7e," (LayoutLMv2 model)"),h7e.forEach(t),epo=i(K),Dh=n(K,"LI",{});var u7e=s(Dh);Ole=n(u7e,"STRONG",{});var Gst=s(Ole);opo=r(Gst,"layoutlmv3"),Gst.forEach(t),rpo=r(u7e," \u2014 "),FN=n(u7e,"A",{href:!0});var Ost=s(FN);tpo=r(Ost,"LayoutLMv3FeatureExtractor"),Ost.forEach(t),apo=r(u7e," (LayoutLMv3 model)"),u7e.forEach(t),npo=i(K),Gh=n(K,"LI",{});var p7e=s(Gh);Vle=n(p7e,"STRONG",{});var Vst=s(Vle);spo=r(Vst,"levit"),Vst.forEach(t),lpo=r(p7e," \u2014 "),TN=n(p7e,"A",{href:!0});var Xst=s(TN);ipo=r(Xst,"LevitFeatureExtractor"),Xst.forEach(t),dpo=r(p7e," (LeViT model)"),p7e.forEach(t),cpo=i(K),Oh=n(K,"LI",{});var _7e=s(Oh);Xle=n(_7e,"STRONG",{});var zst=s(Xle);mpo=r(zst,"maskformer"),zst.forEach(t),fpo=r(_7e," \u2014 "),MN=n(_7e,"A",{href:!0});var Qst=s(MN);gpo=r(Qst,"MaskFormerFeatureExtractor"),Qst.forEach(t),hpo=r(_7e," (MaskFormer model)"),_7e.forEach(t),upo=i(K),Vh=n(K,"LI",{});var b7e=s(Vh);zle=n(b7e,"STRONG",{});var Wst=s(zle);ppo=r(Wst,"mctct"),Wst.forEach(t),_po=r(b7e," \u2014 "),EN=n(b7e,"A",{href:!0});var Hst=s(EN);bpo=r(Hst,"MCTCTFeatureExtractor"),Hst.forEach(t),vpo=r(b7e," (M-CTC-T model)"),b7e.forEach(t),Fpo=i(K),Xh=n(K,"LI",{});var v7e=s(Xh);Qle=n(v7e,"STRONG",{});var Ust=s(Qle);Tpo=r(Ust,"perceiver"),Ust.forEach(t),Mpo=r(v7e," \u2014 "),CN=n(v7e,"A",{href:!0});var Jst=s(CN);Epo=r(Jst,"PerceiverFeatureExtractor"),Jst.forEach(t),Cpo=r(v7e," (Perceiver model)"),v7e.forEach(t),wpo=i(K),zh=n(K,"LI",{});var F7e=s(zh);Wle=n(F7e,"STRONG",{});var Yst=s(Wle);Apo=r(Yst,"poolformer"),Yst.forEach(t),Lpo=r(F7e," \u2014 "),wN=n(F7e,"A",{href:!0});var Kst=s(wN);ypo=r(Kst,"PoolFormerFeatureExtractor"),Kst.forEach(t),xpo=r(F7e," (PoolFormer model)"),F7e.forEach(t),$po=i(K),Qh=n(K,"LI",{});var T7e=s(Qh);Hle=n(T7e,"STRONG",{});var Zst=s(Hle);kpo=r(Zst,"regnet"),Zst.forEach(t),Spo=r(T7e," \u2014 "),AN=n(T7e,"A",{href:!0});var elt=s(AN);Rpo=r(elt,"ConvNextFeatureExtractor"),elt.forEach(t),Ppo=r(T7e," (RegNet model)"),T7e.forEach(t),Bpo=i(K),Wh=n(K,"LI",{});var M7e=s(Wh);Ule=n(M7e,"STRONG",{});var olt=s(Ule);Ipo=r(olt,"resnet"),olt.forEach(t),Npo=r(M7e," \u2014 "),LN=n(M7e,"A",{href:!0});var rlt=s(LN);qpo=r(rlt,"ConvNextFeatureExtractor"),rlt.forEach(t),jpo=r(M7e," (ResNet model)"),M7e.forEach(t),Dpo=i(K),Hh=n(K,"LI",{});var E7e=s(Hh);Jle=n(E7e,"STRONG",{});var tlt=s(Jle);Gpo=r(tlt,"segformer"),tlt.forEach(t),Opo=r(E7e," \u2014 "),yN=n(E7e,"A",{href:!0});var alt=s(yN);Vpo=r(alt,"SegformerFeatureExtractor"),alt.forEach(t),Xpo=r(E7e," (SegFormer model)"),E7e.forEach(t),zpo=i(K),Uh=n(K,"LI",{});var C7e=s(Uh);Yle=n(C7e,"STRONG",{});var nlt=s(Yle);Qpo=r(nlt,"speech_to_text"),nlt.forEach(t),Wpo=r(C7e," \u2014 "),xN=n(C7e,"A",{href:!0});var slt=s(xN);Hpo=r(slt,"Speech2TextFeatureExtractor"),slt.forEach(t),Upo=r(C7e," (Speech2Text model)"),C7e.forEach(t),Jpo=i(K),Jh=n(K,"LI",{});var w7e=s(Jh);Kle=n(w7e,"STRONG",{});var llt=s(Kle);Ypo=r(llt,"swin"),llt.forEach(t),Kpo=r(w7e," \u2014 "),$N=n(w7e,"A",{href:!0});var ilt=s($N);Zpo=r(ilt,"ViTFeatureExtractor"),ilt.forEach(t),e_o=r(w7e," (Swin Transformer model)"),w7e.forEach(t),o_o=i(K),Yh=n(K,"LI",{});var A7e=s(Yh);Zle=n(A7e,"STRONG",{});var dlt=s(Zle);r_o=r(dlt,"van"),dlt.forEach(t),t_o=r(A7e," \u2014 "),kN=n(A7e,"A",{href:!0});var clt=s(kN);a_o=r(clt,"ConvNextFeatureExtractor"),clt.forEach(t),n_o=r(A7e," (VAN model)"),A7e.forEach(t),s_o=i(K),Kh=n(K,"LI",{});var L7e=s(Kh);eie=n(L7e,"STRONG",{});var mlt=s(eie);l_o=r(mlt,"vilt"),mlt.forEach(t),i_o=r(L7e," \u2014 "),SN=n(L7e,"A",{href:!0});var flt=s(SN);d_o=r(flt,"ViltFeatureExtractor"),flt.forEach(t),c_o=r(L7e," (ViLT model)"),L7e.forEach(t),m_o=i(K),Zh=n(K,"LI",{});var y7e=s(Zh);oie=n(y7e,"STRONG",{});var glt=s(oie);f_o=r(glt,"vit"),glt.forEach(t),g_o=r(y7e," \u2014 "),RN=n(y7e,"A",{href:!0});var hlt=s(RN);h_o=r(hlt,"ViTFeatureExtractor"),hlt.forEach(t),u_o=r(y7e," (ViT model)"),y7e.forEach(t),p_o=i(K),eu=n(K,"LI",{});var x7e=s(eu);rie=n(x7e,"STRONG",{});var ult=s(rie);__o=r(ult,"vit_mae"),ult.forEach(t),b_o=r(x7e," \u2014 "),PN=n(x7e,"A",{href:!0});var plt=s(PN);v_o=r(plt,"ViTFeatureExtractor"),plt.forEach(t),F_o=r(x7e," (ViTMAE model)"),x7e.forEach(t),T_o=i(K),ou=n(K,"LI",{});var $7e=s(ou);tie=n($7e,"STRONG",{});var _lt=s(tie);M_o=r(_lt,"wav2vec2"),_lt.forEach(t),E_o=r($7e," \u2014 "),BN=n($7e,"A",{href:!0});var blt=s(BN);C_o=r(blt,"Wav2Vec2FeatureExtractor"),blt.forEach(t),w_o=r($7e," (Wav2Vec2 model)"),$7e.forEach(t),A_o=i(K),ru=n(K,"LI",{});var k7e=s(ru);aie=n(k7e,"STRONG",{});var vlt=s(aie);L_o=r(vlt,"wav2vec2-conformer"),vlt.forEach(t),y_o=r(k7e," \u2014 "),IN=n(k7e,"A",{href:!0});var Flt=s(IN);x_o=r(Flt,"Wav2Vec2FeatureExtractor"),Flt.forEach(t),$_o=r(k7e," (Wav2Vec2-Conformer model)"),k7e.forEach(t),k_o=i(K),tu=n(K,"LI",{});var S7e=s(tu);nie=n(S7e,"STRONG",{});var Tlt=s(nie);S_o=r(Tlt,"yolos"),Tlt.forEach(t),R_o=r(S7e," \u2014 "),NN=n(S7e,"A",{href:!0});var Mlt=s(NN);P_o=r(Mlt,"YolosFeatureExtractor"),Mlt.forEach(t),B_o=r(S7e," (YOLOS model)"),S7e.forEach(t),K.forEach(t),I_o=i(ra),T(au.$$.fragment,ra),N_o=i(ra),T(nu.$$.fragment,ra),ra.forEach(t),q_o=i(Us),su=n(Us,"DIV",{class:!0});var ZVe=s(su);T(Hy.$$.fragment,ZVe),j_o=i(ZVe),sie=n(ZVe,"P",{});var Elt=s(sie);D_o=r(Elt,"Register a new feature extractor for this class."),Elt.forEach(t),ZVe.forEach(t),Us.forEach(t),JGe=i(m),Ri=n(m,"H2",{class:!0});var eXe=s(Ri);lu=n(eXe,"A",{id:!0,class:!0,href:!0});var Clt=s(lu);lie=n(Clt,"SPAN",{});var wlt=s(lie);T(Uy.$$.fragment,wlt),wlt.forEach(t),Clt.forEach(t),G_o=i(eXe),iie=n(eXe,"SPAN",{});var Alt=s(iie);O_o=r(Alt,"AutoProcessor"),Alt.forEach(t),eXe.forEach(t),YGe=i(m),yo=n(m,"DIV",{class:!0});var Js=s(yo);T(Jy.$$.fragment,Js),V_o=i(Js),Yy=n(Js,"P",{});var oXe=s(Yy);X_o=r(oXe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=n(oXe,"A",{href:!0});var Llt=s(qN);z_o=r(Llt,"AutoProcessor.from_pretrained()"),Llt.forEach(t),Q_o=r(oXe," class method."),oXe.forEach(t),W_o=i(Js),Ky=n(Js,"P",{});var rXe=s(Ky);H_o=r(rXe,"This class cannot be instantiated directly using "),die=n(rXe,"CODE",{});var ylt=s(die);U_o=r(ylt,"__init__()"),ylt.forEach(t),J_o=r(rXe," (throws an error)."),rXe.forEach(t),Y_o=i(Js),Ue=n(Js,"DIV",{class:!0});var ta=s(Ue);T(Zy.$$.fragment,ta),K_o=i(ta),cie=n(ta,"P",{});var xlt=s(cie);Z_o=r(xlt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xlt.forEach(t),e2o=i(ta),Pi=n(ta,"P",{});var boe=s(Pi);o2o=r(boe,"The processor class to instantiate is selected based on the "),mie=n(boe,"CODE",{});var $lt=s(mie);r2o=r($lt,"model_type"),$lt.forEach(t),t2o=r(boe,` property of the config object (either
passed as an argument or loaded from `),fie=n(boe,"CODE",{});var klt=s(fie);a2o=r(klt,"pretrained_model_name_or_path"),klt.forEach(t),n2o=r(boe," if possible):"),boe.forEach(t),s2o=i(ta),he=n(ta,"UL",{});var _e=s(he);iu=n(_e,"LI",{});var R7e=s(iu);gie=n(R7e,"STRONG",{});var Slt=s(gie);l2o=r(Slt,"clip"),Slt.forEach(t),i2o=r(R7e," \u2014 "),jN=n(R7e,"A",{href:!0});var Rlt=s(jN);d2o=r(Rlt,"CLIPProcessor"),Rlt.forEach(t),c2o=r(R7e," (CLIP model)"),R7e.forEach(t),m2o=i(_e),du=n(_e,"LI",{});var P7e=s(du);hie=n(P7e,"STRONG",{});var Plt=s(hie);f2o=r(Plt,"flava"),Plt.forEach(t),g2o=r(P7e," \u2014 "),uie=n(P7e,"CODE",{});var Blt=s(uie);h2o=r(Blt,"FLAVAProcessor"),Blt.forEach(t),u2o=r(P7e," (FLAVA model)"),P7e.forEach(t),p2o=i(_e),cu=n(_e,"LI",{});var B7e=s(cu);pie=n(B7e,"STRONG",{});var Ilt=s(pie);_2o=r(Ilt,"layoutlmv2"),Ilt.forEach(t),b2o=r(B7e," \u2014 "),DN=n(B7e,"A",{href:!0});var Nlt=s(DN);v2o=r(Nlt,"LayoutLMv2Processor"),Nlt.forEach(t),F2o=r(B7e," (LayoutLMv2 model)"),B7e.forEach(t),T2o=i(_e),mu=n(_e,"LI",{});var I7e=s(mu);_ie=n(I7e,"STRONG",{});var qlt=s(_ie);M2o=r(qlt,"layoutlmv3"),qlt.forEach(t),E2o=r(I7e," \u2014 "),GN=n(I7e,"A",{href:!0});var jlt=s(GN);C2o=r(jlt,"LayoutLMv3Processor"),jlt.forEach(t),w2o=r(I7e," (LayoutLMv3 model)"),I7e.forEach(t),A2o=i(_e),fu=n(_e,"LI",{});var N7e=s(fu);bie=n(N7e,"STRONG",{});var Dlt=s(bie);L2o=r(Dlt,"layoutxlm"),Dlt.forEach(t),y2o=r(N7e," \u2014 "),ON=n(N7e,"A",{href:!0});var Glt=s(ON);x2o=r(Glt,"LayoutXLMProcessor"),Glt.forEach(t),$2o=r(N7e," (LayoutXLM model)"),N7e.forEach(t),k2o=i(_e),gu=n(_e,"LI",{});var q7e=s(gu);vie=n(q7e,"STRONG",{});var Olt=s(vie);S2o=r(Olt,"sew"),Olt.forEach(t),R2o=r(q7e," \u2014 "),VN=n(q7e,"A",{href:!0});var Vlt=s(VN);P2o=r(Vlt,"Wav2Vec2Processor"),Vlt.forEach(t),B2o=r(q7e," (SEW model)"),q7e.forEach(t),I2o=i(_e),hu=n(_e,"LI",{});var j7e=s(hu);Fie=n(j7e,"STRONG",{});var Xlt=s(Fie);N2o=r(Xlt,"sew-d"),Xlt.forEach(t),q2o=r(j7e," \u2014 "),XN=n(j7e,"A",{href:!0});var zlt=s(XN);j2o=r(zlt,"Wav2Vec2Processor"),zlt.forEach(t),D2o=r(j7e," (SEW-D model)"),j7e.forEach(t),G2o=i(_e),uu=n(_e,"LI",{});var D7e=s(uu);Tie=n(D7e,"STRONG",{});var Qlt=s(Tie);O2o=r(Qlt,"speech_to_text"),Qlt.forEach(t),V2o=r(D7e," \u2014 "),zN=n(D7e,"A",{href:!0});var Wlt=s(zN);X2o=r(Wlt,"Speech2TextProcessor"),Wlt.forEach(t),z2o=r(D7e," (Speech2Text model)"),D7e.forEach(t),Q2o=i(_e),pu=n(_e,"LI",{});var G7e=s(pu);Mie=n(G7e,"STRONG",{});var Hlt=s(Mie);W2o=r(Hlt,"speech_to_text_2"),Hlt.forEach(t),H2o=r(G7e," \u2014 "),QN=n(G7e,"A",{href:!0});var Ult=s(QN);U2o=r(Ult,"Speech2Text2Processor"),Ult.forEach(t),J2o=r(G7e," (Speech2Text2 model)"),G7e.forEach(t),Y2o=i(_e),_u=n(_e,"LI",{});var O7e=s(_u);Eie=n(O7e,"STRONG",{});var Jlt=s(Eie);K2o=r(Jlt,"trocr"),Jlt.forEach(t),Z2o=r(O7e," \u2014 "),WN=n(O7e,"A",{href:!0});var Ylt=s(WN);ebo=r(Ylt,"TrOCRProcessor"),Ylt.forEach(t),obo=r(O7e," (TrOCR model)"),O7e.forEach(t),rbo=i(_e),bu=n(_e,"LI",{});var V7e=s(bu);Cie=n(V7e,"STRONG",{});var Klt=s(Cie);tbo=r(Klt,"unispeech"),Klt.forEach(t),abo=r(V7e," \u2014 "),HN=n(V7e,"A",{href:!0});var Zlt=s(HN);nbo=r(Zlt,"Wav2Vec2Processor"),Zlt.forEach(t),sbo=r(V7e," (UniSpeech model)"),V7e.forEach(t),lbo=i(_e),vu=n(_e,"LI",{});var X7e=s(vu);wie=n(X7e,"STRONG",{});var eit=s(wie);ibo=r(eit,"unispeech-sat"),eit.forEach(t),dbo=r(X7e," \u2014 "),UN=n(X7e,"A",{href:!0});var oit=s(UN);cbo=r(oit,"Wav2Vec2Processor"),oit.forEach(t),mbo=r(X7e," (UniSpeechSat model)"),X7e.forEach(t),fbo=i(_e),Fu=n(_e,"LI",{});var z7e=s(Fu);Aie=n(z7e,"STRONG",{});var rit=s(Aie);gbo=r(rit,"vilt"),rit.forEach(t),hbo=r(z7e," \u2014 "),JN=n(z7e,"A",{href:!0});var tit=s(JN);ubo=r(tit,"ViltProcessor"),tit.forEach(t),pbo=r(z7e," (ViLT model)"),z7e.forEach(t),_bo=i(_e),Tu=n(_e,"LI",{});var Q7e=s(Tu);Lie=n(Q7e,"STRONG",{});var ait=s(Lie);bbo=r(ait,"vision-text-dual-encoder"),ait.forEach(t),vbo=r(Q7e," \u2014 "),YN=n(Q7e,"A",{href:!0});var nit=s(YN);Fbo=r(nit,"VisionTextDualEncoderProcessor"),nit.forEach(t),Tbo=r(Q7e," (VisionTextDualEncoder model)"),Q7e.forEach(t),Mbo=i(_e),Mu=n(_e,"LI",{});var W7e=s(Mu);yie=n(W7e,"STRONG",{});var sit=s(yie);Ebo=r(sit,"wav2vec2"),sit.forEach(t),Cbo=r(W7e," \u2014 "),KN=n(W7e,"A",{href:!0});var lit=s(KN);wbo=r(lit,"Wav2Vec2Processor"),lit.forEach(t),Abo=r(W7e," (Wav2Vec2 model)"),W7e.forEach(t),Lbo=i(_e),Eu=n(_e,"LI",{});var H7e=s(Eu);xie=n(H7e,"STRONG",{});var iit=s(xie);ybo=r(iit,"wav2vec2-conformer"),iit.forEach(t),xbo=r(H7e," \u2014 "),ZN=n(H7e,"A",{href:!0});var dit=s(ZN);$bo=r(dit,"Wav2Vec2Processor"),dit.forEach(t),kbo=r(H7e," (Wav2Vec2-Conformer model)"),H7e.forEach(t),Sbo=i(_e),Cu=n(_e,"LI",{});var U7e=s(Cu);$ie=n(U7e,"STRONG",{});var cit=s($ie);Rbo=r(cit,"wavlm"),cit.forEach(t),Pbo=r(U7e," \u2014 "),eq=n(U7e,"A",{href:!0});var mit=s(eq);Bbo=r(mit,"Wav2Vec2Processor"),mit.forEach(t),Ibo=r(U7e," (WavLM model)"),U7e.forEach(t),_e.forEach(t),Nbo=i(ta),T(wu.$$.fragment,ta),qbo=i(ta),T(Au.$$.fragment,ta),ta.forEach(t),jbo=i(Js),Lu=n(Js,"DIV",{class:!0});var tXe=s(Lu);T(e7.$$.fragment,tXe),Dbo=i(tXe),kie=n(tXe,"P",{});var fit=s(kie);Gbo=r(fit,"Register a new processor for this class."),fit.forEach(t),tXe.forEach(t),Js.forEach(t),KGe=i(m),Bi=n(m,"H2",{class:!0});var aXe=s(Bi);yu=n(aXe,"A",{id:!0,class:!0,href:!0});var git=s(yu);Sie=n(git,"SPAN",{});var hit=s(Sie);T(o7.$$.fragment,hit),hit.forEach(t),git.forEach(t),Obo=i(aXe),Rie=n(aXe,"SPAN",{});var uit=s(Rie);Vbo=r(uit,"AutoModel"),uit.forEach(t),aXe.forEach(t),ZGe=i(m),xo=n(m,"DIV",{class:!0});var Ys=s(xo);T(r7.$$.fragment,Ys),Xbo=i(Ys),Ii=n(Ys,"P",{});var voe=s(Ii);zbo=r(voe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=n(voe,"A",{href:!0});var pit=s(oq);Qbo=r(pit,"from_pretrained()"),pit.forEach(t),Wbo=r(voe," class method or the "),rq=n(voe,"A",{href:!0});var _it=s(rq);Hbo=r(_it,"from_config()"),_it.forEach(t),Ubo=r(voe,` class
method.`),voe.forEach(t),Jbo=i(Ys),t7=n(Ys,"P",{});var nXe=s(t7);Ybo=r(nXe,"This class cannot be instantiated directly using "),Pie=n(nXe,"CODE",{});var bit=s(Pie);Kbo=r(bit,"__init__()"),bit.forEach(t),Zbo=r(nXe," (throws an error)."),nXe.forEach(t),evo=i(Ys),nt=n(Ys,"DIV",{class:!0});var k6=s(nt);T(a7.$$.fragment,k6),ovo=i(k6),Bie=n(k6,"P",{});var vit=s(Bie);rvo=r(vit,"Instantiates one of the base model classes of the library from a configuration."),vit.forEach(t),tvo=i(k6),Ni=n(k6,"P",{});var Foe=s(Ni);avo=r(Foe,`Note:
Loading a model from its configuration file does `),Iie=n(Foe,"STRONG",{});var Fit=s(Iie);nvo=r(Fit,"not"),Fit.forEach(t),svo=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=n(Foe,"A",{href:!0});var Tit=s(tq);lvo=r(Tit,"from_pretrained()"),Tit.forEach(t),ivo=r(Foe," to load the model weights."),Foe.forEach(t),dvo=i(k6),T(xu.$$.fragment,k6),k6.forEach(t),cvo=i(Ys),Je=n(Ys,"DIV",{class:!0});var aa=s(Je);T(n7.$$.fragment,aa),mvo=i(aa),Nie=n(aa,"P",{});var Mit=s(Nie);fvo=r(Mit,"Instantiate one of the base model classes of the library from a pretrained model."),Mit.forEach(t),gvo=i(aa),Ra=n(aa,"P",{});var S6=s(Ra);hvo=r(S6,"The model class to instantiate is selected based on the "),qie=n(S6,"CODE",{});var Eit=s(qie);uvo=r(Eit,"model_type"),Eit.forEach(t),pvo=r(S6,` property of the config object (either
passed as an argument or loaded from `),jie=n(S6,"CODE",{});var Cit=s(jie);_vo=r(Cit,"pretrained_model_name_or_path"),Cit.forEach(t),bvo=r(S6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(S6,"CODE",{});var wit=s(Die);vvo=r(wit,"pretrained_model_name_or_path"),wit.forEach(t),Fvo=r(S6,":"),S6.forEach(t),Tvo=i(aa),y=n(aa,"UL",{});var $=s(y);$u=n($,"LI",{});var J7e=s($u);Gie=n(J7e,"STRONG",{});var Ait=s(Gie);Mvo=r(Ait,"albert"),Ait.forEach(t),Evo=r(J7e," \u2014 "),aq=n(J7e,"A",{href:!0});var Lit=s(aq);Cvo=r(Lit,"AlbertModel"),Lit.forEach(t),wvo=r(J7e," (ALBERT model)"),J7e.forEach(t),Avo=i($),ku=n($,"LI",{});var Y7e=s(ku);Oie=n(Y7e,"STRONG",{});var yit=s(Oie);Lvo=r(yit,"bart"),yit.forEach(t),yvo=r(Y7e," \u2014 "),nq=n(Y7e,"A",{href:!0});var xit=s(nq);xvo=r(xit,"BartModel"),xit.forEach(t),$vo=r(Y7e," (BART model)"),Y7e.forEach(t),kvo=i($),Su=n($,"LI",{});var K7e=s(Su);Vie=n(K7e,"STRONG",{});var $it=s(Vie);Svo=r($it,"beit"),$it.forEach(t),Rvo=r(K7e," \u2014 "),sq=n(K7e,"A",{href:!0});var kit=s(sq);Pvo=r(kit,"BeitModel"),kit.forEach(t),Bvo=r(K7e," (BEiT model)"),K7e.forEach(t),Ivo=i($),Ru=n($,"LI",{});var Z7e=s(Ru);Xie=n(Z7e,"STRONG",{});var Sit=s(Xie);Nvo=r(Sit,"bert"),Sit.forEach(t),qvo=r(Z7e," \u2014 "),lq=n(Z7e,"A",{href:!0});var Rit=s(lq);jvo=r(Rit,"BertModel"),Rit.forEach(t),Dvo=r(Z7e," (BERT model)"),Z7e.forEach(t),Gvo=i($),Pu=n($,"LI",{});var e8e=s(Pu);zie=n(e8e,"STRONG",{});var Pit=s(zie);Ovo=r(Pit,"bert-generation"),Pit.forEach(t),Vvo=r(e8e," \u2014 "),iq=n(e8e,"A",{href:!0});var Bit=s(iq);Xvo=r(Bit,"BertGenerationEncoder"),Bit.forEach(t),zvo=r(e8e," (Bert Generation model)"),e8e.forEach(t),Qvo=i($),Bu=n($,"LI",{});var o8e=s(Bu);Qie=n(o8e,"STRONG",{});var Iit=s(Qie);Wvo=r(Iit,"big_bird"),Iit.forEach(t),Hvo=r(o8e," \u2014 "),dq=n(o8e,"A",{href:!0});var Nit=s(dq);Uvo=r(Nit,"BigBirdModel"),Nit.forEach(t),Jvo=r(o8e," (BigBird model)"),o8e.forEach(t),Yvo=i($),Iu=n($,"LI",{});var r8e=s(Iu);Wie=n(r8e,"STRONG",{});var qit=s(Wie);Kvo=r(qit,"bigbird_pegasus"),qit.forEach(t),Zvo=r(r8e," \u2014 "),cq=n(r8e,"A",{href:!0});var jit=s(cq);eFo=r(jit,"BigBirdPegasusModel"),jit.forEach(t),oFo=r(r8e," (BigBird-Pegasus model)"),r8e.forEach(t),rFo=i($),Nu=n($,"LI",{});var t8e=s(Nu);Hie=n(t8e,"STRONG",{});var Dit=s(Hie);tFo=r(Dit,"blenderbot"),Dit.forEach(t),aFo=r(t8e," \u2014 "),mq=n(t8e,"A",{href:!0});var Git=s(mq);nFo=r(Git,"BlenderbotModel"),Git.forEach(t),sFo=r(t8e," (Blenderbot model)"),t8e.forEach(t),lFo=i($),qu=n($,"LI",{});var a8e=s(qu);Uie=n(a8e,"STRONG",{});var Oit=s(Uie);iFo=r(Oit,"blenderbot-small"),Oit.forEach(t),dFo=r(a8e," \u2014 "),fq=n(a8e,"A",{href:!0});var Vit=s(fq);cFo=r(Vit,"BlenderbotSmallModel"),Vit.forEach(t),mFo=r(a8e," (BlenderbotSmall model)"),a8e.forEach(t),fFo=i($),ju=n($,"LI",{});var n8e=s(ju);Jie=n(n8e,"STRONG",{});var Xit=s(Jie);gFo=r(Xit,"bloom"),Xit.forEach(t),hFo=r(n8e," \u2014 "),gq=n(n8e,"A",{href:!0});var zit=s(gq);uFo=r(zit,"BloomModel"),zit.forEach(t),pFo=r(n8e," (BLOOM model)"),n8e.forEach(t),_Fo=i($),Du=n($,"LI",{});var s8e=s(Du);Yie=n(s8e,"STRONG",{});var Qit=s(Yie);bFo=r(Qit,"camembert"),Qit.forEach(t),vFo=r(s8e," \u2014 "),hq=n(s8e,"A",{href:!0});var Wit=s(hq);FFo=r(Wit,"CamembertModel"),Wit.forEach(t),TFo=r(s8e," (CamemBERT model)"),s8e.forEach(t),MFo=i($),Gu=n($,"LI",{});var l8e=s(Gu);Kie=n(l8e,"STRONG",{});var Hit=s(Kie);EFo=r(Hit,"canine"),Hit.forEach(t),CFo=r(l8e," \u2014 "),uq=n(l8e,"A",{href:!0});var Uit=s(uq);wFo=r(Uit,"CanineModel"),Uit.forEach(t),AFo=r(l8e," (CANINE model)"),l8e.forEach(t),LFo=i($),Ou=n($,"LI",{});var i8e=s(Ou);Zie=n(i8e,"STRONG",{});var Jit=s(Zie);yFo=r(Jit,"clip"),Jit.forEach(t),xFo=r(i8e," \u2014 "),pq=n(i8e,"A",{href:!0});var Yit=s(pq);$Fo=r(Yit,"CLIPModel"),Yit.forEach(t),kFo=r(i8e," (CLIP model)"),i8e.forEach(t),SFo=i($),Vu=n($,"LI",{});var d8e=s(Vu);ede=n(d8e,"STRONG",{});var Kit=s(ede);RFo=r(Kit,"convbert"),Kit.forEach(t),PFo=r(d8e," \u2014 "),_q=n(d8e,"A",{href:!0});var Zit=s(_q);BFo=r(Zit,"ConvBertModel"),Zit.forEach(t),IFo=r(d8e," (ConvBERT model)"),d8e.forEach(t),NFo=i($),Xu=n($,"LI",{});var c8e=s(Xu);ode=n(c8e,"STRONG",{});var edt=s(ode);qFo=r(edt,"convnext"),edt.forEach(t),jFo=r(c8e," \u2014 "),bq=n(c8e,"A",{href:!0});var odt=s(bq);DFo=r(odt,"ConvNextModel"),odt.forEach(t),GFo=r(c8e," (ConvNeXT model)"),c8e.forEach(t),OFo=i($),zu=n($,"LI",{});var m8e=s(zu);rde=n(m8e,"STRONG",{});var rdt=s(rde);VFo=r(rdt,"ctrl"),rdt.forEach(t),XFo=r(m8e," \u2014 "),vq=n(m8e,"A",{href:!0});var tdt=s(vq);zFo=r(tdt,"CTRLModel"),tdt.forEach(t),QFo=r(m8e," (CTRL model)"),m8e.forEach(t),WFo=i($),Qu=n($,"LI",{});var f8e=s(Qu);tde=n(f8e,"STRONG",{});var adt=s(tde);HFo=r(adt,"cvt"),adt.forEach(t),UFo=r(f8e," \u2014 "),Fq=n(f8e,"A",{href:!0});var ndt=s(Fq);JFo=r(ndt,"CvtModel"),ndt.forEach(t),YFo=r(f8e," (CvT model)"),f8e.forEach(t),KFo=i($),Wu=n($,"LI",{});var g8e=s(Wu);ade=n(g8e,"STRONG",{});var sdt=s(ade);ZFo=r(sdt,"data2vec-audio"),sdt.forEach(t),e1o=r(g8e," \u2014 "),Tq=n(g8e,"A",{href:!0});var ldt=s(Tq);o1o=r(ldt,"Data2VecAudioModel"),ldt.forEach(t),r1o=r(g8e," (Data2VecAudio model)"),g8e.forEach(t),t1o=i($),Hu=n($,"LI",{});var h8e=s(Hu);nde=n(h8e,"STRONG",{});var idt=s(nde);a1o=r(idt,"data2vec-text"),idt.forEach(t),n1o=r(h8e," \u2014 "),Mq=n(h8e,"A",{href:!0});var ddt=s(Mq);s1o=r(ddt,"Data2VecTextModel"),ddt.forEach(t),l1o=r(h8e," (Data2VecText model)"),h8e.forEach(t),i1o=i($),Uu=n($,"LI",{});var u8e=s(Uu);sde=n(u8e,"STRONG",{});var cdt=s(sde);d1o=r(cdt,"data2vec-vision"),cdt.forEach(t),c1o=r(u8e," \u2014 "),Eq=n(u8e,"A",{href:!0});var mdt=s(Eq);m1o=r(mdt,"Data2VecVisionModel"),mdt.forEach(t),f1o=r(u8e," (Data2VecVision model)"),u8e.forEach(t),g1o=i($),Ju=n($,"LI",{});var p8e=s(Ju);lde=n(p8e,"STRONG",{});var fdt=s(lde);h1o=r(fdt,"deberta"),fdt.forEach(t),u1o=r(p8e," \u2014 "),Cq=n(p8e,"A",{href:!0});var gdt=s(Cq);p1o=r(gdt,"DebertaModel"),gdt.forEach(t),_1o=r(p8e," (DeBERTa model)"),p8e.forEach(t),b1o=i($),Yu=n($,"LI",{});var _8e=s(Yu);ide=n(_8e,"STRONG",{});var hdt=s(ide);v1o=r(hdt,"deberta-v2"),hdt.forEach(t),F1o=r(_8e," \u2014 "),wq=n(_8e,"A",{href:!0});var udt=s(wq);T1o=r(udt,"DebertaV2Model"),udt.forEach(t),M1o=r(_8e," (DeBERTa-v2 model)"),_8e.forEach(t),E1o=i($),Ku=n($,"LI",{});var b8e=s(Ku);dde=n(b8e,"STRONG",{});var pdt=s(dde);C1o=r(pdt,"decision_transformer"),pdt.forEach(t),w1o=r(b8e," \u2014 "),Aq=n(b8e,"A",{href:!0});var _dt=s(Aq);A1o=r(_dt,"DecisionTransformerModel"),_dt.forEach(t),L1o=r(b8e," (Decision Transformer model)"),b8e.forEach(t),y1o=i($),Zu=n($,"LI",{});var v8e=s(Zu);cde=n(v8e,"STRONG",{});var bdt=s(cde);x1o=r(bdt,"deit"),bdt.forEach(t),$1o=r(v8e," \u2014 "),Lq=n(v8e,"A",{href:!0});var vdt=s(Lq);k1o=r(vdt,"DeiTModel"),vdt.forEach(t),S1o=r(v8e," (DeiT model)"),v8e.forEach(t),R1o=i($),ep=n($,"LI",{});var F8e=s(ep);mde=n(F8e,"STRONG",{});var Fdt=s(mde);P1o=r(Fdt,"detr"),Fdt.forEach(t),B1o=r(F8e," \u2014 "),yq=n(F8e,"A",{href:!0});var Tdt=s(yq);I1o=r(Tdt,"DetrModel"),Tdt.forEach(t),N1o=r(F8e," (DETR model)"),F8e.forEach(t),q1o=i($),op=n($,"LI",{});var T8e=s(op);fde=n(T8e,"STRONG",{});var Mdt=s(fde);j1o=r(Mdt,"distilbert"),Mdt.forEach(t),D1o=r(T8e," \u2014 "),xq=n(T8e,"A",{href:!0});var Edt=s(xq);G1o=r(Edt,"DistilBertModel"),Edt.forEach(t),O1o=r(T8e," (DistilBERT model)"),T8e.forEach(t),V1o=i($),rp=n($,"LI",{});var M8e=s(rp);gde=n(M8e,"STRONG",{});var Cdt=s(gde);X1o=r(Cdt,"dpr"),Cdt.forEach(t),z1o=r(M8e," \u2014 "),$q=n(M8e,"A",{href:!0});var wdt=s($q);Q1o=r(wdt,"DPRQuestionEncoder"),wdt.forEach(t),W1o=r(M8e," (DPR model)"),M8e.forEach(t),H1o=i($),tp=n($,"LI",{});var E8e=s(tp);hde=n(E8e,"STRONG",{});var Adt=s(hde);U1o=r(Adt,"dpt"),Adt.forEach(t),J1o=r(E8e," \u2014 "),kq=n(E8e,"A",{href:!0});var Ldt=s(kq);Y1o=r(Ldt,"DPTModel"),Ldt.forEach(t),K1o=r(E8e," (DPT model)"),E8e.forEach(t),Z1o=i($),ap=n($,"LI",{});var C8e=s(ap);ude=n(C8e,"STRONG",{});var ydt=s(ude);eTo=r(ydt,"electra"),ydt.forEach(t),oTo=r(C8e," \u2014 "),Sq=n(C8e,"A",{href:!0});var xdt=s(Sq);rTo=r(xdt,"ElectraModel"),xdt.forEach(t),tTo=r(C8e," (ELECTRA model)"),C8e.forEach(t),aTo=i($),np=n($,"LI",{});var w8e=s(np);pde=n(w8e,"STRONG",{});var $dt=s(pde);nTo=r($dt,"flaubert"),$dt.forEach(t),sTo=r(w8e," \u2014 "),Rq=n(w8e,"A",{href:!0});var kdt=s(Rq);lTo=r(kdt,"FlaubertModel"),kdt.forEach(t),iTo=r(w8e," (FlauBERT model)"),w8e.forEach(t),dTo=i($),sp=n($,"LI",{});var A8e=s(sp);_de=n(A8e,"STRONG",{});var Sdt=s(_de);cTo=r(Sdt,"flava"),Sdt.forEach(t),mTo=r(A8e," \u2014 "),Pq=n(A8e,"A",{href:!0});var Rdt=s(Pq);fTo=r(Rdt,"FlavaModel"),Rdt.forEach(t),gTo=r(A8e," (FLAVA model)"),A8e.forEach(t),hTo=i($),lp=n($,"LI",{});var L8e=s(lp);bde=n(L8e,"STRONG",{});var Pdt=s(bde);uTo=r(Pdt,"fnet"),Pdt.forEach(t),pTo=r(L8e," \u2014 "),Bq=n(L8e,"A",{href:!0});var Bdt=s(Bq);_To=r(Bdt,"FNetModel"),Bdt.forEach(t),bTo=r(L8e," (FNet model)"),L8e.forEach(t),vTo=i($),ip=n($,"LI",{});var y8e=s(ip);vde=n(y8e,"STRONG",{});var Idt=s(vde);FTo=r(Idt,"fsmt"),Idt.forEach(t),TTo=r(y8e," \u2014 "),Iq=n(y8e,"A",{href:!0});var Ndt=s(Iq);MTo=r(Ndt,"FSMTModel"),Ndt.forEach(t),ETo=r(y8e," (FairSeq Machine-Translation model)"),y8e.forEach(t),CTo=i($),Vs=n($,"LI",{});var Kk=s(Vs);Fde=n(Kk,"STRONG",{});var qdt=s(Fde);wTo=r(qdt,"funnel"),qdt.forEach(t),ATo=r(Kk," \u2014 "),Nq=n(Kk,"A",{href:!0});var jdt=s(Nq);LTo=r(jdt,"FunnelModel"),jdt.forEach(t),yTo=r(Kk," or "),qq=n(Kk,"A",{href:!0});var Ddt=s(qq);xTo=r(Ddt,"FunnelBaseModel"),Ddt.forEach(t),$To=r(Kk," (Funnel Transformer model)"),Kk.forEach(t),kTo=i($),dp=n($,"LI",{});var x8e=s(dp);Tde=n(x8e,"STRONG",{});var Gdt=s(Tde);STo=r(Gdt,"glpn"),Gdt.forEach(t),RTo=r(x8e," \u2014 "),jq=n(x8e,"A",{href:!0});var Odt=s(jq);PTo=r(Odt,"GLPNModel"),Odt.forEach(t),BTo=r(x8e," (GLPN model)"),x8e.forEach(t),ITo=i($),cp=n($,"LI",{});var $8e=s(cp);Mde=n($8e,"STRONG",{});var Vdt=s(Mde);NTo=r(Vdt,"gpt2"),Vdt.forEach(t),qTo=r($8e," \u2014 "),Dq=n($8e,"A",{href:!0});var Xdt=s(Dq);jTo=r(Xdt,"GPT2Model"),Xdt.forEach(t),DTo=r($8e," (OpenAI GPT-2 model)"),$8e.forEach(t),GTo=i($),mp=n($,"LI",{});var k8e=s(mp);Ede=n(k8e,"STRONG",{});var zdt=s(Ede);OTo=r(zdt,"gpt_neo"),zdt.forEach(t),VTo=r(k8e," \u2014 "),Gq=n(k8e,"A",{href:!0});var Qdt=s(Gq);XTo=r(Qdt,"GPTNeoModel"),Qdt.forEach(t),zTo=r(k8e," (GPT Neo model)"),k8e.forEach(t),QTo=i($),fp=n($,"LI",{});var S8e=s(fp);Cde=n(S8e,"STRONG",{});var Wdt=s(Cde);WTo=r(Wdt,"gpt_neox"),Wdt.forEach(t),HTo=r(S8e," \u2014 "),Oq=n(S8e,"A",{href:!0});var Hdt=s(Oq);UTo=r(Hdt,"GPTNeoXModel"),Hdt.forEach(t),JTo=r(S8e," (GPT NeoX model)"),S8e.forEach(t),YTo=i($),gp=n($,"LI",{});var R8e=s(gp);wde=n(R8e,"STRONG",{});var Udt=s(wde);KTo=r(Udt,"gptj"),Udt.forEach(t),ZTo=r(R8e," \u2014 "),Vq=n(R8e,"A",{href:!0});var Jdt=s(Vq);eMo=r(Jdt,"GPTJModel"),Jdt.forEach(t),oMo=r(R8e," (GPT-J model)"),R8e.forEach(t),rMo=i($),hp=n($,"LI",{});var P8e=s(hp);Ade=n(P8e,"STRONG",{});var Ydt=s(Ade);tMo=r(Ydt,"hubert"),Ydt.forEach(t),aMo=r(P8e," \u2014 "),Xq=n(P8e,"A",{href:!0});var Kdt=s(Xq);nMo=r(Kdt,"HubertModel"),Kdt.forEach(t),sMo=r(P8e," (Hubert model)"),P8e.forEach(t),lMo=i($),up=n($,"LI",{});var B8e=s(up);Lde=n(B8e,"STRONG",{});var Zdt=s(Lde);iMo=r(Zdt,"ibert"),Zdt.forEach(t),dMo=r(B8e," \u2014 "),zq=n(B8e,"A",{href:!0});var ect=s(zq);cMo=r(ect,"IBertModel"),ect.forEach(t),mMo=r(B8e," (I-BERT model)"),B8e.forEach(t),fMo=i($),pp=n($,"LI",{});var I8e=s(pp);yde=n(I8e,"STRONG",{});var oct=s(yde);gMo=r(oct,"imagegpt"),oct.forEach(t),hMo=r(I8e," \u2014 "),Qq=n(I8e,"A",{href:!0});var rct=s(Qq);uMo=r(rct,"ImageGPTModel"),rct.forEach(t),pMo=r(I8e," (ImageGPT model)"),I8e.forEach(t),_Mo=i($),_p=n($,"LI",{});var N8e=s(_p);xde=n(N8e,"STRONG",{});var tct=s(xde);bMo=r(tct,"layoutlm"),tct.forEach(t),vMo=r(N8e," \u2014 "),Wq=n(N8e,"A",{href:!0});var act=s(Wq);FMo=r(act,"LayoutLMModel"),act.forEach(t),TMo=r(N8e," (LayoutLM model)"),N8e.forEach(t),MMo=i($),bp=n($,"LI",{});var q8e=s(bp);$de=n(q8e,"STRONG",{});var nct=s($de);EMo=r(nct,"layoutlmv2"),nct.forEach(t),CMo=r(q8e," \u2014 "),Hq=n(q8e,"A",{href:!0});var sct=s(Hq);wMo=r(sct,"LayoutLMv2Model"),sct.forEach(t),AMo=r(q8e," (LayoutLMv2 model)"),q8e.forEach(t),LMo=i($),vp=n($,"LI",{});var j8e=s(vp);kde=n(j8e,"STRONG",{});var lct=s(kde);yMo=r(lct,"layoutlmv3"),lct.forEach(t),xMo=r(j8e," \u2014 "),Uq=n(j8e,"A",{href:!0});var ict=s(Uq);$Mo=r(ict,"LayoutLMv3Model"),ict.forEach(t),kMo=r(j8e," (LayoutLMv3 model)"),j8e.forEach(t),SMo=i($),Fp=n($,"LI",{});var D8e=s(Fp);Sde=n(D8e,"STRONG",{});var dct=s(Sde);RMo=r(dct,"led"),dct.forEach(t),PMo=r(D8e," \u2014 "),Jq=n(D8e,"A",{href:!0});var cct=s(Jq);BMo=r(cct,"LEDModel"),cct.forEach(t),IMo=r(D8e," (LED model)"),D8e.forEach(t),NMo=i($),Tp=n($,"LI",{});var G8e=s(Tp);Rde=n(G8e,"STRONG",{});var mct=s(Rde);qMo=r(mct,"levit"),mct.forEach(t),jMo=r(G8e," \u2014 "),Yq=n(G8e,"A",{href:!0});var fct=s(Yq);DMo=r(fct,"LevitModel"),fct.forEach(t),GMo=r(G8e," (LeViT model)"),G8e.forEach(t),OMo=i($),Mp=n($,"LI",{});var O8e=s(Mp);Pde=n(O8e,"STRONG",{});var gct=s(Pde);VMo=r(gct,"longformer"),gct.forEach(t),XMo=r(O8e," \u2014 "),Kq=n(O8e,"A",{href:!0});var hct=s(Kq);zMo=r(hct,"LongformerModel"),hct.forEach(t),QMo=r(O8e," (Longformer model)"),O8e.forEach(t),WMo=i($),Ep=n($,"LI",{});var V8e=s(Ep);Bde=n(V8e,"STRONG",{});var uct=s(Bde);HMo=r(uct,"longt5"),uct.forEach(t),UMo=r(V8e," \u2014 "),Zq=n(V8e,"A",{href:!0});var pct=s(Zq);JMo=r(pct,"LongT5Model"),pct.forEach(t),YMo=r(V8e," (LongT5 model)"),V8e.forEach(t),KMo=i($),Cp=n($,"LI",{});var X8e=s(Cp);Ide=n(X8e,"STRONG",{});var _ct=s(Ide);ZMo=r(_ct,"luke"),_ct.forEach(t),eEo=r(X8e," \u2014 "),ej=n(X8e,"A",{href:!0});var bct=s(ej);oEo=r(bct,"LukeModel"),bct.forEach(t),rEo=r(X8e," (LUKE model)"),X8e.forEach(t),tEo=i($),wp=n($,"LI",{});var z8e=s(wp);Nde=n(z8e,"STRONG",{});var vct=s(Nde);aEo=r(vct,"lxmert"),vct.forEach(t),nEo=r(z8e," \u2014 "),oj=n(z8e,"A",{href:!0});var Fct=s(oj);sEo=r(Fct,"LxmertModel"),Fct.forEach(t),lEo=r(z8e," (LXMERT model)"),z8e.forEach(t),iEo=i($),Ap=n($,"LI",{});var Q8e=s(Ap);qde=n(Q8e,"STRONG",{});var Tct=s(qde);dEo=r(Tct,"m2m_100"),Tct.forEach(t),cEo=r(Q8e," \u2014 "),rj=n(Q8e,"A",{href:!0});var Mct=s(rj);mEo=r(Mct,"M2M100Model"),Mct.forEach(t),fEo=r(Q8e," (M2M100 model)"),Q8e.forEach(t),gEo=i($),Lp=n($,"LI",{});var W8e=s(Lp);jde=n(W8e,"STRONG",{});var Ect=s(jde);hEo=r(Ect,"marian"),Ect.forEach(t),uEo=r(W8e," \u2014 "),tj=n(W8e,"A",{href:!0});var Cct=s(tj);pEo=r(Cct,"MarianModel"),Cct.forEach(t),_Eo=r(W8e," (Marian model)"),W8e.forEach(t),bEo=i($),yp=n($,"LI",{});var H8e=s(yp);Dde=n(H8e,"STRONG",{});var wct=s(Dde);vEo=r(wct,"maskformer"),wct.forEach(t),FEo=r(H8e," \u2014 "),aj=n(H8e,"A",{href:!0});var Act=s(aj);TEo=r(Act,"MaskFormerModel"),Act.forEach(t),MEo=r(H8e," (MaskFormer model)"),H8e.forEach(t),EEo=i($),xp=n($,"LI",{});var U8e=s(xp);Gde=n(U8e,"STRONG",{});var Lct=s(Gde);CEo=r(Lct,"mbart"),Lct.forEach(t),wEo=r(U8e," \u2014 "),nj=n(U8e,"A",{href:!0});var yct=s(nj);AEo=r(yct,"MBartModel"),yct.forEach(t),LEo=r(U8e," (mBART model)"),U8e.forEach(t),yEo=i($),$p=n($,"LI",{});var J8e=s($p);Ode=n(J8e,"STRONG",{});var xct=s(Ode);xEo=r(xct,"mctct"),xct.forEach(t),$Eo=r(J8e," \u2014 "),sj=n(J8e,"A",{href:!0});var $ct=s(sj);kEo=r($ct,"MCTCTModel"),$ct.forEach(t),SEo=r(J8e," (M-CTC-T model)"),J8e.forEach(t),REo=i($),kp=n($,"LI",{});var Y8e=s(kp);Vde=n(Y8e,"STRONG",{});var kct=s(Vde);PEo=r(kct,"megatron-bert"),kct.forEach(t),BEo=r(Y8e," \u2014 "),lj=n(Y8e,"A",{href:!0});var Sct=s(lj);IEo=r(Sct,"MegatronBertModel"),Sct.forEach(t),NEo=r(Y8e," (Megatron-BERT model)"),Y8e.forEach(t),qEo=i($),Sp=n($,"LI",{});var K8e=s(Sp);Xde=n(K8e,"STRONG",{});var Rct=s(Xde);jEo=r(Rct,"mobilebert"),Rct.forEach(t),DEo=r(K8e," \u2014 "),ij=n(K8e,"A",{href:!0});var Pct=s(ij);GEo=r(Pct,"MobileBertModel"),Pct.forEach(t),OEo=r(K8e," (MobileBERT model)"),K8e.forEach(t),VEo=i($),Rp=n($,"LI",{});var Z8e=s(Rp);zde=n(Z8e,"STRONG",{});var Bct=s(zde);XEo=r(Bct,"mpnet"),Bct.forEach(t),zEo=r(Z8e," \u2014 "),dj=n(Z8e,"A",{href:!0});var Ict=s(dj);QEo=r(Ict,"MPNetModel"),Ict.forEach(t),WEo=r(Z8e," (MPNet model)"),Z8e.forEach(t),HEo=i($),Pp=n($,"LI",{});var e9e=s(Pp);Qde=n(e9e,"STRONG",{});var Nct=s(Qde);UEo=r(Nct,"mt5"),Nct.forEach(t),JEo=r(e9e," \u2014 "),cj=n(e9e,"A",{href:!0});var qct=s(cj);YEo=r(qct,"MT5Model"),qct.forEach(t),KEo=r(e9e," (MT5 model)"),e9e.forEach(t),ZEo=i($),Bp=n($,"LI",{});var o9e=s(Bp);Wde=n(o9e,"STRONG",{});var jct=s(Wde);e4o=r(jct,"nezha"),jct.forEach(t),o4o=r(o9e," \u2014 "),mj=n(o9e,"A",{href:!0});var Dct=s(mj);r4o=r(Dct,"NezhaModel"),Dct.forEach(t),t4o=r(o9e," (Nezha model)"),o9e.forEach(t),a4o=i($),Ip=n($,"LI",{});var r9e=s(Ip);Hde=n(r9e,"STRONG",{});var Gct=s(Hde);n4o=r(Gct,"nystromformer"),Gct.forEach(t),s4o=r(r9e," \u2014 "),fj=n(r9e,"A",{href:!0});var Oct=s(fj);l4o=r(Oct,"NystromformerModel"),Oct.forEach(t),i4o=r(r9e," (Nystr\xF6mformer model)"),r9e.forEach(t),d4o=i($),Np=n($,"LI",{});var t9e=s(Np);Ude=n(t9e,"STRONG",{});var Vct=s(Ude);c4o=r(Vct,"openai-gpt"),Vct.forEach(t),m4o=r(t9e," \u2014 "),gj=n(t9e,"A",{href:!0});var Xct=s(gj);f4o=r(Xct,"OpenAIGPTModel"),Xct.forEach(t),g4o=r(t9e," (OpenAI GPT model)"),t9e.forEach(t),h4o=i($),qp=n($,"LI",{});var a9e=s(qp);Jde=n(a9e,"STRONG",{});var zct=s(Jde);u4o=r(zct,"opt"),zct.forEach(t),p4o=r(a9e," \u2014 "),hj=n(a9e,"A",{href:!0});var Qct=s(hj);_4o=r(Qct,"OPTModel"),Qct.forEach(t),b4o=r(a9e," (OPT model)"),a9e.forEach(t),v4o=i($),jp=n($,"LI",{});var n9e=s(jp);Yde=n(n9e,"STRONG",{});var Wct=s(Yde);F4o=r(Wct,"pegasus"),Wct.forEach(t),T4o=r(n9e," \u2014 "),uj=n(n9e,"A",{href:!0});var Hct=s(uj);M4o=r(Hct,"PegasusModel"),Hct.forEach(t),E4o=r(n9e," (Pegasus model)"),n9e.forEach(t),C4o=i($),Dp=n($,"LI",{});var s9e=s(Dp);Kde=n(s9e,"STRONG",{});var Uct=s(Kde);w4o=r(Uct,"perceiver"),Uct.forEach(t),A4o=r(s9e," \u2014 "),pj=n(s9e,"A",{href:!0});var Jct=s(pj);L4o=r(Jct,"PerceiverModel"),Jct.forEach(t),y4o=r(s9e," (Perceiver model)"),s9e.forEach(t),x4o=i($),Gp=n($,"LI",{});var l9e=s(Gp);Zde=n(l9e,"STRONG",{});var Yct=s(Zde);$4o=r(Yct,"plbart"),Yct.forEach(t),k4o=r(l9e," \u2014 "),_j=n(l9e,"A",{href:!0});var Kct=s(_j);S4o=r(Kct,"PLBartModel"),Kct.forEach(t),R4o=r(l9e," (PLBart model)"),l9e.forEach(t),P4o=i($),Op=n($,"LI",{});var i9e=s(Op);ece=n(i9e,"STRONG",{});var Zct=s(ece);B4o=r(Zct,"poolformer"),Zct.forEach(t),I4o=r(i9e," \u2014 "),bj=n(i9e,"A",{href:!0});var emt=s(bj);N4o=r(emt,"PoolFormerModel"),emt.forEach(t),q4o=r(i9e," (PoolFormer model)"),i9e.forEach(t),j4o=i($),Vp=n($,"LI",{});var d9e=s(Vp);oce=n(d9e,"STRONG",{});var omt=s(oce);D4o=r(omt,"prophetnet"),omt.forEach(t),G4o=r(d9e," \u2014 "),vj=n(d9e,"A",{href:!0});var rmt=s(vj);O4o=r(rmt,"ProphetNetModel"),rmt.forEach(t),V4o=r(d9e," (ProphetNet model)"),d9e.forEach(t),X4o=i($),Xp=n($,"LI",{});var c9e=s(Xp);rce=n(c9e,"STRONG",{});var tmt=s(rce);z4o=r(tmt,"qdqbert"),tmt.forEach(t),Q4o=r(c9e," \u2014 "),Fj=n(c9e,"A",{href:!0});var amt=s(Fj);W4o=r(amt,"QDQBertModel"),amt.forEach(t),H4o=r(c9e," (QDQBert model)"),c9e.forEach(t),U4o=i($),zp=n($,"LI",{});var m9e=s(zp);tce=n(m9e,"STRONG",{});var nmt=s(tce);J4o=r(nmt,"reformer"),nmt.forEach(t),Y4o=r(m9e," \u2014 "),Tj=n(m9e,"A",{href:!0});var smt=s(Tj);K4o=r(smt,"ReformerModel"),smt.forEach(t),Z4o=r(m9e," (Reformer model)"),m9e.forEach(t),eCo=i($),Qp=n($,"LI",{});var f9e=s(Qp);ace=n(f9e,"STRONG",{});var lmt=s(ace);oCo=r(lmt,"regnet"),lmt.forEach(t),rCo=r(f9e," \u2014 "),Mj=n(f9e,"A",{href:!0});var imt=s(Mj);tCo=r(imt,"RegNetModel"),imt.forEach(t),aCo=r(f9e," (RegNet model)"),f9e.forEach(t),nCo=i($),Wp=n($,"LI",{});var g9e=s(Wp);nce=n(g9e,"STRONG",{});var dmt=s(nce);sCo=r(dmt,"rembert"),dmt.forEach(t),lCo=r(g9e," \u2014 "),Ej=n(g9e,"A",{href:!0});var cmt=s(Ej);iCo=r(cmt,"RemBertModel"),cmt.forEach(t),dCo=r(g9e," (RemBERT model)"),g9e.forEach(t),cCo=i($),Hp=n($,"LI",{});var h9e=s(Hp);sce=n(h9e,"STRONG",{});var mmt=s(sce);mCo=r(mmt,"resnet"),mmt.forEach(t),fCo=r(h9e," \u2014 "),Cj=n(h9e,"A",{href:!0});var fmt=s(Cj);gCo=r(fmt,"ResNetModel"),fmt.forEach(t),hCo=r(h9e," (ResNet model)"),h9e.forEach(t),uCo=i($),Up=n($,"LI",{});var u9e=s(Up);lce=n(u9e,"STRONG",{});var gmt=s(lce);pCo=r(gmt,"retribert"),gmt.forEach(t),_Co=r(u9e," \u2014 "),wj=n(u9e,"A",{href:!0});var hmt=s(wj);bCo=r(hmt,"RetriBertModel"),hmt.forEach(t),vCo=r(u9e," (RetriBERT model)"),u9e.forEach(t),FCo=i($),Jp=n($,"LI",{});var p9e=s(Jp);ice=n(p9e,"STRONG",{});var umt=s(ice);TCo=r(umt,"roberta"),umt.forEach(t),MCo=r(p9e," \u2014 "),Aj=n(p9e,"A",{href:!0});var pmt=s(Aj);ECo=r(pmt,"RobertaModel"),pmt.forEach(t),CCo=r(p9e," (RoBERTa model)"),p9e.forEach(t),wCo=i($),Yp=n($,"LI",{});var _9e=s(Yp);dce=n(_9e,"STRONG",{});var _mt=s(dce);ACo=r(_mt,"roformer"),_mt.forEach(t),LCo=r(_9e," \u2014 "),Lj=n(_9e,"A",{href:!0});var bmt=s(Lj);yCo=r(bmt,"RoFormerModel"),bmt.forEach(t),xCo=r(_9e," (RoFormer model)"),_9e.forEach(t),$Co=i($),Kp=n($,"LI",{});var b9e=s(Kp);cce=n(b9e,"STRONG",{});var vmt=s(cce);kCo=r(vmt,"segformer"),vmt.forEach(t),SCo=r(b9e," \u2014 "),yj=n(b9e,"A",{href:!0});var Fmt=s(yj);RCo=r(Fmt,"SegformerModel"),Fmt.forEach(t),PCo=r(b9e," (SegFormer model)"),b9e.forEach(t),BCo=i($),Zp=n($,"LI",{});var v9e=s(Zp);mce=n(v9e,"STRONG",{});var Tmt=s(mce);ICo=r(Tmt,"sew"),Tmt.forEach(t),NCo=r(v9e," \u2014 "),xj=n(v9e,"A",{href:!0});var Mmt=s(xj);qCo=r(Mmt,"SEWModel"),Mmt.forEach(t),jCo=r(v9e," (SEW model)"),v9e.forEach(t),DCo=i($),e_=n($,"LI",{});var F9e=s(e_);fce=n(F9e,"STRONG",{});var Emt=s(fce);GCo=r(Emt,"sew-d"),Emt.forEach(t),OCo=r(F9e," \u2014 "),$j=n(F9e,"A",{href:!0});var Cmt=s($j);VCo=r(Cmt,"SEWDModel"),Cmt.forEach(t),XCo=r(F9e," (SEW-D model)"),F9e.forEach(t),zCo=i($),o_=n($,"LI",{});var T9e=s(o_);gce=n(T9e,"STRONG",{});var wmt=s(gce);QCo=r(wmt,"speech_to_text"),wmt.forEach(t),WCo=r(T9e," \u2014 "),kj=n(T9e,"A",{href:!0});var Amt=s(kj);HCo=r(Amt,"Speech2TextModel"),Amt.forEach(t),UCo=r(T9e," (Speech2Text model)"),T9e.forEach(t),JCo=i($),r_=n($,"LI",{});var M9e=s(r_);hce=n(M9e,"STRONG",{});var Lmt=s(hce);YCo=r(Lmt,"splinter"),Lmt.forEach(t),KCo=r(M9e," \u2014 "),Sj=n(M9e,"A",{href:!0});var ymt=s(Sj);ZCo=r(ymt,"SplinterModel"),ymt.forEach(t),e5o=r(M9e," (Splinter model)"),M9e.forEach(t),o5o=i($),t_=n($,"LI",{});var E9e=s(t_);uce=n(E9e,"STRONG",{});var xmt=s(uce);r5o=r(xmt,"squeezebert"),xmt.forEach(t),t5o=r(E9e," \u2014 "),Rj=n(E9e,"A",{href:!0});var $mt=s(Rj);a5o=r($mt,"SqueezeBertModel"),$mt.forEach(t),n5o=r(E9e," (SqueezeBERT model)"),E9e.forEach(t),s5o=i($),a_=n($,"LI",{});var C9e=s(a_);pce=n(C9e,"STRONG",{});var kmt=s(pce);l5o=r(kmt,"swin"),kmt.forEach(t),i5o=r(C9e," \u2014 "),Pj=n(C9e,"A",{href:!0});var Smt=s(Pj);d5o=r(Smt,"SwinModel"),Smt.forEach(t),c5o=r(C9e," (Swin Transformer model)"),C9e.forEach(t),m5o=i($),n_=n($,"LI",{});var w9e=s(n_);_ce=n(w9e,"STRONG",{});var Rmt=s(_ce);f5o=r(Rmt,"t5"),Rmt.forEach(t),g5o=r(w9e," \u2014 "),Bj=n(w9e,"A",{href:!0});var Pmt=s(Bj);h5o=r(Pmt,"T5Model"),Pmt.forEach(t),u5o=r(w9e," (T5 model)"),w9e.forEach(t),p5o=i($),s_=n($,"LI",{});var A9e=s(s_);bce=n(A9e,"STRONG",{});var Bmt=s(bce);_5o=r(Bmt,"tapas"),Bmt.forEach(t),b5o=r(A9e," \u2014 "),Ij=n(A9e,"A",{href:!0});var Imt=s(Ij);v5o=r(Imt,"TapasModel"),Imt.forEach(t),F5o=r(A9e," (TAPAS model)"),A9e.forEach(t),T5o=i($),l_=n($,"LI",{});var L9e=s(l_);vce=n(L9e,"STRONG",{});var Nmt=s(vce);M5o=r(Nmt,"trajectory_transformer"),Nmt.forEach(t),E5o=r(L9e," \u2014 "),Nj=n(L9e,"A",{href:!0});var qmt=s(Nj);C5o=r(qmt,"TrajectoryTransformerModel"),qmt.forEach(t),w5o=r(L9e," (Trajectory Transformer model)"),L9e.forEach(t),A5o=i($),i_=n($,"LI",{});var y9e=s(i_);Fce=n(y9e,"STRONG",{});var jmt=s(Fce);L5o=r(jmt,"transfo-xl"),jmt.forEach(t),y5o=r(y9e," \u2014 "),qj=n(y9e,"A",{href:!0});var Dmt=s(qj);x5o=r(Dmt,"TransfoXLModel"),Dmt.forEach(t),$5o=r(y9e," (Transformer-XL model)"),y9e.forEach(t),k5o=i($),d_=n($,"LI",{});var x9e=s(d_);Tce=n(x9e,"STRONG",{});var Gmt=s(Tce);S5o=r(Gmt,"unispeech"),Gmt.forEach(t),R5o=r(x9e," \u2014 "),jj=n(x9e,"A",{href:!0});var Omt=s(jj);P5o=r(Omt,"UniSpeechModel"),Omt.forEach(t),B5o=r(x9e," (UniSpeech model)"),x9e.forEach(t),I5o=i($),c_=n($,"LI",{});var $9e=s(c_);Mce=n($9e,"STRONG",{});var Vmt=s(Mce);N5o=r(Vmt,"unispeech-sat"),Vmt.forEach(t),q5o=r($9e," \u2014 "),Dj=n($9e,"A",{href:!0});var Xmt=s(Dj);j5o=r(Xmt,"UniSpeechSatModel"),Xmt.forEach(t),D5o=r($9e," (UniSpeechSat model)"),$9e.forEach(t),G5o=i($),m_=n($,"LI",{});var k9e=s(m_);Ece=n(k9e,"STRONG",{});var zmt=s(Ece);O5o=r(zmt,"van"),zmt.forEach(t),V5o=r(k9e," \u2014 "),Gj=n(k9e,"A",{href:!0});var Qmt=s(Gj);X5o=r(Qmt,"VanModel"),Qmt.forEach(t),z5o=r(k9e," (VAN model)"),k9e.forEach(t),Q5o=i($),f_=n($,"LI",{});var S9e=s(f_);Cce=n(S9e,"STRONG",{});var Wmt=s(Cce);W5o=r(Wmt,"vilt"),Wmt.forEach(t),H5o=r(S9e," \u2014 "),Oj=n(S9e,"A",{href:!0});var Hmt=s(Oj);U5o=r(Hmt,"ViltModel"),Hmt.forEach(t),J5o=r(S9e," (ViLT model)"),S9e.forEach(t),Y5o=i($),g_=n($,"LI",{});var R9e=s(g_);wce=n(R9e,"STRONG",{});var Umt=s(wce);K5o=r(Umt,"vision-text-dual-encoder"),Umt.forEach(t),Z5o=r(R9e," \u2014 "),Vj=n(R9e,"A",{href:!0});var Jmt=s(Vj);e3o=r(Jmt,"VisionTextDualEncoderModel"),Jmt.forEach(t),o3o=r(R9e," (VisionTextDualEncoder model)"),R9e.forEach(t),r3o=i($),h_=n($,"LI",{});var P9e=s(h_);Ace=n(P9e,"STRONG",{});var Ymt=s(Ace);t3o=r(Ymt,"visual_bert"),Ymt.forEach(t),a3o=r(P9e," \u2014 "),Xj=n(P9e,"A",{href:!0});var Kmt=s(Xj);n3o=r(Kmt,"VisualBertModel"),Kmt.forEach(t),s3o=r(P9e," (VisualBERT model)"),P9e.forEach(t),l3o=i($),u_=n($,"LI",{});var B9e=s(u_);Lce=n(B9e,"STRONG",{});var Zmt=s(Lce);i3o=r(Zmt,"vit"),Zmt.forEach(t),d3o=r(B9e," \u2014 "),zj=n(B9e,"A",{href:!0});var eft=s(zj);c3o=r(eft,"ViTModel"),eft.forEach(t),m3o=r(B9e," (ViT model)"),B9e.forEach(t),f3o=i($),p_=n($,"LI",{});var I9e=s(p_);yce=n(I9e,"STRONG",{});var oft=s(yce);g3o=r(oft,"vit_mae"),oft.forEach(t),h3o=r(I9e," \u2014 "),Qj=n(I9e,"A",{href:!0});var rft=s(Qj);u3o=r(rft,"ViTMAEModel"),rft.forEach(t),p3o=r(I9e," (ViTMAE model)"),I9e.forEach(t),_3o=i($),__=n($,"LI",{});var N9e=s(__);xce=n(N9e,"STRONG",{});var tft=s(xce);b3o=r(tft,"wav2vec2"),tft.forEach(t),v3o=r(N9e," \u2014 "),Wj=n(N9e,"A",{href:!0});var aft=s(Wj);F3o=r(aft,"Wav2Vec2Model"),aft.forEach(t),T3o=r(N9e," (Wav2Vec2 model)"),N9e.forEach(t),M3o=i($),b_=n($,"LI",{});var q9e=s(b_);$ce=n(q9e,"STRONG",{});var nft=s($ce);E3o=r(nft,"wav2vec2-conformer"),nft.forEach(t),C3o=r(q9e," \u2014 "),Hj=n(q9e,"A",{href:!0});var sft=s(Hj);w3o=r(sft,"Wav2Vec2ConformerModel"),sft.forEach(t),A3o=r(q9e," (Wav2Vec2-Conformer model)"),q9e.forEach(t),L3o=i($),v_=n($,"LI",{});var j9e=s(v_);kce=n(j9e,"STRONG",{});var lft=s(kce);y3o=r(lft,"wavlm"),lft.forEach(t),x3o=r(j9e," \u2014 "),Uj=n(j9e,"A",{href:!0});var ift=s(Uj);$3o=r(ift,"WavLMModel"),ift.forEach(t),k3o=r(j9e," (WavLM model)"),j9e.forEach(t),S3o=i($),F_=n($,"LI",{});var D9e=s(F_);Sce=n(D9e,"STRONG",{});var dft=s(Sce);R3o=r(dft,"xglm"),dft.forEach(t),P3o=r(D9e," \u2014 "),Jj=n(D9e,"A",{href:!0});var cft=s(Jj);B3o=r(cft,"XGLMModel"),cft.forEach(t),I3o=r(D9e," (XGLM model)"),D9e.forEach(t),N3o=i($),T_=n($,"LI",{});var G9e=s(T_);Rce=n(G9e,"STRONG",{});var mft=s(Rce);q3o=r(mft,"xlm"),mft.forEach(t),j3o=r(G9e," \u2014 "),Yj=n(G9e,"A",{href:!0});var fft=s(Yj);D3o=r(fft,"XLMModel"),fft.forEach(t),G3o=r(G9e," (XLM model)"),G9e.forEach(t),O3o=i($),M_=n($,"LI",{});var O9e=s(M_);Pce=n(O9e,"STRONG",{});var gft=s(Pce);V3o=r(gft,"xlm-prophetnet"),gft.forEach(t),X3o=r(O9e," \u2014 "),Kj=n(O9e,"A",{href:!0});var hft=s(Kj);z3o=r(hft,"XLMProphetNetModel"),hft.forEach(t),Q3o=r(O9e," (XLM-ProphetNet model)"),O9e.forEach(t),W3o=i($),E_=n($,"LI",{});var V9e=s(E_);Bce=n(V9e,"STRONG",{});var uft=s(Bce);H3o=r(uft,"xlm-roberta"),uft.forEach(t),U3o=r(V9e," \u2014 "),Zj=n(V9e,"A",{href:!0});var pft=s(Zj);J3o=r(pft,"XLMRobertaModel"),pft.forEach(t),Y3o=r(V9e," (XLM-RoBERTa model)"),V9e.forEach(t),K3o=i($),C_=n($,"LI",{});var X9e=s(C_);Ice=n(X9e,"STRONG",{});var _ft=s(Ice);Z3o=r(_ft,"xlm-roberta-xl"),_ft.forEach(t),e0o=r(X9e," \u2014 "),eD=n(X9e,"A",{href:!0});var bft=s(eD);o0o=r(bft,"XLMRobertaXLModel"),bft.forEach(t),r0o=r(X9e," (XLM-RoBERTa-XL model)"),X9e.forEach(t),t0o=i($),w_=n($,"LI",{});var z9e=s(w_);Nce=n(z9e,"STRONG",{});var vft=s(Nce);a0o=r(vft,"xlnet"),vft.forEach(t),n0o=r(z9e," \u2014 "),oD=n(z9e,"A",{href:!0});var Fft=s(oD);s0o=r(Fft,"XLNetModel"),Fft.forEach(t),l0o=r(z9e," (XLNet model)"),z9e.forEach(t),i0o=i($),A_=n($,"LI",{});var Q9e=s(A_);qce=n(Q9e,"STRONG",{});var Tft=s(qce);d0o=r(Tft,"yolos"),Tft.forEach(t),c0o=r(Q9e," \u2014 "),rD=n(Q9e,"A",{href:!0});var Mft=s(rD);m0o=r(Mft,"YolosModel"),Mft.forEach(t),f0o=r(Q9e," (YOLOS model)"),Q9e.forEach(t),g0o=i($),L_=n($,"LI",{});var W9e=s(L_);jce=n(W9e,"STRONG",{});var Eft=s(jce);h0o=r(Eft,"yoso"),Eft.forEach(t),u0o=r(W9e," \u2014 "),tD=n(W9e,"A",{href:!0});var Cft=s(tD);p0o=r(Cft,"YosoModel"),Cft.forEach(t),_0o=r(W9e," (YOSO model)"),W9e.forEach(t),$.forEach(t),b0o=i(aa),y_=n(aa,"P",{});var H9e=s(y_);v0o=r(H9e,"The model is set in evaluation mode by default using "),Dce=n(H9e,"CODE",{});var wft=s(Dce);F0o=r(wft,"model.eval()"),wft.forEach(t),T0o=r(H9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=n(H9e,"CODE",{});var Aft=s(Gce);M0o=r(Aft,"model.train()"),Aft.forEach(t),H9e.forEach(t),E0o=i(aa),T(x_.$$.fragment,aa),aa.forEach(t),Ys.forEach(t),eOe=i(m),qi=n(m,"H2",{class:!0});var sXe=s(qi);$_=n(sXe,"A",{id:!0,class:!0,href:!0});var Lft=s($_);Oce=n(Lft,"SPAN",{});var yft=s(Oce);T(s7.$$.fragment,yft),yft.forEach(t),Lft.forEach(t),C0o=i(sXe),Vce=n(sXe,"SPAN",{});var xft=s(Vce);w0o=r(xft,"AutoModelForPreTraining"),xft.forEach(t),sXe.forEach(t),oOe=i(m),$o=n(m,"DIV",{class:!0});var Ks=s($o);T(l7.$$.fragment,Ks),A0o=i(Ks),ji=n(Ks,"P",{});var Toe=s(ji);L0o=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=n(Toe,"A",{href:!0});var $ft=s(aD);y0o=r($ft,"from_pretrained()"),$ft.forEach(t),x0o=r(Toe," class method or the "),nD=n(Toe,"A",{href:!0});var kft=s(nD);$0o=r(kft,"from_config()"),kft.forEach(t),k0o=r(Toe,` class
method.`),Toe.forEach(t),S0o=i(Ks),i7=n(Ks,"P",{});var lXe=s(i7);R0o=r(lXe,"This class cannot be instantiated directly using "),Xce=n(lXe,"CODE",{});var Sft=s(Xce);P0o=r(Sft,"__init__()"),Sft.forEach(t),B0o=r(lXe," (throws an error)."),lXe.forEach(t),I0o=i(Ks),st=n(Ks,"DIV",{class:!0});var R6=s(st);T(d7.$$.fragment,R6),N0o=i(R6),zce=n(R6,"P",{});var Rft=s(zce);q0o=r(Rft,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rft.forEach(t),j0o=i(R6),Di=n(R6,"P",{});var Moe=s(Di);D0o=r(Moe,`Note:
Loading a model from its configuration file does `),Qce=n(Moe,"STRONG",{});var Pft=s(Qce);G0o=r(Pft,"not"),Pft.forEach(t),O0o=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=n(Moe,"A",{href:!0});var Bft=s(sD);V0o=r(Bft,"from_pretrained()"),Bft.forEach(t),X0o=r(Moe," to load the model weights."),Moe.forEach(t),z0o=i(R6),T(k_.$$.fragment,R6),R6.forEach(t),Q0o=i(Ks),Ye=n(Ks,"DIV",{class:!0});var na=s(Ye);T(c7.$$.fragment,na),W0o=i(na),Wce=n(na,"P",{});var Ift=s(Wce);H0o=r(Ift,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Ift.forEach(t),U0o=i(na),Pa=n(na,"P",{});var P6=s(Pa);J0o=r(P6,"The model class to instantiate is selected based on the "),Hce=n(P6,"CODE",{});var Nft=s(Hce);Y0o=r(Nft,"model_type"),Nft.forEach(t),K0o=r(P6,` property of the config object (either
passed as an argument or loaded from `),Uce=n(P6,"CODE",{});var qft=s(Uce);Z0o=r(qft,"pretrained_model_name_or_path"),qft.forEach(t),ewo=r(P6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=n(P6,"CODE",{});var jft=s(Jce);owo=r(jft,"pretrained_model_name_or_path"),jft.forEach(t),rwo=r(P6,":"),P6.forEach(t),two=i(na),G=n(na,"UL",{});var O=s(G);S_=n(O,"LI",{});var U9e=s(S_);Yce=n(U9e,"STRONG",{});var Dft=s(Yce);awo=r(Dft,"albert"),Dft.forEach(t),nwo=r(U9e," \u2014 "),lD=n(U9e,"A",{href:!0});var Gft=s(lD);swo=r(Gft,"AlbertForPreTraining"),Gft.forEach(t),lwo=r(U9e," (ALBERT model)"),U9e.forEach(t),iwo=i(O),R_=n(O,"LI",{});var J9e=s(R_);Kce=n(J9e,"STRONG",{});var Oft=s(Kce);dwo=r(Oft,"bart"),Oft.forEach(t),cwo=r(J9e," \u2014 "),iD=n(J9e,"A",{href:!0});var Vft=s(iD);mwo=r(Vft,"BartForConditionalGeneration"),Vft.forEach(t),fwo=r(J9e," (BART model)"),J9e.forEach(t),gwo=i(O),P_=n(O,"LI",{});var Y9e=s(P_);Zce=n(Y9e,"STRONG",{});var Xft=s(Zce);hwo=r(Xft,"bert"),Xft.forEach(t),uwo=r(Y9e," \u2014 "),dD=n(Y9e,"A",{href:!0});var zft=s(dD);pwo=r(zft,"BertForPreTraining"),zft.forEach(t),_wo=r(Y9e," (BERT model)"),Y9e.forEach(t),bwo=i(O),B_=n(O,"LI",{});var K9e=s(B_);eme=n(K9e,"STRONG",{});var Qft=s(eme);vwo=r(Qft,"big_bird"),Qft.forEach(t),Fwo=r(K9e," \u2014 "),cD=n(K9e,"A",{href:!0});var Wft=s(cD);Two=r(Wft,"BigBirdForPreTraining"),Wft.forEach(t),Mwo=r(K9e," (BigBird model)"),K9e.forEach(t),Ewo=i(O),I_=n(O,"LI",{});var Z9e=s(I_);ome=n(Z9e,"STRONG",{});var Hft=s(ome);Cwo=r(Hft,"bloom"),Hft.forEach(t),wwo=r(Z9e," \u2014 "),mD=n(Z9e,"A",{href:!0});var Uft=s(mD);Awo=r(Uft,"BloomForCausalLM"),Uft.forEach(t),Lwo=r(Z9e," (BLOOM model)"),Z9e.forEach(t),ywo=i(O),N_=n(O,"LI",{});var exe=s(N_);rme=n(exe,"STRONG",{});var Jft=s(rme);xwo=r(Jft,"camembert"),Jft.forEach(t),$wo=r(exe," \u2014 "),fD=n(exe,"A",{href:!0});var Yft=s(fD);kwo=r(Yft,"CamembertForMaskedLM"),Yft.forEach(t),Swo=r(exe," (CamemBERT model)"),exe.forEach(t),Rwo=i(O),q_=n(O,"LI",{});var oxe=s(q_);tme=n(oxe,"STRONG",{});var Kft=s(tme);Pwo=r(Kft,"ctrl"),Kft.forEach(t),Bwo=r(oxe," \u2014 "),gD=n(oxe,"A",{href:!0});var Zft=s(gD);Iwo=r(Zft,"CTRLLMHeadModel"),Zft.forEach(t),Nwo=r(oxe," (CTRL model)"),oxe.forEach(t),qwo=i(O),j_=n(O,"LI",{});var rxe=s(j_);ame=n(rxe,"STRONG",{});var egt=s(ame);jwo=r(egt,"data2vec-text"),egt.forEach(t),Dwo=r(rxe," \u2014 "),hD=n(rxe,"A",{href:!0});var ogt=s(hD);Gwo=r(ogt,"Data2VecTextForMaskedLM"),ogt.forEach(t),Owo=r(rxe," (Data2VecText model)"),rxe.forEach(t),Vwo=i(O),D_=n(O,"LI",{});var txe=s(D_);nme=n(txe,"STRONG",{});var rgt=s(nme);Xwo=r(rgt,"deberta"),rgt.forEach(t),zwo=r(txe," \u2014 "),uD=n(txe,"A",{href:!0});var tgt=s(uD);Qwo=r(tgt,"DebertaForMaskedLM"),tgt.forEach(t),Wwo=r(txe," (DeBERTa model)"),txe.forEach(t),Hwo=i(O),G_=n(O,"LI",{});var axe=s(G_);sme=n(axe,"STRONG",{});var agt=s(sme);Uwo=r(agt,"deberta-v2"),agt.forEach(t),Jwo=r(axe," \u2014 "),pD=n(axe,"A",{href:!0});var ngt=s(pD);Ywo=r(ngt,"DebertaV2ForMaskedLM"),ngt.forEach(t),Kwo=r(axe," (DeBERTa-v2 model)"),axe.forEach(t),Zwo=i(O),O_=n(O,"LI",{});var nxe=s(O_);lme=n(nxe,"STRONG",{});var sgt=s(lme);eAo=r(sgt,"distilbert"),sgt.forEach(t),oAo=r(nxe," \u2014 "),_D=n(nxe,"A",{href:!0});var lgt=s(_D);rAo=r(lgt,"DistilBertForMaskedLM"),lgt.forEach(t),tAo=r(nxe," (DistilBERT model)"),nxe.forEach(t),aAo=i(O),V_=n(O,"LI",{});var sxe=s(V_);ime=n(sxe,"STRONG",{});var igt=s(ime);nAo=r(igt,"electra"),igt.forEach(t),sAo=r(sxe," \u2014 "),bD=n(sxe,"A",{href:!0});var dgt=s(bD);lAo=r(dgt,"ElectraForPreTraining"),dgt.forEach(t),iAo=r(sxe," (ELECTRA model)"),sxe.forEach(t),dAo=i(O),X_=n(O,"LI",{});var lxe=s(X_);dme=n(lxe,"STRONG",{});var cgt=s(dme);cAo=r(cgt,"flaubert"),cgt.forEach(t),mAo=r(lxe," \u2014 "),vD=n(lxe,"A",{href:!0});var mgt=s(vD);fAo=r(mgt,"FlaubertWithLMHeadModel"),mgt.forEach(t),gAo=r(lxe," (FlauBERT model)"),lxe.forEach(t),hAo=i(O),z_=n(O,"LI",{});var ixe=s(z_);cme=n(ixe,"STRONG",{});var fgt=s(cme);uAo=r(fgt,"flava"),fgt.forEach(t),pAo=r(ixe," \u2014 "),FD=n(ixe,"A",{href:!0});var ggt=s(FD);_Ao=r(ggt,"FlavaForPreTraining"),ggt.forEach(t),bAo=r(ixe," (FLAVA model)"),ixe.forEach(t),vAo=i(O),Q_=n(O,"LI",{});var dxe=s(Q_);mme=n(dxe,"STRONG",{});var hgt=s(mme);FAo=r(hgt,"fnet"),hgt.forEach(t),TAo=r(dxe," \u2014 "),TD=n(dxe,"A",{href:!0});var ugt=s(TD);MAo=r(ugt,"FNetForPreTraining"),ugt.forEach(t),EAo=r(dxe," (FNet model)"),dxe.forEach(t),CAo=i(O),W_=n(O,"LI",{});var cxe=s(W_);fme=n(cxe,"STRONG",{});var pgt=s(fme);wAo=r(pgt,"fsmt"),pgt.forEach(t),AAo=r(cxe," \u2014 "),MD=n(cxe,"A",{href:!0});var _gt=s(MD);LAo=r(_gt,"FSMTForConditionalGeneration"),_gt.forEach(t),yAo=r(cxe," (FairSeq Machine-Translation model)"),cxe.forEach(t),xAo=i(O),H_=n(O,"LI",{});var mxe=s(H_);gme=n(mxe,"STRONG",{});var bgt=s(gme);$Ao=r(bgt,"funnel"),bgt.forEach(t),kAo=r(mxe," \u2014 "),ED=n(mxe,"A",{href:!0});var vgt=s(ED);SAo=r(vgt,"FunnelForPreTraining"),vgt.forEach(t),RAo=r(mxe," (Funnel Transformer model)"),mxe.forEach(t),PAo=i(O),U_=n(O,"LI",{});var fxe=s(U_);hme=n(fxe,"STRONG",{});var Fgt=s(hme);BAo=r(Fgt,"gpt2"),Fgt.forEach(t),IAo=r(fxe," \u2014 "),CD=n(fxe,"A",{href:!0});var Tgt=s(CD);NAo=r(Tgt,"GPT2LMHeadModel"),Tgt.forEach(t),qAo=r(fxe," (OpenAI GPT-2 model)"),fxe.forEach(t),jAo=i(O),J_=n(O,"LI",{});var gxe=s(J_);ume=n(gxe,"STRONG",{});var Mgt=s(ume);DAo=r(Mgt,"ibert"),Mgt.forEach(t),GAo=r(gxe," \u2014 "),wD=n(gxe,"A",{href:!0});var Egt=s(wD);OAo=r(Egt,"IBertForMaskedLM"),Egt.forEach(t),VAo=r(gxe," (I-BERT model)"),gxe.forEach(t),XAo=i(O),Y_=n(O,"LI",{});var hxe=s(Y_);pme=n(hxe,"STRONG",{});var Cgt=s(pme);zAo=r(Cgt,"layoutlm"),Cgt.forEach(t),QAo=r(hxe," \u2014 "),AD=n(hxe,"A",{href:!0});var wgt=s(AD);WAo=r(wgt,"LayoutLMForMaskedLM"),wgt.forEach(t),HAo=r(hxe," (LayoutLM model)"),hxe.forEach(t),UAo=i(O),K_=n(O,"LI",{});var uxe=s(K_);_me=n(uxe,"STRONG",{});var Agt=s(_me);JAo=r(Agt,"longformer"),Agt.forEach(t),YAo=r(uxe," \u2014 "),LD=n(uxe,"A",{href:!0});var Lgt=s(LD);KAo=r(Lgt,"LongformerForMaskedLM"),Lgt.forEach(t),ZAo=r(uxe," (Longformer model)"),uxe.forEach(t),e6o=i(O),Z_=n(O,"LI",{});var pxe=s(Z_);bme=n(pxe,"STRONG",{});var ygt=s(bme);o6o=r(ygt,"lxmert"),ygt.forEach(t),r6o=r(pxe," \u2014 "),yD=n(pxe,"A",{href:!0});var xgt=s(yD);t6o=r(xgt,"LxmertForPreTraining"),xgt.forEach(t),a6o=r(pxe," (LXMERT model)"),pxe.forEach(t),n6o=i(O),e2=n(O,"LI",{});var _xe=s(e2);vme=n(_xe,"STRONG",{});var $gt=s(vme);s6o=r($gt,"megatron-bert"),$gt.forEach(t),l6o=r(_xe," \u2014 "),xD=n(_xe,"A",{href:!0});var kgt=s(xD);i6o=r(kgt,"MegatronBertForPreTraining"),kgt.forEach(t),d6o=r(_xe," (Megatron-BERT model)"),_xe.forEach(t),c6o=i(O),o2=n(O,"LI",{});var bxe=s(o2);Fme=n(bxe,"STRONG",{});var Sgt=s(Fme);m6o=r(Sgt,"mobilebert"),Sgt.forEach(t),f6o=r(bxe," \u2014 "),$D=n(bxe,"A",{href:!0});var Rgt=s($D);g6o=r(Rgt,"MobileBertForPreTraining"),Rgt.forEach(t),h6o=r(bxe," (MobileBERT model)"),bxe.forEach(t),u6o=i(O),r2=n(O,"LI",{});var vxe=s(r2);Tme=n(vxe,"STRONG",{});var Pgt=s(Tme);p6o=r(Pgt,"mpnet"),Pgt.forEach(t),_6o=r(vxe," \u2014 "),kD=n(vxe,"A",{href:!0});var Bgt=s(kD);b6o=r(Bgt,"MPNetForMaskedLM"),Bgt.forEach(t),v6o=r(vxe," (MPNet model)"),vxe.forEach(t),F6o=i(O),t2=n(O,"LI",{});var Fxe=s(t2);Mme=n(Fxe,"STRONG",{});var Igt=s(Mme);T6o=r(Igt,"nezha"),Igt.forEach(t),M6o=r(Fxe," \u2014 "),SD=n(Fxe,"A",{href:!0});var Ngt=s(SD);E6o=r(Ngt,"NezhaForPreTraining"),Ngt.forEach(t),C6o=r(Fxe," (Nezha model)"),Fxe.forEach(t),w6o=i(O),a2=n(O,"LI",{});var Txe=s(a2);Eme=n(Txe,"STRONG",{});var qgt=s(Eme);A6o=r(qgt,"openai-gpt"),qgt.forEach(t),L6o=r(Txe," \u2014 "),RD=n(Txe,"A",{href:!0});var jgt=s(RD);y6o=r(jgt,"OpenAIGPTLMHeadModel"),jgt.forEach(t),x6o=r(Txe," (OpenAI GPT model)"),Txe.forEach(t),$6o=i(O),n2=n(O,"LI",{});var Mxe=s(n2);Cme=n(Mxe,"STRONG",{});var Dgt=s(Cme);k6o=r(Dgt,"retribert"),Dgt.forEach(t),S6o=r(Mxe," \u2014 "),PD=n(Mxe,"A",{href:!0});var Ggt=s(PD);R6o=r(Ggt,"RetriBertModel"),Ggt.forEach(t),P6o=r(Mxe," (RetriBERT model)"),Mxe.forEach(t),B6o=i(O),s2=n(O,"LI",{});var Exe=s(s2);wme=n(Exe,"STRONG",{});var Ogt=s(wme);I6o=r(Ogt,"roberta"),Ogt.forEach(t),N6o=r(Exe," \u2014 "),BD=n(Exe,"A",{href:!0});var Vgt=s(BD);q6o=r(Vgt,"RobertaForMaskedLM"),Vgt.forEach(t),j6o=r(Exe," (RoBERTa model)"),Exe.forEach(t),D6o=i(O),l2=n(O,"LI",{});var Cxe=s(l2);Ame=n(Cxe,"STRONG",{});var Xgt=s(Ame);G6o=r(Xgt,"splinter"),Xgt.forEach(t),O6o=r(Cxe," \u2014 "),ID=n(Cxe,"A",{href:!0});var zgt=s(ID);V6o=r(zgt,"SplinterForPreTraining"),zgt.forEach(t),X6o=r(Cxe," (Splinter model)"),Cxe.forEach(t),z6o=i(O),i2=n(O,"LI",{});var wxe=s(i2);Lme=n(wxe,"STRONG",{});var Qgt=s(Lme);Q6o=r(Qgt,"squeezebert"),Qgt.forEach(t),W6o=r(wxe," \u2014 "),ND=n(wxe,"A",{href:!0});var Wgt=s(ND);H6o=r(Wgt,"SqueezeBertForMaskedLM"),Wgt.forEach(t),U6o=r(wxe," (SqueezeBERT model)"),wxe.forEach(t),J6o=i(O),d2=n(O,"LI",{});var Axe=s(d2);yme=n(Axe,"STRONG",{});var Hgt=s(yme);Y6o=r(Hgt,"t5"),Hgt.forEach(t),K6o=r(Axe," \u2014 "),qD=n(Axe,"A",{href:!0});var Ugt=s(qD);Z6o=r(Ugt,"T5ForConditionalGeneration"),Ugt.forEach(t),eLo=r(Axe," (T5 model)"),Axe.forEach(t),oLo=i(O),c2=n(O,"LI",{});var Lxe=s(c2);xme=n(Lxe,"STRONG",{});var Jgt=s(xme);rLo=r(Jgt,"tapas"),Jgt.forEach(t),tLo=r(Lxe," \u2014 "),jD=n(Lxe,"A",{href:!0});var Ygt=s(jD);aLo=r(Ygt,"TapasForMaskedLM"),Ygt.forEach(t),nLo=r(Lxe," (TAPAS model)"),Lxe.forEach(t),sLo=i(O),m2=n(O,"LI",{});var yxe=s(m2);$me=n(yxe,"STRONG",{});var Kgt=s($me);lLo=r(Kgt,"transfo-xl"),Kgt.forEach(t),iLo=r(yxe," \u2014 "),DD=n(yxe,"A",{href:!0});var Zgt=s(DD);dLo=r(Zgt,"TransfoXLLMHeadModel"),Zgt.forEach(t),cLo=r(yxe," (Transformer-XL model)"),yxe.forEach(t),mLo=i(O),f2=n(O,"LI",{});var xxe=s(f2);kme=n(xxe,"STRONG",{});var eht=s(kme);fLo=r(eht,"unispeech"),eht.forEach(t),gLo=r(xxe," \u2014 "),GD=n(xxe,"A",{href:!0});var oht=s(GD);hLo=r(oht,"UniSpeechForPreTraining"),oht.forEach(t),uLo=r(xxe," (UniSpeech model)"),xxe.forEach(t),pLo=i(O),g2=n(O,"LI",{});var $xe=s(g2);Sme=n($xe,"STRONG",{});var rht=s(Sme);_Lo=r(rht,"unispeech-sat"),rht.forEach(t),bLo=r($xe," \u2014 "),OD=n($xe,"A",{href:!0});var tht=s(OD);vLo=r(tht,"UniSpeechSatForPreTraining"),tht.forEach(t),FLo=r($xe," (UniSpeechSat model)"),$xe.forEach(t),TLo=i(O),h2=n(O,"LI",{});var kxe=s(h2);Rme=n(kxe,"STRONG",{});var aht=s(Rme);MLo=r(aht,"visual_bert"),aht.forEach(t),ELo=r(kxe," \u2014 "),VD=n(kxe,"A",{href:!0});var nht=s(VD);CLo=r(nht,"VisualBertForPreTraining"),nht.forEach(t),wLo=r(kxe," (VisualBERT model)"),kxe.forEach(t),ALo=i(O),u2=n(O,"LI",{});var Sxe=s(u2);Pme=n(Sxe,"STRONG",{});var sht=s(Pme);LLo=r(sht,"vit_mae"),sht.forEach(t),yLo=r(Sxe," \u2014 "),XD=n(Sxe,"A",{href:!0});var lht=s(XD);xLo=r(lht,"ViTMAEForPreTraining"),lht.forEach(t),$Lo=r(Sxe," (ViTMAE model)"),Sxe.forEach(t),kLo=i(O),p2=n(O,"LI",{});var Rxe=s(p2);Bme=n(Rxe,"STRONG",{});var iht=s(Bme);SLo=r(iht,"wav2vec2"),iht.forEach(t),RLo=r(Rxe," \u2014 "),zD=n(Rxe,"A",{href:!0});var dht=s(zD);PLo=r(dht,"Wav2Vec2ForPreTraining"),dht.forEach(t),BLo=r(Rxe," (Wav2Vec2 model)"),Rxe.forEach(t),ILo=i(O),_2=n(O,"LI",{});var Pxe=s(_2);Ime=n(Pxe,"STRONG",{});var cht=s(Ime);NLo=r(cht,"wav2vec2-conformer"),cht.forEach(t),qLo=r(Pxe," \u2014 "),QD=n(Pxe,"A",{href:!0});var mht=s(QD);jLo=r(mht,"Wav2Vec2ConformerForPreTraining"),mht.forEach(t),DLo=r(Pxe," (Wav2Vec2-Conformer model)"),Pxe.forEach(t),GLo=i(O),b2=n(O,"LI",{});var Bxe=s(b2);Nme=n(Bxe,"STRONG",{});var fht=s(Nme);OLo=r(fht,"xlm"),fht.forEach(t),VLo=r(Bxe," \u2014 "),WD=n(Bxe,"A",{href:!0});var ght=s(WD);XLo=r(ght,"XLMWithLMHeadModel"),ght.forEach(t),zLo=r(Bxe," (XLM model)"),Bxe.forEach(t),QLo=i(O),v2=n(O,"LI",{});var Ixe=s(v2);qme=n(Ixe,"STRONG",{});var hht=s(qme);WLo=r(hht,"xlm-roberta"),hht.forEach(t),HLo=r(Ixe," \u2014 "),HD=n(Ixe,"A",{href:!0});var uht=s(HD);ULo=r(uht,"XLMRobertaForMaskedLM"),uht.forEach(t),JLo=r(Ixe," (XLM-RoBERTa model)"),Ixe.forEach(t),YLo=i(O),F2=n(O,"LI",{});var Nxe=s(F2);jme=n(Nxe,"STRONG",{});var pht=s(jme);KLo=r(pht,"xlm-roberta-xl"),pht.forEach(t),ZLo=r(Nxe," \u2014 "),UD=n(Nxe,"A",{href:!0});var _ht=s(UD);eyo=r(_ht,"XLMRobertaXLForMaskedLM"),_ht.forEach(t),oyo=r(Nxe," (XLM-RoBERTa-XL model)"),Nxe.forEach(t),ryo=i(O),T2=n(O,"LI",{});var qxe=s(T2);Dme=n(qxe,"STRONG",{});var bht=s(Dme);tyo=r(bht,"xlnet"),bht.forEach(t),ayo=r(qxe," \u2014 "),JD=n(qxe,"A",{href:!0});var vht=s(JD);nyo=r(vht,"XLNetLMHeadModel"),vht.forEach(t),syo=r(qxe," (XLNet model)"),qxe.forEach(t),O.forEach(t),lyo=i(na),M2=n(na,"P",{});var jxe=s(M2);iyo=r(jxe,"The model is set in evaluation mode by default using "),Gme=n(jxe,"CODE",{});var Fht=s(Gme);dyo=r(Fht,"model.eval()"),Fht.forEach(t),cyo=r(jxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ome=n(jxe,"CODE",{});var Tht=s(Ome);myo=r(Tht,"model.train()"),Tht.forEach(t),jxe.forEach(t),fyo=i(na),T(E2.$$.fragment,na),na.forEach(t),Ks.forEach(t),rOe=i(m),Gi=n(m,"H2",{class:!0});var iXe=s(Gi);C2=n(iXe,"A",{id:!0,class:!0,href:!0});var Mht=s(C2);Vme=n(Mht,"SPAN",{});var Eht=s(Vme);T(m7.$$.fragment,Eht),Eht.forEach(t),Mht.forEach(t),gyo=i(iXe),Xme=n(iXe,"SPAN",{});var Cht=s(Xme);hyo=r(Cht,"AutoModelForCausalLM"),Cht.forEach(t),iXe.forEach(t),tOe=i(m),ko=n(m,"DIV",{class:!0});var Zs=s(ko);T(f7.$$.fragment,Zs),uyo=i(Zs),Oi=n(Zs,"P",{});var Eoe=s(Oi);pyo=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=n(Eoe,"A",{href:!0});var wht=s(YD);_yo=r(wht,"from_pretrained()"),wht.forEach(t),byo=r(Eoe," class method or the "),KD=n(Eoe,"A",{href:!0});var Aht=s(KD);vyo=r(Aht,"from_config()"),Aht.forEach(t),Fyo=r(Eoe,` class
method.`),Eoe.forEach(t),Tyo=i(Zs),g7=n(Zs,"P",{});var dXe=s(g7);Myo=r(dXe,"This class cannot be instantiated directly using "),zme=n(dXe,"CODE",{});var Lht=s(zme);Eyo=r(Lht,"__init__()"),Lht.forEach(t),Cyo=r(dXe," (throws an error)."),dXe.forEach(t),wyo=i(Zs),lt=n(Zs,"DIV",{class:!0});var B6=s(lt);T(h7.$$.fragment,B6),Ayo=i(B6),Qme=n(B6,"P",{});var yht=s(Qme);Lyo=r(yht,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yht.forEach(t),yyo=i(B6),Vi=n(B6,"P",{});var Coe=s(Vi);xyo=r(Coe,`Note:
Loading a model from its configuration file does `),Wme=n(Coe,"STRONG",{});var xht=s(Wme);$yo=r(xht,"not"),xht.forEach(t),kyo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(Coe,"A",{href:!0});var $ht=s(ZD);Syo=r($ht,"from_pretrained()"),$ht.forEach(t),Ryo=r(Coe," to load the model weights."),Coe.forEach(t),Pyo=i(B6),T(w2.$$.fragment,B6),B6.forEach(t),Byo=i(Zs),Ke=n(Zs,"DIV",{class:!0});var sa=s(Ke);T(u7.$$.fragment,sa),Iyo=i(sa),Hme=n(sa,"P",{});var kht=s(Hme);Nyo=r(kht,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kht.forEach(t),qyo=i(sa),Ba=n(sa,"P",{});var I6=s(Ba);jyo=r(I6,"The model class to instantiate is selected based on the "),Ume=n(I6,"CODE",{});var Sht=s(Ume);Dyo=r(Sht,"model_type"),Sht.forEach(t),Gyo=r(I6,` property of the config object (either
passed as an argument or loaded from `),Jme=n(I6,"CODE",{});var Rht=s(Jme);Oyo=r(Rht,"pretrained_model_name_or_path"),Rht.forEach(t),Vyo=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yme=n(I6,"CODE",{});var Pht=s(Yme);Xyo=r(Pht,"pretrained_model_name_or_path"),Pht.forEach(t),zyo=r(I6,":"),I6.forEach(t),Qyo=i(sa),z=n(sa,"UL",{});var W=s(z);A2=n(W,"LI",{});var Dxe=s(A2);Kme=n(Dxe,"STRONG",{});var Bht=s(Kme);Wyo=r(Bht,"bart"),Bht.forEach(t),Hyo=r(Dxe," \u2014 "),eG=n(Dxe,"A",{href:!0});var Iht=s(eG);Uyo=r(Iht,"BartForCausalLM"),Iht.forEach(t),Jyo=r(Dxe," (BART model)"),Dxe.forEach(t),Yyo=i(W),L2=n(W,"LI",{});var Gxe=s(L2);Zme=n(Gxe,"STRONG",{});var Nht=s(Zme);Kyo=r(Nht,"bert"),Nht.forEach(t),Zyo=r(Gxe," \u2014 "),oG=n(Gxe,"A",{href:!0});var qht=s(oG);e7o=r(qht,"BertLMHeadModel"),qht.forEach(t),o7o=r(Gxe," (BERT model)"),Gxe.forEach(t),r7o=i(W),y2=n(W,"LI",{});var Oxe=s(y2);efe=n(Oxe,"STRONG",{});var jht=s(efe);t7o=r(jht,"bert-generation"),jht.forEach(t),a7o=r(Oxe," \u2014 "),rG=n(Oxe,"A",{href:!0});var Dht=s(rG);n7o=r(Dht,"BertGenerationDecoder"),Dht.forEach(t),s7o=r(Oxe," (Bert Generation model)"),Oxe.forEach(t),l7o=i(W),x2=n(W,"LI",{});var Vxe=s(x2);ofe=n(Vxe,"STRONG",{});var Ght=s(ofe);i7o=r(Ght,"big_bird"),Ght.forEach(t),d7o=r(Vxe," \u2014 "),tG=n(Vxe,"A",{href:!0});var Oht=s(tG);c7o=r(Oht,"BigBirdForCausalLM"),Oht.forEach(t),m7o=r(Vxe," (BigBird model)"),Vxe.forEach(t),f7o=i(W),$2=n(W,"LI",{});var Xxe=s($2);rfe=n(Xxe,"STRONG",{});var Vht=s(rfe);g7o=r(Vht,"bigbird_pegasus"),Vht.forEach(t),h7o=r(Xxe," \u2014 "),aG=n(Xxe,"A",{href:!0});var Xht=s(aG);u7o=r(Xht,"BigBirdPegasusForCausalLM"),Xht.forEach(t),p7o=r(Xxe," (BigBird-Pegasus model)"),Xxe.forEach(t),_7o=i(W),k2=n(W,"LI",{});var zxe=s(k2);tfe=n(zxe,"STRONG",{});var zht=s(tfe);b7o=r(zht,"blenderbot"),zht.forEach(t),v7o=r(zxe," \u2014 "),nG=n(zxe,"A",{href:!0});var Qht=s(nG);F7o=r(Qht,"BlenderbotForCausalLM"),Qht.forEach(t),T7o=r(zxe," (Blenderbot model)"),zxe.forEach(t),M7o=i(W),S2=n(W,"LI",{});var Qxe=s(S2);afe=n(Qxe,"STRONG",{});var Wht=s(afe);E7o=r(Wht,"blenderbot-small"),Wht.forEach(t),C7o=r(Qxe," \u2014 "),sG=n(Qxe,"A",{href:!0});var Hht=s(sG);w7o=r(Hht,"BlenderbotSmallForCausalLM"),Hht.forEach(t),A7o=r(Qxe," (BlenderbotSmall model)"),Qxe.forEach(t),L7o=i(W),R2=n(W,"LI",{});var Wxe=s(R2);nfe=n(Wxe,"STRONG",{});var Uht=s(nfe);y7o=r(Uht,"bloom"),Uht.forEach(t),x7o=r(Wxe," \u2014 "),lG=n(Wxe,"A",{href:!0});var Jht=s(lG);$7o=r(Jht,"BloomForCausalLM"),Jht.forEach(t),k7o=r(Wxe," (BLOOM model)"),Wxe.forEach(t),S7o=i(W),P2=n(W,"LI",{});var Hxe=s(P2);sfe=n(Hxe,"STRONG",{});var Yht=s(sfe);R7o=r(Yht,"camembert"),Yht.forEach(t),P7o=r(Hxe," \u2014 "),iG=n(Hxe,"A",{href:!0});var Kht=s(iG);B7o=r(Kht,"CamembertForCausalLM"),Kht.forEach(t),I7o=r(Hxe," (CamemBERT model)"),Hxe.forEach(t),N7o=i(W),B2=n(W,"LI",{});var Uxe=s(B2);lfe=n(Uxe,"STRONG",{});var Zht=s(lfe);q7o=r(Zht,"ctrl"),Zht.forEach(t),j7o=r(Uxe," \u2014 "),dG=n(Uxe,"A",{href:!0});var eut=s(dG);D7o=r(eut,"CTRLLMHeadModel"),eut.forEach(t),G7o=r(Uxe," (CTRL model)"),Uxe.forEach(t),O7o=i(W),I2=n(W,"LI",{});var Jxe=s(I2);ife=n(Jxe,"STRONG",{});var out=s(ife);V7o=r(out,"data2vec-text"),out.forEach(t),X7o=r(Jxe," \u2014 "),cG=n(Jxe,"A",{href:!0});var rut=s(cG);z7o=r(rut,"Data2VecTextForCausalLM"),rut.forEach(t),Q7o=r(Jxe," (Data2VecText model)"),Jxe.forEach(t),W7o=i(W),N2=n(W,"LI",{});var Yxe=s(N2);dfe=n(Yxe,"STRONG",{});var tut=s(dfe);H7o=r(tut,"electra"),tut.forEach(t),U7o=r(Yxe," \u2014 "),mG=n(Yxe,"A",{href:!0});var aut=s(mG);J7o=r(aut,"ElectraForCausalLM"),aut.forEach(t),Y7o=r(Yxe," (ELECTRA model)"),Yxe.forEach(t),K7o=i(W),q2=n(W,"LI",{});var Kxe=s(q2);cfe=n(Kxe,"STRONG",{});var nut=s(cfe);Z7o=r(nut,"gpt2"),nut.forEach(t),e8o=r(Kxe," \u2014 "),fG=n(Kxe,"A",{href:!0});var sut=s(fG);o8o=r(sut,"GPT2LMHeadModel"),sut.forEach(t),r8o=r(Kxe," (OpenAI GPT-2 model)"),Kxe.forEach(t),t8o=i(W),j2=n(W,"LI",{});var Zxe=s(j2);mfe=n(Zxe,"STRONG",{});var lut=s(mfe);a8o=r(lut,"gpt_neo"),lut.forEach(t),n8o=r(Zxe," \u2014 "),gG=n(Zxe,"A",{href:!0});var iut=s(gG);s8o=r(iut,"GPTNeoForCausalLM"),iut.forEach(t),l8o=r(Zxe," (GPT Neo model)"),Zxe.forEach(t),i8o=i(W),D2=n(W,"LI",{});var e$e=s(D2);ffe=n(e$e,"STRONG",{});var dut=s(ffe);d8o=r(dut,"gpt_neox"),dut.forEach(t),c8o=r(e$e," \u2014 "),hG=n(e$e,"A",{href:!0});var cut=s(hG);m8o=r(cut,"GPTNeoXForCausalLM"),cut.forEach(t),f8o=r(e$e," (GPT NeoX model)"),e$e.forEach(t),g8o=i(W),G2=n(W,"LI",{});var o$e=s(G2);gfe=n(o$e,"STRONG",{});var mut=s(gfe);h8o=r(mut,"gptj"),mut.forEach(t),u8o=r(o$e," \u2014 "),uG=n(o$e,"A",{href:!0});var fut=s(uG);p8o=r(fut,"GPTJForCausalLM"),fut.forEach(t),_8o=r(o$e," (GPT-J model)"),o$e.forEach(t),b8o=i(W),O2=n(W,"LI",{});var r$e=s(O2);hfe=n(r$e,"STRONG",{});var gut=s(hfe);v8o=r(gut,"marian"),gut.forEach(t),F8o=r(r$e," \u2014 "),pG=n(r$e,"A",{href:!0});var hut=s(pG);T8o=r(hut,"MarianForCausalLM"),hut.forEach(t),M8o=r(r$e," (Marian model)"),r$e.forEach(t),E8o=i(W),V2=n(W,"LI",{});var t$e=s(V2);ufe=n(t$e,"STRONG",{});var uut=s(ufe);C8o=r(uut,"mbart"),uut.forEach(t),w8o=r(t$e," \u2014 "),_G=n(t$e,"A",{href:!0});var put=s(_G);A8o=r(put,"MBartForCausalLM"),put.forEach(t),L8o=r(t$e," (mBART model)"),t$e.forEach(t),y8o=i(W),X2=n(W,"LI",{});var a$e=s(X2);pfe=n(a$e,"STRONG",{});var _ut=s(pfe);x8o=r(_ut,"megatron-bert"),_ut.forEach(t),$8o=r(a$e," \u2014 "),bG=n(a$e,"A",{href:!0});var but=s(bG);k8o=r(but,"MegatronBertForCausalLM"),but.forEach(t),S8o=r(a$e," (Megatron-BERT model)"),a$e.forEach(t),R8o=i(W),z2=n(W,"LI",{});var n$e=s(z2);_fe=n(n$e,"STRONG",{});var vut=s(_fe);P8o=r(vut,"openai-gpt"),vut.forEach(t),B8o=r(n$e," \u2014 "),vG=n(n$e,"A",{href:!0});var Fut=s(vG);I8o=r(Fut,"OpenAIGPTLMHeadModel"),Fut.forEach(t),N8o=r(n$e," (OpenAI GPT model)"),n$e.forEach(t),q8o=i(W),Q2=n(W,"LI",{});var s$e=s(Q2);bfe=n(s$e,"STRONG",{});var Tut=s(bfe);j8o=r(Tut,"opt"),Tut.forEach(t),D8o=r(s$e," \u2014 "),FG=n(s$e,"A",{href:!0});var Mut=s(FG);G8o=r(Mut,"OPTForCausalLM"),Mut.forEach(t),O8o=r(s$e," (OPT model)"),s$e.forEach(t),V8o=i(W),W2=n(W,"LI",{});var l$e=s(W2);vfe=n(l$e,"STRONG",{});var Eut=s(vfe);X8o=r(Eut,"pegasus"),Eut.forEach(t),z8o=r(l$e," \u2014 "),TG=n(l$e,"A",{href:!0});var Cut=s(TG);Q8o=r(Cut,"PegasusForCausalLM"),Cut.forEach(t),W8o=r(l$e," (Pegasus model)"),l$e.forEach(t),H8o=i(W),H2=n(W,"LI",{});var i$e=s(H2);Ffe=n(i$e,"STRONG",{});var wut=s(Ffe);U8o=r(wut,"plbart"),wut.forEach(t),J8o=r(i$e," \u2014 "),MG=n(i$e,"A",{href:!0});var Aut=s(MG);Y8o=r(Aut,"PLBartForCausalLM"),Aut.forEach(t),K8o=r(i$e," (PLBart model)"),i$e.forEach(t),Z8o=i(W),U2=n(W,"LI",{});var d$e=s(U2);Tfe=n(d$e,"STRONG",{});var Lut=s(Tfe);e9o=r(Lut,"prophetnet"),Lut.forEach(t),o9o=r(d$e," \u2014 "),EG=n(d$e,"A",{href:!0});var yut=s(EG);r9o=r(yut,"ProphetNetForCausalLM"),yut.forEach(t),t9o=r(d$e," (ProphetNet model)"),d$e.forEach(t),a9o=i(W),J2=n(W,"LI",{});var c$e=s(J2);Mfe=n(c$e,"STRONG",{});var xut=s(Mfe);n9o=r(xut,"qdqbert"),xut.forEach(t),s9o=r(c$e," \u2014 "),CG=n(c$e,"A",{href:!0});var $ut=s(CG);l9o=r($ut,"QDQBertLMHeadModel"),$ut.forEach(t),i9o=r(c$e," (QDQBert model)"),c$e.forEach(t),d9o=i(W),Y2=n(W,"LI",{});var m$e=s(Y2);Efe=n(m$e,"STRONG",{});var kut=s(Efe);c9o=r(kut,"reformer"),kut.forEach(t),m9o=r(m$e," \u2014 "),wG=n(m$e,"A",{href:!0});var Sut=s(wG);f9o=r(Sut,"ReformerModelWithLMHead"),Sut.forEach(t),g9o=r(m$e," (Reformer model)"),m$e.forEach(t),h9o=i(W),K2=n(W,"LI",{});var f$e=s(K2);Cfe=n(f$e,"STRONG",{});var Rut=s(Cfe);u9o=r(Rut,"rembert"),Rut.forEach(t),p9o=r(f$e," \u2014 "),AG=n(f$e,"A",{href:!0});var Put=s(AG);_9o=r(Put,"RemBertForCausalLM"),Put.forEach(t),b9o=r(f$e," (RemBERT model)"),f$e.forEach(t),v9o=i(W),Z2=n(W,"LI",{});var g$e=s(Z2);wfe=n(g$e,"STRONG",{});var But=s(wfe);F9o=r(But,"roberta"),But.forEach(t),T9o=r(g$e," \u2014 "),LG=n(g$e,"A",{href:!0});var Iut=s(LG);M9o=r(Iut,"RobertaForCausalLM"),Iut.forEach(t),E9o=r(g$e," (RoBERTa model)"),g$e.forEach(t),C9o=i(W),eb=n(W,"LI",{});var h$e=s(eb);Afe=n(h$e,"STRONG",{});var Nut=s(Afe);w9o=r(Nut,"roformer"),Nut.forEach(t),A9o=r(h$e," \u2014 "),yG=n(h$e,"A",{href:!0});var qut=s(yG);L9o=r(qut,"RoFormerForCausalLM"),qut.forEach(t),y9o=r(h$e," (RoFormer model)"),h$e.forEach(t),x9o=i(W),ob=n(W,"LI",{});var u$e=s(ob);Lfe=n(u$e,"STRONG",{});var jut=s(Lfe);$9o=r(jut,"speech_to_text_2"),jut.forEach(t),k9o=r(u$e," \u2014 "),xG=n(u$e,"A",{href:!0});var Dut=s(xG);S9o=r(Dut,"Speech2Text2ForCausalLM"),Dut.forEach(t),R9o=r(u$e," (Speech2Text2 model)"),u$e.forEach(t),P9o=i(W),rb=n(W,"LI",{});var p$e=s(rb);yfe=n(p$e,"STRONG",{});var Gut=s(yfe);B9o=r(Gut,"transfo-xl"),Gut.forEach(t),I9o=r(p$e," \u2014 "),$G=n(p$e,"A",{href:!0});var Out=s($G);N9o=r(Out,"TransfoXLLMHeadModel"),Out.forEach(t),q9o=r(p$e," (Transformer-XL model)"),p$e.forEach(t),j9o=i(W),tb=n(W,"LI",{});var _$e=s(tb);xfe=n(_$e,"STRONG",{});var Vut=s(xfe);D9o=r(Vut,"trocr"),Vut.forEach(t),G9o=r(_$e," \u2014 "),kG=n(_$e,"A",{href:!0});var Xut=s(kG);O9o=r(Xut,"TrOCRForCausalLM"),Xut.forEach(t),V9o=r(_$e," (TrOCR model)"),_$e.forEach(t),X9o=i(W),ab=n(W,"LI",{});var b$e=s(ab);$fe=n(b$e,"STRONG",{});var zut=s($fe);z9o=r(zut,"xglm"),zut.forEach(t),Q9o=r(b$e," \u2014 "),SG=n(b$e,"A",{href:!0});var Qut=s(SG);W9o=r(Qut,"XGLMForCausalLM"),Qut.forEach(t),H9o=r(b$e," (XGLM model)"),b$e.forEach(t),U9o=i(W),nb=n(W,"LI",{});var v$e=s(nb);kfe=n(v$e,"STRONG",{});var Wut=s(kfe);J9o=r(Wut,"xlm"),Wut.forEach(t),Y9o=r(v$e," \u2014 "),RG=n(v$e,"A",{href:!0});var Hut=s(RG);K9o=r(Hut,"XLMWithLMHeadModel"),Hut.forEach(t),Z9o=r(v$e," (XLM model)"),v$e.forEach(t),exo=i(W),sb=n(W,"LI",{});var F$e=s(sb);Sfe=n(F$e,"STRONG",{});var Uut=s(Sfe);oxo=r(Uut,"xlm-prophetnet"),Uut.forEach(t),rxo=r(F$e," \u2014 "),PG=n(F$e,"A",{href:!0});var Jut=s(PG);txo=r(Jut,"XLMProphetNetForCausalLM"),Jut.forEach(t),axo=r(F$e," (XLM-ProphetNet model)"),F$e.forEach(t),nxo=i(W),lb=n(W,"LI",{});var T$e=s(lb);Rfe=n(T$e,"STRONG",{});var Yut=s(Rfe);sxo=r(Yut,"xlm-roberta"),Yut.forEach(t),lxo=r(T$e," \u2014 "),BG=n(T$e,"A",{href:!0});var Kut=s(BG);ixo=r(Kut,"XLMRobertaForCausalLM"),Kut.forEach(t),dxo=r(T$e," (XLM-RoBERTa model)"),T$e.forEach(t),cxo=i(W),ib=n(W,"LI",{});var M$e=s(ib);Pfe=n(M$e,"STRONG",{});var Zut=s(Pfe);mxo=r(Zut,"xlm-roberta-xl"),Zut.forEach(t),fxo=r(M$e," \u2014 "),IG=n(M$e,"A",{href:!0});var ept=s(IG);gxo=r(ept,"XLMRobertaXLForCausalLM"),ept.forEach(t),hxo=r(M$e," (XLM-RoBERTa-XL model)"),M$e.forEach(t),uxo=i(W),db=n(W,"LI",{});var E$e=s(db);Bfe=n(E$e,"STRONG",{});var opt=s(Bfe);pxo=r(opt,"xlnet"),opt.forEach(t),_xo=r(E$e," \u2014 "),NG=n(E$e,"A",{href:!0});var rpt=s(NG);bxo=r(rpt,"XLNetLMHeadModel"),rpt.forEach(t),vxo=r(E$e," (XLNet model)"),E$e.forEach(t),W.forEach(t),Fxo=i(sa),cb=n(sa,"P",{});var C$e=s(cb);Txo=r(C$e,"The model is set in evaluation mode by default using "),Ife=n(C$e,"CODE",{});var tpt=s(Ife);Mxo=r(tpt,"model.eval()"),tpt.forEach(t),Exo=r(C$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nfe=n(C$e,"CODE",{});var apt=s(Nfe);Cxo=r(apt,"model.train()"),apt.forEach(t),C$e.forEach(t),wxo=i(sa),T(mb.$$.fragment,sa),sa.forEach(t),Zs.forEach(t),aOe=i(m),Xi=n(m,"H2",{class:!0});var cXe=s(Xi);fb=n(cXe,"A",{id:!0,class:!0,href:!0});var npt=s(fb);qfe=n(npt,"SPAN",{});var spt=s(qfe);T(p7.$$.fragment,spt),spt.forEach(t),npt.forEach(t),Axo=i(cXe),jfe=n(cXe,"SPAN",{});var lpt=s(jfe);Lxo=r(lpt,"AutoModelForMaskedLM"),lpt.forEach(t),cXe.forEach(t),nOe=i(m),So=n(m,"DIV",{class:!0});var el=s(So);T(_7.$$.fragment,el),yxo=i(el),zi=n(el,"P",{});var woe=s(zi);xxo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=n(woe,"A",{href:!0});var ipt=s(qG);$xo=r(ipt,"from_pretrained()"),ipt.forEach(t),kxo=r(woe," class method or the "),jG=n(woe,"A",{href:!0});var dpt=s(jG);Sxo=r(dpt,"from_config()"),dpt.forEach(t),Rxo=r(woe,` class
method.`),woe.forEach(t),Pxo=i(el),b7=n(el,"P",{});var mXe=s(b7);Bxo=r(mXe,"This class cannot be instantiated directly using "),Dfe=n(mXe,"CODE",{});var cpt=s(Dfe);Ixo=r(cpt,"__init__()"),cpt.forEach(t),Nxo=r(mXe," (throws an error)."),mXe.forEach(t),qxo=i(el),it=n(el,"DIV",{class:!0});var N6=s(it);T(v7.$$.fragment,N6),jxo=i(N6),Gfe=n(N6,"P",{});var mpt=s(Gfe);Dxo=r(mpt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mpt.forEach(t),Gxo=i(N6),Qi=n(N6,"P",{});var Aoe=s(Qi);Oxo=r(Aoe,`Note:
Loading a model from its configuration file does `),Ofe=n(Aoe,"STRONG",{});var fpt=s(Ofe);Vxo=r(fpt,"not"),fpt.forEach(t),Xxo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=n(Aoe,"A",{href:!0});var gpt=s(DG);zxo=r(gpt,"from_pretrained()"),gpt.forEach(t),Qxo=r(Aoe," to load the model weights."),Aoe.forEach(t),Wxo=i(N6),T(gb.$$.fragment,N6),N6.forEach(t),Hxo=i(el),Ze=n(el,"DIV",{class:!0});var la=s(Ze);T(F7.$$.fragment,la),Uxo=i(la),Vfe=n(la,"P",{});var hpt=s(Vfe);Jxo=r(hpt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hpt.forEach(t),Yxo=i(la),Ia=n(la,"P",{});var q6=s(Ia);Kxo=r(q6,"The model class to instantiate is selected based on the "),Xfe=n(q6,"CODE",{});var upt=s(Xfe);Zxo=r(upt,"model_type"),upt.forEach(t),e$o=r(q6,` property of the config object (either
passed as an argument or loaded from `),zfe=n(q6,"CODE",{});var ppt=s(zfe);o$o=r(ppt,"pretrained_model_name_or_path"),ppt.forEach(t),r$o=r(q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qfe=n(q6,"CODE",{});var _pt=s(Qfe);t$o=r(_pt,"pretrained_model_name_or_path"),_pt.forEach(t),a$o=r(q6,":"),q6.forEach(t),n$o=i(la),Q=n(la,"UL",{});var U=s(Q);hb=n(U,"LI",{});var w$e=s(hb);Wfe=n(w$e,"STRONG",{});var bpt=s(Wfe);s$o=r(bpt,"albert"),bpt.forEach(t),l$o=r(w$e," \u2014 "),GG=n(w$e,"A",{href:!0});var vpt=s(GG);i$o=r(vpt,"AlbertForMaskedLM"),vpt.forEach(t),d$o=r(w$e," (ALBERT model)"),w$e.forEach(t),c$o=i(U),ub=n(U,"LI",{});var A$e=s(ub);Hfe=n(A$e,"STRONG",{});var Fpt=s(Hfe);m$o=r(Fpt,"bart"),Fpt.forEach(t),f$o=r(A$e," \u2014 "),OG=n(A$e,"A",{href:!0});var Tpt=s(OG);g$o=r(Tpt,"BartForConditionalGeneration"),Tpt.forEach(t),h$o=r(A$e," (BART model)"),A$e.forEach(t),u$o=i(U),pb=n(U,"LI",{});var L$e=s(pb);Ufe=n(L$e,"STRONG",{});var Mpt=s(Ufe);p$o=r(Mpt,"bert"),Mpt.forEach(t),_$o=r(L$e," \u2014 "),VG=n(L$e,"A",{href:!0});var Ept=s(VG);b$o=r(Ept,"BertForMaskedLM"),Ept.forEach(t),v$o=r(L$e," (BERT model)"),L$e.forEach(t),F$o=i(U),_b=n(U,"LI",{});var y$e=s(_b);Jfe=n(y$e,"STRONG",{});var Cpt=s(Jfe);T$o=r(Cpt,"big_bird"),Cpt.forEach(t),M$o=r(y$e," \u2014 "),XG=n(y$e,"A",{href:!0});var wpt=s(XG);E$o=r(wpt,"BigBirdForMaskedLM"),wpt.forEach(t),C$o=r(y$e," (BigBird model)"),y$e.forEach(t),w$o=i(U),bb=n(U,"LI",{});var x$e=s(bb);Yfe=n(x$e,"STRONG",{});var Apt=s(Yfe);A$o=r(Apt,"camembert"),Apt.forEach(t),L$o=r(x$e," \u2014 "),zG=n(x$e,"A",{href:!0});var Lpt=s(zG);y$o=r(Lpt,"CamembertForMaskedLM"),Lpt.forEach(t),x$o=r(x$e," (CamemBERT model)"),x$e.forEach(t),$$o=i(U),vb=n(U,"LI",{});var $$e=s(vb);Kfe=n($$e,"STRONG",{});var ypt=s(Kfe);k$o=r(ypt,"convbert"),ypt.forEach(t),S$o=r($$e," \u2014 "),QG=n($$e,"A",{href:!0});var xpt=s(QG);R$o=r(xpt,"ConvBertForMaskedLM"),xpt.forEach(t),P$o=r($$e," (ConvBERT model)"),$$e.forEach(t),B$o=i(U),Fb=n(U,"LI",{});var k$e=s(Fb);Zfe=n(k$e,"STRONG",{});var $pt=s(Zfe);I$o=r($pt,"data2vec-text"),$pt.forEach(t),N$o=r(k$e," \u2014 "),WG=n(k$e,"A",{href:!0});var kpt=s(WG);q$o=r(kpt,"Data2VecTextForMaskedLM"),kpt.forEach(t),j$o=r(k$e," (Data2VecText model)"),k$e.forEach(t),D$o=i(U),Tb=n(U,"LI",{});var S$e=s(Tb);ege=n(S$e,"STRONG",{});var Spt=s(ege);G$o=r(Spt,"deberta"),Spt.forEach(t),O$o=r(S$e," \u2014 "),HG=n(S$e,"A",{href:!0});var Rpt=s(HG);V$o=r(Rpt,"DebertaForMaskedLM"),Rpt.forEach(t),X$o=r(S$e," (DeBERTa model)"),S$e.forEach(t),z$o=i(U),Mb=n(U,"LI",{});var R$e=s(Mb);oge=n(R$e,"STRONG",{});var Ppt=s(oge);Q$o=r(Ppt,"deberta-v2"),Ppt.forEach(t),W$o=r(R$e," \u2014 "),UG=n(R$e,"A",{href:!0});var Bpt=s(UG);H$o=r(Bpt,"DebertaV2ForMaskedLM"),Bpt.forEach(t),U$o=r(R$e," (DeBERTa-v2 model)"),R$e.forEach(t),J$o=i(U),Eb=n(U,"LI",{});var P$e=s(Eb);rge=n(P$e,"STRONG",{});var Ipt=s(rge);Y$o=r(Ipt,"distilbert"),Ipt.forEach(t),K$o=r(P$e," \u2014 "),JG=n(P$e,"A",{href:!0});var Npt=s(JG);Z$o=r(Npt,"DistilBertForMaskedLM"),Npt.forEach(t),eko=r(P$e," (DistilBERT model)"),P$e.forEach(t),oko=i(U),Cb=n(U,"LI",{});var B$e=s(Cb);tge=n(B$e,"STRONG",{});var qpt=s(tge);rko=r(qpt,"electra"),qpt.forEach(t),tko=r(B$e," \u2014 "),YG=n(B$e,"A",{href:!0});var jpt=s(YG);ako=r(jpt,"ElectraForMaskedLM"),jpt.forEach(t),nko=r(B$e," (ELECTRA model)"),B$e.forEach(t),sko=i(U),wb=n(U,"LI",{});var I$e=s(wb);age=n(I$e,"STRONG",{});var Dpt=s(age);lko=r(Dpt,"flaubert"),Dpt.forEach(t),iko=r(I$e," \u2014 "),KG=n(I$e,"A",{href:!0});var Gpt=s(KG);dko=r(Gpt,"FlaubertWithLMHeadModel"),Gpt.forEach(t),cko=r(I$e," (FlauBERT model)"),I$e.forEach(t),mko=i(U),Ab=n(U,"LI",{});var N$e=s(Ab);nge=n(N$e,"STRONG",{});var Opt=s(nge);fko=r(Opt,"fnet"),Opt.forEach(t),gko=r(N$e," \u2014 "),ZG=n(N$e,"A",{href:!0});var Vpt=s(ZG);hko=r(Vpt,"FNetForMaskedLM"),Vpt.forEach(t),uko=r(N$e," (FNet model)"),N$e.forEach(t),pko=i(U),Lb=n(U,"LI",{});var q$e=s(Lb);sge=n(q$e,"STRONG",{});var Xpt=s(sge);_ko=r(Xpt,"funnel"),Xpt.forEach(t),bko=r(q$e," \u2014 "),eO=n(q$e,"A",{href:!0});var zpt=s(eO);vko=r(zpt,"FunnelForMaskedLM"),zpt.forEach(t),Fko=r(q$e," (Funnel Transformer model)"),q$e.forEach(t),Tko=i(U),yb=n(U,"LI",{});var j$e=s(yb);lge=n(j$e,"STRONG",{});var Qpt=s(lge);Mko=r(Qpt,"ibert"),Qpt.forEach(t),Eko=r(j$e," \u2014 "),oO=n(j$e,"A",{href:!0});var Wpt=s(oO);Cko=r(Wpt,"IBertForMaskedLM"),Wpt.forEach(t),wko=r(j$e," (I-BERT model)"),j$e.forEach(t),Ako=i(U),xb=n(U,"LI",{});var D$e=s(xb);ige=n(D$e,"STRONG",{});var Hpt=s(ige);Lko=r(Hpt,"layoutlm"),Hpt.forEach(t),yko=r(D$e," \u2014 "),rO=n(D$e,"A",{href:!0});var Upt=s(rO);xko=r(Upt,"LayoutLMForMaskedLM"),Upt.forEach(t),$ko=r(D$e," (LayoutLM model)"),D$e.forEach(t),kko=i(U),$b=n(U,"LI",{});var G$e=s($b);dge=n(G$e,"STRONG",{});var Jpt=s(dge);Sko=r(Jpt,"longformer"),Jpt.forEach(t),Rko=r(G$e," \u2014 "),tO=n(G$e,"A",{href:!0});var Ypt=s(tO);Pko=r(Ypt,"LongformerForMaskedLM"),Ypt.forEach(t),Bko=r(G$e," (Longformer model)"),G$e.forEach(t),Iko=i(U),kb=n(U,"LI",{});var O$e=s(kb);cge=n(O$e,"STRONG",{});var Kpt=s(cge);Nko=r(Kpt,"luke"),Kpt.forEach(t),qko=r(O$e," \u2014 "),aO=n(O$e,"A",{href:!0});var Zpt=s(aO);jko=r(Zpt,"LukeForMaskedLM"),Zpt.forEach(t),Dko=r(O$e," (LUKE model)"),O$e.forEach(t),Gko=i(U),Sb=n(U,"LI",{});var V$e=s(Sb);mge=n(V$e,"STRONG",{});var e_t=s(mge);Oko=r(e_t,"mbart"),e_t.forEach(t),Vko=r(V$e," \u2014 "),nO=n(V$e,"A",{href:!0});var o_t=s(nO);Xko=r(o_t,"MBartForConditionalGeneration"),o_t.forEach(t),zko=r(V$e," (mBART model)"),V$e.forEach(t),Qko=i(U),Rb=n(U,"LI",{});var X$e=s(Rb);fge=n(X$e,"STRONG",{});var r_t=s(fge);Wko=r(r_t,"megatron-bert"),r_t.forEach(t),Hko=r(X$e," \u2014 "),sO=n(X$e,"A",{href:!0});var t_t=s(sO);Uko=r(t_t,"MegatronBertForMaskedLM"),t_t.forEach(t),Jko=r(X$e," (Megatron-BERT model)"),X$e.forEach(t),Yko=i(U),Pb=n(U,"LI",{});var z$e=s(Pb);gge=n(z$e,"STRONG",{});var a_t=s(gge);Kko=r(a_t,"mobilebert"),a_t.forEach(t),Zko=r(z$e," \u2014 "),lO=n(z$e,"A",{href:!0});var n_t=s(lO);eSo=r(n_t,"MobileBertForMaskedLM"),n_t.forEach(t),oSo=r(z$e," (MobileBERT model)"),z$e.forEach(t),rSo=i(U),Bb=n(U,"LI",{});var Q$e=s(Bb);hge=n(Q$e,"STRONG",{});var s_t=s(hge);tSo=r(s_t,"mpnet"),s_t.forEach(t),aSo=r(Q$e," \u2014 "),iO=n(Q$e,"A",{href:!0});var l_t=s(iO);nSo=r(l_t,"MPNetForMaskedLM"),l_t.forEach(t),sSo=r(Q$e," (MPNet model)"),Q$e.forEach(t),lSo=i(U),Ib=n(U,"LI",{});var W$e=s(Ib);uge=n(W$e,"STRONG",{});var i_t=s(uge);iSo=r(i_t,"nezha"),i_t.forEach(t),dSo=r(W$e," \u2014 "),dO=n(W$e,"A",{href:!0});var d_t=s(dO);cSo=r(d_t,"NezhaForMaskedLM"),d_t.forEach(t),mSo=r(W$e," (Nezha model)"),W$e.forEach(t),fSo=i(U),Nb=n(U,"LI",{});var H$e=s(Nb);pge=n(H$e,"STRONG",{});var c_t=s(pge);gSo=r(c_t,"nystromformer"),c_t.forEach(t),hSo=r(H$e," \u2014 "),cO=n(H$e,"A",{href:!0});var m_t=s(cO);uSo=r(m_t,"NystromformerForMaskedLM"),m_t.forEach(t),pSo=r(H$e," (Nystr\xF6mformer model)"),H$e.forEach(t),_So=i(U),qb=n(U,"LI",{});var U$e=s(qb);_ge=n(U$e,"STRONG",{});var f_t=s(_ge);bSo=r(f_t,"perceiver"),f_t.forEach(t),vSo=r(U$e," \u2014 "),mO=n(U$e,"A",{href:!0});var g_t=s(mO);FSo=r(g_t,"PerceiverForMaskedLM"),g_t.forEach(t),TSo=r(U$e," (Perceiver model)"),U$e.forEach(t),MSo=i(U),jb=n(U,"LI",{});var J$e=s(jb);bge=n(J$e,"STRONG",{});var h_t=s(bge);ESo=r(h_t,"qdqbert"),h_t.forEach(t),CSo=r(J$e," \u2014 "),fO=n(J$e,"A",{href:!0});var u_t=s(fO);wSo=r(u_t,"QDQBertForMaskedLM"),u_t.forEach(t),ASo=r(J$e," (QDQBert model)"),J$e.forEach(t),LSo=i(U),Db=n(U,"LI",{});var Y$e=s(Db);vge=n(Y$e,"STRONG",{});var p_t=s(vge);ySo=r(p_t,"reformer"),p_t.forEach(t),xSo=r(Y$e," \u2014 "),gO=n(Y$e,"A",{href:!0});var __t=s(gO);$So=r(__t,"ReformerForMaskedLM"),__t.forEach(t),kSo=r(Y$e," (Reformer model)"),Y$e.forEach(t),SSo=i(U),Gb=n(U,"LI",{});var K$e=s(Gb);Fge=n(K$e,"STRONG",{});var b_t=s(Fge);RSo=r(b_t,"rembert"),b_t.forEach(t),PSo=r(K$e," \u2014 "),hO=n(K$e,"A",{href:!0});var v_t=s(hO);BSo=r(v_t,"RemBertForMaskedLM"),v_t.forEach(t),ISo=r(K$e," (RemBERT model)"),K$e.forEach(t),NSo=i(U),Ob=n(U,"LI",{});var Z$e=s(Ob);Tge=n(Z$e,"STRONG",{});var F_t=s(Tge);qSo=r(F_t,"roberta"),F_t.forEach(t),jSo=r(Z$e," \u2014 "),uO=n(Z$e,"A",{href:!0});var T_t=s(uO);DSo=r(T_t,"RobertaForMaskedLM"),T_t.forEach(t),GSo=r(Z$e," (RoBERTa model)"),Z$e.forEach(t),OSo=i(U),Vb=n(U,"LI",{});var eke=s(Vb);Mge=n(eke,"STRONG",{});var M_t=s(Mge);VSo=r(M_t,"roformer"),M_t.forEach(t),XSo=r(eke," \u2014 "),pO=n(eke,"A",{href:!0});var E_t=s(pO);zSo=r(E_t,"RoFormerForMaskedLM"),E_t.forEach(t),QSo=r(eke," (RoFormer model)"),eke.forEach(t),WSo=i(U),Xb=n(U,"LI",{});var oke=s(Xb);Ege=n(oke,"STRONG",{});var C_t=s(Ege);HSo=r(C_t,"squeezebert"),C_t.forEach(t),USo=r(oke," \u2014 "),_O=n(oke,"A",{href:!0});var w_t=s(_O);JSo=r(w_t,"SqueezeBertForMaskedLM"),w_t.forEach(t),YSo=r(oke," (SqueezeBERT model)"),oke.forEach(t),KSo=i(U),zb=n(U,"LI",{});var rke=s(zb);Cge=n(rke,"STRONG",{});var A_t=s(Cge);ZSo=r(A_t,"tapas"),A_t.forEach(t),eRo=r(rke," \u2014 "),bO=n(rke,"A",{href:!0});var L_t=s(bO);oRo=r(L_t,"TapasForMaskedLM"),L_t.forEach(t),rRo=r(rke," (TAPAS model)"),rke.forEach(t),tRo=i(U),Qb=n(U,"LI",{});var tke=s(Qb);wge=n(tke,"STRONG",{});var y_t=s(wge);aRo=r(y_t,"wav2vec2"),y_t.forEach(t),nRo=r(tke," \u2014 "),Age=n(tke,"CODE",{});var x_t=s(Age);sRo=r(x_t,"Wav2Vec2ForMaskedLM"),x_t.forEach(t),lRo=r(tke," (Wav2Vec2 model)"),tke.forEach(t),iRo=i(U),Wb=n(U,"LI",{});var ake=s(Wb);Lge=n(ake,"STRONG",{});var $_t=s(Lge);dRo=r($_t,"xlm"),$_t.forEach(t),cRo=r(ake," \u2014 "),vO=n(ake,"A",{href:!0});var k_t=s(vO);mRo=r(k_t,"XLMWithLMHeadModel"),k_t.forEach(t),fRo=r(ake," (XLM model)"),ake.forEach(t),gRo=i(U),Hb=n(U,"LI",{});var nke=s(Hb);yge=n(nke,"STRONG",{});var S_t=s(yge);hRo=r(S_t,"xlm-roberta"),S_t.forEach(t),uRo=r(nke," \u2014 "),FO=n(nke,"A",{href:!0});var R_t=s(FO);pRo=r(R_t,"XLMRobertaForMaskedLM"),R_t.forEach(t),_Ro=r(nke," (XLM-RoBERTa model)"),nke.forEach(t),bRo=i(U),Ub=n(U,"LI",{});var ske=s(Ub);xge=n(ske,"STRONG",{});var P_t=s(xge);vRo=r(P_t,"xlm-roberta-xl"),P_t.forEach(t),FRo=r(ske," \u2014 "),TO=n(ske,"A",{href:!0});var B_t=s(TO);TRo=r(B_t,"XLMRobertaXLForMaskedLM"),B_t.forEach(t),MRo=r(ske," (XLM-RoBERTa-XL model)"),ske.forEach(t),ERo=i(U),Jb=n(U,"LI",{});var lke=s(Jb);$ge=n(lke,"STRONG",{});var I_t=s($ge);CRo=r(I_t,"yoso"),I_t.forEach(t),wRo=r(lke," \u2014 "),MO=n(lke,"A",{href:!0});var N_t=s(MO);ARo=r(N_t,"YosoForMaskedLM"),N_t.forEach(t),LRo=r(lke," (YOSO model)"),lke.forEach(t),U.forEach(t),yRo=i(la),Yb=n(la,"P",{});var ike=s(Yb);xRo=r(ike,"The model is set in evaluation mode by default using "),kge=n(ike,"CODE",{});var q_t=s(kge);$Ro=r(q_t,"model.eval()"),q_t.forEach(t),kRo=r(ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=n(ike,"CODE",{});var j_t=s(Sge);SRo=r(j_t,"model.train()"),j_t.forEach(t),ike.forEach(t),RRo=i(la),T(Kb.$$.fragment,la),la.forEach(t),el.forEach(t),sOe=i(m),Wi=n(m,"H2",{class:!0});var fXe=s(Wi);Zb=n(fXe,"A",{id:!0,class:!0,href:!0});var D_t=s(Zb);Rge=n(D_t,"SPAN",{});var G_t=s(Rge);T(T7.$$.fragment,G_t),G_t.forEach(t),D_t.forEach(t),PRo=i(fXe),Pge=n(fXe,"SPAN",{});var O_t=s(Pge);BRo=r(O_t,"AutoModelForSeq2SeqLM"),O_t.forEach(t),fXe.forEach(t),lOe=i(m),Ro=n(m,"DIV",{class:!0});var ol=s(Ro);T(M7.$$.fragment,ol),IRo=i(ol),Hi=n(ol,"P",{});var Loe=s(Hi);NRo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=n(Loe,"A",{href:!0});var V_t=s(EO);qRo=r(V_t,"from_pretrained()"),V_t.forEach(t),jRo=r(Loe," class method or the "),CO=n(Loe,"A",{href:!0});var X_t=s(CO);DRo=r(X_t,"from_config()"),X_t.forEach(t),GRo=r(Loe,` class
method.`),Loe.forEach(t),ORo=i(ol),E7=n(ol,"P",{});var gXe=s(E7);VRo=r(gXe,"This class cannot be instantiated directly using "),Bge=n(gXe,"CODE",{});var z_t=s(Bge);XRo=r(z_t,"__init__()"),z_t.forEach(t),zRo=r(gXe," (throws an error)."),gXe.forEach(t),QRo=i(ol),dt=n(ol,"DIV",{class:!0});var j6=s(dt);T(C7.$$.fragment,j6),WRo=i(j6),Ige=n(j6,"P",{});var Q_t=s(Ige);HRo=r(Q_t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Q_t.forEach(t),URo=i(j6),Ui=n(j6,"P",{});var yoe=s(Ui);JRo=r(yoe,`Note:
Loading a model from its configuration file does `),Nge=n(yoe,"STRONG",{});var W_t=s(Nge);YRo=r(W_t,"not"),W_t.forEach(t),KRo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=n(yoe,"A",{href:!0});var H_t=s(wO);ZRo=r(H_t,"from_pretrained()"),H_t.forEach(t),ePo=r(yoe," to load the model weights."),yoe.forEach(t),oPo=i(j6),T(ev.$$.fragment,j6),j6.forEach(t),rPo=i(ol),eo=n(ol,"DIV",{class:!0});var ia=s(eo);T(w7.$$.fragment,ia),tPo=i(ia),qge=n(ia,"P",{});var U_t=s(qge);aPo=r(U_t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),U_t.forEach(t),nPo=i(ia),Na=n(ia,"P",{});var D6=s(Na);sPo=r(D6,"The model class to instantiate is selected based on the "),jge=n(D6,"CODE",{});var J_t=s(jge);lPo=r(J_t,"model_type"),J_t.forEach(t),iPo=r(D6,` property of the config object (either
passed as an argument or loaded from `),Dge=n(D6,"CODE",{});var Y_t=s(Dge);dPo=r(Y_t,"pretrained_model_name_or_path"),Y_t.forEach(t),cPo=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=n(D6,"CODE",{});var K_t=s(Gge);mPo=r(K_t,"pretrained_model_name_or_path"),K_t.forEach(t),fPo=r(D6,":"),D6.forEach(t),gPo=i(ia),ue=n(ia,"UL",{});var be=s(ue);ov=n(be,"LI",{});var dke=s(ov);Oge=n(dke,"STRONG",{});var Z_t=s(Oge);hPo=r(Z_t,"bart"),Z_t.forEach(t),uPo=r(dke," \u2014 "),AO=n(dke,"A",{href:!0});var e2t=s(AO);pPo=r(e2t,"BartForConditionalGeneration"),e2t.forEach(t),_Po=r(dke," (BART model)"),dke.forEach(t),bPo=i(be),rv=n(be,"LI",{});var cke=s(rv);Vge=n(cke,"STRONG",{});var o2t=s(Vge);vPo=r(o2t,"bigbird_pegasus"),o2t.forEach(t),FPo=r(cke," \u2014 "),LO=n(cke,"A",{href:!0});var r2t=s(LO);TPo=r(r2t,"BigBirdPegasusForConditionalGeneration"),r2t.forEach(t),MPo=r(cke," (BigBird-Pegasus model)"),cke.forEach(t),EPo=i(be),tv=n(be,"LI",{});var mke=s(tv);Xge=n(mke,"STRONG",{});var t2t=s(Xge);CPo=r(t2t,"blenderbot"),t2t.forEach(t),wPo=r(mke," \u2014 "),yO=n(mke,"A",{href:!0});var a2t=s(yO);APo=r(a2t,"BlenderbotForConditionalGeneration"),a2t.forEach(t),LPo=r(mke," (Blenderbot model)"),mke.forEach(t),yPo=i(be),av=n(be,"LI",{});var fke=s(av);zge=n(fke,"STRONG",{});var n2t=s(zge);xPo=r(n2t,"blenderbot-small"),n2t.forEach(t),$Po=r(fke," \u2014 "),xO=n(fke,"A",{href:!0});var s2t=s(xO);kPo=r(s2t,"BlenderbotSmallForConditionalGeneration"),s2t.forEach(t),SPo=r(fke," (BlenderbotSmall model)"),fke.forEach(t),RPo=i(be),nv=n(be,"LI",{});var gke=s(nv);Qge=n(gke,"STRONG",{});var l2t=s(Qge);PPo=r(l2t,"encoder-decoder"),l2t.forEach(t),BPo=r(gke," \u2014 "),$O=n(gke,"A",{href:!0});var i2t=s($O);IPo=r(i2t,"EncoderDecoderModel"),i2t.forEach(t),NPo=r(gke," (Encoder decoder model)"),gke.forEach(t),qPo=i(be),sv=n(be,"LI",{});var hke=s(sv);Wge=n(hke,"STRONG",{});var d2t=s(Wge);jPo=r(d2t,"fsmt"),d2t.forEach(t),DPo=r(hke," \u2014 "),kO=n(hke,"A",{href:!0});var c2t=s(kO);GPo=r(c2t,"FSMTForConditionalGeneration"),c2t.forEach(t),OPo=r(hke," (FairSeq Machine-Translation model)"),hke.forEach(t),VPo=i(be),lv=n(be,"LI",{});var uke=s(lv);Hge=n(uke,"STRONG",{});var m2t=s(Hge);XPo=r(m2t,"led"),m2t.forEach(t),zPo=r(uke," \u2014 "),SO=n(uke,"A",{href:!0});var f2t=s(SO);QPo=r(f2t,"LEDForConditionalGeneration"),f2t.forEach(t),WPo=r(uke," (LED model)"),uke.forEach(t),HPo=i(be),iv=n(be,"LI",{});var pke=s(iv);Uge=n(pke,"STRONG",{});var g2t=s(Uge);UPo=r(g2t,"longt5"),g2t.forEach(t),JPo=r(pke," \u2014 "),RO=n(pke,"A",{href:!0});var h2t=s(RO);YPo=r(h2t,"LongT5ForConditionalGeneration"),h2t.forEach(t),KPo=r(pke," (LongT5 model)"),pke.forEach(t),ZPo=i(be),dv=n(be,"LI",{});var _ke=s(dv);Jge=n(_ke,"STRONG",{});var u2t=s(Jge);eBo=r(u2t,"m2m_100"),u2t.forEach(t),oBo=r(_ke," \u2014 "),PO=n(_ke,"A",{href:!0});var p2t=s(PO);rBo=r(p2t,"M2M100ForConditionalGeneration"),p2t.forEach(t),tBo=r(_ke," (M2M100 model)"),_ke.forEach(t),aBo=i(be),cv=n(be,"LI",{});var bke=s(cv);Yge=n(bke,"STRONG",{});var _2t=s(Yge);nBo=r(_2t,"marian"),_2t.forEach(t),sBo=r(bke," \u2014 "),BO=n(bke,"A",{href:!0});var b2t=s(BO);lBo=r(b2t,"MarianMTModel"),b2t.forEach(t),iBo=r(bke," (Marian model)"),bke.forEach(t),dBo=i(be),mv=n(be,"LI",{});var vke=s(mv);Kge=n(vke,"STRONG",{});var v2t=s(Kge);cBo=r(v2t,"mbart"),v2t.forEach(t),mBo=r(vke," \u2014 "),IO=n(vke,"A",{href:!0});var F2t=s(IO);fBo=r(F2t,"MBartForConditionalGeneration"),F2t.forEach(t),gBo=r(vke," (mBART model)"),vke.forEach(t),hBo=i(be),fv=n(be,"LI",{});var Fke=s(fv);Zge=n(Fke,"STRONG",{});var T2t=s(Zge);uBo=r(T2t,"mt5"),T2t.forEach(t),pBo=r(Fke," \u2014 "),NO=n(Fke,"A",{href:!0});var M2t=s(NO);_Bo=r(M2t,"MT5ForConditionalGeneration"),M2t.forEach(t),bBo=r(Fke," (MT5 model)"),Fke.forEach(t),vBo=i(be),gv=n(be,"LI",{});var Tke=s(gv);ehe=n(Tke,"STRONG",{});var E2t=s(ehe);FBo=r(E2t,"pegasus"),E2t.forEach(t),TBo=r(Tke," \u2014 "),qO=n(Tke,"A",{href:!0});var C2t=s(qO);MBo=r(C2t,"PegasusForConditionalGeneration"),C2t.forEach(t),EBo=r(Tke," (Pegasus model)"),Tke.forEach(t),CBo=i(be),hv=n(be,"LI",{});var Mke=s(hv);ohe=n(Mke,"STRONG",{});var w2t=s(ohe);wBo=r(w2t,"plbart"),w2t.forEach(t),ABo=r(Mke," \u2014 "),jO=n(Mke,"A",{href:!0});var A2t=s(jO);LBo=r(A2t,"PLBartForConditionalGeneration"),A2t.forEach(t),yBo=r(Mke," (PLBart model)"),Mke.forEach(t),xBo=i(be),uv=n(be,"LI",{});var Eke=s(uv);rhe=n(Eke,"STRONG",{});var L2t=s(rhe);$Bo=r(L2t,"prophetnet"),L2t.forEach(t),kBo=r(Eke," \u2014 "),DO=n(Eke,"A",{href:!0});var y2t=s(DO);SBo=r(y2t,"ProphetNetForConditionalGeneration"),y2t.forEach(t),RBo=r(Eke," (ProphetNet model)"),Eke.forEach(t),PBo=i(be),pv=n(be,"LI",{});var Cke=s(pv);the=n(Cke,"STRONG",{});var x2t=s(the);BBo=r(x2t,"t5"),x2t.forEach(t),IBo=r(Cke," \u2014 "),GO=n(Cke,"A",{href:!0});var $2t=s(GO);NBo=r($2t,"T5ForConditionalGeneration"),$2t.forEach(t),qBo=r(Cke," (T5 model)"),Cke.forEach(t),jBo=i(be),_v=n(be,"LI",{});var wke=s(_v);ahe=n(wke,"STRONG",{});var k2t=s(ahe);DBo=r(k2t,"xlm-prophetnet"),k2t.forEach(t),GBo=r(wke," \u2014 "),OO=n(wke,"A",{href:!0});var S2t=s(OO);OBo=r(S2t,"XLMProphetNetForConditionalGeneration"),S2t.forEach(t),VBo=r(wke," (XLM-ProphetNet model)"),wke.forEach(t),be.forEach(t),XBo=i(ia),bv=n(ia,"P",{});var Ake=s(bv);zBo=r(Ake,"The model is set in evaluation mode by default using "),nhe=n(Ake,"CODE",{});var R2t=s(nhe);QBo=r(R2t,"model.eval()"),R2t.forEach(t),WBo=r(Ake,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=n(Ake,"CODE",{});var P2t=s(she);HBo=r(P2t,"model.train()"),P2t.forEach(t),Ake.forEach(t),UBo=i(ia),T(vv.$$.fragment,ia),ia.forEach(t),ol.forEach(t),iOe=i(m),Ji=n(m,"H2",{class:!0});var hXe=s(Ji);Fv=n(hXe,"A",{id:!0,class:!0,href:!0});var B2t=s(Fv);lhe=n(B2t,"SPAN",{});var I2t=s(lhe);T(A7.$$.fragment,I2t),I2t.forEach(t),B2t.forEach(t),JBo=i(hXe),ihe=n(hXe,"SPAN",{});var N2t=s(ihe);YBo=r(N2t,"AutoModelForSequenceClassification"),N2t.forEach(t),hXe.forEach(t),dOe=i(m),Po=n(m,"DIV",{class:!0});var rl=s(Po);T(L7.$$.fragment,rl),KBo=i(rl),Yi=n(rl,"P",{});var xoe=s(Yi);ZBo=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=n(xoe,"A",{href:!0});var q2t=s(VO);eIo=r(q2t,"from_pretrained()"),q2t.forEach(t),oIo=r(xoe," class method or the "),XO=n(xoe,"A",{href:!0});var j2t=s(XO);rIo=r(j2t,"from_config()"),j2t.forEach(t),tIo=r(xoe,` class
method.`),xoe.forEach(t),aIo=i(rl),y7=n(rl,"P",{});var uXe=s(y7);nIo=r(uXe,"This class cannot be instantiated directly using "),dhe=n(uXe,"CODE",{});var D2t=s(dhe);sIo=r(D2t,"__init__()"),D2t.forEach(t),lIo=r(uXe," (throws an error)."),uXe.forEach(t),iIo=i(rl),ct=n(rl,"DIV",{class:!0});var G6=s(ct);T(x7.$$.fragment,G6),dIo=i(G6),che=n(G6,"P",{});var G2t=s(che);cIo=r(G2t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),G2t.forEach(t),mIo=i(G6),Ki=n(G6,"P",{});var $oe=s(Ki);fIo=r($oe,`Note:
Loading a model from its configuration file does `),mhe=n($oe,"STRONG",{});var O2t=s(mhe);gIo=r(O2t,"not"),O2t.forEach(t),hIo=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=n($oe,"A",{href:!0});var V2t=s(zO);uIo=r(V2t,"from_pretrained()"),V2t.forEach(t),pIo=r($oe," to load the model weights."),$oe.forEach(t),_Io=i(G6),T(Tv.$$.fragment,G6),G6.forEach(t),bIo=i(rl),oo=n(rl,"DIV",{class:!0});var da=s(oo);T($7.$$.fragment,da),vIo=i(da),fhe=n(da,"P",{});var X2t=s(fhe);FIo=r(X2t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),X2t.forEach(t),TIo=i(da),qa=n(da,"P",{});var O6=s(qa);MIo=r(O6,"The model class to instantiate is selected based on the "),ghe=n(O6,"CODE",{});var z2t=s(ghe);EIo=r(z2t,"model_type"),z2t.forEach(t),CIo=r(O6,` property of the config object (either
passed as an argument or loaded from `),hhe=n(O6,"CODE",{});var Q2t=s(hhe);wIo=r(Q2t,"pretrained_model_name_or_path"),Q2t.forEach(t),AIo=r(O6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uhe=n(O6,"CODE",{});var W2t=s(uhe);LIo=r(W2t,"pretrained_model_name_or_path"),W2t.forEach(t),yIo=r(O6,":"),O6.forEach(t),xIo=i(da),N=n(da,"UL",{});var q=s(N);Mv=n(q,"LI",{});var Lke=s(Mv);phe=n(Lke,"STRONG",{});var H2t=s(phe);$Io=r(H2t,"albert"),H2t.forEach(t),kIo=r(Lke," \u2014 "),QO=n(Lke,"A",{href:!0});var U2t=s(QO);SIo=r(U2t,"AlbertForSequenceClassification"),U2t.forEach(t),RIo=r(Lke," (ALBERT model)"),Lke.forEach(t),PIo=i(q),Ev=n(q,"LI",{});var yke=s(Ev);_he=n(yke,"STRONG",{});var J2t=s(_he);BIo=r(J2t,"bart"),J2t.forEach(t),IIo=r(yke," \u2014 "),WO=n(yke,"A",{href:!0});var Y2t=s(WO);NIo=r(Y2t,"BartForSequenceClassification"),Y2t.forEach(t),qIo=r(yke," (BART model)"),yke.forEach(t),jIo=i(q),Cv=n(q,"LI",{});var xke=s(Cv);bhe=n(xke,"STRONG",{});var K2t=s(bhe);DIo=r(K2t,"bert"),K2t.forEach(t),GIo=r(xke," \u2014 "),HO=n(xke,"A",{href:!0});var Z2t=s(HO);OIo=r(Z2t,"BertForSequenceClassification"),Z2t.forEach(t),VIo=r(xke," (BERT model)"),xke.forEach(t),XIo=i(q),wv=n(q,"LI",{});var $ke=s(wv);vhe=n($ke,"STRONG",{});var ebt=s(vhe);zIo=r(ebt,"big_bird"),ebt.forEach(t),QIo=r($ke," \u2014 "),UO=n($ke,"A",{href:!0});var obt=s(UO);WIo=r(obt,"BigBirdForSequenceClassification"),obt.forEach(t),HIo=r($ke," (BigBird model)"),$ke.forEach(t),UIo=i(q),Av=n(q,"LI",{});var kke=s(Av);Fhe=n(kke,"STRONG",{});var rbt=s(Fhe);JIo=r(rbt,"bigbird_pegasus"),rbt.forEach(t),YIo=r(kke," \u2014 "),JO=n(kke,"A",{href:!0});var tbt=s(JO);KIo=r(tbt,"BigBirdPegasusForSequenceClassification"),tbt.forEach(t),ZIo=r(kke," (BigBird-Pegasus model)"),kke.forEach(t),eNo=i(q),Lv=n(q,"LI",{});var Ske=s(Lv);The=n(Ske,"STRONG",{});var abt=s(The);oNo=r(abt,"bloom"),abt.forEach(t),rNo=r(Ske," \u2014 "),YO=n(Ske,"A",{href:!0});var nbt=s(YO);tNo=r(nbt,"BloomForSequenceClassification"),nbt.forEach(t),aNo=r(Ske," (BLOOM model)"),Ske.forEach(t),nNo=i(q),yv=n(q,"LI",{});var Rke=s(yv);Mhe=n(Rke,"STRONG",{});var sbt=s(Mhe);sNo=r(sbt,"camembert"),sbt.forEach(t),lNo=r(Rke," \u2014 "),KO=n(Rke,"A",{href:!0});var lbt=s(KO);iNo=r(lbt,"CamembertForSequenceClassification"),lbt.forEach(t),dNo=r(Rke," (CamemBERT model)"),Rke.forEach(t),cNo=i(q),xv=n(q,"LI",{});var Pke=s(xv);Ehe=n(Pke,"STRONG",{});var ibt=s(Ehe);mNo=r(ibt,"canine"),ibt.forEach(t),fNo=r(Pke," \u2014 "),ZO=n(Pke,"A",{href:!0});var dbt=s(ZO);gNo=r(dbt,"CanineForSequenceClassification"),dbt.forEach(t),hNo=r(Pke," (CANINE model)"),Pke.forEach(t),uNo=i(q),$v=n(q,"LI",{});var Bke=s($v);Che=n(Bke,"STRONG",{});var cbt=s(Che);pNo=r(cbt,"convbert"),cbt.forEach(t),_No=r(Bke," \u2014 "),eV=n(Bke,"A",{href:!0});var mbt=s(eV);bNo=r(mbt,"ConvBertForSequenceClassification"),mbt.forEach(t),vNo=r(Bke," (ConvBERT model)"),Bke.forEach(t),FNo=i(q),kv=n(q,"LI",{});var Ike=s(kv);whe=n(Ike,"STRONG",{});var fbt=s(whe);TNo=r(fbt,"ctrl"),fbt.forEach(t),MNo=r(Ike," \u2014 "),oV=n(Ike,"A",{href:!0});var gbt=s(oV);ENo=r(gbt,"CTRLForSequenceClassification"),gbt.forEach(t),CNo=r(Ike," (CTRL model)"),Ike.forEach(t),wNo=i(q),Sv=n(q,"LI",{});var Nke=s(Sv);Ahe=n(Nke,"STRONG",{});var hbt=s(Ahe);ANo=r(hbt,"data2vec-text"),hbt.forEach(t),LNo=r(Nke," \u2014 "),rV=n(Nke,"A",{href:!0});var ubt=s(rV);yNo=r(ubt,"Data2VecTextForSequenceClassification"),ubt.forEach(t),xNo=r(Nke," (Data2VecText model)"),Nke.forEach(t),$No=i(q),Rv=n(q,"LI",{});var qke=s(Rv);Lhe=n(qke,"STRONG",{});var pbt=s(Lhe);kNo=r(pbt,"deberta"),pbt.forEach(t),SNo=r(qke," \u2014 "),tV=n(qke,"A",{href:!0});var _bt=s(tV);RNo=r(_bt,"DebertaForSequenceClassification"),_bt.forEach(t),PNo=r(qke," (DeBERTa model)"),qke.forEach(t),BNo=i(q),Pv=n(q,"LI",{});var jke=s(Pv);yhe=n(jke,"STRONG",{});var bbt=s(yhe);INo=r(bbt,"deberta-v2"),bbt.forEach(t),NNo=r(jke," \u2014 "),aV=n(jke,"A",{href:!0});var vbt=s(aV);qNo=r(vbt,"DebertaV2ForSequenceClassification"),vbt.forEach(t),jNo=r(jke," (DeBERTa-v2 model)"),jke.forEach(t),DNo=i(q),Bv=n(q,"LI",{});var Dke=s(Bv);xhe=n(Dke,"STRONG",{});var Fbt=s(xhe);GNo=r(Fbt,"distilbert"),Fbt.forEach(t),ONo=r(Dke," \u2014 "),nV=n(Dke,"A",{href:!0});var Tbt=s(nV);VNo=r(Tbt,"DistilBertForSequenceClassification"),Tbt.forEach(t),XNo=r(Dke," (DistilBERT model)"),Dke.forEach(t),zNo=i(q),Iv=n(q,"LI",{});var Gke=s(Iv);$he=n(Gke,"STRONG",{});var Mbt=s($he);QNo=r(Mbt,"electra"),Mbt.forEach(t),WNo=r(Gke," \u2014 "),sV=n(Gke,"A",{href:!0});var Ebt=s(sV);HNo=r(Ebt,"ElectraForSequenceClassification"),Ebt.forEach(t),UNo=r(Gke," (ELECTRA model)"),Gke.forEach(t),JNo=i(q),Nv=n(q,"LI",{});var Oke=s(Nv);khe=n(Oke,"STRONG",{});var Cbt=s(khe);YNo=r(Cbt,"flaubert"),Cbt.forEach(t),KNo=r(Oke," \u2014 "),lV=n(Oke,"A",{href:!0});var wbt=s(lV);ZNo=r(wbt,"FlaubertForSequenceClassification"),wbt.forEach(t),eqo=r(Oke," (FlauBERT model)"),Oke.forEach(t),oqo=i(q),qv=n(q,"LI",{});var Vke=s(qv);She=n(Vke,"STRONG",{});var Abt=s(She);rqo=r(Abt,"fnet"),Abt.forEach(t),tqo=r(Vke," \u2014 "),iV=n(Vke,"A",{href:!0});var Lbt=s(iV);aqo=r(Lbt,"FNetForSequenceClassification"),Lbt.forEach(t),nqo=r(Vke," (FNet model)"),Vke.forEach(t),sqo=i(q),jv=n(q,"LI",{});var Xke=s(jv);Rhe=n(Xke,"STRONG",{});var ybt=s(Rhe);lqo=r(ybt,"funnel"),ybt.forEach(t),iqo=r(Xke," \u2014 "),dV=n(Xke,"A",{href:!0});var xbt=s(dV);dqo=r(xbt,"FunnelForSequenceClassification"),xbt.forEach(t),cqo=r(Xke," (Funnel Transformer model)"),Xke.forEach(t),mqo=i(q),Dv=n(q,"LI",{});var zke=s(Dv);Phe=n(zke,"STRONG",{});var $bt=s(Phe);fqo=r($bt,"gpt2"),$bt.forEach(t),gqo=r(zke," \u2014 "),cV=n(zke,"A",{href:!0});var kbt=s(cV);hqo=r(kbt,"GPT2ForSequenceClassification"),kbt.forEach(t),uqo=r(zke," (OpenAI GPT-2 model)"),zke.forEach(t),pqo=i(q),Gv=n(q,"LI",{});var Qke=s(Gv);Bhe=n(Qke,"STRONG",{});var Sbt=s(Bhe);_qo=r(Sbt,"gpt_neo"),Sbt.forEach(t),bqo=r(Qke," \u2014 "),mV=n(Qke,"A",{href:!0});var Rbt=s(mV);vqo=r(Rbt,"GPTNeoForSequenceClassification"),Rbt.forEach(t),Fqo=r(Qke," (GPT Neo model)"),Qke.forEach(t),Tqo=i(q),Ov=n(q,"LI",{});var Wke=s(Ov);Ihe=n(Wke,"STRONG",{});var Pbt=s(Ihe);Mqo=r(Pbt,"gptj"),Pbt.forEach(t),Eqo=r(Wke," \u2014 "),fV=n(Wke,"A",{href:!0});var Bbt=s(fV);Cqo=r(Bbt,"GPTJForSequenceClassification"),Bbt.forEach(t),wqo=r(Wke," (GPT-J model)"),Wke.forEach(t),Aqo=i(q),Vv=n(q,"LI",{});var Hke=s(Vv);Nhe=n(Hke,"STRONG",{});var Ibt=s(Nhe);Lqo=r(Ibt,"ibert"),Ibt.forEach(t),yqo=r(Hke," \u2014 "),gV=n(Hke,"A",{href:!0});var Nbt=s(gV);xqo=r(Nbt,"IBertForSequenceClassification"),Nbt.forEach(t),$qo=r(Hke," (I-BERT model)"),Hke.forEach(t),kqo=i(q),Xv=n(q,"LI",{});var Uke=s(Xv);qhe=n(Uke,"STRONG",{});var qbt=s(qhe);Sqo=r(qbt,"layoutlm"),qbt.forEach(t),Rqo=r(Uke," \u2014 "),hV=n(Uke,"A",{href:!0});var jbt=s(hV);Pqo=r(jbt,"LayoutLMForSequenceClassification"),jbt.forEach(t),Bqo=r(Uke," (LayoutLM model)"),Uke.forEach(t),Iqo=i(q),zv=n(q,"LI",{});var Jke=s(zv);jhe=n(Jke,"STRONG",{});var Dbt=s(jhe);Nqo=r(Dbt,"layoutlmv2"),Dbt.forEach(t),qqo=r(Jke," \u2014 "),uV=n(Jke,"A",{href:!0});var Gbt=s(uV);jqo=r(Gbt,"LayoutLMv2ForSequenceClassification"),Gbt.forEach(t),Dqo=r(Jke," (LayoutLMv2 model)"),Jke.forEach(t),Gqo=i(q),Qv=n(q,"LI",{});var Yke=s(Qv);Dhe=n(Yke,"STRONG",{});var Obt=s(Dhe);Oqo=r(Obt,"layoutlmv3"),Obt.forEach(t),Vqo=r(Yke," \u2014 "),pV=n(Yke,"A",{href:!0});var Vbt=s(pV);Xqo=r(Vbt,"LayoutLMv3ForSequenceClassification"),Vbt.forEach(t),zqo=r(Yke," (LayoutLMv3 model)"),Yke.forEach(t),Qqo=i(q),Wv=n(q,"LI",{});var Kke=s(Wv);Ghe=n(Kke,"STRONG",{});var Xbt=s(Ghe);Wqo=r(Xbt,"led"),Xbt.forEach(t),Hqo=r(Kke," \u2014 "),_V=n(Kke,"A",{href:!0});var zbt=s(_V);Uqo=r(zbt,"LEDForSequenceClassification"),zbt.forEach(t),Jqo=r(Kke," (LED model)"),Kke.forEach(t),Yqo=i(q),Hv=n(q,"LI",{});var Zke=s(Hv);Ohe=n(Zke,"STRONG",{});var Qbt=s(Ohe);Kqo=r(Qbt,"longformer"),Qbt.forEach(t),Zqo=r(Zke," \u2014 "),bV=n(Zke,"A",{href:!0});var Wbt=s(bV);ejo=r(Wbt,"LongformerForSequenceClassification"),Wbt.forEach(t),ojo=r(Zke," (Longformer model)"),Zke.forEach(t),rjo=i(q),Uv=n(q,"LI",{});var eSe=s(Uv);Vhe=n(eSe,"STRONG",{});var Hbt=s(Vhe);tjo=r(Hbt,"mbart"),Hbt.forEach(t),ajo=r(eSe," \u2014 "),vV=n(eSe,"A",{href:!0});var Ubt=s(vV);njo=r(Ubt,"MBartForSequenceClassification"),Ubt.forEach(t),sjo=r(eSe," (mBART model)"),eSe.forEach(t),ljo=i(q),Jv=n(q,"LI",{});var oSe=s(Jv);Xhe=n(oSe,"STRONG",{});var Jbt=s(Xhe);ijo=r(Jbt,"megatron-bert"),Jbt.forEach(t),djo=r(oSe," \u2014 "),FV=n(oSe,"A",{href:!0});var Ybt=s(FV);cjo=r(Ybt,"MegatronBertForSequenceClassification"),Ybt.forEach(t),mjo=r(oSe," (Megatron-BERT model)"),oSe.forEach(t),fjo=i(q),Yv=n(q,"LI",{});var rSe=s(Yv);zhe=n(rSe,"STRONG",{});var Kbt=s(zhe);gjo=r(Kbt,"mobilebert"),Kbt.forEach(t),hjo=r(rSe," \u2014 "),TV=n(rSe,"A",{href:!0});var Zbt=s(TV);ujo=r(Zbt,"MobileBertForSequenceClassification"),Zbt.forEach(t),pjo=r(rSe," (MobileBERT model)"),rSe.forEach(t),_jo=i(q),Kv=n(q,"LI",{});var tSe=s(Kv);Qhe=n(tSe,"STRONG",{});var evt=s(Qhe);bjo=r(evt,"mpnet"),evt.forEach(t),vjo=r(tSe," \u2014 "),MV=n(tSe,"A",{href:!0});var ovt=s(MV);Fjo=r(ovt,"MPNetForSequenceClassification"),ovt.forEach(t),Tjo=r(tSe," (MPNet model)"),tSe.forEach(t),Mjo=i(q),Zv=n(q,"LI",{});var aSe=s(Zv);Whe=n(aSe,"STRONG",{});var rvt=s(Whe);Ejo=r(rvt,"nezha"),rvt.forEach(t),Cjo=r(aSe," \u2014 "),EV=n(aSe,"A",{href:!0});var tvt=s(EV);wjo=r(tvt,"NezhaForSequenceClassification"),tvt.forEach(t),Ajo=r(aSe," (Nezha model)"),aSe.forEach(t),Ljo=i(q),eF=n(q,"LI",{});var nSe=s(eF);Hhe=n(nSe,"STRONG",{});var avt=s(Hhe);yjo=r(avt,"nystromformer"),avt.forEach(t),xjo=r(nSe," \u2014 "),CV=n(nSe,"A",{href:!0});var nvt=s(CV);$jo=r(nvt,"NystromformerForSequenceClassification"),nvt.forEach(t),kjo=r(nSe," (Nystr\xF6mformer model)"),nSe.forEach(t),Sjo=i(q),oF=n(q,"LI",{});var sSe=s(oF);Uhe=n(sSe,"STRONG",{});var svt=s(Uhe);Rjo=r(svt,"openai-gpt"),svt.forEach(t),Pjo=r(sSe," \u2014 "),wV=n(sSe,"A",{href:!0});var lvt=s(wV);Bjo=r(lvt,"OpenAIGPTForSequenceClassification"),lvt.forEach(t),Ijo=r(sSe," (OpenAI GPT model)"),sSe.forEach(t),Njo=i(q),rF=n(q,"LI",{});var lSe=s(rF);Jhe=n(lSe,"STRONG",{});var ivt=s(Jhe);qjo=r(ivt,"perceiver"),ivt.forEach(t),jjo=r(lSe," \u2014 "),AV=n(lSe,"A",{href:!0});var dvt=s(AV);Djo=r(dvt,"PerceiverForSequenceClassification"),dvt.forEach(t),Gjo=r(lSe," (Perceiver model)"),lSe.forEach(t),Ojo=i(q),tF=n(q,"LI",{});var iSe=s(tF);Yhe=n(iSe,"STRONG",{});var cvt=s(Yhe);Vjo=r(cvt,"plbart"),cvt.forEach(t),Xjo=r(iSe," \u2014 "),LV=n(iSe,"A",{href:!0});var mvt=s(LV);zjo=r(mvt,"PLBartForSequenceClassification"),mvt.forEach(t),Qjo=r(iSe," (PLBart model)"),iSe.forEach(t),Wjo=i(q),aF=n(q,"LI",{});var dSe=s(aF);Khe=n(dSe,"STRONG",{});var fvt=s(Khe);Hjo=r(fvt,"qdqbert"),fvt.forEach(t),Ujo=r(dSe," \u2014 "),yV=n(dSe,"A",{href:!0});var gvt=s(yV);Jjo=r(gvt,"QDQBertForSequenceClassification"),gvt.forEach(t),Yjo=r(dSe," (QDQBert model)"),dSe.forEach(t),Kjo=i(q),nF=n(q,"LI",{});var cSe=s(nF);Zhe=n(cSe,"STRONG",{});var hvt=s(Zhe);Zjo=r(hvt,"reformer"),hvt.forEach(t),eDo=r(cSe," \u2014 "),xV=n(cSe,"A",{href:!0});var uvt=s(xV);oDo=r(uvt,"ReformerForSequenceClassification"),uvt.forEach(t),rDo=r(cSe," (Reformer model)"),cSe.forEach(t),tDo=i(q),sF=n(q,"LI",{});var mSe=s(sF);eue=n(mSe,"STRONG",{});var pvt=s(eue);aDo=r(pvt,"rembert"),pvt.forEach(t),nDo=r(mSe," \u2014 "),$V=n(mSe,"A",{href:!0});var _vt=s($V);sDo=r(_vt,"RemBertForSequenceClassification"),_vt.forEach(t),lDo=r(mSe," (RemBERT model)"),mSe.forEach(t),iDo=i(q),lF=n(q,"LI",{});var fSe=s(lF);oue=n(fSe,"STRONG",{});var bvt=s(oue);dDo=r(bvt,"roberta"),bvt.forEach(t),cDo=r(fSe," \u2014 "),kV=n(fSe,"A",{href:!0});var vvt=s(kV);mDo=r(vvt,"RobertaForSequenceClassification"),vvt.forEach(t),fDo=r(fSe," (RoBERTa model)"),fSe.forEach(t),gDo=i(q),iF=n(q,"LI",{});var gSe=s(iF);rue=n(gSe,"STRONG",{});var Fvt=s(rue);hDo=r(Fvt,"roformer"),Fvt.forEach(t),uDo=r(gSe," \u2014 "),SV=n(gSe,"A",{href:!0});var Tvt=s(SV);pDo=r(Tvt,"RoFormerForSequenceClassification"),Tvt.forEach(t),_Do=r(gSe," (RoFormer model)"),gSe.forEach(t),bDo=i(q),dF=n(q,"LI",{});var hSe=s(dF);tue=n(hSe,"STRONG",{});var Mvt=s(tue);vDo=r(Mvt,"squeezebert"),Mvt.forEach(t),FDo=r(hSe," \u2014 "),RV=n(hSe,"A",{href:!0});var Evt=s(RV);TDo=r(Evt,"SqueezeBertForSequenceClassification"),Evt.forEach(t),MDo=r(hSe," (SqueezeBERT model)"),hSe.forEach(t),EDo=i(q),cF=n(q,"LI",{});var uSe=s(cF);aue=n(uSe,"STRONG",{});var Cvt=s(aue);CDo=r(Cvt,"tapas"),Cvt.forEach(t),wDo=r(uSe," \u2014 "),PV=n(uSe,"A",{href:!0});var wvt=s(PV);ADo=r(wvt,"TapasForSequenceClassification"),wvt.forEach(t),LDo=r(uSe," (TAPAS model)"),uSe.forEach(t),yDo=i(q),mF=n(q,"LI",{});var pSe=s(mF);nue=n(pSe,"STRONG",{});var Avt=s(nue);xDo=r(Avt,"transfo-xl"),Avt.forEach(t),$Do=r(pSe," \u2014 "),BV=n(pSe,"A",{href:!0});var Lvt=s(BV);kDo=r(Lvt,"TransfoXLForSequenceClassification"),Lvt.forEach(t),SDo=r(pSe," (Transformer-XL model)"),pSe.forEach(t),RDo=i(q),fF=n(q,"LI",{});var _Se=s(fF);sue=n(_Se,"STRONG",{});var yvt=s(sue);PDo=r(yvt,"xlm"),yvt.forEach(t),BDo=r(_Se," \u2014 "),IV=n(_Se,"A",{href:!0});var xvt=s(IV);IDo=r(xvt,"XLMForSequenceClassification"),xvt.forEach(t),NDo=r(_Se," (XLM model)"),_Se.forEach(t),qDo=i(q),gF=n(q,"LI",{});var bSe=s(gF);lue=n(bSe,"STRONG",{});var $vt=s(lue);jDo=r($vt,"xlm-roberta"),$vt.forEach(t),DDo=r(bSe," \u2014 "),NV=n(bSe,"A",{href:!0});var kvt=s(NV);GDo=r(kvt,"XLMRobertaForSequenceClassification"),kvt.forEach(t),ODo=r(bSe," (XLM-RoBERTa model)"),bSe.forEach(t),VDo=i(q),hF=n(q,"LI",{});var vSe=s(hF);iue=n(vSe,"STRONG",{});var Svt=s(iue);XDo=r(Svt,"xlm-roberta-xl"),Svt.forEach(t),zDo=r(vSe," \u2014 "),qV=n(vSe,"A",{href:!0});var Rvt=s(qV);QDo=r(Rvt,"XLMRobertaXLForSequenceClassification"),Rvt.forEach(t),WDo=r(vSe," (XLM-RoBERTa-XL model)"),vSe.forEach(t),HDo=i(q),uF=n(q,"LI",{});var FSe=s(uF);due=n(FSe,"STRONG",{});var Pvt=s(due);UDo=r(Pvt,"xlnet"),Pvt.forEach(t),JDo=r(FSe," \u2014 "),jV=n(FSe,"A",{href:!0});var Bvt=s(jV);YDo=r(Bvt,"XLNetForSequenceClassification"),Bvt.forEach(t),KDo=r(FSe," (XLNet model)"),FSe.forEach(t),ZDo=i(q),pF=n(q,"LI",{});var TSe=s(pF);cue=n(TSe,"STRONG",{});var Ivt=s(cue);eGo=r(Ivt,"yoso"),Ivt.forEach(t),oGo=r(TSe," \u2014 "),DV=n(TSe,"A",{href:!0});var Nvt=s(DV);rGo=r(Nvt,"YosoForSequenceClassification"),Nvt.forEach(t),tGo=r(TSe," (YOSO model)"),TSe.forEach(t),q.forEach(t),aGo=i(da),_F=n(da,"P",{});var MSe=s(_F);nGo=r(MSe,"The model is set in evaluation mode by default using "),mue=n(MSe,"CODE",{});var qvt=s(mue);sGo=r(qvt,"model.eval()"),qvt.forEach(t),lGo=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fue=n(MSe,"CODE",{});var jvt=s(fue);iGo=r(jvt,"model.train()"),jvt.forEach(t),MSe.forEach(t),dGo=i(da),T(bF.$$.fragment,da),da.forEach(t),rl.forEach(t),cOe=i(m),Zi=n(m,"H2",{class:!0});var pXe=s(Zi);vF=n(pXe,"A",{id:!0,class:!0,href:!0});var Dvt=s(vF);gue=n(Dvt,"SPAN",{});var Gvt=s(gue);T(k7.$$.fragment,Gvt),Gvt.forEach(t),Dvt.forEach(t),cGo=i(pXe),hue=n(pXe,"SPAN",{});var Ovt=s(hue);mGo=r(Ovt,"AutoModelForMultipleChoice"),Ovt.forEach(t),pXe.forEach(t),mOe=i(m),Bo=n(m,"DIV",{class:!0});var tl=s(Bo);T(S7.$$.fragment,tl),fGo=i(tl),ed=n(tl,"P",{});var koe=s(ed);gGo=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=n(koe,"A",{href:!0});var Vvt=s(GV);hGo=r(Vvt,"from_pretrained()"),Vvt.forEach(t),uGo=r(koe," class method or the "),OV=n(koe,"A",{href:!0});var Xvt=s(OV);pGo=r(Xvt,"from_config()"),Xvt.forEach(t),_Go=r(koe,` class
method.`),koe.forEach(t),bGo=i(tl),R7=n(tl,"P",{});var _Xe=s(R7);vGo=r(_Xe,"This class cannot be instantiated directly using "),uue=n(_Xe,"CODE",{});var zvt=s(uue);FGo=r(zvt,"__init__()"),zvt.forEach(t),TGo=r(_Xe," (throws an error)."),_Xe.forEach(t),MGo=i(tl),mt=n(tl,"DIV",{class:!0});var V6=s(mt);T(P7.$$.fragment,V6),EGo=i(V6),pue=n(V6,"P",{});var Qvt=s(pue);CGo=r(Qvt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Qvt.forEach(t),wGo=i(V6),od=n(V6,"P",{});var Soe=s(od);AGo=r(Soe,`Note:
Loading a model from its configuration file does `),_ue=n(Soe,"STRONG",{});var Wvt=s(_ue);LGo=r(Wvt,"not"),Wvt.forEach(t),yGo=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(Soe,"A",{href:!0});var Hvt=s(VV);xGo=r(Hvt,"from_pretrained()"),Hvt.forEach(t),$Go=r(Soe," to load the model weights."),Soe.forEach(t),kGo=i(V6),T(FF.$$.fragment,V6),V6.forEach(t),SGo=i(tl),ro=n(tl,"DIV",{class:!0});var ca=s(ro);T(B7.$$.fragment,ca),RGo=i(ca),bue=n(ca,"P",{});var Uvt=s(bue);PGo=r(Uvt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Uvt.forEach(t),BGo=i(ca),ja=n(ca,"P",{});var X6=s(ja);IGo=r(X6,"The model class to instantiate is selected based on the "),vue=n(X6,"CODE",{});var Jvt=s(vue);NGo=r(Jvt,"model_type"),Jvt.forEach(t),qGo=r(X6,` property of the config object (either
passed as an argument or loaded from `),Fue=n(X6,"CODE",{});var Yvt=s(Fue);jGo=r(Yvt,"pretrained_model_name_or_path"),Yvt.forEach(t),DGo=r(X6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tue=n(X6,"CODE",{});var Kvt=s(Tue);GGo=r(Kvt,"pretrained_model_name_or_path"),Kvt.forEach(t),OGo=r(X6,":"),X6.forEach(t),VGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);TF=n(ee,"LI",{});var ESe=s(TF);Mue=n(ESe,"STRONG",{});var Zvt=s(Mue);XGo=r(Zvt,"albert"),Zvt.forEach(t),zGo=r(ESe," \u2014 "),XV=n(ESe,"A",{href:!0});var eFt=s(XV);QGo=r(eFt,"AlbertForMultipleChoice"),eFt.forEach(t),WGo=r(ESe," (ALBERT model)"),ESe.forEach(t),HGo=i(ee),MF=n(ee,"LI",{});var CSe=s(MF);Eue=n(CSe,"STRONG",{});var oFt=s(Eue);UGo=r(oFt,"bert"),oFt.forEach(t),JGo=r(CSe," \u2014 "),zV=n(CSe,"A",{href:!0});var rFt=s(zV);YGo=r(rFt,"BertForMultipleChoice"),rFt.forEach(t),KGo=r(CSe," (BERT model)"),CSe.forEach(t),ZGo=i(ee),EF=n(ee,"LI",{});var wSe=s(EF);Cue=n(wSe,"STRONG",{});var tFt=s(Cue);eOo=r(tFt,"big_bird"),tFt.forEach(t),oOo=r(wSe," \u2014 "),QV=n(wSe,"A",{href:!0});var aFt=s(QV);rOo=r(aFt,"BigBirdForMultipleChoice"),aFt.forEach(t),tOo=r(wSe," (BigBird model)"),wSe.forEach(t),aOo=i(ee),CF=n(ee,"LI",{});var ASe=s(CF);wue=n(ASe,"STRONG",{});var nFt=s(wue);nOo=r(nFt,"camembert"),nFt.forEach(t),sOo=r(ASe," \u2014 "),WV=n(ASe,"A",{href:!0});var sFt=s(WV);lOo=r(sFt,"CamembertForMultipleChoice"),sFt.forEach(t),iOo=r(ASe," (CamemBERT model)"),ASe.forEach(t),dOo=i(ee),wF=n(ee,"LI",{});var LSe=s(wF);Aue=n(LSe,"STRONG",{});var lFt=s(Aue);cOo=r(lFt,"canine"),lFt.forEach(t),mOo=r(LSe," \u2014 "),HV=n(LSe,"A",{href:!0});var iFt=s(HV);fOo=r(iFt,"CanineForMultipleChoice"),iFt.forEach(t),gOo=r(LSe," (CANINE model)"),LSe.forEach(t),hOo=i(ee),AF=n(ee,"LI",{});var ySe=s(AF);Lue=n(ySe,"STRONG",{});var dFt=s(Lue);uOo=r(dFt,"convbert"),dFt.forEach(t),pOo=r(ySe," \u2014 "),UV=n(ySe,"A",{href:!0});var cFt=s(UV);_Oo=r(cFt,"ConvBertForMultipleChoice"),cFt.forEach(t),bOo=r(ySe," (ConvBERT model)"),ySe.forEach(t),vOo=i(ee),LF=n(ee,"LI",{});var xSe=s(LF);yue=n(xSe,"STRONG",{});var mFt=s(yue);FOo=r(mFt,"data2vec-text"),mFt.forEach(t),TOo=r(xSe," \u2014 "),JV=n(xSe,"A",{href:!0});var fFt=s(JV);MOo=r(fFt,"Data2VecTextForMultipleChoice"),fFt.forEach(t),EOo=r(xSe," (Data2VecText model)"),xSe.forEach(t),COo=i(ee),yF=n(ee,"LI",{});var $Se=s(yF);xue=n($Se,"STRONG",{});var gFt=s(xue);wOo=r(gFt,"deberta-v2"),gFt.forEach(t),AOo=r($Se," \u2014 "),YV=n($Se,"A",{href:!0});var hFt=s(YV);LOo=r(hFt,"DebertaV2ForMultipleChoice"),hFt.forEach(t),yOo=r($Se," (DeBERTa-v2 model)"),$Se.forEach(t),xOo=i(ee),xF=n(ee,"LI",{});var kSe=s(xF);$ue=n(kSe,"STRONG",{});var uFt=s($ue);$Oo=r(uFt,"distilbert"),uFt.forEach(t),kOo=r(kSe," \u2014 "),KV=n(kSe,"A",{href:!0});var pFt=s(KV);SOo=r(pFt,"DistilBertForMultipleChoice"),pFt.forEach(t),ROo=r(kSe," (DistilBERT model)"),kSe.forEach(t),POo=i(ee),$F=n(ee,"LI",{});var SSe=s($F);kue=n(SSe,"STRONG",{});var _Ft=s(kue);BOo=r(_Ft,"electra"),_Ft.forEach(t),IOo=r(SSe," \u2014 "),ZV=n(SSe,"A",{href:!0});var bFt=s(ZV);NOo=r(bFt,"ElectraForMultipleChoice"),bFt.forEach(t),qOo=r(SSe," (ELECTRA model)"),SSe.forEach(t),jOo=i(ee),kF=n(ee,"LI",{});var RSe=s(kF);Sue=n(RSe,"STRONG",{});var vFt=s(Sue);DOo=r(vFt,"flaubert"),vFt.forEach(t),GOo=r(RSe," \u2014 "),eX=n(RSe,"A",{href:!0});var FFt=s(eX);OOo=r(FFt,"FlaubertForMultipleChoice"),FFt.forEach(t),VOo=r(RSe," (FlauBERT model)"),RSe.forEach(t),XOo=i(ee),SF=n(ee,"LI",{});var PSe=s(SF);Rue=n(PSe,"STRONG",{});var TFt=s(Rue);zOo=r(TFt,"fnet"),TFt.forEach(t),QOo=r(PSe," \u2014 "),oX=n(PSe,"A",{href:!0});var MFt=s(oX);WOo=r(MFt,"FNetForMultipleChoice"),MFt.forEach(t),HOo=r(PSe," (FNet model)"),PSe.forEach(t),UOo=i(ee),RF=n(ee,"LI",{});var BSe=s(RF);Pue=n(BSe,"STRONG",{});var EFt=s(Pue);JOo=r(EFt,"funnel"),EFt.forEach(t),YOo=r(BSe," \u2014 "),rX=n(BSe,"A",{href:!0});var CFt=s(rX);KOo=r(CFt,"FunnelForMultipleChoice"),CFt.forEach(t),ZOo=r(BSe," (Funnel Transformer model)"),BSe.forEach(t),eVo=i(ee),PF=n(ee,"LI",{});var ISe=s(PF);Bue=n(ISe,"STRONG",{});var wFt=s(Bue);oVo=r(wFt,"ibert"),wFt.forEach(t),rVo=r(ISe," \u2014 "),tX=n(ISe,"A",{href:!0});var AFt=s(tX);tVo=r(AFt,"IBertForMultipleChoice"),AFt.forEach(t),aVo=r(ISe," (I-BERT model)"),ISe.forEach(t),nVo=i(ee),BF=n(ee,"LI",{});var NSe=s(BF);Iue=n(NSe,"STRONG",{});var LFt=s(Iue);sVo=r(LFt,"longformer"),LFt.forEach(t),lVo=r(NSe," \u2014 "),aX=n(NSe,"A",{href:!0});var yFt=s(aX);iVo=r(yFt,"LongformerForMultipleChoice"),yFt.forEach(t),dVo=r(NSe," (Longformer model)"),NSe.forEach(t),cVo=i(ee),IF=n(ee,"LI",{});var qSe=s(IF);Nue=n(qSe,"STRONG",{});var xFt=s(Nue);mVo=r(xFt,"megatron-bert"),xFt.forEach(t),fVo=r(qSe," \u2014 "),nX=n(qSe,"A",{href:!0});var $Ft=s(nX);gVo=r($Ft,"MegatronBertForMultipleChoice"),$Ft.forEach(t),hVo=r(qSe," (Megatron-BERT model)"),qSe.forEach(t),uVo=i(ee),NF=n(ee,"LI",{});var jSe=s(NF);que=n(jSe,"STRONG",{});var kFt=s(que);pVo=r(kFt,"mobilebert"),kFt.forEach(t),_Vo=r(jSe," \u2014 "),sX=n(jSe,"A",{href:!0});var SFt=s(sX);bVo=r(SFt,"MobileBertForMultipleChoice"),SFt.forEach(t),vVo=r(jSe," (MobileBERT model)"),jSe.forEach(t),FVo=i(ee),qF=n(ee,"LI",{});var DSe=s(qF);jue=n(DSe,"STRONG",{});var RFt=s(jue);TVo=r(RFt,"mpnet"),RFt.forEach(t),MVo=r(DSe," \u2014 "),lX=n(DSe,"A",{href:!0});var PFt=s(lX);EVo=r(PFt,"MPNetForMultipleChoice"),PFt.forEach(t),CVo=r(DSe," (MPNet model)"),DSe.forEach(t),wVo=i(ee),jF=n(ee,"LI",{});var GSe=s(jF);Due=n(GSe,"STRONG",{});var BFt=s(Due);AVo=r(BFt,"nezha"),BFt.forEach(t),LVo=r(GSe," \u2014 "),iX=n(GSe,"A",{href:!0});var IFt=s(iX);yVo=r(IFt,"NezhaForMultipleChoice"),IFt.forEach(t),xVo=r(GSe," (Nezha model)"),GSe.forEach(t),$Vo=i(ee),DF=n(ee,"LI",{});var OSe=s(DF);Gue=n(OSe,"STRONG",{});var NFt=s(Gue);kVo=r(NFt,"nystromformer"),NFt.forEach(t),SVo=r(OSe," \u2014 "),dX=n(OSe,"A",{href:!0});var qFt=s(dX);RVo=r(qFt,"NystromformerForMultipleChoice"),qFt.forEach(t),PVo=r(OSe," (Nystr\xF6mformer model)"),OSe.forEach(t),BVo=i(ee),GF=n(ee,"LI",{});var VSe=s(GF);Oue=n(VSe,"STRONG",{});var jFt=s(Oue);IVo=r(jFt,"qdqbert"),jFt.forEach(t),NVo=r(VSe," \u2014 "),cX=n(VSe,"A",{href:!0});var DFt=s(cX);qVo=r(DFt,"QDQBertForMultipleChoice"),DFt.forEach(t),jVo=r(VSe," (QDQBert model)"),VSe.forEach(t),DVo=i(ee),OF=n(ee,"LI",{});var XSe=s(OF);Vue=n(XSe,"STRONG",{});var GFt=s(Vue);GVo=r(GFt,"rembert"),GFt.forEach(t),OVo=r(XSe," \u2014 "),mX=n(XSe,"A",{href:!0});var OFt=s(mX);VVo=r(OFt,"RemBertForMultipleChoice"),OFt.forEach(t),XVo=r(XSe," (RemBERT model)"),XSe.forEach(t),zVo=i(ee),VF=n(ee,"LI",{});var zSe=s(VF);Xue=n(zSe,"STRONG",{});var VFt=s(Xue);QVo=r(VFt,"roberta"),VFt.forEach(t),WVo=r(zSe," \u2014 "),fX=n(zSe,"A",{href:!0});var XFt=s(fX);HVo=r(XFt,"RobertaForMultipleChoice"),XFt.forEach(t),UVo=r(zSe," (RoBERTa model)"),zSe.forEach(t),JVo=i(ee),XF=n(ee,"LI",{});var QSe=s(XF);zue=n(QSe,"STRONG",{});var zFt=s(zue);YVo=r(zFt,"roformer"),zFt.forEach(t),KVo=r(QSe," \u2014 "),gX=n(QSe,"A",{href:!0});var QFt=s(gX);ZVo=r(QFt,"RoFormerForMultipleChoice"),QFt.forEach(t),eXo=r(QSe," (RoFormer model)"),QSe.forEach(t),oXo=i(ee),zF=n(ee,"LI",{});var WSe=s(zF);Que=n(WSe,"STRONG",{});var WFt=s(Que);rXo=r(WFt,"squeezebert"),WFt.forEach(t),tXo=r(WSe," \u2014 "),hX=n(WSe,"A",{href:!0});var HFt=s(hX);aXo=r(HFt,"SqueezeBertForMultipleChoice"),HFt.forEach(t),nXo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),sXo=i(ee),QF=n(ee,"LI",{});var HSe=s(QF);Wue=n(HSe,"STRONG",{});var UFt=s(Wue);lXo=r(UFt,"xlm"),UFt.forEach(t),iXo=r(HSe," \u2014 "),uX=n(HSe,"A",{href:!0});var JFt=s(uX);dXo=r(JFt,"XLMForMultipleChoice"),JFt.forEach(t),cXo=r(HSe," (XLM model)"),HSe.forEach(t),mXo=i(ee),WF=n(ee,"LI",{});var USe=s(WF);Hue=n(USe,"STRONG",{});var YFt=s(Hue);fXo=r(YFt,"xlm-roberta"),YFt.forEach(t),gXo=r(USe," \u2014 "),pX=n(USe,"A",{href:!0});var KFt=s(pX);hXo=r(KFt,"XLMRobertaForMultipleChoice"),KFt.forEach(t),uXo=r(USe," (XLM-RoBERTa model)"),USe.forEach(t),pXo=i(ee),HF=n(ee,"LI",{});var JSe=s(HF);Uue=n(JSe,"STRONG",{});var ZFt=s(Uue);_Xo=r(ZFt,"xlm-roberta-xl"),ZFt.forEach(t),bXo=r(JSe," \u2014 "),_X=n(JSe,"A",{href:!0});var e1t=s(_X);vXo=r(e1t,"XLMRobertaXLForMultipleChoice"),e1t.forEach(t),FXo=r(JSe," (XLM-RoBERTa-XL model)"),JSe.forEach(t),TXo=i(ee),UF=n(ee,"LI",{});var YSe=s(UF);Jue=n(YSe,"STRONG",{});var o1t=s(Jue);MXo=r(o1t,"xlnet"),o1t.forEach(t),EXo=r(YSe," \u2014 "),bX=n(YSe,"A",{href:!0});var r1t=s(bX);CXo=r(r1t,"XLNetForMultipleChoice"),r1t.forEach(t),wXo=r(YSe," (XLNet model)"),YSe.forEach(t),AXo=i(ee),JF=n(ee,"LI",{});var KSe=s(JF);Yue=n(KSe,"STRONG",{});var t1t=s(Yue);LXo=r(t1t,"yoso"),t1t.forEach(t),yXo=r(KSe," \u2014 "),vX=n(KSe,"A",{href:!0});var a1t=s(vX);xXo=r(a1t,"YosoForMultipleChoice"),a1t.forEach(t),$Xo=r(KSe," (YOSO model)"),KSe.forEach(t),ee.forEach(t),kXo=i(ca),YF=n(ca,"P",{});var ZSe=s(YF);SXo=r(ZSe,"The model is set in evaluation mode by default using "),Kue=n(ZSe,"CODE",{});var n1t=s(Kue);RXo=r(n1t,"model.eval()"),n1t.forEach(t),PXo=r(ZSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zue=n(ZSe,"CODE",{});var s1t=s(Zue);BXo=r(s1t,"model.train()"),s1t.forEach(t),ZSe.forEach(t),IXo=i(ca),T(KF.$$.fragment,ca),ca.forEach(t),tl.forEach(t),fOe=i(m),rd=n(m,"H2",{class:!0});var bXe=s(rd);ZF=n(bXe,"A",{id:!0,class:!0,href:!0});var l1t=s(ZF);epe=n(l1t,"SPAN",{});var i1t=s(epe);T(I7.$$.fragment,i1t),i1t.forEach(t),l1t.forEach(t),NXo=i(bXe),ope=n(bXe,"SPAN",{});var d1t=s(ope);qXo=r(d1t,"AutoModelForNextSentencePrediction"),d1t.forEach(t),bXe.forEach(t),gOe=i(m),Io=n(m,"DIV",{class:!0});var al=s(Io);T(N7.$$.fragment,al),jXo=i(al),td=n(al,"P",{});var Roe=s(td);DXo=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=n(Roe,"A",{href:!0});var c1t=s(FX);GXo=r(c1t,"from_pretrained()"),c1t.forEach(t),OXo=r(Roe," class method or the "),TX=n(Roe,"A",{href:!0});var m1t=s(TX);VXo=r(m1t,"from_config()"),m1t.forEach(t),XXo=r(Roe,` class
method.`),Roe.forEach(t),zXo=i(al),q7=n(al,"P",{});var vXe=s(q7);QXo=r(vXe,"This class cannot be instantiated directly using "),rpe=n(vXe,"CODE",{});var f1t=s(rpe);WXo=r(f1t,"__init__()"),f1t.forEach(t),HXo=r(vXe," (throws an error)."),vXe.forEach(t),UXo=i(al),ft=n(al,"DIV",{class:!0});var z6=s(ft);T(j7.$$.fragment,z6),JXo=i(z6),tpe=n(z6,"P",{});var g1t=s(tpe);YXo=r(g1t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),g1t.forEach(t),KXo=i(z6),ad=n(z6,"P",{});var Poe=s(ad);ZXo=r(Poe,`Note:
Loading a model from its configuration file does `),ape=n(Poe,"STRONG",{});var h1t=s(ape);ezo=r(h1t,"not"),h1t.forEach(t),ozo=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(Poe,"A",{href:!0});var u1t=s(MX);rzo=r(u1t,"from_pretrained()"),u1t.forEach(t),tzo=r(Poe," to load the model weights."),Poe.forEach(t),azo=i(z6),T(e1.$$.fragment,z6),z6.forEach(t),nzo=i(al),to=n(al,"DIV",{class:!0});var ma=s(to);T(D7.$$.fragment,ma),szo=i(ma),npe=n(ma,"P",{});var p1t=s(npe);lzo=r(p1t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),p1t.forEach(t),izo=i(ma),Da=n(ma,"P",{});var Q6=s(Da);dzo=r(Q6,"The model class to instantiate is selected based on the "),spe=n(Q6,"CODE",{});var _1t=s(spe);czo=r(_1t,"model_type"),_1t.forEach(t),mzo=r(Q6,` property of the config object (either
passed as an argument or loaded from `),lpe=n(Q6,"CODE",{});var b1t=s(lpe);fzo=r(b1t,"pretrained_model_name_or_path"),b1t.forEach(t),gzo=r(Q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ipe=n(Q6,"CODE",{});var v1t=s(ipe);hzo=r(v1t,"pretrained_model_name_or_path"),v1t.forEach(t),uzo=r(Q6,":"),Q6.forEach(t),pzo=i(ma),No=n(ma,"UL",{});var fa=s(No);o1=n(fa,"LI",{});var eRe=s(o1);dpe=n(eRe,"STRONG",{});var F1t=s(dpe);_zo=r(F1t,"bert"),F1t.forEach(t),bzo=r(eRe," \u2014 "),EX=n(eRe,"A",{href:!0});var T1t=s(EX);vzo=r(T1t,"BertForNextSentencePrediction"),T1t.forEach(t),Fzo=r(eRe," (BERT model)"),eRe.forEach(t),Tzo=i(fa),r1=n(fa,"LI",{});var oRe=s(r1);cpe=n(oRe,"STRONG",{});var M1t=s(cpe);Mzo=r(M1t,"fnet"),M1t.forEach(t),Ezo=r(oRe," \u2014 "),CX=n(oRe,"A",{href:!0});var E1t=s(CX);Czo=r(E1t,"FNetForNextSentencePrediction"),E1t.forEach(t),wzo=r(oRe," (FNet model)"),oRe.forEach(t),Azo=i(fa),t1=n(fa,"LI",{});var rRe=s(t1);mpe=n(rRe,"STRONG",{});var C1t=s(mpe);Lzo=r(C1t,"megatron-bert"),C1t.forEach(t),yzo=r(rRe," \u2014 "),wX=n(rRe,"A",{href:!0});var w1t=s(wX);xzo=r(w1t,"MegatronBertForNextSentencePrediction"),w1t.forEach(t),$zo=r(rRe," (Megatron-BERT model)"),rRe.forEach(t),kzo=i(fa),a1=n(fa,"LI",{});var tRe=s(a1);fpe=n(tRe,"STRONG",{});var A1t=s(fpe);Szo=r(A1t,"mobilebert"),A1t.forEach(t),Rzo=r(tRe," \u2014 "),AX=n(tRe,"A",{href:!0});var L1t=s(AX);Pzo=r(L1t,"MobileBertForNextSentencePrediction"),L1t.forEach(t),Bzo=r(tRe," (MobileBERT model)"),tRe.forEach(t),Izo=i(fa),n1=n(fa,"LI",{});var aRe=s(n1);gpe=n(aRe,"STRONG",{});var y1t=s(gpe);Nzo=r(y1t,"nezha"),y1t.forEach(t),qzo=r(aRe," \u2014 "),LX=n(aRe,"A",{href:!0});var x1t=s(LX);jzo=r(x1t,"NezhaForNextSentencePrediction"),x1t.forEach(t),Dzo=r(aRe," (Nezha model)"),aRe.forEach(t),Gzo=i(fa),s1=n(fa,"LI",{});var nRe=s(s1);hpe=n(nRe,"STRONG",{});var $1t=s(hpe);Ozo=r($1t,"qdqbert"),$1t.forEach(t),Vzo=r(nRe," \u2014 "),yX=n(nRe,"A",{href:!0});var k1t=s(yX);Xzo=r(k1t,"QDQBertForNextSentencePrediction"),k1t.forEach(t),zzo=r(nRe," (QDQBert model)"),nRe.forEach(t),fa.forEach(t),Qzo=i(ma),l1=n(ma,"P",{});var sRe=s(l1);Wzo=r(sRe,"The model is set in evaluation mode by default using "),upe=n(sRe,"CODE",{});var S1t=s(upe);Hzo=r(S1t,"model.eval()"),S1t.forEach(t),Uzo=r(sRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ppe=n(sRe,"CODE",{});var R1t=s(ppe);Jzo=r(R1t,"model.train()"),R1t.forEach(t),sRe.forEach(t),Yzo=i(ma),T(i1.$$.fragment,ma),ma.forEach(t),al.forEach(t),hOe=i(m),nd=n(m,"H2",{class:!0});var FXe=s(nd);d1=n(FXe,"A",{id:!0,class:!0,href:!0});var P1t=s(d1);_pe=n(P1t,"SPAN",{});var B1t=s(_pe);T(G7.$$.fragment,B1t),B1t.forEach(t),P1t.forEach(t),Kzo=i(FXe),bpe=n(FXe,"SPAN",{});var I1t=s(bpe);Zzo=r(I1t,"AutoModelForTokenClassification"),I1t.forEach(t),FXe.forEach(t),uOe=i(m),qo=n(m,"DIV",{class:!0});var nl=s(qo);T(O7.$$.fragment,nl),eQo=i(nl),sd=n(nl,"P",{});var Boe=s(sd);oQo=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=n(Boe,"A",{href:!0});var N1t=s(xX);rQo=r(N1t,"from_pretrained()"),N1t.forEach(t),tQo=r(Boe," class method or the "),$X=n(Boe,"A",{href:!0});var q1t=s($X);aQo=r(q1t,"from_config()"),q1t.forEach(t),nQo=r(Boe,` class
method.`),Boe.forEach(t),sQo=i(nl),V7=n(nl,"P",{});var TXe=s(V7);lQo=r(TXe,"This class cannot be instantiated directly using "),vpe=n(TXe,"CODE",{});var j1t=s(vpe);iQo=r(j1t,"__init__()"),j1t.forEach(t),dQo=r(TXe," (throws an error)."),TXe.forEach(t),cQo=i(nl),gt=n(nl,"DIV",{class:!0});var W6=s(gt);T(X7.$$.fragment,W6),mQo=i(W6),Fpe=n(W6,"P",{});var D1t=s(Fpe);fQo=r(D1t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),D1t.forEach(t),gQo=i(W6),ld=n(W6,"P",{});var Ioe=s(ld);hQo=r(Ioe,`Note:
Loading a model from its configuration file does `),Tpe=n(Ioe,"STRONG",{});var G1t=s(Tpe);uQo=r(G1t,"not"),G1t.forEach(t),pQo=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(Ioe,"A",{href:!0});var O1t=s(kX);_Qo=r(O1t,"from_pretrained()"),O1t.forEach(t),bQo=r(Ioe," to load the model weights."),Ioe.forEach(t),vQo=i(W6),T(c1.$$.fragment,W6),W6.forEach(t),FQo=i(nl),ao=n(nl,"DIV",{class:!0});var ga=s(ao);T(z7.$$.fragment,ga),TQo=i(ga),Mpe=n(ga,"P",{});var V1t=s(Mpe);MQo=r(V1t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),V1t.forEach(t),EQo=i(ga),Ga=n(ga,"P",{});var H6=s(Ga);CQo=r(H6,"The model class to instantiate is selected based on the "),Epe=n(H6,"CODE",{});var X1t=s(Epe);wQo=r(X1t,"model_type"),X1t.forEach(t),AQo=r(H6,` property of the config object (either
passed as an argument or loaded from `),Cpe=n(H6,"CODE",{});var z1t=s(Cpe);LQo=r(z1t,"pretrained_model_name_or_path"),z1t.forEach(t),yQo=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wpe=n(H6,"CODE",{});var Q1t=s(wpe);xQo=r(Q1t,"pretrained_model_name_or_path"),Q1t.forEach(t),$Qo=r(H6,":"),H6.forEach(t),kQo=i(ga),H=n(ga,"UL",{});var J=s(H);m1=n(J,"LI",{});var lRe=s(m1);Ape=n(lRe,"STRONG",{});var W1t=s(Ape);SQo=r(W1t,"albert"),W1t.forEach(t),RQo=r(lRe," \u2014 "),SX=n(lRe,"A",{href:!0});var H1t=s(SX);PQo=r(H1t,"AlbertForTokenClassification"),H1t.forEach(t),BQo=r(lRe," (ALBERT model)"),lRe.forEach(t),IQo=i(J),f1=n(J,"LI",{});var iRe=s(f1);Lpe=n(iRe,"STRONG",{});var U1t=s(Lpe);NQo=r(U1t,"bert"),U1t.forEach(t),qQo=r(iRe," \u2014 "),RX=n(iRe,"A",{href:!0});var J1t=s(RX);jQo=r(J1t,"BertForTokenClassification"),J1t.forEach(t),DQo=r(iRe," (BERT model)"),iRe.forEach(t),GQo=i(J),g1=n(J,"LI",{});var dRe=s(g1);ype=n(dRe,"STRONG",{});var Y1t=s(ype);OQo=r(Y1t,"big_bird"),Y1t.forEach(t),VQo=r(dRe," \u2014 "),PX=n(dRe,"A",{href:!0});var K1t=s(PX);XQo=r(K1t,"BigBirdForTokenClassification"),K1t.forEach(t),zQo=r(dRe," (BigBird model)"),dRe.forEach(t),QQo=i(J),h1=n(J,"LI",{});var cRe=s(h1);xpe=n(cRe,"STRONG",{});var Z1t=s(xpe);WQo=r(Z1t,"bloom"),Z1t.forEach(t),HQo=r(cRe," \u2014 "),BX=n(cRe,"A",{href:!0});var eTt=s(BX);UQo=r(eTt,"BloomForTokenClassification"),eTt.forEach(t),JQo=r(cRe," (BLOOM model)"),cRe.forEach(t),YQo=i(J),u1=n(J,"LI",{});var mRe=s(u1);$pe=n(mRe,"STRONG",{});var oTt=s($pe);KQo=r(oTt,"camembert"),oTt.forEach(t),ZQo=r(mRe," \u2014 "),IX=n(mRe,"A",{href:!0});var rTt=s(IX);eWo=r(rTt,"CamembertForTokenClassification"),rTt.forEach(t),oWo=r(mRe," (CamemBERT model)"),mRe.forEach(t),rWo=i(J),p1=n(J,"LI",{});var fRe=s(p1);kpe=n(fRe,"STRONG",{});var tTt=s(kpe);tWo=r(tTt,"canine"),tTt.forEach(t),aWo=r(fRe," \u2014 "),NX=n(fRe,"A",{href:!0});var aTt=s(NX);nWo=r(aTt,"CanineForTokenClassification"),aTt.forEach(t),sWo=r(fRe," (CANINE model)"),fRe.forEach(t),lWo=i(J),_1=n(J,"LI",{});var gRe=s(_1);Spe=n(gRe,"STRONG",{});var nTt=s(Spe);iWo=r(nTt,"convbert"),nTt.forEach(t),dWo=r(gRe," \u2014 "),qX=n(gRe,"A",{href:!0});var sTt=s(qX);cWo=r(sTt,"ConvBertForTokenClassification"),sTt.forEach(t),mWo=r(gRe," (ConvBERT model)"),gRe.forEach(t),fWo=i(J),b1=n(J,"LI",{});var hRe=s(b1);Rpe=n(hRe,"STRONG",{});var lTt=s(Rpe);gWo=r(lTt,"data2vec-text"),lTt.forEach(t),hWo=r(hRe," \u2014 "),jX=n(hRe,"A",{href:!0});var iTt=s(jX);uWo=r(iTt,"Data2VecTextForTokenClassification"),iTt.forEach(t),pWo=r(hRe," (Data2VecText model)"),hRe.forEach(t),_Wo=i(J),v1=n(J,"LI",{});var uRe=s(v1);Ppe=n(uRe,"STRONG",{});var dTt=s(Ppe);bWo=r(dTt,"deberta"),dTt.forEach(t),vWo=r(uRe," \u2014 "),DX=n(uRe,"A",{href:!0});var cTt=s(DX);FWo=r(cTt,"DebertaForTokenClassification"),cTt.forEach(t),TWo=r(uRe," (DeBERTa model)"),uRe.forEach(t),MWo=i(J),F1=n(J,"LI",{});var pRe=s(F1);Bpe=n(pRe,"STRONG",{});var mTt=s(Bpe);EWo=r(mTt,"deberta-v2"),mTt.forEach(t),CWo=r(pRe," \u2014 "),GX=n(pRe,"A",{href:!0});var fTt=s(GX);wWo=r(fTt,"DebertaV2ForTokenClassification"),fTt.forEach(t),AWo=r(pRe," (DeBERTa-v2 model)"),pRe.forEach(t),LWo=i(J),T1=n(J,"LI",{});var _Re=s(T1);Ipe=n(_Re,"STRONG",{});var gTt=s(Ipe);yWo=r(gTt,"distilbert"),gTt.forEach(t),xWo=r(_Re," \u2014 "),OX=n(_Re,"A",{href:!0});var hTt=s(OX);$Wo=r(hTt,"DistilBertForTokenClassification"),hTt.forEach(t),kWo=r(_Re," (DistilBERT model)"),_Re.forEach(t),SWo=i(J),M1=n(J,"LI",{});var bRe=s(M1);Npe=n(bRe,"STRONG",{});var uTt=s(Npe);RWo=r(uTt,"electra"),uTt.forEach(t),PWo=r(bRe," \u2014 "),VX=n(bRe,"A",{href:!0});var pTt=s(VX);BWo=r(pTt,"ElectraForTokenClassification"),pTt.forEach(t),IWo=r(bRe," (ELECTRA model)"),bRe.forEach(t),NWo=i(J),E1=n(J,"LI",{});var vRe=s(E1);qpe=n(vRe,"STRONG",{});var _Tt=s(qpe);qWo=r(_Tt,"flaubert"),_Tt.forEach(t),jWo=r(vRe," \u2014 "),XX=n(vRe,"A",{href:!0});var bTt=s(XX);DWo=r(bTt,"FlaubertForTokenClassification"),bTt.forEach(t),GWo=r(vRe," (FlauBERT model)"),vRe.forEach(t),OWo=i(J),C1=n(J,"LI",{});var FRe=s(C1);jpe=n(FRe,"STRONG",{});var vTt=s(jpe);VWo=r(vTt,"fnet"),vTt.forEach(t),XWo=r(FRe," \u2014 "),zX=n(FRe,"A",{href:!0});var FTt=s(zX);zWo=r(FTt,"FNetForTokenClassification"),FTt.forEach(t),QWo=r(FRe," (FNet model)"),FRe.forEach(t),WWo=i(J),w1=n(J,"LI",{});var TRe=s(w1);Dpe=n(TRe,"STRONG",{});var TTt=s(Dpe);HWo=r(TTt,"funnel"),TTt.forEach(t),UWo=r(TRe," \u2014 "),QX=n(TRe,"A",{href:!0});var MTt=s(QX);JWo=r(MTt,"FunnelForTokenClassification"),MTt.forEach(t),YWo=r(TRe," (Funnel Transformer model)"),TRe.forEach(t),KWo=i(J),A1=n(J,"LI",{});var MRe=s(A1);Gpe=n(MRe,"STRONG",{});var ETt=s(Gpe);ZWo=r(ETt,"gpt2"),ETt.forEach(t),eHo=r(MRe," \u2014 "),WX=n(MRe,"A",{href:!0});var CTt=s(WX);oHo=r(CTt,"GPT2ForTokenClassification"),CTt.forEach(t),rHo=r(MRe," (OpenAI GPT-2 model)"),MRe.forEach(t),tHo=i(J),L1=n(J,"LI",{});var ERe=s(L1);Ope=n(ERe,"STRONG",{});var wTt=s(Ope);aHo=r(wTt,"ibert"),wTt.forEach(t),nHo=r(ERe," \u2014 "),HX=n(ERe,"A",{href:!0});var ATt=s(HX);sHo=r(ATt,"IBertForTokenClassification"),ATt.forEach(t),lHo=r(ERe," (I-BERT model)"),ERe.forEach(t),iHo=i(J),y1=n(J,"LI",{});var CRe=s(y1);Vpe=n(CRe,"STRONG",{});var LTt=s(Vpe);dHo=r(LTt,"layoutlm"),LTt.forEach(t),cHo=r(CRe," \u2014 "),UX=n(CRe,"A",{href:!0});var yTt=s(UX);mHo=r(yTt,"LayoutLMForTokenClassification"),yTt.forEach(t),fHo=r(CRe," (LayoutLM model)"),CRe.forEach(t),gHo=i(J),x1=n(J,"LI",{});var wRe=s(x1);Xpe=n(wRe,"STRONG",{});var xTt=s(Xpe);hHo=r(xTt,"layoutlmv2"),xTt.forEach(t),uHo=r(wRe," \u2014 "),JX=n(wRe,"A",{href:!0});var $Tt=s(JX);pHo=r($Tt,"LayoutLMv2ForTokenClassification"),$Tt.forEach(t),_Ho=r(wRe," (LayoutLMv2 model)"),wRe.forEach(t),bHo=i(J),$1=n(J,"LI",{});var ARe=s($1);zpe=n(ARe,"STRONG",{});var kTt=s(zpe);vHo=r(kTt,"layoutlmv3"),kTt.forEach(t),FHo=r(ARe," \u2014 "),YX=n(ARe,"A",{href:!0});var STt=s(YX);THo=r(STt,"LayoutLMv3ForTokenClassification"),STt.forEach(t),MHo=r(ARe," (LayoutLMv3 model)"),ARe.forEach(t),EHo=i(J),k1=n(J,"LI",{});var LRe=s(k1);Qpe=n(LRe,"STRONG",{});var RTt=s(Qpe);CHo=r(RTt,"longformer"),RTt.forEach(t),wHo=r(LRe," \u2014 "),KX=n(LRe,"A",{href:!0});var PTt=s(KX);AHo=r(PTt,"LongformerForTokenClassification"),PTt.forEach(t),LHo=r(LRe," (Longformer model)"),LRe.forEach(t),yHo=i(J),S1=n(J,"LI",{});var yRe=s(S1);Wpe=n(yRe,"STRONG",{});var BTt=s(Wpe);xHo=r(BTt,"megatron-bert"),BTt.forEach(t),$Ho=r(yRe," \u2014 "),ZX=n(yRe,"A",{href:!0});var ITt=s(ZX);kHo=r(ITt,"MegatronBertForTokenClassification"),ITt.forEach(t),SHo=r(yRe," (Megatron-BERT model)"),yRe.forEach(t),RHo=i(J),R1=n(J,"LI",{});var xRe=s(R1);Hpe=n(xRe,"STRONG",{});var NTt=s(Hpe);PHo=r(NTt,"mobilebert"),NTt.forEach(t),BHo=r(xRe," \u2014 "),ez=n(xRe,"A",{href:!0});var qTt=s(ez);IHo=r(qTt,"MobileBertForTokenClassification"),qTt.forEach(t),NHo=r(xRe," (MobileBERT model)"),xRe.forEach(t),qHo=i(J),P1=n(J,"LI",{});var $Re=s(P1);Upe=n($Re,"STRONG",{});var jTt=s(Upe);jHo=r(jTt,"mpnet"),jTt.forEach(t),DHo=r($Re," \u2014 "),oz=n($Re,"A",{href:!0});var DTt=s(oz);GHo=r(DTt,"MPNetForTokenClassification"),DTt.forEach(t),OHo=r($Re," (MPNet model)"),$Re.forEach(t),VHo=i(J),B1=n(J,"LI",{});var kRe=s(B1);Jpe=n(kRe,"STRONG",{});var GTt=s(Jpe);XHo=r(GTt,"nezha"),GTt.forEach(t),zHo=r(kRe," \u2014 "),rz=n(kRe,"A",{href:!0});var OTt=s(rz);QHo=r(OTt,"NezhaForTokenClassification"),OTt.forEach(t),WHo=r(kRe," (Nezha model)"),kRe.forEach(t),HHo=i(J),I1=n(J,"LI",{});var SRe=s(I1);Ype=n(SRe,"STRONG",{});var VTt=s(Ype);UHo=r(VTt,"nystromformer"),VTt.forEach(t),JHo=r(SRe," \u2014 "),tz=n(SRe,"A",{href:!0});var XTt=s(tz);YHo=r(XTt,"NystromformerForTokenClassification"),XTt.forEach(t),KHo=r(SRe," (Nystr\xF6mformer model)"),SRe.forEach(t),ZHo=i(J),N1=n(J,"LI",{});var RRe=s(N1);Kpe=n(RRe,"STRONG",{});var zTt=s(Kpe);eUo=r(zTt,"qdqbert"),zTt.forEach(t),oUo=r(RRe," \u2014 "),az=n(RRe,"A",{href:!0});var QTt=s(az);rUo=r(QTt,"QDQBertForTokenClassification"),QTt.forEach(t),tUo=r(RRe," (QDQBert model)"),RRe.forEach(t),aUo=i(J),q1=n(J,"LI",{});var PRe=s(q1);Zpe=n(PRe,"STRONG",{});var WTt=s(Zpe);nUo=r(WTt,"rembert"),WTt.forEach(t),sUo=r(PRe," \u2014 "),nz=n(PRe,"A",{href:!0});var HTt=s(nz);lUo=r(HTt,"RemBertForTokenClassification"),HTt.forEach(t),iUo=r(PRe," (RemBERT model)"),PRe.forEach(t),dUo=i(J),j1=n(J,"LI",{});var BRe=s(j1);e_e=n(BRe,"STRONG",{});var UTt=s(e_e);cUo=r(UTt,"roberta"),UTt.forEach(t),mUo=r(BRe," \u2014 "),sz=n(BRe,"A",{href:!0});var JTt=s(sz);fUo=r(JTt,"RobertaForTokenClassification"),JTt.forEach(t),gUo=r(BRe," (RoBERTa model)"),BRe.forEach(t),hUo=i(J),D1=n(J,"LI",{});var IRe=s(D1);o_e=n(IRe,"STRONG",{});var YTt=s(o_e);uUo=r(YTt,"roformer"),YTt.forEach(t),pUo=r(IRe," \u2014 "),lz=n(IRe,"A",{href:!0});var KTt=s(lz);_Uo=r(KTt,"RoFormerForTokenClassification"),KTt.forEach(t),bUo=r(IRe," (RoFormer model)"),IRe.forEach(t),vUo=i(J),G1=n(J,"LI",{});var NRe=s(G1);r_e=n(NRe,"STRONG",{});var ZTt=s(r_e);FUo=r(ZTt,"squeezebert"),ZTt.forEach(t),TUo=r(NRe," \u2014 "),iz=n(NRe,"A",{href:!0});var eMt=s(iz);MUo=r(eMt,"SqueezeBertForTokenClassification"),eMt.forEach(t),EUo=r(NRe," (SqueezeBERT model)"),NRe.forEach(t),CUo=i(J),O1=n(J,"LI",{});var qRe=s(O1);t_e=n(qRe,"STRONG",{});var oMt=s(t_e);wUo=r(oMt,"xlm"),oMt.forEach(t),AUo=r(qRe," \u2014 "),dz=n(qRe,"A",{href:!0});var rMt=s(dz);LUo=r(rMt,"XLMForTokenClassification"),rMt.forEach(t),yUo=r(qRe," (XLM model)"),qRe.forEach(t),xUo=i(J),V1=n(J,"LI",{});var jRe=s(V1);a_e=n(jRe,"STRONG",{});var tMt=s(a_e);$Uo=r(tMt,"xlm-roberta"),tMt.forEach(t),kUo=r(jRe," \u2014 "),cz=n(jRe,"A",{href:!0});var aMt=s(cz);SUo=r(aMt,"XLMRobertaForTokenClassification"),aMt.forEach(t),RUo=r(jRe," (XLM-RoBERTa model)"),jRe.forEach(t),PUo=i(J),X1=n(J,"LI",{});var DRe=s(X1);n_e=n(DRe,"STRONG",{});var nMt=s(n_e);BUo=r(nMt,"xlm-roberta-xl"),nMt.forEach(t),IUo=r(DRe," \u2014 "),mz=n(DRe,"A",{href:!0});var sMt=s(mz);NUo=r(sMt,"XLMRobertaXLForTokenClassification"),sMt.forEach(t),qUo=r(DRe," (XLM-RoBERTa-XL model)"),DRe.forEach(t),jUo=i(J),z1=n(J,"LI",{});var GRe=s(z1);s_e=n(GRe,"STRONG",{});var lMt=s(s_e);DUo=r(lMt,"xlnet"),lMt.forEach(t),GUo=r(GRe," \u2014 "),fz=n(GRe,"A",{href:!0});var iMt=s(fz);OUo=r(iMt,"XLNetForTokenClassification"),iMt.forEach(t),VUo=r(GRe," (XLNet model)"),GRe.forEach(t),XUo=i(J),Q1=n(J,"LI",{});var ORe=s(Q1);l_e=n(ORe,"STRONG",{});var dMt=s(l_e);zUo=r(dMt,"yoso"),dMt.forEach(t),QUo=r(ORe," \u2014 "),gz=n(ORe,"A",{href:!0});var cMt=s(gz);WUo=r(cMt,"YosoForTokenClassification"),cMt.forEach(t),HUo=r(ORe," (YOSO model)"),ORe.forEach(t),J.forEach(t),UUo=i(ga),W1=n(ga,"P",{});var VRe=s(W1);JUo=r(VRe,"The model is set in evaluation mode by default using "),i_e=n(VRe,"CODE",{});var mMt=s(i_e);YUo=r(mMt,"model.eval()"),mMt.forEach(t),KUo=r(VRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d_e=n(VRe,"CODE",{});var fMt=s(d_e);ZUo=r(fMt,"model.train()"),fMt.forEach(t),VRe.forEach(t),eJo=i(ga),T(H1.$$.fragment,ga),ga.forEach(t),nl.forEach(t),pOe=i(m),id=n(m,"H2",{class:!0});var MXe=s(id);U1=n(MXe,"A",{id:!0,class:!0,href:!0});var gMt=s(U1);c_e=n(gMt,"SPAN",{});var hMt=s(c_e);T(Q7.$$.fragment,hMt),hMt.forEach(t),gMt.forEach(t),oJo=i(MXe),m_e=n(MXe,"SPAN",{});var uMt=s(m_e);rJo=r(uMt,"AutoModelForQuestionAnswering"),uMt.forEach(t),MXe.forEach(t),_Oe=i(m),jo=n(m,"DIV",{class:!0});var sl=s(jo);T(W7.$$.fragment,sl),tJo=i(sl),dd=n(sl,"P",{});var Noe=s(dd);aJo=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=n(Noe,"A",{href:!0});var pMt=s(hz);nJo=r(pMt,"from_pretrained()"),pMt.forEach(t),sJo=r(Noe," class method or the "),uz=n(Noe,"A",{href:!0});var _Mt=s(uz);lJo=r(_Mt,"from_config()"),_Mt.forEach(t),iJo=r(Noe,` class
method.`),Noe.forEach(t),dJo=i(sl),H7=n(sl,"P",{});var EXe=s(H7);cJo=r(EXe,"This class cannot be instantiated directly using "),f_e=n(EXe,"CODE",{});var bMt=s(f_e);mJo=r(bMt,"__init__()"),bMt.forEach(t),fJo=r(EXe," (throws an error)."),EXe.forEach(t),gJo=i(sl),ht=n(sl,"DIV",{class:!0});var U6=s(ht);T(U7.$$.fragment,U6),hJo=i(U6),g_e=n(U6,"P",{});var vMt=s(g_e);uJo=r(vMt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),vMt.forEach(t),pJo=i(U6),cd=n(U6,"P",{});var qoe=s(cd);_Jo=r(qoe,`Note:
Loading a model from its configuration file does `),h_e=n(qoe,"STRONG",{});var FMt=s(h_e);bJo=r(FMt,"not"),FMt.forEach(t),vJo=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),pz=n(qoe,"A",{href:!0});var TMt=s(pz);FJo=r(TMt,"from_pretrained()"),TMt.forEach(t),TJo=r(qoe," to load the model weights."),qoe.forEach(t),MJo=i(U6),T(J1.$$.fragment,U6),U6.forEach(t),EJo=i(sl),no=n(sl,"DIV",{class:!0});var ha=s(no);T(J7.$$.fragment,ha),CJo=i(ha),u_e=n(ha,"P",{});var MMt=s(u_e);wJo=r(MMt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),MMt.forEach(t),AJo=i(ha),Oa=n(ha,"P",{});var J6=s(Oa);LJo=r(J6,"The model class to instantiate is selected based on the "),p_e=n(J6,"CODE",{});var EMt=s(p_e);yJo=r(EMt,"model_type"),EMt.forEach(t),xJo=r(J6,` property of the config object (either
passed as an argument or loaded from `),__e=n(J6,"CODE",{});var CMt=s(__e);$Jo=r(CMt,"pretrained_model_name_or_path"),CMt.forEach(t),kJo=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=n(J6,"CODE",{});var wMt=s(b_e);SJo=r(wMt,"pretrained_model_name_or_path"),wMt.forEach(t),RJo=r(J6,":"),J6.forEach(t),PJo=i(ha),V=n(ha,"UL",{});var X=s(V);Y1=n(X,"LI",{});var XRe=s(Y1);v_e=n(XRe,"STRONG",{});var AMt=s(v_e);BJo=r(AMt,"albert"),AMt.forEach(t),IJo=r(XRe," \u2014 "),_z=n(XRe,"A",{href:!0});var LMt=s(_z);NJo=r(LMt,"AlbertForQuestionAnswering"),LMt.forEach(t),qJo=r(XRe," (ALBERT model)"),XRe.forEach(t),jJo=i(X),K1=n(X,"LI",{});var zRe=s(K1);F_e=n(zRe,"STRONG",{});var yMt=s(F_e);DJo=r(yMt,"bart"),yMt.forEach(t),GJo=r(zRe," \u2014 "),bz=n(zRe,"A",{href:!0});var xMt=s(bz);OJo=r(xMt,"BartForQuestionAnswering"),xMt.forEach(t),VJo=r(zRe," (BART model)"),zRe.forEach(t),XJo=i(X),Z1=n(X,"LI",{});var QRe=s(Z1);T_e=n(QRe,"STRONG",{});var $Mt=s(T_e);zJo=r($Mt,"bert"),$Mt.forEach(t),QJo=r(QRe," \u2014 "),vz=n(QRe,"A",{href:!0});var kMt=s(vz);WJo=r(kMt,"BertForQuestionAnswering"),kMt.forEach(t),HJo=r(QRe," (BERT model)"),QRe.forEach(t),UJo=i(X),eT=n(X,"LI",{});var WRe=s(eT);M_e=n(WRe,"STRONG",{});var SMt=s(M_e);JJo=r(SMt,"big_bird"),SMt.forEach(t),YJo=r(WRe," \u2014 "),Fz=n(WRe,"A",{href:!0});var RMt=s(Fz);KJo=r(RMt,"BigBirdForQuestionAnswering"),RMt.forEach(t),ZJo=r(WRe," (BigBird model)"),WRe.forEach(t),eYo=i(X),oT=n(X,"LI",{});var HRe=s(oT);E_e=n(HRe,"STRONG",{});var PMt=s(E_e);oYo=r(PMt,"bigbird_pegasus"),PMt.forEach(t),rYo=r(HRe," \u2014 "),Tz=n(HRe,"A",{href:!0});var BMt=s(Tz);tYo=r(BMt,"BigBirdPegasusForQuestionAnswering"),BMt.forEach(t),aYo=r(HRe," (BigBird-Pegasus model)"),HRe.forEach(t),nYo=i(X),rT=n(X,"LI",{});var URe=s(rT);C_e=n(URe,"STRONG",{});var IMt=s(C_e);sYo=r(IMt,"camembert"),IMt.forEach(t),lYo=r(URe," \u2014 "),Mz=n(URe,"A",{href:!0});var NMt=s(Mz);iYo=r(NMt,"CamembertForQuestionAnswering"),NMt.forEach(t),dYo=r(URe," (CamemBERT model)"),URe.forEach(t),cYo=i(X),tT=n(X,"LI",{});var JRe=s(tT);w_e=n(JRe,"STRONG",{});var qMt=s(w_e);mYo=r(qMt,"canine"),qMt.forEach(t),fYo=r(JRe," \u2014 "),Ez=n(JRe,"A",{href:!0});var jMt=s(Ez);gYo=r(jMt,"CanineForQuestionAnswering"),jMt.forEach(t),hYo=r(JRe," (CANINE model)"),JRe.forEach(t),uYo=i(X),aT=n(X,"LI",{});var YRe=s(aT);A_e=n(YRe,"STRONG",{});var DMt=s(A_e);pYo=r(DMt,"convbert"),DMt.forEach(t),_Yo=r(YRe," \u2014 "),Cz=n(YRe,"A",{href:!0});var GMt=s(Cz);bYo=r(GMt,"ConvBertForQuestionAnswering"),GMt.forEach(t),vYo=r(YRe," (ConvBERT model)"),YRe.forEach(t),FYo=i(X),nT=n(X,"LI",{});var KRe=s(nT);L_e=n(KRe,"STRONG",{});var OMt=s(L_e);TYo=r(OMt,"data2vec-text"),OMt.forEach(t),MYo=r(KRe," \u2014 "),wz=n(KRe,"A",{href:!0});var VMt=s(wz);EYo=r(VMt,"Data2VecTextForQuestionAnswering"),VMt.forEach(t),CYo=r(KRe," (Data2VecText model)"),KRe.forEach(t),wYo=i(X),sT=n(X,"LI",{});var ZRe=s(sT);y_e=n(ZRe,"STRONG",{});var XMt=s(y_e);AYo=r(XMt,"deberta"),XMt.forEach(t),LYo=r(ZRe," \u2014 "),Az=n(ZRe,"A",{href:!0});var zMt=s(Az);yYo=r(zMt,"DebertaForQuestionAnswering"),zMt.forEach(t),xYo=r(ZRe," (DeBERTa model)"),ZRe.forEach(t),$Yo=i(X),lT=n(X,"LI",{});var ePe=s(lT);x_e=n(ePe,"STRONG",{});var QMt=s(x_e);kYo=r(QMt,"deberta-v2"),QMt.forEach(t),SYo=r(ePe," \u2014 "),Lz=n(ePe,"A",{href:!0});var WMt=s(Lz);RYo=r(WMt,"DebertaV2ForQuestionAnswering"),WMt.forEach(t),PYo=r(ePe," (DeBERTa-v2 model)"),ePe.forEach(t),BYo=i(X),iT=n(X,"LI",{});var oPe=s(iT);$_e=n(oPe,"STRONG",{});var HMt=s($_e);IYo=r(HMt,"distilbert"),HMt.forEach(t),NYo=r(oPe," \u2014 "),yz=n(oPe,"A",{href:!0});var UMt=s(yz);qYo=r(UMt,"DistilBertForQuestionAnswering"),UMt.forEach(t),jYo=r(oPe," (DistilBERT model)"),oPe.forEach(t),DYo=i(X),dT=n(X,"LI",{});var rPe=s(dT);k_e=n(rPe,"STRONG",{});var JMt=s(k_e);GYo=r(JMt,"electra"),JMt.forEach(t),OYo=r(rPe," \u2014 "),xz=n(rPe,"A",{href:!0});var YMt=s(xz);VYo=r(YMt,"ElectraForQuestionAnswering"),YMt.forEach(t),XYo=r(rPe," (ELECTRA model)"),rPe.forEach(t),zYo=i(X),cT=n(X,"LI",{});var tPe=s(cT);S_e=n(tPe,"STRONG",{});var KMt=s(S_e);QYo=r(KMt,"flaubert"),KMt.forEach(t),WYo=r(tPe," \u2014 "),$z=n(tPe,"A",{href:!0});var ZMt=s($z);HYo=r(ZMt,"FlaubertForQuestionAnsweringSimple"),ZMt.forEach(t),UYo=r(tPe," (FlauBERT model)"),tPe.forEach(t),JYo=i(X),mT=n(X,"LI",{});var aPe=s(mT);R_e=n(aPe,"STRONG",{});var eEt=s(R_e);YYo=r(eEt,"fnet"),eEt.forEach(t),KYo=r(aPe," \u2014 "),kz=n(aPe,"A",{href:!0});var oEt=s(kz);ZYo=r(oEt,"FNetForQuestionAnswering"),oEt.forEach(t),eKo=r(aPe," (FNet model)"),aPe.forEach(t),oKo=i(X),fT=n(X,"LI",{});var nPe=s(fT);P_e=n(nPe,"STRONG",{});var rEt=s(P_e);rKo=r(rEt,"funnel"),rEt.forEach(t),tKo=r(nPe," \u2014 "),Sz=n(nPe,"A",{href:!0});var tEt=s(Sz);aKo=r(tEt,"FunnelForQuestionAnswering"),tEt.forEach(t),nKo=r(nPe," (Funnel Transformer model)"),nPe.forEach(t),sKo=i(X),gT=n(X,"LI",{});var sPe=s(gT);B_e=n(sPe,"STRONG",{});var aEt=s(B_e);lKo=r(aEt,"gptj"),aEt.forEach(t),iKo=r(sPe," \u2014 "),Rz=n(sPe,"A",{href:!0});var nEt=s(Rz);dKo=r(nEt,"GPTJForQuestionAnswering"),nEt.forEach(t),cKo=r(sPe," (GPT-J model)"),sPe.forEach(t),mKo=i(X),hT=n(X,"LI",{});var lPe=s(hT);I_e=n(lPe,"STRONG",{});var sEt=s(I_e);fKo=r(sEt,"ibert"),sEt.forEach(t),gKo=r(lPe," \u2014 "),Pz=n(lPe,"A",{href:!0});var lEt=s(Pz);hKo=r(lEt,"IBertForQuestionAnswering"),lEt.forEach(t),uKo=r(lPe," (I-BERT model)"),lPe.forEach(t),pKo=i(X),uT=n(X,"LI",{});var iPe=s(uT);N_e=n(iPe,"STRONG",{});var iEt=s(N_e);_Ko=r(iEt,"layoutlmv2"),iEt.forEach(t),bKo=r(iPe," \u2014 "),Bz=n(iPe,"A",{href:!0});var dEt=s(Bz);vKo=r(dEt,"LayoutLMv2ForQuestionAnswering"),dEt.forEach(t),FKo=r(iPe," (LayoutLMv2 model)"),iPe.forEach(t),TKo=i(X),pT=n(X,"LI",{});var dPe=s(pT);q_e=n(dPe,"STRONG",{});var cEt=s(q_e);MKo=r(cEt,"layoutlmv3"),cEt.forEach(t),EKo=r(dPe," \u2014 "),Iz=n(dPe,"A",{href:!0});var mEt=s(Iz);CKo=r(mEt,"LayoutLMv3ForQuestionAnswering"),mEt.forEach(t),wKo=r(dPe," (LayoutLMv3 model)"),dPe.forEach(t),AKo=i(X),_T=n(X,"LI",{});var cPe=s(_T);j_e=n(cPe,"STRONG",{});var fEt=s(j_e);LKo=r(fEt,"led"),fEt.forEach(t),yKo=r(cPe," \u2014 "),Nz=n(cPe,"A",{href:!0});var gEt=s(Nz);xKo=r(gEt,"LEDForQuestionAnswering"),gEt.forEach(t),$Ko=r(cPe," (LED model)"),cPe.forEach(t),kKo=i(X),bT=n(X,"LI",{});var mPe=s(bT);D_e=n(mPe,"STRONG",{});var hEt=s(D_e);SKo=r(hEt,"longformer"),hEt.forEach(t),RKo=r(mPe," \u2014 "),qz=n(mPe,"A",{href:!0});var uEt=s(qz);PKo=r(uEt,"LongformerForQuestionAnswering"),uEt.forEach(t),BKo=r(mPe," (Longformer model)"),mPe.forEach(t),IKo=i(X),vT=n(X,"LI",{});var fPe=s(vT);G_e=n(fPe,"STRONG",{});var pEt=s(G_e);NKo=r(pEt,"lxmert"),pEt.forEach(t),qKo=r(fPe," \u2014 "),jz=n(fPe,"A",{href:!0});var _Et=s(jz);jKo=r(_Et,"LxmertForQuestionAnswering"),_Et.forEach(t),DKo=r(fPe," (LXMERT model)"),fPe.forEach(t),GKo=i(X),FT=n(X,"LI",{});var gPe=s(FT);O_e=n(gPe,"STRONG",{});var bEt=s(O_e);OKo=r(bEt,"mbart"),bEt.forEach(t),VKo=r(gPe," \u2014 "),Dz=n(gPe,"A",{href:!0});var vEt=s(Dz);XKo=r(vEt,"MBartForQuestionAnswering"),vEt.forEach(t),zKo=r(gPe," (mBART model)"),gPe.forEach(t),QKo=i(X),TT=n(X,"LI",{});var hPe=s(TT);V_e=n(hPe,"STRONG",{});var FEt=s(V_e);WKo=r(FEt,"megatron-bert"),FEt.forEach(t),HKo=r(hPe," \u2014 "),Gz=n(hPe,"A",{href:!0});var TEt=s(Gz);UKo=r(TEt,"MegatronBertForQuestionAnswering"),TEt.forEach(t),JKo=r(hPe," (Megatron-BERT model)"),hPe.forEach(t),YKo=i(X),MT=n(X,"LI",{});var uPe=s(MT);X_e=n(uPe,"STRONG",{});var MEt=s(X_e);KKo=r(MEt,"mobilebert"),MEt.forEach(t),ZKo=r(uPe," \u2014 "),Oz=n(uPe,"A",{href:!0});var EEt=s(Oz);eZo=r(EEt,"MobileBertForQuestionAnswering"),EEt.forEach(t),oZo=r(uPe," (MobileBERT model)"),uPe.forEach(t),rZo=i(X),ET=n(X,"LI",{});var pPe=s(ET);z_e=n(pPe,"STRONG",{});var CEt=s(z_e);tZo=r(CEt,"mpnet"),CEt.forEach(t),aZo=r(pPe," \u2014 "),Vz=n(pPe,"A",{href:!0});var wEt=s(Vz);nZo=r(wEt,"MPNetForQuestionAnswering"),wEt.forEach(t),sZo=r(pPe," (MPNet model)"),pPe.forEach(t),lZo=i(X),CT=n(X,"LI",{});var _Pe=s(CT);Q_e=n(_Pe,"STRONG",{});var AEt=s(Q_e);iZo=r(AEt,"nezha"),AEt.forEach(t),dZo=r(_Pe," \u2014 "),Xz=n(_Pe,"A",{href:!0});var LEt=s(Xz);cZo=r(LEt,"NezhaForQuestionAnswering"),LEt.forEach(t),mZo=r(_Pe," (Nezha model)"),_Pe.forEach(t),fZo=i(X),wT=n(X,"LI",{});var bPe=s(wT);W_e=n(bPe,"STRONG",{});var yEt=s(W_e);gZo=r(yEt,"nystromformer"),yEt.forEach(t),hZo=r(bPe," \u2014 "),zz=n(bPe,"A",{href:!0});var xEt=s(zz);uZo=r(xEt,"NystromformerForQuestionAnswering"),xEt.forEach(t),pZo=r(bPe," (Nystr\xF6mformer model)"),bPe.forEach(t),_Zo=i(X),AT=n(X,"LI",{});var vPe=s(AT);H_e=n(vPe,"STRONG",{});var $Et=s(H_e);bZo=r($Et,"qdqbert"),$Et.forEach(t),vZo=r(vPe," \u2014 "),Qz=n(vPe,"A",{href:!0});var kEt=s(Qz);FZo=r(kEt,"QDQBertForQuestionAnswering"),kEt.forEach(t),TZo=r(vPe," (QDQBert model)"),vPe.forEach(t),MZo=i(X),LT=n(X,"LI",{});var FPe=s(LT);U_e=n(FPe,"STRONG",{});var SEt=s(U_e);EZo=r(SEt,"reformer"),SEt.forEach(t),CZo=r(FPe," \u2014 "),Wz=n(FPe,"A",{href:!0});var REt=s(Wz);wZo=r(REt,"ReformerForQuestionAnswering"),REt.forEach(t),AZo=r(FPe," (Reformer model)"),FPe.forEach(t),LZo=i(X),yT=n(X,"LI",{});var TPe=s(yT);J_e=n(TPe,"STRONG",{});var PEt=s(J_e);yZo=r(PEt,"rembert"),PEt.forEach(t),xZo=r(TPe," \u2014 "),Hz=n(TPe,"A",{href:!0});var BEt=s(Hz);$Zo=r(BEt,"RemBertForQuestionAnswering"),BEt.forEach(t),kZo=r(TPe," (RemBERT model)"),TPe.forEach(t),SZo=i(X),xT=n(X,"LI",{});var MPe=s(xT);Y_e=n(MPe,"STRONG",{});var IEt=s(Y_e);RZo=r(IEt,"roberta"),IEt.forEach(t),PZo=r(MPe," \u2014 "),Uz=n(MPe,"A",{href:!0});var NEt=s(Uz);BZo=r(NEt,"RobertaForQuestionAnswering"),NEt.forEach(t),IZo=r(MPe," (RoBERTa model)"),MPe.forEach(t),NZo=i(X),$T=n(X,"LI",{});var EPe=s($T);K_e=n(EPe,"STRONG",{});var qEt=s(K_e);qZo=r(qEt,"roformer"),qEt.forEach(t),jZo=r(EPe," \u2014 "),Jz=n(EPe,"A",{href:!0});var jEt=s(Jz);DZo=r(jEt,"RoFormerForQuestionAnswering"),jEt.forEach(t),GZo=r(EPe," (RoFormer model)"),EPe.forEach(t),OZo=i(X),kT=n(X,"LI",{});var CPe=s(kT);Z_e=n(CPe,"STRONG",{});var DEt=s(Z_e);VZo=r(DEt,"splinter"),DEt.forEach(t),XZo=r(CPe," \u2014 "),Yz=n(CPe,"A",{href:!0});var GEt=s(Yz);zZo=r(GEt,"SplinterForQuestionAnswering"),GEt.forEach(t),QZo=r(CPe," (Splinter model)"),CPe.forEach(t),WZo=i(X),ST=n(X,"LI",{});var wPe=s(ST);e2e=n(wPe,"STRONG",{});var OEt=s(e2e);HZo=r(OEt,"squeezebert"),OEt.forEach(t),UZo=r(wPe," \u2014 "),Kz=n(wPe,"A",{href:!0});var VEt=s(Kz);JZo=r(VEt,"SqueezeBertForQuestionAnswering"),VEt.forEach(t),YZo=r(wPe," (SqueezeBERT model)"),wPe.forEach(t),KZo=i(X),RT=n(X,"LI",{});var APe=s(RT);o2e=n(APe,"STRONG",{});var XEt=s(o2e);ZZo=r(XEt,"xlm"),XEt.forEach(t),eer=r(APe," \u2014 "),Zz=n(APe,"A",{href:!0});var zEt=s(Zz);oer=r(zEt,"XLMForQuestionAnsweringSimple"),zEt.forEach(t),rer=r(APe," (XLM model)"),APe.forEach(t),ter=i(X),PT=n(X,"LI",{});var LPe=s(PT);r2e=n(LPe,"STRONG",{});var QEt=s(r2e);aer=r(QEt,"xlm-roberta"),QEt.forEach(t),ner=r(LPe," \u2014 "),eQ=n(LPe,"A",{href:!0});var WEt=s(eQ);ser=r(WEt,"XLMRobertaForQuestionAnswering"),WEt.forEach(t),ler=r(LPe," (XLM-RoBERTa model)"),LPe.forEach(t),ier=i(X),BT=n(X,"LI",{});var yPe=s(BT);t2e=n(yPe,"STRONG",{});var HEt=s(t2e);der=r(HEt,"xlm-roberta-xl"),HEt.forEach(t),cer=r(yPe," \u2014 "),oQ=n(yPe,"A",{href:!0});var UEt=s(oQ);mer=r(UEt,"XLMRobertaXLForQuestionAnswering"),UEt.forEach(t),fer=r(yPe," (XLM-RoBERTa-XL model)"),yPe.forEach(t),ger=i(X),IT=n(X,"LI",{});var xPe=s(IT);a2e=n(xPe,"STRONG",{});var JEt=s(a2e);her=r(JEt,"xlnet"),JEt.forEach(t),uer=r(xPe," \u2014 "),rQ=n(xPe,"A",{href:!0});var YEt=s(rQ);per=r(YEt,"XLNetForQuestionAnsweringSimple"),YEt.forEach(t),_er=r(xPe," (XLNet model)"),xPe.forEach(t),ber=i(X),NT=n(X,"LI",{});var $Pe=s(NT);n2e=n($Pe,"STRONG",{});var KEt=s(n2e);ver=r(KEt,"yoso"),KEt.forEach(t),Fer=r($Pe," \u2014 "),tQ=n($Pe,"A",{href:!0});var ZEt=s(tQ);Ter=r(ZEt,"YosoForQuestionAnswering"),ZEt.forEach(t),Mer=r($Pe," (YOSO model)"),$Pe.forEach(t),X.forEach(t),Eer=i(ha),qT=n(ha,"P",{});var kPe=s(qT);Cer=r(kPe,"The model is set in evaluation mode by default using "),s2e=n(kPe,"CODE",{});var e4t=s(s2e);wer=r(e4t,"model.eval()"),e4t.forEach(t),Aer=r(kPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l2e=n(kPe,"CODE",{});var o4t=s(l2e);Ler=r(o4t,"model.train()"),o4t.forEach(t),kPe.forEach(t),yer=i(ha),T(jT.$$.fragment,ha),ha.forEach(t),sl.forEach(t),bOe=i(m),md=n(m,"H2",{class:!0});var CXe=s(md);DT=n(CXe,"A",{id:!0,class:!0,href:!0});var r4t=s(DT);i2e=n(r4t,"SPAN",{});var t4t=s(i2e);T(Y7.$$.fragment,t4t),t4t.forEach(t),r4t.forEach(t),xer=i(CXe),d2e=n(CXe,"SPAN",{});var a4t=s(d2e);$er=r(a4t,"AutoModelForTableQuestionAnswering"),a4t.forEach(t),CXe.forEach(t),vOe=i(m),Do=n(m,"DIV",{class:!0});var ll=s(Do);T(K7.$$.fragment,ll),ker=i(ll),fd=n(ll,"P",{});var joe=s(fd);Ser=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=n(joe,"A",{href:!0});var n4t=s(aQ);Rer=r(n4t,"from_pretrained()"),n4t.forEach(t),Per=r(joe," class method or the "),nQ=n(joe,"A",{href:!0});var s4t=s(nQ);Ber=r(s4t,"from_config()"),s4t.forEach(t),Ier=r(joe,` class
method.`),joe.forEach(t),Ner=i(ll),Z7=n(ll,"P",{});var wXe=s(Z7);qer=r(wXe,"This class cannot be instantiated directly using "),c2e=n(wXe,"CODE",{});var l4t=s(c2e);jer=r(l4t,"__init__()"),l4t.forEach(t),Der=r(wXe," (throws an error)."),wXe.forEach(t),Ger=i(ll),ut=n(ll,"DIV",{class:!0});var Y6=s(ut);T(e8.$$.fragment,Y6),Oer=i(Y6),m2e=n(Y6,"P",{});var i4t=s(m2e);Ver=r(i4t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),i4t.forEach(t),Xer=i(Y6),gd=n(Y6,"P",{});var Doe=s(gd);zer=r(Doe,`Note:
Loading a model from its configuration file does `),f2e=n(Doe,"STRONG",{});var d4t=s(f2e);Qer=r(d4t,"not"),d4t.forEach(t),Wer=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=n(Doe,"A",{href:!0});var c4t=s(sQ);Her=r(c4t,"from_pretrained()"),c4t.forEach(t),Uer=r(Doe," to load the model weights."),Doe.forEach(t),Jer=i(Y6),T(GT.$$.fragment,Y6),Y6.forEach(t),Yer=i(ll),so=n(ll,"DIV",{class:!0});var ua=s(so);T(o8.$$.fragment,ua),Ker=i(ua),g2e=n(ua,"P",{});var m4t=s(g2e);Zer=r(m4t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),m4t.forEach(t),eor=i(ua),Va=n(ua,"P",{});var K6=s(Va);oor=r(K6,"The model class to instantiate is selected based on the "),h2e=n(K6,"CODE",{});var f4t=s(h2e);ror=r(f4t,"model_type"),f4t.forEach(t),tor=r(K6,` property of the config object (either
passed as an argument or loaded from `),u2e=n(K6,"CODE",{});var g4t=s(u2e);aor=r(g4t,"pretrained_model_name_or_path"),g4t.forEach(t),nor=r(K6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=n(K6,"CODE",{});var h4t=s(p2e);sor=r(h4t,"pretrained_model_name_or_path"),h4t.forEach(t),lor=r(K6,":"),K6.forEach(t),ior=i(ua),_2e=n(ua,"UL",{});var u4t=s(_2e);OT=n(u4t,"LI",{});var SPe=s(OT);b2e=n(SPe,"STRONG",{});var p4t=s(b2e);dor=r(p4t,"tapas"),p4t.forEach(t),cor=r(SPe," \u2014 "),lQ=n(SPe,"A",{href:!0});var _4t=s(lQ);mor=r(_4t,"TapasForQuestionAnswering"),_4t.forEach(t),gor=r(SPe," (TAPAS model)"),SPe.forEach(t),u4t.forEach(t),hor=i(ua),VT=n(ua,"P",{});var RPe=s(VT);uor=r(RPe,"The model is set in evaluation mode by default using "),v2e=n(RPe,"CODE",{});var b4t=s(v2e);por=r(b4t,"model.eval()"),b4t.forEach(t),_or=r(RPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F2e=n(RPe,"CODE",{});var v4t=s(F2e);bor=r(v4t,"model.train()"),v4t.forEach(t),RPe.forEach(t),vor=i(ua),T(XT.$$.fragment,ua),ua.forEach(t),ll.forEach(t),FOe=i(m),hd=n(m,"H2",{class:!0});var AXe=s(hd);zT=n(AXe,"A",{id:!0,class:!0,href:!0});var F4t=s(zT);T2e=n(F4t,"SPAN",{});var T4t=s(T2e);T(r8.$$.fragment,T4t),T4t.forEach(t),F4t.forEach(t),For=i(AXe),M2e=n(AXe,"SPAN",{});var M4t=s(M2e);Tor=r(M4t,"AutoModelForImageClassification"),M4t.forEach(t),AXe.forEach(t),TOe=i(m),Go=n(m,"DIV",{class:!0});var il=s(Go);T(t8.$$.fragment,il),Mor=i(il),ud=n(il,"P",{});var Goe=s(ud);Eor=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=n(Goe,"A",{href:!0});var E4t=s(iQ);Cor=r(E4t,"from_pretrained()"),E4t.forEach(t),wor=r(Goe," class method or the "),dQ=n(Goe,"A",{href:!0});var C4t=s(dQ);Aor=r(C4t,"from_config()"),C4t.forEach(t),Lor=r(Goe,` class
method.`),Goe.forEach(t),yor=i(il),a8=n(il,"P",{});var LXe=s(a8);xor=r(LXe,"This class cannot be instantiated directly using "),E2e=n(LXe,"CODE",{});var w4t=s(E2e);$or=r(w4t,"__init__()"),w4t.forEach(t),kor=r(LXe," (throws an error)."),LXe.forEach(t),Sor=i(il),pt=n(il,"DIV",{class:!0});var Z6=s(pt);T(n8.$$.fragment,Z6),Ror=i(Z6),C2e=n(Z6,"P",{});var A4t=s(C2e);Por=r(A4t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),A4t.forEach(t),Bor=i(Z6),pd=n(Z6,"P",{});var Ooe=s(pd);Ior=r(Ooe,`Note:
Loading a model from its configuration file does `),w2e=n(Ooe,"STRONG",{});var L4t=s(w2e);Nor=r(L4t,"not"),L4t.forEach(t),qor=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Ooe,"A",{href:!0});var y4t=s(cQ);jor=r(y4t,"from_pretrained()"),y4t.forEach(t),Dor=r(Ooe," to load the model weights."),Ooe.forEach(t),Gor=i(Z6),T(QT.$$.fragment,Z6),Z6.forEach(t),Oor=i(il),lo=n(il,"DIV",{class:!0});var pa=s(lo);T(s8.$$.fragment,pa),Vor=i(pa),A2e=n(pa,"P",{});var x4t=s(A2e);Xor=r(x4t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),x4t.forEach(t),zor=i(pa),Xa=n(pa,"P",{});var eL=s(Xa);Qor=r(eL,"The model class to instantiate is selected based on the "),L2e=n(eL,"CODE",{});var $4t=s(L2e);Wor=r($4t,"model_type"),$4t.forEach(t),Hor=r(eL,` property of the config object (either
passed as an argument or loaded from `),y2e=n(eL,"CODE",{});var k4t=s(y2e);Uor=r(k4t,"pretrained_model_name_or_path"),k4t.forEach(t),Jor=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x2e=n(eL,"CODE",{});var S4t=s(x2e);Yor=r(S4t,"pretrained_model_name_or_path"),S4t.forEach(t),Kor=r(eL,":"),eL.forEach(t),Zor=i(pa),Fe=n(pa,"UL",{});var Te=s(Fe);WT=n(Te,"LI",{});var PPe=s(WT);$2e=n(PPe,"STRONG",{});var R4t=s($2e);err=r(R4t,"beit"),R4t.forEach(t),orr=r(PPe," \u2014 "),mQ=n(PPe,"A",{href:!0});var P4t=s(mQ);rrr=r(P4t,"BeitForImageClassification"),P4t.forEach(t),trr=r(PPe," (BEiT model)"),PPe.forEach(t),arr=i(Te),HT=n(Te,"LI",{});var BPe=s(HT);k2e=n(BPe,"STRONG",{});var B4t=s(k2e);nrr=r(B4t,"convnext"),B4t.forEach(t),srr=r(BPe," \u2014 "),fQ=n(BPe,"A",{href:!0});var I4t=s(fQ);lrr=r(I4t,"ConvNextForImageClassification"),I4t.forEach(t),irr=r(BPe," (ConvNeXT model)"),BPe.forEach(t),drr=i(Te),UT=n(Te,"LI",{});var IPe=s(UT);S2e=n(IPe,"STRONG",{});var N4t=s(S2e);crr=r(N4t,"cvt"),N4t.forEach(t),mrr=r(IPe," \u2014 "),gQ=n(IPe,"A",{href:!0});var q4t=s(gQ);frr=r(q4t,"CvtForImageClassification"),q4t.forEach(t),grr=r(IPe," (CvT model)"),IPe.forEach(t),hrr=i(Te),JT=n(Te,"LI",{});var NPe=s(JT);R2e=n(NPe,"STRONG",{});var j4t=s(R2e);urr=r(j4t,"data2vec-vision"),j4t.forEach(t),prr=r(NPe," \u2014 "),hQ=n(NPe,"A",{href:!0});var D4t=s(hQ);_rr=r(D4t,"Data2VecVisionForImageClassification"),D4t.forEach(t),brr=r(NPe," (Data2VecVision model)"),NPe.forEach(t),vrr=i(Te),Xs=n(Te,"LI",{});var Zk=s(Xs);P2e=n(Zk,"STRONG",{});var G4t=s(P2e);Frr=r(G4t,"deit"),G4t.forEach(t),Trr=r(Zk," \u2014 "),uQ=n(Zk,"A",{href:!0});var O4t=s(uQ);Mrr=r(O4t,"DeiTForImageClassification"),O4t.forEach(t),Err=r(Zk," or "),pQ=n(Zk,"A",{href:!0});var V4t=s(pQ);Crr=r(V4t,"DeiTForImageClassificationWithTeacher"),V4t.forEach(t),wrr=r(Zk," (DeiT model)"),Zk.forEach(t),Arr=i(Te),YT=n(Te,"LI",{});var qPe=s(YT);B2e=n(qPe,"STRONG",{});var X4t=s(B2e);Lrr=r(X4t,"imagegpt"),X4t.forEach(t),yrr=r(qPe," \u2014 "),_Q=n(qPe,"A",{href:!0});var z4t=s(_Q);xrr=r(z4t,"ImageGPTForImageClassification"),z4t.forEach(t),$rr=r(qPe," (ImageGPT model)"),qPe.forEach(t),krr=i(Te),zs=n(Te,"LI",{});var eS=s(zs);I2e=n(eS,"STRONG",{});var Q4t=s(I2e);Srr=r(Q4t,"levit"),Q4t.forEach(t),Rrr=r(eS," \u2014 "),bQ=n(eS,"A",{href:!0});var W4t=s(bQ);Prr=r(W4t,"LevitForImageClassification"),W4t.forEach(t),Brr=r(eS," or "),vQ=n(eS,"A",{href:!0});var H4t=s(vQ);Irr=r(H4t,"LevitForImageClassificationWithTeacher"),H4t.forEach(t),Nrr=r(eS," (LeViT model)"),eS.forEach(t),qrr=i(Te),_t=n(Te,"LI",{});var Am=s(_t);N2e=n(Am,"STRONG",{});var U4t=s(N2e);jrr=r(U4t,"perceiver"),U4t.forEach(t),Drr=r(Am," \u2014 "),FQ=n(Am,"A",{href:!0});var J4t=s(FQ);Grr=r(J4t,"PerceiverForImageClassificationLearned"),J4t.forEach(t),Orr=r(Am," or "),TQ=n(Am,"A",{href:!0});var Y4t=s(TQ);Vrr=r(Y4t,"PerceiverForImageClassificationFourier"),Y4t.forEach(t),Xrr=r(Am," or "),MQ=n(Am,"A",{href:!0});var K4t=s(MQ);zrr=r(K4t,"PerceiverForImageClassificationConvProcessing"),K4t.forEach(t),Qrr=r(Am," (Perceiver model)"),Am.forEach(t),Wrr=i(Te),KT=n(Te,"LI",{});var jPe=s(KT);q2e=n(jPe,"STRONG",{});var Z4t=s(q2e);Hrr=r(Z4t,"poolformer"),Z4t.forEach(t),Urr=r(jPe," \u2014 "),EQ=n(jPe,"A",{href:!0});var eCt=s(EQ);Jrr=r(eCt,"PoolFormerForImageClassification"),eCt.forEach(t),Yrr=r(jPe," (PoolFormer model)"),jPe.forEach(t),Krr=i(Te),ZT=n(Te,"LI",{});var DPe=s(ZT);j2e=n(DPe,"STRONG",{});var oCt=s(j2e);Zrr=r(oCt,"regnet"),oCt.forEach(t),etr=r(DPe," \u2014 "),CQ=n(DPe,"A",{href:!0});var rCt=s(CQ);otr=r(rCt,"RegNetForImageClassification"),rCt.forEach(t),rtr=r(DPe," (RegNet model)"),DPe.forEach(t),ttr=i(Te),eM=n(Te,"LI",{});var GPe=s(eM);D2e=n(GPe,"STRONG",{});var tCt=s(D2e);atr=r(tCt,"resnet"),tCt.forEach(t),ntr=r(GPe," \u2014 "),wQ=n(GPe,"A",{href:!0});var aCt=s(wQ);str=r(aCt,"ResNetForImageClassification"),aCt.forEach(t),ltr=r(GPe," (ResNet model)"),GPe.forEach(t),itr=i(Te),oM=n(Te,"LI",{});var OPe=s(oM);G2e=n(OPe,"STRONG",{});var nCt=s(G2e);dtr=r(nCt,"segformer"),nCt.forEach(t),ctr=r(OPe," \u2014 "),AQ=n(OPe,"A",{href:!0});var sCt=s(AQ);mtr=r(sCt,"SegformerForImageClassification"),sCt.forEach(t),ftr=r(OPe," (SegFormer model)"),OPe.forEach(t),gtr=i(Te),rM=n(Te,"LI",{});var VPe=s(rM);O2e=n(VPe,"STRONG",{});var lCt=s(O2e);htr=r(lCt,"swin"),lCt.forEach(t),utr=r(VPe," \u2014 "),LQ=n(VPe,"A",{href:!0});var iCt=s(LQ);ptr=r(iCt,"SwinForImageClassification"),iCt.forEach(t),_tr=r(VPe," (Swin Transformer model)"),VPe.forEach(t),btr=i(Te),tM=n(Te,"LI",{});var XPe=s(tM);V2e=n(XPe,"STRONG",{});var dCt=s(V2e);vtr=r(dCt,"van"),dCt.forEach(t),Ftr=r(XPe," \u2014 "),yQ=n(XPe,"A",{href:!0});var cCt=s(yQ);Ttr=r(cCt,"VanForImageClassification"),cCt.forEach(t),Mtr=r(XPe," (VAN model)"),XPe.forEach(t),Etr=i(Te),aM=n(Te,"LI",{});var zPe=s(aM);X2e=n(zPe,"STRONG",{});var mCt=s(X2e);Ctr=r(mCt,"vit"),mCt.forEach(t),wtr=r(zPe," \u2014 "),xQ=n(zPe,"A",{href:!0});var fCt=s(xQ);Atr=r(fCt,"ViTForImageClassification"),fCt.forEach(t),Ltr=r(zPe," (ViT model)"),zPe.forEach(t),Te.forEach(t),ytr=i(pa),nM=n(pa,"P",{});var QPe=s(nM);xtr=r(QPe,"The model is set in evaluation mode by default using "),z2e=n(QPe,"CODE",{});var gCt=s(z2e);$tr=r(gCt,"model.eval()"),gCt.forEach(t),ktr=r(QPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q2e=n(QPe,"CODE",{});var hCt=s(Q2e);Str=r(hCt,"model.train()"),hCt.forEach(t),QPe.forEach(t),Rtr=i(pa),T(sM.$$.fragment,pa),pa.forEach(t),il.forEach(t),MOe=i(m),_d=n(m,"H2",{class:!0});var yXe=s(_d);lM=n(yXe,"A",{id:!0,class:!0,href:!0});var uCt=s(lM);W2e=n(uCt,"SPAN",{});var pCt=s(W2e);T(l8.$$.fragment,pCt),pCt.forEach(t),uCt.forEach(t),Ptr=i(yXe),H2e=n(yXe,"SPAN",{});var _Ct=s(H2e);Btr=r(_Ct,"AutoModelForVision2Seq"),_Ct.forEach(t),yXe.forEach(t),EOe=i(m),Oo=n(m,"DIV",{class:!0});var dl=s(Oo);T(i8.$$.fragment,dl),Itr=i(dl),bd=n(dl,"P",{});var Voe=s(bd);Ntr=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=n(Voe,"A",{href:!0});var bCt=s($Q);qtr=r(bCt,"from_pretrained()"),bCt.forEach(t),jtr=r(Voe," class method or the "),kQ=n(Voe,"A",{href:!0});var vCt=s(kQ);Dtr=r(vCt,"from_config()"),vCt.forEach(t),Gtr=r(Voe,` class
method.`),Voe.forEach(t),Otr=i(dl),d8=n(dl,"P",{});var xXe=s(d8);Vtr=r(xXe,"This class cannot be instantiated directly using "),U2e=n(xXe,"CODE",{});var FCt=s(U2e);Xtr=r(FCt,"__init__()"),FCt.forEach(t),ztr=r(xXe," (throws an error)."),xXe.forEach(t),Qtr=i(dl),bt=n(dl,"DIV",{class:!0});var oL=s(bt);T(c8.$$.fragment,oL),Wtr=i(oL),J2e=n(oL,"P",{});var TCt=s(J2e);Htr=r(TCt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),TCt.forEach(t),Utr=i(oL),vd=n(oL,"P",{});var Xoe=s(vd);Jtr=r(Xoe,`Note:
Loading a model from its configuration file does `),Y2e=n(Xoe,"STRONG",{});var MCt=s(Y2e);Ytr=r(MCt,"not"),MCt.forEach(t),Ktr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(Xoe,"A",{href:!0});var ECt=s(SQ);Ztr=r(ECt,"from_pretrained()"),ECt.forEach(t),ear=r(Xoe," to load the model weights."),Xoe.forEach(t),oar=i(oL),T(iM.$$.fragment,oL),oL.forEach(t),rar=i(dl),io=n(dl,"DIV",{class:!0});var _a=s(io);T(m8.$$.fragment,_a),tar=i(_a),K2e=n(_a,"P",{});var CCt=s(K2e);aar=r(CCt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CCt.forEach(t),nar=i(_a),za=n(_a,"P",{});var rL=s(za);sar=r(rL,"The model class to instantiate is selected based on the "),Z2e=n(rL,"CODE",{});var wCt=s(Z2e);lar=r(wCt,"model_type"),wCt.forEach(t),iar=r(rL,` property of the config object (either
passed as an argument or loaded from `),ebe=n(rL,"CODE",{});var ACt=s(ebe);dar=r(ACt,"pretrained_model_name_or_path"),ACt.forEach(t),car=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),obe=n(rL,"CODE",{});var LCt=s(obe);mar=r(LCt,"pretrained_model_name_or_path"),LCt.forEach(t),far=r(rL,":"),rL.forEach(t),gar=i(_a),rbe=n(_a,"UL",{});var yCt=s(rbe);dM=n(yCt,"LI",{});var WPe=s(dM);tbe=n(WPe,"STRONG",{});var xCt=s(tbe);har=r(xCt,"vision-encoder-decoder"),xCt.forEach(t),uar=r(WPe," \u2014 "),RQ=n(WPe,"A",{href:!0});var $Ct=s(RQ);par=r($Ct,"VisionEncoderDecoderModel"),$Ct.forEach(t),_ar=r(WPe," (Vision Encoder decoder model)"),WPe.forEach(t),yCt.forEach(t),bar=i(_a),cM=n(_a,"P",{});var HPe=s(cM);Far=r(HPe,"The model is set in evaluation mode by default using "),abe=n(HPe,"CODE",{});var kCt=s(abe);Tar=r(kCt,"model.eval()"),kCt.forEach(t),Mar=r(HPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nbe=n(HPe,"CODE",{});var SCt=s(nbe);Ear=r(SCt,"model.train()"),SCt.forEach(t),HPe.forEach(t),Car=i(_a),T(mM.$$.fragment,_a),_a.forEach(t),dl.forEach(t),COe=i(m),Fd=n(m,"H2",{class:!0});var $Xe=s(Fd);fM=n($Xe,"A",{id:!0,class:!0,href:!0});var RCt=s(fM);sbe=n(RCt,"SPAN",{});var PCt=s(sbe);T(f8.$$.fragment,PCt),PCt.forEach(t),RCt.forEach(t),war=i($Xe),lbe=n($Xe,"SPAN",{});var BCt=s(lbe);Aar=r(BCt,"AutoModelForVisualQuestionAnswering"),BCt.forEach(t),$Xe.forEach(t),wOe=i(m),Vo=n(m,"DIV",{class:!0});var cl=s(Vo);T(g8.$$.fragment,cl),Lar=i(cl),Td=n(cl,"P",{});var zoe=s(Td);yar=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=n(zoe,"A",{href:!0});var ICt=s(PQ);xar=r(ICt,"from_pretrained()"),ICt.forEach(t),$ar=r(zoe," class method or the "),BQ=n(zoe,"A",{href:!0});var NCt=s(BQ);kar=r(NCt,"from_config()"),NCt.forEach(t),Sar=r(zoe,` class
method.`),zoe.forEach(t),Rar=i(cl),h8=n(cl,"P",{});var kXe=s(h8);Par=r(kXe,"This class cannot be instantiated directly using "),ibe=n(kXe,"CODE",{});var qCt=s(ibe);Bar=r(qCt,"__init__()"),qCt.forEach(t),Iar=r(kXe," (throws an error)."),kXe.forEach(t),Nar=i(cl),vt=n(cl,"DIV",{class:!0});var tL=s(vt);T(u8.$$.fragment,tL),qar=i(tL),dbe=n(tL,"P",{});var jCt=s(dbe);jar=r(jCt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),jCt.forEach(t),Dar=i(tL),Md=n(tL,"P",{});var Qoe=s(Md);Gar=r(Qoe,`Note:
Loading a model from its configuration file does `),cbe=n(Qoe,"STRONG",{});var DCt=s(cbe);Oar=r(DCt,"not"),DCt.forEach(t),Var=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(Qoe,"A",{href:!0});var GCt=s(IQ);Xar=r(GCt,"from_pretrained()"),GCt.forEach(t),zar=r(Qoe," to load the model weights."),Qoe.forEach(t),Qar=i(tL),T(gM.$$.fragment,tL),tL.forEach(t),War=i(cl),co=n(cl,"DIV",{class:!0});var ba=s(co);T(p8.$$.fragment,ba),Har=i(ba),mbe=n(ba,"P",{});var OCt=s(mbe);Uar=r(OCt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),OCt.forEach(t),Jar=i(ba),Qa=n(ba,"P",{});var aL=s(Qa);Yar=r(aL,"The model class to instantiate is selected based on the "),fbe=n(aL,"CODE",{});var VCt=s(fbe);Kar=r(VCt,"model_type"),VCt.forEach(t),Zar=r(aL,` property of the config object (either
passed as an argument or loaded from `),gbe=n(aL,"CODE",{});var XCt=s(gbe);enr=r(XCt,"pretrained_model_name_or_path"),XCt.forEach(t),onr=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=n(aL,"CODE",{});var zCt=s(hbe);rnr=r(zCt,"pretrained_model_name_or_path"),zCt.forEach(t),tnr=r(aL,":"),aL.forEach(t),anr=i(ba),ube=n(ba,"UL",{});var QCt=s(ube);hM=n(QCt,"LI",{});var UPe=s(hM);pbe=n(UPe,"STRONG",{});var WCt=s(pbe);nnr=r(WCt,"vilt"),WCt.forEach(t),snr=r(UPe," \u2014 "),NQ=n(UPe,"A",{href:!0});var HCt=s(NQ);lnr=r(HCt,"ViltForQuestionAnswering"),HCt.forEach(t),inr=r(UPe," (ViLT model)"),UPe.forEach(t),QCt.forEach(t),dnr=i(ba),uM=n(ba,"P",{});var JPe=s(uM);cnr=r(JPe,"The model is set in evaluation mode by default using "),_be=n(JPe,"CODE",{});var UCt=s(_be);mnr=r(UCt,"model.eval()"),UCt.forEach(t),fnr=r(JPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bbe=n(JPe,"CODE",{});var JCt=s(bbe);gnr=r(JCt,"model.train()"),JCt.forEach(t),JPe.forEach(t),hnr=i(ba),T(pM.$$.fragment,ba),ba.forEach(t),cl.forEach(t),AOe=i(m),Ed=n(m,"H2",{class:!0});var SXe=s(Ed);_M=n(SXe,"A",{id:!0,class:!0,href:!0});var YCt=s(_M);vbe=n(YCt,"SPAN",{});var KCt=s(vbe);T(_8.$$.fragment,KCt),KCt.forEach(t),YCt.forEach(t),unr=i(SXe),Fbe=n(SXe,"SPAN",{});var ZCt=s(Fbe);pnr=r(ZCt,"AutoModelForAudioClassification"),ZCt.forEach(t),SXe.forEach(t),LOe=i(m),Xo=n(m,"DIV",{class:!0});var ml=s(Xo);T(b8.$$.fragment,ml),_nr=i(ml),Cd=n(ml,"P",{});var Woe=s(Cd);bnr=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=n(Woe,"A",{href:!0});var e5t=s(qQ);vnr=r(e5t,"from_pretrained()"),e5t.forEach(t),Fnr=r(Woe," class method or the "),jQ=n(Woe,"A",{href:!0});var o5t=s(jQ);Tnr=r(o5t,"from_config()"),o5t.forEach(t),Mnr=r(Woe,` class
method.`),Woe.forEach(t),Enr=i(ml),v8=n(ml,"P",{});var RXe=s(v8);Cnr=r(RXe,"This class cannot be instantiated directly using "),Tbe=n(RXe,"CODE",{});var r5t=s(Tbe);wnr=r(r5t,"__init__()"),r5t.forEach(t),Anr=r(RXe," (throws an error)."),RXe.forEach(t),Lnr=i(ml),Ft=n(ml,"DIV",{class:!0});var nL=s(Ft);T(F8.$$.fragment,nL),ynr=i(nL),Mbe=n(nL,"P",{});var t5t=s(Mbe);xnr=r(t5t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),t5t.forEach(t),$nr=i(nL),wd=n(nL,"P",{});var Hoe=s(wd);knr=r(Hoe,`Note:
Loading a model from its configuration file does `),Ebe=n(Hoe,"STRONG",{});var a5t=s(Ebe);Snr=r(a5t,"not"),a5t.forEach(t),Rnr=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Hoe,"A",{href:!0});var n5t=s(DQ);Pnr=r(n5t,"from_pretrained()"),n5t.forEach(t),Bnr=r(Hoe," to load the model weights."),Hoe.forEach(t),Inr=i(nL),T(bM.$$.fragment,nL),nL.forEach(t),Nnr=i(ml),mo=n(ml,"DIV",{class:!0});var va=s(mo);T(T8.$$.fragment,va),qnr=i(va),Cbe=n(va,"P",{});var s5t=s(Cbe);jnr=r(s5t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),s5t.forEach(t),Dnr=i(va),Wa=n(va,"P",{});var sL=s(Wa);Gnr=r(sL,"The model class to instantiate is selected based on the "),wbe=n(sL,"CODE",{});var l5t=s(wbe);Onr=r(l5t,"model_type"),l5t.forEach(t),Vnr=r(sL,` property of the config object (either
passed as an argument or loaded from `),Abe=n(sL,"CODE",{});var i5t=s(Abe);Xnr=r(i5t,"pretrained_model_name_or_path"),i5t.forEach(t),znr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lbe=n(sL,"CODE",{});var d5t=s(Lbe);Qnr=r(d5t,"pretrained_model_name_or_path"),d5t.forEach(t),Wnr=r(sL,":"),sL.forEach(t),Hnr=i(va),Pe=n(va,"UL",{});var ze=s(Pe);vM=n(ze,"LI",{});var YPe=s(vM);ybe=n(YPe,"STRONG",{});var c5t=s(ybe);Unr=r(c5t,"data2vec-audio"),c5t.forEach(t),Jnr=r(YPe," \u2014 "),GQ=n(YPe,"A",{href:!0});var m5t=s(GQ);Ynr=r(m5t,"Data2VecAudioForSequenceClassification"),m5t.forEach(t),Knr=r(YPe," (Data2VecAudio model)"),YPe.forEach(t),Znr=i(ze),FM=n(ze,"LI",{});var KPe=s(FM);xbe=n(KPe,"STRONG",{});var f5t=s(xbe);esr=r(f5t,"hubert"),f5t.forEach(t),osr=r(KPe," \u2014 "),OQ=n(KPe,"A",{href:!0});var g5t=s(OQ);rsr=r(g5t,"HubertForSequenceClassification"),g5t.forEach(t),tsr=r(KPe," (Hubert model)"),KPe.forEach(t),asr=i(ze),TM=n(ze,"LI",{});var ZPe=s(TM);$be=n(ZPe,"STRONG",{});var h5t=s($be);nsr=r(h5t,"sew"),h5t.forEach(t),ssr=r(ZPe," \u2014 "),VQ=n(ZPe,"A",{href:!0});var u5t=s(VQ);lsr=r(u5t,"SEWForSequenceClassification"),u5t.forEach(t),isr=r(ZPe," (SEW model)"),ZPe.forEach(t),dsr=i(ze),MM=n(ze,"LI",{});var eBe=s(MM);kbe=n(eBe,"STRONG",{});var p5t=s(kbe);csr=r(p5t,"sew-d"),p5t.forEach(t),msr=r(eBe," \u2014 "),XQ=n(eBe,"A",{href:!0});var _5t=s(XQ);fsr=r(_5t,"SEWDForSequenceClassification"),_5t.forEach(t),gsr=r(eBe," (SEW-D model)"),eBe.forEach(t),hsr=i(ze),EM=n(ze,"LI",{});var oBe=s(EM);Sbe=n(oBe,"STRONG",{});var b5t=s(Sbe);usr=r(b5t,"unispeech"),b5t.forEach(t),psr=r(oBe," \u2014 "),zQ=n(oBe,"A",{href:!0});var v5t=s(zQ);_sr=r(v5t,"UniSpeechForSequenceClassification"),v5t.forEach(t),bsr=r(oBe," (UniSpeech model)"),oBe.forEach(t),vsr=i(ze),CM=n(ze,"LI",{});var rBe=s(CM);Rbe=n(rBe,"STRONG",{});var F5t=s(Rbe);Fsr=r(F5t,"unispeech-sat"),F5t.forEach(t),Tsr=r(rBe," \u2014 "),QQ=n(rBe,"A",{href:!0});var T5t=s(QQ);Msr=r(T5t,"UniSpeechSatForSequenceClassification"),T5t.forEach(t),Esr=r(rBe," (UniSpeechSat model)"),rBe.forEach(t),Csr=i(ze),wM=n(ze,"LI",{});var tBe=s(wM);Pbe=n(tBe,"STRONG",{});var M5t=s(Pbe);wsr=r(M5t,"wav2vec2"),M5t.forEach(t),Asr=r(tBe," \u2014 "),WQ=n(tBe,"A",{href:!0});var E5t=s(WQ);Lsr=r(E5t,"Wav2Vec2ForSequenceClassification"),E5t.forEach(t),ysr=r(tBe," (Wav2Vec2 model)"),tBe.forEach(t),xsr=i(ze),AM=n(ze,"LI",{});var aBe=s(AM);Bbe=n(aBe,"STRONG",{});var C5t=s(Bbe);$sr=r(C5t,"wav2vec2-conformer"),C5t.forEach(t),ksr=r(aBe," \u2014 "),HQ=n(aBe,"A",{href:!0});var w5t=s(HQ);Ssr=r(w5t,"Wav2Vec2ConformerForSequenceClassification"),w5t.forEach(t),Rsr=r(aBe," (Wav2Vec2-Conformer model)"),aBe.forEach(t),Psr=i(ze),LM=n(ze,"LI",{});var nBe=s(LM);Ibe=n(nBe,"STRONG",{});var A5t=s(Ibe);Bsr=r(A5t,"wavlm"),A5t.forEach(t),Isr=r(nBe," \u2014 "),UQ=n(nBe,"A",{href:!0});var L5t=s(UQ);Nsr=r(L5t,"WavLMForSequenceClassification"),L5t.forEach(t),qsr=r(nBe," (WavLM model)"),nBe.forEach(t),ze.forEach(t),jsr=i(va),yM=n(va,"P",{});var sBe=s(yM);Dsr=r(sBe,"The model is set in evaluation mode by default using "),Nbe=n(sBe,"CODE",{});var y5t=s(Nbe);Gsr=r(y5t,"model.eval()"),y5t.forEach(t),Osr=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qbe=n(sBe,"CODE",{});var x5t=s(qbe);Vsr=r(x5t,"model.train()"),x5t.forEach(t),sBe.forEach(t),Xsr=i(va),T(xM.$$.fragment,va),va.forEach(t),ml.forEach(t),yOe=i(m),Ad=n(m,"H2",{class:!0});var PXe=s(Ad);$M=n(PXe,"A",{id:!0,class:!0,href:!0});var $5t=s($M);jbe=n($5t,"SPAN",{});var k5t=s(jbe);T(M8.$$.fragment,k5t),k5t.forEach(t),$5t.forEach(t),zsr=i(PXe),Dbe=n(PXe,"SPAN",{});var S5t=s(Dbe);Qsr=r(S5t,"AutoModelForAudioFrameClassification"),S5t.forEach(t),PXe.forEach(t),xOe=i(m),zo=n(m,"DIV",{class:!0});var fl=s(zo);T(E8.$$.fragment,fl),Wsr=i(fl),Ld=n(fl,"P",{});var Uoe=s(Ld);Hsr=r(Uoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=n(Uoe,"A",{href:!0});var R5t=s(JQ);Usr=r(R5t,"from_pretrained()"),R5t.forEach(t),Jsr=r(Uoe," class method or the "),YQ=n(Uoe,"A",{href:!0});var P5t=s(YQ);Ysr=r(P5t,"from_config()"),P5t.forEach(t),Ksr=r(Uoe,` class
method.`),Uoe.forEach(t),Zsr=i(fl),C8=n(fl,"P",{});var BXe=s(C8);elr=r(BXe,"This class cannot be instantiated directly using "),Gbe=n(BXe,"CODE",{});var B5t=s(Gbe);olr=r(B5t,"__init__()"),B5t.forEach(t),rlr=r(BXe," (throws an error)."),BXe.forEach(t),tlr=i(fl),Tt=n(fl,"DIV",{class:!0});var lL=s(Tt);T(w8.$$.fragment,lL),alr=i(lL),Obe=n(lL,"P",{});var I5t=s(Obe);nlr=r(I5t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),I5t.forEach(t),slr=i(lL),yd=n(lL,"P",{});var Joe=s(yd);llr=r(Joe,`Note:
Loading a model from its configuration file does `),Vbe=n(Joe,"STRONG",{});var N5t=s(Vbe);ilr=r(N5t,"not"),N5t.forEach(t),dlr=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=n(Joe,"A",{href:!0});var q5t=s(KQ);clr=r(q5t,"from_pretrained()"),q5t.forEach(t),mlr=r(Joe," to load the model weights."),Joe.forEach(t),flr=i(lL),T(kM.$$.fragment,lL),lL.forEach(t),glr=i(fl),fo=n(fl,"DIV",{class:!0});var Fa=s(fo);T(A8.$$.fragment,Fa),hlr=i(Fa),Xbe=n(Fa,"P",{});var j5t=s(Xbe);ulr=r(j5t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),j5t.forEach(t),plr=i(Fa),Ha=n(Fa,"P",{});var iL=s(Ha);_lr=r(iL,"The model class to instantiate is selected based on the "),zbe=n(iL,"CODE",{});var D5t=s(zbe);blr=r(D5t,"model_type"),D5t.forEach(t),vlr=r(iL,` property of the config object (either
passed as an argument or loaded from `),Qbe=n(iL,"CODE",{});var G5t=s(Qbe);Flr=r(G5t,"pretrained_model_name_or_path"),G5t.forEach(t),Tlr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wbe=n(iL,"CODE",{});var O5t=s(Wbe);Mlr=r(O5t,"pretrained_model_name_or_path"),O5t.forEach(t),Elr=r(iL,":"),iL.forEach(t),Clr=i(Fa),et=n(Fa,"UL",{});var gl=s(et);SM=n(gl,"LI",{});var lBe=s(SM);Hbe=n(lBe,"STRONG",{});var V5t=s(Hbe);wlr=r(V5t,"data2vec-audio"),V5t.forEach(t),Alr=r(lBe," \u2014 "),ZQ=n(lBe,"A",{href:!0});var X5t=s(ZQ);Llr=r(X5t,"Data2VecAudioForAudioFrameClassification"),X5t.forEach(t),ylr=r(lBe," (Data2VecAudio model)"),lBe.forEach(t),xlr=i(gl),RM=n(gl,"LI",{});var iBe=s(RM);Ube=n(iBe,"STRONG",{});var z5t=s(Ube);$lr=r(z5t,"unispeech-sat"),z5t.forEach(t),klr=r(iBe," \u2014 "),eW=n(iBe,"A",{href:!0});var Q5t=s(eW);Slr=r(Q5t,"UniSpeechSatForAudioFrameClassification"),Q5t.forEach(t),Rlr=r(iBe," (UniSpeechSat model)"),iBe.forEach(t),Plr=i(gl),PM=n(gl,"LI",{});var dBe=s(PM);Jbe=n(dBe,"STRONG",{});var W5t=s(Jbe);Blr=r(W5t,"wav2vec2"),W5t.forEach(t),Ilr=r(dBe," \u2014 "),oW=n(dBe,"A",{href:!0});var H5t=s(oW);Nlr=r(H5t,"Wav2Vec2ForAudioFrameClassification"),H5t.forEach(t),qlr=r(dBe," (Wav2Vec2 model)"),dBe.forEach(t),jlr=i(gl),BM=n(gl,"LI",{});var cBe=s(BM);Ybe=n(cBe,"STRONG",{});var U5t=s(Ybe);Dlr=r(U5t,"wav2vec2-conformer"),U5t.forEach(t),Glr=r(cBe," \u2014 "),rW=n(cBe,"A",{href:!0});var J5t=s(rW);Olr=r(J5t,"Wav2Vec2ConformerForAudioFrameClassification"),J5t.forEach(t),Vlr=r(cBe," (Wav2Vec2-Conformer model)"),cBe.forEach(t),Xlr=i(gl),IM=n(gl,"LI",{});var mBe=s(IM);Kbe=n(mBe,"STRONG",{});var Y5t=s(Kbe);zlr=r(Y5t,"wavlm"),Y5t.forEach(t),Qlr=r(mBe," \u2014 "),tW=n(mBe,"A",{href:!0});var K5t=s(tW);Wlr=r(K5t,"WavLMForAudioFrameClassification"),K5t.forEach(t),Hlr=r(mBe," (WavLM model)"),mBe.forEach(t),gl.forEach(t),Ulr=i(Fa),NM=n(Fa,"P",{});var fBe=s(NM);Jlr=r(fBe,"The model is set in evaluation mode by default using "),Zbe=n(fBe,"CODE",{});var Z5t=s(Zbe);Ylr=r(Z5t,"model.eval()"),Z5t.forEach(t),Klr=r(fBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eve=n(fBe,"CODE",{});var e3t=s(eve);Zlr=r(e3t,"model.train()"),e3t.forEach(t),fBe.forEach(t),eir=i(Fa),T(qM.$$.fragment,Fa),Fa.forEach(t),fl.forEach(t),$Oe=i(m),xd=n(m,"H2",{class:!0});var IXe=s(xd);jM=n(IXe,"A",{id:!0,class:!0,href:!0});var o3t=s(jM);ove=n(o3t,"SPAN",{});var r3t=s(ove);T(L8.$$.fragment,r3t),r3t.forEach(t),o3t.forEach(t),oir=i(IXe),rve=n(IXe,"SPAN",{});var t3t=s(rve);rir=r(t3t,"AutoModelForCTC"),t3t.forEach(t),IXe.forEach(t),kOe=i(m),Qo=n(m,"DIV",{class:!0});var hl=s(Qo);T(y8.$$.fragment,hl),tir=i(hl),$d=n(hl,"P",{});var Yoe=s($d);air=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=n(Yoe,"A",{href:!0});var a3t=s(aW);nir=r(a3t,"from_pretrained()"),a3t.forEach(t),sir=r(Yoe," class method or the "),nW=n(Yoe,"A",{href:!0});var n3t=s(nW);lir=r(n3t,"from_config()"),n3t.forEach(t),iir=r(Yoe,` class
method.`),Yoe.forEach(t),dir=i(hl),x8=n(hl,"P",{});var NXe=s(x8);cir=r(NXe,"This class cannot be instantiated directly using "),tve=n(NXe,"CODE",{});var s3t=s(tve);mir=r(s3t,"__init__()"),s3t.forEach(t),fir=r(NXe," (throws an error)."),NXe.forEach(t),gir=i(hl),Mt=n(hl,"DIV",{class:!0});var dL=s(Mt);T($8.$$.fragment,dL),hir=i(dL),ave=n(dL,"P",{});var l3t=s(ave);uir=r(l3t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),l3t.forEach(t),pir=i(dL),kd=n(dL,"P",{});var Koe=s(kd);_ir=r(Koe,`Note:
Loading a model from its configuration file does `),nve=n(Koe,"STRONG",{});var i3t=s(nve);bir=r(i3t,"not"),i3t.forEach(t),vir=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(Koe,"A",{href:!0});var d3t=s(sW);Fir=r(d3t,"from_pretrained()"),d3t.forEach(t),Tir=r(Koe," to load the model weights."),Koe.forEach(t),Mir=i(dL),T(DM.$$.fragment,dL),dL.forEach(t),Eir=i(hl),go=n(hl,"DIV",{class:!0});var Ta=s(go);T(k8.$$.fragment,Ta),Cir=i(Ta),sve=n(Ta,"P",{});var c3t=s(sve);wir=r(c3t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),c3t.forEach(t),Air=i(Ta),Ua=n(Ta,"P",{});var cL=s(Ua);Lir=r(cL,"The model class to instantiate is selected based on the "),lve=n(cL,"CODE",{});var m3t=s(lve);yir=r(m3t,"model_type"),m3t.forEach(t),xir=r(cL,` property of the config object (either
passed as an argument or loaded from `),ive=n(cL,"CODE",{});var f3t=s(ive);$ir=r(f3t,"pretrained_model_name_or_path"),f3t.forEach(t),kir=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dve=n(cL,"CODE",{});var g3t=s(dve);Sir=r(g3t,"pretrained_model_name_or_path"),g3t.forEach(t),Rir=r(cL,":"),cL.forEach(t),Pir=i(Ta),Le=n(Ta,"UL",{});var Be=s(Le);GM=n(Be,"LI",{});var gBe=s(GM);cve=n(gBe,"STRONG",{});var h3t=s(cve);Bir=r(h3t,"data2vec-audio"),h3t.forEach(t),Iir=r(gBe," \u2014 "),lW=n(gBe,"A",{href:!0});var u3t=s(lW);Nir=r(u3t,"Data2VecAudioForCTC"),u3t.forEach(t),qir=r(gBe," (Data2VecAudio model)"),gBe.forEach(t),jir=i(Be),OM=n(Be,"LI",{});var hBe=s(OM);mve=n(hBe,"STRONG",{});var p3t=s(mve);Dir=r(p3t,"hubert"),p3t.forEach(t),Gir=r(hBe," \u2014 "),iW=n(hBe,"A",{href:!0});var _3t=s(iW);Oir=r(_3t,"HubertForCTC"),_3t.forEach(t),Vir=r(hBe," (Hubert model)"),hBe.forEach(t),Xir=i(Be),VM=n(Be,"LI",{});var uBe=s(VM);fve=n(uBe,"STRONG",{});var b3t=s(fve);zir=r(b3t,"mctct"),b3t.forEach(t),Qir=r(uBe," \u2014 "),dW=n(uBe,"A",{href:!0});var v3t=s(dW);Wir=r(v3t,"MCTCTForCTC"),v3t.forEach(t),Hir=r(uBe," (M-CTC-T model)"),uBe.forEach(t),Uir=i(Be),XM=n(Be,"LI",{});var pBe=s(XM);gve=n(pBe,"STRONG",{});var F3t=s(gve);Jir=r(F3t,"sew"),F3t.forEach(t),Yir=r(pBe," \u2014 "),cW=n(pBe,"A",{href:!0});var T3t=s(cW);Kir=r(T3t,"SEWForCTC"),T3t.forEach(t),Zir=r(pBe," (SEW model)"),pBe.forEach(t),edr=i(Be),zM=n(Be,"LI",{});var _Be=s(zM);hve=n(_Be,"STRONG",{});var M3t=s(hve);odr=r(M3t,"sew-d"),M3t.forEach(t),rdr=r(_Be," \u2014 "),mW=n(_Be,"A",{href:!0});var E3t=s(mW);tdr=r(E3t,"SEWDForCTC"),E3t.forEach(t),adr=r(_Be," (SEW-D model)"),_Be.forEach(t),ndr=i(Be),QM=n(Be,"LI",{});var bBe=s(QM);uve=n(bBe,"STRONG",{});var C3t=s(uve);sdr=r(C3t,"unispeech"),C3t.forEach(t),ldr=r(bBe," \u2014 "),fW=n(bBe,"A",{href:!0});var w3t=s(fW);idr=r(w3t,"UniSpeechForCTC"),w3t.forEach(t),ddr=r(bBe," (UniSpeech model)"),bBe.forEach(t),cdr=i(Be),WM=n(Be,"LI",{});var vBe=s(WM);pve=n(vBe,"STRONG",{});var A3t=s(pve);mdr=r(A3t,"unispeech-sat"),A3t.forEach(t),fdr=r(vBe," \u2014 "),gW=n(vBe,"A",{href:!0});var L3t=s(gW);gdr=r(L3t,"UniSpeechSatForCTC"),L3t.forEach(t),hdr=r(vBe," (UniSpeechSat model)"),vBe.forEach(t),udr=i(Be),HM=n(Be,"LI",{});var FBe=s(HM);_ve=n(FBe,"STRONG",{});var y3t=s(_ve);pdr=r(y3t,"wav2vec2"),y3t.forEach(t),_dr=r(FBe," \u2014 "),hW=n(FBe,"A",{href:!0});var x3t=s(hW);bdr=r(x3t,"Wav2Vec2ForCTC"),x3t.forEach(t),vdr=r(FBe," (Wav2Vec2 model)"),FBe.forEach(t),Fdr=i(Be),UM=n(Be,"LI",{});var TBe=s(UM);bve=n(TBe,"STRONG",{});var $3t=s(bve);Tdr=r($3t,"wav2vec2-conformer"),$3t.forEach(t),Mdr=r(TBe," \u2014 "),uW=n(TBe,"A",{href:!0});var k3t=s(uW);Edr=r(k3t,"Wav2Vec2ConformerForCTC"),k3t.forEach(t),Cdr=r(TBe," (Wav2Vec2-Conformer model)"),TBe.forEach(t),wdr=i(Be),JM=n(Be,"LI",{});var MBe=s(JM);vve=n(MBe,"STRONG",{});var S3t=s(vve);Adr=r(S3t,"wavlm"),S3t.forEach(t),Ldr=r(MBe," \u2014 "),pW=n(MBe,"A",{href:!0});var R3t=s(pW);ydr=r(R3t,"WavLMForCTC"),R3t.forEach(t),xdr=r(MBe," (WavLM model)"),MBe.forEach(t),Be.forEach(t),$dr=i(Ta),YM=n(Ta,"P",{});var EBe=s(YM);kdr=r(EBe,"The model is set in evaluation mode by default using "),Fve=n(EBe,"CODE",{});var P3t=s(Fve);Sdr=r(P3t,"model.eval()"),P3t.forEach(t),Rdr=r(EBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tve=n(EBe,"CODE",{});var B3t=s(Tve);Pdr=r(B3t,"model.train()"),B3t.forEach(t),EBe.forEach(t),Bdr=i(Ta),T(KM.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),SOe=i(m),Sd=n(m,"H2",{class:!0});var qXe=s(Sd);ZM=n(qXe,"A",{id:!0,class:!0,href:!0});var I3t=s(ZM);Mve=n(I3t,"SPAN",{});var N3t=s(Mve);T(S8.$$.fragment,N3t),N3t.forEach(t),I3t.forEach(t),Idr=i(qXe),Eve=n(qXe,"SPAN",{});var q3t=s(Eve);Ndr=r(q3t,"AutoModelForSpeechSeq2Seq"),q3t.forEach(t),qXe.forEach(t),ROe=i(m),Wo=n(m,"DIV",{class:!0});var ul=s(Wo);T(R8.$$.fragment,ul),qdr=i(ul),Rd=n(ul,"P",{});var Zoe=s(Rd);jdr=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),_W=n(Zoe,"A",{href:!0});var j3t=s(_W);Ddr=r(j3t,"from_pretrained()"),j3t.forEach(t),Gdr=r(Zoe," class method or the "),bW=n(Zoe,"A",{href:!0});var D3t=s(bW);Odr=r(D3t,"from_config()"),D3t.forEach(t),Vdr=r(Zoe,` class
method.`),Zoe.forEach(t),Xdr=i(ul),P8=n(ul,"P",{});var jXe=s(P8);zdr=r(jXe,"This class cannot be instantiated directly using "),Cve=n(jXe,"CODE",{});var G3t=s(Cve);Qdr=r(G3t,"__init__()"),G3t.forEach(t),Wdr=r(jXe," (throws an error)."),jXe.forEach(t),Hdr=i(ul),Et=n(ul,"DIV",{class:!0});var mL=s(Et);T(B8.$$.fragment,mL),Udr=i(mL),wve=n(mL,"P",{});var O3t=s(wve);Jdr=r(O3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),O3t.forEach(t),Ydr=i(mL),Pd=n(mL,"P",{});var ere=s(Pd);Kdr=r(ere,`Note:
Loading a model from its configuration file does `),Ave=n(ere,"STRONG",{});var V3t=s(Ave);Zdr=r(V3t,"not"),V3t.forEach(t),ecr=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=n(ere,"A",{href:!0});var X3t=s(vW);ocr=r(X3t,"from_pretrained()"),X3t.forEach(t),rcr=r(ere," to load the model weights."),ere.forEach(t),tcr=i(mL),T(eE.$$.fragment,mL),mL.forEach(t),acr=i(ul),ho=n(ul,"DIV",{class:!0});var Ma=s(ho);T(I8.$$.fragment,Ma),ncr=i(Ma),Lve=n(Ma,"P",{});var z3t=s(Lve);scr=r(z3t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),z3t.forEach(t),lcr=i(Ma),Ja=n(Ma,"P",{});var fL=s(Ja);icr=r(fL,"The model class to instantiate is selected based on the "),yve=n(fL,"CODE",{});var Q3t=s(yve);dcr=r(Q3t,"model_type"),Q3t.forEach(t),ccr=r(fL,` property of the config object (either
passed as an argument or loaded from `),xve=n(fL,"CODE",{});var W3t=s(xve);mcr=r(W3t,"pretrained_model_name_or_path"),W3t.forEach(t),fcr=r(fL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ve=n(fL,"CODE",{});var H3t=s($ve);gcr=r(H3t,"pretrained_model_name_or_path"),H3t.forEach(t),hcr=r(fL,":"),fL.forEach(t),ucr=i(Ma),N8=n(Ma,"UL",{});var DXe=s(N8);oE=n(DXe,"LI",{});var CBe=s(oE);kve=n(CBe,"STRONG",{});var U3t=s(kve);pcr=r(U3t,"speech-encoder-decoder"),U3t.forEach(t),_cr=r(CBe," \u2014 "),FW=n(CBe,"A",{href:!0});var J3t=s(FW);bcr=r(J3t,"SpeechEncoderDecoderModel"),J3t.forEach(t),vcr=r(CBe," (Speech Encoder decoder model)"),CBe.forEach(t),Fcr=i(DXe),rE=n(DXe,"LI",{});var wBe=s(rE);Sve=n(wBe,"STRONG",{});var Y3t=s(Sve);Tcr=r(Y3t,"speech_to_text"),Y3t.forEach(t),Mcr=r(wBe," \u2014 "),TW=n(wBe,"A",{href:!0});var K3t=s(TW);Ecr=r(K3t,"Speech2TextForConditionalGeneration"),K3t.forEach(t),Ccr=r(wBe," (Speech2Text model)"),wBe.forEach(t),DXe.forEach(t),wcr=i(Ma),tE=n(Ma,"P",{});var ABe=s(tE);Acr=r(ABe,"The model is set in evaluation mode by default using "),Rve=n(ABe,"CODE",{});var Z3t=s(Rve);Lcr=r(Z3t,"model.eval()"),Z3t.forEach(t),ycr=r(ABe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pve=n(ABe,"CODE",{});var e0t=s(Pve);xcr=r(e0t,"model.train()"),e0t.forEach(t),ABe.forEach(t),$cr=i(Ma),T(aE.$$.fragment,Ma),Ma.forEach(t),ul.forEach(t),POe=i(m),Bd=n(m,"H2",{class:!0});var GXe=s(Bd);nE=n(GXe,"A",{id:!0,class:!0,href:!0});var o0t=s(nE);Bve=n(o0t,"SPAN",{});var r0t=s(Bve);T(q8.$$.fragment,r0t),r0t.forEach(t),o0t.forEach(t),kcr=i(GXe),Ive=n(GXe,"SPAN",{});var t0t=s(Ive);Scr=r(t0t,"AutoModelForAudioXVector"),t0t.forEach(t),GXe.forEach(t),BOe=i(m),Ho=n(m,"DIV",{class:!0});var pl=s(Ho);T(j8.$$.fragment,pl),Rcr=i(pl),Id=n(pl,"P",{});var ore=s(Id);Pcr=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=n(ore,"A",{href:!0});var a0t=s(MW);Bcr=r(a0t,"from_pretrained()"),a0t.forEach(t),Icr=r(ore," class method or the "),EW=n(ore,"A",{href:!0});var n0t=s(EW);Ncr=r(n0t,"from_config()"),n0t.forEach(t),qcr=r(ore,` class
method.`),ore.forEach(t),jcr=i(pl),D8=n(pl,"P",{});var OXe=s(D8);Dcr=r(OXe,"This class cannot be instantiated directly using "),Nve=n(OXe,"CODE",{});var s0t=s(Nve);Gcr=r(s0t,"__init__()"),s0t.forEach(t),Ocr=r(OXe," (throws an error)."),OXe.forEach(t),Vcr=i(pl),Ct=n(pl,"DIV",{class:!0});var gL=s(Ct);T(G8.$$.fragment,gL),Xcr=i(gL),qve=n(gL,"P",{});var l0t=s(qve);zcr=r(l0t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),l0t.forEach(t),Qcr=i(gL),Nd=n(gL,"P",{});var rre=s(Nd);Wcr=r(rre,`Note:
Loading a model from its configuration file does `),jve=n(rre,"STRONG",{});var i0t=s(jve);Hcr=r(i0t,"not"),i0t.forEach(t),Ucr=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(rre,"A",{href:!0});var d0t=s(CW);Jcr=r(d0t,"from_pretrained()"),d0t.forEach(t),Ycr=r(rre," to load the model weights."),rre.forEach(t),Kcr=i(gL),T(sE.$$.fragment,gL),gL.forEach(t),Zcr=i(pl),uo=n(pl,"DIV",{class:!0});var Ea=s(uo);T(O8.$$.fragment,Ea),emr=i(Ea),Dve=n(Ea,"P",{});var c0t=s(Dve);omr=r(c0t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),c0t.forEach(t),rmr=i(Ea),Ya=n(Ea,"P",{});var hL=s(Ya);tmr=r(hL,"The model class to instantiate is selected based on the "),Gve=n(hL,"CODE",{});var m0t=s(Gve);amr=r(m0t,"model_type"),m0t.forEach(t),nmr=r(hL,` property of the config object (either
passed as an argument or loaded from `),Ove=n(hL,"CODE",{});var f0t=s(Ove);smr=r(f0t,"pretrained_model_name_or_path"),f0t.forEach(t),lmr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=n(hL,"CODE",{});var g0t=s(Vve);imr=r(g0t,"pretrained_model_name_or_path"),g0t.forEach(t),dmr=r(hL,":"),hL.forEach(t),cmr=i(Ea),ot=n(Ea,"UL",{});var _l=s(ot);lE=n(_l,"LI",{});var LBe=s(lE);Xve=n(LBe,"STRONG",{});var h0t=s(Xve);mmr=r(h0t,"data2vec-audio"),h0t.forEach(t),fmr=r(LBe," \u2014 "),wW=n(LBe,"A",{href:!0});var u0t=s(wW);gmr=r(u0t,"Data2VecAudioForXVector"),u0t.forEach(t),hmr=r(LBe," (Data2VecAudio model)"),LBe.forEach(t),umr=i(_l),iE=n(_l,"LI",{});var yBe=s(iE);zve=n(yBe,"STRONG",{});var p0t=s(zve);pmr=r(p0t,"unispeech-sat"),p0t.forEach(t),_mr=r(yBe," \u2014 "),AW=n(yBe,"A",{href:!0});var _0t=s(AW);bmr=r(_0t,"UniSpeechSatForXVector"),_0t.forEach(t),vmr=r(yBe," (UniSpeechSat model)"),yBe.forEach(t),Fmr=i(_l),dE=n(_l,"LI",{});var xBe=s(dE);Qve=n(xBe,"STRONG",{});var b0t=s(Qve);Tmr=r(b0t,"wav2vec2"),b0t.forEach(t),Mmr=r(xBe," \u2014 "),LW=n(xBe,"A",{href:!0});var v0t=s(LW);Emr=r(v0t,"Wav2Vec2ForXVector"),v0t.forEach(t),Cmr=r(xBe," (Wav2Vec2 model)"),xBe.forEach(t),wmr=i(_l),cE=n(_l,"LI",{});var $Be=s(cE);Wve=n($Be,"STRONG",{});var F0t=s(Wve);Amr=r(F0t,"wav2vec2-conformer"),F0t.forEach(t),Lmr=r($Be," \u2014 "),yW=n($Be,"A",{href:!0});var T0t=s(yW);ymr=r(T0t,"Wav2Vec2ConformerForXVector"),T0t.forEach(t),xmr=r($Be," (Wav2Vec2-Conformer model)"),$Be.forEach(t),$mr=i(_l),mE=n(_l,"LI",{});var kBe=s(mE);Hve=n(kBe,"STRONG",{});var M0t=s(Hve);kmr=r(M0t,"wavlm"),M0t.forEach(t),Smr=r(kBe," \u2014 "),xW=n(kBe,"A",{href:!0});var E0t=s(xW);Rmr=r(E0t,"WavLMForXVector"),E0t.forEach(t),Pmr=r(kBe," (WavLM model)"),kBe.forEach(t),_l.forEach(t),Bmr=i(Ea),fE=n(Ea,"P",{});var SBe=s(fE);Imr=r(SBe,"The model is set in evaluation mode by default using "),Uve=n(SBe,"CODE",{});var C0t=s(Uve);Nmr=r(C0t,"model.eval()"),C0t.forEach(t),qmr=r(SBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jve=n(SBe,"CODE",{});var w0t=s(Jve);jmr=r(w0t,"model.train()"),w0t.forEach(t),SBe.forEach(t),Dmr=i(Ea),T(gE.$$.fragment,Ea),Ea.forEach(t),pl.forEach(t),IOe=i(m),qd=n(m,"H2",{class:!0});var VXe=s(qd);hE=n(VXe,"A",{id:!0,class:!0,href:!0});var A0t=s(hE);Yve=n(A0t,"SPAN",{});var L0t=s(Yve);T(V8.$$.fragment,L0t),L0t.forEach(t),A0t.forEach(t),Gmr=i(VXe),Kve=n(VXe,"SPAN",{});var y0t=s(Kve);Omr=r(y0t,"AutoModelForMaskedImageModeling"),y0t.forEach(t),VXe.forEach(t),NOe=i(m),Uo=n(m,"DIV",{class:!0});var bl=s(Uo);T(X8.$$.fragment,bl),Vmr=i(bl),jd=n(bl,"P",{});var tre=s(jd);Xmr=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=n(tre,"A",{href:!0});var x0t=s($W);zmr=r(x0t,"from_pretrained()"),x0t.forEach(t),Qmr=r(tre," class method or the "),kW=n(tre,"A",{href:!0});var $0t=s(kW);Wmr=r($0t,"from_config()"),$0t.forEach(t),Hmr=r(tre,` class
method.`),tre.forEach(t),Umr=i(bl),z8=n(bl,"P",{});var XXe=s(z8);Jmr=r(XXe,"This class cannot be instantiated directly using "),Zve=n(XXe,"CODE",{});var k0t=s(Zve);Ymr=r(k0t,"__init__()"),k0t.forEach(t),Kmr=r(XXe," (throws an error)."),XXe.forEach(t),Zmr=i(bl),wt=n(bl,"DIV",{class:!0});var uL=s(wt);T(Q8.$$.fragment,uL),efr=i(uL),eFe=n(uL,"P",{});var S0t=s(eFe);ofr=r(S0t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),S0t.forEach(t),rfr=i(uL),Dd=n(uL,"P",{});var are=s(Dd);tfr=r(are,`Note:
Loading a model from its configuration file does `),oFe=n(are,"STRONG",{});var R0t=s(oFe);afr=r(R0t,"not"),R0t.forEach(t),nfr=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(are,"A",{href:!0});var P0t=s(SW);sfr=r(P0t,"from_pretrained()"),P0t.forEach(t),lfr=r(are," to load the model weights."),are.forEach(t),ifr=i(uL),T(uE.$$.fragment,uL),uL.forEach(t),dfr=i(bl),po=n(bl,"DIV",{class:!0});var Ca=s(po);T(W8.$$.fragment,Ca),cfr=i(Ca),rFe=n(Ca,"P",{});var B0t=s(rFe);mfr=r(B0t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B0t.forEach(t),ffr=i(Ca),Ka=n(Ca,"P",{});var pL=s(Ka);gfr=r(pL,"The model class to instantiate is selected based on the "),tFe=n(pL,"CODE",{});var I0t=s(tFe);hfr=r(I0t,"model_type"),I0t.forEach(t),ufr=r(pL,` property of the config object (either
passed as an argument or loaded from `),aFe=n(pL,"CODE",{});var N0t=s(aFe);pfr=r(N0t,"pretrained_model_name_or_path"),N0t.forEach(t),_fr=r(pL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nFe=n(pL,"CODE",{});var q0t=s(nFe);bfr=r(q0t,"pretrained_model_name_or_path"),q0t.forEach(t),vfr=r(pL,":"),pL.forEach(t),Ffr=i(Ca),Gd=n(Ca,"UL",{});var nre=s(Gd);pE=n(nre,"LI",{});var RBe=s(pE);sFe=n(RBe,"STRONG",{});var j0t=s(sFe);Tfr=r(j0t,"deit"),j0t.forEach(t),Mfr=r(RBe," \u2014 "),RW=n(RBe,"A",{href:!0});var D0t=s(RW);Efr=r(D0t,"DeiTForMaskedImageModeling"),D0t.forEach(t),Cfr=r(RBe," (DeiT model)"),RBe.forEach(t),wfr=i(nre),_E=n(nre,"LI",{});var PBe=s(_E);lFe=n(PBe,"STRONG",{});var G0t=s(lFe);Afr=r(G0t,"swin"),G0t.forEach(t),Lfr=r(PBe," \u2014 "),PW=n(PBe,"A",{href:!0});var O0t=s(PW);yfr=r(O0t,"SwinForMaskedImageModeling"),O0t.forEach(t),xfr=r(PBe," (Swin Transformer model)"),PBe.forEach(t),$fr=i(nre),bE=n(nre,"LI",{});var BBe=s(bE);iFe=n(BBe,"STRONG",{});var V0t=s(iFe);kfr=r(V0t,"vit"),V0t.forEach(t),Sfr=r(BBe," \u2014 "),BW=n(BBe,"A",{href:!0});var X0t=s(BW);Rfr=r(X0t,"ViTForMaskedImageModeling"),X0t.forEach(t),Pfr=r(BBe," (ViT model)"),BBe.forEach(t),nre.forEach(t),Bfr=i(Ca),vE=n(Ca,"P",{});var IBe=s(vE);Ifr=r(IBe,"The model is set in evaluation mode by default using "),dFe=n(IBe,"CODE",{});var z0t=s(dFe);Nfr=r(z0t,"model.eval()"),z0t.forEach(t),qfr=r(IBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=n(IBe,"CODE",{});var Q0t=s(cFe);jfr=r(Q0t,"model.train()"),Q0t.forEach(t),IBe.forEach(t),Dfr=i(Ca),T(FE.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),qOe=i(m),Od=n(m,"H2",{class:!0});var zXe=s(Od);TE=n(zXe,"A",{id:!0,class:!0,href:!0});var W0t=s(TE);mFe=n(W0t,"SPAN",{});var H0t=s(mFe);T(H8.$$.fragment,H0t),H0t.forEach(t),W0t.forEach(t),Gfr=i(zXe),fFe=n(zXe,"SPAN",{});var U0t=s(fFe);Ofr=r(U0t,"AutoModelForObjectDetection"),U0t.forEach(t),zXe.forEach(t),jOe=i(m),Jo=n(m,"DIV",{class:!0});var vl=s(Jo);T(U8.$$.fragment,vl),Vfr=i(vl),Vd=n(vl,"P",{});var sre=s(Vd);Xfr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=n(sre,"A",{href:!0});var J0t=s(IW);zfr=r(J0t,"from_pretrained()"),J0t.forEach(t),Qfr=r(sre," class method or the "),NW=n(sre,"A",{href:!0});var Y0t=s(NW);Wfr=r(Y0t,"from_config()"),Y0t.forEach(t),Hfr=r(sre,` class
method.`),sre.forEach(t),Ufr=i(vl),J8=n(vl,"P",{});var QXe=s(J8);Jfr=r(QXe,"This class cannot be instantiated directly using "),gFe=n(QXe,"CODE",{});var K0t=s(gFe);Yfr=r(K0t,"__init__()"),K0t.forEach(t),Kfr=r(QXe," (throws an error)."),QXe.forEach(t),Zfr=i(vl),At=n(vl,"DIV",{class:!0});var _L=s(At);T(Y8.$$.fragment,_L),egr=i(_L),hFe=n(_L,"P",{});var Z0t=s(hFe);ogr=r(Z0t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Z0t.forEach(t),rgr=i(_L),Xd=n(_L,"P",{});var lre=s(Xd);tgr=r(lre,`Note:
Loading a model from its configuration file does `),uFe=n(lre,"STRONG",{});var ewt=s(uFe);agr=r(ewt,"not"),ewt.forEach(t),ngr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(lre,"A",{href:!0});var owt=s(qW);sgr=r(owt,"from_pretrained()"),owt.forEach(t),lgr=r(lre," to load the model weights."),lre.forEach(t),igr=i(_L),T(ME.$$.fragment,_L),_L.forEach(t),dgr=i(vl),_o=n(vl,"DIV",{class:!0});var wa=s(_o);T(K8.$$.fragment,wa),cgr=i(wa),pFe=n(wa,"P",{});var rwt=s(pFe);mgr=r(rwt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),rwt.forEach(t),fgr=i(wa),Za=n(wa,"P",{});var bL=s(Za);ggr=r(bL,"The model class to instantiate is selected based on the "),_Fe=n(bL,"CODE",{});var twt=s(_Fe);hgr=r(twt,"model_type"),twt.forEach(t),ugr=r(bL,` property of the config object (either
passed as an argument or loaded from `),bFe=n(bL,"CODE",{});var awt=s(bFe);pgr=r(awt,"pretrained_model_name_or_path"),awt.forEach(t),_gr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vFe=n(bL,"CODE",{});var nwt=s(vFe);bgr=r(nwt,"pretrained_model_name_or_path"),nwt.forEach(t),vgr=r(bL,":"),bL.forEach(t),Fgr=i(wa),Z8=n(wa,"UL",{});var WXe=s(Z8);EE=n(WXe,"LI",{});var NBe=s(EE);FFe=n(NBe,"STRONG",{});var swt=s(FFe);Tgr=r(swt,"detr"),swt.forEach(t),Mgr=r(NBe," \u2014 "),jW=n(NBe,"A",{href:!0});var lwt=s(jW);Egr=r(lwt,"DetrForObjectDetection"),lwt.forEach(t),Cgr=r(NBe," (DETR model)"),NBe.forEach(t),wgr=i(WXe),CE=n(WXe,"LI",{});var qBe=s(CE);TFe=n(qBe,"STRONG",{});var iwt=s(TFe);Agr=r(iwt,"yolos"),iwt.forEach(t),Lgr=r(qBe," \u2014 "),DW=n(qBe,"A",{href:!0});var dwt=s(DW);ygr=r(dwt,"YolosForObjectDetection"),dwt.forEach(t),xgr=r(qBe," (YOLOS model)"),qBe.forEach(t),WXe.forEach(t),$gr=i(wa),wE=n(wa,"P",{});var jBe=s(wE);kgr=r(jBe,"The model is set in evaluation mode by default using "),MFe=n(jBe,"CODE",{});var cwt=s(MFe);Sgr=r(cwt,"model.eval()"),cwt.forEach(t),Rgr=r(jBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EFe=n(jBe,"CODE",{});var mwt=s(EFe);Pgr=r(mwt,"model.train()"),mwt.forEach(t),jBe.forEach(t),Bgr=i(wa),T(AE.$$.fragment,wa),wa.forEach(t),vl.forEach(t),DOe=i(m),zd=n(m,"H2",{class:!0});var HXe=s(zd);LE=n(HXe,"A",{id:!0,class:!0,href:!0});var fwt=s(LE);CFe=n(fwt,"SPAN",{});var gwt=s(CFe);T(e9.$$.fragment,gwt),gwt.forEach(t),fwt.forEach(t),Igr=i(HXe),wFe=n(HXe,"SPAN",{});var hwt=s(wFe);Ngr=r(hwt,"AutoModelForImageSegmentation"),hwt.forEach(t),HXe.forEach(t),GOe=i(m),Yo=n(m,"DIV",{class:!0});var Fl=s(Yo);T(o9.$$.fragment,Fl),qgr=i(Fl),Qd=n(Fl,"P",{});var ire=s(Qd);jgr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=n(ire,"A",{href:!0});var uwt=s(GW);Dgr=r(uwt,"from_pretrained()"),uwt.forEach(t),Ggr=r(ire," class method or the "),OW=n(ire,"A",{href:!0});var pwt=s(OW);Ogr=r(pwt,"from_config()"),pwt.forEach(t),Vgr=r(ire,` class
method.`),ire.forEach(t),Xgr=i(Fl),r9=n(Fl,"P",{});var UXe=s(r9);zgr=r(UXe,"This class cannot be instantiated directly using "),AFe=n(UXe,"CODE",{});var _wt=s(AFe);Qgr=r(_wt,"__init__()"),_wt.forEach(t),Wgr=r(UXe," (throws an error)."),UXe.forEach(t),Hgr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var vL=s(Lt);T(t9.$$.fragment,vL),Ugr=i(vL),LFe=n(vL,"P",{});var bwt=s(LFe);Jgr=r(bwt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),bwt.forEach(t),Ygr=i(vL),Wd=n(vL,"P",{});var dre=s(Wd);Kgr=r(dre,`Note:
Loading a model from its configuration file does `),yFe=n(dre,"STRONG",{});var vwt=s(yFe);Zgr=r(vwt,"not"),vwt.forEach(t),ehr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(dre,"A",{href:!0});var Fwt=s(VW);ohr=r(Fwt,"from_pretrained()"),Fwt.forEach(t),rhr=r(dre," to load the model weights."),dre.forEach(t),thr=i(vL),T(yE.$$.fragment,vL),vL.forEach(t),ahr=i(Fl),bo=n(Fl,"DIV",{class:!0});var Aa=s(bo);T(a9.$$.fragment,Aa),nhr=i(Aa),xFe=n(Aa,"P",{});var Twt=s(xFe);shr=r(Twt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Twt.forEach(t),lhr=i(Aa),en=n(Aa,"P",{});var FL=s(en);ihr=r(FL,"The model class to instantiate is selected based on the "),$Fe=n(FL,"CODE",{});var Mwt=s($Fe);dhr=r(Mwt,"model_type"),Mwt.forEach(t),chr=r(FL,` property of the config object (either
passed as an argument or loaded from `),kFe=n(FL,"CODE",{});var Ewt=s(kFe);mhr=r(Ewt,"pretrained_model_name_or_path"),Ewt.forEach(t),fhr=r(FL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=n(FL,"CODE",{});var Cwt=s(SFe);ghr=r(Cwt,"pretrained_model_name_or_path"),Cwt.forEach(t),hhr=r(FL,":"),FL.forEach(t),uhr=i(Aa),RFe=n(Aa,"UL",{});var wwt=s(RFe);xE=n(wwt,"LI",{});var DBe=s(xE);PFe=n(DBe,"STRONG",{});var Awt=s(PFe);phr=r(Awt,"detr"),Awt.forEach(t),_hr=r(DBe," \u2014 "),XW=n(DBe,"A",{href:!0});var Lwt=s(XW);bhr=r(Lwt,"DetrForSegmentation"),Lwt.forEach(t),vhr=r(DBe," (DETR model)"),DBe.forEach(t),wwt.forEach(t),Fhr=i(Aa),$E=n(Aa,"P",{});var GBe=s($E);Thr=r(GBe,"The model is set in evaluation mode by default using "),BFe=n(GBe,"CODE",{});var ywt=s(BFe);Mhr=r(ywt,"model.eval()"),ywt.forEach(t),Ehr=r(GBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),IFe=n(GBe,"CODE",{});var xwt=s(IFe);Chr=r(xwt,"model.train()"),xwt.forEach(t),GBe.forEach(t),whr=i(Aa),T(kE.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),OOe=i(m),Hd=n(m,"H2",{class:!0});var JXe=s(Hd);SE=n(JXe,"A",{id:!0,class:!0,href:!0});var $wt=s(SE);NFe=n($wt,"SPAN",{});var kwt=s(NFe);T(n9.$$.fragment,kwt),kwt.forEach(t),$wt.forEach(t),Ahr=i(JXe),qFe=n(JXe,"SPAN",{});var Swt=s(qFe);Lhr=r(Swt,"AutoModelForSemanticSegmentation"),Swt.forEach(t),JXe.forEach(t),VOe=i(m),Ko=n(m,"DIV",{class:!0});var Tl=s(Ko);T(s9.$$.fragment,Tl),yhr=i(Tl),Ud=n(Tl,"P",{});var cre=s(Ud);xhr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=n(cre,"A",{href:!0});var Rwt=s(zW);$hr=r(Rwt,"from_pretrained()"),Rwt.forEach(t),khr=r(cre," class method or the "),QW=n(cre,"A",{href:!0});var Pwt=s(QW);Shr=r(Pwt,"from_config()"),Pwt.forEach(t),Rhr=r(cre,` class
method.`),cre.forEach(t),Phr=i(Tl),l9=n(Tl,"P",{});var YXe=s(l9);Bhr=r(YXe,"This class cannot be instantiated directly using "),jFe=n(YXe,"CODE",{});var Bwt=s(jFe);Ihr=r(Bwt,"__init__()"),Bwt.forEach(t),Nhr=r(YXe," (throws an error)."),YXe.forEach(t),qhr=i(Tl),yt=n(Tl,"DIV",{class:!0});var TL=s(yt);T(i9.$$.fragment,TL),jhr=i(TL),DFe=n(TL,"P",{});var Iwt=s(DFe);Dhr=r(Iwt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Iwt.forEach(t),Ghr=i(TL),Jd=n(TL,"P",{});var mre=s(Jd);Ohr=r(mre,`Note:
Loading a model from its configuration file does `),GFe=n(mre,"STRONG",{});var Nwt=s(GFe);Vhr=r(Nwt,"not"),Nwt.forEach(t),Xhr=r(mre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(mre,"A",{href:!0});var qwt=s(WW);zhr=r(qwt,"from_pretrained()"),qwt.forEach(t),Qhr=r(mre," to load the model weights."),mre.forEach(t),Whr=i(TL),T(RE.$$.fragment,TL),TL.forEach(t),Hhr=i(Tl),vo=n(Tl,"DIV",{class:!0});var La=s(vo);T(d9.$$.fragment,La),Uhr=i(La),OFe=n(La,"P",{});var jwt=s(OFe);Jhr=r(jwt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),jwt.forEach(t),Yhr=i(La),on=n(La,"P",{});var ML=s(on);Khr=r(ML,"The model class to instantiate is selected based on the "),VFe=n(ML,"CODE",{});var Dwt=s(VFe);Zhr=r(Dwt,"model_type"),Dwt.forEach(t),eur=r(ML,` property of the config object (either
passed as an argument or loaded from `),XFe=n(ML,"CODE",{});var Gwt=s(XFe);our=r(Gwt,"pretrained_model_name_or_path"),Gwt.forEach(t),rur=r(ML,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zFe=n(ML,"CODE",{});var Owt=s(zFe);tur=r(Owt,"pretrained_model_name_or_path"),Owt.forEach(t),aur=r(ML,":"),ML.forEach(t),nur=i(La),rn=n(La,"UL",{});var EL=s(rn);PE=n(EL,"LI",{});var OBe=s(PE);QFe=n(OBe,"STRONG",{});var Vwt=s(QFe);sur=r(Vwt,"beit"),Vwt.forEach(t),lur=r(OBe," \u2014 "),HW=n(OBe,"A",{href:!0});var Xwt=s(HW);iur=r(Xwt,"BeitForSemanticSegmentation"),Xwt.forEach(t),dur=r(OBe," (BEiT model)"),OBe.forEach(t),cur=i(EL),BE=n(EL,"LI",{});var VBe=s(BE);WFe=n(VBe,"STRONG",{});var zwt=s(WFe);mur=r(zwt,"data2vec-vision"),zwt.forEach(t),fur=r(VBe," \u2014 "),UW=n(VBe,"A",{href:!0});var Qwt=s(UW);gur=r(Qwt,"Data2VecVisionForSemanticSegmentation"),Qwt.forEach(t),hur=r(VBe," (Data2VecVision model)"),VBe.forEach(t),uur=i(EL),IE=n(EL,"LI",{});var XBe=s(IE);HFe=n(XBe,"STRONG",{});var Wwt=s(HFe);pur=r(Wwt,"dpt"),Wwt.forEach(t),_ur=r(XBe," \u2014 "),JW=n(XBe,"A",{href:!0});var Hwt=s(JW);bur=r(Hwt,"DPTForSemanticSegmentation"),Hwt.forEach(t),vur=r(XBe," (DPT model)"),XBe.forEach(t),Fur=i(EL),NE=n(EL,"LI",{});var zBe=s(NE);UFe=n(zBe,"STRONG",{});var Uwt=s(UFe);Tur=r(Uwt,"segformer"),Uwt.forEach(t),Mur=r(zBe," \u2014 "),YW=n(zBe,"A",{href:!0});var Jwt=s(YW);Eur=r(Jwt,"SegformerForSemanticSegmentation"),Jwt.forEach(t),Cur=r(zBe," (SegFormer model)"),zBe.forEach(t),EL.forEach(t),wur=i(La),qE=n(La,"P",{});var QBe=s(qE);Aur=r(QBe,"The model is set in evaluation mode by default using "),JFe=n(QBe,"CODE",{});var Ywt=s(JFe);Lur=r(Ywt,"model.eval()"),Ywt.forEach(t),yur=r(QBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YFe=n(QBe,"CODE",{});var Kwt=s(YFe);xur=r(Kwt,"model.train()"),Kwt.forEach(t),QBe.forEach(t),$ur=i(La),T(jE.$$.fragment,La),La.forEach(t),Tl.forEach(t),XOe=i(m),Yd=n(m,"H2",{class:!0});var KXe=s(Yd);DE=n(KXe,"A",{id:!0,class:!0,href:!0});var Zwt=s(DE);KFe=n(Zwt,"SPAN",{});var eAt=s(KFe);T(c9.$$.fragment,eAt),eAt.forEach(t),Zwt.forEach(t),kur=i(KXe),ZFe=n(KXe,"SPAN",{});var oAt=s(ZFe);Sur=r(oAt,"AutoModelForInstanceSegmentation"),oAt.forEach(t),KXe.forEach(t),zOe=i(m),Zo=n(m,"DIV",{class:!0});var Ml=s(Zo);T(m9.$$.fragment,Ml),Rur=i(Ml),Kd=n(Ml,"P",{});var fre=s(Kd);Pur=r(fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=n(fre,"A",{href:!0});var rAt=s(KW);Bur=r(rAt,"from_pretrained()"),rAt.forEach(t),Iur=r(fre," class method or the "),ZW=n(fre,"A",{href:!0});var tAt=s(ZW);Nur=r(tAt,"from_config()"),tAt.forEach(t),qur=r(fre,` class
method.`),fre.forEach(t),jur=i(Ml),f9=n(Ml,"P",{});var ZXe=s(f9);Dur=r(ZXe,"This class cannot be instantiated directly using "),e1e=n(ZXe,"CODE",{});var aAt=s(e1e);Gur=r(aAt,"__init__()"),aAt.forEach(t),Our=r(ZXe," (throws an error)."),ZXe.forEach(t),Vur=i(Ml),xt=n(Ml,"DIV",{class:!0});var CL=s(xt);T(g9.$$.fragment,CL),Xur=i(CL),o1e=n(CL,"P",{});var nAt=s(o1e);zur=r(nAt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),nAt.forEach(t),Qur=i(CL),Zd=n(CL,"P",{});var gre=s(Zd);Wur=r(gre,`Note:
Loading a model from its configuration file does `),r1e=n(gre,"STRONG",{});var sAt=s(r1e);Hur=r(sAt,"not"),sAt.forEach(t),Uur=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(gre,"A",{href:!0});var lAt=s(eH);Jur=r(lAt,"from_pretrained()"),lAt.forEach(t),Yur=r(gre," to load the model weights."),gre.forEach(t),Kur=i(CL),T(GE.$$.fragment,CL),CL.forEach(t),Zur=i(Ml),Fo=n(Ml,"DIV",{class:!0});var ya=s(Fo);T(h9.$$.fragment,ya),epr=i(ya),t1e=n(ya,"P",{});var iAt=s(t1e);opr=r(iAt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),iAt.forEach(t),rpr=i(ya),tn=n(ya,"P",{});var wL=s(tn);tpr=r(wL,"The model class to instantiate is selected based on the "),a1e=n(wL,"CODE",{});var dAt=s(a1e);apr=r(dAt,"model_type"),dAt.forEach(t),npr=r(wL,` property of the config object (either
passed as an argument or loaded from `),n1e=n(wL,"CODE",{});var cAt=s(n1e);spr=r(cAt,"pretrained_model_name_or_path"),cAt.forEach(t),lpr=r(wL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s1e=n(wL,"CODE",{});var mAt=s(s1e);ipr=r(mAt,"pretrained_model_name_or_path"),mAt.forEach(t),dpr=r(wL,":"),wL.forEach(t),cpr=i(ya),l1e=n(ya,"UL",{});var fAt=s(l1e);OE=n(fAt,"LI",{});var WBe=s(OE);i1e=n(WBe,"STRONG",{});var gAt=s(i1e);mpr=r(gAt,"maskformer"),gAt.forEach(t),fpr=r(WBe," \u2014 "),oH=n(WBe,"A",{href:!0});var hAt=s(oH);gpr=r(hAt,"MaskFormerForInstanceSegmentation"),hAt.forEach(t),hpr=r(WBe," (MaskFormer model)"),WBe.forEach(t),fAt.forEach(t),upr=i(ya),VE=n(ya,"P",{});var HBe=s(VE);ppr=r(HBe,"The model is set in evaluation mode by default using "),d1e=n(HBe,"CODE",{});var uAt=s(d1e);_pr=r(uAt,"model.eval()"),uAt.forEach(t),bpr=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c1e=n(HBe,"CODE",{});var pAt=s(c1e);vpr=r(pAt,"model.train()"),pAt.forEach(t),HBe.forEach(t),Fpr=i(ya),T(XE.$$.fragment,ya),ya.forEach(t),Ml.forEach(t),QOe=i(m),ec=n(m,"H2",{class:!0});var eze=s(ec);zE=n(eze,"A",{id:!0,class:!0,href:!0});var _At=s(zE);m1e=n(_At,"SPAN",{});var bAt=s(m1e);T(u9.$$.fragment,bAt),bAt.forEach(t),_At.forEach(t),Tpr=i(eze),f1e=n(eze,"SPAN",{});var vAt=s(f1e);Mpr=r(vAt,"TFAutoModel"),vAt.forEach(t),eze.forEach(t),WOe=i(m),er=n(m,"DIV",{class:!0});var El=s(er);T(p9.$$.fragment,El),Epr=i(El),oc=n(El,"P",{});var hre=s(oc);Cpr=r(hre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=n(hre,"A",{href:!0});var FAt=s(rH);wpr=r(FAt,"from_pretrained()"),FAt.forEach(t),Apr=r(hre," class method or the "),tH=n(hre,"A",{href:!0});var TAt=s(tH);Lpr=r(TAt,"from_config()"),TAt.forEach(t),ypr=r(hre,` class
method.`),hre.forEach(t),xpr=i(El),_9=n(El,"P",{});var oze=s(_9);$pr=r(oze,"This class cannot be instantiated directly using "),g1e=n(oze,"CODE",{});var MAt=s(g1e);kpr=r(MAt,"__init__()"),MAt.forEach(t),Spr=r(oze," (throws an error)."),oze.forEach(t),Rpr=i(El),$t=n(El,"DIV",{class:!0});var AL=s($t);T(b9.$$.fragment,AL),Ppr=i(AL),h1e=n(AL,"P",{});var EAt=s(h1e);Bpr=r(EAt,"Instantiates one of the base model classes of the library from a configuration."),EAt.forEach(t),Ipr=i(AL),rc=n(AL,"P",{});var ure=s(rc);Npr=r(ure,`Note:
Loading a model from its configuration file does `),u1e=n(ure,"STRONG",{});var CAt=s(u1e);qpr=r(CAt,"not"),CAt.forEach(t),jpr=r(ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(ure,"A",{href:!0});var wAt=s(aH);Dpr=r(wAt,"from_pretrained()"),wAt.forEach(t),Gpr=r(ure," to load the model weights."),ure.forEach(t),Opr=i(AL),T(QE.$$.fragment,AL),AL.forEach(t),Vpr=i(El),yr=n(El,"DIV",{class:!0});var Cl=s(yr);T(v9.$$.fragment,Cl),Xpr=i(Cl),p1e=n(Cl,"P",{});var AAt=s(p1e);zpr=r(AAt,"Instantiate one of the base model classes of the library from a pretrained model."),AAt.forEach(t),Qpr=i(Cl),an=n(Cl,"P",{});var LL=s(an);Wpr=r(LL,"The model class to instantiate is selected based on the "),_1e=n(LL,"CODE",{});var LAt=s(_1e);Hpr=r(LAt,"model_type"),LAt.forEach(t),Upr=r(LL,` property of the config object (either
passed as an argument or loaded from `),b1e=n(LL,"CODE",{});var yAt=s(b1e);Jpr=r(yAt,"pretrained_model_name_or_path"),yAt.forEach(t),Ypr=r(LL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v1e=n(LL,"CODE",{});var xAt=s(v1e);Kpr=r(xAt,"pretrained_model_name_or_path"),xAt.forEach(t),Zpr=r(LL,":"),LL.forEach(t),e_r=i(Cl),j=n(Cl,"UL",{});var D=s(j);WE=n(D,"LI",{});var UBe=s(WE);F1e=n(UBe,"STRONG",{});var $At=s(F1e);o_r=r($At,"albert"),$At.forEach(t),r_r=r(UBe," \u2014 "),nH=n(UBe,"A",{href:!0});var kAt=s(nH);t_r=r(kAt,"TFAlbertModel"),kAt.forEach(t),a_r=r(UBe," (ALBERT model)"),UBe.forEach(t),n_r=i(D),HE=n(D,"LI",{});var JBe=s(HE);T1e=n(JBe,"STRONG",{});var SAt=s(T1e);s_r=r(SAt,"bart"),SAt.forEach(t),l_r=r(JBe," \u2014 "),sH=n(JBe,"A",{href:!0});var RAt=s(sH);i_r=r(RAt,"TFBartModel"),RAt.forEach(t),d_r=r(JBe," (BART model)"),JBe.forEach(t),c_r=i(D),UE=n(D,"LI",{});var YBe=s(UE);M1e=n(YBe,"STRONG",{});var PAt=s(M1e);m_r=r(PAt,"bert"),PAt.forEach(t),f_r=r(YBe," \u2014 "),lH=n(YBe,"A",{href:!0});var BAt=s(lH);g_r=r(BAt,"TFBertModel"),BAt.forEach(t),h_r=r(YBe," (BERT model)"),YBe.forEach(t),u_r=i(D),JE=n(D,"LI",{});var KBe=s(JE);E1e=n(KBe,"STRONG",{});var IAt=s(E1e);p_r=r(IAt,"blenderbot"),IAt.forEach(t),__r=r(KBe," \u2014 "),iH=n(KBe,"A",{href:!0});var NAt=s(iH);b_r=r(NAt,"TFBlenderbotModel"),NAt.forEach(t),v_r=r(KBe," (Blenderbot model)"),KBe.forEach(t),F_r=i(D),YE=n(D,"LI",{});var ZBe=s(YE);C1e=n(ZBe,"STRONG",{});var qAt=s(C1e);T_r=r(qAt,"blenderbot-small"),qAt.forEach(t),M_r=r(ZBe," \u2014 "),dH=n(ZBe,"A",{href:!0});var jAt=s(dH);E_r=r(jAt,"TFBlenderbotSmallModel"),jAt.forEach(t),C_r=r(ZBe," (BlenderbotSmall model)"),ZBe.forEach(t),w_r=i(D),KE=n(D,"LI",{});var eIe=s(KE);w1e=n(eIe,"STRONG",{});var DAt=s(w1e);A_r=r(DAt,"camembert"),DAt.forEach(t),L_r=r(eIe," \u2014 "),cH=n(eIe,"A",{href:!0});var GAt=s(cH);y_r=r(GAt,"TFCamembertModel"),GAt.forEach(t),x_r=r(eIe," (CamemBERT model)"),eIe.forEach(t),$_r=i(D),ZE=n(D,"LI",{});var oIe=s(ZE);A1e=n(oIe,"STRONG",{});var OAt=s(A1e);k_r=r(OAt,"clip"),OAt.forEach(t),S_r=r(oIe," \u2014 "),mH=n(oIe,"A",{href:!0});var VAt=s(mH);R_r=r(VAt,"TFCLIPModel"),VAt.forEach(t),P_r=r(oIe," (CLIP model)"),oIe.forEach(t),B_r=i(D),e4=n(D,"LI",{});var rIe=s(e4);L1e=n(rIe,"STRONG",{});var XAt=s(L1e);I_r=r(XAt,"convbert"),XAt.forEach(t),N_r=r(rIe," \u2014 "),fH=n(rIe,"A",{href:!0});var zAt=s(fH);q_r=r(zAt,"TFConvBertModel"),zAt.forEach(t),j_r=r(rIe," (ConvBERT model)"),rIe.forEach(t),D_r=i(D),o4=n(D,"LI",{});var tIe=s(o4);y1e=n(tIe,"STRONG",{});var QAt=s(y1e);G_r=r(QAt,"convnext"),QAt.forEach(t),O_r=r(tIe," \u2014 "),gH=n(tIe,"A",{href:!0});var WAt=s(gH);V_r=r(WAt,"TFConvNextModel"),WAt.forEach(t),X_r=r(tIe," (ConvNeXT model)"),tIe.forEach(t),z_r=i(D),r4=n(D,"LI",{});var aIe=s(r4);x1e=n(aIe,"STRONG",{});var HAt=s(x1e);Q_r=r(HAt,"ctrl"),HAt.forEach(t),W_r=r(aIe," \u2014 "),hH=n(aIe,"A",{href:!0});var UAt=s(hH);H_r=r(UAt,"TFCTRLModel"),UAt.forEach(t),U_r=r(aIe," (CTRL model)"),aIe.forEach(t),J_r=i(D),t4=n(D,"LI",{});var nIe=s(t4);$1e=n(nIe,"STRONG",{});var JAt=s($1e);Y_r=r(JAt,"data2vec-vision"),JAt.forEach(t),K_r=r(nIe," \u2014 "),uH=n(nIe,"A",{href:!0});var YAt=s(uH);Z_r=r(YAt,"TFData2VecVisionModel"),YAt.forEach(t),e2r=r(nIe," (Data2VecVision model)"),nIe.forEach(t),o2r=i(D),a4=n(D,"LI",{});var sIe=s(a4);k1e=n(sIe,"STRONG",{});var KAt=s(k1e);r2r=r(KAt,"deberta"),KAt.forEach(t),t2r=r(sIe," \u2014 "),pH=n(sIe,"A",{href:!0});var ZAt=s(pH);a2r=r(ZAt,"TFDebertaModel"),ZAt.forEach(t),n2r=r(sIe," (DeBERTa model)"),sIe.forEach(t),s2r=i(D),n4=n(D,"LI",{});var lIe=s(n4);S1e=n(lIe,"STRONG",{});var e6t=s(S1e);l2r=r(e6t,"deberta-v2"),e6t.forEach(t),i2r=r(lIe," \u2014 "),_H=n(lIe,"A",{href:!0});var o6t=s(_H);d2r=r(o6t,"TFDebertaV2Model"),o6t.forEach(t),c2r=r(lIe," (DeBERTa-v2 model)"),lIe.forEach(t),m2r=i(D),s4=n(D,"LI",{});var iIe=s(s4);R1e=n(iIe,"STRONG",{});var r6t=s(R1e);f2r=r(r6t,"distilbert"),r6t.forEach(t),g2r=r(iIe," \u2014 "),bH=n(iIe,"A",{href:!0});var t6t=s(bH);h2r=r(t6t,"TFDistilBertModel"),t6t.forEach(t),u2r=r(iIe," (DistilBERT model)"),iIe.forEach(t),p2r=i(D),l4=n(D,"LI",{});var dIe=s(l4);P1e=n(dIe,"STRONG",{});var a6t=s(P1e);_2r=r(a6t,"dpr"),a6t.forEach(t),b2r=r(dIe," \u2014 "),vH=n(dIe,"A",{href:!0});var n6t=s(vH);v2r=r(n6t,"TFDPRQuestionEncoder"),n6t.forEach(t),F2r=r(dIe," (DPR model)"),dIe.forEach(t),T2r=i(D),i4=n(D,"LI",{});var cIe=s(i4);B1e=n(cIe,"STRONG",{});var s6t=s(B1e);M2r=r(s6t,"electra"),s6t.forEach(t),E2r=r(cIe," \u2014 "),FH=n(cIe,"A",{href:!0});var l6t=s(FH);C2r=r(l6t,"TFElectraModel"),l6t.forEach(t),w2r=r(cIe," (ELECTRA model)"),cIe.forEach(t),A2r=i(D),d4=n(D,"LI",{});var mIe=s(d4);I1e=n(mIe,"STRONG",{});var i6t=s(I1e);L2r=r(i6t,"flaubert"),i6t.forEach(t),y2r=r(mIe," \u2014 "),TH=n(mIe,"A",{href:!0});var d6t=s(TH);x2r=r(d6t,"TFFlaubertModel"),d6t.forEach(t),$2r=r(mIe," (FlauBERT model)"),mIe.forEach(t),k2r=i(D),Qs=n(D,"LI",{});var oS=s(Qs);N1e=n(oS,"STRONG",{});var c6t=s(N1e);S2r=r(c6t,"funnel"),c6t.forEach(t),R2r=r(oS," \u2014 "),MH=n(oS,"A",{href:!0});var m6t=s(MH);P2r=r(m6t,"TFFunnelModel"),m6t.forEach(t),B2r=r(oS," or "),EH=n(oS,"A",{href:!0});var f6t=s(EH);I2r=r(f6t,"TFFunnelBaseModel"),f6t.forEach(t),N2r=r(oS," (Funnel Transformer model)"),oS.forEach(t),q2r=i(D),c4=n(D,"LI",{});var fIe=s(c4);q1e=n(fIe,"STRONG",{});var g6t=s(q1e);j2r=r(g6t,"gpt2"),g6t.forEach(t),D2r=r(fIe," \u2014 "),CH=n(fIe,"A",{href:!0});var h6t=s(CH);G2r=r(h6t,"TFGPT2Model"),h6t.forEach(t),O2r=r(fIe," (OpenAI GPT-2 model)"),fIe.forEach(t),V2r=i(D),m4=n(D,"LI",{});var gIe=s(m4);j1e=n(gIe,"STRONG",{});var u6t=s(j1e);X2r=r(u6t,"gptj"),u6t.forEach(t),z2r=r(gIe," \u2014 "),wH=n(gIe,"A",{href:!0});var p6t=s(wH);Q2r=r(p6t,"TFGPTJModel"),p6t.forEach(t),W2r=r(gIe," (GPT-J model)"),gIe.forEach(t),H2r=i(D),f4=n(D,"LI",{});var hIe=s(f4);D1e=n(hIe,"STRONG",{});var _6t=s(D1e);U2r=r(_6t,"hubert"),_6t.forEach(t),J2r=r(hIe," \u2014 "),AH=n(hIe,"A",{href:!0});var b6t=s(AH);Y2r=r(b6t,"TFHubertModel"),b6t.forEach(t),K2r=r(hIe," (Hubert model)"),hIe.forEach(t),Z2r=i(D),g4=n(D,"LI",{});var uIe=s(g4);G1e=n(uIe,"STRONG",{});var v6t=s(G1e);ebr=r(v6t,"layoutlm"),v6t.forEach(t),obr=r(uIe," \u2014 "),LH=n(uIe,"A",{href:!0});var F6t=s(LH);rbr=r(F6t,"TFLayoutLMModel"),F6t.forEach(t),tbr=r(uIe," (LayoutLM model)"),uIe.forEach(t),abr=i(D),h4=n(D,"LI",{});var pIe=s(h4);O1e=n(pIe,"STRONG",{});var T6t=s(O1e);nbr=r(T6t,"led"),T6t.forEach(t),sbr=r(pIe," \u2014 "),yH=n(pIe,"A",{href:!0});var M6t=s(yH);lbr=r(M6t,"TFLEDModel"),M6t.forEach(t),ibr=r(pIe," (LED model)"),pIe.forEach(t),dbr=i(D),u4=n(D,"LI",{});var _Ie=s(u4);V1e=n(_Ie,"STRONG",{});var E6t=s(V1e);cbr=r(E6t,"longformer"),E6t.forEach(t),mbr=r(_Ie," \u2014 "),xH=n(_Ie,"A",{href:!0});var C6t=s(xH);fbr=r(C6t,"TFLongformerModel"),C6t.forEach(t),gbr=r(_Ie," (Longformer model)"),_Ie.forEach(t),hbr=i(D),p4=n(D,"LI",{});var bIe=s(p4);X1e=n(bIe,"STRONG",{});var w6t=s(X1e);ubr=r(w6t,"lxmert"),w6t.forEach(t),pbr=r(bIe," \u2014 "),$H=n(bIe,"A",{href:!0});var A6t=s($H);_br=r(A6t,"TFLxmertModel"),A6t.forEach(t),bbr=r(bIe," (LXMERT model)"),bIe.forEach(t),vbr=i(D),_4=n(D,"LI",{});var vIe=s(_4);z1e=n(vIe,"STRONG",{});var L6t=s(z1e);Fbr=r(L6t,"marian"),L6t.forEach(t),Tbr=r(vIe," \u2014 "),kH=n(vIe,"A",{href:!0});var y6t=s(kH);Mbr=r(y6t,"TFMarianModel"),y6t.forEach(t),Ebr=r(vIe," (Marian model)"),vIe.forEach(t),Cbr=i(D),b4=n(D,"LI",{});var FIe=s(b4);Q1e=n(FIe,"STRONG",{});var x6t=s(Q1e);wbr=r(x6t,"mbart"),x6t.forEach(t),Abr=r(FIe," \u2014 "),SH=n(FIe,"A",{href:!0});var $6t=s(SH);Lbr=r($6t,"TFMBartModel"),$6t.forEach(t),ybr=r(FIe," (mBART model)"),FIe.forEach(t),xbr=i(D),v4=n(D,"LI",{});var TIe=s(v4);W1e=n(TIe,"STRONG",{});var k6t=s(W1e);$br=r(k6t,"mobilebert"),k6t.forEach(t),kbr=r(TIe," \u2014 "),RH=n(TIe,"A",{href:!0});var S6t=s(RH);Sbr=r(S6t,"TFMobileBertModel"),S6t.forEach(t),Rbr=r(TIe," (MobileBERT model)"),TIe.forEach(t),Pbr=i(D),F4=n(D,"LI",{});var MIe=s(F4);H1e=n(MIe,"STRONG",{});var R6t=s(H1e);Bbr=r(R6t,"mpnet"),R6t.forEach(t),Ibr=r(MIe," \u2014 "),PH=n(MIe,"A",{href:!0});var P6t=s(PH);Nbr=r(P6t,"TFMPNetModel"),P6t.forEach(t),qbr=r(MIe," (MPNet model)"),MIe.forEach(t),jbr=i(D),T4=n(D,"LI",{});var EIe=s(T4);U1e=n(EIe,"STRONG",{});var B6t=s(U1e);Dbr=r(B6t,"mt5"),B6t.forEach(t),Gbr=r(EIe," \u2014 "),BH=n(EIe,"A",{href:!0});var I6t=s(BH);Obr=r(I6t,"TFMT5Model"),I6t.forEach(t),Vbr=r(EIe," (MT5 model)"),EIe.forEach(t),Xbr=i(D),M4=n(D,"LI",{});var CIe=s(M4);J1e=n(CIe,"STRONG",{});var N6t=s(J1e);zbr=r(N6t,"openai-gpt"),N6t.forEach(t),Qbr=r(CIe," \u2014 "),IH=n(CIe,"A",{href:!0});var q6t=s(IH);Wbr=r(q6t,"TFOpenAIGPTModel"),q6t.forEach(t),Hbr=r(CIe," (OpenAI GPT model)"),CIe.forEach(t),Ubr=i(D),E4=n(D,"LI",{});var wIe=s(E4);Y1e=n(wIe,"STRONG",{});var j6t=s(Y1e);Jbr=r(j6t,"opt"),j6t.forEach(t),Ybr=r(wIe," \u2014 "),NH=n(wIe,"A",{href:!0});var D6t=s(NH);Kbr=r(D6t,"TFOPTModel"),D6t.forEach(t),Zbr=r(wIe," (OPT model)"),wIe.forEach(t),evr=i(D),C4=n(D,"LI",{});var AIe=s(C4);K1e=n(AIe,"STRONG",{});var G6t=s(K1e);ovr=r(G6t,"pegasus"),G6t.forEach(t),rvr=r(AIe," \u2014 "),qH=n(AIe,"A",{href:!0});var O6t=s(qH);tvr=r(O6t,"TFPegasusModel"),O6t.forEach(t),avr=r(AIe," (Pegasus model)"),AIe.forEach(t),nvr=i(D),w4=n(D,"LI",{});var LIe=s(w4);Z1e=n(LIe,"STRONG",{});var V6t=s(Z1e);svr=r(V6t,"rembert"),V6t.forEach(t),lvr=r(LIe," \u2014 "),jH=n(LIe,"A",{href:!0});var X6t=s(jH);ivr=r(X6t,"TFRemBertModel"),X6t.forEach(t),dvr=r(LIe," (RemBERT model)"),LIe.forEach(t),cvr=i(D),A4=n(D,"LI",{});var yIe=s(A4);eTe=n(yIe,"STRONG",{});var z6t=s(eTe);mvr=r(z6t,"roberta"),z6t.forEach(t),fvr=r(yIe," \u2014 "),DH=n(yIe,"A",{href:!0});var Q6t=s(DH);gvr=r(Q6t,"TFRobertaModel"),Q6t.forEach(t),hvr=r(yIe," (RoBERTa model)"),yIe.forEach(t),uvr=i(D),L4=n(D,"LI",{});var xIe=s(L4);oTe=n(xIe,"STRONG",{});var W6t=s(oTe);pvr=r(W6t,"roformer"),W6t.forEach(t),_vr=r(xIe," \u2014 "),GH=n(xIe,"A",{href:!0});var H6t=s(GH);bvr=r(H6t,"TFRoFormerModel"),H6t.forEach(t),vvr=r(xIe," (RoFormer model)"),xIe.forEach(t),Fvr=i(D),y4=n(D,"LI",{});var $Ie=s(y4);rTe=n($Ie,"STRONG",{});var U6t=s(rTe);Tvr=r(U6t,"speech_to_text"),U6t.forEach(t),Mvr=r($Ie," \u2014 "),OH=n($Ie,"A",{href:!0});var J6t=s(OH);Evr=r(J6t,"TFSpeech2TextModel"),J6t.forEach(t),Cvr=r($Ie," (Speech2Text model)"),$Ie.forEach(t),wvr=i(D),x4=n(D,"LI",{});var kIe=s(x4);tTe=n(kIe,"STRONG",{});var Y6t=s(tTe);Avr=r(Y6t,"swin"),Y6t.forEach(t),Lvr=r(kIe," \u2014 "),VH=n(kIe,"A",{href:!0});var K6t=s(VH);yvr=r(K6t,"TFSwinModel"),K6t.forEach(t),xvr=r(kIe," (Swin Transformer model)"),kIe.forEach(t),$vr=i(D),$4=n(D,"LI",{});var SIe=s($4);aTe=n(SIe,"STRONG",{});var Z6t=s(aTe);kvr=r(Z6t,"t5"),Z6t.forEach(t),Svr=r(SIe," \u2014 "),XH=n(SIe,"A",{href:!0});var eLt=s(XH);Rvr=r(eLt,"TFT5Model"),eLt.forEach(t),Pvr=r(SIe," (T5 model)"),SIe.forEach(t),Bvr=i(D),k4=n(D,"LI",{});var RIe=s(k4);nTe=n(RIe,"STRONG",{});var oLt=s(nTe);Ivr=r(oLt,"tapas"),oLt.forEach(t),Nvr=r(RIe," \u2014 "),zH=n(RIe,"A",{href:!0});var rLt=s(zH);qvr=r(rLt,"TFTapasModel"),rLt.forEach(t),jvr=r(RIe," (TAPAS model)"),RIe.forEach(t),Dvr=i(D),S4=n(D,"LI",{});var PIe=s(S4);sTe=n(PIe,"STRONG",{});var tLt=s(sTe);Gvr=r(tLt,"transfo-xl"),tLt.forEach(t),Ovr=r(PIe," \u2014 "),QH=n(PIe,"A",{href:!0});var aLt=s(QH);Vvr=r(aLt,"TFTransfoXLModel"),aLt.forEach(t),Xvr=r(PIe," (Transformer-XL model)"),PIe.forEach(t),zvr=i(D),R4=n(D,"LI",{});var BIe=s(R4);lTe=n(BIe,"STRONG",{});var nLt=s(lTe);Qvr=r(nLt,"vit"),nLt.forEach(t),Wvr=r(BIe," \u2014 "),WH=n(BIe,"A",{href:!0});var sLt=s(WH);Hvr=r(sLt,"TFViTModel"),sLt.forEach(t),Uvr=r(BIe," (ViT model)"),BIe.forEach(t),Jvr=i(D),P4=n(D,"LI",{});var IIe=s(P4);iTe=n(IIe,"STRONG",{});var lLt=s(iTe);Yvr=r(lLt,"vit_mae"),lLt.forEach(t),Kvr=r(IIe," \u2014 "),HH=n(IIe,"A",{href:!0});var iLt=s(HH);Zvr=r(iLt,"TFViTMAEModel"),iLt.forEach(t),eFr=r(IIe," (ViTMAE model)"),IIe.forEach(t),oFr=i(D),B4=n(D,"LI",{});var NIe=s(B4);dTe=n(NIe,"STRONG",{});var dLt=s(dTe);rFr=r(dLt,"wav2vec2"),dLt.forEach(t),tFr=r(NIe," \u2014 "),UH=n(NIe,"A",{href:!0});var cLt=s(UH);aFr=r(cLt,"TFWav2Vec2Model"),cLt.forEach(t),nFr=r(NIe," (Wav2Vec2 model)"),NIe.forEach(t),sFr=i(D),I4=n(D,"LI",{});var qIe=s(I4);cTe=n(qIe,"STRONG",{});var mLt=s(cTe);lFr=r(mLt,"xlm"),mLt.forEach(t),iFr=r(qIe," \u2014 "),JH=n(qIe,"A",{href:!0});var fLt=s(JH);dFr=r(fLt,"TFXLMModel"),fLt.forEach(t),cFr=r(qIe," (XLM model)"),qIe.forEach(t),mFr=i(D),N4=n(D,"LI",{});var jIe=s(N4);mTe=n(jIe,"STRONG",{});var gLt=s(mTe);fFr=r(gLt,"xlm-roberta"),gLt.forEach(t),gFr=r(jIe," \u2014 "),YH=n(jIe,"A",{href:!0});var hLt=s(YH);hFr=r(hLt,"TFXLMRobertaModel"),hLt.forEach(t),uFr=r(jIe," (XLM-RoBERTa model)"),jIe.forEach(t),pFr=i(D),q4=n(D,"LI",{});var DIe=s(q4);fTe=n(DIe,"STRONG",{});var uLt=s(fTe);_Fr=r(uLt,"xlnet"),uLt.forEach(t),bFr=r(DIe," \u2014 "),KH=n(DIe,"A",{href:!0});var pLt=s(KH);vFr=r(pLt,"TFXLNetModel"),pLt.forEach(t),FFr=r(DIe," (XLNet model)"),DIe.forEach(t),D.forEach(t),TFr=i(Cl),T(j4.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),HOe=i(m),tc=n(m,"H2",{class:!0});var rze=s(tc);D4=n(rze,"A",{id:!0,class:!0,href:!0});var _Lt=s(D4);gTe=n(_Lt,"SPAN",{});var bLt=s(gTe);T(F9.$$.fragment,bLt),bLt.forEach(t),_Lt.forEach(t),MFr=i(rze),hTe=n(rze,"SPAN",{});var vLt=s(hTe);EFr=r(vLt,"TFAutoModelForPreTraining"),vLt.forEach(t),rze.forEach(t),UOe=i(m),or=n(m,"DIV",{class:!0});var wl=s(or);T(T9.$$.fragment,wl),CFr=i(wl),ac=n(wl,"P",{});var pre=s(ac);wFr=r(pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=n(pre,"A",{href:!0});var FLt=s(ZH);AFr=r(FLt,"from_pretrained()"),FLt.forEach(t),LFr=r(pre," class method or the "),eU=n(pre,"A",{href:!0});var TLt=s(eU);yFr=r(TLt,"from_config()"),TLt.forEach(t),xFr=r(pre,` class
method.`),pre.forEach(t),$Fr=i(wl),M9=n(wl,"P",{});var tze=s(M9);kFr=r(tze,"This class cannot be instantiated directly using "),uTe=n(tze,"CODE",{});var MLt=s(uTe);SFr=r(MLt,"__init__()"),MLt.forEach(t),RFr=r(tze," (throws an error)."),tze.forEach(t),PFr=i(wl),kt=n(wl,"DIV",{class:!0});var yL=s(kt);T(E9.$$.fragment,yL),BFr=i(yL),pTe=n(yL,"P",{});var ELt=s(pTe);IFr=r(ELt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ELt.forEach(t),NFr=i(yL),nc=n(yL,"P",{});var _re=s(nc);qFr=r(_re,`Note:
Loading a model from its configuration file does `),_Te=n(_re,"STRONG",{});var CLt=s(_Te);jFr=r(CLt,"not"),CLt.forEach(t),DFr=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=n(_re,"A",{href:!0});var wLt=s(oU);GFr=r(wLt,"from_pretrained()"),wLt.forEach(t),OFr=r(_re," to load the model weights."),_re.forEach(t),VFr=i(yL),T(G4.$$.fragment,yL),yL.forEach(t),XFr=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(C9.$$.fragment,Al),zFr=i(Al),bTe=n(Al,"P",{});var ALt=s(bTe);QFr=r(ALt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ALt.forEach(t),WFr=i(Al),nn=n(Al,"P",{});var xL=s(nn);HFr=r(xL,"The model class to instantiate is selected based on the "),vTe=n(xL,"CODE",{});var LLt=s(vTe);UFr=r(LLt,"model_type"),LLt.forEach(t),JFr=r(xL,` property of the config object (either
passed as an argument or loaded from `),FTe=n(xL,"CODE",{});var yLt=s(FTe);YFr=r(yLt,"pretrained_model_name_or_path"),yLt.forEach(t),KFr=r(xL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TTe=n(xL,"CODE",{});var xLt=s(TTe);ZFr=r(xLt,"pretrained_model_name_or_path"),xLt.forEach(t),e1r=r(xL,":"),xL.forEach(t),o1r=i(Al),se=n(Al,"UL",{});var le=s(se);O4=n(le,"LI",{});var GIe=s(O4);MTe=n(GIe,"STRONG",{});var $Lt=s(MTe);r1r=r($Lt,"albert"),$Lt.forEach(t),t1r=r(GIe," \u2014 "),rU=n(GIe,"A",{href:!0});var kLt=s(rU);a1r=r(kLt,"TFAlbertForPreTraining"),kLt.forEach(t),n1r=r(GIe," (ALBERT model)"),GIe.forEach(t),s1r=i(le),V4=n(le,"LI",{});var OIe=s(V4);ETe=n(OIe,"STRONG",{});var SLt=s(ETe);l1r=r(SLt,"bart"),SLt.forEach(t),i1r=r(OIe," \u2014 "),tU=n(OIe,"A",{href:!0});var RLt=s(tU);d1r=r(RLt,"TFBartForConditionalGeneration"),RLt.forEach(t),c1r=r(OIe," (BART model)"),OIe.forEach(t),m1r=i(le),X4=n(le,"LI",{});var VIe=s(X4);CTe=n(VIe,"STRONG",{});var PLt=s(CTe);f1r=r(PLt,"bert"),PLt.forEach(t),g1r=r(VIe," \u2014 "),aU=n(VIe,"A",{href:!0});var BLt=s(aU);h1r=r(BLt,"TFBertForPreTraining"),BLt.forEach(t),u1r=r(VIe," (BERT model)"),VIe.forEach(t),p1r=i(le),z4=n(le,"LI",{});var XIe=s(z4);wTe=n(XIe,"STRONG",{});var ILt=s(wTe);_1r=r(ILt,"camembert"),ILt.forEach(t),b1r=r(XIe," \u2014 "),nU=n(XIe,"A",{href:!0});var NLt=s(nU);v1r=r(NLt,"TFCamembertForMaskedLM"),NLt.forEach(t),F1r=r(XIe," (CamemBERT model)"),XIe.forEach(t),T1r=i(le),Q4=n(le,"LI",{});var zIe=s(Q4);ATe=n(zIe,"STRONG",{});var qLt=s(ATe);M1r=r(qLt,"ctrl"),qLt.forEach(t),E1r=r(zIe," \u2014 "),sU=n(zIe,"A",{href:!0});var jLt=s(sU);C1r=r(jLt,"TFCTRLLMHeadModel"),jLt.forEach(t),w1r=r(zIe," (CTRL model)"),zIe.forEach(t),A1r=i(le),W4=n(le,"LI",{});var QIe=s(W4);LTe=n(QIe,"STRONG",{});var DLt=s(LTe);L1r=r(DLt,"distilbert"),DLt.forEach(t),y1r=r(QIe," \u2014 "),lU=n(QIe,"A",{href:!0});var GLt=s(lU);x1r=r(GLt,"TFDistilBertForMaskedLM"),GLt.forEach(t),$1r=r(QIe," (DistilBERT model)"),QIe.forEach(t),k1r=i(le),H4=n(le,"LI",{});var WIe=s(H4);yTe=n(WIe,"STRONG",{});var OLt=s(yTe);S1r=r(OLt,"electra"),OLt.forEach(t),R1r=r(WIe," \u2014 "),iU=n(WIe,"A",{href:!0});var VLt=s(iU);P1r=r(VLt,"TFElectraForPreTraining"),VLt.forEach(t),B1r=r(WIe," (ELECTRA model)"),WIe.forEach(t),I1r=i(le),U4=n(le,"LI",{});var HIe=s(U4);xTe=n(HIe,"STRONG",{});var XLt=s(xTe);N1r=r(XLt,"flaubert"),XLt.forEach(t),q1r=r(HIe," \u2014 "),dU=n(HIe,"A",{href:!0});var zLt=s(dU);j1r=r(zLt,"TFFlaubertWithLMHeadModel"),zLt.forEach(t),D1r=r(HIe," (FlauBERT model)"),HIe.forEach(t),G1r=i(le),J4=n(le,"LI",{});var UIe=s(J4);$Te=n(UIe,"STRONG",{});var QLt=s($Te);O1r=r(QLt,"funnel"),QLt.forEach(t),V1r=r(UIe," \u2014 "),cU=n(UIe,"A",{href:!0});var WLt=s(cU);X1r=r(WLt,"TFFunnelForPreTraining"),WLt.forEach(t),z1r=r(UIe," (Funnel Transformer model)"),UIe.forEach(t),Q1r=i(le),Y4=n(le,"LI",{});var JIe=s(Y4);kTe=n(JIe,"STRONG",{});var HLt=s(kTe);W1r=r(HLt,"gpt2"),HLt.forEach(t),H1r=r(JIe," \u2014 "),mU=n(JIe,"A",{href:!0});var ULt=s(mU);U1r=r(ULt,"TFGPT2LMHeadModel"),ULt.forEach(t),J1r=r(JIe," (OpenAI GPT-2 model)"),JIe.forEach(t),Y1r=i(le),K4=n(le,"LI",{});var YIe=s(K4);STe=n(YIe,"STRONG",{});var JLt=s(STe);K1r=r(JLt,"layoutlm"),JLt.forEach(t),Z1r=r(YIe," \u2014 "),fU=n(YIe,"A",{href:!0});var YLt=s(fU);eTr=r(YLt,"TFLayoutLMForMaskedLM"),YLt.forEach(t),oTr=r(YIe," (LayoutLM model)"),YIe.forEach(t),rTr=i(le),Z4=n(le,"LI",{});var KIe=s(Z4);RTe=n(KIe,"STRONG",{});var KLt=s(RTe);tTr=r(KLt,"lxmert"),KLt.forEach(t),aTr=r(KIe," \u2014 "),gU=n(KIe,"A",{href:!0});var ZLt=s(gU);nTr=r(ZLt,"TFLxmertForPreTraining"),ZLt.forEach(t),sTr=r(KIe," (LXMERT model)"),KIe.forEach(t),lTr=i(le),eC=n(le,"LI",{});var ZIe=s(eC);PTe=n(ZIe,"STRONG",{});var eyt=s(PTe);iTr=r(eyt,"mobilebert"),eyt.forEach(t),dTr=r(ZIe," \u2014 "),hU=n(ZIe,"A",{href:!0});var oyt=s(hU);cTr=r(oyt,"TFMobileBertForPreTraining"),oyt.forEach(t),mTr=r(ZIe," (MobileBERT model)"),ZIe.forEach(t),fTr=i(le),oC=n(le,"LI",{});var eNe=s(oC);BTe=n(eNe,"STRONG",{});var ryt=s(BTe);gTr=r(ryt,"mpnet"),ryt.forEach(t),hTr=r(eNe," \u2014 "),uU=n(eNe,"A",{href:!0});var tyt=s(uU);uTr=r(tyt,"TFMPNetForMaskedLM"),tyt.forEach(t),pTr=r(eNe," (MPNet model)"),eNe.forEach(t),_Tr=i(le),rC=n(le,"LI",{});var oNe=s(rC);ITe=n(oNe,"STRONG",{});var ayt=s(ITe);bTr=r(ayt,"openai-gpt"),ayt.forEach(t),vTr=r(oNe," \u2014 "),pU=n(oNe,"A",{href:!0});var nyt=s(pU);FTr=r(nyt,"TFOpenAIGPTLMHeadModel"),nyt.forEach(t),TTr=r(oNe," (OpenAI GPT model)"),oNe.forEach(t),MTr=i(le),tC=n(le,"LI",{});var rNe=s(tC);NTe=n(rNe,"STRONG",{});var syt=s(NTe);ETr=r(syt,"roberta"),syt.forEach(t),CTr=r(rNe," \u2014 "),_U=n(rNe,"A",{href:!0});var lyt=s(_U);wTr=r(lyt,"TFRobertaForMaskedLM"),lyt.forEach(t),ATr=r(rNe," (RoBERTa model)"),rNe.forEach(t),LTr=i(le),aC=n(le,"LI",{});var tNe=s(aC);qTe=n(tNe,"STRONG",{});var iyt=s(qTe);yTr=r(iyt,"t5"),iyt.forEach(t),xTr=r(tNe," \u2014 "),bU=n(tNe,"A",{href:!0});var dyt=s(bU);$Tr=r(dyt,"TFT5ForConditionalGeneration"),dyt.forEach(t),kTr=r(tNe," (T5 model)"),tNe.forEach(t),STr=i(le),nC=n(le,"LI",{});var aNe=s(nC);jTe=n(aNe,"STRONG",{});var cyt=s(jTe);RTr=r(cyt,"tapas"),cyt.forEach(t),PTr=r(aNe," \u2014 "),vU=n(aNe,"A",{href:!0});var myt=s(vU);BTr=r(myt,"TFTapasForMaskedLM"),myt.forEach(t),ITr=r(aNe," (TAPAS model)"),aNe.forEach(t),NTr=i(le),sC=n(le,"LI",{});var nNe=s(sC);DTe=n(nNe,"STRONG",{});var fyt=s(DTe);qTr=r(fyt,"transfo-xl"),fyt.forEach(t),jTr=r(nNe," \u2014 "),FU=n(nNe,"A",{href:!0});var gyt=s(FU);DTr=r(gyt,"TFTransfoXLLMHeadModel"),gyt.forEach(t),GTr=r(nNe," (Transformer-XL model)"),nNe.forEach(t),OTr=i(le),lC=n(le,"LI",{});var sNe=s(lC);GTe=n(sNe,"STRONG",{});var hyt=s(GTe);VTr=r(hyt,"vit_mae"),hyt.forEach(t),XTr=r(sNe," \u2014 "),TU=n(sNe,"A",{href:!0});var uyt=s(TU);zTr=r(uyt,"TFViTMAEForPreTraining"),uyt.forEach(t),QTr=r(sNe," (ViTMAE model)"),sNe.forEach(t),WTr=i(le),iC=n(le,"LI",{});var lNe=s(iC);OTe=n(lNe,"STRONG",{});var pyt=s(OTe);HTr=r(pyt,"xlm"),pyt.forEach(t),UTr=r(lNe," \u2014 "),MU=n(lNe,"A",{href:!0});var _yt=s(MU);JTr=r(_yt,"TFXLMWithLMHeadModel"),_yt.forEach(t),YTr=r(lNe," (XLM model)"),lNe.forEach(t),KTr=i(le),dC=n(le,"LI",{});var iNe=s(dC);VTe=n(iNe,"STRONG",{});var byt=s(VTe);ZTr=r(byt,"xlm-roberta"),byt.forEach(t),eMr=r(iNe," \u2014 "),EU=n(iNe,"A",{href:!0});var vyt=s(EU);oMr=r(vyt,"TFXLMRobertaForMaskedLM"),vyt.forEach(t),rMr=r(iNe," (XLM-RoBERTa model)"),iNe.forEach(t),tMr=i(le),cC=n(le,"LI",{});var dNe=s(cC);XTe=n(dNe,"STRONG",{});var Fyt=s(XTe);aMr=r(Fyt,"xlnet"),Fyt.forEach(t),nMr=r(dNe," \u2014 "),CU=n(dNe,"A",{href:!0});var Tyt=s(CU);sMr=r(Tyt,"TFXLNetLMHeadModel"),Tyt.forEach(t),lMr=r(dNe," (XLNet model)"),dNe.forEach(t),le.forEach(t),iMr=i(Al),T(mC.$$.fragment,Al),Al.forEach(t),wl.forEach(t),JOe=i(m),sc=n(m,"H2",{class:!0});var aze=s(sc);fC=n(aze,"A",{id:!0,class:!0,href:!0});var Myt=s(fC);zTe=n(Myt,"SPAN",{});var Eyt=s(zTe);T(w9.$$.fragment,Eyt),Eyt.forEach(t),Myt.forEach(t),dMr=i(aze),QTe=n(aze,"SPAN",{});var Cyt=s(QTe);cMr=r(Cyt,"TFAutoModelForCausalLM"),Cyt.forEach(t),aze.forEach(t),YOe=i(m),rr=n(m,"DIV",{class:!0});var Ll=s(rr);T(A9.$$.fragment,Ll),mMr=i(Ll),lc=n(Ll,"P",{});var bre=s(lc);fMr=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=n(bre,"A",{href:!0});var wyt=s(wU);gMr=r(wyt,"from_pretrained()"),wyt.forEach(t),hMr=r(bre," class method or the "),AU=n(bre,"A",{href:!0});var Ayt=s(AU);uMr=r(Ayt,"from_config()"),Ayt.forEach(t),pMr=r(bre,` class
method.`),bre.forEach(t),_Mr=i(Ll),L9=n(Ll,"P",{});var nze=s(L9);bMr=r(nze,"This class cannot be instantiated directly using "),WTe=n(nze,"CODE",{});var Lyt=s(WTe);vMr=r(Lyt,"__init__()"),Lyt.forEach(t),FMr=r(nze," (throws an error)."),nze.forEach(t),TMr=i(Ll),St=n(Ll,"DIV",{class:!0});var $L=s(St);T(y9.$$.fragment,$L),MMr=i($L),HTe=n($L,"P",{});var yyt=s(HTe);EMr=r(yyt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yyt.forEach(t),CMr=i($L),ic=n($L,"P",{});var vre=s(ic);wMr=r(vre,`Note:
Loading a model from its configuration file does `),UTe=n(vre,"STRONG",{});var xyt=s(UTe);AMr=r(xyt,"not"),xyt.forEach(t),LMr=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(vre,"A",{href:!0});var $yt=s(LU);yMr=r($yt,"from_pretrained()"),$yt.forEach(t),xMr=r(vre," to load the model weights."),vre.forEach(t),$Mr=i($L),T(gC.$$.fragment,$L),$L.forEach(t),kMr=i(Ll),$r=n(Ll,"DIV",{class:!0});var yl=s($r);T(x9.$$.fragment,yl),SMr=i(yl),JTe=n(yl,"P",{});var kyt=s(JTe);RMr=r(kyt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kyt.forEach(t),PMr=i(yl),sn=n(yl,"P",{});var kL=s(sn);BMr=r(kL,"The model class to instantiate is selected based on the "),YTe=n(kL,"CODE",{});var Syt=s(YTe);IMr=r(Syt,"model_type"),Syt.forEach(t),NMr=r(kL,` property of the config object (either
passed as an argument or loaded from `),KTe=n(kL,"CODE",{});var Ryt=s(KTe);qMr=r(Ryt,"pretrained_model_name_or_path"),Ryt.forEach(t),jMr=r(kL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZTe=n(kL,"CODE",{});var Pyt=s(ZTe);DMr=r(Pyt,"pretrained_model_name_or_path"),Pyt.forEach(t),GMr=r(kL,":"),kL.forEach(t),OMr=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);hC=n(Ce,"LI",{});var cNe=s(hC);eMe=n(cNe,"STRONG",{});var Byt=s(eMe);VMr=r(Byt,"bert"),Byt.forEach(t),XMr=r(cNe," \u2014 "),yU=n(cNe,"A",{href:!0});var Iyt=s(yU);zMr=r(Iyt,"TFBertLMHeadModel"),Iyt.forEach(t),QMr=r(cNe," (BERT model)"),cNe.forEach(t),WMr=i(Ce),uC=n(Ce,"LI",{});var mNe=s(uC);oMe=n(mNe,"STRONG",{});var Nyt=s(oMe);HMr=r(Nyt,"camembert"),Nyt.forEach(t),UMr=r(mNe," \u2014 "),xU=n(mNe,"A",{href:!0});var qyt=s(xU);JMr=r(qyt,"TFCamembertForCausalLM"),qyt.forEach(t),YMr=r(mNe," (CamemBERT model)"),mNe.forEach(t),KMr=i(Ce),pC=n(Ce,"LI",{});var fNe=s(pC);rMe=n(fNe,"STRONG",{});var jyt=s(rMe);ZMr=r(jyt,"ctrl"),jyt.forEach(t),eEr=r(fNe," \u2014 "),$U=n(fNe,"A",{href:!0});var Dyt=s($U);oEr=r(Dyt,"TFCTRLLMHeadModel"),Dyt.forEach(t),rEr=r(fNe," (CTRL model)"),fNe.forEach(t),tEr=i(Ce),_C=n(Ce,"LI",{});var gNe=s(_C);tMe=n(gNe,"STRONG",{});var Gyt=s(tMe);aEr=r(Gyt,"gpt2"),Gyt.forEach(t),nEr=r(gNe," \u2014 "),kU=n(gNe,"A",{href:!0});var Oyt=s(kU);sEr=r(Oyt,"TFGPT2LMHeadModel"),Oyt.forEach(t),lEr=r(gNe," (OpenAI GPT-2 model)"),gNe.forEach(t),iEr=i(Ce),bC=n(Ce,"LI",{});var hNe=s(bC);aMe=n(hNe,"STRONG",{});var Vyt=s(aMe);dEr=r(Vyt,"gptj"),Vyt.forEach(t),cEr=r(hNe," \u2014 "),SU=n(hNe,"A",{href:!0});var Xyt=s(SU);mEr=r(Xyt,"TFGPTJForCausalLM"),Xyt.forEach(t),fEr=r(hNe," (GPT-J model)"),hNe.forEach(t),gEr=i(Ce),vC=n(Ce,"LI",{});var uNe=s(vC);nMe=n(uNe,"STRONG",{});var zyt=s(nMe);hEr=r(zyt,"openai-gpt"),zyt.forEach(t),uEr=r(uNe," \u2014 "),RU=n(uNe,"A",{href:!0});var Qyt=s(RU);pEr=r(Qyt,"TFOpenAIGPTLMHeadModel"),Qyt.forEach(t),_Er=r(uNe," (OpenAI GPT model)"),uNe.forEach(t),bEr=i(Ce),FC=n(Ce,"LI",{});var pNe=s(FC);sMe=n(pNe,"STRONG",{});var Wyt=s(sMe);vEr=r(Wyt,"opt"),Wyt.forEach(t),FEr=r(pNe," \u2014 "),PU=n(pNe,"A",{href:!0});var Hyt=s(PU);TEr=r(Hyt,"TFOPTForCausalLM"),Hyt.forEach(t),MEr=r(pNe," (OPT model)"),pNe.forEach(t),EEr=i(Ce),TC=n(Ce,"LI",{});var _Ne=s(TC);lMe=n(_Ne,"STRONG",{});var Uyt=s(lMe);CEr=r(Uyt,"rembert"),Uyt.forEach(t),wEr=r(_Ne," \u2014 "),BU=n(_Ne,"A",{href:!0});var Jyt=s(BU);AEr=r(Jyt,"TFRemBertForCausalLM"),Jyt.forEach(t),LEr=r(_Ne," (RemBERT model)"),_Ne.forEach(t),yEr=i(Ce),MC=n(Ce,"LI",{});var bNe=s(MC);iMe=n(bNe,"STRONG",{});var Yyt=s(iMe);xEr=r(Yyt,"roberta"),Yyt.forEach(t),$Er=r(bNe," \u2014 "),IU=n(bNe,"A",{href:!0});var Kyt=s(IU);kEr=r(Kyt,"TFRobertaForCausalLM"),Kyt.forEach(t),SEr=r(bNe," (RoBERTa model)"),bNe.forEach(t),REr=i(Ce),EC=n(Ce,"LI",{});var vNe=s(EC);dMe=n(vNe,"STRONG",{});var Zyt=s(dMe);PEr=r(Zyt,"roformer"),Zyt.forEach(t),BEr=r(vNe," \u2014 "),NU=n(vNe,"A",{href:!0});var e7t=s(NU);IEr=r(e7t,"TFRoFormerForCausalLM"),e7t.forEach(t),NEr=r(vNe," (RoFormer model)"),vNe.forEach(t),qEr=i(Ce),CC=n(Ce,"LI",{});var FNe=s(CC);cMe=n(FNe,"STRONG",{});var o7t=s(cMe);jEr=r(o7t,"transfo-xl"),o7t.forEach(t),DEr=r(FNe," \u2014 "),qU=n(FNe,"A",{href:!0});var r7t=s(qU);GEr=r(r7t,"TFTransfoXLLMHeadModel"),r7t.forEach(t),OEr=r(FNe," (Transformer-XL model)"),FNe.forEach(t),VEr=i(Ce),wC=n(Ce,"LI",{});var TNe=s(wC);mMe=n(TNe,"STRONG",{});var t7t=s(mMe);XEr=r(t7t,"xlm"),t7t.forEach(t),zEr=r(TNe," \u2014 "),jU=n(TNe,"A",{href:!0});var a7t=s(jU);QEr=r(a7t,"TFXLMWithLMHeadModel"),a7t.forEach(t),WEr=r(TNe," (XLM model)"),TNe.forEach(t),HEr=i(Ce),AC=n(Ce,"LI",{});var MNe=s(AC);fMe=n(MNe,"STRONG",{});var n7t=s(fMe);UEr=r(n7t,"xlnet"),n7t.forEach(t),JEr=r(MNe," \u2014 "),DU=n(MNe,"A",{href:!0});var s7t=s(DU);YEr=r(s7t,"TFXLNetLMHeadModel"),s7t.forEach(t),KEr=r(MNe," (XLNet model)"),MNe.forEach(t),Ce.forEach(t),ZEr=i(yl),T(LC.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),KOe=i(m),dc=n(m,"H2",{class:!0});var sze=s(dc);yC=n(sze,"A",{id:!0,class:!0,href:!0});var l7t=s(yC);gMe=n(l7t,"SPAN",{});var i7t=s(gMe);T($9.$$.fragment,i7t),i7t.forEach(t),l7t.forEach(t),e4r=i(sze),hMe=n(sze,"SPAN",{});var d7t=s(hMe);o4r=r(d7t,"TFAutoModelForImageClassification"),d7t.forEach(t),sze.forEach(t),ZOe=i(m),tr=n(m,"DIV",{class:!0});var xl=s(tr);T(k9.$$.fragment,xl),r4r=i(xl),cc=n(xl,"P",{});var Fre=s(cc);t4r=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=n(Fre,"A",{href:!0});var c7t=s(GU);a4r=r(c7t,"from_pretrained()"),c7t.forEach(t),n4r=r(Fre," class method or the "),OU=n(Fre,"A",{href:!0});var m7t=s(OU);s4r=r(m7t,"from_config()"),m7t.forEach(t),l4r=r(Fre,` class
method.`),Fre.forEach(t),i4r=i(xl),S9=n(xl,"P",{});var lze=s(S9);d4r=r(lze,"This class cannot be instantiated directly using "),uMe=n(lze,"CODE",{});var f7t=s(uMe);c4r=r(f7t,"__init__()"),f7t.forEach(t),m4r=r(lze," (throws an error)."),lze.forEach(t),f4r=i(xl),Rt=n(xl,"DIV",{class:!0});var SL=s(Rt);T(R9.$$.fragment,SL),g4r=i(SL),pMe=n(SL,"P",{});var g7t=s(pMe);h4r=r(g7t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),g7t.forEach(t),u4r=i(SL),mc=n(SL,"P",{});var Tre=s(mc);p4r=r(Tre,`Note:
Loading a model from its configuration file does `),_Me=n(Tre,"STRONG",{});var h7t=s(_Me);_4r=r(h7t,"not"),h7t.forEach(t),b4r=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Tre,"A",{href:!0});var u7t=s(VU);v4r=r(u7t,"from_pretrained()"),u7t.forEach(t),F4r=r(Tre," to load the model weights."),Tre.forEach(t),T4r=i(SL),T(xC.$$.fragment,SL),SL.forEach(t),M4r=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(P9.$$.fragment,$l),E4r=i($l),bMe=n($l,"P",{});var p7t=s(bMe);C4r=r(p7t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),p7t.forEach(t),w4r=i($l),ln=n($l,"P",{});var RL=s(ln);A4r=r(RL,"The model class to instantiate is selected based on the "),vMe=n(RL,"CODE",{});var _7t=s(vMe);L4r=r(_7t,"model_type"),_7t.forEach(t),y4r=r(RL,` property of the config object (either
passed as an argument or loaded from `),FMe=n(RL,"CODE",{});var b7t=s(FMe);x4r=r(b7t,"pretrained_model_name_or_path"),b7t.forEach(t),$4r=r(RL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TMe=n(RL,"CODE",{});var v7t=s(TMe);k4r=r(v7t,"pretrained_model_name_or_path"),v7t.forEach(t),S4r=r(RL,":"),RL.forEach(t),R4r=i($l),dn=n($l,"UL",{});var PL=s(dn);$C=n(PL,"LI",{});var ENe=s($C);MMe=n(ENe,"STRONG",{});var F7t=s(MMe);P4r=r(F7t,"convnext"),F7t.forEach(t),B4r=r(ENe," \u2014 "),XU=n(ENe,"A",{href:!0});var T7t=s(XU);I4r=r(T7t,"TFConvNextForImageClassification"),T7t.forEach(t),N4r=r(ENe," (ConvNeXT model)"),ENe.forEach(t),q4r=i(PL),kC=n(PL,"LI",{});var CNe=s(kC);EMe=n(CNe,"STRONG",{});var M7t=s(EMe);j4r=r(M7t,"data2vec-vision"),M7t.forEach(t),D4r=r(CNe," \u2014 "),zU=n(CNe,"A",{href:!0});var E7t=s(zU);G4r=r(E7t,"TFData2VecVisionForImageClassification"),E7t.forEach(t),O4r=r(CNe," (Data2VecVision model)"),CNe.forEach(t),V4r=i(PL),SC=n(PL,"LI",{});var wNe=s(SC);CMe=n(wNe,"STRONG",{});var C7t=s(CMe);X4r=r(C7t,"swin"),C7t.forEach(t),z4r=r(wNe," \u2014 "),QU=n(wNe,"A",{href:!0});var w7t=s(QU);Q4r=r(w7t,"TFSwinForImageClassification"),w7t.forEach(t),W4r=r(wNe," (Swin Transformer model)"),wNe.forEach(t),H4r=i(PL),RC=n(PL,"LI",{});var ANe=s(RC);wMe=n(ANe,"STRONG",{});var A7t=s(wMe);U4r=r(A7t,"vit"),A7t.forEach(t),J4r=r(ANe," \u2014 "),WU=n(ANe,"A",{href:!0});var L7t=s(WU);Y4r=r(L7t,"TFViTForImageClassification"),L7t.forEach(t),K4r=r(ANe," (ViT model)"),ANe.forEach(t),PL.forEach(t),Z4r=i($l),T(PC.$$.fragment,$l),$l.forEach(t),xl.forEach(t),eVe=i(m),fc=n(m,"H2",{class:!0});var ize=s(fc);BC=n(ize,"A",{id:!0,class:!0,href:!0});var y7t=s(BC);AMe=n(y7t,"SPAN",{});var x7t=s(AMe);T(B9.$$.fragment,x7t),x7t.forEach(t),y7t.forEach(t),eCr=i(ize),LMe=n(ize,"SPAN",{});var $7t=s(LMe);oCr=r($7t,"TFAutoModelForMaskedLM"),$7t.forEach(t),ize.forEach(t),oVe=i(m),ar=n(m,"DIV",{class:!0});var kl=s(ar);T(I9.$$.fragment,kl),rCr=i(kl),gc=n(kl,"P",{});var Mre=s(gc);tCr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=n(Mre,"A",{href:!0});var k7t=s(HU);aCr=r(k7t,"from_pretrained()"),k7t.forEach(t),nCr=r(Mre," class method or the "),UU=n(Mre,"A",{href:!0});var S7t=s(UU);sCr=r(S7t,"from_config()"),S7t.forEach(t),lCr=r(Mre,` class
method.`),Mre.forEach(t),iCr=i(kl),N9=n(kl,"P",{});var dze=s(N9);dCr=r(dze,"This class cannot be instantiated directly using "),yMe=n(dze,"CODE",{});var R7t=s(yMe);cCr=r(R7t,"__init__()"),R7t.forEach(t),mCr=r(dze," (throws an error)."),dze.forEach(t),fCr=i(kl),Pt=n(kl,"DIV",{class:!0});var BL=s(Pt);T(q9.$$.fragment,BL),gCr=i(BL),xMe=n(BL,"P",{});var P7t=s(xMe);hCr=r(P7t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),P7t.forEach(t),uCr=i(BL),hc=n(BL,"P",{});var Ere=s(hc);pCr=r(Ere,`Note:
Loading a model from its configuration file does `),$Me=n(Ere,"STRONG",{});var B7t=s($Me);_Cr=r(B7t,"not"),B7t.forEach(t),bCr=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=n(Ere,"A",{href:!0});var I7t=s(JU);vCr=r(I7t,"from_pretrained()"),I7t.forEach(t),FCr=r(Ere," to load the model weights."),Ere.forEach(t),TCr=i(BL),T(IC.$$.fragment,BL),BL.forEach(t),MCr=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(j9.$$.fragment,Sl),ECr=i(Sl),kMe=n(Sl,"P",{});var N7t=s(kMe);CCr=r(N7t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),N7t.forEach(t),wCr=i(Sl),cn=n(Sl,"P",{});var IL=s(cn);ACr=r(IL,"The model class to instantiate is selected based on the "),SMe=n(IL,"CODE",{});var q7t=s(SMe);LCr=r(q7t,"model_type"),q7t.forEach(t),yCr=r(IL,` property of the config object (either
passed as an argument or loaded from `),RMe=n(IL,"CODE",{});var j7t=s(RMe);xCr=r(j7t,"pretrained_model_name_or_path"),j7t.forEach(t),$Cr=r(IL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PMe=n(IL,"CODE",{});var D7t=s(PMe);kCr=r(D7t,"pretrained_model_name_or_path"),D7t.forEach(t),SCr=r(IL,":"),IL.forEach(t),RCr=i(Sl),ie=n(Sl,"UL",{});var me=s(ie);NC=n(me,"LI",{});var LNe=s(NC);BMe=n(LNe,"STRONG",{});var G7t=s(BMe);PCr=r(G7t,"albert"),G7t.forEach(t),BCr=r(LNe," \u2014 "),YU=n(LNe,"A",{href:!0});var O7t=s(YU);ICr=r(O7t,"TFAlbertForMaskedLM"),O7t.forEach(t),NCr=r(LNe," (ALBERT model)"),LNe.forEach(t),qCr=i(me),qC=n(me,"LI",{});var yNe=s(qC);IMe=n(yNe,"STRONG",{});var V7t=s(IMe);jCr=r(V7t,"bert"),V7t.forEach(t),DCr=r(yNe," \u2014 "),KU=n(yNe,"A",{href:!0});var X7t=s(KU);GCr=r(X7t,"TFBertForMaskedLM"),X7t.forEach(t),OCr=r(yNe," (BERT model)"),yNe.forEach(t),VCr=i(me),jC=n(me,"LI",{});var xNe=s(jC);NMe=n(xNe,"STRONG",{});var z7t=s(NMe);XCr=r(z7t,"camembert"),z7t.forEach(t),zCr=r(xNe," \u2014 "),ZU=n(xNe,"A",{href:!0});var Q7t=s(ZU);QCr=r(Q7t,"TFCamembertForMaskedLM"),Q7t.forEach(t),WCr=r(xNe," (CamemBERT model)"),xNe.forEach(t),HCr=i(me),DC=n(me,"LI",{});var $Ne=s(DC);qMe=n($Ne,"STRONG",{});var W7t=s(qMe);UCr=r(W7t,"convbert"),W7t.forEach(t),JCr=r($Ne," \u2014 "),eJ=n($Ne,"A",{href:!0});var H7t=s(eJ);YCr=r(H7t,"TFConvBertForMaskedLM"),H7t.forEach(t),KCr=r($Ne," (ConvBERT model)"),$Ne.forEach(t),ZCr=i(me),GC=n(me,"LI",{});var kNe=s(GC);jMe=n(kNe,"STRONG",{});var U7t=s(jMe);e5r=r(U7t,"deberta"),U7t.forEach(t),o5r=r(kNe," \u2014 "),oJ=n(kNe,"A",{href:!0});var J7t=s(oJ);r5r=r(J7t,"TFDebertaForMaskedLM"),J7t.forEach(t),t5r=r(kNe," (DeBERTa model)"),kNe.forEach(t),a5r=i(me),OC=n(me,"LI",{});var SNe=s(OC);DMe=n(SNe,"STRONG",{});var Y7t=s(DMe);n5r=r(Y7t,"deberta-v2"),Y7t.forEach(t),s5r=r(SNe," \u2014 "),rJ=n(SNe,"A",{href:!0});var K7t=s(rJ);l5r=r(K7t,"TFDebertaV2ForMaskedLM"),K7t.forEach(t),i5r=r(SNe," (DeBERTa-v2 model)"),SNe.forEach(t),d5r=i(me),VC=n(me,"LI",{});var RNe=s(VC);GMe=n(RNe,"STRONG",{});var Z7t=s(GMe);c5r=r(Z7t,"distilbert"),Z7t.forEach(t),m5r=r(RNe," \u2014 "),tJ=n(RNe,"A",{href:!0});var e8t=s(tJ);f5r=r(e8t,"TFDistilBertForMaskedLM"),e8t.forEach(t),g5r=r(RNe," (DistilBERT model)"),RNe.forEach(t),h5r=i(me),XC=n(me,"LI",{});var PNe=s(XC);OMe=n(PNe,"STRONG",{});var o8t=s(OMe);u5r=r(o8t,"electra"),o8t.forEach(t),p5r=r(PNe," \u2014 "),aJ=n(PNe,"A",{href:!0});var r8t=s(aJ);_5r=r(r8t,"TFElectraForMaskedLM"),r8t.forEach(t),b5r=r(PNe," (ELECTRA model)"),PNe.forEach(t),v5r=i(me),zC=n(me,"LI",{});var BNe=s(zC);VMe=n(BNe,"STRONG",{});var t8t=s(VMe);F5r=r(t8t,"flaubert"),t8t.forEach(t),T5r=r(BNe," \u2014 "),nJ=n(BNe,"A",{href:!0});var a8t=s(nJ);M5r=r(a8t,"TFFlaubertWithLMHeadModel"),a8t.forEach(t),E5r=r(BNe," (FlauBERT model)"),BNe.forEach(t),C5r=i(me),QC=n(me,"LI",{});var INe=s(QC);XMe=n(INe,"STRONG",{});var n8t=s(XMe);w5r=r(n8t,"funnel"),n8t.forEach(t),A5r=r(INe," \u2014 "),sJ=n(INe,"A",{href:!0});var s8t=s(sJ);L5r=r(s8t,"TFFunnelForMaskedLM"),s8t.forEach(t),y5r=r(INe," (Funnel Transformer model)"),INe.forEach(t),x5r=i(me),WC=n(me,"LI",{});var NNe=s(WC);zMe=n(NNe,"STRONG",{});var l8t=s(zMe);$5r=r(l8t,"layoutlm"),l8t.forEach(t),k5r=r(NNe," \u2014 "),lJ=n(NNe,"A",{href:!0});var i8t=s(lJ);S5r=r(i8t,"TFLayoutLMForMaskedLM"),i8t.forEach(t),R5r=r(NNe," (LayoutLM model)"),NNe.forEach(t),P5r=i(me),HC=n(me,"LI",{});var qNe=s(HC);QMe=n(qNe,"STRONG",{});var d8t=s(QMe);B5r=r(d8t,"longformer"),d8t.forEach(t),I5r=r(qNe," \u2014 "),iJ=n(qNe,"A",{href:!0});var c8t=s(iJ);N5r=r(c8t,"TFLongformerForMaskedLM"),c8t.forEach(t),q5r=r(qNe," (Longformer model)"),qNe.forEach(t),j5r=i(me),UC=n(me,"LI",{});var jNe=s(UC);WMe=n(jNe,"STRONG",{});var m8t=s(WMe);D5r=r(m8t,"mobilebert"),m8t.forEach(t),G5r=r(jNe," \u2014 "),dJ=n(jNe,"A",{href:!0});var f8t=s(dJ);O5r=r(f8t,"TFMobileBertForMaskedLM"),f8t.forEach(t),V5r=r(jNe," (MobileBERT model)"),jNe.forEach(t),X5r=i(me),JC=n(me,"LI",{});var DNe=s(JC);HMe=n(DNe,"STRONG",{});var g8t=s(HMe);z5r=r(g8t,"mpnet"),g8t.forEach(t),Q5r=r(DNe," \u2014 "),cJ=n(DNe,"A",{href:!0});var h8t=s(cJ);W5r=r(h8t,"TFMPNetForMaskedLM"),h8t.forEach(t),H5r=r(DNe," (MPNet model)"),DNe.forEach(t),U5r=i(me),YC=n(me,"LI",{});var GNe=s(YC);UMe=n(GNe,"STRONG",{});var u8t=s(UMe);J5r=r(u8t,"rembert"),u8t.forEach(t),Y5r=r(GNe," \u2014 "),mJ=n(GNe,"A",{href:!0});var p8t=s(mJ);K5r=r(p8t,"TFRemBertForMaskedLM"),p8t.forEach(t),Z5r=r(GNe," (RemBERT model)"),GNe.forEach(t),e3r=i(me),KC=n(me,"LI",{});var ONe=s(KC);JMe=n(ONe,"STRONG",{});var _8t=s(JMe);o3r=r(_8t,"roberta"),_8t.forEach(t),r3r=r(ONe," \u2014 "),fJ=n(ONe,"A",{href:!0});var b8t=s(fJ);t3r=r(b8t,"TFRobertaForMaskedLM"),b8t.forEach(t),a3r=r(ONe," (RoBERTa model)"),ONe.forEach(t),n3r=i(me),ZC=n(me,"LI",{});var VNe=s(ZC);YMe=n(VNe,"STRONG",{});var v8t=s(YMe);s3r=r(v8t,"roformer"),v8t.forEach(t),l3r=r(VNe," \u2014 "),gJ=n(VNe,"A",{href:!0});var F8t=s(gJ);i3r=r(F8t,"TFRoFormerForMaskedLM"),F8t.forEach(t),d3r=r(VNe," (RoFormer model)"),VNe.forEach(t),c3r=i(me),e5=n(me,"LI",{});var XNe=s(e5);KMe=n(XNe,"STRONG",{});var T8t=s(KMe);m3r=r(T8t,"tapas"),T8t.forEach(t),f3r=r(XNe," \u2014 "),hJ=n(XNe,"A",{href:!0});var M8t=s(hJ);g3r=r(M8t,"TFTapasForMaskedLM"),M8t.forEach(t),h3r=r(XNe," (TAPAS model)"),XNe.forEach(t),u3r=i(me),o5=n(me,"LI",{});var zNe=s(o5);ZMe=n(zNe,"STRONG",{});var E8t=s(ZMe);p3r=r(E8t,"xlm"),E8t.forEach(t),_3r=r(zNe," \u2014 "),uJ=n(zNe,"A",{href:!0});var C8t=s(uJ);b3r=r(C8t,"TFXLMWithLMHeadModel"),C8t.forEach(t),v3r=r(zNe," (XLM model)"),zNe.forEach(t),F3r=i(me),r5=n(me,"LI",{});var QNe=s(r5);eEe=n(QNe,"STRONG",{});var w8t=s(eEe);T3r=r(w8t,"xlm-roberta"),w8t.forEach(t),M3r=r(QNe," \u2014 "),pJ=n(QNe,"A",{href:!0});var A8t=s(pJ);E3r=r(A8t,"TFXLMRobertaForMaskedLM"),A8t.forEach(t),C3r=r(QNe," (XLM-RoBERTa model)"),QNe.forEach(t),me.forEach(t),w3r=i(Sl),T(t5.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),rVe=i(m),uc=n(m,"H2",{class:!0});var cze=s(uc);a5=n(cze,"A",{id:!0,class:!0,href:!0});var L8t=s(a5);oEe=n(L8t,"SPAN",{});var y8t=s(oEe);T(D9.$$.fragment,y8t),y8t.forEach(t),L8t.forEach(t),A3r=i(cze),rEe=n(cze,"SPAN",{});var x8t=s(rEe);L3r=r(x8t,"TFAutoModelForSeq2SeqLM"),x8t.forEach(t),cze.forEach(t),tVe=i(m),nr=n(m,"DIV",{class:!0});var Rl=s(nr);T(G9.$$.fragment,Rl),y3r=i(Rl),pc=n(Rl,"P",{});var Cre=s(pc);x3r=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_J=n(Cre,"A",{href:!0});var $8t=s(_J);$3r=r($8t,"from_pretrained()"),$8t.forEach(t),k3r=r(Cre," class method or the "),bJ=n(Cre,"A",{href:!0});var k8t=s(bJ);S3r=r(k8t,"from_config()"),k8t.forEach(t),R3r=r(Cre,` class
method.`),Cre.forEach(t),P3r=i(Rl),O9=n(Rl,"P",{});var mze=s(O9);B3r=r(mze,"This class cannot be instantiated directly using "),tEe=n(mze,"CODE",{});var S8t=s(tEe);I3r=r(S8t,"__init__()"),S8t.forEach(t),N3r=r(mze," (throws an error)."),mze.forEach(t),q3r=i(Rl),Bt=n(Rl,"DIV",{class:!0});var NL=s(Bt);T(V9.$$.fragment,NL),j3r=i(NL),aEe=n(NL,"P",{});var R8t=s(aEe);D3r=r(R8t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),R8t.forEach(t),G3r=i(NL),_c=n(NL,"P",{});var wre=s(_c);O3r=r(wre,`Note:
Loading a model from its configuration file does `),nEe=n(wre,"STRONG",{});var P8t=s(nEe);V3r=r(P8t,"not"),P8t.forEach(t),X3r=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(wre,"A",{href:!0});var B8t=s(vJ);z3r=r(B8t,"from_pretrained()"),B8t.forEach(t),Q3r=r(wre," to load the model weights."),wre.forEach(t),W3r=i(NL),T(n5.$$.fragment,NL),NL.forEach(t),H3r=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(X9.$$.fragment,Pl),U3r=i(Pl),sEe=n(Pl,"P",{});var I8t=s(sEe);J3r=r(I8t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),I8t.forEach(t),Y3r=i(Pl),mn=n(Pl,"P",{});var qL=s(mn);K3r=r(qL,"The model class to instantiate is selected based on the "),lEe=n(qL,"CODE",{});var N8t=s(lEe);Z3r=r(N8t,"model_type"),N8t.forEach(t),e0r=r(qL,` property of the config object (either
passed as an argument or loaded from `),iEe=n(qL,"CODE",{});var q8t=s(iEe);o0r=r(q8t,"pretrained_model_name_or_path"),q8t.forEach(t),r0r=r(qL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dEe=n(qL,"CODE",{});var j8t=s(dEe);t0r=r(j8t,"pretrained_model_name_or_path"),j8t.forEach(t),a0r=r(qL,":"),qL.forEach(t),n0r=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);s5=n(Ie,"LI",{});var WNe=s(s5);cEe=n(WNe,"STRONG",{});var D8t=s(cEe);s0r=r(D8t,"bart"),D8t.forEach(t),l0r=r(WNe," \u2014 "),FJ=n(WNe,"A",{href:!0});var G8t=s(FJ);i0r=r(G8t,"TFBartForConditionalGeneration"),G8t.forEach(t),d0r=r(WNe," (BART model)"),WNe.forEach(t),c0r=i(Ie),l5=n(Ie,"LI",{});var HNe=s(l5);mEe=n(HNe,"STRONG",{});var O8t=s(mEe);m0r=r(O8t,"blenderbot"),O8t.forEach(t),f0r=r(HNe," \u2014 "),TJ=n(HNe,"A",{href:!0});var V8t=s(TJ);g0r=r(V8t,"TFBlenderbotForConditionalGeneration"),V8t.forEach(t),h0r=r(HNe," (Blenderbot model)"),HNe.forEach(t),u0r=i(Ie),i5=n(Ie,"LI",{});var UNe=s(i5);fEe=n(UNe,"STRONG",{});var X8t=s(fEe);p0r=r(X8t,"blenderbot-small"),X8t.forEach(t),_0r=r(UNe," \u2014 "),MJ=n(UNe,"A",{href:!0});var z8t=s(MJ);b0r=r(z8t,"TFBlenderbotSmallForConditionalGeneration"),z8t.forEach(t),v0r=r(UNe," (BlenderbotSmall model)"),UNe.forEach(t),F0r=i(Ie),d5=n(Ie,"LI",{});var JNe=s(d5);gEe=n(JNe,"STRONG",{});var Q8t=s(gEe);T0r=r(Q8t,"encoder-decoder"),Q8t.forEach(t),M0r=r(JNe," \u2014 "),EJ=n(JNe,"A",{href:!0});var W8t=s(EJ);E0r=r(W8t,"TFEncoderDecoderModel"),W8t.forEach(t),C0r=r(JNe," (Encoder decoder model)"),JNe.forEach(t),w0r=i(Ie),c5=n(Ie,"LI",{});var YNe=s(c5);hEe=n(YNe,"STRONG",{});var H8t=s(hEe);A0r=r(H8t,"led"),H8t.forEach(t),L0r=r(YNe," \u2014 "),CJ=n(YNe,"A",{href:!0});var U8t=s(CJ);y0r=r(U8t,"TFLEDForConditionalGeneration"),U8t.forEach(t),x0r=r(YNe," (LED model)"),YNe.forEach(t),$0r=i(Ie),m5=n(Ie,"LI",{});var KNe=s(m5);uEe=n(KNe,"STRONG",{});var J8t=s(uEe);k0r=r(J8t,"marian"),J8t.forEach(t),S0r=r(KNe," \u2014 "),wJ=n(KNe,"A",{href:!0});var Y8t=s(wJ);R0r=r(Y8t,"TFMarianMTModel"),Y8t.forEach(t),P0r=r(KNe," (Marian model)"),KNe.forEach(t),B0r=i(Ie),f5=n(Ie,"LI",{});var ZNe=s(f5);pEe=n(ZNe,"STRONG",{});var K8t=s(pEe);I0r=r(K8t,"mbart"),K8t.forEach(t),N0r=r(ZNe," \u2014 "),AJ=n(ZNe,"A",{href:!0});var Z8t=s(AJ);q0r=r(Z8t,"TFMBartForConditionalGeneration"),Z8t.forEach(t),j0r=r(ZNe," (mBART model)"),ZNe.forEach(t),D0r=i(Ie),g5=n(Ie,"LI",{});var eqe=s(g5);_Ee=n(eqe,"STRONG",{});var e9t=s(_Ee);G0r=r(e9t,"mt5"),e9t.forEach(t),O0r=r(eqe," \u2014 "),LJ=n(eqe,"A",{href:!0});var o9t=s(LJ);V0r=r(o9t,"TFMT5ForConditionalGeneration"),o9t.forEach(t),X0r=r(eqe," (MT5 model)"),eqe.forEach(t),z0r=i(Ie),h5=n(Ie,"LI",{});var oqe=s(h5);bEe=n(oqe,"STRONG",{});var r9t=s(bEe);Q0r=r(r9t,"pegasus"),r9t.forEach(t),W0r=r(oqe," \u2014 "),yJ=n(oqe,"A",{href:!0});var t9t=s(yJ);H0r=r(t9t,"TFPegasusForConditionalGeneration"),t9t.forEach(t),U0r=r(oqe," (Pegasus model)"),oqe.forEach(t),J0r=i(Ie),u5=n(Ie,"LI",{});var rqe=s(u5);vEe=n(rqe,"STRONG",{});var a9t=s(vEe);Y0r=r(a9t,"t5"),a9t.forEach(t),K0r=r(rqe," \u2014 "),xJ=n(rqe,"A",{href:!0});var n9t=s(xJ);Z0r=r(n9t,"TFT5ForConditionalGeneration"),n9t.forEach(t),ewr=r(rqe," (T5 model)"),rqe.forEach(t),Ie.forEach(t),owr=i(Pl),T(p5.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),aVe=i(m),bc=n(m,"H2",{class:!0});var fze=s(bc);_5=n(fze,"A",{id:!0,class:!0,href:!0});var s9t=s(_5);FEe=n(s9t,"SPAN",{});var l9t=s(FEe);T(z9.$$.fragment,l9t),l9t.forEach(t),s9t.forEach(t),rwr=i(fze),TEe=n(fze,"SPAN",{});var i9t=s(TEe);twr=r(i9t,"TFAutoModelForSequenceClassification"),i9t.forEach(t),fze.forEach(t),nVe=i(m),sr=n(m,"DIV",{class:!0});var Bl=s(sr);T(Q9.$$.fragment,Bl),awr=i(Bl),vc=n(Bl,"P",{});var Are=s(vc);nwr=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=n(Are,"A",{href:!0});var d9t=s($J);swr=r(d9t,"from_pretrained()"),d9t.forEach(t),lwr=r(Are," class method or the "),kJ=n(Are,"A",{href:!0});var c9t=s(kJ);iwr=r(c9t,"from_config()"),c9t.forEach(t),dwr=r(Are,` class
method.`),Are.forEach(t),cwr=i(Bl),W9=n(Bl,"P",{});var gze=s(W9);mwr=r(gze,"This class cannot be instantiated directly using "),MEe=n(gze,"CODE",{});var m9t=s(MEe);fwr=r(m9t,"__init__()"),m9t.forEach(t),gwr=r(gze," (throws an error)."),gze.forEach(t),hwr=i(Bl),It=n(Bl,"DIV",{class:!0});var jL=s(It);T(H9.$$.fragment,jL),uwr=i(jL),EEe=n(jL,"P",{});var f9t=s(EEe);pwr=r(f9t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),f9t.forEach(t),_wr=i(jL),Fc=n(jL,"P",{});var Lre=s(Fc);bwr=r(Lre,`Note:
Loading a model from its configuration file does `),CEe=n(Lre,"STRONG",{});var g9t=s(CEe);vwr=r(g9t,"not"),g9t.forEach(t),Fwr=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(Lre,"A",{href:!0});var h9t=s(SJ);Twr=r(h9t,"from_pretrained()"),h9t.forEach(t),Mwr=r(Lre," to load the model weights."),Lre.forEach(t),Ewr=i(jL),T(b5.$$.fragment,jL),jL.forEach(t),Cwr=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(U9.$$.fragment,Il),wwr=i(Il),wEe=n(Il,"P",{});var u9t=s(wEe);Awr=r(u9t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),u9t.forEach(t),Lwr=i(Il),fn=n(Il,"P",{});var DL=s(fn);ywr=r(DL,"The model class to instantiate is selected based on the "),AEe=n(DL,"CODE",{});var p9t=s(AEe);xwr=r(p9t,"model_type"),p9t.forEach(t),$wr=r(DL,` property of the config object (either
passed as an argument or loaded from `),LEe=n(DL,"CODE",{});var _9t=s(LEe);kwr=r(_9t,"pretrained_model_name_or_path"),_9t.forEach(t),Swr=r(DL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yEe=n(DL,"CODE",{});var b9t=s(yEe);Rwr=r(b9t,"pretrained_model_name_or_path"),b9t.forEach(t),Pwr=r(DL,":"),DL.forEach(t),Bwr=i(Il),te=n(Il,"UL",{});var ne=s(te);v5=n(ne,"LI",{});var tqe=s(v5);xEe=n(tqe,"STRONG",{});var v9t=s(xEe);Iwr=r(v9t,"albert"),v9t.forEach(t),Nwr=r(tqe," \u2014 "),RJ=n(tqe,"A",{href:!0});var F9t=s(RJ);qwr=r(F9t,"TFAlbertForSequenceClassification"),F9t.forEach(t),jwr=r(tqe," (ALBERT model)"),tqe.forEach(t),Dwr=i(ne),F5=n(ne,"LI",{});var aqe=s(F5);$Ee=n(aqe,"STRONG",{});var T9t=s($Ee);Gwr=r(T9t,"bert"),T9t.forEach(t),Owr=r(aqe," \u2014 "),PJ=n(aqe,"A",{href:!0});var M9t=s(PJ);Vwr=r(M9t,"TFBertForSequenceClassification"),M9t.forEach(t),Xwr=r(aqe," (BERT model)"),aqe.forEach(t),zwr=i(ne),T5=n(ne,"LI",{});var nqe=s(T5);kEe=n(nqe,"STRONG",{});var E9t=s(kEe);Qwr=r(E9t,"camembert"),E9t.forEach(t),Wwr=r(nqe," \u2014 "),BJ=n(nqe,"A",{href:!0});var C9t=s(BJ);Hwr=r(C9t,"TFCamembertForSequenceClassification"),C9t.forEach(t),Uwr=r(nqe," (CamemBERT model)"),nqe.forEach(t),Jwr=i(ne),M5=n(ne,"LI",{});var sqe=s(M5);SEe=n(sqe,"STRONG",{});var w9t=s(SEe);Ywr=r(w9t,"convbert"),w9t.forEach(t),Kwr=r(sqe," \u2014 "),IJ=n(sqe,"A",{href:!0});var A9t=s(IJ);Zwr=r(A9t,"TFConvBertForSequenceClassification"),A9t.forEach(t),eAr=r(sqe," (ConvBERT model)"),sqe.forEach(t),oAr=i(ne),E5=n(ne,"LI",{});var lqe=s(E5);REe=n(lqe,"STRONG",{});var L9t=s(REe);rAr=r(L9t,"ctrl"),L9t.forEach(t),tAr=r(lqe," \u2014 "),NJ=n(lqe,"A",{href:!0});var y9t=s(NJ);aAr=r(y9t,"TFCTRLForSequenceClassification"),y9t.forEach(t),nAr=r(lqe," (CTRL model)"),lqe.forEach(t),sAr=i(ne),C5=n(ne,"LI",{});var iqe=s(C5);PEe=n(iqe,"STRONG",{});var x9t=s(PEe);lAr=r(x9t,"deberta"),x9t.forEach(t),iAr=r(iqe," \u2014 "),qJ=n(iqe,"A",{href:!0});var $9t=s(qJ);dAr=r($9t,"TFDebertaForSequenceClassification"),$9t.forEach(t),cAr=r(iqe," (DeBERTa model)"),iqe.forEach(t),mAr=i(ne),w5=n(ne,"LI",{});var dqe=s(w5);BEe=n(dqe,"STRONG",{});var k9t=s(BEe);fAr=r(k9t,"deberta-v2"),k9t.forEach(t),gAr=r(dqe," \u2014 "),jJ=n(dqe,"A",{href:!0});var S9t=s(jJ);hAr=r(S9t,"TFDebertaV2ForSequenceClassification"),S9t.forEach(t),uAr=r(dqe," (DeBERTa-v2 model)"),dqe.forEach(t),pAr=i(ne),A5=n(ne,"LI",{});var cqe=s(A5);IEe=n(cqe,"STRONG",{});var R9t=s(IEe);_Ar=r(R9t,"distilbert"),R9t.forEach(t),bAr=r(cqe," \u2014 "),DJ=n(cqe,"A",{href:!0});var P9t=s(DJ);vAr=r(P9t,"TFDistilBertForSequenceClassification"),P9t.forEach(t),FAr=r(cqe," (DistilBERT model)"),cqe.forEach(t),TAr=i(ne),L5=n(ne,"LI",{});var mqe=s(L5);NEe=n(mqe,"STRONG",{});var B9t=s(NEe);MAr=r(B9t,"electra"),B9t.forEach(t),EAr=r(mqe," \u2014 "),GJ=n(mqe,"A",{href:!0});var I9t=s(GJ);CAr=r(I9t,"TFElectraForSequenceClassification"),I9t.forEach(t),wAr=r(mqe," (ELECTRA model)"),mqe.forEach(t),AAr=i(ne),y5=n(ne,"LI",{});var fqe=s(y5);qEe=n(fqe,"STRONG",{});var N9t=s(qEe);LAr=r(N9t,"flaubert"),N9t.forEach(t),yAr=r(fqe," \u2014 "),OJ=n(fqe,"A",{href:!0});var q9t=s(OJ);xAr=r(q9t,"TFFlaubertForSequenceClassification"),q9t.forEach(t),$Ar=r(fqe," (FlauBERT model)"),fqe.forEach(t),kAr=i(ne),x5=n(ne,"LI",{});var gqe=s(x5);jEe=n(gqe,"STRONG",{});var j9t=s(jEe);SAr=r(j9t,"funnel"),j9t.forEach(t),RAr=r(gqe," \u2014 "),VJ=n(gqe,"A",{href:!0});var D9t=s(VJ);PAr=r(D9t,"TFFunnelForSequenceClassification"),D9t.forEach(t),BAr=r(gqe," (Funnel Transformer model)"),gqe.forEach(t),IAr=i(ne),$5=n(ne,"LI",{});var hqe=s($5);DEe=n(hqe,"STRONG",{});var G9t=s(DEe);NAr=r(G9t,"gpt2"),G9t.forEach(t),qAr=r(hqe," \u2014 "),XJ=n(hqe,"A",{href:!0});var O9t=s(XJ);jAr=r(O9t,"TFGPT2ForSequenceClassification"),O9t.forEach(t),DAr=r(hqe," (OpenAI GPT-2 model)"),hqe.forEach(t),GAr=i(ne),k5=n(ne,"LI",{});var uqe=s(k5);GEe=n(uqe,"STRONG",{});var V9t=s(GEe);OAr=r(V9t,"gptj"),V9t.forEach(t),VAr=r(uqe," \u2014 "),zJ=n(uqe,"A",{href:!0});var X9t=s(zJ);XAr=r(X9t,"TFGPTJForSequenceClassification"),X9t.forEach(t),zAr=r(uqe," (GPT-J model)"),uqe.forEach(t),QAr=i(ne),S5=n(ne,"LI",{});var pqe=s(S5);OEe=n(pqe,"STRONG",{});var z9t=s(OEe);WAr=r(z9t,"layoutlm"),z9t.forEach(t),HAr=r(pqe," \u2014 "),QJ=n(pqe,"A",{href:!0});var Q9t=s(QJ);UAr=r(Q9t,"TFLayoutLMForSequenceClassification"),Q9t.forEach(t),JAr=r(pqe," (LayoutLM model)"),pqe.forEach(t),YAr=i(ne),R5=n(ne,"LI",{});var _qe=s(R5);VEe=n(_qe,"STRONG",{});var W9t=s(VEe);KAr=r(W9t,"longformer"),W9t.forEach(t),ZAr=r(_qe," \u2014 "),WJ=n(_qe,"A",{href:!0});var H9t=s(WJ);e6r=r(H9t,"TFLongformerForSequenceClassification"),H9t.forEach(t),o6r=r(_qe," (Longformer model)"),_qe.forEach(t),r6r=i(ne),P5=n(ne,"LI",{});var bqe=s(P5);XEe=n(bqe,"STRONG",{});var U9t=s(XEe);t6r=r(U9t,"mobilebert"),U9t.forEach(t),a6r=r(bqe," \u2014 "),HJ=n(bqe,"A",{href:!0});var J9t=s(HJ);n6r=r(J9t,"TFMobileBertForSequenceClassification"),J9t.forEach(t),s6r=r(bqe," (MobileBERT model)"),bqe.forEach(t),l6r=i(ne),B5=n(ne,"LI",{});var vqe=s(B5);zEe=n(vqe,"STRONG",{});var Y9t=s(zEe);i6r=r(Y9t,"mpnet"),Y9t.forEach(t),d6r=r(vqe," \u2014 "),UJ=n(vqe,"A",{href:!0});var K9t=s(UJ);c6r=r(K9t,"TFMPNetForSequenceClassification"),K9t.forEach(t),m6r=r(vqe," (MPNet model)"),vqe.forEach(t),f6r=i(ne),I5=n(ne,"LI",{});var Fqe=s(I5);QEe=n(Fqe,"STRONG",{});var Z9t=s(QEe);g6r=r(Z9t,"openai-gpt"),Z9t.forEach(t),h6r=r(Fqe," \u2014 "),JJ=n(Fqe,"A",{href:!0});var ext=s(JJ);u6r=r(ext,"TFOpenAIGPTForSequenceClassification"),ext.forEach(t),p6r=r(Fqe," (OpenAI GPT model)"),Fqe.forEach(t),_6r=i(ne),N5=n(ne,"LI",{});var Tqe=s(N5);WEe=n(Tqe,"STRONG",{});var oxt=s(WEe);b6r=r(oxt,"rembert"),oxt.forEach(t),v6r=r(Tqe," \u2014 "),YJ=n(Tqe,"A",{href:!0});var rxt=s(YJ);F6r=r(rxt,"TFRemBertForSequenceClassification"),rxt.forEach(t),T6r=r(Tqe," (RemBERT model)"),Tqe.forEach(t),M6r=i(ne),q5=n(ne,"LI",{});var Mqe=s(q5);HEe=n(Mqe,"STRONG",{});var txt=s(HEe);E6r=r(txt,"roberta"),txt.forEach(t),C6r=r(Mqe," \u2014 "),KJ=n(Mqe,"A",{href:!0});var axt=s(KJ);w6r=r(axt,"TFRobertaForSequenceClassification"),axt.forEach(t),A6r=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),L6r=i(ne),j5=n(ne,"LI",{});var Eqe=s(j5);UEe=n(Eqe,"STRONG",{});var nxt=s(UEe);y6r=r(nxt,"roformer"),nxt.forEach(t),x6r=r(Eqe," \u2014 "),ZJ=n(Eqe,"A",{href:!0});var sxt=s(ZJ);$6r=r(sxt,"TFRoFormerForSequenceClassification"),sxt.forEach(t),k6r=r(Eqe," (RoFormer model)"),Eqe.forEach(t),S6r=i(ne),D5=n(ne,"LI",{});var Cqe=s(D5);JEe=n(Cqe,"STRONG",{});var lxt=s(JEe);R6r=r(lxt,"tapas"),lxt.forEach(t),P6r=r(Cqe," \u2014 "),eY=n(Cqe,"A",{href:!0});var ixt=s(eY);B6r=r(ixt,"TFTapasForSequenceClassification"),ixt.forEach(t),I6r=r(Cqe," (TAPAS model)"),Cqe.forEach(t),N6r=i(ne),G5=n(ne,"LI",{});var wqe=s(G5);YEe=n(wqe,"STRONG",{});var dxt=s(YEe);q6r=r(dxt,"transfo-xl"),dxt.forEach(t),j6r=r(wqe," \u2014 "),oY=n(wqe,"A",{href:!0});var cxt=s(oY);D6r=r(cxt,"TFTransfoXLForSequenceClassification"),cxt.forEach(t),G6r=r(wqe," (Transformer-XL model)"),wqe.forEach(t),O6r=i(ne),O5=n(ne,"LI",{});var Aqe=s(O5);KEe=n(Aqe,"STRONG",{});var mxt=s(KEe);V6r=r(mxt,"xlm"),mxt.forEach(t),X6r=r(Aqe," \u2014 "),rY=n(Aqe,"A",{href:!0});var fxt=s(rY);z6r=r(fxt,"TFXLMForSequenceClassification"),fxt.forEach(t),Q6r=r(Aqe," (XLM model)"),Aqe.forEach(t),W6r=i(ne),V5=n(ne,"LI",{});var Lqe=s(V5);ZEe=n(Lqe,"STRONG",{});var gxt=s(ZEe);H6r=r(gxt,"xlm-roberta"),gxt.forEach(t),U6r=r(Lqe," \u2014 "),tY=n(Lqe,"A",{href:!0});var hxt=s(tY);J6r=r(hxt,"TFXLMRobertaForSequenceClassification"),hxt.forEach(t),Y6r=r(Lqe," (XLM-RoBERTa model)"),Lqe.forEach(t),K6r=i(ne),X5=n(ne,"LI",{});var yqe=s(X5);e4e=n(yqe,"STRONG",{});var uxt=s(e4e);Z6r=r(uxt,"xlnet"),uxt.forEach(t),eLr=r(yqe," \u2014 "),aY=n(yqe,"A",{href:!0});var pxt=s(aY);oLr=r(pxt,"TFXLNetForSequenceClassification"),pxt.forEach(t),rLr=r(yqe," (XLNet model)"),yqe.forEach(t),ne.forEach(t),tLr=i(Il),T(z5.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),sVe=i(m),Tc=n(m,"H2",{class:!0});var hze=s(Tc);Q5=n(hze,"A",{id:!0,class:!0,href:!0});var _xt=s(Q5);o4e=n(_xt,"SPAN",{});var bxt=s(o4e);T(J9.$$.fragment,bxt),bxt.forEach(t),_xt.forEach(t),aLr=i(hze),r4e=n(hze,"SPAN",{});var vxt=s(r4e);nLr=r(vxt,"TFAutoModelForMultipleChoice"),vxt.forEach(t),hze.forEach(t),lVe=i(m),lr=n(m,"DIV",{class:!0});var Nl=s(lr);T(Y9.$$.fragment,Nl),sLr=i(Nl),Mc=n(Nl,"P",{});var yre=s(Mc);lLr=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=n(yre,"A",{href:!0});var Fxt=s(nY);iLr=r(Fxt,"from_pretrained()"),Fxt.forEach(t),dLr=r(yre," class method or the "),sY=n(yre,"A",{href:!0});var Txt=s(sY);cLr=r(Txt,"from_config()"),Txt.forEach(t),mLr=r(yre,` class
method.`),yre.forEach(t),fLr=i(Nl),K9=n(Nl,"P",{});var uze=s(K9);gLr=r(uze,"This class cannot be instantiated directly using "),t4e=n(uze,"CODE",{});var Mxt=s(t4e);hLr=r(Mxt,"__init__()"),Mxt.forEach(t),uLr=r(uze," (throws an error)."),uze.forEach(t),pLr=i(Nl),Nt=n(Nl,"DIV",{class:!0});var GL=s(Nt);T(Z9.$$.fragment,GL),_Lr=i(GL),a4e=n(GL,"P",{});var Ext=s(a4e);bLr=r(Ext,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ext.forEach(t),vLr=i(GL),Ec=n(GL,"P",{});var xre=s(Ec);FLr=r(xre,`Note:
Loading a model from its configuration file does `),n4e=n(xre,"STRONG",{});var Cxt=s(n4e);TLr=r(Cxt,"not"),Cxt.forEach(t),MLr=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=n(xre,"A",{href:!0});var wxt=s(lY);ELr=r(wxt,"from_pretrained()"),wxt.forEach(t),CLr=r(xre," to load the model weights."),xre.forEach(t),wLr=i(GL),T(W5.$$.fragment,GL),GL.forEach(t),ALr=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(ex.$$.fragment,ql),LLr=i(ql),s4e=n(ql,"P",{});var Axt=s(s4e);yLr=r(Axt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Axt.forEach(t),xLr=i(ql),gn=n(ql,"P",{});var OL=s(gn);$Lr=r(OL,"The model class to instantiate is selected based on the "),l4e=n(OL,"CODE",{});var Lxt=s(l4e);kLr=r(Lxt,"model_type"),Lxt.forEach(t),SLr=r(OL,` property of the config object (either
passed as an argument or loaded from `),i4e=n(OL,"CODE",{});var yxt=s(i4e);RLr=r(yxt,"pretrained_model_name_or_path"),yxt.forEach(t),PLr=r(OL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d4e=n(OL,"CODE",{});var xxt=s(d4e);BLr=r(xxt,"pretrained_model_name_or_path"),xxt.forEach(t),ILr=r(OL,":"),OL.forEach(t),NLr=i(ql),pe=n(ql,"UL",{});var ve=s(pe);H5=n(ve,"LI",{});var xqe=s(H5);c4e=n(xqe,"STRONG",{});var $xt=s(c4e);qLr=r($xt,"albert"),$xt.forEach(t),jLr=r(xqe," \u2014 "),iY=n(xqe,"A",{href:!0});var kxt=s(iY);DLr=r(kxt,"TFAlbertForMultipleChoice"),kxt.forEach(t),GLr=r(xqe," (ALBERT model)"),xqe.forEach(t),OLr=i(ve),U5=n(ve,"LI",{});var $qe=s(U5);m4e=n($qe,"STRONG",{});var Sxt=s(m4e);VLr=r(Sxt,"bert"),Sxt.forEach(t),XLr=r($qe," \u2014 "),dY=n($qe,"A",{href:!0});var Rxt=s(dY);zLr=r(Rxt,"TFBertForMultipleChoice"),Rxt.forEach(t),QLr=r($qe," (BERT model)"),$qe.forEach(t),WLr=i(ve),J5=n(ve,"LI",{});var kqe=s(J5);f4e=n(kqe,"STRONG",{});var Pxt=s(f4e);HLr=r(Pxt,"camembert"),Pxt.forEach(t),ULr=r(kqe," \u2014 "),cY=n(kqe,"A",{href:!0});var Bxt=s(cY);JLr=r(Bxt,"TFCamembertForMultipleChoice"),Bxt.forEach(t),YLr=r(kqe," (CamemBERT model)"),kqe.forEach(t),KLr=i(ve),Y5=n(ve,"LI",{});var Sqe=s(Y5);g4e=n(Sqe,"STRONG",{});var Ixt=s(g4e);ZLr=r(Ixt,"convbert"),Ixt.forEach(t),eyr=r(Sqe," \u2014 "),mY=n(Sqe,"A",{href:!0});var Nxt=s(mY);oyr=r(Nxt,"TFConvBertForMultipleChoice"),Nxt.forEach(t),ryr=r(Sqe," (ConvBERT model)"),Sqe.forEach(t),tyr=i(ve),K5=n(ve,"LI",{});var Rqe=s(K5);h4e=n(Rqe,"STRONG",{});var qxt=s(h4e);ayr=r(qxt,"distilbert"),qxt.forEach(t),nyr=r(Rqe," \u2014 "),fY=n(Rqe,"A",{href:!0});var jxt=s(fY);syr=r(jxt,"TFDistilBertForMultipleChoice"),jxt.forEach(t),lyr=r(Rqe," (DistilBERT model)"),Rqe.forEach(t),iyr=i(ve),Z5=n(ve,"LI",{});var Pqe=s(Z5);u4e=n(Pqe,"STRONG",{});var Dxt=s(u4e);dyr=r(Dxt,"electra"),Dxt.forEach(t),cyr=r(Pqe," \u2014 "),gY=n(Pqe,"A",{href:!0});var Gxt=s(gY);myr=r(Gxt,"TFElectraForMultipleChoice"),Gxt.forEach(t),fyr=r(Pqe," (ELECTRA model)"),Pqe.forEach(t),gyr=i(ve),e3=n(ve,"LI",{});var Bqe=s(e3);p4e=n(Bqe,"STRONG",{});var Oxt=s(p4e);hyr=r(Oxt,"flaubert"),Oxt.forEach(t),uyr=r(Bqe," \u2014 "),hY=n(Bqe,"A",{href:!0});var Vxt=s(hY);pyr=r(Vxt,"TFFlaubertForMultipleChoice"),Vxt.forEach(t),_yr=r(Bqe," (FlauBERT model)"),Bqe.forEach(t),byr=i(ve),o3=n(ve,"LI",{});var Iqe=s(o3);_4e=n(Iqe,"STRONG",{});var Xxt=s(_4e);vyr=r(Xxt,"funnel"),Xxt.forEach(t),Fyr=r(Iqe," \u2014 "),uY=n(Iqe,"A",{href:!0});var zxt=s(uY);Tyr=r(zxt,"TFFunnelForMultipleChoice"),zxt.forEach(t),Myr=r(Iqe," (Funnel Transformer model)"),Iqe.forEach(t),Eyr=i(ve),r3=n(ve,"LI",{});var Nqe=s(r3);b4e=n(Nqe,"STRONG",{});var Qxt=s(b4e);Cyr=r(Qxt,"longformer"),Qxt.forEach(t),wyr=r(Nqe," \u2014 "),pY=n(Nqe,"A",{href:!0});var Wxt=s(pY);Ayr=r(Wxt,"TFLongformerForMultipleChoice"),Wxt.forEach(t),Lyr=r(Nqe," (Longformer model)"),Nqe.forEach(t),yyr=i(ve),t3=n(ve,"LI",{});var qqe=s(t3);v4e=n(qqe,"STRONG",{});var Hxt=s(v4e);xyr=r(Hxt,"mobilebert"),Hxt.forEach(t),$yr=r(qqe," \u2014 "),_Y=n(qqe,"A",{href:!0});var Uxt=s(_Y);kyr=r(Uxt,"TFMobileBertForMultipleChoice"),Uxt.forEach(t),Syr=r(qqe," (MobileBERT model)"),qqe.forEach(t),Ryr=i(ve),a3=n(ve,"LI",{});var jqe=s(a3);F4e=n(jqe,"STRONG",{});var Jxt=s(F4e);Pyr=r(Jxt,"mpnet"),Jxt.forEach(t),Byr=r(jqe," \u2014 "),bY=n(jqe,"A",{href:!0});var Yxt=s(bY);Iyr=r(Yxt,"TFMPNetForMultipleChoice"),Yxt.forEach(t),Nyr=r(jqe," (MPNet model)"),jqe.forEach(t),qyr=i(ve),n3=n(ve,"LI",{});var Dqe=s(n3);T4e=n(Dqe,"STRONG",{});var Kxt=s(T4e);jyr=r(Kxt,"rembert"),Kxt.forEach(t),Dyr=r(Dqe," \u2014 "),vY=n(Dqe,"A",{href:!0});var Zxt=s(vY);Gyr=r(Zxt,"TFRemBertForMultipleChoice"),Zxt.forEach(t),Oyr=r(Dqe," (RemBERT model)"),Dqe.forEach(t),Vyr=i(ve),s3=n(ve,"LI",{});var Gqe=s(s3);M4e=n(Gqe,"STRONG",{});var e$t=s(M4e);Xyr=r(e$t,"roberta"),e$t.forEach(t),zyr=r(Gqe," \u2014 "),FY=n(Gqe,"A",{href:!0});var o$t=s(FY);Qyr=r(o$t,"TFRobertaForMultipleChoice"),o$t.forEach(t),Wyr=r(Gqe," (RoBERTa model)"),Gqe.forEach(t),Hyr=i(ve),l3=n(ve,"LI",{});var Oqe=s(l3);E4e=n(Oqe,"STRONG",{});var r$t=s(E4e);Uyr=r(r$t,"roformer"),r$t.forEach(t),Jyr=r(Oqe," \u2014 "),TY=n(Oqe,"A",{href:!0});var t$t=s(TY);Yyr=r(t$t,"TFRoFormerForMultipleChoice"),t$t.forEach(t),Kyr=r(Oqe," (RoFormer model)"),Oqe.forEach(t),Zyr=i(ve),i3=n(ve,"LI",{});var Vqe=s(i3);C4e=n(Vqe,"STRONG",{});var a$t=s(C4e);e7r=r(a$t,"xlm"),a$t.forEach(t),o7r=r(Vqe," \u2014 "),MY=n(Vqe,"A",{href:!0});var n$t=s(MY);r7r=r(n$t,"TFXLMForMultipleChoice"),n$t.forEach(t),t7r=r(Vqe," (XLM model)"),Vqe.forEach(t),a7r=i(ve),d3=n(ve,"LI",{});var Xqe=s(d3);w4e=n(Xqe,"STRONG",{});var s$t=s(w4e);n7r=r(s$t,"xlm-roberta"),s$t.forEach(t),s7r=r(Xqe," \u2014 "),EY=n(Xqe,"A",{href:!0});var l$t=s(EY);l7r=r(l$t,"TFXLMRobertaForMultipleChoice"),l$t.forEach(t),i7r=r(Xqe," (XLM-RoBERTa model)"),Xqe.forEach(t),d7r=i(ve),c3=n(ve,"LI",{});var zqe=s(c3);A4e=n(zqe,"STRONG",{});var i$t=s(A4e);c7r=r(i$t,"xlnet"),i$t.forEach(t),m7r=r(zqe," \u2014 "),CY=n(zqe,"A",{href:!0});var d$t=s(CY);f7r=r(d$t,"TFXLNetForMultipleChoice"),d$t.forEach(t),g7r=r(zqe," (XLNet model)"),zqe.forEach(t),ve.forEach(t),h7r=i(ql),T(m3.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),iVe=i(m),Cc=n(m,"H2",{class:!0});var pze=s(Cc);f3=n(pze,"A",{id:!0,class:!0,href:!0});var c$t=s(f3);L4e=n(c$t,"SPAN",{});var m$t=s(L4e);T(ox.$$.fragment,m$t),m$t.forEach(t),c$t.forEach(t),u7r=i(pze),y4e=n(pze,"SPAN",{});var f$t=s(y4e);p7r=r(f$t,"TFAutoModelForNextSentencePrediction"),f$t.forEach(t),pze.forEach(t),dVe=i(m),ir=n(m,"DIV",{class:!0});var jl=s(ir);T(rx.$$.fragment,jl),_7r=i(jl),wc=n(jl,"P",{});var $re=s(wc);b7r=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=n($re,"A",{href:!0});var g$t=s(wY);v7r=r(g$t,"from_pretrained()"),g$t.forEach(t),F7r=r($re," class method or the "),AY=n($re,"A",{href:!0});var h$t=s(AY);T7r=r(h$t,"from_config()"),h$t.forEach(t),M7r=r($re,` class
method.`),$re.forEach(t),E7r=i(jl),tx=n(jl,"P",{});var _ze=s(tx);C7r=r(_ze,"This class cannot be instantiated directly using "),x4e=n(_ze,"CODE",{});var u$t=s(x4e);w7r=r(u$t,"__init__()"),u$t.forEach(t),A7r=r(_ze," (throws an error)."),_ze.forEach(t),L7r=i(jl),qt=n(jl,"DIV",{class:!0});var VL=s(qt);T(ax.$$.fragment,VL),y7r=i(VL),$4e=n(VL,"P",{});var p$t=s($4e);x7r=r(p$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),p$t.forEach(t),$7r=i(VL),Ac=n(VL,"P",{});var kre=s(Ac);k7r=r(kre,`Note:
Loading a model from its configuration file does `),k4e=n(kre,"STRONG",{});var _$t=s(k4e);S7r=r(_$t,"not"),_$t.forEach(t),R7r=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(kre,"A",{href:!0});var b$t=s(LY);P7r=r(b$t,"from_pretrained()"),b$t.forEach(t),B7r=r(kre," to load the model weights."),kre.forEach(t),I7r=i(VL),T(g3.$$.fragment,VL),VL.forEach(t),N7r=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(nx.$$.fragment,Dl),q7r=i(Dl),S4e=n(Dl,"P",{});var v$t=s(S4e);j7r=r(v$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),v$t.forEach(t),D7r=i(Dl),hn=n(Dl,"P",{});var XL=s(hn);G7r=r(XL,"The model class to instantiate is selected based on the "),R4e=n(XL,"CODE",{});var F$t=s(R4e);O7r=r(F$t,"model_type"),F$t.forEach(t),V7r=r(XL,` property of the config object (either
passed as an argument or loaded from `),P4e=n(XL,"CODE",{});var T$t=s(P4e);X7r=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),z7r=r(XL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=n(XL,"CODE",{});var M$t=s(B4e);Q7r=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),W7r=r(XL,":"),XL.forEach(t),H7r=i(Dl),sx=n(Dl,"UL",{});var bze=s(sx);h3=n(bze,"LI",{});var Qqe=s(h3);I4e=n(Qqe,"STRONG",{});var E$t=s(I4e);U7r=r(E$t,"bert"),E$t.forEach(t),J7r=r(Qqe," \u2014 "),yY=n(Qqe,"A",{href:!0});var C$t=s(yY);Y7r=r(C$t,"TFBertForNextSentencePrediction"),C$t.forEach(t),K7r=r(Qqe," (BERT model)"),Qqe.forEach(t),Z7r=i(bze),u3=n(bze,"LI",{});var Wqe=s(u3);N4e=n(Wqe,"STRONG",{});var w$t=s(N4e);e8r=r(w$t,"mobilebert"),w$t.forEach(t),o8r=r(Wqe," \u2014 "),xY=n(Wqe,"A",{href:!0});var A$t=s(xY);r8r=r(A$t,"TFMobileBertForNextSentencePrediction"),A$t.forEach(t),t8r=r(Wqe," (MobileBERT model)"),Wqe.forEach(t),bze.forEach(t),a8r=i(Dl),T(p3.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),cVe=i(m),Lc=n(m,"H2",{class:!0});var vze=s(Lc);_3=n(vze,"A",{id:!0,class:!0,href:!0});var L$t=s(_3);q4e=n(L$t,"SPAN",{});var y$t=s(q4e);T(lx.$$.fragment,y$t),y$t.forEach(t),L$t.forEach(t),n8r=i(vze),j4e=n(vze,"SPAN",{});var x$t=s(j4e);s8r=r(x$t,"TFAutoModelForTableQuestionAnswering"),x$t.forEach(t),vze.forEach(t),mVe=i(m),dr=n(m,"DIV",{class:!0});var Gl=s(dr);T(ix.$$.fragment,Gl),l8r=i(Gl),yc=n(Gl,"P",{});var Sre=s(yc);i8r=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=n(Sre,"A",{href:!0});var $$t=s($Y);d8r=r($$t,"from_pretrained()"),$$t.forEach(t),c8r=r(Sre," class method or the "),kY=n(Sre,"A",{href:!0});var k$t=s(kY);m8r=r(k$t,"from_config()"),k$t.forEach(t),f8r=r(Sre,` class
method.`),Sre.forEach(t),g8r=i(Gl),dx=n(Gl,"P",{});var Fze=s(dx);h8r=r(Fze,"This class cannot be instantiated directly using "),D4e=n(Fze,"CODE",{});var S$t=s(D4e);u8r=r(S$t,"__init__()"),S$t.forEach(t),p8r=r(Fze," (throws an error)."),Fze.forEach(t),_8r=i(Gl),jt=n(Gl,"DIV",{class:!0});var zL=s(jt);T(cx.$$.fragment,zL),b8r=i(zL),G4e=n(zL,"P",{});var R$t=s(G4e);v8r=r(R$t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),R$t.forEach(t),F8r=i(zL),xc=n(zL,"P",{});var Rre=s(xc);T8r=r(Rre,`Note:
Loading a model from its configuration file does `),O4e=n(Rre,"STRONG",{});var P$t=s(O4e);M8r=r(P$t,"not"),P$t.forEach(t),E8r=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(Rre,"A",{href:!0});var B$t=s(SY);C8r=r(B$t,"from_pretrained()"),B$t.forEach(t),w8r=r(Rre," to load the model weights."),Rre.forEach(t),A8r=i(zL),T(b3.$$.fragment,zL),zL.forEach(t),L8r=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(mx.$$.fragment,Ol),y8r=i(Ol),V4e=n(Ol,"P",{});var I$t=s(V4e);x8r=r(I$t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),I$t.forEach(t),$8r=i(Ol),un=n(Ol,"P",{});var QL=s(un);k8r=r(QL,"The model class to instantiate is selected based on the "),X4e=n(QL,"CODE",{});var N$t=s(X4e);S8r=r(N$t,"model_type"),N$t.forEach(t),R8r=r(QL,` property of the config object (either
passed as an argument or loaded from `),z4e=n(QL,"CODE",{});var q$t=s(z4e);P8r=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),B8r=r(QL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q4e=n(QL,"CODE",{});var j$t=s(Q4e);I8r=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),N8r=r(QL,":"),QL.forEach(t),q8r=i(Ol),W4e=n(Ol,"UL",{});var D$t=s(W4e);v3=n(D$t,"LI",{});var Hqe=s(v3);H4e=n(Hqe,"STRONG",{});var G$t=s(H4e);j8r=r(G$t,"tapas"),G$t.forEach(t),D8r=r(Hqe," \u2014 "),RY=n(Hqe,"A",{href:!0});var O$t=s(RY);G8r=r(O$t,"TFTapasForQuestionAnswering"),O$t.forEach(t),O8r=r(Hqe," (TAPAS model)"),Hqe.forEach(t),D$t.forEach(t),V8r=i(Ol),T(F3.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),fVe=i(m),$c=n(m,"H2",{class:!0});var Tze=s($c);T3=n(Tze,"A",{id:!0,class:!0,href:!0});var V$t=s(T3);U4e=n(V$t,"SPAN",{});var X$t=s(U4e);T(fx.$$.fragment,X$t),X$t.forEach(t),V$t.forEach(t),X8r=i(Tze),J4e=n(Tze,"SPAN",{});var z$t=s(J4e);z8r=r(z$t,"TFAutoModelForTokenClassification"),z$t.forEach(t),Tze.forEach(t),gVe=i(m),cr=n(m,"DIV",{class:!0});var Vl=s(cr);T(gx.$$.fragment,Vl),Q8r=i(Vl),kc=n(Vl,"P",{});var Pre=s(kc);W8r=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=n(Pre,"A",{href:!0});var Q$t=s(PY);H8r=r(Q$t,"from_pretrained()"),Q$t.forEach(t),U8r=r(Pre," class method or the "),BY=n(Pre,"A",{href:!0});var W$t=s(BY);J8r=r(W$t,"from_config()"),W$t.forEach(t),Y8r=r(Pre,` class
method.`),Pre.forEach(t),K8r=i(Vl),hx=n(Vl,"P",{});var Mze=s(hx);Z8r=r(Mze,"This class cannot be instantiated directly using "),Y4e=n(Mze,"CODE",{});var H$t=s(Y4e);e9r=r(H$t,"__init__()"),H$t.forEach(t),o9r=r(Mze," (throws an error)."),Mze.forEach(t),r9r=i(Vl),Dt=n(Vl,"DIV",{class:!0});var WL=s(Dt);T(ux.$$.fragment,WL),t9r=i(WL),K4e=n(WL,"P",{});var U$t=s(K4e);a9r=r(U$t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),U$t.forEach(t),n9r=i(WL),Sc=n(WL,"P",{});var Bre=s(Sc);s9r=r(Bre,`Note:
Loading a model from its configuration file does `),Z4e=n(Bre,"STRONG",{});var J$t=s(Z4e);l9r=r(J$t,"not"),J$t.forEach(t),i9r=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(Bre,"A",{href:!0});var Y$t=s(IY);d9r=r(Y$t,"from_pretrained()"),Y$t.forEach(t),c9r=r(Bre," to load the model weights."),Bre.forEach(t),m9r=i(WL),T(M3.$$.fragment,WL),WL.forEach(t),f9r=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(px.$$.fragment,Xl),g9r=i(Xl),eCe=n(Xl,"P",{});var K$t=s(eCe);h9r=r(K$t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),K$t.forEach(t),u9r=i(Xl),pn=n(Xl,"P",{});var HL=s(pn);p9r=r(HL,"The model class to instantiate is selected based on the "),oCe=n(HL,"CODE",{});var Z$t=s(oCe);_9r=r(Z$t,"model_type"),Z$t.forEach(t),b9r=r(HL,` property of the config object (either
passed as an argument or loaded from `),rCe=n(HL,"CODE",{});var ekt=s(rCe);v9r=r(ekt,"pretrained_model_name_or_path"),ekt.forEach(t),F9r=r(HL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tCe=n(HL,"CODE",{});var okt=s(tCe);T9r=r(okt,"pretrained_model_name_or_path"),okt.forEach(t),M9r=r(HL,":"),HL.forEach(t),E9r=i(Xl),de=n(Xl,"UL",{});var fe=s(de);E3=n(fe,"LI",{});var Uqe=s(E3);aCe=n(Uqe,"STRONG",{});var rkt=s(aCe);C9r=r(rkt,"albert"),rkt.forEach(t),w9r=r(Uqe," \u2014 "),NY=n(Uqe,"A",{href:!0});var tkt=s(NY);A9r=r(tkt,"TFAlbertForTokenClassification"),tkt.forEach(t),L9r=r(Uqe," (ALBERT model)"),Uqe.forEach(t),y9r=i(fe),C3=n(fe,"LI",{});var Jqe=s(C3);nCe=n(Jqe,"STRONG",{});var akt=s(nCe);x9r=r(akt,"bert"),akt.forEach(t),$9r=r(Jqe," \u2014 "),qY=n(Jqe,"A",{href:!0});var nkt=s(qY);k9r=r(nkt,"TFBertForTokenClassification"),nkt.forEach(t),S9r=r(Jqe," (BERT model)"),Jqe.forEach(t),R9r=i(fe),w3=n(fe,"LI",{});var Yqe=s(w3);sCe=n(Yqe,"STRONG",{});var skt=s(sCe);P9r=r(skt,"camembert"),skt.forEach(t),B9r=r(Yqe," \u2014 "),jY=n(Yqe,"A",{href:!0});var lkt=s(jY);I9r=r(lkt,"TFCamembertForTokenClassification"),lkt.forEach(t),N9r=r(Yqe," (CamemBERT model)"),Yqe.forEach(t),q9r=i(fe),A3=n(fe,"LI",{});var Kqe=s(A3);lCe=n(Kqe,"STRONG",{});var ikt=s(lCe);j9r=r(ikt,"convbert"),ikt.forEach(t),D9r=r(Kqe," \u2014 "),DY=n(Kqe,"A",{href:!0});var dkt=s(DY);G9r=r(dkt,"TFConvBertForTokenClassification"),dkt.forEach(t),O9r=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),V9r=i(fe),L3=n(fe,"LI",{});var Zqe=s(L3);iCe=n(Zqe,"STRONG",{});var ckt=s(iCe);X9r=r(ckt,"deberta"),ckt.forEach(t),z9r=r(Zqe," \u2014 "),GY=n(Zqe,"A",{href:!0});var mkt=s(GY);Q9r=r(mkt,"TFDebertaForTokenClassification"),mkt.forEach(t),W9r=r(Zqe," (DeBERTa model)"),Zqe.forEach(t),H9r=i(fe),y3=n(fe,"LI",{});var eje=s(y3);dCe=n(eje,"STRONG",{});var fkt=s(dCe);U9r=r(fkt,"deberta-v2"),fkt.forEach(t),J9r=r(eje," \u2014 "),OY=n(eje,"A",{href:!0});var gkt=s(OY);Y9r=r(gkt,"TFDebertaV2ForTokenClassification"),gkt.forEach(t),K9r=r(eje," (DeBERTa-v2 model)"),eje.forEach(t),Z9r=i(fe),x3=n(fe,"LI",{});var oje=s(x3);cCe=n(oje,"STRONG",{});var hkt=s(cCe);exr=r(hkt,"distilbert"),hkt.forEach(t),oxr=r(oje," \u2014 "),VY=n(oje,"A",{href:!0});var ukt=s(VY);rxr=r(ukt,"TFDistilBertForTokenClassification"),ukt.forEach(t),txr=r(oje," (DistilBERT model)"),oje.forEach(t),axr=i(fe),$3=n(fe,"LI",{});var rje=s($3);mCe=n(rje,"STRONG",{});var pkt=s(mCe);nxr=r(pkt,"electra"),pkt.forEach(t),sxr=r(rje," \u2014 "),XY=n(rje,"A",{href:!0});var _kt=s(XY);lxr=r(_kt,"TFElectraForTokenClassification"),_kt.forEach(t),ixr=r(rje," (ELECTRA model)"),rje.forEach(t),dxr=i(fe),k3=n(fe,"LI",{});var tje=s(k3);fCe=n(tje,"STRONG",{});var bkt=s(fCe);cxr=r(bkt,"flaubert"),bkt.forEach(t),mxr=r(tje," \u2014 "),zY=n(tje,"A",{href:!0});var vkt=s(zY);fxr=r(vkt,"TFFlaubertForTokenClassification"),vkt.forEach(t),gxr=r(tje," (FlauBERT model)"),tje.forEach(t),hxr=i(fe),S3=n(fe,"LI",{});var aje=s(S3);gCe=n(aje,"STRONG",{});var Fkt=s(gCe);uxr=r(Fkt,"funnel"),Fkt.forEach(t),pxr=r(aje," \u2014 "),QY=n(aje,"A",{href:!0});var Tkt=s(QY);_xr=r(Tkt,"TFFunnelForTokenClassification"),Tkt.forEach(t),bxr=r(aje," (Funnel Transformer model)"),aje.forEach(t),vxr=i(fe),R3=n(fe,"LI",{});var nje=s(R3);hCe=n(nje,"STRONG",{});var Mkt=s(hCe);Fxr=r(Mkt,"layoutlm"),Mkt.forEach(t),Txr=r(nje," \u2014 "),WY=n(nje,"A",{href:!0});var Ekt=s(WY);Mxr=r(Ekt,"TFLayoutLMForTokenClassification"),Ekt.forEach(t),Exr=r(nje," (LayoutLM model)"),nje.forEach(t),Cxr=i(fe),P3=n(fe,"LI",{});var sje=s(P3);uCe=n(sje,"STRONG",{});var Ckt=s(uCe);wxr=r(Ckt,"longformer"),Ckt.forEach(t),Axr=r(sje," \u2014 "),HY=n(sje,"A",{href:!0});var wkt=s(HY);Lxr=r(wkt,"TFLongformerForTokenClassification"),wkt.forEach(t),yxr=r(sje," (Longformer model)"),sje.forEach(t),xxr=i(fe),B3=n(fe,"LI",{});var lje=s(B3);pCe=n(lje,"STRONG",{});var Akt=s(pCe);$xr=r(Akt,"mobilebert"),Akt.forEach(t),kxr=r(lje," \u2014 "),UY=n(lje,"A",{href:!0});var Lkt=s(UY);Sxr=r(Lkt,"TFMobileBertForTokenClassification"),Lkt.forEach(t),Rxr=r(lje," (MobileBERT model)"),lje.forEach(t),Pxr=i(fe),I3=n(fe,"LI",{});var ije=s(I3);_Ce=n(ije,"STRONG",{});var ykt=s(_Ce);Bxr=r(ykt,"mpnet"),ykt.forEach(t),Ixr=r(ije," \u2014 "),JY=n(ije,"A",{href:!0});var xkt=s(JY);Nxr=r(xkt,"TFMPNetForTokenClassification"),xkt.forEach(t),qxr=r(ije," (MPNet model)"),ije.forEach(t),jxr=i(fe),N3=n(fe,"LI",{});var dje=s(N3);bCe=n(dje,"STRONG",{});var $kt=s(bCe);Dxr=r($kt,"rembert"),$kt.forEach(t),Gxr=r(dje," \u2014 "),YY=n(dje,"A",{href:!0});var kkt=s(YY);Oxr=r(kkt,"TFRemBertForTokenClassification"),kkt.forEach(t),Vxr=r(dje," (RemBERT model)"),dje.forEach(t),Xxr=i(fe),q3=n(fe,"LI",{});var cje=s(q3);vCe=n(cje,"STRONG",{});var Skt=s(vCe);zxr=r(Skt,"roberta"),Skt.forEach(t),Qxr=r(cje," \u2014 "),KY=n(cje,"A",{href:!0});var Rkt=s(KY);Wxr=r(Rkt,"TFRobertaForTokenClassification"),Rkt.forEach(t),Hxr=r(cje," (RoBERTa model)"),cje.forEach(t),Uxr=i(fe),j3=n(fe,"LI",{});var mje=s(j3);FCe=n(mje,"STRONG",{});var Pkt=s(FCe);Jxr=r(Pkt,"roformer"),Pkt.forEach(t),Yxr=r(mje," \u2014 "),ZY=n(mje,"A",{href:!0});var Bkt=s(ZY);Kxr=r(Bkt,"TFRoFormerForTokenClassification"),Bkt.forEach(t),Zxr=r(mje," (RoFormer model)"),mje.forEach(t),e$r=i(fe),D3=n(fe,"LI",{});var fje=s(D3);TCe=n(fje,"STRONG",{});var Ikt=s(TCe);o$r=r(Ikt,"xlm"),Ikt.forEach(t),r$r=r(fje," \u2014 "),eK=n(fje,"A",{href:!0});var Nkt=s(eK);t$r=r(Nkt,"TFXLMForTokenClassification"),Nkt.forEach(t),a$r=r(fje," (XLM model)"),fje.forEach(t),n$r=i(fe),G3=n(fe,"LI",{});var gje=s(G3);MCe=n(gje,"STRONG",{});var qkt=s(MCe);s$r=r(qkt,"xlm-roberta"),qkt.forEach(t),l$r=r(gje," \u2014 "),oK=n(gje,"A",{href:!0});var jkt=s(oK);i$r=r(jkt,"TFXLMRobertaForTokenClassification"),jkt.forEach(t),d$r=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),c$r=i(fe),O3=n(fe,"LI",{});var hje=s(O3);ECe=n(hje,"STRONG",{});var Dkt=s(ECe);m$r=r(Dkt,"xlnet"),Dkt.forEach(t),f$r=r(hje," \u2014 "),rK=n(hje,"A",{href:!0});var Gkt=s(rK);g$r=r(Gkt,"TFXLNetForTokenClassification"),Gkt.forEach(t),h$r=r(hje," (XLNet model)"),hje.forEach(t),fe.forEach(t),u$r=i(Xl),T(V3.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),hVe=i(m),Rc=n(m,"H2",{class:!0});var Eze=s(Rc);X3=n(Eze,"A",{id:!0,class:!0,href:!0});var Okt=s(X3);CCe=n(Okt,"SPAN",{});var Vkt=s(CCe);T(_x.$$.fragment,Vkt),Vkt.forEach(t),Okt.forEach(t),p$r=i(Eze),wCe=n(Eze,"SPAN",{});var Xkt=s(wCe);_$r=r(Xkt,"TFAutoModelForQuestionAnswering"),Xkt.forEach(t),Eze.forEach(t),uVe=i(m),mr=n(m,"DIV",{class:!0});var zl=s(mr);T(bx.$$.fragment,zl),b$r=i(zl),Pc=n(zl,"P",{});var Ire=s(Pc);v$r=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=n(Ire,"A",{href:!0});var zkt=s(tK);F$r=r(zkt,"from_pretrained()"),zkt.forEach(t),T$r=r(Ire," class method or the "),aK=n(Ire,"A",{href:!0});var Qkt=s(aK);M$r=r(Qkt,"from_config()"),Qkt.forEach(t),E$r=r(Ire,` class
method.`),Ire.forEach(t),C$r=i(zl),vx=n(zl,"P",{});var Cze=s(vx);w$r=r(Cze,"This class cannot be instantiated directly using "),ACe=n(Cze,"CODE",{});var Wkt=s(ACe);A$r=r(Wkt,"__init__()"),Wkt.forEach(t),L$r=r(Cze," (throws an error)."),Cze.forEach(t),y$r=i(zl),Gt=n(zl,"DIV",{class:!0});var UL=s(Gt);T(Fx.$$.fragment,UL),x$r=i(UL),LCe=n(UL,"P",{});var Hkt=s(LCe);$$r=r(Hkt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hkt.forEach(t),k$r=i(UL),Bc=n(UL,"P",{});var Nre=s(Bc);S$r=r(Nre,`Note:
Loading a model from its configuration file does `),yCe=n(Nre,"STRONG",{});var Ukt=s(yCe);R$r=r(Ukt,"not"),Ukt.forEach(t),P$r=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(Nre,"A",{href:!0});var Jkt=s(nK);B$r=r(Jkt,"from_pretrained()"),Jkt.forEach(t),I$r=r(Nre," to load the model weights."),Nre.forEach(t),N$r=i(UL),T(z3.$$.fragment,UL),UL.forEach(t),q$r=i(zl),jr=n(zl,"DIV",{class:!0});var Ql=s(jr);T(Tx.$$.fragment,Ql),j$r=i(Ql),xCe=n(Ql,"P",{});var Ykt=s(xCe);D$r=r(Ykt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ykt.forEach(t),G$r=i(Ql),_n=n(Ql,"P",{});var JL=s(_n);O$r=r(JL,"The model class to instantiate is selected based on the "),$Ce=n(JL,"CODE",{});var Kkt=s($Ce);V$r=r(Kkt,"model_type"),Kkt.forEach(t),X$r=r(JL,` property of the config object (either
passed as an argument or loaded from `),kCe=n(JL,"CODE",{});var Zkt=s(kCe);z$r=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),Q$r=r(JL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SCe=n(JL,"CODE",{});var eSt=s(SCe);W$r=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),H$r=r(JL,":"),JL.forEach(t),U$r=i(Ql),ce=n(Ql,"UL",{});var ge=s(ce);Q3=n(ge,"LI",{});var uje=s(Q3);RCe=n(uje,"STRONG",{});var oSt=s(RCe);J$r=r(oSt,"albert"),oSt.forEach(t),Y$r=r(uje," \u2014 "),sK=n(uje,"A",{href:!0});var rSt=s(sK);K$r=r(rSt,"TFAlbertForQuestionAnswering"),rSt.forEach(t),Z$r=r(uje," (ALBERT model)"),uje.forEach(t),ekr=i(ge),W3=n(ge,"LI",{});var pje=s(W3);PCe=n(pje,"STRONG",{});var tSt=s(PCe);okr=r(tSt,"bert"),tSt.forEach(t),rkr=r(pje," \u2014 "),lK=n(pje,"A",{href:!0});var aSt=s(lK);tkr=r(aSt,"TFBertForQuestionAnswering"),aSt.forEach(t),akr=r(pje," (BERT model)"),pje.forEach(t),nkr=i(ge),H3=n(ge,"LI",{});var _je=s(H3);BCe=n(_je,"STRONG",{});var nSt=s(BCe);skr=r(nSt,"camembert"),nSt.forEach(t),lkr=r(_je," \u2014 "),iK=n(_je,"A",{href:!0});var sSt=s(iK);ikr=r(sSt,"TFCamembertForQuestionAnswering"),sSt.forEach(t),dkr=r(_je," (CamemBERT model)"),_je.forEach(t),ckr=i(ge),U3=n(ge,"LI",{});var bje=s(U3);ICe=n(bje,"STRONG",{});var lSt=s(ICe);mkr=r(lSt,"convbert"),lSt.forEach(t),fkr=r(bje," \u2014 "),dK=n(bje,"A",{href:!0});var iSt=s(dK);gkr=r(iSt,"TFConvBertForQuestionAnswering"),iSt.forEach(t),hkr=r(bje," (ConvBERT model)"),bje.forEach(t),ukr=i(ge),J3=n(ge,"LI",{});var vje=s(J3);NCe=n(vje,"STRONG",{});var dSt=s(NCe);pkr=r(dSt,"deberta"),dSt.forEach(t),_kr=r(vje," \u2014 "),cK=n(vje,"A",{href:!0});var cSt=s(cK);bkr=r(cSt,"TFDebertaForQuestionAnswering"),cSt.forEach(t),vkr=r(vje," (DeBERTa model)"),vje.forEach(t),Fkr=i(ge),Y3=n(ge,"LI",{});var Fje=s(Y3);qCe=n(Fje,"STRONG",{});var mSt=s(qCe);Tkr=r(mSt,"deberta-v2"),mSt.forEach(t),Mkr=r(Fje," \u2014 "),mK=n(Fje,"A",{href:!0});var fSt=s(mK);Ekr=r(fSt,"TFDebertaV2ForQuestionAnswering"),fSt.forEach(t),Ckr=r(Fje," (DeBERTa-v2 model)"),Fje.forEach(t),wkr=i(ge),K3=n(ge,"LI",{});var Tje=s(K3);jCe=n(Tje,"STRONG",{});var gSt=s(jCe);Akr=r(gSt,"distilbert"),gSt.forEach(t),Lkr=r(Tje," \u2014 "),fK=n(Tje,"A",{href:!0});var hSt=s(fK);ykr=r(hSt,"TFDistilBertForQuestionAnswering"),hSt.forEach(t),xkr=r(Tje," (DistilBERT model)"),Tje.forEach(t),$kr=i(ge),Z3=n(ge,"LI",{});var Mje=s(Z3);DCe=n(Mje,"STRONG",{});var uSt=s(DCe);kkr=r(uSt,"electra"),uSt.forEach(t),Skr=r(Mje," \u2014 "),gK=n(Mje,"A",{href:!0});var pSt=s(gK);Rkr=r(pSt,"TFElectraForQuestionAnswering"),pSt.forEach(t),Pkr=r(Mje," (ELECTRA model)"),Mje.forEach(t),Bkr=i(ge),e0=n(ge,"LI",{});var Eje=s(e0);GCe=n(Eje,"STRONG",{});var _St=s(GCe);Ikr=r(_St,"flaubert"),_St.forEach(t),Nkr=r(Eje," \u2014 "),hK=n(Eje,"A",{href:!0});var bSt=s(hK);qkr=r(bSt,"TFFlaubertForQuestionAnsweringSimple"),bSt.forEach(t),jkr=r(Eje," (FlauBERT model)"),Eje.forEach(t),Dkr=i(ge),o0=n(ge,"LI",{});var Cje=s(o0);OCe=n(Cje,"STRONG",{});var vSt=s(OCe);Gkr=r(vSt,"funnel"),vSt.forEach(t),Okr=r(Cje," \u2014 "),uK=n(Cje,"A",{href:!0});var FSt=s(uK);Vkr=r(FSt,"TFFunnelForQuestionAnswering"),FSt.forEach(t),Xkr=r(Cje," (Funnel Transformer model)"),Cje.forEach(t),zkr=i(ge),r0=n(ge,"LI",{});var wje=s(r0);VCe=n(wje,"STRONG",{});var TSt=s(VCe);Qkr=r(TSt,"gptj"),TSt.forEach(t),Wkr=r(wje," \u2014 "),pK=n(wje,"A",{href:!0});var MSt=s(pK);Hkr=r(MSt,"TFGPTJForQuestionAnswering"),MSt.forEach(t),Ukr=r(wje," (GPT-J model)"),wje.forEach(t),Jkr=i(ge),t0=n(ge,"LI",{});var Aje=s(t0);XCe=n(Aje,"STRONG",{});var ESt=s(XCe);Ykr=r(ESt,"longformer"),ESt.forEach(t),Kkr=r(Aje," \u2014 "),_K=n(Aje,"A",{href:!0});var CSt=s(_K);Zkr=r(CSt,"TFLongformerForQuestionAnswering"),CSt.forEach(t),eSr=r(Aje," (Longformer model)"),Aje.forEach(t),oSr=i(ge),a0=n(ge,"LI",{});var Lje=s(a0);zCe=n(Lje,"STRONG",{});var wSt=s(zCe);rSr=r(wSt,"mobilebert"),wSt.forEach(t),tSr=r(Lje," \u2014 "),bK=n(Lje,"A",{href:!0});var ASt=s(bK);aSr=r(ASt,"TFMobileBertForQuestionAnswering"),ASt.forEach(t),nSr=r(Lje," (MobileBERT model)"),Lje.forEach(t),sSr=i(ge),n0=n(ge,"LI",{});var yje=s(n0);QCe=n(yje,"STRONG",{});var LSt=s(QCe);lSr=r(LSt,"mpnet"),LSt.forEach(t),iSr=r(yje," \u2014 "),vK=n(yje,"A",{href:!0});var ySt=s(vK);dSr=r(ySt,"TFMPNetForQuestionAnswering"),ySt.forEach(t),cSr=r(yje," (MPNet model)"),yje.forEach(t),mSr=i(ge),s0=n(ge,"LI",{});var xje=s(s0);WCe=n(xje,"STRONG",{});var xSt=s(WCe);fSr=r(xSt,"rembert"),xSt.forEach(t),gSr=r(xje," \u2014 "),FK=n(xje,"A",{href:!0});var $St=s(FK);hSr=r($St,"TFRemBertForQuestionAnswering"),$St.forEach(t),uSr=r(xje," (RemBERT model)"),xje.forEach(t),pSr=i(ge),l0=n(ge,"LI",{});var $je=s(l0);HCe=n($je,"STRONG",{});var kSt=s(HCe);_Sr=r(kSt,"roberta"),kSt.forEach(t),bSr=r($je," \u2014 "),TK=n($je,"A",{href:!0});var SSt=s(TK);vSr=r(SSt,"TFRobertaForQuestionAnswering"),SSt.forEach(t),FSr=r($je," (RoBERTa model)"),$je.forEach(t),TSr=i(ge),i0=n(ge,"LI",{});var kje=s(i0);UCe=n(kje,"STRONG",{});var RSt=s(UCe);MSr=r(RSt,"roformer"),RSt.forEach(t),ESr=r(kje," \u2014 "),MK=n(kje,"A",{href:!0});var PSt=s(MK);CSr=r(PSt,"TFRoFormerForQuestionAnswering"),PSt.forEach(t),wSr=r(kje," (RoFormer model)"),kje.forEach(t),ASr=i(ge),d0=n(ge,"LI",{});var Sje=s(d0);JCe=n(Sje,"STRONG",{});var BSt=s(JCe);LSr=r(BSt,"xlm"),BSt.forEach(t),ySr=r(Sje," \u2014 "),EK=n(Sje,"A",{href:!0});var ISt=s(EK);xSr=r(ISt,"TFXLMForQuestionAnsweringSimple"),ISt.forEach(t),$Sr=r(Sje," (XLM model)"),Sje.forEach(t),kSr=i(ge),c0=n(ge,"LI",{});var Rje=s(c0);YCe=n(Rje,"STRONG",{});var NSt=s(YCe);SSr=r(NSt,"xlm-roberta"),NSt.forEach(t),RSr=r(Rje," \u2014 "),CK=n(Rje,"A",{href:!0});var qSt=s(CK);PSr=r(qSt,"TFXLMRobertaForQuestionAnswering"),qSt.forEach(t),BSr=r(Rje," (XLM-RoBERTa model)"),Rje.forEach(t),ISr=i(ge),m0=n(ge,"LI",{});var Pje=s(m0);KCe=n(Pje,"STRONG",{});var jSt=s(KCe);NSr=r(jSt,"xlnet"),jSt.forEach(t),qSr=r(Pje," \u2014 "),wK=n(Pje,"A",{href:!0});var DSt=s(wK);jSr=r(DSt,"TFXLNetForQuestionAnsweringSimple"),DSt.forEach(t),DSr=r(Pje," (XLNet model)"),Pje.forEach(t),ge.forEach(t),GSr=i(Ql),T(f0.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),pVe=i(m),Ic=n(m,"H2",{class:!0});var wze=s(Ic);g0=n(wze,"A",{id:!0,class:!0,href:!0});var GSt=s(g0);ZCe=n(GSt,"SPAN",{});var OSt=s(ZCe);T(Mx.$$.fragment,OSt),OSt.forEach(t),GSt.forEach(t),OSr=i(wze),e5e=n(wze,"SPAN",{});var VSt=s(e5e);VSr=r(VSt,"TFAutoModelForVision2Seq"),VSt.forEach(t),wze.forEach(t),_Ve=i(m),fr=n(m,"DIV",{class:!0});var Wl=s(fr);T(Ex.$$.fragment,Wl),XSr=i(Wl),Nc=n(Wl,"P",{});var qre=s(Nc);zSr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=n(qre,"A",{href:!0});var XSt=s(AK);QSr=r(XSt,"from_pretrained()"),XSt.forEach(t),WSr=r(qre," class method or the "),LK=n(qre,"A",{href:!0});var zSt=s(LK);HSr=r(zSt,"from_config()"),zSt.forEach(t),USr=r(qre,` class
method.`),qre.forEach(t),JSr=i(Wl),Cx=n(Wl,"P",{});var Aze=s(Cx);YSr=r(Aze,"This class cannot be instantiated directly using "),o5e=n(Aze,"CODE",{});var QSt=s(o5e);KSr=r(QSt,"__init__()"),QSt.forEach(t),ZSr=r(Aze," (throws an error)."),Aze.forEach(t),eRr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var YL=s(Ot);T(wx.$$.fragment,YL),oRr=i(YL),r5e=n(YL,"P",{});var WSt=s(r5e);rRr=r(WSt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WSt.forEach(t),tRr=i(YL),qc=n(YL,"P",{});var jre=s(qc);aRr=r(jre,`Note:
Loading a model from its configuration file does `),t5e=n(jre,"STRONG",{});var HSt=s(t5e);nRr=r(HSt,"not"),HSt.forEach(t),sRr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(jre,"A",{href:!0});var USt=s(yK);lRr=r(USt,"from_pretrained()"),USt.forEach(t),iRr=r(jre," to load the model weights."),jre.forEach(t),dRr=i(YL),T(h0.$$.fragment,YL),YL.forEach(t),cRr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Hl=s(Dr);T(Ax.$$.fragment,Hl),mRr=i(Hl),a5e=n(Hl,"P",{});var JSt=s(a5e);fRr=r(JSt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),JSt.forEach(t),gRr=i(Hl),bn=n(Hl,"P",{});var KL=s(bn);hRr=r(KL,"The model class to instantiate is selected based on the "),n5e=n(KL,"CODE",{});var YSt=s(n5e);uRr=r(YSt,"model_type"),YSt.forEach(t),pRr=r(KL,` property of the config object (either
passed as an argument or loaded from `),s5e=n(KL,"CODE",{});var KSt=s(s5e);_Rr=r(KSt,"pretrained_model_name_or_path"),KSt.forEach(t),bRr=r(KL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l5e=n(KL,"CODE",{});var ZSt=s(l5e);vRr=r(ZSt,"pretrained_model_name_or_path"),ZSt.forEach(t),FRr=r(KL,":"),KL.forEach(t),TRr=i(Hl),i5e=n(Hl,"UL",{});var eRt=s(i5e);u0=n(eRt,"LI",{});var Bje=s(u0);d5e=n(Bje,"STRONG",{});var oRt=s(d5e);MRr=r(oRt,"vision-encoder-decoder"),oRt.forEach(t),ERr=r(Bje," \u2014 "),xK=n(Bje,"A",{href:!0});var rRt=s(xK);CRr=r(rRt,"TFVisionEncoderDecoderModel"),rRt.forEach(t),wRr=r(Bje," (Vision Encoder decoder model)"),Bje.forEach(t),eRt.forEach(t),ARr=i(Hl),T(p0.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),bVe=i(m),jc=n(m,"H2",{class:!0});var Lze=s(jc);_0=n(Lze,"A",{id:!0,class:!0,href:!0});var tRt=s(_0);c5e=n(tRt,"SPAN",{});var aRt=s(c5e);T(Lx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),LRr=i(Lze),m5e=n(Lze,"SPAN",{});var nRt=s(m5e);yRr=r(nRt,"TFAutoModelForSpeechSeq2Seq"),nRt.forEach(t),Lze.forEach(t),vVe=i(m),gr=n(m,"DIV",{class:!0});var Ul=s(gr);T(yx.$$.fragment,Ul),xRr=i(Ul),Dc=n(Ul,"P",{});var Dre=s(Dc);$Rr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=n(Dre,"A",{href:!0});var sRt=s($K);kRr=r(sRt,"from_pretrained()"),sRt.forEach(t),SRr=r(Dre," class method or the "),kK=n(Dre,"A",{href:!0});var lRt=s(kK);RRr=r(lRt,"from_config()"),lRt.forEach(t),PRr=r(Dre,` class
method.`),Dre.forEach(t),BRr=i(Ul),xx=n(Ul,"P",{});var yze=s(xx);IRr=r(yze,"This class cannot be instantiated directly using "),f5e=n(yze,"CODE",{});var iRt=s(f5e);NRr=r(iRt,"__init__()"),iRt.forEach(t),qRr=r(yze," (throws an error)."),yze.forEach(t),jRr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var ZL=s(Vt);T($x.$$.fragment,ZL),DRr=i(ZL),g5e=n(ZL,"P",{});var dRt=s(g5e);GRr=r(dRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dRt.forEach(t),ORr=i(ZL),Gc=n(ZL,"P",{});var Gre=s(Gc);VRr=r(Gre,`Note:
Loading a model from its configuration file does `),h5e=n(Gre,"STRONG",{});var cRt=s(h5e);XRr=r(cRt,"not"),cRt.forEach(t),zRr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(Gre,"A",{href:!0});var mRt=s(SK);QRr=r(mRt,"from_pretrained()"),mRt.forEach(t),WRr=r(Gre," to load the model weights."),Gre.forEach(t),HRr=i(ZL),T(b0.$$.fragment,ZL),ZL.forEach(t),URr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(kx.$$.fragment,Jl),JRr=i(Jl),u5e=n(Jl,"P",{});var fRt=s(u5e);YRr=r(fRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fRt.forEach(t),KRr=i(Jl),vn=n(Jl,"P",{});var ey=s(vn);ZRr=r(ey,"The model class to instantiate is selected based on the "),p5e=n(ey,"CODE",{});var gRt=s(p5e);ePr=r(gRt,"model_type"),gRt.forEach(t),oPr=r(ey,` property of the config object (either
passed as an argument or loaded from `),_5e=n(ey,"CODE",{});var hRt=s(_5e);rPr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),tPr=r(ey,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b5e=n(ey,"CODE",{});var uRt=s(b5e);aPr=r(uRt,"pretrained_model_name_or_path"),uRt.forEach(t),nPr=r(ey,":"),ey.forEach(t),sPr=i(Jl),v5e=n(Jl,"UL",{});var pRt=s(v5e);v0=n(pRt,"LI",{});var Ije=s(v0);F5e=n(Ije,"STRONG",{});var _Rt=s(F5e);lPr=r(_Rt,"speech_to_text"),_Rt.forEach(t),iPr=r(Ije," \u2014 "),RK=n(Ije,"A",{href:!0});var bRt=s(RK);dPr=r(bRt,"TFSpeech2TextForConditionalGeneration"),bRt.forEach(t),cPr=r(Ije," (Speech2Text model)"),Ije.forEach(t),pRt.forEach(t),mPr=i(Jl),T(F0.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),FVe=i(m),Oc=n(m,"H2",{class:!0});var xze=s(Oc);T0=n(xze,"A",{id:!0,class:!0,href:!0});var vRt=s(T0);T5e=n(vRt,"SPAN",{});var FRt=s(T5e);T(Sx.$$.fragment,FRt),FRt.forEach(t),vRt.forEach(t),fPr=i(xze),M5e=n(xze,"SPAN",{});var TRt=s(M5e);gPr=r(TRt,"FlaxAutoModel"),TRt.forEach(t),xze.forEach(t),TVe=i(m),hr=n(m,"DIV",{class:!0});var Yl=s(hr);T(Rx.$$.fragment,Yl),hPr=i(Yl),Vc=n(Yl,"P",{});var Ore=s(Vc);uPr=r(Ore,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=n(Ore,"A",{href:!0});var MRt=s(PK);pPr=r(MRt,"from_pretrained()"),MRt.forEach(t),_Pr=r(Ore," class method or the "),BK=n(Ore,"A",{href:!0});var ERt=s(BK);bPr=r(ERt,"from_config()"),ERt.forEach(t),vPr=r(Ore,` class
method.`),Ore.forEach(t),FPr=i(Yl),Px=n(Yl,"P",{});var $ze=s(Px);TPr=r($ze,"This class cannot be instantiated directly using "),E5e=n($ze,"CODE",{});var CRt=s(E5e);MPr=r(CRt,"__init__()"),CRt.forEach(t),EPr=r($ze," (throws an error)."),$ze.forEach(t),CPr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var oy=s(Xt);T(Bx.$$.fragment,oy),wPr=i(oy),C5e=n(oy,"P",{});var wRt=s(C5e);APr=r(wRt,"Instantiates one of the base model classes of the library from a configuration."),wRt.forEach(t),LPr=i(oy),Xc=n(oy,"P",{});var Vre=s(Xc);yPr=r(Vre,`Note:
Loading a model from its configuration file does `),w5e=n(Vre,"STRONG",{});var ARt=s(w5e);xPr=r(ARt,"not"),ARt.forEach(t),$Pr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Vre,"A",{href:!0});var LRt=s(IK);kPr=r(LRt,"from_pretrained()"),LRt.forEach(t),SPr=r(Vre," to load the model weights."),Vre.forEach(t),RPr=i(oy),T(M0.$$.fragment,oy),oy.forEach(t),PPr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(Ix.$$.fragment,Kl),BPr=i(Kl),A5e=n(Kl,"P",{});var yRt=s(A5e);IPr=r(yRt,"Instantiate one of the base model classes of the library from a pretrained model."),yRt.forEach(t),NPr=i(Kl),Fn=n(Kl,"P",{});var ry=s(Fn);qPr=r(ry,"The model class to instantiate is selected based on the "),L5e=n(ry,"CODE",{});var xRt=s(L5e);jPr=r(xRt,"model_type"),xRt.forEach(t),DPr=r(ry,` property of the config object (either
passed as an argument or loaded from `),y5e=n(ry,"CODE",{});var $Rt=s(y5e);GPr=r($Rt,"pretrained_model_name_or_path"),$Rt.forEach(t),OPr=r(ry,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(ry,"CODE",{});var kRt=s(x5e);VPr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),XPr=r(ry,":"),ry.forEach(t),zPr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);E0=n(ae,"LI",{});var Nje=s(E0);$5e=n(Nje,"STRONG",{});var SRt=s($5e);QPr=r(SRt,"albert"),SRt.forEach(t),WPr=r(Nje," \u2014 "),NK=n(Nje,"A",{href:!0});var RRt=s(NK);HPr=r(RRt,"FlaxAlbertModel"),RRt.forEach(t),UPr=r(Nje," (ALBERT model)"),Nje.forEach(t),JPr=i(ae),C0=n(ae,"LI",{});var qje=s(C0);k5e=n(qje,"STRONG",{});var PRt=s(k5e);YPr=r(PRt,"bart"),PRt.forEach(t),KPr=r(qje," \u2014 "),qK=n(qje,"A",{href:!0});var BRt=s(qK);ZPr=r(BRt,"FlaxBartModel"),BRt.forEach(t),eBr=r(qje," (BART model)"),qje.forEach(t),oBr=i(ae),w0=n(ae,"LI",{});var jje=s(w0);S5e=n(jje,"STRONG",{});var IRt=s(S5e);rBr=r(IRt,"beit"),IRt.forEach(t),tBr=r(jje," \u2014 "),jK=n(jje,"A",{href:!0});var NRt=s(jK);aBr=r(NRt,"FlaxBeitModel"),NRt.forEach(t),nBr=r(jje," (BEiT model)"),jje.forEach(t),sBr=i(ae),A0=n(ae,"LI",{});var Dje=s(A0);R5e=n(Dje,"STRONG",{});var qRt=s(R5e);lBr=r(qRt,"bert"),qRt.forEach(t),iBr=r(Dje," \u2014 "),DK=n(Dje,"A",{href:!0});var jRt=s(DK);dBr=r(jRt,"FlaxBertModel"),jRt.forEach(t),cBr=r(Dje," (BERT model)"),Dje.forEach(t),mBr=i(ae),L0=n(ae,"LI",{});var Gje=s(L0);P5e=n(Gje,"STRONG",{});var DRt=s(P5e);fBr=r(DRt,"big_bird"),DRt.forEach(t),gBr=r(Gje," \u2014 "),GK=n(Gje,"A",{href:!0});var GRt=s(GK);hBr=r(GRt,"FlaxBigBirdModel"),GRt.forEach(t),uBr=r(Gje," (BigBird model)"),Gje.forEach(t),pBr=i(ae),y0=n(ae,"LI",{});var Oje=s(y0);B5e=n(Oje,"STRONG",{});var ORt=s(B5e);_Br=r(ORt,"blenderbot"),ORt.forEach(t),bBr=r(Oje," \u2014 "),OK=n(Oje,"A",{href:!0});var VRt=s(OK);vBr=r(VRt,"FlaxBlenderbotModel"),VRt.forEach(t),FBr=r(Oje," (Blenderbot model)"),Oje.forEach(t),TBr=i(ae),x0=n(ae,"LI",{});var Vje=s(x0);I5e=n(Vje,"STRONG",{});var XRt=s(I5e);MBr=r(XRt,"blenderbot-small"),XRt.forEach(t),EBr=r(Vje," \u2014 "),VK=n(Vje,"A",{href:!0});var zRt=s(VK);CBr=r(zRt,"FlaxBlenderbotSmallModel"),zRt.forEach(t),wBr=r(Vje," (BlenderbotSmall model)"),Vje.forEach(t),ABr=i(ae),$0=n(ae,"LI",{});var Xje=s($0);N5e=n(Xje,"STRONG",{});var QRt=s(N5e);LBr=r(QRt,"clip"),QRt.forEach(t),yBr=r(Xje," \u2014 "),XK=n(Xje,"A",{href:!0});var WRt=s(XK);xBr=r(WRt,"FlaxCLIPModel"),WRt.forEach(t),$Br=r(Xje," (CLIP model)"),Xje.forEach(t),kBr=i(ae),k0=n(ae,"LI",{});var zje=s(k0);q5e=n(zje,"STRONG",{});var HRt=s(q5e);SBr=r(HRt,"distilbert"),HRt.forEach(t),RBr=r(zje," \u2014 "),zK=n(zje,"A",{href:!0});var URt=s(zK);PBr=r(URt,"FlaxDistilBertModel"),URt.forEach(t),BBr=r(zje," (DistilBERT model)"),zje.forEach(t),IBr=i(ae),S0=n(ae,"LI",{});var Qje=s(S0);j5e=n(Qje,"STRONG",{});var JRt=s(j5e);NBr=r(JRt,"electra"),JRt.forEach(t),qBr=r(Qje," \u2014 "),QK=n(Qje,"A",{href:!0});var YRt=s(QK);jBr=r(YRt,"FlaxElectraModel"),YRt.forEach(t),DBr=r(Qje," (ELECTRA model)"),Qje.forEach(t),GBr=i(ae),R0=n(ae,"LI",{});var Wje=s(R0);D5e=n(Wje,"STRONG",{});var KRt=s(D5e);OBr=r(KRt,"gpt2"),KRt.forEach(t),VBr=r(Wje," \u2014 "),WK=n(Wje,"A",{href:!0});var ZRt=s(WK);XBr=r(ZRt,"FlaxGPT2Model"),ZRt.forEach(t),zBr=r(Wje," (OpenAI GPT-2 model)"),Wje.forEach(t),QBr=i(ae),P0=n(ae,"LI",{});var Hje=s(P0);G5e=n(Hje,"STRONG",{});var ePt=s(G5e);WBr=r(ePt,"gpt_neo"),ePt.forEach(t),HBr=r(Hje," \u2014 "),HK=n(Hje,"A",{href:!0});var oPt=s(HK);UBr=r(oPt,"FlaxGPTNeoModel"),oPt.forEach(t),JBr=r(Hje," (GPT Neo model)"),Hje.forEach(t),YBr=i(ae),B0=n(ae,"LI",{});var Uje=s(B0);O5e=n(Uje,"STRONG",{});var rPt=s(O5e);KBr=r(rPt,"gptj"),rPt.forEach(t),ZBr=r(Uje," \u2014 "),UK=n(Uje,"A",{href:!0});var tPt=s(UK);eIr=r(tPt,"FlaxGPTJModel"),tPt.forEach(t),oIr=r(Uje," (GPT-J model)"),Uje.forEach(t),rIr=i(ae),I0=n(ae,"LI",{});var Jje=s(I0);V5e=n(Jje,"STRONG",{});var aPt=s(V5e);tIr=r(aPt,"longt5"),aPt.forEach(t),aIr=r(Jje," \u2014 "),JK=n(Jje,"A",{href:!0});var nPt=s(JK);nIr=r(nPt,"FlaxLongT5Model"),nPt.forEach(t),sIr=r(Jje," (LongT5 model)"),Jje.forEach(t),lIr=i(ae),N0=n(ae,"LI",{});var Yje=s(N0);X5e=n(Yje,"STRONG",{});var sPt=s(X5e);iIr=r(sPt,"marian"),sPt.forEach(t),dIr=r(Yje," \u2014 "),YK=n(Yje,"A",{href:!0});var lPt=s(YK);cIr=r(lPt,"FlaxMarianModel"),lPt.forEach(t),mIr=r(Yje," (Marian model)"),Yje.forEach(t),fIr=i(ae),q0=n(ae,"LI",{});var Kje=s(q0);z5e=n(Kje,"STRONG",{});var iPt=s(z5e);gIr=r(iPt,"mbart"),iPt.forEach(t),hIr=r(Kje," \u2014 "),KK=n(Kje,"A",{href:!0});var dPt=s(KK);uIr=r(dPt,"FlaxMBartModel"),dPt.forEach(t),pIr=r(Kje," (mBART model)"),Kje.forEach(t),_Ir=i(ae),j0=n(ae,"LI",{});var Zje=s(j0);Q5e=n(Zje,"STRONG",{});var cPt=s(Q5e);bIr=r(cPt,"mt5"),cPt.forEach(t),vIr=r(Zje," \u2014 "),ZK=n(Zje,"A",{href:!0});var mPt=s(ZK);FIr=r(mPt,"FlaxMT5Model"),mPt.forEach(t),TIr=r(Zje," (MT5 model)"),Zje.forEach(t),MIr=i(ae),D0=n(ae,"LI",{});var eDe=s(D0);W5e=n(eDe,"STRONG",{});var fPt=s(W5e);EIr=r(fPt,"opt"),fPt.forEach(t),CIr=r(eDe," \u2014 "),eZ=n(eDe,"A",{href:!0});var gPt=s(eZ);wIr=r(gPt,"FlaxOPTModel"),gPt.forEach(t),AIr=r(eDe," (OPT model)"),eDe.forEach(t),LIr=i(ae),G0=n(ae,"LI",{});var oDe=s(G0);H5e=n(oDe,"STRONG",{});var hPt=s(H5e);yIr=r(hPt,"pegasus"),hPt.forEach(t),xIr=r(oDe," \u2014 "),oZ=n(oDe,"A",{href:!0});var uPt=s(oZ);$Ir=r(uPt,"FlaxPegasusModel"),uPt.forEach(t),kIr=r(oDe," (Pegasus model)"),oDe.forEach(t),SIr=i(ae),O0=n(ae,"LI",{});var rDe=s(O0);U5e=n(rDe,"STRONG",{});var pPt=s(U5e);RIr=r(pPt,"roberta"),pPt.forEach(t),PIr=r(rDe," \u2014 "),rZ=n(rDe,"A",{href:!0});var _Pt=s(rZ);BIr=r(_Pt,"FlaxRobertaModel"),_Pt.forEach(t),IIr=r(rDe," (RoBERTa model)"),rDe.forEach(t),NIr=i(ae),V0=n(ae,"LI",{});var tDe=s(V0);J5e=n(tDe,"STRONG",{});var bPt=s(J5e);qIr=r(bPt,"roformer"),bPt.forEach(t),jIr=r(tDe," \u2014 "),tZ=n(tDe,"A",{href:!0});var vPt=s(tZ);DIr=r(vPt,"FlaxRoFormerModel"),vPt.forEach(t),GIr=r(tDe," (RoFormer model)"),tDe.forEach(t),OIr=i(ae),X0=n(ae,"LI",{});var aDe=s(X0);Y5e=n(aDe,"STRONG",{});var FPt=s(Y5e);VIr=r(FPt,"t5"),FPt.forEach(t),XIr=r(aDe," \u2014 "),aZ=n(aDe,"A",{href:!0});var TPt=s(aZ);zIr=r(TPt,"FlaxT5Model"),TPt.forEach(t),QIr=r(aDe," (T5 model)"),aDe.forEach(t),WIr=i(ae),z0=n(ae,"LI",{});var nDe=s(z0);K5e=n(nDe,"STRONG",{});var MPt=s(K5e);HIr=r(MPt,"vision-text-dual-encoder"),MPt.forEach(t),UIr=r(nDe," \u2014 "),nZ=n(nDe,"A",{href:!0});var EPt=s(nZ);JIr=r(EPt,"FlaxVisionTextDualEncoderModel"),EPt.forEach(t),YIr=r(nDe," (VisionTextDualEncoder model)"),nDe.forEach(t),KIr=i(ae),Q0=n(ae,"LI",{});var sDe=s(Q0);Z5e=n(sDe,"STRONG",{});var CPt=s(Z5e);ZIr=r(CPt,"vit"),CPt.forEach(t),eNr=r(sDe," \u2014 "),sZ=n(sDe,"A",{href:!0});var wPt=s(sZ);oNr=r(wPt,"FlaxViTModel"),wPt.forEach(t),rNr=r(sDe," (ViT model)"),sDe.forEach(t),tNr=i(ae),W0=n(ae,"LI",{});var lDe=s(W0);e3e=n(lDe,"STRONG",{});var APt=s(e3e);aNr=r(APt,"wav2vec2"),APt.forEach(t),nNr=r(lDe," \u2014 "),lZ=n(lDe,"A",{href:!0});var LPt=s(lZ);sNr=r(LPt,"FlaxWav2Vec2Model"),LPt.forEach(t),lNr=r(lDe," (Wav2Vec2 model)"),lDe.forEach(t),iNr=i(ae),H0=n(ae,"LI",{});var iDe=s(H0);o3e=n(iDe,"STRONG",{});var yPt=s(o3e);dNr=r(yPt,"xglm"),yPt.forEach(t),cNr=r(iDe," \u2014 "),iZ=n(iDe,"A",{href:!0});var xPt=s(iZ);mNr=r(xPt,"FlaxXGLMModel"),xPt.forEach(t),fNr=r(iDe," (XGLM model)"),iDe.forEach(t),gNr=i(ae),U0=n(ae,"LI",{});var dDe=s(U0);r3e=n(dDe,"STRONG",{});var $Pt=s(r3e);hNr=r($Pt,"xlm-roberta"),$Pt.forEach(t),uNr=r(dDe," \u2014 "),dZ=n(dDe,"A",{href:!0});var kPt=s(dZ);pNr=r(kPt,"FlaxXLMRobertaModel"),kPt.forEach(t),_Nr=r(dDe," (XLM-RoBERTa model)"),dDe.forEach(t),ae.forEach(t),bNr=i(Kl),T(J0.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),MVe=i(m),zc=n(m,"H2",{class:!0});var kze=s(zc);Y0=n(kze,"A",{id:!0,class:!0,href:!0});var SPt=s(Y0);t3e=n(SPt,"SPAN",{});var RPt=s(t3e);T(Nx.$$.fragment,RPt),RPt.forEach(t),SPt.forEach(t),vNr=i(kze),a3e=n(kze,"SPAN",{});var PPt=s(a3e);FNr=r(PPt,"FlaxAutoModelForCausalLM"),PPt.forEach(t),kze.forEach(t),EVe=i(m),ur=n(m,"DIV",{class:!0});var Zl=s(ur);T(qx.$$.fragment,Zl),TNr=i(Zl),Qc=n(Zl,"P",{});var Xre=s(Qc);MNr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=n(Xre,"A",{href:!0});var BPt=s(cZ);ENr=r(BPt,"from_pretrained()"),BPt.forEach(t),CNr=r(Xre," class method or the "),mZ=n(Xre,"A",{href:!0});var IPt=s(mZ);wNr=r(IPt,"from_config()"),IPt.forEach(t),ANr=r(Xre,` class
method.`),Xre.forEach(t),LNr=i(Zl),jx=n(Zl,"P",{});var Sze=s(jx);yNr=r(Sze,"This class cannot be instantiated directly using "),n3e=n(Sze,"CODE",{});var NPt=s(n3e);xNr=r(NPt,"__init__()"),NPt.forEach(t),$Nr=r(Sze," (throws an error)."),Sze.forEach(t),kNr=i(Zl),zt=n(Zl,"DIV",{class:!0});var ty=s(zt);T(Dx.$$.fragment,ty),SNr=i(ty),s3e=n(ty,"P",{});var qPt=s(s3e);RNr=r(qPt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qPt.forEach(t),PNr=i(ty),Wc=n(ty,"P",{});var zre=s(Wc);BNr=r(zre,`Note:
Loading a model from its configuration file does `),l3e=n(zre,"STRONG",{});var jPt=s(l3e);INr=r(jPt,"not"),jPt.forEach(t),NNr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=n(zre,"A",{href:!0});var DPt=s(fZ);qNr=r(DPt,"from_pretrained()"),DPt.forEach(t),jNr=r(zre," to load the model weights."),zre.forEach(t),DNr=i(ty),T(K0.$$.fragment,ty),ty.forEach(t),GNr=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(Gx.$$.fragment,ei),ONr=i(ei),i3e=n(ei,"P",{});var GPt=s(i3e);VNr=r(GPt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GPt.forEach(t),XNr=i(ei),Tn=n(ei,"P",{});var ay=s(Tn);zNr=r(ay,"The model class to instantiate is selected based on the "),d3e=n(ay,"CODE",{});var OPt=s(d3e);QNr=r(OPt,"model_type"),OPt.forEach(t),WNr=r(ay,` property of the config object (either
passed as an argument or loaded from `),c3e=n(ay,"CODE",{});var VPt=s(c3e);HNr=r(VPt,"pretrained_model_name_or_path"),VPt.forEach(t),UNr=r(ay,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m3e=n(ay,"CODE",{});var XPt=s(m3e);JNr=r(XPt,"pretrained_model_name_or_path"),XPt.forEach(t),YNr=r(ay,":"),ay.forEach(t),KNr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);Z0=n(Ne,"LI",{});var cDe=s(Z0);f3e=n(cDe,"STRONG",{});var zPt=s(f3e);ZNr=r(zPt,"bart"),zPt.forEach(t),eqr=r(cDe," \u2014 "),gZ=n(cDe,"A",{href:!0});var QPt=s(gZ);oqr=r(QPt,"FlaxBartForCausalLM"),QPt.forEach(t),rqr=r(cDe," (BART model)"),cDe.forEach(t),tqr=i(Ne),ew=n(Ne,"LI",{});var mDe=s(ew);g3e=n(mDe,"STRONG",{});var WPt=s(g3e);aqr=r(WPt,"bert"),WPt.forEach(t),nqr=r(mDe," \u2014 "),hZ=n(mDe,"A",{href:!0});var HPt=s(hZ);sqr=r(HPt,"FlaxBertForCausalLM"),HPt.forEach(t),lqr=r(mDe," (BERT model)"),mDe.forEach(t),iqr=i(Ne),ow=n(Ne,"LI",{});var fDe=s(ow);h3e=n(fDe,"STRONG",{});var UPt=s(h3e);dqr=r(UPt,"big_bird"),UPt.forEach(t),cqr=r(fDe," \u2014 "),uZ=n(fDe,"A",{href:!0});var JPt=s(uZ);mqr=r(JPt,"FlaxBigBirdForCausalLM"),JPt.forEach(t),fqr=r(fDe," (BigBird model)"),fDe.forEach(t),gqr=i(Ne),rw=n(Ne,"LI",{});var gDe=s(rw);u3e=n(gDe,"STRONG",{});var YPt=s(u3e);hqr=r(YPt,"electra"),YPt.forEach(t),uqr=r(gDe," \u2014 "),pZ=n(gDe,"A",{href:!0});var KPt=s(pZ);pqr=r(KPt,"FlaxElectraForCausalLM"),KPt.forEach(t),_qr=r(gDe," (ELECTRA model)"),gDe.forEach(t),bqr=i(Ne),tw=n(Ne,"LI",{});var hDe=s(tw);p3e=n(hDe,"STRONG",{});var ZPt=s(p3e);vqr=r(ZPt,"gpt2"),ZPt.forEach(t),Fqr=r(hDe," \u2014 "),_Z=n(hDe,"A",{href:!0});var eBt=s(_Z);Tqr=r(eBt,"FlaxGPT2LMHeadModel"),eBt.forEach(t),Mqr=r(hDe," (OpenAI GPT-2 model)"),hDe.forEach(t),Eqr=i(Ne),aw=n(Ne,"LI",{});var uDe=s(aw);_3e=n(uDe,"STRONG",{});var oBt=s(_3e);Cqr=r(oBt,"gpt_neo"),oBt.forEach(t),wqr=r(uDe," \u2014 "),bZ=n(uDe,"A",{href:!0});var rBt=s(bZ);Aqr=r(rBt,"FlaxGPTNeoForCausalLM"),rBt.forEach(t),Lqr=r(uDe," (GPT Neo model)"),uDe.forEach(t),yqr=i(Ne),nw=n(Ne,"LI",{});var pDe=s(nw);b3e=n(pDe,"STRONG",{});var tBt=s(b3e);xqr=r(tBt,"gptj"),tBt.forEach(t),$qr=r(pDe," \u2014 "),vZ=n(pDe,"A",{href:!0});var aBt=s(vZ);kqr=r(aBt,"FlaxGPTJForCausalLM"),aBt.forEach(t),Sqr=r(pDe," (GPT-J model)"),pDe.forEach(t),Rqr=i(Ne),sw=n(Ne,"LI",{});var _De=s(sw);v3e=n(_De,"STRONG",{});var nBt=s(v3e);Pqr=r(nBt,"opt"),nBt.forEach(t),Bqr=r(_De," \u2014 "),FZ=n(_De,"A",{href:!0});var sBt=s(FZ);Iqr=r(sBt,"FlaxOPTForCausalLM"),sBt.forEach(t),Nqr=r(_De," (OPT model)"),_De.forEach(t),qqr=i(Ne),lw=n(Ne,"LI",{});var bDe=s(lw);F3e=n(bDe,"STRONG",{});var lBt=s(F3e);jqr=r(lBt,"roberta"),lBt.forEach(t),Dqr=r(bDe," \u2014 "),TZ=n(bDe,"A",{href:!0});var iBt=s(TZ);Gqr=r(iBt,"FlaxRobertaForCausalLM"),iBt.forEach(t),Oqr=r(bDe," (RoBERTa model)"),bDe.forEach(t),Vqr=i(Ne),iw=n(Ne,"LI",{});var vDe=s(iw);T3e=n(vDe,"STRONG",{});var dBt=s(T3e);Xqr=r(dBt,"xglm"),dBt.forEach(t),zqr=r(vDe," \u2014 "),MZ=n(vDe,"A",{href:!0});var cBt=s(MZ);Qqr=r(cBt,"FlaxXGLMForCausalLM"),cBt.forEach(t),Wqr=r(vDe," (XGLM model)"),vDe.forEach(t),Ne.forEach(t),Hqr=i(ei),T(dw.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),CVe=i(m),Hc=n(m,"H2",{class:!0});var Rze=s(Hc);cw=n(Rze,"A",{id:!0,class:!0,href:!0});var mBt=s(cw);M3e=n(mBt,"SPAN",{});var fBt=s(M3e);T(Ox.$$.fragment,fBt),fBt.forEach(t),mBt.forEach(t),Uqr=i(Rze),E3e=n(Rze,"SPAN",{});var gBt=s(E3e);Jqr=r(gBt,"FlaxAutoModelForPreTraining"),gBt.forEach(t),Rze.forEach(t),wVe=i(m),pr=n(m,"DIV",{class:!0});var oi=s(pr);T(Vx.$$.fragment,oi),Yqr=i(oi),Uc=n(oi,"P",{});var Qre=s(Uc);Kqr=r(Qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=n(Qre,"A",{href:!0});var hBt=s(EZ);Zqr=r(hBt,"from_pretrained()"),hBt.forEach(t),ejr=r(Qre," class method or the "),CZ=n(Qre,"A",{href:!0});var uBt=s(CZ);ojr=r(uBt,"from_config()"),uBt.forEach(t),rjr=r(Qre,` class
method.`),Qre.forEach(t),tjr=i(oi),Xx=n(oi,"P",{});var Pze=s(Xx);ajr=r(Pze,"This class cannot be instantiated directly using "),C3e=n(Pze,"CODE",{});var pBt=s(C3e);njr=r(pBt,"__init__()"),pBt.forEach(t),sjr=r(Pze," (throws an error)."),Pze.forEach(t),ljr=i(oi),Qt=n(oi,"DIV",{class:!0});var ny=s(Qt);T(zx.$$.fragment,ny),ijr=i(ny),w3e=n(ny,"P",{});var _Bt=s(w3e);djr=r(_Bt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_Bt.forEach(t),cjr=i(ny),Jc=n(ny,"P",{});var Wre=s(Jc);mjr=r(Wre,`Note:
Loading a model from its configuration file does `),A3e=n(Wre,"STRONG",{});var bBt=s(A3e);fjr=r(bBt,"not"),bBt.forEach(t),gjr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Wre,"A",{href:!0});var vBt=s(wZ);hjr=r(vBt,"from_pretrained()"),vBt.forEach(t),ujr=r(Wre," to load the model weights."),Wre.forEach(t),pjr=i(ny),T(mw.$$.fragment,ny),ny.forEach(t),_jr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Qx.$$.fragment,ri),bjr=i(ri),L3e=n(ri,"P",{});var FBt=s(L3e);vjr=r(FBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FBt.forEach(t),Fjr=i(ri),Mn=n(ri,"P",{});var sy=s(Mn);Tjr=r(sy,"The model class to instantiate is selected based on the "),y3e=n(sy,"CODE",{});var TBt=s(y3e);Mjr=r(TBt,"model_type"),TBt.forEach(t),Ejr=r(sy,` property of the config object (either
passed as an argument or loaded from `),x3e=n(sy,"CODE",{});var MBt=s(x3e);Cjr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),wjr=r(sy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$3e=n(sy,"CODE",{});var EBt=s($3e);Ajr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),Ljr=r(sy,":"),sy.forEach(t),yjr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);fw=n(we,"LI",{});var FDe=s(fw);k3e=n(FDe,"STRONG",{});var CBt=s(k3e);xjr=r(CBt,"albert"),CBt.forEach(t),$jr=r(FDe," \u2014 "),AZ=n(FDe,"A",{href:!0});var wBt=s(AZ);kjr=r(wBt,"FlaxAlbertForPreTraining"),wBt.forEach(t),Sjr=r(FDe," (ALBERT model)"),FDe.forEach(t),Rjr=i(we),gw=n(we,"LI",{});var TDe=s(gw);S3e=n(TDe,"STRONG",{});var ABt=s(S3e);Pjr=r(ABt,"bart"),ABt.forEach(t),Bjr=r(TDe," \u2014 "),LZ=n(TDe,"A",{href:!0});var LBt=s(LZ);Ijr=r(LBt,"FlaxBartForConditionalGeneration"),LBt.forEach(t),Njr=r(TDe," (BART model)"),TDe.forEach(t),qjr=i(we),hw=n(we,"LI",{});var MDe=s(hw);R3e=n(MDe,"STRONG",{});var yBt=s(R3e);jjr=r(yBt,"bert"),yBt.forEach(t),Djr=r(MDe," \u2014 "),yZ=n(MDe,"A",{href:!0});var xBt=s(yZ);Gjr=r(xBt,"FlaxBertForPreTraining"),xBt.forEach(t),Ojr=r(MDe," (BERT model)"),MDe.forEach(t),Vjr=i(we),uw=n(we,"LI",{});var EDe=s(uw);P3e=n(EDe,"STRONG",{});var $Bt=s(P3e);Xjr=r($Bt,"big_bird"),$Bt.forEach(t),zjr=r(EDe," \u2014 "),xZ=n(EDe,"A",{href:!0});var kBt=s(xZ);Qjr=r(kBt,"FlaxBigBirdForPreTraining"),kBt.forEach(t),Wjr=r(EDe," (BigBird model)"),EDe.forEach(t),Hjr=i(we),pw=n(we,"LI",{});var CDe=s(pw);B3e=n(CDe,"STRONG",{});var SBt=s(B3e);Ujr=r(SBt,"electra"),SBt.forEach(t),Jjr=r(CDe," \u2014 "),$Z=n(CDe,"A",{href:!0});var RBt=s($Z);Yjr=r(RBt,"FlaxElectraForPreTraining"),RBt.forEach(t),Kjr=r(CDe," (ELECTRA model)"),CDe.forEach(t),Zjr=i(we),_w=n(we,"LI",{});var wDe=s(_w);I3e=n(wDe,"STRONG",{});var PBt=s(I3e);eDr=r(PBt,"longt5"),PBt.forEach(t),oDr=r(wDe," \u2014 "),kZ=n(wDe,"A",{href:!0});var BBt=s(kZ);rDr=r(BBt,"FlaxLongT5ForConditionalGeneration"),BBt.forEach(t),tDr=r(wDe," (LongT5 model)"),wDe.forEach(t),aDr=i(we),bw=n(we,"LI",{});var ADe=s(bw);N3e=n(ADe,"STRONG",{});var IBt=s(N3e);nDr=r(IBt,"mbart"),IBt.forEach(t),sDr=r(ADe," \u2014 "),SZ=n(ADe,"A",{href:!0});var NBt=s(SZ);lDr=r(NBt,"FlaxMBartForConditionalGeneration"),NBt.forEach(t),iDr=r(ADe," (mBART model)"),ADe.forEach(t),dDr=i(we),vw=n(we,"LI",{});var LDe=s(vw);q3e=n(LDe,"STRONG",{});var qBt=s(q3e);cDr=r(qBt,"mt5"),qBt.forEach(t),mDr=r(LDe," \u2014 "),RZ=n(LDe,"A",{href:!0});var jBt=s(RZ);fDr=r(jBt,"FlaxMT5ForConditionalGeneration"),jBt.forEach(t),gDr=r(LDe," (MT5 model)"),LDe.forEach(t),hDr=i(we),Fw=n(we,"LI",{});var yDe=s(Fw);j3e=n(yDe,"STRONG",{});var DBt=s(j3e);uDr=r(DBt,"roberta"),DBt.forEach(t),pDr=r(yDe," \u2014 "),PZ=n(yDe,"A",{href:!0});var GBt=s(PZ);_Dr=r(GBt,"FlaxRobertaForMaskedLM"),GBt.forEach(t),bDr=r(yDe," (RoBERTa model)"),yDe.forEach(t),vDr=i(we),Tw=n(we,"LI",{});var xDe=s(Tw);D3e=n(xDe,"STRONG",{});var OBt=s(D3e);FDr=r(OBt,"roformer"),OBt.forEach(t),TDr=r(xDe," \u2014 "),BZ=n(xDe,"A",{href:!0});var VBt=s(BZ);MDr=r(VBt,"FlaxRoFormerForMaskedLM"),VBt.forEach(t),EDr=r(xDe," (RoFormer model)"),xDe.forEach(t),CDr=i(we),Mw=n(we,"LI",{});var $De=s(Mw);G3e=n($De,"STRONG",{});var XBt=s(G3e);wDr=r(XBt,"t5"),XBt.forEach(t),ADr=r($De," \u2014 "),IZ=n($De,"A",{href:!0});var zBt=s(IZ);LDr=r(zBt,"FlaxT5ForConditionalGeneration"),zBt.forEach(t),yDr=r($De," (T5 model)"),$De.forEach(t),xDr=i(we),Ew=n(we,"LI",{});var kDe=s(Ew);O3e=n(kDe,"STRONG",{});var QBt=s(O3e);$Dr=r(QBt,"wav2vec2"),QBt.forEach(t),kDr=r(kDe," \u2014 "),NZ=n(kDe,"A",{href:!0});var WBt=s(NZ);SDr=r(WBt,"FlaxWav2Vec2ForPreTraining"),WBt.forEach(t),RDr=r(kDe," (Wav2Vec2 model)"),kDe.forEach(t),PDr=i(we),Cw=n(we,"LI",{});var SDe=s(Cw);V3e=n(SDe,"STRONG",{});var HBt=s(V3e);BDr=r(HBt,"xlm-roberta"),HBt.forEach(t),IDr=r(SDe," \u2014 "),qZ=n(SDe,"A",{href:!0});var UBt=s(qZ);NDr=r(UBt,"FlaxXLMRobertaForMaskedLM"),UBt.forEach(t),qDr=r(SDe," (XLM-RoBERTa model)"),SDe.forEach(t),we.forEach(t),jDr=i(ri),T(ww.$$.fragment,ri),ri.forEach(t),oi.forEach(t),AVe=i(m),Yc=n(m,"H2",{class:!0});var Bze=s(Yc);Aw=n(Bze,"A",{id:!0,class:!0,href:!0});var JBt=s(Aw);X3e=n(JBt,"SPAN",{});var YBt=s(X3e);T(Wx.$$.fragment,YBt),YBt.forEach(t),JBt.forEach(t),DDr=i(Bze),z3e=n(Bze,"SPAN",{});var KBt=s(z3e);GDr=r(KBt,"FlaxAutoModelForMaskedLM"),KBt.forEach(t),Bze.forEach(t),LVe=i(m),_r=n(m,"DIV",{class:!0});var ti=s(_r);T(Hx.$$.fragment,ti),ODr=i(ti),Kc=n(ti,"P",{});var Hre=s(Kc);VDr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=n(Hre,"A",{href:!0});var ZBt=s(jZ);XDr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),zDr=r(Hre," class method or the "),DZ=n(Hre,"A",{href:!0});var eIt=s(DZ);QDr=r(eIt,"from_config()"),eIt.forEach(t),WDr=r(Hre,` class
method.`),Hre.forEach(t),HDr=i(ti),Ux=n(ti,"P",{});var Ize=s(Ux);UDr=r(Ize,"This class cannot be instantiated directly using "),Q3e=n(Ize,"CODE",{});var oIt=s(Q3e);JDr=r(oIt,"__init__()"),oIt.forEach(t),YDr=r(Ize," (throws an error)."),Ize.forEach(t),KDr=i(ti),Wt=n(ti,"DIV",{class:!0});var ly=s(Wt);T(Jx.$$.fragment,ly),ZDr=i(ly),W3e=n(ly,"P",{});var rIt=s(W3e);eGr=r(rIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rIt.forEach(t),oGr=i(ly),Zc=n(ly,"P",{});var Ure=s(Zc);rGr=r(Ure,`Note:
Loading a model from its configuration file does `),H3e=n(Ure,"STRONG",{});var tIt=s(H3e);tGr=r(tIt,"not"),tIt.forEach(t),aGr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(Ure,"A",{href:!0});var aIt=s(GZ);nGr=r(aIt,"from_pretrained()"),aIt.forEach(t),sGr=r(Ure," to load the model weights."),Ure.forEach(t),lGr=i(ly),T(Lw.$$.fragment,ly),ly.forEach(t),iGr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(Yx.$$.fragment,ai),dGr=i(ai),U3e=n(ai,"P",{});var nIt=s(U3e);cGr=r(nIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nIt.forEach(t),mGr=i(ai),En=n(ai,"P",{});var iy=s(En);fGr=r(iy,"The model class to instantiate is selected based on the "),J3e=n(iy,"CODE",{});var sIt=s(J3e);gGr=r(sIt,"model_type"),sIt.forEach(t),hGr=r(iy,` property of the config object (either
passed as an argument or loaded from `),Y3e=n(iy,"CODE",{});var lIt=s(Y3e);uGr=r(lIt,"pretrained_model_name_or_path"),lIt.forEach(t),pGr=r(iy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K3e=n(iy,"CODE",{});var iIt=s(K3e);_Gr=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),bGr=r(iy,":"),iy.forEach(t),vGr=i(ai),$e=n(ai,"UL",{});var qe=s($e);yw=n(qe,"LI",{});var RDe=s(yw);Z3e=n(RDe,"STRONG",{});var dIt=s(Z3e);FGr=r(dIt,"albert"),dIt.forEach(t),TGr=r(RDe," \u2014 "),OZ=n(RDe,"A",{href:!0});var cIt=s(OZ);MGr=r(cIt,"FlaxAlbertForMaskedLM"),cIt.forEach(t),EGr=r(RDe," (ALBERT model)"),RDe.forEach(t),CGr=i(qe),xw=n(qe,"LI",{});var PDe=s(xw);e0e=n(PDe,"STRONG",{});var mIt=s(e0e);wGr=r(mIt,"bart"),mIt.forEach(t),AGr=r(PDe," \u2014 "),VZ=n(PDe,"A",{href:!0});var fIt=s(VZ);LGr=r(fIt,"FlaxBartForConditionalGeneration"),fIt.forEach(t),yGr=r(PDe," (BART model)"),PDe.forEach(t),xGr=i(qe),$w=n(qe,"LI",{});var BDe=s($w);o0e=n(BDe,"STRONG",{});var gIt=s(o0e);$Gr=r(gIt,"bert"),gIt.forEach(t),kGr=r(BDe," \u2014 "),XZ=n(BDe,"A",{href:!0});var hIt=s(XZ);SGr=r(hIt,"FlaxBertForMaskedLM"),hIt.forEach(t),RGr=r(BDe," (BERT model)"),BDe.forEach(t),PGr=i(qe),kw=n(qe,"LI",{});var IDe=s(kw);r0e=n(IDe,"STRONG",{});var uIt=s(r0e);BGr=r(uIt,"big_bird"),uIt.forEach(t),IGr=r(IDe," \u2014 "),zZ=n(IDe,"A",{href:!0});var pIt=s(zZ);NGr=r(pIt,"FlaxBigBirdForMaskedLM"),pIt.forEach(t),qGr=r(IDe," (BigBird model)"),IDe.forEach(t),jGr=i(qe),Sw=n(qe,"LI",{});var NDe=s(Sw);t0e=n(NDe,"STRONG",{});var _It=s(t0e);DGr=r(_It,"distilbert"),_It.forEach(t),GGr=r(NDe," \u2014 "),QZ=n(NDe,"A",{href:!0});var bIt=s(QZ);OGr=r(bIt,"FlaxDistilBertForMaskedLM"),bIt.forEach(t),VGr=r(NDe," (DistilBERT model)"),NDe.forEach(t),XGr=i(qe),Rw=n(qe,"LI",{});var qDe=s(Rw);a0e=n(qDe,"STRONG",{});var vIt=s(a0e);zGr=r(vIt,"electra"),vIt.forEach(t),QGr=r(qDe," \u2014 "),WZ=n(qDe,"A",{href:!0});var FIt=s(WZ);WGr=r(FIt,"FlaxElectraForMaskedLM"),FIt.forEach(t),HGr=r(qDe," (ELECTRA model)"),qDe.forEach(t),UGr=i(qe),Pw=n(qe,"LI",{});var jDe=s(Pw);n0e=n(jDe,"STRONG",{});var TIt=s(n0e);JGr=r(TIt,"mbart"),TIt.forEach(t),YGr=r(jDe," \u2014 "),HZ=n(jDe,"A",{href:!0});var MIt=s(HZ);KGr=r(MIt,"FlaxMBartForConditionalGeneration"),MIt.forEach(t),ZGr=r(jDe," (mBART model)"),jDe.forEach(t),eOr=i(qe),Bw=n(qe,"LI",{});var DDe=s(Bw);s0e=n(DDe,"STRONG",{});var EIt=s(s0e);oOr=r(EIt,"roberta"),EIt.forEach(t),rOr=r(DDe," \u2014 "),UZ=n(DDe,"A",{href:!0});var CIt=s(UZ);tOr=r(CIt,"FlaxRobertaForMaskedLM"),CIt.forEach(t),aOr=r(DDe," (RoBERTa model)"),DDe.forEach(t),nOr=i(qe),Iw=n(qe,"LI",{});var GDe=s(Iw);l0e=n(GDe,"STRONG",{});var wIt=s(l0e);sOr=r(wIt,"roformer"),wIt.forEach(t),lOr=r(GDe," \u2014 "),JZ=n(GDe,"A",{href:!0});var AIt=s(JZ);iOr=r(AIt,"FlaxRoFormerForMaskedLM"),AIt.forEach(t),dOr=r(GDe," (RoFormer model)"),GDe.forEach(t),cOr=i(qe),Nw=n(qe,"LI",{});var ODe=s(Nw);i0e=n(ODe,"STRONG",{});var LIt=s(i0e);mOr=r(LIt,"xlm-roberta"),LIt.forEach(t),fOr=r(ODe," \u2014 "),YZ=n(ODe,"A",{href:!0});var yIt=s(YZ);gOr=r(yIt,"FlaxXLMRobertaForMaskedLM"),yIt.forEach(t),hOr=r(ODe," (XLM-RoBERTa model)"),ODe.forEach(t),qe.forEach(t),uOr=i(ai),T(qw.$$.fragment,ai),ai.forEach(t),ti.forEach(t),yVe=i(m),em=n(m,"H2",{class:!0});var Nze=s(em);jw=n(Nze,"A",{id:!0,class:!0,href:!0});var xIt=s(jw);d0e=n(xIt,"SPAN",{});var $It=s(d0e);T(Kx.$$.fragment,$It),$It.forEach(t),xIt.forEach(t),pOr=i(Nze),c0e=n(Nze,"SPAN",{});var kIt=s(c0e);_Or=r(kIt,"FlaxAutoModelForSeq2SeqLM"),kIt.forEach(t),Nze.forEach(t),xVe=i(m),br=n(m,"DIV",{class:!0});var ni=s(br);T(Zx.$$.fragment,ni),bOr=i(ni),om=n(ni,"P",{});var Jre=s(om);vOr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=n(Jre,"A",{href:!0});var SIt=s(KZ);FOr=r(SIt,"from_pretrained()"),SIt.forEach(t),TOr=r(Jre," class method or the "),ZZ=n(Jre,"A",{href:!0});var RIt=s(ZZ);MOr=r(RIt,"from_config()"),RIt.forEach(t),EOr=r(Jre,` class
method.`),Jre.forEach(t),COr=i(ni),e$=n(ni,"P",{});var qze=s(e$);wOr=r(qze,"This class cannot be instantiated directly using "),m0e=n(qze,"CODE",{});var PIt=s(m0e);AOr=r(PIt,"__init__()"),PIt.forEach(t),LOr=r(qze," (throws an error)."),qze.forEach(t),yOr=i(ni),Ht=n(ni,"DIV",{class:!0});var dy=s(Ht);T(o$.$$.fragment,dy),xOr=i(dy),f0e=n(dy,"P",{});var BIt=s(f0e);$Or=r(BIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BIt.forEach(t),kOr=i(dy),rm=n(dy,"P",{});var Yre=s(rm);SOr=r(Yre,`Note:
Loading a model from its configuration file does `),g0e=n(Yre,"STRONG",{});var IIt=s(g0e);ROr=r(IIt,"not"),IIt.forEach(t),POr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=n(Yre,"A",{href:!0});var NIt=s(eee);BOr=r(NIt,"from_pretrained()"),NIt.forEach(t),IOr=r(Yre," to load the model weights."),Yre.forEach(t),NOr=i(dy),T(Dw.$$.fragment,dy),dy.forEach(t),qOr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(r$.$$.fragment,si),jOr=i(si),h0e=n(si,"P",{});var qIt=s(h0e);DOr=r(qIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qIt.forEach(t),GOr=i(si),Cn=n(si,"P",{});var cy=s(Cn);OOr=r(cy,"The model class to instantiate is selected based on the "),u0e=n(cy,"CODE",{});var jIt=s(u0e);VOr=r(jIt,"model_type"),jIt.forEach(t),XOr=r(cy,` property of the config object (either
passed as an argument or loaded from `),p0e=n(cy,"CODE",{});var DIt=s(p0e);zOr=r(DIt,"pretrained_model_name_or_path"),DIt.forEach(t),QOr=r(cy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=n(cy,"CODE",{});var GIt=s(_0e);WOr=r(GIt,"pretrained_model_name_or_path"),GIt.forEach(t),HOr=r(cy,":"),cy.forEach(t),UOr=i(si),ke=n(si,"UL",{});var je=s(ke);Gw=n(je,"LI",{});var VDe=s(Gw);b0e=n(VDe,"STRONG",{});var OIt=s(b0e);JOr=r(OIt,"bart"),OIt.forEach(t),YOr=r(VDe," \u2014 "),oee=n(VDe,"A",{href:!0});var VIt=s(oee);KOr=r(VIt,"FlaxBartForConditionalGeneration"),VIt.forEach(t),ZOr=r(VDe," (BART model)"),VDe.forEach(t),eVr=i(je),Ow=n(je,"LI",{});var XDe=s(Ow);v0e=n(XDe,"STRONG",{});var XIt=s(v0e);oVr=r(XIt,"blenderbot"),XIt.forEach(t),rVr=r(XDe," \u2014 "),ree=n(XDe,"A",{href:!0});var zIt=s(ree);tVr=r(zIt,"FlaxBlenderbotForConditionalGeneration"),zIt.forEach(t),aVr=r(XDe," (Blenderbot model)"),XDe.forEach(t),nVr=i(je),Vw=n(je,"LI",{});var zDe=s(Vw);F0e=n(zDe,"STRONG",{});var QIt=s(F0e);sVr=r(QIt,"blenderbot-small"),QIt.forEach(t),lVr=r(zDe," \u2014 "),tee=n(zDe,"A",{href:!0});var WIt=s(tee);iVr=r(WIt,"FlaxBlenderbotSmallForConditionalGeneration"),WIt.forEach(t),dVr=r(zDe," (BlenderbotSmall model)"),zDe.forEach(t),cVr=i(je),Xw=n(je,"LI",{});var QDe=s(Xw);T0e=n(QDe,"STRONG",{});var HIt=s(T0e);mVr=r(HIt,"encoder-decoder"),HIt.forEach(t),fVr=r(QDe," \u2014 "),aee=n(QDe,"A",{href:!0});var UIt=s(aee);gVr=r(UIt,"FlaxEncoderDecoderModel"),UIt.forEach(t),hVr=r(QDe," (Encoder decoder model)"),QDe.forEach(t),uVr=i(je),zw=n(je,"LI",{});var WDe=s(zw);M0e=n(WDe,"STRONG",{});var JIt=s(M0e);pVr=r(JIt,"longt5"),JIt.forEach(t),_Vr=r(WDe," \u2014 "),nee=n(WDe,"A",{href:!0});var YIt=s(nee);bVr=r(YIt,"FlaxLongT5ForConditionalGeneration"),YIt.forEach(t),vVr=r(WDe," (LongT5 model)"),WDe.forEach(t),FVr=i(je),Qw=n(je,"LI",{});var HDe=s(Qw);E0e=n(HDe,"STRONG",{});var KIt=s(E0e);TVr=r(KIt,"marian"),KIt.forEach(t),MVr=r(HDe," \u2014 "),see=n(HDe,"A",{href:!0});var ZIt=s(see);EVr=r(ZIt,"FlaxMarianMTModel"),ZIt.forEach(t),CVr=r(HDe," (Marian model)"),HDe.forEach(t),wVr=i(je),Ww=n(je,"LI",{});var UDe=s(Ww);C0e=n(UDe,"STRONG",{});var eNt=s(C0e);AVr=r(eNt,"mbart"),eNt.forEach(t),LVr=r(UDe," \u2014 "),lee=n(UDe,"A",{href:!0});var oNt=s(lee);yVr=r(oNt,"FlaxMBartForConditionalGeneration"),oNt.forEach(t),xVr=r(UDe," (mBART model)"),UDe.forEach(t),$Vr=i(je),Hw=n(je,"LI",{});var JDe=s(Hw);w0e=n(JDe,"STRONG",{});var rNt=s(w0e);kVr=r(rNt,"mt5"),rNt.forEach(t),SVr=r(JDe," \u2014 "),iee=n(JDe,"A",{href:!0});var tNt=s(iee);RVr=r(tNt,"FlaxMT5ForConditionalGeneration"),tNt.forEach(t),PVr=r(JDe," (MT5 model)"),JDe.forEach(t),BVr=i(je),Uw=n(je,"LI",{});var YDe=s(Uw);A0e=n(YDe,"STRONG",{});var aNt=s(A0e);IVr=r(aNt,"pegasus"),aNt.forEach(t),NVr=r(YDe," \u2014 "),dee=n(YDe,"A",{href:!0});var nNt=s(dee);qVr=r(nNt,"FlaxPegasusForConditionalGeneration"),nNt.forEach(t),jVr=r(YDe," (Pegasus model)"),YDe.forEach(t),DVr=i(je),Jw=n(je,"LI",{});var KDe=s(Jw);L0e=n(KDe,"STRONG",{});var sNt=s(L0e);GVr=r(sNt,"t5"),sNt.forEach(t),OVr=r(KDe," \u2014 "),cee=n(KDe,"A",{href:!0});var lNt=s(cee);VVr=r(lNt,"FlaxT5ForConditionalGeneration"),lNt.forEach(t),XVr=r(KDe," (T5 model)"),KDe.forEach(t),je.forEach(t),zVr=i(si),T(Yw.$$.fragment,si),si.forEach(t),ni.forEach(t),$Ve=i(m),tm=n(m,"H2",{class:!0});var jze=s(tm);Kw=n(jze,"A",{id:!0,class:!0,href:!0});var iNt=s(Kw);y0e=n(iNt,"SPAN",{});var dNt=s(y0e);T(t$.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),QVr=i(jze),x0e=n(jze,"SPAN",{});var cNt=s(x0e);WVr=r(cNt,"FlaxAutoModelForSequenceClassification"),cNt.forEach(t),jze.forEach(t),kVe=i(m),vr=n(m,"DIV",{class:!0});var li=s(vr);T(a$.$$.fragment,li),HVr=i(li),am=n(li,"P",{});var Kre=s(am);UVr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),mee=n(Kre,"A",{href:!0});var mNt=s(mee);JVr=r(mNt,"from_pretrained()"),mNt.forEach(t),YVr=r(Kre," class method or the "),fee=n(Kre,"A",{href:!0});var fNt=s(fee);KVr=r(fNt,"from_config()"),fNt.forEach(t),ZVr=r(Kre,` class
method.`),Kre.forEach(t),eXr=i(li),n$=n(li,"P",{});var Dze=s(n$);oXr=r(Dze,"This class cannot be instantiated directly using "),$0e=n(Dze,"CODE",{});var gNt=s($0e);rXr=r(gNt,"__init__()"),gNt.forEach(t),tXr=r(Dze," (throws an error)."),Dze.forEach(t),aXr=i(li),Ut=n(li,"DIV",{class:!0});var my=s(Ut);T(s$.$$.fragment,my),nXr=i(my),k0e=n(my,"P",{});var hNt=s(k0e);sXr=r(hNt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hNt.forEach(t),lXr=i(my),nm=n(my,"P",{});var Zre=s(nm);iXr=r(Zre,`Note:
Loading a model from its configuration file does `),S0e=n(Zre,"STRONG",{});var uNt=s(S0e);dXr=r(uNt,"not"),uNt.forEach(t),cXr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(Zre,"A",{href:!0});var pNt=s(gee);mXr=r(pNt,"from_pretrained()"),pNt.forEach(t),fXr=r(Zre," to load the model weights."),Zre.forEach(t),gXr=i(my),T(Zw.$$.fragment,my),my.forEach(t),hXr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(l$.$$.fragment,ii),uXr=i(ii),R0e=n(ii,"P",{});var _Nt=s(R0e);pXr=r(_Nt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_Nt.forEach(t),_Xr=i(ii),wn=n(ii,"P",{});var fy=s(wn);bXr=r(fy,"The model class to instantiate is selected based on the "),P0e=n(fy,"CODE",{});var bNt=s(P0e);vXr=r(bNt,"model_type"),bNt.forEach(t),FXr=r(fy,` property of the config object (either
passed as an argument or loaded from `),B0e=n(fy,"CODE",{});var vNt=s(B0e);TXr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),MXr=r(fy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I0e=n(fy,"CODE",{});var FNt=s(I0e);EXr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),CXr=r(fy,":"),fy.forEach(t),wXr=i(ii),Se=n(ii,"UL",{});var De=s(Se);eA=n(De,"LI",{});var ZDe=s(eA);N0e=n(ZDe,"STRONG",{});var TNt=s(N0e);AXr=r(TNt,"albert"),TNt.forEach(t),LXr=r(ZDe," \u2014 "),hee=n(ZDe,"A",{href:!0});var MNt=s(hee);yXr=r(MNt,"FlaxAlbertForSequenceClassification"),MNt.forEach(t),xXr=r(ZDe," (ALBERT model)"),ZDe.forEach(t),$Xr=i(De),oA=n(De,"LI",{});var eGe=s(oA);q0e=n(eGe,"STRONG",{});var ENt=s(q0e);kXr=r(ENt,"bart"),ENt.forEach(t),SXr=r(eGe," \u2014 "),uee=n(eGe,"A",{href:!0});var CNt=s(uee);RXr=r(CNt,"FlaxBartForSequenceClassification"),CNt.forEach(t),PXr=r(eGe," (BART model)"),eGe.forEach(t),BXr=i(De),rA=n(De,"LI",{});var oGe=s(rA);j0e=n(oGe,"STRONG",{});var wNt=s(j0e);IXr=r(wNt,"bert"),wNt.forEach(t),NXr=r(oGe," \u2014 "),pee=n(oGe,"A",{href:!0});var ANt=s(pee);qXr=r(ANt,"FlaxBertForSequenceClassification"),ANt.forEach(t),jXr=r(oGe," (BERT model)"),oGe.forEach(t),DXr=i(De),tA=n(De,"LI",{});var rGe=s(tA);D0e=n(rGe,"STRONG",{});var LNt=s(D0e);GXr=r(LNt,"big_bird"),LNt.forEach(t),OXr=r(rGe," \u2014 "),_ee=n(rGe,"A",{href:!0});var yNt=s(_ee);VXr=r(yNt,"FlaxBigBirdForSequenceClassification"),yNt.forEach(t),XXr=r(rGe," (BigBird model)"),rGe.forEach(t),zXr=i(De),aA=n(De,"LI",{});var tGe=s(aA);G0e=n(tGe,"STRONG",{});var xNt=s(G0e);QXr=r(xNt,"distilbert"),xNt.forEach(t),WXr=r(tGe," \u2014 "),bee=n(tGe,"A",{href:!0});var $Nt=s(bee);HXr=r($Nt,"FlaxDistilBertForSequenceClassification"),$Nt.forEach(t),UXr=r(tGe," (DistilBERT model)"),tGe.forEach(t),JXr=i(De),nA=n(De,"LI",{});var aGe=s(nA);O0e=n(aGe,"STRONG",{});var kNt=s(O0e);YXr=r(kNt,"electra"),kNt.forEach(t),KXr=r(aGe," \u2014 "),vee=n(aGe,"A",{href:!0});var SNt=s(vee);ZXr=r(SNt,"FlaxElectraForSequenceClassification"),SNt.forEach(t),ezr=r(aGe," (ELECTRA model)"),aGe.forEach(t),ozr=i(De),sA=n(De,"LI",{});var nGe=s(sA);V0e=n(nGe,"STRONG",{});var RNt=s(V0e);rzr=r(RNt,"mbart"),RNt.forEach(t),tzr=r(nGe," \u2014 "),Fee=n(nGe,"A",{href:!0});var PNt=s(Fee);azr=r(PNt,"FlaxMBartForSequenceClassification"),PNt.forEach(t),nzr=r(nGe," (mBART model)"),nGe.forEach(t),szr=i(De),lA=n(De,"LI",{});var sGe=s(lA);X0e=n(sGe,"STRONG",{});var BNt=s(X0e);lzr=r(BNt,"roberta"),BNt.forEach(t),izr=r(sGe," \u2014 "),Tee=n(sGe,"A",{href:!0});var INt=s(Tee);dzr=r(INt,"FlaxRobertaForSequenceClassification"),INt.forEach(t),czr=r(sGe," (RoBERTa model)"),sGe.forEach(t),mzr=i(De),iA=n(De,"LI",{});var lGe=s(iA);z0e=n(lGe,"STRONG",{});var NNt=s(z0e);fzr=r(NNt,"roformer"),NNt.forEach(t),gzr=r(lGe," \u2014 "),Mee=n(lGe,"A",{href:!0});var qNt=s(Mee);hzr=r(qNt,"FlaxRoFormerForSequenceClassification"),qNt.forEach(t),uzr=r(lGe," (RoFormer model)"),lGe.forEach(t),pzr=i(De),dA=n(De,"LI",{});var iGe=s(dA);Q0e=n(iGe,"STRONG",{});var jNt=s(Q0e);_zr=r(jNt,"xlm-roberta"),jNt.forEach(t),bzr=r(iGe," \u2014 "),Eee=n(iGe,"A",{href:!0});var DNt=s(Eee);vzr=r(DNt,"FlaxXLMRobertaForSequenceClassification"),DNt.forEach(t),Fzr=r(iGe," (XLM-RoBERTa model)"),iGe.forEach(t),De.forEach(t),Tzr=i(ii),T(cA.$$.fragment,ii),ii.forEach(t),li.forEach(t),SVe=i(m),sm=n(m,"H2",{class:!0});var Gze=s(sm);mA=n(Gze,"A",{id:!0,class:!0,href:!0});var GNt=s(mA);W0e=n(GNt,"SPAN",{});var ONt=s(W0e);T(i$.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),Mzr=i(Gze),H0e=n(Gze,"SPAN",{});var VNt=s(H0e);Ezr=r(VNt,"FlaxAutoModelForQuestionAnswering"),VNt.forEach(t),Gze.forEach(t),RVe=i(m),Fr=n(m,"DIV",{class:!0});var di=s(Fr);T(d$.$$.fragment,di),Czr=i(di),lm=n(di,"P",{});var ete=s(lm);wzr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=n(ete,"A",{href:!0});var XNt=s(Cee);Azr=r(XNt,"from_pretrained()"),XNt.forEach(t),Lzr=r(ete," class method or the "),wee=n(ete,"A",{href:!0});var zNt=s(wee);yzr=r(zNt,"from_config()"),zNt.forEach(t),xzr=r(ete,` class
method.`),ete.forEach(t),$zr=i(di),c$=n(di,"P",{});var Oze=s(c$);kzr=r(Oze,"This class cannot be instantiated directly using "),U0e=n(Oze,"CODE",{});var QNt=s(U0e);Szr=r(QNt,"__init__()"),QNt.forEach(t),Rzr=r(Oze," (throws an error)."),Oze.forEach(t),Pzr=i(di),Jt=n(di,"DIV",{class:!0});var gy=s(Jt);T(m$.$$.fragment,gy),Bzr=i(gy),J0e=n(gy,"P",{});var WNt=s(J0e);Izr=r(WNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WNt.forEach(t),Nzr=i(gy),im=n(gy,"P",{});var ote=s(im);qzr=r(ote,`Note:
Loading a model from its configuration file does `),Y0e=n(ote,"STRONG",{});var HNt=s(Y0e);jzr=r(HNt,"not"),HNt.forEach(t),Dzr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=n(ote,"A",{href:!0});var UNt=s(Aee);Gzr=r(UNt,"from_pretrained()"),UNt.forEach(t),Ozr=r(ote," to load the model weights."),ote.forEach(t),Vzr=i(gy),T(fA.$$.fragment,gy),gy.forEach(t),Xzr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(f$.$$.fragment,ci),zzr=i(ci),K0e=n(ci,"P",{});var JNt=s(K0e);Qzr=r(JNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JNt.forEach(t),Wzr=i(ci),An=n(ci,"P",{});var hy=s(An);Hzr=r(hy,"The model class to instantiate is selected based on the "),Z0e=n(hy,"CODE",{});var YNt=s(Z0e);Uzr=r(YNt,"model_type"),YNt.forEach(t),Jzr=r(hy,` property of the config object (either
passed as an argument or loaded from `),ewe=n(hy,"CODE",{});var KNt=s(ewe);Yzr=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),Kzr=r(hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),owe=n(hy,"CODE",{});var ZNt=s(owe);Zzr=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),eQr=r(hy,":"),hy.forEach(t),oQr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);gA=n(Ge,"LI",{});var dGe=s(gA);rwe=n(dGe,"STRONG",{});var eqt=s(rwe);rQr=r(eqt,"albert"),eqt.forEach(t),tQr=r(dGe," \u2014 "),Lee=n(dGe,"A",{href:!0});var oqt=s(Lee);aQr=r(oqt,"FlaxAlbertForQuestionAnswering"),oqt.forEach(t),nQr=r(dGe," (ALBERT model)"),dGe.forEach(t),sQr=i(Ge),hA=n(Ge,"LI",{});var cGe=s(hA);twe=n(cGe,"STRONG",{});var rqt=s(twe);lQr=r(rqt,"bart"),rqt.forEach(t),iQr=r(cGe," \u2014 "),yee=n(cGe,"A",{href:!0});var tqt=s(yee);dQr=r(tqt,"FlaxBartForQuestionAnswering"),tqt.forEach(t),cQr=r(cGe," (BART model)"),cGe.forEach(t),mQr=i(Ge),uA=n(Ge,"LI",{});var mGe=s(uA);awe=n(mGe,"STRONG",{});var aqt=s(awe);fQr=r(aqt,"bert"),aqt.forEach(t),gQr=r(mGe," \u2014 "),xee=n(mGe,"A",{href:!0});var nqt=s(xee);hQr=r(nqt,"FlaxBertForQuestionAnswering"),nqt.forEach(t),uQr=r(mGe," (BERT model)"),mGe.forEach(t),pQr=i(Ge),pA=n(Ge,"LI",{});var fGe=s(pA);nwe=n(fGe,"STRONG",{});var sqt=s(nwe);_Qr=r(sqt,"big_bird"),sqt.forEach(t),bQr=r(fGe," \u2014 "),$ee=n(fGe,"A",{href:!0});var lqt=s($ee);vQr=r(lqt,"FlaxBigBirdForQuestionAnswering"),lqt.forEach(t),FQr=r(fGe," (BigBird model)"),fGe.forEach(t),TQr=i(Ge),_A=n(Ge,"LI",{});var gGe=s(_A);swe=n(gGe,"STRONG",{});var iqt=s(swe);MQr=r(iqt,"distilbert"),iqt.forEach(t),EQr=r(gGe," \u2014 "),kee=n(gGe,"A",{href:!0});var dqt=s(kee);CQr=r(dqt,"FlaxDistilBertForQuestionAnswering"),dqt.forEach(t),wQr=r(gGe," (DistilBERT model)"),gGe.forEach(t),AQr=i(Ge),bA=n(Ge,"LI",{});var hGe=s(bA);lwe=n(hGe,"STRONG",{});var cqt=s(lwe);LQr=r(cqt,"electra"),cqt.forEach(t),yQr=r(hGe," \u2014 "),See=n(hGe,"A",{href:!0});var mqt=s(See);xQr=r(mqt,"FlaxElectraForQuestionAnswering"),mqt.forEach(t),$Qr=r(hGe," (ELECTRA model)"),hGe.forEach(t),kQr=i(Ge),vA=n(Ge,"LI",{});var uGe=s(vA);iwe=n(uGe,"STRONG",{});var fqt=s(iwe);SQr=r(fqt,"mbart"),fqt.forEach(t),RQr=r(uGe," \u2014 "),Ree=n(uGe,"A",{href:!0});var gqt=s(Ree);PQr=r(gqt,"FlaxMBartForQuestionAnswering"),gqt.forEach(t),BQr=r(uGe," (mBART model)"),uGe.forEach(t),IQr=i(Ge),FA=n(Ge,"LI",{});var pGe=s(FA);dwe=n(pGe,"STRONG",{});var hqt=s(dwe);NQr=r(hqt,"roberta"),hqt.forEach(t),qQr=r(pGe," \u2014 "),Pee=n(pGe,"A",{href:!0});var uqt=s(Pee);jQr=r(uqt,"FlaxRobertaForQuestionAnswering"),uqt.forEach(t),DQr=r(pGe," (RoBERTa model)"),pGe.forEach(t),GQr=i(Ge),TA=n(Ge,"LI",{});var _Ge=s(TA);cwe=n(_Ge,"STRONG",{});var pqt=s(cwe);OQr=r(pqt,"roformer"),pqt.forEach(t),VQr=r(_Ge," \u2014 "),Bee=n(_Ge,"A",{href:!0});var _qt=s(Bee);XQr=r(_qt,"FlaxRoFormerForQuestionAnswering"),_qt.forEach(t),zQr=r(_Ge," (RoFormer model)"),_Ge.forEach(t),QQr=i(Ge),MA=n(Ge,"LI",{});var bGe=s(MA);mwe=n(bGe,"STRONG",{});var bqt=s(mwe);WQr=r(bqt,"xlm-roberta"),bqt.forEach(t),HQr=r(bGe," \u2014 "),Iee=n(bGe,"A",{href:!0});var vqt=s(Iee);UQr=r(vqt,"FlaxXLMRobertaForQuestionAnswering"),vqt.forEach(t),JQr=r(bGe," (XLM-RoBERTa model)"),bGe.forEach(t),Ge.forEach(t),YQr=i(ci),T(EA.$$.fragment,ci),ci.forEach(t),di.forEach(t),PVe=i(m),dm=n(m,"H2",{class:!0});var Vze=s(dm);CA=n(Vze,"A",{id:!0,class:!0,href:!0});var Fqt=s(CA);fwe=n(Fqt,"SPAN",{});var Tqt=s(fwe);T(g$.$$.fragment,Tqt),Tqt.forEach(t),Fqt.forEach(t),KQr=i(Vze),gwe=n(Vze,"SPAN",{});var Mqt=s(gwe);ZQr=r(Mqt,"FlaxAutoModelForTokenClassification"),Mqt.forEach(t),Vze.forEach(t),BVe=i(m),Tr=n(m,"DIV",{class:!0});var mi=s(Tr);T(h$.$$.fragment,mi),eWr=i(mi),cm=n(mi,"P",{});var rte=s(cm);oWr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=n(rte,"A",{href:!0});var Eqt=s(Nee);rWr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),tWr=r(rte," class method or the "),qee=n(rte,"A",{href:!0});var Cqt=s(qee);aWr=r(Cqt,"from_config()"),Cqt.forEach(t),nWr=r(rte,` class
method.`),rte.forEach(t),sWr=i(mi),u$=n(mi,"P",{});var Xze=s(u$);lWr=r(Xze,"This class cannot be instantiated directly using "),hwe=n(Xze,"CODE",{});var wqt=s(hwe);iWr=r(wqt,"__init__()"),wqt.forEach(t),dWr=r(Xze," (throws an error)."),Xze.forEach(t),cWr=i(mi),Yt=n(mi,"DIV",{class:!0});var uy=s(Yt);T(p$.$$.fragment,uy),mWr=i(uy),uwe=n(uy,"P",{});var Aqt=s(uwe);fWr=r(Aqt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aqt.forEach(t),gWr=i(uy),mm=n(uy,"P",{});var tte=s(mm);hWr=r(tte,`Note:
Loading a model from its configuration file does `),pwe=n(tte,"STRONG",{});var Lqt=s(pwe);uWr=r(Lqt,"not"),Lqt.forEach(t),pWr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=n(tte,"A",{href:!0});var yqt=s(jee);_Wr=r(yqt,"from_pretrained()"),yqt.forEach(t),bWr=r(tte," to load the model weights."),tte.forEach(t),vWr=i(uy),T(wA.$$.fragment,uy),uy.forEach(t),FWr=i(mi),Ur=n(mi,"DIV",{class:!0});var fi=s(Ur);T(_$.$$.fragment,fi),TWr=i(fi),_we=n(fi,"P",{});var xqt=s(_we);MWr=r(xqt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xqt.forEach(t),EWr=i(fi),Ln=n(fi,"P",{});var py=s(Ln);CWr=r(py,"The model class to instantiate is selected based on the "),bwe=n(py,"CODE",{});var $qt=s(bwe);wWr=r($qt,"model_type"),$qt.forEach(t),AWr=r(py,` property of the config object (either
passed as an argument or loaded from `),vwe=n(py,"CODE",{});var kqt=s(vwe);LWr=r(kqt,"pretrained_model_name_or_path"),kqt.forEach(t),yWr=r(py,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=n(py,"CODE",{});var Sqt=s(Fwe);xWr=r(Sqt,"pretrained_model_name_or_path"),Sqt.forEach(t),$Wr=r(py,":"),py.forEach(t),kWr=i(fi),Ve=n(fi,"UL",{});var To=s(Ve);AA=n(To,"LI",{});var vGe=s(AA);Twe=n(vGe,"STRONG",{});var Rqt=s(Twe);SWr=r(Rqt,"albert"),Rqt.forEach(t),RWr=r(vGe," \u2014 "),Dee=n(vGe,"A",{href:!0});var Pqt=s(Dee);PWr=r(Pqt,"FlaxAlbertForTokenClassification"),Pqt.forEach(t),BWr=r(vGe," (ALBERT model)"),vGe.forEach(t),IWr=i(To),LA=n(To,"LI",{});var FGe=s(LA);Mwe=n(FGe,"STRONG",{});var Bqt=s(Mwe);NWr=r(Bqt,"bert"),Bqt.forEach(t),qWr=r(FGe," \u2014 "),Gee=n(FGe,"A",{href:!0});var Iqt=s(Gee);jWr=r(Iqt,"FlaxBertForTokenClassification"),Iqt.forEach(t),DWr=r(FGe," (BERT model)"),FGe.forEach(t),GWr=i(To),yA=n(To,"LI",{});var TGe=s(yA);Ewe=n(TGe,"STRONG",{});var Nqt=s(Ewe);OWr=r(Nqt,"big_bird"),Nqt.forEach(t),VWr=r(TGe," \u2014 "),Oee=n(TGe,"A",{href:!0});var qqt=s(Oee);XWr=r(qqt,"FlaxBigBirdForTokenClassification"),qqt.forEach(t),zWr=r(TGe," (BigBird model)"),TGe.forEach(t),QWr=i(To),xA=n(To,"LI",{});var MGe=s(xA);Cwe=n(MGe,"STRONG",{});var jqt=s(Cwe);WWr=r(jqt,"distilbert"),jqt.forEach(t),HWr=r(MGe," \u2014 "),Vee=n(MGe,"A",{href:!0});var Dqt=s(Vee);UWr=r(Dqt,"FlaxDistilBertForTokenClassification"),Dqt.forEach(t),JWr=r(MGe," (DistilBERT model)"),MGe.forEach(t),YWr=i(To),$A=n(To,"LI",{});var EGe=s($A);wwe=n(EGe,"STRONG",{});var Gqt=s(wwe);KWr=r(Gqt,"electra"),Gqt.forEach(t),ZWr=r(EGe," \u2014 "),Xee=n(EGe,"A",{href:!0});var Oqt=s(Xee);eHr=r(Oqt,"FlaxElectraForTokenClassification"),Oqt.forEach(t),oHr=r(EGe," (ELECTRA model)"),EGe.forEach(t),rHr=i(To),kA=n(To,"LI",{});var CGe=s(kA);Awe=n(CGe,"STRONG",{});var Vqt=s(Awe);tHr=r(Vqt,"roberta"),Vqt.forEach(t),aHr=r(CGe," \u2014 "),zee=n(CGe,"A",{href:!0});var Xqt=s(zee);nHr=r(Xqt,"FlaxRobertaForTokenClassification"),Xqt.forEach(t),sHr=r(CGe," (RoBERTa model)"),CGe.forEach(t),lHr=i(To),SA=n(To,"LI",{});var wGe=s(SA);Lwe=n(wGe,"STRONG",{});var zqt=s(Lwe);iHr=r(zqt,"roformer"),zqt.forEach(t),dHr=r(wGe," \u2014 "),Qee=n(wGe,"A",{href:!0});var Qqt=s(Qee);cHr=r(Qqt,"FlaxRoFormerForTokenClassification"),Qqt.forEach(t),mHr=r(wGe," (RoFormer model)"),wGe.forEach(t),fHr=i(To),RA=n(To,"LI",{});var AGe=s(RA);ywe=n(AGe,"STRONG",{});var Wqt=s(ywe);gHr=r(Wqt,"xlm-roberta"),Wqt.forEach(t),hHr=r(AGe," \u2014 "),Wee=n(AGe,"A",{href:!0});var Hqt=s(Wee);uHr=r(Hqt,"FlaxXLMRobertaForTokenClassification"),Hqt.forEach(t),pHr=r(AGe," (XLM-RoBERTa model)"),AGe.forEach(t),To.forEach(t),_Hr=i(fi),T(PA.$$.fragment,fi),fi.forEach(t),mi.forEach(t),IVe=i(m),fm=n(m,"H2",{class:!0});var zze=s(fm);BA=n(zze,"A",{id:!0,class:!0,href:!0});var Uqt=s(BA);xwe=n(Uqt,"SPAN",{});var Jqt=s(xwe);T(b$.$$.fragment,Jqt),Jqt.forEach(t),Uqt.forEach(t),bHr=i(zze),$we=n(zze,"SPAN",{});var Yqt=s($we);vHr=r(Yqt,"FlaxAutoModelForMultipleChoice"),Yqt.forEach(t),zze.forEach(t),NVe=i(m),Mr=n(m,"DIV",{class:!0});var gi=s(Mr);T(v$.$$.fragment,gi),FHr=i(gi),gm=n(gi,"P",{});var ate=s(gm);THr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=n(ate,"A",{href:!0});var Kqt=s(Hee);MHr=r(Kqt,"from_pretrained()"),Kqt.forEach(t),EHr=r(ate," class method or the "),Uee=n(ate,"A",{href:!0});var Zqt=s(Uee);CHr=r(Zqt,"from_config()"),Zqt.forEach(t),wHr=r(ate,` class
method.`),ate.forEach(t),AHr=i(gi),F$=n(gi,"P",{});var Qze=s(F$);LHr=r(Qze,"This class cannot be instantiated directly using "),kwe=n(Qze,"CODE",{});var ejt=s(kwe);yHr=r(ejt,"__init__()"),ejt.forEach(t),xHr=r(Qze," (throws an error)."),Qze.forEach(t),$Hr=i(gi),Kt=n(gi,"DIV",{class:!0});var _y=s(Kt);T(T$.$$.fragment,_y),kHr=i(_y),Swe=n(_y,"P",{});var ojt=s(Swe);SHr=r(ojt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ojt.forEach(t),RHr=i(_y),hm=n(_y,"P",{});var nte=s(hm);PHr=r(nte,`Note:
Loading a model from its configuration file does `),Rwe=n(nte,"STRONG",{});var rjt=s(Rwe);BHr=r(rjt,"not"),rjt.forEach(t),IHr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(nte,"A",{href:!0});var tjt=s(Jee);NHr=r(tjt,"from_pretrained()"),tjt.forEach(t),qHr=r(nte," to load the model weights."),nte.forEach(t),jHr=i(_y),T(IA.$$.fragment,_y),_y.forEach(t),DHr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(M$.$$.fragment,hi),GHr=i(hi),Pwe=n(hi,"P",{});var ajt=s(Pwe);OHr=r(ajt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ajt.forEach(t),VHr=i(hi),yn=n(hi,"P",{});var by=s(yn);XHr=r(by,"The model class to instantiate is selected based on the "),Bwe=n(by,"CODE",{});var njt=s(Bwe);zHr=r(njt,"model_type"),njt.forEach(t),QHr=r(by,` property of the config object (either
passed as an argument or loaded from `),Iwe=n(by,"CODE",{});var sjt=s(Iwe);WHr=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),HHr=r(by,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nwe=n(by,"CODE",{});var ljt=s(Nwe);UHr=r(ljt,"pretrained_model_name_or_path"),ljt.forEach(t),JHr=r(by,":"),by.forEach(t),YHr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);NA=n(Mo,"LI",{});var LGe=s(NA);qwe=n(LGe,"STRONG",{});var ijt=s(qwe);KHr=r(ijt,"albert"),ijt.forEach(t),ZHr=r(LGe," \u2014 "),Yee=n(LGe,"A",{href:!0});var djt=s(Yee);eUr=r(djt,"FlaxAlbertForMultipleChoice"),djt.forEach(t),oUr=r(LGe," (ALBERT model)"),LGe.forEach(t),rUr=i(Mo),qA=n(Mo,"LI",{});var yGe=s(qA);jwe=n(yGe,"STRONG",{});var cjt=s(jwe);tUr=r(cjt,"bert"),cjt.forEach(t),aUr=r(yGe," \u2014 "),Kee=n(yGe,"A",{href:!0});var mjt=s(Kee);nUr=r(mjt,"FlaxBertForMultipleChoice"),mjt.forEach(t),sUr=r(yGe," (BERT model)"),yGe.forEach(t),lUr=i(Mo),jA=n(Mo,"LI",{});var xGe=s(jA);Dwe=n(xGe,"STRONG",{});var fjt=s(Dwe);iUr=r(fjt,"big_bird"),fjt.forEach(t),dUr=r(xGe," \u2014 "),Zee=n(xGe,"A",{href:!0});var gjt=s(Zee);cUr=r(gjt,"FlaxBigBirdForMultipleChoice"),gjt.forEach(t),mUr=r(xGe," (BigBird model)"),xGe.forEach(t),fUr=i(Mo),DA=n(Mo,"LI",{});var $Ge=s(DA);Gwe=n($Ge,"STRONG",{});var hjt=s(Gwe);gUr=r(hjt,"distilbert"),hjt.forEach(t),hUr=r($Ge," \u2014 "),eoe=n($Ge,"A",{href:!0});var ujt=s(eoe);uUr=r(ujt,"FlaxDistilBertForMultipleChoice"),ujt.forEach(t),pUr=r($Ge," (DistilBERT model)"),$Ge.forEach(t),_Ur=i(Mo),GA=n(Mo,"LI",{});var kGe=s(GA);Owe=n(kGe,"STRONG",{});var pjt=s(Owe);bUr=r(pjt,"electra"),pjt.forEach(t),vUr=r(kGe," \u2014 "),ooe=n(kGe,"A",{href:!0});var _jt=s(ooe);FUr=r(_jt,"FlaxElectraForMultipleChoice"),_jt.forEach(t),TUr=r(kGe," (ELECTRA model)"),kGe.forEach(t),MUr=i(Mo),OA=n(Mo,"LI",{});var SGe=s(OA);Vwe=n(SGe,"STRONG",{});var bjt=s(Vwe);EUr=r(bjt,"roberta"),bjt.forEach(t),CUr=r(SGe," \u2014 "),roe=n(SGe,"A",{href:!0});var vjt=s(roe);wUr=r(vjt,"FlaxRobertaForMultipleChoice"),vjt.forEach(t),AUr=r(SGe," (RoBERTa model)"),SGe.forEach(t),LUr=i(Mo),VA=n(Mo,"LI",{});var RGe=s(VA);Xwe=n(RGe,"STRONG",{});var Fjt=s(Xwe);yUr=r(Fjt,"roformer"),Fjt.forEach(t),xUr=r(RGe," \u2014 "),toe=n(RGe,"A",{href:!0});var Tjt=s(toe);$Ur=r(Tjt,"FlaxRoFormerForMultipleChoice"),Tjt.forEach(t),kUr=r(RGe," (RoFormer model)"),RGe.forEach(t),SUr=i(Mo),XA=n(Mo,"LI",{});var PGe=s(XA);zwe=n(PGe,"STRONG",{});var Mjt=s(zwe);RUr=r(Mjt,"xlm-roberta"),Mjt.forEach(t),PUr=r(PGe," \u2014 "),aoe=n(PGe,"A",{href:!0});var Ejt=s(aoe);BUr=r(Ejt,"FlaxXLMRobertaForMultipleChoice"),Ejt.forEach(t),IUr=r(PGe," (XLM-RoBERTa model)"),PGe.forEach(t),Mo.forEach(t),NUr=i(hi),T(zA.$$.fragment,hi),hi.forEach(t),gi.forEach(t),qVe=i(m),um=n(m,"H2",{class:!0});var Wze=s(um);QA=n(Wze,"A",{id:!0,class:!0,href:!0});var Cjt=s(QA);Qwe=n(Cjt,"SPAN",{});var wjt=s(Qwe);T(E$.$$.fragment,wjt),wjt.forEach(t),Cjt.forEach(t),qUr=i(Wze),Wwe=n(Wze,"SPAN",{});var Ajt=s(Wwe);jUr=r(Ajt,"FlaxAutoModelForNextSentencePrediction"),Ajt.forEach(t),Wze.forEach(t),jVe=i(m),Er=n(m,"DIV",{class:!0});var ui=s(Er);T(C$.$$.fragment,ui),DUr=i(ui),pm=n(ui,"P",{});var ste=s(pm);GUr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=n(ste,"A",{href:!0});var Ljt=s(noe);OUr=r(Ljt,"from_pretrained()"),Ljt.forEach(t),VUr=r(ste," class method or the "),soe=n(ste,"A",{href:!0});var yjt=s(soe);XUr=r(yjt,"from_config()"),yjt.forEach(t),zUr=r(ste,` class
method.`),ste.forEach(t),QUr=i(ui),w$=n(ui,"P",{});var Hze=s(w$);WUr=r(Hze,"This class cannot be instantiated directly using "),Hwe=n(Hze,"CODE",{});var xjt=s(Hwe);HUr=r(xjt,"__init__()"),xjt.forEach(t),UUr=r(Hze," (throws an error)."),Hze.forEach(t),JUr=i(ui),Zt=n(ui,"DIV",{class:!0});var vy=s(Zt);T(A$.$$.fragment,vy),YUr=i(vy),Uwe=n(vy,"P",{});var $jt=s(Uwe);KUr=r($jt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$jt.forEach(t),ZUr=i(vy),_m=n(vy,"P",{});var lte=s(_m);eJr=r(lte,`Note:
Loading a model from its configuration file does `),Jwe=n(lte,"STRONG",{});var kjt=s(Jwe);oJr=r(kjt,"not"),kjt.forEach(t),rJr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=n(lte,"A",{href:!0});var Sjt=s(loe);tJr=r(Sjt,"from_pretrained()"),Sjt.forEach(t),aJr=r(lte," to load the model weights."),lte.forEach(t),nJr=i(vy),T(WA.$$.fragment,vy),vy.forEach(t),sJr=i(ui),Yr=n(ui,"DIV",{class:!0});var pi=s(Yr);T(L$.$$.fragment,pi),lJr=i(pi),Ywe=n(pi,"P",{});var Rjt=s(Ywe);iJr=r(Rjt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rjt.forEach(t),dJr=i(pi),xn=n(pi,"P",{});var Fy=s(xn);cJr=r(Fy,"The model class to instantiate is selected based on the "),Kwe=n(Fy,"CODE",{});var Pjt=s(Kwe);mJr=r(Pjt,"model_type"),Pjt.forEach(t),fJr=r(Fy,` property of the config object (either
passed as an argument or loaded from `),Zwe=n(Fy,"CODE",{});var Bjt=s(Zwe);gJr=r(Bjt,"pretrained_model_name_or_path"),Bjt.forEach(t),hJr=r(Fy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eAe=n(Fy,"CODE",{});var Ijt=s(eAe);uJr=r(Ijt,"pretrained_model_name_or_path"),Ijt.forEach(t),pJr=r(Fy,":"),Fy.forEach(t),_Jr=i(pi),oAe=n(pi,"UL",{});var Njt=s(oAe);HA=n(Njt,"LI",{});var BGe=s(HA);rAe=n(BGe,"STRONG",{});var qjt=s(rAe);bJr=r(qjt,"bert"),qjt.forEach(t),vJr=r(BGe," \u2014 "),ioe=n(BGe,"A",{href:!0});var jjt=s(ioe);FJr=r(jjt,"FlaxBertForNextSentencePrediction"),jjt.forEach(t),TJr=r(BGe," (BERT model)"),BGe.forEach(t),Njt.forEach(t),MJr=i(pi),T(UA.$$.fragment,pi),pi.forEach(t),ui.forEach(t),DVe=i(m),bm=n(m,"H2",{class:!0});var Uze=s(bm);JA=n(Uze,"A",{id:!0,class:!0,href:!0});var Djt=s(JA);tAe=n(Djt,"SPAN",{});var Gjt=s(tAe);T(y$.$$.fragment,Gjt),Gjt.forEach(t),Djt.forEach(t),EJr=i(Uze),aAe=n(Uze,"SPAN",{});var Ojt=s(aAe);CJr=r(Ojt,"FlaxAutoModelForImageClassification"),Ojt.forEach(t),Uze.forEach(t),GVe=i(m),Cr=n(m,"DIV",{class:!0});var _i=s(Cr);T(x$.$$.fragment,_i),wJr=i(_i),vm=n(_i,"P",{});var ite=s(vm);AJr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=n(ite,"A",{href:!0});var Vjt=s(doe);LJr=r(Vjt,"from_pretrained()"),Vjt.forEach(t),yJr=r(ite," class method or the "),coe=n(ite,"A",{href:!0});var Xjt=s(coe);xJr=r(Xjt,"from_config()"),Xjt.forEach(t),$Jr=r(ite,` class
method.`),ite.forEach(t),kJr=i(_i),$$=n(_i,"P",{});var Jze=s($$);SJr=r(Jze,"This class cannot be instantiated directly using "),nAe=n(Jze,"CODE",{});var zjt=s(nAe);RJr=r(zjt,"__init__()"),zjt.forEach(t),PJr=r(Jze," (throws an error)."),Jze.forEach(t),BJr=i(_i),ea=n(_i,"DIV",{class:!0});var Ty=s(ea);T(k$.$$.fragment,Ty),IJr=i(Ty),sAe=n(Ty,"P",{});var Qjt=s(sAe);NJr=r(Qjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Qjt.forEach(t),qJr=i(Ty),Fm=n(Ty,"P",{});var dte=s(Fm);jJr=r(dte,`Note:
Loading a model from its configuration file does `),lAe=n(dte,"STRONG",{});var Wjt=s(lAe);DJr=r(Wjt,"not"),Wjt.forEach(t),GJr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=n(dte,"A",{href:!0});var Hjt=s(moe);OJr=r(Hjt,"from_pretrained()"),Hjt.forEach(t),VJr=r(dte," to load the model weights."),dte.forEach(t),XJr=i(Ty),T(YA.$$.fragment,Ty),Ty.forEach(t),zJr=i(_i),Kr=n(_i,"DIV",{class:!0});var bi=s(Kr);T(S$.$$.fragment,bi),QJr=i(bi),iAe=n(bi,"P",{});var Ujt=s(iAe);WJr=r(Ujt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ujt.forEach(t),HJr=i(bi),$n=n(bi,"P",{});var My=s($n);UJr=r(My,"The model class to instantiate is selected based on the "),dAe=n(My,"CODE",{});var Jjt=s(dAe);JJr=r(Jjt,"model_type"),Jjt.forEach(t),YJr=r(My,` property of the config object (either
passed as an argument or loaded from `),cAe=n(My,"CODE",{});var Yjt=s(cAe);KJr=r(Yjt,"pretrained_model_name_or_path"),Yjt.forEach(t),ZJr=r(My,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mAe=n(My,"CODE",{});var Kjt=s(mAe);eYr=r(Kjt,"pretrained_model_name_or_path"),Kjt.forEach(t),oYr=r(My,":"),My.forEach(t),rYr=i(bi),R$=n(bi,"UL",{});var Yze=s(R$);KA=n(Yze,"LI",{});var IGe=s(KA);fAe=n(IGe,"STRONG",{});var Zjt=s(fAe);tYr=r(Zjt,"beit"),Zjt.forEach(t),aYr=r(IGe," \u2014 "),foe=n(IGe,"A",{href:!0});var eDt=s(foe);nYr=r(eDt,"FlaxBeitForImageClassification"),eDt.forEach(t),sYr=r(IGe," (BEiT model)"),IGe.forEach(t),lYr=i(Yze),ZA=n(Yze,"LI",{});var NGe=s(ZA);gAe=n(NGe,"STRONG",{});var oDt=s(gAe);iYr=r(oDt,"vit"),oDt.forEach(t),dYr=r(NGe," \u2014 "),goe=n(NGe,"A",{href:!0});var rDt=s(goe);cYr=r(rDt,"FlaxViTForImageClassification"),rDt.forEach(t),mYr=r(NGe," (ViT model)"),NGe.forEach(t),Yze.forEach(t),fYr=i(bi),T(e6.$$.fragment,bi),bi.forEach(t),_i.forEach(t),OVe=i(m),Tm=n(m,"H2",{class:!0});var Kze=s(Tm);o6=n(Kze,"A",{id:!0,class:!0,href:!0});var tDt=s(o6);hAe=n(tDt,"SPAN",{});var aDt=s(hAe);T(P$.$$.fragment,aDt),aDt.forEach(t),tDt.forEach(t),gYr=i(Kze),uAe=n(Kze,"SPAN",{});var nDt=s(uAe);hYr=r(nDt,"FlaxAutoModelForVision2Seq"),nDt.forEach(t),Kze.forEach(t),VVe=i(m),wr=n(m,"DIV",{class:!0});var vi=s(wr);T(B$.$$.fragment,vi),uYr=i(vi),Mm=n(vi,"P",{});var cte=s(Mm);pYr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=n(cte,"A",{href:!0});var sDt=s(hoe);_Yr=r(sDt,"from_pretrained()"),sDt.forEach(t),bYr=r(cte," class method or the "),uoe=n(cte,"A",{href:!0});var lDt=s(uoe);vYr=r(lDt,"from_config()"),lDt.forEach(t),FYr=r(cte,` class
method.`),cte.forEach(t),TYr=i(vi),I$=n(vi,"P",{});var Zze=s(I$);MYr=r(Zze,"This class cannot be instantiated directly using "),pAe=n(Zze,"CODE",{});var iDt=s(pAe);EYr=r(iDt,"__init__()"),iDt.forEach(t),CYr=r(Zze," (throws an error)."),Zze.forEach(t),wYr=i(vi),oa=n(vi,"DIV",{class:!0});var Ey=s(oa);T(N$.$$.fragment,Ey),AYr=i(Ey),_Ae=n(Ey,"P",{});var dDt=s(_Ae);LYr=r(dDt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dDt.forEach(t),yYr=i(Ey),Em=n(Ey,"P",{});var mte=s(Em);xYr=r(mte,`Note:
Loading a model from its configuration file does `),bAe=n(mte,"STRONG",{});var cDt=s(bAe);$Yr=r(cDt,"not"),cDt.forEach(t),kYr=r(mte,` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=n(mte,"A",{href:!0});var mDt=s(poe);SYr=r(mDt,"from_pretrained()"),mDt.forEach(t),RYr=r(mte," to load the model weights."),mte.forEach(t),PYr=i(Ey),T(r6.$$.fragment,Ey),Ey.forEach(t),BYr=i(vi),Zr=n(vi,"DIV",{class:!0});var Fi=s(Zr);T(q$.$$.fragment,Fi),IYr=i(Fi),vAe=n(Fi,"P",{});var fDt=s(vAe);NYr=r(fDt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fDt.forEach(t),qYr=i(Fi),kn=n(Fi,"P",{});var Cy=s(kn);jYr=r(Cy,"The model class to instantiate is selected based on the "),FAe=n(Cy,"CODE",{});var gDt=s(FAe);DYr=r(gDt,"model_type"),gDt.forEach(t),GYr=r(Cy,` property of the config object (either
passed as an argument or loaded from `),TAe=n(Cy,"CODE",{});var hDt=s(TAe);OYr=r(hDt,"pretrained_model_name_or_path"),hDt.forEach(t),VYr=r(Cy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MAe=n(Cy,"CODE",{});var uDt=s(MAe);XYr=r(uDt,"pretrained_model_name_or_path"),uDt.forEach(t),zYr=r(Cy,":"),Cy.forEach(t),QYr=i(Fi),EAe=n(Fi,"UL",{});var pDt=s(EAe);t6=n(pDt,"LI",{});var qGe=s(t6);CAe=n(qGe,"STRONG",{});var _Dt=s(CAe);WYr=r(_Dt,"vision-encoder-decoder"),_Dt.forEach(t),HYr=r(qGe," \u2014 "),_oe=n(qGe,"A",{href:!0});var bDt=s(_oe);UYr=r(bDt,"FlaxVisionEncoderDecoderModel"),bDt.forEach(t),JYr=r(qGe," (Vision Encoder decoder model)"),qGe.forEach(t),pDt.forEach(t),YYr=i(Fi),T(a6.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(COt)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(Rn,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(km,"id","extending-the-auto-classes"),c(km,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(km,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Rm,"id","transformers.AutoConfig"),c(Rm,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Rm,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(iS,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(dS,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(cS,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(mS,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(fS,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(gS,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(hS,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(uS,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(pS,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(_S,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(bS,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(vS,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c(FS,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(TS,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(MS,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(ES,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(CS,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(wS,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(AS,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(LS,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(yS,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(xS,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c($S,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(kS,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(SS,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(RS,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(PS,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c(BS,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(IS,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(NS,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(qS,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(jS,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(DS,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(GS,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(OS,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(VS,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(XS,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c(zS,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(QS,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(WS,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(HS,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c(US,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(JS,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(YS,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(KS,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(ZS,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(eR,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(oR,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(rR,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(tR,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c(aR,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(nR,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(sR,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(lR,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(iR,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(dR,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(cR,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(mR,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(fR,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(gR,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(hR,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(uR,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(pR,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(_R,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(bR,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(vR,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(FR,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(TR,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(MR,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(ER,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(CR,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(wR,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(AR,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(LR,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(yR,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(xR,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c($R,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(kR,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(SR,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(RR,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(PR,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(BR,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(IR,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(NR,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c(qR,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(jR,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(DR,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(GR,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(OR,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(VR,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(XR,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(zR,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(QR,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(WR,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(HR,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(UR,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(JR,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(YR,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(KR,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(ZR,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(eP,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(oP,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(rP,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c(tP,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(aP,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(nP,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(sP,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(lP,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(iP,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(dP,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(cP,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(mP,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(fP,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(gP,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(hP,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"id","transformers.AutoTokenizer"),c(Vg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(uP,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(pP,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(_P,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(bP,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(vP,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(FP,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(TP,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(MP,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(EP,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(CP,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(wP,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(AP,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(LP,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(yP,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(xP,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c($P,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(kP,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(SP,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(RP,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(PP,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(BP,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(IP,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(NP,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(qP,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(jP,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(DP,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(GP,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(OP,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(VP,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(XP,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(zP,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(QP,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(WP,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HP,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UP,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(JP,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(YP,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(KP,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(ZP,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(eB,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(oB,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(rB,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(tB,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(aB,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(nB,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(sB,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(lB,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(iB,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(dB,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(cB,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(mB,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(fB,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(gB,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(hB,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(uB,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(pB,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(_B,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(bB,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(vB,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(FB,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TB,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MB,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(EB,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(CB,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(wB,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(AB,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(LB,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(yB,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(xB,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c($B,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(kB,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(SB,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(RB,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(PB,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(BB,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(IB,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(NB,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(qB,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(jB,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(DB,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(GB,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(OB,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(VB,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(XB,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(zB,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(QB,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(WB,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(HB,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(UB,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(JB,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(YB,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(KB,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(ZB,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(eI,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(oI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(rI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(tI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(aI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nI,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(sI,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(lI,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iI,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(dI,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(cI,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(mI,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(fI,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(gI,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(hI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(uI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(pI,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(_I,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(bI,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c(vI,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(FI,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(TI,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(MI,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(EI,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(CI,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(wI,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AI,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LI,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(yI,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(xI,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c($I,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(kI,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(SI,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(RI,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(PI,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(BI,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(II,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(NI,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(qI,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c(jI,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(DI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(GI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(OI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(VI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(XI,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(zI,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(QI,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(WI,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(HI,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(UI,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(JI,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(YI,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(KI,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(ZI,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(eN,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(oN,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(rN,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(tN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(aN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wh,"id","transformers.AutoFeatureExtractor"),c(wh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(nN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(sN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(iN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(mN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(fN,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(gN,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(hN,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(uN,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(pN,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(_N,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bN,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(vN,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(FN,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(TN,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(MN,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(EN,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(CN,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wN,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yN,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xN,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($N,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(RN,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PN,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(NN,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(su,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lu,"id","transformers.AutoProcessor"),c(lu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lu,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(qN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(DN,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(GN,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(ON,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(VN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(XN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zN,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(QN,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(WN,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(HN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(JN,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(YN,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(KN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eq,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yu,"id","transformers.AutoModel"),c(yu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yu,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(oq,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rq,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tq,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(nq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(sq,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(lq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(iq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(cq,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(mq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(fq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(hq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(uq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(pq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(_q,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c(bq,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(vq,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(Fq,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(Tq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Mq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Eq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Cq,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(wq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Aq,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Lq,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(yq,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(xq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c($q,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(kq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(Sq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(Rq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(Pq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(Bq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(Iq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(Nq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(qq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(jq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c(Dq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(Gq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Oq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Vq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(Xq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(zq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(Qq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Wq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Hq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Uq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Jq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(Yq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(Kq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(Zq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(ej,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(oj,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(rj,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(tj,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(aj,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(nj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(sj,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(lj,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ij,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(dj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(cj,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(mj,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c(fj,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(gj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(hj,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(uj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(pj,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(_j,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(bj,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(vj,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Fj,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Tj,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(Mj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(Ej,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(Cj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(wj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(Aj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(Lj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(yj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(xj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c($j,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(kj,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Sj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(Rj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Pj,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(Bj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(Ij,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c(Nj,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(qj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(jj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Dj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Gj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(Oj,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(Vj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Xj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(zj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(Qj,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Wj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Hj,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Uj,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(Jj,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c(Yj,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(Kj,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Zj,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(eD,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(oD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(rD,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(tD,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($_,"id","transformers.AutoModelForPreTraining"),c($_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($_,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(aD,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nD,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sD,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(iD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(dD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(cD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(mD,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(fD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(gD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(uD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(pD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(_D,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(bD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(vD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(FD,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(TD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(MD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(ED,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(CD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wD,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(AD,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(LD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(yD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xD,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($D,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SD,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(RD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(PD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(BD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(ID,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(ND,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(qD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(jD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(DD,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(GD,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(OD,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(VD,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(XD,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(zD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(QD,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(WD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(UD,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(JD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C2,"id","transformers.AutoModelForCausalLM"),c(C2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C2,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(YD,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(oG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c(rG,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(tG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(aG,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(nG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(sG,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(lG,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(iG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(dG,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(cG,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(mG,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(fG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(gG,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(hG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(uG,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(pG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(_G,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bG,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(vG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FG,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(TG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(MG,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(EG,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(CG,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(wG,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(AG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(LG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(yG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(xG,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c($G,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(kG,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(SG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(RG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(BG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(IG,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(NG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fb,"id","transformers.AutoModelForMaskedLM"),c(fb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fb,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(qG,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jG,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DG,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(OG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(VG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(XG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(zG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(QG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(WG,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(HG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(UG,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(JG,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(YG,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(KG,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(ZG,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(eO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(oO,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(rO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(tO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(aO,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(nO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(sO,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(lO,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(iO,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(dO,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(cO,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(mO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(fO,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(gO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(hO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(uO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(pO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(_O,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(bO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(vO,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TO,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MO,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zb,"id","transformers.AutoModelForSeq2SeqLM"),c(Zb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zb,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(EO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AO,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(LO,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(yO,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(xO,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c($O,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(kO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(SO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(RO,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(PO,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(BO,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c(IO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(NO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(qO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(jO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(DO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(GO,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(OO,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fv,"id","transformers.AutoModelForSequenceClassification"),c(Fv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fv,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(VO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(WO,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c(HO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(UO,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(JO,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(YO,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(KO,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(ZO,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(eV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(oV,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(rV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(tV,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(aV,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(nV,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(sV,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(lV,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(iV,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(dV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(cV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(mV,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(fV,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(gV,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(hV,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(uV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(pV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(_V,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(bV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(vV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(FV,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(TV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(MV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(EV,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(CV,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(wV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(AV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(LV,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(yV,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(xV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c($V,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(kV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(SV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(RV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(PV,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(BV,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(IV,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(NV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(qV,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(jV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(DV,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vF,"id","transformers.AutoModelForMultipleChoice"),c(vF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vF,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(GV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(zV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(QV,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(WV,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(HV,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(UV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(JV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(YV,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(KV,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(ZV,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(eX,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(oX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(rX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(tX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(aX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(nX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(sX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(lX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(iX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(dX,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(cX,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(mX,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(fX,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(gX,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(hX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(uX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(pX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(_X,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(bX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(vX,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZF,"id","transformers.AutoModelForNextSentencePrediction"),c(ZF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZF,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(FX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(CX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(wX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(AX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(LX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(yX,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d1,"id","transformers.AutoModelForTokenClassification"),c(d1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d1,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(xX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(RX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(PX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(BX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(IX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(NX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(qX,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(jX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(DX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(GX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(OX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(VX,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(XX,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(zX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(QX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(WX,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(HX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(UX,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(JX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(YX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(KX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(ZX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(ez,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(oz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(rz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(tz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(az,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(nz,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(sz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(lz,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(iz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(dz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(cz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(mz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(fz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(gz,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U1,"id","transformers.AutoModelForQuestionAnswering"),c(U1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U1,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(hz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_z,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(bz,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(vz,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Fz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Tz,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Mz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Ez,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Cz,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(wz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Az,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(Lz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(yz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(xz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c($z,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(kz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Sz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Rz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(Pz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Bz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Iz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Nz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(qz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(jz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Dz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Gz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Oz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Vz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Xz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(zz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Qz,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Wz,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Hz,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Uz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Jz,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Yz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Kz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(Zz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(eQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(oQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(rQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(tQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.AutoModelForTableQuestionAnswering"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.AutoModelForTableQuestionAnswering"),c(md,"class","relative group"),c(aQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zT,"id","transformers.AutoModelForImageClassification"),c(zT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zT,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(iQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mQ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(fQ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gQ,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(uQ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(pQ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(_Q,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bQ,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(vQ,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(TQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(MQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(EQ,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(CQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(wQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(AQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(LQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(yQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(xQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lM,"id","transformers.AutoModelForVision2Seq"),c(lM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lM,"href","#transformers.AutoModelForVision2Seq"),c(_d,"class","relative group"),c($Q,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fM,"id","transformers.AutoModelForVisualQuestionAnswering"),c(fM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fM,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(PQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_M,"id","transformers.AutoModelForAudioClassification"),c(_M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_M,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(qQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(OQ,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(VQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(XQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(zQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(QQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(WQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(HQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($M,"id","transformers.AutoModelForAudioFrameClassification"),c($M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($M,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(JQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(eW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(oW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(rW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(tW,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jM,"id","transformers.AutoModelForCTC"),c(jM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jM,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(aW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(iW,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(dW,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(cW,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(mW,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(fW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(gW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(hW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(uW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(pW,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZM,"id","transformers.AutoModelForSpeechSeq2Seq"),c(ZM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZM,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(_W,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FW,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(TW,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nE,"id","transformers.AutoModelForAudioXVector"),c(nE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nE,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(MW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(AW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(LW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(yW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(xW,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hE,"id","transformers.AutoModelForMaskedImageModeling"),c(hE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hE,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c($W,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(PW,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(BW,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TE,"id","transformers.AutoModelForObjectDetection"),c(TE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TE,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(IW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DW,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LE,"id","transformers.AutoModelForImageSegmentation"),c(LE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LE,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(GW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SE,"id","transformers.AutoModelForSemanticSegmentation"),c(SE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SE,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(zW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HW,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(UW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JW,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YW,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DE,"id","transformers.AutoModelForInstanceSegmentation"),c(DE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DE,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(KW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zE,"id","transformers.TFAutoModel"),c(zE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zE,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(rH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(sH,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(lH,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(iH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(dH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(cH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(mH,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(fH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(gH,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(hH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(uH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(pH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(_H,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(vH,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(FH,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(TH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(MH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(EH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(CH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(wH,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(AH,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(LH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(yH,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(xH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c($H,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(kH,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(SH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(RH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(PH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(BH,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(IH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(NH,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c(qH,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(jH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(DH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(GH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(OH,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(VH,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(XH,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(zH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(QH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(WH,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(HH,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(UH,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(JH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(YH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(KH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D4,"id","transformers.TFAutoModelForPreTraining"),c(D4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D4,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(ZH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rU,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(tU,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(aU,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(nU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(sU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(lU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iU,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(dU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(mU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(fU,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(gU,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(hU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(uU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(pU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(_U,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(bU,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(vU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(FU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TU,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(MU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(EU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(CU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fC,"id","transformers.TFAutoModelForCausalLM"),c(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fC,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(wU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(xU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c($U,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(kU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(SU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(RU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(PU,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(BU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(IU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(NU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(qU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(jU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(DU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yC,"id","transformers.TFAutoModelForImageClassification"),c(yC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yC,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(GU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(zU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(QU,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(WU,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BC,"id","transformers.TFAutoModelForMaskedLM"),c(BC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BC,"href","#transformers.TFAutoModelForMaskedLM"),c(fc,"class","relative group"),c(HU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YU,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(KU,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(ZU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(eJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(oJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(rJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(tJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(aJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(nJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(sJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(lJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(iJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(dJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(cJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(mJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(fJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(gJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(hJ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(uJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(pJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a5,"id","transformers.TFAutoModelForSeq2SeqLM"),c(a5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a5,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(uc,"class","relative group"),c(_J,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(TJ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(MJ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(EJ,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(CJ,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(wJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(AJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(LJ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(yJ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(xJ,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_5,"id","transformers.TFAutoModelForSequenceClassification"),c(_5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_5,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c($J,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(PJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(BJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(IJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(NJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(qJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(jJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(DJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(GJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(OJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(VJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(XJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(zJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(QJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(WJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(HJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(UJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(JJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(YJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(KJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(ZJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(eY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(oY,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(rY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(tY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(aY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q5,"id","transformers.TFAutoModelForMultipleChoice"),c(Q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q5,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(nY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iY,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(dY,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(cY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(mY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(fY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(gY,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(hY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(uY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(pY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(_Y,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(bY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(vY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(FY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(TY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(MY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(EY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(CY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f3,"id","transformers.TFAutoModelForNextSentencePrediction"),c(f3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f3,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(wY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(xY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_3,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(_3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_3,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c($Y,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T3,"id","transformers.TFAutoModelForTokenClassification"),c(T3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T3,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(qY,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(jY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(DY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(GY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(OY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(VY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(XY,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(zY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(QY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(WY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(HY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(UY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(JY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(YY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(KY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(ZY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(eK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(oK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(rK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X3,"id","transformers.TFAutoModelForQuestionAnswering"),c(X3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X3,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(tK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(lK,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(iK,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(dK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(cK,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(mK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(fK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(gK,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(hK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(uK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(pK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(_K,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(bK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(vK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(FK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(TK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(MK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(EK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(CK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(wK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g0,"id","transformers.TFAutoModelForVision2Seq"),c(g0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g0,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c(AK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_0,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(_0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_0,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c($K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T0,"id","transformers.FlaxAutoModel"),c(T0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T0,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(PK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(qK,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(jK,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(DK,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(GK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(OK,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(VK,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(XK,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(zK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(QK,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(WK,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(HK,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(UK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(JK,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(YK,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(KK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(ZK,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c(eZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(oZ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(rZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(tZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(aZ,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(nZ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(sZ,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(lZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(iZ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(dZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y0,"id","transformers.FlaxAutoModelForCausalLM"),c(Y0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y0,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(cZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(hZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(uZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(pZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(_Z,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(bZ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(vZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(FZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(TZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(MZ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cw,"id","transformers.FlaxAutoModelForPreTraining"),c(cw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cw,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(EZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(LZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(yZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(xZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c($Z,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(kZ,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(SZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(RZ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(PZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(BZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(IZ,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(NZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(qZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aw,"id","transformers.FlaxAutoModelForMaskedLM"),c(Aw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Aw,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(VZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(XZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(zZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(QZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(WZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(HZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(UZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(JZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(YZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jw,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jw,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(em,"class","relative group"),c(KZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oee,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ree,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(tee,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(aee,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(nee,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(see,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(lee,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(iee,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(dee,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(cee,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kw,"id","transformers.FlaxAutoModelForSequenceClassification"),c(Kw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Kw,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tm,"class","relative group"),c(mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(uee,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(pee,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(_ee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(bee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(vee,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Fee,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Tee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Mee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Eee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mA,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(mA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mA,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sm,"class","relative group"),c(Cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lee,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(yee,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(xee,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c($ee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(kee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(See,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Ree,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Pee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Bee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Iee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CA,"id","transformers.FlaxAutoModelForTokenClassification"),c(CA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CA,"href","#transformers.FlaxAutoModelForTokenClassification"),c(dm,"class","relative group"),c(Nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dee,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Gee,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Oee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Vee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Xee,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(zee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Qee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Wee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BA,"id","transformers.FlaxAutoModelForMultipleChoice"),c(BA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BA,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(fm,"class","relative group"),c(Hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yee,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Kee,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Zee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(eoe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(ooe,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(roe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(toe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(aoe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QA,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(QA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QA,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(um,"class","relative group"),c(noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(soe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ioe,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JA,"id","transformers.FlaxAutoModelForImageClassification"),c(JA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JA,"href","#transformers.FlaxAutoModelForImageClassification"),c(bm,"class","relative group"),c(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(foe,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(goe,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o6,"id","transformers.FlaxAutoModelForVision2Seq"),c(o6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o6,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Tm,"class","relative group"),c(hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_oe,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,Eo),e(Eo,Ti),b(m,Lm,_),b(m,at,_),e(at,Mi),e(at,Ei),e(Ei,wy),e(at,ym),b(m,Oe,_),b(m,Qe,_),e(Qe,Ci),e(Qe,Rn),e(Rn,Ay),e(Qe,Pn),e(Qe,Bn),e(Bn,Ly),e(Qe,wi),e(Qe,In),e(In,yy),e(Qe,Ai),b(m,xm,_),M(xa,m,_),b(m,We,_),b(m,Ae,_),e(Ae,rS),e(Ae,Li),e(Li,tS),e(Ae,aS),b(m,Co,_),b(m,$a,_),e($a,nS),e($a,$m),e($m,sS),e($a,eQe),b(m,jGe,_),b(m,yi,_),e(yi,km),e(km,fte),M(xy,fte,null),e(yi,oQe),e(yi,gte),e(gte,rQe),b(m,DGe,_),b(m,Nn,_),e(Nn,tQe),e(Nn,hte),e(hte,aQe),e(Nn,nQe),e(Nn,ute),e(ute,sQe),e(Nn,lQe),b(m,GGe,_),M($y,m,_),b(m,OGe,_),b(m,lS,_),e(lS,iQe),b(m,VGe,_),M(Sm,m,_),b(m,XGe,_),b(m,xi,_),e(xi,Rm),e(Rm,pte),M(ky,pte,null),e(xi,dQe),e(xi,_te),e(_te,cQe),b(m,zGe,_),b(m,wo,_),M(Sy,wo,null),e(wo,mQe),e(wo,Ry),e(Ry,fQe),e(Ry,iS),e(iS,gQe),e(Ry,hQe),e(wo,uQe),e(wo,Py),e(Py,pQe),e(Py,bte),e(bte,_Qe),e(Py,bQe),e(wo,vQe),e(wo,Ar),M(By,Ar,null),e(Ar,FQe),e(Ar,vte),e(vte,TQe),e(Ar,MQe),e(Ar,$i),e($i,EQe),e($i,Fte),e(Fte,CQe),e($i,wQe),e($i,Tte),e(Tte,AQe),e($i,LQe),e(Ar,yQe),e(Ar,A),e(A,Pm),e(Pm,Mte),e(Mte,xQe),e(Pm,$Qe),e(Pm,dS),e(dS,kQe),e(Pm,SQe),e(A,RQe),e(A,Bm),e(Bm,Ete),e(Ete,PQe),e(Bm,BQe),e(Bm,cS),e(cS,IQe),e(Bm,NQe),e(A,qQe),e(A,Im),e(Im,Cte),e(Cte,jQe),e(Im,DQe),e(Im,mS),e(mS,GQe),e(Im,OQe),e(A,VQe),e(A,Nm),e(Nm,wte),e(wte,XQe),e(Nm,zQe),e(Nm,fS),e(fS,QQe),e(Nm,WQe),e(A,HQe),e(A,qm),e(qm,Ate),e(Ate,UQe),e(qm,JQe),e(qm,gS),e(gS,YQe),e(qm,KQe),e(A,ZQe),e(A,jm),e(jm,Lte),e(Lte,eWe),e(jm,oWe),e(jm,hS),e(hS,rWe),e(jm,tWe),e(A,aWe),e(A,Dm),e(Dm,yte),e(yte,nWe),e(Dm,sWe),e(Dm,uS),e(uS,lWe),e(Dm,iWe),e(A,dWe),e(A,Gm),e(Gm,xte),e(xte,cWe),e(Gm,mWe),e(Gm,pS),e(pS,fWe),e(Gm,gWe),e(A,hWe),e(A,Om),e(Om,$te),e($te,uWe),e(Om,pWe),e(Om,_S),e(_S,_We),e(Om,bWe),e(A,vWe),e(A,Vm),e(Vm,kte),e(kte,FWe),e(Vm,TWe),e(Vm,bS),e(bS,MWe),e(Vm,EWe),e(A,CWe),e(A,Xm),e(Xm,Ste),e(Ste,wWe),e(Xm,AWe),e(Xm,vS),e(vS,LWe),e(Xm,yWe),e(A,xWe),e(A,zm),e(zm,Rte),e(Rte,$We),e(zm,kWe),e(zm,FS),e(FS,SWe),e(zm,RWe),e(A,PWe),e(A,Qm),e(Qm,Pte),e(Pte,BWe),e(Qm,IWe),e(Qm,TS),e(TS,NWe),e(Qm,qWe),e(A,jWe),e(A,Wm),e(Wm,Bte),e(Bte,DWe),e(Wm,GWe),e(Wm,MS),e(MS,OWe),e(Wm,VWe),e(A,XWe),e(A,Hm),e(Hm,Ite),e(Ite,zWe),e(Hm,QWe),e(Hm,ES),e(ES,WWe),e(Hm,HWe),e(A,UWe),e(A,Um),e(Um,Nte),e(Nte,JWe),e(Um,YWe),e(Um,CS),e(CS,KWe),e(Um,ZWe),e(A,eHe),e(A,Jm),e(Jm,qte),e(qte,oHe),e(Jm,rHe),e(Jm,wS),e(wS,tHe),e(Jm,aHe),e(A,nHe),e(A,Ym),e(Ym,jte),e(jte,sHe),e(Ym,lHe),e(Ym,AS),e(AS,iHe),e(Ym,dHe),e(A,cHe),e(A,Km),e(Km,Dte),e(Dte,mHe),e(Km,fHe),e(Km,LS),e(LS,gHe),e(Km,hHe),e(A,uHe),e(A,Zm),e(Zm,Gte),e(Gte,pHe),e(Zm,_He),e(Zm,yS),e(yS,bHe),e(Zm,vHe),e(A,FHe),e(A,ef),e(ef,Ote),e(Ote,THe),e(ef,MHe),e(ef,xS),e(xS,EHe),e(ef,CHe),e(A,wHe),e(A,of),e(of,Vte),e(Vte,AHe),e(of,LHe),e(of,$S),e($S,yHe),e(of,xHe),e(A,$He),e(A,rf),e(rf,Xte),e(Xte,kHe),e(rf,SHe),e(rf,kS),e(kS,RHe),e(rf,PHe),e(A,BHe),e(A,tf),e(tf,zte),e(zte,IHe),e(tf,NHe),e(tf,SS),e(SS,qHe),e(tf,jHe),e(A,DHe),e(A,af),e(af,Qte),e(Qte,GHe),e(af,OHe),e(af,RS),e(RS,VHe),e(af,XHe),e(A,zHe),e(A,nf),e(nf,Wte),e(Wte,QHe),e(nf,WHe),e(nf,PS),e(PS,HHe),e(nf,UHe),e(A,JHe),e(A,sf),e(sf,Hte),e(Hte,YHe),e(sf,KHe),e(sf,BS),e(BS,ZHe),e(sf,eUe),e(A,oUe),e(A,lf),e(lf,Ute),e(Ute,rUe),e(lf,tUe),e(lf,IS),e(IS,aUe),e(lf,nUe),e(A,sUe),e(A,df),e(df,Jte),e(Jte,lUe),e(df,iUe),e(df,NS),e(NS,dUe),e(df,cUe),e(A,mUe),e(A,cf),e(cf,Yte),e(Yte,fUe),e(cf,gUe),e(cf,qS),e(qS,hUe),e(cf,uUe),e(A,pUe),e(A,mf),e(mf,Kte),e(Kte,_Ue),e(mf,bUe),e(mf,jS),e(jS,vUe),e(mf,FUe),e(A,TUe),e(A,ff),e(ff,Zte),e(Zte,MUe),e(ff,EUe),e(ff,DS),e(DS,CUe),e(ff,wUe),e(A,AUe),e(A,gf),e(gf,eae),e(eae,LUe),e(gf,yUe),e(gf,GS),e(GS,xUe),e(gf,$Ue),e(A,kUe),e(A,hf),e(hf,oae),e(oae,SUe),e(hf,RUe),e(hf,OS),e(OS,PUe),e(hf,BUe),e(A,IUe),e(A,uf),e(uf,rae),e(rae,NUe),e(uf,qUe),e(uf,VS),e(VS,jUe),e(uf,DUe),e(A,GUe),e(A,pf),e(pf,tae),e(tae,OUe),e(pf,VUe),e(pf,XS),e(XS,XUe),e(pf,zUe),e(A,QUe),e(A,_f),e(_f,aae),e(aae,WUe),e(_f,HUe),e(_f,zS),e(zS,UUe),e(_f,JUe),e(A,YUe),e(A,bf),e(bf,nae),e(nae,KUe),e(bf,ZUe),e(bf,QS),e(QS,eJe),e(bf,oJe),e(A,rJe),e(A,vf),e(vf,sae),e(sae,tJe),e(vf,aJe),e(vf,WS),e(WS,nJe),e(vf,sJe),e(A,lJe),e(A,Ff),e(Ff,lae),e(lae,iJe),e(Ff,dJe),e(Ff,HS),e(HS,cJe),e(Ff,mJe),e(A,fJe),e(A,Tf),e(Tf,iae),e(iae,gJe),e(Tf,hJe),e(Tf,US),e(US,uJe),e(Tf,pJe),e(A,_Je),e(A,Mf),e(Mf,dae),e(dae,bJe),e(Mf,vJe),e(Mf,JS),e(JS,FJe),e(Mf,TJe),e(A,MJe),e(A,Ef),e(Ef,cae),e(cae,EJe),e(Ef,CJe),e(Ef,YS),e(YS,wJe),e(Ef,AJe),e(A,LJe),e(A,Cf),e(Cf,mae),e(mae,yJe),e(Cf,xJe),e(Cf,KS),e(KS,$Je),e(Cf,kJe),e(A,SJe),e(A,wf),e(wf,fae),e(fae,RJe),e(wf,PJe),e(wf,ZS),e(ZS,BJe),e(wf,IJe),e(A,NJe),e(A,Af),e(Af,gae),e(gae,qJe),e(Af,jJe),e(Af,eR),e(eR,DJe),e(Af,GJe),e(A,OJe),e(A,Lf),e(Lf,hae),e(hae,VJe),e(Lf,XJe),e(Lf,oR),e(oR,zJe),e(Lf,QJe),e(A,WJe),e(A,yf),e(yf,uae),e(uae,HJe),e(yf,UJe),e(yf,rR),e(rR,JJe),e(yf,YJe),e(A,KJe),e(A,xf),e(xf,pae),e(pae,ZJe),e(xf,eYe),e(xf,tR),e(tR,oYe),e(xf,rYe),e(A,tYe),e(A,$f),e($f,_ae),e(_ae,aYe),e($f,nYe),e($f,aR),e(aR,sYe),e($f,lYe),e(A,iYe),e(A,kf),e(kf,bae),e(bae,dYe),e(kf,cYe),e(kf,nR),e(nR,mYe),e(kf,fYe),e(A,gYe),e(A,Sf),e(Sf,vae),e(vae,hYe),e(Sf,uYe),e(Sf,sR),e(sR,pYe),e(Sf,_Ye),e(A,bYe),e(A,Rf),e(Rf,Fae),e(Fae,vYe),e(Rf,FYe),e(Rf,lR),e(lR,TYe),e(Rf,MYe),e(A,EYe),e(A,Pf),e(Pf,Tae),e(Tae,CYe),e(Pf,wYe),e(Pf,iR),e(iR,AYe),e(Pf,LYe),e(A,yYe),e(A,Bf),e(Bf,Mae),e(Mae,xYe),e(Bf,$Ye),e(Bf,dR),e(dR,kYe),e(Bf,SYe),e(A,RYe),e(A,If),e(If,Eae),e(Eae,PYe),e(If,BYe),e(If,cR),e(cR,IYe),e(If,NYe),e(A,qYe),e(A,Nf),e(Nf,Cae),e(Cae,jYe),e(Nf,DYe),e(Nf,mR),e(mR,GYe),e(Nf,OYe),e(A,VYe),e(A,qf),e(qf,wae),e(wae,XYe),e(qf,zYe),e(qf,fR),e(fR,QYe),e(qf,WYe),e(A,HYe),e(A,jf),e(jf,Aae),e(Aae,UYe),e(jf,JYe),e(jf,gR),e(gR,YYe),e(jf,KYe),e(A,ZYe),e(A,Df),e(Df,Lae),e(Lae,eKe),e(Df,oKe),e(Df,hR),e(hR,rKe),e(Df,tKe),e(A,aKe),e(A,Gf),e(Gf,yae),e(yae,nKe),e(Gf,sKe),e(Gf,uR),e(uR,lKe),e(Gf,iKe),e(A,dKe),e(A,Of),e(Of,xae),e(xae,cKe),e(Of,mKe),e(Of,pR),e(pR,fKe),e(Of,gKe),e(A,hKe),e(A,Vf),e(Vf,$ae),e($ae,uKe),e(Vf,pKe),e(Vf,_R),e(_R,_Ke),e(Vf,bKe),e(A,vKe),e(A,Xf),e(Xf,kae),e(kae,FKe),e(Xf,TKe),e(Xf,bR),e(bR,MKe),e(Xf,EKe),e(A,CKe),e(A,zf),e(zf,Sae),e(Sae,wKe),e(zf,AKe),e(zf,vR),e(vR,LKe),e(zf,yKe),e(A,xKe),e(A,Qf),e(Qf,Rae),e(Rae,$Ke),e(Qf,kKe),e(Qf,FR),e(FR,SKe),e(Qf,RKe),e(A,PKe),e(A,Wf),e(Wf,Pae),e(Pae,BKe),e(Wf,IKe),e(Wf,TR),e(TR,NKe),e(Wf,qKe),e(A,jKe),e(A,Hf),e(Hf,Bae),e(Bae,DKe),e(Hf,GKe),e(Hf,MR),e(MR,OKe),e(Hf,VKe),e(A,XKe),e(A,Uf),e(Uf,Iae),e(Iae,zKe),e(Uf,QKe),e(Uf,ER),e(ER,WKe),e(Uf,HKe),e(A,UKe),e(A,Jf),e(Jf,Nae),e(Nae,JKe),e(Jf,YKe),e(Jf,CR),e(CR,KKe),e(Jf,ZKe),e(A,eZe),e(A,Yf),e(Yf,qae),e(qae,oZe),e(Yf,rZe),e(Yf,wR),e(wR,tZe),e(Yf,aZe),e(A,nZe),e(A,Kf),e(Kf,jae),e(jae,sZe),e(Kf,lZe),e(Kf,AR),e(AR,iZe),e(Kf,dZe),e(A,cZe),e(A,Zf),e(Zf,Dae),e(Dae,mZe),e(Zf,fZe),e(Zf,LR),e(LR,gZe),e(Zf,hZe),e(A,uZe),e(A,eg),e(eg,Gae),e(Gae,pZe),e(eg,_Ze),e(eg,yR),e(yR,bZe),e(eg,vZe),e(A,FZe),e(A,og),e(og,Oae),e(Oae,TZe),e(og,MZe),e(og,xR),e(xR,EZe),e(og,CZe),e(A,wZe),e(A,rg),e(rg,Vae),e(Vae,AZe),e(rg,LZe),e(rg,$R),e($R,yZe),e(rg,xZe),e(A,$Ze),e(A,tg),e(tg,Xae),e(Xae,kZe),e(tg,SZe),e(tg,kR),e(kR,RZe),e(tg,PZe),e(A,BZe),e(A,ag),e(ag,zae),e(zae,IZe),e(ag,NZe),e(ag,SR),e(SR,qZe),e(ag,jZe),e(A,DZe),e(A,ng),e(ng,Qae),e(Qae,GZe),e(ng,OZe),e(ng,RR),e(RR,VZe),e(ng,XZe),e(A,zZe),e(A,sg),e(sg,Wae),e(Wae,QZe),e(sg,WZe),e(sg,PR),e(PR,HZe),e(sg,UZe),e(A,JZe),e(A,lg),e(lg,Hae),e(Hae,YZe),e(lg,KZe),e(lg,BR),e(BR,ZZe),e(lg,eeo),e(A,oeo),e(A,ig),e(ig,Uae),e(Uae,reo),e(ig,teo),e(ig,IR),e(IR,aeo),e(ig,neo),e(A,seo),e(A,dg),e(dg,Jae),e(Jae,leo),e(dg,ieo),e(dg,NR),e(NR,deo),e(dg,ceo),e(A,meo),e(A,cg),e(cg,Yae),e(Yae,feo),e(cg,geo),e(cg,qR),e(qR,heo),e(cg,ueo),e(A,peo),e(A,mg),e(mg,Kae),e(Kae,_eo),e(mg,beo),e(mg,jR),e(jR,veo),e(mg,Feo),e(A,Teo),e(A,fg),e(fg,Zae),e(Zae,Meo),e(fg,Eeo),e(fg,DR),e(DR,Ceo),e(fg,weo),e(A,Aeo),e(A,gg),e(gg,ene),e(ene,Leo),e(gg,yeo),e(gg,GR),e(GR,xeo),e(gg,$eo),e(A,keo),e(A,hg),e(hg,one),e(one,Seo),e(hg,Reo),e(hg,OR),e(OR,Peo),e(hg,Beo),e(A,Ieo),e(A,ug),e(ug,rne),e(rne,Neo),e(ug,qeo),e(ug,VR),e(VR,jeo),e(ug,Deo),e(A,Geo),e(A,pg),e(pg,tne),e(tne,Oeo),e(pg,Veo),e(pg,XR),e(XR,Xeo),e(pg,zeo),e(A,Qeo),e(A,_g),e(_g,ane),e(ane,Weo),e(_g,Heo),e(_g,zR),e(zR,Ueo),e(_g,Jeo),e(A,Yeo),e(A,bg),e(bg,nne),e(nne,Keo),e(bg,Zeo),e(bg,QR),e(QR,eoo),e(bg,ooo),e(A,roo),e(A,vg),e(vg,sne),e(sne,too),e(vg,aoo),e(vg,WR),e(WR,noo),e(vg,soo),e(A,loo),e(A,Fg),e(Fg,lne),e(lne,ioo),e(Fg,doo),e(Fg,HR),e(HR,coo),e(Fg,moo),e(A,foo),e(A,Tg),e(Tg,ine),e(ine,goo),e(Tg,hoo),e(Tg,UR),e(UR,uoo),e(Tg,poo),e(A,_oo),e(A,Mg),e(Mg,dne),e(dne,boo),e(Mg,voo),e(Mg,JR),e(JR,Foo),e(Mg,Too),e(A,Moo),e(A,Eg),e(Eg,cne),e(cne,Eoo),e(Eg,Coo),e(Eg,YR),e(YR,woo),e(Eg,Aoo),e(A,Loo),e(A,Cg),e(Cg,mne),e(mne,yoo),e(Cg,xoo),e(Cg,KR),e(KR,$oo),e(Cg,koo),e(A,Soo),e(A,wg),e(wg,fne),e(fne,Roo),e(wg,Poo),e(wg,ZR),e(ZR,Boo),e(wg,Ioo),e(A,Noo),e(A,Ag),e(Ag,gne),e(gne,qoo),e(Ag,joo),e(Ag,eP),e(eP,Doo),e(Ag,Goo),e(A,Ooo),e(A,Lg),e(Lg,hne),e(hne,Voo),e(Lg,Xoo),e(Lg,oP),e(oP,zoo),e(Lg,Qoo),e(A,Woo),e(A,yg),e(yg,une),e(une,Hoo),e(yg,Uoo),e(yg,rP),e(rP,Joo),e(yg,Yoo),e(A,Koo),e(A,xg),e(xg,pne),e(pne,Zoo),e(xg,ero),e(xg,tP),e(tP,oro),e(xg,rro),e(A,tro),e(A,$g),e($g,_ne),e(_ne,aro),e($g,nro),e($g,aP),e(aP,sro),e($g,lro),e(A,iro),e(A,kg),e(kg,bne),e(bne,dro),e(kg,cro),e(kg,nP),e(nP,mro),e(kg,fro),e(A,gro),e(A,Sg),e(Sg,vne),e(vne,hro),e(Sg,uro),e(Sg,sP),e(sP,pro),e(Sg,_ro),e(A,bro),e(A,Rg),e(Rg,Fne),e(Fne,vro),e(Rg,Fro),e(Rg,lP),e(lP,Tro),e(Rg,Mro),e(A,Ero),e(A,Pg),e(Pg,Tne),e(Tne,Cro),e(Pg,wro),e(Pg,iP),e(iP,Aro),e(Pg,Lro),e(A,yro),e(A,Bg),e(Bg,Mne),e(Mne,xro),e(Bg,$ro),e(Bg,dP),e(dP,kro),e(Bg,Sro),e(A,Rro),e(A,Ig),e(Ig,Ene),e(Ene,Pro),e(Ig,Bro),e(Ig,cP),e(cP,Iro),e(Ig,Nro),e(A,qro),e(A,Ng),e(Ng,Cne),e(Cne,jro),e(Ng,Dro),e(Ng,mP),e(mP,Gro),e(Ng,Oro),e(A,Vro),e(A,qg),e(qg,wne),e(wne,Xro),e(qg,zro),e(qg,fP),e(fP,Qro),e(qg,Wro),e(A,Hro),e(A,jg),e(jg,Ane),e(Ane,Uro),e(jg,Jro),e(jg,gP),e(gP,Yro),e(jg,Kro),e(A,Zro),e(A,Dg),e(Dg,Lne),e(Lne,eto),e(Dg,oto),e(Dg,hP),e(hP,rto),e(Dg,tto),e(Ar,ato),M(Gg,Ar,null),e(wo,nto),e(wo,Og),M(Iy,Og,null),e(Og,sto),e(Og,yne),e(yne,lto),b(m,QGe,_),b(m,ki,_),e(ki,Vg),e(Vg,xne),M(Ny,xne,null),e(ki,ito),e(ki,$ne),e($ne,dto),b(m,WGe,_),b(m,Ao,_),M(qy,Ao,null),e(Ao,cto),e(Ao,jy),e(jy,mto),e(jy,uP),e(uP,fto),e(jy,gto),e(Ao,hto),e(Ao,Dy),e(Dy,uto),e(Dy,kne),e(kne,pto),e(Dy,_to),e(Ao,bto),e(Ao,Lr),M(Gy,Lr,null),e(Lr,vto),e(Lr,Sne),e(Sne,Fto),e(Lr,Tto),e(Lr,ka),e(ka,Mto),e(ka,Rne),e(Rne,Eto),e(ka,Cto),e(ka,Pne),e(Pne,wto),e(ka,Ato),e(ka,Bne),e(Bne,Lto),e(ka,yto),e(Lr,xto),e(Lr,k),e(k,qn),e(qn,Ine),e(Ine,$to),e(qn,kto),e(qn,pP),e(pP,Sto),e(qn,Rto),e(qn,_P),e(_P,Pto),e(qn,Bto),e(k,Ito),e(k,jn),e(jn,Nne),e(Nne,Nto),e(jn,qto),e(jn,bP),e(bP,jto),e(jn,Dto),e(jn,vP),e(vP,Gto),e(jn,Oto),e(k,Vto),e(k,Dn),e(Dn,qne),e(qne,Xto),e(Dn,zto),e(Dn,FP),e(FP,Qto),e(Dn,Wto),e(Dn,TP),e(TP,Hto),e(Dn,Uto),e(k,Jto),e(k,Xg),e(Xg,jne),e(jne,Yto),e(Xg,Kto),e(Xg,MP),e(MP,Zto),e(Xg,eao),e(k,oao),e(k,Gn),e(Gn,Dne),e(Dne,rao),e(Gn,tao),e(Gn,EP),e(EP,aao),e(Gn,nao),e(Gn,CP),e(CP,sao),e(Gn,lao),e(k,iao),e(k,zg),e(zg,Gne),e(Gne,dao),e(zg,cao),e(zg,wP),e(wP,mao),e(zg,fao),e(k,gao),e(k,Qg),e(Qg,One),e(One,hao),e(Qg,uao),e(Qg,AP),e(AP,pao),e(Qg,_ao),e(k,bao),e(k,Wg),e(Wg,Vne),e(Vne,vao),e(Wg,Fao),e(Wg,LP),e(LP,Tao),e(Wg,Mao),e(k,Eao),e(k,On),e(On,Xne),e(Xne,Cao),e(On,wao),e(On,yP),e(yP,Aao),e(On,Lao),e(On,xP),e(xP,yao),e(On,xao),e(k,$ao),e(k,Vn),e(Vn,zne),e(zne,kao),e(Vn,Sao),e(Vn,$P),e($P,Rao),e(Vn,Pao),e(Vn,kP),e(kP,Bao),e(Vn,Iao),e(k,Nao),e(k,Xn),e(Xn,Qne),e(Qne,qao),e(Xn,jao),e(Xn,SP),e(SP,Dao),e(Xn,Gao),e(Xn,RP),e(RP,Oao),e(Xn,Vao),e(k,Xao),e(k,Hg),e(Hg,Wne),e(Wne,zao),e(Hg,Qao),e(Hg,PP),e(PP,Wao),e(Hg,Hao),e(k,Uao),e(k,Ug),e(Ug,Hne),e(Hne,Jao),e(Ug,Yao),e(Ug,BP),e(BP,Kao),e(Ug,Zao),e(k,eno),e(k,Jg),e(Jg,Une),e(Une,ono),e(Jg,rno),e(Jg,IP),e(IP,tno),e(Jg,ano),e(k,nno),e(k,zn),e(zn,Jne),e(Jne,sno),e(zn,lno),e(zn,NP),e(NP,ino),e(zn,dno),e(zn,qP),e(qP,cno),e(zn,mno),e(k,fno),e(k,Yg),e(Yg,Yne),e(Yne,gno),e(Yg,hno),e(Yg,jP),e(jP,uno),e(Yg,pno),e(k,_no),e(k,Qn),e(Qn,Kne),e(Kne,bno),e(Qn,vno),e(Qn,DP),e(DP,Fno),e(Qn,Tno),e(Qn,GP),e(GP,Mno),e(Qn,Eno),e(k,Cno),e(k,Wn),e(Wn,Zne),e(Zne,wno),e(Wn,Ano),e(Wn,OP),e(OP,Lno),e(Wn,yno),e(Wn,VP),e(VP,xno),e(Wn,$no),e(k,kno),e(k,Hn),e(Hn,ese),e(ese,Sno),e(Hn,Rno),e(Hn,XP),e(XP,Pno),e(Hn,Bno),e(Hn,zP),e(zP,Ino),e(Hn,Nno),e(k,qno),e(k,Kg),e(Kg,ose),e(ose,jno),e(Kg,Dno),e(Kg,QP),e(QP,Gno),e(Kg,Ono),e(k,Vno),e(k,Un),e(Un,rse),e(rse,Xno),e(Un,zno),e(Un,WP),e(WP,Qno),e(Un,Wno),e(Un,HP),e(HP,Hno),e(Un,Uno),e(k,Jno),e(k,Jn),e(Jn,tse),e(tse,Yno),e(Jn,Kno),e(Jn,UP),e(UP,Zno),e(Jn,eso),e(Jn,JP),e(JP,oso),e(Jn,rso),e(k,tso),e(k,Yn),e(Yn,ase),e(ase,aso),e(Yn,nso),e(Yn,YP),e(YP,sso),e(Yn,lso),e(Yn,KP),e(KP,iso),e(Yn,dso),e(k,cso),e(k,Kn),e(Kn,nse),e(nse,mso),e(Kn,fso),e(Kn,ZP),e(ZP,gso),e(Kn,hso),e(Kn,eB),e(eB,uso),e(Kn,pso),e(k,_so),e(k,Zn),e(Zn,sse),e(sse,bso),e(Zn,vso),e(Zn,oB),e(oB,Fso),e(Zn,Tso),e(Zn,rB),e(rB,Mso),e(Zn,Eso),e(k,Cso),e(k,es),e(es,lse),e(lse,wso),e(es,Aso),e(es,tB),e(tB,Lso),e(es,yso),e(es,aB),e(aB,xso),e(es,$so),e(k,kso),e(k,Zg),e(Zg,ise),e(ise,Sso),e(Zg,Rso),e(Zg,nB),e(nB,Pso),e(Zg,Bso),e(k,Iso),e(k,os),e(os,dse),e(dse,Nso),e(os,qso),e(os,sB),e(sB,jso),e(os,Dso),e(os,lB),e(lB,Gso),e(os,Oso),e(k,Vso),e(k,eh),e(eh,cse),e(cse,Xso),e(eh,zso),e(eh,iB),e(iB,Qso),e(eh,Wso),e(k,Hso),e(k,rs),e(rs,mse),e(mse,Uso),e(rs,Jso),e(rs,dB),e(dB,Yso),e(rs,Kso),e(rs,cB),e(cB,Zso),e(rs,elo),e(k,olo),e(k,ts),e(ts,fse),e(fse,rlo),e(ts,tlo),e(ts,mB),e(mB,alo),e(ts,nlo),e(ts,fB),e(fB,slo),e(ts,llo),e(k,ilo),e(k,as),e(as,gse),e(gse,dlo),e(as,clo),e(as,gB),e(gB,mlo),e(as,flo),e(as,hB),e(hB,glo),e(as,hlo),e(k,ulo),e(k,oh),e(oh,hse),e(hse,plo),e(oh,_lo),e(oh,uB),e(uB,blo),e(oh,vlo),e(k,Flo),e(k,ns),e(ns,use),e(use,Tlo),e(ns,Mlo),e(ns,pB),e(pB,Elo),e(ns,Clo),e(ns,_B),e(_B,wlo),e(ns,Alo),e(k,Llo),e(k,ss),e(ss,pse),e(pse,ylo),e(ss,xlo),e(ss,bB),e(bB,$lo),e(ss,klo),e(ss,vB),e(vB,Slo),e(ss,Rlo),e(k,Plo),e(k,rh),e(rh,_se),e(_se,Blo),e(rh,Ilo),e(rh,FB),e(FB,Nlo),e(rh,qlo),e(k,jlo),e(k,ls),e(ls,bse),e(bse,Dlo),e(ls,Glo),e(ls,TB),e(TB,Olo),e(ls,Vlo),e(ls,MB),e(MB,Xlo),e(ls,zlo),e(k,Qlo),e(k,is),e(is,vse),e(vse,Wlo),e(is,Hlo),e(is,EB),e(EB,Ulo),e(is,Jlo),e(is,CB),e(CB,Ylo),e(is,Klo),e(k,Zlo),e(k,ds),e(ds,Fse),e(Fse,eio),e(ds,oio),e(ds,wB),e(wB,rio),e(ds,tio),e(ds,AB),e(AB,aio),e(ds,nio),e(k,sio),e(k,cs),e(cs,Tse),e(Tse,lio),e(cs,iio),e(cs,LB),e(LB,dio),e(cs,cio),e(cs,yB),e(yB,mio),e(cs,fio),e(k,gio),e(k,ms),e(ms,Mse),e(Mse,hio),e(ms,uio),e(ms,xB),e(xB,pio),e(ms,_io),e(ms,$B),e($B,bio),e(ms,vio),e(k,Fio),e(k,fs),e(fs,Ese),e(Ese,Tio),e(fs,Mio),e(fs,kB),e(kB,Eio),e(fs,Cio),e(fs,SB),e(SB,wio),e(fs,Aio),e(k,Lio),e(k,gs),e(gs,Cse),e(Cse,yio),e(gs,xio),e(gs,RB),e(RB,$io),e(gs,kio),e(gs,PB),e(PB,Sio),e(gs,Rio),e(k,Pio),e(k,hs),e(hs,wse),e(wse,Bio),e(hs,Iio),e(hs,BB),e(BB,Nio),e(hs,qio),e(hs,IB),e(IB,jio),e(hs,Dio),e(k,Gio),e(k,th),e(th,Ase),e(Ase,Oio),e(th,Vio),e(th,NB),e(NB,Xio),e(th,zio),e(k,Qio),e(k,us),e(us,Lse),e(Lse,Wio),e(us,Hio),e(us,qB),e(qB,Uio),e(us,Jio),e(us,jB),e(jB,Yio),e(us,Kio),e(k,Zio),e(k,ah),e(ah,yse),e(yse,edo),e(ah,odo),e(ah,DB),e(DB,rdo),e(ah,tdo),e(k,ado),e(k,nh),e(nh,xse),e(xse,ndo),e(nh,sdo),e(nh,GB),e(GB,ldo),e(nh,ido),e(k,ddo),e(k,ps),e(ps,$se),e($se,cdo),e(ps,mdo),e(ps,OB),e(OB,fdo),e(ps,gdo),e(ps,VB),e(VB,hdo),e(ps,udo),e(k,pdo),e(k,_s),e(_s,kse),e(kse,_do),e(_s,bdo),e(_s,XB),e(XB,vdo),e(_s,Fdo),e(_s,zB),e(zB,Tdo),e(_s,Mdo),e(k,Edo),e(k,bs),e(bs,Sse),e(Sse,Cdo),e(bs,wdo),e(bs,QB),e(QB,Ado),e(bs,Ldo),e(bs,WB),e(WB,ydo),e(bs,xdo),e(k,$do),e(k,sh),e(sh,Rse),e(Rse,kdo),e(sh,Sdo),e(sh,HB),e(HB,Rdo),e(sh,Pdo),e(k,Bdo),e(k,vs),e(vs,Pse),e(Pse,Ido),e(vs,Ndo),e(vs,UB),e(UB,qdo),e(vs,jdo),e(vs,JB),e(JB,Ddo),e(vs,Gdo),e(k,Odo),e(k,Fs),e(Fs,Bse),e(Bse,Vdo),e(Fs,Xdo),e(Fs,YB),e(YB,zdo),e(Fs,Qdo),e(Fs,KB),e(KB,Wdo),e(Fs,Hdo),e(k,Udo),e(k,Ts),e(Ts,Ise),e(Ise,Jdo),e(Ts,Ydo),e(Ts,ZB),e(ZB,Kdo),e(Ts,Zdo),e(Ts,eI),e(eI,eco),e(Ts,oco),e(k,rco),e(k,Ms),e(Ms,Nse),e(Nse,tco),e(Ms,aco),e(Ms,oI),e(oI,nco),e(Ms,sco),e(Ms,rI),e(rI,lco),e(Ms,ico),e(k,dco),e(k,Es),e(Es,qse),e(qse,cco),e(Es,mco),e(Es,tI),e(tI,fco),e(Es,gco),e(Es,aI),e(aI,hco),e(Es,uco),e(k,pco),e(k,Cs),e(Cs,jse),e(jse,_co),e(Cs,bco),e(Cs,nI),e(nI,vco),e(Cs,Fco),e(Cs,sI),e(sI,Tco),e(Cs,Mco),e(k,Eco),e(k,lh),e(lh,Dse),e(Dse,Cco),e(lh,wco),e(lh,lI),e(lI,Aco),e(lh,Lco),e(k,yco),e(k,ws),e(ws,Gse),e(Gse,xco),e(ws,$co),e(ws,iI),e(iI,kco),e(ws,Sco),e(ws,dI),e(dI,Rco),e(ws,Pco),e(k,Bco),e(k,ih),e(ih,Ose),e(Ose,Ico),e(ih,Nco),e(ih,cI),e(cI,qco),e(ih,jco),e(k,Dco),e(k,dh),e(dh,Vse),e(Vse,Gco),e(dh,Oco),e(dh,mI),e(mI,Vco),e(dh,Xco),e(k,zco),e(k,ch),e(ch,Xse),e(Xse,Qco),e(ch,Wco),e(ch,fI),e(fI,Hco),e(ch,Uco),e(k,Jco),e(k,mh),e(mh,zse),e(zse,Yco),e(mh,Kco),e(mh,gI),e(gI,Zco),e(mh,emo),e(k,omo),e(k,As),e(As,Qse),e(Qse,rmo),e(As,tmo),e(As,hI),e(hI,amo),e(As,nmo),e(As,uI),e(uI,smo),e(As,lmo),e(k,imo),e(k,fh),e(fh,Wse),e(Wse,dmo),e(fh,cmo),e(fh,pI),e(pI,mmo),e(fh,fmo),e(k,gmo),e(k,Ls),e(Ls,Hse),e(Hse,hmo),e(Ls,umo),e(Ls,_I),e(_I,pmo),e(Ls,_mo),e(Ls,bI),e(bI,bmo),e(Ls,vmo),e(k,Fmo),e(k,ys),e(ys,Use),e(Use,Tmo),e(ys,Mmo),e(ys,vI),e(vI,Emo),e(ys,Cmo),e(ys,FI),e(FI,wmo),e(ys,Amo),e(k,Lmo),e(k,xs),e(xs,Jse),e(Jse,ymo),e(xs,xmo),e(xs,TI),e(TI,$mo),e(xs,kmo),e(xs,MI),e(MI,Smo),e(xs,Rmo),e(k,Pmo),e(k,$s),e($s,Yse),e(Yse,Bmo),e($s,Imo),e($s,EI),e(EI,Nmo),e($s,qmo),e($s,CI),e(CI,jmo),e($s,Dmo),e(k,Gmo),e(k,ks),e(ks,Kse),e(Kse,Omo),e(ks,Vmo),e(ks,wI),e(wI,Xmo),e(ks,zmo),e(ks,AI),e(AI,Qmo),e(ks,Wmo),e(k,Hmo),e(k,Ss),e(Ss,Zse),e(Zse,Umo),e(Ss,Jmo),e(Ss,LI),e(LI,Ymo),e(Ss,Kmo),e(Ss,yI),e(yI,Zmo),e(Ss,efo),e(k,ofo),e(k,gh),e(gh,ele),e(ele,rfo),e(gh,tfo),e(gh,xI),e(xI,afo),e(gh,nfo),e(k,sfo),e(k,hh),e(hh,ole),e(ole,lfo),e(hh,ifo),e(hh,$I),e($I,dfo),e(hh,cfo),e(k,mfo),e(k,Rs),e(Rs,rle),e(rle,ffo),e(Rs,gfo),e(Rs,kI),e(kI,hfo),e(Rs,ufo),e(Rs,SI),e(SI,pfo),e(Rs,_fo),e(k,bfo),e(k,Ps),e(Ps,tle),e(tle,vfo),e(Ps,Ffo),e(Ps,RI),e(RI,Tfo),e(Ps,Mfo),e(Ps,PI),e(PI,Efo),e(Ps,Cfo),e(k,wfo),e(k,Bs),e(Bs,ale),e(ale,Afo),e(Bs,Lfo),e(Bs,BI),e(BI,yfo),e(Bs,xfo),e(Bs,II),e(II,$fo),e(Bs,kfo),e(k,Sfo),e(k,uh),e(uh,nle),e(nle,Rfo),e(uh,Pfo),e(uh,NI),e(NI,Bfo),e(uh,Ifo),e(k,Nfo),e(k,ph),e(ph,sle),e(sle,qfo),e(ph,jfo),e(ph,qI),e(qI,Dfo),e(ph,Gfo),e(k,Ofo),e(k,_h),e(_h,lle),e(lle,Vfo),e(_h,Xfo),e(_h,jI),e(jI,zfo),e(_h,Qfo),e(k,Wfo),e(k,Is),e(Is,ile),e(ile,Hfo),e(Is,Ufo),e(Is,DI),e(DI,Jfo),e(Is,Yfo),e(Is,GI),e(GI,Kfo),e(Is,Zfo),e(k,ego),e(k,Ns),e(Ns,dle),e(dle,ogo),e(Ns,rgo),e(Ns,OI),e(OI,tgo),e(Ns,ago),e(Ns,VI),e(VI,ngo),e(Ns,sgo),e(k,lgo),e(k,bh),e(bh,cle),e(cle,igo),e(bh,dgo),e(bh,XI),e(XI,cgo),e(bh,mgo),e(k,fgo),e(k,vh),e(vh,mle),e(mle,ggo),e(vh,hgo),e(vh,zI),e(zI,ugo),e(vh,pgo),e(k,_go),e(k,Fh),e(Fh,fle),e(fle,bgo),e(Fh,vgo),e(Fh,QI),e(QI,Fgo),e(Fh,Tgo),e(k,Mgo),e(k,qs),e(qs,gle),e(gle,Ego),e(qs,Cgo),e(qs,WI),e(WI,wgo),e(qs,Ago),e(qs,HI),e(HI,Lgo),e(qs,ygo),e(k,xgo),e(k,Th),e(Th,hle),e(hle,$go),e(Th,kgo),e(Th,UI),e(UI,Sgo),e(Th,Rgo),e(k,Pgo),e(k,Mh),e(Mh,ule),e(ule,Bgo),e(Mh,Igo),e(Mh,JI),e(JI,Ngo),e(Mh,qgo),e(k,jgo),e(k,js),e(js,ple),e(ple,Dgo),e(js,Ggo),e(js,YI),e(YI,Ogo),e(js,Vgo),e(js,KI),e(KI,Xgo),e(js,zgo),e(k,Qgo),e(k,Ds),e(Ds,_le),e(_le,Wgo),e(Ds,Hgo),e(Ds,ZI),e(ZI,Ugo),e(Ds,Jgo),e(Ds,eN),e(eN,Ygo),e(Ds,Kgo),e(k,Zgo),e(k,Gs),e(Gs,ble),e(ble,eho),e(Gs,oho),e(Gs,oN),e(oN,rho),e(Gs,tho),e(Gs,rN),e(rN,aho),e(Gs,nho),e(k,sho),e(k,Os),e(Os,vle),e(vle,lho),e(Os,iho),e(Os,tN),e(tN,dho),e(Os,cho),e(Os,aN),e(aN,mho),e(Os,fho),e(Lr,gho),M(Eh,Lr,null),e(Ao,hho),e(Ao,Ch),M(Oy,Ch,null),e(Ch,uho),e(Ch,Fle),e(Fle,pho),b(m,HGe,_),b(m,Si,_),e(Si,wh),e(wh,Tle),M(Vy,Tle,null),e(Si,_ho),e(Si,Mle),e(Mle,bho),b(m,UGe,_),b(m,Lo,_),M(Xy,Lo,null),e(Lo,vho),e(Lo,zy),e(zy,Fho),e(zy,nN),e(nN,Tho),e(zy,Mho),e(Lo,Eho),e(Lo,Qy),e(Qy,Cho),e(Qy,Ele),e(Ele,who),e(Qy,Aho),e(Lo,Lho),e(Lo,He),M(Wy,He,null),e(He,yho),e(He,Cle),e(Cle,xho),e(He,$ho),e(He,Sa),e(Sa,kho),e(Sa,wle),e(wle,Sho),e(Sa,Rho),e(Sa,Ale),e(Ale,Pho),e(Sa,Bho),e(Sa,Lle),e(Lle,Iho),e(Sa,Nho),e(He,qho),e(He,Y),e(Y,Ah),e(Ah,yle),e(yle,jho),e(Ah,Dho),e(Ah,sN),e(sN,Gho),e(Ah,Oho),e(Y,Vho),e(Y,Lh),e(Lh,xle),e(xle,Xho),e(Lh,zho),e(Lh,lN),e(lN,Qho),e(Lh,Who),e(Y,Hho),e(Y,yh),e(yh,$le),e($le,Uho),e(yh,Jho),e(yh,iN),e(iN,Yho),e(yh,Kho),e(Y,Zho),e(Y,xh),e(xh,kle),e(kle,euo),e(xh,ouo),e(xh,dN),e(dN,ruo),e(xh,tuo),e(Y,auo),e(Y,$h),e($h,Sle),e(Sle,nuo),e($h,suo),e($h,cN),e(cN,luo),e($h,iuo),e(Y,duo),e(Y,kh),e(kh,Rle),e(Rle,cuo),e(kh,muo),e(kh,mN),e(mN,fuo),e(kh,guo),e(Y,huo),e(Y,Sh),e(Sh,Ple),e(Ple,uuo),e(Sh,puo),e(Sh,fN),e(fN,_uo),e(Sh,buo),e(Y,vuo),e(Y,Rh),e(Rh,Ble),e(Ble,Fuo),e(Rh,Tuo),e(Rh,gN),e(gN,Muo),e(Rh,Euo),e(Y,Cuo),e(Y,Ph),e(Ph,Ile),e(Ile,wuo),e(Ph,Auo),e(Ph,hN),e(hN,Luo),e(Ph,yuo),e(Y,xuo),e(Y,Bh),e(Bh,Nle),e(Nle,$uo),e(Bh,kuo),e(Bh,uN),e(uN,Suo),e(Bh,Ruo),e(Y,Puo),e(Y,Ih),e(Ih,qle),e(qle,Buo),e(Ih,Iuo),e(Ih,pN),e(pN,Nuo),e(Ih,quo),e(Y,juo),e(Y,Nh),e(Nh,jle),e(jle,Duo),e(Nh,Guo),e(Nh,_N),e(_N,Ouo),e(Nh,Vuo),e(Y,Xuo),e(Y,qh),e(qh,Dle),e(Dle,zuo),e(qh,Quo),e(qh,bN),e(bN,Wuo),e(qh,Huo),e(Y,Uuo),e(Y,jh),e(jh,Gle),e(Gle,Juo),e(jh,Yuo),e(jh,vN),e(vN,Kuo),e(jh,Zuo),e(Y,epo),e(Y,Dh),e(Dh,Ole),e(Ole,opo),e(Dh,rpo),e(Dh,FN),e(FN,tpo),e(Dh,apo),e(Y,npo),e(Y,Gh),e(Gh,Vle),e(Vle,spo),e(Gh,lpo),e(Gh,TN),e(TN,ipo),e(Gh,dpo),e(Y,cpo),e(Y,Oh),e(Oh,Xle),e(Xle,mpo),e(Oh,fpo),e(Oh,MN),e(MN,gpo),e(Oh,hpo),e(Y,upo),e(Y,Vh),e(Vh,zle),e(zle,ppo),e(Vh,_po),e(Vh,EN),e(EN,bpo),e(Vh,vpo),e(Y,Fpo),e(Y,Xh),e(Xh,Qle),e(Qle,Tpo),e(Xh,Mpo),e(Xh,CN),e(CN,Epo),e(Xh,Cpo),e(Y,wpo),e(Y,zh),e(zh,Wle),e(Wle,Apo),e(zh,Lpo),e(zh,wN),e(wN,ypo),e(zh,xpo),e(Y,$po),e(Y,Qh),e(Qh,Hle),e(Hle,kpo),e(Qh,Spo),e(Qh,AN),e(AN,Rpo),e(Qh,Ppo),e(Y,Bpo),e(Y,Wh),e(Wh,Ule),e(Ule,Ipo),e(Wh,Npo),e(Wh,LN),e(LN,qpo),e(Wh,jpo),e(Y,Dpo),e(Y,Hh),e(Hh,Jle),e(Jle,Gpo),e(Hh,Opo),e(Hh,yN),e(yN,Vpo),e(Hh,Xpo),e(Y,zpo),e(Y,Uh),e(Uh,Yle),e(Yle,Qpo),e(Uh,Wpo),e(Uh,xN),e(xN,Hpo),e(Uh,Upo),e(Y,Jpo),e(Y,Jh),e(Jh,Kle),e(Kle,Ypo),e(Jh,Kpo),e(Jh,$N),e($N,Zpo),e(Jh,e_o),e(Y,o_o),e(Y,Yh),e(Yh,Zle),e(Zle,r_o),e(Yh,t_o),e(Yh,kN),e(kN,a_o),e(Yh,n_o),e(Y,s_o),e(Y,Kh),e(Kh,eie),e(eie,l_o),e(Kh,i_o),e(Kh,SN),e(SN,d_o),e(Kh,c_o),e(Y,m_o),e(Y,Zh),e(Zh,oie),e(oie,f_o),e(Zh,g_o),e(Zh,RN),e(RN,h_o),e(Zh,u_o),e(Y,p_o),e(Y,eu),e(eu,rie),e(rie,__o),e(eu,b_o),e(eu,PN),e(PN,v_o),e(eu,F_o),e(Y,T_o),e(Y,ou),e(ou,tie),e(tie,M_o),e(ou,E_o),e(ou,BN),e(BN,C_o),e(ou,w_o),e(Y,A_o),e(Y,ru),e(ru,aie),e(aie,L_o),e(ru,y_o),e(ru,IN),e(IN,x_o),e(ru,$_o),e(Y,k_o),e(Y,tu),e(tu,nie),e(nie,S_o),e(tu,R_o),e(tu,NN),e(NN,P_o),e(tu,B_o),e(He,I_o),M(au,He,null),e(He,N_o),M(nu,He,null),e(Lo,q_o),e(Lo,su),M(Hy,su,null),e(su,j_o),e(su,sie),e(sie,D_o),b(m,JGe,_),b(m,Ri,_),e(Ri,lu),e(lu,lie),M(Uy,lie,null),e(Ri,G_o),e(Ri,iie),e(iie,O_o),b(m,YGe,_),b(m,yo,_),M(Jy,yo,null),e(yo,V_o),e(yo,Yy),e(Yy,X_o),e(Yy,qN),e(qN,z_o),e(Yy,Q_o),e(yo,W_o),e(yo,Ky),e(Ky,H_o),e(Ky,die),e(die,U_o),e(Ky,J_o),e(yo,Y_o),e(yo,Ue),M(Zy,Ue,null),e(Ue,K_o),e(Ue,cie),e(cie,Z_o),e(Ue,e2o),e(Ue,Pi),e(Pi,o2o),e(Pi,mie),e(mie,r2o),e(Pi,t2o),e(Pi,fie),e(fie,a2o),e(Pi,n2o),e(Ue,s2o),e(Ue,he),e(he,iu),e(iu,gie),e(gie,l2o),e(iu,i2o),e(iu,jN),e(jN,d2o),e(iu,c2o),e(he,m2o),e(he,du),e(du,hie),e(hie,f2o),e(du,g2o),e(du,uie),e(uie,h2o),e(du,u2o),e(he,p2o),e(he,cu),e(cu,pie),e(pie,_2o),e(cu,b2o),e(cu,DN),e(DN,v2o),e(cu,F2o),e(he,T2o),e(he,mu),e(mu,_ie),e(_ie,M2o),e(mu,E2o),e(mu,GN),e(GN,C2o),e(mu,w2o),e(he,A2o),e(he,fu),e(fu,bie),e(bie,L2o),e(fu,y2o),e(fu,ON),e(ON,x2o),e(fu,$2o),e(he,k2o),e(he,gu),e(gu,vie),e(vie,S2o),e(gu,R2o),e(gu,VN),e(VN,P2o),e(gu,B2o),e(he,I2o),e(he,hu),e(hu,Fie),e(Fie,N2o),e(hu,q2o),e(hu,XN),e(XN,j2o),e(hu,D2o),e(he,G2o),e(he,uu),e(uu,Tie),e(Tie,O2o),e(uu,V2o),e(uu,zN),e(zN,X2o),e(uu,z2o),e(he,Q2o),e(he,pu),e(pu,Mie),e(Mie,W2o),e(pu,H2o),e(pu,QN),e(QN,U2o),e(pu,J2o),e(he,Y2o),e(he,_u),e(_u,Eie),e(Eie,K2o),e(_u,Z2o),e(_u,WN),e(WN,ebo),e(_u,obo),e(he,rbo),e(he,bu),e(bu,Cie),e(Cie,tbo),e(bu,abo),e(bu,HN),e(HN,nbo),e(bu,sbo),e(he,lbo),e(he,vu),e(vu,wie),e(wie,ibo),e(vu,dbo),e(vu,UN),e(UN,cbo),e(vu,mbo),e(he,fbo),e(he,Fu),e(Fu,Aie),e(Aie,gbo),e(Fu,hbo),e(Fu,JN),e(JN,ubo),e(Fu,pbo),e(he,_bo),e(he,Tu),e(Tu,Lie),e(Lie,bbo),e(Tu,vbo),e(Tu,YN),e(YN,Fbo),e(Tu,Tbo),e(he,Mbo),e(he,Mu),e(Mu,yie),e(yie,Ebo),e(Mu,Cbo),e(Mu,KN),e(KN,wbo),e(Mu,Abo),e(he,Lbo),e(he,Eu),e(Eu,xie),e(xie,ybo),e(Eu,xbo),e(Eu,ZN),e(ZN,$bo),e(Eu,kbo),e(he,Sbo),e(he,Cu),e(Cu,$ie),e($ie,Rbo),e(Cu,Pbo),e(Cu,eq),e(eq,Bbo),e(Cu,Ibo),e(Ue,Nbo),M(wu,Ue,null),e(Ue,qbo),M(Au,Ue,null),e(yo,jbo),e(yo,Lu),M(e7,Lu,null),e(Lu,Dbo),e(Lu,kie),e(kie,Gbo),b(m,KGe,_),b(m,Bi,_),e(Bi,yu),e(yu,Sie),M(o7,Sie,null),e(Bi,Obo),e(Bi,Rie),e(Rie,Vbo),b(m,ZGe,_),b(m,xo,_),M(r7,xo,null),e(xo,Xbo),e(xo,Ii),e(Ii,zbo),e(Ii,oq),e(oq,Qbo),e(Ii,Wbo),e(Ii,rq),e(rq,Hbo),e(Ii,Ubo),e(xo,Jbo),e(xo,t7),e(t7,Ybo),e(t7,Pie),e(Pie,Kbo),e(t7,Zbo),e(xo,evo),e(xo,nt),M(a7,nt,null),e(nt,ovo),e(nt,Bie),e(Bie,rvo),e(nt,tvo),e(nt,Ni),e(Ni,avo),e(Ni,Iie),e(Iie,nvo),e(Ni,svo),e(Ni,tq),e(tq,lvo),e(Ni,ivo),e(nt,dvo),M(xu,nt,null),e(xo,cvo),e(xo,Je),M(n7,Je,null),e(Je,mvo),e(Je,Nie),e(Nie,fvo),e(Je,gvo),e(Je,Ra),e(Ra,hvo),e(Ra,qie),e(qie,uvo),e(Ra,pvo),e(Ra,jie),e(jie,_vo),e(Ra,bvo),e(Ra,Die),e(Die,vvo),e(Ra,Fvo),e(Je,Tvo),e(Je,y),e(y,$u),e($u,Gie),e(Gie,Mvo),e($u,Evo),e($u,aq),e(aq,Cvo),e($u,wvo),e(y,Avo),e(y,ku),e(ku,Oie),e(Oie,Lvo),e(ku,yvo),e(ku,nq),e(nq,xvo),e(ku,$vo),e(y,kvo),e(y,Su),e(Su,Vie),e(Vie,Svo),e(Su,Rvo),e(Su,sq),e(sq,Pvo),e(Su,Bvo),e(y,Ivo),e(y,Ru),e(Ru,Xie),e(Xie,Nvo),e(Ru,qvo),e(Ru,lq),e(lq,jvo),e(Ru,Dvo),e(y,Gvo),e(y,Pu),e(Pu,zie),e(zie,Ovo),e(Pu,Vvo),e(Pu,iq),e(iq,Xvo),e(Pu,zvo),e(y,Qvo),e(y,Bu),e(Bu,Qie),e(Qie,Wvo),e(Bu,Hvo),e(Bu,dq),e(dq,Uvo),e(Bu,Jvo),e(y,Yvo),e(y,Iu),e(Iu,Wie),e(Wie,Kvo),e(Iu,Zvo),e(Iu,cq),e(cq,eFo),e(Iu,oFo),e(y,rFo),e(y,Nu),e(Nu,Hie),e(Hie,tFo),e(Nu,aFo),e(Nu,mq),e(mq,nFo),e(Nu,sFo),e(y,lFo),e(y,qu),e(qu,Uie),e(Uie,iFo),e(qu,dFo),e(qu,fq),e(fq,cFo),e(qu,mFo),e(y,fFo),e(y,ju),e(ju,Jie),e(Jie,gFo),e(ju,hFo),e(ju,gq),e(gq,uFo),e(ju,pFo),e(y,_Fo),e(y,Du),e(Du,Yie),e(Yie,bFo),e(Du,vFo),e(Du,hq),e(hq,FFo),e(Du,TFo),e(y,MFo),e(y,Gu),e(Gu,Kie),e(Kie,EFo),e(Gu,CFo),e(Gu,uq),e(uq,wFo),e(Gu,AFo),e(y,LFo),e(y,Ou),e(Ou,Zie),e(Zie,yFo),e(Ou,xFo),e(Ou,pq),e(pq,$Fo),e(Ou,kFo),e(y,SFo),e(y,Vu),e(Vu,ede),e(ede,RFo),e(Vu,PFo),e(Vu,_q),e(_q,BFo),e(Vu,IFo),e(y,NFo),e(y,Xu),e(Xu,ode),e(ode,qFo),e(Xu,jFo),e(Xu,bq),e(bq,DFo),e(Xu,GFo),e(y,OFo),e(y,zu),e(zu,rde),e(rde,VFo),e(zu,XFo),e(zu,vq),e(vq,zFo),e(zu,QFo),e(y,WFo),e(y,Qu),e(Qu,tde),e(tde,HFo),e(Qu,UFo),e(Qu,Fq),e(Fq,JFo),e(Qu,YFo),e(y,KFo),e(y,Wu),e(Wu,ade),e(ade,ZFo),e(Wu,e1o),e(Wu,Tq),e(Tq,o1o),e(Wu,r1o),e(y,t1o),e(y,Hu),e(Hu,nde),e(nde,a1o),e(Hu,n1o),e(Hu,Mq),e(Mq,s1o),e(Hu,l1o),e(y,i1o),e(y,Uu),e(Uu,sde),e(sde,d1o),e(Uu,c1o),e(Uu,Eq),e(Eq,m1o),e(Uu,f1o),e(y,g1o),e(y,Ju),e(Ju,lde),e(lde,h1o),e(Ju,u1o),e(Ju,Cq),e(Cq,p1o),e(Ju,_1o),e(y,b1o),e(y,Yu),e(Yu,ide),e(ide,v1o),e(Yu,F1o),e(Yu,wq),e(wq,T1o),e(Yu,M1o),e(y,E1o),e(y,Ku),e(Ku,dde),e(dde,C1o),e(Ku,w1o),e(Ku,Aq),e(Aq,A1o),e(Ku,L1o),e(y,y1o),e(y,Zu),e(Zu,cde),e(cde,x1o),e(Zu,$1o),e(Zu,Lq),e(Lq,k1o),e(Zu,S1o),e(y,R1o),e(y,ep),e(ep,mde),e(mde,P1o),e(ep,B1o),e(ep,yq),e(yq,I1o),e(ep,N1o),e(y,q1o),e(y,op),e(op,fde),e(fde,j1o),e(op,D1o),e(op,xq),e(xq,G1o),e(op,O1o),e(y,V1o),e(y,rp),e(rp,gde),e(gde,X1o),e(rp,z1o),e(rp,$q),e($q,Q1o),e(rp,W1o),e(y,H1o),e(y,tp),e(tp,hde),e(hde,U1o),e(tp,J1o),e(tp,kq),e(kq,Y1o),e(tp,K1o),e(y,Z1o),e(y,ap),e(ap,ude),e(ude,eTo),e(ap,oTo),e(ap,Sq),e(Sq,rTo),e(ap,tTo),e(y,aTo),e(y,np),e(np,pde),e(pde,nTo),e(np,sTo),e(np,Rq),e(Rq,lTo),e(np,iTo),e(y,dTo),e(y,sp),e(sp,_de),e(_de,cTo),e(sp,mTo),e(sp,Pq),e(Pq,fTo),e(sp,gTo),e(y,hTo),e(y,lp),e(lp,bde),e(bde,uTo),e(lp,pTo),e(lp,Bq),e(Bq,_To),e(lp,bTo),e(y,vTo),e(y,ip),e(ip,vde),e(vde,FTo),e(ip,TTo),e(ip,Iq),e(Iq,MTo),e(ip,ETo),e(y,CTo),e(y,Vs),e(Vs,Fde),e(Fde,wTo),e(Vs,ATo),e(Vs,Nq),e(Nq,LTo),e(Vs,yTo),e(Vs,qq),e(qq,xTo),e(Vs,$To),e(y,kTo),e(y,dp),e(dp,Tde),e(Tde,STo),e(dp,RTo),e(dp,jq),e(jq,PTo),e(dp,BTo),e(y,ITo),e(y,cp),e(cp,Mde),e(Mde,NTo),e(cp,qTo),e(cp,Dq),e(Dq,jTo),e(cp,DTo),e(y,GTo),e(y,mp),e(mp,Ede),e(Ede,OTo),e(mp,VTo),e(mp,Gq),e(Gq,XTo),e(mp,zTo),e(y,QTo),e(y,fp),e(fp,Cde),e(Cde,WTo),e(fp,HTo),e(fp,Oq),e(Oq,UTo),e(fp,JTo),e(y,YTo),e(y,gp),e(gp,wde),e(wde,KTo),e(gp,ZTo),e(gp,Vq),e(Vq,eMo),e(gp,oMo),e(y,rMo),e(y,hp),e(hp,Ade),e(Ade,tMo),e(hp,aMo),e(hp,Xq),e(Xq,nMo),e(hp,sMo),e(y,lMo),e(y,up),e(up,Lde),e(Lde,iMo),e(up,dMo),e(up,zq),e(zq,cMo),e(up,mMo),e(y,fMo),e(y,pp),e(pp,yde),e(yde,gMo),e(pp,hMo),e(pp,Qq),e(Qq,uMo),e(pp,pMo),e(y,_Mo),e(y,_p),e(_p,xde),e(xde,bMo),e(_p,vMo),e(_p,Wq),e(Wq,FMo),e(_p,TMo),e(y,MMo),e(y,bp),e(bp,$de),e($de,EMo),e(bp,CMo),e(bp,Hq),e(Hq,wMo),e(bp,AMo),e(y,LMo),e(y,vp),e(vp,kde),e(kde,yMo),e(vp,xMo),e(vp,Uq),e(Uq,$Mo),e(vp,kMo),e(y,SMo),e(y,Fp),e(Fp,Sde),e(Sde,RMo),e(Fp,PMo),e(Fp,Jq),e(Jq,BMo),e(Fp,IMo),e(y,NMo),e(y,Tp),e(Tp,Rde),e(Rde,qMo),e(Tp,jMo),e(Tp,Yq),e(Yq,DMo),e(Tp,GMo),e(y,OMo),e(y,Mp),e(Mp,Pde),e(Pde,VMo),e(Mp,XMo),e(Mp,Kq),e(Kq,zMo),e(Mp,QMo),e(y,WMo),e(y,Ep),e(Ep,Bde),e(Bde,HMo),e(Ep,UMo),e(Ep,Zq),e(Zq,JMo),e(Ep,YMo),e(y,KMo),e(y,Cp),e(Cp,Ide),e(Ide,ZMo),e(Cp,eEo),e(Cp,ej),e(ej,oEo),e(Cp,rEo),e(y,tEo),e(y,wp),e(wp,Nde),e(Nde,aEo),e(wp,nEo),e(wp,oj),e(oj,sEo),e(wp,lEo),e(y,iEo),e(y,Ap),e(Ap,qde),e(qde,dEo),e(Ap,cEo),e(Ap,rj),e(rj,mEo),e(Ap,fEo),e(y,gEo),e(y,Lp),e(Lp,jde),e(jde,hEo),e(Lp,uEo),e(Lp,tj),e(tj,pEo),e(Lp,_Eo),e(y,bEo),e(y,yp),e(yp,Dde),e(Dde,vEo),e(yp,FEo),e(yp,aj),e(aj,TEo),e(yp,MEo),e(y,EEo),e(y,xp),e(xp,Gde),e(Gde,CEo),e(xp,wEo),e(xp,nj),e(nj,AEo),e(xp,LEo),e(y,yEo),e(y,$p),e($p,Ode),e(Ode,xEo),e($p,$Eo),e($p,sj),e(sj,kEo),e($p,SEo),e(y,REo),e(y,kp),e(kp,Vde),e(Vde,PEo),e(kp,BEo),e(kp,lj),e(lj,IEo),e(kp,NEo),e(y,qEo),e(y,Sp),e(Sp,Xde),e(Xde,jEo),e(Sp,DEo),e(Sp,ij),e(ij,GEo),e(Sp,OEo),e(y,VEo),e(y,Rp),e(Rp,zde),e(zde,XEo),e(Rp,zEo),e(Rp,dj),e(dj,QEo),e(Rp,WEo),e(y,HEo),e(y,Pp),e(Pp,Qde),e(Qde,UEo),e(Pp,JEo),e(Pp,cj),e(cj,YEo),e(Pp,KEo),e(y,ZEo),e(y,Bp),e(Bp,Wde),e(Wde,e4o),e(Bp,o4o),e(Bp,mj),e(mj,r4o),e(Bp,t4o),e(y,a4o),e(y,Ip),e(Ip,Hde),e(Hde,n4o),e(Ip,s4o),e(Ip,fj),e(fj,l4o),e(Ip,i4o),e(y,d4o),e(y,Np),e(Np,Ude),e(Ude,c4o),e(Np,m4o),e(Np,gj),e(gj,f4o),e(Np,g4o),e(y,h4o),e(y,qp),e(qp,Jde),e(Jde,u4o),e(qp,p4o),e(qp,hj),e(hj,_4o),e(qp,b4o),e(y,v4o),e(y,jp),e(jp,Yde),e(Yde,F4o),e(jp,T4o),e(jp,uj),e(uj,M4o),e(jp,E4o),e(y,C4o),e(y,Dp),e(Dp,Kde),e(Kde,w4o),e(Dp,A4o),e(Dp,pj),e(pj,L4o),e(Dp,y4o),e(y,x4o),e(y,Gp),e(Gp,Zde),e(Zde,$4o),e(Gp,k4o),e(Gp,_j),e(_j,S4o),e(Gp,R4o),e(y,P4o),e(y,Op),e(Op,ece),e(ece,B4o),e(Op,I4o),e(Op,bj),e(bj,N4o),e(Op,q4o),e(y,j4o),e(y,Vp),e(Vp,oce),e(oce,D4o),e(Vp,G4o),e(Vp,vj),e(vj,O4o),e(Vp,V4o),e(y,X4o),e(y,Xp),e(Xp,rce),e(rce,z4o),e(Xp,Q4o),e(Xp,Fj),e(Fj,W4o),e(Xp,H4o),e(y,U4o),e(y,zp),e(zp,tce),e(tce,J4o),e(zp,Y4o),e(zp,Tj),e(Tj,K4o),e(zp,Z4o),e(y,eCo),e(y,Qp),e(Qp,ace),e(ace,oCo),e(Qp,rCo),e(Qp,Mj),e(Mj,tCo),e(Qp,aCo),e(y,nCo),e(y,Wp),e(Wp,nce),e(nce,sCo),e(Wp,lCo),e(Wp,Ej),e(Ej,iCo),e(Wp,dCo),e(y,cCo),e(y,Hp),e(Hp,sce),e(sce,mCo),e(Hp,fCo),e(Hp,Cj),e(Cj,gCo),e(Hp,hCo),e(y,uCo),e(y,Up),e(Up,lce),e(lce,pCo),e(Up,_Co),e(Up,wj),e(wj,bCo),e(Up,vCo),e(y,FCo),e(y,Jp),e(Jp,ice),e(ice,TCo),e(Jp,MCo),e(Jp,Aj),e(Aj,ECo),e(Jp,CCo),e(y,wCo),e(y,Yp),e(Yp,dce),e(dce,ACo),e(Yp,LCo),e(Yp,Lj),e(Lj,yCo),e(Yp,xCo),e(y,$Co),e(y,Kp),e(Kp,cce),e(cce,kCo),e(Kp,SCo),e(Kp,yj),e(yj,RCo),e(Kp,PCo),e(y,BCo),e(y,Zp),e(Zp,mce),e(mce,ICo),e(Zp,NCo),e(Zp,xj),e(xj,qCo),e(Zp,jCo),e(y,DCo),e(y,e_),e(e_,fce),e(fce,GCo),e(e_,OCo),e(e_,$j),e($j,VCo),e(e_,XCo),e(y,zCo),e(y,o_),e(o_,gce),e(gce,QCo),e(o_,WCo),e(o_,kj),e(kj,HCo),e(o_,UCo),e(y,JCo),e(y,r_),e(r_,hce),e(hce,YCo),e(r_,KCo),e(r_,Sj),e(Sj,ZCo),e(r_,e5o),e(y,o5o),e(y,t_),e(t_,uce),e(uce,r5o),e(t_,t5o),e(t_,Rj),e(Rj,a5o),e(t_,n5o),e(y,s5o),e(y,a_),e(a_,pce),e(pce,l5o),e(a_,i5o),e(a_,Pj),e(Pj,d5o),e(a_,c5o),e(y,m5o),e(y,n_),e(n_,_ce),e(_ce,f5o),e(n_,g5o),e(n_,Bj),e(Bj,h5o),e(n_,u5o),e(y,p5o),e(y,s_),e(s_,bce),e(bce,_5o),e(s_,b5o),e(s_,Ij),e(Ij,v5o),e(s_,F5o),e(y,T5o),e(y,l_),e(l_,vce),e(vce,M5o),e(l_,E5o),e(l_,Nj),e(Nj,C5o),e(l_,w5o),e(y,A5o),e(y,i_),e(i_,Fce),e(Fce,L5o),e(i_,y5o),e(i_,qj),e(qj,x5o),e(i_,$5o),e(y,k5o),e(y,d_),e(d_,Tce),e(Tce,S5o),e(d_,R5o),e(d_,jj),e(jj,P5o),e(d_,B5o),e(y,I5o),e(y,c_),e(c_,Mce),e(Mce,N5o),e(c_,q5o),e(c_,Dj),e(Dj,j5o),e(c_,D5o),e(y,G5o),e(y,m_),e(m_,Ece),e(Ece,O5o),e(m_,V5o),e(m_,Gj),e(Gj,X5o),e(m_,z5o),e(y,Q5o),e(y,f_),e(f_,Cce),e(Cce,W5o),e(f_,H5o),e(f_,Oj),e(Oj,U5o),e(f_,J5o),e(y,Y5o),e(y,g_),e(g_,wce),e(wce,K5o),e(g_,Z5o),e(g_,Vj),e(Vj,e3o),e(g_,o3o),e(y,r3o),e(y,h_),e(h_,Ace),e(Ace,t3o),e(h_,a3o),e(h_,Xj),e(Xj,n3o),e(h_,s3o),e(y,l3o),e(y,u_),e(u_,Lce),e(Lce,i3o),e(u_,d3o),e(u_,zj),e(zj,c3o),e(u_,m3o),e(y,f3o),e(y,p_),e(p_,yce),e(yce,g3o),e(p_,h3o),e(p_,Qj),e(Qj,u3o),e(p_,p3o),e(y,_3o),e(y,__),e(__,xce),e(xce,b3o),e(__,v3o),e(__,Wj),e(Wj,F3o),e(__,T3o),e(y,M3o),e(y,b_),e(b_,$ce),e($ce,E3o),e(b_,C3o),e(b_,Hj),e(Hj,w3o),e(b_,A3o),e(y,L3o),e(y,v_),e(v_,kce),e(kce,y3o),e(v_,x3o),e(v_,Uj),e(Uj,$3o),e(v_,k3o),e(y,S3o),e(y,F_),e(F_,Sce),e(Sce,R3o),e(F_,P3o),e(F_,Jj),e(Jj,B3o),e(F_,I3o),e(y,N3o),e(y,T_),e(T_,Rce),e(Rce,q3o),e(T_,j3o),e(T_,Yj),e(Yj,D3o),e(T_,G3o),e(y,O3o),e(y,M_),e(M_,Pce),e(Pce,V3o),e(M_,X3o),e(M_,Kj),e(Kj,z3o),e(M_,Q3o),e(y,W3o),e(y,E_),e(E_,Bce),e(Bce,H3o),e(E_,U3o),e(E_,Zj),e(Zj,J3o),e(E_,Y3o),e(y,K3o),e(y,C_),e(C_,Ice),e(Ice,Z3o),e(C_,e0o),e(C_,eD),e(eD,o0o),e(C_,r0o),e(y,t0o),e(y,w_),e(w_,Nce),e(Nce,a0o),e(w_,n0o),e(w_,oD),e(oD,s0o),e(w_,l0o),e(y,i0o),e(y,A_),e(A_,qce),e(qce,d0o),e(A_,c0o),e(A_,rD),e(rD,m0o),e(A_,f0o),e(y,g0o),e(y,L_),e(L_,jce),e(jce,h0o),e(L_,u0o),e(L_,tD),e(tD,p0o),e(L_,_0o),e(Je,b0o),e(Je,y_),e(y_,v0o),e(y_,Dce),e(Dce,F0o),e(y_,T0o),e(y_,Gce),e(Gce,M0o),e(Je,E0o),M(x_,Je,null),b(m,eOe,_),b(m,qi,_),e(qi,$_),e($_,Oce),M(s7,Oce,null),e(qi,C0o),e(qi,Vce),e(Vce,w0o),b(m,oOe,_),b(m,$o,_),M(l7,$o,null),e($o,A0o),e($o,ji),e(ji,L0o),e(ji,aD),e(aD,y0o),e(ji,x0o),e(ji,nD),e(nD,$0o),e(ji,k0o),e($o,S0o),e($o,i7),e(i7,R0o),e(i7,Xce),e(Xce,P0o),e(i7,B0o),e($o,I0o),e($o,st),M(d7,st,null),e(st,N0o),e(st,zce),e(zce,q0o),e(st,j0o),e(st,Di),e(Di,D0o),e(Di,Qce),e(Qce,G0o),e(Di,O0o),e(Di,sD),e(sD,V0o),e(Di,X0o),e(st,z0o),M(k_,st,null),e($o,Q0o),e($o,Ye),M(c7,Ye,null),e(Ye,W0o),e(Ye,Wce),e(Wce,H0o),e(Ye,U0o),e(Ye,Pa),e(Pa,J0o),e(Pa,Hce),e(Hce,Y0o),e(Pa,K0o),e(Pa,Uce),e(Uce,Z0o),e(Pa,ewo),e(Pa,Jce),e(Jce,owo),e(Pa,rwo),e(Ye,two),e(Ye,G),e(G,S_),e(S_,Yce),e(Yce,awo),e(S_,nwo),e(S_,lD),e(lD,swo),e(S_,lwo),e(G,iwo),e(G,R_),e(R_,Kce),e(Kce,dwo),e(R_,cwo),e(R_,iD),e(iD,mwo),e(R_,fwo),e(G,gwo),e(G,P_),e(P_,Zce),e(Zce,hwo),e(P_,uwo),e(P_,dD),e(dD,pwo),e(P_,_wo),e(G,bwo),e(G,B_),e(B_,eme),e(eme,vwo),e(B_,Fwo),e(B_,cD),e(cD,Two),e(B_,Mwo),e(G,Ewo),e(G,I_),e(I_,ome),e(ome,Cwo),e(I_,wwo),e(I_,mD),e(mD,Awo),e(I_,Lwo),e(G,ywo),e(G,N_),e(N_,rme),e(rme,xwo),e(N_,$wo),e(N_,fD),e(fD,kwo),e(N_,Swo),e(G,Rwo),e(G,q_),e(q_,tme),e(tme,Pwo),e(q_,Bwo),e(q_,gD),e(gD,Iwo),e(q_,Nwo),e(G,qwo),e(G,j_),e(j_,ame),e(ame,jwo),e(j_,Dwo),e(j_,hD),e(hD,Gwo),e(j_,Owo),e(G,Vwo),e(G,D_),e(D_,nme),e(nme,Xwo),e(D_,zwo),e(D_,uD),e(uD,Qwo),e(D_,Wwo),e(G,Hwo),e(G,G_),e(G_,sme),e(sme,Uwo),e(G_,Jwo),e(G_,pD),e(pD,Ywo),e(G_,Kwo),e(G,Zwo),e(G,O_),e(O_,lme),e(lme,eAo),e(O_,oAo),e(O_,_D),e(_D,rAo),e(O_,tAo),e(G,aAo),e(G,V_),e(V_,ime),e(ime,nAo),e(V_,sAo),e(V_,bD),e(bD,lAo),e(V_,iAo),e(G,dAo),e(G,X_),e(X_,dme),e(dme,cAo),e(X_,mAo),e(X_,vD),e(vD,fAo),e(X_,gAo),e(G,hAo),e(G,z_),e(z_,cme),e(cme,uAo),e(z_,pAo),e(z_,FD),e(FD,_Ao),e(z_,bAo),e(G,vAo),e(G,Q_),e(Q_,mme),e(mme,FAo),e(Q_,TAo),e(Q_,TD),e(TD,MAo),e(Q_,EAo),e(G,CAo),e(G,W_),e(W_,fme),e(fme,wAo),e(W_,AAo),e(W_,MD),e(MD,LAo),e(W_,yAo),e(G,xAo),e(G,H_),e(H_,gme),e(gme,$Ao),e(H_,kAo),e(H_,ED),e(ED,SAo),e(H_,RAo),e(G,PAo),e(G,U_),e(U_,hme),e(hme,BAo),e(U_,IAo),e(U_,CD),e(CD,NAo),e(U_,qAo),e(G,jAo),e(G,J_),e(J_,ume),e(ume,DAo),e(J_,GAo),e(J_,wD),e(wD,OAo),e(J_,VAo),e(G,XAo),e(G,Y_),e(Y_,pme),e(pme,zAo),e(Y_,QAo),e(Y_,AD),e(AD,WAo),e(Y_,HAo),e(G,UAo),e(G,K_),e(K_,_me),e(_me,JAo),e(K_,YAo),e(K_,LD),e(LD,KAo),e(K_,ZAo),e(G,e6o),e(G,Z_),e(Z_,bme),e(bme,o6o),e(Z_,r6o),e(Z_,yD),e(yD,t6o),e(Z_,a6o),e(G,n6o),e(G,e2),e(e2,vme),e(vme,s6o),e(e2,l6o),e(e2,xD),e(xD,i6o),e(e2,d6o),e(G,c6o),e(G,o2),e(o2,Fme),e(Fme,m6o),e(o2,f6o),e(o2,$D),e($D,g6o),e(o2,h6o),e(G,u6o),e(G,r2),e(r2,Tme),e(Tme,p6o),e(r2,_6o),e(r2,kD),e(kD,b6o),e(r2,v6o),e(G,F6o),e(G,t2),e(t2,Mme),e(Mme,T6o),e(t2,M6o),e(t2,SD),e(SD,E6o),e(t2,C6o),e(G,w6o),e(G,a2),e(a2,Eme),e(Eme,A6o),e(a2,L6o),e(a2,RD),e(RD,y6o),e(a2,x6o),e(G,$6o),e(G,n2),e(n2,Cme),e(Cme,k6o),e(n2,S6o),e(n2,PD),e(PD,R6o),e(n2,P6o),e(G,B6o),e(G,s2),e(s2,wme),e(wme,I6o),e(s2,N6o),e(s2,BD),e(BD,q6o),e(s2,j6o),e(G,D6o),e(G,l2),e(l2,Ame),e(Ame,G6o),e(l2,O6o),e(l2,ID),e(ID,V6o),e(l2,X6o),e(G,z6o),e(G,i2),e(i2,Lme),e(Lme,Q6o),e(i2,W6o),e(i2,ND),e(ND,H6o),e(i2,U6o),e(G,J6o),e(G,d2),e(d2,yme),e(yme,Y6o),e(d2,K6o),e(d2,qD),e(qD,Z6o),e(d2,eLo),e(G,oLo),e(G,c2),e(c2,xme),e(xme,rLo),e(c2,tLo),e(c2,jD),e(jD,aLo),e(c2,nLo),e(G,sLo),e(G,m2),e(m2,$me),e($me,lLo),e(m2,iLo),e(m2,DD),e(DD,dLo),e(m2,cLo),e(G,mLo),e(G,f2),e(f2,kme),e(kme,fLo),e(f2,gLo),e(f2,GD),e(GD,hLo),e(f2,uLo),e(G,pLo),e(G,g2),e(g2,Sme),e(Sme,_Lo),e(g2,bLo),e(g2,OD),e(OD,vLo),e(g2,FLo),e(G,TLo),e(G,h2),e(h2,Rme),e(Rme,MLo),e(h2,ELo),e(h2,VD),e(VD,CLo),e(h2,wLo),e(G,ALo),e(G,u2),e(u2,Pme),e(Pme,LLo),e(u2,yLo),e(u2,XD),e(XD,xLo),e(u2,$Lo),e(G,kLo),e(G,p2),e(p2,Bme),e(Bme,SLo),e(p2,RLo),e(p2,zD),e(zD,PLo),e(p2,BLo),e(G,ILo),e(G,_2),e(_2,Ime),e(Ime,NLo),e(_2,qLo),e(_2,QD),e(QD,jLo),e(_2,DLo),e(G,GLo),e(G,b2),e(b2,Nme),e(Nme,OLo),e(b2,VLo),e(b2,WD),e(WD,XLo),e(b2,zLo),e(G,QLo),e(G,v2),e(v2,qme),e(qme,WLo),e(v2,HLo),e(v2,HD),e(HD,ULo),e(v2,JLo),e(G,YLo),e(G,F2),e(F2,jme),e(jme,KLo),e(F2,ZLo),e(F2,UD),e(UD,eyo),e(F2,oyo),e(G,ryo),e(G,T2),e(T2,Dme),e(Dme,tyo),e(T2,ayo),e(T2,JD),e(JD,nyo),e(T2,syo),e(Ye,lyo),e(Ye,M2),e(M2,iyo),e(M2,Gme),e(Gme,dyo),e(M2,cyo),e(M2,Ome),e(Ome,myo),e(Ye,fyo),M(E2,Ye,null),b(m,rOe,_),b(m,Gi,_),e(Gi,C2),e(C2,Vme),M(m7,Vme,null),e(Gi,gyo),e(Gi,Xme),e(Xme,hyo),b(m,tOe,_),b(m,ko,_),M(f7,ko,null),e(ko,uyo),e(ko,Oi),e(Oi,pyo),e(Oi,YD),e(YD,_yo),e(Oi,byo),e(Oi,KD),e(KD,vyo),e(Oi,Fyo),e(ko,Tyo),e(ko,g7),e(g7,Myo),e(g7,zme),e(zme,Eyo),e(g7,Cyo),e(ko,wyo),e(ko,lt),M(h7,lt,null),e(lt,Ayo),e(lt,Qme),e(Qme,Lyo),e(lt,yyo),e(lt,Vi),e(Vi,xyo),e(Vi,Wme),e(Wme,$yo),e(Vi,kyo),e(Vi,ZD),e(ZD,Syo),e(Vi,Ryo),e(lt,Pyo),M(w2,lt,null),e(ko,Byo),e(ko,Ke),M(u7,Ke,null),e(Ke,Iyo),e(Ke,Hme),e(Hme,Nyo),e(Ke,qyo),e(Ke,Ba),e(Ba,jyo),e(Ba,Ume),e(Ume,Dyo),e(Ba,Gyo),e(Ba,Jme),e(Jme,Oyo),e(Ba,Vyo),e(Ba,Yme),e(Yme,Xyo),e(Ba,zyo),e(Ke,Qyo),e(Ke,z),e(z,A2),e(A2,Kme),e(Kme,Wyo),e(A2,Hyo),e(A2,eG),e(eG,Uyo),e(A2,Jyo),e(z,Yyo),e(z,L2),e(L2,Zme),e(Zme,Kyo),e(L2,Zyo),e(L2,oG),e(oG,e7o),e(L2,o7o),e(z,r7o),e(z,y2),e(y2,efe),e(efe,t7o),e(y2,a7o),e(y2,rG),e(rG,n7o),e(y2,s7o),e(z,l7o),e(z,x2),e(x2,ofe),e(ofe,i7o),e(x2,d7o),e(x2,tG),e(tG,c7o),e(x2,m7o),e(z,f7o),e(z,$2),e($2,rfe),e(rfe,g7o),e($2,h7o),e($2,aG),e(aG,u7o),e($2,p7o),e(z,_7o),e(z,k2),e(k2,tfe),e(tfe,b7o),e(k2,v7o),e(k2,nG),e(nG,F7o),e(k2,T7o),e(z,M7o),e(z,S2),e(S2,afe),e(afe,E7o),e(S2,C7o),e(S2,sG),e(sG,w7o),e(S2,A7o),e(z,L7o),e(z,R2),e(R2,nfe),e(nfe,y7o),e(R2,x7o),e(R2,lG),e(lG,$7o),e(R2,k7o),e(z,S7o),e(z,P2),e(P2,sfe),e(sfe,R7o),e(P2,P7o),e(P2,iG),e(iG,B7o),e(P2,I7o),e(z,N7o),e(z,B2),e(B2,lfe),e(lfe,q7o),e(B2,j7o),e(B2,dG),e(dG,D7o),e(B2,G7o),e(z,O7o),e(z,I2),e(I2,ife),e(ife,V7o),e(I2,X7o),e(I2,cG),e(cG,z7o),e(I2,Q7o),e(z,W7o),e(z,N2),e(N2,dfe),e(dfe,H7o),e(N2,U7o),e(N2,mG),e(mG,J7o),e(N2,Y7o),e(z,K7o),e(z,q2),e(q2,cfe),e(cfe,Z7o),e(q2,e8o),e(q2,fG),e(fG,o8o),e(q2,r8o),e(z,t8o),e(z,j2),e(j2,mfe),e(mfe,a8o),e(j2,n8o),e(j2,gG),e(gG,s8o),e(j2,l8o),e(z,i8o),e(z,D2),e(D2,ffe),e(ffe,d8o),e(D2,c8o),e(D2,hG),e(hG,m8o),e(D2,f8o),e(z,g8o),e(z,G2),e(G2,gfe),e(gfe,h8o),e(G2,u8o),e(G2,uG),e(uG,p8o),e(G2,_8o),e(z,b8o),e(z,O2),e(O2,hfe),e(hfe,v8o),e(O2,F8o),e(O2,pG),e(pG,T8o),e(O2,M8o),e(z,E8o),e(z,V2),e(V2,ufe),e(ufe,C8o),e(V2,w8o),e(V2,_G),e(_G,A8o),e(V2,L8o),e(z,y8o),e(z,X2),e(X2,pfe),e(pfe,x8o),e(X2,$8o),e(X2,bG),e(bG,k8o),e(X2,S8o),e(z,R8o),e(z,z2),e(z2,_fe),e(_fe,P8o),e(z2,B8o),e(z2,vG),e(vG,I8o),e(z2,N8o),e(z,q8o),e(z,Q2),e(Q2,bfe),e(bfe,j8o),e(Q2,D8o),e(Q2,FG),e(FG,G8o),e(Q2,O8o),e(z,V8o),e(z,W2),e(W2,vfe),e(vfe,X8o),e(W2,z8o),e(W2,TG),e(TG,Q8o),e(W2,W8o),e(z,H8o),e(z,H2),e(H2,Ffe),e(Ffe,U8o),e(H2,J8o),e(H2,MG),e(MG,Y8o),e(H2,K8o),e(z,Z8o),e(z,U2),e(U2,Tfe),e(Tfe,e9o),e(U2,o9o),e(U2,EG),e(EG,r9o),e(U2,t9o),e(z,a9o),e(z,J2),e(J2,Mfe),e(Mfe,n9o),e(J2,s9o),e(J2,CG),e(CG,l9o),e(J2,i9o),e(z,d9o),e(z,Y2),e(Y2,Efe),e(Efe,c9o),e(Y2,m9o),e(Y2,wG),e(wG,f9o),e(Y2,g9o),e(z,h9o),e(z,K2),e(K2,Cfe),e(Cfe,u9o),e(K2,p9o),e(K2,AG),e(AG,_9o),e(K2,b9o),e(z,v9o),e(z,Z2),e(Z2,wfe),e(wfe,F9o),e(Z2,T9o),e(Z2,LG),e(LG,M9o),e(Z2,E9o),e(z,C9o),e(z,eb),e(eb,Afe),e(Afe,w9o),e(eb,A9o),e(eb,yG),e(yG,L9o),e(eb,y9o),e(z,x9o),e(z,ob),e(ob,Lfe),e(Lfe,$9o),e(ob,k9o),e(ob,xG),e(xG,S9o),e(ob,R9o),e(z,P9o),e(z,rb),e(rb,yfe),e(yfe,B9o),e(rb,I9o),e(rb,$G),e($G,N9o),e(rb,q9o),e(z,j9o),e(z,tb),e(tb,xfe),e(xfe,D9o),e(tb,G9o),e(tb,kG),e(kG,O9o),e(tb,V9o),e(z,X9o),e(z,ab),e(ab,$fe),e($fe,z9o),e(ab,Q9o),e(ab,SG),e(SG,W9o),e(ab,H9o),e(z,U9o),e(z,nb),e(nb,kfe),e(kfe,J9o),e(nb,Y9o),e(nb,RG),e(RG,K9o),e(nb,Z9o),e(z,exo),e(z,sb),e(sb,Sfe),e(Sfe,oxo),e(sb,rxo),e(sb,PG),e(PG,txo),e(sb,axo),e(z,nxo),e(z,lb),e(lb,Rfe),e(Rfe,sxo),e(lb,lxo),e(lb,BG),e(BG,ixo),e(lb,dxo),e(z,cxo),e(z,ib),e(ib,Pfe),e(Pfe,mxo),e(ib,fxo),e(ib,IG),e(IG,gxo),e(ib,hxo),e(z,uxo),e(z,db),e(db,Bfe),e(Bfe,pxo),e(db,_xo),e(db,NG),e(NG,bxo),e(db,vxo),e(Ke,Fxo),e(Ke,cb),e(cb,Txo),e(cb,Ife),e(Ife,Mxo),e(cb,Exo),e(cb,Nfe),e(Nfe,Cxo),e(Ke,wxo),M(mb,Ke,null),b(m,aOe,_),b(m,Xi,_),e(Xi,fb),e(fb,qfe),M(p7,qfe,null),e(Xi,Axo),e(Xi,jfe),e(jfe,Lxo),b(m,nOe,_),b(m,So,_),M(_7,So,null),e(So,yxo),e(So,zi),e(zi,xxo),e(zi,qG),e(qG,$xo),e(zi,kxo),e(zi,jG),e(jG,Sxo),e(zi,Rxo),e(So,Pxo),e(So,b7),e(b7,Bxo),e(b7,Dfe),e(Dfe,Ixo),e(b7,Nxo),e(So,qxo),e(So,it),M(v7,it,null),e(it,jxo),e(it,Gfe),e(Gfe,Dxo),e(it,Gxo),e(it,Qi),e(Qi,Oxo),e(Qi,Ofe),e(Ofe,Vxo),e(Qi,Xxo),e(Qi,DG),e(DG,zxo),e(Qi,Qxo),e(it,Wxo),M(gb,it,null),e(So,Hxo),e(So,Ze),M(F7,Ze,null),e(Ze,Uxo),e(Ze,Vfe),e(Vfe,Jxo),e(Ze,Yxo),e(Ze,Ia),e(Ia,Kxo),e(Ia,Xfe),e(Xfe,Zxo),e(Ia,e$o),e(Ia,zfe),e(zfe,o$o),e(Ia,r$o),e(Ia,Qfe),e(Qfe,t$o),e(Ia,a$o),e(Ze,n$o),e(Ze,Q),e(Q,hb),e(hb,Wfe),e(Wfe,s$o),e(hb,l$o),e(hb,GG),e(GG,i$o),e(hb,d$o),e(Q,c$o),e(Q,ub),e(ub,Hfe),e(Hfe,m$o),e(ub,f$o),e(ub,OG),e(OG,g$o),e(ub,h$o),e(Q,u$o),e(Q,pb),e(pb,Ufe),e(Ufe,p$o),e(pb,_$o),e(pb,VG),e(VG,b$o),e(pb,v$o),e(Q,F$o),e(Q,_b),e(_b,Jfe),e(Jfe,T$o),e(_b,M$o),e(_b,XG),e(XG,E$o),e(_b,C$o),e(Q,w$o),e(Q,bb),e(bb,Yfe),e(Yfe,A$o),e(bb,L$o),e(bb,zG),e(zG,y$o),e(bb,x$o),e(Q,$$o),e(Q,vb),e(vb,Kfe),e(Kfe,k$o),e(vb,S$o),e(vb,QG),e(QG,R$o),e(vb,P$o),e(Q,B$o),e(Q,Fb),e(Fb,Zfe),e(Zfe,I$o),e(Fb,N$o),e(Fb,WG),e(WG,q$o),e(Fb,j$o),e(Q,D$o),e(Q,Tb),e(Tb,ege),e(ege,G$o),e(Tb,O$o),e(Tb,HG),e(HG,V$o),e(Tb,X$o),e(Q,z$o),e(Q,Mb),e(Mb,oge),e(oge,Q$o),e(Mb,W$o),e(Mb,UG),e(UG,H$o),e(Mb,U$o),e(Q,J$o),e(Q,Eb),e(Eb,rge),e(rge,Y$o),e(Eb,K$o),e(Eb,JG),e(JG,Z$o),e(Eb,eko),e(Q,oko),e(Q,Cb),e(Cb,tge),e(tge,rko),e(Cb,tko),e(Cb,YG),e(YG,ako),e(Cb,nko),e(Q,sko),e(Q,wb),e(wb,age),e(age,lko),e(wb,iko),e(wb,KG),e(KG,dko),e(wb,cko),e(Q,mko),e(Q,Ab),e(Ab,nge),e(nge,fko),e(Ab,gko),e(Ab,ZG),e(ZG,hko),e(Ab,uko),e(Q,pko),e(Q,Lb),e(Lb,sge),e(sge,_ko),e(Lb,bko),e(Lb,eO),e(eO,vko),e(Lb,Fko),e(Q,Tko),e(Q,yb),e(yb,lge),e(lge,Mko),e(yb,Eko),e(yb,oO),e(oO,Cko),e(yb,wko),e(Q,Ako),e(Q,xb),e(xb,ige),e(ige,Lko),e(xb,yko),e(xb,rO),e(rO,xko),e(xb,$ko),e(Q,kko),e(Q,$b),e($b,dge),e(dge,Sko),e($b,Rko),e($b,tO),e(tO,Pko),e($b,Bko),e(Q,Iko),e(Q,kb),e(kb,cge),e(cge,Nko),e(kb,qko),e(kb,aO),e(aO,jko),e(kb,Dko),e(Q,Gko),e(Q,Sb),e(Sb,mge),e(mge,Oko),e(Sb,Vko),e(Sb,nO),e(nO,Xko),e(Sb,zko),e(Q,Qko),e(Q,Rb),e(Rb,fge),e(fge,Wko),e(Rb,Hko),e(Rb,sO),e(sO,Uko),e(Rb,Jko),e(Q,Yko),e(Q,Pb),e(Pb,gge),e(gge,Kko),e(Pb,Zko),e(Pb,lO),e(lO,eSo),e(Pb,oSo),e(Q,rSo),e(Q,Bb),e(Bb,hge),e(hge,tSo),e(Bb,aSo),e(Bb,iO),e(iO,nSo),e(Bb,sSo),e(Q,lSo),e(Q,Ib),e(Ib,uge),e(uge,iSo),e(Ib,dSo),e(Ib,dO),e(dO,cSo),e(Ib,mSo),e(Q,fSo),e(Q,Nb),e(Nb,pge),e(pge,gSo),e(Nb,hSo),e(Nb,cO),e(cO,uSo),e(Nb,pSo),e(Q,_So),e(Q,qb),e(qb,_ge),e(_ge,bSo),e(qb,vSo),e(qb,mO),e(mO,FSo),e(qb,TSo),e(Q,MSo),e(Q,jb),e(jb,bge),e(bge,ESo),e(jb,CSo),e(jb,fO),e(fO,wSo),e(jb,ASo),e(Q,LSo),e(Q,Db),e(Db,vge),e(vge,ySo),e(Db,xSo),e(Db,gO),e(gO,$So),e(Db,kSo),e(Q,SSo),e(Q,Gb),e(Gb,Fge),e(Fge,RSo),e(Gb,PSo),e(Gb,hO),e(hO,BSo),e(Gb,ISo),e(Q,NSo),e(Q,Ob),e(Ob,Tge),e(Tge,qSo),e(Ob,jSo),e(Ob,uO),e(uO,DSo),e(Ob,GSo),e(Q,OSo),e(Q,Vb),e(Vb,Mge),e(Mge,VSo),e(Vb,XSo),e(Vb,pO),e(pO,zSo),e(Vb,QSo),e(Q,WSo),e(Q,Xb),e(Xb,Ege),e(Ege,HSo),e(Xb,USo),e(Xb,_O),e(_O,JSo),e(Xb,YSo),e(Q,KSo),e(Q,zb),e(zb,Cge),e(Cge,ZSo),e(zb,eRo),e(zb,bO),e(bO,oRo),e(zb,rRo),e(Q,tRo),e(Q,Qb),e(Qb,wge),e(wge,aRo),e(Qb,nRo),e(Qb,Age),e(Age,sRo),e(Qb,lRo),e(Q,iRo),e(Q,Wb),e(Wb,Lge),e(Lge,dRo),e(Wb,cRo),e(Wb,vO),e(vO,mRo),e(Wb,fRo),e(Q,gRo),e(Q,Hb),e(Hb,yge),e(yge,hRo),e(Hb,uRo),e(Hb,FO),e(FO,pRo),e(Hb,_Ro),e(Q,bRo),e(Q,Ub),e(Ub,xge),e(xge,vRo),e(Ub,FRo),e(Ub,TO),e(TO,TRo),e(Ub,MRo),e(Q,ERo),e(Q,Jb),e(Jb,$ge),e($ge,CRo),e(Jb,wRo),e(Jb,MO),e(MO,ARo),e(Jb,LRo),e(Ze,yRo),e(Ze,Yb),e(Yb,xRo),e(Yb,kge),e(kge,$Ro),e(Yb,kRo),e(Yb,Sge),e(Sge,SRo),e(Ze,RRo),M(Kb,Ze,null),b(m,sOe,_),b(m,Wi,_),e(Wi,Zb),e(Zb,Rge),M(T7,Rge,null),e(Wi,PRo),e(Wi,Pge),e(Pge,BRo),b(m,lOe,_),b(m,Ro,_),M(M7,Ro,null),e(Ro,IRo),e(Ro,Hi),e(Hi,NRo),e(Hi,EO),e(EO,qRo),e(Hi,jRo),e(Hi,CO),e(CO,DRo),e(Hi,GRo),e(Ro,ORo),e(Ro,E7),e(E7,VRo),e(E7,Bge),e(Bge,XRo),e(E7,zRo),e(Ro,QRo),e(Ro,dt),M(C7,dt,null),e(dt,WRo),e(dt,Ige),e(Ige,HRo),e(dt,URo),e(dt,Ui),e(Ui,JRo),e(Ui,Nge),e(Nge,YRo),e(Ui,KRo),e(Ui,wO),e(wO,ZRo),e(Ui,ePo),e(dt,oPo),M(ev,dt,null),e(Ro,rPo),e(Ro,eo),M(w7,eo,null),e(eo,tPo),e(eo,qge),e(qge,aPo),e(eo,nPo),e(eo,Na),e(Na,sPo),e(Na,jge),e(jge,lPo),e(Na,iPo),e(Na,Dge),e(Dge,dPo),e(Na,cPo),e(Na,Gge),e(Gge,mPo),e(Na,fPo),e(eo,gPo),e(eo,ue),e(ue,ov),e(ov,Oge),e(Oge,hPo),e(ov,uPo),e(ov,AO),e(AO,pPo),e(ov,_Po),e(ue,bPo),e(ue,rv),e(rv,Vge),e(Vge,vPo),e(rv,FPo),e(rv,LO),e(LO,TPo),e(rv,MPo),e(ue,EPo),e(ue,tv),e(tv,Xge),e(Xge,CPo),e(tv,wPo),e(tv,yO),e(yO,APo),e(tv,LPo),e(ue,yPo),e(ue,av),e(av,zge),e(zge,xPo),e(av,$Po),e(av,xO),e(xO,kPo),e(av,SPo),e(ue,RPo),e(ue,nv),e(nv,Qge),e(Qge,PPo),e(nv,BPo),e(nv,$O),e($O,IPo),e(nv,NPo),e(ue,qPo),e(ue,sv),e(sv,Wge),e(Wge,jPo),e(sv,DPo),e(sv,kO),e(kO,GPo),e(sv,OPo),e(ue,VPo),e(ue,lv),e(lv,Hge),e(Hge,XPo),e(lv,zPo),e(lv,SO),e(SO,QPo),e(lv,WPo),e(ue,HPo),e(ue,iv),e(iv,Uge),e(Uge,UPo),e(iv,JPo),e(iv,RO),e(RO,YPo),e(iv,KPo),e(ue,ZPo),e(ue,dv),e(dv,Jge),e(Jge,eBo),e(dv,oBo),e(dv,PO),e(PO,rBo),e(dv,tBo),e(ue,aBo),e(ue,cv),e(cv,Yge),e(Yge,nBo),e(cv,sBo),e(cv,BO),e(BO,lBo),e(cv,iBo),e(ue,dBo),e(ue,mv),e(mv,Kge),e(Kge,cBo),e(mv,mBo),e(mv,IO),e(IO,fBo),e(mv,gBo),e(ue,hBo),e(ue,fv),e(fv,Zge),e(Zge,uBo),e(fv,pBo),e(fv,NO),e(NO,_Bo),e(fv,bBo),e(ue,vBo),e(ue,gv),e(gv,ehe),e(ehe,FBo),e(gv,TBo),e(gv,qO),e(qO,MBo),e(gv,EBo),e(ue,CBo),e(ue,hv),e(hv,ohe),e(ohe,wBo),e(hv,ABo),e(hv,jO),e(jO,LBo),e(hv,yBo),e(ue,xBo),e(ue,uv),e(uv,rhe),e(rhe,$Bo),e(uv,kBo),e(uv,DO),e(DO,SBo),e(uv,RBo),e(ue,PBo),e(ue,pv),e(pv,the),e(the,BBo),e(pv,IBo),e(pv,GO),e(GO,NBo),e(pv,qBo),e(ue,jBo),e(ue,_v),e(_v,ahe),e(ahe,DBo),e(_v,GBo),e(_v,OO),e(OO,OBo),e(_v,VBo),e(eo,XBo),e(eo,bv),e(bv,zBo),e(bv,nhe),e(nhe,QBo),e(bv,WBo),e(bv,she),e(she,HBo),e(eo,UBo),M(vv,eo,null),b(m,iOe,_),b(m,Ji,_),e(Ji,Fv),e(Fv,lhe),M(A7,lhe,null),e(Ji,JBo),e(Ji,ihe),e(ihe,YBo),b(m,dOe,_),b(m,Po,_),M(L7,Po,null),e(Po,KBo),e(Po,Yi),e(Yi,ZBo),e(Yi,VO),e(VO,eIo),e(Yi,oIo),e(Yi,XO),e(XO,rIo),e(Yi,tIo),e(Po,aIo),e(Po,y7),e(y7,nIo),e(y7,dhe),e(dhe,sIo),e(y7,lIo),e(Po,iIo),e(Po,ct),M(x7,ct,null),e(ct,dIo),e(ct,che),e(che,cIo),e(ct,mIo),e(ct,Ki),e(Ki,fIo),e(Ki,mhe),e(mhe,gIo),e(Ki,hIo),e(Ki,zO),e(zO,uIo),e(Ki,pIo),e(ct,_Io),M(Tv,ct,null),e(Po,bIo),e(Po,oo),M($7,oo,null),e(oo,vIo),e(oo,fhe),e(fhe,FIo),e(oo,TIo),e(oo,qa),e(qa,MIo),e(qa,ghe),e(ghe,EIo),e(qa,CIo),e(qa,hhe),e(hhe,wIo),e(qa,AIo),e(qa,uhe),e(uhe,LIo),e(qa,yIo),e(oo,xIo),e(oo,N),e(N,Mv),e(Mv,phe),e(phe,$Io),e(Mv,kIo),e(Mv,QO),e(QO,SIo),e(Mv,RIo),e(N,PIo),e(N,Ev),e(Ev,_he),e(_he,BIo),e(Ev,IIo),e(Ev,WO),e(WO,NIo),e(Ev,qIo),e(N,jIo),e(N,Cv),e(Cv,bhe),e(bhe,DIo),e(Cv,GIo),e(Cv,HO),e(HO,OIo),e(Cv,VIo),e(N,XIo),e(N,wv),e(wv,vhe),e(vhe,zIo),e(wv,QIo),e(wv,UO),e(UO,WIo),e(wv,HIo),e(N,UIo),e(N,Av),e(Av,Fhe),e(Fhe,JIo),e(Av,YIo),e(Av,JO),e(JO,KIo),e(Av,ZIo),e(N,eNo),e(N,Lv),e(Lv,The),e(The,oNo),e(Lv,rNo),e(Lv,YO),e(YO,tNo),e(Lv,aNo),e(N,nNo),e(N,yv),e(yv,Mhe),e(Mhe,sNo),e(yv,lNo),e(yv,KO),e(KO,iNo),e(yv,dNo),e(N,cNo),e(N,xv),e(xv,Ehe),e(Ehe,mNo),e(xv,fNo),e(xv,ZO),e(ZO,gNo),e(xv,hNo),e(N,uNo),e(N,$v),e($v,Che),e(Che,pNo),e($v,_No),e($v,eV),e(eV,bNo),e($v,vNo),e(N,FNo),e(N,kv),e(kv,whe),e(whe,TNo),e(kv,MNo),e(kv,oV),e(oV,ENo),e(kv,CNo),e(N,wNo),e(N,Sv),e(Sv,Ahe),e(Ahe,ANo),e(Sv,LNo),e(Sv,rV),e(rV,yNo),e(Sv,xNo),e(N,$No),e(N,Rv),e(Rv,Lhe),e(Lhe,kNo),e(Rv,SNo),e(Rv,tV),e(tV,RNo),e(Rv,PNo),e(N,BNo),e(N,Pv),e(Pv,yhe),e(yhe,INo),e(Pv,NNo),e(Pv,aV),e(aV,qNo),e(Pv,jNo),e(N,DNo),e(N,Bv),e(Bv,xhe),e(xhe,GNo),e(Bv,ONo),e(Bv,nV),e(nV,VNo),e(Bv,XNo),e(N,zNo),e(N,Iv),e(Iv,$he),e($he,QNo),e(Iv,WNo),e(Iv,sV),e(sV,HNo),e(Iv,UNo),e(N,JNo),e(N,Nv),e(Nv,khe),e(khe,YNo),e(Nv,KNo),e(Nv,lV),e(lV,ZNo),e(Nv,eqo),e(N,oqo),e(N,qv),e(qv,She),e(She,rqo),e(qv,tqo),e(qv,iV),e(iV,aqo),e(qv,nqo),e(N,sqo),e(N,jv),e(jv,Rhe),e(Rhe,lqo),e(jv,iqo),e(jv,dV),e(dV,dqo),e(jv,cqo),e(N,mqo),e(N,Dv),e(Dv,Phe),e(Phe,fqo),e(Dv,gqo),e(Dv,cV),e(cV,hqo),e(Dv,uqo),e(N,pqo),e(N,Gv),e(Gv,Bhe),e(Bhe,_qo),e(Gv,bqo),e(Gv,mV),e(mV,vqo),e(Gv,Fqo),e(N,Tqo),e(N,Ov),e(Ov,Ihe),e(Ihe,Mqo),e(Ov,Eqo),e(Ov,fV),e(fV,Cqo),e(Ov,wqo),e(N,Aqo),e(N,Vv),e(Vv,Nhe),e(Nhe,Lqo),e(Vv,yqo),e(Vv,gV),e(gV,xqo),e(Vv,$qo),e(N,kqo),e(N,Xv),e(Xv,qhe),e(qhe,Sqo),e(Xv,Rqo),e(Xv,hV),e(hV,Pqo),e(Xv,Bqo),e(N,Iqo),e(N,zv),e(zv,jhe),e(jhe,Nqo),e(zv,qqo),e(zv,uV),e(uV,jqo),e(zv,Dqo),e(N,Gqo),e(N,Qv),e(Qv,Dhe),e(Dhe,Oqo),e(Qv,Vqo),e(Qv,pV),e(pV,Xqo),e(Qv,zqo),e(N,Qqo),e(N,Wv),e(Wv,Ghe),e(Ghe,Wqo),e(Wv,Hqo),e(Wv,_V),e(_V,Uqo),e(Wv,Jqo),e(N,Yqo),e(N,Hv),e(Hv,Ohe),e(Ohe,Kqo),e(Hv,Zqo),e(Hv,bV),e(bV,ejo),e(Hv,ojo),e(N,rjo),e(N,Uv),e(Uv,Vhe),e(Vhe,tjo),e(Uv,ajo),e(Uv,vV),e(vV,njo),e(Uv,sjo),e(N,ljo),e(N,Jv),e(Jv,Xhe),e(Xhe,ijo),e(Jv,djo),e(Jv,FV),e(FV,cjo),e(Jv,mjo),e(N,fjo),e(N,Yv),e(Yv,zhe),e(zhe,gjo),e(Yv,hjo),e(Yv,TV),e(TV,ujo),e(Yv,pjo),e(N,_jo),e(N,Kv),e(Kv,Qhe),e(Qhe,bjo),e(Kv,vjo),e(Kv,MV),e(MV,Fjo),e(Kv,Tjo),e(N,Mjo),e(N,Zv),e(Zv,Whe),e(Whe,Ejo),e(Zv,Cjo),e(Zv,EV),e(EV,wjo),e(Zv,Ajo),e(N,Ljo),e(N,eF),e(eF,Hhe),e(Hhe,yjo),e(eF,xjo),e(eF,CV),e(CV,$jo),e(eF,kjo),e(N,Sjo),e(N,oF),e(oF,Uhe),e(Uhe,Rjo),e(oF,Pjo),e(oF,wV),e(wV,Bjo),e(oF,Ijo),e(N,Njo),e(N,rF),e(rF,Jhe),e(Jhe,qjo),e(rF,jjo),e(rF,AV),e(AV,Djo),e(rF,Gjo),e(N,Ojo),e(N,tF),e(tF,Yhe),e(Yhe,Vjo),e(tF,Xjo),e(tF,LV),e(LV,zjo),e(tF,Qjo),e(N,Wjo),e(N,aF),e(aF,Khe),e(Khe,Hjo),e(aF,Ujo),e(aF,yV),e(yV,Jjo),e(aF,Yjo),e(N,Kjo),e(N,nF),e(nF,Zhe),e(Zhe,Zjo),e(nF,eDo),e(nF,xV),e(xV,oDo),e(nF,rDo),e(N,tDo),e(N,sF),e(sF,eue),e(eue,aDo),e(sF,nDo),e(sF,$V),e($V,sDo),e(sF,lDo),e(N,iDo),e(N,lF),e(lF,oue),e(oue,dDo),e(lF,cDo),e(lF,kV),e(kV,mDo),e(lF,fDo),e(N,gDo),e(N,iF),e(iF,rue),e(rue,hDo),e(iF,uDo),e(iF,SV),e(SV,pDo),e(iF,_Do),e(N,bDo),e(N,dF),e(dF,tue),e(tue,vDo),e(dF,FDo),e(dF,RV),e(RV,TDo),e(dF,MDo),e(N,EDo),e(N,cF),e(cF,aue),e(aue,CDo),e(cF,wDo),e(cF,PV),e(PV,ADo),e(cF,LDo),e(N,yDo),e(N,mF),e(mF,nue),e(nue,xDo),e(mF,$Do),e(mF,BV),e(BV,kDo),e(mF,SDo),e(N,RDo),e(N,fF),e(fF,sue),e(sue,PDo),e(fF,BDo),e(fF,IV),e(IV,IDo),e(fF,NDo),e(N,qDo),e(N,gF),e(gF,lue),e(lue,jDo),e(gF,DDo),e(gF,NV),e(NV,GDo),e(gF,ODo),e(N,VDo),e(N,hF),e(hF,iue),e(iue,XDo),e(hF,zDo),e(hF,qV),e(qV,QDo),e(hF,WDo),e(N,HDo),e(N,uF),e(uF,due),e(due,UDo),e(uF,JDo),e(uF,jV),e(jV,YDo),e(uF,KDo),e(N,ZDo),e(N,pF),e(pF,cue),e(cue,eGo),e(pF,oGo),e(pF,DV),e(DV,rGo),e(pF,tGo),e(oo,aGo),e(oo,_F),e(_F,nGo),e(_F,mue),e(mue,sGo),e(_F,lGo),e(_F,fue),e(fue,iGo),e(oo,dGo),M(bF,oo,null),b(m,cOe,_),b(m,Zi,_),e(Zi,vF),e(vF,gue),M(k7,gue,null),e(Zi,cGo),e(Zi,hue),e(hue,mGo),b(m,mOe,_),b(m,Bo,_),M(S7,Bo,null),e(Bo,fGo),e(Bo,ed),e(ed,gGo),e(ed,GV),e(GV,hGo),e(ed,uGo),e(ed,OV),e(OV,pGo),e(ed,_Go),e(Bo,bGo),e(Bo,R7),e(R7,vGo),e(R7,uue),e(uue,FGo),e(R7,TGo),e(Bo,MGo),e(Bo,mt),M(P7,mt,null),e(mt,EGo),e(mt,pue),e(pue,CGo),e(mt,wGo),e(mt,od),e(od,AGo),e(od,_ue),e(_ue,LGo),e(od,yGo),e(od,VV),e(VV,xGo),e(od,$Go),e(mt,kGo),M(FF,mt,null),e(Bo,SGo),e(Bo,ro),M(B7,ro,null),e(ro,RGo),e(ro,bue),e(bue,PGo),e(ro,BGo),e(ro,ja),e(ja,IGo),e(ja,vue),e(vue,NGo),e(ja,qGo),e(ja,Fue),e(Fue,jGo),e(ja,DGo),e(ja,Tue),e(Tue,GGo),e(ja,OGo),e(ro,VGo),e(ro,Z),e(Z,TF),e(TF,Mue),e(Mue,XGo),e(TF,zGo),e(TF,XV),e(XV,QGo),e(TF,WGo),e(Z,HGo),e(Z,MF),e(MF,Eue),e(Eue,UGo),e(MF,JGo),e(MF,zV),e(zV,YGo),e(MF,KGo),e(Z,ZGo),e(Z,EF),e(EF,Cue),e(Cue,eOo),e(EF,oOo),e(EF,QV),e(QV,rOo),e(EF,tOo),e(Z,aOo),e(Z,CF),e(CF,wue),e(wue,nOo),e(CF,sOo),e(CF,WV),e(WV,lOo),e(CF,iOo),e(Z,dOo),e(Z,wF),e(wF,Aue),e(Aue,cOo),e(wF,mOo),e(wF,HV),e(HV,fOo),e(wF,gOo),e(Z,hOo),e(Z,AF),e(AF,Lue),e(Lue,uOo),e(AF,pOo),e(AF,UV),e(UV,_Oo),e(AF,bOo),e(Z,vOo),e(Z,LF),e(LF,yue),e(yue,FOo),e(LF,TOo),e(LF,JV),e(JV,MOo),e(LF,EOo),e(Z,COo),e(Z,yF),e(yF,xue),e(xue,wOo),e(yF,AOo),e(yF,YV),e(YV,LOo),e(yF,yOo),e(Z,xOo),e(Z,xF),e(xF,$ue),e($ue,$Oo),e(xF,kOo),e(xF,KV),e(KV,SOo),e(xF,ROo),e(Z,POo),e(Z,$F),e($F,kue),e(kue,BOo),e($F,IOo),e($F,ZV),e(ZV,NOo),e($F,qOo),e(Z,jOo),e(Z,kF),e(kF,Sue),e(Sue,DOo),e(kF,GOo),e(kF,eX),e(eX,OOo),e(kF,VOo),e(Z,XOo),e(Z,SF),e(SF,Rue),e(Rue,zOo),e(SF,QOo),e(SF,oX),e(oX,WOo),e(SF,HOo),e(Z,UOo),e(Z,RF),e(RF,Pue),e(Pue,JOo),e(RF,YOo),e(RF,rX),e(rX,KOo),e(RF,ZOo),e(Z,eVo),e(Z,PF),e(PF,Bue),e(Bue,oVo),e(PF,rVo),e(PF,tX),e(tX,tVo),e(PF,aVo),e(Z,nVo),e(Z,BF),e(BF,Iue),e(Iue,sVo),e(BF,lVo),e(BF,aX),e(aX,iVo),e(BF,dVo),e(Z,cVo),e(Z,IF),e(IF,Nue),e(Nue,mVo),e(IF,fVo),e(IF,nX),e(nX,gVo),e(IF,hVo),e(Z,uVo),e(Z,NF),e(NF,que),e(que,pVo),e(NF,_Vo),e(NF,sX),e(sX,bVo),e(NF,vVo),e(Z,FVo),e(Z,qF),e(qF,jue),e(jue,TVo),e(qF,MVo),e(qF,lX),e(lX,EVo),e(qF,CVo),e(Z,wVo),e(Z,jF),e(jF,Due),e(Due,AVo),e(jF,LVo),e(jF,iX),e(iX,yVo),e(jF,xVo),e(Z,$Vo),e(Z,DF),e(DF,Gue),e(Gue,kVo),e(DF,SVo),e(DF,dX),e(dX,RVo),e(DF,PVo),e(Z,BVo),e(Z,GF),e(GF,Oue),e(Oue,IVo),e(GF,NVo),e(GF,cX),e(cX,qVo),e(GF,jVo),e(Z,DVo),e(Z,OF),e(OF,Vue),e(Vue,GVo),e(OF,OVo),e(OF,mX),e(mX,VVo),e(OF,XVo),e(Z,zVo),e(Z,VF),e(VF,Xue),e(Xue,QVo),e(VF,WVo),e(VF,fX),e(fX,HVo),e(VF,UVo),e(Z,JVo),e(Z,XF),e(XF,zue),e(zue,YVo),e(XF,KVo),e(XF,gX),e(gX,ZVo),e(XF,eXo),e(Z,oXo),e(Z,zF),e(zF,Que),e(Que,rXo),e(zF,tXo),e(zF,hX),e(hX,aXo),e(zF,nXo),e(Z,sXo),e(Z,QF),e(QF,Wue),e(Wue,lXo),e(QF,iXo),e(QF,uX),e(uX,dXo),e(QF,cXo),e(Z,mXo),e(Z,WF),e(WF,Hue),e(Hue,fXo),e(WF,gXo),e(WF,pX),e(pX,hXo),e(WF,uXo),e(Z,pXo),e(Z,HF),e(HF,Uue),e(Uue,_Xo),e(HF,bXo),e(HF,_X),e(_X,vXo),e(HF,FXo),e(Z,TXo),e(Z,UF),e(UF,Jue),e(Jue,MXo),e(UF,EXo),e(UF,bX),e(bX,CXo),e(UF,wXo),e(Z,AXo),e(Z,JF),e(JF,Yue),e(Yue,LXo),e(JF,yXo),e(JF,vX),e(vX,xXo),e(JF,$Xo),e(ro,kXo),e(ro,YF),e(YF,SXo),e(YF,Kue),e(Kue,RXo),e(YF,PXo),e(YF,Zue),e(Zue,BXo),e(ro,IXo),M(KF,ro,null),b(m,fOe,_),b(m,rd,_),e(rd,ZF),e(ZF,epe),M(I7,epe,null),e(rd,NXo),e(rd,ope),e(ope,qXo),b(m,gOe,_),b(m,Io,_),M(N7,Io,null),e(Io,jXo),e(Io,td),e(td,DXo),e(td,FX),e(FX,GXo),e(td,OXo),e(td,TX),e(TX,VXo),e(td,XXo),e(Io,zXo),e(Io,q7),e(q7,QXo),e(q7,rpe),e(rpe,WXo),e(q7,HXo),e(Io,UXo),e(Io,ft),M(j7,ft,null),e(ft,JXo),e(ft,tpe),e(tpe,YXo),e(ft,KXo),e(ft,ad),e(ad,ZXo),e(ad,ape),e(ape,ezo),e(ad,ozo),e(ad,MX),e(MX,rzo),e(ad,tzo),e(ft,azo),M(e1,ft,null),e(Io,nzo),e(Io,to),M(D7,to,null),e(to,szo),e(to,npe),e(npe,lzo),e(to,izo),e(to,Da),e(Da,dzo),e(Da,spe),e(spe,czo),e(Da,mzo),e(Da,lpe),e(lpe,fzo),e(Da,gzo),e(Da,ipe),e(ipe,hzo),e(Da,uzo),e(to,pzo),e(to,No),e(No,o1),e(o1,dpe),e(dpe,_zo),e(o1,bzo),e(o1,EX),e(EX,vzo),e(o1,Fzo),e(No,Tzo),e(No,r1),e(r1,cpe),e(cpe,Mzo),e(r1,Ezo),e(r1,CX),e(CX,Czo),e(r1,wzo),e(No,Azo),e(No,t1),e(t1,mpe),e(mpe,Lzo),e(t1,yzo),e(t1,wX),e(wX,xzo),e(t1,$zo),e(No,kzo),e(No,a1),e(a1,fpe),e(fpe,Szo),e(a1,Rzo),e(a1,AX),e(AX,Pzo),e(a1,Bzo),e(No,Izo),e(No,n1),e(n1,gpe),e(gpe,Nzo),e(n1,qzo),e(n1,LX),e(LX,jzo),e(n1,Dzo),e(No,Gzo),e(No,s1),e(s1,hpe),e(hpe,Ozo),e(s1,Vzo),e(s1,yX),e(yX,Xzo),e(s1,zzo),e(to,Qzo),e(to,l1),e(l1,Wzo),e(l1,upe),e(upe,Hzo),e(l1,Uzo),e(l1,ppe),e(ppe,Jzo),e(to,Yzo),M(i1,to,null),b(m,hOe,_),b(m,nd,_),e(nd,d1),e(d1,_pe),M(G7,_pe,null),e(nd,Kzo),e(nd,bpe),e(bpe,Zzo),b(m,uOe,_),b(m,qo,_),M(O7,qo,null),e(qo,eQo),e(qo,sd),e(sd,oQo),e(sd,xX),e(xX,rQo),e(sd,tQo),e(sd,$X),e($X,aQo),e(sd,nQo),e(qo,sQo),e(qo,V7),e(V7,lQo),e(V7,vpe),e(vpe,iQo),e(V7,dQo),e(qo,cQo),e(qo,gt),M(X7,gt,null),e(gt,mQo),e(gt,Fpe),e(Fpe,fQo),e(gt,gQo),e(gt,ld),e(ld,hQo),e(ld,Tpe),e(Tpe,uQo),e(ld,pQo),e(ld,kX),e(kX,_Qo),e(ld,bQo),e(gt,vQo),M(c1,gt,null),e(qo,FQo),e(qo,ao),M(z7,ao,null),e(ao,TQo),e(ao,Mpe),e(Mpe,MQo),e(ao,EQo),e(ao,Ga),e(Ga,CQo),e(Ga,Epe),e(Epe,wQo),e(Ga,AQo),e(Ga,Cpe),e(Cpe,LQo),e(Ga,yQo),e(Ga,wpe),e(wpe,xQo),e(Ga,$Qo),e(ao,kQo),e(ao,H),e(H,m1),e(m1,Ape),e(Ape,SQo),e(m1,RQo),e(m1,SX),e(SX,PQo),e(m1,BQo),e(H,IQo),e(H,f1),e(f1,Lpe),e(Lpe,NQo),e(f1,qQo),e(f1,RX),e(RX,jQo),e(f1,DQo),e(H,GQo),e(H,g1),e(g1,ype),e(ype,OQo),e(g1,VQo),e(g1,PX),e(PX,XQo),e(g1,zQo),e(H,QQo),e(H,h1),e(h1,xpe),e(xpe,WQo),e(h1,HQo),e(h1,BX),e(BX,UQo),e(h1,JQo),e(H,YQo),e(H,u1),e(u1,$pe),e($pe,KQo),e(u1,ZQo),e(u1,IX),e(IX,eWo),e(u1,oWo),e(H,rWo),e(H,p1),e(p1,kpe),e(kpe,tWo),e(p1,aWo),e(p1,NX),e(NX,nWo),e(p1,sWo),e(H,lWo),e(H,_1),e(_1,Spe),e(Spe,iWo),e(_1,dWo),e(_1,qX),e(qX,cWo),e(_1,mWo),e(H,fWo),e(H,b1),e(b1,Rpe),e(Rpe,gWo),e(b1,hWo),e(b1,jX),e(jX,uWo),e(b1,pWo),e(H,_Wo),e(H,v1),e(v1,Ppe),e(Ppe,bWo),e(v1,vWo),e(v1,DX),e(DX,FWo),e(v1,TWo),e(H,MWo),e(H,F1),e(F1,Bpe),e(Bpe,EWo),e(F1,CWo),e(F1,GX),e(GX,wWo),e(F1,AWo),e(H,LWo),e(H,T1),e(T1,Ipe),e(Ipe,yWo),e(T1,xWo),e(T1,OX),e(OX,$Wo),e(T1,kWo),e(H,SWo),e(H,M1),e(M1,Npe),e(Npe,RWo),e(M1,PWo),e(M1,VX),e(VX,BWo),e(M1,IWo),e(H,NWo),e(H,E1),e(E1,qpe),e(qpe,qWo),e(E1,jWo),e(E1,XX),e(XX,DWo),e(E1,GWo),e(H,OWo),e(H,C1),e(C1,jpe),e(jpe,VWo),e(C1,XWo),e(C1,zX),e(zX,zWo),e(C1,QWo),e(H,WWo),e(H,w1),e(w1,Dpe),e(Dpe,HWo),e(w1,UWo),e(w1,QX),e(QX,JWo),e(w1,YWo),e(H,KWo),e(H,A1),e(A1,Gpe),e(Gpe,ZWo),e(A1,eHo),e(A1,WX),e(WX,oHo),e(A1,rHo),e(H,tHo),e(H,L1),e(L1,Ope),e(Ope,aHo),e(L1,nHo),e(L1,HX),e(HX,sHo),e(L1,lHo),e(H,iHo),e(H,y1),e(y1,Vpe),e(Vpe,dHo),e(y1,cHo),e(y1,UX),e(UX,mHo),e(y1,fHo),e(H,gHo),e(H,x1),e(x1,Xpe),e(Xpe,hHo),e(x1,uHo),e(x1,JX),e(JX,pHo),e(x1,_Ho),e(H,bHo),e(H,$1),e($1,zpe),e(zpe,vHo),e($1,FHo),e($1,YX),e(YX,THo),e($1,MHo),e(H,EHo),e(H,k1),e(k1,Qpe),e(Qpe,CHo),e(k1,wHo),e(k1,KX),e(KX,AHo),e(k1,LHo),e(H,yHo),e(H,S1),e(S1,Wpe),e(Wpe,xHo),e(S1,$Ho),e(S1,ZX),e(ZX,kHo),e(S1,SHo),e(H,RHo),e(H,R1),e(R1,Hpe),e(Hpe,PHo),e(R1,BHo),e(R1,ez),e(ez,IHo),e(R1,NHo),e(H,qHo),e(H,P1),e(P1,Upe),e(Upe,jHo),e(P1,DHo),e(P1,oz),e(oz,GHo),e(P1,OHo),e(H,VHo),e(H,B1),e(B1,Jpe),e(Jpe,XHo),e(B1,zHo),e(B1,rz),e(rz,QHo),e(B1,WHo),e(H,HHo),e(H,I1),e(I1,Ype),e(Ype,UHo),e(I1,JHo),e(I1,tz),e(tz,YHo),e(I1,KHo),e(H,ZHo),e(H,N1),e(N1,Kpe),e(Kpe,eUo),e(N1,oUo),e(N1,az),e(az,rUo),e(N1,tUo),e(H,aUo),e(H,q1),e(q1,Zpe),e(Zpe,nUo),e(q1,sUo),e(q1,nz),e(nz,lUo),e(q1,iUo),e(H,dUo),e(H,j1),e(j1,e_e),e(e_e,cUo),e(j1,mUo),e(j1,sz),e(sz,fUo),e(j1,gUo),e(H,hUo),e(H,D1),e(D1,o_e),e(o_e,uUo),e(D1,pUo),e(D1,lz),e(lz,_Uo),e(D1,bUo),e(H,vUo),e(H,G1),e(G1,r_e),e(r_e,FUo),e(G1,TUo),e(G1,iz),e(iz,MUo),e(G1,EUo),e(H,CUo),e(H,O1),e(O1,t_e),e(t_e,wUo),e(O1,AUo),e(O1,dz),e(dz,LUo),e(O1,yUo),e(H,xUo),e(H,V1),e(V1,a_e),e(a_e,$Uo),e(V1,kUo),e(V1,cz),e(cz,SUo),e(V1,RUo),e(H,PUo),e(H,X1),e(X1,n_e),e(n_e,BUo),e(X1,IUo),e(X1,mz),e(mz,NUo),e(X1,qUo),e(H,jUo),e(H,z1),e(z1,s_e),e(s_e,DUo),e(z1,GUo),e(z1,fz),e(fz,OUo),e(z1,VUo),e(H,XUo),e(H,Q1),e(Q1,l_e),e(l_e,zUo),e(Q1,QUo),e(Q1,gz),e(gz,WUo),e(Q1,HUo),e(ao,UUo),e(ao,W1),e(W1,JUo),e(W1,i_e),e(i_e,YUo),e(W1,KUo),e(W1,d_e),e(d_e,ZUo),e(ao,eJo),M(H1,ao,null),b(m,pOe,_),b(m,id,_),e(id,U1),e(U1,c_e),M(Q7,c_e,null),e(id,oJo),e(id,m_e),e(m_e,rJo),b(m,_Oe,_),b(m,jo,_),M(W7,jo,null),e(jo,tJo),e(jo,dd),e(dd,aJo),e(dd,hz),e(hz,nJo),e(dd,sJo),e(dd,uz),e(uz,lJo),e(dd,iJo),e(jo,dJo),e(jo,H7),e(H7,cJo),e(H7,f_e),e(f_e,mJo),e(H7,fJo),e(jo,gJo),e(jo,ht),M(U7,ht,null),e(ht,hJo),e(ht,g_e),e(g_e,uJo),e(ht,pJo),e(ht,cd),e(cd,_Jo),e(cd,h_e),e(h_e,bJo),e(cd,vJo),e(cd,pz),e(pz,FJo),e(cd,TJo),e(ht,MJo),M(J1,ht,null),e(jo,EJo),e(jo,no),M(J7,no,null),e(no,CJo),e(no,u_e),e(u_e,wJo),e(no,AJo),e(no,Oa),e(Oa,LJo),e(Oa,p_e),e(p_e,yJo),e(Oa,xJo),e(Oa,__e),e(__e,$Jo),e(Oa,kJo),e(Oa,b_e),e(b_e,SJo),e(Oa,RJo),e(no,PJo),e(no,V),e(V,Y1),e(Y1,v_e),e(v_e,BJo),e(Y1,IJo),e(Y1,_z),e(_z,NJo),e(Y1,qJo),e(V,jJo),e(V,K1),e(K1,F_e),e(F_e,DJo),e(K1,GJo),e(K1,bz),e(bz,OJo),e(K1,VJo),e(V,XJo),e(V,Z1),e(Z1,T_e),e(T_e,zJo),e(Z1,QJo),e(Z1,vz),e(vz,WJo),e(Z1,HJo),e(V,UJo),e(V,eT),e(eT,M_e),e(M_e,JJo),e(eT,YJo),e(eT,Fz),e(Fz,KJo),e(eT,ZJo),e(V,eYo),e(V,oT),e(oT,E_e),e(E_e,oYo),e(oT,rYo),e(oT,Tz),e(Tz,tYo),e(oT,aYo),e(V,nYo),e(V,rT),e(rT,C_e),e(C_e,sYo),e(rT,lYo),e(rT,Mz),e(Mz,iYo),e(rT,dYo),e(V,cYo),e(V,tT),e(tT,w_e),e(w_e,mYo),e(tT,fYo),e(tT,Ez),e(Ez,gYo),e(tT,hYo),e(V,uYo),e(V,aT),e(aT,A_e),e(A_e,pYo),e(aT,_Yo),e(aT,Cz),e(Cz,bYo),e(aT,vYo),e(V,FYo),e(V,nT),e(nT,L_e),e(L_e,TYo),e(nT,MYo),e(nT,wz),e(wz,EYo),e(nT,CYo),e(V,wYo),e(V,sT),e(sT,y_e),e(y_e,AYo),e(sT,LYo),e(sT,Az),e(Az,yYo),e(sT,xYo),e(V,$Yo),e(V,lT),e(lT,x_e),e(x_e,kYo),e(lT,SYo),e(lT,Lz),e(Lz,RYo),e(lT,PYo),e(V,BYo),e(V,iT),e(iT,$_e),e($_e,IYo),e(iT,NYo),e(iT,yz),e(yz,qYo),e(iT,jYo),e(V,DYo),e(V,dT),e(dT,k_e),e(k_e,GYo),e(dT,OYo),e(dT,xz),e(xz,VYo),e(dT,XYo),e(V,zYo),e(V,cT),e(cT,S_e),e(S_e,QYo),e(cT,WYo),e(cT,$z),e($z,HYo),e(cT,UYo),e(V,JYo),e(V,mT),e(mT,R_e),e(R_e,YYo),e(mT,KYo),e(mT,kz),e(kz,ZYo),e(mT,eKo),e(V,oKo),e(V,fT),e(fT,P_e),e(P_e,rKo),e(fT,tKo),e(fT,Sz),e(Sz,aKo),e(fT,nKo),e(V,sKo),e(V,gT),e(gT,B_e),e(B_e,lKo),e(gT,iKo),e(gT,Rz),e(Rz,dKo),e(gT,cKo),e(V,mKo),e(V,hT),e(hT,I_e),e(I_e,fKo),e(hT,gKo),e(hT,Pz),e(Pz,hKo),e(hT,uKo),e(V,pKo),e(V,uT),e(uT,N_e),e(N_e,_Ko),e(uT,bKo),e(uT,Bz),e(Bz,vKo),e(uT,FKo),e(V,TKo),e(V,pT),e(pT,q_e),e(q_e,MKo),e(pT,EKo),e(pT,Iz),e(Iz,CKo),e(pT,wKo),e(V,AKo),e(V,_T),e(_T,j_e),e(j_e,LKo),e(_T,yKo),e(_T,Nz),e(Nz,xKo),e(_T,$Ko),e(V,kKo),e(V,bT),e(bT,D_e),e(D_e,SKo),e(bT,RKo),e(bT,qz),e(qz,PKo),e(bT,BKo),e(V,IKo),e(V,vT),e(vT,G_e),e(G_e,NKo),e(vT,qKo),e(vT,jz),e(jz,jKo),e(vT,DKo),e(V,GKo),e(V,FT),e(FT,O_e),e(O_e,OKo),e(FT,VKo),e(FT,Dz),e(Dz,XKo),e(FT,zKo),e(V,QKo),e(V,TT),e(TT,V_e),e(V_e,WKo),e(TT,HKo),e(TT,Gz),e(Gz,UKo),e(TT,JKo),e(V,YKo),e(V,MT),e(MT,X_e),e(X_e,KKo),e(MT,ZKo),e(MT,Oz),e(Oz,eZo),e(MT,oZo),e(V,rZo),e(V,ET),e(ET,z_e),e(z_e,tZo),e(ET,aZo),e(ET,Vz),e(Vz,nZo),e(ET,sZo),e(V,lZo),e(V,CT),e(CT,Q_e),e(Q_e,iZo),e(CT,dZo),e(CT,Xz),e(Xz,cZo),e(CT,mZo),e(V,fZo),e(V,wT),e(wT,W_e),e(W_e,gZo),e(wT,hZo),e(wT,zz),e(zz,uZo),e(wT,pZo),e(V,_Zo),e(V,AT),e(AT,H_e),e(H_e,bZo),e(AT,vZo),e(AT,Qz),e(Qz,FZo),e(AT,TZo),e(V,MZo),e(V,LT),e(LT,U_e),e(U_e,EZo),e(LT,CZo),e(LT,Wz),e(Wz,wZo),e(LT,AZo),e(V,LZo),e(V,yT),e(yT,J_e),e(J_e,yZo),e(yT,xZo),e(yT,Hz),e(Hz,$Zo),e(yT,kZo),e(V,SZo),e(V,xT),e(xT,Y_e),e(Y_e,RZo),e(xT,PZo),e(xT,Uz),e(Uz,BZo),e(xT,IZo),e(V,NZo),e(V,$T),e($T,K_e),e(K_e,qZo),e($T,jZo),e($T,Jz),e(Jz,DZo),e($T,GZo),e(V,OZo),e(V,kT),e(kT,Z_e),e(Z_e,VZo),e(kT,XZo),e(kT,Yz),e(Yz,zZo),e(kT,QZo),e(V,WZo),e(V,ST),e(ST,e2e),e(e2e,HZo),e(ST,UZo),e(ST,Kz),e(Kz,JZo),e(ST,YZo),e(V,KZo),e(V,RT),e(RT,o2e),e(o2e,ZZo),e(RT,eer),e(RT,Zz),e(Zz,oer),e(RT,rer),e(V,ter),e(V,PT),e(PT,r2e),e(r2e,aer),e(PT,ner),e(PT,eQ),e(eQ,ser),e(PT,ler),e(V,ier),e(V,BT),e(BT,t2e),e(t2e,der),e(BT,cer),e(BT,oQ),e(oQ,mer),e(BT,fer),e(V,ger),e(V,IT),e(IT,a2e),e(a2e,her),e(IT,uer),e(IT,rQ),e(rQ,per),e(IT,_er),e(V,ber),e(V,NT),e(NT,n2e),e(n2e,ver),e(NT,Fer),e(NT,tQ),e(tQ,Ter),e(NT,Mer),e(no,Eer),e(no,qT),e(qT,Cer),e(qT,s2e),e(s2e,wer),e(qT,Aer),e(qT,l2e),e(l2e,Ler),e(no,yer),M(jT,no,null),b(m,bOe,_),b(m,md,_),e(md,DT),e(DT,i2e),M(Y7,i2e,null),e(md,xer),e(md,d2e),e(d2e,$er),b(m,vOe,_),b(m,Do,_),M(K7,Do,null),e(Do,ker),e(Do,fd),e(fd,Ser),e(fd,aQ),e(aQ,Rer),e(fd,Per),e(fd,nQ),e(nQ,Ber),e(fd,Ier),e(Do,Ner),e(Do,Z7),e(Z7,qer),e(Z7,c2e),e(c2e,jer),e(Z7,Der),e(Do,Ger),e(Do,ut),M(e8,ut,null),e(ut,Oer),e(ut,m2e),e(m2e,Ver),e(ut,Xer),e(ut,gd),e(gd,zer),e(gd,f2e),e(f2e,Qer),e(gd,Wer),e(gd,sQ),e(sQ,Her),e(gd,Uer),e(ut,Jer),M(GT,ut,null),e(Do,Yer),e(Do,so),M(o8,so,null),e(so,Ker),e(so,g2e),e(g2e,Zer),e(so,eor),e(so,Va),e(Va,oor),e(Va,h2e),e(h2e,ror),e(Va,tor),e(Va,u2e),e(u2e,aor),e(Va,nor),e(Va,p2e),e(p2e,sor),e(Va,lor),e(so,ior),e(so,_2e),e(_2e,OT),e(OT,b2e),e(b2e,dor),e(OT,cor),e(OT,lQ),e(lQ,mor),e(OT,gor),e(so,hor),e(so,VT),e(VT,uor),e(VT,v2e),e(v2e,por),e(VT,_or),e(VT,F2e),e(F2e,bor),e(so,vor),M(XT,so,null),b(m,FOe,_),b(m,hd,_),e(hd,zT),e(zT,T2e),M(r8,T2e,null),e(hd,For),e(hd,M2e),e(M2e,Tor),b(m,TOe,_),b(m,Go,_),M(t8,Go,null),e(Go,Mor),e(Go,ud),e(ud,Eor),e(ud,iQ),e(iQ,Cor),e(ud,wor),e(ud,dQ),e(dQ,Aor),e(ud,Lor),e(Go,yor),e(Go,a8),e(a8,xor),e(a8,E2e),e(E2e,$or),e(a8,kor),e(Go,Sor),e(Go,pt),M(n8,pt,null),e(pt,Ror),e(pt,C2e),e(C2e,Por),e(pt,Bor),e(pt,pd),e(pd,Ior),e(pd,w2e),e(w2e,Nor),e(pd,qor),e(pd,cQ),e(cQ,jor),e(pd,Dor),e(pt,Gor),M(QT,pt,null),e(Go,Oor),e(Go,lo),M(s8,lo,null),e(lo,Vor),e(lo,A2e),e(A2e,Xor),e(lo,zor),e(lo,Xa),e(Xa,Qor),e(Xa,L2e),e(L2e,Wor),e(Xa,Hor),e(Xa,y2e),e(y2e,Uor),e(Xa,Jor),e(Xa,x2e),e(x2e,Yor),e(Xa,Kor),e(lo,Zor),e(lo,Fe),e(Fe,WT),e(WT,$2e),e($2e,err),e(WT,orr),e(WT,mQ),e(mQ,rrr),e(WT,trr),e(Fe,arr),e(Fe,HT),e(HT,k2e),e(k2e,nrr),e(HT,srr),e(HT,fQ),e(fQ,lrr),e(HT,irr),e(Fe,drr),e(Fe,UT),e(UT,S2e),e(S2e,crr),e(UT,mrr),e(UT,gQ),e(gQ,frr),e(UT,grr),e(Fe,hrr),e(Fe,JT),e(JT,R2e),e(R2e,urr),e(JT,prr),e(JT,hQ),e(hQ,_rr),e(JT,brr),e(Fe,vrr),e(Fe,Xs),e(Xs,P2e),e(P2e,Frr),e(Xs,Trr),e(Xs,uQ),e(uQ,Mrr),e(Xs,Err),e(Xs,pQ),e(pQ,Crr),e(Xs,wrr),e(Fe,Arr),e(Fe,YT),e(YT,B2e),e(B2e,Lrr),e(YT,yrr),e(YT,_Q),e(_Q,xrr),e(YT,$rr),e(Fe,krr),e(Fe,zs),e(zs,I2e),e(I2e,Srr),e(zs,Rrr),e(zs,bQ),e(bQ,Prr),e(zs,Brr),e(zs,vQ),e(vQ,Irr),e(zs,Nrr),e(Fe,qrr),e(Fe,_t),e(_t,N2e),e(N2e,jrr),e(_t,Drr),e(_t,FQ),e(FQ,Grr),e(_t,Orr),e(_t,TQ),e(TQ,Vrr),e(_t,Xrr),e(_t,MQ),e(MQ,zrr),e(_t,Qrr),e(Fe,Wrr),e(Fe,KT),e(KT,q2e),e(q2e,Hrr),e(KT,Urr),e(KT,EQ),e(EQ,Jrr),e(KT,Yrr),e(Fe,Krr),e(Fe,ZT),e(ZT,j2e),e(j2e,Zrr),e(ZT,etr),e(ZT,CQ),e(CQ,otr),e(ZT,rtr),e(Fe,ttr),e(Fe,eM),e(eM,D2e),e(D2e,atr),e(eM,ntr),e(eM,wQ),e(wQ,str),e(eM,ltr),e(Fe,itr),e(Fe,oM),e(oM,G2e),e(G2e,dtr),e(oM,ctr),e(oM,AQ),e(AQ,mtr),e(oM,ftr),e(Fe,gtr),e(Fe,rM),e(rM,O2e),e(O2e,htr),e(rM,utr),e(rM,LQ),e(LQ,ptr),e(rM,_tr),e(Fe,btr),e(Fe,tM),e(tM,V2e),e(V2e,vtr),e(tM,Ftr),e(tM,yQ),e(yQ,Ttr),e(tM,Mtr),e(Fe,Etr),e(Fe,aM),e(aM,X2e),e(X2e,Ctr),e(aM,wtr),e(aM,xQ),e(xQ,Atr),e(aM,Ltr),e(lo,ytr),e(lo,nM),e(nM,xtr),e(nM,z2e),e(z2e,$tr),e(nM,ktr),e(nM,Q2e),e(Q2e,Str),e(lo,Rtr),M(sM,lo,null),b(m,MOe,_),b(m,_d,_),e(_d,lM),e(lM,W2e),M(l8,W2e,null),e(_d,Ptr),e(_d,H2e),e(H2e,Btr),b(m,EOe,_),b(m,Oo,_),M(i8,Oo,null),e(Oo,Itr),e(Oo,bd),e(bd,Ntr),e(bd,$Q),e($Q,qtr),e(bd,jtr),e(bd,kQ),e(kQ,Dtr),e(bd,Gtr),e(Oo,Otr),e(Oo,d8),e(d8,Vtr),e(d8,U2e),e(U2e,Xtr),e(d8,ztr),e(Oo,Qtr),e(Oo,bt),M(c8,bt,null),e(bt,Wtr),e(bt,J2e),e(J2e,Htr),e(bt,Utr),e(bt,vd),e(vd,Jtr),e(vd,Y2e),e(Y2e,Ytr),e(vd,Ktr),e(vd,SQ),e(SQ,Ztr),e(vd,ear),e(bt,oar),M(iM,bt,null),e(Oo,rar),e(Oo,io),M(m8,io,null),e(io,tar),e(io,K2e),e(K2e,aar),e(io,nar),e(io,za),e(za,sar),e(za,Z2e),e(Z2e,lar),e(za,iar),e(za,ebe),e(ebe,dar),e(za,car),e(za,obe),e(obe,mar),e(za,far),e(io,gar),e(io,rbe),e(rbe,dM),e(dM,tbe),e(tbe,har),e(dM,uar),e(dM,RQ),e(RQ,par),e(dM,_ar),e(io,bar),e(io,cM),e(cM,Far),e(cM,abe),e(abe,Tar),e(cM,Mar),e(cM,nbe),e(nbe,Ear),e(io,Car),M(mM,io,null),b(m,COe,_),b(m,Fd,_),e(Fd,fM),e(fM,sbe),M(f8,sbe,null),e(Fd,war),e(Fd,lbe),e(lbe,Aar),b(m,wOe,_),b(m,Vo,_),M(g8,Vo,null),e(Vo,Lar),e(Vo,Td),e(Td,yar),e(Td,PQ),e(PQ,xar),e(Td,$ar),e(Td,BQ),e(BQ,kar),e(Td,Sar),e(Vo,Rar),e(Vo,h8),e(h8,Par),e(h8,ibe),e(ibe,Bar),e(h8,Iar),e(Vo,Nar),e(Vo,vt),M(u8,vt,null),e(vt,qar),e(vt,dbe),e(dbe,jar),e(vt,Dar),e(vt,Md),e(Md,Gar),e(Md,cbe),e(cbe,Oar),e(Md,Var),e(Md,IQ),e(IQ,Xar),e(Md,zar),e(vt,Qar),M(gM,vt,null),e(Vo,War),e(Vo,co),M(p8,co,null),e(co,Har),e(co,mbe),e(mbe,Uar),e(co,Jar),e(co,Qa),e(Qa,Yar),e(Qa,fbe),e(fbe,Kar),e(Qa,Zar),e(Qa,gbe),e(gbe,enr),e(Qa,onr),e(Qa,hbe),e(hbe,rnr),e(Qa,tnr),e(co,anr),e(co,ube),e(ube,hM),e(hM,pbe),e(pbe,nnr),e(hM,snr),e(hM,NQ),e(NQ,lnr),e(hM,inr),e(co,dnr),e(co,uM),e(uM,cnr),e(uM,_be),e(_be,mnr),e(uM,fnr),e(uM,bbe),e(bbe,gnr),e(co,hnr),M(pM,co,null),b(m,AOe,_),b(m,Ed,_),e(Ed,_M),e(_M,vbe),M(_8,vbe,null),e(Ed,unr),e(Ed,Fbe),e(Fbe,pnr),b(m,LOe,_),b(m,Xo,_),M(b8,Xo,null),e(Xo,_nr),e(Xo,Cd),e(Cd,bnr),e(Cd,qQ),e(qQ,vnr),e(Cd,Fnr),e(Cd,jQ),e(jQ,Tnr),e(Cd,Mnr),e(Xo,Enr),e(Xo,v8),e(v8,Cnr),e(v8,Tbe),e(Tbe,wnr),e(v8,Anr),e(Xo,Lnr),e(Xo,Ft),M(F8,Ft,null),e(Ft,ynr),e(Ft,Mbe),e(Mbe,xnr),e(Ft,$nr),e(Ft,wd),e(wd,knr),e(wd,Ebe),e(Ebe,Snr),e(wd,Rnr),e(wd,DQ),e(DQ,Pnr),e(wd,Bnr),e(Ft,Inr),M(bM,Ft,null),e(Xo,Nnr),e(Xo,mo),M(T8,mo,null),e(mo,qnr),e(mo,Cbe),e(Cbe,jnr),e(mo,Dnr),e(mo,Wa),e(Wa,Gnr),e(Wa,wbe),e(wbe,Onr),e(Wa,Vnr),e(Wa,Abe),e(Abe,Xnr),e(Wa,znr),e(Wa,Lbe),e(Lbe,Qnr),e(Wa,Wnr),e(mo,Hnr),e(mo,Pe),e(Pe,vM),e(vM,ybe),e(ybe,Unr),e(vM,Jnr),e(vM,GQ),e(GQ,Ynr),e(vM,Knr),e(Pe,Znr),e(Pe,FM),e(FM,xbe),e(xbe,esr),e(FM,osr),e(FM,OQ),e(OQ,rsr),e(FM,tsr),e(Pe,asr),e(Pe,TM),e(TM,$be),e($be,nsr),e(TM,ssr),e(TM,VQ),e(VQ,lsr),e(TM,isr),e(Pe,dsr),e(Pe,MM),e(MM,kbe),e(kbe,csr),e(MM,msr),e(MM,XQ),e(XQ,fsr),e(MM,gsr),e(Pe,hsr),e(Pe,EM),e(EM,Sbe),e(Sbe,usr),e(EM,psr),e(EM,zQ),e(zQ,_sr),e(EM,bsr),e(Pe,vsr),e(Pe,CM),e(CM,Rbe),e(Rbe,Fsr),e(CM,Tsr),e(CM,QQ),e(QQ,Msr),e(CM,Esr),e(Pe,Csr),e(Pe,wM),e(wM,Pbe),e(Pbe,wsr),e(wM,Asr),e(wM,WQ),e(WQ,Lsr),e(wM,ysr),e(Pe,xsr),e(Pe,AM),e(AM,Bbe),e(Bbe,$sr),e(AM,ksr),e(AM,HQ),e(HQ,Ssr),e(AM,Rsr),e(Pe,Psr),e(Pe,LM),e(LM,Ibe),e(Ibe,Bsr),e(LM,Isr),e(LM,UQ),e(UQ,Nsr),e(LM,qsr),e(mo,jsr),e(mo,yM),e(yM,Dsr),e(yM,Nbe),e(Nbe,Gsr),e(yM,Osr),e(yM,qbe),e(qbe,Vsr),e(mo,Xsr),M(xM,mo,null),b(m,yOe,_),b(m,Ad,_),e(Ad,$M),e($M,jbe),M(M8,jbe,null),e(Ad,zsr),e(Ad,Dbe),e(Dbe,Qsr),b(m,xOe,_),b(m,zo,_),M(E8,zo,null),e(zo,Wsr),e(zo,Ld),e(Ld,Hsr),e(Ld,JQ),e(JQ,Usr),e(Ld,Jsr),e(Ld,YQ),e(YQ,Ysr),e(Ld,Ksr),e(zo,Zsr),e(zo,C8),e(C8,elr),e(C8,Gbe),e(Gbe,olr),e(C8,rlr),e(zo,tlr),e(zo,Tt),M(w8,Tt,null),e(Tt,alr),e(Tt,Obe),e(Obe,nlr),e(Tt,slr),e(Tt,yd),e(yd,llr),e(yd,Vbe),e(Vbe,ilr),e(yd,dlr),e(yd,KQ),e(KQ,clr),e(yd,mlr),e(Tt,flr),M(kM,Tt,null),e(zo,glr),e(zo,fo),M(A8,fo,null),e(fo,hlr),e(fo,Xbe),e(Xbe,ulr),e(fo,plr),e(fo,Ha),e(Ha,_lr),e(Ha,zbe),e(zbe,blr),e(Ha,vlr),e(Ha,Qbe),e(Qbe,Flr),e(Ha,Tlr),e(Ha,Wbe),e(Wbe,Mlr),e(Ha,Elr),e(fo,Clr),e(fo,et),e(et,SM),e(SM,Hbe),e(Hbe,wlr),e(SM,Alr),e(SM,ZQ),e(ZQ,Llr),e(SM,ylr),e(et,xlr),e(et,RM),e(RM,Ube),e(Ube,$lr),e(RM,klr),e(RM,eW),e(eW,Slr),e(RM,Rlr),e(et,Plr),e(et,PM),e(PM,Jbe),e(Jbe,Blr),e(PM,Ilr),e(PM,oW),e(oW,Nlr),e(PM,qlr),e(et,jlr),e(et,BM),e(BM,Ybe),e(Ybe,Dlr),e(BM,Glr),e(BM,rW),e(rW,Olr),e(BM,Vlr),e(et,Xlr),e(et,IM),e(IM,Kbe),e(Kbe,zlr),e(IM,Qlr),e(IM,tW),e(tW,Wlr),e(IM,Hlr),e(fo,Ulr),e(fo,NM),e(NM,Jlr),e(NM,Zbe),e(Zbe,Ylr),e(NM,Klr),e(NM,eve),e(eve,Zlr),e(fo,eir),M(qM,fo,null),b(m,$Oe,_),b(m,xd,_),e(xd,jM),e(jM,ove),M(L8,ove,null),e(xd,oir),e(xd,rve),e(rve,rir),b(m,kOe,_),b(m,Qo,_),M(y8,Qo,null),e(Qo,tir),e(Qo,$d),e($d,air),e($d,aW),e(aW,nir),e($d,sir),e($d,nW),e(nW,lir),e($d,iir),e(Qo,dir),e(Qo,x8),e(x8,cir),e(x8,tve),e(tve,mir),e(x8,fir),e(Qo,gir),e(Qo,Mt),M($8,Mt,null),e(Mt,hir),e(Mt,ave),e(ave,uir),e(Mt,pir),e(Mt,kd),e(kd,_ir),e(kd,nve),e(nve,bir),e(kd,vir),e(kd,sW),e(sW,Fir),e(kd,Tir),e(Mt,Mir),M(DM,Mt,null),e(Qo,Eir),e(Qo,go),M(k8,go,null),e(go,Cir),e(go,sve),e(sve,wir),e(go,Air),e(go,Ua),e(Ua,Lir),e(Ua,lve),e(lve,yir),e(Ua,xir),e(Ua,ive),e(ive,$ir),e(Ua,kir),e(Ua,dve),e(dve,Sir),e(Ua,Rir),e(go,Pir),e(go,Le),e(Le,GM),e(GM,cve),e(cve,Bir),e(GM,Iir),e(GM,lW),e(lW,Nir),e(GM,qir),e(Le,jir),e(Le,OM),e(OM,mve),e(mve,Dir),e(OM,Gir),e(OM,iW),e(iW,Oir),e(OM,Vir),e(Le,Xir),e(Le,VM),e(VM,fve),e(fve,zir),e(VM,Qir),e(VM,dW),e(dW,Wir),e(VM,Hir),e(Le,Uir),e(Le,XM),e(XM,gve),e(gve,Jir),e(XM,Yir),e(XM,cW),e(cW,Kir),e(XM,Zir),e(Le,edr),e(Le,zM),e(zM,hve),e(hve,odr),e(zM,rdr),e(zM,mW),e(mW,tdr),e(zM,adr),e(Le,ndr),e(Le,QM),e(QM,uve),e(uve,sdr),e(QM,ldr),e(QM,fW),e(fW,idr),e(QM,ddr),e(Le,cdr),e(Le,WM),e(WM,pve),e(pve,mdr),e(WM,fdr),e(WM,gW),e(gW,gdr),e(WM,hdr),e(Le,udr),e(Le,HM),e(HM,_ve),e(_ve,pdr),e(HM,_dr),e(HM,hW),e(hW,bdr),e(HM,vdr),e(Le,Fdr),e(Le,UM),e(UM,bve),e(bve,Tdr),e(UM,Mdr),e(UM,uW),e(uW,Edr),e(UM,Cdr),e(Le,wdr),e(Le,JM),e(JM,vve),e(vve,Adr),e(JM,Ldr),e(JM,pW),e(pW,ydr),e(JM,xdr),e(go,$dr),e(go,YM),e(YM,kdr),e(YM,Fve),e(Fve,Sdr),e(YM,Rdr),e(YM,Tve),e(Tve,Pdr),e(go,Bdr),M(KM,go,null),b(m,SOe,_),b(m,Sd,_),e(Sd,ZM),e(ZM,Mve),M(S8,Mve,null),e(Sd,Idr),e(Sd,Eve),e(Eve,Ndr),b(m,ROe,_),b(m,Wo,_),M(R8,Wo,null),e(Wo,qdr),e(Wo,Rd),e(Rd,jdr),e(Rd,_W),e(_W,Ddr),e(Rd,Gdr),e(Rd,bW),e(bW,Odr),e(Rd,Vdr),e(Wo,Xdr),e(Wo,P8),e(P8,zdr),e(P8,Cve),e(Cve,Qdr),e(P8,Wdr),e(Wo,Hdr),e(Wo,Et),M(B8,Et,null),e(Et,Udr),e(Et,wve),e(wve,Jdr),e(Et,Ydr),e(Et,Pd),e(Pd,Kdr),e(Pd,Ave),e(Ave,Zdr),e(Pd,ecr),e(Pd,vW),e(vW,ocr),e(Pd,rcr),e(Et,tcr),M(eE,Et,null),e(Wo,acr),e(Wo,ho),M(I8,ho,null),e(ho,ncr),e(ho,Lve),e(Lve,scr),e(ho,lcr),e(ho,Ja),e(Ja,icr),e(Ja,yve),e(yve,dcr),e(Ja,ccr),e(Ja,xve),e(xve,mcr),e(Ja,fcr),e(Ja,$ve),e($ve,gcr),e(Ja,hcr),e(ho,ucr),e(ho,N8),e(N8,oE),e(oE,kve),e(kve,pcr),e(oE,_cr),e(oE,FW),e(FW,bcr),e(oE,vcr),e(N8,Fcr),e(N8,rE),e(rE,Sve),e(Sve,Tcr),e(rE,Mcr),e(rE,TW),e(TW,Ecr),e(rE,Ccr),e(ho,wcr),e(ho,tE),e(tE,Acr),e(tE,Rve),e(Rve,Lcr),e(tE,ycr),e(tE,Pve),e(Pve,xcr),e(ho,$cr),M(aE,ho,null),b(m,POe,_),b(m,Bd,_),e(Bd,nE),e(nE,Bve),M(q8,Bve,null),e(Bd,kcr),e(Bd,Ive),e(Ive,Scr),b(m,BOe,_),b(m,Ho,_),M(j8,Ho,null),e(Ho,Rcr),e(Ho,Id),e(Id,Pcr),e(Id,MW),e(MW,Bcr),e(Id,Icr),e(Id,EW),e(EW,Ncr),e(Id,qcr),e(Ho,jcr),e(Ho,D8),e(D8,Dcr),e(D8,Nve),e(Nve,Gcr),e(D8,Ocr),e(Ho,Vcr),e(Ho,Ct),M(G8,Ct,null),e(Ct,Xcr),e(Ct,qve),e(qve,zcr),e(Ct,Qcr),e(Ct,Nd),e(Nd,Wcr),e(Nd,jve),e(jve,Hcr),e(Nd,Ucr),e(Nd,CW),e(CW,Jcr),e(Nd,Ycr),e(Ct,Kcr),M(sE,Ct,null),e(Ho,Zcr),e(Ho,uo),M(O8,uo,null),e(uo,emr),e(uo,Dve),e(Dve,omr),e(uo,rmr),e(uo,Ya),e(Ya,tmr),e(Ya,Gve),e(Gve,amr),e(Ya,nmr),e(Ya,Ove),e(Ove,smr),e(Ya,lmr),e(Ya,Vve),e(Vve,imr),e(Ya,dmr),e(uo,cmr),e(uo,ot),e(ot,lE),e(lE,Xve),e(Xve,mmr),e(lE,fmr),e(lE,wW),e(wW,gmr),e(lE,hmr),e(ot,umr),e(ot,iE),e(iE,zve),e(zve,pmr),e(iE,_mr),e(iE,AW),e(AW,bmr),e(iE,vmr),e(ot,Fmr),e(ot,dE),e(dE,Qve),e(Qve,Tmr),e(dE,Mmr),e(dE,LW),e(LW,Emr),e(dE,Cmr),e(ot,wmr),e(ot,cE),e(cE,Wve),e(Wve,Amr),e(cE,Lmr),e(cE,yW),e(yW,ymr),e(cE,xmr),e(ot,$mr),e(ot,mE),e(mE,Hve),e(Hve,kmr),e(mE,Smr),e(mE,xW),e(xW,Rmr),e(mE,Pmr),e(uo,Bmr),e(uo,fE),e(fE,Imr),e(fE,Uve),e(Uve,Nmr),e(fE,qmr),e(fE,Jve),e(Jve,jmr),e(uo,Dmr),M(gE,uo,null),b(m,IOe,_),b(m,qd,_),e(qd,hE),e(hE,Yve),M(V8,Yve,null),e(qd,Gmr),e(qd,Kve),e(Kve,Omr),b(m,NOe,_),b(m,Uo,_),M(X8,Uo,null),e(Uo,Vmr),e(Uo,jd),e(jd,Xmr),e(jd,$W),e($W,zmr),e(jd,Qmr),e(jd,kW),e(kW,Wmr),e(jd,Hmr),e(Uo,Umr),e(Uo,z8),e(z8,Jmr),e(z8,Zve),e(Zve,Ymr),e(z8,Kmr),e(Uo,Zmr),e(Uo,wt),M(Q8,wt,null),e(wt,efr),e(wt,eFe),e(eFe,ofr),e(wt,rfr),e(wt,Dd),e(Dd,tfr),e(Dd,oFe),e(oFe,afr),e(Dd,nfr),e(Dd,SW),e(SW,sfr),e(Dd,lfr),e(wt,ifr),M(uE,wt,null),e(Uo,dfr),e(Uo,po),M(W8,po,null),e(po,cfr),e(po,rFe),e(rFe,mfr),e(po,ffr),e(po,Ka),e(Ka,gfr),e(Ka,tFe),e(tFe,hfr),e(Ka,ufr),e(Ka,aFe),e(aFe,pfr),e(Ka,_fr),e(Ka,nFe),e(nFe,bfr),e(Ka,vfr),e(po,Ffr),e(po,Gd),e(Gd,pE),e(pE,sFe),e(sFe,Tfr),e(pE,Mfr),e(pE,RW),e(RW,Efr),e(pE,Cfr),e(Gd,wfr),e(Gd,_E),e(_E,lFe),e(lFe,Afr),e(_E,Lfr),e(_E,PW),e(PW,yfr),e(_E,xfr),e(Gd,$fr),e(Gd,bE),e(bE,iFe),e(iFe,kfr),e(bE,Sfr),e(bE,BW),e(BW,Rfr),e(bE,Pfr),e(po,Bfr),e(po,vE),e(vE,Ifr),e(vE,dFe),e(dFe,Nfr),e(vE,qfr),e(vE,cFe),e(cFe,jfr),e(po,Dfr),M(FE,po,null),b(m,qOe,_),b(m,Od,_),e(Od,TE),e(TE,mFe),M(H8,mFe,null),e(Od,Gfr),e(Od,fFe),e(fFe,Ofr),b(m,jOe,_),b(m,Jo,_),M(U8,Jo,null),e(Jo,Vfr),e(Jo,Vd),e(Vd,Xfr),e(Vd,IW),e(IW,zfr),e(Vd,Qfr),e(Vd,NW),e(NW,Wfr),e(Vd,Hfr),e(Jo,Ufr),e(Jo,J8),e(J8,Jfr),e(J8,gFe),e(gFe,Yfr),e(J8,Kfr),e(Jo,Zfr),e(Jo,At),M(Y8,At,null),e(At,egr),e(At,hFe),e(hFe,ogr),e(At,rgr),e(At,Xd),e(Xd,tgr),e(Xd,uFe),e(uFe,agr),e(Xd,ngr),e(Xd,qW),e(qW,sgr),e(Xd,lgr),e(At,igr),M(ME,At,null),e(Jo,dgr),e(Jo,_o),M(K8,_o,null),e(_o,cgr),e(_o,pFe),e(pFe,mgr),e(_o,fgr),e(_o,Za),e(Za,ggr),e(Za,_Fe),e(_Fe,hgr),e(Za,ugr),e(Za,bFe),e(bFe,pgr),e(Za,_gr),e(Za,vFe),e(vFe,bgr),e(Za,vgr),e(_o,Fgr),e(_o,Z8),e(Z8,EE),e(EE,FFe),e(FFe,Tgr),e(EE,Mgr),e(EE,jW),e(jW,Egr),e(EE,Cgr),e(Z8,wgr),e(Z8,CE),e(CE,TFe),e(TFe,Agr),e(CE,Lgr),e(CE,DW),e(DW,ygr),e(CE,xgr),e(_o,$gr),e(_o,wE),e(wE,kgr),e(wE,MFe),e(MFe,Sgr),e(wE,Rgr),e(wE,EFe),e(EFe,Pgr),e(_o,Bgr),M(AE,_o,null),b(m,DOe,_),b(m,zd,_),e(zd,LE),e(LE,CFe),M(e9,CFe,null),e(zd,Igr),e(zd,wFe),e(wFe,Ngr),b(m,GOe,_),b(m,Yo,_),M(o9,Yo,null),e(Yo,qgr),e(Yo,Qd),e(Qd,jgr),e(Qd,GW),e(GW,Dgr),e(Qd,Ggr),e(Qd,OW),e(OW,Ogr),e(Qd,Vgr),e(Yo,Xgr),e(Yo,r9),e(r9,zgr),e(r9,AFe),e(AFe,Qgr),e(r9,Wgr),e(Yo,Hgr),e(Yo,Lt),M(t9,Lt,null),e(Lt,Ugr),e(Lt,LFe),e(LFe,Jgr),e(Lt,Ygr),e(Lt,Wd),e(Wd,Kgr),e(Wd,yFe),e(yFe,Zgr),e(Wd,ehr),e(Wd,VW),e(VW,ohr),e(Wd,rhr),e(Lt,thr),M(yE,Lt,null),e(Yo,ahr),e(Yo,bo),M(a9,bo,null),e(bo,nhr),e(bo,xFe),e(xFe,shr),e(bo,lhr),e(bo,en),e(en,ihr),e(en,$Fe),e($Fe,dhr),e(en,chr),e(en,kFe),e(kFe,mhr),e(en,fhr),e(en,SFe),e(SFe,ghr),e(en,hhr),e(bo,uhr),e(bo,RFe),e(RFe,xE),e(xE,PFe),e(PFe,phr),e(xE,_hr),e(xE,XW),e(XW,bhr),e(xE,vhr),e(bo,Fhr),e(bo,$E),e($E,Thr),e($E,BFe),e(BFe,Mhr),e($E,Ehr),e($E,IFe),e(IFe,Chr),e(bo,whr),M(kE,bo,null),b(m,OOe,_),b(m,Hd,_),e(Hd,SE),e(SE,NFe),M(n9,NFe,null),e(Hd,Ahr),e(Hd,qFe),e(qFe,Lhr),b(m,VOe,_),b(m,Ko,_),M(s9,Ko,null),e(Ko,yhr),e(Ko,Ud),e(Ud,xhr),e(Ud,zW),e(zW,$hr),e(Ud,khr),e(Ud,QW),e(QW,Shr),e(Ud,Rhr),e(Ko,Phr),e(Ko,l9),e(l9,Bhr),e(l9,jFe),e(jFe,Ihr),e(l9,Nhr),e(Ko,qhr),e(Ko,yt),M(i9,yt,null),e(yt,jhr),e(yt,DFe),e(DFe,Dhr),e(yt,Ghr),e(yt,Jd),e(Jd,Ohr),e(Jd,GFe),e(GFe,Vhr),e(Jd,Xhr),e(Jd,WW),e(WW,zhr),e(Jd,Qhr),e(yt,Whr),M(RE,yt,null),e(Ko,Hhr),e(Ko,vo),M(d9,vo,null),e(vo,Uhr),e(vo,OFe),e(OFe,Jhr),e(vo,Yhr),e(vo,on),e(on,Khr),e(on,VFe),e(VFe,Zhr),e(on,eur),e(on,XFe),e(XFe,our),e(on,rur),e(on,zFe),e(zFe,tur),e(on,aur),e(vo,nur),e(vo,rn),e(rn,PE),e(PE,QFe),e(QFe,sur),e(PE,lur),e(PE,HW),e(HW,iur),e(PE,dur),e(rn,cur),e(rn,BE),e(BE,WFe),e(WFe,mur),e(BE,fur),e(BE,UW),e(UW,gur),e(BE,hur),e(rn,uur),e(rn,IE),e(IE,HFe),e(HFe,pur),e(IE,_ur),e(IE,JW),e(JW,bur),e(IE,vur),e(rn,Fur),e(rn,NE),e(NE,UFe),e(UFe,Tur),e(NE,Mur),e(NE,YW),e(YW,Eur),e(NE,Cur),e(vo,wur),e(vo,qE),e(qE,Aur),e(qE,JFe),e(JFe,Lur),e(qE,yur),e(qE,YFe),e(YFe,xur),e(vo,$ur),M(jE,vo,null),b(m,XOe,_),b(m,Yd,_),e(Yd,DE),e(DE,KFe),M(c9,KFe,null),e(Yd,kur),e(Yd,ZFe),e(ZFe,Sur),b(m,zOe,_),b(m,Zo,_),M(m9,Zo,null),e(Zo,Rur),e(Zo,Kd),e(Kd,Pur),e(Kd,KW),e(KW,Bur),e(Kd,Iur),e(Kd,ZW),e(ZW,Nur),e(Kd,qur),e(Zo,jur),e(Zo,f9),e(f9,Dur),e(f9,e1e),e(e1e,Gur),e(f9,Our),e(Zo,Vur),e(Zo,xt),M(g9,xt,null),e(xt,Xur),e(xt,o1e),e(o1e,zur),e(xt,Qur),e(xt,Zd),e(Zd,Wur),e(Zd,r1e),e(r1e,Hur),e(Zd,Uur),e(Zd,eH),e(eH,Jur),e(Zd,Yur),e(xt,Kur),M(GE,xt,null),e(Zo,Zur),e(Zo,Fo),M(h9,Fo,null),e(Fo,epr),e(Fo,t1e),e(t1e,opr),e(Fo,rpr),e(Fo,tn),e(tn,tpr),e(tn,a1e),e(a1e,apr),e(tn,npr),e(tn,n1e),e(n1e,spr),e(tn,lpr),e(tn,s1e),e(s1e,ipr),e(tn,dpr),e(Fo,cpr),e(Fo,l1e),e(l1e,OE),e(OE,i1e),e(i1e,mpr),e(OE,fpr),e(OE,oH),e(oH,gpr),e(OE,hpr),e(Fo,upr),e(Fo,VE),e(VE,ppr),e(VE,d1e),e(d1e,_pr),e(VE,bpr),e(VE,c1e),e(c1e,vpr),e(Fo,Fpr),M(XE,Fo,null),b(m,QOe,_),b(m,ec,_),e(ec,zE),e(zE,m1e),M(u9,m1e,null),e(ec,Tpr),e(ec,f1e),e(f1e,Mpr),b(m,WOe,_),b(m,er,_),M(p9,er,null),e(er,Epr),e(er,oc),e(oc,Cpr),e(oc,rH),e(rH,wpr),e(oc,Apr),e(oc,tH),e(tH,Lpr),e(oc,ypr),e(er,xpr),e(er,_9),e(_9,$pr),e(_9,g1e),e(g1e,kpr),e(_9,Spr),e(er,Rpr),e(er,$t),M(b9,$t,null),e($t,Ppr),e($t,h1e),e(h1e,Bpr),e($t,Ipr),e($t,rc),e(rc,Npr),e(rc,u1e),e(u1e,qpr),e(rc,jpr),e(rc,aH),e(aH,Dpr),e(rc,Gpr),e($t,Opr),M(QE,$t,null),e(er,Vpr),e(er,yr),M(v9,yr,null),e(yr,Xpr),e(yr,p1e),e(p1e,zpr),e(yr,Qpr),e(yr,an),e(an,Wpr),e(an,_1e),e(_1e,Hpr),e(an,Upr),e(an,b1e),e(b1e,Jpr),e(an,Ypr),e(an,v1e),e(v1e,Kpr),e(an,Zpr),e(yr,e_r),e(yr,j),e(j,WE),e(WE,F1e),e(F1e,o_r),e(WE,r_r),e(WE,nH),e(nH,t_r),e(WE,a_r),e(j,n_r),e(j,HE),e(HE,T1e),e(T1e,s_r),e(HE,l_r),e(HE,sH),e(sH,i_r),e(HE,d_r),e(j,c_r),e(j,UE),e(UE,M1e),e(M1e,m_r),e(UE,f_r),e(UE,lH),e(lH,g_r),e(UE,h_r),e(j,u_r),e(j,JE),e(JE,E1e),e(E1e,p_r),e(JE,__r),e(JE,iH),e(iH,b_r),e(JE,v_r),e(j,F_r),e(j,YE),e(YE,C1e),e(C1e,T_r),e(YE,M_r),e(YE,dH),e(dH,E_r),e(YE,C_r),e(j,w_r),e(j,KE),e(KE,w1e),e(w1e,A_r),e(KE,L_r),e(KE,cH),e(cH,y_r),e(KE,x_r),e(j,$_r),e(j,ZE),e(ZE,A1e),e(A1e,k_r),e(ZE,S_r),e(ZE,mH),e(mH,R_r),e(ZE,P_r),e(j,B_r),e(j,e4),e(e4,L1e),e(L1e,I_r),e(e4,N_r),e(e4,fH),e(fH,q_r),e(e4,j_r),e(j,D_r),e(j,o4),e(o4,y1e),e(y1e,G_r),e(o4,O_r),e(o4,gH),e(gH,V_r),e(o4,X_r),e(j,z_r),e(j,r4),e(r4,x1e),e(x1e,Q_r),e(r4,W_r),e(r4,hH),e(hH,H_r),e(r4,U_r),e(j,J_r),e(j,t4),e(t4,$1e),e($1e,Y_r),e(t4,K_r),e(t4,uH),e(uH,Z_r),e(t4,e2r),e(j,o2r),e(j,a4),e(a4,k1e),e(k1e,r2r),e(a4,t2r),e(a4,pH),e(pH,a2r),e(a4,n2r),e(j,s2r),e(j,n4),e(n4,S1e),e(S1e,l2r),e(n4,i2r),e(n4,_H),e(_H,d2r),e(n4,c2r),e(j,m2r),e(j,s4),e(s4,R1e),e(R1e,f2r),e(s4,g2r),e(s4,bH),e(bH,h2r),e(s4,u2r),e(j,p2r),e(j,l4),e(l4,P1e),e(P1e,_2r),e(l4,b2r),e(l4,vH),e(vH,v2r),e(l4,F2r),e(j,T2r),e(j,i4),e(i4,B1e),e(B1e,M2r),e(i4,E2r),e(i4,FH),e(FH,C2r),e(i4,w2r),e(j,A2r),e(j,d4),e(d4,I1e),e(I1e,L2r),e(d4,y2r),e(d4,TH),e(TH,x2r),e(d4,$2r),e(j,k2r),e(j,Qs),e(Qs,N1e),e(N1e,S2r),e(Qs,R2r),e(Qs,MH),e(MH,P2r),e(Qs,B2r),e(Qs,EH),e(EH,I2r),e(Qs,N2r),e(j,q2r),e(j,c4),e(c4,q1e),e(q1e,j2r),e(c4,D2r),e(c4,CH),e(CH,G2r),e(c4,O2r),e(j,V2r),e(j,m4),e(m4,j1e),e(j1e,X2r),e(m4,z2r),e(m4,wH),e(wH,Q2r),e(m4,W2r),e(j,H2r),e(j,f4),e(f4,D1e),e(D1e,U2r),e(f4,J2r),e(f4,AH),e(AH,Y2r),e(f4,K2r),e(j,Z2r),e(j,g4),e(g4,G1e),e(G1e,ebr),e(g4,obr),e(g4,LH),e(LH,rbr),e(g4,tbr),e(j,abr),e(j,h4),e(h4,O1e),e(O1e,nbr),e(h4,sbr),e(h4,yH),e(yH,lbr),e(h4,ibr),e(j,dbr),e(j,u4),e(u4,V1e),e(V1e,cbr),e(u4,mbr),e(u4,xH),e(xH,fbr),e(u4,gbr),e(j,hbr),e(j,p4),e(p4,X1e),e(X1e,ubr),e(p4,pbr),e(p4,$H),e($H,_br),e(p4,bbr),e(j,vbr),e(j,_4),e(_4,z1e),e(z1e,Fbr),e(_4,Tbr),e(_4,kH),e(kH,Mbr),e(_4,Ebr),e(j,Cbr),e(j,b4),e(b4,Q1e),e(Q1e,wbr),e(b4,Abr),e(b4,SH),e(SH,Lbr),e(b4,ybr),e(j,xbr),e(j,v4),e(v4,W1e),e(W1e,$br),e(v4,kbr),e(v4,RH),e(RH,Sbr),e(v4,Rbr),e(j,Pbr),e(j,F4),e(F4,H1e),e(H1e,Bbr),e(F4,Ibr),e(F4,PH),e(PH,Nbr),e(F4,qbr),e(j,jbr),e(j,T4),e(T4,U1e),e(U1e,Dbr),e(T4,Gbr),e(T4,BH),e(BH,Obr),e(T4,Vbr),e(j,Xbr),e(j,M4),e(M4,J1e),e(J1e,zbr),e(M4,Qbr),e(M4,IH),e(IH,Wbr),e(M4,Hbr),e(j,Ubr),e(j,E4),e(E4,Y1e),e(Y1e,Jbr),e(E4,Ybr),e(E4,NH),e(NH,Kbr),e(E4,Zbr),e(j,evr),e(j,C4),e(C4,K1e),e(K1e,ovr),e(C4,rvr),e(C4,qH),e(qH,tvr),e(C4,avr),e(j,nvr),e(j,w4),e(w4,Z1e),e(Z1e,svr),e(w4,lvr),e(w4,jH),e(jH,ivr),e(w4,dvr),e(j,cvr),e(j,A4),e(A4,eTe),e(eTe,mvr),e(A4,fvr),e(A4,DH),e(DH,gvr),e(A4,hvr),e(j,uvr),e(j,L4),e(L4,oTe),e(oTe,pvr),e(L4,_vr),e(L4,GH),e(GH,bvr),e(L4,vvr),e(j,Fvr),e(j,y4),e(y4,rTe),e(rTe,Tvr),e(y4,Mvr),e(y4,OH),e(OH,Evr),e(y4,Cvr),e(j,wvr),e(j,x4),e(x4,tTe),e(tTe,Avr),e(x4,Lvr),e(x4,VH),e(VH,yvr),e(x4,xvr),e(j,$vr),e(j,$4),e($4,aTe),e(aTe,kvr),e($4,Svr),e($4,XH),e(XH,Rvr),e($4,Pvr),e(j,Bvr),e(j,k4),e(k4,nTe),e(nTe,Ivr),e(k4,Nvr),e(k4,zH),e(zH,qvr),e(k4,jvr),e(j,Dvr),e(j,S4),e(S4,sTe),e(sTe,Gvr),e(S4,Ovr),e(S4,QH),e(QH,Vvr),e(S4,Xvr),e(j,zvr),e(j,R4),e(R4,lTe),e(lTe,Qvr),e(R4,Wvr),e(R4,WH),e(WH,Hvr),e(R4,Uvr),e(j,Jvr),e(j,P4),e(P4,iTe),e(iTe,Yvr),e(P4,Kvr),e(P4,HH),e(HH,Zvr),e(P4,eFr),e(j,oFr),e(j,B4),e(B4,dTe),e(dTe,rFr),e(B4,tFr),e(B4,UH),e(UH,aFr),e(B4,nFr),e(j,sFr),e(j,I4),e(I4,cTe),e(cTe,lFr),e(I4,iFr),e(I4,JH),e(JH,dFr),e(I4,cFr),e(j,mFr),e(j,N4),e(N4,mTe),e(mTe,fFr),e(N4,gFr),e(N4,YH),e(YH,hFr),e(N4,uFr),e(j,pFr),e(j,q4),e(q4,fTe),e(fTe,_Fr),e(q4,bFr),e(q4,KH),e(KH,vFr),e(q4,FFr),e(yr,TFr),M(j4,yr,null),b(m,HOe,_),b(m,tc,_),e(tc,D4),e(D4,gTe),M(F9,gTe,null),e(tc,MFr),e(tc,hTe),e(hTe,EFr),b(m,UOe,_),b(m,or,_),M(T9,or,null),e(or,CFr),e(or,ac),e(ac,wFr),e(ac,ZH),e(ZH,AFr),e(ac,LFr),e(ac,eU),e(eU,yFr),e(ac,xFr),e(or,$Fr),e(or,M9),e(M9,kFr),e(M9,uTe),e(uTe,SFr),e(M9,RFr),e(or,PFr),e(or,kt),M(E9,kt,null),e(kt,BFr),e(kt,pTe),e(pTe,IFr),e(kt,NFr),e(kt,nc),e(nc,qFr),e(nc,_Te),e(_Te,jFr),e(nc,DFr),e(nc,oU),e(oU,GFr),e(nc,OFr),e(kt,VFr),M(G4,kt,null),e(or,XFr),e(or,xr),M(C9,xr,null),e(xr,zFr),e(xr,bTe),e(bTe,QFr),e(xr,WFr),e(xr,nn),e(nn,HFr),e(nn,vTe),e(vTe,UFr),e(nn,JFr),e(nn,FTe),e(FTe,YFr),e(nn,KFr),e(nn,TTe),e(TTe,ZFr),e(nn,e1r),e(xr,o1r),e(xr,se),e(se,O4),e(O4,MTe),e(MTe,r1r),e(O4,t1r),e(O4,rU),e(rU,a1r),e(O4,n1r),e(se,s1r),e(se,V4),e(V4,ETe),e(ETe,l1r),e(V4,i1r),e(V4,tU),e(tU,d1r),e(V4,c1r),e(se,m1r),e(se,X4),e(X4,CTe),e(CTe,f1r),e(X4,g1r),e(X4,aU),e(aU,h1r),e(X4,u1r),e(se,p1r),e(se,z4),e(z4,wTe),e(wTe,_1r),e(z4,b1r),e(z4,nU),e(nU,v1r),e(z4,F1r),e(se,T1r),e(se,Q4),e(Q4,ATe),e(ATe,M1r),e(Q4,E1r),e(Q4,sU),e(sU,C1r),e(Q4,w1r),e(se,A1r),e(se,W4),e(W4,LTe),e(LTe,L1r),e(W4,y1r),e(W4,lU),e(lU,x1r),e(W4,$1r),e(se,k1r),e(se,H4),e(H4,yTe),e(yTe,S1r),e(H4,R1r),e(H4,iU),e(iU,P1r),e(H4,B1r),e(se,I1r),e(se,U4),e(U4,xTe),e(xTe,N1r),e(U4,q1r),e(U4,dU),e(dU,j1r),e(U4,D1r),e(se,G1r),e(se,J4),e(J4,$Te),e($Te,O1r),e(J4,V1r),e(J4,cU),e(cU,X1r),e(J4,z1r),e(se,Q1r),e(se,Y4),e(Y4,kTe),e(kTe,W1r),e(Y4,H1r),e(Y4,mU),e(mU,U1r),e(Y4,J1r),e(se,Y1r),e(se,K4),e(K4,STe),e(STe,K1r),e(K4,Z1r),e(K4,fU),e(fU,eTr),e(K4,oTr),e(se,rTr),e(se,Z4),e(Z4,RTe),e(RTe,tTr),e(Z4,aTr),e(Z4,gU),e(gU,nTr),e(Z4,sTr),e(se,lTr),e(se,eC),e(eC,PTe),e(PTe,iTr),e(eC,dTr),e(eC,hU),e(hU,cTr),e(eC,mTr),e(se,fTr),e(se,oC),e(oC,BTe),e(BTe,gTr),e(oC,hTr),e(oC,uU),e(uU,uTr),e(oC,pTr),e(se,_Tr),e(se,rC),e(rC,ITe),e(ITe,bTr),e(rC,vTr),e(rC,pU),e(pU,FTr),e(rC,TTr),e(se,MTr),e(se,tC),e(tC,NTe),e(NTe,ETr),e(tC,CTr),e(tC,_U),e(_U,wTr),e(tC,ATr),e(se,LTr),e(se,aC),e(aC,qTe),e(qTe,yTr),e(aC,xTr),e(aC,bU),e(bU,$Tr),e(aC,kTr),e(se,STr),e(se,nC),e(nC,jTe),e(jTe,RTr),e(nC,PTr),e(nC,vU),e(vU,BTr),e(nC,ITr),e(se,NTr),e(se,sC),e(sC,DTe),e(DTe,qTr),e(sC,jTr),e(sC,FU),e(FU,DTr),e(sC,GTr),e(se,OTr),e(se,lC),e(lC,GTe),e(GTe,VTr),e(lC,XTr),e(lC,TU),e(TU,zTr),e(lC,QTr),e(se,WTr),e(se,iC),e(iC,OTe),e(OTe,HTr),e(iC,UTr),e(iC,MU),e(MU,JTr),e(iC,YTr),e(se,KTr),e(se,dC),e(dC,VTe),e(VTe,ZTr),e(dC,eMr),e(dC,EU),e(EU,oMr),e(dC,rMr),e(se,tMr),e(se,cC),e(cC,XTe),e(XTe,aMr),e(cC,nMr),e(cC,CU),e(CU,sMr),e(cC,lMr),e(xr,iMr),M(mC,xr,null),b(m,JOe,_),b(m,sc,_),e(sc,fC),e(fC,zTe),M(w9,zTe,null),e(sc,dMr),e(sc,QTe),e(QTe,cMr),b(m,YOe,_),b(m,rr,_),M(A9,rr,null),e(rr,mMr),e(rr,lc),e(lc,fMr),e(lc,wU),e(wU,gMr),e(lc,hMr),e(lc,AU),e(AU,uMr),e(lc,pMr),e(rr,_Mr),e(rr,L9),e(L9,bMr),e(L9,WTe),e(WTe,vMr),e(L9,FMr),e(rr,TMr),e(rr,St),M(y9,St,null),e(St,MMr),e(St,HTe),e(HTe,EMr),e(St,CMr),e(St,ic),e(ic,wMr),e(ic,UTe),e(UTe,AMr),e(ic,LMr),e(ic,LU),e(LU,yMr),e(ic,xMr),e(St,$Mr),M(gC,St,null),e(rr,kMr),e(rr,$r),M(x9,$r,null),e($r,SMr),e($r,JTe),e(JTe,RMr),e($r,PMr),e($r,sn),e(sn,BMr),e(sn,YTe),e(YTe,IMr),e(sn,NMr),e(sn,KTe),e(KTe,qMr),e(sn,jMr),e(sn,ZTe),e(ZTe,DMr),e(sn,GMr),e($r,OMr),e($r,Me),e(Me,hC),e(hC,eMe),e(eMe,VMr),e(hC,XMr),e(hC,yU),e(yU,zMr),e(hC,QMr),e(Me,WMr),e(Me,uC),e(uC,oMe),e(oMe,HMr),e(uC,UMr),e(uC,xU),e(xU,JMr),e(uC,YMr),e(Me,KMr),e(Me,pC),e(pC,rMe),e(rMe,ZMr),e(pC,eEr),e(pC,$U),e($U,oEr),e(pC,rEr),e(Me,tEr),e(Me,_C),e(_C,tMe),e(tMe,aEr),e(_C,nEr),e(_C,kU),e(kU,sEr),e(_C,lEr),e(Me,iEr),e(Me,bC),e(bC,aMe),e(aMe,dEr),e(bC,cEr),e(bC,SU),e(SU,mEr),e(bC,fEr),e(Me,gEr),e(Me,vC),e(vC,nMe),e(nMe,hEr),e(vC,uEr),e(vC,RU),e(RU,pEr),e(vC,_Er),e(Me,bEr),e(Me,FC),e(FC,sMe),e(sMe,vEr),e(FC,FEr),e(FC,PU),e(PU,TEr),e(FC,MEr),e(Me,EEr),e(Me,TC),e(TC,lMe),e(lMe,CEr),e(TC,wEr),e(TC,BU),e(BU,AEr),e(TC,LEr),e(Me,yEr),e(Me,MC),e(MC,iMe),e(iMe,xEr),e(MC,$Er),e(MC,IU),e(IU,kEr),e(MC,SEr),e(Me,REr),e(Me,EC),e(EC,dMe),e(dMe,PEr),e(EC,BEr),e(EC,NU),e(NU,IEr),e(EC,NEr),e(Me,qEr),e(Me,CC),e(CC,cMe),e(cMe,jEr),e(CC,DEr),e(CC,qU),e(qU,GEr),e(CC,OEr),e(Me,VEr),e(Me,wC),e(wC,mMe),e(mMe,XEr),e(wC,zEr),e(wC,jU),e(jU,QEr),e(wC,WEr),e(Me,HEr),e(Me,AC),e(AC,fMe),e(fMe,UEr),e(AC,JEr),e(AC,DU),e(DU,YEr),e(AC,KEr),e($r,ZEr),M(LC,$r,null),b(m,KOe,_),b(m,dc,_),e(dc,yC),e(yC,gMe),M($9,gMe,null),e(dc,e4r),e(dc,hMe),e(hMe,o4r),b(m,ZOe,_),b(m,tr,_),M(k9,tr,null),e(tr,r4r),e(tr,cc),e(cc,t4r),e(cc,GU),e(GU,a4r),e(cc,n4r),e(cc,OU),e(OU,s4r),e(cc,l4r),e(tr,i4r),e(tr,S9),e(S9,d4r),e(S9,uMe),e(uMe,c4r),e(S9,m4r),e(tr,f4r),e(tr,Rt),M(R9,Rt,null),e(Rt,g4r),e(Rt,pMe),e(pMe,h4r),e(Rt,u4r),e(Rt,mc),e(mc,p4r),e(mc,_Me),e(_Me,_4r),e(mc,b4r),e(mc,VU),e(VU,v4r),e(mc,F4r),e(Rt,T4r),M(xC,Rt,null),e(tr,M4r),e(tr,kr),M(P9,kr,null),e(kr,E4r),e(kr,bMe),e(bMe,C4r),e(kr,w4r),e(kr,ln),e(ln,A4r),e(ln,vMe),e(vMe,L4r),e(ln,y4r),e(ln,FMe),e(FMe,x4r),e(ln,$4r),e(ln,TMe),e(TMe,k4r),e(ln,S4r),e(kr,R4r),e(kr,dn),e(dn,$C),e($C,MMe),e(MMe,P4r),e($C,B4r),e($C,XU),e(XU,I4r),e($C,N4r),e(dn,q4r),e(dn,kC),e(kC,EMe),e(EMe,j4r),e(kC,D4r),e(kC,zU),e(zU,G4r),e(kC,O4r),e(dn,V4r),e(dn,SC),e(SC,CMe),e(CMe,X4r),e(SC,z4r),e(SC,QU),e(QU,Q4r),e(SC,W4r),e(dn,H4r),e(dn,RC),e(RC,wMe),e(wMe,U4r),e(RC,J4r),e(RC,WU),e(WU,Y4r),e(RC,K4r),e(kr,Z4r),M(PC,kr,null),b(m,eVe,_),b(m,fc,_),e(fc,BC),e(BC,AMe),M(B9,AMe,null),e(fc,eCr),e(fc,LMe),e(LMe,oCr),b(m,oVe,_),b(m,ar,_),M(I9,ar,null),e(ar,rCr),e(ar,gc),e(gc,tCr),e(gc,HU),e(HU,aCr),e(gc,nCr),e(gc,UU),e(UU,sCr),e(gc,lCr),e(ar,iCr),e(ar,N9),e(N9,dCr),e(N9,yMe),e(yMe,cCr),e(N9,mCr),e(ar,fCr),e(ar,Pt),M(q9,Pt,null),e(Pt,gCr),e(Pt,xMe),e(xMe,hCr),e(Pt,uCr),e(Pt,hc),e(hc,pCr),e(hc,$Me),e($Me,_Cr),e(hc,bCr),e(hc,JU),e(JU,vCr),e(hc,FCr),e(Pt,TCr),M(IC,Pt,null),e(ar,MCr),e(ar,Sr),M(j9,Sr,null),e(Sr,ECr),e(Sr,kMe),e(kMe,CCr),e(Sr,wCr),e(Sr,cn),e(cn,ACr),e(cn,SMe),e(SMe,LCr),e(cn,yCr),e(cn,RMe),e(RMe,xCr),e(cn,$Cr),e(cn,PMe),e(PMe,kCr),e(cn,SCr),e(Sr,RCr),e(Sr,ie),e(ie,NC),e(NC,BMe),e(BMe,PCr),e(NC,BCr),e(NC,YU),e(YU,ICr),e(NC,NCr),e(ie,qCr),e(ie,qC),e(qC,IMe),e(IMe,jCr),e(qC,DCr),e(qC,KU),e(KU,GCr),e(qC,OCr),e(ie,VCr),e(ie,jC),e(jC,NMe),e(NMe,XCr),e(jC,zCr),e(jC,ZU),e(ZU,QCr),e(jC,WCr),e(ie,HCr),e(ie,DC),e(DC,qMe),e(qMe,UCr),e(DC,JCr),e(DC,eJ),e(eJ,YCr),e(DC,KCr),e(ie,ZCr),e(ie,GC),e(GC,jMe),e(jMe,e5r),e(GC,o5r),e(GC,oJ),e(oJ,r5r),e(GC,t5r),e(ie,a5r),e(ie,OC),e(OC,DMe),e(DMe,n5r),e(OC,s5r),e(OC,rJ),e(rJ,l5r),e(OC,i5r),e(ie,d5r),e(ie,VC),e(VC,GMe),e(GMe,c5r),e(VC,m5r),e(VC,tJ),e(tJ,f5r),e(VC,g5r),e(ie,h5r),e(ie,XC),e(XC,OMe),e(OMe,u5r),e(XC,p5r),e(XC,aJ),e(aJ,_5r),e(XC,b5r),e(ie,v5r),e(ie,zC),e(zC,VMe),e(VMe,F5r),e(zC,T5r),e(zC,nJ),e(nJ,M5r),e(zC,E5r),e(ie,C5r),e(ie,QC),e(QC,XMe),e(XMe,w5r),e(QC,A5r),e(QC,sJ),e(sJ,L5r),e(QC,y5r),e(ie,x5r),e(ie,WC),e(WC,zMe),e(zMe,$5r),e(WC,k5r),e(WC,lJ),e(lJ,S5r),e(WC,R5r),e(ie,P5r),e(ie,HC),e(HC,QMe),e(QMe,B5r),e(HC,I5r),e(HC,iJ),e(iJ,N5r),e(HC,q5r),e(ie,j5r),e(ie,UC),e(UC,WMe),e(WMe,D5r),e(UC,G5r),e(UC,dJ),e(dJ,O5r),e(UC,V5r),e(ie,X5r),e(ie,JC),e(JC,HMe),e(HMe,z5r),e(JC,Q5r),e(JC,cJ),e(cJ,W5r),e(JC,H5r),e(ie,U5r),e(ie,YC),e(YC,UMe),e(UMe,J5r),e(YC,Y5r),e(YC,mJ),e(mJ,K5r),e(YC,Z5r),e(ie,e3r),e(ie,KC),e(KC,JMe),e(JMe,o3r),e(KC,r3r),e(KC,fJ),e(fJ,t3r),e(KC,a3r),e(ie,n3r),e(ie,ZC),e(ZC,YMe),e(YMe,s3r),e(ZC,l3r),e(ZC,gJ),e(gJ,i3r),e(ZC,d3r),e(ie,c3r),e(ie,e5),e(e5,KMe),e(KMe,m3r),e(e5,f3r),e(e5,hJ),e(hJ,g3r),e(e5,h3r),e(ie,u3r),e(ie,o5),e(o5,ZMe),e(ZMe,p3r),e(o5,_3r),e(o5,uJ),e(uJ,b3r),e(o5,v3r),e(ie,F3r),e(ie,r5),e(r5,eEe),e(eEe,T3r),e(r5,M3r),e(r5,pJ),e(pJ,E3r),e(r5,C3r),e(Sr,w3r),M(t5,Sr,null),b(m,rVe,_),b(m,uc,_),e(uc,a5),e(a5,oEe),M(D9,oEe,null),e(uc,A3r),e(uc,rEe),e(rEe,L3r),b(m,tVe,_),b(m,nr,_),M(G9,nr,null),e(nr,y3r),e(nr,pc),e(pc,x3r),e(pc,_J),e(_J,$3r),e(pc,k3r),e(pc,bJ),e(bJ,S3r),e(pc,R3r),e(nr,P3r),e(nr,O9),e(O9,B3r),e(O9,tEe),e(tEe,I3r),e(O9,N3r),e(nr,q3r),e(nr,Bt),M(V9,Bt,null),e(Bt,j3r),e(Bt,aEe),e(aEe,D3r),e(Bt,G3r),e(Bt,_c),e(_c,O3r),e(_c,nEe),e(nEe,V3r),e(_c,X3r),e(_c,vJ),e(vJ,z3r),e(_c,Q3r),e(Bt,W3r),M(n5,Bt,null),e(nr,H3r),e(nr,Rr),M(X9,Rr,null),e(Rr,U3r),e(Rr,sEe),e(sEe,J3r),e(Rr,Y3r),e(Rr,mn),e(mn,K3r),e(mn,lEe),e(lEe,Z3r),e(mn,e0r),e(mn,iEe),e(iEe,o0r),e(mn,r0r),e(mn,dEe),e(dEe,t0r),e(mn,a0r),e(Rr,n0r),e(Rr,ye),e(ye,s5),e(s5,cEe),e(cEe,s0r),e(s5,l0r),e(s5,FJ),e(FJ,i0r),e(s5,d0r),e(ye,c0r),e(ye,l5),e(l5,mEe),e(mEe,m0r),e(l5,f0r),e(l5,TJ),e(TJ,g0r),e(l5,h0r),e(ye,u0r),e(ye,i5),e(i5,fEe),e(fEe,p0r),e(i5,_0r),e(i5,MJ),e(MJ,b0r),e(i5,v0r),e(ye,F0r),e(ye,d5),e(d5,gEe),e(gEe,T0r),e(d5,M0r),e(d5,EJ),e(EJ,E0r),e(d5,C0r),e(ye,w0r),e(ye,c5),e(c5,hEe),e(hEe,A0r),e(c5,L0r),e(c5,CJ),e(CJ,y0r),e(c5,x0r),e(ye,$0r),e(ye,m5),e(m5,uEe),e(uEe,k0r),e(m5,S0r),e(m5,wJ),e(wJ,R0r),e(m5,P0r),e(ye,B0r),e(ye,f5),e(f5,pEe),e(pEe,I0r),e(f5,N0r),e(f5,AJ),e(AJ,q0r),e(f5,j0r),e(ye,D0r),e(ye,g5),e(g5,_Ee),e(_Ee,G0r),e(g5,O0r),e(g5,LJ),e(LJ,V0r),e(g5,X0r),e(ye,z0r),e(ye,h5),e(h5,bEe),e(bEe,Q0r),e(h5,W0r),e(h5,yJ),e(yJ,H0r),e(h5,U0r),e(ye,J0r),e(ye,u5),e(u5,vEe),e(vEe,Y0r),e(u5,K0r),e(u5,xJ),e(xJ,Z0r),e(u5,ewr),e(Rr,owr),M(p5,Rr,null),b(m,aVe,_),b(m,bc,_),e(bc,_5),e(_5,FEe),M(z9,FEe,null),e(bc,rwr),e(bc,TEe),e(TEe,twr),b(m,nVe,_),b(m,sr,_),M(Q9,sr,null),e(sr,awr),e(sr,vc),e(vc,nwr),e(vc,$J),e($J,swr),e(vc,lwr),e(vc,kJ),e(kJ,iwr),e(vc,dwr),e(sr,cwr),e(sr,W9),e(W9,mwr),e(W9,MEe),e(MEe,fwr),e(W9,gwr),e(sr,hwr),e(sr,It),M(H9,It,null),e(It,uwr),e(It,EEe),e(EEe,pwr),e(It,_wr),e(It,Fc),e(Fc,bwr),e(Fc,CEe),e(CEe,vwr),e(Fc,Fwr),e(Fc,SJ),e(SJ,Twr),e(Fc,Mwr),e(It,Ewr),M(b5,It,null),e(sr,Cwr),e(sr,Pr),M(U9,Pr,null),e(Pr,wwr),e(Pr,wEe),e(wEe,Awr),e(Pr,Lwr),e(Pr,fn),e(fn,ywr),e(fn,AEe),e(AEe,xwr),e(fn,$wr),e(fn,LEe),e(LEe,kwr),e(fn,Swr),e(fn,yEe),e(yEe,Rwr),e(fn,Pwr),e(Pr,Bwr),e(Pr,te),e(te,v5),e(v5,xEe),e(xEe,Iwr),e(v5,Nwr),e(v5,RJ),e(RJ,qwr),e(v5,jwr),e(te,Dwr),e(te,F5),e(F5,$Ee),e($Ee,Gwr),e(F5,Owr),e(F5,PJ),e(PJ,Vwr),e(F5,Xwr),e(te,zwr),e(te,T5),e(T5,kEe),e(kEe,Qwr),e(T5,Wwr),e(T5,BJ),e(BJ,Hwr),e(T5,Uwr),e(te,Jwr),e(te,M5),e(M5,SEe),e(SEe,Ywr),e(M5,Kwr),e(M5,IJ),e(IJ,Zwr),e(M5,eAr),e(te,oAr),e(te,E5),e(E5,REe),e(REe,rAr),e(E5,tAr),e(E5,NJ),e(NJ,aAr),e(E5,nAr),e(te,sAr),e(te,C5),e(C5,PEe),e(PEe,lAr),e(C5,iAr),e(C5,qJ),e(qJ,dAr),e(C5,cAr),e(te,mAr),e(te,w5),e(w5,BEe),e(BEe,fAr),e(w5,gAr),e(w5,jJ),e(jJ,hAr),e(w5,uAr),e(te,pAr),e(te,A5),e(A5,IEe),e(IEe,_Ar),e(A5,bAr),e(A5,DJ),e(DJ,vAr),e(A5,FAr),e(te,TAr),e(te,L5),e(L5,NEe),e(NEe,MAr),e(L5,EAr),e(L5,GJ),e(GJ,CAr),e(L5,wAr),e(te,AAr),e(te,y5),e(y5,qEe),e(qEe,LAr),e(y5,yAr),e(y5,OJ),e(OJ,xAr),e(y5,$Ar),e(te,kAr),e(te,x5),e(x5,jEe),e(jEe,SAr),e(x5,RAr),e(x5,VJ),e(VJ,PAr),e(x5,BAr),e(te,IAr),e(te,$5),e($5,DEe),e(DEe,NAr),e($5,qAr),e($5,XJ),e(XJ,jAr),e($5,DAr),e(te,GAr),e(te,k5),e(k5,GEe),e(GEe,OAr),e(k5,VAr),e(k5,zJ),e(zJ,XAr),e(k5,zAr),e(te,QAr),e(te,S5),e(S5,OEe),e(OEe,WAr),e(S5,HAr),e(S5,QJ),e(QJ,UAr),e(S5,JAr),e(te,YAr),e(te,R5),e(R5,VEe),e(VEe,KAr),e(R5,ZAr),e(R5,WJ),e(WJ,e6r),e(R5,o6r),e(te,r6r),e(te,P5),e(P5,XEe),e(XEe,t6r),e(P5,a6r),e(P5,HJ),e(HJ,n6r),e(P5,s6r),e(te,l6r),e(te,B5),e(B5,zEe),e(zEe,i6r),e(B5,d6r),e(B5,UJ),e(UJ,c6r),e(B5,m6r),e(te,f6r),e(te,I5),e(I5,QEe),e(QEe,g6r),e(I5,h6r),e(I5,JJ),e(JJ,u6r),e(I5,p6r),e(te,_6r),e(te,N5),e(N5,WEe),e(WEe,b6r),e(N5,v6r),e(N5,YJ),e(YJ,F6r),e(N5,T6r),e(te,M6r),e(te,q5),e(q5,HEe),e(HEe,E6r),e(q5,C6r),e(q5,KJ),e(KJ,w6r),e(q5,A6r),e(te,L6r),e(te,j5),e(j5,UEe),e(UEe,y6r),e(j5,x6r),e(j5,ZJ),e(ZJ,$6r),e(j5,k6r),e(te,S6r),e(te,D5),e(D5,JEe),e(JEe,R6r),e(D5,P6r),e(D5,eY),e(eY,B6r),e(D5,I6r),e(te,N6r),e(te,G5),e(G5,YEe),e(YEe,q6r),e(G5,j6r),e(G5,oY),e(oY,D6r),e(G5,G6r),e(te,O6r),e(te,O5),e(O5,KEe),e(KEe,V6r),e(O5,X6r),e(O5,rY),e(rY,z6r),e(O5,Q6r),e(te,W6r),e(te,V5),e(V5,ZEe),e(ZEe,H6r),e(V5,U6r),e(V5,tY),e(tY,J6r),e(V5,Y6r),e(te,K6r),e(te,X5),e(X5,e4e),e(e4e,Z6r),e(X5,eLr),e(X5,aY),e(aY,oLr),e(X5,rLr),e(Pr,tLr),M(z5,Pr,null),b(m,sVe,_),b(m,Tc,_),e(Tc,Q5),e(Q5,o4e),M(J9,o4e,null),e(Tc,aLr),e(Tc,r4e),e(r4e,nLr),b(m,lVe,_),b(m,lr,_),M(Y9,lr,null),e(lr,sLr),e(lr,Mc),e(Mc,lLr),e(Mc,nY),e(nY,iLr),e(Mc,dLr),e(Mc,sY),e(sY,cLr),e(Mc,mLr),e(lr,fLr),e(lr,K9),e(K9,gLr),e(K9,t4e),e(t4e,hLr),e(K9,uLr),e(lr,pLr),e(lr,Nt),M(Z9,Nt,null),e(Nt,_Lr),e(Nt,a4e),e(a4e,bLr),e(Nt,vLr),e(Nt,Ec),e(Ec,FLr),e(Ec,n4e),e(n4e,TLr),e(Ec,MLr),e(Ec,lY),e(lY,ELr),e(Ec,CLr),e(Nt,wLr),M(W5,Nt,null),e(lr,ALr),e(lr,Br),M(ex,Br,null),e(Br,LLr),e(Br,s4e),e(s4e,yLr),e(Br,xLr),e(Br,gn),e(gn,$Lr),e(gn,l4e),e(l4e,kLr),e(gn,SLr),e(gn,i4e),e(i4e,RLr),e(gn,PLr),e(gn,d4e),e(d4e,BLr),e(gn,ILr),e(Br,NLr),e(Br,pe),e(pe,H5),e(H5,c4e),e(c4e,qLr),e(H5,jLr),e(H5,iY),e(iY,DLr),e(H5,GLr),e(pe,OLr),e(pe,U5),e(U5,m4e),e(m4e,VLr),e(U5,XLr),e(U5,dY),e(dY,zLr),e(U5,QLr),e(pe,WLr),e(pe,J5),e(J5,f4e),e(f4e,HLr),e(J5,ULr),e(J5,cY),e(cY,JLr),e(J5,YLr),e(pe,KLr),e(pe,Y5),e(Y5,g4e),e(g4e,ZLr),e(Y5,eyr),e(Y5,mY),e(mY,oyr),e(Y5,ryr),e(pe,tyr),e(pe,K5),e(K5,h4e),e(h4e,ayr),e(K5,nyr),e(K5,fY),e(fY,syr),e(K5,lyr),e(pe,iyr),e(pe,Z5),e(Z5,u4e),e(u4e,dyr),e(Z5,cyr),e(Z5,gY),e(gY,myr),e(Z5,fyr),e(pe,gyr),e(pe,e3),e(e3,p4e),e(p4e,hyr),e(e3,uyr),e(e3,hY),e(hY,pyr),e(e3,_yr),e(pe,byr),e(pe,o3),e(o3,_4e),e(_4e,vyr),e(o3,Fyr),e(o3,uY),e(uY,Tyr),e(o3,Myr),e(pe,Eyr),e(pe,r3),e(r3,b4e),e(b4e,Cyr),e(r3,wyr),e(r3,pY),e(pY,Ayr),e(r3,Lyr),e(pe,yyr),e(pe,t3),e(t3,v4e),e(v4e,xyr),e(t3,$yr),e(t3,_Y),e(_Y,kyr),e(t3,Syr),e(pe,Ryr),e(pe,a3),e(a3,F4e),e(F4e,Pyr),e(a3,Byr),e(a3,bY),e(bY,Iyr),e(a3,Nyr),e(pe,qyr),e(pe,n3),e(n3,T4e),e(T4e,jyr),e(n3,Dyr),e(n3,vY),e(vY,Gyr),e(n3,Oyr),e(pe,Vyr),e(pe,s3),e(s3,M4e),e(M4e,Xyr),e(s3,zyr),e(s3,FY),e(FY,Qyr),e(s3,Wyr),e(pe,Hyr),e(pe,l3),e(l3,E4e),e(E4e,Uyr),e(l3,Jyr),e(l3,TY),e(TY,Yyr),e(l3,Kyr),e(pe,Zyr),e(pe,i3),e(i3,C4e),e(C4e,e7r),e(i3,o7r),e(i3,MY),e(MY,r7r),e(i3,t7r),e(pe,a7r),e(pe,d3),e(d3,w4e),e(w4e,n7r),e(d3,s7r),e(d3,EY),e(EY,l7r),e(d3,i7r),e(pe,d7r),e(pe,c3),e(c3,A4e),e(A4e,c7r),e(c3,m7r),e(c3,CY),e(CY,f7r),e(c3,g7r),e(Br,h7r),M(m3,Br,null),b(m,iVe,_),b(m,Cc,_),e(Cc,f3),e(f3,L4e),M(ox,L4e,null),e(Cc,u7r),e(Cc,y4e),e(y4e,p7r),b(m,dVe,_),b(m,ir,_),M(rx,ir,null),e(ir,_7r),e(ir,wc),e(wc,b7r),e(wc,wY),e(wY,v7r),e(wc,F7r),e(wc,AY),e(AY,T7r),e(wc,M7r),e(ir,E7r),e(ir,tx),e(tx,C7r),e(tx,x4e),e(x4e,w7r),e(tx,A7r),e(ir,L7r),e(ir,qt),M(ax,qt,null),e(qt,y7r),e(qt,$4e),e($4e,x7r),e(qt,$7r),e(qt,Ac),e(Ac,k7r),e(Ac,k4e),e(k4e,S7r),e(Ac,R7r),e(Ac,LY),e(LY,P7r),e(Ac,B7r),e(qt,I7r),M(g3,qt,null),e(ir,N7r),e(ir,Ir),M(nx,Ir,null),e(Ir,q7r),e(Ir,S4e),e(S4e,j7r),e(Ir,D7r),e(Ir,hn),e(hn,G7r),e(hn,R4e),e(R4e,O7r),e(hn,V7r),e(hn,P4e),e(P4e,X7r),e(hn,z7r),e(hn,B4e),e(B4e,Q7r),e(hn,W7r),e(Ir,H7r),e(Ir,sx),e(sx,h3),e(h3,I4e),e(I4e,U7r),e(h3,J7r),e(h3,yY),e(yY,Y7r),e(h3,K7r),e(sx,Z7r),e(sx,u3),e(u3,N4e),e(N4e,e8r),e(u3,o8r),e(u3,xY),e(xY,r8r),e(u3,t8r),e(Ir,a8r),M(p3,Ir,null),b(m,cVe,_),b(m,Lc,_),e(Lc,_3),e(_3,q4e),M(lx,q4e,null),e(Lc,n8r),e(Lc,j4e),e(j4e,s8r),b(m,mVe,_),b(m,dr,_),M(ix,dr,null),e(dr,l8r),e(dr,yc),e(yc,i8r),e(yc,$Y),e($Y,d8r),e(yc,c8r),e(yc,kY),e(kY,m8r),e(yc,f8r),e(dr,g8r),e(dr,dx),e(dx,h8r),e(dx,D4e),e(D4e,u8r),e(dx,p8r),e(dr,_8r),e(dr,jt),M(cx,jt,null),e(jt,b8r),e(jt,G4e),e(G4e,v8r),e(jt,F8r),e(jt,xc),e(xc,T8r),e(xc,O4e),e(O4e,M8r),e(xc,E8r),e(xc,SY),e(SY,C8r),e(xc,w8r),e(jt,A8r),M(b3,jt,null),e(dr,L8r),e(dr,Nr),M(mx,Nr,null),e(Nr,y8r),e(Nr,V4e),e(V4e,x8r),e(Nr,$8r),e(Nr,un),e(un,k8r),e(un,X4e),e(X4e,S8r),e(un,R8r),e(un,z4e),e(z4e,P8r),e(un,B8r),e(un,Q4e),e(Q4e,I8r),e(un,N8r),e(Nr,q8r),e(Nr,W4e),e(W4e,v3),e(v3,H4e),e(H4e,j8r),e(v3,D8r),e(v3,RY),e(RY,G8r),e(v3,O8r),e(Nr,V8r),M(F3,Nr,null),b(m,fVe,_),b(m,$c,_),e($c,T3),e(T3,U4e),M(fx,U4e,null),e($c,X8r),e($c,J4e),e(J4e,z8r),b(m,gVe,_),b(m,cr,_),M(gx,cr,null),e(cr,Q8r),e(cr,kc),e(kc,W8r),e(kc,PY),e(PY,H8r),e(kc,U8r),e(kc,BY),e(BY,J8r),e(kc,Y8r),e(cr,K8r),e(cr,hx),e(hx,Z8r),e(hx,Y4e),e(Y4e,e9r),e(hx,o9r),e(cr,r9r),e(cr,Dt),M(ux,Dt,null),e(Dt,t9r),e(Dt,K4e),e(K4e,a9r),e(Dt,n9r),e(Dt,Sc),e(Sc,s9r),e(Sc,Z4e),e(Z4e,l9r),e(Sc,i9r),e(Sc,IY),e(IY,d9r),e(Sc,c9r),e(Dt,m9r),M(M3,Dt,null),e(cr,f9r),e(cr,qr),M(px,qr,null),e(qr,g9r),e(qr,eCe),e(eCe,h9r),e(qr,u9r),e(qr,pn),e(pn,p9r),e(pn,oCe),e(oCe,_9r),e(pn,b9r),e(pn,rCe),e(rCe,v9r),e(pn,F9r),e(pn,tCe),e(tCe,T9r),e(pn,M9r),e(qr,E9r),e(qr,de),e(de,E3),e(E3,aCe),e(aCe,C9r),e(E3,w9r),e(E3,NY),e(NY,A9r),e(E3,L9r),e(de,y9r),e(de,C3),e(C3,nCe),e(nCe,x9r),e(C3,$9r),e(C3,qY),e(qY,k9r),e(C3,S9r),e(de,R9r),e(de,w3),e(w3,sCe),e(sCe,P9r),e(w3,B9r),e(w3,jY),e(jY,I9r),e(w3,N9r),e(de,q9r),e(de,A3),e(A3,lCe),e(lCe,j9r),e(A3,D9r),e(A3,DY),e(DY,G9r),e(A3,O9r),e(de,V9r),e(de,L3),e(L3,iCe),e(iCe,X9r),e(L3,z9r),e(L3,GY),e(GY,Q9r),e(L3,W9r),e(de,H9r),e(de,y3),e(y3,dCe),e(dCe,U9r),e(y3,J9r),e(y3,OY),e(OY,Y9r),e(y3,K9r),e(de,Z9r),e(de,x3),e(x3,cCe),e(cCe,exr),e(x3,oxr),e(x3,VY),e(VY,rxr),e(x3,txr),e(de,axr),e(de,$3),e($3,mCe),e(mCe,nxr),e($3,sxr),e($3,XY),e(XY,lxr),e($3,ixr),e(de,dxr),e(de,k3),e(k3,fCe),e(fCe,cxr),e(k3,mxr),e(k3,zY),e(zY,fxr),e(k3,gxr),e(de,hxr),e(de,S3),e(S3,gCe),e(gCe,uxr),e(S3,pxr),e(S3,QY),e(QY,_xr),e(S3,bxr),e(de,vxr),e(de,R3),e(R3,hCe),e(hCe,Fxr),e(R3,Txr),e(R3,WY),e(WY,Mxr),e(R3,Exr),e(de,Cxr),e(de,P3),e(P3,uCe),e(uCe,wxr),e(P3,Axr),e(P3,HY),e(HY,Lxr),e(P3,yxr),e(de,xxr),e(de,B3),e(B3,pCe),e(pCe,$xr),e(B3,kxr),e(B3,UY),e(UY,Sxr),e(B3,Rxr),e(de,Pxr),e(de,I3),e(I3,_Ce),e(_Ce,Bxr),e(I3,Ixr),e(I3,JY),e(JY,Nxr),e(I3,qxr),e(de,jxr),e(de,N3),e(N3,bCe),e(bCe,Dxr),e(N3,Gxr),e(N3,YY),e(YY,Oxr),e(N3,Vxr),e(de,Xxr),e(de,q3),e(q3,vCe),e(vCe,zxr),e(q3,Qxr),e(q3,KY),e(KY,Wxr),e(q3,Hxr),e(de,Uxr),e(de,j3),e(j3,FCe),e(FCe,Jxr),e(j3,Yxr),e(j3,ZY),e(ZY,Kxr),e(j3,Zxr),e(de,e$r),e(de,D3),e(D3,TCe),e(TCe,o$r),e(D3,r$r),e(D3,eK),e(eK,t$r),e(D3,a$r),e(de,n$r),e(de,G3),e(G3,MCe),e(MCe,s$r),e(G3,l$r),e(G3,oK),e(oK,i$r),e(G3,d$r),e(de,c$r),e(de,O3),e(O3,ECe),e(ECe,m$r),e(O3,f$r),e(O3,rK),e(rK,g$r),e(O3,h$r),e(qr,u$r),M(V3,qr,null),b(m,hVe,_),b(m,Rc,_),e(Rc,X3),e(X3,CCe),M(_x,CCe,null),e(Rc,p$r),e(Rc,wCe),e(wCe,_$r),b(m,uVe,_),b(m,mr,_),M(bx,mr,null),e(mr,b$r),e(mr,Pc),e(Pc,v$r),e(Pc,tK),e(tK,F$r),e(Pc,T$r),e(Pc,aK),e(aK,M$r),e(Pc,E$r),e(mr,C$r),e(mr,vx),e(vx,w$r),e(vx,ACe),e(ACe,A$r),e(vx,L$r),e(mr,y$r),e(mr,Gt),M(Fx,Gt,null),e(Gt,x$r),e(Gt,LCe),e(LCe,$$r),e(Gt,k$r),e(Gt,Bc),e(Bc,S$r),e(Bc,yCe),e(yCe,R$r),e(Bc,P$r),e(Bc,nK),e(nK,B$r),e(Bc,I$r),e(Gt,N$r),M(z3,Gt,null),e(mr,q$r),e(mr,jr),M(Tx,jr,null),e(jr,j$r),e(jr,xCe),e(xCe,D$r),e(jr,G$r),e(jr,_n),e(_n,O$r),e(_n,$Ce),e($Ce,V$r),e(_n,X$r),e(_n,kCe),e(kCe,z$r),e(_n,Q$r),e(_n,SCe),e(SCe,W$r),e(_n,H$r),e(jr,U$r),e(jr,ce),e(ce,Q3),e(Q3,RCe),e(RCe,J$r),e(Q3,Y$r),e(Q3,sK),e(sK,K$r),e(Q3,Z$r),e(ce,ekr),e(ce,W3),e(W3,PCe),e(PCe,okr),e(W3,rkr),e(W3,lK),e(lK,tkr),e(W3,akr),e(ce,nkr),e(ce,H3),e(H3,BCe),e(BCe,skr),e(H3,lkr),e(H3,iK),e(iK,ikr),e(H3,dkr),e(ce,ckr),e(ce,U3),e(U3,ICe),e(ICe,mkr),e(U3,fkr),e(U3,dK),e(dK,gkr),e(U3,hkr),e(ce,ukr),e(ce,J3),e(J3,NCe),e(NCe,pkr),e(J3,_kr),e(J3,cK),e(cK,bkr),e(J3,vkr),e(ce,Fkr),e(ce,Y3),e(Y3,qCe),e(qCe,Tkr),e(Y3,Mkr),e(Y3,mK),e(mK,Ekr),e(Y3,Ckr),e(ce,wkr),e(ce,K3),e(K3,jCe),e(jCe,Akr),e(K3,Lkr),e(K3,fK),e(fK,ykr),e(K3,xkr),e(ce,$kr),e(ce,Z3),e(Z3,DCe),e(DCe,kkr),e(Z3,Skr),e(Z3,gK),e(gK,Rkr),e(Z3,Pkr),e(ce,Bkr),e(ce,e0),e(e0,GCe),e(GCe,Ikr),e(e0,Nkr),e(e0,hK),e(hK,qkr),e(e0,jkr),e(ce,Dkr),e(ce,o0),e(o0,OCe),e(OCe,Gkr),e(o0,Okr),e(o0,uK),e(uK,Vkr),e(o0,Xkr),e(ce,zkr),e(ce,r0),e(r0,VCe),e(VCe,Qkr),e(r0,Wkr),e(r0,pK),e(pK,Hkr),e(r0,Ukr),e(ce,Jkr),e(ce,t0),e(t0,XCe),e(XCe,Ykr),e(t0,Kkr),e(t0,_K),e(_K,Zkr),e(t0,eSr),e(ce,oSr),e(ce,a0),e(a0,zCe),e(zCe,rSr),e(a0,tSr),e(a0,bK),e(bK,aSr),e(a0,nSr),e(ce,sSr),e(ce,n0),e(n0,QCe),e(QCe,lSr),e(n0,iSr),e(n0,vK),e(vK,dSr),e(n0,cSr),e(ce,mSr),e(ce,s0),e(s0,WCe),e(WCe,fSr),e(s0,gSr),e(s0,FK),e(FK,hSr),e(s0,uSr),e(ce,pSr),e(ce,l0),e(l0,HCe),e(HCe,_Sr),e(l0,bSr),e(l0,TK),e(TK,vSr),e(l0,FSr),e(ce,TSr),e(ce,i0),e(i0,UCe),e(UCe,MSr),e(i0,ESr),e(i0,MK),e(MK,CSr),e(i0,wSr),e(ce,ASr),e(ce,d0),e(d0,JCe),e(JCe,LSr),e(d0,ySr),e(d0,EK),e(EK,xSr),e(d0,$Sr),e(ce,kSr),e(ce,c0),e(c0,YCe),e(YCe,SSr),e(c0,RSr),e(c0,CK),e(CK,PSr),e(c0,BSr),e(ce,ISr),e(ce,m0),e(m0,KCe),e(KCe,NSr),e(m0,qSr),e(m0,wK),e(wK,jSr),e(m0,DSr),e(jr,GSr),M(f0,jr,null),b(m,pVe,_),b(m,Ic,_),e(Ic,g0),e(g0,ZCe),M(Mx,ZCe,null),e(Ic,OSr),e(Ic,e5e),e(e5e,VSr),b(m,_Ve,_),b(m,fr,_),M(Ex,fr,null),e(fr,XSr),e(fr,Nc),e(Nc,zSr),e(Nc,AK),e(AK,QSr),e(Nc,WSr),e(Nc,LK),e(LK,HSr),e(Nc,USr),e(fr,JSr),e(fr,Cx),e(Cx,YSr),e(Cx,o5e),e(o5e,KSr),e(Cx,ZSr),e(fr,eRr),e(fr,Ot),M(wx,Ot,null),e(Ot,oRr),e(Ot,r5e),e(r5e,rRr),e(Ot,tRr),e(Ot,qc),e(qc,aRr),e(qc,t5e),e(t5e,nRr),e(qc,sRr),e(qc,yK),e(yK,lRr),e(qc,iRr),e(Ot,dRr),M(h0,Ot,null),e(fr,cRr),e(fr,Dr),M(Ax,Dr,null),e(Dr,mRr),e(Dr,a5e),e(a5e,fRr),e(Dr,gRr),e(Dr,bn),e(bn,hRr),e(bn,n5e),e(n5e,uRr),e(bn,pRr),e(bn,s5e),e(s5e,_Rr),e(bn,bRr),e(bn,l5e),e(l5e,vRr),e(bn,FRr),e(Dr,TRr),e(Dr,i5e),e(i5e,u0),e(u0,d5e),e(d5e,MRr),e(u0,ERr),e(u0,xK),e(xK,CRr),e(u0,wRr),e(Dr,ARr),M(p0,Dr,null),b(m,bVe,_),b(m,jc,_),e(jc,_0),e(_0,c5e),M(Lx,c5e,null),e(jc,LRr),e(jc,m5e),e(m5e,yRr),b(m,vVe,_),b(m,gr,_),M(yx,gr,null),e(gr,xRr),e(gr,Dc),e(Dc,$Rr),e(Dc,$K),e($K,kRr),e(Dc,SRr),e(Dc,kK),e(kK,RRr),e(Dc,PRr),e(gr,BRr),e(gr,xx),e(xx,IRr),e(xx,f5e),e(f5e,NRr),e(xx,qRr),e(gr,jRr),e(gr,Vt),M($x,Vt,null),e(Vt,DRr),e(Vt,g5e),e(g5e,GRr),e(Vt,ORr),e(Vt,Gc),e(Gc,VRr),e(Gc,h5e),e(h5e,XRr),e(Gc,zRr),e(Gc,SK),e(SK,QRr),e(Gc,WRr),e(Vt,HRr),M(b0,Vt,null),e(gr,URr),e(gr,Gr),M(kx,Gr,null),e(Gr,JRr),e(Gr,u5e),e(u5e,YRr),e(Gr,KRr),e(Gr,vn),e(vn,ZRr),e(vn,p5e),e(p5e,ePr),e(vn,oPr),e(vn,_5e),e(_5e,rPr),e(vn,tPr),e(vn,b5e),e(b5e,aPr),e(vn,nPr),e(Gr,sPr),e(Gr,v5e),e(v5e,v0),e(v0,F5e),e(F5e,lPr),e(v0,iPr),e(v0,RK),e(RK,dPr),e(v0,cPr),e(Gr,mPr),M(F0,Gr,null),b(m,FVe,_),b(m,Oc,_),e(Oc,T0),e(T0,T5e),M(Sx,T5e,null),e(Oc,fPr),e(Oc,M5e),e(M5e,gPr),b(m,TVe,_),b(m,hr,_),M(Rx,hr,null),e(hr,hPr),e(hr,Vc),e(Vc,uPr),e(Vc,PK),e(PK,pPr),e(Vc,_Pr),e(Vc,BK),e(BK,bPr),e(Vc,vPr),e(hr,FPr),e(hr,Px),e(Px,TPr),e(Px,E5e),e(E5e,MPr),e(Px,EPr),e(hr,CPr),e(hr,Xt),M(Bx,Xt,null),e(Xt,wPr),e(Xt,C5e),e(C5e,APr),e(Xt,LPr),e(Xt,Xc),e(Xc,yPr),e(Xc,w5e),e(w5e,xPr),e(Xc,$Pr),e(Xc,IK),e(IK,kPr),e(Xc,SPr),e(Xt,RPr),M(M0,Xt,null),e(hr,PPr),e(hr,Or),M(Ix,Or,null),e(Or,BPr),e(Or,A5e),e(A5e,IPr),e(Or,NPr),e(Or,Fn),e(Fn,qPr),e(Fn,L5e),e(L5e,jPr),e(Fn,DPr),e(Fn,y5e),e(y5e,GPr),e(Fn,OPr),e(Fn,x5e),e(x5e,VPr),e(Fn,XPr),e(Or,zPr),e(Or,oe),e(oe,E0),e(E0,$5e),e($5e,QPr),e(E0,WPr),e(E0,NK),e(NK,HPr),e(E0,UPr),e(oe,JPr),e(oe,C0),e(C0,k5e),e(k5e,YPr),e(C0,KPr),e(C0,qK),e(qK,ZPr),e(C0,eBr),e(oe,oBr),e(oe,w0),e(w0,S5e),e(S5e,rBr),e(w0,tBr),e(w0,jK),e(jK,aBr),e(w0,nBr),e(oe,sBr),e(oe,A0),e(A0,R5e),e(R5e,lBr),e(A0,iBr),e(A0,DK),e(DK,dBr),e(A0,cBr),e(oe,mBr),e(oe,L0),e(L0,P5e),e(P5e,fBr),e(L0,gBr),e(L0,GK),e(GK,hBr),e(L0,uBr),e(oe,pBr),e(oe,y0),e(y0,B5e),e(B5e,_Br),e(y0,bBr),e(y0,OK),e(OK,vBr),e(y0,FBr),e(oe,TBr),e(oe,x0),e(x0,I5e),e(I5e,MBr),e(x0,EBr),e(x0,VK),e(VK,CBr),e(x0,wBr),e(oe,ABr),e(oe,$0),e($0,N5e),e(N5e,LBr),e($0,yBr),e($0,XK),e(XK,xBr),e($0,$Br),e(oe,kBr),e(oe,k0),e(k0,q5e),e(q5e,SBr),e(k0,RBr),e(k0,zK),e(zK,PBr),e(k0,BBr),e(oe,IBr),e(oe,S0),e(S0,j5e),e(j5e,NBr),e(S0,qBr),e(S0,QK),e(QK,jBr),e(S0,DBr),e(oe,GBr),e(oe,R0),e(R0,D5e),e(D5e,OBr),e(R0,VBr),e(R0,WK),e(WK,XBr),e(R0,zBr),e(oe,QBr),e(oe,P0),e(P0,G5e),e(G5e,WBr),e(P0,HBr),e(P0,HK),e(HK,UBr),e(P0,JBr),e(oe,YBr),e(oe,B0),e(B0,O5e),e(O5e,KBr),e(B0,ZBr),e(B0,UK),e(UK,eIr),e(B0,oIr),e(oe,rIr),e(oe,I0),e(I0,V5e),e(V5e,tIr),e(I0,aIr),e(I0,JK),e(JK,nIr),e(I0,sIr),e(oe,lIr),e(oe,N0),e(N0,X5e),e(X5e,iIr),e(N0,dIr),e(N0,YK),e(YK,cIr),e(N0,mIr),e(oe,fIr),e(oe,q0),e(q0,z5e),e(z5e,gIr),e(q0,hIr),e(q0,KK),e(KK,uIr),e(q0,pIr),e(oe,_Ir),e(oe,j0),e(j0,Q5e),e(Q5e,bIr),e(j0,vIr),e(j0,ZK),e(ZK,FIr),e(j0,TIr),e(oe,MIr),e(oe,D0),e(D0,W5e),e(W5e,EIr),e(D0,CIr),e(D0,eZ),e(eZ,wIr),e(D0,AIr),e(oe,LIr),e(oe,G0),e(G0,H5e),e(H5e,yIr),e(G0,xIr),e(G0,oZ),e(oZ,$Ir),e(G0,kIr),e(oe,SIr),e(oe,O0),e(O0,U5e),e(U5e,RIr),e(O0,PIr),e(O0,rZ),e(rZ,BIr),e(O0,IIr),e(oe,NIr),e(oe,V0),e(V0,J5e),e(J5e,qIr),e(V0,jIr),e(V0,tZ),e(tZ,DIr),e(V0,GIr),e(oe,OIr),e(oe,X0),e(X0,Y5e),e(Y5e,VIr),e(X0,XIr),e(X0,aZ),e(aZ,zIr),e(X0,QIr),e(oe,WIr),e(oe,z0),e(z0,K5e),e(K5e,HIr),e(z0,UIr),e(z0,nZ),e(nZ,JIr),e(z0,YIr),e(oe,KIr),e(oe,Q0),e(Q0,Z5e),e(Z5e,ZIr),e(Q0,eNr),e(Q0,sZ),e(sZ,oNr),e(Q0,rNr),e(oe,tNr),e(oe,W0),e(W0,e3e),e(e3e,aNr),e(W0,nNr),e(W0,lZ),e(lZ,sNr),e(W0,lNr),e(oe,iNr),e(oe,H0),e(H0,o3e),e(o3e,dNr),e(H0,cNr),e(H0,iZ),e(iZ,mNr),e(H0,fNr),e(oe,gNr),e(oe,U0),e(U0,r3e),e(r3e,hNr),e(U0,uNr),e(U0,dZ),e(dZ,pNr),e(U0,_Nr),e(Or,bNr),M(J0,Or,null),b(m,MVe,_),b(m,zc,_),e(zc,Y0),e(Y0,t3e),M(Nx,t3e,null),e(zc,vNr),e(zc,a3e),e(a3e,FNr),b(m,EVe,_),b(m,ur,_),M(qx,ur,null),e(ur,TNr),e(ur,Qc),e(Qc,MNr),e(Qc,cZ),e(cZ,ENr),e(Qc,CNr),e(Qc,mZ),e(mZ,wNr),e(Qc,ANr),e(ur,LNr),e(ur,jx),e(jx,yNr),e(jx,n3e),e(n3e,xNr),e(jx,$Nr),e(ur,kNr),e(ur,zt),M(Dx,zt,null),e(zt,SNr),e(zt,s3e),e(s3e,RNr),e(zt,PNr),e(zt,Wc),e(Wc,BNr),e(Wc,l3e),e(l3e,INr),e(Wc,NNr),e(Wc,fZ),e(fZ,qNr),e(Wc,jNr),e(zt,DNr),M(K0,zt,null),e(ur,GNr),e(ur,Vr),M(Gx,Vr,null),e(Vr,ONr),e(Vr,i3e),e(i3e,VNr),e(Vr,XNr),e(Vr,Tn),e(Tn,zNr),e(Tn,d3e),e(d3e,QNr),e(Tn,WNr),e(Tn,c3e),e(c3e,HNr),e(Tn,UNr),e(Tn,m3e),e(m3e,JNr),e(Tn,YNr),e(Vr,KNr),e(Vr,xe),e(xe,Z0),e(Z0,f3e),e(f3e,ZNr),e(Z0,eqr),e(Z0,gZ),e(gZ,oqr),e(Z0,rqr),e(xe,tqr),e(xe,ew),e(ew,g3e),e(g3e,aqr),e(ew,nqr),e(ew,hZ),e(hZ,sqr),e(ew,lqr),e(xe,iqr),e(xe,ow),e(ow,h3e),e(h3e,dqr),e(ow,cqr),e(ow,uZ),e(uZ,mqr),e(ow,fqr),e(xe,gqr),e(xe,rw),e(rw,u3e),e(u3e,hqr),e(rw,uqr),e(rw,pZ),e(pZ,pqr),e(rw,_qr),e(xe,bqr),e(xe,tw),e(tw,p3e),e(p3e,vqr),e(tw,Fqr),e(tw,_Z),e(_Z,Tqr),e(tw,Mqr),e(xe,Eqr),e(xe,aw),e(aw,_3e),e(_3e,Cqr),e(aw,wqr),e(aw,bZ),e(bZ,Aqr),e(aw,Lqr),e(xe,yqr),e(xe,nw),e(nw,b3e),e(b3e,xqr),e(nw,$qr),e(nw,vZ),e(vZ,kqr),e(nw,Sqr),e(xe,Rqr),e(xe,sw),e(sw,v3e),e(v3e,Pqr),e(sw,Bqr),e(sw,FZ),e(FZ,Iqr),e(sw,Nqr),e(xe,qqr),e(xe,lw),e(lw,F3e),e(F3e,jqr),e(lw,Dqr),e(lw,TZ),e(TZ,Gqr),e(lw,Oqr),e(xe,Vqr),e(xe,iw),e(iw,T3e),e(T3e,Xqr),e(iw,zqr),e(iw,MZ),e(MZ,Qqr),e(iw,Wqr),e(Vr,Hqr),M(dw,Vr,null),b(m,CVe,_),b(m,Hc,_),e(Hc,cw),e(cw,M3e),M(Ox,M3e,null),e(Hc,Uqr),e(Hc,E3e),e(E3e,Jqr),b(m,wVe,_),b(m,pr,_),M(Vx,pr,null),e(pr,Yqr),e(pr,Uc),e(Uc,Kqr),e(Uc,EZ),e(EZ,Zqr),e(Uc,ejr),e(Uc,CZ),e(CZ,ojr),e(Uc,rjr),e(pr,tjr),e(pr,Xx),e(Xx,ajr),e(Xx,C3e),e(C3e,njr),e(Xx,sjr),e(pr,ljr),e(pr,Qt),M(zx,Qt,null),e(Qt,ijr),e(Qt,w3e),e(w3e,djr),e(Qt,cjr),e(Qt,Jc),e(Jc,mjr),e(Jc,A3e),e(A3e,fjr),e(Jc,gjr),e(Jc,wZ),e(wZ,hjr),e(Jc,ujr),e(Qt,pjr),M(mw,Qt,null),e(pr,_jr),e(pr,Xr),M(Qx,Xr,null),e(Xr,bjr),e(Xr,L3e),e(L3e,vjr),e(Xr,Fjr),e(Xr,Mn),e(Mn,Tjr),e(Mn,y3e),e(y3e,Mjr),e(Mn,Ejr),e(Mn,x3e),e(x3e,Cjr),e(Mn,wjr),e(Mn,$3e),e($3e,Ajr),e(Mn,Ljr),e(Xr,yjr),e(Xr,Ee),e(Ee,fw),e(fw,k3e),e(k3e,xjr),e(fw,$jr),e(fw,AZ),e(AZ,kjr),e(fw,Sjr),e(Ee,Rjr),e(Ee,gw),e(gw,S3e),e(S3e,Pjr),e(gw,Bjr),e(gw,LZ),e(LZ,Ijr),e(gw,Njr),e(Ee,qjr),e(Ee,hw),e(hw,R3e),e(R3e,jjr),e(hw,Djr),e(hw,yZ),e(yZ,Gjr),e(hw,Ojr),e(Ee,Vjr),e(Ee,uw),e(uw,P3e),e(P3e,Xjr),e(uw,zjr),e(uw,xZ),e(xZ,Qjr),e(uw,Wjr),e(Ee,Hjr),e(Ee,pw),e(pw,B3e),e(B3e,Ujr),e(pw,Jjr),e(pw,$Z),e($Z,Yjr),e(pw,Kjr),e(Ee,Zjr),e(Ee,_w),e(_w,I3e),e(I3e,eDr),e(_w,oDr),e(_w,kZ),e(kZ,rDr),e(_w,tDr),e(Ee,aDr),e(Ee,bw),e(bw,N3e),e(N3e,nDr),e(bw,sDr),e(bw,SZ),e(SZ,lDr),e(bw,iDr),e(Ee,dDr),e(Ee,vw),e(vw,q3e),e(q3e,cDr),e(vw,mDr),e(vw,RZ),e(RZ,fDr),e(vw,gDr),e(Ee,hDr),e(Ee,Fw),e(Fw,j3e),e(j3e,uDr),e(Fw,pDr),e(Fw,PZ),e(PZ,_Dr),e(Fw,bDr),e(Ee,vDr),e(Ee,Tw),e(Tw,D3e),e(D3e,FDr),e(Tw,TDr),e(Tw,BZ),e(BZ,MDr),e(Tw,EDr),e(Ee,CDr),e(Ee,Mw),e(Mw,G3e),e(G3e,wDr),e(Mw,ADr),e(Mw,IZ),e(IZ,LDr),e(Mw,yDr),e(Ee,xDr),e(Ee,Ew),e(Ew,O3e),e(O3e,$Dr),e(Ew,kDr),e(Ew,NZ),e(NZ,SDr),e(Ew,RDr),e(Ee,PDr),e(Ee,Cw),e(Cw,V3e),e(V3e,BDr),e(Cw,IDr),e(Cw,qZ),e(qZ,NDr),e(Cw,qDr),e(Xr,jDr),M(ww,Xr,null),b(m,AVe,_),b(m,Yc,_),e(Yc,Aw),e(Aw,X3e),M(Wx,X3e,null),e(Yc,DDr),e(Yc,z3e),e(z3e,GDr),b(m,LVe,_),b(m,_r,_),M(Hx,_r,null),e(_r,ODr),e(_r,Kc),e(Kc,VDr),e(Kc,jZ),e(jZ,XDr),e(Kc,zDr),e(Kc,DZ),e(DZ,QDr),e(Kc,WDr),e(_r,HDr),e(_r,Ux),e(Ux,UDr),e(Ux,Q3e),e(Q3e,JDr),e(Ux,YDr),e(_r,KDr),e(_r,Wt),M(Jx,Wt,null),e(Wt,ZDr),e(Wt,W3e),e(W3e,eGr),e(Wt,oGr),e(Wt,Zc),e(Zc,rGr),e(Zc,H3e),e(H3e,tGr),e(Zc,aGr),e(Zc,GZ),e(GZ,nGr),e(Zc,sGr),e(Wt,lGr),M(Lw,Wt,null),e(_r,iGr),e(_r,zr),M(Yx,zr,null),e(zr,dGr),e(zr,U3e),e(U3e,cGr),e(zr,mGr),e(zr,En),e(En,fGr),e(En,J3e),e(J3e,gGr),e(En,hGr),e(En,Y3e),e(Y3e,uGr),e(En,pGr),e(En,K3e),e(K3e,_Gr),e(En,bGr),e(zr,vGr),e(zr,$e),e($e,yw),e(yw,Z3e),e(Z3e,FGr),e(yw,TGr),e(yw,OZ),e(OZ,MGr),e(yw,EGr),e($e,CGr),e($e,xw),e(xw,e0e),e(e0e,wGr),e(xw,AGr),e(xw,VZ),e(VZ,LGr),e(xw,yGr),e($e,xGr),e($e,$w),e($w,o0e),e(o0e,$Gr),e($w,kGr),e($w,XZ),e(XZ,SGr),e($w,RGr),e($e,PGr),e($e,kw),e(kw,r0e),e(r0e,BGr),e(kw,IGr),e(kw,zZ),e(zZ,NGr),e(kw,qGr),e($e,jGr),e($e,Sw),e(Sw,t0e),e(t0e,DGr),e(Sw,GGr),e(Sw,QZ),e(QZ,OGr),e(Sw,VGr),e($e,XGr),e($e,Rw),e(Rw,a0e),e(a0e,zGr),e(Rw,QGr),e(Rw,WZ),e(WZ,WGr),e(Rw,HGr),e($e,UGr),e($e,Pw),e(Pw,n0e),e(n0e,JGr),e(Pw,YGr),e(Pw,HZ),e(HZ,KGr),e(Pw,ZGr),e($e,eOr),e($e,Bw),e(Bw,s0e),e(s0e,oOr),e(Bw,rOr),e(Bw,UZ),e(UZ,tOr),e(Bw,aOr),e($e,nOr),e($e,Iw),e(Iw,l0e),e(l0e,sOr),e(Iw,lOr),e(Iw,JZ),e(JZ,iOr),e(Iw,dOr),e($e,cOr),e($e,Nw),e(Nw,i0e),e(i0e,mOr),e(Nw,fOr),e(Nw,YZ),e(YZ,gOr),e(Nw,hOr),e(zr,uOr),M(qw,zr,null),b(m,yVe,_),b(m,em,_),e(em,jw),e(jw,d0e),M(Kx,d0e,null),e(em,pOr),e(em,c0e),e(c0e,_Or),b(m,xVe,_),b(m,br,_),M(Zx,br,null),e(br,bOr),e(br,om),e(om,vOr),e(om,KZ),e(KZ,FOr),e(om,TOr),e(om,ZZ),e(ZZ,MOr),e(om,EOr),e(br,COr),e(br,e$),e(e$,wOr),e(e$,m0e),e(m0e,AOr),e(e$,LOr),e(br,yOr),e(br,Ht),M(o$,Ht,null),e(Ht,xOr),e(Ht,f0e),e(f0e,$Or),e(Ht,kOr),e(Ht,rm),e(rm,SOr),e(rm,g0e),e(g0e,ROr),e(rm,POr),e(rm,eee),e(eee,BOr),e(rm,IOr),e(Ht,NOr),M(Dw,Ht,null),e(br,qOr),e(br,Qr),M(r$,Qr,null),e(Qr,jOr),e(Qr,h0e),e(h0e,DOr),e(Qr,GOr),e(Qr,Cn),e(Cn,OOr),e(Cn,u0e),e(u0e,VOr),e(Cn,XOr),e(Cn,p0e),e(p0e,zOr),e(Cn,QOr),e(Cn,_0e),e(_0e,WOr),e(Cn,HOr),e(Qr,UOr),e(Qr,ke),e(ke,Gw),e(Gw,b0e),e(b0e,JOr),e(Gw,YOr),e(Gw,oee),e(oee,KOr),e(Gw,ZOr),e(ke,eVr),e(ke,Ow),e(Ow,v0e),e(v0e,oVr),e(Ow,rVr),e(Ow,ree),e(ree,tVr),e(Ow,aVr),e(ke,nVr),e(ke,Vw),e(Vw,F0e),e(F0e,sVr),e(Vw,lVr),e(Vw,tee),e(tee,iVr),e(Vw,dVr),e(ke,cVr),e(ke,Xw),e(Xw,T0e),e(T0e,mVr),e(Xw,fVr),e(Xw,aee),e(aee,gVr),e(Xw,hVr),e(ke,uVr),e(ke,zw),e(zw,M0e),e(M0e,pVr),e(zw,_Vr),e(zw,nee),e(nee,bVr),e(zw,vVr),e(ke,FVr),e(ke,Qw),e(Qw,E0e),e(E0e,TVr),e(Qw,MVr),e(Qw,see),e(see,EVr),e(Qw,CVr),e(ke,wVr),e(ke,Ww),e(Ww,C0e),e(C0e,AVr),e(Ww,LVr),e(Ww,lee),e(lee,yVr),e(Ww,xVr),e(ke,$Vr),e(ke,Hw),e(Hw,w0e),e(w0e,kVr),e(Hw,SVr),e(Hw,iee),e(iee,RVr),e(Hw,PVr),e(ke,BVr),e(ke,Uw),e(Uw,A0e),e(A0e,IVr),e(Uw,NVr),e(Uw,dee),e(dee,qVr),e(Uw,jVr),e(ke,DVr),e(ke,Jw),e(Jw,L0e),e(L0e,GVr),e(Jw,OVr),e(Jw,cee),e(cee,VVr),e(Jw,XVr),e(Qr,zVr),M(Yw,Qr,null),b(m,$Ve,_),b(m,tm,_),e(tm,Kw),e(Kw,y0e),M(t$,y0e,null),e(tm,QVr),e(tm,x0e),e(x0e,WVr),b(m,kVe,_),b(m,vr,_),M(a$,vr,null),e(vr,HVr),e(vr,am),e(am,UVr),e(am,mee),e(mee,JVr),e(am,YVr),e(am,fee),e(fee,KVr),e(am,ZVr),e(vr,eXr),e(vr,n$),e(n$,oXr),e(n$,$0e),e($0e,rXr),e(n$,tXr),e(vr,aXr),e(vr,Ut),M(s$,Ut,null),e(Ut,nXr),e(Ut,k0e),e(k0e,sXr),e(Ut,lXr),e(Ut,nm),e(nm,iXr),e(nm,S0e),e(S0e,dXr),e(nm,cXr),e(nm,gee),e(gee,mXr),e(nm,fXr),e(Ut,gXr),M(Zw,Ut,null),e(vr,hXr),e(vr,Wr),M(l$,Wr,null),e(Wr,uXr),e(Wr,R0e),e(R0e,pXr),e(Wr,_Xr),e(Wr,wn),e(wn,bXr),e(wn,P0e),e(P0e,vXr),e(wn,FXr),e(wn,B0e),e(B0e,TXr),e(wn,MXr),e(wn,I0e),e(I0e,EXr),e(wn,CXr),e(Wr,wXr),e(Wr,Se),e(Se,eA),e(eA,N0e),e(N0e,AXr),e(eA,LXr),e(eA,hee),e(hee,yXr),e(eA,xXr),e(Se,$Xr),e(Se,oA),e(oA,q0e),e(q0e,kXr),e(oA,SXr),e(oA,uee),e(uee,RXr),e(oA,PXr),e(Se,BXr),e(Se,rA),e(rA,j0e),e(j0e,IXr),e(rA,NXr),e(rA,pee),e(pee,qXr),e(rA,jXr),e(Se,DXr),e(Se,tA),e(tA,D0e),e(D0e,GXr),e(tA,OXr),e(tA,_ee),e(_ee,VXr),e(tA,XXr),e(Se,zXr),e(Se,aA),e(aA,G0e),e(G0e,QXr),e(aA,WXr),e(aA,bee),e(bee,HXr),e(aA,UXr),e(Se,JXr),e(Se,nA),e(nA,O0e),e(O0e,YXr),e(nA,KXr),e(nA,vee),e(vee,ZXr),e(nA,ezr),e(Se,ozr),e(Se,sA),e(sA,V0e),e(V0e,rzr),e(sA,tzr),e(sA,Fee),e(Fee,azr),e(sA,nzr),e(Se,szr),e(Se,lA),e(lA,X0e),e(X0e,lzr),e(lA,izr),e(lA,Tee),e(Tee,dzr),e(lA,czr),e(Se,mzr),e(Se,iA),e(iA,z0e),e(z0e,fzr),e(iA,gzr),e(iA,Mee),e(Mee,hzr),e(iA,uzr),e(Se,pzr),e(Se,dA),e(dA,Q0e),e(Q0e,_zr),e(dA,bzr),e(dA,Eee),e(Eee,vzr),e(dA,Fzr),e(Wr,Tzr),M(cA,Wr,null),b(m,SVe,_),b(m,sm,_),e(sm,mA),e(mA,W0e),M(i$,W0e,null),e(sm,Mzr),e(sm,H0e),e(H0e,Ezr),b(m,RVe,_),b(m,Fr,_),M(d$,Fr,null),e(Fr,Czr),e(Fr,lm),e(lm,wzr),e(lm,Cee),e(Cee,Azr),e(lm,Lzr),e(lm,wee),e(wee,yzr),e(lm,xzr),e(Fr,$zr),e(Fr,c$),e(c$,kzr),e(c$,U0e),e(U0e,Szr),e(c$,Rzr),e(Fr,Pzr),e(Fr,Jt),M(m$,Jt,null),e(Jt,Bzr),e(Jt,J0e),e(J0e,Izr),e(Jt,Nzr),e(Jt,im),e(im,qzr),e(im,Y0e),e(Y0e,jzr),e(im,Dzr),e(im,Aee),e(Aee,Gzr),e(im,Ozr),e(Jt,Vzr),M(fA,Jt,null),e(Fr,Xzr),e(Fr,Hr),M(f$,Hr,null),e(Hr,zzr),e(Hr,K0e),e(K0e,Qzr),e(Hr,Wzr),e(Hr,An),e(An,Hzr),e(An,Z0e),e(Z0e,Uzr),e(An,Jzr),e(An,ewe),e(ewe,Yzr),e(An,Kzr),e(An,owe),e(owe,Zzr),e(An,eQr),e(Hr,oQr),e(Hr,Re),e(Re,gA),e(gA,rwe),e(rwe,rQr),e(gA,tQr),e(gA,Lee),e(Lee,aQr),e(gA,nQr),e(Re,sQr),e(Re,hA),e(hA,twe),e(twe,lQr),e(hA,iQr),e(hA,yee),e(yee,dQr),e(hA,cQr),e(Re,mQr),e(Re,uA),e(uA,awe),e(awe,fQr),e(uA,gQr),e(uA,xee),e(xee,hQr),e(uA,uQr),e(Re,pQr),e(Re,pA),e(pA,nwe),e(nwe,_Qr),e(pA,bQr),e(pA,$ee),e($ee,vQr),e(pA,FQr),e(Re,TQr),e(Re,_A),e(_A,swe),e(swe,MQr),e(_A,EQr),e(_A,kee),e(kee,CQr),e(_A,wQr),e(Re,AQr),e(Re,bA),e(bA,lwe),e(lwe,LQr),e(bA,yQr),e(bA,See),e(See,xQr),e(bA,$Qr),e(Re,kQr),e(Re,vA),e(vA,iwe),e(iwe,SQr),e(vA,RQr),e(vA,Ree),e(Ree,PQr),e(vA,BQr),e(Re,IQr),e(Re,FA),e(FA,dwe),e(dwe,NQr),e(FA,qQr),e(FA,Pee),e(Pee,jQr),e(FA,DQr),e(Re,GQr),e(Re,TA),e(TA,cwe),e(cwe,OQr),e(TA,VQr),e(TA,Bee),e(Bee,XQr),e(TA,zQr),e(Re,QQr),e(Re,MA),e(MA,mwe),e(mwe,WQr),e(MA,HQr),e(MA,Iee),e(Iee,UQr),e(MA,JQr),e(Hr,YQr),M(EA,Hr,null),b(m,PVe,_),b(m,dm,_),e(dm,CA),e(CA,fwe),M(g$,fwe,null),e(dm,KQr),e(dm,gwe),e(gwe,ZQr),b(m,BVe,_),b(m,Tr,_),M(h$,Tr,null),e(Tr,eWr),e(Tr,cm),e(cm,oWr),e(cm,Nee),e(Nee,rWr),e(cm,tWr),e(cm,qee),e(qee,aWr),e(cm,nWr),e(Tr,sWr),e(Tr,u$),e(u$,lWr),e(u$,hwe),e(hwe,iWr),e(u$,dWr),e(Tr,cWr),e(Tr,Yt),M(p$,Yt,null),e(Yt,mWr),e(Yt,uwe),e(uwe,fWr),e(Yt,gWr),e(Yt,mm),e(mm,hWr),e(mm,pwe),e(pwe,uWr),e(mm,pWr),e(mm,jee),e(jee,_Wr),e(mm,bWr),e(Yt,vWr),M(wA,Yt,null),e(Tr,FWr),e(Tr,Ur),M(_$,Ur,null),e(Ur,TWr),e(Ur,_we),e(_we,MWr),e(Ur,EWr),e(Ur,Ln),e(Ln,CWr),e(Ln,bwe),e(bwe,wWr),e(Ln,AWr),e(Ln,vwe),e(vwe,LWr),e(Ln,yWr),e(Ln,Fwe),e(Fwe,xWr),e(Ln,$Wr),e(Ur,kWr),e(Ur,Ve),e(Ve,AA),e(AA,Twe),e(Twe,SWr),e(AA,RWr),e(AA,Dee),e(Dee,PWr),e(AA,BWr),e(Ve,IWr),e(Ve,LA),e(LA,Mwe),e(Mwe,NWr),e(LA,qWr),e(LA,Gee),e(Gee,jWr),e(LA,DWr),e(Ve,GWr),e(Ve,yA),e(yA,Ewe),e(Ewe,OWr),e(yA,VWr),e(yA,Oee),e(Oee,XWr),e(yA,zWr),e(Ve,QWr),e(Ve,xA),e(xA,Cwe),e(Cwe,WWr),e(xA,HWr),e(xA,Vee),e(Vee,UWr),e(xA,JWr),e(Ve,YWr),e(Ve,$A),e($A,wwe),e(wwe,KWr),e($A,ZWr),e($A,Xee),e(Xee,eHr),e($A,oHr),e(Ve,rHr),e(Ve,kA),e(kA,Awe),e(Awe,tHr),e(kA,aHr),e(kA,zee),e(zee,nHr),e(kA,sHr),e(Ve,lHr),e(Ve,SA),e(SA,Lwe),e(Lwe,iHr),e(SA,dHr),e(SA,Qee),e(Qee,cHr),e(SA,mHr),e(Ve,fHr),e(Ve,RA),e(RA,ywe),e(ywe,gHr),e(RA,hHr),e(RA,Wee),e(Wee,uHr),e(RA,pHr),e(Ur,_Hr),M(PA,Ur,null),b(m,IVe,_),b(m,fm,_),e(fm,BA),e(BA,xwe),M(b$,xwe,null),e(fm,bHr),e(fm,$we),e($we,vHr),b(m,NVe,_),b(m,Mr,_),M(v$,Mr,null),e(Mr,FHr),e(Mr,gm),e(gm,THr),e(gm,Hee),e(Hee,MHr),e(gm,EHr),e(gm,Uee),e(Uee,CHr),e(gm,wHr),e(Mr,AHr),e(Mr,F$),e(F$,LHr),e(F$,kwe),e(kwe,yHr),e(F$,xHr),e(Mr,$Hr),e(Mr,Kt),M(T$,Kt,null),e(Kt,kHr),e(Kt,Swe),e(Swe,SHr),e(Kt,RHr),e(Kt,hm),e(hm,PHr),e(hm,Rwe),e(Rwe,BHr),e(hm,IHr),e(hm,Jee),e(Jee,NHr),e(hm,qHr),e(Kt,jHr),M(IA,Kt,null),e(Mr,DHr),e(Mr,Jr),M(M$,Jr,null),e(Jr,GHr),e(Jr,Pwe),e(Pwe,OHr),e(Jr,VHr),e(Jr,yn),e(yn,XHr),e(yn,Bwe),e(Bwe,zHr),e(yn,QHr),e(yn,Iwe),e(Iwe,WHr),e(yn,HHr),e(yn,Nwe),e(Nwe,UHr),e(yn,JHr),e(Jr,YHr),e(Jr,Xe),e(Xe,NA),e(NA,qwe),e(qwe,KHr),e(NA,ZHr),e(NA,Yee),e(Yee,eUr),e(NA,oUr),e(Xe,rUr),e(Xe,qA),e(qA,jwe),e(jwe,tUr),e(qA,aUr),e(qA,Kee),e(Kee,nUr),e(qA,sUr),e(Xe,lUr),e(Xe,jA),e(jA,Dwe),e(Dwe,iUr),e(jA,dUr),e(jA,Zee),e(Zee,cUr),e(jA,mUr),e(Xe,fUr),e(Xe,DA),e(DA,Gwe),e(Gwe,gUr),e(DA,hUr),e(DA,eoe),e(eoe,uUr),e(DA,pUr),e(Xe,_Ur),e(Xe,GA),e(GA,Owe),e(Owe,bUr),e(GA,vUr),e(GA,ooe),e(ooe,FUr),e(GA,TUr),e(Xe,MUr),e(Xe,OA),e(OA,Vwe),e(Vwe,EUr),e(OA,CUr),e(OA,roe),e(roe,wUr),e(OA,AUr),e(Xe,LUr),e(Xe,VA),e(VA,Xwe),e(Xwe,yUr),e(VA,xUr),e(VA,toe),e(toe,$Ur),e(VA,kUr),e(Xe,SUr),e(Xe,XA),e(XA,zwe),e(zwe,RUr),e(XA,PUr),e(XA,aoe),e(aoe,BUr),e(XA,IUr),e(Jr,NUr),M(zA,Jr,null),b(m,qVe,_),b(m,um,_),e(um,QA),e(QA,Qwe),M(E$,Qwe,null),e(um,qUr),e(um,Wwe),e(Wwe,jUr),b(m,jVe,_),b(m,Er,_),M(C$,Er,null),e(Er,DUr),e(Er,pm),e(pm,GUr),e(pm,noe),e(noe,OUr),e(pm,VUr),e(pm,soe),e(soe,XUr),e(pm,zUr),e(Er,QUr),e(Er,w$),e(w$,WUr),e(w$,Hwe),e(Hwe,HUr),e(w$,UUr),e(Er,JUr),e(Er,Zt),M(A$,Zt,null),e(Zt,YUr),e(Zt,Uwe),e(Uwe,KUr),e(Zt,ZUr),e(Zt,_m),e(_m,eJr),e(_m,Jwe),e(Jwe,oJr),e(_m,rJr),e(_m,loe),e(loe,tJr),e(_m,aJr),e(Zt,nJr),M(WA,Zt,null),e(Er,sJr),e(Er,Yr),M(L$,Yr,null),e(Yr,lJr),e(Yr,Ywe),e(Ywe,iJr),e(Yr,dJr),e(Yr,xn),e(xn,cJr),e(xn,Kwe),e(Kwe,mJr),e(xn,fJr),e(xn,Zwe),e(Zwe,gJr),e(xn,hJr),e(xn,eAe),e(eAe,uJr),e(xn,pJr),e(Yr,_Jr),e(Yr,oAe),e(oAe,HA),e(HA,rAe),e(rAe,bJr),e(HA,vJr),e(HA,ioe),e(ioe,FJr),e(HA,TJr),e(Yr,MJr),M(UA,Yr,null),b(m,DVe,_),b(m,bm,_),e(bm,JA),e(JA,tAe),M(y$,tAe,null),e(bm,EJr),e(bm,aAe),e(aAe,CJr),b(m,GVe,_),b(m,Cr,_),M(x$,Cr,null),e(Cr,wJr),e(Cr,vm),e(vm,AJr),e(vm,doe),e(doe,LJr),e(vm,yJr),e(vm,coe),e(coe,xJr),e(vm,$Jr),e(Cr,kJr),e(Cr,$$),e($$,SJr),e($$,nAe),e(nAe,RJr),e($$,PJr),e(Cr,BJr),e(Cr,ea),M(k$,ea,null),e(ea,IJr),e(ea,sAe),e(sAe,NJr),e(ea,qJr),e(ea,Fm),e(Fm,jJr),e(Fm,lAe),e(lAe,DJr),e(Fm,GJr),e(Fm,moe),e(moe,OJr),e(Fm,VJr),e(ea,XJr),M(YA,ea,null),e(Cr,zJr),e(Cr,Kr),M(S$,Kr,null),e(Kr,QJr),e(Kr,iAe),e(iAe,WJr),e(Kr,HJr),e(Kr,$n),e($n,UJr),e($n,dAe),e(dAe,JJr),e($n,YJr),e($n,cAe),e(cAe,KJr),e($n,ZJr),e($n,mAe),e(mAe,eYr),e($n,oYr),e(Kr,rYr),e(Kr,R$),e(R$,KA),e(KA,fAe),e(fAe,tYr),e(KA,aYr),e(KA,foe),e(foe,nYr),e(KA,sYr),e(R$,lYr),e(R$,ZA),e(ZA,gAe),e(gAe,iYr),e(ZA,dYr),e(ZA,goe),e(goe,cYr),e(ZA,mYr),e(Kr,fYr),M(e6,Kr,null),b(m,OVe,_),b(m,Tm,_),e(Tm,o6),e(o6,hAe),M(P$,hAe,null),e(Tm,gYr),e(Tm,uAe),e(uAe,hYr),b(m,VVe,_),b(m,wr,_),M(B$,wr,null),e(wr,uYr),e(wr,Mm),e(Mm,pYr),e(Mm,hoe),e(hoe,_Yr),e(Mm,bYr),e(Mm,uoe),e(uoe,vYr),e(Mm,FYr),e(wr,TYr),e(wr,I$),e(I$,MYr),e(I$,pAe),e(pAe,EYr),e(I$,CYr),e(wr,wYr),e(wr,oa),M(N$,oa,null),e(oa,AYr),e(oa,_Ae),e(_Ae,LYr),e(oa,yYr),e(oa,Em),e(Em,xYr),e(Em,bAe),e(bAe,$Yr),e(Em,kYr),e(Em,poe),e(poe,SYr),e(Em,RYr),e(oa,PYr),M(r6,oa,null),e(wr,BYr),e(wr,Zr),M(q$,Zr,null),e(Zr,IYr),e(Zr,vAe),e(vAe,NYr),e(Zr,qYr),e(Zr,kn),e(kn,jYr),e(kn,FAe),e(FAe,DYr),e(kn,GYr),e(kn,TAe),e(TAe,OYr),e(kn,VYr),e(kn,MAe),e(MAe,XYr),e(kn,zYr),e(Zr,QYr),e(Zr,EAe),e(EAe,t6),e(t6,CAe),e(CAe,WYr),e(t6,HYr),e(t6,_oe),e(_oe,UYr),e(t6,JYr),e(Zr,YYr),M(a6,Zr,null),XVe=!0},p(m,[_]){const j$={};_&2&&(j$.$$scope={dirty:_,ctx:m}),Sm.$set(j$);const wAe={};_&2&&(wAe.$$scope={dirty:_,ctx:m}),Gg.$set(wAe);const AAe={};_&2&&(AAe.$$scope={dirty:_,ctx:m}),Eh.$set(AAe);const LAe={};_&2&&(LAe.$$scope={dirty:_,ctx:m}),au.$set(LAe);const D$={};_&2&&(D$.$$scope={dirty:_,ctx:m}),nu.$set(D$);const yAe={};_&2&&(yAe.$$scope={dirty:_,ctx:m}),wu.$set(yAe);const Sn={};_&2&&(Sn.$$scope={dirty:_,ctx:m}),Au.$set(Sn);const xAe={};_&2&&(xAe.$$scope={dirty:_,ctx:m}),xu.$set(xAe);const $Ae={};_&2&&($Ae.$$scope={dirty:_,ctx:m}),x_.$set($Ae);const kAe={};_&2&&(kAe.$$scope={dirty:_,ctx:m}),k_.$set(kAe);const G$={};_&2&&(G$.$$scope={dirty:_,ctx:m}),E2.$set(G$);const SAe={};_&2&&(SAe.$$scope={dirty:_,ctx:m}),w2.$set(SAe);const O$={};_&2&&(O$.$$scope={dirty:_,ctx:m}),mb.$set(O$);const RAe={};_&2&&(RAe.$$scope={dirty:_,ctx:m}),gb.$set(RAe);const V$={};_&2&&(V$.$$scope={dirty:_,ctx:m}),Kb.$set(V$);const PAe={};_&2&&(PAe.$$scope={dirty:_,ctx:m}),ev.$set(PAe);const BAe={};_&2&&(BAe.$$scope={dirty:_,ctx:m}),vv.$set(BAe);const IAe={};_&2&&(IAe.$$scope={dirty:_,ctx:m}),Tv.$set(IAe);const Cm={};_&2&&(Cm.$$scope={dirty:_,ctx:m}),bF.$set(Cm);const NAe={};_&2&&(NAe.$$scope={dirty:_,ctx:m}),FF.$set(NAe);const qAe={};_&2&&(qAe.$$scope={dirty:_,ctx:m}),KF.$set(qAe);const jAe={};_&2&&(jAe.$$scope={dirty:_,ctx:m}),e1.$set(jAe);const X$={};_&2&&(X$.$$scope={dirty:_,ctx:m}),i1.$set(X$);const DAe={};_&2&&(DAe.$$scope={dirty:_,ctx:m}),c1.$set(DAe);const GAe={};_&2&&(GAe.$$scope={dirty:_,ctx:m}),H1.$set(GAe);const OAe={};_&2&&(OAe.$$scope={dirty:_,ctx:m}),J1.$set(OAe);const rt={};_&2&&(rt.$$scope={dirty:_,ctx:m}),jT.$set(rt);const z$={};_&2&&(z$.$$scope={dirty:_,ctx:m}),GT.$set(z$);const VAe={};_&2&&(VAe.$$scope={dirty:_,ctx:m}),XT.$set(VAe);const Q$={};_&2&&(Q$.$$scope={dirty:_,ctx:m}),QT.$set(Q$);const XAe={};_&2&&(XAe.$$scope={dirty:_,ctx:m}),sM.$set(XAe);const tt={};_&2&&(tt.$$scope={dirty:_,ctx:m}),iM.$set(tt);const zAe={};_&2&&(zAe.$$scope={dirty:_,ctx:m}),mM.$set(zAe);const wm={};_&2&&(wm.$$scope={dirty:_,ctx:m}),gM.$set(wm);const QAe={};_&2&&(QAe.$$scope={dirty:_,ctx:m}),pM.$set(QAe);const WAe={};_&2&&(WAe.$$scope={dirty:_,ctx:m}),bM.$set(WAe);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),xM.$set(L);const n6={};_&2&&(n6.$$scope={dirty:_,ctx:m}),kM.$set(n6);const HAe={};_&2&&(HAe.$$scope={dirty:_,ctx:m}),qM.$set(HAe);const UAe={};_&2&&(UAe.$$scope={dirty:_,ctx:m}),DM.$set(UAe);const s6={};_&2&&(s6.$$scope={dirty:_,ctx:m}),KM.$set(s6);const JAe={};_&2&&(JAe.$$scope={dirty:_,ctx:m}),eE.$set(JAe);const YAe={};_&2&&(YAe.$$scope={dirty:_,ctx:m}),aE.$set(YAe);const l6={};_&2&&(l6.$$scope={dirty:_,ctx:m}),sE.$set(l6);const KAe={};_&2&&(KAe.$$scope={dirty:_,ctx:m}),gE.$set(KAe);const ZAe={};_&2&&(ZAe.$$scope={dirty:_,ctx:m}),uE.$set(ZAe);const i6={};_&2&&(i6.$$scope={dirty:_,ctx:m}),FE.$set(i6);const e6e={};_&2&&(e6e.$$scope={dirty:_,ctx:m}),ME.$set(e6e);const o6e={};_&2&&(o6e.$$scope={dirty:_,ctx:m}),AE.$set(o6e);const d6={};_&2&&(d6.$$scope={dirty:_,ctx:m}),yE.$set(d6);const r6e={};_&2&&(r6e.$$scope={dirty:_,ctx:m}),kE.$set(r6e);const t6e={};_&2&&(t6e.$$scope={dirty:_,ctx:m}),RE.$set(t6e);const c6={};_&2&&(c6.$$scope={dirty:_,ctx:m}),jE.$set(c6);const a6e={};_&2&&(a6e.$$scope={dirty:_,ctx:m}),GE.$set(a6e);const n6e={};_&2&&(n6e.$$scope={dirty:_,ctx:m}),XE.$set(n6e);const m6={};_&2&&(m6.$$scope={dirty:_,ctx:m}),QE.$set(m6);const s6e={};_&2&&(s6e.$$scope={dirty:_,ctx:m}),j4.$set(s6e);const l6e={};_&2&&(l6e.$$scope={dirty:_,ctx:m}),G4.$set(l6e);const f6={};_&2&&(f6.$$scope={dirty:_,ctx:m}),mC.$set(f6);const i6e={};_&2&&(i6e.$$scope={dirty:_,ctx:m}),gC.$set(i6e);const d6e={};_&2&&(d6e.$$scope={dirty:_,ctx:m}),LC.$set(d6e);const g6={};_&2&&(g6.$$scope={dirty:_,ctx:m}),xC.$set(g6);const c6e={};_&2&&(c6e.$$scope={dirty:_,ctx:m}),PC.$set(c6e);const m6e={};_&2&&(m6e.$$scope={dirty:_,ctx:m}),IC.$set(m6e);const h6={};_&2&&(h6.$$scope={dirty:_,ctx:m}),t5.$set(h6);const f6e={};_&2&&(f6e.$$scope={dirty:_,ctx:m}),n5.$set(f6e);const g6e={};_&2&&(g6e.$$scope={dirty:_,ctx:m}),p5.$set(g6e);const u6={};_&2&&(u6.$$scope={dirty:_,ctx:m}),b5.$set(u6);const h6e={};_&2&&(h6e.$$scope={dirty:_,ctx:m}),z5.$set(h6e);const u6e={};_&2&&(u6e.$$scope={dirty:_,ctx:m}),W5.$set(u6e);const p6={};_&2&&(p6.$$scope={dirty:_,ctx:m}),m3.$set(p6);const p6e={};_&2&&(p6e.$$scope={dirty:_,ctx:m}),g3.$set(p6e);const _6e={};_&2&&(_6e.$$scope={dirty:_,ctx:m}),p3.$set(_6e);const _6={};_&2&&(_6.$$scope={dirty:_,ctx:m}),b3.$set(_6);const b6e={};_&2&&(b6e.$$scope={dirty:_,ctx:m}),F3.$set(b6e);const v6e={};_&2&&(v6e.$$scope={dirty:_,ctx:m}),M3.$set(v6e);const b6={};_&2&&(b6.$$scope={dirty:_,ctx:m}),V3.$set(b6);const F6e={};_&2&&(F6e.$$scope={dirty:_,ctx:m}),z3.$set(F6e);const T6e={};_&2&&(T6e.$$scope={dirty:_,ctx:m}),f0.$set(T6e);const v6={};_&2&&(v6.$$scope={dirty:_,ctx:m}),h0.$set(v6);const M6e={};_&2&&(M6e.$$scope={dirty:_,ctx:m}),p0.$set(M6e);const E6e={};_&2&&(E6e.$$scope={dirty:_,ctx:m}),b0.$set(E6e);const F6={};_&2&&(F6.$$scope={dirty:_,ctx:m}),F0.$set(F6);const C6e={};_&2&&(C6e.$$scope={dirty:_,ctx:m}),M0.$set(C6e);const w6e={};_&2&&(w6e.$$scope={dirty:_,ctx:m}),J0.$set(w6e);const T6={};_&2&&(T6.$$scope={dirty:_,ctx:m}),K0.$set(T6);const A6e={};_&2&&(A6e.$$scope={dirty:_,ctx:m}),dw.$set(A6e);const L6e={};_&2&&(L6e.$$scope={dirty:_,ctx:m}),mw.$set(L6e);const M6={};_&2&&(M6.$$scope={dirty:_,ctx:m}),ww.$set(M6);const y6e={};_&2&&(y6e.$$scope={dirty:_,ctx:m}),Lw.$set(y6e);const x6e={};_&2&&(x6e.$$scope={dirty:_,ctx:m}),qw.$set(x6e);const E6={};_&2&&(E6.$$scope={dirty:_,ctx:m}),Dw.$set(E6);const $6e={};_&2&&($6e.$$scope={dirty:_,ctx:m}),Yw.$set($6e);const k6e={};_&2&&(k6e.$$scope={dirty:_,ctx:m}),Zw.$set(k6e);const C6={};_&2&&(C6.$$scope={dirty:_,ctx:m}),cA.$set(C6);const S6e={};_&2&&(S6e.$$scope={dirty:_,ctx:m}),fA.$set(S6e);const R6e={};_&2&&(R6e.$$scope={dirty:_,ctx:m}),EA.$set(R6e);const w6={};_&2&&(w6.$$scope={dirty:_,ctx:m}),wA.$set(w6);const P6e={};_&2&&(P6e.$$scope={dirty:_,ctx:m}),PA.$set(P6e);const B6e={};_&2&&(B6e.$$scope={dirty:_,ctx:m}),IA.$set(B6e);const A6={};_&2&&(A6.$$scope={dirty:_,ctx:m}),zA.$set(A6);const I6e={};_&2&&(I6e.$$scope={dirty:_,ctx:m}),WA.$set(I6e);const N6e={};_&2&&(N6e.$$scope={dirty:_,ctx:m}),UA.$set(N6e);const L6={};_&2&&(L6.$$scope={dirty:_,ctx:m}),YA.$set(L6);const q6e={};_&2&&(q6e.$$scope={dirty:_,ctx:m}),e6.$set(q6e);const j6e={};_&2&&(j6e.$$scope={dirty:_,ctx:m}),r6.$set(j6e);const y6={};_&2&&(y6.$$scope={dirty:_,ctx:m}),a6.$set(y6)},i(m){XVe||(E(d.$$.fragment,m),E(xa.$$.fragment,m),E(xy.$$.fragment,m),E($y.$$.fragment,m),E(Sm.$$.fragment,m),E(ky.$$.fragment,m),E(Sy.$$.fragment,m),E(By.$$.fragment,m),E(Gg.$$.fragment,m),E(Iy.$$.fragment,m),E(Ny.$$.fragment,m),E(qy.$$.fragment,m),E(Gy.$$.fragment,m),E(Eh.$$.fragment,m),E(Oy.$$.fragment,m),E(Vy.$$.fragment,m),E(Xy.$$.fragment,m),E(Wy.$$.fragment,m),E(au.$$.fragment,m),E(nu.$$.fragment,m),E(Hy.$$.fragment,m),E(Uy.$$.fragment,m),E(Jy.$$.fragment,m),E(Zy.$$.fragment,m),E(wu.$$.fragment,m),E(Au.$$.fragment,m),E(e7.$$.fragment,m),E(o7.$$.fragment,m),E(r7.$$.fragment,m),E(a7.$$.fragment,m),E(xu.$$.fragment,m),E(n7.$$.fragment,m),E(x_.$$.fragment,m),E(s7.$$.fragment,m),E(l7.$$.fragment,m),E(d7.$$.fragment,m),E(k_.$$.fragment,m),E(c7.$$.fragment,m),E(E2.$$.fragment,m),E(m7.$$.fragment,m),E(f7.$$.fragment,m),E(h7.$$.fragment,m),E(w2.$$.fragment,m),E(u7.$$.fragment,m),E(mb.$$.fragment,m),E(p7.$$.fragment,m),E(_7.$$.fragment,m),E(v7.$$.fragment,m),E(gb.$$.fragment,m),E(F7.$$.fragment,m),E(Kb.$$.fragment,m),E(T7.$$.fragment,m),E(M7.$$.fragment,m),E(C7.$$.fragment,m),E(ev.$$.fragment,m),E(w7.$$.fragment,m),E(vv.$$.fragment,m),E(A7.$$.fragment,m),E(L7.$$.fragment,m),E(x7.$$.fragment,m),E(Tv.$$.fragment,m),E($7.$$.fragment,m),E(bF.$$.fragment,m),E(k7.$$.fragment,m),E(S7.$$.fragment,m),E(P7.$$.fragment,m),E(FF.$$.fragment,m),E(B7.$$.fragment,m),E(KF.$$.fragment,m),E(I7.$$.fragment,m),E(N7.$$.fragment,m),E(j7.$$.fragment,m),E(e1.$$.fragment,m),E(D7.$$.fragment,m),E(i1.$$.fragment,m),E(G7.$$.fragment,m),E(O7.$$.fragment,m),E(X7.$$.fragment,m),E(c1.$$.fragment,m),E(z7.$$.fragment,m),E(H1.$$.fragment,m),E(Q7.$$.fragment,m),E(W7.$$.fragment,m),E(U7.$$.fragment,m),E(J1.$$.fragment,m),E(J7.$$.fragment,m),E(jT.$$.fragment,m),E(Y7.$$.fragment,m),E(K7.$$.fragment,m),E(e8.$$.fragment,m),E(GT.$$.fragment,m),E(o8.$$.fragment,m),E(XT.$$.fragment,m),E(r8.$$.fragment,m),E(t8.$$.fragment,m),E(n8.$$.fragment,m),E(QT.$$.fragment,m),E(s8.$$.fragment,m),E(sM.$$.fragment,m),E(l8.$$.fragment,m),E(i8.$$.fragment,m),E(c8.$$.fragment,m),E(iM.$$.fragment,m),E(m8.$$.fragment,m),E(mM.$$.fragment,m),E(f8.$$.fragment,m),E(g8.$$.fragment,m),E(u8.$$.fragment,m),E(gM.$$.fragment,m),E(p8.$$.fragment,m),E(pM.$$.fragment,m),E(_8.$$.fragment,m),E(b8.$$.fragment,m),E(F8.$$.fragment,m),E(bM.$$.fragment,m),E(T8.$$.fragment,m),E(xM.$$.fragment,m),E(M8.$$.fragment,m),E(E8.$$.fragment,m),E(w8.$$.fragment,m),E(kM.$$.fragment,m),E(A8.$$.fragment,m),E(qM.$$.fragment,m),E(L8.$$.fragment,m),E(y8.$$.fragment,m),E($8.$$.fragment,m),E(DM.$$.fragment,m),E(k8.$$.fragment,m),E(KM.$$.fragment,m),E(S8.$$.fragment,m),E(R8.$$.fragment,m),E(B8.$$.fragment,m),E(eE.$$.fragment,m),E(I8.$$.fragment,m),E(aE.$$.fragment,m),E(q8.$$.fragment,m),E(j8.$$.fragment,m),E(G8.$$.fragment,m),E(sE.$$.fragment,m),E(O8.$$.fragment,m),E(gE.$$.fragment,m),E(V8.$$.fragment,m),E(X8.$$.fragment,m),E(Q8.$$.fragment,m),E(uE.$$.fragment,m),E(W8.$$.fragment,m),E(FE.$$.fragment,m),E(H8.$$.fragment,m),E(U8.$$.fragment,m),E(Y8.$$.fragment,m),E(ME.$$.fragment,m),E(K8.$$.fragment,m),E(AE.$$.fragment,m),E(e9.$$.fragment,m),E(o9.$$.fragment,m),E(t9.$$.fragment,m),E(yE.$$.fragment,m),E(a9.$$.fragment,m),E(kE.$$.fragment,m),E(n9.$$.fragment,m),E(s9.$$.fragment,m),E(i9.$$.fragment,m),E(RE.$$.fragment,m),E(d9.$$.fragment,m),E(jE.$$.fragment,m),E(c9.$$.fragment,m),E(m9.$$.fragment,m),E(g9.$$.fragment,m),E(GE.$$.fragment,m),E(h9.$$.fragment,m),E(XE.$$.fragment,m),E(u9.$$.fragment,m),E(p9.$$.fragment,m),E(b9.$$.fragment,m),E(QE.$$.fragment,m),E(v9.$$.fragment,m),E(j4.$$.fragment,m),E(F9.$$.fragment,m),E(T9.$$.fragment,m),E(E9.$$.fragment,m),E(G4.$$.fragment,m),E(C9.$$.fragment,m),E(mC.$$.fragment,m),E(w9.$$.fragment,m),E(A9.$$.fragment,m),E(y9.$$.fragment,m),E(gC.$$.fragment,m),E(x9.$$.fragment,m),E(LC.$$.fragment,m),E($9.$$.fragment,m),E(k9.$$.fragment,m),E(R9.$$.fragment,m),E(xC.$$.fragment,m),E(P9.$$.fragment,m),E(PC.$$.fragment,m),E(B9.$$.fragment,m),E(I9.$$.fragment,m),E(q9.$$.fragment,m),E(IC.$$.fragment,m),E(j9.$$.fragment,m),E(t5.$$.fragment,m),E(D9.$$.fragment,m),E(G9.$$.fragment,m),E(V9.$$.fragment,m),E(n5.$$.fragment,m),E(X9.$$.fragment,m),E(p5.$$.fragment,m),E(z9.$$.fragment,m),E(Q9.$$.fragment,m),E(H9.$$.fragment,m),E(b5.$$.fragment,m),E(U9.$$.fragment,m),E(z5.$$.fragment,m),E(J9.$$.fragment,m),E(Y9.$$.fragment,m),E(Z9.$$.fragment,m),E(W5.$$.fragment,m),E(ex.$$.fragment,m),E(m3.$$.fragment,m),E(ox.$$.fragment,m),E(rx.$$.fragment,m),E(ax.$$.fragment,m),E(g3.$$.fragment,m),E(nx.$$.fragment,m),E(p3.$$.fragment,m),E(lx.$$.fragment,m),E(ix.$$.fragment,m),E(cx.$$.fragment,m),E(b3.$$.fragment,m),E(mx.$$.fragment,m),E(F3.$$.fragment,m),E(fx.$$.fragment,m),E(gx.$$.fragment,m),E(ux.$$.fragment,m),E(M3.$$.fragment,m),E(px.$$.fragment,m),E(V3.$$.fragment,m),E(_x.$$.fragment,m),E(bx.$$.fragment,m),E(Fx.$$.fragment,m),E(z3.$$.fragment,m),E(Tx.$$.fragment,m),E(f0.$$.fragment,m),E(Mx.$$.fragment,m),E(Ex.$$.fragment,m),E(wx.$$.fragment,m),E(h0.$$.fragment,m),E(Ax.$$.fragment,m),E(p0.$$.fragment,m),E(Lx.$$.fragment,m),E(yx.$$.fragment,m),E($x.$$.fragment,m),E(b0.$$.fragment,m),E(kx.$$.fragment,m),E(F0.$$.fragment,m),E(Sx.$$.fragment,m),E(Rx.$$.fragment,m),E(Bx.$$.fragment,m),E(M0.$$.fragment,m),E(Ix.$$.fragment,m),E(J0.$$.fragment,m),E(Nx.$$.fragment,m),E(qx.$$.fragment,m),E(Dx.$$.fragment,m),E(K0.$$.fragment,m),E(Gx.$$.fragment,m),E(dw.$$.fragment,m),E(Ox.$$.fragment,m),E(Vx.$$.fragment,m),E(zx.$$.fragment,m),E(mw.$$.fragment,m),E(Qx.$$.fragment,m),E(ww.$$.fragment,m),E(Wx.$$.fragment,m),E(Hx.$$.fragment,m),E(Jx.$$.fragment,m),E(Lw.$$.fragment,m),E(Yx.$$.fragment,m),E(qw.$$.fragment,m),E(Kx.$$.fragment,m),E(Zx.$$.fragment,m),E(o$.$$.fragment,m),E(Dw.$$.fragment,m),E(r$.$$.fragment,m),E(Yw.$$.fragment,m),E(t$.$$.fragment,m),E(a$.$$.fragment,m),E(s$.$$.fragment,m),E(Zw.$$.fragment,m),E(l$.$$.fragment,m),E(cA.$$.fragment,m),E(i$.$$.fragment,m),E(d$.$$.fragment,m),E(m$.$$.fragment,m),E(fA.$$.fragment,m),E(f$.$$.fragment,m),E(EA.$$.fragment,m),E(g$.$$.fragment,m),E(h$.$$.fragment,m),E(p$.$$.fragment,m),E(wA.$$.fragment,m),E(_$.$$.fragment,m),E(PA.$$.fragment,m),E(b$.$$.fragment,m),E(v$.$$.fragment,m),E(T$.$$.fragment,m),E(IA.$$.fragment,m),E(M$.$$.fragment,m),E(zA.$$.fragment,m),E(E$.$$.fragment,m),E(C$.$$.fragment,m),E(A$.$$.fragment,m),E(WA.$$.fragment,m),E(L$.$$.fragment,m),E(UA.$$.fragment,m),E(y$.$$.fragment,m),E(x$.$$.fragment,m),E(k$.$$.fragment,m),E(YA.$$.fragment,m),E(S$.$$.fragment,m),E(e6.$$.fragment,m),E(P$.$$.fragment,m),E(B$.$$.fragment,m),E(N$.$$.fragment,m),E(r6.$$.fragment,m),E(q$.$$.fragment,m),E(a6.$$.fragment,m),XVe=!0)},o(m){C(d.$$.fragment,m),C(xa.$$.fragment,m),C(xy.$$.fragment,m),C($y.$$.fragment,m),C(Sm.$$.fragment,m),C(ky.$$.fragment,m),C(Sy.$$.fragment,m),C(By.$$.fragment,m),C(Gg.$$.fragment,m),C(Iy.$$.fragment,m),C(Ny.$$.fragment,m),C(qy.$$.fragment,m),C(Gy.$$.fragment,m),C(Eh.$$.fragment,m),C(Oy.$$.fragment,m),C(Vy.$$.fragment,m),C(Xy.$$.fragment,m),C(Wy.$$.fragment,m),C(au.$$.fragment,m),C(nu.$$.fragment,m),C(Hy.$$.fragment,m),C(Uy.$$.fragment,m),C(Jy.$$.fragment,m),C(Zy.$$.fragment,m),C(wu.$$.fragment,m),C(Au.$$.fragment,m),C(e7.$$.fragment,m),C(o7.$$.fragment,m),C(r7.$$.fragment,m),C(a7.$$.fragment,m),C(xu.$$.fragment,m),C(n7.$$.fragment,m),C(x_.$$.fragment,m),C(s7.$$.fragment,m),C(l7.$$.fragment,m),C(d7.$$.fragment,m),C(k_.$$.fragment,m),C(c7.$$.fragment,m),C(E2.$$.fragment,m),C(m7.$$.fragment,m),C(f7.$$.fragment,m),C(h7.$$.fragment,m),C(w2.$$.fragment,m),C(u7.$$.fragment,m),C(mb.$$.fragment,m),C(p7.$$.fragment,m),C(_7.$$.fragment,m),C(v7.$$.fragment,m),C(gb.$$.fragment,m),C(F7.$$.fragment,m),C(Kb.$$.fragment,m),C(T7.$$.fragment,m),C(M7.$$.fragment,m),C(C7.$$.fragment,m),C(ev.$$.fragment,m),C(w7.$$.fragment,m),C(vv.$$.fragment,m),C(A7.$$.fragment,m),C(L7.$$.fragment,m),C(x7.$$.fragment,m),C(Tv.$$.fragment,m),C($7.$$.fragment,m),C(bF.$$.fragment,m),C(k7.$$.fragment,m),C(S7.$$.fragment,m),C(P7.$$.fragment,m),C(FF.$$.fragment,m),C(B7.$$.fragment,m),C(KF.$$.fragment,m),C(I7.$$.fragment,m),C(N7.$$.fragment,m),C(j7.$$.fragment,m),C(e1.$$.fragment,m),C(D7.$$.fragment,m),C(i1.$$.fragment,m),C(G7.$$.fragment,m),C(O7.$$.fragment,m),C(X7.$$.fragment,m),C(c1.$$.fragment,m),C(z7.$$.fragment,m),C(H1.$$.fragment,m),C(Q7.$$.fragment,m),C(W7.$$.fragment,m),C(U7.$$.fragment,m),C(J1.$$.fragment,m),C(J7.$$.fragment,m),C(jT.$$.fragment,m),C(Y7.$$.fragment,m),C(K7.$$.fragment,m),C(e8.$$.fragment,m),C(GT.$$.fragment,m),C(o8.$$.fragment,m),C(XT.$$.fragment,m),C(r8.$$.fragment,m),C(t8.$$.fragment,m),C(n8.$$.fragment,m),C(QT.$$.fragment,m),C(s8.$$.fragment,m),C(sM.$$.fragment,m),C(l8.$$.fragment,m),C(i8.$$.fragment,m),C(c8.$$.fragment,m),C(iM.$$.fragment,m),C(m8.$$.fragment,m),C(mM.$$.fragment,m),C(f8.$$.fragment,m),C(g8.$$.fragment,m),C(u8.$$.fragment,m),C(gM.$$.fragment,m),C(p8.$$.fragment,m),C(pM.$$.fragment,m),C(_8.$$.fragment,m),C(b8.$$.fragment,m),C(F8.$$.fragment,m),C(bM.$$.fragment,m),C(T8.$$.fragment,m),C(xM.$$.fragment,m),C(M8.$$.fragment,m),C(E8.$$.fragment,m),C(w8.$$.fragment,m),C(kM.$$.fragment,m),C(A8.$$.fragment,m),C(qM.$$.fragment,m),C(L8.$$.fragment,m),C(y8.$$.fragment,m),C($8.$$.fragment,m),C(DM.$$.fragment,m),C(k8.$$.fragment,m),C(KM.$$.fragment,m),C(S8.$$.fragment,m),C(R8.$$.fragment,m),C(B8.$$.fragment,m),C(eE.$$.fragment,m),C(I8.$$.fragment,m),C(aE.$$.fragment,m),C(q8.$$.fragment,m),C(j8.$$.fragment,m),C(G8.$$.fragment,m),C(sE.$$.fragment,m),C(O8.$$.fragment,m),C(gE.$$.fragment,m),C(V8.$$.fragment,m),C(X8.$$.fragment,m),C(Q8.$$.fragment,m),C(uE.$$.fragment,m),C(W8.$$.fragment,m),C(FE.$$.fragment,m),C(H8.$$.fragment,m),C(U8.$$.fragment,m),C(Y8.$$.fragment,m),C(ME.$$.fragment,m),C(K8.$$.fragment,m),C(AE.$$.fragment,m),C(e9.$$.fragment,m),C(o9.$$.fragment,m),C(t9.$$.fragment,m),C(yE.$$.fragment,m),C(a9.$$.fragment,m),C(kE.$$.fragment,m),C(n9.$$.fragment,m),C(s9.$$.fragment,m),C(i9.$$.fragment,m),C(RE.$$.fragment,m),C(d9.$$.fragment,m),C(jE.$$.fragment,m),C(c9.$$.fragment,m),C(m9.$$.fragment,m),C(g9.$$.fragment,m),C(GE.$$.fragment,m),C(h9.$$.fragment,m),C(XE.$$.fragment,m),C(u9.$$.fragment,m),C(p9.$$.fragment,m),C(b9.$$.fragment,m),C(QE.$$.fragment,m),C(v9.$$.fragment,m),C(j4.$$.fragment,m),C(F9.$$.fragment,m),C(T9.$$.fragment,m),C(E9.$$.fragment,m),C(G4.$$.fragment,m),C(C9.$$.fragment,m),C(mC.$$.fragment,m),C(w9.$$.fragment,m),C(A9.$$.fragment,m),C(y9.$$.fragment,m),C(gC.$$.fragment,m),C(x9.$$.fragment,m),C(LC.$$.fragment,m),C($9.$$.fragment,m),C(k9.$$.fragment,m),C(R9.$$.fragment,m),C(xC.$$.fragment,m),C(P9.$$.fragment,m),C(PC.$$.fragment,m),C(B9.$$.fragment,m),C(I9.$$.fragment,m),C(q9.$$.fragment,m),C(IC.$$.fragment,m),C(j9.$$.fragment,m),C(t5.$$.fragment,m),C(D9.$$.fragment,m),C(G9.$$.fragment,m),C(V9.$$.fragment,m),C(n5.$$.fragment,m),C(X9.$$.fragment,m),C(p5.$$.fragment,m),C(z9.$$.fragment,m),C(Q9.$$.fragment,m),C(H9.$$.fragment,m),C(b5.$$.fragment,m),C(U9.$$.fragment,m),C(z5.$$.fragment,m),C(J9.$$.fragment,m),C(Y9.$$.fragment,m),C(Z9.$$.fragment,m),C(W5.$$.fragment,m),C(ex.$$.fragment,m),C(m3.$$.fragment,m),C(ox.$$.fragment,m),C(rx.$$.fragment,m),C(ax.$$.fragment,m),C(g3.$$.fragment,m),C(nx.$$.fragment,m),C(p3.$$.fragment,m),C(lx.$$.fragment,m),C(ix.$$.fragment,m),C(cx.$$.fragment,m),C(b3.$$.fragment,m),C(mx.$$.fragment,m),C(F3.$$.fragment,m),C(fx.$$.fragment,m),C(gx.$$.fragment,m),C(ux.$$.fragment,m),C(M3.$$.fragment,m),C(px.$$.fragment,m),C(V3.$$.fragment,m),C(_x.$$.fragment,m),C(bx.$$.fragment,m),C(Fx.$$.fragment,m),C(z3.$$.fragment,m),C(Tx.$$.fragment,m),C(f0.$$.fragment,m),C(Mx.$$.fragment,m),C(Ex.$$.fragment,m),C(wx.$$.fragment,m),C(h0.$$.fragment,m),C(Ax.$$.fragment,m),C(p0.$$.fragment,m),C(Lx.$$.fragment,m),C(yx.$$.fragment,m),C($x.$$.fragment,m),C(b0.$$.fragment,m),C(kx.$$.fragment,m),C(F0.$$.fragment,m),C(Sx.$$.fragment,m),C(Rx.$$.fragment,m),C(Bx.$$.fragment,m),C(M0.$$.fragment,m),C(Ix.$$.fragment,m),C(J0.$$.fragment,m),C(Nx.$$.fragment,m),C(qx.$$.fragment,m),C(Dx.$$.fragment,m),C(K0.$$.fragment,m),C(Gx.$$.fragment,m),C(dw.$$.fragment,m),C(Ox.$$.fragment,m),C(Vx.$$.fragment,m),C(zx.$$.fragment,m),C(mw.$$.fragment,m),C(Qx.$$.fragment,m),C(ww.$$.fragment,m),C(Wx.$$.fragment,m),C(Hx.$$.fragment,m),C(Jx.$$.fragment,m),C(Lw.$$.fragment,m),C(Yx.$$.fragment,m),C(qw.$$.fragment,m),C(Kx.$$.fragment,m),C(Zx.$$.fragment,m),C(o$.$$.fragment,m),C(Dw.$$.fragment,m),C(r$.$$.fragment,m),C(Yw.$$.fragment,m),C(t$.$$.fragment,m),C(a$.$$.fragment,m),C(s$.$$.fragment,m),C(Zw.$$.fragment,m),C(l$.$$.fragment,m),C(cA.$$.fragment,m),C(i$.$$.fragment,m),C(d$.$$.fragment,m),C(m$.$$.fragment,m),C(fA.$$.fragment,m),C(f$.$$.fragment,m),C(EA.$$.fragment,m),C(g$.$$.fragment,m),C(h$.$$.fragment,m),C(p$.$$.fragment,m),C(wA.$$.fragment,m),C(_$.$$.fragment,m),C(PA.$$.fragment,m),C(b$.$$.fragment,m),C(v$.$$.fragment,m),C(T$.$$.fragment,m),C(IA.$$.fragment,m),C(M$.$$.fragment,m),C(zA.$$.fragment,m),C(E$.$$.fragment,m),C(C$.$$.fragment,m),C(A$.$$.fragment,m),C(WA.$$.fragment,m),C(L$.$$.fragment,m),C(UA.$$.fragment,m),C(y$.$$.fragment,m),C(x$.$$.fragment,m),C(k$.$$.fragment,m),C(YA.$$.fragment,m),C(S$.$$.fragment,m),C(e6.$$.fragment,m),C(P$.$$.fragment,m),C(B$.$$.fragment,m),C(N$.$$.fragment,m),C(r6.$$.fragment,m),C(q$.$$.fragment,m),C(a6.$$.fragment,m),XVe=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Lm),m&&t(at),m&&t(Oe),m&&t(Qe),m&&t(xm),w(xa,m),m&&t(We),m&&t(Ae),m&&t(Co),m&&t($a),m&&t(jGe),m&&t(yi),w(xy),m&&t(DGe),m&&t(Nn),m&&t(GGe),w($y,m),m&&t(OGe),m&&t(lS),m&&t(VGe),w(Sm,m),m&&t(XGe),m&&t(xi),w(ky),m&&t(zGe),m&&t(wo),w(Sy),w(By),w(Gg),w(Iy),m&&t(QGe),m&&t(ki),w(Ny),m&&t(WGe),m&&t(Ao),w(qy),w(Gy),w(Eh),w(Oy),m&&t(HGe),m&&t(Si),w(Vy),m&&t(UGe),m&&t(Lo),w(Xy),w(Wy),w(au),w(nu),w(Hy),m&&t(JGe),m&&t(Ri),w(Uy),m&&t(YGe),m&&t(yo),w(Jy),w(Zy),w(wu),w(Au),w(e7),m&&t(KGe),m&&t(Bi),w(o7),m&&t(ZGe),m&&t(xo),w(r7),w(a7),w(xu),w(n7),w(x_),m&&t(eOe),m&&t(qi),w(s7),m&&t(oOe),m&&t($o),w(l7),w(d7),w(k_),w(c7),w(E2),m&&t(rOe),m&&t(Gi),w(m7),m&&t(tOe),m&&t(ko),w(f7),w(h7),w(w2),w(u7),w(mb),m&&t(aOe),m&&t(Xi),w(p7),m&&t(nOe),m&&t(So),w(_7),w(v7),w(gb),w(F7),w(Kb),m&&t(sOe),m&&t(Wi),w(T7),m&&t(lOe),m&&t(Ro),w(M7),w(C7),w(ev),w(w7),w(vv),m&&t(iOe),m&&t(Ji),w(A7),m&&t(dOe),m&&t(Po),w(L7),w(x7),w(Tv),w($7),w(bF),m&&t(cOe),m&&t(Zi),w(k7),m&&t(mOe),m&&t(Bo),w(S7),w(P7),w(FF),w(B7),w(KF),m&&t(fOe),m&&t(rd),w(I7),m&&t(gOe),m&&t(Io),w(N7),w(j7),w(e1),w(D7),w(i1),m&&t(hOe),m&&t(nd),w(G7),m&&t(uOe),m&&t(qo),w(O7),w(X7),w(c1),w(z7),w(H1),m&&t(pOe),m&&t(id),w(Q7),m&&t(_Oe),m&&t(jo),w(W7),w(U7),w(J1),w(J7),w(jT),m&&t(bOe),m&&t(md),w(Y7),m&&t(vOe),m&&t(Do),w(K7),w(e8),w(GT),w(o8),w(XT),m&&t(FOe),m&&t(hd),w(r8),m&&t(TOe),m&&t(Go),w(t8),w(n8),w(QT),w(s8),w(sM),m&&t(MOe),m&&t(_d),w(l8),m&&t(EOe),m&&t(Oo),w(i8),w(c8),w(iM),w(m8),w(mM),m&&t(COe),m&&t(Fd),w(f8),m&&t(wOe),m&&t(Vo),w(g8),w(u8),w(gM),w(p8),w(pM),m&&t(AOe),m&&t(Ed),w(_8),m&&t(LOe),m&&t(Xo),w(b8),w(F8),w(bM),w(T8),w(xM),m&&t(yOe),m&&t(Ad),w(M8),m&&t(xOe),m&&t(zo),w(E8),w(w8),w(kM),w(A8),w(qM),m&&t($Oe),m&&t(xd),w(L8),m&&t(kOe),m&&t(Qo),w(y8),w($8),w(DM),w(k8),w(KM),m&&t(SOe),m&&t(Sd),w(S8),m&&t(ROe),m&&t(Wo),w(R8),w(B8),w(eE),w(I8),w(aE),m&&t(POe),m&&t(Bd),w(q8),m&&t(BOe),m&&t(Ho),w(j8),w(G8),w(sE),w(O8),w(gE),m&&t(IOe),m&&t(qd),w(V8),m&&t(NOe),m&&t(Uo),w(X8),w(Q8),w(uE),w(W8),w(FE),m&&t(qOe),m&&t(Od),w(H8),m&&t(jOe),m&&t(Jo),w(U8),w(Y8),w(ME),w(K8),w(AE),m&&t(DOe),m&&t(zd),w(e9),m&&t(GOe),m&&t(Yo),w(o9),w(t9),w(yE),w(a9),w(kE),m&&t(OOe),m&&t(Hd),w(n9),m&&t(VOe),m&&t(Ko),w(s9),w(i9),w(RE),w(d9),w(jE),m&&t(XOe),m&&t(Yd),w(c9),m&&t(zOe),m&&t(Zo),w(m9),w(g9),w(GE),w(h9),w(XE),m&&t(QOe),m&&t(ec),w(u9),m&&t(WOe),m&&t(er),w(p9),w(b9),w(QE),w(v9),w(j4),m&&t(HOe),m&&t(tc),w(F9),m&&t(UOe),m&&t(or),w(T9),w(E9),w(G4),w(C9),w(mC),m&&t(JOe),m&&t(sc),w(w9),m&&t(YOe),m&&t(rr),w(A9),w(y9),w(gC),w(x9),w(LC),m&&t(KOe),m&&t(dc),w($9),m&&t(ZOe),m&&t(tr),w(k9),w(R9),w(xC),w(P9),w(PC),m&&t(eVe),m&&t(fc),w(B9),m&&t(oVe),m&&t(ar),w(I9),w(q9),w(IC),w(j9),w(t5),m&&t(rVe),m&&t(uc),w(D9),m&&t(tVe),m&&t(nr),w(G9),w(V9),w(n5),w(X9),w(p5),m&&t(aVe),m&&t(bc),w(z9),m&&t(nVe),m&&t(sr),w(Q9),w(H9),w(b5),w(U9),w(z5),m&&t(sVe),m&&t(Tc),w(J9),m&&t(lVe),m&&t(lr),w(Y9),w(Z9),w(W5),w(ex),w(m3),m&&t(iVe),m&&t(Cc),w(ox),m&&t(dVe),m&&t(ir),w(rx),w(ax),w(g3),w(nx),w(p3),m&&t(cVe),m&&t(Lc),w(lx),m&&t(mVe),m&&t(dr),w(ix),w(cx),w(b3),w(mx),w(F3),m&&t(fVe),m&&t($c),w(fx),m&&t(gVe),m&&t(cr),w(gx),w(ux),w(M3),w(px),w(V3),m&&t(hVe),m&&t(Rc),w(_x),m&&t(uVe),m&&t(mr),w(bx),w(Fx),w(z3),w(Tx),w(f0),m&&t(pVe),m&&t(Ic),w(Mx),m&&t(_Ve),m&&t(fr),w(Ex),w(wx),w(h0),w(Ax),w(p0),m&&t(bVe),m&&t(jc),w(Lx),m&&t(vVe),m&&t(gr),w(yx),w($x),w(b0),w(kx),w(F0),m&&t(FVe),m&&t(Oc),w(Sx),m&&t(TVe),m&&t(hr),w(Rx),w(Bx),w(M0),w(Ix),w(J0),m&&t(MVe),m&&t(zc),w(Nx),m&&t(EVe),m&&t(ur),w(qx),w(Dx),w(K0),w(Gx),w(dw),m&&t(CVe),m&&t(Hc),w(Ox),m&&t(wVe),m&&t(pr),w(Vx),w(zx),w(mw),w(Qx),w(ww),m&&t(AVe),m&&t(Yc),w(Wx),m&&t(LVe),m&&t(_r),w(Hx),w(Jx),w(Lw),w(Yx),w(qw),m&&t(yVe),m&&t(em),w(Kx),m&&t(xVe),m&&t(br),w(Zx),w(o$),w(Dw),w(r$),w(Yw),m&&t($Ve),m&&t(tm),w(t$),m&&t(kVe),m&&t(vr),w(a$),w(s$),w(Zw),w(l$),w(cA),m&&t(SVe),m&&t(sm),w(i$),m&&t(RVe),m&&t(Fr),w(d$),w(m$),w(fA),w(f$),w(EA),m&&t(PVe),m&&t(dm),w(g$),m&&t(BVe),m&&t(Tr),w(h$),w(p$),w(wA),w(_$),w(PA),m&&t(IVe),m&&t(fm),w(b$),m&&t(NVe),m&&t(Mr),w(v$),w(T$),w(IA),w(M$),w(zA),m&&t(qVe),m&&t(um),w(E$),m&&t(jVe),m&&t(Er),w(C$),w(A$),w(WA),w(L$),w(UA),m&&t(DVe),m&&t(bm),w(y$),m&&t(GVe),m&&t(Cr),w(x$),w(k$),w(YA),w(S$),w(e6),m&&t(OVe),m&&t(Tm),w(P$),m&&t(VVe),m&&t(wr),w(B$),w(N$),w(r6),w(q$),w(a6)}}}const COt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function wOt(x){return EDt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class SOt extends vDt{constructor(g){super();FDt(this,g,wOt,EOt,TDt,{})}}export{SOt as default,COt as metadata};
