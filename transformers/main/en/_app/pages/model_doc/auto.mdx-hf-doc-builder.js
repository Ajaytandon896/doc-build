import{S as Ifa,i as Nfa,s as qfa,e as a,k as l,w as F,t as o,M as jfa,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as Dfa,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as Dbt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Gfa($){let g,v,u,f,p,d,h,yo,rd,Mf,pt,td,ad,v9,Ef,Ve,He,nd,Zn,F9,es,os,T9,sd,rs,M9,ld,Cf,Qa;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),rd=a("code"),Mf=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),td=a("code"),ad=o('"new-model"'),v9=o(")."),Ef=l(),Ve=a("p"),He=o("Likewise, if your "),nd=a("code"),Zn=o("NewModel"),F9=o(" is a subclass of "),es=a("a"),os=o("PreTrainedModel"),T9=o(`, make sure its
`),sd=a("code"),rs=o("config_class"),M9=o(` attribute is set to the same class you use when registering the model (here
`),ld=a("code"),Cf=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var CB=s(u);f=r(CB,"NewModelConfig"),CB.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var id=s(d);h=r(id,"PretrainedConfig"),id.forEach(t),yo=r(Ae,`, make sure its
`),rd=n(Ae,"CODE",{});var wB=s(rd);Mf=r(wB,"model_type"),wB.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),td=n(Ae,"CODE",{});var AB=s(td);ad=r(AB,'"new-model"'),AB.forEach(t),v9=r(Ae,")."),Ae.forEach(t),Ef=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),nd=n(xo,"CODE",{});var Wa=s(nd);Zn=r(Wa,"NewModel"),Wa.forEach(t),F9=r(xo," is a subclass of "),es=n(xo,"A",{href:!0});var LB=s(es);os=r(LB,"PreTrainedModel"),LB.forEach(t),T9=r(xo,`, make sure its
`),sd=n(xo,"CODE",{});var wf=s(sd);rs=r(wf,"config_class"),wf.forEach(t),M9=r(xo,` attribute is set to the same class you use when registering the model (here
`),ld=n(xo,"CODE",{});var yB=s(ld);Cf=r(yB,"NewModelConfig"),yB.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){c(es,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,yo),e(g,rd),e(rd,Mf),e(g,pt),e(g,td),e(td,ad),e(g,v9),b(Je,Ef,Ae),b(Je,Ve,Ae),e(Ve,He),e(Ve,nd),e(nd,Zn),e(Ve,F9),e(Ve,es),e(es,os),e(Ve,T9),e(Ve,sd),e(sd,rs),e(Ve,M9),e(Ve,ld),e(ld,Cf),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(Ef),Je&&t(Ve)}}}function Ofa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Xfa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function zfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Qfa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function Wfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Ufa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Hfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Jfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Yfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Kfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Zfa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ega($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _ga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Tga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Ega($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Aga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $ga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Sga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Bga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Nga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Dga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Gga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Oga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Xga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Qga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Wga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Uga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Hga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Jga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Yga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Kga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Zga($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _ha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Tha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Eha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Aha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $ha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Sha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Bha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Nha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Dha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Gha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Oha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Xha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Qha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Wha($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Uha($){let g,v,u,f,p,d,h,yo,rd,Mf,pt,td,ad,v9,Ef,Ve,He,nd,Zn,F9,es,os,T9,sd,rs,M9,ld,Cf,Qa,Je,Ae,CB,id,wB,AB,xo,Wa,LB,wf,yB,iro,kYe,dd,Af,Hie,E9,dro,Jie,cro,SYe,ts,mro,Yie,fro,gro,Kie,hro,uro,RYe,C9,PYe,xB,pro,BYe,Lf,IYe,cd,yf,Zie,w9,_ro,ede,bro,NYe,$o,A9,vro,L9,Fro,$B,Tro,Mro,Ero,y9,Cro,ode,wro,Aro,Lro,Pr,x9,yro,rde,xro,$ro,md,kro,tde,Sro,Rro,ade,Pro,Bro,Iro,A,xf,nde,Nro,qro,kB,jro,Dro,Gro,$f,sde,Oro,Vro,SB,Xro,zro,Qro,kf,lde,Wro,Uro,RB,Hro,Jro,Yro,Sf,ide,Kro,Zro,PB,eto,oto,rto,Rf,dde,tto,ato,BB,nto,sto,lto,Pf,cde,ito,dto,IB,cto,mto,fto,Bf,mde,gto,hto,NB,uto,pto,_to,If,fde,bto,vto,qB,Fto,Tto,Mto,Nf,gde,Eto,Cto,jB,wto,Ato,Lto,qf,hde,yto,xto,DB,$to,kto,Sto,jf,ude,Rto,Pto,GB,Bto,Ito,Nto,Df,pde,qto,jto,OB,Dto,Gto,Oto,Gf,_de,Vto,Xto,VB,zto,Qto,Wto,Of,bde,Uto,Hto,XB,Jto,Yto,Kto,Vf,vde,Zto,eao,zB,oao,rao,tao,Xf,Fde,aao,nao,QB,sao,lao,iao,zf,Tde,dao,cao,WB,mao,fao,gao,Qf,Mde,hao,uao,UB,pao,_ao,bao,Wf,Ede,vao,Fao,HB,Tao,Mao,Eao,Uf,Cde,Cao,wao,JB,Aao,Lao,yao,Hf,wde,xao,$ao,YB,kao,Sao,Rao,Jf,Ade,Pao,Bao,KB,Iao,Nao,qao,Yf,Lde,jao,Dao,ZB,Gao,Oao,Vao,Kf,yde,Xao,zao,eI,Qao,Wao,Uao,Zf,xde,Hao,Jao,oI,Yao,Kao,Zao,eg,$de,eno,ono,rI,rno,tno,ano,og,kde,nno,sno,tI,lno,ino,dno,rg,Sde,cno,mno,aI,fno,gno,hno,tg,Rde,uno,pno,nI,_no,bno,vno,ag,Pde,Fno,Tno,sI,Mno,Eno,Cno,ng,Bde,wno,Ano,lI,Lno,yno,xno,sg,Ide,$no,kno,iI,Sno,Rno,Pno,lg,Nde,Bno,Ino,dI,Nno,qno,jno,ig,qde,Dno,Gno,cI,Ono,Vno,Xno,dg,jde,zno,Qno,mI,Wno,Uno,Hno,cg,Dde,Jno,Yno,fI,Kno,Zno,eso,mg,Gde,oso,rso,gI,tso,aso,nso,fg,Ode,sso,lso,hI,iso,dso,cso,gg,Vde,mso,fso,uI,gso,hso,uso,hg,Xde,pso,_so,pI,bso,vso,Fso,ug,zde,Tso,Mso,_I,Eso,Cso,wso,pg,Qde,Aso,Lso,bI,yso,xso,$so,_g,Wde,kso,Sso,vI,Rso,Pso,Bso,bg,Ude,Iso,Nso,FI,qso,jso,Dso,vg,Hde,Gso,Oso,TI,Vso,Xso,zso,Fg,Jde,Qso,Wso,MI,Uso,Hso,Jso,Tg,Yde,Yso,Kso,EI,Zso,elo,olo,Mg,Kde,rlo,tlo,CI,alo,nlo,slo,Eg,Zde,llo,ilo,wI,dlo,clo,mlo,Cg,ece,flo,glo,AI,hlo,ulo,plo,wg,oce,_lo,blo,LI,vlo,Flo,Tlo,Ag,rce,Mlo,Elo,yI,Clo,wlo,Alo,Lg,tce,Llo,ylo,xI,xlo,$lo,klo,yg,ace,Slo,Rlo,$I,Plo,Blo,Ilo,xg,nce,Nlo,qlo,kI,jlo,Dlo,Glo,$g,sce,Olo,Vlo,SI,Xlo,zlo,Qlo,kg,lce,Wlo,Ulo,RI,Hlo,Jlo,Ylo,Sg,ice,Klo,Zlo,PI,eio,oio,rio,Rg,dce,tio,aio,BI,nio,sio,lio,Pg,cce,iio,dio,II,cio,mio,fio,Bg,mce,gio,hio,NI,uio,pio,_io,Ig,fce,bio,vio,qI,Fio,Tio,Mio,Ng,gce,Eio,Cio,jI,wio,Aio,Lio,qg,hce,yio,xio,DI,$io,kio,Sio,jg,uce,Rio,Pio,GI,Bio,Iio,Nio,Dg,pce,qio,jio,OI,Dio,Gio,Oio,Gg,_ce,Vio,Xio,VI,zio,Qio,Wio,Og,bce,Uio,Hio,XI,Jio,Yio,Kio,Vg,vce,Zio,edo,zI,odo,rdo,tdo,Xg,Fce,ado,ndo,QI,sdo,ldo,ido,zg,Tce,ddo,cdo,WI,mdo,fdo,gdo,Qg,Mce,hdo,udo,UI,pdo,_do,bdo,Wg,Ece,vdo,Fdo,HI,Tdo,Mdo,Edo,Ug,Cce,Cdo,wdo,JI,Ado,Ldo,ydo,Hg,wce,xdo,$do,YI,kdo,Sdo,Rdo,Jg,Ace,Pdo,Bdo,KI,Ido,Ndo,qdo,Yg,Lce,jdo,Ddo,ZI,Gdo,Odo,Vdo,Kg,yce,Xdo,zdo,eN,Qdo,Wdo,Udo,Zg,xce,Hdo,Jdo,oN,Ydo,Kdo,Zdo,eh,$ce,eco,oco,rN,rco,tco,aco,oh,kce,nco,sco,tN,lco,ico,dco,rh,Sce,cco,mco,aN,fco,gco,hco,th,Rce,uco,pco,nN,_co,bco,vco,ah,Pce,Fco,Tco,sN,Mco,Eco,Cco,nh,Bce,wco,Aco,lN,Lco,yco,xco,sh,Ice,$co,kco,iN,Sco,Rco,Pco,lh,Nce,Bco,Ico,dN,Nco,qco,jco,ih,qce,Dco,Gco,cN,Oco,Vco,Xco,dh,jce,zco,Qco,mN,Wco,Uco,Hco,ch,Dce,Jco,Yco,fN,Kco,Zco,emo,mh,Gce,omo,rmo,gN,tmo,amo,nmo,fh,Oce,smo,lmo,hN,imo,dmo,cmo,gh,Vce,mmo,fmo,uN,gmo,hmo,umo,hh,Xce,pmo,_mo,pN,bmo,vmo,Fmo,uh,zce,Tmo,Mmo,_N,Emo,Cmo,wmo,ph,Qce,Amo,Lmo,bN,ymo,xmo,$mo,_h,Wce,kmo,Smo,vN,Rmo,Pmo,Bmo,bh,Uce,Imo,Nmo,FN,qmo,jmo,Dmo,vh,Hce,Gmo,Omo,TN,Vmo,Xmo,zmo,Fh,Jce,Qmo,Wmo,MN,Umo,Hmo,Jmo,Th,Yce,Ymo,Kmo,EN,Zmo,efo,ofo,Mh,Kce,rfo,tfo,CN,afo,nfo,sfo,Eh,Zce,lfo,ifo,wN,dfo,cfo,mfo,Ch,eme,ffo,gfo,AN,hfo,ufo,pfo,wh,ome,_fo,bfo,LN,vfo,Ffo,Tfo,Ah,rme,Mfo,Efo,yN,Cfo,wfo,Afo,Lh,tme,Lfo,yfo,xN,xfo,$fo,kfo,yh,ame,Sfo,Rfo,$N,Pfo,Bfo,Ifo,xh,nme,Nfo,qfo,kN,jfo,Dfo,Gfo,$h,sme,Ofo,Vfo,SN,Xfo,zfo,Qfo,kh,lme,Wfo,Ufo,RN,Hfo,Jfo,Yfo,Sh,ime,Kfo,Zfo,PN,ego,ogo,rgo,Rh,dme,tgo,ago,BN,ngo,sgo,lgo,Ph,cme,igo,dgo,IN,cgo,mgo,fgo,Bh,mme,ggo,hgo,NN,ugo,pgo,_go,Ih,fme,bgo,vgo,qN,Fgo,Tgo,Mgo,Nh,gme,Ego,Cgo,jN,wgo,Ago,Lgo,qh,hme,ygo,xgo,DN,$go,kgo,Sgo,jh,ume,Rgo,Pgo,GN,Bgo,Igo,Ngo,Dh,pme,qgo,jgo,ON,Dgo,Ggo,Ogo,Gh,_me,Vgo,Xgo,VN,zgo,Qgo,Wgo,Oh,bme,Ugo,Hgo,XN,Jgo,Ygo,Kgo,Vh,vme,Zgo,eho,zN,oho,rho,tho,Xh,Fme,aho,nho,QN,sho,lho,iho,zh,Tme,dho,cho,WN,mho,fho,gho,Qh,hho,Wh,$9,uho,Mme,pho,qYe,fd,Uh,Eme,k9,_ho,Cme,bho,jYe,ko,S9,vho,R9,Fho,UN,Tho,Mho,Eho,P9,Cho,wme,who,Aho,Lho,Br,B9,yho,Ame,xho,$ho,Ua,kho,Lme,Sho,Rho,yme,Pho,Bho,xme,Iho,Nho,qho,k,as,$me,jho,Dho,HN,Gho,Oho,JN,Vho,Xho,zho,ns,kme,Qho,Who,YN,Uho,Hho,KN,Jho,Yho,Kho,ss,Sme,Zho,euo,ZN,ouo,ruo,eq,tuo,auo,nuo,Hh,Rme,suo,luo,oq,iuo,duo,cuo,ls,Pme,muo,fuo,rq,guo,huo,tq,uuo,puo,_uo,Jh,Bme,buo,vuo,aq,Fuo,Tuo,Muo,Yh,Ime,Euo,Cuo,nq,wuo,Auo,Luo,Kh,Nme,yuo,xuo,sq,$uo,kuo,Suo,is,qme,Ruo,Puo,lq,Buo,Iuo,iq,Nuo,quo,juo,ds,jme,Duo,Guo,dq,Ouo,Vuo,cq,Xuo,zuo,Quo,cs,Dme,Wuo,Uuo,mq,Huo,Juo,fq,Yuo,Kuo,Zuo,Zh,Gme,epo,opo,gq,rpo,tpo,apo,eu,Ome,npo,spo,hq,lpo,ipo,dpo,ou,Vme,cpo,mpo,uq,fpo,gpo,hpo,ms,Xme,upo,ppo,pq,_po,bpo,_q,vpo,Fpo,Tpo,ru,zme,Mpo,Epo,bq,Cpo,wpo,Apo,fs,Qme,Lpo,ypo,vq,xpo,$po,Fq,kpo,Spo,Rpo,gs,Wme,Ppo,Bpo,Tq,Ipo,Npo,Mq,qpo,jpo,Dpo,hs,Ume,Gpo,Opo,Eq,Vpo,Xpo,Cq,zpo,Qpo,Wpo,us,Hme,Upo,Hpo,wq,Jpo,Ypo,Aq,Kpo,Zpo,e_o,tu,Jme,o_o,r_o,Lq,t_o,a_o,n_o,ps,Yme,s_o,l_o,yq,i_o,d_o,xq,c_o,m_o,f_o,_s,Kme,g_o,h_o,$q,u_o,p_o,kq,__o,b_o,v_o,bs,Zme,F_o,T_o,Sq,M_o,E_o,Rq,C_o,w_o,A_o,vs,efe,L_o,y_o,Pq,x_o,$_o,Bq,k_o,S_o,R_o,Fs,ofe,P_o,B_o,Iq,I_o,N_o,Nq,q_o,j_o,D_o,Ts,rfe,G_o,O_o,qq,V_o,X_o,jq,z_o,Q_o,W_o,Ms,tfe,U_o,H_o,Dq,J_o,Y_o,Gq,K_o,Z_o,e2o,au,afe,o2o,r2o,Oq,t2o,a2o,n2o,Es,nfe,s2o,l2o,Vq,i2o,d2o,Xq,c2o,m2o,f2o,nu,sfe,g2o,h2o,zq,u2o,p2o,_2o,Cs,lfe,b2o,v2o,Qq,F2o,T2o,Wq,M2o,E2o,C2o,ws,ife,w2o,A2o,Uq,L2o,y2o,Hq,x2o,$2o,k2o,As,dfe,S2o,R2o,Jq,P2o,B2o,Yq,I2o,N2o,q2o,su,cfe,j2o,D2o,Kq,G2o,O2o,V2o,Ls,mfe,X2o,z2o,Zq,Q2o,W2o,ej,U2o,H2o,J2o,ys,ffe,Y2o,K2o,oj,Z2o,ebo,rj,obo,rbo,tbo,xs,gfe,abo,nbo,tj,sbo,lbo,aj,ibo,dbo,cbo,lu,hfe,mbo,fbo,nj,gbo,hbo,ubo,$s,ufe,pbo,_bo,sj,bbo,vbo,lj,Fbo,Tbo,Mbo,ks,pfe,Ebo,Cbo,ij,wbo,Abo,dj,Lbo,ybo,xbo,Ss,_fe,$bo,kbo,cj,Sbo,Rbo,mj,Pbo,Bbo,Ibo,Rs,bfe,Nbo,qbo,fj,jbo,Dbo,gj,Gbo,Obo,Vbo,Ps,vfe,Xbo,zbo,hj,Qbo,Wbo,uj,Ubo,Hbo,Jbo,Bs,Ffe,Ybo,Kbo,pj,Zbo,e1o,_j,o1o,r1o,t1o,Is,Tfe,a1o,n1o,bj,s1o,l1o,vj,i1o,d1o,c1o,Ns,Mfe,m1o,f1o,Fj,g1o,h1o,Tj,u1o,p1o,_1o,iu,Efe,b1o,v1o,Mj,F1o,T1o,M1o,qs,Cfe,E1o,C1o,Ej,w1o,A1o,Cj,L1o,y1o,x1o,du,wfe,$1o,k1o,wj,S1o,R1o,P1o,cu,Afe,B1o,I1o,Aj,N1o,q1o,j1o,js,Lfe,D1o,G1o,Lj,O1o,V1o,yj,X1o,z1o,Q1o,Ds,yfe,W1o,U1o,xj,H1o,J1o,$j,Y1o,K1o,Z1o,Gs,xfe,evo,ovo,kj,rvo,tvo,Sj,avo,nvo,svo,mu,$fe,lvo,ivo,Rj,dvo,cvo,mvo,Os,kfe,fvo,gvo,Pj,hvo,uvo,Bj,pvo,_vo,bvo,Vs,Sfe,vvo,Fvo,Ij,Tvo,Mvo,Nj,Evo,Cvo,wvo,Xs,Rfe,Avo,Lvo,qj,yvo,xvo,jj,$vo,kvo,Svo,zs,Pfe,Rvo,Pvo,Dj,Bvo,Ivo,Gj,Nvo,qvo,jvo,Qs,Bfe,Dvo,Gvo,Oj,Ovo,Vvo,Vj,Xvo,zvo,Qvo,Ws,Ife,Wvo,Uvo,Xj,Hvo,Jvo,zj,Yvo,Kvo,Zvo,Us,Nfe,eFo,oFo,Qj,rFo,tFo,Wj,aFo,nFo,sFo,Hs,qfe,lFo,iFo,Uj,dFo,cFo,Hj,mFo,fFo,gFo,fu,jfe,hFo,uFo,Jj,pFo,_Fo,bFo,Js,Dfe,vFo,FFo,Yj,TFo,MFo,Kj,EFo,CFo,wFo,Ys,Gfe,AFo,LFo,Zj,yFo,xFo,eD,$Fo,kFo,SFo,gu,Ofe,RFo,PFo,oD,BFo,IFo,NFo,hu,Vfe,qFo,jFo,rD,DFo,GFo,OFo,uu,Xfe,VFo,XFo,tD,zFo,QFo,WFo,pu,zfe,UFo,HFo,aD,JFo,YFo,KFo,Ks,Qfe,ZFo,eTo,nD,oTo,rTo,sD,tTo,aTo,nTo,_u,Wfe,sTo,lTo,lD,iTo,dTo,cTo,Zs,Ufe,mTo,fTo,iD,gTo,hTo,dD,uTo,pTo,_To,el,Hfe,bTo,vTo,cD,FTo,TTo,mD,MTo,ETo,CTo,ol,Jfe,wTo,ATo,fD,LTo,yTo,gD,xTo,$To,kTo,rl,Yfe,STo,RTo,hD,PTo,BTo,uD,ITo,NTo,qTo,tl,Kfe,jTo,DTo,pD,GTo,OTo,_D,VTo,XTo,zTo,al,Zfe,QTo,WTo,bD,UTo,HTo,vD,JTo,YTo,KTo,bu,ege,ZTo,eMo,FD,oMo,rMo,tMo,vu,oge,aMo,nMo,TD,sMo,lMo,iMo,nl,rge,dMo,cMo,MD,mMo,fMo,ED,gMo,hMo,uMo,sl,tge,pMo,_Mo,CD,bMo,vMo,wD,FMo,TMo,MMo,ll,age,EMo,CMo,AD,wMo,AMo,LD,LMo,yMo,xMo,Fu,nge,$Mo,kMo,yD,SMo,RMo,PMo,Tu,sge,BMo,IMo,xD,NMo,qMo,jMo,Mu,lge,DMo,GMo,$D,OMo,VMo,XMo,il,ige,zMo,QMo,kD,WMo,UMo,SD,HMo,JMo,YMo,dl,dge,KMo,ZMo,RD,eEo,oEo,PD,rEo,tEo,aEo,Eu,cge,nEo,sEo,BD,lEo,iEo,dEo,Cu,mge,cEo,mEo,ID,fEo,gEo,hEo,wu,fge,uEo,pEo,ND,_Eo,bEo,vEo,cl,gge,FEo,TEo,qD,MEo,EEo,jD,CEo,wEo,AEo,ml,hge,LEo,yEo,DD,xEo,$Eo,GD,kEo,SEo,REo,Au,uge,PEo,BEo,OD,IEo,NEo,qEo,Lu,pge,jEo,DEo,VD,GEo,OEo,VEo,fl,_ge,XEo,zEo,XD,QEo,WEo,zD,UEo,HEo,JEo,gl,bge,YEo,KEo,QD,ZEo,e4o,WD,o4o,r4o,t4o,hl,vge,a4o,n4o,UD,s4o,l4o,HD,i4o,d4o,c4o,ul,Fge,m4o,f4o,JD,g4o,h4o,YD,u4o,p4o,_4o,yu,b4o,xu,I9,v4o,Tge,F4o,DYe,gd,$u,Mge,N9,T4o,Ege,M4o,GYe,So,q9,E4o,j9,C4o,KD,w4o,A4o,L4o,D9,y4o,Cge,x4o,$4o,k4o,Ye,G9,S4o,wge,R4o,P4o,Ha,B4o,Age,I4o,N4o,Lge,q4o,j4o,yge,D4o,G4o,O4o,W,ku,xge,V4o,X4o,ZD,z4o,Q4o,W4o,Su,$ge,U4o,H4o,eG,J4o,Y4o,K4o,Ru,kge,Z4o,eCo,oG,oCo,rCo,tCo,Pu,Sge,aCo,nCo,rG,sCo,lCo,iCo,Bu,Rge,dCo,cCo,tG,mCo,fCo,gCo,Iu,Pge,hCo,uCo,aG,pCo,_Co,bCo,Nu,Bge,vCo,FCo,nG,TCo,MCo,ECo,qu,Ige,CCo,wCo,sG,ACo,LCo,yCo,ju,Nge,xCo,$Co,lG,kCo,SCo,RCo,Du,qge,PCo,BCo,iG,ICo,NCo,qCo,Gu,jge,jCo,DCo,dG,GCo,OCo,VCo,Ou,Dge,XCo,zCo,cG,QCo,WCo,UCo,Vu,Gge,HCo,JCo,mG,YCo,KCo,ZCo,Xu,Oge,e3o,o3o,fG,r3o,t3o,a3o,zu,Vge,n3o,s3o,gG,l3o,i3o,d3o,Qu,Xge,c3o,m3o,hG,f3o,g3o,h3o,Wu,zge,u3o,p3o,uG,_3o,b3o,v3o,Uu,Qge,F3o,T3o,pG,M3o,E3o,C3o,Hu,Wge,w3o,A3o,_G,L3o,y3o,x3o,Ju,Uge,$3o,k3o,bG,S3o,R3o,P3o,Yu,Hge,B3o,I3o,vG,N3o,q3o,j3o,Ku,Jge,D3o,G3o,FG,O3o,V3o,X3o,Zu,Yge,z3o,Q3o,TG,W3o,U3o,H3o,ep,Kge,J3o,Y3o,MG,K3o,Z3o,e5o,op,Zge,o5o,r5o,EG,t5o,a5o,n5o,rp,ehe,s5o,l5o,CG,i5o,d5o,c5o,tp,ohe,m5o,f5o,wG,g5o,h5o,u5o,ap,rhe,p5o,_5o,AG,b5o,v5o,F5o,np,the,T5o,M5o,LG,E5o,C5o,w5o,sp,ahe,A5o,L5o,yG,y5o,x5o,$5o,lp,nhe,k5o,S5o,xG,R5o,P5o,B5o,ip,she,I5o,N5o,$G,q5o,j5o,D5o,dp,lhe,G5o,O5o,kG,V5o,X5o,z5o,cp,ihe,Q5o,W5o,SG,U5o,H5o,J5o,mp,dhe,Y5o,K5o,RG,Z5o,e0o,o0o,fp,che,r0o,t0o,PG,a0o,n0o,s0o,gp,mhe,l0o,i0o,BG,d0o,c0o,m0o,hp,fhe,f0o,g0o,IG,h0o,u0o,p0o,up,ghe,_0o,b0o,NG,v0o,F0o,T0o,pp,M0o,_p,E0o,bp,O9,C0o,hhe,w0o,OYe,hd,vp,uhe,V9,A0o,phe,L0o,VYe,Ro,X9,y0o,z9,x0o,qG,$0o,k0o,S0o,Q9,R0o,_he,P0o,B0o,I0o,Ke,W9,N0o,bhe,q0o,j0o,ud,D0o,vhe,G0o,O0o,Fhe,V0o,X0o,z0o,ie,Fp,The,Q0o,W0o,jG,U0o,H0o,J0o,Tp,Mhe,Y0o,K0o,DG,Z0o,ewo,owo,Mp,Ehe,rwo,two,GG,awo,nwo,swo,Ep,Che,lwo,iwo,OG,dwo,cwo,mwo,Cp,whe,fwo,gwo,VG,hwo,uwo,pwo,wp,Ahe,_wo,bwo,XG,vwo,Fwo,Two,Ap,Lhe,Mwo,Ewo,zG,Cwo,wwo,Awo,Lp,yhe,Lwo,ywo,QG,xwo,$wo,kwo,yp,xhe,Swo,Rwo,WG,Pwo,Bwo,Iwo,xp,$he,Nwo,qwo,UG,jwo,Dwo,Gwo,$p,khe,Owo,Vwo,HG,Xwo,zwo,Qwo,kp,She,Wwo,Uwo,JG,Hwo,Jwo,Ywo,Sp,Rhe,Kwo,Zwo,YG,eAo,oAo,rAo,Rp,Phe,tAo,aAo,KG,nAo,sAo,lAo,Pp,Bhe,iAo,dAo,ZG,cAo,mAo,fAo,Bp,Ihe,gAo,hAo,eO,uAo,pAo,_Ao,Ip,Nhe,bAo,vAo,oO,FAo,TAo,MAo,Np,qhe,EAo,CAo,rO,wAo,AAo,LAo,qp,jhe,yAo,xAo,tO,$Ao,kAo,SAo,jp,Dhe,RAo,PAo,aO,BAo,IAo,NAo,Dp,Ghe,qAo,jAo,nO,DAo,GAo,OAo,Gp,VAo,Op,XAo,Vp,U9,zAo,Ohe,QAo,XYe,pd,Xp,Vhe,H9,WAo,Xhe,UAo,zYe,Po,J9,HAo,_d,JAo,sO,YAo,KAo,lO,ZAo,e6o,o6o,Y9,r6o,zhe,t6o,a6o,n6o,_t,K9,s6o,Qhe,l6o,i6o,bd,d6o,Whe,c6o,m6o,iO,f6o,g6o,h6o,zp,u6o,Ze,Z9,p6o,Uhe,_6o,b6o,Ja,v6o,Hhe,F6o,T6o,Jhe,M6o,E6o,Yhe,C6o,w6o,A6o,y,Qp,Khe,L6o,y6o,dO,x6o,$6o,k6o,Wp,Zhe,S6o,R6o,cO,P6o,B6o,I6o,Up,eue,N6o,q6o,mO,j6o,D6o,G6o,Hp,oue,O6o,V6o,fO,X6o,z6o,Q6o,Jp,rue,W6o,U6o,gO,H6o,J6o,Y6o,Yp,tue,K6o,Z6o,hO,e7o,o7o,r7o,Kp,aue,t7o,a7o,uO,n7o,s7o,l7o,Zp,nue,i7o,d7o,pO,c7o,m7o,f7o,e_,sue,g7o,h7o,_O,u7o,p7o,_7o,o_,lue,b7o,v7o,bO,F7o,T7o,M7o,r_,iue,E7o,C7o,vO,w7o,A7o,L7o,t_,due,y7o,x7o,FO,$7o,k7o,S7o,a_,cue,R7o,P7o,TO,B7o,I7o,N7o,n_,mue,q7o,j7o,MO,D7o,G7o,O7o,s_,fue,V7o,X7o,EO,z7o,Q7o,W7o,l_,gue,U7o,H7o,CO,J7o,Y7o,K7o,i_,hue,Z7o,eLo,wO,oLo,rLo,tLo,d_,uue,aLo,nLo,AO,sLo,lLo,iLo,c_,pue,dLo,cLo,LO,mLo,fLo,gLo,m_,_ue,hLo,uLo,yO,pLo,_Lo,bLo,f_,bue,vLo,FLo,xO,TLo,MLo,ELo,g_,vue,CLo,wLo,$O,ALo,LLo,yLo,h_,Fue,xLo,$Lo,kO,kLo,SLo,RLo,u_,Tue,PLo,BLo,SO,ILo,NLo,qLo,p_,Mue,jLo,DLo,RO,GLo,OLo,VLo,__,Eue,XLo,zLo,PO,QLo,WLo,ULo,b_,Cue,HLo,JLo,BO,YLo,KLo,ZLo,v_,wue,eyo,oyo,IO,ryo,tyo,ayo,F_,Aue,nyo,syo,NO,lyo,iyo,dyo,T_,Lue,cyo,myo,qO,fyo,gyo,hyo,M_,yue,uyo,pyo,jO,_yo,byo,vyo,E_,xue,Fyo,Tyo,DO,Myo,Eyo,Cyo,C_,$ue,wyo,Ayo,GO,Lyo,yyo,xyo,w_,kue,$yo,kyo,OO,Syo,Ryo,Pyo,A_,Sue,Byo,Iyo,VO,Nyo,qyo,jyo,L_,Rue,Dyo,Gyo,XO,Oyo,Vyo,Xyo,pl,Pue,zyo,Qyo,zO,Wyo,Uyo,QO,Hyo,Jyo,Yyo,y_,Bue,Kyo,Zyo,WO,e8o,o8o,r8o,x_,Iue,t8o,a8o,UO,n8o,s8o,l8o,$_,Nue,i8o,d8o,HO,c8o,m8o,f8o,k_,que,g8o,h8o,JO,u8o,p8o,_8o,S_,jue,b8o,v8o,YO,F8o,T8o,M8o,R_,Due,E8o,C8o,KO,w8o,A8o,L8o,P_,Gue,y8o,x8o,ZO,$8o,k8o,S8o,B_,Oue,R8o,P8o,eV,B8o,I8o,N8o,I_,Vue,q8o,j8o,oV,D8o,G8o,O8o,N_,Xue,V8o,X8o,rV,z8o,Q8o,W8o,q_,zue,U8o,H8o,tV,J8o,Y8o,K8o,j_,Que,Z8o,e9o,aV,o9o,r9o,t9o,D_,Wue,a9o,n9o,nV,s9o,l9o,i9o,G_,Uue,d9o,c9o,sV,m9o,f9o,g9o,O_,Hue,h9o,u9o,lV,p9o,_9o,b9o,V_,Jue,v9o,F9o,iV,T9o,M9o,E9o,X_,Yue,C9o,w9o,dV,A9o,L9o,y9o,z_,Kue,x9o,$9o,cV,k9o,S9o,R9o,Q_,Zue,P9o,B9o,mV,I9o,N9o,q9o,W_,epe,j9o,D9o,fV,G9o,O9o,V9o,U_,ope,X9o,z9o,gV,Q9o,W9o,U9o,H_,rpe,H9o,J9o,hV,Y9o,K9o,Z9o,J_,tpe,exo,oxo,uV,rxo,txo,axo,Y_,ape,nxo,sxo,pV,lxo,ixo,dxo,K_,npe,cxo,mxo,_V,fxo,gxo,hxo,Z_,spe,uxo,pxo,bV,_xo,bxo,vxo,e2,lpe,Fxo,Txo,vV,Mxo,Exo,Cxo,o2,ipe,wxo,Axo,FV,Lxo,yxo,xxo,r2,dpe,$xo,kxo,TV,Sxo,Rxo,Pxo,t2,cpe,Bxo,Ixo,MV,Nxo,qxo,jxo,a2,mpe,Dxo,Gxo,EV,Oxo,Vxo,Xxo,n2,fpe,zxo,Qxo,CV,Wxo,Uxo,Hxo,s2,gpe,Jxo,Yxo,wV,Kxo,Zxo,e$o,l2,hpe,o$o,r$o,AV,t$o,a$o,n$o,i2,upe,s$o,l$o,LV,i$o,d$o,c$o,d2,ppe,m$o,f$o,yV,g$o,h$o,u$o,c2,_pe,p$o,_$o,xV,b$o,v$o,F$o,m2,bpe,T$o,M$o,$V,E$o,C$o,w$o,f2,vpe,A$o,L$o,kV,y$o,x$o,$$o,g2,Fpe,k$o,S$o,SV,R$o,P$o,B$o,h2,Tpe,I$o,N$o,RV,q$o,j$o,D$o,u2,Mpe,G$o,O$o,PV,V$o,X$o,z$o,p2,Epe,Q$o,W$o,BV,U$o,H$o,J$o,_2,Cpe,Y$o,K$o,IV,Z$o,eko,oko,b2,wpe,rko,tko,NV,ako,nko,sko,v2,Ape,lko,iko,qV,dko,cko,mko,F2,Lpe,fko,gko,jV,hko,uko,pko,T2,ype,_ko,bko,DV,vko,Fko,Tko,M2,xpe,Mko,Eko,GV,Cko,wko,Ako,E2,$pe,Lko,yko,OV,xko,$ko,kko,C2,kpe,Sko,Rko,VV,Pko,Bko,Iko,w2,Spe,Nko,qko,XV,jko,Dko,Gko,A2,Rpe,Oko,Vko,zV,Xko,zko,Qko,L2,Ppe,Wko,Uko,QV,Hko,Jko,Yko,y2,Bpe,Kko,Zko,WV,eSo,oSo,rSo,x2,Ipe,tSo,aSo,UV,nSo,sSo,lSo,$2,Npe,iSo,dSo,HV,cSo,mSo,fSo,k2,qpe,gSo,hSo,JV,uSo,pSo,_So,S2,jpe,bSo,vSo,YV,FSo,TSo,MSo,R2,Dpe,ESo,CSo,KV,wSo,ASo,LSo,P2,Gpe,ySo,xSo,ZV,$So,kSo,SSo,B2,Ope,RSo,PSo,eX,BSo,ISo,NSo,I2,Vpe,qSo,jSo,oX,DSo,GSo,OSo,N2,Xpe,VSo,XSo,rX,zSo,QSo,WSo,q2,zpe,USo,HSo,tX,JSo,YSo,KSo,j2,Qpe,ZSo,eRo,aX,oRo,rRo,tRo,D2,Wpe,aRo,nRo,nX,sRo,lRo,iRo,G2,Upe,dRo,cRo,sX,mRo,fRo,gRo,O2,Hpe,hRo,uRo,lX,pRo,_Ro,bRo,V2,Jpe,vRo,FRo,iX,TRo,MRo,ERo,X2,Ype,CRo,wRo,dX,ARo,LRo,yRo,z2,Kpe,xRo,$Ro,cX,kRo,SRo,RRo,Q2,Zpe,PRo,BRo,mX,IRo,NRo,qRo,W2,e_e,jRo,DRo,fX,GRo,ORo,VRo,U2,o_e,XRo,zRo,gX,QRo,WRo,URo,H2,r_e,HRo,JRo,hX,YRo,KRo,ZRo,J2,t_e,ePo,oPo,uX,rPo,tPo,aPo,Y2,a_e,nPo,sPo,pX,lPo,iPo,dPo,K2,n_e,cPo,mPo,_X,fPo,gPo,hPo,Z2,s_e,uPo,pPo,bX,_Po,bPo,vPo,eb,l_e,FPo,TPo,vX,MPo,EPo,CPo,ob,i_e,wPo,APo,FX,LPo,yPo,xPo,rb,$Po,d_e,kPo,SPo,c_e,RPo,PPo,tb,QYe,vd,ab,m_e,ex,BPo,f_e,IPo,WYe,Bo,ox,NPo,Fd,qPo,TX,jPo,DPo,MX,GPo,OPo,VPo,rx,XPo,g_e,zPo,QPo,WPo,bt,tx,UPo,h_e,HPo,JPo,Td,YPo,u_e,KPo,ZPo,EX,eBo,oBo,rBo,nb,tBo,eo,ax,aBo,p_e,nBo,sBo,Ya,lBo,__e,iBo,dBo,b_e,cBo,mBo,v_e,fBo,gBo,hBo,G,sb,F_e,uBo,pBo,CX,_Bo,bBo,vBo,lb,T_e,FBo,TBo,wX,MBo,EBo,CBo,ib,M_e,wBo,ABo,AX,LBo,yBo,xBo,db,E_e,$Bo,kBo,LX,SBo,RBo,PBo,cb,C_e,BBo,IBo,yX,NBo,qBo,jBo,mb,w_e,DBo,GBo,xX,OBo,VBo,XBo,fb,A_e,zBo,QBo,$X,WBo,UBo,HBo,gb,L_e,JBo,YBo,kX,KBo,ZBo,eIo,hb,y_e,oIo,rIo,SX,tIo,aIo,nIo,ub,x_e,sIo,lIo,RX,iIo,dIo,cIo,pb,$_e,mIo,fIo,PX,gIo,hIo,uIo,_b,k_e,pIo,_Io,BX,bIo,vIo,FIo,bb,S_e,TIo,MIo,IX,EIo,CIo,wIo,vb,R_e,AIo,LIo,NX,yIo,xIo,$Io,Fb,P_e,kIo,SIo,qX,RIo,PIo,BIo,Tb,B_e,IIo,NIo,jX,qIo,jIo,DIo,Mb,I_e,GIo,OIo,DX,VIo,XIo,zIo,Eb,N_e,QIo,WIo,GX,UIo,HIo,JIo,Cb,q_e,YIo,KIo,OX,ZIo,eNo,oNo,wb,j_e,rNo,tNo,VX,aNo,nNo,sNo,Ab,D_e,lNo,iNo,XX,dNo,cNo,mNo,Lb,G_e,fNo,gNo,zX,hNo,uNo,pNo,yb,O_e,_No,bNo,QX,vNo,FNo,TNo,xb,V_e,MNo,ENo,WX,CNo,wNo,ANo,$b,X_e,LNo,yNo,UX,xNo,$No,kNo,kb,z_e,SNo,RNo,HX,PNo,BNo,INo,Sb,Q_e,NNo,qNo,JX,jNo,DNo,GNo,Rb,W_e,ONo,VNo,YX,XNo,zNo,QNo,Pb,U_e,WNo,UNo,KX,HNo,JNo,YNo,Bb,H_e,KNo,ZNo,ZX,eqo,oqo,rqo,Ib,J_e,tqo,aqo,ez,nqo,sqo,lqo,Nb,Y_e,iqo,dqo,oz,cqo,mqo,fqo,qb,K_e,gqo,hqo,rz,uqo,pqo,_qo,jb,Z_e,bqo,vqo,tz,Fqo,Tqo,Mqo,Db,e2e,Eqo,Cqo,az,wqo,Aqo,Lqo,Gb,o2e,yqo,xqo,nz,$qo,kqo,Sqo,Ob,r2e,Rqo,Pqo,sz,Bqo,Iqo,Nqo,Vb,t2e,qqo,jqo,lz,Dqo,Gqo,Oqo,Xb,a2e,Vqo,Xqo,iz,zqo,Qqo,Wqo,zb,n2e,Uqo,Hqo,dz,Jqo,Yqo,Kqo,Qb,s2e,Zqo,ejo,cz,ojo,rjo,tjo,Wb,l2e,ajo,njo,mz,sjo,ljo,ijo,Ub,i2e,djo,cjo,fz,mjo,fjo,gjo,Hb,d2e,hjo,ujo,gz,pjo,_jo,bjo,Jb,c2e,vjo,Fjo,hz,Tjo,Mjo,Ejo,Yb,m2e,Cjo,wjo,uz,Ajo,Ljo,yjo,Kb,f2e,xjo,$jo,pz,kjo,Sjo,Rjo,Zb,g2e,Pjo,Bjo,_z,Ijo,Njo,qjo,e1,jjo,h2e,Djo,Gjo,u2e,Ojo,Vjo,o1,UYe,Md,r1,p2e,nx,Xjo,_2e,zjo,HYe,Io,sx,Qjo,Ed,Wjo,bz,Ujo,Hjo,vz,Jjo,Yjo,Kjo,lx,Zjo,b2e,eDo,oDo,rDo,vt,ix,tDo,v2e,aDo,nDo,Cd,sDo,F2e,lDo,iDo,Fz,dDo,cDo,mDo,t1,fDo,oo,dx,gDo,T2e,hDo,uDo,Ka,pDo,M2e,_Do,bDo,E2e,vDo,FDo,C2e,TDo,MDo,EDo,z,a1,w2e,CDo,wDo,Tz,ADo,LDo,yDo,n1,A2e,xDo,$Do,Mz,kDo,SDo,RDo,s1,L2e,PDo,BDo,Ez,IDo,NDo,qDo,l1,y2e,jDo,DDo,Cz,GDo,ODo,VDo,i1,x2e,XDo,zDo,wz,QDo,WDo,UDo,d1,$2e,HDo,JDo,Az,YDo,KDo,ZDo,c1,k2e,eGo,oGo,Lz,rGo,tGo,aGo,m1,S2e,nGo,sGo,yz,lGo,iGo,dGo,f1,R2e,cGo,mGo,xz,fGo,gGo,hGo,g1,P2e,uGo,pGo,$z,_Go,bGo,vGo,h1,B2e,FGo,TGo,kz,MGo,EGo,CGo,u1,I2e,wGo,AGo,Sz,LGo,yGo,xGo,p1,N2e,$Go,kGo,Rz,SGo,RGo,PGo,_1,q2e,BGo,IGo,Pz,NGo,qGo,jGo,b1,j2e,DGo,GGo,Bz,OGo,VGo,XGo,v1,D2e,zGo,QGo,Iz,WGo,UGo,HGo,F1,G2e,JGo,YGo,Nz,KGo,ZGo,eOo,T1,O2e,oOo,rOo,qz,tOo,aOo,nOo,M1,V2e,sOo,lOo,jz,iOo,dOo,cOo,E1,X2e,mOo,fOo,Dz,gOo,hOo,uOo,C1,z2e,pOo,_Oo,Gz,bOo,vOo,FOo,w1,Q2e,TOo,MOo,Oz,EOo,COo,wOo,A1,W2e,AOo,LOo,Vz,yOo,xOo,$Oo,L1,U2e,kOo,SOo,Xz,ROo,POo,BOo,y1,H2e,IOo,NOo,zz,qOo,jOo,DOo,x1,J2e,GOo,OOo,Qz,VOo,XOo,zOo,$1,Y2e,QOo,WOo,Wz,UOo,HOo,JOo,k1,K2e,YOo,KOo,Uz,ZOo,eVo,oVo,S1,Z2e,rVo,tVo,Hz,aVo,nVo,sVo,R1,ebe,lVo,iVo,Jz,dVo,cVo,mVo,P1,obe,fVo,gVo,Yz,hVo,uVo,pVo,B1,rbe,_Vo,bVo,Kz,vVo,FVo,TVo,I1,tbe,MVo,EVo,Zz,CVo,wVo,AVo,N1,abe,LVo,yVo,eQ,xVo,$Vo,kVo,q1,nbe,SVo,RVo,oQ,PVo,BVo,IVo,j1,sbe,NVo,qVo,rQ,jVo,DVo,GVo,D1,lbe,OVo,VVo,tQ,XVo,zVo,QVo,G1,ibe,WVo,UVo,aQ,HVo,JVo,YVo,O1,dbe,KVo,ZVo,nQ,eXo,oXo,rXo,V1,cbe,tXo,aXo,sQ,nXo,sXo,lXo,X1,mbe,iXo,dXo,lQ,cXo,mXo,fXo,z1,gXo,fbe,hXo,uXo,gbe,pXo,_Xo,Q1,JYe,wd,W1,hbe,cx,bXo,ube,vXo,YYe,No,mx,FXo,Ad,TXo,iQ,MXo,EXo,dQ,CXo,wXo,AXo,fx,LXo,pbe,yXo,xXo,$Xo,Ft,gx,kXo,_be,SXo,RXo,Ld,PXo,bbe,BXo,IXo,cQ,NXo,qXo,jXo,U1,DXo,ro,hx,GXo,vbe,OXo,VXo,Za,XXo,Fbe,zXo,QXo,Tbe,WXo,UXo,Mbe,HXo,JXo,YXo,U,H1,Ebe,KXo,ZXo,mQ,ezo,ozo,rzo,J1,Cbe,tzo,azo,fQ,nzo,szo,lzo,Y1,wbe,izo,dzo,gQ,czo,mzo,fzo,K1,Abe,gzo,hzo,hQ,uzo,pzo,_zo,Z1,Lbe,bzo,vzo,uQ,Fzo,Tzo,Mzo,ev,ybe,Ezo,Czo,pQ,wzo,Azo,Lzo,ov,xbe,yzo,xzo,_Q,$zo,kzo,Szo,rv,$be,Rzo,Pzo,bQ,Bzo,Izo,Nzo,tv,kbe,qzo,jzo,vQ,Dzo,Gzo,Ozo,av,Sbe,Vzo,Xzo,FQ,zzo,Qzo,Wzo,nv,Rbe,Uzo,Hzo,TQ,Jzo,Yzo,Kzo,sv,Pbe,Zzo,eQo,MQ,oQo,rQo,tQo,lv,Bbe,aQo,nQo,EQ,sQo,lQo,iQo,iv,Ibe,dQo,cQo,CQ,mQo,fQo,gQo,dv,Nbe,hQo,uQo,wQ,pQo,_Qo,bQo,cv,qbe,vQo,FQo,AQ,TQo,MQo,EQo,mv,jbe,CQo,wQo,LQ,AQo,LQo,yQo,fv,Dbe,xQo,$Qo,yQ,kQo,SQo,RQo,gv,Gbe,PQo,BQo,xQ,IQo,NQo,qQo,hv,Obe,jQo,DQo,$Q,GQo,OQo,VQo,uv,Vbe,XQo,zQo,kQ,QQo,WQo,UQo,pv,Xbe,HQo,JQo,SQ,YQo,KQo,ZQo,_v,zbe,eWo,oWo,RQ,rWo,tWo,aWo,bv,Qbe,nWo,sWo,PQ,lWo,iWo,dWo,vv,Wbe,cWo,mWo,BQ,fWo,gWo,hWo,Fv,Ube,uWo,pWo,IQ,_Wo,bWo,vWo,Tv,Hbe,FWo,TWo,NQ,MWo,EWo,CWo,Mv,Jbe,wWo,AWo,qQ,LWo,yWo,xWo,Ev,Ybe,$Wo,kWo,jQ,SWo,RWo,PWo,Cv,Kbe,BWo,IWo,DQ,NWo,qWo,jWo,wv,Zbe,DWo,GWo,GQ,OWo,VWo,XWo,Av,e1e,zWo,QWo,OQ,WWo,UWo,HWo,Lv,o1e,JWo,YWo,VQ,KWo,ZWo,eUo,yv,r1e,oUo,rUo,XQ,tUo,aUo,nUo,xv,t1e,sUo,lUo,a1e,iUo,dUo,cUo,$v,n1e,mUo,fUo,zQ,gUo,hUo,uUo,kv,s1e,pUo,_Uo,QQ,bUo,vUo,FUo,Sv,l1e,TUo,MUo,WQ,EUo,CUo,wUo,Rv,i1e,AUo,LUo,UQ,yUo,xUo,$Uo,Pv,kUo,d1e,SUo,RUo,c1e,PUo,BUo,Bv,KYe,yd,Iv,m1e,ux,IUo,f1e,NUo,ZYe,qo,px,qUo,xd,jUo,HQ,DUo,GUo,JQ,OUo,VUo,XUo,_x,zUo,g1e,QUo,WUo,UUo,Tt,bx,HUo,h1e,JUo,YUo,$d,KUo,u1e,ZUo,eHo,YQ,oHo,rHo,tHo,Nv,aHo,to,vx,nHo,p1e,sHo,lHo,en,iHo,_1e,dHo,cHo,b1e,mHo,fHo,v1e,gHo,hHo,uHo,me,qv,F1e,pHo,_Ho,KQ,bHo,vHo,FHo,jv,T1e,THo,MHo,ZQ,EHo,CHo,wHo,Dv,M1e,AHo,LHo,eW,yHo,xHo,$Ho,Gv,E1e,kHo,SHo,oW,RHo,PHo,BHo,Ov,C1e,IHo,NHo,rW,qHo,jHo,DHo,Vv,w1e,GHo,OHo,tW,VHo,XHo,zHo,Xv,A1e,QHo,WHo,aW,UHo,HHo,JHo,zv,L1e,YHo,KHo,nW,ZHo,eJo,oJo,Qv,y1e,rJo,tJo,sW,aJo,nJo,sJo,Wv,x1e,lJo,iJo,lW,dJo,cJo,mJo,Uv,$1e,fJo,gJo,iW,hJo,uJo,pJo,Hv,k1e,_Jo,bJo,dW,vJo,FJo,TJo,Jv,S1e,MJo,EJo,cW,CJo,wJo,AJo,Yv,R1e,LJo,yJo,mW,xJo,$Jo,kJo,Kv,P1e,SJo,RJo,fW,PJo,BJo,IJo,Zv,B1e,NJo,qJo,gW,jJo,DJo,GJo,eF,I1e,OJo,VJo,hW,XJo,zJo,QJo,oF,N1e,WJo,UJo,uW,HJo,JJo,YJo,rF,q1e,KJo,ZJo,pW,eYo,oYo,rYo,tF,j1e,tYo,aYo,_W,nYo,sYo,lYo,aF,iYo,D1e,dYo,cYo,G1e,mYo,fYo,nF,eKe,kd,sF,O1e,Fx,gYo,V1e,hYo,oKe,jo,Tx,uYo,Sd,pYo,bW,_Yo,bYo,vW,vYo,FYo,TYo,Mx,MYo,X1e,EYo,CYo,wYo,Mt,Ex,AYo,z1e,LYo,yYo,Rd,xYo,Q1e,$Yo,kYo,FW,SYo,RYo,PYo,lF,BYo,ao,Cx,IYo,W1e,NYo,qYo,on,jYo,U1e,DYo,GYo,H1e,OYo,VYo,J1e,XYo,zYo,QYo,q,iF,Y1e,WYo,UYo,TW,HYo,JYo,YYo,dF,K1e,KYo,ZYo,MW,eKo,oKo,rKo,cF,Z1e,tKo,aKo,EW,nKo,sKo,lKo,mF,eve,iKo,dKo,CW,cKo,mKo,fKo,fF,ove,gKo,hKo,wW,uKo,pKo,_Ko,gF,rve,bKo,vKo,AW,FKo,TKo,MKo,hF,tve,EKo,CKo,LW,wKo,AKo,LKo,uF,ave,yKo,xKo,yW,$Ko,kKo,SKo,pF,nve,RKo,PKo,xW,BKo,IKo,NKo,_F,sve,qKo,jKo,$W,DKo,GKo,OKo,bF,lve,VKo,XKo,kW,zKo,QKo,WKo,vF,ive,UKo,HKo,SW,JKo,YKo,KKo,FF,dve,ZKo,eZo,RW,oZo,rZo,tZo,TF,cve,aZo,nZo,PW,sZo,lZo,iZo,MF,mve,dZo,cZo,BW,mZo,fZo,gZo,EF,fve,hZo,uZo,IW,pZo,_Zo,bZo,CF,gve,vZo,FZo,NW,TZo,MZo,EZo,wF,hve,CZo,wZo,qW,AZo,LZo,yZo,AF,uve,xZo,$Zo,jW,kZo,SZo,RZo,LF,pve,PZo,BZo,DW,IZo,NZo,qZo,yF,_ve,jZo,DZo,GW,GZo,OZo,VZo,xF,bve,XZo,zZo,OW,QZo,WZo,UZo,$F,vve,HZo,JZo,VW,YZo,KZo,ZZo,kF,Fve,eer,oer,XW,rer,ter,aer,SF,Tve,ner,ser,zW,ler,ier,der,RF,Mve,cer,mer,QW,fer,ger,her,PF,Eve,uer,per,WW,_er,ber,ver,BF,Cve,Fer,Ter,UW,Mer,Eer,Cer,IF,wve,wer,Aer,HW,Ler,yer,xer,NF,Ave,$er,ker,JW,Ser,Rer,Per,qF,Lve,Ber,Ier,YW,Ner,qer,jer,jF,yve,Der,Ger,KW,Oer,Ver,Xer,DF,xve,zer,Qer,ZW,Wer,Uer,Her,GF,$ve,Jer,Yer,eU,Ker,Zer,eor,OF,kve,oor,ror,oU,tor,aor,nor,VF,Sve,sor,lor,rU,ior,dor,cor,XF,Rve,mor,gor,tU,hor,uor,por,zF,Pve,_or,bor,aU,vor,For,Tor,QF,Bve,Mor,Eor,nU,Cor,wor,Aor,WF,Ive,Lor,yor,sU,xor,$or,kor,UF,Nve,Sor,Ror,lU,Por,Bor,Ior,HF,qve,Nor,qor,iU,jor,Dor,Gor,JF,jve,Oor,Vor,dU,Xor,zor,Qor,YF,Dve,Wor,Uor,cU,Hor,Jor,Yor,KF,Gve,Kor,Zor,mU,err,orr,rrr,ZF,Ove,trr,arr,fU,nrr,srr,lrr,eT,Vve,irr,drr,gU,crr,mrr,frr,oT,Xve,grr,hrr,hU,urr,prr,_rr,rT,zve,brr,vrr,uU,Frr,Trr,Mrr,tT,Qve,Err,Crr,pU,wrr,Arr,Lrr,aT,Wve,yrr,xrr,_U,$rr,krr,Srr,nT,Uve,Rrr,Prr,bU,Brr,Irr,Nrr,sT,Hve,qrr,jrr,vU,Drr,Grr,Orr,lT,Vrr,Jve,Xrr,zrr,Yve,Qrr,Wrr,iT,rKe,Pd,dT,Kve,wx,Urr,Zve,Hrr,tKe,Do,Ax,Jrr,Bd,Yrr,FU,Krr,Zrr,TU,etr,otr,rtr,Lx,ttr,eFe,atr,ntr,str,Et,yx,ltr,oFe,itr,dtr,Id,ctr,rFe,mtr,ftr,MU,gtr,htr,utr,cT,ptr,no,xx,_tr,tFe,btr,vtr,rn,Ftr,aFe,Ttr,Mtr,nFe,Etr,Ctr,sFe,wtr,Atr,Ltr,Z,mT,lFe,ytr,xtr,EU,$tr,ktr,Str,fT,iFe,Rtr,Ptr,CU,Btr,Itr,Ntr,gT,dFe,qtr,jtr,wU,Dtr,Gtr,Otr,hT,cFe,Vtr,Xtr,AU,ztr,Qtr,Wtr,uT,mFe,Utr,Htr,LU,Jtr,Ytr,Ktr,pT,fFe,Ztr,ear,yU,oar,rar,tar,_T,gFe,aar,nar,xU,sar,lar,iar,bT,hFe,dar,car,$U,mar,far,gar,vT,uFe,har,uar,kU,par,_ar,bar,FT,pFe,Far,Tar,SU,Mar,Ear,Car,TT,_Fe,war,Aar,RU,Lar,yar,xar,MT,bFe,$ar,kar,PU,Sar,Rar,Par,ET,vFe,Bar,Iar,BU,Nar,qar,jar,CT,FFe,Dar,Gar,IU,Oar,Var,Xar,wT,TFe,zar,Qar,NU,War,Uar,Har,AT,MFe,Jar,Yar,qU,Kar,Zar,enr,LT,EFe,onr,rnr,jU,tnr,anr,nnr,yT,CFe,snr,lnr,DU,inr,dnr,cnr,xT,wFe,mnr,fnr,GU,gnr,hnr,unr,$T,AFe,pnr,_nr,OU,bnr,vnr,Fnr,kT,LFe,Tnr,Mnr,VU,Enr,Cnr,wnr,ST,yFe,Anr,Lnr,XU,ynr,xnr,$nr,RT,xFe,knr,Snr,zU,Rnr,Pnr,Bnr,PT,$Fe,Inr,Nnr,QU,qnr,jnr,Dnr,BT,kFe,Gnr,Onr,WU,Vnr,Xnr,znr,IT,SFe,Qnr,Wnr,UU,Unr,Hnr,Jnr,NT,RFe,Ynr,Knr,HU,Znr,esr,osr,qT,PFe,rsr,tsr,JU,asr,nsr,ssr,jT,BFe,lsr,isr,YU,dsr,csr,msr,DT,IFe,fsr,gsr,KU,hsr,usr,psr,GT,NFe,_sr,bsr,ZU,vsr,Fsr,Tsr,OT,qFe,Msr,Esr,eH,Csr,wsr,Asr,VT,Lsr,jFe,ysr,xsr,DFe,$sr,ksr,XT,aKe,Nd,zT,GFe,$x,Ssr,OFe,Rsr,nKe,Go,kx,Psr,qd,Bsr,oH,Isr,Nsr,rH,qsr,jsr,Dsr,Sx,Gsr,VFe,Osr,Vsr,Xsr,Ct,Rx,zsr,XFe,Qsr,Wsr,jd,Usr,zFe,Hsr,Jsr,tH,Ysr,Ksr,Zsr,QT,elr,so,Px,olr,QFe,rlr,tlr,tn,alr,WFe,nlr,slr,UFe,llr,ilr,HFe,dlr,clr,mlr,Ue,WT,JFe,flr,glr,aH,hlr,ulr,plr,UT,YFe,_lr,blr,nH,vlr,Flr,Tlr,HT,KFe,Mlr,Elr,sH,Clr,wlr,Alr,JT,ZFe,Llr,ylr,lH,xlr,$lr,klr,YT,eTe,Slr,Rlr,iH,Plr,Blr,Ilr,KT,oTe,Nlr,qlr,dH,jlr,Dlr,Glr,ZT,rTe,Olr,Vlr,cH,Xlr,zlr,Qlr,eM,Wlr,tTe,Ulr,Hlr,aTe,Jlr,Ylr,oM,sKe,Dd,rM,nTe,Bx,Klr,sTe,Zlr,lKe,Oo,Ix,eir,Gd,oir,mH,rir,tir,fH,air,nir,sir,Nx,lir,lTe,iir,dir,cir,wt,qx,mir,iTe,fir,gir,Od,hir,dTe,uir,pir,gH,_ir,bir,vir,tM,Fir,lo,jx,Tir,cTe,Mir,Eir,an,Cir,mTe,wir,Air,fTe,Lir,yir,gTe,xir,$ir,kir,H,aM,hTe,Sir,Rir,hH,Pir,Bir,Iir,nM,uTe,Nir,qir,uH,jir,Dir,Gir,sM,pTe,Oir,Vir,pH,Xir,zir,Qir,lM,_Te,Wir,Uir,_H,Hir,Jir,Yir,iM,bTe,Kir,Zir,bH,edr,odr,rdr,dM,vTe,tdr,adr,vH,ndr,sdr,ldr,cM,FTe,idr,ddr,FH,cdr,mdr,fdr,mM,TTe,gdr,hdr,TH,udr,pdr,_dr,fM,MTe,bdr,vdr,MH,Fdr,Tdr,Mdr,gM,ETe,Edr,Cdr,EH,wdr,Adr,Ldr,hM,CTe,ydr,xdr,CH,$dr,kdr,Sdr,uM,wTe,Rdr,Pdr,wH,Bdr,Idr,Ndr,pM,ATe,qdr,jdr,AH,Ddr,Gdr,Odr,_M,LTe,Vdr,Xdr,LH,zdr,Qdr,Wdr,bM,yTe,Udr,Hdr,yH,Jdr,Ydr,Kdr,vM,xTe,Zdr,ecr,xH,ocr,rcr,tcr,FM,$Te,acr,ncr,$H,scr,lcr,icr,TM,kTe,dcr,ccr,kH,mcr,fcr,gcr,MM,STe,hcr,ucr,SH,pcr,_cr,bcr,EM,RTe,vcr,Fcr,RH,Tcr,Mcr,Ecr,CM,PTe,Ccr,wcr,PH,Acr,Lcr,ycr,wM,BTe,xcr,$cr,BH,kcr,Scr,Rcr,AM,ITe,Pcr,Bcr,IH,Icr,Ncr,qcr,LM,NTe,jcr,Dcr,NH,Gcr,Ocr,Vcr,yM,qTe,Xcr,zcr,qH,Qcr,Wcr,Ucr,xM,jTe,Hcr,Jcr,jH,Ycr,Kcr,Zcr,$M,DTe,emr,omr,DH,rmr,tmr,amr,kM,GTe,nmr,smr,GH,lmr,imr,dmr,SM,OTe,cmr,mmr,OH,fmr,gmr,hmr,RM,VTe,umr,pmr,VH,_mr,bmr,vmr,PM,XTe,Fmr,Tmr,XH,Mmr,Emr,Cmr,BM,zTe,wmr,Amr,zH,Lmr,ymr,xmr,IM,QTe,$mr,kmr,QH,Smr,Rmr,Pmr,NM,WTe,Bmr,Imr,WH,Nmr,qmr,jmr,qM,UTe,Dmr,Gmr,UH,Omr,Vmr,Xmr,jM,HTe,zmr,Qmr,HH,Wmr,Umr,Hmr,DM,JTe,Jmr,Ymr,JH,Kmr,Zmr,efr,GM,YTe,ofr,rfr,YH,tfr,afr,nfr,OM,sfr,KTe,lfr,ifr,ZTe,dfr,cfr,VM,iKe,Vd,XM,eMe,Dx,mfr,oMe,ffr,dKe,Vo,Gx,gfr,Xd,hfr,KH,ufr,pfr,ZH,_fr,bfr,vfr,Ox,Ffr,rMe,Tfr,Mfr,Efr,At,Vx,Cfr,tMe,wfr,Afr,zd,Lfr,aMe,yfr,xfr,eJ,$fr,kfr,Sfr,zM,Rfr,io,Xx,Pfr,nMe,Bfr,Ifr,nn,Nfr,sMe,qfr,jfr,lMe,Dfr,Gfr,iMe,Ofr,Vfr,Xfr,V,QM,dMe,zfr,Qfr,oJ,Wfr,Ufr,Hfr,WM,cMe,Jfr,Yfr,rJ,Kfr,Zfr,egr,UM,mMe,ogr,rgr,tJ,tgr,agr,ngr,HM,fMe,sgr,lgr,aJ,igr,dgr,cgr,JM,gMe,mgr,fgr,nJ,ggr,hgr,ugr,YM,hMe,pgr,_gr,sJ,bgr,vgr,Fgr,KM,uMe,Tgr,Mgr,lJ,Egr,Cgr,wgr,ZM,pMe,Agr,Lgr,iJ,ygr,xgr,$gr,eE,_Me,kgr,Sgr,dJ,Rgr,Pgr,Bgr,oE,bMe,Igr,Ngr,cJ,qgr,jgr,Dgr,rE,vMe,Ggr,Ogr,mJ,Vgr,Xgr,zgr,tE,FMe,Qgr,Wgr,fJ,Ugr,Hgr,Jgr,aE,TMe,Ygr,Kgr,gJ,Zgr,ehr,ohr,nE,MMe,rhr,thr,hJ,ahr,nhr,shr,sE,EMe,lhr,ihr,uJ,dhr,chr,mhr,lE,CMe,fhr,ghr,pJ,hhr,uhr,phr,iE,wMe,_hr,bhr,_J,vhr,Fhr,Thr,dE,AMe,Mhr,Ehr,bJ,Chr,whr,Ahr,cE,LMe,Lhr,yhr,vJ,xhr,$hr,khr,mE,yMe,Shr,Rhr,FJ,Phr,Bhr,Ihr,fE,xMe,Nhr,qhr,TJ,jhr,Dhr,Ghr,gE,$Me,Ohr,Vhr,MJ,Xhr,zhr,Qhr,hE,kMe,Whr,Uhr,EJ,Hhr,Jhr,Yhr,uE,SMe,Khr,Zhr,CJ,eur,our,rur,pE,RMe,tur,aur,wJ,nur,sur,lur,_E,PMe,iur,dur,AJ,cur,mur,fur,bE,BMe,gur,hur,LJ,uur,pur,_ur,vE,IMe,bur,vur,yJ,Fur,Tur,Mur,FE,NMe,Eur,Cur,xJ,wur,Aur,Lur,TE,qMe,yur,xur,$J,$ur,kur,Sur,ME,jMe,Rur,Pur,kJ,Bur,Iur,Nur,EE,DMe,qur,jur,SJ,Dur,Gur,Our,CE,GMe,Vur,Xur,RJ,zur,Qur,Wur,wE,OMe,Uur,Hur,PJ,Jur,Yur,Kur,AE,VMe,Zur,epr,BJ,opr,rpr,tpr,LE,XMe,apr,npr,IJ,spr,lpr,ipr,yE,zMe,dpr,cpr,NJ,mpr,fpr,gpr,xE,QMe,hpr,upr,qJ,ppr,_pr,bpr,$E,WMe,vpr,Fpr,jJ,Tpr,Mpr,Epr,kE,UMe,Cpr,wpr,DJ,Apr,Lpr,ypr,SE,HMe,xpr,$pr,GJ,kpr,Spr,Rpr,RE,JMe,Ppr,Bpr,OJ,Ipr,Npr,qpr,PE,YMe,jpr,Dpr,VJ,Gpr,Opr,Vpr,BE,KMe,Xpr,zpr,XJ,Qpr,Wpr,Upr,IE,Hpr,ZMe,Jpr,Ypr,eEe,Kpr,Zpr,NE,cKe,Qd,qE,oEe,zx,e_r,rEe,o_r,mKe,Xo,Qx,r_r,Wd,t_r,zJ,a_r,n_r,QJ,s_r,l_r,i_r,Wx,d_r,tEe,c_r,m_r,f_r,Lt,Ux,g_r,aEe,h_r,u_r,Ud,p_r,nEe,__r,b_r,WJ,v_r,F_r,T_r,jE,M_r,co,Hx,E_r,sEe,C_r,w_r,sn,A_r,lEe,L_r,y_r,iEe,x_r,$_r,dEe,k_r,S_r,R_r,cEe,DE,mEe,P_r,B_r,UJ,I_r,N_r,q_r,GE,j_r,fEe,D_r,G_r,gEe,O_r,V_r,OE,fKe,Hd,VE,hEe,Jx,X_r,uEe,z_r,gKe,zo,Yx,Q_r,Jd,W_r,HJ,U_r,H_r,JJ,J_r,Y_r,K_r,Kx,Z_r,pEe,e2r,o2r,r2r,yt,Zx,t2r,_Ee,a2r,n2r,Yd,s2r,bEe,l2r,i2r,YJ,d2r,c2r,m2r,XE,f2r,mo,e$,g2r,vEe,h2r,u2r,ln,p2r,FEe,_2r,b2r,TEe,v2r,F2r,MEe,T2r,M2r,E2r,Kd,zE,EEe,C2r,w2r,KJ,A2r,L2r,y2r,QE,CEe,x2r,$2r,ZJ,k2r,S2r,R2r,WE,wEe,P2r,B2r,eY,I2r,N2r,q2r,UE,j2r,AEe,D2r,G2r,LEe,O2r,V2r,HE,hKe,Zd,JE,yEe,o$,X2r,xEe,z2r,uKe,Qo,r$,Q2r,ec,W2r,oY,U2r,H2r,rY,J2r,Y2r,K2r,t$,Z2r,$Ee,ebr,obr,rbr,xt,a$,tbr,kEe,abr,nbr,oc,sbr,SEe,lbr,ibr,tY,dbr,cbr,mbr,YE,fbr,fo,n$,gbr,REe,hbr,ubr,dn,pbr,PEe,_br,bbr,BEe,vbr,Fbr,IEe,Tbr,Mbr,Ebr,be,KE,NEe,Cbr,wbr,aY,Abr,Lbr,ybr,ZE,qEe,xbr,$br,nY,kbr,Sbr,Rbr,e4,jEe,Pbr,Bbr,sY,Ibr,Nbr,qbr,o4,DEe,jbr,Dbr,lY,Gbr,Obr,Vbr,_l,GEe,Xbr,zbr,iY,Qbr,Wbr,dY,Ubr,Hbr,Jbr,r4,OEe,Ybr,Kbr,cY,Zbr,e1r,o1r,bl,VEe,r1r,t1r,mY,a1r,n1r,fY,s1r,l1r,i1r,t4,XEe,d1r,c1r,gY,m1r,f1r,g1r,$t,zEe,h1r,u1r,hY,p1r,_1r,uY,b1r,v1r,pY,F1r,T1r,M1r,a4,QEe,E1r,C1r,_Y,w1r,A1r,L1r,n4,WEe,y1r,x1r,bY,$1r,k1r,S1r,s4,UEe,R1r,P1r,vY,B1r,I1r,N1r,l4,HEe,q1r,j1r,FY,D1r,G1r,O1r,i4,JEe,V1r,X1r,TY,z1r,Q1r,W1r,d4,YEe,U1r,H1r,MY,J1r,Y1r,K1r,c4,KEe,Z1r,evr,EY,ovr,rvr,tvr,m4,ZEe,avr,nvr,CY,svr,lvr,ivr,f4,dvr,e4e,cvr,mvr,o4e,fvr,gvr,g4,pKe,rc,h4,r4e,s$,hvr,t4e,uvr,_Ke,Wo,l$,pvr,tc,_vr,wY,bvr,vvr,AY,Fvr,Tvr,Mvr,i$,Evr,a4e,Cvr,wvr,Avr,kt,d$,Lvr,n4e,yvr,xvr,ac,$vr,s4e,kvr,Svr,LY,Rvr,Pvr,Bvr,u4,Ivr,go,c$,Nvr,l4e,qvr,jvr,cn,Dvr,i4e,Gvr,Ovr,d4e,Vvr,Xvr,c4e,zvr,Qvr,Wvr,m4e,p4,f4e,Uvr,Hvr,yY,Jvr,Yvr,Kvr,_4,Zvr,g4e,eFr,oFr,h4e,rFr,tFr,b4,bKe,nc,v4,u4e,m$,aFr,p4e,nFr,vKe,Uo,f$,sFr,sc,lFr,xY,iFr,dFr,$Y,cFr,mFr,fFr,g$,gFr,_4e,hFr,uFr,pFr,St,h$,_Fr,b4e,bFr,vFr,lc,FFr,v4e,TFr,MFr,kY,EFr,CFr,wFr,F4,AFr,ho,u$,LFr,F4e,yFr,xFr,mn,$Fr,T4e,kFr,SFr,M4e,RFr,PFr,E4e,BFr,IFr,NFr,C4e,T4,w4e,qFr,jFr,SY,DFr,GFr,OFr,M4,VFr,A4e,XFr,zFr,L4e,QFr,WFr,E4,FKe,ic,C4,y4e,p$,UFr,x4e,HFr,TKe,Ho,_$,JFr,dc,YFr,RY,KFr,ZFr,PY,eTr,oTr,rTr,b$,tTr,$4e,aTr,nTr,sTr,Rt,v$,lTr,k4e,iTr,dTr,cc,cTr,S4e,mTr,fTr,BY,gTr,hTr,uTr,w4,pTr,uo,F$,_Tr,R4e,bTr,vTr,fn,FTr,P4e,TTr,MTr,B4e,ETr,CTr,I4e,wTr,ATr,LTr,N4e,A4,q4e,yTr,xTr,IY,$Tr,kTr,STr,L4,RTr,j4e,PTr,BTr,D4e,ITr,NTr,y4,MKe,mc,x4,G4e,T$,qTr,O4e,jTr,EKe,Jo,M$,DTr,fc,GTr,NY,OTr,VTr,qY,XTr,zTr,QTr,E$,WTr,V4e,UTr,HTr,JTr,Pt,C$,YTr,X4e,KTr,ZTr,gc,eMr,z4e,oMr,rMr,jY,tMr,aMr,nMr,$4,sMr,po,w$,lMr,Q4e,iMr,dMr,gn,cMr,W4e,mMr,fMr,U4e,gMr,hMr,H4e,uMr,pMr,_Mr,Pe,k4,J4e,bMr,vMr,DY,FMr,TMr,MMr,S4,Y4e,EMr,CMr,GY,wMr,AMr,LMr,R4,K4e,yMr,xMr,OY,$Mr,kMr,SMr,P4,Z4e,RMr,PMr,VY,BMr,IMr,NMr,B4,eCe,qMr,jMr,XY,DMr,GMr,OMr,I4,oCe,VMr,XMr,zY,zMr,QMr,WMr,N4,rCe,UMr,HMr,QY,JMr,YMr,KMr,q4,tCe,ZMr,eEr,WY,oEr,rEr,tEr,j4,aCe,aEr,nEr,UY,sEr,lEr,iEr,D4,dEr,nCe,cEr,mEr,sCe,fEr,gEr,G4,CKe,hc,O4,lCe,A$,hEr,iCe,uEr,wKe,Yo,L$,pEr,uc,_Er,HY,bEr,vEr,JY,FEr,TEr,MEr,y$,EEr,dCe,CEr,wEr,AEr,Bt,x$,LEr,cCe,yEr,xEr,pc,$Er,mCe,kEr,SEr,YY,REr,PEr,BEr,V4,IEr,_o,$$,NEr,fCe,qEr,jEr,hn,DEr,gCe,GEr,OEr,hCe,VEr,XEr,uCe,zEr,QEr,WEr,mt,X4,pCe,UEr,HEr,KY,JEr,YEr,KEr,z4,_Ce,ZEr,e4r,ZY,o4r,r4r,t4r,Q4,bCe,a4r,n4r,eK,s4r,l4r,i4r,W4,vCe,d4r,c4r,oK,m4r,f4r,g4r,U4,FCe,h4r,u4r,rK,p4r,_4r,b4r,H4,v4r,TCe,F4r,T4r,MCe,M4r,E4r,J4,AKe,_c,Y4,ECe,k$,C4r,CCe,w4r,LKe,Ko,S$,A4r,bc,L4r,tK,y4r,x4r,aK,$4r,k4r,S4r,R$,R4r,wCe,P4r,B4r,I4r,It,P$,N4r,ACe,q4r,j4r,vc,D4r,LCe,G4r,O4r,nK,V4r,X4r,z4r,K4,Q4r,bo,B$,W4r,yCe,U4r,H4r,un,J4r,xCe,Y4r,K4r,$Ce,Z4r,eCr,kCe,oCr,rCr,tCr,Le,Z4,SCe,aCr,nCr,sK,sCr,lCr,iCr,eC,RCe,dCr,cCr,lK,mCr,fCr,gCr,oC,PCe,hCr,uCr,iK,pCr,_Cr,bCr,rC,BCe,vCr,FCr,dK,TCr,MCr,ECr,tC,ICe,CCr,wCr,cK,ACr,LCr,yCr,aC,NCe,xCr,$Cr,mK,kCr,SCr,RCr,nC,qCe,PCr,BCr,fK,ICr,NCr,qCr,sC,jCe,jCr,DCr,gK,GCr,OCr,VCr,lC,DCe,XCr,zCr,hK,QCr,WCr,UCr,iC,GCe,HCr,JCr,uK,YCr,KCr,ZCr,dC,e3r,OCe,o3r,r3r,VCe,t3r,a3r,cC,yKe,Fc,mC,XCe,I$,n3r,zCe,s3r,xKe,Zo,N$,l3r,Tc,i3r,pK,d3r,c3r,_K,m3r,f3r,g3r,q$,h3r,QCe,u3r,p3r,_3r,Nt,j$,b3r,WCe,v3r,F3r,Mc,T3r,UCe,M3r,E3r,bK,C3r,w3r,A3r,fC,L3r,vo,D$,y3r,HCe,x3r,$3r,pn,k3r,JCe,S3r,R3r,YCe,P3r,B3r,KCe,I3r,N3r,q3r,G$,gC,ZCe,j3r,D3r,vK,G3r,O3r,V3r,hC,e3e,X3r,z3r,FK,Q3r,W3r,U3r,uC,H3r,o3e,J3r,Y3r,r3e,K3r,Z3r,pC,$Ke,Ec,_C,t3e,O$,e5r,a3e,o5r,kKe,er,V$,r5r,Cc,t5r,TK,a5r,n5r,MK,s5r,l5r,i5r,X$,d5r,n3e,c5r,m5r,f5r,qt,z$,g5r,s3e,h5r,u5r,wc,p5r,l3e,_5r,b5r,EK,v5r,F5r,T5r,bC,M5r,Fo,Q$,E5r,i3e,C5r,w5r,_n,A5r,d3e,L5r,y5r,c3e,x5r,$5r,m3e,k5r,S5r,R5r,ft,vC,f3e,P5r,B5r,CK,I5r,N5r,q5r,FC,g3e,j5r,D5r,wK,G5r,O5r,V5r,TC,h3e,X5r,z5r,AK,Q5r,W5r,U5r,MC,u3e,H5r,J5r,LK,Y5r,K5r,Z5r,EC,p3e,e0r,o0r,yK,r0r,t0r,a0r,CC,n0r,_3e,s0r,l0r,b3e,i0r,d0r,wC,SKe,Ac,AC,v3e,W$,c0r,F3e,m0r,RKe,or,U$,f0r,Lc,g0r,xK,h0r,u0r,$K,p0r,_0r,b0r,H$,v0r,T3e,F0r,T0r,M0r,jt,J$,E0r,M3e,C0r,w0r,yc,A0r,E3e,L0r,y0r,kK,x0r,$0r,k0r,LC,S0r,To,Y$,R0r,C3e,P0r,B0r,bn,I0r,w3e,N0r,q0r,A3e,j0r,D0r,L3e,G0r,O0r,V0r,vn,yC,y3e,X0r,z0r,SK,Q0r,W0r,U0r,xC,x3e,H0r,J0r,RK,Y0r,K0r,Z0r,$C,$3e,ewr,owr,PK,rwr,twr,awr,kC,k3e,nwr,swr,BK,lwr,iwr,dwr,SC,cwr,S3e,mwr,fwr,R3e,gwr,hwr,RC,PKe,xc,PC,P3e,K$,uwr,B3e,pwr,BKe,rr,Z$,_wr,$c,bwr,IK,vwr,Fwr,NK,Twr,Mwr,Ewr,ek,Cwr,I3e,wwr,Awr,Lwr,Dt,ok,ywr,N3e,xwr,$wr,kc,kwr,q3e,Swr,Rwr,qK,Pwr,Bwr,Iwr,BC,Nwr,Mo,rk,qwr,j3e,jwr,Dwr,Fn,Gwr,D3e,Owr,Vwr,G3e,Xwr,zwr,O3e,Qwr,Wwr,Uwr,tk,IC,V3e,Hwr,Jwr,jK,Ywr,Kwr,Zwr,NC,X3e,eAr,oAr,DK,rAr,tAr,aAr,qC,nAr,z3e,sAr,lAr,Q3e,iAr,dAr,jC,IKe,Sc,DC,W3e,ak,cAr,U3e,mAr,NKe,tr,nk,fAr,Rc,gAr,GK,hAr,uAr,OK,pAr,_Ar,bAr,sk,vAr,H3e,FAr,TAr,MAr,Gt,lk,EAr,J3e,CAr,wAr,Pc,AAr,Y3e,LAr,yAr,VK,xAr,$Ar,kAr,GC,SAr,Eo,ik,RAr,K3e,PAr,BAr,Tn,IAr,Z3e,NAr,qAr,e5e,jAr,DAr,o5e,GAr,OAr,VAr,r5e,OC,t5e,XAr,zAr,XK,QAr,WAr,UAr,VC,HAr,a5e,JAr,YAr,n5e,KAr,ZAr,XC,qKe,Bc,zC,s5e,dk,e6r,l5e,o6r,jKe,ar,ck,r6r,Ic,t6r,zK,a6r,n6r,QK,s6r,l6r,i6r,mk,d6r,i5e,c6r,m6r,f6r,Ot,fk,g6r,d5e,h6r,u6r,Nc,p6r,c5e,_6r,b6r,WK,v6r,F6r,T6r,QC,M6r,Co,gk,E6r,m5e,C6r,w6r,Mn,A6r,f5e,L6r,y6r,g5e,x6r,$6r,h5e,k6r,S6r,R6r,gt,WC,u5e,P6r,B6r,UK,I6r,N6r,q6r,UC,p5e,j6r,D6r,HK,G6r,O6r,V6r,HC,_5e,X6r,z6r,JK,Q6r,W6r,U6r,JC,b5e,H6r,J6r,YK,Y6r,K6r,Z6r,YC,v5e,e7r,o7r,KK,r7r,t7r,a7r,KC,n7r,F5e,s7r,l7r,T5e,i7r,d7r,ZC,DKe,qc,e3,M5e,hk,c7r,E5e,m7r,GKe,nr,uk,f7r,jc,g7r,ZK,h7r,u7r,eZ,p7r,_7r,b7r,pk,v7r,C5e,F7r,T7r,M7r,Vt,_k,E7r,w5e,C7r,w7r,Dc,A7r,A5e,L7r,y7r,oZ,x7r,$7r,k7r,o3,S7r,wo,bk,R7r,L5e,P7r,B7r,En,I7r,y5e,N7r,q7r,x5e,j7r,D7r,$5e,G7r,O7r,V7r,k5e,r3,S5e,X7r,z7r,rZ,Q7r,W7r,U7r,t3,H7r,R5e,J7r,Y7r,P5e,K7r,Z7r,a3,OKe,Gc,n3,B5e,vk,eLr,I5e,oLr,VKe,sr,Fk,rLr,Oc,tLr,tZ,aLr,nLr,aZ,sLr,lLr,iLr,Tk,dLr,N5e,cLr,mLr,fLr,Xt,Mk,gLr,q5e,hLr,uLr,Vc,pLr,j5e,_Lr,bLr,nZ,vLr,FLr,TLr,s3,MLr,Ir,Ek,ELr,D5e,CLr,wLr,Cn,ALr,G5e,LLr,yLr,O5e,xLr,$Lr,V5e,kLr,SLr,RLr,N,l3,X5e,PLr,BLr,sZ,ILr,NLr,qLr,i3,z5e,jLr,DLr,lZ,GLr,OLr,VLr,d3,Q5e,XLr,zLr,iZ,QLr,WLr,ULr,c3,W5e,HLr,JLr,dZ,YLr,KLr,ZLr,m3,U5e,eyr,oyr,cZ,ryr,tyr,ayr,f3,H5e,nyr,syr,mZ,lyr,iyr,dyr,g3,J5e,cyr,myr,fZ,fyr,gyr,hyr,h3,Y5e,uyr,pyr,gZ,_yr,byr,vyr,u3,K5e,Fyr,Tyr,hZ,Myr,Eyr,Cyr,p3,Z5e,wyr,Ayr,uZ,Lyr,yyr,xyr,_3,e0e,$yr,kyr,pZ,Syr,Ryr,Pyr,b3,o0e,Byr,Iyr,_Z,Nyr,qyr,jyr,v3,r0e,Dyr,Gyr,bZ,Oyr,Vyr,Xyr,F3,t0e,zyr,Qyr,vZ,Wyr,Uyr,Hyr,T3,a0e,Jyr,Yyr,FZ,Kyr,Zyr,e8r,M3,n0e,o8r,r8r,TZ,t8r,a8r,n8r,E3,s0e,s8r,l8r,MZ,i8r,d8r,c8r,C3,l0e,m8r,f8r,EZ,g8r,h8r,u8r,vl,i0e,p8r,_8r,CZ,b8r,v8r,wZ,F8r,T8r,M8r,w3,d0e,E8r,C8r,AZ,w8r,A8r,L8r,A3,c0e,y8r,x8r,LZ,$8r,k8r,S8r,L3,m0e,R8r,P8r,yZ,B8r,I8r,N8r,y3,f0e,q8r,j8r,xZ,D8r,G8r,O8r,x3,g0e,V8r,X8r,$Z,z8r,Q8r,W8r,$3,h0e,U8r,H8r,kZ,J8r,Y8r,K8r,k3,u0e,Z8r,e9r,SZ,o9r,r9r,t9r,S3,p0e,a9r,n9r,RZ,s9r,l9r,i9r,R3,_0e,d9r,c9r,PZ,m9r,f9r,g9r,P3,b0e,h9r,u9r,BZ,p9r,_9r,b9r,B3,v0e,v9r,F9r,IZ,T9r,M9r,E9r,I3,F0e,C9r,w9r,NZ,A9r,L9r,y9r,N3,T0e,x9r,$9r,qZ,k9r,S9r,R9r,q3,M0e,P9r,B9r,jZ,I9r,N9r,q9r,j3,E0e,j9r,D9r,DZ,G9r,O9r,V9r,D3,C0e,X9r,z9r,GZ,Q9r,W9r,U9r,G3,w0e,H9r,J9r,OZ,Y9r,K9r,Z9r,O3,A0e,exr,oxr,VZ,rxr,txr,axr,V3,L0e,nxr,sxr,XZ,lxr,ixr,dxr,X3,y0e,cxr,mxr,zZ,fxr,gxr,hxr,z3,x0e,uxr,pxr,QZ,_xr,bxr,vxr,Q3,$0e,Fxr,Txr,WZ,Mxr,Exr,Cxr,W3,k0e,wxr,Axr,UZ,Lxr,yxr,xxr,U3,S0e,$xr,kxr,HZ,Sxr,Rxr,Pxr,H3,R0e,Bxr,Ixr,JZ,Nxr,qxr,jxr,J3,P0e,Dxr,Gxr,YZ,Oxr,Vxr,Xxr,Y3,B0e,zxr,Qxr,KZ,Wxr,Uxr,Hxr,K3,I0e,Jxr,Yxr,ZZ,Kxr,Zxr,e$r,Z3,N0e,o$r,r$r,eee,t$r,a$r,n$r,e5,q0e,s$r,l$r,oee,i$r,d$r,c$r,o5,j0e,m$r,f$r,ree,g$r,h$r,u$r,r5,D0e,p$r,_$r,tee,b$r,v$r,F$r,t5,G0e,T$r,M$r,aee,E$r,C$r,w$r,a5,O0e,A$r,L$r,nee,y$r,x$r,$$r,n5,V0e,k$r,S$r,see,R$r,P$r,B$r,s5,XKe,Xc,l5,X0e,Ck,I$r,z0e,N$r,zKe,lr,wk,q$r,zc,j$r,lee,D$r,G$r,iee,O$r,V$r,X$r,Ak,z$r,Q0e,Q$r,W$r,U$r,zt,Lk,H$r,W0e,J$r,Y$r,Qc,K$r,U0e,Z$r,ekr,dee,okr,rkr,tkr,i5,akr,Nr,yk,nkr,H0e,skr,lkr,wn,ikr,J0e,dkr,ckr,Y0e,mkr,fkr,K0e,gkr,hkr,ukr,se,d5,Z0e,pkr,_kr,cee,bkr,vkr,Fkr,c5,ewe,Tkr,Mkr,mee,Ekr,Ckr,wkr,m5,owe,Akr,Lkr,fee,ykr,xkr,$kr,f5,rwe,kkr,Skr,gee,Rkr,Pkr,Bkr,g5,twe,Ikr,Nkr,hee,qkr,jkr,Dkr,h5,awe,Gkr,Okr,uee,Vkr,Xkr,zkr,u5,nwe,Qkr,Wkr,pee,Ukr,Hkr,Jkr,p5,swe,Ykr,Kkr,_ee,Zkr,eSr,oSr,_5,lwe,rSr,tSr,bee,aSr,nSr,sSr,b5,iwe,lSr,iSr,vee,dSr,cSr,mSr,v5,dwe,fSr,gSr,Fee,hSr,uSr,pSr,F5,cwe,_Sr,bSr,Tee,vSr,FSr,TSr,T5,mwe,MSr,ESr,Mee,CSr,wSr,ASr,M5,fwe,LSr,ySr,Eee,xSr,$Sr,kSr,E5,gwe,SSr,RSr,Cee,PSr,BSr,ISr,C5,hwe,NSr,qSr,wee,jSr,DSr,GSr,w5,uwe,OSr,VSr,Aee,XSr,zSr,QSr,A5,pwe,WSr,USr,Lee,HSr,JSr,YSr,L5,_we,KSr,ZSr,yee,eRr,oRr,rRr,y5,bwe,tRr,aRr,xee,nRr,sRr,lRr,x5,vwe,iRr,dRr,$ee,cRr,mRr,fRr,$5,Fwe,gRr,hRr,kee,uRr,pRr,_Rr,k5,Twe,bRr,vRr,See,FRr,TRr,MRr,S5,QKe,Wc,R5,Mwe,xk,ERr,Ewe,CRr,WKe,ir,$k,wRr,Uc,ARr,Ree,LRr,yRr,Pee,xRr,$Rr,kRr,kk,SRr,Cwe,RRr,PRr,BRr,Qt,Sk,IRr,wwe,NRr,qRr,Hc,jRr,Awe,DRr,GRr,Bee,ORr,VRr,XRr,P5,zRr,qr,Rk,QRr,Lwe,WRr,URr,An,HRr,ywe,JRr,YRr,xwe,KRr,ZRr,$we,ePr,oPr,rPr,Me,B5,kwe,tPr,aPr,Iee,nPr,sPr,lPr,I5,Swe,iPr,dPr,Nee,cPr,mPr,fPr,N5,Rwe,gPr,hPr,qee,uPr,pPr,_Pr,q5,Pwe,bPr,vPr,jee,FPr,TPr,MPr,j5,Bwe,EPr,CPr,Dee,wPr,APr,LPr,D5,Iwe,yPr,xPr,Gee,$Pr,kPr,SPr,G5,Nwe,RPr,PPr,Oee,BPr,IPr,NPr,O5,qwe,qPr,jPr,Vee,DPr,GPr,OPr,V5,jwe,VPr,XPr,Xee,zPr,QPr,WPr,X5,Dwe,UPr,HPr,zee,JPr,YPr,KPr,z5,Gwe,ZPr,eBr,Qee,oBr,rBr,tBr,Q5,Owe,aBr,nBr,Wee,sBr,lBr,iBr,W5,Vwe,dBr,cBr,Uee,mBr,fBr,gBr,U5,Xwe,hBr,uBr,Hee,pBr,_Br,bBr,H5,UKe,Jc,J5,zwe,Pk,vBr,Qwe,FBr,HKe,dr,Bk,TBr,Yc,MBr,Jee,EBr,CBr,Yee,wBr,ABr,LBr,Ik,yBr,Wwe,xBr,$Br,kBr,Wt,Nk,SBr,Uwe,RBr,PBr,Kc,BBr,Hwe,IBr,NBr,Kee,qBr,jBr,DBr,Y5,GBr,jr,qk,OBr,Jwe,VBr,XBr,Ln,zBr,Ywe,QBr,WBr,Kwe,UBr,HBr,Zwe,JBr,YBr,KBr,Be,K5,eAe,ZBr,eIr,Zee,oIr,rIr,tIr,Z5,oAe,aIr,nIr,eoe,sIr,lIr,iIr,Fl,rAe,dIr,cIr,ooe,mIr,fIr,roe,gIr,hIr,uIr,e0,tAe,pIr,_Ir,toe,bIr,vIr,FIr,o0,aAe,TIr,MIr,aoe,EIr,CIr,wIr,r0,nAe,AIr,LIr,noe,yIr,xIr,$Ir,t0,sAe,kIr,SIr,soe,RIr,PIr,BIr,a0,lAe,IIr,NIr,loe,qIr,jIr,DIr,n0,iAe,GIr,OIr,ioe,VIr,XIr,zIr,s0,JKe,Zc,l0,dAe,jk,QIr,cAe,WIr,YKe,cr,Dk,UIr,em,HIr,doe,JIr,YIr,coe,KIr,ZIr,eNr,Gk,oNr,mAe,rNr,tNr,aNr,Ut,Ok,nNr,fAe,sNr,lNr,om,iNr,gAe,dNr,cNr,moe,mNr,fNr,gNr,i0,hNr,Dr,Vk,uNr,hAe,pNr,_Nr,yn,bNr,uAe,vNr,FNr,pAe,TNr,MNr,_Ae,ENr,CNr,wNr,rm,d0,bAe,ANr,LNr,foe,yNr,xNr,$Nr,c0,vAe,kNr,SNr,goe,RNr,PNr,BNr,m0,FAe,INr,NNr,hoe,qNr,jNr,DNr,f0,KKe,tm,g0,TAe,Xk,GNr,MAe,ONr,ZKe,mr,zk,VNr,am,XNr,uoe,zNr,QNr,poe,WNr,UNr,HNr,Qk,JNr,EAe,YNr,KNr,ZNr,Ht,Wk,eqr,CAe,oqr,rqr,nm,tqr,wAe,aqr,nqr,_oe,sqr,lqr,iqr,h0,dqr,Gr,Uk,cqr,AAe,mqr,fqr,xn,gqr,LAe,hqr,uqr,yAe,pqr,_qr,xAe,bqr,vqr,Fqr,fe,u0,$Ae,Tqr,Mqr,boe,Eqr,Cqr,wqr,p0,kAe,Aqr,Lqr,voe,yqr,xqr,$qr,_0,SAe,kqr,Sqr,Foe,Rqr,Pqr,Bqr,b0,RAe,Iqr,Nqr,Toe,qqr,jqr,Dqr,v0,PAe,Gqr,Oqr,Moe,Vqr,Xqr,zqr,F0,BAe,Qqr,Wqr,Eoe,Uqr,Hqr,Jqr,T0,IAe,Yqr,Kqr,Coe,Zqr,ejr,ojr,M0,NAe,rjr,tjr,woe,ajr,njr,sjr,E0,qAe,ljr,ijr,Aoe,djr,cjr,mjr,C0,jAe,fjr,gjr,Loe,hjr,ujr,pjr,w0,DAe,_jr,bjr,yoe,vjr,Fjr,Tjr,A0,GAe,Mjr,Ejr,xoe,Cjr,wjr,Ajr,L0,OAe,Ljr,yjr,$oe,xjr,$jr,kjr,y0,VAe,Sjr,Rjr,koe,Pjr,Bjr,Ijr,x0,XAe,Njr,qjr,Soe,jjr,Djr,Gjr,$0,zAe,Ojr,Vjr,Roe,Xjr,zjr,Qjr,k0,QAe,Wjr,Ujr,Poe,Hjr,Jjr,Yjr,S0,WAe,Kjr,Zjr,Boe,eDr,oDr,rDr,R0,UAe,tDr,aDr,Ioe,nDr,sDr,lDr,P0,HAe,iDr,dDr,Noe,cDr,mDr,fDr,B0,eZe,sm,I0,JAe,Hk,gDr,YAe,hDr,oZe,fr,Jk,uDr,lm,pDr,qoe,_Dr,bDr,joe,vDr,FDr,TDr,Yk,MDr,KAe,EDr,CDr,wDr,Jt,Kk,ADr,ZAe,LDr,yDr,im,xDr,e6e,$Dr,kDr,Doe,SDr,RDr,PDr,N0,BDr,Or,Zk,IDr,o6e,NDr,qDr,$n,jDr,r6e,DDr,GDr,t6e,ODr,VDr,a6e,XDr,zDr,QDr,ye,q0,n6e,WDr,UDr,Goe,HDr,JDr,YDr,j0,s6e,KDr,ZDr,Ooe,eGr,oGr,rGr,D0,l6e,tGr,aGr,Voe,nGr,sGr,lGr,G0,i6e,iGr,dGr,Xoe,cGr,mGr,fGr,O0,d6e,gGr,hGr,zoe,uGr,pGr,_Gr,V0,c6e,bGr,vGr,Qoe,FGr,TGr,MGr,X0,m6e,EGr,CGr,Woe,wGr,AGr,LGr,z0,f6e,yGr,xGr,Uoe,$Gr,kGr,SGr,Q0,g6e,RGr,PGr,Hoe,BGr,IGr,NGr,W0,h6e,qGr,jGr,Joe,DGr,GGr,OGr,U0,rZe,dm,H0,u6e,eS,VGr,p6e,XGr,tZe,gr,oS,zGr,cm,QGr,Yoe,WGr,UGr,Koe,HGr,JGr,YGr,rS,KGr,_6e,ZGr,eOr,oOr,Yt,tS,rOr,b6e,tOr,aOr,mm,nOr,v6e,sOr,lOr,Zoe,iOr,dOr,cOr,J0,mOr,Vr,aS,fOr,F6e,gOr,hOr,kn,uOr,T6e,pOr,_Or,M6e,bOr,vOr,E6e,FOr,TOr,MOr,re,Y0,C6e,EOr,COr,ere,wOr,AOr,LOr,K0,w6e,yOr,xOr,ore,$Or,kOr,SOr,Z0,A6e,ROr,POr,rre,BOr,IOr,NOr,ew,L6e,qOr,jOr,tre,DOr,GOr,OOr,ow,y6e,VOr,XOr,are,zOr,QOr,WOr,rw,x6e,UOr,HOr,nre,JOr,YOr,KOr,tw,$6e,ZOr,eVr,sre,oVr,rVr,tVr,aw,k6e,aVr,nVr,lre,sVr,lVr,iVr,nw,S6e,dVr,cVr,ire,mVr,fVr,gVr,sw,R6e,hVr,uVr,dre,pVr,_Vr,bVr,lw,P6e,vVr,FVr,cre,TVr,MVr,EVr,iw,B6e,CVr,wVr,mre,AVr,LVr,yVr,dw,I6e,xVr,$Vr,fre,kVr,SVr,RVr,cw,N6e,PVr,BVr,gre,IVr,NVr,qVr,mw,q6e,jVr,DVr,hre,GVr,OVr,VVr,fw,j6e,XVr,zVr,ure,QVr,WVr,UVr,gw,D6e,HVr,JVr,pre,YVr,KVr,ZVr,hw,G6e,eXr,oXr,_re,rXr,tXr,aXr,uw,O6e,nXr,sXr,bre,lXr,iXr,dXr,pw,V6e,cXr,mXr,vre,fXr,gXr,hXr,_w,X6e,uXr,pXr,Fre,_Xr,bXr,vXr,bw,z6e,FXr,TXr,Tre,MXr,EXr,CXr,vw,Q6e,wXr,AXr,Mre,LXr,yXr,xXr,Fw,W6e,$Xr,kXr,Ere,SXr,RXr,PXr,Tw,U6e,BXr,IXr,Cre,NXr,qXr,jXr,Mw,H6e,DXr,GXr,wre,OXr,VXr,XXr,Ew,J6e,zXr,QXr,Are,WXr,UXr,HXr,Cw,aZe,fm,ww,Y6e,nS,JXr,K6e,YXr,nZe,hr,sS,KXr,gm,ZXr,Lre,ezr,ozr,yre,rzr,tzr,azr,lS,nzr,Z6e,szr,lzr,izr,Kt,iS,dzr,e7e,czr,mzr,hm,fzr,o7e,gzr,hzr,xre,uzr,pzr,_zr,Aw,bzr,Xr,dS,vzr,r7e,Fzr,Tzr,Sn,Mzr,t7e,Ezr,Czr,a7e,wzr,Azr,n7e,Lzr,yzr,xzr,ve,Lw,s7e,$zr,kzr,$re,Szr,Rzr,Pzr,yw,l7e,Bzr,Izr,kre,Nzr,qzr,jzr,xw,i7e,Dzr,Gzr,Sre,Ozr,Vzr,Xzr,$w,d7e,zzr,Qzr,Rre,Wzr,Uzr,Hzr,kw,c7e,Jzr,Yzr,Pre,Kzr,Zzr,eQr,Sw,m7e,oQr,rQr,Bre,tQr,aQr,nQr,Rw,f7e,sQr,lQr,Ire,iQr,dQr,cQr,Pw,g7e,mQr,fQr,Nre,gQr,hQr,uQr,Bw,h7e,pQr,_Qr,qre,bQr,vQr,FQr,Iw,u7e,TQr,MQr,jre,EQr,CQr,wQr,Nw,p7e,AQr,LQr,Dre,yQr,xQr,$Qr,qw,_7e,kQr,SQr,Gre,RQr,PQr,BQr,jw,b7e,IQr,NQr,Ore,qQr,jQr,DQr,Dw,v7e,GQr,OQr,Vre,VQr,XQr,zQr,Gw,F7e,QQr,WQr,Xre,UQr,HQr,JQr,Ow,T7e,YQr,KQr,zre,ZQr,eWr,oWr,Vw,M7e,rWr,tWr,Qre,aWr,nWr,sWr,Xw,sZe,um,zw,E7e,cS,lWr,C7e,iWr,lZe,ur,mS,dWr,pm,cWr,Wre,mWr,fWr,Ure,gWr,hWr,uWr,fS,pWr,w7e,_Wr,bWr,vWr,Zt,gS,FWr,A7e,TWr,MWr,_m,EWr,L7e,CWr,wWr,Hre,AWr,LWr,yWr,Qw,xWr,zr,hS,$Wr,y7e,kWr,SWr,Rn,RWr,x7e,PWr,BWr,$7e,IWr,NWr,k7e,qWr,jWr,DWr,uS,Ww,S7e,GWr,OWr,Jre,VWr,XWr,zWr,Uw,R7e,QWr,WWr,Yre,UWr,HWr,JWr,Hw,iZe,bm,Jw,P7e,pS,YWr,B7e,KWr,dZe,pr,_S,ZWr,vm,eUr,Kre,oUr,rUr,Zre,tUr,aUr,nUr,bS,sUr,I7e,lUr,iUr,dUr,ea,vS,cUr,N7e,mUr,fUr,Fm,gUr,q7e,hUr,uUr,ete,pUr,_Ur,bUr,Yw,vUr,Qr,FS,FUr,j7e,TUr,MUr,Pn,EUr,D7e,CUr,wUr,G7e,AUr,LUr,O7e,yUr,xUr,$Ur,V7e,Kw,X7e,kUr,SUr,ote,RUr,PUr,BUr,Zw,cZe,Tm,eA,z7e,TS,IUr,Q7e,NUr,mZe,_r,MS,qUr,Mm,jUr,rte,DUr,GUr,tte,OUr,VUr,XUr,ES,zUr,W7e,QUr,WUr,UUr,oa,CS,HUr,U7e,JUr,YUr,Em,KUr,H7e,ZUr,eHr,ate,oHr,rHr,tHr,oA,aHr,Wr,wS,nHr,J7e,sHr,lHr,Bn,iHr,Y7e,dHr,cHr,K7e,mHr,fHr,Z7e,gHr,hHr,uHr,eLe,rA,oLe,pHr,_Hr,nte,bHr,vHr,FHr,tA,fZe,Cm,aA,rLe,AS,THr,tLe,MHr,gZe,br,LS,EHr,wm,CHr,ste,wHr,AHr,lte,LHr,yHr,xHr,yS,$Hr,aLe,kHr,SHr,RHr,ra,xS,PHr,nLe,BHr,IHr,Am,NHr,sLe,qHr,jHr,ite,DHr,GHr,OHr,nA,VHr,Ur,$S,XHr,lLe,zHr,QHr,In,WHr,iLe,UHr,HHr,dLe,JHr,YHr,cLe,KHr,ZHr,eJr,de,sA,mLe,oJr,rJr,dte,tJr,aJr,nJr,lA,fLe,sJr,lJr,cte,iJr,dJr,cJr,iA,gLe,mJr,fJr,mte,gJr,hJr,uJr,dA,hLe,pJr,_Jr,fte,bJr,vJr,FJr,cA,uLe,TJr,MJr,gte,EJr,CJr,wJr,mA,pLe,AJr,LJr,hte,yJr,xJr,$Jr,fA,_Le,kJr,SJr,ute,RJr,PJr,BJr,gA,bLe,IJr,NJr,pte,qJr,jJr,DJr,hA,vLe,GJr,OJr,_te,VJr,XJr,zJr,uA,FLe,QJr,WJr,bte,UJr,HJr,JJr,pA,TLe,YJr,KJr,vte,ZJr,eYr,oYr,_A,MLe,rYr,tYr,Fte,aYr,nYr,sYr,bA,ELe,lYr,iYr,Tte,dYr,cYr,mYr,vA,CLe,fYr,gYr,Mte,hYr,uYr,pYr,FA,wLe,_Yr,bYr,Ete,vYr,FYr,TYr,TA,ALe,MYr,EYr,Cte,CYr,wYr,AYr,MA,LLe,LYr,yYr,wte,xYr,$Yr,kYr,EA,yLe,SYr,RYr,Ate,PYr,BYr,IYr,CA,xLe,NYr,qYr,Lte,jYr,DYr,GYr,wA,$Le,OYr,VYr,yte,XYr,zYr,QYr,AA,kLe,WYr,UYr,xte,HYr,JYr,YYr,LA,hZe,Lm,yA,SLe,kS,KYr,RLe,ZYr,uZe,vr,SS,eKr,ym,oKr,$te,rKr,tKr,kte,aKr,nKr,sKr,RS,lKr,PLe,iKr,dKr,cKr,ta,PS,mKr,BLe,fKr,gKr,xm,hKr,ILe,uKr,pKr,Ste,_Kr,bKr,vKr,xA,FKr,Hr,BS,TKr,NLe,MKr,EKr,Nn,CKr,qLe,wKr,AKr,jLe,LKr,yKr,DLe,xKr,$Kr,kKr,ce,$A,GLe,SKr,RKr,Rte,PKr,BKr,IKr,kA,OLe,NKr,qKr,Pte,jKr,DKr,GKr,SA,VLe,OKr,VKr,Bte,XKr,zKr,QKr,RA,XLe,WKr,UKr,Ite,HKr,JKr,YKr,PA,zLe,KKr,ZKr,Nte,eZr,oZr,rZr,BA,QLe,tZr,aZr,qte,nZr,sZr,lZr,IA,WLe,iZr,dZr,jte,cZr,mZr,fZr,NA,ULe,gZr,hZr,Dte,uZr,pZr,_Zr,qA,HLe,bZr,vZr,Gte,FZr,TZr,MZr,jA,JLe,EZr,CZr,Ote,wZr,AZr,LZr,DA,YLe,yZr,xZr,Vte,$Zr,kZr,SZr,GA,KLe,RZr,PZr,Xte,BZr,IZr,NZr,OA,ZLe,qZr,jZr,zte,DZr,GZr,OZr,VA,eye,VZr,XZr,Qte,zZr,QZr,WZr,XA,oye,UZr,HZr,Wte,JZr,YZr,KZr,zA,rye,ZZr,eet,Ute,oet,ret,tet,QA,tye,aet,net,Hte,set,iet,det,WA,aye,cet,met,Jte,fet,get,het,UA,nye,uet,pet,Yte,_et,bet,vet,HA,sye,Fet,Tet,Kte,Met,Eet,Cet,JA,lye,wet,Aet,Zte,Let,yet,xet,YA,pZe,$m,KA,iye,IS,$et,dye,ket,_Ze,Fr,NS,Set,km,Ret,eae,Pet,Bet,oae,Iet,Net,qet,qS,jet,cye,Det,Get,Oet,aa,jS,Vet,mye,Xet,zet,Sm,Qet,fye,Wet,Uet,rae,Het,Jet,Yet,ZA,Ket,Jr,DS,Zet,gye,eot,oot,qn,rot,hye,tot,aot,uye,not,sot,pye,lot,iot,dot,_ye,e6,bye,cot,mot,tae,fot,got,hot,o6,bZe,Rm,r6,vye,GS,uot,Fye,pot,vZe,Tr,OS,_ot,Pm,bot,aae,vot,Fot,nae,Tot,Mot,Eot,VS,Cot,Tye,wot,Aot,Lot,na,XS,yot,Mye,xot,$ot,Bm,kot,Eye,Sot,Rot,sae,Pot,Bot,Iot,t6,Not,Yr,zS,qot,Cye,jot,Dot,jn,Got,wye,Oot,Vot,Aye,Xot,zot,Lye,Qot,Wot,Uot,yye,a6,xye,Hot,Jot,lae,Yot,Kot,Zot,n6,FZe,Im,s6,$ye,QS,ert,kye,ort,TZe,Mr,WS,rrt,Nm,trt,iae,art,nrt,dae,srt,lrt,irt,US,drt,Sye,crt,mrt,frt,sa,HS,grt,Rye,hrt,urt,qm,prt,Pye,_rt,brt,cae,vrt,Frt,Trt,l6,Mrt,Kr,JS,Ert,Bye,Crt,wrt,Dn,Art,Iye,Lrt,yrt,Nye,xrt,$rt,qye,krt,Srt,Rrt,te,i6,jye,Prt,Brt,mae,Irt,Nrt,qrt,d6,Dye,jrt,Drt,fae,Grt,Ort,Vrt,c6,Gye,Xrt,zrt,gae,Qrt,Wrt,Urt,m6,Oye,Hrt,Jrt,hae,Yrt,Krt,Zrt,f6,Vye,ett,ott,uae,rtt,ttt,att,g6,Xye,ntt,stt,pae,ltt,itt,dtt,h6,zye,ctt,mtt,_ae,ftt,gtt,htt,u6,Qye,utt,ptt,bae,_tt,btt,vtt,p6,Wye,Ftt,Ttt,vae,Mtt,Ett,Ctt,_6,Uye,wtt,Att,Fae,Ltt,ytt,xtt,b6,Hye,$tt,ktt,Tae,Stt,Rtt,Ptt,v6,Jye,Btt,Itt,Mae,Ntt,qtt,jtt,F6,Yye,Dtt,Gtt,Eae,Ott,Vtt,Xtt,T6,Kye,ztt,Qtt,Cae,Wtt,Utt,Htt,M6,Zye,Jtt,Ytt,wae,Ktt,Ztt,eat,E6,e8e,oat,rat,Aae,tat,aat,nat,C6,o8e,sat,lat,Lae,iat,dat,cat,w6,r8e,mat,fat,yae,gat,hat,uat,A6,t8e,pat,_at,xae,bat,vat,Fat,L6,a8e,Tat,Mat,$ae,Eat,Cat,wat,y6,n8e,Aat,Lat,kae,yat,xat,$at,x6,s8e,kat,Sat,Sae,Rat,Pat,Bat,$6,l8e,Iat,Nat,Rae,qat,jat,Dat,k6,i8e,Gat,Oat,Pae,Vat,Xat,zat,S6,d8e,Qat,Wat,Bae,Uat,Hat,Jat,R6,c8e,Yat,Kat,Iae,Zat,ent,ont,P6,m8e,rnt,tnt,Nae,ant,nnt,snt,B6,MZe,jm,I6,f8e,YS,lnt,g8e,int,EZe,Er,KS,dnt,Dm,cnt,qae,mnt,fnt,jae,gnt,hnt,unt,ZS,pnt,h8e,_nt,bnt,vnt,la,eR,Fnt,u8e,Tnt,Mnt,Gm,Ent,p8e,Cnt,wnt,Dae,Ant,Lnt,ynt,N6,xnt,Zr,oR,$nt,_8e,knt,Snt,Gn,Rnt,b8e,Pnt,Bnt,v8e,Int,Nnt,F8e,qnt,jnt,Dnt,xe,q6,T8e,Gnt,Ont,Gae,Vnt,Xnt,znt,j6,M8e,Qnt,Wnt,Oae,Unt,Hnt,Jnt,D6,E8e,Ynt,Knt,Vae,Znt,est,ost,G6,C8e,rst,tst,Xae,ast,nst,sst,O6,w8e,lst,ist,zae,dst,cst,mst,V6,A8e,fst,gst,Qae,hst,ust,pst,X6,L8e,_st,bst,Wae,vst,Fst,Tst,z6,y8e,Mst,Est,Uae,Cst,wst,Ast,Q6,x8e,Lst,yst,Hae,xst,$st,kst,W6,$8e,Sst,Rst,Jae,Pst,Bst,Ist,U6,CZe,Om,H6,k8e,rR,Nst,S8e,qst,wZe,Cr,tR,jst,Vm,Dst,Yae,Gst,Ost,Kae,Vst,Xst,zst,aR,Qst,R8e,Wst,Ust,Hst,ia,nR,Jst,P8e,Yst,Kst,Xm,Zst,B8e,elt,olt,Zae,rlt,tlt,alt,J6,nlt,et,sR,slt,I8e,llt,ilt,On,dlt,N8e,clt,mlt,q8e,flt,glt,j8e,hlt,ult,plt,Ee,Y6,D8e,_lt,blt,ene,vlt,Flt,Tlt,K6,G8e,Mlt,Elt,one,Clt,wlt,Alt,Z6,O8e,Llt,ylt,rne,xlt,$lt,klt,e7,V8e,Slt,Rlt,tne,Plt,Blt,Ilt,o7,X8e,Nlt,qlt,ane,jlt,Dlt,Glt,r7,z8e,Olt,Vlt,nne,Xlt,zlt,Qlt,t7,Q8e,Wlt,Ult,sne,Hlt,Jlt,Ylt,a7,W8e,Klt,Zlt,lne,eit,oit,rit,n7,U8e,tit,ait,ine,nit,sit,lit,s7,H8e,iit,dit,dne,cit,mit,fit,l7,J8e,git,hit,cne,uit,pit,_it,i7,Y8e,bit,vit,mne,Fit,Tit,Mit,d7,K8e,Eit,Cit,fne,wit,Ait,Lit,c7,AZe,zm,m7,Z8e,lR,yit,e9e,xit,LZe,wr,iR,$it,Qm,kit,gne,Sit,Rit,hne,Pit,Bit,Iit,dR,Nit,o9e,qit,jit,Dit,da,cR,Git,r9e,Oit,Vit,Wm,Xit,t9e,zit,Qit,une,Wit,Uit,Hit,f7,Jit,ot,mR,Yit,a9e,Kit,Zit,Vn,edt,n9e,odt,rdt,s9e,tdt,adt,l9e,ndt,sdt,ldt,$e,g7,i9e,idt,ddt,pne,cdt,mdt,fdt,h7,d9e,gdt,hdt,_ne,udt,pdt,_dt,u7,c9e,bdt,vdt,bne,Fdt,Tdt,Mdt,p7,m9e,Edt,Cdt,vne,wdt,Adt,Ldt,_7,f9e,ydt,xdt,Fne,$dt,kdt,Sdt,b7,g9e,Rdt,Pdt,Tne,Bdt,Idt,Ndt,v7,h9e,qdt,jdt,Mne,Ddt,Gdt,Odt,F7,u9e,Vdt,Xdt,Ene,zdt,Qdt,Wdt,T7,p9e,Udt,Hdt,Cne,Jdt,Ydt,Kdt,M7,_9e,Zdt,ect,wne,oct,rct,tct,E7,yZe,Um,C7,b9e,fR,act,v9e,nct,xZe,Ar,gR,sct,Hm,lct,Ane,ict,dct,Lne,cct,mct,fct,hR,gct,F9e,hct,uct,pct,ca,uR,_ct,T9e,bct,vct,Jm,Fct,M9e,Tct,Mct,yne,Ect,Cct,wct,w7,Act,rt,pR,Lct,E9e,yct,xct,Xn,$ct,C9e,kct,Sct,w9e,Rct,Pct,A9e,Bct,Ict,Nct,ke,A7,L9e,qct,jct,xne,Dct,Gct,Oct,L7,y9e,Vct,Xct,$ne,zct,Qct,Wct,y7,x9e,Uct,Hct,kne,Jct,Yct,Kct,x7,$9e,Zct,emt,Sne,omt,rmt,tmt,$7,k9e,amt,nmt,Rne,smt,lmt,imt,k7,S9e,dmt,cmt,Pne,mmt,fmt,gmt,S7,R9e,hmt,umt,Bne,pmt,_mt,bmt,R7,P9e,vmt,Fmt,Ine,Tmt,Mmt,Emt,P7,B9e,Cmt,wmt,Nne,Amt,Lmt,ymt,B7,I9e,xmt,$mt,qne,kmt,Smt,Rmt,I7,$Ze,Ym,N7,N9e,_R,Pmt,q9e,Bmt,kZe,Lr,bR,Imt,Km,Nmt,jne,qmt,jmt,Dne,Dmt,Gmt,Omt,vR,Vmt,j9e,Xmt,zmt,Qmt,ma,FR,Wmt,D9e,Umt,Hmt,Zm,Jmt,G9e,Ymt,Kmt,Gne,Zmt,eft,oft,q7,rft,tt,TR,tft,O9e,aft,nft,zn,sft,V9e,lft,ift,X9e,dft,cft,z9e,mft,fft,gft,Se,j7,Q9e,hft,uft,One,pft,_ft,bft,D7,W9e,vft,Fft,Vne,Tft,Mft,Eft,G7,U9e,Cft,wft,Xne,Aft,Lft,yft,O7,H9e,xft,$ft,zne,kft,Sft,Rft,V7,J9e,Pft,Bft,Qne,Ift,Nft,qft,X7,Y9e,jft,Dft,Wne,Gft,Oft,Vft,z7,K9e,Xft,zft,Une,Qft,Wft,Uft,Q7,Z9e,Hft,Jft,Hne,Yft,Kft,Zft,W7,exe,egt,ogt,Jne,rgt,tgt,agt,U7,oxe,ngt,sgt,Yne,lgt,igt,dgt,H7,SZe,ef,J7,rxe,MR,cgt,txe,mgt,RZe,yr,ER,fgt,of,ggt,Kne,hgt,ugt,Zne,pgt,_gt,bgt,CR,vgt,axe,Fgt,Tgt,Mgt,fa,wR,Egt,nxe,Cgt,wgt,rf,Agt,sxe,Lgt,ygt,ese,xgt,$gt,kgt,Y7,Sgt,at,AR,Rgt,lxe,Pgt,Bgt,Qn,Igt,ixe,Ngt,qgt,dxe,jgt,Dgt,cxe,Ggt,Ogt,Vgt,Re,K7,mxe,Xgt,zgt,ose,Qgt,Wgt,Ugt,Z7,fxe,Hgt,Jgt,rse,Ygt,Kgt,Zgt,eL,gxe,eht,oht,tse,rht,tht,aht,oL,hxe,nht,sht,ase,lht,iht,dht,rL,uxe,cht,mht,nse,fht,ght,hht,tL,pxe,uht,pht,sse,_ht,bht,vht,aL,_xe,Fht,Tht,lse,Mht,Eht,Cht,nL,bxe,wht,Aht,ise,Lht,yht,xht,sL,vxe,$ht,kht,dse,Sht,Rht,Pht,lL,Fxe,Bht,Iht,cse,Nht,qht,jht,iL,PZe,tf,dL,Txe,LR,Dht,Mxe,Ght,BZe,xr,yR,Oht,af,Vht,mse,Xht,zht,fse,Qht,Wht,Uht,xR,Hht,Exe,Jht,Yht,Kht,ga,$R,Zht,Cxe,eut,out,nf,rut,wxe,tut,aut,gse,nut,sut,lut,cL,iut,nt,kR,dut,Axe,cut,mut,Wn,fut,Lxe,gut,hut,yxe,uut,put,xxe,_ut,but,vut,Xe,mL,$xe,Fut,Tut,hse,Mut,Eut,Cut,fL,kxe,wut,Aut,use,Lut,yut,xut,gL,Sxe,$ut,kut,pse,Sut,Rut,Put,hL,Rxe,But,Iut,_se,Nut,qut,jut,uL,Pxe,Dut,Gut,bse,Out,Vut,Xut,pL,Bxe,zut,Qut,vse,Wut,Uut,Hut,_L,Ixe,Jut,Yut,Fse,Kut,Zut,ept,bL,Nxe,opt,rpt,Tse,tpt,apt,npt,vL,IZe,sf,FL,qxe,SR,spt,jxe,lpt,NZe,$r,RR,ipt,lf,dpt,Mse,cpt,mpt,Ese,fpt,gpt,hpt,PR,upt,Dxe,ppt,_pt,bpt,ha,BR,vpt,Gxe,Fpt,Tpt,df,Mpt,Oxe,Ept,Cpt,Cse,wpt,Apt,Lpt,TL,ypt,st,IR,xpt,Vxe,$pt,kpt,Un,Spt,Xxe,Rpt,Ppt,zxe,Bpt,Ipt,Qxe,Npt,qpt,jpt,ze,ML,Wxe,Dpt,Gpt,wse,Opt,Vpt,Xpt,EL,Uxe,zpt,Qpt,Ase,Wpt,Upt,Hpt,CL,Hxe,Jpt,Ypt,Lse,Kpt,Zpt,e_t,wL,Jxe,o_t,r_t,yse,t_t,a_t,n_t,AL,Yxe,s_t,l_t,xse,i_t,d_t,c_t,LL,Kxe,m_t,f_t,$se,g_t,h_t,u_t,yL,Zxe,p_t,__t,kse,b_t,v_t,F_t,xL,e$e,T_t,M_t,Sse,E_t,C_t,w_t,$L,qZe,cf,kL,o$e,NR,A_t,r$e,L_t,jZe,kr,qR,y_t,mf,x_t,Rse,$_t,k_t,Pse,S_t,R_t,P_t,jR,B_t,t$e,I_t,N_t,q_t,ua,DR,j_t,a$e,D_t,G_t,ff,O_t,n$e,V_t,X_t,Bse,z_t,Q_t,W_t,SL,U_t,lt,GR,H_t,s$e,J_t,Y_t,Hn,K_t,l$e,Z_t,e2t,i$e,o2t,r2t,d$e,t2t,a2t,n2t,c$e,RL,m$e,s2t,l2t,Ise,i2t,d2t,c2t,PL,DZe,gf,BL,f$e,OR,m2t,g$e,f2t,GZe,Sr,VR,g2t,hf,h2t,Nse,u2t,p2t,qse,_2t,b2t,v2t,XR,F2t,h$e,T2t,M2t,E2t,pa,zR,C2t,u$e,w2t,A2t,uf,L2t,p$e,y2t,x2t,jse,$2t,k2t,S2t,IL,R2t,it,QR,P2t,_$e,B2t,I2t,Jn,N2t,b$e,q2t,j2t,v$e,D2t,G2t,F$e,O2t,V2t,X2t,WR,NL,T$e,z2t,Q2t,Dse,W2t,U2t,H2t,qL,M$e,J2t,Y2t,Gse,K2t,Z2t,ebt,jL,OZe,pf,DL,E$e,UR,obt,C$e,rbt,VZe,Rr,HR,tbt,_f,abt,Ose,nbt,sbt,Vse,lbt,ibt,dbt,JR,cbt,w$e,mbt,fbt,gbt,_a,YR,hbt,A$e,ubt,pbt,bf,_bt,L$e,bbt,vbt,Xse,Fbt,Tbt,Mbt,GL,Ebt,dt,KR,Cbt,y$e,wbt,Abt,Yn,Lbt,x$e,ybt,xbt,$$e,$bt,kbt,k$e,Sbt,Rbt,Pbt,S$e,OL,R$e,Bbt,Ibt,zse,Nbt,qbt,jbt,VL,XZe;return d=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),E9=new oe({}),C9=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Lf=new Dbt({props:{warning:!0,$$slots:{default:[Gfa]},$$scope:{ctx:$}}}),w9=new oe({}),A9=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L635"}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L658"}}),Qh=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Ofa]},$$scope:{ctx:$}}}),$9=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L781"}}),k9=new oe({}),S9=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L426"}}),B9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L440"}}),yu=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Vfa]},$$scope:{ctx:$}}}),I9=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L641"}}),N9=new oe({}),q9=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L200"}}),G9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L214"}}),pp=new Dbt({props:{$$slots:{default:[Xfa]},$$scope:{ctx:$}}}),_p=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[zfa]},$$scope:{ctx:$}}}),O9=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L341"}}),V9=new oe({}),X9=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L92"}}),W9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L106"}}),Gp=new Dbt({props:{$$slots:{default:[Qfa]},$$scope:{ctx:$}}}),Op=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Wfa]},$$scope:{ctx:$}}}),U9=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L259"}}),H9=new oe({}),J9=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L833"}}),K9=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Ufa]},$$scope:{ctx:$}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tb=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Hfa]},$$scope:{ctx:$}}}),ex=new oe({}),ox=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L840"}}),tx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nb=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Jfa]},$$scope:{ctx:$}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Yfa]},$$scope:{ctx:$}}}),nx=new oe({}),sx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L855"}}),ix=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Kfa]},$$scope:{ctx:$}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Zfa]},$$scope:{ctx:$}}}),cx=new oe({}),mx=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L862"}}),gx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),U1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[ega]},$$scope:{ctx:$}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Bv=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[oga]},$$scope:{ctx:$}}}),ux=new oe({}),px=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L869"}}),bx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Nv=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[rga]},$$scope:{ctx:$}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nF=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[tga]},$$scope:{ctx:$}}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L878"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lF=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[aga]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iT=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[nga]},$$scope:{ctx:$}}}),wx=new oe({}),Ax=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L934"}}),yx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cT=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[sga]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XT=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[lga]},$$scope:{ctx:$}}}),$x=new oe({}),kx=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L941"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QT=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[iga]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),oM=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[dga]},$$scope:{ctx:$}}}),Bx=new oe({}),Ix=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L927"}}),qx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),tM=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[cga]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VM=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[mga]},$$scope:{ctx:$}}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L887"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zM=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[fga]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NE=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[gga]},$$scope:{ctx:$}}}),zx=new oe({}),Qx=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L894"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jE=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[hga]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),OE=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[uga]},$$scope:{ctx:$}}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L916"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),XE=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[pga]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HE=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_ga]},$$scope:{ctx:$}}}),o$=new oe({}),r$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L950"}}),a$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YE=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[bga]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g4=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[vga]},$$scope:{ctx:$}}}),s$=new oe({}),l$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L989"}}),d$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u4=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Fga]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),b4=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Tga]},$$scope:{ctx:$}}}),m$=new oe({}),f$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L996"}}),h$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),F4=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Mga]},$$scope:{ctx:$}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E4=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Ega]},$$scope:{ctx:$}}}),p$=new oe({}),_$=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L905"}}),v$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w4=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Cga]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y4=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[wga]},$$scope:{ctx:$}}}),T$=new oe({}),M$=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1003"}}),C$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$4=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Aga]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G4=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Lga]},$$scope:{ctx:$}}}),A$=new oe({}),L$=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1026"}}),x$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V4=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[yga]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J4=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[xga]},$$scope:{ctx:$}}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1010"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K4=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[$ga]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cC=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[kga]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1017"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Sga]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pC=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Rga]},$$scope:{ctx:$}}}),O$=new oe({}),V$=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1035"}}),z$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bC=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Pga]},$$scope:{ctx:$}}}),Q$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wC=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Bga]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1042"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Iga]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),RC=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Nga]},$$scope:{ctx:$}}}),K$=new oe({}),Z$=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L982"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[qga]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[jga]},$$scope:{ctx:$}}}),ak=new oe({}),nk=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L957"}}),lk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Dga]},$$scope:{ctx:$}}}),ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Gga]},$$scope:{ctx:$}}}),dk=new oe({}),ck=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L964"}}),fk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Oga]},$$scope:{ctx:$}}}),gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZC=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Vga]},$$scope:{ctx:$}}}),hk=new oe({}),uk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L973"}}),_k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Xga]},$$scope:{ctx:$}}}),bk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[zga]},$$scope:{ctx:$}}}),vk=new oe({}),Fk=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),Mk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s3=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Qga]},$$scope:{ctx:$}}}),Ek=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Wga]},$$scope:{ctx:$}}}),Ck=new oe({}),wk=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L440"}}),Lk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Uga]},$$scope:{ctx:$}}}),yk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S5=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Hga]},$$scope:{ctx:$}}}),xk=new oe({}),$k=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),Sk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P5=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Jga]},$$scope:{ctx:$}}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H5=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Yga]},$$scope:{ctx:$}}}),Pk=new oe({}),Bk=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),Nk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y5=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Kga]},$$scope:{ctx:$}}}),qk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s0=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Zga]},$$scope:{ctx:$}}}),jk=new oe({}),Dk=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),Ok=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i0=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[eha]},$$scope:{ctx:$}}}),Vk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f0=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[oha]},$$scope:{ctx:$}}}),Xk=new oe({}),zk=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),Wk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h0=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[rha]},$$scope:{ctx:$}}}),Uk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B0=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[tha]},$$scope:{ctx:$}}}),Hk=new oe({}),Jk=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L503"}}),Kk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N0=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[aha]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),U0=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[nha]},$$scope:{ctx:$}}}),eS=new oe({}),oS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),tS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J0=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[sha]},$$scope:{ctx:$}}}),aS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[lha]},$$scope:{ctx:$}}}),nS=new oe({}),sS=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L559"}}),iS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[iha]},$$scope:{ctx:$}}}),dS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Xw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[dha]},$$scope:{ctx:$}}}),cS=new oe({}),mS=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L566"}}),gS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Qw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[cha]},$$scope:{ctx:$}}}),hS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Hw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[mha]},$$scope:{ctx:$}}}),pS=new oe({}),_S=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),vS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Yw=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[fha]},$$scope:{ctx:$}}}),FS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Zw=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[gha]},$$scope:{ctx:$}}}),TS=new oe({}),MS=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),CS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[hha]},$$scope:{ctx:$}}}),wS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[uha]},$$scope:{ctx:$}}}),AS=new oe({}),LS=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),xS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[pha]},$$scope:{ctx:$}}}),$S=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),LA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[_ha]},$$scope:{ctx:$}}}),kS=new oe({}),SS=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),PS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[bha]},$$scope:{ctx:$}}}),BS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[vha]},$$scope:{ctx:$}}}),IS=new oe({}),NS=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L489"}}),jS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ZA=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Fha]},$$scope:{ctx:$}}}),DS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Tha]},$$scope:{ctx:$}}}),GS=new oe({}),OS=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L575"}}),XS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Mha]},$$scope:{ctx:$}}}),zS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Eha]},$$scope:{ctx:$}}}),QS=new oe({}),WS=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),HS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l6=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Cha]},$$scope:{ctx:$}}}),JS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[wha]},$$scope:{ctx:$}}}),YS=new oe({}),KS=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),eR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Aha]},$$scope:{ctx:$}}}),oR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),U6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Lha]},$$scope:{ctx:$}}}),rR=new oe({}),tR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),nR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J6=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[yha]},$$scope:{ctx:$}}}),sR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c7=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[xha]},$$scope:{ctx:$}}}),lR=new oe({}),iR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),cR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[$ha]},$$scope:{ctx:$}}}),mR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[kha]},$$scope:{ctx:$}}}),fR=new oe({}),gR=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),uR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Sha]},$$scope:{ctx:$}}}),pR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Rha]},$$scope:{ctx:$}}}),_R=new oe({}),bR=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),FR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Pha]},$$scope:{ctx:$}}}),TR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Bha]},$$scope:{ctx:$}}}),MR=new oe({}),ER=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),wR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y7=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Iha]},$$scope:{ctx:$}}}),AR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iL=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Nha]},$$scope:{ctx:$}}}),LR=new oe({}),yR=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),$R=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[qha]},$$scope:{ctx:$}}}),kR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[jha]},$$scope:{ctx:$}}}),SR=new oe({}),RR=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),BR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),TL=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Dha]},$$scope:{ctx:$}}}),IR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$L=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Gha]},$$scope:{ctx:$}}}),NR=new oe({}),qR=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),DR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Oha]},$$scope:{ctx:$}}}),GR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Vha]},$$scope:{ctx:$}}}),OR=new oe({}),VR=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),zR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Xha]},$$scope:{ctx:$}}}),QR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[zha]},$$scope:{ctx:$}}}),UR=new oe({}),HR=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),YR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Qha]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Wha]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),yo=a("span"),rd=o("Auto Classes"),Mf=l(),pt=a("p"),td=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=a("code"),v9=o("from_pretrained()"),Ef=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),nd=o("Instantiating one of "),Zn=a("a"),F9=o("AutoConfig"),es=o(", "),os=a("a"),T9=o("AutoModel"),sd=o(`, and
`),rs=a("a"),M9=o("AutoTokenizer"),ld=o(" will directly create a class of the relevant architecture. For instance"),Cf=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),CB=o("will create a model that is an instance of "),id=a("a"),wB=o("BertModel"),AB=o("."),xo=l(),Wa=a("p"),LB=o("There is one class of "),wf=a("code"),yB=o("AutoModel"),iro=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),kYe=l(),dd=a("h2"),Af=a("a"),Hie=a("span"),F(E9.$$.fragment),dro=l(),Jie=a("span"),cro=o("Extending the Auto Classes"),SYe=l(),ts=a("p"),mro=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yie=a("code"),fro=o("NewModel"),gro=o(", make sure you have a "),Kie=a("code"),hro=o("NewModelConfig"),uro=o(` then you can add those to the auto
classes like this:`),RYe=l(),F(C9.$$.fragment),PYe=l(),xB=a("p"),pro=o("You will then be able to use the auto classes like you would usually do!"),BYe=l(),F(Lf.$$.fragment),IYe=l(),cd=a("h2"),yf=a("a"),Zie=a("span"),F(w9.$$.fragment),_ro=l(),ede=a("span"),bro=o("AutoConfig"),NYe=l(),$o=a("div"),F(A9.$$.fragment),vro=l(),L9=a("p"),Fro=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),$B=a("a"),Tro=o("from_pretrained()"),Mro=o(" class method."),Ero=l(),y9=a("p"),Cro=o("This class cannot be instantiated directly using "),ode=a("code"),wro=o("__init__()"),Aro=o(" (throws an error)."),Lro=l(),Pr=a("div"),F(x9.$$.fragment),yro=l(),rde=a("p"),xro=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),$ro=l(),md=a("p"),kro=o("The configuration class to instantiate is selected based on the "),tde=a("code"),Sro=o("model_type"),Rro=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ade=a("code"),Pro=o("pretrained_model_name_or_path"),Bro=o(":"),Iro=l(),A=a("ul"),xf=a("li"),nde=a("strong"),Nro=o("albert"),qro=o(" \u2014 "),kB=a("a"),jro=o("AlbertConfig"),Dro=o(" (ALBERT model)"),Gro=l(),$f=a("li"),sde=a("strong"),Oro=o("bart"),Vro=o(" \u2014 "),SB=a("a"),Xro=o("BartConfig"),zro=o(" (BART model)"),Qro=l(),kf=a("li"),lde=a("strong"),Wro=o("beit"),Uro=o(" \u2014 "),RB=a("a"),Hro=o("BeitConfig"),Jro=o(" (BEiT model)"),Yro=l(),Sf=a("li"),ide=a("strong"),Kro=o("bert"),Zro=o(" \u2014 "),PB=a("a"),eto=o("BertConfig"),oto=o(" (BERT model)"),rto=l(),Rf=a("li"),dde=a("strong"),tto=o("bert-generation"),ato=o(" \u2014 "),BB=a("a"),nto=o("BertGenerationConfig"),sto=o(" (Bert Generation model)"),lto=l(),Pf=a("li"),cde=a("strong"),ito=o("big_bird"),dto=o(" \u2014 "),IB=a("a"),cto=o("BigBirdConfig"),mto=o(" (BigBird model)"),fto=l(),Bf=a("li"),mde=a("strong"),gto=o("bigbird_pegasus"),hto=o(" \u2014 "),NB=a("a"),uto=o("BigBirdPegasusConfig"),pto=o(" (BigBird-Pegasus model)"),_to=l(),If=a("li"),fde=a("strong"),bto=o("blenderbot"),vto=o(" \u2014 "),qB=a("a"),Fto=o("BlenderbotConfig"),Tto=o(" (Blenderbot model)"),Mto=l(),Nf=a("li"),gde=a("strong"),Eto=o("blenderbot-small"),Cto=o(" \u2014 "),jB=a("a"),wto=o("BlenderbotSmallConfig"),Ato=o(" (BlenderbotSmall model)"),Lto=l(),qf=a("li"),hde=a("strong"),yto=o("bloom"),xto=o(" \u2014 "),DB=a("a"),$to=o("BloomConfig"),kto=o(" (BLOOM model)"),Sto=l(),jf=a("li"),ude=a("strong"),Rto=o("camembert"),Pto=o(" \u2014 "),GB=a("a"),Bto=o("CamembertConfig"),Ito=o(" (CamemBERT model)"),Nto=l(),Df=a("li"),pde=a("strong"),qto=o("canine"),jto=o(" \u2014 "),OB=a("a"),Dto=o("CanineConfig"),Gto=o(" (CANINE model)"),Oto=l(),Gf=a("li"),_de=a("strong"),Vto=o("clip"),Xto=o(" \u2014 "),VB=a("a"),zto=o("CLIPConfig"),Qto=o(" (CLIP model)"),Wto=l(),Of=a("li"),bde=a("strong"),Uto=o("codegen"),Hto=o(" \u2014 "),XB=a("a"),Jto=o("CodeGenConfig"),Yto=o(" (CodeGen model)"),Kto=l(),Vf=a("li"),vde=a("strong"),Zto=o("convbert"),eao=o(" \u2014 "),zB=a("a"),oao=o("ConvBertConfig"),rao=o(" (ConvBERT model)"),tao=l(),Xf=a("li"),Fde=a("strong"),aao=o("convnext"),nao=o(" \u2014 "),QB=a("a"),sao=o("ConvNextConfig"),lao=o(" (ConvNeXT model)"),iao=l(),zf=a("li"),Tde=a("strong"),dao=o("ctrl"),cao=o(" \u2014 "),WB=a("a"),mao=o("CTRLConfig"),fao=o(" (CTRL model)"),gao=l(),Qf=a("li"),Mde=a("strong"),hao=o("cvt"),uao=o(" \u2014 "),UB=a("a"),pao=o("CvtConfig"),_ao=o(" (CvT model)"),bao=l(),Wf=a("li"),Ede=a("strong"),vao=o("data2vec-audio"),Fao=o(" \u2014 "),HB=a("a"),Tao=o("Data2VecAudioConfig"),Mao=o(" (Data2VecAudio model)"),Eao=l(),Uf=a("li"),Cde=a("strong"),Cao=o("data2vec-text"),wao=o(" \u2014 "),JB=a("a"),Aao=o("Data2VecTextConfig"),Lao=o(" (Data2VecText model)"),yao=l(),Hf=a("li"),wde=a("strong"),xao=o("data2vec-vision"),$ao=o(" \u2014 "),YB=a("a"),kao=o("Data2VecVisionConfig"),Sao=o(" (Data2VecVision model)"),Rao=l(),Jf=a("li"),Ade=a("strong"),Pao=o("deberta"),Bao=o(" \u2014 "),KB=a("a"),Iao=o("DebertaConfig"),Nao=o(" (DeBERTa model)"),qao=l(),Yf=a("li"),Lde=a("strong"),jao=o("deberta-v2"),Dao=o(" \u2014 "),ZB=a("a"),Gao=o("DebertaV2Config"),Oao=o(" (DeBERTa-v2 model)"),Vao=l(),Kf=a("li"),yde=a("strong"),Xao=o("decision_transformer"),zao=o(" \u2014 "),eI=a("a"),Qao=o("DecisionTransformerConfig"),Wao=o(" (Decision Transformer model)"),Uao=l(),Zf=a("li"),xde=a("strong"),Hao=o("deit"),Jao=o(" \u2014 "),oI=a("a"),Yao=o("DeiTConfig"),Kao=o(" (DeiT model)"),Zao=l(),eg=a("li"),$de=a("strong"),eno=o("detr"),ono=o(" \u2014 "),rI=a("a"),rno=o("DetrConfig"),tno=o(" (DETR model)"),ano=l(),og=a("li"),kde=a("strong"),nno=o("distilbert"),sno=o(" \u2014 "),tI=a("a"),lno=o("DistilBertConfig"),ino=o(" (DistilBERT model)"),dno=l(),rg=a("li"),Sde=a("strong"),cno=o("donut-swin"),mno=o(" \u2014 "),aI=a("a"),fno=o("DonutSwinConfig"),gno=o(" (DonutSwin model)"),hno=l(),tg=a("li"),Rde=a("strong"),uno=o("dpr"),pno=o(" \u2014 "),nI=a("a"),_no=o("DPRConfig"),bno=o(" (DPR model)"),vno=l(),ag=a("li"),Pde=a("strong"),Fno=o("dpt"),Tno=o(" \u2014 "),sI=a("a"),Mno=o("DPTConfig"),Eno=o(" (DPT model)"),Cno=l(),ng=a("li"),Bde=a("strong"),wno=o("electra"),Ano=o(" \u2014 "),lI=a("a"),Lno=o("ElectraConfig"),yno=o(" (ELECTRA model)"),xno=l(),sg=a("li"),Ide=a("strong"),$no=o("encoder-decoder"),kno=o(" \u2014 "),iI=a("a"),Sno=o("EncoderDecoderConfig"),Rno=o(" (Encoder decoder model)"),Pno=l(),lg=a("li"),Nde=a("strong"),Bno=o("ernie"),Ino=o(" \u2014 "),dI=a("a"),Nno=o("ErnieConfig"),qno=o(" (ERNIE model)"),jno=l(),ig=a("li"),qde=a("strong"),Dno=o("flaubert"),Gno=o(" \u2014 "),cI=a("a"),Ono=o("FlaubertConfig"),Vno=o(" (FlauBERT model)"),Xno=l(),dg=a("li"),jde=a("strong"),zno=o("flava"),Qno=o(" \u2014 "),mI=a("a"),Wno=o("FlavaConfig"),Uno=o(" (FLAVA model)"),Hno=l(),cg=a("li"),Dde=a("strong"),Jno=o("fnet"),Yno=o(" \u2014 "),fI=a("a"),Kno=o("FNetConfig"),Zno=o(" (FNet model)"),eso=l(),mg=a("li"),Gde=a("strong"),oso=o("fsmt"),rso=o(" \u2014 "),gI=a("a"),tso=o("FSMTConfig"),aso=o(" (FairSeq Machine-Translation model)"),nso=l(),fg=a("li"),Ode=a("strong"),sso=o("funnel"),lso=o(" \u2014 "),hI=a("a"),iso=o("FunnelConfig"),dso=o(" (Funnel Transformer model)"),cso=l(),gg=a("li"),Vde=a("strong"),mso=o("glpn"),fso=o(" \u2014 "),uI=a("a"),gso=o("GLPNConfig"),hso=o(" (GLPN model)"),uso=l(),hg=a("li"),Xde=a("strong"),pso=o("gpt2"),_so=o(" \u2014 "),pI=a("a"),bso=o("GPT2Config"),vso=o(" (OpenAI GPT-2 model)"),Fso=l(),ug=a("li"),zde=a("strong"),Tso=o("gpt_neo"),Mso=o(" \u2014 "),_I=a("a"),Eso=o("GPTNeoConfig"),Cso=o(" (GPT Neo model)"),wso=l(),pg=a("li"),Qde=a("strong"),Aso=o("gpt_neox"),Lso=o(" \u2014 "),bI=a("a"),yso=o("GPTNeoXConfig"),xso=o(" (GPT NeoX model)"),$so=l(),_g=a("li"),Wde=a("strong"),kso=o("gptj"),Sso=o(" \u2014 "),vI=a("a"),Rso=o("GPTJConfig"),Pso=o(" (GPT-J model)"),Bso=l(),bg=a("li"),Ude=a("strong"),Iso=o("groupvit"),Nso=o(" \u2014 "),FI=a("a"),qso=o("GroupViTConfig"),jso=o(" (GroupViT model)"),Dso=l(),vg=a("li"),Hde=a("strong"),Gso=o("hubert"),Oso=o(" \u2014 "),TI=a("a"),Vso=o("HubertConfig"),Xso=o(" (Hubert model)"),zso=l(),Fg=a("li"),Jde=a("strong"),Qso=o("ibert"),Wso=o(" \u2014 "),MI=a("a"),Uso=o("IBertConfig"),Hso=o(" (I-BERT model)"),Jso=l(),Tg=a("li"),Yde=a("strong"),Yso=o("imagegpt"),Kso=o(" \u2014 "),EI=a("a"),Zso=o("ImageGPTConfig"),elo=o(" (ImageGPT model)"),olo=l(),Mg=a("li"),Kde=a("strong"),rlo=o("layoutlm"),tlo=o(" \u2014 "),CI=a("a"),alo=o("LayoutLMConfig"),nlo=o(" (LayoutLM model)"),slo=l(),Eg=a("li"),Zde=a("strong"),llo=o("layoutlmv2"),ilo=o(" \u2014 "),wI=a("a"),dlo=o("LayoutLMv2Config"),clo=o(" (LayoutLMv2 model)"),mlo=l(),Cg=a("li"),ece=a("strong"),flo=o("layoutlmv3"),glo=o(" \u2014 "),AI=a("a"),hlo=o("LayoutLMv3Config"),ulo=o(" (LayoutLMv3 model)"),plo=l(),wg=a("li"),oce=a("strong"),_lo=o("led"),blo=o(" \u2014 "),LI=a("a"),vlo=o("LEDConfig"),Flo=o(" (LED model)"),Tlo=l(),Ag=a("li"),rce=a("strong"),Mlo=o("levit"),Elo=o(" \u2014 "),yI=a("a"),Clo=o("LevitConfig"),wlo=o(" (LeViT model)"),Alo=l(),Lg=a("li"),tce=a("strong"),Llo=o("longformer"),ylo=o(" \u2014 "),xI=a("a"),xlo=o("LongformerConfig"),$lo=o(" (Longformer model)"),klo=l(),yg=a("li"),ace=a("strong"),Slo=o("longt5"),Rlo=o(" \u2014 "),$I=a("a"),Plo=o("LongT5Config"),Blo=o(" (LongT5 model)"),Ilo=l(),xg=a("li"),nce=a("strong"),Nlo=o("luke"),qlo=o(" \u2014 "),kI=a("a"),jlo=o("LukeConfig"),Dlo=o(" (LUKE model)"),Glo=l(),$g=a("li"),sce=a("strong"),Olo=o("lxmert"),Vlo=o(" \u2014 "),SI=a("a"),Xlo=o("LxmertConfig"),zlo=o(" (LXMERT model)"),Qlo=l(),kg=a("li"),lce=a("strong"),Wlo=o("m2m_100"),Ulo=o(" \u2014 "),RI=a("a"),Hlo=o("M2M100Config"),Jlo=o(" (M2M100 model)"),Ylo=l(),Sg=a("li"),ice=a("strong"),Klo=o("marian"),Zlo=o(" \u2014 "),PI=a("a"),eio=o("MarianConfig"),oio=o(" (Marian model)"),rio=l(),Rg=a("li"),dce=a("strong"),tio=o("maskformer"),aio=o(" \u2014 "),BI=a("a"),nio=o("MaskFormerConfig"),sio=o(" (MaskFormer model)"),lio=l(),Pg=a("li"),cce=a("strong"),iio=o("mbart"),dio=o(" \u2014 "),II=a("a"),cio=o("MBartConfig"),mio=o(" (mBART model)"),fio=l(),Bg=a("li"),mce=a("strong"),gio=o("mctct"),hio=o(" \u2014 "),NI=a("a"),uio=o("MCTCTConfig"),pio=o(" (M-CTC-T model)"),_io=l(),Ig=a("li"),fce=a("strong"),bio=o("megatron-bert"),vio=o(" \u2014 "),qI=a("a"),Fio=o("MegatronBertConfig"),Tio=o(" (Megatron-BERT model)"),Mio=l(),Ng=a("li"),gce=a("strong"),Eio=o("mobilebert"),Cio=o(" \u2014 "),jI=a("a"),wio=o("MobileBertConfig"),Aio=o(" (MobileBERT model)"),Lio=l(),qg=a("li"),hce=a("strong"),yio=o("mobilevit"),xio=o(" \u2014 "),DI=a("a"),$io=o("MobileViTConfig"),kio=o(" (MobileViT model)"),Sio=l(),jg=a("li"),uce=a("strong"),Rio=o("mpnet"),Pio=o(" \u2014 "),GI=a("a"),Bio=o("MPNetConfig"),Iio=o(" (MPNet model)"),Nio=l(),Dg=a("li"),pce=a("strong"),qio=o("mt5"),jio=o(" \u2014 "),OI=a("a"),Dio=o("MT5Config"),Gio=o(" (MT5 model)"),Oio=l(),Gg=a("li"),_ce=a("strong"),Vio=o("mvp"),Xio=o(" \u2014 "),VI=a("a"),zio=o("MvpConfig"),Qio=o(" (MVP model)"),Wio=l(),Og=a("li"),bce=a("strong"),Uio=o("nezha"),Hio=o(" \u2014 "),XI=a("a"),Jio=o("NezhaConfig"),Yio=o(" (Nezha model)"),Kio=l(),Vg=a("li"),vce=a("strong"),Zio=o("nystromformer"),edo=o(" \u2014 "),zI=a("a"),odo=o("NystromformerConfig"),rdo=o(" (Nystr\xF6mformer model)"),tdo=l(),Xg=a("li"),Fce=a("strong"),ado=o("openai-gpt"),ndo=o(" \u2014 "),QI=a("a"),sdo=o("OpenAIGPTConfig"),ldo=o(" (OpenAI GPT model)"),ido=l(),zg=a("li"),Tce=a("strong"),ddo=o("opt"),cdo=o(" \u2014 "),WI=a("a"),mdo=o("OPTConfig"),fdo=o(" (OPT model)"),gdo=l(),Qg=a("li"),Mce=a("strong"),hdo=o("owlvit"),udo=o(" \u2014 "),UI=a("a"),pdo=o("OwlViTConfig"),_do=o(" (OWL-ViT model)"),bdo=l(),Wg=a("li"),Ece=a("strong"),vdo=o("pegasus"),Fdo=o(" \u2014 "),HI=a("a"),Tdo=o("PegasusConfig"),Mdo=o(" (Pegasus model)"),Edo=l(),Ug=a("li"),Cce=a("strong"),Cdo=o("pegasus_x"),wdo=o(" \u2014 "),JI=a("a"),Ado=o("PegasusXConfig"),Ldo=o(" (PEGASUS-X model)"),ydo=l(),Hg=a("li"),wce=a("strong"),xdo=o("perceiver"),$do=o(" \u2014 "),YI=a("a"),kdo=o("PerceiverConfig"),Sdo=o(" (Perceiver model)"),Rdo=l(),Jg=a("li"),Ace=a("strong"),Pdo=o("plbart"),Bdo=o(" \u2014 "),KI=a("a"),Ido=o("PLBartConfig"),Ndo=o(" (PLBart model)"),qdo=l(),Yg=a("li"),Lce=a("strong"),jdo=o("poolformer"),Ddo=o(" \u2014 "),ZI=a("a"),Gdo=o("PoolFormerConfig"),Odo=o(" (PoolFormer model)"),Vdo=l(),Kg=a("li"),yce=a("strong"),Xdo=o("prophetnet"),zdo=o(" \u2014 "),eN=a("a"),Qdo=o("ProphetNetConfig"),Wdo=o(" (ProphetNet model)"),Udo=l(),Zg=a("li"),xce=a("strong"),Hdo=o("qdqbert"),Jdo=o(" \u2014 "),oN=a("a"),Ydo=o("QDQBertConfig"),Kdo=o(" (QDQBert model)"),Zdo=l(),eh=a("li"),$ce=a("strong"),eco=o("rag"),oco=o(" \u2014 "),rN=a("a"),rco=o("RagConfig"),tco=o(" (RAG model)"),aco=l(),oh=a("li"),kce=a("strong"),nco=o("realm"),sco=o(" \u2014 "),tN=a("a"),lco=o("RealmConfig"),ico=o(" (REALM model)"),dco=l(),rh=a("li"),Sce=a("strong"),cco=o("reformer"),mco=o(" \u2014 "),aN=a("a"),fco=o("ReformerConfig"),gco=o(" (Reformer model)"),hco=l(),th=a("li"),Rce=a("strong"),uco=o("regnet"),pco=o(" \u2014 "),nN=a("a"),_co=o("RegNetConfig"),bco=o(" (RegNet model)"),vco=l(),ah=a("li"),Pce=a("strong"),Fco=o("rembert"),Tco=o(" \u2014 "),sN=a("a"),Mco=o("RemBertConfig"),Eco=o(" (RemBERT model)"),Cco=l(),nh=a("li"),Bce=a("strong"),wco=o("resnet"),Aco=o(" \u2014 "),lN=a("a"),Lco=o("ResNetConfig"),yco=o(" (ResNet model)"),xco=l(),sh=a("li"),Ice=a("strong"),$co=o("retribert"),kco=o(" \u2014 "),iN=a("a"),Sco=o("RetriBertConfig"),Rco=o(" (RetriBERT model)"),Pco=l(),lh=a("li"),Nce=a("strong"),Bco=o("roberta"),Ico=o(" \u2014 "),dN=a("a"),Nco=o("RobertaConfig"),qco=o(" (RoBERTa model)"),jco=l(),ih=a("li"),qce=a("strong"),Dco=o("roformer"),Gco=o(" \u2014 "),cN=a("a"),Oco=o("RoFormerConfig"),Vco=o(" (RoFormer model)"),Xco=l(),dh=a("li"),jce=a("strong"),zco=o("segformer"),Qco=o(" \u2014 "),mN=a("a"),Wco=o("SegformerConfig"),Uco=o(" (SegFormer model)"),Hco=l(),ch=a("li"),Dce=a("strong"),Jco=o("sew"),Yco=o(" \u2014 "),fN=a("a"),Kco=o("SEWConfig"),Zco=o(" (SEW model)"),emo=l(),mh=a("li"),Gce=a("strong"),omo=o("sew-d"),rmo=o(" \u2014 "),gN=a("a"),tmo=o("SEWDConfig"),amo=o(" (SEW-D model)"),nmo=l(),fh=a("li"),Oce=a("strong"),smo=o("speech-encoder-decoder"),lmo=o(" \u2014 "),hN=a("a"),imo=o("SpeechEncoderDecoderConfig"),dmo=o(" (Speech Encoder decoder model)"),cmo=l(),gh=a("li"),Vce=a("strong"),mmo=o("speech_to_text"),fmo=o(" \u2014 "),uN=a("a"),gmo=o("Speech2TextConfig"),hmo=o(" (Speech2Text model)"),umo=l(),hh=a("li"),Xce=a("strong"),pmo=o("speech_to_text_2"),_mo=o(" \u2014 "),pN=a("a"),bmo=o("Speech2Text2Config"),vmo=o(" (Speech2Text2 model)"),Fmo=l(),uh=a("li"),zce=a("strong"),Tmo=o("splinter"),Mmo=o(" \u2014 "),_N=a("a"),Emo=o("SplinterConfig"),Cmo=o(" (Splinter model)"),wmo=l(),ph=a("li"),Qce=a("strong"),Amo=o("squeezebert"),Lmo=o(" \u2014 "),bN=a("a"),ymo=o("SqueezeBertConfig"),xmo=o(" (SqueezeBERT model)"),$mo=l(),_h=a("li"),Wce=a("strong"),kmo=o("swin"),Smo=o(" \u2014 "),vN=a("a"),Rmo=o("SwinConfig"),Pmo=o(" (Swin Transformer model)"),Bmo=l(),bh=a("li"),Uce=a("strong"),Imo=o("swinv2"),Nmo=o(" \u2014 "),FN=a("a"),qmo=o("Swinv2Config"),jmo=o(" (Swin Transformer V2 model)"),Dmo=l(),vh=a("li"),Hce=a("strong"),Gmo=o("t5"),Omo=o(" \u2014 "),TN=a("a"),Vmo=o("T5Config"),Xmo=o(" (T5 model)"),zmo=l(),Fh=a("li"),Jce=a("strong"),Qmo=o("tapas"),Wmo=o(" \u2014 "),MN=a("a"),Umo=o("TapasConfig"),Hmo=o(" (TAPAS model)"),Jmo=l(),Th=a("li"),Yce=a("strong"),Ymo=o("trajectory_transformer"),Kmo=o(" \u2014 "),EN=a("a"),Zmo=o("TrajectoryTransformerConfig"),efo=o(" (Trajectory Transformer model)"),ofo=l(),Mh=a("li"),Kce=a("strong"),rfo=o("transfo-xl"),tfo=o(" \u2014 "),CN=a("a"),afo=o("TransfoXLConfig"),nfo=o(" (Transformer-XL model)"),sfo=l(),Eh=a("li"),Zce=a("strong"),lfo=o("trocr"),ifo=o(" \u2014 "),wN=a("a"),dfo=o("TrOCRConfig"),cfo=o(" (TrOCR model)"),mfo=l(),Ch=a("li"),eme=a("strong"),ffo=o("unispeech"),gfo=o(" \u2014 "),AN=a("a"),hfo=o("UniSpeechConfig"),ufo=o(" (UniSpeech model)"),pfo=l(),wh=a("li"),ome=a("strong"),_fo=o("unispeech-sat"),bfo=o(" \u2014 "),LN=a("a"),vfo=o("UniSpeechSatConfig"),Ffo=o(" (UniSpeechSat model)"),Tfo=l(),Ah=a("li"),rme=a("strong"),Mfo=o("van"),Efo=o(" \u2014 "),yN=a("a"),Cfo=o("VanConfig"),wfo=o(" (VAN model)"),Afo=l(),Lh=a("li"),tme=a("strong"),Lfo=o("videomae"),yfo=o(" \u2014 "),xN=a("a"),xfo=o("VideoMAEConfig"),$fo=o(" (VideoMAE model)"),kfo=l(),yh=a("li"),ame=a("strong"),Sfo=o("vilt"),Rfo=o(" \u2014 "),$N=a("a"),Pfo=o("ViltConfig"),Bfo=o(" (ViLT model)"),Ifo=l(),xh=a("li"),nme=a("strong"),Nfo=o("vision-encoder-decoder"),qfo=o(" \u2014 "),kN=a("a"),jfo=o("VisionEncoderDecoderConfig"),Dfo=o(" (Vision Encoder decoder model)"),Gfo=l(),$h=a("li"),sme=a("strong"),Ofo=o("vision-text-dual-encoder"),Vfo=o(" \u2014 "),SN=a("a"),Xfo=o("VisionTextDualEncoderConfig"),zfo=o(" (VisionTextDualEncoder model)"),Qfo=l(),kh=a("li"),lme=a("strong"),Wfo=o("visual_bert"),Ufo=o(" \u2014 "),RN=a("a"),Hfo=o("VisualBertConfig"),Jfo=o(" (VisualBERT model)"),Yfo=l(),Sh=a("li"),ime=a("strong"),Kfo=o("vit"),Zfo=o(" \u2014 "),PN=a("a"),ego=o("ViTConfig"),ogo=o(" (ViT model)"),rgo=l(),Rh=a("li"),dme=a("strong"),tgo=o("vit_mae"),ago=o(" \u2014 "),BN=a("a"),ngo=o("ViTMAEConfig"),sgo=o(" (ViTMAE model)"),lgo=l(),Ph=a("li"),cme=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),IN=a("a"),cgo=o("Wav2Vec2Config"),mgo=o(" (Wav2Vec2 model)"),fgo=l(),Bh=a("li"),mme=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),NN=a("a"),ugo=o("Wav2Vec2ConformerConfig"),pgo=o(" (Wav2Vec2-Conformer model)"),_go=l(),Ih=a("li"),fme=a("strong"),bgo=o("wavlm"),vgo=o(" \u2014 "),qN=a("a"),Fgo=o("WavLMConfig"),Tgo=o(" (WavLM model)"),Mgo=l(),Nh=a("li"),gme=a("strong"),Ego=o("xclip"),Cgo=o(" \u2014 "),jN=a("a"),wgo=o("XCLIPConfig"),Ago=o(" (X-CLIP model)"),Lgo=l(),qh=a("li"),hme=a("strong"),ygo=o("xglm"),xgo=o(" \u2014 "),DN=a("a"),$go=o("XGLMConfig"),kgo=o(" (XGLM model)"),Sgo=l(),jh=a("li"),ume=a("strong"),Rgo=o("xlm"),Pgo=o(" \u2014 "),GN=a("a"),Bgo=o("XLMConfig"),Igo=o(" (XLM model)"),Ngo=l(),Dh=a("li"),pme=a("strong"),qgo=o("xlm-prophetnet"),jgo=o(" \u2014 "),ON=a("a"),Dgo=o("XLMProphetNetConfig"),Ggo=o(" (XLM-ProphetNet model)"),Ogo=l(),Gh=a("li"),_me=a("strong"),Vgo=o("xlm-roberta"),Xgo=o(" \u2014 "),VN=a("a"),zgo=o("XLMRobertaConfig"),Qgo=o(" (XLM-RoBERTa model)"),Wgo=l(),Oh=a("li"),bme=a("strong"),Ugo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),XN=a("a"),Jgo=o("XLMRobertaXLConfig"),Ygo=o(" (XLM-RoBERTa-XL model)"),Kgo=l(),Vh=a("li"),vme=a("strong"),Zgo=o("xlnet"),eho=o(" \u2014 "),zN=a("a"),oho=o("XLNetConfig"),rho=o(" (XLNet model)"),tho=l(),Xh=a("li"),Fme=a("strong"),aho=o("yolos"),nho=o(" \u2014 "),QN=a("a"),sho=o("YolosConfig"),lho=o(" (YOLOS model)"),iho=l(),zh=a("li"),Tme=a("strong"),dho=o("yoso"),cho=o(" \u2014 "),WN=a("a"),mho=o("YosoConfig"),fho=o(" (YOSO model)"),gho=l(),F(Qh.$$.fragment),hho=l(),Wh=a("div"),F($9.$$.fragment),uho=l(),Mme=a("p"),pho=o("Register a new configuration for this class."),qYe=l(),fd=a("h2"),Uh=a("a"),Eme=a("span"),F(k9.$$.fragment),_ho=l(),Cme=a("span"),bho=o("AutoTokenizer"),jYe=l(),ko=a("div"),F(S9.$$.fragment),vho=l(),R9=a("p"),Fho=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UN=a("a"),Tho=o("AutoTokenizer.from_pretrained()"),Mho=o(" class method."),Eho=l(),P9=a("p"),Cho=o("This class cannot be instantiated directly using "),wme=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),Br=a("div"),F(B9.$$.fragment),yho=l(),Ame=a("p"),xho=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),$ho=l(),Ua=a("p"),kho=o("The tokenizer class to instantiate is selected based on the "),Lme=a("code"),Sho=o("model_type"),Rho=o(` property of the config object (either
passed as an argument or loaded from `),yme=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xme=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),k=a("ul"),as=a("li"),$me=a("strong"),jho=o("albert"),Dho=o(" \u2014 "),HN=a("a"),Gho=o("AlbertTokenizer"),Oho=o(" or "),JN=a("a"),Vho=o("AlbertTokenizerFast"),Xho=o(" (ALBERT model)"),zho=l(),ns=a("li"),kme=a("strong"),Qho=o("bart"),Who=o(" \u2014 "),YN=a("a"),Uho=o("BartTokenizer"),Hho=o(" or "),KN=a("a"),Jho=o("BartTokenizerFast"),Yho=o(" (BART model)"),Kho=l(),ss=a("li"),Sme=a("strong"),Zho=o("barthez"),euo=o(" \u2014 "),ZN=a("a"),ouo=o("BarthezTokenizer"),ruo=o(" or "),eq=a("a"),tuo=o("BarthezTokenizerFast"),auo=o(" (BARThez model)"),nuo=l(),Hh=a("li"),Rme=a("strong"),suo=o("bartpho"),luo=o(" \u2014 "),oq=a("a"),iuo=o("BartphoTokenizer"),duo=o(" (BARTpho model)"),cuo=l(),ls=a("li"),Pme=a("strong"),muo=o("bert"),fuo=o(" \u2014 "),rq=a("a"),guo=o("BertTokenizer"),huo=o(" or "),tq=a("a"),uuo=o("BertTokenizerFast"),puo=o(" (BERT model)"),_uo=l(),Jh=a("li"),Bme=a("strong"),buo=o("bert-generation"),vuo=o(" \u2014 "),aq=a("a"),Fuo=o("BertGenerationTokenizer"),Tuo=o(" (Bert Generation model)"),Muo=l(),Yh=a("li"),Ime=a("strong"),Euo=o("bert-japanese"),Cuo=o(" \u2014 "),nq=a("a"),wuo=o("BertJapaneseTokenizer"),Auo=o(" (BertJapanese model)"),Luo=l(),Kh=a("li"),Nme=a("strong"),yuo=o("bertweet"),xuo=o(" \u2014 "),sq=a("a"),$uo=o("BertweetTokenizer"),kuo=o(" (BERTweet model)"),Suo=l(),is=a("li"),qme=a("strong"),Ruo=o("big_bird"),Puo=o(" \u2014 "),lq=a("a"),Buo=o("BigBirdTokenizer"),Iuo=o(" or "),iq=a("a"),Nuo=o("BigBirdTokenizerFast"),quo=o(" (BigBird model)"),juo=l(),ds=a("li"),jme=a("strong"),Duo=o("bigbird_pegasus"),Guo=o(" \u2014 "),dq=a("a"),Ouo=o("PegasusTokenizer"),Vuo=o(" or "),cq=a("a"),Xuo=o("PegasusTokenizerFast"),zuo=o(" (BigBird-Pegasus model)"),Quo=l(),cs=a("li"),Dme=a("strong"),Wuo=o("blenderbot"),Uuo=o(" \u2014 "),mq=a("a"),Huo=o("BlenderbotTokenizer"),Juo=o(" or "),fq=a("a"),Yuo=o("BlenderbotTokenizerFast"),Kuo=o(" (Blenderbot model)"),Zuo=l(),Zh=a("li"),Gme=a("strong"),epo=o("blenderbot-small"),opo=o(" \u2014 "),gq=a("a"),rpo=o("BlenderbotSmallTokenizer"),tpo=o(" (BlenderbotSmall model)"),apo=l(),eu=a("li"),Ome=a("strong"),npo=o("bloom"),spo=o(" \u2014 "),hq=a("a"),lpo=o("BloomTokenizerFast"),ipo=o(" (BLOOM model)"),dpo=l(),ou=a("li"),Vme=a("strong"),cpo=o("byt5"),mpo=o(" \u2014 "),uq=a("a"),fpo=o("ByT5Tokenizer"),gpo=o(" (ByT5 model)"),hpo=l(),ms=a("li"),Xme=a("strong"),upo=o("camembert"),ppo=o(" \u2014 "),pq=a("a"),_po=o("CamembertTokenizer"),bpo=o(" or "),_q=a("a"),vpo=o("CamembertTokenizerFast"),Fpo=o(" (CamemBERT model)"),Tpo=l(),ru=a("li"),zme=a("strong"),Mpo=o("canine"),Epo=o(" \u2014 "),bq=a("a"),Cpo=o("CanineTokenizer"),wpo=o(" (CANINE model)"),Apo=l(),fs=a("li"),Qme=a("strong"),Lpo=o("clip"),ypo=o(" \u2014 "),vq=a("a"),xpo=o("CLIPTokenizer"),$po=o(" or "),Fq=a("a"),kpo=o("CLIPTokenizerFast"),Spo=o(" (CLIP model)"),Rpo=l(),gs=a("li"),Wme=a("strong"),Ppo=o("codegen"),Bpo=o(" \u2014 "),Tq=a("a"),Ipo=o("CodeGenTokenizer"),Npo=o(" or "),Mq=a("a"),qpo=o("CodeGenTokenizerFast"),jpo=o(" (CodeGen model)"),Dpo=l(),hs=a("li"),Ume=a("strong"),Gpo=o("convbert"),Opo=o(" \u2014 "),Eq=a("a"),Vpo=o("ConvBertTokenizer"),Xpo=o(" or "),Cq=a("a"),zpo=o("ConvBertTokenizerFast"),Qpo=o(" (ConvBERT model)"),Wpo=l(),us=a("li"),Hme=a("strong"),Upo=o("cpm"),Hpo=o(" \u2014 "),wq=a("a"),Jpo=o("CpmTokenizer"),Ypo=o(" or "),Aq=a("a"),Kpo=o("CpmTokenizerFast"),Zpo=o(" (CPM model)"),e_o=l(),tu=a("li"),Jme=a("strong"),o_o=o("ctrl"),r_o=o(" \u2014 "),Lq=a("a"),t_o=o("CTRLTokenizer"),a_o=o(" (CTRL model)"),n_o=l(),ps=a("li"),Yme=a("strong"),s_o=o("data2vec-text"),l_o=o(" \u2014 "),yq=a("a"),i_o=o("RobertaTokenizer"),d_o=o(" or "),xq=a("a"),c_o=o("RobertaTokenizerFast"),m_o=o(" (Data2VecText model)"),f_o=l(),_s=a("li"),Kme=a("strong"),g_o=o("deberta"),h_o=o(" \u2014 "),$q=a("a"),u_o=o("DebertaTokenizer"),p_o=o(" or "),kq=a("a"),__o=o("DebertaTokenizerFast"),b_o=o(" (DeBERTa model)"),v_o=l(),bs=a("li"),Zme=a("strong"),F_o=o("deberta-v2"),T_o=o(" \u2014 "),Sq=a("a"),M_o=o("DebertaV2Tokenizer"),E_o=o(" or "),Rq=a("a"),C_o=o("DebertaV2TokenizerFast"),w_o=o(" (DeBERTa-v2 model)"),A_o=l(),vs=a("li"),efe=a("strong"),L_o=o("distilbert"),y_o=o(" \u2014 "),Pq=a("a"),x_o=o("DistilBertTokenizer"),$_o=o(" or "),Bq=a("a"),k_o=o("DistilBertTokenizerFast"),S_o=o(" (DistilBERT model)"),R_o=l(),Fs=a("li"),ofe=a("strong"),P_o=o("dpr"),B_o=o(" \u2014 "),Iq=a("a"),I_o=o("DPRQuestionEncoderTokenizer"),N_o=o(" or "),Nq=a("a"),q_o=o("DPRQuestionEncoderTokenizerFast"),j_o=o(" (DPR model)"),D_o=l(),Ts=a("li"),rfe=a("strong"),G_o=o("electra"),O_o=o(" \u2014 "),qq=a("a"),V_o=o("ElectraTokenizer"),X_o=o(" or "),jq=a("a"),z_o=o("ElectraTokenizerFast"),Q_o=o(" (ELECTRA model)"),W_o=l(),Ms=a("li"),tfe=a("strong"),U_o=o("ernie"),H_o=o(" \u2014 "),Dq=a("a"),J_o=o("BertTokenizer"),Y_o=o(" or "),Gq=a("a"),K_o=o("BertTokenizerFast"),Z_o=o(" (ERNIE model)"),e2o=l(),au=a("li"),afe=a("strong"),o2o=o("flaubert"),r2o=o(" \u2014 "),Oq=a("a"),t2o=o("FlaubertTokenizer"),a2o=o(" (FlauBERT model)"),n2o=l(),Es=a("li"),nfe=a("strong"),s2o=o("fnet"),l2o=o(" \u2014 "),Vq=a("a"),i2o=o("FNetTokenizer"),d2o=o(" or "),Xq=a("a"),c2o=o("FNetTokenizerFast"),m2o=o(" (FNet model)"),f2o=l(),nu=a("li"),sfe=a("strong"),g2o=o("fsmt"),h2o=o(" \u2014 "),zq=a("a"),u2o=o("FSMTTokenizer"),p2o=o(" (FairSeq Machine-Translation model)"),_2o=l(),Cs=a("li"),lfe=a("strong"),b2o=o("funnel"),v2o=o(" \u2014 "),Qq=a("a"),F2o=o("FunnelTokenizer"),T2o=o(" or "),Wq=a("a"),M2o=o("FunnelTokenizerFast"),E2o=o(" (Funnel Transformer model)"),C2o=l(),ws=a("li"),ife=a("strong"),w2o=o("gpt2"),A2o=o(" \u2014 "),Uq=a("a"),L2o=o("GPT2Tokenizer"),y2o=o(" or "),Hq=a("a"),x2o=o("GPT2TokenizerFast"),$2o=o(" (OpenAI GPT-2 model)"),k2o=l(),As=a("li"),dfe=a("strong"),S2o=o("gpt_neo"),R2o=o(" \u2014 "),Jq=a("a"),P2o=o("GPT2Tokenizer"),B2o=o(" or "),Yq=a("a"),I2o=o("GPT2TokenizerFast"),N2o=o(" (GPT Neo model)"),q2o=l(),su=a("li"),cfe=a("strong"),j2o=o("gpt_neox"),D2o=o(" \u2014 "),Kq=a("a"),G2o=o("GPTNeoXTokenizerFast"),O2o=o(" (GPT NeoX model)"),V2o=l(),Ls=a("li"),mfe=a("strong"),X2o=o("gptj"),z2o=o(" \u2014 "),Zq=a("a"),Q2o=o("GPT2Tokenizer"),W2o=o(" or "),ej=a("a"),U2o=o("GPT2TokenizerFast"),H2o=o(" (GPT-J model)"),J2o=l(),ys=a("li"),ffe=a("strong"),Y2o=o("groupvit"),K2o=o(" \u2014 "),oj=a("a"),Z2o=o("CLIPTokenizer"),ebo=o(" or "),rj=a("a"),obo=o("CLIPTokenizerFast"),rbo=o(" (GroupViT model)"),tbo=l(),xs=a("li"),gfe=a("strong"),abo=o("herbert"),nbo=o(" \u2014 "),tj=a("a"),sbo=o("HerbertTokenizer"),lbo=o(" or "),aj=a("a"),ibo=o("HerbertTokenizerFast"),dbo=o(" (HerBERT model)"),cbo=l(),lu=a("li"),hfe=a("strong"),mbo=o("hubert"),fbo=o(" \u2014 "),nj=a("a"),gbo=o("Wav2Vec2CTCTokenizer"),hbo=o(" (Hubert model)"),ubo=l(),$s=a("li"),ufe=a("strong"),pbo=o("ibert"),_bo=o(" \u2014 "),sj=a("a"),bbo=o("RobertaTokenizer"),vbo=o(" or "),lj=a("a"),Fbo=o("RobertaTokenizerFast"),Tbo=o(" (I-BERT model)"),Mbo=l(),ks=a("li"),pfe=a("strong"),Ebo=o("layoutlm"),Cbo=o(" \u2014 "),ij=a("a"),wbo=o("LayoutLMTokenizer"),Abo=o(" or "),dj=a("a"),Lbo=o("LayoutLMTokenizerFast"),ybo=o(" (LayoutLM model)"),xbo=l(),Ss=a("li"),_fe=a("strong"),$bo=o("layoutlmv2"),kbo=o(" \u2014 "),cj=a("a"),Sbo=o("LayoutLMv2Tokenizer"),Rbo=o(" or "),mj=a("a"),Pbo=o("LayoutLMv2TokenizerFast"),Bbo=o(" (LayoutLMv2 model)"),Ibo=l(),Rs=a("li"),bfe=a("strong"),Nbo=o("layoutlmv3"),qbo=o(" \u2014 "),fj=a("a"),jbo=o("LayoutLMv3Tokenizer"),Dbo=o(" or "),gj=a("a"),Gbo=o("LayoutLMv3TokenizerFast"),Obo=o(" (LayoutLMv3 model)"),Vbo=l(),Ps=a("li"),vfe=a("strong"),Xbo=o("layoutxlm"),zbo=o(" \u2014 "),hj=a("a"),Qbo=o("LayoutXLMTokenizer"),Wbo=o(" or "),uj=a("a"),Ubo=o("LayoutXLMTokenizerFast"),Hbo=o(" (LayoutXLM model)"),Jbo=l(),Bs=a("li"),Ffe=a("strong"),Ybo=o("led"),Kbo=o(" \u2014 "),pj=a("a"),Zbo=o("LEDTokenizer"),e1o=o(" or "),_j=a("a"),o1o=o("LEDTokenizerFast"),r1o=o(" (LED model)"),t1o=l(),Is=a("li"),Tfe=a("strong"),a1o=o("longformer"),n1o=o(" \u2014 "),bj=a("a"),s1o=o("LongformerTokenizer"),l1o=o(" or "),vj=a("a"),i1o=o("LongformerTokenizerFast"),d1o=o(" (Longformer model)"),c1o=l(),Ns=a("li"),Mfe=a("strong"),m1o=o("longt5"),f1o=o(" \u2014 "),Fj=a("a"),g1o=o("T5Tokenizer"),h1o=o(" or "),Tj=a("a"),u1o=o("T5TokenizerFast"),p1o=o(" (LongT5 model)"),_1o=l(),iu=a("li"),Efe=a("strong"),b1o=o("luke"),v1o=o(" \u2014 "),Mj=a("a"),F1o=o("LukeTokenizer"),T1o=o(" (LUKE model)"),M1o=l(),qs=a("li"),Cfe=a("strong"),E1o=o("lxmert"),C1o=o(" \u2014 "),Ej=a("a"),w1o=o("LxmertTokenizer"),A1o=o(" or "),Cj=a("a"),L1o=o("LxmertTokenizerFast"),y1o=o(" (LXMERT model)"),x1o=l(),du=a("li"),wfe=a("strong"),$1o=o("m2m_100"),k1o=o(" \u2014 "),wj=a("a"),S1o=o("M2M100Tokenizer"),R1o=o(" (M2M100 model)"),P1o=l(),cu=a("li"),Afe=a("strong"),B1o=o("marian"),I1o=o(" \u2014 "),Aj=a("a"),N1o=o("MarianTokenizer"),q1o=o(" (Marian model)"),j1o=l(),js=a("li"),Lfe=a("strong"),D1o=o("mbart"),G1o=o(" \u2014 "),Lj=a("a"),O1o=o("MBartTokenizer"),V1o=o(" or "),yj=a("a"),X1o=o("MBartTokenizerFast"),z1o=o(" (mBART model)"),Q1o=l(),Ds=a("li"),yfe=a("strong"),W1o=o("mbart50"),U1o=o(" \u2014 "),xj=a("a"),H1o=o("MBart50Tokenizer"),J1o=o(" or "),$j=a("a"),Y1o=o("MBart50TokenizerFast"),K1o=o(" (mBART-50 model)"),Z1o=l(),Gs=a("li"),xfe=a("strong"),evo=o("megatron-bert"),ovo=o(" \u2014 "),kj=a("a"),rvo=o("BertTokenizer"),tvo=o(" or "),Sj=a("a"),avo=o("BertTokenizerFast"),nvo=o(" (Megatron-BERT model)"),svo=l(),mu=a("li"),$fe=a("strong"),lvo=o("mluke"),ivo=o(" \u2014 "),Rj=a("a"),dvo=o("MLukeTokenizer"),cvo=o(" (mLUKE model)"),mvo=l(),Os=a("li"),kfe=a("strong"),fvo=o("mobilebert"),gvo=o(" \u2014 "),Pj=a("a"),hvo=o("MobileBertTokenizer"),uvo=o(" or "),Bj=a("a"),pvo=o("MobileBertTokenizerFast"),_vo=o(" (MobileBERT model)"),bvo=l(),Vs=a("li"),Sfe=a("strong"),vvo=o("mpnet"),Fvo=o(" \u2014 "),Ij=a("a"),Tvo=o("MPNetTokenizer"),Mvo=o(" or "),Nj=a("a"),Evo=o("MPNetTokenizerFast"),Cvo=o(" (MPNet model)"),wvo=l(),Xs=a("li"),Rfe=a("strong"),Avo=o("mt5"),Lvo=o(" \u2014 "),qj=a("a"),yvo=o("MT5Tokenizer"),xvo=o(" or "),jj=a("a"),$vo=o("MT5TokenizerFast"),kvo=o(" (MT5 model)"),Svo=l(),zs=a("li"),Pfe=a("strong"),Rvo=o("mvp"),Pvo=o(" \u2014 "),Dj=a("a"),Bvo=o("MvpTokenizer"),Ivo=o(" or "),Gj=a("a"),Nvo=o("MvpTokenizerFast"),qvo=o(" (MVP model)"),jvo=l(),Qs=a("li"),Bfe=a("strong"),Dvo=o("nezha"),Gvo=o(" \u2014 "),Oj=a("a"),Ovo=o("BertTokenizer"),Vvo=o(" or "),Vj=a("a"),Xvo=o("BertTokenizerFast"),zvo=o(" (Nezha model)"),Qvo=l(),Ws=a("li"),Ife=a("strong"),Wvo=o("nllb"),Uvo=o(" \u2014 "),Xj=a("a"),Hvo=o("NllbTokenizer"),Jvo=o(" or "),zj=a("a"),Yvo=o("NllbTokenizerFast"),Kvo=o(" (NLLB model)"),Zvo=l(),Us=a("li"),Nfe=a("strong"),eFo=o("nystromformer"),oFo=o(" \u2014 "),Qj=a("a"),rFo=o("AlbertTokenizer"),tFo=o(" or "),Wj=a("a"),aFo=o("AlbertTokenizerFast"),nFo=o(" (Nystr\xF6mformer model)"),sFo=l(),Hs=a("li"),qfe=a("strong"),lFo=o("openai-gpt"),iFo=o(" \u2014 "),Uj=a("a"),dFo=o("OpenAIGPTTokenizer"),cFo=o(" or "),Hj=a("a"),mFo=o("OpenAIGPTTokenizerFast"),fFo=o(" (OpenAI GPT model)"),gFo=l(),fu=a("li"),jfe=a("strong"),hFo=o("opt"),uFo=o(" \u2014 "),Jj=a("a"),pFo=o("GPT2Tokenizer"),_Fo=o(" (OPT model)"),bFo=l(),Js=a("li"),Dfe=a("strong"),vFo=o("owlvit"),FFo=o(" \u2014 "),Yj=a("a"),TFo=o("CLIPTokenizer"),MFo=o(" or "),Kj=a("a"),EFo=o("CLIPTokenizerFast"),CFo=o(" (OWL-ViT model)"),wFo=l(),Ys=a("li"),Gfe=a("strong"),AFo=o("pegasus"),LFo=o(" \u2014 "),Zj=a("a"),yFo=o("PegasusTokenizer"),xFo=o(" or "),eD=a("a"),$Fo=o("PegasusTokenizerFast"),kFo=o(" (Pegasus model)"),SFo=l(),gu=a("li"),Ofe=a("strong"),RFo=o("perceiver"),PFo=o(" \u2014 "),oD=a("a"),BFo=o("PerceiverTokenizer"),IFo=o(" (Perceiver model)"),NFo=l(),hu=a("li"),Vfe=a("strong"),qFo=o("phobert"),jFo=o(" \u2014 "),rD=a("a"),DFo=o("PhobertTokenizer"),GFo=o(" (PhoBERT model)"),OFo=l(),uu=a("li"),Xfe=a("strong"),VFo=o("plbart"),XFo=o(" \u2014 "),tD=a("a"),zFo=o("PLBartTokenizer"),QFo=o(" (PLBart model)"),WFo=l(),pu=a("li"),zfe=a("strong"),UFo=o("prophetnet"),HFo=o(" \u2014 "),aD=a("a"),JFo=o("ProphetNetTokenizer"),YFo=o(" (ProphetNet model)"),KFo=l(),Ks=a("li"),Qfe=a("strong"),ZFo=o("qdqbert"),eTo=o(" \u2014 "),nD=a("a"),oTo=o("BertTokenizer"),rTo=o(" or "),sD=a("a"),tTo=o("BertTokenizerFast"),aTo=o(" (QDQBert model)"),nTo=l(),_u=a("li"),Wfe=a("strong"),sTo=o("rag"),lTo=o(" \u2014 "),lD=a("a"),iTo=o("RagTokenizer"),dTo=o(" (RAG model)"),cTo=l(),Zs=a("li"),Ufe=a("strong"),mTo=o("realm"),fTo=o(" \u2014 "),iD=a("a"),gTo=o("RealmTokenizer"),hTo=o(" or "),dD=a("a"),uTo=o("RealmTokenizerFast"),pTo=o(" (REALM model)"),_To=l(),el=a("li"),Hfe=a("strong"),bTo=o("reformer"),vTo=o(" \u2014 "),cD=a("a"),FTo=o("ReformerTokenizer"),TTo=o(" or "),mD=a("a"),MTo=o("ReformerTokenizerFast"),ETo=o(" (Reformer model)"),CTo=l(),ol=a("li"),Jfe=a("strong"),wTo=o("rembert"),ATo=o(" \u2014 "),fD=a("a"),LTo=o("RemBertTokenizer"),yTo=o(" or "),gD=a("a"),xTo=o("RemBertTokenizerFast"),$To=o(" (RemBERT model)"),kTo=l(),rl=a("li"),Yfe=a("strong"),STo=o("retribert"),RTo=o(" \u2014 "),hD=a("a"),PTo=o("RetriBertTokenizer"),BTo=o(" or "),uD=a("a"),ITo=o("RetriBertTokenizerFast"),NTo=o(" (RetriBERT model)"),qTo=l(),tl=a("li"),Kfe=a("strong"),jTo=o("roberta"),DTo=o(" \u2014 "),pD=a("a"),GTo=o("RobertaTokenizer"),OTo=o(" or "),_D=a("a"),VTo=o("RobertaTokenizerFast"),XTo=o(" (RoBERTa model)"),zTo=l(),al=a("li"),Zfe=a("strong"),QTo=o("roformer"),WTo=o(" \u2014 "),bD=a("a"),UTo=o("RoFormerTokenizer"),HTo=o(" or "),vD=a("a"),JTo=o("RoFormerTokenizerFast"),YTo=o(" (RoFormer model)"),KTo=l(),bu=a("li"),ege=a("strong"),ZTo=o("speech_to_text"),eMo=o(" \u2014 "),FD=a("a"),oMo=o("Speech2TextTokenizer"),rMo=o(" (Speech2Text model)"),tMo=l(),vu=a("li"),oge=a("strong"),aMo=o("speech_to_text_2"),nMo=o(" \u2014 "),TD=a("a"),sMo=o("Speech2Text2Tokenizer"),lMo=o(" (Speech2Text2 model)"),iMo=l(),nl=a("li"),rge=a("strong"),dMo=o("splinter"),cMo=o(" \u2014 "),MD=a("a"),mMo=o("SplinterTokenizer"),fMo=o(" or "),ED=a("a"),gMo=o("SplinterTokenizerFast"),hMo=o(" (Splinter model)"),uMo=l(),sl=a("li"),tge=a("strong"),pMo=o("squeezebert"),_Mo=o(" \u2014 "),CD=a("a"),bMo=o("SqueezeBertTokenizer"),vMo=o(" or "),wD=a("a"),FMo=o("SqueezeBertTokenizerFast"),TMo=o(" (SqueezeBERT model)"),MMo=l(),ll=a("li"),age=a("strong"),EMo=o("t5"),CMo=o(" \u2014 "),AD=a("a"),wMo=o("T5Tokenizer"),AMo=o(" or "),LD=a("a"),LMo=o("T5TokenizerFast"),yMo=o(" (T5 model)"),xMo=l(),Fu=a("li"),nge=a("strong"),$Mo=o("tapas"),kMo=o(" \u2014 "),yD=a("a"),SMo=o("TapasTokenizer"),RMo=o(" (TAPAS model)"),PMo=l(),Tu=a("li"),sge=a("strong"),BMo=o("tapex"),IMo=o(" \u2014 "),xD=a("a"),NMo=o("TapexTokenizer"),qMo=o(" (TAPEX model)"),jMo=l(),Mu=a("li"),lge=a("strong"),DMo=o("transfo-xl"),GMo=o(" \u2014 "),$D=a("a"),OMo=o("TransfoXLTokenizer"),VMo=o(" (Transformer-XL model)"),XMo=l(),il=a("li"),ige=a("strong"),zMo=o("vilt"),QMo=o(" \u2014 "),kD=a("a"),WMo=o("BertTokenizer"),UMo=o(" or "),SD=a("a"),HMo=o("BertTokenizerFast"),JMo=o(" (ViLT model)"),YMo=l(),dl=a("li"),dge=a("strong"),KMo=o("visual_bert"),ZMo=o(" \u2014 "),RD=a("a"),eEo=o("BertTokenizer"),oEo=o(" or "),PD=a("a"),rEo=o("BertTokenizerFast"),tEo=o(" (VisualBERT model)"),aEo=l(),Eu=a("li"),cge=a("strong"),nEo=o("wav2vec2"),sEo=o(" \u2014 "),BD=a("a"),lEo=o("Wav2Vec2CTCTokenizer"),iEo=o(" (Wav2Vec2 model)"),dEo=l(),Cu=a("li"),mge=a("strong"),cEo=o("wav2vec2-conformer"),mEo=o(" \u2014 "),ID=a("a"),fEo=o("Wav2Vec2CTCTokenizer"),gEo=o(" (Wav2Vec2-Conformer model)"),hEo=l(),wu=a("li"),fge=a("strong"),uEo=o("wav2vec2_phoneme"),pEo=o(" \u2014 "),ND=a("a"),_Eo=o("Wav2Vec2PhonemeCTCTokenizer"),bEo=o(" (Wav2Vec2Phoneme model)"),vEo=l(),cl=a("li"),gge=a("strong"),FEo=o("xclip"),TEo=o(" \u2014 "),qD=a("a"),MEo=o("CLIPTokenizer"),EEo=o(" or "),jD=a("a"),CEo=o("CLIPTokenizerFast"),wEo=o(" (X-CLIP model)"),AEo=l(),ml=a("li"),hge=a("strong"),LEo=o("xglm"),yEo=o(" \u2014 "),DD=a("a"),xEo=o("XGLMTokenizer"),$Eo=o(" or "),GD=a("a"),kEo=o("XGLMTokenizerFast"),SEo=o(" (XGLM model)"),REo=l(),Au=a("li"),uge=a("strong"),PEo=o("xlm"),BEo=o(" \u2014 "),OD=a("a"),IEo=o("XLMTokenizer"),NEo=o(" (XLM model)"),qEo=l(),Lu=a("li"),pge=a("strong"),jEo=o("xlm-prophetnet"),DEo=o(" \u2014 "),VD=a("a"),GEo=o("XLMProphetNetTokenizer"),OEo=o(" (XLM-ProphetNet model)"),VEo=l(),fl=a("li"),_ge=a("strong"),XEo=o("xlm-roberta"),zEo=o(" \u2014 "),XD=a("a"),QEo=o("XLMRobertaTokenizer"),WEo=o(" or "),zD=a("a"),UEo=o("XLMRobertaTokenizerFast"),HEo=o(" (XLM-RoBERTa model)"),JEo=l(),gl=a("li"),bge=a("strong"),YEo=o("xlm-roberta-xl"),KEo=o(" \u2014 "),QD=a("a"),ZEo=o("XLMRobertaTokenizer"),e4o=o(" or "),WD=a("a"),o4o=o("XLMRobertaTokenizerFast"),r4o=o(" (XLM-RoBERTa-XL model)"),t4o=l(),hl=a("li"),vge=a("strong"),a4o=o("xlnet"),n4o=o(" \u2014 "),UD=a("a"),s4o=o("XLNetTokenizer"),l4o=o(" or "),HD=a("a"),i4o=o("XLNetTokenizerFast"),d4o=o(" (XLNet model)"),c4o=l(),ul=a("li"),Fge=a("strong"),m4o=o("yoso"),f4o=o(" \u2014 "),JD=a("a"),g4o=o("AlbertTokenizer"),h4o=o(" or "),YD=a("a"),u4o=o("AlbertTokenizerFast"),p4o=o(" (YOSO model)"),_4o=l(),F(yu.$$.fragment),b4o=l(),xu=a("div"),F(I9.$$.fragment),v4o=l(),Tge=a("p"),F4o=o("Register a new tokenizer in this mapping."),DYe=l(),gd=a("h2"),$u=a("a"),Mge=a("span"),F(N9.$$.fragment),T4o=l(),Ege=a("span"),M4o=o("AutoFeatureExtractor"),GYe=l(),So=a("div"),F(q9.$$.fragment),E4o=l(),j9=a("p"),C4o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KD=a("a"),w4o=o("AutoFeatureExtractor.from_pretrained()"),A4o=o(" class method."),L4o=l(),D9=a("p"),y4o=o("This class cannot be instantiated directly using "),Cge=a("code"),x4o=o("__init__()"),$4o=o(" (throws an error)."),k4o=l(),Ye=a("div"),F(G9.$$.fragment),S4o=l(),wge=a("p"),R4o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),P4o=l(),Ha=a("p"),B4o=o("The feature extractor class to instantiate is selected based on the "),Age=a("code"),I4o=o("model_type"),N4o=o(` property of the config object
(either passed as an argument or loaded from `),Lge=a("code"),q4o=o("pretrained_model_name_or_path"),j4o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),yge=a("code"),D4o=o("pretrained_model_name_or_path"),G4o=o(":"),O4o=l(),W=a("ul"),ku=a("li"),xge=a("strong"),V4o=o("beit"),X4o=o(" \u2014 "),ZD=a("a"),z4o=o("BeitFeatureExtractor"),Q4o=o(" (BEiT model)"),W4o=l(),Su=a("li"),$ge=a("strong"),U4o=o("clip"),H4o=o(" \u2014 "),eG=a("a"),J4o=o("CLIPFeatureExtractor"),Y4o=o(" (CLIP model)"),K4o=l(),Ru=a("li"),kge=a("strong"),Z4o=o("convnext"),eCo=o(" \u2014 "),oG=a("a"),oCo=o("ConvNextFeatureExtractor"),rCo=o(" (ConvNeXT model)"),tCo=l(),Pu=a("li"),Sge=a("strong"),aCo=o("cvt"),nCo=o(" \u2014 "),rG=a("a"),sCo=o("ConvNextFeatureExtractor"),lCo=o(" (CvT model)"),iCo=l(),Bu=a("li"),Rge=a("strong"),dCo=o("data2vec-audio"),cCo=o(" \u2014 "),tG=a("a"),mCo=o("Wav2Vec2FeatureExtractor"),fCo=o(" (Data2VecAudio model)"),gCo=l(),Iu=a("li"),Pge=a("strong"),hCo=o("data2vec-vision"),uCo=o(" \u2014 "),aG=a("a"),pCo=o("BeitFeatureExtractor"),_Co=o(" (Data2VecVision model)"),bCo=l(),Nu=a("li"),Bge=a("strong"),vCo=o("deit"),FCo=o(" \u2014 "),nG=a("a"),TCo=o("DeiTFeatureExtractor"),MCo=o(" (DeiT model)"),ECo=l(),qu=a("li"),Ige=a("strong"),CCo=o("detr"),wCo=o(" \u2014 "),sG=a("a"),ACo=o("DetrFeatureExtractor"),LCo=o(" (DETR model)"),yCo=l(),ju=a("li"),Nge=a("strong"),xCo=o("donut"),$Co=o(" \u2014 "),lG=a("a"),kCo=o("DonutFeatureExtractor"),SCo=o(" (Donut model)"),RCo=l(),Du=a("li"),qge=a("strong"),PCo=o("dpt"),BCo=o(" \u2014 "),iG=a("a"),ICo=o("DPTFeatureExtractor"),NCo=o(" (DPT model)"),qCo=l(),Gu=a("li"),jge=a("strong"),jCo=o("flava"),DCo=o(" \u2014 "),dG=a("a"),GCo=o("FlavaFeatureExtractor"),OCo=o(" (FLAVA model)"),VCo=l(),Ou=a("li"),Dge=a("strong"),XCo=o("glpn"),zCo=o(" \u2014 "),cG=a("a"),QCo=o("GLPNFeatureExtractor"),WCo=o(" (GLPN model)"),UCo=l(),Vu=a("li"),Gge=a("strong"),HCo=o("groupvit"),JCo=o(" \u2014 "),mG=a("a"),YCo=o("CLIPFeatureExtractor"),KCo=o(" (GroupViT model)"),ZCo=l(),Xu=a("li"),Oge=a("strong"),e3o=o("hubert"),o3o=o(" \u2014 "),fG=a("a"),r3o=o("Wav2Vec2FeatureExtractor"),t3o=o(" (Hubert model)"),a3o=l(),zu=a("li"),Vge=a("strong"),n3o=o("imagegpt"),s3o=o(" \u2014 "),gG=a("a"),l3o=o("ImageGPTFeatureExtractor"),i3o=o(" (ImageGPT model)"),d3o=l(),Qu=a("li"),Xge=a("strong"),c3o=o("layoutlmv2"),m3o=o(" \u2014 "),hG=a("a"),f3o=o("LayoutLMv2FeatureExtractor"),g3o=o(" (LayoutLMv2 model)"),h3o=l(),Wu=a("li"),zge=a("strong"),u3o=o("layoutlmv3"),p3o=o(" \u2014 "),uG=a("a"),_3o=o("LayoutLMv3FeatureExtractor"),b3o=o(" (LayoutLMv3 model)"),v3o=l(),Uu=a("li"),Qge=a("strong"),F3o=o("levit"),T3o=o(" \u2014 "),pG=a("a"),M3o=o("LevitFeatureExtractor"),E3o=o(" (LeViT model)"),C3o=l(),Hu=a("li"),Wge=a("strong"),w3o=o("maskformer"),A3o=o(" \u2014 "),_G=a("a"),L3o=o("MaskFormerFeatureExtractor"),y3o=o(" (MaskFormer model)"),x3o=l(),Ju=a("li"),Uge=a("strong"),$3o=o("mctct"),k3o=o(" \u2014 "),bG=a("a"),S3o=o("MCTCTFeatureExtractor"),R3o=o(" (M-CTC-T model)"),P3o=l(),Yu=a("li"),Hge=a("strong"),B3o=o("mobilevit"),I3o=o(" \u2014 "),vG=a("a"),N3o=o("MobileViTFeatureExtractor"),q3o=o(" (MobileViT model)"),j3o=l(),Ku=a("li"),Jge=a("strong"),D3o=o("owlvit"),G3o=o(" \u2014 "),FG=a("a"),O3o=o("OwlViTFeatureExtractor"),V3o=o(" (OWL-ViT model)"),X3o=l(),Zu=a("li"),Yge=a("strong"),z3o=o("perceiver"),Q3o=o(" \u2014 "),TG=a("a"),W3o=o("PerceiverFeatureExtractor"),U3o=o(" (Perceiver model)"),H3o=l(),ep=a("li"),Kge=a("strong"),J3o=o("poolformer"),Y3o=o(" \u2014 "),MG=a("a"),K3o=o("PoolFormerFeatureExtractor"),Z3o=o(" (PoolFormer model)"),e5o=l(),op=a("li"),Zge=a("strong"),o5o=o("regnet"),r5o=o(" \u2014 "),EG=a("a"),t5o=o("ConvNextFeatureExtractor"),a5o=o(" (RegNet model)"),n5o=l(),rp=a("li"),ehe=a("strong"),s5o=o("resnet"),l5o=o(" \u2014 "),CG=a("a"),i5o=o("ConvNextFeatureExtractor"),d5o=o(" (ResNet model)"),c5o=l(),tp=a("li"),ohe=a("strong"),m5o=o("segformer"),f5o=o(" \u2014 "),wG=a("a"),g5o=o("SegformerFeatureExtractor"),h5o=o(" (SegFormer model)"),u5o=l(),ap=a("li"),rhe=a("strong"),p5o=o("speech_to_text"),_5o=o(" \u2014 "),AG=a("a"),b5o=o("Speech2TextFeatureExtractor"),v5o=o(" (Speech2Text model)"),F5o=l(),np=a("li"),the=a("strong"),T5o=o("swin"),M5o=o(" \u2014 "),LG=a("a"),E5o=o("ViTFeatureExtractor"),C5o=o(" (Swin Transformer model)"),w5o=l(),sp=a("li"),ahe=a("strong"),A5o=o("swinv2"),L5o=o(" \u2014 "),yG=a("a"),y5o=o("ViTFeatureExtractor"),x5o=o(" (Swin Transformer V2 model)"),$5o=l(),lp=a("li"),nhe=a("strong"),k5o=o("van"),S5o=o(" \u2014 "),xG=a("a"),R5o=o("ConvNextFeatureExtractor"),P5o=o(" (VAN model)"),B5o=l(),ip=a("li"),she=a("strong"),I5o=o("videomae"),N5o=o(" \u2014 "),$G=a("a"),q5o=o("VideoMAEFeatureExtractor"),j5o=o(" (VideoMAE model)"),D5o=l(),dp=a("li"),lhe=a("strong"),G5o=o("vilt"),O5o=o(" \u2014 "),kG=a("a"),V5o=o("ViltFeatureExtractor"),X5o=o(" (ViLT model)"),z5o=l(),cp=a("li"),ihe=a("strong"),Q5o=o("vit"),W5o=o(" \u2014 "),SG=a("a"),U5o=o("ViTFeatureExtractor"),H5o=o(" (ViT model)"),J5o=l(),mp=a("li"),dhe=a("strong"),Y5o=o("vit_mae"),K5o=o(" \u2014 "),RG=a("a"),Z5o=o("ViTFeatureExtractor"),e0o=o(" (ViTMAE model)"),o0o=l(),fp=a("li"),che=a("strong"),r0o=o("wav2vec2"),t0o=o(" \u2014 "),PG=a("a"),a0o=o("Wav2Vec2FeatureExtractor"),n0o=o(" (Wav2Vec2 model)"),s0o=l(),gp=a("li"),mhe=a("strong"),l0o=o("wav2vec2-conformer"),i0o=o(" \u2014 "),BG=a("a"),d0o=o("Wav2Vec2FeatureExtractor"),c0o=o(" (Wav2Vec2-Conformer model)"),m0o=l(),hp=a("li"),fhe=a("strong"),f0o=o("xclip"),g0o=o(" \u2014 "),IG=a("a"),h0o=o("CLIPFeatureExtractor"),u0o=o(" (X-CLIP model)"),p0o=l(),up=a("li"),ghe=a("strong"),_0o=o("yolos"),b0o=o(" \u2014 "),NG=a("a"),v0o=o("YolosFeatureExtractor"),F0o=o(" (YOLOS model)"),T0o=l(),F(pp.$$.fragment),M0o=l(),F(_p.$$.fragment),E0o=l(),bp=a("div"),F(O9.$$.fragment),C0o=l(),hhe=a("p"),w0o=o("Register a new feature extractor for this class."),OYe=l(),hd=a("h2"),vp=a("a"),uhe=a("span"),F(V9.$$.fragment),A0o=l(),phe=a("span"),L0o=o("AutoProcessor"),VYe=l(),Ro=a("div"),F(X9.$$.fragment),y0o=l(),z9=a("p"),x0o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qG=a("a"),$0o=o("AutoProcessor.from_pretrained()"),k0o=o(" class method."),S0o=l(),Q9=a("p"),R0o=o("This class cannot be instantiated directly using "),_he=a("code"),P0o=o("__init__()"),B0o=o(" (throws an error)."),I0o=l(),Ke=a("div"),F(W9.$$.fragment),N0o=l(),bhe=a("p"),q0o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),j0o=l(),ud=a("p"),D0o=o("The processor class to instantiate is selected based on the "),vhe=a("code"),G0o=o("model_type"),O0o=o(` property of the config object (either
passed as an argument or loaded from `),Fhe=a("code"),V0o=o("pretrained_model_name_or_path"),X0o=o(" if possible):"),z0o=l(),ie=a("ul"),Fp=a("li"),The=a("strong"),Q0o=o("clip"),W0o=o(" \u2014 "),jG=a("a"),U0o=o("CLIPProcessor"),H0o=o(" (CLIP model)"),J0o=l(),Tp=a("li"),Mhe=a("strong"),Y0o=o("donut"),K0o=o(" \u2014 "),DG=a("a"),Z0o=o("DonutProcessor"),ewo=o(" (Donut model)"),owo=l(),Mp=a("li"),Ehe=a("strong"),rwo=o("flava"),two=o(" \u2014 "),GG=a("a"),awo=o("FlavaProcessor"),nwo=o(" (FLAVA model)"),swo=l(),Ep=a("li"),Che=a("strong"),lwo=o("groupvit"),iwo=o(" \u2014 "),OG=a("a"),dwo=o("CLIPProcessor"),cwo=o(" (GroupViT model)"),mwo=l(),Cp=a("li"),whe=a("strong"),fwo=o("layoutlmv2"),gwo=o(" \u2014 "),VG=a("a"),hwo=o("LayoutLMv2Processor"),uwo=o(" (LayoutLMv2 model)"),pwo=l(),wp=a("li"),Ahe=a("strong"),_wo=o("layoutlmv3"),bwo=o(" \u2014 "),XG=a("a"),vwo=o("LayoutLMv3Processor"),Fwo=o(" (LayoutLMv3 model)"),Two=l(),Ap=a("li"),Lhe=a("strong"),Mwo=o("layoutxlm"),Ewo=o(" \u2014 "),zG=a("a"),Cwo=o("LayoutXLMProcessor"),wwo=o(" (LayoutXLM model)"),Awo=l(),Lp=a("li"),yhe=a("strong"),Lwo=o("owlvit"),ywo=o(" \u2014 "),QG=a("a"),xwo=o("OwlViTProcessor"),$wo=o(" (OWL-ViT model)"),kwo=l(),yp=a("li"),xhe=a("strong"),Swo=o("sew"),Rwo=o(" \u2014 "),WG=a("a"),Pwo=o("Wav2Vec2Processor"),Bwo=o(" (SEW model)"),Iwo=l(),xp=a("li"),$he=a("strong"),Nwo=o("sew-d"),qwo=o(" \u2014 "),UG=a("a"),jwo=o("Wav2Vec2Processor"),Dwo=o(" (SEW-D model)"),Gwo=l(),$p=a("li"),khe=a("strong"),Owo=o("speech_to_text"),Vwo=o(" \u2014 "),HG=a("a"),Xwo=o("Speech2TextProcessor"),zwo=o(" (Speech2Text model)"),Qwo=l(),kp=a("li"),She=a("strong"),Wwo=o("speech_to_text_2"),Uwo=o(" \u2014 "),JG=a("a"),Hwo=o("Speech2Text2Processor"),Jwo=o(" (Speech2Text2 model)"),Ywo=l(),Sp=a("li"),Rhe=a("strong"),Kwo=o("trocr"),Zwo=o(" \u2014 "),YG=a("a"),eAo=o("TrOCRProcessor"),oAo=o(" (TrOCR model)"),rAo=l(),Rp=a("li"),Phe=a("strong"),tAo=o("unispeech"),aAo=o(" \u2014 "),KG=a("a"),nAo=o("Wav2Vec2Processor"),sAo=o(" (UniSpeech model)"),lAo=l(),Pp=a("li"),Bhe=a("strong"),iAo=o("unispeech-sat"),dAo=o(" \u2014 "),ZG=a("a"),cAo=o("Wav2Vec2Processor"),mAo=o(" (UniSpeechSat model)"),fAo=l(),Bp=a("li"),Ihe=a("strong"),gAo=o("vilt"),hAo=o(" \u2014 "),eO=a("a"),uAo=o("ViltProcessor"),pAo=o(" (ViLT model)"),_Ao=l(),Ip=a("li"),Nhe=a("strong"),bAo=o("vision-text-dual-encoder"),vAo=o(" \u2014 "),oO=a("a"),FAo=o("VisionTextDualEncoderProcessor"),TAo=o(" (VisionTextDualEncoder model)"),MAo=l(),Np=a("li"),qhe=a("strong"),EAo=o("wav2vec2"),CAo=o(" \u2014 "),rO=a("a"),wAo=o("Wav2Vec2Processor"),AAo=o(" (Wav2Vec2 model)"),LAo=l(),qp=a("li"),jhe=a("strong"),yAo=o("wav2vec2-conformer"),xAo=o(" \u2014 "),tO=a("a"),$Ao=o("Wav2Vec2Processor"),kAo=o(" (Wav2Vec2-Conformer model)"),SAo=l(),jp=a("li"),Dhe=a("strong"),RAo=o("wavlm"),PAo=o(" \u2014 "),aO=a("a"),BAo=o("Wav2Vec2Processor"),IAo=o(" (WavLM model)"),NAo=l(),Dp=a("li"),Ghe=a("strong"),qAo=o("xclip"),jAo=o(" \u2014 "),nO=a("a"),DAo=o("CLIPProcessor"),GAo=o(" (X-CLIP model)"),OAo=l(),F(Gp.$$.fragment),VAo=l(),F(Op.$$.fragment),XAo=l(),Vp=a("div"),F(U9.$$.fragment),zAo=l(),Ohe=a("p"),QAo=o("Register a new processor for this class."),XYe=l(),pd=a("h2"),Xp=a("a"),Vhe=a("span"),F(H9.$$.fragment),WAo=l(),Xhe=a("span"),UAo=o("AutoModel"),zYe=l(),Po=a("div"),F(J9.$$.fragment),HAo=l(),_d=a("p"),JAo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sO=a("a"),YAo=o("from_pretrained()"),KAo=o(" class method or the "),lO=a("a"),ZAo=o("from_config()"),e6o=o(` class
method.`),o6o=l(),Y9=a("p"),r6o=o("This class cannot be instantiated directly using "),zhe=a("code"),t6o=o("__init__()"),a6o=o(" (throws an error)."),n6o=l(),_t=a("div"),F(K9.$$.fragment),s6o=l(),Qhe=a("p"),l6o=o("Instantiates one of the base model classes of the library from a configuration."),i6o=l(),bd=a("p"),d6o=o(`Note:
Loading a model from its configuration file does `),Whe=a("strong"),c6o=o("not"),m6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=a("a"),f6o=o("from_pretrained()"),g6o=o(" to load the model weights."),h6o=l(),F(zp.$$.fragment),u6o=l(),Ze=a("div"),F(Z9.$$.fragment),p6o=l(),Uhe=a("p"),_6o=o("Instantiate one of the base model classes of the library from a pretrained model."),b6o=l(),Ja=a("p"),v6o=o("The model class to instantiate is selected based on the "),Hhe=a("code"),F6o=o("model_type"),T6o=o(` property of the config object (either
passed as an argument or loaded from `),Jhe=a("code"),M6o=o("pretrained_model_name_or_path"),E6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=a("code"),C6o=o("pretrained_model_name_or_path"),w6o=o(":"),A6o=l(),y=a("ul"),Qp=a("li"),Khe=a("strong"),L6o=o("albert"),y6o=o(" \u2014 "),dO=a("a"),x6o=o("AlbertModel"),$6o=o(" (ALBERT model)"),k6o=l(),Wp=a("li"),Zhe=a("strong"),S6o=o("bart"),R6o=o(" \u2014 "),cO=a("a"),P6o=o("BartModel"),B6o=o(" (BART model)"),I6o=l(),Up=a("li"),eue=a("strong"),N6o=o("beit"),q6o=o(" \u2014 "),mO=a("a"),j6o=o("BeitModel"),D6o=o(" (BEiT model)"),G6o=l(),Hp=a("li"),oue=a("strong"),O6o=o("bert"),V6o=o(" \u2014 "),fO=a("a"),X6o=o("BertModel"),z6o=o(" (BERT model)"),Q6o=l(),Jp=a("li"),rue=a("strong"),W6o=o("bert-generation"),U6o=o(" \u2014 "),gO=a("a"),H6o=o("BertGenerationEncoder"),J6o=o(" (Bert Generation model)"),Y6o=l(),Yp=a("li"),tue=a("strong"),K6o=o("big_bird"),Z6o=o(" \u2014 "),hO=a("a"),e7o=o("BigBirdModel"),o7o=o(" (BigBird model)"),r7o=l(),Kp=a("li"),aue=a("strong"),t7o=o("bigbird_pegasus"),a7o=o(" \u2014 "),uO=a("a"),n7o=o("BigBirdPegasusModel"),s7o=o(" (BigBird-Pegasus model)"),l7o=l(),Zp=a("li"),nue=a("strong"),i7o=o("blenderbot"),d7o=o(" \u2014 "),pO=a("a"),c7o=o("BlenderbotModel"),m7o=o(" (Blenderbot model)"),f7o=l(),e_=a("li"),sue=a("strong"),g7o=o("blenderbot-small"),h7o=o(" \u2014 "),_O=a("a"),u7o=o("BlenderbotSmallModel"),p7o=o(" (BlenderbotSmall model)"),_7o=l(),o_=a("li"),lue=a("strong"),b7o=o("bloom"),v7o=o(" \u2014 "),bO=a("a"),F7o=o("BloomModel"),T7o=o(" (BLOOM model)"),M7o=l(),r_=a("li"),iue=a("strong"),E7o=o("camembert"),C7o=o(" \u2014 "),vO=a("a"),w7o=o("CamembertModel"),A7o=o(" (CamemBERT model)"),L7o=l(),t_=a("li"),due=a("strong"),y7o=o("canine"),x7o=o(" \u2014 "),FO=a("a"),$7o=o("CanineModel"),k7o=o(" (CANINE model)"),S7o=l(),a_=a("li"),cue=a("strong"),R7o=o("clip"),P7o=o(" \u2014 "),TO=a("a"),B7o=o("CLIPModel"),I7o=o(" (CLIP model)"),N7o=l(),n_=a("li"),mue=a("strong"),q7o=o("codegen"),j7o=o(" \u2014 "),MO=a("a"),D7o=o("CodeGenModel"),G7o=o(" (CodeGen model)"),O7o=l(),s_=a("li"),fue=a("strong"),V7o=o("convbert"),X7o=o(" \u2014 "),EO=a("a"),z7o=o("ConvBertModel"),Q7o=o(" (ConvBERT model)"),W7o=l(),l_=a("li"),gue=a("strong"),U7o=o("convnext"),H7o=o(" \u2014 "),CO=a("a"),J7o=o("ConvNextModel"),Y7o=o(" (ConvNeXT model)"),K7o=l(),i_=a("li"),hue=a("strong"),Z7o=o("ctrl"),eLo=o(" \u2014 "),wO=a("a"),oLo=o("CTRLModel"),rLo=o(" (CTRL model)"),tLo=l(),d_=a("li"),uue=a("strong"),aLo=o("cvt"),nLo=o(" \u2014 "),AO=a("a"),sLo=o("CvtModel"),lLo=o(" (CvT model)"),iLo=l(),c_=a("li"),pue=a("strong"),dLo=o("data2vec-audio"),cLo=o(" \u2014 "),LO=a("a"),mLo=o("Data2VecAudioModel"),fLo=o(" (Data2VecAudio model)"),gLo=l(),m_=a("li"),_ue=a("strong"),hLo=o("data2vec-text"),uLo=o(" \u2014 "),yO=a("a"),pLo=o("Data2VecTextModel"),_Lo=o(" (Data2VecText model)"),bLo=l(),f_=a("li"),bue=a("strong"),vLo=o("data2vec-vision"),FLo=o(" \u2014 "),xO=a("a"),TLo=o("Data2VecVisionModel"),MLo=o(" (Data2VecVision model)"),ELo=l(),g_=a("li"),vue=a("strong"),CLo=o("deberta"),wLo=o(" \u2014 "),$O=a("a"),ALo=o("DebertaModel"),LLo=o(" (DeBERTa model)"),yLo=l(),h_=a("li"),Fue=a("strong"),xLo=o("deberta-v2"),$Lo=o(" \u2014 "),kO=a("a"),kLo=o("DebertaV2Model"),SLo=o(" (DeBERTa-v2 model)"),RLo=l(),u_=a("li"),Tue=a("strong"),PLo=o("decision_transformer"),BLo=o(" \u2014 "),SO=a("a"),ILo=o("DecisionTransformerModel"),NLo=o(" (Decision Transformer model)"),qLo=l(),p_=a("li"),Mue=a("strong"),jLo=o("deit"),DLo=o(" \u2014 "),RO=a("a"),GLo=o("DeiTModel"),OLo=o(" (DeiT model)"),VLo=l(),__=a("li"),Eue=a("strong"),XLo=o("detr"),zLo=o(" \u2014 "),PO=a("a"),QLo=o("DetrModel"),WLo=o(" (DETR model)"),ULo=l(),b_=a("li"),Cue=a("strong"),HLo=o("distilbert"),JLo=o(" \u2014 "),BO=a("a"),YLo=o("DistilBertModel"),KLo=o(" (DistilBERT model)"),ZLo=l(),v_=a("li"),wue=a("strong"),eyo=o("donut-swin"),oyo=o(" \u2014 "),IO=a("a"),ryo=o("DonutSwinModel"),tyo=o(" (DonutSwin model)"),ayo=l(),F_=a("li"),Aue=a("strong"),nyo=o("dpr"),syo=o(" \u2014 "),NO=a("a"),lyo=o("DPRQuestionEncoder"),iyo=o(" (DPR model)"),dyo=l(),T_=a("li"),Lue=a("strong"),cyo=o("dpt"),myo=o(" \u2014 "),qO=a("a"),fyo=o("DPTModel"),gyo=o(" (DPT model)"),hyo=l(),M_=a("li"),yue=a("strong"),uyo=o("electra"),pyo=o(" \u2014 "),jO=a("a"),_yo=o("ElectraModel"),byo=o(" (ELECTRA model)"),vyo=l(),E_=a("li"),xue=a("strong"),Fyo=o("ernie"),Tyo=o(" \u2014 "),DO=a("a"),Myo=o("ErnieModel"),Eyo=o(" (ERNIE model)"),Cyo=l(),C_=a("li"),$ue=a("strong"),wyo=o("flaubert"),Ayo=o(" \u2014 "),GO=a("a"),Lyo=o("FlaubertModel"),yyo=o(" (FlauBERT model)"),xyo=l(),w_=a("li"),kue=a("strong"),$yo=o("flava"),kyo=o(" \u2014 "),OO=a("a"),Syo=o("FlavaModel"),Ryo=o(" (FLAVA model)"),Pyo=l(),A_=a("li"),Sue=a("strong"),Byo=o("fnet"),Iyo=o(" \u2014 "),VO=a("a"),Nyo=o("FNetModel"),qyo=o(" (FNet model)"),jyo=l(),L_=a("li"),Rue=a("strong"),Dyo=o("fsmt"),Gyo=o(" \u2014 "),XO=a("a"),Oyo=o("FSMTModel"),Vyo=o(" (FairSeq Machine-Translation model)"),Xyo=l(),pl=a("li"),Pue=a("strong"),zyo=o("funnel"),Qyo=o(" \u2014 "),zO=a("a"),Wyo=o("FunnelModel"),Uyo=o(" or "),QO=a("a"),Hyo=o("FunnelBaseModel"),Jyo=o(" (Funnel Transformer model)"),Yyo=l(),y_=a("li"),Bue=a("strong"),Kyo=o("glpn"),Zyo=o(" \u2014 "),WO=a("a"),e8o=o("GLPNModel"),o8o=o(" (GLPN model)"),r8o=l(),x_=a("li"),Iue=a("strong"),t8o=o("gpt2"),a8o=o(" \u2014 "),UO=a("a"),n8o=o("GPT2Model"),s8o=o(" (OpenAI GPT-2 model)"),l8o=l(),$_=a("li"),Nue=a("strong"),i8o=o("gpt_neo"),d8o=o(" \u2014 "),HO=a("a"),c8o=o("GPTNeoModel"),m8o=o(" (GPT Neo model)"),f8o=l(),k_=a("li"),que=a("strong"),g8o=o("gpt_neox"),h8o=o(" \u2014 "),JO=a("a"),u8o=o("GPTNeoXModel"),p8o=o(" (GPT NeoX model)"),_8o=l(),S_=a("li"),jue=a("strong"),b8o=o("gptj"),v8o=o(" \u2014 "),YO=a("a"),F8o=o("GPTJModel"),T8o=o(" (GPT-J model)"),M8o=l(),R_=a("li"),Due=a("strong"),E8o=o("groupvit"),C8o=o(" \u2014 "),KO=a("a"),w8o=o("GroupViTModel"),A8o=o(" (GroupViT model)"),L8o=l(),P_=a("li"),Gue=a("strong"),y8o=o("hubert"),x8o=o(" \u2014 "),ZO=a("a"),$8o=o("HubertModel"),k8o=o(" (Hubert model)"),S8o=l(),B_=a("li"),Oue=a("strong"),R8o=o("ibert"),P8o=o(" \u2014 "),eV=a("a"),B8o=o("IBertModel"),I8o=o(" (I-BERT model)"),N8o=l(),I_=a("li"),Vue=a("strong"),q8o=o("imagegpt"),j8o=o(" \u2014 "),oV=a("a"),D8o=o("ImageGPTModel"),G8o=o(" (ImageGPT model)"),O8o=l(),N_=a("li"),Xue=a("strong"),V8o=o("layoutlm"),X8o=o(" \u2014 "),rV=a("a"),z8o=o("LayoutLMModel"),Q8o=o(" (LayoutLM model)"),W8o=l(),q_=a("li"),zue=a("strong"),U8o=o("layoutlmv2"),H8o=o(" \u2014 "),tV=a("a"),J8o=o("LayoutLMv2Model"),Y8o=o(" (LayoutLMv2 model)"),K8o=l(),j_=a("li"),Que=a("strong"),Z8o=o("layoutlmv3"),e9o=o(" \u2014 "),aV=a("a"),o9o=o("LayoutLMv3Model"),r9o=o(" (LayoutLMv3 model)"),t9o=l(),D_=a("li"),Wue=a("strong"),a9o=o("led"),n9o=o(" \u2014 "),nV=a("a"),s9o=o("LEDModel"),l9o=o(" (LED model)"),i9o=l(),G_=a("li"),Uue=a("strong"),d9o=o("levit"),c9o=o(" \u2014 "),sV=a("a"),m9o=o("LevitModel"),f9o=o(" (LeViT model)"),g9o=l(),O_=a("li"),Hue=a("strong"),h9o=o("longformer"),u9o=o(" \u2014 "),lV=a("a"),p9o=o("LongformerModel"),_9o=o(" (Longformer model)"),b9o=l(),V_=a("li"),Jue=a("strong"),v9o=o("longt5"),F9o=o(" \u2014 "),iV=a("a"),T9o=o("LongT5Model"),M9o=o(" (LongT5 model)"),E9o=l(),X_=a("li"),Yue=a("strong"),C9o=o("luke"),w9o=o(" \u2014 "),dV=a("a"),A9o=o("LukeModel"),L9o=o(" (LUKE model)"),y9o=l(),z_=a("li"),Kue=a("strong"),x9o=o("lxmert"),$9o=o(" \u2014 "),cV=a("a"),k9o=o("LxmertModel"),S9o=o(" (LXMERT model)"),R9o=l(),Q_=a("li"),Zue=a("strong"),P9o=o("m2m_100"),B9o=o(" \u2014 "),mV=a("a"),I9o=o("M2M100Model"),N9o=o(" (M2M100 model)"),q9o=l(),W_=a("li"),epe=a("strong"),j9o=o("marian"),D9o=o(" \u2014 "),fV=a("a"),G9o=o("MarianModel"),O9o=o(" (Marian model)"),V9o=l(),U_=a("li"),ope=a("strong"),X9o=o("maskformer"),z9o=o(" \u2014 "),gV=a("a"),Q9o=o("MaskFormerModel"),W9o=o(" (MaskFormer model)"),U9o=l(),H_=a("li"),rpe=a("strong"),H9o=o("mbart"),J9o=o(" \u2014 "),hV=a("a"),Y9o=o("MBartModel"),K9o=o(" (mBART model)"),Z9o=l(),J_=a("li"),tpe=a("strong"),exo=o("mctct"),oxo=o(" \u2014 "),uV=a("a"),rxo=o("MCTCTModel"),txo=o(" (M-CTC-T model)"),axo=l(),Y_=a("li"),ape=a("strong"),nxo=o("megatron-bert"),sxo=o(" \u2014 "),pV=a("a"),lxo=o("MegatronBertModel"),ixo=o(" (Megatron-BERT model)"),dxo=l(),K_=a("li"),npe=a("strong"),cxo=o("mobilebert"),mxo=o(" \u2014 "),_V=a("a"),fxo=o("MobileBertModel"),gxo=o(" (MobileBERT model)"),hxo=l(),Z_=a("li"),spe=a("strong"),uxo=o("mobilevit"),pxo=o(" \u2014 "),bV=a("a"),_xo=o("MobileViTModel"),bxo=o(" (MobileViT model)"),vxo=l(),e2=a("li"),lpe=a("strong"),Fxo=o("mpnet"),Txo=o(" \u2014 "),vV=a("a"),Mxo=o("MPNetModel"),Exo=o(" (MPNet model)"),Cxo=l(),o2=a("li"),ipe=a("strong"),wxo=o("mt5"),Axo=o(" \u2014 "),FV=a("a"),Lxo=o("MT5Model"),yxo=o(" (MT5 model)"),xxo=l(),r2=a("li"),dpe=a("strong"),$xo=o("mvp"),kxo=o(" \u2014 "),TV=a("a"),Sxo=o("MvpModel"),Rxo=o(" (MVP model)"),Pxo=l(),t2=a("li"),cpe=a("strong"),Bxo=o("nezha"),Ixo=o(" \u2014 "),MV=a("a"),Nxo=o("NezhaModel"),qxo=o(" (Nezha model)"),jxo=l(),a2=a("li"),mpe=a("strong"),Dxo=o("nllb"),Gxo=o(" \u2014 "),EV=a("a"),Oxo=o("M2M100Model"),Vxo=o(" (NLLB model)"),Xxo=l(),n2=a("li"),fpe=a("strong"),zxo=o("nystromformer"),Qxo=o(" \u2014 "),CV=a("a"),Wxo=o("NystromformerModel"),Uxo=o(" (Nystr\xF6mformer model)"),Hxo=l(),s2=a("li"),gpe=a("strong"),Jxo=o("openai-gpt"),Yxo=o(" \u2014 "),wV=a("a"),Kxo=o("OpenAIGPTModel"),Zxo=o(" (OpenAI GPT model)"),e$o=l(),l2=a("li"),hpe=a("strong"),o$o=o("opt"),r$o=o(" \u2014 "),AV=a("a"),t$o=o("OPTModel"),a$o=o(" (OPT model)"),n$o=l(),i2=a("li"),upe=a("strong"),s$o=o("owlvit"),l$o=o(" \u2014 "),LV=a("a"),i$o=o("OwlViTModel"),d$o=o(" (OWL-ViT model)"),c$o=l(),d2=a("li"),ppe=a("strong"),m$o=o("pegasus"),f$o=o(" \u2014 "),yV=a("a"),g$o=o("PegasusModel"),h$o=o(" (Pegasus model)"),u$o=l(),c2=a("li"),_pe=a("strong"),p$o=o("pegasus_x"),_$o=o(" \u2014 "),xV=a("a"),b$o=o("PegasusXModel"),v$o=o(" (PEGASUS-X model)"),F$o=l(),m2=a("li"),bpe=a("strong"),T$o=o("perceiver"),M$o=o(" \u2014 "),$V=a("a"),E$o=o("PerceiverModel"),C$o=o(" (Perceiver model)"),w$o=l(),f2=a("li"),vpe=a("strong"),A$o=o("plbart"),L$o=o(" \u2014 "),kV=a("a"),y$o=o("PLBartModel"),x$o=o(" (PLBart model)"),$$o=l(),g2=a("li"),Fpe=a("strong"),k$o=o("poolformer"),S$o=o(" \u2014 "),SV=a("a"),R$o=o("PoolFormerModel"),P$o=o(" (PoolFormer model)"),B$o=l(),h2=a("li"),Tpe=a("strong"),I$o=o("prophetnet"),N$o=o(" \u2014 "),RV=a("a"),q$o=o("ProphetNetModel"),j$o=o(" (ProphetNet model)"),D$o=l(),u2=a("li"),Mpe=a("strong"),G$o=o("qdqbert"),O$o=o(" \u2014 "),PV=a("a"),V$o=o("QDQBertModel"),X$o=o(" (QDQBert model)"),z$o=l(),p2=a("li"),Epe=a("strong"),Q$o=o("reformer"),W$o=o(" \u2014 "),BV=a("a"),U$o=o("ReformerModel"),H$o=o(" (Reformer model)"),J$o=l(),_2=a("li"),Cpe=a("strong"),Y$o=o("regnet"),K$o=o(" \u2014 "),IV=a("a"),Z$o=o("RegNetModel"),eko=o(" (RegNet model)"),oko=l(),b2=a("li"),wpe=a("strong"),rko=o("rembert"),tko=o(" \u2014 "),NV=a("a"),ako=o("RemBertModel"),nko=o(" (RemBERT model)"),sko=l(),v2=a("li"),Ape=a("strong"),lko=o("resnet"),iko=o(" \u2014 "),qV=a("a"),dko=o("ResNetModel"),cko=o(" (ResNet model)"),mko=l(),F2=a("li"),Lpe=a("strong"),fko=o("retribert"),gko=o(" \u2014 "),jV=a("a"),hko=o("RetriBertModel"),uko=o(" (RetriBERT model)"),pko=l(),T2=a("li"),ype=a("strong"),_ko=o("roberta"),bko=o(" \u2014 "),DV=a("a"),vko=o("RobertaModel"),Fko=o(" (RoBERTa model)"),Tko=l(),M2=a("li"),xpe=a("strong"),Mko=o("roformer"),Eko=o(" \u2014 "),GV=a("a"),Cko=o("RoFormerModel"),wko=o(" (RoFormer model)"),Ako=l(),E2=a("li"),$pe=a("strong"),Lko=o("segformer"),yko=o(" \u2014 "),OV=a("a"),xko=o("SegformerModel"),$ko=o(" (SegFormer model)"),kko=l(),C2=a("li"),kpe=a("strong"),Sko=o("sew"),Rko=o(" \u2014 "),VV=a("a"),Pko=o("SEWModel"),Bko=o(" (SEW model)"),Iko=l(),w2=a("li"),Spe=a("strong"),Nko=o("sew-d"),qko=o(" \u2014 "),XV=a("a"),jko=o("SEWDModel"),Dko=o(" (SEW-D model)"),Gko=l(),A2=a("li"),Rpe=a("strong"),Oko=o("speech_to_text"),Vko=o(" \u2014 "),zV=a("a"),Xko=o("Speech2TextModel"),zko=o(" (Speech2Text model)"),Qko=l(),L2=a("li"),Ppe=a("strong"),Wko=o("splinter"),Uko=o(" \u2014 "),QV=a("a"),Hko=o("SplinterModel"),Jko=o(" (Splinter model)"),Yko=l(),y2=a("li"),Bpe=a("strong"),Kko=o("squeezebert"),Zko=o(" \u2014 "),WV=a("a"),eSo=o("SqueezeBertModel"),oSo=o(" (SqueezeBERT model)"),rSo=l(),x2=a("li"),Ipe=a("strong"),tSo=o("swin"),aSo=o(" \u2014 "),UV=a("a"),nSo=o("SwinModel"),sSo=o(" (Swin Transformer model)"),lSo=l(),$2=a("li"),Npe=a("strong"),iSo=o("swinv2"),dSo=o(" \u2014 "),HV=a("a"),cSo=o("Swinv2Model"),mSo=o(" (Swin Transformer V2 model)"),fSo=l(),k2=a("li"),qpe=a("strong"),gSo=o("t5"),hSo=o(" \u2014 "),JV=a("a"),uSo=o("T5Model"),pSo=o(" (T5 model)"),_So=l(),S2=a("li"),jpe=a("strong"),bSo=o("tapas"),vSo=o(" \u2014 "),YV=a("a"),FSo=o("TapasModel"),TSo=o(" (TAPAS model)"),MSo=l(),R2=a("li"),Dpe=a("strong"),ESo=o("trajectory_transformer"),CSo=o(" \u2014 "),KV=a("a"),wSo=o("TrajectoryTransformerModel"),ASo=o(" (Trajectory Transformer model)"),LSo=l(),P2=a("li"),Gpe=a("strong"),ySo=o("transfo-xl"),xSo=o(" \u2014 "),ZV=a("a"),$So=o("TransfoXLModel"),kSo=o(" (Transformer-XL model)"),SSo=l(),B2=a("li"),Ope=a("strong"),RSo=o("unispeech"),PSo=o(" \u2014 "),eX=a("a"),BSo=o("UniSpeechModel"),ISo=o(" (UniSpeech model)"),NSo=l(),I2=a("li"),Vpe=a("strong"),qSo=o("unispeech-sat"),jSo=o(" \u2014 "),oX=a("a"),DSo=o("UniSpeechSatModel"),GSo=o(" (UniSpeechSat model)"),OSo=l(),N2=a("li"),Xpe=a("strong"),VSo=o("van"),XSo=o(" \u2014 "),rX=a("a"),zSo=o("VanModel"),QSo=o(" (VAN model)"),WSo=l(),q2=a("li"),zpe=a("strong"),USo=o("videomae"),HSo=o(" \u2014 "),tX=a("a"),JSo=o("VideoMAEModel"),YSo=o(" (VideoMAE model)"),KSo=l(),j2=a("li"),Qpe=a("strong"),ZSo=o("vilt"),eRo=o(" \u2014 "),aX=a("a"),oRo=o("ViltModel"),rRo=o(" (ViLT model)"),tRo=l(),D2=a("li"),Wpe=a("strong"),aRo=o("vision-text-dual-encoder"),nRo=o(" \u2014 "),nX=a("a"),sRo=o("VisionTextDualEncoderModel"),lRo=o(" (VisionTextDualEncoder model)"),iRo=l(),G2=a("li"),Upe=a("strong"),dRo=o("visual_bert"),cRo=o(" \u2014 "),sX=a("a"),mRo=o("VisualBertModel"),fRo=o(" (VisualBERT model)"),gRo=l(),O2=a("li"),Hpe=a("strong"),hRo=o("vit"),uRo=o(" \u2014 "),lX=a("a"),pRo=o("ViTModel"),_Ro=o(" (ViT model)"),bRo=l(),V2=a("li"),Jpe=a("strong"),vRo=o("vit_mae"),FRo=o(" \u2014 "),iX=a("a"),TRo=o("ViTMAEModel"),MRo=o(" (ViTMAE model)"),ERo=l(),X2=a("li"),Ype=a("strong"),CRo=o("wav2vec2"),wRo=o(" \u2014 "),dX=a("a"),ARo=o("Wav2Vec2Model"),LRo=o(" (Wav2Vec2 model)"),yRo=l(),z2=a("li"),Kpe=a("strong"),xRo=o("wav2vec2-conformer"),$Ro=o(" \u2014 "),cX=a("a"),kRo=o("Wav2Vec2ConformerModel"),SRo=o(" (Wav2Vec2-Conformer model)"),RRo=l(),Q2=a("li"),Zpe=a("strong"),PRo=o("wavlm"),BRo=o(" \u2014 "),mX=a("a"),IRo=o("WavLMModel"),NRo=o(" (WavLM model)"),qRo=l(),W2=a("li"),e_e=a("strong"),jRo=o("xclip"),DRo=o(" \u2014 "),fX=a("a"),GRo=o("XCLIPModel"),ORo=o(" (X-CLIP model)"),VRo=l(),U2=a("li"),o_e=a("strong"),XRo=o("xglm"),zRo=o(" \u2014 "),gX=a("a"),QRo=o("XGLMModel"),WRo=o(" (XGLM model)"),URo=l(),H2=a("li"),r_e=a("strong"),HRo=o("xlm"),JRo=o(" \u2014 "),hX=a("a"),YRo=o("XLMModel"),KRo=o(" (XLM model)"),ZRo=l(),J2=a("li"),t_e=a("strong"),ePo=o("xlm-prophetnet"),oPo=o(" \u2014 "),uX=a("a"),rPo=o("XLMProphetNetModel"),tPo=o(" (XLM-ProphetNet model)"),aPo=l(),Y2=a("li"),a_e=a("strong"),nPo=o("xlm-roberta"),sPo=o(" \u2014 "),pX=a("a"),lPo=o("XLMRobertaModel"),iPo=o(" (XLM-RoBERTa model)"),dPo=l(),K2=a("li"),n_e=a("strong"),cPo=o("xlm-roberta-xl"),mPo=o(" \u2014 "),_X=a("a"),fPo=o("XLMRobertaXLModel"),gPo=o(" (XLM-RoBERTa-XL model)"),hPo=l(),Z2=a("li"),s_e=a("strong"),uPo=o("xlnet"),pPo=o(" \u2014 "),bX=a("a"),_Po=o("XLNetModel"),bPo=o(" (XLNet model)"),vPo=l(),eb=a("li"),l_e=a("strong"),FPo=o("yolos"),TPo=o(" \u2014 "),vX=a("a"),MPo=o("YolosModel"),EPo=o(" (YOLOS model)"),CPo=l(),ob=a("li"),i_e=a("strong"),wPo=o("yoso"),APo=o(" \u2014 "),FX=a("a"),LPo=o("YosoModel"),yPo=o(" (YOSO model)"),xPo=l(),rb=a("p"),$Po=o("The model is set in evaluation mode by default using "),d_e=a("code"),kPo=o("model.eval()"),SPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=a("code"),RPo=o("model.train()"),PPo=l(),F(tb.$$.fragment),QYe=l(),vd=a("h2"),ab=a("a"),m_e=a("span"),F(ex.$$.fragment),BPo=l(),f_e=a("span"),IPo=o("AutoModelForPreTraining"),WYe=l(),Bo=a("div"),F(ox.$$.fragment),NPo=l(),Fd=a("p"),qPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TX=a("a"),jPo=o("from_pretrained()"),DPo=o(" class method or the "),MX=a("a"),GPo=o("from_config()"),OPo=o(` class
method.`),VPo=l(),rx=a("p"),XPo=o("This class cannot be instantiated directly using "),g_e=a("code"),zPo=o("__init__()"),QPo=o(" (throws an error)."),WPo=l(),bt=a("div"),F(tx.$$.fragment),UPo=l(),h_e=a("p"),HPo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),JPo=l(),Td=a("p"),YPo=o(`Note:
Loading a model from its configuration file does `),u_e=a("strong"),KPo=o("not"),ZPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=a("a"),eBo=o("from_pretrained()"),oBo=o(" to load the model weights."),rBo=l(),F(nb.$$.fragment),tBo=l(),eo=a("div"),F(ax.$$.fragment),aBo=l(),p_e=a("p"),nBo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),sBo=l(),Ya=a("p"),lBo=o("The model class to instantiate is selected based on the "),__e=a("code"),iBo=o("model_type"),dBo=o(` property of the config object (either
passed as an argument or loaded from `),b_e=a("code"),cBo=o("pretrained_model_name_or_path"),mBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v_e=a("code"),fBo=o("pretrained_model_name_or_path"),gBo=o(":"),hBo=l(),G=a("ul"),sb=a("li"),F_e=a("strong"),uBo=o("albert"),pBo=o(" \u2014 "),CX=a("a"),_Bo=o("AlbertForPreTraining"),bBo=o(" (ALBERT model)"),vBo=l(),lb=a("li"),T_e=a("strong"),FBo=o("bart"),TBo=o(" \u2014 "),wX=a("a"),MBo=o("BartForConditionalGeneration"),EBo=o(" (BART model)"),CBo=l(),ib=a("li"),M_e=a("strong"),wBo=o("bert"),ABo=o(" \u2014 "),AX=a("a"),LBo=o("BertForPreTraining"),yBo=o(" (BERT model)"),xBo=l(),db=a("li"),E_e=a("strong"),$Bo=o("big_bird"),kBo=o(" \u2014 "),LX=a("a"),SBo=o("BigBirdForPreTraining"),RBo=o(" (BigBird model)"),PBo=l(),cb=a("li"),C_e=a("strong"),BBo=o("bloom"),IBo=o(" \u2014 "),yX=a("a"),NBo=o("BloomForCausalLM"),qBo=o(" (BLOOM model)"),jBo=l(),mb=a("li"),w_e=a("strong"),DBo=o("camembert"),GBo=o(" \u2014 "),xX=a("a"),OBo=o("CamembertForMaskedLM"),VBo=o(" (CamemBERT model)"),XBo=l(),fb=a("li"),A_e=a("strong"),zBo=o("ctrl"),QBo=o(" \u2014 "),$X=a("a"),WBo=o("CTRLLMHeadModel"),UBo=o(" (CTRL model)"),HBo=l(),gb=a("li"),L_e=a("strong"),JBo=o("data2vec-text"),YBo=o(" \u2014 "),kX=a("a"),KBo=o("Data2VecTextForMaskedLM"),ZBo=o(" (Data2VecText model)"),eIo=l(),hb=a("li"),y_e=a("strong"),oIo=o("deberta"),rIo=o(" \u2014 "),SX=a("a"),tIo=o("DebertaForMaskedLM"),aIo=o(" (DeBERTa model)"),nIo=l(),ub=a("li"),x_e=a("strong"),sIo=o("deberta-v2"),lIo=o(" \u2014 "),RX=a("a"),iIo=o("DebertaV2ForMaskedLM"),dIo=o(" (DeBERTa-v2 model)"),cIo=l(),pb=a("li"),$_e=a("strong"),mIo=o("distilbert"),fIo=o(" \u2014 "),PX=a("a"),gIo=o("DistilBertForMaskedLM"),hIo=o(" (DistilBERT model)"),uIo=l(),_b=a("li"),k_e=a("strong"),pIo=o("electra"),_Io=o(" \u2014 "),BX=a("a"),bIo=o("ElectraForPreTraining"),vIo=o(" (ELECTRA model)"),FIo=l(),bb=a("li"),S_e=a("strong"),TIo=o("ernie"),MIo=o(" \u2014 "),IX=a("a"),EIo=o("ErnieForPreTraining"),CIo=o(" (ERNIE model)"),wIo=l(),vb=a("li"),R_e=a("strong"),AIo=o("flaubert"),LIo=o(" \u2014 "),NX=a("a"),yIo=o("FlaubertWithLMHeadModel"),xIo=o(" (FlauBERT model)"),$Io=l(),Fb=a("li"),P_e=a("strong"),kIo=o("flava"),SIo=o(" \u2014 "),qX=a("a"),RIo=o("FlavaForPreTraining"),PIo=o(" (FLAVA model)"),BIo=l(),Tb=a("li"),B_e=a("strong"),IIo=o("fnet"),NIo=o(" \u2014 "),jX=a("a"),qIo=o("FNetForPreTraining"),jIo=o(" (FNet model)"),DIo=l(),Mb=a("li"),I_e=a("strong"),GIo=o("fsmt"),OIo=o(" \u2014 "),DX=a("a"),VIo=o("FSMTForConditionalGeneration"),XIo=o(" (FairSeq Machine-Translation model)"),zIo=l(),Eb=a("li"),N_e=a("strong"),QIo=o("funnel"),WIo=o(" \u2014 "),GX=a("a"),UIo=o("FunnelForPreTraining"),HIo=o(" (Funnel Transformer model)"),JIo=l(),Cb=a("li"),q_e=a("strong"),YIo=o("gpt2"),KIo=o(" \u2014 "),OX=a("a"),ZIo=o("GPT2LMHeadModel"),eNo=o(" (OpenAI GPT-2 model)"),oNo=l(),wb=a("li"),j_e=a("strong"),rNo=o("ibert"),tNo=o(" \u2014 "),VX=a("a"),aNo=o("IBertForMaskedLM"),nNo=o(" (I-BERT model)"),sNo=l(),Ab=a("li"),D_e=a("strong"),lNo=o("layoutlm"),iNo=o(" \u2014 "),XX=a("a"),dNo=o("LayoutLMForMaskedLM"),cNo=o(" (LayoutLM model)"),mNo=l(),Lb=a("li"),G_e=a("strong"),fNo=o("longformer"),gNo=o(" \u2014 "),zX=a("a"),hNo=o("LongformerForMaskedLM"),uNo=o(" (Longformer model)"),pNo=l(),yb=a("li"),O_e=a("strong"),_No=o("luke"),bNo=o(" \u2014 "),QX=a("a"),vNo=o("LukeForMaskedLM"),FNo=o(" (LUKE model)"),TNo=l(),xb=a("li"),V_e=a("strong"),MNo=o("lxmert"),ENo=o(" \u2014 "),WX=a("a"),CNo=o("LxmertForPreTraining"),wNo=o(" (LXMERT model)"),ANo=l(),$b=a("li"),X_e=a("strong"),LNo=o("megatron-bert"),yNo=o(" \u2014 "),UX=a("a"),xNo=o("MegatronBertForPreTraining"),$No=o(" (Megatron-BERT model)"),kNo=l(),kb=a("li"),z_e=a("strong"),SNo=o("mobilebert"),RNo=o(" \u2014 "),HX=a("a"),PNo=o("MobileBertForPreTraining"),BNo=o(" (MobileBERT model)"),INo=l(),Sb=a("li"),Q_e=a("strong"),NNo=o("mpnet"),qNo=o(" \u2014 "),JX=a("a"),jNo=o("MPNetForMaskedLM"),DNo=o(" (MPNet model)"),GNo=l(),Rb=a("li"),W_e=a("strong"),ONo=o("mvp"),VNo=o(" \u2014 "),YX=a("a"),XNo=o("MvpForConditionalGeneration"),zNo=o(" (MVP model)"),QNo=l(),Pb=a("li"),U_e=a("strong"),WNo=o("nezha"),UNo=o(" \u2014 "),KX=a("a"),HNo=o("NezhaForPreTraining"),JNo=o(" (Nezha model)"),YNo=l(),Bb=a("li"),H_e=a("strong"),KNo=o("openai-gpt"),ZNo=o(" \u2014 "),ZX=a("a"),eqo=o("OpenAIGPTLMHeadModel"),oqo=o(" (OpenAI GPT model)"),rqo=l(),Ib=a("li"),J_e=a("strong"),tqo=o("retribert"),aqo=o(" \u2014 "),ez=a("a"),nqo=o("RetriBertModel"),sqo=o(" (RetriBERT model)"),lqo=l(),Nb=a("li"),Y_e=a("strong"),iqo=o("roberta"),dqo=o(" \u2014 "),oz=a("a"),cqo=o("RobertaForMaskedLM"),mqo=o(" (RoBERTa model)"),fqo=l(),qb=a("li"),K_e=a("strong"),gqo=o("splinter"),hqo=o(" \u2014 "),rz=a("a"),uqo=o("SplinterForPreTraining"),pqo=o(" (Splinter model)"),_qo=l(),jb=a("li"),Z_e=a("strong"),bqo=o("squeezebert"),vqo=o(" \u2014 "),tz=a("a"),Fqo=o("SqueezeBertForMaskedLM"),Tqo=o(" (SqueezeBERT model)"),Mqo=l(),Db=a("li"),e2e=a("strong"),Eqo=o("t5"),Cqo=o(" \u2014 "),az=a("a"),wqo=o("T5ForConditionalGeneration"),Aqo=o(" (T5 model)"),Lqo=l(),Gb=a("li"),o2e=a("strong"),yqo=o("tapas"),xqo=o(" \u2014 "),nz=a("a"),$qo=o("TapasForMaskedLM"),kqo=o(" (TAPAS model)"),Sqo=l(),Ob=a("li"),r2e=a("strong"),Rqo=o("transfo-xl"),Pqo=o(" \u2014 "),sz=a("a"),Bqo=o("TransfoXLLMHeadModel"),Iqo=o(" (Transformer-XL model)"),Nqo=l(),Vb=a("li"),t2e=a("strong"),qqo=o("unispeech"),jqo=o(" \u2014 "),lz=a("a"),Dqo=o("UniSpeechForPreTraining"),Gqo=o(" (UniSpeech model)"),Oqo=l(),Xb=a("li"),a2e=a("strong"),Vqo=o("unispeech-sat"),Xqo=o(" \u2014 "),iz=a("a"),zqo=o("UniSpeechSatForPreTraining"),Qqo=o(" (UniSpeechSat model)"),Wqo=l(),zb=a("li"),n2e=a("strong"),Uqo=o("videomae"),Hqo=o(" \u2014 "),dz=a("a"),Jqo=o("VideoMAEForPreTraining"),Yqo=o(" (VideoMAE model)"),Kqo=l(),Qb=a("li"),s2e=a("strong"),Zqo=o("visual_bert"),ejo=o(" \u2014 "),cz=a("a"),ojo=o("VisualBertForPreTraining"),rjo=o(" (VisualBERT model)"),tjo=l(),Wb=a("li"),l2e=a("strong"),ajo=o("vit_mae"),njo=o(" \u2014 "),mz=a("a"),sjo=o("ViTMAEForPreTraining"),ljo=o(" (ViTMAE model)"),ijo=l(),Ub=a("li"),i2e=a("strong"),djo=o("wav2vec2"),cjo=o(" \u2014 "),fz=a("a"),mjo=o("Wav2Vec2ForPreTraining"),fjo=o(" (Wav2Vec2 model)"),gjo=l(),Hb=a("li"),d2e=a("strong"),hjo=o("wav2vec2-conformer"),ujo=o(" \u2014 "),gz=a("a"),pjo=o("Wav2Vec2ConformerForPreTraining"),_jo=o(" (Wav2Vec2-Conformer model)"),bjo=l(),Jb=a("li"),c2e=a("strong"),vjo=o("xlm"),Fjo=o(" \u2014 "),hz=a("a"),Tjo=o("XLMWithLMHeadModel"),Mjo=o(" (XLM model)"),Ejo=l(),Yb=a("li"),m2e=a("strong"),Cjo=o("xlm-roberta"),wjo=o(" \u2014 "),uz=a("a"),Ajo=o("XLMRobertaForMaskedLM"),Ljo=o(" (XLM-RoBERTa model)"),yjo=l(),Kb=a("li"),f2e=a("strong"),xjo=o("xlm-roberta-xl"),$jo=o(" \u2014 "),pz=a("a"),kjo=o("XLMRobertaXLForMaskedLM"),Sjo=o(" (XLM-RoBERTa-XL model)"),Rjo=l(),Zb=a("li"),g2e=a("strong"),Pjo=o("xlnet"),Bjo=o(" \u2014 "),_z=a("a"),Ijo=o("XLNetLMHeadModel"),Njo=o(" (XLNet model)"),qjo=l(),e1=a("p"),jjo=o("The model is set in evaluation mode by default using "),h2e=a("code"),Djo=o("model.eval()"),Gjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=a("code"),Ojo=o("model.train()"),Vjo=l(),F(o1.$$.fragment),UYe=l(),Md=a("h2"),r1=a("a"),p2e=a("span"),F(nx.$$.fragment),Xjo=l(),_2e=a("span"),zjo=o("AutoModelForCausalLM"),HYe=l(),Io=a("div"),F(sx.$$.fragment),Qjo=l(),Ed=a("p"),Wjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),bz=a("a"),Ujo=o("from_pretrained()"),Hjo=o(" class method or the "),vz=a("a"),Jjo=o("from_config()"),Yjo=o(` class
method.`),Kjo=l(),lx=a("p"),Zjo=o("This class cannot be instantiated directly using "),b2e=a("code"),eDo=o("__init__()"),oDo=o(" (throws an error)."),rDo=l(),vt=a("div"),F(ix.$$.fragment),tDo=l(),v2e=a("p"),aDo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),nDo=l(),Cd=a("p"),sDo=o(`Note:
Loading a model from its configuration file does `),F2e=a("strong"),lDo=o("not"),iDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),dDo=o("from_pretrained()"),cDo=o(" to load the model weights."),mDo=l(),F(t1.$$.fragment),fDo=l(),oo=a("div"),F(dx.$$.fragment),gDo=l(),T2e=a("p"),hDo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uDo=l(),Ka=a("p"),pDo=o("The model class to instantiate is selected based on the "),M2e=a("code"),_Do=o("model_type"),bDo=o(` property of the config object (either
passed as an argument or loaded from `),E2e=a("code"),vDo=o("pretrained_model_name_or_path"),FDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C2e=a("code"),TDo=o("pretrained_model_name_or_path"),MDo=o(":"),EDo=l(),z=a("ul"),a1=a("li"),w2e=a("strong"),CDo=o("bart"),wDo=o(" \u2014 "),Tz=a("a"),ADo=o("BartForCausalLM"),LDo=o(" (BART model)"),yDo=l(),n1=a("li"),A2e=a("strong"),xDo=o("bert"),$Do=o(" \u2014 "),Mz=a("a"),kDo=o("BertLMHeadModel"),SDo=o(" (BERT model)"),RDo=l(),s1=a("li"),L2e=a("strong"),PDo=o("bert-generation"),BDo=o(" \u2014 "),Ez=a("a"),IDo=o("BertGenerationDecoder"),NDo=o(" (Bert Generation model)"),qDo=l(),l1=a("li"),y2e=a("strong"),jDo=o("big_bird"),DDo=o(" \u2014 "),Cz=a("a"),GDo=o("BigBirdForCausalLM"),ODo=o(" (BigBird model)"),VDo=l(),i1=a("li"),x2e=a("strong"),XDo=o("bigbird_pegasus"),zDo=o(" \u2014 "),wz=a("a"),QDo=o("BigBirdPegasusForCausalLM"),WDo=o(" (BigBird-Pegasus model)"),UDo=l(),d1=a("li"),$2e=a("strong"),HDo=o("blenderbot"),JDo=o(" \u2014 "),Az=a("a"),YDo=o("BlenderbotForCausalLM"),KDo=o(" (Blenderbot model)"),ZDo=l(),c1=a("li"),k2e=a("strong"),eGo=o("blenderbot-small"),oGo=o(" \u2014 "),Lz=a("a"),rGo=o("BlenderbotSmallForCausalLM"),tGo=o(" (BlenderbotSmall model)"),aGo=l(),m1=a("li"),S2e=a("strong"),nGo=o("bloom"),sGo=o(" \u2014 "),yz=a("a"),lGo=o("BloomForCausalLM"),iGo=o(" (BLOOM model)"),dGo=l(),f1=a("li"),R2e=a("strong"),cGo=o("camembert"),mGo=o(" \u2014 "),xz=a("a"),fGo=o("CamembertForCausalLM"),gGo=o(" (CamemBERT model)"),hGo=l(),g1=a("li"),P2e=a("strong"),uGo=o("codegen"),pGo=o(" \u2014 "),$z=a("a"),_Go=o("CodeGenForCausalLM"),bGo=o(" (CodeGen model)"),vGo=l(),h1=a("li"),B2e=a("strong"),FGo=o("ctrl"),TGo=o(" \u2014 "),kz=a("a"),MGo=o("CTRLLMHeadModel"),EGo=o(" (CTRL model)"),CGo=l(),u1=a("li"),I2e=a("strong"),wGo=o("data2vec-text"),AGo=o(" \u2014 "),Sz=a("a"),LGo=o("Data2VecTextForCausalLM"),yGo=o(" (Data2VecText model)"),xGo=l(),p1=a("li"),N2e=a("strong"),$Go=o("electra"),kGo=o(" \u2014 "),Rz=a("a"),SGo=o("ElectraForCausalLM"),RGo=o(" (ELECTRA model)"),PGo=l(),_1=a("li"),q2e=a("strong"),BGo=o("ernie"),IGo=o(" \u2014 "),Pz=a("a"),NGo=o("ErnieForCausalLM"),qGo=o(" (ERNIE model)"),jGo=l(),b1=a("li"),j2e=a("strong"),DGo=o("gpt2"),GGo=o(" \u2014 "),Bz=a("a"),OGo=o("GPT2LMHeadModel"),VGo=o(" (OpenAI GPT-2 model)"),XGo=l(),v1=a("li"),D2e=a("strong"),zGo=o("gpt_neo"),QGo=o(" \u2014 "),Iz=a("a"),WGo=o("GPTNeoForCausalLM"),UGo=o(" (GPT Neo model)"),HGo=l(),F1=a("li"),G2e=a("strong"),JGo=o("gpt_neox"),YGo=o(" \u2014 "),Nz=a("a"),KGo=o("GPTNeoXForCausalLM"),ZGo=o(" (GPT NeoX model)"),eOo=l(),T1=a("li"),O2e=a("strong"),oOo=o("gptj"),rOo=o(" \u2014 "),qz=a("a"),tOo=o("GPTJForCausalLM"),aOo=o(" (GPT-J model)"),nOo=l(),M1=a("li"),V2e=a("strong"),sOo=o("marian"),lOo=o(" \u2014 "),jz=a("a"),iOo=o("MarianForCausalLM"),dOo=o(" (Marian model)"),cOo=l(),E1=a("li"),X2e=a("strong"),mOo=o("mbart"),fOo=o(" \u2014 "),Dz=a("a"),gOo=o("MBartForCausalLM"),hOo=o(" (mBART model)"),uOo=l(),C1=a("li"),z2e=a("strong"),pOo=o("megatron-bert"),_Oo=o(" \u2014 "),Gz=a("a"),bOo=o("MegatronBertForCausalLM"),vOo=o(" (Megatron-BERT model)"),FOo=l(),w1=a("li"),Q2e=a("strong"),TOo=o("mvp"),MOo=o(" \u2014 "),Oz=a("a"),EOo=o("MvpForCausalLM"),COo=o(" (MVP model)"),wOo=l(),A1=a("li"),W2e=a("strong"),AOo=o("openai-gpt"),LOo=o(" \u2014 "),Vz=a("a"),yOo=o("OpenAIGPTLMHeadModel"),xOo=o(" (OpenAI GPT model)"),$Oo=l(),L1=a("li"),U2e=a("strong"),kOo=o("opt"),SOo=o(" \u2014 "),Xz=a("a"),ROo=o("OPTForCausalLM"),POo=o(" (OPT model)"),BOo=l(),y1=a("li"),H2e=a("strong"),IOo=o("pegasus"),NOo=o(" \u2014 "),zz=a("a"),qOo=o("PegasusForCausalLM"),jOo=o(" (Pegasus model)"),DOo=l(),x1=a("li"),J2e=a("strong"),GOo=o("plbart"),OOo=o(" \u2014 "),Qz=a("a"),VOo=o("PLBartForCausalLM"),XOo=o(" (PLBart model)"),zOo=l(),$1=a("li"),Y2e=a("strong"),QOo=o("prophetnet"),WOo=o(" \u2014 "),Wz=a("a"),UOo=o("ProphetNetForCausalLM"),HOo=o(" (ProphetNet model)"),JOo=l(),k1=a("li"),K2e=a("strong"),YOo=o("qdqbert"),KOo=o(" \u2014 "),Uz=a("a"),ZOo=o("QDQBertLMHeadModel"),eVo=o(" (QDQBert model)"),oVo=l(),S1=a("li"),Z2e=a("strong"),rVo=o("reformer"),tVo=o(" \u2014 "),Hz=a("a"),aVo=o("ReformerModelWithLMHead"),nVo=o(" (Reformer model)"),sVo=l(),R1=a("li"),ebe=a("strong"),lVo=o("rembert"),iVo=o(" \u2014 "),Jz=a("a"),dVo=o("RemBertForCausalLM"),cVo=o(" (RemBERT model)"),mVo=l(),P1=a("li"),obe=a("strong"),fVo=o("roberta"),gVo=o(" \u2014 "),Yz=a("a"),hVo=o("RobertaForCausalLM"),uVo=o(" (RoBERTa model)"),pVo=l(),B1=a("li"),rbe=a("strong"),_Vo=o("roformer"),bVo=o(" \u2014 "),Kz=a("a"),vVo=o("RoFormerForCausalLM"),FVo=o(" (RoFormer model)"),TVo=l(),I1=a("li"),tbe=a("strong"),MVo=o("speech_to_text_2"),EVo=o(" \u2014 "),Zz=a("a"),CVo=o("Speech2Text2ForCausalLM"),wVo=o(" (Speech2Text2 model)"),AVo=l(),N1=a("li"),abe=a("strong"),LVo=o("transfo-xl"),yVo=o(" \u2014 "),eQ=a("a"),xVo=o("TransfoXLLMHeadModel"),$Vo=o(" (Transformer-XL model)"),kVo=l(),q1=a("li"),nbe=a("strong"),SVo=o("trocr"),RVo=o(" \u2014 "),oQ=a("a"),PVo=o("TrOCRForCausalLM"),BVo=o(" (TrOCR model)"),IVo=l(),j1=a("li"),sbe=a("strong"),NVo=o("xglm"),qVo=o(" \u2014 "),rQ=a("a"),jVo=o("XGLMForCausalLM"),DVo=o(" (XGLM model)"),GVo=l(),D1=a("li"),lbe=a("strong"),OVo=o("xlm"),VVo=o(" \u2014 "),tQ=a("a"),XVo=o("XLMWithLMHeadModel"),zVo=o(" (XLM model)"),QVo=l(),G1=a("li"),ibe=a("strong"),WVo=o("xlm-prophetnet"),UVo=o(" \u2014 "),aQ=a("a"),HVo=o("XLMProphetNetForCausalLM"),JVo=o(" (XLM-ProphetNet model)"),YVo=l(),O1=a("li"),dbe=a("strong"),KVo=o("xlm-roberta"),ZVo=o(" \u2014 "),nQ=a("a"),eXo=o("XLMRobertaForCausalLM"),oXo=o(" (XLM-RoBERTa model)"),rXo=l(),V1=a("li"),cbe=a("strong"),tXo=o("xlm-roberta-xl"),aXo=o(" \u2014 "),sQ=a("a"),nXo=o("XLMRobertaXLForCausalLM"),sXo=o(" (XLM-RoBERTa-XL model)"),lXo=l(),X1=a("li"),mbe=a("strong"),iXo=o("xlnet"),dXo=o(" \u2014 "),lQ=a("a"),cXo=o("XLNetLMHeadModel"),mXo=o(" (XLNet model)"),fXo=l(),z1=a("p"),gXo=o("The model is set in evaluation mode by default using "),fbe=a("code"),hXo=o("model.eval()"),uXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gbe=a("code"),pXo=o("model.train()"),_Xo=l(),F(Q1.$$.fragment),JYe=l(),wd=a("h2"),W1=a("a"),hbe=a("span"),F(cx.$$.fragment),bXo=l(),ube=a("span"),vXo=o("AutoModelForMaskedLM"),YYe=l(),No=a("div"),F(mx.$$.fragment),FXo=l(),Ad=a("p"),TXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),iQ=a("a"),MXo=o("from_pretrained()"),EXo=o(" class method or the "),dQ=a("a"),CXo=o("from_config()"),wXo=o(` class
method.`),AXo=l(),fx=a("p"),LXo=o("This class cannot be instantiated directly using "),pbe=a("code"),yXo=o("__init__()"),xXo=o(" (throws an error)."),$Xo=l(),Ft=a("div"),F(gx.$$.fragment),kXo=l(),_be=a("p"),SXo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),RXo=l(),Ld=a("p"),PXo=o(`Note:
Loading a model from its configuration file does `),bbe=a("strong"),BXo=o("not"),IXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),NXo=o("from_pretrained()"),qXo=o(" to load the model weights."),jXo=l(),F(U1.$$.fragment),DXo=l(),ro=a("div"),F(hx.$$.fragment),GXo=l(),vbe=a("p"),OXo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),VXo=l(),Za=a("p"),XXo=o("The model class to instantiate is selected based on the "),Fbe=a("code"),zXo=o("model_type"),QXo=o(` property of the config object (either
passed as an argument or loaded from `),Tbe=a("code"),WXo=o("pretrained_model_name_or_path"),UXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mbe=a("code"),HXo=o("pretrained_model_name_or_path"),JXo=o(":"),YXo=l(),U=a("ul"),H1=a("li"),Ebe=a("strong"),KXo=o("albert"),ZXo=o(" \u2014 "),mQ=a("a"),ezo=o("AlbertForMaskedLM"),ozo=o(" (ALBERT model)"),rzo=l(),J1=a("li"),Cbe=a("strong"),tzo=o("bart"),azo=o(" \u2014 "),fQ=a("a"),nzo=o("BartForConditionalGeneration"),szo=o(" (BART model)"),lzo=l(),Y1=a("li"),wbe=a("strong"),izo=o("bert"),dzo=o(" \u2014 "),gQ=a("a"),czo=o("BertForMaskedLM"),mzo=o(" (BERT model)"),fzo=l(),K1=a("li"),Abe=a("strong"),gzo=o("big_bird"),hzo=o(" \u2014 "),hQ=a("a"),uzo=o("BigBirdForMaskedLM"),pzo=o(" (BigBird model)"),_zo=l(),Z1=a("li"),Lbe=a("strong"),bzo=o("camembert"),vzo=o(" \u2014 "),uQ=a("a"),Fzo=o("CamembertForMaskedLM"),Tzo=o(" (CamemBERT model)"),Mzo=l(),ev=a("li"),ybe=a("strong"),Ezo=o("convbert"),Czo=o(" \u2014 "),pQ=a("a"),wzo=o("ConvBertForMaskedLM"),Azo=o(" (ConvBERT model)"),Lzo=l(),ov=a("li"),xbe=a("strong"),yzo=o("data2vec-text"),xzo=o(" \u2014 "),_Q=a("a"),$zo=o("Data2VecTextForMaskedLM"),kzo=o(" (Data2VecText model)"),Szo=l(),rv=a("li"),$be=a("strong"),Rzo=o("deberta"),Pzo=o(" \u2014 "),bQ=a("a"),Bzo=o("DebertaForMaskedLM"),Izo=o(" (DeBERTa model)"),Nzo=l(),tv=a("li"),kbe=a("strong"),qzo=o("deberta-v2"),jzo=o(" \u2014 "),vQ=a("a"),Dzo=o("DebertaV2ForMaskedLM"),Gzo=o(" (DeBERTa-v2 model)"),Ozo=l(),av=a("li"),Sbe=a("strong"),Vzo=o("distilbert"),Xzo=o(" \u2014 "),FQ=a("a"),zzo=o("DistilBertForMaskedLM"),Qzo=o(" (DistilBERT model)"),Wzo=l(),nv=a("li"),Rbe=a("strong"),Uzo=o("electra"),Hzo=o(" \u2014 "),TQ=a("a"),Jzo=o("ElectraForMaskedLM"),Yzo=o(" (ELECTRA model)"),Kzo=l(),sv=a("li"),Pbe=a("strong"),Zzo=o("ernie"),eQo=o(" \u2014 "),MQ=a("a"),oQo=o("ErnieForMaskedLM"),rQo=o(" (ERNIE model)"),tQo=l(),lv=a("li"),Bbe=a("strong"),aQo=o("flaubert"),nQo=o(" \u2014 "),EQ=a("a"),sQo=o("FlaubertWithLMHeadModel"),lQo=o(" (FlauBERT model)"),iQo=l(),iv=a("li"),Ibe=a("strong"),dQo=o("fnet"),cQo=o(" \u2014 "),CQ=a("a"),mQo=o("FNetForMaskedLM"),fQo=o(" (FNet model)"),gQo=l(),dv=a("li"),Nbe=a("strong"),hQo=o("funnel"),uQo=o(" \u2014 "),wQ=a("a"),pQo=o("FunnelForMaskedLM"),_Qo=o(" (Funnel Transformer model)"),bQo=l(),cv=a("li"),qbe=a("strong"),vQo=o("ibert"),FQo=o(" \u2014 "),AQ=a("a"),TQo=o("IBertForMaskedLM"),MQo=o(" (I-BERT model)"),EQo=l(),mv=a("li"),jbe=a("strong"),CQo=o("layoutlm"),wQo=o(" \u2014 "),LQ=a("a"),AQo=o("LayoutLMForMaskedLM"),LQo=o(" (LayoutLM model)"),yQo=l(),fv=a("li"),Dbe=a("strong"),xQo=o("longformer"),$Qo=o(" \u2014 "),yQ=a("a"),kQo=o("LongformerForMaskedLM"),SQo=o(" (Longformer model)"),RQo=l(),gv=a("li"),Gbe=a("strong"),PQo=o("luke"),BQo=o(" \u2014 "),xQ=a("a"),IQo=o("LukeForMaskedLM"),NQo=o(" (LUKE model)"),qQo=l(),hv=a("li"),Obe=a("strong"),jQo=o("mbart"),DQo=o(" \u2014 "),$Q=a("a"),GQo=o("MBartForConditionalGeneration"),OQo=o(" (mBART model)"),VQo=l(),uv=a("li"),Vbe=a("strong"),XQo=o("megatron-bert"),zQo=o(" \u2014 "),kQ=a("a"),QQo=o("MegatronBertForMaskedLM"),WQo=o(" (Megatron-BERT model)"),UQo=l(),pv=a("li"),Xbe=a("strong"),HQo=o("mobilebert"),JQo=o(" \u2014 "),SQ=a("a"),YQo=o("MobileBertForMaskedLM"),KQo=o(" (MobileBERT model)"),ZQo=l(),_v=a("li"),zbe=a("strong"),eWo=o("mpnet"),oWo=o(" \u2014 "),RQ=a("a"),rWo=o("MPNetForMaskedLM"),tWo=o(" (MPNet model)"),aWo=l(),bv=a("li"),Qbe=a("strong"),nWo=o("mvp"),sWo=o(" \u2014 "),PQ=a("a"),lWo=o("MvpForConditionalGeneration"),iWo=o(" (MVP model)"),dWo=l(),vv=a("li"),Wbe=a("strong"),cWo=o("nezha"),mWo=o(" \u2014 "),BQ=a("a"),fWo=o("NezhaForMaskedLM"),gWo=o(" (Nezha model)"),hWo=l(),Fv=a("li"),Ube=a("strong"),uWo=o("nystromformer"),pWo=o(" \u2014 "),IQ=a("a"),_Wo=o("NystromformerForMaskedLM"),bWo=o(" (Nystr\xF6mformer model)"),vWo=l(),Tv=a("li"),Hbe=a("strong"),FWo=o("perceiver"),TWo=o(" \u2014 "),NQ=a("a"),MWo=o("PerceiverForMaskedLM"),EWo=o(" (Perceiver model)"),CWo=l(),Mv=a("li"),Jbe=a("strong"),wWo=o("qdqbert"),AWo=o(" \u2014 "),qQ=a("a"),LWo=o("QDQBertForMaskedLM"),yWo=o(" (QDQBert model)"),xWo=l(),Ev=a("li"),Ybe=a("strong"),$Wo=o("reformer"),kWo=o(" \u2014 "),jQ=a("a"),SWo=o("ReformerForMaskedLM"),RWo=o(" (Reformer model)"),PWo=l(),Cv=a("li"),Kbe=a("strong"),BWo=o("rembert"),IWo=o(" \u2014 "),DQ=a("a"),NWo=o("RemBertForMaskedLM"),qWo=o(" (RemBERT model)"),jWo=l(),wv=a("li"),Zbe=a("strong"),DWo=o("roberta"),GWo=o(" \u2014 "),GQ=a("a"),OWo=o("RobertaForMaskedLM"),VWo=o(" (RoBERTa model)"),XWo=l(),Av=a("li"),e1e=a("strong"),zWo=o("roformer"),QWo=o(" \u2014 "),OQ=a("a"),WWo=o("RoFormerForMaskedLM"),UWo=o(" (RoFormer model)"),HWo=l(),Lv=a("li"),o1e=a("strong"),JWo=o("squeezebert"),YWo=o(" \u2014 "),VQ=a("a"),KWo=o("SqueezeBertForMaskedLM"),ZWo=o(" (SqueezeBERT model)"),eUo=l(),yv=a("li"),r1e=a("strong"),oUo=o("tapas"),rUo=o(" \u2014 "),XQ=a("a"),tUo=o("TapasForMaskedLM"),aUo=o(" (TAPAS model)"),nUo=l(),xv=a("li"),t1e=a("strong"),sUo=o("wav2vec2"),lUo=o(" \u2014 "),a1e=a("code"),iUo=o("Wav2Vec2ForMaskedLM"),dUo=o(" (Wav2Vec2 model)"),cUo=l(),$v=a("li"),n1e=a("strong"),mUo=o("xlm"),fUo=o(" \u2014 "),zQ=a("a"),gUo=o("XLMWithLMHeadModel"),hUo=o(" (XLM model)"),uUo=l(),kv=a("li"),s1e=a("strong"),pUo=o("xlm-roberta"),_Uo=o(" \u2014 "),QQ=a("a"),bUo=o("XLMRobertaForMaskedLM"),vUo=o(" (XLM-RoBERTa model)"),FUo=l(),Sv=a("li"),l1e=a("strong"),TUo=o("xlm-roberta-xl"),MUo=o(" \u2014 "),WQ=a("a"),EUo=o("XLMRobertaXLForMaskedLM"),CUo=o(" (XLM-RoBERTa-XL model)"),wUo=l(),Rv=a("li"),i1e=a("strong"),AUo=o("yoso"),LUo=o(" \u2014 "),UQ=a("a"),yUo=o("YosoForMaskedLM"),xUo=o(" (YOSO model)"),$Uo=l(),Pv=a("p"),kUo=o("The model is set in evaluation mode by default using "),d1e=a("code"),SUo=o("model.eval()"),RUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c1e=a("code"),PUo=o("model.train()"),BUo=l(),F(Bv.$$.fragment),KYe=l(),yd=a("h2"),Iv=a("a"),m1e=a("span"),F(ux.$$.fragment),IUo=l(),f1e=a("span"),NUo=o("AutoModelForSeq2SeqLM"),ZYe=l(),qo=a("div"),F(px.$$.fragment),qUo=l(),xd=a("p"),jUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HQ=a("a"),DUo=o("from_pretrained()"),GUo=o(" class method or the "),JQ=a("a"),OUo=o("from_config()"),VUo=o(` class
method.`),XUo=l(),_x=a("p"),zUo=o("This class cannot be instantiated directly using "),g1e=a("code"),QUo=o("__init__()"),WUo=o(" (throws an error)."),UUo=l(),Tt=a("div"),F(bx.$$.fragment),HUo=l(),h1e=a("p"),JUo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YUo=l(),$d=a("p"),KUo=o(`Note:
Loading a model from its configuration file does `),u1e=a("strong"),ZUo=o("not"),eHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=a("a"),oHo=o("from_pretrained()"),rHo=o(" to load the model weights."),tHo=l(),F(Nv.$$.fragment),aHo=l(),to=a("div"),F(vx.$$.fragment),nHo=l(),p1e=a("p"),sHo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),lHo=l(),en=a("p"),iHo=o("The model class to instantiate is selected based on the "),_1e=a("code"),dHo=o("model_type"),cHo=o(` property of the config object (either
passed as an argument or loaded from `),b1e=a("code"),mHo=o("pretrained_model_name_or_path"),fHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v1e=a("code"),gHo=o("pretrained_model_name_or_path"),hHo=o(":"),uHo=l(),me=a("ul"),qv=a("li"),F1e=a("strong"),pHo=o("bart"),_Ho=o(" \u2014 "),KQ=a("a"),bHo=o("BartForConditionalGeneration"),vHo=o(" (BART model)"),FHo=l(),jv=a("li"),T1e=a("strong"),THo=o("bigbird_pegasus"),MHo=o(" \u2014 "),ZQ=a("a"),EHo=o("BigBirdPegasusForConditionalGeneration"),CHo=o(" (BigBird-Pegasus model)"),wHo=l(),Dv=a("li"),M1e=a("strong"),AHo=o("blenderbot"),LHo=o(" \u2014 "),eW=a("a"),yHo=o("BlenderbotForConditionalGeneration"),xHo=o(" (Blenderbot model)"),$Ho=l(),Gv=a("li"),E1e=a("strong"),kHo=o("blenderbot-small"),SHo=o(" \u2014 "),oW=a("a"),RHo=o("BlenderbotSmallForConditionalGeneration"),PHo=o(" (BlenderbotSmall model)"),BHo=l(),Ov=a("li"),C1e=a("strong"),IHo=o("encoder-decoder"),NHo=o(" \u2014 "),rW=a("a"),qHo=o("EncoderDecoderModel"),jHo=o(" (Encoder decoder model)"),DHo=l(),Vv=a("li"),w1e=a("strong"),GHo=o("fsmt"),OHo=o(" \u2014 "),tW=a("a"),VHo=o("FSMTForConditionalGeneration"),XHo=o(" (FairSeq Machine-Translation model)"),zHo=l(),Xv=a("li"),A1e=a("strong"),QHo=o("led"),WHo=o(" \u2014 "),aW=a("a"),UHo=o("LEDForConditionalGeneration"),HHo=o(" (LED model)"),JHo=l(),zv=a("li"),L1e=a("strong"),YHo=o("longt5"),KHo=o(" \u2014 "),nW=a("a"),ZHo=o("LongT5ForConditionalGeneration"),eJo=o(" (LongT5 model)"),oJo=l(),Qv=a("li"),y1e=a("strong"),rJo=o("m2m_100"),tJo=o(" \u2014 "),sW=a("a"),aJo=o("M2M100ForConditionalGeneration"),nJo=o(" (M2M100 model)"),sJo=l(),Wv=a("li"),x1e=a("strong"),lJo=o("marian"),iJo=o(" \u2014 "),lW=a("a"),dJo=o("MarianMTModel"),cJo=o(" (Marian model)"),mJo=l(),Uv=a("li"),$1e=a("strong"),fJo=o("mbart"),gJo=o(" \u2014 "),iW=a("a"),hJo=o("MBartForConditionalGeneration"),uJo=o(" (mBART model)"),pJo=l(),Hv=a("li"),k1e=a("strong"),_Jo=o("mt5"),bJo=o(" \u2014 "),dW=a("a"),vJo=o("MT5ForConditionalGeneration"),FJo=o(" (MT5 model)"),TJo=l(),Jv=a("li"),S1e=a("strong"),MJo=o("mvp"),EJo=o(" \u2014 "),cW=a("a"),CJo=o("MvpForConditionalGeneration"),wJo=o(" (MVP model)"),AJo=l(),Yv=a("li"),R1e=a("strong"),LJo=o("nllb"),yJo=o(" \u2014 "),mW=a("a"),xJo=o("M2M100ForConditionalGeneration"),$Jo=o(" (NLLB model)"),kJo=l(),Kv=a("li"),P1e=a("strong"),SJo=o("pegasus"),RJo=o(" \u2014 "),fW=a("a"),PJo=o("PegasusForConditionalGeneration"),BJo=o(" (Pegasus model)"),IJo=l(),Zv=a("li"),B1e=a("strong"),NJo=o("pegasus_x"),qJo=o(" \u2014 "),gW=a("a"),jJo=o("PegasusXForConditionalGeneration"),DJo=o(" (PEGASUS-X model)"),GJo=l(),eF=a("li"),I1e=a("strong"),OJo=o("plbart"),VJo=o(" \u2014 "),hW=a("a"),XJo=o("PLBartForConditionalGeneration"),zJo=o(" (PLBart model)"),QJo=l(),oF=a("li"),N1e=a("strong"),WJo=o("prophetnet"),UJo=o(" \u2014 "),uW=a("a"),HJo=o("ProphetNetForConditionalGeneration"),JJo=o(" (ProphetNet model)"),YJo=l(),rF=a("li"),q1e=a("strong"),KJo=o("t5"),ZJo=o(" \u2014 "),pW=a("a"),eYo=o("T5ForConditionalGeneration"),oYo=o(" (T5 model)"),rYo=l(),tF=a("li"),j1e=a("strong"),tYo=o("xlm-prophetnet"),aYo=o(" \u2014 "),_W=a("a"),nYo=o("XLMProphetNetForConditionalGeneration"),sYo=o(" (XLM-ProphetNet model)"),lYo=l(),aF=a("p"),iYo=o("The model is set in evaluation mode by default using "),D1e=a("code"),dYo=o("model.eval()"),cYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G1e=a("code"),mYo=o("model.train()"),fYo=l(),F(nF.$$.fragment),eKe=l(),kd=a("h2"),sF=a("a"),O1e=a("span"),F(Fx.$$.fragment),gYo=l(),V1e=a("span"),hYo=o("AutoModelForSequenceClassification"),oKe=l(),jo=a("div"),F(Tx.$$.fragment),uYo=l(),Sd=a("p"),pYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),bW=a("a"),_Yo=o("from_pretrained()"),bYo=o(" class method or the "),vW=a("a"),vYo=o("from_config()"),FYo=o(` class
method.`),TYo=l(),Mx=a("p"),MYo=o("This class cannot be instantiated directly using "),X1e=a("code"),EYo=o("__init__()"),CYo=o(" (throws an error)."),wYo=l(),Mt=a("div"),F(Ex.$$.fragment),AYo=l(),z1e=a("p"),LYo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yYo=l(),Rd=a("p"),xYo=o(`Note:
Loading a model from its configuration file does `),Q1e=a("strong"),$Yo=o("not"),kYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FW=a("a"),SYo=o("from_pretrained()"),RYo=o(" to load the model weights."),PYo=l(),F(lF.$$.fragment),BYo=l(),ao=a("div"),F(Cx.$$.fragment),IYo=l(),W1e=a("p"),NYo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qYo=l(),on=a("p"),jYo=o("The model class to instantiate is selected based on the "),U1e=a("code"),DYo=o("model_type"),GYo=o(` property of the config object (either
passed as an argument or loaded from `),H1e=a("code"),OYo=o("pretrained_model_name_or_path"),VYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J1e=a("code"),XYo=o("pretrained_model_name_or_path"),zYo=o(":"),QYo=l(),q=a("ul"),iF=a("li"),Y1e=a("strong"),WYo=o("albert"),UYo=o(" \u2014 "),TW=a("a"),HYo=o("AlbertForSequenceClassification"),JYo=o(" (ALBERT model)"),YYo=l(),dF=a("li"),K1e=a("strong"),KYo=o("bart"),ZYo=o(" \u2014 "),MW=a("a"),eKo=o("BartForSequenceClassification"),oKo=o(" (BART model)"),rKo=l(),cF=a("li"),Z1e=a("strong"),tKo=o("bert"),aKo=o(" \u2014 "),EW=a("a"),nKo=o("BertForSequenceClassification"),sKo=o(" (BERT model)"),lKo=l(),mF=a("li"),eve=a("strong"),iKo=o("big_bird"),dKo=o(" \u2014 "),CW=a("a"),cKo=o("BigBirdForSequenceClassification"),mKo=o(" (BigBird model)"),fKo=l(),fF=a("li"),ove=a("strong"),gKo=o("bigbird_pegasus"),hKo=o(" \u2014 "),wW=a("a"),uKo=o("BigBirdPegasusForSequenceClassification"),pKo=o(" (BigBird-Pegasus model)"),_Ko=l(),gF=a("li"),rve=a("strong"),bKo=o("bloom"),vKo=o(" \u2014 "),AW=a("a"),FKo=o("BloomForSequenceClassification"),TKo=o(" (BLOOM model)"),MKo=l(),hF=a("li"),tve=a("strong"),EKo=o("camembert"),CKo=o(" \u2014 "),LW=a("a"),wKo=o("CamembertForSequenceClassification"),AKo=o(" (CamemBERT model)"),LKo=l(),uF=a("li"),ave=a("strong"),yKo=o("canine"),xKo=o(" \u2014 "),yW=a("a"),$Ko=o("CanineForSequenceClassification"),kKo=o(" (CANINE model)"),SKo=l(),pF=a("li"),nve=a("strong"),RKo=o("convbert"),PKo=o(" \u2014 "),xW=a("a"),BKo=o("ConvBertForSequenceClassification"),IKo=o(" (ConvBERT model)"),NKo=l(),_F=a("li"),sve=a("strong"),qKo=o("ctrl"),jKo=o(" \u2014 "),$W=a("a"),DKo=o("CTRLForSequenceClassification"),GKo=o(" (CTRL model)"),OKo=l(),bF=a("li"),lve=a("strong"),VKo=o("data2vec-text"),XKo=o(" \u2014 "),kW=a("a"),zKo=o("Data2VecTextForSequenceClassification"),QKo=o(" (Data2VecText model)"),WKo=l(),vF=a("li"),ive=a("strong"),UKo=o("deberta"),HKo=o(" \u2014 "),SW=a("a"),JKo=o("DebertaForSequenceClassification"),YKo=o(" (DeBERTa model)"),KKo=l(),FF=a("li"),dve=a("strong"),ZKo=o("deberta-v2"),eZo=o(" \u2014 "),RW=a("a"),oZo=o("DebertaV2ForSequenceClassification"),rZo=o(" (DeBERTa-v2 model)"),tZo=l(),TF=a("li"),cve=a("strong"),aZo=o("distilbert"),nZo=o(" \u2014 "),PW=a("a"),sZo=o("DistilBertForSequenceClassification"),lZo=o(" (DistilBERT model)"),iZo=l(),MF=a("li"),mve=a("strong"),dZo=o("electra"),cZo=o(" \u2014 "),BW=a("a"),mZo=o("ElectraForSequenceClassification"),fZo=o(" (ELECTRA model)"),gZo=l(),EF=a("li"),fve=a("strong"),hZo=o("ernie"),uZo=o(" \u2014 "),IW=a("a"),pZo=o("ErnieForSequenceClassification"),_Zo=o(" (ERNIE model)"),bZo=l(),CF=a("li"),gve=a("strong"),vZo=o("flaubert"),FZo=o(" \u2014 "),NW=a("a"),TZo=o("FlaubertForSequenceClassification"),MZo=o(" (FlauBERT model)"),EZo=l(),wF=a("li"),hve=a("strong"),CZo=o("fnet"),wZo=o(" \u2014 "),qW=a("a"),AZo=o("FNetForSequenceClassification"),LZo=o(" (FNet model)"),yZo=l(),AF=a("li"),uve=a("strong"),xZo=o("funnel"),$Zo=o(" \u2014 "),jW=a("a"),kZo=o("FunnelForSequenceClassification"),SZo=o(" (Funnel Transformer model)"),RZo=l(),LF=a("li"),pve=a("strong"),PZo=o("gpt2"),BZo=o(" \u2014 "),DW=a("a"),IZo=o("GPT2ForSequenceClassification"),NZo=o(" (OpenAI GPT-2 model)"),qZo=l(),yF=a("li"),_ve=a("strong"),jZo=o("gpt_neo"),DZo=o(" \u2014 "),GW=a("a"),GZo=o("GPTNeoForSequenceClassification"),OZo=o(" (GPT Neo model)"),VZo=l(),xF=a("li"),bve=a("strong"),XZo=o("gptj"),zZo=o(" \u2014 "),OW=a("a"),QZo=o("GPTJForSequenceClassification"),WZo=o(" (GPT-J model)"),UZo=l(),$F=a("li"),vve=a("strong"),HZo=o("ibert"),JZo=o(" \u2014 "),VW=a("a"),YZo=o("IBertForSequenceClassification"),KZo=o(" (I-BERT model)"),ZZo=l(),kF=a("li"),Fve=a("strong"),eer=o("layoutlm"),oer=o(" \u2014 "),XW=a("a"),rer=o("LayoutLMForSequenceClassification"),ter=o(" (LayoutLM model)"),aer=l(),SF=a("li"),Tve=a("strong"),ner=o("layoutlmv2"),ser=o(" \u2014 "),zW=a("a"),ler=o("LayoutLMv2ForSequenceClassification"),ier=o(" (LayoutLMv2 model)"),der=l(),RF=a("li"),Mve=a("strong"),cer=o("layoutlmv3"),mer=o(" \u2014 "),QW=a("a"),fer=o("LayoutLMv3ForSequenceClassification"),ger=o(" (LayoutLMv3 model)"),her=l(),PF=a("li"),Eve=a("strong"),uer=o("led"),per=o(" \u2014 "),WW=a("a"),_er=o("LEDForSequenceClassification"),ber=o(" (LED model)"),ver=l(),BF=a("li"),Cve=a("strong"),Fer=o("longformer"),Ter=o(" \u2014 "),UW=a("a"),Mer=o("LongformerForSequenceClassification"),Eer=o(" (Longformer model)"),Cer=l(),IF=a("li"),wve=a("strong"),wer=o("luke"),Aer=o(" \u2014 "),HW=a("a"),Ler=o("LukeForSequenceClassification"),yer=o(" (LUKE model)"),xer=l(),NF=a("li"),Ave=a("strong"),$er=o("mbart"),ker=o(" \u2014 "),JW=a("a"),Ser=o("MBartForSequenceClassification"),Rer=o(" (mBART model)"),Per=l(),qF=a("li"),Lve=a("strong"),Ber=o("megatron-bert"),Ier=o(" \u2014 "),YW=a("a"),Ner=o("MegatronBertForSequenceClassification"),qer=o(" (Megatron-BERT model)"),jer=l(),jF=a("li"),yve=a("strong"),Der=o("mobilebert"),Ger=o(" \u2014 "),KW=a("a"),Oer=o("MobileBertForSequenceClassification"),Ver=o(" (MobileBERT model)"),Xer=l(),DF=a("li"),xve=a("strong"),zer=o("mpnet"),Qer=o(" \u2014 "),ZW=a("a"),Wer=o("MPNetForSequenceClassification"),Uer=o(" (MPNet model)"),Her=l(),GF=a("li"),$ve=a("strong"),Jer=o("mvp"),Yer=o(" \u2014 "),eU=a("a"),Ker=o("MvpForSequenceClassification"),Zer=o(" (MVP model)"),eor=l(),OF=a("li"),kve=a("strong"),oor=o("nezha"),ror=o(" \u2014 "),oU=a("a"),tor=o("NezhaForSequenceClassification"),aor=o(" (Nezha model)"),nor=l(),VF=a("li"),Sve=a("strong"),sor=o("nystromformer"),lor=o(" \u2014 "),rU=a("a"),ior=o("NystromformerForSequenceClassification"),dor=o(" (Nystr\xF6mformer model)"),cor=l(),XF=a("li"),Rve=a("strong"),mor=o("openai-gpt"),gor=o(" \u2014 "),tU=a("a"),hor=o("OpenAIGPTForSequenceClassification"),uor=o(" (OpenAI GPT model)"),por=l(),zF=a("li"),Pve=a("strong"),_or=o("opt"),bor=o(" \u2014 "),aU=a("a"),vor=o("OPTForSequenceClassification"),For=o(" (OPT model)"),Tor=l(),QF=a("li"),Bve=a("strong"),Mor=o("perceiver"),Eor=o(" \u2014 "),nU=a("a"),Cor=o("PerceiverForSequenceClassification"),wor=o(" (Perceiver model)"),Aor=l(),WF=a("li"),Ive=a("strong"),Lor=o("plbart"),yor=o(" \u2014 "),sU=a("a"),xor=o("PLBartForSequenceClassification"),$or=o(" (PLBart model)"),kor=l(),UF=a("li"),Nve=a("strong"),Sor=o("qdqbert"),Ror=o(" \u2014 "),lU=a("a"),Por=o("QDQBertForSequenceClassification"),Bor=o(" (QDQBert model)"),Ior=l(),HF=a("li"),qve=a("strong"),Nor=o("reformer"),qor=o(" \u2014 "),iU=a("a"),jor=o("ReformerForSequenceClassification"),Dor=o(" (Reformer model)"),Gor=l(),JF=a("li"),jve=a("strong"),Oor=o("rembert"),Vor=o(" \u2014 "),dU=a("a"),Xor=o("RemBertForSequenceClassification"),zor=o(" (RemBERT model)"),Qor=l(),YF=a("li"),Dve=a("strong"),Wor=o("roberta"),Uor=o(" \u2014 "),cU=a("a"),Hor=o("RobertaForSequenceClassification"),Jor=o(" (RoBERTa model)"),Yor=l(),KF=a("li"),Gve=a("strong"),Kor=o("roformer"),Zor=o(" \u2014 "),mU=a("a"),err=o("RoFormerForSequenceClassification"),orr=o(" (RoFormer model)"),rrr=l(),ZF=a("li"),Ove=a("strong"),trr=o("squeezebert"),arr=o(" \u2014 "),fU=a("a"),nrr=o("SqueezeBertForSequenceClassification"),srr=o(" (SqueezeBERT model)"),lrr=l(),eT=a("li"),Vve=a("strong"),irr=o("tapas"),drr=o(" \u2014 "),gU=a("a"),crr=o("TapasForSequenceClassification"),mrr=o(" (TAPAS model)"),frr=l(),oT=a("li"),Xve=a("strong"),grr=o("transfo-xl"),hrr=o(" \u2014 "),hU=a("a"),urr=o("TransfoXLForSequenceClassification"),prr=o(" (Transformer-XL model)"),_rr=l(),rT=a("li"),zve=a("strong"),brr=o("xlm"),vrr=o(" \u2014 "),uU=a("a"),Frr=o("XLMForSequenceClassification"),Trr=o(" (XLM model)"),Mrr=l(),tT=a("li"),Qve=a("strong"),Err=o("xlm-roberta"),Crr=o(" \u2014 "),pU=a("a"),wrr=o("XLMRobertaForSequenceClassification"),Arr=o(" (XLM-RoBERTa model)"),Lrr=l(),aT=a("li"),Wve=a("strong"),yrr=o("xlm-roberta-xl"),xrr=o(" \u2014 "),_U=a("a"),$rr=o("XLMRobertaXLForSequenceClassification"),krr=o(" (XLM-RoBERTa-XL model)"),Srr=l(),nT=a("li"),Uve=a("strong"),Rrr=o("xlnet"),Prr=o(" \u2014 "),bU=a("a"),Brr=o("XLNetForSequenceClassification"),Irr=o(" (XLNet model)"),Nrr=l(),sT=a("li"),Hve=a("strong"),qrr=o("yoso"),jrr=o(" \u2014 "),vU=a("a"),Drr=o("YosoForSequenceClassification"),Grr=o(" (YOSO model)"),Orr=l(),lT=a("p"),Vrr=o("The model is set in evaluation mode by default using "),Jve=a("code"),Xrr=o("model.eval()"),zrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=a("code"),Qrr=o("model.train()"),Wrr=l(),F(iT.$$.fragment),rKe=l(),Pd=a("h2"),dT=a("a"),Kve=a("span"),F(wx.$$.fragment),Urr=l(),Zve=a("span"),Hrr=o("AutoModelForMultipleChoice"),tKe=l(),Do=a("div"),F(Ax.$$.fragment),Jrr=l(),Bd=a("p"),Yrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FU=a("a"),Krr=o("from_pretrained()"),Zrr=o(" class method or the "),TU=a("a"),etr=o("from_config()"),otr=o(` class
method.`),rtr=l(),Lx=a("p"),ttr=o("This class cannot be instantiated directly using "),eFe=a("code"),atr=o("__init__()"),ntr=o(" (throws an error)."),str=l(),Et=a("div"),F(yx.$$.fragment),ltr=l(),oFe=a("p"),itr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),dtr=l(),Id=a("p"),ctr=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),mtr=o("not"),ftr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=a("a"),gtr=o("from_pretrained()"),htr=o(" to load the model weights."),utr=l(),F(cT.$$.fragment),ptr=l(),no=a("div"),F(xx.$$.fragment),_tr=l(),tFe=a("p"),btr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),vtr=l(),rn=a("p"),Ftr=o("The model class to instantiate is selected based on the "),aFe=a("code"),Ttr=o("model_type"),Mtr=o(` property of the config object (either
passed as an argument or loaded from `),nFe=a("code"),Etr=o("pretrained_model_name_or_path"),Ctr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=a("code"),wtr=o("pretrained_model_name_or_path"),Atr=o(":"),Ltr=l(),Z=a("ul"),mT=a("li"),lFe=a("strong"),ytr=o("albert"),xtr=o(" \u2014 "),EU=a("a"),$tr=o("AlbertForMultipleChoice"),ktr=o(" (ALBERT model)"),Str=l(),fT=a("li"),iFe=a("strong"),Rtr=o("bert"),Ptr=o(" \u2014 "),CU=a("a"),Btr=o("BertForMultipleChoice"),Itr=o(" (BERT model)"),Ntr=l(),gT=a("li"),dFe=a("strong"),qtr=o("big_bird"),jtr=o(" \u2014 "),wU=a("a"),Dtr=o("BigBirdForMultipleChoice"),Gtr=o(" (BigBird model)"),Otr=l(),hT=a("li"),cFe=a("strong"),Vtr=o("camembert"),Xtr=o(" \u2014 "),AU=a("a"),ztr=o("CamembertForMultipleChoice"),Qtr=o(" (CamemBERT model)"),Wtr=l(),uT=a("li"),mFe=a("strong"),Utr=o("canine"),Htr=o(" \u2014 "),LU=a("a"),Jtr=o("CanineForMultipleChoice"),Ytr=o(" (CANINE model)"),Ktr=l(),pT=a("li"),fFe=a("strong"),Ztr=o("convbert"),ear=o(" \u2014 "),yU=a("a"),oar=o("ConvBertForMultipleChoice"),rar=o(" (ConvBERT model)"),tar=l(),_T=a("li"),gFe=a("strong"),aar=o("data2vec-text"),nar=o(" \u2014 "),xU=a("a"),sar=o("Data2VecTextForMultipleChoice"),lar=o(" (Data2VecText model)"),iar=l(),bT=a("li"),hFe=a("strong"),dar=o("deberta-v2"),car=o(" \u2014 "),$U=a("a"),mar=o("DebertaV2ForMultipleChoice"),far=o(" (DeBERTa-v2 model)"),gar=l(),vT=a("li"),uFe=a("strong"),har=o("distilbert"),uar=o(" \u2014 "),kU=a("a"),par=o("DistilBertForMultipleChoice"),_ar=o(" (DistilBERT model)"),bar=l(),FT=a("li"),pFe=a("strong"),Far=o("electra"),Tar=o(" \u2014 "),SU=a("a"),Mar=o("ElectraForMultipleChoice"),Ear=o(" (ELECTRA model)"),Car=l(),TT=a("li"),_Fe=a("strong"),war=o("ernie"),Aar=o(" \u2014 "),RU=a("a"),Lar=o("ErnieForMultipleChoice"),yar=o(" (ERNIE model)"),xar=l(),MT=a("li"),bFe=a("strong"),$ar=o("flaubert"),kar=o(" \u2014 "),PU=a("a"),Sar=o("FlaubertForMultipleChoice"),Rar=o(" (FlauBERT model)"),Par=l(),ET=a("li"),vFe=a("strong"),Bar=o("fnet"),Iar=o(" \u2014 "),BU=a("a"),Nar=o("FNetForMultipleChoice"),qar=o(" (FNet model)"),jar=l(),CT=a("li"),FFe=a("strong"),Dar=o("funnel"),Gar=o(" \u2014 "),IU=a("a"),Oar=o("FunnelForMultipleChoice"),Var=o(" (Funnel Transformer model)"),Xar=l(),wT=a("li"),TFe=a("strong"),zar=o("ibert"),Qar=o(" \u2014 "),NU=a("a"),War=o("IBertForMultipleChoice"),Uar=o(" (I-BERT model)"),Har=l(),AT=a("li"),MFe=a("strong"),Jar=o("longformer"),Yar=o(" \u2014 "),qU=a("a"),Kar=o("LongformerForMultipleChoice"),Zar=o(" (Longformer model)"),enr=l(),LT=a("li"),EFe=a("strong"),onr=o("luke"),rnr=o(" \u2014 "),jU=a("a"),tnr=o("LukeForMultipleChoice"),anr=o(" (LUKE model)"),nnr=l(),yT=a("li"),CFe=a("strong"),snr=o("megatron-bert"),lnr=o(" \u2014 "),DU=a("a"),inr=o("MegatronBertForMultipleChoice"),dnr=o(" (Megatron-BERT model)"),cnr=l(),xT=a("li"),wFe=a("strong"),mnr=o("mobilebert"),fnr=o(" \u2014 "),GU=a("a"),gnr=o("MobileBertForMultipleChoice"),hnr=o(" (MobileBERT model)"),unr=l(),$T=a("li"),AFe=a("strong"),pnr=o("mpnet"),_nr=o(" \u2014 "),OU=a("a"),bnr=o("MPNetForMultipleChoice"),vnr=o(" (MPNet model)"),Fnr=l(),kT=a("li"),LFe=a("strong"),Tnr=o("nezha"),Mnr=o(" \u2014 "),VU=a("a"),Enr=o("NezhaForMultipleChoice"),Cnr=o(" (Nezha model)"),wnr=l(),ST=a("li"),yFe=a("strong"),Anr=o("nystromformer"),Lnr=o(" \u2014 "),XU=a("a"),ynr=o("NystromformerForMultipleChoice"),xnr=o(" (Nystr\xF6mformer model)"),$nr=l(),RT=a("li"),xFe=a("strong"),knr=o("qdqbert"),Snr=o(" \u2014 "),zU=a("a"),Rnr=o("QDQBertForMultipleChoice"),Pnr=o(" (QDQBert model)"),Bnr=l(),PT=a("li"),$Fe=a("strong"),Inr=o("rembert"),Nnr=o(" \u2014 "),QU=a("a"),qnr=o("RemBertForMultipleChoice"),jnr=o(" (RemBERT model)"),Dnr=l(),BT=a("li"),kFe=a("strong"),Gnr=o("roberta"),Onr=o(" \u2014 "),WU=a("a"),Vnr=o("RobertaForMultipleChoice"),Xnr=o(" (RoBERTa model)"),znr=l(),IT=a("li"),SFe=a("strong"),Qnr=o("roformer"),Wnr=o(" \u2014 "),UU=a("a"),Unr=o("RoFormerForMultipleChoice"),Hnr=o(" (RoFormer model)"),Jnr=l(),NT=a("li"),RFe=a("strong"),Ynr=o("squeezebert"),Knr=o(" \u2014 "),HU=a("a"),Znr=o("SqueezeBertForMultipleChoice"),esr=o(" (SqueezeBERT model)"),osr=l(),qT=a("li"),PFe=a("strong"),rsr=o("xlm"),tsr=o(" \u2014 "),JU=a("a"),asr=o("XLMForMultipleChoice"),nsr=o(" (XLM model)"),ssr=l(),jT=a("li"),BFe=a("strong"),lsr=o("xlm-roberta"),isr=o(" \u2014 "),YU=a("a"),dsr=o("XLMRobertaForMultipleChoice"),csr=o(" (XLM-RoBERTa model)"),msr=l(),DT=a("li"),IFe=a("strong"),fsr=o("xlm-roberta-xl"),gsr=o(" \u2014 "),KU=a("a"),hsr=o("XLMRobertaXLForMultipleChoice"),usr=o(" (XLM-RoBERTa-XL model)"),psr=l(),GT=a("li"),NFe=a("strong"),_sr=o("xlnet"),bsr=o(" \u2014 "),ZU=a("a"),vsr=o("XLNetForMultipleChoice"),Fsr=o(" (XLNet model)"),Tsr=l(),OT=a("li"),qFe=a("strong"),Msr=o("yoso"),Esr=o(" \u2014 "),eH=a("a"),Csr=o("YosoForMultipleChoice"),wsr=o(" (YOSO model)"),Asr=l(),VT=a("p"),Lsr=o("The model is set in evaluation mode by default using "),jFe=a("code"),ysr=o("model.eval()"),xsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DFe=a("code"),$sr=o("model.train()"),ksr=l(),F(XT.$$.fragment),aKe=l(),Nd=a("h2"),zT=a("a"),GFe=a("span"),F($x.$$.fragment),Ssr=l(),OFe=a("span"),Rsr=o("AutoModelForNextSentencePrediction"),nKe=l(),Go=a("div"),F(kx.$$.fragment),Psr=l(),qd=a("p"),Bsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oH=a("a"),Isr=o("from_pretrained()"),Nsr=o(" class method or the "),rH=a("a"),qsr=o("from_config()"),jsr=o(` class
method.`),Dsr=l(),Sx=a("p"),Gsr=o("This class cannot be instantiated directly using "),VFe=a("code"),Osr=o("__init__()"),Vsr=o(" (throws an error)."),Xsr=l(),Ct=a("div"),F(Rx.$$.fragment),zsr=l(),XFe=a("p"),Qsr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wsr=l(),jd=a("p"),Usr=o(`Note:
Loading a model from its configuration file does `),zFe=a("strong"),Hsr=o("not"),Jsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=a("a"),Ysr=o("from_pretrained()"),Ksr=o(" to load the model weights."),Zsr=l(),F(QT.$$.fragment),elr=l(),so=a("div"),F(Px.$$.fragment),olr=l(),QFe=a("p"),rlr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),tlr=l(),tn=a("p"),alr=o("The model class to instantiate is selected based on the "),WFe=a("code"),nlr=o("model_type"),slr=o(` property of the config object (either
passed as an argument or loaded from `),UFe=a("code"),llr=o("pretrained_model_name_or_path"),ilr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HFe=a("code"),dlr=o("pretrained_model_name_or_path"),clr=o(":"),mlr=l(),Ue=a("ul"),WT=a("li"),JFe=a("strong"),flr=o("bert"),glr=o(" \u2014 "),aH=a("a"),hlr=o("BertForNextSentencePrediction"),ulr=o(" (BERT model)"),plr=l(),UT=a("li"),YFe=a("strong"),_lr=o("ernie"),blr=o(" \u2014 "),nH=a("a"),vlr=o("ErnieForNextSentencePrediction"),Flr=o(" (ERNIE model)"),Tlr=l(),HT=a("li"),KFe=a("strong"),Mlr=o("fnet"),Elr=o(" \u2014 "),sH=a("a"),Clr=o("FNetForNextSentencePrediction"),wlr=o(" (FNet model)"),Alr=l(),JT=a("li"),ZFe=a("strong"),Llr=o("megatron-bert"),ylr=o(" \u2014 "),lH=a("a"),xlr=o("MegatronBertForNextSentencePrediction"),$lr=o(" (Megatron-BERT model)"),klr=l(),YT=a("li"),eTe=a("strong"),Slr=o("mobilebert"),Rlr=o(" \u2014 "),iH=a("a"),Plr=o("MobileBertForNextSentencePrediction"),Blr=o(" (MobileBERT model)"),Ilr=l(),KT=a("li"),oTe=a("strong"),Nlr=o("nezha"),qlr=o(" \u2014 "),dH=a("a"),jlr=o("NezhaForNextSentencePrediction"),Dlr=o(" (Nezha model)"),Glr=l(),ZT=a("li"),rTe=a("strong"),Olr=o("qdqbert"),Vlr=o(" \u2014 "),cH=a("a"),Xlr=o("QDQBertForNextSentencePrediction"),zlr=o(" (QDQBert model)"),Qlr=l(),eM=a("p"),Wlr=o("The model is set in evaluation mode by default using "),tTe=a("code"),Ulr=o("model.eval()"),Hlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aTe=a("code"),Jlr=o("model.train()"),Ylr=l(),F(oM.$$.fragment),sKe=l(),Dd=a("h2"),rM=a("a"),nTe=a("span"),F(Bx.$$.fragment),Klr=l(),sTe=a("span"),Zlr=o("AutoModelForTokenClassification"),lKe=l(),Oo=a("div"),F(Ix.$$.fragment),eir=l(),Gd=a("p"),oir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mH=a("a"),rir=o("from_pretrained()"),tir=o(" class method or the "),fH=a("a"),air=o("from_config()"),nir=o(` class
method.`),sir=l(),Nx=a("p"),lir=o("This class cannot be instantiated directly using "),lTe=a("code"),iir=o("__init__()"),dir=o(" (throws an error)."),cir=l(),wt=a("div"),F(qx.$$.fragment),mir=l(),iTe=a("p"),fir=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gir=l(),Od=a("p"),hir=o(`Note:
Loading a model from its configuration file does `),dTe=a("strong"),uir=o("not"),pir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=a("a"),_ir=o("from_pretrained()"),bir=o(" to load the model weights."),vir=l(),F(tM.$$.fragment),Fir=l(),lo=a("div"),F(jx.$$.fragment),Tir=l(),cTe=a("p"),Mir=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Eir=l(),an=a("p"),Cir=o("The model class to instantiate is selected based on the "),mTe=a("code"),wir=o("model_type"),Air=o(` property of the config object (either
passed as an argument or loaded from `),fTe=a("code"),Lir=o("pretrained_model_name_or_path"),yir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gTe=a("code"),xir=o("pretrained_model_name_or_path"),$ir=o(":"),kir=l(),H=a("ul"),aM=a("li"),hTe=a("strong"),Sir=o("albert"),Rir=o(" \u2014 "),hH=a("a"),Pir=o("AlbertForTokenClassification"),Bir=o(" (ALBERT model)"),Iir=l(),nM=a("li"),uTe=a("strong"),Nir=o("bert"),qir=o(" \u2014 "),uH=a("a"),jir=o("BertForTokenClassification"),Dir=o(" (BERT model)"),Gir=l(),sM=a("li"),pTe=a("strong"),Oir=o("big_bird"),Vir=o(" \u2014 "),pH=a("a"),Xir=o("BigBirdForTokenClassification"),zir=o(" (BigBird model)"),Qir=l(),lM=a("li"),_Te=a("strong"),Wir=o("bloom"),Uir=o(" \u2014 "),_H=a("a"),Hir=o("BloomForTokenClassification"),Jir=o(" (BLOOM model)"),Yir=l(),iM=a("li"),bTe=a("strong"),Kir=o("camembert"),Zir=o(" \u2014 "),bH=a("a"),edr=o("CamembertForTokenClassification"),odr=o(" (CamemBERT model)"),rdr=l(),dM=a("li"),vTe=a("strong"),tdr=o("canine"),adr=o(" \u2014 "),vH=a("a"),ndr=o("CanineForTokenClassification"),sdr=o(" (CANINE model)"),ldr=l(),cM=a("li"),FTe=a("strong"),idr=o("convbert"),ddr=o(" \u2014 "),FH=a("a"),cdr=o("ConvBertForTokenClassification"),mdr=o(" (ConvBERT model)"),fdr=l(),mM=a("li"),TTe=a("strong"),gdr=o("data2vec-text"),hdr=o(" \u2014 "),TH=a("a"),udr=o("Data2VecTextForTokenClassification"),pdr=o(" (Data2VecText model)"),_dr=l(),fM=a("li"),MTe=a("strong"),bdr=o("deberta"),vdr=o(" \u2014 "),MH=a("a"),Fdr=o("DebertaForTokenClassification"),Tdr=o(" (DeBERTa model)"),Mdr=l(),gM=a("li"),ETe=a("strong"),Edr=o("deberta-v2"),Cdr=o(" \u2014 "),EH=a("a"),wdr=o("DebertaV2ForTokenClassification"),Adr=o(" (DeBERTa-v2 model)"),Ldr=l(),hM=a("li"),CTe=a("strong"),ydr=o("distilbert"),xdr=o(" \u2014 "),CH=a("a"),$dr=o("DistilBertForTokenClassification"),kdr=o(" (DistilBERT model)"),Sdr=l(),uM=a("li"),wTe=a("strong"),Rdr=o("electra"),Pdr=o(" \u2014 "),wH=a("a"),Bdr=o("ElectraForTokenClassification"),Idr=o(" (ELECTRA model)"),Ndr=l(),pM=a("li"),ATe=a("strong"),qdr=o("ernie"),jdr=o(" \u2014 "),AH=a("a"),Ddr=o("ErnieForTokenClassification"),Gdr=o(" (ERNIE model)"),Odr=l(),_M=a("li"),LTe=a("strong"),Vdr=o("flaubert"),Xdr=o(" \u2014 "),LH=a("a"),zdr=o("FlaubertForTokenClassification"),Qdr=o(" (FlauBERT model)"),Wdr=l(),bM=a("li"),yTe=a("strong"),Udr=o("fnet"),Hdr=o(" \u2014 "),yH=a("a"),Jdr=o("FNetForTokenClassification"),Ydr=o(" (FNet model)"),Kdr=l(),vM=a("li"),xTe=a("strong"),Zdr=o("funnel"),ecr=o(" \u2014 "),xH=a("a"),ocr=o("FunnelForTokenClassification"),rcr=o(" (Funnel Transformer model)"),tcr=l(),FM=a("li"),$Te=a("strong"),acr=o("gpt2"),ncr=o(" \u2014 "),$H=a("a"),scr=o("GPT2ForTokenClassification"),lcr=o(" (OpenAI GPT-2 model)"),icr=l(),TM=a("li"),kTe=a("strong"),dcr=o("ibert"),ccr=o(" \u2014 "),kH=a("a"),mcr=o("IBertForTokenClassification"),fcr=o(" (I-BERT model)"),gcr=l(),MM=a("li"),STe=a("strong"),hcr=o("layoutlm"),ucr=o(" \u2014 "),SH=a("a"),pcr=o("LayoutLMForTokenClassification"),_cr=o(" (LayoutLM model)"),bcr=l(),EM=a("li"),RTe=a("strong"),vcr=o("layoutlmv2"),Fcr=o(" \u2014 "),RH=a("a"),Tcr=o("LayoutLMv2ForTokenClassification"),Mcr=o(" (LayoutLMv2 model)"),Ecr=l(),CM=a("li"),PTe=a("strong"),Ccr=o("layoutlmv3"),wcr=o(" \u2014 "),PH=a("a"),Acr=o("LayoutLMv3ForTokenClassification"),Lcr=o(" (LayoutLMv3 model)"),ycr=l(),wM=a("li"),BTe=a("strong"),xcr=o("longformer"),$cr=o(" \u2014 "),BH=a("a"),kcr=o("LongformerForTokenClassification"),Scr=o(" (Longformer model)"),Rcr=l(),AM=a("li"),ITe=a("strong"),Pcr=o("luke"),Bcr=o(" \u2014 "),IH=a("a"),Icr=o("LukeForTokenClassification"),Ncr=o(" (LUKE model)"),qcr=l(),LM=a("li"),NTe=a("strong"),jcr=o("megatron-bert"),Dcr=o(" \u2014 "),NH=a("a"),Gcr=o("MegatronBertForTokenClassification"),Ocr=o(" (Megatron-BERT model)"),Vcr=l(),yM=a("li"),qTe=a("strong"),Xcr=o("mobilebert"),zcr=o(" \u2014 "),qH=a("a"),Qcr=o("MobileBertForTokenClassification"),Wcr=o(" (MobileBERT model)"),Ucr=l(),xM=a("li"),jTe=a("strong"),Hcr=o("mpnet"),Jcr=o(" \u2014 "),jH=a("a"),Ycr=o("MPNetForTokenClassification"),Kcr=o(" (MPNet model)"),Zcr=l(),$M=a("li"),DTe=a("strong"),emr=o("nezha"),omr=o(" \u2014 "),DH=a("a"),rmr=o("NezhaForTokenClassification"),tmr=o(" (Nezha model)"),amr=l(),kM=a("li"),GTe=a("strong"),nmr=o("nystromformer"),smr=o(" \u2014 "),GH=a("a"),lmr=o("NystromformerForTokenClassification"),imr=o(" (Nystr\xF6mformer model)"),dmr=l(),SM=a("li"),OTe=a("strong"),cmr=o("qdqbert"),mmr=o(" \u2014 "),OH=a("a"),fmr=o("QDQBertForTokenClassification"),gmr=o(" (QDQBert model)"),hmr=l(),RM=a("li"),VTe=a("strong"),umr=o("rembert"),pmr=o(" \u2014 "),VH=a("a"),_mr=o("RemBertForTokenClassification"),bmr=o(" (RemBERT model)"),vmr=l(),PM=a("li"),XTe=a("strong"),Fmr=o("roberta"),Tmr=o(" \u2014 "),XH=a("a"),Mmr=o("RobertaForTokenClassification"),Emr=o(" (RoBERTa model)"),Cmr=l(),BM=a("li"),zTe=a("strong"),wmr=o("roformer"),Amr=o(" \u2014 "),zH=a("a"),Lmr=o("RoFormerForTokenClassification"),ymr=o(" (RoFormer model)"),xmr=l(),IM=a("li"),QTe=a("strong"),$mr=o("squeezebert"),kmr=o(" \u2014 "),QH=a("a"),Smr=o("SqueezeBertForTokenClassification"),Rmr=o(" (SqueezeBERT model)"),Pmr=l(),NM=a("li"),WTe=a("strong"),Bmr=o("xlm"),Imr=o(" \u2014 "),WH=a("a"),Nmr=o("XLMForTokenClassification"),qmr=o(" (XLM model)"),jmr=l(),qM=a("li"),UTe=a("strong"),Dmr=o("xlm-roberta"),Gmr=o(" \u2014 "),UH=a("a"),Omr=o("XLMRobertaForTokenClassification"),Vmr=o(" (XLM-RoBERTa model)"),Xmr=l(),jM=a("li"),HTe=a("strong"),zmr=o("xlm-roberta-xl"),Qmr=o(" \u2014 "),HH=a("a"),Wmr=o("XLMRobertaXLForTokenClassification"),Umr=o(" (XLM-RoBERTa-XL model)"),Hmr=l(),DM=a("li"),JTe=a("strong"),Jmr=o("xlnet"),Ymr=o(" \u2014 "),JH=a("a"),Kmr=o("XLNetForTokenClassification"),Zmr=o(" (XLNet model)"),efr=l(),GM=a("li"),YTe=a("strong"),ofr=o("yoso"),rfr=o(" \u2014 "),YH=a("a"),tfr=o("YosoForTokenClassification"),afr=o(" (YOSO model)"),nfr=l(),OM=a("p"),sfr=o("The model is set in evaluation mode by default using "),KTe=a("code"),lfr=o("model.eval()"),ifr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZTe=a("code"),dfr=o("model.train()"),cfr=l(),F(VM.$$.fragment),iKe=l(),Vd=a("h2"),XM=a("a"),eMe=a("span"),F(Dx.$$.fragment),mfr=l(),oMe=a("span"),ffr=o("AutoModelForQuestionAnswering"),dKe=l(),Vo=a("div"),F(Gx.$$.fragment),gfr=l(),Xd=a("p"),hfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KH=a("a"),ufr=o("from_pretrained()"),pfr=o(" class method or the "),ZH=a("a"),_fr=o("from_config()"),bfr=o(` class
method.`),vfr=l(),Ox=a("p"),Ffr=o("This class cannot be instantiated directly using "),rMe=a("code"),Tfr=o("__init__()"),Mfr=o(" (throws an error)."),Efr=l(),At=a("div"),F(Vx.$$.fragment),Cfr=l(),tMe=a("p"),wfr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Afr=l(),zd=a("p"),Lfr=o(`Note:
Loading a model from its configuration file does `),aMe=a("strong"),yfr=o("not"),xfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),$fr=o("from_pretrained()"),kfr=o(" to load the model weights."),Sfr=l(),F(zM.$$.fragment),Rfr=l(),io=a("div"),F(Xx.$$.fragment),Pfr=l(),nMe=a("p"),Bfr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ifr=l(),nn=a("p"),Nfr=o("The model class to instantiate is selected based on the "),sMe=a("code"),qfr=o("model_type"),jfr=o(` property of the config object (either
passed as an argument or loaded from `),lMe=a("code"),Dfr=o("pretrained_model_name_or_path"),Gfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iMe=a("code"),Ofr=o("pretrained_model_name_or_path"),Vfr=o(":"),Xfr=l(),V=a("ul"),QM=a("li"),dMe=a("strong"),zfr=o("albert"),Qfr=o(" \u2014 "),oJ=a("a"),Wfr=o("AlbertForQuestionAnswering"),Ufr=o(" (ALBERT model)"),Hfr=l(),WM=a("li"),cMe=a("strong"),Jfr=o("bart"),Yfr=o(" \u2014 "),rJ=a("a"),Kfr=o("BartForQuestionAnswering"),Zfr=o(" (BART model)"),egr=l(),UM=a("li"),mMe=a("strong"),ogr=o("bert"),rgr=o(" \u2014 "),tJ=a("a"),tgr=o("BertForQuestionAnswering"),agr=o(" (BERT model)"),ngr=l(),HM=a("li"),fMe=a("strong"),sgr=o("big_bird"),lgr=o(" \u2014 "),aJ=a("a"),igr=o("BigBirdForQuestionAnswering"),dgr=o(" (BigBird model)"),cgr=l(),JM=a("li"),gMe=a("strong"),mgr=o("bigbird_pegasus"),fgr=o(" \u2014 "),nJ=a("a"),ggr=o("BigBirdPegasusForQuestionAnswering"),hgr=o(" (BigBird-Pegasus model)"),ugr=l(),YM=a("li"),hMe=a("strong"),pgr=o("camembert"),_gr=o(" \u2014 "),sJ=a("a"),bgr=o("CamembertForQuestionAnswering"),vgr=o(" (CamemBERT model)"),Fgr=l(),KM=a("li"),uMe=a("strong"),Tgr=o("canine"),Mgr=o(" \u2014 "),lJ=a("a"),Egr=o("CanineForQuestionAnswering"),Cgr=o(" (CANINE model)"),wgr=l(),ZM=a("li"),pMe=a("strong"),Agr=o("convbert"),Lgr=o(" \u2014 "),iJ=a("a"),ygr=o("ConvBertForQuestionAnswering"),xgr=o(" (ConvBERT model)"),$gr=l(),eE=a("li"),_Me=a("strong"),kgr=o("data2vec-text"),Sgr=o(" \u2014 "),dJ=a("a"),Rgr=o("Data2VecTextForQuestionAnswering"),Pgr=o(" (Data2VecText model)"),Bgr=l(),oE=a("li"),bMe=a("strong"),Igr=o("deberta"),Ngr=o(" \u2014 "),cJ=a("a"),qgr=o("DebertaForQuestionAnswering"),jgr=o(" (DeBERTa model)"),Dgr=l(),rE=a("li"),vMe=a("strong"),Ggr=o("deberta-v2"),Ogr=o(" \u2014 "),mJ=a("a"),Vgr=o("DebertaV2ForQuestionAnswering"),Xgr=o(" (DeBERTa-v2 model)"),zgr=l(),tE=a("li"),FMe=a("strong"),Qgr=o("distilbert"),Wgr=o(" \u2014 "),fJ=a("a"),Ugr=o("DistilBertForQuestionAnswering"),Hgr=o(" (DistilBERT model)"),Jgr=l(),aE=a("li"),TMe=a("strong"),Ygr=o("electra"),Kgr=o(" \u2014 "),gJ=a("a"),Zgr=o("ElectraForQuestionAnswering"),ehr=o(" (ELECTRA model)"),ohr=l(),nE=a("li"),MMe=a("strong"),rhr=o("ernie"),thr=o(" \u2014 "),hJ=a("a"),ahr=o("ErnieForQuestionAnswering"),nhr=o(" (ERNIE model)"),shr=l(),sE=a("li"),EMe=a("strong"),lhr=o("flaubert"),ihr=o(" \u2014 "),uJ=a("a"),dhr=o("FlaubertForQuestionAnsweringSimple"),chr=o(" (FlauBERT model)"),mhr=l(),lE=a("li"),CMe=a("strong"),fhr=o("fnet"),ghr=o(" \u2014 "),pJ=a("a"),hhr=o("FNetForQuestionAnswering"),uhr=o(" (FNet model)"),phr=l(),iE=a("li"),wMe=a("strong"),_hr=o("funnel"),bhr=o(" \u2014 "),_J=a("a"),vhr=o("FunnelForQuestionAnswering"),Fhr=o(" (Funnel Transformer model)"),Thr=l(),dE=a("li"),AMe=a("strong"),Mhr=o("gptj"),Ehr=o(" \u2014 "),bJ=a("a"),Chr=o("GPTJForQuestionAnswering"),whr=o(" (GPT-J model)"),Ahr=l(),cE=a("li"),LMe=a("strong"),Lhr=o("ibert"),yhr=o(" \u2014 "),vJ=a("a"),xhr=o("IBertForQuestionAnswering"),$hr=o(" (I-BERT model)"),khr=l(),mE=a("li"),yMe=a("strong"),Shr=o("layoutlmv2"),Rhr=o(" \u2014 "),FJ=a("a"),Phr=o("LayoutLMv2ForQuestionAnswering"),Bhr=o(" (LayoutLMv2 model)"),Ihr=l(),fE=a("li"),xMe=a("strong"),Nhr=o("layoutlmv3"),qhr=o(" \u2014 "),TJ=a("a"),jhr=o("LayoutLMv3ForQuestionAnswering"),Dhr=o(" (LayoutLMv3 model)"),Ghr=l(),gE=a("li"),$Me=a("strong"),Ohr=o("led"),Vhr=o(" \u2014 "),MJ=a("a"),Xhr=o("LEDForQuestionAnswering"),zhr=o(" (LED model)"),Qhr=l(),hE=a("li"),kMe=a("strong"),Whr=o("longformer"),Uhr=o(" \u2014 "),EJ=a("a"),Hhr=o("LongformerForQuestionAnswering"),Jhr=o(" (Longformer model)"),Yhr=l(),uE=a("li"),SMe=a("strong"),Khr=o("luke"),Zhr=o(" \u2014 "),CJ=a("a"),eur=o("LukeForQuestionAnswering"),our=o(" (LUKE model)"),rur=l(),pE=a("li"),RMe=a("strong"),tur=o("lxmert"),aur=o(" \u2014 "),wJ=a("a"),nur=o("LxmertForQuestionAnswering"),sur=o(" (LXMERT model)"),lur=l(),_E=a("li"),PMe=a("strong"),iur=o("mbart"),dur=o(" \u2014 "),AJ=a("a"),cur=o("MBartForQuestionAnswering"),mur=o(" (mBART model)"),fur=l(),bE=a("li"),BMe=a("strong"),gur=o("megatron-bert"),hur=o(" \u2014 "),LJ=a("a"),uur=o("MegatronBertForQuestionAnswering"),pur=o(" (Megatron-BERT model)"),_ur=l(),vE=a("li"),IMe=a("strong"),bur=o("mobilebert"),vur=o(" \u2014 "),yJ=a("a"),Fur=o("MobileBertForQuestionAnswering"),Tur=o(" (MobileBERT model)"),Mur=l(),FE=a("li"),NMe=a("strong"),Eur=o("mpnet"),Cur=o(" \u2014 "),xJ=a("a"),wur=o("MPNetForQuestionAnswering"),Aur=o(" (MPNet model)"),Lur=l(),TE=a("li"),qMe=a("strong"),yur=o("mvp"),xur=o(" \u2014 "),$J=a("a"),$ur=o("MvpForQuestionAnswering"),kur=o(" (MVP model)"),Sur=l(),ME=a("li"),jMe=a("strong"),Rur=o("nezha"),Pur=o(" \u2014 "),kJ=a("a"),Bur=o("NezhaForQuestionAnswering"),Iur=o(" (Nezha model)"),Nur=l(),EE=a("li"),DMe=a("strong"),qur=o("nystromformer"),jur=o(" \u2014 "),SJ=a("a"),Dur=o("NystromformerForQuestionAnswering"),Gur=o(" (Nystr\xF6mformer model)"),Our=l(),CE=a("li"),GMe=a("strong"),Vur=o("qdqbert"),Xur=o(" \u2014 "),RJ=a("a"),zur=o("QDQBertForQuestionAnswering"),Qur=o(" (QDQBert model)"),Wur=l(),wE=a("li"),OMe=a("strong"),Uur=o("reformer"),Hur=o(" \u2014 "),PJ=a("a"),Jur=o("ReformerForQuestionAnswering"),Yur=o(" (Reformer model)"),Kur=l(),AE=a("li"),VMe=a("strong"),Zur=o("rembert"),epr=o(" \u2014 "),BJ=a("a"),opr=o("RemBertForQuestionAnswering"),rpr=o(" (RemBERT model)"),tpr=l(),LE=a("li"),XMe=a("strong"),apr=o("roberta"),npr=o(" \u2014 "),IJ=a("a"),spr=o("RobertaForQuestionAnswering"),lpr=o(" (RoBERTa model)"),ipr=l(),yE=a("li"),zMe=a("strong"),dpr=o("roformer"),cpr=o(" \u2014 "),NJ=a("a"),mpr=o("RoFormerForQuestionAnswering"),fpr=o(" (RoFormer model)"),gpr=l(),xE=a("li"),QMe=a("strong"),hpr=o("splinter"),upr=o(" \u2014 "),qJ=a("a"),ppr=o("SplinterForQuestionAnswering"),_pr=o(" (Splinter model)"),bpr=l(),$E=a("li"),WMe=a("strong"),vpr=o("squeezebert"),Fpr=o(" \u2014 "),jJ=a("a"),Tpr=o("SqueezeBertForQuestionAnswering"),Mpr=o(" (SqueezeBERT model)"),Epr=l(),kE=a("li"),UMe=a("strong"),Cpr=o("xlm"),wpr=o(" \u2014 "),DJ=a("a"),Apr=o("XLMForQuestionAnsweringSimple"),Lpr=o(" (XLM model)"),ypr=l(),SE=a("li"),HMe=a("strong"),xpr=o("xlm-roberta"),$pr=o(" \u2014 "),GJ=a("a"),kpr=o("XLMRobertaForQuestionAnswering"),Spr=o(" (XLM-RoBERTa model)"),Rpr=l(),RE=a("li"),JMe=a("strong"),Ppr=o("xlm-roberta-xl"),Bpr=o(" \u2014 "),OJ=a("a"),Ipr=o("XLMRobertaXLForQuestionAnswering"),Npr=o(" (XLM-RoBERTa-XL model)"),qpr=l(),PE=a("li"),YMe=a("strong"),jpr=o("xlnet"),Dpr=o(" \u2014 "),VJ=a("a"),Gpr=o("XLNetForQuestionAnsweringSimple"),Opr=o(" (XLNet model)"),Vpr=l(),BE=a("li"),KMe=a("strong"),Xpr=o("yoso"),zpr=o(" \u2014 "),XJ=a("a"),Qpr=o("YosoForQuestionAnswering"),Wpr=o(" (YOSO model)"),Upr=l(),IE=a("p"),Hpr=o("The model is set in evaluation mode by default using "),ZMe=a("code"),Jpr=o("model.eval()"),Ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eEe=a("code"),Kpr=o("model.train()"),Zpr=l(),F(NE.$$.fragment),cKe=l(),Qd=a("h2"),qE=a("a"),oEe=a("span"),F(zx.$$.fragment),e_r=l(),rEe=a("span"),o_r=o("AutoModelForTableQuestionAnswering"),mKe=l(),Xo=a("div"),F(Qx.$$.fragment),r_r=l(),Wd=a("p"),t_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zJ=a("a"),a_r=o("from_pretrained()"),n_r=o(" class method or the "),QJ=a("a"),s_r=o("from_config()"),l_r=o(` class
method.`),i_r=l(),Wx=a("p"),d_r=o("This class cannot be instantiated directly using "),tEe=a("code"),c_r=o("__init__()"),m_r=o(" (throws an error)."),f_r=l(),Lt=a("div"),F(Ux.$$.fragment),g_r=l(),aEe=a("p"),h_r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),u_r=l(),Ud=a("p"),p_r=o(`Note:
Loading a model from its configuration file does `),nEe=a("strong"),__r=o("not"),b_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=a("a"),v_r=o("from_pretrained()"),F_r=o(" to load the model weights."),T_r=l(),F(jE.$$.fragment),M_r=l(),co=a("div"),F(Hx.$$.fragment),E_r=l(),sEe=a("p"),C_r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),w_r=l(),sn=a("p"),A_r=o("The model class to instantiate is selected based on the "),lEe=a("code"),L_r=o("model_type"),y_r=o(` property of the config object (either
passed as an argument or loaded from `),iEe=a("code"),x_r=o("pretrained_model_name_or_path"),$_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dEe=a("code"),k_r=o("pretrained_model_name_or_path"),S_r=o(":"),R_r=l(),cEe=a("ul"),DE=a("li"),mEe=a("strong"),P_r=o("tapas"),B_r=o(" \u2014 "),UJ=a("a"),I_r=o("TapasForQuestionAnswering"),N_r=o(" (TAPAS model)"),q_r=l(),GE=a("p"),j_r=o("The model is set in evaluation mode by default using "),fEe=a("code"),D_r=o("model.eval()"),G_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gEe=a("code"),O_r=o("model.train()"),V_r=l(),F(OE.$$.fragment),fKe=l(),Hd=a("h2"),VE=a("a"),hEe=a("span"),F(Jx.$$.fragment),X_r=l(),uEe=a("span"),z_r=o("AutoModelForDocumentQuestionAnswering"),gKe=l(),zo=a("div"),F(Yx.$$.fragment),Q_r=l(),Jd=a("p"),W_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),HJ=a("a"),U_r=o("from_pretrained()"),H_r=o(" class method or the "),JJ=a("a"),J_r=o("from_config()"),Y_r=o(` class
method.`),K_r=l(),Kx=a("p"),Z_r=o("This class cannot be instantiated directly using "),pEe=a("code"),e2r=o("__init__()"),o2r=o(" (throws an error)."),r2r=l(),yt=a("div"),F(Zx.$$.fragment),t2r=l(),_Ee=a("p"),a2r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),n2r=l(),Yd=a("p"),s2r=o(`Note:
Loading a model from its configuration file does `),bEe=a("strong"),l2r=o("not"),i2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),d2r=o("from_pretrained()"),c2r=o(" to load the model weights."),m2r=l(),F(XE.$$.fragment),f2r=l(),mo=a("div"),F(e$.$$.fragment),g2r=l(),vEe=a("p"),h2r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),u2r=l(),ln=a("p"),p2r=o("The model class to instantiate is selected based on the "),FEe=a("code"),_2r=o("model_type"),b2r=o(` property of the config object (either
passed as an argument or loaded from `),TEe=a("code"),v2r=o("pretrained_model_name_or_path"),F2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MEe=a("code"),T2r=o("pretrained_model_name_or_path"),M2r=o(":"),E2r=l(),Kd=a("ul"),zE=a("li"),EEe=a("strong"),C2r=o("layoutlm"),w2r=o(" \u2014 "),KJ=a("a"),A2r=o("LayoutLMForQuestionAnswering"),L2r=o(" (LayoutLM model)"),y2r=l(),QE=a("li"),CEe=a("strong"),x2r=o("layoutlmv2"),$2r=o(" \u2014 "),ZJ=a("a"),k2r=o("LayoutLMv2ForQuestionAnswering"),S2r=o(" (LayoutLMv2 model)"),R2r=l(),WE=a("li"),wEe=a("strong"),P2r=o("layoutlmv3"),B2r=o(" \u2014 "),eY=a("a"),I2r=o("LayoutLMv3ForQuestionAnswering"),N2r=o(" (LayoutLMv3 model)"),q2r=l(),UE=a("p"),j2r=o("The model is set in evaluation mode by default using "),AEe=a("code"),D2r=o("model.eval()"),G2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=a("code"),O2r=o("model.train()"),V2r=l(),F(HE.$$.fragment),hKe=l(),Zd=a("h2"),JE=a("a"),yEe=a("span"),F(o$.$$.fragment),X2r=l(),xEe=a("span"),z2r=o("AutoModelForImageClassification"),uKe=l(),Qo=a("div"),F(r$.$$.fragment),Q2r=l(),ec=a("p"),W2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),oY=a("a"),U2r=o("from_pretrained()"),H2r=o(" class method or the "),rY=a("a"),J2r=o("from_config()"),Y2r=o(` class
method.`),K2r=l(),t$=a("p"),Z2r=o("This class cannot be instantiated directly using "),$Ee=a("code"),ebr=o("__init__()"),obr=o(" (throws an error)."),rbr=l(),xt=a("div"),F(a$.$$.fragment),tbr=l(),kEe=a("p"),abr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),nbr=l(),oc=a("p"),sbr=o(`Note:
Loading a model from its configuration file does `),SEe=a("strong"),lbr=o("not"),ibr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=a("a"),dbr=o("from_pretrained()"),cbr=o(" to load the model weights."),mbr=l(),F(YE.$$.fragment),fbr=l(),fo=a("div"),F(n$.$$.fragment),gbr=l(),REe=a("p"),hbr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),ubr=l(),dn=a("p"),pbr=o("The model class to instantiate is selected based on the "),PEe=a("code"),_br=o("model_type"),bbr=o(` property of the config object (either
passed as an argument or loaded from `),BEe=a("code"),vbr=o("pretrained_model_name_or_path"),Fbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=a("code"),Tbr=o("pretrained_model_name_or_path"),Mbr=o(":"),Ebr=l(),be=a("ul"),KE=a("li"),NEe=a("strong"),Cbr=o("beit"),wbr=o(" \u2014 "),aY=a("a"),Abr=o("BeitForImageClassification"),Lbr=o(" (BEiT model)"),ybr=l(),ZE=a("li"),qEe=a("strong"),xbr=o("convnext"),$br=o(" \u2014 "),nY=a("a"),kbr=o("ConvNextForImageClassification"),Sbr=o(" (ConvNeXT model)"),Rbr=l(),e4=a("li"),jEe=a("strong"),Pbr=o("cvt"),Bbr=o(" \u2014 "),sY=a("a"),Ibr=o("CvtForImageClassification"),Nbr=o(" (CvT model)"),qbr=l(),o4=a("li"),DEe=a("strong"),jbr=o("data2vec-vision"),Dbr=o(" \u2014 "),lY=a("a"),Gbr=o("Data2VecVisionForImageClassification"),Obr=o(" (Data2VecVision model)"),Vbr=l(),_l=a("li"),GEe=a("strong"),Xbr=o("deit"),zbr=o(" \u2014 "),iY=a("a"),Qbr=o("DeiTForImageClassification"),Wbr=o(" or "),dY=a("a"),Ubr=o("DeiTForImageClassificationWithTeacher"),Hbr=o(" (DeiT model)"),Jbr=l(),r4=a("li"),OEe=a("strong"),Ybr=o("imagegpt"),Kbr=o(" \u2014 "),cY=a("a"),Zbr=o("ImageGPTForImageClassification"),e1r=o(" (ImageGPT model)"),o1r=l(),bl=a("li"),VEe=a("strong"),r1r=o("levit"),t1r=o(" \u2014 "),mY=a("a"),a1r=o("LevitForImageClassification"),n1r=o(" or "),fY=a("a"),s1r=o("LevitForImageClassificationWithTeacher"),l1r=o(" (LeViT model)"),i1r=l(),t4=a("li"),XEe=a("strong"),d1r=o("mobilevit"),c1r=o(" \u2014 "),gY=a("a"),m1r=o("MobileViTForImageClassification"),f1r=o(" (MobileViT model)"),g1r=l(),$t=a("li"),zEe=a("strong"),h1r=o("perceiver"),u1r=o(" \u2014 "),hY=a("a"),p1r=o("PerceiverForImageClassificationLearned"),_1r=o(" or "),uY=a("a"),b1r=o("PerceiverForImageClassificationFourier"),v1r=o(" or "),pY=a("a"),F1r=o("PerceiverForImageClassificationConvProcessing"),T1r=o(" (Perceiver model)"),M1r=l(),a4=a("li"),QEe=a("strong"),E1r=o("poolformer"),C1r=o(" \u2014 "),_Y=a("a"),w1r=o("PoolFormerForImageClassification"),A1r=o(" (PoolFormer model)"),L1r=l(),n4=a("li"),WEe=a("strong"),y1r=o("regnet"),x1r=o(" \u2014 "),bY=a("a"),$1r=o("RegNetForImageClassification"),k1r=o(" (RegNet model)"),S1r=l(),s4=a("li"),UEe=a("strong"),R1r=o("resnet"),P1r=o(" \u2014 "),vY=a("a"),B1r=o("ResNetForImageClassification"),I1r=o(" (ResNet model)"),N1r=l(),l4=a("li"),HEe=a("strong"),q1r=o("segformer"),j1r=o(" \u2014 "),FY=a("a"),D1r=o("SegformerForImageClassification"),G1r=o(" (SegFormer model)"),O1r=l(),i4=a("li"),JEe=a("strong"),V1r=o("swin"),X1r=o(" \u2014 "),TY=a("a"),z1r=o("SwinForImageClassification"),Q1r=o(" (Swin Transformer model)"),W1r=l(),d4=a("li"),YEe=a("strong"),U1r=o("swinv2"),H1r=o(" \u2014 "),MY=a("a"),J1r=o("Swinv2ForImageClassification"),Y1r=o(" (Swin Transformer V2 model)"),K1r=l(),c4=a("li"),KEe=a("strong"),Z1r=o("van"),evr=o(" \u2014 "),EY=a("a"),ovr=o("VanForImageClassification"),rvr=o(" (VAN model)"),tvr=l(),m4=a("li"),ZEe=a("strong"),avr=o("vit"),nvr=o(" \u2014 "),CY=a("a"),svr=o("ViTForImageClassification"),lvr=o(" (ViT model)"),ivr=l(),f4=a("p"),dvr=o("The model is set in evaluation mode by default using "),e4e=a("code"),cvr=o("model.eval()"),mvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o4e=a("code"),fvr=o("model.train()"),gvr=l(),F(g4.$$.fragment),pKe=l(),rc=a("h2"),h4=a("a"),r4e=a("span"),F(s$.$$.fragment),hvr=l(),t4e=a("span"),uvr=o("AutoModelForVideoClassification"),_Ke=l(),Wo=a("div"),F(l$.$$.fragment),pvr=l(),tc=a("p"),_vr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),wY=a("a"),bvr=o("from_pretrained()"),vvr=o(" class method or the "),AY=a("a"),Fvr=o("from_config()"),Tvr=o(` class
method.`),Mvr=l(),i$=a("p"),Evr=o("This class cannot be instantiated directly using "),a4e=a("code"),Cvr=o("__init__()"),wvr=o(" (throws an error)."),Avr=l(),kt=a("div"),F(d$.$$.fragment),Lvr=l(),n4e=a("p"),yvr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),xvr=l(),ac=a("p"),$vr=o(`Note:
Loading a model from its configuration file does `),s4e=a("strong"),kvr=o("not"),Svr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),Rvr=o("from_pretrained()"),Pvr=o(" to load the model weights."),Bvr=l(),F(u4.$$.fragment),Ivr=l(),go=a("div"),F(c$.$$.fragment),Nvr=l(),l4e=a("p"),qvr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),jvr=l(),cn=a("p"),Dvr=o("The model class to instantiate is selected based on the "),i4e=a("code"),Gvr=o("model_type"),Ovr=o(` property of the config object (either
passed as an argument or loaded from `),d4e=a("code"),Vvr=o("pretrained_model_name_or_path"),Xvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c4e=a("code"),zvr=o("pretrained_model_name_or_path"),Qvr=o(":"),Wvr=l(),m4e=a("ul"),p4=a("li"),f4e=a("strong"),Uvr=o("videomae"),Hvr=o(" \u2014 "),yY=a("a"),Jvr=o("VideoMAEForVideoClassification"),Yvr=o(" (VideoMAE model)"),Kvr=l(),_4=a("p"),Zvr=o("The model is set in evaluation mode by default using "),g4e=a("code"),eFr=o("model.eval()"),oFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h4e=a("code"),rFr=o("model.train()"),tFr=l(),F(b4.$$.fragment),bKe=l(),nc=a("h2"),v4=a("a"),u4e=a("span"),F(m$.$$.fragment),aFr=l(),p4e=a("span"),nFr=o("AutoModelForVision2Seq"),vKe=l(),Uo=a("div"),F(f$.$$.fragment),sFr=l(),sc=a("p"),lFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xY=a("a"),iFr=o("from_pretrained()"),dFr=o(" class method or the "),$Y=a("a"),cFr=o("from_config()"),mFr=o(` class
method.`),fFr=l(),g$=a("p"),gFr=o("This class cannot be instantiated directly using "),_4e=a("code"),hFr=o("__init__()"),uFr=o(" (throws an error)."),pFr=l(),St=a("div"),F(h$.$$.fragment),_Fr=l(),b4e=a("p"),bFr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),vFr=l(),lc=a("p"),FFr=o(`Note:
Loading a model from its configuration file does `),v4e=a("strong"),TFr=o("not"),MFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=a("a"),EFr=o("from_pretrained()"),CFr=o(" to load the model weights."),wFr=l(),F(F4.$$.fragment),AFr=l(),ho=a("div"),F(u$.$$.fragment),LFr=l(),F4e=a("p"),yFr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xFr=l(),mn=a("p"),$Fr=o("The model class to instantiate is selected based on the "),T4e=a("code"),kFr=o("model_type"),SFr=o(` property of the config object (either
passed as an argument or loaded from `),M4e=a("code"),RFr=o("pretrained_model_name_or_path"),PFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E4e=a("code"),BFr=o("pretrained_model_name_or_path"),IFr=o(":"),NFr=l(),C4e=a("ul"),T4=a("li"),w4e=a("strong"),qFr=o("vision-encoder-decoder"),jFr=o(" \u2014 "),SY=a("a"),DFr=o("VisionEncoderDecoderModel"),GFr=o(" (Vision Encoder decoder model)"),OFr=l(),M4=a("p"),VFr=o("The model is set in evaluation mode by default using "),A4e=a("code"),XFr=o("model.eval()"),zFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L4e=a("code"),QFr=o("model.train()"),WFr=l(),F(E4.$$.fragment),FKe=l(),ic=a("h2"),C4=a("a"),y4e=a("span"),F(p$.$$.fragment),UFr=l(),x4e=a("span"),HFr=o("AutoModelForVisualQuestionAnswering"),TKe=l(),Ho=a("div"),F(_$.$$.fragment),JFr=l(),dc=a("p"),YFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),RY=a("a"),KFr=o("from_pretrained()"),ZFr=o(" class method or the "),PY=a("a"),eTr=o("from_config()"),oTr=o(` class
method.`),rTr=l(),b$=a("p"),tTr=o("This class cannot be instantiated directly using "),$4e=a("code"),aTr=o("__init__()"),nTr=o(" (throws an error)."),sTr=l(),Rt=a("div"),F(v$.$$.fragment),lTr=l(),k4e=a("p"),iTr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),dTr=l(),cc=a("p"),cTr=o(`Note:
Loading a model from its configuration file does `),S4e=a("strong"),mTr=o("not"),fTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=a("a"),gTr=o("from_pretrained()"),hTr=o(" to load the model weights."),uTr=l(),F(w4.$$.fragment),pTr=l(),uo=a("div"),F(F$.$$.fragment),_Tr=l(),R4e=a("p"),bTr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),vTr=l(),fn=a("p"),FTr=o("The model class to instantiate is selected based on the "),P4e=a("code"),TTr=o("model_type"),MTr=o(` property of the config object (either
passed as an argument or loaded from `),B4e=a("code"),ETr=o("pretrained_model_name_or_path"),CTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=a("code"),wTr=o("pretrained_model_name_or_path"),ATr=o(":"),LTr=l(),N4e=a("ul"),A4=a("li"),q4e=a("strong"),yTr=o("vilt"),xTr=o(" \u2014 "),IY=a("a"),$Tr=o("ViltForQuestionAnswering"),kTr=o(" (ViLT model)"),STr=l(),L4=a("p"),RTr=o("The model is set in evaluation mode by default using "),j4e=a("code"),PTr=o("model.eval()"),BTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D4e=a("code"),ITr=o("model.train()"),NTr=l(),F(y4.$$.fragment),MKe=l(),mc=a("h2"),x4=a("a"),G4e=a("span"),F(T$.$$.fragment),qTr=l(),O4e=a("span"),jTr=o("AutoModelForAudioClassification"),EKe=l(),Jo=a("div"),F(M$.$$.fragment),DTr=l(),fc=a("p"),GTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),NY=a("a"),OTr=o("from_pretrained()"),VTr=o(" class method or the "),qY=a("a"),XTr=o("from_config()"),zTr=o(` class
method.`),QTr=l(),E$=a("p"),WTr=o("This class cannot be instantiated directly using "),V4e=a("code"),UTr=o("__init__()"),HTr=o(" (throws an error)."),JTr=l(),Pt=a("div"),F(C$.$$.fragment),YTr=l(),X4e=a("p"),KTr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),ZTr=l(),gc=a("p"),eMr=o(`Note:
Loading a model from its configuration file does `),z4e=a("strong"),oMr=o("not"),rMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=a("a"),tMr=o("from_pretrained()"),aMr=o(" to load the model weights."),nMr=l(),F($4.$$.fragment),sMr=l(),po=a("div"),F(w$.$$.fragment),lMr=l(),Q4e=a("p"),iMr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),dMr=l(),gn=a("p"),cMr=o("The model class to instantiate is selected based on the "),W4e=a("code"),mMr=o("model_type"),fMr=o(` property of the config object (either
passed as an argument or loaded from `),U4e=a("code"),gMr=o("pretrained_model_name_or_path"),hMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H4e=a("code"),uMr=o("pretrained_model_name_or_path"),pMr=o(":"),_Mr=l(),Pe=a("ul"),k4=a("li"),J4e=a("strong"),bMr=o("data2vec-audio"),vMr=o(" \u2014 "),DY=a("a"),FMr=o("Data2VecAudioForSequenceClassification"),TMr=o(" (Data2VecAudio model)"),MMr=l(),S4=a("li"),Y4e=a("strong"),EMr=o("hubert"),CMr=o(" \u2014 "),GY=a("a"),wMr=o("HubertForSequenceClassification"),AMr=o(" (Hubert model)"),LMr=l(),R4=a("li"),K4e=a("strong"),yMr=o("sew"),xMr=o(" \u2014 "),OY=a("a"),$Mr=o("SEWForSequenceClassification"),kMr=o(" (SEW model)"),SMr=l(),P4=a("li"),Z4e=a("strong"),RMr=o("sew-d"),PMr=o(" \u2014 "),VY=a("a"),BMr=o("SEWDForSequenceClassification"),IMr=o(" (SEW-D model)"),NMr=l(),B4=a("li"),eCe=a("strong"),qMr=o("unispeech"),jMr=o(" \u2014 "),XY=a("a"),DMr=o("UniSpeechForSequenceClassification"),GMr=o(" (UniSpeech model)"),OMr=l(),I4=a("li"),oCe=a("strong"),VMr=o("unispeech-sat"),XMr=o(" \u2014 "),zY=a("a"),zMr=o("UniSpeechSatForSequenceClassification"),QMr=o(" (UniSpeechSat model)"),WMr=l(),N4=a("li"),rCe=a("strong"),UMr=o("wav2vec2"),HMr=o(" \u2014 "),QY=a("a"),JMr=o("Wav2Vec2ForSequenceClassification"),YMr=o(" (Wav2Vec2 model)"),KMr=l(),q4=a("li"),tCe=a("strong"),ZMr=o("wav2vec2-conformer"),eEr=o(" \u2014 "),WY=a("a"),oEr=o("Wav2Vec2ConformerForSequenceClassification"),rEr=o(" (Wav2Vec2-Conformer model)"),tEr=l(),j4=a("li"),aCe=a("strong"),aEr=o("wavlm"),nEr=o(" \u2014 "),UY=a("a"),sEr=o("WavLMForSequenceClassification"),lEr=o(" (WavLM model)"),iEr=l(),D4=a("p"),dEr=o("The model is set in evaluation mode by default using "),nCe=a("code"),cEr=o("model.eval()"),mEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sCe=a("code"),fEr=o("model.train()"),gEr=l(),F(G4.$$.fragment),CKe=l(),hc=a("h2"),O4=a("a"),lCe=a("span"),F(A$.$$.fragment),hEr=l(),iCe=a("span"),uEr=o("AutoModelForAudioFrameClassification"),wKe=l(),Yo=a("div"),F(L$.$$.fragment),pEr=l(),uc=a("p"),_Er=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),HY=a("a"),bEr=o("from_pretrained()"),vEr=o(" class method or the "),JY=a("a"),FEr=o("from_config()"),TEr=o(` class
method.`),MEr=l(),y$=a("p"),EEr=o("This class cannot be instantiated directly using "),dCe=a("code"),CEr=o("__init__()"),wEr=o(" (throws an error)."),AEr=l(),Bt=a("div"),F(x$.$$.fragment),LEr=l(),cCe=a("p"),yEr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xEr=l(),pc=a("p"),$Er=o(`Note:
Loading a model from its configuration file does `),mCe=a("strong"),kEr=o("not"),SEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=a("a"),REr=o("from_pretrained()"),PEr=o(" to load the model weights."),BEr=l(),F(V4.$$.fragment),IEr=l(),_o=a("div"),F($$.$$.fragment),NEr=l(),fCe=a("p"),qEr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jEr=l(),hn=a("p"),DEr=o("The model class to instantiate is selected based on the "),gCe=a("code"),GEr=o("model_type"),OEr=o(` property of the config object (either
passed as an argument or loaded from `),hCe=a("code"),VEr=o("pretrained_model_name_or_path"),XEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=a("code"),zEr=o("pretrained_model_name_or_path"),QEr=o(":"),WEr=l(),mt=a("ul"),X4=a("li"),pCe=a("strong"),UEr=o("data2vec-audio"),HEr=o(" \u2014 "),KY=a("a"),JEr=o("Data2VecAudioForAudioFrameClassification"),YEr=o(" (Data2VecAudio model)"),KEr=l(),z4=a("li"),_Ce=a("strong"),ZEr=o("unispeech-sat"),e4r=o(" \u2014 "),ZY=a("a"),o4r=o("UniSpeechSatForAudioFrameClassification"),r4r=o(" (UniSpeechSat model)"),t4r=l(),Q4=a("li"),bCe=a("strong"),a4r=o("wav2vec2"),n4r=o(" \u2014 "),eK=a("a"),s4r=o("Wav2Vec2ForAudioFrameClassification"),l4r=o(" (Wav2Vec2 model)"),i4r=l(),W4=a("li"),vCe=a("strong"),d4r=o("wav2vec2-conformer"),c4r=o(" \u2014 "),oK=a("a"),m4r=o("Wav2Vec2ConformerForAudioFrameClassification"),f4r=o(" (Wav2Vec2-Conformer model)"),g4r=l(),U4=a("li"),FCe=a("strong"),h4r=o("wavlm"),u4r=o(" \u2014 "),rK=a("a"),p4r=o("WavLMForAudioFrameClassification"),_4r=o(" (WavLM model)"),b4r=l(),H4=a("p"),v4r=o("The model is set in evaluation mode by default using "),TCe=a("code"),F4r=o("model.eval()"),T4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MCe=a("code"),M4r=o("model.train()"),E4r=l(),F(J4.$$.fragment),AKe=l(),_c=a("h2"),Y4=a("a"),ECe=a("span"),F(k$.$$.fragment),C4r=l(),CCe=a("span"),w4r=o("AutoModelForCTC"),LKe=l(),Ko=a("div"),F(S$.$$.fragment),A4r=l(),bc=a("p"),L4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),tK=a("a"),y4r=o("from_pretrained()"),x4r=o(" class method or the "),aK=a("a"),$4r=o("from_config()"),k4r=o(` class
method.`),S4r=l(),R$=a("p"),R4r=o("This class cannot be instantiated directly using "),wCe=a("code"),P4r=o("__init__()"),B4r=o(" (throws an error)."),I4r=l(),It=a("div"),F(P$.$$.fragment),N4r=l(),ACe=a("p"),q4r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),j4r=l(),vc=a("p"),D4r=o(`Note:
Loading a model from its configuration file does `),LCe=a("strong"),G4r=o("not"),O4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),V4r=o("from_pretrained()"),X4r=o(" to load the model weights."),z4r=l(),F(K4.$$.fragment),Q4r=l(),bo=a("div"),F(B$.$$.fragment),W4r=l(),yCe=a("p"),U4r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),H4r=l(),un=a("p"),J4r=o("The model class to instantiate is selected based on the "),xCe=a("code"),Y4r=o("model_type"),K4r=o(` property of the config object (either
passed as an argument or loaded from `),$Ce=a("code"),Z4r=o("pretrained_model_name_or_path"),eCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kCe=a("code"),oCr=o("pretrained_model_name_or_path"),rCr=o(":"),tCr=l(),Le=a("ul"),Z4=a("li"),SCe=a("strong"),aCr=o("data2vec-audio"),nCr=o(" \u2014 "),sK=a("a"),sCr=o("Data2VecAudioForCTC"),lCr=o(" (Data2VecAudio model)"),iCr=l(),eC=a("li"),RCe=a("strong"),dCr=o("hubert"),cCr=o(" \u2014 "),lK=a("a"),mCr=o("HubertForCTC"),fCr=o(" (Hubert model)"),gCr=l(),oC=a("li"),PCe=a("strong"),hCr=o("mctct"),uCr=o(" \u2014 "),iK=a("a"),pCr=o("MCTCTForCTC"),_Cr=o(" (M-CTC-T model)"),bCr=l(),rC=a("li"),BCe=a("strong"),vCr=o("sew"),FCr=o(" \u2014 "),dK=a("a"),TCr=o("SEWForCTC"),MCr=o(" (SEW model)"),ECr=l(),tC=a("li"),ICe=a("strong"),CCr=o("sew-d"),wCr=o(" \u2014 "),cK=a("a"),ACr=o("SEWDForCTC"),LCr=o(" (SEW-D model)"),yCr=l(),aC=a("li"),NCe=a("strong"),xCr=o("unispeech"),$Cr=o(" \u2014 "),mK=a("a"),kCr=o("UniSpeechForCTC"),SCr=o(" (UniSpeech model)"),RCr=l(),nC=a("li"),qCe=a("strong"),PCr=o("unispeech-sat"),BCr=o(" \u2014 "),fK=a("a"),ICr=o("UniSpeechSatForCTC"),NCr=o(" (UniSpeechSat model)"),qCr=l(),sC=a("li"),jCe=a("strong"),jCr=o("wav2vec2"),DCr=o(" \u2014 "),gK=a("a"),GCr=o("Wav2Vec2ForCTC"),OCr=o(" (Wav2Vec2 model)"),VCr=l(),lC=a("li"),DCe=a("strong"),XCr=o("wav2vec2-conformer"),zCr=o(" \u2014 "),hK=a("a"),QCr=o("Wav2Vec2ConformerForCTC"),WCr=o(" (Wav2Vec2-Conformer model)"),UCr=l(),iC=a("li"),GCe=a("strong"),HCr=o("wavlm"),JCr=o(" \u2014 "),uK=a("a"),YCr=o("WavLMForCTC"),KCr=o(" (WavLM model)"),ZCr=l(),dC=a("p"),e3r=o("The model is set in evaluation mode by default using "),OCe=a("code"),o3r=o("model.eval()"),r3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VCe=a("code"),t3r=o("model.train()"),a3r=l(),F(cC.$$.fragment),yKe=l(),Fc=a("h2"),mC=a("a"),XCe=a("span"),F(I$.$$.fragment),n3r=l(),zCe=a("span"),s3r=o("AutoModelForSpeechSeq2Seq"),xKe=l(),Zo=a("div"),F(N$.$$.fragment),l3r=l(),Tc=a("p"),i3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pK=a("a"),d3r=o("from_pretrained()"),c3r=o(" class method or the "),_K=a("a"),m3r=o("from_config()"),f3r=o(` class
method.`),g3r=l(),q$=a("p"),h3r=o("This class cannot be instantiated directly using "),QCe=a("code"),u3r=o("__init__()"),p3r=o(" (throws an error)."),_3r=l(),Nt=a("div"),F(j$.$$.fragment),b3r=l(),WCe=a("p"),v3r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),F3r=l(),Mc=a("p"),T3r=o(`Note:
Loading a model from its configuration file does `),UCe=a("strong"),M3r=o("not"),E3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=a("a"),C3r=o("from_pretrained()"),w3r=o(" to load the model weights."),A3r=l(),F(fC.$$.fragment),L3r=l(),vo=a("div"),F(D$.$$.fragment),y3r=l(),HCe=a("p"),x3r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$3r=l(),pn=a("p"),k3r=o("The model class to instantiate is selected based on the "),JCe=a("code"),S3r=o("model_type"),R3r=o(` property of the config object (either
passed as an argument or loaded from `),YCe=a("code"),P3r=o("pretrained_model_name_or_path"),B3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=a("code"),I3r=o("pretrained_model_name_or_path"),N3r=o(":"),q3r=l(),G$=a("ul"),gC=a("li"),ZCe=a("strong"),j3r=o("speech-encoder-decoder"),D3r=o(" \u2014 "),vK=a("a"),G3r=o("SpeechEncoderDecoderModel"),O3r=o(" (Speech Encoder decoder model)"),V3r=l(),hC=a("li"),e3e=a("strong"),X3r=o("speech_to_text"),z3r=o(" \u2014 "),FK=a("a"),Q3r=o("Speech2TextForConditionalGeneration"),W3r=o(" (Speech2Text model)"),U3r=l(),uC=a("p"),H3r=o("The model is set in evaluation mode by default using "),o3e=a("code"),J3r=o("model.eval()"),Y3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r3e=a("code"),K3r=o("model.train()"),Z3r=l(),F(pC.$$.fragment),$Ke=l(),Ec=a("h2"),_C=a("a"),t3e=a("span"),F(O$.$$.fragment),e5r=l(),a3e=a("span"),o5r=o("AutoModelForAudioXVector"),kKe=l(),er=a("div"),F(V$.$$.fragment),r5r=l(),Cc=a("p"),t5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),TK=a("a"),a5r=o("from_pretrained()"),n5r=o(" class method or the "),MK=a("a"),s5r=o("from_config()"),l5r=o(` class
method.`),i5r=l(),X$=a("p"),d5r=o("This class cannot be instantiated directly using "),n3e=a("code"),c5r=o("__init__()"),m5r=o(" (throws an error)."),f5r=l(),qt=a("div"),F(z$.$$.fragment),g5r=l(),s3e=a("p"),h5r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),u5r=l(),wc=a("p"),p5r=o(`Note:
Loading a model from its configuration file does `),l3e=a("strong"),_5r=o("not"),b5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=a("a"),v5r=o("from_pretrained()"),F5r=o(" to load the model weights."),T5r=l(),F(bC.$$.fragment),M5r=l(),Fo=a("div"),F(Q$.$$.fragment),E5r=l(),i3e=a("p"),C5r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),w5r=l(),_n=a("p"),A5r=o("The model class to instantiate is selected based on the "),d3e=a("code"),L5r=o("model_type"),y5r=o(` property of the config object (either
passed as an argument or loaded from `),c3e=a("code"),x5r=o("pretrained_model_name_or_path"),$5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m3e=a("code"),k5r=o("pretrained_model_name_or_path"),S5r=o(":"),R5r=l(),ft=a("ul"),vC=a("li"),f3e=a("strong"),P5r=o("data2vec-audio"),B5r=o(" \u2014 "),CK=a("a"),I5r=o("Data2VecAudioForXVector"),N5r=o(" (Data2VecAudio model)"),q5r=l(),FC=a("li"),g3e=a("strong"),j5r=o("unispeech-sat"),D5r=o(" \u2014 "),wK=a("a"),G5r=o("UniSpeechSatForXVector"),O5r=o(" (UniSpeechSat model)"),V5r=l(),TC=a("li"),h3e=a("strong"),X5r=o("wav2vec2"),z5r=o(" \u2014 "),AK=a("a"),Q5r=o("Wav2Vec2ForXVector"),W5r=o(" (Wav2Vec2 model)"),U5r=l(),MC=a("li"),u3e=a("strong"),H5r=o("wav2vec2-conformer"),J5r=o(" \u2014 "),LK=a("a"),Y5r=o("Wav2Vec2ConformerForXVector"),K5r=o(" (Wav2Vec2-Conformer model)"),Z5r=l(),EC=a("li"),p3e=a("strong"),e0r=o("wavlm"),o0r=o(" \u2014 "),yK=a("a"),r0r=o("WavLMForXVector"),t0r=o(" (WavLM model)"),a0r=l(),CC=a("p"),n0r=o("The model is set in evaluation mode by default using "),_3e=a("code"),s0r=o("model.eval()"),l0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b3e=a("code"),i0r=o("model.train()"),d0r=l(),F(wC.$$.fragment),SKe=l(),Ac=a("h2"),AC=a("a"),v3e=a("span"),F(W$.$$.fragment),c0r=l(),F3e=a("span"),m0r=o("AutoModelForMaskedImageModeling"),RKe=l(),or=a("div"),F(U$.$$.fragment),f0r=l(),Lc=a("p"),g0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xK=a("a"),h0r=o("from_pretrained()"),u0r=o(" class method or the "),$K=a("a"),p0r=o("from_config()"),_0r=o(` class
method.`),b0r=l(),H$=a("p"),v0r=o("This class cannot be instantiated directly using "),T3e=a("code"),F0r=o("__init__()"),T0r=o(" (throws an error)."),M0r=l(),jt=a("div"),F(J$.$$.fragment),E0r=l(),M3e=a("p"),C0r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),w0r=l(),yc=a("p"),A0r=o(`Note:
Loading a model from its configuration file does `),E3e=a("strong"),L0r=o("not"),y0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),x0r=o("from_pretrained()"),$0r=o(" to load the model weights."),k0r=l(),F(LC.$$.fragment),S0r=l(),To=a("div"),F(Y$.$$.fragment),R0r=l(),C3e=a("p"),P0r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B0r=l(),bn=a("p"),I0r=o("The model class to instantiate is selected based on the "),w3e=a("code"),N0r=o("model_type"),q0r=o(` property of the config object (either
passed as an argument or loaded from `),A3e=a("code"),j0r=o("pretrained_model_name_or_path"),D0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L3e=a("code"),G0r=o("pretrained_model_name_or_path"),O0r=o(":"),V0r=l(),vn=a("ul"),yC=a("li"),y3e=a("strong"),X0r=o("deit"),z0r=o(" \u2014 "),SK=a("a"),Q0r=o("DeiTForMaskedImageModeling"),W0r=o(" (DeiT model)"),U0r=l(),xC=a("li"),x3e=a("strong"),H0r=o("swin"),J0r=o(" \u2014 "),RK=a("a"),Y0r=o("SwinForMaskedImageModeling"),K0r=o(" (Swin Transformer model)"),Z0r=l(),$C=a("li"),$3e=a("strong"),ewr=o("swinv2"),owr=o(" \u2014 "),PK=a("a"),rwr=o("Swinv2ForMaskedImageModeling"),twr=o(" (Swin Transformer V2 model)"),awr=l(),kC=a("li"),k3e=a("strong"),nwr=o("vit"),swr=o(" \u2014 "),BK=a("a"),lwr=o("ViTForMaskedImageModeling"),iwr=o(" (ViT model)"),dwr=l(),SC=a("p"),cwr=o("The model is set in evaluation mode by default using "),S3e=a("code"),mwr=o("model.eval()"),fwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R3e=a("code"),gwr=o("model.train()"),hwr=l(),F(RC.$$.fragment),PKe=l(),xc=a("h2"),PC=a("a"),P3e=a("span"),F(K$.$$.fragment),uwr=l(),B3e=a("span"),pwr=o("AutoModelForObjectDetection"),BKe=l(),rr=a("div"),F(Z$.$$.fragment),_wr=l(),$c=a("p"),bwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IK=a("a"),vwr=o("from_pretrained()"),Fwr=o(" class method or the "),NK=a("a"),Twr=o("from_config()"),Mwr=o(` class
method.`),Ewr=l(),ek=a("p"),Cwr=o("This class cannot be instantiated directly using "),I3e=a("code"),wwr=o("__init__()"),Awr=o(" (throws an error)."),Lwr=l(),Dt=a("div"),F(ok.$$.fragment),ywr=l(),N3e=a("p"),xwr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),$wr=l(),kc=a("p"),kwr=o(`Note:
Loading a model from its configuration file does `),q3e=a("strong"),Swr=o("not"),Rwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=a("a"),Pwr=o("from_pretrained()"),Bwr=o(" to load the model weights."),Iwr=l(),F(BC.$$.fragment),Nwr=l(),Mo=a("div"),F(rk.$$.fragment),qwr=l(),j3e=a("p"),jwr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Dwr=l(),Fn=a("p"),Gwr=o("The model class to instantiate is selected based on the "),D3e=a("code"),Owr=o("model_type"),Vwr=o(` property of the config object (either
passed as an argument or loaded from `),G3e=a("code"),Xwr=o("pretrained_model_name_or_path"),zwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O3e=a("code"),Qwr=o("pretrained_model_name_or_path"),Wwr=o(":"),Uwr=l(),tk=a("ul"),IC=a("li"),V3e=a("strong"),Hwr=o("detr"),Jwr=o(" \u2014 "),jK=a("a"),Ywr=o("DetrForObjectDetection"),Kwr=o(" (DETR model)"),Zwr=l(),NC=a("li"),X3e=a("strong"),eAr=o("yolos"),oAr=o(" \u2014 "),DK=a("a"),rAr=o("YolosForObjectDetection"),tAr=o(" (YOLOS model)"),aAr=l(),qC=a("p"),nAr=o("The model is set in evaluation mode by default using "),z3e=a("code"),sAr=o("model.eval()"),lAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q3e=a("code"),iAr=o("model.train()"),dAr=l(),F(jC.$$.fragment),IKe=l(),Sc=a("h2"),DC=a("a"),W3e=a("span"),F(ak.$$.fragment),cAr=l(),U3e=a("span"),mAr=o("AutoModelForImageSegmentation"),NKe=l(),tr=a("div"),F(nk.$$.fragment),fAr=l(),Rc=a("p"),gAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GK=a("a"),hAr=o("from_pretrained()"),uAr=o(" class method or the "),OK=a("a"),pAr=o("from_config()"),_Ar=o(` class
method.`),bAr=l(),sk=a("p"),vAr=o("This class cannot be instantiated directly using "),H3e=a("code"),FAr=o("__init__()"),TAr=o(" (throws an error)."),MAr=l(),Gt=a("div"),F(lk.$$.fragment),EAr=l(),J3e=a("p"),CAr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),wAr=l(),Pc=a("p"),AAr=o(`Note:
Loading a model from its configuration file does `),Y3e=a("strong"),LAr=o("not"),yAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=a("a"),xAr=o("from_pretrained()"),$Ar=o(" to load the model weights."),kAr=l(),F(GC.$$.fragment),SAr=l(),Eo=a("div"),F(ik.$$.fragment),RAr=l(),K3e=a("p"),PAr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),BAr=l(),Tn=a("p"),IAr=o("The model class to instantiate is selected based on the "),Z3e=a("code"),NAr=o("model_type"),qAr=o(` property of the config object (either
passed as an argument or loaded from `),e5e=a("code"),jAr=o("pretrained_model_name_or_path"),DAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o5e=a("code"),GAr=o("pretrained_model_name_or_path"),OAr=o(":"),VAr=l(),r5e=a("ul"),OC=a("li"),t5e=a("strong"),XAr=o("detr"),zAr=o(" \u2014 "),XK=a("a"),QAr=o("DetrForSegmentation"),WAr=o(" (DETR model)"),UAr=l(),VC=a("p"),HAr=o("The model is set in evaluation mode by default using "),a5e=a("code"),JAr=o("model.eval()"),YAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n5e=a("code"),KAr=o("model.train()"),ZAr=l(),F(XC.$$.fragment),qKe=l(),Bc=a("h2"),zC=a("a"),s5e=a("span"),F(dk.$$.fragment),e6r=l(),l5e=a("span"),o6r=o("AutoModelForSemanticSegmentation"),jKe=l(),ar=a("div"),F(ck.$$.fragment),r6r=l(),Ic=a("p"),t6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zK=a("a"),a6r=o("from_pretrained()"),n6r=o(" class method or the "),QK=a("a"),s6r=o("from_config()"),l6r=o(` class
method.`),i6r=l(),mk=a("p"),d6r=o("This class cannot be instantiated directly using "),i5e=a("code"),c6r=o("__init__()"),m6r=o(" (throws an error)."),f6r=l(),Ot=a("div"),F(fk.$$.fragment),g6r=l(),d5e=a("p"),h6r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),u6r=l(),Nc=a("p"),p6r=o(`Note:
Loading a model from its configuration file does `),c5e=a("strong"),_6r=o("not"),b6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WK=a("a"),v6r=o("from_pretrained()"),F6r=o(" to load the model weights."),T6r=l(),F(QC.$$.fragment),M6r=l(),Co=a("div"),F(gk.$$.fragment),E6r=l(),m5e=a("p"),C6r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),w6r=l(),Mn=a("p"),A6r=o("The model class to instantiate is selected based on the "),f5e=a("code"),L6r=o("model_type"),y6r=o(` property of the config object (either
passed as an argument or loaded from `),g5e=a("code"),x6r=o("pretrained_model_name_or_path"),$6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h5e=a("code"),k6r=o("pretrained_model_name_or_path"),S6r=o(":"),R6r=l(),gt=a("ul"),WC=a("li"),u5e=a("strong"),P6r=o("beit"),B6r=o(" \u2014 "),UK=a("a"),I6r=o("BeitForSemanticSegmentation"),N6r=o(" (BEiT model)"),q6r=l(),UC=a("li"),p5e=a("strong"),j6r=o("data2vec-vision"),D6r=o(" \u2014 "),HK=a("a"),G6r=o("Data2VecVisionForSemanticSegmentation"),O6r=o(" (Data2VecVision model)"),V6r=l(),HC=a("li"),_5e=a("strong"),X6r=o("dpt"),z6r=o(" \u2014 "),JK=a("a"),Q6r=o("DPTForSemanticSegmentation"),W6r=o(" (DPT model)"),U6r=l(),JC=a("li"),b5e=a("strong"),H6r=o("mobilevit"),J6r=o(" \u2014 "),YK=a("a"),Y6r=o("MobileViTForSemanticSegmentation"),K6r=o(" (MobileViT model)"),Z6r=l(),YC=a("li"),v5e=a("strong"),e7r=o("segformer"),o7r=o(" \u2014 "),KK=a("a"),r7r=o("SegformerForSemanticSegmentation"),t7r=o(" (SegFormer model)"),a7r=l(),KC=a("p"),n7r=o("The model is set in evaluation mode by default using "),F5e=a("code"),s7r=o("model.eval()"),l7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T5e=a("code"),i7r=o("model.train()"),d7r=l(),F(ZC.$$.fragment),DKe=l(),qc=a("h2"),e3=a("a"),M5e=a("span"),F(hk.$$.fragment),c7r=l(),E5e=a("span"),m7r=o("AutoModelForInstanceSegmentation"),GKe=l(),nr=a("div"),F(uk.$$.fragment),f7r=l(),jc=a("p"),g7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),ZK=a("a"),h7r=o("from_pretrained()"),u7r=o(" class method or the "),eZ=a("a"),p7r=o("from_config()"),_7r=o(` class
method.`),b7r=l(),pk=a("p"),v7r=o("This class cannot be instantiated directly using "),C5e=a("code"),F7r=o("__init__()"),T7r=o(" (throws an error)."),M7r=l(),Vt=a("div"),F(_k.$$.fragment),E7r=l(),w5e=a("p"),C7r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),w7r=l(),Dc=a("p"),A7r=o(`Note:
Loading a model from its configuration file does `),A5e=a("strong"),L7r=o("not"),y7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),x7r=o("from_pretrained()"),$7r=o(" to load the model weights."),k7r=l(),F(o3.$$.fragment),S7r=l(),wo=a("div"),F(bk.$$.fragment),R7r=l(),L5e=a("p"),P7r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),B7r=l(),En=a("p"),I7r=o("The model class to instantiate is selected based on the "),y5e=a("code"),N7r=o("model_type"),q7r=o(` property of the config object (either
passed as an argument or loaded from `),x5e=a("code"),j7r=o("pretrained_model_name_or_path"),D7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$5e=a("code"),G7r=o("pretrained_model_name_or_path"),O7r=o(":"),V7r=l(),k5e=a("ul"),r3=a("li"),S5e=a("strong"),X7r=o("maskformer"),z7r=o(" \u2014 "),rZ=a("a"),Q7r=o("MaskFormerForInstanceSegmentation"),W7r=o(" (MaskFormer model)"),U7r=l(),t3=a("p"),H7r=o("The model is set in evaluation mode by default using "),R5e=a("code"),J7r=o("model.eval()"),Y7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=a("code"),K7r=o("model.train()"),Z7r=l(),F(a3.$$.fragment),OKe=l(),Gc=a("h2"),n3=a("a"),B5e=a("span"),F(vk.$$.fragment),eLr=l(),I5e=a("span"),oLr=o("TFAutoModel"),VKe=l(),sr=a("div"),F(Fk.$$.fragment),rLr=l(),Oc=a("p"),tLr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tZ=a("a"),aLr=o("from_pretrained()"),nLr=o(" class method or the "),aZ=a("a"),sLr=o("from_config()"),lLr=o(` class
method.`),iLr=l(),Tk=a("p"),dLr=o("This class cannot be instantiated directly using "),N5e=a("code"),cLr=o("__init__()"),mLr=o(" (throws an error)."),fLr=l(),Xt=a("div"),F(Mk.$$.fragment),gLr=l(),q5e=a("p"),hLr=o("Instantiates one of the base model classes of the library from a configuration."),uLr=l(),Vc=a("p"),pLr=o(`Note:
Loading a model from its configuration file does `),j5e=a("strong"),_Lr=o("not"),bLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=a("a"),vLr=o("from_pretrained()"),FLr=o(" to load the model weights."),TLr=l(),F(s3.$$.fragment),MLr=l(),Ir=a("div"),F(Ek.$$.fragment),ELr=l(),D5e=a("p"),CLr=o("Instantiate one of the base model classes of the library from a pretrained model."),wLr=l(),Cn=a("p"),ALr=o("The model class to instantiate is selected based on the "),G5e=a("code"),LLr=o("model_type"),yLr=o(` property of the config object (either
passed as an argument or loaded from `),O5e=a("code"),xLr=o("pretrained_model_name_or_path"),$Lr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=a("code"),kLr=o("pretrained_model_name_or_path"),SLr=o(":"),RLr=l(),N=a("ul"),l3=a("li"),X5e=a("strong"),PLr=o("albert"),BLr=o(" \u2014 "),sZ=a("a"),ILr=o("TFAlbertModel"),NLr=o(" (ALBERT model)"),qLr=l(),i3=a("li"),z5e=a("strong"),jLr=o("bart"),DLr=o(" \u2014 "),lZ=a("a"),GLr=o("TFBartModel"),OLr=o(" (BART model)"),VLr=l(),d3=a("li"),Q5e=a("strong"),XLr=o("bert"),zLr=o(" \u2014 "),iZ=a("a"),QLr=o("TFBertModel"),WLr=o(" (BERT model)"),ULr=l(),c3=a("li"),W5e=a("strong"),HLr=o("blenderbot"),JLr=o(" \u2014 "),dZ=a("a"),YLr=o("TFBlenderbotModel"),KLr=o(" (Blenderbot model)"),ZLr=l(),m3=a("li"),U5e=a("strong"),eyr=o("blenderbot-small"),oyr=o(" \u2014 "),cZ=a("a"),ryr=o("TFBlenderbotSmallModel"),tyr=o(" (BlenderbotSmall model)"),ayr=l(),f3=a("li"),H5e=a("strong"),nyr=o("camembert"),syr=o(" \u2014 "),mZ=a("a"),lyr=o("TFCamembertModel"),iyr=o(" (CamemBERT model)"),dyr=l(),g3=a("li"),J5e=a("strong"),cyr=o("clip"),myr=o(" \u2014 "),fZ=a("a"),fyr=o("TFCLIPModel"),gyr=o(" (CLIP model)"),hyr=l(),h3=a("li"),Y5e=a("strong"),uyr=o("convbert"),pyr=o(" \u2014 "),gZ=a("a"),_yr=o("TFConvBertModel"),byr=o(" (ConvBERT model)"),vyr=l(),u3=a("li"),K5e=a("strong"),Fyr=o("convnext"),Tyr=o(" \u2014 "),hZ=a("a"),Myr=o("TFConvNextModel"),Eyr=o(" (ConvNeXT model)"),Cyr=l(),p3=a("li"),Z5e=a("strong"),wyr=o("ctrl"),Ayr=o(" \u2014 "),uZ=a("a"),Lyr=o("TFCTRLModel"),yyr=o(" (CTRL model)"),xyr=l(),_3=a("li"),e0e=a("strong"),$yr=o("data2vec-vision"),kyr=o(" \u2014 "),pZ=a("a"),Syr=o("TFData2VecVisionModel"),Ryr=o(" (Data2VecVision model)"),Pyr=l(),b3=a("li"),o0e=a("strong"),Byr=o("deberta"),Iyr=o(" \u2014 "),_Z=a("a"),Nyr=o("TFDebertaModel"),qyr=o(" (DeBERTa model)"),jyr=l(),v3=a("li"),r0e=a("strong"),Dyr=o("deberta-v2"),Gyr=o(" \u2014 "),bZ=a("a"),Oyr=o("TFDebertaV2Model"),Vyr=o(" (DeBERTa-v2 model)"),Xyr=l(),F3=a("li"),t0e=a("strong"),zyr=o("deit"),Qyr=o(" \u2014 "),vZ=a("a"),Wyr=o("TFDeiTModel"),Uyr=o(" (DeiT model)"),Hyr=l(),T3=a("li"),a0e=a("strong"),Jyr=o("distilbert"),Yyr=o(" \u2014 "),FZ=a("a"),Kyr=o("TFDistilBertModel"),Zyr=o(" (DistilBERT model)"),e8r=l(),M3=a("li"),n0e=a("strong"),o8r=o("dpr"),r8r=o(" \u2014 "),TZ=a("a"),t8r=o("TFDPRQuestionEncoder"),a8r=o(" (DPR model)"),n8r=l(),E3=a("li"),s0e=a("strong"),s8r=o("electra"),l8r=o(" \u2014 "),MZ=a("a"),i8r=o("TFElectraModel"),d8r=o(" (ELECTRA model)"),c8r=l(),C3=a("li"),l0e=a("strong"),m8r=o("flaubert"),f8r=o(" \u2014 "),EZ=a("a"),g8r=o("TFFlaubertModel"),h8r=o(" (FlauBERT model)"),u8r=l(),vl=a("li"),i0e=a("strong"),p8r=o("funnel"),_8r=o(" \u2014 "),CZ=a("a"),b8r=o("TFFunnelModel"),v8r=o(" or "),wZ=a("a"),F8r=o("TFFunnelBaseModel"),T8r=o(" (Funnel Transformer model)"),M8r=l(),w3=a("li"),d0e=a("strong"),E8r=o("gpt2"),C8r=o(" \u2014 "),AZ=a("a"),w8r=o("TFGPT2Model"),A8r=o(" (OpenAI GPT-2 model)"),L8r=l(),A3=a("li"),c0e=a("strong"),y8r=o("gptj"),x8r=o(" \u2014 "),LZ=a("a"),$8r=o("TFGPTJModel"),k8r=o(" (GPT-J model)"),S8r=l(),L3=a("li"),m0e=a("strong"),R8r=o("hubert"),P8r=o(" \u2014 "),yZ=a("a"),B8r=o("TFHubertModel"),I8r=o(" (Hubert model)"),N8r=l(),y3=a("li"),f0e=a("strong"),q8r=o("layoutlm"),j8r=o(" \u2014 "),xZ=a("a"),D8r=o("TFLayoutLMModel"),G8r=o(" (LayoutLM model)"),O8r=l(),x3=a("li"),g0e=a("strong"),V8r=o("layoutlmv3"),X8r=o(" \u2014 "),$Z=a("a"),z8r=o("TFLayoutLMv3Model"),Q8r=o(" (LayoutLMv3 model)"),W8r=l(),$3=a("li"),h0e=a("strong"),U8r=o("led"),H8r=o(" \u2014 "),kZ=a("a"),J8r=o("TFLEDModel"),Y8r=o(" (LED model)"),K8r=l(),k3=a("li"),u0e=a("strong"),Z8r=o("longformer"),e9r=o(" \u2014 "),SZ=a("a"),o9r=o("TFLongformerModel"),r9r=o(" (Longformer model)"),t9r=l(),S3=a("li"),p0e=a("strong"),a9r=o("lxmert"),n9r=o(" \u2014 "),RZ=a("a"),s9r=o("TFLxmertModel"),l9r=o(" (LXMERT model)"),i9r=l(),R3=a("li"),_0e=a("strong"),d9r=o("marian"),c9r=o(" \u2014 "),PZ=a("a"),m9r=o("TFMarianModel"),f9r=o(" (Marian model)"),g9r=l(),P3=a("li"),b0e=a("strong"),h9r=o("mbart"),u9r=o(" \u2014 "),BZ=a("a"),p9r=o("TFMBartModel"),_9r=o(" (mBART model)"),b9r=l(),B3=a("li"),v0e=a("strong"),v9r=o("mobilebert"),F9r=o(" \u2014 "),IZ=a("a"),T9r=o("TFMobileBertModel"),M9r=o(" (MobileBERT model)"),E9r=l(),I3=a("li"),F0e=a("strong"),C9r=o("mobilevit"),w9r=o(" \u2014 "),NZ=a("a"),A9r=o("TFMobileViTModel"),L9r=o(" (MobileViT model)"),y9r=l(),N3=a("li"),T0e=a("strong"),x9r=o("mpnet"),$9r=o(" \u2014 "),qZ=a("a"),k9r=o("TFMPNetModel"),S9r=o(" (MPNet model)"),R9r=l(),q3=a("li"),M0e=a("strong"),P9r=o("mt5"),B9r=o(" \u2014 "),jZ=a("a"),I9r=o("TFMT5Model"),N9r=o(" (MT5 model)"),q9r=l(),j3=a("li"),E0e=a("strong"),j9r=o("openai-gpt"),D9r=o(" \u2014 "),DZ=a("a"),G9r=o("TFOpenAIGPTModel"),O9r=o(" (OpenAI GPT model)"),V9r=l(),D3=a("li"),C0e=a("strong"),X9r=o("opt"),z9r=o(" \u2014 "),GZ=a("a"),Q9r=o("TFOPTModel"),W9r=o(" (OPT model)"),U9r=l(),G3=a("li"),w0e=a("strong"),H9r=o("pegasus"),J9r=o(" \u2014 "),OZ=a("a"),Y9r=o("TFPegasusModel"),K9r=o(" (Pegasus model)"),Z9r=l(),O3=a("li"),A0e=a("strong"),exr=o("regnet"),oxr=o(" \u2014 "),VZ=a("a"),rxr=o("TFRegNetModel"),txr=o(" (RegNet model)"),axr=l(),V3=a("li"),L0e=a("strong"),nxr=o("rembert"),sxr=o(" \u2014 "),XZ=a("a"),lxr=o("TFRemBertModel"),ixr=o(" (RemBERT model)"),dxr=l(),X3=a("li"),y0e=a("strong"),cxr=o("resnet"),mxr=o(" \u2014 "),zZ=a("a"),fxr=o("TFResNetModel"),gxr=o(" (ResNet model)"),hxr=l(),z3=a("li"),x0e=a("strong"),uxr=o("roberta"),pxr=o(" \u2014 "),QZ=a("a"),_xr=o("TFRobertaModel"),bxr=o(" (RoBERTa model)"),vxr=l(),Q3=a("li"),$0e=a("strong"),Fxr=o("roformer"),Txr=o(" \u2014 "),WZ=a("a"),Mxr=o("TFRoFormerModel"),Exr=o(" (RoFormer model)"),Cxr=l(),W3=a("li"),k0e=a("strong"),wxr=o("segformer"),Axr=o(" \u2014 "),UZ=a("a"),Lxr=o("TFSegformerModel"),yxr=o(" (SegFormer model)"),xxr=l(),U3=a("li"),S0e=a("strong"),$xr=o("speech_to_text"),kxr=o(" \u2014 "),HZ=a("a"),Sxr=o("TFSpeech2TextModel"),Rxr=o(" (Speech2Text model)"),Pxr=l(),H3=a("li"),R0e=a("strong"),Bxr=o("swin"),Ixr=o(" \u2014 "),JZ=a("a"),Nxr=o("TFSwinModel"),qxr=o(" (Swin Transformer model)"),jxr=l(),J3=a("li"),P0e=a("strong"),Dxr=o("t5"),Gxr=o(" \u2014 "),YZ=a("a"),Oxr=o("TFT5Model"),Vxr=o(" (T5 model)"),Xxr=l(),Y3=a("li"),B0e=a("strong"),zxr=o("tapas"),Qxr=o(" \u2014 "),KZ=a("a"),Wxr=o("TFTapasModel"),Uxr=o(" (TAPAS model)"),Hxr=l(),K3=a("li"),I0e=a("strong"),Jxr=o("transfo-xl"),Yxr=o(" \u2014 "),ZZ=a("a"),Kxr=o("TFTransfoXLModel"),Zxr=o(" (Transformer-XL model)"),e$r=l(),Z3=a("li"),N0e=a("strong"),o$r=o("vit"),r$r=o(" \u2014 "),eee=a("a"),t$r=o("TFViTModel"),a$r=o(" (ViT model)"),n$r=l(),e5=a("li"),q0e=a("strong"),s$r=o("vit_mae"),l$r=o(" \u2014 "),oee=a("a"),i$r=o("TFViTMAEModel"),d$r=o(" (ViTMAE model)"),c$r=l(),o5=a("li"),j0e=a("strong"),m$r=o("wav2vec2"),f$r=o(" \u2014 "),ree=a("a"),g$r=o("TFWav2Vec2Model"),h$r=o(" (Wav2Vec2 model)"),u$r=l(),r5=a("li"),D0e=a("strong"),p$r=o("xglm"),_$r=o(" \u2014 "),tee=a("a"),b$r=o("TFXGLMModel"),v$r=o(" (XGLM model)"),F$r=l(),t5=a("li"),G0e=a("strong"),T$r=o("xlm"),M$r=o(" \u2014 "),aee=a("a"),E$r=o("TFXLMModel"),C$r=o(" (XLM model)"),w$r=l(),a5=a("li"),O0e=a("strong"),A$r=o("xlm-roberta"),L$r=o(" \u2014 "),nee=a("a"),y$r=o("TFXLMRobertaModel"),x$r=o(" (XLM-RoBERTa model)"),$$r=l(),n5=a("li"),V0e=a("strong"),k$r=o("xlnet"),S$r=o(" \u2014 "),see=a("a"),R$r=o("TFXLNetModel"),P$r=o(" (XLNet model)"),B$r=l(),F(s5.$$.fragment),XKe=l(),Xc=a("h2"),l5=a("a"),X0e=a("span"),F(Ck.$$.fragment),I$r=l(),z0e=a("span"),N$r=o("TFAutoModelForPreTraining"),zKe=l(),lr=a("div"),F(wk.$$.fragment),q$r=l(),zc=a("p"),j$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lee=a("a"),D$r=o("from_pretrained()"),G$r=o(" class method or the "),iee=a("a"),O$r=o("from_config()"),V$r=o(` class
method.`),X$r=l(),Ak=a("p"),z$r=o("This class cannot be instantiated directly using "),Q0e=a("code"),Q$r=o("__init__()"),W$r=o(" (throws an error)."),U$r=l(),zt=a("div"),F(Lk.$$.fragment),H$r=l(),W0e=a("p"),J$r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Y$r=l(),Qc=a("p"),K$r=o(`Note:
Loading a model from its configuration file does `),U0e=a("strong"),Z$r=o("not"),ekr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=a("a"),okr=o("from_pretrained()"),rkr=o(" to load the model weights."),tkr=l(),F(i5.$$.fragment),akr=l(),Nr=a("div"),F(yk.$$.fragment),nkr=l(),H0e=a("p"),skr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lkr=l(),wn=a("p"),ikr=o("The model class to instantiate is selected based on the "),J0e=a("code"),dkr=o("model_type"),ckr=o(` property of the config object (either
passed as an argument or loaded from `),Y0e=a("code"),mkr=o("pretrained_model_name_or_path"),fkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K0e=a("code"),gkr=o("pretrained_model_name_or_path"),hkr=o(":"),ukr=l(),se=a("ul"),d5=a("li"),Z0e=a("strong"),pkr=o("albert"),_kr=o(" \u2014 "),cee=a("a"),bkr=o("TFAlbertForPreTraining"),vkr=o(" (ALBERT model)"),Fkr=l(),c5=a("li"),ewe=a("strong"),Tkr=o("bart"),Mkr=o(" \u2014 "),mee=a("a"),Ekr=o("TFBartForConditionalGeneration"),Ckr=o(" (BART model)"),wkr=l(),m5=a("li"),owe=a("strong"),Akr=o("bert"),Lkr=o(" \u2014 "),fee=a("a"),ykr=o("TFBertForPreTraining"),xkr=o(" (BERT model)"),$kr=l(),f5=a("li"),rwe=a("strong"),kkr=o("camembert"),Skr=o(" \u2014 "),gee=a("a"),Rkr=o("TFCamembertForMaskedLM"),Pkr=o(" (CamemBERT model)"),Bkr=l(),g5=a("li"),twe=a("strong"),Ikr=o("ctrl"),Nkr=o(" \u2014 "),hee=a("a"),qkr=o("TFCTRLLMHeadModel"),jkr=o(" (CTRL model)"),Dkr=l(),h5=a("li"),awe=a("strong"),Gkr=o("distilbert"),Okr=o(" \u2014 "),uee=a("a"),Vkr=o("TFDistilBertForMaskedLM"),Xkr=o(" (DistilBERT model)"),zkr=l(),u5=a("li"),nwe=a("strong"),Qkr=o("electra"),Wkr=o(" \u2014 "),pee=a("a"),Ukr=o("TFElectraForPreTraining"),Hkr=o(" (ELECTRA model)"),Jkr=l(),p5=a("li"),swe=a("strong"),Ykr=o("flaubert"),Kkr=o(" \u2014 "),_ee=a("a"),Zkr=o("TFFlaubertWithLMHeadModel"),eSr=o(" (FlauBERT model)"),oSr=l(),_5=a("li"),lwe=a("strong"),rSr=o("funnel"),tSr=o(" \u2014 "),bee=a("a"),aSr=o("TFFunnelForPreTraining"),nSr=o(" (Funnel Transformer model)"),sSr=l(),b5=a("li"),iwe=a("strong"),lSr=o("gpt2"),iSr=o(" \u2014 "),vee=a("a"),dSr=o("TFGPT2LMHeadModel"),cSr=o(" (OpenAI GPT-2 model)"),mSr=l(),v5=a("li"),dwe=a("strong"),fSr=o("layoutlm"),gSr=o(" \u2014 "),Fee=a("a"),hSr=o("TFLayoutLMForMaskedLM"),uSr=o(" (LayoutLM model)"),pSr=l(),F5=a("li"),cwe=a("strong"),_Sr=o("lxmert"),bSr=o(" \u2014 "),Tee=a("a"),vSr=o("TFLxmertForPreTraining"),FSr=o(" (LXMERT model)"),TSr=l(),T5=a("li"),mwe=a("strong"),MSr=o("mobilebert"),ESr=o(" \u2014 "),Mee=a("a"),CSr=o("TFMobileBertForPreTraining"),wSr=o(" (MobileBERT model)"),ASr=l(),M5=a("li"),fwe=a("strong"),LSr=o("mpnet"),ySr=o(" \u2014 "),Eee=a("a"),xSr=o("TFMPNetForMaskedLM"),$Sr=o(" (MPNet model)"),kSr=l(),E5=a("li"),gwe=a("strong"),SSr=o("openai-gpt"),RSr=o(" \u2014 "),Cee=a("a"),PSr=o("TFOpenAIGPTLMHeadModel"),BSr=o(" (OpenAI GPT model)"),ISr=l(),C5=a("li"),hwe=a("strong"),NSr=o("roberta"),qSr=o(" \u2014 "),wee=a("a"),jSr=o("TFRobertaForMaskedLM"),DSr=o(" (RoBERTa model)"),GSr=l(),w5=a("li"),uwe=a("strong"),OSr=o("t5"),VSr=o(" \u2014 "),Aee=a("a"),XSr=o("TFT5ForConditionalGeneration"),zSr=o(" (T5 model)"),QSr=l(),A5=a("li"),pwe=a("strong"),WSr=o("tapas"),USr=o(" \u2014 "),Lee=a("a"),HSr=o("TFTapasForMaskedLM"),JSr=o(" (TAPAS model)"),YSr=l(),L5=a("li"),_we=a("strong"),KSr=o("transfo-xl"),ZSr=o(" \u2014 "),yee=a("a"),eRr=o("TFTransfoXLLMHeadModel"),oRr=o(" (Transformer-XL model)"),rRr=l(),y5=a("li"),bwe=a("strong"),tRr=o("vit_mae"),aRr=o(" \u2014 "),xee=a("a"),nRr=o("TFViTMAEForPreTraining"),sRr=o(" (ViTMAE model)"),lRr=l(),x5=a("li"),vwe=a("strong"),iRr=o("xlm"),dRr=o(" \u2014 "),$ee=a("a"),cRr=o("TFXLMWithLMHeadModel"),mRr=o(" (XLM model)"),fRr=l(),$5=a("li"),Fwe=a("strong"),gRr=o("xlm-roberta"),hRr=o(" \u2014 "),kee=a("a"),uRr=o("TFXLMRobertaForMaskedLM"),pRr=o(" (XLM-RoBERTa model)"),_Rr=l(),k5=a("li"),Twe=a("strong"),bRr=o("xlnet"),vRr=o(" \u2014 "),See=a("a"),FRr=o("TFXLNetLMHeadModel"),TRr=o(" (XLNet model)"),MRr=l(),F(S5.$$.fragment),QKe=l(),Wc=a("h2"),R5=a("a"),Mwe=a("span"),F(xk.$$.fragment),ERr=l(),Ewe=a("span"),CRr=o("TFAutoModelForCausalLM"),WKe=l(),ir=a("div"),F($k.$$.fragment),wRr=l(),Uc=a("p"),ARr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Ree=a("a"),LRr=o("from_pretrained()"),yRr=o(" class method or the "),Pee=a("a"),xRr=o("from_config()"),$Rr=o(` class
method.`),kRr=l(),kk=a("p"),SRr=o("This class cannot be instantiated directly using "),Cwe=a("code"),RRr=o("__init__()"),PRr=o(" (throws an error)."),BRr=l(),Qt=a("div"),F(Sk.$$.fragment),IRr=l(),wwe=a("p"),NRr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qRr=l(),Hc=a("p"),jRr=o(`Note:
Loading a model from its configuration file does `),Awe=a("strong"),DRr=o("not"),GRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=a("a"),ORr=o("from_pretrained()"),VRr=o(" to load the model weights."),XRr=l(),F(P5.$$.fragment),zRr=l(),qr=a("div"),F(Rk.$$.fragment),QRr=l(),Lwe=a("p"),WRr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),URr=l(),An=a("p"),HRr=o("The model class to instantiate is selected based on the "),ywe=a("code"),JRr=o("model_type"),YRr=o(` property of the config object (either
passed as an argument or loaded from `),xwe=a("code"),KRr=o("pretrained_model_name_or_path"),ZRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=a("code"),ePr=o("pretrained_model_name_or_path"),oPr=o(":"),rPr=l(),Me=a("ul"),B5=a("li"),kwe=a("strong"),tPr=o("bert"),aPr=o(" \u2014 "),Iee=a("a"),nPr=o("TFBertLMHeadModel"),sPr=o(" (BERT model)"),lPr=l(),I5=a("li"),Swe=a("strong"),iPr=o("camembert"),dPr=o(" \u2014 "),Nee=a("a"),cPr=o("TFCamembertForCausalLM"),mPr=o(" (CamemBERT model)"),fPr=l(),N5=a("li"),Rwe=a("strong"),gPr=o("ctrl"),hPr=o(" \u2014 "),qee=a("a"),uPr=o("TFCTRLLMHeadModel"),pPr=o(" (CTRL model)"),_Pr=l(),q5=a("li"),Pwe=a("strong"),bPr=o("gpt2"),vPr=o(" \u2014 "),jee=a("a"),FPr=o("TFGPT2LMHeadModel"),TPr=o(" (OpenAI GPT-2 model)"),MPr=l(),j5=a("li"),Bwe=a("strong"),EPr=o("gptj"),CPr=o(" \u2014 "),Dee=a("a"),wPr=o("TFGPTJForCausalLM"),APr=o(" (GPT-J model)"),LPr=l(),D5=a("li"),Iwe=a("strong"),yPr=o("openai-gpt"),xPr=o(" \u2014 "),Gee=a("a"),$Pr=o("TFOpenAIGPTLMHeadModel"),kPr=o(" (OpenAI GPT model)"),SPr=l(),G5=a("li"),Nwe=a("strong"),RPr=o("opt"),PPr=o(" \u2014 "),Oee=a("a"),BPr=o("TFOPTForCausalLM"),IPr=o(" (OPT model)"),NPr=l(),O5=a("li"),qwe=a("strong"),qPr=o("rembert"),jPr=o(" \u2014 "),Vee=a("a"),DPr=o("TFRemBertForCausalLM"),GPr=o(" (RemBERT model)"),OPr=l(),V5=a("li"),jwe=a("strong"),VPr=o("roberta"),XPr=o(" \u2014 "),Xee=a("a"),zPr=o("TFRobertaForCausalLM"),QPr=o(" (RoBERTa model)"),WPr=l(),X5=a("li"),Dwe=a("strong"),UPr=o("roformer"),HPr=o(" \u2014 "),zee=a("a"),JPr=o("TFRoFormerForCausalLM"),YPr=o(" (RoFormer model)"),KPr=l(),z5=a("li"),Gwe=a("strong"),ZPr=o("transfo-xl"),eBr=o(" \u2014 "),Qee=a("a"),oBr=o("TFTransfoXLLMHeadModel"),rBr=o(" (Transformer-XL model)"),tBr=l(),Q5=a("li"),Owe=a("strong"),aBr=o("xglm"),nBr=o(" \u2014 "),Wee=a("a"),sBr=o("TFXGLMForCausalLM"),lBr=o(" (XGLM model)"),iBr=l(),W5=a("li"),Vwe=a("strong"),dBr=o("xlm"),cBr=o(" \u2014 "),Uee=a("a"),mBr=o("TFXLMWithLMHeadModel"),fBr=o(" (XLM model)"),gBr=l(),U5=a("li"),Xwe=a("strong"),hBr=o("xlnet"),uBr=o(" \u2014 "),Hee=a("a"),pBr=o("TFXLNetLMHeadModel"),_Br=o(" (XLNet model)"),bBr=l(),F(H5.$$.fragment),UKe=l(),Jc=a("h2"),J5=a("a"),zwe=a("span"),F(Pk.$$.fragment),vBr=l(),Qwe=a("span"),FBr=o("TFAutoModelForImageClassification"),HKe=l(),dr=a("div"),F(Bk.$$.fragment),TBr=l(),Yc=a("p"),MBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jee=a("a"),EBr=o("from_pretrained()"),CBr=o(" class method or the "),Yee=a("a"),wBr=o("from_config()"),ABr=o(` class
method.`),LBr=l(),Ik=a("p"),yBr=o("This class cannot be instantiated directly using "),Wwe=a("code"),xBr=o("__init__()"),$Br=o(" (throws an error)."),kBr=l(),Wt=a("div"),F(Nk.$$.fragment),SBr=l(),Uwe=a("p"),RBr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),PBr=l(),Kc=a("p"),BBr=o(`Note:
Loading a model from its configuration file does `),Hwe=a("strong"),IBr=o("not"),NBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=a("a"),qBr=o("from_pretrained()"),jBr=o(" to load the model weights."),DBr=l(),F(Y5.$$.fragment),GBr=l(),jr=a("div"),F(qk.$$.fragment),OBr=l(),Jwe=a("p"),VBr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XBr=l(),Ln=a("p"),zBr=o("The model class to instantiate is selected based on the "),Ywe=a("code"),QBr=o("model_type"),WBr=o(` property of the config object (either
passed as an argument or loaded from `),Kwe=a("code"),UBr=o("pretrained_model_name_or_path"),HBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=a("code"),JBr=o("pretrained_model_name_or_path"),YBr=o(":"),KBr=l(),Be=a("ul"),K5=a("li"),eAe=a("strong"),ZBr=o("convnext"),eIr=o(" \u2014 "),Zee=a("a"),oIr=o("TFConvNextForImageClassification"),rIr=o(" (ConvNeXT model)"),tIr=l(),Z5=a("li"),oAe=a("strong"),aIr=o("data2vec-vision"),nIr=o(" \u2014 "),eoe=a("a"),sIr=o("TFData2VecVisionForImageClassification"),lIr=o(" (Data2VecVision model)"),iIr=l(),Fl=a("li"),rAe=a("strong"),dIr=o("deit"),cIr=o(" \u2014 "),ooe=a("a"),mIr=o("TFDeiTForImageClassification"),fIr=o(" or "),roe=a("a"),gIr=o("TFDeiTForImageClassificationWithTeacher"),hIr=o(" (DeiT model)"),uIr=l(),e0=a("li"),tAe=a("strong"),pIr=o("mobilevit"),_Ir=o(" \u2014 "),toe=a("a"),bIr=o("TFMobileViTForImageClassification"),vIr=o(" (MobileViT model)"),FIr=l(),o0=a("li"),aAe=a("strong"),TIr=o("regnet"),MIr=o(" \u2014 "),aoe=a("a"),EIr=o("TFRegNetForImageClassification"),CIr=o(" (RegNet model)"),wIr=l(),r0=a("li"),nAe=a("strong"),AIr=o("resnet"),LIr=o(" \u2014 "),noe=a("a"),yIr=o("TFResNetForImageClassification"),xIr=o(" (ResNet model)"),$Ir=l(),t0=a("li"),sAe=a("strong"),kIr=o("segformer"),SIr=o(" \u2014 "),soe=a("a"),RIr=o("TFSegformerForImageClassification"),PIr=o(" (SegFormer model)"),BIr=l(),a0=a("li"),lAe=a("strong"),IIr=o("swin"),NIr=o(" \u2014 "),loe=a("a"),qIr=o("TFSwinForImageClassification"),jIr=o(" (Swin Transformer model)"),DIr=l(),n0=a("li"),iAe=a("strong"),GIr=o("vit"),OIr=o(" \u2014 "),ioe=a("a"),VIr=o("TFViTForImageClassification"),XIr=o(" (ViT model)"),zIr=l(),F(s0.$$.fragment),JKe=l(),Zc=a("h2"),l0=a("a"),dAe=a("span"),F(jk.$$.fragment),QIr=l(),cAe=a("span"),WIr=o("TFAutoModelForSemanticSegmentation"),YKe=l(),cr=a("div"),F(Dk.$$.fragment),UIr=l(),em=a("p"),HIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),doe=a("a"),JIr=o("from_pretrained()"),YIr=o(" class method or the "),coe=a("a"),KIr=o("from_config()"),ZIr=o(` class
method.`),eNr=l(),Gk=a("p"),oNr=o("This class cannot be instantiated directly using "),mAe=a("code"),rNr=o("__init__()"),tNr=o(" (throws an error)."),aNr=l(),Ut=a("div"),F(Ok.$$.fragment),nNr=l(),fAe=a("p"),sNr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),lNr=l(),om=a("p"),iNr=o(`Note:
Loading a model from its configuration file does `),gAe=a("strong"),dNr=o("not"),cNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=a("a"),mNr=o("from_pretrained()"),fNr=o(" to load the model weights."),gNr=l(),F(i0.$$.fragment),hNr=l(),Dr=a("div"),F(Vk.$$.fragment),uNr=l(),hAe=a("p"),pNr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),_Nr=l(),yn=a("p"),bNr=o("The model class to instantiate is selected based on the "),uAe=a("code"),vNr=o("model_type"),FNr=o(` property of the config object (either
passed as an argument or loaded from `),pAe=a("code"),TNr=o("pretrained_model_name_or_path"),MNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=a("code"),ENr=o("pretrained_model_name_or_path"),CNr=o(":"),wNr=l(),rm=a("ul"),d0=a("li"),bAe=a("strong"),ANr=o("data2vec-vision"),LNr=o(" \u2014 "),foe=a("a"),yNr=o("TFData2VecVisionForSemanticSegmentation"),xNr=o(" (Data2VecVision model)"),$Nr=l(),c0=a("li"),vAe=a("strong"),kNr=o("mobilevit"),SNr=o(" \u2014 "),goe=a("a"),RNr=o("TFMobileViTForSemanticSegmentation"),PNr=o(" (MobileViT model)"),BNr=l(),m0=a("li"),FAe=a("strong"),INr=o("segformer"),NNr=o(" \u2014 "),hoe=a("a"),qNr=o("TFSegformerForSemanticSegmentation"),jNr=o(" (SegFormer model)"),DNr=l(),F(f0.$$.fragment),KKe=l(),tm=a("h2"),g0=a("a"),TAe=a("span"),F(Xk.$$.fragment),GNr=l(),MAe=a("span"),ONr=o("TFAutoModelForMaskedLM"),ZKe=l(),mr=a("div"),F(zk.$$.fragment),VNr=l(),am=a("p"),XNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uoe=a("a"),zNr=o("from_pretrained()"),QNr=o(" class method or the "),poe=a("a"),WNr=o("from_config()"),UNr=o(` class
method.`),HNr=l(),Qk=a("p"),JNr=o("This class cannot be instantiated directly using "),EAe=a("code"),YNr=o("__init__()"),KNr=o(" (throws an error)."),ZNr=l(),Ht=a("div"),F(Wk.$$.fragment),eqr=l(),CAe=a("p"),oqr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rqr=l(),nm=a("p"),tqr=o(`Note:
Loading a model from its configuration file does `),wAe=a("strong"),aqr=o("not"),nqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),sqr=o("from_pretrained()"),lqr=o(" to load the model weights."),iqr=l(),F(h0.$$.fragment),dqr=l(),Gr=a("div"),F(Uk.$$.fragment),cqr=l(),AAe=a("p"),mqr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fqr=l(),xn=a("p"),gqr=o("The model class to instantiate is selected based on the "),LAe=a("code"),hqr=o("model_type"),uqr=o(` property of the config object (either
passed as an argument or loaded from `),yAe=a("code"),pqr=o("pretrained_model_name_or_path"),_qr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=a("code"),bqr=o("pretrained_model_name_or_path"),vqr=o(":"),Fqr=l(),fe=a("ul"),u0=a("li"),$Ae=a("strong"),Tqr=o("albert"),Mqr=o(" \u2014 "),boe=a("a"),Eqr=o("TFAlbertForMaskedLM"),Cqr=o(" (ALBERT model)"),wqr=l(),p0=a("li"),kAe=a("strong"),Aqr=o("bert"),Lqr=o(" \u2014 "),voe=a("a"),yqr=o("TFBertForMaskedLM"),xqr=o(" (BERT model)"),$qr=l(),_0=a("li"),SAe=a("strong"),kqr=o("camembert"),Sqr=o(" \u2014 "),Foe=a("a"),Rqr=o("TFCamembertForMaskedLM"),Pqr=o(" (CamemBERT model)"),Bqr=l(),b0=a("li"),RAe=a("strong"),Iqr=o("convbert"),Nqr=o(" \u2014 "),Toe=a("a"),qqr=o("TFConvBertForMaskedLM"),jqr=o(" (ConvBERT model)"),Dqr=l(),v0=a("li"),PAe=a("strong"),Gqr=o("deberta"),Oqr=o(" \u2014 "),Moe=a("a"),Vqr=o("TFDebertaForMaskedLM"),Xqr=o(" (DeBERTa model)"),zqr=l(),F0=a("li"),BAe=a("strong"),Qqr=o("deberta-v2"),Wqr=o(" \u2014 "),Eoe=a("a"),Uqr=o("TFDebertaV2ForMaskedLM"),Hqr=o(" (DeBERTa-v2 model)"),Jqr=l(),T0=a("li"),IAe=a("strong"),Yqr=o("distilbert"),Kqr=o(" \u2014 "),Coe=a("a"),Zqr=o("TFDistilBertForMaskedLM"),ejr=o(" (DistilBERT model)"),ojr=l(),M0=a("li"),NAe=a("strong"),rjr=o("electra"),tjr=o(" \u2014 "),woe=a("a"),ajr=o("TFElectraForMaskedLM"),njr=o(" (ELECTRA model)"),sjr=l(),E0=a("li"),qAe=a("strong"),ljr=o("flaubert"),ijr=o(" \u2014 "),Aoe=a("a"),djr=o("TFFlaubertWithLMHeadModel"),cjr=o(" (FlauBERT model)"),mjr=l(),C0=a("li"),jAe=a("strong"),fjr=o("funnel"),gjr=o(" \u2014 "),Loe=a("a"),hjr=o("TFFunnelForMaskedLM"),ujr=o(" (Funnel Transformer model)"),pjr=l(),w0=a("li"),DAe=a("strong"),_jr=o("layoutlm"),bjr=o(" \u2014 "),yoe=a("a"),vjr=o("TFLayoutLMForMaskedLM"),Fjr=o(" (LayoutLM model)"),Tjr=l(),A0=a("li"),GAe=a("strong"),Mjr=o("longformer"),Ejr=o(" \u2014 "),xoe=a("a"),Cjr=o("TFLongformerForMaskedLM"),wjr=o(" (Longformer model)"),Ajr=l(),L0=a("li"),OAe=a("strong"),Ljr=o("mobilebert"),yjr=o(" \u2014 "),$oe=a("a"),xjr=o("TFMobileBertForMaskedLM"),$jr=o(" (MobileBERT model)"),kjr=l(),y0=a("li"),VAe=a("strong"),Sjr=o("mpnet"),Rjr=o(" \u2014 "),koe=a("a"),Pjr=o("TFMPNetForMaskedLM"),Bjr=o(" (MPNet model)"),Ijr=l(),x0=a("li"),XAe=a("strong"),Njr=o("rembert"),qjr=o(" \u2014 "),Soe=a("a"),jjr=o("TFRemBertForMaskedLM"),Djr=o(" (RemBERT model)"),Gjr=l(),$0=a("li"),zAe=a("strong"),Ojr=o("roberta"),Vjr=o(" \u2014 "),Roe=a("a"),Xjr=o("TFRobertaForMaskedLM"),zjr=o(" (RoBERTa model)"),Qjr=l(),k0=a("li"),QAe=a("strong"),Wjr=o("roformer"),Ujr=o(" \u2014 "),Poe=a("a"),Hjr=o("TFRoFormerForMaskedLM"),Jjr=o(" (RoFormer model)"),Yjr=l(),S0=a("li"),WAe=a("strong"),Kjr=o("tapas"),Zjr=o(" \u2014 "),Boe=a("a"),eDr=o("TFTapasForMaskedLM"),oDr=o(" (TAPAS model)"),rDr=l(),R0=a("li"),UAe=a("strong"),tDr=o("xlm"),aDr=o(" \u2014 "),Ioe=a("a"),nDr=o("TFXLMWithLMHeadModel"),sDr=o(" (XLM model)"),lDr=l(),P0=a("li"),HAe=a("strong"),iDr=o("xlm-roberta"),dDr=o(" \u2014 "),Noe=a("a"),cDr=o("TFXLMRobertaForMaskedLM"),mDr=o(" (XLM-RoBERTa model)"),fDr=l(),F(B0.$$.fragment),eZe=l(),sm=a("h2"),I0=a("a"),JAe=a("span"),F(Hk.$$.fragment),gDr=l(),YAe=a("span"),hDr=o("TFAutoModelForSeq2SeqLM"),oZe=l(),fr=a("div"),F(Jk.$$.fragment),uDr=l(),lm=a("p"),pDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qoe=a("a"),_Dr=o("from_pretrained()"),bDr=o(" class method or the "),joe=a("a"),vDr=o("from_config()"),FDr=o(` class
method.`),TDr=l(),Yk=a("p"),MDr=o("This class cannot be instantiated directly using "),KAe=a("code"),EDr=o("__init__()"),CDr=o(" (throws an error)."),wDr=l(),Jt=a("div"),F(Kk.$$.fragment),ADr=l(),ZAe=a("p"),LDr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yDr=l(),im=a("p"),xDr=o(`Note:
Loading a model from its configuration file does `),e6e=a("strong"),$Dr=o("not"),kDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=a("a"),SDr=o("from_pretrained()"),RDr=o(" to load the model weights."),PDr=l(),F(N0.$$.fragment),BDr=l(),Or=a("div"),F(Zk.$$.fragment),IDr=l(),o6e=a("p"),NDr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qDr=l(),$n=a("p"),jDr=o("The model class to instantiate is selected based on the "),r6e=a("code"),DDr=o("model_type"),GDr=o(` property of the config object (either
passed as an argument or loaded from `),t6e=a("code"),ODr=o("pretrained_model_name_or_path"),VDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=a("code"),XDr=o("pretrained_model_name_or_path"),zDr=o(":"),QDr=l(),ye=a("ul"),q0=a("li"),n6e=a("strong"),WDr=o("bart"),UDr=o(" \u2014 "),Goe=a("a"),HDr=o("TFBartForConditionalGeneration"),JDr=o(" (BART model)"),YDr=l(),j0=a("li"),s6e=a("strong"),KDr=o("blenderbot"),ZDr=o(" \u2014 "),Ooe=a("a"),eGr=o("TFBlenderbotForConditionalGeneration"),oGr=o(" (Blenderbot model)"),rGr=l(),D0=a("li"),l6e=a("strong"),tGr=o("blenderbot-small"),aGr=o(" \u2014 "),Voe=a("a"),nGr=o("TFBlenderbotSmallForConditionalGeneration"),sGr=o(" (BlenderbotSmall model)"),lGr=l(),G0=a("li"),i6e=a("strong"),iGr=o("encoder-decoder"),dGr=o(" \u2014 "),Xoe=a("a"),cGr=o("TFEncoderDecoderModel"),mGr=o(" (Encoder decoder model)"),fGr=l(),O0=a("li"),d6e=a("strong"),gGr=o("led"),hGr=o(" \u2014 "),zoe=a("a"),uGr=o("TFLEDForConditionalGeneration"),pGr=o(" (LED model)"),_Gr=l(),V0=a("li"),c6e=a("strong"),bGr=o("marian"),vGr=o(" \u2014 "),Qoe=a("a"),FGr=o("TFMarianMTModel"),TGr=o(" (Marian model)"),MGr=l(),X0=a("li"),m6e=a("strong"),EGr=o("mbart"),CGr=o(" \u2014 "),Woe=a("a"),wGr=o("TFMBartForConditionalGeneration"),AGr=o(" (mBART model)"),LGr=l(),z0=a("li"),f6e=a("strong"),yGr=o("mt5"),xGr=o(" \u2014 "),Uoe=a("a"),$Gr=o("TFMT5ForConditionalGeneration"),kGr=o(" (MT5 model)"),SGr=l(),Q0=a("li"),g6e=a("strong"),RGr=o("pegasus"),PGr=o(" \u2014 "),Hoe=a("a"),BGr=o("TFPegasusForConditionalGeneration"),IGr=o(" (Pegasus model)"),NGr=l(),W0=a("li"),h6e=a("strong"),qGr=o("t5"),jGr=o(" \u2014 "),Joe=a("a"),DGr=o("TFT5ForConditionalGeneration"),GGr=o(" (T5 model)"),OGr=l(),F(U0.$$.fragment),rZe=l(),dm=a("h2"),H0=a("a"),u6e=a("span"),F(eS.$$.fragment),VGr=l(),p6e=a("span"),XGr=o("TFAutoModelForSequenceClassification"),tZe=l(),gr=a("div"),F(oS.$$.fragment),zGr=l(),cm=a("p"),QGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yoe=a("a"),WGr=o("from_pretrained()"),UGr=o(" class method or the "),Koe=a("a"),HGr=o("from_config()"),JGr=o(` class
method.`),YGr=l(),rS=a("p"),KGr=o("This class cannot be instantiated directly using "),_6e=a("code"),ZGr=o("__init__()"),eOr=o(" (throws an error)."),oOr=l(),Yt=a("div"),F(tS.$$.fragment),rOr=l(),b6e=a("p"),tOr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aOr=l(),mm=a("p"),nOr=o(`Note:
Loading a model from its configuration file does `),v6e=a("strong"),sOr=o("not"),lOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=a("a"),iOr=o("from_pretrained()"),dOr=o(" to load the model weights."),cOr=l(),F(J0.$$.fragment),mOr=l(),Vr=a("div"),F(aS.$$.fragment),fOr=l(),F6e=a("p"),gOr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hOr=l(),kn=a("p"),uOr=o("The model class to instantiate is selected based on the "),T6e=a("code"),pOr=o("model_type"),_Or=o(` property of the config object (either
passed as an argument or loaded from `),M6e=a("code"),bOr=o("pretrained_model_name_or_path"),vOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=a("code"),FOr=o("pretrained_model_name_or_path"),TOr=o(":"),MOr=l(),re=a("ul"),Y0=a("li"),C6e=a("strong"),EOr=o("albert"),COr=o(" \u2014 "),ere=a("a"),wOr=o("TFAlbertForSequenceClassification"),AOr=o(" (ALBERT model)"),LOr=l(),K0=a("li"),w6e=a("strong"),yOr=o("bert"),xOr=o(" \u2014 "),ore=a("a"),$Or=o("TFBertForSequenceClassification"),kOr=o(" (BERT model)"),SOr=l(),Z0=a("li"),A6e=a("strong"),ROr=o("camembert"),POr=o(" \u2014 "),rre=a("a"),BOr=o("TFCamembertForSequenceClassification"),IOr=o(" (CamemBERT model)"),NOr=l(),ew=a("li"),L6e=a("strong"),qOr=o("convbert"),jOr=o(" \u2014 "),tre=a("a"),DOr=o("TFConvBertForSequenceClassification"),GOr=o(" (ConvBERT model)"),OOr=l(),ow=a("li"),y6e=a("strong"),VOr=o("ctrl"),XOr=o(" \u2014 "),are=a("a"),zOr=o("TFCTRLForSequenceClassification"),QOr=o(" (CTRL model)"),WOr=l(),rw=a("li"),x6e=a("strong"),UOr=o("deberta"),HOr=o(" \u2014 "),nre=a("a"),JOr=o("TFDebertaForSequenceClassification"),YOr=o(" (DeBERTa model)"),KOr=l(),tw=a("li"),$6e=a("strong"),ZOr=o("deberta-v2"),eVr=o(" \u2014 "),sre=a("a"),oVr=o("TFDebertaV2ForSequenceClassification"),rVr=o(" (DeBERTa-v2 model)"),tVr=l(),aw=a("li"),k6e=a("strong"),aVr=o("distilbert"),nVr=o(" \u2014 "),lre=a("a"),sVr=o("TFDistilBertForSequenceClassification"),lVr=o(" (DistilBERT model)"),iVr=l(),nw=a("li"),S6e=a("strong"),dVr=o("electra"),cVr=o(" \u2014 "),ire=a("a"),mVr=o("TFElectraForSequenceClassification"),fVr=o(" (ELECTRA model)"),gVr=l(),sw=a("li"),R6e=a("strong"),hVr=o("flaubert"),uVr=o(" \u2014 "),dre=a("a"),pVr=o("TFFlaubertForSequenceClassification"),_Vr=o(" (FlauBERT model)"),bVr=l(),lw=a("li"),P6e=a("strong"),vVr=o("funnel"),FVr=o(" \u2014 "),cre=a("a"),TVr=o("TFFunnelForSequenceClassification"),MVr=o(" (Funnel Transformer model)"),EVr=l(),iw=a("li"),B6e=a("strong"),CVr=o("gpt2"),wVr=o(" \u2014 "),mre=a("a"),AVr=o("TFGPT2ForSequenceClassification"),LVr=o(" (OpenAI GPT-2 model)"),yVr=l(),dw=a("li"),I6e=a("strong"),xVr=o("gptj"),$Vr=o(" \u2014 "),fre=a("a"),kVr=o("TFGPTJForSequenceClassification"),SVr=o(" (GPT-J model)"),RVr=l(),cw=a("li"),N6e=a("strong"),PVr=o("layoutlm"),BVr=o(" \u2014 "),gre=a("a"),IVr=o("TFLayoutLMForSequenceClassification"),NVr=o(" (LayoutLM model)"),qVr=l(),mw=a("li"),q6e=a("strong"),jVr=o("layoutlmv3"),DVr=o(" \u2014 "),hre=a("a"),GVr=o("TFLayoutLMv3ForSequenceClassification"),OVr=o(" (LayoutLMv3 model)"),VVr=l(),fw=a("li"),j6e=a("strong"),XVr=o("longformer"),zVr=o(" \u2014 "),ure=a("a"),QVr=o("TFLongformerForSequenceClassification"),WVr=o(" (Longformer model)"),UVr=l(),gw=a("li"),D6e=a("strong"),HVr=o("mobilebert"),JVr=o(" \u2014 "),pre=a("a"),YVr=o("TFMobileBertForSequenceClassification"),KVr=o(" (MobileBERT model)"),ZVr=l(),hw=a("li"),G6e=a("strong"),eXr=o("mpnet"),oXr=o(" \u2014 "),_re=a("a"),rXr=o("TFMPNetForSequenceClassification"),tXr=o(" (MPNet model)"),aXr=l(),uw=a("li"),O6e=a("strong"),nXr=o("openai-gpt"),sXr=o(" \u2014 "),bre=a("a"),lXr=o("TFOpenAIGPTForSequenceClassification"),iXr=o(" (OpenAI GPT model)"),dXr=l(),pw=a("li"),V6e=a("strong"),cXr=o("rembert"),mXr=o(" \u2014 "),vre=a("a"),fXr=o("TFRemBertForSequenceClassification"),gXr=o(" (RemBERT model)"),hXr=l(),_w=a("li"),X6e=a("strong"),uXr=o("roberta"),pXr=o(" \u2014 "),Fre=a("a"),_Xr=o("TFRobertaForSequenceClassification"),bXr=o(" (RoBERTa model)"),vXr=l(),bw=a("li"),z6e=a("strong"),FXr=o("roformer"),TXr=o(" \u2014 "),Tre=a("a"),MXr=o("TFRoFormerForSequenceClassification"),EXr=o(" (RoFormer model)"),CXr=l(),vw=a("li"),Q6e=a("strong"),wXr=o("tapas"),AXr=o(" \u2014 "),Mre=a("a"),LXr=o("TFTapasForSequenceClassification"),yXr=o(" (TAPAS model)"),xXr=l(),Fw=a("li"),W6e=a("strong"),$Xr=o("transfo-xl"),kXr=o(" \u2014 "),Ere=a("a"),SXr=o("TFTransfoXLForSequenceClassification"),RXr=o(" (Transformer-XL model)"),PXr=l(),Tw=a("li"),U6e=a("strong"),BXr=o("xlm"),IXr=o(" \u2014 "),Cre=a("a"),NXr=o("TFXLMForSequenceClassification"),qXr=o(" (XLM model)"),jXr=l(),Mw=a("li"),H6e=a("strong"),DXr=o("xlm-roberta"),GXr=o(" \u2014 "),wre=a("a"),OXr=o("TFXLMRobertaForSequenceClassification"),VXr=o(" (XLM-RoBERTa model)"),XXr=l(),Ew=a("li"),J6e=a("strong"),zXr=o("xlnet"),QXr=o(" \u2014 "),Are=a("a"),WXr=o("TFXLNetForSequenceClassification"),UXr=o(" (XLNet model)"),HXr=l(),F(Cw.$$.fragment),aZe=l(),fm=a("h2"),ww=a("a"),Y6e=a("span"),F(nS.$$.fragment),JXr=l(),K6e=a("span"),YXr=o("TFAutoModelForMultipleChoice"),nZe=l(),hr=a("div"),F(sS.$$.fragment),KXr=l(),gm=a("p"),ZXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lre=a("a"),ezr=o("from_pretrained()"),ozr=o(" class method or the "),yre=a("a"),rzr=o("from_config()"),tzr=o(` class
method.`),azr=l(),lS=a("p"),nzr=o("This class cannot be instantiated directly using "),Z6e=a("code"),szr=o("__init__()"),lzr=o(" (throws an error)."),izr=l(),Kt=a("div"),F(iS.$$.fragment),dzr=l(),e7e=a("p"),czr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),mzr=l(),hm=a("p"),fzr=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),gzr=o("not"),hzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=a("a"),uzr=o("from_pretrained()"),pzr=o(" to load the model weights."),_zr=l(),F(Aw.$$.fragment),bzr=l(),Xr=a("div"),F(dS.$$.fragment),vzr=l(),r7e=a("p"),Fzr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tzr=l(),Sn=a("p"),Mzr=o("The model class to instantiate is selected based on the "),t7e=a("code"),Ezr=o("model_type"),Czr=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),wzr=o("pretrained_model_name_or_path"),Azr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),Lzr=o("pretrained_model_name_or_path"),yzr=o(":"),xzr=l(),ve=a("ul"),Lw=a("li"),s7e=a("strong"),$zr=o("albert"),kzr=o(" \u2014 "),$re=a("a"),Szr=o("TFAlbertForMultipleChoice"),Rzr=o(" (ALBERT model)"),Pzr=l(),yw=a("li"),l7e=a("strong"),Bzr=o("bert"),Izr=o(" \u2014 "),kre=a("a"),Nzr=o("TFBertForMultipleChoice"),qzr=o(" (BERT model)"),jzr=l(),xw=a("li"),i7e=a("strong"),Dzr=o("camembert"),Gzr=o(" \u2014 "),Sre=a("a"),Ozr=o("TFCamembertForMultipleChoice"),Vzr=o(" (CamemBERT model)"),Xzr=l(),$w=a("li"),d7e=a("strong"),zzr=o("convbert"),Qzr=o(" \u2014 "),Rre=a("a"),Wzr=o("TFConvBertForMultipleChoice"),Uzr=o(" (ConvBERT model)"),Hzr=l(),kw=a("li"),c7e=a("strong"),Jzr=o("distilbert"),Yzr=o(" \u2014 "),Pre=a("a"),Kzr=o("TFDistilBertForMultipleChoice"),Zzr=o(" (DistilBERT model)"),eQr=l(),Sw=a("li"),m7e=a("strong"),oQr=o("electra"),rQr=o(" \u2014 "),Bre=a("a"),tQr=o("TFElectraForMultipleChoice"),aQr=o(" (ELECTRA model)"),nQr=l(),Rw=a("li"),f7e=a("strong"),sQr=o("flaubert"),lQr=o(" \u2014 "),Ire=a("a"),iQr=o("TFFlaubertForMultipleChoice"),dQr=o(" (FlauBERT model)"),cQr=l(),Pw=a("li"),g7e=a("strong"),mQr=o("funnel"),fQr=o(" \u2014 "),Nre=a("a"),gQr=o("TFFunnelForMultipleChoice"),hQr=o(" (Funnel Transformer model)"),uQr=l(),Bw=a("li"),h7e=a("strong"),pQr=o("longformer"),_Qr=o(" \u2014 "),qre=a("a"),bQr=o("TFLongformerForMultipleChoice"),vQr=o(" (Longformer model)"),FQr=l(),Iw=a("li"),u7e=a("strong"),TQr=o("mobilebert"),MQr=o(" \u2014 "),jre=a("a"),EQr=o("TFMobileBertForMultipleChoice"),CQr=o(" (MobileBERT model)"),wQr=l(),Nw=a("li"),p7e=a("strong"),AQr=o("mpnet"),LQr=o(" \u2014 "),Dre=a("a"),yQr=o("TFMPNetForMultipleChoice"),xQr=o(" (MPNet model)"),$Qr=l(),qw=a("li"),_7e=a("strong"),kQr=o("rembert"),SQr=o(" \u2014 "),Gre=a("a"),RQr=o("TFRemBertForMultipleChoice"),PQr=o(" (RemBERT model)"),BQr=l(),jw=a("li"),b7e=a("strong"),IQr=o("roberta"),NQr=o(" \u2014 "),Ore=a("a"),qQr=o("TFRobertaForMultipleChoice"),jQr=o(" (RoBERTa model)"),DQr=l(),Dw=a("li"),v7e=a("strong"),GQr=o("roformer"),OQr=o(" \u2014 "),Vre=a("a"),VQr=o("TFRoFormerForMultipleChoice"),XQr=o(" (RoFormer model)"),zQr=l(),Gw=a("li"),F7e=a("strong"),QQr=o("xlm"),WQr=o(" \u2014 "),Xre=a("a"),UQr=o("TFXLMForMultipleChoice"),HQr=o(" (XLM model)"),JQr=l(),Ow=a("li"),T7e=a("strong"),YQr=o("xlm-roberta"),KQr=o(" \u2014 "),zre=a("a"),ZQr=o("TFXLMRobertaForMultipleChoice"),eWr=o(" (XLM-RoBERTa model)"),oWr=l(),Vw=a("li"),M7e=a("strong"),rWr=o("xlnet"),tWr=o(" \u2014 "),Qre=a("a"),aWr=o("TFXLNetForMultipleChoice"),nWr=o(" (XLNet model)"),sWr=l(),F(Xw.$$.fragment),sZe=l(),um=a("h2"),zw=a("a"),E7e=a("span"),F(cS.$$.fragment),lWr=l(),C7e=a("span"),iWr=o("TFAutoModelForNextSentencePrediction"),lZe=l(),ur=a("div"),F(mS.$$.fragment),dWr=l(),pm=a("p"),cWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wre=a("a"),mWr=o("from_pretrained()"),fWr=o(" class method or the "),Ure=a("a"),gWr=o("from_config()"),hWr=o(` class
method.`),uWr=l(),fS=a("p"),pWr=o("This class cannot be instantiated directly using "),w7e=a("code"),_Wr=o("__init__()"),bWr=o(" (throws an error)."),vWr=l(),Zt=a("div"),F(gS.$$.fragment),FWr=l(),A7e=a("p"),TWr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),MWr=l(),_m=a("p"),EWr=o(`Note:
Loading a model from its configuration file does `),L7e=a("strong"),CWr=o("not"),wWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hre=a("a"),AWr=o("from_pretrained()"),LWr=o(" to load the model weights."),yWr=l(),F(Qw.$$.fragment),xWr=l(),zr=a("div"),F(hS.$$.fragment),$Wr=l(),y7e=a("p"),kWr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SWr=l(),Rn=a("p"),RWr=o("The model class to instantiate is selected based on the "),x7e=a("code"),PWr=o("model_type"),BWr=o(` property of the config object (either
passed as an argument or loaded from `),$7e=a("code"),IWr=o("pretrained_model_name_or_path"),NWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=a("code"),qWr=o("pretrained_model_name_or_path"),jWr=o(":"),DWr=l(),uS=a("ul"),Ww=a("li"),S7e=a("strong"),GWr=o("bert"),OWr=o(" \u2014 "),Jre=a("a"),VWr=o("TFBertForNextSentencePrediction"),XWr=o(" (BERT model)"),zWr=l(),Uw=a("li"),R7e=a("strong"),QWr=o("mobilebert"),WWr=o(" \u2014 "),Yre=a("a"),UWr=o("TFMobileBertForNextSentencePrediction"),HWr=o(" (MobileBERT model)"),JWr=l(),F(Hw.$$.fragment),iZe=l(),bm=a("h2"),Jw=a("a"),P7e=a("span"),F(pS.$$.fragment),YWr=l(),B7e=a("span"),KWr=o("TFAutoModelForTableQuestionAnswering"),dZe=l(),pr=a("div"),F(_S.$$.fragment),ZWr=l(),vm=a("p"),eUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kre=a("a"),oUr=o("from_pretrained()"),rUr=o(" class method or the "),Zre=a("a"),tUr=o("from_config()"),aUr=o(` class
method.`),nUr=l(),bS=a("p"),sUr=o("This class cannot be instantiated directly using "),I7e=a("code"),lUr=o("__init__()"),iUr=o(" (throws an error)."),dUr=l(),ea=a("div"),F(vS.$$.fragment),cUr=l(),N7e=a("p"),mUr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),fUr=l(),Fm=a("p"),gUr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),hUr=o("not"),uUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=a("a"),pUr=o("from_pretrained()"),_Ur=o(" to load the model weights."),bUr=l(),F(Yw.$$.fragment),vUr=l(),Qr=a("div"),F(FS.$$.fragment),FUr=l(),j7e=a("p"),TUr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),MUr=l(),Pn=a("p"),EUr=o("The model class to instantiate is selected based on the "),D7e=a("code"),CUr=o("model_type"),wUr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),AUr=o("pretrained_model_name_or_path"),LUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),yUr=o("pretrained_model_name_or_path"),xUr=o(":"),$Ur=l(),V7e=a("ul"),Kw=a("li"),X7e=a("strong"),kUr=o("tapas"),SUr=o(" \u2014 "),ote=a("a"),RUr=o("TFTapasForQuestionAnswering"),PUr=o(" (TAPAS model)"),BUr=l(),F(Zw.$$.fragment),cZe=l(),Tm=a("h2"),eA=a("a"),z7e=a("span"),F(TS.$$.fragment),IUr=l(),Q7e=a("span"),NUr=o("TFAutoModelForDocumentQuestionAnswering"),mZe=l(),_r=a("div"),F(MS.$$.fragment),qUr=l(),Mm=a("p"),jUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rte=a("a"),DUr=o("from_pretrained()"),GUr=o(" class method or the "),tte=a("a"),OUr=o("from_config()"),VUr=o(` class
method.`),XUr=l(),ES=a("p"),zUr=o("This class cannot be instantiated directly using "),W7e=a("code"),QUr=o("__init__()"),WUr=o(" (throws an error)."),UUr=l(),oa=a("div"),F(CS.$$.fragment),HUr=l(),U7e=a("p"),JUr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),YUr=l(),Em=a("p"),KUr=o(`Note:
Loading a model from its configuration file does `),H7e=a("strong"),ZUr=o("not"),eHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=a("a"),oHr=o("from_pretrained()"),rHr=o(" to load the model weights."),tHr=l(),F(oA.$$.fragment),aHr=l(),Wr=a("div"),F(wS.$$.fragment),nHr=l(),J7e=a("p"),sHr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),lHr=l(),Bn=a("p"),iHr=o("The model class to instantiate is selected based on the "),Y7e=a("code"),dHr=o("model_type"),cHr=o(` property of the config object (either
passed as an argument or loaded from `),K7e=a("code"),mHr=o("pretrained_model_name_or_path"),fHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z7e=a("code"),gHr=o("pretrained_model_name_or_path"),hHr=o(":"),uHr=l(),eLe=a("ul"),rA=a("li"),oLe=a("strong"),pHr=o("layoutlm"),_Hr=o(" \u2014 "),nte=a("a"),bHr=o("TFLayoutLMForQuestionAnswering"),vHr=o(" (LayoutLM model)"),FHr=l(),F(tA.$$.fragment),fZe=l(),Cm=a("h2"),aA=a("a"),rLe=a("span"),F(AS.$$.fragment),THr=l(),tLe=a("span"),MHr=o("TFAutoModelForTokenClassification"),gZe=l(),br=a("div"),F(LS.$$.fragment),EHr=l(),wm=a("p"),CHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ste=a("a"),wHr=o("from_pretrained()"),AHr=o(" class method or the "),lte=a("a"),LHr=o("from_config()"),yHr=o(` class
method.`),xHr=l(),yS=a("p"),$Hr=o("This class cannot be instantiated directly using "),aLe=a("code"),kHr=o("__init__()"),SHr=o(" (throws an error)."),RHr=l(),ra=a("div"),F(xS.$$.fragment),PHr=l(),nLe=a("p"),BHr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),IHr=l(),Am=a("p"),NHr=o(`Note:
Loading a model from its configuration file does `),sLe=a("strong"),qHr=o("not"),jHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=a("a"),DHr=o("from_pretrained()"),GHr=o(" to load the model weights."),OHr=l(),F(nA.$$.fragment),VHr=l(),Ur=a("div"),F($S.$$.fragment),XHr=l(),lLe=a("p"),zHr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),QHr=l(),In=a("p"),WHr=o("The model class to instantiate is selected based on the "),iLe=a("code"),UHr=o("model_type"),HHr=o(` property of the config object (either
passed as an argument or loaded from `),dLe=a("code"),JHr=o("pretrained_model_name_or_path"),YHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cLe=a("code"),KHr=o("pretrained_model_name_or_path"),ZHr=o(":"),eJr=l(),de=a("ul"),sA=a("li"),mLe=a("strong"),oJr=o("albert"),rJr=o(" \u2014 "),dte=a("a"),tJr=o("TFAlbertForTokenClassification"),aJr=o(" (ALBERT model)"),nJr=l(),lA=a("li"),fLe=a("strong"),sJr=o("bert"),lJr=o(" \u2014 "),cte=a("a"),iJr=o("TFBertForTokenClassification"),dJr=o(" (BERT model)"),cJr=l(),iA=a("li"),gLe=a("strong"),mJr=o("camembert"),fJr=o(" \u2014 "),mte=a("a"),gJr=o("TFCamembertForTokenClassification"),hJr=o(" (CamemBERT model)"),uJr=l(),dA=a("li"),hLe=a("strong"),pJr=o("convbert"),_Jr=o(" \u2014 "),fte=a("a"),bJr=o("TFConvBertForTokenClassification"),vJr=o(" (ConvBERT model)"),FJr=l(),cA=a("li"),uLe=a("strong"),TJr=o("deberta"),MJr=o(" \u2014 "),gte=a("a"),EJr=o("TFDebertaForTokenClassification"),CJr=o(" (DeBERTa model)"),wJr=l(),mA=a("li"),pLe=a("strong"),AJr=o("deberta-v2"),LJr=o(" \u2014 "),hte=a("a"),yJr=o("TFDebertaV2ForTokenClassification"),xJr=o(" (DeBERTa-v2 model)"),$Jr=l(),fA=a("li"),_Le=a("strong"),kJr=o("distilbert"),SJr=o(" \u2014 "),ute=a("a"),RJr=o("TFDistilBertForTokenClassification"),PJr=o(" (DistilBERT model)"),BJr=l(),gA=a("li"),bLe=a("strong"),IJr=o("electra"),NJr=o(" \u2014 "),pte=a("a"),qJr=o("TFElectraForTokenClassification"),jJr=o(" (ELECTRA model)"),DJr=l(),hA=a("li"),vLe=a("strong"),GJr=o("flaubert"),OJr=o(" \u2014 "),_te=a("a"),VJr=o("TFFlaubertForTokenClassification"),XJr=o(" (FlauBERT model)"),zJr=l(),uA=a("li"),FLe=a("strong"),QJr=o("funnel"),WJr=o(" \u2014 "),bte=a("a"),UJr=o("TFFunnelForTokenClassification"),HJr=o(" (Funnel Transformer model)"),JJr=l(),pA=a("li"),TLe=a("strong"),YJr=o("layoutlm"),KJr=o(" \u2014 "),vte=a("a"),ZJr=o("TFLayoutLMForTokenClassification"),eYr=o(" (LayoutLM model)"),oYr=l(),_A=a("li"),MLe=a("strong"),rYr=o("layoutlmv3"),tYr=o(" \u2014 "),Fte=a("a"),aYr=o("TFLayoutLMv3ForTokenClassification"),nYr=o(" (LayoutLMv3 model)"),sYr=l(),bA=a("li"),ELe=a("strong"),lYr=o("longformer"),iYr=o(" \u2014 "),Tte=a("a"),dYr=o("TFLongformerForTokenClassification"),cYr=o(" (Longformer model)"),mYr=l(),vA=a("li"),CLe=a("strong"),fYr=o("mobilebert"),gYr=o(" \u2014 "),Mte=a("a"),hYr=o("TFMobileBertForTokenClassification"),uYr=o(" (MobileBERT model)"),pYr=l(),FA=a("li"),wLe=a("strong"),_Yr=o("mpnet"),bYr=o(" \u2014 "),Ete=a("a"),vYr=o("TFMPNetForTokenClassification"),FYr=o(" (MPNet model)"),TYr=l(),TA=a("li"),ALe=a("strong"),MYr=o("rembert"),EYr=o(" \u2014 "),Cte=a("a"),CYr=o("TFRemBertForTokenClassification"),wYr=o(" (RemBERT model)"),AYr=l(),MA=a("li"),LLe=a("strong"),LYr=o("roberta"),yYr=o(" \u2014 "),wte=a("a"),xYr=o("TFRobertaForTokenClassification"),$Yr=o(" (RoBERTa model)"),kYr=l(),EA=a("li"),yLe=a("strong"),SYr=o("roformer"),RYr=o(" \u2014 "),Ate=a("a"),PYr=o("TFRoFormerForTokenClassification"),BYr=o(" (RoFormer model)"),IYr=l(),CA=a("li"),xLe=a("strong"),NYr=o("xlm"),qYr=o(" \u2014 "),Lte=a("a"),jYr=o("TFXLMForTokenClassification"),DYr=o(" (XLM model)"),GYr=l(),wA=a("li"),$Le=a("strong"),OYr=o("xlm-roberta"),VYr=o(" \u2014 "),yte=a("a"),XYr=o("TFXLMRobertaForTokenClassification"),zYr=o(" (XLM-RoBERTa model)"),QYr=l(),AA=a("li"),kLe=a("strong"),WYr=o("xlnet"),UYr=o(" \u2014 "),xte=a("a"),HYr=o("TFXLNetForTokenClassification"),JYr=o(" (XLNet model)"),YYr=l(),F(LA.$$.fragment),hZe=l(),Lm=a("h2"),yA=a("a"),SLe=a("span"),F(kS.$$.fragment),KYr=l(),RLe=a("span"),ZYr=o("TFAutoModelForQuestionAnswering"),uZe=l(),vr=a("div"),F(SS.$$.fragment),eKr=l(),ym=a("p"),oKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$te=a("a"),rKr=o("from_pretrained()"),tKr=o(" class method or the "),kte=a("a"),aKr=o("from_config()"),nKr=o(` class
method.`),sKr=l(),RS=a("p"),lKr=o("This class cannot be instantiated directly using "),PLe=a("code"),iKr=o("__init__()"),dKr=o(" (throws an error)."),cKr=l(),ta=a("div"),F(PS.$$.fragment),mKr=l(),BLe=a("p"),fKr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gKr=l(),xm=a("p"),hKr=o(`Note:
Loading a model from its configuration file does `),ILe=a("strong"),uKr=o("not"),pKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ste=a("a"),_Kr=o("from_pretrained()"),bKr=o(" to load the model weights."),vKr=l(),F(xA.$$.fragment),FKr=l(),Hr=a("div"),F(BS.$$.fragment),TKr=l(),NLe=a("p"),MKr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),EKr=l(),Nn=a("p"),CKr=o("The model class to instantiate is selected based on the "),qLe=a("code"),wKr=o("model_type"),AKr=o(` property of the config object (either
passed as an argument or loaded from `),jLe=a("code"),LKr=o("pretrained_model_name_or_path"),yKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DLe=a("code"),xKr=o("pretrained_model_name_or_path"),$Kr=o(":"),kKr=l(),ce=a("ul"),$A=a("li"),GLe=a("strong"),SKr=o("albert"),RKr=o(" \u2014 "),Rte=a("a"),PKr=o("TFAlbertForQuestionAnswering"),BKr=o(" (ALBERT model)"),IKr=l(),kA=a("li"),OLe=a("strong"),NKr=o("bert"),qKr=o(" \u2014 "),Pte=a("a"),jKr=o("TFBertForQuestionAnswering"),DKr=o(" (BERT model)"),GKr=l(),SA=a("li"),VLe=a("strong"),OKr=o("camembert"),VKr=o(" \u2014 "),Bte=a("a"),XKr=o("TFCamembertForQuestionAnswering"),zKr=o(" (CamemBERT model)"),QKr=l(),RA=a("li"),XLe=a("strong"),WKr=o("convbert"),UKr=o(" \u2014 "),Ite=a("a"),HKr=o("TFConvBertForQuestionAnswering"),JKr=o(" (ConvBERT model)"),YKr=l(),PA=a("li"),zLe=a("strong"),KKr=o("deberta"),ZKr=o(" \u2014 "),Nte=a("a"),eZr=o("TFDebertaForQuestionAnswering"),oZr=o(" (DeBERTa model)"),rZr=l(),BA=a("li"),QLe=a("strong"),tZr=o("deberta-v2"),aZr=o(" \u2014 "),qte=a("a"),nZr=o("TFDebertaV2ForQuestionAnswering"),sZr=o(" (DeBERTa-v2 model)"),lZr=l(),IA=a("li"),WLe=a("strong"),iZr=o("distilbert"),dZr=o(" \u2014 "),jte=a("a"),cZr=o("TFDistilBertForQuestionAnswering"),mZr=o(" (DistilBERT model)"),fZr=l(),NA=a("li"),ULe=a("strong"),gZr=o("electra"),hZr=o(" \u2014 "),Dte=a("a"),uZr=o("TFElectraForQuestionAnswering"),pZr=o(" (ELECTRA model)"),_Zr=l(),qA=a("li"),HLe=a("strong"),bZr=o("flaubert"),vZr=o(" \u2014 "),Gte=a("a"),FZr=o("TFFlaubertForQuestionAnsweringSimple"),TZr=o(" (FlauBERT model)"),MZr=l(),jA=a("li"),JLe=a("strong"),EZr=o("funnel"),CZr=o(" \u2014 "),Ote=a("a"),wZr=o("TFFunnelForQuestionAnswering"),AZr=o(" (Funnel Transformer model)"),LZr=l(),DA=a("li"),YLe=a("strong"),yZr=o("gptj"),xZr=o(" \u2014 "),Vte=a("a"),$Zr=o("TFGPTJForQuestionAnswering"),kZr=o(" (GPT-J model)"),SZr=l(),GA=a("li"),KLe=a("strong"),RZr=o("layoutlmv3"),PZr=o(" \u2014 "),Xte=a("a"),BZr=o("TFLayoutLMv3ForQuestionAnswering"),IZr=o(" (LayoutLMv3 model)"),NZr=l(),OA=a("li"),ZLe=a("strong"),qZr=o("longformer"),jZr=o(" \u2014 "),zte=a("a"),DZr=o("TFLongformerForQuestionAnswering"),GZr=o(" (Longformer model)"),OZr=l(),VA=a("li"),eye=a("strong"),VZr=o("mobilebert"),XZr=o(" \u2014 "),Qte=a("a"),zZr=o("TFMobileBertForQuestionAnswering"),QZr=o(" (MobileBERT model)"),WZr=l(),XA=a("li"),oye=a("strong"),UZr=o("mpnet"),HZr=o(" \u2014 "),Wte=a("a"),JZr=o("TFMPNetForQuestionAnswering"),YZr=o(" (MPNet model)"),KZr=l(),zA=a("li"),rye=a("strong"),ZZr=o("rembert"),eet=o(" \u2014 "),Ute=a("a"),oet=o("TFRemBertForQuestionAnswering"),ret=o(" (RemBERT model)"),tet=l(),QA=a("li"),tye=a("strong"),aet=o("roberta"),net=o(" \u2014 "),Hte=a("a"),set=o("TFRobertaForQuestionAnswering"),iet=o(" (RoBERTa model)"),det=l(),WA=a("li"),aye=a("strong"),cet=o("roformer"),met=o(" \u2014 "),Jte=a("a"),fet=o("TFRoFormerForQuestionAnswering"),get=o(" (RoFormer model)"),het=l(),UA=a("li"),nye=a("strong"),uet=o("xlm"),pet=o(" \u2014 "),Yte=a("a"),_et=o("TFXLMForQuestionAnsweringSimple"),bet=o(" (XLM model)"),vet=l(),HA=a("li"),sye=a("strong"),Fet=o("xlm-roberta"),Tet=o(" \u2014 "),Kte=a("a"),Met=o("TFXLMRobertaForQuestionAnswering"),Eet=o(" (XLM-RoBERTa model)"),Cet=l(),JA=a("li"),lye=a("strong"),wet=o("xlnet"),Aet=o(" \u2014 "),Zte=a("a"),Let=o("TFXLNetForQuestionAnsweringSimple"),yet=o(" (XLNet model)"),xet=l(),F(YA.$$.fragment),pZe=l(),$m=a("h2"),KA=a("a"),iye=a("span"),F(IS.$$.fragment),$et=l(),dye=a("span"),ket=o("TFAutoModelForVision2Seq"),_Ze=l(),Fr=a("div"),F(NS.$$.fragment),Set=l(),km=a("p"),Ret=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=a("a"),Pet=o("from_pretrained()"),Bet=o(" class method or the "),oae=a("a"),Iet=o("from_config()"),Net=o(` class
method.`),qet=l(),qS=a("p"),jet=o("This class cannot be instantiated directly using "),cye=a("code"),Det=o("__init__()"),Get=o(" (throws an error)."),Oet=l(),aa=a("div"),F(jS.$$.fragment),Vet=l(),mye=a("p"),Xet=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zet=l(),Sm=a("p"),Qet=o(`Note:
Loading a model from its configuration file does `),fye=a("strong"),Wet=o("not"),Uet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=a("a"),Het=o("from_pretrained()"),Jet=o(" to load the model weights."),Yet=l(),F(ZA.$$.fragment),Ket=l(),Jr=a("div"),F(DS.$$.fragment),Zet=l(),gye=a("p"),eot=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oot=l(),qn=a("p"),rot=o("The model class to instantiate is selected based on the "),hye=a("code"),tot=o("model_type"),aot=o(` property of the config object (either
passed as an argument or loaded from `),uye=a("code"),not=o("pretrained_model_name_or_path"),sot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pye=a("code"),lot=o("pretrained_model_name_or_path"),iot=o(":"),dot=l(),_ye=a("ul"),e6=a("li"),bye=a("strong"),cot=o("vision-encoder-decoder"),mot=o(" \u2014 "),tae=a("a"),fot=o("TFVisionEncoderDecoderModel"),got=o(" (Vision Encoder decoder model)"),hot=l(),F(o6.$$.fragment),bZe=l(),Rm=a("h2"),r6=a("a"),vye=a("span"),F(GS.$$.fragment),uot=l(),Fye=a("span"),pot=o("TFAutoModelForSpeechSeq2Seq"),vZe=l(),Tr=a("div"),F(OS.$$.fragment),_ot=l(),Pm=a("p"),bot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),aae=a("a"),vot=o("from_pretrained()"),Fot=o(" class method or the "),nae=a("a"),Tot=o("from_config()"),Mot=o(` class
method.`),Eot=l(),VS=a("p"),Cot=o("This class cannot be instantiated directly using "),Tye=a("code"),wot=o("__init__()"),Aot=o(" (throws an error)."),Lot=l(),na=a("div"),F(XS.$$.fragment),yot=l(),Mye=a("p"),xot=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$ot=l(),Bm=a("p"),kot=o(`Note:
Loading a model from its configuration file does `),Eye=a("strong"),Sot=o("not"),Rot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=a("a"),Pot=o("from_pretrained()"),Bot=o(" to load the model weights."),Iot=l(),F(t6.$$.fragment),Not=l(),Yr=a("div"),F(zS.$$.fragment),qot=l(),Cye=a("p"),jot=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dot=l(),jn=a("p"),Got=o("The model class to instantiate is selected based on the "),wye=a("code"),Oot=o("model_type"),Vot=o(` property of the config object (either
passed as an argument or loaded from `),Aye=a("code"),Xot=o("pretrained_model_name_or_path"),zot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lye=a("code"),Qot=o("pretrained_model_name_or_path"),Wot=o(":"),Uot=l(),yye=a("ul"),a6=a("li"),xye=a("strong"),Hot=o("speech_to_text"),Jot=o(" \u2014 "),lae=a("a"),Yot=o("TFSpeech2TextForConditionalGeneration"),Kot=o(" (Speech2Text model)"),Zot=l(),F(n6.$$.fragment),FZe=l(),Im=a("h2"),s6=a("a"),$ye=a("span"),F(QS.$$.fragment),ert=l(),kye=a("span"),ort=o("FlaxAutoModel"),TZe=l(),Mr=a("div"),F(WS.$$.fragment),rrt=l(),Nm=a("p"),trt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),iae=a("a"),art=o("from_pretrained()"),nrt=o(" class method or the "),dae=a("a"),srt=o("from_config()"),lrt=o(` class
method.`),irt=l(),US=a("p"),drt=o("This class cannot be instantiated directly using "),Sye=a("code"),crt=o("__init__()"),mrt=o(" (throws an error)."),frt=l(),sa=a("div"),F(HS.$$.fragment),grt=l(),Rye=a("p"),hrt=o("Instantiates one of the base model classes of the library from a configuration."),urt=l(),qm=a("p"),prt=o(`Note:
Loading a model from its configuration file does `),Pye=a("strong"),_rt=o("not"),brt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=a("a"),vrt=o("from_pretrained()"),Frt=o(" to load the model weights."),Trt=l(),F(l6.$$.fragment),Mrt=l(),Kr=a("div"),F(JS.$$.fragment),Ert=l(),Bye=a("p"),Crt=o("Instantiate one of the base model classes of the library from a pretrained model."),wrt=l(),Dn=a("p"),Art=o("The model class to instantiate is selected based on the "),Iye=a("code"),Lrt=o("model_type"),yrt=o(` property of the config object (either
passed as an argument or loaded from `),Nye=a("code"),xrt=o("pretrained_model_name_or_path"),$rt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=a("code"),krt=o("pretrained_model_name_or_path"),Srt=o(":"),Rrt=l(),te=a("ul"),i6=a("li"),jye=a("strong"),Prt=o("albert"),Brt=o(" \u2014 "),mae=a("a"),Irt=o("FlaxAlbertModel"),Nrt=o(" (ALBERT model)"),qrt=l(),d6=a("li"),Dye=a("strong"),jrt=o("bart"),Drt=o(" \u2014 "),fae=a("a"),Grt=o("FlaxBartModel"),Ort=o(" (BART model)"),Vrt=l(),c6=a("li"),Gye=a("strong"),Xrt=o("beit"),zrt=o(" \u2014 "),gae=a("a"),Qrt=o("FlaxBeitModel"),Wrt=o(" (BEiT model)"),Urt=l(),m6=a("li"),Oye=a("strong"),Hrt=o("bert"),Jrt=o(" \u2014 "),hae=a("a"),Yrt=o("FlaxBertModel"),Krt=o(" (BERT model)"),Zrt=l(),f6=a("li"),Vye=a("strong"),ett=o("big_bird"),ott=o(" \u2014 "),uae=a("a"),rtt=o("FlaxBigBirdModel"),ttt=o(" (BigBird model)"),att=l(),g6=a("li"),Xye=a("strong"),ntt=o("blenderbot"),stt=o(" \u2014 "),pae=a("a"),ltt=o("FlaxBlenderbotModel"),itt=o(" (Blenderbot model)"),dtt=l(),h6=a("li"),zye=a("strong"),ctt=o("blenderbot-small"),mtt=o(" \u2014 "),_ae=a("a"),ftt=o("FlaxBlenderbotSmallModel"),gtt=o(" (BlenderbotSmall model)"),htt=l(),u6=a("li"),Qye=a("strong"),utt=o("clip"),ptt=o(" \u2014 "),bae=a("a"),_tt=o("FlaxCLIPModel"),btt=o(" (CLIP model)"),vtt=l(),p6=a("li"),Wye=a("strong"),Ftt=o("distilbert"),Ttt=o(" \u2014 "),vae=a("a"),Mtt=o("FlaxDistilBertModel"),Ett=o(" (DistilBERT model)"),Ctt=l(),_6=a("li"),Uye=a("strong"),wtt=o("electra"),Att=o(" \u2014 "),Fae=a("a"),Ltt=o("FlaxElectraModel"),ytt=o(" (ELECTRA model)"),xtt=l(),b6=a("li"),Hye=a("strong"),$tt=o("gpt2"),ktt=o(" \u2014 "),Tae=a("a"),Stt=o("FlaxGPT2Model"),Rtt=o(" (OpenAI GPT-2 model)"),Ptt=l(),v6=a("li"),Jye=a("strong"),Btt=o("gpt_neo"),Itt=o(" \u2014 "),Mae=a("a"),Ntt=o("FlaxGPTNeoModel"),qtt=o(" (GPT Neo model)"),jtt=l(),F6=a("li"),Yye=a("strong"),Dtt=o("gptj"),Gtt=o(" \u2014 "),Eae=a("a"),Ott=o("FlaxGPTJModel"),Vtt=o(" (GPT-J model)"),Xtt=l(),T6=a("li"),Kye=a("strong"),ztt=o("longt5"),Qtt=o(" \u2014 "),Cae=a("a"),Wtt=o("FlaxLongT5Model"),Utt=o(" (LongT5 model)"),Htt=l(),M6=a("li"),Zye=a("strong"),Jtt=o("marian"),Ytt=o(" \u2014 "),wae=a("a"),Ktt=o("FlaxMarianModel"),Ztt=o(" (Marian model)"),eat=l(),E6=a("li"),e8e=a("strong"),oat=o("mbart"),rat=o(" \u2014 "),Aae=a("a"),tat=o("FlaxMBartModel"),aat=o(" (mBART model)"),nat=l(),C6=a("li"),o8e=a("strong"),sat=o("mt5"),lat=o(" \u2014 "),Lae=a("a"),iat=o("FlaxMT5Model"),dat=o(" (MT5 model)"),cat=l(),w6=a("li"),r8e=a("strong"),mat=o("opt"),fat=o(" \u2014 "),yae=a("a"),gat=o("FlaxOPTModel"),hat=o(" (OPT model)"),uat=l(),A6=a("li"),t8e=a("strong"),pat=o("pegasus"),_at=o(" \u2014 "),xae=a("a"),bat=o("FlaxPegasusModel"),vat=o(" (Pegasus model)"),Fat=l(),L6=a("li"),a8e=a("strong"),Tat=o("roberta"),Mat=o(" \u2014 "),$ae=a("a"),Eat=o("FlaxRobertaModel"),Cat=o(" (RoBERTa model)"),wat=l(),y6=a("li"),n8e=a("strong"),Aat=o("roformer"),Lat=o(" \u2014 "),kae=a("a"),yat=o("FlaxRoFormerModel"),xat=o(" (RoFormer model)"),$at=l(),x6=a("li"),s8e=a("strong"),kat=o("t5"),Sat=o(" \u2014 "),Sae=a("a"),Rat=o("FlaxT5Model"),Pat=o(" (T5 model)"),Bat=l(),$6=a("li"),l8e=a("strong"),Iat=o("vision-text-dual-encoder"),Nat=o(" \u2014 "),Rae=a("a"),qat=o("FlaxVisionTextDualEncoderModel"),jat=o(" (VisionTextDualEncoder model)"),Dat=l(),k6=a("li"),i8e=a("strong"),Gat=o("vit"),Oat=o(" \u2014 "),Pae=a("a"),Vat=o("FlaxViTModel"),Xat=o(" (ViT model)"),zat=l(),S6=a("li"),d8e=a("strong"),Qat=o("wav2vec2"),Wat=o(" \u2014 "),Bae=a("a"),Uat=o("FlaxWav2Vec2Model"),Hat=o(" (Wav2Vec2 model)"),Jat=l(),R6=a("li"),c8e=a("strong"),Yat=o("xglm"),Kat=o(" \u2014 "),Iae=a("a"),Zat=o("FlaxXGLMModel"),ent=o(" (XGLM model)"),ont=l(),P6=a("li"),m8e=a("strong"),rnt=o("xlm-roberta"),tnt=o(" \u2014 "),Nae=a("a"),ant=o("FlaxXLMRobertaModel"),nnt=o(" (XLM-RoBERTa model)"),snt=l(),F(B6.$$.fragment),MZe=l(),jm=a("h2"),I6=a("a"),f8e=a("span"),F(YS.$$.fragment),lnt=l(),g8e=a("span"),int=o("FlaxAutoModelForCausalLM"),EZe=l(),Er=a("div"),F(KS.$$.fragment),dnt=l(),Dm=a("p"),cnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qae=a("a"),mnt=o("from_pretrained()"),fnt=o(" class method or the "),jae=a("a"),gnt=o("from_config()"),hnt=o(` class
method.`),unt=l(),ZS=a("p"),pnt=o("This class cannot be instantiated directly using "),h8e=a("code"),_nt=o("__init__()"),bnt=o(" (throws an error)."),vnt=l(),la=a("div"),F(eR.$$.fragment),Fnt=l(),u8e=a("p"),Tnt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Mnt=l(),Gm=a("p"),Ent=o(`Note:
Loading a model from its configuration file does `),p8e=a("strong"),Cnt=o("not"),wnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=a("a"),Ant=o("from_pretrained()"),Lnt=o(" to load the model weights."),ynt=l(),F(N6.$$.fragment),xnt=l(),Zr=a("div"),F(oR.$$.fragment),$nt=l(),_8e=a("p"),knt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Snt=l(),Gn=a("p"),Rnt=o("The model class to instantiate is selected based on the "),b8e=a("code"),Pnt=o("model_type"),Bnt=o(` property of the config object (either
passed as an argument or loaded from `),v8e=a("code"),Int=o("pretrained_model_name_or_path"),Nnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=a("code"),qnt=o("pretrained_model_name_or_path"),jnt=o(":"),Dnt=l(),xe=a("ul"),q6=a("li"),T8e=a("strong"),Gnt=o("bart"),Ont=o(" \u2014 "),Gae=a("a"),Vnt=o("FlaxBartForCausalLM"),Xnt=o(" (BART model)"),znt=l(),j6=a("li"),M8e=a("strong"),Qnt=o("bert"),Wnt=o(" \u2014 "),Oae=a("a"),Unt=o("FlaxBertForCausalLM"),Hnt=o(" (BERT model)"),Jnt=l(),D6=a("li"),E8e=a("strong"),Ynt=o("big_bird"),Knt=o(" \u2014 "),Vae=a("a"),Znt=o("FlaxBigBirdForCausalLM"),est=o(" (BigBird model)"),ost=l(),G6=a("li"),C8e=a("strong"),rst=o("electra"),tst=o(" \u2014 "),Xae=a("a"),ast=o("FlaxElectraForCausalLM"),nst=o(" (ELECTRA model)"),sst=l(),O6=a("li"),w8e=a("strong"),lst=o("gpt2"),ist=o(" \u2014 "),zae=a("a"),dst=o("FlaxGPT2LMHeadModel"),cst=o(" (OpenAI GPT-2 model)"),mst=l(),V6=a("li"),A8e=a("strong"),fst=o("gpt_neo"),gst=o(" \u2014 "),Qae=a("a"),hst=o("FlaxGPTNeoForCausalLM"),ust=o(" (GPT Neo model)"),pst=l(),X6=a("li"),L8e=a("strong"),_st=o("gptj"),bst=o(" \u2014 "),Wae=a("a"),vst=o("FlaxGPTJForCausalLM"),Fst=o(" (GPT-J model)"),Tst=l(),z6=a("li"),y8e=a("strong"),Mst=o("opt"),Est=o(" \u2014 "),Uae=a("a"),Cst=o("FlaxOPTForCausalLM"),wst=o(" (OPT model)"),Ast=l(),Q6=a("li"),x8e=a("strong"),Lst=o("roberta"),yst=o(" \u2014 "),Hae=a("a"),xst=o("FlaxRobertaForCausalLM"),$st=o(" (RoBERTa model)"),kst=l(),W6=a("li"),$8e=a("strong"),Sst=o("xglm"),Rst=o(" \u2014 "),Jae=a("a"),Pst=o("FlaxXGLMForCausalLM"),Bst=o(" (XGLM model)"),Ist=l(),F(U6.$$.fragment),CZe=l(),Om=a("h2"),H6=a("a"),k8e=a("span"),F(rR.$$.fragment),Nst=l(),S8e=a("span"),qst=o("FlaxAutoModelForPreTraining"),wZe=l(),Cr=a("div"),F(tR.$$.fragment),jst=l(),Vm=a("p"),Dst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yae=a("a"),Gst=o("from_pretrained()"),Ost=o(" class method or the "),Kae=a("a"),Vst=o("from_config()"),Xst=o(` class
method.`),zst=l(),aR=a("p"),Qst=o("This class cannot be instantiated directly using "),R8e=a("code"),Wst=o("__init__()"),Ust=o(" (throws an error)."),Hst=l(),ia=a("div"),F(nR.$$.fragment),Jst=l(),P8e=a("p"),Yst=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Kst=l(),Xm=a("p"),Zst=o(`Note:
Loading a model from its configuration file does `),B8e=a("strong"),elt=o("not"),olt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=a("a"),rlt=o("from_pretrained()"),tlt=o(" to load the model weights."),alt=l(),F(J6.$$.fragment),nlt=l(),et=a("div"),F(sR.$$.fragment),slt=l(),I8e=a("p"),llt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ilt=l(),On=a("p"),dlt=o("The model class to instantiate is selected based on the "),N8e=a("code"),clt=o("model_type"),mlt=o(` property of the config object (either
passed as an argument or loaded from `),q8e=a("code"),flt=o("pretrained_model_name_or_path"),glt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=a("code"),hlt=o("pretrained_model_name_or_path"),ult=o(":"),plt=l(),Ee=a("ul"),Y6=a("li"),D8e=a("strong"),_lt=o("albert"),blt=o(" \u2014 "),ene=a("a"),vlt=o("FlaxAlbertForPreTraining"),Flt=o(" (ALBERT model)"),Tlt=l(),K6=a("li"),G8e=a("strong"),Mlt=o("bart"),Elt=o(" \u2014 "),one=a("a"),Clt=o("FlaxBartForConditionalGeneration"),wlt=o(" (BART model)"),Alt=l(),Z6=a("li"),O8e=a("strong"),Llt=o("bert"),ylt=o(" \u2014 "),rne=a("a"),xlt=o("FlaxBertForPreTraining"),$lt=o(" (BERT model)"),klt=l(),e7=a("li"),V8e=a("strong"),Slt=o("big_bird"),Rlt=o(" \u2014 "),tne=a("a"),Plt=o("FlaxBigBirdForPreTraining"),Blt=o(" (BigBird model)"),Ilt=l(),o7=a("li"),X8e=a("strong"),Nlt=o("electra"),qlt=o(" \u2014 "),ane=a("a"),jlt=o("FlaxElectraForPreTraining"),Dlt=o(" (ELECTRA model)"),Glt=l(),r7=a("li"),z8e=a("strong"),Olt=o("longt5"),Vlt=o(" \u2014 "),nne=a("a"),Xlt=o("FlaxLongT5ForConditionalGeneration"),zlt=o(" (LongT5 model)"),Qlt=l(),t7=a("li"),Q8e=a("strong"),Wlt=o("mbart"),Ult=o(" \u2014 "),sne=a("a"),Hlt=o("FlaxMBartForConditionalGeneration"),Jlt=o(" (mBART model)"),Ylt=l(),a7=a("li"),W8e=a("strong"),Klt=o("mt5"),Zlt=o(" \u2014 "),lne=a("a"),eit=o("FlaxMT5ForConditionalGeneration"),oit=o(" (MT5 model)"),rit=l(),n7=a("li"),U8e=a("strong"),tit=o("roberta"),ait=o(" \u2014 "),ine=a("a"),nit=o("FlaxRobertaForMaskedLM"),sit=o(" (RoBERTa model)"),lit=l(),s7=a("li"),H8e=a("strong"),iit=o("roformer"),dit=o(" \u2014 "),dne=a("a"),cit=o("FlaxRoFormerForMaskedLM"),mit=o(" (RoFormer model)"),fit=l(),l7=a("li"),J8e=a("strong"),git=o("t5"),hit=o(" \u2014 "),cne=a("a"),uit=o("FlaxT5ForConditionalGeneration"),pit=o(" (T5 model)"),_it=l(),i7=a("li"),Y8e=a("strong"),bit=o("wav2vec2"),vit=o(" \u2014 "),mne=a("a"),Fit=o("FlaxWav2Vec2ForPreTraining"),Tit=o(" (Wav2Vec2 model)"),Mit=l(),d7=a("li"),K8e=a("strong"),Eit=o("xlm-roberta"),Cit=o(" \u2014 "),fne=a("a"),wit=o("FlaxXLMRobertaForMaskedLM"),Ait=o(" (XLM-RoBERTa model)"),Lit=l(),F(c7.$$.fragment),AZe=l(),zm=a("h2"),m7=a("a"),Z8e=a("span"),F(lR.$$.fragment),yit=l(),e9e=a("span"),xit=o("FlaxAutoModelForMaskedLM"),LZe=l(),wr=a("div"),F(iR.$$.fragment),$it=l(),Qm=a("p"),kit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gne=a("a"),Sit=o("from_pretrained()"),Rit=o(" class method or the "),hne=a("a"),Pit=o("from_config()"),Bit=o(` class
method.`),Iit=l(),dR=a("p"),Nit=o("This class cannot be instantiated directly using "),o9e=a("code"),qit=o("__init__()"),jit=o(" (throws an error)."),Dit=l(),da=a("div"),F(cR.$$.fragment),Git=l(),r9e=a("p"),Oit=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Vit=l(),Wm=a("p"),Xit=o(`Note:
Loading a model from its configuration file does `),t9e=a("strong"),zit=o("not"),Qit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),une=a("a"),Wit=o("from_pretrained()"),Uit=o(" to load the model weights."),Hit=l(),F(f7.$$.fragment),Jit=l(),ot=a("div"),F(mR.$$.fragment),Yit=l(),a9e=a("p"),Kit=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Zit=l(),Vn=a("p"),edt=o("The model class to instantiate is selected based on the "),n9e=a("code"),odt=o("model_type"),rdt=o(` property of the config object (either
passed as an argument or loaded from `),s9e=a("code"),tdt=o("pretrained_model_name_or_path"),adt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=a("code"),ndt=o("pretrained_model_name_or_path"),sdt=o(":"),ldt=l(),$e=a("ul"),g7=a("li"),i9e=a("strong"),idt=o("albert"),ddt=o(" \u2014 "),pne=a("a"),cdt=o("FlaxAlbertForMaskedLM"),mdt=o(" (ALBERT model)"),fdt=l(),h7=a("li"),d9e=a("strong"),gdt=o("bart"),hdt=o(" \u2014 "),_ne=a("a"),udt=o("FlaxBartForConditionalGeneration"),pdt=o(" (BART model)"),_dt=l(),u7=a("li"),c9e=a("strong"),bdt=o("bert"),vdt=o(" \u2014 "),bne=a("a"),Fdt=o("FlaxBertForMaskedLM"),Tdt=o(" (BERT model)"),Mdt=l(),p7=a("li"),m9e=a("strong"),Edt=o("big_bird"),Cdt=o(" \u2014 "),vne=a("a"),wdt=o("FlaxBigBirdForMaskedLM"),Adt=o(" (BigBird model)"),Ldt=l(),_7=a("li"),f9e=a("strong"),ydt=o("distilbert"),xdt=o(" \u2014 "),Fne=a("a"),$dt=o("FlaxDistilBertForMaskedLM"),kdt=o(" (DistilBERT model)"),Sdt=l(),b7=a("li"),g9e=a("strong"),Rdt=o("electra"),Pdt=o(" \u2014 "),Tne=a("a"),Bdt=o("FlaxElectraForMaskedLM"),Idt=o(" (ELECTRA model)"),Ndt=l(),v7=a("li"),h9e=a("strong"),qdt=o("mbart"),jdt=o(" \u2014 "),Mne=a("a"),Ddt=o("FlaxMBartForConditionalGeneration"),Gdt=o(" (mBART model)"),Odt=l(),F7=a("li"),u9e=a("strong"),Vdt=o("roberta"),Xdt=o(" \u2014 "),Ene=a("a"),zdt=o("FlaxRobertaForMaskedLM"),Qdt=o(" (RoBERTa model)"),Wdt=l(),T7=a("li"),p9e=a("strong"),Udt=o("roformer"),Hdt=o(" \u2014 "),Cne=a("a"),Jdt=o("FlaxRoFormerForMaskedLM"),Ydt=o(" (RoFormer model)"),Kdt=l(),M7=a("li"),_9e=a("strong"),Zdt=o("xlm-roberta"),ect=o(" \u2014 "),wne=a("a"),oct=o("FlaxXLMRobertaForMaskedLM"),rct=o(" (XLM-RoBERTa model)"),tct=l(),F(E7.$$.fragment),yZe=l(),Um=a("h2"),C7=a("a"),b9e=a("span"),F(fR.$$.fragment),act=l(),v9e=a("span"),nct=o("FlaxAutoModelForSeq2SeqLM"),xZe=l(),Ar=a("div"),F(gR.$$.fragment),sct=l(),Hm=a("p"),lct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ane=a("a"),ict=o("from_pretrained()"),dct=o(" class method or the "),Lne=a("a"),cct=o("from_config()"),mct=o(` class
method.`),fct=l(),hR=a("p"),gct=o("This class cannot be instantiated directly using "),F9e=a("code"),hct=o("__init__()"),uct=o(" (throws an error)."),pct=l(),ca=a("div"),F(uR.$$.fragment),_ct=l(),T9e=a("p"),bct=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vct=l(),Jm=a("p"),Fct=o(`Note:
Loading a model from its configuration file does `),M9e=a("strong"),Tct=o("not"),Mct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=a("a"),Ect=o("from_pretrained()"),Cct=o(" to load the model weights."),wct=l(),F(w7.$$.fragment),Act=l(),rt=a("div"),F(pR.$$.fragment),Lct=l(),E9e=a("p"),yct=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xct=l(),Xn=a("p"),$ct=o("The model class to instantiate is selected based on the "),C9e=a("code"),kct=o("model_type"),Sct=o(` property of the config object (either
passed as an argument or loaded from `),w9e=a("code"),Rct=o("pretrained_model_name_or_path"),Pct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A9e=a("code"),Bct=o("pretrained_model_name_or_path"),Ict=o(":"),Nct=l(),ke=a("ul"),A7=a("li"),L9e=a("strong"),qct=o("bart"),jct=o(" \u2014 "),xne=a("a"),Dct=o("FlaxBartForConditionalGeneration"),Gct=o(" (BART model)"),Oct=l(),L7=a("li"),y9e=a("strong"),Vct=o("blenderbot"),Xct=o(" \u2014 "),$ne=a("a"),zct=o("FlaxBlenderbotForConditionalGeneration"),Qct=o(" (Blenderbot model)"),Wct=l(),y7=a("li"),x9e=a("strong"),Uct=o("blenderbot-small"),Hct=o(" \u2014 "),kne=a("a"),Jct=o("FlaxBlenderbotSmallForConditionalGeneration"),Yct=o(" (BlenderbotSmall model)"),Kct=l(),x7=a("li"),$9e=a("strong"),Zct=o("encoder-decoder"),emt=o(" \u2014 "),Sne=a("a"),omt=o("FlaxEncoderDecoderModel"),rmt=o(" (Encoder decoder model)"),tmt=l(),$7=a("li"),k9e=a("strong"),amt=o("longt5"),nmt=o(" \u2014 "),Rne=a("a"),smt=o("FlaxLongT5ForConditionalGeneration"),lmt=o(" (LongT5 model)"),imt=l(),k7=a("li"),S9e=a("strong"),dmt=o("marian"),cmt=o(" \u2014 "),Pne=a("a"),mmt=o("FlaxMarianMTModel"),fmt=o(" (Marian model)"),gmt=l(),S7=a("li"),R9e=a("strong"),hmt=o("mbart"),umt=o(" \u2014 "),Bne=a("a"),pmt=o("FlaxMBartForConditionalGeneration"),_mt=o(" (mBART model)"),bmt=l(),R7=a("li"),P9e=a("strong"),vmt=o("mt5"),Fmt=o(" \u2014 "),Ine=a("a"),Tmt=o("FlaxMT5ForConditionalGeneration"),Mmt=o(" (MT5 model)"),Emt=l(),P7=a("li"),B9e=a("strong"),Cmt=o("pegasus"),wmt=o(" \u2014 "),Nne=a("a"),Amt=o("FlaxPegasusForConditionalGeneration"),Lmt=o(" (Pegasus model)"),ymt=l(),B7=a("li"),I9e=a("strong"),xmt=o("t5"),$mt=o(" \u2014 "),qne=a("a"),kmt=o("FlaxT5ForConditionalGeneration"),Smt=o(" (T5 model)"),Rmt=l(),F(I7.$$.fragment),$Ze=l(),Ym=a("h2"),N7=a("a"),N9e=a("span"),F(_R.$$.fragment),Pmt=l(),q9e=a("span"),Bmt=o("FlaxAutoModelForSequenceClassification"),kZe=l(),Lr=a("div"),F(bR.$$.fragment),Imt=l(),Km=a("p"),Nmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),jne=a("a"),qmt=o("from_pretrained()"),jmt=o(" class method or the "),Dne=a("a"),Dmt=o("from_config()"),Gmt=o(` class
method.`),Omt=l(),vR=a("p"),Vmt=o("This class cannot be instantiated directly using "),j9e=a("code"),Xmt=o("__init__()"),zmt=o(" (throws an error)."),Qmt=l(),ma=a("div"),F(FR.$$.fragment),Wmt=l(),D9e=a("p"),Umt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hmt=l(),Zm=a("p"),Jmt=o(`Note:
Loading a model from its configuration file does `),G9e=a("strong"),Ymt=o("not"),Kmt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=a("a"),Zmt=o("from_pretrained()"),eft=o(" to load the model weights."),oft=l(),F(q7.$$.fragment),rft=l(),tt=a("div"),F(TR.$$.fragment),tft=l(),O9e=a("p"),aft=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nft=l(),zn=a("p"),sft=o("The model class to instantiate is selected based on the "),V9e=a("code"),lft=o("model_type"),ift=o(` property of the config object (either
passed as an argument or loaded from `),X9e=a("code"),dft=o("pretrained_model_name_or_path"),cft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=a("code"),mft=o("pretrained_model_name_or_path"),fft=o(":"),gft=l(),Se=a("ul"),j7=a("li"),Q9e=a("strong"),hft=o("albert"),uft=o(" \u2014 "),One=a("a"),pft=o("FlaxAlbertForSequenceClassification"),_ft=o(" (ALBERT model)"),bft=l(),D7=a("li"),W9e=a("strong"),vft=o("bart"),Fft=o(" \u2014 "),Vne=a("a"),Tft=o("FlaxBartForSequenceClassification"),Mft=o(" (BART model)"),Eft=l(),G7=a("li"),U9e=a("strong"),Cft=o("bert"),wft=o(" \u2014 "),Xne=a("a"),Aft=o("FlaxBertForSequenceClassification"),Lft=o(" (BERT model)"),yft=l(),O7=a("li"),H9e=a("strong"),xft=o("big_bird"),$ft=o(" \u2014 "),zne=a("a"),kft=o("FlaxBigBirdForSequenceClassification"),Sft=o(" (BigBird model)"),Rft=l(),V7=a("li"),J9e=a("strong"),Pft=o("distilbert"),Bft=o(" \u2014 "),Qne=a("a"),Ift=o("FlaxDistilBertForSequenceClassification"),Nft=o(" (DistilBERT model)"),qft=l(),X7=a("li"),Y9e=a("strong"),jft=o("electra"),Dft=o(" \u2014 "),Wne=a("a"),Gft=o("FlaxElectraForSequenceClassification"),Oft=o(" (ELECTRA model)"),Vft=l(),z7=a("li"),K9e=a("strong"),Xft=o("mbart"),zft=o(" \u2014 "),Une=a("a"),Qft=o("FlaxMBartForSequenceClassification"),Wft=o(" (mBART model)"),Uft=l(),Q7=a("li"),Z9e=a("strong"),Hft=o("roberta"),Jft=o(" \u2014 "),Hne=a("a"),Yft=o("FlaxRobertaForSequenceClassification"),Kft=o(" (RoBERTa model)"),Zft=l(),W7=a("li"),exe=a("strong"),egt=o("roformer"),ogt=o(" \u2014 "),Jne=a("a"),rgt=o("FlaxRoFormerForSequenceClassification"),tgt=o(" (RoFormer model)"),agt=l(),U7=a("li"),oxe=a("strong"),ngt=o("xlm-roberta"),sgt=o(" \u2014 "),Yne=a("a"),lgt=o("FlaxXLMRobertaForSequenceClassification"),igt=o(" (XLM-RoBERTa model)"),dgt=l(),F(H7.$$.fragment),SZe=l(),ef=a("h2"),J7=a("a"),rxe=a("span"),F(MR.$$.fragment),cgt=l(),txe=a("span"),mgt=o("FlaxAutoModelForQuestionAnswering"),RZe=l(),yr=a("div"),F(ER.$$.fragment),fgt=l(),of=a("p"),ggt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kne=a("a"),hgt=o("from_pretrained()"),ugt=o(" class method or the "),Zne=a("a"),pgt=o("from_config()"),_gt=o(` class
method.`),bgt=l(),CR=a("p"),vgt=o("This class cannot be instantiated directly using "),axe=a("code"),Fgt=o("__init__()"),Tgt=o(" (throws an error)."),Mgt=l(),fa=a("div"),F(wR.$$.fragment),Egt=l(),nxe=a("p"),Cgt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),wgt=l(),rf=a("p"),Agt=o(`Note:
Loading a model from its configuration file does `),sxe=a("strong"),Lgt=o("not"),ygt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ese=a("a"),xgt=o("from_pretrained()"),$gt=o(" to load the model weights."),kgt=l(),F(Y7.$$.fragment),Sgt=l(),at=a("div"),F(AR.$$.fragment),Rgt=l(),lxe=a("p"),Pgt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Bgt=l(),Qn=a("p"),Igt=o("The model class to instantiate is selected based on the "),ixe=a("code"),Ngt=o("model_type"),qgt=o(` property of the config object (either
passed as an argument or loaded from `),dxe=a("code"),jgt=o("pretrained_model_name_or_path"),Dgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cxe=a("code"),Ggt=o("pretrained_model_name_or_path"),Ogt=o(":"),Vgt=l(),Re=a("ul"),K7=a("li"),mxe=a("strong"),Xgt=o("albert"),zgt=o(" \u2014 "),ose=a("a"),Qgt=o("FlaxAlbertForQuestionAnswering"),Wgt=o(" (ALBERT model)"),Ugt=l(),Z7=a("li"),fxe=a("strong"),Hgt=o("bart"),Jgt=o(" \u2014 "),rse=a("a"),Ygt=o("FlaxBartForQuestionAnswering"),Kgt=o(" (BART model)"),Zgt=l(),eL=a("li"),gxe=a("strong"),eht=o("bert"),oht=o(" \u2014 "),tse=a("a"),rht=o("FlaxBertForQuestionAnswering"),tht=o(" (BERT model)"),aht=l(),oL=a("li"),hxe=a("strong"),nht=o("big_bird"),sht=o(" \u2014 "),ase=a("a"),lht=o("FlaxBigBirdForQuestionAnswering"),iht=o(" (BigBird model)"),dht=l(),rL=a("li"),uxe=a("strong"),cht=o("distilbert"),mht=o(" \u2014 "),nse=a("a"),fht=o("FlaxDistilBertForQuestionAnswering"),ght=o(" (DistilBERT model)"),hht=l(),tL=a("li"),pxe=a("strong"),uht=o("electra"),pht=o(" \u2014 "),sse=a("a"),_ht=o("FlaxElectraForQuestionAnswering"),bht=o(" (ELECTRA model)"),vht=l(),aL=a("li"),_xe=a("strong"),Fht=o("mbart"),Tht=o(" \u2014 "),lse=a("a"),Mht=o("FlaxMBartForQuestionAnswering"),Eht=o(" (mBART model)"),Cht=l(),nL=a("li"),bxe=a("strong"),wht=o("roberta"),Aht=o(" \u2014 "),ise=a("a"),Lht=o("FlaxRobertaForQuestionAnswering"),yht=o(" (RoBERTa model)"),xht=l(),sL=a("li"),vxe=a("strong"),$ht=o("roformer"),kht=o(" \u2014 "),dse=a("a"),Sht=o("FlaxRoFormerForQuestionAnswering"),Rht=o(" (RoFormer model)"),Pht=l(),lL=a("li"),Fxe=a("strong"),Bht=o("xlm-roberta"),Iht=o(" \u2014 "),cse=a("a"),Nht=o("FlaxXLMRobertaForQuestionAnswering"),qht=o(" (XLM-RoBERTa model)"),jht=l(),F(iL.$$.fragment),PZe=l(),tf=a("h2"),dL=a("a"),Txe=a("span"),F(LR.$$.fragment),Dht=l(),Mxe=a("span"),Ght=o("FlaxAutoModelForTokenClassification"),BZe=l(),xr=a("div"),F(yR.$$.fragment),Oht=l(),af=a("p"),Vht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mse=a("a"),Xht=o("from_pretrained()"),zht=o(" class method or the "),fse=a("a"),Qht=o("from_config()"),Wht=o(` class
method.`),Uht=l(),xR=a("p"),Hht=o("This class cannot be instantiated directly using "),Exe=a("code"),Jht=o("__init__()"),Yht=o(" (throws an error)."),Kht=l(),ga=a("div"),F($R.$$.fragment),Zht=l(),Cxe=a("p"),eut=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),out=l(),nf=a("p"),rut=o(`Note:
Loading a model from its configuration file does `),wxe=a("strong"),tut=o("not"),aut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=a("a"),nut=o("from_pretrained()"),sut=o(" to load the model weights."),lut=l(),F(cL.$$.fragment),iut=l(),nt=a("div"),F(kR.$$.fragment),dut=l(),Axe=a("p"),cut=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),mut=l(),Wn=a("p"),fut=o("The model class to instantiate is selected based on the "),Lxe=a("code"),gut=o("model_type"),hut=o(` property of the config object (either
passed as an argument or loaded from `),yxe=a("code"),uut=o("pretrained_model_name_or_path"),put=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xxe=a("code"),_ut=o("pretrained_model_name_or_path"),but=o(":"),vut=l(),Xe=a("ul"),mL=a("li"),$xe=a("strong"),Fut=o("albert"),Tut=o(" \u2014 "),hse=a("a"),Mut=o("FlaxAlbertForTokenClassification"),Eut=o(" (ALBERT model)"),Cut=l(),fL=a("li"),kxe=a("strong"),wut=o("bert"),Aut=o(" \u2014 "),use=a("a"),Lut=o("FlaxBertForTokenClassification"),yut=o(" (BERT model)"),xut=l(),gL=a("li"),Sxe=a("strong"),$ut=o("big_bird"),kut=o(" \u2014 "),pse=a("a"),Sut=o("FlaxBigBirdForTokenClassification"),Rut=o(" (BigBird model)"),Put=l(),hL=a("li"),Rxe=a("strong"),But=o("distilbert"),Iut=o(" \u2014 "),_se=a("a"),Nut=o("FlaxDistilBertForTokenClassification"),qut=o(" (DistilBERT model)"),jut=l(),uL=a("li"),Pxe=a("strong"),Dut=o("electra"),Gut=o(" \u2014 "),bse=a("a"),Out=o("FlaxElectraForTokenClassification"),Vut=o(" (ELECTRA model)"),Xut=l(),pL=a("li"),Bxe=a("strong"),zut=o("roberta"),Qut=o(" \u2014 "),vse=a("a"),Wut=o("FlaxRobertaForTokenClassification"),Uut=o(" (RoBERTa model)"),Hut=l(),_L=a("li"),Ixe=a("strong"),Jut=o("roformer"),Yut=o(" \u2014 "),Fse=a("a"),Kut=o("FlaxRoFormerForTokenClassification"),Zut=o(" (RoFormer model)"),ept=l(),bL=a("li"),Nxe=a("strong"),opt=o("xlm-roberta"),rpt=o(" \u2014 "),Tse=a("a"),tpt=o("FlaxXLMRobertaForTokenClassification"),apt=o(" (XLM-RoBERTa model)"),npt=l(),F(vL.$$.fragment),IZe=l(),sf=a("h2"),FL=a("a"),qxe=a("span"),F(SR.$$.fragment),spt=l(),jxe=a("span"),lpt=o("FlaxAutoModelForMultipleChoice"),NZe=l(),$r=a("div"),F(RR.$$.fragment),ipt=l(),lf=a("p"),dpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Mse=a("a"),cpt=o("from_pretrained()"),mpt=o(" class method or the "),Ese=a("a"),fpt=o("from_config()"),gpt=o(` class
method.`),hpt=l(),PR=a("p"),upt=o("This class cannot be instantiated directly using "),Dxe=a("code"),ppt=o("__init__()"),_pt=o(" (throws an error)."),bpt=l(),ha=a("div"),F(BR.$$.fragment),vpt=l(),Gxe=a("p"),Fpt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tpt=l(),df=a("p"),Mpt=o(`Note:
Loading a model from its configuration file does `),Oxe=a("strong"),Ept=o("not"),Cpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=a("a"),wpt=o("from_pretrained()"),Apt=o(" to load the model weights."),Lpt=l(),F(TL.$$.fragment),ypt=l(),st=a("div"),F(IR.$$.fragment),xpt=l(),Vxe=a("p"),$pt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kpt=l(),Un=a("p"),Spt=o("The model class to instantiate is selected based on the "),Xxe=a("code"),Rpt=o("model_type"),Ppt=o(` property of the config object (either
passed as an argument or loaded from `),zxe=a("code"),Bpt=o("pretrained_model_name_or_path"),Ipt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qxe=a("code"),Npt=o("pretrained_model_name_or_path"),qpt=o(":"),jpt=l(),ze=a("ul"),ML=a("li"),Wxe=a("strong"),Dpt=o("albert"),Gpt=o(" \u2014 "),wse=a("a"),Opt=o("FlaxAlbertForMultipleChoice"),Vpt=o(" (ALBERT model)"),Xpt=l(),EL=a("li"),Uxe=a("strong"),zpt=o("bert"),Qpt=o(" \u2014 "),Ase=a("a"),Wpt=o("FlaxBertForMultipleChoice"),Upt=o(" (BERT model)"),Hpt=l(),CL=a("li"),Hxe=a("strong"),Jpt=o("big_bird"),Ypt=o(" \u2014 "),Lse=a("a"),Kpt=o("FlaxBigBirdForMultipleChoice"),Zpt=o(" (BigBird model)"),e_t=l(),wL=a("li"),Jxe=a("strong"),o_t=o("distilbert"),r_t=o(" \u2014 "),yse=a("a"),t_t=o("FlaxDistilBertForMultipleChoice"),a_t=o(" (DistilBERT model)"),n_t=l(),AL=a("li"),Yxe=a("strong"),s_t=o("electra"),l_t=o(" \u2014 "),xse=a("a"),i_t=o("FlaxElectraForMultipleChoice"),d_t=o(" (ELECTRA model)"),c_t=l(),LL=a("li"),Kxe=a("strong"),m_t=o("roberta"),f_t=o(" \u2014 "),$se=a("a"),g_t=o("FlaxRobertaForMultipleChoice"),h_t=o(" (RoBERTa model)"),u_t=l(),yL=a("li"),Zxe=a("strong"),p_t=o("roformer"),__t=o(" \u2014 "),kse=a("a"),b_t=o("FlaxRoFormerForMultipleChoice"),v_t=o(" (RoFormer model)"),F_t=l(),xL=a("li"),e$e=a("strong"),T_t=o("xlm-roberta"),M_t=o(" \u2014 "),Sse=a("a"),E_t=o("FlaxXLMRobertaForMultipleChoice"),C_t=o(" (XLM-RoBERTa model)"),w_t=l(),F($L.$$.fragment),qZe=l(),cf=a("h2"),kL=a("a"),o$e=a("span"),F(NR.$$.fragment),A_t=l(),r$e=a("span"),L_t=o("FlaxAutoModelForNextSentencePrediction"),jZe=l(),kr=a("div"),F(qR.$$.fragment),y_t=l(),mf=a("p"),x_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Rse=a("a"),$_t=o("from_pretrained()"),k_t=o(" class method or the "),Pse=a("a"),S_t=o("from_config()"),R_t=o(` class
method.`),P_t=l(),jR=a("p"),B_t=o("This class cannot be instantiated directly using "),t$e=a("code"),I_t=o("__init__()"),N_t=o(" (throws an error)."),q_t=l(),ua=a("div"),F(DR.$$.fragment),j_t=l(),a$e=a("p"),D_t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),G_t=l(),ff=a("p"),O_t=o(`Note:
Loading a model from its configuration file does `),n$e=a("strong"),V_t=o("not"),X_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bse=a("a"),z_t=o("from_pretrained()"),Q_t=o(" to load the model weights."),W_t=l(),F(SL.$$.fragment),U_t=l(),lt=a("div"),F(GR.$$.fragment),H_t=l(),s$e=a("p"),J_t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Y_t=l(),Hn=a("p"),K_t=o("The model class to instantiate is selected based on the "),l$e=a("code"),Z_t=o("model_type"),e2t=o(` property of the config object (either
passed as an argument or loaded from `),i$e=a("code"),o2t=o("pretrained_model_name_or_path"),r2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=a("code"),t2t=o("pretrained_model_name_or_path"),a2t=o(":"),n2t=l(),c$e=a("ul"),RL=a("li"),m$e=a("strong"),s2t=o("bert"),l2t=o(" \u2014 "),Ise=a("a"),i2t=o("FlaxBertForNextSentencePrediction"),d2t=o(" (BERT model)"),c2t=l(),F(PL.$$.fragment),DZe=l(),gf=a("h2"),BL=a("a"),f$e=a("span"),F(OR.$$.fragment),m2t=l(),g$e=a("span"),f2t=o("FlaxAutoModelForImageClassification"),GZe=l(),Sr=a("div"),F(VR.$$.fragment),g2t=l(),hf=a("p"),h2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nse=a("a"),u2t=o("from_pretrained()"),p2t=o(" class method or the "),qse=a("a"),_2t=o("from_config()"),b2t=o(` class
method.`),v2t=l(),XR=a("p"),F2t=o("This class cannot be instantiated directly using "),h$e=a("code"),T2t=o("__init__()"),M2t=o(" (throws an error)."),E2t=l(),pa=a("div"),F(zR.$$.fragment),C2t=l(),u$e=a("p"),w2t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),A2t=l(),uf=a("p"),L2t=o(`Note:
Loading a model from its configuration file does `),p$e=a("strong"),y2t=o("not"),x2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=a("a"),$2t=o("from_pretrained()"),k2t=o(" to load the model weights."),S2t=l(),F(IL.$$.fragment),R2t=l(),it=a("div"),F(QR.$$.fragment),P2t=l(),_$e=a("p"),B2t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),I2t=l(),Jn=a("p"),N2t=o("The model class to instantiate is selected based on the "),b$e=a("code"),q2t=o("model_type"),j2t=o(` property of the config object (either
passed as an argument or loaded from `),v$e=a("code"),D2t=o("pretrained_model_name_or_path"),G2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=a("code"),O2t=o("pretrained_model_name_or_path"),V2t=o(":"),X2t=l(),WR=a("ul"),NL=a("li"),T$e=a("strong"),z2t=o("beit"),Q2t=o(" \u2014 "),Dse=a("a"),W2t=o("FlaxBeitForImageClassification"),U2t=o(" (BEiT model)"),H2t=l(),qL=a("li"),M$e=a("strong"),J2t=o("vit"),Y2t=o(" \u2014 "),Gse=a("a"),K2t=o("FlaxViTForImageClassification"),Z2t=o(" (ViT model)"),ebt=l(),F(jL.$$.fragment),OZe=l(),pf=a("h2"),DL=a("a"),E$e=a("span"),F(UR.$$.fragment),obt=l(),C$e=a("span"),rbt=o("FlaxAutoModelForVision2Seq"),VZe=l(),Rr=a("div"),F(HR.$$.fragment),tbt=l(),_f=a("p"),abt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ose=a("a"),nbt=o("from_pretrained()"),sbt=o(" class method or the "),Vse=a("a"),lbt=o("from_config()"),ibt=o(` class
method.`),dbt=l(),JR=a("p"),cbt=o("This class cannot be instantiated directly using "),w$e=a("code"),mbt=o("__init__()"),fbt=o(" (throws an error)."),gbt=l(),_a=a("div"),F(YR.$$.fragment),hbt=l(),A$e=a("p"),ubt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pbt=l(),bf=a("p"),_bt=o(`Note:
Loading a model from its configuration file does `),L$e=a("strong"),bbt=o("not"),vbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=a("a"),Fbt=o("from_pretrained()"),Tbt=o(" to load the model weights."),Mbt=l(),F(GL.$$.fragment),Ebt=l(),dt=a("div"),F(KR.$$.fragment),Cbt=l(),y$e=a("p"),wbt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Abt=l(),Yn=a("p"),Lbt=o("The model class to instantiate is selected based on the "),x$e=a("code"),ybt=o("model_type"),xbt=o(` property of the config object (either
passed as an argument or loaded from `),$$e=a("code"),$bt=o("pretrained_model_name_or_path"),kbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=a("code"),Sbt=o("pretrained_model_name_or_path"),Rbt=o(":"),Pbt=l(),S$e=a("ul"),OL=a("li"),R$e=a("strong"),Bbt=o("vision-encoder-decoder"),Ibt=o(" \u2014 "),zse=a("a"),Nbt=o("FlaxVisionEncoderDecoderModel"),qbt=o(" (Vision Encoder decoder model)"),jbt=l(),F(VL.$$.fragment),this.h()},l(m){const _=jfa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var ZR=s(u);f=n(ZR,"A",{id:!0,class:!0,href:!0});var P$e=s(f);p=n(P$e,"SPAN",{});var B$e=s(p);T(d.$$.fragment,B$e),B$e.forEach(t),P$e.forEach(t),h=i(ZR),yo=n(ZR,"SPAN",{});var I$e=s(yo);rd=r(I$e,"Auto Classes"),I$e.forEach(t),ZR.forEach(t),Mf=i(m),pt=n(m,"P",{});var eP=s(pt);td=r(eP,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=n(eP,"CODE",{});var N$e=s(ad);v9=r(N$e,"from_pretrained()"),N$e.forEach(t),Ef=r(eP,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),eP.forEach(t),Ve=i(m),He=n(m,"P",{});var Kn=s(He);nd=r(Kn,"Instantiating one of "),Zn=n(Kn,"A",{href:!0});var q$e=s(Zn);F9=r(q$e,"AutoConfig"),q$e.forEach(t),es=r(Kn,", "),os=n(Kn,"A",{href:!0});var j$e=s(os);T9=r(j$e,"AutoModel"),j$e.forEach(t),sd=r(Kn,`, and
`),rs=n(Kn,"A",{href:!0});var D$e=s(rs);M9=r(D$e,"AutoTokenizer"),D$e.forEach(t),ld=r(Kn," will directly create a class of the relevant architecture. For instance"),Kn.forEach(t),Cf=i(m),T(Qa.$$.fragment,m),Je=i(m),Ae=n(m,"P",{});var oP=s(Ae);CB=r(oP,"will create a model that is an instance of "),id=n(oP,"A",{href:!0});var G$e=s(id);wB=r(G$e,"BertModel"),G$e.forEach(t),AB=r(oP,"."),oP.forEach(t),xo=i(m),Wa=n(m,"P",{});var rP=s(Wa);LB=r(rP,"There is one class of "),wf=n(rP,"CODE",{});var O$e=s(wf);yB=r(O$e,"AutoModel"),O$e.forEach(t),iro=r(rP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),rP.forEach(t),kYe=i(m),dd=n(m,"H2",{class:!0});var tP=s(dd);Af=n(tP,"A",{id:!0,class:!0,href:!0});var V$e=s(Af);Hie=n(V$e,"SPAN",{});var X$e=s(Hie);T(E9.$$.fragment,X$e),X$e.forEach(t),V$e.forEach(t),dro=i(tP),Jie=n(tP,"SPAN",{});var z$e=s(Jie);cro=r(z$e,"Extending the Auto Classes"),z$e.forEach(t),tP.forEach(t),SYe=i(m),ts=n(m,"P",{});var vf=s(ts);mro=r(vf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yie=n(vf,"CODE",{});var Q$e=s(Yie);fro=r(Q$e,"NewModel"),Q$e.forEach(t),gro=r(vf,", make sure you have a "),Kie=n(vf,"CODE",{});var W$e=s(Kie);hro=r(W$e,"NewModelConfig"),W$e.forEach(t),uro=r(vf,` then you can add those to the auto
classes like this:`),vf.forEach(t),RYe=i(m),T(C9.$$.fragment,m),PYe=i(m),xB=n(m,"P",{});var U$e=s(xB);pro=r(U$e,"You will then be able to use the auto classes like you would usually do!"),U$e.forEach(t),BYe=i(m),T(Lf.$$.fragment,m),IYe=i(m),cd=n(m,"H2",{class:!0});var aP=s(cd);yf=n(aP,"A",{id:!0,class:!0,href:!0});var H$e=s(yf);Zie=n(H$e,"SPAN",{});var J$e=s(Zie);T(w9.$$.fragment,J$e),J$e.forEach(t),H$e.forEach(t),_ro=i(aP),ede=n(aP,"SPAN",{});var Y$e=s(ede);bro=r(Y$e,"AutoConfig"),Y$e.forEach(t),aP.forEach(t),NYe=i(m),$o=n(m,"DIV",{class:!0});var ht=s($o);T(A9.$$.fragment,ht),vro=i(ht),L9=n(ht,"P",{});var nP=s(L9);Fro=r(nP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),$B=n(nP,"A",{href:!0});var K$e=s($B);Tro=r(K$e,"from_pretrained()"),K$e.forEach(t),Mro=r(nP," class method."),nP.forEach(t),Ero=i(ht),y9=n(ht,"P",{});var sP=s(y9);Cro=r(sP,"This class cannot be instantiated directly using "),ode=n(sP,"CODE",{});var Z$e=s(ode);wro=r(Z$e,"__init__()"),Z$e.forEach(t),Aro=r(sP," (throws an error)."),sP.forEach(t),Lro=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(x9.$$.fragment,ut),yro=i(ut),rde=n(ut,"P",{});var eke=s(rde);xro=r(eke,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),eke.forEach(t),$ro=i(ut),md=n(ut,"P",{});var Ff=s(md);kro=r(Ff,"The configuration class to instantiate is selected based on the "),tde=n(Ff,"CODE",{});var oke=s(tde);Sro=r(oke,"model_type"),oke.forEach(t),Rro=r(Ff,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ade=n(Ff,"CODE",{});var rke=s(ade);Pro=r(rke,"pretrained_model_name_or_path"),rke.forEach(t),Bro=r(Ff,":"),Ff.forEach(t),Iro=i(ut),A=n(ut,"UL",{});var L=s(A);xf=n(L,"LI",{});var XL=s(xf);nde=n(XL,"STRONG",{});var tke=s(nde);Nro=r(tke,"albert"),tke.forEach(t),qro=r(XL," \u2014 "),kB=n(XL,"A",{href:!0});var ake=s(kB);jro=r(ake,"AlbertConfig"),ake.forEach(t),Dro=r(XL," (ALBERT model)"),XL.forEach(t),Gro=i(L),$f=n(L,"LI",{});var zL=s($f);sde=n(zL,"STRONG",{});var nke=s(sde);Oro=r(nke,"bart"),nke.forEach(t),Vro=r(zL," \u2014 "),SB=n(zL,"A",{href:!0});var ske=s(SB);Xro=r(ske,"BartConfig"),ske.forEach(t),zro=r(zL," (BART model)"),zL.forEach(t),Qro=i(L),kf=n(L,"LI",{});var QL=s(kf);lde=n(QL,"STRONG",{});var lke=s(lde);Wro=r(lke,"beit"),lke.forEach(t),Uro=r(QL," \u2014 "),RB=n(QL,"A",{href:!0});var ike=s(RB);Hro=r(ike,"BeitConfig"),ike.forEach(t),Jro=r(QL," (BEiT model)"),QL.forEach(t),Yro=i(L),Sf=n(L,"LI",{});var WL=s(Sf);ide=n(WL,"STRONG",{});var dke=s(ide);Kro=r(dke,"bert"),dke.forEach(t),Zro=r(WL," \u2014 "),PB=n(WL,"A",{href:!0});var cke=s(PB);eto=r(cke,"BertConfig"),cke.forEach(t),oto=r(WL," (BERT model)"),WL.forEach(t),rto=i(L),Rf=n(L,"LI",{});var UL=s(Rf);dde=n(UL,"STRONG",{});var mke=s(dde);tto=r(mke,"bert-generation"),mke.forEach(t),ato=r(UL," \u2014 "),BB=n(UL,"A",{href:!0});var fke=s(BB);nto=r(fke,"BertGenerationConfig"),fke.forEach(t),sto=r(UL," (Bert Generation model)"),UL.forEach(t),lto=i(L),Pf=n(L,"LI",{});var HL=s(Pf);cde=n(HL,"STRONG",{});var gke=s(cde);ito=r(gke,"big_bird"),gke.forEach(t),dto=r(HL," \u2014 "),IB=n(HL,"A",{href:!0});var hke=s(IB);cto=r(hke,"BigBirdConfig"),hke.forEach(t),mto=r(HL," (BigBird model)"),HL.forEach(t),fto=i(L),Bf=n(L,"LI",{});var JL=s(Bf);mde=n(JL,"STRONG",{});var uke=s(mde);gto=r(uke,"bigbird_pegasus"),uke.forEach(t),hto=r(JL," \u2014 "),NB=n(JL,"A",{href:!0});var pke=s(NB);uto=r(pke,"BigBirdPegasusConfig"),pke.forEach(t),pto=r(JL," (BigBird-Pegasus model)"),JL.forEach(t),_to=i(L),If=n(L,"LI",{});var YL=s(If);fde=n(YL,"STRONG",{});var _ke=s(fde);bto=r(_ke,"blenderbot"),_ke.forEach(t),vto=r(YL," \u2014 "),qB=n(YL,"A",{href:!0});var bke=s(qB);Fto=r(bke,"BlenderbotConfig"),bke.forEach(t),Tto=r(YL," (Blenderbot model)"),YL.forEach(t),Mto=i(L),Nf=n(L,"LI",{});var KL=s(Nf);gde=n(KL,"STRONG",{});var vke=s(gde);Eto=r(vke,"blenderbot-small"),vke.forEach(t),Cto=r(KL," \u2014 "),jB=n(KL,"A",{href:!0});var Fke=s(jB);wto=r(Fke,"BlenderbotSmallConfig"),Fke.forEach(t),Ato=r(KL," (BlenderbotSmall model)"),KL.forEach(t),Lto=i(L),qf=n(L,"LI",{});var ZL=s(qf);hde=n(ZL,"STRONG",{});var Tke=s(hde);yto=r(Tke,"bloom"),Tke.forEach(t),xto=r(ZL," \u2014 "),DB=n(ZL,"A",{href:!0});var Mke=s(DB);$to=r(Mke,"BloomConfig"),Mke.forEach(t),kto=r(ZL," (BLOOM model)"),ZL.forEach(t),Sto=i(L),jf=n(L,"LI",{});var ey=s(jf);ude=n(ey,"STRONG",{});var Eke=s(ude);Rto=r(Eke,"camembert"),Eke.forEach(t),Pto=r(ey," \u2014 "),GB=n(ey,"A",{href:!0});var Cke=s(GB);Bto=r(Cke,"CamembertConfig"),Cke.forEach(t),Ito=r(ey," (CamemBERT model)"),ey.forEach(t),Nto=i(L),Df=n(L,"LI",{});var oy=s(Df);pde=n(oy,"STRONG",{});var wke=s(pde);qto=r(wke,"canine"),wke.forEach(t),jto=r(oy," \u2014 "),OB=n(oy,"A",{href:!0});var Ake=s(OB);Dto=r(Ake,"CanineConfig"),Ake.forEach(t),Gto=r(oy," (CANINE model)"),oy.forEach(t),Oto=i(L),Gf=n(L,"LI",{});var ry=s(Gf);_de=n(ry,"STRONG",{});var Lke=s(_de);Vto=r(Lke,"clip"),Lke.forEach(t),Xto=r(ry," \u2014 "),VB=n(ry,"A",{href:!0});var yke=s(VB);zto=r(yke,"CLIPConfig"),yke.forEach(t),Qto=r(ry," (CLIP model)"),ry.forEach(t),Wto=i(L),Of=n(L,"LI",{});var ty=s(Of);bde=n(ty,"STRONG",{});var xke=s(bde);Uto=r(xke,"codegen"),xke.forEach(t),Hto=r(ty," \u2014 "),XB=n(ty,"A",{href:!0});var $ke=s(XB);Jto=r($ke,"CodeGenConfig"),$ke.forEach(t),Yto=r(ty," (CodeGen model)"),ty.forEach(t),Kto=i(L),Vf=n(L,"LI",{});var ay=s(Vf);vde=n(ay,"STRONG",{});var kke=s(vde);Zto=r(kke,"convbert"),kke.forEach(t),eao=r(ay," \u2014 "),zB=n(ay,"A",{href:!0});var Ske=s(zB);oao=r(Ske,"ConvBertConfig"),Ske.forEach(t),rao=r(ay," (ConvBERT model)"),ay.forEach(t),tao=i(L),Xf=n(L,"LI",{});var ny=s(Xf);Fde=n(ny,"STRONG",{});var Rke=s(Fde);aao=r(Rke,"convnext"),Rke.forEach(t),nao=r(ny," \u2014 "),QB=n(ny,"A",{href:!0});var Pke=s(QB);sao=r(Pke,"ConvNextConfig"),Pke.forEach(t),lao=r(ny," (ConvNeXT model)"),ny.forEach(t),iao=i(L),zf=n(L,"LI",{});var sy=s(zf);Tde=n(sy,"STRONG",{});var Bke=s(Tde);dao=r(Bke,"ctrl"),Bke.forEach(t),cao=r(sy," \u2014 "),WB=n(sy,"A",{href:!0});var Ike=s(WB);mao=r(Ike,"CTRLConfig"),Ike.forEach(t),fao=r(sy," (CTRL model)"),sy.forEach(t),gao=i(L),Qf=n(L,"LI",{});var ly=s(Qf);Mde=n(ly,"STRONG",{});var Nke=s(Mde);hao=r(Nke,"cvt"),Nke.forEach(t),uao=r(ly," \u2014 "),UB=n(ly,"A",{href:!0});var qke=s(UB);pao=r(qke,"CvtConfig"),qke.forEach(t),_ao=r(ly," (CvT model)"),ly.forEach(t),bao=i(L),Wf=n(L,"LI",{});var iy=s(Wf);Ede=n(iy,"STRONG",{});var jke=s(Ede);vao=r(jke,"data2vec-audio"),jke.forEach(t),Fao=r(iy," \u2014 "),HB=n(iy,"A",{href:!0});var Dke=s(HB);Tao=r(Dke,"Data2VecAudioConfig"),Dke.forEach(t),Mao=r(iy," (Data2VecAudio model)"),iy.forEach(t),Eao=i(L),Uf=n(L,"LI",{});var dy=s(Uf);Cde=n(dy,"STRONG",{});var Gke=s(Cde);Cao=r(Gke,"data2vec-text"),Gke.forEach(t),wao=r(dy," \u2014 "),JB=n(dy,"A",{href:!0});var Oke=s(JB);Aao=r(Oke,"Data2VecTextConfig"),Oke.forEach(t),Lao=r(dy," (Data2VecText model)"),dy.forEach(t),yao=i(L),Hf=n(L,"LI",{});var cy=s(Hf);wde=n(cy,"STRONG",{});var Vke=s(wde);xao=r(Vke,"data2vec-vision"),Vke.forEach(t),$ao=r(cy," \u2014 "),YB=n(cy,"A",{href:!0});var Xke=s(YB);kao=r(Xke,"Data2VecVisionConfig"),Xke.forEach(t),Sao=r(cy," (Data2VecVision model)"),cy.forEach(t),Rao=i(L),Jf=n(L,"LI",{});var my=s(Jf);Ade=n(my,"STRONG",{});var zke=s(Ade);Pao=r(zke,"deberta"),zke.forEach(t),Bao=r(my," \u2014 "),KB=n(my,"A",{href:!0});var Qke=s(KB);Iao=r(Qke,"DebertaConfig"),Qke.forEach(t),Nao=r(my," (DeBERTa model)"),my.forEach(t),qao=i(L),Yf=n(L,"LI",{});var fy=s(Yf);Lde=n(fy,"STRONG",{});var Wke=s(Lde);jao=r(Wke,"deberta-v2"),Wke.forEach(t),Dao=r(fy," \u2014 "),ZB=n(fy,"A",{href:!0});var Uke=s(ZB);Gao=r(Uke,"DebertaV2Config"),Uke.forEach(t),Oao=r(fy," (DeBERTa-v2 model)"),fy.forEach(t),Vao=i(L),Kf=n(L,"LI",{});var gy=s(Kf);yde=n(gy,"STRONG",{});var Hke=s(yde);Xao=r(Hke,"decision_transformer"),Hke.forEach(t),zao=r(gy," \u2014 "),eI=n(gy,"A",{href:!0});var Jke=s(eI);Qao=r(Jke,"DecisionTransformerConfig"),Jke.forEach(t),Wao=r(gy," (Decision Transformer model)"),gy.forEach(t),Uao=i(L),Zf=n(L,"LI",{});var hy=s(Zf);xde=n(hy,"STRONG",{});var Yke=s(xde);Hao=r(Yke,"deit"),Yke.forEach(t),Jao=r(hy," \u2014 "),oI=n(hy,"A",{href:!0});var Kke=s(oI);Yao=r(Kke,"DeiTConfig"),Kke.forEach(t),Kao=r(hy," (DeiT model)"),hy.forEach(t),Zao=i(L),eg=n(L,"LI",{});var uy=s(eg);$de=n(uy,"STRONG",{});var Zke=s($de);eno=r(Zke,"detr"),Zke.forEach(t),ono=r(uy," \u2014 "),rI=n(uy,"A",{href:!0});var eSe=s(rI);rno=r(eSe,"DetrConfig"),eSe.forEach(t),tno=r(uy," (DETR model)"),uy.forEach(t),ano=i(L),og=n(L,"LI",{});var oSe=s(og);kde=n(oSe,"STRONG",{});var Gbt=s(kde);nno=r(Gbt,"distilbert"),Gbt.forEach(t),sno=r(oSe," \u2014 "),tI=n(oSe,"A",{href:!0});var Obt=s(tI);lno=r(Obt,"DistilBertConfig"),Obt.forEach(t),ino=r(oSe," (DistilBERT model)"),oSe.forEach(t),dno=i(L),rg=n(L,"LI",{});var rSe=s(rg);Sde=n(rSe,"STRONG",{});var Vbt=s(Sde);cno=r(Vbt,"donut-swin"),Vbt.forEach(t),mno=r(rSe," \u2014 "),aI=n(rSe,"A",{href:!0});var Xbt=s(aI);fno=r(Xbt,"DonutSwinConfig"),Xbt.forEach(t),gno=r(rSe," (DonutSwin model)"),rSe.forEach(t),hno=i(L),tg=n(L,"LI",{});var tSe=s(tg);Rde=n(tSe,"STRONG",{});var zbt=s(Rde);uno=r(zbt,"dpr"),zbt.forEach(t),pno=r(tSe," \u2014 "),nI=n(tSe,"A",{href:!0});var Qbt=s(nI);_no=r(Qbt,"DPRConfig"),Qbt.forEach(t),bno=r(tSe," (DPR model)"),tSe.forEach(t),vno=i(L),ag=n(L,"LI",{});var aSe=s(ag);Pde=n(aSe,"STRONG",{});var Wbt=s(Pde);Fno=r(Wbt,"dpt"),Wbt.forEach(t),Tno=r(aSe," \u2014 "),sI=n(aSe,"A",{href:!0});var Ubt=s(sI);Mno=r(Ubt,"DPTConfig"),Ubt.forEach(t),Eno=r(aSe," (DPT model)"),aSe.forEach(t),Cno=i(L),ng=n(L,"LI",{});var nSe=s(ng);Bde=n(nSe,"STRONG",{});var Hbt=s(Bde);wno=r(Hbt,"electra"),Hbt.forEach(t),Ano=r(nSe," \u2014 "),lI=n(nSe,"A",{href:!0});var Jbt=s(lI);Lno=r(Jbt,"ElectraConfig"),Jbt.forEach(t),yno=r(nSe," (ELECTRA model)"),nSe.forEach(t),xno=i(L),sg=n(L,"LI",{});var sSe=s(sg);Ide=n(sSe,"STRONG",{});var Ybt=s(Ide);$no=r(Ybt,"encoder-decoder"),Ybt.forEach(t),kno=r(sSe," \u2014 "),iI=n(sSe,"A",{href:!0});var Kbt=s(iI);Sno=r(Kbt,"EncoderDecoderConfig"),Kbt.forEach(t),Rno=r(sSe," (Encoder decoder model)"),sSe.forEach(t),Pno=i(L),lg=n(L,"LI",{});var lSe=s(lg);Nde=n(lSe,"STRONG",{});var Zbt=s(Nde);Bno=r(Zbt,"ernie"),Zbt.forEach(t),Ino=r(lSe," \u2014 "),dI=n(lSe,"A",{href:!0});var e1t=s(dI);Nno=r(e1t,"ErnieConfig"),e1t.forEach(t),qno=r(lSe," (ERNIE model)"),lSe.forEach(t),jno=i(L),ig=n(L,"LI",{});var iSe=s(ig);qde=n(iSe,"STRONG",{});var o1t=s(qde);Dno=r(o1t,"flaubert"),o1t.forEach(t),Gno=r(iSe," \u2014 "),cI=n(iSe,"A",{href:!0});var r1t=s(cI);Ono=r(r1t,"FlaubertConfig"),r1t.forEach(t),Vno=r(iSe," (FlauBERT model)"),iSe.forEach(t),Xno=i(L),dg=n(L,"LI",{});var dSe=s(dg);jde=n(dSe,"STRONG",{});var t1t=s(jde);zno=r(t1t,"flava"),t1t.forEach(t),Qno=r(dSe," \u2014 "),mI=n(dSe,"A",{href:!0});var a1t=s(mI);Wno=r(a1t,"FlavaConfig"),a1t.forEach(t),Uno=r(dSe," (FLAVA model)"),dSe.forEach(t),Hno=i(L),cg=n(L,"LI",{});var cSe=s(cg);Dde=n(cSe,"STRONG",{});var n1t=s(Dde);Jno=r(n1t,"fnet"),n1t.forEach(t),Yno=r(cSe," \u2014 "),fI=n(cSe,"A",{href:!0});var s1t=s(fI);Kno=r(s1t,"FNetConfig"),s1t.forEach(t),Zno=r(cSe," (FNet model)"),cSe.forEach(t),eso=i(L),mg=n(L,"LI",{});var mSe=s(mg);Gde=n(mSe,"STRONG",{});var l1t=s(Gde);oso=r(l1t,"fsmt"),l1t.forEach(t),rso=r(mSe," \u2014 "),gI=n(mSe,"A",{href:!0});var i1t=s(gI);tso=r(i1t,"FSMTConfig"),i1t.forEach(t),aso=r(mSe," (FairSeq Machine-Translation model)"),mSe.forEach(t),nso=i(L),fg=n(L,"LI",{});var fSe=s(fg);Ode=n(fSe,"STRONG",{});var d1t=s(Ode);sso=r(d1t,"funnel"),d1t.forEach(t),lso=r(fSe," \u2014 "),hI=n(fSe,"A",{href:!0});var c1t=s(hI);iso=r(c1t,"FunnelConfig"),c1t.forEach(t),dso=r(fSe," (Funnel Transformer model)"),fSe.forEach(t),cso=i(L),gg=n(L,"LI",{});var gSe=s(gg);Vde=n(gSe,"STRONG",{});var m1t=s(Vde);mso=r(m1t,"glpn"),m1t.forEach(t),fso=r(gSe," \u2014 "),uI=n(gSe,"A",{href:!0});var f1t=s(uI);gso=r(f1t,"GLPNConfig"),f1t.forEach(t),hso=r(gSe," (GLPN model)"),gSe.forEach(t),uso=i(L),hg=n(L,"LI",{});var hSe=s(hg);Xde=n(hSe,"STRONG",{});var g1t=s(Xde);pso=r(g1t,"gpt2"),g1t.forEach(t),_so=r(hSe," \u2014 "),pI=n(hSe,"A",{href:!0});var h1t=s(pI);bso=r(h1t,"GPT2Config"),h1t.forEach(t),vso=r(hSe," (OpenAI GPT-2 model)"),hSe.forEach(t),Fso=i(L),ug=n(L,"LI",{});var uSe=s(ug);zde=n(uSe,"STRONG",{});var u1t=s(zde);Tso=r(u1t,"gpt_neo"),u1t.forEach(t),Mso=r(uSe," \u2014 "),_I=n(uSe,"A",{href:!0});var p1t=s(_I);Eso=r(p1t,"GPTNeoConfig"),p1t.forEach(t),Cso=r(uSe," (GPT Neo model)"),uSe.forEach(t),wso=i(L),pg=n(L,"LI",{});var pSe=s(pg);Qde=n(pSe,"STRONG",{});var _1t=s(Qde);Aso=r(_1t,"gpt_neox"),_1t.forEach(t),Lso=r(pSe," \u2014 "),bI=n(pSe,"A",{href:!0});var b1t=s(bI);yso=r(b1t,"GPTNeoXConfig"),b1t.forEach(t),xso=r(pSe," (GPT NeoX model)"),pSe.forEach(t),$so=i(L),_g=n(L,"LI",{});var _Se=s(_g);Wde=n(_Se,"STRONG",{});var v1t=s(Wde);kso=r(v1t,"gptj"),v1t.forEach(t),Sso=r(_Se," \u2014 "),vI=n(_Se,"A",{href:!0});var F1t=s(vI);Rso=r(F1t,"GPTJConfig"),F1t.forEach(t),Pso=r(_Se," (GPT-J model)"),_Se.forEach(t),Bso=i(L),bg=n(L,"LI",{});var bSe=s(bg);Ude=n(bSe,"STRONG",{});var T1t=s(Ude);Iso=r(T1t,"groupvit"),T1t.forEach(t),Nso=r(bSe," \u2014 "),FI=n(bSe,"A",{href:!0});var M1t=s(FI);qso=r(M1t,"GroupViTConfig"),M1t.forEach(t),jso=r(bSe," (GroupViT model)"),bSe.forEach(t),Dso=i(L),vg=n(L,"LI",{});var vSe=s(vg);Hde=n(vSe,"STRONG",{});var E1t=s(Hde);Gso=r(E1t,"hubert"),E1t.forEach(t),Oso=r(vSe," \u2014 "),TI=n(vSe,"A",{href:!0});var C1t=s(TI);Vso=r(C1t,"HubertConfig"),C1t.forEach(t),Xso=r(vSe," (Hubert model)"),vSe.forEach(t),zso=i(L),Fg=n(L,"LI",{});var FSe=s(Fg);Jde=n(FSe,"STRONG",{});var w1t=s(Jde);Qso=r(w1t,"ibert"),w1t.forEach(t),Wso=r(FSe," \u2014 "),MI=n(FSe,"A",{href:!0});var A1t=s(MI);Uso=r(A1t,"IBertConfig"),A1t.forEach(t),Hso=r(FSe," (I-BERT model)"),FSe.forEach(t),Jso=i(L),Tg=n(L,"LI",{});var TSe=s(Tg);Yde=n(TSe,"STRONG",{});var L1t=s(Yde);Yso=r(L1t,"imagegpt"),L1t.forEach(t),Kso=r(TSe," \u2014 "),EI=n(TSe,"A",{href:!0});var y1t=s(EI);Zso=r(y1t,"ImageGPTConfig"),y1t.forEach(t),elo=r(TSe," (ImageGPT model)"),TSe.forEach(t),olo=i(L),Mg=n(L,"LI",{});var MSe=s(Mg);Kde=n(MSe,"STRONG",{});var x1t=s(Kde);rlo=r(x1t,"layoutlm"),x1t.forEach(t),tlo=r(MSe," \u2014 "),CI=n(MSe,"A",{href:!0});var $1t=s(CI);alo=r($1t,"LayoutLMConfig"),$1t.forEach(t),nlo=r(MSe," (LayoutLM model)"),MSe.forEach(t),slo=i(L),Eg=n(L,"LI",{});var ESe=s(Eg);Zde=n(ESe,"STRONG",{});var k1t=s(Zde);llo=r(k1t,"layoutlmv2"),k1t.forEach(t),ilo=r(ESe," \u2014 "),wI=n(ESe,"A",{href:!0});var S1t=s(wI);dlo=r(S1t,"LayoutLMv2Config"),S1t.forEach(t),clo=r(ESe," (LayoutLMv2 model)"),ESe.forEach(t),mlo=i(L),Cg=n(L,"LI",{});var CSe=s(Cg);ece=n(CSe,"STRONG",{});var R1t=s(ece);flo=r(R1t,"layoutlmv3"),R1t.forEach(t),glo=r(CSe," \u2014 "),AI=n(CSe,"A",{href:!0});var P1t=s(AI);hlo=r(P1t,"LayoutLMv3Config"),P1t.forEach(t),ulo=r(CSe," (LayoutLMv3 model)"),CSe.forEach(t),plo=i(L),wg=n(L,"LI",{});var wSe=s(wg);oce=n(wSe,"STRONG",{});var B1t=s(oce);_lo=r(B1t,"led"),B1t.forEach(t),blo=r(wSe," \u2014 "),LI=n(wSe,"A",{href:!0});var I1t=s(LI);vlo=r(I1t,"LEDConfig"),I1t.forEach(t),Flo=r(wSe," (LED model)"),wSe.forEach(t),Tlo=i(L),Ag=n(L,"LI",{});var ASe=s(Ag);rce=n(ASe,"STRONG",{});var N1t=s(rce);Mlo=r(N1t,"levit"),N1t.forEach(t),Elo=r(ASe," \u2014 "),yI=n(ASe,"A",{href:!0});var q1t=s(yI);Clo=r(q1t,"LevitConfig"),q1t.forEach(t),wlo=r(ASe," (LeViT model)"),ASe.forEach(t),Alo=i(L),Lg=n(L,"LI",{});var LSe=s(Lg);tce=n(LSe,"STRONG",{});var j1t=s(tce);Llo=r(j1t,"longformer"),j1t.forEach(t),ylo=r(LSe," \u2014 "),xI=n(LSe,"A",{href:!0});var D1t=s(xI);xlo=r(D1t,"LongformerConfig"),D1t.forEach(t),$lo=r(LSe," (Longformer model)"),LSe.forEach(t),klo=i(L),yg=n(L,"LI",{});var ySe=s(yg);ace=n(ySe,"STRONG",{});var G1t=s(ace);Slo=r(G1t,"longt5"),G1t.forEach(t),Rlo=r(ySe," \u2014 "),$I=n(ySe,"A",{href:!0});var O1t=s($I);Plo=r(O1t,"LongT5Config"),O1t.forEach(t),Blo=r(ySe," (LongT5 model)"),ySe.forEach(t),Ilo=i(L),xg=n(L,"LI",{});var xSe=s(xg);nce=n(xSe,"STRONG",{});var V1t=s(nce);Nlo=r(V1t,"luke"),V1t.forEach(t),qlo=r(xSe," \u2014 "),kI=n(xSe,"A",{href:!0});var X1t=s(kI);jlo=r(X1t,"LukeConfig"),X1t.forEach(t),Dlo=r(xSe," (LUKE model)"),xSe.forEach(t),Glo=i(L),$g=n(L,"LI",{});var $Se=s($g);sce=n($Se,"STRONG",{});var z1t=s(sce);Olo=r(z1t,"lxmert"),z1t.forEach(t),Vlo=r($Se," \u2014 "),SI=n($Se,"A",{href:!0});var Q1t=s(SI);Xlo=r(Q1t,"LxmertConfig"),Q1t.forEach(t),zlo=r($Se," (LXMERT model)"),$Se.forEach(t),Qlo=i(L),kg=n(L,"LI",{});var kSe=s(kg);lce=n(kSe,"STRONG",{});var W1t=s(lce);Wlo=r(W1t,"m2m_100"),W1t.forEach(t),Ulo=r(kSe," \u2014 "),RI=n(kSe,"A",{href:!0});var U1t=s(RI);Hlo=r(U1t,"M2M100Config"),U1t.forEach(t),Jlo=r(kSe," (M2M100 model)"),kSe.forEach(t),Ylo=i(L),Sg=n(L,"LI",{});var SSe=s(Sg);ice=n(SSe,"STRONG",{});var H1t=s(ice);Klo=r(H1t,"marian"),H1t.forEach(t),Zlo=r(SSe," \u2014 "),PI=n(SSe,"A",{href:!0});var J1t=s(PI);eio=r(J1t,"MarianConfig"),J1t.forEach(t),oio=r(SSe," (Marian model)"),SSe.forEach(t),rio=i(L),Rg=n(L,"LI",{});var RSe=s(Rg);dce=n(RSe,"STRONG",{});var Y1t=s(dce);tio=r(Y1t,"maskformer"),Y1t.forEach(t),aio=r(RSe," \u2014 "),BI=n(RSe,"A",{href:!0});var K1t=s(BI);nio=r(K1t,"MaskFormerConfig"),K1t.forEach(t),sio=r(RSe," (MaskFormer model)"),RSe.forEach(t),lio=i(L),Pg=n(L,"LI",{});var PSe=s(Pg);cce=n(PSe,"STRONG",{});var Z1t=s(cce);iio=r(Z1t,"mbart"),Z1t.forEach(t),dio=r(PSe," \u2014 "),II=n(PSe,"A",{href:!0});var evt=s(II);cio=r(evt,"MBartConfig"),evt.forEach(t),mio=r(PSe," (mBART model)"),PSe.forEach(t),fio=i(L),Bg=n(L,"LI",{});var BSe=s(Bg);mce=n(BSe,"STRONG",{});var ovt=s(mce);gio=r(ovt,"mctct"),ovt.forEach(t),hio=r(BSe," \u2014 "),NI=n(BSe,"A",{href:!0});var rvt=s(NI);uio=r(rvt,"MCTCTConfig"),rvt.forEach(t),pio=r(BSe," (M-CTC-T model)"),BSe.forEach(t),_io=i(L),Ig=n(L,"LI",{});var ISe=s(Ig);fce=n(ISe,"STRONG",{});var tvt=s(fce);bio=r(tvt,"megatron-bert"),tvt.forEach(t),vio=r(ISe," \u2014 "),qI=n(ISe,"A",{href:!0});var avt=s(qI);Fio=r(avt,"MegatronBertConfig"),avt.forEach(t),Tio=r(ISe," (Megatron-BERT model)"),ISe.forEach(t),Mio=i(L),Ng=n(L,"LI",{});var NSe=s(Ng);gce=n(NSe,"STRONG",{});var nvt=s(gce);Eio=r(nvt,"mobilebert"),nvt.forEach(t),Cio=r(NSe," \u2014 "),jI=n(NSe,"A",{href:!0});var svt=s(jI);wio=r(svt,"MobileBertConfig"),svt.forEach(t),Aio=r(NSe," (MobileBERT model)"),NSe.forEach(t),Lio=i(L),qg=n(L,"LI",{});var qSe=s(qg);hce=n(qSe,"STRONG",{});var lvt=s(hce);yio=r(lvt,"mobilevit"),lvt.forEach(t),xio=r(qSe," \u2014 "),DI=n(qSe,"A",{href:!0});var ivt=s(DI);$io=r(ivt,"MobileViTConfig"),ivt.forEach(t),kio=r(qSe," (MobileViT model)"),qSe.forEach(t),Sio=i(L),jg=n(L,"LI",{});var jSe=s(jg);uce=n(jSe,"STRONG",{});var dvt=s(uce);Rio=r(dvt,"mpnet"),dvt.forEach(t),Pio=r(jSe," \u2014 "),GI=n(jSe,"A",{href:!0});var cvt=s(GI);Bio=r(cvt,"MPNetConfig"),cvt.forEach(t),Iio=r(jSe," (MPNet model)"),jSe.forEach(t),Nio=i(L),Dg=n(L,"LI",{});var DSe=s(Dg);pce=n(DSe,"STRONG",{});var mvt=s(pce);qio=r(mvt,"mt5"),mvt.forEach(t),jio=r(DSe," \u2014 "),OI=n(DSe,"A",{href:!0});var fvt=s(OI);Dio=r(fvt,"MT5Config"),fvt.forEach(t),Gio=r(DSe," (MT5 model)"),DSe.forEach(t),Oio=i(L),Gg=n(L,"LI",{});var GSe=s(Gg);_ce=n(GSe,"STRONG",{});var gvt=s(_ce);Vio=r(gvt,"mvp"),gvt.forEach(t),Xio=r(GSe," \u2014 "),VI=n(GSe,"A",{href:!0});var hvt=s(VI);zio=r(hvt,"MvpConfig"),hvt.forEach(t),Qio=r(GSe," (MVP model)"),GSe.forEach(t),Wio=i(L),Og=n(L,"LI",{});var OSe=s(Og);bce=n(OSe,"STRONG",{});var uvt=s(bce);Uio=r(uvt,"nezha"),uvt.forEach(t),Hio=r(OSe," \u2014 "),XI=n(OSe,"A",{href:!0});var pvt=s(XI);Jio=r(pvt,"NezhaConfig"),pvt.forEach(t),Yio=r(OSe," (Nezha model)"),OSe.forEach(t),Kio=i(L),Vg=n(L,"LI",{});var VSe=s(Vg);vce=n(VSe,"STRONG",{});var _vt=s(vce);Zio=r(_vt,"nystromformer"),_vt.forEach(t),edo=r(VSe," \u2014 "),zI=n(VSe,"A",{href:!0});var bvt=s(zI);odo=r(bvt,"NystromformerConfig"),bvt.forEach(t),rdo=r(VSe," (Nystr\xF6mformer model)"),VSe.forEach(t),tdo=i(L),Xg=n(L,"LI",{});var XSe=s(Xg);Fce=n(XSe,"STRONG",{});var vvt=s(Fce);ado=r(vvt,"openai-gpt"),vvt.forEach(t),ndo=r(XSe," \u2014 "),QI=n(XSe,"A",{href:!0});var Fvt=s(QI);sdo=r(Fvt,"OpenAIGPTConfig"),Fvt.forEach(t),ldo=r(XSe," (OpenAI GPT model)"),XSe.forEach(t),ido=i(L),zg=n(L,"LI",{});var zSe=s(zg);Tce=n(zSe,"STRONG",{});var Tvt=s(Tce);ddo=r(Tvt,"opt"),Tvt.forEach(t),cdo=r(zSe," \u2014 "),WI=n(zSe,"A",{href:!0});var Mvt=s(WI);mdo=r(Mvt,"OPTConfig"),Mvt.forEach(t),fdo=r(zSe," (OPT model)"),zSe.forEach(t),gdo=i(L),Qg=n(L,"LI",{});var QSe=s(Qg);Mce=n(QSe,"STRONG",{});var Evt=s(Mce);hdo=r(Evt,"owlvit"),Evt.forEach(t),udo=r(QSe," \u2014 "),UI=n(QSe,"A",{href:!0});var Cvt=s(UI);pdo=r(Cvt,"OwlViTConfig"),Cvt.forEach(t),_do=r(QSe," (OWL-ViT model)"),QSe.forEach(t),bdo=i(L),Wg=n(L,"LI",{});var WSe=s(Wg);Ece=n(WSe,"STRONG",{});var wvt=s(Ece);vdo=r(wvt,"pegasus"),wvt.forEach(t),Fdo=r(WSe," \u2014 "),HI=n(WSe,"A",{href:!0});var Avt=s(HI);Tdo=r(Avt,"PegasusConfig"),Avt.forEach(t),Mdo=r(WSe," (Pegasus model)"),WSe.forEach(t),Edo=i(L),Ug=n(L,"LI",{});var USe=s(Ug);Cce=n(USe,"STRONG",{});var Lvt=s(Cce);Cdo=r(Lvt,"pegasus_x"),Lvt.forEach(t),wdo=r(USe," \u2014 "),JI=n(USe,"A",{href:!0});var yvt=s(JI);Ado=r(yvt,"PegasusXConfig"),yvt.forEach(t),Ldo=r(USe," (PEGASUS-X model)"),USe.forEach(t),ydo=i(L),Hg=n(L,"LI",{});var HSe=s(Hg);wce=n(HSe,"STRONG",{});var xvt=s(wce);xdo=r(xvt,"perceiver"),xvt.forEach(t),$do=r(HSe," \u2014 "),YI=n(HSe,"A",{href:!0});var $vt=s(YI);kdo=r($vt,"PerceiverConfig"),$vt.forEach(t),Sdo=r(HSe," (Perceiver model)"),HSe.forEach(t),Rdo=i(L),Jg=n(L,"LI",{});var JSe=s(Jg);Ace=n(JSe,"STRONG",{});var kvt=s(Ace);Pdo=r(kvt,"plbart"),kvt.forEach(t),Bdo=r(JSe," \u2014 "),KI=n(JSe,"A",{href:!0});var Svt=s(KI);Ido=r(Svt,"PLBartConfig"),Svt.forEach(t),Ndo=r(JSe," (PLBart model)"),JSe.forEach(t),qdo=i(L),Yg=n(L,"LI",{});var YSe=s(Yg);Lce=n(YSe,"STRONG",{});var Rvt=s(Lce);jdo=r(Rvt,"poolformer"),Rvt.forEach(t),Ddo=r(YSe," \u2014 "),ZI=n(YSe,"A",{href:!0});var Pvt=s(ZI);Gdo=r(Pvt,"PoolFormerConfig"),Pvt.forEach(t),Odo=r(YSe," (PoolFormer model)"),YSe.forEach(t),Vdo=i(L),Kg=n(L,"LI",{});var KSe=s(Kg);yce=n(KSe,"STRONG",{});var Bvt=s(yce);Xdo=r(Bvt,"prophetnet"),Bvt.forEach(t),zdo=r(KSe," \u2014 "),eN=n(KSe,"A",{href:!0});var Ivt=s(eN);Qdo=r(Ivt,"ProphetNetConfig"),Ivt.forEach(t),Wdo=r(KSe," (ProphetNet model)"),KSe.forEach(t),Udo=i(L),Zg=n(L,"LI",{});var ZSe=s(Zg);xce=n(ZSe,"STRONG",{});var Nvt=s(xce);Hdo=r(Nvt,"qdqbert"),Nvt.forEach(t),Jdo=r(ZSe," \u2014 "),oN=n(ZSe,"A",{href:!0});var qvt=s(oN);Ydo=r(qvt,"QDQBertConfig"),qvt.forEach(t),Kdo=r(ZSe," (QDQBert model)"),ZSe.forEach(t),Zdo=i(L),eh=n(L,"LI",{});var eRe=s(eh);$ce=n(eRe,"STRONG",{});var jvt=s($ce);eco=r(jvt,"rag"),jvt.forEach(t),oco=r(eRe," \u2014 "),rN=n(eRe,"A",{href:!0});var Dvt=s(rN);rco=r(Dvt,"RagConfig"),Dvt.forEach(t),tco=r(eRe," (RAG model)"),eRe.forEach(t),aco=i(L),oh=n(L,"LI",{});var oRe=s(oh);kce=n(oRe,"STRONG",{});var Gvt=s(kce);nco=r(Gvt,"realm"),Gvt.forEach(t),sco=r(oRe," \u2014 "),tN=n(oRe,"A",{href:!0});var Ovt=s(tN);lco=r(Ovt,"RealmConfig"),Ovt.forEach(t),ico=r(oRe," (REALM model)"),oRe.forEach(t),dco=i(L),rh=n(L,"LI",{});var rRe=s(rh);Sce=n(rRe,"STRONG",{});var Vvt=s(Sce);cco=r(Vvt,"reformer"),Vvt.forEach(t),mco=r(rRe," \u2014 "),aN=n(rRe,"A",{href:!0});var Xvt=s(aN);fco=r(Xvt,"ReformerConfig"),Xvt.forEach(t),gco=r(rRe," (Reformer model)"),rRe.forEach(t),hco=i(L),th=n(L,"LI",{});var tRe=s(th);Rce=n(tRe,"STRONG",{});var zvt=s(Rce);uco=r(zvt,"regnet"),zvt.forEach(t),pco=r(tRe," \u2014 "),nN=n(tRe,"A",{href:!0});var Qvt=s(nN);_co=r(Qvt,"RegNetConfig"),Qvt.forEach(t),bco=r(tRe," (RegNet model)"),tRe.forEach(t),vco=i(L),ah=n(L,"LI",{});var aRe=s(ah);Pce=n(aRe,"STRONG",{});var Wvt=s(Pce);Fco=r(Wvt,"rembert"),Wvt.forEach(t),Tco=r(aRe," \u2014 "),sN=n(aRe,"A",{href:!0});var Uvt=s(sN);Mco=r(Uvt,"RemBertConfig"),Uvt.forEach(t),Eco=r(aRe," (RemBERT model)"),aRe.forEach(t),Cco=i(L),nh=n(L,"LI",{});var nRe=s(nh);Bce=n(nRe,"STRONG",{});var Hvt=s(Bce);wco=r(Hvt,"resnet"),Hvt.forEach(t),Aco=r(nRe," \u2014 "),lN=n(nRe,"A",{href:!0});var Jvt=s(lN);Lco=r(Jvt,"ResNetConfig"),Jvt.forEach(t),yco=r(nRe," (ResNet model)"),nRe.forEach(t),xco=i(L),sh=n(L,"LI",{});var sRe=s(sh);Ice=n(sRe,"STRONG",{});var Yvt=s(Ice);$co=r(Yvt,"retribert"),Yvt.forEach(t),kco=r(sRe," \u2014 "),iN=n(sRe,"A",{href:!0});var Kvt=s(iN);Sco=r(Kvt,"RetriBertConfig"),Kvt.forEach(t),Rco=r(sRe," (RetriBERT model)"),sRe.forEach(t),Pco=i(L),lh=n(L,"LI",{});var lRe=s(lh);Nce=n(lRe,"STRONG",{});var Zvt=s(Nce);Bco=r(Zvt,"roberta"),Zvt.forEach(t),Ico=r(lRe," \u2014 "),dN=n(lRe,"A",{href:!0});var eFt=s(dN);Nco=r(eFt,"RobertaConfig"),eFt.forEach(t),qco=r(lRe," (RoBERTa model)"),lRe.forEach(t),jco=i(L),ih=n(L,"LI",{});var iRe=s(ih);qce=n(iRe,"STRONG",{});var oFt=s(qce);Dco=r(oFt,"roformer"),oFt.forEach(t),Gco=r(iRe," \u2014 "),cN=n(iRe,"A",{href:!0});var rFt=s(cN);Oco=r(rFt,"RoFormerConfig"),rFt.forEach(t),Vco=r(iRe," (RoFormer model)"),iRe.forEach(t),Xco=i(L),dh=n(L,"LI",{});var dRe=s(dh);jce=n(dRe,"STRONG",{});var tFt=s(jce);zco=r(tFt,"segformer"),tFt.forEach(t),Qco=r(dRe," \u2014 "),mN=n(dRe,"A",{href:!0});var aFt=s(mN);Wco=r(aFt,"SegformerConfig"),aFt.forEach(t),Uco=r(dRe," (SegFormer model)"),dRe.forEach(t),Hco=i(L),ch=n(L,"LI",{});var cRe=s(ch);Dce=n(cRe,"STRONG",{});var nFt=s(Dce);Jco=r(nFt,"sew"),nFt.forEach(t),Yco=r(cRe," \u2014 "),fN=n(cRe,"A",{href:!0});var sFt=s(fN);Kco=r(sFt,"SEWConfig"),sFt.forEach(t),Zco=r(cRe," (SEW model)"),cRe.forEach(t),emo=i(L),mh=n(L,"LI",{});var mRe=s(mh);Gce=n(mRe,"STRONG",{});var lFt=s(Gce);omo=r(lFt,"sew-d"),lFt.forEach(t),rmo=r(mRe," \u2014 "),gN=n(mRe,"A",{href:!0});var iFt=s(gN);tmo=r(iFt,"SEWDConfig"),iFt.forEach(t),amo=r(mRe," (SEW-D model)"),mRe.forEach(t),nmo=i(L),fh=n(L,"LI",{});var fRe=s(fh);Oce=n(fRe,"STRONG",{});var dFt=s(Oce);smo=r(dFt,"speech-encoder-decoder"),dFt.forEach(t),lmo=r(fRe," \u2014 "),hN=n(fRe,"A",{href:!0});var cFt=s(hN);imo=r(cFt,"SpeechEncoderDecoderConfig"),cFt.forEach(t),dmo=r(fRe," (Speech Encoder decoder model)"),fRe.forEach(t),cmo=i(L),gh=n(L,"LI",{});var gRe=s(gh);Vce=n(gRe,"STRONG",{});var mFt=s(Vce);mmo=r(mFt,"speech_to_text"),mFt.forEach(t),fmo=r(gRe," \u2014 "),uN=n(gRe,"A",{href:!0});var fFt=s(uN);gmo=r(fFt,"Speech2TextConfig"),fFt.forEach(t),hmo=r(gRe," (Speech2Text model)"),gRe.forEach(t),umo=i(L),hh=n(L,"LI",{});var hRe=s(hh);Xce=n(hRe,"STRONG",{});var gFt=s(Xce);pmo=r(gFt,"speech_to_text_2"),gFt.forEach(t),_mo=r(hRe," \u2014 "),pN=n(hRe,"A",{href:!0});var hFt=s(pN);bmo=r(hFt,"Speech2Text2Config"),hFt.forEach(t),vmo=r(hRe," (Speech2Text2 model)"),hRe.forEach(t),Fmo=i(L),uh=n(L,"LI",{});var uRe=s(uh);zce=n(uRe,"STRONG",{});var uFt=s(zce);Tmo=r(uFt,"splinter"),uFt.forEach(t),Mmo=r(uRe," \u2014 "),_N=n(uRe,"A",{href:!0});var pFt=s(_N);Emo=r(pFt,"SplinterConfig"),pFt.forEach(t),Cmo=r(uRe," (Splinter model)"),uRe.forEach(t),wmo=i(L),ph=n(L,"LI",{});var pRe=s(ph);Qce=n(pRe,"STRONG",{});var _Ft=s(Qce);Amo=r(_Ft,"squeezebert"),_Ft.forEach(t),Lmo=r(pRe," \u2014 "),bN=n(pRe,"A",{href:!0});var bFt=s(bN);ymo=r(bFt,"SqueezeBertConfig"),bFt.forEach(t),xmo=r(pRe," (SqueezeBERT model)"),pRe.forEach(t),$mo=i(L),_h=n(L,"LI",{});var _Re=s(_h);Wce=n(_Re,"STRONG",{});var vFt=s(Wce);kmo=r(vFt,"swin"),vFt.forEach(t),Smo=r(_Re," \u2014 "),vN=n(_Re,"A",{href:!0});var FFt=s(vN);Rmo=r(FFt,"SwinConfig"),FFt.forEach(t),Pmo=r(_Re," (Swin Transformer model)"),_Re.forEach(t),Bmo=i(L),bh=n(L,"LI",{});var bRe=s(bh);Uce=n(bRe,"STRONG",{});var TFt=s(Uce);Imo=r(TFt,"swinv2"),TFt.forEach(t),Nmo=r(bRe," \u2014 "),FN=n(bRe,"A",{href:!0});var MFt=s(FN);qmo=r(MFt,"Swinv2Config"),MFt.forEach(t),jmo=r(bRe," (Swin Transformer V2 model)"),bRe.forEach(t),Dmo=i(L),vh=n(L,"LI",{});var vRe=s(vh);Hce=n(vRe,"STRONG",{});var EFt=s(Hce);Gmo=r(EFt,"t5"),EFt.forEach(t),Omo=r(vRe," \u2014 "),TN=n(vRe,"A",{href:!0});var CFt=s(TN);Vmo=r(CFt,"T5Config"),CFt.forEach(t),Xmo=r(vRe," (T5 model)"),vRe.forEach(t),zmo=i(L),Fh=n(L,"LI",{});var FRe=s(Fh);Jce=n(FRe,"STRONG",{});var wFt=s(Jce);Qmo=r(wFt,"tapas"),wFt.forEach(t),Wmo=r(FRe," \u2014 "),MN=n(FRe,"A",{href:!0});var AFt=s(MN);Umo=r(AFt,"TapasConfig"),AFt.forEach(t),Hmo=r(FRe," (TAPAS model)"),FRe.forEach(t),Jmo=i(L),Th=n(L,"LI",{});var TRe=s(Th);Yce=n(TRe,"STRONG",{});var LFt=s(Yce);Ymo=r(LFt,"trajectory_transformer"),LFt.forEach(t),Kmo=r(TRe," \u2014 "),EN=n(TRe,"A",{href:!0});var yFt=s(EN);Zmo=r(yFt,"TrajectoryTransformerConfig"),yFt.forEach(t),efo=r(TRe," (Trajectory Transformer model)"),TRe.forEach(t),ofo=i(L),Mh=n(L,"LI",{});var MRe=s(Mh);Kce=n(MRe,"STRONG",{});var xFt=s(Kce);rfo=r(xFt,"transfo-xl"),xFt.forEach(t),tfo=r(MRe," \u2014 "),CN=n(MRe,"A",{href:!0});var $Ft=s(CN);afo=r($Ft,"TransfoXLConfig"),$Ft.forEach(t),nfo=r(MRe," (Transformer-XL model)"),MRe.forEach(t),sfo=i(L),Eh=n(L,"LI",{});var ERe=s(Eh);Zce=n(ERe,"STRONG",{});var kFt=s(Zce);lfo=r(kFt,"trocr"),kFt.forEach(t),ifo=r(ERe," \u2014 "),wN=n(ERe,"A",{href:!0});var SFt=s(wN);dfo=r(SFt,"TrOCRConfig"),SFt.forEach(t),cfo=r(ERe," (TrOCR model)"),ERe.forEach(t),mfo=i(L),Ch=n(L,"LI",{});var CRe=s(Ch);eme=n(CRe,"STRONG",{});var RFt=s(eme);ffo=r(RFt,"unispeech"),RFt.forEach(t),gfo=r(CRe," \u2014 "),AN=n(CRe,"A",{href:!0});var PFt=s(AN);hfo=r(PFt,"UniSpeechConfig"),PFt.forEach(t),ufo=r(CRe," (UniSpeech model)"),CRe.forEach(t),pfo=i(L),wh=n(L,"LI",{});var wRe=s(wh);ome=n(wRe,"STRONG",{});var BFt=s(ome);_fo=r(BFt,"unispeech-sat"),BFt.forEach(t),bfo=r(wRe," \u2014 "),LN=n(wRe,"A",{href:!0});var IFt=s(LN);vfo=r(IFt,"UniSpeechSatConfig"),IFt.forEach(t),Ffo=r(wRe," (UniSpeechSat model)"),wRe.forEach(t),Tfo=i(L),Ah=n(L,"LI",{});var ARe=s(Ah);rme=n(ARe,"STRONG",{});var NFt=s(rme);Mfo=r(NFt,"van"),NFt.forEach(t),Efo=r(ARe," \u2014 "),yN=n(ARe,"A",{href:!0});var qFt=s(yN);Cfo=r(qFt,"VanConfig"),qFt.forEach(t),wfo=r(ARe," (VAN model)"),ARe.forEach(t),Afo=i(L),Lh=n(L,"LI",{});var LRe=s(Lh);tme=n(LRe,"STRONG",{});var jFt=s(tme);Lfo=r(jFt,"videomae"),jFt.forEach(t),yfo=r(LRe," \u2014 "),xN=n(LRe,"A",{href:!0});var DFt=s(xN);xfo=r(DFt,"VideoMAEConfig"),DFt.forEach(t),$fo=r(LRe," (VideoMAE model)"),LRe.forEach(t),kfo=i(L),yh=n(L,"LI",{});var yRe=s(yh);ame=n(yRe,"STRONG",{});var GFt=s(ame);Sfo=r(GFt,"vilt"),GFt.forEach(t),Rfo=r(yRe," \u2014 "),$N=n(yRe,"A",{href:!0});var OFt=s($N);Pfo=r(OFt,"ViltConfig"),OFt.forEach(t),Bfo=r(yRe," (ViLT model)"),yRe.forEach(t),Ifo=i(L),xh=n(L,"LI",{});var xRe=s(xh);nme=n(xRe,"STRONG",{});var VFt=s(nme);Nfo=r(VFt,"vision-encoder-decoder"),VFt.forEach(t),qfo=r(xRe," \u2014 "),kN=n(xRe,"A",{href:!0});var XFt=s(kN);jfo=r(XFt,"VisionEncoderDecoderConfig"),XFt.forEach(t),Dfo=r(xRe," (Vision Encoder decoder model)"),xRe.forEach(t),Gfo=i(L),$h=n(L,"LI",{});var $Re=s($h);sme=n($Re,"STRONG",{});var zFt=s(sme);Ofo=r(zFt,"vision-text-dual-encoder"),zFt.forEach(t),Vfo=r($Re," \u2014 "),SN=n($Re,"A",{href:!0});var QFt=s(SN);Xfo=r(QFt,"VisionTextDualEncoderConfig"),QFt.forEach(t),zfo=r($Re," (VisionTextDualEncoder model)"),$Re.forEach(t),Qfo=i(L),kh=n(L,"LI",{});var kRe=s(kh);lme=n(kRe,"STRONG",{});var WFt=s(lme);Wfo=r(WFt,"visual_bert"),WFt.forEach(t),Ufo=r(kRe," \u2014 "),RN=n(kRe,"A",{href:!0});var UFt=s(RN);Hfo=r(UFt,"VisualBertConfig"),UFt.forEach(t),Jfo=r(kRe," (VisualBERT model)"),kRe.forEach(t),Yfo=i(L),Sh=n(L,"LI",{});var SRe=s(Sh);ime=n(SRe,"STRONG",{});var HFt=s(ime);Kfo=r(HFt,"vit"),HFt.forEach(t),Zfo=r(SRe," \u2014 "),PN=n(SRe,"A",{href:!0});var JFt=s(PN);ego=r(JFt,"ViTConfig"),JFt.forEach(t),ogo=r(SRe," (ViT model)"),SRe.forEach(t),rgo=i(L),Rh=n(L,"LI",{});var RRe=s(Rh);dme=n(RRe,"STRONG",{});var YFt=s(dme);tgo=r(YFt,"vit_mae"),YFt.forEach(t),ago=r(RRe," \u2014 "),BN=n(RRe,"A",{href:!0});var KFt=s(BN);ngo=r(KFt,"ViTMAEConfig"),KFt.forEach(t),sgo=r(RRe," (ViTMAE model)"),RRe.forEach(t),lgo=i(L),Ph=n(L,"LI",{});var PRe=s(Ph);cme=n(PRe,"STRONG",{});var ZFt=s(cme);igo=r(ZFt,"wav2vec2"),ZFt.forEach(t),dgo=r(PRe," \u2014 "),IN=n(PRe,"A",{href:!0});var eTt=s(IN);cgo=r(eTt,"Wav2Vec2Config"),eTt.forEach(t),mgo=r(PRe," (Wav2Vec2 model)"),PRe.forEach(t),fgo=i(L),Bh=n(L,"LI",{});var BRe=s(Bh);mme=n(BRe,"STRONG",{});var oTt=s(mme);ggo=r(oTt,"wav2vec2-conformer"),oTt.forEach(t),hgo=r(BRe," \u2014 "),NN=n(BRe,"A",{href:!0});var rTt=s(NN);ugo=r(rTt,"Wav2Vec2ConformerConfig"),rTt.forEach(t),pgo=r(BRe," (Wav2Vec2-Conformer model)"),BRe.forEach(t),_go=i(L),Ih=n(L,"LI",{});var IRe=s(Ih);fme=n(IRe,"STRONG",{});var tTt=s(fme);bgo=r(tTt,"wavlm"),tTt.forEach(t),vgo=r(IRe," \u2014 "),qN=n(IRe,"A",{href:!0});var aTt=s(qN);Fgo=r(aTt,"WavLMConfig"),aTt.forEach(t),Tgo=r(IRe," (WavLM model)"),IRe.forEach(t),Mgo=i(L),Nh=n(L,"LI",{});var NRe=s(Nh);gme=n(NRe,"STRONG",{});var nTt=s(gme);Ego=r(nTt,"xclip"),nTt.forEach(t),Cgo=r(NRe," \u2014 "),jN=n(NRe,"A",{href:!0});var sTt=s(jN);wgo=r(sTt,"XCLIPConfig"),sTt.forEach(t),Ago=r(NRe," (X-CLIP model)"),NRe.forEach(t),Lgo=i(L),qh=n(L,"LI",{});var qRe=s(qh);hme=n(qRe,"STRONG",{});var lTt=s(hme);ygo=r(lTt,"xglm"),lTt.forEach(t),xgo=r(qRe," \u2014 "),DN=n(qRe,"A",{href:!0});var iTt=s(DN);$go=r(iTt,"XGLMConfig"),iTt.forEach(t),kgo=r(qRe," (XGLM model)"),qRe.forEach(t),Sgo=i(L),jh=n(L,"LI",{});var jRe=s(jh);ume=n(jRe,"STRONG",{});var dTt=s(ume);Rgo=r(dTt,"xlm"),dTt.forEach(t),Pgo=r(jRe," \u2014 "),GN=n(jRe,"A",{href:!0});var cTt=s(GN);Bgo=r(cTt,"XLMConfig"),cTt.forEach(t),Igo=r(jRe," (XLM model)"),jRe.forEach(t),Ngo=i(L),Dh=n(L,"LI",{});var DRe=s(Dh);pme=n(DRe,"STRONG",{});var mTt=s(pme);qgo=r(mTt,"xlm-prophetnet"),mTt.forEach(t),jgo=r(DRe," \u2014 "),ON=n(DRe,"A",{href:!0});var fTt=s(ON);Dgo=r(fTt,"XLMProphetNetConfig"),fTt.forEach(t),Ggo=r(DRe," (XLM-ProphetNet model)"),DRe.forEach(t),Ogo=i(L),Gh=n(L,"LI",{});var GRe=s(Gh);_me=n(GRe,"STRONG",{});var gTt=s(_me);Vgo=r(gTt,"xlm-roberta"),gTt.forEach(t),Xgo=r(GRe," \u2014 "),VN=n(GRe,"A",{href:!0});var hTt=s(VN);zgo=r(hTt,"XLMRobertaConfig"),hTt.forEach(t),Qgo=r(GRe," (XLM-RoBERTa model)"),GRe.forEach(t),Wgo=i(L),Oh=n(L,"LI",{});var ORe=s(Oh);bme=n(ORe,"STRONG",{});var uTt=s(bme);Ugo=r(uTt,"xlm-roberta-xl"),uTt.forEach(t),Hgo=r(ORe," \u2014 "),XN=n(ORe,"A",{href:!0});var pTt=s(XN);Jgo=r(pTt,"XLMRobertaXLConfig"),pTt.forEach(t),Ygo=r(ORe," (XLM-RoBERTa-XL model)"),ORe.forEach(t),Kgo=i(L),Vh=n(L,"LI",{});var VRe=s(Vh);vme=n(VRe,"STRONG",{});var _Tt=s(vme);Zgo=r(_Tt,"xlnet"),_Tt.forEach(t),eho=r(VRe," \u2014 "),zN=n(VRe,"A",{href:!0});var bTt=s(zN);oho=r(bTt,"XLNetConfig"),bTt.forEach(t),rho=r(VRe," (XLNet model)"),VRe.forEach(t),tho=i(L),Xh=n(L,"LI",{});var XRe=s(Xh);Fme=n(XRe,"STRONG",{});var vTt=s(Fme);aho=r(vTt,"yolos"),vTt.forEach(t),nho=r(XRe," \u2014 "),QN=n(XRe,"A",{href:!0});var FTt=s(QN);sho=r(FTt,"YolosConfig"),FTt.forEach(t),lho=r(XRe," (YOLOS model)"),XRe.forEach(t),iho=i(L),zh=n(L,"LI",{});var zRe=s(zh);Tme=n(zRe,"STRONG",{});var TTt=s(Tme);dho=r(TTt,"yoso"),TTt.forEach(t),cho=r(zRe," \u2014 "),WN=n(zRe,"A",{href:!0});var MTt=s(WN);mho=r(MTt,"YosoConfig"),MTt.forEach(t),fho=r(zRe," (YOSO model)"),zRe.forEach(t),L.forEach(t),gho=i(ut),T(Qh.$$.fragment,ut),ut.forEach(t),hho=i(ht),Wh=n(ht,"DIV",{class:!0});var zZe=s(Wh);T($9.$$.fragment,zZe),uho=i(zZe),Mme=n(zZe,"P",{});var ETt=s(Mme);pho=r(ETt,"Register a new configuration for this class."),ETt.forEach(t),zZe.forEach(t),ht.forEach(t),qYe=i(m),fd=n(m,"H2",{class:!0});var QZe=s(fd);Uh=n(QZe,"A",{id:!0,class:!0,href:!0});var CTt=s(Uh);Eme=n(CTt,"SPAN",{});var wTt=s(Eme);T(k9.$$.fragment,wTt),wTt.forEach(t),CTt.forEach(t),_ho=i(QZe),Cme=n(QZe,"SPAN",{});var ATt=s(Cme);bho=r(ATt,"AutoTokenizer"),ATt.forEach(t),QZe.forEach(t),jYe=i(m),ko=n(m,"DIV",{class:!0});var Tl=s(ko);T(S9.$$.fragment,Tl),vho=i(Tl),R9=n(Tl,"P",{});var WZe=s(R9);Fho=r(WZe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UN=n(WZe,"A",{href:!0});var LTt=s(UN);Tho=r(LTt,"AutoTokenizer.from_pretrained()"),LTt.forEach(t),Mho=r(WZe," class method."),WZe.forEach(t),Eho=i(Tl),P9=n(Tl,"P",{});var UZe=s(P9);Cho=r(UZe,"This class cannot be instantiated directly using "),wme=n(UZe,"CODE",{});var yTt=s(wme);who=r(yTt,"__init__()"),yTt.forEach(t),Aho=r(UZe," (throws an error)."),UZe.forEach(t),Lho=i(Tl),Br=n(Tl,"DIV",{class:!0});var Ml=s(Br);T(B9.$$.fragment,Ml),yho=i(Ml),Ame=n(Ml,"P",{});var xTt=s(Ame);xho=r(xTt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),xTt.forEach(t),$ho=i(Ml),Ua=n(Ml,"P",{});var py=s(Ua);kho=r(py,"The tokenizer class to instantiate is selected based on the "),Lme=n(py,"CODE",{});var $Tt=s(Lme);Sho=r($Tt,"model_type"),$Tt.forEach(t),Rho=r(py,` property of the config object (either
passed as an argument or loaded from `),yme=n(py,"CODE",{});var kTt=s(yme);Pho=r(kTt,"pretrained_model_name_or_path"),kTt.forEach(t),Bho=r(py,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xme=n(py,"CODE",{});var STt=s(xme);Iho=r(STt,"pretrained_model_name_or_path"),STt.forEach(t),Nho=r(py,":"),py.forEach(t),qho=i(Ml),k=n(Ml,"UL",{});var S=s(k);as=n(S,"LI",{});var lP=s(as);$me=n(lP,"STRONG",{});var RTt=s($me);jho=r(RTt,"albert"),RTt.forEach(t),Dho=r(lP," \u2014 "),HN=n(lP,"A",{href:!0});var PTt=s(HN);Gho=r(PTt,"AlbertTokenizer"),PTt.forEach(t),Oho=r(lP," or "),JN=n(lP,"A",{href:!0});var BTt=s(JN);Vho=r(BTt,"AlbertTokenizerFast"),BTt.forEach(t),Xho=r(lP," (ALBERT model)"),lP.forEach(t),zho=i(S),ns=n(S,"LI",{});var iP=s(ns);kme=n(iP,"STRONG",{});var ITt=s(kme);Qho=r(ITt,"bart"),ITt.forEach(t),Who=r(iP," \u2014 "),YN=n(iP,"A",{href:!0});var NTt=s(YN);Uho=r(NTt,"BartTokenizer"),NTt.forEach(t),Hho=r(iP," or "),KN=n(iP,"A",{href:!0});var qTt=s(KN);Jho=r(qTt,"BartTokenizerFast"),qTt.forEach(t),Yho=r(iP," (BART model)"),iP.forEach(t),Kho=i(S),ss=n(S,"LI",{});var dP=s(ss);Sme=n(dP,"STRONG",{});var jTt=s(Sme);Zho=r(jTt,"barthez"),jTt.forEach(t),euo=r(dP," \u2014 "),ZN=n(dP,"A",{href:!0});var DTt=s(ZN);ouo=r(DTt,"BarthezTokenizer"),DTt.forEach(t),ruo=r(dP," or "),eq=n(dP,"A",{href:!0});var GTt=s(eq);tuo=r(GTt,"BarthezTokenizerFast"),GTt.forEach(t),auo=r(dP," (BARThez model)"),dP.forEach(t),nuo=i(S),Hh=n(S,"LI",{});var QRe=s(Hh);Rme=n(QRe,"STRONG",{});var OTt=s(Rme);suo=r(OTt,"bartpho"),OTt.forEach(t),luo=r(QRe," \u2014 "),oq=n(QRe,"A",{href:!0});var VTt=s(oq);iuo=r(VTt,"BartphoTokenizer"),VTt.forEach(t),duo=r(QRe," (BARTpho model)"),QRe.forEach(t),cuo=i(S),ls=n(S,"LI",{});var cP=s(ls);Pme=n(cP,"STRONG",{});var XTt=s(Pme);muo=r(XTt,"bert"),XTt.forEach(t),fuo=r(cP," \u2014 "),rq=n(cP,"A",{href:!0});var zTt=s(rq);guo=r(zTt,"BertTokenizer"),zTt.forEach(t),huo=r(cP," or "),tq=n(cP,"A",{href:!0});var QTt=s(tq);uuo=r(QTt,"BertTokenizerFast"),QTt.forEach(t),puo=r(cP," (BERT model)"),cP.forEach(t),_uo=i(S),Jh=n(S,"LI",{});var WRe=s(Jh);Bme=n(WRe,"STRONG",{});var WTt=s(Bme);buo=r(WTt,"bert-generation"),WTt.forEach(t),vuo=r(WRe," \u2014 "),aq=n(WRe,"A",{href:!0});var UTt=s(aq);Fuo=r(UTt,"BertGenerationTokenizer"),UTt.forEach(t),Tuo=r(WRe," (Bert Generation model)"),WRe.forEach(t),Muo=i(S),Yh=n(S,"LI",{});var URe=s(Yh);Ime=n(URe,"STRONG",{});var HTt=s(Ime);Euo=r(HTt,"bert-japanese"),HTt.forEach(t),Cuo=r(URe," \u2014 "),nq=n(URe,"A",{href:!0});var JTt=s(nq);wuo=r(JTt,"BertJapaneseTokenizer"),JTt.forEach(t),Auo=r(URe," (BertJapanese model)"),URe.forEach(t),Luo=i(S),Kh=n(S,"LI",{});var HRe=s(Kh);Nme=n(HRe,"STRONG",{});var YTt=s(Nme);yuo=r(YTt,"bertweet"),YTt.forEach(t),xuo=r(HRe," \u2014 "),sq=n(HRe,"A",{href:!0});var KTt=s(sq);$uo=r(KTt,"BertweetTokenizer"),KTt.forEach(t),kuo=r(HRe," (BERTweet model)"),HRe.forEach(t),Suo=i(S),is=n(S,"LI",{});var mP=s(is);qme=n(mP,"STRONG",{});var ZTt=s(qme);Ruo=r(ZTt,"big_bird"),ZTt.forEach(t),Puo=r(mP," \u2014 "),lq=n(mP,"A",{href:!0});var eMt=s(lq);Buo=r(eMt,"BigBirdTokenizer"),eMt.forEach(t),Iuo=r(mP," or "),iq=n(mP,"A",{href:!0});var oMt=s(iq);Nuo=r(oMt,"BigBirdTokenizerFast"),oMt.forEach(t),quo=r(mP," (BigBird model)"),mP.forEach(t),juo=i(S),ds=n(S,"LI",{});var fP=s(ds);jme=n(fP,"STRONG",{});var rMt=s(jme);Duo=r(rMt,"bigbird_pegasus"),rMt.forEach(t),Guo=r(fP," \u2014 "),dq=n(fP,"A",{href:!0});var tMt=s(dq);Ouo=r(tMt,"PegasusTokenizer"),tMt.forEach(t),Vuo=r(fP," or "),cq=n(fP,"A",{href:!0});var aMt=s(cq);Xuo=r(aMt,"PegasusTokenizerFast"),aMt.forEach(t),zuo=r(fP," (BigBird-Pegasus model)"),fP.forEach(t),Quo=i(S),cs=n(S,"LI",{});var gP=s(cs);Dme=n(gP,"STRONG",{});var nMt=s(Dme);Wuo=r(nMt,"blenderbot"),nMt.forEach(t),Uuo=r(gP," \u2014 "),mq=n(gP,"A",{href:!0});var sMt=s(mq);Huo=r(sMt,"BlenderbotTokenizer"),sMt.forEach(t),Juo=r(gP," or "),fq=n(gP,"A",{href:!0});var lMt=s(fq);Yuo=r(lMt,"BlenderbotTokenizerFast"),lMt.forEach(t),Kuo=r(gP," (Blenderbot model)"),gP.forEach(t),Zuo=i(S),Zh=n(S,"LI",{});var JRe=s(Zh);Gme=n(JRe,"STRONG",{});var iMt=s(Gme);epo=r(iMt,"blenderbot-small"),iMt.forEach(t),opo=r(JRe," \u2014 "),gq=n(JRe,"A",{href:!0});var dMt=s(gq);rpo=r(dMt,"BlenderbotSmallTokenizer"),dMt.forEach(t),tpo=r(JRe," (BlenderbotSmall model)"),JRe.forEach(t),apo=i(S),eu=n(S,"LI",{});var YRe=s(eu);Ome=n(YRe,"STRONG",{});var cMt=s(Ome);npo=r(cMt,"bloom"),cMt.forEach(t),spo=r(YRe," \u2014 "),hq=n(YRe,"A",{href:!0});var mMt=s(hq);lpo=r(mMt,"BloomTokenizerFast"),mMt.forEach(t),ipo=r(YRe," (BLOOM model)"),YRe.forEach(t),dpo=i(S),ou=n(S,"LI",{});var KRe=s(ou);Vme=n(KRe,"STRONG",{});var fMt=s(Vme);cpo=r(fMt,"byt5"),fMt.forEach(t),mpo=r(KRe," \u2014 "),uq=n(KRe,"A",{href:!0});var gMt=s(uq);fpo=r(gMt,"ByT5Tokenizer"),gMt.forEach(t),gpo=r(KRe," (ByT5 model)"),KRe.forEach(t),hpo=i(S),ms=n(S,"LI",{});var hP=s(ms);Xme=n(hP,"STRONG",{});var hMt=s(Xme);upo=r(hMt,"camembert"),hMt.forEach(t),ppo=r(hP," \u2014 "),pq=n(hP,"A",{href:!0});var uMt=s(pq);_po=r(uMt,"CamembertTokenizer"),uMt.forEach(t),bpo=r(hP," or "),_q=n(hP,"A",{href:!0});var pMt=s(_q);vpo=r(pMt,"CamembertTokenizerFast"),pMt.forEach(t),Fpo=r(hP," (CamemBERT model)"),hP.forEach(t),Tpo=i(S),ru=n(S,"LI",{});var ZRe=s(ru);zme=n(ZRe,"STRONG",{});var _Mt=s(zme);Mpo=r(_Mt,"canine"),_Mt.forEach(t),Epo=r(ZRe," \u2014 "),bq=n(ZRe,"A",{href:!0});var bMt=s(bq);Cpo=r(bMt,"CanineTokenizer"),bMt.forEach(t),wpo=r(ZRe," (CANINE model)"),ZRe.forEach(t),Apo=i(S),fs=n(S,"LI",{});var uP=s(fs);Qme=n(uP,"STRONG",{});var vMt=s(Qme);Lpo=r(vMt,"clip"),vMt.forEach(t),ypo=r(uP," \u2014 "),vq=n(uP,"A",{href:!0});var FMt=s(vq);xpo=r(FMt,"CLIPTokenizer"),FMt.forEach(t),$po=r(uP," or "),Fq=n(uP,"A",{href:!0});var TMt=s(Fq);kpo=r(TMt,"CLIPTokenizerFast"),TMt.forEach(t),Spo=r(uP," (CLIP model)"),uP.forEach(t),Rpo=i(S),gs=n(S,"LI",{});var pP=s(gs);Wme=n(pP,"STRONG",{});var MMt=s(Wme);Ppo=r(MMt,"codegen"),MMt.forEach(t),Bpo=r(pP," \u2014 "),Tq=n(pP,"A",{href:!0});var EMt=s(Tq);Ipo=r(EMt,"CodeGenTokenizer"),EMt.forEach(t),Npo=r(pP," or "),Mq=n(pP,"A",{href:!0});var CMt=s(Mq);qpo=r(CMt,"CodeGenTokenizerFast"),CMt.forEach(t),jpo=r(pP," (CodeGen model)"),pP.forEach(t),Dpo=i(S),hs=n(S,"LI",{});var _P=s(hs);Ume=n(_P,"STRONG",{});var wMt=s(Ume);Gpo=r(wMt,"convbert"),wMt.forEach(t),Opo=r(_P," \u2014 "),Eq=n(_P,"A",{href:!0});var AMt=s(Eq);Vpo=r(AMt,"ConvBertTokenizer"),AMt.forEach(t),Xpo=r(_P," or "),Cq=n(_P,"A",{href:!0});var LMt=s(Cq);zpo=r(LMt,"ConvBertTokenizerFast"),LMt.forEach(t),Qpo=r(_P," (ConvBERT model)"),_P.forEach(t),Wpo=i(S),us=n(S,"LI",{});var bP=s(us);Hme=n(bP,"STRONG",{});var yMt=s(Hme);Upo=r(yMt,"cpm"),yMt.forEach(t),Hpo=r(bP," \u2014 "),wq=n(bP,"A",{href:!0});var xMt=s(wq);Jpo=r(xMt,"CpmTokenizer"),xMt.forEach(t),Ypo=r(bP," or "),Aq=n(bP,"A",{href:!0});var $Mt=s(Aq);Kpo=r($Mt,"CpmTokenizerFast"),$Mt.forEach(t),Zpo=r(bP," (CPM model)"),bP.forEach(t),e_o=i(S),tu=n(S,"LI",{});var ePe=s(tu);Jme=n(ePe,"STRONG",{});var kMt=s(Jme);o_o=r(kMt,"ctrl"),kMt.forEach(t),r_o=r(ePe," \u2014 "),Lq=n(ePe,"A",{href:!0});var SMt=s(Lq);t_o=r(SMt,"CTRLTokenizer"),SMt.forEach(t),a_o=r(ePe," (CTRL model)"),ePe.forEach(t),n_o=i(S),ps=n(S,"LI",{});var vP=s(ps);Yme=n(vP,"STRONG",{});var RMt=s(Yme);s_o=r(RMt,"data2vec-text"),RMt.forEach(t),l_o=r(vP," \u2014 "),yq=n(vP,"A",{href:!0});var PMt=s(yq);i_o=r(PMt,"RobertaTokenizer"),PMt.forEach(t),d_o=r(vP," or "),xq=n(vP,"A",{href:!0});var BMt=s(xq);c_o=r(BMt,"RobertaTokenizerFast"),BMt.forEach(t),m_o=r(vP," (Data2VecText model)"),vP.forEach(t),f_o=i(S),_s=n(S,"LI",{});var FP=s(_s);Kme=n(FP,"STRONG",{});var IMt=s(Kme);g_o=r(IMt,"deberta"),IMt.forEach(t),h_o=r(FP," \u2014 "),$q=n(FP,"A",{href:!0});var NMt=s($q);u_o=r(NMt,"DebertaTokenizer"),NMt.forEach(t),p_o=r(FP," or "),kq=n(FP,"A",{href:!0});var qMt=s(kq);__o=r(qMt,"DebertaTokenizerFast"),qMt.forEach(t),b_o=r(FP," (DeBERTa model)"),FP.forEach(t),v_o=i(S),bs=n(S,"LI",{});var TP=s(bs);Zme=n(TP,"STRONG",{});var jMt=s(Zme);F_o=r(jMt,"deberta-v2"),jMt.forEach(t),T_o=r(TP," \u2014 "),Sq=n(TP,"A",{href:!0});var DMt=s(Sq);M_o=r(DMt,"DebertaV2Tokenizer"),DMt.forEach(t),E_o=r(TP," or "),Rq=n(TP,"A",{href:!0});var GMt=s(Rq);C_o=r(GMt,"DebertaV2TokenizerFast"),GMt.forEach(t),w_o=r(TP," (DeBERTa-v2 model)"),TP.forEach(t),A_o=i(S),vs=n(S,"LI",{});var MP=s(vs);efe=n(MP,"STRONG",{});var OMt=s(efe);L_o=r(OMt,"distilbert"),OMt.forEach(t),y_o=r(MP," \u2014 "),Pq=n(MP,"A",{href:!0});var VMt=s(Pq);x_o=r(VMt,"DistilBertTokenizer"),VMt.forEach(t),$_o=r(MP," or "),Bq=n(MP,"A",{href:!0});var XMt=s(Bq);k_o=r(XMt,"DistilBertTokenizerFast"),XMt.forEach(t),S_o=r(MP," (DistilBERT model)"),MP.forEach(t),R_o=i(S),Fs=n(S,"LI",{});var EP=s(Fs);ofe=n(EP,"STRONG",{});var zMt=s(ofe);P_o=r(zMt,"dpr"),zMt.forEach(t),B_o=r(EP," \u2014 "),Iq=n(EP,"A",{href:!0});var QMt=s(Iq);I_o=r(QMt,"DPRQuestionEncoderTokenizer"),QMt.forEach(t),N_o=r(EP," or "),Nq=n(EP,"A",{href:!0});var WMt=s(Nq);q_o=r(WMt,"DPRQuestionEncoderTokenizerFast"),WMt.forEach(t),j_o=r(EP," (DPR model)"),EP.forEach(t),D_o=i(S),Ts=n(S,"LI",{});var CP=s(Ts);rfe=n(CP,"STRONG",{});var UMt=s(rfe);G_o=r(UMt,"electra"),UMt.forEach(t),O_o=r(CP," \u2014 "),qq=n(CP,"A",{href:!0});var HMt=s(qq);V_o=r(HMt,"ElectraTokenizer"),HMt.forEach(t),X_o=r(CP," or "),jq=n(CP,"A",{href:!0});var JMt=s(jq);z_o=r(JMt,"ElectraTokenizerFast"),JMt.forEach(t),Q_o=r(CP," (ELECTRA model)"),CP.forEach(t),W_o=i(S),Ms=n(S,"LI",{});var wP=s(Ms);tfe=n(wP,"STRONG",{});var YMt=s(tfe);U_o=r(YMt,"ernie"),YMt.forEach(t),H_o=r(wP," \u2014 "),Dq=n(wP,"A",{href:!0});var KMt=s(Dq);J_o=r(KMt,"BertTokenizer"),KMt.forEach(t),Y_o=r(wP," or "),Gq=n(wP,"A",{href:!0});var ZMt=s(Gq);K_o=r(ZMt,"BertTokenizerFast"),ZMt.forEach(t),Z_o=r(wP," (ERNIE model)"),wP.forEach(t),e2o=i(S),au=n(S,"LI",{});var oPe=s(au);afe=n(oPe,"STRONG",{});var eEt=s(afe);o2o=r(eEt,"flaubert"),eEt.forEach(t),r2o=r(oPe," \u2014 "),Oq=n(oPe,"A",{href:!0});var oEt=s(Oq);t2o=r(oEt,"FlaubertTokenizer"),oEt.forEach(t),a2o=r(oPe," (FlauBERT model)"),oPe.forEach(t),n2o=i(S),Es=n(S,"LI",{});var AP=s(Es);nfe=n(AP,"STRONG",{});var rEt=s(nfe);s2o=r(rEt,"fnet"),rEt.forEach(t),l2o=r(AP," \u2014 "),Vq=n(AP,"A",{href:!0});var tEt=s(Vq);i2o=r(tEt,"FNetTokenizer"),tEt.forEach(t),d2o=r(AP," or "),Xq=n(AP,"A",{href:!0});var aEt=s(Xq);c2o=r(aEt,"FNetTokenizerFast"),aEt.forEach(t),m2o=r(AP," (FNet model)"),AP.forEach(t),f2o=i(S),nu=n(S,"LI",{});var rPe=s(nu);sfe=n(rPe,"STRONG",{});var nEt=s(sfe);g2o=r(nEt,"fsmt"),nEt.forEach(t),h2o=r(rPe," \u2014 "),zq=n(rPe,"A",{href:!0});var sEt=s(zq);u2o=r(sEt,"FSMTTokenizer"),sEt.forEach(t),p2o=r(rPe," (FairSeq Machine-Translation model)"),rPe.forEach(t),_2o=i(S),Cs=n(S,"LI",{});var LP=s(Cs);lfe=n(LP,"STRONG",{});var lEt=s(lfe);b2o=r(lEt,"funnel"),lEt.forEach(t),v2o=r(LP," \u2014 "),Qq=n(LP,"A",{href:!0});var iEt=s(Qq);F2o=r(iEt,"FunnelTokenizer"),iEt.forEach(t),T2o=r(LP," or "),Wq=n(LP,"A",{href:!0});var dEt=s(Wq);M2o=r(dEt,"FunnelTokenizerFast"),dEt.forEach(t),E2o=r(LP," (Funnel Transformer model)"),LP.forEach(t),C2o=i(S),ws=n(S,"LI",{});var yP=s(ws);ife=n(yP,"STRONG",{});var cEt=s(ife);w2o=r(cEt,"gpt2"),cEt.forEach(t),A2o=r(yP," \u2014 "),Uq=n(yP,"A",{href:!0});var mEt=s(Uq);L2o=r(mEt,"GPT2Tokenizer"),mEt.forEach(t),y2o=r(yP," or "),Hq=n(yP,"A",{href:!0});var fEt=s(Hq);x2o=r(fEt,"GPT2TokenizerFast"),fEt.forEach(t),$2o=r(yP," (OpenAI GPT-2 model)"),yP.forEach(t),k2o=i(S),As=n(S,"LI",{});var xP=s(As);dfe=n(xP,"STRONG",{});var gEt=s(dfe);S2o=r(gEt,"gpt_neo"),gEt.forEach(t),R2o=r(xP," \u2014 "),Jq=n(xP,"A",{href:!0});var hEt=s(Jq);P2o=r(hEt,"GPT2Tokenizer"),hEt.forEach(t),B2o=r(xP," or "),Yq=n(xP,"A",{href:!0});var uEt=s(Yq);I2o=r(uEt,"GPT2TokenizerFast"),uEt.forEach(t),N2o=r(xP," (GPT Neo model)"),xP.forEach(t),q2o=i(S),su=n(S,"LI",{});var tPe=s(su);cfe=n(tPe,"STRONG",{});var pEt=s(cfe);j2o=r(pEt,"gpt_neox"),pEt.forEach(t),D2o=r(tPe," \u2014 "),Kq=n(tPe,"A",{href:!0});var _Et=s(Kq);G2o=r(_Et,"GPTNeoXTokenizerFast"),_Et.forEach(t),O2o=r(tPe," (GPT NeoX model)"),tPe.forEach(t),V2o=i(S),Ls=n(S,"LI",{});var $P=s(Ls);mfe=n($P,"STRONG",{});var bEt=s(mfe);X2o=r(bEt,"gptj"),bEt.forEach(t),z2o=r($P," \u2014 "),Zq=n($P,"A",{href:!0});var vEt=s(Zq);Q2o=r(vEt,"GPT2Tokenizer"),vEt.forEach(t),W2o=r($P," or "),ej=n($P,"A",{href:!0});var FEt=s(ej);U2o=r(FEt,"GPT2TokenizerFast"),FEt.forEach(t),H2o=r($P," (GPT-J model)"),$P.forEach(t),J2o=i(S),ys=n(S,"LI",{});var kP=s(ys);ffe=n(kP,"STRONG",{});var TEt=s(ffe);Y2o=r(TEt,"groupvit"),TEt.forEach(t),K2o=r(kP," \u2014 "),oj=n(kP,"A",{href:!0});var MEt=s(oj);Z2o=r(MEt,"CLIPTokenizer"),MEt.forEach(t),ebo=r(kP," or "),rj=n(kP,"A",{href:!0});var EEt=s(rj);obo=r(EEt,"CLIPTokenizerFast"),EEt.forEach(t),rbo=r(kP," (GroupViT model)"),kP.forEach(t),tbo=i(S),xs=n(S,"LI",{});var SP=s(xs);gfe=n(SP,"STRONG",{});var CEt=s(gfe);abo=r(CEt,"herbert"),CEt.forEach(t),nbo=r(SP," \u2014 "),tj=n(SP,"A",{href:!0});var wEt=s(tj);sbo=r(wEt,"HerbertTokenizer"),wEt.forEach(t),lbo=r(SP," or "),aj=n(SP,"A",{href:!0});var AEt=s(aj);ibo=r(AEt,"HerbertTokenizerFast"),AEt.forEach(t),dbo=r(SP," (HerBERT model)"),SP.forEach(t),cbo=i(S),lu=n(S,"LI",{});var aPe=s(lu);hfe=n(aPe,"STRONG",{});var LEt=s(hfe);mbo=r(LEt,"hubert"),LEt.forEach(t),fbo=r(aPe," \u2014 "),nj=n(aPe,"A",{href:!0});var yEt=s(nj);gbo=r(yEt,"Wav2Vec2CTCTokenizer"),yEt.forEach(t),hbo=r(aPe," (Hubert model)"),aPe.forEach(t),ubo=i(S),$s=n(S,"LI",{});var RP=s($s);ufe=n(RP,"STRONG",{});var xEt=s(ufe);pbo=r(xEt,"ibert"),xEt.forEach(t),_bo=r(RP," \u2014 "),sj=n(RP,"A",{href:!0});var $Et=s(sj);bbo=r($Et,"RobertaTokenizer"),$Et.forEach(t),vbo=r(RP," or "),lj=n(RP,"A",{href:!0});var kEt=s(lj);Fbo=r(kEt,"RobertaTokenizerFast"),kEt.forEach(t),Tbo=r(RP," (I-BERT model)"),RP.forEach(t),Mbo=i(S),ks=n(S,"LI",{});var PP=s(ks);pfe=n(PP,"STRONG",{});var SEt=s(pfe);Ebo=r(SEt,"layoutlm"),SEt.forEach(t),Cbo=r(PP," \u2014 "),ij=n(PP,"A",{href:!0});var REt=s(ij);wbo=r(REt,"LayoutLMTokenizer"),REt.forEach(t),Abo=r(PP," or "),dj=n(PP,"A",{href:!0});var PEt=s(dj);Lbo=r(PEt,"LayoutLMTokenizerFast"),PEt.forEach(t),ybo=r(PP," (LayoutLM model)"),PP.forEach(t),xbo=i(S),Ss=n(S,"LI",{});var BP=s(Ss);_fe=n(BP,"STRONG",{});var BEt=s(_fe);$bo=r(BEt,"layoutlmv2"),BEt.forEach(t),kbo=r(BP," \u2014 "),cj=n(BP,"A",{href:!0});var IEt=s(cj);Sbo=r(IEt,"LayoutLMv2Tokenizer"),IEt.forEach(t),Rbo=r(BP," or "),mj=n(BP,"A",{href:!0});var NEt=s(mj);Pbo=r(NEt,"LayoutLMv2TokenizerFast"),NEt.forEach(t),Bbo=r(BP," (LayoutLMv2 model)"),BP.forEach(t),Ibo=i(S),Rs=n(S,"LI",{});var IP=s(Rs);bfe=n(IP,"STRONG",{});var qEt=s(bfe);Nbo=r(qEt,"layoutlmv3"),qEt.forEach(t),qbo=r(IP," \u2014 "),fj=n(IP,"A",{href:!0});var jEt=s(fj);jbo=r(jEt,"LayoutLMv3Tokenizer"),jEt.forEach(t),Dbo=r(IP," or "),gj=n(IP,"A",{href:!0});var DEt=s(gj);Gbo=r(DEt,"LayoutLMv3TokenizerFast"),DEt.forEach(t),Obo=r(IP," (LayoutLMv3 model)"),IP.forEach(t),Vbo=i(S),Ps=n(S,"LI",{});var NP=s(Ps);vfe=n(NP,"STRONG",{});var GEt=s(vfe);Xbo=r(GEt,"layoutxlm"),GEt.forEach(t),zbo=r(NP," \u2014 "),hj=n(NP,"A",{href:!0});var OEt=s(hj);Qbo=r(OEt,"LayoutXLMTokenizer"),OEt.forEach(t),Wbo=r(NP," or "),uj=n(NP,"A",{href:!0});var VEt=s(uj);Ubo=r(VEt,"LayoutXLMTokenizerFast"),VEt.forEach(t),Hbo=r(NP," (LayoutXLM model)"),NP.forEach(t),Jbo=i(S),Bs=n(S,"LI",{});var qP=s(Bs);Ffe=n(qP,"STRONG",{});var XEt=s(Ffe);Ybo=r(XEt,"led"),XEt.forEach(t),Kbo=r(qP," \u2014 "),pj=n(qP,"A",{href:!0});var zEt=s(pj);Zbo=r(zEt,"LEDTokenizer"),zEt.forEach(t),e1o=r(qP," or "),_j=n(qP,"A",{href:!0});var QEt=s(_j);o1o=r(QEt,"LEDTokenizerFast"),QEt.forEach(t),r1o=r(qP," (LED model)"),qP.forEach(t),t1o=i(S),Is=n(S,"LI",{});var jP=s(Is);Tfe=n(jP,"STRONG",{});var WEt=s(Tfe);a1o=r(WEt,"longformer"),WEt.forEach(t),n1o=r(jP," \u2014 "),bj=n(jP,"A",{href:!0});var UEt=s(bj);s1o=r(UEt,"LongformerTokenizer"),UEt.forEach(t),l1o=r(jP," or "),vj=n(jP,"A",{href:!0});var HEt=s(vj);i1o=r(HEt,"LongformerTokenizerFast"),HEt.forEach(t),d1o=r(jP," (Longformer model)"),jP.forEach(t),c1o=i(S),Ns=n(S,"LI",{});var DP=s(Ns);Mfe=n(DP,"STRONG",{});var JEt=s(Mfe);m1o=r(JEt,"longt5"),JEt.forEach(t),f1o=r(DP," \u2014 "),Fj=n(DP,"A",{href:!0});var YEt=s(Fj);g1o=r(YEt,"T5Tokenizer"),YEt.forEach(t),h1o=r(DP," or "),Tj=n(DP,"A",{href:!0});var KEt=s(Tj);u1o=r(KEt,"T5TokenizerFast"),KEt.forEach(t),p1o=r(DP," (LongT5 model)"),DP.forEach(t),_1o=i(S),iu=n(S,"LI",{});var nPe=s(iu);Efe=n(nPe,"STRONG",{});var ZEt=s(Efe);b1o=r(ZEt,"luke"),ZEt.forEach(t),v1o=r(nPe," \u2014 "),Mj=n(nPe,"A",{href:!0});var e4t=s(Mj);F1o=r(e4t,"LukeTokenizer"),e4t.forEach(t),T1o=r(nPe," (LUKE model)"),nPe.forEach(t),M1o=i(S),qs=n(S,"LI",{});var GP=s(qs);Cfe=n(GP,"STRONG",{});var o4t=s(Cfe);E1o=r(o4t,"lxmert"),o4t.forEach(t),C1o=r(GP," \u2014 "),Ej=n(GP,"A",{href:!0});var r4t=s(Ej);w1o=r(r4t,"LxmertTokenizer"),r4t.forEach(t),A1o=r(GP," or "),Cj=n(GP,"A",{href:!0});var t4t=s(Cj);L1o=r(t4t,"LxmertTokenizerFast"),t4t.forEach(t),y1o=r(GP," (LXMERT model)"),GP.forEach(t),x1o=i(S),du=n(S,"LI",{});var sPe=s(du);wfe=n(sPe,"STRONG",{});var a4t=s(wfe);$1o=r(a4t,"m2m_100"),a4t.forEach(t),k1o=r(sPe," \u2014 "),wj=n(sPe,"A",{href:!0});var n4t=s(wj);S1o=r(n4t,"M2M100Tokenizer"),n4t.forEach(t),R1o=r(sPe," (M2M100 model)"),sPe.forEach(t),P1o=i(S),cu=n(S,"LI",{});var lPe=s(cu);Afe=n(lPe,"STRONG",{});var s4t=s(Afe);B1o=r(s4t,"marian"),s4t.forEach(t),I1o=r(lPe," \u2014 "),Aj=n(lPe,"A",{href:!0});var l4t=s(Aj);N1o=r(l4t,"MarianTokenizer"),l4t.forEach(t),q1o=r(lPe," (Marian model)"),lPe.forEach(t),j1o=i(S),js=n(S,"LI",{});var OP=s(js);Lfe=n(OP,"STRONG",{});var i4t=s(Lfe);D1o=r(i4t,"mbart"),i4t.forEach(t),G1o=r(OP," \u2014 "),Lj=n(OP,"A",{href:!0});var d4t=s(Lj);O1o=r(d4t,"MBartTokenizer"),d4t.forEach(t),V1o=r(OP," or "),yj=n(OP,"A",{href:!0});var c4t=s(yj);X1o=r(c4t,"MBartTokenizerFast"),c4t.forEach(t),z1o=r(OP," (mBART model)"),OP.forEach(t),Q1o=i(S),Ds=n(S,"LI",{});var VP=s(Ds);yfe=n(VP,"STRONG",{});var m4t=s(yfe);W1o=r(m4t,"mbart50"),m4t.forEach(t),U1o=r(VP," \u2014 "),xj=n(VP,"A",{href:!0});var f4t=s(xj);H1o=r(f4t,"MBart50Tokenizer"),f4t.forEach(t),J1o=r(VP," or "),$j=n(VP,"A",{href:!0});var g4t=s($j);Y1o=r(g4t,"MBart50TokenizerFast"),g4t.forEach(t),K1o=r(VP," (mBART-50 model)"),VP.forEach(t),Z1o=i(S),Gs=n(S,"LI",{});var XP=s(Gs);xfe=n(XP,"STRONG",{});var h4t=s(xfe);evo=r(h4t,"megatron-bert"),h4t.forEach(t),ovo=r(XP," \u2014 "),kj=n(XP,"A",{href:!0});var u4t=s(kj);rvo=r(u4t,"BertTokenizer"),u4t.forEach(t),tvo=r(XP," or "),Sj=n(XP,"A",{href:!0});var p4t=s(Sj);avo=r(p4t,"BertTokenizerFast"),p4t.forEach(t),nvo=r(XP," (Megatron-BERT model)"),XP.forEach(t),svo=i(S),mu=n(S,"LI",{});var iPe=s(mu);$fe=n(iPe,"STRONG",{});var _4t=s($fe);lvo=r(_4t,"mluke"),_4t.forEach(t),ivo=r(iPe," \u2014 "),Rj=n(iPe,"A",{href:!0});var b4t=s(Rj);dvo=r(b4t,"MLukeTokenizer"),b4t.forEach(t),cvo=r(iPe," (mLUKE model)"),iPe.forEach(t),mvo=i(S),Os=n(S,"LI",{});var zP=s(Os);kfe=n(zP,"STRONG",{});var v4t=s(kfe);fvo=r(v4t,"mobilebert"),v4t.forEach(t),gvo=r(zP," \u2014 "),Pj=n(zP,"A",{href:!0});var F4t=s(Pj);hvo=r(F4t,"MobileBertTokenizer"),F4t.forEach(t),uvo=r(zP," or "),Bj=n(zP,"A",{href:!0});var T4t=s(Bj);pvo=r(T4t,"MobileBertTokenizerFast"),T4t.forEach(t),_vo=r(zP," (MobileBERT model)"),zP.forEach(t),bvo=i(S),Vs=n(S,"LI",{});var QP=s(Vs);Sfe=n(QP,"STRONG",{});var M4t=s(Sfe);vvo=r(M4t,"mpnet"),M4t.forEach(t),Fvo=r(QP," \u2014 "),Ij=n(QP,"A",{href:!0});var E4t=s(Ij);Tvo=r(E4t,"MPNetTokenizer"),E4t.forEach(t),Mvo=r(QP," or "),Nj=n(QP,"A",{href:!0});var C4t=s(Nj);Evo=r(C4t,"MPNetTokenizerFast"),C4t.forEach(t),Cvo=r(QP," (MPNet model)"),QP.forEach(t),wvo=i(S),Xs=n(S,"LI",{});var WP=s(Xs);Rfe=n(WP,"STRONG",{});var w4t=s(Rfe);Avo=r(w4t,"mt5"),w4t.forEach(t),Lvo=r(WP," \u2014 "),qj=n(WP,"A",{href:!0});var A4t=s(qj);yvo=r(A4t,"MT5Tokenizer"),A4t.forEach(t),xvo=r(WP," or "),jj=n(WP,"A",{href:!0});var L4t=s(jj);$vo=r(L4t,"MT5TokenizerFast"),L4t.forEach(t),kvo=r(WP," (MT5 model)"),WP.forEach(t),Svo=i(S),zs=n(S,"LI",{});var UP=s(zs);Pfe=n(UP,"STRONG",{});var y4t=s(Pfe);Rvo=r(y4t,"mvp"),y4t.forEach(t),Pvo=r(UP," \u2014 "),Dj=n(UP,"A",{href:!0});var x4t=s(Dj);Bvo=r(x4t,"MvpTokenizer"),x4t.forEach(t),Ivo=r(UP," or "),Gj=n(UP,"A",{href:!0});var $4t=s(Gj);Nvo=r($4t,"MvpTokenizerFast"),$4t.forEach(t),qvo=r(UP," (MVP model)"),UP.forEach(t),jvo=i(S),Qs=n(S,"LI",{});var HP=s(Qs);Bfe=n(HP,"STRONG",{});var k4t=s(Bfe);Dvo=r(k4t,"nezha"),k4t.forEach(t),Gvo=r(HP," \u2014 "),Oj=n(HP,"A",{href:!0});var S4t=s(Oj);Ovo=r(S4t,"BertTokenizer"),S4t.forEach(t),Vvo=r(HP," or "),Vj=n(HP,"A",{href:!0});var R4t=s(Vj);Xvo=r(R4t,"BertTokenizerFast"),R4t.forEach(t),zvo=r(HP," (Nezha model)"),HP.forEach(t),Qvo=i(S),Ws=n(S,"LI",{});var JP=s(Ws);Ife=n(JP,"STRONG",{});var P4t=s(Ife);Wvo=r(P4t,"nllb"),P4t.forEach(t),Uvo=r(JP," \u2014 "),Xj=n(JP,"A",{href:!0});var B4t=s(Xj);Hvo=r(B4t,"NllbTokenizer"),B4t.forEach(t),Jvo=r(JP," or "),zj=n(JP,"A",{href:!0});var I4t=s(zj);Yvo=r(I4t,"NllbTokenizerFast"),I4t.forEach(t),Kvo=r(JP," (NLLB model)"),JP.forEach(t),Zvo=i(S),Us=n(S,"LI",{});var YP=s(Us);Nfe=n(YP,"STRONG",{});var N4t=s(Nfe);eFo=r(N4t,"nystromformer"),N4t.forEach(t),oFo=r(YP," \u2014 "),Qj=n(YP,"A",{href:!0});var q4t=s(Qj);rFo=r(q4t,"AlbertTokenizer"),q4t.forEach(t),tFo=r(YP," or "),Wj=n(YP,"A",{href:!0});var j4t=s(Wj);aFo=r(j4t,"AlbertTokenizerFast"),j4t.forEach(t),nFo=r(YP," (Nystr\xF6mformer model)"),YP.forEach(t),sFo=i(S),Hs=n(S,"LI",{});var KP=s(Hs);qfe=n(KP,"STRONG",{});var D4t=s(qfe);lFo=r(D4t,"openai-gpt"),D4t.forEach(t),iFo=r(KP," \u2014 "),Uj=n(KP,"A",{href:!0});var G4t=s(Uj);dFo=r(G4t,"OpenAIGPTTokenizer"),G4t.forEach(t),cFo=r(KP," or "),Hj=n(KP,"A",{href:!0});var O4t=s(Hj);mFo=r(O4t,"OpenAIGPTTokenizerFast"),O4t.forEach(t),fFo=r(KP," (OpenAI GPT model)"),KP.forEach(t),gFo=i(S),fu=n(S,"LI",{});var dPe=s(fu);jfe=n(dPe,"STRONG",{});var V4t=s(jfe);hFo=r(V4t,"opt"),V4t.forEach(t),uFo=r(dPe," \u2014 "),Jj=n(dPe,"A",{href:!0});var X4t=s(Jj);pFo=r(X4t,"GPT2Tokenizer"),X4t.forEach(t),_Fo=r(dPe," (OPT model)"),dPe.forEach(t),bFo=i(S),Js=n(S,"LI",{});var ZP=s(Js);Dfe=n(ZP,"STRONG",{});var z4t=s(Dfe);vFo=r(z4t,"owlvit"),z4t.forEach(t),FFo=r(ZP," \u2014 "),Yj=n(ZP,"A",{href:!0});var Q4t=s(Yj);TFo=r(Q4t,"CLIPTokenizer"),Q4t.forEach(t),MFo=r(ZP," or "),Kj=n(ZP,"A",{href:!0});var W4t=s(Kj);EFo=r(W4t,"CLIPTokenizerFast"),W4t.forEach(t),CFo=r(ZP," (OWL-ViT model)"),ZP.forEach(t),wFo=i(S),Ys=n(S,"LI",{});var eB=s(Ys);Gfe=n(eB,"STRONG",{});var U4t=s(Gfe);AFo=r(U4t,"pegasus"),U4t.forEach(t),LFo=r(eB," \u2014 "),Zj=n(eB,"A",{href:!0});var H4t=s(Zj);yFo=r(H4t,"PegasusTokenizer"),H4t.forEach(t),xFo=r(eB," or "),eD=n(eB,"A",{href:!0});var J4t=s(eD);$Fo=r(J4t,"PegasusTokenizerFast"),J4t.forEach(t),kFo=r(eB," (Pegasus model)"),eB.forEach(t),SFo=i(S),gu=n(S,"LI",{});var cPe=s(gu);Ofe=n(cPe,"STRONG",{});var Y4t=s(Ofe);RFo=r(Y4t,"perceiver"),Y4t.forEach(t),PFo=r(cPe," \u2014 "),oD=n(cPe,"A",{href:!0});var K4t=s(oD);BFo=r(K4t,"PerceiverTokenizer"),K4t.forEach(t),IFo=r(cPe," (Perceiver model)"),cPe.forEach(t),NFo=i(S),hu=n(S,"LI",{});var mPe=s(hu);Vfe=n(mPe,"STRONG",{});var Z4t=s(Vfe);qFo=r(Z4t,"phobert"),Z4t.forEach(t),jFo=r(mPe," \u2014 "),rD=n(mPe,"A",{href:!0});var eCt=s(rD);DFo=r(eCt,"PhobertTokenizer"),eCt.forEach(t),GFo=r(mPe," (PhoBERT model)"),mPe.forEach(t),OFo=i(S),uu=n(S,"LI",{});var fPe=s(uu);Xfe=n(fPe,"STRONG",{});var oCt=s(Xfe);VFo=r(oCt,"plbart"),oCt.forEach(t),XFo=r(fPe," \u2014 "),tD=n(fPe,"A",{href:!0});var rCt=s(tD);zFo=r(rCt,"PLBartTokenizer"),rCt.forEach(t),QFo=r(fPe," (PLBart model)"),fPe.forEach(t),WFo=i(S),pu=n(S,"LI",{});var gPe=s(pu);zfe=n(gPe,"STRONG",{});var tCt=s(zfe);UFo=r(tCt,"prophetnet"),tCt.forEach(t),HFo=r(gPe," \u2014 "),aD=n(gPe,"A",{href:!0});var aCt=s(aD);JFo=r(aCt,"ProphetNetTokenizer"),aCt.forEach(t),YFo=r(gPe," (ProphetNet model)"),gPe.forEach(t),KFo=i(S),Ks=n(S,"LI",{});var oB=s(Ks);Qfe=n(oB,"STRONG",{});var nCt=s(Qfe);ZFo=r(nCt,"qdqbert"),nCt.forEach(t),eTo=r(oB," \u2014 "),nD=n(oB,"A",{href:!0});var sCt=s(nD);oTo=r(sCt,"BertTokenizer"),sCt.forEach(t),rTo=r(oB," or "),sD=n(oB,"A",{href:!0});var lCt=s(sD);tTo=r(lCt,"BertTokenizerFast"),lCt.forEach(t),aTo=r(oB," (QDQBert model)"),oB.forEach(t),nTo=i(S),_u=n(S,"LI",{});var hPe=s(_u);Wfe=n(hPe,"STRONG",{});var iCt=s(Wfe);sTo=r(iCt,"rag"),iCt.forEach(t),lTo=r(hPe," \u2014 "),lD=n(hPe,"A",{href:!0});var dCt=s(lD);iTo=r(dCt,"RagTokenizer"),dCt.forEach(t),dTo=r(hPe," (RAG model)"),hPe.forEach(t),cTo=i(S),Zs=n(S,"LI",{});var rB=s(Zs);Ufe=n(rB,"STRONG",{});var cCt=s(Ufe);mTo=r(cCt,"realm"),cCt.forEach(t),fTo=r(rB," \u2014 "),iD=n(rB,"A",{href:!0});var mCt=s(iD);gTo=r(mCt,"RealmTokenizer"),mCt.forEach(t),hTo=r(rB," or "),dD=n(rB,"A",{href:!0});var fCt=s(dD);uTo=r(fCt,"RealmTokenizerFast"),fCt.forEach(t),pTo=r(rB," (REALM model)"),rB.forEach(t),_To=i(S),el=n(S,"LI",{});var tB=s(el);Hfe=n(tB,"STRONG",{});var gCt=s(Hfe);bTo=r(gCt,"reformer"),gCt.forEach(t),vTo=r(tB," \u2014 "),cD=n(tB,"A",{href:!0});var hCt=s(cD);FTo=r(hCt,"ReformerTokenizer"),hCt.forEach(t),TTo=r(tB," or "),mD=n(tB,"A",{href:!0});var uCt=s(mD);MTo=r(uCt,"ReformerTokenizerFast"),uCt.forEach(t),ETo=r(tB," (Reformer model)"),tB.forEach(t),CTo=i(S),ol=n(S,"LI",{});var aB=s(ol);Jfe=n(aB,"STRONG",{});var pCt=s(Jfe);wTo=r(pCt,"rembert"),pCt.forEach(t),ATo=r(aB," \u2014 "),fD=n(aB,"A",{href:!0});var _Ct=s(fD);LTo=r(_Ct,"RemBertTokenizer"),_Ct.forEach(t),yTo=r(aB," or "),gD=n(aB,"A",{href:!0});var bCt=s(gD);xTo=r(bCt,"RemBertTokenizerFast"),bCt.forEach(t),$To=r(aB," (RemBERT model)"),aB.forEach(t),kTo=i(S),rl=n(S,"LI",{});var nB=s(rl);Yfe=n(nB,"STRONG",{});var vCt=s(Yfe);STo=r(vCt,"retribert"),vCt.forEach(t),RTo=r(nB," \u2014 "),hD=n(nB,"A",{href:!0});var FCt=s(hD);PTo=r(FCt,"RetriBertTokenizer"),FCt.forEach(t),BTo=r(nB," or "),uD=n(nB,"A",{href:!0});var TCt=s(uD);ITo=r(TCt,"RetriBertTokenizerFast"),TCt.forEach(t),NTo=r(nB," (RetriBERT model)"),nB.forEach(t),qTo=i(S),tl=n(S,"LI",{});var sB=s(tl);Kfe=n(sB,"STRONG",{});var MCt=s(Kfe);jTo=r(MCt,"roberta"),MCt.forEach(t),DTo=r(sB," \u2014 "),pD=n(sB,"A",{href:!0});var ECt=s(pD);GTo=r(ECt,"RobertaTokenizer"),ECt.forEach(t),OTo=r(sB," or "),_D=n(sB,"A",{href:!0});var CCt=s(_D);VTo=r(CCt,"RobertaTokenizerFast"),CCt.forEach(t),XTo=r(sB," (RoBERTa model)"),sB.forEach(t),zTo=i(S),al=n(S,"LI",{});var lB=s(al);Zfe=n(lB,"STRONG",{});var wCt=s(Zfe);QTo=r(wCt,"roformer"),wCt.forEach(t),WTo=r(lB," \u2014 "),bD=n(lB,"A",{href:!0});var ACt=s(bD);UTo=r(ACt,"RoFormerTokenizer"),ACt.forEach(t),HTo=r(lB," or "),vD=n(lB,"A",{href:!0});var LCt=s(vD);JTo=r(LCt,"RoFormerTokenizerFast"),LCt.forEach(t),YTo=r(lB," (RoFormer model)"),lB.forEach(t),KTo=i(S),bu=n(S,"LI",{});var uPe=s(bu);ege=n(uPe,"STRONG",{});var yCt=s(ege);ZTo=r(yCt,"speech_to_text"),yCt.forEach(t),eMo=r(uPe," \u2014 "),FD=n(uPe,"A",{href:!0});var xCt=s(FD);oMo=r(xCt,"Speech2TextTokenizer"),xCt.forEach(t),rMo=r(uPe," (Speech2Text model)"),uPe.forEach(t),tMo=i(S),vu=n(S,"LI",{});var pPe=s(vu);oge=n(pPe,"STRONG",{});var $Ct=s(oge);aMo=r($Ct,"speech_to_text_2"),$Ct.forEach(t),nMo=r(pPe," \u2014 "),TD=n(pPe,"A",{href:!0});var kCt=s(TD);sMo=r(kCt,"Speech2Text2Tokenizer"),kCt.forEach(t),lMo=r(pPe," (Speech2Text2 model)"),pPe.forEach(t),iMo=i(S),nl=n(S,"LI",{});var iB=s(nl);rge=n(iB,"STRONG",{});var SCt=s(rge);dMo=r(SCt,"splinter"),SCt.forEach(t),cMo=r(iB," \u2014 "),MD=n(iB,"A",{href:!0});var RCt=s(MD);mMo=r(RCt,"SplinterTokenizer"),RCt.forEach(t),fMo=r(iB," or "),ED=n(iB,"A",{href:!0});var PCt=s(ED);gMo=r(PCt,"SplinterTokenizerFast"),PCt.forEach(t),hMo=r(iB," (Splinter model)"),iB.forEach(t),uMo=i(S),sl=n(S,"LI",{});var dB=s(sl);tge=n(dB,"STRONG",{});var BCt=s(tge);pMo=r(BCt,"squeezebert"),BCt.forEach(t),_Mo=r(dB," \u2014 "),CD=n(dB,"A",{href:!0});var ICt=s(CD);bMo=r(ICt,"SqueezeBertTokenizer"),ICt.forEach(t),vMo=r(dB," or "),wD=n(dB,"A",{href:!0});var NCt=s(wD);FMo=r(NCt,"SqueezeBertTokenizerFast"),NCt.forEach(t),TMo=r(dB," (SqueezeBERT model)"),dB.forEach(t),MMo=i(S),ll=n(S,"LI",{});var cB=s(ll);age=n(cB,"STRONG",{});var qCt=s(age);EMo=r(qCt,"t5"),qCt.forEach(t),CMo=r(cB," \u2014 "),AD=n(cB,"A",{href:!0});var jCt=s(AD);wMo=r(jCt,"T5Tokenizer"),jCt.forEach(t),AMo=r(cB," or "),LD=n(cB,"A",{href:!0});var DCt=s(LD);LMo=r(DCt,"T5TokenizerFast"),DCt.forEach(t),yMo=r(cB," (T5 model)"),cB.forEach(t),xMo=i(S),Fu=n(S,"LI",{});var _Pe=s(Fu);nge=n(_Pe,"STRONG",{});var GCt=s(nge);$Mo=r(GCt,"tapas"),GCt.forEach(t),kMo=r(_Pe," \u2014 "),yD=n(_Pe,"A",{href:!0});var OCt=s(yD);SMo=r(OCt,"TapasTokenizer"),OCt.forEach(t),RMo=r(_Pe," (TAPAS model)"),_Pe.forEach(t),PMo=i(S),Tu=n(S,"LI",{});var bPe=s(Tu);sge=n(bPe,"STRONG",{});var VCt=s(sge);BMo=r(VCt,"tapex"),VCt.forEach(t),IMo=r(bPe," \u2014 "),xD=n(bPe,"A",{href:!0});var XCt=s(xD);NMo=r(XCt,"TapexTokenizer"),XCt.forEach(t),qMo=r(bPe," (TAPEX model)"),bPe.forEach(t),jMo=i(S),Mu=n(S,"LI",{});var vPe=s(Mu);lge=n(vPe,"STRONG",{});var zCt=s(lge);DMo=r(zCt,"transfo-xl"),zCt.forEach(t),GMo=r(vPe," \u2014 "),$D=n(vPe,"A",{href:!0});var QCt=s($D);OMo=r(QCt,"TransfoXLTokenizer"),QCt.forEach(t),VMo=r(vPe," (Transformer-XL model)"),vPe.forEach(t),XMo=i(S),il=n(S,"LI",{});var mB=s(il);ige=n(mB,"STRONG",{});var WCt=s(ige);zMo=r(WCt,"vilt"),WCt.forEach(t),QMo=r(mB," \u2014 "),kD=n(mB,"A",{href:!0});var UCt=s(kD);WMo=r(UCt,"BertTokenizer"),UCt.forEach(t),UMo=r(mB," or "),SD=n(mB,"A",{href:!0});var HCt=s(SD);HMo=r(HCt,"BertTokenizerFast"),HCt.forEach(t),JMo=r(mB," (ViLT model)"),mB.forEach(t),YMo=i(S),dl=n(S,"LI",{});var fB=s(dl);dge=n(fB,"STRONG",{});var JCt=s(dge);KMo=r(JCt,"visual_bert"),JCt.forEach(t),ZMo=r(fB," \u2014 "),RD=n(fB,"A",{href:!0});var YCt=s(RD);eEo=r(YCt,"BertTokenizer"),YCt.forEach(t),oEo=r(fB," or "),PD=n(fB,"A",{href:!0});var KCt=s(PD);rEo=r(KCt,"BertTokenizerFast"),KCt.forEach(t),tEo=r(fB," (VisualBERT model)"),fB.forEach(t),aEo=i(S),Eu=n(S,"LI",{});var FPe=s(Eu);cge=n(FPe,"STRONG",{});var ZCt=s(cge);nEo=r(ZCt,"wav2vec2"),ZCt.forEach(t),sEo=r(FPe," \u2014 "),BD=n(FPe,"A",{href:!0});var e3t=s(BD);lEo=r(e3t,"Wav2Vec2CTCTokenizer"),e3t.forEach(t),iEo=r(FPe," (Wav2Vec2 model)"),FPe.forEach(t),dEo=i(S),Cu=n(S,"LI",{});var TPe=s(Cu);mge=n(TPe,"STRONG",{});var o3t=s(mge);cEo=r(o3t,"wav2vec2-conformer"),o3t.forEach(t),mEo=r(TPe," \u2014 "),ID=n(TPe,"A",{href:!0});var r3t=s(ID);fEo=r(r3t,"Wav2Vec2CTCTokenizer"),r3t.forEach(t),gEo=r(TPe," (Wav2Vec2-Conformer model)"),TPe.forEach(t),hEo=i(S),wu=n(S,"LI",{});var MPe=s(wu);fge=n(MPe,"STRONG",{});var t3t=s(fge);uEo=r(t3t,"wav2vec2_phoneme"),t3t.forEach(t),pEo=r(MPe," \u2014 "),ND=n(MPe,"A",{href:!0});var a3t=s(ND);_Eo=r(a3t,"Wav2Vec2PhonemeCTCTokenizer"),a3t.forEach(t),bEo=r(MPe," (Wav2Vec2Phoneme model)"),MPe.forEach(t),vEo=i(S),cl=n(S,"LI",{});var gB=s(cl);gge=n(gB,"STRONG",{});var n3t=s(gge);FEo=r(n3t,"xclip"),n3t.forEach(t),TEo=r(gB," \u2014 "),qD=n(gB,"A",{href:!0});var s3t=s(qD);MEo=r(s3t,"CLIPTokenizer"),s3t.forEach(t),EEo=r(gB," or "),jD=n(gB,"A",{href:!0});var l3t=s(jD);CEo=r(l3t,"CLIPTokenizerFast"),l3t.forEach(t),wEo=r(gB," (X-CLIP model)"),gB.forEach(t),AEo=i(S),ml=n(S,"LI",{});var hB=s(ml);hge=n(hB,"STRONG",{});var i3t=s(hge);LEo=r(i3t,"xglm"),i3t.forEach(t),yEo=r(hB," \u2014 "),DD=n(hB,"A",{href:!0});var d3t=s(DD);xEo=r(d3t,"XGLMTokenizer"),d3t.forEach(t),$Eo=r(hB," or "),GD=n(hB,"A",{href:!0});var c3t=s(GD);kEo=r(c3t,"XGLMTokenizerFast"),c3t.forEach(t),SEo=r(hB," (XGLM model)"),hB.forEach(t),REo=i(S),Au=n(S,"LI",{});var EPe=s(Au);uge=n(EPe,"STRONG",{});var m3t=s(uge);PEo=r(m3t,"xlm"),m3t.forEach(t),BEo=r(EPe," \u2014 "),OD=n(EPe,"A",{href:!0});var f3t=s(OD);IEo=r(f3t,"XLMTokenizer"),f3t.forEach(t),NEo=r(EPe," (XLM model)"),EPe.forEach(t),qEo=i(S),Lu=n(S,"LI",{});var CPe=s(Lu);pge=n(CPe,"STRONG",{});var g3t=s(pge);jEo=r(g3t,"xlm-prophetnet"),g3t.forEach(t),DEo=r(CPe," \u2014 "),VD=n(CPe,"A",{href:!0});var h3t=s(VD);GEo=r(h3t,"XLMProphetNetTokenizer"),h3t.forEach(t),OEo=r(CPe," (XLM-ProphetNet model)"),CPe.forEach(t),VEo=i(S),fl=n(S,"LI",{});var uB=s(fl);_ge=n(uB,"STRONG",{});var u3t=s(_ge);XEo=r(u3t,"xlm-roberta"),u3t.forEach(t),zEo=r(uB," \u2014 "),XD=n(uB,"A",{href:!0});var p3t=s(XD);QEo=r(p3t,"XLMRobertaTokenizer"),p3t.forEach(t),WEo=r(uB," or "),zD=n(uB,"A",{href:!0});var _3t=s(zD);UEo=r(_3t,"XLMRobertaTokenizerFast"),_3t.forEach(t),HEo=r(uB," (XLM-RoBERTa model)"),uB.forEach(t),JEo=i(S),gl=n(S,"LI",{});var pB=s(gl);bge=n(pB,"STRONG",{});var b3t=s(bge);YEo=r(b3t,"xlm-roberta-xl"),b3t.forEach(t),KEo=r(pB," \u2014 "),QD=n(pB,"A",{href:!0});var v3t=s(QD);ZEo=r(v3t,"XLMRobertaTokenizer"),v3t.forEach(t),e4o=r(pB," or "),WD=n(pB,"A",{href:!0});var F3t=s(WD);o4o=r(F3t,"XLMRobertaTokenizerFast"),F3t.forEach(t),r4o=r(pB," (XLM-RoBERTa-XL model)"),pB.forEach(t),t4o=i(S),hl=n(S,"LI",{});var _B=s(hl);vge=n(_B,"STRONG",{});var T3t=s(vge);a4o=r(T3t,"xlnet"),T3t.forEach(t),n4o=r(_B," \u2014 "),UD=n(_B,"A",{href:!0});var M3t=s(UD);s4o=r(M3t,"XLNetTokenizer"),M3t.forEach(t),l4o=r(_B," or "),HD=n(_B,"A",{href:!0});var E3t=s(HD);i4o=r(E3t,"XLNetTokenizerFast"),E3t.forEach(t),d4o=r(_B," (XLNet model)"),_B.forEach(t),c4o=i(S),ul=n(S,"LI",{});var bB=s(ul);Fge=n(bB,"STRONG",{});var C3t=s(Fge);m4o=r(C3t,"yoso"),C3t.forEach(t),f4o=r(bB," \u2014 "),JD=n(bB,"A",{href:!0});var w3t=s(JD);g4o=r(w3t,"AlbertTokenizer"),w3t.forEach(t),h4o=r(bB," or "),YD=n(bB,"A",{href:!0});var A3t=s(YD);u4o=r(A3t,"AlbertTokenizerFast"),A3t.forEach(t),p4o=r(bB," (YOSO model)"),bB.forEach(t),S.forEach(t),_4o=i(Ml),T(yu.$$.fragment,Ml),Ml.forEach(t),b4o=i(Tl),xu=n(Tl,"DIV",{class:!0});var HZe=s(xu);T(I9.$$.fragment,HZe),v4o=i(HZe),Tge=n(HZe,"P",{});var L3t=s(Tge);F4o=r(L3t,"Register a new tokenizer in this mapping."),L3t.forEach(t),HZe.forEach(t),Tl.forEach(t),DYe=i(m),gd=n(m,"H2",{class:!0});var JZe=s(gd);$u=n(JZe,"A",{id:!0,class:!0,href:!0});var y3t=s($u);Mge=n(y3t,"SPAN",{});var x3t=s(Mge);T(N9.$$.fragment,x3t),x3t.forEach(t),y3t.forEach(t),T4o=i(JZe),Ege=n(JZe,"SPAN",{});var $3t=s(Ege);M4o=r($3t,"AutoFeatureExtractor"),$3t.forEach(t),JZe.forEach(t),GYe=i(m),So=n(m,"DIV",{class:!0});var El=s(So);T(q9.$$.fragment,El),E4o=i(El),j9=n(El,"P",{});var YZe=s(j9);C4o=r(YZe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KD=n(YZe,"A",{href:!0});var k3t=s(KD);w4o=r(k3t,"AutoFeatureExtractor.from_pretrained()"),k3t.forEach(t),A4o=r(YZe," class method."),YZe.forEach(t),L4o=i(El),D9=n(El,"P",{});var KZe=s(D9);y4o=r(KZe,"This class cannot be instantiated directly using "),Cge=n(KZe,"CODE",{});var S3t=s(Cge);x4o=r(S3t,"__init__()"),S3t.forEach(t),$4o=r(KZe," (throws an error)."),KZe.forEach(t),k4o=i(El),Ye=n(El,"DIV",{class:!0});var ba=s(Ye);T(G9.$$.fragment,ba),S4o=i(ba),wge=n(ba,"P",{});var R3t=s(wge);R4o=r(R3t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),R3t.forEach(t),P4o=i(ba),Ha=n(ba,"P",{});var _y=s(Ha);B4o=r(_y,"The feature extractor class to instantiate is selected based on the "),Age=n(_y,"CODE",{});var P3t=s(Age);I4o=r(P3t,"model_type"),P3t.forEach(t),N4o=r(_y,` property of the config object
(either passed as an argument or loaded from `),Lge=n(_y,"CODE",{});var B3t=s(Lge);q4o=r(B3t,"pretrained_model_name_or_path"),B3t.forEach(t),j4o=r(_y,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),yge=n(_y,"CODE",{});var I3t=s(yge);D4o=r(I3t,"pretrained_model_name_or_path"),I3t.forEach(t),G4o=r(_y,":"),_y.forEach(t),O4o=i(ba),W=n(ba,"UL",{});var J=s(W);ku=n(J,"LI",{});var wPe=s(ku);xge=n(wPe,"STRONG",{});var N3t=s(xge);V4o=r(N3t,"beit"),N3t.forEach(t),X4o=r(wPe," \u2014 "),ZD=n(wPe,"A",{href:!0});var q3t=s(ZD);z4o=r(q3t,"BeitFeatureExtractor"),q3t.forEach(t),Q4o=r(wPe," (BEiT model)"),wPe.forEach(t),W4o=i(J),Su=n(J,"LI",{});var APe=s(Su);$ge=n(APe,"STRONG",{});var j3t=s($ge);U4o=r(j3t,"clip"),j3t.forEach(t),H4o=r(APe," \u2014 "),eG=n(APe,"A",{href:!0});var D3t=s(eG);J4o=r(D3t,"CLIPFeatureExtractor"),D3t.forEach(t),Y4o=r(APe," (CLIP model)"),APe.forEach(t),K4o=i(J),Ru=n(J,"LI",{});var LPe=s(Ru);kge=n(LPe,"STRONG",{});var G3t=s(kge);Z4o=r(G3t,"convnext"),G3t.forEach(t),eCo=r(LPe," \u2014 "),oG=n(LPe,"A",{href:!0});var O3t=s(oG);oCo=r(O3t,"ConvNextFeatureExtractor"),O3t.forEach(t),rCo=r(LPe," (ConvNeXT model)"),LPe.forEach(t),tCo=i(J),Pu=n(J,"LI",{});var yPe=s(Pu);Sge=n(yPe,"STRONG",{});var V3t=s(Sge);aCo=r(V3t,"cvt"),V3t.forEach(t),nCo=r(yPe," \u2014 "),rG=n(yPe,"A",{href:!0});var X3t=s(rG);sCo=r(X3t,"ConvNextFeatureExtractor"),X3t.forEach(t),lCo=r(yPe," (CvT model)"),yPe.forEach(t),iCo=i(J),Bu=n(J,"LI",{});var xPe=s(Bu);Rge=n(xPe,"STRONG",{});var z3t=s(Rge);dCo=r(z3t,"data2vec-audio"),z3t.forEach(t),cCo=r(xPe," \u2014 "),tG=n(xPe,"A",{href:!0});var Q3t=s(tG);mCo=r(Q3t,"Wav2Vec2FeatureExtractor"),Q3t.forEach(t),fCo=r(xPe," (Data2VecAudio model)"),xPe.forEach(t),gCo=i(J),Iu=n(J,"LI",{});var $Pe=s(Iu);Pge=n($Pe,"STRONG",{});var W3t=s(Pge);hCo=r(W3t,"data2vec-vision"),W3t.forEach(t),uCo=r($Pe," \u2014 "),aG=n($Pe,"A",{href:!0});var U3t=s(aG);pCo=r(U3t,"BeitFeatureExtractor"),U3t.forEach(t),_Co=r($Pe," (Data2VecVision model)"),$Pe.forEach(t),bCo=i(J),Nu=n(J,"LI",{});var kPe=s(Nu);Bge=n(kPe,"STRONG",{});var H3t=s(Bge);vCo=r(H3t,"deit"),H3t.forEach(t),FCo=r(kPe," \u2014 "),nG=n(kPe,"A",{href:!0});var J3t=s(nG);TCo=r(J3t,"DeiTFeatureExtractor"),J3t.forEach(t),MCo=r(kPe," (DeiT model)"),kPe.forEach(t),ECo=i(J),qu=n(J,"LI",{});var SPe=s(qu);Ige=n(SPe,"STRONG",{});var Y3t=s(Ige);CCo=r(Y3t,"detr"),Y3t.forEach(t),wCo=r(SPe," \u2014 "),sG=n(SPe,"A",{href:!0});var K3t=s(sG);ACo=r(K3t,"DetrFeatureExtractor"),K3t.forEach(t),LCo=r(SPe," (DETR model)"),SPe.forEach(t),yCo=i(J),ju=n(J,"LI",{});var RPe=s(ju);Nge=n(RPe,"STRONG",{});var Z3t=s(Nge);xCo=r(Z3t,"donut"),Z3t.forEach(t),$Co=r(RPe," \u2014 "),lG=n(RPe,"A",{href:!0});var e5t=s(lG);kCo=r(e5t,"DonutFeatureExtractor"),e5t.forEach(t),SCo=r(RPe," (Donut model)"),RPe.forEach(t),RCo=i(J),Du=n(J,"LI",{});var PPe=s(Du);qge=n(PPe,"STRONG",{});var o5t=s(qge);PCo=r(o5t,"dpt"),o5t.forEach(t),BCo=r(PPe," \u2014 "),iG=n(PPe,"A",{href:!0});var r5t=s(iG);ICo=r(r5t,"DPTFeatureExtractor"),r5t.forEach(t),NCo=r(PPe," (DPT model)"),PPe.forEach(t),qCo=i(J),Gu=n(J,"LI",{});var BPe=s(Gu);jge=n(BPe,"STRONG",{});var t5t=s(jge);jCo=r(t5t,"flava"),t5t.forEach(t),DCo=r(BPe," \u2014 "),dG=n(BPe,"A",{href:!0});var a5t=s(dG);GCo=r(a5t,"FlavaFeatureExtractor"),a5t.forEach(t),OCo=r(BPe," (FLAVA model)"),BPe.forEach(t),VCo=i(J),Ou=n(J,"LI",{});var IPe=s(Ou);Dge=n(IPe,"STRONG",{});var n5t=s(Dge);XCo=r(n5t,"glpn"),n5t.forEach(t),zCo=r(IPe," \u2014 "),cG=n(IPe,"A",{href:!0});var s5t=s(cG);QCo=r(s5t,"GLPNFeatureExtractor"),s5t.forEach(t),WCo=r(IPe," (GLPN model)"),IPe.forEach(t),UCo=i(J),Vu=n(J,"LI",{});var NPe=s(Vu);Gge=n(NPe,"STRONG",{});var l5t=s(Gge);HCo=r(l5t,"groupvit"),l5t.forEach(t),JCo=r(NPe," \u2014 "),mG=n(NPe,"A",{href:!0});var i5t=s(mG);YCo=r(i5t,"CLIPFeatureExtractor"),i5t.forEach(t),KCo=r(NPe," (GroupViT model)"),NPe.forEach(t),ZCo=i(J),Xu=n(J,"LI",{});var qPe=s(Xu);Oge=n(qPe,"STRONG",{});var d5t=s(Oge);e3o=r(d5t,"hubert"),d5t.forEach(t),o3o=r(qPe," \u2014 "),fG=n(qPe,"A",{href:!0});var c5t=s(fG);r3o=r(c5t,"Wav2Vec2FeatureExtractor"),c5t.forEach(t),t3o=r(qPe," (Hubert model)"),qPe.forEach(t),a3o=i(J),zu=n(J,"LI",{});var jPe=s(zu);Vge=n(jPe,"STRONG",{});var m5t=s(Vge);n3o=r(m5t,"imagegpt"),m5t.forEach(t),s3o=r(jPe," \u2014 "),gG=n(jPe,"A",{href:!0});var f5t=s(gG);l3o=r(f5t,"ImageGPTFeatureExtractor"),f5t.forEach(t),i3o=r(jPe," (ImageGPT model)"),jPe.forEach(t),d3o=i(J),Qu=n(J,"LI",{});var DPe=s(Qu);Xge=n(DPe,"STRONG",{});var g5t=s(Xge);c3o=r(g5t,"layoutlmv2"),g5t.forEach(t),m3o=r(DPe," \u2014 "),hG=n(DPe,"A",{href:!0});var h5t=s(hG);f3o=r(h5t,"LayoutLMv2FeatureExtractor"),h5t.forEach(t),g3o=r(DPe," (LayoutLMv2 model)"),DPe.forEach(t),h3o=i(J),Wu=n(J,"LI",{});var GPe=s(Wu);zge=n(GPe,"STRONG",{});var u5t=s(zge);u3o=r(u5t,"layoutlmv3"),u5t.forEach(t),p3o=r(GPe," \u2014 "),uG=n(GPe,"A",{href:!0});var p5t=s(uG);_3o=r(p5t,"LayoutLMv3FeatureExtractor"),p5t.forEach(t),b3o=r(GPe," (LayoutLMv3 model)"),GPe.forEach(t),v3o=i(J),Uu=n(J,"LI",{});var OPe=s(Uu);Qge=n(OPe,"STRONG",{});var _5t=s(Qge);F3o=r(_5t,"levit"),_5t.forEach(t),T3o=r(OPe," \u2014 "),pG=n(OPe,"A",{href:!0});var b5t=s(pG);M3o=r(b5t,"LevitFeatureExtractor"),b5t.forEach(t),E3o=r(OPe," (LeViT model)"),OPe.forEach(t),C3o=i(J),Hu=n(J,"LI",{});var VPe=s(Hu);Wge=n(VPe,"STRONG",{});var v5t=s(Wge);w3o=r(v5t,"maskformer"),v5t.forEach(t),A3o=r(VPe," \u2014 "),_G=n(VPe,"A",{href:!0});var F5t=s(_G);L3o=r(F5t,"MaskFormerFeatureExtractor"),F5t.forEach(t),y3o=r(VPe," (MaskFormer model)"),VPe.forEach(t),x3o=i(J),Ju=n(J,"LI",{});var XPe=s(Ju);Uge=n(XPe,"STRONG",{});var T5t=s(Uge);$3o=r(T5t,"mctct"),T5t.forEach(t),k3o=r(XPe," \u2014 "),bG=n(XPe,"A",{href:!0});var M5t=s(bG);S3o=r(M5t,"MCTCTFeatureExtractor"),M5t.forEach(t),R3o=r(XPe," (M-CTC-T model)"),XPe.forEach(t),P3o=i(J),Yu=n(J,"LI",{});var zPe=s(Yu);Hge=n(zPe,"STRONG",{});var E5t=s(Hge);B3o=r(E5t,"mobilevit"),E5t.forEach(t),I3o=r(zPe," \u2014 "),vG=n(zPe,"A",{href:!0});var C5t=s(vG);N3o=r(C5t,"MobileViTFeatureExtractor"),C5t.forEach(t),q3o=r(zPe," (MobileViT model)"),zPe.forEach(t),j3o=i(J),Ku=n(J,"LI",{});var QPe=s(Ku);Jge=n(QPe,"STRONG",{});var w5t=s(Jge);D3o=r(w5t,"owlvit"),w5t.forEach(t),G3o=r(QPe," \u2014 "),FG=n(QPe,"A",{href:!0});var A5t=s(FG);O3o=r(A5t,"OwlViTFeatureExtractor"),A5t.forEach(t),V3o=r(QPe," (OWL-ViT model)"),QPe.forEach(t),X3o=i(J),Zu=n(J,"LI",{});var WPe=s(Zu);Yge=n(WPe,"STRONG",{});var L5t=s(Yge);z3o=r(L5t,"perceiver"),L5t.forEach(t),Q3o=r(WPe," \u2014 "),TG=n(WPe,"A",{href:!0});var y5t=s(TG);W3o=r(y5t,"PerceiverFeatureExtractor"),y5t.forEach(t),U3o=r(WPe," (Perceiver model)"),WPe.forEach(t),H3o=i(J),ep=n(J,"LI",{});var UPe=s(ep);Kge=n(UPe,"STRONG",{});var x5t=s(Kge);J3o=r(x5t,"poolformer"),x5t.forEach(t),Y3o=r(UPe," \u2014 "),MG=n(UPe,"A",{href:!0});var $5t=s(MG);K3o=r($5t,"PoolFormerFeatureExtractor"),$5t.forEach(t),Z3o=r(UPe," (PoolFormer model)"),UPe.forEach(t),e5o=i(J),op=n(J,"LI",{});var HPe=s(op);Zge=n(HPe,"STRONG",{});var k5t=s(Zge);o5o=r(k5t,"regnet"),k5t.forEach(t),r5o=r(HPe," \u2014 "),EG=n(HPe,"A",{href:!0});var S5t=s(EG);t5o=r(S5t,"ConvNextFeatureExtractor"),S5t.forEach(t),a5o=r(HPe," (RegNet model)"),HPe.forEach(t),n5o=i(J),rp=n(J,"LI",{});var JPe=s(rp);ehe=n(JPe,"STRONG",{});var R5t=s(ehe);s5o=r(R5t,"resnet"),R5t.forEach(t),l5o=r(JPe," \u2014 "),CG=n(JPe,"A",{href:!0});var P5t=s(CG);i5o=r(P5t,"ConvNextFeatureExtractor"),P5t.forEach(t),d5o=r(JPe," (ResNet model)"),JPe.forEach(t),c5o=i(J),tp=n(J,"LI",{});var YPe=s(tp);ohe=n(YPe,"STRONG",{});var B5t=s(ohe);m5o=r(B5t,"segformer"),B5t.forEach(t),f5o=r(YPe," \u2014 "),wG=n(YPe,"A",{href:!0});var I5t=s(wG);g5o=r(I5t,"SegformerFeatureExtractor"),I5t.forEach(t),h5o=r(YPe," (SegFormer model)"),YPe.forEach(t),u5o=i(J),ap=n(J,"LI",{});var KPe=s(ap);rhe=n(KPe,"STRONG",{});var N5t=s(rhe);p5o=r(N5t,"speech_to_text"),N5t.forEach(t),_5o=r(KPe," \u2014 "),AG=n(KPe,"A",{href:!0});var q5t=s(AG);b5o=r(q5t,"Speech2TextFeatureExtractor"),q5t.forEach(t),v5o=r(KPe," (Speech2Text model)"),KPe.forEach(t),F5o=i(J),np=n(J,"LI",{});var ZPe=s(np);the=n(ZPe,"STRONG",{});var j5t=s(the);T5o=r(j5t,"swin"),j5t.forEach(t),M5o=r(ZPe," \u2014 "),LG=n(ZPe,"A",{href:!0});var D5t=s(LG);E5o=r(D5t,"ViTFeatureExtractor"),D5t.forEach(t),C5o=r(ZPe," (Swin Transformer model)"),ZPe.forEach(t),w5o=i(J),sp=n(J,"LI",{});var eBe=s(sp);ahe=n(eBe,"STRONG",{});var G5t=s(ahe);A5o=r(G5t,"swinv2"),G5t.forEach(t),L5o=r(eBe," \u2014 "),yG=n(eBe,"A",{href:!0});var O5t=s(yG);y5o=r(O5t,"ViTFeatureExtractor"),O5t.forEach(t),x5o=r(eBe," (Swin Transformer V2 model)"),eBe.forEach(t),$5o=i(J),lp=n(J,"LI",{});var oBe=s(lp);nhe=n(oBe,"STRONG",{});var V5t=s(nhe);k5o=r(V5t,"van"),V5t.forEach(t),S5o=r(oBe," \u2014 "),xG=n(oBe,"A",{href:!0});var X5t=s(xG);R5o=r(X5t,"ConvNextFeatureExtractor"),X5t.forEach(t),P5o=r(oBe," (VAN model)"),oBe.forEach(t),B5o=i(J),ip=n(J,"LI",{});var rBe=s(ip);she=n(rBe,"STRONG",{});var z5t=s(she);I5o=r(z5t,"videomae"),z5t.forEach(t),N5o=r(rBe," \u2014 "),$G=n(rBe,"A",{href:!0});var Q5t=s($G);q5o=r(Q5t,"VideoMAEFeatureExtractor"),Q5t.forEach(t),j5o=r(rBe," (VideoMAE model)"),rBe.forEach(t),D5o=i(J),dp=n(J,"LI",{});var tBe=s(dp);lhe=n(tBe,"STRONG",{});var W5t=s(lhe);G5o=r(W5t,"vilt"),W5t.forEach(t),O5o=r(tBe," \u2014 "),kG=n(tBe,"A",{href:!0});var U5t=s(kG);V5o=r(U5t,"ViltFeatureExtractor"),U5t.forEach(t),X5o=r(tBe," (ViLT model)"),tBe.forEach(t),z5o=i(J),cp=n(J,"LI",{});var aBe=s(cp);ihe=n(aBe,"STRONG",{});var H5t=s(ihe);Q5o=r(H5t,"vit"),H5t.forEach(t),W5o=r(aBe," \u2014 "),SG=n(aBe,"A",{href:!0});var J5t=s(SG);U5o=r(J5t,"ViTFeatureExtractor"),J5t.forEach(t),H5o=r(aBe," (ViT model)"),aBe.forEach(t),J5o=i(J),mp=n(J,"LI",{});var nBe=s(mp);dhe=n(nBe,"STRONG",{});var Y5t=s(dhe);Y5o=r(Y5t,"vit_mae"),Y5t.forEach(t),K5o=r(nBe," \u2014 "),RG=n(nBe,"A",{href:!0});var K5t=s(RG);Z5o=r(K5t,"ViTFeatureExtractor"),K5t.forEach(t),e0o=r(nBe," (ViTMAE model)"),nBe.forEach(t),o0o=i(J),fp=n(J,"LI",{});var sBe=s(fp);che=n(sBe,"STRONG",{});var Z5t=s(che);r0o=r(Z5t,"wav2vec2"),Z5t.forEach(t),t0o=r(sBe," \u2014 "),PG=n(sBe,"A",{href:!0});var e0t=s(PG);a0o=r(e0t,"Wav2Vec2FeatureExtractor"),e0t.forEach(t),n0o=r(sBe," (Wav2Vec2 model)"),sBe.forEach(t),s0o=i(J),gp=n(J,"LI",{});var lBe=s(gp);mhe=n(lBe,"STRONG",{});var o0t=s(mhe);l0o=r(o0t,"wav2vec2-conformer"),o0t.forEach(t),i0o=r(lBe," \u2014 "),BG=n(lBe,"A",{href:!0});var r0t=s(BG);d0o=r(r0t,"Wav2Vec2FeatureExtractor"),r0t.forEach(t),c0o=r(lBe," (Wav2Vec2-Conformer model)"),lBe.forEach(t),m0o=i(J),hp=n(J,"LI",{});var iBe=s(hp);fhe=n(iBe,"STRONG",{});var t0t=s(fhe);f0o=r(t0t,"xclip"),t0t.forEach(t),g0o=r(iBe," \u2014 "),IG=n(iBe,"A",{href:!0});var a0t=s(IG);h0o=r(a0t,"CLIPFeatureExtractor"),a0t.forEach(t),u0o=r(iBe," (X-CLIP model)"),iBe.forEach(t),p0o=i(J),up=n(J,"LI",{});var dBe=s(up);ghe=n(dBe,"STRONG",{});var n0t=s(ghe);_0o=r(n0t,"yolos"),n0t.forEach(t),b0o=r(dBe," \u2014 "),NG=n(dBe,"A",{href:!0});var s0t=s(NG);v0o=r(s0t,"YolosFeatureExtractor"),s0t.forEach(t),F0o=r(dBe," (YOLOS model)"),dBe.forEach(t),J.forEach(t),T0o=i(ba),T(pp.$$.fragment,ba),M0o=i(ba),T(_p.$$.fragment,ba),ba.forEach(t),E0o=i(El),bp=n(El,"DIV",{class:!0});var ZZe=s(bp);T(O9.$$.fragment,ZZe),C0o=i(ZZe),hhe=n(ZZe,"P",{});var l0t=s(hhe);w0o=r(l0t,"Register a new feature extractor for this class."),l0t.forEach(t),ZZe.forEach(t),El.forEach(t),OYe=i(m),hd=n(m,"H2",{class:!0});var eeo=s(hd);vp=n(eeo,"A",{id:!0,class:!0,href:!0});var i0t=s(vp);uhe=n(i0t,"SPAN",{});var d0t=s(uhe);T(V9.$$.fragment,d0t),d0t.forEach(t),i0t.forEach(t),A0o=i(eeo),phe=n(eeo,"SPAN",{});var c0t=s(phe);L0o=r(c0t,"AutoProcessor"),c0t.forEach(t),eeo.forEach(t),VYe=i(m),Ro=n(m,"DIV",{class:!0});var Cl=s(Ro);T(X9.$$.fragment,Cl),y0o=i(Cl),z9=n(Cl,"P",{});var oeo=s(z9);x0o=r(oeo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qG=n(oeo,"A",{href:!0});var m0t=s(qG);$0o=r(m0t,"AutoProcessor.from_pretrained()"),m0t.forEach(t),k0o=r(oeo," class method."),oeo.forEach(t),S0o=i(Cl),Q9=n(Cl,"P",{});var reo=s(Q9);R0o=r(reo,"This class cannot be instantiated directly using "),_he=n(reo,"CODE",{});var f0t=s(_he);P0o=r(f0t,"__init__()"),f0t.forEach(t),B0o=r(reo," (throws an error)."),reo.forEach(t),I0o=i(Cl),Ke=n(Cl,"DIV",{class:!0});var va=s(Ke);T(W9.$$.fragment,va),N0o=i(va),bhe=n(va,"P",{});var g0t=s(bhe);q0o=r(g0t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),g0t.forEach(t),j0o=i(va),ud=n(va,"P",{});var Qse=s(ud);D0o=r(Qse,"The processor class to instantiate is selected based on the "),vhe=n(Qse,"CODE",{});var h0t=s(vhe);G0o=r(h0t,"model_type"),h0t.forEach(t),O0o=r(Qse,` property of the config object (either
passed as an argument or loaded from `),Fhe=n(Qse,"CODE",{});var u0t=s(Fhe);V0o=r(u0t,"pretrained_model_name_or_path"),u0t.forEach(t),X0o=r(Qse," if possible):"),Qse.forEach(t),z0o=i(va),ie=n(va,"UL",{});var ge=s(ie);Fp=n(ge,"LI",{});var cBe=s(Fp);The=n(cBe,"STRONG",{});var p0t=s(The);Q0o=r(p0t,"clip"),p0t.forEach(t),W0o=r(cBe," \u2014 "),jG=n(cBe,"A",{href:!0});var _0t=s(jG);U0o=r(_0t,"CLIPProcessor"),_0t.forEach(t),H0o=r(cBe," (CLIP model)"),cBe.forEach(t),J0o=i(ge),Tp=n(ge,"LI",{});var mBe=s(Tp);Mhe=n(mBe,"STRONG",{});var b0t=s(Mhe);Y0o=r(b0t,"donut"),b0t.forEach(t),K0o=r(mBe," \u2014 "),DG=n(mBe,"A",{href:!0});var v0t=s(DG);Z0o=r(v0t,"DonutProcessor"),v0t.forEach(t),ewo=r(mBe," (Donut model)"),mBe.forEach(t),owo=i(ge),Mp=n(ge,"LI",{});var fBe=s(Mp);Ehe=n(fBe,"STRONG",{});var F0t=s(Ehe);rwo=r(F0t,"flava"),F0t.forEach(t),two=r(fBe," \u2014 "),GG=n(fBe,"A",{href:!0});var T0t=s(GG);awo=r(T0t,"FlavaProcessor"),T0t.forEach(t),nwo=r(fBe," (FLAVA model)"),fBe.forEach(t),swo=i(ge),Ep=n(ge,"LI",{});var gBe=s(Ep);Che=n(gBe,"STRONG",{});var M0t=s(Che);lwo=r(M0t,"groupvit"),M0t.forEach(t),iwo=r(gBe," \u2014 "),OG=n(gBe,"A",{href:!0});var E0t=s(OG);dwo=r(E0t,"CLIPProcessor"),E0t.forEach(t),cwo=r(gBe," (GroupViT model)"),gBe.forEach(t),mwo=i(ge),Cp=n(ge,"LI",{});var hBe=s(Cp);whe=n(hBe,"STRONG",{});var C0t=s(whe);fwo=r(C0t,"layoutlmv2"),C0t.forEach(t),gwo=r(hBe," \u2014 "),VG=n(hBe,"A",{href:!0});var w0t=s(VG);hwo=r(w0t,"LayoutLMv2Processor"),w0t.forEach(t),uwo=r(hBe," (LayoutLMv2 model)"),hBe.forEach(t),pwo=i(ge),wp=n(ge,"LI",{});var uBe=s(wp);Ahe=n(uBe,"STRONG",{});var A0t=s(Ahe);_wo=r(A0t,"layoutlmv3"),A0t.forEach(t),bwo=r(uBe," \u2014 "),XG=n(uBe,"A",{href:!0});var L0t=s(XG);vwo=r(L0t,"LayoutLMv3Processor"),L0t.forEach(t),Fwo=r(uBe," (LayoutLMv3 model)"),uBe.forEach(t),Two=i(ge),Ap=n(ge,"LI",{});var pBe=s(Ap);Lhe=n(pBe,"STRONG",{});var y0t=s(Lhe);Mwo=r(y0t,"layoutxlm"),y0t.forEach(t),Ewo=r(pBe," \u2014 "),zG=n(pBe,"A",{href:!0});var x0t=s(zG);Cwo=r(x0t,"LayoutXLMProcessor"),x0t.forEach(t),wwo=r(pBe," (LayoutXLM model)"),pBe.forEach(t),Awo=i(ge),Lp=n(ge,"LI",{});var _Be=s(Lp);yhe=n(_Be,"STRONG",{});var $0t=s(yhe);Lwo=r($0t,"owlvit"),$0t.forEach(t),ywo=r(_Be," \u2014 "),QG=n(_Be,"A",{href:!0});var k0t=s(QG);xwo=r(k0t,"OwlViTProcessor"),k0t.forEach(t),$wo=r(_Be," (OWL-ViT model)"),_Be.forEach(t),kwo=i(ge),yp=n(ge,"LI",{});var bBe=s(yp);xhe=n(bBe,"STRONG",{});var S0t=s(xhe);Swo=r(S0t,"sew"),S0t.forEach(t),Rwo=r(bBe," \u2014 "),WG=n(bBe,"A",{href:!0});var R0t=s(WG);Pwo=r(R0t,"Wav2Vec2Processor"),R0t.forEach(t),Bwo=r(bBe," (SEW model)"),bBe.forEach(t),Iwo=i(ge),xp=n(ge,"LI",{});var vBe=s(xp);$he=n(vBe,"STRONG",{});var P0t=s($he);Nwo=r(P0t,"sew-d"),P0t.forEach(t),qwo=r(vBe," \u2014 "),UG=n(vBe,"A",{href:!0});var B0t=s(UG);jwo=r(B0t,"Wav2Vec2Processor"),B0t.forEach(t),Dwo=r(vBe," (SEW-D model)"),vBe.forEach(t),Gwo=i(ge),$p=n(ge,"LI",{});var FBe=s($p);khe=n(FBe,"STRONG",{});var I0t=s(khe);Owo=r(I0t,"speech_to_text"),I0t.forEach(t),Vwo=r(FBe," \u2014 "),HG=n(FBe,"A",{href:!0});var N0t=s(HG);Xwo=r(N0t,"Speech2TextProcessor"),N0t.forEach(t),zwo=r(FBe," (Speech2Text model)"),FBe.forEach(t),Qwo=i(ge),kp=n(ge,"LI",{});var TBe=s(kp);She=n(TBe,"STRONG",{});var q0t=s(She);Wwo=r(q0t,"speech_to_text_2"),q0t.forEach(t),Uwo=r(TBe," \u2014 "),JG=n(TBe,"A",{href:!0});var j0t=s(JG);Hwo=r(j0t,"Speech2Text2Processor"),j0t.forEach(t),Jwo=r(TBe," (Speech2Text2 model)"),TBe.forEach(t),Ywo=i(ge),Sp=n(ge,"LI",{});var MBe=s(Sp);Rhe=n(MBe,"STRONG",{});var D0t=s(Rhe);Kwo=r(D0t,"trocr"),D0t.forEach(t),Zwo=r(MBe," \u2014 "),YG=n(MBe,"A",{href:!0});var G0t=s(YG);eAo=r(G0t,"TrOCRProcessor"),G0t.forEach(t),oAo=r(MBe," (TrOCR model)"),MBe.forEach(t),rAo=i(ge),Rp=n(ge,"LI",{});var EBe=s(Rp);Phe=n(EBe,"STRONG",{});var O0t=s(Phe);tAo=r(O0t,"unispeech"),O0t.forEach(t),aAo=r(EBe," \u2014 "),KG=n(EBe,"A",{href:!0});var V0t=s(KG);nAo=r(V0t,"Wav2Vec2Processor"),V0t.forEach(t),sAo=r(EBe," (UniSpeech model)"),EBe.forEach(t),lAo=i(ge),Pp=n(ge,"LI",{});var CBe=s(Pp);Bhe=n(CBe,"STRONG",{});var X0t=s(Bhe);iAo=r(X0t,"unispeech-sat"),X0t.forEach(t),dAo=r(CBe," \u2014 "),ZG=n(CBe,"A",{href:!0});var z0t=s(ZG);cAo=r(z0t,"Wav2Vec2Processor"),z0t.forEach(t),mAo=r(CBe," (UniSpeechSat model)"),CBe.forEach(t),fAo=i(ge),Bp=n(ge,"LI",{});var wBe=s(Bp);Ihe=n(wBe,"STRONG",{});var Q0t=s(Ihe);gAo=r(Q0t,"vilt"),Q0t.forEach(t),hAo=r(wBe," \u2014 "),eO=n(wBe,"A",{href:!0});var W0t=s(eO);uAo=r(W0t,"ViltProcessor"),W0t.forEach(t),pAo=r(wBe," (ViLT model)"),wBe.forEach(t),_Ao=i(ge),Ip=n(ge,"LI",{});var ABe=s(Ip);Nhe=n(ABe,"STRONG",{});var U0t=s(Nhe);bAo=r(U0t,"vision-text-dual-encoder"),U0t.forEach(t),vAo=r(ABe," \u2014 "),oO=n(ABe,"A",{href:!0});var H0t=s(oO);FAo=r(H0t,"VisionTextDualEncoderProcessor"),H0t.forEach(t),TAo=r(ABe," (VisionTextDualEncoder model)"),ABe.forEach(t),MAo=i(ge),Np=n(ge,"LI",{});var LBe=s(Np);qhe=n(LBe,"STRONG",{});var J0t=s(qhe);EAo=r(J0t,"wav2vec2"),J0t.forEach(t),CAo=r(LBe," \u2014 "),rO=n(LBe,"A",{href:!0});var Y0t=s(rO);wAo=r(Y0t,"Wav2Vec2Processor"),Y0t.forEach(t),AAo=r(LBe," (Wav2Vec2 model)"),LBe.forEach(t),LAo=i(ge),qp=n(ge,"LI",{});var yBe=s(qp);jhe=n(yBe,"STRONG",{});var K0t=s(jhe);yAo=r(K0t,"wav2vec2-conformer"),K0t.forEach(t),xAo=r(yBe," \u2014 "),tO=n(yBe,"A",{href:!0});var Z0t=s(tO);$Ao=r(Z0t,"Wav2Vec2Processor"),Z0t.forEach(t),kAo=r(yBe," (Wav2Vec2-Conformer model)"),yBe.forEach(t),SAo=i(ge),jp=n(ge,"LI",{});var xBe=s(jp);Dhe=n(xBe,"STRONG",{});var ewt=s(Dhe);RAo=r(ewt,"wavlm"),ewt.forEach(t),PAo=r(xBe," \u2014 "),aO=n(xBe,"A",{href:!0});var owt=s(aO);BAo=r(owt,"Wav2Vec2Processor"),owt.forEach(t),IAo=r(xBe," (WavLM model)"),xBe.forEach(t),NAo=i(ge),Dp=n(ge,"LI",{});var $Be=s(Dp);Ghe=n($Be,"STRONG",{});var rwt=s(Ghe);qAo=r(rwt,"xclip"),rwt.forEach(t),jAo=r($Be," \u2014 "),nO=n($Be,"A",{href:!0});var twt=s(nO);DAo=r(twt,"CLIPProcessor"),twt.forEach(t),GAo=r($Be," (X-CLIP model)"),$Be.forEach(t),ge.forEach(t),OAo=i(va),T(Gp.$$.fragment,va),VAo=i(va),T(Op.$$.fragment,va),va.forEach(t),XAo=i(Cl),Vp=n(Cl,"DIV",{class:!0});var teo=s(Vp);T(U9.$$.fragment,teo),zAo=i(teo),Ohe=n(teo,"P",{});var awt=s(Ohe);QAo=r(awt,"Register a new processor for this class."),awt.forEach(t),teo.forEach(t),Cl.forEach(t),XYe=i(m),pd=n(m,"H2",{class:!0});var aeo=s(pd);Xp=n(aeo,"A",{id:!0,class:!0,href:!0});var nwt=s(Xp);Vhe=n(nwt,"SPAN",{});var swt=s(Vhe);T(H9.$$.fragment,swt),swt.forEach(t),nwt.forEach(t),WAo=i(aeo),Xhe=n(aeo,"SPAN",{});var lwt=s(Xhe);UAo=r(lwt,"AutoModel"),lwt.forEach(t),aeo.forEach(t),zYe=i(m),Po=n(m,"DIV",{class:!0});var wl=s(Po);T(J9.$$.fragment,wl),HAo=i(wl),_d=n(wl,"P",{});var Wse=s(_d);JAo=r(Wse,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sO=n(Wse,"A",{href:!0});var iwt=s(sO);YAo=r(iwt,"from_pretrained()"),iwt.forEach(t),KAo=r(Wse," class method or the "),lO=n(Wse,"A",{href:!0});var dwt=s(lO);ZAo=r(dwt,"from_config()"),dwt.forEach(t),e6o=r(Wse,` class
method.`),Wse.forEach(t),o6o=i(wl),Y9=n(wl,"P",{});var neo=s(Y9);r6o=r(neo,"This class cannot be instantiated directly using "),zhe=n(neo,"CODE",{});var cwt=s(zhe);t6o=r(cwt,"__init__()"),cwt.forEach(t),a6o=r(neo," (throws an error)."),neo.forEach(t),n6o=i(wl),_t=n(wl,"DIV",{class:!0});var by=s(_t);T(K9.$$.fragment,by),s6o=i(by),Qhe=n(by,"P",{});var mwt=s(Qhe);l6o=r(mwt,"Instantiates one of the base model classes of the library from a configuration."),mwt.forEach(t),i6o=i(by),bd=n(by,"P",{});var Use=s(bd);d6o=r(Use,`Note:
Loading a model from its configuration file does `),Whe=n(Use,"STRONG",{});var fwt=s(Whe);c6o=r(fwt,"not"),fwt.forEach(t),m6o=r(Use,` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=n(Use,"A",{href:!0});var gwt=s(iO);f6o=r(gwt,"from_pretrained()"),gwt.forEach(t),g6o=r(Use," to load the model weights."),Use.forEach(t),h6o=i(by),T(zp.$$.fragment,by),by.forEach(t),u6o=i(wl),Ze=n(wl,"DIV",{class:!0});var Fa=s(Ze);T(Z9.$$.fragment,Fa),p6o=i(Fa),Uhe=n(Fa,"P",{});var hwt=s(Uhe);_6o=r(hwt,"Instantiate one of the base model classes of the library from a pretrained model."),hwt.forEach(t),b6o=i(Fa),Ja=n(Fa,"P",{});var vy=s(Ja);v6o=r(vy,"The model class to instantiate is selected based on the "),Hhe=n(vy,"CODE",{});var uwt=s(Hhe);F6o=r(uwt,"model_type"),uwt.forEach(t),T6o=r(vy,` property of the config object (either
passed as an argument or loaded from `),Jhe=n(vy,"CODE",{});var pwt=s(Jhe);M6o=r(pwt,"pretrained_model_name_or_path"),pwt.forEach(t),E6o=r(vy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=n(vy,"CODE",{});var _wt=s(Yhe);C6o=r(_wt,"pretrained_model_name_or_path"),_wt.forEach(t),w6o=r(vy,":"),vy.forEach(t),A6o=i(Fa),y=n(Fa,"UL",{});var x=s(y);Qp=n(x,"LI",{});var kBe=s(Qp);Khe=n(kBe,"STRONG",{});var bwt=s(Khe);L6o=r(bwt,"albert"),bwt.forEach(t),y6o=r(kBe," \u2014 "),dO=n(kBe,"A",{href:!0});var vwt=s(dO);x6o=r(vwt,"AlbertModel"),vwt.forEach(t),$6o=r(kBe," (ALBERT model)"),kBe.forEach(t),k6o=i(x),Wp=n(x,"LI",{});var SBe=s(Wp);Zhe=n(SBe,"STRONG",{});var Fwt=s(Zhe);S6o=r(Fwt,"bart"),Fwt.forEach(t),R6o=r(SBe," \u2014 "),cO=n(SBe,"A",{href:!0});var Twt=s(cO);P6o=r(Twt,"BartModel"),Twt.forEach(t),B6o=r(SBe," (BART model)"),SBe.forEach(t),I6o=i(x),Up=n(x,"LI",{});var RBe=s(Up);eue=n(RBe,"STRONG",{});var Mwt=s(eue);N6o=r(Mwt,"beit"),Mwt.forEach(t),q6o=r(RBe," \u2014 "),mO=n(RBe,"A",{href:!0});var Ewt=s(mO);j6o=r(Ewt,"BeitModel"),Ewt.forEach(t),D6o=r(RBe," (BEiT model)"),RBe.forEach(t),G6o=i(x),Hp=n(x,"LI",{});var PBe=s(Hp);oue=n(PBe,"STRONG",{});var Cwt=s(oue);O6o=r(Cwt,"bert"),Cwt.forEach(t),V6o=r(PBe," \u2014 "),fO=n(PBe,"A",{href:!0});var wwt=s(fO);X6o=r(wwt,"BertModel"),wwt.forEach(t),z6o=r(PBe," (BERT model)"),PBe.forEach(t),Q6o=i(x),Jp=n(x,"LI",{});var BBe=s(Jp);rue=n(BBe,"STRONG",{});var Awt=s(rue);W6o=r(Awt,"bert-generation"),Awt.forEach(t),U6o=r(BBe," \u2014 "),gO=n(BBe,"A",{href:!0});var Lwt=s(gO);H6o=r(Lwt,"BertGenerationEncoder"),Lwt.forEach(t),J6o=r(BBe," (Bert Generation model)"),BBe.forEach(t),Y6o=i(x),Yp=n(x,"LI",{});var IBe=s(Yp);tue=n(IBe,"STRONG",{});var ywt=s(tue);K6o=r(ywt,"big_bird"),ywt.forEach(t),Z6o=r(IBe," \u2014 "),hO=n(IBe,"A",{href:!0});var xwt=s(hO);e7o=r(xwt,"BigBirdModel"),xwt.forEach(t),o7o=r(IBe," (BigBird model)"),IBe.forEach(t),r7o=i(x),Kp=n(x,"LI",{});var NBe=s(Kp);aue=n(NBe,"STRONG",{});var $wt=s(aue);t7o=r($wt,"bigbird_pegasus"),$wt.forEach(t),a7o=r(NBe," \u2014 "),uO=n(NBe,"A",{href:!0});var kwt=s(uO);n7o=r(kwt,"BigBirdPegasusModel"),kwt.forEach(t),s7o=r(NBe," (BigBird-Pegasus model)"),NBe.forEach(t),l7o=i(x),Zp=n(x,"LI",{});var qBe=s(Zp);nue=n(qBe,"STRONG",{});var Swt=s(nue);i7o=r(Swt,"blenderbot"),Swt.forEach(t),d7o=r(qBe," \u2014 "),pO=n(qBe,"A",{href:!0});var Rwt=s(pO);c7o=r(Rwt,"BlenderbotModel"),Rwt.forEach(t),m7o=r(qBe," (Blenderbot model)"),qBe.forEach(t),f7o=i(x),e_=n(x,"LI",{});var jBe=s(e_);sue=n(jBe,"STRONG",{});var Pwt=s(sue);g7o=r(Pwt,"blenderbot-small"),Pwt.forEach(t),h7o=r(jBe," \u2014 "),_O=n(jBe,"A",{href:!0});var Bwt=s(_O);u7o=r(Bwt,"BlenderbotSmallModel"),Bwt.forEach(t),p7o=r(jBe," (BlenderbotSmall model)"),jBe.forEach(t),_7o=i(x),o_=n(x,"LI",{});var DBe=s(o_);lue=n(DBe,"STRONG",{});var Iwt=s(lue);b7o=r(Iwt,"bloom"),Iwt.forEach(t),v7o=r(DBe," \u2014 "),bO=n(DBe,"A",{href:!0});var Nwt=s(bO);F7o=r(Nwt,"BloomModel"),Nwt.forEach(t),T7o=r(DBe," (BLOOM model)"),DBe.forEach(t),M7o=i(x),r_=n(x,"LI",{});var GBe=s(r_);iue=n(GBe,"STRONG",{});var qwt=s(iue);E7o=r(qwt,"camembert"),qwt.forEach(t),C7o=r(GBe," \u2014 "),vO=n(GBe,"A",{href:!0});var jwt=s(vO);w7o=r(jwt,"CamembertModel"),jwt.forEach(t),A7o=r(GBe," (CamemBERT model)"),GBe.forEach(t),L7o=i(x),t_=n(x,"LI",{});var OBe=s(t_);due=n(OBe,"STRONG",{});var Dwt=s(due);y7o=r(Dwt,"canine"),Dwt.forEach(t),x7o=r(OBe," \u2014 "),FO=n(OBe,"A",{href:!0});var Gwt=s(FO);$7o=r(Gwt,"CanineModel"),Gwt.forEach(t),k7o=r(OBe," (CANINE model)"),OBe.forEach(t),S7o=i(x),a_=n(x,"LI",{});var VBe=s(a_);cue=n(VBe,"STRONG",{});var Owt=s(cue);R7o=r(Owt,"clip"),Owt.forEach(t),P7o=r(VBe," \u2014 "),TO=n(VBe,"A",{href:!0});var Vwt=s(TO);B7o=r(Vwt,"CLIPModel"),Vwt.forEach(t),I7o=r(VBe," (CLIP model)"),VBe.forEach(t),N7o=i(x),n_=n(x,"LI",{});var XBe=s(n_);mue=n(XBe,"STRONG",{});var Xwt=s(mue);q7o=r(Xwt,"codegen"),Xwt.forEach(t),j7o=r(XBe," \u2014 "),MO=n(XBe,"A",{href:!0});var zwt=s(MO);D7o=r(zwt,"CodeGenModel"),zwt.forEach(t),G7o=r(XBe," (CodeGen model)"),XBe.forEach(t),O7o=i(x),s_=n(x,"LI",{});var zBe=s(s_);fue=n(zBe,"STRONG",{});var Qwt=s(fue);V7o=r(Qwt,"convbert"),Qwt.forEach(t),X7o=r(zBe," \u2014 "),EO=n(zBe,"A",{href:!0});var Wwt=s(EO);z7o=r(Wwt,"ConvBertModel"),Wwt.forEach(t),Q7o=r(zBe," (ConvBERT model)"),zBe.forEach(t),W7o=i(x),l_=n(x,"LI",{});var QBe=s(l_);gue=n(QBe,"STRONG",{});var Uwt=s(gue);U7o=r(Uwt,"convnext"),Uwt.forEach(t),H7o=r(QBe," \u2014 "),CO=n(QBe,"A",{href:!0});var Hwt=s(CO);J7o=r(Hwt,"ConvNextModel"),Hwt.forEach(t),Y7o=r(QBe," (ConvNeXT model)"),QBe.forEach(t),K7o=i(x),i_=n(x,"LI",{});var WBe=s(i_);hue=n(WBe,"STRONG",{});var Jwt=s(hue);Z7o=r(Jwt,"ctrl"),Jwt.forEach(t),eLo=r(WBe," \u2014 "),wO=n(WBe,"A",{href:!0});var Ywt=s(wO);oLo=r(Ywt,"CTRLModel"),Ywt.forEach(t),rLo=r(WBe," (CTRL model)"),WBe.forEach(t),tLo=i(x),d_=n(x,"LI",{});var UBe=s(d_);uue=n(UBe,"STRONG",{});var Kwt=s(uue);aLo=r(Kwt,"cvt"),Kwt.forEach(t),nLo=r(UBe," \u2014 "),AO=n(UBe,"A",{href:!0});var Zwt=s(AO);sLo=r(Zwt,"CvtModel"),Zwt.forEach(t),lLo=r(UBe," (CvT model)"),UBe.forEach(t),iLo=i(x),c_=n(x,"LI",{});var HBe=s(c_);pue=n(HBe,"STRONG",{});var eAt=s(pue);dLo=r(eAt,"data2vec-audio"),eAt.forEach(t),cLo=r(HBe," \u2014 "),LO=n(HBe,"A",{href:!0});var oAt=s(LO);mLo=r(oAt,"Data2VecAudioModel"),oAt.forEach(t),fLo=r(HBe," (Data2VecAudio model)"),HBe.forEach(t),gLo=i(x),m_=n(x,"LI",{});var JBe=s(m_);_ue=n(JBe,"STRONG",{});var rAt=s(_ue);hLo=r(rAt,"data2vec-text"),rAt.forEach(t),uLo=r(JBe," \u2014 "),yO=n(JBe,"A",{href:!0});var tAt=s(yO);pLo=r(tAt,"Data2VecTextModel"),tAt.forEach(t),_Lo=r(JBe," (Data2VecText model)"),JBe.forEach(t),bLo=i(x),f_=n(x,"LI",{});var YBe=s(f_);bue=n(YBe,"STRONG",{});var aAt=s(bue);vLo=r(aAt,"data2vec-vision"),aAt.forEach(t),FLo=r(YBe," \u2014 "),xO=n(YBe,"A",{href:!0});var nAt=s(xO);TLo=r(nAt,"Data2VecVisionModel"),nAt.forEach(t),MLo=r(YBe," (Data2VecVision model)"),YBe.forEach(t),ELo=i(x),g_=n(x,"LI",{});var KBe=s(g_);vue=n(KBe,"STRONG",{});var sAt=s(vue);CLo=r(sAt,"deberta"),sAt.forEach(t),wLo=r(KBe," \u2014 "),$O=n(KBe,"A",{href:!0});var lAt=s($O);ALo=r(lAt,"DebertaModel"),lAt.forEach(t),LLo=r(KBe," (DeBERTa model)"),KBe.forEach(t),yLo=i(x),h_=n(x,"LI",{});var ZBe=s(h_);Fue=n(ZBe,"STRONG",{});var iAt=s(Fue);xLo=r(iAt,"deberta-v2"),iAt.forEach(t),$Lo=r(ZBe," \u2014 "),kO=n(ZBe,"A",{href:!0});var dAt=s(kO);kLo=r(dAt,"DebertaV2Model"),dAt.forEach(t),SLo=r(ZBe," (DeBERTa-v2 model)"),ZBe.forEach(t),RLo=i(x),u_=n(x,"LI",{});var eIe=s(u_);Tue=n(eIe,"STRONG",{});var cAt=s(Tue);PLo=r(cAt,"decision_transformer"),cAt.forEach(t),BLo=r(eIe," \u2014 "),SO=n(eIe,"A",{href:!0});var mAt=s(SO);ILo=r(mAt,"DecisionTransformerModel"),mAt.forEach(t),NLo=r(eIe," (Decision Transformer model)"),eIe.forEach(t),qLo=i(x),p_=n(x,"LI",{});var oIe=s(p_);Mue=n(oIe,"STRONG",{});var fAt=s(Mue);jLo=r(fAt,"deit"),fAt.forEach(t),DLo=r(oIe," \u2014 "),RO=n(oIe,"A",{href:!0});var gAt=s(RO);GLo=r(gAt,"DeiTModel"),gAt.forEach(t),OLo=r(oIe," (DeiT model)"),oIe.forEach(t),VLo=i(x),__=n(x,"LI",{});var rIe=s(__);Eue=n(rIe,"STRONG",{});var hAt=s(Eue);XLo=r(hAt,"detr"),hAt.forEach(t),zLo=r(rIe," \u2014 "),PO=n(rIe,"A",{href:!0});var uAt=s(PO);QLo=r(uAt,"DetrModel"),uAt.forEach(t),WLo=r(rIe," (DETR model)"),rIe.forEach(t),ULo=i(x),b_=n(x,"LI",{});var tIe=s(b_);Cue=n(tIe,"STRONG",{});var pAt=s(Cue);HLo=r(pAt,"distilbert"),pAt.forEach(t),JLo=r(tIe," \u2014 "),BO=n(tIe,"A",{href:!0});var _At=s(BO);YLo=r(_At,"DistilBertModel"),_At.forEach(t),KLo=r(tIe," (DistilBERT model)"),tIe.forEach(t),ZLo=i(x),v_=n(x,"LI",{});var aIe=s(v_);wue=n(aIe,"STRONG",{});var bAt=s(wue);eyo=r(bAt,"donut-swin"),bAt.forEach(t),oyo=r(aIe," \u2014 "),IO=n(aIe,"A",{href:!0});var vAt=s(IO);ryo=r(vAt,"DonutSwinModel"),vAt.forEach(t),tyo=r(aIe," (DonutSwin model)"),aIe.forEach(t),ayo=i(x),F_=n(x,"LI",{});var nIe=s(F_);Aue=n(nIe,"STRONG",{});var FAt=s(Aue);nyo=r(FAt,"dpr"),FAt.forEach(t),syo=r(nIe," \u2014 "),NO=n(nIe,"A",{href:!0});var TAt=s(NO);lyo=r(TAt,"DPRQuestionEncoder"),TAt.forEach(t),iyo=r(nIe," (DPR model)"),nIe.forEach(t),dyo=i(x),T_=n(x,"LI",{});var sIe=s(T_);Lue=n(sIe,"STRONG",{});var MAt=s(Lue);cyo=r(MAt,"dpt"),MAt.forEach(t),myo=r(sIe," \u2014 "),qO=n(sIe,"A",{href:!0});var EAt=s(qO);fyo=r(EAt,"DPTModel"),EAt.forEach(t),gyo=r(sIe," (DPT model)"),sIe.forEach(t),hyo=i(x),M_=n(x,"LI",{});var lIe=s(M_);yue=n(lIe,"STRONG",{});var CAt=s(yue);uyo=r(CAt,"electra"),CAt.forEach(t),pyo=r(lIe," \u2014 "),jO=n(lIe,"A",{href:!0});var wAt=s(jO);_yo=r(wAt,"ElectraModel"),wAt.forEach(t),byo=r(lIe," (ELECTRA model)"),lIe.forEach(t),vyo=i(x),E_=n(x,"LI",{});var iIe=s(E_);xue=n(iIe,"STRONG",{});var AAt=s(xue);Fyo=r(AAt,"ernie"),AAt.forEach(t),Tyo=r(iIe," \u2014 "),DO=n(iIe,"A",{href:!0});var LAt=s(DO);Myo=r(LAt,"ErnieModel"),LAt.forEach(t),Eyo=r(iIe," (ERNIE model)"),iIe.forEach(t),Cyo=i(x),C_=n(x,"LI",{});var dIe=s(C_);$ue=n(dIe,"STRONG",{});var yAt=s($ue);wyo=r(yAt,"flaubert"),yAt.forEach(t),Ayo=r(dIe," \u2014 "),GO=n(dIe,"A",{href:!0});var xAt=s(GO);Lyo=r(xAt,"FlaubertModel"),xAt.forEach(t),yyo=r(dIe," (FlauBERT model)"),dIe.forEach(t),xyo=i(x),w_=n(x,"LI",{});var cIe=s(w_);kue=n(cIe,"STRONG",{});var $At=s(kue);$yo=r($At,"flava"),$At.forEach(t),kyo=r(cIe," \u2014 "),OO=n(cIe,"A",{href:!0});var kAt=s(OO);Syo=r(kAt,"FlavaModel"),kAt.forEach(t),Ryo=r(cIe," (FLAVA model)"),cIe.forEach(t),Pyo=i(x),A_=n(x,"LI",{});var mIe=s(A_);Sue=n(mIe,"STRONG",{});var SAt=s(Sue);Byo=r(SAt,"fnet"),SAt.forEach(t),Iyo=r(mIe," \u2014 "),VO=n(mIe,"A",{href:!0});var RAt=s(VO);Nyo=r(RAt,"FNetModel"),RAt.forEach(t),qyo=r(mIe," (FNet model)"),mIe.forEach(t),jyo=i(x),L_=n(x,"LI",{});var fIe=s(L_);Rue=n(fIe,"STRONG",{});var PAt=s(Rue);Dyo=r(PAt,"fsmt"),PAt.forEach(t),Gyo=r(fIe," \u2014 "),XO=n(fIe,"A",{href:!0});var BAt=s(XO);Oyo=r(BAt,"FSMTModel"),BAt.forEach(t),Vyo=r(fIe," (FairSeq Machine-Translation model)"),fIe.forEach(t),Xyo=i(x),pl=n(x,"LI",{});var vB=s(pl);Pue=n(vB,"STRONG",{});var IAt=s(Pue);zyo=r(IAt,"funnel"),IAt.forEach(t),Qyo=r(vB," \u2014 "),zO=n(vB,"A",{href:!0});var NAt=s(zO);Wyo=r(NAt,"FunnelModel"),NAt.forEach(t),Uyo=r(vB," or "),QO=n(vB,"A",{href:!0});var qAt=s(QO);Hyo=r(qAt,"FunnelBaseModel"),qAt.forEach(t),Jyo=r(vB," (Funnel Transformer model)"),vB.forEach(t),Yyo=i(x),y_=n(x,"LI",{});var gIe=s(y_);Bue=n(gIe,"STRONG",{});var jAt=s(Bue);Kyo=r(jAt,"glpn"),jAt.forEach(t),Zyo=r(gIe," \u2014 "),WO=n(gIe,"A",{href:!0});var DAt=s(WO);e8o=r(DAt,"GLPNModel"),DAt.forEach(t),o8o=r(gIe," (GLPN model)"),gIe.forEach(t),r8o=i(x),x_=n(x,"LI",{});var hIe=s(x_);Iue=n(hIe,"STRONG",{});var GAt=s(Iue);t8o=r(GAt,"gpt2"),GAt.forEach(t),a8o=r(hIe," \u2014 "),UO=n(hIe,"A",{href:!0});var OAt=s(UO);n8o=r(OAt,"GPT2Model"),OAt.forEach(t),s8o=r(hIe," (OpenAI GPT-2 model)"),hIe.forEach(t),l8o=i(x),$_=n(x,"LI",{});var uIe=s($_);Nue=n(uIe,"STRONG",{});var VAt=s(Nue);i8o=r(VAt,"gpt_neo"),VAt.forEach(t),d8o=r(uIe," \u2014 "),HO=n(uIe,"A",{href:!0});var XAt=s(HO);c8o=r(XAt,"GPTNeoModel"),XAt.forEach(t),m8o=r(uIe," (GPT Neo model)"),uIe.forEach(t),f8o=i(x),k_=n(x,"LI",{});var pIe=s(k_);que=n(pIe,"STRONG",{});var zAt=s(que);g8o=r(zAt,"gpt_neox"),zAt.forEach(t),h8o=r(pIe," \u2014 "),JO=n(pIe,"A",{href:!0});var QAt=s(JO);u8o=r(QAt,"GPTNeoXModel"),QAt.forEach(t),p8o=r(pIe," (GPT NeoX model)"),pIe.forEach(t),_8o=i(x),S_=n(x,"LI",{});var _Ie=s(S_);jue=n(_Ie,"STRONG",{});var WAt=s(jue);b8o=r(WAt,"gptj"),WAt.forEach(t),v8o=r(_Ie," \u2014 "),YO=n(_Ie,"A",{href:!0});var UAt=s(YO);F8o=r(UAt,"GPTJModel"),UAt.forEach(t),T8o=r(_Ie," (GPT-J model)"),_Ie.forEach(t),M8o=i(x),R_=n(x,"LI",{});var bIe=s(R_);Due=n(bIe,"STRONG",{});var HAt=s(Due);E8o=r(HAt,"groupvit"),HAt.forEach(t),C8o=r(bIe," \u2014 "),KO=n(bIe,"A",{href:!0});var JAt=s(KO);w8o=r(JAt,"GroupViTModel"),JAt.forEach(t),A8o=r(bIe," (GroupViT model)"),bIe.forEach(t),L8o=i(x),P_=n(x,"LI",{});var vIe=s(P_);Gue=n(vIe,"STRONG",{});var YAt=s(Gue);y8o=r(YAt,"hubert"),YAt.forEach(t),x8o=r(vIe," \u2014 "),ZO=n(vIe,"A",{href:!0});var KAt=s(ZO);$8o=r(KAt,"HubertModel"),KAt.forEach(t),k8o=r(vIe," (Hubert model)"),vIe.forEach(t),S8o=i(x),B_=n(x,"LI",{});var FIe=s(B_);Oue=n(FIe,"STRONG",{});var ZAt=s(Oue);R8o=r(ZAt,"ibert"),ZAt.forEach(t),P8o=r(FIe," \u2014 "),eV=n(FIe,"A",{href:!0});var e6t=s(eV);B8o=r(e6t,"IBertModel"),e6t.forEach(t),I8o=r(FIe," (I-BERT model)"),FIe.forEach(t),N8o=i(x),I_=n(x,"LI",{});var TIe=s(I_);Vue=n(TIe,"STRONG",{});var o6t=s(Vue);q8o=r(o6t,"imagegpt"),o6t.forEach(t),j8o=r(TIe," \u2014 "),oV=n(TIe,"A",{href:!0});var r6t=s(oV);D8o=r(r6t,"ImageGPTModel"),r6t.forEach(t),G8o=r(TIe," (ImageGPT model)"),TIe.forEach(t),O8o=i(x),N_=n(x,"LI",{});var MIe=s(N_);Xue=n(MIe,"STRONG",{});var t6t=s(Xue);V8o=r(t6t,"layoutlm"),t6t.forEach(t),X8o=r(MIe," \u2014 "),rV=n(MIe,"A",{href:!0});var a6t=s(rV);z8o=r(a6t,"LayoutLMModel"),a6t.forEach(t),Q8o=r(MIe," (LayoutLM model)"),MIe.forEach(t),W8o=i(x),q_=n(x,"LI",{});var EIe=s(q_);zue=n(EIe,"STRONG",{});var n6t=s(zue);U8o=r(n6t,"layoutlmv2"),n6t.forEach(t),H8o=r(EIe," \u2014 "),tV=n(EIe,"A",{href:!0});var s6t=s(tV);J8o=r(s6t,"LayoutLMv2Model"),s6t.forEach(t),Y8o=r(EIe," (LayoutLMv2 model)"),EIe.forEach(t),K8o=i(x),j_=n(x,"LI",{});var CIe=s(j_);Que=n(CIe,"STRONG",{});var l6t=s(Que);Z8o=r(l6t,"layoutlmv3"),l6t.forEach(t),e9o=r(CIe," \u2014 "),aV=n(CIe,"A",{href:!0});var i6t=s(aV);o9o=r(i6t,"LayoutLMv3Model"),i6t.forEach(t),r9o=r(CIe," (LayoutLMv3 model)"),CIe.forEach(t),t9o=i(x),D_=n(x,"LI",{});var wIe=s(D_);Wue=n(wIe,"STRONG",{});var d6t=s(Wue);a9o=r(d6t,"led"),d6t.forEach(t),n9o=r(wIe," \u2014 "),nV=n(wIe,"A",{href:!0});var c6t=s(nV);s9o=r(c6t,"LEDModel"),c6t.forEach(t),l9o=r(wIe," (LED model)"),wIe.forEach(t),i9o=i(x),G_=n(x,"LI",{});var AIe=s(G_);Uue=n(AIe,"STRONG",{});var m6t=s(Uue);d9o=r(m6t,"levit"),m6t.forEach(t),c9o=r(AIe," \u2014 "),sV=n(AIe,"A",{href:!0});var f6t=s(sV);m9o=r(f6t,"LevitModel"),f6t.forEach(t),f9o=r(AIe," (LeViT model)"),AIe.forEach(t),g9o=i(x),O_=n(x,"LI",{});var LIe=s(O_);Hue=n(LIe,"STRONG",{});var g6t=s(Hue);h9o=r(g6t,"longformer"),g6t.forEach(t),u9o=r(LIe," \u2014 "),lV=n(LIe,"A",{href:!0});var h6t=s(lV);p9o=r(h6t,"LongformerModel"),h6t.forEach(t),_9o=r(LIe," (Longformer model)"),LIe.forEach(t),b9o=i(x),V_=n(x,"LI",{});var yIe=s(V_);Jue=n(yIe,"STRONG",{});var u6t=s(Jue);v9o=r(u6t,"longt5"),u6t.forEach(t),F9o=r(yIe," \u2014 "),iV=n(yIe,"A",{href:!0});var p6t=s(iV);T9o=r(p6t,"LongT5Model"),p6t.forEach(t),M9o=r(yIe," (LongT5 model)"),yIe.forEach(t),E9o=i(x),X_=n(x,"LI",{});var xIe=s(X_);Yue=n(xIe,"STRONG",{});var _6t=s(Yue);C9o=r(_6t,"luke"),_6t.forEach(t),w9o=r(xIe," \u2014 "),dV=n(xIe,"A",{href:!0});var b6t=s(dV);A9o=r(b6t,"LukeModel"),b6t.forEach(t),L9o=r(xIe," (LUKE model)"),xIe.forEach(t),y9o=i(x),z_=n(x,"LI",{});var $Ie=s(z_);Kue=n($Ie,"STRONG",{});var v6t=s(Kue);x9o=r(v6t,"lxmert"),v6t.forEach(t),$9o=r($Ie," \u2014 "),cV=n($Ie,"A",{href:!0});var F6t=s(cV);k9o=r(F6t,"LxmertModel"),F6t.forEach(t),S9o=r($Ie," (LXMERT model)"),$Ie.forEach(t),R9o=i(x),Q_=n(x,"LI",{});var kIe=s(Q_);Zue=n(kIe,"STRONG",{});var T6t=s(Zue);P9o=r(T6t,"m2m_100"),T6t.forEach(t),B9o=r(kIe," \u2014 "),mV=n(kIe,"A",{href:!0});var M6t=s(mV);I9o=r(M6t,"M2M100Model"),M6t.forEach(t),N9o=r(kIe," (M2M100 model)"),kIe.forEach(t),q9o=i(x),W_=n(x,"LI",{});var SIe=s(W_);epe=n(SIe,"STRONG",{});var E6t=s(epe);j9o=r(E6t,"marian"),E6t.forEach(t),D9o=r(SIe," \u2014 "),fV=n(SIe,"A",{href:!0});var C6t=s(fV);G9o=r(C6t,"MarianModel"),C6t.forEach(t),O9o=r(SIe," (Marian model)"),SIe.forEach(t),V9o=i(x),U_=n(x,"LI",{});var RIe=s(U_);ope=n(RIe,"STRONG",{});var w6t=s(ope);X9o=r(w6t,"maskformer"),w6t.forEach(t),z9o=r(RIe," \u2014 "),gV=n(RIe,"A",{href:!0});var A6t=s(gV);Q9o=r(A6t,"MaskFormerModel"),A6t.forEach(t),W9o=r(RIe," (MaskFormer model)"),RIe.forEach(t),U9o=i(x),H_=n(x,"LI",{});var PIe=s(H_);rpe=n(PIe,"STRONG",{});var L6t=s(rpe);H9o=r(L6t,"mbart"),L6t.forEach(t),J9o=r(PIe," \u2014 "),hV=n(PIe,"A",{href:!0});var y6t=s(hV);Y9o=r(y6t,"MBartModel"),y6t.forEach(t),K9o=r(PIe," (mBART model)"),PIe.forEach(t),Z9o=i(x),J_=n(x,"LI",{});var BIe=s(J_);tpe=n(BIe,"STRONG",{});var x6t=s(tpe);exo=r(x6t,"mctct"),x6t.forEach(t),oxo=r(BIe," \u2014 "),uV=n(BIe,"A",{href:!0});var $6t=s(uV);rxo=r($6t,"MCTCTModel"),$6t.forEach(t),txo=r(BIe," (M-CTC-T model)"),BIe.forEach(t),axo=i(x),Y_=n(x,"LI",{});var IIe=s(Y_);ape=n(IIe,"STRONG",{});var k6t=s(ape);nxo=r(k6t,"megatron-bert"),k6t.forEach(t),sxo=r(IIe," \u2014 "),pV=n(IIe,"A",{href:!0});var S6t=s(pV);lxo=r(S6t,"MegatronBertModel"),S6t.forEach(t),ixo=r(IIe," (Megatron-BERT model)"),IIe.forEach(t),dxo=i(x),K_=n(x,"LI",{});var NIe=s(K_);npe=n(NIe,"STRONG",{});var R6t=s(npe);cxo=r(R6t,"mobilebert"),R6t.forEach(t),mxo=r(NIe," \u2014 "),_V=n(NIe,"A",{href:!0});var P6t=s(_V);fxo=r(P6t,"MobileBertModel"),P6t.forEach(t),gxo=r(NIe," (MobileBERT model)"),NIe.forEach(t),hxo=i(x),Z_=n(x,"LI",{});var qIe=s(Z_);spe=n(qIe,"STRONG",{});var B6t=s(spe);uxo=r(B6t,"mobilevit"),B6t.forEach(t),pxo=r(qIe," \u2014 "),bV=n(qIe,"A",{href:!0});var I6t=s(bV);_xo=r(I6t,"MobileViTModel"),I6t.forEach(t),bxo=r(qIe," (MobileViT model)"),qIe.forEach(t),vxo=i(x),e2=n(x,"LI",{});var jIe=s(e2);lpe=n(jIe,"STRONG",{});var N6t=s(lpe);Fxo=r(N6t,"mpnet"),N6t.forEach(t),Txo=r(jIe," \u2014 "),vV=n(jIe,"A",{href:!0});var q6t=s(vV);Mxo=r(q6t,"MPNetModel"),q6t.forEach(t),Exo=r(jIe," (MPNet model)"),jIe.forEach(t),Cxo=i(x),o2=n(x,"LI",{});var DIe=s(o2);ipe=n(DIe,"STRONG",{});var j6t=s(ipe);wxo=r(j6t,"mt5"),j6t.forEach(t),Axo=r(DIe," \u2014 "),FV=n(DIe,"A",{href:!0});var D6t=s(FV);Lxo=r(D6t,"MT5Model"),D6t.forEach(t),yxo=r(DIe," (MT5 model)"),DIe.forEach(t),xxo=i(x),r2=n(x,"LI",{});var GIe=s(r2);dpe=n(GIe,"STRONG",{});var G6t=s(dpe);$xo=r(G6t,"mvp"),G6t.forEach(t),kxo=r(GIe," \u2014 "),TV=n(GIe,"A",{href:!0});var O6t=s(TV);Sxo=r(O6t,"MvpModel"),O6t.forEach(t),Rxo=r(GIe," (MVP model)"),GIe.forEach(t),Pxo=i(x),t2=n(x,"LI",{});var OIe=s(t2);cpe=n(OIe,"STRONG",{});var V6t=s(cpe);Bxo=r(V6t,"nezha"),V6t.forEach(t),Ixo=r(OIe," \u2014 "),MV=n(OIe,"A",{href:!0});var X6t=s(MV);Nxo=r(X6t,"NezhaModel"),X6t.forEach(t),qxo=r(OIe," (Nezha model)"),OIe.forEach(t),jxo=i(x),a2=n(x,"LI",{});var VIe=s(a2);mpe=n(VIe,"STRONG",{});var z6t=s(mpe);Dxo=r(z6t,"nllb"),z6t.forEach(t),Gxo=r(VIe," \u2014 "),EV=n(VIe,"A",{href:!0});var Q6t=s(EV);Oxo=r(Q6t,"M2M100Model"),Q6t.forEach(t),Vxo=r(VIe," (NLLB model)"),VIe.forEach(t),Xxo=i(x),n2=n(x,"LI",{});var XIe=s(n2);fpe=n(XIe,"STRONG",{});var W6t=s(fpe);zxo=r(W6t,"nystromformer"),W6t.forEach(t),Qxo=r(XIe," \u2014 "),CV=n(XIe,"A",{href:!0});var U6t=s(CV);Wxo=r(U6t,"NystromformerModel"),U6t.forEach(t),Uxo=r(XIe," (Nystr\xF6mformer model)"),XIe.forEach(t),Hxo=i(x),s2=n(x,"LI",{});var zIe=s(s2);gpe=n(zIe,"STRONG",{});var H6t=s(gpe);Jxo=r(H6t,"openai-gpt"),H6t.forEach(t),Yxo=r(zIe," \u2014 "),wV=n(zIe,"A",{href:!0});var J6t=s(wV);Kxo=r(J6t,"OpenAIGPTModel"),J6t.forEach(t),Zxo=r(zIe," (OpenAI GPT model)"),zIe.forEach(t),e$o=i(x),l2=n(x,"LI",{});var QIe=s(l2);hpe=n(QIe,"STRONG",{});var Y6t=s(hpe);o$o=r(Y6t,"opt"),Y6t.forEach(t),r$o=r(QIe," \u2014 "),AV=n(QIe,"A",{href:!0});var K6t=s(AV);t$o=r(K6t,"OPTModel"),K6t.forEach(t),a$o=r(QIe," (OPT model)"),QIe.forEach(t),n$o=i(x),i2=n(x,"LI",{});var WIe=s(i2);upe=n(WIe,"STRONG",{});var Z6t=s(upe);s$o=r(Z6t,"owlvit"),Z6t.forEach(t),l$o=r(WIe," \u2014 "),LV=n(WIe,"A",{href:!0});var e7t=s(LV);i$o=r(e7t,"OwlViTModel"),e7t.forEach(t),d$o=r(WIe," (OWL-ViT model)"),WIe.forEach(t),c$o=i(x),d2=n(x,"LI",{});var UIe=s(d2);ppe=n(UIe,"STRONG",{});var o7t=s(ppe);m$o=r(o7t,"pegasus"),o7t.forEach(t),f$o=r(UIe," \u2014 "),yV=n(UIe,"A",{href:!0});var r7t=s(yV);g$o=r(r7t,"PegasusModel"),r7t.forEach(t),h$o=r(UIe," (Pegasus model)"),UIe.forEach(t),u$o=i(x),c2=n(x,"LI",{});var HIe=s(c2);_pe=n(HIe,"STRONG",{});var t7t=s(_pe);p$o=r(t7t,"pegasus_x"),t7t.forEach(t),_$o=r(HIe," \u2014 "),xV=n(HIe,"A",{href:!0});var a7t=s(xV);b$o=r(a7t,"PegasusXModel"),a7t.forEach(t),v$o=r(HIe," (PEGASUS-X model)"),HIe.forEach(t),F$o=i(x),m2=n(x,"LI",{});var JIe=s(m2);bpe=n(JIe,"STRONG",{});var n7t=s(bpe);T$o=r(n7t,"perceiver"),n7t.forEach(t),M$o=r(JIe," \u2014 "),$V=n(JIe,"A",{href:!0});var s7t=s($V);E$o=r(s7t,"PerceiverModel"),s7t.forEach(t),C$o=r(JIe," (Perceiver model)"),JIe.forEach(t),w$o=i(x),f2=n(x,"LI",{});var YIe=s(f2);vpe=n(YIe,"STRONG",{});var l7t=s(vpe);A$o=r(l7t,"plbart"),l7t.forEach(t),L$o=r(YIe," \u2014 "),kV=n(YIe,"A",{href:!0});var i7t=s(kV);y$o=r(i7t,"PLBartModel"),i7t.forEach(t),x$o=r(YIe," (PLBart model)"),YIe.forEach(t),$$o=i(x),g2=n(x,"LI",{});var KIe=s(g2);Fpe=n(KIe,"STRONG",{});var d7t=s(Fpe);k$o=r(d7t,"poolformer"),d7t.forEach(t),S$o=r(KIe," \u2014 "),SV=n(KIe,"A",{href:!0});var c7t=s(SV);R$o=r(c7t,"PoolFormerModel"),c7t.forEach(t),P$o=r(KIe," (PoolFormer model)"),KIe.forEach(t),B$o=i(x),h2=n(x,"LI",{});var ZIe=s(h2);Tpe=n(ZIe,"STRONG",{});var m7t=s(Tpe);I$o=r(m7t,"prophetnet"),m7t.forEach(t),N$o=r(ZIe," \u2014 "),RV=n(ZIe,"A",{href:!0});var f7t=s(RV);q$o=r(f7t,"ProphetNetModel"),f7t.forEach(t),j$o=r(ZIe," (ProphetNet model)"),ZIe.forEach(t),D$o=i(x),u2=n(x,"LI",{});var eNe=s(u2);Mpe=n(eNe,"STRONG",{});var g7t=s(Mpe);G$o=r(g7t,"qdqbert"),g7t.forEach(t),O$o=r(eNe," \u2014 "),PV=n(eNe,"A",{href:!0});var h7t=s(PV);V$o=r(h7t,"QDQBertModel"),h7t.forEach(t),X$o=r(eNe," (QDQBert model)"),eNe.forEach(t),z$o=i(x),p2=n(x,"LI",{});var oNe=s(p2);Epe=n(oNe,"STRONG",{});var u7t=s(Epe);Q$o=r(u7t,"reformer"),u7t.forEach(t),W$o=r(oNe," \u2014 "),BV=n(oNe,"A",{href:!0});var p7t=s(BV);U$o=r(p7t,"ReformerModel"),p7t.forEach(t),H$o=r(oNe," (Reformer model)"),oNe.forEach(t),J$o=i(x),_2=n(x,"LI",{});var rNe=s(_2);Cpe=n(rNe,"STRONG",{});var _7t=s(Cpe);Y$o=r(_7t,"regnet"),_7t.forEach(t),K$o=r(rNe," \u2014 "),IV=n(rNe,"A",{href:!0});var b7t=s(IV);Z$o=r(b7t,"RegNetModel"),b7t.forEach(t),eko=r(rNe," (RegNet model)"),rNe.forEach(t),oko=i(x),b2=n(x,"LI",{});var tNe=s(b2);wpe=n(tNe,"STRONG",{});var v7t=s(wpe);rko=r(v7t,"rembert"),v7t.forEach(t),tko=r(tNe," \u2014 "),NV=n(tNe,"A",{href:!0});var F7t=s(NV);ako=r(F7t,"RemBertModel"),F7t.forEach(t),nko=r(tNe," (RemBERT model)"),tNe.forEach(t),sko=i(x),v2=n(x,"LI",{});var aNe=s(v2);Ape=n(aNe,"STRONG",{});var T7t=s(Ape);lko=r(T7t,"resnet"),T7t.forEach(t),iko=r(aNe," \u2014 "),qV=n(aNe,"A",{href:!0});var M7t=s(qV);dko=r(M7t,"ResNetModel"),M7t.forEach(t),cko=r(aNe," (ResNet model)"),aNe.forEach(t),mko=i(x),F2=n(x,"LI",{});var nNe=s(F2);Lpe=n(nNe,"STRONG",{});var E7t=s(Lpe);fko=r(E7t,"retribert"),E7t.forEach(t),gko=r(nNe," \u2014 "),jV=n(nNe,"A",{href:!0});var C7t=s(jV);hko=r(C7t,"RetriBertModel"),C7t.forEach(t),uko=r(nNe," (RetriBERT model)"),nNe.forEach(t),pko=i(x),T2=n(x,"LI",{});var sNe=s(T2);ype=n(sNe,"STRONG",{});var w7t=s(ype);_ko=r(w7t,"roberta"),w7t.forEach(t),bko=r(sNe," \u2014 "),DV=n(sNe,"A",{href:!0});var A7t=s(DV);vko=r(A7t,"RobertaModel"),A7t.forEach(t),Fko=r(sNe," (RoBERTa model)"),sNe.forEach(t),Tko=i(x),M2=n(x,"LI",{});var lNe=s(M2);xpe=n(lNe,"STRONG",{});var L7t=s(xpe);Mko=r(L7t,"roformer"),L7t.forEach(t),Eko=r(lNe," \u2014 "),GV=n(lNe,"A",{href:!0});var y7t=s(GV);Cko=r(y7t,"RoFormerModel"),y7t.forEach(t),wko=r(lNe," (RoFormer model)"),lNe.forEach(t),Ako=i(x),E2=n(x,"LI",{});var iNe=s(E2);$pe=n(iNe,"STRONG",{});var x7t=s($pe);Lko=r(x7t,"segformer"),x7t.forEach(t),yko=r(iNe," \u2014 "),OV=n(iNe,"A",{href:!0});var $7t=s(OV);xko=r($7t,"SegformerModel"),$7t.forEach(t),$ko=r(iNe," (SegFormer model)"),iNe.forEach(t),kko=i(x),C2=n(x,"LI",{});var dNe=s(C2);kpe=n(dNe,"STRONG",{});var k7t=s(kpe);Sko=r(k7t,"sew"),k7t.forEach(t),Rko=r(dNe," \u2014 "),VV=n(dNe,"A",{href:!0});var S7t=s(VV);Pko=r(S7t,"SEWModel"),S7t.forEach(t),Bko=r(dNe," (SEW model)"),dNe.forEach(t),Iko=i(x),w2=n(x,"LI",{});var cNe=s(w2);Spe=n(cNe,"STRONG",{});var R7t=s(Spe);Nko=r(R7t,"sew-d"),R7t.forEach(t),qko=r(cNe," \u2014 "),XV=n(cNe,"A",{href:!0});var P7t=s(XV);jko=r(P7t,"SEWDModel"),P7t.forEach(t),Dko=r(cNe," (SEW-D model)"),cNe.forEach(t),Gko=i(x),A2=n(x,"LI",{});var mNe=s(A2);Rpe=n(mNe,"STRONG",{});var B7t=s(Rpe);Oko=r(B7t,"speech_to_text"),B7t.forEach(t),Vko=r(mNe," \u2014 "),zV=n(mNe,"A",{href:!0});var I7t=s(zV);Xko=r(I7t,"Speech2TextModel"),I7t.forEach(t),zko=r(mNe," (Speech2Text model)"),mNe.forEach(t),Qko=i(x),L2=n(x,"LI",{});var fNe=s(L2);Ppe=n(fNe,"STRONG",{});var N7t=s(Ppe);Wko=r(N7t,"splinter"),N7t.forEach(t),Uko=r(fNe," \u2014 "),QV=n(fNe,"A",{href:!0});var q7t=s(QV);Hko=r(q7t,"SplinterModel"),q7t.forEach(t),Jko=r(fNe," (Splinter model)"),fNe.forEach(t),Yko=i(x),y2=n(x,"LI",{});var gNe=s(y2);Bpe=n(gNe,"STRONG",{});var j7t=s(Bpe);Kko=r(j7t,"squeezebert"),j7t.forEach(t),Zko=r(gNe," \u2014 "),WV=n(gNe,"A",{href:!0});var D7t=s(WV);eSo=r(D7t,"SqueezeBertModel"),D7t.forEach(t),oSo=r(gNe," (SqueezeBERT model)"),gNe.forEach(t),rSo=i(x),x2=n(x,"LI",{});var hNe=s(x2);Ipe=n(hNe,"STRONG",{});var G7t=s(Ipe);tSo=r(G7t,"swin"),G7t.forEach(t),aSo=r(hNe," \u2014 "),UV=n(hNe,"A",{href:!0});var O7t=s(UV);nSo=r(O7t,"SwinModel"),O7t.forEach(t),sSo=r(hNe," (Swin Transformer model)"),hNe.forEach(t),lSo=i(x),$2=n(x,"LI",{});var uNe=s($2);Npe=n(uNe,"STRONG",{});var V7t=s(Npe);iSo=r(V7t,"swinv2"),V7t.forEach(t),dSo=r(uNe," \u2014 "),HV=n(uNe,"A",{href:!0});var X7t=s(HV);cSo=r(X7t,"Swinv2Model"),X7t.forEach(t),mSo=r(uNe," (Swin Transformer V2 model)"),uNe.forEach(t),fSo=i(x),k2=n(x,"LI",{});var pNe=s(k2);qpe=n(pNe,"STRONG",{});var z7t=s(qpe);gSo=r(z7t,"t5"),z7t.forEach(t),hSo=r(pNe," \u2014 "),JV=n(pNe,"A",{href:!0});var Q7t=s(JV);uSo=r(Q7t,"T5Model"),Q7t.forEach(t),pSo=r(pNe," (T5 model)"),pNe.forEach(t),_So=i(x),S2=n(x,"LI",{});var _Ne=s(S2);jpe=n(_Ne,"STRONG",{});var W7t=s(jpe);bSo=r(W7t,"tapas"),W7t.forEach(t),vSo=r(_Ne," \u2014 "),YV=n(_Ne,"A",{href:!0});var U7t=s(YV);FSo=r(U7t,"TapasModel"),U7t.forEach(t),TSo=r(_Ne," (TAPAS model)"),_Ne.forEach(t),MSo=i(x),R2=n(x,"LI",{});var bNe=s(R2);Dpe=n(bNe,"STRONG",{});var H7t=s(Dpe);ESo=r(H7t,"trajectory_transformer"),H7t.forEach(t),CSo=r(bNe," \u2014 "),KV=n(bNe,"A",{href:!0});var J7t=s(KV);wSo=r(J7t,"TrajectoryTransformerModel"),J7t.forEach(t),ASo=r(bNe," (Trajectory Transformer model)"),bNe.forEach(t),LSo=i(x),P2=n(x,"LI",{});var vNe=s(P2);Gpe=n(vNe,"STRONG",{});var Y7t=s(Gpe);ySo=r(Y7t,"transfo-xl"),Y7t.forEach(t),xSo=r(vNe," \u2014 "),ZV=n(vNe,"A",{href:!0});var K7t=s(ZV);$So=r(K7t,"TransfoXLModel"),K7t.forEach(t),kSo=r(vNe," (Transformer-XL model)"),vNe.forEach(t),SSo=i(x),B2=n(x,"LI",{});var FNe=s(B2);Ope=n(FNe,"STRONG",{});var Z7t=s(Ope);RSo=r(Z7t,"unispeech"),Z7t.forEach(t),PSo=r(FNe," \u2014 "),eX=n(FNe,"A",{href:!0});var eLt=s(eX);BSo=r(eLt,"UniSpeechModel"),eLt.forEach(t),ISo=r(FNe," (UniSpeech model)"),FNe.forEach(t),NSo=i(x),I2=n(x,"LI",{});var TNe=s(I2);Vpe=n(TNe,"STRONG",{});var oLt=s(Vpe);qSo=r(oLt,"unispeech-sat"),oLt.forEach(t),jSo=r(TNe," \u2014 "),oX=n(TNe,"A",{href:!0});var rLt=s(oX);DSo=r(rLt,"UniSpeechSatModel"),rLt.forEach(t),GSo=r(TNe," (UniSpeechSat model)"),TNe.forEach(t),OSo=i(x),N2=n(x,"LI",{});var MNe=s(N2);Xpe=n(MNe,"STRONG",{});var tLt=s(Xpe);VSo=r(tLt,"van"),tLt.forEach(t),XSo=r(MNe," \u2014 "),rX=n(MNe,"A",{href:!0});var aLt=s(rX);zSo=r(aLt,"VanModel"),aLt.forEach(t),QSo=r(MNe," (VAN model)"),MNe.forEach(t),WSo=i(x),q2=n(x,"LI",{});var ENe=s(q2);zpe=n(ENe,"STRONG",{});var nLt=s(zpe);USo=r(nLt,"videomae"),nLt.forEach(t),HSo=r(ENe," \u2014 "),tX=n(ENe,"A",{href:!0});var sLt=s(tX);JSo=r(sLt,"VideoMAEModel"),sLt.forEach(t),YSo=r(ENe," (VideoMAE model)"),ENe.forEach(t),KSo=i(x),j2=n(x,"LI",{});var CNe=s(j2);Qpe=n(CNe,"STRONG",{});var lLt=s(Qpe);ZSo=r(lLt,"vilt"),lLt.forEach(t),eRo=r(CNe," \u2014 "),aX=n(CNe,"A",{href:!0});var iLt=s(aX);oRo=r(iLt,"ViltModel"),iLt.forEach(t),rRo=r(CNe," (ViLT model)"),CNe.forEach(t),tRo=i(x),D2=n(x,"LI",{});var wNe=s(D2);Wpe=n(wNe,"STRONG",{});var dLt=s(Wpe);aRo=r(dLt,"vision-text-dual-encoder"),dLt.forEach(t),nRo=r(wNe," \u2014 "),nX=n(wNe,"A",{href:!0});var cLt=s(nX);sRo=r(cLt,"VisionTextDualEncoderModel"),cLt.forEach(t),lRo=r(wNe," (VisionTextDualEncoder model)"),wNe.forEach(t),iRo=i(x),G2=n(x,"LI",{});var ANe=s(G2);Upe=n(ANe,"STRONG",{});var mLt=s(Upe);dRo=r(mLt,"visual_bert"),mLt.forEach(t),cRo=r(ANe," \u2014 "),sX=n(ANe,"A",{href:!0});var fLt=s(sX);mRo=r(fLt,"VisualBertModel"),fLt.forEach(t),fRo=r(ANe," (VisualBERT model)"),ANe.forEach(t),gRo=i(x),O2=n(x,"LI",{});var LNe=s(O2);Hpe=n(LNe,"STRONG",{});var gLt=s(Hpe);hRo=r(gLt,"vit"),gLt.forEach(t),uRo=r(LNe," \u2014 "),lX=n(LNe,"A",{href:!0});var hLt=s(lX);pRo=r(hLt,"ViTModel"),hLt.forEach(t),_Ro=r(LNe," (ViT model)"),LNe.forEach(t),bRo=i(x),V2=n(x,"LI",{});var yNe=s(V2);Jpe=n(yNe,"STRONG",{});var uLt=s(Jpe);vRo=r(uLt,"vit_mae"),uLt.forEach(t),FRo=r(yNe," \u2014 "),iX=n(yNe,"A",{href:!0});var pLt=s(iX);TRo=r(pLt,"ViTMAEModel"),pLt.forEach(t),MRo=r(yNe," (ViTMAE model)"),yNe.forEach(t),ERo=i(x),X2=n(x,"LI",{});var xNe=s(X2);Ype=n(xNe,"STRONG",{});var _Lt=s(Ype);CRo=r(_Lt,"wav2vec2"),_Lt.forEach(t),wRo=r(xNe," \u2014 "),dX=n(xNe,"A",{href:!0});var bLt=s(dX);ARo=r(bLt,"Wav2Vec2Model"),bLt.forEach(t),LRo=r(xNe," (Wav2Vec2 model)"),xNe.forEach(t),yRo=i(x),z2=n(x,"LI",{});var $Ne=s(z2);Kpe=n($Ne,"STRONG",{});var vLt=s(Kpe);xRo=r(vLt,"wav2vec2-conformer"),vLt.forEach(t),$Ro=r($Ne," \u2014 "),cX=n($Ne,"A",{href:!0});var FLt=s(cX);kRo=r(FLt,"Wav2Vec2ConformerModel"),FLt.forEach(t),SRo=r($Ne," (Wav2Vec2-Conformer model)"),$Ne.forEach(t),RRo=i(x),Q2=n(x,"LI",{});var kNe=s(Q2);Zpe=n(kNe,"STRONG",{});var TLt=s(Zpe);PRo=r(TLt,"wavlm"),TLt.forEach(t),BRo=r(kNe," \u2014 "),mX=n(kNe,"A",{href:!0});var MLt=s(mX);IRo=r(MLt,"WavLMModel"),MLt.forEach(t),NRo=r(kNe," (WavLM model)"),kNe.forEach(t),qRo=i(x),W2=n(x,"LI",{});var SNe=s(W2);e_e=n(SNe,"STRONG",{});var ELt=s(e_e);jRo=r(ELt,"xclip"),ELt.forEach(t),DRo=r(SNe," \u2014 "),fX=n(SNe,"A",{href:!0});var CLt=s(fX);GRo=r(CLt,"XCLIPModel"),CLt.forEach(t),ORo=r(SNe," (X-CLIP model)"),SNe.forEach(t),VRo=i(x),U2=n(x,"LI",{});var RNe=s(U2);o_e=n(RNe,"STRONG",{});var wLt=s(o_e);XRo=r(wLt,"xglm"),wLt.forEach(t),zRo=r(RNe," \u2014 "),gX=n(RNe,"A",{href:!0});var ALt=s(gX);QRo=r(ALt,"XGLMModel"),ALt.forEach(t),WRo=r(RNe," (XGLM model)"),RNe.forEach(t),URo=i(x),H2=n(x,"LI",{});var PNe=s(H2);r_e=n(PNe,"STRONG",{});var LLt=s(r_e);HRo=r(LLt,"xlm"),LLt.forEach(t),JRo=r(PNe," \u2014 "),hX=n(PNe,"A",{href:!0});var yLt=s(hX);YRo=r(yLt,"XLMModel"),yLt.forEach(t),KRo=r(PNe," (XLM model)"),PNe.forEach(t),ZRo=i(x),J2=n(x,"LI",{});var BNe=s(J2);t_e=n(BNe,"STRONG",{});var xLt=s(t_e);ePo=r(xLt,"xlm-prophetnet"),xLt.forEach(t),oPo=r(BNe," \u2014 "),uX=n(BNe,"A",{href:!0});var $Lt=s(uX);rPo=r($Lt,"XLMProphetNetModel"),$Lt.forEach(t),tPo=r(BNe," (XLM-ProphetNet model)"),BNe.forEach(t),aPo=i(x),Y2=n(x,"LI",{});var INe=s(Y2);a_e=n(INe,"STRONG",{});var kLt=s(a_e);nPo=r(kLt,"xlm-roberta"),kLt.forEach(t),sPo=r(INe," \u2014 "),pX=n(INe,"A",{href:!0});var SLt=s(pX);lPo=r(SLt,"XLMRobertaModel"),SLt.forEach(t),iPo=r(INe," (XLM-RoBERTa model)"),INe.forEach(t),dPo=i(x),K2=n(x,"LI",{});var NNe=s(K2);n_e=n(NNe,"STRONG",{});var RLt=s(n_e);cPo=r(RLt,"xlm-roberta-xl"),RLt.forEach(t),mPo=r(NNe," \u2014 "),_X=n(NNe,"A",{href:!0});var PLt=s(_X);fPo=r(PLt,"XLMRobertaXLModel"),PLt.forEach(t),gPo=r(NNe," (XLM-RoBERTa-XL model)"),NNe.forEach(t),hPo=i(x),Z2=n(x,"LI",{});var qNe=s(Z2);s_e=n(qNe,"STRONG",{});var BLt=s(s_e);uPo=r(BLt,"xlnet"),BLt.forEach(t),pPo=r(qNe," \u2014 "),bX=n(qNe,"A",{href:!0});var ILt=s(bX);_Po=r(ILt,"XLNetModel"),ILt.forEach(t),bPo=r(qNe," (XLNet model)"),qNe.forEach(t),vPo=i(x),eb=n(x,"LI",{});var jNe=s(eb);l_e=n(jNe,"STRONG",{});var NLt=s(l_e);FPo=r(NLt,"yolos"),NLt.forEach(t),TPo=r(jNe," \u2014 "),vX=n(jNe,"A",{href:!0});var qLt=s(vX);MPo=r(qLt,"YolosModel"),qLt.forEach(t),EPo=r(jNe," (YOLOS model)"),jNe.forEach(t),CPo=i(x),ob=n(x,"LI",{});var DNe=s(ob);i_e=n(DNe,"STRONG",{});var jLt=s(i_e);wPo=r(jLt,"yoso"),jLt.forEach(t),APo=r(DNe," \u2014 "),FX=n(DNe,"A",{href:!0});var DLt=s(FX);LPo=r(DLt,"YosoModel"),DLt.forEach(t),yPo=r(DNe," (YOSO model)"),DNe.forEach(t),x.forEach(t),xPo=i(Fa),rb=n(Fa,"P",{});var GNe=s(rb);$Po=r(GNe,"The model is set in evaluation mode by default using "),d_e=n(GNe,"CODE",{});var GLt=s(d_e);kPo=r(GLt,"model.eval()"),GLt.forEach(t),SPo=r(GNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=n(GNe,"CODE",{});var OLt=s(c_e);RPo=r(OLt,"model.train()"),OLt.forEach(t),GNe.forEach(t),PPo=i(Fa),T(tb.$$.fragment,Fa),Fa.forEach(t),wl.forEach(t),QYe=i(m),vd=n(m,"H2",{class:!0});var seo=s(vd);ab=n(seo,"A",{id:!0,class:!0,href:!0});var VLt=s(ab);m_e=n(VLt,"SPAN",{});var XLt=s(m_e);T(ex.$$.fragment,XLt),XLt.forEach(t),VLt.forEach(t),BPo=i(seo),f_e=n(seo,"SPAN",{});var zLt=s(f_e);IPo=r(zLt,"AutoModelForPreTraining"),zLt.forEach(t),seo.forEach(t),WYe=i(m),Bo=n(m,"DIV",{class:!0});var Al=s(Bo);T(ox.$$.fragment,Al),NPo=i(Al),Fd=n(Al,"P",{});var Hse=s(Fd);qPo=r(Hse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TX=n(Hse,"A",{href:!0});var QLt=s(TX);jPo=r(QLt,"from_pretrained()"),QLt.forEach(t),DPo=r(Hse," class method or the "),MX=n(Hse,"A",{href:!0});var WLt=s(MX);GPo=r(WLt,"from_config()"),WLt.forEach(t),OPo=r(Hse,` class
method.`),Hse.forEach(t),VPo=i(Al),rx=n(Al,"P",{});var leo=s(rx);XPo=r(leo,"This class cannot be instantiated directly using "),g_e=n(leo,"CODE",{});var ULt=s(g_e);zPo=r(ULt,"__init__()"),ULt.forEach(t),QPo=r(leo," (throws an error)."),leo.forEach(t),WPo=i(Al),bt=n(Al,"DIV",{class:!0});var Fy=s(bt);T(tx.$$.fragment,Fy),UPo=i(Fy),h_e=n(Fy,"P",{});var HLt=s(h_e);HPo=r(HLt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HLt.forEach(t),JPo=i(Fy),Td=n(Fy,"P",{});var Jse=s(Td);YPo=r(Jse,`Note:
Loading a model from its configuration file does `),u_e=n(Jse,"STRONG",{});var JLt=s(u_e);KPo=r(JLt,"not"),JLt.forEach(t),ZPo=r(Jse,` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=n(Jse,"A",{href:!0});var YLt=s(EX);eBo=r(YLt,"from_pretrained()"),YLt.forEach(t),oBo=r(Jse," to load the model weights."),Jse.forEach(t),rBo=i(Fy),T(nb.$$.fragment,Fy),Fy.forEach(t),tBo=i(Al),eo=n(Al,"DIV",{class:!0});var Ta=s(eo);T(ax.$$.fragment,Ta),aBo=i(Ta),p_e=n(Ta,"P",{});var KLt=s(p_e);nBo=r(KLt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KLt.forEach(t),sBo=i(Ta),Ya=n(Ta,"P",{});var Ty=s(Ya);lBo=r(Ty,"The model class to instantiate is selected based on the "),__e=n(Ty,"CODE",{});var ZLt=s(__e);iBo=r(ZLt,"model_type"),ZLt.forEach(t),dBo=r(Ty,` property of the config object (either
passed as an argument or loaded from `),b_e=n(Ty,"CODE",{});var eyt=s(b_e);cBo=r(eyt,"pretrained_model_name_or_path"),eyt.forEach(t),mBo=r(Ty,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v_e=n(Ty,"CODE",{});var oyt=s(v_e);fBo=r(oyt,"pretrained_model_name_or_path"),oyt.forEach(t),gBo=r(Ty,":"),Ty.forEach(t),hBo=i(Ta),G=n(Ta,"UL",{});var O=s(G);sb=n(O,"LI",{});var ONe=s(sb);F_e=n(ONe,"STRONG",{});var ryt=s(F_e);uBo=r(ryt,"albert"),ryt.forEach(t),pBo=r(ONe," \u2014 "),CX=n(ONe,"A",{href:!0});var tyt=s(CX);_Bo=r(tyt,"AlbertForPreTraining"),tyt.forEach(t),bBo=r(ONe," (ALBERT model)"),ONe.forEach(t),vBo=i(O),lb=n(O,"LI",{});var VNe=s(lb);T_e=n(VNe,"STRONG",{});var ayt=s(T_e);FBo=r(ayt,"bart"),ayt.forEach(t),TBo=r(VNe," \u2014 "),wX=n(VNe,"A",{href:!0});var nyt=s(wX);MBo=r(nyt,"BartForConditionalGeneration"),nyt.forEach(t),EBo=r(VNe," (BART model)"),VNe.forEach(t),CBo=i(O),ib=n(O,"LI",{});var XNe=s(ib);M_e=n(XNe,"STRONG",{});var syt=s(M_e);wBo=r(syt,"bert"),syt.forEach(t),ABo=r(XNe," \u2014 "),AX=n(XNe,"A",{href:!0});var lyt=s(AX);LBo=r(lyt,"BertForPreTraining"),lyt.forEach(t),yBo=r(XNe," (BERT model)"),XNe.forEach(t),xBo=i(O),db=n(O,"LI",{});var zNe=s(db);E_e=n(zNe,"STRONG",{});var iyt=s(E_e);$Bo=r(iyt,"big_bird"),iyt.forEach(t),kBo=r(zNe," \u2014 "),LX=n(zNe,"A",{href:!0});var dyt=s(LX);SBo=r(dyt,"BigBirdForPreTraining"),dyt.forEach(t),RBo=r(zNe," (BigBird model)"),zNe.forEach(t),PBo=i(O),cb=n(O,"LI",{});var QNe=s(cb);C_e=n(QNe,"STRONG",{});var cyt=s(C_e);BBo=r(cyt,"bloom"),cyt.forEach(t),IBo=r(QNe," \u2014 "),yX=n(QNe,"A",{href:!0});var myt=s(yX);NBo=r(myt,"BloomForCausalLM"),myt.forEach(t),qBo=r(QNe," (BLOOM model)"),QNe.forEach(t),jBo=i(O),mb=n(O,"LI",{});var WNe=s(mb);w_e=n(WNe,"STRONG",{});var fyt=s(w_e);DBo=r(fyt,"camembert"),fyt.forEach(t),GBo=r(WNe," \u2014 "),xX=n(WNe,"A",{href:!0});var gyt=s(xX);OBo=r(gyt,"CamembertForMaskedLM"),gyt.forEach(t),VBo=r(WNe," (CamemBERT model)"),WNe.forEach(t),XBo=i(O),fb=n(O,"LI",{});var UNe=s(fb);A_e=n(UNe,"STRONG",{});var hyt=s(A_e);zBo=r(hyt,"ctrl"),hyt.forEach(t),QBo=r(UNe," \u2014 "),$X=n(UNe,"A",{href:!0});var uyt=s($X);WBo=r(uyt,"CTRLLMHeadModel"),uyt.forEach(t),UBo=r(UNe," (CTRL model)"),UNe.forEach(t),HBo=i(O),gb=n(O,"LI",{});var HNe=s(gb);L_e=n(HNe,"STRONG",{});var pyt=s(L_e);JBo=r(pyt,"data2vec-text"),pyt.forEach(t),YBo=r(HNe," \u2014 "),kX=n(HNe,"A",{href:!0});var _yt=s(kX);KBo=r(_yt,"Data2VecTextForMaskedLM"),_yt.forEach(t),ZBo=r(HNe," (Data2VecText model)"),HNe.forEach(t),eIo=i(O),hb=n(O,"LI",{});var JNe=s(hb);y_e=n(JNe,"STRONG",{});var byt=s(y_e);oIo=r(byt,"deberta"),byt.forEach(t),rIo=r(JNe," \u2014 "),SX=n(JNe,"A",{href:!0});var vyt=s(SX);tIo=r(vyt,"DebertaForMaskedLM"),vyt.forEach(t),aIo=r(JNe," (DeBERTa model)"),JNe.forEach(t),nIo=i(O),ub=n(O,"LI",{});var YNe=s(ub);x_e=n(YNe,"STRONG",{});var Fyt=s(x_e);sIo=r(Fyt,"deberta-v2"),Fyt.forEach(t),lIo=r(YNe," \u2014 "),RX=n(YNe,"A",{href:!0});var Tyt=s(RX);iIo=r(Tyt,"DebertaV2ForMaskedLM"),Tyt.forEach(t),dIo=r(YNe," (DeBERTa-v2 model)"),YNe.forEach(t),cIo=i(O),pb=n(O,"LI",{});var KNe=s(pb);$_e=n(KNe,"STRONG",{});var Myt=s($_e);mIo=r(Myt,"distilbert"),Myt.forEach(t),fIo=r(KNe," \u2014 "),PX=n(KNe,"A",{href:!0});var Eyt=s(PX);gIo=r(Eyt,"DistilBertForMaskedLM"),Eyt.forEach(t),hIo=r(KNe," (DistilBERT model)"),KNe.forEach(t),uIo=i(O),_b=n(O,"LI",{});var ZNe=s(_b);k_e=n(ZNe,"STRONG",{});var Cyt=s(k_e);pIo=r(Cyt,"electra"),Cyt.forEach(t),_Io=r(ZNe," \u2014 "),BX=n(ZNe,"A",{href:!0});var wyt=s(BX);bIo=r(wyt,"ElectraForPreTraining"),wyt.forEach(t),vIo=r(ZNe," (ELECTRA model)"),ZNe.forEach(t),FIo=i(O),bb=n(O,"LI",{});var eqe=s(bb);S_e=n(eqe,"STRONG",{});var Ayt=s(S_e);TIo=r(Ayt,"ernie"),Ayt.forEach(t),MIo=r(eqe," \u2014 "),IX=n(eqe,"A",{href:!0});var Lyt=s(IX);EIo=r(Lyt,"ErnieForPreTraining"),Lyt.forEach(t),CIo=r(eqe," (ERNIE model)"),eqe.forEach(t),wIo=i(O),vb=n(O,"LI",{});var oqe=s(vb);R_e=n(oqe,"STRONG",{});var yyt=s(R_e);AIo=r(yyt,"flaubert"),yyt.forEach(t),LIo=r(oqe," \u2014 "),NX=n(oqe,"A",{href:!0});var xyt=s(NX);yIo=r(xyt,"FlaubertWithLMHeadModel"),xyt.forEach(t),xIo=r(oqe," (FlauBERT model)"),oqe.forEach(t),$Io=i(O),Fb=n(O,"LI",{});var rqe=s(Fb);P_e=n(rqe,"STRONG",{});var $yt=s(P_e);kIo=r($yt,"flava"),$yt.forEach(t),SIo=r(rqe," \u2014 "),qX=n(rqe,"A",{href:!0});var kyt=s(qX);RIo=r(kyt,"FlavaForPreTraining"),kyt.forEach(t),PIo=r(rqe," (FLAVA model)"),rqe.forEach(t),BIo=i(O),Tb=n(O,"LI",{});var tqe=s(Tb);B_e=n(tqe,"STRONG",{});var Syt=s(B_e);IIo=r(Syt,"fnet"),Syt.forEach(t),NIo=r(tqe," \u2014 "),jX=n(tqe,"A",{href:!0});var Ryt=s(jX);qIo=r(Ryt,"FNetForPreTraining"),Ryt.forEach(t),jIo=r(tqe," (FNet model)"),tqe.forEach(t),DIo=i(O),Mb=n(O,"LI",{});var aqe=s(Mb);I_e=n(aqe,"STRONG",{});var Pyt=s(I_e);GIo=r(Pyt,"fsmt"),Pyt.forEach(t),OIo=r(aqe," \u2014 "),DX=n(aqe,"A",{href:!0});var Byt=s(DX);VIo=r(Byt,"FSMTForConditionalGeneration"),Byt.forEach(t),XIo=r(aqe," (FairSeq Machine-Translation model)"),aqe.forEach(t),zIo=i(O),Eb=n(O,"LI",{});var nqe=s(Eb);N_e=n(nqe,"STRONG",{});var Iyt=s(N_e);QIo=r(Iyt,"funnel"),Iyt.forEach(t),WIo=r(nqe," \u2014 "),GX=n(nqe,"A",{href:!0});var Nyt=s(GX);UIo=r(Nyt,"FunnelForPreTraining"),Nyt.forEach(t),HIo=r(nqe," (Funnel Transformer model)"),nqe.forEach(t),JIo=i(O),Cb=n(O,"LI",{});var sqe=s(Cb);q_e=n(sqe,"STRONG",{});var qyt=s(q_e);YIo=r(qyt,"gpt2"),qyt.forEach(t),KIo=r(sqe," \u2014 "),OX=n(sqe,"A",{href:!0});var jyt=s(OX);ZIo=r(jyt,"GPT2LMHeadModel"),jyt.forEach(t),eNo=r(sqe," (OpenAI GPT-2 model)"),sqe.forEach(t),oNo=i(O),wb=n(O,"LI",{});var lqe=s(wb);j_e=n(lqe,"STRONG",{});var Dyt=s(j_e);rNo=r(Dyt,"ibert"),Dyt.forEach(t),tNo=r(lqe," \u2014 "),VX=n(lqe,"A",{href:!0});var Gyt=s(VX);aNo=r(Gyt,"IBertForMaskedLM"),Gyt.forEach(t),nNo=r(lqe," (I-BERT model)"),lqe.forEach(t),sNo=i(O),Ab=n(O,"LI",{});var iqe=s(Ab);D_e=n(iqe,"STRONG",{});var Oyt=s(D_e);lNo=r(Oyt,"layoutlm"),Oyt.forEach(t),iNo=r(iqe," \u2014 "),XX=n(iqe,"A",{href:!0});var Vyt=s(XX);dNo=r(Vyt,"LayoutLMForMaskedLM"),Vyt.forEach(t),cNo=r(iqe," (LayoutLM model)"),iqe.forEach(t),mNo=i(O),Lb=n(O,"LI",{});var dqe=s(Lb);G_e=n(dqe,"STRONG",{});var Xyt=s(G_e);fNo=r(Xyt,"longformer"),Xyt.forEach(t),gNo=r(dqe," \u2014 "),zX=n(dqe,"A",{href:!0});var zyt=s(zX);hNo=r(zyt,"LongformerForMaskedLM"),zyt.forEach(t),uNo=r(dqe," (Longformer model)"),dqe.forEach(t),pNo=i(O),yb=n(O,"LI",{});var cqe=s(yb);O_e=n(cqe,"STRONG",{});var Qyt=s(O_e);_No=r(Qyt,"luke"),Qyt.forEach(t),bNo=r(cqe," \u2014 "),QX=n(cqe,"A",{href:!0});var Wyt=s(QX);vNo=r(Wyt,"LukeForMaskedLM"),Wyt.forEach(t),FNo=r(cqe," (LUKE model)"),cqe.forEach(t),TNo=i(O),xb=n(O,"LI",{});var mqe=s(xb);V_e=n(mqe,"STRONG",{});var Uyt=s(V_e);MNo=r(Uyt,"lxmert"),Uyt.forEach(t),ENo=r(mqe," \u2014 "),WX=n(mqe,"A",{href:!0});var Hyt=s(WX);CNo=r(Hyt,"LxmertForPreTraining"),Hyt.forEach(t),wNo=r(mqe," (LXMERT model)"),mqe.forEach(t),ANo=i(O),$b=n(O,"LI",{});var fqe=s($b);X_e=n(fqe,"STRONG",{});var Jyt=s(X_e);LNo=r(Jyt,"megatron-bert"),Jyt.forEach(t),yNo=r(fqe," \u2014 "),UX=n(fqe,"A",{href:!0});var Yyt=s(UX);xNo=r(Yyt,"MegatronBertForPreTraining"),Yyt.forEach(t),$No=r(fqe," (Megatron-BERT model)"),fqe.forEach(t),kNo=i(O),kb=n(O,"LI",{});var gqe=s(kb);z_e=n(gqe,"STRONG",{});var Kyt=s(z_e);SNo=r(Kyt,"mobilebert"),Kyt.forEach(t),RNo=r(gqe," \u2014 "),HX=n(gqe,"A",{href:!0});var Zyt=s(HX);PNo=r(Zyt,"MobileBertForPreTraining"),Zyt.forEach(t),BNo=r(gqe," (MobileBERT model)"),gqe.forEach(t),INo=i(O),Sb=n(O,"LI",{});var hqe=s(Sb);Q_e=n(hqe,"STRONG",{});var e8t=s(Q_e);NNo=r(e8t,"mpnet"),e8t.forEach(t),qNo=r(hqe," \u2014 "),JX=n(hqe,"A",{href:!0});var o8t=s(JX);jNo=r(o8t,"MPNetForMaskedLM"),o8t.forEach(t),DNo=r(hqe," (MPNet model)"),hqe.forEach(t),GNo=i(O),Rb=n(O,"LI",{});var uqe=s(Rb);W_e=n(uqe,"STRONG",{});var r8t=s(W_e);ONo=r(r8t,"mvp"),r8t.forEach(t),VNo=r(uqe," \u2014 "),YX=n(uqe,"A",{href:!0});var t8t=s(YX);XNo=r(t8t,"MvpForConditionalGeneration"),t8t.forEach(t),zNo=r(uqe," (MVP model)"),uqe.forEach(t),QNo=i(O),Pb=n(O,"LI",{});var pqe=s(Pb);U_e=n(pqe,"STRONG",{});var a8t=s(U_e);WNo=r(a8t,"nezha"),a8t.forEach(t),UNo=r(pqe," \u2014 "),KX=n(pqe,"A",{href:!0});var n8t=s(KX);HNo=r(n8t,"NezhaForPreTraining"),n8t.forEach(t),JNo=r(pqe," (Nezha model)"),pqe.forEach(t),YNo=i(O),Bb=n(O,"LI",{});var _qe=s(Bb);H_e=n(_qe,"STRONG",{});var s8t=s(H_e);KNo=r(s8t,"openai-gpt"),s8t.forEach(t),ZNo=r(_qe," \u2014 "),ZX=n(_qe,"A",{href:!0});var l8t=s(ZX);eqo=r(l8t,"OpenAIGPTLMHeadModel"),l8t.forEach(t),oqo=r(_qe," (OpenAI GPT model)"),_qe.forEach(t),rqo=i(O),Ib=n(O,"LI",{});var bqe=s(Ib);J_e=n(bqe,"STRONG",{});var i8t=s(J_e);tqo=r(i8t,"retribert"),i8t.forEach(t),aqo=r(bqe," \u2014 "),ez=n(bqe,"A",{href:!0});var d8t=s(ez);nqo=r(d8t,"RetriBertModel"),d8t.forEach(t),sqo=r(bqe," (RetriBERT model)"),bqe.forEach(t),lqo=i(O),Nb=n(O,"LI",{});var vqe=s(Nb);Y_e=n(vqe,"STRONG",{});var c8t=s(Y_e);iqo=r(c8t,"roberta"),c8t.forEach(t),dqo=r(vqe," \u2014 "),oz=n(vqe,"A",{href:!0});var m8t=s(oz);cqo=r(m8t,"RobertaForMaskedLM"),m8t.forEach(t),mqo=r(vqe," (RoBERTa model)"),vqe.forEach(t),fqo=i(O),qb=n(O,"LI",{});var Fqe=s(qb);K_e=n(Fqe,"STRONG",{});var f8t=s(K_e);gqo=r(f8t,"splinter"),f8t.forEach(t),hqo=r(Fqe," \u2014 "),rz=n(Fqe,"A",{href:!0});var g8t=s(rz);uqo=r(g8t,"SplinterForPreTraining"),g8t.forEach(t),pqo=r(Fqe," (Splinter model)"),Fqe.forEach(t),_qo=i(O),jb=n(O,"LI",{});var Tqe=s(jb);Z_e=n(Tqe,"STRONG",{});var h8t=s(Z_e);bqo=r(h8t,"squeezebert"),h8t.forEach(t),vqo=r(Tqe," \u2014 "),tz=n(Tqe,"A",{href:!0});var u8t=s(tz);Fqo=r(u8t,"SqueezeBertForMaskedLM"),u8t.forEach(t),Tqo=r(Tqe," (SqueezeBERT model)"),Tqe.forEach(t),Mqo=i(O),Db=n(O,"LI",{});var Mqe=s(Db);e2e=n(Mqe,"STRONG",{});var p8t=s(e2e);Eqo=r(p8t,"t5"),p8t.forEach(t),Cqo=r(Mqe," \u2014 "),az=n(Mqe,"A",{href:!0});var _8t=s(az);wqo=r(_8t,"T5ForConditionalGeneration"),_8t.forEach(t),Aqo=r(Mqe," (T5 model)"),Mqe.forEach(t),Lqo=i(O),Gb=n(O,"LI",{});var Eqe=s(Gb);o2e=n(Eqe,"STRONG",{});var b8t=s(o2e);yqo=r(b8t,"tapas"),b8t.forEach(t),xqo=r(Eqe," \u2014 "),nz=n(Eqe,"A",{href:!0});var v8t=s(nz);$qo=r(v8t,"TapasForMaskedLM"),v8t.forEach(t),kqo=r(Eqe," (TAPAS model)"),Eqe.forEach(t),Sqo=i(O),Ob=n(O,"LI",{});var Cqe=s(Ob);r2e=n(Cqe,"STRONG",{});var F8t=s(r2e);Rqo=r(F8t,"transfo-xl"),F8t.forEach(t),Pqo=r(Cqe," \u2014 "),sz=n(Cqe,"A",{href:!0});var T8t=s(sz);Bqo=r(T8t,"TransfoXLLMHeadModel"),T8t.forEach(t),Iqo=r(Cqe," (Transformer-XL model)"),Cqe.forEach(t),Nqo=i(O),Vb=n(O,"LI",{});var wqe=s(Vb);t2e=n(wqe,"STRONG",{});var M8t=s(t2e);qqo=r(M8t,"unispeech"),M8t.forEach(t),jqo=r(wqe," \u2014 "),lz=n(wqe,"A",{href:!0});var E8t=s(lz);Dqo=r(E8t,"UniSpeechForPreTraining"),E8t.forEach(t),Gqo=r(wqe," (UniSpeech model)"),wqe.forEach(t),Oqo=i(O),Xb=n(O,"LI",{});var Aqe=s(Xb);a2e=n(Aqe,"STRONG",{});var C8t=s(a2e);Vqo=r(C8t,"unispeech-sat"),C8t.forEach(t),Xqo=r(Aqe," \u2014 "),iz=n(Aqe,"A",{href:!0});var w8t=s(iz);zqo=r(w8t,"UniSpeechSatForPreTraining"),w8t.forEach(t),Qqo=r(Aqe," (UniSpeechSat model)"),Aqe.forEach(t),Wqo=i(O),zb=n(O,"LI",{});var Lqe=s(zb);n2e=n(Lqe,"STRONG",{});var A8t=s(n2e);Uqo=r(A8t,"videomae"),A8t.forEach(t),Hqo=r(Lqe," \u2014 "),dz=n(Lqe,"A",{href:!0});var L8t=s(dz);Jqo=r(L8t,"VideoMAEForPreTraining"),L8t.forEach(t),Yqo=r(Lqe," (VideoMAE model)"),Lqe.forEach(t),Kqo=i(O),Qb=n(O,"LI",{});var yqe=s(Qb);s2e=n(yqe,"STRONG",{});var y8t=s(s2e);Zqo=r(y8t,"visual_bert"),y8t.forEach(t),ejo=r(yqe," \u2014 "),cz=n(yqe,"A",{href:!0});var x8t=s(cz);ojo=r(x8t,"VisualBertForPreTraining"),x8t.forEach(t),rjo=r(yqe," (VisualBERT model)"),yqe.forEach(t),tjo=i(O),Wb=n(O,"LI",{});var xqe=s(Wb);l2e=n(xqe,"STRONG",{});var $8t=s(l2e);ajo=r($8t,"vit_mae"),$8t.forEach(t),njo=r(xqe," \u2014 "),mz=n(xqe,"A",{href:!0});var k8t=s(mz);sjo=r(k8t,"ViTMAEForPreTraining"),k8t.forEach(t),ljo=r(xqe," (ViTMAE model)"),xqe.forEach(t),ijo=i(O),Ub=n(O,"LI",{});var $qe=s(Ub);i2e=n($qe,"STRONG",{});var S8t=s(i2e);djo=r(S8t,"wav2vec2"),S8t.forEach(t),cjo=r($qe," \u2014 "),fz=n($qe,"A",{href:!0});var R8t=s(fz);mjo=r(R8t,"Wav2Vec2ForPreTraining"),R8t.forEach(t),fjo=r($qe," (Wav2Vec2 model)"),$qe.forEach(t),gjo=i(O),Hb=n(O,"LI",{});var kqe=s(Hb);d2e=n(kqe,"STRONG",{});var P8t=s(d2e);hjo=r(P8t,"wav2vec2-conformer"),P8t.forEach(t),ujo=r(kqe," \u2014 "),gz=n(kqe,"A",{href:!0});var B8t=s(gz);pjo=r(B8t,"Wav2Vec2ConformerForPreTraining"),B8t.forEach(t),_jo=r(kqe," (Wav2Vec2-Conformer model)"),kqe.forEach(t),bjo=i(O),Jb=n(O,"LI",{});var Sqe=s(Jb);c2e=n(Sqe,"STRONG",{});var I8t=s(c2e);vjo=r(I8t,"xlm"),I8t.forEach(t),Fjo=r(Sqe," \u2014 "),hz=n(Sqe,"A",{href:!0});var N8t=s(hz);Tjo=r(N8t,"XLMWithLMHeadModel"),N8t.forEach(t),Mjo=r(Sqe," (XLM model)"),Sqe.forEach(t),Ejo=i(O),Yb=n(O,"LI",{});var Rqe=s(Yb);m2e=n(Rqe,"STRONG",{});var q8t=s(m2e);Cjo=r(q8t,"xlm-roberta"),q8t.forEach(t),wjo=r(Rqe," \u2014 "),uz=n(Rqe,"A",{href:!0});var j8t=s(uz);Ajo=r(j8t,"XLMRobertaForMaskedLM"),j8t.forEach(t),Ljo=r(Rqe," (XLM-RoBERTa model)"),Rqe.forEach(t),yjo=i(O),Kb=n(O,"LI",{});var Pqe=s(Kb);f2e=n(Pqe,"STRONG",{});var D8t=s(f2e);xjo=r(D8t,"xlm-roberta-xl"),D8t.forEach(t),$jo=r(Pqe," \u2014 "),pz=n(Pqe,"A",{href:!0});var G8t=s(pz);kjo=r(G8t,"XLMRobertaXLForMaskedLM"),G8t.forEach(t),Sjo=r(Pqe," (XLM-RoBERTa-XL model)"),Pqe.forEach(t),Rjo=i(O),Zb=n(O,"LI",{});var Bqe=s(Zb);g2e=n(Bqe,"STRONG",{});var O8t=s(g2e);Pjo=r(O8t,"xlnet"),O8t.forEach(t),Bjo=r(Bqe," \u2014 "),_z=n(Bqe,"A",{href:!0});var V8t=s(_z);Ijo=r(V8t,"XLNetLMHeadModel"),V8t.forEach(t),Njo=r(Bqe," (XLNet model)"),Bqe.forEach(t),O.forEach(t),qjo=i(Ta),e1=n(Ta,"P",{});var Iqe=s(e1);jjo=r(Iqe,"The model is set in evaluation mode by default using "),h2e=n(Iqe,"CODE",{});var X8t=s(h2e);Djo=r(X8t,"model.eval()"),X8t.forEach(t),Gjo=r(Iqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=n(Iqe,"CODE",{});var z8t=s(u2e);Ojo=r(z8t,"model.train()"),z8t.forEach(t),Iqe.forEach(t),Vjo=i(Ta),T(o1.$$.fragment,Ta),Ta.forEach(t),Al.forEach(t),UYe=i(m),Md=n(m,"H2",{class:!0});var ieo=s(Md);r1=n(ieo,"A",{id:!0,class:!0,href:!0});var Q8t=s(r1);p2e=n(Q8t,"SPAN",{});var W8t=s(p2e);T(nx.$$.fragment,W8t),W8t.forEach(t),Q8t.forEach(t),Xjo=i(ieo),_2e=n(ieo,"SPAN",{});var U8t=s(_2e);zjo=r(U8t,"AutoModelForCausalLM"),U8t.forEach(t),ieo.forEach(t),HYe=i(m),Io=n(m,"DIV",{class:!0});var Ll=s(Io);T(sx.$$.fragment,Ll),Qjo=i(Ll),Ed=n(Ll,"P",{});var Yse=s(Ed);Wjo=r(Yse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),bz=n(Yse,"A",{href:!0});var H8t=s(bz);Ujo=r(H8t,"from_pretrained()"),H8t.forEach(t),Hjo=r(Yse," class method or the "),vz=n(Yse,"A",{href:!0});var J8t=s(vz);Jjo=r(J8t,"from_config()"),J8t.forEach(t),Yjo=r(Yse,` class
method.`),Yse.forEach(t),Kjo=i(Ll),lx=n(Ll,"P",{});var deo=s(lx);Zjo=r(deo,"This class cannot be instantiated directly using "),b2e=n(deo,"CODE",{});var Y8t=s(b2e);eDo=r(Y8t,"__init__()"),Y8t.forEach(t),oDo=r(deo," (throws an error)."),deo.forEach(t),rDo=i(Ll),vt=n(Ll,"DIV",{class:!0});var My=s(vt);T(ix.$$.fragment,My),tDo=i(My),v2e=n(My,"P",{});var K8t=s(v2e);aDo=r(K8t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),K8t.forEach(t),nDo=i(My),Cd=n(My,"P",{});var Kse=s(Cd);sDo=r(Kse,`Note:
Loading a model from its configuration file does `),F2e=n(Kse,"STRONG",{});var Z8t=s(F2e);lDo=r(Z8t,"not"),Z8t.forEach(t),iDo=r(Kse,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(Kse,"A",{href:!0});var e9t=s(Fz);dDo=r(e9t,"from_pretrained()"),e9t.forEach(t),cDo=r(Kse," to load the model weights."),Kse.forEach(t),mDo=i(My),T(t1.$$.fragment,My),My.forEach(t),fDo=i(Ll),oo=n(Ll,"DIV",{class:!0});var Ma=s(oo);T(dx.$$.fragment,Ma),gDo=i(Ma),T2e=n(Ma,"P",{});var o9t=s(T2e);hDo=r(o9t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),o9t.forEach(t),uDo=i(Ma),Ka=n(Ma,"P",{});var Ey=s(Ka);pDo=r(Ey,"The model class to instantiate is selected based on the "),M2e=n(Ey,"CODE",{});var r9t=s(M2e);_Do=r(r9t,"model_type"),r9t.forEach(t),bDo=r(Ey,` property of the config object (either
passed as an argument or loaded from `),E2e=n(Ey,"CODE",{});var t9t=s(E2e);vDo=r(t9t,"pretrained_model_name_or_path"),t9t.forEach(t),FDo=r(Ey,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C2e=n(Ey,"CODE",{});var a9t=s(C2e);TDo=r(a9t,"pretrained_model_name_or_path"),a9t.forEach(t),MDo=r(Ey,":"),Ey.forEach(t),EDo=i(Ma),z=n(Ma,"UL",{});var Q=s(z);a1=n(Q,"LI",{});var Nqe=s(a1);w2e=n(Nqe,"STRONG",{});var n9t=s(w2e);CDo=r(n9t,"bart"),n9t.forEach(t),wDo=r(Nqe," \u2014 "),Tz=n(Nqe,"A",{href:!0});var s9t=s(Tz);ADo=r(s9t,"BartForCausalLM"),s9t.forEach(t),LDo=r(Nqe," (BART model)"),Nqe.forEach(t),yDo=i(Q),n1=n(Q,"LI",{});var qqe=s(n1);A2e=n(qqe,"STRONG",{});var l9t=s(A2e);xDo=r(l9t,"bert"),l9t.forEach(t),$Do=r(qqe," \u2014 "),Mz=n(qqe,"A",{href:!0});var i9t=s(Mz);kDo=r(i9t,"BertLMHeadModel"),i9t.forEach(t),SDo=r(qqe," (BERT model)"),qqe.forEach(t),RDo=i(Q),s1=n(Q,"LI",{});var jqe=s(s1);L2e=n(jqe,"STRONG",{});var d9t=s(L2e);PDo=r(d9t,"bert-generation"),d9t.forEach(t),BDo=r(jqe," \u2014 "),Ez=n(jqe,"A",{href:!0});var c9t=s(Ez);IDo=r(c9t,"BertGenerationDecoder"),c9t.forEach(t),NDo=r(jqe," (Bert Generation model)"),jqe.forEach(t),qDo=i(Q),l1=n(Q,"LI",{});var Dqe=s(l1);y2e=n(Dqe,"STRONG",{});var m9t=s(y2e);jDo=r(m9t,"big_bird"),m9t.forEach(t),DDo=r(Dqe," \u2014 "),Cz=n(Dqe,"A",{href:!0});var f9t=s(Cz);GDo=r(f9t,"BigBirdForCausalLM"),f9t.forEach(t),ODo=r(Dqe," (BigBird model)"),Dqe.forEach(t),VDo=i(Q),i1=n(Q,"LI",{});var Gqe=s(i1);x2e=n(Gqe,"STRONG",{});var g9t=s(x2e);XDo=r(g9t,"bigbird_pegasus"),g9t.forEach(t),zDo=r(Gqe," \u2014 "),wz=n(Gqe,"A",{href:!0});var h9t=s(wz);QDo=r(h9t,"BigBirdPegasusForCausalLM"),h9t.forEach(t),WDo=r(Gqe," (BigBird-Pegasus model)"),Gqe.forEach(t),UDo=i(Q),d1=n(Q,"LI",{});var Oqe=s(d1);$2e=n(Oqe,"STRONG",{});var u9t=s($2e);HDo=r(u9t,"blenderbot"),u9t.forEach(t),JDo=r(Oqe," \u2014 "),Az=n(Oqe,"A",{href:!0});var p9t=s(Az);YDo=r(p9t,"BlenderbotForCausalLM"),p9t.forEach(t),KDo=r(Oqe," (Blenderbot model)"),Oqe.forEach(t),ZDo=i(Q),c1=n(Q,"LI",{});var Vqe=s(c1);k2e=n(Vqe,"STRONG",{});var _9t=s(k2e);eGo=r(_9t,"blenderbot-small"),_9t.forEach(t),oGo=r(Vqe," \u2014 "),Lz=n(Vqe,"A",{href:!0});var b9t=s(Lz);rGo=r(b9t,"BlenderbotSmallForCausalLM"),b9t.forEach(t),tGo=r(Vqe," (BlenderbotSmall model)"),Vqe.forEach(t),aGo=i(Q),m1=n(Q,"LI",{});var Xqe=s(m1);S2e=n(Xqe,"STRONG",{});var v9t=s(S2e);nGo=r(v9t,"bloom"),v9t.forEach(t),sGo=r(Xqe," \u2014 "),yz=n(Xqe,"A",{href:!0});var F9t=s(yz);lGo=r(F9t,"BloomForCausalLM"),F9t.forEach(t),iGo=r(Xqe," (BLOOM model)"),Xqe.forEach(t),dGo=i(Q),f1=n(Q,"LI",{});var zqe=s(f1);R2e=n(zqe,"STRONG",{});var T9t=s(R2e);cGo=r(T9t,"camembert"),T9t.forEach(t),mGo=r(zqe," \u2014 "),xz=n(zqe,"A",{href:!0});var M9t=s(xz);fGo=r(M9t,"CamembertForCausalLM"),M9t.forEach(t),gGo=r(zqe," (CamemBERT model)"),zqe.forEach(t),hGo=i(Q),g1=n(Q,"LI",{});var Qqe=s(g1);P2e=n(Qqe,"STRONG",{});var E9t=s(P2e);uGo=r(E9t,"codegen"),E9t.forEach(t),pGo=r(Qqe," \u2014 "),$z=n(Qqe,"A",{href:!0});var C9t=s($z);_Go=r(C9t,"CodeGenForCausalLM"),C9t.forEach(t),bGo=r(Qqe," (CodeGen model)"),Qqe.forEach(t),vGo=i(Q),h1=n(Q,"LI",{});var Wqe=s(h1);B2e=n(Wqe,"STRONG",{});var w9t=s(B2e);FGo=r(w9t,"ctrl"),w9t.forEach(t),TGo=r(Wqe," \u2014 "),kz=n(Wqe,"A",{href:!0});var A9t=s(kz);MGo=r(A9t,"CTRLLMHeadModel"),A9t.forEach(t),EGo=r(Wqe," (CTRL model)"),Wqe.forEach(t),CGo=i(Q),u1=n(Q,"LI",{});var Uqe=s(u1);I2e=n(Uqe,"STRONG",{});var L9t=s(I2e);wGo=r(L9t,"data2vec-text"),L9t.forEach(t),AGo=r(Uqe," \u2014 "),Sz=n(Uqe,"A",{href:!0});var y9t=s(Sz);LGo=r(y9t,"Data2VecTextForCausalLM"),y9t.forEach(t),yGo=r(Uqe," (Data2VecText model)"),Uqe.forEach(t),xGo=i(Q),p1=n(Q,"LI",{});var Hqe=s(p1);N2e=n(Hqe,"STRONG",{});var x9t=s(N2e);$Go=r(x9t,"electra"),x9t.forEach(t),kGo=r(Hqe," \u2014 "),Rz=n(Hqe,"A",{href:!0});var $9t=s(Rz);SGo=r($9t,"ElectraForCausalLM"),$9t.forEach(t),RGo=r(Hqe," (ELECTRA model)"),Hqe.forEach(t),PGo=i(Q),_1=n(Q,"LI",{});var Jqe=s(_1);q2e=n(Jqe,"STRONG",{});var k9t=s(q2e);BGo=r(k9t,"ernie"),k9t.forEach(t),IGo=r(Jqe," \u2014 "),Pz=n(Jqe,"A",{href:!0});var S9t=s(Pz);NGo=r(S9t,"ErnieForCausalLM"),S9t.forEach(t),qGo=r(Jqe," (ERNIE model)"),Jqe.forEach(t),jGo=i(Q),b1=n(Q,"LI",{});var Yqe=s(b1);j2e=n(Yqe,"STRONG",{});var R9t=s(j2e);DGo=r(R9t,"gpt2"),R9t.forEach(t),GGo=r(Yqe," \u2014 "),Bz=n(Yqe,"A",{href:!0});var P9t=s(Bz);OGo=r(P9t,"GPT2LMHeadModel"),P9t.forEach(t),VGo=r(Yqe," (OpenAI GPT-2 model)"),Yqe.forEach(t),XGo=i(Q),v1=n(Q,"LI",{});var Kqe=s(v1);D2e=n(Kqe,"STRONG",{});var B9t=s(D2e);zGo=r(B9t,"gpt_neo"),B9t.forEach(t),QGo=r(Kqe," \u2014 "),Iz=n(Kqe,"A",{href:!0});var I9t=s(Iz);WGo=r(I9t,"GPTNeoForCausalLM"),I9t.forEach(t),UGo=r(Kqe," (GPT Neo model)"),Kqe.forEach(t),HGo=i(Q),F1=n(Q,"LI",{});var Zqe=s(F1);G2e=n(Zqe,"STRONG",{});var N9t=s(G2e);JGo=r(N9t,"gpt_neox"),N9t.forEach(t),YGo=r(Zqe," \u2014 "),Nz=n(Zqe,"A",{href:!0});var q9t=s(Nz);KGo=r(q9t,"GPTNeoXForCausalLM"),q9t.forEach(t),ZGo=r(Zqe," (GPT NeoX model)"),Zqe.forEach(t),eOo=i(Q),T1=n(Q,"LI",{});var eje=s(T1);O2e=n(eje,"STRONG",{});var j9t=s(O2e);oOo=r(j9t,"gptj"),j9t.forEach(t),rOo=r(eje," \u2014 "),qz=n(eje,"A",{href:!0});var D9t=s(qz);tOo=r(D9t,"GPTJForCausalLM"),D9t.forEach(t),aOo=r(eje," (GPT-J model)"),eje.forEach(t),nOo=i(Q),M1=n(Q,"LI",{});var oje=s(M1);V2e=n(oje,"STRONG",{});var G9t=s(V2e);sOo=r(G9t,"marian"),G9t.forEach(t),lOo=r(oje," \u2014 "),jz=n(oje,"A",{href:!0});var O9t=s(jz);iOo=r(O9t,"MarianForCausalLM"),O9t.forEach(t),dOo=r(oje," (Marian model)"),oje.forEach(t),cOo=i(Q),E1=n(Q,"LI",{});var rje=s(E1);X2e=n(rje,"STRONG",{});var V9t=s(X2e);mOo=r(V9t,"mbart"),V9t.forEach(t),fOo=r(rje," \u2014 "),Dz=n(rje,"A",{href:!0});var X9t=s(Dz);gOo=r(X9t,"MBartForCausalLM"),X9t.forEach(t),hOo=r(rje," (mBART model)"),rje.forEach(t),uOo=i(Q),C1=n(Q,"LI",{});var tje=s(C1);z2e=n(tje,"STRONG",{});var z9t=s(z2e);pOo=r(z9t,"megatron-bert"),z9t.forEach(t),_Oo=r(tje," \u2014 "),Gz=n(tje,"A",{href:!0});var Q9t=s(Gz);bOo=r(Q9t,"MegatronBertForCausalLM"),Q9t.forEach(t),vOo=r(tje," (Megatron-BERT model)"),tje.forEach(t),FOo=i(Q),w1=n(Q,"LI",{});var aje=s(w1);Q2e=n(aje,"STRONG",{});var W9t=s(Q2e);TOo=r(W9t,"mvp"),W9t.forEach(t),MOo=r(aje," \u2014 "),Oz=n(aje,"A",{href:!0});var U9t=s(Oz);EOo=r(U9t,"MvpForCausalLM"),U9t.forEach(t),COo=r(aje," (MVP model)"),aje.forEach(t),wOo=i(Q),A1=n(Q,"LI",{});var nje=s(A1);W2e=n(nje,"STRONG",{});var H9t=s(W2e);AOo=r(H9t,"openai-gpt"),H9t.forEach(t),LOo=r(nje," \u2014 "),Vz=n(nje,"A",{href:!0});var J9t=s(Vz);yOo=r(J9t,"OpenAIGPTLMHeadModel"),J9t.forEach(t),xOo=r(nje," (OpenAI GPT model)"),nje.forEach(t),$Oo=i(Q),L1=n(Q,"LI",{});var sje=s(L1);U2e=n(sje,"STRONG",{});var Y9t=s(U2e);kOo=r(Y9t,"opt"),Y9t.forEach(t),SOo=r(sje," \u2014 "),Xz=n(sje,"A",{href:!0});var K9t=s(Xz);ROo=r(K9t,"OPTForCausalLM"),K9t.forEach(t),POo=r(sje," (OPT model)"),sje.forEach(t),BOo=i(Q),y1=n(Q,"LI",{});var lje=s(y1);H2e=n(lje,"STRONG",{});var Z9t=s(H2e);IOo=r(Z9t,"pegasus"),Z9t.forEach(t),NOo=r(lje," \u2014 "),zz=n(lje,"A",{href:!0});var ext=s(zz);qOo=r(ext,"PegasusForCausalLM"),ext.forEach(t),jOo=r(lje," (Pegasus model)"),lje.forEach(t),DOo=i(Q),x1=n(Q,"LI",{});var ije=s(x1);J2e=n(ije,"STRONG",{});var oxt=s(J2e);GOo=r(oxt,"plbart"),oxt.forEach(t),OOo=r(ije," \u2014 "),Qz=n(ije,"A",{href:!0});var rxt=s(Qz);VOo=r(rxt,"PLBartForCausalLM"),rxt.forEach(t),XOo=r(ije," (PLBart model)"),ije.forEach(t),zOo=i(Q),$1=n(Q,"LI",{});var dje=s($1);Y2e=n(dje,"STRONG",{});var txt=s(Y2e);QOo=r(txt,"prophetnet"),txt.forEach(t),WOo=r(dje," \u2014 "),Wz=n(dje,"A",{href:!0});var axt=s(Wz);UOo=r(axt,"ProphetNetForCausalLM"),axt.forEach(t),HOo=r(dje," (ProphetNet model)"),dje.forEach(t),JOo=i(Q),k1=n(Q,"LI",{});var cje=s(k1);K2e=n(cje,"STRONG",{});var nxt=s(K2e);YOo=r(nxt,"qdqbert"),nxt.forEach(t),KOo=r(cje," \u2014 "),Uz=n(cje,"A",{href:!0});var sxt=s(Uz);ZOo=r(sxt,"QDQBertLMHeadModel"),sxt.forEach(t),eVo=r(cje," (QDQBert model)"),cje.forEach(t),oVo=i(Q),S1=n(Q,"LI",{});var mje=s(S1);Z2e=n(mje,"STRONG",{});var lxt=s(Z2e);rVo=r(lxt,"reformer"),lxt.forEach(t),tVo=r(mje," \u2014 "),Hz=n(mje,"A",{href:!0});var ixt=s(Hz);aVo=r(ixt,"ReformerModelWithLMHead"),ixt.forEach(t),nVo=r(mje," (Reformer model)"),mje.forEach(t),sVo=i(Q),R1=n(Q,"LI",{});var fje=s(R1);ebe=n(fje,"STRONG",{});var dxt=s(ebe);lVo=r(dxt,"rembert"),dxt.forEach(t),iVo=r(fje," \u2014 "),Jz=n(fje,"A",{href:!0});var cxt=s(Jz);dVo=r(cxt,"RemBertForCausalLM"),cxt.forEach(t),cVo=r(fje," (RemBERT model)"),fje.forEach(t),mVo=i(Q),P1=n(Q,"LI",{});var gje=s(P1);obe=n(gje,"STRONG",{});var mxt=s(obe);fVo=r(mxt,"roberta"),mxt.forEach(t),gVo=r(gje," \u2014 "),Yz=n(gje,"A",{href:!0});var fxt=s(Yz);hVo=r(fxt,"RobertaForCausalLM"),fxt.forEach(t),uVo=r(gje," (RoBERTa model)"),gje.forEach(t),pVo=i(Q),B1=n(Q,"LI",{});var hje=s(B1);rbe=n(hje,"STRONG",{});var gxt=s(rbe);_Vo=r(gxt,"roformer"),gxt.forEach(t),bVo=r(hje," \u2014 "),Kz=n(hje,"A",{href:!0});var hxt=s(Kz);vVo=r(hxt,"RoFormerForCausalLM"),hxt.forEach(t),FVo=r(hje," (RoFormer model)"),hje.forEach(t),TVo=i(Q),I1=n(Q,"LI",{});var uje=s(I1);tbe=n(uje,"STRONG",{});var uxt=s(tbe);MVo=r(uxt,"speech_to_text_2"),uxt.forEach(t),EVo=r(uje," \u2014 "),Zz=n(uje,"A",{href:!0});var pxt=s(Zz);CVo=r(pxt,"Speech2Text2ForCausalLM"),pxt.forEach(t),wVo=r(uje," (Speech2Text2 model)"),uje.forEach(t),AVo=i(Q),N1=n(Q,"LI",{});var pje=s(N1);abe=n(pje,"STRONG",{});var _xt=s(abe);LVo=r(_xt,"transfo-xl"),_xt.forEach(t),yVo=r(pje," \u2014 "),eQ=n(pje,"A",{href:!0});var bxt=s(eQ);xVo=r(bxt,"TransfoXLLMHeadModel"),bxt.forEach(t),$Vo=r(pje," (Transformer-XL model)"),pje.forEach(t),kVo=i(Q),q1=n(Q,"LI",{});var _je=s(q1);nbe=n(_je,"STRONG",{});var vxt=s(nbe);SVo=r(vxt,"trocr"),vxt.forEach(t),RVo=r(_je," \u2014 "),oQ=n(_je,"A",{href:!0});var Fxt=s(oQ);PVo=r(Fxt,"TrOCRForCausalLM"),Fxt.forEach(t),BVo=r(_je," (TrOCR model)"),_je.forEach(t),IVo=i(Q),j1=n(Q,"LI",{});var bje=s(j1);sbe=n(bje,"STRONG",{});var Txt=s(sbe);NVo=r(Txt,"xglm"),Txt.forEach(t),qVo=r(bje," \u2014 "),rQ=n(bje,"A",{href:!0});var Mxt=s(rQ);jVo=r(Mxt,"XGLMForCausalLM"),Mxt.forEach(t),DVo=r(bje," (XGLM model)"),bje.forEach(t),GVo=i(Q),D1=n(Q,"LI",{});var vje=s(D1);lbe=n(vje,"STRONG",{});var Ext=s(lbe);OVo=r(Ext,"xlm"),Ext.forEach(t),VVo=r(vje," \u2014 "),tQ=n(vje,"A",{href:!0});var Cxt=s(tQ);XVo=r(Cxt,"XLMWithLMHeadModel"),Cxt.forEach(t),zVo=r(vje," (XLM model)"),vje.forEach(t),QVo=i(Q),G1=n(Q,"LI",{});var Fje=s(G1);ibe=n(Fje,"STRONG",{});var wxt=s(ibe);WVo=r(wxt,"xlm-prophetnet"),wxt.forEach(t),UVo=r(Fje," \u2014 "),aQ=n(Fje,"A",{href:!0});var Axt=s(aQ);HVo=r(Axt,"XLMProphetNetForCausalLM"),Axt.forEach(t),JVo=r(Fje," (XLM-ProphetNet model)"),Fje.forEach(t),YVo=i(Q),O1=n(Q,"LI",{});var Tje=s(O1);dbe=n(Tje,"STRONG",{});var Lxt=s(dbe);KVo=r(Lxt,"xlm-roberta"),Lxt.forEach(t),ZVo=r(Tje," \u2014 "),nQ=n(Tje,"A",{href:!0});var yxt=s(nQ);eXo=r(yxt,"XLMRobertaForCausalLM"),yxt.forEach(t),oXo=r(Tje," (XLM-RoBERTa model)"),Tje.forEach(t),rXo=i(Q),V1=n(Q,"LI",{});var Mje=s(V1);cbe=n(Mje,"STRONG",{});var xxt=s(cbe);tXo=r(xxt,"xlm-roberta-xl"),xxt.forEach(t),aXo=r(Mje," \u2014 "),sQ=n(Mje,"A",{href:!0});var $xt=s(sQ);nXo=r($xt,"XLMRobertaXLForCausalLM"),$xt.forEach(t),sXo=r(Mje," (XLM-RoBERTa-XL model)"),Mje.forEach(t),lXo=i(Q),X1=n(Q,"LI",{});var Eje=s(X1);mbe=n(Eje,"STRONG",{});var kxt=s(mbe);iXo=r(kxt,"xlnet"),kxt.forEach(t),dXo=r(Eje," \u2014 "),lQ=n(Eje,"A",{href:!0});var Sxt=s(lQ);cXo=r(Sxt,"XLNetLMHeadModel"),Sxt.forEach(t),mXo=r(Eje," (XLNet model)"),Eje.forEach(t),Q.forEach(t),fXo=i(Ma),z1=n(Ma,"P",{});var Cje=s(z1);gXo=r(Cje,"The model is set in evaluation mode by default using "),fbe=n(Cje,"CODE",{});var Rxt=s(fbe);hXo=r(Rxt,"model.eval()"),Rxt.forEach(t),uXo=r(Cje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gbe=n(Cje,"CODE",{});var Pxt=s(gbe);pXo=r(Pxt,"model.train()"),Pxt.forEach(t),Cje.forEach(t),_Xo=i(Ma),T(Q1.$$.fragment,Ma),Ma.forEach(t),Ll.forEach(t),JYe=i(m),wd=n(m,"H2",{class:!0});var ceo=s(wd);W1=n(ceo,"A",{id:!0,class:!0,href:!0});var Bxt=s(W1);hbe=n(Bxt,"SPAN",{});var Ixt=s(hbe);T(cx.$$.fragment,Ixt),Ixt.forEach(t),Bxt.forEach(t),bXo=i(ceo),ube=n(ceo,"SPAN",{});var Nxt=s(ube);vXo=r(Nxt,"AutoModelForMaskedLM"),Nxt.forEach(t),ceo.forEach(t),YYe=i(m),No=n(m,"DIV",{class:!0});var yl=s(No);T(mx.$$.fragment,yl),FXo=i(yl),Ad=n(yl,"P",{});var Zse=s(Ad);TXo=r(Zse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),iQ=n(Zse,"A",{href:!0});var qxt=s(iQ);MXo=r(qxt,"from_pretrained()"),qxt.forEach(t),EXo=r(Zse," class method or the "),dQ=n(Zse,"A",{href:!0});var jxt=s(dQ);CXo=r(jxt,"from_config()"),jxt.forEach(t),wXo=r(Zse,` class
method.`),Zse.forEach(t),AXo=i(yl),fx=n(yl,"P",{});var meo=s(fx);LXo=r(meo,"This class cannot be instantiated directly using "),pbe=n(meo,"CODE",{});var Dxt=s(pbe);yXo=r(Dxt,"__init__()"),Dxt.forEach(t),xXo=r(meo," (throws an error)."),meo.forEach(t),$Xo=i(yl),Ft=n(yl,"DIV",{class:!0});var Cy=s(Ft);T(gx.$$.fragment,Cy),kXo=i(Cy),_be=n(Cy,"P",{});var Gxt=s(_be);SXo=r(Gxt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxt.forEach(t),RXo=i(Cy),Ld=n(Cy,"P",{});var ele=s(Ld);PXo=r(ele,`Note:
Loading a model from its configuration file does `),bbe=n(ele,"STRONG",{});var Oxt=s(bbe);BXo=r(Oxt,"not"),Oxt.forEach(t),IXo=r(ele,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(ele,"A",{href:!0});var Vxt=s(cQ);NXo=r(Vxt,"from_pretrained()"),Vxt.forEach(t),qXo=r(ele," to load the model weights."),ele.forEach(t),jXo=i(Cy),T(U1.$$.fragment,Cy),Cy.forEach(t),DXo=i(yl),ro=n(yl,"DIV",{class:!0});var Ea=s(ro);T(hx.$$.fragment,Ea),GXo=i(Ea),vbe=n(Ea,"P",{});var Xxt=s(vbe);OXo=r(Xxt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xxt.forEach(t),VXo=i(Ea),Za=n(Ea,"P",{});var wy=s(Za);XXo=r(wy,"The model class to instantiate is selected based on the "),Fbe=n(wy,"CODE",{});var zxt=s(Fbe);zXo=r(zxt,"model_type"),zxt.forEach(t),QXo=r(wy,` property of the config object (either
passed as an argument or loaded from `),Tbe=n(wy,"CODE",{});var Qxt=s(Tbe);WXo=r(Qxt,"pretrained_model_name_or_path"),Qxt.forEach(t),UXo=r(wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mbe=n(wy,"CODE",{});var Wxt=s(Mbe);HXo=r(Wxt,"pretrained_model_name_or_path"),Wxt.forEach(t),JXo=r(wy,":"),wy.forEach(t),YXo=i(Ea),U=n(Ea,"UL",{});var Y=s(U);H1=n(Y,"LI",{});var wje=s(H1);Ebe=n(wje,"STRONG",{});var Uxt=s(Ebe);KXo=r(Uxt,"albert"),Uxt.forEach(t),ZXo=r(wje," \u2014 "),mQ=n(wje,"A",{href:!0});var Hxt=s(mQ);ezo=r(Hxt,"AlbertForMaskedLM"),Hxt.forEach(t),ozo=r(wje," (ALBERT model)"),wje.forEach(t),rzo=i(Y),J1=n(Y,"LI",{});var Aje=s(J1);Cbe=n(Aje,"STRONG",{});var Jxt=s(Cbe);tzo=r(Jxt,"bart"),Jxt.forEach(t),azo=r(Aje," \u2014 "),fQ=n(Aje,"A",{href:!0});var Yxt=s(fQ);nzo=r(Yxt,"BartForConditionalGeneration"),Yxt.forEach(t),szo=r(Aje," (BART model)"),Aje.forEach(t),lzo=i(Y),Y1=n(Y,"LI",{});var Lje=s(Y1);wbe=n(Lje,"STRONG",{});var Kxt=s(wbe);izo=r(Kxt,"bert"),Kxt.forEach(t),dzo=r(Lje," \u2014 "),gQ=n(Lje,"A",{href:!0});var Zxt=s(gQ);czo=r(Zxt,"BertForMaskedLM"),Zxt.forEach(t),mzo=r(Lje," (BERT model)"),Lje.forEach(t),fzo=i(Y),K1=n(Y,"LI",{});var yje=s(K1);Abe=n(yje,"STRONG",{});var e$t=s(Abe);gzo=r(e$t,"big_bird"),e$t.forEach(t),hzo=r(yje," \u2014 "),hQ=n(yje,"A",{href:!0});var o$t=s(hQ);uzo=r(o$t,"BigBirdForMaskedLM"),o$t.forEach(t),pzo=r(yje," (BigBird model)"),yje.forEach(t),_zo=i(Y),Z1=n(Y,"LI",{});var xje=s(Z1);Lbe=n(xje,"STRONG",{});var r$t=s(Lbe);bzo=r(r$t,"camembert"),r$t.forEach(t),vzo=r(xje," \u2014 "),uQ=n(xje,"A",{href:!0});var t$t=s(uQ);Fzo=r(t$t,"CamembertForMaskedLM"),t$t.forEach(t),Tzo=r(xje," (CamemBERT model)"),xje.forEach(t),Mzo=i(Y),ev=n(Y,"LI",{});var $je=s(ev);ybe=n($je,"STRONG",{});var a$t=s(ybe);Ezo=r(a$t,"convbert"),a$t.forEach(t),Czo=r($je," \u2014 "),pQ=n($je,"A",{href:!0});var n$t=s(pQ);wzo=r(n$t,"ConvBertForMaskedLM"),n$t.forEach(t),Azo=r($je," (ConvBERT model)"),$je.forEach(t),Lzo=i(Y),ov=n(Y,"LI",{});var kje=s(ov);xbe=n(kje,"STRONG",{});var s$t=s(xbe);yzo=r(s$t,"data2vec-text"),s$t.forEach(t),xzo=r(kje," \u2014 "),_Q=n(kje,"A",{href:!0});var l$t=s(_Q);$zo=r(l$t,"Data2VecTextForMaskedLM"),l$t.forEach(t),kzo=r(kje," (Data2VecText model)"),kje.forEach(t),Szo=i(Y),rv=n(Y,"LI",{});var Sje=s(rv);$be=n(Sje,"STRONG",{});var i$t=s($be);Rzo=r(i$t,"deberta"),i$t.forEach(t),Pzo=r(Sje," \u2014 "),bQ=n(Sje,"A",{href:!0});var d$t=s(bQ);Bzo=r(d$t,"DebertaForMaskedLM"),d$t.forEach(t),Izo=r(Sje," (DeBERTa model)"),Sje.forEach(t),Nzo=i(Y),tv=n(Y,"LI",{});var Rje=s(tv);kbe=n(Rje,"STRONG",{});var c$t=s(kbe);qzo=r(c$t,"deberta-v2"),c$t.forEach(t),jzo=r(Rje," \u2014 "),vQ=n(Rje,"A",{href:!0});var m$t=s(vQ);Dzo=r(m$t,"DebertaV2ForMaskedLM"),m$t.forEach(t),Gzo=r(Rje," (DeBERTa-v2 model)"),Rje.forEach(t),Ozo=i(Y),av=n(Y,"LI",{});var Pje=s(av);Sbe=n(Pje,"STRONG",{});var f$t=s(Sbe);Vzo=r(f$t,"distilbert"),f$t.forEach(t),Xzo=r(Pje," \u2014 "),FQ=n(Pje,"A",{href:!0});var g$t=s(FQ);zzo=r(g$t,"DistilBertForMaskedLM"),g$t.forEach(t),Qzo=r(Pje," (DistilBERT model)"),Pje.forEach(t),Wzo=i(Y),nv=n(Y,"LI",{});var Bje=s(nv);Rbe=n(Bje,"STRONG",{});var h$t=s(Rbe);Uzo=r(h$t,"electra"),h$t.forEach(t),Hzo=r(Bje," \u2014 "),TQ=n(Bje,"A",{href:!0});var u$t=s(TQ);Jzo=r(u$t,"ElectraForMaskedLM"),u$t.forEach(t),Yzo=r(Bje," (ELECTRA model)"),Bje.forEach(t),Kzo=i(Y),sv=n(Y,"LI",{});var Ije=s(sv);Pbe=n(Ije,"STRONG",{});var p$t=s(Pbe);Zzo=r(p$t,"ernie"),p$t.forEach(t),eQo=r(Ije," \u2014 "),MQ=n(Ije,"A",{href:!0});var _$t=s(MQ);oQo=r(_$t,"ErnieForMaskedLM"),_$t.forEach(t),rQo=r(Ije," (ERNIE model)"),Ije.forEach(t),tQo=i(Y),lv=n(Y,"LI",{});var Nje=s(lv);Bbe=n(Nje,"STRONG",{});var b$t=s(Bbe);aQo=r(b$t,"flaubert"),b$t.forEach(t),nQo=r(Nje," \u2014 "),EQ=n(Nje,"A",{href:!0});var v$t=s(EQ);sQo=r(v$t,"FlaubertWithLMHeadModel"),v$t.forEach(t),lQo=r(Nje," (FlauBERT model)"),Nje.forEach(t),iQo=i(Y),iv=n(Y,"LI",{});var qje=s(iv);Ibe=n(qje,"STRONG",{});var F$t=s(Ibe);dQo=r(F$t,"fnet"),F$t.forEach(t),cQo=r(qje," \u2014 "),CQ=n(qje,"A",{href:!0});var T$t=s(CQ);mQo=r(T$t,"FNetForMaskedLM"),T$t.forEach(t),fQo=r(qje," (FNet model)"),qje.forEach(t),gQo=i(Y),dv=n(Y,"LI",{});var jje=s(dv);Nbe=n(jje,"STRONG",{});var M$t=s(Nbe);hQo=r(M$t,"funnel"),M$t.forEach(t),uQo=r(jje," \u2014 "),wQ=n(jje,"A",{href:!0});var E$t=s(wQ);pQo=r(E$t,"FunnelForMaskedLM"),E$t.forEach(t),_Qo=r(jje," (Funnel Transformer model)"),jje.forEach(t),bQo=i(Y),cv=n(Y,"LI",{});var Dje=s(cv);qbe=n(Dje,"STRONG",{});var C$t=s(qbe);vQo=r(C$t,"ibert"),C$t.forEach(t),FQo=r(Dje," \u2014 "),AQ=n(Dje,"A",{href:!0});var w$t=s(AQ);TQo=r(w$t,"IBertForMaskedLM"),w$t.forEach(t),MQo=r(Dje," (I-BERT model)"),Dje.forEach(t),EQo=i(Y),mv=n(Y,"LI",{});var Gje=s(mv);jbe=n(Gje,"STRONG",{});var A$t=s(jbe);CQo=r(A$t,"layoutlm"),A$t.forEach(t),wQo=r(Gje," \u2014 "),LQ=n(Gje,"A",{href:!0});var L$t=s(LQ);AQo=r(L$t,"LayoutLMForMaskedLM"),L$t.forEach(t),LQo=r(Gje," (LayoutLM model)"),Gje.forEach(t),yQo=i(Y),fv=n(Y,"LI",{});var Oje=s(fv);Dbe=n(Oje,"STRONG",{});var y$t=s(Dbe);xQo=r(y$t,"longformer"),y$t.forEach(t),$Qo=r(Oje," \u2014 "),yQ=n(Oje,"A",{href:!0});var x$t=s(yQ);kQo=r(x$t,"LongformerForMaskedLM"),x$t.forEach(t),SQo=r(Oje," (Longformer model)"),Oje.forEach(t),RQo=i(Y),gv=n(Y,"LI",{});var Vje=s(gv);Gbe=n(Vje,"STRONG",{});var $$t=s(Gbe);PQo=r($$t,"luke"),$$t.forEach(t),BQo=r(Vje," \u2014 "),xQ=n(Vje,"A",{href:!0});var k$t=s(xQ);IQo=r(k$t,"LukeForMaskedLM"),k$t.forEach(t),NQo=r(Vje," (LUKE model)"),Vje.forEach(t),qQo=i(Y),hv=n(Y,"LI",{});var Xje=s(hv);Obe=n(Xje,"STRONG",{});var S$t=s(Obe);jQo=r(S$t,"mbart"),S$t.forEach(t),DQo=r(Xje," \u2014 "),$Q=n(Xje,"A",{href:!0});var R$t=s($Q);GQo=r(R$t,"MBartForConditionalGeneration"),R$t.forEach(t),OQo=r(Xje," (mBART model)"),Xje.forEach(t),VQo=i(Y),uv=n(Y,"LI",{});var zje=s(uv);Vbe=n(zje,"STRONG",{});var P$t=s(Vbe);XQo=r(P$t,"megatron-bert"),P$t.forEach(t),zQo=r(zje," \u2014 "),kQ=n(zje,"A",{href:!0});var B$t=s(kQ);QQo=r(B$t,"MegatronBertForMaskedLM"),B$t.forEach(t),WQo=r(zje," (Megatron-BERT model)"),zje.forEach(t),UQo=i(Y),pv=n(Y,"LI",{});var Qje=s(pv);Xbe=n(Qje,"STRONG",{});var I$t=s(Xbe);HQo=r(I$t,"mobilebert"),I$t.forEach(t),JQo=r(Qje," \u2014 "),SQ=n(Qje,"A",{href:!0});var N$t=s(SQ);YQo=r(N$t,"MobileBertForMaskedLM"),N$t.forEach(t),KQo=r(Qje," (MobileBERT model)"),Qje.forEach(t),ZQo=i(Y),_v=n(Y,"LI",{});var Wje=s(_v);zbe=n(Wje,"STRONG",{});var q$t=s(zbe);eWo=r(q$t,"mpnet"),q$t.forEach(t),oWo=r(Wje," \u2014 "),RQ=n(Wje,"A",{href:!0});var j$t=s(RQ);rWo=r(j$t,"MPNetForMaskedLM"),j$t.forEach(t),tWo=r(Wje," (MPNet model)"),Wje.forEach(t),aWo=i(Y),bv=n(Y,"LI",{});var Uje=s(bv);Qbe=n(Uje,"STRONG",{});var D$t=s(Qbe);nWo=r(D$t,"mvp"),D$t.forEach(t),sWo=r(Uje," \u2014 "),PQ=n(Uje,"A",{href:!0});var G$t=s(PQ);lWo=r(G$t,"MvpForConditionalGeneration"),G$t.forEach(t),iWo=r(Uje," (MVP model)"),Uje.forEach(t),dWo=i(Y),vv=n(Y,"LI",{});var Hje=s(vv);Wbe=n(Hje,"STRONG",{});var O$t=s(Wbe);cWo=r(O$t,"nezha"),O$t.forEach(t),mWo=r(Hje," \u2014 "),BQ=n(Hje,"A",{href:!0});var V$t=s(BQ);fWo=r(V$t,"NezhaForMaskedLM"),V$t.forEach(t),gWo=r(Hje," (Nezha model)"),Hje.forEach(t),hWo=i(Y),Fv=n(Y,"LI",{});var Jje=s(Fv);Ube=n(Jje,"STRONG",{});var X$t=s(Ube);uWo=r(X$t,"nystromformer"),X$t.forEach(t),pWo=r(Jje," \u2014 "),IQ=n(Jje,"A",{href:!0});var z$t=s(IQ);_Wo=r(z$t,"NystromformerForMaskedLM"),z$t.forEach(t),bWo=r(Jje," (Nystr\xF6mformer model)"),Jje.forEach(t),vWo=i(Y),Tv=n(Y,"LI",{});var Yje=s(Tv);Hbe=n(Yje,"STRONG",{});var Q$t=s(Hbe);FWo=r(Q$t,"perceiver"),Q$t.forEach(t),TWo=r(Yje," \u2014 "),NQ=n(Yje,"A",{href:!0});var W$t=s(NQ);MWo=r(W$t,"PerceiverForMaskedLM"),W$t.forEach(t),EWo=r(Yje," (Perceiver model)"),Yje.forEach(t),CWo=i(Y),Mv=n(Y,"LI",{});var Kje=s(Mv);Jbe=n(Kje,"STRONG",{});var U$t=s(Jbe);wWo=r(U$t,"qdqbert"),U$t.forEach(t),AWo=r(Kje," \u2014 "),qQ=n(Kje,"A",{href:!0});var H$t=s(qQ);LWo=r(H$t,"QDQBertForMaskedLM"),H$t.forEach(t),yWo=r(Kje," (QDQBert model)"),Kje.forEach(t),xWo=i(Y),Ev=n(Y,"LI",{});var Zje=s(Ev);Ybe=n(Zje,"STRONG",{});var J$t=s(Ybe);$Wo=r(J$t,"reformer"),J$t.forEach(t),kWo=r(Zje," \u2014 "),jQ=n(Zje,"A",{href:!0});var Y$t=s(jQ);SWo=r(Y$t,"ReformerForMaskedLM"),Y$t.forEach(t),RWo=r(Zje," (Reformer model)"),Zje.forEach(t),PWo=i(Y),Cv=n(Y,"LI",{});var eDe=s(Cv);Kbe=n(eDe,"STRONG",{});var K$t=s(Kbe);BWo=r(K$t,"rembert"),K$t.forEach(t),IWo=r(eDe," \u2014 "),DQ=n(eDe,"A",{href:!0});var Z$t=s(DQ);NWo=r(Z$t,"RemBertForMaskedLM"),Z$t.forEach(t),qWo=r(eDe," (RemBERT model)"),eDe.forEach(t),jWo=i(Y),wv=n(Y,"LI",{});var oDe=s(wv);Zbe=n(oDe,"STRONG",{});var ekt=s(Zbe);DWo=r(ekt,"roberta"),ekt.forEach(t),GWo=r(oDe," \u2014 "),GQ=n(oDe,"A",{href:!0});var okt=s(GQ);OWo=r(okt,"RobertaForMaskedLM"),okt.forEach(t),VWo=r(oDe," (RoBERTa model)"),oDe.forEach(t),XWo=i(Y),Av=n(Y,"LI",{});var rDe=s(Av);e1e=n(rDe,"STRONG",{});var rkt=s(e1e);zWo=r(rkt,"roformer"),rkt.forEach(t),QWo=r(rDe," \u2014 "),OQ=n(rDe,"A",{href:!0});var tkt=s(OQ);WWo=r(tkt,"RoFormerForMaskedLM"),tkt.forEach(t),UWo=r(rDe," (RoFormer model)"),rDe.forEach(t),HWo=i(Y),Lv=n(Y,"LI",{});var tDe=s(Lv);o1e=n(tDe,"STRONG",{});var akt=s(o1e);JWo=r(akt,"squeezebert"),akt.forEach(t),YWo=r(tDe," \u2014 "),VQ=n(tDe,"A",{href:!0});var nkt=s(VQ);KWo=r(nkt,"SqueezeBertForMaskedLM"),nkt.forEach(t),ZWo=r(tDe," (SqueezeBERT model)"),tDe.forEach(t),eUo=i(Y),yv=n(Y,"LI",{});var aDe=s(yv);r1e=n(aDe,"STRONG",{});var skt=s(r1e);oUo=r(skt,"tapas"),skt.forEach(t),rUo=r(aDe," \u2014 "),XQ=n(aDe,"A",{href:!0});var lkt=s(XQ);tUo=r(lkt,"TapasForMaskedLM"),lkt.forEach(t),aUo=r(aDe," (TAPAS model)"),aDe.forEach(t),nUo=i(Y),xv=n(Y,"LI",{});var nDe=s(xv);t1e=n(nDe,"STRONG",{});var ikt=s(t1e);sUo=r(ikt,"wav2vec2"),ikt.forEach(t),lUo=r(nDe," \u2014 "),a1e=n(nDe,"CODE",{});var dkt=s(a1e);iUo=r(dkt,"Wav2Vec2ForMaskedLM"),dkt.forEach(t),dUo=r(nDe," (Wav2Vec2 model)"),nDe.forEach(t),cUo=i(Y),$v=n(Y,"LI",{});var sDe=s($v);n1e=n(sDe,"STRONG",{});var ckt=s(n1e);mUo=r(ckt,"xlm"),ckt.forEach(t),fUo=r(sDe," \u2014 "),zQ=n(sDe,"A",{href:!0});var mkt=s(zQ);gUo=r(mkt,"XLMWithLMHeadModel"),mkt.forEach(t),hUo=r(sDe," (XLM model)"),sDe.forEach(t),uUo=i(Y),kv=n(Y,"LI",{});var lDe=s(kv);s1e=n(lDe,"STRONG",{});var fkt=s(s1e);pUo=r(fkt,"xlm-roberta"),fkt.forEach(t),_Uo=r(lDe," \u2014 "),QQ=n(lDe,"A",{href:!0});var gkt=s(QQ);bUo=r(gkt,"XLMRobertaForMaskedLM"),gkt.forEach(t),vUo=r(lDe," (XLM-RoBERTa model)"),lDe.forEach(t),FUo=i(Y),Sv=n(Y,"LI",{});var iDe=s(Sv);l1e=n(iDe,"STRONG",{});var hkt=s(l1e);TUo=r(hkt,"xlm-roberta-xl"),hkt.forEach(t),MUo=r(iDe," \u2014 "),WQ=n(iDe,"A",{href:!0});var ukt=s(WQ);EUo=r(ukt,"XLMRobertaXLForMaskedLM"),ukt.forEach(t),CUo=r(iDe," (XLM-RoBERTa-XL model)"),iDe.forEach(t),wUo=i(Y),Rv=n(Y,"LI",{});var dDe=s(Rv);i1e=n(dDe,"STRONG",{});var pkt=s(i1e);AUo=r(pkt,"yoso"),pkt.forEach(t),LUo=r(dDe," \u2014 "),UQ=n(dDe,"A",{href:!0});var _kt=s(UQ);yUo=r(_kt,"YosoForMaskedLM"),_kt.forEach(t),xUo=r(dDe," (YOSO model)"),dDe.forEach(t),Y.forEach(t),$Uo=i(Ea),Pv=n(Ea,"P",{});var cDe=s(Pv);kUo=r(cDe,"The model is set in evaluation mode by default using "),d1e=n(cDe,"CODE",{});var bkt=s(d1e);SUo=r(bkt,"model.eval()"),bkt.forEach(t),RUo=r(cDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c1e=n(cDe,"CODE",{});var vkt=s(c1e);PUo=r(vkt,"model.train()"),vkt.forEach(t),cDe.forEach(t),BUo=i(Ea),T(Bv.$$.fragment,Ea),Ea.forEach(t),yl.forEach(t),KYe=i(m),yd=n(m,"H2",{class:!0});var feo=s(yd);Iv=n(feo,"A",{id:!0,class:!0,href:!0});var Fkt=s(Iv);m1e=n(Fkt,"SPAN",{});var Tkt=s(m1e);T(ux.$$.fragment,Tkt),Tkt.forEach(t),Fkt.forEach(t),IUo=i(feo),f1e=n(feo,"SPAN",{});var Mkt=s(f1e);NUo=r(Mkt,"AutoModelForSeq2SeqLM"),Mkt.forEach(t),feo.forEach(t),ZYe=i(m),qo=n(m,"DIV",{class:!0});var xl=s(qo);T(px.$$.fragment,xl),qUo=i(xl),xd=n(xl,"P",{});var ole=s(xd);jUo=r(ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HQ=n(ole,"A",{href:!0});var Ekt=s(HQ);DUo=r(Ekt,"from_pretrained()"),Ekt.forEach(t),GUo=r(ole," class method or the "),JQ=n(ole,"A",{href:!0});var Ckt=s(JQ);OUo=r(Ckt,"from_config()"),Ckt.forEach(t),VUo=r(ole,` class
method.`),ole.forEach(t),XUo=i(xl),_x=n(xl,"P",{});var geo=s(_x);zUo=r(geo,"This class cannot be instantiated directly using "),g1e=n(geo,"CODE",{});var wkt=s(g1e);QUo=r(wkt,"__init__()"),wkt.forEach(t),WUo=r(geo," (throws an error)."),geo.forEach(t),UUo=i(xl),Tt=n(xl,"DIV",{class:!0});var Ay=s(Tt);T(bx.$$.fragment,Ay),HUo=i(Ay),h1e=n(Ay,"P",{});var Akt=s(h1e);JUo=r(Akt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Akt.forEach(t),YUo=i(Ay),$d=n(Ay,"P",{});var rle=s($d);KUo=r(rle,`Note:
Loading a model from its configuration file does `),u1e=n(rle,"STRONG",{});var Lkt=s(u1e);ZUo=r(Lkt,"not"),Lkt.forEach(t),eHo=r(rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=n(rle,"A",{href:!0});var ykt=s(YQ);oHo=r(ykt,"from_pretrained()"),ykt.forEach(t),rHo=r(rle," to load the model weights."),rle.forEach(t),tHo=i(Ay),T(Nv.$$.fragment,Ay),Ay.forEach(t),aHo=i(xl),to=n(xl,"DIV",{class:!0});var Ca=s(to);T(vx.$$.fragment,Ca),nHo=i(Ca),p1e=n(Ca,"P",{});var xkt=s(p1e);sHo=r(xkt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xkt.forEach(t),lHo=i(Ca),en=n(Ca,"P",{});var Ly=s(en);iHo=r(Ly,"The model class to instantiate is selected based on the "),_1e=n(Ly,"CODE",{});var $kt=s(_1e);dHo=r($kt,"model_type"),$kt.forEach(t),cHo=r(Ly,` property of the config object (either
passed as an argument or loaded from `),b1e=n(Ly,"CODE",{});var kkt=s(b1e);mHo=r(kkt,"pretrained_model_name_or_path"),kkt.forEach(t),fHo=r(Ly,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v1e=n(Ly,"CODE",{});var Skt=s(v1e);gHo=r(Skt,"pretrained_model_name_or_path"),Skt.forEach(t),hHo=r(Ly,":"),Ly.forEach(t),uHo=i(Ca),me=n(Ca,"UL",{});var pe=s(me);qv=n(pe,"LI",{});var mDe=s(qv);F1e=n(mDe,"STRONG",{});var Rkt=s(F1e);pHo=r(Rkt,"bart"),Rkt.forEach(t),_Ho=r(mDe," \u2014 "),KQ=n(mDe,"A",{href:!0});var Pkt=s(KQ);bHo=r(Pkt,"BartForConditionalGeneration"),Pkt.forEach(t),vHo=r(mDe," (BART model)"),mDe.forEach(t),FHo=i(pe),jv=n(pe,"LI",{});var fDe=s(jv);T1e=n(fDe,"STRONG",{});var Bkt=s(T1e);THo=r(Bkt,"bigbird_pegasus"),Bkt.forEach(t),MHo=r(fDe," \u2014 "),ZQ=n(fDe,"A",{href:!0});var Ikt=s(ZQ);EHo=r(Ikt,"BigBirdPegasusForConditionalGeneration"),Ikt.forEach(t),CHo=r(fDe," (BigBird-Pegasus model)"),fDe.forEach(t),wHo=i(pe),Dv=n(pe,"LI",{});var gDe=s(Dv);M1e=n(gDe,"STRONG",{});var Nkt=s(M1e);AHo=r(Nkt,"blenderbot"),Nkt.forEach(t),LHo=r(gDe," \u2014 "),eW=n(gDe,"A",{href:!0});var qkt=s(eW);yHo=r(qkt,"BlenderbotForConditionalGeneration"),qkt.forEach(t),xHo=r(gDe," (Blenderbot model)"),gDe.forEach(t),$Ho=i(pe),Gv=n(pe,"LI",{});var hDe=s(Gv);E1e=n(hDe,"STRONG",{});var jkt=s(E1e);kHo=r(jkt,"blenderbot-small"),jkt.forEach(t),SHo=r(hDe," \u2014 "),oW=n(hDe,"A",{href:!0});var Dkt=s(oW);RHo=r(Dkt,"BlenderbotSmallForConditionalGeneration"),Dkt.forEach(t),PHo=r(hDe," (BlenderbotSmall model)"),hDe.forEach(t),BHo=i(pe),Ov=n(pe,"LI",{});var uDe=s(Ov);C1e=n(uDe,"STRONG",{});var Gkt=s(C1e);IHo=r(Gkt,"encoder-decoder"),Gkt.forEach(t),NHo=r(uDe," \u2014 "),rW=n(uDe,"A",{href:!0});var Okt=s(rW);qHo=r(Okt,"EncoderDecoderModel"),Okt.forEach(t),jHo=r(uDe," (Encoder decoder model)"),uDe.forEach(t),DHo=i(pe),Vv=n(pe,"LI",{});var pDe=s(Vv);w1e=n(pDe,"STRONG",{});var Vkt=s(w1e);GHo=r(Vkt,"fsmt"),Vkt.forEach(t),OHo=r(pDe," \u2014 "),tW=n(pDe,"A",{href:!0});var Xkt=s(tW);VHo=r(Xkt,"FSMTForConditionalGeneration"),Xkt.forEach(t),XHo=r(pDe," (FairSeq Machine-Translation model)"),pDe.forEach(t),zHo=i(pe),Xv=n(pe,"LI",{});var _De=s(Xv);A1e=n(_De,"STRONG",{});var zkt=s(A1e);QHo=r(zkt,"led"),zkt.forEach(t),WHo=r(_De," \u2014 "),aW=n(_De,"A",{href:!0});var Qkt=s(aW);UHo=r(Qkt,"LEDForConditionalGeneration"),Qkt.forEach(t),HHo=r(_De," (LED model)"),_De.forEach(t),JHo=i(pe),zv=n(pe,"LI",{});var bDe=s(zv);L1e=n(bDe,"STRONG",{});var Wkt=s(L1e);YHo=r(Wkt,"longt5"),Wkt.forEach(t),KHo=r(bDe," \u2014 "),nW=n(bDe,"A",{href:!0});var Ukt=s(nW);ZHo=r(Ukt,"LongT5ForConditionalGeneration"),Ukt.forEach(t),eJo=r(bDe," (LongT5 model)"),bDe.forEach(t),oJo=i(pe),Qv=n(pe,"LI",{});var vDe=s(Qv);y1e=n(vDe,"STRONG",{});var Hkt=s(y1e);rJo=r(Hkt,"m2m_100"),Hkt.forEach(t),tJo=r(vDe," \u2014 "),sW=n(vDe,"A",{href:!0});var Jkt=s(sW);aJo=r(Jkt,"M2M100ForConditionalGeneration"),Jkt.forEach(t),nJo=r(vDe," (M2M100 model)"),vDe.forEach(t),sJo=i(pe),Wv=n(pe,"LI",{});var FDe=s(Wv);x1e=n(FDe,"STRONG",{});var Ykt=s(x1e);lJo=r(Ykt,"marian"),Ykt.forEach(t),iJo=r(FDe," \u2014 "),lW=n(FDe,"A",{href:!0});var Kkt=s(lW);dJo=r(Kkt,"MarianMTModel"),Kkt.forEach(t),cJo=r(FDe," (Marian model)"),FDe.forEach(t),mJo=i(pe),Uv=n(pe,"LI",{});var TDe=s(Uv);$1e=n(TDe,"STRONG",{});var Zkt=s($1e);fJo=r(Zkt,"mbart"),Zkt.forEach(t),gJo=r(TDe," \u2014 "),iW=n(TDe,"A",{href:!0});var eSt=s(iW);hJo=r(eSt,"MBartForConditionalGeneration"),eSt.forEach(t),uJo=r(TDe," (mBART model)"),TDe.forEach(t),pJo=i(pe),Hv=n(pe,"LI",{});var MDe=s(Hv);k1e=n(MDe,"STRONG",{});var oSt=s(k1e);_Jo=r(oSt,"mt5"),oSt.forEach(t),bJo=r(MDe," \u2014 "),dW=n(MDe,"A",{href:!0});var rSt=s(dW);vJo=r(rSt,"MT5ForConditionalGeneration"),rSt.forEach(t),FJo=r(MDe," (MT5 model)"),MDe.forEach(t),TJo=i(pe),Jv=n(pe,"LI",{});var EDe=s(Jv);S1e=n(EDe,"STRONG",{});var tSt=s(S1e);MJo=r(tSt,"mvp"),tSt.forEach(t),EJo=r(EDe," \u2014 "),cW=n(EDe,"A",{href:!0});var aSt=s(cW);CJo=r(aSt,"MvpForConditionalGeneration"),aSt.forEach(t),wJo=r(EDe," (MVP model)"),EDe.forEach(t),AJo=i(pe),Yv=n(pe,"LI",{});var CDe=s(Yv);R1e=n(CDe,"STRONG",{});var nSt=s(R1e);LJo=r(nSt,"nllb"),nSt.forEach(t),yJo=r(CDe," \u2014 "),mW=n(CDe,"A",{href:!0});var sSt=s(mW);xJo=r(sSt,"M2M100ForConditionalGeneration"),sSt.forEach(t),$Jo=r(CDe," (NLLB model)"),CDe.forEach(t),kJo=i(pe),Kv=n(pe,"LI",{});var wDe=s(Kv);P1e=n(wDe,"STRONG",{});var lSt=s(P1e);SJo=r(lSt,"pegasus"),lSt.forEach(t),RJo=r(wDe," \u2014 "),fW=n(wDe,"A",{href:!0});var iSt=s(fW);PJo=r(iSt,"PegasusForConditionalGeneration"),iSt.forEach(t),BJo=r(wDe," (Pegasus model)"),wDe.forEach(t),IJo=i(pe),Zv=n(pe,"LI",{});var ADe=s(Zv);B1e=n(ADe,"STRONG",{});var dSt=s(B1e);NJo=r(dSt,"pegasus_x"),dSt.forEach(t),qJo=r(ADe," \u2014 "),gW=n(ADe,"A",{href:!0});var cSt=s(gW);jJo=r(cSt,"PegasusXForConditionalGeneration"),cSt.forEach(t),DJo=r(ADe," (PEGASUS-X model)"),ADe.forEach(t),GJo=i(pe),eF=n(pe,"LI",{});var LDe=s(eF);I1e=n(LDe,"STRONG",{});var mSt=s(I1e);OJo=r(mSt,"plbart"),mSt.forEach(t),VJo=r(LDe," \u2014 "),hW=n(LDe,"A",{href:!0});var fSt=s(hW);XJo=r(fSt,"PLBartForConditionalGeneration"),fSt.forEach(t),zJo=r(LDe," (PLBart model)"),LDe.forEach(t),QJo=i(pe),oF=n(pe,"LI",{});var yDe=s(oF);N1e=n(yDe,"STRONG",{});var gSt=s(N1e);WJo=r(gSt,"prophetnet"),gSt.forEach(t),UJo=r(yDe," \u2014 "),uW=n(yDe,"A",{href:!0});var hSt=s(uW);HJo=r(hSt,"ProphetNetForConditionalGeneration"),hSt.forEach(t),JJo=r(yDe," (ProphetNet model)"),yDe.forEach(t),YJo=i(pe),rF=n(pe,"LI",{});var xDe=s(rF);q1e=n(xDe,"STRONG",{});var uSt=s(q1e);KJo=r(uSt,"t5"),uSt.forEach(t),ZJo=r(xDe," \u2014 "),pW=n(xDe,"A",{href:!0});var pSt=s(pW);eYo=r(pSt,"T5ForConditionalGeneration"),pSt.forEach(t),oYo=r(xDe," (T5 model)"),xDe.forEach(t),rYo=i(pe),tF=n(pe,"LI",{});var $De=s(tF);j1e=n($De,"STRONG",{});var _St=s(j1e);tYo=r(_St,"xlm-prophetnet"),_St.forEach(t),aYo=r($De," \u2014 "),_W=n($De,"A",{href:!0});var bSt=s(_W);nYo=r(bSt,"XLMProphetNetForConditionalGeneration"),bSt.forEach(t),sYo=r($De," (XLM-ProphetNet model)"),$De.forEach(t),pe.forEach(t),lYo=i(Ca),aF=n(Ca,"P",{});var kDe=s(aF);iYo=r(kDe,"The model is set in evaluation mode by default using "),D1e=n(kDe,"CODE",{});var vSt=s(D1e);dYo=r(vSt,"model.eval()"),vSt.forEach(t),cYo=r(kDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G1e=n(kDe,"CODE",{});var FSt=s(G1e);mYo=r(FSt,"model.train()"),FSt.forEach(t),kDe.forEach(t),fYo=i(Ca),T(nF.$$.fragment,Ca),Ca.forEach(t),xl.forEach(t),eKe=i(m),kd=n(m,"H2",{class:!0});var heo=s(kd);sF=n(heo,"A",{id:!0,class:!0,href:!0});var TSt=s(sF);O1e=n(TSt,"SPAN",{});var MSt=s(O1e);T(Fx.$$.fragment,MSt),MSt.forEach(t),TSt.forEach(t),gYo=i(heo),V1e=n(heo,"SPAN",{});var ESt=s(V1e);hYo=r(ESt,"AutoModelForSequenceClassification"),ESt.forEach(t),heo.forEach(t),oKe=i(m),jo=n(m,"DIV",{class:!0});var $l=s(jo);T(Tx.$$.fragment,$l),uYo=i($l),Sd=n($l,"P",{});var tle=s(Sd);pYo=r(tle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),bW=n(tle,"A",{href:!0});var CSt=s(bW);_Yo=r(CSt,"from_pretrained()"),CSt.forEach(t),bYo=r(tle," class method or the "),vW=n(tle,"A",{href:!0});var wSt=s(vW);vYo=r(wSt,"from_config()"),wSt.forEach(t),FYo=r(tle,` class
method.`),tle.forEach(t),TYo=i($l),Mx=n($l,"P",{});var ueo=s(Mx);MYo=r(ueo,"This class cannot be instantiated directly using "),X1e=n(ueo,"CODE",{});var ASt=s(X1e);EYo=r(ASt,"__init__()"),ASt.forEach(t),CYo=r(ueo," (throws an error)."),ueo.forEach(t),wYo=i($l),Mt=n($l,"DIV",{class:!0});var yy=s(Mt);T(Ex.$$.fragment,yy),AYo=i(yy),z1e=n(yy,"P",{});var LSt=s(z1e);LYo=r(LSt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),LSt.forEach(t),yYo=i(yy),Rd=n(yy,"P",{});var ale=s(Rd);xYo=r(ale,`Note:
Loading a model from its configuration file does `),Q1e=n(ale,"STRONG",{});var ySt=s(Q1e);$Yo=r(ySt,"not"),ySt.forEach(t),kYo=r(ale,` load the model weights. It only affects the
model\u2019s configuration. Use `),FW=n(ale,"A",{href:!0});var xSt=s(FW);SYo=r(xSt,"from_pretrained()"),xSt.forEach(t),RYo=r(ale," to load the model weights."),ale.forEach(t),PYo=i(yy),T(lF.$$.fragment,yy),yy.forEach(t),BYo=i($l),ao=n($l,"DIV",{class:!0});var wa=s(ao);T(Cx.$$.fragment,wa),IYo=i(wa),W1e=n(wa,"P",{});var $St=s(W1e);NYo=r($St,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),$St.forEach(t),qYo=i(wa),on=n(wa,"P",{});var xy=s(on);jYo=r(xy,"The model class to instantiate is selected based on the "),U1e=n(xy,"CODE",{});var kSt=s(U1e);DYo=r(kSt,"model_type"),kSt.forEach(t),GYo=r(xy,` property of the config object (either
passed as an argument or loaded from `),H1e=n(xy,"CODE",{});var SSt=s(H1e);OYo=r(SSt,"pretrained_model_name_or_path"),SSt.forEach(t),VYo=r(xy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J1e=n(xy,"CODE",{});var RSt=s(J1e);XYo=r(RSt,"pretrained_model_name_or_path"),RSt.forEach(t),zYo=r(xy,":"),xy.forEach(t),QYo=i(wa),q=n(wa,"UL",{});var D=s(q);iF=n(D,"LI",{});var SDe=s(iF);Y1e=n(SDe,"STRONG",{});var PSt=s(Y1e);WYo=r(PSt,"albert"),PSt.forEach(t),UYo=r(SDe," \u2014 "),TW=n(SDe,"A",{href:!0});var BSt=s(TW);HYo=r(BSt,"AlbertForSequenceClassification"),BSt.forEach(t),JYo=r(SDe," (ALBERT model)"),SDe.forEach(t),YYo=i(D),dF=n(D,"LI",{});var RDe=s(dF);K1e=n(RDe,"STRONG",{});var ISt=s(K1e);KYo=r(ISt,"bart"),ISt.forEach(t),ZYo=r(RDe," \u2014 "),MW=n(RDe,"A",{href:!0});var NSt=s(MW);eKo=r(NSt,"BartForSequenceClassification"),NSt.forEach(t),oKo=r(RDe," (BART model)"),RDe.forEach(t),rKo=i(D),cF=n(D,"LI",{});var PDe=s(cF);Z1e=n(PDe,"STRONG",{});var qSt=s(Z1e);tKo=r(qSt,"bert"),qSt.forEach(t),aKo=r(PDe," \u2014 "),EW=n(PDe,"A",{href:!0});var jSt=s(EW);nKo=r(jSt,"BertForSequenceClassification"),jSt.forEach(t),sKo=r(PDe," (BERT model)"),PDe.forEach(t),lKo=i(D),mF=n(D,"LI",{});var BDe=s(mF);eve=n(BDe,"STRONG",{});var DSt=s(eve);iKo=r(DSt,"big_bird"),DSt.forEach(t),dKo=r(BDe," \u2014 "),CW=n(BDe,"A",{href:!0});var GSt=s(CW);cKo=r(GSt,"BigBirdForSequenceClassification"),GSt.forEach(t),mKo=r(BDe," (BigBird model)"),BDe.forEach(t),fKo=i(D),fF=n(D,"LI",{});var IDe=s(fF);ove=n(IDe,"STRONG",{});var OSt=s(ove);gKo=r(OSt,"bigbird_pegasus"),OSt.forEach(t),hKo=r(IDe," \u2014 "),wW=n(IDe,"A",{href:!0});var VSt=s(wW);uKo=r(VSt,"BigBirdPegasusForSequenceClassification"),VSt.forEach(t),pKo=r(IDe," (BigBird-Pegasus model)"),IDe.forEach(t),_Ko=i(D),gF=n(D,"LI",{});var NDe=s(gF);rve=n(NDe,"STRONG",{});var XSt=s(rve);bKo=r(XSt,"bloom"),XSt.forEach(t),vKo=r(NDe," \u2014 "),AW=n(NDe,"A",{href:!0});var zSt=s(AW);FKo=r(zSt,"BloomForSequenceClassification"),zSt.forEach(t),TKo=r(NDe," (BLOOM model)"),NDe.forEach(t),MKo=i(D),hF=n(D,"LI",{});var qDe=s(hF);tve=n(qDe,"STRONG",{});var QSt=s(tve);EKo=r(QSt,"camembert"),QSt.forEach(t),CKo=r(qDe," \u2014 "),LW=n(qDe,"A",{href:!0});var WSt=s(LW);wKo=r(WSt,"CamembertForSequenceClassification"),WSt.forEach(t),AKo=r(qDe," (CamemBERT model)"),qDe.forEach(t),LKo=i(D),uF=n(D,"LI",{});var jDe=s(uF);ave=n(jDe,"STRONG",{});var USt=s(ave);yKo=r(USt,"canine"),USt.forEach(t),xKo=r(jDe," \u2014 "),yW=n(jDe,"A",{href:!0});var HSt=s(yW);$Ko=r(HSt,"CanineForSequenceClassification"),HSt.forEach(t),kKo=r(jDe," (CANINE model)"),jDe.forEach(t),SKo=i(D),pF=n(D,"LI",{});var DDe=s(pF);nve=n(DDe,"STRONG",{});var JSt=s(nve);RKo=r(JSt,"convbert"),JSt.forEach(t),PKo=r(DDe," \u2014 "),xW=n(DDe,"A",{href:!0});var YSt=s(xW);BKo=r(YSt,"ConvBertForSequenceClassification"),YSt.forEach(t),IKo=r(DDe," (ConvBERT model)"),DDe.forEach(t),NKo=i(D),_F=n(D,"LI",{});var GDe=s(_F);sve=n(GDe,"STRONG",{});var KSt=s(sve);qKo=r(KSt,"ctrl"),KSt.forEach(t),jKo=r(GDe," \u2014 "),$W=n(GDe,"A",{href:!0});var ZSt=s($W);DKo=r(ZSt,"CTRLForSequenceClassification"),ZSt.forEach(t),GKo=r(GDe," (CTRL model)"),GDe.forEach(t),OKo=i(D),bF=n(D,"LI",{});var ODe=s(bF);lve=n(ODe,"STRONG",{});var eRt=s(lve);VKo=r(eRt,"data2vec-text"),eRt.forEach(t),XKo=r(ODe," \u2014 "),kW=n(ODe,"A",{href:!0});var oRt=s(kW);zKo=r(oRt,"Data2VecTextForSequenceClassification"),oRt.forEach(t),QKo=r(ODe," (Data2VecText model)"),ODe.forEach(t),WKo=i(D),vF=n(D,"LI",{});var VDe=s(vF);ive=n(VDe,"STRONG",{});var rRt=s(ive);UKo=r(rRt,"deberta"),rRt.forEach(t),HKo=r(VDe," \u2014 "),SW=n(VDe,"A",{href:!0});var tRt=s(SW);JKo=r(tRt,"DebertaForSequenceClassification"),tRt.forEach(t),YKo=r(VDe," (DeBERTa model)"),VDe.forEach(t),KKo=i(D),FF=n(D,"LI",{});var XDe=s(FF);dve=n(XDe,"STRONG",{});var aRt=s(dve);ZKo=r(aRt,"deberta-v2"),aRt.forEach(t),eZo=r(XDe," \u2014 "),RW=n(XDe,"A",{href:!0});var nRt=s(RW);oZo=r(nRt,"DebertaV2ForSequenceClassification"),nRt.forEach(t),rZo=r(XDe," (DeBERTa-v2 model)"),XDe.forEach(t),tZo=i(D),TF=n(D,"LI",{});var zDe=s(TF);cve=n(zDe,"STRONG",{});var sRt=s(cve);aZo=r(sRt,"distilbert"),sRt.forEach(t),nZo=r(zDe," \u2014 "),PW=n(zDe,"A",{href:!0});var lRt=s(PW);sZo=r(lRt,"DistilBertForSequenceClassification"),lRt.forEach(t),lZo=r(zDe," (DistilBERT model)"),zDe.forEach(t),iZo=i(D),MF=n(D,"LI",{});var QDe=s(MF);mve=n(QDe,"STRONG",{});var iRt=s(mve);dZo=r(iRt,"electra"),iRt.forEach(t),cZo=r(QDe," \u2014 "),BW=n(QDe,"A",{href:!0});var dRt=s(BW);mZo=r(dRt,"ElectraForSequenceClassification"),dRt.forEach(t),fZo=r(QDe," (ELECTRA model)"),QDe.forEach(t),gZo=i(D),EF=n(D,"LI",{});var WDe=s(EF);fve=n(WDe,"STRONG",{});var cRt=s(fve);hZo=r(cRt,"ernie"),cRt.forEach(t),uZo=r(WDe," \u2014 "),IW=n(WDe,"A",{href:!0});var mRt=s(IW);pZo=r(mRt,"ErnieForSequenceClassification"),mRt.forEach(t),_Zo=r(WDe," (ERNIE model)"),WDe.forEach(t),bZo=i(D),CF=n(D,"LI",{});var UDe=s(CF);gve=n(UDe,"STRONG",{});var fRt=s(gve);vZo=r(fRt,"flaubert"),fRt.forEach(t),FZo=r(UDe," \u2014 "),NW=n(UDe,"A",{href:!0});var gRt=s(NW);TZo=r(gRt,"FlaubertForSequenceClassification"),gRt.forEach(t),MZo=r(UDe," (FlauBERT model)"),UDe.forEach(t),EZo=i(D),wF=n(D,"LI",{});var HDe=s(wF);hve=n(HDe,"STRONG",{});var hRt=s(hve);CZo=r(hRt,"fnet"),hRt.forEach(t),wZo=r(HDe," \u2014 "),qW=n(HDe,"A",{href:!0});var uRt=s(qW);AZo=r(uRt,"FNetForSequenceClassification"),uRt.forEach(t),LZo=r(HDe," (FNet model)"),HDe.forEach(t),yZo=i(D),AF=n(D,"LI",{});var JDe=s(AF);uve=n(JDe,"STRONG",{});var pRt=s(uve);xZo=r(pRt,"funnel"),pRt.forEach(t),$Zo=r(JDe," \u2014 "),jW=n(JDe,"A",{href:!0});var _Rt=s(jW);kZo=r(_Rt,"FunnelForSequenceClassification"),_Rt.forEach(t),SZo=r(JDe," (Funnel Transformer model)"),JDe.forEach(t),RZo=i(D),LF=n(D,"LI",{});var YDe=s(LF);pve=n(YDe,"STRONG",{});var bRt=s(pve);PZo=r(bRt,"gpt2"),bRt.forEach(t),BZo=r(YDe," \u2014 "),DW=n(YDe,"A",{href:!0});var vRt=s(DW);IZo=r(vRt,"GPT2ForSequenceClassification"),vRt.forEach(t),NZo=r(YDe," (OpenAI GPT-2 model)"),YDe.forEach(t),qZo=i(D),yF=n(D,"LI",{});var KDe=s(yF);_ve=n(KDe,"STRONG",{});var FRt=s(_ve);jZo=r(FRt,"gpt_neo"),FRt.forEach(t),DZo=r(KDe," \u2014 "),GW=n(KDe,"A",{href:!0});var TRt=s(GW);GZo=r(TRt,"GPTNeoForSequenceClassification"),TRt.forEach(t),OZo=r(KDe," (GPT Neo model)"),KDe.forEach(t),VZo=i(D),xF=n(D,"LI",{});var ZDe=s(xF);bve=n(ZDe,"STRONG",{});var MRt=s(bve);XZo=r(MRt,"gptj"),MRt.forEach(t),zZo=r(ZDe," \u2014 "),OW=n(ZDe,"A",{href:!0});var ERt=s(OW);QZo=r(ERt,"GPTJForSequenceClassification"),ERt.forEach(t),WZo=r(ZDe," (GPT-J model)"),ZDe.forEach(t),UZo=i(D),$F=n(D,"LI",{});var eGe=s($F);vve=n(eGe,"STRONG",{});var CRt=s(vve);HZo=r(CRt,"ibert"),CRt.forEach(t),JZo=r(eGe," \u2014 "),VW=n(eGe,"A",{href:!0});var wRt=s(VW);YZo=r(wRt,"IBertForSequenceClassification"),wRt.forEach(t),KZo=r(eGe," (I-BERT model)"),eGe.forEach(t),ZZo=i(D),kF=n(D,"LI",{});var oGe=s(kF);Fve=n(oGe,"STRONG",{});var ARt=s(Fve);eer=r(ARt,"layoutlm"),ARt.forEach(t),oer=r(oGe," \u2014 "),XW=n(oGe,"A",{href:!0});var LRt=s(XW);rer=r(LRt,"LayoutLMForSequenceClassification"),LRt.forEach(t),ter=r(oGe," (LayoutLM model)"),oGe.forEach(t),aer=i(D),SF=n(D,"LI",{});var rGe=s(SF);Tve=n(rGe,"STRONG",{});var yRt=s(Tve);ner=r(yRt,"layoutlmv2"),yRt.forEach(t),ser=r(rGe," \u2014 "),zW=n(rGe,"A",{href:!0});var xRt=s(zW);ler=r(xRt,"LayoutLMv2ForSequenceClassification"),xRt.forEach(t),ier=r(rGe," (LayoutLMv2 model)"),rGe.forEach(t),der=i(D),RF=n(D,"LI",{});var tGe=s(RF);Mve=n(tGe,"STRONG",{});var $Rt=s(Mve);cer=r($Rt,"layoutlmv3"),$Rt.forEach(t),mer=r(tGe," \u2014 "),QW=n(tGe,"A",{href:!0});var kRt=s(QW);fer=r(kRt,"LayoutLMv3ForSequenceClassification"),kRt.forEach(t),ger=r(tGe," (LayoutLMv3 model)"),tGe.forEach(t),her=i(D),PF=n(D,"LI",{});var aGe=s(PF);Eve=n(aGe,"STRONG",{});var SRt=s(Eve);uer=r(SRt,"led"),SRt.forEach(t),per=r(aGe," \u2014 "),WW=n(aGe,"A",{href:!0});var RRt=s(WW);_er=r(RRt,"LEDForSequenceClassification"),RRt.forEach(t),ber=r(aGe," (LED model)"),aGe.forEach(t),ver=i(D),BF=n(D,"LI",{});var nGe=s(BF);Cve=n(nGe,"STRONG",{});var PRt=s(Cve);Fer=r(PRt,"longformer"),PRt.forEach(t),Ter=r(nGe," \u2014 "),UW=n(nGe,"A",{href:!0});var BRt=s(UW);Mer=r(BRt,"LongformerForSequenceClassification"),BRt.forEach(t),Eer=r(nGe," (Longformer model)"),nGe.forEach(t),Cer=i(D),IF=n(D,"LI",{});var sGe=s(IF);wve=n(sGe,"STRONG",{});var IRt=s(wve);wer=r(IRt,"luke"),IRt.forEach(t),Aer=r(sGe," \u2014 "),HW=n(sGe,"A",{href:!0});var NRt=s(HW);Ler=r(NRt,"LukeForSequenceClassification"),NRt.forEach(t),yer=r(sGe," (LUKE model)"),sGe.forEach(t),xer=i(D),NF=n(D,"LI",{});var lGe=s(NF);Ave=n(lGe,"STRONG",{});var qRt=s(Ave);$er=r(qRt,"mbart"),qRt.forEach(t),ker=r(lGe," \u2014 "),JW=n(lGe,"A",{href:!0});var jRt=s(JW);Ser=r(jRt,"MBartForSequenceClassification"),jRt.forEach(t),Rer=r(lGe," (mBART model)"),lGe.forEach(t),Per=i(D),qF=n(D,"LI",{});var iGe=s(qF);Lve=n(iGe,"STRONG",{});var DRt=s(Lve);Ber=r(DRt,"megatron-bert"),DRt.forEach(t),Ier=r(iGe," \u2014 "),YW=n(iGe,"A",{href:!0});var GRt=s(YW);Ner=r(GRt,"MegatronBertForSequenceClassification"),GRt.forEach(t),qer=r(iGe," (Megatron-BERT model)"),iGe.forEach(t),jer=i(D),jF=n(D,"LI",{});var dGe=s(jF);yve=n(dGe,"STRONG",{});var ORt=s(yve);Der=r(ORt,"mobilebert"),ORt.forEach(t),Ger=r(dGe," \u2014 "),KW=n(dGe,"A",{href:!0});var VRt=s(KW);Oer=r(VRt,"MobileBertForSequenceClassification"),VRt.forEach(t),Ver=r(dGe," (MobileBERT model)"),dGe.forEach(t),Xer=i(D),DF=n(D,"LI",{});var cGe=s(DF);xve=n(cGe,"STRONG",{});var XRt=s(xve);zer=r(XRt,"mpnet"),XRt.forEach(t),Qer=r(cGe," \u2014 "),ZW=n(cGe,"A",{href:!0});var zRt=s(ZW);Wer=r(zRt,"MPNetForSequenceClassification"),zRt.forEach(t),Uer=r(cGe," (MPNet model)"),cGe.forEach(t),Her=i(D),GF=n(D,"LI",{});var mGe=s(GF);$ve=n(mGe,"STRONG",{});var QRt=s($ve);Jer=r(QRt,"mvp"),QRt.forEach(t),Yer=r(mGe," \u2014 "),eU=n(mGe,"A",{href:!0});var WRt=s(eU);Ker=r(WRt,"MvpForSequenceClassification"),WRt.forEach(t),Zer=r(mGe," (MVP model)"),mGe.forEach(t),eor=i(D),OF=n(D,"LI",{});var fGe=s(OF);kve=n(fGe,"STRONG",{});var URt=s(kve);oor=r(URt,"nezha"),URt.forEach(t),ror=r(fGe," \u2014 "),oU=n(fGe,"A",{href:!0});var HRt=s(oU);tor=r(HRt,"NezhaForSequenceClassification"),HRt.forEach(t),aor=r(fGe," (Nezha model)"),fGe.forEach(t),nor=i(D),VF=n(D,"LI",{});var gGe=s(VF);Sve=n(gGe,"STRONG",{});var JRt=s(Sve);sor=r(JRt,"nystromformer"),JRt.forEach(t),lor=r(gGe," \u2014 "),rU=n(gGe,"A",{href:!0});var YRt=s(rU);ior=r(YRt,"NystromformerForSequenceClassification"),YRt.forEach(t),dor=r(gGe," (Nystr\xF6mformer model)"),gGe.forEach(t),cor=i(D),XF=n(D,"LI",{});var hGe=s(XF);Rve=n(hGe,"STRONG",{});var KRt=s(Rve);mor=r(KRt,"openai-gpt"),KRt.forEach(t),gor=r(hGe," \u2014 "),tU=n(hGe,"A",{href:!0});var ZRt=s(tU);hor=r(ZRt,"OpenAIGPTForSequenceClassification"),ZRt.forEach(t),uor=r(hGe," (OpenAI GPT model)"),hGe.forEach(t),por=i(D),zF=n(D,"LI",{});var uGe=s(zF);Pve=n(uGe,"STRONG",{});var ePt=s(Pve);_or=r(ePt,"opt"),ePt.forEach(t),bor=r(uGe," \u2014 "),aU=n(uGe,"A",{href:!0});var oPt=s(aU);vor=r(oPt,"OPTForSequenceClassification"),oPt.forEach(t),For=r(uGe," (OPT model)"),uGe.forEach(t),Tor=i(D),QF=n(D,"LI",{});var pGe=s(QF);Bve=n(pGe,"STRONG",{});var rPt=s(Bve);Mor=r(rPt,"perceiver"),rPt.forEach(t),Eor=r(pGe," \u2014 "),nU=n(pGe,"A",{href:!0});var tPt=s(nU);Cor=r(tPt,"PerceiverForSequenceClassification"),tPt.forEach(t),wor=r(pGe," (Perceiver model)"),pGe.forEach(t),Aor=i(D),WF=n(D,"LI",{});var _Ge=s(WF);Ive=n(_Ge,"STRONG",{});var aPt=s(Ive);Lor=r(aPt,"plbart"),aPt.forEach(t),yor=r(_Ge," \u2014 "),sU=n(_Ge,"A",{href:!0});var nPt=s(sU);xor=r(nPt,"PLBartForSequenceClassification"),nPt.forEach(t),$or=r(_Ge," (PLBart model)"),_Ge.forEach(t),kor=i(D),UF=n(D,"LI",{});var bGe=s(UF);Nve=n(bGe,"STRONG",{});var sPt=s(Nve);Sor=r(sPt,"qdqbert"),sPt.forEach(t),Ror=r(bGe," \u2014 "),lU=n(bGe,"A",{href:!0});var lPt=s(lU);Por=r(lPt,"QDQBertForSequenceClassification"),lPt.forEach(t),Bor=r(bGe," (QDQBert model)"),bGe.forEach(t),Ior=i(D),HF=n(D,"LI",{});var vGe=s(HF);qve=n(vGe,"STRONG",{});var iPt=s(qve);Nor=r(iPt,"reformer"),iPt.forEach(t),qor=r(vGe," \u2014 "),iU=n(vGe,"A",{href:!0});var dPt=s(iU);jor=r(dPt,"ReformerForSequenceClassification"),dPt.forEach(t),Dor=r(vGe," (Reformer model)"),vGe.forEach(t),Gor=i(D),JF=n(D,"LI",{});var FGe=s(JF);jve=n(FGe,"STRONG",{});var cPt=s(jve);Oor=r(cPt,"rembert"),cPt.forEach(t),Vor=r(FGe," \u2014 "),dU=n(FGe,"A",{href:!0});var mPt=s(dU);Xor=r(mPt,"RemBertForSequenceClassification"),mPt.forEach(t),zor=r(FGe," (RemBERT model)"),FGe.forEach(t),Qor=i(D),YF=n(D,"LI",{});var TGe=s(YF);Dve=n(TGe,"STRONG",{});var fPt=s(Dve);Wor=r(fPt,"roberta"),fPt.forEach(t),Uor=r(TGe," \u2014 "),cU=n(TGe,"A",{href:!0});var gPt=s(cU);Hor=r(gPt,"RobertaForSequenceClassification"),gPt.forEach(t),Jor=r(TGe," (RoBERTa model)"),TGe.forEach(t),Yor=i(D),KF=n(D,"LI",{});var MGe=s(KF);Gve=n(MGe,"STRONG",{});var hPt=s(Gve);Kor=r(hPt,"roformer"),hPt.forEach(t),Zor=r(MGe," \u2014 "),mU=n(MGe,"A",{href:!0});var uPt=s(mU);err=r(uPt,"RoFormerForSequenceClassification"),uPt.forEach(t),orr=r(MGe," (RoFormer model)"),MGe.forEach(t),rrr=i(D),ZF=n(D,"LI",{});var EGe=s(ZF);Ove=n(EGe,"STRONG",{});var pPt=s(Ove);trr=r(pPt,"squeezebert"),pPt.forEach(t),arr=r(EGe," \u2014 "),fU=n(EGe,"A",{href:!0});var _Pt=s(fU);nrr=r(_Pt,"SqueezeBertForSequenceClassification"),_Pt.forEach(t),srr=r(EGe," (SqueezeBERT model)"),EGe.forEach(t),lrr=i(D),eT=n(D,"LI",{});var CGe=s(eT);Vve=n(CGe,"STRONG",{});var bPt=s(Vve);irr=r(bPt,"tapas"),bPt.forEach(t),drr=r(CGe," \u2014 "),gU=n(CGe,"A",{href:!0});var vPt=s(gU);crr=r(vPt,"TapasForSequenceClassification"),vPt.forEach(t),mrr=r(CGe," (TAPAS model)"),CGe.forEach(t),frr=i(D),oT=n(D,"LI",{});var wGe=s(oT);Xve=n(wGe,"STRONG",{});var FPt=s(Xve);grr=r(FPt,"transfo-xl"),FPt.forEach(t),hrr=r(wGe," \u2014 "),hU=n(wGe,"A",{href:!0});var TPt=s(hU);urr=r(TPt,"TransfoXLForSequenceClassification"),TPt.forEach(t),prr=r(wGe," (Transformer-XL model)"),wGe.forEach(t),_rr=i(D),rT=n(D,"LI",{});var AGe=s(rT);zve=n(AGe,"STRONG",{});var MPt=s(zve);brr=r(MPt,"xlm"),MPt.forEach(t),vrr=r(AGe," \u2014 "),uU=n(AGe,"A",{href:!0});var EPt=s(uU);Frr=r(EPt,"XLMForSequenceClassification"),EPt.forEach(t),Trr=r(AGe," (XLM model)"),AGe.forEach(t),Mrr=i(D),tT=n(D,"LI",{});var LGe=s(tT);Qve=n(LGe,"STRONG",{});var CPt=s(Qve);Err=r(CPt,"xlm-roberta"),CPt.forEach(t),Crr=r(LGe," \u2014 "),pU=n(LGe,"A",{href:!0});var wPt=s(pU);wrr=r(wPt,"XLMRobertaForSequenceClassification"),wPt.forEach(t),Arr=r(LGe," (XLM-RoBERTa model)"),LGe.forEach(t),Lrr=i(D),aT=n(D,"LI",{});var yGe=s(aT);Wve=n(yGe,"STRONG",{});var APt=s(Wve);yrr=r(APt,"xlm-roberta-xl"),APt.forEach(t),xrr=r(yGe," \u2014 "),_U=n(yGe,"A",{href:!0});var LPt=s(_U);$rr=r(LPt,"XLMRobertaXLForSequenceClassification"),LPt.forEach(t),krr=r(yGe," (XLM-RoBERTa-XL model)"),yGe.forEach(t),Srr=i(D),nT=n(D,"LI",{});var xGe=s(nT);Uve=n(xGe,"STRONG",{});var yPt=s(Uve);Rrr=r(yPt,"xlnet"),yPt.forEach(t),Prr=r(xGe," \u2014 "),bU=n(xGe,"A",{href:!0});var xPt=s(bU);Brr=r(xPt,"XLNetForSequenceClassification"),xPt.forEach(t),Irr=r(xGe," (XLNet model)"),xGe.forEach(t),Nrr=i(D),sT=n(D,"LI",{});var $Ge=s(sT);Hve=n($Ge,"STRONG",{});var $Pt=s(Hve);qrr=r($Pt,"yoso"),$Pt.forEach(t),jrr=r($Ge," \u2014 "),vU=n($Ge,"A",{href:!0});var kPt=s(vU);Drr=r(kPt,"YosoForSequenceClassification"),kPt.forEach(t),Grr=r($Ge," (YOSO model)"),$Ge.forEach(t),D.forEach(t),Orr=i(wa),lT=n(wa,"P",{});var kGe=s(lT);Vrr=r(kGe,"The model is set in evaluation mode by default using "),Jve=n(kGe,"CODE",{});var SPt=s(Jve);Xrr=r(SPt,"model.eval()"),SPt.forEach(t),zrr=r(kGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=n(kGe,"CODE",{});var RPt=s(Yve);Qrr=r(RPt,"model.train()"),RPt.forEach(t),kGe.forEach(t),Wrr=i(wa),T(iT.$$.fragment,wa),wa.forEach(t),$l.forEach(t),rKe=i(m),Pd=n(m,"H2",{class:!0});var peo=s(Pd);dT=n(peo,"A",{id:!0,class:!0,href:!0});var PPt=s(dT);Kve=n(PPt,"SPAN",{});var BPt=s(Kve);T(wx.$$.fragment,BPt),BPt.forEach(t),PPt.forEach(t),Urr=i(peo),Zve=n(peo,"SPAN",{});var IPt=s(Zve);Hrr=r(IPt,"AutoModelForMultipleChoice"),IPt.forEach(t),peo.forEach(t),tKe=i(m),Do=n(m,"DIV",{class:!0});var kl=s(Do);T(Ax.$$.fragment,kl),Jrr=i(kl),Bd=n(kl,"P",{});var nle=s(Bd);Yrr=r(nle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FU=n(nle,"A",{href:!0});var NPt=s(FU);Krr=r(NPt,"from_pretrained()"),NPt.forEach(t),Zrr=r(nle," class method or the "),TU=n(nle,"A",{href:!0});var qPt=s(TU);etr=r(qPt,"from_config()"),qPt.forEach(t),otr=r(nle,` class
method.`),nle.forEach(t),rtr=i(kl),Lx=n(kl,"P",{});var _eo=s(Lx);ttr=r(_eo,"This class cannot be instantiated directly using "),eFe=n(_eo,"CODE",{});var jPt=s(eFe);atr=r(jPt,"__init__()"),jPt.forEach(t),ntr=r(_eo," (throws an error)."),_eo.forEach(t),str=i(kl),Et=n(kl,"DIV",{class:!0});var $y=s(Et);T(yx.$$.fragment,$y),ltr=i($y),oFe=n($y,"P",{});var DPt=s(oFe);itr=r(DPt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),DPt.forEach(t),dtr=i($y),Id=n($y,"P",{});var sle=s(Id);ctr=r(sle,`Note:
Loading a model from its configuration file does `),rFe=n(sle,"STRONG",{});var GPt=s(rFe);mtr=r(GPt,"not"),GPt.forEach(t),ftr=r(sle,` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=n(sle,"A",{href:!0});var OPt=s(MU);gtr=r(OPt,"from_pretrained()"),OPt.forEach(t),htr=r(sle," to load the model weights."),sle.forEach(t),utr=i($y),T(cT.$$.fragment,$y),$y.forEach(t),ptr=i(kl),no=n(kl,"DIV",{class:!0});var Aa=s(no);T(xx.$$.fragment,Aa),_tr=i(Aa),tFe=n(Aa,"P",{});var VPt=s(tFe);btr=r(VPt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VPt.forEach(t),vtr=i(Aa),rn=n(Aa,"P",{});var ky=s(rn);Ftr=r(ky,"The model class to instantiate is selected based on the "),aFe=n(ky,"CODE",{});var XPt=s(aFe);Ttr=r(XPt,"model_type"),XPt.forEach(t),Mtr=r(ky,` property of the config object (either
passed as an argument or loaded from `),nFe=n(ky,"CODE",{});var zPt=s(nFe);Etr=r(zPt,"pretrained_model_name_or_path"),zPt.forEach(t),Ctr=r(ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=n(ky,"CODE",{});var QPt=s(sFe);wtr=r(QPt,"pretrained_model_name_or_path"),QPt.forEach(t),Atr=r(ky,":"),ky.forEach(t),Ltr=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);mT=n(ee,"LI",{});var SGe=s(mT);lFe=n(SGe,"STRONG",{});var WPt=s(lFe);ytr=r(WPt,"albert"),WPt.forEach(t),xtr=r(SGe," \u2014 "),EU=n(SGe,"A",{href:!0});var UPt=s(EU);$tr=r(UPt,"AlbertForMultipleChoice"),UPt.forEach(t),ktr=r(SGe," (ALBERT model)"),SGe.forEach(t),Str=i(ee),fT=n(ee,"LI",{});var RGe=s(fT);iFe=n(RGe,"STRONG",{});var HPt=s(iFe);Rtr=r(HPt,"bert"),HPt.forEach(t),Ptr=r(RGe," \u2014 "),CU=n(RGe,"A",{href:!0});var JPt=s(CU);Btr=r(JPt,"BertForMultipleChoice"),JPt.forEach(t),Itr=r(RGe," (BERT model)"),RGe.forEach(t),Ntr=i(ee),gT=n(ee,"LI",{});var PGe=s(gT);dFe=n(PGe,"STRONG",{});var YPt=s(dFe);qtr=r(YPt,"big_bird"),YPt.forEach(t),jtr=r(PGe," \u2014 "),wU=n(PGe,"A",{href:!0});var KPt=s(wU);Dtr=r(KPt,"BigBirdForMultipleChoice"),KPt.forEach(t),Gtr=r(PGe," (BigBird model)"),PGe.forEach(t),Otr=i(ee),hT=n(ee,"LI",{});var BGe=s(hT);cFe=n(BGe,"STRONG",{});var ZPt=s(cFe);Vtr=r(ZPt,"camembert"),ZPt.forEach(t),Xtr=r(BGe," \u2014 "),AU=n(BGe,"A",{href:!0});var eBt=s(AU);ztr=r(eBt,"CamembertForMultipleChoice"),eBt.forEach(t),Qtr=r(BGe," (CamemBERT model)"),BGe.forEach(t),Wtr=i(ee),uT=n(ee,"LI",{});var IGe=s(uT);mFe=n(IGe,"STRONG",{});var oBt=s(mFe);Utr=r(oBt,"canine"),oBt.forEach(t),Htr=r(IGe," \u2014 "),LU=n(IGe,"A",{href:!0});var rBt=s(LU);Jtr=r(rBt,"CanineForMultipleChoice"),rBt.forEach(t),Ytr=r(IGe," (CANINE model)"),IGe.forEach(t),Ktr=i(ee),pT=n(ee,"LI",{});var NGe=s(pT);fFe=n(NGe,"STRONG",{});var tBt=s(fFe);Ztr=r(tBt,"convbert"),tBt.forEach(t),ear=r(NGe," \u2014 "),yU=n(NGe,"A",{href:!0});var aBt=s(yU);oar=r(aBt,"ConvBertForMultipleChoice"),aBt.forEach(t),rar=r(NGe," (ConvBERT model)"),NGe.forEach(t),tar=i(ee),_T=n(ee,"LI",{});var qGe=s(_T);gFe=n(qGe,"STRONG",{});var nBt=s(gFe);aar=r(nBt,"data2vec-text"),nBt.forEach(t),nar=r(qGe," \u2014 "),xU=n(qGe,"A",{href:!0});var sBt=s(xU);sar=r(sBt,"Data2VecTextForMultipleChoice"),sBt.forEach(t),lar=r(qGe," (Data2VecText model)"),qGe.forEach(t),iar=i(ee),bT=n(ee,"LI",{});var jGe=s(bT);hFe=n(jGe,"STRONG",{});var lBt=s(hFe);dar=r(lBt,"deberta-v2"),lBt.forEach(t),car=r(jGe," \u2014 "),$U=n(jGe,"A",{href:!0});var iBt=s($U);mar=r(iBt,"DebertaV2ForMultipleChoice"),iBt.forEach(t),far=r(jGe," (DeBERTa-v2 model)"),jGe.forEach(t),gar=i(ee),vT=n(ee,"LI",{});var DGe=s(vT);uFe=n(DGe,"STRONG",{});var dBt=s(uFe);har=r(dBt,"distilbert"),dBt.forEach(t),uar=r(DGe," \u2014 "),kU=n(DGe,"A",{href:!0});var cBt=s(kU);par=r(cBt,"DistilBertForMultipleChoice"),cBt.forEach(t),_ar=r(DGe," (DistilBERT model)"),DGe.forEach(t),bar=i(ee),FT=n(ee,"LI",{});var GGe=s(FT);pFe=n(GGe,"STRONG",{});var mBt=s(pFe);Far=r(mBt,"electra"),mBt.forEach(t),Tar=r(GGe," \u2014 "),SU=n(GGe,"A",{href:!0});var fBt=s(SU);Mar=r(fBt,"ElectraForMultipleChoice"),fBt.forEach(t),Ear=r(GGe," (ELECTRA model)"),GGe.forEach(t),Car=i(ee),TT=n(ee,"LI",{});var OGe=s(TT);_Fe=n(OGe,"STRONG",{});var gBt=s(_Fe);war=r(gBt,"ernie"),gBt.forEach(t),Aar=r(OGe," \u2014 "),RU=n(OGe,"A",{href:!0});var hBt=s(RU);Lar=r(hBt,"ErnieForMultipleChoice"),hBt.forEach(t),yar=r(OGe," (ERNIE model)"),OGe.forEach(t),xar=i(ee),MT=n(ee,"LI",{});var VGe=s(MT);bFe=n(VGe,"STRONG",{});var uBt=s(bFe);$ar=r(uBt,"flaubert"),uBt.forEach(t),kar=r(VGe," \u2014 "),PU=n(VGe,"A",{href:!0});var pBt=s(PU);Sar=r(pBt,"FlaubertForMultipleChoice"),pBt.forEach(t),Rar=r(VGe," (FlauBERT model)"),VGe.forEach(t),Par=i(ee),ET=n(ee,"LI",{});var XGe=s(ET);vFe=n(XGe,"STRONG",{});var _Bt=s(vFe);Bar=r(_Bt,"fnet"),_Bt.forEach(t),Iar=r(XGe," \u2014 "),BU=n(XGe,"A",{href:!0});var bBt=s(BU);Nar=r(bBt,"FNetForMultipleChoice"),bBt.forEach(t),qar=r(XGe," (FNet model)"),XGe.forEach(t),jar=i(ee),CT=n(ee,"LI",{});var zGe=s(CT);FFe=n(zGe,"STRONG",{});var vBt=s(FFe);Dar=r(vBt,"funnel"),vBt.forEach(t),Gar=r(zGe," \u2014 "),IU=n(zGe,"A",{href:!0});var FBt=s(IU);Oar=r(FBt,"FunnelForMultipleChoice"),FBt.forEach(t),Var=r(zGe," (Funnel Transformer model)"),zGe.forEach(t),Xar=i(ee),wT=n(ee,"LI",{});var QGe=s(wT);TFe=n(QGe,"STRONG",{});var TBt=s(TFe);zar=r(TBt,"ibert"),TBt.forEach(t),Qar=r(QGe," \u2014 "),NU=n(QGe,"A",{href:!0});var MBt=s(NU);War=r(MBt,"IBertForMultipleChoice"),MBt.forEach(t),Uar=r(QGe," (I-BERT model)"),QGe.forEach(t),Har=i(ee),AT=n(ee,"LI",{});var WGe=s(AT);MFe=n(WGe,"STRONG",{});var EBt=s(MFe);Jar=r(EBt,"longformer"),EBt.forEach(t),Yar=r(WGe," \u2014 "),qU=n(WGe,"A",{href:!0});var CBt=s(qU);Kar=r(CBt,"LongformerForMultipleChoice"),CBt.forEach(t),Zar=r(WGe," (Longformer model)"),WGe.forEach(t),enr=i(ee),LT=n(ee,"LI",{});var UGe=s(LT);EFe=n(UGe,"STRONG",{});var wBt=s(EFe);onr=r(wBt,"luke"),wBt.forEach(t),rnr=r(UGe," \u2014 "),jU=n(UGe,"A",{href:!0});var ABt=s(jU);tnr=r(ABt,"LukeForMultipleChoice"),ABt.forEach(t),anr=r(UGe," (LUKE model)"),UGe.forEach(t),nnr=i(ee),yT=n(ee,"LI",{});var HGe=s(yT);CFe=n(HGe,"STRONG",{});var LBt=s(CFe);snr=r(LBt,"megatron-bert"),LBt.forEach(t),lnr=r(HGe," \u2014 "),DU=n(HGe,"A",{href:!0});var yBt=s(DU);inr=r(yBt,"MegatronBertForMultipleChoice"),yBt.forEach(t),dnr=r(HGe," (Megatron-BERT model)"),HGe.forEach(t),cnr=i(ee),xT=n(ee,"LI",{});var JGe=s(xT);wFe=n(JGe,"STRONG",{});var xBt=s(wFe);mnr=r(xBt,"mobilebert"),xBt.forEach(t),fnr=r(JGe," \u2014 "),GU=n(JGe,"A",{href:!0});var $Bt=s(GU);gnr=r($Bt,"MobileBertForMultipleChoice"),$Bt.forEach(t),hnr=r(JGe," (MobileBERT model)"),JGe.forEach(t),unr=i(ee),$T=n(ee,"LI",{});var YGe=s($T);AFe=n(YGe,"STRONG",{});var kBt=s(AFe);pnr=r(kBt,"mpnet"),kBt.forEach(t),_nr=r(YGe," \u2014 "),OU=n(YGe,"A",{href:!0});var SBt=s(OU);bnr=r(SBt,"MPNetForMultipleChoice"),SBt.forEach(t),vnr=r(YGe," (MPNet model)"),YGe.forEach(t),Fnr=i(ee),kT=n(ee,"LI",{});var KGe=s(kT);LFe=n(KGe,"STRONG",{});var RBt=s(LFe);Tnr=r(RBt,"nezha"),RBt.forEach(t),Mnr=r(KGe," \u2014 "),VU=n(KGe,"A",{href:!0});var PBt=s(VU);Enr=r(PBt,"NezhaForMultipleChoice"),PBt.forEach(t),Cnr=r(KGe," (Nezha model)"),KGe.forEach(t),wnr=i(ee),ST=n(ee,"LI",{});var ZGe=s(ST);yFe=n(ZGe,"STRONG",{});var BBt=s(yFe);Anr=r(BBt,"nystromformer"),BBt.forEach(t),Lnr=r(ZGe," \u2014 "),XU=n(ZGe,"A",{href:!0});var IBt=s(XU);ynr=r(IBt,"NystromformerForMultipleChoice"),IBt.forEach(t),xnr=r(ZGe," (Nystr\xF6mformer model)"),ZGe.forEach(t),$nr=i(ee),RT=n(ee,"LI",{});var eOe=s(RT);xFe=n(eOe,"STRONG",{});var NBt=s(xFe);knr=r(NBt,"qdqbert"),NBt.forEach(t),Snr=r(eOe," \u2014 "),zU=n(eOe,"A",{href:!0});var qBt=s(zU);Rnr=r(qBt,"QDQBertForMultipleChoice"),qBt.forEach(t),Pnr=r(eOe," (QDQBert model)"),eOe.forEach(t),Bnr=i(ee),PT=n(ee,"LI",{});var oOe=s(PT);$Fe=n(oOe,"STRONG",{});var jBt=s($Fe);Inr=r(jBt,"rembert"),jBt.forEach(t),Nnr=r(oOe," \u2014 "),QU=n(oOe,"A",{href:!0});var DBt=s(QU);qnr=r(DBt,"RemBertForMultipleChoice"),DBt.forEach(t),jnr=r(oOe," (RemBERT model)"),oOe.forEach(t),Dnr=i(ee),BT=n(ee,"LI",{});var rOe=s(BT);kFe=n(rOe,"STRONG",{});var GBt=s(kFe);Gnr=r(GBt,"roberta"),GBt.forEach(t),Onr=r(rOe," \u2014 "),WU=n(rOe,"A",{href:!0});var OBt=s(WU);Vnr=r(OBt,"RobertaForMultipleChoice"),OBt.forEach(t),Xnr=r(rOe," (RoBERTa model)"),rOe.forEach(t),znr=i(ee),IT=n(ee,"LI",{});var tOe=s(IT);SFe=n(tOe,"STRONG",{});var VBt=s(SFe);Qnr=r(VBt,"roformer"),VBt.forEach(t),Wnr=r(tOe," \u2014 "),UU=n(tOe,"A",{href:!0});var XBt=s(UU);Unr=r(XBt,"RoFormerForMultipleChoice"),XBt.forEach(t),Hnr=r(tOe," (RoFormer model)"),tOe.forEach(t),Jnr=i(ee),NT=n(ee,"LI",{});var aOe=s(NT);RFe=n(aOe,"STRONG",{});var zBt=s(RFe);Ynr=r(zBt,"squeezebert"),zBt.forEach(t),Knr=r(aOe," \u2014 "),HU=n(aOe,"A",{href:!0});var QBt=s(HU);Znr=r(QBt,"SqueezeBertForMultipleChoice"),QBt.forEach(t),esr=r(aOe," (SqueezeBERT model)"),aOe.forEach(t),osr=i(ee),qT=n(ee,"LI",{});var nOe=s(qT);PFe=n(nOe,"STRONG",{});var WBt=s(PFe);rsr=r(WBt,"xlm"),WBt.forEach(t),tsr=r(nOe," \u2014 "),JU=n(nOe,"A",{href:!0});var UBt=s(JU);asr=r(UBt,"XLMForMultipleChoice"),UBt.forEach(t),nsr=r(nOe," (XLM model)"),nOe.forEach(t),ssr=i(ee),jT=n(ee,"LI",{});var sOe=s(jT);BFe=n(sOe,"STRONG",{});var HBt=s(BFe);lsr=r(HBt,"xlm-roberta"),HBt.forEach(t),isr=r(sOe," \u2014 "),YU=n(sOe,"A",{href:!0});var JBt=s(YU);dsr=r(JBt,"XLMRobertaForMultipleChoice"),JBt.forEach(t),csr=r(sOe," (XLM-RoBERTa model)"),sOe.forEach(t),msr=i(ee),DT=n(ee,"LI",{});var lOe=s(DT);IFe=n(lOe,"STRONG",{});var YBt=s(IFe);fsr=r(YBt,"xlm-roberta-xl"),YBt.forEach(t),gsr=r(lOe," \u2014 "),KU=n(lOe,"A",{href:!0});var KBt=s(KU);hsr=r(KBt,"XLMRobertaXLForMultipleChoice"),KBt.forEach(t),usr=r(lOe," (XLM-RoBERTa-XL model)"),lOe.forEach(t),psr=i(ee),GT=n(ee,"LI",{});var iOe=s(GT);NFe=n(iOe,"STRONG",{});var ZBt=s(NFe);_sr=r(ZBt,"xlnet"),ZBt.forEach(t),bsr=r(iOe," \u2014 "),ZU=n(iOe,"A",{href:!0});var eIt=s(ZU);vsr=r(eIt,"XLNetForMultipleChoice"),eIt.forEach(t),Fsr=r(iOe," (XLNet model)"),iOe.forEach(t),Tsr=i(ee),OT=n(ee,"LI",{});var dOe=s(OT);qFe=n(dOe,"STRONG",{});var oIt=s(qFe);Msr=r(oIt,"yoso"),oIt.forEach(t),Esr=r(dOe," \u2014 "),eH=n(dOe,"A",{href:!0});var rIt=s(eH);Csr=r(rIt,"YosoForMultipleChoice"),rIt.forEach(t),wsr=r(dOe," (YOSO model)"),dOe.forEach(t),ee.forEach(t),Asr=i(Aa),VT=n(Aa,"P",{});var cOe=s(VT);Lsr=r(cOe,"The model is set in evaluation mode by default using "),jFe=n(cOe,"CODE",{});var tIt=s(jFe);ysr=r(tIt,"model.eval()"),tIt.forEach(t),xsr=r(cOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DFe=n(cOe,"CODE",{});var aIt=s(DFe);$sr=r(aIt,"model.train()"),aIt.forEach(t),cOe.forEach(t),ksr=i(Aa),T(XT.$$.fragment,Aa),Aa.forEach(t),kl.forEach(t),aKe=i(m),Nd=n(m,"H2",{class:!0});var beo=s(Nd);zT=n(beo,"A",{id:!0,class:!0,href:!0});var nIt=s(zT);GFe=n(nIt,"SPAN",{});var sIt=s(GFe);T($x.$$.fragment,sIt),sIt.forEach(t),nIt.forEach(t),Ssr=i(beo),OFe=n(beo,"SPAN",{});var lIt=s(OFe);Rsr=r(lIt,"AutoModelForNextSentencePrediction"),lIt.forEach(t),beo.forEach(t),nKe=i(m),Go=n(m,"DIV",{class:!0});var Sl=s(Go);T(kx.$$.fragment,Sl),Psr=i(Sl),qd=n(Sl,"P",{});var lle=s(qd);Bsr=r(lle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oH=n(lle,"A",{href:!0});var iIt=s(oH);Isr=r(iIt,"from_pretrained()"),iIt.forEach(t),Nsr=r(lle," class method or the "),rH=n(lle,"A",{href:!0});var dIt=s(rH);qsr=r(dIt,"from_config()"),dIt.forEach(t),jsr=r(lle,` class
method.`),lle.forEach(t),Dsr=i(Sl),Sx=n(Sl,"P",{});var veo=s(Sx);Gsr=r(veo,"This class cannot be instantiated directly using "),VFe=n(veo,"CODE",{});var cIt=s(VFe);Osr=r(cIt,"__init__()"),cIt.forEach(t),Vsr=r(veo," (throws an error)."),veo.forEach(t),Xsr=i(Sl),Ct=n(Sl,"DIV",{class:!0});var Sy=s(Ct);T(Rx.$$.fragment,Sy),zsr=i(Sy),XFe=n(Sy,"P",{});var mIt=s(XFe);Qsr=r(mIt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),mIt.forEach(t),Wsr=i(Sy),jd=n(Sy,"P",{});var ile=s(jd);Usr=r(ile,`Note:
Loading a model from its configuration file does `),zFe=n(ile,"STRONG",{});var fIt=s(zFe);Hsr=r(fIt,"not"),fIt.forEach(t),Jsr=r(ile,` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=n(ile,"A",{href:!0});var gIt=s(tH);Ysr=r(gIt,"from_pretrained()"),gIt.forEach(t),Ksr=r(ile," to load the model weights."),ile.forEach(t),Zsr=i(Sy),T(QT.$$.fragment,Sy),Sy.forEach(t),elr=i(Sl),so=n(Sl,"DIV",{class:!0});var La=s(so);T(Px.$$.fragment,La),olr=i(La),QFe=n(La,"P",{});var hIt=s(QFe);rlr=r(hIt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hIt.forEach(t),tlr=i(La),tn=n(La,"P",{});var Ry=s(tn);alr=r(Ry,"The model class to instantiate is selected based on the "),WFe=n(Ry,"CODE",{});var uIt=s(WFe);nlr=r(uIt,"model_type"),uIt.forEach(t),slr=r(Ry,` property of the config object (either
passed as an argument or loaded from `),UFe=n(Ry,"CODE",{});var pIt=s(UFe);llr=r(pIt,"pretrained_model_name_or_path"),pIt.forEach(t),ilr=r(Ry,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HFe=n(Ry,"CODE",{});var _It=s(HFe);dlr=r(_It,"pretrained_model_name_or_path"),_It.forEach(t),clr=r(Ry,":"),Ry.forEach(t),mlr=i(La),Ue=n(La,"UL",{});var ct=s(Ue);WT=n(ct,"LI",{});var mOe=s(WT);JFe=n(mOe,"STRONG",{});var bIt=s(JFe);flr=r(bIt,"bert"),bIt.forEach(t),glr=r(mOe," \u2014 "),aH=n(mOe,"A",{href:!0});var vIt=s(aH);hlr=r(vIt,"BertForNextSentencePrediction"),vIt.forEach(t),ulr=r(mOe," (BERT model)"),mOe.forEach(t),plr=i(ct),UT=n(ct,"LI",{});var fOe=s(UT);YFe=n(fOe,"STRONG",{});var FIt=s(YFe);_lr=r(FIt,"ernie"),FIt.forEach(t),blr=r(fOe," \u2014 "),nH=n(fOe,"A",{href:!0});var TIt=s(nH);vlr=r(TIt,"ErnieForNextSentencePrediction"),TIt.forEach(t),Flr=r(fOe," (ERNIE model)"),fOe.forEach(t),Tlr=i(ct),HT=n(ct,"LI",{});var gOe=s(HT);KFe=n(gOe,"STRONG",{});var MIt=s(KFe);Mlr=r(MIt,"fnet"),MIt.forEach(t),Elr=r(gOe," \u2014 "),sH=n(gOe,"A",{href:!0});var EIt=s(sH);Clr=r(EIt,"FNetForNextSentencePrediction"),EIt.forEach(t),wlr=r(gOe," (FNet model)"),gOe.forEach(t),Alr=i(ct),JT=n(ct,"LI",{});var hOe=s(JT);ZFe=n(hOe,"STRONG",{});var CIt=s(ZFe);Llr=r(CIt,"megatron-bert"),CIt.forEach(t),ylr=r(hOe," \u2014 "),lH=n(hOe,"A",{href:!0});var wIt=s(lH);xlr=r(wIt,"MegatronBertForNextSentencePrediction"),wIt.forEach(t),$lr=r(hOe," (Megatron-BERT model)"),hOe.forEach(t),klr=i(ct),YT=n(ct,"LI",{});var uOe=s(YT);eTe=n(uOe,"STRONG",{});var AIt=s(eTe);Slr=r(AIt,"mobilebert"),AIt.forEach(t),Rlr=r(uOe," \u2014 "),iH=n(uOe,"A",{href:!0});var LIt=s(iH);Plr=r(LIt,"MobileBertForNextSentencePrediction"),LIt.forEach(t),Blr=r(uOe," (MobileBERT model)"),uOe.forEach(t),Ilr=i(ct),KT=n(ct,"LI",{});var pOe=s(KT);oTe=n(pOe,"STRONG",{});var yIt=s(oTe);Nlr=r(yIt,"nezha"),yIt.forEach(t),qlr=r(pOe," \u2014 "),dH=n(pOe,"A",{href:!0});var xIt=s(dH);jlr=r(xIt,"NezhaForNextSentencePrediction"),xIt.forEach(t),Dlr=r(pOe," (Nezha model)"),pOe.forEach(t),Glr=i(ct),ZT=n(ct,"LI",{});var _Oe=s(ZT);rTe=n(_Oe,"STRONG",{});var $It=s(rTe);Olr=r($It,"qdqbert"),$It.forEach(t),Vlr=r(_Oe," \u2014 "),cH=n(_Oe,"A",{href:!0});var kIt=s(cH);Xlr=r(kIt,"QDQBertForNextSentencePrediction"),kIt.forEach(t),zlr=r(_Oe," (QDQBert model)"),_Oe.forEach(t),ct.forEach(t),Qlr=i(La),eM=n(La,"P",{});var bOe=s(eM);Wlr=r(bOe,"The model is set in evaluation mode by default using "),tTe=n(bOe,"CODE",{});var SIt=s(tTe);Ulr=r(SIt,"model.eval()"),SIt.forEach(t),Hlr=r(bOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aTe=n(bOe,"CODE",{});var RIt=s(aTe);Jlr=r(RIt,"model.train()"),RIt.forEach(t),bOe.forEach(t),Ylr=i(La),T(oM.$$.fragment,La),La.forEach(t),Sl.forEach(t),sKe=i(m),Dd=n(m,"H2",{class:!0});var Feo=s(Dd);rM=n(Feo,"A",{id:!0,class:!0,href:!0});var PIt=s(rM);nTe=n(PIt,"SPAN",{});var BIt=s(nTe);T(Bx.$$.fragment,BIt),BIt.forEach(t),PIt.forEach(t),Klr=i(Feo),sTe=n(Feo,"SPAN",{});var IIt=s(sTe);Zlr=r(IIt,"AutoModelForTokenClassification"),IIt.forEach(t),Feo.forEach(t),lKe=i(m),Oo=n(m,"DIV",{class:!0});var Rl=s(Oo);T(Ix.$$.fragment,Rl),eir=i(Rl),Gd=n(Rl,"P",{});var dle=s(Gd);oir=r(dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mH=n(dle,"A",{href:!0});var NIt=s(mH);rir=r(NIt,"from_pretrained()"),NIt.forEach(t),tir=r(dle," class method or the "),fH=n(dle,"A",{href:!0});var qIt=s(fH);air=r(qIt,"from_config()"),qIt.forEach(t),nir=r(dle,` class
method.`),dle.forEach(t),sir=i(Rl),Nx=n(Rl,"P",{});var Teo=s(Nx);lir=r(Teo,"This class cannot be instantiated directly using "),lTe=n(Teo,"CODE",{});var jIt=s(lTe);iir=r(jIt,"__init__()"),jIt.forEach(t),dir=r(Teo," (throws an error)."),Teo.forEach(t),cir=i(Rl),wt=n(Rl,"DIV",{class:!0});var Py=s(wt);T(qx.$$.fragment,Py),mir=i(Py),iTe=n(Py,"P",{});var DIt=s(iTe);fir=r(DIt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DIt.forEach(t),gir=i(Py),Od=n(Py,"P",{});var cle=s(Od);hir=r(cle,`Note:
Loading a model from its configuration file does `),dTe=n(cle,"STRONG",{});var GIt=s(dTe);uir=r(GIt,"not"),GIt.forEach(t),pir=r(cle,` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=n(cle,"A",{href:!0});var OIt=s(gH);_ir=r(OIt,"from_pretrained()"),OIt.forEach(t),bir=r(cle," to load the model weights."),cle.forEach(t),vir=i(Py),T(tM.$$.fragment,Py),Py.forEach(t),Fir=i(Rl),lo=n(Rl,"DIV",{class:!0});var ya=s(lo);T(jx.$$.fragment,ya),Tir=i(ya),cTe=n(ya,"P",{});var VIt=s(cTe);Mir=r(VIt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VIt.forEach(t),Eir=i(ya),an=n(ya,"P",{});var By=s(an);Cir=r(By,"The model class to instantiate is selected based on the "),mTe=n(By,"CODE",{});var XIt=s(mTe);wir=r(XIt,"model_type"),XIt.forEach(t),Air=r(By,` property of the config object (either
passed as an argument or loaded from `),fTe=n(By,"CODE",{});var zIt=s(fTe);Lir=r(zIt,"pretrained_model_name_or_path"),zIt.forEach(t),yir=r(By,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gTe=n(By,"CODE",{});var QIt=s(gTe);xir=r(QIt,"pretrained_model_name_or_path"),QIt.forEach(t),$ir=r(By,":"),By.forEach(t),kir=i(ya),H=n(ya,"UL",{});var K=s(H);aM=n(K,"LI",{});var vOe=s(aM);hTe=n(vOe,"STRONG",{});var WIt=s(hTe);Sir=r(WIt,"albert"),WIt.forEach(t),Rir=r(vOe," \u2014 "),hH=n(vOe,"A",{href:!0});var UIt=s(hH);Pir=r(UIt,"AlbertForTokenClassification"),UIt.forEach(t),Bir=r(vOe," (ALBERT model)"),vOe.forEach(t),Iir=i(K),nM=n(K,"LI",{});var FOe=s(nM);uTe=n(FOe,"STRONG",{});var HIt=s(uTe);Nir=r(HIt,"bert"),HIt.forEach(t),qir=r(FOe," \u2014 "),uH=n(FOe,"A",{href:!0});var JIt=s(uH);jir=r(JIt,"BertForTokenClassification"),JIt.forEach(t),Dir=r(FOe," (BERT model)"),FOe.forEach(t),Gir=i(K),sM=n(K,"LI",{});var TOe=s(sM);pTe=n(TOe,"STRONG",{});var YIt=s(pTe);Oir=r(YIt,"big_bird"),YIt.forEach(t),Vir=r(TOe," \u2014 "),pH=n(TOe,"A",{href:!0});var KIt=s(pH);Xir=r(KIt,"BigBirdForTokenClassification"),KIt.forEach(t),zir=r(TOe," (BigBird model)"),TOe.forEach(t),Qir=i(K),lM=n(K,"LI",{});var MOe=s(lM);_Te=n(MOe,"STRONG",{});var ZIt=s(_Te);Wir=r(ZIt,"bloom"),ZIt.forEach(t),Uir=r(MOe," \u2014 "),_H=n(MOe,"A",{href:!0});var eNt=s(_H);Hir=r(eNt,"BloomForTokenClassification"),eNt.forEach(t),Jir=r(MOe," (BLOOM model)"),MOe.forEach(t),Yir=i(K),iM=n(K,"LI",{});var EOe=s(iM);bTe=n(EOe,"STRONG",{});var oNt=s(bTe);Kir=r(oNt,"camembert"),oNt.forEach(t),Zir=r(EOe," \u2014 "),bH=n(EOe,"A",{href:!0});var rNt=s(bH);edr=r(rNt,"CamembertForTokenClassification"),rNt.forEach(t),odr=r(EOe," (CamemBERT model)"),EOe.forEach(t),rdr=i(K),dM=n(K,"LI",{});var COe=s(dM);vTe=n(COe,"STRONG",{});var tNt=s(vTe);tdr=r(tNt,"canine"),tNt.forEach(t),adr=r(COe," \u2014 "),vH=n(COe,"A",{href:!0});var aNt=s(vH);ndr=r(aNt,"CanineForTokenClassification"),aNt.forEach(t),sdr=r(COe," (CANINE model)"),COe.forEach(t),ldr=i(K),cM=n(K,"LI",{});var wOe=s(cM);FTe=n(wOe,"STRONG",{});var nNt=s(FTe);idr=r(nNt,"convbert"),nNt.forEach(t),ddr=r(wOe," \u2014 "),FH=n(wOe,"A",{href:!0});var sNt=s(FH);cdr=r(sNt,"ConvBertForTokenClassification"),sNt.forEach(t),mdr=r(wOe," (ConvBERT model)"),wOe.forEach(t),fdr=i(K),mM=n(K,"LI",{});var AOe=s(mM);TTe=n(AOe,"STRONG",{});var lNt=s(TTe);gdr=r(lNt,"data2vec-text"),lNt.forEach(t),hdr=r(AOe," \u2014 "),TH=n(AOe,"A",{href:!0});var iNt=s(TH);udr=r(iNt,"Data2VecTextForTokenClassification"),iNt.forEach(t),pdr=r(AOe," (Data2VecText model)"),AOe.forEach(t),_dr=i(K),fM=n(K,"LI",{});var LOe=s(fM);MTe=n(LOe,"STRONG",{});var dNt=s(MTe);bdr=r(dNt,"deberta"),dNt.forEach(t),vdr=r(LOe," \u2014 "),MH=n(LOe,"A",{href:!0});var cNt=s(MH);Fdr=r(cNt,"DebertaForTokenClassification"),cNt.forEach(t),Tdr=r(LOe," (DeBERTa model)"),LOe.forEach(t),Mdr=i(K),gM=n(K,"LI",{});var yOe=s(gM);ETe=n(yOe,"STRONG",{});var mNt=s(ETe);Edr=r(mNt,"deberta-v2"),mNt.forEach(t),Cdr=r(yOe," \u2014 "),EH=n(yOe,"A",{href:!0});var fNt=s(EH);wdr=r(fNt,"DebertaV2ForTokenClassification"),fNt.forEach(t),Adr=r(yOe," (DeBERTa-v2 model)"),yOe.forEach(t),Ldr=i(K),hM=n(K,"LI",{});var xOe=s(hM);CTe=n(xOe,"STRONG",{});var gNt=s(CTe);ydr=r(gNt,"distilbert"),gNt.forEach(t),xdr=r(xOe," \u2014 "),CH=n(xOe,"A",{href:!0});var hNt=s(CH);$dr=r(hNt,"DistilBertForTokenClassification"),hNt.forEach(t),kdr=r(xOe," (DistilBERT model)"),xOe.forEach(t),Sdr=i(K),uM=n(K,"LI",{});var $Oe=s(uM);wTe=n($Oe,"STRONG",{});var uNt=s(wTe);Rdr=r(uNt,"electra"),uNt.forEach(t),Pdr=r($Oe," \u2014 "),wH=n($Oe,"A",{href:!0});var pNt=s(wH);Bdr=r(pNt,"ElectraForTokenClassification"),pNt.forEach(t),Idr=r($Oe," (ELECTRA model)"),$Oe.forEach(t),Ndr=i(K),pM=n(K,"LI",{});var kOe=s(pM);ATe=n(kOe,"STRONG",{});var _Nt=s(ATe);qdr=r(_Nt,"ernie"),_Nt.forEach(t),jdr=r(kOe," \u2014 "),AH=n(kOe,"A",{href:!0});var bNt=s(AH);Ddr=r(bNt,"ErnieForTokenClassification"),bNt.forEach(t),Gdr=r(kOe," (ERNIE model)"),kOe.forEach(t),Odr=i(K),_M=n(K,"LI",{});var SOe=s(_M);LTe=n(SOe,"STRONG",{});var vNt=s(LTe);Vdr=r(vNt,"flaubert"),vNt.forEach(t),Xdr=r(SOe," \u2014 "),LH=n(SOe,"A",{href:!0});var FNt=s(LH);zdr=r(FNt,"FlaubertForTokenClassification"),FNt.forEach(t),Qdr=r(SOe," (FlauBERT model)"),SOe.forEach(t),Wdr=i(K),bM=n(K,"LI",{});var ROe=s(bM);yTe=n(ROe,"STRONG",{});var TNt=s(yTe);Udr=r(TNt,"fnet"),TNt.forEach(t),Hdr=r(ROe," \u2014 "),yH=n(ROe,"A",{href:!0});var MNt=s(yH);Jdr=r(MNt,"FNetForTokenClassification"),MNt.forEach(t),Ydr=r(ROe," (FNet model)"),ROe.forEach(t),Kdr=i(K),vM=n(K,"LI",{});var POe=s(vM);xTe=n(POe,"STRONG",{});var ENt=s(xTe);Zdr=r(ENt,"funnel"),ENt.forEach(t),ecr=r(POe," \u2014 "),xH=n(POe,"A",{href:!0});var CNt=s(xH);ocr=r(CNt,"FunnelForTokenClassification"),CNt.forEach(t),rcr=r(POe," (Funnel Transformer model)"),POe.forEach(t),tcr=i(K),FM=n(K,"LI",{});var BOe=s(FM);$Te=n(BOe,"STRONG",{});var wNt=s($Te);acr=r(wNt,"gpt2"),wNt.forEach(t),ncr=r(BOe," \u2014 "),$H=n(BOe,"A",{href:!0});var ANt=s($H);scr=r(ANt,"GPT2ForTokenClassification"),ANt.forEach(t),lcr=r(BOe," (OpenAI GPT-2 model)"),BOe.forEach(t),icr=i(K),TM=n(K,"LI",{});var IOe=s(TM);kTe=n(IOe,"STRONG",{});var LNt=s(kTe);dcr=r(LNt,"ibert"),LNt.forEach(t),ccr=r(IOe," \u2014 "),kH=n(IOe,"A",{href:!0});var yNt=s(kH);mcr=r(yNt,"IBertForTokenClassification"),yNt.forEach(t),fcr=r(IOe," (I-BERT model)"),IOe.forEach(t),gcr=i(K),MM=n(K,"LI",{});var NOe=s(MM);STe=n(NOe,"STRONG",{});var xNt=s(STe);hcr=r(xNt,"layoutlm"),xNt.forEach(t),ucr=r(NOe," \u2014 "),SH=n(NOe,"A",{href:!0});var $Nt=s(SH);pcr=r($Nt,"LayoutLMForTokenClassification"),$Nt.forEach(t),_cr=r(NOe," (LayoutLM model)"),NOe.forEach(t),bcr=i(K),EM=n(K,"LI",{});var qOe=s(EM);RTe=n(qOe,"STRONG",{});var kNt=s(RTe);vcr=r(kNt,"layoutlmv2"),kNt.forEach(t),Fcr=r(qOe," \u2014 "),RH=n(qOe,"A",{href:!0});var SNt=s(RH);Tcr=r(SNt,"LayoutLMv2ForTokenClassification"),SNt.forEach(t),Mcr=r(qOe," (LayoutLMv2 model)"),qOe.forEach(t),Ecr=i(K),CM=n(K,"LI",{});var jOe=s(CM);PTe=n(jOe,"STRONG",{});var RNt=s(PTe);Ccr=r(RNt,"layoutlmv3"),RNt.forEach(t),wcr=r(jOe," \u2014 "),PH=n(jOe,"A",{href:!0});var PNt=s(PH);Acr=r(PNt,"LayoutLMv3ForTokenClassification"),PNt.forEach(t),Lcr=r(jOe," (LayoutLMv3 model)"),jOe.forEach(t),ycr=i(K),wM=n(K,"LI",{});var DOe=s(wM);BTe=n(DOe,"STRONG",{});var BNt=s(BTe);xcr=r(BNt,"longformer"),BNt.forEach(t),$cr=r(DOe," \u2014 "),BH=n(DOe,"A",{href:!0});var INt=s(BH);kcr=r(INt,"LongformerForTokenClassification"),INt.forEach(t),Scr=r(DOe," (Longformer model)"),DOe.forEach(t),Rcr=i(K),AM=n(K,"LI",{});var GOe=s(AM);ITe=n(GOe,"STRONG",{});var NNt=s(ITe);Pcr=r(NNt,"luke"),NNt.forEach(t),Bcr=r(GOe," \u2014 "),IH=n(GOe,"A",{href:!0});var qNt=s(IH);Icr=r(qNt,"LukeForTokenClassification"),qNt.forEach(t),Ncr=r(GOe," (LUKE model)"),GOe.forEach(t),qcr=i(K),LM=n(K,"LI",{});var OOe=s(LM);NTe=n(OOe,"STRONG",{});var jNt=s(NTe);jcr=r(jNt,"megatron-bert"),jNt.forEach(t),Dcr=r(OOe," \u2014 "),NH=n(OOe,"A",{href:!0});var DNt=s(NH);Gcr=r(DNt,"MegatronBertForTokenClassification"),DNt.forEach(t),Ocr=r(OOe," (Megatron-BERT model)"),OOe.forEach(t),Vcr=i(K),yM=n(K,"LI",{});var VOe=s(yM);qTe=n(VOe,"STRONG",{});var GNt=s(qTe);Xcr=r(GNt,"mobilebert"),GNt.forEach(t),zcr=r(VOe," \u2014 "),qH=n(VOe,"A",{href:!0});var ONt=s(qH);Qcr=r(ONt,"MobileBertForTokenClassification"),ONt.forEach(t),Wcr=r(VOe," (MobileBERT model)"),VOe.forEach(t),Ucr=i(K),xM=n(K,"LI",{});var XOe=s(xM);jTe=n(XOe,"STRONG",{});var VNt=s(jTe);Hcr=r(VNt,"mpnet"),VNt.forEach(t),Jcr=r(XOe," \u2014 "),jH=n(XOe,"A",{href:!0});var XNt=s(jH);Ycr=r(XNt,"MPNetForTokenClassification"),XNt.forEach(t),Kcr=r(XOe," (MPNet model)"),XOe.forEach(t),Zcr=i(K),$M=n(K,"LI",{});var zOe=s($M);DTe=n(zOe,"STRONG",{});var zNt=s(DTe);emr=r(zNt,"nezha"),zNt.forEach(t),omr=r(zOe," \u2014 "),DH=n(zOe,"A",{href:!0});var QNt=s(DH);rmr=r(QNt,"NezhaForTokenClassification"),QNt.forEach(t),tmr=r(zOe," (Nezha model)"),zOe.forEach(t),amr=i(K),kM=n(K,"LI",{});var QOe=s(kM);GTe=n(QOe,"STRONG",{});var WNt=s(GTe);nmr=r(WNt,"nystromformer"),WNt.forEach(t),smr=r(QOe," \u2014 "),GH=n(QOe,"A",{href:!0});var UNt=s(GH);lmr=r(UNt,"NystromformerForTokenClassification"),UNt.forEach(t),imr=r(QOe," (Nystr\xF6mformer model)"),QOe.forEach(t),dmr=i(K),SM=n(K,"LI",{});var WOe=s(SM);OTe=n(WOe,"STRONG",{});var HNt=s(OTe);cmr=r(HNt,"qdqbert"),HNt.forEach(t),mmr=r(WOe," \u2014 "),OH=n(WOe,"A",{href:!0});var JNt=s(OH);fmr=r(JNt,"QDQBertForTokenClassification"),JNt.forEach(t),gmr=r(WOe," (QDQBert model)"),WOe.forEach(t),hmr=i(K),RM=n(K,"LI",{});var UOe=s(RM);VTe=n(UOe,"STRONG",{});var YNt=s(VTe);umr=r(YNt,"rembert"),YNt.forEach(t),pmr=r(UOe," \u2014 "),VH=n(UOe,"A",{href:!0});var KNt=s(VH);_mr=r(KNt,"RemBertForTokenClassification"),KNt.forEach(t),bmr=r(UOe," (RemBERT model)"),UOe.forEach(t),vmr=i(K),PM=n(K,"LI",{});var HOe=s(PM);XTe=n(HOe,"STRONG",{});var ZNt=s(XTe);Fmr=r(ZNt,"roberta"),ZNt.forEach(t),Tmr=r(HOe," \u2014 "),XH=n(HOe,"A",{href:!0});var eqt=s(XH);Mmr=r(eqt,"RobertaForTokenClassification"),eqt.forEach(t),Emr=r(HOe," (RoBERTa model)"),HOe.forEach(t),Cmr=i(K),BM=n(K,"LI",{});var JOe=s(BM);zTe=n(JOe,"STRONG",{});var oqt=s(zTe);wmr=r(oqt,"roformer"),oqt.forEach(t),Amr=r(JOe," \u2014 "),zH=n(JOe,"A",{href:!0});var rqt=s(zH);Lmr=r(rqt,"RoFormerForTokenClassification"),rqt.forEach(t),ymr=r(JOe," (RoFormer model)"),JOe.forEach(t),xmr=i(K),IM=n(K,"LI",{});var YOe=s(IM);QTe=n(YOe,"STRONG",{});var tqt=s(QTe);$mr=r(tqt,"squeezebert"),tqt.forEach(t),kmr=r(YOe," \u2014 "),QH=n(YOe,"A",{href:!0});var aqt=s(QH);Smr=r(aqt,"SqueezeBertForTokenClassification"),aqt.forEach(t),Rmr=r(YOe," (SqueezeBERT model)"),YOe.forEach(t),Pmr=i(K),NM=n(K,"LI",{});var KOe=s(NM);WTe=n(KOe,"STRONG",{});var nqt=s(WTe);Bmr=r(nqt,"xlm"),nqt.forEach(t),Imr=r(KOe," \u2014 "),WH=n(KOe,"A",{href:!0});var sqt=s(WH);Nmr=r(sqt,"XLMForTokenClassification"),sqt.forEach(t),qmr=r(KOe," (XLM model)"),KOe.forEach(t),jmr=i(K),qM=n(K,"LI",{});var ZOe=s(qM);UTe=n(ZOe,"STRONG",{});var lqt=s(UTe);Dmr=r(lqt,"xlm-roberta"),lqt.forEach(t),Gmr=r(ZOe," \u2014 "),UH=n(ZOe,"A",{href:!0});var iqt=s(UH);Omr=r(iqt,"XLMRobertaForTokenClassification"),iqt.forEach(t),Vmr=r(ZOe," (XLM-RoBERTa model)"),ZOe.forEach(t),Xmr=i(K),jM=n(K,"LI",{});var eVe=s(jM);HTe=n(eVe,"STRONG",{});var dqt=s(HTe);zmr=r(dqt,"xlm-roberta-xl"),dqt.forEach(t),Qmr=r(eVe," \u2014 "),HH=n(eVe,"A",{href:!0});var cqt=s(HH);Wmr=r(cqt,"XLMRobertaXLForTokenClassification"),cqt.forEach(t),Umr=r(eVe," (XLM-RoBERTa-XL model)"),eVe.forEach(t),Hmr=i(K),DM=n(K,"LI",{});var oVe=s(DM);JTe=n(oVe,"STRONG",{});var mqt=s(JTe);Jmr=r(mqt,"xlnet"),mqt.forEach(t),Ymr=r(oVe," \u2014 "),JH=n(oVe,"A",{href:!0});var fqt=s(JH);Kmr=r(fqt,"XLNetForTokenClassification"),fqt.forEach(t),Zmr=r(oVe," (XLNet model)"),oVe.forEach(t),efr=i(K),GM=n(K,"LI",{});var rVe=s(GM);YTe=n(rVe,"STRONG",{});var gqt=s(YTe);ofr=r(gqt,"yoso"),gqt.forEach(t),rfr=r(rVe," \u2014 "),YH=n(rVe,"A",{href:!0});var hqt=s(YH);tfr=r(hqt,"YosoForTokenClassification"),hqt.forEach(t),afr=r(rVe," (YOSO model)"),rVe.forEach(t),K.forEach(t),nfr=i(ya),OM=n(ya,"P",{});var tVe=s(OM);sfr=r(tVe,"The model is set in evaluation mode by default using "),KTe=n(tVe,"CODE",{});var uqt=s(KTe);lfr=r(uqt,"model.eval()"),uqt.forEach(t),ifr=r(tVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZTe=n(tVe,"CODE",{});var pqt=s(ZTe);dfr=r(pqt,"model.train()"),pqt.forEach(t),tVe.forEach(t),cfr=i(ya),T(VM.$$.fragment,ya),ya.forEach(t),Rl.forEach(t),iKe=i(m),Vd=n(m,"H2",{class:!0});var Meo=s(Vd);XM=n(Meo,"A",{id:!0,class:!0,href:!0});var _qt=s(XM);eMe=n(_qt,"SPAN",{});var bqt=s(eMe);T(Dx.$$.fragment,bqt),bqt.forEach(t),_qt.forEach(t),mfr=i(Meo),oMe=n(Meo,"SPAN",{});var vqt=s(oMe);ffr=r(vqt,"AutoModelForQuestionAnswering"),vqt.forEach(t),Meo.forEach(t),dKe=i(m),Vo=n(m,"DIV",{class:!0});var Pl=s(Vo);T(Gx.$$.fragment,Pl),gfr=i(Pl),Xd=n(Pl,"P",{});var mle=s(Xd);hfr=r(mle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KH=n(mle,"A",{href:!0});var Fqt=s(KH);ufr=r(Fqt,"from_pretrained()"),Fqt.forEach(t),pfr=r(mle," class method or the "),ZH=n(mle,"A",{href:!0});var Tqt=s(ZH);_fr=r(Tqt,"from_config()"),Tqt.forEach(t),bfr=r(mle,` class
method.`),mle.forEach(t),vfr=i(Pl),Ox=n(Pl,"P",{});var Eeo=s(Ox);Ffr=r(Eeo,"This class cannot be instantiated directly using "),rMe=n(Eeo,"CODE",{});var Mqt=s(rMe);Tfr=r(Mqt,"__init__()"),Mqt.forEach(t),Mfr=r(Eeo," (throws an error)."),Eeo.forEach(t),Efr=i(Pl),At=n(Pl,"DIV",{class:!0});var Iy=s(At);T(Vx.$$.fragment,Iy),Cfr=i(Iy),tMe=n(Iy,"P",{});var Eqt=s(tMe);wfr=r(Eqt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Eqt.forEach(t),Afr=i(Iy),zd=n(Iy,"P",{});var fle=s(zd);Lfr=r(fle,`Note:
Loading a model from its configuration file does `),aMe=n(fle,"STRONG",{});var Cqt=s(aMe);yfr=r(Cqt,"not"),Cqt.forEach(t),xfr=r(fle,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(fle,"A",{href:!0});var wqt=s(eJ);$fr=r(wqt,"from_pretrained()"),wqt.forEach(t),kfr=r(fle," to load the model weights."),fle.forEach(t),Sfr=i(Iy),T(zM.$$.fragment,Iy),Iy.forEach(t),Rfr=i(Pl),io=n(Pl,"DIV",{class:!0});var xa=s(io);T(Xx.$$.fragment,xa),Pfr=i(xa),nMe=n(xa,"P",{});var Aqt=s(nMe);Bfr=r(Aqt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Aqt.forEach(t),Ifr=i(xa),nn=n(xa,"P",{});var Ny=s(nn);Nfr=r(Ny,"The model class to instantiate is selected based on the "),sMe=n(Ny,"CODE",{});var Lqt=s(sMe);qfr=r(Lqt,"model_type"),Lqt.forEach(t),jfr=r(Ny,` property of the config object (either
passed as an argument or loaded from `),lMe=n(Ny,"CODE",{});var yqt=s(lMe);Dfr=r(yqt,"pretrained_model_name_or_path"),yqt.forEach(t),Gfr=r(Ny,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iMe=n(Ny,"CODE",{});var xqt=s(iMe);Ofr=r(xqt,"pretrained_model_name_or_path"),xqt.forEach(t),Vfr=r(Ny,":"),Ny.forEach(t),Xfr=i(xa),V=n(xa,"UL",{});var X=s(V);QM=n(X,"LI",{});var aVe=s(QM);dMe=n(aVe,"STRONG",{});var $qt=s(dMe);zfr=r($qt,"albert"),$qt.forEach(t),Qfr=r(aVe," \u2014 "),oJ=n(aVe,"A",{href:!0});var kqt=s(oJ);Wfr=r(kqt,"AlbertForQuestionAnswering"),kqt.forEach(t),Ufr=r(aVe," (ALBERT model)"),aVe.forEach(t),Hfr=i(X),WM=n(X,"LI",{});var nVe=s(WM);cMe=n(nVe,"STRONG",{});var Sqt=s(cMe);Jfr=r(Sqt,"bart"),Sqt.forEach(t),Yfr=r(nVe," \u2014 "),rJ=n(nVe,"A",{href:!0});var Rqt=s(rJ);Kfr=r(Rqt,"BartForQuestionAnswering"),Rqt.forEach(t),Zfr=r(nVe," (BART model)"),nVe.forEach(t),egr=i(X),UM=n(X,"LI",{});var sVe=s(UM);mMe=n(sVe,"STRONG",{});var Pqt=s(mMe);ogr=r(Pqt,"bert"),Pqt.forEach(t),rgr=r(sVe," \u2014 "),tJ=n(sVe,"A",{href:!0});var Bqt=s(tJ);tgr=r(Bqt,"BertForQuestionAnswering"),Bqt.forEach(t),agr=r(sVe," (BERT model)"),sVe.forEach(t),ngr=i(X),HM=n(X,"LI",{});var lVe=s(HM);fMe=n(lVe,"STRONG",{});var Iqt=s(fMe);sgr=r(Iqt,"big_bird"),Iqt.forEach(t),lgr=r(lVe," \u2014 "),aJ=n(lVe,"A",{href:!0});var Nqt=s(aJ);igr=r(Nqt,"BigBirdForQuestionAnswering"),Nqt.forEach(t),dgr=r(lVe," (BigBird model)"),lVe.forEach(t),cgr=i(X),JM=n(X,"LI",{});var iVe=s(JM);gMe=n(iVe,"STRONG",{});var qqt=s(gMe);mgr=r(qqt,"bigbird_pegasus"),qqt.forEach(t),fgr=r(iVe," \u2014 "),nJ=n(iVe,"A",{href:!0});var jqt=s(nJ);ggr=r(jqt,"BigBirdPegasusForQuestionAnswering"),jqt.forEach(t),hgr=r(iVe," (BigBird-Pegasus model)"),iVe.forEach(t),ugr=i(X),YM=n(X,"LI",{});var dVe=s(YM);hMe=n(dVe,"STRONG",{});var Dqt=s(hMe);pgr=r(Dqt,"camembert"),Dqt.forEach(t),_gr=r(dVe," \u2014 "),sJ=n(dVe,"A",{href:!0});var Gqt=s(sJ);bgr=r(Gqt,"CamembertForQuestionAnswering"),Gqt.forEach(t),vgr=r(dVe," (CamemBERT model)"),dVe.forEach(t),Fgr=i(X),KM=n(X,"LI",{});var cVe=s(KM);uMe=n(cVe,"STRONG",{});var Oqt=s(uMe);Tgr=r(Oqt,"canine"),Oqt.forEach(t),Mgr=r(cVe," \u2014 "),lJ=n(cVe,"A",{href:!0});var Vqt=s(lJ);Egr=r(Vqt,"CanineForQuestionAnswering"),Vqt.forEach(t),Cgr=r(cVe," (CANINE model)"),cVe.forEach(t),wgr=i(X),ZM=n(X,"LI",{});var mVe=s(ZM);pMe=n(mVe,"STRONG",{});var Xqt=s(pMe);Agr=r(Xqt,"convbert"),Xqt.forEach(t),Lgr=r(mVe," \u2014 "),iJ=n(mVe,"A",{href:!0});var zqt=s(iJ);ygr=r(zqt,"ConvBertForQuestionAnswering"),zqt.forEach(t),xgr=r(mVe," (ConvBERT model)"),mVe.forEach(t),$gr=i(X),eE=n(X,"LI",{});var fVe=s(eE);_Me=n(fVe,"STRONG",{});var Qqt=s(_Me);kgr=r(Qqt,"data2vec-text"),Qqt.forEach(t),Sgr=r(fVe," \u2014 "),dJ=n(fVe,"A",{href:!0});var Wqt=s(dJ);Rgr=r(Wqt,"Data2VecTextForQuestionAnswering"),Wqt.forEach(t),Pgr=r(fVe," (Data2VecText model)"),fVe.forEach(t),Bgr=i(X),oE=n(X,"LI",{});var gVe=s(oE);bMe=n(gVe,"STRONG",{});var Uqt=s(bMe);Igr=r(Uqt,"deberta"),Uqt.forEach(t),Ngr=r(gVe," \u2014 "),cJ=n(gVe,"A",{href:!0});var Hqt=s(cJ);qgr=r(Hqt,"DebertaForQuestionAnswering"),Hqt.forEach(t),jgr=r(gVe," (DeBERTa model)"),gVe.forEach(t),Dgr=i(X),rE=n(X,"LI",{});var hVe=s(rE);vMe=n(hVe,"STRONG",{});var Jqt=s(vMe);Ggr=r(Jqt,"deberta-v2"),Jqt.forEach(t),Ogr=r(hVe," \u2014 "),mJ=n(hVe,"A",{href:!0});var Yqt=s(mJ);Vgr=r(Yqt,"DebertaV2ForQuestionAnswering"),Yqt.forEach(t),Xgr=r(hVe," (DeBERTa-v2 model)"),hVe.forEach(t),zgr=i(X),tE=n(X,"LI",{});var uVe=s(tE);FMe=n(uVe,"STRONG",{});var Kqt=s(FMe);Qgr=r(Kqt,"distilbert"),Kqt.forEach(t),Wgr=r(uVe," \u2014 "),fJ=n(uVe,"A",{href:!0});var Zqt=s(fJ);Ugr=r(Zqt,"DistilBertForQuestionAnswering"),Zqt.forEach(t),Hgr=r(uVe," (DistilBERT model)"),uVe.forEach(t),Jgr=i(X),aE=n(X,"LI",{});var pVe=s(aE);TMe=n(pVe,"STRONG",{});var ejt=s(TMe);Ygr=r(ejt,"electra"),ejt.forEach(t),Kgr=r(pVe," \u2014 "),gJ=n(pVe,"A",{href:!0});var ojt=s(gJ);Zgr=r(ojt,"ElectraForQuestionAnswering"),ojt.forEach(t),ehr=r(pVe," (ELECTRA model)"),pVe.forEach(t),ohr=i(X),nE=n(X,"LI",{});var _Ve=s(nE);MMe=n(_Ve,"STRONG",{});var rjt=s(MMe);rhr=r(rjt,"ernie"),rjt.forEach(t),thr=r(_Ve," \u2014 "),hJ=n(_Ve,"A",{href:!0});var tjt=s(hJ);ahr=r(tjt,"ErnieForQuestionAnswering"),tjt.forEach(t),nhr=r(_Ve," (ERNIE model)"),_Ve.forEach(t),shr=i(X),sE=n(X,"LI",{});var bVe=s(sE);EMe=n(bVe,"STRONG",{});var ajt=s(EMe);lhr=r(ajt,"flaubert"),ajt.forEach(t),ihr=r(bVe," \u2014 "),uJ=n(bVe,"A",{href:!0});var njt=s(uJ);dhr=r(njt,"FlaubertForQuestionAnsweringSimple"),njt.forEach(t),chr=r(bVe," (FlauBERT model)"),bVe.forEach(t),mhr=i(X),lE=n(X,"LI",{});var vVe=s(lE);CMe=n(vVe,"STRONG",{});var sjt=s(CMe);fhr=r(sjt,"fnet"),sjt.forEach(t),ghr=r(vVe," \u2014 "),pJ=n(vVe,"A",{href:!0});var ljt=s(pJ);hhr=r(ljt,"FNetForQuestionAnswering"),ljt.forEach(t),uhr=r(vVe," (FNet model)"),vVe.forEach(t),phr=i(X),iE=n(X,"LI",{});var FVe=s(iE);wMe=n(FVe,"STRONG",{});var ijt=s(wMe);_hr=r(ijt,"funnel"),ijt.forEach(t),bhr=r(FVe," \u2014 "),_J=n(FVe,"A",{href:!0});var djt=s(_J);vhr=r(djt,"FunnelForQuestionAnswering"),djt.forEach(t),Fhr=r(FVe," (Funnel Transformer model)"),FVe.forEach(t),Thr=i(X),dE=n(X,"LI",{});var TVe=s(dE);AMe=n(TVe,"STRONG",{});var cjt=s(AMe);Mhr=r(cjt,"gptj"),cjt.forEach(t),Ehr=r(TVe," \u2014 "),bJ=n(TVe,"A",{href:!0});var mjt=s(bJ);Chr=r(mjt,"GPTJForQuestionAnswering"),mjt.forEach(t),whr=r(TVe," (GPT-J model)"),TVe.forEach(t),Ahr=i(X),cE=n(X,"LI",{});var MVe=s(cE);LMe=n(MVe,"STRONG",{});var fjt=s(LMe);Lhr=r(fjt,"ibert"),fjt.forEach(t),yhr=r(MVe," \u2014 "),vJ=n(MVe,"A",{href:!0});var gjt=s(vJ);xhr=r(gjt,"IBertForQuestionAnswering"),gjt.forEach(t),$hr=r(MVe," (I-BERT model)"),MVe.forEach(t),khr=i(X),mE=n(X,"LI",{});var EVe=s(mE);yMe=n(EVe,"STRONG",{});var hjt=s(yMe);Shr=r(hjt,"layoutlmv2"),hjt.forEach(t),Rhr=r(EVe," \u2014 "),FJ=n(EVe,"A",{href:!0});var ujt=s(FJ);Phr=r(ujt,"LayoutLMv2ForQuestionAnswering"),ujt.forEach(t),Bhr=r(EVe," (LayoutLMv2 model)"),EVe.forEach(t),Ihr=i(X),fE=n(X,"LI",{});var CVe=s(fE);xMe=n(CVe,"STRONG",{});var pjt=s(xMe);Nhr=r(pjt,"layoutlmv3"),pjt.forEach(t),qhr=r(CVe," \u2014 "),TJ=n(CVe,"A",{href:!0});var _jt=s(TJ);jhr=r(_jt,"LayoutLMv3ForQuestionAnswering"),_jt.forEach(t),Dhr=r(CVe," (LayoutLMv3 model)"),CVe.forEach(t),Ghr=i(X),gE=n(X,"LI",{});var wVe=s(gE);$Me=n(wVe,"STRONG",{});var bjt=s($Me);Ohr=r(bjt,"led"),bjt.forEach(t),Vhr=r(wVe," \u2014 "),MJ=n(wVe,"A",{href:!0});var vjt=s(MJ);Xhr=r(vjt,"LEDForQuestionAnswering"),vjt.forEach(t),zhr=r(wVe," (LED model)"),wVe.forEach(t),Qhr=i(X),hE=n(X,"LI",{});var AVe=s(hE);kMe=n(AVe,"STRONG",{});var Fjt=s(kMe);Whr=r(Fjt,"longformer"),Fjt.forEach(t),Uhr=r(AVe," \u2014 "),EJ=n(AVe,"A",{href:!0});var Tjt=s(EJ);Hhr=r(Tjt,"LongformerForQuestionAnswering"),Tjt.forEach(t),Jhr=r(AVe," (Longformer model)"),AVe.forEach(t),Yhr=i(X),uE=n(X,"LI",{});var LVe=s(uE);SMe=n(LVe,"STRONG",{});var Mjt=s(SMe);Khr=r(Mjt,"luke"),Mjt.forEach(t),Zhr=r(LVe," \u2014 "),CJ=n(LVe,"A",{href:!0});var Ejt=s(CJ);eur=r(Ejt,"LukeForQuestionAnswering"),Ejt.forEach(t),our=r(LVe," (LUKE model)"),LVe.forEach(t),rur=i(X),pE=n(X,"LI",{});var yVe=s(pE);RMe=n(yVe,"STRONG",{});var Cjt=s(RMe);tur=r(Cjt,"lxmert"),Cjt.forEach(t),aur=r(yVe," \u2014 "),wJ=n(yVe,"A",{href:!0});var wjt=s(wJ);nur=r(wjt,"LxmertForQuestionAnswering"),wjt.forEach(t),sur=r(yVe," (LXMERT model)"),yVe.forEach(t),lur=i(X),_E=n(X,"LI",{});var xVe=s(_E);PMe=n(xVe,"STRONG",{});var Ajt=s(PMe);iur=r(Ajt,"mbart"),Ajt.forEach(t),dur=r(xVe," \u2014 "),AJ=n(xVe,"A",{href:!0});var Ljt=s(AJ);cur=r(Ljt,"MBartForQuestionAnswering"),Ljt.forEach(t),mur=r(xVe," (mBART model)"),xVe.forEach(t),fur=i(X),bE=n(X,"LI",{});var $Ve=s(bE);BMe=n($Ve,"STRONG",{});var yjt=s(BMe);gur=r(yjt,"megatron-bert"),yjt.forEach(t),hur=r($Ve," \u2014 "),LJ=n($Ve,"A",{href:!0});var xjt=s(LJ);uur=r(xjt,"MegatronBertForQuestionAnswering"),xjt.forEach(t),pur=r($Ve," (Megatron-BERT model)"),$Ve.forEach(t),_ur=i(X),vE=n(X,"LI",{});var kVe=s(vE);IMe=n(kVe,"STRONG",{});var $jt=s(IMe);bur=r($jt,"mobilebert"),$jt.forEach(t),vur=r(kVe," \u2014 "),yJ=n(kVe,"A",{href:!0});var kjt=s(yJ);Fur=r(kjt,"MobileBertForQuestionAnswering"),kjt.forEach(t),Tur=r(kVe," (MobileBERT model)"),kVe.forEach(t),Mur=i(X),FE=n(X,"LI",{});var SVe=s(FE);NMe=n(SVe,"STRONG",{});var Sjt=s(NMe);Eur=r(Sjt,"mpnet"),Sjt.forEach(t),Cur=r(SVe," \u2014 "),xJ=n(SVe,"A",{href:!0});var Rjt=s(xJ);wur=r(Rjt,"MPNetForQuestionAnswering"),Rjt.forEach(t),Aur=r(SVe," (MPNet model)"),SVe.forEach(t),Lur=i(X),TE=n(X,"LI",{});var RVe=s(TE);qMe=n(RVe,"STRONG",{});var Pjt=s(qMe);yur=r(Pjt,"mvp"),Pjt.forEach(t),xur=r(RVe," \u2014 "),$J=n(RVe,"A",{href:!0});var Bjt=s($J);$ur=r(Bjt,"MvpForQuestionAnswering"),Bjt.forEach(t),kur=r(RVe," (MVP model)"),RVe.forEach(t),Sur=i(X),ME=n(X,"LI",{});var PVe=s(ME);jMe=n(PVe,"STRONG",{});var Ijt=s(jMe);Rur=r(Ijt,"nezha"),Ijt.forEach(t),Pur=r(PVe," \u2014 "),kJ=n(PVe,"A",{href:!0});var Njt=s(kJ);Bur=r(Njt,"NezhaForQuestionAnswering"),Njt.forEach(t),Iur=r(PVe," (Nezha model)"),PVe.forEach(t),Nur=i(X),EE=n(X,"LI",{});var BVe=s(EE);DMe=n(BVe,"STRONG",{});var qjt=s(DMe);qur=r(qjt,"nystromformer"),qjt.forEach(t),jur=r(BVe," \u2014 "),SJ=n(BVe,"A",{href:!0});var jjt=s(SJ);Dur=r(jjt,"NystromformerForQuestionAnswering"),jjt.forEach(t),Gur=r(BVe," (Nystr\xF6mformer model)"),BVe.forEach(t),Our=i(X),CE=n(X,"LI",{});var IVe=s(CE);GMe=n(IVe,"STRONG",{});var Djt=s(GMe);Vur=r(Djt,"qdqbert"),Djt.forEach(t),Xur=r(IVe," \u2014 "),RJ=n(IVe,"A",{href:!0});var Gjt=s(RJ);zur=r(Gjt,"QDQBertForQuestionAnswering"),Gjt.forEach(t),Qur=r(IVe," (QDQBert model)"),IVe.forEach(t),Wur=i(X),wE=n(X,"LI",{});var NVe=s(wE);OMe=n(NVe,"STRONG",{});var Ojt=s(OMe);Uur=r(Ojt,"reformer"),Ojt.forEach(t),Hur=r(NVe," \u2014 "),PJ=n(NVe,"A",{href:!0});var Vjt=s(PJ);Jur=r(Vjt,"ReformerForQuestionAnswering"),Vjt.forEach(t),Yur=r(NVe," (Reformer model)"),NVe.forEach(t),Kur=i(X),AE=n(X,"LI",{});var qVe=s(AE);VMe=n(qVe,"STRONG",{});var Xjt=s(VMe);Zur=r(Xjt,"rembert"),Xjt.forEach(t),epr=r(qVe," \u2014 "),BJ=n(qVe,"A",{href:!0});var zjt=s(BJ);opr=r(zjt,"RemBertForQuestionAnswering"),zjt.forEach(t),rpr=r(qVe," (RemBERT model)"),qVe.forEach(t),tpr=i(X),LE=n(X,"LI",{});var jVe=s(LE);XMe=n(jVe,"STRONG",{});var Qjt=s(XMe);apr=r(Qjt,"roberta"),Qjt.forEach(t),npr=r(jVe," \u2014 "),IJ=n(jVe,"A",{href:!0});var Wjt=s(IJ);spr=r(Wjt,"RobertaForQuestionAnswering"),Wjt.forEach(t),lpr=r(jVe," (RoBERTa model)"),jVe.forEach(t),ipr=i(X),yE=n(X,"LI",{});var DVe=s(yE);zMe=n(DVe,"STRONG",{});var Ujt=s(zMe);dpr=r(Ujt,"roformer"),Ujt.forEach(t),cpr=r(DVe," \u2014 "),NJ=n(DVe,"A",{href:!0});var Hjt=s(NJ);mpr=r(Hjt,"RoFormerForQuestionAnswering"),Hjt.forEach(t),fpr=r(DVe," (RoFormer model)"),DVe.forEach(t),gpr=i(X),xE=n(X,"LI",{});var GVe=s(xE);QMe=n(GVe,"STRONG",{});var Jjt=s(QMe);hpr=r(Jjt,"splinter"),Jjt.forEach(t),upr=r(GVe," \u2014 "),qJ=n(GVe,"A",{href:!0});var Yjt=s(qJ);ppr=r(Yjt,"SplinterForQuestionAnswering"),Yjt.forEach(t),_pr=r(GVe," (Splinter model)"),GVe.forEach(t),bpr=i(X),$E=n(X,"LI",{});var OVe=s($E);WMe=n(OVe,"STRONG",{});var Kjt=s(WMe);vpr=r(Kjt,"squeezebert"),Kjt.forEach(t),Fpr=r(OVe," \u2014 "),jJ=n(OVe,"A",{href:!0});var Zjt=s(jJ);Tpr=r(Zjt,"SqueezeBertForQuestionAnswering"),Zjt.forEach(t),Mpr=r(OVe," (SqueezeBERT model)"),OVe.forEach(t),Epr=i(X),kE=n(X,"LI",{});var VVe=s(kE);UMe=n(VVe,"STRONG",{});var eDt=s(UMe);Cpr=r(eDt,"xlm"),eDt.forEach(t),wpr=r(VVe," \u2014 "),DJ=n(VVe,"A",{href:!0});var oDt=s(DJ);Apr=r(oDt,"XLMForQuestionAnsweringSimple"),oDt.forEach(t),Lpr=r(VVe," (XLM model)"),VVe.forEach(t),ypr=i(X),SE=n(X,"LI",{});var XVe=s(SE);HMe=n(XVe,"STRONG",{});var rDt=s(HMe);xpr=r(rDt,"xlm-roberta"),rDt.forEach(t),$pr=r(XVe," \u2014 "),GJ=n(XVe,"A",{href:!0});var tDt=s(GJ);kpr=r(tDt,"XLMRobertaForQuestionAnswering"),tDt.forEach(t),Spr=r(XVe," (XLM-RoBERTa model)"),XVe.forEach(t),Rpr=i(X),RE=n(X,"LI",{});var zVe=s(RE);JMe=n(zVe,"STRONG",{});var aDt=s(JMe);Ppr=r(aDt,"xlm-roberta-xl"),aDt.forEach(t),Bpr=r(zVe," \u2014 "),OJ=n(zVe,"A",{href:!0});var nDt=s(OJ);Ipr=r(nDt,"XLMRobertaXLForQuestionAnswering"),nDt.forEach(t),Npr=r(zVe," (XLM-RoBERTa-XL model)"),zVe.forEach(t),qpr=i(X),PE=n(X,"LI",{});var QVe=s(PE);YMe=n(QVe,"STRONG",{});var sDt=s(YMe);jpr=r(sDt,"xlnet"),sDt.forEach(t),Dpr=r(QVe," \u2014 "),VJ=n(QVe,"A",{href:!0});var lDt=s(VJ);Gpr=r(lDt,"XLNetForQuestionAnsweringSimple"),lDt.forEach(t),Opr=r(QVe," (XLNet model)"),QVe.forEach(t),Vpr=i(X),BE=n(X,"LI",{});var WVe=s(BE);KMe=n(WVe,"STRONG",{});var iDt=s(KMe);Xpr=r(iDt,"yoso"),iDt.forEach(t),zpr=r(WVe," \u2014 "),XJ=n(WVe,"A",{href:!0});var dDt=s(XJ);Qpr=r(dDt,"YosoForQuestionAnswering"),dDt.forEach(t),Wpr=r(WVe," (YOSO model)"),WVe.forEach(t),X.forEach(t),Upr=i(xa),IE=n(xa,"P",{});var UVe=s(IE);Hpr=r(UVe,"The model is set in evaluation mode by default using "),ZMe=n(UVe,"CODE",{});var cDt=s(ZMe);Jpr=r(cDt,"model.eval()"),cDt.forEach(t),Ypr=r(UVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eEe=n(UVe,"CODE",{});var mDt=s(eEe);Kpr=r(mDt,"model.train()"),mDt.forEach(t),UVe.forEach(t),Zpr=i(xa),T(NE.$$.fragment,xa),xa.forEach(t),Pl.forEach(t),cKe=i(m),Qd=n(m,"H2",{class:!0});var Ceo=s(Qd);qE=n(Ceo,"A",{id:!0,class:!0,href:!0});var fDt=s(qE);oEe=n(fDt,"SPAN",{});var gDt=s(oEe);T(zx.$$.fragment,gDt),gDt.forEach(t),fDt.forEach(t),e_r=i(Ceo),rEe=n(Ceo,"SPAN",{});var hDt=s(rEe);o_r=r(hDt,"AutoModelForTableQuestionAnswering"),hDt.forEach(t),Ceo.forEach(t),mKe=i(m),Xo=n(m,"DIV",{class:!0});var Bl=s(Xo);T(Qx.$$.fragment,Bl),r_r=i(Bl),Wd=n(Bl,"P",{});var gle=s(Wd);t_r=r(gle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zJ=n(gle,"A",{href:!0});var uDt=s(zJ);a_r=r(uDt,"from_pretrained()"),uDt.forEach(t),n_r=r(gle," class method or the "),QJ=n(gle,"A",{href:!0});var pDt=s(QJ);s_r=r(pDt,"from_config()"),pDt.forEach(t),l_r=r(gle,` class
method.`),gle.forEach(t),i_r=i(Bl),Wx=n(Bl,"P",{});var weo=s(Wx);d_r=r(weo,"This class cannot be instantiated directly using "),tEe=n(weo,"CODE",{});var _Dt=s(tEe);c_r=r(_Dt,"__init__()"),_Dt.forEach(t),m_r=r(weo," (throws an error)."),weo.forEach(t),f_r=i(Bl),Lt=n(Bl,"DIV",{class:!0});var qy=s(Lt);T(Ux.$$.fragment,qy),g_r=i(qy),aEe=n(qy,"P",{});var bDt=s(aEe);h_r=r(bDt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),bDt.forEach(t),u_r=i(qy),Ud=n(qy,"P",{});var hle=s(Ud);p_r=r(hle,`Note:
Loading a model from its configuration file does `),nEe=n(hle,"STRONG",{});var vDt=s(nEe);__r=r(vDt,"not"),vDt.forEach(t),b_r=r(hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=n(hle,"A",{href:!0});var FDt=s(WJ);v_r=r(FDt,"from_pretrained()"),FDt.forEach(t),F_r=r(hle," to load the model weights."),hle.forEach(t),T_r=i(qy),T(jE.$$.fragment,qy),qy.forEach(t),M_r=i(Bl),co=n(Bl,"DIV",{class:!0});var $a=s(co);T(Hx.$$.fragment,$a),E_r=i($a),sEe=n($a,"P",{});var TDt=s(sEe);C_r=r(TDt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),TDt.forEach(t),w_r=i($a),sn=n($a,"P",{});var jy=s(sn);A_r=r(jy,"The model class to instantiate is selected based on the "),lEe=n(jy,"CODE",{});var MDt=s(lEe);L_r=r(MDt,"model_type"),MDt.forEach(t),y_r=r(jy,` property of the config object (either
passed as an argument or loaded from `),iEe=n(jy,"CODE",{});var EDt=s(iEe);x_r=r(EDt,"pretrained_model_name_or_path"),EDt.forEach(t),$_r=r(jy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dEe=n(jy,"CODE",{});var CDt=s(dEe);k_r=r(CDt,"pretrained_model_name_or_path"),CDt.forEach(t),S_r=r(jy,":"),jy.forEach(t),R_r=i($a),cEe=n($a,"UL",{});var wDt=s(cEe);DE=n(wDt,"LI",{});var HVe=s(DE);mEe=n(HVe,"STRONG",{});var ADt=s(mEe);P_r=r(ADt,"tapas"),ADt.forEach(t),B_r=r(HVe," \u2014 "),UJ=n(HVe,"A",{href:!0});var LDt=s(UJ);I_r=r(LDt,"TapasForQuestionAnswering"),LDt.forEach(t),N_r=r(HVe," (TAPAS model)"),HVe.forEach(t),wDt.forEach(t),q_r=i($a),GE=n($a,"P",{});var JVe=s(GE);j_r=r(JVe,"The model is set in evaluation mode by default using "),fEe=n(JVe,"CODE",{});var yDt=s(fEe);D_r=r(yDt,"model.eval()"),yDt.forEach(t),G_r=r(JVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gEe=n(JVe,"CODE",{});var xDt=s(gEe);O_r=r(xDt,"model.train()"),xDt.forEach(t),JVe.forEach(t),V_r=i($a),T(OE.$$.fragment,$a),$a.forEach(t),Bl.forEach(t),fKe=i(m),Hd=n(m,"H2",{class:!0});var Aeo=s(Hd);VE=n(Aeo,"A",{id:!0,class:!0,href:!0});var $Dt=s(VE);hEe=n($Dt,"SPAN",{});var kDt=s(hEe);T(Jx.$$.fragment,kDt),kDt.forEach(t),$Dt.forEach(t),X_r=i(Aeo),uEe=n(Aeo,"SPAN",{});var SDt=s(uEe);z_r=r(SDt,"AutoModelForDocumentQuestionAnswering"),SDt.forEach(t),Aeo.forEach(t),gKe=i(m),zo=n(m,"DIV",{class:!0});var Il=s(zo);T(Yx.$$.fragment,Il),Q_r=i(Il),Jd=n(Il,"P",{});var ule=s(Jd);W_r=r(ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),HJ=n(ule,"A",{href:!0});var RDt=s(HJ);U_r=r(RDt,"from_pretrained()"),RDt.forEach(t),H_r=r(ule," class method or the "),JJ=n(ule,"A",{href:!0});var PDt=s(JJ);J_r=r(PDt,"from_config()"),PDt.forEach(t),Y_r=r(ule,` class
method.`),ule.forEach(t),K_r=i(Il),Kx=n(Il,"P",{});var Leo=s(Kx);Z_r=r(Leo,"This class cannot be instantiated directly using "),pEe=n(Leo,"CODE",{});var BDt=s(pEe);e2r=r(BDt,"__init__()"),BDt.forEach(t),o2r=r(Leo," (throws an error)."),Leo.forEach(t),r2r=i(Il),yt=n(Il,"DIV",{class:!0});var Dy=s(yt);T(Zx.$$.fragment,Dy),t2r=i(Dy),_Ee=n(Dy,"P",{});var IDt=s(_Ee);a2r=r(IDt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),IDt.forEach(t),n2r=i(Dy),Yd=n(Dy,"P",{});var ple=s(Yd);s2r=r(ple,`Note:
Loading a model from its configuration file does `),bEe=n(ple,"STRONG",{});var NDt=s(bEe);l2r=r(NDt,"not"),NDt.forEach(t),i2r=r(ple,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(ple,"A",{href:!0});var qDt=s(YJ);d2r=r(qDt,"from_pretrained()"),qDt.forEach(t),c2r=r(ple," to load the model weights."),ple.forEach(t),m2r=i(Dy),T(XE.$$.fragment,Dy),Dy.forEach(t),f2r=i(Il),mo=n(Il,"DIV",{class:!0});var ka=s(mo);T(e$.$$.fragment,ka),g2r=i(ka),vEe=n(ka,"P",{});var jDt=s(vEe);h2r=r(jDt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),jDt.forEach(t),u2r=i(ka),ln=n(ka,"P",{});var Gy=s(ln);p2r=r(Gy,"The model class to instantiate is selected based on the "),FEe=n(Gy,"CODE",{});var DDt=s(FEe);_2r=r(DDt,"model_type"),DDt.forEach(t),b2r=r(Gy,` property of the config object (either
passed as an argument or loaded from `),TEe=n(Gy,"CODE",{});var GDt=s(TEe);v2r=r(GDt,"pretrained_model_name_or_path"),GDt.forEach(t),F2r=r(Gy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MEe=n(Gy,"CODE",{});var ODt=s(MEe);T2r=r(ODt,"pretrained_model_name_or_path"),ODt.forEach(t),M2r=r(Gy,":"),Gy.forEach(t),E2r=i(ka),Kd=n(ka,"UL",{});var _le=s(Kd);zE=n(_le,"LI",{});var YVe=s(zE);EEe=n(YVe,"STRONG",{});var VDt=s(EEe);C2r=r(VDt,"layoutlm"),VDt.forEach(t),w2r=r(YVe," \u2014 "),KJ=n(YVe,"A",{href:!0});var XDt=s(KJ);A2r=r(XDt,"LayoutLMForQuestionAnswering"),XDt.forEach(t),L2r=r(YVe," (LayoutLM model)"),YVe.forEach(t),y2r=i(_le),QE=n(_le,"LI",{});var KVe=s(QE);CEe=n(KVe,"STRONG",{});var zDt=s(CEe);x2r=r(zDt,"layoutlmv2"),zDt.forEach(t),$2r=r(KVe," \u2014 "),ZJ=n(KVe,"A",{href:!0});var QDt=s(ZJ);k2r=r(QDt,"LayoutLMv2ForQuestionAnswering"),QDt.forEach(t),S2r=r(KVe," (LayoutLMv2 model)"),KVe.forEach(t),R2r=i(_le),WE=n(_le,"LI",{});var ZVe=s(WE);wEe=n(ZVe,"STRONG",{});var WDt=s(wEe);P2r=r(WDt,"layoutlmv3"),WDt.forEach(t),B2r=r(ZVe," \u2014 "),eY=n(ZVe,"A",{href:!0});var UDt=s(eY);I2r=r(UDt,"LayoutLMv3ForQuestionAnswering"),UDt.forEach(t),N2r=r(ZVe," (LayoutLMv3 model)"),ZVe.forEach(t),_le.forEach(t),q2r=i(ka),UE=n(ka,"P",{});var eXe=s(UE);j2r=r(eXe,"The model is set in evaluation mode by default using "),AEe=n(eXe,"CODE",{});var HDt=s(AEe);D2r=r(HDt,"model.eval()"),HDt.forEach(t),G2r=r(eXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=n(eXe,"CODE",{});var JDt=s(LEe);O2r=r(JDt,"model.train()"),JDt.forEach(t),eXe.forEach(t),V2r=i(ka),T(HE.$$.fragment,ka),ka.forEach(t),Il.forEach(t),hKe=i(m),Zd=n(m,"H2",{class:!0});var yeo=s(Zd);JE=n(yeo,"A",{id:!0,class:!0,href:!0});var YDt=s(JE);yEe=n(YDt,"SPAN",{});var KDt=s(yEe);T(o$.$$.fragment,KDt),KDt.forEach(t),YDt.forEach(t),X2r=i(yeo),xEe=n(yeo,"SPAN",{});var ZDt=s(xEe);z2r=r(ZDt,"AutoModelForImageClassification"),ZDt.forEach(t),yeo.forEach(t),uKe=i(m),Qo=n(m,"DIV",{class:!0});var Nl=s(Qo);T(r$.$$.fragment,Nl),Q2r=i(Nl),ec=n(Nl,"P",{});var ble=s(ec);W2r=r(ble,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),oY=n(ble,"A",{href:!0});var eGt=s(oY);U2r=r(eGt,"from_pretrained()"),eGt.forEach(t),H2r=r(ble," class method or the "),rY=n(ble,"A",{href:!0});var oGt=s(rY);J2r=r(oGt,"from_config()"),oGt.forEach(t),Y2r=r(ble,` class
method.`),ble.forEach(t),K2r=i(Nl),t$=n(Nl,"P",{});var xeo=s(t$);Z2r=r(xeo,"This class cannot be instantiated directly using "),$Ee=n(xeo,"CODE",{});var rGt=s($Ee);ebr=r(rGt,"__init__()"),rGt.forEach(t),obr=r(xeo," (throws an error)."),xeo.forEach(t),rbr=i(Nl),xt=n(Nl,"DIV",{class:!0});var Oy=s(xt);T(a$.$$.fragment,Oy),tbr=i(Oy),kEe=n(Oy,"P",{});var tGt=s(kEe);abr=r(tGt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),tGt.forEach(t),nbr=i(Oy),oc=n(Oy,"P",{});var vle=s(oc);sbr=r(vle,`Note:
Loading a model from its configuration file does `),SEe=n(vle,"STRONG",{});var aGt=s(SEe);lbr=r(aGt,"not"),aGt.forEach(t),ibr=r(vle,` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=n(vle,"A",{href:!0});var nGt=s(tY);dbr=r(nGt,"from_pretrained()"),nGt.forEach(t),cbr=r(vle," to load the model weights."),vle.forEach(t),mbr=i(Oy),T(YE.$$.fragment,Oy),Oy.forEach(t),fbr=i(Nl),fo=n(Nl,"DIV",{class:!0});var Sa=s(fo);T(n$.$$.fragment,Sa),gbr=i(Sa),REe=n(Sa,"P",{});var sGt=s(REe);hbr=r(sGt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),sGt.forEach(t),ubr=i(Sa),dn=n(Sa,"P",{});var Vy=s(dn);pbr=r(Vy,"The model class to instantiate is selected based on the "),PEe=n(Vy,"CODE",{});var lGt=s(PEe);_br=r(lGt,"model_type"),lGt.forEach(t),bbr=r(Vy,` property of the config object (either
passed as an argument or loaded from `),BEe=n(Vy,"CODE",{});var iGt=s(BEe);vbr=r(iGt,"pretrained_model_name_or_path"),iGt.forEach(t),Fbr=r(Vy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=n(Vy,"CODE",{});var dGt=s(IEe);Tbr=r(dGt,"pretrained_model_name_or_path"),dGt.forEach(t),Mbr=r(Vy,":"),Vy.forEach(t),Ebr=i(Sa),be=n(Sa,"UL",{});var Fe=s(be);KE=n(Fe,"LI",{});var oXe=s(KE);NEe=n(oXe,"STRONG",{});var cGt=s(NEe);Cbr=r(cGt,"beit"),cGt.forEach(t),wbr=r(oXe," \u2014 "),aY=n(oXe,"A",{href:!0});var mGt=s(aY);Abr=r(mGt,"BeitForImageClassification"),mGt.forEach(t),Lbr=r(oXe," (BEiT model)"),oXe.forEach(t),ybr=i(Fe),ZE=n(Fe,"LI",{});var rXe=s(ZE);qEe=n(rXe,"STRONG",{});var fGt=s(qEe);xbr=r(fGt,"convnext"),fGt.forEach(t),$br=r(rXe," \u2014 "),nY=n(rXe,"A",{href:!0});var gGt=s(nY);kbr=r(gGt,"ConvNextForImageClassification"),gGt.forEach(t),Sbr=r(rXe," (ConvNeXT model)"),rXe.forEach(t),Rbr=i(Fe),e4=n(Fe,"LI",{});var tXe=s(e4);jEe=n(tXe,"STRONG",{});var hGt=s(jEe);Pbr=r(hGt,"cvt"),hGt.forEach(t),Bbr=r(tXe," \u2014 "),sY=n(tXe,"A",{href:!0});var uGt=s(sY);Ibr=r(uGt,"CvtForImageClassification"),uGt.forEach(t),Nbr=r(tXe," (CvT model)"),tXe.forEach(t),qbr=i(Fe),o4=n(Fe,"LI",{});var aXe=s(o4);DEe=n(aXe,"STRONG",{});var pGt=s(DEe);jbr=r(pGt,"data2vec-vision"),pGt.forEach(t),Dbr=r(aXe," \u2014 "),lY=n(aXe,"A",{href:!0});var _Gt=s(lY);Gbr=r(_Gt,"Data2VecVisionForImageClassification"),_Gt.forEach(t),Obr=r(aXe," (Data2VecVision model)"),aXe.forEach(t),Vbr=i(Fe),_l=n(Fe,"LI",{});var FB=s(_l);GEe=n(FB,"STRONG",{});var bGt=s(GEe);Xbr=r(bGt,"deit"),bGt.forEach(t),zbr=r(FB," \u2014 "),iY=n(FB,"A",{href:!0});var vGt=s(iY);Qbr=r(vGt,"DeiTForImageClassification"),vGt.forEach(t),Wbr=r(FB," or "),dY=n(FB,"A",{href:!0});var FGt=s(dY);Ubr=r(FGt,"DeiTForImageClassificationWithTeacher"),FGt.forEach(t),Hbr=r(FB," (DeiT model)"),FB.forEach(t),Jbr=i(Fe),r4=n(Fe,"LI",{});var nXe=s(r4);OEe=n(nXe,"STRONG",{});var TGt=s(OEe);Ybr=r(TGt,"imagegpt"),TGt.forEach(t),Kbr=r(nXe," \u2014 "),cY=n(nXe,"A",{href:!0});var MGt=s(cY);Zbr=r(MGt,"ImageGPTForImageClassification"),MGt.forEach(t),e1r=r(nXe," (ImageGPT model)"),nXe.forEach(t),o1r=i(Fe),bl=n(Fe,"LI",{});var TB=s(bl);VEe=n(TB,"STRONG",{});var EGt=s(VEe);r1r=r(EGt,"levit"),EGt.forEach(t),t1r=r(TB," \u2014 "),mY=n(TB,"A",{href:!0});var CGt=s(mY);a1r=r(CGt,"LevitForImageClassification"),CGt.forEach(t),n1r=r(TB," or "),fY=n(TB,"A",{href:!0});var wGt=s(fY);s1r=r(wGt,"LevitForImageClassificationWithTeacher"),wGt.forEach(t),l1r=r(TB," (LeViT model)"),TB.forEach(t),i1r=i(Fe),t4=n(Fe,"LI",{});var sXe=s(t4);XEe=n(sXe,"STRONG",{});var AGt=s(XEe);d1r=r(AGt,"mobilevit"),AGt.forEach(t),c1r=r(sXe," \u2014 "),gY=n(sXe,"A",{href:!0});var LGt=s(gY);m1r=r(LGt,"MobileViTForImageClassification"),LGt.forEach(t),f1r=r(sXe," (MobileViT model)"),sXe.forEach(t),g1r=i(Fe),$t=n(Fe,"LI",{});var Tf=s($t);zEe=n(Tf,"STRONG",{});var yGt=s(zEe);h1r=r(yGt,"perceiver"),yGt.forEach(t),u1r=r(Tf," \u2014 "),hY=n(Tf,"A",{href:!0});var xGt=s(hY);p1r=r(xGt,"PerceiverForImageClassificationLearned"),xGt.forEach(t),_1r=r(Tf," or "),uY=n(Tf,"A",{href:!0});var $Gt=s(uY);b1r=r($Gt,"PerceiverForImageClassificationFourier"),$Gt.forEach(t),v1r=r(Tf," or "),pY=n(Tf,"A",{href:!0});var kGt=s(pY);F1r=r(kGt,"PerceiverForImageClassificationConvProcessing"),kGt.forEach(t),T1r=r(Tf," (Perceiver model)"),Tf.forEach(t),M1r=i(Fe),a4=n(Fe,"LI",{});var lXe=s(a4);QEe=n(lXe,"STRONG",{});var SGt=s(QEe);E1r=r(SGt,"poolformer"),SGt.forEach(t),C1r=r(lXe," \u2014 "),_Y=n(lXe,"A",{href:!0});var RGt=s(_Y);w1r=r(RGt,"PoolFormerForImageClassification"),RGt.forEach(t),A1r=r(lXe," (PoolFormer model)"),lXe.forEach(t),L1r=i(Fe),n4=n(Fe,"LI",{});var iXe=s(n4);WEe=n(iXe,"STRONG",{});var PGt=s(WEe);y1r=r(PGt,"regnet"),PGt.forEach(t),x1r=r(iXe," \u2014 "),bY=n(iXe,"A",{href:!0});var BGt=s(bY);$1r=r(BGt,"RegNetForImageClassification"),BGt.forEach(t),k1r=r(iXe," (RegNet model)"),iXe.forEach(t),S1r=i(Fe),s4=n(Fe,"LI",{});var dXe=s(s4);UEe=n(dXe,"STRONG",{});var IGt=s(UEe);R1r=r(IGt,"resnet"),IGt.forEach(t),P1r=r(dXe," \u2014 "),vY=n(dXe,"A",{href:!0});var NGt=s(vY);B1r=r(NGt,"ResNetForImageClassification"),NGt.forEach(t),I1r=r(dXe," (ResNet model)"),dXe.forEach(t),N1r=i(Fe),l4=n(Fe,"LI",{});var cXe=s(l4);HEe=n(cXe,"STRONG",{});var qGt=s(HEe);q1r=r(qGt,"segformer"),qGt.forEach(t),j1r=r(cXe," \u2014 "),FY=n(cXe,"A",{href:!0});var jGt=s(FY);D1r=r(jGt,"SegformerForImageClassification"),jGt.forEach(t),G1r=r(cXe," (SegFormer model)"),cXe.forEach(t),O1r=i(Fe),i4=n(Fe,"LI",{});var mXe=s(i4);JEe=n(mXe,"STRONG",{});var DGt=s(JEe);V1r=r(DGt,"swin"),DGt.forEach(t),X1r=r(mXe," \u2014 "),TY=n(mXe,"A",{href:!0});var GGt=s(TY);z1r=r(GGt,"SwinForImageClassification"),GGt.forEach(t),Q1r=r(mXe," (Swin Transformer model)"),mXe.forEach(t),W1r=i(Fe),d4=n(Fe,"LI",{});var fXe=s(d4);YEe=n(fXe,"STRONG",{});var OGt=s(YEe);U1r=r(OGt,"swinv2"),OGt.forEach(t),H1r=r(fXe," \u2014 "),MY=n(fXe,"A",{href:!0});var VGt=s(MY);J1r=r(VGt,"Swinv2ForImageClassification"),VGt.forEach(t),Y1r=r(fXe," (Swin Transformer V2 model)"),fXe.forEach(t),K1r=i(Fe),c4=n(Fe,"LI",{});var gXe=s(c4);KEe=n(gXe,"STRONG",{});var XGt=s(KEe);Z1r=r(XGt,"van"),XGt.forEach(t),evr=r(gXe," \u2014 "),EY=n(gXe,"A",{href:!0});var zGt=s(EY);ovr=r(zGt,"VanForImageClassification"),zGt.forEach(t),rvr=r(gXe," (VAN model)"),gXe.forEach(t),tvr=i(Fe),m4=n(Fe,"LI",{});var hXe=s(m4);ZEe=n(hXe,"STRONG",{});var QGt=s(ZEe);avr=r(QGt,"vit"),QGt.forEach(t),nvr=r(hXe," \u2014 "),CY=n(hXe,"A",{href:!0});var WGt=s(CY);svr=r(WGt,"ViTForImageClassification"),WGt.forEach(t),lvr=r(hXe," (ViT model)"),hXe.forEach(t),Fe.forEach(t),ivr=i(Sa),f4=n(Sa,"P",{});var uXe=s(f4);dvr=r(uXe,"The model is set in evaluation mode by default using "),e4e=n(uXe,"CODE",{});var UGt=s(e4e);cvr=r(UGt,"model.eval()"),UGt.forEach(t),mvr=r(uXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o4e=n(uXe,"CODE",{});var HGt=s(o4e);fvr=r(HGt,"model.train()"),HGt.forEach(t),uXe.forEach(t),gvr=i(Sa),T(g4.$$.fragment,Sa),Sa.forEach(t),Nl.forEach(t),pKe=i(m),rc=n(m,"H2",{class:!0});var $eo=s(rc);h4=n($eo,"A",{id:!0,class:!0,href:!0});var JGt=s(h4);r4e=n(JGt,"SPAN",{});var YGt=s(r4e);T(s$.$$.fragment,YGt),YGt.forEach(t),JGt.forEach(t),hvr=i($eo),t4e=n($eo,"SPAN",{});var KGt=s(t4e);uvr=r(KGt,"AutoModelForVideoClassification"),KGt.forEach(t),$eo.forEach(t),_Ke=i(m),Wo=n(m,"DIV",{class:!0});var ql=s(Wo);T(l$.$$.fragment,ql),pvr=i(ql),tc=n(ql,"P",{});var Fle=s(tc);_vr=r(Fle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),wY=n(Fle,"A",{href:!0});var ZGt=s(wY);bvr=r(ZGt,"from_pretrained()"),ZGt.forEach(t),vvr=r(Fle," class method or the "),AY=n(Fle,"A",{href:!0});var eOt=s(AY);Fvr=r(eOt,"from_config()"),eOt.forEach(t),Tvr=r(Fle,` class
method.`),Fle.forEach(t),Mvr=i(ql),i$=n(ql,"P",{});var keo=s(i$);Evr=r(keo,"This class cannot be instantiated directly using "),a4e=n(keo,"CODE",{});var oOt=s(a4e);Cvr=r(oOt,"__init__()"),oOt.forEach(t),wvr=r(keo," (throws an error)."),keo.forEach(t),Avr=i(ql),kt=n(ql,"DIV",{class:!0});var Xy=s(kt);T(d$.$$.fragment,Xy),Lvr=i(Xy),n4e=n(Xy,"P",{});var rOt=s(n4e);yvr=r(rOt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),rOt.forEach(t),xvr=i(Xy),ac=n(Xy,"P",{});var Tle=s(ac);$vr=r(Tle,`Note:
Loading a model from its configuration file does `),s4e=n(Tle,"STRONG",{});var tOt=s(s4e);kvr=r(tOt,"not"),tOt.forEach(t),Svr=r(Tle,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(Tle,"A",{href:!0});var aOt=s(LY);Rvr=r(aOt,"from_pretrained()"),aOt.forEach(t),Pvr=r(Tle," to load the model weights."),Tle.forEach(t),Bvr=i(Xy),T(u4.$$.fragment,Xy),Xy.forEach(t),Ivr=i(ql),go=n(ql,"DIV",{class:!0});var Ra=s(go);T(c$.$$.fragment,Ra),Nvr=i(Ra),l4e=n(Ra,"P",{});var nOt=s(l4e);qvr=r(nOt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),nOt.forEach(t),jvr=i(Ra),cn=n(Ra,"P",{});var zy=s(cn);Dvr=r(zy,"The model class to instantiate is selected based on the "),i4e=n(zy,"CODE",{});var sOt=s(i4e);Gvr=r(sOt,"model_type"),sOt.forEach(t),Ovr=r(zy,` property of the config object (either
passed as an argument or loaded from `),d4e=n(zy,"CODE",{});var lOt=s(d4e);Vvr=r(lOt,"pretrained_model_name_or_path"),lOt.forEach(t),Xvr=r(zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c4e=n(zy,"CODE",{});var iOt=s(c4e);zvr=r(iOt,"pretrained_model_name_or_path"),iOt.forEach(t),Qvr=r(zy,":"),zy.forEach(t),Wvr=i(Ra),m4e=n(Ra,"UL",{});var dOt=s(m4e);p4=n(dOt,"LI",{});var pXe=s(p4);f4e=n(pXe,"STRONG",{});var cOt=s(f4e);Uvr=r(cOt,"videomae"),cOt.forEach(t),Hvr=r(pXe," \u2014 "),yY=n(pXe,"A",{href:!0});var mOt=s(yY);Jvr=r(mOt,"VideoMAEForVideoClassification"),mOt.forEach(t),Yvr=r(pXe," (VideoMAE model)"),pXe.forEach(t),dOt.forEach(t),Kvr=i(Ra),_4=n(Ra,"P",{});var _Xe=s(_4);Zvr=r(_Xe,"The model is set in evaluation mode by default using "),g4e=n(_Xe,"CODE",{});var fOt=s(g4e);eFr=r(fOt,"model.eval()"),fOt.forEach(t),oFr=r(_Xe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h4e=n(_Xe,"CODE",{});var gOt=s(h4e);rFr=r(gOt,"model.train()"),gOt.forEach(t),_Xe.forEach(t),tFr=i(Ra),T(b4.$$.fragment,Ra),Ra.forEach(t),ql.forEach(t),bKe=i(m),nc=n(m,"H2",{class:!0});var Seo=s(nc);v4=n(Seo,"A",{id:!0,class:!0,href:!0});var hOt=s(v4);u4e=n(hOt,"SPAN",{});var uOt=s(u4e);T(m$.$$.fragment,uOt),uOt.forEach(t),hOt.forEach(t),aFr=i(Seo),p4e=n(Seo,"SPAN",{});var pOt=s(p4e);nFr=r(pOt,"AutoModelForVision2Seq"),pOt.forEach(t),Seo.forEach(t),vKe=i(m),Uo=n(m,"DIV",{class:!0});var jl=s(Uo);T(f$.$$.fragment,jl),sFr=i(jl),sc=n(jl,"P",{});var Mle=s(sc);lFr=r(Mle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xY=n(Mle,"A",{href:!0});var _Ot=s(xY);iFr=r(_Ot,"from_pretrained()"),_Ot.forEach(t),dFr=r(Mle," class method or the "),$Y=n(Mle,"A",{href:!0});var bOt=s($Y);cFr=r(bOt,"from_config()"),bOt.forEach(t),mFr=r(Mle,` class
method.`),Mle.forEach(t),fFr=i(jl),g$=n(jl,"P",{});var Reo=s(g$);gFr=r(Reo,"This class cannot be instantiated directly using "),_4e=n(Reo,"CODE",{});var vOt=s(_4e);hFr=r(vOt,"__init__()"),vOt.forEach(t),uFr=r(Reo," (throws an error)."),Reo.forEach(t),pFr=i(jl),St=n(jl,"DIV",{class:!0});var Qy=s(St);T(h$.$$.fragment,Qy),_Fr=i(Qy),b4e=n(Qy,"P",{});var FOt=s(b4e);bFr=r(FOt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),FOt.forEach(t),vFr=i(Qy),lc=n(Qy,"P",{});var Ele=s(lc);FFr=r(Ele,`Note:
Loading a model from its configuration file does `),v4e=n(Ele,"STRONG",{});var TOt=s(v4e);TFr=r(TOt,"not"),TOt.forEach(t),MFr=r(Ele,` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=n(Ele,"A",{href:!0});var MOt=s(kY);EFr=r(MOt,"from_pretrained()"),MOt.forEach(t),CFr=r(Ele," to load the model weights."),Ele.forEach(t),wFr=i(Qy),T(F4.$$.fragment,Qy),Qy.forEach(t),AFr=i(jl),ho=n(jl,"DIV",{class:!0});var Pa=s(ho);T(u$.$$.fragment,Pa),LFr=i(Pa),F4e=n(Pa,"P",{});var EOt=s(F4e);yFr=r(EOt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),EOt.forEach(t),xFr=i(Pa),mn=n(Pa,"P",{});var Wy=s(mn);$Fr=r(Wy,"The model class to instantiate is selected based on the "),T4e=n(Wy,"CODE",{});var COt=s(T4e);kFr=r(COt,"model_type"),COt.forEach(t),SFr=r(Wy,` property of the config object (either
passed as an argument or loaded from `),M4e=n(Wy,"CODE",{});var wOt=s(M4e);RFr=r(wOt,"pretrained_model_name_or_path"),wOt.forEach(t),PFr=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E4e=n(Wy,"CODE",{});var AOt=s(E4e);BFr=r(AOt,"pretrained_model_name_or_path"),AOt.forEach(t),IFr=r(Wy,":"),Wy.forEach(t),NFr=i(Pa),C4e=n(Pa,"UL",{});var LOt=s(C4e);T4=n(LOt,"LI",{});var bXe=s(T4);w4e=n(bXe,"STRONG",{});var yOt=s(w4e);qFr=r(yOt,"vision-encoder-decoder"),yOt.forEach(t),jFr=r(bXe," \u2014 "),SY=n(bXe,"A",{href:!0});var xOt=s(SY);DFr=r(xOt,"VisionEncoderDecoderModel"),xOt.forEach(t),GFr=r(bXe," (Vision Encoder decoder model)"),bXe.forEach(t),LOt.forEach(t),OFr=i(Pa),M4=n(Pa,"P",{});var vXe=s(M4);VFr=r(vXe,"The model is set in evaluation mode by default using "),A4e=n(vXe,"CODE",{});var $Ot=s(A4e);XFr=r($Ot,"model.eval()"),$Ot.forEach(t),zFr=r(vXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L4e=n(vXe,"CODE",{});var kOt=s(L4e);QFr=r(kOt,"model.train()"),kOt.forEach(t),vXe.forEach(t),WFr=i(Pa),T(E4.$$.fragment,Pa),Pa.forEach(t),jl.forEach(t),FKe=i(m),ic=n(m,"H2",{class:!0});var Peo=s(ic);C4=n(Peo,"A",{id:!0,class:!0,href:!0});var SOt=s(C4);y4e=n(SOt,"SPAN",{});var ROt=s(y4e);T(p$.$$.fragment,ROt),ROt.forEach(t),SOt.forEach(t),UFr=i(Peo),x4e=n(Peo,"SPAN",{});var POt=s(x4e);HFr=r(POt,"AutoModelForVisualQuestionAnswering"),POt.forEach(t),Peo.forEach(t),TKe=i(m),Ho=n(m,"DIV",{class:!0});var Dl=s(Ho);T(_$.$$.fragment,Dl),JFr=i(Dl),dc=n(Dl,"P",{});var Cle=s(dc);YFr=r(Cle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),RY=n(Cle,"A",{href:!0});var BOt=s(RY);KFr=r(BOt,"from_pretrained()"),BOt.forEach(t),ZFr=r(Cle," class method or the "),PY=n(Cle,"A",{href:!0});var IOt=s(PY);eTr=r(IOt,"from_config()"),IOt.forEach(t),oTr=r(Cle,` class
method.`),Cle.forEach(t),rTr=i(Dl),b$=n(Dl,"P",{});var Beo=s(b$);tTr=r(Beo,"This class cannot be instantiated directly using "),$4e=n(Beo,"CODE",{});var NOt=s($4e);aTr=r(NOt,"__init__()"),NOt.forEach(t),nTr=r(Beo," (throws an error)."),Beo.forEach(t),sTr=i(Dl),Rt=n(Dl,"DIV",{class:!0});var Uy=s(Rt);T(v$.$$.fragment,Uy),lTr=i(Uy),k4e=n(Uy,"P",{});var qOt=s(k4e);iTr=r(qOt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),qOt.forEach(t),dTr=i(Uy),cc=n(Uy,"P",{});var wle=s(cc);cTr=r(wle,`Note:
Loading a model from its configuration file does `),S4e=n(wle,"STRONG",{});var jOt=s(S4e);mTr=r(jOt,"not"),jOt.forEach(t),fTr=r(wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=n(wle,"A",{href:!0});var DOt=s(BY);gTr=r(DOt,"from_pretrained()"),DOt.forEach(t),hTr=r(wle," to load the model weights."),wle.forEach(t),uTr=i(Uy),T(w4.$$.fragment,Uy),Uy.forEach(t),pTr=i(Dl),uo=n(Dl,"DIV",{class:!0});var Ba=s(uo);T(F$.$$.fragment,Ba),_Tr=i(Ba),R4e=n(Ba,"P",{});var GOt=s(R4e);bTr=r(GOt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),GOt.forEach(t),vTr=i(Ba),fn=n(Ba,"P",{});var Hy=s(fn);FTr=r(Hy,"The model class to instantiate is selected based on the "),P4e=n(Hy,"CODE",{});var OOt=s(P4e);TTr=r(OOt,"model_type"),OOt.forEach(t),MTr=r(Hy,` property of the config object (either
passed as an argument or loaded from `),B4e=n(Hy,"CODE",{});var VOt=s(B4e);ETr=r(VOt,"pretrained_model_name_or_path"),VOt.forEach(t),CTr=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=n(Hy,"CODE",{});var XOt=s(I4e);wTr=r(XOt,"pretrained_model_name_or_path"),XOt.forEach(t),ATr=r(Hy,":"),Hy.forEach(t),LTr=i(Ba),N4e=n(Ba,"UL",{});var zOt=s(N4e);A4=n(zOt,"LI",{});var FXe=s(A4);q4e=n(FXe,"STRONG",{});var QOt=s(q4e);yTr=r(QOt,"vilt"),QOt.forEach(t),xTr=r(FXe," \u2014 "),IY=n(FXe,"A",{href:!0});var WOt=s(IY);$Tr=r(WOt,"ViltForQuestionAnswering"),WOt.forEach(t),kTr=r(FXe," (ViLT model)"),FXe.forEach(t),zOt.forEach(t),STr=i(Ba),L4=n(Ba,"P",{});var TXe=s(L4);RTr=r(TXe,"The model is set in evaluation mode by default using "),j4e=n(TXe,"CODE",{});var UOt=s(j4e);PTr=r(UOt,"model.eval()"),UOt.forEach(t),BTr=r(TXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D4e=n(TXe,"CODE",{});var HOt=s(D4e);ITr=r(HOt,"model.train()"),HOt.forEach(t),TXe.forEach(t),NTr=i(Ba),T(y4.$$.fragment,Ba),Ba.forEach(t),Dl.forEach(t),MKe=i(m),mc=n(m,"H2",{class:!0});var Ieo=s(mc);x4=n(Ieo,"A",{id:!0,class:!0,href:!0});var JOt=s(x4);G4e=n(JOt,"SPAN",{});var YOt=s(G4e);T(T$.$$.fragment,YOt),YOt.forEach(t),JOt.forEach(t),qTr=i(Ieo),O4e=n(Ieo,"SPAN",{});var KOt=s(O4e);jTr=r(KOt,"AutoModelForAudioClassification"),KOt.forEach(t),Ieo.forEach(t),EKe=i(m),Jo=n(m,"DIV",{class:!0});var Gl=s(Jo);T(M$.$$.fragment,Gl),DTr=i(Gl),fc=n(Gl,"P",{});var Ale=s(fc);GTr=r(Ale,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),NY=n(Ale,"A",{href:!0});var ZOt=s(NY);OTr=r(ZOt,"from_pretrained()"),ZOt.forEach(t),VTr=r(Ale," class method or the "),qY=n(Ale,"A",{href:!0});var eVt=s(qY);XTr=r(eVt,"from_config()"),eVt.forEach(t),zTr=r(Ale,` class
method.`),Ale.forEach(t),QTr=i(Gl),E$=n(Gl,"P",{});var Neo=s(E$);WTr=r(Neo,"This class cannot be instantiated directly using "),V4e=n(Neo,"CODE",{});var oVt=s(V4e);UTr=r(oVt,"__init__()"),oVt.forEach(t),HTr=r(Neo," (throws an error)."),Neo.forEach(t),JTr=i(Gl),Pt=n(Gl,"DIV",{class:!0});var Jy=s(Pt);T(C$.$$.fragment,Jy),YTr=i(Jy),X4e=n(Jy,"P",{});var rVt=s(X4e);KTr=r(rVt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),rVt.forEach(t),ZTr=i(Jy),gc=n(Jy,"P",{});var Lle=s(gc);eMr=r(Lle,`Note:
Loading a model from its configuration file does `),z4e=n(Lle,"STRONG",{});var tVt=s(z4e);oMr=r(tVt,"not"),tVt.forEach(t),rMr=r(Lle,` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=n(Lle,"A",{href:!0});var aVt=s(jY);tMr=r(aVt,"from_pretrained()"),aVt.forEach(t),aMr=r(Lle," to load the model weights."),Lle.forEach(t),nMr=i(Jy),T($4.$$.fragment,Jy),Jy.forEach(t),sMr=i(Gl),po=n(Gl,"DIV",{class:!0});var Ia=s(po);T(w$.$$.fragment,Ia),lMr=i(Ia),Q4e=n(Ia,"P",{});var nVt=s(Q4e);iMr=r(nVt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),nVt.forEach(t),dMr=i(Ia),gn=n(Ia,"P",{});var Yy=s(gn);cMr=r(Yy,"The model class to instantiate is selected based on the "),W4e=n(Yy,"CODE",{});var sVt=s(W4e);mMr=r(sVt,"model_type"),sVt.forEach(t),fMr=r(Yy,` property of the config object (either
passed as an argument or loaded from `),U4e=n(Yy,"CODE",{});var lVt=s(U4e);gMr=r(lVt,"pretrained_model_name_or_path"),lVt.forEach(t),hMr=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H4e=n(Yy,"CODE",{});var iVt=s(H4e);uMr=r(iVt,"pretrained_model_name_or_path"),iVt.forEach(t),pMr=r(Yy,":"),Yy.forEach(t),_Mr=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);k4=n(Qe,"LI",{});var MXe=s(k4);J4e=n(MXe,"STRONG",{});var dVt=s(J4e);bMr=r(dVt,"data2vec-audio"),dVt.forEach(t),vMr=r(MXe," \u2014 "),DY=n(MXe,"A",{href:!0});var cVt=s(DY);FMr=r(cVt,"Data2VecAudioForSequenceClassification"),cVt.forEach(t),TMr=r(MXe," (Data2VecAudio model)"),MXe.forEach(t),MMr=i(Qe),S4=n(Qe,"LI",{});var EXe=s(S4);Y4e=n(EXe,"STRONG",{});var mVt=s(Y4e);EMr=r(mVt,"hubert"),mVt.forEach(t),CMr=r(EXe," \u2014 "),GY=n(EXe,"A",{href:!0});var fVt=s(GY);wMr=r(fVt,"HubertForSequenceClassification"),fVt.forEach(t),AMr=r(EXe," (Hubert model)"),EXe.forEach(t),LMr=i(Qe),R4=n(Qe,"LI",{});var CXe=s(R4);K4e=n(CXe,"STRONG",{});var gVt=s(K4e);yMr=r(gVt,"sew"),gVt.forEach(t),xMr=r(CXe," \u2014 "),OY=n(CXe,"A",{href:!0});var hVt=s(OY);$Mr=r(hVt,"SEWForSequenceClassification"),hVt.forEach(t),kMr=r(CXe," (SEW model)"),CXe.forEach(t),SMr=i(Qe),P4=n(Qe,"LI",{});var wXe=s(P4);Z4e=n(wXe,"STRONG",{});var uVt=s(Z4e);RMr=r(uVt,"sew-d"),uVt.forEach(t),PMr=r(wXe," \u2014 "),VY=n(wXe,"A",{href:!0});var pVt=s(VY);BMr=r(pVt,"SEWDForSequenceClassification"),pVt.forEach(t),IMr=r(wXe," (SEW-D model)"),wXe.forEach(t),NMr=i(Qe),B4=n(Qe,"LI",{});var AXe=s(B4);eCe=n(AXe,"STRONG",{});var _Vt=s(eCe);qMr=r(_Vt,"unispeech"),_Vt.forEach(t),jMr=r(AXe," \u2014 "),XY=n(AXe,"A",{href:!0});var bVt=s(XY);DMr=r(bVt,"UniSpeechForSequenceClassification"),bVt.forEach(t),GMr=r(AXe," (UniSpeech model)"),AXe.forEach(t),OMr=i(Qe),I4=n(Qe,"LI",{});var LXe=s(I4);oCe=n(LXe,"STRONG",{});var vVt=s(oCe);VMr=r(vVt,"unispeech-sat"),vVt.forEach(t),XMr=r(LXe," \u2014 "),zY=n(LXe,"A",{href:!0});var FVt=s(zY);zMr=r(FVt,"UniSpeechSatForSequenceClassification"),FVt.forEach(t),QMr=r(LXe," (UniSpeechSat model)"),LXe.forEach(t),WMr=i(Qe),N4=n(Qe,"LI",{});var yXe=s(N4);rCe=n(yXe,"STRONG",{});var TVt=s(rCe);UMr=r(TVt,"wav2vec2"),TVt.forEach(t),HMr=r(yXe," \u2014 "),QY=n(yXe,"A",{href:!0});var MVt=s(QY);JMr=r(MVt,"Wav2Vec2ForSequenceClassification"),MVt.forEach(t),YMr=r(yXe," (Wav2Vec2 model)"),yXe.forEach(t),KMr=i(Qe),q4=n(Qe,"LI",{});var xXe=s(q4);tCe=n(xXe,"STRONG",{});var EVt=s(tCe);ZMr=r(EVt,"wav2vec2-conformer"),EVt.forEach(t),eEr=r(xXe," \u2014 "),WY=n(xXe,"A",{href:!0});var CVt=s(WY);oEr=r(CVt,"Wav2Vec2ConformerForSequenceClassification"),CVt.forEach(t),rEr=r(xXe," (Wav2Vec2-Conformer model)"),xXe.forEach(t),tEr=i(Qe),j4=n(Qe,"LI",{});var $Xe=s(j4);aCe=n($Xe,"STRONG",{});var wVt=s(aCe);aEr=r(wVt,"wavlm"),wVt.forEach(t),nEr=r($Xe," \u2014 "),UY=n($Xe,"A",{href:!0});var AVt=s(UY);sEr=r(AVt,"WavLMForSequenceClassification"),AVt.forEach(t),lEr=r($Xe," (WavLM model)"),$Xe.forEach(t),Qe.forEach(t),iEr=i(Ia),D4=n(Ia,"P",{});var kXe=s(D4);dEr=r(kXe,"The model is set in evaluation mode by default using "),nCe=n(kXe,"CODE",{});var LVt=s(nCe);cEr=r(LVt,"model.eval()"),LVt.forEach(t),mEr=r(kXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sCe=n(kXe,"CODE",{});var yVt=s(sCe);fEr=r(yVt,"model.train()"),yVt.forEach(t),kXe.forEach(t),gEr=i(Ia),T(G4.$$.fragment,Ia),Ia.forEach(t),Gl.forEach(t),CKe=i(m),hc=n(m,"H2",{class:!0});var qeo=s(hc);O4=n(qeo,"A",{id:!0,class:!0,href:!0});var xVt=s(O4);lCe=n(xVt,"SPAN",{});var $Vt=s(lCe);T(A$.$$.fragment,$Vt),$Vt.forEach(t),xVt.forEach(t),hEr=i(qeo),iCe=n(qeo,"SPAN",{});var kVt=s(iCe);uEr=r(kVt,"AutoModelForAudioFrameClassification"),kVt.forEach(t),qeo.forEach(t),wKe=i(m),Yo=n(m,"DIV",{class:!0});var Ol=s(Yo);T(L$.$$.fragment,Ol),pEr=i(Ol),uc=n(Ol,"P",{});var yle=s(uc);_Er=r(yle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),HY=n(yle,"A",{href:!0});var SVt=s(HY);bEr=r(SVt,"from_pretrained()"),SVt.forEach(t),vEr=r(yle," class method or the "),JY=n(yle,"A",{href:!0});var RVt=s(JY);FEr=r(RVt,"from_config()"),RVt.forEach(t),TEr=r(yle,` class
method.`),yle.forEach(t),MEr=i(Ol),y$=n(Ol,"P",{});var jeo=s(y$);EEr=r(jeo,"This class cannot be instantiated directly using "),dCe=n(jeo,"CODE",{});var PVt=s(dCe);CEr=r(PVt,"__init__()"),PVt.forEach(t),wEr=r(jeo," (throws an error)."),jeo.forEach(t),AEr=i(Ol),Bt=n(Ol,"DIV",{class:!0});var Ky=s(Bt);T(x$.$$.fragment,Ky),LEr=i(Ky),cCe=n(Ky,"P",{});var BVt=s(cCe);yEr=r(BVt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),BVt.forEach(t),xEr=i(Ky),pc=n(Ky,"P",{});var xle=s(pc);$Er=r(xle,`Note:
Loading a model from its configuration file does `),mCe=n(xle,"STRONG",{});var IVt=s(mCe);kEr=r(IVt,"not"),IVt.forEach(t),SEr=r(xle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=n(xle,"A",{href:!0});var NVt=s(YY);REr=r(NVt,"from_pretrained()"),NVt.forEach(t),PEr=r(xle," to load the model weights."),xle.forEach(t),BEr=i(Ky),T(V4.$$.fragment,Ky),Ky.forEach(t),IEr=i(Ol),_o=n(Ol,"DIV",{class:!0});var Na=s(_o);T($$.$$.fragment,Na),NEr=i(Na),fCe=n(Na,"P",{});var qVt=s(fCe);qEr=r(qVt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),qVt.forEach(t),jEr=i(Na),hn=n(Na,"P",{});var Zy=s(hn);DEr=r(Zy,"The model class to instantiate is selected based on the "),gCe=n(Zy,"CODE",{});var jVt=s(gCe);GEr=r(jVt,"model_type"),jVt.forEach(t),OEr=r(Zy,` property of the config object (either
passed as an argument or loaded from `),hCe=n(Zy,"CODE",{});var DVt=s(hCe);VEr=r(DVt,"pretrained_model_name_or_path"),DVt.forEach(t),XEr=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=n(Zy,"CODE",{});var GVt=s(uCe);zEr=r(GVt,"pretrained_model_name_or_path"),GVt.forEach(t),QEr=r(Zy,":"),Zy.forEach(t),WEr=i(Na),mt=n(Na,"UL",{});var Vl=s(mt);X4=n(Vl,"LI",{});var SXe=s(X4);pCe=n(SXe,"STRONG",{});var OVt=s(pCe);UEr=r(OVt,"data2vec-audio"),OVt.forEach(t),HEr=r(SXe," \u2014 "),KY=n(SXe,"A",{href:!0});var VVt=s(KY);JEr=r(VVt,"Data2VecAudioForAudioFrameClassification"),VVt.forEach(t),YEr=r(SXe," (Data2VecAudio model)"),SXe.forEach(t),KEr=i(Vl),z4=n(Vl,"LI",{});var RXe=s(z4);_Ce=n(RXe,"STRONG",{});var XVt=s(_Ce);ZEr=r(XVt,"unispeech-sat"),XVt.forEach(t),e4r=r(RXe," \u2014 "),ZY=n(RXe,"A",{href:!0});var zVt=s(ZY);o4r=r(zVt,"UniSpeechSatForAudioFrameClassification"),zVt.forEach(t),r4r=r(RXe," (UniSpeechSat model)"),RXe.forEach(t),t4r=i(Vl),Q4=n(Vl,"LI",{});var PXe=s(Q4);bCe=n(PXe,"STRONG",{});var QVt=s(bCe);a4r=r(QVt,"wav2vec2"),QVt.forEach(t),n4r=r(PXe," \u2014 "),eK=n(PXe,"A",{href:!0});var WVt=s(eK);s4r=r(WVt,"Wav2Vec2ForAudioFrameClassification"),WVt.forEach(t),l4r=r(PXe," (Wav2Vec2 model)"),PXe.forEach(t),i4r=i(Vl),W4=n(Vl,"LI",{});var BXe=s(W4);vCe=n(BXe,"STRONG",{});var UVt=s(vCe);d4r=r(UVt,"wav2vec2-conformer"),UVt.forEach(t),c4r=r(BXe," \u2014 "),oK=n(BXe,"A",{href:!0});var HVt=s(oK);m4r=r(HVt,"Wav2Vec2ConformerForAudioFrameClassification"),HVt.forEach(t),f4r=r(BXe," (Wav2Vec2-Conformer model)"),BXe.forEach(t),g4r=i(Vl),U4=n(Vl,"LI",{});var IXe=s(U4);FCe=n(IXe,"STRONG",{});var JVt=s(FCe);h4r=r(JVt,"wavlm"),JVt.forEach(t),u4r=r(IXe," \u2014 "),rK=n(IXe,"A",{href:!0});var YVt=s(rK);p4r=r(YVt,"WavLMForAudioFrameClassification"),YVt.forEach(t),_4r=r(IXe," (WavLM model)"),IXe.forEach(t),Vl.forEach(t),b4r=i(Na),H4=n(Na,"P",{});var NXe=s(H4);v4r=r(NXe,"The model is set in evaluation mode by default using "),TCe=n(NXe,"CODE",{});var KVt=s(TCe);F4r=r(KVt,"model.eval()"),KVt.forEach(t),T4r=r(NXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MCe=n(NXe,"CODE",{});var ZVt=s(MCe);M4r=r(ZVt,"model.train()"),ZVt.forEach(t),NXe.forEach(t),E4r=i(Na),T(J4.$$.fragment,Na),Na.forEach(t),Ol.forEach(t),AKe=i(m),_c=n(m,"H2",{class:!0});var Deo=s(_c);Y4=n(Deo,"A",{id:!0,class:!0,href:!0});var eXt=s(Y4);ECe=n(eXt,"SPAN",{});var oXt=s(ECe);T(k$.$$.fragment,oXt),oXt.forEach(t),eXt.forEach(t),C4r=i(Deo),CCe=n(Deo,"SPAN",{});var rXt=s(CCe);w4r=r(rXt,"AutoModelForCTC"),rXt.forEach(t),Deo.forEach(t),LKe=i(m),Ko=n(m,"DIV",{class:!0});var Xl=s(Ko);T(S$.$$.fragment,Xl),A4r=i(Xl),bc=n(Xl,"P",{});var $le=s(bc);L4r=r($le,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),tK=n($le,"A",{href:!0});var tXt=s(tK);y4r=r(tXt,"from_pretrained()"),tXt.forEach(t),x4r=r($le," class method or the "),aK=n($le,"A",{href:!0});var aXt=s(aK);$4r=r(aXt,"from_config()"),aXt.forEach(t),k4r=r($le,` class
method.`),$le.forEach(t),S4r=i(Xl),R$=n(Xl,"P",{});var Geo=s(R$);R4r=r(Geo,"This class cannot be instantiated directly using "),wCe=n(Geo,"CODE",{});var nXt=s(wCe);P4r=r(nXt,"__init__()"),nXt.forEach(t),B4r=r(Geo," (throws an error)."),Geo.forEach(t),I4r=i(Xl),It=n(Xl,"DIV",{class:!0});var e8=s(It);T(P$.$$.fragment,e8),N4r=i(e8),ACe=n(e8,"P",{});var sXt=s(ACe);q4r=r(sXt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),sXt.forEach(t),j4r=i(e8),vc=n(e8,"P",{});var kle=s(vc);D4r=r(kle,`Note:
Loading a model from its configuration file does `),LCe=n(kle,"STRONG",{});var lXt=s(LCe);G4r=r(lXt,"not"),lXt.forEach(t),O4r=r(kle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(kle,"A",{href:!0});var iXt=s(nK);V4r=r(iXt,"from_pretrained()"),iXt.forEach(t),X4r=r(kle," to load the model weights."),kle.forEach(t),z4r=i(e8),T(K4.$$.fragment,e8),e8.forEach(t),Q4r=i(Xl),bo=n(Xl,"DIV",{class:!0});var qa=s(bo);T(B$.$$.fragment,qa),W4r=i(qa),yCe=n(qa,"P",{});var dXt=s(yCe);U4r=r(dXt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),dXt.forEach(t),H4r=i(qa),un=n(qa,"P",{});var o8=s(un);J4r=r(o8,"The model class to instantiate is selected based on the "),xCe=n(o8,"CODE",{});var cXt=s(xCe);Y4r=r(cXt,"model_type"),cXt.forEach(t),K4r=r(o8,` property of the config object (either
passed as an argument or loaded from `),$Ce=n(o8,"CODE",{});var mXt=s($Ce);Z4r=r(mXt,"pretrained_model_name_or_path"),mXt.forEach(t),eCr=r(o8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kCe=n(o8,"CODE",{});var fXt=s(kCe);oCr=r(fXt,"pretrained_model_name_or_path"),fXt.forEach(t),rCr=r(o8,":"),o8.forEach(t),tCr=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);Z4=n(Ie,"LI",{});var qXe=s(Z4);SCe=n(qXe,"STRONG",{});var gXt=s(SCe);aCr=r(gXt,"data2vec-audio"),gXt.forEach(t),nCr=r(qXe," \u2014 "),sK=n(qXe,"A",{href:!0});var hXt=s(sK);sCr=r(hXt,"Data2VecAudioForCTC"),hXt.forEach(t),lCr=r(qXe," (Data2VecAudio model)"),qXe.forEach(t),iCr=i(Ie),eC=n(Ie,"LI",{});var jXe=s(eC);RCe=n(jXe,"STRONG",{});var uXt=s(RCe);dCr=r(uXt,"hubert"),uXt.forEach(t),cCr=r(jXe," \u2014 "),lK=n(jXe,"A",{href:!0});var pXt=s(lK);mCr=r(pXt,"HubertForCTC"),pXt.forEach(t),fCr=r(jXe," (Hubert model)"),jXe.forEach(t),gCr=i(Ie),oC=n(Ie,"LI",{});var DXe=s(oC);PCe=n(DXe,"STRONG",{});var _Xt=s(PCe);hCr=r(_Xt,"mctct"),_Xt.forEach(t),uCr=r(DXe," \u2014 "),iK=n(DXe,"A",{href:!0});var bXt=s(iK);pCr=r(bXt,"MCTCTForCTC"),bXt.forEach(t),_Cr=r(DXe," (M-CTC-T model)"),DXe.forEach(t),bCr=i(Ie),rC=n(Ie,"LI",{});var GXe=s(rC);BCe=n(GXe,"STRONG",{});var vXt=s(BCe);vCr=r(vXt,"sew"),vXt.forEach(t),FCr=r(GXe," \u2014 "),dK=n(GXe,"A",{href:!0});var FXt=s(dK);TCr=r(FXt,"SEWForCTC"),FXt.forEach(t),MCr=r(GXe," (SEW model)"),GXe.forEach(t),ECr=i(Ie),tC=n(Ie,"LI",{});var OXe=s(tC);ICe=n(OXe,"STRONG",{});var TXt=s(ICe);CCr=r(TXt,"sew-d"),TXt.forEach(t),wCr=r(OXe," \u2014 "),cK=n(OXe,"A",{href:!0});var MXt=s(cK);ACr=r(MXt,"SEWDForCTC"),MXt.forEach(t),LCr=r(OXe," (SEW-D model)"),OXe.forEach(t),yCr=i(Ie),aC=n(Ie,"LI",{});var VXe=s(aC);NCe=n(VXe,"STRONG",{});var EXt=s(NCe);xCr=r(EXt,"unispeech"),EXt.forEach(t),$Cr=r(VXe," \u2014 "),mK=n(VXe,"A",{href:!0});var CXt=s(mK);kCr=r(CXt,"UniSpeechForCTC"),CXt.forEach(t),SCr=r(VXe," (UniSpeech model)"),VXe.forEach(t),RCr=i(Ie),nC=n(Ie,"LI",{});var XXe=s(nC);qCe=n(XXe,"STRONG",{});var wXt=s(qCe);PCr=r(wXt,"unispeech-sat"),wXt.forEach(t),BCr=r(XXe," \u2014 "),fK=n(XXe,"A",{href:!0});var AXt=s(fK);ICr=r(AXt,"UniSpeechSatForCTC"),AXt.forEach(t),NCr=r(XXe," (UniSpeechSat model)"),XXe.forEach(t),qCr=i(Ie),sC=n(Ie,"LI",{});var zXe=s(sC);jCe=n(zXe,"STRONG",{});var LXt=s(jCe);jCr=r(LXt,"wav2vec2"),LXt.forEach(t),DCr=r(zXe," \u2014 "),gK=n(zXe,"A",{href:!0});var yXt=s(gK);GCr=r(yXt,"Wav2Vec2ForCTC"),yXt.forEach(t),OCr=r(zXe," (Wav2Vec2 model)"),zXe.forEach(t),VCr=i(Ie),lC=n(Ie,"LI",{});var QXe=s(lC);DCe=n(QXe,"STRONG",{});var xXt=s(DCe);XCr=r(xXt,"wav2vec2-conformer"),xXt.forEach(t),zCr=r(QXe," \u2014 "),hK=n(QXe,"A",{href:!0});var $Xt=s(hK);QCr=r($Xt,"Wav2Vec2ConformerForCTC"),$Xt.forEach(t),WCr=r(QXe," (Wav2Vec2-Conformer model)"),QXe.forEach(t),UCr=i(Ie),iC=n(Ie,"LI",{});var WXe=s(iC);GCe=n(WXe,"STRONG",{});var kXt=s(GCe);HCr=r(kXt,"wavlm"),kXt.forEach(t),JCr=r(WXe," \u2014 "),uK=n(WXe,"A",{href:!0});var SXt=s(uK);YCr=r(SXt,"WavLMForCTC"),SXt.forEach(t),KCr=r(WXe," (WavLM model)"),WXe.forEach(t),Ie.forEach(t),ZCr=i(qa),dC=n(qa,"P",{});var UXe=s(dC);e3r=r(UXe,"The model is set in evaluation mode by default using "),OCe=n(UXe,"CODE",{});var RXt=s(OCe);o3r=r(RXt,"model.eval()"),RXt.forEach(t),r3r=r(UXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VCe=n(UXe,"CODE",{});var PXt=s(VCe);t3r=r(PXt,"model.train()"),PXt.forEach(t),UXe.forEach(t),a3r=i(qa),T(cC.$$.fragment,qa),qa.forEach(t),Xl.forEach(t),yKe=i(m),Fc=n(m,"H2",{class:!0});var Oeo=s(Fc);mC=n(Oeo,"A",{id:!0,class:!0,href:!0});var BXt=s(mC);XCe=n(BXt,"SPAN",{});var IXt=s(XCe);T(I$.$$.fragment,IXt),IXt.forEach(t),BXt.forEach(t),n3r=i(Oeo),zCe=n(Oeo,"SPAN",{});var NXt=s(zCe);s3r=r(NXt,"AutoModelForSpeechSeq2Seq"),NXt.forEach(t),Oeo.forEach(t),xKe=i(m),Zo=n(m,"DIV",{class:!0});var zl=s(Zo);T(N$.$$.fragment,zl),l3r=i(zl),Tc=n(zl,"P",{});var Sle=s(Tc);i3r=r(Sle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pK=n(Sle,"A",{href:!0});var qXt=s(pK);d3r=r(qXt,"from_pretrained()"),qXt.forEach(t),c3r=r(Sle," class method or the "),_K=n(Sle,"A",{href:!0});var jXt=s(_K);m3r=r(jXt,"from_config()"),jXt.forEach(t),f3r=r(Sle,` class
method.`),Sle.forEach(t),g3r=i(zl),q$=n(zl,"P",{});var Veo=s(q$);h3r=r(Veo,"This class cannot be instantiated directly using "),QCe=n(Veo,"CODE",{});var DXt=s(QCe);u3r=r(DXt,"__init__()"),DXt.forEach(t),p3r=r(Veo," (throws an error)."),Veo.forEach(t),_3r=i(zl),Nt=n(zl,"DIV",{class:!0});var r8=s(Nt);T(j$.$$.fragment,r8),b3r=i(r8),WCe=n(r8,"P",{});var GXt=s(WCe);v3r=r(GXt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),GXt.forEach(t),F3r=i(r8),Mc=n(r8,"P",{});var Rle=s(Mc);T3r=r(Rle,`Note:
Loading a model from its configuration file does `),UCe=n(Rle,"STRONG",{});var OXt=s(UCe);M3r=r(OXt,"not"),OXt.forEach(t),E3r=r(Rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=n(Rle,"A",{href:!0});var VXt=s(bK);C3r=r(VXt,"from_pretrained()"),VXt.forEach(t),w3r=r(Rle," to load the model weights."),Rle.forEach(t),A3r=i(r8),T(fC.$$.fragment,r8),r8.forEach(t),L3r=i(zl),vo=n(zl,"DIV",{class:!0});var ja=s(vo);T(D$.$$.fragment,ja),y3r=i(ja),HCe=n(ja,"P",{});var XXt=s(HCe);x3r=r(XXt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),XXt.forEach(t),$3r=i(ja),pn=n(ja,"P",{});var t8=s(pn);k3r=r(t8,"The model class to instantiate is selected based on the "),JCe=n(t8,"CODE",{});var zXt=s(JCe);S3r=r(zXt,"model_type"),zXt.forEach(t),R3r=r(t8,` property of the config object (either
passed as an argument or loaded from `),YCe=n(t8,"CODE",{});var QXt=s(YCe);P3r=r(QXt,"pretrained_model_name_or_path"),QXt.forEach(t),B3r=r(t8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=n(t8,"CODE",{});var WXt=s(KCe);I3r=r(WXt,"pretrained_model_name_or_path"),WXt.forEach(t),N3r=r(t8,":"),t8.forEach(t),q3r=i(ja),G$=n(ja,"UL",{});var Xeo=s(G$);gC=n(Xeo,"LI",{});var HXe=s(gC);ZCe=n(HXe,"STRONG",{});var UXt=s(ZCe);j3r=r(UXt,"speech-encoder-decoder"),UXt.forEach(t),D3r=r(HXe," \u2014 "),vK=n(HXe,"A",{href:!0});var HXt=s(vK);G3r=r(HXt,"SpeechEncoderDecoderModel"),HXt.forEach(t),O3r=r(HXe," (Speech Encoder decoder model)"),HXe.forEach(t),V3r=i(Xeo),hC=n(Xeo,"LI",{});var JXe=s(hC);e3e=n(JXe,"STRONG",{});var JXt=s(e3e);X3r=r(JXt,"speech_to_text"),JXt.forEach(t),z3r=r(JXe," \u2014 "),FK=n(JXe,"A",{href:!0});var YXt=s(FK);Q3r=r(YXt,"Speech2TextForConditionalGeneration"),YXt.forEach(t),W3r=r(JXe," (Speech2Text model)"),JXe.forEach(t),Xeo.forEach(t),U3r=i(ja),uC=n(ja,"P",{});var YXe=s(uC);H3r=r(YXe,"The model is set in evaluation mode by default using "),o3e=n(YXe,"CODE",{});var KXt=s(o3e);J3r=r(KXt,"model.eval()"),KXt.forEach(t),Y3r=r(YXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r3e=n(YXe,"CODE",{});var ZXt=s(r3e);K3r=r(ZXt,"model.train()"),ZXt.forEach(t),YXe.forEach(t),Z3r=i(ja),T(pC.$$.fragment,ja),ja.forEach(t),zl.forEach(t),$Ke=i(m),Ec=n(m,"H2",{class:!0});var zeo=s(Ec);_C=n(zeo,"A",{id:!0,class:!0,href:!0});var ezt=s(_C);t3e=n(ezt,"SPAN",{});var ozt=s(t3e);T(O$.$$.fragment,ozt),ozt.forEach(t),ezt.forEach(t),e5r=i(zeo),a3e=n(zeo,"SPAN",{});var rzt=s(a3e);o5r=r(rzt,"AutoModelForAudioXVector"),rzt.forEach(t),zeo.forEach(t),kKe=i(m),er=n(m,"DIV",{class:!0});var Ql=s(er);T(V$.$$.fragment,Ql),r5r=i(Ql),Cc=n(Ql,"P",{});var Ple=s(Cc);t5r=r(Ple,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),TK=n(Ple,"A",{href:!0});var tzt=s(TK);a5r=r(tzt,"from_pretrained()"),tzt.forEach(t),n5r=r(Ple," class method or the "),MK=n(Ple,"A",{href:!0});var azt=s(MK);s5r=r(azt,"from_config()"),azt.forEach(t),l5r=r(Ple,` class
method.`),Ple.forEach(t),i5r=i(Ql),X$=n(Ql,"P",{});var Qeo=s(X$);d5r=r(Qeo,"This class cannot be instantiated directly using "),n3e=n(Qeo,"CODE",{});var nzt=s(n3e);c5r=r(nzt,"__init__()"),nzt.forEach(t),m5r=r(Qeo," (throws an error)."),Qeo.forEach(t),f5r=i(Ql),qt=n(Ql,"DIV",{class:!0});var a8=s(qt);T(z$.$$.fragment,a8),g5r=i(a8),s3e=n(a8,"P",{});var szt=s(s3e);h5r=r(szt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),szt.forEach(t),u5r=i(a8),wc=n(a8,"P",{});var Ble=s(wc);p5r=r(Ble,`Note:
Loading a model from its configuration file does `),l3e=n(Ble,"STRONG",{});var lzt=s(l3e);_5r=r(lzt,"not"),lzt.forEach(t),b5r=r(Ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=n(Ble,"A",{href:!0});var izt=s(EK);v5r=r(izt,"from_pretrained()"),izt.forEach(t),F5r=r(Ble," to load the model weights."),Ble.forEach(t),T5r=i(a8),T(bC.$$.fragment,a8),a8.forEach(t),M5r=i(Ql),Fo=n(Ql,"DIV",{class:!0});var Da=s(Fo);T(Q$.$$.fragment,Da),E5r=i(Da),i3e=n(Da,"P",{});var dzt=s(i3e);C5r=r(dzt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dzt.forEach(t),w5r=i(Da),_n=n(Da,"P",{});var n8=s(_n);A5r=r(n8,"The model class to instantiate is selected based on the "),d3e=n(n8,"CODE",{});var czt=s(d3e);L5r=r(czt,"model_type"),czt.forEach(t),y5r=r(n8,` property of the config object (either
passed as an argument or loaded from `),c3e=n(n8,"CODE",{});var mzt=s(c3e);x5r=r(mzt,"pretrained_model_name_or_path"),mzt.forEach(t),$5r=r(n8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m3e=n(n8,"CODE",{});var fzt=s(m3e);k5r=r(fzt,"pretrained_model_name_or_path"),fzt.forEach(t),S5r=r(n8,":"),n8.forEach(t),R5r=i(Da),ft=n(Da,"UL",{});var Wl=s(ft);vC=n(Wl,"LI",{});var KXe=s(vC);f3e=n(KXe,"STRONG",{});var gzt=s(f3e);P5r=r(gzt,"data2vec-audio"),gzt.forEach(t),B5r=r(KXe," \u2014 "),CK=n(KXe,"A",{href:!0});var hzt=s(CK);I5r=r(hzt,"Data2VecAudioForXVector"),hzt.forEach(t),N5r=r(KXe," (Data2VecAudio model)"),KXe.forEach(t),q5r=i(Wl),FC=n(Wl,"LI",{});var ZXe=s(FC);g3e=n(ZXe,"STRONG",{});var uzt=s(g3e);j5r=r(uzt,"unispeech-sat"),uzt.forEach(t),D5r=r(ZXe," \u2014 "),wK=n(ZXe,"A",{href:!0});var pzt=s(wK);G5r=r(pzt,"UniSpeechSatForXVector"),pzt.forEach(t),O5r=r(ZXe," (UniSpeechSat model)"),ZXe.forEach(t),V5r=i(Wl),TC=n(Wl,"LI",{});var eze=s(TC);h3e=n(eze,"STRONG",{});var _zt=s(h3e);X5r=r(_zt,"wav2vec2"),_zt.forEach(t),z5r=r(eze," \u2014 "),AK=n(eze,"A",{href:!0});var bzt=s(AK);Q5r=r(bzt,"Wav2Vec2ForXVector"),bzt.forEach(t),W5r=r(eze," (Wav2Vec2 model)"),eze.forEach(t),U5r=i(Wl),MC=n(Wl,"LI",{});var oze=s(MC);u3e=n(oze,"STRONG",{});var vzt=s(u3e);H5r=r(vzt,"wav2vec2-conformer"),vzt.forEach(t),J5r=r(oze," \u2014 "),LK=n(oze,"A",{href:!0});var Fzt=s(LK);Y5r=r(Fzt,"Wav2Vec2ConformerForXVector"),Fzt.forEach(t),K5r=r(oze," (Wav2Vec2-Conformer model)"),oze.forEach(t),Z5r=i(Wl),EC=n(Wl,"LI",{});var rze=s(EC);p3e=n(rze,"STRONG",{});var Tzt=s(p3e);e0r=r(Tzt,"wavlm"),Tzt.forEach(t),o0r=r(rze," \u2014 "),yK=n(rze,"A",{href:!0});var Mzt=s(yK);r0r=r(Mzt,"WavLMForXVector"),Mzt.forEach(t),t0r=r(rze," (WavLM model)"),rze.forEach(t),Wl.forEach(t),a0r=i(Da),CC=n(Da,"P",{});var tze=s(CC);n0r=r(tze,"The model is set in evaluation mode by default using "),_3e=n(tze,"CODE",{});var Ezt=s(_3e);s0r=r(Ezt,"model.eval()"),Ezt.forEach(t),l0r=r(tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b3e=n(tze,"CODE",{});var Czt=s(b3e);i0r=r(Czt,"model.train()"),Czt.forEach(t),tze.forEach(t),d0r=i(Da),T(wC.$$.fragment,Da),Da.forEach(t),Ql.forEach(t),SKe=i(m),Ac=n(m,"H2",{class:!0});var Weo=s(Ac);AC=n(Weo,"A",{id:!0,class:!0,href:!0});var wzt=s(AC);v3e=n(wzt,"SPAN",{});var Azt=s(v3e);T(W$.$$.fragment,Azt),Azt.forEach(t),wzt.forEach(t),c0r=i(Weo),F3e=n(Weo,"SPAN",{});var Lzt=s(F3e);m0r=r(Lzt,"AutoModelForMaskedImageModeling"),Lzt.forEach(t),Weo.forEach(t),RKe=i(m),or=n(m,"DIV",{class:!0});var Ul=s(or);T(U$.$$.fragment,Ul),f0r=i(Ul),Lc=n(Ul,"P",{});var Ile=s(Lc);g0r=r(Ile,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xK=n(Ile,"A",{href:!0});var yzt=s(xK);h0r=r(yzt,"from_pretrained()"),yzt.forEach(t),u0r=r(Ile," class method or the "),$K=n(Ile,"A",{href:!0});var xzt=s($K);p0r=r(xzt,"from_config()"),xzt.forEach(t),_0r=r(Ile,` class
method.`),Ile.forEach(t),b0r=i(Ul),H$=n(Ul,"P",{});var Ueo=s(H$);v0r=r(Ueo,"This class cannot be instantiated directly using "),T3e=n(Ueo,"CODE",{});var $zt=s(T3e);F0r=r($zt,"__init__()"),$zt.forEach(t),T0r=r(Ueo," (throws an error)."),Ueo.forEach(t),M0r=i(Ul),jt=n(Ul,"DIV",{class:!0});var s8=s(jt);T(J$.$$.fragment,s8),E0r=i(s8),M3e=n(s8,"P",{});var kzt=s(M3e);C0r=r(kzt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),kzt.forEach(t),w0r=i(s8),yc=n(s8,"P",{});var Nle=s(yc);A0r=r(Nle,`Note:
Loading a model from its configuration file does `),E3e=n(Nle,"STRONG",{});var Szt=s(E3e);L0r=r(Szt,"not"),Szt.forEach(t),y0r=r(Nle,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(Nle,"A",{href:!0});var Rzt=s(kK);x0r=r(Rzt,"from_pretrained()"),Rzt.forEach(t),$0r=r(Nle," to load the model weights."),Nle.forEach(t),k0r=i(s8),T(LC.$$.fragment,s8),s8.forEach(t),S0r=i(Ul),To=n(Ul,"DIV",{class:!0});var Ga=s(To);T(Y$.$$.fragment,Ga),R0r=i(Ga),C3e=n(Ga,"P",{});var Pzt=s(C3e);P0r=r(Pzt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Pzt.forEach(t),B0r=i(Ga),bn=n(Ga,"P",{});var l8=s(bn);I0r=r(l8,"The model class to instantiate is selected based on the "),w3e=n(l8,"CODE",{});var Bzt=s(w3e);N0r=r(Bzt,"model_type"),Bzt.forEach(t),q0r=r(l8,` property of the config object (either
passed as an argument or loaded from `),A3e=n(l8,"CODE",{});var Izt=s(A3e);j0r=r(Izt,"pretrained_model_name_or_path"),Izt.forEach(t),D0r=r(l8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L3e=n(l8,"CODE",{});var Nzt=s(L3e);G0r=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),O0r=r(l8,":"),l8.forEach(t),V0r=i(Ga),vn=n(Ga,"UL",{});var i8=s(vn);yC=n(i8,"LI",{});var aze=s(yC);y3e=n(aze,"STRONG",{});var qzt=s(y3e);X0r=r(qzt,"deit"),qzt.forEach(t),z0r=r(aze," \u2014 "),SK=n(aze,"A",{href:!0});var jzt=s(SK);Q0r=r(jzt,"DeiTForMaskedImageModeling"),jzt.forEach(t),W0r=r(aze," (DeiT model)"),aze.forEach(t),U0r=i(i8),xC=n(i8,"LI",{});var nze=s(xC);x3e=n(nze,"STRONG",{});var Dzt=s(x3e);H0r=r(Dzt,"swin"),Dzt.forEach(t),J0r=r(nze," \u2014 "),RK=n(nze,"A",{href:!0});var Gzt=s(RK);Y0r=r(Gzt,"SwinForMaskedImageModeling"),Gzt.forEach(t),K0r=r(nze," (Swin Transformer model)"),nze.forEach(t),Z0r=i(i8),$C=n(i8,"LI",{});var sze=s($C);$3e=n(sze,"STRONG",{});var Ozt=s($3e);ewr=r(Ozt,"swinv2"),Ozt.forEach(t),owr=r(sze," \u2014 "),PK=n(sze,"A",{href:!0});var Vzt=s(PK);rwr=r(Vzt,"Swinv2ForMaskedImageModeling"),Vzt.forEach(t),twr=r(sze," (Swin Transformer V2 model)"),sze.forEach(t),awr=i(i8),kC=n(i8,"LI",{});var lze=s(kC);k3e=n(lze,"STRONG",{});var Xzt=s(k3e);nwr=r(Xzt,"vit"),Xzt.forEach(t),swr=r(lze," \u2014 "),BK=n(lze,"A",{href:!0});var zzt=s(BK);lwr=r(zzt,"ViTForMaskedImageModeling"),zzt.forEach(t),iwr=r(lze," (ViT model)"),lze.forEach(t),i8.forEach(t),dwr=i(Ga),SC=n(Ga,"P",{});var ize=s(SC);cwr=r(ize,"The model is set in evaluation mode by default using "),S3e=n(ize,"CODE",{});var Qzt=s(S3e);mwr=r(Qzt,"model.eval()"),Qzt.forEach(t),fwr=r(ize,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R3e=n(ize,"CODE",{});var Wzt=s(R3e);gwr=r(Wzt,"model.train()"),Wzt.forEach(t),ize.forEach(t),hwr=i(Ga),T(RC.$$.fragment,Ga),Ga.forEach(t),Ul.forEach(t),PKe=i(m),xc=n(m,"H2",{class:!0});var Heo=s(xc);PC=n(Heo,"A",{id:!0,class:!0,href:!0});var Uzt=s(PC);P3e=n(Uzt,"SPAN",{});var Hzt=s(P3e);T(K$.$$.fragment,Hzt),Hzt.forEach(t),Uzt.forEach(t),uwr=i(Heo),B3e=n(Heo,"SPAN",{});var Jzt=s(B3e);pwr=r(Jzt,"AutoModelForObjectDetection"),Jzt.forEach(t),Heo.forEach(t),BKe=i(m),rr=n(m,"DIV",{class:!0});var Hl=s(rr);T(Z$.$$.fragment,Hl),_wr=i(Hl),$c=n(Hl,"P",{});var qle=s($c);bwr=r(qle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IK=n(qle,"A",{href:!0});var Yzt=s(IK);vwr=r(Yzt,"from_pretrained()"),Yzt.forEach(t),Fwr=r(qle," class method or the "),NK=n(qle,"A",{href:!0});var Kzt=s(NK);Twr=r(Kzt,"from_config()"),Kzt.forEach(t),Mwr=r(qle,` class
method.`),qle.forEach(t),Ewr=i(Hl),ek=n(Hl,"P",{});var Jeo=s(ek);Cwr=r(Jeo,"This class cannot be instantiated directly using "),I3e=n(Jeo,"CODE",{});var Zzt=s(I3e);wwr=r(Zzt,"__init__()"),Zzt.forEach(t),Awr=r(Jeo," (throws an error)."),Jeo.forEach(t),Lwr=i(Hl),Dt=n(Hl,"DIV",{class:!0});var d8=s(Dt);T(ok.$$.fragment,d8),ywr=i(d8),N3e=n(d8,"P",{});var eQt=s(N3e);xwr=r(eQt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),eQt.forEach(t),$wr=i(d8),kc=n(d8,"P",{});var jle=s(kc);kwr=r(jle,`Note:
Loading a model from its configuration file does `),q3e=n(jle,"STRONG",{});var oQt=s(q3e);Swr=r(oQt,"not"),oQt.forEach(t),Rwr=r(jle,` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=n(jle,"A",{href:!0});var rQt=s(qK);Pwr=r(rQt,"from_pretrained()"),rQt.forEach(t),Bwr=r(jle," to load the model weights."),jle.forEach(t),Iwr=i(d8),T(BC.$$.fragment,d8),d8.forEach(t),Nwr=i(Hl),Mo=n(Hl,"DIV",{class:!0});var Oa=s(Mo);T(rk.$$.fragment,Oa),qwr=i(Oa),j3e=n(Oa,"P",{});var tQt=s(j3e);jwr=r(tQt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),tQt.forEach(t),Dwr=i(Oa),Fn=n(Oa,"P",{});var c8=s(Fn);Gwr=r(c8,"The model class to instantiate is selected based on the "),D3e=n(c8,"CODE",{});var aQt=s(D3e);Owr=r(aQt,"model_type"),aQt.forEach(t),Vwr=r(c8,` property of the config object (either
passed as an argument or loaded from `),G3e=n(c8,"CODE",{});var nQt=s(G3e);Xwr=r(nQt,"pretrained_model_name_or_path"),nQt.forEach(t),zwr=r(c8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O3e=n(c8,"CODE",{});var sQt=s(O3e);Qwr=r(sQt,"pretrained_model_name_or_path"),sQt.forEach(t),Wwr=r(c8,":"),c8.forEach(t),Uwr=i(Oa),tk=n(Oa,"UL",{});var Yeo=s(tk);IC=n(Yeo,"LI",{});var dze=s(IC);V3e=n(dze,"STRONG",{});var lQt=s(V3e);Hwr=r(lQt,"detr"),lQt.forEach(t),Jwr=r(dze," \u2014 "),jK=n(dze,"A",{href:!0});var iQt=s(jK);Ywr=r(iQt,"DetrForObjectDetection"),iQt.forEach(t),Kwr=r(dze," (DETR model)"),dze.forEach(t),Zwr=i(Yeo),NC=n(Yeo,"LI",{});var cze=s(NC);X3e=n(cze,"STRONG",{});var dQt=s(X3e);eAr=r(dQt,"yolos"),dQt.forEach(t),oAr=r(cze," \u2014 "),DK=n(cze,"A",{href:!0});var cQt=s(DK);rAr=r(cQt,"YolosForObjectDetection"),cQt.forEach(t),tAr=r(cze," (YOLOS model)"),cze.forEach(t),Yeo.forEach(t),aAr=i(Oa),qC=n(Oa,"P",{});var mze=s(qC);nAr=r(mze,"The model is set in evaluation mode by default using "),z3e=n(mze,"CODE",{});var mQt=s(z3e);sAr=r(mQt,"model.eval()"),mQt.forEach(t),lAr=r(mze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q3e=n(mze,"CODE",{});var fQt=s(Q3e);iAr=r(fQt,"model.train()"),fQt.forEach(t),mze.forEach(t),dAr=i(Oa),T(jC.$$.fragment,Oa),Oa.forEach(t),Hl.forEach(t),IKe=i(m),Sc=n(m,"H2",{class:!0});var Keo=s(Sc);DC=n(Keo,"A",{id:!0,class:!0,href:!0});var gQt=s(DC);W3e=n(gQt,"SPAN",{});var hQt=s(W3e);T(ak.$$.fragment,hQt),hQt.forEach(t),gQt.forEach(t),cAr=i(Keo),U3e=n(Keo,"SPAN",{});var uQt=s(U3e);mAr=r(uQt,"AutoModelForImageSegmentation"),uQt.forEach(t),Keo.forEach(t),NKe=i(m),tr=n(m,"DIV",{class:!0});var Jl=s(tr);T(nk.$$.fragment,Jl),fAr=i(Jl),Rc=n(Jl,"P",{});var Dle=s(Rc);gAr=r(Dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GK=n(Dle,"A",{href:!0});var pQt=s(GK);hAr=r(pQt,"from_pretrained()"),pQt.forEach(t),uAr=r(Dle," class method or the "),OK=n(Dle,"A",{href:!0});var _Qt=s(OK);pAr=r(_Qt,"from_config()"),_Qt.forEach(t),_Ar=r(Dle,` class
method.`),Dle.forEach(t),bAr=i(Jl),sk=n(Jl,"P",{});var Zeo=s(sk);vAr=r(Zeo,"This class cannot be instantiated directly using "),H3e=n(Zeo,"CODE",{});var bQt=s(H3e);FAr=r(bQt,"__init__()"),bQt.forEach(t),TAr=r(Zeo," (throws an error)."),Zeo.forEach(t),MAr=i(Jl),Gt=n(Jl,"DIV",{class:!0});var m8=s(Gt);T(lk.$$.fragment,m8),EAr=i(m8),J3e=n(m8,"P",{});var vQt=s(J3e);CAr=r(vQt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),vQt.forEach(t),wAr=i(m8),Pc=n(m8,"P",{});var Gle=s(Pc);AAr=r(Gle,`Note:
Loading a model from its configuration file does `),Y3e=n(Gle,"STRONG",{});var FQt=s(Y3e);LAr=r(FQt,"not"),FQt.forEach(t),yAr=r(Gle,` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=n(Gle,"A",{href:!0});var TQt=s(VK);xAr=r(TQt,"from_pretrained()"),TQt.forEach(t),$Ar=r(Gle," to load the model weights."),Gle.forEach(t),kAr=i(m8),T(GC.$$.fragment,m8),m8.forEach(t),SAr=i(Jl),Eo=n(Jl,"DIV",{class:!0});var Va=s(Eo);T(ik.$$.fragment,Va),RAr=i(Va),K3e=n(Va,"P",{});var MQt=s(K3e);PAr=r(MQt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),MQt.forEach(t),BAr=i(Va),Tn=n(Va,"P",{});var f8=s(Tn);IAr=r(f8,"The model class to instantiate is selected based on the "),Z3e=n(f8,"CODE",{});var EQt=s(Z3e);NAr=r(EQt,"model_type"),EQt.forEach(t),qAr=r(f8,` property of the config object (either
passed as an argument or loaded from `),e5e=n(f8,"CODE",{});var CQt=s(e5e);jAr=r(CQt,"pretrained_model_name_or_path"),CQt.forEach(t),DAr=r(f8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o5e=n(f8,"CODE",{});var wQt=s(o5e);GAr=r(wQt,"pretrained_model_name_or_path"),wQt.forEach(t),OAr=r(f8,":"),f8.forEach(t),VAr=i(Va),r5e=n(Va,"UL",{});var AQt=s(r5e);OC=n(AQt,"LI",{});var fze=s(OC);t5e=n(fze,"STRONG",{});var LQt=s(t5e);XAr=r(LQt,"detr"),LQt.forEach(t),zAr=r(fze," \u2014 "),XK=n(fze,"A",{href:!0});var yQt=s(XK);QAr=r(yQt,"DetrForSegmentation"),yQt.forEach(t),WAr=r(fze," (DETR model)"),fze.forEach(t),AQt.forEach(t),UAr=i(Va),VC=n(Va,"P",{});var gze=s(VC);HAr=r(gze,"The model is set in evaluation mode by default using "),a5e=n(gze,"CODE",{});var xQt=s(a5e);JAr=r(xQt,"model.eval()"),xQt.forEach(t),YAr=r(gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n5e=n(gze,"CODE",{});var $Qt=s(n5e);KAr=r($Qt,"model.train()"),$Qt.forEach(t),gze.forEach(t),ZAr=i(Va),T(XC.$$.fragment,Va),Va.forEach(t),Jl.forEach(t),qKe=i(m),Bc=n(m,"H2",{class:!0});var eoo=s(Bc);zC=n(eoo,"A",{id:!0,class:!0,href:!0});var kQt=s(zC);s5e=n(kQt,"SPAN",{});var SQt=s(s5e);T(dk.$$.fragment,SQt),SQt.forEach(t),kQt.forEach(t),e6r=i(eoo),l5e=n(eoo,"SPAN",{});var RQt=s(l5e);o6r=r(RQt,"AutoModelForSemanticSegmentation"),RQt.forEach(t),eoo.forEach(t),jKe=i(m),ar=n(m,"DIV",{class:!0});var Yl=s(ar);T(ck.$$.fragment,Yl),r6r=i(Yl),Ic=n(Yl,"P",{});var Ole=s(Ic);t6r=r(Ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zK=n(Ole,"A",{href:!0});var PQt=s(zK);a6r=r(PQt,"from_pretrained()"),PQt.forEach(t),n6r=r(Ole," class method or the "),QK=n(Ole,"A",{href:!0});var BQt=s(QK);s6r=r(BQt,"from_config()"),BQt.forEach(t),l6r=r(Ole,` class
method.`),Ole.forEach(t),i6r=i(Yl),mk=n(Yl,"P",{});var ooo=s(mk);d6r=r(ooo,"This class cannot be instantiated directly using "),i5e=n(ooo,"CODE",{});var IQt=s(i5e);c6r=r(IQt,"__init__()"),IQt.forEach(t),m6r=r(ooo," (throws an error)."),ooo.forEach(t),f6r=i(Yl),Ot=n(Yl,"DIV",{class:!0});var g8=s(Ot);T(fk.$$.fragment,g8),g6r=i(g8),d5e=n(g8,"P",{});var NQt=s(d5e);h6r=r(NQt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),NQt.forEach(t),u6r=i(g8),Nc=n(g8,"P",{});var Vle=s(Nc);p6r=r(Vle,`Note:
Loading a model from its configuration file does `),c5e=n(Vle,"STRONG",{});var qQt=s(c5e);_6r=r(qQt,"not"),qQt.forEach(t),b6r=r(Vle,` load the model weights. It only affects the
model\u2019s configuration. Use `),WK=n(Vle,"A",{href:!0});var jQt=s(WK);v6r=r(jQt,"from_pretrained()"),jQt.forEach(t),F6r=r(Vle," to load the model weights."),Vle.forEach(t),T6r=i(g8),T(QC.$$.fragment,g8),g8.forEach(t),M6r=i(Yl),Co=n(Yl,"DIV",{class:!0});var Xa=s(Co);T(gk.$$.fragment,Xa),E6r=i(Xa),m5e=n(Xa,"P",{});var DQt=s(m5e);C6r=r(DQt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),DQt.forEach(t),w6r=i(Xa),Mn=n(Xa,"P",{});var h8=s(Mn);A6r=r(h8,"The model class to instantiate is selected based on the "),f5e=n(h8,"CODE",{});var GQt=s(f5e);L6r=r(GQt,"model_type"),GQt.forEach(t),y6r=r(h8,` property of the config object (either
passed as an argument or loaded from `),g5e=n(h8,"CODE",{});var OQt=s(g5e);x6r=r(OQt,"pretrained_model_name_or_path"),OQt.forEach(t),$6r=r(h8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h5e=n(h8,"CODE",{});var VQt=s(h5e);k6r=r(VQt,"pretrained_model_name_or_path"),VQt.forEach(t),S6r=r(h8,":"),h8.forEach(t),R6r=i(Xa),gt=n(Xa,"UL",{});var Kl=s(gt);WC=n(Kl,"LI",{});var hze=s(WC);u5e=n(hze,"STRONG",{});var XQt=s(u5e);P6r=r(XQt,"beit"),XQt.forEach(t),B6r=r(hze," \u2014 "),UK=n(hze,"A",{href:!0});var zQt=s(UK);I6r=r(zQt,"BeitForSemanticSegmentation"),zQt.forEach(t),N6r=r(hze," (BEiT model)"),hze.forEach(t),q6r=i(Kl),UC=n(Kl,"LI",{});var uze=s(UC);p5e=n(uze,"STRONG",{});var QQt=s(p5e);j6r=r(QQt,"data2vec-vision"),QQt.forEach(t),D6r=r(uze," \u2014 "),HK=n(uze,"A",{href:!0});var WQt=s(HK);G6r=r(WQt,"Data2VecVisionForSemanticSegmentation"),WQt.forEach(t),O6r=r(uze," (Data2VecVision model)"),uze.forEach(t),V6r=i(Kl),HC=n(Kl,"LI",{});var pze=s(HC);_5e=n(pze,"STRONG",{});var UQt=s(_5e);X6r=r(UQt,"dpt"),UQt.forEach(t),z6r=r(pze," \u2014 "),JK=n(pze,"A",{href:!0});var HQt=s(JK);Q6r=r(HQt,"DPTForSemanticSegmentation"),HQt.forEach(t),W6r=r(pze," (DPT model)"),pze.forEach(t),U6r=i(Kl),JC=n(Kl,"LI",{});var _ze=s(JC);b5e=n(_ze,"STRONG",{});var JQt=s(b5e);H6r=r(JQt,"mobilevit"),JQt.forEach(t),J6r=r(_ze," \u2014 "),YK=n(_ze,"A",{href:!0});var YQt=s(YK);Y6r=r(YQt,"MobileViTForSemanticSegmentation"),YQt.forEach(t),K6r=r(_ze," (MobileViT model)"),_ze.forEach(t),Z6r=i(Kl),YC=n(Kl,"LI",{});var bze=s(YC);v5e=n(bze,"STRONG",{});var KQt=s(v5e);e7r=r(KQt,"segformer"),KQt.forEach(t),o7r=r(bze," \u2014 "),KK=n(bze,"A",{href:!0});var ZQt=s(KK);r7r=r(ZQt,"SegformerForSemanticSegmentation"),ZQt.forEach(t),t7r=r(bze," (SegFormer model)"),bze.forEach(t),Kl.forEach(t),a7r=i(Xa),KC=n(Xa,"P",{});var vze=s(KC);n7r=r(vze,"The model is set in evaluation mode by default using "),F5e=n(vze,"CODE",{});var eWt=s(F5e);s7r=r(eWt,"model.eval()"),eWt.forEach(t),l7r=r(vze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T5e=n(vze,"CODE",{});var oWt=s(T5e);i7r=r(oWt,"model.train()"),oWt.forEach(t),vze.forEach(t),d7r=i(Xa),T(ZC.$$.fragment,Xa),Xa.forEach(t),Yl.forEach(t),DKe=i(m),qc=n(m,"H2",{class:!0});var roo=s(qc);e3=n(roo,"A",{id:!0,class:!0,href:!0});var rWt=s(e3);M5e=n(rWt,"SPAN",{});var tWt=s(M5e);T(hk.$$.fragment,tWt),tWt.forEach(t),rWt.forEach(t),c7r=i(roo),E5e=n(roo,"SPAN",{});var aWt=s(E5e);m7r=r(aWt,"AutoModelForInstanceSegmentation"),aWt.forEach(t),roo.forEach(t),GKe=i(m),nr=n(m,"DIV",{class:!0});var Zl=s(nr);T(uk.$$.fragment,Zl),f7r=i(Zl),jc=n(Zl,"P",{});var Xle=s(jc);g7r=r(Xle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),ZK=n(Xle,"A",{href:!0});var nWt=s(ZK);h7r=r(nWt,"from_pretrained()"),nWt.forEach(t),u7r=r(Xle," class method or the "),eZ=n(Xle,"A",{href:!0});var sWt=s(eZ);p7r=r(sWt,"from_config()"),sWt.forEach(t),_7r=r(Xle,` class
method.`),Xle.forEach(t),b7r=i(Zl),pk=n(Zl,"P",{});var too=s(pk);v7r=r(too,"This class cannot be instantiated directly using "),C5e=n(too,"CODE",{});var lWt=s(C5e);F7r=r(lWt,"__init__()"),lWt.forEach(t),T7r=r(too," (throws an error)."),too.forEach(t),M7r=i(Zl),Vt=n(Zl,"DIV",{class:!0});var u8=s(Vt);T(_k.$$.fragment,u8),E7r=i(u8),w5e=n(u8,"P",{});var iWt=s(w5e);C7r=r(iWt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),iWt.forEach(t),w7r=i(u8),Dc=n(u8,"P",{});var zle=s(Dc);A7r=r(zle,`Note:
Loading a model from its configuration file does `),A5e=n(zle,"STRONG",{});var dWt=s(A5e);L7r=r(dWt,"not"),dWt.forEach(t),y7r=r(zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(zle,"A",{href:!0});var cWt=s(oZ);x7r=r(cWt,"from_pretrained()"),cWt.forEach(t),$7r=r(zle," to load the model weights."),zle.forEach(t),k7r=i(u8),T(o3.$$.fragment,u8),u8.forEach(t),S7r=i(Zl),wo=n(Zl,"DIV",{class:!0});var za=s(wo);T(bk.$$.fragment,za),R7r=i(za),L5e=n(za,"P",{});var mWt=s(L5e);P7r=r(mWt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),mWt.forEach(t),B7r=i(za),En=n(za,"P",{});var p8=s(En);I7r=r(p8,"The model class to instantiate is selected based on the "),y5e=n(p8,"CODE",{});var fWt=s(y5e);N7r=r(fWt,"model_type"),fWt.forEach(t),q7r=r(p8,` property of the config object (either
passed as an argument or loaded from `),x5e=n(p8,"CODE",{});var gWt=s(x5e);j7r=r(gWt,"pretrained_model_name_or_path"),gWt.forEach(t),D7r=r(p8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$5e=n(p8,"CODE",{});var hWt=s($5e);G7r=r(hWt,"pretrained_model_name_or_path"),hWt.forEach(t),O7r=r(p8,":"),p8.forEach(t),V7r=i(za),k5e=n(za,"UL",{});var uWt=s(k5e);r3=n(uWt,"LI",{});var Fze=s(r3);S5e=n(Fze,"STRONG",{});var pWt=s(S5e);X7r=r(pWt,"maskformer"),pWt.forEach(t),z7r=r(Fze," \u2014 "),rZ=n(Fze,"A",{href:!0});var _Wt=s(rZ);Q7r=r(_Wt,"MaskFormerForInstanceSegmentation"),_Wt.forEach(t),W7r=r(Fze," (MaskFormer model)"),Fze.forEach(t),uWt.forEach(t),U7r=i(za),t3=n(za,"P",{});var Tze=s(t3);H7r=r(Tze,"The model is set in evaluation mode by default using "),R5e=n(Tze,"CODE",{});var bWt=s(R5e);J7r=r(bWt,"model.eval()"),bWt.forEach(t),Y7r=r(Tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=n(Tze,"CODE",{});var vWt=s(P5e);K7r=r(vWt,"model.train()"),vWt.forEach(t),Tze.forEach(t),Z7r=i(za),T(a3.$$.fragment,za),za.forEach(t),Zl.forEach(t),OKe=i(m),Gc=n(m,"H2",{class:!0});var aoo=s(Gc);n3=n(aoo,"A",{id:!0,class:!0,href:!0});var FWt=s(n3);B5e=n(FWt,"SPAN",{});var TWt=s(B5e);T(vk.$$.fragment,TWt),TWt.forEach(t),FWt.forEach(t),eLr=i(aoo),I5e=n(aoo,"SPAN",{});var MWt=s(I5e);oLr=r(MWt,"TFAutoModel"),MWt.forEach(t),aoo.forEach(t),VKe=i(m),sr=n(m,"DIV",{class:!0});var ei=s(sr);T(Fk.$$.fragment,ei),rLr=i(ei),Oc=n(ei,"P",{});var Qle=s(Oc);tLr=r(Qle,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tZ=n(Qle,"A",{href:!0});var EWt=s(tZ);aLr=r(EWt,"from_pretrained()"),EWt.forEach(t),nLr=r(Qle," class method or the "),aZ=n(Qle,"A",{href:!0});var CWt=s(aZ);sLr=r(CWt,"from_config()"),CWt.forEach(t),lLr=r(Qle,` class
method.`),Qle.forEach(t),iLr=i(ei),Tk=n(ei,"P",{});var noo=s(Tk);dLr=r(noo,"This class cannot be instantiated directly using "),N5e=n(noo,"CODE",{});var wWt=s(N5e);cLr=r(wWt,"__init__()"),wWt.forEach(t),mLr=r(noo," (throws an error)."),noo.forEach(t),fLr=i(ei),Xt=n(ei,"DIV",{class:!0});var _8=s(Xt);T(Mk.$$.fragment,_8),gLr=i(_8),q5e=n(_8,"P",{});var AWt=s(q5e);hLr=r(AWt,"Instantiates one of the base model classes of the library from a configuration."),AWt.forEach(t),uLr=i(_8),Vc=n(_8,"P",{});var Wle=s(Vc);pLr=r(Wle,`Note:
Loading a model from its configuration file does `),j5e=n(Wle,"STRONG",{});var LWt=s(j5e);_Lr=r(LWt,"not"),LWt.forEach(t),bLr=r(Wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=n(Wle,"A",{href:!0});var yWt=s(nZ);vLr=r(yWt,"from_pretrained()"),yWt.forEach(t),FLr=r(Wle," to load the model weights."),Wle.forEach(t),TLr=i(_8),T(s3.$$.fragment,_8),_8.forEach(t),MLr=i(ei),Ir=n(ei,"DIV",{class:!0});var oi=s(Ir);T(Ek.$$.fragment,oi),ELr=i(oi),D5e=n(oi,"P",{});var xWt=s(D5e);CLr=r(xWt,"Instantiate one of the base model classes of the library from a pretrained model."),xWt.forEach(t),wLr=i(oi),Cn=n(oi,"P",{});var b8=s(Cn);ALr=r(b8,"The model class to instantiate is selected based on the "),G5e=n(b8,"CODE",{});var $Wt=s(G5e);LLr=r($Wt,"model_type"),$Wt.forEach(t),yLr=r(b8,` property of the config object (either
passed as an argument or loaded from `),O5e=n(b8,"CODE",{});var kWt=s(O5e);xLr=r(kWt,"pretrained_model_name_or_path"),kWt.forEach(t),$Lr=r(b8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=n(b8,"CODE",{});var SWt=s(V5e);kLr=r(SWt,"pretrained_model_name_or_path"),SWt.forEach(t),SLr=r(b8,":"),b8.forEach(t),RLr=i(oi),N=n(oi,"UL",{});var j=s(N);l3=n(j,"LI",{});var Mze=s(l3);X5e=n(Mze,"STRONG",{});var RWt=s(X5e);PLr=r(RWt,"albert"),RWt.forEach(t),BLr=r(Mze," \u2014 "),sZ=n(Mze,"A",{href:!0});var PWt=s(sZ);ILr=r(PWt,"TFAlbertModel"),PWt.forEach(t),NLr=r(Mze," (ALBERT model)"),Mze.forEach(t),qLr=i(j),i3=n(j,"LI",{});var Eze=s(i3);z5e=n(Eze,"STRONG",{});var BWt=s(z5e);jLr=r(BWt,"bart"),BWt.forEach(t),DLr=r(Eze," \u2014 "),lZ=n(Eze,"A",{href:!0});var IWt=s(lZ);GLr=r(IWt,"TFBartModel"),IWt.forEach(t),OLr=r(Eze," (BART model)"),Eze.forEach(t),VLr=i(j),d3=n(j,"LI",{});var Cze=s(d3);Q5e=n(Cze,"STRONG",{});var NWt=s(Q5e);XLr=r(NWt,"bert"),NWt.forEach(t),zLr=r(Cze," \u2014 "),iZ=n(Cze,"A",{href:!0});var qWt=s(iZ);QLr=r(qWt,"TFBertModel"),qWt.forEach(t),WLr=r(Cze," (BERT model)"),Cze.forEach(t),ULr=i(j),c3=n(j,"LI",{});var wze=s(c3);W5e=n(wze,"STRONG",{});var jWt=s(W5e);HLr=r(jWt,"blenderbot"),jWt.forEach(t),JLr=r(wze," \u2014 "),dZ=n(wze,"A",{href:!0});var DWt=s(dZ);YLr=r(DWt,"TFBlenderbotModel"),DWt.forEach(t),KLr=r(wze," (Blenderbot model)"),wze.forEach(t),ZLr=i(j),m3=n(j,"LI",{});var Aze=s(m3);U5e=n(Aze,"STRONG",{});var GWt=s(U5e);eyr=r(GWt,"blenderbot-small"),GWt.forEach(t),oyr=r(Aze," \u2014 "),cZ=n(Aze,"A",{href:!0});var OWt=s(cZ);ryr=r(OWt,"TFBlenderbotSmallModel"),OWt.forEach(t),tyr=r(Aze," (BlenderbotSmall model)"),Aze.forEach(t),ayr=i(j),f3=n(j,"LI",{});var Lze=s(f3);H5e=n(Lze,"STRONG",{});var VWt=s(H5e);nyr=r(VWt,"camembert"),VWt.forEach(t),syr=r(Lze," \u2014 "),mZ=n(Lze,"A",{href:!0});var XWt=s(mZ);lyr=r(XWt,"TFCamembertModel"),XWt.forEach(t),iyr=r(Lze," (CamemBERT model)"),Lze.forEach(t),dyr=i(j),g3=n(j,"LI",{});var yze=s(g3);J5e=n(yze,"STRONG",{});var zWt=s(J5e);cyr=r(zWt,"clip"),zWt.forEach(t),myr=r(yze," \u2014 "),fZ=n(yze,"A",{href:!0});var QWt=s(fZ);fyr=r(QWt,"TFCLIPModel"),QWt.forEach(t),gyr=r(yze," (CLIP model)"),yze.forEach(t),hyr=i(j),h3=n(j,"LI",{});var xze=s(h3);Y5e=n(xze,"STRONG",{});var WWt=s(Y5e);uyr=r(WWt,"convbert"),WWt.forEach(t),pyr=r(xze," \u2014 "),gZ=n(xze,"A",{href:!0});var UWt=s(gZ);_yr=r(UWt,"TFConvBertModel"),UWt.forEach(t),byr=r(xze," (ConvBERT model)"),xze.forEach(t),vyr=i(j),u3=n(j,"LI",{});var $ze=s(u3);K5e=n($ze,"STRONG",{});var HWt=s(K5e);Fyr=r(HWt,"convnext"),HWt.forEach(t),Tyr=r($ze," \u2014 "),hZ=n($ze,"A",{href:!0});var JWt=s(hZ);Myr=r(JWt,"TFConvNextModel"),JWt.forEach(t),Eyr=r($ze," (ConvNeXT model)"),$ze.forEach(t),Cyr=i(j),p3=n(j,"LI",{});var kze=s(p3);Z5e=n(kze,"STRONG",{});var YWt=s(Z5e);wyr=r(YWt,"ctrl"),YWt.forEach(t),Ayr=r(kze," \u2014 "),uZ=n(kze,"A",{href:!0});var KWt=s(uZ);Lyr=r(KWt,"TFCTRLModel"),KWt.forEach(t),yyr=r(kze," (CTRL model)"),kze.forEach(t),xyr=i(j),_3=n(j,"LI",{});var Sze=s(_3);e0e=n(Sze,"STRONG",{});var ZWt=s(e0e);$yr=r(ZWt,"data2vec-vision"),ZWt.forEach(t),kyr=r(Sze," \u2014 "),pZ=n(Sze,"A",{href:!0});var eUt=s(pZ);Syr=r(eUt,"TFData2VecVisionModel"),eUt.forEach(t),Ryr=r(Sze," (Data2VecVision model)"),Sze.forEach(t),Pyr=i(j),b3=n(j,"LI",{});var Rze=s(b3);o0e=n(Rze,"STRONG",{});var oUt=s(o0e);Byr=r(oUt,"deberta"),oUt.forEach(t),Iyr=r(Rze," \u2014 "),_Z=n(Rze,"A",{href:!0});var rUt=s(_Z);Nyr=r(rUt,"TFDebertaModel"),rUt.forEach(t),qyr=r(Rze," (DeBERTa model)"),Rze.forEach(t),jyr=i(j),v3=n(j,"LI",{});var Pze=s(v3);r0e=n(Pze,"STRONG",{});var tUt=s(r0e);Dyr=r(tUt,"deberta-v2"),tUt.forEach(t),Gyr=r(Pze," \u2014 "),bZ=n(Pze,"A",{href:!0});var aUt=s(bZ);Oyr=r(aUt,"TFDebertaV2Model"),aUt.forEach(t),Vyr=r(Pze," (DeBERTa-v2 model)"),Pze.forEach(t),Xyr=i(j),F3=n(j,"LI",{});var Bze=s(F3);t0e=n(Bze,"STRONG",{});var nUt=s(t0e);zyr=r(nUt,"deit"),nUt.forEach(t),Qyr=r(Bze," \u2014 "),vZ=n(Bze,"A",{href:!0});var sUt=s(vZ);Wyr=r(sUt,"TFDeiTModel"),sUt.forEach(t),Uyr=r(Bze," (DeiT model)"),Bze.forEach(t),Hyr=i(j),T3=n(j,"LI",{});var Ize=s(T3);a0e=n(Ize,"STRONG",{});var lUt=s(a0e);Jyr=r(lUt,"distilbert"),lUt.forEach(t),Yyr=r(Ize," \u2014 "),FZ=n(Ize,"A",{href:!0});var iUt=s(FZ);Kyr=r(iUt,"TFDistilBertModel"),iUt.forEach(t),Zyr=r(Ize," (DistilBERT model)"),Ize.forEach(t),e8r=i(j),M3=n(j,"LI",{});var Nze=s(M3);n0e=n(Nze,"STRONG",{});var dUt=s(n0e);o8r=r(dUt,"dpr"),dUt.forEach(t),r8r=r(Nze," \u2014 "),TZ=n(Nze,"A",{href:!0});var cUt=s(TZ);t8r=r(cUt,"TFDPRQuestionEncoder"),cUt.forEach(t),a8r=r(Nze," (DPR model)"),Nze.forEach(t),n8r=i(j),E3=n(j,"LI",{});var qze=s(E3);s0e=n(qze,"STRONG",{});var mUt=s(s0e);s8r=r(mUt,"electra"),mUt.forEach(t),l8r=r(qze," \u2014 "),MZ=n(qze,"A",{href:!0});var fUt=s(MZ);i8r=r(fUt,"TFElectraModel"),fUt.forEach(t),d8r=r(qze," (ELECTRA model)"),qze.forEach(t),c8r=i(j),C3=n(j,"LI",{});var jze=s(C3);l0e=n(jze,"STRONG",{});var gUt=s(l0e);m8r=r(gUt,"flaubert"),gUt.forEach(t),f8r=r(jze," \u2014 "),EZ=n(jze,"A",{href:!0});var hUt=s(EZ);g8r=r(hUt,"TFFlaubertModel"),hUt.forEach(t),h8r=r(jze," (FlauBERT model)"),jze.forEach(t),u8r=i(j),vl=n(j,"LI",{});var MB=s(vl);i0e=n(MB,"STRONG",{});var uUt=s(i0e);p8r=r(uUt,"funnel"),uUt.forEach(t),_8r=r(MB," \u2014 "),CZ=n(MB,"A",{href:!0});var pUt=s(CZ);b8r=r(pUt,"TFFunnelModel"),pUt.forEach(t),v8r=r(MB," or "),wZ=n(MB,"A",{href:!0});var _Ut=s(wZ);F8r=r(_Ut,"TFFunnelBaseModel"),_Ut.forEach(t),T8r=r(MB," (Funnel Transformer model)"),MB.forEach(t),M8r=i(j),w3=n(j,"LI",{});var Dze=s(w3);d0e=n(Dze,"STRONG",{});var bUt=s(d0e);E8r=r(bUt,"gpt2"),bUt.forEach(t),C8r=r(Dze," \u2014 "),AZ=n(Dze,"A",{href:!0});var vUt=s(AZ);w8r=r(vUt,"TFGPT2Model"),vUt.forEach(t),A8r=r(Dze," (OpenAI GPT-2 model)"),Dze.forEach(t),L8r=i(j),A3=n(j,"LI",{});var Gze=s(A3);c0e=n(Gze,"STRONG",{});var FUt=s(c0e);y8r=r(FUt,"gptj"),FUt.forEach(t),x8r=r(Gze," \u2014 "),LZ=n(Gze,"A",{href:!0});var TUt=s(LZ);$8r=r(TUt,"TFGPTJModel"),TUt.forEach(t),k8r=r(Gze," (GPT-J model)"),Gze.forEach(t),S8r=i(j),L3=n(j,"LI",{});var Oze=s(L3);m0e=n(Oze,"STRONG",{});var MUt=s(m0e);R8r=r(MUt,"hubert"),MUt.forEach(t),P8r=r(Oze," \u2014 "),yZ=n(Oze,"A",{href:!0});var EUt=s(yZ);B8r=r(EUt,"TFHubertModel"),EUt.forEach(t),I8r=r(Oze," (Hubert model)"),Oze.forEach(t),N8r=i(j),y3=n(j,"LI",{});var Vze=s(y3);f0e=n(Vze,"STRONG",{});var CUt=s(f0e);q8r=r(CUt,"layoutlm"),CUt.forEach(t),j8r=r(Vze," \u2014 "),xZ=n(Vze,"A",{href:!0});var wUt=s(xZ);D8r=r(wUt,"TFLayoutLMModel"),wUt.forEach(t),G8r=r(Vze," (LayoutLM model)"),Vze.forEach(t),O8r=i(j),x3=n(j,"LI",{});var Xze=s(x3);g0e=n(Xze,"STRONG",{});var AUt=s(g0e);V8r=r(AUt,"layoutlmv3"),AUt.forEach(t),X8r=r(Xze," \u2014 "),$Z=n(Xze,"A",{href:!0});var LUt=s($Z);z8r=r(LUt,"TFLayoutLMv3Model"),LUt.forEach(t),Q8r=r(Xze," (LayoutLMv3 model)"),Xze.forEach(t),W8r=i(j),$3=n(j,"LI",{});var zze=s($3);h0e=n(zze,"STRONG",{});var yUt=s(h0e);U8r=r(yUt,"led"),yUt.forEach(t),H8r=r(zze," \u2014 "),kZ=n(zze,"A",{href:!0});var xUt=s(kZ);J8r=r(xUt,"TFLEDModel"),xUt.forEach(t),Y8r=r(zze," (LED model)"),zze.forEach(t),K8r=i(j),k3=n(j,"LI",{});var Qze=s(k3);u0e=n(Qze,"STRONG",{});var $Ut=s(u0e);Z8r=r($Ut,"longformer"),$Ut.forEach(t),e9r=r(Qze," \u2014 "),SZ=n(Qze,"A",{href:!0});var kUt=s(SZ);o9r=r(kUt,"TFLongformerModel"),kUt.forEach(t),r9r=r(Qze," (Longformer model)"),Qze.forEach(t),t9r=i(j),S3=n(j,"LI",{});var Wze=s(S3);p0e=n(Wze,"STRONG",{});var SUt=s(p0e);a9r=r(SUt,"lxmert"),SUt.forEach(t),n9r=r(Wze," \u2014 "),RZ=n(Wze,"A",{href:!0});var RUt=s(RZ);s9r=r(RUt,"TFLxmertModel"),RUt.forEach(t),l9r=r(Wze," (LXMERT model)"),Wze.forEach(t),i9r=i(j),R3=n(j,"LI",{});var Uze=s(R3);_0e=n(Uze,"STRONG",{});var PUt=s(_0e);d9r=r(PUt,"marian"),PUt.forEach(t),c9r=r(Uze," \u2014 "),PZ=n(Uze,"A",{href:!0});var BUt=s(PZ);m9r=r(BUt,"TFMarianModel"),BUt.forEach(t),f9r=r(Uze," (Marian model)"),Uze.forEach(t),g9r=i(j),P3=n(j,"LI",{});var Hze=s(P3);b0e=n(Hze,"STRONG",{});var IUt=s(b0e);h9r=r(IUt,"mbart"),IUt.forEach(t),u9r=r(Hze," \u2014 "),BZ=n(Hze,"A",{href:!0});var NUt=s(BZ);p9r=r(NUt,"TFMBartModel"),NUt.forEach(t),_9r=r(Hze," (mBART model)"),Hze.forEach(t),b9r=i(j),B3=n(j,"LI",{});var Jze=s(B3);v0e=n(Jze,"STRONG",{});var qUt=s(v0e);v9r=r(qUt,"mobilebert"),qUt.forEach(t),F9r=r(Jze," \u2014 "),IZ=n(Jze,"A",{href:!0});var jUt=s(IZ);T9r=r(jUt,"TFMobileBertModel"),jUt.forEach(t),M9r=r(Jze," (MobileBERT model)"),Jze.forEach(t),E9r=i(j),I3=n(j,"LI",{});var Yze=s(I3);F0e=n(Yze,"STRONG",{});var DUt=s(F0e);C9r=r(DUt,"mobilevit"),DUt.forEach(t),w9r=r(Yze," \u2014 "),NZ=n(Yze,"A",{href:!0});var GUt=s(NZ);A9r=r(GUt,"TFMobileViTModel"),GUt.forEach(t),L9r=r(Yze," (MobileViT model)"),Yze.forEach(t),y9r=i(j),N3=n(j,"LI",{});var Kze=s(N3);T0e=n(Kze,"STRONG",{});var OUt=s(T0e);x9r=r(OUt,"mpnet"),OUt.forEach(t),$9r=r(Kze," \u2014 "),qZ=n(Kze,"A",{href:!0});var VUt=s(qZ);k9r=r(VUt,"TFMPNetModel"),VUt.forEach(t),S9r=r(Kze," (MPNet model)"),Kze.forEach(t),R9r=i(j),q3=n(j,"LI",{});var Zze=s(q3);M0e=n(Zze,"STRONG",{});var XUt=s(M0e);P9r=r(XUt,"mt5"),XUt.forEach(t),B9r=r(Zze," \u2014 "),jZ=n(Zze,"A",{href:!0});var zUt=s(jZ);I9r=r(zUt,"TFMT5Model"),zUt.forEach(t),N9r=r(Zze," (MT5 model)"),Zze.forEach(t),q9r=i(j),j3=n(j,"LI",{});var eQe=s(j3);E0e=n(eQe,"STRONG",{});var QUt=s(E0e);j9r=r(QUt,"openai-gpt"),QUt.forEach(t),D9r=r(eQe," \u2014 "),DZ=n(eQe,"A",{href:!0});var WUt=s(DZ);G9r=r(WUt,"TFOpenAIGPTModel"),WUt.forEach(t),O9r=r(eQe," (OpenAI GPT model)"),eQe.forEach(t),V9r=i(j),D3=n(j,"LI",{});var oQe=s(D3);C0e=n(oQe,"STRONG",{});var UUt=s(C0e);X9r=r(UUt,"opt"),UUt.forEach(t),z9r=r(oQe," \u2014 "),GZ=n(oQe,"A",{href:!0});var HUt=s(GZ);Q9r=r(HUt,"TFOPTModel"),HUt.forEach(t),W9r=r(oQe," (OPT model)"),oQe.forEach(t),U9r=i(j),G3=n(j,"LI",{});var rQe=s(G3);w0e=n(rQe,"STRONG",{});var JUt=s(w0e);H9r=r(JUt,"pegasus"),JUt.forEach(t),J9r=r(rQe," \u2014 "),OZ=n(rQe,"A",{href:!0});var YUt=s(OZ);Y9r=r(YUt,"TFPegasusModel"),YUt.forEach(t),K9r=r(rQe," (Pegasus model)"),rQe.forEach(t),Z9r=i(j),O3=n(j,"LI",{});var tQe=s(O3);A0e=n(tQe,"STRONG",{});var KUt=s(A0e);exr=r(KUt,"regnet"),KUt.forEach(t),oxr=r(tQe," \u2014 "),VZ=n(tQe,"A",{href:!0});var ZUt=s(VZ);rxr=r(ZUt,"TFRegNetModel"),ZUt.forEach(t),txr=r(tQe," (RegNet model)"),tQe.forEach(t),axr=i(j),V3=n(j,"LI",{});var aQe=s(V3);L0e=n(aQe,"STRONG",{});var eHt=s(L0e);nxr=r(eHt,"rembert"),eHt.forEach(t),sxr=r(aQe," \u2014 "),XZ=n(aQe,"A",{href:!0});var oHt=s(XZ);lxr=r(oHt,"TFRemBertModel"),oHt.forEach(t),ixr=r(aQe," (RemBERT model)"),aQe.forEach(t),dxr=i(j),X3=n(j,"LI",{});var nQe=s(X3);y0e=n(nQe,"STRONG",{});var rHt=s(y0e);cxr=r(rHt,"resnet"),rHt.forEach(t),mxr=r(nQe," \u2014 "),zZ=n(nQe,"A",{href:!0});var tHt=s(zZ);fxr=r(tHt,"TFResNetModel"),tHt.forEach(t),gxr=r(nQe," (ResNet model)"),nQe.forEach(t),hxr=i(j),z3=n(j,"LI",{});var sQe=s(z3);x0e=n(sQe,"STRONG",{});var aHt=s(x0e);uxr=r(aHt,"roberta"),aHt.forEach(t),pxr=r(sQe," \u2014 "),QZ=n(sQe,"A",{href:!0});var nHt=s(QZ);_xr=r(nHt,"TFRobertaModel"),nHt.forEach(t),bxr=r(sQe," (RoBERTa model)"),sQe.forEach(t),vxr=i(j),Q3=n(j,"LI",{});var lQe=s(Q3);$0e=n(lQe,"STRONG",{});var sHt=s($0e);Fxr=r(sHt,"roformer"),sHt.forEach(t),Txr=r(lQe," \u2014 "),WZ=n(lQe,"A",{href:!0});var lHt=s(WZ);Mxr=r(lHt,"TFRoFormerModel"),lHt.forEach(t),Exr=r(lQe," (RoFormer model)"),lQe.forEach(t),Cxr=i(j),W3=n(j,"LI",{});var iQe=s(W3);k0e=n(iQe,"STRONG",{});var iHt=s(k0e);wxr=r(iHt,"segformer"),iHt.forEach(t),Axr=r(iQe," \u2014 "),UZ=n(iQe,"A",{href:!0});var dHt=s(UZ);Lxr=r(dHt,"TFSegformerModel"),dHt.forEach(t),yxr=r(iQe," (SegFormer model)"),iQe.forEach(t),xxr=i(j),U3=n(j,"LI",{});var dQe=s(U3);S0e=n(dQe,"STRONG",{});var cHt=s(S0e);$xr=r(cHt,"speech_to_text"),cHt.forEach(t),kxr=r(dQe," \u2014 "),HZ=n(dQe,"A",{href:!0});var mHt=s(HZ);Sxr=r(mHt,"TFSpeech2TextModel"),mHt.forEach(t),Rxr=r(dQe," (Speech2Text model)"),dQe.forEach(t),Pxr=i(j),H3=n(j,"LI",{});var cQe=s(H3);R0e=n(cQe,"STRONG",{});var fHt=s(R0e);Bxr=r(fHt,"swin"),fHt.forEach(t),Ixr=r(cQe," \u2014 "),JZ=n(cQe,"A",{href:!0});var gHt=s(JZ);Nxr=r(gHt,"TFSwinModel"),gHt.forEach(t),qxr=r(cQe," (Swin Transformer model)"),cQe.forEach(t),jxr=i(j),J3=n(j,"LI",{});var mQe=s(J3);P0e=n(mQe,"STRONG",{});var hHt=s(P0e);Dxr=r(hHt,"t5"),hHt.forEach(t),Gxr=r(mQe," \u2014 "),YZ=n(mQe,"A",{href:!0});var uHt=s(YZ);Oxr=r(uHt,"TFT5Model"),uHt.forEach(t),Vxr=r(mQe," (T5 model)"),mQe.forEach(t),Xxr=i(j),Y3=n(j,"LI",{});var fQe=s(Y3);B0e=n(fQe,"STRONG",{});var pHt=s(B0e);zxr=r(pHt,"tapas"),pHt.forEach(t),Qxr=r(fQe," \u2014 "),KZ=n(fQe,"A",{href:!0});var _Ht=s(KZ);Wxr=r(_Ht,"TFTapasModel"),_Ht.forEach(t),Uxr=r(fQe," (TAPAS model)"),fQe.forEach(t),Hxr=i(j),K3=n(j,"LI",{});var gQe=s(K3);I0e=n(gQe,"STRONG",{});var bHt=s(I0e);Jxr=r(bHt,"transfo-xl"),bHt.forEach(t),Yxr=r(gQe," \u2014 "),ZZ=n(gQe,"A",{href:!0});var vHt=s(ZZ);Kxr=r(vHt,"TFTransfoXLModel"),vHt.forEach(t),Zxr=r(gQe," (Transformer-XL model)"),gQe.forEach(t),e$r=i(j),Z3=n(j,"LI",{});var hQe=s(Z3);N0e=n(hQe,"STRONG",{});var FHt=s(N0e);o$r=r(FHt,"vit"),FHt.forEach(t),r$r=r(hQe," \u2014 "),eee=n(hQe,"A",{href:!0});var THt=s(eee);t$r=r(THt,"TFViTModel"),THt.forEach(t),a$r=r(hQe," (ViT model)"),hQe.forEach(t),n$r=i(j),e5=n(j,"LI",{});var uQe=s(e5);q0e=n(uQe,"STRONG",{});var MHt=s(q0e);s$r=r(MHt,"vit_mae"),MHt.forEach(t),l$r=r(uQe," \u2014 "),oee=n(uQe,"A",{href:!0});var EHt=s(oee);i$r=r(EHt,"TFViTMAEModel"),EHt.forEach(t),d$r=r(uQe," (ViTMAE model)"),uQe.forEach(t),c$r=i(j),o5=n(j,"LI",{});var pQe=s(o5);j0e=n(pQe,"STRONG",{});var CHt=s(j0e);m$r=r(CHt,"wav2vec2"),CHt.forEach(t),f$r=r(pQe," \u2014 "),ree=n(pQe,"A",{href:!0});var wHt=s(ree);g$r=r(wHt,"TFWav2Vec2Model"),wHt.forEach(t),h$r=r(pQe," (Wav2Vec2 model)"),pQe.forEach(t),u$r=i(j),r5=n(j,"LI",{});var _Qe=s(r5);D0e=n(_Qe,"STRONG",{});var AHt=s(D0e);p$r=r(AHt,"xglm"),AHt.forEach(t),_$r=r(_Qe," \u2014 "),tee=n(_Qe,"A",{href:!0});var LHt=s(tee);b$r=r(LHt,"TFXGLMModel"),LHt.forEach(t),v$r=r(_Qe," (XGLM model)"),_Qe.forEach(t),F$r=i(j),t5=n(j,"LI",{});var bQe=s(t5);G0e=n(bQe,"STRONG",{});var yHt=s(G0e);T$r=r(yHt,"xlm"),yHt.forEach(t),M$r=r(bQe," \u2014 "),aee=n(bQe,"A",{href:!0});var xHt=s(aee);E$r=r(xHt,"TFXLMModel"),xHt.forEach(t),C$r=r(bQe," (XLM model)"),bQe.forEach(t),w$r=i(j),a5=n(j,"LI",{});var vQe=s(a5);O0e=n(vQe,"STRONG",{});var $Ht=s(O0e);A$r=r($Ht,"xlm-roberta"),$Ht.forEach(t),L$r=r(vQe," \u2014 "),nee=n(vQe,"A",{href:!0});var kHt=s(nee);y$r=r(kHt,"TFXLMRobertaModel"),kHt.forEach(t),x$r=r(vQe," (XLM-RoBERTa model)"),vQe.forEach(t),$$r=i(j),n5=n(j,"LI",{});var FQe=s(n5);V0e=n(FQe,"STRONG",{});var SHt=s(V0e);k$r=r(SHt,"xlnet"),SHt.forEach(t),S$r=r(FQe," \u2014 "),see=n(FQe,"A",{href:!0});var RHt=s(see);R$r=r(RHt,"TFXLNetModel"),RHt.forEach(t),P$r=r(FQe," (XLNet model)"),FQe.forEach(t),j.forEach(t),B$r=i(oi),T(s5.$$.fragment,oi),oi.forEach(t),ei.forEach(t),XKe=i(m),Xc=n(m,"H2",{class:!0});var soo=s(Xc);l5=n(soo,"A",{id:!0,class:!0,href:!0});var PHt=s(l5);X0e=n(PHt,"SPAN",{});var BHt=s(X0e);T(Ck.$$.fragment,BHt),BHt.forEach(t),PHt.forEach(t),I$r=i(soo),z0e=n(soo,"SPAN",{});var IHt=s(z0e);N$r=r(IHt,"TFAutoModelForPreTraining"),IHt.forEach(t),soo.forEach(t),zKe=i(m),lr=n(m,"DIV",{class:!0});var ri=s(lr);T(wk.$$.fragment,ri),q$r=i(ri),zc=n(ri,"P",{});var Ule=s(zc);j$r=r(Ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lee=n(Ule,"A",{href:!0});var NHt=s(lee);D$r=r(NHt,"from_pretrained()"),NHt.forEach(t),G$r=r(Ule," class method or the "),iee=n(Ule,"A",{href:!0});var qHt=s(iee);O$r=r(qHt,"from_config()"),qHt.forEach(t),V$r=r(Ule,` class
method.`),Ule.forEach(t),X$r=i(ri),Ak=n(ri,"P",{});var loo=s(Ak);z$r=r(loo,"This class cannot be instantiated directly using "),Q0e=n(loo,"CODE",{});var jHt=s(Q0e);Q$r=r(jHt,"__init__()"),jHt.forEach(t),W$r=r(loo," (throws an error)."),loo.forEach(t),U$r=i(ri),zt=n(ri,"DIV",{class:!0});var v8=s(zt);T(Lk.$$.fragment,v8),H$r=i(v8),W0e=n(v8,"P",{});var DHt=s(W0e);J$r=r(DHt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),DHt.forEach(t),Y$r=i(v8),Qc=n(v8,"P",{});var Hle=s(Qc);K$r=r(Hle,`Note:
Loading a model from its configuration file does `),U0e=n(Hle,"STRONG",{});var GHt=s(U0e);Z$r=r(GHt,"not"),GHt.forEach(t),ekr=r(Hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=n(Hle,"A",{href:!0});var OHt=s(dee);okr=r(OHt,"from_pretrained()"),OHt.forEach(t),rkr=r(Hle," to load the model weights."),Hle.forEach(t),tkr=i(v8),T(i5.$$.fragment,v8),v8.forEach(t),akr=i(ri),Nr=n(ri,"DIV",{class:!0});var ti=s(Nr);T(yk.$$.fragment,ti),nkr=i(ti),H0e=n(ti,"P",{});var VHt=s(H0e);skr=r(VHt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),VHt.forEach(t),lkr=i(ti),wn=n(ti,"P",{});var F8=s(wn);ikr=r(F8,"The model class to instantiate is selected based on the "),J0e=n(F8,"CODE",{});var XHt=s(J0e);dkr=r(XHt,"model_type"),XHt.forEach(t),ckr=r(F8,` property of the config object (either
passed as an argument or loaded from `),Y0e=n(F8,"CODE",{});var zHt=s(Y0e);mkr=r(zHt,"pretrained_model_name_or_path"),zHt.forEach(t),fkr=r(F8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K0e=n(F8,"CODE",{});var QHt=s(K0e);gkr=r(QHt,"pretrained_model_name_or_path"),QHt.forEach(t),hkr=r(F8,":"),F8.forEach(t),ukr=i(ti),se=n(ti,"UL",{});var le=s(se);d5=n(le,"LI",{});var TQe=s(d5);Z0e=n(TQe,"STRONG",{});var WHt=s(Z0e);pkr=r(WHt,"albert"),WHt.forEach(t),_kr=r(TQe," \u2014 "),cee=n(TQe,"A",{href:!0});var UHt=s(cee);bkr=r(UHt,"TFAlbertForPreTraining"),UHt.forEach(t),vkr=r(TQe," (ALBERT model)"),TQe.forEach(t),Fkr=i(le),c5=n(le,"LI",{});var MQe=s(c5);ewe=n(MQe,"STRONG",{});var HHt=s(ewe);Tkr=r(HHt,"bart"),HHt.forEach(t),Mkr=r(MQe," \u2014 "),mee=n(MQe,"A",{href:!0});var JHt=s(mee);Ekr=r(JHt,"TFBartForConditionalGeneration"),JHt.forEach(t),Ckr=r(MQe," (BART model)"),MQe.forEach(t),wkr=i(le),m5=n(le,"LI",{});var EQe=s(m5);owe=n(EQe,"STRONG",{});var YHt=s(owe);Akr=r(YHt,"bert"),YHt.forEach(t),Lkr=r(EQe," \u2014 "),fee=n(EQe,"A",{href:!0});var KHt=s(fee);ykr=r(KHt,"TFBertForPreTraining"),KHt.forEach(t),xkr=r(EQe," (BERT model)"),EQe.forEach(t),$kr=i(le),f5=n(le,"LI",{});var CQe=s(f5);rwe=n(CQe,"STRONG",{});var ZHt=s(rwe);kkr=r(ZHt,"camembert"),ZHt.forEach(t),Skr=r(CQe," \u2014 "),gee=n(CQe,"A",{href:!0});var eJt=s(gee);Rkr=r(eJt,"TFCamembertForMaskedLM"),eJt.forEach(t),Pkr=r(CQe," (CamemBERT model)"),CQe.forEach(t),Bkr=i(le),g5=n(le,"LI",{});var wQe=s(g5);twe=n(wQe,"STRONG",{});var oJt=s(twe);Ikr=r(oJt,"ctrl"),oJt.forEach(t),Nkr=r(wQe," \u2014 "),hee=n(wQe,"A",{href:!0});var rJt=s(hee);qkr=r(rJt,"TFCTRLLMHeadModel"),rJt.forEach(t),jkr=r(wQe," (CTRL model)"),wQe.forEach(t),Dkr=i(le),h5=n(le,"LI",{});var AQe=s(h5);awe=n(AQe,"STRONG",{});var tJt=s(awe);Gkr=r(tJt,"distilbert"),tJt.forEach(t),Okr=r(AQe," \u2014 "),uee=n(AQe,"A",{href:!0});var aJt=s(uee);Vkr=r(aJt,"TFDistilBertForMaskedLM"),aJt.forEach(t),Xkr=r(AQe," (DistilBERT model)"),AQe.forEach(t),zkr=i(le),u5=n(le,"LI",{});var LQe=s(u5);nwe=n(LQe,"STRONG",{});var nJt=s(nwe);Qkr=r(nJt,"electra"),nJt.forEach(t),Wkr=r(LQe," \u2014 "),pee=n(LQe,"A",{href:!0});var sJt=s(pee);Ukr=r(sJt,"TFElectraForPreTraining"),sJt.forEach(t),Hkr=r(LQe," (ELECTRA model)"),LQe.forEach(t),Jkr=i(le),p5=n(le,"LI",{});var yQe=s(p5);swe=n(yQe,"STRONG",{});var lJt=s(swe);Ykr=r(lJt,"flaubert"),lJt.forEach(t),Kkr=r(yQe," \u2014 "),_ee=n(yQe,"A",{href:!0});var iJt=s(_ee);Zkr=r(iJt,"TFFlaubertWithLMHeadModel"),iJt.forEach(t),eSr=r(yQe," (FlauBERT model)"),yQe.forEach(t),oSr=i(le),_5=n(le,"LI",{});var xQe=s(_5);lwe=n(xQe,"STRONG",{});var dJt=s(lwe);rSr=r(dJt,"funnel"),dJt.forEach(t),tSr=r(xQe," \u2014 "),bee=n(xQe,"A",{href:!0});var cJt=s(bee);aSr=r(cJt,"TFFunnelForPreTraining"),cJt.forEach(t),nSr=r(xQe," (Funnel Transformer model)"),xQe.forEach(t),sSr=i(le),b5=n(le,"LI",{});var $Qe=s(b5);iwe=n($Qe,"STRONG",{});var mJt=s(iwe);lSr=r(mJt,"gpt2"),mJt.forEach(t),iSr=r($Qe," \u2014 "),vee=n($Qe,"A",{href:!0});var fJt=s(vee);dSr=r(fJt,"TFGPT2LMHeadModel"),fJt.forEach(t),cSr=r($Qe," (OpenAI GPT-2 model)"),$Qe.forEach(t),mSr=i(le),v5=n(le,"LI",{});var kQe=s(v5);dwe=n(kQe,"STRONG",{});var gJt=s(dwe);fSr=r(gJt,"layoutlm"),gJt.forEach(t),gSr=r(kQe," \u2014 "),Fee=n(kQe,"A",{href:!0});var hJt=s(Fee);hSr=r(hJt,"TFLayoutLMForMaskedLM"),hJt.forEach(t),uSr=r(kQe," (LayoutLM model)"),kQe.forEach(t),pSr=i(le),F5=n(le,"LI",{});var SQe=s(F5);cwe=n(SQe,"STRONG",{});var uJt=s(cwe);_Sr=r(uJt,"lxmert"),uJt.forEach(t),bSr=r(SQe," \u2014 "),Tee=n(SQe,"A",{href:!0});var pJt=s(Tee);vSr=r(pJt,"TFLxmertForPreTraining"),pJt.forEach(t),FSr=r(SQe," (LXMERT model)"),SQe.forEach(t),TSr=i(le),T5=n(le,"LI",{});var RQe=s(T5);mwe=n(RQe,"STRONG",{});var _Jt=s(mwe);MSr=r(_Jt,"mobilebert"),_Jt.forEach(t),ESr=r(RQe," \u2014 "),Mee=n(RQe,"A",{href:!0});var bJt=s(Mee);CSr=r(bJt,"TFMobileBertForPreTraining"),bJt.forEach(t),wSr=r(RQe," (MobileBERT model)"),RQe.forEach(t),ASr=i(le),M5=n(le,"LI",{});var PQe=s(M5);fwe=n(PQe,"STRONG",{});var vJt=s(fwe);LSr=r(vJt,"mpnet"),vJt.forEach(t),ySr=r(PQe," \u2014 "),Eee=n(PQe,"A",{href:!0});var FJt=s(Eee);xSr=r(FJt,"TFMPNetForMaskedLM"),FJt.forEach(t),$Sr=r(PQe," (MPNet model)"),PQe.forEach(t),kSr=i(le),E5=n(le,"LI",{});var BQe=s(E5);gwe=n(BQe,"STRONG",{});var TJt=s(gwe);SSr=r(TJt,"openai-gpt"),TJt.forEach(t),RSr=r(BQe," \u2014 "),Cee=n(BQe,"A",{href:!0});var MJt=s(Cee);PSr=r(MJt,"TFOpenAIGPTLMHeadModel"),MJt.forEach(t),BSr=r(BQe," (OpenAI GPT model)"),BQe.forEach(t),ISr=i(le),C5=n(le,"LI",{});var IQe=s(C5);hwe=n(IQe,"STRONG",{});var EJt=s(hwe);NSr=r(EJt,"roberta"),EJt.forEach(t),qSr=r(IQe," \u2014 "),wee=n(IQe,"A",{href:!0});var CJt=s(wee);jSr=r(CJt,"TFRobertaForMaskedLM"),CJt.forEach(t),DSr=r(IQe," (RoBERTa model)"),IQe.forEach(t),GSr=i(le),w5=n(le,"LI",{});var NQe=s(w5);uwe=n(NQe,"STRONG",{});var wJt=s(uwe);OSr=r(wJt,"t5"),wJt.forEach(t),VSr=r(NQe," \u2014 "),Aee=n(NQe,"A",{href:!0});var AJt=s(Aee);XSr=r(AJt,"TFT5ForConditionalGeneration"),AJt.forEach(t),zSr=r(NQe," (T5 model)"),NQe.forEach(t),QSr=i(le),A5=n(le,"LI",{});var qQe=s(A5);pwe=n(qQe,"STRONG",{});var LJt=s(pwe);WSr=r(LJt,"tapas"),LJt.forEach(t),USr=r(qQe," \u2014 "),Lee=n(qQe,"A",{href:!0});var yJt=s(Lee);HSr=r(yJt,"TFTapasForMaskedLM"),yJt.forEach(t),JSr=r(qQe," (TAPAS model)"),qQe.forEach(t),YSr=i(le),L5=n(le,"LI",{});var jQe=s(L5);_we=n(jQe,"STRONG",{});var xJt=s(_we);KSr=r(xJt,"transfo-xl"),xJt.forEach(t),ZSr=r(jQe," \u2014 "),yee=n(jQe,"A",{href:!0});var $Jt=s(yee);eRr=r($Jt,"TFTransfoXLLMHeadModel"),$Jt.forEach(t),oRr=r(jQe," (Transformer-XL model)"),jQe.forEach(t),rRr=i(le),y5=n(le,"LI",{});var DQe=s(y5);bwe=n(DQe,"STRONG",{});var kJt=s(bwe);tRr=r(kJt,"vit_mae"),kJt.forEach(t),aRr=r(DQe," \u2014 "),xee=n(DQe,"A",{href:!0});var SJt=s(xee);nRr=r(SJt,"TFViTMAEForPreTraining"),SJt.forEach(t),sRr=r(DQe," (ViTMAE model)"),DQe.forEach(t),lRr=i(le),x5=n(le,"LI",{});var GQe=s(x5);vwe=n(GQe,"STRONG",{});var RJt=s(vwe);iRr=r(RJt,"xlm"),RJt.forEach(t),dRr=r(GQe," \u2014 "),$ee=n(GQe,"A",{href:!0});var PJt=s($ee);cRr=r(PJt,"TFXLMWithLMHeadModel"),PJt.forEach(t),mRr=r(GQe," (XLM model)"),GQe.forEach(t),fRr=i(le),$5=n(le,"LI",{});var OQe=s($5);Fwe=n(OQe,"STRONG",{});var BJt=s(Fwe);gRr=r(BJt,"xlm-roberta"),BJt.forEach(t),hRr=r(OQe," \u2014 "),kee=n(OQe,"A",{href:!0});var IJt=s(kee);uRr=r(IJt,"TFXLMRobertaForMaskedLM"),IJt.forEach(t),pRr=r(OQe," (XLM-RoBERTa model)"),OQe.forEach(t),_Rr=i(le),k5=n(le,"LI",{});var VQe=s(k5);Twe=n(VQe,"STRONG",{});var NJt=s(Twe);bRr=r(NJt,"xlnet"),NJt.forEach(t),vRr=r(VQe," \u2014 "),See=n(VQe,"A",{href:!0});var qJt=s(See);FRr=r(qJt,"TFXLNetLMHeadModel"),qJt.forEach(t),TRr=r(VQe," (XLNet model)"),VQe.forEach(t),le.forEach(t),MRr=i(ti),T(S5.$$.fragment,ti),ti.forEach(t),ri.forEach(t),QKe=i(m),Wc=n(m,"H2",{class:!0});var ioo=s(Wc);R5=n(ioo,"A",{id:!0,class:!0,href:!0});var jJt=s(R5);Mwe=n(jJt,"SPAN",{});var DJt=s(Mwe);T(xk.$$.fragment,DJt),DJt.forEach(t),jJt.forEach(t),ERr=i(ioo),Ewe=n(ioo,"SPAN",{});var GJt=s(Ewe);CRr=r(GJt,"TFAutoModelForCausalLM"),GJt.forEach(t),ioo.forEach(t),WKe=i(m),ir=n(m,"DIV",{class:!0});var ai=s(ir);T($k.$$.fragment,ai),wRr=i(ai),Uc=n(ai,"P",{});var Jle=s(Uc);ARr=r(Jle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Ree=n(Jle,"A",{href:!0});var OJt=s(Ree);LRr=r(OJt,"from_pretrained()"),OJt.forEach(t),yRr=r(Jle," class method or the "),Pee=n(Jle,"A",{href:!0});var VJt=s(Pee);xRr=r(VJt,"from_config()"),VJt.forEach(t),$Rr=r(Jle,` class
method.`),Jle.forEach(t),kRr=i(ai),kk=n(ai,"P",{});var doo=s(kk);SRr=r(doo,"This class cannot be instantiated directly using "),Cwe=n(doo,"CODE",{});var XJt=s(Cwe);RRr=r(XJt,"__init__()"),XJt.forEach(t),PRr=r(doo," (throws an error)."),doo.forEach(t),BRr=i(ai),Qt=n(ai,"DIV",{class:!0});var T8=s(Qt);T(Sk.$$.fragment,T8),IRr=i(T8),wwe=n(T8,"P",{});var zJt=s(wwe);NRr=r(zJt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zJt.forEach(t),qRr=i(T8),Hc=n(T8,"P",{});var Yle=s(Hc);jRr=r(Yle,`Note:
Loading a model from its configuration file does `),Awe=n(Yle,"STRONG",{});var QJt=s(Awe);DRr=r(QJt,"not"),QJt.forEach(t),GRr=r(Yle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=n(Yle,"A",{href:!0});var WJt=s(Bee);ORr=r(WJt,"from_pretrained()"),WJt.forEach(t),VRr=r(Yle," to load the model weights."),Yle.forEach(t),XRr=i(T8),T(P5.$$.fragment,T8),T8.forEach(t),zRr=i(ai),qr=n(ai,"DIV",{class:!0});var ni=s(qr);T(Rk.$$.fragment,ni),QRr=i(ni),Lwe=n(ni,"P",{});var UJt=s(Lwe);WRr=r(UJt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),UJt.forEach(t),URr=i(ni),An=n(ni,"P",{});var M8=s(An);HRr=r(M8,"The model class to instantiate is selected based on the "),ywe=n(M8,"CODE",{});var HJt=s(ywe);JRr=r(HJt,"model_type"),HJt.forEach(t),YRr=r(M8,` property of the config object (either
passed as an argument or loaded from `),xwe=n(M8,"CODE",{});var JJt=s(xwe);KRr=r(JJt,"pretrained_model_name_or_path"),JJt.forEach(t),ZRr=r(M8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=n(M8,"CODE",{});var YJt=s($we);ePr=r(YJt,"pretrained_model_name_or_path"),YJt.forEach(t),oPr=r(M8,":"),M8.forEach(t),rPr=i(ni),Me=n(ni,"UL",{});var Ce=s(Me);B5=n(Ce,"LI",{});var XQe=s(B5);kwe=n(XQe,"STRONG",{});var KJt=s(kwe);tPr=r(KJt,"bert"),KJt.forEach(t),aPr=r(XQe," \u2014 "),Iee=n(XQe,"A",{href:!0});var ZJt=s(Iee);nPr=r(ZJt,"TFBertLMHeadModel"),ZJt.forEach(t),sPr=r(XQe," (BERT model)"),XQe.forEach(t),lPr=i(Ce),I5=n(Ce,"LI",{});var zQe=s(I5);Swe=n(zQe,"STRONG",{});var eYt=s(Swe);iPr=r(eYt,"camembert"),eYt.forEach(t),dPr=r(zQe," \u2014 "),Nee=n(zQe,"A",{href:!0});var oYt=s(Nee);cPr=r(oYt,"TFCamembertForCausalLM"),oYt.forEach(t),mPr=r(zQe," (CamemBERT model)"),zQe.forEach(t),fPr=i(Ce),N5=n(Ce,"LI",{});var QQe=s(N5);Rwe=n(QQe,"STRONG",{});var rYt=s(Rwe);gPr=r(rYt,"ctrl"),rYt.forEach(t),hPr=r(QQe," \u2014 "),qee=n(QQe,"A",{href:!0});var tYt=s(qee);uPr=r(tYt,"TFCTRLLMHeadModel"),tYt.forEach(t),pPr=r(QQe," (CTRL model)"),QQe.forEach(t),_Pr=i(Ce),q5=n(Ce,"LI",{});var WQe=s(q5);Pwe=n(WQe,"STRONG",{});var aYt=s(Pwe);bPr=r(aYt,"gpt2"),aYt.forEach(t),vPr=r(WQe," \u2014 "),jee=n(WQe,"A",{href:!0});var nYt=s(jee);FPr=r(nYt,"TFGPT2LMHeadModel"),nYt.forEach(t),TPr=r(WQe," (OpenAI GPT-2 model)"),WQe.forEach(t),MPr=i(Ce),j5=n(Ce,"LI",{});var UQe=s(j5);Bwe=n(UQe,"STRONG",{});var sYt=s(Bwe);EPr=r(sYt,"gptj"),sYt.forEach(t),CPr=r(UQe," \u2014 "),Dee=n(UQe,"A",{href:!0});var lYt=s(Dee);wPr=r(lYt,"TFGPTJForCausalLM"),lYt.forEach(t),APr=r(UQe," (GPT-J model)"),UQe.forEach(t),LPr=i(Ce),D5=n(Ce,"LI",{});var HQe=s(D5);Iwe=n(HQe,"STRONG",{});var iYt=s(Iwe);yPr=r(iYt,"openai-gpt"),iYt.forEach(t),xPr=r(HQe," \u2014 "),Gee=n(HQe,"A",{href:!0});var dYt=s(Gee);$Pr=r(dYt,"TFOpenAIGPTLMHeadModel"),dYt.forEach(t),kPr=r(HQe," (OpenAI GPT model)"),HQe.forEach(t),SPr=i(Ce),G5=n(Ce,"LI",{});var JQe=s(G5);Nwe=n(JQe,"STRONG",{});var cYt=s(Nwe);RPr=r(cYt,"opt"),cYt.forEach(t),PPr=r(JQe," \u2014 "),Oee=n(JQe,"A",{href:!0});var mYt=s(Oee);BPr=r(mYt,"TFOPTForCausalLM"),mYt.forEach(t),IPr=r(JQe," (OPT model)"),JQe.forEach(t),NPr=i(Ce),O5=n(Ce,"LI",{});var YQe=s(O5);qwe=n(YQe,"STRONG",{});var fYt=s(qwe);qPr=r(fYt,"rembert"),fYt.forEach(t),jPr=r(YQe," \u2014 "),Vee=n(YQe,"A",{href:!0});var gYt=s(Vee);DPr=r(gYt,"TFRemBertForCausalLM"),gYt.forEach(t),GPr=r(YQe," (RemBERT model)"),YQe.forEach(t),OPr=i(Ce),V5=n(Ce,"LI",{});var KQe=s(V5);jwe=n(KQe,"STRONG",{});var hYt=s(jwe);VPr=r(hYt,"roberta"),hYt.forEach(t),XPr=r(KQe," \u2014 "),Xee=n(KQe,"A",{href:!0});var uYt=s(Xee);zPr=r(uYt,"TFRobertaForCausalLM"),uYt.forEach(t),QPr=r(KQe," (RoBERTa model)"),KQe.forEach(t),WPr=i(Ce),X5=n(Ce,"LI",{});var ZQe=s(X5);Dwe=n(ZQe,"STRONG",{});var pYt=s(Dwe);UPr=r(pYt,"roformer"),pYt.forEach(t),HPr=r(ZQe," \u2014 "),zee=n(ZQe,"A",{href:!0});var _Yt=s(zee);JPr=r(_Yt,"TFRoFormerForCausalLM"),_Yt.forEach(t),YPr=r(ZQe," (RoFormer model)"),ZQe.forEach(t),KPr=i(Ce),z5=n(Ce,"LI",{});var eWe=s(z5);Gwe=n(eWe,"STRONG",{});var bYt=s(Gwe);ZPr=r(bYt,"transfo-xl"),bYt.forEach(t),eBr=r(eWe," \u2014 "),Qee=n(eWe,"A",{href:!0});var vYt=s(Qee);oBr=r(vYt,"TFTransfoXLLMHeadModel"),vYt.forEach(t),rBr=r(eWe," (Transformer-XL model)"),eWe.forEach(t),tBr=i(Ce),Q5=n(Ce,"LI",{});var oWe=s(Q5);Owe=n(oWe,"STRONG",{});var FYt=s(Owe);aBr=r(FYt,"xglm"),FYt.forEach(t),nBr=r(oWe," \u2014 "),Wee=n(oWe,"A",{href:!0});var TYt=s(Wee);sBr=r(TYt,"TFXGLMForCausalLM"),TYt.forEach(t),lBr=r(oWe," (XGLM model)"),oWe.forEach(t),iBr=i(Ce),W5=n(Ce,"LI",{});var rWe=s(W5);Vwe=n(rWe,"STRONG",{});var MYt=s(Vwe);dBr=r(MYt,"xlm"),MYt.forEach(t),cBr=r(rWe," \u2014 "),Uee=n(rWe,"A",{href:!0});var EYt=s(Uee);mBr=r(EYt,"TFXLMWithLMHeadModel"),EYt.forEach(t),fBr=r(rWe," (XLM model)"),rWe.forEach(t),gBr=i(Ce),U5=n(Ce,"LI",{});var tWe=s(U5);Xwe=n(tWe,"STRONG",{});var CYt=s(Xwe);hBr=r(CYt,"xlnet"),CYt.forEach(t),uBr=r(tWe," \u2014 "),Hee=n(tWe,"A",{href:!0});var wYt=s(Hee);pBr=r(wYt,"TFXLNetLMHeadModel"),wYt.forEach(t),_Br=r(tWe," (XLNet model)"),tWe.forEach(t),Ce.forEach(t),bBr=i(ni),T(H5.$$.fragment,ni),ni.forEach(t),ai.forEach(t),UKe=i(m),Jc=n(m,"H2",{class:!0});var coo=s(Jc);J5=n(coo,"A",{id:!0,class:!0,href:!0});var AYt=s(J5);zwe=n(AYt,"SPAN",{});var LYt=s(zwe);T(Pk.$$.fragment,LYt),LYt.forEach(t),AYt.forEach(t),vBr=i(coo),Qwe=n(coo,"SPAN",{});var yYt=s(Qwe);FBr=r(yYt,"TFAutoModelForImageClassification"),yYt.forEach(t),coo.forEach(t),HKe=i(m),dr=n(m,"DIV",{class:!0});var si=s(dr);T(Bk.$$.fragment,si),TBr=i(si),Yc=n(si,"P",{});var Kle=s(Yc);MBr=r(Kle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jee=n(Kle,"A",{href:!0});var xYt=s(Jee);EBr=r(xYt,"from_pretrained()"),xYt.forEach(t),CBr=r(Kle," class method or the "),Yee=n(Kle,"A",{href:!0});var $Yt=s(Yee);wBr=r($Yt,"from_config()"),$Yt.forEach(t),ABr=r(Kle,` class
method.`),Kle.forEach(t),LBr=i(si),Ik=n(si,"P",{});var moo=s(Ik);yBr=r(moo,"This class cannot be instantiated directly using "),Wwe=n(moo,"CODE",{});var kYt=s(Wwe);xBr=r(kYt,"__init__()"),kYt.forEach(t),$Br=r(moo," (throws an error)."),moo.forEach(t),kBr=i(si),Wt=n(si,"DIV",{class:!0});var E8=s(Wt);T(Nk.$$.fragment,E8),SBr=i(E8),Uwe=n(E8,"P",{});var SYt=s(Uwe);RBr=r(SYt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),SYt.forEach(t),PBr=i(E8),Kc=n(E8,"P",{});var Zle=s(Kc);BBr=r(Zle,`Note:
Loading a model from its configuration file does `),Hwe=n(Zle,"STRONG",{});var RYt=s(Hwe);IBr=r(RYt,"not"),RYt.forEach(t),NBr=r(Zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=n(Zle,"A",{href:!0});var PYt=s(Kee);qBr=r(PYt,"from_pretrained()"),PYt.forEach(t),jBr=r(Zle," to load the model weights."),Zle.forEach(t),DBr=i(E8),T(Y5.$$.fragment,E8),E8.forEach(t),GBr=i(si),jr=n(si,"DIV",{class:!0});var li=s(jr);T(qk.$$.fragment,li),OBr=i(li),Jwe=n(li,"P",{});var BYt=s(Jwe);VBr=r(BYt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BYt.forEach(t),XBr=i(li),Ln=n(li,"P",{});var C8=s(Ln);zBr=r(C8,"The model class to instantiate is selected based on the "),Ywe=n(C8,"CODE",{});var IYt=s(Ywe);QBr=r(IYt,"model_type"),IYt.forEach(t),WBr=r(C8,` property of the config object (either
passed as an argument or loaded from `),Kwe=n(C8,"CODE",{});var NYt=s(Kwe);UBr=r(NYt,"pretrained_model_name_or_path"),NYt.forEach(t),HBr=r(C8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=n(C8,"CODE",{});var qYt=s(Zwe);JBr=r(qYt,"pretrained_model_name_or_path"),qYt.forEach(t),YBr=r(C8,":"),C8.forEach(t),KBr=i(li),Be=n(li,"UL",{});var We=s(Be);K5=n(We,"LI",{});var aWe=s(K5);eAe=n(aWe,"STRONG",{});var jYt=s(eAe);ZBr=r(jYt,"convnext"),jYt.forEach(t),eIr=r(aWe," \u2014 "),Zee=n(aWe,"A",{href:!0});var DYt=s(Zee);oIr=r(DYt,"TFConvNextForImageClassification"),DYt.forEach(t),rIr=r(aWe," (ConvNeXT model)"),aWe.forEach(t),tIr=i(We),Z5=n(We,"LI",{});var nWe=s(Z5);oAe=n(nWe,"STRONG",{});var GYt=s(oAe);aIr=r(GYt,"data2vec-vision"),GYt.forEach(t),nIr=r(nWe," \u2014 "),eoe=n(nWe,"A",{href:!0});var OYt=s(eoe);sIr=r(OYt,"TFData2VecVisionForImageClassification"),OYt.forEach(t),lIr=r(nWe," (Data2VecVision model)"),nWe.forEach(t),iIr=i(We),Fl=n(We,"LI",{});var EB=s(Fl);rAe=n(EB,"STRONG",{});var VYt=s(rAe);dIr=r(VYt,"deit"),VYt.forEach(t),cIr=r(EB," \u2014 "),ooe=n(EB,"A",{href:!0});var XYt=s(ooe);mIr=r(XYt,"TFDeiTForImageClassification"),XYt.forEach(t),fIr=r(EB," or "),roe=n(EB,"A",{href:!0});var zYt=s(roe);gIr=r(zYt,"TFDeiTForImageClassificationWithTeacher"),zYt.forEach(t),hIr=r(EB," (DeiT model)"),EB.forEach(t),uIr=i(We),e0=n(We,"LI",{});var sWe=s(e0);tAe=n(sWe,"STRONG",{});var QYt=s(tAe);pIr=r(QYt,"mobilevit"),QYt.forEach(t),_Ir=r(sWe," \u2014 "),toe=n(sWe,"A",{href:!0});var WYt=s(toe);bIr=r(WYt,"TFMobileViTForImageClassification"),WYt.forEach(t),vIr=r(sWe," (MobileViT model)"),sWe.forEach(t),FIr=i(We),o0=n(We,"LI",{});var lWe=s(o0);aAe=n(lWe,"STRONG",{});var UYt=s(aAe);TIr=r(UYt,"regnet"),UYt.forEach(t),MIr=r(lWe," \u2014 "),aoe=n(lWe,"A",{href:!0});var HYt=s(aoe);EIr=r(HYt,"TFRegNetForImageClassification"),HYt.forEach(t),CIr=r(lWe," (RegNet model)"),lWe.forEach(t),wIr=i(We),r0=n(We,"LI",{});var iWe=s(r0);nAe=n(iWe,"STRONG",{});var JYt=s(nAe);AIr=r(JYt,"resnet"),JYt.forEach(t),LIr=r(iWe," \u2014 "),noe=n(iWe,"A",{href:!0});var YYt=s(noe);yIr=r(YYt,"TFResNetForImageClassification"),YYt.forEach(t),xIr=r(iWe," (ResNet model)"),iWe.forEach(t),$Ir=i(We),t0=n(We,"LI",{});var dWe=s(t0);sAe=n(dWe,"STRONG",{});var KYt=s(sAe);kIr=r(KYt,"segformer"),KYt.forEach(t),SIr=r(dWe," \u2014 "),soe=n(dWe,"A",{href:!0});var ZYt=s(soe);RIr=r(ZYt,"TFSegformerForImageClassification"),ZYt.forEach(t),PIr=r(dWe," (SegFormer model)"),dWe.forEach(t),BIr=i(We),a0=n(We,"LI",{});var cWe=s(a0);lAe=n(cWe,"STRONG",{});var eKt=s(lAe);IIr=r(eKt,"swin"),eKt.forEach(t),NIr=r(cWe," \u2014 "),loe=n(cWe,"A",{href:!0});var oKt=s(loe);qIr=r(oKt,"TFSwinForImageClassification"),oKt.forEach(t),jIr=r(cWe," (Swin Transformer model)"),cWe.forEach(t),DIr=i(We),n0=n(We,"LI",{});var mWe=s(n0);iAe=n(mWe,"STRONG",{});var rKt=s(iAe);GIr=r(rKt,"vit"),rKt.forEach(t),OIr=r(mWe," \u2014 "),ioe=n(mWe,"A",{href:!0});var tKt=s(ioe);VIr=r(tKt,"TFViTForImageClassification"),tKt.forEach(t),XIr=r(mWe," (ViT model)"),mWe.forEach(t),We.forEach(t),zIr=i(li),T(s0.$$.fragment,li),li.forEach(t),si.forEach(t),JKe=i(m),Zc=n(m,"H2",{class:!0});var foo=s(Zc);l0=n(foo,"A",{id:!0,class:!0,href:!0});var aKt=s(l0);dAe=n(aKt,"SPAN",{});var nKt=s(dAe);T(jk.$$.fragment,nKt),nKt.forEach(t),aKt.forEach(t),QIr=i(foo),cAe=n(foo,"SPAN",{});var sKt=s(cAe);WIr=r(sKt,"TFAutoModelForSemanticSegmentation"),sKt.forEach(t),foo.forEach(t),YKe=i(m),cr=n(m,"DIV",{class:!0});var ii=s(cr);T(Dk.$$.fragment,ii),UIr=i(ii),em=n(ii,"P",{});var eie=s(em);HIr=r(eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),doe=n(eie,"A",{href:!0});var lKt=s(doe);JIr=r(lKt,"from_pretrained()"),lKt.forEach(t),YIr=r(eie," class method or the "),coe=n(eie,"A",{href:!0});var iKt=s(coe);KIr=r(iKt,"from_config()"),iKt.forEach(t),ZIr=r(eie,` class
method.`),eie.forEach(t),eNr=i(ii),Gk=n(ii,"P",{});var goo=s(Gk);oNr=r(goo,"This class cannot be instantiated directly using "),mAe=n(goo,"CODE",{});var dKt=s(mAe);rNr=r(dKt,"__init__()"),dKt.forEach(t),tNr=r(goo," (throws an error)."),goo.forEach(t),aNr=i(ii),Ut=n(ii,"DIV",{class:!0});var w8=s(Ut);T(Ok.$$.fragment,w8),nNr=i(w8),fAe=n(w8,"P",{});var cKt=s(fAe);sNr=r(cKt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),cKt.forEach(t),lNr=i(w8),om=n(w8,"P",{});var oie=s(om);iNr=r(oie,`Note:
Loading a model from its configuration file does `),gAe=n(oie,"STRONG",{});var mKt=s(gAe);dNr=r(mKt,"not"),mKt.forEach(t),cNr=r(oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=n(oie,"A",{href:!0});var fKt=s(moe);mNr=r(fKt,"from_pretrained()"),fKt.forEach(t),fNr=r(oie," to load the model weights."),oie.forEach(t),gNr=i(w8),T(i0.$$.fragment,w8),w8.forEach(t),hNr=i(ii),Dr=n(ii,"DIV",{class:!0});var di=s(Dr);T(Vk.$$.fragment,di),uNr=i(di),hAe=n(di,"P",{});var gKt=s(hAe);pNr=r(gKt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),gKt.forEach(t),_Nr=i(di),yn=n(di,"P",{});var A8=s(yn);bNr=r(A8,"The model class to instantiate is selected based on the "),uAe=n(A8,"CODE",{});var hKt=s(uAe);vNr=r(hKt,"model_type"),hKt.forEach(t),FNr=r(A8,` property of the config object (either
passed as an argument or loaded from `),pAe=n(A8,"CODE",{});var uKt=s(pAe);TNr=r(uKt,"pretrained_model_name_or_path"),uKt.forEach(t),MNr=r(A8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=n(A8,"CODE",{});var pKt=s(_Ae);ENr=r(pKt,"pretrained_model_name_or_path"),pKt.forEach(t),CNr=r(A8,":"),A8.forEach(t),wNr=i(di),rm=n(di,"UL",{});var rie=s(rm);d0=n(rie,"LI",{});var fWe=s(d0);bAe=n(fWe,"STRONG",{});var _Kt=s(bAe);ANr=r(_Kt,"data2vec-vision"),_Kt.forEach(t),LNr=r(fWe," \u2014 "),foe=n(fWe,"A",{href:!0});var bKt=s(foe);yNr=r(bKt,"TFData2VecVisionForSemanticSegmentation"),bKt.forEach(t),xNr=r(fWe," (Data2VecVision model)"),fWe.forEach(t),$Nr=i(rie),c0=n(rie,"LI",{});var gWe=s(c0);vAe=n(gWe,"STRONG",{});var vKt=s(vAe);kNr=r(vKt,"mobilevit"),vKt.forEach(t),SNr=r(gWe," \u2014 "),goe=n(gWe,"A",{href:!0});var FKt=s(goe);RNr=r(FKt,"TFMobileViTForSemanticSegmentation"),FKt.forEach(t),PNr=r(gWe," (MobileViT model)"),gWe.forEach(t),BNr=i(rie),m0=n(rie,"LI",{});var hWe=s(m0);FAe=n(hWe,"STRONG",{});var TKt=s(FAe);INr=r(TKt,"segformer"),TKt.forEach(t),NNr=r(hWe," \u2014 "),hoe=n(hWe,"A",{href:!0});var MKt=s(hoe);qNr=r(MKt,"TFSegformerForSemanticSegmentation"),MKt.forEach(t),jNr=r(hWe," (SegFormer model)"),hWe.forEach(t),rie.forEach(t),DNr=i(di),T(f0.$$.fragment,di),di.forEach(t),ii.forEach(t),KKe=i(m),tm=n(m,"H2",{class:!0});var hoo=s(tm);g0=n(hoo,"A",{id:!0,class:!0,href:!0});var EKt=s(g0);TAe=n(EKt,"SPAN",{});var CKt=s(TAe);T(Xk.$$.fragment,CKt),CKt.forEach(t),EKt.forEach(t),GNr=i(hoo),MAe=n(hoo,"SPAN",{});var wKt=s(MAe);ONr=r(wKt,"TFAutoModelForMaskedLM"),wKt.forEach(t),hoo.forEach(t),ZKe=i(m),mr=n(m,"DIV",{class:!0});var ci=s(mr);T(zk.$$.fragment,ci),VNr=i(ci),am=n(ci,"P",{});var tie=s(am);XNr=r(tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uoe=n(tie,"A",{href:!0});var AKt=s(uoe);zNr=r(AKt,"from_pretrained()"),AKt.forEach(t),QNr=r(tie," class method or the "),poe=n(tie,"A",{href:!0});var LKt=s(poe);WNr=r(LKt,"from_config()"),LKt.forEach(t),UNr=r(tie,` class
method.`),tie.forEach(t),HNr=i(ci),Qk=n(ci,"P",{});var uoo=s(Qk);JNr=r(uoo,"This class cannot be instantiated directly using "),EAe=n(uoo,"CODE",{});var yKt=s(EAe);YNr=r(yKt,"__init__()"),yKt.forEach(t),KNr=r(uoo," (throws an error)."),uoo.forEach(t),ZNr=i(ci),Ht=n(ci,"DIV",{class:!0});var L8=s(Ht);T(Wk.$$.fragment,L8),eqr=i(L8),CAe=n(L8,"P",{});var xKt=s(CAe);oqr=r(xKt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xKt.forEach(t),rqr=i(L8),nm=n(L8,"P",{});var aie=s(nm);tqr=r(aie,`Note:
Loading a model from its configuration file does `),wAe=n(aie,"STRONG",{});var $Kt=s(wAe);aqr=r($Kt,"not"),$Kt.forEach(t),nqr=r(aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(aie,"A",{href:!0});var kKt=s(_oe);sqr=r(kKt,"from_pretrained()"),kKt.forEach(t),lqr=r(aie," to load the model weights."),aie.forEach(t),iqr=i(L8),T(h0.$$.fragment,L8),L8.forEach(t),dqr=i(ci),Gr=n(ci,"DIV",{class:!0});var mi=s(Gr);T(Uk.$$.fragment,mi),cqr=i(mi),AAe=n(mi,"P",{});var SKt=s(AAe);mqr=r(SKt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),SKt.forEach(t),fqr=i(mi),xn=n(mi,"P",{});var y8=s(xn);gqr=r(y8,"The model class to instantiate is selected based on the "),LAe=n(y8,"CODE",{});var RKt=s(LAe);hqr=r(RKt,"model_type"),RKt.forEach(t),uqr=r(y8,` property of the config object (either
passed as an argument or loaded from `),yAe=n(y8,"CODE",{});var PKt=s(yAe);pqr=r(PKt,"pretrained_model_name_or_path"),PKt.forEach(t),_qr=r(y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=n(y8,"CODE",{});var BKt=s(xAe);bqr=r(BKt,"pretrained_model_name_or_path"),BKt.forEach(t),vqr=r(y8,":"),y8.forEach(t),Fqr=i(mi),fe=n(mi,"UL",{});var _e=s(fe);u0=n(_e,"LI",{});var uWe=s(u0);$Ae=n(uWe,"STRONG",{});var IKt=s($Ae);Tqr=r(IKt,"albert"),IKt.forEach(t),Mqr=r(uWe," \u2014 "),boe=n(uWe,"A",{href:!0});var NKt=s(boe);Eqr=r(NKt,"TFAlbertForMaskedLM"),NKt.forEach(t),Cqr=r(uWe," (ALBERT model)"),uWe.forEach(t),wqr=i(_e),p0=n(_e,"LI",{});var pWe=s(p0);kAe=n(pWe,"STRONG",{});var qKt=s(kAe);Aqr=r(qKt,"bert"),qKt.forEach(t),Lqr=r(pWe," \u2014 "),voe=n(pWe,"A",{href:!0});var jKt=s(voe);yqr=r(jKt,"TFBertForMaskedLM"),jKt.forEach(t),xqr=r(pWe," (BERT model)"),pWe.forEach(t),$qr=i(_e),_0=n(_e,"LI",{});var _We=s(_0);SAe=n(_We,"STRONG",{});var DKt=s(SAe);kqr=r(DKt,"camembert"),DKt.forEach(t),Sqr=r(_We," \u2014 "),Foe=n(_We,"A",{href:!0});var GKt=s(Foe);Rqr=r(GKt,"TFCamembertForMaskedLM"),GKt.forEach(t),Pqr=r(_We," (CamemBERT model)"),_We.forEach(t),Bqr=i(_e),b0=n(_e,"LI",{});var bWe=s(b0);RAe=n(bWe,"STRONG",{});var OKt=s(RAe);Iqr=r(OKt,"convbert"),OKt.forEach(t),Nqr=r(bWe," \u2014 "),Toe=n(bWe,"A",{href:!0});var VKt=s(Toe);qqr=r(VKt,"TFConvBertForMaskedLM"),VKt.forEach(t),jqr=r(bWe," (ConvBERT model)"),bWe.forEach(t),Dqr=i(_e),v0=n(_e,"LI",{});var vWe=s(v0);PAe=n(vWe,"STRONG",{});var XKt=s(PAe);Gqr=r(XKt,"deberta"),XKt.forEach(t),Oqr=r(vWe," \u2014 "),Moe=n(vWe,"A",{href:!0});var zKt=s(Moe);Vqr=r(zKt,"TFDebertaForMaskedLM"),zKt.forEach(t),Xqr=r(vWe," (DeBERTa model)"),vWe.forEach(t),zqr=i(_e),F0=n(_e,"LI",{});var FWe=s(F0);BAe=n(FWe,"STRONG",{});var QKt=s(BAe);Qqr=r(QKt,"deberta-v2"),QKt.forEach(t),Wqr=r(FWe," \u2014 "),Eoe=n(FWe,"A",{href:!0});var WKt=s(Eoe);Uqr=r(WKt,"TFDebertaV2ForMaskedLM"),WKt.forEach(t),Hqr=r(FWe," (DeBERTa-v2 model)"),FWe.forEach(t),Jqr=i(_e),T0=n(_e,"LI",{});var TWe=s(T0);IAe=n(TWe,"STRONG",{});var UKt=s(IAe);Yqr=r(UKt,"distilbert"),UKt.forEach(t),Kqr=r(TWe," \u2014 "),Coe=n(TWe,"A",{href:!0});var HKt=s(Coe);Zqr=r(HKt,"TFDistilBertForMaskedLM"),HKt.forEach(t),ejr=r(TWe," (DistilBERT model)"),TWe.forEach(t),ojr=i(_e),M0=n(_e,"LI",{});var MWe=s(M0);NAe=n(MWe,"STRONG",{});var JKt=s(NAe);rjr=r(JKt,"electra"),JKt.forEach(t),tjr=r(MWe," \u2014 "),woe=n(MWe,"A",{href:!0});var YKt=s(woe);ajr=r(YKt,"TFElectraForMaskedLM"),YKt.forEach(t),njr=r(MWe," (ELECTRA model)"),MWe.forEach(t),sjr=i(_e),E0=n(_e,"LI",{});var EWe=s(E0);qAe=n(EWe,"STRONG",{});var KKt=s(qAe);ljr=r(KKt,"flaubert"),KKt.forEach(t),ijr=r(EWe," \u2014 "),Aoe=n(EWe,"A",{href:!0});var ZKt=s(Aoe);djr=r(ZKt,"TFFlaubertWithLMHeadModel"),ZKt.forEach(t),cjr=r(EWe," (FlauBERT model)"),EWe.forEach(t),mjr=i(_e),C0=n(_e,"LI",{});var CWe=s(C0);jAe=n(CWe,"STRONG",{});var eZt=s(jAe);fjr=r(eZt,"funnel"),eZt.forEach(t),gjr=r(CWe," \u2014 "),Loe=n(CWe,"A",{href:!0});var oZt=s(Loe);hjr=r(oZt,"TFFunnelForMaskedLM"),oZt.forEach(t),ujr=r(CWe," (Funnel Transformer model)"),CWe.forEach(t),pjr=i(_e),w0=n(_e,"LI",{});var wWe=s(w0);DAe=n(wWe,"STRONG",{});var rZt=s(DAe);_jr=r(rZt,"layoutlm"),rZt.forEach(t),bjr=r(wWe," \u2014 "),yoe=n(wWe,"A",{href:!0});var tZt=s(yoe);vjr=r(tZt,"TFLayoutLMForMaskedLM"),tZt.forEach(t),Fjr=r(wWe," (LayoutLM model)"),wWe.forEach(t),Tjr=i(_e),A0=n(_e,"LI",{});var AWe=s(A0);GAe=n(AWe,"STRONG",{});var aZt=s(GAe);Mjr=r(aZt,"longformer"),aZt.forEach(t),Ejr=r(AWe," \u2014 "),xoe=n(AWe,"A",{href:!0});var nZt=s(xoe);Cjr=r(nZt,"TFLongformerForMaskedLM"),nZt.forEach(t),wjr=r(AWe," (Longformer model)"),AWe.forEach(t),Ajr=i(_e),L0=n(_e,"LI",{});var LWe=s(L0);OAe=n(LWe,"STRONG",{});var sZt=s(OAe);Ljr=r(sZt,"mobilebert"),sZt.forEach(t),yjr=r(LWe," \u2014 "),$oe=n(LWe,"A",{href:!0});var lZt=s($oe);xjr=r(lZt,"TFMobileBertForMaskedLM"),lZt.forEach(t),$jr=r(LWe," (MobileBERT model)"),LWe.forEach(t),kjr=i(_e),y0=n(_e,"LI",{});var yWe=s(y0);VAe=n(yWe,"STRONG",{});var iZt=s(VAe);Sjr=r(iZt,"mpnet"),iZt.forEach(t),Rjr=r(yWe," \u2014 "),koe=n(yWe,"A",{href:!0});var dZt=s(koe);Pjr=r(dZt,"TFMPNetForMaskedLM"),dZt.forEach(t),Bjr=r(yWe," (MPNet model)"),yWe.forEach(t),Ijr=i(_e),x0=n(_e,"LI",{});var xWe=s(x0);XAe=n(xWe,"STRONG",{});var cZt=s(XAe);Njr=r(cZt,"rembert"),cZt.forEach(t),qjr=r(xWe," \u2014 "),Soe=n(xWe,"A",{href:!0});var mZt=s(Soe);jjr=r(mZt,"TFRemBertForMaskedLM"),mZt.forEach(t),Djr=r(xWe," (RemBERT model)"),xWe.forEach(t),Gjr=i(_e),$0=n(_e,"LI",{});var $We=s($0);zAe=n($We,"STRONG",{});var fZt=s(zAe);Ojr=r(fZt,"roberta"),fZt.forEach(t),Vjr=r($We," \u2014 "),Roe=n($We,"A",{href:!0});var gZt=s(Roe);Xjr=r(gZt,"TFRobertaForMaskedLM"),gZt.forEach(t),zjr=r($We," (RoBERTa model)"),$We.forEach(t),Qjr=i(_e),k0=n(_e,"LI",{});var kWe=s(k0);QAe=n(kWe,"STRONG",{});var hZt=s(QAe);Wjr=r(hZt,"roformer"),hZt.forEach(t),Ujr=r(kWe," \u2014 "),Poe=n(kWe,"A",{href:!0});var uZt=s(Poe);Hjr=r(uZt,"TFRoFormerForMaskedLM"),uZt.forEach(t),Jjr=r(kWe," (RoFormer model)"),kWe.forEach(t),Yjr=i(_e),S0=n(_e,"LI",{});var SWe=s(S0);WAe=n(SWe,"STRONG",{});var pZt=s(WAe);Kjr=r(pZt,"tapas"),pZt.forEach(t),Zjr=r(SWe," \u2014 "),Boe=n(SWe,"A",{href:!0});var _Zt=s(Boe);eDr=r(_Zt,"TFTapasForMaskedLM"),_Zt.forEach(t),oDr=r(SWe," (TAPAS model)"),SWe.forEach(t),rDr=i(_e),R0=n(_e,"LI",{});var RWe=s(R0);UAe=n(RWe,"STRONG",{});var bZt=s(UAe);tDr=r(bZt,"xlm"),bZt.forEach(t),aDr=r(RWe," \u2014 "),Ioe=n(RWe,"A",{href:!0});var vZt=s(Ioe);nDr=r(vZt,"TFXLMWithLMHeadModel"),vZt.forEach(t),sDr=r(RWe," (XLM model)"),RWe.forEach(t),lDr=i(_e),P0=n(_e,"LI",{});var PWe=s(P0);HAe=n(PWe,"STRONG",{});var FZt=s(HAe);iDr=r(FZt,"xlm-roberta"),FZt.forEach(t),dDr=r(PWe," \u2014 "),Noe=n(PWe,"A",{href:!0});var TZt=s(Noe);cDr=r(TZt,"TFXLMRobertaForMaskedLM"),TZt.forEach(t),mDr=r(PWe," (XLM-RoBERTa model)"),PWe.forEach(t),_e.forEach(t),fDr=i(mi),T(B0.$$.fragment,mi),mi.forEach(t),ci.forEach(t),eZe=i(m),sm=n(m,"H2",{class:!0});var poo=s(sm);I0=n(poo,"A",{id:!0,class:!0,href:!0});var MZt=s(I0);JAe=n(MZt,"SPAN",{});var EZt=s(JAe);T(Hk.$$.fragment,EZt),EZt.forEach(t),MZt.forEach(t),gDr=i(poo),YAe=n(poo,"SPAN",{});var CZt=s(YAe);hDr=r(CZt,"TFAutoModelForSeq2SeqLM"),CZt.forEach(t),poo.forEach(t),oZe=i(m),fr=n(m,"DIV",{class:!0});var fi=s(fr);T(Jk.$$.fragment,fi),uDr=i(fi),lm=n(fi,"P",{});var nie=s(lm);pDr=r(nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qoe=n(nie,"A",{href:!0});var wZt=s(qoe);_Dr=r(wZt,"from_pretrained()"),wZt.forEach(t),bDr=r(nie," class method or the "),joe=n(nie,"A",{href:!0});var AZt=s(joe);vDr=r(AZt,"from_config()"),AZt.forEach(t),FDr=r(nie,` class
method.`),nie.forEach(t),TDr=i(fi),Yk=n(fi,"P",{});var _oo=s(Yk);MDr=r(_oo,"This class cannot be instantiated directly using "),KAe=n(_oo,"CODE",{});var LZt=s(KAe);EDr=r(LZt,"__init__()"),LZt.forEach(t),CDr=r(_oo," (throws an error)."),_oo.forEach(t),wDr=i(fi),Jt=n(fi,"DIV",{class:!0});var x8=s(Jt);T(Kk.$$.fragment,x8),ADr=i(x8),ZAe=n(x8,"P",{});var yZt=s(ZAe);LDr=r(yZt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yZt.forEach(t),yDr=i(x8),im=n(x8,"P",{});var sie=s(im);xDr=r(sie,`Note:
Loading a model from its configuration file does `),e6e=n(sie,"STRONG",{});var xZt=s(e6e);$Dr=r(xZt,"not"),xZt.forEach(t),kDr=r(sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=n(sie,"A",{href:!0});var $Zt=s(Doe);SDr=r($Zt,"from_pretrained()"),$Zt.forEach(t),RDr=r(sie," to load the model weights."),sie.forEach(t),PDr=i(x8),T(N0.$$.fragment,x8),x8.forEach(t),BDr=i(fi),Or=n(fi,"DIV",{class:!0});var gi=s(Or);T(Zk.$$.fragment,gi),IDr=i(gi),o6e=n(gi,"P",{});var kZt=s(o6e);NDr=r(kZt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kZt.forEach(t),qDr=i(gi),$n=n(gi,"P",{});var $8=s($n);jDr=r($8,"The model class to instantiate is selected based on the "),r6e=n($8,"CODE",{});var SZt=s(r6e);DDr=r(SZt,"model_type"),SZt.forEach(t),GDr=r($8,` property of the config object (either
passed as an argument or loaded from `),t6e=n($8,"CODE",{});var RZt=s(t6e);ODr=r(RZt,"pretrained_model_name_or_path"),RZt.forEach(t),VDr=r($8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=n($8,"CODE",{});var PZt=s(a6e);XDr=r(PZt,"pretrained_model_name_or_path"),PZt.forEach(t),zDr=r($8,":"),$8.forEach(t),QDr=i(gi),ye=n(gi,"UL",{});var Ne=s(ye);q0=n(Ne,"LI",{});var BWe=s(q0);n6e=n(BWe,"STRONG",{});var BZt=s(n6e);WDr=r(BZt,"bart"),BZt.forEach(t),UDr=r(BWe," \u2014 "),Goe=n(BWe,"A",{href:!0});var IZt=s(Goe);HDr=r(IZt,"TFBartForConditionalGeneration"),IZt.forEach(t),JDr=r(BWe," (BART model)"),BWe.forEach(t),YDr=i(Ne),j0=n(Ne,"LI",{});var IWe=s(j0);s6e=n(IWe,"STRONG",{});var NZt=s(s6e);KDr=r(NZt,"blenderbot"),NZt.forEach(t),ZDr=r(IWe," \u2014 "),Ooe=n(IWe,"A",{href:!0});var qZt=s(Ooe);eGr=r(qZt,"TFBlenderbotForConditionalGeneration"),qZt.forEach(t),oGr=r(IWe," (Blenderbot model)"),IWe.forEach(t),rGr=i(Ne),D0=n(Ne,"LI",{});var NWe=s(D0);l6e=n(NWe,"STRONG",{});var jZt=s(l6e);tGr=r(jZt,"blenderbot-small"),jZt.forEach(t),aGr=r(NWe," \u2014 "),Voe=n(NWe,"A",{href:!0});var DZt=s(Voe);nGr=r(DZt,"TFBlenderbotSmallForConditionalGeneration"),DZt.forEach(t),sGr=r(NWe," (BlenderbotSmall model)"),NWe.forEach(t),lGr=i(Ne),G0=n(Ne,"LI",{});var qWe=s(G0);i6e=n(qWe,"STRONG",{});var GZt=s(i6e);iGr=r(GZt,"encoder-decoder"),GZt.forEach(t),dGr=r(qWe," \u2014 "),Xoe=n(qWe,"A",{href:!0});var OZt=s(Xoe);cGr=r(OZt,"TFEncoderDecoderModel"),OZt.forEach(t),mGr=r(qWe," (Encoder decoder model)"),qWe.forEach(t),fGr=i(Ne),O0=n(Ne,"LI",{});var jWe=s(O0);d6e=n(jWe,"STRONG",{});var VZt=s(d6e);gGr=r(VZt,"led"),VZt.forEach(t),hGr=r(jWe," \u2014 "),zoe=n(jWe,"A",{href:!0});var XZt=s(zoe);uGr=r(XZt,"TFLEDForConditionalGeneration"),XZt.forEach(t),pGr=r(jWe," (LED model)"),jWe.forEach(t),_Gr=i(Ne),V0=n(Ne,"LI",{});var DWe=s(V0);c6e=n(DWe,"STRONG",{});var zZt=s(c6e);bGr=r(zZt,"marian"),zZt.forEach(t),vGr=r(DWe," \u2014 "),Qoe=n(DWe,"A",{href:!0});var QZt=s(Qoe);FGr=r(QZt,"TFMarianMTModel"),QZt.forEach(t),TGr=r(DWe," (Marian model)"),DWe.forEach(t),MGr=i(Ne),X0=n(Ne,"LI",{});var GWe=s(X0);m6e=n(GWe,"STRONG",{});var WZt=s(m6e);EGr=r(WZt,"mbart"),WZt.forEach(t),CGr=r(GWe," \u2014 "),Woe=n(GWe,"A",{href:!0});var UZt=s(Woe);wGr=r(UZt,"TFMBartForConditionalGeneration"),UZt.forEach(t),AGr=r(GWe," (mBART model)"),GWe.forEach(t),LGr=i(Ne),z0=n(Ne,"LI",{});var OWe=s(z0);f6e=n(OWe,"STRONG",{});var HZt=s(f6e);yGr=r(HZt,"mt5"),HZt.forEach(t),xGr=r(OWe," \u2014 "),Uoe=n(OWe,"A",{href:!0});var JZt=s(Uoe);$Gr=r(JZt,"TFMT5ForConditionalGeneration"),JZt.forEach(t),kGr=r(OWe," (MT5 model)"),OWe.forEach(t),SGr=i(Ne),Q0=n(Ne,"LI",{});var VWe=s(Q0);g6e=n(VWe,"STRONG",{});var YZt=s(g6e);RGr=r(YZt,"pegasus"),YZt.forEach(t),PGr=r(VWe," \u2014 "),Hoe=n(VWe,"A",{href:!0});var KZt=s(Hoe);BGr=r(KZt,"TFPegasusForConditionalGeneration"),KZt.forEach(t),IGr=r(VWe," (Pegasus model)"),VWe.forEach(t),NGr=i(Ne),W0=n(Ne,"LI",{});var XWe=s(W0);h6e=n(XWe,"STRONG",{});var ZZt=s(h6e);qGr=r(ZZt,"t5"),ZZt.forEach(t),jGr=r(XWe," \u2014 "),Joe=n(XWe,"A",{href:!0});var eea=s(Joe);DGr=r(eea,"TFT5ForConditionalGeneration"),eea.forEach(t),GGr=r(XWe," (T5 model)"),XWe.forEach(t),Ne.forEach(t),OGr=i(gi),T(U0.$$.fragment,gi),gi.forEach(t),fi.forEach(t),rZe=i(m),dm=n(m,"H2",{class:!0});var boo=s(dm);H0=n(boo,"A",{id:!0,class:!0,href:!0});var oea=s(H0);u6e=n(oea,"SPAN",{});var rea=s(u6e);T(eS.$$.fragment,rea),rea.forEach(t),oea.forEach(t),VGr=i(boo),p6e=n(boo,"SPAN",{});var tea=s(p6e);XGr=r(tea,"TFAutoModelForSequenceClassification"),tea.forEach(t),boo.forEach(t),tZe=i(m),gr=n(m,"DIV",{class:!0});var hi=s(gr);T(oS.$$.fragment,hi),zGr=i(hi),cm=n(hi,"P",{});var lie=s(cm);QGr=r(lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yoe=n(lie,"A",{href:!0});var aea=s(Yoe);WGr=r(aea,"from_pretrained()"),aea.forEach(t),UGr=r(lie," class method or the "),Koe=n(lie,"A",{href:!0});var nea=s(Koe);HGr=r(nea,"from_config()"),nea.forEach(t),JGr=r(lie,` class
method.`),lie.forEach(t),YGr=i(hi),rS=n(hi,"P",{});var voo=s(rS);KGr=r(voo,"This class cannot be instantiated directly using "),_6e=n(voo,"CODE",{});var sea=s(_6e);ZGr=r(sea,"__init__()"),sea.forEach(t),eOr=r(voo," (throws an error)."),voo.forEach(t),oOr=i(hi),Yt=n(hi,"DIV",{class:!0});var k8=s(Yt);T(tS.$$.fragment,k8),rOr=i(k8),b6e=n(k8,"P",{});var lea=s(b6e);tOr=r(lea,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lea.forEach(t),aOr=i(k8),mm=n(k8,"P",{});var iie=s(mm);nOr=r(iie,`Note:
Loading a model from its configuration file does `),v6e=n(iie,"STRONG",{});var iea=s(v6e);sOr=r(iea,"not"),iea.forEach(t),lOr=r(iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=n(iie,"A",{href:!0});var dea=s(Zoe);iOr=r(dea,"from_pretrained()"),dea.forEach(t),dOr=r(iie," to load the model weights."),iie.forEach(t),cOr=i(k8),T(J0.$$.fragment,k8),k8.forEach(t),mOr=i(hi),Vr=n(hi,"DIV",{class:!0});var ui=s(Vr);T(aS.$$.fragment,ui),fOr=i(ui),F6e=n(ui,"P",{});var cea=s(F6e);gOr=r(cea,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cea.forEach(t),hOr=i(ui),kn=n(ui,"P",{});var S8=s(kn);uOr=r(S8,"The model class to instantiate is selected based on the "),T6e=n(S8,"CODE",{});var mea=s(T6e);pOr=r(mea,"model_type"),mea.forEach(t),_Or=r(S8,` property of the config object (either
passed as an argument or loaded from `),M6e=n(S8,"CODE",{});var fea=s(M6e);bOr=r(fea,"pretrained_model_name_or_path"),fea.forEach(t),vOr=r(S8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=n(S8,"CODE",{});var gea=s(E6e);FOr=r(gea,"pretrained_model_name_or_path"),gea.forEach(t),TOr=r(S8,":"),S8.forEach(t),MOr=i(ui),re=n(ui,"UL",{});var ae=s(re);Y0=n(ae,"LI",{});var zWe=s(Y0);C6e=n(zWe,"STRONG",{});var hea=s(C6e);EOr=r(hea,"albert"),hea.forEach(t),COr=r(zWe," \u2014 "),ere=n(zWe,"A",{href:!0});var uea=s(ere);wOr=r(uea,"TFAlbertForSequenceClassification"),uea.forEach(t),AOr=r(zWe," (ALBERT model)"),zWe.forEach(t),LOr=i(ae),K0=n(ae,"LI",{});var QWe=s(K0);w6e=n(QWe,"STRONG",{});var pea=s(w6e);yOr=r(pea,"bert"),pea.forEach(t),xOr=r(QWe," \u2014 "),ore=n(QWe,"A",{href:!0});var _ea=s(ore);$Or=r(_ea,"TFBertForSequenceClassification"),_ea.forEach(t),kOr=r(QWe," (BERT model)"),QWe.forEach(t),SOr=i(ae),Z0=n(ae,"LI",{});var WWe=s(Z0);A6e=n(WWe,"STRONG",{});var bea=s(A6e);ROr=r(bea,"camembert"),bea.forEach(t),POr=r(WWe," \u2014 "),rre=n(WWe,"A",{href:!0});var vea=s(rre);BOr=r(vea,"TFCamembertForSequenceClassification"),vea.forEach(t),IOr=r(WWe," (CamemBERT model)"),WWe.forEach(t),NOr=i(ae),ew=n(ae,"LI",{});var UWe=s(ew);L6e=n(UWe,"STRONG",{});var Fea=s(L6e);qOr=r(Fea,"convbert"),Fea.forEach(t),jOr=r(UWe," \u2014 "),tre=n(UWe,"A",{href:!0});var Tea=s(tre);DOr=r(Tea,"TFConvBertForSequenceClassification"),Tea.forEach(t),GOr=r(UWe," (ConvBERT model)"),UWe.forEach(t),OOr=i(ae),ow=n(ae,"LI",{});var HWe=s(ow);y6e=n(HWe,"STRONG",{});var Mea=s(y6e);VOr=r(Mea,"ctrl"),Mea.forEach(t),XOr=r(HWe," \u2014 "),are=n(HWe,"A",{href:!0});var Eea=s(are);zOr=r(Eea,"TFCTRLForSequenceClassification"),Eea.forEach(t),QOr=r(HWe," (CTRL model)"),HWe.forEach(t),WOr=i(ae),rw=n(ae,"LI",{});var JWe=s(rw);x6e=n(JWe,"STRONG",{});var Cea=s(x6e);UOr=r(Cea,"deberta"),Cea.forEach(t),HOr=r(JWe," \u2014 "),nre=n(JWe,"A",{href:!0});var wea=s(nre);JOr=r(wea,"TFDebertaForSequenceClassification"),wea.forEach(t),YOr=r(JWe," (DeBERTa model)"),JWe.forEach(t),KOr=i(ae),tw=n(ae,"LI",{});var YWe=s(tw);$6e=n(YWe,"STRONG",{});var Aea=s($6e);ZOr=r(Aea,"deberta-v2"),Aea.forEach(t),eVr=r(YWe," \u2014 "),sre=n(YWe,"A",{href:!0});var Lea=s(sre);oVr=r(Lea,"TFDebertaV2ForSequenceClassification"),Lea.forEach(t),rVr=r(YWe," (DeBERTa-v2 model)"),YWe.forEach(t),tVr=i(ae),aw=n(ae,"LI",{});var KWe=s(aw);k6e=n(KWe,"STRONG",{});var yea=s(k6e);aVr=r(yea,"distilbert"),yea.forEach(t),nVr=r(KWe," \u2014 "),lre=n(KWe,"A",{href:!0});var xea=s(lre);sVr=r(xea,"TFDistilBertForSequenceClassification"),xea.forEach(t),lVr=r(KWe," (DistilBERT model)"),KWe.forEach(t),iVr=i(ae),nw=n(ae,"LI",{});var ZWe=s(nw);S6e=n(ZWe,"STRONG",{});var $ea=s(S6e);dVr=r($ea,"electra"),$ea.forEach(t),cVr=r(ZWe," \u2014 "),ire=n(ZWe,"A",{href:!0});var kea=s(ire);mVr=r(kea,"TFElectraForSequenceClassification"),kea.forEach(t),fVr=r(ZWe," (ELECTRA model)"),ZWe.forEach(t),gVr=i(ae),sw=n(ae,"LI",{});var eUe=s(sw);R6e=n(eUe,"STRONG",{});var Sea=s(R6e);hVr=r(Sea,"flaubert"),Sea.forEach(t),uVr=r(eUe," \u2014 "),dre=n(eUe,"A",{href:!0});var Rea=s(dre);pVr=r(Rea,"TFFlaubertForSequenceClassification"),Rea.forEach(t),_Vr=r(eUe," (FlauBERT model)"),eUe.forEach(t),bVr=i(ae),lw=n(ae,"LI",{});var oUe=s(lw);P6e=n(oUe,"STRONG",{});var Pea=s(P6e);vVr=r(Pea,"funnel"),Pea.forEach(t),FVr=r(oUe," \u2014 "),cre=n(oUe,"A",{href:!0});var Bea=s(cre);TVr=r(Bea,"TFFunnelForSequenceClassification"),Bea.forEach(t),MVr=r(oUe," (Funnel Transformer model)"),oUe.forEach(t),EVr=i(ae),iw=n(ae,"LI",{});var rUe=s(iw);B6e=n(rUe,"STRONG",{});var Iea=s(B6e);CVr=r(Iea,"gpt2"),Iea.forEach(t),wVr=r(rUe," \u2014 "),mre=n(rUe,"A",{href:!0});var Nea=s(mre);AVr=r(Nea,"TFGPT2ForSequenceClassification"),Nea.forEach(t),LVr=r(rUe," (OpenAI GPT-2 model)"),rUe.forEach(t),yVr=i(ae),dw=n(ae,"LI",{});var tUe=s(dw);I6e=n(tUe,"STRONG",{});var qea=s(I6e);xVr=r(qea,"gptj"),qea.forEach(t),$Vr=r(tUe," \u2014 "),fre=n(tUe,"A",{href:!0});var jea=s(fre);kVr=r(jea,"TFGPTJForSequenceClassification"),jea.forEach(t),SVr=r(tUe," (GPT-J model)"),tUe.forEach(t),RVr=i(ae),cw=n(ae,"LI",{});var aUe=s(cw);N6e=n(aUe,"STRONG",{});var Dea=s(N6e);PVr=r(Dea,"layoutlm"),Dea.forEach(t),BVr=r(aUe," \u2014 "),gre=n(aUe,"A",{href:!0});var Gea=s(gre);IVr=r(Gea,"TFLayoutLMForSequenceClassification"),Gea.forEach(t),NVr=r(aUe," (LayoutLM model)"),aUe.forEach(t),qVr=i(ae),mw=n(ae,"LI",{});var nUe=s(mw);q6e=n(nUe,"STRONG",{});var Oea=s(q6e);jVr=r(Oea,"layoutlmv3"),Oea.forEach(t),DVr=r(nUe," \u2014 "),hre=n(nUe,"A",{href:!0});var Vea=s(hre);GVr=r(Vea,"TFLayoutLMv3ForSequenceClassification"),Vea.forEach(t),OVr=r(nUe," (LayoutLMv3 model)"),nUe.forEach(t),VVr=i(ae),fw=n(ae,"LI",{});var sUe=s(fw);j6e=n(sUe,"STRONG",{});var Xea=s(j6e);XVr=r(Xea,"longformer"),Xea.forEach(t),zVr=r(sUe," \u2014 "),ure=n(sUe,"A",{href:!0});var zea=s(ure);QVr=r(zea,"TFLongformerForSequenceClassification"),zea.forEach(t),WVr=r(sUe," (Longformer model)"),sUe.forEach(t),UVr=i(ae),gw=n(ae,"LI",{});var lUe=s(gw);D6e=n(lUe,"STRONG",{});var Qea=s(D6e);HVr=r(Qea,"mobilebert"),Qea.forEach(t),JVr=r(lUe," \u2014 "),pre=n(lUe,"A",{href:!0});var Wea=s(pre);YVr=r(Wea,"TFMobileBertForSequenceClassification"),Wea.forEach(t),KVr=r(lUe," (MobileBERT model)"),lUe.forEach(t),ZVr=i(ae),hw=n(ae,"LI",{});var iUe=s(hw);G6e=n(iUe,"STRONG",{});var Uea=s(G6e);eXr=r(Uea,"mpnet"),Uea.forEach(t),oXr=r(iUe," \u2014 "),_re=n(iUe,"A",{href:!0});var Hea=s(_re);rXr=r(Hea,"TFMPNetForSequenceClassification"),Hea.forEach(t),tXr=r(iUe," (MPNet model)"),iUe.forEach(t),aXr=i(ae),uw=n(ae,"LI",{});var dUe=s(uw);O6e=n(dUe,"STRONG",{});var Jea=s(O6e);nXr=r(Jea,"openai-gpt"),Jea.forEach(t),sXr=r(dUe," \u2014 "),bre=n(dUe,"A",{href:!0});var Yea=s(bre);lXr=r(Yea,"TFOpenAIGPTForSequenceClassification"),Yea.forEach(t),iXr=r(dUe," (OpenAI GPT model)"),dUe.forEach(t),dXr=i(ae),pw=n(ae,"LI",{});var cUe=s(pw);V6e=n(cUe,"STRONG",{});var Kea=s(V6e);cXr=r(Kea,"rembert"),Kea.forEach(t),mXr=r(cUe," \u2014 "),vre=n(cUe,"A",{href:!0});var Zea=s(vre);fXr=r(Zea,"TFRemBertForSequenceClassification"),Zea.forEach(t),gXr=r(cUe," (RemBERT model)"),cUe.forEach(t),hXr=i(ae),_w=n(ae,"LI",{});var mUe=s(_w);X6e=n(mUe,"STRONG",{});var eoa=s(X6e);uXr=r(eoa,"roberta"),eoa.forEach(t),pXr=r(mUe," \u2014 "),Fre=n(mUe,"A",{href:!0});var ooa=s(Fre);_Xr=r(ooa,"TFRobertaForSequenceClassification"),ooa.forEach(t),bXr=r(mUe," (RoBERTa model)"),mUe.forEach(t),vXr=i(ae),bw=n(ae,"LI",{});var fUe=s(bw);z6e=n(fUe,"STRONG",{});var roa=s(z6e);FXr=r(roa,"roformer"),roa.forEach(t),TXr=r(fUe," \u2014 "),Tre=n(fUe,"A",{href:!0});var toa=s(Tre);MXr=r(toa,"TFRoFormerForSequenceClassification"),toa.forEach(t),EXr=r(fUe," (RoFormer model)"),fUe.forEach(t),CXr=i(ae),vw=n(ae,"LI",{});var gUe=s(vw);Q6e=n(gUe,"STRONG",{});var aoa=s(Q6e);wXr=r(aoa,"tapas"),aoa.forEach(t),AXr=r(gUe," \u2014 "),Mre=n(gUe,"A",{href:!0});var noa=s(Mre);LXr=r(noa,"TFTapasForSequenceClassification"),noa.forEach(t),yXr=r(gUe," (TAPAS model)"),gUe.forEach(t),xXr=i(ae),Fw=n(ae,"LI",{});var hUe=s(Fw);W6e=n(hUe,"STRONG",{});var soa=s(W6e);$Xr=r(soa,"transfo-xl"),soa.forEach(t),kXr=r(hUe," \u2014 "),Ere=n(hUe,"A",{href:!0});var loa=s(Ere);SXr=r(loa,"TFTransfoXLForSequenceClassification"),loa.forEach(t),RXr=r(hUe," (Transformer-XL model)"),hUe.forEach(t),PXr=i(ae),Tw=n(ae,"LI",{});var uUe=s(Tw);U6e=n(uUe,"STRONG",{});var ioa=s(U6e);BXr=r(ioa,"xlm"),ioa.forEach(t),IXr=r(uUe," \u2014 "),Cre=n(uUe,"A",{href:!0});var doa=s(Cre);NXr=r(doa,"TFXLMForSequenceClassification"),doa.forEach(t),qXr=r(uUe," (XLM model)"),uUe.forEach(t),jXr=i(ae),Mw=n(ae,"LI",{});var pUe=s(Mw);H6e=n(pUe,"STRONG",{});var coa=s(H6e);DXr=r(coa,"xlm-roberta"),coa.forEach(t),GXr=r(pUe," \u2014 "),wre=n(pUe,"A",{href:!0});var moa=s(wre);OXr=r(moa,"TFXLMRobertaForSequenceClassification"),moa.forEach(t),VXr=r(pUe," (XLM-RoBERTa model)"),pUe.forEach(t),XXr=i(ae),Ew=n(ae,"LI",{});var _Ue=s(Ew);J6e=n(_Ue,"STRONG",{});var foa=s(J6e);zXr=r(foa,"xlnet"),foa.forEach(t),QXr=r(_Ue," \u2014 "),Are=n(_Ue,"A",{href:!0});var goa=s(Are);WXr=r(goa,"TFXLNetForSequenceClassification"),goa.forEach(t),UXr=r(_Ue," (XLNet model)"),_Ue.forEach(t),ae.forEach(t),HXr=i(ui),T(Cw.$$.fragment,ui),ui.forEach(t),hi.forEach(t),aZe=i(m),fm=n(m,"H2",{class:!0});var Foo=s(fm);ww=n(Foo,"A",{id:!0,class:!0,href:!0});var hoa=s(ww);Y6e=n(hoa,"SPAN",{});var uoa=s(Y6e);T(nS.$$.fragment,uoa),uoa.forEach(t),hoa.forEach(t),JXr=i(Foo),K6e=n(Foo,"SPAN",{});var poa=s(K6e);YXr=r(poa,"TFAutoModelForMultipleChoice"),poa.forEach(t),Foo.forEach(t),nZe=i(m),hr=n(m,"DIV",{class:!0});var pi=s(hr);T(sS.$$.fragment,pi),KXr=i(pi),gm=n(pi,"P",{});var die=s(gm);ZXr=r(die,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lre=n(die,"A",{href:!0});var _oa=s(Lre);ezr=r(_oa,"from_pretrained()"),_oa.forEach(t),ozr=r(die," class method or the "),yre=n(die,"A",{href:!0});var boa=s(yre);rzr=r(boa,"from_config()"),boa.forEach(t),tzr=r(die,` class
method.`),die.forEach(t),azr=i(pi),lS=n(pi,"P",{});var Too=s(lS);nzr=r(Too,"This class cannot be instantiated directly using "),Z6e=n(Too,"CODE",{});var voa=s(Z6e);szr=r(voa,"__init__()"),voa.forEach(t),lzr=r(Too," (throws an error)."),Too.forEach(t),izr=i(pi),Kt=n(pi,"DIV",{class:!0});var R8=s(Kt);T(iS.$$.fragment,R8),dzr=i(R8),e7e=n(R8,"P",{});var Foa=s(e7e);czr=r(Foa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Foa.forEach(t),mzr=i(R8),hm=n(R8,"P",{});var cie=s(hm);fzr=r(cie,`Note:
Loading a model from its configuration file does `),o7e=n(cie,"STRONG",{});var Toa=s(o7e);gzr=r(Toa,"not"),Toa.forEach(t),hzr=r(cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=n(cie,"A",{href:!0});var Moa=s(xre);uzr=r(Moa,"from_pretrained()"),Moa.forEach(t),pzr=r(cie," to load the model weights."),cie.forEach(t),_zr=i(R8),T(Aw.$$.fragment,R8),R8.forEach(t),bzr=i(pi),Xr=n(pi,"DIV",{class:!0});var _i=s(Xr);T(dS.$$.fragment,_i),vzr=i(_i),r7e=n(_i,"P",{});var Eoa=s(r7e);Fzr=r(Eoa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Eoa.forEach(t),Tzr=i(_i),Sn=n(_i,"P",{});var P8=s(Sn);Mzr=r(P8,"The model class to instantiate is selected based on the "),t7e=n(P8,"CODE",{});var Coa=s(t7e);Ezr=r(Coa,"model_type"),Coa.forEach(t),Czr=r(P8,` property of the config object (either
passed as an argument or loaded from `),a7e=n(P8,"CODE",{});var woa=s(a7e);wzr=r(woa,"pretrained_model_name_or_path"),woa.forEach(t),Azr=r(P8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(P8,"CODE",{});var Aoa=s(n7e);Lzr=r(Aoa,"pretrained_model_name_or_path"),Aoa.forEach(t),yzr=r(P8,":"),P8.forEach(t),xzr=i(_i),ve=n(_i,"UL",{});var Te=s(ve);Lw=n(Te,"LI",{});var bUe=s(Lw);s7e=n(bUe,"STRONG",{});var Loa=s(s7e);$zr=r(Loa,"albert"),Loa.forEach(t),kzr=r(bUe," \u2014 "),$re=n(bUe,"A",{href:!0});var yoa=s($re);Szr=r(yoa,"TFAlbertForMultipleChoice"),yoa.forEach(t),Rzr=r(bUe," (ALBERT model)"),bUe.forEach(t),Pzr=i(Te),yw=n(Te,"LI",{});var vUe=s(yw);l7e=n(vUe,"STRONG",{});var xoa=s(l7e);Bzr=r(xoa,"bert"),xoa.forEach(t),Izr=r(vUe," \u2014 "),kre=n(vUe,"A",{href:!0});var $oa=s(kre);Nzr=r($oa,"TFBertForMultipleChoice"),$oa.forEach(t),qzr=r(vUe," (BERT model)"),vUe.forEach(t),jzr=i(Te),xw=n(Te,"LI",{});var FUe=s(xw);i7e=n(FUe,"STRONG",{});var koa=s(i7e);Dzr=r(koa,"camembert"),koa.forEach(t),Gzr=r(FUe," \u2014 "),Sre=n(FUe,"A",{href:!0});var Soa=s(Sre);Ozr=r(Soa,"TFCamembertForMultipleChoice"),Soa.forEach(t),Vzr=r(FUe," (CamemBERT model)"),FUe.forEach(t),Xzr=i(Te),$w=n(Te,"LI",{});var TUe=s($w);d7e=n(TUe,"STRONG",{});var Roa=s(d7e);zzr=r(Roa,"convbert"),Roa.forEach(t),Qzr=r(TUe," \u2014 "),Rre=n(TUe,"A",{href:!0});var Poa=s(Rre);Wzr=r(Poa,"TFConvBertForMultipleChoice"),Poa.forEach(t),Uzr=r(TUe," (ConvBERT model)"),TUe.forEach(t),Hzr=i(Te),kw=n(Te,"LI",{});var MUe=s(kw);c7e=n(MUe,"STRONG",{});var Boa=s(c7e);Jzr=r(Boa,"distilbert"),Boa.forEach(t),Yzr=r(MUe," \u2014 "),Pre=n(MUe,"A",{href:!0});var Ioa=s(Pre);Kzr=r(Ioa,"TFDistilBertForMultipleChoice"),Ioa.forEach(t),Zzr=r(MUe," (DistilBERT model)"),MUe.forEach(t),eQr=i(Te),Sw=n(Te,"LI",{});var EUe=s(Sw);m7e=n(EUe,"STRONG",{});var Noa=s(m7e);oQr=r(Noa,"electra"),Noa.forEach(t),rQr=r(EUe," \u2014 "),Bre=n(EUe,"A",{href:!0});var qoa=s(Bre);tQr=r(qoa,"TFElectraForMultipleChoice"),qoa.forEach(t),aQr=r(EUe," (ELECTRA model)"),EUe.forEach(t),nQr=i(Te),Rw=n(Te,"LI",{});var CUe=s(Rw);f7e=n(CUe,"STRONG",{});var joa=s(f7e);sQr=r(joa,"flaubert"),joa.forEach(t),lQr=r(CUe," \u2014 "),Ire=n(CUe,"A",{href:!0});var Doa=s(Ire);iQr=r(Doa,"TFFlaubertForMultipleChoice"),Doa.forEach(t),dQr=r(CUe," (FlauBERT model)"),CUe.forEach(t),cQr=i(Te),Pw=n(Te,"LI",{});var wUe=s(Pw);g7e=n(wUe,"STRONG",{});var Goa=s(g7e);mQr=r(Goa,"funnel"),Goa.forEach(t),fQr=r(wUe," \u2014 "),Nre=n(wUe,"A",{href:!0});var Ooa=s(Nre);gQr=r(Ooa,"TFFunnelForMultipleChoice"),Ooa.forEach(t),hQr=r(wUe," (Funnel Transformer model)"),wUe.forEach(t),uQr=i(Te),Bw=n(Te,"LI",{});var AUe=s(Bw);h7e=n(AUe,"STRONG",{});var Voa=s(h7e);pQr=r(Voa,"longformer"),Voa.forEach(t),_Qr=r(AUe," \u2014 "),qre=n(AUe,"A",{href:!0});var Xoa=s(qre);bQr=r(Xoa,"TFLongformerForMultipleChoice"),Xoa.forEach(t),vQr=r(AUe," (Longformer model)"),AUe.forEach(t),FQr=i(Te),Iw=n(Te,"LI",{});var LUe=s(Iw);u7e=n(LUe,"STRONG",{});var zoa=s(u7e);TQr=r(zoa,"mobilebert"),zoa.forEach(t),MQr=r(LUe," \u2014 "),jre=n(LUe,"A",{href:!0});var Qoa=s(jre);EQr=r(Qoa,"TFMobileBertForMultipleChoice"),Qoa.forEach(t),CQr=r(LUe," (MobileBERT model)"),LUe.forEach(t),wQr=i(Te),Nw=n(Te,"LI",{});var yUe=s(Nw);p7e=n(yUe,"STRONG",{});var Woa=s(p7e);AQr=r(Woa,"mpnet"),Woa.forEach(t),LQr=r(yUe," \u2014 "),Dre=n(yUe,"A",{href:!0});var Uoa=s(Dre);yQr=r(Uoa,"TFMPNetForMultipleChoice"),Uoa.forEach(t),xQr=r(yUe," (MPNet model)"),yUe.forEach(t),$Qr=i(Te),qw=n(Te,"LI",{});var xUe=s(qw);_7e=n(xUe,"STRONG",{});var Hoa=s(_7e);kQr=r(Hoa,"rembert"),Hoa.forEach(t),SQr=r(xUe," \u2014 "),Gre=n(xUe,"A",{href:!0});var Joa=s(Gre);RQr=r(Joa,"TFRemBertForMultipleChoice"),Joa.forEach(t),PQr=r(xUe," (RemBERT model)"),xUe.forEach(t),BQr=i(Te),jw=n(Te,"LI",{});var $Ue=s(jw);b7e=n($Ue,"STRONG",{});var Yoa=s(b7e);IQr=r(Yoa,"roberta"),Yoa.forEach(t),NQr=r($Ue," \u2014 "),Ore=n($Ue,"A",{href:!0});var Koa=s(Ore);qQr=r(Koa,"TFRobertaForMultipleChoice"),Koa.forEach(t),jQr=r($Ue," (RoBERTa model)"),$Ue.forEach(t),DQr=i(Te),Dw=n(Te,"LI",{});var kUe=s(Dw);v7e=n(kUe,"STRONG",{});var Zoa=s(v7e);GQr=r(Zoa,"roformer"),Zoa.forEach(t),OQr=r(kUe," \u2014 "),Vre=n(kUe,"A",{href:!0});var era=s(Vre);VQr=r(era,"TFRoFormerForMultipleChoice"),era.forEach(t),XQr=r(kUe," (RoFormer model)"),kUe.forEach(t),zQr=i(Te),Gw=n(Te,"LI",{});var SUe=s(Gw);F7e=n(SUe,"STRONG",{});var ora=s(F7e);QQr=r(ora,"xlm"),ora.forEach(t),WQr=r(SUe," \u2014 "),Xre=n(SUe,"A",{href:!0});var rra=s(Xre);UQr=r(rra,"TFXLMForMultipleChoice"),rra.forEach(t),HQr=r(SUe," (XLM model)"),SUe.forEach(t),JQr=i(Te),Ow=n(Te,"LI",{});var RUe=s(Ow);T7e=n(RUe,"STRONG",{});var tra=s(T7e);YQr=r(tra,"xlm-roberta"),tra.forEach(t),KQr=r(RUe," \u2014 "),zre=n(RUe,"A",{href:!0});var ara=s(zre);ZQr=r(ara,"TFXLMRobertaForMultipleChoice"),ara.forEach(t),eWr=r(RUe," (XLM-RoBERTa model)"),RUe.forEach(t),oWr=i(Te),Vw=n(Te,"LI",{});var PUe=s(Vw);M7e=n(PUe,"STRONG",{});var nra=s(M7e);rWr=r(nra,"xlnet"),nra.forEach(t),tWr=r(PUe," \u2014 "),Qre=n(PUe,"A",{href:!0});var sra=s(Qre);aWr=r(sra,"TFXLNetForMultipleChoice"),sra.forEach(t),nWr=r(PUe," (XLNet model)"),PUe.forEach(t),Te.forEach(t),sWr=i(_i),T(Xw.$$.fragment,_i),_i.forEach(t),pi.forEach(t),sZe=i(m),um=n(m,"H2",{class:!0});var Moo=s(um);zw=n(Moo,"A",{id:!0,class:!0,href:!0});var lra=s(zw);E7e=n(lra,"SPAN",{});var ira=s(E7e);T(cS.$$.fragment,ira),ira.forEach(t),lra.forEach(t),lWr=i(Moo),C7e=n(Moo,"SPAN",{});var dra=s(C7e);iWr=r(dra,"TFAutoModelForNextSentencePrediction"),dra.forEach(t),Moo.forEach(t),lZe=i(m),ur=n(m,"DIV",{class:!0});var bi=s(ur);T(mS.$$.fragment,bi),dWr=i(bi),pm=n(bi,"P",{});var mie=s(pm);cWr=r(mie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wre=n(mie,"A",{href:!0});var cra=s(Wre);mWr=r(cra,"from_pretrained()"),cra.forEach(t),fWr=r(mie," class method or the "),Ure=n(mie,"A",{href:!0});var mra=s(Ure);gWr=r(mra,"from_config()"),mra.forEach(t),hWr=r(mie,` class
method.`),mie.forEach(t),uWr=i(bi),fS=n(bi,"P",{});var Eoo=s(fS);pWr=r(Eoo,"This class cannot be instantiated directly using "),w7e=n(Eoo,"CODE",{});var fra=s(w7e);_Wr=r(fra,"__init__()"),fra.forEach(t),bWr=r(Eoo," (throws an error)."),Eoo.forEach(t),vWr=i(bi),Zt=n(bi,"DIV",{class:!0});var B8=s(Zt);T(gS.$$.fragment,B8),FWr=i(B8),A7e=n(B8,"P",{});var gra=s(A7e);TWr=r(gra,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gra.forEach(t),MWr=i(B8),_m=n(B8,"P",{});var fie=s(_m);EWr=r(fie,`Note:
Loading a model from its configuration file does `),L7e=n(fie,"STRONG",{});var hra=s(L7e);CWr=r(hra,"not"),hra.forEach(t),wWr=r(fie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hre=n(fie,"A",{href:!0});var ura=s(Hre);AWr=r(ura,"from_pretrained()"),ura.forEach(t),LWr=r(fie," to load the model weights."),fie.forEach(t),yWr=i(B8),T(Qw.$$.fragment,B8),B8.forEach(t),xWr=i(bi),zr=n(bi,"DIV",{class:!0});var vi=s(zr);T(hS.$$.fragment,vi),$Wr=i(vi),y7e=n(vi,"P",{});var pra=s(y7e);kWr=r(pra,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),pra.forEach(t),SWr=i(vi),Rn=n(vi,"P",{});var I8=s(Rn);RWr=r(I8,"The model class to instantiate is selected based on the "),x7e=n(I8,"CODE",{});var _ra=s(x7e);PWr=r(_ra,"model_type"),_ra.forEach(t),BWr=r(I8,` property of the config object (either
passed as an argument or loaded from `),$7e=n(I8,"CODE",{});var bra=s($7e);IWr=r(bra,"pretrained_model_name_or_path"),bra.forEach(t),NWr=r(I8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=n(I8,"CODE",{});var vra=s(k7e);qWr=r(vra,"pretrained_model_name_or_path"),vra.forEach(t),jWr=r(I8,":"),I8.forEach(t),DWr=i(vi),uS=n(vi,"UL",{});var Coo=s(uS);Ww=n(Coo,"LI",{});var BUe=s(Ww);S7e=n(BUe,"STRONG",{});var Fra=s(S7e);GWr=r(Fra,"bert"),Fra.forEach(t),OWr=r(BUe," \u2014 "),Jre=n(BUe,"A",{href:!0});var Tra=s(Jre);VWr=r(Tra,"TFBertForNextSentencePrediction"),Tra.forEach(t),XWr=r(BUe," (BERT model)"),BUe.forEach(t),zWr=i(Coo),Uw=n(Coo,"LI",{});var IUe=s(Uw);R7e=n(IUe,"STRONG",{});var Mra=s(R7e);QWr=r(Mra,"mobilebert"),Mra.forEach(t),WWr=r(IUe," \u2014 "),Yre=n(IUe,"A",{href:!0});var Era=s(Yre);UWr=r(Era,"TFMobileBertForNextSentencePrediction"),Era.forEach(t),HWr=r(IUe," (MobileBERT model)"),IUe.forEach(t),Coo.forEach(t),JWr=i(vi),T(Hw.$$.fragment,vi),vi.forEach(t),bi.forEach(t),iZe=i(m),bm=n(m,"H2",{class:!0});var woo=s(bm);Jw=n(woo,"A",{id:!0,class:!0,href:!0});var Cra=s(Jw);P7e=n(Cra,"SPAN",{});var wra=s(P7e);T(pS.$$.fragment,wra),wra.forEach(t),Cra.forEach(t),YWr=i(woo),B7e=n(woo,"SPAN",{});var Ara=s(B7e);KWr=r(Ara,"TFAutoModelForTableQuestionAnswering"),Ara.forEach(t),woo.forEach(t),dZe=i(m),pr=n(m,"DIV",{class:!0});var Fi=s(pr);T(_S.$$.fragment,Fi),ZWr=i(Fi),vm=n(Fi,"P",{});var gie=s(vm);eUr=r(gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kre=n(gie,"A",{href:!0});var Lra=s(Kre);oUr=r(Lra,"from_pretrained()"),Lra.forEach(t),rUr=r(gie," class method or the "),Zre=n(gie,"A",{href:!0});var yra=s(Zre);tUr=r(yra,"from_config()"),yra.forEach(t),aUr=r(gie,` class
method.`),gie.forEach(t),nUr=i(Fi),bS=n(Fi,"P",{});var Aoo=s(bS);sUr=r(Aoo,"This class cannot be instantiated directly using "),I7e=n(Aoo,"CODE",{});var xra=s(I7e);lUr=r(xra,"__init__()"),xra.forEach(t),iUr=r(Aoo," (throws an error)."),Aoo.forEach(t),dUr=i(Fi),ea=n(Fi,"DIV",{class:!0});var N8=s(ea);T(vS.$$.fragment,N8),cUr=i(N8),N7e=n(N8,"P",{});var $ra=s(N7e);mUr=r($ra,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$ra.forEach(t),fUr=i(N8),Fm=n(N8,"P",{});var hie=s(Fm);gUr=r(hie,`Note:
Loading a model from its configuration file does `),q7e=n(hie,"STRONG",{});var kra=s(q7e);hUr=r(kra,"not"),kra.forEach(t),uUr=r(hie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=n(hie,"A",{href:!0});var Sra=s(ete);pUr=r(Sra,"from_pretrained()"),Sra.forEach(t),_Ur=r(hie," to load the model weights."),hie.forEach(t),bUr=i(N8),T(Yw.$$.fragment,N8),N8.forEach(t),vUr=i(Fi),Qr=n(Fi,"DIV",{class:!0});var Ti=s(Qr);T(FS.$$.fragment,Ti),FUr=i(Ti),j7e=n(Ti,"P",{});var Rra=s(j7e);TUr=r(Rra,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Rra.forEach(t),MUr=i(Ti),Pn=n(Ti,"P",{});var q8=s(Pn);EUr=r(q8,"The model class to instantiate is selected based on the "),D7e=n(q8,"CODE",{});var Pra=s(D7e);CUr=r(Pra,"model_type"),Pra.forEach(t),wUr=r(q8,` property of the config object (either
passed as an argument or loaded from `),G7e=n(q8,"CODE",{});var Bra=s(G7e);AUr=r(Bra,"pretrained_model_name_or_path"),Bra.forEach(t),LUr=r(q8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(q8,"CODE",{});var Ira=s(O7e);yUr=r(Ira,"pretrained_model_name_or_path"),Ira.forEach(t),xUr=r(q8,":"),q8.forEach(t),$Ur=i(Ti),V7e=n(Ti,"UL",{});var Nra=s(V7e);Kw=n(Nra,"LI",{});var NUe=s(Kw);X7e=n(NUe,"STRONG",{});var qra=s(X7e);kUr=r(qra,"tapas"),qra.forEach(t),SUr=r(NUe," \u2014 "),ote=n(NUe,"A",{href:!0});var jra=s(ote);RUr=r(jra,"TFTapasForQuestionAnswering"),jra.forEach(t),PUr=r(NUe," (TAPAS model)"),NUe.forEach(t),Nra.forEach(t),BUr=i(Ti),T(Zw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),cZe=i(m),Tm=n(m,"H2",{class:!0});var Loo=s(Tm);eA=n(Loo,"A",{id:!0,class:!0,href:!0});var Dra=s(eA);z7e=n(Dra,"SPAN",{});var Gra=s(z7e);T(TS.$$.fragment,Gra),Gra.forEach(t),Dra.forEach(t),IUr=i(Loo),Q7e=n(Loo,"SPAN",{});var Ora=s(Q7e);NUr=r(Ora,"TFAutoModelForDocumentQuestionAnswering"),Ora.forEach(t),Loo.forEach(t),mZe=i(m),_r=n(m,"DIV",{class:!0});var Mi=s(_r);T(MS.$$.fragment,Mi),qUr=i(Mi),Mm=n(Mi,"P",{});var uie=s(Mm);jUr=r(uie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rte=n(uie,"A",{href:!0});var Vra=s(rte);DUr=r(Vra,"from_pretrained()"),Vra.forEach(t),GUr=r(uie," class method or the "),tte=n(uie,"A",{href:!0});var Xra=s(tte);OUr=r(Xra,"from_config()"),Xra.forEach(t),VUr=r(uie,` class
method.`),uie.forEach(t),XUr=i(Mi),ES=n(Mi,"P",{});var yoo=s(ES);zUr=r(yoo,"This class cannot be instantiated directly using "),W7e=n(yoo,"CODE",{});var zra=s(W7e);QUr=r(zra,"__init__()"),zra.forEach(t),WUr=r(yoo," (throws an error)."),yoo.forEach(t),UUr=i(Mi),oa=n(Mi,"DIV",{class:!0});var j8=s(oa);T(CS.$$.fragment,j8),HUr=i(j8),U7e=n(j8,"P",{});var Qra=s(U7e);JUr=r(Qra,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Qra.forEach(t),YUr=i(j8),Em=n(j8,"P",{});var pie=s(Em);KUr=r(pie,`Note:
Loading a model from its configuration file does `),H7e=n(pie,"STRONG",{});var Wra=s(H7e);ZUr=r(Wra,"not"),Wra.forEach(t),eHr=r(pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=n(pie,"A",{href:!0});var Ura=s(ate);oHr=r(Ura,"from_pretrained()"),Ura.forEach(t),rHr=r(pie," to load the model weights."),pie.forEach(t),tHr=i(j8),T(oA.$$.fragment,j8),j8.forEach(t),aHr=i(Mi),Wr=n(Mi,"DIV",{class:!0});var Ei=s(Wr);T(wS.$$.fragment,Ei),nHr=i(Ei),J7e=n(Ei,"P",{});var Hra=s(J7e);sHr=r(Hra,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Hra.forEach(t),lHr=i(Ei),Bn=n(Ei,"P",{});var D8=s(Bn);iHr=r(D8,"The model class to instantiate is selected based on the "),Y7e=n(D8,"CODE",{});var Jra=s(Y7e);dHr=r(Jra,"model_type"),Jra.forEach(t),cHr=r(D8,` property of the config object (either
passed as an argument or loaded from `),K7e=n(D8,"CODE",{});var Yra=s(K7e);mHr=r(Yra,"pretrained_model_name_or_path"),Yra.forEach(t),fHr=r(D8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z7e=n(D8,"CODE",{});var Kra=s(Z7e);gHr=r(Kra,"pretrained_model_name_or_path"),Kra.forEach(t),hHr=r(D8,":"),D8.forEach(t),uHr=i(Ei),eLe=n(Ei,"UL",{});var Zra=s(eLe);rA=n(Zra,"LI",{});var qUe=s(rA);oLe=n(qUe,"STRONG",{});var eta=s(oLe);pHr=r(eta,"layoutlm"),eta.forEach(t),_Hr=r(qUe," \u2014 "),nte=n(qUe,"A",{href:!0});var ota=s(nte);bHr=r(ota,"TFLayoutLMForQuestionAnswering"),ota.forEach(t),vHr=r(qUe," (LayoutLM model)"),qUe.forEach(t),Zra.forEach(t),FHr=i(Ei),T(tA.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),fZe=i(m),Cm=n(m,"H2",{class:!0});var xoo=s(Cm);aA=n(xoo,"A",{id:!0,class:!0,href:!0});var rta=s(aA);rLe=n(rta,"SPAN",{});var tta=s(rLe);T(AS.$$.fragment,tta),tta.forEach(t),rta.forEach(t),THr=i(xoo),tLe=n(xoo,"SPAN",{});var ata=s(tLe);MHr=r(ata,"TFAutoModelForTokenClassification"),ata.forEach(t),xoo.forEach(t),gZe=i(m),br=n(m,"DIV",{class:!0});var Ci=s(br);T(LS.$$.fragment,Ci),EHr=i(Ci),wm=n(Ci,"P",{});var _ie=s(wm);CHr=r(_ie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ste=n(_ie,"A",{href:!0});var nta=s(ste);wHr=r(nta,"from_pretrained()"),nta.forEach(t),AHr=r(_ie," class method or the "),lte=n(_ie,"A",{href:!0});var sta=s(lte);LHr=r(sta,"from_config()"),sta.forEach(t),yHr=r(_ie,` class
method.`),_ie.forEach(t),xHr=i(Ci),yS=n(Ci,"P",{});var $oo=s(yS);$Hr=r($oo,"This class cannot be instantiated directly using "),aLe=n($oo,"CODE",{});var lta=s(aLe);kHr=r(lta,"__init__()"),lta.forEach(t),SHr=r($oo," (throws an error)."),$oo.forEach(t),RHr=i(Ci),ra=n(Ci,"DIV",{class:!0});var G8=s(ra);T(xS.$$.fragment,G8),PHr=i(G8),nLe=n(G8,"P",{});var ita=s(nLe);BHr=r(ita,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ita.forEach(t),IHr=i(G8),Am=n(G8,"P",{});var bie=s(Am);NHr=r(bie,`Note:
Loading a model from its configuration file does `),sLe=n(bie,"STRONG",{});var dta=s(sLe);qHr=r(dta,"not"),dta.forEach(t),jHr=r(bie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=n(bie,"A",{href:!0});var cta=s(ite);DHr=r(cta,"from_pretrained()"),cta.forEach(t),GHr=r(bie," to load the model weights."),bie.forEach(t),OHr=i(G8),T(nA.$$.fragment,G8),G8.forEach(t),VHr=i(Ci),Ur=n(Ci,"DIV",{class:!0});var wi=s(Ur);T($S.$$.fragment,wi),XHr=i(wi),lLe=n(wi,"P",{});var mta=s(lLe);zHr=r(mta,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),mta.forEach(t),QHr=i(wi),In=n(wi,"P",{});var O8=s(In);WHr=r(O8,"The model class to instantiate is selected based on the "),iLe=n(O8,"CODE",{});var fta=s(iLe);UHr=r(fta,"model_type"),fta.forEach(t),HHr=r(O8,` property of the config object (either
passed as an argument or loaded from `),dLe=n(O8,"CODE",{});var gta=s(dLe);JHr=r(gta,"pretrained_model_name_or_path"),gta.forEach(t),YHr=r(O8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cLe=n(O8,"CODE",{});var hta=s(cLe);KHr=r(hta,"pretrained_model_name_or_path"),hta.forEach(t),ZHr=r(O8,":"),O8.forEach(t),eJr=i(wi),de=n(wi,"UL",{});var he=s(de);sA=n(he,"LI",{});var jUe=s(sA);mLe=n(jUe,"STRONG",{});var uta=s(mLe);oJr=r(uta,"albert"),uta.forEach(t),rJr=r(jUe," \u2014 "),dte=n(jUe,"A",{href:!0});var pta=s(dte);tJr=r(pta,"TFAlbertForTokenClassification"),pta.forEach(t),aJr=r(jUe," (ALBERT model)"),jUe.forEach(t),nJr=i(he),lA=n(he,"LI",{});var DUe=s(lA);fLe=n(DUe,"STRONG",{});var _ta=s(fLe);sJr=r(_ta,"bert"),_ta.forEach(t),lJr=r(DUe," \u2014 "),cte=n(DUe,"A",{href:!0});var bta=s(cte);iJr=r(bta,"TFBertForTokenClassification"),bta.forEach(t),dJr=r(DUe," (BERT model)"),DUe.forEach(t),cJr=i(he),iA=n(he,"LI",{});var GUe=s(iA);gLe=n(GUe,"STRONG",{});var vta=s(gLe);mJr=r(vta,"camembert"),vta.forEach(t),fJr=r(GUe," \u2014 "),mte=n(GUe,"A",{href:!0});var Fta=s(mte);gJr=r(Fta,"TFCamembertForTokenClassification"),Fta.forEach(t),hJr=r(GUe," (CamemBERT model)"),GUe.forEach(t),uJr=i(he),dA=n(he,"LI",{});var OUe=s(dA);hLe=n(OUe,"STRONG",{});var Tta=s(hLe);pJr=r(Tta,"convbert"),Tta.forEach(t),_Jr=r(OUe," \u2014 "),fte=n(OUe,"A",{href:!0});var Mta=s(fte);bJr=r(Mta,"TFConvBertForTokenClassification"),Mta.forEach(t),vJr=r(OUe," (ConvBERT model)"),OUe.forEach(t),FJr=i(he),cA=n(he,"LI",{});var VUe=s(cA);uLe=n(VUe,"STRONG",{});var Eta=s(uLe);TJr=r(Eta,"deberta"),Eta.forEach(t),MJr=r(VUe," \u2014 "),gte=n(VUe,"A",{href:!0});var Cta=s(gte);EJr=r(Cta,"TFDebertaForTokenClassification"),Cta.forEach(t),CJr=r(VUe," (DeBERTa model)"),VUe.forEach(t),wJr=i(he),mA=n(he,"LI",{});var XUe=s(mA);pLe=n(XUe,"STRONG",{});var wta=s(pLe);AJr=r(wta,"deberta-v2"),wta.forEach(t),LJr=r(XUe," \u2014 "),hte=n(XUe,"A",{href:!0});var Ata=s(hte);yJr=r(Ata,"TFDebertaV2ForTokenClassification"),Ata.forEach(t),xJr=r(XUe," (DeBERTa-v2 model)"),XUe.forEach(t),$Jr=i(he),fA=n(he,"LI",{});var zUe=s(fA);_Le=n(zUe,"STRONG",{});var Lta=s(_Le);kJr=r(Lta,"distilbert"),Lta.forEach(t),SJr=r(zUe," \u2014 "),ute=n(zUe,"A",{href:!0});var yta=s(ute);RJr=r(yta,"TFDistilBertForTokenClassification"),yta.forEach(t),PJr=r(zUe," (DistilBERT model)"),zUe.forEach(t),BJr=i(he),gA=n(he,"LI",{});var QUe=s(gA);bLe=n(QUe,"STRONG",{});var xta=s(bLe);IJr=r(xta,"electra"),xta.forEach(t),NJr=r(QUe," \u2014 "),pte=n(QUe,"A",{href:!0});var $ta=s(pte);qJr=r($ta,"TFElectraForTokenClassification"),$ta.forEach(t),jJr=r(QUe," (ELECTRA model)"),QUe.forEach(t),DJr=i(he),hA=n(he,"LI",{});var WUe=s(hA);vLe=n(WUe,"STRONG",{});var kta=s(vLe);GJr=r(kta,"flaubert"),kta.forEach(t),OJr=r(WUe," \u2014 "),_te=n(WUe,"A",{href:!0});var Sta=s(_te);VJr=r(Sta,"TFFlaubertForTokenClassification"),Sta.forEach(t),XJr=r(WUe," (FlauBERT model)"),WUe.forEach(t),zJr=i(he),uA=n(he,"LI",{});var UUe=s(uA);FLe=n(UUe,"STRONG",{});var Rta=s(FLe);QJr=r(Rta,"funnel"),Rta.forEach(t),WJr=r(UUe," \u2014 "),bte=n(UUe,"A",{href:!0});var Pta=s(bte);UJr=r(Pta,"TFFunnelForTokenClassification"),Pta.forEach(t),HJr=r(UUe," (Funnel Transformer model)"),UUe.forEach(t),JJr=i(he),pA=n(he,"LI",{});var HUe=s(pA);TLe=n(HUe,"STRONG",{});var Bta=s(TLe);YJr=r(Bta,"layoutlm"),Bta.forEach(t),KJr=r(HUe," \u2014 "),vte=n(HUe,"A",{href:!0});var Ita=s(vte);ZJr=r(Ita,"TFLayoutLMForTokenClassification"),Ita.forEach(t),eYr=r(HUe," (LayoutLM model)"),HUe.forEach(t),oYr=i(he),_A=n(he,"LI",{});var JUe=s(_A);MLe=n(JUe,"STRONG",{});var Nta=s(MLe);rYr=r(Nta,"layoutlmv3"),Nta.forEach(t),tYr=r(JUe," \u2014 "),Fte=n(JUe,"A",{href:!0});var qta=s(Fte);aYr=r(qta,"TFLayoutLMv3ForTokenClassification"),qta.forEach(t),nYr=r(JUe," (LayoutLMv3 model)"),JUe.forEach(t),sYr=i(he),bA=n(he,"LI",{});var YUe=s(bA);ELe=n(YUe,"STRONG",{});var jta=s(ELe);lYr=r(jta,"longformer"),jta.forEach(t),iYr=r(YUe," \u2014 "),Tte=n(YUe,"A",{href:!0});var Dta=s(Tte);dYr=r(Dta,"TFLongformerForTokenClassification"),Dta.forEach(t),cYr=r(YUe," (Longformer model)"),YUe.forEach(t),mYr=i(he),vA=n(he,"LI",{});var KUe=s(vA);CLe=n(KUe,"STRONG",{});var Gta=s(CLe);fYr=r(Gta,"mobilebert"),Gta.forEach(t),gYr=r(KUe," \u2014 "),Mte=n(KUe,"A",{href:!0});var Ota=s(Mte);hYr=r(Ota,"TFMobileBertForTokenClassification"),Ota.forEach(t),uYr=r(KUe," (MobileBERT model)"),KUe.forEach(t),pYr=i(he),FA=n(he,"LI",{});var ZUe=s(FA);wLe=n(ZUe,"STRONG",{});var Vta=s(wLe);_Yr=r(Vta,"mpnet"),Vta.forEach(t),bYr=r(ZUe," \u2014 "),Ete=n(ZUe,"A",{href:!0});var Xta=s(Ete);vYr=r(Xta,"TFMPNetForTokenClassification"),Xta.forEach(t),FYr=r(ZUe," (MPNet model)"),ZUe.forEach(t),TYr=i(he),TA=n(he,"LI",{});var eHe=s(TA);ALe=n(eHe,"STRONG",{});var zta=s(ALe);MYr=r(zta,"rembert"),zta.forEach(t),EYr=r(eHe," \u2014 "),Cte=n(eHe,"A",{href:!0});var Qta=s(Cte);CYr=r(Qta,"TFRemBertForTokenClassification"),Qta.forEach(t),wYr=r(eHe," (RemBERT model)"),eHe.forEach(t),AYr=i(he),MA=n(he,"LI",{});var oHe=s(MA);LLe=n(oHe,"STRONG",{});var Wta=s(LLe);LYr=r(Wta,"roberta"),Wta.forEach(t),yYr=r(oHe," \u2014 "),wte=n(oHe,"A",{href:!0});var Uta=s(wte);xYr=r(Uta,"TFRobertaForTokenClassification"),Uta.forEach(t),$Yr=r(oHe," (RoBERTa model)"),oHe.forEach(t),kYr=i(he),EA=n(he,"LI",{});var rHe=s(EA);yLe=n(rHe,"STRONG",{});var Hta=s(yLe);SYr=r(Hta,"roformer"),Hta.forEach(t),RYr=r(rHe," \u2014 "),Ate=n(rHe,"A",{href:!0});var Jta=s(Ate);PYr=r(Jta,"TFRoFormerForTokenClassification"),Jta.forEach(t),BYr=r(rHe," (RoFormer model)"),rHe.forEach(t),IYr=i(he),CA=n(he,"LI",{});var tHe=s(CA);xLe=n(tHe,"STRONG",{});var Yta=s(xLe);NYr=r(Yta,"xlm"),Yta.forEach(t),qYr=r(tHe," \u2014 "),Lte=n(tHe,"A",{href:!0});var Kta=s(Lte);jYr=r(Kta,"TFXLMForTokenClassification"),Kta.forEach(t),DYr=r(tHe," (XLM model)"),tHe.forEach(t),GYr=i(he),wA=n(he,"LI",{});var aHe=s(wA);$Le=n(aHe,"STRONG",{});var Zta=s($Le);OYr=r(Zta,"xlm-roberta"),Zta.forEach(t),VYr=r(aHe," \u2014 "),yte=n(aHe,"A",{href:!0});var eaa=s(yte);XYr=r(eaa,"TFXLMRobertaForTokenClassification"),eaa.forEach(t),zYr=r(aHe," (XLM-RoBERTa model)"),aHe.forEach(t),QYr=i(he),AA=n(he,"LI",{});var nHe=s(AA);kLe=n(nHe,"STRONG",{});var oaa=s(kLe);WYr=r(oaa,"xlnet"),oaa.forEach(t),UYr=r(nHe," \u2014 "),xte=n(nHe,"A",{href:!0});var raa=s(xte);HYr=r(raa,"TFXLNetForTokenClassification"),raa.forEach(t),JYr=r(nHe," (XLNet model)"),nHe.forEach(t),he.forEach(t),YYr=i(wi),T(LA.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),hZe=i(m),Lm=n(m,"H2",{class:!0});var koo=s(Lm);yA=n(koo,"A",{id:!0,class:!0,href:!0});var taa=s(yA);SLe=n(taa,"SPAN",{});var aaa=s(SLe);T(kS.$$.fragment,aaa),aaa.forEach(t),taa.forEach(t),KYr=i(koo),RLe=n(koo,"SPAN",{});var naa=s(RLe);ZYr=r(naa,"TFAutoModelForQuestionAnswering"),naa.forEach(t),koo.forEach(t),uZe=i(m),vr=n(m,"DIV",{class:!0});var Ai=s(vr);T(SS.$$.fragment,Ai),eKr=i(Ai),ym=n(Ai,"P",{});var vie=s(ym);oKr=r(vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$te=n(vie,"A",{href:!0});var saa=s($te);rKr=r(saa,"from_pretrained()"),saa.forEach(t),tKr=r(vie," class method or the "),kte=n(vie,"A",{href:!0});var laa=s(kte);aKr=r(laa,"from_config()"),laa.forEach(t),nKr=r(vie,` class
method.`),vie.forEach(t),sKr=i(Ai),RS=n(Ai,"P",{});var Soo=s(RS);lKr=r(Soo,"This class cannot be instantiated directly using "),PLe=n(Soo,"CODE",{});var iaa=s(PLe);iKr=r(iaa,"__init__()"),iaa.forEach(t),dKr=r(Soo," (throws an error)."),Soo.forEach(t),cKr=i(Ai),ta=n(Ai,"DIV",{class:!0});var V8=s(ta);T(PS.$$.fragment,V8),mKr=i(V8),BLe=n(V8,"P",{});var daa=s(BLe);fKr=r(daa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),daa.forEach(t),gKr=i(V8),xm=n(V8,"P",{});var Fie=s(xm);hKr=r(Fie,`Note:
Loading a model from its configuration file does `),ILe=n(Fie,"STRONG",{});var caa=s(ILe);uKr=r(caa,"not"),caa.forEach(t),pKr=r(Fie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ste=n(Fie,"A",{href:!0});var maa=s(Ste);_Kr=r(maa,"from_pretrained()"),maa.forEach(t),bKr=r(Fie," to load the model weights."),Fie.forEach(t),vKr=i(V8),T(xA.$$.fragment,V8),V8.forEach(t),FKr=i(Ai),Hr=n(Ai,"DIV",{class:!0});var Li=s(Hr);T(BS.$$.fragment,Li),TKr=i(Li),NLe=n(Li,"P",{});var faa=s(NLe);MKr=r(faa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),faa.forEach(t),EKr=i(Li),Nn=n(Li,"P",{});var X8=s(Nn);CKr=r(X8,"The model class to instantiate is selected based on the "),qLe=n(X8,"CODE",{});var gaa=s(qLe);wKr=r(gaa,"model_type"),gaa.forEach(t),AKr=r(X8,` property of the config object (either
passed as an argument or loaded from `),jLe=n(X8,"CODE",{});var haa=s(jLe);LKr=r(haa,"pretrained_model_name_or_path"),haa.forEach(t),yKr=r(X8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DLe=n(X8,"CODE",{});var uaa=s(DLe);xKr=r(uaa,"pretrained_model_name_or_path"),uaa.forEach(t),$Kr=r(X8,":"),X8.forEach(t),kKr=i(Li),ce=n(Li,"UL",{});var ue=s(ce);$A=n(ue,"LI",{});var sHe=s($A);GLe=n(sHe,"STRONG",{});var paa=s(GLe);SKr=r(paa,"albert"),paa.forEach(t),RKr=r(sHe," \u2014 "),Rte=n(sHe,"A",{href:!0});var _aa=s(Rte);PKr=r(_aa,"TFAlbertForQuestionAnswering"),_aa.forEach(t),BKr=r(sHe," (ALBERT model)"),sHe.forEach(t),IKr=i(ue),kA=n(ue,"LI",{});var lHe=s(kA);OLe=n(lHe,"STRONG",{});var baa=s(OLe);NKr=r(baa,"bert"),baa.forEach(t),qKr=r(lHe," \u2014 "),Pte=n(lHe,"A",{href:!0});var vaa=s(Pte);jKr=r(vaa,"TFBertForQuestionAnswering"),vaa.forEach(t),DKr=r(lHe," (BERT model)"),lHe.forEach(t),GKr=i(ue),SA=n(ue,"LI",{});var iHe=s(SA);VLe=n(iHe,"STRONG",{});var Faa=s(VLe);OKr=r(Faa,"camembert"),Faa.forEach(t),VKr=r(iHe," \u2014 "),Bte=n(iHe,"A",{href:!0});var Taa=s(Bte);XKr=r(Taa,"TFCamembertForQuestionAnswering"),Taa.forEach(t),zKr=r(iHe," (CamemBERT model)"),iHe.forEach(t),QKr=i(ue),RA=n(ue,"LI",{});var dHe=s(RA);XLe=n(dHe,"STRONG",{});var Maa=s(XLe);WKr=r(Maa,"convbert"),Maa.forEach(t),UKr=r(dHe," \u2014 "),Ite=n(dHe,"A",{href:!0});var Eaa=s(Ite);HKr=r(Eaa,"TFConvBertForQuestionAnswering"),Eaa.forEach(t),JKr=r(dHe," (ConvBERT model)"),dHe.forEach(t),YKr=i(ue),PA=n(ue,"LI",{});var cHe=s(PA);zLe=n(cHe,"STRONG",{});var Caa=s(zLe);KKr=r(Caa,"deberta"),Caa.forEach(t),ZKr=r(cHe," \u2014 "),Nte=n(cHe,"A",{href:!0});var waa=s(Nte);eZr=r(waa,"TFDebertaForQuestionAnswering"),waa.forEach(t),oZr=r(cHe," (DeBERTa model)"),cHe.forEach(t),rZr=i(ue),BA=n(ue,"LI",{});var mHe=s(BA);QLe=n(mHe,"STRONG",{});var Aaa=s(QLe);tZr=r(Aaa,"deberta-v2"),Aaa.forEach(t),aZr=r(mHe," \u2014 "),qte=n(mHe,"A",{href:!0});var Laa=s(qte);nZr=r(Laa,"TFDebertaV2ForQuestionAnswering"),Laa.forEach(t),sZr=r(mHe," (DeBERTa-v2 model)"),mHe.forEach(t),lZr=i(ue),IA=n(ue,"LI",{});var fHe=s(IA);WLe=n(fHe,"STRONG",{});var yaa=s(WLe);iZr=r(yaa,"distilbert"),yaa.forEach(t),dZr=r(fHe," \u2014 "),jte=n(fHe,"A",{href:!0});var xaa=s(jte);cZr=r(xaa,"TFDistilBertForQuestionAnswering"),xaa.forEach(t),mZr=r(fHe," (DistilBERT model)"),fHe.forEach(t),fZr=i(ue),NA=n(ue,"LI",{});var gHe=s(NA);ULe=n(gHe,"STRONG",{});var $aa=s(ULe);gZr=r($aa,"electra"),$aa.forEach(t),hZr=r(gHe," \u2014 "),Dte=n(gHe,"A",{href:!0});var kaa=s(Dte);uZr=r(kaa,"TFElectraForQuestionAnswering"),kaa.forEach(t),pZr=r(gHe," (ELECTRA model)"),gHe.forEach(t),_Zr=i(ue),qA=n(ue,"LI",{});var hHe=s(qA);HLe=n(hHe,"STRONG",{});var Saa=s(HLe);bZr=r(Saa,"flaubert"),Saa.forEach(t),vZr=r(hHe," \u2014 "),Gte=n(hHe,"A",{href:!0});var Raa=s(Gte);FZr=r(Raa,"TFFlaubertForQuestionAnsweringSimple"),Raa.forEach(t),TZr=r(hHe," (FlauBERT model)"),hHe.forEach(t),MZr=i(ue),jA=n(ue,"LI",{});var uHe=s(jA);JLe=n(uHe,"STRONG",{});var Paa=s(JLe);EZr=r(Paa,"funnel"),Paa.forEach(t),CZr=r(uHe," \u2014 "),Ote=n(uHe,"A",{href:!0});var Baa=s(Ote);wZr=r(Baa,"TFFunnelForQuestionAnswering"),Baa.forEach(t),AZr=r(uHe," (Funnel Transformer model)"),uHe.forEach(t),LZr=i(ue),DA=n(ue,"LI",{});var pHe=s(DA);YLe=n(pHe,"STRONG",{});var Iaa=s(YLe);yZr=r(Iaa,"gptj"),Iaa.forEach(t),xZr=r(pHe," \u2014 "),Vte=n(pHe,"A",{href:!0});var Naa=s(Vte);$Zr=r(Naa,"TFGPTJForQuestionAnswering"),Naa.forEach(t),kZr=r(pHe," (GPT-J model)"),pHe.forEach(t),SZr=i(ue),GA=n(ue,"LI",{});var _He=s(GA);KLe=n(_He,"STRONG",{});var qaa=s(KLe);RZr=r(qaa,"layoutlmv3"),qaa.forEach(t),PZr=r(_He," \u2014 "),Xte=n(_He,"A",{href:!0});var jaa=s(Xte);BZr=r(jaa,"TFLayoutLMv3ForQuestionAnswering"),jaa.forEach(t),IZr=r(_He," (LayoutLMv3 model)"),_He.forEach(t),NZr=i(ue),OA=n(ue,"LI",{});var bHe=s(OA);ZLe=n(bHe,"STRONG",{});var Daa=s(ZLe);qZr=r(Daa,"longformer"),Daa.forEach(t),jZr=r(bHe," \u2014 "),zte=n(bHe,"A",{href:!0});var Gaa=s(zte);DZr=r(Gaa,"TFLongformerForQuestionAnswering"),Gaa.forEach(t),GZr=r(bHe," (Longformer model)"),bHe.forEach(t),OZr=i(ue),VA=n(ue,"LI",{});var vHe=s(VA);eye=n(vHe,"STRONG",{});var Oaa=s(eye);VZr=r(Oaa,"mobilebert"),Oaa.forEach(t),XZr=r(vHe," \u2014 "),Qte=n(vHe,"A",{href:!0});var Vaa=s(Qte);zZr=r(Vaa,"TFMobileBertForQuestionAnswering"),Vaa.forEach(t),QZr=r(vHe," (MobileBERT model)"),vHe.forEach(t),WZr=i(ue),XA=n(ue,"LI",{});var FHe=s(XA);oye=n(FHe,"STRONG",{});var Xaa=s(oye);UZr=r(Xaa,"mpnet"),Xaa.forEach(t),HZr=r(FHe," \u2014 "),Wte=n(FHe,"A",{href:!0});var zaa=s(Wte);JZr=r(zaa,"TFMPNetForQuestionAnswering"),zaa.forEach(t),YZr=r(FHe," (MPNet model)"),FHe.forEach(t),KZr=i(ue),zA=n(ue,"LI",{});var THe=s(zA);rye=n(THe,"STRONG",{});var Qaa=s(rye);ZZr=r(Qaa,"rembert"),Qaa.forEach(t),eet=r(THe," \u2014 "),Ute=n(THe,"A",{href:!0});var Waa=s(Ute);oet=r(Waa,"TFRemBertForQuestionAnswering"),Waa.forEach(t),ret=r(THe," (RemBERT model)"),THe.forEach(t),tet=i(ue),QA=n(ue,"LI",{});var MHe=s(QA);tye=n(MHe,"STRONG",{});var Uaa=s(tye);aet=r(Uaa,"roberta"),Uaa.forEach(t),net=r(MHe," \u2014 "),Hte=n(MHe,"A",{href:!0});var Haa=s(Hte);set=r(Haa,"TFRobertaForQuestionAnswering"),Haa.forEach(t),iet=r(MHe," (RoBERTa model)"),MHe.forEach(t),det=i(ue),WA=n(ue,"LI",{});var EHe=s(WA);aye=n(EHe,"STRONG",{});var Jaa=s(aye);cet=r(Jaa,"roformer"),Jaa.forEach(t),met=r(EHe," \u2014 "),Jte=n(EHe,"A",{href:!0});var Yaa=s(Jte);fet=r(Yaa,"TFRoFormerForQuestionAnswering"),Yaa.forEach(t),get=r(EHe," (RoFormer model)"),EHe.forEach(t),het=i(ue),UA=n(ue,"LI",{});var CHe=s(UA);nye=n(CHe,"STRONG",{});var Kaa=s(nye);uet=r(Kaa,"xlm"),Kaa.forEach(t),pet=r(CHe," \u2014 "),Yte=n(CHe,"A",{href:!0});var Zaa=s(Yte);_et=r(Zaa,"TFXLMForQuestionAnsweringSimple"),Zaa.forEach(t),bet=r(CHe," (XLM model)"),CHe.forEach(t),vet=i(ue),HA=n(ue,"LI",{});var wHe=s(HA);sye=n(wHe,"STRONG",{});var ena=s(sye);Fet=r(ena,"xlm-roberta"),ena.forEach(t),Tet=r(wHe," \u2014 "),Kte=n(wHe,"A",{href:!0});var ona=s(Kte);Met=r(ona,"TFXLMRobertaForQuestionAnswering"),ona.forEach(t),Eet=r(wHe," (XLM-RoBERTa model)"),wHe.forEach(t),Cet=i(ue),JA=n(ue,"LI",{});var AHe=s(JA);lye=n(AHe,"STRONG",{});var rna=s(lye);wet=r(rna,"xlnet"),rna.forEach(t),Aet=r(AHe," \u2014 "),Zte=n(AHe,"A",{href:!0});var tna=s(Zte);Let=r(tna,"TFXLNetForQuestionAnsweringSimple"),tna.forEach(t),yet=r(AHe," (XLNet model)"),AHe.forEach(t),ue.forEach(t),xet=i(Li),T(YA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),pZe=i(m),$m=n(m,"H2",{class:!0});var Roo=s($m);KA=n(Roo,"A",{id:!0,class:!0,href:!0});var ana=s(KA);iye=n(ana,"SPAN",{});var nna=s(iye);T(IS.$$.fragment,nna),nna.forEach(t),ana.forEach(t),$et=i(Roo),dye=n(Roo,"SPAN",{});var sna=s(dye);ket=r(sna,"TFAutoModelForVision2Seq"),sna.forEach(t),Roo.forEach(t),_Ze=i(m),Fr=n(m,"DIV",{class:!0});var yi=s(Fr);T(NS.$$.fragment,yi),Set=i(yi),km=n(yi,"P",{});var Tie=s(km);Ret=r(Tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=n(Tie,"A",{href:!0});var lna=s(eae);Pet=r(lna,"from_pretrained()"),lna.forEach(t),Bet=r(Tie," class method or the "),oae=n(Tie,"A",{href:!0});var ina=s(oae);Iet=r(ina,"from_config()"),ina.forEach(t),Net=r(Tie,` class
method.`),Tie.forEach(t),qet=i(yi),qS=n(yi,"P",{});var Poo=s(qS);jet=r(Poo,"This class cannot be instantiated directly using "),cye=n(Poo,"CODE",{});var dna=s(cye);Det=r(dna,"__init__()"),dna.forEach(t),Get=r(Poo," (throws an error)."),Poo.forEach(t),Oet=i(yi),aa=n(yi,"DIV",{class:!0});var z8=s(aa);T(jS.$$.fragment,z8),Vet=i(z8),mye=n(z8,"P",{});var cna=s(mye);Xet=r(cna,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),cna.forEach(t),zet=i(z8),Sm=n(z8,"P",{});var Mie=s(Sm);Qet=r(Mie,`Note:
Loading a model from its configuration file does `),fye=n(Mie,"STRONG",{});var mna=s(fye);Wet=r(mna,"not"),mna.forEach(t),Uet=r(Mie,` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=n(Mie,"A",{href:!0});var fna=s(rae);Het=r(fna,"from_pretrained()"),fna.forEach(t),Jet=r(Mie," to load the model weights."),Mie.forEach(t),Yet=i(z8),T(ZA.$$.fragment,z8),z8.forEach(t),Ket=i(yi),Jr=n(yi,"DIV",{class:!0});var xi=s(Jr);T(DS.$$.fragment,xi),Zet=i(xi),gye=n(xi,"P",{});var gna=s(gye);eot=r(gna,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gna.forEach(t),oot=i(xi),qn=n(xi,"P",{});var Q8=s(qn);rot=r(Q8,"The model class to instantiate is selected based on the "),hye=n(Q8,"CODE",{});var hna=s(hye);tot=r(hna,"model_type"),hna.forEach(t),aot=r(Q8,` property of the config object (either
passed as an argument or loaded from `),uye=n(Q8,"CODE",{});var una=s(uye);not=r(una,"pretrained_model_name_or_path"),una.forEach(t),sot=r(Q8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pye=n(Q8,"CODE",{});var pna=s(pye);lot=r(pna,"pretrained_model_name_or_path"),pna.forEach(t),iot=r(Q8,":"),Q8.forEach(t),dot=i(xi),_ye=n(xi,"UL",{});var _na=s(_ye);e6=n(_na,"LI",{});var LHe=s(e6);bye=n(LHe,"STRONG",{});var bna=s(bye);cot=r(bna,"vision-encoder-decoder"),bna.forEach(t),mot=r(LHe," \u2014 "),tae=n(LHe,"A",{href:!0});var vna=s(tae);fot=r(vna,"TFVisionEncoderDecoderModel"),vna.forEach(t),got=r(LHe," (Vision Encoder decoder model)"),LHe.forEach(t),_na.forEach(t),hot=i(xi),T(o6.$$.fragment,xi),xi.forEach(t),yi.forEach(t),bZe=i(m),Rm=n(m,"H2",{class:!0});var Boo=s(Rm);r6=n(Boo,"A",{id:!0,class:!0,href:!0});var Fna=s(r6);vye=n(Fna,"SPAN",{});var Tna=s(vye);T(GS.$$.fragment,Tna),Tna.forEach(t),Fna.forEach(t),uot=i(Boo),Fye=n(Boo,"SPAN",{});var Mna=s(Fye);pot=r(Mna,"TFAutoModelForSpeechSeq2Seq"),Mna.forEach(t),Boo.forEach(t),vZe=i(m),Tr=n(m,"DIV",{class:!0});var $i=s(Tr);T(OS.$$.fragment,$i),_ot=i($i),Pm=n($i,"P",{});var Eie=s(Pm);bot=r(Eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),aae=n(Eie,"A",{href:!0});var Ena=s(aae);vot=r(Ena,"from_pretrained()"),Ena.forEach(t),Fot=r(Eie," class method or the "),nae=n(Eie,"A",{href:!0});var Cna=s(nae);Tot=r(Cna,"from_config()"),Cna.forEach(t),Mot=r(Eie,` class
method.`),Eie.forEach(t),Eot=i($i),VS=n($i,"P",{});var Ioo=s(VS);Cot=r(Ioo,"This class cannot be instantiated directly using "),Tye=n(Ioo,"CODE",{});var wna=s(Tye);wot=r(wna,"__init__()"),wna.forEach(t),Aot=r(Ioo," (throws an error)."),Ioo.forEach(t),Lot=i($i),na=n($i,"DIV",{class:!0});var W8=s(na);T(XS.$$.fragment,W8),yot=i(W8),Mye=n(W8,"P",{});var Ana=s(Mye);xot=r(Ana,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ana.forEach(t),$ot=i(W8),Bm=n(W8,"P",{});var Cie=s(Bm);kot=r(Cie,`Note:
Loading a model from its configuration file does `),Eye=n(Cie,"STRONG",{});var Lna=s(Eye);Sot=r(Lna,"not"),Lna.forEach(t),Rot=r(Cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=n(Cie,"A",{href:!0});var yna=s(sae);Pot=r(yna,"from_pretrained()"),yna.forEach(t),Bot=r(Cie," to load the model weights."),Cie.forEach(t),Iot=i(W8),T(t6.$$.fragment,W8),W8.forEach(t),Not=i($i),Yr=n($i,"DIV",{class:!0});var ki=s(Yr);T(zS.$$.fragment,ki),qot=i(ki),Cye=n(ki,"P",{});var xna=s(Cye);jot=r(xna,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),xna.forEach(t),Dot=i(ki),jn=n(ki,"P",{});var U8=s(jn);Got=r(U8,"The model class to instantiate is selected based on the "),wye=n(U8,"CODE",{});var $na=s(wye);Oot=r($na,"model_type"),$na.forEach(t),Vot=r(U8,` property of the config object (either
passed as an argument or loaded from `),Aye=n(U8,"CODE",{});var kna=s(Aye);Xot=r(kna,"pretrained_model_name_or_path"),kna.forEach(t),zot=r(U8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lye=n(U8,"CODE",{});var Sna=s(Lye);Qot=r(Sna,"pretrained_model_name_or_path"),Sna.forEach(t),Wot=r(U8,":"),U8.forEach(t),Uot=i(ki),yye=n(ki,"UL",{});var Rna=s(yye);a6=n(Rna,"LI",{});var yHe=s(a6);xye=n(yHe,"STRONG",{});var Pna=s(xye);Hot=r(Pna,"speech_to_text"),Pna.forEach(t),Jot=r(yHe," \u2014 "),lae=n(yHe,"A",{href:!0});var Bna=s(lae);Yot=r(Bna,"TFSpeech2TextForConditionalGeneration"),Bna.forEach(t),Kot=r(yHe," (Speech2Text model)"),yHe.forEach(t),Rna.forEach(t),Zot=i(ki),T(n6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),FZe=i(m),Im=n(m,"H2",{class:!0});var Noo=s(Im);s6=n(Noo,"A",{id:!0,class:!0,href:!0});var Ina=s(s6);$ye=n(Ina,"SPAN",{});var Nna=s($ye);T(QS.$$.fragment,Nna),Nna.forEach(t),Ina.forEach(t),ert=i(Noo),kye=n(Noo,"SPAN",{});var qna=s(kye);ort=r(qna,"FlaxAutoModel"),qna.forEach(t),Noo.forEach(t),TZe=i(m),Mr=n(m,"DIV",{class:!0});var Si=s(Mr);T(WS.$$.fragment,Si),rrt=i(Si),Nm=n(Si,"P",{});var wie=s(Nm);trt=r(wie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),iae=n(wie,"A",{href:!0});var jna=s(iae);art=r(jna,"from_pretrained()"),jna.forEach(t),nrt=r(wie," class method or the "),dae=n(wie,"A",{href:!0});var Dna=s(dae);srt=r(Dna,"from_config()"),Dna.forEach(t),lrt=r(wie,` class
method.`),wie.forEach(t),irt=i(Si),US=n(Si,"P",{});var qoo=s(US);drt=r(qoo,"This class cannot be instantiated directly using "),Sye=n(qoo,"CODE",{});var Gna=s(Sye);crt=r(Gna,"__init__()"),Gna.forEach(t),mrt=r(qoo," (throws an error)."),qoo.forEach(t),frt=i(Si),sa=n(Si,"DIV",{class:!0});var H8=s(sa);T(HS.$$.fragment,H8),grt=i(H8),Rye=n(H8,"P",{});var Ona=s(Rye);hrt=r(Ona,"Instantiates one of the base model classes of the library from a configuration."),Ona.forEach(t),urt=i(H8),qm=n(H8,"P",{});var Aie=s(qm);prt=r(Aie,`Note:
Loading a model from its configuration file does `),Pye=n(Aie,"STRONG",{});var Vna=s(Pye);_rt=r(Vna,"not"),Vna.forEach(t),brt=r(Aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=n(Aie,"A",{href:!0});var Xna=s(cae);vrt=r(Xna,"from_pretrained()"),Xna.forEach(t),Frt=r(Aie," to load the model weights."),Aie.forEach(t),Trt=i(H8),T(l6.$$.fragment,H8),H8.forEach(t),Mrt=i(Si),Kr=n(Si,"DIV",{class:!0});var Ri=s(Kr);T(JS.$$.fragment,Ri),Ert=i(Ri),Bye=n(Ri,"P",{});var zna=s(Bye);Crt=r(zna,"Instantiate one of the base model classes of the library from a pretrained model."),zna.forEach(t),wrt=i(Ri),Dn=n(Ri,"P",{});var J8=s(Dn);Art=r(J8,"The model class to instantiate is selected based on the "),Iye=n(J8,"CODE",{});var Qna=s(Iye);Lrt=r(Qna,"model_type"),Qna.forEach(t),yrt=r(J8,` property of the config object (either
passed as an argument or loaded from `),Nye=n(J8,"CODE",{});var Wna=s(Nye);xrt=r(Wna,"pretrained_model_name_or_path"),Wna.forEach(t),$rt=r(J8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=n(J8,"CODE",{});var Una=s(qye);krt=r(Una,"pretrained_model_name_or_path"),Una.forEach(t),Srt=r(J8,":"),J8.forEach(t),Rrt=i(Ri),te=n(Ri,"UL",{});var ne=s(te);i6=n(ne,"LI",{});var xHe=s(i6);jye=n(xHe,"STRONG",{});var Hna=s(jye);Prt=r(Hna,"albert"),Hna.forEach(t),Brt=r(xHe," \u2014 "),mae=n(xHe,"A",{href:!0});var Jna=s(mae);Irt=r(Jna,"FlaxAlbertModel"),Jna.forEach(t),Nrt=r(xHe," (ALBERT model)"),xHe.forEach(t),qrt=i(ne),d6=n(ne,"LI",{});var $He=s(d6);Dye=n($He,"STRONG",{});var Yna=s(Dye);jrt=r(Yna,"bart"),Yna.forEach(t),Drt=r($He," \u2014 "),fae=n($He,"A",{href:!0});var Kna=s(fae);Grt=r(Kna,"FlaxBartModel"),Kna.forEach(t),Ort=r($He," (BART model)"),$He.forEach(t),Vrt=i(ne),c6=n(ne,"LI",{});var kHe=s(c6);Gye=n(kHe,"STRONG",{});var Zna=s(Gye);Xrt=r(Zna,"beit"),Zna.forEach(t),zrt=r(kHe," \u2014 "),gae=n(kHe,"A",{href:!0});var esa=s(gae);Qrt=r(esa,"FlaxBeitModel"),esa.forEach(t),Wrt=r(kHe," (BEiT model)"),kHe.forEach(t),Urt=i(ne),m6=n(ne,"LI",{});var SHe=s(m6);Oye=n(SHe,"STRONG",{});var osa=s(Oye);Hrt=r(osa,"bert"),osa.forEach(t),Jrt=r(SHe," \u2014 "),hae=n(SHe,"A",{href:!0});var rsa=s(hae);Yrt=r(rsa,"FlaxBertModel"),rsa.forEach(t),Krt=r(SHe," (BERT model)"),SHe.forEach(t),Zrt=i(ne),f6=n(ne,"LI",{});var RHe=s(f6);Vye=n(RHe,"STRONG",{});var tsa=s(Vye);ett=r(tsa,"big_bird"),tsa.forEach(t),ott=r(RHe," \u2014 "),uae=n(RHe,"A",{href:!0});var asa=s(uae);rtt=r(asa,"FlaxBigBirdModel"),asa.forEach(t),ttt=r(RHe," (BigBird model)"),RHe.forEach(t),att=i(ne),g6=n(ne,"LI",{});var PHe=s(g6);Xye=n(PHe,"STRONG",{});var nsa=s(Xye);ntt=r(nsa,"blenderbot"),nsa.forEach(t),stt=r(PHe," \u2014 "),pae=n(PHe,"A",{href:!0});var ssa=s(pae);ltt=r(ssa,"FlaxBlenderbotModel"),ssa.forEach(t),itt=r(PHe," (Blenderbot model)"),PHe.forEach(t),dtt=i(ne),h6=n(ne,"LI",{});var BHe=s(h6);zye=n(BHe,"STRONG",{});var lsa=s(zye);ctt=r(lsa,"blenderbot-small"),lsa.forEach(t),mtt=r(BHe," \u2014 "),_ae=n(BHe,"A",{href:!0});var isa=s(_ae);ftt=r(isa,"FlaxBlenderbotSmallModel"),isa.forEach(t),gtt=r(BHe," (BlenderbotSmall model)"),BHe.forEach(t),htt=i(ne),u6=n(ne,"LI",{});var IHe=s(u6);Qye=n(IHe,"STRONG",{});var dsa=s(Qye);utt=r(dsa,"clip"),dsa.forEach(t),ptt=r(IHe," \u2014 "),bae=n(IHe,"A",{href:!0});var csa=s(bae);_tt=r(csa,"FlaxCLIPModel"),csa.forEach(t),btt=r(IHe," (CLIP model)"),IHe.forEach(t),vtt=i(ne),p6=n(ne,"LI",{});var NHe=s(p6);Wye=n(NHe,"STRONG",{});var msa=s(Wye);Ftt=r(msa,"distilbert"),msa.forEach(t),Ttt=r(NHe," \u2014 "),vae=n(NHe,"A",{href:!0});var fsa=s(vae);Mtt=r(fsa,"FlaxDistilBertModel"),fsa.forEach(t),Ett=r(NHe," (DistilBERT model)"),NHe.forEach(t),Ctt=i(ne),_6=n(ne,"LI",{});var qHe=s(_6);Uye=n(qHe,"STRONG",{});var gsa=s(Uye);wtt=r(gsa,"electra"),gsa.forEach(t),Att=r(qHe," \u2014 "),Fae=n(qHe,"A",{href:!0});var hsa=s(Fae);Ltt=r(hsa,"FlaxElectraModel"),hsa.forEach(t),ytt=r(qHe," (ELECTRA model)"),qHe.forEach(t),xtt=i(ne),b6=n(ne,"LI",{});var jHe=s(b6);Hye=n(jHe,"STRONG",{});var usa=s(Hye);$tt=r(usa,"gpt2"),usa.forEach(t),ktt=r(jHe," \u2014 "),Tae=n(jHe,"A",{href:!0});var psa=s(Tae);Stt=r(psa,"FlaxGPT2Model"),psa.forEach(t),Rtt=r(jHe," (OpenAI GPT-2 model)"),jHe.forEach(t),Ptt=i(ne),v6=n(ne,"LI",{});var DHe=s(v6);Jye=n(DHe,"STRONG",{});var _sa=s(Jye);Btt=r(_sa,"gpt_neo"),_sa.forEach(t),Itt=r(DHe," \u2014 "),Mae=n(DHe,"A",{href:!0});var bsa=s(Mae);Ntt=r(bsa,"FlaxGPTNeoModel"),bsa.forEach(t),qtt=r(DHe," (GPT Neo model)"),DHe.forEach(t),jtt=i(ne),F6=n(ne,"LI",{});var GHe=s(F6);Yye=n(GHe,"STRONG",{});var vsa=s(Yye);Dtt=r(vsa,"gptj"),vsa.forEach(t),Gtt=r(GHe," \u2014 "),Eae=n(GHe,"A",{href:!0});var Fsa=s(Eae);Ott=r(Fsa,"FlaxGPTJModel"),Fsa.forEach(t),Vtt=r(GHe," (GPT-J model)"),GHe.forEach(t),Xtt=i(ne),T6=n(ne,"LI",{});var OHe=s(T6);Kye=n(OHe,"STRONG",{});var Tsa=s(Kye);ztt=r(Tsa,"longt5"),Tsa.forEach(t),Qtt=r(OHe," \u2014 "),Cae=n(OHe,"A",{href:!0});var Msa=s(Cae);Wtt=r(Msa,"FlaxLongT5Model"),Msa.forEach(t),Utt=r(OHe," (LongT5 model)"),OHe.forEach(t),Htt=i(ne),M6=n(ne,"LI",{});var VHe=s(M6);Zye=n(VHe,"STRONG",{});var Esa=s(Zye);Jtt=r(Esa,"marian"),Esa.forEach(t),Ytt=r(VHe," \u2014 "),wae=n(VHe,"A",{href:!0});var Csa=s(wae);Ktt=r(Csa,"FlaxMarianModel"),Csa.forEach(t),Ztt=r(VHe," (Marian model)"),VHe.forEach(t),eat=i(ne),E6=n(ne,"LI",{});var XHe=s(E6);e8e=n(XHe,"STRONG",{});var wsa=s(e8e);oat=r(wsa,"mbart"),wsa.forEach(t),rat=r(XHe," \u2014 "),Aae=n(XHe,"A",{href:!0});var Asa=s(Aae);tat=r(Asa,"FlaxMBartModel"),Asa.forEach(t),aat=r(XHe," (mBART model)"),XHe.forEach(t),nat=i(ne),C6=n(ne,"LI",{});var zHe=s(C6);o8e=n(zHe,"STRONG",{});var Lsa=s(o8e);sat=r(Lsa,"mt5"),Lsa.forEach(t),lat=r(zHe," \u2014 "),Lae=n(zHe,"A",{href:!0});var ysa=s(Lae);iat=r(ysa,"FlaxMT5Model"),ysa.forEach(t),dat=r(zHe," (MT5 model)"),zHe.forEach(t),cat=i(ne),w6=n(ne,"LI",{});var QHe=s(w6);r8e=n(QHe,"STRONG",{});var xsa=s(r8e);mat=r(xsa,"opt"),xsa.forEach(t),fat=r(QHe," \u2014 "),yae=n(QHe,"A",{href:!0});var $sa=s(yae);gat=r($sa,"FlaxOPTModel"),$sa.forEach(t),hat=r(QHe," (OPT model)"),QHe.forEach(t),uat=i(ne),A6=n(ne,"LI",{});var WHe=s(A6);t8e=n(WHe,"STRONG",{});var ksa=s(t8e);pat=r(ksa,"pegasus"),ksa.forEach(t),_at=r(WHe," \u2014 "),xae=n(WHe,"A",{href:!0});var Ssa=s(xae);bat=r(Ssa,"FlaxPegasusModel"),Ssa.forEach(t),vat=r(WHe," (Pegasus model)"),WHe.forEach(t),Fat=i(ne),L6=n(ne,"LI",{});var UHe=s(L6);a8e=n(UHe,"STRONG",{});var Rsa=s(a8e);Tat=r(Rsa,"roberta"),Rsa.forEach(t),Mat=r(UHe," \u2014 "),$ae=n(UHe,"A",{href:!0});var Psa=s($ae);Eat=r(Psa,"FlaxRobertaModel"),Psa.forEach(t),Cat=r(UHe," (RoBERTa model)"),UHe.forEach(t),wat=i(ne),y6=n(ne,"LI",{});var HHe=s(y6);n8e=n(HHe,"STRONG",{});var Bsa=s(n8e);Aat=r(Bsa,"roformer"),Bsa.forEach(t),Lat=r(HHe," \u2014 "),kae=n(HHe,"A",{href:!0});var Isa=s(kae);yat=r(Isa,"FlaxRoFormerModel"),Isa.forEach(t),xat=r(HHe," (RoFormer model)"),HHe.forEach(t),$at=i(ne),x6=n(ne,"LI",{});var JHe=s(x6);s8e=n(JHe,"STRONG",{});var Nsa=s(s8e);kat=r(Nsa,"t5"),Nsa.forEach(t),Sat=r(JHe," \u2014 "),Sae=n(JHe,"A",{href:!0});var qsa=s(Sae);Rat=r(qsa,"FlaxT5Model"),qsa.forEach(t),Pat=r(JHe," (T5 model)"),JHe.forEach(t),Bat=i(ne),$6=n(ne,"LI",{});var YHe=s($6);l8e=n(YHe,"STRONG",{});var jsa=s(l8e);Iat=r(jsa,"vision-text-dual-encoder"),jsa.forEach(t),Nat=r(YHe," \u2014 "),Rae=n(YHe,"A",{href:!0});var Dsa=s(Rae);qat=r(Dsa,"FlaxVisionTextDualEncoderModel"),Dsa.forEach(t),jat=r(YHe," (VisionTextDualEncoder model)"),YHe.forEach(t),Dat=i(ne),k6=n(ne,"LI",{});var KHe=s(k6);i8e=n(KHe,"STRONG",{});var Gsa=s(i8e);Gat=r(Gsa,"vit"),Gsa.forEach(t),Oat=r(KHe," \u2014 "),Pae=n(KHe,"A",{href:!0});var Osa=s(Pae);Vat=r(Osa,"FlaxViTModel"),Osa.forEach(t),Xat=r(KHe," (ViT model)"),KHe.forEach(t),zat=i(ne),S6=n(ne,"LI",{});var ZHe=s(S6);d8e=n(ZHe,"STRONG",{});var Vsa=s(d8e);Qat=r(Vsa,"wav2vec2"),Vsa.forEach(t),Wat=r(ZHe," \u2014 "),Bae=n(ZHe,"A",{href:!0});var Xsa=s(Bae);Uat=r(Xsa,"FlaxWav2Vec2Model"),Xsa.forEach(t),Hat=r(ZHe," (Wav2Vec2 model)"),ZHe.forEach(t),Jat=i(ne),R6=n(ne,"LI",{});var eJe=s(R6);c8e=n(eJe,"STRONG",{});var zsa=s(c8e);Yat=r(zsa,"xglm"),zsa.forEach(t),Kat=r(eJe," \u2014 "),Iae=n(eJe,"A",{href:!0});var Qsa=s(Iae);Zat=r(Qsa,"FlaxXGLMModel"),Qsa.forEach(t),ent=r(eJe," (XGLM model)"),eJe.forEach(t),ont=i(ne),P6=n(ne,"LI",{});var oJe=s(P6);m8e=n(oJe,"STRONG",{});var Wsa=s(m8e);rnt=r(Wsa,"xlm-roberta"),Wsa.forEach(t),tnt=r(oJe," \u2014 "),Nae=n(oJe,"A",{href:!0});var Usa=s(Nae);ant=r(Usa,"FlaxXLMRobertaModel"),Usa.forEach(t),nnt=r(oJe," (XLM-RoBERTa model)"),oJe.forEach(t),ne.forEach(t),snt=i(Ri),T(B6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),MZe=i(m),jm=n(m,"H2",{class:!0});var joo=s(jm);I6=n(joo,"A",{id:!0,class:!0,href:!0});var Hsa=s(I6);f8e=n(Hsa,"SPAN",{});var Jsa=s(f8e);T(YS.$$.fragment,Jsa),Jsa.forEach(t),Hsa.forEach(t),lnt=i(joo),g8e=n(joo,"SPAN",{});var Ysa=s(g8e);int=r(Ysa,"FlaxAutoModelForCausalLM"),Ysa.forEach(t),joo.forEach(t),EZe=i(m),Er=n(m,"DIV",{class:!0});var Pi=s(Er);T(KS.$$.fragment,Pi),dnt=i(Pi),Dm=n(Pi,"P",{});var Lie=s(Dm);cnt=r(Lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qae=n(Lie,"A",{href:!0});var Ksa=s(qae);mnt=r(Ksa,"from_pretrained()"),Ksa.forEach(t),fnt=r(Lie," class method or the "),jae=n(Lie,"A",{href:!0});var Zsa=s(jae);gnt=r(Zsa,"from_config()"),Zsa.forEach(t),hnt=r(Lie,` class
method.`),Lie.forEach(t),unt=i(Pi),ZS=n(Pi,"P",{});var Doo=s(ZS);pnt=r(Doo,"This class cannot be instantiated directly using "),h8e=n(Doo,"CODE",{});var ela=s(h8e);_nt=r(ela,"__init__()"),ela.forEach(t),bnt=r(Doo," (throws an error)."),Doo.forEach(t),vnt=i(Pi),la=n(Pi,"DIV",{class:!0});var Y8=s(la);T(eR.$$.fragment,Y8),Fnt=i(Y8),u8e=n(Y8,"P",{});var ola=s(u8e);Tnt=r(ola,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ola.forEach(t),Mnt=i(Y8),Gm=n(Y8,"P",{});var yie=s(Gm);Ent=r(yie,`Note:
Loading a model from its configuration file does `),p8e=n(yie,"STRONG",{});var rla=s(p8e);Cnt=r(rla,"not"),rla.forEach(t),wnt=r(yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=n(yie,"A",{href:!0});var tla=s(Dae);Ant=r(tla,"from_pretrained()"),tla.forEach(t),Lnt=r(yie," to load the model weights."),yie.forEach(t),ynt=i(Y8),T(N6.$$.fragment,Y8),Y8.forEach(t),xnt=i(Pi),Zr=n(Pi,"DIV",{class:!0});var Bi=s(Zr);T(oR.$$.fragment,Bi),$nt=i(Bi),_8e=n(Bi,"P",{});var ala=s(_8e);knt=r(ala,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ala.forEach(t),Snt=i(Bi),Gn=n(Bi,"P",{});var K8=s(Gn);Rnt=r(K8,"The model class to instantiate is selected based on the "),b8e=n(K8,"CODE",{});var nla=s(b8e);Pnt=r(nla,"model_type"),nla.forEach(t),Bnt=r(K8,` property of the config object (either
passed as an argument or loaded from `),v8e=n(K8,"CODE",{});var sla=s(v8e);Int=r(sla,"pretrained_model_name_or_path"),sla.forEach(t),Nnt=r(K8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=n(K8,"CODE",{});var lla=s(F8e);qnt=r(lla,"pretrained_model_name_or_path"),lla.forEach(t),jnt=r(K8,":"),K8.forEach(t),Dnt=i(Bi),xe=n(Bi,"UL",{});var qe=s(xe);q6=n(qe,"LI",{});var rJe=s(q6);T8e=n(rJe,"STRONG",{});var ila=s(T8e);Gnt=r(ila,"bart"),ila.forEach(t),Ont=r(rJe," \u2014 "),Gae=n(rJe,"A",{href:!0});var dla=s(Gae);Vnt=r(dla,"FlaxBartForCausalLM"),dla.forEach(t),Xnt=r(rJe," (BART model)"),rJe.forEach(t),znt=i(qe),j6=n(qe,"LI",{});var tJe=s(j6);M8e=n(tJe,"STRONG",{});var cla=s(M8e);Qnt=r(cla,"bert"),cla.forEach(t),Wnt=r(tJe," \u2014 "),Oae=n(tJe,"A",{href:!0});var mla=s(Oae);Unt=r(mla,"FlaxBertForCausalLM"),mla.forEach(t),Hnt=r(tJe," (BERT model)"),tJe.forEach(t),Jnt=i(qe),D6=n(qe,"LI",{});var aJe=s(D6);E8e=n(aJe,"STRONG",{});var fla=s(E8e);Ynt=r(fla,"big_bird"),fla.forEach(t),Knt=r(aJe," \u2014 "),Vae=n(aJe,"A",{href:!0});var gla=s(Vae);Znt=r(gla,"FlaxBigBirdForCausalLM"),gla.forEach(t),est=r(aJe," (BigBird model)"),aJe.forEach(t),ost=i(qe),G6=n(qe,"LI",{});var nJe=s(G6);C8e=n(nJe,"STRONG",{});var hla=s(C8e);rst=r(hla,"electra"),hla.forEach(t),tst=r(nJe," \u2014 "),Xae=n(nJe,"A",{href:!0});var ula=s(Xae);ast=r(ula,"FlaxElectraForCausalLM"),ula.forEach(t),nst=r(nJe," (ELECTRA model)"),nJe.forEach(t),sst=i(qe),O6=n(qe,"LI",{});var sJe=s(O6);w8e=n(sJe,"STRONG",{});var pla=s(w8e);lst=r(pla,"gpt2"),pla.forEach(t),ist=r(sJe," \u2014 "),zae=n(sJe,"A",{href:!0});var _la=s(zae);dst=r(_la,"FlaxGPT2LMHeadModel"),_la.forEach(t),cst=r(sJe," (OpenAI GPT-2 model)"),sJe.forEach(t),mst=i(qe),V6=n(qe,"LI",{});var lJe=s(V6);A8e=n(lJe,"STRONG",{});var bla=s(A8e);fst=r(bla,"gpt_neo"),bla.forEach(t),gst=r(lJe," \u2014 "),Qae=n(lJe,"A",{href:!0});var vla=s(Qae);hst=r(vla,"FlaxGPTNeoForCausalLM"),vla.forEach(t),ust=r(lJe," (GPT Neo model)"),lJe.forEach(t),pst=i(qe),X6=n(qe,"LI",{});var iJe=s(X6);L8e=n(iJe,"STRONG",{});var Fla=s(L8e);_st=r(Fla,"gptj"),Fla.forEach(t),bst=r(iJe," \u2014 "),Wae=n(iJe,"A",{href:!0});var Tla=s(Wae);vst=r(Tla,"FlaxGPTJForCausalLM"),Tla.forEach(t),Fst=r(iJe," (GPT-J model)"),iJe.forEach(t),Tst=i(qe),z6=n(qe,"LI",{});var dJe=s(z6);y8e=n(dJe,"STRONG",{});var Mla=s(y8e);Mst=r(Mla,"opt"),Mla.forEach(t),Est=r(dJe," \u2014 "),Uae=n(dJe,"A",{href:!0});var Ela=s(Uae);Cst=r(Ela,"FlaxOPTForCausalLM"),Ela.forEach(t),wst=r(dJe," (OPT model)"),dJe.forEach(t),Ast=i(qe),Q6=n(qe,"LI",{});var cJe=s(Q6);x8e=n(cJe,"STRONG",{});var Cla=s(x8e);Lst=r(Cla,"roberta"),Cla.forEach(t),yst=r(cJe," \u2014 "),Hae=n(cJe,"A",{href:!0});var wla=s(Hae);xst=r(wla,"FlaxRobertaForCausalLM"),wla.forEach(t),$st=r(cJe," (RoBERTa model)"),cJe.forEach(t),kst=i(qe),W6=n(qe,"LI",{});var mJe=s(W6);$8e=n(mJe,"STRONG",{});var Ala=s($8e);Sst=r(Ala,"xglm"),Ala.forEach(t),Rst=r(mJe," \u2014 "),Jae=n(mJe,"A",{href:!0});var Lla=s(Jae);Pst=r(Lla,"FlaxXGLMForCausalLM"),Lla.forEach(t),Bst=r(mJe," (XGLM model)"),mJe.forEach(t),qe.forEach(t),Ist=i(Bi),T(U6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),CZe=i(m),Om=n(m,"H2",{class:!0});var Goo=s(Om);H6=n(Goo,"A",{id:!0,class:!0,href:!0});var yla=s(H6);k8e=n(yla,"SPAN",{});var xla=s(k8e);T(rR.$$.fragment,xla),xla.forEach(t),yla.forEach(t),Nst=i(Goo),S8e=n(Goo,"SPAN",{});var $la=s(S8e);qst=r($la,"FlaxAutoModelForPreTraining"),$la.forEach(t),Goo.forEach(t),wZe=i(m),Cr=n(m,"DIV",{class:!0});var Ii=s(Cr);T(tR.$$.fragment,Ii),jst=i(Ii),Vm=n(Ii,"P",{});var xie=s(Vm);Dst=r(xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yae=n(xie,"A",{href:!0});var kla=s(Yae);Gst=r(kla,"from_pretrained()"),kla.forEach(t),Ost=r(xie," class method or the "),Kae=n(xie,"A",{href:!0});var Sla=s(Kae);Vst=r(Sla,"from_config()"),Sla.forEach(t),Xst=r(xie,` class
method.`),xie.forEach(t),zst=i(Ii),aR=n(Ii,"P",{});var Ooo=s(aR);Qst=r(Ooo,"This class cannot be instantiated directly using "),R8e=n(Ooo,"CODE",{});var Rla=s(R8e);Wst=r(Rla,"__init__()"),Rla.forEach(t),Ust=r(Ooo," (throws an error)."),Ooo.forEach(t),Hst=i(Ii),ia=n(Ii,"DIV",{class:!0});var Z8=s(ia);T(nR.$$.fragment,Z8),Jst=i(Z8),P8e=n(Z8,"P",{});var Pla=s(P8e);Yst=r(Pla,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Pla.forEach(t),Kst=i(Z8),Xm=n(Z8,"P",{});var $ie=s(Xm);Zst=r($ie,`Note:
Loading a model from its configuration file does `),B8e=n($ie,"STRONG",{});var Bla=s(B8e);elt=r(Bla,"not"),Bla.forEach(t),olt=r($ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=n($ie,"A",{href:!0});var Ila=s(Zae);rlt=r(Ila,"from_pretrained()"),Ila.forEach(t),tlt=r($ie," to load the model weights."),$ie.forEach(t),alt=i(Z8),T(J6.$$.fragment,Z8),Z8.forEach(t),nlt=i(Ii),et=n(Ii,"DIV",{class:!0});var Ni=s(et);T(sR.$$.fragment,Ni),slt=i(Ni),I8e=n(Ni,"P",{});var Nla=s(I8e);llt=r(Nla,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Nla.forEach(t),ilt=i(Ni),On=n(Ni,"P",{});var e9=s(On);dlt=r(e9,"The model class to instantiate is selected based on the "),N8e=n(e9,"CODE",{});var qla=s(N8e);clt=r(qla,"model_type"),qla.forEach(t),mlt=r(e9,` property of the config object (either
passed as an argument or loaded from `),q8e=n(e9,"CODE",{});var jla=s(q8e);flt=r(jla,"pretrained_model_name_or_path"),jla.forEach(t),glt=r(e9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=n(e9,"CODE",{});var Dla=s(j8e);hlt=r(Dla,"pretrained_model_name_or_path"),Dla.forEach(t),ult=r(e9,":"),e9.forEach(t),plt=i(Ni),Ee=n(Ni,"UL",{});var we=s(Ee);Y6=n(we,"LI",{});var fJe=s(Y6);D8e=n(fJe,"STRONG",{});var Gla=s(D8e);_lt=r(Gla,"albert"),Gla.forEach(t),blt=r(fJe," \u2014 "),ene=n(fJe,"A",{href:!0});var Ola=s(ene);vlt=r(Ola,"FlaxAlbertForPreTraining"),Ola.forEach(t),Flt=r(fJe," (ALBERT model)"),fJe.forEach(t),Tlt=i(we),K6=n(we,"LI",{});var gJe=s(K6);G8e=n(gJe,"STRONG",{});var Vla=s(G8e);Mlt=r(Vla,"bart"),Vla.forEach(t),Elt=r(gJe," \u2014 "),one=n(gJe,"A",{href:!0});var Xla=s(one);Clt=r(Xla,"FlaxBartForConditionalGeneration"),Xla.forEach(t),wlt=r(gJe," (BART model)"),gJe.forEach(t),Alt=i(we),Z6=n(we,"LI",{});var hJe=s(Z6);O8e=n(hJe,"STRONG",{});var zla=s(O8e);Llt=r(zla,"bert"),zla.forEach(t),ylt=r(hJe," \u2014 "),rne=n(hJe,"A",{href:!0});var Qla=s(rne);xlt=r(Qla,"FlaxBertForPreTraining"),Qla.forEach(t),$lt=r(hJe," (BERT model)"),hJe.forEach(t),klt=i(we),e7=n(we,"LI",{});var uJe=s(e7);V8e=n(uJe,"STRONG",{});var Wla=s(V8e);Slt=r(Wla,"big_bird"),Wla.forEach(t),Rlt=r(uJe," \u2014 "),tne=n(uJe,"A",{href:!0});var Ula=s(tne);Plt=r(Ula,"FlaxBigBirdForPreTraining"),Ula.forEach(t),Blt=r(uJe," (BigBird model)"),uJe.forEach(t),Ilt=i(we),o7=n(we,"LI",{});var pJe=s(o7);X8e=n(pJe,"STRONG",{});var Hla=s(X8e);Nlt=r(Hla,"electra"),Hla.forEach(t),qlt=r(pJe," \u2014 "),ane=n(pJe,"A",{href:!0});var Jla=s(ane);jlt=r(Jla,"FlaxElectraForPreTraining"),Jla.forEach(t),Dlt=r(pJe," (ELECTRA model)"),pJe.forEach(t),Glt=i(we),r7=n(we,"LI",{});var _Je=s(r7);z8e=n(_Je,"STRONG",{});var Yla=s(z8e);Olt=r(Yla,"longt5"),Yla.forEach(t),Vlt=r(_Je," \u2014 "),nne=n(_Je,"A",{href:!0});var Kla=s(nne);Xlt=r(Kla,"FlaxLongT5ForConditionalGeneration"),Kla.forEach(t),zlt=r(_Je," (LongT5 model)"),_Je.forEach(t),Qlt=i(we),t7=n(we,"LI",{});var bJe=s(t7);Q8e=n(bJe,"STRONG",{});var Zla=s(Q8e);Wlt=r(Zla,"mbart"),Zla.forEach(t),Ult=r(bJe," \u2014 "),sne=n(bJe,"A",{href:!0});var eia=s(sne);Hlt=r(eia,"FlaxMBartForConditionalGeneration"),eia.forEach(t),Jlt=r(bJe," (mBART model)"),bJe.forEach(t),Ylt=i(we),a7=n(we,"LI",{});var vJe=s(a7);W8e=n(vJe,"STRONG",{});var oia=s(W8e);Klt=r(oia,"mt5"),oia.forEach(t),Zlt=r(vJe," \u2014 "),lne=n(vJe,"A",{href:!0});var ria=s(lne);eit=r(ria,"FlaxMT5ForConditionalGeneration"),ria.forEach(t),oit=r(vJe," (MT5 model)"),vJe.forEach(t),rit=i(we),n7=n(we,"LI",{});var FJe=s(n7);U8e=n(FJe,"STRONG",{});var tia=s(U8e);tit=r(tia,"roberta"),tia.forEach(t),ait=r(FJe," \u2014 "),ine=n(FJe,"A",{href:!0});var aia=s(ine);nit=r(aia,"FlaxRobertaForMaskedLM"),aia.forEach(t),sit=r(FJe," (RoBERTa model)"),FJe.forEach(t),lit=i(we),s7=n(we,"LI",{});var TJe=s(s7);H8e=n(TJe,"STRONG",{});var nia=s(H8e);iit=r(nia,"roformer"),nia.forEach(t),dit=r(TJe," \u2014 "),dne=n(TJe,"A",{href:!0});var sia=s(dne);cit=r(sia,"FlaxRoFormerForMaskedLM"),sia.forEach(t),mit=r(TJe," (RoFormer model)"),TJe.forEach(t),fit=i(we),l7=n(we,"LI",{});var MJe=s(l7);J8e=n(MJe,"STRONG",{});var lia=s(J8e);git=r(lia,"t5"),lia.forEach(t),hit=r(MJe," \u2014 "),cne=n(MJe,"A",{href:!0});var iia=s(cne);uit=r(iia,"FlaxT5ForConditionalGeneration"),iia.forEach(t),pit=r(MJe," (T5 model)"),MJe.forEach(t),_it=i(we),i7=n(we,"LI",{});var EJe=s(i7);Y8e=n(EJe,"STRONG",{});var dia=s(Y8e);bit=r(dia,"wav2vec2"),dia.forEach(t),vit=r(EJe," \u2014 "),mne=n(EJe,"A",{href:!0});var cia=s(mne);Fit=r(cia,"FlaxWav2Vec2ForPreTraining"),cia.forEach(t),Tit=r(EJe," (Wav2Vec2 model)"),EJe.forEach(t),Mit=i(we),d7=n(we,"LI",{});var CJe=s(d7);K8e=n(CJe,"STRONG",{});var mia=s(K8e);Eit=r(mia,"xlm-roberta"),mia.forEach(t),Cit=r(CJe," \u2014 "),fne=n(CJe,"A",{href:!0});var fia=s(fne);wit=r(fia,"FlaxXLMRobertaForMaskedLM"),fia.forEach(t),Ait=r(CJe," (XLM-RoBERTa model)"),CJe.forEach(t),we.forEach(t),Lit=i(Ni),T(c7.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),AZe=i(m),zm=n(m,"H2",{class:!0});var Voo=s(zm);m7=n(Voo,"A",{id:!0,class:!0,href:!0});var gia=s(m7);Z8e=n(gia,"SPAN",{});var hia=s(Z8e);T(lR.$$.fragment,hia),hia.forEach(t),gia.forEach(t),yit=i(Voo),e9e=n(Voo,"SPAN",{});var uia=s(e9e);xit=r(uia,"FlaxAutoModelForMaskedLM"),uia.forEach(t),Voo.forEach(t),LZe=i(m),wr=n(m,"DIV",{class:!0});var qi=s(wr);T(iR.$$.fragment,qi),$it=i(qi),Qm=n(qi,"P",{});var kie=s(Qm);kit=r(kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gne=n(kie,"A",{href:!0});var pia=s(gne);Sit=r(pia,"from_pretrained()"),pia.forEach(t),Rit=r(kie," class method or the "),hne=n(kie,"A",{href:!0});var _ia=s(hne);Pit=r(_ia,"from_config()"),_ia.forEach(t),Bit=r(kie,` class
method.`),kie.forEach(t),Iit=i(qi),dR=n(qi,"P",{});var Xoo=s(dR);Nit=r(Xoo,"This class cannot be instantiated directly using "),o9e=n(Xoo,"CODE",{});var bia=s(o9e);qit=r(bia,"__init__()"),bia.forEach(t),jit=r(Xoo," (throws an error)."),Xoo.forEach(t),Dit=i(qi),da=n(qi,"DIV",{class:!0});var o9=s(da);T(cR.$$.fragment,o9),Git=i(o9),r9e=n(o9,"P",{});var via=s(r9e);Oit=r(via,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),via.forEach(t),Vit=i(o9),Wm=n(o9,"P",{});var Sie=s(Wm);Xit=r(Sie,`Note:
Loading a model from its configuration file does `),t9e=n(Sie,"STRONG",{});var Fia=s(t9e);zit=r(Fia,"not"),Fia.forEach(t),Qit=r(Sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),une=n(Sie,"A",{href:!0});var Tia=s(une);Wit=r(Tia,"from_pretrained()"),Tia.forEach(t),Uit=r(Sie," to load the model weights."),Sie.forEach(t),Hit=i(o9),T(f7.$$.fragment,o9),o9.forEach(t),Jit=i(qi),ot=n(qi,"DIV",{class:!0});var ji=s(ot);T(mR.$$.fragment,ji),Yit=i(ji),a9e=n(ji,"P",{});var Mia=s(a9e);Kit=r(Mia,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Mia.forEach(t),Zit=i(ji),Vn=n(ji,"P",{});var r9=s(Vn);edt=r(r9,"The model class to instantiate is selected based on the "),n9e=n(r9,"CODE",{});var Eia=s(n9e);odt=r(Eia,"model_type"),Eia.forEach(t),rdt=r(r9,` property of the config object (either
passed as an argument or loaded from `),s9e=n(r9,"CODE",{});var Cia=s(s9e);tdt=r(Cia,"pretrained_model_name_or_path"),Cia.forEach(t),adt=r(r9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=n(r9,"CODE",{});var wia=s(l9e);ndt=r(wia,"pretrained_model_name_or_path"),wia.forEach(t),sdt=r(r9,":"),r9.forEach(t),ldt=i(ji),$e=n(ji,"UL",{});var je=s($e);g7=n(je,"LI",{});var wJe=s(g7);i9e=n(wJe,"STRONG",{});var Aia=s(i9e);idt=r(Aia,"albert"),Aia.forEach(t),ddt=r(wJe," \u2014 "),pne=n(wJe,"A",{href:!0});var Lia=s(pne);cdt=r(Lia,"FlaxAlbertForMaskedLM"),Lia.forEach(t),mdt=r(wJe," (ALBERT model)"),wJe.forEach(t),fdt=i(je),h7=n(je,"LI",{});var AJe=s(h7);d9e=n(AJe,"STRONG",{});var yia=s(d9e);gdt=r(yia,"bart"),yia.forEach(t),hdt=r(AJe," \u2014 "),_ne=n(AJe,"A",{href:!0});var xia=s(_ne);udt=r(xia,"FlaxBartForConditionalGeneration"),xia.forEach(t),pdt=r(AJe," (BART model)"),AJe.forEach(t),_dt=i(je),u7=n(je,"LI",{});var LJe=s(u7);c9e=n(LJe,"STRONG",{});var $ia=s(c9e);bdt=r($ia,"bert"),$ia.forEach(t),vdt=r(LJe," \u2014 "),bne=n(LJe,"A",{href:!0});var kia=s(bne);Fdt=r(kia,"FlaxBertForMaskedLM"),kia.forEach(t),Tdt=r(LJe," (BERT model)"),LJe.forEach(t),Mdt=i(je),p7=n(je,"LI",{});var yJe=s(p7);m9e=n(yJe,"STRONG",{});var Sia=s(m9e);Edt=r(Sia,"big_bird"),Sia.forEach(t),Cdt=r(yJe," \u2014 "),vne=n(yJe,"A",{href:!0});var Ria=s(vne);wdt=r(Ria,"FlaxBigBirdForMaskedLM"),Ria.forEach(t),Adt=r(yJe," (BigBird model)"),yJe.forEach(t),Ldt=i(je),_7=n(je,"LI",{});var xJe=s(_7);f9e=n(xJe,"STRONG",{});var Pia=s(f9e);ydt=r(Pia,"distilbert"),Pia.forEach(t),xdt=r(xJe," \u2014 "),Fne=n(xJe,"A",{href:!0});var Bia=s(Fne);$dt=r(Bia,"FlaxDistilBertForMaskedLM"),Bia.forEach(t),kdt=r(xJe," (DistilBERT model)"),xJe.forEach(t),Sdt=i(je),b7=n(je,"LI",{});var $Je=s(b7);g9e=n($Je,"STRONG",{});var Iia=s(g9e);Rdt=r(Iia,"electra"),Iia.forEach(t),Pdt=r($Je," \u2014 "),Tne=n($Je,"A",{href:!0});var Nia=s(Tne);Bdt=r(Nia,"FlaxElectraForMaskedLM"),Nia.forEach(t),Idt=r($Je," (ELECTRA model)"),$Je.forEach(t),Ndt=i(je),v7=n(je,"LI",{});var kJe=s(v7);h9e=n(kJe,"STRONG",{});var qia=s(h9e);qdt=r(qia,"mbart"),qia.forEach(t),jdt=r(kJe," \u2014 "),Mne=n(kJe,"A",{href:!0});var jia=s(Mne);Ddt=r(jia,"FlaxMBartForConditionalGeneration"),jia.forEach(t),Gdt=r(kJe," (mBART model)"),kJe.forEach(t),Odt=i(je),F7=n(je,"LI",{});var SJe=s(F7);u9e=n(SJe,"STRONG",{});var Dia=s(u9e);Vdt=r(Dia,"roberta"),Dia.forEach(t),Xdt=r(SJe," \u2014 "),Ene=n(SJe,"A",{href:!0});var Gia=s(Ene);zdt=r(Gia,"FlaxRobertaForMaskedLM"),Gia.forEach(t),Qdt=r(SJe," (RoBERTa model)"),SJe.forEach(t),Wdt=i(je),T7=n(je,"LI",{});var RJe=s(T7);p9e=n(RJe,"STRONG",{});var Oia=s(p9e);Udt=r(Oia,"roformer"),Oia.forEach(t),Hdt=r(RJe," \u2014 "),Cne=n(RJe,"A",{href:!0});var Via=s(Cne);Jdt=r(Via,"FlaxRoFormerForMaskedLM"),Via.forEach(t),Ydt=r(RJe," (RoFormer model)"),RJe.forEach(t),Kdt=i(je),M7=n(je,"LI",{});var PJe=s(M7);_9e=n(PJe,"STRONG",{});var Xia=s(_9e);Zdt=r(Xia,"xlm-roberta"),Xia.forEach(t),ect=r(PJe," \u2014 "),wne=n(PJe,"A",{href:!0});var zia=s(wne);oct=r(zia,"FlaxXLMRobertaForMaskedLM"),zia.forEach(t),rct=r(PJe," (XLM-RoBERTa model)"),PJe.forEach(t),je.forEach(t),tct=i(ji),T(E7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),yZe=i(m),Um=n(m,"H2",{class:!0});var zoo=s(Um);C7=n(zoo,"A",{id:!0,class:!0,href:!0});var Qia=s(C7);b9e=n(Qia,"SPAN",{});var Wia=s(b9e);T(fR.$$.fragment,Wia),Wia.forEach(t),Qia.forEach(t),act=i(zoo),v9e=n(zoo,"SPAN",{});var Uia=s(v9e);nct=r(Uia,"FlaxAutoModelForSeq2SeqLM"),Uia.forEach(t),zoo.forEach(t),xZe=i(m),Ar=n(m,"DIV",{class:!0});var Di=s(Ar);T(gR.$$.fragment,Di),sct=i(Di),Hm=n(Di,"P",{});var Rie=s(Hm);lct=r(Rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ane=n(Rie,"A",{href:!0});var Hia=s(Ane);ict=r(Hia,"from_pretrained()"),Hia.forEach(t),dct=r(Rie," class method or the "),Lne=n(Rie,"A",{href:!0});var Jia=s(Lne);cct=r(Jia,"from_config()"),Jia.forEach(t),mct=r(Rie,` class
method.`),Rie.forEach(t),fct=i(Di),hR=n(Di,"P",{});var Qoo=s(hR);gct=r(Qoo,"This class cannot be instantiated directly using "),F9e=n(Qoo,"CODE",{});var Yia=s(F9e);hct=r(Yia,"__init__()"),Yia.forEach(t),uct=r(Qoo," (throws an error)."),Qoo.forEach(t),pct=i(Di),ca=n(Di,"DIV",{class:!0});var t9=s(ca);T(uR.$$.fragment,t9),_ct=i(t9),T9e=n(t9,"P",{});var Kia=s(T9e);bct=r(Kia,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Kia.forEach(t),vct=i(t9),Jm=n(t9,"P",{});var Pie=s(Jm);Fct=r(Pie,`Note:
Loading a model from its configuration file does `),M9e=n(Pie,"STRONG",{});var Zia=s(M9e);Tct=r(Zia,"not"),Zia.forEach(t),Mct=r(Pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=n(Pie,"A",{href:!0});var eda=s(yne);Ect=r(eda,"from_pretrained()"),eda.forEach(t),Cct=r(Pie," to load the model weights."),Pie.forEach(t),wct=i(t9),T(w7.$$.fragment,t9),t9.forEach(t),Act=i(Di),rt=n(Di,"DIV",{class:!0});var Gi=s(rt);T(pR.$$.fragment,Gi),Lct=i(Gi),E9e=n(Gi,"P",{});var oda=s(E9e);yct=r(oda,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oda.forEach(t),xct=i(Gi),Xn=n(Gi,"P",{});var a9=s(Xn);$ct=r(a9,"The model class to instantiate is selected based on the "),C9e=n(a9,"CODE",{});var rda=s(C9e);kct=r(rda,"model_type"),rda.forEach(t),Sct=r(a9,` property of the config object (either
passed as an argument or loaded from `),w9e=n(a9,"CODE",{});var tda=s(w9e);Rct=r(tda,"pretrained_model_name_or_path"),tda.forEach(t),Pct=r(a9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A9e=n(a9,"CODE",{});var ada=s(A9e);Bct=r(ada,"pretrained_model_name_or_path"),ada.forEach(t),Ict=r(a9,":"),a9.forEach(t),Nct=i(Gi),ke=n(Gi,"UL",{});var De=s(ke);A7=n(De,"LI",{});var BJe=s(A7);L9e=n(BJe,"STRONG",{});var nda=s(L9e);qct=r(nda,"bart"),nda.forEach(t),jct=r(BJe," \u2014 "),xne=n(BJe,"A",{href:!0});var sda=s(xne);Dct=r(sda,"FlaxBartForConditionalGeneration"),sda.forEach(t),Gct=r(BJe," (BART model)"),BJe.forEach(t),Oct=i(De),L7=n(De,"LI",{});var IJe=s(L7);y9e=n(IJe,"STRONG",{});var lda=s(y9e);Vct=r(lda,"blenderbot"),lda.forEach(t),Xct=r(IJe," \u2014 "),$ne=n(IJe,"A",{href:!0});var ida=s($ne);zct=r(ida,"FlaxBlenderbotForConditionalGeneration"),ida.forEach(t),Qct=r(IJe," (Blenderbot model)"),IJe.forEach(t),Wct=i(De),y7=n(De,"LI",{});var NJe=s(y7);x9e=n(NJe,"STRONG",{});var dda=s(x9e);Uct=r(dda,"blenderbot-small"),dda.forEach(t),Hct=r(NJe," \u2014 "),kne=n(NJe,"A",{href:!0});var cda=s(kne);Jct=r(cda,"FlaxBlenderbotSmallForConditionalGeneration"),cda.forEach(t),Yct=r(NJe," (BlenderbotSmall model)"),NJe.forEach(t),Kct=i(De),x7=n(De,"LI",{});var qJe=s(x7);$9e=n(qJe,"STRONG",{});var mda=s($9e);Zct=r(mda,"encoder-decoder"),mda.forEach(t),emt=r(qJe," \u2014 "),Sne=n(qJe,"A",{href:!0});var fda=s(Sne);omt=r(fda,"FlaxEncoderDecoderModel"),fda.forEach(t),rmt=r(qJe," (Encoder decoder model)"),qJe.forEach(t),tmt=i(De),$7=n(De,"LI",{});var jJe=s($7);k9e=n(jJe,"STRONG",{});var gda=s(k9e);amt=r(gda,"longt5"),gda.forEach(t),nmt=r(jJe," \u2014 "),Rne=n(jJe,"A",{href:!0});var hda=s(Rne);smt=r(hda,"FlaxLongT5ForConditionalGeneration"),hda.forEach(t),lmt=r(jJe," (LongT5 model)"),jJe.forEach(t),imt=i(De),k7=n(De,"LI",{});var DJe=s(k7);S9e=n(DJe,"STRONG",{});var uda=s(S9e);dmt=r(uda,"marian"),uda.forEach(t),cmt=r(DJe," \u2014 "),Pne=n(DJe,"A",{href:!0});var pda=s(Pne);mmt=r(pda,"FlaxMarianMTModel"),pda.forEach(t),fmt=r(DJe," (Marian model)"),DJe.forEach(t),gmt=i(De),S7=n(De,"LI",{});var GJe=s(S7);R9e=n(GJe,"STRONG",{});var _da=s(R9e);hmt=r(_da,"mbart"),_da.forEach(t),umt=r(GJe," \u2014 "),Bne=n(GJe,"A",{href:!0});var bda=s(Bne);pmt=r(bda,"FlaxMBartForConditionalGeneration"),bda.forEach(t),_mt=r(GJe," (mBART model)"),GJe.forEach(t),bmt=i(De),R7=n(De,"LI",{});var OJe=s(R7);P9e=n(OJe,"STRONG",{});var vda=s(P9e);vmt=r(vda,"mt5"),vda.forEach(t),Fmt=r(OJe," \u2014 "),Ine=n(OJe,"A",{href:!0});var Fda=s(Ine);Tmt=r(Fda,"FlaxMT5ForConditionalGeneration"),Fda.forEach(t),Mmt=r(OJe," (MT5 model)"),OJe.forEach(t),Emt=i(De),P7=n(De,"LI",{});var VJe=s(P7);B9e=n(VJe,"STRONG",{});var Tda=s(B9e);Cmt=r(Tda,"pegasus"),Tda.forEach(t),wmt=r(VJe," \u2014 "),Nne=n(VJe,"A",{href:!0});var Mda=s(Nne);Amt=r(Mda,"FlaxPegasusForConditionalGeneration"),Mda.forEach(t),Lmt=r(VJe," (Pegasus model)"),VJe.forEach(t),ymt=i(De),B7=n(De,"LI",{});var XJe=s(B7);I9e=n(XJe,"STRONG",{});var Eda=s(I9e);xmt=r(Eda,"t5"),Eda.forEach(t),$mt=r(XJe," \u2014 "),qne=n(XJe,"A",{href:!0});var Cda=s(qne);kmt=r(Cda,"FlaxT5ForConditionalGeneration"),Cda.forEach(t),Smt=r(XJe," (T5 model)"),XJe.forEach(t),De.forEach(t),Rmt=i(Gi),T(I7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),$Ze=i(m),Ym=n(m,"H2",{class:!0});var Woo=s(Ym);N7=n(Woo,"A",{id:!0,class:!0,href:!0});var wda=s(N7);N9e=n(wda,"SPAN",{});var Ada=s(N9e);T(_R.$$.fragment,Ada),Ada.forEach(t),wda.forEach(t),Pmt=i(Woo),q9e=n(Woo,"SPAN",{});var Lda=s(q9e);Bmt=r(Lda,"FlaxAutoModelForSequenceClassification"),Lda.forEach(t),Woo.forEach(t),kZe=i(m),Lr=n(m,"DIV",{class:!0});var Oi=s(Lr);T(bR.$$.fragment,Oi),Imt=i(Oi),Km=n(Oi,"P",{});var Bie=s(Km);Nmt=r(Bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),jne=n(Bie,"A",{href:!0});var yda=s(jne);qmt=r(yda,"from_pretrained()"),yda.forEach(t),jmt=r(Bie," class method or the "),Dne=n(Bie,"A",{href:!0});var xda=s(Dne);Dmt=r(xda,"from_config()"),xda.forEach(t),Gmt=r(Bie,` class
method.`),Bie.forEach(t),Omt=i(Oi),vR=n(Oi,"P",{});var Uoo=s(vR);Vmt=r(Uoo,"This class cannot be instantiated directly using "),j9e=n(Uoo,"CODE",{});var $da=s(j9e);Xmt=r($da,"__init__()"),$da.forEach(t),zmt=r(Uoo," (throws an error)."),Uoo.forEach(t),Qmt=i(Oi),ma=n(Oi,"DIV",{class:!0});var n9=s(ma);T(FR.$$.fragment,n9),Wmt=i(n9),D9e=n(n9,"P",{});var kda=s(D9e);Umt=r(kda,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),kda.forEach(t),Hmt=i(n9),Zm=n(n9,"P",{});var Iie=s(Zm);Jmt=r(Iie,`Note:
Loading a model from its configuration file does `),G9e=n(Iie,"STRONG",{});var Sda=s(G9e);Ymt=r(Sda,"not"),Sda.forEach(t),Kmt=r(Iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=n(Iie,"A",{href:!0});var Rda=s(Gne);Zmt=r(Rda,"from_pretrained()"),Rda.forEach(t),eft=r(Iie," to load the model weights."),Iie.forEach(t),oft=i(n9),T(q7.$$.fragment,n9),n9.forEach(t),rft=i(Oi),tt=n(Oi,"DIV",{class:!0});var Vi=s(tt);T(TR.$$.fragment,Vi),tft=i(Vi),O9e=n(Vi,"P",{});var Pda=s(O9e);aft=r(Pda,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Pda.forEach(t),nft=i(Vi),zn=n(Vi,"P",{});var s9=s(zn);sft=r(s9,"The model class to instantiate is selected based on the "),V9e=n(s9,"CODE",{});var Bda=s(V9e);lft=r(Bda,"model_type"),Bda.forEach(t),ift=r(s9,` property of the config object (either
passed as an argument or loaded from `),X9e=n(s9,"CODE",{});var Ida=s(X9e);dft=r(Ida,"pretrained_model_name_or_path"),Ida.forEach(t),cft=r(s9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=n(s9,"CODE",{});var Nda=s(z9e);mft=r(Nda,"pretrained_model_name_or_path"),Nda.forEach(t),fft=r(s9,":"),s9.forEach(t),gft=i(Vi),Se=n(Vi,"UL",{});var Ge=s(Se);j7=n(Ge,"LI",{});var zJe=s(j7);Q9e=n(zJe,"STRONG",{});var qda=s(Q9e);hft=r(qda,"albert"),qda.forEach(t),uft=r(zJe," \u2014 "),One=n(zJe,"A",{href:!0});var jda=s(One);pft=r(jda,"FlaxAlbertForSequenceClassification"),jda.forEach(t),_ft=r(zJe," (ALBERT model)"),zJe.forEach(t),bft=i(Ge),D7=n(Ge,"LI",{});var QJe=s(D7);W9e=n(QJe,"STRONG",{});var Dda=s(W9e);vft=r(Dda,"bart"),Dda.forEach(t),Fft=r(QJe," \u2014 "),Vne=n(QJe,"A",{href:!0});var Gda=s(Vne);Tft=r(Gda,"FlaxBartForSequenceClassification"),Gda.forEach(t),Mft=r(QJe," (BART model)"),QJe.forEach(t),Eft=i(Ge),G7=n(Ge,"LI",{});var WJe=s(G7);U9e=n(WJe,"STRONG",{});var Oda=s(U9e);Cft=r(Oda,"bert"),Oda.forEach(t),wft=r(WJe," \u2014 "),Xne=n(WJe,"A",{href:!0});var Vda=s(Xne);Aft=r(Vda,"FlaxBertForSequenceClassification"),Vda.forEach(t),Lft=r(WJe," (BERT model)"),WJe.forEach(t),yft=i(Ge),O7=n(Ge,"LI",{});var UJe=s(O7);H9e=n(UJe,"STRONG",{});var Xda=s(H9e);xft=r(Xda,"big_bird"),Xda.forEach(t),$ft=r(UJe," \u2014 "),zne=n(UJe,"A",{href:!0});var zda=s(zne);kft=r(zda,"FlaxBigBirdForSequenceClassification"),zda.forEach(t),Sft=r(UJe," (BigBird model)"),UJe.forEach(t),Rft=i(Ge),V7=n(Ge,"LI",{});var HJe=s(V7);J9e=n(HJe,"STRONG",{});var Qda=s(J9e);Pft=r(Qda,"distilbert"),Qda.forEach(t),Bft=r(HJe," \u2014 "),Qne=n(HJe,"A",{href:!0});var Wda=s(Qne);Ift=r(Wda,"FlaxDistilBertForSequenceClassification"),Wda.forEach(t),Nft=r(HJe," (DistilBERT model)"),HJe.forEach(t),qft=i(Ge),X7=n(Ge,"LI",{});var JJe=s(X7);Y9e=n(JJe,"STRONG",{});var Uda=s(Y9e);jft=r(Uda,"electra"),Uda.forEach(t),Dft=r(JJe," \u2014 "),Wne=n(JJe,"A",{href:!0});var Hda=s(Wne);Gft=r(Hda,"FlaxElectraForSequenceClassification"),Hda.forEach(t),Oft=r(JJe," (ELECTRA model)"),JJe.forEach(t),Vft=i(Ge),z7=n(Ge,"LI",{});var YJe=s(z7);K9e=n(YJe,"STRONG",{});var Jda=s(K9e);Xft=r(Jda,"mbart"),Jda.forEach(t),zft=r(YJe," \u2014 "),Une=n(YJe,"A",{href:!0});var Yda=s(Une);Qft=r(Yda,"FlaxMBartForSequenceClassification"),Yda.forEach(t),Wft=r(YJe," (mBART model)"),YJe.forEach(t),Uft=i(Ge),Q7=n(Ge,"LI",{});var KJe=s(Q7);Z9e=n(KJe,"STRONG",{});var Kda=s(Z9e);Hft=r(Kda,"roberta"),Kda.forEach(t),Jft=r(KJe," \u2014 "),Hne=n(KJe,"A",{href:!0});var Zda=s(Hne);Yft=r(Zda,"FlaxRobertaForSequenceClassification"),Zda.forEach(t),Kft=r(KJe," (RoBERTa model)"),KJe.forEach(t),Zft=i(Ge),W7=n(Ge,"LI",{});var ZJe=s(W7);exe=n(ZJe,"STRONG",{});var eca=s(exe);egt=r(eca,"roformer"),eca.forEach(t),ogt=r(ZJe," \u2014 "),Jne=n(ZJe,"A",{href:!0});var oca=s(Jne);rgt=r(oca,"FlaxRoFormerForSequenceClassification"),oca.forEach(t),tgt=r(ZJe," (RoFormer model)"),ZJe.forEach(t),agt=i(Ge),U7=n(Ge,"LI",{});var eYe=s(U7);oxe=n(eYe,"STRONG",{});var rca=s(oxe);ngt=r(rca,"xlm-roberta"),rca.forEach(t),sgt=r(eYe," \u2014 "),Yne=n(eYe,"A",{href:!0});var tca=s(Yne);lgt=r(tca,"FlaxXLMRobertaForSequenceClassification"),tca.forEach(t),igt=r(eYe," (XLM-RoBERTa model)"),eYe.forEach(t),Ge.forEach(t),dgt=i(Vi),T(H7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),SZe=i(m),ef=n(m,"H2",{class:!0});var Hoo=s(ef);J7=n(Hoo,"A",{id:!0,class:!0,href:!0});var aca=s(J7);rxe=n(aca,"SPAN",{});var nca=s(rxe);T(MR.$$.fragment,nca),nca.forEach(t),aca.forEach(t),cgt=i(Hoo),txe=n(Hoo,"SPAN",{});var sca=s(txe);mgt=r(sca,"FlaxAutoModelForQuestionAnswering"),sca.forEach(t),Hoo.forEach(t),RZe=i(m),yr=n(m,"DIV",{class:!0});var Xi=s(yr);T(ER.$$.fragment,Xi),fgt=i(Xi),of=n(Xi,"P",{});var Nie=s(of);ggt=r(Nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kne=n(Nie,"A",{href:!0});var lca=s(Kne);hgt=r(lca,"from_pretrained()"),lca.forEach(t),ugt=r(Nie," class method or the "),Zne=n(Nie,"A",{href:!0});var ica=s(Zne);pgt=r(ica,"from_config()"),ica.forEach(t),_gt=r(Nie,` class
method.`),Nie.forEach(t),bgt=i(Xi),CR=n(Xi,"P",{});var Joo=s(CR);vgt=r(Joo,"This class cannot be instantiated directly using "),axe=n(Joo,"CODE",{});var dca=s(axe);Fgt=r(dca,"__init__()"),dca.forEach(t),Tgt=r(Joo," (throws an error)."),Joo.forEach(t),Mgt=i(Xi),fa=n(Xi,"DIV",{class:!0});var l9=s(fa);T(wR.$$.fragment,l9),Egt=i(l9),nxe=n(l9,"P",{});var cca=s(nxe);Cgt=r(cca,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cca.forEach(t),wgt=i(l9),rf=n(l9,"P",{});var qie=s(rf);Agt=r(qie,`Note:
Loading a model from its configuration file does `),sxe=n(qie,"STRONG",{});var mca=s(sxe);Lgt=r(mca,"not"),mca.forEach(t),ygt=r(qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ese=n(qie,"A",{href:!0});var fca=s(ese);xgt=r(fca,"from_pretrained()"),fca.forEach(t),$gt=r(qie," to load the model weights."),qie.forEach(t),kgt=i(l9),T(Y7.$$.fragment,l9),l9.forEach(t),Sgt=i(Xi),at=n(Xi,"DIV",{class:!0});var zi=s(at);T(AR.$$.fragment,zi),Rgt=i(zi),lxe=n(zi,"P",{});var gca=s(lxe);Pgt=r(gca,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),gca.forEach(t),Bgt=i(zi),Qn=n(zi,"P",{});var i9=s(Qn);Igt=r(i9,"The model class to instantiate is selected based on the "),ixe=n(i9,"CODE",{});var hca=s(ixe);Ngt=r(hca,"model_type"),hca.forEach(t),qgt=r(i9,` property of the config object (either
passed as an argument or loaded from `),dxe=n(i9,"CODE",{});var uca=s(dxe);jgt=r(uca,"pretrained_model_name_or_path"),uca.forEach(t),Dgt=r(i9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cxe=n(i9,"CODE",{});var pca=s(cxe);Ggt=r(pca,"pretrained_model_name_or_path"),pca.forEach(t),Ogt=r(i9,":"),i9.forEach(t),Vgt=i(zi),Re=n(zi,"UL",{});var Oe=s(Re);K7=n(Oe,"LI",{});var oYe=s(K7);mxe=n(oYe,"STRONG",{});var _ca=s(mxe);Xgt=r(_ca,"albert"),_ca.forEach(t),zgt=r(oYe," \u2014 "),ose=n(oYe,"A",{href:!0});var bca=s(ose);Qgt=r(bca,"FlaxAlbertForQuestionAnswering"),bca.forEach(t),Wgt=r(oYe," (ALBERT model)"),oYe.forEach(t),Ugt=i(Oe),Z7=n(Oe,"LI",{});var rYe=s(Z7);fxe=n(rYe,"STRONG",{});var vca=s(fxe);Hgt=r(vca,"bart"),vca.forEach(t),Jgt=r(rYe," \u2014 "),rse=n(rYe,"A",{href:!0});var Fca=s(rse);Ygt=r(Fca,"FlaxBartForQuestionAnswering"),Fca.forEach(t),Kgt=r(rYe," (BART model)"),rYe.forEach(t),Zgt=i(Oe),eL=n(Oe,"LI",{});var tYe=s(eL);gxe=n(tYe,"STRONG",{});var Tca=s(gxe);eht=r(Tca,"bert"),Tca.forEach(t),oht=r(tYe," \u2014 "),tse=n(tYe,"A",{href:!0});var Mca=s(tse);rht=r(Mca,"FlaxBertForQuestionAnswering"),Mca.forEach(t),tht=r(tYe," (BERT model)"),tYe.forEach(t),aht=i(Oe),oL=n(Oe,"LI",{});var aYe=s(oL);hxe=n(aYe,"STRONG",{});var Eca=s(hxe);nht=r(Eca,"big_bird"),Eca.forEach(t),sht=r(aYe," \u2014 "),ase=n(aYe,"A",{href:!0});var Cca=s(ase);lht=r(Cca,"FlaxBigBirdForQuestionAnswering"),Cca.forEach(t),iht=r(aYe," (BigBird model)"),aYe.forEach(t),dht=i(Oe),rL=n(Oe,"LI",{});var nYe=s(rL);uxe=n(nYe,"STRONG",{});var wca=s(uxe);cht=r(wca,"distilbert"),wca.forEach(t),mht=r(nYe," \u2014 "),nse=n(nYe,"A",{href:!0});var Aca=s(nse);fht=r(Aca,"FlaxDistilBertForQuestionAnswering"),Aca.forEach(t),ght=r(nYe," (DistilBERT model)"),nYe.forEach(t),hht=i(Oe),tL=n(Oe,"LI",{});var sYe=s(tL);pxe=n(sYe,"STRONG",{});var Lca=s(pxe);uht=r(Lca,"electra"),Lca.forEach(t),pht=r(sYe," \u2014 "),sse=n(sYe,"A",{href:!0});var yca=s(sse);_ht=r(yca,"FlaxElectraForQuestionAnswering"),yca.forEach(t),bht=r(sYe," (ELECTRA model)"),sYe.forEach(t),vht=i(Oe),aL=n(Oe,"LI",{});var lYe=s(aL);_xe=n(lYe,"STRONG",{});var xca=s(_xe);Fht=r(xca,"mbart"),xca.forEach(t),Tht=r(lYe," \u2014 "),lse=n(lYe,"A",{href:!0});var $ca=s(lse);Mht=r($ca,"FlaxMBartForQuestionAnswering"),$ca.forEach(t),Eht=r(lYe," (mBART model)"),lYe.forEach(t),Cht=i(Oe),nL=n(Oe,"LI",{});var iYe=s(nL);bxe=n(iYe,"STRONG",{});var kca=s(bxe);wht=r(kca,"roberta"),kca.forEach(t),Aht=r(iYe," \u2014 "),ise=n(iYe,"A",{href:!0});var Sca=s(ise);Lht=r(Sca,"FlaxRobertaForQuestionAnswering"),Sca.forEach(t),yht=r(iYe," (RoBERTa model)"),iYe.forEach(t),xht=i(Oe),sL=n(Oe,"LI",{});var dYe=s(sL);vxe=n(dYe,"STRONG",{});var Rca=s(vxe);$ht=r(Rca,"roformer"),Rca.forEach(t),kht=r(dYe," \u2014 "),dse=n(dYe,"A",{href:!0});var Pca=s(dse);Sht=r(Pca,"FlaxRoFormerForQuestionAnswering"),Pca.forEach(t),Rht=r(dYe," (RoFormer model)"),dYe.forEach(t),Pht=i(Oe),lL=n(Oe,"LI",{});var cYe=s(lL);Fxe=n(cYe,"STRONG",{});var Bca=s(Fxe);Bht=r(Bca,"xlm-roberta"),Bca.forEach(t),Iht=r(cYe," \u2014 "),cse=n(cYe,"A",{href:!0});var Ica=s(cse);Nht=r(Ica,"FlaxXLMRobertaForQuestionAnswering"),Ica.forEach(t),qht=r(cYe," (XLM-RoBERTa model)"),cYe.forEach(t),Oe.forEach(t),jht=i(zi),T(iL.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),PZe=i(m),tf=n(m,"H2",{class:!0});var Yoo=s(tf);dL=n(Yoo,"A",{id:!0,class:!0,href:!0});var Nca=s(dL);Txe=n(Nca,"SPAN",{});var qca=s(Txe);T(LR.$$.fragment,qca),qca.forEach(t),Nca.forEach(t),Dht=i(Yoo),Mxe=n(Yoo,"SPAN",{});var jca=s(Mxe);Ght=r(jca,"FlaxAutoModelForTokenClassification"),jca.forEach(t),Yoo.forEach(t),BZe=i(m),xr=n(m,"DIV",{class:!0});var Qi=s(xr);T(yR.$$.fragment,Qi),Oht=i(Qi),af=n(Qi,"P",{});var jie=s(af);Vht=r(jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mse=n(jie,"A",{href:!0});var Dca=s(mse);Xht=r(Dca,"from_pretrained()"),Dca.forEach(t),zht=r(jie," class method or the "),fse=n(jie,"A",{href:!0});var Gca=s(fse);Qht=r(Gca,"from_config()"),Gca.forEach(t),Wht=r(jie,` class
method.`),jie.forEach(t),Uht=i(Qi),xR=n(Qi,"P",{});var Koo=s(xR);Hht=r(Koo,"This class cannot be instantiated directly using "),Exe=n(Koo,"CODE",{});var Oca=s(Exe);Jht=r(Oca,"__init__()"),Oca.forEach(t),Yht=r(Koo," (throws an error)."),Koo.forEach(t),Kht=i(Qi),ga=n(Qi,"DIV",{class:!0});var d9=s(ga);T($R.$$.fragment,d9),Zht=i(d9),Cxe=n(d9,"P",{});var Vca=s(Cxe);eut=r(Vca,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Vca.forEach(t),out=i(d9),nf=n(d9,"P",{});var Die=s(nf);rut=r(Die,`Note:
Loading a model from its configuration file does `),wxe=n(Die,"STRONG",{});var Xca=s(wxe);tut=r(Xca,"not"),Xca.forEach(t),aut=r(Die,` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=n(Die,"A",{href:!0});var zca=s(gse);nut=r(zca,"from_pretrained()"),zca.forEach(t),sut=r(Die," to load the model weights."),Die.forEach(t),lut=i(d9),T(cL.$$.fragment,d9),d9.forEach(t),iut=i(Qi),nt=n(Qi,"DIV",{class:!0});var Wi=s(nt);T(kR.$$.fragment,Wi),dut=i(Wi),Axe=n(Wi,"P",{});var Qca=s(Axe);cut=r(Qca,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Qca.forEach(t),mut=i(Wi),Wn=n(Wi,"P",{});var c9=s(Wn);fut=r(c9,"The model class to instantiate is selected based on the "),Lxe=n(c9,"CODE",{});var Wca=s(Lxe);gut=r(Wca,"model_type"),Wca.forEach(t),hut=r(c9,` property of the config object (either
passed as an argument or loaded from `),yxe=n(c9,"CODE",{});var Uca=s(yxe);uut=r(Uca,"pretrained_model_name_or_path"),Uca.forEach(t),put=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xxe=n(c9,"CODE",{});var Hca=s(xxe);_ut=r(Hca,"pretrained_model_name_or_path"),Hca.forEach(t),but=r(c9,":"),c9.forEach(t),vut=i(Wi),Xe=n(Wi,"UL",{});var Ao=s(Xe);mL=n(Ao,"LI",{});var mYe=s(mL);$xe=n(mYe,"STRONG",{});var Jca=s($xe);Fut=r(Jca,"albert"),Jca.forEach(t),Tut=r(mYe," \u2014 "),hse=n(mYe,"A",{href:!0});var Yca=s(hse);Mut=r(Yca,"FlaxAlbertForTokenClassification"),Yca.forEach(t),Eut=r(mYe," (ALBERT model)"),mYe.forEach(t),Cut=i(Ao),fL=n(Ao,"LI",{});var fYe=s(fL);kxe=n(fYe,"STRONG",{});var Kca=s(kxe);wut=r(Kca,"bert"),Kca.forEach(t),Aut=r(fYe," \u2014 "),use=n(fYe,"A",{href:!0});var Zca=s(use);Lut=r(Zca,"FlaxBertForTokenClassification"),Zca.forEach(t),yut=r(fYe," (BERT model)"),fYe.forEach(t),xut=i(Ao),gL=n(Ao,"LI",{});var gYe=s(gL);Sxe=n(gYe,"STRONG",{});var ema=s(Sxe);$ut=r(ema,"big_bird"),ema.forEach(t),kut=r(gYe," \u2014 "),pse=n(gYe,"A",{href:!0});var oma=s(pse);Sut=r(oma,"FlaxBigBirdForTokenClassification"),oma.forEach(t),Rut=r(gYe," (BigBird model)"),gYe.forEach(t),Put=i(Ao),hL=n(Ao,"LI",{});var hYe=s(hL);Rxe=n(hYe,"STRONG",{});var rma=s(Rxe);But=r(rma,"distilbert"),rma.forEach(t),Iut=r(hYe," \u2014 "),_se=n(hYe,"A",{href:!0});var tma=s(_se);Nut=r(tma,"FlaxDistilBertForTokenClassification"),tma.forEach(t),qut=r(hYe," (DistilBERT model)"),hYe.forEach(t),jut=i(Ao),uL=n(Ao,"LI",{});var uYe=s(uL);Pxe=n(uYe,"STRONG",{});var ama=s(Pxe);Dut=r(ama,"electra"),ama.forEach(t),Gut=r(uYe," \u2014 "),bse=n(uYe,"A",{href:!0});var nma=s(bse);Out=r(nma,"FlaxElectraForTokenClassification"),nma.forEach(t),Vut=r(uYe," (ELECTRA model)"),uYe.forEach(t),Xut=i(Ao),pL=n(Ao,"LI",{});var pYe=s(pL);Bxe=n(pYe,"STRONG",{});var sma=s(Bxe);zut=r(sma,"roberta"),sma.forEach(t),Qut=r(pYe," \u2014 "),vse=n(pYe,"A",{href:!0});var lma=s(vse);Wut=r(lma,"FlaxRobertaForTokenClassification"),lma.forEach(t),Uut=r(pYe," (RoBERTa model)"),pYe.forEach(t),Hut=i(Ao),_L=n(Ao,"LI",{});var _Ye=s(_L);Ixe=n(_Ye,"STRONG",{});var ima=s(Ixe);Jut=r(ima,"roformer"),ima.forEach(t),Yut=r(_Ye," \u2014 "),Fse=n(_Ye,"A",{href:!0});var dma=s(Fse);Kut=r(dma,"FlaxRoFormerForTokenClassification"),dma.forEach(t),Zut=r(_Ye," (RoFormer model)"),_Ye.forEach(t),ept=i(Ao),bL=n(Ao,"LI",{});var bYe=s(bL);Nxe=n(bYe,"STRONG",{});var cma=s(Nxe);opt=r(cma,"xlm-roberta"),cma.forEach(t),rpt=r(bYe," \u2014 "),Tse=n(bYe,"A",{href:!0});var mma=s(Tse);tpt=r(mma,"FlaxXLMRobertaForTokenClassification"),mma.forEach(t),apt=r(bYe," (XLM-RoBERTa model)"),bYe.forEach(t),Ao.forEach(t),npt=i(Wi),T(vL.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),IZe=i(m),sf=n(m,"H2",{class:!0});var Zoo=s(sf);FL=n(Zoo,"A",{id:!0,class:!0,href:!0});var fma=s(FL);qxe=n(fma,"SPAN",{});var gma=s(qxe);T(SR.$$.fragment,gma),gma.forEach(t),fma.forEach(t),spt=i(Zoo),jxe=n(Zoo,"SPAN",{});var hma=s(jxe);lpt=r(hma,"FlaxAutoModelForMultipleChoice"),hma.forEach(t),Zoo.forEach(t),NZe=i(m),$r=n(m,"DIV",{class:!0});var Ui=s($r);T(RR.$$.fragment,Ui),ipt=i(Ui),lf=n(Ui,"P",{});var Gie=s(lf);dpt=r(Gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Mse=n(Gie,"A",{href:!0});var uma=s(Mse);cpt=r(uma,"from_pretrained()"),uma.forEach(t),mpt=r(Gie," class method or the "),Ese=n(Gie,"A",{href:!0});var pma=s(Ese);fpt=r(pma,"from_config()"),pma.forEach(t),gpt=r(Gie,` class
method.`),Gie.forEach(t),hpt=i(Ui),PR=n(Ui,"P",{});var ero=s(PR);upt=r(ero,"This class cannot be instantiated directly using "),Dxe=n(ero,"CODE",{});var _ma=s(Dxe);ppt=r(_ma,"__init__()"),_ma.forEach(t),_pt=r(ero," (throws an error)."),ero.forEach(t),bpt=i(Ui),ha=n(Ui,"DIV",{class:!0});var m9=s(ha);T(BR.$$.fragment,m9),vpt=i(m9),Gxe=n(m9,"P",{});var bma=s(Gxe);Fpt=r(bma,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),bma.forEach(t),Tpt=i(m9),df=n(m9,"P",{});var Oie=s(df);Mpt=r(Oie,`Note:
Loading a model from its configuration file does `),Oxe=n(Oie,"STRONG",{});var vma=s(Oxe);Ept=r(vma,"not"),vma.forEach(t),Cpt=r(Oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=n(Oie,"A",{href:!0});var Fma=s(Cse);wpt=r(Fma,"from_pretrained()"),Fma.forEach(t),Apt=r(Oie," to load the model weights."),Oie.forEach(t),Lpt=i(m9),T(TL.$$.fragment,m9),m9.forEach(t),ypt=i(Ui),st=n(Ui,"DIV",{class:!0});var Hi=s(st);T(IR.$$.fragment,Hi),xpt=i(Hi),Vxe=n(Hi,"P",{});var Tma=s(Vxe);$pt=r(Tma,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tma.forEach(t),kpt=i(Hi),Un=n(Hi,"P",{});var f9=s(Un);Spt=r(f9,"The model class to instantiate is selected based on the "),Xxe=n(f9,"CODE",{});var Mma=s(Xxe);Rpt=r(Mma,"model_type"),Mma.forEach(t),Ppt=r(f9,` property of the config object (either
passed as an argument or loaded from `),zxe=n(f9,"CODE",{});var Ema=s(zxe);Bpt=r(Ema,"pretrained_model_name_or_path"),Ema.forEach(t),Ipt=r(f9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qxe=n(f9,"CODE",{});var Cma=s(Qxe);Npt=r(Cma,"pretrained_model_name_or_path"),Cma.forEach(t),qpt=r(f9,":"),f9.forEach(t),jpt=i(Hi),ze=n(Hi,"UL",{});var Lo=s(ze);ML=n(Lo,"LI",{});var vYe=s(ML);Wxe=n(vYe,"STRONG",{});var wma=s(Wxe);Dpt=r(wma,"albert"),wma.forEach(t),Gpt=r(vYe," \u2014 "),wse=n(vYe,"A",{href:!0});var Ama=s(wse);Opt=r(Ama,"FlaxAlbertForMultipleChoice"),Ama.forEach(t),Vpt=r(vYe," (ALBERT model)"),vYe.forEach(t),Xpt=i(Lo),EL=n(Lo,"LI",{});var FYe=s(EL);Uxe=n(FYe,"STRONG",{});var Lma=s(Uxe);zpt=r(Lma,"bert"),Lma.forEach(t),Qpt=r(FYe," \u2014 "),Ase=n(FYe,"A",{href:!0});var yma=s(Ase);Wpt=r(yma,"FlaxBertForMultipleChoice"),yma.forEach(t),Upt=r(FYe," (BERT model)"),FYe.forEach(t),Hpt=i(Lo),CL=n(Lo,"LI",{});var TYe=s(CL);Hxe=n(TYe,"STRONG",{});var xma=s(Hxe);Jpt=r(xma,"big_bird"),xma.forEach(t),Ypt=r(TYe," \u2014 "),Lse=n(TYe,"A",{href:!0});var $ma=s(Lse);Kpt=r($ma,"FlaxBigBirdForMultipleChoice"),$ma.forEach(t),Zpt=r(TYe," (BigBird model)"),TYe.forEach(t),e_t=i(Lo),wL=n(Lo,"LI",{});var MYe=s(wL);Jxe=n(MYe,"STRONG",{});var kma=s(Jxe);o_t=r(kma,"distilbert"),kma.forEach(t),r_t=r(MYe," \u2014 "),yse=n(MYe,"A",{href:!0});var Sma=s(yse);t_t=r(Sma,"FlaxDistilBertForMultipleChoice"),Sma.forEach(t),a_t=r(MYe," (DistilBERT model)"),MYe.forEach(t),n_t=i(Lo),AL=n(Lo,"LI",{});var EYe=s(AL);Yxe=n(EYe,"STRONG",{});var Rma=s(Yxe);s_t=r(Rma,"electra"),Rma.forEach(t),l_t=r(EYe," \u2014 "),xse=n(EYe,"A",{href:!0});var Pma=s(xse);i_t=r(Pma,"FlaxElectraForMultipleChoice"),Pma.forEach(t),d_t=r(EYe," (ELECTRA model)"),EYe.forEach(t),c_t=i(Lo),LL=n(Lo,"LI",{});var CYe=s(LL);Kxe=n(CYe,"STRONG",{});var Bma=s(Kxe);m_t=r(Bma,"roberta"),Bma.forEach(t),f_t=r(CYe," \u2014 "),$se=n(CYe,"A",{href:!0});var Ima=s($se);g_t=r(Ima,"FlaxRobertaForMultipleChoice"),Ima.forEach(t),h_t=r(CYe," (RoBERTa model)"),CYe.forEach(t),u_t=i(Lo),yL=n(Lo,"LI",{});var wYe=s(yL);Zxe=n(wYe,"STRONG",{});var Nma=s(Zxe);p_t=r(Nma,"roformer"),Nma.forEach(t),__t=r(wYe," \u2014 "),kse=n(wYe,"A",{href:!0});var qma=s(kse);b_t=r(qma,"FlaxRoFormerForMultipleChoice"),qma.forEach(t),v_t=r(wYe," (RoFormer model)"),wYe.forEach(t),F_t=i(Lo),xL=n(Lo,"LI",{});var AYe=s(xL);e$e=n(AYe,"STRONG",{});var jma=s(e$e);T_t=r(jma,"xlm-roberta"),jma.forEach(t),M_t=r(AYe," \u2014 "),Sse=n(AYe,"A",{href:!0});var Dma=s(Sse);E_t=r(Dma,"FlaxXLMRobertaForMultipleChoice"),Dma.forEach(t),C_t=r(AYe," (XLM-RoBERTa model)"),AYe.forEach(t),Lo.forEach(t),w_t=i(Hi),T($L.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),qZe=i(m),cf=n(m,"H2",{class:!0});var oro=s(cf);kL=n(oro,"A",{id:!0,class:!0,href:!0});var Gma=s(kL);o$e=n(Gma,"SPAN",{});var Oma=s(o$e);T(NR.$$.fragment,Oma),Oma.forEach(t),Gma.forEach(t),A_t=i(oro),r$e=n(oro,"SPAN",{});var Vma=s(r$e);L_t=r(Vma,"FlaxAutoModelForNextSentencePrediction"),Vma.forEach(t),oro.forEach(t),jZe=i(m),kr=n(m,"DIV",{class:!0});var Ji=s(kr);T(qR.$$.fragment,Ji),y_t=i(Ji),mf=n(Ji,"P",{});var Vie=s(mf);x_t=r(Vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Rse=n(Vie,"A",{href:!0});var Xma=s(Rse);$_t=r(Xma,"from_pretrained()"),Xma.forEach(t),k_t=r(Vie," class method or the "),Pse=n(Vie,"A",{href:!0});var zma=s(Pse);S_t=r(zma,"from_config()"),zma.forEach(t),R_t=r(Vie,` class
method.`),Vie.forEach(t),P_t=i(Ji),jR=n(Ji,"P",{});var rro=s(jR);B_t=r(rro,"This class cannot be instantiated directly using "),t$e=n(rro,"CODE",{});var Qma=s(t$e);I_t=r(Qma,"__init__()"),Qma.forEach(t),N_t=r(rro," (throws an error)."),rro.forEach(t),q_t=i(Ji),ua=n(Ji,"DIV",{class:!0});var g9=s(ua);T(DR.$$.fragment,g9),j_t=i(g9),a$e=n(g9,"P",{});var Wma=s(a$e);D_t=r(Wma,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wma.forEach(t),G_t=i(g9),ff=n(g9,"P",{});var Xie=s(ff);O_t=r(Xie,`Note:
Loading a model from its configuration file does `),n$e=n(Xie,"STRONG",{});var Uma=s(n$e);V_t=r(Uma,"not"),Uma.forEach(t),X_t=r(Xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bse=n(Xie,"A",{href:!0});var Hma=s(Bse);z_t=r(Hma,"from_pretrained()"),Hma.forEach(t),Q_t=r(Xie," to load the model weights."),Xie.forEach(t),W_t=i(g9),T(SL.$$.fragment,g9),g9.forEach(t),U_t=i(Ji),lt=n(Ji,"DIV",{class:!0});var Yi=s(lt);T(GR.$$.fragment,Yi),H_t=i(Yi),s$e=n(Yi,"P",{});var Jma=s(s$e);J_t=r(Jma,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Jma.forEach(t),Y_t=i(Yi),Hn=n(Yi,"P",{});var h9=s(Hn);K_t=r(h9,"The model class to instantiate is selected based on the "),l$e=n(h9,"CODE",{});var Yma=s(l$e);Z_t=r(Yma,"model_type"),Yma.forEach(t),e2t=r(h9,` property of the config object (either
passed as an argument or loaded from `),i$e=n(h9,"CODE",{});var Kma=s(i$e);o2t=r(Kma,"pretrained_model_name_or_path"),Kma.forEach(t),r2t=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=n(h9,"CODE",{});var Zma=s(d$e);t2t=r(Zma,"pretrained_model_name_or_path"),Zma.forEach(t),a2t=r(h9,":"),h9.forEach(t),n2t=i(Yi),c$e=n(Yi,"UL",{});var efa=s(c$e);RL=n(efa,"LI",{});var LYe=s(RL);m$e=n(LYe,"STRONG",{});var ofa=s(m$e);s2t=r(ofa,"bert"),ofa.forEach(t),l2t=r(LYe," \u2014 "),Ise=n(LYe,"A",{href:!0});var rfa=s(Ise);i2t=r(rfa,"FlaxBertForNextSentencePrediction"),rfa.forEach(t),d2t=r(LYe," (BERT model)"),LYe.forEach(t),efa.forEach(t),c2t=i(Yi),T(PL.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),DZe=i(m),gf=n(m,"H2",{class:!0});var tro=s(gf);BL=n(tro,"A",{id:!0,class:!0,href:!0});var tfa=s(BL);f$e=n(tfa,"SPAN",{});var afa=s(f$e);T(OR.$$.fragment,afa),afa.forEach(t),tfa.forEach(t),m2t=i(tro),g$e=n(tro,"SPAN",{});var nfa=s(g$e);f2t=r(nfa,"FlaxAutoModelForImageClassification"),nfa.forEach(t),tro.forEach(t),GZe=i(m),Sr=n(m,"DIV",{class:!0});var Ki=s(Sr);T(VR.$$.fragment,Ki),g2t=i(Ki),hf=n(Ki,"P",{});var zie=s(hf);h2t=r(zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nse=n(zie,"A",{href:!0});var sfa=s(Nse);u2t=r(sfa,"from_pretrained()"),sfa.forEach(t),p2t=r(zie," class method or the "),qse=n(zie,"A",{href:!0});var lfa=s(qse);_2t=r(lfa,"from_config()"),lfa.forEach(t),b2t=r(zie,` class
method.`),zie.forEach(t),v2t=i(Ki),XR=n(Ki,"P",{});var aro=s(XR);F2t=r(aro,"This class cannot be instantiated directly using "),h$e=n(aro,"CODE",{});var ifa=s(h$e);T2t=r(ifa,"__init__()"),ifa.forEach(t),M2t=r(aro," (throws an error)."),aro.forEach(t),E2t=i(Ki),pa=n(Ki,"DIV",{class:!0});var u9=s(pa);T(zR.$$.fragment,u9),C2t=i(u9),u$e=n(u9,"P",{});var dfa=s(u$e);w2t=r(dfa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),dfa.forEach(t),A2t=i(u9),uf=n(u9,"P",{});var Qie=s(uf);L2t=r(Qie,`Note:
Loading a model from its configuration file does `),p$e=n(Qie,"STRONG",{});var cfa=s(p$e);y2t=r(cfa,"not"),cfa.forEach(t),x2t=r(Qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=n(Qie,"A",{href:!0});var mfa=s(jse);$2t=r(mfa,"from_pretrained()"),mfa.forEach(t),k2t=r(Qie," to load the model weights."),Qie.forEach(t),S2t=i(u9),T(IL.$$.fragment,u9),u9.forEach(t),R2t=i(Ki),it=n(Ki,"DIV",{class:!0});var Zi=s(it);T(QR.$$.fragment,Zi),P2t=i(Zi),_$e=n(Zi,"P",{});var ffa=s(_$e);B2t=r(ffa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),ffa.forEach(t),I2t=i(Zi),Jn=n(Zi,"P",{});var p9=s(Jn);N2t=r(p9,"The model class to instantiate is selected based on the "),b$e=n(p9,"CODE",{});var gfa=s(b$e);q2t=r(gfa,"model_type"),gfa.forEach(t),j2t=r(p9,` property of the config object (either
passed as an argument or loaded from `),v$e=n(p9,"CODE",{});var hfa=s(v$e);D2t=r(hfa,"pretrained_model_name_or_path"),hfa.forEach(t),G2t=r(p9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=n(p9,"CODE",{});var ufa=s(F$e);O2t=r(ufa,"pretrained_model_name_or_path"),ufa.forEach(t),V2t=r(p9,":"),p9.forEach(t),X2t=i(Zi),WR=n(Zi,"UL",{});var nro=s(WR);NL=n(nro,"LI",{});var yYe=s(NL);T$e=n(yYe,"STRONG",{});var pfa=s(T$e);z2t=r(pfa,"beit"),pfa.forEach(t),Q2t=r(yYe," \u2014 "),Dse=n(yYe,"A",{href:!0});var _fa=s(Dse);W2t=r(_fa,"FlaxBeitForImageClassification"),_fa.forEach(t),U2t=r(yYe," (BEiT model)"),yYe.forEach(t),H2t=i(nro),qL=n(nro,"LI",{});var xYe=s(qL);M$e=n(xYe,"STRONG",{});var bfa=s(M$e);J2t=r(bfa,"vit"),bfa.forEach(t),Y2t=r(xYe," \u2014 "),Gse=n(xYe,"A",{href:!0});var vfa=s(Gse);K2t=r(vfa,"FlaxViTForImageClassification"),vfa.forEach(t),Z2t=r(xYe," (ViT model)"),xYe.forEach(t),nro.forEach(t),ebt=i(Zi),T(jL.$$.fragment,Zi),Zi.forEach(t),Ki.forEach(t),OZe=i(m),pf=n(m,"H2",{class:!0});var sro=s(pf);DL=n(sro,"A",{id:!0,class:!0,href:!0});var Ffa=s(DL);E$e=n(Ffa,"SPAN",{});var Tfa=s(E$e);T(UR.$$.fragment,Tfa),Tfa.forEach(t),Ffa.forEach(t),obt=i(sro),C$e=n(sro,"SPAN",{});var Mfa=s(C$e);rbt=r(Mfa,"FlaxAutoModelForVision2Seq"),Mfa.forEach(t),sro.forEach(t),VZe=i(m),Rr=n(m,"DIV",{class:!0});var ed=s(Rr);T(HR.$$.fragment,ed),tbt=i(ed),_f=n(ed,"P",{});var Wie=s(_f);abt=r(Wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ose=n(Wie,"A",{href:!0});var Efa=s(Ose);nbt=r(Efa,"from_pretrained()"),Efa.forEach(t),sbt=r(Wie," class method or the "),Vse=n(Wie,"A",{href:!0});var Cfa=s(Vse);lbt=r(Cfa,"from_config()"),Cfa.forEach(t),ibt=r(Wie,` class
method.`),Wie.forEach(t),dbt=i(ed),JR=n(ed,"P",{});var lro=s(JR);cbt=r(lro,"This class cannot be instantiated directly using "),w$e=n(lro,"CODE",{});var wfa=s(w$e);mbt=r(wfa,"__init__()"),wfa.forEach(t),fbt=r(lro," (throws an error)."),lro.forEach(t),gbt=i(ed),_a=n(ed,"DIV",{class:!0});var _9=s(_a);T(YR.$$.fragment,_9),hbt=i(_9),A$e=n(_9,"P",{});var Afa=s(A$e);ubt=r(Afa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Afa.forEach(t),pbt=i(_9),bf=n(_9,"P",{});var Uie=s(bf);_bt=r(Uie,`Note:
Loading a model from its configuration file does `),L$e=n(Uie,"STRONG",{});var Lfa=s(L$e);bbt=r(Lfa,"not"),Lfa.forEach(t),vbt=r(Uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=n(Uie,"A",{href:!0});var yfa=s(Xse);Fbt=r(yfa,"from_pretrained()"),yfa.forEach(t),Tbt=r(Uie," to load the model weights."),Uie.forEach(t),Mbt=i(_9),T(GL.$$.fragment,_9),_9.forEach(t),Ebt=i(ed),dt=n(ed,"DIV",{class:!0});var od=s(dt);T(KR.$$.fragment,od),Cbt=i(od),y$e=n(od,"P",{});var xfa=s(y$e);wbt=r(xfa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xfa.forEach(t),Abt=i(od),Yn=n(od,"P",{});var b9=s(Yn);Lbt=r(b9,"The model class to instantiate is selected based on the "),x$e=n(b9,"CODE",{});var $fa=s(x$e);ybt=r($fa,"model_type"),$fa.forEach(t),xbt=r(b9,` property of the config object (either
passed as an argument or loaded from `),$$e=n(b9,"CODE",{});var kfa=s($$e);$bt=r(kfa,"pretrained_model_name_or_path"),kfa.forEach(t),kbt=r(b9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=n(b9,"CODE",{});var Sfa=s(k$e);Sbt=r(Sfa,"pretrained_model_name_or_path"),Sfa.forEach(t),Rbt=r(b9,":"),b9.forEach(t),Pbt=i(od),S$e=n(od,"UL",{});var Rfa=s(S$e);OL=n(Rfa,"LI",{});var $Ye=s(OL);R$e=n($Ye,"STRONG",{});var Pfa=s(R$e);Bbt=r(Pfa,"vision-encoder-decoder"),Pfa.forEach(t),Ibt=r($Ye," \u2014 "),zse=n($Ye,"A",{href:!0});var Bfa=s(zse);Nbt=r(Bfa,"FlaxVisionEncoderDecoderModel"),Bfa.forEach(t),qbt=r($Ye," (Vision Encoder decoder model)"),$Ye.forEach(t),Rfa.forEach(t),jbt=i(od),T(VL.$$.fragment,od),od.forEach(t),ed.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Hha)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(Zn,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(os,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(rs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(id,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(Af,"id","extending-the-auto-classes"),c(Af,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Af,"href","#extending-the-auto-classes"),c(dd,"class","relative group"),c(yf,"id","transformers.AutoConfig"),c(yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yf,"href","#transformers.AutoConfig"),c(cd,"class","relative group"),c($B,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(kB,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(SB,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(RB,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(PB,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(BB,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(IB,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(NB,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(qB,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(jB,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(DB,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(GB,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c(OB,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(VB,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(XB,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),c(zB,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(QB,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(WB,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(UB,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(HB,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(JB,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(YB,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(KB,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c(ZB,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(eI,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(oI,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(rI,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(tI,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c(aI,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),c(nI,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(sI,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(lI,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(iI,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(dI,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),c(cI,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(mI,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(fI,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(gI,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(hI,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(uI,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c(pI,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(_I,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(bI,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(vI,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c(FI,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),c(TI,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(MI,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(EI,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(CI,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(wI,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(AI,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(LI,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(yI,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(xI,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c($I,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(kI,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(SI,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(RI,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(PI,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(BI,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(II,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(NI,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(qI,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(jI,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(DI,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(GI,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(OI,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(VI,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),c(XI,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(zI,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(QI,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(WI,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(UI,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),c(HI,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(JI,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(YI,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(KI,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(ZI,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(eN,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(oN,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(rN,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(tN,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(aN,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(nN,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c(sN,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(lN,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(iN,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(dN,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(cN,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(mN,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(fN,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(gN,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c(hN,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(uN,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(pN,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(_N,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(bN,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(vN,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(FN,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),c(TN,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(MN,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(EN,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(CN,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(wN,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(AN,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(LN,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(yN,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(xN,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),c($N,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(kN,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(SN,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(RN,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(PN,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c(BN,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(IN,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(NN,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(qN,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(jN,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),c(DN,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(GN,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(ON,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(VN,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(XN,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(zN,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(QN,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(WN,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"id","transformers.AutoTokenizer"),c(Uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uh,"href","#transformers.AutoTokenizer"),c(fd,"class","relative group"),c(UN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(HN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(JN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(YN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(KN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(ZN,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(eq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(oq,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(rq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(tq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(aq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(nq,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(sq,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(lq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(iq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(dq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(cq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(mq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(fq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(gq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(hq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(uq,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(pq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(_q,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(bq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(vq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(Fq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Tq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Mq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(Eq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(Cq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(wq,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(Aq,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(Lq,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(yq,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(xq,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c($q,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(kq,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(Sq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(Rq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(Pq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Bq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(Iq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(Nq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(qq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(jq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(Dq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Gq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Oq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(Vq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(Xq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(zq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(Qq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(Wq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(Uq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Hq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Jq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Yq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Kq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(Zq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ej,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(oj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(rj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(tj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(aj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(nj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(sj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(lj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(ij,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(dj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(cj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(mj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(fj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(gj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(hj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(uj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(pj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(_j,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(bj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(vj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(Fj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(Tj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(Mj,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(Ej,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(Cj,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(wj,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(Aj,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(Lj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(yj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(xj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c($j,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(kj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Sj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Rj,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(Pj,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(Bj,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(Ij,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(Nj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(qj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(jj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(Dj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),c(Gj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(Oj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Vj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Xj,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),c(zj,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(Qj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(Wj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Uj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(Hj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(Jj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Yj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(Kj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Zj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(eD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(oD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(rD,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(tD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(aD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(nD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(sD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(lD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(iD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(dD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c(cD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(mD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(fD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(gD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(hD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(uD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(pD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_D,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(bD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(vD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(FD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(TD,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(MD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(ED,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(CD,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(wD,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(AD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),c(LD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),c(yD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(xD,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c($D,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(kD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(SD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(RD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(PD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(BD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ID,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ND,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(qD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(jD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(DD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(GD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(OD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(VD,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(XD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(zD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(QD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(WD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(UD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(HD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(JD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(YD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoFeatureExtractor"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoFeatureExtractor"),c(gd,"class","relative group"),c(KD,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(ZD,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(eG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(oG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(tG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(aG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(nG,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(sG,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(lG,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(iG,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(dG,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(cG,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(mG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(fG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(gG,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(hG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(uG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(pG,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(_G,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(bG,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(vG,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(FG,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(TG,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(MG,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(EG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(CG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(wG,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(AG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(LG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(yG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(xG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c($G,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(kG,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(SG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(RG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(BG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(NG,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vp,"id","transformers.AutoProcessor"),c(vp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vp,"href","#transformers.AutoProcessor"),c(hd,"class","relative group"),c(qG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(DG,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),c(GG,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),c(OG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(VG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(XG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(zG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(QG,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(WG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(JG,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(YG,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(KG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(oO,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(rO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(tO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(aO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(nO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xp,"id","transformers.AutoModel"),c(Xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xp,"href","#transformers.AutoModel"),c(pd,"class","relative group"),c(sO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(cO,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(mO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(fO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(gO,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(hO,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(uO,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(pO,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(_O,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(bO,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(vO,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(FO,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(TO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(MO,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),c(EO,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c(CO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(wO,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(AO,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(LO,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(yO,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(xO,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c($O,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(kO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(SO,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(RO,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(PO,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(BO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c(IO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),c(NO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(qO,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(jO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(DO,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),c(GO,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(OO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(VO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(XO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(zO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(QO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(WO,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c(UO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(HO,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(JO,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(YO,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(KO,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),c(ZO,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(eV,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(oV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(rV,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(tV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(aV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(nV,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(sV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(lV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(iV,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(dV,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(cV,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(mV,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(fV,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(gV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(hV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(uV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(pV,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(_V,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(bV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),c(vV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(FV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(TV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),c(MV,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c(EV,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(CV,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(wV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(AV,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(LV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),c(yV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(xV,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),c($V,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(kV,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(SV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(RV,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(PV,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(BV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(IV,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(NV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(qV,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(jV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(DV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(GV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(OV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(VV,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c(XV,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(zV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(QV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(WV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(UV,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(HV,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),c(JV,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(YV,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c(KV,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(ZV,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(eX,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(oX,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(rX,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(tX,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),c(aX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(nX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(sX,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(lX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(iX,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(dX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(cX,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(mX,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(fX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),c(gX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c(hX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(uX,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(pX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(_X,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(bX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(vX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(FX,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ab,"id","transformers.AutoModelForPreTraining"),c(ab,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ab,"href","#transformers.AutoModelForPreTraining"),c(vd,"class","relative group"),c(TX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(wX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(AX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(LX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(yX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(xX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c($X,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(kX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(SX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(RX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(PX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(BX,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(IX,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(NX,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(qX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(jX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(DX,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(GX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(OX,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(VX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(XX,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(zX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(QX,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(WX,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(UX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(HX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(JX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(YX,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(KX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(ZX,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(ez,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(oz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(rz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(tz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(az,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(nz,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(sz,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(lz,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(iz,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(dz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(cz,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(mz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(fz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(gz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(hz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(uz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(pz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(_z,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r1,"id","transformers.AutoModelForCausalLM"),c(r1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r1,"href","#transformers.AutoModelForCausalLM"),c(Md,"class","relative group"),c(bz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(Mz,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c(Ez,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(Cz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(wz,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Az,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Lz,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(yz,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(xz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c($z,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(kz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Sz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(Rz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Pz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(Bz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Iz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Nz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(qz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(jz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(Dz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Gz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(Oz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),c(Vz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Xz,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(zz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Qz,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(Wz,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(Uz,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(Hz,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(Jz,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(Yz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(Kz,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(Zz,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(eQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(oQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(rQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(tQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(aQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(nQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(sQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(lQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W1,"id","transformers.AutoModelForMaskedLM"),c(W1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W1,"href","#transformers.AutoModelForMaskedLM"),c(wd,"class","relative group"),c(iQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(fQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(gQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(hQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(uQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(pQ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(_Q,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(bQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(vQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(FQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(TQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(MQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(EQ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(CQ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(wQ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(AQ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(LQ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(yQ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(xQ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c($Q,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(kQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(SQ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(RQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(PQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(BQ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(IQ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(NQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(qQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(jQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(DQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(GQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(OQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(VQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(XQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(zQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(WQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(UQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iv,"id","transformers.AutoModelForSeq2SeqLM"),c(Iv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Iv,"href","#transformers.AutoModelForSeq2SeqLM"),c(yd,"class","relative group"),c(HQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(ZQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(eW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(oW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(rW,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(tW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(aW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(nW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(sW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(lW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c(iW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(dW,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(cW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(mW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(fW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(gW,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(hW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(uW,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(pW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(_W,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sF,"id","transformers.AutoModelForSequenceClassification"),c(sF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sF,"href","#transformers.AutoModelForSequenceClassification"),c(kd,"class","relative group"),c(bW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(MW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c(EW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(CW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(wW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(AW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(LW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(yW,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(xW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c($W,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(kW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(SW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(RW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(PW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(BW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(IW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(NW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(qW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(jW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(DW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(GW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(OW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(VW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(XW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(zW,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(QW,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(WW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(UW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(HW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(JW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(YW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(KW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(ZW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(eU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(oU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(rU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(tU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(aU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(nU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(sU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(lU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(iU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(dU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(cU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(mU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(fU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(gU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(hU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(uU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(pU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(_U,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(bU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(vU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dT,"id","transformers.AutoModelForMultipleChoice"),c(dT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dT,"href","#transformers.AutoModelForMultipleChoice"),c(Pd,"class","relative group"),c(FU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(CU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(wU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(AU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(LU,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(yU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(xU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c($U,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(kU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(SU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(RU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(PU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(BU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(IU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(NU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(qU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(jU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(DU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(GU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(OU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(VU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(XU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(zU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(QU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(WU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(UU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(HU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(JU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(YU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(KU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(ZU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(eH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zT,"id","transformers.AutoModelForNextSentencePrediction"),c(zT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zT,"href","#transformers.AutoModelForNextSentencePrediction"),c(Nd,"class","relative group"),c(oH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(nH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(sH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(lH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(iH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(dH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(cH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rM,"id","transformers.AutoModelForTokenClassification"),c(rM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rM,"href","#transformers.AutoModelForTokenClassification"),c(Dd,"class","relative group"),c(mH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(uH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(pH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(_H,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(bH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(vH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(FH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(TH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(MH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(EH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(CH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(wH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(AH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(LH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(yH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(xH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c($H,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(kH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(SH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(RH,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(PH,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(BH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(IH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),c(NH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(qH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(jH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(DH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(GH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(OH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(VH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(XH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(zH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(QH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(WH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(UH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(HH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(JH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(YH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XM,"id","transformers.AutoModelForQuestionAnswering"),c(XM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XM,"href","#transformers.AutoModelForQuestionAnswering"),c(Vd,"class","relative group"),c(KH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(rJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(tJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(aJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(nJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(sJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(lJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(iJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(dJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(cJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(mJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(fJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(gJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(hJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(uJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(pJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(_J,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(bJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(vJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(FJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(TJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(MJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(EJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(CJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(wJ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(AJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(LJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(yJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(xJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c($J,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(kJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(SJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(RJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(PJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(BJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(IJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(NJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(qJ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(jJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(DJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(GJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(OJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(VJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(XJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qE,"id","transformers.AutoModelForTableQuestionAnswering"),c(qE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qE,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Qd,"class","relative group"),c(zJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UJ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VE,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(VE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VE,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(Hd,"class","relative group"),c(HJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(ZJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(eY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JE,"id","transformers.AutoModelForImageClassification"),c(JE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JE,"href","#transformers.AutoModelForImageClassification"),c(Zd,"class","relative group"),c(oY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aY,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(nY,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(sY,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(lY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(iY,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(dY,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(cY,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(mY,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(fY,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(gY,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(hY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(uY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(pY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(_Y,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(bY,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(vY,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(FY,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(TY,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(MY,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(EY,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(CY,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h4,"id","transformers.AutoModelForVideoClassification"),c(h4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h4,"href","#transformers.AutoModelForVideoClassification"),c(rc,"class","relative group"),c(wY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v4,"id","transformers.AutoModelForVision2Seq"),c(v4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v4,"href","#transformers.AutoModelForVision2Seq"),c(nc,"class","relative group"),c(xY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($Y,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SY,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C4,"id","transformers.AutoModelForVisualQuestionAnswering"),c(C4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C4,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(ic,"class","relative group"),c(RY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IY,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x4,"id","transformers.AutoModelForAudioClassification"),c(x4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x4,"href","#transformers.AutoModelForAudioClassification"),c(mc,"class","relative group"),c(NY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(GY,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(OY,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(VY,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(XY,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(zY,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(QY,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(WY,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UY,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O4,"id","transformers.AutoModelForAudioFrameClassification"),c(O4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O4,"href","#transformers.AutoModelForAudioFrameClassification"),c(hc,"class","relative group"),c(HY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(ZY,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(eK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(oK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(rK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y4,"id","transformers.AutoModelForCTC"),c(Y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y4,"href","#transformers.AutoModelForCTC"),c(_c,"class","relative group"),c(tK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(lK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(iK,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(dK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(cK,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(mK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(fK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(gK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(hK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(uK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mC,"id","transformers.AutoModelForSpeechSeq2Seq"),c(mC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mC,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Fc,"class","relative group"),c(pK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vK,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(FK,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_C,"id","transformers.AutoModelForAudioXVector"),c(_C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_C,"href","#transformers.AutoModelForAudioXVector"),c(Ec,"class","relative group"),c(TK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(wK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(AK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(LK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(yK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AC,"id","transformers.AutoModelForMaskedImageModeling"),c(AC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AC,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ac,"class","relative group"),c(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(RK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(PK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(BK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PC,"id","transformers.AutoModelForObjectDetection"),c(PC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PC,"href","#transformers.AutoModelForObjectDetection"),c(xc,"class","relative group"),c(IK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jK,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DK,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.AutoModelForImageSegmentation"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.AutoModelForImageSegmentation"),c(Sc,"class","relative group"),c(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XK,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zC,"id","transformers.AutoModelForSemanticSegmentation"),c(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zC,"href","#transformers.AutoModelForSemanticSegmentation"),c(Bc,"class","relative group"),c(zK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(HK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JK,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(KK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e3,"id","transformers.AutoModelForInstanceSegmentation"),c(e3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e3,"href","#transformers.AutoModelForInstanceSegmentation"),c(qc,"class","relative group"),c(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rZ,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n3,"id","transformers.TFAutoModel"),c(n3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n3,"href","#transformers.TFAutoModel"),c(Gc,"class","relative group"),c(tZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(lZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(iZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(dZ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(cZ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(mZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(fZ,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(gZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(hZ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(uZ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_Z,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(bZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(vZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),c(FZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(TZ,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(MZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(EZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(CZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(wZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(AZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(LZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(yZ,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(xZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c($Z,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(kZ,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(SZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c(RZ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(PZ,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(BZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(IZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(NZ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(qZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(jZ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(DZ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(GZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c(OZ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(VZ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),c(XZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(zZ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),c(QZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(WZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(UZ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),c(HZ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(JZ,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(YZ,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(KZ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(ZZ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(eee,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(oee,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(ree,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(tee,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),c(aee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(nee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(see,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l5,"id","transformers.TFAutoModelForPreTraining"),c(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l5,"href","#transformers.TFAutoModelForPreTraining"),c(Xc,"class","relative group"),c(lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cee,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(mee,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(fee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(gee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hee,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(uee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(pee,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(_ee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(bee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(vee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Fee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Tee,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(Mee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(Eee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Cee,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(wee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Aee,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Lee,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(yee,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(xee,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c($ee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(kee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(See,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R5,"id","transformers.TFAutoModelForCausalLM"),c(R5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R5,"href","#transformers.TFAutoModelForCausalLM"),c(Wc,"class","relative group"),c(Ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(Nee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(qee,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(jee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Dee,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Gee,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Oee,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Vee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Xee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(zee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(Qee,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Wee,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Uee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Hee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J5,"id","transformers.TFAutoModelForImageClassification"),c(J5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J5,"href","#transformers.TFAutoModelForImageClassification"),c(Jc,"class","relative group"),c(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zee,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(eoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(ooe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(roe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(toe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(aoe,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(noe,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(soe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(loe,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(ioe,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l0,"id","transformers.TFAutoModelForSemanticSegmentation"),c(l0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l0,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(Zc,"class","relative group"),c(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(foe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(goe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(hoe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g0,"id","transformers.TFAutoModelForMaskedLM"),c(g0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g0,"href","#transformers.TFAutoModelForMaskedLM"),c(tm,"class","relative group"),c(uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(boe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(voe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(Foe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Toe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(Moe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(Eoe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(Coe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(woe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Aoe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Loe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(yoe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(xoe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c($oe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(koe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Soe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Roe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Poe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Boe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Ioe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Noe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I0,"id","transformers.TFAutoModelForSeq2SeqLM"),c(I0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I0,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(sm,"class","relative group"),c(qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Goe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Ooe,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Voe,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Xoe,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(zoe,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(Qoe,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(Woe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Uoe,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Hoe,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Joe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H0,"id","transformers.TFAutoModelForSequenceClassification"),c(H0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H0,"href","#transformers.TFAutoModelForSequenceClassification"),c(dm,"class","relative group"),c(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ere,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(ore,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(rre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(tre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(are,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(nre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(sre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(lre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(ire,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(dre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(cre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(mre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(fre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(gre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(hre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(ure,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(pre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(_re,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(bre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(vre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(Fre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(Tre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(Mre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(Ere,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(Cre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(wre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(Are,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ww,"id","transformers.TFAutoModelForMultipleChoice"),c(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ww,"href","#transformers.TFAutoModelForMultipleChoice"),c(fm,"class","relative group"),c(Lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($re,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(kre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Sre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Rre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Pre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(Bre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(Ire,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(Nre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(qre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(jre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Dre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Gre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Ore,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Vre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Xre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(zre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(Qre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zw,"id","transformers.TFAutoModelForNextSentencePrediction"),c(zw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zw,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(um,"class","relative group"),c(Wre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ure,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Yre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jw,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(Jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jw,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(bm,"class","relative group"),c(Kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ete,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ote,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(eA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Tm,"class","relative group"),c(rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aA,"id","transformers.TFAutoModelForTokenClassification"),c(aA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aA,"href","#transformers.TFAutoModelForTokenClassification"),c(Cm,"class","relative group"),c(ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ite,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(cte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(mte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(fte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(gte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(hte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(ute,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(pte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(_te,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(bte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(vte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Fte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(Tte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Mte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Ete,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Cte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(wte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Ate,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Lte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(yte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(xte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yA,"id","transformers.TFAutoModelForQuestionAnswering"),c(yA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yA,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Lm,"class","relative group"),c($te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Pte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Bte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Ite,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Nte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(qte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(jte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Dte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Gte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Ote,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Vte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Xte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(zte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(Qte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Wte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(Ute,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(Hte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Jte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Yte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(Kte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(Zte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KA,"id","transformers.TFAutoModelForVision2Seq"),c(KA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KA,"href","#transformers.TFAutoModelForVision2Seq"),c($m,"class","relative group"),c(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tae,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Rm,"class","relative group"),c(aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lae,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s6,"id","transformers.FlaxAutoModel"),c(s6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s6,"href","#transformers.FlaxAutoModel"),c(Im,"class","relative group"),c(iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mae,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(fae,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(gae,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(hae,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(uae,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(pae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(_ae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(bae,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(vae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Fae,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(Tae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Mae,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Eae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Cae,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(wae,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(Aae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Lae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c(yae,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(xae,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c($ae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(kae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Sae,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(Rae,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Pae,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(Bae,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Iae,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Nae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I6,"id","transformers.FlaxAutoModelForCausalLM"),c(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I6,"href","#transformers.FlaxAutoModelForCausalLM"),c(jm,"class","relative group"),c(qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gae,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Oae,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Vae,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Xae,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(zae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(Qae,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Wae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Uae,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(Hae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Jae,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H6,"id","transformers.FlaxAutoModelForPreTraining"),c(H6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H6,"href","#transformers.FlaxAutoModelForPreTraining"),c(Om,"class","relative group"),c(Yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ene,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(one,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(rne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(tne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(ane,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(nne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(sne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(lne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ine,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(dne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(cne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(mne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(fne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m7,"id","transformers.FlaxAutoModelForMaskedLM"),c(m7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m7,"href","#transformers.FlaxAutoModelForMaskedLM"),c(zm,"class","relative group"),c(gne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pne,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(_ne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(bne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(vne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Fne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Tne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Mne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ene,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Cne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(wne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C7,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C7,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Um,"class","relative group"),c(Ane,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c($ne,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(kne,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Sne,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Rne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Pne,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Bne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ine,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Nne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(qne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N7,"id","transformers.FlaxAutoModelForSequenceClassification"),c(N7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N7,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Ym,"class","relative group"),c(jne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(One,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Vne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Xne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(zne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Qne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Wne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Une,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Hne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Jne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Yne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J7,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(J7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J7,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(ef,"class","relative group"),c(Kne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ese,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ose,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(rse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(tse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(ase,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(nse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(sse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(lse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(ise,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(dse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(cse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dL,"id","transformers.FlaxAutoModelForTokenClassification"),c(dL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dL,"href","#transformers.FlaxAutoModelForTokenClassification"),c(tf,"class","relative group"),c(mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(use,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(pse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(_se,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(bse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(vse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Fse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Tse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FL,"id","transformers.FlaxAutoModelForMultipleChoice"),c(FL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FL,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(sf,"class","relative group"),c(Mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ese,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Ase,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Lse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(yse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(xse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c($se,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(kse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Sse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kL,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(kL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kL,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(cf,"class","relative group"),c(Rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ise,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BL,"id","transformers.FlaxAutoModelForImageClassification"),c(BL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BL,"href","#transformers.FlaxAutoModelForImageClassification"),c(gf,"class","relative group"),c(Nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dse,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Gse,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DL,"id","transformers.FlaxAutoModelForVision2Seq"),c(DL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DL,"href","#transformers.FlaxAutoModelForVision2Seq"),c(pf,"class","relative group"),c(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zse,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,yo),e(yo,rd),b(m,Mf,_),b(m,pt,_),e(pt,td),e(pt,ad),e(ad,v9),e(pt,Ef),b(m,Ve,_),b(m,He,_),e(He,nd),e(He,Zn),e(Zn,F9),e(He,es),e(He,os),e(os,T9),e(He,sd),e(He,rs),e(rs,M9),e(He,ld),b(m,Cf,_),M(Qa,m,_),b(m,Je,_),b(m,Ae,_),e(Ae,CB),e(Ae,id),e(id,wB),e(Ae,AB),b(m,xo,_),b(m,Wa,_),e(Wa,LB),e(Wa,wf),e(wf,yB),e(Wa,iro),b(m,kYe,_),b(m,dd,_),e(dd,Af),e(Af,Hie),M(E9,Hie,null),e(dd,dro),e(dd,Jie),e(Jie,cro),b(m,SYe,_),b(m,ts,_),e(ts,mro),e(ts,Yie),e(Yie,fro),e(ts,gro),e(ts,Kie),e(Kie,hro),e(ts,uro),b(m,RYe,_),M(C9,m,_),b(m,PYe,_),b(m,xB,_),e(xB,pro),b(m,BYe,_),M(Lf,m,_),b(m,IYe,_),b(m,cd,_),e(cd,yf),e(yf,Zie),M(w9,Zie,null),e(cd,_ro),e(cd,ede),e(ede,bro),b(m,NYe,_),b(m,$o,_),M(A9,$o,null),e($o,vro),e($o,L9),e(L9,Fro),e(L9,$B),e($B,Tro),e(L9,Mro),e($o,Ero),e($o,y9),e(y9,Cro),e(y9,ode),e(ode,wro),e(y9,Aro),e($o,Lro),e($o,Pr),M(x9,Pr,null),e(Pr,yro),e(Pr,rde),e(rde,xro),e(Pr,$ro),e(Pr,md),e(md,kro),e(md,tde),e(tde,Sro),e(md,Rro),e(md,ade),e(ade,Pro),e(md,Bro),e(Pr,Iro),e(Pr,A),e(A,xf),e(xf,nde),e(nde,Nro),e(xf,qro),e(xf,kB),e(kB,jro),e(xf,Dro),e(A,Gro),e(A,$f),e($f,sde),e(sde,Oro),e($f,Vro),e($f,SB),e(SB,Xro),e($f,zro),e(A,Qro),e(A,kf),e(kf,lde),e(lde,Wro),e(kf,Uro),e(kf,RB),e(RB,Hro),e(kf,Jro),e(A,Yro),e(A,Sf),e(Sf,ide),e(ide,Kro),e(Sf,Zro),e(Sf,PB),e(PB,eto),e(Sf,oto),e(A,rto),e(A,Rf),e(Rf,dde),e(dde,tto),e(Rf,ato),e(Rf,BB),e(BB,nto),e(Rf,sto),e(A,lto),e(A,Pf),e(Pf,cde),e(cde,ito),e(Pf,dto),e(Pf,IB),e(IB,cto),e(Pf,mto),e(A,fto),e(A,Bf),e(Bf,mde),e(mde,gto),e(Bf,hto),e(Bf,NB),e(NB,uto),e(Bf,pto),e(A,_to),e(A,If),e(If,fde),e(fde,bto),e(If,vto),e(If,qB),e(qB,Fto),e(If,Tto),e(A,Mto),e(A,Nf),e(Nf,gde),e(gde,Eto),e(Nf,Cto),e(Nf,jB),e(jB,wto),e(Nf,Ato),e(A,Lto),e(A,qf),e(qf,hde),e(hde,yto),e(qf,xto),e(qf,DB),e(DB,$to),e(qf,kto),e(A,Sto),e(A,jf),e(jf,ude),e(ude,Rto),e(jf,Pto),e(jf,GB),e(GB,Bto),e(jf,Ito),e(A,Nto),e(A,Df),e(Df,pde),e(pde,qto),e(Df,jto),e(Df,OB),e(OB,Dto),e(Df,Gto),e(A,Oto),e(A,Gf),e(Gf,_de),e(_de,Vto),e(Gf,Xto),e(Gf,VB),e(VB,zto),e(Gf,Qto),e(A,Wto),e(A,Of),e(Of,bde),e(bde,Uto),e(Of,Hto),e(Of,XB),e(XB,Jto),e(Of,Yto),e(A,Kto),e(A,Vf),e(Vf,vde),e(vde,Zto),e(Vf,eao),e(Vf,zB),e(zB,oao),e(Vf,rao),e(A,tao),e(A,Xf),e(Xf,Fde),e(Fde,aao),e(Xf,nao),e(Xf,QB),e(QB,sao),e(Xf,lao),e(A,iao),e(A,zf),e(zf,Tde),e(Tde,dao),e(zf,cao),e(zf,WB),e(WB,mao),e(zf,fao),e(A,gao),e(A,Qf),e(Qf,Mde),e(Mde,hao),e(Qf,uao),e(Qf,UB),e(UB,pao),e(Qf,_ao),e(A,bao),e(A,Wf),e(Wf,Ede),e(Ede,vao),e(Wf,Fao),e(Wf,HB),e(HB,Tao),e(Wf,Mao),e(A,Eao),e(A,Uf),e(Uf,Cde),e(Cde,Cao),e(Uf,wao),e(Uf,JB),e(JB,Aao),e(Uf,Lao),e(A,yao),e(A,Hf),e(Hf,wde),e(wde,xao),e(Hf,$ao),e(Hf,YB),e(YB,kao),e(Hf,Sao),e(A,Rao),e(A,Jf),e(Jf,Ade),e(Ade,Pao),e(Jf,Bao),e(Jf,KB),e(KB,Iao),e(Jf,Nao),e(A,qao),e(A,Yf),e(Yf,Lde),e(Lde,jao),e(Yf,Dao),e(Yf,ZB),e(ZB,Gao),e(Yf,Oao),e(A,Vao),e(A,Kf),e(Kf,yde),e(yde,Xao),e(Kf,zao),e(Kf,eI),e(eI,Qao),e(Kf,Wao),e(A,Uao),e(A,Zf),e(Zf,xde),e(xde,Hao),e(Zf,Jao),e(Zf,oI),e(oI,Yao),e(Zf,Kao),e(A,Zao),e(A,eg),e(eg,$de),e($de,eno),e(eg,ono),e(eg,rI),e(rI,rno),e(eg,tno),e(A,ano),e(A,og),e(og,kde),e(kde,nno),e(og,sno),e(og,tI),e(tI,lno),e(og,ino),e(A,dno),e(A,rg),e(rg,Sde),e(Sde,cno),e(rg,mno),e(rg,aI),e(aI,fno),e(rg,gno),e(A,hno),e(A,tg),e(tg,Rde),e(Rde,uno),e(tg,pno),e(tg,nI),e(nI,_no),e(tg,bno),e(A,vno),e(A,ag),e(ag,Pde),e(Pde,Fno),e(ag,Tno),e(ag,sI),e(sI,Mno),e(ag,Eno),e(A,Cno),e(A,ng),e(ng,Bde),e(Bde,wno),e(ng,Ano),e(ng,lI),e(lI,Lno),e(ng,yno),e(A,xno),e(A,sg),e(sg,Ide),e(Ide,$no),e(sg,kno),e(sg,iI),e(iI,Sno),e(sg,Rno),e(A,Pno),e(A,lg),e(lg,Nde),e(Nde,Bno),e(lg,Ino),e(lg,dI),e(dI,Nno),e(lg,qno),e(A,jno),e(A,ig),e(ig,qde),e(qde,Dno),e(ig,Gno),e(ig,cI),e(cI,Ono),e(ig,Vno),e(A,Xno),e(A,dg),e(dg,jde),e(jde,zno),e(dg,Qno),e(dg,mI),e(mI,Wno),e(dg,Uno),e(A,Hno),e(A,cg),e(cg,Dde),e(Dde,Jno),e(cg,Yno),e(cg,fI),e(fI,Kno),e(cg,Zno),e(A,eso),e(A,mg),e(mg,Gde),e(Gde,oso),e(mg,rso),e(mg,gI),e(gI,tso),e(mg,aso),e(A,nso),e(A,fg),e(fg,Ode),e(Ode,sso),e(fg,lso),e(fg,hI),e(hI,iso),e(fg,dso),e(A,cso),e(A,gg),e(gg,Vde),e(Vde,mso),e(gg,fso),e(gg,uI),e(uI,gso),e(gg,hso),e(A,uso),e(A,hg),e(hg,Xde),e(Xde,pso),e(hg,_so),e(hg,pI),e(pI,bso),e(hg,vso),e(A,Fso),e(A,ug),e(ug,zde),e(zde,Tso),e(ug,Mso),e(ug,_I),e(_I,Eso),e(ug,Cso),e(A,wso),e(A,pg),e(pg,Qde),e(Qde,Aso),e(pg,Lso),e(pg,bI),e(bI,yso),e(pg,xso),e(A,$so),e(A,_g),e(_g,Wde),e(Wde,kso),e(_g,Sso),e(_g,vI),e(vI,Rso),e(_g,Pso),e(A,Bso),e(A,bg),e(bg,Ude),e(Ude,Iso),e(bg,Nso),e(bg,FI),e(FI,qso),e(bg,jso),e(A,Dso),e(A,vg),e(vg,Hde),e(Hde,Gso),e(vg,Oso),e(vg,TI),e(TI,Vso),e(vg,Xso),e(A,zso),e(A,Fg),e(Fg,Jde),e(Jde,Qso),e(Fg,Wso),e(Fg,MI),e(MI,Uso),e(Fg,Hso),e(A,Jso),e(A,Tg),e(Tg,Yde),e(Yde,Yso),e(Tg,Kso),e(Tg,EI),e(EI,Zso),e(Tg,elo),e(A,olo),e(A,Mg),e(Mg,Kde),e(Kde,rlo),e(Mg,tlo),e(Mg,CI),e(CI,alo),e(Mg,nlo),e(A,slo),e(A,Eg),e(Eg,Zde),e(Zde,llo),e(Eg,ilo),e(Eg,wI),e(wI,dlo),e(Eg,clo),e(A,mlo),e(A,Cg),e(Cg,ece),e(ece,flo),e(Cg,glo),e(Cg,AI),e(AI,hlo),e(Cg,ulo),e(A,plo),e(A,wg),e(wg,oce),e(oce,_lo),e(wg,blo),e(wg,LI),e(LI,vlo),e(wg,Flo),e(A,Tlo),e(A,Ag),e(Ag,rce),e(rce,Mlo),e(Ag,Elo),e(Ag,yI),e(yI,Clo),e(Ag,wlo),e(A,Alo),e(A,Lg),e(Lg,tce),e(tce,Llo),e(Lg,ylo),e(Lg,xI),e(xI,xlo),e(Lg,$lo),e(A,klo),e(A,yg),e(yg,ace),e(ace,Slo),e(yg,Rlo),e(yg,$I),e($I,Plo),e(yg,Blo),e(A,Ilo),e(A,xg),e(xg,nce),e(nce,Nlo),e(xg,qlo),e(xg,kI),e(kI,jlo),e(xg,Dlo),e(A,Glo),e(A,$g),e($g,sce),e(sce,Olo),e($g,Vlo),e($g,SI),e(SI,Xlo),e($g,zlo),e(A,Qlo),e(A,kg),e(kg,lce),e(lce,Wlo),e(kg,Ulo),e(kg,RI),e(RI,Hlo),e(kg,Jlo),e(A,Ylo),e(A,Sg),e(Sg,ice),e(ice,Klo),e(Sg,Zlo),e(Sg,PI),e(PI,eio),e(Sg,oio),e(A,rio),e(A,Rg),e(Rg,dce),e(dce,tio),e(Rg,aio),e(Rg,BI),e(BI,nio),e(Rg,sio),e(A,lio),e(A,Pg),e(Pg,cce),e(cce,iio),e(Pg,dio),e(Pg,II),e(II,cio),e(Pg,mio),e(A,fio),e(A,Bg),e(Bg,mce),e(mce,gio),e(Bg,hio),e(Bg,NI),e(NI,uio),e(Bg,pio),e(A,_io),e(A,Ig),e(Ig,fce),e(fce,bio),e(Ig,vio),e(Ig,qI),e(qI,Fio),e(Ig,Tio),e(A,Mio),e(A,Ng),e(Ng,gce),e(gce,Eio),e(Ng,Cio),e(Ng,jI),e(jI,wio),e(Ng,Aio),e(A,Lio),e(A,qg),e(qg,hce),e(hce,yio),e(qg,xio),e(qg,DI),e(DI,$io),e(qg,kio),e(A,Sio),e(A,jg),e(jg,uce),e(uce,Rio),e(jg,Pio),e(jg,GI),e(GI,Bio),e(jg,Iio),e(A,Nio),e(A,Dg),e(Dg,pce),e(pce,qio),e(Dg,jio),e(Dg,OI),e(OI,Dio),e(Dg,Gio),e(A,Oio),e(A,Gg),e(Gg,_ce),e(_ce,Vio),e(Gg,Xio),e(Gg,VI),e(VI,zio),e(Gg,Qio),e(A,Wio),e(A,Og),e(Og,bce),e(bce,Uio),e(Og,Hio),e(Og,XI),e(XI,Jio),e(Og,Yio),e(A,Kio),e(A,Vg),e(Vg,vce),e(vce,Zio),e(Vg,edo),e(Vg,zI),e(zI,odo),e(Vg,rdo),e(A,tdo),e(A,Xg),e(Xg,Fce),e(Fce,ado),e(Xg,ndo),e(Xg,QI),e(QI,sdo),e(Xg,ldo),e(A,ido),e(A,zg),e(zg,Tce),e(Tce,ddo),e(zg,cdo),e(zg,WI),e(WI,mdo),e(zg,fdo),e(A,gdo),e(A,Qg),e(Qg,Mce),e(Mce,hdo),e(Qg,udo),e(Qg,UI),e(UI,pdo),e(Qg,_do),e(A,bdo),e(A,Wg),e(Wg,Ece),e(Ece,vdo),e(Wg,Fdo),e(Wg,HI),e(HI,Tdo),e(Wg,Mdo),e(A,Edo),e(A,Ug),e(Ug,Cce),e(Cce,Cdo),e(Ug,wdo),e(Ug,JI),e(JI,Ado),e(Ug,Ldo),e(A,ydo),e(A,Hg),e(Hg,wce),e(wce,xdo),e(Hg,$do),e(Hg,YI),e(YI,kdo),e(Hg,Sdo),e(A,Rdo),e(A,Jg),e(Jg,Ace),e(Ace,Pdo),e(Jg,Bdo),e(Jg,KI),e(KI,Ido),e(Jg,Ndo),e(A,qdo),e(A,Yg),e(Yg,Lce),e(Lce,jdo),e(Yg,Ddo),e(Yg,ZI),e(ZI,Gdo),e(Yg,Odo),e(A,Vdo),e(A,Kg),e(Kg,yce),e(yce,Xdo),e(Kg,zdo),e(Kg,eN),e(eN,Qdo),e(Kg,Wdo),e(A,Udo),e(A,Zg),e(Zg,xce),e(xce,Hdo),e(Zg,Jdo),e(Zg,oN),e(oN,Ydo),e(Zg,Kdo),e(A,Zdo),e(A,eh),e(eh,$ce),e($ce,eco),e(eh,oco),e(eh,rN),e(rN,rco),e(eh,tco),e(A,aco),e(A,oh),e(oh,kce),e(kce,nco),e(oh,sco),e(oh,tN),e(tN,lco),e(oh,ico),e(A,dco),e(A,rh),e(rh,Sce),e(Sce,cco),e(rh,mco),e(rh,aN),e(aN,fco),e(rh,gco),e(A,hco),e(A,th),e(th,Rce),e(Rce,uco),e(th,pco),e(th,nN),e(nN,_co),e(th,bco),e(A,vco),e(A,ah),e(ah,Pce),e(Pce,Fco),e(ah,Tco),e(ah,sN),e(sN,Mco),e(ah,Eco),e(A,Cco),e(A,nh),e(nh,Bce),e(Bce,wco),e(nh,Aco),e(nh,lN),e(lN,Lco),e(nh,yco),e(A,xco),e(A,sh),e(sh,Ice),e(Ice,$co),e(sh,kco),e(sh,iN),e(iN,Sco),e(sh,Rco),e(A,Pco),e(A,lh),e(lh,Nce),e(Nce,Bco),e(lh,Ico),e(lh,dN),e(dN,Nco),e(lh,qco),e(A,jco),e(A,ih),e(ih,qce),e(qce,Dco),e(ih,Gco),e(ih,cN),e(cN,Oco),e(ih,Vco),e(A,Xco),e(A,dh),e(dh,jce),e(jce,zco),e(dh,Qco),e(dh,mN),e(mN,Wco),e(dh,Uco),e(A,Hco),e(A,ch),e(ch,Dce),e(Dce,Jco),e(ch,Yco),e(ch,fN),e(fN,Kco),e(ch,Zco),e(A,emo),e(A,mh),e(mh,Gce),e(Gce,omo),e(mh,rmo),e(mh,gN),e(gN,tmo),e(mh,amo),e(A,nmo),e(A,fh),e(fh,Oce),e(Oce,smo),e(fh,lmo),e(fh,hN),e(hN,imo),e(fh,dmo),e(A,cmo),e(A,gh),e(gh,Vce),e(Vce,mmo),e(gh,fmo),e(gh,uN),e(uN,gmo),e(gh,hmo),e(A,umo),e(A,hh),e(hh,Xce),e(Xce,pmo),e(hh,_mo),e(hh,pN),e(pN,bmo),e(hh,vmo),e(A,Fmo),e(A,uh),e(uh,zce),e(zce,Tmo),e(uh,Mmo),e(uh,_N),e(_N,Emo),e(uh,Cmo),e(A,wmo),e(A,ph),e(ph,Qce),e(Qce,Amo),e(ph,Lmo),e(ph,bN),e(bN,ymo),e(ph,xmo),e(A,$mo),e(A,_h),e(_h,Wce),e(Wce,kmo),e(_h,Smo),e(_h,vN),e(vN,Rmo),e(_h,Pmo),e(A,Bmo),e(A,bh),e(bh,Uce),e(Uce,Imo),e(bh,Nmo),e(bh,FN),e(FN,qmo),e(bh,jmo),e(A,Dmo),e(A,vh),e(vh,Hce),e(Hce,Gmo),e(vh,Omo),e(vh,TN),e(TN,Vmo),e(vh,Xmo),e(A,zmo),e(A,Fh),e(Fh,Jce),e(Jce,Qmo),e(Fh,Wmo),e(Fh,MN),e(MN,Umo),e(Fh,Hmo),e(A,Jmo),e(A,Th),e(Th,Yce),e(Yce,Ymo),e(Th,Kmo),e(Th,EN),e(EN,Zmo),e(Th,efo),e(A,ofo),e(A,Mh),e(Mh,Kce),e(Kce,rfo),e(Mh,tfo),e(Mh,CN),e(CN,afo),e(Mh,nfo),e(A,sfo),e(A,Eh),e(Eh,Zce),e(Zce,lfo),e(Eh,ifo),e(Eh,wN),e(wN,dfo),e(Eh,cfo),e(A,mfo),e(A,Ch),e(Ch,eme),e(eme,ffo),e(Ch,gfo),e(Ch,AN),e(AN,hfo),e(Ch,ufo),e(A,pfo),e(A,wh),e(wh,ome),e(ome,_fo),e(wh,bfo),e(wh,LN),e(LN,vfo),e(wh,Ffo),e(A,Tfo),e(A,Ah),e(Ah,rme),e(rme,Mfo),e(Ah,Efo),e(Ah,yN),e(yN,Cfo),e(Ah,wfo),e(A,Afo),e(A,Lh),e(Lh,tme),e(tme,Lfo),e(Lh,yfo),e(Lh,xN),e(xN,xfo),e(Lh,$fo),e(A,kfo),e(A,yh),e(yh,ame),e(ame,Sfo),e(yh,Rfo),e(yh,$N),e($N,Pfo),e(yh,Bfo),e(A,Ifo),e(A,xh),e(xh,nme),e(nme,Nfo),e(xh,qfo),e(xh,kN),e(kN,jfo),e(xh,Dfo),e(A,Gfo),e(A,$h),e($h,sme),e(sme,Ofo),e($h,Vfo),e($h,SN),e(SN,Xfo),e($h,zfo),e(A,Qfo),e(A,kh),e(kh,lme),e(lme,Wfo),e(kh,Ufo),e(kh,RN),e(RN,Hfo),e(kh,Jfo),e(A,Yfo),e(A,Sh),e(Sh,ime),e(ime,Kfo),e(Sh,Zfo),e(Sh,PN),e(PN,ego),e(Sh,ogo),e(A,rgo),e(A,Rh),e(Rh,dme),e(dme,tgo),e(Rh,ago),e(Rh,BN),e(BN,ngo),e(Rh,sgo),e(A,lgo),e(A,Ph),e(Ph,cme),e(cme,igo),e(Ph,dgo),e(Ph,IN),e(IN,cgo),e(Ph,mgo),e(A,fgo),e(A,Bh),e(Bh,mme),e(mme,ggo),e(Bh,hgo),e(Bh,NN),e(NN,ugo),e(Bh,pgo),e(A,_go),e(A,Ih),e(Ih,fme),e(fme,bgo),e(Ih,vgo),e(Ih,qN),e(qN,Fgo),e(Ih,Tgo),e(A,Mgo),e(A,Nh),e(Nh,gme),e(gme,Ego),e(Nh,Cgo),e(Nh,jN),e(jN,wgo),e(Nh,Ago),e(A,Lgo),e(A,qh),e(qh,hme),e(hme,ygo),e(qh,xgo),e(qh,DN),e(DN,$go),e(qh,kgo),e(A,Sgo),e(A,jh),e(jh,ume),e(ume,Rgo),e(jh,Pgo),e(jh,GN),e(GN,Bgo),e(jh,Igo),e(A,Ngo),e(A,Dh),e(Dh,pme),e(pme,qgo),e(Dh,jgo),e(Dh,ON),e(ON,Dgo),e(Dh,Ggo),e(A,Ogo),e(A,Gh),e(Gh,_me),e(_me,Vgo),e(Gh,Xgo),e(Gh,VN),e(VN,zgo),e(Gh,Qgo),e(A,Wgo),e(A,Oh),e(Oh,bme),e(bme,Ugo),e(Oh,Hgo),e(Oh,XN),e(XN,Jgo),e(Oh,Ygo),e(A,Kgo),e(A,Vh),e(Vh,vme),e(vme,Zgo),e(Vh,eho),e(Vh,zN),e(zN,oho),e(Vh,rho),e(A,tho),e(A,Xh),e(Xh,Fme),e(Fme,aho),e(Xh,nho),e(Xh,QN),e(QN,sho),e(Xh,lho),e(A,iho),e(A,zh),e(zh,Tme),e(Tme,dho),e(zh,cho),e(zh,WN),e(WN,mho),e(zh,fho),e(Pr,gho),M(Qh,Pr,null),e($o,hho),e($o,Wh),M($9,Wh,null),e(Wh,uho),e(Wh,Mme),e(Mme,pho),b(m,qYe,_),b(m,fd,_),e(fd,Uh),e(Uh,Eme),M(k9,Eme,null),e(fd,_ho),e(fd,Cme),e(Cme,bho),b(m,jYe,_),b(m,ko,_),M(S9,ko,null),e(ko,vho),e(ko,R9),e(R9,Fho),e(R9,UN),e(UN,Tho),e(R9,Mho),e(ko,Eho),e(ko,P9),e(P9,Cho),e(P9,wme),e(wme,who),e(P9,Aho),e(ko,Lho),e(ko,Br),M(B9,Br,null),e(Br,yho),e(Br,Ame),e(Ame,xho),e(Br,$ho),e(Br,Ua),e(Ua,kho),e(Ua,Lme),e(Lme,Sho),e(Ua,Rho),e(Ua,yme),e(yme,Pho),e(Ua,Bho),e(Ua,xme),e(xme,Iho),e(Ua,Nho),e(Br,qho),e(Br,k),e(k,as),e(as,$me),e($me,jho),e(as,Dho),e(as,HN),e(HN,Gho),e(as,Oho),e(as,JN),e(JN,Vho),e(as,Xho),e(k,zho),e(k,ns),e(ns,kme),e(kme,Qho),e(ns,Who),e(ns,YN),e(YN,Uho),e(ns,Hho),e(ns,KN),e(KN,Jho),e(ns,Yho),e(k,Kho),e(k,ss),e(ss,Sme),e(Sme,Zho),e(ss,euo),e(ss,ZN),e(ZN,ouo),e(ss,ruo),e(ss,eq),e(eq,tuo),e(ss,auo),e(k,nuo),e(k,Hh),e(Hh,Rme),e(Rme,suo),e(Hh,luo),e(Hh,oq),e(oq,iuo),e(Hh,duo),e(k,cuo),e(k,ls),e(ls,Pme),e(Pme,muo),e(ls,fuo),e(ls,rq),e(rq,guo),e(ls,huo),e(ls,tq),e(tq,uuo),e(ls,puo),e(k,_uo),e(k,Jh),e(Jh,Bme),e(Bme,buo),e(Jh,vuo),e(Jh,aq),e(aq,Fuo),e(Jh,Tuo),e(k,Muo),e(k,Yh),e(Yh,Ime),e(Ime,Euo),e(Yh,Cuo),e(Yh,nq),e(nq,wuo),e(Yh,Auo),e(k,Luo),e(k,Kh),e(Kh,Nme),e(Nme,yuo),e(Kh,xuo),e(Kh,sq),e(sq,$uo),e(Kh,kuo),e(k,Suo),e(k,is),e(is,qme),e(qme,Ruo),e(is,Puo),e(is,lq),e(lq,Buo),e(is,Iuo),e(is,iq),e(iq,Nuo),e(is,quo),e(k,juo),e(k,ds),e(ds,jme),e(jme,Duo),e(ds,Guo),e(ds,dq),e(dq,Ouo),e(ds,Vuo),e(ds,cq),e(cq,Xuo),e(ds,zuo),e(k,Quo),e(k,cs),e(cs,Dme),e(Dme,Wuo),e(cs,Uuo),e(cs,mq),e(mq,Huo),e(cs,Juo),e(cs,fq),e(fq,Yuo),e(cs,Kuo),e(k,Zuo),e(k,Zh),e(Zh,Gme),e(Gme,epo),e(Zh,opo),e(Zh,gq),e(gq,rpo),e(Zh,tpo),e(k,apo),e(k,eu),e(eu,Ome),e(Ome,npo),e(eu,spo),e(eu,hq),e(hq,lpo),e(eu,ipo),e(k,dpo),e(k,ou),e(ou,Vme),e(Vme,cpo),e(ou,mpo),e(ou,uq),e(uq,fpo),e(ou,gpo),e(k,hpo),e(k,ms),e(ms,Xme),e(Xme,upo),e(ms,ppo),e(ms,pq),e(pq,_po),e(ms,bpo),e(ms,_q),e(_q,vpo),e(ms,Fpo),e(k,Tpo),e(k,ru),e(ru,zme),e(zme,Mpo),e(ru,Epo),e(ru,bq),e(bq,Cpo),e(ru,wpo),e(k,Apo),e(k,fs),e(fs,Qme),e(Qme,Lpo),e(fs,ypo),e(fs,vq),e(vq,xpo),e(fs,$po),e(fs,Fq),e(Fq,kpo),e(fs,Spo),e(k,Rpo),e(k,gs),e(gs,Wme),e(Wme,Ppo),e(gs,Bpo),e(gs,Tq),e(Tq,Ipo),e(gs,Npo),e(gs,Mq),e(Mq,qpo),e(gs,jpo),e(k,Dpo),e(k,hs),e(hs,Ume),e(Ume,Gpo),e(hs,Opo),e(hs,Eq),e(Eq,Vpo),e(hs,Xpo),e(hs,Cq),e(Cq,zpo),e(hs,Qpo),e(k,Wpo),e(k,us),e(us,Hme),e(Hme,Upo),e(us,Hpo),e(us,wq),e(wq,Jpo),e(us,Ypo),e(us,Aq),e(Aq,Kpo),e(us,Zpo),e(k,e_o),e(k,tu),e(tu,Jme),e(Jme,o_o),e(tu,r_o),e(tu,Lq),e(Lq,t_o),e(tu,a_o),e(k,n_o),e(k,ps),e(ps,Yme),e(Yme,s_o),e(ps,l_o),e(ps,yq),e(yq,i_o),e(ps,d_o),e(ps,xq),e(xq,c_o),e(ps,m_o),e(k,f_o),e(k,_s),e(_s,Kme),e(Kme,g_o),e(_s,h_o),e(_s,$q),e($q,u_o),e(_s,p_o),e(_s,kq),e(kq,__o),e(_s,b_o),e(k,v_o),e(k,bs),e(bs,Zme),e(Zme,F_o),e(bs,T_o),e(bs,Sq),e(Sq,M_o),e(bs,E_o),e(bs,Rq),e(Rq,C_o),e(bs,w_o),e(k,A_o),e(k,vs),e(vs,efe),e(efe,L_o),e(vs,y_o),e(vs,Pq),e(Pq,x_o),e(vs,$_o),e(vs,Bq),e(Bq,k_o),e(vs,S_o),e(k,R_o),e(k,Fs),e(Fs,ofe),e(ofe,P_o),e(Fs,B_o),e(Fs,Iq),e(Iq,I_o),e(Fs,N_o),e(Fs,Nq),e(Nq,q_o),e(Fs,j_o),e(k,D_o),e(k,Ts),e(Ts,rfe),e(rfe,G_o),e(Ts,O_o),e(Ts,qq),e(qq,V_o),e(Ts,X_o),e(Ts,jq),e(jq,z_o),e(Ts,Q_o),e(k,W_o),e(k,Ms),e(Ms,tfe),e(tfe,U_o),e(Ms,H_o),e(Ms,Dq),e(Dq,J_o),e(Ms,Y_o),e(Ms,Gq),e(Gq,K_o),e(Ms,Z_o),e(k,e2o),e(k,au),e(au,afe),e(afe,o2o),e(au,r2o),e(au,Oq),e(Oq,t2o),e(au,a2o),e(k,n2o),e(k,Es),e(Es,nfe),e(nfe,s2o),e(Es,l2o),e(Es,Vq),e(Vq,i2o),e(Es,d2o),e(Es,Xq),e(Xq,c2o),e(Es,m2o),e(k,f2o),e(k,nu),e(nu,sfe),e(sfe,g2o),e(nu,h2o),e(nu,zq),e(zq,u2o),e(nu,p2o),e(k,_2o),e(k,Cs),e(Cs,lfe),e(lfe,b2o),e(Cs,v2o),e(Cs,Qq),e(Qq,F2o),e(Cs,T2o),e(Cs,Wq),e(Wq,M2o),e(Cs,E2o),e(k,C2o),e(k,ws),e(ws,ife),e(ife,w2o),e(ws,A2o),e(ws,Uq),e(Uq,L2o),e(ws,y2o),e(ws,Hq),e(Hq,x2o),e(ws,$2o),e(k,k2o),e(k,As),e(As,dfe),e(dfe,S2o),e(As,R2o),e(As,Jq),e(Jq,P2o),e(As,B2o),e(As,Yq),e(Yq,I2o),e(As,N2o),e(k,q2o),e(k,su),e(su,cfe),e(cfe,j2o),e(su,D2o),e(su,Kq),e(Kq,G2o),e(su,O2o),e(k,V2o),e(k,Ls),e(Ls,mfe),e(mfe,X2o),e(Ls,z2o),e(Ls,Zq),e(Zq,Q2o),e(Ls,W2o),e(Ls,ej),e(ej,U2o),e(Ls,H2o),e(k,J2o),e(k,ys),e(ys,ffe),e(ffe,Y2o),e(ys,K2o),e(ys,oj),e(oj,Z2o),e(ys,ebo),e(ys,rj),e(rj,obo),e(ys,rbo),e(k,tbo),e(k,xs),e(xs,gfe),e(gfe,abo),e(xs,nbo),e(xs,tj),e(tj,sbo),e(xs,lbo),e(xs,aj),e(aj,ibo),e(xs,dbo),e(k,cbo),e(k,lu),e(lu,hfe),e(hfe,mbo),e(lu,fbo),e(lu,nj),e(nj,gbo),e(lu,hbo),e(k,ubo),e(k,$s),e($s,ufe),e(ufe,pbo),e($s,_bo),e($s,sj),e(sj,bbo),e($s,vbo),e($s,lj),e(lj,Fbo),e($s,Tbo),e(k,Mbo),e(k,ks),e(ks,pfe),e(pfe,Ebo),e(ks,Cbo),e(ks,ij),e(ij,wbo),e(ks,Abo),e(ks,dj),e(dj,Lbo),e(ks,ybo),e(k,xbo),e(k,Ss),e(Ss,_fe),e(_fe,$bo),e(Ss,kbo),e(Ss,cj),e(cj,Sbo),e(Ss,Rbo),e(Ss,mj),e(mj,Pbo),e(Ss,Bbo),e(k,Ibo),e(k,Rs),e(Rs,bfe),e(bfe,Nbo),e(Rs,qbo),e(Rs,fj),e(fj,jbo),e(Rs,Dbo),e(Rs,gj),e(gj,Gbo),e(Rs,Obo),e(k,Vbo),e(k,Ps),e(Ps,vfe),e(vfe,Xbo),e(Ps,zbo),e(Ps,hj),e(hj,Qbo),e(Ps,Wbo),e(Ps,uj),e(uj,Ubo),e(Ps,Hbo),e(k,Jbo),e(k,Bs),e(Bs,Ffe),e(Ffe,Ybo),e(Bs,Kbo),e(Bs,pj),e(pj,Zbo),e(Bs,e1o),e(Bs,_j),e(_j,o1o),e(Bs,r1o),e(k,t1o),e(k,Is),e(Is,Tfe),e(Tfe,a1o),e(Is,n1o),e(Is,bj),e(bj,s1o),e(Is,l1o),e(Is,vj),e(vj,i1o),e(Is,d1o),e(k,c1o),e(k,Ns),e(Ns,Mfe),e(Mfe,m1o),e(Ns,f1o),e(Ns,Fj),e(Fj,g1o),e(Ns,h1o),e(Ns,Tj),e(Tj,u1o),e(Ns,p1o),e(k,_1o),e(k,iu),e(iu,Efe),e(Efe,b1o),e(iu,v1o),e(iu,Mj),e(Mj,F1o),e(iu,T1o),e(k,M1o),e(k,qs),e(qs,Cfe),e(Cfe,E1o),e(qs,C1o),e(qs,Ej),e(Ej,w1o),e(qs,A1o),e(qs,Cj),e(Cj,L1o),e(qs,y1o),e(k,x1o),e(k,du),e(du,wfe),e(wfe,$1o),e(du,k1o),e(du,wj),e(wj,S1o),e(du,R1o),e(k,P1o),e(k,cu),e(cu,Afe),e(Afe,B1o),e(cu,I1o),e(cu,Aj),e(Aj,N1o),e(cu,q1o),e(k,j1o),e(k,js),e(js,Lfe),e(Lfe,D1o),e(js,G1o),e(js,Lj),e(Lj,O1o),e(js,V1o),e(js,yj),e(yj,X1o),e(js,z1o),e(k,Q1o),e(k,Ds),e(Ds,yfe),e(yfe,W1o),e(Ds,U1o),e(Ds,xj),e(xj,H1o),e(Ds,J1o),e(Ds,$j),e($j,Y1o),e(Ds,K1o),e(k,Z1o),e(k,Gs),e(Gs,xfe),e(xfe,evo),e(Gs,ovo),e(Gs,kj),e(kj,rvo),e(Gs,tvo),e(Gs,Sj),e(Sj,avo),e(Gs,nvo),e(k,svo),e(k,mu),e(mu,$fe),e($fe,lvo),e(mu,ivo),e(mu,Rj),e(Rj,dvo),e(mu,cvo),e(k,mvo),e(k,Os),e(Os,kfe),e(kfe,fvo),e(Os,gvo),e(Os,Pj),e(Pj,hvo),e(Os,uvo),e(Os,Bj),e(Bj,pvo),e(Os,_vo),e(k,bvo),e(k,Vs),e(Vs,Sfe),e(Sfe,vvo),e(Vs,Fvo),e(Vs,Ij),e(Ij,Tvo),e(Vs,Mvo),e(Vs,Nj),e(Nj,Evo),e(Vs,Cvo),e(k,wvo),e(k,Xs),e(Xs,Rfe),e(Rfe,Avo),e(Xs,Lvo),e(Xs,qj),e(qj,yvo),e(Xs,xvo),e(Xs,jj),e(jj,$vo),e(Xs,kvo),e(k,Svo),e(k,zs),e(zs,Pfe),e(Pfe,Rvo),e(zs,Pvo),e(zs,Dj),e(Dj,Bvo),e(zs,Ivo),e(zs,Gj),e(Gj,Nvo),e(zs,qvo),e(k,jvo),e(k,Qs),e(Qs,Bfe),e(Bfe,Dvo),e(Qs,Gvo),e(Qs,Oj),e(Oj,Ovo),e(Qs,Vvo),e(Qs,Vj),e(Vj,Xvo),e(Qs,zvo),e(k,Qvo),e(k,Ws),e(Ws,Ife),e(Ife,Wvo),e(Ws,Uvo),e(Ws,Xj),e(Xj,Hvo),e(Ws,Jvo),e(Ws,zj),e(zj,Yvo),e(Ws,Kvo),e(k,Zvo),e(k,Us),e(Us,Nfe),e(Nfe,eFo),e(Us,oFo),e(Us,Qj),e(Qj,rFo),e(Us,tFo),e(Us,Wj),e(Wj,aFo),e(Us,nFo),e(k,sFo),e(k,Hs),e(Hs,qfe),e(qfe,lFo),e(Hs,iFo),e(Hs,Uj),e(Uj,dFo),e(Hs,cFo),e(Hs,Hj),e(Hj,mFo),e(Hs,fFo),e(k,gFo),e(k,fu),e(fu,jfe),e(jfe,hFo),e(fu,uFo),e(fu,Jj),e(Jj,pFo),e(fu,_Fo),e(k,bFo),e(k,Js),e(Js,Dfe),e(Dfe,vFo),e(Js,FFo),e(Js,Yj),e(Yj,TFo),e(Js,MFo),e(Js,Kj),e(Kj,EFo),e(Js,CFo),e(k,wFo),e(k,Ys),e(Ys,Gfe),e(Gfe,AFo),e(Ys,LFo),e(Ys,Zj),e(Zj,yFo),e(Ys,xFo),e(Ys,eD),e(eD,$Fo),e(Ys,kFo),e(k,SFo),e(k,gu),e(gu,Ofe),e(Ofe,RFo),e(gu,PFo),e(gu,oD),e(oD,BFo),e(gu,IFo),e(k,NFo),e(k,hu),e(hu,Vfe),e(Vfe,qFo),e(hu,jFo),e(hu,rD),e(rD,DFo),e(hu,GFo),e(k,OFo),e(k,uu),e(uu,Xfe),e(Xfe,VFo),e(uu,XFo),e(uu,tD),e(tD,zFo),e(uu,QFo),e(k,WFo),e(k,pu),e(pu,zfe),e(zfe,UFo),e(pu,HFo),e(pu,aD),e(aD,JFo),e(pu,YFo),e(k,KFo),e(k,Ks),e(Ks,Qfe),e(Qfe,ZFo),e(Ks,eTo),e(Ks,nD),e(nD,oTo),e(Ks,rTo),e(Ks,sD),e(sD,tTo),e(Ks,aTo),e(k,nTo),e(k,_u),e(_u,Wfe),e(Wfe,sTo),e(_u,lTo),e(_u,lD),e(lD,iTo),e(_u,dTo),e(k,cTo),e(k,Zs),e(Zs,Ufe),e(Ufe,mTo),e(Zs,fTo),e(Zs,iD),e(iD,gTo),e(Zs,hTo),e(Zs,dD),e(dD,uTo),e(Zs,pTo),e(k,_To),e(k,el),e(el,Hfe),e(Hfe,bTo),e(el,vTo),e(el,cD),e(cD,FTo),e(el,TTo),e(el,mD),e(mD,MTo),e(el,ETo),e(k,CTo),e(k,ol),e(ol,Jfe),e(Jfe,wTo),e(ol,ATo),e(ol,fD),e(fD,LTo),e(ol,yTo),e(ol,gD),e(gD,xTo),e(ol,$To),e(k,kTo),e(k,rl),e(rl,Yfe),e(Yfe,STo),e(rl,RTo),e(rl,hD),e(hD,PTo),e(rl,BTo),e(rl,uD),e(uD,ITo),e(rl,NTo),e(k,qTo),e(k,tl),e(tl,Kfe),e(Kfe,jTo),e(tl,DTo),e(tl,pD),e(pD,GTo),e(tl,OTo),e(tl,_D),e(_D,VTo),e(tl,XTo),e(k,zTo),e(k,al),e(al,Zfe),e(Zfe,QTo),e(al,WTo),e(al,bD),e(bD,UTo),e(al,HTo),e(al,vD),e(vD,JTo),e(al,YTo),e(k,KTo),e(k,bu),e(bu,ege),e(ege,ZTo),e(bu,eMo),e(bu,FD),e(FD,oMo),e(bu,rMo),e(k,tMo),e(k,vu),e(vu,oge),e(oge,aMo),e(vu,nMo),e(vu,TD),e(TD,sMo),e(vu,lMo),e(k,iMo),e(k,nl),e(nl,rge),e(rge,dMo),e(nl,cMo),e(nl,MD),e(MD,mMo),e(nl,fMo),e(nl,ED),e(ED,gMo),e(nl,hMo),e(k,uMo),e(k,sl),e(sl,tge),e(tge,pMo),e(sl,_Mo),e(sl,CD),e(CD,bMo),e(sl,vMo),e(sl,wD),e(wD,FMo),e(sl,TMo),e(k,MMo),e(k,ll),e(ll,age),e(age,EMo),e(ll,CMo),e(ll,AD),e(AD,wMo),e(ll,AMo),e(ll,LD),e(LD,LMo),e(ll,yMo),e(k,xMo),e(k,Fu),e(Fu,nge),e(nge,$Mo),e(Fu,kMo),e(Fu,yD),e(yD,SMo),e(Fu,RMo),e(k,PMo),e(k,Tu),e(Tu,sge),e(sge,BMo),e(Tu,IMo),e(Tu,xD),e(xD,NMo),e(Tu,qMo),e(k,jMo),e(k,Mu),e(Mu,lge),e(lge,DMo),e(Mu,GMo),e(Mu,$D),e($D,OMo),e(Mu,VMo),e(k,XMo),e(k,il),e(il,ige),e(ige,zMo),e(il,QMo),e(il,kD),e(kD,WMo),e(il,UMo),e(il,SD),e(SD,HMo),e(il,JMo),e(k,YMo),e(k,dl),e(dl,dge),e(dge,KMo),e(dl,ZMo),e(dl,RD),e(RD,eEo),e(dl,oEo),e(dl,PD),e(PD,rEo),e(dl,tEo),e(k,aEo),e(k,Eu),e(Eu,cge),e(cge,nEo),e(Eu,sEo),e(Eu,BD),e(BD,lEo),e(Eu,iEo),e(k,dEo),e(k,Cu),e(Cu,mge),e(mge,cEo),e(Cu,mEo),e(Cu,ID),e(ID,fEo),e(Cu,gEo),e(k,hEo),e(k,wu),e(wu,fge),e(fge,uEo),e(wu,pEo),e(wu,ND),e(ND,_Eo),e(wu,bEo),e(k,vEo),e(k,cl),e(cl,gge),e(gge,FEo),e(cl,TEo),e(cl,qD),e(qD,MEo),e(cl,EEo),e(cl,jD),e(jD,CEo),e(cl,wEo),e(k,AEo),e(k,ml),e(ml,hge),e(hge,LEo),e(ml,yEo),e(ml,DD),e(DD,xEo),e(ml,$Eo),e(ml,GD),e(GD,kEo),e(ml,SEo),e(k,REo),e(k,Au),e(Au,uge),e(uge,PEo),e(Au,BEo),e(Au,OD),e(OD,IEo),e(Au,NEo),e(k,qEo),e(k,Lu),e(Lu,pge),e(pge,jEo),e(Lu,DEo),e(Lu,VD),e(VD,GEo),e(Lu,OEo),e(k,VEo),e(k,fl),e(fl,_ge),e(_ge,XEo),e(fl,zEo),e(fl,XD),e(XD,QEo),e(fl,WEo),e(fl,zD),e(zD,UEo),e(fl,HEo),e(k,JEo),e(k,gl),e(gl,bge),e(bge,YEo),e(gl,KEo),e(gl,QD),e(QD,ZEo),e(gl,e4o),e(gl,WD),e(WD,o4o),e(gl,r4o),e(k,t4o),e(k,hl),e(hl,vge),e(vge,a4o),e(hl,n4o),e(hl,UD),e(UD,s4o),e(hl,l4o),e(hl,HD),e(HD,i4o),e(hl,d4o),e(k,c4o),e(k,ul),e(ul,Fge),e(Fge,m4o),e(ul,f4o),e(ul,JD),e(JD,g4o),e(ul,h4o),e(ul,YD),e(YD,u4o),e(ul,p4o),e(Br,_4o),M(yu,Br,null),e(ko,b4o),e(ko,xu),M(I9,xu,null),e(xu,v4o),e(xu,Tge),e(Tge,F4o),b(m,DYe,_),b(m,gd,_),e(gd,$u),e($u,Mge),M(N9,Mge,null),e(gd,T4o),e(gd,Ege),e(Ege,M4o),b(m,GYe,_),b(m,So,_),M(q9,So,null),e(So,E4o),e(So,j9),e(j9,C4o),e(j9,KD),e(KD,w4o),e(j9,A4o),e(So,L4o),e(So,D9),e(D9,y4o),e(D9,Cge),e(Cge,x4o),e(D9,$4o),e(So,k4o),e(So,Ye),M(G9,Ye,null),e(Ye,S4o),e(Ye,wge),e(wge,R4o),e(Ye,P4o),e(Ye,Ha),e(Ha,B4o),e(Ha,Age),e(Age,I4o),e(Ha,N4o),e(Ha,Lge),e(Lge,q4o),e(Ha,j4o),e(Ha,yge),e(yge,D4o),e(Ha,G4o),e(Ye,O4o),e(Ye,W),e(W,ku),e(ku,xge),e(xge,V4o),e(ku,X4o),e(ku,ZD),e(ZD,z4o),e(ku,Q4o),e(W,W4o),e(W,Su),e(Su,$ge),e($ge,U4o),e(Su,H4o),e(Su,eG),e(eG,J4o),e(Su,Y4o),e(W,K4o),e(W,Ru),e(Ru,kge),e(kge,Z4o),e(Ru,eCo),e(Ru,oG),e(oG,oCo),e(Ru,rCo),e(W,tCo),e(W,Pu),e(Pu,Sge),e(Sge,aCo),e(Pu,nCo),e(Pu,rG),e(rG,sCo),e(Pu,lCo),e(W,iCo),e(W,Bu),e(Bu,Rge),e(Rge,dCo),e(Bu,cCo),e(Bu,tG),e(tG,mCo),e(Bu,fCo),e(W,gCo),e(W,Iu),e(Iu,Pge),e(Pge,hCo),e(Iu,uCo),e(Iu,aG),e(aG,pCo),e(Iu,_Co),e(W,bCo),e(W,Nu),e(Nu,Bge),e(Bge,vCo),e(Nu,FCo),e(Nu,nG),e(nG,TCo),e(Nu,MCo),e(W,ECo),e(W,qu),e(qu,Ige),e(Ige,CCo),e(qu,wCo),e(qu,sG),e(sG,ACo),e(qu,LCo),e(W,yCo),e(W,ju),e(ju,Nge),e(Nge,xCo),e(ju,$Co),e(ju,lG),e(lG,kCo),e(ju,SCo),e(W,RCo),e(W,Du),e(Du,qge),e(qge,PCo),e(Du,BCo),e(Du,iG),e(iG,ICo),e(Du,NCo),e(W,qCo),e(W,Gu),e(Gu,jge),e(jge,jCo),e(Gu,DCo),e(Gu,dG),e(dG,GCo),e(Gu,OCo),e(W,VCo),e(W,Ou),e(Ou,Dge),e(Dge,XCo),e(Ou,zCo),e(Ou,cG),e(cG,QCo),e(Ou,WCo),e(W,UCo),e(W,Vu),e(Vu,Gge),e(Gge,HCo),e(Vu,JCo),e(Vu,mG),e(mG,YCo),e(Vu,KCo),e(W,ZCo),e(W,Xu),e(Xu,Oge),e(Oge,e3o),e(Xu,o3o),e(Xu,fG),e(fG,r3o),e(Xu,t3o),e(W,a3o),e(W,zu),e(zu,Vge),e(Vge,n3o),e(zu,s3o),e(zu,gG),e(gG,l3o),e(zu,i3o),e(W,d3o),e(W,Qu),e(Qu,Xge),e(Xge,c3o),e(Qu,m3o),e(Qu,hG),e(hG,f3o),e(Qu,g3o),e(W,h3o),e(W,Wu),e(Wu,zge),e(zge,u3o),e(Wu,p3o),e(Wu,uG),e(uG,_3o),e(Wu,b3o),e(W,v3o),e(W,Uu),e(Uu,Qge),e(Qge,F3o),e(Uu,T3o),e(Uu,pG),e(pG,M3o),e(Uu,E3o),e(W,C3o),e(W,Hu),e(Hu,Wge),e(Wge,w3o),e(Hu,A3o),e(Hu,_G),e(_G,L3o),e(Hu,y3o),e(W,x3o),e(W,Ju),e(Ju,Uge),e(Uge,$3o),e(Ju,k3o),e(Ju,bG),e(bG,S3o),e(Ju,R3o),e(W,P3o),e(W,Yu),e(Yu,Hge),e(Hge,B3o),e(Yu,I3o),e(Yu,vG),e(vG,N3o),e(Yu,q3o),e(W,j3o),e(W,Ku),e(Ku,Jge),e(Jge,D3o),e(Ku,G3o),e(Ku,FG),e(FG,O3o),e(Ku,V3o),e(W,X3o),e(W,Zu),e(Zu,Yge),e(Yge,z3o),e(Zu,Q3o),e(Zu,TG),e(TG,W3o),e(Zu,U3o),e(W,H3o),e(W,ep),e(ep,Kge),e(Kge,J3o),e(ep,Y3o),e(ep,MG),e(MG,K3o),e(ep,Z3o),e(W,e5o),e(W,op),e(op,Zge),e(Zge,o5o),e(op,r5o),e(op,EG),e(EG,t5o),e(op,a5o),e(W,n5o),e(W,rp),e(rp,ehe),e(ehe,s5o),e(rp,l5o),e(rp,CG),e(CG,i5o),e(rp,d5o),e(W,c5o),e(W,tp),e(tp,ohe),e(ohe,m5o),e(tp,f5o),e(tp,wG),e(wG,g5o),e(tp,h5o),e(W,u5o),e(W,ap),e(ap,rhe),e(rhe,p5o),e(ap,_5o),e(ap,AG),e(AG,b5o),e(ap,v5o),e(W,F5o),e(W,np),e(np,the),e(the,T5o),e(np,M5o),e(np,LG),e(LG,E5o),e(np,C5o),e(W,w5o),e(W,sp),e(sp,ahe),e(ahe,A5o),e(sp,L5o),e(sp,yG),e(yG,y5o),e(sp,x5o),e(W,$5o),e(W,lp),e(lp,nhe),e(nhe,k5o),e(lp,S5o),e(lp,xG),e(xG,R5o),e(lp,P5o),e(W,B5o),e(W,ip),e(ip,she),e(she,I5o),e(ip,N5o),e(ip,$G),e($G,q5o),e(ip,j5o),e(W,D5o),e(W,dp),e(dp,lhe),e(lhe,G5o),e(dp,O5o),e(dp,kG),e(kG,V5o),e(dp,X5o),e(W,z5o),e(W,cp),e(cp,ihe),e(ihe,Q5o),e(cp,W5o),e(cp,SG),e(SG,U5o),e(cp,H5o),e(W,J5o),e(W,mp),e(mp,dhe),e(dhe,Y5o),e(mp,K5o),e(mp,RG),e(RG,Z5o),e(mp,e0o),e(W,o0o),e(W,fp),e(fp,che),e(che,r0o),e(fp,t0o),e(fp,PG),e(PG,a0o),e(fp,n0o),e(W,s0o),e(W,gp),e(gp,mhe),e(mhe,l0o),e(gp,i0o),e(gp,BG),e(BG,d0o),e(gp,c0o),e(W,m0o),e(W,hp),e(hp,fhe),e(fhe,f0o),e(hp,g0o),e(hp,IG),e(IG,h0o),e(hp,u0o),e(W,p0o),e(W,up),e(up,ghe),e(ghe,_0o),e(up,b0o),e(up,NG),e(NG,v0o),e(up,F0o),e(Ye,T0o),M(pp,Ye,null),e(Ye,M0o),M(_p,Ye,null),e(So,E0o),e(So,bp),M(O9,bp,null),e(bp,C0o),e(bp,hhe),e(hhe,w0o),b(m,OYe,_),b(m,hd,_),e(hd,vp),e(vp,uhe),M(V9,uhe,null),e(hd,A0o),e(hd,phe),e(phe,L0o),b(m,VYe,_),b(m,Ro,_),M(X9,Ro,null),e(Ro,y0o),e(Ro,z9),e(z9,x0o),e(z9,qG),e(qG,$0o),e(z9,k0o),e(Ro,S0o),e(Ro,Q9),e(Q9,R0o),e(Q9,_he),e(_he,P0o),e(Q9,B0o),e(Ro,I0o),e(Ro,Ke),M(W9,Ke,null),e(Ke,N0o),e(Ke,bhe),e(bhe,q0o),e(Ke,j0o),e(Ke,ud),e(ud,D0o),e(ud,vhe),e(vhe,G0o),e(ud,O0o),e(ud,Fhe),e(Fhe,V0o),e(ud,X0o),e(Ke,z0o),e(Ke,ie),e(ie,Fp),e(Fp,The),e(The,Q0o),e(Fp,W0o),e(Fp,jG),e(jG,U0o),e(Fp,H0o),e(ie,J0o),e(ie,Tp),e(Tp,Mhe),e(Mhe,Y0o),e(Tp,K0o),e(Tp,DG),e(DG,Z0o),e(Tp,ewo),e(ie,owo),e(ie,Mp),e(Mp,Ehe),e(Ehe,rwo),e(Mp,two),e(Mp,GG),e(GG,awo),e(Mp,nwo),e(ie,swo),e(ie,Ep),e(Ep,Che),e(Che,lwo),e(Ep,iwo),e(Ep,OG),e(OG,dwo),e(Ep,cwo),e(ie,mwo),e(ie,Cp),e(Cp,whe),e(whe,fwo),e(Cp,gwo),e(Cp,VG),e(VG,hwo),e(Cp,uwo),e(ie,pwo),e(ie,wp),e(wp,Ahe),e(Ahe,_wo),e(wp,bwo),e(wp,XG),e(XG,vwo),e(wp,Fwo),e(ie,Two),e(ie,Ap),e(Ap,Lhe),e(Lhe,Mwo),e(Ap,Ewo),e(Ap,zG),e(zG,Cwo),e(Ap,wwo),e(ie,Awo),e(ie,Lp),e(Lp,yhe),e(yhe,Lwo),e(Lp,ywo),e(Lp,QG),e(QG,xwo),e(Lp,$wo),e(ie,kwo),e(ie,yp),e(yp,xhe),e(xhe,Swo),e(yp,Rwo),e(yp,WG),e(WG,Pwo),e(yp,Bwo),e(ie,Iwo),e(ie,xp),e(xp,$he),e($he,Nwo),e(xp,qwo),e(xp,UG),e(UG,jwo),e(xp,Dwo),e(ie,Gwo),e(ie,$p),e($p,khe),e(khe,Owo),e($p,Vwo),e($p,HG),e(HG,Xwo),e($p,zwo),e(ie,Qwo),e(ie,kp),e(kp,She),e(She,Wwo),e(kp,Uwo),e(kp,JG),e(JG,Hwo),e(kp,Jwo),e(ie,Ywo),e(ie,Sp),e(Sp,Rhe),e(Rhe,Kwo),e(Sp,Zwo),e(Sp,YG),e(YG,eAo),e(Sp,oAo),e(ie,rAo),e(ie,Rp),e(Rp,Phe),e(Phe,tAo),e(Rp,aAo),e(Rp,KG),e(KG,nAo),e(Rp,sAo),e(ie,lAo),e(ie,Pp),e(Pp,Bhe),e(Bhe,iAo),e(Pp,dAo),e(Pp,ZG),e(ZG,cAo),e(Pp,mAo),e(ie,fAo),e(ie,Bp),e(Bp,Ihe),e(Ihe,gAo),e(Bp,hAo),e(Bp,eO),e(eO,uAo),e(Bp,pAo),e(ie,_Ao),e(ie,Ip),e(Ip,Nhe),e(Nhe,bAo),e(Ip,vAo),e(Ip,oO),e(oO,FAo),e(Ip,TAo),e(ie,MAo),e(ie,Np),e(Np,qhe),e(qhe,EAo),e(Np,CAo),e(Np,rO),e(rO,wAo),e(Np,AAo),e(ie,LAo),e(ie,qp),e(qp,jhe),e(jhe,yAo),e(qp,xAo),e(qp,tO),e(tO,$Ao),e(qp,kAo),e(ie,SAo),e(ie,jp),e(jp,Dhe),e(Dhe,RAo),e(jp,PAo),e(jp,aO),e(aO,BAo),e(jp,IAo),e(ie,NAo),e(ie,Dp),e(Dp,Ghe),e(Ghe,qAo),e(Dp,jAo),e(Dp,nO),e(nO,DAo),e(Dp,GAo),e(Ke,OAo),M(Gp,Ke,null),e(Ke,VAo),M(Op,Ke,null),e(Ro,XAo),e(Ro,Vp),M(U9,Vp,null),e(Vp,zAo),e(Vp,Ohe),e(Ohe,QAo),b(m,XYe,_),b(m,pd,_),e(pd,Xp),e(Xp,Vhe),M(H9,Vhe,null),e(pd,WAo),e(pd,Xhe),e(Xhe,UAo),b(m,zYe,_),b(m,Po,_),M(J9,Po,null),e(Po,HAo),e(Po,_d),e(_d,JAo),e(_d,sO),e(sO,YAo),e(_d,KAo),e(_d,lO),e(lO,ZAo),e(_d,e6o),e(Po,o6o),e(Po,Y9),e(Y9,r6o),e(Y9,zhe),e(zhe,t6o),e(Y9,a6o),e(Po,n6o),e(Po,_t),M(K9,_t,null),e(_t,s6o),e(_t,Qhe),e(Qhe,l6o),e(_t,i6o),e(_t,bd),e(bd,d6o),e(bd,Whe),e(Whe,c6o),e(bd,m6o),e(bd,iO),e(iO,f6o),e(bd,g6o),e(_t,h6o),M(zp,_t,null),e(Po,u6o),e(Po,Ze),M(Z9,Ze,null),e(Ze,p6o),e(Ze,Uhe),e(Uhe,_6o),e(Ze,b6o),e(Ze,Ja),e(Ja,v6o),e(Ja,Hhe),e(Hhe,F6o),e(Ja,T6o),e(Ja,Jhe),e(Jhe,M6o),e(Ja,E6o),e(Ja,Yhe),e(Yhe,C6o),e(Ja,w6o),e(Ze,A6o),e(Ze,y),e(y,Qp),e(Qp,Khe),e(Khe,L6o),e(Qp,y6o),e(Qp,dO),e(dO,x6o),e(Qp,$6o),e(y,k6o),e(y,Wp),e(Wp,Zhe),e(Zhe,S6o),e(Wp,R6o),e(Wp,cO),e(cO,P6o),e(Wp,B6o),e(y,I6o),e(y,Up),e(Up,eue),e(eue,N6o),e(Up,q6o),e(Up,mO),e(mO,j6o),e(Up,D6o),e(y,G6o),e(y,Hp),e(Hp,oue),e(oue,O6o),e(Hp,V6o),e(Hp,fO),e(fO,X6o),e(Hp,z6o),e(y,Q6o),e(y,Jp),e(Jp,rue),e(rue,W6o),e(Jp,U6o),e(Jp,gO),e(gO,H6o),e(Jp,J6o),e(y,Y6o),e(y,Yp),e(Yp,tue),e(tue,K6o),e(Yp,Z6o),e(Yp,hO),e(hO,e7o),e(Yp,o7o),e(y,r7o),e(y,Kp),e(Kp,aue),e(aue,t7o),e(Kp,a7o),e(Kp,uO),e(uO,n7o),e(Kp,s7o),e(y,l7o),e(y,Zp),e(Zp,nue),e(nue,i7o),e(Zp,d7o),e(Zp,pO),e(pO,c7o),e(Zp,m7o),e(y,f7o),e(y,e_),e(e_,sue),e(sue,g7o),e(e_,h7o),e(e_,_O),e(_O,u7o),e(e_,p7o),e(y,_7o),e(y,o_),e(o_,lue),e(lue,b7o),e(o_,v7o),e(o_,bO),e(bO,F7o),e(o_,T7o),e(y,M7o),e(y,r_),e(r_,iue),e(iue,E7o),e(r_,C7o),e(r_,vO),e(vO,w7o),e(r_,A7o),e(y,L7o),e(y,t_),e(t_,due),e(due,y7o),e(t_,x7o),e(t_,FO),e(FO,$7o),e(t_,k7o),e(y,S7o),e(y,a_),e(a_,cue),e(cue,R7o),e(a_,P7o),e(a_,TO),e(TO,B7o),e(a_,I7o),e(y,N7o),e(y,n_),e(n_,mue),e(mue,q7o),e(n_,j7o),e(n_,MO),e(MO,D7o),e(n_,G7o),e(y,O7o),e(y,s_),e(s_,fue),e(fue,V7o),e(s_,X7o),e(s_,EO),e(EO,z7o),e(s_,Q7o),e(y,W7o),e(y,l_),e(l_,gue),e(gue,U7o),e(l_,H7o),e(l_,CO),e(CO,J7o),e(l_,Y7o),e(y,K7o),e(y,i_),e(i_,hue),e(hue,Z7o),e(i_,eLo),e(i_,wO),e(wO,oLo),e(i_,rLo),e(y,tLo),e(y,d_),e(d_,uue),e(uue,aLo),e(d_,nLo),e(d_,AO),e(AO,sLo),e(d_,lLo),e(y,iLo),e(y,c_),e(c_,pue),e(pue,dLo),e(c_,cLo),e(c_,LO),e(LO,mLo),e(c_,fLo),e(y,gLo),e(y,m_),e(m_,_ue),e(_ue,hLo),e(m_,uLo),e(m_,yO),e(yO,pLo),e(m_,_Lo),e(y,bLo),e(y,f_),e(f_,bue),e(bue,vLo),e(f_,FLo),e(f_,xO),e(xO,TLo),e(f_,MLo),e(y,ELo),e(y,g_),e(g_,vue),e(vue,CLo),e(g_,wLo),e(g_,$O),e($O,ALo),e(g_,LLo),e(y,yLo),e(y,h_),e(h_,Fue),e(Fue,xLo),e(h_,$Lo),e(h_,kO),e(kO,kLo),e(h_,SLo),e(y,RLo),e(y,u_),e(u_,Tue),e(Tue,PLo),e(u_,BLo),e(u_,SO),e(SO,ILo),e(u_,NLo),e(y,qLo),e(y,p_),e(p_,Mue),e(Mue,jLo),e(p_,DLo),e(p_,RO),e(RO,GLo),e(p_,OLo),e(y,VLo),e(y,__),e(__,Eue),e(Eue,XLo),e(__,zLo),e(__,PO),e(PO,QLo),e(__,WLo),e(y,ULo),e(y,b_),e(b_,Cue),e(Cue,HLo),e(b_,JLo),e(b_,BO),e(BO,YLo),e(b_,KLo),e(y,ZLo),e(y,v_),e(v_,wue),e(wue,eyo),e(v_,oyo),e(v_,IO),e(IO,ryo),e(v_,tyo),e(y,ayo),e(y,F_),e(F_,Aue),e(Aue,nyo),e(F_,syo),e(F_,NO),e(NO,lyo),e(F_,iyo),e(y,dyo),e(y,T_),e(T_,Lue),e(Lue,cyo),e(T_,myo),e(T_,qO),e(qO,fyo),e(T_,gyo),e(y,hyo),e(y,M_),e(M_,yue),e(yue,uyo),e(M_,pyo),e(M_,jO),e(jO,_yo),e(M_,byo),e(y,vyo),e(y,E_),e(E_,xue),e(xue,Fyo),e(E_,Tyo),e(E_,DO),e(DO,Myo),e(E_,Eyo),e(y,Cyo),e(y,C_),e(C_,$ue),e($ue,wyo),e(C_,Ayo),e(C_,GO),e(GO,Lyo),e(C_,yyo),e(y,xyo),e(y,w_),e(w_,kue),e(kue,$yo),e(w_,kyo),e(w_,OO),e(OO,Syo),e(w_,Ryo),e(y,Pyo),e(y,A_),e(A_,Sue),e(Sue,Byo),e(A_,Iyo),e(A_,VO),e(VO,Nyo),e(A_,qyo),e(y,jyo),e(y,L_),e(L_,Rue),e(Rue,Dyo),e(L_,Gyo),e(L_,XO),e(XO,Oyo),e(L_,Vyo),e(y,Xyo),e(y,pl),e(pl,Pue),e(Pue,zyo),e(pl,Qyo),e(pl,zO),e(zO,Wyo),e(pl,Uyo),e(pl,QO),e(QO,Hyo),e(pl,Jyo),e(y,Yyo),e(y,y_),e(y_,Bue),e(Bue,Kyo),e(y_,Zyo),e(y_,WO),e(WO,e8o),e(y_,o8o),e(y,r8o),e(y,x_),e(x_,Iue),e(Iue,t8o),e(x_,a8o),e(x_,UO),e(UO,n8o),e(x_,s8o),e(y,l8o),e(y,$_),e($_,Nue),e(Nue,i8o),e($_,d8o),e($_,HO),e(HO,c8o),e($_,m8o),e(y,f8o),e(y,k_),e(k_,que),e(que,g8o),e(k_,h8o),e(k_,JO),e(JO,u8o),e(k_,p8o),e(y,_8o),e(y,S_),e(S_,jue),e(jue,b8o),e(S_,v8o),e(S_,YO),e(YO,F8o),e(S_,T8o),e(y,M8o),e(y,R_),e(R_,Due),e(Due,E8o),e(R_,C8o),e(R_,KO),e(KO,w8o),e(R_,A8o),e(y,L8o),e(y,P_),e(P_,Gue),e(Gue,y8o),e(P_,x8o),e(P_,ZO),e(ZO,$8o),e(P_,k8o),e(y,S8o),e(y,B_),e(B_,Oue),e(Oue,R8o),e(B_,P8o),e(B_,eV),e(eV,B8o),e(B_,I8o),e(y,N8o),e(y,I_),e(I_,Vue),e(Vue,q8o),e(I_,j8o),e(I_,oV),e(oV,D8o),e(I_,G8o),e(y,O8o),e(y,N_),e(N_,Xue),e(Xue,V8o),e(N_,X8o),e(N_,rV),e(rV,z8o),e(N_,Q8o),e(y,W8o),e(y,q_),e(q_,zue),e(zue,U8o),e(q_,H8o),e(q_,tV),e(tV,J8o),e(q_,Y8o),e(y,K8o),e(y,j_),e(j_,Que),e(Que,Z8o),e(j_,e9o),e(j_,aV),e(aV,o9o),e(j_,r9o),e(y,t9o),e(y,D_),e(D_,Wue),e(Wue,a9o),e(D_,n9o),e(D_,nV),e(nV,s9o),e(D_,l9o),e(y,i9o),e(y,G_),e(G_,Uue),e(Uue,d9o),e(G_,c9o),e(G_,sV),e(sV,m9o),e(G_,f9o),e(y,g9o),e(y,O_),e(O_,Hue),e(Hue,h9o),e(O_,u9o),e(O_,lV),e(lV,p9o),e(O_,_9o),e(y,b9o),e(y,V_),e(V_,Jue),e(Jue,v9o),e(V_,F9o),e(V_,iV),e(iV,T9o),e(V_,M9o),e(y,E9o),e(y,X_),e(X_,Yue),e(Yue,C9o),e(X_,w9o),e(X_,dV),e(dV,A9o),e(X_,L9o),e(y,y9o),e(y,z_),e(z_,Kue),e(Kue,x9o),e(z_,$9o),e(z_,cV),e(cV,k9o),e(z_,S9o),e(y,R9o),e(y,Q_),e(Q_,Zue),e(Zue,P9o),e(Q_,B9o),e(Q_,mV),e(mV,I9o),e(Q_,N9o),e(y,q9o),e(y,W_),e(W_,epe),e(epe,j9o),e(W_,D9o),e(W_,fV),e(fV,G9o),e(W_,O9o),e(y,V9o),e(y,U_),e(U_,ope),e(ope,X9o),e(U_,z9o),e(U_,gV),e(gV,Q9o),e(U_,W9o),e(y,U9o),e(y,H_),e(H_,rpe),e(rpe,H9o),e(H_,J9o),e(H_,hV),e(hV,Y9o),e(H_,K9o),e(y,Z9o),e(y,J_),e(J_,tpe),e(tpe,exo),e(J_,oxo),e(J_,uV),e(uV,rxo),e(J_,txo),e(y,axo),e(y,Y_),e(Y_,ape),e(ape,nxo),e(Y_,sxo),e(Y_,pV),e(pV,lxo),e(Y_,ixo),e(y,dxo),e(y,K_),e(K_,npe),e(npe,cxo),e(K_,mxo),e(K_,_V),e(_V,fxo),e(K_,gxo),e(y,hxo),e(y,Z_),e(Z_,spe),e(spe,uxo),e(Z_,pxo),e(Z_,bV),e(bV,_xo),e(Z_,bxo),e(y,vxo),e(y,e2),e(e2,lpe),e(lpe,Fxo),e(e2,Txo),e(e2,vV),e(vV,Mxo),e(e2,Exo),e(y,Cxo),e(y,o2),e(o2,ipe),e(ipe,wxo),e(o2,Axo),e(o2,FV),e(FV,Lxo),e(o2,yxo),e(y,xxo),e(y,r2),e(r2,dpe),e(dpe,$xo),e(r2,kxo),e(r2,TV),e(TV,Sxo),e(r2,Rxo),e(y,Pxo),e(y,t2),e(t2,cpe),e(cpe,Bxo),e(t2,Ixo),e(t2,MV),e(MV,Nxo),e(t2,qxo),e(y,jxo),e(y,a2),e(a2,mpe),e(mpe,Dxo),e(a2,Gxo),e(a2,EV),e(EV,Oxo),e(a2,Vxo),e(y,Xxo),e(y,n2),e(n2,fpe),e(fpe,zxo),e(n2,Qxo),e(n2,CV),e(CV,Wxo),e(n2,Uxo),e(y,Hxo),e(y,s2),e(s2,gpe),e(gpe,Jxo),e(s2,Yxo),e(s2,wV),e(wV,Kxo),e(s2,Zxo),e(y,e$o),e(y,l2),e(l2,hpe),e(hpe,o$o),e(l2,r$o),e(l2,AV),e(AV,t$o),e(l2,a$o),e(y,n$o),e(y,i2),e(i2,upe),e(upe,s$o),e(i2,l$o),e(i2,LV),e(LV,i$o),e(i2,d$o),e(y,c$o),e(y,d2),e(d2,ppe),e(ppe,m$o),e(d2,f$o),e(d2,yV),e(yV,g$o),e(d2,h$o),e(y,u$o),e(y,c2),e(c2,_pe),e(_pe,p$o),e(c2,_$o),e(c2,xV),e(xV,b$o),e(c2,v$o),e(y,F$o),e(y,m2),e(m2,bpe),e(bpe,T$o),e(m2,M$o),e(m2,$V),e($V,E$o),e(m2,C$o),e(y,w$o),e(y,f2),e(f2,vpe),e(vpe,A$o),e(f2,L$o),e(f2,kV),e(kV,y$o),e(f2,x$o),e(y,$$o),e(y,g2),e(g2,Fpe),e(Fpe,k$o),e(g2,S$o),e(g2,SV),e(SV,R$o),e(g2,P$o),e(y,B$o),e(y,h2),e(h2,Tpe),e(Tpe,I$o),e(h2,N$o),e(h2,RV),e(RV,q$o),e(h2,j$o),e(y,D$o),e(y,u2),e(u2,Mpe),e(Mpe,G$o),e(u2,O$o),e(u2,PV),e(PV,V$o),e(u2,X$o),e(y,z$o),e(y,p2),e(p2,Epe),e(Epe,Q$o),e(p2,W$o),e(p2,BV),e(BV,U$o),e(p2,H$o),e(y,J$o),e(y,_2),e(_2,Cpe),e(Cpe,Y$o),e(_2,K$o),e(_2,IV),e(IV,Z$o),e(_2,eko),e(y,oko),e(y,b2),e(b2,wpe),e(wpe,rko),e(b2,tko),e(b2,NV),e(NV,ako),e(b2,nko),e(y,sko),e(y,v2),e(v2,Ape),e(Ape,lko),e(v2,iko),e(v2,qV),e(qV,dko),e(v2,cko),e(y,mko),e(y,F2),e(F2,Lpe),e(Lpe,fko),e(F2,gko),e(F2,jV),e(jV,hko),e(F2,uko),e(y,pko),e(y,T2),e(T2,ype),e(ype,_ko),e(T2,bko),e(T2,DV),e(DV,vko),e(T2,Fko),e(y,Tko),e(y,M2),e(M2,xpe),e(xpe,Mko),e(M2,Eko),e(M2,GV),e(GV,Cko),e(M2,wko),e(y,Ako),e(y,E2),e(E2,$pe),e($pe,Lko),e(E2,yko),e(E2,OV),e(OV,xko),e(E2,$ko),e(y,kko),e(y,C2),e(C2,kpe),e(kpe,Sko),e(C2,Rko),e(C2,VV),e(VV,Pko),e(C2,Bko),e(y,Iko),e(y,w2),e(w2,Spe),e(Spe,Nko),e(w2,qko),e(w2,XV),e(XV,jko),e(w2,Dko),e(y,Gko),e(y,A2),e(A2,Rpe),e(Rpe,Oko),e(A2,Vko),e(A2,zV),e(zV,Xko),e(A2,zko),e(y,Qko),e(y,L2),e(L2,Ppe),e(Ppe,Wko),e(L2,Uko),e(L2,QV),e(QV,Hko),e(L2,Jko),e(y,Yko),e(y,y2),e(y2,Bpe),e(Bpe,Kko),e(y2,Zko),e(y2,WV),e(WV,eSo),e(y2,oSo),e(y,rSo),e(y,x2),e(x2,Ipe),e(Ipe,tSo),e(x2,aSo),e(x2,UV),e(UV,nSo),e(x2,sSo),e(y,lSo),e(y,$2),e($2,Npe),e(Npe,iSo),e($2,dSo),e($2,HV),e(HV,cSo),e($2,mSo),e(y,fSo),e(y,k2),e(k2,qpe),e(qpe,gSo),e(k2,hSo),e(k2,JV),e(JV,uSo),e(k2,pSo),e(y,_So),e(y,S2),e(S2,jpe),e(jpe,bSo),e(S2,vSo),e(S2,YV),e(YV,FSo),e(S2,TSo),e(y,MSo),e(y,R2),e(R2,Dpe),e(Dpe,ESo),e(R2,CSo),e(R2,KV),e(KV,wSo),e(R2,ASo),e(y,LSo),e(y,P2),e(P2,Gpe),e(Gpe,ySo),e(P2,xSo),e(P2,ZV),e(ZV,$So),e(P2,kSo),e(y,SSo),e(y,B2),e(B2,Ope),e(Ope,RSo),e(B2,PSo),e(B2,eX),e(eX,BSo),e(B2,ISo),e(y,NSo),e(y,I2),e(I2,Vpe),e(Vpe,qSo),e(I2,jSo),e(I2,oX),e(oX,DSo),e(I2,GSo),e(y,OSo),e(y,N2),e(N2,Xpe),e(Xpe,VSo),e(N2,XSo),e(N2,rX),e(rX,zSo),e(N2,QSo),e(y,WSo),e(y,q2),e(q2,zpe),e(zpe,USo),e(q2,HSo),e(q2,tX),e(tX,JSo),e(q2,YSo),e(y,KSo),e(y,j2),e(j2,Qpe),e(Qpe,ZSo),e(j2,eRo),e(j2,aX),e(aX,oRo),e(j2,rRo),e(y,tRo),e(y,D2),e(D2,Wpe),e(Wpe,aRo),e(D2,nRo),e(D2,nX),e(nX,sRo),e(D2,lRo),e(y,iRo),e(y,G2),e(G2,Upe),e(Upe,dRo),e(G2,cRo),e(G2,sX),e(sX,mRo),e(G2,fRo),e(y,gRo),e(y,O2),e(O2,Hpe),e(Hpe,hRo),e(O2,uRo),e(O2,lX),e(lX,pRo),e(O2,_Ro),e(y,bRo),e(y,V2),e(V2,Jpe),e(Jpe,vRo),e(V2,FRo),e(V2,iX),e(iX,TRo),e(V2,MRo),e(y,ERo),e(y,X2),e(X2,Ype),e(Ype,CRo),e(X2,wRo),e(X2,dX),e(dX,ARo),e(X2,LRo),e(y,yRo),e(y,z2),e(z2,Kpe),e(Kpe,xRo),e(z2,$Ro),e(z2,cX),e(cX,kRo),e(z2,SRo),e(y,RRo),e(y,Q2),e(Q2,Zpe),e(Zpe,PRo),e(Q2,BRo),e(Q2,mX),e(mX,IRo),e(Q2,NRo),e(y,qRo),e(y,W2),e(W2,e_e),e(e_e,jRo),e(W2,DRo),e(W2,fX),e(fX,GRo),e(W2,ORo),e(y,VRo),e(y,U2),e(U2,o_e),e(o_e,XRo),e(U2,zRo),e(U2,gX),e(gX,QRo),e(U2,WRo),e(y,URo),e(y,H2),e(H2,r_e),e(r_e,HRo),e(H2,JRo),e(H2,hX),e(hX,YRo),e(H2,KRo),e(y,ZRo),e(y,J2),e(J2,t_e),e(t_e,ePo),e(J2,oPo),e(J2,uX),e(uX,rPo),e(J2,tPo),e(y,aPo),e(y,Y2),e(Y2,a_e),e(a_e,nPo),e(Y2,sPo),e(Y2,pX),e(pX,lPo),e(Y2,iPo),e(y,dPo),e(y,K2),e(K2,n_e),e(n_e,cPo),e(K2,mPo),e(K2,_X),e(_X,fPo),e(K2,gPo),e(y,hPo),e(y,Z2),e(Z2,s_e),e(s_e,uPo),e(Z2,pPo),e(Z2,bX),e(bX,_Po),e(Z2,bPo),e(y,vPo),e(y,eb),e(eb,l_e),e(l_e,FPo),e(eb,TPo),e(eb,vX),e(vX,MPo),e(eb,EPo),e(y,CPo),e(y,ob),e(ob,i_e),e(i_e,wPo),e(ob,APo),e(ob,FX),e(FX,LPo),e(ob,yPo),e(Ze,xPo),e(Ze,rb),e(rb,$Po),e(rb,d_e),e(d_e,kPo),e(rb,SPo),e(rb,c_e),e(c_e,RPo),e(Ze,PPo),M(tb,Ze,null),b(m,QYe,_),b(m,vd,_),e(vd,ab),e(ab,m_e),M(ex,m_e,null),e(vd,BPo),e(vd,f_e),e(f_e,IPo),b(m,WYe,_),b(m,Bo,_),M(ox,Bo,null),e(Bo,NPo),e(Bo,Fd),e(Fd,qPo),e(Fd,TX),e(TX,jPo),e(Fd,DPo),e(Fd,MX),e(MX,GPo),e(Fd,OPo),e(Bo,VPo),e(Bo,rx),e(rx,XPo),e(rx,g_e),e(g_e,zPo),e(rx,QPo),e(Bo,WPo),e(Bo,bt),M(tx,bt,null),e(bt,UPo),e(bt,h_e),e(h_e,HPo),e(bt,JPo),e(bt,Td),e(Td,YPo),e(Td,u_e),e(u_e,KPo),e(Td,ZPo),e(Td,EX),e(EX,eBo),e(Td,oBo),e(bt,rBo),M(nb,bt,null),e(Bo,tBo),e(Bo,eo),M(ax,eo,null),e(eo,aBo),e(eo,p_e),e(p_e,nBo),e(eo,sBo),e(eo,Ya),e(Ya,lBo),e(Ya,__e),e(__e,iBo),e(Ya,dBo),e(Ya,b_e),e(b_e,cBo),e(Ya,mBo),e(Ya,v_e),e(v_e,fBo),e(Ya,gBo),e(eo,hBo),e(eo,G),e(G,sb),e(sb,F_e),e(F_e,uBo),e(sb,pBo),e(sb,CX),e(CX,_Bo),e(sb,bBo),e(G,vBo),e(G,lb),e(lb,T_e),e(T_e,FBo),e(lb,TBo),e(lb,wX),e(wX,MBo),e(lb,EBo),e(G,CBo),e(G,ib),e(ib,M_e),e(M_e,wBo),e(ib,ABo),e(ib,AX),e(AX,LBo),e(ib,yBo),e(G,xBo),e(G,db),e(db,E_e),e(E_e,$Bo),e(db,kBo),e(db,LX),e(LX,SBo),e(db,RBo),e(G,PBo),e(G,cb),e(cb,C_e),e(C_e,BBo),e(cb,IBo),e(cb,yX),e(yX,NBo),e(cb,qBo),e(G,jBo),e(G,mb),e(mb,w_e),e(w_e,DBo),e(mb,GBo),e(mb,xX),e(xX,OBo),e(mb,VBo),e(G,XBo),e(G,fb),e(fb,A_e),e(A_e,zBo),e(fb,QBo),e(fb,$X),e($X,WBo),e(fb,UBo),e(G,HBo),e(G,gb),e(gb,L_e),e(L_e,JBo),e(gb,YBo),e(gb,kX),e(kX,KBo),e(gb,ZBo),e(G,eIo),e(G,hb),e(hb,y_e),e(y_e,oIo),e(hb,rIo),e(hb,SX),e(SX,tIo),e(hb,aIo),e(G,nIo),e(G,ub),e(ub,x_e),e(x_e,sIo),e(ub,lIo),e(ub,RX),e(RX,iIo),e(ub,dIo),e(G,cIo),e(G,pb),e(pb,$_e),e($_e,mIo),e(pb,fIo),e(pb,PX),e(PX,gIo),e(pb,hIo),e(G,uIo),e(G,_b),e(_b,k_e),e(k_e,pIo),e(_b,_Io),e(_b,BX),e(BX,bIo),e(_b,vIo),e(G,FIo),e(G,bb),e(bb,S_e),e(S_e,TIo),e(bb,MIo),e(bb,IX),e(IX,EIo),e(bb,CIo),e(G,wIo),e(G,vb),e(vb,R_e),e(R_e,AIo),e(vb,LIo),e(vb,NX),e(NX,yIo),e(vb,xIo),e(G,$Io),e(G,Fb),e(Fb,P_e),e(P_e,kIo),e(Fb,SIo),e(Fb,qX),e(qX,RIo),e(Fb,PIo),e(G,BIo),e(G,Tb),e(Tb,B_e),e(B_e,IIo),e(Tb,NIo),e(Tb,jX),e(jX,qIo),e(Tb,jIo),e(G,DIo),e(G,Mb),e(Mb,I_e),e(I_e,GIo),e(Mb,OIo),e(Mb,DX),e(DX,VIo),e(Mb,XIo),e(G,zIo),e(G,Eb),e(Eb,N_e),e(N_e,QIo),e(Eb,WIo),e(Eb,GX),e(GX,UIo),e(Eb,HIo),e(G,JIo),e(G,Cb),e(Cb,q_e),e(q_e,YIo),e(Cb,KIo),e(Cb,OX),e(OX,ZIo),e(Cb,eNo),e(G,oNo),e(G,wb),e(wb,j_e),e(j_e,rNo),e(wb,tNo),e(wb,VX),e(VX,aNo),e(wb,nNo),e(G,sNo),e(G,Ab),e(Ab,D_e),e(D_e,lNo),e(Ab,iNo),e(Ab,XX),e(XX,dNo),e(Ab,cNo),e(G,mNo),e(G,Lb),e(Lb,G_e),e(G_e,fNo),e(Lb,gNo),e(Lb,zX),e(zX,hNo),e(Lb,uNo),e(G,pNo),e(G,yb),e(yb,O_e),e(O_e,_No),e(yb,bNo),e(yb,QX),e(QX,vNo),e(yb,FNo),e(G,TNo),e(G,xb),e(xb,V_e),e(V_e,MNo),e(xb,ENo),e(xb,WX),e(WX,CNo),e(xb,wNo),e(G,ANo),e(G,$b),e($b,X_e),e(X_e,LNo),e($b,yNo),e($b,UX),e(UX,xNo),e($b,$No),e(G,kNo),e(G,kb),e(kb,z_e),e(z_e,SNo),e(kb,RNo),e(kb,HX),e(HX,PNo),e(kb,BNo),e(G,INo),e(G,Sb),e(Sb,Q_e),e(Q_e,NNo),e(Sb,qNo),e(Sb,JX),e(JX,jNo),e(Sb,DNo),e(G,GNo),e(G,Rb),e(Rb,W_e),e(W_e,ONo),e(Rb,VNo),e(Rb,YX),e(YX,XNo),e(Rb,zNo),e(G,QNo),e(G,Pb),e(Pb,U_e),e(U_e,WNo),e(Pb,UNo),e(Pb,KX),e(KX,HNo),e(Pb,JNo),e(G,YNo),e(G,Bb),e(Bb,H_e),e(H_e,KNo),e(Bb,ZNo),e(Bb,ZX),e(ZX,eqo),e(Bb,oqo),e(G,rqo),e(G,Ib),e(Ib,J_e),e(J_e,tqo),e(Ib,aqo),e(Ib,ez),e(ez,nqo),e(Ib,sqo),e(G,lqo),e(G,Nb),e(Nb,Y_e),e(Y_e,iqo),e(Nb,dqo),e(Nb,oz),e(oz,cqo),e(Nb,mqo),e(G,fqo),e(G,qb),e(qb,K_e),e(K_e,gqo),e(qb,hqo),e(qb,rz),e(rz,uqo),e(qb,pqo),e(G,_qo),e(G,jb),e(jb,Z_e),e(Z_e,bqo),e(jb,vqo),e(jb,tz),e(tz,Fqo),e(jb,Tqo),e(G,Mqo),e(G,Db),e(Db,e2e),e(e2e,Eqo),e(Db,Cqo),e(Db,az),e(az,wqo),e(Db,Aqo),e(G,Lqo),e(G,Gb),e(Gb,o2e),e(o2e,yqo),e(Gb,xqo),e(Gb,nz),e(nz,$qo),e(Gb,kqo),e(G,Sqo),e(G,Ob),e(Ob,r2e),e(r2e,Rqo),e(Ob,Pqo),e(Ob,sz),e(sz,Bqo),e(Ob,Iqo),e(G,Nqo),e(G,Vb),e(Vb,t2e),e(t2e,qqo),e(Vb,jqo),e(Vb,lz),e(lz,Dqo),e(Vb,Gqo),e(G,Oqo),e(G,Xb),e(Xb,a2e),e(a2e,Vqo),e(Xb,Xqo),e(Xb,iz),e(iz,zqo),e(Xb,Qqo),e(G,Wqo),e(G,zb),e(zb,n2e),e(n2e,Uqo),e(zb,Hqo),e(zb,dz),e(dz,Jqo),e(zb,Yqo),e(G,Kqo),e(G,Qb),e(Qb,s2e),e(s2e,Zqo),e(Qb,ejo),e(Qb,cz),e(cz,ojo),e(Qb,rjo),e(G,tjo),e(G,Wb),e(Wb,l2e),e(l2e,ajo),e(Wb,njo),e(Wb,mz),e(mz,sjo),e(Wb,ljo),e(G,ijo),e(G,Ub),e(Ub,i2e),e(i2e,djo),e(Ub,cjo),e(Ub,fz),e(fz,mjo),e(Ub,fjo),e(G,gjo),e(G,Hb),e(Hb,d2e),e(d2e,hjo),e(Hb,ujo),e(Hb,gz),e(gz,pjo),e(Hb,_jo),e(G,bjo),e(G,Jb),e(Jb,c2e),e(c2e,vjo),e(Jb,Fjo),e(Jb,hz),e(hz,Tjo),e(Jb,Mjo),e(G,Ejo),e(G,Yb),e(Yb,m2e),e(m2e,Cjo),e(Yb,wjo),e(Yb,uz),e(uz,Ajo),e(Yb,Ljo),e(G,yjo),e(G,Kb),e(Kb,f2e),e(f2e,xjo),e(Kb,$jo),e(Kb,pz),e(pz,kjo),e(Kb,Sjo),e(G,Rjo),e(G,Zb),e(Zb,g2e),e(g2e,Pjo),e(Zb,Bjo),e(Zb,_z),e(_z,Ijo),e(Zb,Njo),e(eo,qjo),e(eo,e1),e(e1,jjo),e(e1,h2e),e(h2e,Djo),e(e1,Gjo),e(e1,u2e),e(u2e,Ojo),e(eo,Vjo),M(o1,eo,null),b(m,UYe,_),b(m,Md,_),e(Md,r1),e(r1,p2e),M(nx,p2e,null),e(Md,Xjo),e(Md,_2e),e(_2e,zjo),b(m,HYe,_),b(m,Io,_),M(sx,Io,null),e(Io,Qjo),e(Io,Ed),e(Ed,Wjo),e(Ed,bz),e(bz,Ujo),e(Ed,Hjo),e(Ed,vz),e(vz,Jjo),e(Ed,Yjo),e(Io,Kjo),e(Io,lx),e(lx,Zjo),e(lx,b2e),e(b2e,eDo),e(lx,oDo),e(Io,rDo),e(Io,vt),M(ix,vt,null),e(vt,tDo),e(vt,v2e),e(v2e,aDo),e(vt,nDo),e(vt,Cd),e(Cd,sDo),e(Cd,F2e),e(F2e,lDo),e(Cd,iDo),e(Cd,Fz),e(Fz,dDo),e(Cd,cDo),e(vt,mDo),M(t1,vt,null),e(Io,fDo),e(Io,oo),M(dx,oo,null),e(oo,gDo),e(oo,T2e),e(T2e,hDo),e(oo,uDo),e(oo,Ka),e(Ka,pDo),e(Ka,M2e),e(M2e,_Do),e(Ka,bDo),e(Ka,E2e),e(E2e,vDo),e(Ka,FDo),e(Ka,C2e),e(C2e,TDo),e(Ka,MDo),e(oo,EDo),e(oo,z),e(z,a1),e(a1,w2e),e(w2e,CDo),e(a1,wDo),e(a1,Tz),e(Tz,ADo),e(a1,LDo),e(z,yDo),e(z,n1),e(n1,A2e),e(A2e,xDo),e(n1,$Do),e(n1,Mz),e(Mz,kDo),e(n1,SDo),e(z,RDo),e(z,s1),e(s1,L2e),e(L2e,PDo),e(s1,BDo),e(s1,Ez),e(Ez,IDo),e(s1,NDo),e(z,qDo),e(z,l1),e(l1,y2e),e(y2e,jDo),e(l1,DDo),e(l1,Cz),e(Cz,GDo),e(l1,ODo),e(z,VDo),e(z,i1),e(i1,x2e),e(x2e,XDo),e(i1,zDo),e(i1,wz),e(wz,QDo),e(i1,WDo),e(z,UDo),e(z,d1),e(d1,$2e),e($2e,HDo),e(d1,JDo),e(d1,Az),e(Az,YDo),e(d1,KDo),e(z,ZDo),e(z,c1),e(c1,k2e),e(k2e,eGo),e(c1,oGo),e(c1,Lz),e(Lz,rGo),e(c1,tGo),e(z,aGo),e(z,m1),e(m1,S2e),e(S2e,nGo),e(m1,sGo),e(m1,yz),e(yz,lGo),e(m1,iGo),e(z,dGo),e(z,f1),e(f1,R2e),e(R2e,cGo),e(f1,mGo),e(f1,xz),e(xz,fGo),e(f1,gGo),e(z,hGo),e(z,g1),e(g1,P2e),e(P2e,uGo),e(g1,pGo),e(g1,$z),e($z,_Go),e(g1,bGo),e(z,vGo),e(z,h1),e(h1,B2e),e(B2e,FGo),e(h1,TGo),e(h1,kz),e(kz,MGo),e(h1,EGo),e(z,CGo),e(z,u1),e(u1,I2e),e(I2e,wGo),e(u1,AGo),e(u1,Sz),e(Sz,LGo),e(u1,yGo),e(z,xGo),e(z,p1),e(p1,N2e),e(N2e,$Go),e(p1,kGo),e(p1,Rz),e(Rz,SGo),e(p1,RGo),e(z,PGo),e(z,_1),e(_1,q2e),e(q2e,BGo),e(_1,IGo),e(_1,Pz),e(Pz,NGo),e(_1,qGo),e(z,jGo),e(z,b1),e(b1,j2e),e(j2e,DGo),e(b1,GGo),e(b1,Bz),e(Bz,OGo),e(b1,VGo),e(z,XGo),e(z,v1),e(v1,D2e),e(D2e,zGo),e(v1,QGo),e(v1,Iz),e(Iz,WGo),e(v1,UGo),e(z,HGo),e(z,F1),e(F1,G2e),e(G2e,JGo),e(F1,YGo),e(F1,Nz),e(Nz,KGo),e(F1,ZGo),e(z,eOo),e(z,T1),e(T1,O2e),e(O2e,oOo),e(T1,rOo),e(T1,qz),e(qz,tOo),e(T1,aOo),e(z,nOo),e(z,M1),e(M1,V2e),e(V2e,sOo),e(M1,lOo),e(M1,jz),e(jz,iOo),e(M1,dOo),e(z,cOo),e(z,E1),e(E1,X2e),e(X2e,mOo),e(E1,fOo),e(E1,Dz),e(Dz,gOo),e(E1,hOo),e(z,uOo),e(z,C1),e(C1,z2e),e(z2e,pOo),e(C1,_Oo),e(C1,Gz),e(Gz,bOo),e(C1,vOo),e(z,FOo),e(z,w1),e(w1,Q2e),e(Q2e,TOo),e(w1,MOo),e(w1,Oz),e(Oz,EOo),e(w1,COo),e(z,wOo),e(z,A1),e(A1,W2e),e(W2e,AOo),e(A1,LOo),e(A1,Vz),e(Vz,yOo),e(A1,xOo),e(z,$Oo),e(z,L1),e(L1,U2e),e(U2e,kOo),e(L1,SOo),e(L1,Xz),e(Xz,ROo),e(L1,POo),e(z,BOo),e(z,y1),e(y1,H2e),e(H2e,IOo),e(y1,NOo),e(y1,zz),e(zz,qOo),e(y1,jOo),e(z,DOo),e(z,x1),e(x1,J2e),e(J2e,GOo),e(x1,OOo),e(x1,Qz),e(Qz,VOo),e(x1,XOo),e(z,zOo),e(z,$1),e($1,Y2e),e(Y2e,QOo),e($1,WOo),e($1,Wz),e(Wz,UOo),e($1,HOo),e(z,JOo),e(z,k1),e(k1,K2e),e(K2e,YOo),e(k1,KOo),e(k1,Uz),e(Uz,ZOo),e(k1,eVo),e(z,oVo),e(z,S1),e(S1,Z2e),e(Z2e,rVo),e(S1,tVo),e(S1,Hz),e(Hz,aVo),e(S1,nVo),e(z,sVo),e(z,R1),e(R1,ebe),e(ebe,lVo),e(R1,iVo),e(R1,Jz),e(Jz,dVo),e(R1,cVo),e(z,mVo),e(z,P1),e(P1,obe),e(obe,fVo),e(P1,gVo),e(P1,Yz),e(Yz,hVo),e(P1,uVo),e(z,pVo),e(z,B1),e(B1,rbe),e(rbe,_Vo),e(B1,bVo),e(B1,Kz),e(Kz,vVo),e(B1,FVo),e(z,TVo),e(z,I1),e(I1,tbe),e(tbe,MVo),e(I1,EVo),e(I1,Zz),e(Zz,CVo),e(I1,wVo),e(z,AVo),e(z,N1),e(N1,abe),e(abe,LVo),e(N1,yVo),e(N1,eQ),e(eQ,xVo),e(N1,$Vo),e(z,kVo),e(z,q1),e(q1,nbe),e(nbe,SVo),e(q1,RVo),e(q1,oQ),e(oQ,PVo),e(q1,BVo),e(z,IVo),e(z,j1),e(j1,sbe),e(sbe,NVo),e(j1,qVo),e(j1,rQ),e(rQ,jVo),e(j1,DVo),e(z,GVo),e(z,D1),e(D1,lbe),e(lbe,OVo),e(D1,VVo),e(D1,tQ),e(tQ,XVo),e(D1,zVo),e(z,QVo),e(z,G1),e(G1,ibe),e(ibe,WVo),e(G1,UVo),e(G1,aQ),e(aQ,HVo),e(G1,JVo),e(z,YVo),e(z,O1),e(O1,dbe),e(dbe,KVo),e(O1,ZVo),e(O1,nQ),e(nQ,eXo),e(O1,oXo),e(z,rXo),e(z,V1),e(V1,cbe),e(cbe,tXo),e(V1,aXo),e(V1,sQ),e(sQ,nXo),e(V1,sXo),e(z,lXo),e(z,X1),e(X1,mbe),e(mbe,iXo),e(X1,dXo),e(X1,lQ),e(lQ,cXo),e(X1,mXo),e(oo,fXo),e(oo,z1),e(z1,gXo),e(z1,fbe),e(fbe,hXo),e(z1,uXo),e(z1,gbe),e(gbe,pXo),e(oo,_Xo),M(Q1,oo,null),b(m,JYe,_),b(m,wd,_),e(wd,W1),e(W1,hbe),M(cx,hbe,null),e(wd,bXo),e(wd,ube),e(ube,vXo),b(m,YYe,_),b(m,No,_),M(mx,No,null),e(No,FXo),e(No,Ad),e(Ad,TXo),e(Ad,iQ),e(iQ,MXo),e(Ad,EXo),e(Ad,dQ),e(dQ,CXo),e(Ad,wXo),e(No,AXo),e(No,fx),e(fx,LXo),e(fx,pbe),e(pbe,yXo),e(fx,xXo),e(No,$Xo),e(No,Ft),M(gx,Ft,null),e(Ft,kXo),e(Ft,_be),e(_be,SXo),e(Ft,RXo),e(Ft,Ld),e(Ld,PXo),e(Ld,bbe),e(bbe,BXo),e(Ld,IXo),e(Ld,cQ),e(cQ,NXo),e(Ld,qXo),e(Ft,jXo),M(U1,Ft,null),e(No,DXo),e(No,ro),M(hx,ro,null),e(ro,GXo),e(ro,vbe),e(vbe,OXo),e(ro,VXo),e(ro,Za),e(Za,XXo),e(Za,Fbe),e(Fbe,zXo),e(Za,QXo),e(Za,Tbe),e(Tbe,WXo),e(Za,UXo),e(Za,Mbe),e(Mbe,HXo),e(Za,JXo),e(ro,YXo),e(ro,U),e(U,H1),e(H1,Ebe),e(Ebe,KXo),e(H1,ZXo),e(H1,mQ),e(mQ,ezo),e(H1,ozo),e(U,rzo),e(U,J1),e(J1,Cbe),e(Cbe,tzo),e(J1,azo),e(J1,fQ),e(fQ,nzo),e(J1,szo),e(U,lzo),e(U,Y1),e(Y1,wbe),e(wbe,izo),e(Y1,dzo),e(Y1,gQ),e(gQ,czo),e(Y1,mzo),e(U,fzo),e(U,K1),e(K1,Abe),e(Abe,gzo),e(K1,hzo),e(K1,hQ),e(hQ,uzo),e(K1,pzo),e(U,_zo),e(U,Z1),e(Z1,Lbe),e(Lbe,bzo),e(Z1,vzo),e(Z1,uQ),e(uQ,Fzo),e(Z1,Tzo),e(U,Mzo),e(U,ev),e(ev,ybe),e(ybe,Ezo),e(ev,Czo),e(ev,pQ),e(pQ,wzo),e(ev,Azo),e(U,Lzo),e(U,ov),e(ov,xbe),e(xbe,yzo),e(ov,xzo),e(ov,_Q),e(_Q,$zo),e(ov,kzo),e(U,Szo),e(U,rv),e(rv,$be),e($be,Rzo),e(rv,Pzo),e(rv,bQ),e(bQ,Bzo),e(rv,Izo),e(U,Nzo),e(U,tv),e(tv,kbe),e(kbe,qzo),e(tv,jzo),e(tv,vQ),e(vQ,Dzo),e(tv,Gzo),e(U,Ozo),e(U,av),e(av,Sbe),e(Sbe,Vzo),e(av,Xzo),e(av,FQ),e(FQ,zzo),e(av,Qzo),e(U,Wzo),e(U,nv),e(nv,Rbe),e(Rbe,Uzo),e(nv,Hzo),e(nv,TQ),e(TQ,Jzo),e(nv,Yzo),e(U,Kzo),e(U,sv),e(sv,Pbe),e(Pbe,Zzo),e(sv,eQo),e(sv,MQ),e(MQ,oQo),e(sv,rQo),e(U,tQo),e(U,lv),e(lv,Bbe),e(Bbe,aQo),e(lv,nQo),e(lv,EQ),e(EQ,sQo),e(lv,lQo),e(U,iQo),e(U,iv),e(iv,Ibe),e(Ibe,dQo),e(iv,cQo),e(iv,CQ),e(CQ,mQo),e(iv,fQo),e(U,gQo),e(U,dv),e(dv,Nbe),e(Nbe,hQo),e(dv,uQo),e(dv,wQ),e(wQ,pQo),e(dv,_Qo),e(U,bQo),e(U,cv),e(cv,qbe),e(qbe,vQo),e(cv,FQo),e(cv,AQ),e(AQ,TQo),e(cv,MQo),e(U,EQo),e(U,mv),e(mv,jbe),e(jbe,CQo),e(mv,wQo),e(mv,LQ),e(LQ,AQo),e(mv,LQo),e(U,yQo),e(U,fv),e(fv,Dbe),e(Dbe,xQo),e(fv,$Qo),e(fv,yQ),e(yQ,kQo),e(fv,SQo),e(U,RQo),e(U,gv),e(gv,Gbe),e(Gbe,PQo),e(gv,BQo),e(gv,xQ),e(xQ,IQo),e(gv,NQo),e(U,qQo),e(U,hv),e(hv,Obe),e(Obe,jQo),e(hv,DQo),e(hv,$Q),e($Q,GQo),e(hv,OQo),e(U,VQo),e(U,uv),e(uv,Vbe),e(Vbe,XQo),e(uv,zQo),e(uv,kQ),e(kQ,QQo),e(uv,WQo),e(U,UQo),e(U,pv),e(pv,Xbe),e(Xbe,HQo),e(pv,JQo),e(pv,SQ),e(SQ,YQo),e(pv,KQo),e(U,ZQo),e(U,_v),e(_v,zbe),e(zbe,eWo),e(_v,oWo),e(_v,RQ),e(RQ,rWo),e(_v,tWo),e(U,aWo),e(U,bv),e(bv,Qbe),e(Qbe,nWo),e(bv,sWo),e(bv,PQ),e(PQ,lWo),e(bv,iWo),e(U,dWo),e(U,vv),e(vv,Wbe),e(Wbe,cWo),e(vv,mWo),e(vv,BQ),e(BQ,fWo),e(vv,gWo),e(U,hWo),e(U,Fv),e(Fv,Ube),e(Ube,uWo),e(Fv,pWo),e(Fv,IQ),e(IQ,_Wo),e(Fv,bWo),e(U,vWo),e(U,Tv),e(Tv,Hbe),e(Hbe,FWo),e(Tv,TWo),e(Tv,NQ),e(NQ,MWo),e(Tv,EWo),e(U,CWo),e(U,Mv),e(Mv,Jbe),e(Jbe,wWo),e(Mv,AWo),e(Mv,qQ),e(qQ,LWo),e(Mv,yWo),e(U,xWo),e(U,Ev),e(Ev,Ybe),e(Ybe,$Wo),e(Ev,kWo),e(Ev,jQ),e(jQ,SWo),e(Ev,RWo),e(U,PWo),e(U,Cv),e(Cv,Kbe),e(Kbe,BWo),e(Cv,IWo),e(Cv,DQ),e(DQ,NWo),e(Cv,qWo),e(U,jWo),e(U,wv),e(wv,Zbe),e(Zbe,DWo),e(wv,GWo),e(wv,GQ),e(GQ,OWo),e(wv,VWo),e(U,XWo),e(U,Av),e(Av,e1e),e(e1e,zWo),e(Av,QWo),e(Av,OQ),e(OQ,WWo),e(Av,UWo),e(U,HWo),e(U,Lv),e(Lv,o1e),e(o1e,JWo),e(Lv,YWo),e(Lv,VQ),e(VQ,KWo),e(Lv,ZWo),e(U,eUo),e(U,yv),e(yv,r1e),e(r1e,oUo),e(yv,rUo),e(yv,XQ),e(XQ,tUo),e(yv,aUo),e(U,nUo),e(U,xv),e(xv,t1e),e(t1e,sUo),e(xv,lUo),e(xv,a1e),e(a1e,iUo),e(xv,dUo),e(U,cUo),e(U,$v),e($v,n1e),e(n1e,mUo),e($v,fUo),e($v,zQ),e(zQ,gUo),e($v,hUo),e(U,uUo),e(U,kv),e(kv,s1e),e(s1e,pUo),e(kv,_Uo),e(kv,QQ),e(QQ,bUo),e(kv,vUo),e(U,FUo),e(U,Sv),e(Sv,l1e),e(l1e,TUo),e(Sv,MUo),e(Sv,WQ),e(WQ,EUo),e(Sv,CUo),e(U,wUo),e(U,Rv),e(Rv,i1e),e(i1e,AUo),e(Rv,LUo),e(Rv,UQ),e(UQ,yUo),e(Rv,xUo),e(ro,$Uo),e(ro,Pv),e(Pv,kUo),e(Pv,d1e),e(d1e,SUo),e(Pv,RUo),e(Pv,c1e),e(c1e,PUo),e(ro,BUo),M(Bv,ro,null),b(m,KYe,_),b(m,yd,_),e(yd,Iv),e(Iv,m1e),M(ux,m1e,null),e(yd,IUo),e(yd,f1e),e(f1e,NUo),b(m,ZYe,_),b(m,qo,_),M(px,qo,null),e(qo,qUo),e(qo,xd),e(xd,jUo),e(xd,HQ),e(HQ,DUo),e(xd,GUo),e(xd,JQ),e(JQ,OUo),e(xd,VUo),e(qo,XUo),e(qo,_x),e(_x,zUo),e(_x,g1e),e(g1e,QUo),e(_x,WUo),e(qo,UUo),e(qo,Tt),M(bx,Tt,null),e(Tt,HUo),e(Tt,h1e),e(h1e,JUo),e(Tt,YUo),e(Tt,$d),e($d,KUo),e($d,u1e),e(u1e,ZUo),e($d,eHo),e($d,YQ),e(YQ,oHo),e($d,rHo),e(Tt,tHo),M(Nv,Tt,null),e(qo,aHo),e(qo,to),M(vx,to,null),e(to,nHo),e(to,p1e),e(p1e,sHo),e(to,lHo),e(to,en),e(en,iHo),e(en,_1e),e(_1e,dHo),e(en,cHo),e(en,b1e),e(b1e,mHo),e(en,fHo),e(en,v1e),e(v1e,gHo),e(en,hHo),e(to,uHo),e(to,me),e(me,qv),e(qv,F1e),e(F1e,pHo),e(qv,_Ho),e(qv,KQ),e(KQ,bHo),e(qv,vHo),e(me,FHo),e(me,jv),e(jv,T1e),e(T1e,THo),e(jv,MHo),e(jv,ZQ),e(ZQ,EHo),e(jv,CHo),e(me,wHo),e(me,Dv),e(Dv,M1e),e(M1e,AHo),e(Dv,LHo),e(Dv,eW),e(eW,yHo),e(Dv,xHo),e(me,$Ho),e(me,Gv),e(Gv,E1e),e(E1e,kHo),e(Gv,SHo),e(Gv,oW),e(oW,RHo),e(Gv,PHo),e(me,BHo),e(me,Ov),e(Ov,C1e),e(C1e,IHo),e(Ov,NHo),e(Ov,rW),e(rW,qHo),e(Ov,jHo),e(me,DHo),e(me,Vv),e(Vv,w1e),e(w1e,GHo),e(Vv,OHo),e(Vv,tW),e(tW,VHo),e(Vv,XHo),e(me,zHo),e(me,Xv),e(Xv,A1e),e(A1e,QHo),e(Xv,WHo),e(Xv,aW),e(aW,UHo),e(Xv,HHo),e(me,JHo),e(me,zv),e(zv,L1e),e(L1e,YHo),e(zv,KHo),e(zv,nW),e(nW,ZHo),e(zv,eJo),e(me,oJo),e(me,Qv),e(Qv,y1e),e(y1e,rJo),e(Qv,tJo),e(Qv,sW),e(sW,aJo),e(Qv,nJo),e(me,sJo),e(me,Wv),e(Wv,x1e),e(x1e,lJo),e(Wv,iJo),e(Wv,lW),e(lW,dJo),e(Wv,cJo),e(me,mJo),e(me,Uv),e(Uv,$1e),e($1e,fJo),e(Uv,gJo),e(Uv,iW),e(iW,hJo),e(Uv,uJo),e(me,pJo),e(me,Hv),e(Hv,k1e),e(k1e,_Jo),e(Hv,bJo),e(Hv,dW),e(dW,vJo),e(Hv,FJo),e(me,TJo),e(me,Jv),e(Jv,S1e),e(S1e,MJo),e(Jv,EJo),e(Jv,cW),e(cW,CJo),e(Jv,wJo),e(me,AJo),e(me,Yv),e(Yv,R1e),e(R1e,LJo),e(Yv,yJo),e(Yv,mW),e(mW,xJo),e(Yv,$Jo),e(me,kJo),e(me,Kv),e(Kv,P1e),e(P1e,SJo),e(Kv,RJo),e(Kv,fW),e(fW,PJo),e(Kv,BJo),e(me,IJo),e(me,Zv),e(Zv,B1e),e(B1e,NJo),e(Zv,qJo),e(Zv,gW),e(gW,jJo),e(Zv,DJo),e(me,GJo),e(me,eF),e(eF,I1e),e(I1e,OJo),e(eF,VJo),e(eF,hW),e(hW,XJo),e(eF,zJo),e(me,QJo),e(me,oF),e(oF,N1e),e(N1e,WJo),e(oF,UJo),e(oF,uW),e(uW,HJo),e(oF,JJo),e(me,YJo),e(me,rF),e(rF,q1e),e(q1e,KJo),e(rF,ZJo),e(rF,pW),e(pW,eYo),e(rF,oYo),e(me,rYo),e(me,tF),e(tF,j1e),e(j1e,tYo),e(tF,aYo),e(tF,_W),e(_W,nYo),e(tF,sYo),e(to,lYo),e(to,aF),e(aF,iYo),e(aF,D1e),e(D1e,dYo),e(aF,cYo),e(aF,G1e),e(G1e,mYo),e(to,fYo),M(nF,to,null),b(m,eKe,_),b(m,kd,_),e(kd,sF),e(sF,O1e),M(Fx,O1e,null),e(kd,gYo),e(kd,V1e),e(V1e,hYo),b(m,oKe,_),b(m,jo,_),M(Tx,jo,null),e(jo,uYo),e(jo,Sd),e(Sd,pYo),e(Sd,bW),e(bW,_Yo),e(Sd,bYo),e(Sd,vW),e(vW,vYo),e(Sd,FYo),e(jo,TYo),e(jo,Mx),e(Mx,MYo),e(Mx,X1e),e(X1e,EYo),e(Mx,CYo),e(jo,wYo),e(jo,Mt),M(Ex,Mt,null),e(Mt,AYo),e(Mt,z1e),e(z1e,LYo),e(Mt,yYo),e(Mt,Rd),e(Rd,xYo),e(Rd,Q1e),e(Q1e,$Yo),e(Rd,kYo),e(Rd,FW),e(FW,SYo),e(Rd,RYo),e(Mt,PYo),M(lF,Mt,null),e(jo,BYo),e(jo,ao),M(Cx,ao,null),e(ao,IYo),e(ao,W1e),e(W1e,NYo),e(ao,qYo),e(ao,on),e(on,jYo),e(on,U1e),e(U1e,DYo),e(on,GYo),e(on,H1e),e(H1e,OYo),e(on,VYo),e(on,J1e),e(J1e,XYo),e(on,zYo),e(ao,QYo),e(ao,q),e(q,iF),e(iF,Y1e),e(Y1e,WYo),e(iF,UYo),e(iF,TW),e(TW,HYo),e(iF,JYo),e(q,YYo),e(q,dF),e(dF,K1e),e(K1e,KYo),e(dF,ZYo),e(dF,MW),e(MW,eKo),e(dF,oKo),e(q,rKo),e(q,cF),e(cF,Z1e),e(Z1e,tKo),e(cF,aKo),e(cF,EW),e(EW,nKo),e(cF,sKo),e(q,lKo),e(q,mF),e(mF,eve),e(eve,iKo),e(mF,dKo),e(mF,CW),e(CW,cKo),e(mF,mKo),e(q,fKo),e(q,fF),e(fF,ove),e(ove,gKo),e(fF,hKo),e(fF,wW),e(wW,uKo),e(fF,pKo),e(q,_Ko),e(q,gF),e(gF,rve),e(rve,bKo),e(gF,vKo),e(gF,AW),e(AW,FKo),e(gF,TKo),e(q,MKo),e(q,hF),e(hF,tve),e(tve,EKo),e(hF,CKo),e(hF,LW),e(LW,wKo),e(hF,AKo),e(q,LKo),e(q,uF),e(uF,ave),e(ave,yKo),e(uF,xKo),e(uF,yW),e(yW,$Ko),e(uF,kKo),e(q,SKo),e(q,pF),e(pF,nve),e(nve,RKo),e(pF,PKo),e(pF,xW),e(xW,BKo),e(pF,IKo),e(q,NKo),e(q,_F),e(_F,sve),e(sve,qKo),e(_F,jKo),e(_F,$W),e($W,DKo),e(_F,GKo),e(q,OKo),e(q,bF),e(bF,lve),e(lve,VKo),e(bF,XKo),e(bF,kW),e(kW,zKo),e(bF,QKo),e(q,WKo),e(q,vF),e(vF,ive),e(ive,UKo),e(vF,HKo),e(vF,SW),e(SW,JKo),e(vF,YKo),e(q,KKo),e(q,FF),e(FF,dve),e(dve,ZKo),e(FF,eZo),e(FF,RW),e(RW,oZo),e(FF,rZo),e(q,tZo),e(q,TF),e(TF,cve),e(cve,aZo),e(TF,nZo),e(TF,PW),e(PW,sZo),e(TF,lZo),e(q,iZo),e(q,MF),e(MF,mve),e(mve,dZo),e(MF,cZo),e(MF,BW),e(BW,mZo),e(MF,fZo),e(q,gZo),e(q,EF),e(EF,fve),e(fve,hZo),e(EF,uZo),e(EF,IW),e(IW,pZo),e(EF,_Zo),e(q,bZo),e(q,CF),e(CF,gve),e(gve,vZo),e(CF,FZo),e(CF,NW),e(NW,TZo),e(CF,MZo),e(q,EZo),e(q,wF),e(wF,hve),e(hve,CZo),e(wF,wZo),e(wF,qW),e(qW,AZo),e(wF,LZo),e(q,yZo),e(q,AF),e(AF,uve),e(uve,xZo),e(AF,$Zo),e(AF,jW),e(jW,kZo),e(AF,SZo),e(q,RZo),e(q,LF),e(LF,pve),e(pve,PZo),e(LF,BZo),e(LF,DW),e(DW,IZo),e(LF,NZo),e(q,qZo),e(q,yF),e(yF,_ve),e(_ve,jZo),e(yF,DZo),e(yF,GW),e(GW,GZo),e(yF,OZo),e(q,VZo),e(q,xF),e(xF,bve),e(bve,XZo),e(xF,zZo),e(xF,OW),e(OW,QZo),e(xF,WZo),e(q,UZo),e(q,$F),e($F,vve),e(vve,HZo),e($F,JZo),e($F,VW),e(VW,YZo),e($F,KZo),e(q,ZZo),e(q,kF),e(kF,Fve),e(Fve,eer),e(kF,oer),e(kF,XW),e(XW,rer),e(kF,ter),e(q,aer),e(q,SF),e(SF,Tve),e(Tve,ner),e(SF,ser),e(SF,zW),e(zW,ler),e(SF,ier),e(q,der),e(q,RF),e(RF,Mve),e(Mve,cer),e(RF,mer),e(RF,QW),e(QW,fer),e(RF,ger),e(q,her),e(q,PF),e(PF,Eve),e(Eve,uer),e(PF,per),e(PF,WW),e(WW,_er),e(PF,ber),e(q,ver),e(q,BF),e(BF,Cve),e(Cve,Fer),e(BF,Ter),e(BF,UW),e(UW,Mer),e(BF,Eer),e(q,Cer),e(q,IF),e(IF,wve),e(wve,wer),e(IF,Aer),e(IF,HW),e(HW,Ler),e(IF,yer),e(q,xer),e(q,NF),e(NF,Ave),e(Ave,$er),e(NF,ker),e(NF,JW),e(JW,Ser),e(NF,Rer),e(q,Per),e(q,qF),e(qF,Lve),e(Lve,Ber),e(qF,Ier),e(qF,YW),e(YW,Ner),e(qF,qer),e(q,jer),e(q,jF),e(jF,yve),e(yve,Der),e(jF,Ger),e(jF,KW),e(KW,Oer),e(jF,Ver),e(q,Xer),e(q,DF),e(DF,xve),e(xve,zer),e(DF,Qer),e(DF,ZW),e(ZW,Wer),e(DF,Uer),e(q,Her),e(q,GF),e(GF,$ve),e($ve,Jer),e(GF,Yer),e(GF,eU),e(eU,Ker),e(GF,Zer),e(q,eor),e(q,OF),e(OF,kve),e(kve,oor),e(OF,ror),e(OF,oU),e(oU,tor),e(OF,aor),e(q,nor),e(q,VF),e(VF,Sve),e(Sve,sor),e(VF,lor),e(VF,rU),e(rU,ior),e(VF,dor),e(q,cor),e(q,XF),e(XF,Rve),e(Rve,mor),e(XF,gor),e(XF,tU),e(tU,hor),e(XF,uor),e(q,por),e(q,zF),e(zF,Pve),e(Pve,_or),e(zF,bor),e(zF,aU),e(aU,vor),e(zF,For),e(q,Tor),e(q,QF),e(QF,Bve),e(Bve,Mor),e(QF,Eor),e(QF,nU),e(nU,Cor),e(QF,wor),e(q,Aor),e(q,WF),e(WF,Ive),e(Ive,Lor),e(WF,yor),e(WF,sU),e(sU,xor),e(WF,$or),e(q,kor),e(q,UF),e(UF,Nve),e(Nve,Sor),e(UF,Ror),e(UF,lU),e(lU,Por),e(UF,Bor),e(q,Ior),e(q,HF),e(HF,qve),e(qve,Nor),e(HF,qor),e(HF,iU),e(iU,jor),e(HF,Dor),e(q,Gor),e(q,JF),e(JF,jve),e(jve,Oor),e(JF,Vor),e(JF,dU),e(dU,Xor),e(JF,zor),e(q,Qor),e(q,YF),e(YF,Dve),e(Dve,Wor),e(YF,Uor),e(YF,cU),e(cU,Hor),e(YF,Jor),e(q,Yor),e(q,KF),e(KF,Gve),e(Gve,Kor),e(KF,Zor),e(KF,mU),e(mU,err),e(KF,orr),e(q,rrr),e(q,ZF),e(ZF,Ove),e(Ove,trr),e(ZF,arr),e(ZF,fU),e(fU,nrr),e(ZF,srr),e(q,lrr),e(q,eT),e(eT,Vve),e(Vve,irr),e(eT,drr),e(eT,gU),e(gU,crr),e(eT,mrr),e(q,frr),e(q,oT),e(oT,Xve),e(Xve,grr),e(oT,hrr),e(oT,hU),e(hU,urr),e(oT,prr),e(q,_rr),e(q,rT),e(rT,zve),e(zve,brr),e(rT,vrr),e(rT,uU),e(uU,Frr),e(rT,Trr),e(q,Mrr),e(q,tT),e(tT,Qve),e(Qve,Err),e(tT,Crr),e(tT,pU),e(pU,wrr),e(tT,Arr),e(q,Lrr),e(q,aT),e(aT,Wve),e(Wve,yrr),e(aT,xrr),e(aT,_U),e(_U,$rr),e(aT,krr),e(q,Srr),e(q,nT),e(nT,Uve),e(Uve,Rrr),e(nT,Prr),e(nT,bU),e(bU,Brr),e(nT,Irr),e(q,Nrr),e(q,sT),e(sT,Hve),e(Hve,qrr),e(sT,jrr),e(sT,vU),e(vU,Drr),e(sT,Grr),e(ao,Orr),e(ao,lT),e(lT,Vrr),e(lT,Jve),e(Jve,Xrr),e(lT,zrr),e(lT,Yve),e(Yve,Qrr),e(ao,Wrr),M(iT,ao,null),b(m,rKe,_),b(m,Pd,_),e(Pd,dT),e(dT,Kve),M(wx,Kve,null),e(Pd,Urr),e(Pd,Zve),e(Zve,Hrr),b(m,tKe,_),b(m,Do,_),M(Ax,Do,null),e(Do,Jrr),e(Do,Bd),e(Bd,Yrr),e(Bd,FU),e(FU,Krr),e(Bd,Zrr),e(Bd,TU),e(TU,etr),e(Bd,otr),e(Do,rtr),e(Do,Lx),e(Lx,ttr),e(Lx,eFe),e(eFe,atr),e(Lx,ntr),e(Do,str),e(Do,Et),M(yx,Et,null),e(Et,ltr),e(Et,oFe),e(oFe,itr),e(Et,dtr),e(Et,Id),e(Id,ctr),e(Id,rFe),e(rFe,mtr),e(Id,ftr),e(Id,MU),e(MU,gtr),e(Id,htr),e(Et,utr),M(cT,Et,null),e(Do,ptr),e(Do,no),M(xx,no,null),e(no,_tr),e(no,tFe),e(tFe,btr),e(no,vtr),e(no,rn),e(rn,Ftr),e(rn,aFe),e(aFe,Ttr),e(rn,Mtr),e(rn,nFe),e(nFe,Etr),e(rn,Ctr),e(rn,sFe),e(sFe,wtr),e(rn,Atr),e(no,Ltr),e(no,Z),e(Z,mT),e(mT,lFe),e(lFe,ytr),e(mT,xtr),e(mT,EU),e(EU,$tr),e(mT,ktr),e(Z,Str),e(Z,fT),e(fT,iFe),e(iFe,Rtr),e(fT,Ptr),e(fT,CU),e(CU,Btr),e(fT,Itr),e(Z,Ntr),e(Z,gT),e(gT,dFe),e(dFe,qtr),e(gT,jtr),e(gT,wU),e(wU,Dtr),e(gT,Gtr),e(Z,Otr),e(Z,hT),e(hT,cFe),e(cFe,Vtr),e(hT,Xtr),e(hT,AU),e(AU,ztr),e(hT,Qtr),e(Z,Wtr),e(Z,uT),e(uT,mFe),e(mFe,Utr),e(uT,Htr),e(uT,LU),e(LU,Jtr),e(uT,Ytr),e(Z,Ktr),e(Z,pT),e(pT,fFe),e(fFe,Ztr),e(pT,ear),e(pT,yU),e(yU,oar),e(pT,rar),e(Z,tar),e(Z,_T),e(_T,gFe),e(gFe,aar),e(_T,nar),e(_T,xU),e(xU,sar),e(_T,lar),e(Z,iar),e(Z,bT),e(bT,hFe),e(hFe,dar),e(bT,car),e(bT,$U),e($U,mar),e(bT,far),e(Z,gar),e(Z,vT),e(vT,uFe),e(uFe,har),e(vT,uar),e(vT,kU),e(kU,par),e(vT,_ar),e(Z,bar),e(Z,FT),e(FT,pFe),e(pFe,Far),e(FT,Tar),e(FT,SU),e(SU,Mar),e(FT,Ear),e(Z,Car),e(Z,TT),e(TT,_Fe),e(_Fe,war),e(TT,Aar),e(TT,RU),e(RU,Lar),e(TT,yar),e(Z,xar),e(Z,MT),e(MT,bFe),e(bFe,$ar),e(MT,kar),e(MT,PU),e(PU,Sar),e(MT,Rar),e(Z,Par),e(Z,ET),e(ET,vFe),e(vFe,Bar),e(ET,Iar),e(ET,BU),e(BU,Nar),e(ET,qar),e(Z,jar),e(Z,CT),e(CT,FFe),e(FFe,Dar),e(CT,Gar),e(CT,IU),e(IU,Oar),e(CT,Var),e(Z,Xar),e(Z,wT),e(wT,TFe),e(TFe,zar),e(wT,Qar),e(wT,NU),e(NU,War),e(wT,Uar),e(Z,Har),e(Z,AT),e(AT,MFe),e(MFe,Jar),e(AT,Yar),e(AT,qU),e(qU,Kar),e(AT,Zar),e(Z,enr),e(Z,LT),e(LT,EFe),e(EFe,onr),e(LT,rnr),e(LT,jU),e(jU,tnr),e(LT,anr),e(Z,nnr),e(Z,yT),e(yT,CFe),e(CFe,snr),e(yT,lnr),e(yT,DU),e(DU,inr),e(yT,dnr),e(Z,cnr),e(Z,xT),e(xT,wFe),e(wFe,mnr),e(xT,fnr),e(xT,GU),e(GU,gnr),e(xT,hnr),e(Z,unr),e(Z,$T),e($T,AFe),e(AFe,pnr),e($T,_nr),e($T,OU),e(OU,bnr),e($T,vnr),e(Z,Fnr),e(Z,kT),e(kT,LFe),e(LFe,Tnr),e(kT,Mnr),e(kT,VU),e(VU,Enr),e(kT,Cnr),e(Z,wnr),e(Z,ST),e(ST,yFe),e(yFe,Anr),e(ST,Lnr),e(ST,XU),e(XU,ynr),e(ST,xnr),e(Z,$nr),e(Z,RT),e(RT,xFe),e(xFe,knr),e(RT,Snr),e(RT,zU),e(zU,Rnr),e(RT,Pnr),e(Z,Bnr),e(Z,PT),e(PT,$Fe),e($Fe,Inr),e(PT,Nnr),e(PT,QU),e(QU,qnr),e(PT,jnr),e(Z,Dnr),e(Z,BT),e(BT,kFe),e(kFe,Gnr),e(BT,Onr),e(BT,WU),e(WU,Vnr),e(BT,Xnr),e(Z,znr),e(Z,IT),e(IT,SFe),e(SFe,Qnr),e(IT,Wnr),e(IT,UU),e(UU,Unr),e(IT,Hnr),e(Z,Jnr),e(Z,NT),e(NT,RFe),e(RFe,Ynr),e(NT,Knr),e(NT,HU),e(HU,Znr),e(NT,esr),e(Z,osr),e(Z,qT),e(qT,PFe),e(PFe,rsr),e(qT,tsr),e(qT,JU),e(JU,asr),e(qT,nsr),e(Z,ssr),e(Z,jT),e(jT,BFe),e(BFe,lsr),e(jT,isr),e(jT,YU),e(YU,dsr),e(jT,csr),e(Z,msr),e(Z,DT),e(DT,IFe),e(IFe,fsr),e(DT,gsr),e(DT,KU),e(KU,hsr),e(DT,usr),e(Z,psr),e(Z,GT),e(GT,NFe),e(NFe,_sr),e(GT,bsr),e(GT,ZU),e(ZU,vsr),e(GT,Fsr),e(Z,Tsr),e(Z,OT),e(OT,qFe),e(qFe,Msr),e(OT,Esr),e(OT,eH),e(eH,Csr),e(OT,wsr),e(no,Asr),e(no,VT),e(VT,Lsr),e(VT,jFe),e(jFe,ysr),e(VT,xsr),e(VT,DFe),e(DFe,$sr),e(no,ksr),M(XT,no,null),b(m,aKe,_),b(m,Nd,_),e(Nd,zT),e(zT,GFe),M($x,GFe,null),e(Nd,Ssr),e(Nd,OFe),e(OFe,Rsr),b(m,nKe,_),b(m,Go,_),M(kx,Go,null),e(Go,Psr),e(Go,qd),e(qd,Bsr),e(qd,oH),e(oH,Isr),e(qd,Nsr),e(qd,rH),e(rH,qsr),e(qd,jsr),e(Go,Dsr),e(Go,Sx),e(Sx,Gsr),e(Sx,VFe),e(VFe,Osr),e(Sx,Vsr),e(Go,Xsr),e(Go,Ct),M(Rx,Ct,null),e(Ct,zsr),e(Ct,XFe),e(XFe,Qsr),e(Ct,Wsr),e(Ct,jd),e(jd,Usr),e(jd,zFe),e(zFe,Hsr),e(jd,Jsr),e(jd,tH),e(tH,Ysr),e(jd,Ksr),e(Ct,Zsr),M(QT,Ct,null),e(Go,elr),e(Go,so),M(Px,so,null),e(so,olr),e(so,QFe),e(QFe,rlr),e(so,tlr),e(so,tn),e(tn,alr),e(tn,WFe),e(WFe,nlr),e(tn,slr),e(tn,UFe),e(UFe,llr),e(tn,ilr),e(tn,HFe),e(HFe,dlr),e(tn,clr),e(so,mlr),e(so,Ue),e(Ue,WT),e(WT,JFe),e(JFe,flr),e(WT,glr),e(WT,aH),e(aH,hlr),e(WT,ulr),e(Ue,plr),e(Ue,UT),e(UT,YFe),e(YFe,_lr),e(UT,blr),e(UT,nH),e(nH,vlr),e(UT,Flr),e(Ue,Tlr),e(Ue,HT),e(HT,KFe),e(KFe,Mlr),e(HT,Elr),e(HT,sH),e(sH,Clr),e(HT,wlr),e(Ue,Alr),e(Ue,JT),e(JT,ZFe),e(ZFe,Llr),e(JT,ylr),e(JT,lH),e(lH,xlr),e(JT,$lr),e(Ue,klr),e(Ue,YT),e(YT,eTe),e(eTe,Slr),e(YT,Rlr),e(YT,iH),e(iH,Plr),e(YT,Blr),e(Ue,Ilr),e(Ue,KT),e(KT,oTe),e(oTe,Nlr),e(KT,qlr),e(KT,dH),e(dH,jlr),e(KT,Dlr),e(Ue,Glr),e(Ue,ZT),e(ZT,rTe),e(rTe,Olr),e(ZT,Vlr),e(ZT,cH),e(cH,Xlr),e(ZT,zlr),e(so,Qlr),e(so,eM),e(eM,Wlr),e(eM,tTe),e(tTe,Ulr),e(eM,Hlr),e(eM,aTe),e(aTe,Jlr),e(so,Ylr),M(oM,so,null),b(m,sKe,_),b(m,Dd,_),e(Dd,rM),e(rM,nTe),M(Bx,nTe,null),e(Dd,Klr),e(Dd,sTe),e(sTe,Zlr),b(m,lKe,_),b(m,Oo,_),M(Ix,Oo,null),e(Oo,eir),e(Oo,Gd),e(Gd,oir),e(Gd,mH),e(mH,rir),e(Gd,tir),e(Gd,fH),e(fH,air),e(Gd,nir),e(Oo,sir),e(Oo,Nx),e(Nx,lir),e(Nx,lTe),e(lTe,iir),e(Nx,dir),e(Oo,cir),e(Oo,wt),M(qx,wt,null),e(wt,mir),e(wt,iTe),e(iTe,fir),e(wt,gir),e(wt,Od),e(Od,hir),e(Od,dTe),e(dTe,uir),e(Od,pir),e(Od,gH),e(gH,_ir),e(Od,bir),e(wt,vir),M(tM,wt,null),e(Oo,Fir),e(Oo,lo),M(jx,lo,null),e(lo,Tir),e(lo,cTe),e(cTe,Mir),e(lo,Eir),e(lo,an),e(an,Cir),e(an,mTe),e(mTe,wir),e(an,Air),e(an,fTe),e(fTe,Lir),e(an,yir),e(an,gTe),e(gTe,xir),e(an,$ir),e(lo,kir),e(lo,H),e(H,aM),e(aM,hTe),e(hTe,Sir),e(aM,Rir),e(aM,hH),e(hH,Pir),e(aM,Bir),e(H,Iir),e(H,nM),e(nM,uTe),e(uTe,Nir),e(nM,qir),e(nM,uH),e(uH,jir),e(nM,Dir),e(H,Gir),e(H,sM),e(sM,pTe),e(pTe,Oir),e(sM,Vir),e(sM,pH),e(pH,Xir),e(sM,zir),e(H,Qir),e(H,lM),e(lM,_Te),e(_Te,Wir),e(lM,Uir),e(lM,_H),e(_H,Hir),e(lM,Jir),e(H,Yir),e(H,iM),e(iM,bTe),e(bTe,Kir),e(iM,Zir),e(iM,bH),e(bH,edr),e(iM,odr),e(H,rdr),e(H,dM),e(dM,vTe),e(vTe,tdr),e(dM,adr),e(dM,vH),e(vH,ndr),e(dM,sdr),e(H,ldr),e(H,cM),e(cM,FTe),e(FTe,idr),e(cM,ddr),e(cM,FH),e(FH,cdr),e(cM,mdr),e(H,fdr),e(H,mM),e(mM,TTe),e(TTe,gdr),e(mM,hdr),e(mM,TH),e(TH,udr),e(mM,pdr),e(H,_dr),e(H,fM),e(fM,MTe),e(MTe,bdr),e(fM,vdr),e(fM,MH),e(MH,Fdr),e(fM,Tdr),e(H,Mdr),e(H,gM),e(gM,ETe),e(ETe,Edr),e(gM,Cdr),e(gM,EH),e(EH,wdr),e(gM,Adr),e(H,Ldr),e(H,hM),e(hM,CTe),e(CTe,ydr),e(hM,xdr),e(hM,CH),e(CH,$dr),e(hM,kdr),e(H,Sdr),e(H,uM),e(uM,wTe),e(wTe,Rdr),e(uM,Pdr),e(uM,wH),e(wH,Bdr),e(uM,Idr),e(H,Ndr),e(H,pM),e(pM,ATe),e(ATe,qdr),e(pM,jdr),e(pM,AH),e(AH,Ddr),e(pM,Gdr),e(H,Odr),e(H,_M),e(_M,LTe),e(LTe,Vdr),e(_M,Xdr),e(_M,LH),e(LH,zdr),e(_M,Qdr),e(H,Wdr),e(H,bM),e(bM,yTe),e(yTe,Udr),e(bM,Hdr),e(bM,yH),e(yH,Jdr),e(bM,Ydr),e(H,Kdr),e(H,vM),e(vM,xTe),e(xTe,Zdr),e(vM,ecr),e(vM,xH),e(xH,ocr),e(vM,rcr),e(H,tcr),e(H,FM),e(FM,$Te),e($Te,acr),e(FM,ncr),e(FM,$H),e($H,scr),e(FM,lcr),e(H,icr),e(H,TM),e(TM,kTe),e(kTe,dcr),e(TM,ccr),e(TM,kH),e(kH,mcr),e(TM,fcr),e(H,gcr),e(H,MM),e(MM,STe),e(STe,hcr),e(MM,ucr),e(MM,SH),e(SH,pcr),e(MM,_cr),e(H,bcr),e(H,EM),e(EM,RTe),e(RTe,vcr),e(EM,Fcr),e(EM,RH),e(RH,Tcr),e(EM,Mcr),e(H,Ecr),e(H,CM),e(CM,PTe),e(PTe,Ccr),e(CM,wcr),e(CM,PH),e(PH,Acr),e(CM,Lcr),e(H,ycr),e(H,wM),e(wM,BTe),e(BTe,xcr),e(wM,$cr),e(wM,BH),e(BH,kcr),e(wM,Scr),e(H,Rcr),e(H,AM),e(AM,ITe),e(ITe,Pcr),e(AM,Bcr),e(AM,IH),e(IH,Icr),e(AM,Ncr),e(H,qcr),e(H,LM),e(LM,NTe),e(NTe,jcr),e(LM,Dcr),e(LM,NH),e(NH,Gcr),e(LM,Ocr),e(H,Vcr),e(H,yM),e(yM,qTe),e(qTe,Xcr),e(yM,zcr),e(yM,qH),e(qH,Qcr),e(yM,Wcr),e(H,Ucr),e(H,xM),e(xM,jTe),e(jTe,Hcr),e(xM,Jcr),e(xM,jH),e(jH,Ycr),e(xM,Kcr),e(H,Zcr),e(H,$M),e($M,DTe),e(DTe,emr),e($M,omr),e($M,DH),e(DH,rmr),e($M,tmr),e(H,amr),e(H,kM),e(kM,GTe),e(GTe,nmr),e(kM,smr),e(kM,GH),e(GH,lmr),e(kM,imr),e(H,dmr),e(H,SM),e(SM,OTe),e(OTe,cmr),e(SM,mmr),e(SM,OH),e(OH,fmr),e(SM,gmr),e(H,hmr),e(H,RM),e(RM,VTe),e(VTe,umr),e(RM,pmr),e(RM,VH),e(VH,_mr),e(RM,bmr),e(H,vmr),e(H,PM),e(PM,XTe),e(XTe,Fmr),e(PM,Tmr),e(PM,XH),e(XH,Mmr),e(PM,Emr),e(H,Cmr),e(H,BM),e(BM,zTe),e(zTe,wmr),e(BM,Amr),e(BM,zH),e(zH,Lmr),e(BM,ymr),e(H,xmr),e(H,IM),e(IM,QTe),e(QTe,$mr),e(IM,kmr),e(IM,QH),e(QH,Smr),e(IM,Rmr),e(H,Pmr),e(H,NM),e(NM,WTe),e(WTe,Bmr),e(NM,Imr),e(NM,WH),e(WH,Nmr),e(NM,qmr),e(H,jmr),e(H,qM),e(qM,UTe),e(UTe,Dmr),e(qM,Gmr),e(qM,UH),e(UH,Omr),e(qM,Vmr),e(H,Xmr),e(H,jM),e(jM,HTe),e(HTe,zmr),e(jM,Qmr),e(jM,HH),e(HH,Wmr),e(jM,Umr),e(H,Hmr),e(H,DM),e(DM,JTe),e(JTe,Jmr),e(DM,Ymr),e(DM,JH),e(JH,Kmr),e(DM,Zmr),e(H,efr),e(H,GM),e(GM,YTe),e(YTe,ofr),e(GM,rfr),e(GM,YH),e(YH,tfr),e(GM,afr),e(lo,nfr),e(lo,OM),e(OM,sfr),e(OM,KTe),e(KTe,lfr),e(OM,ifr),e(OM,ZTe),e(ZTe,dfr),e(lo,cfr),M(VM,lo,null),b(m,iKe,_),b(m,Vd,_),e(Vd,XM),e(XM,eMe),M(Dx,eMe,null),e(Vd,mfr),e(Vd,oMe),e(oMe,ffr),b(m,dKe,_),b(m,Vo,_),M(Gx,Vo,null),e(Vo,gfr),e(Vo,Xd),e(Xd,hfr),e(Xd,KH),e(KH,ufr),e(Xd,pfr),e(Xd,ZH),e(ZH,_fr),e(Xd,bfr),e(Vo,vfr),e(Vo,Ox),e(Ox,Ffr),e(Ox,rMe),e(rMe,Tfr),e(Ox,Mfr),e(Vo,Efr),e(Vo,At),M(Vx,At,null),e(At,Cfr),e(At,tMe),e(tMe,wfr),e(At,Afr),e(At,zd),e(zd,Lfr),e(zd,aMe),e(aMe,yfr),e(zd,xfr),e(zd,eJ),e(eJ,$fr),e(zd,kfr),e(At,Sfr),M(zM,At,null),e(Vo,Rfr),e(Vo,io),M(Xx,io,null),e(io,Pfr),e(io,nMe),e(nMe,Bfr),e(io,Ifr),e(io,nn),e(nn,Nfr),e(nn,sMe),e(sMe,qfr),e(nn,jfr),e(nn,lMe),e(lMe,Dfr),e(nn,Gfr),e(nn,iMe),e(iMe,Ofr),e(nn,Vfr),e(io,Xfr),e(io,V),e(V,QM),e(QM,dMe),e(dMe,zfr),e(QM,Qfr),e(QM,oJ),e(oJ,Wfr),e(QM,Ufr),e(V,Hfr),e(V,WM),e(WM,cMe),e(cMe,Jfr),e(WM,Yfr),e(WM,rJ),e(rJ,Kfr),e(WM,Zfr),e(V,egr),e(V,UM),e(UM,mMe),e(mMe,ogr),e(UM,rgr),e(UM,tJ),e(tJ,tgr),e(UM,agr),e(V,ngr),e(V,HM),e(HM,fMe),e(fMe,sgr),e(HM,lgr),e(HM,aJ),e(aJ,igr),e(HM,dgr),e(V,cgr),e(V,JM),e(JM,gMe),e(gMe,mgr),e(JM,fgr),e(JM,nJ),e(nJ,ggr),e(JM,hgr),e(V,ugr),e(V,YM),e(YM,hMe),e(hMe,pgr),e(YM,_gr),e(YM,sJ),e(sJ,bgr),e(YM,vgr),e(V,Fgr),e(V,KM),e(KM,uMe),e(uMe,Tgr),e(KM,Mgr),e(KM,lJ),e(lJ,Egr),e(KM,Cgr),e(V,wgr),e(V,ZM),e(ZM,pMe),e(pMe,Agr),e(ZM,Lgr),e(ZM,iJ),e(iJ,ygr),e(ZM,xgr),e(V,$gr),e(V,eE),e(eE,_Me),e(_Me,kgr),e(eE,Sgr),e(eE,dJ),e(dJ,Rgr),e(eE,Pgr),e(V,Bgr),e(V,oE),e(oE,bMe),e(bMe,Igr),e(oE,Ngr),e(oE,cJ),e(cJ,qgr),e(oE,jgr),e(V,Dgr),e(V,rE),e(rE,vMe),e(vMe,Ggr),e(rE,Ogr),e(rE,mJ),e(mJ,Vgr),e(rE,Xgr),e(V,zgr),e(V,tE),e(tE,FMe),e(FMe,Qgr),e(tE,Wgr),e(tE,fJ),e(fJ,Ugr),e(tE,Hgr),e(V,Jgr),e(V,aE),e(aE,TMe),e(TMe,Ygr),e(aE,Kgr),e(aE,gJ),e(gJ,Zgr),e(aE,ehr),e(V,ohr),e(V,nE),e(nE,MMe),e(MMe,rhr),e(nE,thr),e(nE,hJ),e(hJ,ahr),e(nE,nhr),e(V,shr),e(V,sE),e(sE,EMe),e(EMe,lhr),e(sE,ihr),e(sE,uJ),e(uJ,dhr),e(sE,chr),e(V,mhr),e(V,lE),e(lE,CMe),e(CMe,fhr),e(lE,ghr),e(lE,pJ),e(pJ,hhr),e(lE,uhr),e(V,phr),e(V,iE),e(iE,wMe),e(wMe,_hr),e(iE,bhr),e(iE,_J),e(_J,vhr),e(iE,Fhr),e(V,Thr),e(V,dE),e(dE,AMe),e(AMe,Mhr),e(dE,Ehr),e(dE,bJ),e(bJ,Chr),e(dE,whr),e(V,Ahr),e(V,cE),e(cE,LMe),e(LMe,Lhr),e(cE,yhr),e(cE,vJ),e(vJ,xhr),e(cE,$hr),e(V,khr),e(V,mE),e(mE,yMe),e(yMe,Shr),e(mE,Rhr),e(mE,FJ),e(FJ,Phr),e(mE,Bhr),e(V,Ihr),e(V,fE),e(fE,xMe),e(xMe,Nhr),e(fE,qhr),e(fE,TJ),e(TJ,jhr),e(fE,Dhr),e(V,Ghr),e(V,gE),e(gE,$Me),e($Me,Ohr),e(gE,Vhr),e(gE,MJ),e(MJ,Xhr),e(gE,zhr),e(V,Qhr),e(V,hE),e(hE,kMe),e(kMe,Whr),e(hE,Uhr),e(hE,EJ),e(EJ,Hhr),e(hE,Jhr),e(V,Yhr),e(V,uE),e(uE,SMe),e(SMe,Khr),e(uE,Zhr),e(uE,CJ),e(CJ,eur),e(uE,our),e(V,rur),e(V,pE),e(pE,RMe),e(RMe,tur),e(pE,aur),e(pE,wJ),e(wJ,nur),e(pE,sur),e(V,lur),e(V,_E),e(_E,PMe),e(PMe,iur),e(_E,dur),e(_E,AJ),e(AJ,cur),e(_E,mur),e(V,fur),e(V,bE),e(bE,BMe),e(BMe,gur),e(bE,hur),e(bE,LJ),e(LJ,uur),e(bE,pur),e(V,_ur),e(V,vE),e(vE,IMe),e(IMe,bur),e(vE,vur),e(vE,yJ),e(yJ,Fur),e(vE,Tur),e(V,Mur),e(V,FE),e(FE,NMe),e(NMe,Eur),e(FE,Cur),e(FE,xJ),e(xJ,wur),e(FE,Aur),e(V,Lur),e(V,TE),e(TE,qMe),e(qMe,yur),e(TE,xur),e(TE,$J),e($J,$ur),e(TE,kur),e(V,Sur),e(V,ME),e(ME,jMe),e(jMe,Rur),e(ME,Pur),e(ME,kJ),e(kJ,Bur),e(ME,Iur),e(V,Nur),e(V,EE),e(EE,DMe),e(DMe,qur),e(EE,jur),e(EE,SJ),e(SJ,Dur),e(EE,Gur),e(V,Our),e(V,CE),e(CE,GMe),e(GMe,Vur),e(CE,Xur),e(CE,RJ),e(RJ,zur),e(CE,Qur),e(V,Wur),e(V,wE),e(wE,OMe),e(OMe,Uur),e(wE,Hur),e(wE,PJ),e(PJ,Jur),e(wE,Yur),e(V,Kur),e(V,AE),e(AE,VMe),e(VMe,Zur),e(AE,epr),e(AE,BJ),e(BJ,opr),e(AE,rpr),e(V,tpr),e(V,LE),e(LE,XMe),e(XMe,apr),e(LE,npr),e(LE,IJ),e(IJ,spr),e(LE,lpr),e(V,ipr),e(V,yE),e(yE,zMe),e(zMe,dpr),e(yE,cpr),e(yE,NJ),e(NJ,mpr),e(yE,fpr),e(V,gpr),e(V,xE),e(xE,QMe),e(QMe,hpr),e(xE,upr),e(xE,qJ),e(qJ,ppr),e(xE,_pr),e(V,bpr),e(V,$E),e($E,WMe),e(WMe,vpr),e($E,Fpr),e($E,jJ),e(jJ,Tpr),e($E,Mpr),e(V,Epr),e(V,kE),e(kE,UMe),e(UMe,Cpr),e(kE,wpr),e(kE,DJ),e(DJ,Apr),e(kE,Lpr),e(V,ypr),e(V,SE),e(SE,HMe),e(HMe,xpr),e(SE,$pr),e(SE,GJ),e(GJ,kpr),e(SE,Spr),e(V,Rpr),e(V,RE),e(RE,JMe),e(JMe,Ppr),e(RE,Bpr),e(RE,OJ),e(OJ,Ipr),e(RE,Npr),e(V,qpr),e(V,PE),e(PE,YMe),e(YMe,jpr),e(PE,Dpr),e(PE,VJ),e(VJ,Gpr),e(PE,Opr),e(V,Vpr),e(V,BE),e(BE,KMe),e(KMe,Xpr),e(BE,zpr),e(BE,XJ),e(XJ,Qpr),e(BE,Wpr),e(io,Upr),e(io,IE),e(IE,Hpr),e(IE,ZMe),e(ZMe,Jpr),e(IE,Ypr),e(IE,eEe),e(eEe,Kpr),e(io,Zpr),M(NE,io,null),b(m,cKe,_),b(m,Qd,_),e(Qd,qE),e(qE,oEe),M(zx,oEe,null),e(Qd,e_r),e(Qd,rEe),e(rEe,o_r),b(m,mKe,_),b(m,Xo,_),M(Qx,Xo,null),e(Xo,r_r),e(Xo,Wd),e(Wd,t_r),e(Wd,zJ),e(zJ,a_r),e(Wd,n_r),e(Wd,QJ),e(QJ,s_r),e(Wd,l_r),e(Xo,i_r),e(Xo,Wx),e(Wx,d_r),e(Wx,tEe),e(tEe,c_r),e(Wx,m_r),e(Xo,f_r),e(Xo,Lt),M(Ux,Lt,null),e(Lt,g_r),e(Lt,aEe),e(aEe,h_r),e(Lt,u_r),e(Lt,Ud),e(Ud,p_r),e(Ud,nEe),e(nEe,__r),e(Ud,b_r),e(Ud,WJ),e(WJ,v_r),e(Ud,F_r),e(Lt,T_r),M(jE,Lt,null),e(Xo,M_r),e(Xo,co),M(Hx,co,null),e(co,E_r),e(co,sEe),e(sEe,C_r),e(co,w_r),e(co,sn),e(sn,A_r),e(sn,lEe),e(lEe,L_r),e(sn,y_r),e(sn,iEe),e(iEe,x_r),e(sn,$_r),e(sn,dEe),e(dEe,k_r),e(sn,S_r),e(co,R_r),e(co,cEe),e(cEe,DE),e(DE,mEe),e(mEe,P_r),e(DE,B_r),e(DE,UJ),e(UJ,I_r),e(DE,N_r),e(co,q_r),e(co,GE),e(GE,j_r),e(GE,fEe),e(fEe,D_r),e(GE,G_r),e(GE,gEe),e(gEe,O_r),e(co,V_r),M(OE,co,null),b(m,fKe,_),b(m,Hd,_),e(Hd,VE),e(VE,hEe),M(Jx,hEe,null),e(Hd,X_r),e(Hd,uEe),e(uEe,z_r),b(m,gKe,_),b(m,zo,_),M(Yx,zo,null),e(zo,Q_r),e(zo,Jd),e(Jd,W_r),e(Jd,HJ),e(HJ,U_r),e(Jd,H_r),e(Jd,JJ),e(JJ,J_r),e(Jd,Y_r),e(zo,K_r),e(zo,Kx),e(Kx,Z_r),e(Kx,pEe),e(pEe,e2r),e(Kx,o2r),e(zo,r2r),e(zo,yt),M(Zx,yt,null),e(yt,t2r),e(yt,_Ee),e(_Ee,a2r),e(yt,n2r),e(yt,Yd),e(Yd,s2r),e(Yd,bEe),e(bEe,l2r),e(Yd,i2r),e(Yd,YJ),e(YJ,d2r),e(Yd,c2r),e(yt,m2r),M(XE,yt,null),e(zo,f2r),e(zo,mo),M(e$,mo,null),e(mo,g2r),e(mo,vEe),e(vEe,h2r),e(mo,u2r),e(mo,ln),e(ln,p2r),e(ln,FEe),e(FEe,_2r),e(ln,b2r),e(ln,TEe),e(TEe,v2r),e(ln,F2r),e(ln,MEe),e(MEe,T2r),e(ln,M2r),e(mo,E2r),e(mo,Kd),e(Kd,zE),e(zE,EEe),e(EEe,C2r),e(zE,w2r),e(zE,KJ),e(KJ,A2r),e(zE,L2r),e(Kd,y2r),e(Kd,QE),e(QE,CEe),e(CEe,x2r),e(QE,$2r),e(QE,ZJ),e(ZJ,k2r),e(QE,S2r),e(Kd,R2r),e(Kd,WE),e(WE,wEe),e(wEe,P2r),e(WE,B2r),e(WE,eY),e(eY,I2r),e(WE,N2r),e(mo,q2r),e(mo,UE),e(UE,j2r),e(UE,AEe),e(AEe,D2r),e(UE,G2r),e(UE,LEe),e(LEe,O2r),e(mo,V2r),M(HE,mo,null),b(m,hKe,_),b(m,Zd,_),e(Zd,JE),e(JE,yEe),M(o$,yEe,null),e(Zd,X2r),e(Zd,xEe),e(xEe,z2r),b(m,uKe,_),b(m,Qo,_),M(r$,Qo,null),e(Qo,Q2r),e(Qo,ec),e(ec,W2r),e(ec,oY),e(oY,U2r),e(ec,H2r),e(ec,rY),e(rY,J2r),e(ec,Y2r),e(Qo,K2r),e(Qo,t$),e(t$,Z2r),e(t$,$Ee),e($Ee,ebr),e(t$,obr),e(Qo,rbr),e(Qo,xt),M(a$,xt,null),e(xt,tbr),e(xt,kEe),e(kEe,abr),e(xt,nbr),e(xt,oc),e(oc,sbr),e(oc,SEe),e(SEe,lbr),e(oc,ibr),e(oc,tY),e(tY,dbr),e(oc,cbr),e(xt,mbr),M(YE,xt,null),e(Qo,fbr),e(Qo,fo),M(n$,fo,null),e(fo,gbr),e(fo,REe),e(REe,hbr),e(fo,ubr),e(fo,dn),e(dn,pbr),e(dn,PEe),e(PEe,_br),e(dn,bbr),e(dn,BEe),e(BEe,vbr),e(dn,Fbr),e(dn,IEe),e(IEe,Tbr),e(dn,Mbr),e(fo,Ebr),e(fo,be),e(be,KE),e(KE,NEe),e(NEe,Cbr),e(KE,wbr),e(KE,aY),e(aY,Abr),e(KE,Lbr),e(be,ybr),e(be,ZE),e(ZE,qEe),e(qEe,xbr),e(ZE,$br),e(ZE,nY),e(nY,kbr),e(ZE,Sbr),e(be,Rbr),e(be,e4),e(e4,jEe),e(jEe,Pbr),e(e4,Bbr),e(e4,sY),e(sY,Ibr),e(e4,Nbr),e(be,qbr),e(be,o4),e(o4,DEe),e(DEe,jbr),e(o4,Dbr),e(o4,lY),e(lY,Gbr),e(o4,Obr),e(be,Vbr),e(be,_l),e(_l,GEe),e(GEe,Xbr),e(_l,zbr),e(_l,iY),e(iY,Qbr),e(_l,Wbr),e(_l,dY),e(dY,Ubr),e(_l,Hbr),e(be,Jbr),e(be,r4),e(r4,OEe),e(OEe,Ybr),e(r4,Kbr),e(r4,cY),e(cY,Zbr),e(r4,e1r),e(be,o1r),e(be,bl),e(bl,VEe),e(VEe,r1r),e(bl,t1r),e(bl,mY),e(mY,a1r),e(bl,n1r),e(bl,fY),e(fY,s1r),e(bl,l1r),e(be,i1r),e(be,t4),e(t4,XEe),e(XEe,d1r),e(t4,c1r),e(t4,gY),e(gY,m1r),e(t4,f1r),e(be,g1r),e(be,$t),e($t,zEe),e(zEe,h1r),e($t,u1r),e($t,hY),e(hY,p1r),e($t,_1r),e($t,uY),e(uY,b1r),e($t,v1r),e($t,pY),e(pY,F1r),e($t,T1r),e(be,M1r),e(be,a4),e(a4,QEe),e(QEe,E1r),e(a4,C1r),e(a4,_Y),e(_Y,w1r),e(a4,A1r),e(be,L1r),e(be,n4),e(n4,WEe),e(WEe,y1r),e(n4,x1r),e(n4,bY),e(bY,$1r),e(n4,k1r),e(be,S1r),e(be,s4),e(s4,UEe),e(UEe,R1r),e(s4,P1r),e(s4,vY),e(vY,B1r),e(s4,I1r),e(be,N1r),e(be,l4),e(l4,HEe),e(HEe,q1r),e(l4,j1r),e(l4,FY),e(FY,D1r),e(l4,G1r),e(be,O1r),e(be,i4),e(i4,JEe),e(JEe,V1r),e(i4,X1r),e(i4,TY),e(TY,z1r),e(i4,Q1r),e(be,W1r),e(be,d4),e(d4,YEe),e(YEe,U1r),e(d4,H1r),e(d4,MY),e(MY,J1r),e(d4,Y1r),e(be,K1r),e(be,c4),e(c4,KEe),e(KEe,Z1r),e(c4,evr),e(c4,EY),e(EY,ovr),e(c4,rvr),e(be,tvr),e(be,m4),e(m4,ZEe),e(ZEe,avr),e(m4,nvr),e(m4,CY),e(CY,svr),e(m4,lvr),e(fo,ivr),e(fo,f4),e(f4,dvr),e(f4,e4e),e(e4e,cvr),e(f4,mvr),e(f4,o4e),e(o4e,fvr),e(fo,gvr),M(g4,fo,null),b(m,pKe,_),b(m,rc,_),e(rc,h4),e(h4,r4e),M(s$,r4e,null),e(rc,hvr),e(rc,t4e),e(t4e,uvr),b(m,_Ke,_),b(m,Wo,_),M(l$,Wo,null),e(Wo,pvr),e(Wo,tc),e(tc,_vr),e(tc,wY),e(wY,bvr),e(tc,vvr),e(tc,AY),e(AY,Fvr),e(tc,Tvr),e(Wo,Mvr),e(Wo,i$),e(i$,Evr),e(i$,a4e),e(a4e,Cvr),e(i$,wvr),e(Wo,Avr),e(Wo,kt),M(d$,kt,null),e(kt,Lvr),e(kt,n4e),e(n4e,yvr),e(kt,xvr),e(kt,ac),e(ac,$vr),e(ac,s4e),e(s4e,kvr),e(ac,Svr),e(ac,LY),e(LY,Rvr),e(ac,Pvr),e(kt,Bvr),M(u4,kt,null),e(Wo,Ivr),e(Wo,go),M(c$,go,null),e(go,Nvr),e(go,l4e),e(l4e,qvr),e(go,jvr),e(go,cn),e(cn,Dvr),e(cn,i4e),e(i4e,Gvr),e(cn,Ovr),e(cn,d4e),e(d4e,Vvr),e(cn,Xvr),e(cn,c4e),e(c4e,zvr),e(cn,Qvr),e(go,Wvr),e(go,m4e),e(m4e,p4),e(p4,f4e),e(f4e,Uvr),e(p4,Hvr),e(p4,yY),e(yY,Jvr),e(p4,Yvr),e(go,Kvr),e(go,_4),e(_4,Zvr),e(_4,g4e),e(g4e,eFr),e(_4,oFr),e(_4,h4e),e(h4e,rFr),e(go,tFr),M(b4,go,null),b(m,bKe,_),b(m,nc,_),e(nc,v4),e(v4,u4e),M(m$,u4e,null),e(nc,aFr),e(nc,p4e),e(p4e,nFr),b(m,vKe,_),b(m,Uo,_),M(f$,Uo,null),e(Uo,sFr),e(Uo,sc),e(sc,lFr),e(sc,xY),e(xY,iFr),e(sc,dFr),e(sc,$Y),e($Y,cFr),e(sc,mFr),e(Uo,fFr),e(Uo,g$),e(g$,gFr),e(g$,_4e),e(_4e,hFr),e(g$,uFr),e(Uo,pFr),e(Uo,St),M(h$,St,null),e(St,_Fr),e(St,b4e),e(b4e,bFr),e(St,vFr),e(St,lc),e(lc,FFr),e(lc,v4e),e(v4e,TFr),e(lc,MFr),e(lc,kY),e(kY,EFr),e(lc,CFr),e(St,wFr),M(F4,St,null),e(Uo,AFr),e(Uo,ho),M(u$,ho,null),e(ho,LFr),e(ho,F4e),e(F4e,yFr),e(ho,xFr),e(ho,mn),e(mn,$Fr),e(mn,T4e),e(T4e,kFr),e(mn,SFr),e(mn,M4e),e(M4e,RFr),e(mn,PFr),e(mn,E4e),e(E4e,BFr),e(mn,IFr),e(ho,NFr),e(ho,C4e),e(C4e,T4),e(T4,w4e),e(w4e,qFr),e(T4,jFr),e(T4,SY),e(SY,DFr),e(T4,GFr),e(ho,OFr),e(ho,M4),e(M4,VFr),e(M4,A4e),e(A4e,XFr),e(M4,zFr),e(M4,L4e),e(L4e,QFr),e(ho,WFr),M(E4,ho,null),b(m,FKe,_),b(m,ic,_),e(ic,C4),e(C4,y4e),M(p$,y4e,null),e(ic,UFr),e(ic,x4e),e(x4e,HFr),b(m,TKe,_),b(m,Ho,_),M(_$,Ho,null),e(Ho,JFr),e(Ho,dc),e(dc,YFr),e(dc,RY),e(RY,KFr),e(dc,ZFr),e(dc,PY),e(PY,eTr),e(dc,oTr),e(Ho,rTr),e(Ho,b$),e(b$,tTr),e(b$,$4e),e($4e,aTr),e(b$,nTr),e(Ho,sTr),e(Ho,Rt),M(v$,Rt,null),e(Rt,lTr),e(Rt,k4e),e(k4e,iTr),e(Rt,dTr),e(Rt,cc),e(cc,cTr),e(cc,S4e),e(S4e,mTr),e(cc,fTr),e(cc,BY),e(BY,gTr),e(cc,hTr),e(Rt,uTr),M(w4,Rt,null),e(Ho,pTr),e(Ho,uo),M(F$,uo,null),e(uo,_Tr),e(uo,R4e),e(R4e,bTr),e(uo,vTr),e(uo,fn),e(fn,FTr),e(fn,P4e),e(P4e,TTr),e(fn,MTr),e(fn,B4e),e(B4e,ETr),e(fn,CTr),e(fn,I4e),e(I4e,wTr),e(fn,ATr),e(uo,LTr),e(uo,N4e),e(N4e,A4),e(A4,q4e),e(q4e,yTr),e(A4,xTr),e(A4,IY),e(IY,$Tr),e(A4,kTr),e(uo,STr),e(uo,L4),e(L4,RTr),e(L4,j4e),e(j4e,PTr),e(L4,BTr),e(L4,D4e),e(D4e,ITr),e(uo,NTr),M(y4,uo,null),b(m,MKe,_),b(m,mc,_),e(mc,x4),e(x4,G4e),M(T$,G4e,null),e(mc,qTr),e(mc,O4e),e(O4e,jTr),b(m,EKe,_),b(m,Jo,_),M(M$,Jo,null),e(Jo,DTr),e(Jo,fc),e(fc,GTr),e(fc,NY),e(NY,OTr),e(fc,VTr),e(fc,qY),e(qY,XTr),e(fc,zTr),e(Jo,QTr),e(Jo,E$),e(E$,WTr),e(E$,V4e),e(V4e,UTr),e(E$,HTr),e(Jo,JTr),e(Jo,Pt),M(C$,Pt,null),e(Pt,YTr),e(Pt,X4e),e(X4e,KTr),e(Pt,ZTr),e(Pt,gc),e(gc,eMr),e(gc,z4e),e(z4e,oMr),e(gc,rMr),e(gc,jY),e(jY,tMr),e(gc,aMr),e(Pt,nMr),M($4,Pt,null),e(Jo,sMr),e(Jo,po),M(w$,po,null),e(po,lMr),e(po,Q4e),e(Q4e,iMr),e(po,dMr),e(po,gn),e(gn,cMr),e(gn,W4e),e(W4e,mMr),e(gn,fMr),e(gn,U4e),e(U4e,gMr),e(gn,hMr),e(gn,H4e),e(H4e,uMr),e(gn,pMr),e(po,_Mr),e(po,Pe),e(Pe,k4),e(k4,J4e),e(J4e,bMr),e(k4,vMr),e(k4,DY),e(DY,FMr),e(k4,TMr),e(Pe,MMr),e(Pe,S4),e(S4,Y4e),e(Y4e,EMr),e(S4,CMr),e(S4,GY),e(GY,wMr),e(S4,AMr),e(Pe,LMr),e(Pe,R4),e(R4,K4e),e(K4e,yMr),e(R4,xMr),e(R4,OY),e(OY,$Mr),e(R4,kMr),e(Pe,SMr),e(Pe,P4),e(P4,Z4e),e(Z4e,RMr),e(P4,PMr),e(P4,VY),e(VY,BMr),e(P4,IMr),e(Pe,NMr),e(Pe,B4),e(B4,eCe),e(eCe,qMr),e(B4,jMr),e(B4,XY),e(XY,DMr),e(B4,GMr),e(Pe,OMr),e(Pe,I4),e(I4,oCe),e(oCe,VMr),e(I4,XMr),e(I4,zY),e(zY,zMr),e(I4,QMr),e(Pe,WMr),e(Pe,N4),e(N4,rCe),e(rCe,UMr),e(N4,HMr),e(N4,QY),e(QY,JMr),e(N4,YMr),e(Pe,KMr),e(Pe,q4),e(q4,tCe),e(tCe,ZMr),e(q4,eEr),e(q4,WY),e(WY,oEr),e(q4,rEr),e(Pe,tEr),e(Pe,j4),e(j4,aCe),e(aCe,aEr),e(j4,nEr),e(j4,UY),e(UY,sEr),e(j4,lEr),e(po,iEr),e(po,D4),e(D4,dEr),e(D4,nCe),e(nCe,cEr),e(D4,mEr),e(D4,sCe),e(sCe,fEr),e(po,gEr),M(G4,po,null),b(m,CKe,_),b(m,hc,_),e(hc,O4),e(O4,lCe),M(A$,lCe,null),e(hc,hEr),e(hc,iCe),e(iCe,uEr),b(m,wKe,_),b(m,Yo,_),M(L$,Yo,null),e(Yo,pEr),e(Yo,uc),e(uc,_Er),e(uc,HY),e(HY,bEr),e(uc,vEr),e(uc,JY),e(JY,FEr),e(uc,TEr),e(Yo,MEr),e(Yo,y$),e(y$,EEr),e(y$,dCe),e(dCe,CEr),e(y$,wEr),e(Yo,AEr),e(Yo,Bt),M(x$,Bt,null),e(Bt,LEr),e(Bt,cCe),e(cCe,yEr),e(Bt,xEr),e(Bt,pc),e(pc,$Er),e(pc,mCe),e(mCe,kEr),e(pc,SEr),e(pc,YY),e(YY,REr),e(pc,PEr),e(Bt,BEr),M(V4,Bt,null),e(Yo,IEr),e(Yo,_o),M($$,_o,null),e(_o,NEr),e(_o,fCe),e(fCe,qEr),e(_o,jEr),e(_o,hn),e(hn,DEr),e(hn,gCe),e(gCe,GEr),e(hn,OEr),e(hn,hCe),e(hCe,VEr),e(hn,XEr),e(hn,uCe),e(uCe,zEr),e(hn,QEr),e(_o,WEr),e(_o,mt),e(mt,X4),e(X4,pCe),e(pCe,UEr),e(X4,HEr),e(X4,KY),e(KY,JEr),e(X4,YEr),e(mt,KEr),e(mt,z4),e(z4,_Ce),e(_Ce,ZEr),e(z4,e4r),e(z4,ZY),e(ZY,o4r),e(z4,r4r),e(mt,t4r),e(mt,Q4),e(Q4,bCe),e(bCe,a4r),e(Q4,n4r),e(Q4,eK),e(eK,s4r),e(Q4,l4r),e(mt,i4r),e(mt,W4),e(W4,vCe),e(vCe,d4r),e(W4,c4r),e(W4,oK),e(oK,m4r),e(W4,f4r),e(mt,g4r),e(mt,U4),e(U4,FCe),e(FCe,h4r),e(U4,u4r),e(U4,rK),e(rK,p4r),e(U4,_4r),e(_o,b4r),e(_o,H4),e(H4,v4r),e(H4,TCe),e(TCe,F4r),e(H4,T4r),e(H4,MCe),e(MCe,M4r),e(_o,E4r),M(J4,_o,null),b(m,AKe,_),b(m,_c,_),e(_c,Y4),e(Y4,ECe),M(k$,ECe,null),e(_c,C4r),e(_c,CCe),e(CCe,w4r),b(m,LKe,_),b(m,Ko,_),M(S$,Ko,null),e(Ko,A4r),e(Ko,bc),e(bc,L4r),e(bc,tK),e(tK,y4r),e(bc,x4r),e(bc,aK),e(aK,$4r),e(bc,k4r),e(Ko,S4r),e(Ko,R$),e(R$,R4r),e(R$,wCe),e(wCe,P4r),e(R$,B4r),e(Ko,I4r),e(Ko,It),M(P$,It,null),e(It,N4r),e(It,ACe),e(ACe,q4r),e(It,j4r),e(It,vc),e(vc,D4r),e(vc,LCe),e(LCe,G4r),e(vc,O4r),e(vc,nK),e(nK,V4r),e(vc,X4r),e(It,z4r),M(K4,It,null),e(Ko,Q4r),e(Ko,bo),M(B$,bo,null),e(bo,W4r),e(bo,yCe),e(yCe,U4r),e(bo,H4r),e(bo,un),e(un,J4r),e(un,xCe),e(xCe,Y4r),e(un,K4r),e(un,$Ce),e($Ce,Z4r),e(un,eCr),e(un,kCe),e(kCe,oCr),e(un,rCr),e(bo,tCr),e(bo,Le),e(Le,Z4),e(Z4,SCe),e(SCe,aCr),e(Z4,nCr),e(Z4,sK),e(sK,sCr),e(Z4,lCr),e(Le,iCr),e(Le,eC),e(eC,RCe),e(RCe,dCr),e(eC,cCr),e(eC,lK),e(lK,mCr),e(eC,fCr),e(Le,gCr),e(Le,oC),e(oC,PCe),e(PCe,hCr),e(oC,uCr),e(oC,iK),e(iK,pCr),e(oC,_Cr),e(Le,bCr),e(Le,rC),e(rC,BCe),e(BCe,vCr),e(rC,FCr),e(rC,dK),e(dK,TCr),e(rC,MCr),e(Le,ECr),e(Le,tC),e(tC,ICe),e(ICe,CCr),e(tC,wCr),e(tC,cK),e(cK,ACr),e(tC,LCr),e(Le,yCr),e(Le,aC),e(aC,NCe),e(NCe,xCr),e(aC,$Cr),e(aC,mK),e(mK,kCr),e(aC,SCr),e(Le,RCr),e(Le,nC),e(nC,qCe),e(qCe,PCr),e(nC,BCr),e(nC,fK),e(fK,ICr),e(nC,NCr),e(Le,qCr),e(Le,sC),e(sC,jCe),e(jCe,jCr),e(sC,DCr),e(sC,gK),e(gK,GCr),e(sC,OCr),e(Le,VCr),e(Le,lC),e(lC,DCe),e(DCe,XCr),e(lC,zCr),e(lC,hK),e(hK,QCr),e(lC,WCr),e(Le,UCr),e(Le,iC),e(iC,GCe),e(GCe,HCr),e(iC,JCr),e(iC,uK),e(uK,YCr),e(iC,KCr),e(bo,ZCr),e(bo,dC),e(dC,e3r),e(dC,OCe),e(OCe,o3r),e(dC,r3r),e(dC,VCe),e(VCe,t3r),e(bo,a3r),M(cC,bo,null),b(m,yKe,_),b(m,Fc,_),e(Fc,mC),e(mC,XCe),M(I$,XCe,null),e(Fc,n3r),e(Fc,zCe),e(zCe,s3r),b(m,xKe,_),b(m,Zo,_),M(N$,Zo,null),e(Zo,l3r),e(Zo,Tc),e(Tc,i3r),e(Tc,pK),e(pK,d3r),e(Tc,c3r),e(Tc,_K),e(_K,m3r),e(Tc,f3r),e(Zo,g3r),e(Zo,q$),e(q$,h3r),e(q$,QCe),e(QCe,u3r),e(q$,p3r),e(Zo,_3r),e(Zo,Nt),M(j$,Nt,null),e(Nt,b3r),e(Nt,WCe),e(WCe,v3r),e(Nt,F3r),e(Nt,Mc),e(Mc,T3r),e(Mc,UCe),e(UCe,M3r),e(Mc,E3r),e(Mc,bK),e(bK,C3r),e(Mc,w3r),e(Nt,A3r),M(fC,Nt,null),e(Zo,L3r),e(Zo,vo),M(D$,vo,null),e(vo,y3r),e(vo,HCe),e(HCe,x3r),e(vo,$3r),e(vo,pn),e(pn,k3r),e(pn,JCe),e(JCe,S3r),e(pn,R3r),e(pn,YCe),e(YCe,P3r),e(pn,B3r),e(pn,KCe),e(KCe,I3r),e(pn,N3r),e(vo,q3r),e(vo,G$),e(G$,gC),e(gC,ZCe),e(ZCe,j3r),e(gC,D3r),e(gC,vK),e(vK,G3r),e(gC,O3r),e(G$,V3r),e(G$,hC),e(hC,e3e),e(e3e,X3r),e(hC,z3r),e(hC,FK),e(FK,Q3r),e(hC,W3r),e(vo,U3r),e(vo,uC),e(uC,H3r),e(uC,o3e),e(o3e,J3r),e(uC,Y3r),e(uC,r3e),e(r3e,K3r),e(vo,Z3r),M(pC,vo,null),b(m,$Ke,_),b(m,Ec,_),e(Ec,_C),e(_C,t3e),M(O$,t3e,null),e(Ec,e5r),e(Ec,a3e),e(a3e,o5r),b(m,kKe,_),b(m,er,_),M(V$,er,null),e(er,r5r),e(er,Cc),e(Cc,t5r),e(Cc,TK),e(TK,a5r),e(Cc,n5r),e(Cc,MK),e(MK,s5r),e(Cc,l5r),e(er,i5r),e(er,X$),e(X$,d5r),e(X$,n3e),e(n3e,c5r),e(X$,m5r),e(er,f5r),e(er,qt),M(z$,qt,null),e(qt,g5r),e(qt,s3e),e(s3e,h5r),e(qt,u5r),e(qt,wc),e(wc,p5r),e(wc,l3e),e(l3e,_5r),e(wc,b5r),e(wc,EK),e(EK,v5r),e(wc,F5r),e(qt,T5r),M(bC,qt,null),e(er,M5r),e(er,Fo),M(Q$,Fo,null),e(Fo,E5r),e(Fo,i3e),e(i3e,C5r),e(Fo,w5r),e(Fo,_n),e(_n,A5r),e(_n,d3e),e(d3e,L5r),e(_n,y5r),e(_n,c3e),e(c3e,x5r),e(_n,$5r),e(_n,m3e),e(m3e,k5r),e(_n,S5r),e(Fo,R5r),e(Fo,ft),e(ft,vC),e(vC,f3e),e(f3e,P5r),e(vC,B5r),e(vC,CK),e(CK,I5r),e(vC,N5r),e(ft,q5r),e(ft,FC),e(FC,g3e),e(g3e,j5r),e(FC,D5r),e(FC,wK),e(wK,G5r),e(FC,O5r),e(ft,V5r),e(ft,TC),e(TC,h3e),e(h3e,X5r),e(TC,z5r),e(TC,AK),e(AK,Q5r),e(TC,W5r),e(ft,U5r),e(ft,MC),e(MC,u3e),e(u3e,H5r),e(MC,J5r),e(MC,LK),e(LK,Y5r),e(MC,K5r),e(ft,Z5r),e(ft,EC),e(EC,p3e),e(p3e,e0r),e(EC,o0r),e(EC,yK),e(yK,r0r),e(EC,t0r),e(Fo,a0r),e(Fo,CC),e(CC,n0r),e(CC,_3e),e(_3e,s0r),e(CC,l0r),e(CC,b3e),e(b3e,i0r),e(Fo,d0r),M(wC,Fo,null),b(m,SKe,_),b(m,Ac,_),e(Ac,AC),e(AC,v3e),M(W$,v3e,null),e(Ac,c0r),e(Ac,F3e),e(F3e,m0r),b(m,RKe,_),b(m,or,_),M(U$,or,null),e(or,f0r),e(or,Lc),e(Lc,g0r),e(Lc,xK),e(xK,h0r),e(Lc,u0r),e(Lc,$K),e($K,p0r),e(Lc,_0r),e(or,b0r),e(or,H$),e(H$,v0r),e(H$,T3e),e(T3e,F0r),e(H$,T0r),e(or,M0r),e(or,jt),M(J$,jt,null),e(jt,E0r),e(jt,M3e),e(M3e,C0r),e(jt,w0r),e(jt,yc),e(yc,A0r),e(yc,E3e),e(E3e,L0r),e(yc,y0r),e(yc,kK),e(kK,x0r),e(yc,$0r),e(jt,k0r),M(LC,jt,null),e(or,S0r),e(or,To),M(Y$,To,null),e(To,R0r),e(To,C3e),e(C3e,P0r),e(To,B0r),e(To,bn),e(bn,I0r),e(bn,w3e),e(w3e,N0r),e(bn,q0r),e(bn,A3e),e(A3e,j0r),e(bn,D0r),e(bn,L3e),e(L3e,G0r),e(bn,O0r),e(To,V0r),e(To,vn),e(vn,yC),e(yC,y3e),e(y3e,X0r),e(yC,z0r),e(yC,SK),e(SK,Q0r),e(yC,W0r),e(vn,U0r),e(vn,xC),e(xC,x3e),e(x3e,H0r),e(xC,J0r),e(xC,RK),e(RK,Y0r),e(xC,K0r),e(vn,Z0r),e(vn,$C),e($C,$3e),e($3e,ewr),e($C,owr),e($C,PK),e(PK,rwr),e($C,twr),e(vn,awr),e(vn,kC),e(kC,k3e),e(k3e,nwr),e(kC,swr),e(kC,BK),e(BK,lwr),e(kC,iwr),e(To,dwr),e(To,SC),e(SC,cwr),e(SC,S3e),e(S3e,mwr),e(SC,fwr),e(SC,R3e),e(R3e,gwr),e(To,hwr),M(RC,To,null),b(m,PKe,_),b(m,xc,_),e(xc,PC),e(PC,P3e),M(K$,P3e,null),e(xc,uwr),e(xc,B3e),e(B3e,pwr),b(m,BKe,_),b(m,rr,_),M(Z$,rr,null),e(rr,_wr),e(rr,$c),e($c,bwr),e($c,IK),e(IK,vwr),e($c,Fwr),e($c,NK),e(NK,Twr),e($c,Mwr),e(rr,Ewr),e(rr,ek),e(ek,Cwr),e(ek,I3e),e(I3e,wwr),e(ek,Awr),e(rr,Lwr),e(rr,Dt),M(ok,Dt,null),e(Dt,ywr),e(Dt,N3e),e(N3e,xwr),e(Dt,$wr),e(Dt,kc),e(kc,kwr),e(kc,q3e),e(q3e,Swr),e(kc,Rwr),e(kc,qK),e(qK,Pwr),e(kc,Bwr),e(Dt,Iwr),M(BC,Dt,null),e(rr,Nwr),e(rr,Mo),M(rk,Mo,null),e(Mo,qwr),e(Mo,j3e),e(j3e,jwr),e(Mo,Dwr),e(Mo,Fn),e(Fn,Gwr),e(Fn,D3e),e(D3e,Owr),e(Fn,Vwr),e(Fn,G3e),e(G3e,Xwr),e(Fn,zwr),e(Fn,O3e),e(O3e,Qwr),e(Fn,Wwr),e(Mo,Uwr),e(Mo,tk),e(tk,IC),e(IC,V3e),e(V3e,Hwr),e(IC,Jwr),e(IC,jK),e(jK,Ywr),e(IC,Kwr),e(tk,Zwr),e(tk,NC),e(NC,X3e),e(X3e,eAr),e(NC,oAr),e(NC,DK),e(DK,rAr),e(NC,tAr),e(Mo,aAr),e(Mo,qC),e(qC,nAr),e(qC,z3e),e(z3e,sAr),e(qC,lAr),e(qC,Q3e),e(Q3e,iAr),e(Mo,dAr),M(jC,Mo,null),b(m,IKe,_),b(m,Sc,_),e(Sc,DC),e(DC,W3e),M(ak,W3e,null),e(Sc,cAr),e(Sc,U3e),e(U3e,mAr),b(m,NKe,_),b(m,tr,_),M(nk,tr,null),e(tr,fAr),e(tr,Rc),e(Rc,gAr),e(Rc,GK),e(GK,hAr),e(Rc,uAr),e(Rc,OK),e(OK,pAr),e(Rc,_Ar),e(tr,bAr),e(tr,sk),e(sk,vAr),e(sk,H3e),e(H3e,FAr),e(sk,TAr),e(tr,MAr),e(tr,Gt),M(lk,Gt,null),e(Gt,EAr),e(Gt,J3e),e(J3e,CAr),e(Gt,wAr),e(Gt,Pc),e(Pc,AAr),e(Pc,Y3e),e(Y3e,LAr),e(Pc,yAr),e(Pc,VK),e(VK,xAr),e(Pc,$Ar),e(Gt,kAr),M(GC,Gt,null),e(tr,SAr),e(tr,Eo),M(ik,Eo,null),e(Eo,RAr),e(Eo,K3e),e(K3e,PAr),e(Eo,BAr),e(Eo,Tn),e(Tn,IAr),e(Tn,Z3e),e(Z3e,NAr),e(Tn,qAr),e(Tn,e5e),e(e5e,jAr),e(Tn,DAr),e(Tn,o5e),e(o5e,GAr),e(Tn,OAr),e(Eo,VAr),e(Eo,r5e),e(r5e,OC),e(OC,t5e),e(t5e,XAr),e(OC,zAr),e(OC,XK),e(XK,QAr),e(OC,WAr),e(Eo,UAr),e(Eo,VC),e(VC,HAr),e(VC,a5e),e(a5e,JAr),e(VC,YAr),e(VC,n5e),e(n5e,KAr),e(Eo,ZAr),M(XC,Eo,null),b(m,qKe,_),b(m,Bc,_),e(Bc,zC),e(zC,s5e),M(dk,s5e,null),e(Bc,e6r),e(Bc,l5e),e(l5e,o6r),b(m,jKe,_),b(m,ar,_),M(ck,ar,null),e(ar,r6r),e(ar,Ic),e(Ic,t6r),e(Ic,zK),e(zK,a6r),e(Ic,n6r),e(Ic,QK),e(QK,s6r),e(Ic,l6r),e(ar,i6r),e(ar,mk),e(mk,d6r),e(mk,i5e),e(i5e,c6r),e(mk,m6r),e(ar,f6r),e(ar,Ot),M(fk,Ot,null),e(Ot,g6r),e(Ot,d5e),e(d5e,h6r),e(Ot,u6r),e(Ot,Nc),e(Nc,p6r),e(Nc,c5e),e(c5e,_6r),e(Nc,b6r),e(Nc,WK),e(WK,v6r),e(Nc,F6r),e(Ot,T6r),M(QC,Ot,null),e(ar,M6r),e(ar,Co),M(gk,Co,null),e(Co,E6r),e(Co,m5e),e(m5e,C6r),e(Co,w6r),e(Co,Mn),e(Mn,A6r),e(Mn,f5e),e(f5e,L6r),e(Mn,y6r),e(Mn,g5e),e(g5e,x6r),e(Mn,$6r),e(Mn,h5e),e(h5e,k6r),e(Mn,S6r),e(Co,R6r),e(Co,gt),e(gt,WC),e(WC,u5e),e(u5e,P6r),e(WC,B6r),e(WC,UK),e(UK,I6r),e(WC,N6r),e(gt,q6r),e(gt,UC),e(UC,p5e),e(p5e,j6r),e(UC,D6r),e(UC,HK),e(HK,G6r),e(UC,O6r),e(gt,V6r),e(gt,HC),e(HC,_5e),e(_5e,X6r),e(HC,z6r),e(HC,JK),e(JK,Q6r),e(HC,W6r),e(gt,U6r),e(gt,JC),e(JC,b5e),e(b5e,H6r),e(JC,J6r),e(JC,YK),e(YK,Y6r),e(JC,K6r),e(gt,Z6r),e(gt,YC),e(YC,v5e),e(v5e,e7r),e(YC,o7r),e(YC,KK),e(KK,r7r),e(YC,t7r),e(Co,a7r),e(Co,KC),e(KC,n7r),e(KC,F5e),e(F5e,s7r),e(KC,l7r),e(KC,T5e),e(T5e,i7r),e(Co,d7r),M(ZC,Co,null),b(m,DKe,_),b(m,qc,_),e(qc,e3),e(e3,M5e),M(hk,M5e,null),e(qc,c7r),e(qc,E5e),e(E5e,m7r),b(m,GKe,_),b(m,nr,_),M(uk,nr,null),e(nr,f7r),e(nr,jc),e(jc,g7r),e(jc,ZK),e(ZK,h7r),e(jc,u7r),e(jc,eZ),e(eZ,p7r),e(jc,_7r),e(nr,b7r),e(nr,pk),e(pk,v7r),e(pk,C5e),e(C5e,F7r),e(pk,T7r),e(nr,M7r),e(nr,Vt),M(_k,Vt,null),e(Vt,E7r),e(Vt,w5e),e(w5e,C7r),e(Vt,w7r),e(Vt,Dc),e(Dc,A7r),e(Dc,A5e),e(A5e,L7r),e(Dc,y7r),e(Dc,oZ),e(oZ,x7r),e(Dc,$7r),e(Vt,k7r),M(o3,Vt,null),e(nr,S7r),e(nr,wo),M(bk,wo,null),e(wo,R7r),e(wo,L5e),e(L5e,P7r),e(wo,B7r),e(wo,En),e(En,I7r),e(En,y5e),e(y5e,N7r),e(En,q7r),e(En,x5e),e(x5e,j7r),e(En,D7r),e(En,$5e),e($5e,G7r),e(En,O7r),e(wo,V7r),e(wo,k5e),e(k5e,r3),e(r3,S5e),e(S5e,X7r),e(r3,z7r),e(r3,rZ),e(rZ,Q7r),e(r3,W7r),e(wo,U7r),e(wo,t3),e(t3,H7r),e(t3,R5e),e(R5e,J7r),e(t3,Y7r),e(t3,P5e),e(P5e,K7r),e(wo,Z7r),M(a3,wo,null),b(m,OKe,_),b(m,Gc,_),e(Gc,n3),e(n3,B5e),M(vk,B5e,null),e(Gc,eLr),e(Gc,I5e),e(I5e,oLr),b(m,VKe,_),b(m,sr,_),M(Fk,sr,null),e(sr,rLr),e(sr,Oc),e(Oc,tLr),e(Oc,tZ),e(tZ,aLr),e(Oc,nLr),e(Oc,aZ),e(aZ,sLr),e(Oc,lLr),e(sr,iLr),e(sr,Tk),e(Tk,dLr),e(Tk,N5e),e(N5e,cLr),e(Tk,mLr),e(sr,fLr),e(sr,Xt),M(Mk,Xt,null),e(Xt,gLr),e(Xt,q5e),e(q5e,hLr),e(Xt,uLr),e(Xt,Vc),e(Vc,pLr),e(Vc,j5e),e(j5e,_Lr),e(Vc,bLr),e(Vc,nZ),e(nZ,vLr),e(Vc,FLr),e(Xt,TLr),M(s3,Xt,null),e(sr,MLr),e(sr,Ir),M(Ek,Ir,null),e(Ir,ELr),e(Ir,D5e),e(D5e,CLr),e(Ir,wLr),e(Ir,Cn),e(Cn,ALr),e(Cn,G5e),e(G5e,LLr),e(Cn,yLr),e(Cn,O5e),e(O5e,xLr),e(Cn,$Lr),e(Cn,V5e),e(V5e,kLr),e(Cn,SLr),e(Ir,RLr),e(Ir,N),e(N,l3),e(l3,X5e),e(X5e,PLr),e(l3,BLr),e(l3,sZ),e(sZ,ILr),e(l3,NLr),e(N,qLr),e(N,i3),e(i3,z5e),e(z5e,jLr),e(i3,DLr),e(i3,lZ),e(lZ,GLr),e(i3,OLr),e(N,VLr),e(N,d3),e(d3,Q5e),e(Q5e,XLr),e(d3,zLr),e(d3,iZ),e(iZ,QLr),e(d3,WLr),e(N,ULr),e(N,c3),e(c3,W5e),e(W5e,HLr),e(c3,JLr),e(c3,dZ),e(dZ,YLr),e(c3,KLr),e(N,ZLr),e(N,m3),e(m3,U5e),e(U5e,eyr),e(m3,oyr),e(m3,cZ),e(cZ,ryr),e(m3,tyr),e(N,ayr),e(N,f3),e(f3,H5e),e(H5e,nyr),e(f3,syr),e(f3,mZ),e(mZ,lyr),e(f3,iyr),e(N,dyr),e(N,g3),e(g3,J5e),e(J5e,cyr),e(g3,myr),e(g3,fZ),e(fZ,fyr),e(g3,gyr),e(N,hyr),e(N,h3),e(h3,Y5e),e(Y5e,uyr),e(h3,pyr),e(h3,gZ),e(gZ,_yr),e(h3,byr),e(N,vyr),e(N,u3),e(u3,K5e),e(K5e,Fyr),e(u3,Tyr),e(u3,hZ),e(hZ,Myr),e(u3,Eyr),e(N,Cyr),e(N,p3),e(p3,Z5e),e(Z5e,wyr),e(p3,Ayr),e(p3,uZ),e(uZ,Lyr),e(p3,yyr),e(N,xyr),e(N,_3),e(_3,e0e),e(e0e,$yr),e(_3,kyr),e(_3,pZ),e(pZ,Syr),e(_3,Ryr),e(N,Pyr),e(N,b3),e(b3,o0e),e(o0e,Byr),e(b3,Iyr),e(b3,_Z),e(_Z,Nyr),e(b3,qyr),e(N,jyr),e(N,v3),e(v3,r0e),e(r0e,Dyr),e(v3,Gyr),e(v3,bZ),e(bZ,Oyr),e(v3,Vyr),e(N,Xyr),e(N,F3),e(F3,t0e),e(t0e,zyr),e(F3,Qyr),e(F3,vZ),e(vZ,Wyr),e(F3,Uyr),e(N,Hyr),e(N,T3),e(T3,a0e),e(a0e,Jyr),e(T3,Yyr),e(T3,FZ),e(FZ,Kyr),e(T3,Zyr),e(N,e8r),e(N,M3),e(M3,n0e),e(n0e,o8r),e(M3,r8r),e(M3,TZ),e(TZ,t8r),e(M3,a8r),e(N,n8r),e(N,E3),e(E3,s0e),e(s0e,s8r),e(E3,l8r),e(E3,MZ),e(MZ,i8r),e(E3,d8r),e(N,c8r),e(N,C3),e(C3,l0e),e(l0e,m8r),e(C3,f8r),e(C3,EZ),e(EZ,g8r),e(C3,h8r),e(N,u8r),e(N,vl),e(vl,i0e),e(i0e,p8r),e(vl,_8r),e(vl,CZ),e(CZ,b8r),e(vl,v8r),e(vl,wZ),e(wZ,F8r),e(vl,T8r),e(N,M8r),e(N,w3),e(w3,d0e),e(d0e,E8r),e(w3,C8r),e(w3,AZ),e(AZ,w8r),e(w3,A8r),e(N,L8r),e(N,A3),e(A3,c0e),e(c0e,y8r),e(A3,x8r),e(A3,LZ),e(LZ,$8r),e(A3,k8r),e(N,S8r),e(N,L3),e(L3,m0e),e(m0e,R8r),e(L3,P8r),e(L3,yZ),e(yZ,B8r),e(L3,I8r),e(N,N8r),e(N,y3),e(y3,f0e),e(f0e,q8r),e(y3,j8r),e(y3,xZ),e(xZ,D8r),e(y3,G8r),e(N,O8r),e(N,x3),e(x3,g0e),e(g0e,V8r),e(x3,X8r),e(x3,$Z),e($Z,z8r),e(x3,Q8r),e(N,W8r),e(N,$3),e($3,h0e),e(h0e,U8r),e($3,H8r),e($3,kZ),e(kZ,J8r),e($3,Y8r),e(N,K8r),e(N,k3),e(k3,u0e),e(u0e,Z8r),e(k3,e9r),e(k3,SZ),e(SZ,o9r),e(k3,r9r),e(N,t9r),e(N,S3),e(S3,p0e),e(p0e,a9r),e(S3,n9r),e(S3,RZ),e(RZ,s9r),e(S3,l9r),e(N,i9r),e(N,R3),e(R3,_0e),e(_0e,d9r),e(R3,c9r),e(R3,PZ),e(PZ,m9r),e(R3,f9r),e(N,g9r),e(N,P3),e(P3,b0e),e(b0e,h9r),e(P3,u9r),e(P3,BZ),e(BZ,p9r),e(P3,_9r),e(N,b9r),e(N,B3),e(B3,v0e),e(v0e,v9r),e(B3,F9r),e(B3,IZ),e(IZ,T9r),e(B3,M9r),e(N,E9r),e(N,I3),e(I3,F0e),e(F0e,C9r),e(I3,w9r),e(I3,NZ),e(NZ,A9r),e(I3,L9r),e(N,y9r),e(N,N3),e(N3,T0e),e(T0e,x9r),e(N3,$9r),e(N3,qZ),e(qZ,k9r),e(N3,S9r),e(N,R9r),e(N,q3),e(q3,M0e),e(M0e,P9r),e(q3,B9r),e(q3,jZ),e(jZ,I9r),e(q3,N9r),e(N,q9r),e(N,j3),e(j3,E0e),e(E0e,j9r),e(j3,D9r),e(j3,DZ),e(DZ,G9r),e(j3,O9r),e(N,V9r),e(N,D3),e(D3,C0e),e(C0e,X9r),e(D3,z9r),e(D3,GZ),e(GZ,Q9r),e(D3,W9r),e(N,U9r),e(N,G3),e(G3,w0e),e(w0e,H9r),e(G3,J9r),e(G3,OZ),e(OZ,Y9r),e(G3,K9r),e(N,Z9r),e(N,O3),e(O3,A0e),e(A0e,exr),e(O3,oxr),e(O3,VZ),e(VZ,rxr),e(O3,txr),e(N,axr),e(N,V3),e(V3,L0e),e(L0e,nxr),e(V3,sxr),e(V3,XZ),e(XZ,lxr),e(V3,ixr),e(N,dxr),e(N,X3),e(X3,y0e),e(y0e,cxr),e(X3,mxr),e(X3,zZ),e(zZ,fxr),e(X3,gxr),e(N,hxr),e(N,z3),e(z3,x0e),e(x0e,uxr),e(z3,pxr),e(z3,QZ),e(QZ,_xr),e(z3,bxr),e(N,vxr),e(N,Q3),e(Q3,$0e),e($0e,Fxr),e(Q3,Txr),e(Q3,WZ),e(WZ,Mxr),e(Q3,Exr),e(N,Cxr),e(N,W3),e(W3,k0e),e(k0e,wxr),e(W3,Axr),e(W3,UZ),e(UZ,Lxr),e(W3,yxr),e(N,xxr),e(N,U3),e(U3,S0e),e(S0e,$xr),e(U3,kxr),e(U3,HZ),e(HZ,Sxr),e(U3,Rxr),e(N,Pxr),e(N,H3),e(H3,R0e),e(R0e,Bxr),e(H3,Ixr),e(H3,JZ),e(JZ,Nxr),e(H3,qxr),e(N,jxr),e(N,J3),e(J3,P0e),e(P0e,Dxr),e(J3,Gxr),e(J3,YZ),e(YZ,Oxr),e(J3,Vxr),e(N,Xxr),e(N,Y3),e(Y3,B0e),e(B0e,zxr),e(Y3,Qxr),e(Y3,KZ),e(KZ,Wxr),e(Y3,Uxr),e(N,Hxr),e(N,K3),e(K3,I0e),e(I0e,Jxr),e(K3,Yxr),e(K3,ZZ),e(ZZ,Kxr),e(K3,Zxr),e(N,e$r),e(N,Z3),e(Z3,N0e),e(N0e,o$r),e(Z3,r$r),e(Z3,eee),e(eee,t$r),e(Z3,a$r),e(N,n$r),e(N,e5),e(e5,q0e),e(q0e,s$r),e(e5,l$r),e(e5,oee),e(oee,i$r),e(e5,d$r),e(N,c$r),e(N,o5),e(o5,j0e),e(j0e,m$r),e(o5,f$r),e(o5,ree),e(ree,g$r),e(o5,h$r),e(N,u$r),e(N,r5),e(r5,D0e),e(D0e,p$r),e(r5,_$r),e(r5,tee),e(tee,b$r),e(r5,v$r),e(N,F$r),e(N,t5),e(t5,G0e),e(G0e,T$r),e(t5,M$r),e(t5,aee),e(aee,E$r),e(t5,C$r),e(N,w$r),e(N,a5),e(a5,O0e),e(O0e,A$r),e(a5,L$r),e(a5,nee),e(nee,y$r),e(a5,x$r),e(N,$$r),e(N,n5),e(n5,V0e),e(V0e,k$r),e(n5,S$r),e(n5,see),e(see,R$r),e(n5,P$r),e(Ir,B$r),M(s5,Ir,null),b(m,XKe,_),b(m,Xc,_),e(Xc,l5),e(l5,X0e),M(Ck,X0e,null),e(Xc,I$r),e(Xc,z0e),e(z0e,N$r),b(m,zKe,_),b(m,lr,_),M(wk,lr,null),e(lr,q$r),e(lr,zc),e(zc,j$r),e(zc,lee),e(lee,D$r),e(zc,G$r),e(zc,iee),e(iee,O$r),e(zc,V$r),e(lr,X$r),e(lr,Ak),e(Ak,z$r),e(Ak,Q0e),e(Q0e,Q$r),e(Ak,W$r),e(lr,U$r),e(lr,zt),M(Lk,zt,null),e(zt,H$r),e(zt,W0e),e(W0e,J$r),e(zt,Y$r),e(zt,Qc),e(Qc,K$r),e(Qc,U0e),e(U0e,Z$r),e(Qc,ekr),e(Qc,dee),e(dee,okr),e(Qc,rkr),e(zt,tkr),M(i5,zt,null),e(lr,akr),e(lr,Nr),M(yk,Nr,null),e(Nr,nkr),e(Nr,H0e),e(H0e,skr),e(Nr,lkr),e(Nr,wn),e(wn,ikr),e(wn,J0e),e(J0e,dkr),e(wn,ckr),e(wn,Y0e),e(Y0e,mkr),e(wn,fkr),e(wn,K0e),e(K0e,gkr),e(wn,hkr),e(Nr,ukr),e(Nr,se),e(se,d5),e(d5,Z0e),e(Z0e,pkr),e(d5,_kr),e(d5,cee),e(cee,bkr),e(d5,vkr),e(se,Fkr),e(se,c5),e(c5,ewe),e(ewe,Tkr),e(c5,Mkr),e(c5,mee),e(mee,Ekr),e(c5,Ckr),e(se,wkr),e(se,m5),e(m5,owe),e(owe,Akr),e(m5,Lkr),e(m5,fee),e(fee,ykr),e(m5,xkr),e(se,$kr),e(se,f5),e(f5,rwe),e(rwe,kkr),e(f5,Skr),e(f5,gee),e(gee,Rkr),e(f5,Pkr),e(se,Bkr),e(se,g5),e(g5,twe),e(twe,Ikr),e(g5,Nkr),e(g5,hee),e(hee,qkr),e(g5,jkr),e(se,Dkr),e(se,h5),e(h5,awe),e(awe,Gkr),e(h5,Okr),e(h5,uee),e(uee,Vkr),e(h5,Xkr),e(se,zkr),e(se,u5),e(u5,nwe),e(nwe,Qkr),e(u5,Wkr),e(u5,pee),e(pee,Ukr),e(u5,Hkr),e(se,Jkr),e(se,p5),e(p5,swe),e(swe,Ykr),e(p5,Kkr),e(p5,_ee),e(_ee,Zkr),e(p5,eSr),e(se,oSr),e(se,_5),e(_5,lwe),e(lwe,rSr),e(_5,tSr),e(_5,bee),e(bee,aSr),e(_5,nSr),e(se,sSr),e(se,b5),e(b5,iwe),e(iwe,lSr),e(b5,iSr),e(b5,vee),e(vee,dSr),e(b5,cSr),e(se,mSr),e(se,v5),e(v5,dwe),e(dwe,fSr),e(v5,gSr),e(v5,Fee),e(Fee,hSr),e(v5,uSr),e(se,pSr),e(se,F5),e(F5,cwe),e(cwe,_Sr),e(F5,bSr),e(F5,Tee),e(Tee,vSr),e(F5,FSr),e(se,TSr),e(se,T5),e(T5,mwe),e(mwe,MSr),e(T5,ESr),e(T5,Mee),e(Mee,CSr),e(T5,wSr),e(se,ASr),e(se,M5),e(M5,fwe),e(fwe,LSr),e(M5,ySr),e(M5,Eee),e(Eee,xSr),e(M5,$Sr),e(se,kSr),e(se,E5),e(E5,gwe),e(gwe,SSr),e(E5,RSr),e(E5,Cee),e(Cee,PSr),e(E5,BSr),e(se,ISr),e(se,C5),e(C5,hwe),e(hwe,NSr),e(C5,qSr),e(C5,wee),e(wee,jSr),e(C5,DSr),e(se,GSr),e(se,w5),e(w5,uwe),e(uwe,OSr),e(w5,VSr),e(w5,Aee),e(Aee,XSr),e(w5,zSr),e(se,QSr),e(se,A5),e(A5,pwe),e(pwe,WSr),e(A5,USr),e(A5,Lee),e(Lee,HSr),e(A5,JSr),e(se,YSr),e(se,L5),e(L5,_we),e(_we,KSr),e(L5,ZSr),e(L5,yee),e(yee,eRr),e(L5,oRr),e(se,rRr),e(se,y5),e(y5,bwe),e(bwe,tRr),e(y5,aRr),e(y5,xee),e(xee,nRr),e(y5,sRr),e(se,lRr),e(se,x5),e(x5,vwe),e(vwe,iRr),e(x5,dRr),e(x5,$ee),e($ee,cRr),e(x5,mRr),e(se,fRr),e(se,$5),e($5,Fwe),e(Fwe,gRr),e($5,hRr),e($5,kee),e(kee,uRr),e($5,pRr),e(se,_Rr),e(se,k5),e(k5,Twe),e(Twe,bRr),e(k5,vRr),e(k5,See),e(See,FRr),e(k5,TRr),e(Nr,MRr),M(S5,Nr,null),b(m,QKe,_),b(m,Wc,_),e(Wc,R5),e(R5,Mwe),M(xk,Mwe,null),e(Wc,ERr),e(Wc,Ewe),e(Ewe,CRr),b(m,WKe,_),b(m,ir,_),M($k,ir,null),e(ir,wRr),e(ir,Uc),e(Uc,ARr),e(Uc,Ree),e(Ree,LRr),e(Uc,yRr),e(Uc,Pee),e(Pee,xRr),e(Uc,$Rr),e(ir,kRr),e(ir,kk),e(kk,SRr),e(kk,Cwe),e(Cwe,RRr),e(kk,PRr),e(ir,BRr),e(ir,Qt),M(Sk,Qt,null),e(Qt,IRr),e(Qt,wwe),e(wwe,NRr),e(Qt,qRr),e(Qt,Hc),e(Hc,jRr),e(Hc,Awe),e(Awe,DRr),e(Hc,GRr),e(Hc,Bee),e(Bee,ORr),e(Hc,VRr),e(Qt,XRr),M(P5,Qt,null),e(ir,zRr),e(ir,qr),M(Rk,qr,null),e(qr,QRr),e(qr,Lwe),e(Lwe,WRr),e(qr,URr),e(qr,An),e(An,HRr),e(An,ywe),e(ywe,JRr),e(An,YRr),e(An,xwe),e(xwe,KRr),e(An,ZRr),e(An,$we),e($we,ePr),e(An,oPr),e(qr,rPr),e(qr,Me),e(Me,B5),e(B5,kwe),e(kwe,tPr),e(B5,aPr),e(B5,Iee),e(Iee,nPr),e(B5,sPr),e(Me,lPr),e(Me,I5),e(I5,Swe),e(Swe,iPr),e(I5,dPr),e(I5,Nee),e(Nee,cPr),e(I5,mPr),e(Me,fPr),e(Me,N5),e(N5,Rwe),e(Rwe,gPr),e(N5,hPr),e(N5,qee),e(qee,uPr),e(N5,pPr),e(Me,_Pr),e(Me,q5),e(q5,Pwe),e(Pwe,bPr),e(q5,vPr),e(q5,jee),e(jee,FPr),e(q5,TPr),e(Me,MPr),e(Me,j5),e(j5,Bwe),e(Bwe,EPr),e(j5,CPr),e(j5,Dee),e(Dee,wPr),e(j5,APr),e(Me,LPr),e(Me,D5),e(D5,Iwe),e(Iwe,yPr),e(D5,xPr),e(D5,Gee),e(Gee,$Pr),e(D5,kPr),e(Me,SPr),e(Me,G5),e(G5,Nwe),e(Nwe,RPr),e(G5,PPr),e(G5,Oee),e(Oee,BPr),e(G5,IPr),e(Me,NPr),e(Me,O5),e(O5,qwe),e(qwe,qPr),e(O5,jPr),e(O5,Vee),e(Vee,DPr),e(O5,GPr),e(Me,OPr),e(Me,V5),e(V5,jwe),e(jwe,VPr),e(V5,XPr),e(V5,Xee),e(Xee,zPr),e(V5,QPr),e(Me,WPr),e(Me,X5),e(X5,Dwe),e(Dwe,UPr),e(X5,HPr),e(X5,zee),e(zee,JPr),e(X5,YPr),e(Me,KPr),e(Me,z5),e(z5,Gwe),e(Gwe,ZPr),e(z5,eBr),e(z5,Qee),e(Qee,oBr),e(z5,rBr),e(Me,tBr),e(Me,Q5),e(Q5,Owe),e(Owe,aBr),e(Q5,nBr),e(Q5,Wee),e(Wee,sBr),e(Q5,lBr),e(Me,iBr),e(Me,W5),e(W5,Vwe),e(Vwe,dBr),e(W5,cBr),e(W5,Uee),e(Uee,mBr),e(W5,fBr),e(Me,gBr),e(Me,U5),e(U5,Xwe),e(Xwe,hBr),e(U5,uBr),e(U5,Hee),e(Hee,pBr),e(U5,_Br),e(qr,bBr),M(H5,qr,null),b(m,UKe,_),b(m,Jc,_),e(Jc,J5),e(J5,zwe),M(Pk,zwe,null),e(Jc,vBr),e(Jc,Qwe),e(Qwe,FBr),b(m,HKe,_),b(m,dr,_),M(Bk,dr,null),e(dr,TBr),e(dr,Yc),e(Yc,MBr),e(Yc,Jee),e(Jee,EBr),e(Yc,CBr),e(Yc,Yee),e(Yee,wBr),e(Yc,ABr),e(dr,LBr),e(dr,Ik),e(Ik,yBr),e(Ik,Wwe),e(Wwe,xBr),e(Ik,$Br),e(dr,kBr),e(dr,Wt),M(Nk,Wt,null),e(Wt,SBr),e(Wt,Uwe),e(Uwe,RBr),e(Wt,PBr),e(Wt,Kc),e(Kc,BBr),e(Kc,Hwe),e(Hwe,IBr),e(Kc,NBr),e(Kc,Kee),e(Kee,qBr),e(Kc,jBr),e(Wt,DBr),M(Y5,Wt,null),e(dr,GBr),e(dr,jr),M(qk,jr,null),e(jr,OBr),e(jr,Jwe),e(Jwe,VBr),e(jr,XBr),e(jr,Ln),e(Ln,zBr),e(Ln,Ywe),e(Ywe,QBr),e(Ln,WBr),e(Ln,Kwe),e(Kwe,UBr),e(Ln,HBr),e(Ln,Zwe),e(Zwe,JBr),e(Ln,YBr),e(jr,KBr),e(jr,Be),e(Be,K5),e(K5,eAe),e(eAe,ZBr),e(K5,eIr),e(K5,Zee),e(Zee,oIr),e(K5,rIr),e(Be,tIr),e(Be,Z5),e(Z5,oAe),e(oAe,aIr),e(Z5,nIr),e(Z5,eoe),e(eoe,sIr),e(Z5,lIr),e(Be,iIr),e(Be,Fl),e(Fl,rAe),e(rAe,dIr),e(Fl,cIr),e(Fl,ooe),e(ooe,mIr),e(Fl,fIr),e(Fl,roe),e(roe,gIr),e(Fl,hIr),e(Be,uIr),e(Be,e0),e(e0,tAe),e(tAe,pIr),e(e0,_Ir),e(e0,toe),e(toe,bIr),e(e0,vIr),e(Be,FIr),e(Be,o0),e(o0,aAe),e(aAe,TIr),e(o0,MIr),e(o0,aoe),e(aoe,EIr),e(o0,CIr),e(Be,wIr),e(Be,r0),e(r0,nAe),e(nAe,AIr),e(r0,LIr),e(r0,noe),e(noe,yIr),e(r0,xIr),e(Be,$Ir),e(Be,t0),e(t0,sAe),e(sAe,kIr),e(t0,SIr),e(t0,soe),e(soe,RIr),e(t0,PIr),e(Be,BIr),e(Be,a0),e(a0,lAe),e(lAe,IIr),e(a0,NIr),e(a0,loe),e(loe,qIr),e(a0,jIr),e(Be,DIr),e(Be,n0),e(n0,iAe),e(iAe,GIr),e(n0,OIr),e(n0,ioe),e(ioe,VIr),e(n0,XIr),e(jr,zIr),M(s0,jr,null),b(m,JKe,_),b(m,Zc,_),e(Zc,l0),e(l0,dAe),M(jk,dAe,null),e(Zc,QIr),e(Zc,cAe),e(cAe,WIr),b(m,YKe,_),b(m,cr,_),M(Dk,cr,null),e(cr,UIr),e(cr,em),e(em,HIr),e(em,doe),e(doe,JIr),e(em,YIr),e(em,coe),e(coe,KIr),e(em,ZIr),e(cr,eNr),e(cr,Gk),e(Gk,oNr),e(Gk,mAe),e(mAe,rNr),e(Gk,tNr),e(cr,aNr),e(cr,Ut),M(Ok,Ut,null),e(Ut,nNr),e(Ut,fAe),e(fAe,sNr),e(Ut,lNr),e(Ut,om),e(om,iNr),e(om,gAe),e(gAe,dNr),e(om,cNr),e(om,moe),e(moe,mNr),e(om,fNr),e(Ut,gNr),M(i0,Ut,null),e(cr,hNr),e(cr,Dr),M(Vk,Dr,null),e(Dr,uNr),e(Dr,hAe),e(hAe,pNr),e(Dr,_Nr),e(Dr,yn),e(yn,bNr),e(yn,uAe),e(uAe,vNr),e(yn,FNr),e(yn,pAe),e(pAe,TNr),e(yn,MNr),e(yn,_Ae),e(_Ae,ENr),e(yn,CNr),e(Dr,wNr),e(Dr,rm),e(rm,d0),e(d0,bAe),e(bAe,ANr),e(d0,LNr),e(d0,foe),e(foe,yNr),e(d0,xNr),e(rm,$Nr),e(rm,c0),e(c0,vAe),e(vAe,kNr),e(c0,SNr),e(c0,goe),e(goe,RNr),e(c0,PNr),e(rm,BNr),e(rm,m0),e(m0,FAe),e(FAe,INr),e(m0,NNr),e(m0,hoe),e(hoe,qNr),e(m0,jNr),e(Dr,DNr),M(f0,Dr,null),b(m,KKe,_),b(m,tm,_),e(tm,g0),e(g0,TAe),M(Xk,TAe,null),e(tm,GNr),e(tm,MAe),e(MAe,ONr),b(m,ZKe,_),b(m,mr,_),M(zk,mr,null),e(mr,VNr),e(mr,am),e(am,XNr),e(am,uoe),e(uoe,zNr),e(am,QNr),e(am,poe),e(poe,WNr),e(am,UNr),e(mr,HNr),e(mr,Qk),e(Qk,JNr),e(Qk,EAe),e(EAe,YNr),e(Qk,KNr),e(mr,ZNr),e(mr,Ht),M(Wk,Ht,null),e(Ht,eqr),e(Ht,CAe),e(CAe,oqr),e(Ht,rqr),e(Ht,nm),e(nm,tqr),e(nm,wAe),e(wAe,aqr),e(nm,nqr),e(nm,_oe),e(_oe,sqr),e(nm,lqr),e(Ht,iqr),M(h0,Ht,null),e(mr,dqr),e(mr,Gr),M(Uk,Gr,null),e(Gr,cqr),e(Gr,AAe),e(AAe,mqr),e(Gr,fqr),e(Gr,xn),e(xn,gqr),e(xn,LAe),e(LAe,hqr),e(xn,uqr),e(xn,yAe),e(yAe,pqr),e(xn,_qr),e(xn,xAe),e(xAe,bqr),e(xn,vqr),e(Gr,Fqr),e(Gr,fe),e(fe,u0),e(u0,$Ae),e($Ae,Tqr),e(u0,Mqr),e(u0,boe),e(boe,Eqr),e(u0,Cqr),e(fe,wqr),e(fe,p0),e(p0,kAe),e(kAe,Aqr),e(p0,Lqr),e(p0,voe),e(voe,yqr),e(p0,xqr),e(fe,$qr),e(fe,_0),e(_0,SAe),e(SAe,kqr),e(_0,Sqr),e(_0,Foe),e(Foe,Rqr),e(_0,Pqr),e(fe,Bqr),e(fe,b0),e(b0,RAe),e(RAe,Iqr),e(b0,Nqr),e(b0,Toe),e(Toe,qqr),e(b0,jqr),e(fe,Dqr),e(fe,v0),e(v0,PAe),e(PAe,Gqr),e(v0,Oqr),e(v0,Moe),e(Moe,Vqr),e(v0,Xqr),e(fe,zqr),e(fe,F0),e(F0,BAe),e(BAe,Qqr),e(F0,Wqr),e(F0,Eoe),e(Eoe,Uqr),e(F0,Hqr),e(fe,Jqr),e(fe,T0),e(T0,IAe),e(IAe,Yqr),e(T0,Kqr),e(T0,Coe),e(Coe,Zqr),e(T0,ejr),e(fe,ojr),e(fe,M0),e(M0,NAe),e(NAe,rjr),e(M0,tjr),e(M0,woe),e(woe,ajr),e(M0,njr),e(fe,sjr),e(fe,E0),e(E0,qAe),e(qAe,ljr),e(E0,ijr),e(E0,Aoe),e(Aoe,djr),e(E0,cjr),e(fe,mjr),e(fe,C0),e(C0,jAe),e(jAe,fjr),e(C0,gjr),e(C0,Loe),e(Loe,hjr),e(C0,ujr),e(fe,pjr),e(fe,w0),e(w0,DAe),e(DAe,_jr),e(w0,bjr),e(w0,yoe),e(yoe,vjr),e(w0,Fjr),e(fe,Tjr),e(fe,A0),e(A0,GAe),e(GAe,Mjr),e(A0,Ejr),e(A0,xoe),e(xoe,Cjr),e(A0,wjr),e(fe,Ajr),e(fe,L0),e(L0,OAe),e(OAe,Ljr),e(L0,yjr),e(L0,$oe),e($oe,xjr),e(L0,$jr),e(fe,kjr),e(fe,y0),e(y0,VAe),e(VAe,Sjr),e(y0,Rjr),e(y0,koe),e(koe,Pjr),e(y0,Bjr),e(fe,Ijr),e(fe,x0),e(x0,XAe),e(XAe,Njr),e(x0,qjr),e(x0,Soe),e(Soe,jjr),e(x0,Djr),e(fe,Gjr),e(fe,$0),e($0,zAe),e(zAe,Ojr),e($0,Vjr),e($0,Roe),e(Roe,Xjr),e($0,zjr),e(fe,Qjr),e(fe,k0),e(k0,QAe),e(QAe,Wjr),e(k0,Ujr),e(k0,Poe),e(Poe,Hjr),e(k0,Jjr),e(fe,Yjr),e(fe,S0),e(S0,WAe),e(WAe,Kjr),e(S0,Zjr),e(S0,Boe),e(Boe,eDr),e(S0,oDr),e(fe,rDr),e(fe,R0),e(R0,UAe),e(UAe,tDr),e(R0,aDr),e(R0,Ioe),e(Ioe,nDr),e(R0,sDr),e(fe,lDr),e(fe,P0),e(P0,HAe),e(HAe,iDr),e(P0,dDr),e(P0,Noe),e(Noe,cDr),e(P0,mDr),e(Gr,fDr),M(B0,Gr,null),b(m,eZe,_),b(m,sm,_),e(sm,I0),e(I0,JAe),M(Hk,JAe,null),e(sm,gDr),e(sm,YAe),e(YAe,hDr),b(m,oZe,_),b(m,fr,_),M(Jk,fr,null),e(fr,uDr),e(fr,lm),e(lm,pDr),e(lm,qoe),e(qoe,_Dr),e(lm,bDr),e(lm,joe),e(joe,vDr),e(lm,FDr),e(fr,TDr),e(fr,Yk),e(Yk,MDr),e(Yk,KAe),e(KAe,EDr),e(Yk,CDr),e(fr,wDr),e(fr,Jt),M(Kk,Jt,null),e(Jt,ADr),e(Jt,ZAe),e(ZAe,LDr),e(Jt,yDr),e(Jt,im),e(im,xDr),e(im,e6e),e(e6e,$Dr),e(im,kDr),e(im,Doe),e(Doe,SDr),e(im,RDr),e(Jt,PDr),M(N0,Jt,null),e(fr,BDr),e(fr,Or),M(Zk,Or,null),e(Or,IDr),e(Or,o6e),e(o6e,NDr),e(Or,qDr),e(Or,$n),e($n,jDr),e($n,r6e),e(r6e,DDr),e($n,GDr),e($n,t6e),e(t6e,ODr),e($n,VDr),e($n,a6e),e(a6e,XDr),e($n,zDr),e(Or,QDr),e(Or,ye),e(ye,q0),e(q0,n6e),e(n6e,WDr),e(q0,UDr),e(q0,Goe),e(Goe,HDr),e(q0,JDr),e(ye,YDr),e(ye,j0),e(j0,s6e),e(s6e,KDr),e(j0,ZDr),e(j0,Ooe),e(Ooe,eGr),e(j0,oGr),e(ye,rGr),e(ye,D0),e(D0,l6e),e(l6e,tGr),e(D0,aGr),e(D0,Voe),e(Voe,nGr),e(D0,sGr),e(ye,lGr),e(ye,G0),e(G0,i6e),e(i6e,iGr),e(G0,dGr),e(G0,Xoe),e(Xoe,cGr),e(G0,mGr),e(ye,fGr),e(ye,O0),e(O0,d6e),e(d6e,gGr),e(O0,hGr),e(O0,zoe),e(zoe,uGr),e(O0,pGr),e(ye,_Gr),e(ye,V0),e(V0,c6e),e(c6e,bGr),e(V0,vGr),e(V0,Qoe),e(Qoe,FGr),e(V0,TGr),e(ye,MGr),e(ye,X0),e(X0,m6e),e(m6e,EGr),e(X0,CGr),e(X0,Woe),e(Woe,wGr),e(X0,AGr),e(ye,LGr),e(ye,z0),e(z0,f6e),e(f6e,yGr),e(z0,xGr),e(z0,Uoe),e(Uoe,$Gr),e(z0,kGr),e(ye,SGr),e(ye,Q0),e(Q0,g6e),e(g6e,RGr),e(Q0,PGr),e(Q0,Hoe),e(Hoe,BGr),e(Q0,IGr),e(ye,NGr),e(ye,W0),e(W0,h6e),e(h6e,qGr),e(W0,jGr),e(W0,Joe),e(Joe,DGr),e(W0,GGr),e(Or,OGr),M(U0,Or,null),b(m,rZe,_),b(m,dm,_),e(dm,H0),e(H0,u6e),M(eS,u6e,null),e(dm,VGr),e(dm,p6e),e(p6e,XGr),b(m,tZe,_),b(m,gr,_),M(oS,gr,null),e(gr,zGr),e(gr,cm),e(cm,QGr),e(cm,Yoe),e(Yoe,WGr),e(cm,UGr),e(cm,Koe),e(Koe,HGr),e(cm,JGr),e(gr,YGr),e(gr,rS),e(rS,KGr),e(rS,_6e),e(_6e,ZGr),e(rS,eOr),e(gr,oOr),e(gr,Yt),M(tS,Yt,null),e(Yt,rOr),e(Yt,b6e),e(b6e,tOr),e(Yt,aOr),e(Yt,mm),e(mm,nOr),e(mm,v6e),e(v6e,sOr),e(mm,lOr),e(mm,Zoe),e(Zoe,iOr),e(mm,dOr),e(Yt,cOr),M(J0,Yt,null),e(gr,mOr),e(gr,Vr),M(aS,Vr,null),e(Vr,fOr),e(Vr,F6e),e(F6e,gOr),e(Vr,hOr),e(Vr,kn),e(kn,uOr),e(kn,T6e),e(T6e,pOr),e(kn,_Or),e(kn,M6e),e(M6e,bOr),e(kn,vOr),e(kn,E6e),e(E6e,FOr),e(kn,TOr),e(Vr,MOr),e(Vr,re),e(re,Y0),e(Y0,C6e),e(C6e,EOr),e(Y0,COr),e(Y0,ere),e(ere,wOr),e(Y0,AOr),e(re,LOr),e(re,K0),e(K0,w6e),e(w6e,yOr),e(K0,xOr),e(K0,ore),e(ore,$Or),e(K0,kOr),e(re,SOr),e(re,Z0),e(Z0,A6e),e(A6e,ROr),e(Z0,POr),e(Z0,rre),e(rre,BOr),e(Z0,IOr),e(re,NOr),e(re,ew),e(ew,L6e),e(L6e,qOr),e(ew,jOr),e(ew,tre),e(tre,DOr),e(ew,GOr),e(re,OOr),e(re,ow),e(ow,y6e),e(y6e,VOr),e(ow,XOr),e(ow,are),e(are,zOr),e(ow,QOr),e(re,WOr),e(re,rw),e(rw,x6e),e(x6e,UOr),e(rw,HOr),e(rw,nre),e(nre,JOr),e(rw,YOr),e(re,KOr),e(re,tw),e(tw,$6e),e($6e,ZOr),e(tw,eVr),e(tw,sre),e(sre,oVr),e(tw,rVr),e(re,tVr),e(re,aw),e(aw,k6e),e(k6e,aVr),e(aw,nVr),e(aw,lre),e(lre,sVr),e(aw,lVr),e(re,iVr),e(re,nw),e(nw,S6e),e(S6e,dVr),e(nw,cVr),e(nw,ire),e(ire,mVr),e(nw,fVr),e(re,gVr),e(re,sw),e(sw,R6e),e(R6e,hVr),e(sw,uVr),e(sw,dre),e(dre,pVr),e(sw,_Vr),e(re,bVr),e(re,lw),e(lw,P6e),e(P6e,vVr),e(lw,FVr),e(lw,cre),e(cre,TVr),e(lw,MVr),e(re,EVr),e(re,iw),e(iw,B6e),e(B6e,CVr),e(iw,wVr),e(iw,mre),e(mre,AVr),e(iw,LVr),e(re,yVr),e(re,dw),e(dw,I6e),e(I6e,xVr),e(dw,$Vr),e(dw,fre),e(fre,kVr),e(dw,SVr),e(re,RVr),e(re,cw),e(cw,N6e),e(N6e,PVr),e(cw,BVr),e(cw,gre),e(gre,IVr),e(cw,NVr),e(re,qVr),e(re,mw),e(mw,q6e),e(q6e,jVr),e(mw,DVr),e(mw,hre),e(hre,GVr),e(mw,OVr),e(re,VVr),e(re,fw),e(fw,j6e),e(j6e,XVr),e(fw,zVr),e(fw,ure),e(ure,QVr),e(fw,WVr),e(re,UVr),e(re,gw),e(gw,D6e),e(D6e,HVr),e(gw,JVr),e(gw,pre),e(pre,YVr),e(gw,KVr),e(re,ZVr),e(re,hw),e(hw,G6e),e(G6e,eXr),e(hw,oXr),e(hw,_re),e(_re,rXr),e(hw,tXr),e(re,aXr),e(re,uw),e(uw,O6e),e(O6e,nXr),e(uw,sXr),e(uw,bre),e(bre,lXr),e(uw,iXr),e(re,dXr),e(re,pw),e(pw,V6e),e(V6e,cXr),e(pw,mXr),e(pw,vre),e(vre,fXr),e(pw,gXr),e(re,hXr),e(re,_w),e(_w,X6e),e(X6e,uXr),e(_w,pXr),e(_w,Fre),e(Fre,_Xr),e(_w,bXr),e(re,vXr),e(re,bw),e(bw,z6e),e(z6e,FXr),e(bw,TXr),e(bw,Tre),e(Tre,MXr),e(bw,EXr),e(re,CXr),e(re,vw),e(vw,Q6e),e(Q6e,wXr),e(vw,AXr),e(vw,Mre),e(Mre,LXr),e(vw,yXr),e(re,xXr),e(re,Fw),e(Fw,W6e),e(W6e,$Xr),e(Fw,kXr),e(Fw,Ere),e(Ere,SXr),e(Fw,RXr),e(re,PXr),e(re,Tw),e(Tw,U6e),e(U6e,BXr),e(Tw,IXr),e(Tw,Cre),e(Cre,NXr),e(Tw,qXr),e(re,jXr),e(re,Mw),e(Mw,H6e),e(H6e,DXr),e(Mw,GXr),e(Mw,wre),e(wre,OXr),e(Mw,VXr),e(re,XXr),e(re,Ew),e(Ew,J6e),e(J6e,zXr),e(Ew,QXr),e(Ew,Are),e(Are,WXr),e(Ew,UXr),e(Vr,HXr),M(Cw,Vr,null),b(m,aZe,_),b(m,fm,_),e(fm,ww),e(ww,Y6e),M(nS,Y6e,null),e(fm,JXr),e(fm,K6e),e(K6e,YXr),b(m,nZe,_),b(m,hr,_),M(sS,hr,null),e(hr,KXr),e(hr,gm),e(gm,ZXr),e(gm,Lre),e(Lre,ezr),e(gm,ozr),e(gm,yre),e(yre,rzr),e(gm,tzr),e(hr,azr),e(hr,lS),e(lS,nzr),e(lS,Z6e),e(Z6e,szr),e(lS,lzr),e(hr,izr),e(hr,Kt),M(iS,Kt,null),e(Kt,dzr),e(Kt,e7e),e(e7e,czr),e(Kt,mzr),e(Kt,hm),e(hm,fzr),e(hm,o7e),e(o7e,gzr),e(hm,hzr),e(hm,xre),e(xre,uzr),e(hm,pzr),e(Kt,_zr),M(Aw,Kt,null),e(hr,bzr),e(hr,Xr),M(dS,Xr,null),e(Xr,vzr),e(Xr,r7e),e(r7e,Fzr),e(Xr,Tzr),e(Xr,Sn),e(Sn,Mzr),e(Sn,t7e),e(t7e,Ezr),e(Sn,Czr),e(Sn,a7e),e(a7e,wzr),e(Sn,Azr),e(Sn,n7e),e(n7e,Lzr),e(Sn,yzr),e(Xr,xzr),e(Xr,ve),e(ve,Lw),e(Lw,s7e),e(s7e,$zr),e(Lw,kzr),e(Lw,$re),e($re,Szr),e(Lw,Rzr),e(ve,Pzr),e(ve,yw),e(yw,l7e),e(l7e,Bzr),e(yw,Izr),e(yw,kre),e(kre,Nzr),e(yw,qzr),e(ve,jzr),e(ve,xw),e(xw,i7e),e(i7e,Dzr),e(xw,Gzr),e(xw,Sre),e(Sre,Ozr),e(xw,Vzr),e(ve,Xzr),e(ve,$w),e($w,d7e),e(d7e,zzr),e($w,Qzr),e($w,Rre),e(Rre,Wzr),e($w,Uzr),e(ve,Hzr),e(ve,kw),e(kw,c7e),e(c7e,Jzr),e(kw,Yzr),e(kw,Pre),e(Pre,Kzr),e(kw,Zzr),e(ve,eQr),e(ve,Sw),e(Sw,m7e),e(m7e,oQr),e(Sw,rQr),e(Sw,Bre),e(Bre,tQr),e(Sw,aQr),e(ve,nQr),e(ve,Rw),e(Rw,f7e),e(f7e,sQr),e(Rw,lQr),e(Rw,Ire),e(Ire,iQr),e(Rw,dQr),e(ve,cQr),e(ve,Pw),e(Pw,g7e),e(g7e,mQr),e(Pw,fQr),e(Pw,Nre),e(Nre,gQr),e(Pw,hQr),e(ve,uQr),e(ve,Bw),e(Bw,h7e),e(h7e,pQr),e(Bw,_Qr),e(Bw,qre),e(qre,bQr),e(Bw,vQr),e(ve,FQr),e(ve,Iw),e(Iw,u7e),e(u7e,TQr),e(Iw,MQr),e(Iw,jre),e(jre,EQr),e(Iw,CQr),e(ve,wQr),e(ve,Nw),e(Nw,p7e),e(p7e,AQr),e(Nw,LQr),e(Nw,Dre),e(Dre,yQr),e(Nw,xQr),e(ve,$Qr),e(ve,qw),e(qw,_7e),e(_7e,kQr),e(qw,SQr),e(qw,Gre),e(Gre,RQr),e(qw,PQr),e(ve,BQr),e(ve,jw),e(jw,b7e),e(b7e,IQr),e(jw,NQr),e(jw,Ore),e(Ore,qQr),e(jw,jQr),e(ve,DQr),e(ve,Dw),e(Dw,v7e),e(v7e,GQr),e(Dw,OQr),e(Dw,Vre),e(Vre,VQr),e(Dw,XQr),e(ve,zQr),e(ve,Gw),e(Gw,F7e),e(F7e,QQr),e(Gw,WQr),e(Gw,Xre),e(Xre,UQr),e(Gw,HQr),e(ve,JQr),e(ve,Ow),e(Ow,T7e),e(T7e,YQr),e(Ow,KQr),e(Ow,zre),e(zre,ZQr),e(Ow,eWr),e(ve,oWr),e(ve,Vw),e(Vw,M7e),e(M7e,rWr),e(Vw,tWr),e(Vw,Qre),e(Qre,aWr),e(Vw,nWr),e(Xr,sWr),M(Xw,Xr,null),b(m,sZe,_),b(m,um,_),e(um,zw),e(zw,E7e),M(cS,E7e,null),e(um,lWr),e(um,C7e),e(C7e,iWr),b(m,lZe,_),b(m,ur,_),M(mS,ur,null),e(ur,dWr),e(ur,pm),e(pm,cWr),e(pm,Wre),e(Wre,mWr),e(pm,fWr),e(pm,Ure),e(Ure,gWr),e(pm,hWr),e(ur,uWr),e(ur,fS),e(fS,pWr),e(fS,w7e),e(w7e,_Wr),e(fS,bWr),e(ur,vWr),e(ur,Zt),M(gS,Zt,null),e(Zt,FWr),e(Zt,A7e),e(A7e,TWr),e(Zt,MWr),e(Zt,_m),e(_m,EWr),e(_m,L7e),e(L7e,CWr),e(_m,wWr),e(_m,Hre),e(Hre,AWr),e(_m,LWr),e(Zt,yWr),M(Qw,Zt,null),e(ur,xWr),e(ur,zr),M(hS,zr,null),e(zr,$Wr),e(zr,y7e),e(y7e,kWr),e(zr,SWr),e(zr,Rn),e(Rn,RWr),e(Rn,x7e),e(x7e,PWr),e(Rn,BWr),e(Rn,$7e),e($7e,IWr),e(Rn,NWr),e(Rn,k7e),e(k7e,qWr),e(Rn,jWr),e(zr,DWr),e(zr,uS),e(uS,Ww),e(Ww,S7e),e(S7e,GWr),e(Ww,OWr),e(Ww,Jre),e(Jre,VWr),e(Ww,XWr),e(uS,zWr),e(uS,Uw),e(Uw,R7e),e(R7e,QWr),e(Uw,WWr),e(Uw,Yre),e(Yre,UWr),e(Uw,HWr),e(zr,JWr),M(Hw,zr,null),b(m,iZe,_),b(m,bm,_),e(bm,Jw),e(Jw,P7e),M(pS,P7e,null),e(bm,YWr),e(bm,B7e),e(B7e,KWr),b(m,dZe,_),b(m,pr,_),M(_S,pr,null),e(pr,ZWr),e(pr,vm),e(vm,eUr),e(vm,Kre),e(Kre,oUr),e(vm,rUr),e(vm,Zre),e(Zre,tUr),e(vm,aUr),e(pr,nUr),e(pr,bS),e(bS,sUr),e(bS,I7e),e(I7e,lUr),e(bS,iUr),e(pr,dUr),e(pr,ea),M(vS,ea,null),e(ea,cUr),e(ea,N7e),e(N7e,mUr),e(ea,fUr),e(ea,Fm),e(Fm,gUr),e(Fm,q7e),e(q7e,hUr),e(Fm,uUr),e(Fm,ete),e(ete,pUr),e(Fm,_Ur),e(ea,bUr),M(Yw,ea,null),e(pr,vUr),e(pr,Qr),M(FS,Qr,null),e(Qr,FUr),e(Qr,j7e),e(j7e,TUr),e(Qr,MUr),e(Qr,Pn),e(Pn,EUr),e(Pn,D7e),e(D7e,CUr),e(Pn,wUr),e(Pn,G7e),e(G7e,AUr),e(Pn,LUr),e(Pn,O7e),e(O7e,yUr),e(Pn,xUr),e(Qr,$Ur),e(Qr,V7e),e(V7e,Kw),e(Kw,X7e),e(X7e,kUr),e(Kw,SUr),e(Kw,ote),e(ote,RUr),e(Kw,PUr),e(Qr,BUr),M(Zw,Qr,null),b(m,cZe,_),b(m,Tm,_),e(Tm,eA),e(eA,z7e),M(TS,z7e,null),e(Tm,IUr),e(Tm,Q7e),e(Q7e,NUr),b(m,mZe,_),b(m,_r,_),M(MS,_r,null),e(_r,qUr),e(_r,Mm),e(Mm,jUr),e(Mm,rte),e(rte,DUr),e(Mm,GUr),e(Mm,tte),e(tte,OUr),e(Mm,VUr),e(_r,XUr),e(_r,ES),e(ES,zUr),e(ES,W7e),e(W7e,QUr),e(ES,WUr),e(_r,UUr),e(_r,oa),M(CS,oa,null),e(oa,HUr),e(oa,U7e),e(U7e,JUr),e(oa,YUr),e(oa,Em),e(Em,KUr),e(Em,H7e),e(H7e,ZUr),e(Em,eHr),e(Em,ate),e(ate,oHr),e(Em,rHr),e(oa,tHr),M(oA,oa,null),e(_r,aHr),e(_r,Wr),M(wS,Wr,null),e(Wr,nHr),e(Wr,J7e),e(J7e,sHr),e(Wr,lHr),e(Wr,Bn),e(Bn,iHr),e(Bn,Y7e),e(Y7e,dHr),e(Bn,cHr),e(Bn,K7e),e(K7e,mHr),e(Bn,fHr),e(Bn,Z7e),e(Z7e,gHr),e(Bn,hHr),e(Wr,uHr),e(Wr,eLe),e(eLe,rA),e(rA,oLe),e(oLe,pHr),e(rA,_Hr),e(rA,nte),e(nte,bHr),e(rA,vHr),e(Wr,FHr),M(tA,Wr,null),b(m,fZe,_),b(m,Cm,_),e(Cm,aA),e(aA,rLe),M(AS,rLe,null),e(Cm,THr),e(Cm,tLe),e(tLe,MHr),b(m,gZe,_),b(m,br,_),M(LS,br,null),e(br,EHr),e(br,wm),e(wm,CHr),e(wm,ste),e(ste,wHr),e(wm,AHr),e(wm,lte),e(lte,LHr),e(wm,yHr),e(br,xHr),e(br,yS),e(yS,$Hr),e(yS,aLe),e(aLe,kHr),e(yS,SHr),e(br,RHr),e(br,ra),M(xS,ra,null),e(ra,PHr),e(ra,nLe),e(nLe,BHr),e(ra,IHr),e(ra,Am),e(Am,NHr),e(Am,sLe),e(sLe,qHr),e(Am,jHr),e(Am,ite),e(ite,DHr),e(Am,GHr),e(ra,OHr),M(nA,ra,null),e(br,VHr),e(br,Ur),M($S,Ur,null),e(Ur,XHr),e(Ur,lLe),e(lLe,zHr),e(Ur,QHr),e(Ur,In),e(In,WHr),e(In,iLe),e(iLe,UHr),e(In,HHr),e(In,dLe),e(dLe,JHr),e(In,YHr),e(In,cLe),e(cLe,KHr),e(In,ZHr),e(Ur,eJr),e(Ur,de),e(de,sA),e(sA,mLe),e(mLe,oJr),e(sA,rJr),e(sA,dte),e(dte,tJr),e(sA,aJr),e(de,nJr),e(de,lA),e(lA,fLe),e(fLe,sJr),e(lA,lJr),e(lA,cte),e(cte,iJr),e(lA,dJr),e(de,cJr),e(de,iA),e(iA,gLe),e(gLe,mJr),e(iA,fJr),e(iA,mte),e(mte,gJr),e(iA,hJr),e(de,uJr),e(de,dA),e(dA,hLe),e(hLe,pJr),e(dA,_Jr),e(dA,fte),e(fte,bJr),e(dA,vJr),e(de,FJr),e(de,cA),e(cA,uLe),e(uLe,TJr),e(cA,MJr),e(cA,gte),e(gte,EJr),e(cA,CJr),e(de,wJr),e(de,mA),e(mA,pLe),e(pLe,AJr),e(mA,LJr),e(mA,hte),e(hte,yJr),e(mA,xJr),e(de,$Jr),e(de,fA),e(fA,_Le),e(_Le,kJr),e(fA,SJr),e(fA,ute),e(ute,RJr),e(fA,PJr),e(de,BJr),e(de,gA),e(gA,bLe),e(bLe,IJr),e(gA,NJr),e(gA,pte),e(pte,qJr),e(gA,jJr),e(de,DJr),e(de,hA),e(hA,vLe),e(vLe,GJr),e(hA,OJr),e(hA,_te),e(_te,VJr),e(hA,XJr),e(de,zJr),e(de,uA),e(uA,FLe),e(FLe,QJr),e(uA,WJr),e(uA,bte),e(bte,UJr),e(uA,HJr),e(de,JJr),e(de,pA),e(pA,TLe),e(TLe,YJr),e(pA,KJr),e(pA,vte),e(vte,ZJr),e(pA,eYr),e(de,oYr),e(de,_A),e(_A,MLe),e(MLe,rYr),e(_A,tYr),e(_A,Fte),e(Fte,aYr),e(_A,nYr),e(de,sYr),e(de,bA),e(bA,ELe),e(ELe,lYr),e(bA,iYr),e(bA,Tte),e(Tte,dYr),e(bA,cYr),e(de,mYr),e(de,vA),e(vA,CLe),e(CLe,fYr),e(vA,gYr),e(vA,Mte),e(Mte,hYr),e(vA,uYr),e(de,pYr),e(de,FA),e(FA,wLe),e(wLe,_Yr),e(FA,bYr),e(FA,Ete),e(Ete,vYr),e(FA,FYr),e(de,TYr),e(de,TA),e(TA,ALe),e(ALe,MYr),e(TA,EYr),e(TA,Cte),e(Cte,CYr),e(TA,wYr),e(de,AYr),e(de,MA),e(MA,LLe),e(LLe,LYr),e(MA,yYr),e(MA,wte),e(wte,xYr),e(MA,$Yr),e(de,kYr),e(de,EA),e(EA,yLe),e(yLe,SYr),e(EA,RYr),e(EA,Ate),e(Ate,PYr),e(EA,BYr),e(de,IYr),e(de,CA),e(CA,xLe),e(xLe,NYr),e(CA,qYr),e(CA,Lte),e(Lte,jYr),e(CA,DYr),e(de,GYr),e(de,wA),e(wA,$Le),e($Le,OYr),e(wA,VYr),e(wA,yte),e(yte,XYr),e(wA,zYr),e(de,QYr),e(de,AA),e(AA,kLe),e(kLe,WYr),e(AA,UYr),e(AA,xte),e(xte,HYr),e(AA,JYr),e(Ur,YYr),M(LA,Ur,null),b(m,hZe,_),b(m,Lm,_),e(Lm,yA),e(yA,SLe),M(kS,SLe,null),e(Lm,KYr),e(Lm,RLe),e(RLe,ZYr),b(m,uZe,_),b(m,vr,_),M(SS,vr,null),e(vr,eKr),e(vr,ym),e(ym,oKr),e(ym,$te),e($te,rKr),e(ym,tKr),e(ym,kte),e(kte,aKr),e(ym,nKr),e(vr,sKr),e(vr,RS),e(RS,lKr),e(RS,PLe),e(PLe,iKr),e(RS,dKr),e(vr,cKr),e(vr,ta),M(PS,ta,null),e(ta,mKr),e(ta,BLe),e(BLe,fKr),e(ta,gKr),e(ta,xm),e(xm,hKr),e(xm,ILe),e(ILe,uKr),e(xm,pKr),e(xm,Ste),e(Ste,_Kr),e(xm,bKr),e(ta,vKr),M(xA,ta,null),e(vr,FKr),e(vr,Hr),M(BS,Hr,null),e(Hr,TKr),e(Hr,NLe),e(NLe,MKr),e(Hr,EKr),e(Hr,Nn),e(Nn,CKr),e(Nn,qLe),e(qLe,wKr),e(Nn,AKr),e(Nn,jLe),e(jLe,LKr),e(Nn,yKr),e(Nn,DLe),e(DLe,xKr),e(Nn,$Kr),e(Hr,kKr),e(Hr,ce),e(ce,$A),e($A,GLe),e(GLe,SKr),e($A,RKr),e($A,Rte),e(Rte,PKr),e($A,BKr),e(ce,IKr),e(ce,kA),e(kA,OLe),e(OLe,NKr),e(kA,qKr),e(kA,Pte),e(Pte,jKr),e(kA,DKr),e(ce,GKr),e(ce,SA),e(SA,VLe),e(VLe,OKr),e(SA,VKr),e(SA,Bte),e(Bte,XKr),e(SA,zKr),e(ce,QKr),e(ce,RA),e(RA,XLe),e(XLe,WKr),e(RA,UKr),e(RA,Ite),e(Ite,HKr),e(RA,JKr),e(ce,YKr),e(ce,PA),e(PA,zLe),e(zLe,KKr),e(PA,ZKr),e(PA,Nte),e(Nte,eZr),e(PA,oZr),e(ce,rZr),e(ce,BA),e(BA,QLe),e(QLe,tZr),e(BA,aZr),e(BA,qte),e(qte,nZr),e(BA,sZr),e(ce,lZr),e(ce,IA),e(IA,WLe),e(WLe,iZr),e(IA,dZr),e(IA,jte),e(jte,cZr),e(IA,mZr),e(ce,fZr),e(ce,NA),e(NA,ULe),e(ULe,gZr),e(NA,hZr),e(NA,Dte),e(Dte,uZr),e(NA,pZr),e(ce,_Zr),e(ce,qA),e(qA,HLe),e(HLe,bZr),e(qA,vZr),e(qA,Gte),e(Gte,FZr),e(qA,TZr),e(ce,MZr),e(ce,jA),e(jA,JLe),e(JLe,EZr),e(jA,CZr),e(jA,Ote),e(Ote,wZr),e(jA,AZr),e(ce,LZr),e(ce,DA),e(DA,YLe),e(YLe,yZr),e(DA,xZr),e(DA,Vte),e(Vte,$Zr),e(DA,kZr),e(ce,SZr),e(ce,GA),e(GA,KLe),e(KLe,RZr),e(GA,PZr),e(GA,Xte),e(Xte,BZr),e(GA,IZr),e(ce,NZr),e(ce,OA),e(OA,ZLe),e(ZLe,qZr),e(OA,jZr),e(OA,zte),e(zte,DZr),e(OA,GZr),e(ce,OZr),e(ce,VA),e(VA,eye),e(eye,VZr),e(VA,XZr),e(VA,Qte),e(Qte,zZr),e(VA,QZr),e(ce,WZr),e(ce,XA),e(XA,oye),e(oye,UZr),e(XA,HZr),e(XA,Wte),e(Wte,JZr),e(XA,YZr),e(ce,KZr),e(ce,zA),e(zA,rye),e(rye,ZZr),e(zA,eet),e(zA,Ute),e(Ute,oet),e(zA,ret),e(ce,tet),e(ce,QA),e(QA,tye),e(tye,aet),e(QA,net),e(QA,Hte),e(Hte,set),e(QA,iet),e(ce,det),e(ce,WA),e(WA,aye),e(aye,cet),e(WA,met),e(WA,Jte),e(Jte,fet),e(WA,get),e(ce,het),e(ce,UA),e(UA,nye),e(nye,uet),e(UA,pet),e(UA,Yte),e(Yte,_et),e(UA,bet),e(ce,vet),e(ce,HA),e(HA,sye),e(sye,Fet),e(HA,Tet),e(HA,Kte),e(Kte,Met),e(HA,Eet),e(ce,Cet),e(ce,JA),e(JA,lye),e(lye,wet),e(JA,Aet),e(JA,Zte),e(Zte,Let),e(JA,yet),e(Hr,xet),M(YA,Hr,null),b(m,pZe,_),b(m,$m,_),e($m,KA),e(KA,iye),M(IS,iye,null),e($m,$et),e($m,dye),e(dye,ket),b(m,_Ze,_),b(m,Fr,_),M(NS,Fr,null),e(Fr,Set),e(Fr,km),e(km,Ret),e(km,eae),e(eae,Pet),e(km,Bet),e(km,oae),e(oae,Iet),e(km,Net),e(Fr,qet),e(Fr,qS),e(qS,jet),e(qS,cye),e(cye,Det),e(qS,Get),e(Fr,Oet),e(Fr,aa),M(jS,aa,null),e(aa,Vet),e(aa,mye),e(mye,Xet),e(aa,zet),e(aa,Sm),e(Sm,Qet),e(Sm,fye),e(fye,Wet),e(Sm,Uet),e(Sm,rae),e(rae,Het),e(Sm,Jet),e(aa,Yet),M(ZA,aa,null),e(Fr,Ket),e(Fr,Jr),M(DS,Jr,null),e(Jr,Zet),e(Jr,gye),e(gye,eot),e(Jr,oot),e(Jr,qn),e(qn,rot),e(qn,hye),e(hye,tot),e(qn,aot),e(qn,uye),e(uye,not),e(qn,sot),e(qn,pye),e(pye,lot),e(qn,iot),e(Jr,dot),e(Jr,_ye),e(_ye,e6),e(e6,bye),e(bye,cot),e(e6,mot),e(e6,tae),e(tae,fot),e(e6,got),e(Jr,hot),M(o6,Jr,null),b(m,bZe,_),b(m,Rm,_),e(Rm,r6),e(r6,vye),M(GS,vye,null),e(Rm,uot),e(Rm,Fye),e(Fye,pot),b(m,vZe,_),b(m,Tr,_),M(OS,Tr,null),e(Tr,_ot),e(Tr,Pm),e(Pm,bot),e(Pm,aae),e(aae,vot),e(Pm,Fot),e(Pm,nae),e(nae,Tot),e(Pm,Mot),e(Tr,Eot),e(Tr,VS),e(VS,Cot),e(VS,Tye),e(Tye,wot),e(VS,Aot),e(Tr,Lot),e(Tr,na),M(XS,na,null),e(na,yot),e(na,Mye),e(Mye,xot),e(na,$ot),e(na,Bm),e(Bm,kot),e(Bm,Eye),e(Eye,Sot),e(Bm,Rot),e(Bm,sae),e(sae,Pot),e(Bm,Bot),e(na,Iot),M(t6,na,null),e(Tr,Not),e(Tr,Yr),M(zS,Yr,null),e(Yr,qot),e(Yr,Cye),e(Cye,jot),e(Yr,Dot),e(Yr,jn),e(jn,Got),e(jn,wye),e(wye,Oot),e(jn,Vot),e(jn,Aye),e(Aye,Xot),e(jn,zot),e(jn,Lye),e(Lye,Qot),e(jn,Wot),e(Yr,Uot),e(Yr,yye),e(yye,a6),e(a6,xye),e(xye,Hot),e(a6,Jot),e(a6,lae),e(lae,Yot),e(a6,Kot),e(Yr,Zot),M(n6,Yr,null),b(m,FZe,_),b(m,Im,_),e(Im,s6),e(s6,$ye),M(QS,$ye,null),e(Im,ert),e(Im,kye),e(kye,ort),b(m,TZe,_),b(m,Mr,_),M(WS,Mr,null),e(Mr,rrt),e(Mr,Nm),e(Nm,trt),e(Nm,iae),e(iae,art),e(Nm,nrt),e(Nm,dae),e(dae,srt),e(Nm,lrt),e(Mr,irt),e(Mr,US),e(US,drt),e(US,Sye),e(Sye,crt),e(US,mrt),e(Mr,frt),e(Mr,sa),M(HS,sa,null),e(sa,grt),e(sa,Rye),e(Rye,hrt),e(sa,urt),e(sa,qm),e(qm,prt),e(qm,Pye),e(Pye,_rt),e(qm,brt),e(qm,cae),e(cae,vrt),e(qm,Frt),e(sa,Trt),M(l6,sa,null),e(Mr,Mrt),e(Mr,Kr),M(JS,Kr,null),e(Kr,Ert),e(Kr,Bye),e(Bye,Crt),e(Kr,wrt),e(Kr,Dn),e(Dn,Art),e(Dn,Iye),e(Iye,Lrt),e(Dn,yrt),e(Dn,Nye),e(Nye,xrt),e(Dn,$rt),e(Dn,qye),e(qye,krt),e(Dn,Srt),e(Kr,Rrt),e(Kr,te),e(te,i6),e(i6,jye),e(jye,Prt),e(i6,Brt),e(i6,mae),e(mae,Irt),e(i6,Nrt),e(te,qrt),e(te,d6),e(d6,Dye),e(Dye,jrt),e(d6,Drt),e(d6,fae),e(fae,Grt),e(d6,Ort),e(te,Vrt),e(te,c6),e(c6,Gye),e(Gye,Xrt),e(c6,zrt),e(c6,gae),e(gae,Qrt),e(c6,Wrt),e(te,Urt),e(te,m6),e(m6,Oye),e(Oye,Hrt),e(m6,Jrt),e(m6,hae),e(hae,Yrt),e(m6,Krt),e(te,Zrt),e(te,f6),e(f6,Vye),e(Vye,ett),e(f6,ott),e(f6,uae),e(uae,rtt),e(f6,ttt),e(te,att),e(te,g6),e(g6,Xye),e(Xye,ntt),e(g6,stt),e(g6,pae),e(pae,ltt),e(g6,itt),e(te,dtt),e(te,h6),e(h6,zye),e(zye,ctt),e(h6,mtt),e(h6,_ae),e(_ae,ftt),e(h6,gtt),e(te,htt),e(te,u6),e(u6,Qye),e(Qye,utt),e(u6,ptt),e(u6,bae),e(bae,_tt),e(u6,btt),e(te,vtt),e(te,p6),e(p6,Wye),e(Wye,Ftt),e(p6,Ttt),e(p6,vae),e(vae,Mtt),e(p6,Ett),e(te,Ctt),e(te,_6),e(_6,Uye),e(Uye,wtt),e(_6,Att),e(_6,Fae),e(Fae,Ltt),e(_6,ytt),e(te,xtt),e(te,b6),e(b6,Hye),e(Hye,$tt),e(b6,ktt),e(b6,Tae),e(Tae,Stt),e(b6,Rtt),e(te,Ptt),e(te,v6),e(v6,Jye),e(Jye,Btt),e(v6,Itt),e(v6,Mae),e(Mae,Ntt),e(v6,qtt),e(te,jtt),e(te,F6),e(F6,Yye),e(Yye,Dtt),e(F6,Gtt),e(F6,Eae),e(Eae,Ott),e(F6,Vtt),e(te,Xtt),e(te,T6),e(T6,Kye),e(Kye,ztt),e(T6,Qtt),e(T6,Cae),e(Cae,Wtt),e(T6,Utt),e(te,Htt),e(te,M6),e(M6,Zye),e(Zye,Jtt),e(M6,Ytt),e(M6,wae),e(wae,Ktt),e(M6,Ztt),e(te,eat),e(te,E6),e(E6,e8e),e(e8e,oat),e(E6,rat),e(E6,Aae),e(Aae,tat),e(E6,aat),e(te,nat),e(te,C6),e(C6,o8e),e(o8e,sat),e(C6,lat),e(C6,Lae),e(Lae,iat),e(C6,dat),e(te,cat),e(te,w6),e(w6,r8e),e(r8e,mat),e(w6,fat),e(w6,yae),e(yae,gat),e(w6,hat),e(te,uat),e(te,A6),e(A6,t8e),e(t8e,pat),e(A6,_at),e(A6,xae),e(xae,bat),e(A6,vat),e(te,Fat),e(te,L6),e(L6,a8e),e(a8e,Tat),e(L6,Mat),e(L6,$ae),e($ae,Eat),e(L6,Cat),e(te,wat),e(te,y6),e(y6,n8e),e(n8e,Aat),e(y6,Lat),e(y6,kae),e(kae,yat),e(y6,xat),e(te,$at),e(te,x6),e(x6,s8e),e(s8e,kat),e(x6,Sat),e(x6,Sae),e(Sae,Rat),e(x6,Pat),e(te,Bat),e(te,$6),e($6,l8e),e(l8e,Iat),e($6,Nat),e($6,Rae),e(Rae,qat),e($6,jat),e(te,Dat),e(te,k6),e(k6,i8e),e(i8e,Gat),e(k6,Oat),e(k6,Pae),e(Pae,Vat),e(k6,Xat),e(te,zat),e(te,S6),e(S6,d8e),e(d8e,Qat),e(S6,Wat),e(S6,Bae),e(Bae,Uat),e(S6,Hat),e(te,Jat),e(te,R6),e(R6,c8e),e(c8e,Yat),e(R6,Kat),e(R6,Iae),e(Iae,Zat),e(R6,ent),e(te,ont),e(te,P6),e(P6,m8e),e(m8e,rnt),e(P6,tnt),e(P6,Nae),e(Nae,ant),e(P6,nnt),e(Kr,snt),M(B6,Kr,null),b(m,MZe,_),b(m,jm,_),e(jm,I6),e(I6,f8e),M(YS,f8e,null),e(jm,lnt),e(jm,g8e),e(g8e,int),b(m,EZe,_),b(m,Er,_),M(KS,Er,null),e(Er,dnt),e(Er,Dm),e(Dm,cnt),e(Dm,qae),e(qae,mnt),e(Dm,fnt),e(Dm,jae),e(jae,gnt),e(Dm,hnt),e(Er,unt),e(Er,ZS),e(ZS,pnt),e(ZS,h8e),e(h8e,_nt),e(ZS,bnt),e(Er,vnt),e(Er,la),M(eR,la,null),e(la,Fnt),e(la,u8e),e(u8e,Tnt),e(la,Mnt),e(la,Gm),e(Gm,Ent),e(Gm,p8e),e(p8e,Cnt),e(Gm,wnt),e(Gm,Dae),e(Dae,Ant),e(Gm,Lnt),e(la,ynt),M(N6,la,null),e(Er,xnt),e(Er,Zr),M(oR,Zr,null),e(Zr,$nt),e(Zr,_8e),e(_8e,knt),e(Zr,Snt),e(Zr,Gn),e(Gn,Rnt),e(Gn,b8e),e(b8e,Pnt),e(Gn,Bnt),e(Gn,v8e),e(v8e,Int),e(Gn,Nnt),e(Gn,F8e),e(F8e,qnt),e(Gn,jnt),e(Zr,Dnt),e(Zr,xe),e(xe,q6),e(q6,T8e),e(T8e,Gnt),e(q6,Ont),e(q6,Gae),e(Gae,Vnt),e(q6,Xnt),e(xe,znt),e(xe,j6),e(j6,M8e),e(M8e,Qnt),e(j6,Wnt),e(j6,Oae),e(Oae,Unt),e(j6,Hnt),e(xe,Jnt),e(xe,D6),e(D6,E8e),e(E8e,Ynt),e(D6,Knt),e(D6,Vae),e(Vae,Znt),e(D6,est),e(xe,ost),e(xe,G6),e(G6,C8e),e(C8e,rst),e(G6,tst),e(G6,Xae),e(Xae,ast),e(G6,nst),e(xe,sst),e(xe,O6),e(O6,w8e),e(w8e,lst),e(O6,ist),e(O6,zae),e(zae,dst),e(O6,cst),e(xe,mst),e(xe,V6),e(V6,A8e),e(A8e,fst),e(V6,gst),e(V6,Qae),e(Qae,hst),e(V6,ust),e(xe,pst),e(xe,X6),e(X6,L8e),e(L8e,_st),e(X6,bst),e(X6,Wae),e(Wae,vst),e(X6,Fst),e(xe,Tst),e(xe,z6),e(z6,y8e),e(y8e,Mst),e(z6,Est),e(z6,Uae),e(Uae,Cst),e(z6,wst),e(xe,Ast),e(xe,Q6),e(Q6,x8e),e(x8e,Lst),e(Q6,yst),e(Q6,Hae),e(Hae,xst),e(Q6,$st),e(xe,kst),e(xe,W6),e(W6,$8e),e($8e,Sst),e(W6,Rst),e(W6,Jae),e(Jae,Pst),e(W6,Bst),e(Zr,Ist),M(U6,Zr,null),b(m,CZe,_),b(m,Om,_),e(Om,H6),e(H6,k8e),M(rR,k8e,null),e(Om,Nst),e(Om,S8e),e(S8e,qst),b(m,wZe,_),b(m,Cr,_),M(tR,Cr,null),e(Cr,jst),e(Cr,Vm),e(Vm,Dst),e(Vm,Yae),e(Yae,Gst),e(Vm,Ost),e(Vm,Kae),e(Kae,Vst),e(Vm,Xst),e(Cr,zst),e(Cr,aR),e(aR,Qst),e(aR,R8e),e(R8e,Wst),e(aR,Ust),e(Cr,Hst),e(Cr,ia),M(nR,ia,null),e(ia,Jst),e(ia,P8e),e(P8e,Yst),e(ia,Kst),e(ia,Xm),e(Xm,Zst),e(Xm,B8e),e(B8e,elt),e(Xm,olt),e(Xm,Zae),e(Zae,rlt),e(Xm,tlt),e(ia,alt),M(J6,ia,null),e(Cr,nlt),e(Cr,et),M(sR,et,null),e(et,slt),e(et,I8e),e(I8e,llt),e(et,ilt),e(et,On),e(On,dlt),e(On,N8e),e(N8e,clt),e(On,mlt),e(On,q8e),e(q8e,flt),e(On,glt),e(On,j8e),e(j8e,hlt),e(On,ult),e(et,plt),e(et,Ee),e(Ee,Y6),e(Y6,D8e),e(D8e,_lt),e(Y6,blt),e(Y6,ene),e(ene,vlt),e(Y6,Flt),e(Ee,Tlt),e(Ee,K6),e(K6,G8e),e(G8e,Mlt),e(K6,Elt),e(K6,one),e(one,Clt),e(K6,wlt),e(Ee,Alt),e(Ee,Z6),e(Z6,O8e),e(O8e,Llt),e(Z6,ylt),e(Z6,rne),e(rne,xlt),e(Z6,$lt),e(Ee,klt),e(Ee,e7),e(e7,V8e),e(V8e,Slt),e(e7,Rlt),e(e7,tne),e(tne,Plt),e(e7,Blt),e(Ee,Ilt),e(Ee,o7),e(o7,X8e),e(X8e,Nlt),e(o7,qlt),e(o7,ane),e(ane,jlt),e(o7,Dlt),e(Ee,Glt),e(Ee,r7),e(r7,z8e),e(z8e,Olt),e(r7,Vlt),e(r7,nne),e(nne,Xlt),e(r7,zlt),e(Ee,Qlt),e(Ee,t7),e(t7,Q8e),e(Q8e,Wlt),e(t7,Ult),e(t7,sne),e(sne,Hlt),e(t7,Jlt),e(Ee,Ylt),e(Ee,a7),e(a7,W8e),e(W8e,Klt),e(a7,Zlt),e(a7,lne),e(lne,eit),e(a7,oit),e(Ee,rit),e(Ee,n7),e(n7,U8e),e(U8e,tit),e(n7,ait),e(n7,ine),e(ine,nit),e(n7,sit),e(Ee,lit),e(Ee,s7),e(s7,H8e),e(H8e,iit),e(s7,dit),e(s7,dne),e(dne,cit),e(s7,mit),e(Ee,fit),e(Ee,l7),e(l7,J8e),e(J8e,git),e(l7,hit),e(l7,cne),e(cne,uit),e(l7,pit),e(Ee,_it),e(Ee,i7),e(i7,Y8e),e(Y8e,bit),e(i7,vit),e(i7,mne),e(mne,Fit),e(i7,Tit),e(Ee,Mit),e(Ee,d7),e(d7,K8e),e(K8e,Eit),e(d7,Cit),e(d7,fne),e(fne,wit),e(d7,Ait),e(et,Lit),M(c7,et,null),b(m,AZe,_),b(m,zm,_),e(zm,m7),e(m7,Z8e),M(lR,Z8e,null),e(zm,yit),e(zm,e9e),e(e9e,xit),b(m,LZe,_),b(m,wr,_),M(iR,wr,null),e(wr,$it),e(wr,Qm),e(Qm,kit),e(Qm,gne),e(gne,Sit),e(Qm,Rit),e(Qm,hne),e(hne,Pit),e(Qm,Bit),e(wr,Iit),e(wr,dR),e(dR,Nit),e(dR,o9e),e(o9e,qit),e(dR,jit),e(wr,Dit),e(wr,da),M(cR,da,null),e(da,Git),e(da,r9e),e(r9e,Oit),e(da,Vit),e(da,Wm),e(Wm,Xit),e(Wm,t9e),e(t9e,zit),e(Wm,Qit),e(Wm,une),e(une,Wit),e(Wm,Uit),e(da,Hit),M(f7,da,null),e(wr,Jit),e(wr,ot),M(mR,ot,null),e(ot,Yit),e(ot,a9e),e(a9e,Kit),e(ot,Zit),e(ot,Vn),e(Vn,edt),e(Vn,n9e),e(n9e,odt),e(Vn,rdt),e(Vn,s9e),e(s9e,tdt),e(Vn,adt),e(Vn,l9e),e(l9e,ndt),e(Vn,sdt),e(ot,ldt),e(ot,$e),e($e,g7),e(g7,i9e),e(i9e,idt),e(g7,ddt),e(g7,pne),e(pne,cdt),e(g7,mdt),e($e,fdt),e($e,h7),e(h7,d9e),e(d9e,gdt),e(h7,hdt),e(h7,_ne),e(_ne,udt),e(h7,pdt),e($e,_dt),e($e,u7),e(u7,c9e),e(c9e,bdt),e(u7,vdt),e(u7,bne),e(bne,Fdt),e(u7,Tdt),e($e,Mdt),e($e,p7),e(p7,m9e),e(m9e,Edt),e(p7,Cdt),e(p7,vne),e(vne,wdt),e(p7,Adt),e($e,Ldt),e($e,_7),e(_7,f9e),e(f9e,ydt),e(_7,xdt),e(_7,Fne),e(Fne,$dt),e(_7,kdt),e($e,Sdt),e($e,b7),e(b7,g9e),e(g9e,Rdt),e(b7,Pdt),e(b7,Tne),e(Tne,Bdt),e(b7,Idt),e($e,Ndt),e($e,v7),e(v7,h9e),e(h9e,qdt),e(v7,jdt),e(v7,Mne),e(Mne,Ddt),e(v7,Gdt),e($e,Odt),e($e,F7),e(F7,u9e),e(u9e,Vdt),e(F7,Xdt),e(F7,Ene),e(Ene,zdt),e(F7,Qdt),e($e,Wdt),e($e,T7),e(T7,p9e),e(p9e,Udt),e(T7,Hdt),e(T7,Cne),e(Cne,Jdt),e(T7,Ydt),e($e,Kdt),e($e,M7),e(M7,_9e),e(_9e,Zdt),e(M7,ect),e(M7,wne),e(wne,oct),e(M7,rct),e(ot,tct),M(E7,ot,null),b(m,yZe,_),b(m,Um,_),e(Um,C7),e(C7,b9e),M(fR,b9e,null),e(Um,act),e(Um,v9e),e(v9e,nct),b(m,xZe,_),b(m,Ar,_),M(gR,Ar,null),e(Ar,sct),e(Ar,Hm),e(Hm,lct),e(Hm,Ane),e(Ane,ict),e(Hm,dct),e(Hm,Lne),e(Lne,cct),e(Hm,mct),e(Ar,fct),e(Ar,hR),e(hR,gct),e(hR,F9e),e(F9e,hct),e(hR,uct),e(Ar,pct),e(Ar,ca),M(uR,ca,null),e(ca,_ct),e(ca,T9e),e(T9e,bct),e(ca,vct),e(ca,Jm),e(Jm,Fct),e(Jm,M9e),e(M9e,Tct),e(Jm,Mct),e(Jm,yne),e(yne,Ect),e(Jm,Cct),e(ca,wct),M(w7,ca,null),e(Ar,Act),e(Ar,rt),M(pR,rt,null),e(rt,Lct),e(rt,E9e),e(E9e,yct),e(rt,xct),e(rt,Xn),e(Xn,$ct),e(Xn,C9e),e(C9e,kct),e(Xn,Sct),e(Xn,w9e),e(w9e,Rct),e(Xn,Pct),e(Xn,A9e),e(A9e,Bct),e(Xn,Ict),e(rt,Nct),e(rt,ke),e(ke,A7),e(A7,L9e),e(L9e,qct),e(A7,jct),e(A7,xne),e(xne,Dct),e(A7,Gct),e(ke,Oct),e(ke,L7),e(L7,y9e),e(y9e,Vct),e(L7,Xct),e(L7,$ne),e($ne,zct),e(L7,Qct),e(ke,Wct),e(ke,y7),e(y7,x9e),e(x9e,Uct),e(y7,Hct),e(y7,kne),e(kne,Jct),e(y7,Yct),e(ke,Kct),e(ke,x7),e(x7,$9e),e($9e,Zct),e(x7,emt),e(x7,Sne),e(Sne,omt),e(x7,rmt),e(ke,tmt),e(ke,$7),e($7,k9e),e(k9e,amt),e($7,nmt),e($7,Rne),e(Rne,smt),e($7,lmt),e(ke,imt),e(ke,k7),e(k7,S9e),e(S9e,dmt),e(k7,cmt),e(k7,Pne),e(Pne,mmt),e(k7,fmt),e(ke,gmt),e(ke,S7),e(S7,R9e),e(R9e,hmt),e(S7,umt),e(S7,Bne),e(Bne,pmt),e(S7,_mt),e(ke,bmt),e(ke,R7),e(R7,P9e),e(P9e,vmt),e(R7,Fmt),e(R7,Ine),e(Ine,Tmt),e(R7,Mmt),e(ke,Emt),e(ke,P7),e(P7,B9e),e(B9e,Cmt),e(P7,wmt),e(P7,Nne),e(Nne,Amt),e(P7,Lmt),e(ke,ymt),e(ke,B7),e(B7,I9e),e(I9e,xmt),e(B7,$mt),e(B7,qne),e(qne,kmt),e(B7,Smt),e(rt,Rmt),M(I7,rt,null),b(m,$Ze,_),b(m,Ym,_),e(Ym,N7),e(N7,N9e),M(_R,N9e,null),e(Ym,Pmt),e(Ym,q9e),e(q9e,Bmt),b(m,kZe,_),b(m,Lr,_),M(bR,Lr,null),e(Lr,Imt),e(Lr,Km),e(Km,Nmt),e(Km,jne),e(jne,qmt),e(Km,jmt),e(Km,Dne),e(Dne,Dmt),e(Km,Gmt),e(Lr,Omt),e(Lr,vR),e(vR,Vmt),e(vR,j9e),e(j9e,Xmt),e(vR,zmt),e(Lr,Qmt),e(Lr,ma),M(FR,ma,null),e(ma,Wmt),e(ma,D9e),e(D9e,Umt),e(ma,Hmt),e(ma,Zm),e(Zm,Jmt),e(Zm,G9e),e(G9e,Ymt),e(Zm,Kmt),e(Zm,Gne),e(Gne,Zmt),e(Zm,eft),e(ma,oft),M(q7,ma,null),e(Lr,rft),e(Lr,tt),M(TR,tt,null),e(tt,tft),e(tt,O9e),e(O9e,aft),e(tt,nft),e(tt,zn),e(zn,sft),e(zn,V9e),e(V9e,lft),e(zn,ift),e(zn,X9e),e(X9e,dft),e(zn,cft),e(zn,z9e),e(z9e,mft),e(zn,fft),e(tt,gft),e(tt,Se),e(Se,j7),e(j7,Q9e),e(Q9e,hft),e(j7,uft),e(j7,One),e(One,pft),e(j7,_ft),e(Se,bft),e(Se,D7),e(D7,W9e),e(W9e,vft),e(D7,Fft),e(D7,Vne),e(Vne,Tft),e(D7,Mft),e(Se,Eft),e(Se,G7),e(G7,U9e),e(U9e,Cft),e(G7,wft),e(G7,Xne),e(Xne,Aft),e(G7,Lft),e(Se,yft),e(Se,O7),e(O7,H9e),e(H9e,xft),e(O7,$ft),e(O7,zne),e(zne,kft),e(O7,Sft),e(Se,Rft),e(Se,V7),e(V7,J9e),e(J9e,Pft),e(V7,Bft),e(V7,Qne),e(Qne,Ift),e(V7,Nft),e(Se,qft),e(Se,X7),e(X7,Y9e),e(Y9e,jft),e(X7,Dft),e(X7,Wne),e(Wne,Gft),e(X7,Oft),e(Se,Vft),e(Se,z7),e(z7,K9e),e(K9e,Xft),e(z7,zft),e(z7,Une),e(Une,Qft),e(z7,Wft),e(Se,Uft),e(Se,Q7),e(Q7,Z9e),e(Z9e,Hft),e(Q7,Jft),e(Q7,Hne),e(Hne,Yft),e(Q7,Kft),e(Se,Zft),e(Se,W7),e(W7,exe),e(exe,egt),e(W7,ogt),e(W7,Jne),e(Jne,rgt),e(W7,tgt),e(Se,agt),e(Se,U7),e(U7,oxe),e(oxe,ngt),e(U7,sgt),e(U7,Yne),e(Yne,lgt),e(U7,igt),e(tt,dgt),M(H7,tt,null),b(m,SZe,_),b(m,ef,_),e(ef,J7),e(J7,rxe),M(MR,rxe,null),e(ef,cgt),e(ef,txe),e(txe,mgt),b(m,RZe,_),b(m,yr,_),M(ER,yr,null),e(yr,fgt),e(yr,of),e(of,ggt),e(of,Kne),e(Kne,hgt),e(of,ugt),e(of,Zne),e(Zne,pgt),e(of,_gt),e(yr,bgt),e(yr,CR),e(CR,vgt),e(CR,axe),e(axe,Fgt),e(CR,Tgt),e(yr,Mgt),e(yr,fa),M(wR,fa,null),e(fa,Egt),e(fa,nxe),e(nxe,Cgt),e(fa,wgt),e(fa,rf),e(rf,Agt),e(rf,sxe),e(sxe,Lgt),e(rf,ygt),e(rf,ese),e(ese,xgt),e(rf,$gt),e(fa,kgt),M(Y7,fa,null),e(yr,Sgt),e(yr,at),M(AR,at,null),e(at,Rgt),e(at,lxe),e(lxe,Pgt),e(at,Bgt),e(at,Qn),e(Qn,Igt),e(Qn,ixe),e(ixe,Ngt),e(Qn,qgt),e(Qn,dxe),e(dxe,jgt),e(Qn,Dgt),e(Qn,cxe),e(cxe,Ggt),e(Qn,Ogt),e(at,Vgt),e(at,Re),e(Re,K7),e(K7,mxe),e(mxe,Xgt),e(K7,zgt),e(K7,ose),e(ose,Qgt),e(K7,Wgt),e(Re,Ugt),e(Re,Z7),e(Z7,fxe),e(fxe,Hgt),e(Z7,Jgt),e(Z7,rse),e(rse,Ygt),e(Z7,Kgt),e(Re,Zgt),e(Re,eL),e(eL,gxe),e(gxe,eht),e(eL,oht),e(eL,tse),e(tse,rht),e(eL,tht),e(Re,aht),e(Re,oL),e(oL,hxe),e(hxe,nht),e(oL,sht),e(oL,ase),e(ase,lht),e(oL,iht),e(Re,dht),e(Re,rL),e(rL,uxe),e(uxe,cht),e(rL,mht),e(rL,nse),e(nse,fht),e(rL,ght),e(Re,hht),e(Re,tL),e(tL,pxe),e(pxe,uht),e(tL,pht),e(tL,sse),e(sse,_ht),e(tL,bht),e(Re,vht),e(Re,aL),e(aL,_xe),e(_xe,Fht),e(aL,Tht),e(aL,lse),e(lse,Mht),e(aL,Eht),e(Re,Cht),e(Re,nL),e(nL,bxe),e(bxe,wht),e(nL,Aht),e(nL,ise),e(ise,Lht),e(nL,yht),e(Re,xht),e(Re,sL),e(sL,vxe),e(vxe,$ht),e(sL,kht),e(sL,dse),e(dse,Sht),e(sL,Rht),e(Re,Pht),e(Re,lL),e(lL,Fxe),e(Fxe,Bht),e(lL,Iht),e(lL,cse),e(cse,Nht),e(lL,qht),e(at,jht),M(iL,at,null),b(m,PZe,_),b(m,tf,_),e(tf,dL),e(dL,Txe),M(LR,Txe,null),e(tf,Dht),e(tf,Mxe),e(Mxe,Ght),b(m,BZe,_),b(m,xr,_),M(yR,xr,null),e(xr,Oht),e(xr,af),e(af,Vht),e(af,mse),e(mse,Xht),e(af,zht),e(af,fse),e(fse,Qht),e(af,Wht),e(xr,Uht),e(xr,xR),e(xR,Hht),e(xR,Exe),e(Exe,Jht),e(xR,Yht),e(xr,Kht),e(xr,ga),M($R,ga,null),e(ga,Zht),e(ga,Cxe),e(Cxe,eut),e(ga,out),e(ga,nf),e(nf,rut),e(nf,wxe),e(wxe,tut),e(nf,aut),e(nf,gse),e(gse,nut),e(nf,sut),e(ga,lut),M(cL,ga,null),e(xr,iut),e(xr,nt),M(kR,nt,null),e(nt,dut),e(nt,Axe),e(Axe,cut),e(nt,mut),e(nt,Wn),e(Wn,fut),e(Wn,Lxe),e(Lxe,gut),e(Wn,hut),e(Wn,yxe),e(yxe,uut),e(Wn,put),e(Wn,xxe),e(xxe,_ut),e(Wn,but),e(nt,vut),e(nt,Xe),e(Xe,mL),e(mL,$xe),e($xe,Fut),e(mL,Tut),e(mL,hse),e(hse,Mut),e(mL,Eut),e(Xe,Cut),e(Xe,fL),e(fL,kxe),e(kxe,wut),e(fL,Aut),e(fL,use),e(use,Lut),e(fL,yut),e(Xe,xut),e(Xe,gL),e(gL,Sxe),e(Sxe,$ut),e(gL,kut),e(gL,pse),e(pse,Sut),e(gL,Rut),e(Xe,Put),e(Xe,hL),e(hL,Rxe),e(Rxe,But),e(hL,Iut),e(hL,_se),e(_se,Nut),e(hL,qut),e(Xe,jut),e(Xe,uL),e(uL,Pxe),e(Pxe,Dut),e(uL,Gut),e(uL,bse),e(bse,Out),e(uL,Vut),e(Xe,Xut),e(Xe,pL),e(pL,Bxe),e(Bxe,zut),e(pL,Qut),e(pL,vse),e(vse,Wut),e(pL,Uut),e(Xe,Hut),e(Xe,_L),e(_L,Ixe),e(Ixe,Jut),e(_L,Yut),e(_L,Fse),e(Fse,Kut),e(_L,Zut),e(Xe,ept),e(Xe,bL),e(bL,Nxe),e(Nxe,opt),e(bL,rpt),e(bL,Tse),e(Tse,tpt),e(bL,apt),e(nt,npt),M(vL,nt,null),b(m,IZe,_),b(m,sf,_),e(sf,FL),e(FL,qxe),M(SR,qxe,null),e(sf,spt),e(sf,jxe),e(jxe,lpt),b(m,NZe,_),b(m,$r,_),M(RR,$r,null),e($r,ipt),e($r,lf),e(lf,dpt),e(lf,Mse),e(Mse,cpt),e(lf,mpt),e(lf,Ese),e(Ese,fpt),e(lf,gpt),e($r,hpt),e($r,PR),e(PR,upt),e(PR,Dxe),e(Dxe,ppt),e(PR,_pt),e($r,bpt),e($r,ha),M(BR,ha,null),e(ha,vpt),e(ha,Gxe),e(Gxe,Fpt),e(ha,Tpt),e(ha,df),e(df,Mpt),e(df,Oxe),e(Oxe,Ept),e(df,Cpt),e(df,Cse),e(Cse,wpt),e(df,Apt),e(ha,Lpt),M(TL,ha,null),e($r,ypt),e($r,st),M(IR,st,null),e(st,xpt),e(st,Vxe),e(Vxe,$pt),e(st,kpt),e(st,Un),e(Un,Spt),e(Un,Xxe),e(Xxe,Rpt),e(Un,Ppt),e(Un,zxe),e(zxe,Bpt),e(Un,Ipt),e(Un,Qxe),e(Qxe,Npt),e(Un,qpt),e(st,jpt),e(st,ze),e(ze,ML),e(ML,Wxe),e(Wxe,Dpt),e(ML,Gpt),e(ML,wse),e(wse,Opt),e(ML,Vpt),e(ze,Xpt),e(ze,EL),e(EL,Uxe),e(Uxe,zpt),e(EL,Qpt),e(EL,Ase),e(Ase,Wpt),e(EL,Upt),e(ze,Hpt),e(ze,CL),e(CL,Hxe),e(Hxe,Jpt),e(CL,Ypt),e(CL,Lse),e(Lse,Kpt),e(CL,Zpt),e(ze,e_t),e(ze,wL),e(wL,Jxe),e(Jxe,o_t),e(wL,r_t),e(wL,yse),e(yse,t_t),e(wL,a_t),e(ze,n_t),e(ze,AL),e(AL,Yxe),e(Yxe,s_t),e(AL,l_t),e(AL,xse),e(xse,i_t),e(AL,d_t),e(ze,c_t),e(ze,LL),e(LL,Kxe),e(Kxe,m_t),e(LL,f_t),e(LL,$se),e($se,g_t),e(LL,h_t),e(ze,u_t),e(ze,yL),e(yL,Zxe),e(Zxe,p_t),e(yL,__t),e(yL,kse),e(kse,b_t),e(yL,v_t),e(ze,F_t),e(ze,xL),e(xL,e$e),e(e$e,T_t),e(xL,M_t),e(xL,Sse),e(Sse,E_t),e(xL,C_t),e(st,w_t),M($L,st,null),b(m,qZe,_),b(m,cf,_),e(cf,kL),e(kL,o$e),M(NR,o$e,null),e(cf,A_t),e(cf,r$e),e(r$e,L_t),b(m,jZe,_),b(m,kr,_),M(qR,kr,null),e(kr,y_t),e(kr,mf),e(mf,x_t),e(mf,Rse),e(Rse,$_t),e(mf,k_t),e(mf,Pse),e(Pse,S_t),e(mf,R_t),e(kr,P_t),e(kr,jR),e(jR,B_t),e(jR,t$e),e(t$e,I_t),e(jR,N_t),e(kr,q_t),e(kr,ua),M(DR,ua,null),e(ua,j_t),e(ua,a$e),e(a$e,D_t),e(ua,G_t),e(ua,ff),e(ff,O_t),e(ff,n$e),e(n$e,V_t),e(ff,X_t),e(ff,Bse),e(Bse,z_t),e(ff,Q_t),e(ua,W_t),M(SL,ua,null),e(kr,U_t),e(kr,lt),M(GR,lt,null),e(lt,H_t),e(lt,s$e),e(s$e,J_t),e(lt,Y_t),e(lt,Hn),e(Hn,K_t),e(Hn,l$e),e(l$e,Z_t),e(Hn,e2t),e(Hn,i$e),e(i$e,o2t),e(Hn,r2t),e(Hn,d$e),e(d$e,t2t),e(Hn,a2t),e(lt,n2t),e(lt,c$e),e(c$e,RL),e(RL,m$e),e(m$e,s2t),e(RL,l2t),e(RL,Ise),e(Ise,i2t),e(RL,d2t),e(lt,c2t),M(PL,lt,null),b(m,DZe,_),b(m,gf,_),e(gf,BL),e(BL,f$e),M(OR,f$e,null),e(gf,m2t),e(gf,g$e),e(g$e,f2t),b(m,GZe,_),b(m,Sr,_),M(VR,Sr,null),e(Sr,g2t),e(Sr,hf),e(hf,h2t),e(hf,Nse),e(Nse,u2t),e(hf,p2t),e(hf,qse),e(qse,_2t),e(hf,b2t),e(Sr,v2t),e(Sr,XR),e(XR,F2t),e(XR,h$e),e(h$e,T2t),e(XR,M2t),e(Sr,E2t),e(Sr,pa),M(zR,pa,null),e(pa,C2t),e(pa,u$e),e(u$e,w2t),e(pa,A2t),e(pa,uf),e(uf,L2t),e(uf,p$e),e(p$e,y2t),e(uf,x2t),e(uf,jse),e(jse,$2t),e(uf,k2t),e(pa,S2t),M(IL,pa,null),e(Sr,R2t),e(Sr,it),M(QR,it,null),e(it,P2t),e(it,_$e),e(_$e,B2t),e(it,I2t),e(it,Jn),e(Jn,N2t),e(Jn,b$e),e(b$e,q2t),e(Jn,j2t),e(Jn,v$e),e(v$e,D2t),e(Jn,G2t),e(Jn,F$e),e(F$e,O2t),e(Jn,V2t),e(it,X2t),e(it,WR),e(WR,NL),e(NL,T$e),e(T$e,z2t),e(NL,Q2t),e(NL,Dse),e(Dse,W2t),e(NL,U2t),e(WR,H2t),e(WR,qL),e(qL,M$e),e(M$e,J2t),e(qL,Y2t),e(qL,Gse),e(Gse,K2t),e(qL,Z2t),e(it,ebt),M(jL,it,null),b(m,OZe,_),b(m,pf,_),e(pf,DL),e(DL,E$e),M(UR,E$e,null),e(pf,obt),e(pf,C$e),e(C$e,rbt),b(m,VZe,_),b(m,Rr,_),M(HR,Rr,null),e(Rr,tbt),e(Rr,_f),e(_f,abt),e(_f,Ose),e(Ose,nbt),e(_f,sbt),e(_f,Vse),e(Vse,lbt),e(_f,ibt),e(Rr,dbt),e(Rr,JR),e(JR,cbt),e(JR,w$e),e(w$e,mbt),e(JR,fbt),e(Rr,gbt),e(Rr,_a),M(YR,_a,null),e(_a,hbt),e(_a,A$e),e(A$e,ubt),e(_a,pbt),e(_a,bf),e(bf,_bt),e(bf,L$e),e(L$e,bbt),e(bf,vbt),e(bf,Xse),e(Xse,Fbt),e(bf,Tbt),e(_a,Mbt),M(GL,_a,null),e(Rr,Ebt),e(Rr,dt),M(KR,dt,null),e(dt,Cbt),e(dt,y$e),e(y$e,wbt),e(dt,Abt),e(dt,Yn),e(Yn,Lbt),e(Yn,x$e),e(x$e,ybt),e(Yn,xbt),e(Yn,$$e),e($$e,$bt),e(Yn,kbt),e(Yn,k$e),e(k$e,Sbt),e(Yn,Rbt),e(dt,Pbt),e(dt,S$e),e(S$e,OL),e(OL,R$e),e(R$e,Bbt),e(OL,Ibt),e(OL,zse),e(zse,Nbt),e(OL,qbt),e(dt,jbt),M(VL,dt,null),XZe=!0},p(m,[_]){const ZR={};_&2&&(ZR.$$scope={dirty:_,ctx:m}),Lf.$set(ZR);const P$e={};_&2&&(P$e.$$scope={dirty:_,ctx:m}),Qh.$set(P$e);const B$e={};_&2&&(B$e.$$scope={dirty:_,ctx:m}),yu.$set(B$e);const I$e={};_&2&&(I$e.$$scope={dirty:_,ctx:m}),pp.$set(I$e);const eP={};_&2&&(eP.$$scope={dirty:_,ctx:m}),_p.$set(eP);const N$e={};_&2&&(N$e.$$scope={dirty:_,ctx:m}),Gp.$set(N$e);const Kn={};_&2&&(Kn.$$scope={dirty:_,ctx:m}),Op.$set(Kn);const q$e={};_&2&&(q$e.$$scope={dirty:_,ctx:m}),zp.$set(q$e);const j$e={};_&2&&(j$e.$$scope={dirty:_,ctx:m}),tb.$set(j$e);const D$e={};_&2&&(D$e.$$scope={dirty:_,ctx:m}),nb.$set(D$e);const oP={};_&2&&(oP.$$scope={dirty:_,ctx:m}),o1.$set(oP);const G$e={};_&2&&(G$e.$$scope={dirty:_,ctx:m}),t1.$set(G$e);const rP={};_&2&&(rP.$$scope={dirty:_,ctx:m}),Q1.$set(rP);const O$e={};_&2&&(O$e.$$scope={dirty:_,ctx:m}),U1.$set(O$e);const tP={};_&2&&(tP.$$scope={dirty:_,ctx:m}),Bv.$set(tP);const V$e={};_&2&&(V$e.$$scope={dirty:_,ctx:m}),Nv.$set(V$e);const X$e={};_&2&&(X$e.$$scope={dirty:_,ctx:m}),nF.$set(X$e);const z$e={};_&2&&(z$e.$$scope={dirty:_,ctx:m}),lF.$set(z$e);const vf={};_&2&&(vf.$$scope={dirty:_,ctx:m}),iT.$set(vf);const Q$e={};_&2&&(Q$e.$$scope={dirty:_,ctx:m}),cT.$set(Q$e);const W$e={};_&2&&(W$e.$$scope={dirty:_,ctx:m}),XT.$set(W$e);const U$e={};_&2&&(U$e.$$scope={dirty:_,ctx:m}),QT.$set(U$e);const aP={};_&2&&(aP.$$scope={dirty:_,ctx:m}),oM.$set(aP);const H$e={};_&2&&(H$e.$$scope={dirty:_,ctx:m}),tM.$set(H$e);const J$e={};_&2&&(J$e.$$scope={dirty:_,ctx:m}),VM.$set(J$e);const Y$e={};_&2&&(Y$e.$$scope={dirty:_,ctx:m}),zM.$set(Y$e);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:m}),NE.$set(ht);const nP={};_&2&&(nP.$$scope={dirty:_,ctx:m}),jE.$set(nP);const K$e={};_&2&&(K$e.$$scope={dirty:_,ctx:m}),OE.$set(K$e);const sP={};_&2&&(sP.$$scope={dirty:_,ctx:m}),XE.$set(sP);const Z$e={};_&2&&(Z$e.$$scope={dirty:_,ctx:m}),HE.$set(Z$e);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:m}),YE.$set(ut);const eke={};_&2&&(eke.$$scope={dirty:_,ctx:m}),g4.$set(eke);const Ff={};_&2&&(Ff.$$scope={dirty:_,ctx:m}),u4.$set(Ff);const oke={};_&2&&(oke.$$scope={dirty:_,ctx:m}),b4.$set(oke);const rke={};_&2&&(rke.$$scope={dirty:_,ctx:m}),F4.$set(rke);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),E4.$set(L);const XL={};_&2&&(XL.$$scope={dirty:_,ctx:m}),w4.$set(XL);const tke={};_&2&&(tke.$$scope={dirty:_,ctx:m}),y4.$set(tke);const ake={};_&2&&(ake.$$scope={dirty:_,ctx:m}),$4.$set(ake);const zL={};_&2&&(zL.$$scope={dirty:_,ctx:m}),G4.$set(zL);const nke={};_&2&&(nke.$$scope={dirty:_,ctx:m}),V4.$set(nke);const ske={};_&2&&(ske.$$scope={dirty:_,ctx:m}),J4.$set(ske);const QL={};_&2&&(QL.$$scope={dirty:_,ctx:m}),K4.$set(QL);const lke={};_&2&&(lke.$$scope={dirty:_,ctx:m}),cC.$set(lke);const ike={};_&2&&(ike.$$scope={dirty:_,ctx:m}),fC.$set(ike);const WL={};_&2&&(WL.$$scope={dirty:_,ctx:m}),pC.$set(WL);const dke={};_&2&&(dke.$$scope={dirty:_,ctx:m}),bC.$set(dke);const cke={};_&2&&(cke.$$scope={dirty:_,ctx:m}),wC.$set(cke);const UL={};_&2&&(UL.$$scope={dirty:_,ctx:m}),LC.$set(UL);const mke={};_&2&&(mke.$$scope={dirty:_,ctx:m}),RC.$set(mke);const fke={};_&2&&(fke.$$scope={dirty:_,ctx:m}),BC.$set(fke);const HL={};_&2&&(HL.$$scope={dirty:_,ctx:m}),jC.$set(HL);const gke={};_&2&&(gke.$$scope={dirty:_,ctx:m}),GC.$set(gke);const hke={};_&2&&(hke.$$scope={dirty:_,ctx:m}),XC.$set(hke);const JL={};_&2&&(JL.$$scope={dirty:_,ctx:m}),QC.$set(JL);const uke={};_&2&&(uke.$$scope={dirty:_,ctx:m}),ZC.$set(uke);const pke={};_&2&&(pke.$$scope={dirty:_,ctx:m}),o3.$set(pke);const YL={};_&2&&(YL.$$scope={dirty:_,ctx:m}),a3.$set(YL);const _ke={};_&2&&(_ke.$$scope={dirty:_,ctx:m}),s3.$set(_ke);const bke={};_&2&&(bke.$$scope={dirty:_,ctx:m}),s5.$set(bke);const KL={};_&2&&(KL.$$scope={dirty:_,ctx:m}),i5.$set(KL);const vke={};_&2&&(vke.$$scope={dirty:_,ctx:m}),S5.$set(vke);const Fke={};_&2&&(Fke.$$scope={dirty:_,ctx:m}),P5.$set(Fke);const ZL={};_&2&&(ZL.$$scope={dirty:_,ctx:m}),H5.$set(ZL);const Tke={};_&2&&(Tke.$$scope={dirty:_,ctx:m}),Y5.$set(Tke);const Mke={};_&2&&(Mke.$$scope={dirty:_,ctx:m}),s0.$set(Mke);const ey={};_&2&&(ey.$$scope={dirty:_,ctx:m}),i0.$set(ey);const Eke={};_&2&&(Eke.$$scope={dirty:_,ctx:m}),f0.$set(Eke);const Cke={};_&2&&(Cke.$$scope={dirty:_,ctx:m}),h0.$set(Cke);const oy={};_&2&&(oy.$$scope={dirty:_,ctx:m}),B0.$set(oy);const wke={};_&2&&(wke.$$scope={dirty:_,ctx:m}),N0.$set(wke);const Ake={};_&2&&(Ake.$$scope={dirty:_,ctx:m}),U0.$set(Ake);const ry={};_&2&&(ry.$$scope={dirty:_,ctx:m}),J0.$set(ry);const Lke={};_&2&&(Lke.$$scope={dirty:_,ctx:m}),Cw.$set(Lke);const yke={};_&2&&(yke.$$scope={dirty:_,ctx:m}),Aw.$set(yke);const ty={};_&2&&(ty.$$scope={dirty:_,ctx:m}),Xw.$set(ty);const xke={};_&2&&(xke.$$scope={dirty:_,ctx:m}),Qw.$set(xke);const $ke={};_&2&&($ke.$$scope={dirty:_,ctx:m}),Hw.$set($ke);const ay={};_&2&&(ay.$$scope={dirty:_,ctx:m}),Yw.$set(ay);const kke={};_&2&&(kke.$$scope={dirty:_,ctx:m}),Zw.$set(kke);const Ske={};_&2&&(Ske.$$scope={dirty:_,ctx:m}),oA.$set(Ske);const ny={};_&2&&(ny.$$scope={dirty:_,ctx:m}),tA.$set(ny);const Rke={};_&2&&(Rke.$$scope={dirty:_,ctx:m}),nA.$set(Rke);const Pke={};_&2&&(Pke.$$scope={dirty:_,ctx:m}),LA.$set(Pke);const sy={};_&2&&(sy.$$scope={dirty:_,ctx:m}),xA.$set(sy);const Bke={};_&2&&(Bke.$$scope={dirty:_,ctx:m}),YA.$set(Bke);const Ike={};_&2&&(Ike.$$scope={dirty:_,ctx:m}),ZA.$set(Ike);const ly={};_&2&&(ly.$$scope={dirty:_,ctx:m}),o6.$set(ly);const Nke={};_&2&&(Nke.$$scope={dirty:_,ctx:m}),t6.$set(Nke);const qke={};_&2&&(qke.$$scope={dirty:_,ctx:m}),n6.$set(qke);const iy={};_&2&&(iy.$$scope={dirty:_,ctx:m}),l6.$set(iy);const jke={};_&2&&(jke.$$scope={dirty:_,ctx:m}),B6.$set(jke);const Dke={};_&2&&(Dke.$$scope={dirty:_,ctx:m}),N6.$set(Dke);const dy={};_&2&&(dy.$$scope={dirty:_,ctx:m}),U6.$set(dy);const Gke={};_&2&&(Gke.$$scope={dirty:_,ctx:m}),J6.$set(Gke);const Oke={};_&2&&(Oke.$$scope={dirty:_,ctx:m}),c7.$set(Oke);const cy={};_&2&&(cy.$$scope={dirty:_,ctx:m}),f7.$set(cy);const Vke={};_&2&&(Vke.$$scope={dirty:_,ctx:m}),E7.$set(Vke);const Xke={};_&2&&(Xke.$$scope={dirty:_,ctx:m}),w7.$set(Xke);const my={};_&2&&(my.$$scope={dirty:_,ctx:m}),I7.$set(my);const zke={};_&2&&(zke.$$scope={dirty:_,ctx:m}),q7.$set(zke);const Qke={};_&2&&(Qke.$$scope={dirty:_,ctx:m}),H7.$set(Qke);const fy={};_&2&&(fy.$$scope={dirty:_,ctx:m}),Y7.$set(fy);const Wke={};_&2&&(Wke.$$scope={dirty:_,ctx:m}),iL.$set(Wke);const Uke={};_&2&&(Uke.$$scope={dirty:_,ctx:m}),cL.$set(Uke);const gy={};_&2&&(gy.$$scope={dirty:_,ctx:m}),vL.$set(gy);const Hke={};_&2&&(Hke.$$scope={dirty:_,ctx:m}),TL.$set(Hke);const Jke={};_&2&&(Jke.$$scope={dirty:_,ctx:m}),$L.$set(Jke);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:m}),SL.$set(hy);const Yke={};_&2&&(Yke.$$scope={dirty:_,ctx:m}),PL.$set(Yke);const Kke={};_&2&&(Kke.$$scope={dirty:_,ctx:m}),IL.$set(Kke);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:m}),jL.$set(uy);const Zke={};_&2&&(Zke.$$scope={dirty:_,ctx:m}),GL.$set(Zke);const eSe={};_&2&&(eSe.$$scope={dirty:_,ctx:m}),VL.$set(eSe)},i(m){XZe||(E(d.$$.fragment,m),E(Qa.$$.fragment,m),E(E9.$$.fragment,m),E(C9.$$.fragment,m),E(Lf.$$.fragment,m),E(w9.$$.fragment,m),E(A9.$$.fragment,m),E(x9.$$.fragment,m),E(Qh.$$.fragment,m),E($9.$$.fragment,m),E(k9.$$.fragment,m),E(S9.$$.fragment,m),E(B9.$$.fragment,m),E(yu.$$.fragment,m),E(I9.$$.fragment,m),E(N9.$$.fragment,m),E(q9.$$.fragment,m),E(G9.$$.fragment,m),E(pp.$$.fragment,m),E(_p.$$.fragment,m),E(O9.$$.fragment,m),E(V9.$$.fragment,m),E(X9.$$.fragment,m),E(W9.$$.fragment,m),E(Gp.$$.fragment,m),E(Op.$$.fragment,m),E(U9.$$.fragment,m),E(H9.$$.fragment,m),E(J9.$$.fragment,m),E(K9.$$.fragment,m),E(zp.$$.fragment,m),E(Z9.$$.fragment,m),E(tb.$$.fragment,m),E(ex.$$.fragment,m),E(ox.$$.fragment,m),E(tx.$$.fragment,m),E(nb.$$.fragment,m),E(ax.$$.fragment,m),E(o1.$$.fragment,m),E(nx.$$.fragment,m),E(sx.$$.fragment,m),E(ix.$$.fragment,m),E(t1.$$.fragment,m),E(dx.$$.fragment,m),E(Q1.$$.fragment,m),E(cx.$$.fragment,m),E(mx.$$.fragment,m),E(gx.$$.fragment,m),E(U1.$$.fragment,m),E(hx.$$.fragment,m),E(Bv.$$.fragment,m),E(ux.$$.fragment,m),E(px.$$.fragment,m),E(bx.$$.fragment,m),E(Nv.$$.fragment,m),E(vx.$$.fragment,m),E(nF.$$.fragment,m),E(Fx.$$.fragment,m),E(Tx.$$.fragment,m),E(Ex.$$.fragment,m),E(lF.$$.fragment,m),E(Cx.$$.fragment,m),E(iT.$$.fragment,m),E(wx.$$.fragment,m),E(Ax.$$.fragment,m),E(yx.$$.fragment,m),E(cT.$$.fragment,m),E(xx.$$.fragment,m),E(XT.$$.fragment,m),E($x.$$.fragment,m),E(kx.$$.fragment,m),E(Rx.$$.fragment,m),E(QT.$$.fragment,m),E(Px.$$.fragment,m),E(oM.$$.fragment,m),E(Bx.$$.fragment,m),E(Ix.$$.fragment,m),E(qx.$$.fragment,m),E(tM.$$.fragment,m),E(jx.$$.fragment,m),E(VM.$$.fragment,m),E(Dx.$$.fragment,m),E(Gx.$$.fragment,m),E(Vx.$$.fragment,m),E(zM.$$.fragment,m),E(Xx.$$.fragment,m),E(NE.$$.fragment,m),E(zx.$$.fragment,m),E(Qx.$$.fragment,m),E(Ux.$$.fragment,m),E(jE.$$.fragment,m),E(Hx.$$.fragment,m),E(OE.$$.fragment,m),E(Jx.$$.fragment,m),E(Yx.$$.fragment,m),E(Zx.$$.fragment,m),E(XE.$$.fragment,m),E(e$.$$.fragment,m),E(HE.$$.fragment,m),E(o$.$$.fragment,m),E(r$.$$.fragment,m),E(a$.$$.fragment,m),E(YE.$$.fragment,m),E(n$.$$.fragment,m),E(g4.$$.fragment,m),E(s$.$$.fragment,m),E(l$.$$.fragment,m),E(d$.$$.fragment,m),E(u4.$$.fragment,m),E(c$.$$.fragment,m),E(b4.$$.fragment,m),E(m$.$$.fragment,m),E(f$.$$.fragment,m),E(h$.$$.fragment,m),E(F4.$$.fragment,m),E(u$.$$.fragment,m),E(E4.$$.fragment,m),E(p$.$$.fragment,m),E(_$.$$.fragment,m),E(v$.$$.fragment,m),E(w4.$$.fragment,m),E(F$.$$.fragment,m),E(y4.$$.fragment,m),E(T$.$$.fragment,m),E(M$.$$.fragment,m),E(C$.$$.fragment,m),E($4.$$.fragment,m),E(w$.$$.fragment,m),E(G4.$$.fragment,m),E(A$.$$.fragment,m),E(L$.$$.fragment,m),E(x$.$$.fragment,m),E(V4.$$.fragment,m),E($$.$$.fragment,m),E(J4.$$.fragment,m),E(k$.$$.fragment,m),E(S$.$$.fragment,m),E(P$.$$.fragment,m),E(K4.$$.fragment,m),E(B$.$$.fragment,m),E(cC.$$.fragment,m),E(I$.$$.fragment,m),E(N$.$$.fragment,m),E(j$.$$.fragment,m),E(fC.$$.fragment,m),E(D$.$$.fragment,m),E(pC.$$.fragment,m),E(O$.$$.fragment,m),E(V$.$$.fragment,m),E(z$.$$.fragment,m),E(bC.$$.fragment,m),E(Q$.$$.fragment,m),E(wC.$$.fragment,m),E(W$.$$.fragment,m),E(U$.$$.fragment,m),E(J$.$$.fragment,m),E(LC.$$.fragment,m),E(Y$.$$.fragment,m),E(RC.$$.fragment,m),E(K$.$$.fragment,m),E(Z$.$$.fragment,m),E(ok.$$.fragment,m),E(BC.$$.fragment,m),E(rk.$$.fragment,m),E(jC.$$.fragment,m),E(ak.$$.fragment,m),E(nk.$$.fragment,m),E(lk.$$.fragment,m),E(GC.$$.fragment,m),E(ik.$$.fragment,m),E(XC.$$.fragment,m),E(dk.$$.fragment,m),E(ck.$$.fragment,m),E(fk.$$.fragment,m),E(QC.$$.fragment,m),E(gk.$$.fragment,m),E(ZC.$$.fragment,m),E(hk.$$.fragment,m),E(uk.$$.fragment,m),E(_k.$$.fragment,m),E(o3.$$.fragment,m),E(bk.$$.fragment,m),E(a3.$$.fragment,m),E(vk.$$.fragment,m),E(Fk.$$.fragment,m),E(Mk.$$.fragment,m),E(s3.$$.fragment,m),E(Ek.$$.fragment,m),E(s5.$$.fragment,m),E(Ck.$$.fragment,m),E(wk.$$.fragment,m),E(Lk.$$.fragment,m),E(i5.$$.fragment,m),E(yk.$$.fragment,m),E(S5.$$.fragment,m),E(xk.$$.fragment,m),E($k.$$.fragment,m),E(Sk.$$.fragment,m),E(P5.$$.fragment,m),E(Rk.$$.fragment,m),E(H5.$$.fragment,m),E(Pk.$$.fragment,m),E(Bk.$$.fragment,m),E(Nk.$$.fragment,m),E(Y5.$$.fragment,m),E(qk.$$.fragment,m),E(s0.$$.fragment,m),E(jk.$$.fragment,m),E(Dk.$$.fragment,m),E(Ok.$$.fragment,m),E(i0.$$.fragment,m),E(Vk.$$.fragment,m),E(f0.$$.fragment,m),E(Xk.$$.fragment,m),E(zk.$$.fragment,m),E(Wk.$$.fragment,m),E(h0.$$.fragment,m),E(Uk.$$.fragment,m),E(B0.$$.fragment,m),E(Hk.$$.fragment,m),E(Jk.$$.fragment,m),E(Kk.$$.fragment,m),E(N0.$$.fragment,m),E(Zk.$$.fragment,m),E(U0.$$.fragment,m),E(eS.$$.fragment,m),E(oS.$$.fragment,m),E(tS.$$.fragment,m),E(J0.$$.fragment,m),E(aS.$$.fragment,m),E(Cw.$$.fragment,m),E(nS.$$.fragment,m),E(sS.$$.fragment,m),E(iS.$$.fragment,m),E(Aw.$$.fragment,m),E(dS.$$.fragment,m),E(Xw.$$.fragment,m),E(cS.$$.fragment,m),E(mS.$$.fragment,m),E(gS.$$.fragment,m),E(Qw.$$.fragment,m),E(hS.$$.fragment,m),E(Hw.$$.fragment,m),E(pS.$$.fragment,m),E(_S.$$.fragment,m),E(vS.$$.fragment,m),E(Yw.$$.fragment,m),E(FS.$$.fragment,m),E(Zw.$$.fragment,m),E(TS.$$.fragment,m),E(MS.$$.fragment,m),E(CS.$$.fragment,m),E(oA.$$.fragment,m),E(wS.$$.fragment,m),E(tA.$$.fragment,m),E(AS.$$.fragment,m),E(LS.$$.fragment,m),E(xS.$$.fragment,m),E(nA.$$.fragment,m),E($S.$$.fragment,m),E(LA.$$.fragment,m),E(kS.$$.fragment,m),E(SS.$$.fragment,m),E(PS.$$.fragment,m),E(xA.$$.fragment,m),E(BS.$$.fragment,m),E(YA.$$.fragment,m),E(IS.$$.fragment,m),E(NS.$$.fragment,m),E(jS.$$.fragment,m),E(ZA.$$.fragment,m),E(DS.$$.fragment,m),E(o6.$$.fragment,m),E(GS.$$.fragment,m),E(OS.$$.fragment,m),E(XS.$$.fragment,m),E(t6.$$.fragment,m),E(zS.$$.fragment,m),E(n6.$$.fragment,m),E(QS.$$.fragment,m),E(WS.$$.fragment,m),E(HS.$$.fragment,m),E(l6.$$.fragment,m),E(JS.$$.fragment,m),E(B6.$$.fragment,m),E(YS.$$.fragment,m),E(KS.$$.fragment,m),E(eR.$$.fragment,m),E(N6.$$.fragment,m),E(oR.$$.fragment,m),E(U6.$$.fragment,m),E(rR.$$.fragment,m),E(tR.$$.fragment,m),E(nR.$$.fragment,m),E(J6.$$.fragment,m),E(sR.$$.fragment,m),E(c7.$$.fragment,m),E(lR.$$.fragment,m),E(iR.$$.fragment,m),E(cR.$$.fragment,m),E(f7.$$.fragment,m),E(mR.$$.fragment,m),E(E7.$$.fragment,m),E(fR.$$.fragment,m),E(gR.$$.fragment,m),E(uR.$$.fragment,m),E(w7.$$.fragment,m),E(pR.$$.fragment,m),E(I7.$$.fragment,m),E(_R.$$.fragment,m),E(bR.$$.fragment,m),E(FR.$$.fragment,m),E(q7.$$.fragment,m),E(TR.$$.fragment,m),E(H7.$$.fragment,m),E(MR.$$.fragment,m),E(ER.$$.fragment,m),E(wR.$$.fragment,m),E(Y7.$$.fragment,m),E(AR.$$.fragment,m),E(iL.$$.fragment,m),E(LR.$$.fragment,m),E(yR.$$.fragment,m),E($R.$$.fragment,m),E(cL.$$.fragment,m),E(kR.$$.fragment,m),E(vL.$$.fragment,m),E(SR.$$.fragment,m),E(RR.$$.fragment,m),E(BR.$$.fragment,m),E(TL.$$.fragment,m),E(IR.$$.fragment,m),E($L.$$.fragment,m),E(NR.$$.fragment,m),E(qR.$$.fragment,m),E(DR.$$.fragment,m),E(SL.$$.fragment,m),E(GR.$$.fragment,m),E(PL.$$.fragment,m),E(OR.$$.fragment,m),E(VR.$$.fragment,m),E(zR.$$.fragment,m),E(IL.$$.fragment,m),E(QR.$$.fragment,m),E(jL.$$.fragment,m),E(UR.$$.fragment,m),E(HR.$$.fragment,m),E(YR.$$.fragment,m),E(GL.$$.fragment,m),E(KR.$$.fragment,m),E(VL.$$.fragment,m),XZe=!0)},o(m){C(d.$$.fragment,m),C(Qa.$$.fragment,m),C(E9.$$.fragment,m),C(C9.$$.fragment,m),C(Lf.$$.fragment,m),C(w9.$$.fragment,m),C(A9.$$.fragment,m),C(x9.$$.fragment,m),C(Qh.$$.fragment,m),C($9.$$.fragment,m),C(k9.$$.fragment,m),C(S9.$$.fragment,m),C(B9.$$.fragment,m),C(yu.$$.fragment,m),C(I9.$$.fragment,m),C(N9.$$.fragment,m),C(q9.$$.fragment,m),C(G9.$$.fragment,m),C(pp.$$.fragment,m),C(_p.$$.fragment,m),C(O9.$$.fragment,m),C(V9.$$.fragment,m),C(X9.$$.fragment,m),C(W9.$$.fragment,m),C(Gp.$$.fragment,m),C(Op.$$.fragment,m),C(U9.$$.fragment,m),C(H9.$$.fragment,m),C(J9.$$.fragment,m),C(K9.$$.fragment,m),C(zp.$$.fragment,m),C(Z9.$$.fragment,m),C(tb.$$.fragment,m),C(ex.$$.fragment,m),C(ox.$$.fragment,m),C(tx.$$.fragment,m),C(nb.$$.fragment,m),C(ax.$$.fragment,m),C(o1.$$.fragment,m),C(nx.$$.fragment,m),C(sx.$$.fragment,m),C(ix.$$.fragment,m),C(t1.$$.fragment,m),C(dx.$$.fragment,m),C(Q1.$$.fragment,m),C(cx.$$.fragment,m),C(mx.$$.fragment,m),C(gx.$$.fragment,m),C(U1.$$.fragment,m),C(hx.$$.fragment,m),C(Bv.$$.fragment,m),C(ux.$$.fragment,m),C(px.$$.fragment,m),C(bx.$$.fragment,m),C(Nv.$$.fragment,m),C(vx.$$.fragment,m),C(nF.$$.fragment,m),C(Fx.$$.fragment,m),C(Tx.$$.fragment,m),C(Ex.$$.fragment,m),C(lF.$$.fragment,m),C(Cx.$$.fragment,m),C(iT.$$.fragment,m),C(wx.$$.fragment,m),C(Ax.$$.fragment,m),C(yx.$$.fragment,m),C(cT.$$.fragment,m),C(xx.$$.fragment,m),C(XT.$$.fragment,m),C($x.$$.fragment,m),C(kx.$$.fragment,m),C(Rx.$$.fragment,m),C(QT.$$.fragment,m),C(Px.$$.fragment,m),C(oM.$$.fragment,m),C(Bx.$$.fragment,m),C(Ix.$$.fragment,m),C(qx.$$.fragment,m),C(tM.$$.fragment,m),C(jx.$$.fragment,m),C(VM.$$.fragment,m),C(Dx.$$.fragment,m),C(Gx.$$.fragment,m),C(Vx.$$.fragment,m),C(zM.$$.fragment,m),C(Xx.$$.fragment,m),C(NE.$$.fragment,m),C(zx.$$.fragment,m),C(Qx.$$.fragment,m),C(Ux.$$.fragment,m),C(jE.$$.fragment,m),C(Hx.$$.fragment,m),C(OE.$$.fragment,m),C(Jx.$$.fragment,m),C(Yx.$$.fragment,m),C(Zx.$$.fragment,m),C(XE.$$.fragment,m),C(e$.$$.fragment,m),C(HE.$$.fragment,m),C(o$.$$.fragment,m),C(r$.$$.fragment,m),C(a$.$$.fragment,m),C(YE.$$.fragment,m),C(n$.$$.fragment,m),C(g4.$$.fragment,m),C(s$.$$.fragment,m),C(l$.$$.fragment,m),C(d$.$$.fragment,m),C(u4.$$.fragment,m),C(c$.$$.fragment,m),C(b4.$$.fragment,m),C(m$.$$.fragment,m),C(f$.$$.fragment,m),C(h$.$$.fragment,m),C(F4.$$.fragment,m),C(u$.$$.fragment,m),C(E4.$$.fragment,m),C(p$.$$.fragment,m),C(_$.$$.fragment,m),C(v$.$$.fragment,m),C(w4.$$.fragment,m),C(F$.$$.fragment,m),C(y4.$$.fragment,m),C(T$.$$.fragment,m),C(M$.$$.fragment,m),C(C$.$$.fragment,m),C($4.$$.fragment,m),C(w$.$$.fragment,m),C(G4.$$.fragment,m),C(A$.$$.fragment,m),C(L$.$$.fragment,m),C(x$.$$.fragment,m),C(V4.$$.fragment,m),C($$.$$.fragment,m),C(J4.$$.fragment,m),C(k$.$$.fragment,m),C(S$.$$.fragment,m),C(P$.$$.fragment,m),C(K4.$$.fragment,m),C(B$.$$.fragment,m),C(cC.$$.fragment,m),C(I$.$$.fragment,m),C(N$.$$.fragment,m),C(j$.$$.fragment,m),C(fC.$$.fragment,m),C(D$.$$.fragment,m),C(pC.$$.fragment,m),C(O$.$$.fragment,m),C(V$.$$.fragment,m),C(z$.$$.fragment,m),C(bC.$$.fragment,m),C(Q$.$$.fragment,m),C(wC.$$.fragment,m),C(W$.$$.fragment,m),C(U$.$$.fragment,m),C(J$.$$.fragment,m),C(LC.$$.fragment,m),C(Y$.$$.fragment,m),C(RC.$$.fragment,m),C(K$.$$.fragment,m),C(Z$.$$.fragment,m),C(ok.$$.fragment,m),C(BC.$$.fragment,m),C(rk.$$.fragment,m),C(jC.$$.fragment,m),C(ak.$$.fragment,m),C(nk.$$.fragment,m),C(lk.$$.fragment,m),C(GC.$$.fragment,m),C(ik.$$.fragment,m),C(XC.$$.fragment,m),C(dk.$$.fragment,m),C(ck.$$.fragment,m),C(fk.$$.fragment,m),C(QC.$$.fragment,m),C(gk.$$.fragment,m),C(ZC.$$.fragment,m),C(hk.$$.fragment,m),C(uk.$$.fragment,m),C(_k.$$.fragment,m),C(o3.$$.fragment,m),C(bk.$$.fragment,m),C(a3.$$.fragment,m),C(vk.$$.fragment,m),C(Fk.$$.fragment,m),C(Mk.$$.fragment,m),C(s3.$$.fragment,m),C(Ek.$$.fragment,m),C(s5.$$.fragment,m),C(Ck.$$.fragment,m),C(wk.$$.fragment,m),C(Lk.$$.fragment,m),C(i5.$$.fragment,m),C(yk.$$.fragment,m),C(S5.$$.fragment,m),C(xk.$$.fragment,m),C($k.$$.fragment,m),C(Sk.$$.fragment,m),C(P5.$$.fragment,m),C(Rk.$$.fragment,m),C(H5.$$.fragment,m),C(Pk.$$.fragment,m),C(Bk.$$.fragment,m),C(Nk.$$.fragment,m),C(Y5.$$.fragment,m),C(qk.$$.fragment,m),C(s0.$$.fragment,m),C(jk.$$.fragment,m),C(Dk.$$.fragment,m),C(Ok.$$.fragment,m),C(i0.$$.fragment,m),C(Vk.$$.fragment,m),C(f0.$$.fragment,m),C(Xk.$$.fragment,m),C(zk.$$.fragment,m),C(Wk.$$.fragment,m),C(h0.$$.fragment,m),C(Uk.$$.fragment,m),C(B0.$$.fragment,m),C(Hk.$$.fragment,m),C(Jk.$$.fragment,m),C(Kk.$$.fragment,m),C(N0.$$.fragment,m),C(Zk.$$.fragment,m),C(U0.$$.fragment,m),C(eS.$$.fragment,m),C(oS.$$.fragment,m),C(tS.$$.fragment,m),C(J0.$$.fragment,m),C(aS.$$.fragment,m),C(Cw.$$.fragment,m),C(nS.$$.fragment,m),C(sS.$$.fragment,m),C(iS.$$.fragment,m),C(Aw.$$.fragment,m),C(dS.$$.fragment,m),C(Xw.$$.fragment,m),C(cS.$$.fragment,m),C(mS.$$.fragment,m),C(gS.$$.fragment,m),C(Qw.$$.fragment,m),C(hS.$$.fragment,m),C(Hw.$$.fragment,m),C(pS.$$.fragment,m),C(_S.$$.fragment,m),C(vS.$$.fragment,m),C(Yw.$$.fragment,m),C(FS.$$.fragment,m),C(Zw.$$.fragment,m),C(TS.$$.fragment,m),C(MS.$$.fragment,m),C(CS.$$.fragment,m),C(oA.$$.fragment,m),C(wS.$$.fragment,m),C(tA.$$.fragment,m),C(AS.$$.fragment,m),C(LS.$$.fragment,m),C(xS.$$.fragment,m),C(nA.$$.fragment,m),C($S.$$.fragment,m),C(LA.$$.fragment,m),C(kS.$$.fragment,m),C(SS.$$.fragment,m),C(PS.$$.fragment,m),C(xA.$$.fragment,m),C(BS.$$.fragment,m),C(YA.$$.fragment,m),C(IS.$$.fragment,m),C(NS.$$.fragment,m),C(jS.$$.fragment,m),C(ZA.$$.fragment,m),C(DS.$$.fragment,m),C(o6.$$.fragment,m),C(GS.$$.fragment,m),C(OS.$$.fragment,m),C(XS.$$.fragment,m),C(t6.$$.fragment,m),C(zS.$$.fragment,m),C(n6.$$.fragment,m),C(QS.$$.fragment,m),C(WS.$$.fragment,m),C(HS.$$.fragment,m),C(l6.$$.fragment,m),C(JS.$$.fragment,m),C(B6.$$.fragment,m),C(YS.$$.fragment,m),C(KS.$$.fragment,m),C(eR.$$.fragment,m),C(N6.$$.fragment,m),C(oR.$$.fragment,m),C(U6.$$.fragment,m),C(rR.$$.fragment,m),C(tR.$$.fragment,m),C(nR.$$.fragment,m),C(J6.$$.fragment,m),C(sR.$$.fragment,m),C(c7.$$.fragment,m),C(lR.$$.fragment,m),C(iR.$$.fragment,m),C(cR.$$.fragment,m),C(f7.$$.fragment,m),C(mR.$$.fragment,m),C(E7.$$.fragment,m),C(fR.$$.fragment,m),C(gR.$$.fragment,m),C(uR.$$.fragment,m),C(w7.$$.fragment,m),C(pR.$$.fragment,m),C(I7.$$.fragment,m),C(_R.$$.fragment,m),C(bR.$$.fragment,m),C(FR.$$.fragment,m),C(q7.$$.fragment,m),C(TR.$$.fragment,m),C(H7.$$.fragment,m),C(MR.$$.fragment,m),C(ER.$$.fragment,m),C(wR.$$.fragment,m),C(Y7.$$.fragment,m),C(AR.$$.fragment,m),C(iL.$$.fragment,m),C(LR.$$.fragment,m),C(yR.$$.fragment,m),C($R.$$.fragment,m),C(cL.$$.fragment,m),C(kR.$$.fragment,m),C(vL.$$.fragment,m),C(SR.$$.fragment,m),C(RR.$$.fragment,m),C(BR.$$.fragment,m),C(TL.$$.fragment,m),C(IR.$$.fragment,m),C($L.$$.fragment,m),C(NR.$$.fragment,m),C(qR.$$.fragment,m),C(DR.$$.fragment,m),C(SL.$$.fragment,m),C(GR.$$.fragment,m),C(PL.$$.fragment,m),C(OR.$$.fragment,m),C(VR.$$.fragment,m),C(zR.$$.fragment,m),C(IL.$$.fragment,m),C(QR.$$.fragment,m),C(jL.$$.fragment,m),C(UR.$$.fragment,m),C(HR.$$.fragment,m),C(YR.$$.fragment,m),C(GL.$$.fragment,m),C(KR.$$.fragment,m),C(VL.$$.fragment,m),XZe=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Mf),m&&t(pt),m&&t(Ve),m&&t(He),m&&t(Cf),w(Qa,m),m&&t(Je),m&&t(Ae),m&&t(xo),m&&t(Wa),m&&t(kYe),m&&t(dd),w(E9),m&&t(SYe),m&&t(ts),m&&t(RYe),w(C9,m),m&&t(PYe),m&&t(xB),m&&t(BYe),w(Lf,m),m&&t(IYe),m&&t(cd),w(w9),m&&t(NYe),m&&t($o),w(A9),w(x9),w(Qh),w($9),m&&t(qYe),m&&t(fd),w(k9),m&&t(jYe),m&&t(ko),w(S9),w(B9),w(yu),w(I9),m&&t(DYe),m&&t(gd),w(N9),m&&t(GYe),m&&t(So),w(q9),w(G9),w(pp),w(_p),w(O9),m&&t(OYe),m&&t(hd),w(V9),m&&t(VYe),m&&t(Ro),w(X9),w(W9),w(Gp),w(Op),w(U9),m&&t(XYe),m&&t(pd),w(H9),m&&t(zYe),m&&t(Po),w(J9),w(K9),w(zp),w(Z9),w(tb),m&&t(QYe),m&&t(vd),w(ex),m&&t(WYe),m&&t(Bo),w(ox),w(tx),w(nb),w(ax),w(o1),m&&t(UYe),m&&t(Md),w(nx),m&&t(HYe),m&&t(Io),w(sx),w(ix),w(t1),w(dx),w(Q1),m&&t(JYe),m&&t(wd),w(cx),m&&t(YYe),m&&t(No),w(mx),w(gx),w(U1),w(hx),w(Bv),m&&t(KYe),m&&t(yd),w(ux),m&&t(ZYe),m&&t(qo),w(px),w(bx),w(Nv),w(vx),w(nF),m&&t(eKe),m&&t(kd),w(Fx),m&&t(oKe),m&&t(jo),w(Tx),w(Ex),w(lF),w(Cx),w(iT),m&&t(rKe),m&&t(Pd),w(wx),m&&t(tKe),m&&t(Do),w(Ax),w(yx),w(cT),w(xx),w(XT),m&&t(aKe),m&&t(Nd),w($x),m&&t(nKe),m&&t(Go),w(kx),w(Rx),w(QT),w(Px),w(oM),m&&t(sKe),m&&t(Dd),w(Bx),m&&t(lKe),m&&t(Oo),w(Ix),w(qx),w(tM),w(jx),w(VM),m&&t(iKe),m&&t(Vd),w(Dx),m&&t(dKe),m&&t(Vo),w(Gx),w(Vx),w(zM),w(Xx),w(NE),m&&t(cKe),m&&t(Qd),w(zx),m&&t(mKe),m&&t(Xo),w(Qx),w(Ux),w(jE),w(Hx),w(OE),m&&t(fKe),m&&t(Hd),w(Jx),m&&t(gKe),m&&t(zo),w(Yx),w(Zx),w(XE),w(e$),w(HE),m&&t(hKe),m&&t(Zd),w(o$),m&&t(uKe),m&&t(Qo),w(r$),w(a$),w(YE),w(n$),w(g4),m&&t(pKe),m&&t(rc),w(s$),m&&t(_Ke),m&&t(Wo),w(l$),w(d$),w(u4),w(c$),w(b4),m&&t(bKe),m&&t(nc),w(m$),m&&t(vKe),m&&t(Uo),w(f$),w(h$),w(F4),w(u$),w(E4),m&&t(FKe),m&&t(ic),w(p$),m&&t(TKe),m&&t(Ho),w(_$),w(v$),w(w4),w(F$),w(y4),m&&t(MKe),m&&t(mc),w(T$),m&&t(EKe),m&&t(Jo),w(M$),w(C$),w($4),w(w$),w(G4),m&&t(CKe),m&&t(hc),w(A$),m&&t(wKe),m&&t(Yo),w(L$),w(x$),w(V4),w($$),w(J4),m&&t(AKe),m&&t(_c),w(k$),m&&t(LKe),m&&t(Ko),w(S$),w(P$),w(K4),w(B$),w(cC),m&&t(yKe),m&&t(Fc),w(I$),m&&t(xKe),m&&t(Zo),w(N$),w(j$),w(fC),w(D$),w(pC),m&&t($Ke),m&&t(Ec),w(O$),m&&t(kKe),m&&t(er),w(V$),w(z$),w(bC),w(Q$),w(wC),m&&t(SKe),m&&t(Ac),w(W$),m&&t(RKe),m&&t(or),w(U$),w(J$),w(LC),w(Y$),w(RC),m&&t(PKe),m&&t(xc),w(K$),m&&t(BKe),m&&t(rr),w(Z$),w(ok),w(BC),w(rk),w(jC),m&&t(IKe),m&&t(Sc),w(ak),m&&t(NKe),m&&t(tr),w(nk),w(lk),w(GC),w(ik),w(XC),m&&t(qKe),m&&t(Bc),w(dk),m&&t(jKe),m&&t(ar),w(ck),w(fk),w(QC),w(gk),w(ZC),m&&t(DKe),m&&t(qc),w(hk),m&&t(GKe),m&&t(nr),w(uk),w(_k),w(o3),w(bk),w(a3),m&&t(OKe),m&&t(Gc),w(vk),m&&t(VKe),m&&t(sr),w(Fk),w(Mk),w(s3),w(Ek),w(s5),m&&t(XKe),m&&t(Xc),w(Ck),m&&t(zKe),m&&t(lr),w(wk),w(Lk),w(i5),w(yk),w(S5),m&&t(QKe),m&&t(Wc),w(xk),m&&t(WKe),m&&t(ir),w($k),w(Sk),w(P5),w(Rk),w(H5),m&&t(UKe),m&&t(Jc),w(Pk),m&&t(HKe),m&&t(dr),w(Bk),w(Nk),w(Y5),w(qk),w(s0),m&&t(JKe),m&&t(Zc),w(jk),m&&t(YKe),m&&t(cr),w(Dk),w(Ok),w(i0),w(Vk),w(f0),m&&t(KKe),m&&t(tm),w(Xk),m&&t(ZKe),m&&t(mr),w(zk),w(Wk),w(h0),w(Uk),w(B0),m&&t(eZe),m&&t(sm),w(Hk),m&&t(oZe),m&&t(fr),w(Jk),w(Kk),w(N0),w(Zk),w(U0),m&&t(rZe),m&&t(dm),w(eS),m&&t(tZe),m&&t(gr),w(oS),w(tS),w(J0),w(aS),w(Cw),m&&t(aZe),m&&t(fm),w(nS),m&&t(nZe),m&&t(hr),w(sS),w(iS),w(Aw),w(dS),w(Xw),m&&t(sZe),m&&t(um),w(cS),m&&t(lZe),m&&t(ur),w(mS),w(gS),w(Qw),w(hS),w(Hw),m&&t(iZe),m&&t(bm),w(pS),m&&t(dZe),m&&t(pr),w(_S),w(vS),w(Yw),w(FS),w(Zw),m&&t(cZe),m&&t(Tm),w(TS),m&&t(mZe),m&&t(_r),w(MS),w(CS),w(oA),w(wS),w(tA),m&&t(fZe),m&&t(Cm),w(AS),m&&t(gZe),m&&t(br),w(LS),w(xS),w(nA),w($S),w(LA),m&&t(hZe),m&&t(Lm),w(kS),m&&t(uZe),m&&t(vr),w(SS),w(PS),w(xA),w(BS),w(YA),m&&t(pZe),m&&t($m),w(IS),m&&t(_Ze),m&&t(Fr),w(NS),w(jS),w(ZA),w(DS),w(o6),m&&t(bZe),m&&t(Rm),w(GS),m&&t(vZe),m&&t(Tr),w(OS),w(XS),w(t6),w(zS),w(n6),m&&t(FZe),m&&t(Im),w(QS),m&&t(TZe),m&&t(Mr),w(WS),w(HS),w(l6),w(JS),w(B6),m&&t(MZe),m&&t(jm),w(YS),m&&t(EZe),m&&t(Er),w(KS),w(eR),w(N6),w(oR),w(U6),m&&t(CZe),m&&t(Om),w(rR),m&&t(wZe),m&&t(Cr),w(tR),w(nR),w(J6),w(sR),w(c7),m&&t(AZe),m&&t(zm),w(lR),m&&t(LZe),m&&t(wr),w(iR),w(cR),w(f7),w(mR),w(E7),m&&t(yZe),m&&t(Um),w(fR),m&&t(xZe),m&&t(Ar),w(gR),w(uR),w(w7),w(pR),w(I7),m&&t($Ze),m&&t(Ym),w(_R),m&&t(kZe),m&&t(Lr),w(bR),w(FR),w(q7),w(TR),w(H7),m&&t(SZe),m&&t(ef),w(MR),m&&t(RZe),m&&t(yr),w(ER),w(wR),w(Y7),w(AR),w(iL),m&&t(PZe),m&&t(tf),w(LR),m&&t(BZe),m&&t(xr),w(yR),w($R),w(cL),w(kR),w(vL),m&&t(IZe),m&&t(sf),w(SR),m&&t(NZe),m&&t($r),w(RR),w(BR),w(TL),w(IR),w($L),m&&t(qZe),m&&t(cf),w(NR),m&&t(jZe),m&&t(kr),w(qR),w(DR),w(SL),w(GR),w(PL),m&&t(DZe),m&&t(gf),w(OR),m&&t(GZe),m&&t(Sr),w(VR),w(zR),w(IL),w(QR),w(jL),m&&t(OZe),m&&t(pf),w(UR),m&&t(VZe),m&&t(Rr),w(HR),w(YR),w(GL),w(KR),w(VL)}}}const Hha={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Jha($){return Dfa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tua extends Ifa{constructor(g){super();Nfa(this,g,Jha,Uha,qfa,{})}}export{tua as default,Hha as metadata};
