import{S as xCa,i as $Ca,s as kCa,e as a,k as l,w as F,t as o,M as SCa,c as n,d as t,m as i,a as s,x as T,h as r,b as m,G as e,g as b,y as M,q as E,o as C,B as w,v as RCa,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as rAt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function PCa($){let g,v,u,f,p,d,h,$o,pd,Vf,Ft,_d,bd,o$,Xf,Xe,He,vd,ms,r$,cs,fs,t$,Fd,gs,a$,Td,zf,en;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),pd=a("code"),Vf=o("model_type"),Ft=o(" attribute is set to the same key you use when registering the config (here "),_d=a("code"),bd=o('"new-model"'),o$=o(")."),Xf=l(),Xe=a("p"),He=o("Likewise, if your "),vd=a("code"),ms=o("NewModel"),r$=o(" is a subclass of "),cs=a("a"),fs=o("PreTrainedModel"),t$=o(`, make sure its
`),Fd=a("code"),gs=o("config_class"),a$=o(` attribute is set to the same class you use when registering the model (here
`),Td=a("code"),zf=o("NewModelConfig"),en=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var _N=s(u);f=r(_N,"NewModelConfig"),_N.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Md=s(d);h=r(Md,"~transformer.PretrainedConfig"),Md.forEach(t),$o=r(Ae,`, make sure its
`),pd=n(Ae,"CODE",{});var bN=s(pd);Vf=r(bN,"model_type"),bN.forEach(t),Ft=r(Ae," attribute is set to the same key you use when registering the config (here "),_d=n(Ae,"CODE",{});var vN=s(_d);bd=r(vN,'"new-model"'),vN.forEach(t),o$=r(Ae,")."),Ae.forEach(t),Xf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),vd=n(ko,"CODE",{});var on=s(vd);ms=r(on,"NewModel"),on.forEach(t),r$=r(ko," is a subclass of "),cs=n(ko,"A",{href:!0});var FN=s(cs);fs=r(FN,"PreTrainedModel"),FN.forEach(t),t$=r(ko,`, make sure its
`),Fd=n(ko,"CODE",{});var Qf=s(Fd);gs=r(Qf,"config_class"),Qf.forEach(t),a$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Td=n(ko,"CODE",{});var TN=s(Td);zf=r(TN,"NewModelConfig"),TN.forEach(t),en=r(ko,")."),ko.forEach(t),this.h()},h(){m(cs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,pd),e(pd,Vf),e(g,Ft),e(g,_d),e(_d,bd),e(g,o$),b(Je,Xf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,vd),e(vd,ms),e(Xe,r$),e(Xe,cs),e(cs,fs),e(Xe,t$),e(Xe,Fd),e(Fd,gs),e(Xe,a$),e(Xe,Td),e(Td,zf),e(Xe,en)},d(Je){Je&&t(g),Je&&t(Xf),Je&&t(Xe)}}}function BCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ICa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NCa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function qCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jCa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function DCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KCa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z5a($){let g,v,u,f,p,d,h,$o,pd,Vf,Ft,_d,bd,o$,Xf,Xe,He,vd,ms,r$,cs,fs,t$,Fd,gs,a$,Td,zf,en,Je,Ae,_N,Md,bN,vN,ko,on,FN,Qf,TN,Wlo,ito,Ed,Wf,ofe,n$,Ulo,rfe,Hlo,dto,hs,Jlo,tfe,Ylo,Zlo,afe,Klo,eio,mto,s$,cto,MN,oio,fto,Uf,gto,Cd,Hf,nfe,l$,rio,sfe,tio,hto,So,i$,aio,d$,nio,EN,sio,lio,iio,m$,dio,lfe,mio,cio,fio,qr,c$,gio,ife,hio,uio,wd,pio,dfe,_io,bio,mfe,vio,Fio,Tio,A,Jf,cfe,Mio,Eio,CN,Cio,wio,Aio,Yf,ffe,Lio,yio,wN,xio,$io,kio,Zf,gfe,Sio,Rio,AN,Pio,Bio,Iio,Kf,hfe,Nio,qio,LN,jio,Dio,Gio,eg,ufe,Oio,Vio,yN,Xio,zio,Qio,og,pfe,Wio,Uio,xN,Hio,Jio,Yio,rg,_fe,Zio,Kio,$N,edo,odo,rdo,tg,bfe,tdo,ado,kN,ndo,sdo,ldo,ag,vfe,ido,ddo,SN,mdo,cdo,fdo,ng,Ffe,gdo,hdo,RN,udo,pdo,_do,sg,Tfe,bdo,vdo,PN,Fdo,Tdo,Mdo,lg,Mfe,Edo,Cdo,BN,wdo,Ado,Ldo,ig,Efe,ydo,xdo,IN,$do,kdo,Sdo,dg,Cfe,Rdo,Pdo,NN,Bdo,Ido,Ndo,mg,wfe,qdo,jdo,qN,Ddo,Gdo,Odo,cg,Afe,Vdo,Xdo,jN,zdo,Qdo,Wdo,fg,Lfe,Udo,Hdo,DN,Jdo,Ydo,Zdo,gg,yfe,Kdo,emo,GN,omo,rmo,tmo,hg,xfe,amo,nmo,ON,smo,lmo,imo,ug,$fe,dmo,mmo,VN,cmo,fmo,gmo,pg,kfe,hmo,umo,XN,pmo,_mo,bmo,_g,Sfe,vmo,Fmo,zN,Tmo,Mmo,Emo,bg,Rfe,Cmo,wmo,QN,Amo,Lmo,ymo,vg,Pfe,xmo,$mo,WN,kmo,Smo,Rmo,Fg,Bfe,Pmo,Bmo,UN,Imo,Nmo,qmo,Tg,Ife,jmo,Dmo,HN,Gmo,Omo,Vmo,Mg,Nfe,Xmo,zmo,JN,Qmo,Wmo,Umo,Eg,qfe,Hmo,Jmo,YN,Ymo,Zmo,Kmo,Cg,jfe,eco,oco,ZN,rco,tco,aco,wg,Dfe,nco,sco,KN,lco,ico,dco,Ag,Gfe,mco,cco,eq,fco,gco,hco,Lg,Ofe,uco,pco,oq,_co,bco,vco,yg,Vfe,Fco,Tco,rq,Mco,Eco,Cco,xg,Xfe,wco,Aco,tq,Lco,yco,xco,$g,zfe,$co,kco,aq,Sco,Rco,Pco,kg,Qfe,Bco,Ico,nq,Nco,qco,jco,Sg,Wfe,Dco,Gco,sq,Oco,Vco,Xco,Rg,Ufe,zco,Qco,lq,Wco,Uco,Hco,Pg,Hfe,Jco,Yco,iq,Zco,Kco,efo,Bg,Jfe,ofo,rfo,dq,tfo,afo,nfo,Ig,Yfe,sfo,lfo,mq,ifo,dfo,mfo,Ng,Zfe,cfo,ffo,cq,gfo,hfo,ufo,qg,Kfe,pfo,_fo,fq,bfo,vfo,Ffo,jg,ege,Tfo,Mfo,gq,Efo,Cfo,wfo,Dg,oge,Afo,Lfo,hq,yfo,xfo,$fo,Gg,rge,kfo,Sfo,uq,Rfo,Pfo,Bfo,Og,tge,Ifo,Nfo,pq,qfo,jfo,Dfo,Vg,age,Gfo,Ofo,_q,Vfo,Xfo,zfo,Xg,nge,Qfo,Wfo,bq,Ufo,Hfo,Jfo,zg,sge,Yfo,Zfo,vq,Kfo,ego,ogo,Qg,lge,rgo,tgo,Fq,ago,ngo,sgo,Wg,ige,lgo,igo,Tq,dgo,mgo,cgo,Ug,dge,fgo,ggo,Mq,hgo,ugo,pgo,Hg,mge,_go,bgo,Eq,vgo,Fgo,Tgo,Jg,cge,Mgo,Ego,Cq,Cgo,wgo,Ago,Yg,fge,Lgo,ygo,wq,xgo,$go,kgo,Zg,gge,Sgo,Rgo,Aq,Pgo,Bgo,Igo,Kg,hge,Ngo,qgo,Lq,jgo,Dgo,Ggo,eh,uge,Ogo,Vgo,yq,Xgo,zgo,Qgo,oh,pge,Wgo,Ugo,xq,Hgo,Jgo,Ygo,rh,_ge,Zgo,Kgo,$q,eho,oho,rho,th,bge,tho,aho,kq,nho,sho,lho,ah,vge,iho,dho,Sq,mho,cho,fho,nh,Fge,gho,hho,Rq,uho,pho,_ho,sh,Tge,bho,vho,Pq,Fho,Tho,Mho,lh,Mge,Eho,Cho,Bq,who,Aho,Lho,ih,Ege,yho,xho,Iq,$ho,kho,Sho,dh,Cge,Rho,Pho,Nq,Bho,Iho,Nho,mh,wge,qho,jho,qq,Dho,Gho,Oho,ch,Age,Vho,Xho,jq,zho,Qho,Who,fh,Lge,Uho,Hho,Dq,Jho,Yho,Zho,gh,yge,Kho,euo,Gq,ouo,ruo,tuo,hh,xge,auo,nuo,Oq,suo,luo,iuo,uh,$ge,duo,muo,Vq,cuo,fuo,guo,ph,kge,huo,uuo,Xq,puo,_uo,buo,_h,Sge,vuo,Fuo,zq,Tuo,Muo,Euo,bh,Rge,Cuo,wuo,Qq,Auo,Luo,yuo,vh,Pge,xuo,$uo,Wq,kuo,Suo,Ruo,Fh,Bge,Puo,Buo,Uq,Iuo,Nuo,quo,Th,Ige,juo,Duo,Hq,Guo,Ouo,Vuo,Mh,Nge,Xuo,zuo,Jq,Quo,Wuo,Uuo,Eh,qge,Huo,Juo,Yq,Yuo,Zuo,Kuo,Ch,jge,epo,opo,Zq,rpo,tpo,apo,wh,Dge,npo,spo,Kq,lpo,ipo,dpo,Ah,Gge,mpo,cpo,ej,fpo,gpo,hpo,Lh,Oge,upo,ppo,oj,_po,bpo,vpo,yh,Vge,Fpo,Tpo,rj,Mpo,Epo,Cpo,xh,Xge,wpo,Apo,tj,Lpo,ypo,xpo,$h,zge,$po,kpo,aj,Spo,Rpo,Ppo,kh,Qge,Bpo,Ipo,nj,Npo,qpo,jpo,Sh,Wge,Dpo,Gpo,sj,Opo,Vpo,Xpo,Rh,Uge,zpo,Qpo,lj,Wpo,Upo,Hpo,Ph,Hge,Jpo,Ypo,ij,Zpo,Kpo,e_o,Bh,Jge,o_o,r_o,dj,t_o,a_o,n_o,Ih,Yge,s_o,l_o,mj,i_o,d_o,m_o,Nh,Zge,c_o,f_o,cj,g_o,h_o,u_o,qh,Kge,p_o,__o,fj,b_o,v_o,F_o,jh,ehe,T_o,M_o,gj,E_o,C_o,w_o,Dh,ohe,A_o,L_o,hj,y_o,x_o,$_o,Gh,rhe,k_o,S_o,uj,R_o,P_o,B_o,Oh,the,I_o,N_o,pj,q_o,j_o,D_o,Vh,ahe,G_o,O_o,_j,V_o,X_o,z_o,Xh,nhe,Q_o,W_o,bj,U_o,H_o,J_o,zh,she,Y_o,Z_o,vj,K_o,e1o,o1o,Qh,lhe,r1o,t1o,Fj,a1o,n1o,s1o,Wh,ihe,l1o,i1o,Tj,d1o,m1o,c1o,Uh,dhe,f1o,g1o,Mj,h1o,u1o,p1o,Hh,mhe,_1o,b1o,Ej,v1o,F1o,T1o,Jh,che,M1o,E1o,Cj,C1o,w1o,A1o,Yh,fhe,L1o,y1o,wj,x1o,$1o,k1o,Zh,ghe,S1o,R1o,Aj,P1o,B1o,I1o,Kh,hhe,N1o,q1o,Lj,j1o,D1o,G1o,eu,uhe,O1o,V1o,yj,X1o,z1o,Q1o,ou,phe,W1o,U1o,xj,H1o,J1o,Y1o,ru,_he,Z1o,K1o,$j,e2o,o2o,r2o,tu,bhe,t2o,a2o,kj,n2o,s2o,l2o,au,vhe,i2o,d2o,Sj,m2o,c2o,f2o,nu,Fhe,g2o,h2o,Rj,u2o,p2o,_2o,su,The,b2o,v2o,Pj,F2o,T2o,M2o,lu,Mhe,E2o,C2o,Bj,w2o,A2o,L2o,iu,Ehe,y2o,x2o,Ij,$2o,k2o,S2o,du,Che,R2o,P2o,Nj,B2o,I2o,N2o,mu,whe,q2o,j2o,qj,D2o,G2o,O2o,cu,Ahe,V2o,X2o,jj,z2o,Q2o,W2o,fu,Lhe,U2o,H2o,Dj,J2o,Y2o,Z2o,gu,yhe,K2o,ebo,Gj,obo,rbo,tbo,hu,xhe,abo,nbo,Oj,sbo,lbo,ibo,uu,$he,dbo,mbo,Vj,cbo,fbo,gbo,pu,khe,hbo,ubo,Xj,pbo,_bo,bbo,_u,She,vbo,Fbo,zj,Tbo,Mbo,Ebo,bu,Rhe,Cbo,wbo,Qj,Abo,Lbo,ybo,vu,Phe,xbo,$bo,Wj,kbo,Sbo,Rbo,Fu,Bhe,Pbo,Bbo,Uj,Ibo,Nbo,qbo,Tu,Ihe,jbo,Dbo,Hj,Gbo,Obo,Vbo,Mu,Xbo,Eu,f$,zbo,Nhe,Qbo,uto,Ad,Cu,qhe,g$,Wbo,jhe,Ubo,pto,Ro,h$,Hbo,u$,Jbo,Jj,Ybo,Zbo,Kbo,p$,evo,Dhe,ovo,rvo,tvo,jr,_$,avo,Ghe,nvo,svo,rn,lvo,Ohe,ivo,dvo,Vhe,mvo,cvo,Xhe,fvo,gvo,hvo,k,us,zhe,uvo,pvo,Yj,_vo,bvo,Zj,vvo,Fvo,Tvo,ps,Qhe,Mvo,Evo,Kj,Cvo,wvo,eD,Avo,Lvo,yvo,_s,Whe,xvo,$vo,oD,kvo,Svo,rD,Rvo,Pvo,Bvo,wu,Uhe,Ivo,Nvo,tD,qvo,jvo,Dvo,bs,Hhe,Gvo,Ovo,aD,Vvo,Xvo,nD,zvo,Qvo,Wvo,Au,Jhe,Uvo,Hvo,sD,Jvo,Yvo,Zvo,Lu,Yhe,Kvo,eFo,lD,oFo,rFo,tFo,yu,Zhe,aFo,nFo,iD,sFo,lFo,iFo,vs,Khe,dFo,mFo,dD,cFo,fFo,mD,gFo,hFo,uFo,Fs,eue,pFo,_Fo,cD,bFo,vFo,fD,FFo,TFo,MFo,Ts,oue,EFo,CFo,gD,wFo,AFo,hD,LFo,yFo,xFo,xu,rue,$Fo,kFo,uD,SFo,RFo,PFo,$u,tue,BFo,IFo,pD,NFo,qFo,jFo,ku,aue,DFo,GFo,_D,OFo,VFo,XFo,Ms,nue,zFo,QFo,bD,WFo,UFo,vD,HFo,JFo,YFo,Su,sue,ZFo,KFo,FD,eTo,oTo,rTo,Es,lue,tTo,aTo,TD,nTo,sTo,MD,lTo,iTo,dTo,Cs,iue,mTo,cTo,ED,fTo,gTo,CD,hTo,uTo,pTo,ws,due,_To,bTo,wD,vTo,FTo,AD,TTo,MTo,ETo,As,mue,CTo,wTo,LD,ATo,LTo,yD,yTo,xTo,$To,Ru,cue,kTo,STo,xD,RTo,PTo,BTo,Ls,fue,ITo,NTo,$D,qTo,jTo,kD,DTo,GTo,OTo,ys,gue,VTo,XTo,SD,zTo,QTo,RD,WTo,UTo,HTo,xs,hue,JTo,YTo,PD,ZTo,KTo,BD,eMo,oMo,rMo,$s,uue,tMo,aMo,ID,nMo,sMo,ND,lMo,iMo,dMo,ks,pue,mMo,cMo,qD,fMo,gMo,jD,hMo,uMo,pMo,Ss,_ue,_Mo,bMo,DD,vMo,FMo,GD,TMo,MMo,EMo,Rs,bue,CMo,wMo,OD,AMo,LMo,VD,yMo,xMo,$Mo,Pu,vue,kMo,SMo,XD,RMo,PMo,BMo,Bu,Fue,IMo,NMo,zD,qMo,jMo,DMo,Ps,Tue,GMo,OMo,QD,VMo,XMo,WD,zMo,QMo,WMo,Iu,Mue,UMo,HMo,UD,JMo,YMo,ZMo,Bs,Eue,KMo,eEo,HD,oEo,rEo,JD,tEo,aEo,nEo,Is,Cue,sEo,lEo,YD,iEo,dEo,ZD,mEo,cEo,fEo,Ns,wue,gEo,hEo,KD,uEo,pEo,eG,_Eo,bEo,vEo,Nu,Aue,FEo,TEo,oG,MEo,EEo,CEo,qu,Lue,wEo,AEo,rG,LEo,yEo,xEo,qs,yue,$Eo,kEo,tG,SEo,REo,aG,PEo,BEo,IEo,js,xue,NEo,qEo,nG,jEo,DEo,sG,GEo,OEo,VEo,Ds,$ue,XEo,zEo,lG,QEo,WEo,iG,UEo,HEo,JEo,ju,kue,YEo,ZEo,dG,KEo,e4o,o4o,Gs,Sue,r4o,t4o,mG,a4o,n4o,cG,s4o,l4o,i4o,Os,Rue,d4o,m4o,fG,c4o,f4o,gG,g4o,h4o,u4o,Vs,Pue,p4o,_4o,hG,b4o,v4o,uG,F4o,T4o,M4o,Xs,Bue,E4o,C4o,pG,w4o,A4o,_G,L4o,y4o,x4o,zs,Iue,$4o,k4o,bG,S4o,R4o,vG,P4o,B4o,I4o,Qs,Nue,N4o,q4o,FG,j4o,D4o,TG,G4o,O4o,V4o,Ws,que,X4o,z4o,MG,Q4o,W4o,EG,U4o,H4o,J4o,Us,jue,Y4o,Z4o,CG,K4o,eCo,wG,oCo,rCo,tCo,Hs,Due,aCo,nCo,AG,sCo,lCo,LG,iCo,dCo,mCo,Du,Gue,cCo,fCo,yG,gCo,hCo,uCo,Js,Oue,pCo,_Co,xG,bCo,vCo,$G,FCo,TCo,MCo,Gu,Vue,ECo,CCo,kG,wCo,ACo,LCo,Ou,Xue,yCo,xCo,SG,$Co,kCo,SCo,Ys,zue,RCo,PCo,RG,BCo,ICo,PG,NCo,qCo,jCo,Zs,Que,DCo,GCo,BG,OCo,VCo,IG,XCo,zCo,QCo,Ks,Wue,WCo,UCo,NG,HCo,JCo,qG,YCo,ZCo,KCo,Vu,Uue,e3o,o3o,jG,r3o,t3o,a3o,el,Hue,n3o,s3o,DG,l3o,i3o,GG,d3o,m3o,c3o,ol,Jue,f3o,g3o,OG,h3o,u3o,VG,p3o,_3o,b3o,rl,Yue,v3o,F3o,XG,T3o,M3o,zG,E3o,C3o,w3o,tl,Zue,A3o,L3o,QG,y3o,x3o,WG,$3o,k3o,S3o,al,Kue,R3o,P3o,UG,B3o,I3o,HG,N3o,q3o,j3o,nl,epe,D3o,G3o,JG,O3o,V3o,YG,X3o,z3o,Q3o,sl,ope,W3o,U3o,ZG,H3o,J3o,KG,Y3o,Z3o,K3o,ll,rpe,e5o,o5o,eO,r5o,t5o,oO,a5o,n5o,s5o,Xu,tpe,l5o,i5o,rO,d5o,m5o,c5o,il,ape,f5o,g5o,tO,h5o,u5o,aO,p5o,_5o,b5o,dl,npe,v5o,F5o,nO,T5o,M5o,sO,E5o,C5o,w5o,zu,spe,A5o,L5o,lO,y5o,x5o,$5o,Qu,lpe,k5o,S5o,iO,R5o,P5o,B5o,Wu,ipe,I5o,N5o,dO,q5o,j5o,D5o,Uu,dpe,G5o,O5o,mO,V5o,X5o,z5o,ml,mpe,Q5o,W5o,cO,U5o,H5o,fO,J5o,Y5o,Z5o,Hu,cpe,K5o,e0o,gO,o0o,r0o,t0o,cl,fpe,a0o,n0o,hO,s0o,l0o,uO,i0o,d0o,m0o,fl,gpe,c0o,f0o,pO,g0o,h0o,_O,u0o,p0o,_0o,gl,hpe,b0o,v0o,bO,F0o,T0o,vO,M0o,E0o,C0o,hl,upe,w0o,A0o,FO,L0o,y0o,TO,x0o,$0o,k0o,ul,ppe,S0o,R0o,MO,P0o,B0o,EO,I0o,N0o,q0o,pl,_pe,j0o,D0o,CO,G0o,O0o,wO,V0o,X0o,z0o,Ju,bpe,Q0o,W0o,AO,U0o,H0o,J0o,Yu,vpe,Y0o,Z0o,LO,K0o,ewo,owo,_l,Fpe,rwo,two,yO,awo,nwo,xO,swo,lwo,iwo,bl,Tpe,dwo,mwo,$O,cwo,fwo,kO,gwo,hwo,uwo,vl,Mpe,pwo,_wo,SO,bwo,vwo,RO,Fwo,Two,Mwo,Zu,Epe,Ewo,Cwo,PO,wwo,Awo,Lwo,Ku,Cpe,ywo,xwo,BO,$wo,kwo,Swo,ep,wpe,Rwo,Pwo,IO,Bwo,Iwo,Nwo,Fl,Ape,qwo,jwo,NO,Dwo,Gwo,qO,Owo,Vwo,Xwo,Tl,Lpe,zwo,Qwo,jO,Wwo,Uwo,DO,Hwo,Jwo,Ywo,op,ype,Zwo,Kwo,GO,eAo,oAo,rAo,rp,xpe,tAo,aAo,OO,nAo,sAo,lAo,tp,$pe,iAo,dAo,VO,mAo,cAo,fAo,ap,kpe,gAo,hAo,XO,uAo,pAo,_Ao,Ml,Spe,bAo,vAo,zO,FAo,TAo,QO,MAo,EAo,CAo,El,Rpe,wAo,AAo,WO,LAo,yAo,UO,xAo,$Ao,kAo,np,Ppe,SAo,RAo,HO,PAo,BAo,IAo,sp,Bpe,NAo,qAo,JO,jAo,DAo,GAo,Cl,Ipe,OAo,VAo,YO,XAo,zAo,ZO,QAo,WAo,UAo,wl,Npe,HAo,JAo,KO,YAo,ZAo,eV,KAo,e6o,o6o,Al,qpe,r6o,t6o,oV,a6o,n6o,rV,s6o,l6o,i6o,Ll,jpe,d6o,m6o,tV,c6o,f6o,aV,g6o,h6o,u6o,lp,p6o,ip,b$,_6o,Dpe,b6o,_to,Ld,dp,Gpe,v$,v6o,Ope,F6o,bto,Po,F$,T6o,T$,M6o,nV,E6o,C6o,w6o,M$,A6o,Vpe,L6o,y6o,x6o,Ye,E$,$6o,Xpe,k6o,S6o,tn,R6o,zpe,P6o,B6o,Qpe,I6o,N6o,Wpe,q6o,j6o,D6o,z,mp,Upe,G6o,O6o,sV,V6o,X6o,z6o,cp,Hpe,Q6o,W6o,lV,U6o,H6o,J6o,fp,Jpe,Y6o,Z6o,iV,K6o,e7o,o7o,gp,Ype,r7o,t7o,dV,a7o,n7o,s7o,hp,Zpe,l7o,i7o,mV,d7o,m7o,c7o,up,Kpe,f7o,g7o,cV,h7o,u7o,p7o,pp,e_e,_7o,b7o,fV,v7o,F7o,T7o,_p,o_e,M7o,E7o,gV,C7o,w7o,A7o,bp,r_e,L7o,y7o,hV,x7o,$7o,k7o,vp,t_e,S7o,R7o,uV,P7o,B7o,I7o,Fp,a_e,N7o,q7o,pV,j7o,D7o,G7o,Tp,n_e,O7o,V7o,_V,X7o,z7o,Q7o,Mp,s_e,W7o,U7o,bV,H7o,J7o,Y7o,Ep,l_e,Z7o,K7o,vV,e8o,o8o,r8o,Cp,i_e,t8o,a8o,FV,n8o,s8o,l8o,wp,d_e,i8o,d8o,TV,m8o,c8o,f8o,Ap,m_e,g8o,h8o,MV,u8o,p8o,_8o,Lp,c_e,b8o,v8o,EV,F8o,T8o,M8o,yp,f_e,E8o,C8o,CV,w8o,A8o,L8o,xp,g_e,y8o,x8o,wV,$8o,k8o,S8o,$p,h_e,R8o,P8o,AV,B8o,I8o,N8o,kp,u_e,q8o,j8o,LV,D8o,G8o,O8o,Sp,p_e,V8o,X8o,yV,z8o,Q8o,W8o,Rp,__e,U8o,H8o,xV,J8o,Y8o,Z8o,Pp,b_e,K8o,eLo,$V,oLo,rLo,tLo,Bp,v_e,aLo,nLo,kV,sLo,lLo,iLo,Ip,F_e,dLo,mLo,SV,cLo,fLo,gLo,Np,T_e,hLo,uLo,RV,pLo,_Lo,bLo,qp,M_e,vLo,FLo,PV,TLo,MLo,ELo,jp,E_e,CLo,wLo,BV,ALo,LLo,yLo,Dp,C_e,xLo,$Lo,IV,kLo,SLo,RLo,Gp,w_e,PLo,BLo,NV,ILo,NLo,qLo,Op,A_e,jLo,DLo,qV,GLo,OLo,VLo,Vp,L_e,XLo,zLo,jV,QLo,WLo,ULo,Xp,y_e,HLo,JLo,DV,YLo,ZLo,KLo,zp,x_e,eyo,oyo,GV,ryo,tyo,ayo,Qp,$_e,nyo,syo,OV,lyo,iyo,dyo,Wp,k_e,myo,cyo,VV,fyo,gyo,hyo,Up,S_e,uyo,pyo,XV,_yo,byo,vyo,Hp,R_e,Fyo,Tyo,zV,Myo,Eyo,Cyo,Jp,P_e,wyo,Ayo,QV,Lyo,yyo,xyo,Yp,B_e,$yo,kyo,WV,Syo,Ryo,Pyo,Zp,I_e,Byo,Iyo,UV,Nyo,qyo,jyo,Kp,Dyo,e_,Gyo,o_,C$,Oyo,N_e,Vyo,vto,yd,r_,q_e,w$,Xyo,j_e,zyo,Fto,Bo,A$,Qyo,L$,Wyo,HV,Uyo,Hyo,Jyo,y$,Yyo,D_e,Zyo,Kyo,e9o,Ze,x$,o9o,G_e,r9o,t9o,xd,a9o,O_e,n9o,s9o,V_e,l9o,i9o,d9o,se,t_,X_e,m9o,c9o,JV,f9o,g9o,h9o,a_,z_e,u9o,p9o,YV,_9o,b9o,v9o,n_,Q_e,F9o,T9o,ZV,M9o,E9o,C9o,s_,W_e,w9o,A9o,KV,L9o,y9o,x9o,l_,U_e,$9o,k9o,eX,S9o,R9o,P9o,i_,H_e,B9o,I9o,oX,N9o,q9o,j9o,d_,J_e,D9o,G9o,rX,O9o,V9o,X9o,m_,Y_e,z9o,Q9o,tX,W9o,U9o,H9o,c_,Z_e,J9o,Y9o,aX,Z9o,K9o,exo,f_,K_e,oxo,rxo,nX,txo,axo,nxo,g_,e1e,sxo,lxo,sX,ixo,dxo,mxo,h_,o1e,cxo,fxo,lX,gxo,hxo,uxo,u_,r1e,pxo,_xo,iX,bxo,vxo,Fxo,p_,t1e,Txo,Mxo,dX,Exo,Cxo,wxo,__,a1e,Axo,Lxo,mX,yxo,xxo,$xo,b_,n1e,kxo,Sxo,cX,Rxo,Pxo,Bxo,v_,s1e,Ixo,Nxo,fX,qxo,jxo,Dxo,F_,l1e,Gxo,Oxo,gX,Vxo,Xxo,zxo,T_,i1e,Qxo,Wxo,hX,Uxo,Hxo,Jxo,M_,d1e,Yxo,Zxo,uX,Kxo,e$o,o$o,E_,m1e,r$o,t$o,pX,a$o,n$o,s$o,C_,c1e,l$o,i$o,_X,d$o,m$o,c$o,w_,f1e,f$o,g$o,bX,h$o,u$o,p$o,A_,_$o,L_,b$o,y_,$$,v$o,g1e,F$o,Tto,$d,x_,h1e,k$,T$o,u1e,M$o,Mto,Io,S$,E$o,kd,C$o,vX,w$o,A$o,FX,L$o,y$o,x$o,R$,$$o,p1e,k$o,S$o,R$o,Tt,P$,P$o,_1e,B$o,I$o,Sd,N$o,b1e,q$o,j$o,TX,D$o,G$o,O$o,$_,V$o,Ke,B$,X$o,v1e,z$o,Q$o,an,W$o,F1e,U$o,H$o,T1e,J$o,Y$o,M1e,Z$o,K$o,eko,y,k_,E1e,oko,rko,MX,tko,ako,nko,S_,C1e,sko,lko,EX,iko,dko,mko,R_,w1e,cko,fko,CX,gko,hko,uko,P_,A1e,pko,_ko,wX,bko,vko,Fko,B_,L1e,Tko,Mko,AX,Eko,Cko,wko,I_,y1e,Ako,Lko,LX,yko,xko,$ko,N_,x1e,kko,Sko,yX,Rko,Pko,Bko,q_,$1e,Iko,Nko,xX,qko,jko,Dko,j_,k1e,Gko,Oko,$X,Vko,Xko,zko,D_,S1e,Qko,Wko,kX,Uko,Hko,Jko,G_,R1e,Yko,Zko,SX,Kko,eSo,oSo,O_,P1e,rSo,tSo,RX,aSo,nSo,sSo,V_,B1e,lSo,iSo,PX,dSo,mSo,cSo,X_,I1e,fSo,gSo,BX,hSo,uSo,pSo,z_,N1e,_So,bSo,IX,vSo,FSo,TSo,Q_,q1e,MSo,ESo,NX,CSo,wSo,ASo,W_,j1e,LSo,ySo,qX,xSo,$So,kSo,U_,D1e,SSo,RSo,jX,PSo,BSo,ISo,H_,G1e,NSo,qSo,DX,jSo,DSo,GSo,J_,O1e,OSo,VSo,GX,XSo,zSo,QSo,Y_,V1e,WSo,USo,OX,HSo,JSo,YSo,Z_,X1e,ZSo,KSo,VX,eRo,oRo,rRo,K_,z1e,tRo,aRo,XX,nRo,sRo,lRo,e1,Q1e,iRo,dRo,zX,mRo,cRo,fRo,o1,W1e,gRo,hRo,QX,uRo,pRo,_Ro,r1,U1e,bRo,vRo,WX,FRo,TRo,MRo,t1,H1e,ERo,CRo,UX,wRo,ARo,LRo,a1,J1e,yRo,xRo,HX,$Ro,kRo,SRo,n1,Y1e,RRo,PRo,JX,BRo,IRo,NRo,s1,Z1e,qRo,jRo,YX,DRo,GRo,ORo,l1,K1e,VRo,XRo,ZX,zRo,QRo,WRo,i1,e2e,URo,HRo,KX,JRo,YRo,ZRo,d1,o2e,KRo,ePo,ez,oPo,rPo,tPo,m1,r2e,aPo,nPo,oz,sPo,lPo,iPo,c1,t2e,dPo,mPo,rz,cPo,fPo,gPo,f1,a2e,hPo,uPo,tz,pPo,_Po,bPo,g1,n2e,vPo,FPo,az,TPo,MPo,EPo,h1,s2e,CPo,wPo,nz,APo,LPo,yPo,u1,l2e,xPo,$Po,sz,kPo,SPo,RPo,yl,i2e,PPo,BPo,lz,IPo,NPo,iz,qPo,jPo,DPo,p1,d2e,GPo,OPo,dz,VPo,XPo,zPo,_1,m2e,QPo,WPo,mz,UPo,HPo,JPo,b1,c2e,YPo,ZPo,cz,KPo,eBo,oBo,v1,f2e,rBo,tBo,fz,aBo,nBo,sBo,F1,g2e,lBo,iBo,gz,dBo,mBo,cBo,T1,h2e,fBo,gBo,hz,hBo,uBo,pBo,M1,u2e,_Bo,bBo,uz,vBo,FBo,TBo,E1,p2e,MBo,EBo,pz,CBo,wBo,ABo,C1,_2e,LBo,yBo,_z,xBo,$Bo,kBo,w1,b2e,SBo,RBo,bz,PBo,BBo,IBo,A1,v2e,NBo,qBo,vz,jBo,DBo,GBo,L1,F2e,OBo,VBo,Fz,XBo,zBo,QBo,y1,T2e,WBo,UBo,Tz,HBo,JBo,YBo,x1,M2e,ZBo,KBo,Mz,eIo,oIo,rIo,$1,E2e,tIo,aIo,Ez,nIo,sIo,lIo,k1,C2e,iIo,dIo,Cz,mIo,cIo,fIo,S1,w2e,gIo,hIo,wz,uIo,pIo,_Io,R1,A2e,bIo,vIo,Az,FIo,TIo,MIo,P1,L2e,EIo,CIo,Lz,wIo,AIo,LIo,B1,y2e,yIo,xIo,yz,$Io,kIo,SIo,I1,x2e,RIo,PIo,xz,BIo,IIo,NIo,N1,$2e,qIo,jIo,$z,DIo,GIo,OIo,q1,k2e,VIo,XIo,kz,zIo,QIo,WIo,j1,S2e,UIo,HIo,Sz,JIo,YIo,ZIo,D1,R2e,KIo,eNo,Rz,oNo,rNo,tNo,G1,P2e,aNo,nNo,Pz,sNo,lNo,iNo,O1,B2e,dNo,mNo,Bz,cNo,fNo,gNo,V1,I2e,hNo,uNo,Iz,pNo,_No,bNo,X1,N2e,vNo,FNo,Nz,TNo,MNo,ENo,z1,q2e,CNo,wNo,qz,ANo,LNo,yNo,Q1,j2e,xNo,$No,jz,kNo,SNo,RNo,W1,D2e,PNo,BNo,Dz,INo,NNo,qNo,U1,G2e,jNo,DNo,Gz,GNo,ONo,VNo,H1,O2e,XNo,zNo,Oz,QNo,WNo,UNo,J1,V2e,HNo,JNo,Vz,YNo,ZNo,KNo,Y1,X2e,eqo,oqo,Xz,rqo,tqo,aqo,Z1,z2e,nqo,sqo,zz,lqo,iqo,dqo,K1,Q2e,mqo,cqo,Qz,fqo,gqo,hqo,e2,W2e,uqo,pqo,Wz,_qo,bqo,vqo,o2,U2e,Fqo,Tqo,Uz,Mqo,Eqo,Cqo,r2,H2e,wqo,Aqo,Hz,Lqo,yqo,xqo,t2,J2e,$qo,kqo,Jz,Sqo,Rqo,Pqo,a2,Y2e,Bqo,Iqo,Yz,Nqo,qqo,jqo,n2,Z2e,Dqo,Gqo,Zz,Oqo,Vqo,Xqo,s2,K2e,zqo,Qqo,Kz,Wqo,Uqo,Hqo,l2,ebe,Jqo,Yqo,eQ,Zqo,Kqo,ejo,i2,obe,ojo,rjo,oQ,tjo,ajo,njo,d2,rbe,sjo,ljo,rQ,ijo,djo,mjo,m2,tbe,cjo,fjo,tQ,gjo,hjo,ujo,c2,abe,pjo,_jo,aQ,bjo,vjo,Fjo,f2,nbe,Tjo,Mjo,nQ,Ejo,Cjo,wjo,g2,sbe,Ajo,Ljo,sQ,yjo,xjo,$jo,h2,lbe,kjo,Sjo,lQ,Rjo,Pjo,Bjo,u2,ibe,Ijo,Njo,iQ,qjo,jjo,Djo,p2,dbe,Gjo,Ojo,dQ,Vjo,Xjo,zjo,_2,mbe,Qjo,Wjo,mQ,Ujo,Hjo,Jjo,b2,cbe,Yjo,Zjo,cQ,Kjo,eDo,oDo,v2,fbe,rDo,tDo,fQ,aDo,nDo,sDo,F2,gbe,lDo,iDo,gQ,dDo,mDo,cDo,T2,hbe,fDo,gDo,hQ,hDo,uDo,pDo,M2,ube,_Do,bDo,uQ,vDo,FDo,TDo,E2,pbe,MDo,EDo,pQ,CDo,wDo,ADo,C2,_be,LDo,yDo,_Q,xDo,$Do,kDo,w2,bbe,SDo,RDo,bQ,PDo,BDo,IDo,A2,vbe,NDo,qDo,vQ,jDo,DDo,GDo,L2,Fbe,ODo,VDo,FQ,XDo,zDo,QDo,y2,Tbe,WDo,UDo,TQ,HDo,JDo,YDo,x2,Mbe,ZDo,KDo,MQ,eGo,oGo,rGo,$2,Ebe,tGo,aGo,EQ,nGo,sGo,lGo,k2,Cbe,iGo,dGo,CQ,mGo,cGo,fGo,S2,wbe,gGo,hGo,wQ,uGo,pGo,_Go,R2,Abe,bGo,vGo,AQ,FGo,TGo,MGo,P2,Lbe,EGo,CGo,LQ,wGo,AGo,LGo,B2,ybe,yGo,xGo,yQ,$Go,kGo,SGo,I2,xbe,RGo,PGo,xQ,BGo,IGo,NGo,N2,$be,qGo,jGo,$Q,DGo,GGo,OGo,q2,kbe,VGo,XGo,kQ,zGo,QGo,WGo,j2,Sbe,UGo,HGo,SQ,JGo,YGo,ZGo,D2,Rbe,KGo,eOo,RQ,oOo,rOo,tOo,G2,Pbe,aOo,nOo,PQ,sOo,lOo,iOo,O2,Bbe,dOo,mOo,BQ,cOo,fOo,gOo,V2,Ibe,hOo,uOo,IQ,pOo,_Oo,bOo,X2,Nbe,vOo,FOo,NQ,TOo,MOo,EOo,z2,qbe,COo,wOo,qQ,AOo,LOo,yOo,Q2,jbe,xOo,$Oo,jQ,kOo,SOo,ROo,W2,Dbe,POo,BOo,DQ,IOo,NOo,qOo,U2,Gbe,jOo,DOo,GQ,GOo,OOo,VOo,H2,Obe,XOo,zOo,OQ,QOo,WOo,UOo,J2,HOo,Vbe,JOo,YOo,Xbe,ZOo,KOo,Y2,Eto,Rd,Z2,zbe,I$,eVo,Qbe,oVo,Cto,No,N$,rVo,Pd,tVo,VQ,aVo,nVo,XQ,sVo,lVo,iVo,q$,dVo,Wbe,mVo,cVo,fVo,Mt,j$,gVo,Ube,hVo,uVo,Bd,pVo,Hbe,_Vo,bVo,zQ,vVo,FVo,TVo,K2,MVo,eo,D$,EVo,Jbe,CVo,wVo,nn,AVo,Ybe,LVo,yVo,Zbe,xVo,$Vo,Kbe,kVo,SVo,RVo,G,eb,eve,PVo,BVo,QQ,IVo,NVo,qVo,ob,ove,jVo,DVo,WQ,GVo,OVo,VVo,rb,rve,XVo,zVo,UQ,QVo,WVo,UVo,tb,tve,HVo,JVo,HQ,YVo,ZVo,KVo,ab,ave,eXo,oXo,JQ,rXo,tXo,aXo,nb,nve,nXo,sXo,YQ,lXo,iXo,dXo,sb,sve,mXo,cXo,ZQ,fXo,gXo,hXo,lb,lve,uXo,pXo,KQ,_Xo,bXo,vXo,ib,ive,FXo,TXo,eW,MXo,EXo,CXo,db,dve,wXo,AXo,oW,LXo,yXo,xXo,mb,mve,$Xo,kXo,rW,SXo,RXo,PXo,cb,cve,BXo,IXo,tW,NXo,qXo,jXo,fb,fve,DXo,GXo,aW,OXo,VXo,XXo,gb,gve,zXo,QXo,nW,WXo,UXo,HXo,hb,hve,JXo,YXo,sW,ZXo,KXo,ezo,ub,uve,ozo,rzo,lW,tzo,azo,nzo,pb,pve,szo,lzo,iW,izo,dzo,mzo,_b,_ve,czo,fzo,dW,gzo,hzo,uzo,bb,bve,pzo,_zo,mW,bzo,vzo,Fzo,vb,vve,Tzo,Mzo,cW,Ezo,Czo,wzo,Fb,Fve,Azo,Lzo,fW,yzo,xzo,$zo,Tb,Tve,kzo,Szo,gW,Rzo,Pzo,Bzo,Mb,Mve,Izo,Nzo,hW,qzo,jzo,Dzo,Eb,Eve,Gzo,Ozo,uW,Vzo,Xzo,zzo,Cb,Cve,Qzo,Wzo,pW,Uzo,Hzo,Jzo,wb,wve,Yzo,Zzo,_W,Kzo,eQo,oQo,Ab,Ave,rQo,tQo,bW,aQo,nQo,sQo,Lb,Lve,lQo,iQo,vW,dQo,mQo,cQo,yb,yve,fQo,gQo,FW,hQo,uQo,pQo,xb,xve,_Qo,bQo,TW,vQo,FQo,TQo,$b,$ve,MQo,EQo,MW,CQo,wQo,AQo,kb,kve,LQo,yQo,EW,xQo,$Qo,kQo,Sb,Sve,SQo,RQo,CW,PQo,BQo,IQo,Rb,Rve,NQo,qQo,wW,jQo,DQo,GQo,Pb,Pve,OQo,VQo,AW,XQo,zQo,QQo,Bb,Bve,WQo,UQo,LW,HQo,JQo,YQo,Ib,Ive,ZQo,KQo,yW,eWo,oWo,rWo,Nb,Nve,tWo,aWo,xW,nWo,sWo,lWo,qb,qve,iWo,dWo,$W,mWo,cWo,fWo,jb,jve,gWo,hWo,kW,uWo,pWo,_Wo,Db,Dve,bWo,vWo,SW,FWo,TWo,MWo,Gb,Gve,EWo,CWo,RW,wWo,AWo,LWo,Ob,Ove,yWo,xWo,PW,$Wo,kWo,SWo,Vb,Vve,RWo,PWo,BW,BWo,IWo,NWo,Xb,Xve,qWo,jWo,IW,DWo,GWo,OWo,zb,zve,VWo,XWo,NW,zWo,QWo,WWo,Qb,Qve,UWo,HWo,qW,JWo,YWo,ZWo,Wb,Wve,KWo,eUo,jW,oUo,rUo,tUo,Ub,aUo,Uve,nUo,sUo,Hve,lUo,iUo,Hb,wto,Id,Jb,Jve,G$,dUo,Yve,mUo,Ato,qo,O$,cUo,Nd,fUo,DW,gUo,hUo,GW,uUo,pUo,_Uo,V$,bUo,Zve,vUo,FUo,TUo,Et,X$,MUo,Kve,EUo,CUo,qd,wUo,eFe,AUo,LUo,OW,yUo,xUo,$Uo,Yb,kUo,oo,z$,SUo,oFe,RUo,PUo,sn,BUo,rFe,IUo,NUo,tFe,qUo,jUo,aFe,DUo,GUo,OUo,Q,Zb,nFe,VUo,XUo,VW,zUo,QUo,WUo,Kb,sFe,UUo,HUo,XW,JUo,YUo,ZUo,ev,lFe,KUo,eHo,zW,oHo,rHo,tHo,ov,iFe,aHo,nHo,QW,sHo,lHo,iHo,rv,dFe,dHo,mHo,WW,cHo,fHo,gHo,tv,mFe,hHo,uHo,UW,pHo,_Ho,bHo,av,cFe,vHo,FHo,HW,THo,MHo,EHo,nv,fFe,CHo,wHo,JW,AHo,LHo,yHo,sv,gFe,xHo,$Ho,YW,kHo,SHo,RHo,lv,hFe,PHo,BHo,ZW,IHo,NHo,qHo,iv,uFe,jHo,DHo,KW,GHo,OHo,VHo,dv,pFe,XHo,zHo,eU,QHo,WHo,UHo,mv,_Fe,HHo,JHo,oU,YHo,ZHo,KHo,cv,bFe,eJo,oJo,rU,rJo,tJo,aJo,fv,vFe,nJo,sJo,tU,lJo,iJo,dJo,gv,FFe,mJo,cJo,aU,fJo,gJo,hJo,hv,TFe,uJo,pJo,nU,_Jo,bJo,vJo,uv,MFe,FJo,TJo,sU,MJo,EJo,CJo,pv,EFe,wJo,AJo,lU,LJo,yJo,xJo,_v,CFe,$Jo,kJo,iU,SJo,RJo,PJo,bv,wFe,BJo,IJo,dU,NJo,qJo,jJo,vv,AFe,DJo,GJo,mU,OJo,VJo,XJo,Fv,LFe,zJo,QJo,cU,WJo,UJo,HJo,Tv,yFe,JJo,YJo,fU,ZJo,KJo,eYo,Mv,xFe,oYo,rYo,gU,tYo,aYo,nYo,Ev,$Fe,sYo,lYo,hU,iYo,dYo,mYo,Cv,kFe,cYo,fYo,uU,gYo,hYo,uYo,wv,SFe,pYo,_Yo,pU,bYo,vYo,FYo,Av,RFe,TYo,MYo,_U,EYo,CYo,wYo,Lv,PFe,AYo,LYo,bU,yYo,xYo,$Yo,yv,BFe,kYo,SYo,vU,RYo,PYo,BYo,xv,IFe,IYo,NYo,FU,qYo,jYo,DYo,$v,NFe,GYo,OYo,TU,VYo,XYo,zYo,kv,qFe,QYo,WYo,MU,UYo,HYo,JYo,Sv,jFe,YYo,ZYo,EU,KYo,eZo,oZo,Rv,DFe,rZo,tZo,CU,aZo,nZo,sZo,Pv,GFe,lZo,iZo,wU,dZo,mZo,cZo,Bv,OFe,fZo,gZo,AU,hZo,uZo,pZo,Iv,VFe,_Zo,bZo,LU,vZo,FZo,TZo,Nv,XFe,MZo,EZo,yU,CZo,wZo,AZo,qv,zFe,LZo,yZo,xU,xZo,$Zo,kZo,jv,QFe,SZo,RZo,$U,PZo,BZo,IZo,Dv,NZo,WFe,qZo,jZo,UFe,DZo,GZo,Gv,Lto,jd,Ov,HFe,Q$,OZo,JFe,VZo,yto,jo,W$,XZo,Dd,zZo,kU,QZo,WZo,SU,UZo,HZo,JZo,U$,YZo,YFe,ZZo,KZo,eKo,Ct,H$,oKo,ZFe,rKo,tKo,Gd,aKo,KFe,nKo,sKo,RU,lKo,iKo,dKo,Vv,mKo,ro,J$,cKo,eTe,fKo,gKo,ln,hKo,oTe,uKo,pKo,rTe,_Ko,bKo,tTe,vKo,FKo,TKo,Y$,Xv,aTe,MKo,EKo,PU,CKo,wKo,AKo,zv,nTe,LKo,yKo,BU,xKo,$Ko,kKo,Qv,SKo,sTe,RKo,PKo,lTe,BKo,IKo,Wv,xto,Od,Uv,iTe,Z$,NKo,dTe,qKo,$to,Do,K$,jKo,Vd,DKo,IU,GKo,OKo,NU,VKo,XKo,zKo,ek,QKo,mTe,WKo,UKo,HKo,wt,ok,JKo,cTe,YKo,ZKo,Xd,KKo,fTe,eer,oer,qU,rer,ter,aer,Hv,ner,to,rk,ser,gTe,ler,ier,dn,der,hTe,mer,cer,uTe,fer,ger,pTe,her,uer,per,Y,Jv,_Te,_er,ber,jU,ver,Fer,Ter,Yv,bTe,Mer,Eer,DU,Cer,wer,Aer,Zv,vTe,Ler,yer,GU,xer,$er,ker,Kv,FTe,Ser,Rer,OU,Per,Ber,Ier,eF,TTe,Ner,qer,VU,jer,Der,Ger,oF,MTe,Oer,Ver,XU,Xer,zer,Qer,rF,ETe,Wer,Uer,zU,Her,Jer,Yer,tF,CTe,Zer,Ker,QU,eor,oor,ror,aF,wTe,tor,aor,WU,nor,sor,lor,nF,ATe,ior,dor,UU,mor,cor,gor,sF,LTe,hor,uor,HU,por,_or,bor,lF,yTe,vor,For,JU,Tor,Mor,Eor,iF,xTe,Cor,wor,YU,Aor,Lor,yor,dF,$Te,xor,$or,ZU,kor,Sor,Ror,mF,kTe,Por,Bor,KU,Ior,Nor,qor,cF,STe,jor,Dor,eH,Gor,Oor,Vor,fF,RTe,Xor,zor,oH,Qor,Wor,Uor,gF,PTe,Hor,Jor,rH,Yor,Zor,Kor,hF,BTe,err,orr,tH,rrr,trr,arr,uF,ITe,nrr,srr,aH,lrr,irr,drr,pF,NTe,mrr,crr,nH,frr,grr,hrr,_F,qTe,urr,prr,sH,_rr,brr,vrr,bF,jTe,Frr,Trr,lH,Mrr,Err,Crr,vF,DTe,wrr,Arr,iH,Lrr,yrr,xrr,FF,GTe,$rr,krr,dH,Srr,Rrr,Prr,TF,OTe,Brr,Irr,mH,Nrr,qrr,jrr,MF,VTe,Drr,Grr,cH,Orr,Vrr,Xrr,EF,XTe,zrr,Qrr,fH,Wrr,Urr,Hrr,CF,zTe,Jrr,Yrr,gH,Zrr,Krr,etr,wF,QTe,otr,rtr,hH,ttr,atr,ntr,AF,WTe,str,ltr,uH,itr,dtr,mtr,LF,UTe,ctr,ftr,pH,gtr,htr,utr,yF,HTe,ptr,_tr,_H,btr,vtr,Ftr,xF,JTe,Ttr,Mtr,bH,Etr,Ctr,wtr,$F,YTe,Atr,Ltr,ZTe,ytr,xtr,$tr,kF,KTe,ktr,Str,vH,Rtr,Ptr,Btr,SF,eMe,Itr,Ntr,FH,qtr,jtr,Dtr,RF,oMe,Gtr,Otr,TH,Vtr,Xtr,ztr,PF,rMe,Qtr,Wtr,MH,Utr,Htr,Jtr,BF,Ytr,tMe,Ztr,Ktr,aMe,ear,oar,IF,kto,zd,NF,nMe,tk,rar,sMe,tar,Sto,Go,ak,aar,Qd,nar,EH,sar,lar,CH,iar,dar,mar,nk,car,lMe,far,gar,har,At,sk,uar,iMe,par,_ar,Wd,bar,dMe,Far,Tar,wH,Mar,Ear,Car,qF,war,ao,lk,Aar,mMe,Lar,yar,mn,xar,cMe,$ar,kar,fMe,Sar,Rar,gMe,Par,Bar,Iar,he,jF,hMe,Nar,qar,AH,jar,Dar,Gar,DF,uMe,Oar,Var,LH,Xar,zar,Qar,GF,pMe,War,Uar,yH,Har,Jar,Yar,OF,_Me,Zar,Kar,xH,enr,onr,rnr,VF,bMe,tnr,anr,$H,nnr,snr,lnr,XF,vMe,inr,dnr,kH,mnr,cnr,fnr,zF,FMe,gnr,hnr,SH,unr,pnr,_nr,QF,TMe,bnr,vnr,RH,Fnr,Tnr,Mnr,WF,MMe,Enr,Cnr,PH,wnr,Anr,Lnr,UF,EMe,ynr,xnr,BH,$nr,knr,Snr,HF,CMe,Rnr,Pnr,IH,Bnr,Inr,Nnr,JF,wMe,qnr,jnr,NH,Dnr,Gnr,Onr,YF,AMe,Vnr,Xnr,qH,znr,Qnr,Wnr,ZF,LMe,Unr,Hnr,jH,Jnr,Ynr,Znr,KF,yMe,Knr,esr,DH,osr,rsr,tsr,eT,xMe,asr,nsr,GH,ssr,lsr,isr,oT,$Me,dsr,msr,OH,csr,fsr,gsr,rT,kMe,hsr,usr,VH,psr,_sr,bsr,tT,SMe,vsr,Fsr,XH,Tsr,Msr,Esr,aT,RMe,Csr,wsr,zH,Asr,Lsr,ysr,nT,xsr,PMe,$sr,ksr,BMe,Ssr,Rsr,sT,Rto,Ud,lT,IMe,ik,Psr,NMe,Bsr,Pto,Oo,dk,Isr,Hd,Nsr,QH,qsr,jsr,WH,Dsr,Gsr,Osr,mk,Vsr,qMe,Xsr,zsr,Qsr,Lt,ck,Wsr,jMe,Usr,Hsr,Jd,Jsr,DMe,Ysr,Zsr,UH,Ksr,elr,olr,iT,rlr,no,fk,tlr,GMe,alr,nlr,cn,slr,OMe,llr,ilr,VMe,dlr,mlr,XMe,clr,flr,glr,j,dT,zMe,hlr,ulr,HH,plr,_lr,blr,mT,QMe,vlr,Flr,JH,Tlr,Mlr,Elr,cT,WMe,Clr,wlr,YH,Alr,Llr,ylr,fT,UMe,xlr,$lr,ZH,klr,Slr,Rlr,gT,HMe,Plr,Blr,KH,Ilr,Nlr,qlr,hT,JMe,jlr,Dlr,eJ,Glr,Olr,Vlr,uT,YMe,Xlr,zlr,oJ,Qlr,Wlr,Ulr,pT,ZMe,Hlr,Jlr,rJ,Ylr,Zlr,Klr,_T,KMe,eir,oir,tJ,rir,tir,air,bT,eEe,nir,sir,aJ,lir,iir,dir,vT,oEe,mir,cir,nJ,fir,gir,hir,FT,rEe,uir,pir,sJ,_ir,bir,vir,TT,tEe,Fir,Tir,lJ,Mir,Eir,Cir,MT,aEe,wir,Air,iJ,Lir,yir,xir,ET,nEe,$ir,kir,dJ,Sir,Rir,Pir,CT,sEe,Bir,Iir,mJ,Nir,qir,jir,wT,lEe,Dir,Gir,cJ,Oir,Vir,Xir,AT,iEe,zir,Qir,fJ,Wir,Uir,Hir,LT,dEe,Jir,Yir,gJ,Zir,Kir,edr,yT,mEe,odr,rdr,hJ,tdr,adr,ndr,xT,cEe,sdr,ldr,uJ,idr,ddr,mdr,$T,fEe,cdr,fdr,pJ,gdr,hdr,udr,kT,gEe,pdr,_dr,_J,bdr,vdr,Fdr,ST,hEe,Tdr,Mdr,bJ,Edr,Cdr,wdr,RT,uEe,Adr,Ldr,vJ,ydr,xdr,$dr,PT,pEe,kdr,Sdr,FJ,Rdr,Pdr,Bdr,BT,_Ee,Idr,Ndr,TJ,qdr,jdr,Ddr,IT,bEe,Gdr,Odr,MJ,Vdr,Xdr,zdr,NT,vEe,Qdr,Wdr,EJ,Udr,Hdr,Jdr,qT,FEe,Ydr,Zdr,CJ,Kdr,emr,omr,jT,TEe,rmr,tmr,wJ,amr,nmr,smr,DT,MEe,lmr,imr,AJ,dmr,mmr,cmr,GT,EEe,fmr,gmr,LJ,hmr,umr,pmr,OT,CEe,_mr,bmr,yJ,vmr,Fmr,Tmr,VT,wEe,Mmr,Emr,xJ,Cmr,wmr,Amr,XT,AEe,Lmr,ymr,$J,xmr,$mr,kmr,zT,LEe,Smr,Rmr,kJ,Pmr,Bmr,Imr,QT,yEe,Nmr,qmr,SJ,jmr,Dmr,Gmr,WT,xEe,Omr,Vmr,RJ,Xmr,zmr,Qmr,UT,$Ee,Wmr,Umr,PJ,Hmr,Jmr,Ymr,HT,kEe,Zmr,Kmr,BJ,ecr,ocr,rcr,JT,SEe,tcr,acr,IJ,ncr,scr,lcr,YT,REe,icr,dcr,NJ,mcr,ccr,fcr,ZT,PEe,gcr,hcr,qJ,ucr,pcr,_cr,KT,BEe,bcr,vcr,jJ,Fcr,Tcr,Mcr,eM,IEe,Ecr,Ccr,DJ,wcr,Acr,Lcr,oM,NEe,ycr,xcr,GJ,$cr,kcr,Scr,rM,qEe,Rcr,Pcr,OJ,Bcr,Icr,Ncr,tM,jEe,qcr,jcr,VJ,Dcr,Gcr,Ocr,aM,DEe,Vcr,Xcr,XJ,zcr,Qcr,Wcr,nM,GEe,Ucr,Hcr,zJ,Jcr,Ycr,Zcr,sM,OEe,Kcr,efr,QJ,ofr,rfr,tfr,lM,VEe,afr,nfr,WJ,sfr,lfr,ifr,iM,XEe,dfr,mfr,UJ,cfr,ffr,gfr,dM,zEe,hfr,ufr,HJ,pfr,_fr,bfr,mM,QEe,vfr,Ffr,JJ,Tfr,Mfr,Efr,cM,Cfr,WEe,wfr,Afr,UEe,Lfr,yfr,fM,Bto,Yd,gM,HEe,gk,xfr,JEe,$fr,Ito,Vo,hk,kfr,Zd,Sfr,YJ,Rfr,Pfr,ZJ,Bfr,Ifr,Nfr,uk,qfr,YEe,jfr,Dfr,Gfr,yt,pk,Ofr,ZEe,Vfr,Xfr,Kd,zfr,KEe,Qfr,Wfr,KJ,Ufr,Hfr,Jfr,hM,Yfr,so,_k,Zfr,e4e,Kfr,egr,fn,ogr,o4e,rgr,tgr,r4e,agr,ngr,t4e,sgr,lgr,igr,K,uM,a4e,dgr,mgr,eY,cgr,fgr,ggr,pM,n4e,hgr,ugr,oY,pgr,_gr,bgr,_M,s4e,vgr,Fgr,rY,Tgr,Mgr,Egr,bM,l4e,Cgr,wgr,tY,Agr,Lgr,ygr,vM,i4e,xgr,$gr,aY,kgr,Sgr,Rgr,FM,d4e,Pgr,Bgr,nY,Igr,Ngr,qgr,TM,m4e,jgr,Dgr,sY,Ggr,Ogr,Vgr,MM,c4e,Xgr,zgr,lY,Qgr,Wgr,Ugr,EM,f4e,Hgr,Jgr,iY,Ygr,Zgr,Kgr,CM,g4e,ehr,ohr,dY,rhr,thr,ahr,wM,h4e,nhr,shr,mY,lhr,ihr,dhr,AM,u4e,mhr,chr,cY,fhr,ghr,hhr,LM,p4e,uhr,phr,fY,_hr,bhr,vhr,yM,_4e,Fhr,Thr,gY,Mhr,Ehr,Chr,xM,b4e,whr,Ahr,hY,Lhr,yhr,xhr,$M,v4e,$hr,khr,uY,Shr,Rhr,Phr,kM,F4e,Bhr,Ihr,pY,Nhr,qhr,jhr,SM,T4e,Dhr,Ghr,_Y,Ohr,Vhr,Xhr,RM,M4e,zhr,Qhr,bY,Whr,Uhr,Hhr,PM,E4e,Jhr,Yhr,vY,Zhr,Khr,eur,BM,C4e,our,rur,FY,tur,aur,nur,IM,w4e,sur,lur,TY,iur,dur,mur,NM,A4e,cur,fur,MY,gur,hur,uur,qM,L4e,pur,_ur,EY,bur,vur,Fur,jM,y4e,Tur,Mur,CY,Eur,Cur,wur,DM,x4e,Aur,Lur,wY,yur,xur,$ur,GM,$4e,kur,Sur,AY,Rur,Pur,Bur,OM,k4e,Iur,Nur,LY,qur,jur,Dur,VM,S4e,Gur,Our,yY,Vur,Xur,zur,XM,R4e,Qur,Wur,xY,Uur,Hur,Jur,zM,P4e,Yur,Zur,$Y,Kur,epr,opr,QM,B4e,rpr,tpr,kY,apr,npr,spr,WM,lpr,I4e,ipr,dpr,N4e,mpr,cpr,UM,Nto,em,HM,q4e,bk,fpr,j4e,gpr,qto,Xo,vk,hpr,om,upr,SY,ppr,_pr,RY,bpr,vpr,Fpr,Fk,Tpr,D4e,Mpr,Epr,Cpr,xt,Tk,wpr,G4e,Apr,Lpr,rm,ypr,O4e,xpr,$pr,PY,kpr,Spr,Rpr,JM,Ppr,lo,Mk,Bpr,V4e,Ipr,Npr,gn,qpr,X4e,jpr,Dpr,z4e,Gpr,Opr,Q4e,Vpr,Xpr,zpr,Ue,YM,W4e,Qpr,Wpr,BY,Upr,Hpr,Jpr,ZM,U4e,Ypr,Zpr,IY,Kpr,e_r,o_r,KM,H4e,r_r,t_r,NY,a_r,n_r,s_r,eE,J4e,l_r,i_r,qY,d_r,m_r,c_r,oE,Y4e,f_r,g_r,jY,h_r,u_r,p_r,rE,Z4e,__r,b_r,DY,v_r,F_r,T_r,tE,K4e,M_r,E_r,GY,C_r,w_r,A_r,aE,L_r,eCe,y_r,x_r,oCe,$_r,k_r,nE,jto,tm,sE,rCe,Ek,S_r,tCe,R_r,Dto,zo,Ck,P_r,am,B_r,OY,I_r,N_r,VY,q_r,j_r,D_r,wk,G_r,aCe,O_r,V_r,X_r,$t,Ak,z_r,nCe,Q_r,W_r,nm,U_r,sCe,H_r,J_r,XY,Y_r,Z_r,K_r,lE,e1r,io,Lk,o1r,lCe,r1r,t1r,hn,a1r,iCe,n1r,s1r,dCe,l1r,i1r,mCe,d1r,m1r,c1r,U,iE,cCe,f1r,g1r,zY,h1r,u1r,p1r,dE,fCe,_1r,b1r,QY,v1r,F1r,T1r,mE,gCe,M1r,E1r,WY,C1r,w1r,A1r,cE,hCe,L1r,y1r,UY,x1r,$1r,k1r,fE,uCe,S1r,R1r,HY,P1r,B1r,I1r,gE,pCe,N1r,q1r,JY,j1r,D1r,G1r,hE,_Ce,O1r,V1r,YY,X1r,z1r,Q1r,uE,bCe,W1r,U1r,ZY,H1r,J1r,Y1r,pE,vCe,Z1r,K1r,KY,e2r,o2r,r2r,_E,FCe,t2r,a2r,eZ,n2r,s2r,l2r,bE,TCe,i2r,d2r,oZ,m2r,c2r,f2r,vE,MCe,g2r,h2r,rZ,u2r,p2r,_2r,FE,ECe,b2r,v2r,tZ,F2r,T2r,M2r,TE,CCe,E2r,C2r,aZ,w2r,A2r,L2r,ME,wCe,y2r,x2r,nZ,$2r,k2r,S2r,EE,ACe,R2r,P2r,sZ,B2r,I2r,N2r,CE,LCe,q2r,j2r,lZ,D2r,G2r,O2r,wE,yCe,V2r,X2r,iZ,z2r,Q2r,W2r,AE,xCe,U2r,H2r,dZ,J2r,Y2r,Z2r,LE,$Ce,K2r,ebr,mZ,obr,rbr,tbr,yE,kCe,abr,nbr,cZ,sbr,lbr,ibr,xE,SCe,dbr,mbr,fZ,cbr,fbr,gbr,$E,RCe,hbr,ubr,gZ,pbr,_br,bbr,kE,PCe,vbr,Fbr,hZ,Tbr,Mbr,Ebr,SE,BCe,Cbr,wbr,uZ,Abr,Lbr,ybr,RE,ICe,xbr,$br,pZ,kbr,Sbr,Rbr,PE,NCe,Pbr,Bbr,_Z,Ibr,Nbr,qbr,BE,qCe,jbr,Dbr,bZ,Gbr,Obr,Vbr,IE,jCe,Xbr,zbr,vZ,Qbr,Wbr,Ubr,NE,DCe,Hbr,Jbr,FZ,Ybr,Zbr,Kbr,qE,GCe,evr,ovr,TZ,rvr,tvr,avr,jE,OCe,nvr,svr,MZ,lvr,ivr,dvr,DE,VCe,mvr,cvr,EZ,fvr,gvr,hvr,GE,XCe,uvr,pvr,CZ,_vr,bvr,vvr,OE,zCe,Fvr,Tvr,wZ,Mvr,Evr,Cvr,VE,QCe,wvr,Avr,AZ,Lvr,yvr,xvr,XE,WCe,$vr,kvr,LZ,Svr,Rvr,Pvr,zE,UCe,Bvr,Ivr,yZ,Nvr,qvr,jvr,QE,HCe,Dvr,Gvr,xZ,Ovr,Vvr,Xvr,WE,JCe,zvr,Qvr,$Z,Wvr,Uvr,Hvr,UE,YCe,Jvr,Yvr,kZ,Zvr,Kvr,eFr,HE,oFr,ZCe,rFr,tFr,KCe,aFr,nFr,JE,Gto,sm,YE,e3e,yk,sFr,o3e,lFr,Oto,Qo,xk,iFr,lm,dFr,SZ,mFr,cFr,RZ,fFr,gFr,hFr,$k,uFr,r3e,pFr,_Fr,bFr,kt,kk,vFr,t3e,FFr,TFr,im,MFr,a3e,EFr,CFr,PZ,wFr,AFr,LFr,ZE,yFr,mo,Sk,xFr,n3e,$Fr,kFr,un,SFr,s3e,RFr,PFr,l3e,BFr,IFr,i3e,NFr,qFr,jFr,O,KE,d3e,DFr,GFr,BZ,OFr,VFr,XFr,e4,m3e,zFr,QFr,IZ,WFr,UFr,HFr,o4,c3e,JFr,YFr,NZ,ZFr,KFr,eTr,r4,f3e,oTr,rTr,qZ,tTr,aTr,nTr,t4,g3e,sTr,lTr,jZ,iTr,dTr,mTr,a4,h3e,cTr,fTr,DZ,gTr,hTr,uTr,n4,u3e,pTr,_Tr,GZ,bTr,vTr,FTr,s4,p3e,TTr,MTr,OZ,ETr,CTr,wTr,l4,_3e,ATr,LTr,VZ,yTr,xTr,$Tr,i4,b3e,kTr,STr,XZ,RTr,PTr,BTr,d4,v3e,ITr,NTr,zZ,qTr,jTr,DTr,m4,F3e,GTr,OTr,QZ,VTr,XTr,zTr,c4,T3e,QTr,WTr,WZ,UTr,HTr,JTr,f4,M3e,YTr,ZTr,UZ,KTr,eMr,oMr,g4,E3e,rMr,tMr,HZ,aMr,nMr,sMr,h4,C3e,lMr,iMr,JZ,dMr,mMr,cMr,u4,w3e,fMr,gMr,YZ,hMr,uMr,pMr,p4,A3e,_Mr,bMr,ZZ,vMr,FMr,TMr,_4,L3e,MMr,EMr,KZ,CMr,wMr,AMr,b4,y3e,LMr,yMr,eK,xMr,$Mr,kMr,v4,x3e,SMr,RMr,oK,PMr,BMr,IMr,F4,$3e,NMr,qMr,rK,jMr,DMr,GMr,T4,k3e,OMr,VMr,tK,XMr,zMr,QMr,M4,S3e,WMr,UMr,aK,HMr,JMr,YMr,E4,R3e,ZMr,KMr,nK,eEr,oEr,rEr,C4,P3e,tEr,aEr,sK,nEr,sEr,lEr,w4,B3e,iEr,dEr,lK,mEr,cEr,fEr,A4,I3e,gEr,hEr,iK,uEr,pEr,_Er,L4,N3e,bEr,vEr,dK,FEr,TEr,MEr,y4,q3e,EEr,CEr,mK,wEr,AEr,LEr,x4,j3e,yEr,xEr,cK,$Er,kEr,SEr,$4,D3e,REr,PEr,fK,BEr,IEr,NEr,k4,G3e,qEr,jEr,gK,DEr,GEr,OEr,S4,O3e,VEr,XEr,hK,zEr,QEr,WEr,R4,V3e,UEr,HEr,uK,JEr,YEr,ZEr,P4,X3e,KEr,e4r,pK,o4r,r4r,t4r,B4,z3e,a4r,n4r,_K,s4r,l4r,i4r,I4,Q3e,d4r,m4r,bK,c4r,f4r,g4r,N4,W3e,h4r,u4r,vK,p4r,_4r,b4r,q4,U3e,v4r,F4r,FK,T4r,M4r,E4r,j4,H3e,C4r,w4r,TK,A4r,L4r,y4r,D4,J3e,x4r,$4r,MK,k4r,S4r,R4r,G4,Y3e,P4r,B4r,EK,I4r,N4r,q4r,O4,Z3e,j4r,D4r,CK,G4r,O4r,V4r,V4,K3e,X4r,z4r,wK,Q4r,W4r,U4r,X4,e5e,H4r,J4r,AK,Y4r,Z4r,K4r,z4,o5e,eCr,oCr,LK,rCr,tCr,aCr,Q4,r5e,nCr,sCr,yK,lCr,iCr,dCr,W4,mCr,t5e,cCr,fCr,a5e,gCr,hCr,U4,Vto,dm,H4,n5e,Rk,uCr,s5e,pCr,Xto,Wo,Pk,_Cr,mm,bCr,xK,vCr,FCr,$K,TCr,MCr,ECr,Bk,CCr,l5e,wCr,ACr,LCr,St,Ik,yCr,i5e,xCr,$Cr,cm,kCr,d5e,SCr,RCr,kK,PCr,BCr,ICr,J4,NCr,co,Nk,qCr,m5e,jCr,DCr,pn,GCr,c5e,OCr,VCr,f5e,XCr,zCr,g5e,QCr,WCr,UCr,h5e,Y4,u5e,HCr,JCr,SK,YCr,ZCr,KCr,Z4,e3r,p5e,o3r,r3r,_5e,t3r,a3r,K4,zto,fm,eC,b5e,qk,n3r,v5e,s3r,Qto,Uo,jk,l3r,gm,i3r,RK,d3r,m3r,PK,c3r,f3r,g3r,Dk,h3r,F5e,u3r,p3r,_3r,Rt,Gk,b3r,T5e,v3r,F3r,hm,T3r,M5e,M3r,E3r,BK,C3r,w3r,A3r,oC,L3r,fo,Ok,y3r,E5e,x3r,$3r,_n,k3r,C5e,S3r,R3r,w5e,P3r,B3r,A5e,I3r,N3r,q3r,um,rC,L5e,j3r,D3r,IK,G3r,O3r,V3r,tC,y5e,X3r,z3r,NK,Q3r,W3r,U3r,aC,x5e,H3r,J3r,qK,Y3r,Z3r,K3r,nC,e5r,$5e,o5r,r5r,k5e,t5r,a5r,sC,Wto,pm,lC,S5e,Vk,n5r,R5e,s5r,Uto,Ho,Xk,l5r,_m,i5r,jK,d5r,m5r,DK,c5r,f5r,g5r,zk,h5r,P5e,u5r,p5r,_5r,Pt,Qk,b5r,B5e,v5r,F5r,bm,T5r,I5e,M5r,E5r,GK,C5r,w5r,A5r,iC,L5r,go,Wk,y5r,N5e,x5r,$5r,bn,k5r,q5e,S5r,R5r,j5e,P5r,B5r,D5e,I5r,N5r,q5r,be,dC,G5e,j5r,D5r,OK,G5r,O5r,V5r,mC,O5e,X5r,z5r,VK,Q5r,W5r,U5r,cC,V5e,H5r,J5r,XK,Y5r,Z5r,K5r,fC,X5e,e0r,o0r,zK,r0r,t0r,a0r,xl,z5e,n0r,s0r,QK,l0r,i0r,WK,d0r,m0r,c0r,gC,Q5e,f0r,g0r,UK,h0r,u0r,p0r,$l,W5e,_0r,b0r,HK,v0r,F0r,JK,T0r,M0r,E0r,hC,U5e,C0r,w0r,YK,A0r,L0r,y0r,Bt,H5e,x0r,$0r,ZK,k0r,S0r,KK,R0r,P0r,eee,B0r,I0r,N0r,uC,J5e,q0r,j0r,oee,D0r,G0r,O0r,pC,Y5e,V0r,X0r,ree,z0r,Q0r,W0r,_C,Z5e,U0r,H0r,tee,J0r,Y0r,Z0r,bC,K5e,K0r,ewr,aee,owr,rwr,twr,vC,e0e,awr,nwr,nee,swr,lwr,iwr,FC,o0e,dwr,mwr,see,cwr,fwr,gwr,TC,r0e,hwr,uwr,lee,pwr,_wr,bwr,MC,t0e,vwr,Fwr,iee,Twr,Mwr,Ewr,EC,a0e,Cwr,wwr,dee,Awr,Lwr,ywr,CC,xwr,n0e,$wr,kwr,s0e,Swr,Rwr,wC,Hto,vm,AC,l0e,Uk,Pwr,i0e,Bwr,Jto,Jo,Hk,Iwr,Fm,Nwr,mee,qwr,jwr,cee,Dwr,Gwr,Owr,Jk,Vwr,d0e,Xwr,zwr,Qwr,It,Yk,Wwr,m0e,Uwr,Hwr,Tm,Jwr,c0e,Ywr,Zwr,fee,Kwr,eAr,oAr,LC,rAr,ho,Zk,tAr,f0e,aAr,nAr,vn,sAr,g0e,lAr,iAr,h0e,dAr,mAr,u0e,cAr,fAr,gAr,p0e,yC,_0e,hAr,uAr,gee,pAr,_Ar,bAr,xC,vAr,b0e,FAr,TAr,v0e,MAr,EAr,$C,Yto,Mm,kC,F0e,Kk,CAr,T0e,wAr,Zto,Yo,eS,AAr,Em,LAr,hee,yAr,xAr,uee,$Ar,kAr,SAr,oS,RAr,M0e,PAr,BAr,IAr,Nt,rS,NAr,E0e,qAr,jAr,Cm,DAr,C0e,GAr,OAr,pee,VAr,XAr,zAr,SC,QAr,uo,tS,WAr,w0e,UAr,HAr,Fn,JAr,A0e,YAr,ZAr,L0e,KAr,e6r,y0e,o6r,r6r,t6r,x0e,RC,$0e,a6r,n6r,_ee,s6r,l6r,i6r,PC,d6r,k0e,m6r,c6r,S0e,f6r,g6r,BC,Kto,wm,IC,R0e,aS,h6r,P0e,u6r,eao,Zo,nS,p6r,Am,_6r,bee,b6r,v6r,vee,F6r,T6r,M6r,sS,E6r,B0e,C6r,w6r,A6r,qt,lS,L6r,I0e,y6r,x6r,Lm,$6r,N0e,k6r,S6r,Fee,R6r,P6r,B6r,NC,I6r,po,iS,N6r,q0e,q6r,j6r,Tn,D6r,j0e,G6r,O6r,D0e,V6r,X6r,G0e,z6r,Q6r,W6r,O0e,qC,V0e,U6r,H6r,Tee,J6r,Y6r,Z6r,jC,K6r,X0e,e7r,o7r,z0e,r7r,t7r,DC,oao,ym,GC,Q0e,dS,a7r,W0e,n7r,rao,Ko,mS,s7r,xm,l7r,Mee,i7r,d7r,Eee,m7r,c7r,f7r,cS,g7r,U0e,h7r,u7r,p7r,jt,fS,_7r,H0e,b7r,v7r,$m,F7r,J0e,T7r,M7r,Cee,E7r,C7r,w7r,OC,A7r,_o,gS,L7r,Y0e,y7r,x7r,Mn,$7r,Z0e,k7r,S7r,K0e,R7r,P7r,ewe,B7r,I7r,N7r,Be,VC,owe,q7r,j7r,wee,D7r,G7r,O7r,XC,rwe,V7r,X7r,Aee,z7r,Q7r,W7r,zC,twe,U7r,H7r,Lee,J7r,Y7r,Z7r,QC,awe,K7r,e8r,yee,o8r,r8r,t8r,WC,nwe,a8r,n8r,xee,s8r,l8r,i8r,UC,swe,d8r,m8r,$ee,c8r,f8r,g8r,HC,lwe,h8r,u8r,kee,p8r,_8r,b8r,JC,iwe,v8r,F8r,See,T8r,M8r,E8r,YC,dwe,C8r,w8r,Ree,A8r,L8r,y8r,ZC,x8r,mwe,$8r,k8r,cwe,S8r,R8r,KC,tao,km,e3,fwe,hS,P8r,gwe,B8r,aao,er,uS,I8r,Sm,N8r,Pee,q8r,j8r,Bee,D8r,G8r,O8r,pS,V8r,hwe,X8r,z8r,Q8r,Dt,_S,W8r,uwe,U8r,H8r,Rm,J8r,pwe,Y8r,Z8r,Iee,K8r,eLr,oLr,o3,rLr,bo,bS,tLr,_we,aLr,nLr,En,sLr,bwe,lLr,iLr,vwe,dLr,mLr,Fwe,cLr,fLr,gLr,ut,r3,Twe,hLr,uLr,Nee,pLr,_Lr,bLr,t3,Mwe,vLr,FLr,qee,TLr,MLr,ELr,a3,Ewe,CLr,wLr,jee,ALr,LLr,yLr,n3,Cwe,xLr,$Lr,Dee,kLr,SLr,RLr,s3,wwe,PLr,BLr,Gee,ILr,NLr,qLr,l3,jLr,Awe,DLr,GLr,Lwe,OLr,VLr,i3,nao,Pm,d3,ywe,vS,XLr,xwe,zLr,sao,or,FS,QLr,Bm,WLr,Oee,ULr,HLr,Vee,JLr,YLr,ZLr,TS,KLr,$we,eyr,oyr,ryr,Gt,MS,tyr,kwe,ayr,nyr,Im,syr,Swe,lyr,iyr,Xee,dyr,myr,cyr,m3,fyr,vo,ES,gyr,Rwe,hyr,uyr,Cn,pyr,Pwe,_yr,byr,Bwe,vyr,Fyr,Iwe,Tyr,Myr,Eyr,Le,c3,Nwe,Cyr,wyr,zee,Ayr,Lyr,yyr,f3,qwe,xyr,$yr,Qee,kyr,Syr,Ryr,g3,jwe,Pyr,Byr,Wee,Iyr,Nyr,qyr,h3,Dwe,jyr,Dyr,Uee,Gyr,Oyr,Vyr,u3,Gwe,Xyr,zyr,Hee,Qyr,Wyr,Uyr,p3,Owe,Hyr,Jyr,Jee,Yyr,Zyr,Kyr,_3,Vwe,e9r,o9r,Yee,r9r,t9r,a9r,b3,Xwe,n9r,s9r,Zee,l9r,i9r,d9r,v3,zwe,m9r,c9r,Kee,f9r,g9r,h9r,F3,Qwe,u9r,p9r,eoe,_9r,b9r,v9r,T3,F9r,Wwe,T9r,M9r,Uwe,E9r,C9r,M3,lao,Nm,E3,Hwe,CS,w9r,Jwe,A9r,iao,rr,wS,L9r,qm,y9r,ooe,x9r,$9r,roe,k9r,S9r,R9r,AS,P9r,Ywe,B9r,I9r,N9r,Ot,LS,q9r,Zwe,j9r,D9r,jm,G9r,Kwe,O9r,V9r,toe,X9r,z9r,Q9r,C3,W9r,Fo,yS,U9r,eAe,H9r,J9r,wn,Y9r,oAe,Z9r,K9r,rAe,exr,oxr,tAe,rxr,txr,axr,Dm,w3,aAe,nxr,sxr,aoe,lxr,ixr,dxr,A3,nAe,mxr,cxr,noe,fxr,gxr,hxr,L3,sAe,uxr,pxr,soe,_xr,bxr,vxr,y3,Fxr,lAe,Txr,Mxr,iAe,Exr,Cxr,x3,dao,Gm,$3,dAe,xS,wxr,mAe,Axr,mao,tr,$S,Lxr,Om,yxr,loe,xxr,$xr,ioe,kxr,Sxr,Rxr,kS,Pxr,cAe,Bxr,Ixr,Nxr,Vt,SS,qxr,fAe,jxr,Dxr,Vm,Gxr,gAe,Oxr,Vxr,doe,Xxr,zxr,Qxr,k3,Wxr,To,RS,Uxr,hAe,Hxr,Jxr,An,Yxr,uAe,Zxr,Kxr,pAe,e$r,o$r,_Ae,r$r,t$r,a$r,pt,S3,bAe,n$r,s$r,moe,l$r,i$r,d$r,R3,vAe,m$r,c$r,coe,f$r,g$r,h$r,P3,FAe,u$r,p$r,foe,_$r,b$r,v$r,B3,TAe,F$r,T$r,goe,M$r,E$r,C$r,I3,MAe,w$r,A$r,hoe,L$r,y$r,x$r,N3,$$r,EAe,k$r,S$r,CAe,R$r,P$r,q3,cao,Xm,j3,wAe,PS,B$r,AAe,I$r,fao,ar,BS,N$r,zm,q$r,uoe,j$r,D$r,poe,G$r,O$r,V$r,IS,X$r,LAe,z$r,Q$r,W$r,Xt,NS,U$r,yAe,H$r,J$r,Qm,Y$r,xAe,Z$r,K$r,_oe,ekr,okr,rkr,D3,tkr,Mo,qS,akr,$Ae,nkr,skr,Ln,lkr,kAe,ikr,dkr,SAe,mkr,ckr,RAe,fkr,gkr,hkr,yn,G3,PAe,ukr,pkr,boe,_kr,bkr,vkr,O3,BAe,Fkr,Tkr,voe,Mkr,Ekr,Ckr,V3,IAe,wkr,Akr,Foe,Lkr,ykr,xkr,X3,NAe,$kr,kkr,Toe,Skr,Rkr,Pkr,z3,Bkr,qAe,Ikr,Nkr,jAe,qkr,jkr,Q3,gao,Wm,W3,DAe,jS,Dkr,GAe,Gkr,hao,nr,DS,Okr,Um,Vkr,Moe,Xkr,zkr,Eoe,Qkr,Wkr,Ukr,GS,Hkr,OAe,Jkr,Ykr,Zkr,zt,OS,Kkr,VAe,eSr,oSr,Hm,rSr,XAe,tSr,aSr,Coe,nSr,sSr,lSr,U3,iSr,Eo,VS,dSr,zAe,mSr,cSr,xn,fSr,QAe,gSr,hSr,WAe,uSr,pSr,UAe,_Sr,bSr,vSr,$n,H3,HAe,FSr,TSr,woe,MSr,ESr,CSr,J3,JAe,wSr,ASr,Aoe,LSr,ySr,xSr,Y3,YAe,$Sr,kSr,Loe,SSr,RSr,PSr,Z3,ZAe,BSr,ISr,yoe,NSr,qSr,jSr,K3,DSr,KAe,GSr,OSr,e6e,VSr,XSr,e5,uao,Jm,o5,o6e,XS,zSr,r6e,QSr,pao,sr,zS,WSr,Ym,USr,xoe,HSr,JSr,$oe,YSr,ZSr,KSr,QS,eRr,t6e,oRr,rRr,tRr,Qt,WS,aRr,a6e,nRr,sRr,Zm,lRr,n6e,iRr,dRr,koe,mRr,cRr,fRr,r5,gRr,Co,US,hRr,s6e,uRr,pRr,kn,_Rr,l6e,bRr,vRr,i6e,FRr,TRr,d6e,MRr,ERr,CRr,m6e,t5,c6e,wRr,ARr,Soe,LRr,yRr,xRr,a5,$Rr,f6e,kRr,SRr,g6e,RRr,PRr,n5,_ao,Km,s5,h6e,HS,BRr,u6e,IRr,bao,lr,JS,NRr,ec,qRr,Roe,jRr,DRr,Poe,GRr,ORr,VRr,YS,XRr,p6e,zRr,QRr,WRr,Wt,ZS,URr,_6e,HRr,JRr,oc,YRr,b6e,ZRr,KRr,Boe,ePr,oPr,rPr,l5,tPr,wo,KS,aPr,v6e,nPr,sPr,Sn,lPr,F6e,iPr,dPr,T6e,mPr,cPr,M6e,fPr,gPr,hPr,_t,i5,E6e,uPr,pPr,Ioe,_Pr,bPr,vPr,d5,C6e,FPr,TPr,Noe,MPr,EPr,CPr,m5,w6e,wPr,APr,qoe,LPr,yPr,xPr,c5,A6e,$Pr,kPr,joe,SPr,RPr,PPr,f5,L6e,BPr,IPr,Doe,NPr,qPr,jPr,g5,DPr,y6e,GPr,OPr,x6e,VPr,XPr,h5,vao,rc,u5,$6e,eR,zPr,k6e,QPr,Fao,ir,oR,WPr,tc,UPr,Goe,HPr,JPr,Ooe,YPr,ZPr,KPr,rR,eBr,S6e,oBr,rBr,tBr,Ut,tR,aBr,R6e,nBr,sBr,ac,lBr,P6e,iBr,dBr,Voe,mBr,cBr,fBr,p5,gBr,Ao,aR,hBr,B6e,uBr,pBr,Rn,_Br,I6e,bBr,vBr,N6e,FBr,TBr,q6e,MBr,EBr,CBr,j6e,_5,D6e,wBr,ABr,Xoe,LBr,yBr,xBr,b5,$Br,G6e,kBr,SBr,O6e,RBr,PBr,v5,Tao,nc,F5,V6e,nR,BBr,X6e,IBr,Mao,dr,sR,NBr,sc,qBr,zoe,jBr,DBr,Qoe,GBr,OBr,VBr,lR,XBr,z6e,zBr,QBr,WBr,Ht,iR,UBr,Q6e,HBr,JBr,lc,YBr,W6e,ZBr,KBr,Woe,eIr,oIr,rIr,T5,tIr,Lo,dR,aIr,U6e,nIr,sIr,Pn,lIr,H6e,iIr,dIr,J6e,mIr,cIr,Y6e,fIr,gIr,hIr,Z6e,M5,K6e,uIr,pIr,Uoe,_Ir,bIr,vIr,E5,FIr,e7e,TIr,MIr,o7e,EIr,CIr,C5,Eao,ic,w5,r7e,mR,wIr,t7e,AIr,Cao,mr,cR,LIr,dc,yIr,Hoe,xIr,$Ir,Joe,kIr,SIr,RIr,fR,PIr,a7e,BIr,IIr,NIr,Jt,gR,qIr,n7e,jIr,DIr,mc,GIr,s7e,OIr,VIr,Yoe,XIr,zIr,QIr,A5,WIr,Dr,hR,UIr,l7e,HIr,JIr,Bn,YIr,i7e,ZIr,KIr,d7e,eNr,oNr,m7e,rNr,tNr,aNr,P,L5,c7e,nNr,sNr,Zoe,lNr,iNr,dNr,y5,f7e,mNr,cNr,Koe,fNr,gNr,hNr,x5,g7e,uNr,pNr,ere,_Nr,bNr,vNr,$5,h7e,FNr,TNr,ore,MNr,ENr,CNr,k5,u7e,wNr,ANr,rre,LNr,yNr,xNr,S5,p7e,$Nr,kNr,tre,SNr,RNr,PNr,R5,_7e,BNr,INr,are,NNr,qNr,jNr,P5,b7e,DNr,GNr,nre,ONr,VNr,XNr,B5,v7e,zNr,QNr,sre,WNr,UNr,HNr,I5,F7e,JNr,YNr,lre,ZNr,KNr,eqr,N5,T7e,oqr,rqr,ire,tqr,aqr,nqr,q5,M7e,sqr,lqr,dre,iqr,dqr,mqr,j5,E7e,cqr,fqr,mre,gqr,hqr,uqr,D5,C7e,pqr,_qr,cre,bqr,vqr,Fqr,G5,w7e,Tqr,Mqr,fre,Eqr,Cqr,wqr,O5,A7e,Aqr,Lqr,gre,yqr,xqr,$qr,V5,L7e,kqr,Sqr,hre,Rqr,Pqr,Bqr,X5,y7e,Iqr,Nqr,ure,qqr,jqr,Dqr,z5,x7e,Gqr,Oqr,pre,Vqr,Xqr,zqr,Q5,$7e,Qqr,Wqr,_re,Uqr,Hqr,Jqr,kl,k7e,Yqr,Zqr,bre,Kqr,ejr,vre,ojr,rjr,tjr,W5,S7e,ajr,njr,Fre,sjr,ljr,ijr,U5,R7e,djr,mjr,Tre,cjr,fjr,gjr,H5,P7e,hjr,ujr,Mre,pjr,_jr,bjr,J5,B7e,vjr,Fjr,Ere,Tjr,Mjr,Ejr,Y5,I7e,Cjr,wjr,Cre,Ajr,Ljr,yjr,Z5,N7e,xjr,$jr,wre,kjr,Sjr,Rjr,K5,q7e,Pjr,Bjr,Are,Ijr,Njr,qjr,e0,j7e,jjr,Djr,Lre,Gjr,Ojr,Vjr,o0,D7e,Xjr,zjr,yre,Qjr,Wjr,Ujr,r0,G7e,Hjr,Jjr,xre,Yjr,Zjr,Kjr,t0,O7e,eDr,oDr,$re,rDr,tDr,aDr,a0,V7e,nDr,sDr,kre,lDr,iDr,dDr,n0,X7e,mDr,cDr,Sre,fDr,gDr,hDr,s0,z7e,uDr,pDr,Rre,_Dr,bDr,vDr,l0,Q7e,FDr,TDr,Pre,MDr,EDr,CDr,i0,W7e,wDr,ADr,Bre,LDr,yDr,xDr,d0,U7e,$Dr,kDr,Ire,SDr,RDr,PDr,m0,H7e,BDr,IDr,Nre,NDr,qDr,jDr,c0,J7e,DDr,GDr,qre,ODr,VDr,XDr,f0,Y7e,zDr,QDr,jre,WDr,UDr,HDr,g0,Z7e,JDr,YDr,Dre,ZDr,KDr,eGr,h0,K7e,oGr,rGr,Gre,tGr,aGr,nGr,u0,e8e,sGr,lGr,Ore,iGr,dGr,mGr,p0,o8e,cGr,fGr,Vre,gGr,hGr,uGr,_0,r8e,pGr,_Gr,Xre,bGr,vGr,FGr,b0,t8e,TGr,MGr,zre,EGr,CGr,wGr,v0,a8e,AGr,LGr,Qre,yGr,xGr,$Gr,F0,n8e,kGr,SGr,Wre,RGr,PGr,BGr,T0,s8e,IGr,NGr,Ure,qGr,jGr,DGr,M0,l8e,GGr,OGr,Hre,VGr,XGr,zGr,E0,i8e,QGr,WGr,Jre,UGr,HGr,JGr,C0,d8e,YGr,ZGr,Yre,KGr,eOr,oOr,w0,m8e,rOr,tOr,Zre,aOr,nOr,sOr,A0,c8e,lOr,iOr,Kre,dOr,mOr,cOr,L0,f8e,fOr,gOr,ete,hOr,uOr,pOr,y0,g8e,_Or,bOr,ote,vOr,FOr,TOr,x0,h8e,MOr,EOr,rte,COr,wOr,AOr,$0,wao,cc,k0,u8e,uR,LOr,p8e,yOr,Aao,cr,pR,xOr,fc,$Or,tte,kOr,SOr,ate,ROr,POr,BOr,_R,IOr,_8e,NOr,qOr,jOr,Yt,bR,DOr,b8e,GOr,OOr,gc,VOr,v8e,XOr,zOr,nte,QOr,WOr,UOr,S0,HOr,Gr,vR,JOr,F8e,YOr,ZOr,In,KOr,T8e,eVr,oVr,M8e,rVr,tVr,E8e,aVr,nVr,sVr,le,R0,C8e,lVr,iVr,ste,dVr,mVr,cVr,P0,w8e,fVr,gVr,lte,hVr,uVr,pVr,B0,A8e,_Vr,bVr,ite,vVr,FVr,TVr,I0,L8e,MVr,EVr,dte,CVr,wVr,AVr,N0,y8e,LVr,yVr,mte,xVr,$Vr,kVr,q0,x8e,SVr,RVr,cte,PVr,BVr,IVr,j0,$8e,NVr,qVr,fte,jVr,DVr,GVr,D0,k8e,OVr,VVr,gte,XVr,zVr,QVr,G0,S8e,WVr,UVr,hte,HVr,JVr,YVr,O0,R8e,ZVr,KVr,ute,eXr,oXr,rXr,V0,P8e,tXr,aXr,pte,nXr,sXr,lXr,X0,B8e,iXr,dXr,_te,mXr,cXr,fXr,z0,I8e,gXr,hXr,bte,uXr,pXr,_Xr,Q0,N8e,bXr,vXr,vte,FXr,TXr,MXr,W0,q8e,EXr,CXr,Fte,wXr,AXr,LXr,U0,j8e,yXr,xXr,Tte,$Xr,kXr,SXr,H0,D8e,RXr,PXr,Mte,BXr,IXr,NXr,J0,G8e,qXr,jXr,Ete,DXr,GXr,OXr,Y0,O8e,VXr,XXr,Cte,zXr,QXr,WXr,Z0,V8e,UXr,HXr,wte,JXr,YXr,ZXr,K0,X8e,KXr,ezr,Ate,ozr,rzr,tzr,ew,z8e,azr,nzr,Lte,szr,lzr,izr,ow,Q8e,dzr,mzr,yte,czr,fzr,gzr,rw,Lao,hc,tw,W8e,FR,hzr,U8e,uzr,yao,fr,TR,pzr,uc,_zr,xte,bzr,vzr,$te,Fzr,Tzr,Mzr,MR,Ezr,H8e,Czr,wzr,Azr,Zt,ER,Lzr,J8e,yzr,xzr,pc,$zr,Y8e,kzr,Szr,kte,Rzr,Pzr,Bzr,aw,Izr,Or,CR,Nzr,Z8e,qzr,jzr,Nn,Dzr,K8e,Gzr,Ozr,eLe,Vzr,Xzr,oLe,zzr,Qzr,Wzr,Me,nw,rLe,Uzr,Hzr,Ste,Jzr,Yzr,Zzr,sw,tLe,Kzr,eQr,Rte,oQr,rQr,tQr,lw,aLe,aQr,nQr,Pte,sQr,lQr,iQr,iw,nLe,dQr,mQr,Bte,cQr,fQr,gQr,dw,sLe,hQr,uQr,Ite,pQr,_Qr,bQr,mw,lLe,vQr,FQr,Nte,TQr,MQr,EQr,cw,iLe,CQr,wQr,qte,AQr,LQr,yQr,fw,dLe,xQr,$Qr,jte,kQr,SQr,RQr,gw,mLe,PQr,BQr,Dte,IQr,NQr,qQr,hw,cLe,jQr,DQr,Gte,GQr,OQr,VQr,uw,fLe,XQr,zQr,Ote,QQr,WQr,UQr,pw,gLe,HQr,JQr,Vte,YQr,ZQr,KQr,_w,hLe,eWr,oWr,Xte,rWr,tWr,aWr,bw,uLe,nWr,sWr,zte,lWr,iWr,dWr,vw,xao,_c,Fw,pLe,wR,mWr,_Le,cWr,$ao,gr,AR,fWr,bc,gWr,Qte,hWr,uWr,Wte,pWr,_Wr,bWr,LR,vWr,bLe,FWr,TWr,MWr,Kt,yR,EWr,vLe,CWr,wWr,vc,AWr,FLe,LWr,yWr,Ute,xWr,$Wr,kWr,Tw,SWr,Vr,xR,RWr,TLe,PWr,BWr,qn,IWr,MLe,NWr,qWr,ELe,jWr,DWr,CLe,GWr,OWr,VWr,ye,Mw,wLe,XWr,zWr,Hte,QWr,WWr,UWr,Ew,ALe,HWr,JWr,Jte,YWr,ZWr,KWr,Cw,LLe,eUr,oUr,Yte,rUr,tUr,aUr,Sl,yLe,nUr,sUr,Zte,lUr,iUr,Kte,dUr,mUr,cUr,ww,xLe,fUr,gUr,eae,hUr,uUr,pUr,Aw,$Le,_Ur,bUr,oae,vUr,FUr,TUr,Lw,kLe,MUr,EUr,rae,CUr,wUr,AUr,yw,SLe,LUr,yUr,tae,xUr,$Ur,kUr,xw,RLe,SUr,RUr,aae,PUr,BUr,IUr,$w,PLe,NUr,qUr,nae,jUr,DUr,GUr,kw,kao,Fc,Sw,BLe,$R,OUr,ILe,VUr,Sao,hr,kR,XUr,Tc,zUr,sae,QUr,WUr,lae,UUr,HUr,JUr,SR,YUr,NLe,ZUr,KUr,eHr,ea,RR,oHr,qLe,rHr,tHr,Mc,aHr,jLe,nHr,sHr,iae,lHr,iHr,dHr,Rw,mHr,Xr,PR,cHr,DLe,fHr,gHr,jn,hHr,GLe,uHr,pHr,OLe,_Hr,bHr,VLe,vHr,FHr,THr,Ec,Pw,XLe,MHr,EHr,dae,CHr,wHr,AHr,Bw,zLe,LHr,yHr,mae,xHr,$Hr,kHr,Iw,QLe,SHr,RHr,cae,PHr,BHr,IHr,Nw,Rao,Cc,qw,WLe,BR,NHr,ULe,qHr,Pao,ur,IR,jHr,wc,DHr,fae,GHr,OHr,gae,VHr,XHr,zHr,NR,QHr,HLe,WHr,UHr,HHr,oa,qR,JHr,JLe,YHr,ZHr,Ac,KHr,YLe,eJr,oJr,hae,rJr,tJr,aJr,jw,nJr,zr,jR,sJr,ZLe,lJr,iJr,Dn,dJr,KLe,mJr,cJr,eye,fJr,gJr,oye,hJr,uJr,pJr,ce,Dw,rye,_Jr,bJr,uae,vJr,FJr,TJr,Gw,tye,MJr,EJr,pae,CJr,wJr,AJr,Ow,aye,LJr,yJr,_ae,xJr,$Jr,kJr,Vw,nye,SJr,RJr,bae,PJr,BJr,IJr,Xw,sye,NJr,qJr,vae,jJr,DJr,GJr,zw,lye,OJr,VJr,Fae,XJr,zJr,QJr,Qw,iye,WJr,UJr,Tae,HJr,JJr,YJr,Ww,dye,ZJr,KJr,Mae,eYr,oYr,rYr,Uw,mye,tYr,aYr,Eae,nYr,sYr,lYr,Hw,cye,iYr,dYr,Cae,mYr,cYr,fYr,Jw,fye,gYr,hYr,wae,uYr,pYr,_Yr,Yw,gye,bYr,vYr,Aae,FYr,TYr,MYr,Zw,hye,EYr,CYr,Lae,wYr,AYr,LYr,Kw,uye,yYr,xYr,yae,$Yr,kYr,SYr,eA,pye,RYr,PYr,xae,BYr,IYr,NYr,oA,_ye,qYr,jYr,$ae,DYr,GYr,OYr,rA,bye,VYr,XYr,kae,zYr,QYr,WYr,tA,vye,UYr,HYr,Sae,JYr,YYr,ZYr,aA,Fye,KYr,eZr,Rae,oZr,rZr,tZr,nA,Tye,aZr,nZr,Pae,sZr,lZr,iZr,sA,Mye,dZr,mZr,Bae,cZr,fZr,gZr,lA,Bao,Lc,iA,Eye,DR,hZr,Cye,uZr,Iao,pr,GR,pZr,yc,_Zr,Iae,bZr,vZr,Nae,FZr,TZr,MZr,OR,EZr,wye,CZr,wZr,AZr,ra,VR,LZr,Aye,yZr,xZr,xc,$Zr,Lye,kZr,SZr,qae,RZr,PZr,BZr,dA,IZr,Qr,XR,NZr,yye,qZr,jZr,Gn,DZr,xye,GZr,OZr,$ye,VZr,XZr,kye,zZr,QZr,WZr,xe,mA,Sye,UZr,HZr,jae,JZr,YZr,ZZr,cA,Rye,KZr,eKr,Dae,oKr,rKr,tKr,fA,Pye,aKr,nKr,Gae,sKr,lKr,iKr,gA,Bye,dKr,mKr,Oae,cKr,fKr,gKr,hA,Iye,hKr,uKr,Vae,pKr,_Kr,bKr,uA,Nye,vKr,FKr,Xae,TKr,MKr,EKr,pA,qye,CKr,wKr,zae,AKr,LKr,yKr,_A,jye,xKr,$Kr,Qae,kKr,SKr,RKr,bA,Dye,PKr,BKr,Wae,IKr,NKr,qKr,vA,Gye,jKr,DKr,Uae,GKr,OKr,VKr,FA,Nao,$c,TA,Oye,zR,XKr,Vye,zKr,qao,_r,QR,QKr,kc,WKr,Hae,UKr,HKr,Jae,JKr,YKr,ZKr,WR,KKr,Xye,eet,oet,ret,ta,UR,tet,zye,aet,net,Sc,set,Qye,iet,det,Yae,met,cet,fet,MA,get,Wr,HR,het,Wye,uet,pet,On,_et,Uye,bet,vet,Hye,Fet,Tet,Jye,Met,Eet,Cet,re,EA,Yye,wet,Aet,Zae,Let,yet,xet,CA,Zye,$et,ket,Kae,Set,Ret,Pet,wA,Kye,Bet,Iet,ene,Net,qet,jet,AA,e9e,Det,Get,one,Oet,Vet,Xet,LA,o9e,zet,Qet,rne,Wet,Uet,Het,yA,r9e,Jet,Yet,tne,Zet,Ket,eot,xA,t9e,oot,rot,ane,tot,aot,not,$A,a9e,sot,lot,nne,iot,dot,mot,kA,n9e,cot,fot,sne,got,hot,uot,SA,s9e,pot,_ot,lne,bot,vot,Fot,RA,l9e,Tot,Mot,ine,Eot,Cot,wot,PA,i9e,Aot,Lot,dne,yot,xot,$ot,BA,d9e,kot,Sot,mne,Rot,Pot,Bot,IA,m9e,Iot,Not,cne,qot,jot,Dot,NA,c9e,Got,Oot,fne,Vot,Xot,zot,qA,f9e,Qot,Wot,gne,Uot,Hot,Jot,jA,g9e,Yot,Zot,hne,Kot,ert,ort,DA,h9e,rrt,trt,une,art,nrt,srt,GA,u9e,lrt,irt,pne,drt,mrt,crt,OA,p9e,frt,grt,_ne,hrt,urt,prt,VA,_9e,_rt,brt,bne,vrt,Frt,Trt,XA,b9e,Mrt,Ert,vne,Crt,wrt,Art,zA,v9e,Lrt,yrt,Fne,xrt,$rt,krt,QA,F9e,Srt,Rrt,Tne,Prt,Brt,Irt,WA,T9e,Nrt,qrt,Mne,jrt,Drt,Grt,UA,M9e,Ort,Vrt,Ene,Xrt,zrt,Qrt,HA,E9e,Wrt,Urt,Cne,Hrt,Jrt,Yrt,JA,C9e,Zrt,Krt,wne,ett,ott,rtt,YA,jao,Rc,ZA,w9e,JR,ttt,A9e,att,Dao,br,YR,ntt,Pc,stt,Ane,ltt,itt,Lne,dtt,mtt,ctt,ZR,ftt,L9e,gtt,htt,utt,aa,KR,ptt,y9e,_tt,btt,Bc,vtt,x9e,Ftt,Ttt,yne,Mtt,Ett,Ctt,KA,wtt,Ur,eP,Att,$9e,Ltt,ytt,Vn,xtt,k9e,$tt,ktt,S9e,Stt,Rtt,R9e,Ptt,Btt,Itt,ve,e6,P9e,Ntt,qtt,xne,jtt,Dtt,Gtt,o6,B9e,Ott,Vtt,$ne,Xtt,ztt,Qtt,r6,I9e,Wtt,Utt,kne,Htt,Jtt,Ytt,t6,N9e,Ztt,Ktt,Sne,eat,oat,rat,a6,q9e,tat,aat,Rne,nat,sat,lat,n6,j9e,iat,dat,Pne,mat,cat,fat,s6,D9e,gat,hat,Bne,uat,pat,_at,l6,G9e,bat,vat,Ine,Fat,Tat,Mat,i6,O9e,Eat,Cat,Nne,wat,Aat,Lat,d6,V9e,yat,xat,qne,$at,kat,Sat,m6,X9e,Rat,Pat,jne,Bat,Iat,Nat,c6,z9e,qat,jat,Dne,Dat,Gat,Oat,f6,Q9e,Vat,Xat,Gne,zat,Qat,Wat,g6,W9e,Uat,Hat,One,Jat,Yat,Zat,h6,U9e,Kat,ent,Vne,ont,rnt,tnt,u6,H9e,ant,nnt,Xne,snt,lnt,int,p6,J9e,dnt,mnt,zne,cnt,fnt,gnt,_6,Gao,Ic,b6,Y9e,oP,hnt,Z9e,unt,Oao,vr,rP,pnt,Nc,_nt,Qne,bnt,vnt,Wne,Fnt,Tnt,Mnt,tP,Ent,K9e,Cnt,wnt,Ant,na,aP,Lnt,exe,ynt,xnt,qc,$nt,oxe,knt,Snt,Une,Rnt,Pnt,Bnt,v6,Int,Hr,nP,Nnt,rxe,qnt,jnt,Xn,Dnt,txe,Gnt,Ont,axe,Vnt,Xnt,nxe,znt,Qnt,Wnt,sP,F6,sxe,Unt,Hnt,Hne,Jnt,Ynt,Znt,T6,lxe,Knt,est,Jne,ost,rst,tst,M6,Vao,jc,E6,ixe,lP,ast,dxe,nst,Xao,Fr,iP,sst,Dc,lst,Yne,ist,dst,Zne,mst,cst,fst,dP,gst,mxe,hst,ust,pst,sa,mP,_st,cxe,bst,vst,Gc,Fst,fxe,Tst,Mst,Kne,Est,Cst,wst,C6,Ast,Jr,cP,Lst,gxe,yst,xst,zn,$st,hxe,kst,Sst,uxe,Rst,Pst,pxe,Bst,Ist,Nst,_xe,w6,bxe,qst,jst,ese,Dst,Gst,Ost,A6,zao,Oc,L6,vxe,fP,Vst,Fxe,Xst,Qao,Tr,gP,zst,Vc,Qst,ose,Wst,Ust,rse,Hst,Jst,Yst,hP,Zst,Txe,Kst,elt,olt,la,uP,rlt,Mxe,tlt,alt,Xc,nlt,Exe,slt,llt,tse,ilt,dlt,mlt,y6,clt,Yr,pP,flt,Cxe,glt,hlt,Qn,ult,wxe,plt,_lt,Axe,blt,vlt,Lxe,Flt,Tlt,Mlt,yxe,x6,xxe,Elt,Clt,ase,wlt,Alt,Llt,$6,Wao,zc,k6,$xe,_P,ylt,kxe,xlt,Uao,Mr,bP,$lt,Qc,klt,nse,Slt,Rlt,sse,Plt,Blt,Ilt,vP,Nlt,Sxe,qlt,jlt,Dlt,ia,FP,Glt,Rxe,Olt,Vlt,Wc,Xlt,Pxe,zlt,Qlt,lse,Wlt,Ult,Hlt,S6,Jlt,Zr,TP,Ylt,Bxe,Zlt,Klt,Wn,eit,Ixe,oit,rit,Nxe,tit,ait,qxe,nit,sit,lit,ie,R6,jxe,iit,dit,ise,mit,cit,fit,P6,Dxe,git,hit,dse,uit,pit,_it,B6,Gxe,bit,vit,mse,Fit,Tit,Mit,I6,Oxe,Eit,Cit,cse,wit,Ait,Lit,N6,Vxe,yit,xit,fse,$it,kit,Sit,q6,Xxe,Rit,Pit,gse,Bit,Iit,Nit,j6,zxe,qit,jit,hse,Dit,Git,Oit,D6,Qxe,Vit,Xit,use,zit,Qit,Wit,G6,Wxe,Uit,Hit,pse,Jit,Yit,Zit,O6,Uxe,Kit,edt,_se,odt,rdt,tdt,V6,Hxe,adt,ndt,bse,sdt,ldt,idt,X6,Jxe,ddt,mdt,vse,cdt,fdt,gdt,z6,Yxe,hdt,udt,Fse,pdt,_dt,bdt,Q6,Zxe,vdt,Fdt,Tse,Tdt,Mdt,Edt,W6,Kxe,Cdt,wdt,Mse,Adt,Ldt,ydt,U6,e$e,xdt,$dt,Ese,kdt,Sdt,Rdt,H6,o$e,Pdt,Bdt,Cse,Idt,Ndt,qdt,J6,r$e,jdt,Ddt,wse,Gdt,Odt,Vdt,Y6,t$e,Xdt,zdt,Ase,Qdt,Wdt,Udt,Z6,a$e,Hdt,Jdt,Lse,Ydt,Zdt,Kdt,K6,n$e,emt,omt,yse,rmt,tmt,amt,e7,s$e,nmt,smt,xse,lmt,imt,dmt,o7,Hao,Uc,r7,l$e,MP,mmt,i$e,cmt,Jao,Er,EP,fmt,Hc,gmt,$se,hmt,umt,kse,pmt,_mt,bmt,CP,vmt,d$e,Fmt,Tmt,Mmt,da,wP,Emt,m$e,Cmt,wmt,Jc,Amt,c$e,Lmt,ymt,Sse,xmt,$mt,kmt,t7,Smt,Kr,AP,Rmt,f$e,Pmt,Bmt,Un,Imt,g$e,Nmt,qmt,h$e,jmt,Dmt,u$e,Gmt,Omt,Vmt,fe,a7,p$e,Xmt,zmt,Rse,Qmt,Wmt,Umt,n7,_$e,Hmt,Jmt,Pse,Ymt,Zmt,Kmt,s7,b$e,ect,oct,Bse,rct,tct,act,l7,v$e,nct,sct,Ise,lct,ict,dct,i7,F$e,mct,cct,Nse,fct,gct,hct,d7,T$e,uct,pct,qse,_ct,bct,vct,m7,M$e,Fct,Tct,jse,Mct,Ect,Cct,c7,E$e,wct,Act,Dse,Lct,yct,xct,f7,C$e,$ct,kct,Gse,Sct,Rct,Pct,g7,w$e,Bct,Ict,Ose,Nct,qct,jct,h7,A$e,Dct,Gct,Vse,Oct,Vct,Xct,u7,L$e,zct,Qct,Xse,Wct,Uct,Hct,p7,y$e,Jct,Yct,zse,Zct,Kct,eft,_7,x$e,oft,rft,Qse,tft,aft,nft,b7,$$e,sft,lft,Wse,ift,dft,mft,v7,k$e,cft,fft,Use,gft,hft,uft,F7,S$e,pft,_ft,Hse,bft,vft,Fft,T7,R$e,Tft,Mft,Jse,Eft,Cft,wft,M7,P$e,Aft,Lft,Yse,yft,xft,$ft,E7,B$e,kft,Sft,Zse,Rft,Pft,Bft,C7,I$e,Ift,Nft,Kse,qft,jft,Dft,w7,Yao,Yc,A7,N$e,LP,Gft,q$e,Oft,Zao,Cr,yP,Vft,Zc,Xft,ele,zft,Qft,ole,Wft,Uft,Hft,xP,Jft,j$e,Yft,Zft,Kft,ma,$P,egt,D$e,ogt,rgt,Kc,tgt,G$e,agt,ngt,rle,sgt,lgt,igt,L7,dgt,et,kP,mgt,O$e,cgt,fgt,Hn,ggt,V$e,hgt,ugt,X$e,pgt,_gt,z$e,bgt,vgt,Fgt,Q$e,y7,W$e,Tgt,Mgt,tle,Egt,Cgt,wgt,x7,Kao,ef,$7,U$e,SP,Agt,H$e,Lgt,eno,wr,RP,ygt,of,xgt,ale,$gt,kgt,nle,Sgt,Rgt,Pgt,PP,Bgt,J$e,Igt,Ngt,qgt,ca,BP,jgt,Y$e,Dgt,Ggt,rf,Ogt,Z$e,Vgt,Xgt,sle,zgt,Qgt,Wgt,k7,Ugt,ot,IP,Hgt,K$e,Jgt,Ygt,Jn,Zgt,eke,Kgt,eht,oke,oht,rht,rke,tht,aht,nht,NP,S7,tke,sht,lht,lle,iht,dht,mht,R7,ake,cht,fht,ile,ght,hht,uht,P7,ono,tf,B7,nke,qP,pht,ske,_ht,rno,Ar,jP,bht,af,vht,dle,Fht,Tht,mle,Mht,Eht,Cht,DP,wht,lke,Aht,Lht,yht,fa,GP,xht,ike,$ht,kht,nf,Sht,dke,Rht,Pht,cle,Bht,Iht,Nht,I7,qht,rt,OP,jht,mke,Dht,Ght,Yn,Oht,cke,Vht,Xht,fke,zht,Qht,gke,Wht,Uht,Hht,te,N7,hke,Jht,Yht,fle,Zht,Kht,eut,q7,uke,out,rut,gle,tut,aut,nut,j7,pke,sut,lut,hle,iut,dut,mut,D7,_ke,cut,fut,ule,gut,hut,uut,G7,bke,put,_ut,ple,but,vut,Fut,O7,vke,Tut,Mut,_le,Eut,Cut,wut,V7,Fke,Aut,Lut,ble,yut,xut,$ut,X7,Tke,kut,Sut,vle,Rut,Put,But,z7,Mke,Iut,Nut,Fle,qut,jut,Dut,Q7,Eke,Gut,Out,Tle,Vut,Xut,zut,W7,Cke,Qut,Wut,Mle,Uut,Hut,Jut,U7,wke,Yut,Zut,Ele,Kut,ept,opt,H7,Ake,rpt,tpt,Cle,apt,npt,spt,J7,Lke,lpt,ipt,wle,dpt,mpt,cpt,Y7,yke,fpt,gpt,Ale,hpt,upt,ppt,Z7,xke,_pt,bpt,Lle,vpt,Fpt,Tpt,K7,$ke,Mpt,Ept,yle,Cpt,wpt,Apt,e8,kke,Lpt,ypt,xle,xpt,$pt,kpt,o8,Ske,Spt,Rpt,$le,Ppt,Bpt,Ipt,r8,Rke,Npt,qpt,kle,jpt,Dpt,Gpt,t8,Pke,Opt,Vpt,Sle,Xpt,zpt,Qpt,a8,Bke,Wpt,Upt,Rle,Hpt,Jpt,Ypt,n8,Ike,Zpt,Kpt,Ple,e_t,o_t,r_t,s8,Nke,t_t,a_t,Ble,n_t,s_t,l_t,l8,qke,i_t,d_t,Ile,m_t,c_t,f_t,i8,jke,g_t,h_t,Nle,u_t,p_t,__t,d8,Dke,b_t,v_t,qle,F_t,T_t,M_t,m8,tno,sf,c8,Gke,VP,E_t,Oke,C_t,ano,Lr,XP,w_t,lf,A_t,jle,L_t,y_t,Dle,x_t,$_t,k_t,zP,S_t,Vke,R_t,P_t,B_t,ga,QP,I_t,Xke,N_t,q_t,df,j_t,zke,D_t,G_t,Gle,O_t,V_t,X_t,f8,z_t,tt,WP,Q_t,Qke,W_t,U_t,Zn,H_t,Wke,J_t,Y_t,Uke,Z_t,K_t,Hke,e1t,o1t,r1t,$e,g8,Jke,t1t,a1t,Ole,n1t,s1t,l1t,h8,Yke,i1t,d1t,Vle,m1t,c1t,f1t,u8,Zke,g1t,h1t,Xle,u1t,p1t,_1t,p8,Kke,b1t,v1t,zle,F1t,T1t,M1t,_8,eSe,E1t,C1t,Qle,w1t,A1t,L1t,b8,oSe,y1t,x1t,Wle,$1t,k1t,S1t,v8,rSe,R1t,P1t,Ule,B1t,I1t,N1t,F8,tSe,q1t,j1t,Hle,D1t,G1t,O1t,T8,aSe,V1t,X1t,Jle,z1t,Q1t,W1t,M8,nSe,U1t,H1t,Yle,J1t,Y1t,Z1t,E8,nno,mf,C8,sSe,UP,K1t,lSe,e2t,sno,yr,HP,o2t,cf,r2t,Zle,t2t,a2t,Kle,n2t,s2t,l2t,JP,i2t,iSe,d2t,m2t,c2t,ha,YP,f2t,dSe,g2t,h2t,ff,u2t,mSe,p2t,_2t,eie,b2t,v2t,F2t,w8,T2t,at,ZP,M2t,cSe,E2t,C2t,Kn,w2t,fSe,A2t,L2t,gSe,y2t,x2t,hSe,$2t,k2t,S2t,Ee,A8,uSe,R2t,P2t,oie,B2t,I2t,N2t,L8,pSe,q2t,j2t,rie,D2t,G2t,O2t,y8,_Se,V2t,X2t,tie,z2t,Q2t,W2t,x8,bSe,U2t,H2t,aie,J2t,Y2t,Z2t,$8,vSe,K2t,ebt,nie,obt,rbt,tbt,k8,FSe,abt,nbt,sie,sbt,lbt,ibt,S8,TSe,dbt,mbt,lie,cbt,fbt,gbt,R8,MSe,hbt,ubt,iie,pbt,_bt,bbt,P8,ESe,vbt,Fbt,die,Tbt,Mbt,Ebt,B8,CSe,Cbt,wbt,mie,Abt,Lbt,ybt,I8,wSe,xbt,$bt,cie,kbt,Sbt,Rbt,N8,ASe,Pbt,Bbt,fie,Ibt,Nbt,qbt,q8,LSe,jbt,Dbt,gie,Gbt,Obt,Vbt,j8,lno,gf,D8,ySe,KP,Xbt,xSe,zbt,ino,xr,eB,Qbt,hf,Wbt,hie,Ubt,Hbt,uie,Jbt,Ybt,Zbt,oB,Kbt,$Se,evt,ovt,rvt,ua,rB,tvt,kSe,avt,nvt,uf,svt,SSe,lvt,ivt,pie,dvt,mvt,cvt,G8,fvt,nt,tB,gvt,RSe,hvt,uvt,es,pvt,PSe,_vt,bvt,BSe,vvt,Fvt,ISe,Tvt,Mvt,Evt,ke,O8,NSe,Cvt,wvt,_ie,Avt,Lvt,yvt,V8,qSe,xvt,$vt,bie,kvt,Svt,Rvt,X8,jSe,Pvt,Bvt,vie,Ivt,Nvt,qvt,z8,DSe,jvt,Dvt,Fie,Gvt,Ovt,Vvt,Q8,GSe,Xvt,zvt,Tie,Qvt,Wvt,Uvt,W8,OSe,Hvt,Jvt,Mie,Yvt,Zvt,Kvt,U8,VSe,eFt,oFt,Eie,rFt,tFt,aFt,H8,XSe,nFt,sFt,Cie,lFt,iFt,dFt,J8,zSe,mFt,cFt,wie,fFt,gFt,hFt,Y8,QSe,uFt,pFt,Aie,_Ft,bFt,vFt,Z8,dno,pf,K8,WSe,aB,FFt,USe,TFt,mno,$r,nB,MFt,_f,EFt,Lie,CFt,wFt,yie,AFt,LFt,yFt,sB,xFt,HSe,$Ft,kFt,SFt,pa,lB,RFt,JSe,PFt,BFt,bf,IFt,YSe,NFt,qFt,xie,jFt,DFt,GFt,eL,OFt,st,iB,VFt,ZSe,XFt,zFt,os,QFt,KSe,WFt,UFt,eRe,HFt,JFt,oRe,YFt,ZFt,KFt,Se,oL,rRe,eTt,oTt,$ie,rTt,tTt,aTt,rL,tRe,nTt,sTt,kie,lTt,iTt,dTt,tL,aRe,mTt,cTt,Sie,fTt,gTt,hTt,aL,nRe,uTt,pTt,Rie,_Tt,bTt,vTt,nL,sRe,FTt,TTt,Pie,MTt,ETt,CTt,sL,lRe,wTt,ATt,Bie,LTt,yTt,xTt,lL,iRe,$Tt,kTt,Iie,STt,RTt,PTt,iL,dRe,BTt,ITt,Nie,NTt,qTt,jTt,dL,mRe,DTt,GTt,qie,OTt,VTt,XTt,mL,cRe,zTt,QTt,jie,WTt,UTt,HTt,cL,cno,vf,fL,fRe,dB,JTt,gRe,YTt,fno,kr,mB,ZTt,Ff,KTt,Die,eMt,oMt,Gie,rMt,tMt,aMt,cB,nMt,hRe,sMt,lMt,iMt,_a,fB,dMt,uRe,mMt,cMt,Tf,fMt,pRe,gMt,hMt,Oie,uMt,pMt,_Mt,gL,bMt,lt,gB,vMt,_Re,FMt,TMt,rs,MMt,bRe,EMt,CMt,vRe,wMt,AMt,FRe,LMt,yMt,xMt,Re,hL,TRe,$Mt,kMt,Vie,SMt,RMt,PMt,uL,MRe,BMt,IMt,Xie,NMt,qMt,jMt,pL,ERe,DMt,GMt,zie,OMt,VMt,XMt,_L,CRe,zMt,QMt,Qie,WMt,UMt,HMt,bL,wRe,JMt,YMt,Wie,ZMt,KMt,eEt,vL,ARe,oEt,rEt,Uie,tEt,aEt,nEt,FL,LRe,sEt,lEt,Hie,iEt,dEt,mEt,TL,yRe,cEt,fEt,Jie,gEt,hEt,uEt,ML,xRe,pEt,_Et,Yie,bEt,vEt,FEt,EL,$Re,TEt,MEt,Zie,EEt,CEt,wEt,CL,gno,Mf,wL,kRe,hB,AEt,SRe,LEt,hno,Sr,uB,yEt,Ef,xEt,Kie,$Et,kEt,ede,SEt,REt,PEt,pB,BEt,RRe,IEt,NEt,qEt,ba,_B,jEt,PRe,DEt,GEt,Cf,OEt,BRe,VEt,XEt,ode,zEt,QEt,WEt,AL,UEt,it,bB,HEt,IRe,JEt,YEt,ts,ZEt,NRe,KEt,e4t,qRe,o4t,r4t,jRe,t4t,a4t,n4t,Pe,LL,DRe,s4t,l4t,rde,i4t,d4t,m4t,yL,GRe,c4t,f4t,tde,g4t,h4t,u4t,xL,ORe,p4t,_4t,ade,b4t,v4t,F4t,$L,VRe,T4t,M4t,nde,E4t,C4t,w4t,kL,XRe,A4t,L4t,sde,y4t,x4t,$4t,SL,zRe,k4t,S4t,lde,R4t,P4t,B4t,RL,QRe,I4t,N4t,ide,q4t,j4t,D4t,PL,WRe,G4t,O4t,dde,V4t,X4t,z4t,BL,URe,Q4t,W4t,mde,U4t,H4t,J4t,IL,HRe,Y4t,Z4t,cde,K4t,eCt,oCt,NL,uno,wf,qL,JRe,vB,rCt,YRe,tCt,pno,Rr,FB,aCt,Af,nCt,fde,sCt,lCt,gde,iCt,dCt,mCt,TB,cCt,ZRe,fCt,gCt,hCt,va,MB,uCt,KRe,pCt,_Ct,Lf,bCt,ePe,vCt,FCt,hde,TCt,MCt,ECt,jL,CCt,dt,EB,wCt,oPe,ACt,LCt,as,yCt,rPe,xCt,$Ct,tPe,kCt,SCt,aPe,RCt,PCt,BCt,ze,DL,nPe,ICt,NCt,ude,qCt,jCt,DCt,GL,sPe,GCt,OCt,pde,VCt,XCt,zCt,OL,lPe,QCt,WCt,_de,UCt,HCt,JCt,VL,iPe,YCt,ZCt,bde,KCt,e3t,o3t,XL,dPe,r3t,t3t,vde,a3t,n3t,s3t,zL,mPe,l3t,i3t,Fde,d3t,m3t,c3t,QL,cPe,f3t,g3t,Tde,h3t,u3t,p3t,WL,fPe,_3t,b3t,Mde,v3t,F3t,T3t,UL,_no,yf,HL,gPe,CB,M3t,hPe,E3t,bno,Pr,wB,C3t,xf,w3t,Ede,A3t,L3t,Cde,y3t,x3t,$3t,AB,k3t,uPe,S3t,R3t,P3t,Fa,LB,B3t,pPe,I3t,N3t,$f,q3t,_Pe,j3t,D3t,wde,G3t,O3t,V3t,JL,X3t,mt,yB,z3t,bPe,Q3t,W3t,ns,U3t,vPe,H3t,J3t,FPe,Y3t,Z3t,TPe,K3t,e5t,o5t,Qe,YL,MPe,r5t,t5t,Ade,a5t,n5t,s5t,ZL,EPe,l5t,i5t,Lde,d5t,m5t,c5t,KL,CPe,f5t,g5t,yde,h5t,u5t,p5t,ey,wPe,_5t,b5t,xde,v5t,F5t,T5t,oy,APe,M5t,E5t,$de,C5t,w5t,A5t,ry,LPe,L5t,y5t,kde,x5t,$5t,k5t,ty,yPe,S5t,R5t,Sde,P5t,B5t,I5t,ay,xPe,N5t,q5t,Rde,j5t,D5t,G5t,ny,vno,kf,sy,$Pe,xB,O5t,kPe,V5t,Fno,Br,$B,X5t,Sf,z5t,Pde,Q5t,W5t,Bde,U5t,H5t,J5t,kB,Y5t,SPe,Z5t,K5t,e0t,Ta,SB,o0t,RPe,r0t,t0t,Rf,a0t,PPe,n0t,s0t,Ide,l0t,i0t,d0t,ly,m0t,ct,RB,c0t,BPe,f0t,g0t,ss,h0t,IPe,u0t,p0t,NPe,_0t,b0t,qPe,v0t,F0t,T0t,jPe,iy,DPe,M0t,E0t,Nde,C0t,w0t,A0t,dy,Tno,Pf,my,GPe,PB,L0t,OPe,y0t,Mno,Ir,BB,x0t,Bf,$0t,qde,k0t,S0t,jde,R0t,P0t,B0t,IB,I0t,VPe,N0t,q0t,j0t,Ma,NB,D0t,XPe,G0t,O0t,If,V0t,zPe,X0t,z0t,Dde,Q0t,W0t,U0t,cy,H0t,ft,qB,J0t,QPe,Y0t,Z0t,ls,K0t,WPe,ewt,owt,UPe,rwt,twt,HPe,awt,nwt,swt,jB,fy,JPe,lwt,iwt,Gde,dwt,mwt,cwt,gy,YPe,fwt,gwt,Ode,hwt,uwt,pwt,hy,Eno,Nf,uy,ZPe,DB,_wt,KPe,bwt,Cno,Nr,GB,vwt,qf,Fwt,Vde,Twt,Mwt,Xde,Ewt,Cwt,wwt,OB,Awt,eBe,Lwt,ywt,xwt,Ea,VB,$wt,oBe,kwt,Swt,jf,Rwt,rBe,Pwt,Bwt,zde,Iwt,Nwt,qwt,py,jwt,gt,XB,Dwt,tBe,Gwt,Owt,is,Vwt,aBe,Xwt,zwt,nBe,Qwt,Wwt,sBe,Uwt,Hwt,Jwt,lBe,_y,iBe,Ywt,Zwt,Qde,Kwt,eAt,oAt,by,wno;return d=new oe({}),en=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),n$=new oe({}),s$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Uf=new rAt({props:{warning:!0,$$slots:{default:[PCa]},$$scope:{ctx:$}}}),l$=new oe({}),i$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L662"}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L685"}}),Mu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[BCa]},$$scope:{ctx:$}}}),f$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L808"}}),g$=new oe({}),h$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L430"}}),_$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L444"}}),lp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[ICa]},$$scope:{ctx:$}}}),b$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L645"}}),v$=new oe({}),F$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L203"}}),E$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L217"}}),Kp=new rAt({props:{$$slots:{default:[NCa]},$$scope:{ctx:$}}}),e_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[qCa]},$$scope:{ctx:$}}}),C$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L344"}}),w$=new oe({}),A$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),x$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),A_=new rAt({props:{$$slots:{default:[jCa]},$$scope:{ctx:$}}}),L_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[DCa]},$$scope:{ctx:$}}}),$$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L885"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[GCa]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Y2=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[OCa]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L892"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K2=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[VCa]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Hb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[XCa]},$$scope:{ctx:$}}}),G$=new oe({}),O$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L907"}}),X$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Yb=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[zCa]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Gv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[QCa]},$$scope:{ctx:$}}}),Q$=new oe({}),W$=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1050"}}),H$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Vv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[WCa]},$$scope:{ctx:$}}}),J$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Wv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[UCa]},$$scope:{ctx:$}}}),Z$=new oe({}),K$=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L914"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Hv=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[HCa]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),IF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[JCa]},$$scope:{ctx:$}}}),tk=new oe({}),ak=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L921"}}),sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),qF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[YCa]},$$scope:{ctx:$}}}),lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[ZCa]},$$scope:{ctx:$}}}),ik=new oe({}),dk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L930"}}),ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),iT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[KCa]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[e3a]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L986"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[o3a]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[r3a]},$$scope:{ctx:$}}}),bk=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L993"}}),Tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JM=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[t3a]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[a3a]},$$scope:{ctx:$}}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L979"}}),Ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[n3a]},$$scope:{ctx:$}}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),JE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[s3a]},$$scope:{ctx:$}}}),yk=new oe({}),xk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L939"}}),kk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ZE=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[l3a]},$$scope:{ctx:$}}}),Sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),U4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[i3a]},$$scope:{ctx:$}}}),Rk=new oe({}),Pk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L946"}}),Ik=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[d3a]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),K4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[m3a]},$$scope:{ctx:$}}}),qk=new oe({}),jk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L968"}}),Gk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[c3a]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[f3a]},$$scope:{ctx:$}}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1002"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),iC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[g3a]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[h3a]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1057"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[u3a]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[p3a]},$$scope:{ctx:$}}}),Kk=new oe({}),eS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1064"}}),rS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[_3a]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),BC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[b3a]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L957"}}),lS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),NC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[v3a]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),DC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[F3a]},$$scope:{ctx:$}}}),dS=new oe({}),mS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1071"}}),fS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),OC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[T3a]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[M3a]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1094"}}),_S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[E3a]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[C3a]},$$scope:{ctx:$}}}),vS=new oe({}),FS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1078"}}),MS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[w3a]},$$scope:{ctx:$}}}),ES=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M3=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[A3a]},$$scope:{ctx:$}}}),CS=new oe({}),wS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1085"}}),LS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[L3a]},$$scope:{ctx:$}}}),yS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[y3a]},$$scope:{ctx:$}}}),xS=new oe({}),$S=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1103"}}),SS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[x3a]},$$scope:{ctx:$}}}),RS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[$3a]},$$scope:{ctx:$}}}),PS=new oe({}),BS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1110"}}),NS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[k3a]},$$scope:{ctx:$}}}),qS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[S3a]},$$scope:{ctx:$}}}),jS=new oe({}),DS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1034"}}),OS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),U3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[R3a]},$$scope:{ctx:$}}}),VS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[P3a]},$$scope:{ctx:$}}}),XS=new oe({}),zS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1009"}}),WS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[B3a]},$$scope:{ctx:$}}}),US=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[I3a]},$$scope:{ctx:$}}}),HS=new oe({}),JS=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1016"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[N3a]},$$scope:{ctx:$}}}),KS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),h5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[q3a]},$$scope:{ctx:$}}}),eR=new oe({}),oR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1025"}}),tR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),p5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[j3a]},$$scope:{ctx:$}}}),aR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[D3a]},$$scope:{ctx:$}}}),nR=new oe({}),sR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1041"}}),iR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[G3a]},$$scope:{ctx:$}}}),dR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[O3a]},$$scope:{ctx:$}}}),mR=new oe({}),cR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),gR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A5=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[V3a]},$$scope:{ctx:$}}}),hR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$0=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[X3a]},$$scope:{ctx:$}}}),uR=new oe({}),pR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),bR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[z3a]},$$scope:{ctx:$}}}),vR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),rw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Q3a]},$$scope:{ctx:$}}}),FR=new oe({}),TR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),ER=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),aw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[W3a]},$$scope:{ctx:$}}}),CR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[U3a]},$$scope:{ctx:$}}}),wR=new oe({}),AR=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),yR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Tw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[H3a]},$$scope:{ctx:$}}}),xR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),kw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[J3a]},$$scope:{ctx:$}}}),$R=new oe({}),kR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),RR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Rw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Y3a]},$$scope:{ctx:$}}}),PR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Nw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Z3a]},$$scope:{ctx:$}}}),BR=new oe({}),IR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),qR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[K3a]},$$scope:{ctx:$}}}),jR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),lA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[e5a]},$$scope:{ctx:$}}}),DR=new oe({}),GR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),VR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[o5a]},$$scope:{ctx:$}}}),XR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[r5a]},$$scope:{ctx:$}}}),zR=new oe({}),QR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),UR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),MA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[t5a]},$$scope:{ctx:$}}}),HR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[a5a]},$$scope:{ctx:$}}}),JR=new oe({}),YR=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),KR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),KA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[n5a]},$$scope:{ctx:$}}}),eP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[s5a]},$$scope:{ctx:$}}}),oP=new oe({}),rP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),aP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[l5a]},$$scope:{ctx:$}}}),nP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[i5a]},$$scope:{ctx:$}}}),lP=new oe({}),iP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),mP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[d5a]},$$scope:{ctx:$}}}),cP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[m5a]},$$scope:{ctx:$}}}),fP=new oe({}),gP=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),uP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[c5a]},$$scope:{ctx:$}}}),pP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[f5a]},$$scope:{ctx:$}}}),_P=new oe({}),bP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),FP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[g5a]},$$scope:{ctx:$}}}),TP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[h5a]},$$scope:{ctx:$}}}),MP=new oe({}),EP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),wP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[u5a]},$$scope:{ctx:$}}}),AP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[p5a]},$$scope:{ctx:$}}}),LP=new oe({}),yP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),$P=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),L7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[_5a]},$$scope:{ctx:$}}}),kP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[b5a]},$$scope:{ctx:$}}}),SP=new oe({}),RP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),BP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[v5a]},$$scope:{ctx:$}}}),IP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[F5a]},$$scope:{ctx:$}}}),qP=new oe({}),jP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),GP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[T5a]},$$scope:{ctx:$}}}),OP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m8=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[M5a]},$$scope:{ctx:$}}}),VP=new oe({}),XP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),QP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[E5a]},$$scope:{ctx:$}}}),WP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[C5a]},$$scope:{ctx:$}}}),UP=new oe({}),HP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),YP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[w5a]},$$scope:{ctx:$}}}),ZP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[A5a]},$$scope:{ctx:$}}}),KP=new oe({}),eB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),rB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[L5a]},$$scope:{ctx:$}}}),tB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[y5a]},$$scope:{ctx:$}}}),aB=new oe({}),nB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),lB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[x5a]},$$scope:{ctx:$}}}),iB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[$5a]},$$scope:{ctx:$}}}),dB=new oe({}),mB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),fB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[k5a]},$$scope:{ctx:$}}}),gB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),CL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[S5a]},$$scope:{ctx:$}}}),hB=new oe({}),uB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),_B=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),AL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[R5a]},$$scope:{ctx:$}}}),bB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[P5a]},$$scope:{ctx:$}}}),vB=new oe({}),FB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),MB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[B5a]},$$scope:{ctx:$}}}),EB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[I5a]},$$scope:{ctx:$}}}),CB=new oe({}),wB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),LB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JL=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[N5a]},$$scope:{ctx:$}}}),yB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ny=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[q5a]},$$scope:{ctx:$}}}),xB=new oe({}),$B=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),SB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ly=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[j5a]},$$scope:{ctx:$}}}),RB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[D5a]},$$scope:{ctx:$}}}),PB=new oe({}),BB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),NB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[G5a]},$$scope:{ctx:$}}}),qB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[O5a]},$$scope:{ctx:$}}}),DB=new oe({}),GB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),VB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),py=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[V5a]},$$scope:{ctx:$}}}),XB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),by=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[X5a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),pd=o("Auto Classes"),Vf=l(),Ft=a("p"),_d=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),bd=a("code"),o$=o("from_pretrained()"),Xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),vd=o("Instantiating one of "),ms=a("a"),r$=o("AutoConfig"),cs=o(", "),fs=a("a"),t$=o("AutoModel"),Fd=o(`, and
`),gs=a("a"),a$=o("AutoTokenizer"),Td=o(" will directly create a class of the relevant architecture. For instance"),zf=l(),F(en.$$.fragment),Je=l(),Ae=a("p"),_N=o("will create a model that is an instance of "),Md=a("a"),bN=o("BertModel"),vN=o("."),ko=l(),on=a("p"),FN=o("There is one class of "),Qf=a("code"),TN=o("AutoModel"),Wlo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ito=l(),Ed=a("h2"),Wf=a("a"),ofe=a("span"),F(n$.$$.fragment),Ulo=l(),rfe=a("span"),Hlo=o("Extending the Auto Classes"),dto=l(),hs=a("p"),Jlo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),tfe=a("code"),Ylo=o("NewModel"),Zlo=o(", make sure you have a "),afe=a("code"),Klo=o("NewModelConfig"),eio=o(` then you can add those to the auto
classes like this:`),mto=l(),F(s$.$$.fragment),cto=l(),MN=a("p"),oio=o("You will then be able to use the auto classes like you would usually do!"),fto=l(),F(Uf.$$.fragment),gto=l(),Cd=a("h2"),Hf=a("a"),nfe=a("span"),F(l$.$$.fragment),rio=l(),sfe=a("span"),tio=o("AutoConfig"),hto=l(),So=a("div"),F(i$.$$.fragment),aio=l(),d$=a("p"),nio=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),EN=a("a"),sio=o("from_pretrained()"),lio=o(" class method."),iio=l(),m$=a("p"),dio=o("This class cannot be instantiated directly using "),lfe=a("code"),mio=o("__init__()"),cio=o(" (throws an error)."),fio=l(),qr=a("div"),F(c$.$$.fragment),gio=l(),ife=a("p"),hio=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),uio=l(),wd=a("p"),pio=o("The configuration class to instantiate is selected based on the "),dfe=a("code"),_io=o("model_type"),bio=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),mfe=a("code"),vio=o("pretrained_model_name_or_path"),Fio=o(":"),Tio=l(),A=a("ul"),Jf=a("li"),cfe=a("strong"),Mio=o("albert"),Eio=o(" \u2014 "),CN=a("a"),Cio=o("AlbertConfig"),wio=o(" (ALBERT model)"),Aio=l(),Yf=a("li"),ffe=a("strong"),Lio=o("bart"),yio=o(" \u2014 "),wN=a("a"),xio=o("BartConfig"),$io=o(" (BART model)"),kio=l(),Zf=a("li"),gfe=a("strong"),Sio=o("beit"),Rio=o(" \u2014 "),AN=a("a"),Pio=o("BeitConfig"),Bio=o(" (BEiT model)"),Iio=l(),Kf=a("li"),hfe=a("strong"),Nio=o("bert"),qio=o(" \u2014 "),LN=a("a"),jio=o("BertConfig"),Dio=o(" (BERT model)"),Gio=l(),eg=a("li"),ufe=a("strong"),Oio=o("bert-generation"),Vio=o(" \u2014 "),yN=a("a"),Xio=o("BertGenerationConfig"),zio=o(" (Bert Generation model)"),Qio=l(),og=a("li"),pfe=a("strong"),Wio=o("big_bird"),Uio=o(" \u2014 "),xN=a("a"),Hio=o("BigBirdConfig"),Jio=o(" (BigBird model)"),Yio=l(),rg=a("li"),_fe=a("strong"),Zio=o("bigbird_pegasus"),Kio=o(" \u2014 "),$N=a("a"),edo=o("BigBirdPegasusConfig"),odo=o(" (BigBird-Pegasus model)"),rdo=l(),tg=a("li"),bfe=a("strong"),tdo=o("blenderbot"),ado=o(" \u2014 "),kN=a("a"),ndo=o("BlenderbotConfig"),sdo=o(" (Blenderbot model)"),ldo=l(),ag=a("li"),vfe=a("strong"),ido=o("blenderbot-small"),ddo=o(" \u2014 "),SN=a("a"),mdo=o("BlenderbotSmallConfig"),cdo=o(" (BlenderbotSmall model)"),fdo=l(),ng=a("li"),Ffe=a("strong"),gdo=o("bloom"),hdo=o(" \u2014 "),RN=a("a"),udo=o("BloomConfig"),pdo=o(" (BLOOM model)"),_do=l(),sg=a("li"),Tfe=a("strong"),bdo=o("camembert"),vdo=o(" \u2014 "),PN=a("a"),Fdo=o("CamembertConfig"),Tdo=o(" (CamemBERT model)"),Mdo=l(),lg=a("li"),Mfe=a("strong"),Edo=o("canine"),Cdo=o(" \u2014 "),BN=a("a"),wdo=o("CanineConfig"),Ado=o(" (CANINE model)"),Ldo=l(),ig=a("li"),Efe=a("strong"),ydo=o("clip"),xdo=o(" \u2014 "),IN=a("a"),$do=o("CLIPConfig"),kdo=o(" (CLIP model)"),Sdo=l(),dg=a("li"),Cfe=a("strong"),Rdo=o("codegen"),Pdo=o(" \u2014 "),NN=a("a"),Bdo=o("CodeGenConfig"),Ido=o(" (CodeGen model)"),Ndo=l(),mg=a("li"),wfe=a("strong"),qdo=o("conditional_detr"),jdo=o(" \u2014 "),qN=a("a"),Ddo=o("ConditionalDetrConfig"),Gdo=o(" (Conditional DETR model)"),Odo=l(),cg=a("li"),Afe=a("strong"),Vdo=o("convbert"),Xdo=o(" \u2014 "),jN=a("a"),zdo=o("ConvBertConfig"),Qdo=o(" (ConvBERT model)"),Wdo=l(),fg=a("li"),Lfe=a("strong"),Udo=o("convnext"),Hdo=o(" \u2014 "),DN=a("a"),Jdo=o("ConvNextConfig"),Ydo=o(" (ConvNeXT model)"),Zdo=l(),gg=a("li"),yfe=a("strong"),Kdo=o("ctrl"),emo=o(" \u2014 "),GN=a("a"),omo=o("CTRLConfig"),rmo=o(" (CTRL model)"),tmo=l(),hg=a("li"),xfe=a("strong"),amo=o("cvt"),nmo=o(" \u2014 "),ON=a("a"),smo=o("CvtConfig"),lmo=o(" (CvT model)"),imo=l(),ug=a("li"),$fe=a("strong"),dmo=o("data2vec-audio"),mmo=o(" \u2014 "),VN=a("a"),cmo=o("Data2VecAudioConfig"),fmo=o(" (Data2VecAudio model)"),gmo=l(),pg=a("li"),kfe=a("strong"),hmo=o("data2vec-text"),umo=o(" \u2014 "),XN=a("a"),pmo=o("Data2VecTextConfig"),_mo=o(" (Data2VecText model)"),bmo=l(),_g=a("li"),Sfe=a("strong"),vmo=o("data2vec-vision"),Fmo=o(" \u2014 "),zN=a("a"),Tmo=o("Data2VecVisionConfig"),Mmo=o(" (Data2VecVision model)"),Emo=l(),bg=a("li"),Rfe=a("strong"),Cmo=o("deberta"),wmo=o(" \u2014 "),QN=a("a"),Amo=o("DebertaConfig"),Lmo=o(" (DeBERTa model)"),ymo=l(),vg=a("li"),Pfe=a("strong"),xmo=o("deberta-v2"),$mo=o(" \u2014 "),WN=a("a"),kmo=o("DebertaV2Config"),Smo=o(" (DeBERTa-v2 model)"),Rmo=l(),Fg=a("li"),Bfe=a("strong"),Pmo=o("decision_transformer"),Bmo=o(" \u2014 "),UN=a("a"),Imo=o("DecisionTransformerConfig"),Nmo=o(" (Decision Transformer model)"),qmo=l(),Tg=a("li"),Ife=a("strong"),jmo=o("deformable_detr"),Dmo=o(" \u2014 "),HN=a("a"),Gmo=o("DeformableDetrConfig"),Omo=o(" (Deformable DETR model)"),Vmo=l(),Mg=a("li"),Nfe=a("strong"),Xmo=o("deit"),zmo=o(" \u2014 "),JN=a("a"),Qmo=o("DeiTConfig"),Wmo=o(" (DeiT model)"),Umo=l(),Eg=a("li"),qfe=a("strong"),Hmo=o("detr"),Jmo=o(" \u2014 "),YN=a("a"),Ymo=o("DetrConfig"),Zmo=o(" (DETR model)"),Kmo=l(),Cg=a("li"),jfe=a("strong"),eco=o("distilbert"),oco=o(" \u2014 "),ZN=a("a"),rco=o("DistilBertConfig"),tco=o(" (DistilBERT model)"),aco=l(),wg=a("li"),Dfe=a("strong"),nco=o("donut-swin"),sco=o(" \u2014 "),KN=a("a"),lco=o("DonutSwinConfig"),ico=o(" (DonutSwin model)"),dco=l(),Ag=a("li"),Gfe=a("strong"),mco=o("dpr"),cco=o(" \u2014 "),eq=a("a"),fco=o("DPRConfig"),gco=o(" (DPR model)"),hco=l(),Lg=a("li"),Ofe=a("strong"),uco=o("dpt"),pco=o(" \u2014 "),oq=a("a"),_co=o("DPTConfig"),bco=o(" (DPT model)"),vco=l(),yg=a("li"),Vfe=a("strong"),Fco=o("electra"),Tco=o(" \u2014 "),rq=a("a"),Mco=o("ElectraConfig"),Eco=o(" (ELECTRA model)"),Cco=l(),xg=a("li"),Xfe=a("strong"),wco=o("encoder-decoder"),Aco=o(" \u2014 "),tq=a("a"),Lco=o("EncoderDecoderConfig"),yco=o(" (Encoder decoder model)"),xco=l(),$g=a("li"),zfe=a("strong"),$co=o("ernie"),kco=o(" \u2014 "),aq=a("a"),Sco=o("ErnieConfig"),Rco=o(" (ERNIE model)"),Pco=l(),kg=a("li"),Qfe=a("strong"),Bco=o("esm"),Ico=o(" \u2014 "),nq=a("a"),Nco=o("EsmConfig"),qco=o(" (ESM model)"),jco=l(),Sg=a("li"),Wfe=a("strong"),Dco=o("flaubert"),Gco=o(" \u2014 "),sq=a("a"),Oco=o("FlaubertConfig"),Vco=o(" (FlauBERT model)"),Xco=l(),Rg=a("li"),Ufe=a("strong"),zco=o("flava"),Qco=o(" \u2014 "),lq=a("a"),Wco=o("FlavaConfig"),Uco=o(" (FLAVA model)"),Hco=l(),Pg=a("li"),Hfe=a("strong"),Jco=o("fnet"),Yco=o(" \u2014 "),iq=a("a"),Zco=o("FNetConfig"),Kco=o(" (FNet model)"),efo=l(),Bg=a("li"),Jfe=a("strong"),ofo=o("fsmt"),rfo=o(" \u2014 "),dq=a("a"),tfo=o("FSMTConfig"),afo=o(" (FairSeq Machine-Translation model)"),nfo=l(),Ig=a("li"),Yfe=a("strong"),sfo=o("funnel"),lfo=o(" \u2014 "),mq=a("a"),ifo=o("FunnelConfig"),dfo=o(" (Funnel Transformer model)"),mfo=l(),Ng=a("li"),Zfe=a("strong"),cfo=o("glpn"),ffo=o(" \u2014 "),cq=a("a"),gfo=o("GLPNConfig"),hfo=o(" (GLPN model)"),ufo=l(),qg=a("li"),Kfe=a("strong"),pfo=o("gpt2"),_fo=o(" \u2014 "),fq=a("a"),bfo=o("GPT2Config"),vfo=o(" (OpenAI GPT-2 model)"),Ffo=l(),jg=a("li"),ege=a("strong"),Tfo=o("gpt_neo"),Mfo=o(" \u2014 "),gq=a("a"),Efo=o("GPTNeoConfig"),Cfo=o(" (GPT Neo model)"),wfo=l(),Dg=a("li"),oge=a("strong"),Afo=o("gpt_neox"),Lfo=o(" \u2014 "),hq=a("a"),yfo=o("GPTNeoXConfig"),xfo=o(" (GPT NeoX model)"),$fo=l(),Gg=a("li"),rge=a("strong"),kfo=o("gpt_neox_japanese"),Sfo=o(" \u2014 "),uq=a("a"),Rfo=o("GPTNeoXJapaneseConfig"),Pfo=o(" (GPT NeoX Japanese model)"),Bfo=l(),Og=a("li"),tge=a("strong"),Ifo=o("gptj"),Nfo=o(" \u2014 "),pq=a("a"),qfo=o("GPTJConfig"),jfo=o(" (GPT-J model)"),Dfo=l(),Vg=a("li"),age=a("strong"),Gfo=o("groupvit"),Ofo=o(" \u2014 "),_q=a("a"),Vfo=o("GroupViTConfig"),Xfo=o(" (GroupViT model)"),zfo=l(),Xg=a("li"),nge=a("strong"),Qfo=o("hubert"),Wfo=o(" \u2014 "),bq=a("a"),Ufo=o("HubertConfig"),Hfo=o(" (Hubert model)"),Jfo=l(),zg=a("li"),sge=a("strong"),Yfo=o("ibert"),Zfo=o(" \u2014 "),vq=a("a"),Kfo=o("IBertConfig"),ego=o(" (I-BERT model)"),ogo=l(),Qg=a("li"),lge=a("strong"),rgo=o("imagegpt"),tgo=o(" \u2014 "),Fq=a("a"),ago=o("ImageGPTConfig"),ngo=o(" (ImageGPT model)"),sgo=l(),Wg=a("li"),ige=a("strong"),lgo=o("layoutlm"),igo=o(" \u2014 "),Tq=a("a"),dgo=o("LayoutLMConfig"),mgo=o(" (LayoutLM model)"),cgo=l(),Ug=a("li"),dge=a("strong"),fgo=o("layoutlmv2"),ggo=o(" \u2014 "),Mq=a("a"),hgo=o("LayoutLMv2Config"),ugo=o(" (LayoutLMv2 model)"),pgo=l(),Hg=a("li"),mge=a("strong"),_go=o("layoutlmv3"),bgo=o(" \u2014 "),Eq=a("a"),vgo=o("LayoutLMv3Config"),Fgo=o(" (LayoutLMv3 model)"),Tgo=l(),Jg=a("li"),cge=a("strong"),Mgo=o("led"),Ego=o(" \u2014 "),Cq=a("a"),Cgo=o("LEDConfig"),wgo=o(" (LED model)"),Ago=l(),Yg=a("li"),fge=a("strong"),Lgo=o("levit"),ygo=o(" \u2014 "),wq=a("a"),xgo=o("LevitConfig"),$go=o(" (LeViT model)"),kgo=l(),Zg=a("li"),gge=a("strong"),Sgo=o("lilt"),Rgo=o(" \u2014 "),Aq=a("a"),Pgo=o("LiltConfig"),Bgo=o(" (LiLT model)"),Igo=l(),Kg=a("li"),hge=a("strong"),Ngo=o("longformer"),qgo=o(" \u2014 "),Lq=a("a"),jgo=o("LongformerConfig"),Dgo=o(" (Longformer model)"),Ggo=l(),eh=a("li"),uge=a("strong"),Ogo=o("longt5"),Vgo=o(" \u2014 "),yq=a("a"),Xgo=o("LongT5Config"),zgo=o(" (LongT5 model)"),Qgo=l(),oh=a("li"),pge=a("strong"),Wgo=o("luke"),Ugo=o(" \u2014 "),xq=a("a"),Hgo=o("LukeConfig"),Jgo=o(" (LUKE model)"),Ygo=l(),rh=a("li"),_ge=a("strong"),Zgo=o("lxmert"),Kgo=o(" \u2014 "),$q=a("a"),eho=o("LxmertConfig"),oho=o(" (LXMERT model)"),rho=l(),th=a("li"),bge=a("strong"),tho=o("m2m_100"),aho=o(" \u2014 "),kq=a("a"),nho=o("M2M100Config"),sho=o(" (M2M100 model)"),lho=l(),ah=a("li"),vge=a("strong"),iho=o("marian"),dho=o(" \u2014 "),Sq=a("a"),mho=o("MarianConfig"),cho=o(" (Marian model)"),fho=l(),nh=a("li"),Fge=a("strong"),gho=o("markuplm"),hho=o(" \u2014 "),Rq=a("a"),uho=o("MarkupLMConfig"),pho=o(" (MarkupLM model)"),_ho=l(),sh=a("li"),Tge=a("strong"),bho=o("maskformer"),vho=o(" \u2014 "),Pq=a("a"),Fho=o("MaskFormerConfig"),Tho=o(" (MaskFormer model)"),Mho=l(),lh=a("li"),Mge=a("strong"),Eho=o("mbart"),Cho=o(" \u2014 "),Bq=a("a"),who=o("MBartConfig"),Aho=o(" (mBART model)"),Lho=l(),ih=a("li"),Ege=a("strong"),yho=o("mctct"),xho=o(" \u2014 "),Iq=a("a"),$ho=o("MCTCTConfig"),kho=o(" (M-CTC-T model)"),Sho=l(),dh=a("li"),Cge=a("strong"),Rho=o("megatron-bert"),Pho=o(" \u2014 "),Nq=a("a"),Bho=o("MegatronBertConfig"),Iho=o(" (Megatron-BERT model)"),Nho=l(),mh=a("li"),wge=a("strong"),qho=o("mobilebert"),jho=o(" \u2014 "),qq=a("a"),Dho=o("MobileBertConfig"),Gho=o(" (MobileBERT model)"),Oho=l(),ch=a("li"),Age=a("strong"),Vho=o("mobilevit"),Xho=o(" \u2014 "),jq=a("a"),zho=o("MobileViTConfig"),Qho=o(" (MobileViT model)"),Who=l(),fh=a("li"),Lge=a("strong"),Uho=o("mpnet"),Hho=o(" \u2014 "),Dq=a("a"),Jho=o("MPNetConfig"),Yho=o(" (MPNet model)"),Zho=l(),gh=a("li"),yge=a("strong"),Kho=o("mt5"),euo=o(" \u2014 "),Gq=a("a"),ouo=o("MT5Config"),ruo=o(" (MT5 model)"),tuo=l(),hh=a("li"),xge=a("strong"),auo=o("mvp"),nuo=o(" \u2014 "),Oq=a("a"),suo=o("MvpConfig"),luo=o(" (MVP model)"),iuo=l(),uh=a("li"),$ge=a("strong"),duo=o("nezha"),muo=o(" \u2014 "),Vq=a("a"),cuo=o("NezhaConfig"),fuo=o(" (Nezha model)"),guo=l(),ph=a("li"),kge=a("strong"),huo=o("nystromformer"),uuo=o(" \u2014 "),Xq=a("a"),puo=o("NystromformerConfig"),_uo=o(" (Nystr\xF6mformer model)"),buo=l(),_h=a("li"),Sge=a("strong"),vuo=o("openai-gpt"),Fuo=o(" \u2014 "),zq=a("a"),Tuo=o("OpenAIGPTConfig"),Muo=o(" (OpenAI GPT model)"),Euo=l(),bh=a("li"),Rge=a("strong"),Cuo=o("opt"),wuo=o(" \u2014 "),Qq=a("a"),Auo=o("OPTConfig"),Luo=o(" (OPT model)"),yuo=l(),vh=a("li"),Pge=a("strong"),xuo=o("owlvit"),$uo=o(" \u2014 "),Wq=a("a"),kuo=o("OwlViTConfig"),Suo=o(" (OWL-ViT model)"),Ruo=l(),Fh=a("li"),Bge=a("strong"),Puo=o("pegasus"),Buo=o(" \u2014 "),Uq=a("a"),Iuo=o("PegasusConfig"),Nuo=o(" (Pegasus model)"),quo=l(),Th=a("li"),Ige=a("strong"),juo=o("pegasus_x"),Duo=o(" \u2014 "),Hq=a("a"),Guo=o("PegasusXConfig"),Ouo=o(" (PEGASUS-X model)"),Vuo=l(),Mh=a("li"),Nge=a("strong"),Xuo=o("perceiver"),zuo=o(" \u2014 "),Jq=a("a"),Quo=o("PerceiverConfig"),Wuo=o(" (Perceiver model)"),Uuo=l(),Eh=a("li"),qge=a("strong"),Huo=o("plbart"),Juo=o(" \u2014 "),Yq=a("a"),Yuo=o("PLBartConfig"),Zuo=o(" (PLBart model)"),Kuo=l(),Ch=a("li"),jge=a("strong"),epo=o("poolformer"),opo=o(" \u2014 "),Zq=a("a"),rpo=o("PoolFormerConfig"),tpo=o(" (PoolFormer model)"),apo=l(),wh=a("li"),Dge=a("strong"),npo=o("prophetnet"),spo=o(" \u2014 "),Kq=a("a"),lpo=o("ProphetNetConfig"),ipo=o(" (ProphetNet model)"),dpo=l(),Ah=a("li"),Gge=a("strong"),mpo=o("qdqbert"),cpo=o(" \u2014 "),ej=a("a"),fpo=o("QDQBertConfig"),gpo=o(" (QDQBert model)"),hpo=l(),Lh=a("li"),Oge=a("strong"),upo=o("rag"),ppo=o(" \u2014 "),oj=a("a"),_po=o("RagConfig"),bpo=o(" (RAG model)"),vpo=l(),yh=a("li"),Vge=a("strong"),Fpo=o("realm"),Tpo=o(" \u2014 "),rj=a("a"),Mpo=o("RealmConfig"),Epo=o(" (REALM model)"),Cpo=l(),xh=a("li"),Xge=a("strong"),wpo=o("reformer"),Apo=o(" \u2014 "),tj=a("a"),Lpo=o("ReformerConfig"),ypo=o(" (Reformer model)"),xpo=l(),$h=a("li"),zge=a("strong"),$po=o("regnet"),kpo=o(" \u2014 "),aj=a("a"),Spo=o("RegNetConfig"),Rpo=o(" (RegNet model)"),Ppo=l(),kh=a("li"),Qge=a("strong"),Bpo=o("rembert"),Ipo=o(" \u2014 "),nj=a("a"),Npo=o("RemBertConfig"),qpo=o(" (RemBERT model)"),jpo=l(),Sh=a("li"),Wge=a("strong"),Dpo=o("resnet"),Gpo=o(" \u2014 "),sj=a("a"),Opo=o("ResNetConfig"),Vpo=o(" (ResNet model)"),Xpo=l(),Rh=a("li"),Uge=a("strong"),zpo=o("retribert"),Qpo=o(" \u2014 "),lj=a("a"),Wpo=o("RetriBertConfig"),Upo=o(" (RetriBERT model)"),Hpo=l(),Ph=a("li"),Hge=a("strong"),Jpo=o("roberta"),Ypo=o(" \u2014 "),ij=a("a"),Zpo=o("RobertaConfig"),Kpo=o(" (RoBERTa model)"),e_o=l(),Bh=a("li"),Jge=a("strong"),o_o=o("roformer"),r_o=o(" \u2014 "),dj=a("a"),t_o=o("RoFormerConfig"),a_o=o(" (RoFormer model)"),n_o=l(),Ih=a("li"),Yge=a("strong"),s_o=o("segformer"),l_o=o(" \u2014 "),mj=a("a"),i_o=o("SegformerConfig"),d_o=o(" (SegFormer model)"),m_o=l(),Nh=a("li"),Zge=a("strong"),c_o=o("sew"),f_o=o(" \u2014 "),cj=a("a"),g_o=o("SEWConfig"),h_o=o(" (SEW model)"),u_o=l(),qh=a("li"),Kge=a("strong"),p_o=o("sew-d"),__o=o(" \u2014 "),fj=a("a"),b_o=o("SEWDConfig"),v_o=o(" (SEW-D model)"),F_o=l(),jh=a("li"),ehe=a("strong"),T_o=o("speech-encoder-decoder"),M_o=o(" \u2014 "),gj=a("a"),E_o=o("SpeechEncoderDecoderConfig"),C_o=o(" (Speech Encoder decoder model)"),w_o=l(),Dh=a("li"),ohe=a("strong"),A_o=o("speech_to_text"),L_o=o(" \u2014 "),hj=a("a"),y_o=o("Speech2TextConfig"),x_o=o(" (Speech2Text model)"),$_o=l(),Gh=a("li"),rhe=a("strong"),k_o=o("speech_to_text_2"),S_o=o(" \u2014 "),uj=a("a"),R_o=o("Speech2Text2Config"),P_o=o(" (Speech2Text2 model)"),B_o=l(),Oh=a("li"),the=a("strong"),I_o=o("splinter"),N_o=o(" \u2014 "),pj=a("a"),q_o=o("SplinterConfig"),j_o=o(" (Splinter model)"),D_o=l(),Vh=a("li"),ahe=a("strong"),G_o=o("squeezebert"),O_o=o(" \u2014 "),_j=a("a"),V_o=o("SqueezeBertConfig"),X_o=o(" (SqueezeBERT model)"),z_o=l(),Xh=a("li"),nhe=a("strong"),Q_o=o("swin"),W_o=o(" \u2014 "),bj=a("a"),U_o=o("SwinConfig"),H_o=o(" (Swin Transformer model)"),J_o=l(),zh=a("li"),she=a("strong"),Y_o=o("swinv2"),Z_o=o(" \u2014 "),vj=a("a"),K_o=o("Swinv2Config"),e1o=o(" (Swin Transformer V2 model)"),o1o=l(),Qh=a("li"),lhe=a("strong"),r1o=o("t5"),t1o=o(" \u2014 "),Fj=a("a"),a1o=o("T5Config"),n1o=o(" (T5 model)"),s1o=l(),Wh=a("li"),ihe=a("strong"),l1o=o("tapas"),i1o=o(" \u2014 "),Tj=a("a"),d1o=o("TapasConfig"),m1o=o(" (TAPAS model)"),c1o=l(),Uh=a("li"),dhe=a("strong"),f1o=o("time_series_transformer"),g1o=o(" \u2014 "),Mj=a("a"),h1o=o("TimeSeriesTransformerConfig"),u1o=o(" (Time Series Transformer model)"),p1o=l(),Hh=a("li"),mhe=a("strong"),_1o=o("trajectory_transformer"),b1o=o(" \u2014 "),Ej=a("a"),v1o=o("TrajectoryTransformerConfig"),F1o=o(" (Trajectory Transformer model)"),T1o=l(),Jh=a("li"),che=a("strong"),M1o=o("transfo-xl"),E1o=o(" \u2014 "),Cj=a("a"),C1o=o("TransfoXLConfig"),w1o=o(" (Transformer-XL model)"),A1o=l(),Yh=a("li"),fhe=a("strong"),L1o=o("trocr"),y1o=o(" \u2014 "),wj=a("a"),x1o=o("TrOCRConfig"),$1o=o(" (TrOCR model)"),k1o=l(),Zh=a("li"),ghe=a("strong"),S1o=o("unispeech"),R1o=o(" \u2014 "),Aj=a("a"),P1o=o("UniSpeechConfig"),B1o=o(" (UniSpeech model)"),I1o=l(),Kh=a("li"),hhe=a("strong"),N1o=o("unispeech-sat"),q1o=o(" \u2014 "),Lj=a("a"),j1o=o("UniSpeechSatConfig"),D1o=o(" (UniSpeechSat model)"),G1o=l(),eu=a("li"),uhe=a("strong"),O1o=o("van"),V1o=o(" \u2014 "),yj=a("a"),X1o=o("VanConfig"),z1o=o(" (VAN model)"),Q1o=l(),ou=a("li"),phe=a("strong"),W1o=o("videomae"),U1o=o(" \u2014 "),xj=a("a"),H1o=o("VideoMAEConfig"),J1o=o(" (VideoMAE model)"),Y1o=l(),ru=a("li"),_he=a("strong"),Z1o=o("vilt"),K1o=o(" \u2014 "),$j=a("a"),e2o=o("ViltConfig"),o2o=o(" (ViLT model)"),r2o=l(),tu=a("li"),bhe=a("strong"),t2o=o("vision-encoder-decoder"),a2o=o(" \u2014 "),kj=a("a"),n2o=o("VisionEncoderDecoderConfig"),s2o=o(" (Vision Encoder decoder model)"),l2o=l(),au=a("li"),vhe=a("strong"),i2o=o("vision-text-dual-encoder"),d2o=o(" \u2014 "),Sj=a("a"),m2o=o("VisionTextDualEncoderConfig"),c2o=o(" (VisionTextDualEncoder model)"),f2o=l(),nu=a("li"),Fhe=a("strong"),g2o=o("visual_bert"),h2o=o(" \u2014 "),Rj=a("a"),u2o=o("VisualBertConfig"),p2o=o(" (VisualBERT model)"),_2o=l(),su=a("li"),The=a("strong"),b2o=o("vit"),v2o=o(" \u2014 "),Pj=a("a"),F2o=o("ViTConfig"),T2o=o(" (ViT model)"),M2o=l(),lu=a("li"),Mhe=a("strong"),E2o=o("vit_mae"),C2o=o(" \u2014 "),Bj=a("a"),w2o=o("ViTMAEConfig"),A2o=o(" (ViTMAE model)"),L2o=l(),iu=a("li"),Ehe=a("strong"),y2o=o("vit_msn"),x2o=o(" \u2014 "),Ij=a("a"),$2o=o("ViTMSNConfig"),k2o=o(" (ViTMSN model)"),S2o=l(),du=a("li"),Che=a("strong"),R2o=o("wav2vec2"),P2o=o(" \u2014 "),Nj=a("a"),B2o=o("Wav2Vec2Config"),I2o=o(" (Wav2Vec2 model)"),N2o=l(),mu=a("li"),whe=a("strong"),q2o=o("wav2vec2-conformer"),j2o=o(" \u2014 "),qj=a("a"),D2o=o("Wav2Vec2ConformerConfig"),G2o=o(" (Wav2Vec2-Conformer model)"),O2o=l(),cu=a("li"),Ahe=a("strong"),V2o=o("wavlm"),X2o=o(" \u2014 "),jj=a("a"),z2o=o("WavLMConfig"),Q2o=o(" (WavLM model)"),W2o=l(),fu=a("li"),Lhe=a("strong"),U2o=o("whisper"),H2o=o(" \u2014 "),Dj=a("a"),J2o=o("WhisperConfig"),Y2o=o(" (Whisper model)"),Z2o=l(),gu=a("li"),yhe=a("strong"),K2o=o("xclip"),ebo=o(" \u2014 "),Gj=a("a"),obo=o("XCLIPConfig"),rbo=o(" (X-CLIP model)"),tbo=l(),hu=a("li"),xhe=a("strong"),abo=o("xglm"),nbo=o(" \u2014 "),Oj=a("a"),sbo=o("XGLMConfig"),lbo=o(" (XGLM model)"),ibo=l(),uu=a("li"),$he=a("strong"),dbo=o("xlm"),mbo=o(" \u2014 "),Vj=a("a"),cbo=o("XLMConfig"),fbo=o(" (XLM model)"),gbo=l(),pu=a("li"),khe=a("strong"),hbo=o("xlm-prophetnet"),ubo=o(" \u2014 "),Xj=a("a"),pbo=o("XLMProphetNetConfig"),_bo=o(" (XLM-ProphetNet model)"),bbo=l(),_u=a("li"),She=a("strong"),vbo=o("xlm-roberta"),Fbo=o(" \u2014 "),zj=a("a"),Tbo=o("XLMRobertaConfig"),Mbo=o(" (XLM-RoBERTa model)"),Ebo=l(),bu=a("li"),Rhe=a("strong"),Cbo=o("xlm-roberta-xl"),wbo=o(" \u2014 "),Qj=a("a"),Abo=o("XLMRobertaXLConfig"),Lbo=o(" (XLM-RoBERTa-XL model)"),ybo=l(),vu=a("li"),Phe=a("strong"),xbo=o("xlnet"),$bo=o(" \u2014 "),Wj=a("a"),kbo=o("XLNetConfig"),Sbo=o(" (XLNet model)"),Rbo=l(),Fu=a("li"),Bhe=a("strong"),Pbo=o("yolos"),Bbo=o(" \u2014 "),Uj=a("a"),Ibo=o("YolosConfig"),Nbo=o(" (YOLOS model)"),qbo=l(),Tu=a("li"),Ihe=a("strong"),jbo=o("yoso"),Dbo=o(" \u2014 "),Hj=a("a"),Gbo=o("YosoConfig"),Obo=o(" (YOSO model)"),Vbo=l(),F(Mu.$$.fragment),Xbo=l(),Eu=a("div"),F(f$.$$.fragment),zbo=l(),Nhe=a("p"),Qbo=o("Register a new configuration for this class."),uto=l(),Ad=a("h2"),Cu=a("a"),qhe=a("span"),F(g$.$$.fragment),Wbo=l(),jhe=a("span"),Ubo=o("AutoTokenizer"),pto=l(),Ro=a("div"),F(h$.$$.fragment),Hbo=l(),u$=a("p"),Jbo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),Jj=a("a"),Ybo=o("AutoTokenizer.from_pretrained()"),Zbo=o(" class method."),Kbo=l(),p$=a("p"),evo=o("This class cannot be instantiated directly using "),Dhe=a("code"),ovo=o("__init__()"),rvo=o(" (throws an error)."),tvo=l(),jr=a("div"),F(_$.$$.fragment),avo=l(),Ghe=a("p"),nvo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),svo=l(),rn=a("p"),lvo=o("The tokenizer class to instantiate is selected based on the "),Ohe=a("code"),ivo=o("model_type"),dvo=o(` property of the config object (either
passed as an argument or loaded from `),Vhe=a("code"),mvo=o("pretrained_model_name_or_path"),cvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xhe=a("code"),fvo=o("pretrained_model_name_or_path"),gvo=o(":"),hvo=l(),k=a("ul"),us=a("li"),zhe=a("strong"),uvo=o("albert"),pvo=o(" \u2014 "),Yj=a("a"),_vo=o("AlbertTokenizer"),bvo=o(" or "),Zj=a("a"),vvo=o("AlbertTokenizerFast"),Fvo=o(" (ALBERT model)"),Tvo=l(),ps=a("li"),Qhe=a("strong"),Mvo=o("bart"),Evo=o(" \u2014 "),Kj=a("a"),Cvo=o("BartTokenizer"),wvo=o(" or "),eD=a("a"),Avo=o("BartTokenizerFast"),Lvo=o(" (BART model)"),yvo=l(),_s=a("li"),Whe=a("strong"),xvo=o("barthez"),$vo=o(" \u2014 "),oD=a("a"),kvo=o("BarthezTokenizer"),Svo=o(" or "),rD=a("a"),Rvo=o("BarthezTokenizerFast"),Pvo=o(" (BARThez model)"),Bvo=l(),wu=a("li"),Uhe=a("strong"),Ivo=o("bartpho"),Nvo=o(" \u2014 "),tD=a("a"),qvo=o("BartphoTokenizer"),jvo=o(" (BARTpho model)"),Dvo=l(),bs=a("li"),Hhe=a("strong"),Gvo=o("bert"),Ovo=o(" \u2014 "),aD=a("a"),Vvo=o("BertTokenizer"),Xvo=o(" or "),nD=a("a"),zvo=o("BertTokenizerFast"),Qvo=o(" (BERT model)"),Wvo=l(),Au=a("li"),Jhe=a("strong"),Uvo=o("bert-generation"),Hvo=o(" \u2014 "),sD=a("a"),Jvo=o("BertGenerationTokenizer"),Yvo=o(" (Bert Generation model)"),Zvo=l(),Lu=a("li"),Yhe=a("strong"),Kvo=o("bert-japanese"),eFo=o(" \u2014 "),lD=a("a"),oFo=o("BertJapaneseTokenizer"),rFo=o(" (BertJapanese model)"),tFo=l(),yu=a("li"),Zhe=a("strong"),aFo=o("bertweet"),nFo=o(" \u2014 "),iD=a("a"),sFo=o("BertweetTokenizer"),lFo=o(" (BERTweet model)"),iFo=l(),vs=a("li"),Khe=a("strong"),dFo=o("big_bird"),mFo=o(" \u2014 "),dD=a("a"),cFo=o("BigBirdTokenizer"),fFo=o(" or "),mD=a("a"),gFo=o("BigBirdTokenizerFast"),hFo=o(" (BigBird model)"),uFo=l(),Fs=a("li"),eue=a("strong"),pFo=o("bigbird_pegasus"),_Fo=o(" \u2014 "),cD=a("a"),bFo=o("PegasusTokenizer"),vFo=o(" or "),fD=a("a"),FFo=o("PegasusTokenizerFast"),TFo=o(" (BigBird-Pegasus model)"),MFo=l(),Ts=a("li"),oue=a("strong"),EFo=o("blenderbot"),CFo=o(" \u2014 "),gD=a("a"),wFo=o("BlenderbotTokenizer"),AFo=o(" or "),hD=a("a"),LFo=o("BlenderbotTokenizerFast"),yFo=o(" (Blenderbot model)"),xFo=l(),xu=a("li"),rue=a("strong"),$Fo=o("blenderbot-small"),kFo=o(" \u2014 "),uD=a("a"),SFo=o("BlenderbotSmallTokenizer"),RFo=o(" (BlenderbotSmall model)"),PFo=l(),$u=a("li"),tue=a("strong"),BFo=o("bloom"),IFo=o(" \u2014 "),pD=a("a"),NFo=o("BloomTokenizerFast"),qFo=o(" (BLOOM model)"),jFo=l(),ku=a("li"),aue=a("strong"),DFo=o("byt5"),GFo=o(" \u2014 "),_D=a("a"),OFo=o("ByT5Tokenizer"),VFo=o(" (ByT5 model)"),XFo=l(),Ms=a("li"),nue=a("strong"),zFo=o("camembert"),QFo=o(" \u2014 "),bD=a("a"),WFo=o("CamembertTokenizer"),UFo=o(" or "),vD=a("a"),HFo=o("CamembertTokenizerFast"),JFo=o(" (CamemBERT model)"),YFo=l(),Su=a("li"),sue=a("strong"),ZFo=o("canine"),KFo=o(" \u2014 "),FD=a("a"),eTo=o("CanineTokenizer"),oTo=o(" (CANINE model)"),rTo=l(),Es=a("li"),lue=a("strong"),tTo=o("clip"),aTo=o(" \u2014 "),TD=a("a"),nTo=o("CLIPTokenizer"),sTo=o(" or "),MD=a("a"),lTo=o("CLIPTokenizerFast"),iTo=o(" (CLIP model)"),dTo=l(),Cs=a("li"),iue=a("strong"),mTo=o("codegen"),cTo=o(" \u2014 "),ED=a("a"),fTo=o("CodeGenTokenizer"),gTo=o(" or "),CD=a("a"),hTo=o("CodeGenTokenizerFast"),uTo=o(" (CodeGen model)"),pTo=l(),ws=a("li"),due=a("strong"),_To=o("convbert"),bTo=o(" \u2014 "),wD=a("a"),vTo=o("ConvBertTokenizer"),FTo=o(" or "),AD=a("a"),TTo=o("ConvBertTokenizerFast"),MTo=o(" (ConvBERT model)"),ETo=l(),As=a("li"),mue=a("strong"),CTo=o("cpm"),wTo=o(" \u2014 "),LD=a("a"),ATo=o("CpmTokenizer"),LTo=o(" or "),yD=a("a"),yTo=o("CpmTokenizerFast"),xTo=o(" (CPM model)"),$To=l(),Ru=a("li"),cue=a("strong"),kTo=o("ctrl"),STo=o(" \u2014 "),xD=a("a"),RTo=o("CTRLTokenizer"),PTo=o(" (CTRL model)"),BTo=l(),Ls=a("li"),fue=a("strong"),ITo=o("data2vec-text"),NTo=o(" \u2014 "),$D=a("a"),qTo=o("RobertaTokenizer"),jTo=o(" or "),kD=a("a"),DTo=o("RobertaTokenizerFast"),GTo=o(" (Data2VecText model)"),OTo=l(),ys=a("li"),gue=a("strong"),VTo=o("deberta"),XTo=o(" \u2014 "),SD=a("a"),zTo=o("DebertaTokenizer"),QTo=o(" or "),RD=a("a"),WTo=o("DebertaTokenizerFast"),UTo=o(" (DeBERTa model)"),HTo=l(),xs=a("li"),hue=a("strong"),JTo=o("deberta-v2"),YTo=o(" \u2014 "),PD=a("a"),ZTo=o("DebertaV2Tokenizer"),KTo=o(" or "),BD=a("a"),eMo=o("DebertaV2TokenizerFast"),oMo=o(" (DeBERTa-v2 model)"),rMo=l(),$s=a("li"),uue=a("strong"),tMo=o("distilbert"),aMo=o(" \u2014 "),ID=a("a"),nMo=o("DistilBertTokenizer"),sMo=o(" or "),ND=a("a"),lMo=o("DistilBertTokenizerFast"),iMo=o(" (DistilBERT model)"),dMo=l(),ks=a("li"),pue=a("strong"),mMo=o("dpr"),cMo=o(" \u2014 "),qD=a("a"),fMo=o("DPRQuestionEncoderTokenizer"),gMo=o(" or "),jD=a("a"),hMo=o("DPRQuestionEncoderTokenizerFast"),uMo=o(" (DPR model)"),pMo=l(),Ss=a("li"),_ue=a("strong"),_Mo=o("electra"),bMo=o(" \u2014 "),DD=a("a"),vMo=o("ElectraTokenizer"),FMo=o(" or "),GD=a("a"),TMo=o("ElectraTokenizerFast"),MMo=o(" (ELECTRA model)"),EMo=l(),Rs=a("li"),bue=a("strong"),CMo=o("ernie"),wMo=o(" \u2014 "),OD=a("a"),AMo=o("BertTokenizer"),LMo=o(" or "),VD=a("a"),yMo=o("BertTokenizerFast"),xMo=o(" (ERNIE model)"),$Mo=l(),Pu=a("li"),vue=a("strong"),kMo=o("esm"),SMo=o(" \u2014 "),XD=a("a"),RMo=o("EsmTokenizer"),PMo=o(" (ESM model)"),BMo=l(),Bu=a("li"),Fue=a("strong"),IMo=o("flaubert"),NMo=o(" \u2014 "),zD=a("a"),qMo=o("FlaubertTokenizer"),jMo=o(" (FlauBERT model)"),DMo=l(),Ps=a("li"),Tue=a("strong"),GMo=o("fnet"),OMo=o(" \u2014 "),QD=a("a"),VMo=o("FNetTokenizer"),XMo=o(" or "),WD=a("a"),zMo=o("FNetTokenizerFast"),QMo=o(" (FNet model)"),WMo=l(),Iu=a("li"),Mue=a("strong"),UMo=o("fsmt"),HMo=o(" \u2014 "),UD=a("a"),JMo=o("FSMTTokenizer"),YMo=o(" (FairSeq Machine-Translation model)"),ZMo=l(),Bs=a("li"),Eue=a("strong"),KMo=o("funnel"),eEo=o(" \u2014 "),HD=a("a"),oEo=o("FunnelTokenizer"),rEo=o(" or "),JD=a("a"),tEo=o("FunnelTokenizerFast"),aEo=o(" (Funnel Transformer model)"),nEo=l(),Is=a("li"),Cue=a("strong"),sEo=o("gpt2"),lEo=o(" \u2014 "),YD=a("a"),iEo=o("GPT2Tokenizer"),dEo=o(" or "),ZD=a("a"),mEo=o("GPT2TokenizerFast"),cEo=o(" (OpenAI GPT-2 model)"),fEo=l(),Ns=a("li"),wue=a("strong"),gEo=o("gpt_neo"),hEo=o(" \u2014 "),KD=a("a"),uEo=o("GPT2Tokenizer"),pEo=o(" or "),eG=a("a"),_Eo=o("GPT2TokenizerFast"),bEo=o(" (GPT Neo model)"),vEo=l(),Nu=a("li"),Aue=a("strong"),FEo=o("gpt_neox"),TEo=o(" \u2014 "),oG=a("a"),MEo=o("GPTNeoXTokenizerFast"),EEo=o(" (GPT NeoX model)"),CEo=l(),qu=a("li"),Lue=a("strong"),wEo=o("gpt_neox_japanese"),AEo=o(" \u2014 "),rG=a("a"),LEo=o("GPTNeoXJapaneseTokenizer"),yEo=o(" (GPT NeoX Japanese model)"),xEo=l(),qs=a("li"),yue=a("strong"),$Eo=o("gptj"),kEo=o(" \u2014 "),tG=a("a"),SEo=o("GPT2Tokenizer"),REo=o(" or "),aG=a("a"),PEo=o("GPT2TokenizerFast"),BEo=o(" (GPT-J model)"),IEo=l(),js=a("li"),xue=a("strong"),NEo=o("groupvit"),qEo=o(" \u2014 "),nG=a("a"),jEo=o("CLIPTokenizer"),DEo=o(" or "),sG=a("a"),GEo=o("CLIPTokenizerFast"),OEo=o(" (GroupViT model)"),VEo=l(),Ds=a("li"),$ue=a("strong"),XEo=o("herbert"),zEo=o(" \u2014 "),lG=a("a"),QEo=o("HerbertTokenizer"),WEo=o(" or "),iG=a("a"),UEo=o("HerbertTokenizerFast"),HEo=o(" (HerBERT model)"),JEo=l(),ju=a("li"),kue=a("strong"),YEo=o("hubert"),ZEo=o(" \u2014 "),dG=a("a"),KEo=o("Wav2Vec2CTCTokenizer"),e4o=o(" (Hubert model)"),o4o=l(),Gs=a("li"),Sue=a("strong"),r4o=o("ibert"),t4o=o(" \u2014 "),mG=a("a"),a4o=o("RobertaTokenizer"),n4o=o(" or "),cG=a("a"),s4o=o("RobertaTokenizerFast"),l4o=o(" (I-BERT model)"),i4o=l(),Os=a("li"),Rue=a("strong"),d4o=o("layoutlm"),m4o=o(" \u2014 "),fG=a("a"),c4o=o("LayoutLMTokenizer"),f4o=o(" or "),gG=a("a"),g4o=o("LayoutLMTokenizerFast"),h4o=o(" (LayoutLM model)"),u4o=l(),Vs=a("li"),Pue=a("strong"),p4o=o("layoutlmv2"),_4o=o(" \u2014 "),hG=a("a"),b4o=o("LayoutLMv2Tokenizer"),v4o=o(" or "),uG=a("a"),F4o=o("LayoutLMv2TokenizerFast"),T4o=o(" (LayoutLMv2 model)"),M4o=l(),Xs=a("li"),Bue=a("strong"),E4o=o("layoutlmv3"),C4o=o(" \u2014 "),pG=a("a"),w4o=o("LayoutLMv3Tokenizer"),A4o=o(" or "),_G=a("a"),L4o=o("LayoutLMv3TokenizerFast"),y4o=o(" (LayoutLMv3 model)"),x4o=l(),zs=a("li"),Iue=a("strong"),$4o=o("layoutxlm"),k4o=o(" \u2014 "),bG=a("a"),S4o=o("LayoutXLMTokenizer"),R4o=o(" or "),vG=a("a"),P4o=o("LayoutXLMTokenizerFast"),B4o=o(" (LayoutXLM model)"),I4o=l(),Qs=a("li"),Nue=a("strong"),N4o=o("led"),q4o=o(" \u2014 "),FG=a("a"),j4o=o("LEDTokenizer"),D4o=o(" or "),TG=a("a"),G4o=o("LEDTokenizerFast"),O4o=o(" (LED model)"),V4o=l(),Ws=a("li"),que=a("strong"),X4o=o("lilt"),z4o=o(" \u2014 "),MG=a("a"),Q4o=o("LayoutLMv3Tokenizer"),W4o=o(" or "),EG=a("a"),U4o=o("LayoutLMv3TokenizerFast"),H4o=o(" (LiLT model)"),J4o=l(),Us=a("li"),jue=a("strong"),Y4o=o("longformer"),Z4o=o(" \u2014 "),CG=a("a"),K4o=o("LongformerTokenizer"),eCo=o(" or "),wG=a("a"),oCo=o("LongformerTokenizerFast"),rCo=o(" (Longformer model)"),tCo=l(),Hs=a("li"),Due=a("strong"),aCo=o("longt5"),nCo=o(" \u2014 "),AG=a("a"),sCo=o("T5Tokenizer"),lCo=o(" or "),LG=a("a"),iCo=o("T5TokenizerFast"),dCo=o(" (LongT5 model)"),mCo=l(),Du=a("li"),Gue=a("strong"),cCo=o("luke"),fCo=o(" \u2014 "),yG=a("a"),gCo=o("LukeTokenizer"),hCo=o(" (LUKE model)"),uCo=l(),Js=a("li"),Oue=a("strong"),pCo=o("lxmert"),_Co=o(" \u2014 "),xG=a("a"),bCo=o("LxmertTokenizer"),vCo=o(" or "),$G=a("a"),FCo=o("LxmertTokenizerFast"),TCo=o(" (LXMERT model)"),MCo=l(),Gu=a("li"),Vue=a("strong"),ECo=o("m2m_100"),CCo=o(" \u2014 "),kG=a("a"),wCo=o("M2M100Tokenizer"),ACo=o(" (M2M100 model)"),LCo=l(),Ou=a("li"),Xue=a("strong"),yCo=o("marian"),xCo=o(" \u2014 "),SG=a("a"),$Co=o("MarianTokenizer"),kCo=o(" (Marian model)"),SCo=l(),Ys=a("li"),zue=a("strong"),RCo=o("mbart"),PCo=o(" \u2014 "),RG=a("a"),BCo=o("MBartTokenizer"),ICo=o(" or "),PG=a("a"),NCo=o("MBartTokenizerFast"),qCo=o(" (mBART model)"),jCo=l(),Zs=a("li"),Que=a("strong"),DCo=o("mbart50"),GCo=o(" \u2014 "),BG=a("a"),OCo=o("MBart50Tokenizer"),VCo=o(" or "),IG=a("a"),XCo=o("MBart50TokenizerFast"),zCo=o(" (mBART-50 model)"),QCo=l(),Ks=a("li"),Wue=a("strong"),WCo=o("megatron-bert"),UCo=o(" \u2014 "),NG=a("a"),HCo=o("BertTokenizer"),JCo=o(" or "),qG=a("a"),YCo=o("BertTokenizerFast"),ZCo=o(" (Megatron-BERT model)"),KCo=l(),Vu=a("li"),Uue=a("strong"),e3o=o("mluke"),o3o=o(" \u2014 "),jG=a("a"),r3o=o("MLukeTokenizer"),t3o=o(" (mLUKE model)"),a3o=l(),el=a("li"),Hue=a("strong"),n3o=o("mobilebert"),s3o=o(" \u2014 "),DG=a("a"),l3o=o("MobileBertTokenizer"),i3o=o(" or "),GG=a("a"),d3o=o("MobileBertTokenizerFast"),m3o=o(" (MobileBERT model)"),c3o=l(),ol=a("li"),Jue=a("strong"),f3o=o("mpnet"),g3o=o(" \u2014 "),OG=a("a"),h3o=o("MPNetTokenizer"),u3o=o(" or "),VG=a("a"),p3o=o("MPNetTokenizerFast"),_3o=o(" (MPNet model)"),b3o=l(),rl=a("li"),Yue=a("strong"),v3o=o("mt5"),F3o=o(" \u2014 "),XG=a("a"),T3o=o("MT5Tokenizer"),M3o=o(" or "),zG=a("a"),E3o=o("MT5TokenizerFast"),C3o=o(" (MT5 model)"),w3o=l(),tl=a("li"),Zue=a("strong"),A3o=o("mvp"),L3o=o(" \u2014 "),QG=a("a"),y3o=o("MvpTokenizer"),x3o=o(" or "),WG=a("a"),$3o=o("MvpTokenizerFast"),k3o=o(" (MVP model)"),S3o=l(),al=a("li"),Kue=a("strong"),R3o=o("nezha"),P3o=o(" \u2014 "),UG=a("a"),B3o=o("BertTokenizer"),I3o=o(" or "),HG=a("a"),N3o=o("BertTokenizerFast"),q3o=o(" (Nezha model)"),j3o=l(),nl=a("li"),epe=a("strong"),D3o=o("nllb"),G3o=o(" \u2014 "),JG=a("a"),O3o=o("NllbTokenizer"),V3o=o(" or "),YG=a("a"),X3o=o("NllbTokenizerFast"),z3o=o(" (NLLB model)"),Q3o=l(),sl=a("li"),ope=a("strong"),W3o=o("nystromformer"),U3o=o(" \u2014 "),ZG=a("a"),H3o=o("AlbertTokenizer"),J3o=o(" or "),KG=a("a"),Y3o=o("AlbertTokenizerFast"),Z3o=o(" (Nystr\xF6mformer model)"),K3o=l(),ll=a("li"),rpe=a("strong"),e5o=o("openai-gpt"),o5o=o(" \u2014 "),eO=a("a"),r5o=o("OpenAIGPTTokenizer"),t5o=o(" or "),oO=a("a"),a5o=o("OpenAIGPTTokenizerFast"),n5o=o(" (OpenAI GPT model)"),s5o=l(),Xu=a("li"),tpe=a("strong"),l5o=o("opt"),i5o=o(" \u2014 "),rO=a("a"),d5o=o("GPT2Tokenizer"),m5o=o(" (OPT model)"),c5o=l(),il=a("li"),ape=a("strong"),f5o=o("owlvit"),g5o=o(" \u2014 "),tO=a("a"),h5o=o("CLIPTokenizer"),u5o=o(" or "),aO=a("a"),p5o=o("CLIPTokenizerFast"),_5o=o(" (OWL-ViT model)"),b5o=l(),dl=a("li"),npe=a("strong"),v5o=o("pegasus"),F5o=o(" \u2014 "),nO=a("a"),T5o=o("PegasusTokenizer"),M5o=o(" or "),sO=a("a"),E5o=o("PegasusTokenizerFast"),C5o=o(" (Pegasus model)"),w5o=l(),zu=a("li"),spe=a("strong"),A5o=o("perceiver"),L5o=o(" \u2014 "),lO=a("a"),y5o=o("PerceiverTokenizer"),x5o=o(" (Perceiver model)"),$5o=l(),Qu=a("li"),lpe=a("strong"),k5o=o("phobert"),S5o=o(" \u2014 "),iO=a("a"),R5o=o("PhobertTokenizer"),P5o=o(" (PhoBERT model)"),B5o=l(),Wu=a("li"),ipe=a("strong"),I5o=o("plbart"),N5o=o(" \u2014 "),dO=a("a"),q5o=o("PLBartTokenizer"),j5o=o(" (PLBart model)"),D5o=l(),Uu=a("li"),dpe=a("strong"),G5o=o("prophetnet"),O5o=o(" \u2014 "),mO=a("a"),V5o=o("ProphetNetTokenizer"),X5o=o(" (ProphetNet model)"),z5o=l(),ml=a("li"),mpe=a("strong"),Q5o=o("qdqbert"),W5o=o(" \u2014 "),cO=a("a"),U5o=o("BertTokenizer"),H5o=o(" or "),fO=a("a"),J5o=o("BertTokenizerFast"),Y5o=o(" (QDQBert model)"),Z5o=l(),Hu=a("li"),cpe=a("strong"),K5o=o("rag"),e0o=o(" \u2014 "),gO=a("a"),o0o=o("RagTokenizer"),r0o=o(" (RAG model)"),t0o=l(),cl=a("li"),fpe=a("strong"),a0o=o("realm"),n0o=o(" \u2014 "),hO=a("a"),s0o=o("RealmTokenizer"),l0o=o(" or "),uO=a("a"),i0o=o("RealmTokenizerFast"),d0o=o(" (REALM model)"),m0o=l(),fl=a("li"),gpe=a("strong"),c0o=o("reformer"),f0o=o(" \u2014 "),pO=a("a"),g0o=o("ReformerTokenizer"),h0o=o(" or "),_O=a("a"),u0o=o("ReformerTokenizerFast"),p0o=o(" (Reformer model)"),_0o=l(),gl=a("li"),hpe=a("strong"),b0o=o("rembert"),v0o=o(" \u2014 "),bO=a("a"),F0o=o("RemBertTokenizer"),T0o=o(" or "),vO=a("a"),M0o=o("RemBertTokenizerFast"),E0o=o(" (RemBERT model)"),C0o=l(),hl=a("li"),upe=a("strong"),w0o=o("retribert"),A0o=o(" \u2014 "),FO=a("a"),L0o=o("RetriBertTokenizer"),y0o=o(" or "),TO=a("a"),x0o=o("RetriBertTokenizerFast"),$0o=o(" (RetriBERT model)"),k0o=l(),ul=a("li"),ppe=a("strong"),S0o=o("roberta"),R0o=o(" \u2014 "),MO=a("a"),P0o=o("RobertaTokenizer"),B0o=o(" or "),EO=a("a"),I0o=o("RobertaTokenizerFast"),N0o=o(" (RoBERTa model)"),q0o=l(),pl=a("li"),_pe=a("strong"),j0o=o("roformer"),D0o=o(" \u2014 "),CO=a("a"),G0o=o("RoFormerTokenizer"),O0o=o(" or "),wO=a("a"),V0o=o("RoFormerTokenizerFast"),X0o=o(" (RoFormer model)"),z0o=l(),Ju=a("li"),bpe=a("strong"),Q0o=o("speech_to_text"),W0o=o(" \u2014 "),AO=a("a"),U0o=o("Speech2TextTokenizer"),H0o=o(" (Speech2Text model)"),J0o=l(),Yu=a("li"),vpe=a("strong"),Y0o=o("speech_to_text_2"),Z0o=o(" \u2014 "),LO=a("a"),K0o=o("Speech2Text2Tokenizer"),ewo=o(" (Speech2Text2 model)"),owo=l(),_l=a("li"),Fpe=a("strong"),rwo=o("splinter"),two=o(" \u2014 "),yO=a("a"),awo=o("SplinterTokenizer"),nwo=o(" or "),xO=a("a"),swo=o("SplinterTokenizerFast"),lwo=o(" (Splinter model)"),iwo=l(),bl=a("li"),Tpe=a("strong"),dwo=o("squeezebert"),mwo=o(" \u2014 "),$O=a("a"),cwo=o("SqueezeBertTokenizer"),fwo=o(" or "),kO=a("a"),gwo=o("SqueezeBertTokenizerFast"),hwo=o(" (SqueezeBERT model)"),uwo=l(),vl=a("li"),Mpe=a("strong"),pwo=o("t5"),_wo=o(" \u2014 "),SO=a("a"),bwo=o("T5Tokenizer"),vwo=o(" or "),RO=a("a"),Fwo=o("T5TokenizerFast"),Two=o(" (T5 model)"),Mwo=l(),Zu=a("li"),Epe=a("strong"),Ewo=o("tapas"),Cwo=o(" \u2014 "),PO=a("a"),wwo=o("TapasTokenizer"),Awo=o(" (TAPAS model)"),Lwo=l(),Ku=a("li"),Cpe=a("strong"),ywo=o("tapex"),xwo=o(" \u2014 "),BO=a("a"),$wo=o("TapexTokenizer"),kwo=o(" (TAPEX model)"),Swo=l(),ep=a("li"),wpe=a("strong"),Rwo=o("transfo-xl"),Pwo=o(" \u2014 "),IO=a("a"),Bwo=o("TransfoXLTokenizer"),Iwo=o(" (Transformer-XL model)"),Nwo=l(),Fl=a("li"),Ape=a("strong"),qwo=o("vilt"),jwo=o(" \u2014 "),NO=a("a"),Dwo=o("BertTokenizer"),Gwo=o(" or "),qO=a("a"),Owo=o("BertTokenizerFast"),Vwo=o(" (ViLT model)"),Xwo=l(),Tl=a("li"),Lpe=a("strong"),zwo=o("visual_bert"),Qwo=o(" \u2014 "),jO=a("a"),Wwo=o("BertTokenizer"),Uwo=o(" or "),DO=a("a"),Hwo=o("BertTokenizerFast"),Jwo=o(" (VisualBERT model)"),Ywo=l(),op=a("li"),ype=a("strong"),Zwo=o("wav2vec2"),Kwo=o(" \u2014 "),GO=a("a"),eAo=o("Wav2Vec2CTCTokenizer"),oAo=o(" (Wav2Vec2 model)"),rAo=l(),rp=a("li"),xpe=a("strong"),tAo=o("wav2vec2-conformer"),aAo=o(" \u2014 "),OO=a("a"),nAo=o("Wav2Vec2CTCTokenizer"),sAo=o(" (Wav2Vec2-Conformer model)"),lAo=l(),tp=a("li"),$pe=a("strong"),iAo=o("wav2vec2_phoneme"),dAo=o(" \u2014 "),VO=a("a"),mAo=o("Wav2Vec2PhonemeCTCTokenizer"),cAo=o(" (Wav2Vec2Phoneme model)"),fAo=l(),ap=a("li"),kpe=a("strong"),gAo=o("whisper"),hAo=o(" \u2014 "),XO=a("a"),uAo=o("WhisperTokenizer"),pAo=o(" (Whisper model)"),_Ao=l(),Ml=a("li"),Spe=a("strong"),bAo=o("xclip"),vAo=o(" \u2014 "),zO=a("a"),FAo=o("CLIPTokenizer"),TAo=o(" or "),QO=a("a"),MAo=o("CLIPTokenizerFast"),EAo=o(" (X-CLIP model)"),CAo=l(),El=a("li"),Rpe=a("strong"),wAo=o("xglm"),AAo=o(" \u2014 "),WO=a("a"),LAo=o("XGLMTokenizer"),yAo=o(" or "),UO=a("a"),xAo=o("XGLMTokenizerFast"),$Ao=o(" (XGLM model)"),kAo=l(),np=a("li"),Ppe=a("strong"),SAo=o("xlm"),RAo=o(" \u2014 "),HO=a("a"),PAo=o("XLMTokenizer"),BAo=o(" (XLM model)"),IAo=l(),sp=a("li"),Bpe=a("strong"),NAo=o("xlm-prophetnet"),qAo=o(" \u2014 "),JO=a("a"),jAo=o("XLMProphetNetTokenizer"),DAo=o(" (XLM-ProphetNet model)"),GAo=l(),Cl=a("li"),Ipe=a("strong"),OAo=o("xlm-roberta"),VAo=o(" \u2014 "),YO=a("a"),XAo=o("XLMRobertaTokenizer"),zAo=o(" or "),ZO=a("a"),QAo=o("XLMRobertaTokenizerFast"),WAo=o(" (XLM-RoBERTa model)"),UAo=l(),wl=a("li"),Npe=a("strong"),HAo=o("xlm-roberta-xl"),JAo=o(" \u2014 "),KO=a("a"),YAo=o("XLMRobertaTokenizer"),ZAo=o(" or "),eV=a("a"),KAo=o("XLMRobertaTokenizerFast"),e6o=o(" (XLM-RoBERTa-XL model)"),o6o=l(),Al=a("li"),qpe=a("strong"),r6o=o("xlnet"),t6o=o(" \u2014 "),oV=a("a"),a6o=o("XLNetTokenizer"),n6o=o(" or "),rV=a("a"),s6o=o("XLNetTokenizerFast"),l6o=o(" (XLNet model)"),i6o=l(),Ll=a("li"),jpe=a("strong"),d6o=o("yoso"),m6o=o(" \u2014 "),tV=a("a"),c6o=o("AlbertTokenizer"),f6o=o(" or "),aV=a("a"),g6o=o("AlbertTokenizerFast"),h6o=o(" (YOSO model)"),u6o=l(),F(lp.$$.fragment),p6o=l(),ip=a("div"),F(b$.$$.fragment),_6o=l(),Dpe=a("p"),b6o=o("Register a new tokenizer in this mapping."),_to=l(),Ld=a("h2"),dp=a("a"),Gpe=a("span"),F(v$.$$.fragment),v6o=l(),Ope=a("span"),F6o=o("AutoFeatureExtractor"),bto=l(),Po=a("div"),F(F$.$$.fragment),T6o=l(),T$=a("p"),M6o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nV=a("a"),E6o=o("AutoFeatureExtractor.from_pretrained()"),C6o=o(" class method."),w6o=l(),M$=a("p"),A6o=o("This class cannot be instantiated directly using "),Vpe=a("code"),L6o=o("__init__()"),y6o=o(" (throws an error)."),x6o=l(),Ye=a("div"),F(E$.$$.fragment),$6o=l(),Xpe=a("p"),k6o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),S6o=l(),tn=a("p"),R6o=o("The feature extractor class to instantiate is selected based on the "),zpe=a("code"),P6o=o("model_type"),B6o=o(` property of the config object
(either passed as an argument or loaded from `),Qpe=a("code"),I6o=o("pretrained_model_name_or_path"),N6o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Wpe=a("code"),q6o=o("pretrained_model_name_or_path"),j6o=o(":"),D6o=l(),z=a("ul"),mp=a("li"),Upe=a("strong"),G6o=o("beit"),O6o=o(" \u2014 "),sV=a("a"),V6o=o("BeitFeatureExtractor"),X6o=o(" (BEiT model)"),z6o=l(),cp=a("li"),Hpe=a("strong"),Q6o=o("clip"),W6o=o(" \u2014 "),lV=a("a"),U6o=o("CLIPFeatureExtractor"),H6o=o(" (CLIP model)"),J6o=l(),fp=a("li"),Jpe=a("strong"),Y6o=o("conditional_detr"),Z6o=o(" \u2014 "),iV=a("a"),K6o=o("ConditionalDetrFeatureExtractor"),e7o=o(" (Conditional DETR model)"),o7o=l(),gp=a("li"),Ype=a("strong"),r7o=o("convnext"),t7o=o(" \u2014 "),dV=a("a"),a7o=o("ConvNextFeatureExtractor"),n7o=o(" (ConvNeXT model)"),s7o=l(),hp=a("li"),Zpe=a("strong"),l7o=o("cvt"),i7o=o(" \u2014 "),mV=a("a"),d7o=o("ConvNextFeatureExtractor"),m7o=o(" (CvT model)"),c7o=l(),up=a("li"),Kpe=a("strong"),f7o=o("data2vec-audio"),g7o=o(" \u2014 "),cV=a("a"),h7o=o("Wav2Vec2FeatureExtractor"),u7o=o(" (Data2VecAudio model)"),p7o=l(),pp=a("li"),e_e=a("strong"),_7o=o("data2vec-vision"),b7o=o(" \u2014 "),fV=a("a"),v7o=o("BeitFeatureExtractor"),F7o=o(" (Data2VecVision model)"),T7o=l(),_p=a("li"),o_e=a("strong"),M7o=o("deformable_detr"),E7o=o(" \u2014 "),gV=a("a"),C7o=o("DeformableDetrFeatureExtractor"),w7o=o(" (Deformable DETR model)"),A7o=l(),bp=a("li"),r_e=a("strong"),L7o=o("deit"),y7o=o(" \u2014 "),hV=a("a"),x7o=o("DeiTFeatureExtractor"),$7o=o(" (DeiT model)"),k7o=l(),vp=a("li"),t_e=a("strong"),S7o=o("detr"),R7o=o(" \u2014 "),uV=a("a"),P7o=o("DetrFeatureExtractor"),B7o=o(" (DETR model)"),I7o=l(),Fp=a("li"),a_e=a("strong"),N7o=o("donut"),q7o=o(" \u2014 "),pV=a("a"),j7o=o("DonutFeatureExtractor"),D7o=o(" (Donut model)"),G7o=l(),Tp=a("li"),n_e=a("strong"),O7o=o("dpt"),V7o=o(" \u2014 "),_V=a("a"),X7o=o("DPTFeatureExtractor"),z7o=o(" (DPT model)"),Q7o=l(),Mp=a("li"),s_e=a("strong"),W7o=o("flava"),U7o=o(" \u2014 "),bV=a("a"),H7o=o("FlavaFeatureExtractor"),J7o=o(" (FLAVA model)"),Y7o=l(),Ep=a("li"),l_e=a("strong"),Z7o=o("glpn"),K7o=o(" \u2014 "),vV=a("a"),e8o=o("GLPNFeatureExtractor"),o8o=o(" (GLPN model)"),r8o=l(),Cp=a("li"),i_e=a("strong"),t8o=o("groupvit"),a8o=o(" \u2014 "),FV=a("a"),n8o=o("CLIPFeatureExtractor"),s8o=o(" (GroupViT model)"),l8o=l(),wp=a("li"),d_e=a("strong"),i8o=o("hubert"),d8o=o(" \u2014 "),TV=a("a"),m8o=o("Wav2Vec2FeatureExtractor"),c8o=o(" (Hubert model)"),f8o=l(),Ap=a("li"),m_e=a("strong"),g8o=o("imagegpt"),h8o=o(" \u2014 "),MV=a("a"),u8o=o("ImageGPTFeatureExtractor"),p8o=o(" (ImageGPT model)"),_8o=l(),Lp=a("li"),c_e=a("strong"),b8o=o("layoutlmv2"),v8o=o(" \u2014 "),EV=a("a"),F8o=o("LayoutLMv2FeatureExtractor"),T8o=o(" (LayoutLMv2 model)"),M8o=l(),yp=a("li"),f_e=a("strong"),E8o=o("layoutlmv3"),C8o=o(" \u2014 "),CV=a("a"),w8o=o("LayoutLMv3FeatureExtractor"),A8o=o(" (LayoutLMv3 model)"),L8o=l(),xp=a("li"),g_e=a("strong"),y8o=o("levit"),x8o=o(" \u2014 "),wV=a("a"),$8o=o("LevitFeatureExtractor"),k8o=o(" (LeViT model)"),S8o=l(),$p=a("li"),h_e=a("strong"),R8o=o("maskformer"),P8o=o(" \u2014 "),AV=a("a"),B8o=o("MaskFormerFeatureExtractor"),I8o=o(" (MaskFormer model)"),N8o=l(),kp=a("li"),u_e=a("strong"),q8o=o("mctct"),j8o=o(" \u2014 "),LV=a("a"),D8o=o("MCTCTFeatureExtractor"),G8o=o(" (M-CTC-T model)"),O8o=l(),Sp=a("li"),p_e=a("strong"),V8o=o("mobilevit"),X8o=o(" \u2014 "),yV=a("a"),z8o=o("MobileViTFeatureExtractor"),Q8o=o(" (MobileViT model)"),W8o=l(),Rp=a("li"),__e=a("strong"),U8o=o("owlvit"),H8o=o(" \u2014 "),xV=a("a"),J8o=o("OwlViTFeatureExtractor"),Y8o=o(" (OWL-ViT model)"),Z8o=l(),Pp=a("li"),b_e=a("strong"),K8o=o("perceiver"),eLo=o(" \u2014 "),$V=a("a"),oLo=o("PerceiverFeatureExtractor"),rLo=o(" (Perceiver model)"),tLo=l(),Bp=a("li"),v_e=a("strong"),aLo=o("poolformer"),nLo=o(" \u2014 "),kV=a("a"),sLo=o("PoolFormerFeatureExtractor"),lLo=o(" (PoolFormer model)"),iLo=l(),Ip=a("li"),F_e=a("strong"),dLo=o("regnet"),mLo=o(" \u2014 "),SV=a("a"),cLo=o("ConvNextFeatureExtractor"),fLo=o(" (RegNet model)"),gLo=l(),Np=a("li"),T_e=a("strong"),hLo=o("resnet"),uLo=o(" \u2014 "),RV=a("a"),pLo=o("ConvNextFeatureExtractor"),_Lo=o(" (ResNet model)"),bLo=l(),qp=a("li"),M_e=a("strong"),vLo=o("segformer"),FLo=o(" \u2014 "),PV=a("a"),TLo=o("SegformerFeatureExtractor"),MLo=o(" (SegFormer model)"),ELo=l(),jp=a("li"),E_e=a("strong"),CLo=o("speech_to_text"),wLo=o(" \u2014 "),BV=a("a"),ALo=o("Speech2TextFeatureExtractor"),LLo=o(" (Speech2Text model)"),yLo=l(),Dp=a("li"),C_e=a("strong"),xLo=o("swin"),$Lo=o(" \u2014 "),IV=a("a"),kLo=o("ViTFeatureExtractor"),SLo=o(" (Swin Transformer model)"),RLo=l(),Gp=a("li"),w_e=a("strong"),PLo=o("swinv2"),BLo=o(" \u2014 "),NV=a("a"),ILo=o("ViTFeatureExtractor"),NLo=o(" (Swin Transformer V2 model)"),qLo=l(),Op=a("li"),A_e=a("strong"),jLo=o("van"),DLo=o(" \u2014 "),qV=a("a"),GLo=o("ConvNextFeatureExtractor"),OLo=o(" (VAN model)"),VLo=l(),Vp=a("li"),L_e=a("strong"),XLo=o("videomae"),zLo=o(" \u2014 "),jV=a("a"),QLo=o("VideoMAEFeatureExtractor"),WLo=o(" (VideoMAE model)"),ULo=l(),Xp=a("li"),y_e=a("strong"),HLo=o("vilt"),JLo=o(" \u2014 "),DV=a("a"),YLo=o("ViltFeatureExtractor"),ZLo=o(" (ViLT model)"),KLo=l(),zp=a("li"),x_e=a("strong"),eyo=o("vit"),oyo=o(" \u2014 "),GV=a("a"),ryo=o("ViTFeatureExtractor"),tyo=o(" (ViT model)"),ayo=l(),Qp=a("li"),$_e=a("strong"),nyo=o("vit_mae"),syo=o(" \u2014 "),OV=a("a"),lyo=o("ViTFeatureExtractor"),iyo=o(" (ViTMAE model)"),dyo=l(),Wp=a("li"),k_e=a("strong"),myo=o("vit_msn"),cyo=o(" \u2014 "),VV=a("a"),fyo=o("ViTFeatureExtractor"),gyo=o(" (ViTMSN model)"),hyo=l(),Up=a("li"),S_e=a("strong"),uyo=o("wav2vec2"),pyo=o(" \u2014 "),XV=a("a"),_yo=o("Wav2Vec2FeatureExtractor"),byo=o(" (Wav2Vec2 model)"),vyo=l(),Hp=a("li"),R_e=a("strong"),Fyo=o("wav2vec2-conformer"),Tyo=o(" \u2014 "),zV=a("a"),Myo=o("Wav2Vec2FeatureExtractor"),Eyo=o(" (Wav2Vec2-Conformer model)"),Cyo=l(),Jp=a("li"),P_e=a("strong"),wyo=o("whisper"),Ayo=o(" \u2014 "),QV=a("a"),Lyo=o("WhisperFeatureExtractor"),yyo=o(" (Whisper model)"),xyo=l(),Yp=a("li"),B_e=a("strong"),$yo=o("xclip"),kyo=o(" \u2014 "),WV=a("a"),Syo=o("CLIPFeatureExtractor"),Ryo=o(" (X-CLIP model)"),Pyo=l(),Zp=a("li"),I_e=a("strong"),Byo=o("yolos"),Iyo=o(" \u2014 "),UV=a("a"),Nyo=o("YolosFeatureExtractor"),qyo=o(" (YOLOS model)"),jyo=l(),F(Kp.$$.fragment),Dyo=l(),F(e_.$$.fragment),Gyo=l(),o_=a("div"),F(C$.$$.fragment),Oyo=l(),N_e=a("p"),Vyo=o("Register a new feature extractor for this class."),vto=l(),yd=a("h2"),r_=a("a"),q_e=a("span"),F(w$.$$.fragment),Xyo=l(),j_e=a("span"),zyo=o("AutoProcessor"),Fto=l(),Bo=a("div"),F(A$.$$.fragment),Qyo=l(),L$=a("p"),Wyo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),HV=a("a"),Uyo=o("AutoProcessor.from_pretrained()"),Hyo=o(" class method."),Jyo=l(),y$=a("p"),Yyo=o("This class cannot be instantiated directly using "),D_e=a("code"),Zyo=o("__init__()"),Kyo=o(" (throws an error)."),e9o=l(),Ze=a("div"),F(x$.$$.fragment),o9o=l(),G_e=a("p"),r9o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),t9o=l(),xd=a("p"),a9o=o("The processor class to instantiate is selected based on the "),O_e=a("code"),n9o=o("model_type"),s9o=o(` property of the config object (either
passed as an argument or loaded from `),V_e=a("code"),l9o=o("pretrained_model_name_or_path"),i9o=o(" if possible):"),d9o=l(),se=a("ul"),t_=a("li"),X_e=a("strong"),m9o=o("clip"),c9o=o(" \u2014 "),JV=a("a"),f9o=o("CLIPProcessor"),g9o=o(" (CLIP model)"),h9o=l(),a_=a("li"),z_e=a("strong"),u9o=o("donut"),p9o=o(" \u2014 "),YV=a("a"),_9o=o("DonutProcessor"),b9o=o(" (Donut model)"),v9o=l(),n_=a("li"),Q_e=a("strong"),F9o=o("flava"),T9o=o(" \u2014 "),ZV=a("a"),M9o=o("FlavaProcessor"),E9o=o(" (FLAVA model)"),C9o=l(),s_=a("li"),W_e=a("strong"),w9o=o("groupvit"),A9o=o(" \u2014 "),KV=a("a"),L9o=o("CLIPProcessor"),y9o=o(" (GroupViT model)"),x9o=l(),l_=a("li"),U_e=a("strong"),$9o=o("layoutlmv2"),k9o=o(" \u2014 "),eX=a("a"),S9o=o("LayoutLMv2Processor"),R9o=o(" (LayoutLMv2 model)"),P9o=l(),i_=a("li"),H_e=a("strong"),B9o=o("layoutlmv3"),I9o=o(" \u2014 "),oX=a("a"),N9o=o("LayoutLMv3Processor"),q9o=o(" (LayoutLMv3 model)"),j9o=l(),d_=a("li"),J_e=a("strong"),D9o=o("layoutxlm"),G9o=o(" \u2014 "),rX=a("a"),O9o=o("LayoutXLMProcessor"),V9o=o(" (LayoutXLM model)"),X9o=l(),m_=a("li"),Y_e=a("strong"),z9o=o("markuplm"),Q9o=o(" \u2014 "),tX=a("a"),W9o=o("MarkupLMProcessor"),U9o=o(" (MarkupLM model)"),H9o=l(),c_=a("li"),Z_e=a("strong"),J9o=o("owlvit"),Y9o=o(" \u2014 "),aX=a("a"),Z9o=o("OwlViTProcessor"),K9o=o(" (OWL-ViT model)"),exo=l(),f_=a("li"),K_e=a("strong"),oxo=o("sew"),rxo=o(" \u2014 "),nX=a("a"),txo=o("Wav2Vec2Processor"),axo=o(" (SEW model)"),nxo=l(),g_=a("li"),e1e=a("strong"),sxo=o("sew-d"),lxo=o(" \u2014 "),sX=a("a"),ixo=o("Wav2Vec2Processor"),dxo=o(" (SEW-D model)"),mxo=l(),h_=a("li"),o1e=a("strong"),cxo=o("speech_to_text"),fxo=o(" \u2014 "),lX=a("a"),gxo=o("Speech2TextProcessor"),hxo=o(" (Speech2Text model)"),uxo=l(),u_=a("li"),r1e=a("strong"),pxo=o("speech_to_text_2"),_xo=o(" \u2014 "),iX=a("a"),bxo=o("Speech2Text2Processor"),vxo=o(" (Speech2Text2 model)"),Fxo=l(),p_=a("li"),t1e=a("strong"),Txo=o("trocr"),Mxo=o(" \u2014 "),dX=a("a"),Exo=o("TrOCRProcessor"),Cxo=o(" (TrOCR model)"),wxo=l(),__=a("li"),a1e=a("strong"),Axo=o("unispeech"),Lxo=o(" \u2014 "),mX=a("a"),yxo=o("Wav2Vec2Processor"),xxo=o(" (UniSpeech model)"),$xo=l(),b_=a("li"),n1e=a("strong"),kxo=o("unispeech-sat"),Sxo=o(" \u2014 "),cX=a("a"),Rxo=o("Wav2Vec2Processor"),Pxo=o(" (UniSpeechSat model)"),Bxo=l(),v_=a("li"),s1e=a("strong"),Ixo=o("vilt"),Nxo=o(" \u2014 "),fX=a("a"),qxo=o("ViltProcessor"),jxo=o(" (ViLT model)"),Dxo=l(),F_=a("li"),l1e=a("strong"),Gxo=o("vision-text-dual-encoder"),Oxo=o(" \u2014 "),gX=a("a"),Vxo=o("VisionTextDualEncoderProcessor"),Xxo=o(" (VisionTextDualEncoder model)"),zxo=l(),T_=a("li"),i1e=a("strong"),Qxo=o("wav2vec2"),Wxo=o(" \u2014 "),hX=a("a"),Uxo=o("Wav2Vec2Processor"),Hxo=o(" (Wav2Vec2 model)"),Jxo=l(),M_=a("li"),d1e=a("strong"),Yxo=o("wav2vec2-conformer"),Zxo=o(" \u2014 "),uX=a("a"),Kxo=o("Wav2Vec2Processor"),e$o=o(" (Wav2Vec2-Conformer model)"),o$o=l(),E_=a("li"),m1e=a("strong"),r$o=o("wavlm"),t$o=o(" \u2014 "),pX=a("a"),a$o=o("Wav2Vec2Processor"),n$o=o(" (WavLM model)"),s$o=l(),C_=a("li"),c1e=a("strong"),l$o=o("whisper"),i$o=o(" \u2014 "),_X=a("a"),d$o=o("WhisperProcessor"),m$o=o(" (Whisper model)"),c$o=l(),w_=a("li"),f1e=a("strong"),f$o=o("xclip"),g$o=o(" \u2014 "),bX=a("a"),h$o=o("XCLIPProcessor"),u$o=o(" (X-CLIP model)"),p$o=l(),F(A_.$$.fragment),_$o=l(),F(L_.$$.fragment),b$o=l(),y_=a("div"),F($$.$$.fragment),v$o=l(),g1e=a("p"),F$o=o("Register a new processor for this class."),Tto=l(),$d=a("h2"),x_=a("a"),h1e=a("span"),F(k$.$$.fragment),T$o=l(),u1e=a("span"),M$o=o("AutoModel"),Mto=l(),Io=a("div"),F(S$.$$.fragment),E$o=l(),kd=a("p"),C$o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),vX=a("a"),w$o=o("from_pretrained()"),A$o=o(" class method or the "),FX=a("a"),L$o=o("from_config()"),y$o=o(` class
method.`),x$o=l(),R$=a("p"),$$o=o("This class cannot be instantiated directly using "),p1e=a("code"),k$o=o("__init__()"),S$o=o(" (throws an error)."),R$o=l(),Tt=a("div"),F(P$.$$.fragment),P$o=l(),_1e=a("p"),B$o=o("Instantiates one of the base model classes of the library from a configuration."),I$o=l(),Sd=a("p"),N$o=o(`Note:
Loading a model from its configuration file does `),b1e=a("strong"),q$o=o("not"),j$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TX=a("a"),D$o=o("from_pretrained()"),G$o=o(" to load the model weights."),O$o=l(),F($_.$$.fragment),V$o=l(),Ke=a("div"),F(B$.$$.fragment),X$o=l(),v1e=a("p"),z$o=o("Instantiate one of the base model classes of the library from a pretrained model."),Q$o=l(),an=a("p"),W$o=o("The model class to instantiate is selected based on the "),F1e=a("code"),U$o=o("model_type"),H$o=o(` property of the config object (either
passed as an argument or loaded from `),T1e=a("code"),J$o=o("pretrained_model_name_or_path"),Y$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M1e=a("code"),Z$o=o("pretrained_model_name_or_path"),K$o=o(":"),eko=l(),y=a("ul"),k_=a("li"),E1e=a("strong"),oko=o("albert"),rko=o(" \u2014 "),MX=a("a"),tko=o("AlbertModel"),ako=o(" (ALBERT model)"),nko=l(),S_=a("li"),C1e=a("strong"),sko=o("bart"),lko=o(" \u2014 "),EX=a("a"),iko=o("BartModel"),dko=o(" (BART model)"),mko=l(),R_=a("li"),w1e=a("strong"),cko=o("beit"),fko=o(" \u2014 "),CX=a("a"),gko=o("BeitModel"),hko=o(" (BEiT model)"),uko=l(),P_=a("li"),A1e=a("strong"),pko=o("bert"),_ko=o(" \u2014 "),wX=a("a"),bko=o("BertModel"),vko=o(" (BERT model)"),Fko=l(),B_=a("li"),L1e=a("strong"),Tko=o("bert-generation"),Mko=o(" \u2014 "),AX=a("a"),Eko=o("BertGenerationEncoder"),Cko=o(" (Bert Generation model)"),wko=l(),I_=a("li"),y1e=a("strong"),Ako=o("big_bird"),Lko=o(" \u2014 "),LX=a("a"),yko=o("BigBirdModel"),xko=o(" (BigBird model)"),$ko=l(),N_=a("li"),x1e=a("strong"),kko=o("bigbird_pegasus"),Sko=o(" \u2014 "),yX=a("a"),Rko=o("BigBirdPegasusModel"),Pko=o(" (BigBird-Pegasus model)"),Bko=l(),q_=a("li"),$1e=a("strong"),Iko=o("blenderbot"),Nko=o(" \u2014 "),xX=a("a"),qko=o("BlenderbotModel"),jko=o(" (Blenderbot model)"),Dko=l(),j_=a("li"),k1e=a("strong"),Gko=o("blenderbot-small"),Oko=o(" \u2014 "),$X=a("a"),Vko=o("BlenderbotSmallModel"),Xko=o(" (BlenderbotSmall model)"),zko=l(),D_=a("li"),S1e=a("strong"),Qko=o("bloom"),Wko=o(" \u2014 "),kX=a("a"),Uko=o("BloomModel"),Hko=o(" (BLOOM model)"),Jko=l(),G_=a("li"),R1e=a("strong"),Yko=o("camembert"),Zko=o(" \u2014 "),SX=a("a"),Kko=o("CamembertModel"),eSo=o(" (CamemBERT model)"),oSo=l(),O_=a("li"),P1e=a("strong"),rSo=o("canine"),tSo=o(" \u2014 "),RX=a("a"),aSo=o("CanineModel"),nSo=o(" (CANINE model)"),sSo=l(),V_=a("li"),B1e=a("strong"),lSo=o("clip"),iSo=o(" \u2014 "),PX=a("a"),dSo=o("CLIPModel"),mSo=o(" (CLIP model)"),cSo=l(),X_=a("li"),I1e=a("strong"),fSo=o("codegen"),gSo=o(" \u2014 "),BX=a("a"),hSo=o("CodeGenModel"),uSo=o(" (CodeGen model)"),pSo=l(),z_=a("li"),N1e=a("strong"),_So=o("conditional_detr"),bSo=o(" \u2014 "),IX=a("a"),vSo=o("ConditionalDetrModel"),FSo=o(" (Conditional DETR model)"),TSo=l(),Q_=a("li"),q1e=a("strong"),MSo=o("convbert"),ESo=o(" \u2014 "),NX=a("a"),CSo=o("ConvBertModel"),wSo=o(" (ConvBERT model)"),ASo=l(),W_=a("li"),j1e=a("strong"),LSo=o("convnext"),ySo=o(" \u2014 "),qX=a("a"),xSo=o("ConvNextModel"),$So=o(" (ConvNeXT model)"),kSo=l(),U_=a("li"),D1e=a("strong"),SSo=o("ctrl"),RSo=o(" \u2014 "),jX=a("a"),PSo=o("CTRLModel"),BSo=o(" (CTRL model)"),ISo=l(),H_=a("li"),G1e=a("strong"),NSo=o("cvt"),qSo=o(" \u2014 "),DX=a("a"),jSo=o("CvtModel"),DSo=o(" (CvT model)"),GSo=l(),J_=a("li"),O1e=a("strong"),OSo=o("data2vec-audio"),VSo=o(" \u2014 "),GX=a("a"),XSo=o("Data2VecAudioModel"),zSo=o(" (Data2VecAudio model)"),QSo=l(),Y_=a("li"),V1e=a("strong"),WSo=o("data2vec-text"),USo=o(" \u2014 "),OX=a("a"),HSo=o("Data2VecTextModel"),JSo=o(" (Data2VecText model)"),YSo=l(),Z_=a("li"),X1e=a("strong"),ZSo=o("data2vec-vision"),KSo=o(" \u2014 "),VX=a("a"),eRo=o("Data2VecVisionModel"),oRo=o(" (Data2VecVision model)"),rRo=l(),K_=a("li"),z1e=a("strong"),tRo=o("deberta"),aRo=o(" \u2014 "),XX=a("a"),nRo=o("DebertaModel"),sRo=o(" (DeBERTa model)"),lRo=l(),e1=a("li"),Q1e=a("strong"),iRo=o("deberta-v2"),dRo=o(" \u2014 "),zX=a("a"),mRo=o("DebertaV2Model"),cRo=o(" (DeBERTa-v2 model)"),fRo=l(),o1=a("li"),W1e=a("strong"),gRo=o("decision_transformer"),hRo=o(" \u2014 "),QX=a("a"),uRo=o("DecisionTransformerModel"),pRo=o(" (Decision Transformer model)"),_Ro=l(),r1=a("li"),U1e=a("strong"),bRo=o("deformable_detr"),vRo=o(" \u2014 "),WX=a("a"),FRo=o("DeformableDetrModel"),TRo=o(" (Deformable DETR model)"),MRo=l(),t1=a("li"),H1e=a("strong"),ERo=o("deit"),CRo=o(" \u2014 "),UX=a("a"),wRo=o("DeiTModel"),ARo=o(" (DeiT model)"),LRo=l(),a1=a("li"),J1e=a("strong"),yRo=o("detr"),xRo=o(" \u2014 "),HX=a("a"),$Ro=o("DetrModel"),kRo=o(" (DETR model)"),SRo=l(),n1=a("li"),Y1e=a("strong"),RRo=o("distilbert"),PRo=o(" \u2014 "),JX=a("a"),BRo=o("DistilBertModel"),IRo=o(" (DistilBERT model)"),NRo=l(),s1=a("li"),Z1e=a("strong"),qRo=o("donut-swin"),jRo=o(" \u2014 "),YX=a("a"),DRo=o("DonutSwinModel"),GRo=o(" (DonutSwin model)"),ORo=l(),l1=a("li"),K1e=a("strong"),VRo=o("dpr"),XRo=o(" \u2014 "),ZX=a("a"),zRo=o("DPRQuestionEncoder"),QRo=o(" (DPR model)"),WRo=l(),i1=a("li"),e2e=a("strong"),URo=o("dpt"),HRo=o(" \u2014 "),KX=a("a"),JRo=o("DPTModel"),YRo=o(" (DPT model)"),ZRo=l(),d1=a("li"),o2e=a("strong"),KRo=o("electra"),ePo=o(" \u2014 "),ez=a("a"),oPo=o("ElectraModel"),rPo=o(" (ELECTRA model)"),tPo=l(),m1=a("li"),r2e=a("strong"),aPo=o("ernie"),nPo=o(" \u2014 "),oz=a("a"),sPo=o("ErnieModel"),lPo=o(" (ERNIE model)"),iPo=l(),c1=a("li"),t2e=a("strong"),dPo=o("esm"),mPo=o(" \u2014 "),rz=a("a"),cPo=o("EsmModel"),fPo=o(" (ESM model)"),gPo=l(),f1=a("li"),a2e=a("strong"),hPo=o("flaubert"),uPo=o(" \u2014 "),tz=a("a"),pPo=o("FlaubertModel"),_Po=o(" (FlauBERT model)"),bPo=l(),g1=a("li"),n2e=a("strong"),vPo=o("flava"),FPo=o(" \u2014 "),az=a("a"),TPo=o("FlavaModel"),MPo=o(" (FLAVA model)"),EPo=l(),h1=a("li"),s2e=a("strong"),CPo=o("fnet"),wPo=o(" \u2014 "),nz=a("a"),APo=o("FNetModel"),LPo=o(" (FNet model)"),yPo=l(),u1=a("li"),l2e=a("strong"),xPo=o("fsmt"),$Po=o(" \u2014 "),sz=a("a"),kPo=o("FSMTModel"),SPo=o(" (FairSeq Machine-Translation model)"),RPo=l(),yl=a("li"),i2e=a("strong"),PPo=o("funnel"),BPo=o(" \u2014 "),lz=a("a"),IPo=o("FunnelModel"),NPo=o(" or "),iz=a("a"),qPo=o("FunnelBaseModel"),jPo=o(" (Funnel Transformer model)"),DPo=l(),p1=a("li"),d2e=a("strong"),GPo=o("glpn"),OPo=o(" \u2014 "),dz=a("a"),VPo=o("GLPNModel"),XPo=o(" (GLPN model)"),zPo=l(),_1=a("li"),m2e=a("strong"),QPo=o("gpt2"),WPo=o(" \u2014 "),mz=a("a"),UPo=o("GPT2Model"),HPo=o(" (OpenAI GPT-2 model)"),JPo=l(),b1=a("li"),c2e=a("strong"),YPo=o("gpt_neo"),ZPo=o(" \u2014 "),cz=a("a"),KPo=o("GPTNeoModel"),eBo=o(" (GPT Neo model)"),oBo=l(),v1=a("li"),f2e=a("strong"),rBo=o("gpt_neox"),tBo=o(" \u2014 "),fz=a("a"),aBo=o("GPTNeoXModel"),nBo=o(" (GPT NeoX model)"),sBo=l(),F1=a("li"),g2e=a("strong"),lBo=o("gpt_neox_japanese"),iBo=o(" \u2014 "),gz=a("a"),dBo=o("GPTNeoXJapaneseModel"),mBo=o(" (GPT NeoX Japanese model)"),cBo=l(),T1=a("li"),h2e=a("strong"),fBo=o("gptj"),gBo=o(" \u2014 "),hz=a("a"),hBo=o("GPTJModel"),uBo=o(" (GPT-J model)"),pBo=l(),M1=a("li"),u2e=a("strong"),_Bo=o("groupvit"),bBo=o(" \u2014 "),uz=a("a"),vBo=o("GroupViTModel"),FBo=o(" (GroupViT model)"),TBo=l(),E1=a("li"),p2e=a("strong"),MBo=o("hubert"),EBo=o(" \u2014 "),pz=a("a"),CBo=o("HubertModel"),wBo=o(" (Hubert model)"),ABo=l(),C1=a("li"),_2e=a("strong"),LBo=o("ibert"),yBo=o(" \u2014 "),_z=a("a"),xBo=o("IBertModel"),$Bo=o(" (I-BERT model)"),kBo=l(),w1=a("li"),b2e=a("strong"),SBo=o("imagegpt"),RBo=o(" \u2014 "),bz=a("a"),PBo=o("ImageGPTModel"),BBo=o(" (ImageGPT model)"),IBo=l(),A1=a("li"),v2e=a("strong"),NBo=o("layoutlm"),qBo=o(" \u2014 "),vz=a("a"),jBo=o("LayoutLMModel"),DBo=o(" (LayoutLM model)"),GBo=l(),L1=a("li"),F2e=a("strong"),OBo=o("layoutlmv2"),VBo=o(" \u2014 "),Fz=a("a"),XBo=o("LayoutLMv2Model"),zBo=o(" (LayoutLMv2 model)"),QBo=l(),y1=a("li"),T2e=a("strong"),WBo=o("layoutlmv3"),UBo=o(" \u2014 "),Tz=a("a"),HBo=o("LayoutLMv3Model"),JBo=o(" (LayoutLMv3 model)"),YBo=l(),x1=a("li"),M2e=a("strong"),ZBo=o("led"),KBo=o(" \u2014 "),Mz=a("a"),eIo=o("LEDModel"),oIo=o(" (LED model)"),rIo=l(),$1=a("li"),E2e=a("strong"),tIo=o("levit"),aIo=o(" \u2014 "),Ez=a("a"),nIo=o("LevitModel"),sIo=o(" (LeViT model)"),lIo=l(),k1=a("li"),C2e=a("strong"),iIo=o("lilt"),dIo=o(" \u2014 "),Cz=a("a"),mIo=o("LiltModel"),cIo=o(" (LiLT model)"),fIo=l(),S1=a("li"),w2e=a("strong"),gIo=o("longformer"),hIo=o(" \u2014 "),wz=a("a"),uIo=o("LongformerModel"),pIo=o(" (Longformer model)"),_Io=l(),R1=a("li"),A2e=a("strong"),bIo=o("longt5"),vIo=o(" \u2014 "),Az=a("a"),FIo=o("LongT5Model"),TIo=o(" (LongT5 model)"),MIo=l(),P1=a("li"),L2e=a("strong"),EIo=o("luke"),CIo=o(" \u2014 "),Lz=a("a"),wIo=o("LukeModel"),AIo=o(" (LUKE model)"),LIo=l(),B1=a("li"),y2e=a("strong"),yIo=o("lxmert"),xIo=o(" \u2014 "),yz=a("a"),$Io=o("LxmertModel"),kIo=o(" (LXMERT model)"),SIo=l(),I1=a("li"),x2e=a("strong"),RIo=o("m2m_100"),PIo=o(" \u2014 "),xz=a("a"),BIo=o("M2M100Model"),IIo=o(" (M2M100 model)"),NIo=l(),N1=a("li"),$2e=a("strong"),qIo=o("marian"),jIo=o(" \u2014 "),$z=a("a"),DIo=o("MarianModel"),GIo=o(" (Marian model)"),OIo=l(),q1=a("li"),k2e=a("strong"),VIo=o("markuplm"),XIo=o(" \u2014 "),kz=a("a"),zIo=o("MarkupLMModel"),QIo=o(" (MarkupLM model)"),WIo=l(),j1=a("li"),S2e=a("strong"),UIo=o("maskformer"),HIo=o(" \u2014 "),Sz=a("a"),JIo=o("MaskFormerModel"),YIo=o(" (MaskFormer model)"),ZIo=l(),D1=a("li"),R2e=a("strong"),KIo=o("mbart"),eNo=o(" \u2014 "),Rz=a("a"),oNo=o("MBartModel"),rNo=o(" (mBART model)"),tNo=l(),G1=a("li"),P2e=a("strong"),aNo=o("mctct"),nNo=o(" \u2014 "),Pz=a("a"),sNo=o("MCTCTModel"),lNo=o(" (M-CTC-T model)"),iNo=l(),O1=a("li"),B2e=a("strong"),dNo=o("megatron-bert"),mNo=o(" \u2014 "),Bz=a("a"),cNo=o("MegatronBertModel"),fNo=o(" (Megatron-BERT model)"),gNo=l(),V1=a("li"),I2e=a("strong"),hNo=o("mobilebert"),uNo=o(" \u2014 "),Iz=a("a"),pNo=o("MobileBertModel"),_No=o(" (MobileBERT model)"),bNo=l(),X1=a("li"),N2e=a("strong"),vNo=o("mobilevit"),FNo=o(" \u2014 "),Nz=a("a"),TNo=o("MobileViTModel"),MNo=o(" (MobileViT model)"),ENo=l(),z1=a("li"),q2e=a("strong"),CNo=o("mpnet"),wNo=o(" \u2014 "),qz=a("a"),ANo=o("MPNetModel"),LNo=o(" (MPNet model)"),yNo=l(),Q1=a("li"),j2e=a("strong"),xNo=o("mt5"),$No=o(" \u2014 "),jz=a("a"),kNo=o("MT5Model"),SNo=o(" (MT5 model)"),RNo=l(),W1=a("li"),D2e=a("strong"),PNo=o("mvp"),BNo=o(" \u2014 "),Dz=a("a"),INo=o("MvpModel"),NNo=o(" (MVP model)"),qNo=l(),U1=a("li"),G2e=a("strong"),jNo=o("nezha"),DNo=o(" \u2014 "),Gz=a("a"),GNo=o("NezhaModel"),ONo=o(" (Nezha model)"),VNo=l(),H1=a("li"),O2e=a("strong"),XNo=o("nllb"),zNo=o(" \u2014 "),Oz=a("a"),QNo=o("M2M100Model"),WNo=o(" (NLLB model)"),UNo=l(),J1=a("li"),V2e=a("strong"),HNo=o("nystromformer"),JNo=o(" \u2014 "),Vz=a("a"),YNo=o("NystromformerModel"),ZNo=o(" (Nystr\xF6mformer model)"),KNo=l(),Y1=a("li"),X2e=a("strong"),eqo=o("openai-gpt"),oqo=o(" \u2014 "),Xz=a("a"),rqo=o("OpenAIGPTModel"),tqo=o(" (OpenAI GPT model)"),aqo=l(),Z1=a("li"),z2e=a("strong"),nqo=o("opt"),sqo=o(" \u2014 "),zz=a("a"),lqo=o("OPTModel"),iqo=o(" (OPT model)"),dqo=l(),K1=a("li"),Q2e=a("strong"),mqo=o("owlvit"),cqo=o(" \u2014 "),Qz=a("a"),fqo=o("OwlViTModel"),gqo=o(" (OWL-ViT model)"),hqo=l(),e2=a("li"),W2e=a("strong"),uqo=o("pegasus"),pqo=o(" \u2014 "),Wz=a("a"),_qo=o("PegasusModel"),bqo=o(" (Pegasus model)"),vqo=l(),o2=a("li"),U2e=a("strong"),Fqo=o("pegasus_x"),Tqo=o(" \u2014 "),Uz=a("a"),Mqo=o("PegasusXModel"),Eqo=o(" (PEGASUS-X model)"),Cqo=l(),r2=a("li"),H2e=a("strong"),wqo=o("perceiver"),Aqo=o(" \u2014 "),Hz=a("a"),Lqo=o("PerceiverModel"),yqo=o(" (Perceiver model)"),xqo=l(),t2=a("li"),J2e=a("strong"),$qo=o("plbart"),kqo=o(" \u2014 "),Jz=a("a"),Sqo=o("PLBartModel"),Rqo=o(" (PLBart model)"),Pqo=l(),a2=a("li"),Y2e=a("strong"),Bqo=o("poolformer"),Iqo=o(" \u2014 "),Yz=a("a"),Nqo=o("PoolFormerModel"),qqo=o(" (PoolFormer model)"),jqo=l(),n2=a("li"),Z2e=a("strong"),Dqo=o("prophetnet"),Gqo=o(" \u2014 "),Zz=a("a"),Oqo=o("ProphetNetModel"),Vqo=o(" (ProphetNet model)"),Xqo=l(),s2=a("li"),K2e=a("strong"),zqo=o("qdqbert"),Qqo=o(" \u2014 "),Kz=a("a"),Wqo=o("QDQBertModel"),Uqo=o(" (QDQBert model)"),Hqo=l(),l2=a("li"),ebe=a("strong"),Jqo=o("reformer"),Yqo=o(" \u2014 "),eQ=a("a"),Zqo=o("ReformerModel"),Kqo=o(" (Reformer model)"),ejo=l(),i2=a("li"),obe=a("strong"),ojo=o("regnet"),rjo=o(" \u2014 "),oQ=a("a"),tjo=o("RegNetModel"),ajo=o(" (RegNet model)"),njo=l(),d2=a("li"),rbe=a("strong"),sjo=o("rembert"),ljo=o(" \u2014 "),rQ=a("a"),ijo=o("RemBertModel"),djo=o(" (RemBERT model)"),mjo=l(),m2=a("li"),tbe=a("strong"),cjo=o("resnet"),fjo=o(" \u2014 "),tQ=a("a"),gjo=o("ResNetModel"),hjo=o(" (ResNet model)"),ujo=l(),c2=a("li"),abe=a("strong"),pjo=o("retribert"),_jo=o(" \u2014 "),aQ=a("a"),bjo=o("RetriBertModel"),vjo=o(" (RetriBERT model)"),Fjo=l(),f2=a("li"),nbe=a("strong"),Tjo=o("roberta"),Mjo=o(" \u2014 "),nQ=a("a"),Ejo=o("RobertaModel"),Cjo=o(" (RoBERTa model)"),wjo=l(),g2=a("li"),sbe=a("strong"),Ajo=o("roformer"),Ljo=o(" \u2014 "),sQ=a("a"),yjo=o("RoFormerModel"),xjo=o(" (RoFormer model)"),$jo=l(),h2=a("li"),lbe=a("strong"),kjo=o("segformer"),Sjo=o(" \u2014 "),lQ=a("a"),Rjo=o("SegformerModel"),Pjo=o(" (SegFormer model)"),Bjo=l(),u2=a("li"),ibe=a("strong"),Ijo=o("sew"),Njo=o(" \u2014 "),iQ=a("a"),qjo=o("SEWModel"),jjo=o(" (SEW model)"),Djo=l(),p2=a("li"),dbe=a("strong"),Gjo=o("sew-d"),Ojo=o(" \u2014 "),dQ=a("a"),Vjo=o("SEWDModel"),Xjo=o(" (SEW-D model)"),zjo=l(),_2=a("li"),mbe=a("strong"),Qjo=o("speech_to_text"),Wjo=o(" \u2014 "),mQ=a("a"),Ujo=o("Speech2TextModel"),Hjo=o(" (Speech2Text model)"),Jjo=l(),b2=a("li"),cbe=a("strong"),Yjo=o("splinter"),Zjo=o(" \u2014 "),cQ=a("a"),Kjo=o("SplinterModel"),eDo=o(" (Splinter model)"),oDo=l(),v2=a("li"),fbe=a("strong"),rDo=o("squeezebert"),tDo=o(" \u2014 "),fQ=a("a"),aDo=o("SqueezeBertModel"),nDo=o(" (SqueezeBERT model)"),sDo=l(),F2=a("li"),gbe=a("strong"),lDo=o("swin"),iDo=o(" \u2014 "),gQ=a("a"),dDo=o("SwinModel"),mDo=o(" (Swin Transformer model)"),cDo=l(),T2=a("li"),hbe=a("strong"),fDo=o("swinv2"),gDo=o(" \u2014 "),hQ=a("a"),hDo=o("Swinv2Model"),uDo=o(" (Swin Transformer V2 model)"),pDo=l(),M2=a("li"),ube=a("strong"),_Do=o("t5"),bDo=o(" \u2014 "),uQ=a("a"),vDo=o("T5Model"),FDo=o(" (T5 model)"),TDo=l(),E2=a("li"),pbe=a("strong"),MDo=o("tapas"),EDo=o(" \u2014 "),pQ=a("a"),CDo=o("TapasModel"),wDo=o(" (TAPAS model)"),ADo=l(),C2=a("li"),_be=a("strong"),LDo=o("time_series_transformer"),yDo=o(" \u2014 "),_Q=a("a"),xDo=o("TimeSeriesTransformerModel"),$Do=o(" (Time Series Transformer model)"),kDo=l(),w2=a("li"),bbe=a("strong"),SDo=o("trajectory_transformer"),RDo=o(" \u2014 "),bQ=a("a"),PDo=o("TrajectoryTransformerModel"),BDo=o(" (Trajectory Transformer model)"),IDo=l(),A2=a("li"),vbe=a("strong"),NDo=o("transfo-xl"),qDo=o(" \u2014 "),vQ=a("a"),jDo=o("TransfoXLModel"),DDo=o(" (Transformer-XL model)"),GDo=l(),L2=a("li"),Fbe=a("strong"),ODo=o("unispeech"),VDo=o(" \u2014 "),FQ=a("a"),XDo=o("UniSpeechModel"),zDo=o(" (UniSpeech model)"),QDo=l(),y2=a("li"),Tbe=a("strong"),WDo=o("unispeech-sat"),UDo=o(" \u2014 "),TQ=a("a"),HDo=o("UniSpeechSatModel"),JDo=o(" (UniSpeechSat model)"),YDo=l(),x2=a("li"),Mbe=a("strong"),ZDo=o("van"),KDo=o(" \u2014 "),MQ=a("a"),eGo=o("VanModel"),oGo=o(" (VAN model)"),rGo=l(),$2=a("li"),Ebe=a("strong"),tGo=o("videomae"),aGo=o(" \u2014 "),EQ=a("a"),nGo=o("VideoMAEModel"),sGo=o(" (VideoMAE model)"),lGo=l(),k2=a("li"),Cbe=a("strong"),iGo=o("vilt"),dGo=o(" \u2014 "),CQ=a("a"),mGo=o("ViltModel"),cGo=o(" (ViLT model)"),fGo=l(),S2=a("li"),wbe=a("strong"),gGo=o("vision-text-dual-encoder"),hGo=o(" \u2014 "),wQ=a("a"),uGo=o("VisionTextDualEncoderModel"),pGo=o(" (VisionTextDualEncoder model)"),_Go=l(),R2=a("li"),Abe=a("strong"),bGo=o("visual_bert"),vGo=o(" \u2014 "),AQ=a("a"),FGo=o("VisualBertModel"),TGo=o(" (VisualBERT model)"),MGo=l(),P2=a("li"),Lbe=a("strong"),EGo=o("vit"),CGo=o(" \u2014 "),LQ=a("a"),wGo=o("ViTModel"),AGo=o(" (ViT model)"),LGo=l(),B2=a("li"),ybe=a("strong"),yGo=o("vit_mae"),xGo=o(" \u2014 "),yQ=a("a"),$Go=o("ViTMAEModel"),kGo=o(" (ViTMAE model)"),SGo=l(),I2=a("li"),xbe=a("strong"),RGo=o("vit_msn"),PGo=o(" \u2014 "),xQ=a("a"),BGo=o("ViTMSNModel"),IGo=o(" (ViTMSN model)"),NGo=l(),N2=a("li"),$be=a("strong"),qGo=o("wav2vec2"),jGo=o(" \u2014 "),$Q=a("a"),DGo=o("Wav2Vec2Model"),GGo=o(" (Wav2Vec2 model)"),OGo=l(),q2=a("li"),kbe=a("strong"),VGo=o("wav2vec2-conformer"),XGo=o(" \u2014 "),kQ=a("a"),zGo=o("Wav2Vec2ConformerModel"),QGo=o(" (Wav2Vec2-Conformer model)"),WGo=l(),j2=a("li"),Sbe=a("strong"),UGo=o("wavlm"),HGo=o(" \u2014 "),SQ=a("a"),JGo=o("WavLMModel"),YGo=o(" (WavLM model)"),ZGo=l(),D2=a("li"),Rbe=a("strong"),KGo=o("whisper"),eOo=o(" \u2014 "),RQ=a("a"),oOo=o("WhisperModel"),rOo=o(" (Whisper model)"),tOo=l(),G2=a("li"),Pbe=a("strong"),aOo=o("xclip"),nOo=o(" \u2014 "),PQ=a("a"),sOo=o("XCLIPModel"),lOo=o(" (X-CLIP model)"),iOo=l(),O2=a("li"),Bbe=a("strong"),dOo=o("xglm"),mOo=o(" \u2014 "),BQ=a("a"),cOo=o("XGLMModel"),fOo=o(" (XGLM model)"),gOo=l(),V2=a("li"),Ibe=a("strong"),hOo=o("xlm"),uOo=o(" \u2014 "),IQ=a("a"),pOo=o("XLMModel"),_Oo=o(" (XLM model)"),bOo=l(),X2=a("li"),Nbe=a("strong"),vOo=o("xlm-prophetnet"),FOo=o(" \u2014 "),NQ=a("a"),TOo=o("XLMProphetNetModel"),MOo=o(" (XLM-ProphetNet model)"),EOo=l(),z2=a("li"),qbe=a("strong"),COo=o("xlm-roberta"),wOo=o(" \u2014 "),qQ=a("a"),AOo=o("XLMRobertaModel"),LOo=o(" (XLM-RoBERTa model)"),yOo=l(),Q2=a("li"),jbe=a("strong"),xOo=o("xlm-roberta-xl"),$Oo=o(" \u2014 "),jQ=a("a"),kOo=o("XLMRobertaXLModel"),SOo=o(" (XLM-RoBERTa-XL model)"),ROo=l(),W2=a("li"),Dbe=a("strong"),POo=o("xlnet"),BOo=o(" \u2014 "),DQ=a("a"),IOo=o("XLNetModel"),NOo=o(" (XLNet model)"),qOo=l(),U2=a("li"),Gbe=a("strong"),jOo=o("yolos"),DOo=o(" \u2014 "),GQ=a("a"),GOo=o("YolosModel"),OOo=o(" (YOLOS model)"),VOo=l(),H2=a("li"),Obe=a("strong"),XOo=o("yoso"),zOo=o(" \u2014 "),OQ=a("a"),QOo=o("YosoModel"),WOo=o(" (YOSO model)"),UOo=l(),J2=a("p"),HOo=o("The model is set in evaluation mode by default using "),Vbe=a("code"),JOo=o("model.eval()"),YOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xbe=a("code"),ZOo=o("model.train()"),KOo=l(),F(Y2.$$.fragment),Eto=l(),Rd=a("h2"),Z2=a("a"),zbe=a("span"),F(I$.$$.fragment),eVo=l(),Qbe=a("span"),oVo=o("AutoModelForPreTraining"),Cto=l(),No=a("div"),F(N$.$$.fragment),rVo=l(),Pd=a("p"),tVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VQ=a("a"),aVo=o("from_pretrained()"),nVo=o(" class method or the "),XQ=a("a"),sVo=o("from_config()"),lVo=o(` class
method.`),iVo=l(),q$=a("p"),dVo=o("This class cannot be instantiated directly using "),Wbe=a("code"),mVo=o("__init__()"),cVo=o(" (throws an error)."),fVo=l(),Mt=a("div"),F(j$.$$.fragment),gVo=l(),Ube=a("p"),hVo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uVo=l(),Bd=a("p"),pVo=o(`Note:
Loading a model from its configuration file does `),Hbe=a("strong"),_Vo=o("not"),bVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zQ=a("a"),vVo=o("from_pretrained()"),FVo=o(" to load the model weights."),TVo=l(),F(K2.$$.fragment),MVo=l(),eo=a("div"),F(D$.$$.fragment),EVo=l(),Jbe=a("p"),CVo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),wVo=l(),nn=a("p"),AVo=o("The model class to instantiate is selected based on the "),Ybe=a("code"),LVo=o("model_type"),yVo=o(` property of the config object (either
passed as an argument or loaded from `),Zbe=a("code"),xVo=o("pretrained_model_name_or_path"),$Vo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kbe=a("code"),kVo=o("pretrained_model_name_or_path"),SVo=o(":"),RVo=l(),G=a("ul"),eb=a("li"),eve=a("strong"),PVo=o("albert"),BVo=o(" \u2014 "),QQ=a("a"),IVo=o("AlbertForPreTraining"),NVo=o(" (ALBERT model)"),qVo=l(),ob=a("li"),ove=a("strong"),jVo=o("bart"),DVo=o(" \u2014 "),WQ=a("a"),GVo=o("BartForConditionalGeneration"),OVo=o(" (BART model)"),VVo=l(),rb=a("li"),rve=a("strong"),XVo=o("bert"),zVo=o(" \u2014 "),UQ=a("a"),QVo=o("BertForPreTraining"),WVo=o(" (BERT model)"),UVo=l(),tb=a("li"),tve=a("strong"),HVo=o("big_bird"),JVo=o(" \u2014 "),HQ=a("a"),YVo=o("BigBirdForPreTraining"),ZVo=o(" (BigBird model)"),KVo=l(),ab=a("li"),ave=a("strong"),eXo=o("bloom"),oXo=o(" \u2014 "),JQ=a("a"),rXo=o("BloomForCausalLM"),tXo=o(" (BLOOM model)"),aXo=l(),nb=a("li"),nve=a("strong"),nXo=o("camembert"),sXo=o(" \u2014 "),YQ=a("a"),lXo=o("CamembertForMaskedLM"),iXo=o(" (CamemBERT model)"),dXo=l(),sb=a("li"),sve=a("strong"),mXo=o("ctrl"),cXo=o(" \u2014 "),ZQ=a("a"),fXo=o("CTRLLMHeadModel"),gXo=o(" (CTRL model)"),hXo=l(),lb=a("li"),lve=a("strong"),uXo=o("data2vec-text"),pXo=o(" \u2014 "),KQ=a("a"),_Xo=o("Data2VecTextForMaskedLM"),bXo=o(" (Data2VecText model)"),vXo=l(),ib=a("li"),ive=a("strong"),FXo=o("deberta"),TXo=o(" \u2014 "),eW=a("a"),MXo=o("DebertaForMaskedLM"),EXo=o(" (DeBERTa model)"),CXo=l(),db=a("li"),dve=a("strong"),wXo=o("deberta-v2"),AXo=o(" \u2014 "),oW=a("a"),LXo=o("DebertaV2ForMaskedLM"),yXo=o(" (DeBERTa-v2 model)"),xXo=l(),mb=a("li"),mve=a("strong"),$Xo=o("distilbert"),kXo=o(" \u2014 "),rW=a("a"),SXo=o("DistilBertForMaskedLM"),RXo=o(" (DistilBERT model)"),PXo=l(),cb=a("li"),cve=a("strong"),BXo=o("electra"),IXo=o(" \u2014 "),tW=a("a"),NXo=o("ElectraForPreTraining"),qXo=o(" (ELECTRA model)"),jXo=l(),fb=a("li"),fve=a("strong"),DXo=o("ernie"),GXo=o(" \u2014 "),aW=a("a"),OXo=o("ErnieForPreTraining"),VXo=o(" (ERNIE model)"),XXo=l(),gb=a("li"),gve=a("strong"),zXo=o("flaubert"),QXo=o(" \u2014 "),nW=a("a"),WXo=o("FlaubertWithLMHeadModel"),UXo=o(" (FlauBERT model)"),HXo=l(),hb=a("li"),hve=a("strong"),JXo=o("flava"),YXo=o(" \u2014 "),sW=a("a"),ZXo=o("FlavaForPreTraining"),KXo=o(" (FLAVA model)"),ezo=l(),ub=a("li"),uve=a("strong"),ozo=o("fnet"),rzo=o(" \u2014 "),lW=a("a"),tzo=o("FNetForPreTraining"),azo=o(" (FNet model)"),nzo=l(),pb=a("li"),pve=a("strong"),szo=o("fsmt"),lzo=o(" \u2014 "),iW=a("a"),izo=o("FSMTForConditionalGeneration"),dzo=o(" (FairSeq Machine-Translation model)"),mzo=l(),_b=a("li"),_ve=a("strong"),czo=o("funnel"),fzo=o(" \u2014 "),dW=a("a"),gzo=o("FunnelForPreTraining"),hzo=o(" (Funnel Transformer model)"),uzo=l(),bb=a("li"),bve=a("strong"),pzo=o("gpt2"),_zo=o(" \u2014 "),mW=a("a"),bzo=o("GPT2LMHeadModel"),vzo=o(" (OpenAI GPT-2 model)"),Fzo=l(),vb=a("li"),vve=a("strong"),Tzo=o("ibert"),Mzo=o(" \u2014 "),cW=a("a"),Ezo=o("IBertForMaskedLM"),Czo=o(" (I-BERT model)"),wzo=l(),Fb=a("li"),Fve=a("strong"),Azo=o("layoutlm"),Lzo=o(" \u2014 "),fW=a("a"),yzo=o("LayoutLMForMaskedLM"),xzo=o(" (LayoutLM model)"),$zo=l(),Tb=a("li"),Tve=a("strong"),kzo=o("longformer"),Szo=o(" \u2014 "),gW=a("a"),Rzo=o("LongformerForMaskedLM"),Pzo=o(" (Longformer model)"),Bzo=l(),Mb=a("li"),Mve=a("strong"),Izo=o("luke"),Nzo=o(" \u2014 "),hW=a("a"),qzo=o("LukeForMaskedLM"),jzo=o(" (LUKE model)"),Dzo=l(),Eb=a("li"),Eve=a("strong"),Gzo=o("lxmert"),Ozo=o(" \u2014 "),uW=a("a"),Vzo=o("LxmertForPreTraining"),Xzo=o(" (LXMERT model)"),zzo=l(),Cb=a("li"),Cve=a("strong"),Qzo=o("megatron-bert"),Wzo=o(" \u2014 "),pW=a("a"),Uzo=o("MegatronBertForPreTraining"),Hzo=o(" (Megatron-BERT model)"),Jzo=l(),wb=a("li"),wve=a("strong"),Yzo=o("mobilebert"),Zzo=o(" \u2014 "),_W=a("a"),Kzo=o("MobileBertForPreTraining"),eQo=o(" (MobileBERT model)"),oQo=l(),Ab=a("li"),Ave=a("strong"),rQo=o("mpnet"),tQo=o(" \u2014 "),bW=a("a"),aQo=o("MPNetForMaskedLM"),nQo=o(" (MPNet model)"),sQo=l(),Lb=a("li"),Lve=a("strong"),lQo=o("mvp"),iQo=o(" \u2014 "),vW=a("a"),dQo=o("MvpForConditionalGeneration"),mQo=o(" (MVP model)"),cQo=l(),yb=a("li"),yve=a("strong"),fQo=o("nezha"),gQo=o(" \u2014 "),FW=a("a"),hQo=o("NezhaForPreTraining"),uQo=o(" (Nezha model)"),pQo=l(),xb=a("li"),xve=a("strong"),_Qo=o("openai-gpt"),bQo=o(" \u2014 "),TW=a("a"),vQo=o("OpenAIGPTLMHeadModel"),FQo=o(" (OpenAI GPT model)"),TQo=l(),$b=a("li"),$ve=a("strong"),MQo=o("retribert"),EQo=o(" \u2014 "),MW=a("a"),CQo=o("RetriBertModel"),wQo=o(" (RetriBERT model)"),AQo=l(),kb=a("li"),kve=a("strong"),LQo=o("roberta"),yQo=o(" \u2014 "),EW=a("a"),xQo=o("RobertaForMaskedLM"),$Qo=o(" (RoBERTa model)"),kQo=l(),Sb=a("li"),Sve=a("strong"),SQo=o("splinter"),RQo=o(" \u2014 "),CW=a("a"),PQo=o("SplinterForPreTraining"),BQo=o(" (Splinter model)"),IQo=l(),Rb=a("li"),Rve=a("strong"),NQo=o("squeezebert"),qQo=o(" \u2014 "),wW=a("a"),jQo=o("SqueezeBertForMaskedLM"),DQo=o(" (SqueezeBERT model)"),GQo=l(),Pb=a("li"),Pve=a("strong"),OQo=o("t5"),VQo=o(" \u2014 "),AW=a("a"),XQo=o("T5ForConditionalGeneration"),zQo=o(" (T5 model)"),QQo=l(),Bb=a("li"),Bve=a("strong"),WQo=o("tapas"),UQo=o(" \u2014 "),LW=a("a"),HQo=o("TapasForMaskedLM"),JQo=o(" (TAPAS model)"),YQo=l(),Ib=a("li"),Ive=a("strong"),ZQo=o("transfo-xl"),KQo=o(" \u2014 "),yW=a("a"),eWo=o("TransfoXLLMHeadModel"),oWo=o(" (Transformer-XL model)"),rWo=l(),Nb=a("li"),Nve=a("strong"),tWo=o("unispeech"),aWo=o(" \u2014 "),xW=a("a"),nWo=o("UniSpeechForPreTraining"),sWo=o(" (UniSpeech model)"),lWo=l(),qb=a("li"),qve=a("strong"),iWo=o("unispeech-sat"),dWo=o(" \u2014 "),$W=a("a"),mWo=o("UniSpeechSatForPreTraining"),cWo=o(" (UniSpeechSat model)"),fWo=l(),jb=a("li"),jve=a("strong"),gWo=o("videomae"),hWo=o(" \u2014 "),kW=a("a"),uWo=o("VideoMAEForPreTraining"),pWo=o(" (VideoMAE model)"),_Wo=l(),Db=a("li"),Dve=a("strong"),bWo=o("visual_bert"),vWo=o(" \u2014 "),SW=a("a"),FWo=o("VisualBertForPreTraining"),TWo=o(" (VisualBERT model)"),MWo=l(),Gb=a("li"),Gve=a("strong"),EWo=o("vit_mae"),CWo=o(" \u2014 "),RW=a("a"),wWo=o("ViTMAEForPreTraining"),AWo=o(" (ViTMAE model)"),LWo=l(),Ob=a("li"),Ove=a("strong"),yWo=o("wav2vec2"),xWo=o(" \u2014 "),PW=a("a"),$Wo=o("Wav2Vec2ForPreTraining"),kWo=o(" (Wav2Vec2 model)"),SWo=l(),Vb=a("li"),Vve=a("strong"),RWo=o("wav2vec2-conformer"),PWo=o(" \u2014 "),BW=a("a"),BWo=o("Wav2Vec2ConformerForPreTraining"),IWo=o(" (Wav2Vec2-Conformer model)"),NWo=l(),Xb=a("li"),Xve=a("strong"),qWo=o("xlm"),jWo=o(" \u2014 "),IW=a("a"),DWo=o("XLMWithLMHeadModel"),GWo=o(" (XLM model)"),OWo=l(),zb=a("li"),zve=a("strong"),VWo=o("xlm-roberta"),XWo=o(" \u2014 "),NW=a("a"),zWo=o("XLMRobertaForMaskedLM"),QWo=o(" (XLM-RoBERTa model)"),WWo=l(),Qb=a("li"),Qve=a("strong"),UWo=o("xlm-roberta-xl"),HWo=o(" \u2014 "),qW=a("a"),JWo=o("XLMRobertaXLForMaskedLM"),YWo=o(" (XLM-RoBERTa-XL model)"),ZWo=l(),Wb=a("li"),Wve=a("strong"),KWo=o("xlnet"),eUo=o(" \u2014 "),jW=a("a"),oUo=o("XLNetLMHeadModel"),rUo=o(" (XLNet model)"),tUo=l(),Ub=a("p"),aUo=o("The model is set in evaluation mode by default using "),Uve=a("code"),nUo=o("model.eval()"),sUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hve=a("code"),lUo=o("model.train()"),iUo=l(),F(Hb.$$.fragment),wto=l(),Id=a("h2"),Jb=a("a"),Jve=a("span"),F(G$.$$.fragment),dUo=l(),Yve=a("span"),mUo=o("AutoModelForCausalLM"),Ato=l(),qo=a("div"),F(O$.$$.fragment),cUo=l(),Nd=a("p"),fUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),DW=a("a"),gUo=o("from_pretrained()"),hUo=o(" class method or the "),GW=a("a"),uUo=o("from_config()"),pUo=o(` class
method.`),_Uo=l(),V$=a("p"),bUo=o("This class cannot be instantiated directly using "),Zve=a("code"),vUo=o("__init__()"),FUo=o(" (throws an error)."),TUo=l(),Et=a("div"),F(X$.$$.fragment),MUo=l(),Kve=a("p"),EUo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),CUo=l(),qd=a("p"),wUo=o(`Note:
Loading a model from its configuration file does `),eFe=a("strong"),AUo=o("not"),LUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=a("a"),yUo=o("from_pretrained()"),xUo=o(" to load the model weights."),$Uo=l(),F(Yb.$$.fragment),kUo=l(),oo=a("div"),F(z$.$$.fragment),SUo=l(),oFe=a("p"),RUo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),PUo=l(),sn=a("p"),BUo=o("The model class to instantiate is selected based on the "),rFe=a("code"),IUo=o("model_type"),NUo=o(` property of the config object (either
passed as an argument or loaded from `),tFe=a("code"),qUo=o("pretrained_model_name_or_path"),jUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aFe=a("code"),DUo=o("pretrained_model_name_or_path"),GUo=o(":"),OUo=l(),Q=a("ul"),Zb=a("li"),nFe=a("strong"),VUo=o("bart"),XUo=o(" \u2014 "),VW=a("a"),zUo=o("BartForCausalLM"),QUo=o(" (BART model)"),WUo=l(),Kb=a("li"),sFe=a("strong"),UUo=o("bert"),HUo=o(" \u2014 "),XW=a("a"),JUo=o("BertLMHeadModel"),YUo=o(" (BERT model)"),ZUo=l(),ev=a("li"),lFe=a("strong"),KUo=o("bert-generation"),eHo=o(" \u2014 "),zW=a("a"),oHo=o("BertGenerationDecoder"),rHo=o(" (Bert Generation model)"),tHo=l(),ov=a("li"),iFe=a("strong"),aHo=o("big_bird"),nHo=o(" \u2014 "),QW=a("a"),sHo=o("BigBirdForCausalLM"),lHo=o(" (BigBird model)"),iHo=l(),rv=a("li"),dFe=a("strong"),dHo=o("bigbird_pegasus"),mHo=o(" \u2014 "),WW=a("a"),cHo=o("BigBirdPegasusForCausalLM"),fHo=o(" (BigBird-Pegasus model)"),gHo=l(),tv=a("li"),mFe=a("strong"),hHo=o("blenderbot"),uHo=o(" \u2014 "),UW=a("a"),pHo=o("BlenderbotForCausalLM"),_Ho=o(" (Blenderbot model)"),bHo=l(),av=a("li"),cFe=a("strong"),vHo=o("blenderbot-small"),FHo=o(" \u2014 "),HW=a("a"),THo=o("BlenderbotSmallForCausalLM"),MHo=o(" (BlenderbotSmall model)"),EHo=l(),nv=a("li"),fFe=a("strong"),CHo=o("bloom"),wHo=o(" \u2014 "),JW=a("a"),AHo=o("BloomForCausalLM"),LHo=o(" (BLOOM model)"),yHo=l(),sv=a("li"),gFe=a("strong"),xHo=o("camembert"),$Ho=o(" \u2014 "),YW=a("a"),kHo=o("CamembertForCausalLM"),SHo=o(" (CamemBERT model)"),RHo=l(),lv=a("li"),hFe=a("strong"),PHo=o("codegen"),BHo=o(" \u2014 "),ZW=a("a"),IHo=o("CodeGenForCausalLM"),NHo=o(" (CodeGen model)"),qHo=l(),iv=a("li"),uFe=a("strong"),jHo=o("ctrl"),DHo=o(" \u2014 "),KW=a("a"),GHo=o("CTRLLMHeadModel"),OHo=o(" (CTRL model)"),VHo=l(),dv=a("li"),pFe=a("strong"),XHo=o("data2vec-text"),zHo=o(" \u2014 "),eU=a("a"),QHo=o("Data2VecTextForCausalLM"),WHo=o(" (Data2VecText model)"),UHo=l(),mv=a("li"),_Fe=a("strong"),HHo=o("electra"),JHo=o(" \u2014 "),oU=a("a"),YHo=o("ElectraForCausalLM"),ZHo=o(" (ELECTRA model)"),KHo=l(),cv=a("li"),bFe=a("strong"),eJo=o("ernie"),oJo=o(" \u2014 "),rU=a("a"),rJo=o("ErnieForCausalLM"),tJo=o(" (ERNIE model)"),aJo=l(),fv=a("li"),vFe=a("strong"),nJo=o("gpt2"),sJo=o(" \u2014 "),tU=a("a"),lJo=o("GPT2LMHeadModel"),iJo=o(" (OpenAI GPT-2 model)"),dJo=l(),gv=a("li"),FFe=a("strong"),mJo=o("gpt_neo"),cJo=o(" \u2014 "),aU=a("a"),fJo=o("GPTNeoForCausalLM"),gJo=o(" (GPT Neo model)"),hJo=l(),hv=a("li"),TFe=a("strong"),uJo=o("gpt_neox"),pJo=o(" \u2014 "),nU=a("a"),_Jo=o("GPTNeoXForCausalLM"),bJo=o(" (GPT NeoX model)"),vJo=l(),uv=a("li"),MFe=a("strong"),FJo=o("gpt_neox_japanese"),TJo=o(" \u2014 "),sU=a("a"),MJo=o("GPTNeoXJapaneseForCausalLM"),EJo=o(" (GPT NeoX Japanese model)"),CJo=l(),pv=a("li"),EFe=a("strong"),wJo=o("gptj"),AJo=o(" \u2014 "),lU=a("a"),LJo=o("GPTJForCausalLM"),yJo=o(" (GPT-J model)"),xJo=l(),_v=a("li"),CFe=a("strong"),$Jo=o("marian"),kJo=o(" \u2014 "),iU=a("a"),SJo=o("MarianForCausalLM"),RJo=o(" (Marian model)"),PJo=l(),bv=a("li"),wFe=a("strong"),BJo=o("mbart"),IJo=o(" \u2014 "),dU=a("a"),NJo=o("MBartForCausalLM"),qJo=o(" (mBART model)"),jJo=l(),vv=a("li"),AFe=a("strong"),DJo=o("megatron-bert"),GJo=o(" \u2014 "),mU=a("a"),OJo=o("MegatronBertForCausalLM"),VJo=o(" (Megatron-BERT model)"),XJo=l(),Fv=a("li"),LFe=a("strong"),zJo=o("mvp"),QJo=o(" \u2014 "),cU=a("a"),WJo=o("MvpForCausalLM"),UJo=o(" (MVP model)"),HJo=l(),Tv=a("li"),yFe=a("strong"),JJo=o("openai-gpt"),YJo=o(" \u2014 "),fU=a("a"),ZJo=o("OpenAIGPTLMHeadModel"),KJo=o(" (OpenAI GPT model)"),eYo=l(),Mv=a("li"),xFe=a("strong"),oYo=o("opt"),rYo=o(" \u2014 "),gU=a("a"),tYo=o("OPTForCausalLM"),aYo=o(" (OPT model)"),nYo=l(),Ev=a("li"),$Fe=a("strong"),sYo=o("pegasus"),lYo=o(" \u2014 "),hU=a("a"),iYo=o("PegasusForCausalLM"),dYo=o(" (Pegasus model)"),mYo=l(),Cv=a("li"),kFe=a("strong"),cYo=o("plbart"),fYo=o(" \u2014 "),uU=a("a"),gYo=o("PLBartForCausalLM"),hYo=o(" (PLBart model)"),uYo=l(),wv=a("li"),SFe=a("strong"),pYo=o("prophetnet"),_Yo=o(" \u2014 "),pU=a("a"),bYo=o("ProphetNetForCausalLM"),vYo=o(" (ProphetNet model)"),FYo=l(),Av=a("li"),RFe=a("strong"),TYo=o("qdqbert"),MYo=o(" \u2014 "),_U=a("a"),EYo=o("QDQBertLMHeadModel"),CYo=o(" (QDQBert model)"),wYo=l(),Lv=a("li"),PFe=a("strong"),AYo=o("reformer"),LYo=o(" \u2014 "),bU=a("a"),yYo=o("ReformerModelWithLMHead"),xYo=o(" (Reformer model)"),$Yo=l(),yv=a("li"),BFe=a("strong"),kYo=o("rembert"),SYo=o(" \u2014 "),vU=a("a"),RYo=o("RemBertForCausalLM"),PYo=o(" (RemBERT model)"),BYo=l(),xv=a("li"),IFe=a("strong"),IYo=o("roberta"),NYo=o(" \u2014 "),FU=a("a"),qYo=o("RobertaForCausalLM"),jYo=o(" (RoBERTa model)"),DYo=l(),$v=a("li"),NFe=a("strong"),GYo=o("roformer"),OYo=o(" \u2014 "),TU=a("a"),VYo=o("RoFormerForCausalLM"),XYo=o(" (RoFormer model)"),zYo=l(),kv=a("li"),qFe=a("strong"),QYo=o("speech_to_text_2"),WYo=o(" \u2014 "),MU=a("a"),UYo=o("Speech2Text2ForCausalLM"),HYo=o(" (Speech2Text2 model)"),JYo=l(),Sv=a("li"),jFe=a("strong"),YYo=o("transfo-xl"),ZYo=o(" \u2014 "),EU=a("a"),KYo=o("TransfoXLLMHeadModel"),eZo=o(" (Transformer-XL model)"),oZo=l(),Rv=a("li"),DFe=a("strong"),rZo=o("trocr"),tZo=o(" \u2014 "),CU=a("a"),aZo=o("TrOCRForCausalLM"),nZo=o(" (TrOCR model)"),sZo=l(),Pv=a("li"),GFe=a("strong"),lZo=o("xglm"),iZo=o(" \u2014 "),wU=a("a"),dZo=o("XGLMForCausalLM"),mZo=o(" (XGLM model)"),cZo=l(),Bv=a("li"),OFe=a("strong"),fZo=o("xlm"),gZo=o(" \u2014 "),AU=a("a"),hZo=o("XLMWithLMHeadModel"),uZo=o(" (XLM model)"),pZo=l(),Iv=a("li"),VFe=a("strong"),_Zo=o("xlm-prophetnet"),bZo=o(" \u2014 "),LU=a("a"),vZo=o("XLMProphetNetForCausalLM"),FZo=o(" (XLM-ProphetNet model)"),TZo=l(),Nv=a("li"),XFe=a("strong"),MZo=o("xlm-roberta"),EZo=o(" \u2014 "),yU=a("a"),CZo=o("XLMRobertaForCausalLM"),wZo=o(" (XLM-RoBERTa model)"),AZo=l(),qv=a("li"),zFe=a("strong"),LZo=o("xlm-roberta-xl"),yZo=o(" \u2014 "),xU=a("a"),xZo=o("XLMRobertaXLForCausalLM"),$Zo=o(" (XLM-RoBERTa-XL model)"),kZo=l(),jv=a("li"),QFe=a("strong"),SZo=o("xlnet"),RZo=o(" \u2014 "),$U=a("a"),PZo=o("XLNetLMHeadModel"),BZo=o(" (XLNet model)"),IZo=l(),Dv=a("p"),NZo=o("The model is set in evaluation mode by default using "),WFe=a("code"),qZo=o("model.eval()"),jZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UFe=a("code"),DZo=o("model.train()"),GZo=l(),F(Gv.$$.fragment),Lto=l(),jd=a("h2"),Ov=a("a"),HFe=a("span"),F(Q$.$$.fragment),OZo=l(),JFe=a("span"),VZo=o("AutoModelForDepthEstimation"),yto=l(),jo=a("div"),F(W$.$$.fragment),XZo=l(),Dd=a("p"),zZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),kU=a("a"),QZo=o("from_pretrained()"),WZo=o(" class method or the "),SU=a("a"),UZo=o("from_config()"),HZo=o(` class
method.`),JZo=l(),U$=a("p"),YZo=o("This class cannot be instantiated directly using "),YFe=a("code"),ZZo=o("__init__()"),KZo=o(" (throws an error)."),eKo=l(),Ct=a("div"),F(H$.$$.fragment),oKo=l(),ZFe=a("p"),rKo=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),tKo=l(),Gd=a("p"),aKo=o(`Note:
Loading a model from its configuration file does `),KFe=a("strong"),nKo=o("not"),sKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=a("a"),lKo=o("from_pretrained()"),iKo=o(" to load the model weights."),dKo=l(),F(Vv.$$.fragment),mKo=l(),ro=a("div"),F(J$.$$.fragment),cKo=l(),eTe=a("p"),fKo=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),gKo=l(),ln=a("p"),hKo=o("The model class to instantiate is selected based on the "),oTe=a("code"),uKo=o("model_type"),pKo=o(` property of the config object (either
passed as an argument or loaded from `),rTe=a("code"),_Ko=o("pretrained_model_name_or_path"),bKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tTe=a("code"),vKo=o("pretrained_model_name_or_path"),FKo=o(":"),TKo=l(),Y$=a("ul"),Xv=a("li"),aTe=a("strong"),MKo=o("dpt"),EKo=o(" \u2014 "),PU=a("a"),CKo=o("DPTForDepthEstimation"),wKo=o(" (DPT model)"),AKo=l(),zv=a("li"),nTe=a("strong"),LKo=o("glpn"),yKo=o(" \u2014 "),BU=a("a"),xKo=o("GLPNForDepthEstimation"),$Ko=o(" (GLPN model)"),kKo=l(),Qv=a("p"),SKo=o("The model is set in evaluation mode by default using "),sTe=a("code"),RKo=o("model.eval()"),PKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lTe=a("code"),BKo=o("model.train()"),IKo=l(),F(Wv.$$.fragment),xto=l(),Od=a("h2"),Uv=a("a"),iTe=a("span"),F(Z$.$$.fragment),NKo=l(),dTe=a("span"),qKo=o("AutoModelForMaskedLM"),$to=l(),Do=a("div"),F(K$.$$.fragment),jKo=l(),Vd=a("p"),DKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),IU=a("a"),GKo=o("from_pretrained()"),OKo=o(" class method or the "),NU=a("a"),VKo=o("from_config()"),XKo=o(` class
method.`),zKo=l(),ek=a("p"),QKo=o("This class cannot be instantiated directly using "),mTe=a("code"),WKo=o("__init__()"),UKo=o(" (throws an error)."),HKo=l(),wt=a("div"),F(ok.$$.fragment),JKo=l(),cTe=a("p"),YKo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ZKo=l(),Xd=a("p"),KKo=o(`Note:
Loading a model from its configuration file does `),fTe=a("strong"),eer=o("not"),oer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=a("a"),rer=o("from_pretrained()"),ter=o(" to load the model weights."),aer=l(),F(Hv.$$.fragment),ner=l(),to=a("div"),F(rk.$$.fragment),ser=l(),gTe=a("p"),ler=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ier=l(),dn=a("p"),der=o("The model class to instantiate is selected based on the "),hTe=a("code"),mer=o("model_type"),cer=o(` property of the config object (either
passed as an argument or loaded from `),uTe=a("code"),fer=o("pretrained_model_name_or_path"),ger=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=a("code"),her=o("pretrained_model_name_or_path"),uer=o(":"),per=l(),Y=a("ul"),Jv=a("li"),_Te=a("strong"),_er=o("albert"),ber=o(" \u2014 "),jU=a("a"),ver=o("AlbertForMaskedLM"),Fer=o(" (ALBERT model)"),Ter=l(),Yv=a("li"),bTe=a("strong"),Mer=o("bart"),Eer=o(" \u2014 "),DU=a("a"),Cer=o("BartForConditionalGeneration"),wer=o(" (BART model)"),Aer=l(),Zv=a("li"),vTe=a("strong"),Ler=o("bert"),yer=o(" \u2014 "),GU=a("a"),xer=o("BertForMaskedLM"),$er=o(" (BERT model)"),ker=l(),Kv=a("li"),FTe=a("strong"),Ser=o("big_bird"),Rer=o(" \u2014 "),OU=a("a"),Per=o("BigBirdForMaskedLM"),Ber=o(" (BigBird model)"),Ier=l(),eF=a("li"),TTe=a("strong"),Ner=o("camembert"),qer=o(" \u2014 "),VU=a("a"),jer=o("CamembertForMaskedLM"),Der=o(" (CamemBERT model)"),Ger=l(),oF=a("li"),MTe=a("strong"),Oer=o("convbert"),Ver=o(" \u2014 "),XU=a("a"),Xer=o("ConvBertForMaskedLM"),zer=o(" (ConvBERT model)"),Qer=l(),rF=a("li"),ETe=a("strong"),Wer=o("data2vec-text"),Uer=o(" \u2014 "),zU=a("a"),Her=o("Data2VecTextForMaskedLM"),Jer=o(" (Data2VecText model)"),Yer=l(),tF=a("li"),CTe=a("strong"),Zer=o("deberta"),Ker=o(" \u2014 "),QU=a("a"),eor=o("DebertaForMaskedLM"),oor=o(" (DeBERTa model)"),ror=l(),aF=a("li"),wTe=a("strong"),tor=o("deberta-v2"),aor=o(" \u2014 "),WU=a("a"),nor=o("DebertaV2ForMaskedLM"),sor=o(" (DeBERTa-v2 model)"),lor=l(),nF=a("li"),ATe=a("strong"),ior=o("distilbert"),dor=o(" \u2014 "),UU=a("a"),mor=o("DistilBertForMaskedLM"),cor=o(" (DistilBERT model)"),gor=l(),sF=a("li"),LTe=a("strong"),hor=o("electra"),uor=o(" \u2014 "),HU=a("a"),por=o("ElectraForMaskedLM"),_or=o(" (ELECTRA model)"),bor=l(),lF=a("li"),yTe=a("strong"),vor=o("ernie"),For=o(" \u2014 "),JU=a("a"),Tor=o("ErnieForMaskedLM"),Mor=o(" (ERNIE model)"),Eor=l(),iF=a("li"),xTe=a("strong"),Cor=o("flaubert"),wor=o(" \u2014 "),YU=a("a"),Aor=o("FlaubertWithLMHeadModel"),Lor=o(" (FlauBERT model)"),yor=l(),dF=a("li"),$Te=a("strong"),xor=o("fnet"),$or=o(" \u2014 "),ZU=a("a"),kor=o("FNetForMaskedLM"),Sor=o(" (FNet model)"),Ror=l(),mF=a("li"),kTe=a("strong"),Por=o("funnel"),Bor=o(" \u2014 "),KU=a("a"),Ior=o("FunnelForMaskedLM"),Nor=o(" (Funnel Transformer model)"),qor=l(),cF=a("li"),STe=a("strong"),jor=o("ibert"),Dor=o(" \u2014 "),eH=a("a"),Gor=o("IBertForMaskedLM"),Oor=o(" (I-BERT model)"),Vor=l(),fF=a("li"),RTe=a("strong"),Xor=o("layoutlm"),zor=o(" \u2014 "),oH=a("a"),Qor=o("LayoutLMForMaskedLM"),Wor=o(" (LayoutLM model)"),Uor=l(),gF=a("li"),PTe=a("strong"),Hor=o("longformer"),Jor=o(" \u2014 "),rH=a("a"),Yor=o("LongformerForMaskedLM"),Zor=o(" (Longformer model)"),Kor=l(),hF=a("li"),BTe=a("strong"),err=o("luke"),orr=o(" \u2014 "),tH=a("a"),rrr=o("LukeForMaskedLM"),trr=o(" (LUKE model)"),arr=l(),uF=a("li"),ITe=a("strong"),nrr=o("mbart"),srr=o(" \u2014 "),aH=a("a"),lrr=o("MBartForConditionalGeneration"),irr=o(" (mBART model)"),drr=l(),pF=a("li"),NTe=a("strong"),mrr=o("megatron-bert"),crr=o(" \u2014 "),nH=a("a"),frr=o("MegatronBertForMaskedLM"),grr=o(" (Megatron-BERT model)"),hrr=l(),_F=a("li"),qTe=a("strong"),urr=o("mobilebert"),prr=o(" \u2014 "),sH=a("a"),_rr=o("MobileBertForMaskedLM"),brr=o(" (MobileBERT model)"),vrr=l(),bF=a("li"),jTe=a("strong"),Frr=o("mpnet"),Trr=o(" \u2014 "),lH=a("a"),Mrr=o("MPNetForMaskedLM"),Err=o(" (MPNet model)"),Crr=l(),vF=a("li"),DTe=a("strong"),wrr=o("mvp"),Arr=o(" \u2014 "),iH=a("a"),Lrr=o("MvpForConditionalGeneration"),yrr=o(" (MVP model)"),xrr=l(),FF=a("li"),GTe=a("strong"),$rr=o("nezha"),krr=o(" \u2014 "),dH=a("a"),Srr=o("NezhaForMaskedLM"),Rrr=o(" (Nezha model)"),Prr=l(),TF=a("li"),OTe=a("strong"),Brr=o("nystromformer"),Irr=o(" \u2014 "),mH=a("a"),Nrr=o("NystromformerForMaskedLM"),qrr=o(" (Nystr\xF6mformer model)"),jrr=l(),MF=a("li"),VTe=a("strong"),Drr=o("perceiver"),Grr=o(" \u2014 "),cH=a("a"),Orr=o("PerceiverForMaskedLM"),Vrr=o(" (Perceiver model)"),Xrr=l(),EF=a("li"),XTe=a("strong"),zrr=o("qdqbert"),Qrr=o(" \u2014 "),fH=a("a"),Wrr=o("QDQBertForMaskedLM"),Urr=o(" (QDQBert model)"),Hrr=l(),CF=a("li"),zTe=a("strong"),Jrr=o("reformer"),Yrr=o(" \u2014 "),gH=a("a"),Zrr=o("ReformerForMaskedLM"),Krr=o(" (Reformer model)"),etr=l(),wF=a("li"),QTe=a("strong"),otr=o("rembert"),rtr=o(" \u2014 "),hH=a("a"),ttr=o("RemBertForMaskedLM"),atr=o(" (RemBERT model)"),ntr=l(),AF=a("li"),WTe=a("strong"),str=o("roberta"),ltr=o(" \u2014 "),uH=a("a"),itr=o("RobertaForMaskedLM"),dtr=o(" (RoBERTa model)"),mtr=l(),LF=a("li"),UTe=a("strong"),ctr=o("roformer"),ftr=o(" \u2014 "),pH=a("a"),gtr=o("RoFormerForMaskedLM"),htr=o(" (RoFormer model)"),utr=l(),yF=a("li"),HTe=a("strong"),ptr=o("squeezebert"),_tr=o(" \u2014 "),_H=a("a"),btr=o("SqueezeBertForMaskedLM"),vtr=o(" (SqueezeBERT model)"),Ftr=l(),xF=a("li"),JTe=a("strong"),Ttr=o("tapas"),Mtr=o(" \u2014 "),bH=a("a"),Etr=o("TapasForMaskedLM"),Ctr=o(" (TAPAS model)"),wtr=l(),$F=a("li"),YTe=a("strong"),Atr=o("wav2vec2"),Ltr=o(" \u2014 "),ZTe=a("code"),ytr=o("Wav2Vec2ForMaskedLM"),xtr=o(" (Wav2Vec2 model)"),$tr=l(),kF=a("li"),KTe=a("strong"),ktr=o("xlm"),Str=o(" \u2014 "),vH=a("a"),Rtr=o("XLMWithLMHeadModel"),Ptr=o(" (XLM model)"),Btr=l(),SF=a("li"),eMe=a("strong"),Itr=o("xlm-roberta"),Ntr=o(" \u2014 "),FH=a("a"),qtr=o("XLMRobertaForMaskedLM"),jtr=o(" (XLM-RoBERTa model)"),Dtr=l(),RF=a("li"),oMe=a("strong"),Gtr=o("xlm-roberta-xl"),Otr=o(" \u2014 "),TH=a("a"),Vtr=o("XLMRobertaXLForMaskedLM"),Xtr=o(" (XLM-RoBERTa-XL model)"),ztr=l(),PF=a("li"),rMe=a("strong"),Qtr=o("yoso"),Wtr=o(" \u2014 "),MH=a("a"),Utr=o("YosoForMaskedLM"),Htr=o(" (YOSO model)"),Jtr=l(),BF=a("p"),Ytr=o("The model is set in evaluation mode by default using "),tMe=a("code"),Ztr=o("model.eval()"),Ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aMe=a("code"),ear=o("model.train()"),oar=l(),F(IF.$$.fragment),kto=l(),zd=a("h2"),NF=a("a"),nMe=a("span"),F(tk.$$.fragment),rar=l(),sMe=a("span"),tar=o("AutoModelForSeq2SeqLM"),Sto=l(),Go=a("div"),F(ak.$$.fragment),aar=l(),Qd=a("p"),nar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EH=a("a"),sar=o("from_pretrained()"),lar=o(" class method or the "),CH=a("a"),iar=o("from_config()"),dar=o(` class
method.`),mar=l(),nk=a("p"),car=o("This class cannot be instantiated directly using "),lMe=a("code"),far=o("__init__()"),gar=o(" (throws an error)."),har=l(),At=a("div"),F(sk.$$.fragment),uar=l(),iMe=a("p"),par=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_ar=l(),Wd=a("p"),bar=o(`Note:
Loading a model from its configuration file does `),dMe=a("strong"),Far=o("not"),Tar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wH=a("a"),Mar=o("from_pretrained()"),Ear=o(" to load the model weights."),Car=l(),F(qF.$$.fragment),war=l(),ao=a("div"),F(lk.$$.fragment),Aar=l(),mMe=a("p"),Lar=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),yar=l(),mn=a("p"),xar=o("The model class to instantiate is selected based on the "),cMe=a("code"),$ar=o("model_type"),kar=o(` property of the config object (either
passed as an argument or loaded from `),fMe=a("code"),Sar=o("pretrained_model_name_or_path"),Rar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gMe=a("code"),Par=o("pretrained_model_name_or_path"),Bar=o(":"),Iar=l(),he=a("ul"),jF=a("li"),hMe=a("strong"),Nar=o("bart"),qar=o(" \u2014 "),AH=a("a"),jar=o("BartForConditionalGeneration"),Dar=o(" (BART model)"),Gar=l(),DF=a("li"),uMe=a("strong"),Oar=o("bigbird_pegasus"),Var=o(" \u2014 "),LH=a("a"),Xar=o("BigBirdPegasusForConditionalGeneration"),zar=o(" (BigBird-Pegasus model)"),Qar=l(),GF=a("li"),pMe=a("strong"),War=o("blenderbot"),Uar=o(" \u2014 "),yH=a("a"),Har=o("BlenderbotForConditionalGeneration"),Jar=o(" (Blenderbot model)"),Yar=l(),OF=a("li"),_Me=a("strong"),Zar=o("blenderbot-small"),Kar=o(" \u2014 "),xH=a("a"),enr=o("BlenderbotSmallForConditionalGeneration"),onr=o(" (BlenderbotSmall model)"),rnr=l(),VF=a("li"),bMe=a("strong"),tnr=o("encoder-decoder"),anr=o(" \u2014 "),$H=a("a"),nnr=o("EncoderDecoderModel"),snr=o(" (Encoder decoder model)"),lnr=l(),XF=a("li"),vMe=a("strong"),inr=o("fsmt"),dnr=o(" \u2014 "),kH=a("a"),mnr=o("FSMTForConditionalGeneration"),cnr=o(" (FairSeq Machine-Translation model)"),fnr=l(),zF=a("li"),FMe=a("strong"),gnr=o("led"),hnr=o(" \u2014 "),SH=a("a"),unr=o("LEDForConditionalGeneration"),pnr=o(" (LED model)"),_nr=l(),QF=a("li"),TMe=a("strong"),bnr=o("longt5"),vnr=o(" \u2014 "),RH=a("a"),Fnr=o("LongT5ForConditionalGeneration"),Tnr=o(" (LongT5 model)"),Mnr=l(),WF=a("li"),MMe=a("strong"),Enr=o("m2m_100"),Cnr=o(" \u2014 "),PH=a("a"),wnr=o("M2M100ForConditionalGeneration"),Anr=o(" (M2M100 model)"),Lnr=l(),UF=a("li"),EMe=a("strong"),ynr=o("marian"),xnr=o(" \u2014 "),BH=a("a"),$nr=o("MarianMTModel"),knr=o(" (Marian model)"),Snr=l(),HF=a("li"),CMe=a("strong"),Rnr=o("mbart"),Pnr=o(" \u2014 "),IH=a("a"),Bnr=o("MBartForConditionalGeneration"),Inr=o(" (mBART model)"),Nnr=l(),JF=a("li"),wMe=a("strong"),qnr=o("mt5"),jnr=o(" \u2014 "),NH=a("a"),Dnr=o("MT5ForConditionalGeneration"),Gnr=o(" (MT5 model)"),Onr=l(),YF=a("li"),AMe=a("strong"),Vnr=o("mvp"),Xnr=o(" \u2014 "),qH=a("a"),znr=o("MvpForConditionalGeneration"),Qnr=o(" (MVP model)"),Wnr=l(),ZF=a("li"),LMe=a("strong"),Unr=o("nllb"),Hnr=o(" \u2014 "),jH=a("a"),Jnr=o("M2M100ForConditionalGeneration"),Ynr=o(" (NLLB model)"),Znr=l(),KF=a("li"),yMe=a("strong"),Knr=o("pegasus"),esr=o(" \u2014 "),DH=a("a"),osr=o("PegasusForConditionalGeneration"),rsr=o(" (Pegasus model)"),tsr=l(),eT=a("li"),xMe=a("strong"),asr=o("pegasus_x"),nsr=o(" \u2014 "),GH=a("a"),ssr=o("PegasusXForConditionalGeneration"),lsr=o(" (PEGASUS-X model)"),isr=l(),oT=a("li"),$Me=a("strong"),dsr=o("plbart"),msr=o(" \u2014 "),OH=a("a"),csr=o("PLBartForConditionalGeneration"),fsr=o(" (PLBart model)"),gsr=l(),rT=a("li"),kMe=a("strong"),hsr=o("prophetnet"),usr=o(" \u2014 "),VH=a("a"),psr=o("ProphetNetForConditionalGeneration"),_sr=o(" (ProphetNet model)"),bsr=l(),tT=a("li"),SMe=a("strong"),vsr=o("t5"),Fsr=o(" \u2014 "),XH=a("a"),Tsr=o("T5ForConditionalGeneration"),Msr=o(" (T5 model)"),Esr=l(),aT=a("li"),RMe=a("strong"),Csr=o("xlm-prophetnet"),wsr=o(" \u2014 "),zH=a("a"),Asr=o("XLMProphetNetForConditionalGeneration"),Lsr=o(" (XLM-ProphetNet model)"),ysr=l(),nT=a("p"),xsr=o("The model is set in evaluation mode by default using "),PMe=a("code"),$sr=o("model.eval()"),ksr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),BMe=a("code"),Ssr=o("model.train()"),Rsr=l(),F(sT.$$.fragment),Rto=l(),Ud=a("h2"),lT=a("a"),IMe=a("span"),F(ik.$$.fragment),Psr=l(),NMe=a("span"),Bsr=o("AutoModelForSequenceClassification"),Pto=l(),Oo=a("div"),F(dk.$$.fragment),Isr=l(),Hd=a("p"),Nsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),QH=a("a"),qsr=o("from_pretrained()"),jsr=o(" class method or the "),WH=a("a"),Dsr=o("from_config()"),Gsr=o(` class
method.`),Osr=l(),mk=a("p"),Vsr=o("This class cannot be instantiated directly using "),qMe=a("code"),Xsr=o("__init__()"),zsr=o(" (throws an error)."),Qsr=l(),Lt=a("div"),F(ck.$$.fragment),Wsr=l(),jMe=a("p"),Usr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hsr=l(),Jd=a("p"),Jsr=o(`Note:
Loading a model from its configuration file does `),DMe=a("strong"),Ysr=o("not"),Zsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UH=a("a"),Ksr=o("from_pretrained()"),elr=o(" to load the model weights."),olr=l(),F(iT.$$.fragment),rlr=l(),no=a("div"),F(fk.$$.fragment),tlr=l(),GMe=a("p"),alr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nlr=l(),cn=a("p"),slr=o("The model class to instantiate is selected based on the "),OMe=a("code"),llr=o("model_type"),ilr=o(` property of the config object (either
passed as an argument or loaded from `),VMe=a("code"),dlr=o("pretrained_model_name_or_path"),mlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XMe=a("code"),clr=o("pretrained_model_name_or_path"),flr=o(":"),glr=l(),j=a("ul"),dT=a("li"),zMe=a("strong"),hlr=o("albert"),ulr=o(" \u2014 "),HH=a("a"),plr=o("AlbertForSequenceClassification"),_lr=o(" (ALBERT model)"),blr=l(),mT=a("li"),QMe=a("strong"),vlr=o("bart"),Flr=o(" \u2014 "),JH=a("a"),Tlr=o("BartForSequenceClassification"),Mlr=o(" (BART model)"),Elr=l(),cT=a("li"),WMe=a("strong"),Clr=o("bert"),wlr=o(" \u2014 "),YH=a("a"),Alr=o("BertForSequenceClassification"),Llr=o(" (BERT model)"),ylr=l(),fT=a("li"),UMe=a("strong"),xlr=o("big_bird"),$lr=o(" \u2014 "),ZH=a("a"),klr=o("BigBirdForSequenceClassification"),Slr=o(" (BigBird model)"),Rlr=l(),gT=a("li"),HMe=a("strong"),Plr=o("bigbird_pegasus"),Blr=o(" \u2014 "),KH=a("a"),Ilr=o("BigBirdPegasusForSequenceClassification"),Nlr=o(" (BigBird-Pegasus model)"),qlr=l(),hT=a("li"),JMe=a("strong"),jlr=o("bloom"),Dlr=o(" \u2014 "),eJ=a("a"),Glr=o("BloomForSequenceClassification"),Olr=o(" (BLOOM model)"),Vlr=l(),uT=a("li"),YMe=a("strong"),Xlr=o("camembert"),zlr=o(" \u2014 "),oJ=a("a"),Qlr=o("CamembertForSequenceClassification"),Wlr=o(" (CamemBERT model)"),Ulr=l(),pT=a("li"),ZMe=a("strong"),Hlr=o("canine"),Jlr=o(" \u2014 "),rJ=a("a"),Ylr=o("CanineForSequenceClassification"),Zlr=o(" (CANINE model)"),Klr=l(),_T=a("li"),KMe=a("strong"),eir=o("convbert"),oir=o(" \u2014 "),tJ=a("a"),rir=o("ConvBertForSequenceClassification"),tir=o(" (ConvBERT model)"),air=l(),bT=a("li"),eEe=a("strong"),nir=o("ctrl"),sir=o(" \u2014 "),aJ=a("a"),lir=o("CTRLForSequenceClassification"),iir=o(" (CTRL model)"),dir=l(),vT=a("li"),oEe=a("strong"),mir=o("data2vec-text"),cir=o(" \u2014 "),nJ=a("a"),fir=o("Data2VecTextForSequenceClassification"),gir=o(" (Data2VecText model)"),hir=l(),FT=a("li"),rEe=a("strong"),uir=o("deberta"),pir=o(" \u2014 "),sJ=a("a"),_ir=o("DebertaForSequenceClassification"),bir=o(" (DeBERTa model)"),vir=l(),TT=a("li"),tEe=a("strong"),Fir=o("deberta-v2"),Tir=o(" \u2014 "),lJ=a("a"),Mir=o("DebertaV2ForSequenceClassification"),Eir=o(" (DeBERTa-v2 model)"),Cir=l(),MT=a("li"),aEe=a("strong"),wir=o("distilbert"),Air=o(" \u2014 "),iJ=a("a"),Lir=o("DistilBertForSequenceClassification"),yir=o(" (DistilBERT model)"),xir=l(),ET=a("li"),nEe=a("strong"),$ir=o("electra"),kir=o(" \u2014 "),dJ=a("a"),Sir=o("ElectraForSequenceClassification"),Rir=o(" (ELECTRA model)"),Pir=l(),CT=a("li"),sEe=a("strong"),Bir=o("ernie"),Iir=o(" \u2014 "),mJ=a("a"),Nir=o("ErnieForSequenceClassification"),qir=o(" (ERNIE model)"),jir=l(),wT=a("li"),lEe=a("strong"),Dir=o("esm"),Gir=o(" \u2014 "),cJ=a("a"),Oir=o("EsmForSequenceClassification"),Vir=o(" (ESM model)"),Xir=l(),AT=a("li"),iEe=a("strong"),zir=o("flaubert"),Qir=o(" \u2014 "),fJ=a("a"),Wir=o("FlaubertForSequenceClassification"),Uir=o(" (FlauBERT model)"),Hir=l(),LT=a("li"),dEe=a("strong"),Jir=o("fnet"),Yir=o(" \u2014 "),gJ=a("a"),Zir=o("FNetForSequenceClassification"),Kir=o(" (FNet model)"),edr=l(),yT=a("li"),mEe=a("strong"),odr=o("funnel"),rdr=o(" \u2014 "),hJ=a("a"),tdr=o("FunnelForSequenceClassification"),adr=o(" (Funnel Transformer model)"),ndr=l(),xT=a("li"),cEe=a("strong"),sdr=o("gpt2"),ldr=o(" \u2014 "),uJ=a("a"),idr=o("GPT2ForSequenceClassification"),ddr=o(" (OpenAI GPT-2 model)"),mdr=l(),$T=a("li"),fEe=a("strong"),cdr=o("gpt_neo"),fdr=o(" \u2014 "),pJ=a("a"),gdr=o("GPTNeoForSequenceClassification"),hdr=o(" (GPT Neo model)"),udr=l(),kT=a("li"),gEe=a("strong"),pdr=o("gptj"),_dr=o(" \u2014 "),_J=a("a"),bdr=o("GPTJForSequenceClassification"),vdr=o(" (GPT-J model)"),Fdr=l(),ST=a("li"),hEe=a("strong"),Tdr=o("ibert"),Mdr=o(" \u2014 "),bJ=a("a"),Edr=o("IBertForSequenceClassification"),Cdr=o(" (I-BERT model)"),wdr=l(),RT=a("li"),uEe=a("strong"),Adr=o("layoutlm"),Ldr=o(" \u2014 "),vJ=a("a"),ydr=o("LayoutLMForSequenceClassification"),xdr=o(" (LayoutLM model)"),$dr=l(),PT=a("li"),pEe=a("strong"),kdr=o("layoutlmv2"),Sdr=o(" \u2014 "),FJ=a("a"),Rdr=o("LayoutLMv2ForSequenceClassification"),Pdr=o(" (LayoutLMv2 model)"),Bdr=l(),BT=a("li"),_Ee=a("strong"),Idr=o("layoutlmv3"),Ndr=o(" \u2014 "),TJ=a("a"),qdr=o("LayoutLMv3ForSequenceClassification"),jdr=o(" (LayoutLMv3 model)"),Ddr=l(),IT=a("li"),bEe=a("strong"),Gdr=o("led"),Odr=o(" \u2014 "),MJ=a("a"),Vdr=o("LEDForSequenceClassification"),Xdr=o(" (LED model)"),zdr=l(),NT=a("li"),vEe=a("strong"),Qdr=o("lilt"),Wdr=o(" \u2014 "),EJ=a("a"),Udr=o("LiltForSequenceClassification"),Hdr=o(" (LiLT model)"),Jdr=l(),qT=a("li"),FEe=a("strong"),Ydr=o("longformer"),Zdr=o(" \u2014 "),CJ=a("a"),Kdr=o("LongformerForSequenceClassification"),emr=o(" (Longformer model)"),omr=l(),jT=a("li"),TEe=a("strong"),rmr=o("luke"),tmr=o(" \u2014 "),wJ=a("a"),amr=o("LukeForSequenceClassification"),nmr=o(" (LUKE model)"),smr=l(),DT=a("li"),MEe=a("strong"),lmr=o("markuplm"),imr=o(" \u2014 "),AJ=a("a"),dmr=o("MarkupLMForSequenceClassification"),mmr=o(" (MarkupLM model)"),cmr=l(),GT=a("li"),EEe=a("strong"),fmr=o("mbart"),gmr=o(" \u2014 "),LJ=a("a"),hmr=o("MBartForSequenceClassification"),umr=o(" (mBART model)"),pmr=l(),OT=a("li"),CEe=a("strong"),_mr=o("megatron-bert"),bmr=o(" \u2014 "),yJ=a("a"),vmr=o("MegatronBertForSequenceClassification"),Fmr=o(" (Megatron-BERT model)"),Tmr=l(),VT=a("li"),wEe=a("strong"),Mmr=o("mobilebert"),Emr=o(" \u2014 "),xJ=a("a"),Cmr=o("MobileBertForSequenceClassification"),wmr=o(" (MobileBERT model)"),Amr=l(),XT=a("li"),AEe=a("strong"),Lmr=o("mpnet"),ymr=o(" \u2014 "),$J=a("a"),xmr=o("MPNetForSequenceClassification"),$mr=o(" (MPNet model)"),kmr=l(),zT=a("li"),LEe=a("strong"),Smr=o("mvp"),Rmr=o(" \u2014 "),kJ=a("a"),Pmr=o("MvpForSequenceClassification"),Bmr=o(" (MVP model)"),Imr=l(),QT=a("li"),yEe=a("strong"),Nmr=o("nezha"),qmr=o(" \u2014 "),SJ=a("a"),jmr=o("NezhaForSequenceClassification"),Dmr=o(" (Nezha model)"),Gmr=l(),WT=a("li"),xEe=a("strong"),Omr=o("nystromformer"),Vmr=o(" \u2014 "),RJ=a("a"),Xmr=o("NystromformerForSequenceClassification"),zmr=o(" (Nystr\xF6mformer model)"),Qmr=l(),UT=a("li"),$Ee=a("strong"),Wmr=o("openai-gpt"),Umr=o(" \u2014 "),PJ=a("a"),Hmr=o("OpenAIGPTForSequenceClassification"),Jmr=o(" (OpenAI GPT model)"),Ymr=l(),HT=a("li"),kEe=a("strong"),Zmr=o("opt"),Kmr=o(" \u2014 "),BJ=a("a"),ecr=o("OPTForSequenceClassification"),ocr=o(" (OPT model)"),rcr=l(),JT=a("li"),SEe=a("strong"),tcr=o("perceiver"),acr=o(" \u2014 "),IJ=a("a"),ncr=o("PerceiverForSequenceClassification"),scr=o(" (Perceiver model)"),lcr=l(),YT=a("li"),REe=a("strong"),icr=o("plbart"),dcr=o(" \u2014 "),NJ=a("a"),mcr=o("PLBartForSequenceClassification"),ccr=o(" (PLBart model)"),fcr=l(),ZT=a("li"),PEe=a("strong"),gcr=o("qdqbert"),hcr=o(" \u2014 "),qJ=a("a"),ucr=o("QDQBertForSequenceClassification"),pcr=o(" (QDQBert model)"),_cr=l(),KT=a("li"),BEe=a("strong"),bcr=o("reformer"),vcr=o(" \u2014 "),jJ=a("a"),Fcr=o("ReformerForSequenceClassification"),Tcr=o(" (Reformer model)"),Mcr=l(),eM=a("li"),IEe=a("strong"),Ecr=o("rembert"),Ccr=o(" \u2014 "),DJ=a("a"),wcr=o("RemBertForSequenceClassification"),Acr=o(" (RemBERT model)"),Lcr=l(),oM=a("li"),NEe=a("strong"),ycr=o("roberta"),xcr=o(" \u2014 "),GJ=a("a"),$cr=o("RobertaForSequenceClassification"),kcr=o(" (RoBERTa model)"),Scr=l(),rM=a("li"),qEe=a("strong"),Rcr=o("roformer"),Pcr=o(" \u2014 "),OJ=a("a"),Bcr=o("RoFormerForSequenceClassification"),Icr=o(" (RoFormer model)"),Ncr=l(),tM=a("li"),jEe=a("strong"),qcr=o("squeezebert"),jcr=o(" \u2014 "),VJ=a("a"),Dcr=o("SqueezeBertForSequenceClassification"),Gcr=o(" (SqueezeBERT model)"),Ocr=l(),aM=a("li"),DEe=a("strong"),Vcr=o("tapas"),Xcr=o(" \u2014 "),XJ=a("a"),zcr=o("TapasForSequenceClassification"),Qcr=o(" (TAPAS model)"),Wcr=l(),nM=a("li"),GEe=a("strong"),Ucr=o("transfo-xl"),Hcr=o(" \u2014 "),zJ=a("a"),Jcr=o("TransfoXLForSequenceClassification"),Ycr=o(" (Transformer-XL model)"),Zcr=l(),sM=a("li"),OEe=a("strong"),Kcr=o("xlm"),efr=o(" \u2014 "),QJ=a("a"),ofr=o("XLMForSequenceClassification"),rfr=o(" (XLM model)"),tfr=l(),lM=a("li"),VEe=a("strong"),afr=o("xlm-roberta"),nfr=o(" \u2014 "),WJ=a("a"),sfr=o("XLMRobertaForSequenceClassification"),lfr=o(" (XLM-RoBERTa model)"),ifr=l(),iM=a("li"),XEe=a("strong"),dfr=o("xlm-roberta-xl"),mfr=o(" \u2014 "),UJ=a("a"),cfr=o("XLMRobertaXLForSequenceClassification"),ffr=o(" (XLM-RoBERTa-XL model)"),gfr=l(),dM=a("li"),zEe=a("strong"),hfr=o("xlnet"),ufr=o(" \u2014 "),HJ=a("a"),pfr=o("XLNetForSequenceClassification"),_fr=o(" (XLNet model)"),bfr=l(),mM=a("li"),QEe=a("strong"),vfr=o("yoso"),Ffr=o(" \u2014 "),JJ=a("a"),Tfr=o("YosoForSequenceClassification"),Mfr=o(" (YOSO model)"),Efr=l(),cM=a("p"),Cfr=o("The model is set in evaluation mode by default using "),WEe=a("code"),wfr=o("model.eval()"),Afr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UEe=a("code"),Lfr=o("model.train()"),yfr=l(),F(fM.$$.fragment),Bto=l(),Yd=a("h2"),gM=a("a"),HEe=a("span"),F(gk.$$.fragment),xfr=l(),JEe=a("span"),$fr=o("AutoModelForMultipleChoice"),Ito=l(),Vo=a("div"),F(hk.$$.fragment),kfr=l(),Zd=a("p"),Sfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),YJ=a("a"),Rfr=o("from_pretrained()"),Pfr=o(" class method or the "),ZJ=a("a"),Bfr=o("from_config()"),Ifr=o(` class
method.`),Nfr=l(),uk=a("p"),qfr=o("This class cannot be instantiated directly using "),YEe=a("code"),jfr=o("__init__()"),Dfr=o(" (throws an error)."),Gfr=l(),yt=a("div"),F(pk.$$.fragment),Ofr=l(),ZEe=a("p"),Vfr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Xfr=l(),Kd=a("p"),zfr=o(`Note:
Loading a model from its configuration file does `),KEe=a("strong"),Qfr=o("not"),Wfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KJ=a("a"),Ufr=o("from_pretrained()"),Hfr=o(" to load the model weights."),Jfr=l(),F(hM.$$.fragment),Yfr=l(),so=a("div"),F(_k.$$.fragment),Zfr=l(),e4e=a("p"),Kfr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),egr=l(),fn=a("p"),ogr=o("The model class to instantiate is selected based on the "),o4e=a("code"),rgr=o("model_type"),tgr=o(` property of the config object (either
passed as an argument or loaded from `),r4e=a("code"),agr=o("pretrained_model_name_or_path"),ngr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t4e=a("code"),sgr=o("pretrained_model_name_or_path"),lgr=o(":"),igr=l(),K=a("ul"),uM=a("li"),a4e=a("strong"),dgr=o("albert"),mgr=o(" \u2014 "),eY=a("a"),cgr=o("AlbertForMultipleChoice"),fgr=o(" (ALBERT model)"),ggr=l(),pM=a("li"),n4e=a("strong"),hgr=o("bert"),ugr=o(" \u2014 "),oY=a("a"),pgr=o("BertForMultipleChoice"),_gr=o(" (BERT model)"),bgr=l(),_M=a("li"),s4e=a("strong"),vgr=o("big_bird"),Fgr=o(" \u2014 "),rY=a("a"),Tgr=o("BigBirdForMultipleChoice"),Mgr=o(" (BigBird model)"),Egr=l(),bM=a("li"),l4e=a("strong"),Cgr=o("camembert"),wgr=o(" \u2014 "),tY=a("a"),Agr=o("CamembertForMultipleChoice"),Lgr=o(" (CamemBERT model)"),ygr=l(),vM=a("li"),i4e=a("strong"),xgr=o("canine"),$gr=o(" \u2014 "),aY=a("a"),kgr=o("CanineForMultipleChoice"),Sgr=o(" (CANINE model)"),Rgr=l(),FM=a("li"),d4e=a("strong"),Pgr=o("convbert"),Bgr=o(" \u2014 "),nY=a("a"),Igr=o("ConvBertForMultipleChoice"),Ngr=o(" (ConvBERT model)"),qgr=l(),TM=a("li"),m4e=a("strong"),jgr=o("data2vec-text"),Dgr=o(" \u2014 "),sY=a("a"),Ggr=o("Data2VecTextForMultipleChoice"),Ogr=o(" (Data2VecText model)"),Vgr=l(),MM=a("li"),c4e=a("strong"),Xgr=o("deberta-v2"),zgr=o(" \u2014 "),lY=a("a"),Qgr=o("DebertaV2ForMultipleChoice"),Wgr=o(" (DeBERTa-v2 model)"),Ugr=l(),EM=a("li"),f4e=a("strong"),Hgr=o("distilbert"),Jgr=o(" \u2014 "),iY=a("a"),Ygr=o("DistilBertForMultipleChoice"),Zgr=o(" (DistilBERT model)"),Kgr=l(),CM=a("li"),g4e=a("strong"),ehr=o("electra"),ohr=o(" \u2014 "),dY=a("a"),rhr=o("ElectraForMultipleChoice"),thr=o(" (ELECTRA model)"),ahr=l(),wM=a("li"),h4e=a("strong"),nhr=o("ernie"),shr=o(" \u2014 "),mY=a("a"),lhr=o("ErnieForMultipleChoice"),ihr=o(" (ERNIE model)"),dhr=l(),AM=a("li"),u4e=a("strong"),mhr=o("flaubert"),chr=o(" \u2014 "),cY=a("a"),fhr=o("FlaubertForMultipleChoice"),ghr=o(" (FlauBERT model)"),hhr=l(),LM=a("li"),p4e=a("strong"),uhr=o("fnet"),phr=o(" \u2014 "),fY=a("a"),_hr=o("FNetForMultipleChoice"),bhr=o(" (FNet model)"),vhr=l(),yM=a("li"),_4e=a("strong"),Fhr=o("funnel"),Thr=o(" \u2014 "),gY=a("a"),Mhr=o("FunnelForMultipleChoice"),Ehr=o(" (Funnel Transformer model)"),Chr=l(),xM=a("li"),b4e=a("strong"),whr=o("ibert"),Ahr=o(" \u2014 "),hY=a("a"),Lhr=o("IBertForMultipleChoice"),yhr=o(" (I-BERT model)"),xhr=l(),$M=a("li"),v4e=a("strong"),$hr=o("longformer"),khr=o(" \u2014 "),uY=a("a"),Shr=o("LongformerForMultipleChoice"),Rhr=o(" (Longformer model)"),Phr=l(),kM=a("li"),F4e=a("strong"),Bhr=o("luke"),Ihr=o(" \u2014 "),pY=a("a"),Nhr=o("LukeForMultipleChoice"),qhr=o(" (LUKE model)"),jhr=l(),SM=a("li"),T4e=a("strong"),Dhr=o("megatron-bert"),Ghr=o(" \u2014 "),_Y=a("a"),Ohr=o("MegatronBertForMultipleChoice"),Vhr=o(" (Megatron-BERT model)"),Xhr=l(),RM=a("li"),M4e=a("strong"),zhr=o("mobilebert"),Qhr=o(" \u2014 "),bY=a("a"),Whr=o("MobileBertForMultipleChoice"),Uhr=o(" (MobileBERT model)"),Hhr=l(),PM=a("li"),E4e=a("strong"),Jhr=o("mpnet"),Yhr=o(" \u2014 "),vY=a("a"),Zhr=o("MPNetForMultipleChoice"),Khr=o(" (MPNet model)"),eur=l(),BM=a("li"),C4e=a("strong"),our=o("nezha"),rur=o(" \u2014 "),FY=a("a"),tur=o("NezhaForMultipleChoice"),aur=o(" (Nezha model)"),nur=l(),IM=a("li"),w4e=a("strong"),sur=o("nystromformer"),lur=o(" \u2014 "),TY=a("a"),iur=o("NystromformerForMultipleChoice"),dur=o(" (Nystr\xF6mformer model)"),mur=l(),NM=a("li"),A4e=a("strong"),cur=o("qdqbert"),fur=o(" \u2014 "),MY=a("a"),gur=o("QDQBertForMultipleChoice"),hur=o(" (QDQBert model)"),uur=l(),qM=a("li"),L4e=a("strong"),pur=o("rembert"),_ur=o(" \u2014 "),EY=a("a"),bur=o("RemBertForMultipleChoice"),vur=o(" (RemBERT model)"),Fur=l(),jM=a("li"),y4e=a("strong"),Tur=o("roberta"),Mur=o(" \u2014 "),CY=a("a"),Eur=o("RobertaForMultipleChoice"),Cur=o(" (RoBERTa model)"),wur=l(),DM=a("li"),x4e=a("strong"),Aur=o("roformer"),Lur=o(" \u2014 "),wY=a("a"),yur=o("RoFormerForMultipleChoice"),xur=o(" (RoFormer model)"),$ur=l(),GM=a("li"),$4e=a("strong"),kur=o("squeezebert"),Sur=o(" \u2014 "),AY=a("a"),Rur=o("SqueezeBertForMultipleChoice"),Pur=o(" (SqueezeBERT model)"),Bur=l(),OM=a("li"),k4e=a("strong"),Iur=o("xlm"),Nur=o(" \u2014 "),LY=a("a"),qur=o("XLMForMultipleChoice"),jur=o(" (XLM model)"),Dur=l(),VM=a("li"),S4e=a("strong"),Gur=o("xlm-roberta"),Our=o(" \u2014 "),yY=a("a"),Vur=o("XLMRobertaForMultipleChoice"),Xur=o(" (XLM-RoBERTa model)"),zur=l(),XM=a("li"),R4e=a("strong"),Qur=o("xlm-roberta-xl"),Wur=o(" \u2014 "),xY=a("a"),Uur=o("XLMRobertaXLForMultipleChoice"),Hur=o(" (XLM-RoBERTa-XL model)"),Jur=l(),zM=a("li"),P4e=a("strong"),Yur=o("xlnet"),Zur=o(" \u2014 "),$Y=a("a"),Kur=o("XLNetForMultipleChoice"),epr=o(" (XLNet model)"),opr=l(),QM=a("li"),B4e=a("strong"),rpr=o("yoso"),tpr=o(" \u2014 "),kY=a("a"),apr=o("YosoForMultipleChoice"),npr=o(" (YOSO model)"),spr=l(),WM=a("p"),lpr=o("The model is set in evaluation mode by default using "),I4e=a("code"),ipr=o("model.eval()"),dpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N4e=a("code"),mpr=o("model.train()"),cpr=l(),F(UM.$$.fragment),Nto=l(),em=a("h2"),HM=a("a"),q4e=a("span"),F(bk.$$.fragment),fpr=l(),j4e=a("span"),gpr=o("AutoModelForNextSentencePrediction"),qto=l(),Xo=a("div"),F(vk.$$.fragment),hpr=l(),om=a("p"),upr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),SY=a("a"),ppr=o("from_pretrained()"),_pr=o(" class method or the "),RY=a("a"),bpr=o("from_config()"),vpr=o(` class
method.`),Fpr=l(),Fk=a("p"),Tpr=o("This class cannot be instantiated directly using "),D4e=a("code"),Mpr=o("__init__()"),Epr=o(" (throws an error)."),Cpr=l(),xt=a("div"),F(Tk.$$.fragment),wpr=l(),G4e=a("p"),Apr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Lpr=l(),rm=a("p"),ypr=o(`Note:
Loading a model from its configuration file does `),O4e=a("strong"),xpr=o("not"),$pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=a("a"),kpr=o("from_pretrained()"),Spr=o(" to load the model weights."),Rpr=l(),F(JM.$$.fragment),Ppr=l(),lo=a("div"),F(Mk.$$.fragment),Bpr=l(),V4e=a("p"),Ipr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Npr=l(),gn=a("p"),qpr=o("The model class to instantiate is selected based on the "),X4e=a("code"),jpr=o("model_type"),Dpr=o(` property of the config object (either
passed as an argument or loaded from `),z4e=a("code"),Gpr=o("pretrained_model_name_or_path"),Opr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q4e=a("code"),Vpr=o("pretrained_model_name_or_path"),Xpr=o(":"),zpr=l(),Ue=a("ul"),YM=a("li"),W4e=a("strong"),Qpr=o("bert"),Wpr=o(" \u2014 "),BY=a("a"),Upr=o("BertForNextSentencePrediction"),Hpr=o(" (BERT model)"),Jpr=l(),ZM=a("li"),U4e=a("strong"),Ypr=o("ernie"),Zpr=o(" \u2014 "),IY=a("a"),Kpr=o("ErnieForNextSentencePrediction"),e_r=o(" (ERNIE model)"),o_r=l(),KM=a("li"),H4e=a("strong"),r_r=o("fnet"),t_r=o(" \u2014 "),NY=a("a"),a_r=o("FNetForNextSentencePrediction"),n_r=o(" (FNet model)"),s_r=l(),eE=a("li"),J4e=a("strong"),l_r=o("megatron-bert"),i_r=o(" \u2014 "),qY=a("a"),d_r=o("MegatronBertForNextSentencePrediction"),m_r=o(" (Megatron-BERT model)"),c_r=l(),oE=a("li"),Y4e=a("strong"),f_r=o("mobilebert"),g_r=o(" \u2014 "),jY=a("a"),h_r=o("MobileBertForNextSentencePrediction"),u_r=o(" (MobileBERT model)"),p_r=l(),rE=a("li"),Z4e=a("strong"),__r=o("nezha"),b_r=o(" \u2014 "),DY=a("a"),v_r=o("NezhaForNextSentencePrediction"),F_r=o(" (Nezha model)"),T_r=l(),tE=a("li"),K4e=a("strong"),M_r=o("qdqbert"),E_r=o(" \u2014 "),GY=a("a"),C_r=o("QDQBertForNextSentencePrediction"),w_r=o(" (QDQBert model)"),A_r=l(),aE=a("p"),L_r=o("The model is set in evaluation mode by default using "),eCe=a("code"),y_r=o("model.eval()"),x_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oCe=a("code"),$_r=o("model.train()"),k_r=l(),F(nE.$$.fragment),jto=l(),tm=a("h2"),sE=a("a"),rCe=a("span"),F(Ek.$$.fragment),S_r=l(),tCe=a("span"),R_r=o("AutoModelForTokenClassification"),Dto=l(),zo=a("div"),F(Ck.$$.fragment),P_r=l(),am=a("p"),B_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),OY=a("a"),I_r=o("from_pretrained()"),N_r=o(" class method or the "),VY=a("a"),q_r=o("from_config()"),j_r=o(` class
method.`),D_r=l(),wk=a("p"),G_r=o("This class cannot be instantiated directly using "),aCe=a("code"),O_r=o("__init__()"),V_r=o(" (throws an error)."),X_r=l(),$t=a("div"),F(Ak.$$.fragment),z_r=l(),nCe=a("p"),Q_r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),W_r=l(),nm=a("p"),U_r=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),H_r=o("not"),J_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XY=a("a"),Y_r=o("from_pretrained()"),Z_r=o(" to load the model weights."),K_r=l(),F(lE.$$.fragment),e1r=l(),io=a("div"),F(Lk.$$.fragment),o1r=l(),lCe=a("p"),r1r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),t1r=l(),hn=a("p"),a1r=o("The model class to instantiate is selected based on the "),iCe=a("code"),n1r=o("model_type"),s1r=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),l1r=o("pretrained_model_name_or_path"),i1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mCe=a("code"),d1r=o("pretrained_model_name_or_path"),m1r=o(":"),c1r=l(),U=a("ul"),iE=a("li"),cCe=a("strong"),f1r=o("albert"),g1r=o(" \u2014 "),zY=a("a"),h1r=o("AlbertForTokenClassification"),u1r=o(" (ALBERT model)"),p1r=l(),dE=a("li"),fCe=a("strong"),_1r=o("bert"),b1r=o(" \u2014 "),QY=a("a"),v1r=o("BertForTokenClassification"),F1r=o(" (BERT model)"),T1r=l(),mE=a("li"),gCe=a("strong"),M1r=o("big_bird"),E1r=o(" \u2014 "),WY=a("a"),C1r=o("BigBirdForTokenClassification"),w1r=o(" (BigBird model)"),A1r=l(),cE=a("li"),hCe=a("strong"),L1r=o("bloom"),y1r=o(" \u2014 "),UY=a("a"),x1r=o("BloomForTokenClassification"),$1r=o(" (BLOOM model)"),k1r=l(),fE=a("li"),uCe=a("strong"),S1r=o("camembert"),R1r=o(" \u2014 "),HY=a("a"),P1r=o("CamembertForTokenClassification"),B1r=o(" (CamemBERT model)"),I1r=l(),gE=a("li"),pCe=a("strong"),N1r=o("canine"),q1r=o(" \u2014 "),JY=a("a"),j1r=o("CanineForTokenClassification"),D1r=o(" (CANINE model)"),G1r=l(),hE=a("li"),_Ce=a("strong"),O1r=o("convbert"),V1r=o(" \u2014 "),YY=a("a"),X1r=o("ConvBertForTokenClassification"),z1r=o(" (ConvBERT model)"),Q1r=l(),uE=a("li"),bCe=a("strong"),W1r=o("data2vec-text"),U1r=o(" \u2014 "),ZY=a("a"),H1r=o("Data2VecTextForTokenClassification"),J1r=o(" (Data2VecText model)"),Y1r=l(),pE=a("li"),vCe=a("strong"),Z1r=o("deberta"),K1r=o(" \u2014 "),KY=a("a"),e2r=o("DebertaForTokenClassification"),o2r=o(" (DeBERTa model)"),r2r=l(),_E=a("li"),FCe=a("strong"),t2r=o("deberta-v2"),a2r=o(" \u2014 "),eZ=a("a"),n2r=o("DebertaV2ForTokenClassification"),s2r=o(" (DeBERTa-v2 model)"),l2r=l(),bE=a("li"),TCe=a("strong"),i2r=o("distilbert"),d2r=o(" \u2014 "),oZ=a("a"),m2r=o("DistilBertForTokenClassification"),c2r=o(" (DistilBERT model)"),f2r=l(),vE=a("li"),MCe=a("strong"),g2r=o("electra"),h2r=o(" \u2014 "),rZ=a("a"),u2r=o("ElectraForTokenClassification"),p2r=o(" (ELECTRA model)"),_2r=l(),FE=a("li"),ECe=a("strong"),b2r=o("ernie"),v2r=o(" \u2014 "),tZ=a("a"),F2r=o("ErnieForTokenClassification"),T2r=o(" (ERNIE model)"),M2r=l(),TE=a("li"),CCe=a("strong"),E2r=o("esm"),C2r=o(" \u2014 "),aZ=a("a"),w2r=o("EsmForTokenClassification"),A2r=o(" (ESM model)"),L2r=l(),ME=a("li"),wCe=a("strong"),y2r=o("flaubert"),x2r=o(" \u2014 "),nZ=a("a"),$2r=o("FlaubertForTokenClassification"),k2r=o(" (FlauBERT model)"),S2r=l(),EE=a("li"),ACe=a("strong"),R2r=o("fnet"),P2r=o(" \u2014 "),sZ=a("a"),B2r=o("FNetForTokenClassification"),I2r=o(" (FNet model)"),N2r=l(),CE=a("li"),LCe=a("strong"),q2r=o("funnel"),j2r=o(" \u2014 "),lZ=a("a"),D2r=o("FunnelForTokenClassification"),G2r=o(" (Funnel Transformer model)"),O2r=l(),wE=a("li"),yCe=a("strong"),V2r=o("gpt2"),X2r=o(" \u2014 "),iZ=a("a"),z2r=o("GPT2ForTokenClassification"),Q2r=o(" (OpenAI GPT-2 model)"),W2r=l(),AE=a("li"),xCe=a("strong"),U2r=o("ibert"),H2r=o(" \u2014 "),dZ=a("a"),J2r=o("IBertForTokenClassification"),Y2r=o(" (I-BERT model)"),Z2r=l(),LE=a("li"),$Ce=a("strong"),K2r=o("layoutlm"),ebr=o(" \u2014 "),mZ=a("a"),obr=o("LayoutLMForTokenClassification"),rbr=o(" (LayoutLM model)"),tbr=l(),yE=a("li"),kCe=a("strong"),abr=o("layoutlmv2"),nbr=o(" \u2014 "),cZ=a("a"),sbr=o("LayoutLMv2ForTokenClassification"),lbr=o(" (LayoutLMv2 model)"),ibr=l(),xE=a("li"),SCe=a("strong"),dbr=o("layoutlmv3"),mbr=o(" \u2014 "),fZ=a("a"),cbr=o("LayoutLMv3ForTokenClassification"),fbr=o(" (LayoutLMv3 model)"),gbr=l(),$E=a("li"),RCe=a("strong"),hbr=o("lilt"),ubr=o(" \u2014 "),gZ=a("a"),pbr=o("LiltForTokenClassification"),_br=o(" (LiLT model)"),bbr=l(),kE=a("li"),PCe=a("strong"),vbr=o("longformer"),Fbr=o(" \u2014 "),hZ=a("a"),Tbr=o("LongformerForTokenClassification"),Mbr=o(" (Longformer model)"),Ebr=l(),SE=a("li"),BCe=a("strong"),Cbr=o("luke"),wbr=o(" \u2014 "),uZ=a("a"),Abr=o("LukeForTokenClassification"),Lbr=o(" (LUKE model)"),ybr=l(),RE=a("li"),ICe=a("strong"),xbr=o("markuplm"),$br=o(" \u2014 "),pZ=a("a"),kbr=o("MarkupLMForTokenClassification"),Sbr=o(" (MarkupLM model)"),Rbr=l(),PE=a("li"),NCe=a("strong"),Pbr=o("megatron-bert"),Bbr=o(" \u2014 "),_Z=a("a"),Ibr=o("MegatronBertForTokenClassification"),Nbr=o(" (Megatron-BERT model)"),qbr=l(),BE=a("li"),qCe=a("strong"),jbr=o("mobilebert"),Dbr=o(" \u2014 "),bZ=a("a"),Gbr=o("MobileBertForTokenClassification"),Obr=o(" (MobileBERT model)"),Vbr=l(),IE=a("li"),jCe=a("strong"),Xbr=o("mpnet"),zbr=o(" \u2014 "),vZ=a("a"),Qbr=o("MPNetForTokenClassification"),Wbr=o(" (MPNet model)"),Ubr=l(),NE=a("li"),DCe=a("strong"),Hbr=o("nezha"),Jbr=o(" \u2014 "),FZ=a("a"),Ybr=o("NezhaForTokenClassification"),Zbr=o(" (Nezha model)"),Kbr=l(),qE=a("li"),GCe=a("strong"),evr=o("nystromformer"),ovr=o(" \u2014 "),TZ=a("a"),rvr=o("NystromformerForTokenClassification"),tvr=o(" (Nystr\xF6mformer model)"),avr=l(),jE=a("li"),OCe=a("strong"),nvr=o("qdqbert"),svr=o(" \u2014 "),MZ=a("a"),lvr=o("QDQBertForTokenClassification"),ivr=o(" (QDQBert model)"),dvr=l(),DE=a("li"),VCe=a("strong"),mvr=o("rembert"),cvr=o(" \u2014 "),EZ=a("a"),fvr=o("RemBertForTokenClassification"),gvr=o(" (RemBERT model)"),hvr=l(),GE=a("li"),XCe=a("strong"),uvr=o("roberta"),pvr=o(" \u2014 "),CZ=a("a"),_vr=o("RobertaForTokenClassification"),bvr=o(" (RoBERTa model)"),vvr=l(),OE=a("li"),zCe=a("strong"),Fvr=o("roformer"),Tvr=o(" \u2014 "),wZ=a("a"),Mvr=o("RoFormerForTokenClassification"),Evr=o(" (RoFormer model)"),Cvr=l(),VE=a("li"),QCe=a("strong"),wvr=o("squeezebert"),Avr=o(" \u2014 "),AZ=a("a"),Lvr=o("SqueezeBertForTokenClassification"),yvr=o(" (SqueezeBERT model)"),xvr=l(),XE=a("li"),WCe=a("strong"),$vr=o("xlm"),kvr=o(" \u2014 "),LZ=a("a"),Svr=o("XLMForTokenClassification"),Rvr=o(" (XLM model)"),Pvr=l(),zE=a("li"),UCe=a("strong"),Bvr=o("xlm-roberta"),Ivr=o(" \u2014 "),yZ=a("a"),Nvr=o("XLMRobertaForTokenClassification"),qvr=o(" (XLM-RoBERTa model)"),jvr=l(),QE=a("li"),HCe=a("strong"),Dvr=o("xlm-roberta-xl"),Gvr=o(" \u2014 "),xZ=a("a"),Ovr=o("XLMRobertaXLForTokenClassification"),Vvr=o(" (XLM-RoBERTa-XL model)"),Xvr=l(),WE=a("li"),JCe=a("strong"),zvr=o("xlnet"),Qvr=o(" \u2014 "),$Z=a("a"),Wvr=o("XLNetForTokenClassification"),Uvr=o(" (XLNet model)"),Hvr=l(),UE=a("li"),YCe=a("strong"),Jvr=o("yoso"),Yvr=o(" \u2014 "),kZ=a("a"),Zvr=o("YosoForTokenClassification"),Kvr=o(" (YOSO model)"),eFr=l(),HE=a("p"),oFr=o("The model is set in evaluation mode by default using "),ZCe=a("code"),rFr=o("model.eval()"),tFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KCe=a("code"),aFr=o("model.train()"),nFr=l(),F(JE.$$.fragment),Gto=l(),sm=a("h2"),YE=a("a"),e3e=a("span"),F(yk.$$.fragment),sFr=l(),o3e=a("span"),lFr=o("AutoModelForQuestionAnswering"),Oto=l(),Qo=a("div"),F(xk.$$.fragment),iFr=l(),lm=a("p"),dFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),SZ=a("a"),mFr=o("from_pretrained()"),cFr=o(" class method or the "),RZ=a("a"),fFr=o("from_config()"),gFr=o(` class
method.`),hFr=l(),$k=a("p"),uFr=o("This class cannot be instantiated directly using "),r3e=a("code"),pFr=o("__init__()"),_Fr=o(" (throws an error)."),bFr=l(),kt=a("div"),F(kk.$$.fragment),vFr=l(),t3e=a("p"),FFr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),TFr=l(),im=a("p"),MFr=o(`Note:
Loading a model from its configuration file does `),a3e=a("strong"),EFr=o("not"),CFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PZ=a("a"),wFr=o("from_pretrained()"),AFr=o(" to load the model weights."),LFr=l(),F(ZE.$$.fragment),yFr=l(),mo=a("div"),F(Sk.$$.fragment),xFr=l(),n3e=a("p"),$Fr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),kFr=l(),un=a("p"),SFr=o("The model class to instantiate is selected based on the "),s3e=a("code"),RFr=o("model_type"),PFr=o(` property of the config object (either
passed as an argument or loaded from `),l3e=a("code"),BFr=o("pretrained_model_name_or_path"),IFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=a("code"),NFr=o("pretrained_model_name_or_path"),qFr=o(":"),jFr=l(),O=a("ul"),KE=a("li"),d3e=a("strong"),DFr=o("albert"),GFr=o(" \u2014 "),BZ=a("a"),OFr=o("AlbertForQuestionAnswering"),VFr=o(" (ALBERT model)"),XFr=l(),e4=a("li"),m3e=a("strong"),zFr=o("bart"),QFr=o(" \u2014 "),IZ=a("a"),WFr=o("BartForQuestionAnswering"),UFr=o(" (BART model)"),HFr=l(),o4=a("li"),c3e=a("strong"),JFr=o("bert"),YFr=o(" \u2014 "),NZ=a("a"),ZFr=o("BertForQuestionAnswering"),KFr=o(" (BERT model)"),eTr=l(),r4=a("li"),f3e=a("strong"),oTr=o("big_bird"),rTr=o(" \u2014 "),qZ=a("a"),tTr=o("BigBirdForQuestionAnswering"),aTr=o(" (BigBird model)"),nTr=l(),t4=a("li"),g3e=a("strong"),sTr=o("bigbird_pegasus"),lTr=o(" \u2014 "),jZ=a("a"),iTr=o("BigBirdPegasusForQuestionAnswering"),dTr=o(" (BigBird-Pegasus model)"),mTr=l(),a4=a("li"),h3e=a("strong"),cTr=o("bloom"),fTr=o(" \u2014 "),DZ=a("a"),gTr=o("BloomForQuestionAnswering"),hTr=o(" (BLOOM model)"),uTr=l(),n4=a("li"),u3e=a("strong"),pTr=o("camembert"),_Tr=o(" \u2014 "),GZ=a("a"),bTr=o("CamembertForQuestionAnswering"),vTr=o(" (CamemBERT model)"),FTr=l(),s4=a("li"),p3e=a("strong"),TTr=o("canine"),MTr=o(" \u2014 "),OZ=a("a"),ETr=o("CanineForQuestionAnswering"),CTr=o(" (CANINE model)"),wTr=l(),l4=a("li"),_3e=a("strong"),ATr=o("convbert"),LTr=o(" \u2014 "),VZ=a("a"),yTr=o("ConvBertForQuestionAnswering"),xTr=o(" (ConvBERT model)"),$Tr=l(),i4=a("li"),b3e=a("strong"),kTr=o("data2vec-text"),STr=o(" \u2014 "),XZ=a("a"),RTr=o("Data2VecTextForQuestionAnswering"),PTr=o(" (Data2VecText model)"),BTr=l(),d4=a("li"),v3e=a("strong"),ITr=o("deberta"),NTr=o(" \u2014 "),zZ=a("a"),qTr=o("DebertaForQuestionAnswering"),jTr=o(" (DeBERTa model)"),DTr=l(),m4=a("li"),F3e=a("strong"),GTr=o("deberta-v2"),OTr=o(" \u2014 "),QZ=a("a"),VTr=o("DebertaV2ForQuestionAnswering"),XTr=o(" (DeBERTa-v2 model)"),zTr=l(),c4=a("li"),T3e=a("strong"),QTr=o("distilbert"),WTr=o(" \u2014 "),WZ=a("a"),UTr=o("DistilBertForQuestionAnswering"),HTr=o(" (DistilBERT model)"),JTr=l(),f4=a("li"),M3e=a("strong"),YTr=o("electra"),ZTr=o(" \u2014 "),UZ=a("a"),KTr=o("ElectraForQuestionAnswering"),eMr=o(" (ELECTRA model)"),oMr=l(),g4=a("li"),E3e=a("strong"),rMr=o("ernie"),tMr=o(" \u2014 "),HZ=a("a"),aMr=o("ErnieForQuestionAnswering"),nMr=o(" (ERNIE model)"),sMr=l(),h4=a("li"),C3e=a("strong"),lMr=o("flaubert"),iMr=o(" \u2014 "),JZ=a("a"),dMr=o("FlaubertForQuestionAnsweringSimple"),mMr=o(" (FlauBERT model)"),cMr=l(),u4=a("li"),w3e=a("strong"),fMr=o("fnet"),gMr=o(" \u2014 "),YZ=a("a"),hMr=o("FNetForQuestionAnswering"),uMr=o(" (FNet model)"),pMr=l(),p4=a("li"),A3e=a("strong"),_Mr=o("funnel"),bMr=o(" \u2014 "),ZZ=a("a"),vMr=o("FunnelForQuestionAnswering"),FMr=o(" (Funnel Transformer model)"),TMr=l(),_4=a("li"),L3e=a("strong"),MMr=o("gptj"),EMr=o(" \u2014 "),KZ=a("a"),CMr=o("GPTJForQuestionAnswering"),wMr=o(" (GPT-J model)"),AMr=l(),b4=a("li"),y3e=a("strong"),LMr=o("ibert"),yMr=o(" \u2014 "),eK=a("a"),xMr=o("IBertForQuestionAnswering"),$Mr=o(" (I-BERT model)"),kMr=l(),v4=a("li"),x3e=a("strong"),SMr=o("layoutlmv2"),RMr=o(" \u2014 "),oK=a("a"),PMr=o("LayoutLMv2ForQuestionAnswering"),BMr=o(" (LayoutLMv2 model)"),IMr=l(),F4=a("li"),$3e=a("strong"),NMr=o("layoutlmv3"),qMr=o(" \u2014 "),rK=a("a"),jMr=o("LayoutLMv3ForQuestionAnswering"),DMr=o(" (LayoutLMv3 model)"),GMr=l(),T4=a("li"),k3e=a("strong"),OMr=o("led"),VMr=o(" \u2014 "),tK=a("a"),XMr=o("LEDForQuestionAnswering"),zMr=o(" (LED model)"),QMr=l(),M4=a("li"),S3e=a("strong"),WMr=o("lilt"),UMr=o(" \u2014 "),aK=a("a"),HMr=o("LiltForQuestionAnswering"),JMr=o(" (LiLT model)"),YMr=l(),E4=a("li"),R3e=a("strong"),ZMr=o("longformer"),KMr=o(" \u2014 "),nK=a("a"),eEr=o("LongformerForQuestionAnswering"),oEr=o(" (Longformer model)"),rEr=l(),C4=a("li"),P3e=a("strong"),tEr=o("luke"),aEr=o(" \u2014 "),sK=a("a"),nEr=o("LukeForQuestionAnswering"),sEr=o(" (LUKE model)"),lEr=l(),w4=a("li"),B3e=a("strong"),iEr=o("lxmert"),dEr=o(" \u2014 "),lK=a("a"),mEr=o("LxmertForQuestionAnswering"),cEr=o(" (LXMERT model)"),fEr=l(),A4=a("li"),I3e=a("strong"),gEr=o("markuplm"),hEr=o(" \u2014 "),iK=a("a"),uEr=o("MarkupLMForQuestionAnswering"),pEr=o(" (MarkupLM model)"),_Er=l(),L4=a("li"),N3e=a("strong"),bEr=o("mbart"),vEr=o(" \u2014 "),dK=a("a"),FEr=o("MBartForQuestionAnswering"),TEr=o(" (mBART model)"),MEr=l(),y4=a("li"),q3e=a("strong"),EEr=o("megatron-bert"),CEr=o(" \u2014 "),mK=a("a"),wEr=o("MegatronBertForQuestionAnswering"),AEr=o(" (Megatron-BERT model)"),LEr=l(),x4=a("li"),j3e=a("strong"),yEr=o("mobilebert"),xEr=o(" \u2014 "),cK=a("a"),$Er=o("MobileBertForQuestionAnswering"),kEr=o(" (MobileBERT model)"),SEr=l(),$4=a("li"),D3e=a("strong"),REr=o("mpnet"),PEr=o(" \u2014 "),fK=a("a"),BEr=o("MPNetForQuestionAnswering"),IEr=o(" (MPNet model)"),NEr=l(),k4=a("li"),G3e=a("strong"),qEr=o("mvp"),jEr=o(" \u2014 "),gK=a("a"),DEr=o("MvpForQuestionAnswering"),GEr=o(" (MVP model)"),OEr=l(),S4=a("li"),O3e=a("strong"),VEr=o("nezha"),XEr=o(" \u2014 "),hK=a("a"),zEr=o("NezhaForQuestionAnswering"),QEr=o(" (Nezha model)"),WEr=l(),R4=a("li"),V3e=a("strong"),UEr=o("nystromformer"),HEr=o(" \u2014 "),uK=a("a"),JEr=o("NystromformerForQuestionAnswering"),YEr=o(" (Nystr\xF6mformer model)"),ZEr=l(),P4=a("li"),X3e=a("strong"),KEr=o("opt"),e4r=o(" \u2014 "),pK=a("a"),o4r=o("OPTForQuestionAnswering"),r4r=o(" (OPT model)"),t4r=l(),B4=a("li"),z3e=a("strong"),a4r=o("qdqbert"),n4r=o(" \u2014 "),_K=a("a"),s4r=o("QDQBertForQuestionAnswering"),l4r=o(" (QDQBert model)"),i4r=l(),I4=a("li"),Q3e=a("strong"),d4r=o("reformer"),m4r=o(" \u2014 "),bK=a("a"),c4r=o("ReformerForQuestionAnswering"),f4r=o(" (Reformer model)"),g4r=l(),N4=a("li"),W3e=a("strong"),h4r=o("rembert"),u4r=o(" \u2014 "),vK=a("a"),p4r=o("RemBertForQuestionAnswering"),_4r=o(" (RemBERT model)"),b4r=l(),q4=a("li"),U3e=a("strong"),v4r=o("roberta"),F4r=o(" \u2014 "),FK=a("a"),T4r=o("RobertaForQuestionAnswering"),M4r=o(" (RoBERTa model)"),E4r=l(),j4=a("li"),H3e=a("strong"),C4r=o("roformer"),w4r=o(" \u2014 "),TK=a("a"),A4r=o("RoFormerForQuestionAnswering"),L4r=o(" (RoFormer model)"),y4r=l(),D4=a("li"),J3e=a("strong"),x4r=o("splinter"),$4r=o(" \u2014 "),MK=a("a"),k4r=o("SplinterForQuestionAnswering"),S4r=o(" (Splinter model)"),R4r=l(),G4=a("li"),Y3e=a("strong"),P4r=o("squeezebert"),B4r=o(" \u2014 "),EK=a("a"),I4r=o("SqueezeBertForQuestionAnswering"),N4r=o(" (SqueezeBERT model)"),q4r=l(),O4=a("li"),Z3e=a("strong"),j4r=o("xlm"),D4r=o(" \u2014 "),CK=a("a"),G4r=o("XLMForQuestionAnsweringSimple"),O4r=o(" (XLM model)"),V4r=l(),V4=a("li"),K3e=a("strong"),X4r=o("xlm-roberta"),z4r=o(" \u2014 "),wK=a("a"),Q4r=o("XLMRobertaForQuestionAnswering"),W4r=o(" (XLM-RoBERTa model)"),U4r=l(),X4=a("li"),e5e=a("strong"),H4r=o("xlm-roberta-xl"),J4r=o(" \u2014 "),AK=a("a"),Y4r=o("XLMRobertaXLForQuestionAnswering"),Z4r=o(" (XLM-RoBERTa-XL model)"),K4r=l(),z4=a("li"),o5e=a("strong"),eCr=o("xlnet"),oCr=o(" \u2014 "),LK=a("a"),rCr=o("XLNetForQuestionAnsweringSimple"),tCr=o(" (XLNet model)"),aCr=l(),Q4=a("li"),r5e=a("strong"),nCr=o("yoso"),sCr=o(" \u2014 "),yK=a("a"),lCr=o("YosoForQuestionAnswering"),iCr=o(" (YOSO model)"),dCr=l(),W4=a("p"),mCr=o("The model is set in evaluation mode by default using "),t5e=a("code"),cCr=o("model.eval()"),fCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a5e=a("code"),gCr=o("model.train()"),hCr=l(),F(U4.$$.fragment),Vto=l(),dm=a("h2"),H4=a("a"),n5e=a("span"),F(Rk.$$.fragment),uCr=l(),s5e=a("span"),pCr=o("AutoModelForTableQuestionAnswering"),Xto=l(),Wo=a("div"),F(Pk.$$.fragment),_Cr=l(),mm=a("p"),bCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),xK=a("a"),vCr=o("from_pretrained()"),FCr=o(" class method or the "),$K=a("a"),TCr=o("from_config()"),MCr=o(` class
method.`),ECr=l(),Bk=a("p"),CCr=o("This class cannot be instantiated directly using "),l5e=a("code"),wCr=o("__init__()"),ACr=o(" (throws an error)."),LCr=l(),St=a("div"),F(Ik.$$.fragment),yCr=l(),i5e=a("p"),xCr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$Cr=l(),cm=a("p"),kCr=o(`Note:
Loading a model from its configuration file does `),d5e=a("strong"),SCr=o("not"),RCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),PCr=o("from_pretrained()"),BCr=o(" to load the model weights."),ICr=l(),F(J4.$$.fragment),NCr=l(),co=a("div"),F(Nk.$$.fragment),qCr=l(),m5e=a("p"),jCr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),DCr=l(),pn=a("p"),GCr=o("The model class to instantiate is selected based on the "),c5e=a("code"),OCr=o("model_type"),VCr=o(` property of the config object (either
passed as an argument or loaded from `),f5e=a("code"),XCr=o("pretrained_model_name_or_path"),zCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=a("code"),QCr=o("pretrained_model_name_or_path"),WCr=o(":"),UCr=l(),h5e=a("ul"),Y4=a("li"),u5e=a("strong"),HCr=o("tapas"),JCr=o(" \u2014 "),SK=a("a"),YCr=o("TapasForQuestionAnswering"),ZCr=o(" (TAPAS model)"),KCr=l(),Z4=a("p"),e3r=o("The model is set in evaluation mode by default using "),p5e=a("code"),o3r=o("model.eval()"),r3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_5e=a("code"),t3r=o("model.train()"),a3r=l(),F(K4.$$.fragment),zto=l(),fm=a("h2"),eC=a("a"),b5e=a("span"),F(qk.$$.fragment),n3r=l(),v5e=a("span"),s3r=o("AutoModelForDocumentQuestionAnswering"),Qto=l(),Uo=a("div"),F(jk.$$.fragment),l3r=l(),gm=a("p"),i3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),RK=a("a"),d3r=o("from_pretrained()"),m3r=o(" class method or the "),PK=a("a"),c3r=o("from_config()"),f3r=o(` class
method.`),g3r=l(),Dk=a("p"),h3r=o("This class cannot be instantiated directly using "),F5e=a("code"),u3r=o("__init__()"),p3r=o(" (throws an error)."),_3r=l(),Rt=a("div"),F(Gk.$$.fragment),b3r=l(),T5e=a("p"),v3r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),F3r=l(),hm=a("p"),T3r=o(`Note:
Loading a model from its configuration file does `),M5e=a("strong"),M3r=o("not"),E3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BK=a("a"),C3r=o("from_pretrained()"),w3r=o(" to load the model weights."),A3r=l(),F(oC.$$.fragment),L3r=l(),fo=a("div"),F(Ok.$$.fragment),y3r=l(),E5e=a("p"),x3r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),$3r=l(),_n=a("p"),k3r=o("The model class to instantiate is selected based on the "),C5e=a("code"),S3r=o("model_type"),R3r=o(` property of the config object (either
passed as an argument or loaded from `),w5e=a("code"),P3r=o("pretrained_model_name_or_path"),B3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A5e=a("code"),I3r=o("pretrained_model_name_or_path"),N3r=o(":"),q3r=l(),um=a("ul"),rC=a("li"),L5e=a("strong"),j3r=o("layoutlm"),D3r=o(" \u2014 "),IK=a("a"),G3r=o("LayoutLMForQuestionAnswering"),O3r=o(" (LayoutLM model)"),V3r=l(),tC=a("li"),y5e=a("strong"),X3r=o("layoutlmv2"),z3r=o(" \u2014 "),NK=a("a"),Q3r=o("LayoutLMv2ForQuestionAnswering"),W3r=o(" (LayoutLMv2 model)"),U3r=l(),aC=a("li"),x5e=a("strong"),H3r=o("layoutlmv3"),J3r=o(" \u2014 "),qK=a("a"),Y3r=o("LayoutLMv3ForQuestionAnswering"),Z3r=o(" (LayoutLMv3 model)"),K3r=l(),nC=a("p"),e5r=o("The model is set in evaluation mode by default using "),$5e=a("code"),o5r=o("model.eval()"),r5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k5e=a("code"),t5r=o("model.train()"),a5r=l(),F(sC.$$.fragment),Wto=l(),pm=a("h2"),lC=a("a"),S5e=a("span"),F(Vk.$$.fragment),n5r=l(),R5e=a("span"),s5r=o("AutoModelForImageClassification"),Uto=l(),Ho=a("div"),F(Xk.$$.fragment),l5r=l(),_m=a("p"),i5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jK=a("a"),d5r=o("from_pretrained()"),m5r=o(" class method or the "),DK=a("a"),c5r=o("from_config()"),f5r=o(` class
method.`),g5r=l(),zk=a("p"),h5r=o("This class cannot be instantiated directly using "),P5e=a("code"),u5r=o("__init__()"),p5r=o(" (throws an error)."),_5r=l(),Pt=a("div"),F(Qk.$$.fragment),b5r=l(),B5e=a("p"),v5r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),F5r=l(),bm=a("p"),T5r=o(`Note:
Loading a model from its configuration file does `),I5e=a("strong"),M5r=o("not"),E5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=a("a"),C5r=o("from_pretrained()"),w5r=o(" to load the model weights."),A5r=l(),F(iC.$$.fragment),L5r=l(),go=a("div"),F(Wk.$$.fragment),y5r=l(),N5e=a("p"),x5r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$5r=l(),bn=a("p"),k5r=o("The model class to instantiate is selected based on the "),q5e=a("code"),S5r=o("model_type"),R5r=o(` property of the config object (either
passed as an argument or loaded from `),j5e=a("code"),P5r=o("pretrained_model_name_or_path"),B5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D5e=a("code"),I5r=o("pretrained_model_name_or_path"),N5r=o(":"),q5r=l(),be=a("ul"),dC=a("li"),G5e=a("strong"),j5r=o("beit"),D5r=o(" \u2014 "),OK=a("a"),G5r=o("BeitForImageClassification"),O5r=o(" (BEiT model)"),V5r=l(),mC=a("li"),O5e=a("strong"),X5r=o("convnext"),z5r=o(" \u2014 "),VK=a("a"),Q5r=o("ConvNextForImageClassification"),W5r=o(" (ConvNeXT model)"),U5r=l(),cC=a("li"),V5e=a("strong"),H5r=o("cvt"),J5r=o(" \u2014 "),XK=a("a"),Y5r=o("CvtForImageClassification"),Z5r=o(" (CvT model)"),K5r=l(),fC=a("li"),X5e=a("strong"),e0r=o("data2vec-vision"),o0r=o(" \u2014 "),zK=a("a"),r0r=o("Data2VecVisionForImageClassification"),t0r=o(" (Data2VecVision model)"),a0r=l(),xl=a("li"),z5e=a("strong"),n0r=o("deit"),s0r=o(" \u2014 "),QK=a("a"),l0r=o("DeiTForImageClassification"),i0r=o(" or "),WK=a("a"),d0r=o("DeiTForImageClassificationWithTeacher"),m0r=o(" (DeiT model)"),c0r=l(),gC=a("li"),Q5e=a("strong"),f0r=o("imagegpt"),g0r=o(" \u2014 "),UK=a("a"),h0r=o("ImageGPTForImageClassification"),u0r=o(" (ImageGPT model)"),p0r=l(),$l=a("li"),W5e=a("strong"),_0r=o("levit"),b0r=o(" \u2014 "),HK=a("a"),v0r=o("LevitForImageClassification"),F0r=o(" or "),JK=a("a"),T0r=o("LevitForImageClassificationWithTeacher"),M0r=o(" (LeViT model)"),E0r=l(),hC=a("li"),U5e=a("strong"),C0r=o("mobilevit"),w0r=o(" \u2014 "),YK=a("a"),A0r=o("MobileViTForImageClassification"),L0r=o(" (MobileViT model)"),y0r=l(),Bt=a("li"),H5e=a("strong"),x0r=o("perceiver"),$0r=o(" \u2014 "),ZK=a("a"),k0r=o("PerceiverForImageClassificationLearned"),S0r=o(" or "),KK=a("a"),R0r=o("PerceiverForImageClassificationFourier"),P0r=o(" or "),eee=a("a"),B0r=o("PerceiverForImageClassificationConvProcessing"),I0r=o(" (Perceiver model)"),N0r=l(),uC=a("li"),J5e=a("strong"),q0r=o("poolformer"),j0r=o(" \u2014 "),oee=a("a"),D0r=o("PoolFormerForImageClassification"),G0r=o(" (PoolFormer model)"),O0r=l(),pC=a("li"),Y5e=a("strong"),V0r=o("regnet"),X0r=o(" \u2014 "),ree=a("a"),z0r=o("RegNetForImageClassification"),Q0r=o(" (RegNet model)"),W0r=l(),_C=a("li"),Z5e=a("strong"),U0r=o("resnet"),H0r=o(" \u2014 "),tee=a("a"),J0r=o("ResNetForImageClassification"),Y0r=o(" (ResNet model)"),Z0r=l(),bC=a("li"),K5e=a("strong"),K0r=o("segformer"),ewr=o(" \u2014 "),aee=a("a"),owr=o("SegformerForImageClassification"),rwr=o(" (SegFormer model)"),twr=l(),vC=a("li"),e0e=a("strong"),awr=o("swin"),nwr=o(" \u2014 "),nee=a("a"),swr=o("SwinForImageClassification"),lwr=o(" (Swin Transformer model)"),iwr=l(),FC=a("li"),o0e=a("strong"),dwr=o("swinv2"),mwr=o(" \u2014 "),see=a("a"),cwr=o("Swinv2ForImageClassification"),fwr=o(" (Swin Transformer V2 model)"),gwr=l(),TC=a("li"),r0e=a("strong"),hwr=o("van"),uwr=o(" \u2014 "),lee=a("a"),pwr=o("VanForImageClassification"),_wr=o(" (VAN model)"),bwr=l(),MC=a("li"),t0e=a("strong"),vwr=o("vit"),Fwr=o(" \u2014 "),iee=a("a"),Twr=o("ViTForImageClassification"),Mwr=o(" (ViT model)"),Ewr=l(),EC=a("li"),a0e=a("strong"),Cwr=o("vit_msn"),wwr=o(" \u2014 "),dee=a("a"),Awr=o("ViTMSNForImageClassification"),Lwr=o(" (ViTMSN model)"),ywr=l(),CC=a("p"),xwr=o("The model is set in evaluation mode by default using "),n0e=a("code"),$wr=o("model.eval()"),kwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s0e=a("code"),Swr=o("model.train()"),Rwr=l(),F(wC.$$.fragment),Hto=l(),vm=a("h2"),AC=a("a"),l0e=a("span"),F(Uk.$$.fragment),Pwr=l(),i0e=a("span"),Bwr=o("AutoModelForVideoClassification"),Jto=l(),Jo=a("div"),F(Hk.$$.fragment),Iwr=l(),Fm=a("p"),Nwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),mee=a("a"),qwr=o("from_pretrained()"),jwr=o(" class method or the "),cee=a("a"),Dwr=o("from_config()"),Gwr=o(` class
method.`),Owr=l(),Jk=a("p"),Vwr=o("This class cannot be instantiated directly using "),d0e=a("code"),Xwr=o("__init__()"),zwr=o(" (throws an error)."),Qwr=l(),It=a("div"),F(Yk.$$.fragment),Wwr=l(),m0e=a("p"),Uwr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),Hwr=l(),Tm=a("p"),Jwr=o(`Note:
Loading a model from its configuration file does `),c0e=a("strong"),Ywr=o("not"),Zwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fee=a("a"),Kwr=o("from_pretrained()"),eAr=o(" to load the model weights."),oAr=l(),F(LC.$$.fragment),rAr=l(),ho=a("div"),F(Zk.$$.fragment),tAr=l(),f0e=a("p"),aAr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),nAr=l(),vn=a("p"),sAr=o("The model class to instantiate is selected based on the "),g0e=a("code"),lAr=o("model_type"),iAr=o(` property of the config object (either
passed as an argument or loaded from `),h0e=a("code"),dAr=o("pretrained_model_name_or_path"),mAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u0e=a("code"),cAr=o("pretrained_model_name_or_path"),fAr=o(":"),gAr=l(),p0e=a("ul"),yC=a("li"),_0e=a("strong"),hAr=o("videomae"),uAr=o(" \u2014 "),gee=a("a"),pAr=o("VideoMAEForVideoClassification"),_Ar=o(" (VideoMAE model)"),bAr=l(),xC=a("p"),vAr=o("The model is set in evaluation mode by default using "),b0e=a("code"),FAr=o("model.eval()"),TAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v0e=a("code"),MAr=o("model.train()"),EAr=l(),F($C.$$.fragment),Yto=l(),Mm=a("h2"),kC=a("a"),F0e=a("span"),F(Kk.$$.fragment),CAr=l(),T0e=a("span"),wAr=o("AutoModelForVision2Seq"),Zto=l(),Yo=a("div"),F(eS.$$.fragment),AAr=l(),Em=a("p"),LAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hee=a("a"),yAr=o("from_pretrained()"),xAr=o(" class method or the "),uee=a("a"),$Ar=o("from_config()"),kAr=o(` class
method.`),SAr=l(),oS=a("p"),RAr=o("This class cannot be instantiated directly using "),M0e=a("code"),PAr=o("__init__()"),BAr=o(" (throws an error)."),IAr=l(),Nt=a("div"),F(rS.$$.fragment),NAr=l(),E0e=a("p"),qAr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jAr=l(),Cm=a("p"),DAr=o(`Note:
Loading a model from its configuration file does `),C0e=a("strong"),GAr=o("not"),OAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pee=a("a"),VAr=o("from_pretrained()"),XAr=o(" to load the model weights."),zAr=l(),F(SC.$$.fragment),QAr=l(),uo=a("div"),F(tS.$$.fragment),WAr=l(),w0e=a("p"),UAr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),HAr=l(),Fn=a("p"),JAr=o("The model class to instantiate is selected based on the "),A0e=a("code"),YAr=o("model_type"),ZAr=o(` property of the config object (either
passed as an argument or loaded from `),L0e=a("code"),KAr=o("pretrained_model_name_or_path"),e6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y0e=a("code"),o6r=o("pretrained_model_name_or_path"),r6r=o(":"),t6r=l(),x0e=a("ul"),RC=a("li"),$0e=a("strong"),a6r=o("vision-encoder-decoder"),n6r=o(" \u2014 "),_ee=a("a"),s6r=o("VisionEncoderDecoderModel"),l6r=o(" (Vision Encoder decoder model)"),i6r=l(),PC=a("p"),d6r=o("The model is set in evaluation mode by default using "),k0e=a("code"),m6r=o("model.eval()"),c6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=a("code"),f6r=o("model.train()"),g6r=l(),F(BC.$$.fragment),Kto=l(),wm=a("h2"),IC=a("a"),R0e=a("span"),F(aS.$$.fragment),h6r=l(),P0e=a("span"),u6r=o("AutoModelForVisualQuestionAnswering"),eao=l(),Zo=a("div"),F(nS.$$.fragment),p6r=l(),Am=a("p"),_6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),bee=a("a"),b6r=o("from_pretrained()"),v6r=o(" class method or the "),vee=a("a"),F6r=o("from_config()"),T6r=o(` class
method.`),M6r=l(),sS=a("p"),E6r=o("This class cannot be instantiated directly using "),B0e=a("code"),C6r=o("__init__()"),w6r=o(" (throws an error)."),A6r=l(),qt=a("div"),F(lS.$$.fragment),L6r=l(),I0e=a("p"),y6r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),x6r=l(),Lm=a("p"),$6r=o(`Note:
Loading a model from its configuration file does `),N0e=a("strong"),k6r=o("not"),S6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fee=a("a"),R6r=o("from_pretrained()"),P6r=o(" to load the model weights."),B6r=l(),F(NC.$$.fragment),I6r=l(),po=a("div"),F(iS.$$.fragment),N6r=l(),q0e=a("p"),q6r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),j6r=l(),Tn=a("p"),D6r=o("The model class to instantiate is selected based on the "),j0e=a("code"),G6r=o("model_type"),O6r=o(` property of the config object (either
passed as an argument or loaded from `),D0e=a("code"),V6r=o("pretrained_model_name_or_path"),X6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=a("code"),z6r=o("pretrained_model_name_or_path"),Q6r=o(":"),W6r=l(),O0e=a("ul"),qC=a("li"),V0e=a("strong"),U6r=o("vilt"),H6r=o(" \u2014 "),Tee=a("a"),J6r=o("ViltForQuestionAnswering"),Y6r=o(" (ViLT model)"),Z6r=l(),jC=a("p"),K6r=o("The model is set in evaluation mode by default using "),X0e=a("code"),e7r=o("model.eval()"),o7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z0e=a("code"),r7r=o("model.train()"),t7r=l(),F(DC.$$.fragment),oao=l(),ym=a("h2"),GC=a("a"),Q0e=a("span"),F(dS.$$.fragment),a7r=l(),W0e=a("span"),n7r=o("AutoModelForAudioClassification"),rao=l(),Ko=a("div"),F(mS.$$.fragment),s7r=l(),xm=a("p"),l7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Mee=a("a"),i7r=o("from_pretrained()"),d7r=o(" class method or the "),Eee=a("a"),m7r=o("from_config()"),c7r=o(` class
method.`),f7r=l(),cS=a("p"),g7r=o("This class cannot be instantiated directly using "),U0e=a("code"),h7r=o("__init__()"),u7r=o(" (throws an error)."),p7r=l(),jt=a("div"),F(fS.$$.fragment),_7r=l(),H0e=a("p"),b7r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),v7r=l(),$m=a("p"),F7r=o(`Note:
Loading a model from its configuration file does `),J0e=a("strong"),T7r=o("not"),M7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cee=a("a"),E7r=o("from_pretrained()"),C7r=o(" to load the model weights."),w7r=l(),F(OC.$$.fragment),A7r=l(),_o=a("div"),F(gS.$$.fragment),L7r=l(),Y0e=a("p"),y7r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),x7r=l(),Mn=a("p"),$7r=o("The model class to instantiate is selected based on the "),Z0e=a("code"),k7r=o("model_type"),S7r=o(` property of the config object (either
passed as an argument or loaded from `),K0e=a("code"),R7r=o("pretrained_model_name_or_path"),P7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=a("code"),B7r=o("pretrained_model_name_or_path"),I7r=o(":"),N7r=l(),Be=a("ul"),VC=a("li"),owe=a("strong"),q7r=o("data2vec-audio"),j7r=o(" \u2014 "),wee=a("a"),D7r=o("Data2VecAudioForSequenceClassification"),G7r=o(" (Data2VecAudio model)"),O7r=l(),XC=a("li"),rwe=a("strong"),V7r=o("hubert"),X7r=o(" \u2014 "),Aee=a("a"),z7r=o("HubertForSequenceClassification"),Q7r=o(" (Hubert model)"),W7r=l(),zC=a("li"),twe=a("strong"),U7r=o("sew"),H7r=o(" \u2014 "),Lee=a("a"),J7r=o("SEWForSequenceClassification"),Y7r=o(" (SEW model)"),Z7r=l(),QC=a("li"),awe=a("strong"),K7r=o("sew-d"),e8r=o(" \u2014 "),yee=a("a"),o8r=o("SEWDForSequenceClassification"),r8r=o(" (SEW-D model)"),t8r=l(),WC=a("li"),nwe=a("strong"),a8r=o("unispeech"),n8r=o(" \u2014 "),xee=a("a"),s8r=o("UniSpeechForSequenceClassification"),l8r=o(" (UniSpeech model)"),i8r=l(),UC=a("li"),swe=a("strong"),d8r=o("unispeech-sat"),m8r=o(" \u2014 "),$ee=a("a"),c8r=o("UniSpeechSatForSequenceClassification"),f8r=o(" (UniSpeechSat model)"),g8r=l(),HC=a("li"),lwe=a("strong"),h8r=o("wav2vec2"),u8r=o(" \u2014 "),kee=a("a"),p8r=o("Wav2Vec2ForSequenceClassification"),_8r=o(" (Wav2Vec2 model)"),b8r=l(),JC=a("li"),iwe=a("strong"),v8r=o("wav2vec2-conformer"),F8r=o(" \u2014 "),See=a("a"),T8r=o("Wav2Vec2ConformerForSequenceClassification"),M8r=o(" (Wav2Vec2-Conformer model)"),E8r=l(),YC=a("li"),dwe=a("strong"),C8r=o("wavlm"),w8r=o(" \u2014 "),Ree=a("a"),A8r=o("WavLMForSequenceClassification"),L8r=o(" (WavLM model)"),y8r=l(),ZC=a("p"),x8r=o("The model is set in evaluation mode by default using "),mwe=a("code"),$8r=o("model.eval()"),k8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cwe=a("code"),S8r=o("model.train()"),R8r=l(),F(KC.$$.fragment),tao=l(),km=a("h2"),e3=a("a"),fwe=a("span"),F(hS.$$.fragment),P8r=l(),gwe=a("span"),B8r=o("AutoModelForAudioFrameClassification"),aao=l(),er=a("div"),F(uS.$$.fragment),I8r=l(),Sm=a("p"),N8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Pee=a("a"),q8r=o("from_pretrained()"),j8r=o(" class method or the "),Bee=a("a"),D8r=o("from_config()"),G8r=o(` class
method.`),O8r=l(),pS=a("p"),V8r=o("This class cannot be instantiated directly using "),hwe=a("code"),X8r=o("__init__()"),z8r=o(" (throws an error)."),Q8r=l(),Dt=a("div"),F(_S.$$.fragment),W8r=l(),uwe=a("p"),U8r=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),H8r=l(),Rm=a("p"),J8r=o(`Note:
Loading a model from its configuration file does `),pwe=a("strong"),Y8r=o("not"),Z8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=a("a"),K8r=o("from_pretrained()"),eLr=o(" to load the model weights."),oLr=l(),F(o3.$$.fragment),rLr=l(),bo=a("div"),F(bS.$$.fragment),tLr=l(),_we=a("p"),aLr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),nLr=l(),En=a("p"),sLr=o("The model class to instantiate is selected based on the "),bwe=a("code"),lLr=o("model_type"),iLr=o(` property of the config object (either
passed as an argument or loaded from `),vwe=a("code"),dLr=o("pretrained_model_name_or_path"),mLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=a("code"),cLr=o("pretrained_model_name_or_path"),fLr=o(":"),gLr=l(),ut=a("ul"),r3=a("li"),Twe=a("strong"),hLr=o("data2vec-audio"),uLr=o(" \u2014 "),Nee=a("a"),pLr=o("Data2VecAudioForAudioFrameClassification"),_Lr=o(" (Data2VecAudio model)"),bLr=l(),t3=a("li"),Mwe=a("strong"),vLr=o("unispeech-sat"),FLr=o(" \u2014 "),qee=a("a"),TLr=o("UniSpeechSatForAudioFrameClassification"),MLr=o(" (UniSpeechSat model)"),ELr=l(),a3=a("li"),Ewe=a("strong"),CLr=o("wav2vec2"),wLr=o(" \u2014 "),jee=a("a"),ALr=o("Wav2Vec2ForAudioFrameClassification"),LLr=o(" (Wav2Vec2 model)"),yLr=l(),n3=a("li"),Cwe=a("strong"),xLr=o("wav2vec2-conformer"),$Lr=o(" \u2014 "),Dee=a("a"),kLr=o("Wav2Vec2ConformerForAudioFrameClassification"),SLr=o(" (Wav2Vec2-Conformer model)"),RLr=l(),s3=a("li"),wwe=a("strong"),PLr=o("wavlm"),BLr=o(" \u2014 "),Gee=a("a"),ILr=o("WavLMForAudioFrameClassification"),NLr=o(" (WavLM model)"),qLr=l(),l3=a("p"),jLr=o("The model is set in evaluation mode by default using "),Awe=a("code"),DLr=o("model.eval()"),GLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lwe=a("code"),OLr=o("model.train()"),VLr=l(),F(i3.$$.fragment),nao=l(),Pm=a("h2"),d3=a("a"),ywe=a("span"),F(vS.$$.fragment),XLr=l(),xwe=a("span"),zLr=o("AutoModelForCTC"),sao=l(),or=a("div"),F(FS.$$.fragment),QLr=l(),Bm=a("p"),WLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Oee=a("a"),ULr=o("from_pretrained()"),HLr=o(" class method or the "),Vee=a("a"),JLr=o("from_config()"),YLr=o(` class
method.`),ZLr=l(),TS=a("p"),KLr=o("This class cannot be instantiated directly using "),$we=a("code"),eyr=o("__init__()"),oyr=o(" (throws an error)."),ryr=l(),Gt=a("div"),F(MS.$$.fragment),tyr=l(),kwe=a("p"),ayr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),nyr=l(),Im=a("p"),syr=o(`Note:
Loading a model from its configuration file does `),Swe=a("strong"),lyr=o("not"),iyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xee=a("a"),dyr=o("from_pretrained()"),myr=o(" to load the model weights."),cyr=l(),F(m3.$$.fragment),fyr=l(),vo=a("div"),F(ES.$$.fragment),gyr=l(),Rwe=a("p"),hyr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),uyr=l(),Cn=a("p"),pyr=o("The model class to instantiate is selected based on the "),Pwe=a("code"),_yr=o("model_type"),byr=o(` property of the config object (either
passed as an argument or loaded from `),Bwe=a("code"),vyr=o("pretrained_model_name_or_path"),Fyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iwe=a("code"),Tyr=o("pretrained_model_name_or_path"),Myr=o(":"),Eyr=l(),Le=a("ul"),c3=a("li"),Nwe=a("strong"),Cyr=o("data2vec-audio"),wyr=o(" \u2014 "),zee=a("a"),Ayr=o("Data2VecAudioForCTC"),Lyr=o(" (Data2VecAudio model)"),yyr=l(),f3=a("li"),qwe=a("strong"),xyr=o("hubert"),$yr=o(" \u2014 "),Qee=a("a"),kyr=o("HubertForCTC"),Syr=o(" (Hubert model)"),Ryr=l(),g3=a("li"),jwe=a("strong"),Pyr=o("mctct"),Byr=o(" \u2014 "),Wee=a("a"),Iyr=o("MCTCTForCTC"),Nyr=o(" (M-CTC-T model)"),qyr=l(),h3=a("li"),Dwe=a("strong"),jyr=o("sew"),Dyr=o(" \u2014 "),Uee=a("a"),Gyr=o("SEWForCTC"),Oyr=o(" (SEW model)"),Vyr=l(),u3=a("li"),Gwe=a("strong"),Xyr=o("sew-d"),zyr=o(" \u2014 "),Hee=a("a"),Qyr=o("SEWDForCTC"),Wyr=o(" (SEW-D model)"),Uyr=l(),p3=a("li"),Owe=a("strong"),Hyr=o("unispeech"),Jyr=o(" \u2014 "),Jee=a("a"),Yyr=o("UniSpeechForCTC"),Zyr=o(" (UniSpeech model)"),Kyr=l(),_3=a("li"),Vwe=a("strong"),e9r=o("unispeech-sat"),o9r=o(" \u2014 "),Yee=a("a"),r9r=o("UniSpeechSatForCTC"),t9r=o(" (UniSpeechSat model)"),a9r=l(),b3=a("li"),Xwe=a("strong"),n9r=o("wav2vec2"),s9r=o(" \u2014 "),Zee=a("a"),l9r=o("Wav2Vec2ForCTC"),i9r=o(" (Wav2Vec2 model)"),d9r=l(),v3=a("li"),zwe=a("strong"),m9r=o("wav2vec2-conformer"),c9r=o(" \u2014 "),Kee=a("a"),f9r=o("Wav2Vec2ConformerForCTC"),g9r=o(" (Wav2Vec2-Conformer model)"),h9r=l(),F3=a("li"),Qwe=a("strong"),u9r=o("wavlm"),p9r=o(" \u2014 "),eoe=a("a"),_9r=o("WavLMForCTC"),b9r=o(" (WavLM model)"),v9r=l(),T3=a("p"),F9r=o("The model is set in evaluation mode by default using "),Wwe=a("code"),T9r=o("model.eval()"),M9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uwe=a("code"),E9r=o("model.train()"),C9r=l(),F(M3.$$.fragment),lao=l(),Nm=a("h2"),E3=a("a"),Hwe=a("span"),F(CS.$$.fragment),w9r=l(),Jwe=a("span"),A9r=o("AutoModelForSpeechSeq2Seq"),iao=l(),rr=a("div"),F(wS.$$.fragment),L9r=l(),qm=a("p"),y9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ooe=a("a"),x9r=o("from_pretrained()"),$9r=o(" class method or the "),roe=a("a"),k9r=o("from_config()"),S9r=o(` class
method.`),R9r=l(),AS=a("p"),P9r=o("This class cannot be instantiated directly using "),Ywe=a("code"),B9r=o("__init__()"),I9r=o(" (throws an error)."),N9r=l(),Ot=a("div"),F(LS.$$.fragment),q9r=l(),Zwe=a("p"),j9r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),D9r=l(),jm=a("p"),G9r=o(`Note:
Loading a model from its configuration file does `),Kwe=a("strong"),O9r=o("not"),V9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=a("a"),X9r=o("from_pretrained()"),z9r=o(" to load the model weights."),Q9r=l(),F(C3.$$.fragment),W9r=l(),Fo=a("div"),F(yS.$$.fragment),U9r=l(),eAe=a("p"),H9r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),J9r=l(),wn=a("p"),Y9r=o("The model class to instantiate is selected based on the "),oAe=a("code"),Z9r=o("model_type"),K9r=o(` property of the config object (either
passed as an argument or loaded from `),rAe=a("code"),exr=o("pretrained_model_name_or_path"),oxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tAe=a("code"),rxr=o("pretrained_model_name_or_path"),txr=o(":"),axr=l(),Dm=a("ul"),w3=a("li"),aAe=a("strong"),nxr=o("speech-encoder-decoder"),sxr=o(" \u2014 "),aoe=a("a"),lxr=o("SpeechEncoderDecoderModel"),ixr=o(" (Speech Encoder decoder model)"),dxr=l(),A3=a("li"),nAe=a("strong"),mxr=o("speech_to_text"),cxr=o(" \u2014 "),noe=a("a"),fxr=o("Speech2TextForConditionalGeneration"),gxr=o(" (Speech2Text model)"),hxr=l(),L3=a("li"),sAe=a("strong"),uxr=o("whisper"),pxr=o(" \u2014 "),soe=a("a"),_xr=o("WhisperForConditionalGeneration"),bxr=o(" (Whisper model)"),vxr=l(),y3=a("p"),Fxr=o("The model is set in evaluation mode by default using "),lAe=a("code"),Txr=o("model.eval()"),Mxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iAe=a("code"),Exr=o("model.train()"),Cxr=l(),F(x3.$$.fragment),dao=l(),Gm=a("h2"),$3=a("a"),dAe=a("span"),F(xS.$$.fragment),wxr=l(),mAe=a("span"),Axr=o("AutoModelForAudioXVector"),mao=l(),tr=a("div"),F($S.$$.fragment),Lxr=l(),Om=a("p"),yxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),loe=a("a"),xxr=o("from_pretrained()"),$xr=o(" class method or the "),ioe=a("a"),kxr=o("from_config()"),Sxr=o(` class
method.`),Rxr=l(),kS=a("p"),Pxr=o("This class cannot be instantiated directly using "),cAe=a("code"),Bxr=o("__init__()"),Ixr=o(" (throws an error)."),Nxr=l(),Vt=a("div"),F(SS.$$.fragment),qxr=l(),fAe=a("p"),jxr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Dxr=l(),Vm=a("p"),Gxr=o(`Note:
Loading a model from its configuration file does `),gAe=a("strong"),Oxr=o("not"),Vxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=a("a"),Xxr=o("from_pretrained()"),zxr=o(" to load the model weights."),Qxr=l(),F(k3.$$.fragment),Wxr=l(),To=a("div"),F(RS.$$.fragment),Uxr=l(),hAe=a("p"),Hxr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Jxr=l(),An=a("p"),Yxr=o("The model class to instantiate is selected based on the "),uAe=a("code"),Zxr=o("model_type"),Kxr=o(` property of the config object (either
passed as an argument or loaded from `),pAe=a("code"),e$r=o("pretrained_model_name_or_path"),o$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=a("code"),r$r=o("pretrained_model_name_or_path"),t$r=o(":"),a$r=l(),pt=a("ul"),S3=a("li"),bAe=a("strong"),n$r=o("data2vec-audio"),s$r=o(" \u2014 "),moe=a("a"),l$r=o("Data2VecAudioForXVector"),i$r=o(" (Data2VecAudio model)"),d$r=l(),R3=a("li"),vAe=a("strong"),m$r=o("unispeech-sat"),c$r=o(" \u2014 "),coe=a("a"),f$r=o("UniSpeechSatForXVector"),g$r=o(" (UniSpeechSat model)"),h$r=l(),P3=a("li"),FAe=a("strong"),u$r=o("wav2vec2"),p$r=o(" \u2014 "),foe=a("a"),_$r=o("Wav2Vec2ForXVector"),b$r=o(" (Wav2Vec2 model)"),v$r=l(),B3=a("li"),TAe=a("strong"),F$r=o("wav2vec2-conformer"),T$r=o(" \u2014 "),goe=a("a"),M$r=o("Wav2Vec2ConformerForXVector"),E$r=o(" (Wav2Vec2-Conformer model)"),C$r=l(),I3=a("li"),MAe=a("strong"),w$r=o("wavlm"),A$r=o(" \u2014 "),hoe=a("a"),L$r=o("WavLMForXVector"),y$r=o(" (WavLM model)"),x$r=l(),N3=a("p"),$$r=o("The model is set in evaluation mode by default using "),EAe=a("code"),k$r=o("model.eval()"),S$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CAe=a("code"),R$r=o("model.train()"),P$r=l(),F(q3.$$.fragment),cao=l(),Xm=a("h2"),j3=a("a"),wAe=a("span"),F(PS.$$.fragment),B$r=l(),AAe=a("span"),I$r=o("AutoModelForMaskedImageModeling"),fao=l(),ar=a("div"),F(BS.$$.fragment),N$r=l(),zm=a("p"),q$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),uoe=a("a"),j$r=o("from_pretrained()"),D$r=o(" class method or the "),poe=a("a"),G$r=o("from_config()"),O$r=o(` class
method.`),V$r=l(),IS=a("p"),X$r=o("This class cannot be instantiated directly using "),LAe=a("code"),z$r=o("__init__()"),Q$r=o(" (throws an error)."),W$r=l(),Xt=a("div"),F(NS.$$.fragment),U$r=l(),yAe=a("p"),H$r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),J$r=l(),Qm=a("p"),Y$r=o(`Note:
Loading a model from its configuration file does `),xAe=a("strong"),Z$r=o("not"),K$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),ekr=o("from_pretrained()"),okr=o(" to load the model weights."),rkr=l(),F(D3.$$.fragment),tkr=l(),Mo=a("div"),F(qS.$$.fragment),akr=l(),$Ae=a("p"),nkr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),skr=l(),Ln=a("p"),lkr=o("The model class to instantiate is selected based on the "),kAe=a("code"),ikr=o("model_type"),dkr=o(` property of the config object (either
passed as an argument or loaded from `),SAe=a("code"),mkr=o("pretrained_model_name_or_path"),ckr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RAe=a("code"),fkr=o("pretrained_model_name_or_path"),gkr=o(":"),hkr=l(),yn=a("ul"),G3=a("li"),PAe=a("strong"),ukr=o("deit"),pkr=o(" \u2014 "),boe=a("a"),_kr=o("DeiTForMaskedImageModeling"),bkr=o(" (DeiT model)"),vkr=l(),O3=a("li"),BAe=a("strong"),Fkr=o("swin"),Tkr=o(" \u2014 "),voe=a("a"),Mkr=o("SwinForMaskedImageModeling"),Ekr=o(" (Swin Transformer model)"),Ckr=l(),V3=a("li"),IAe=a("strong"),wkr=o("swinv2"),Akr=o(" \u2014 "),Foe=a("a"),Lkr=o("Swinv2ForMaskedImageModeling"),ykr=o(" (Swin Transformer V2 model)"),xkr=l(),X3=a("li"),NAe=a("strong"),$kr=o("vit"),kkr=o(" \u2014 "),Toe=a("a"),Skr=o("ViTForMaskedImageModeling"),Rkr=o(" (ViT model)"),Pkr=l(),z3=a("p"),Bkr=o("The model is set in evaluation mode by default using "),qAe=a("code"),Ikr=o("model.eval()"),Nkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jAe=a("code"),qkr=o("model.train()"),jkr=l(),F(Q3.$$.fragment),gao=l(),Wm=a("h2"),W3=a("a"),DAe=a("span"),F(jS.$$.fragment),Dkr=l(),GAe=a("span"),Gkr=o("AutoModelForObjectDetection"),hao=l(),nr=a("div"),F(DS.$$.fragment),Okr=l(),Um=a("p"),Vkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Moe=a("a"),Xkr=o("from_pretrained()"),zkr=o(" class method or the "),Eoe=a("a"),Qkr=o("from_config()"),Wkr=o(` class
method.`),Ukr=l(),GS=a("p"),Hkr=o("This class cannot be instantiated directly using "),OAe=a("code"),Jkr=o("__init__()"),Ykr=o(" (throws an error)."),Zkr=l(),zt=a("div"),F(OS.$$.fragment),Kkr=l(),VAe=a("p"),eSr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),oSr=l(),Hm=a("p"),rSr=o(`Note:
Loading a model from its configuration file does `),XAe=a("strong"),tSr=o("not"),aSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Coe=a("a"),nSr=o("from_pretrained()"),sSr=o(" to load the model weights."),lSr=l(),F(U3.$$.fragment),iSr=l(),Eo=a("div"),F(VS.$$.fragment),dSr=l(),zAe=a("p"),mSr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),cSr=l(),xn=a("p"),fSr=o("The model class to instantiate is selected based on the "),QAe=a("code"),gSr=o("model_type"),hSr=o(` property of the config object (either
passed as an argument or loaded from `),WAe=a("code"),uSr=o("pretrained_model_name_or_path"),pSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UAe=a("code"),_Sr=o("pretrained_model_name_or_path"),bSr=o(":"),vSr=l(),$n=a("ul"),H3=a("li"),HAe=a("strong"),FSr=o("conditional_detr"),TSr=o(" \u2014 "),woe=a("a"),MSr=o("ConditionalDetrForObjectDetection"),ESr=o(" (Conditional DETR model)"),CSr=l(),J3=a("li"),JAe=a("strong"),wSr=o("deformable_detr"),ASr=o(" \u2014 "),Aoe=a("a"),LSr=o("DeformableDetrForObjectDetection"),ySr=o(" (Deformable DETR model)"),xSr=l(),Y3=a("li"),YAe=a("strong"),$Sr=o("detr"),kSr=o(" \u2014 "),Loe=a("a"),SSr=o("DetrForObjectDetection"),RSr=o(" (DETR model)"),PSr=l(),Z3=a("li"),ZAe=a("strong"),BSr=o("yolos"),ISr=o(" \u2014 "),yoe=a("a"),NSr=o("YolosForObjectDetection"),qSr=o(" (YOLOS model)"),jSr=l(),K3=a("p"),DSr=o("The model is set in evaluation mode by default using "),KAe=a("code"),GSr=o("model.eval()"),OSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e6e=a("code"),VSr=o("model.train()"),XSr=l(),F(e5.$$.fragment),uao=l(),Jm=a("h2"),o5=a("a"),o6e=a("span"),F(XS.$$.fragment),zSr=l(),r6e=a("span"),QSr=o("AutoModelForImageSegmentation"),pao=l(),sr=a("div"),F(zS.$$.fragment),WSr=l(),Ym=a("p"),USr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),xoe=a("a"),HSr=o("from_pretrained()"),JSr=o(" class method or the "),$oe=a("a"),YSr=o("from_config()"),ZSr=o(` class
method.`),KSr=l(),QS=a("p"),eRr=o("This class cannot be instantiated directly using "),t6e=a("code"),oRr=o("__init__()"),rRr=o(" (throws an error)."),tRr=l(),Qt=a("div"),F(WS.$$.fragment),aRr=l(),a6e=a("p"),nRr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),sRr=l(),Zm=a("p"),lRr=o(`Note:
Loading a model from its configuration file does `),n6e=a("strong"),iRr=o("not"),dRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),koe=a("a"),mRr=o("from_pretrained()"),cRr=o(" to load the model weights."),fRr=l(),F(r5.$$.fragment),gRr=l(),Co=a("div"),F(US.$$.fragment),hRr=l(),s6e=a("p"),uRr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),pRr=l(),kn=a("p"),_Rr=o("The model class to instantiate is selected based on the "),l6e=a("code"),bRr=o("model_type"),vRr=o(` property of the config object (either
passed as an argument or loaded from `),i6e=a("code"),FRr=o("pretrained_model_name_or_path"),TRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d6e=a("code"),MRr=o("pretrained_model_name_or_path"),ERr=o(":"),CRr=l(),m6e=a("ul"),t5=a("li"),c6e=a("strong"),wRr=o("detr"),ARr=o(" \u2014 "),Soe=a("a"),LRr=o("DetrForSegmentation"),yRr=o(" (DETR model)"),xRr=l(),a5=a("p"),$Rr=o("The model is set in evaluation mode by default using "),f6e=a("code"),kRr=o("model.eval()"),SRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g6e=a("code"),RRr=o("model.train()"),PRr=l(),F(n5.$$.fragment),_ao=l(),Km=a("h2"),s5=a("a"),h6e=a("span"),F(HS.$$.fragment),BRr=l(),u6e=a("span"),IRr=o("AutoModelForSemanticSegmentation"),bao=l(),lr=a("div"),F(JS.$$.fragment),NRr=l(),ec=a("p"),qRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Roe=a("a"),jRr=o("from_pretrained()"),DRr=o(" class method or the "),Poe=a("a"),GRr=o("from_config()"),ORr=o(` class
method.`),VRr=l(),YS=a("p"),XRr=o("This class cannot be instantiated directly using "),p6e=a("code"),zRr=o("__init__()"),QRr=o(" (throws an error)."),WRr=l(),Wt=a("div"),F(ZS.$$.fragment),URr=l(),_6e=a("p"),HRr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),JRr=l(),oc=a("p"),YRr=o(`Note:
Loading a model from its configuration file does `),b6e=a("strong"),ZRr=o("not"),KRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Boe=a("a"),ePr=o("from_pretrained()"),oPr=o(" to load the model weights."),rPr=l(),F(l5.$$.fragment),tPr=l(),wo=a("div"),F(KS.$$.fragment),aPr=l(),v6e=a("p"),nPr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),sPr=l(),Sn=a("p"),lPr=o("The model class to instantiate is selected based on the "),F6e=a("code"),iPr=o("model_type"),dPr=o(` property of the config object (either
passed as an argument or loaded from `),T6e=a("code"),mPr=o("pretrained_model_name_or_path"),cPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M6e=a("code"),fPr=o("pretrained_model_name_or_path"),gPr=o(":"),hPr=l(),_t=a("ul"),i5=a("li"),E6e=a("strong"),uPr=o("beit"),pPr=o(" \u2014 "),Ioe=a("a"),_Pr=o("BeitForSemanticSegmentation"),bPr=o(" (BEiT model)"),vPr=l(),d5=a("li"),C6e=a("strong"),FPr=o("data2vec-vision"),TPr=o(" \u2014 "),Noe=a("a"),MPr=o("Data2VecVisionForSemanticSegmentation"),EPr=o(" (Data2VecVision model)"),CPr=l(),m5=a("li"),w6e=a("strong"),wPr=o("dpt"),APr=o(" \u2014 "),qoe=a("a"),LPr=o("DPTForSemanticSegmentation"),yPr=o(" (DPT model)"),xPr=l(),c5=a("li"),A6e=a("strong"),$Pr=o("mobilevit"),kPr=o(" \u2014 "),joe=a("a"),SPr=o("MobileViTForSemanticSegmentation"),RPr=o(" (MobileViT model)"),PPr=l(),f5=a("li"),L6e=a("strong"),BPr=o("segformer"),IPr=o(" \u2014 "),Doe=a("a"),NPr=o("SegformerForSemanticSegmentation"),qPr=o(" (SegFormer model)"),jPr=l(),g5=a("p"),DPr=o("The model is set in evaluation mode by default using "),y6e=a("code"),GPr=o("model.eval()"),OPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x6e=a("code"),VPr=o("model.train()"),XPr=l(),F(h5.$$.fragment),vao=l(),rc=a("h2"),u5=a("a"),$6e=a("span"),F(eR.$$.fragment),zPr=l(),k6e=a("span"),QPr=o("AutoModelForInstanceSegmentation"),Fao=l(),ir=a("div"),F(oR.$$.fragment),WPr=l(),tc=a("p"),UPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Goe=a("a"),HPr=o("from_pretrained()"),JPr=o(" class method or the "),Ooe=a("a"),YPr=o("from_config()"),ZPr=o(` class
method.`),KPr=l(),rR=a("p"),eBr=o("This class cannot be instantiated directly using "),S6e=a("code"),oBr=o("__init__()"),rBr=o(" (throws an error)."),tBr=l(),Ut=a("div"),F(tR.$$.fragment),aBr=l(),R6e=a("p"),nBr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),sBr=l(),ac=a("p"),lBr=o(`Note:
Loading a model from its configuration file does `),P6e=a("strong"),iBr=o("not"),dBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=a("a"),mBr=o("from_pretrained()"),cBr=o(" to load the model weights."),fBr=l(),F(p5.$$.fragment),gBr=l(),Ao=a("div"),F(aR.$$.fragment),hBr=l(),B6e=a("p"),uBr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),pBr=l(),Rn=a("p"),_Br=o("The model class to instantiate is selected based on the "),I6e=a("code"),bBr=o("model_type"),vBr=o(` property of the config object (either
passed as an argument or loaded from `),N6e=a("code"),FBr=o("pretrained_model_name_or_path"),TBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q6e=a("code"),MBr=o("pretrained_model_name_or_path"),EBr=o(":"),CBr=l(),j6e=a("ul"),_5=a("li"),D6e=a("strong"),wBr=o("maskformer"),ABr=o(" \u2014 "),Xoe=a("a"),LBr=o("MaskFormerForInstanceSegmentation"),yBr=o(" (MaskFormer model)"),xBr=l(),b5=a("p"),$Br=o("The model is set in evaluation mode by default using "),G6e=a("code"),kBr=o("model.eval()"),SBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O6e=a("code"),RBr=o("model.train()"),PBr=l(),F(v5.$$.fragment),Tao=l(),nc=a("h2"),F5=a("a"),V6e=a("span"),F(nR.$$.fragment),BBr=l(),X6e=a("span"),IBr=o("AutoModelForZeroShotObjectDetection"),Mao=l(),dr=a("div"),F(sR.$$.fragment),NBr=l(),sc=a("p"),qBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),zoe=a("a"),jBr=o("from_pretrained()"),DBr=o(" class method or the "),Qoe=a("a"),GBr=o("from_config()"),OBr=o(` class
method.`),VBr=l(),lR=a("p"),XBr=o("This class cannot be instantiated directly using "),z6e=a("code"),zBr=o("__init__()"),QBr=o(" (throws an error)."),WBr=l(),Ht=a("div"),F(iR.$$.fragment),UBr=l(),Q6e=a("p"),HBr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),JBr=l(),lc=a("p"),YBr=o(`Note:
Loading a model from its configuration file does `),W6e=a("strong"),ZBr=o("not"),KBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Woe=a("a"),eIr=o("from_pretrained()"),oIr=o(" to load the model weights."),rIr=l(),F(T5.$$.fragment),tIr=l(),Lo=a("div"),F(dR.$$.fragment),aIr=l(),U6e=a("p"),nIr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),sIr=l(),Pn=a("p"),lIr=o("The model class to instantiate is selected based on the "),H6e=a("code"),iIr=o("model_type"),dIr=o(` property of the config object (either
passed as an argument or loaded from `),J6e=a("code"),mIr=o("pretrained_model_name_or_path"),cIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=a("code"),fIr=o("pretrained_model_name_or_path"),gIr=o(":"),hIr=l(),Z6e=a("ul"),M5=a("li"),K6e=a("strong"),uIr=o("owlvit"),pIr=o(" \u2014 "),Uoe=a("a"),_Ir=o("OwlViTForObjectDetection"),bIr=o(" (OWL-ViT model)"),vIr=l(),E5=a("p"),FIr=o("The model is set in evaluation mode by default using "),e7e=a("code"),TIr=o("model.eval()"),MIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o7e=a("code"),EIr=o("model.train()"),CIr=l(),F(C5.$$.fragment),Eao=l(),ic=a("h2"),w5=a("a"),r7e=a("span"),F(mR.$$.fragment),wIr=l(),t7e=a("span"),AIr=o("TFAutoModel"),Cao=l(),mr=a("div"),F(cR.$$.fragment),LIr=l(),dc=a("p"),yIr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Hoe=a("a"),xIr=o("from_pretrained()"),$Ir=o(" class method or the "),Joe=a("a"),kIr=o("from_config()"),SIr=o(` class
method.`),RIr=l(),fR=a("p"),PIr=o("This class cannot be instantiated directly using "),a7e=a("code"),BIr=o("__init__()"),IIr=o(" (throws an error)."),NIr=l(),Jt=a("div"),F(gR.$$.fragment),qIr=l(),n7e=a("p"),jIr=o("Instantiates one of the base model classes of the library from a configuration."),DIr=l(),mc=a("p"),GIr=o(`Note:
Loading a model from its configuration file does `),s7e=a("strong"),OIr=o("not"),VIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yoe=a("a"),XIr=o("from_pretrained()"),zIr=o(" to load the model weights."),QIr=l(),F(A5.$$.fragment),WIr=l(),Dr=a("div"),F(hR.$$.fragment),UIr=l(),l7e=a("p"),HIr=o("Instantiate one of the base model classes of the library from a pretrained model."),JIr=l(),Bn=a("p"),YIr=o("The model class to instantiate is selected based on the "),i7e=a("code"),ZIr=o("model_type"),KIr=o(` property of the config object (either
passed as an argument or loaded from `),d7e=a("code"),eNr=o("pretrained_model_name_or_path"),oNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m7e=a("code"),rNr=o("pretrained_model_name_or_path"),tNr=o(":"),aNr=l(),P=a("ul"),L5=a("li"),c7e=a("strong"),nNr=o("albert"),sNr=o(" \u2014 "),Zoe=a("a"),lNr=o("TFAlbertModel"),iNr=o(" (ALBERT model)"),dNr=l(),y5=a("li"),f7e=a("strong"),mNr=o("bart"),cNr=o(" \u2014 "),Koe=a("a"),fNr=o("TFBartModel"),gNr=o(" (BART model)"),hNr=l(),x5=a("li"),g7e=a("strong"),uNr=o("bert"),pNr=o(" \u2014 "),ere=a("a"),_Nr=o("TFBertModel"),bNr=o(" (BERT model)"),vNr=l(),$5=a("li"),h7e=a("strong"),FNr=o("blenderbot"),TNr=o(" \u2014 "),ore=a("a"),MNr=o("TFBlenderbotModel"),ENr=o(" (Blenderbot model)"),CNr=l(),k5=a("li"),u7e=a("strong"),wNr=o("blenderbot-small"),ANr=o(" \u2014 "),rre=a("a"),LNr=o("TFBlenderbotSmallModel"),yNr=o(" (BlenderbotSmall model)"),xNr=l(),S5=a("li"),p7e=a("strong"),$Nr=o("camembert"),kNr=o(" \u2014 "),tre=a("a"),SNr=o("TFCamembertModel"),RNr=o(" (CamemBERT model)"),PNr=l(),R5=a("li"),_7e=a("strong"),BNr=o("clip"),INr=o(" \u2014 "),are=a("a"),NNr=o("TFCLIPModel"),qNr=o(" (CLIP model)"),jNr=l(),P5=a("li"),b7e=a("strong"),DNr=o("convbert"),GNr=o(" \u2014 "),nre=a("a"),ONr=o("TFConvBertModel"),VNr=o(" (ConvBERT model)"),XNr=l(),B5=a("li"),v7e=a("strong"),zNr=o("convnext"),QNr=o(" \u2014 "),sre=a("a"),WNr=o("TFConvNextModel"),UNr=o(" (ConvNeXT model)"),HNr=l(),I5=a("li"),F7e=a("strong"),JNr=o("ctrl"),YNr=o(" \u2014 "),lre=a("a"),ZNr=o("TFCTRLModel"),KNr=o(" (CTRL model)"),eqr=l(),N5=a("li"),T7e=a("strong"),oqr=o("cvt"),rqr=o(" \u2014 "),ire=a("a"),tqr=o("TFCvtModel"),aqr=o(" (CvT model)"),nqr=l(),q5=a("li"),M7e=a("strong"),sqr=o("data2vec-vision"),lqr=o(" \u2014 "),dre=a("a"),iqr=o("TFData2VecVisionModel"),dqr=o(" (Data2VecVision model)"),mqr=l(),j5=a("li"),E7e=a("strong"),cqr=o("deberta"),fqr=o(" \u2014 "),mre=a("a"),gqr=o("TFDebertaModel"),hqr=o(" (DeBERTa model)"),uqr=l(),D5=a("li"),C7e=a("strong"),pqr=o("deberta-v2"),_qr=o(" \u2014 "),cre=a("a"),bqr=o("TFDebertaV2Model"),vqr=o(" (DeBERTa-v2 model)"),Fqr=l(),G5=a("li"),w7e=a("strong"),Tqr=o("deit"),Mqr=o(" \u2014 "),fre=a("a"),Eqr=o("TFDeiTModel"),Cqr=o(" (DeiT model)"),wqr=l(),O5=a("li"),A7e=a("strong"),Aqr=o("distilbert"),Lqr=o(" \u2014 "),gre=a("a"),yqr=o("TFDistilBertModel"),xqr=o(" (DistilBERT model)"),$qr=l(),V5=a("li"),L7e=a("strong"),kqr=o("dpr"),Sqr=o(" \u2014 "),hre=a("a"),Rqr=o("TFDPRQuestionEncoder"),Pqr=o(" (DPR model)"),Bqr=l(),X5=a("li"),y7e=a("strong"),Iqr=o("electra"),Nqr=o(" \u2014 "),ure=a("a"),qqr=o("TFElectraModel"),jqr=o(" (ELECTRA model)"),Dqr=l(),z5=a("li"),x7e=a("strong"),Gqr=o("esm"),Oqr=o(" \u2014 "),pre=a("a"),Vqr=o("TFEsmModel"),Xqr=o(" (ESM model)"),zqr=l(),Q5=a("li"),$7e=a("strong"),Qqr=o("flaubert"),Wqr=o(" \u2014 "),_re=a("a"),Uqr=o("TFFlaubertModel"),Hqr=o(" (FlauBERT model)"),Jqr=l(),kl=a("li"),k7e=a("strong"),Yqr=o("funnel"),Zqr=o(" \u2014 "),bre=a("a"),Kqr=o("TFFunnelModel"),ejr=o(" or "),vre=a("a"),ojr=o("TFFunnelBaseModel"),rjr=o(" (Funnel Transformer model)"),tjr=l(),W5=a("li"),S7e=a("strong"),ajr=o("gpt2"),njr=o(" \u2014 "),Fre=a("a"),sjr=o("TFGPT2Model"),ljr=o(" (OpenAI GPT-2 model)"),ijr=l(),U5=a("li"),R7e=a("strong"),djr=o("gptj"),mjr=o(" \u2014 "),Tre=a("a"),cjr=o("TFGPTJModel"),fjr=o(" (GPT-J model)"),gjr=l(),H5=a("li"),P7e=a("strong"),hjr=o("groupvit"),ujr=o(" \u2014 "),Mre=a("a"),pjr=o("TFGroupViTModel"),_jr=o(" (GroupViT model)"),bjr=l(),J5=a("li"),B7e=a("strong"),vjr=o("hubert"),Fjr=o(" \u2014 "),Ere=a("a"),Tjr=o("TFHubertModel"),Mjr=o(" (Hubert model)"),Ejr=l(),Y5=a("li"),I7e=a("strong"),Cjr=o("layoutlm"),wjr=o(" \u2014 "),Cre=a("a"),Ajr=o("TFLayoutLMModel"),Ljr=o(" (LayoutLM model)"),yjr=l(),Z5=a("li"),N7e=a("strong"),xjr=o("layoutlmv3"),$jr=o(" \u2014 "),wre=a("a"),kjr=o("TFLayoutLMv3Model"),Sjr=o(" (LayoutLMv3 model)"),Rjr=l(),K5=a("li"),q7e=a("strong"),Pjr=o("led"),Bjr=o(" \u2014 "),Are=a("a"),Ijr=o("TFLEDModel"),Njr=o(" (LED model)"),qjr=l(),e0=a("li"),j7e=a("strong"),jjr=o("longformer"),Djr=o(" \u2014 "),Lre=a("a"),Gjr=o("TFLongformerModel"),Ojr=o(" (Longformer model)"),Vjr=l(),o0=a("li"),D7e=a("strong"),Xjr=o("lxmert"),zjr=o(" \u2014 "),yre=a("a"),Qjr=o("TFLxmertModel"),Wjr=o(" (LXMERT model)"),Ujr=l(),r0=a("li"),G7e=a("strong"),Hjr=o("marian"),Jjr=o(" \u2014 "),xre=a("a"),Yjr=o("TFMarianModel"),Zjr=o(" (Marian model)"),Kjr=l(),t0=a("li"),O7e=a("strong"),eDr=o("mbart"),oDr=o(" \u2014 "),$re=a("a"),rDr=o("TFMBartModel"),tDr=o(" (mBART model)"),aDr=l(),a0=a("li"),V7e=a("strong"),nDr=o("mobilebert"),sDr=o(" \u2014 "),kre=a("a"),lDr=o("TFMobileBertModel"),iDr=o(" (MobileBERT model)"),dDr=l(),n0=a("li"),X7e=a("strong"),mDr=o("mobilevit"),cDr=o(" \u2014 "),Sre=a("a"),fDr=o("TFMobileViTModel"),gDr=o(" (MobileViT model)"),hDr=l(),s0=a("li"),z7e=a("strong"),uDr=o("mpnet"),pDr=o(" \u2014 "),Rre=a("a"),_Dr=o("TFMPNetModel"),bDr=o(" (MPNet model)"),vDr=l(),l0=a("li"),Q7e=a("strong"),FDr=o("mt5"),TDr=o(" \u2014 "),Pre=a("a"),MDr=o("TFMT5Model"),EDr=o(" (MT5 model)"),CDr=l(),i0=a("li"),W7e=a("strong"),wDr=o("openai-gpt"),ADr=o(" \u2014 "),Bre=a("a"),LDr=o("TFOpenAIGPTModel"),yDr=o(" (OpenAI GPT model)"),xDr=l(),d0=a("li"),U7e=a("strong"),$Dr=o("opt"),kDr=o(" \u2014 "),Ire=a("a"),SDr=o("TFOPTModel"),RDr=o(" (OPT model)"),PDr=l(),m0=a("li"),H7e=a("strong"),BDr=o("pegasus"),IDr=o(" \u2014 "),Nre=a("a"),NDr=o("TFPegasusModel"),qDr=o(" (Pegasus model)"),jDr=l(),c0=a("li"),J7e=a("strong"),DDr=o("regnet"),GDr=o(" \u2014 "),qre=a("a"),ODr=o("TFRegNetModel"),VDr=o(" (RegNet model)"),XDr=l(),f0=a("li"),Y7e=a("strong"),zDr=o("rembert"),QDr=o(" \u2014 "),jre=a("a"),WDr=o("TFRemBertModel"),UDr=o(" (RemBERT model)"),HDr=l(),g0=a("li"),Z7e=a("strong"),JDr=o("resnet"),YDr=o(" \u2014 "),Dre=a("a"),ZDr=o("TFResNetModel"),KDr=o(" (ResNet model)"),eGr=l(),h0=a("li"),K7e=a("strong"),oGr=o("roberta"),rGr=o(" \u2014 "),Gre=a("a"),tGr=o("TFRobertaModel"),aGr=o(" (RoBERTa model)"),nGr=l(),u0=a("li"),e8e=a("strong"),sGr=o("roformer"),lGr=o(" \u2014 "),Ore=a("a"),iGr=o("TFRoFormerModel"),dGr=o(" (RoFormer model)"),mGr=l(),p0=a("li"),o8e=a("strong"),cGr=o("segformer"),fGr=o(" \u2014 "),Vre=a("a"),gGr=o("TFSegformerModel"),hGr=o(" (SegFormer model)"),uGr=l(),_0=a("li"),r8e=a("strong"),pGr=o("speech_to_text"),_Gr=o(" \u2014 "),Xre=a("a"),bGr=o("TFSpeech2TextModel"),vGr=o(" (Speech2Text model)"),FGr=l(),b0=a("li"),t8e=a("strong"),TGr=o("swin"),MGr=o(" \u2014 "),zre=a("a"),EGr=o("TFSwinModel"),CGr=o(" (Swin Transformer model)"),wGr=l(),v0=a("li"),a8e=a("strong"),AGr=o("t5"),LGr=o(" \u2014 "),Qre=a("a"),yGr=o("TFT5Model"),xGr=o(" (T5 model)"),$Gr=l(),F0=a("li"),n8e=a("strong"),kGr=o("tapas"),SGr=o(" \u2014 "),Wre=a("a"),RGr=o("TFTapasModel"),PGr=o(" (TAPAS model)"),BGr=l(),T0=a("li"),s8e=a("strong"),IGr=o("transfo-xl"),NGr=o(" \u2014 "),Ure=a("a"),qGr=o("TFTransfoXLModel"),jGr=o(" (Transformer-XL model)"),DGr=l(),M0=a("li"),l8e=a("strong"),GGr=o("vit"),OGr=o(" \u2014 "),Hre=a("a"),VGr=o("TFViTModel"),XGr=o(" (ViT model)"),zGr=l(),E0=a("li"),i8e=a("strong"),QGr=o("vit_mae"),WGr=o(" \u2014 "),Jre=a("a"),UGr=o("TFViTMAEModel"),HGr=o(" (ViTMAE model)"),JGr=l(),C0=a("li"),d8e=a("strong"),YGr=o("wav2vec2"),ZGr=o(" \u2014 "),Yre=a("a"),KGr=o("TFWav2Vec2Model"),eOr=o(" (Wav2Vec2 model)"),oOr=l(),w0=a("li"),m8e=a("strong"),rOr=o("whisper"),tOr=o(" \u2014 "),Zre=a("a"),aOr=o("TFWhisperModel"),nOr=o(" (Whisper model)"),sOr=l(),A0=a("li"),c8e=a("strong"),lOr=o("xglm"),iOr=o(" \u2014 "),Kre=a("a"),dOr=o("TFXGLMModel"),mOr=o(" (XGLM model)"),cOr=l(),L0=a("li"),f8e=a("strong"),fOr=o("xlm"),gOr=o(" \u2014 "),ete=a("a"),hOr=o("TFXLMModel"),uOr=o(" (XLM model)"),pOr=l(),y0=a("li"),g8e=a("strong"),_Or=o("xlm-roberta"),bOr=o(" \u2014 "),ote=a("a"),vOr=o("TFXLMRobertaModel"),FOr=o(" (XLM-RoBERTa model)"),TOr=l(),x0=a("li"),h8e=a("strong"),MOr=o("xlnet"),EOr=o(" \u2014 "),rte=a("a"),COr=o("TFXLNetModel"),wOr=o(" (XLNet model)"),AOr=l(),F($0.$$.fragment),wao=l(),cc=a("h2"),k0=a("a"),u8e=a("span"),F(uR.$$.fragment),LOr=l(),p8e=a("span"),yOr=o("TFAutoModelForPreTraining"),Aao=l(),cr=a("div"),F(pR.$$.fragment),xOr=l(),fc=a("p"),$Or=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),tte=a("a"),kOr=o("from_pretrained()"),SOr=o(" class method or the "),ate=a("a"),ROr=o("from_config()"),POr=o(` class
method.`),BOr=l(),_R=a("p"),IOr=o("This class cannot be instantiated directly using "),_8e=a("code"),NOr=o("__init__()"),qOr=o(" (throws an error)."),jOr=l(),Yt=a("div"),F(bR.$$.fragment),DOr=l(),b8e=a("p"),GOr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),OOr=l(),gc=a("p"),VOr=o(`Note:
Loading a model from its configuration file does `),v8e=a("strong"),XOr=o("not"),zOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nte=a("a"),QOr=o("from_pretrained()"),WOr=o(" to load the model weights."),UOr=l(),F(S0.$$.fragment),HOr=l(),Gr=a("div"),F(vR.$$.fragment),JOr=l(),F8e=a("p"),YOr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZOr=l(),In=a("p"),KOr=o("The model class to instantiate is selected based on the "),T8e=a("code"),eVr=o("model_type"),oVr=o(` property of the config object (either
passed as an argument or loaded from `),M8e=a("code"),rVr=o("pretrained_model_name_or_path"),tVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E8e=a("code"),aVr=o("pretrained_model_name_or_path"),nVr=o(":"),sVr=l(),le=a("ul"),R0=a("li"),C8e=a("strong"),lVr=o("albert"),iVr=o(" \u2014 "),ste=a("a"),dVr=o("TFAlbertForPreTraining"),mVr=o(" (ALBERT model)"),cVr=l(),P0=a("li"),w8e=a("strong"),fVr=o("bart"),gVr=o(" \u2014 "),lte=a("a"),hVr=o("TFBartForConditionalGeneration"),uVr=o(" (BART model)"),pVr=l(),B0=a("li"),A8e=a("strong"),_Vr=o("bert"),bVr=o(" \u2014 "),ite=a("a"),vVr=o("TFBertForPreTraining"),FVr=o(" (BERT model)"),TVr=l(),I0=a("li"),L8e=a("strong"),MVr=o("camembert"),EVr=o(" \u2014 "),dte=a("a"),CVr=o("TFCamembertForMaskedLM"),wVr=o(" (CamemBERT model)"),AVr=l(),N0=a("li"),y8e=a("strong"),LVr=o("ctrl"),yVr=o(" \u2014 "),mte=a("a"),xVr=o("TFCTRLLMHeadModel"),$Vr=o(" (CTRL model)"),kVr=l(),q0=a("li"),x8e=a("strong"),SVr=o("distilbert"),RVr=o(" \u2014 "),cte=a("a"),PVr=o("TFDistilBertForMaskedLM"),BVr=o(" (DistilBERT model)"),IVr=l(),j0=a("li"),$8e=a("strong"),NVr=o("electra"),qVr=o(" \u2014 "),fte=a("a"),jVr=o("TFElectraForPreTraining"),DVr=o(" (ELECTRA model)"),GVr=l(),D0=a("li"),k8e=a("strong"),OVr=o("flaubert"),VVr=o(" \u2014 "),gte=a("a"),XVr=o("TFFlaubertWithLMHeadModel"),zVr=o(" (FlauBERT model)"),QVr=l(),G0=a("li"),S8e=a("strong"),WVr=o("funnel"),UVr=o(" \u2014 "),hte=a("a"),HVr=o("TFFunnelForPreTraining"),JVr=o(" (Funnel Transformer model)"),YVr=l(),O0=a("li"),R8e=a("strong"),ZVr=o("gpt2"),KVr=o(" \u2014 "),ute=a("a"),eXr=o("TFGPT2LMHeadModel"),oXr=o(" (OpenAI GPT-2 model)"),rXr=l(),V0=a("li"),P8e=a("strong"),tXr=o("layoutlm"),aXr=o(" \u2014 "),pte=a("a"),nXr=o("TFLayoutLMForMaskedLM"),sXr=o(" (LayoutLM model)"),lXr=l(),X0=a("li"),B8e=a("strong"),iXr=o("lxmert"),dXr=o(" \u2014 "),_te=a("a"),mXr=o("TFLxmertForPreTraining"),cXr=o(" (LXMERT model)"),fXr=l(),z0=a("li"),I8e=a("strong"),gXr=o("mobilebert"),hXr=o(" \u2014 "),bte=a("a"),uXr=o("TFMobileBertForPreTraining"),pXr=o(" (MobileBERT model)"),_Xr=l(),Q0=a("li"),N8e=a("strong"),bXr=o("mpnet"),vXr=o(" \u2014 "),vte=a("a"),FXr=o("TFMPNetForMaskedLM"),TXr=o(" (MPNet model)"),MXr=l(),W0=a("li"),q8e=a("strong"),EXr=o("openai-gpt"),CXr=o(" \u2014 "),Fte=a("a"),wXr=o("TFOpenAIGPTLMHeadModel"),AXr=o(" (OpenAI GPT model)"),LXr=l(),U0=a("li"),j8e=a("strong"),yXr=o("roberta"),xXr=o(" \u2014 "),Tte=a("a"),$Xr=o("TFRobertaForMaskedLM"),kXr=o(" (RoBERTa model)"),SXr=l(),H0=a("li"),D8e=a("strong"),RXr=o("t5"),PXr=o(" \u2014 "),Mte=a("a"),BXr=o("TFT5ForConditionalGeneration"),IXr=o(" (T5 model)"),NXr=l(),J0=a("li"),G8e=a("strong"),qXr=o("tapas"),jXr=o(" \u2014 "),Ete=a("a"),DXr=o("TFTapasForMaskedLM"),GXr=o(" (TAPAS model)"),OXr=l(),Y0=a("li"),O8e=a("strong"),VXr=o("transfo-xl"),XXr=o(" \u2014 "),Cte=a("a"),zXr=o("TFTransfoXLLMHeadModel"),QXr=o(" (Transformer-XL model)"),WXr=l(),Z0=a("li"),V8e=a("strong"),UXr=o("vit_mae"),HXr=o(" \u2014 "),wte=a("a"),JXr=o("TFViTMAEForPreTraining"),YXr=o(" (ViTMAE model)"),ZXr=l(),K0=a("li"),X8e=a("strong"),KXr=o("xlm"),ezr=o(" \u2014 "),Ate=a("a"),ozr=o("TFXLMWithLMHeadModel"),rzr=o(" (XLM model)"),tzr=l(),ew=a("li"),z8e=a("strong"),azr=o("xlm-roberta"),nzr=o(" \u2014 "),Lte=a("a"),szr=o("TFXLMRobertaForMaskedLM"),lzr=o(" (XLM-RoBERTa model)"),izr=l(),ow=a("li"),Q8e=a("strong"),dzr=o("xlnet"),mzr=o(" \u2014 "),yte=a("a"),czr=o("TFXLNetLMHeadModel"),fzr=o(" (XLNet model)"),gzr=l(),F(rw.$$.fragment),Lao=l(),hc=a("h2"),tw=a("a"),W8e=a("span"),F(FR.$$.fragment),hzr=l(),U8e=a("span"),uzr=o("TFAutoModelForCausalLM"),yao=l(),fr=a("div"),F(TR.$$.fragment),pzr=l(),uc=a("p"),_zr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),xte=a("a"),bzr=o("from_pretrained()"),vzr=o(" class method or the "),$te=a("a"),Fzr=o("from_config()"),Tzr=o(` class
method.`),Mzr=l(),MR=a("p"),Ezr=o("This class cannot be instantiated directly using "),H8e=a("code"),Czr=o("__init__()"),wzr=o(" (throws an error)."),Azr=l(),Zt=a("div"),F(ER.$$.fragment),Lzr=l(),J8e=a("p"),yzr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),xzr=l(),pc=a("p"),$zr=o(`Note:
Loading a model from its configuration file does `),Y8e=a("strong"),kzr=o("not"),Szr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kte=a("a"),Rzr=o("from_pretrained()"),Pzr=o(" to load the model weights."),Bzr=l(),F(aw.$$.fragment),Izr=l(),Or=a("div"),F(CR.$$.fragment),Nzr=l(),Z8e=a("p"),qzr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),jzr=l(),Nn=a("p"),Dzr=o("The model class to instantiate is selected based on the "),K8e=a("code"),Gzr=o("model_type"),Ozr=o(` property of the config object (either
passed as an argument or loaded from `),eLe=a("code"),Vzr=o("pretrained_model_name_or_path"),Xzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=a("code"),zzr=o("pretrained_model_name_or_path"),Qzr=o(":"),Wzr=l(),Me=a("ul"),nw=a("li"),rLe=a("strong"),Uzr=o("bert"),Hzr=o(" \u2014 "),Ste=a("a"),Jzr=o("TFBertLMHeadModel"),Yzr=o(" (BERT model)"),Zzr=l(),sw=a("li"),tLe=a("strong"),Kzr=o("camembert"),eQr=o(" \u2014 "),Rte=a("a"),oQr=o("TFCamembertForCausalLM"),rQr=o(" (CamemBERT model)"),tQr=l(),lw=a("li"),aLe=a("strong"),aQr=o("ctrl"),nQr=o(" \u2014 "),Pte=a("a"),sQr=o("TFCTRLLMHeadModel"),lQr=o(" (CTRL model)"),iQr=l(),iw=a("li"),nLe=a("strong"),dQr=o("gpt2"),mQr=o(" \u2014 "),Bte=a("a"),cQr=o("TFGPT2LMHeadModel"),fQr=o(" (OpenAI GPT-2 model)"),gQr=l(),dw=a("li"),sLe=a("strong"),hQr=o("gptj"),uQr=o(" \u2014 "),Ite=a("a"),pQr=o("TFGPTJForCausalLM"),_Qr=o(" (GPT-J model)"),bQr=l(),mw=a("li"),lLe=a("strong"),vQr=o("openai-gpt"),FQr=o(" \u2014 "),Nte=a("a"),TQr=o("TFOpenAIGPTLMHeadModel"),MQr=o(" (OpenAI GPT model)"),EQr=l(),cw=a("li"),iLe=a("strong"),CQr=o("opt"),wQr=o(" \u2014 "),qte=a("a"),AQr=o("TFOPTForCausalLM"),LQr=o(" (OPT model)"),yQr=l(),fw=a("li"),dLe=a("strong"),xQr=o("rembert"),$Qr=o(" \u2014 "),jte=a("a"),kQr=o("TFRemBertForCausalLM"),SQr=o(" (RemBERT model)"),RQr=l(),gw=a("li"),mLe=a("strong"),PQr=o("roberta"),BQr=o(" \u2014 "),Dte=a("a"),IQr=o("TFRobertaForCausalLM"),NQr=o(" (RoBERTa model)"),qQr=l(),hw=a("li"),cLe=a("strong"),jQr=o("roformer"),DQr=o(" \u2014 "),Gte=a("a"),GQr=o("TFRoFormerForCausalLM"),OQr=o(" (RoFormer model)"),VQr=l(),uw=a("li"),fLe=a("strong"),XQr=o("transfo-xl"),zQr=o(" \u2014 "),Ote=a("a"),QQr=o("TFTransfoXLLMHeadModel"),WQr=o(" (Transformer-XL model)"),UQr=l(),pw=a("li"),gLe=a("strong"),HQr=o("xglm"),JQr=o(" \u2014 "),Vte=a("a"),YQr=o("TFXGLMForCausalLM"),ZQr=o(" (XGLM model)"),KQr=l(),_w=a("li"),hLe=a("strong"),eWr=o("xlm"),oWr=o(" \u2014 "),Xte=a("a"),rWr=o("TFXLMWithLMHeadModel"),tWr=o(" (XLM model)"),aWr=l(),bw=a("li"),uLe=a("strong"),nWr=o("xlnet"),sWr=o(" \u2014 "),zte=a("a"),lWr=o("TFXLNetLMHeadModel"),iWr=o(" (XLNet model)"),dWr=l(),F(vw.$$.fragment),xao=l(),_c=a("h2"),Fw=a("a"),pLe=a("span"),F(wR.$$.fragment),mWr=l(),_Le=a("span"),cWr=o("TFAutoModelForImageClassification"),$ao=l(),gr=a("div"),F(AR.$$.fragment),fWr=l(),bc=a("p"),gWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Qte=a("a"),hWr=o("from_pretrained()"),uWr=o(" class method or the "),Wte=a("a"),pWr=o("from_config()"),_Wr=o(` class
method.`),bWr=l(),LR=a("p"),vWr=o("This class cannot be instantiated directly using "),bLe=a("code"),FWr=o("__init__()"),TWr=o(" (throws an error)."),MWr=l(),Kt=a("div"),F(yR.$$.fragment),EWr=l(),vLe=a("p"),CWr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wWr=l(),vc=a("p"),AWr=o(`Note:
Loading a model from its configuration file does `),FLe=a("strong"),LWr=o("not"),yWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ute=a("a"),xWr=o("from_pretrained()"),$Wr=o(" to load the model weights."),kWr=l(),F(Tw.$$.fragment),SWr=l(),Vr=a("div"),F(xR.$$.fragment),RWr=l(),TLe=a("p"),PWr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BWr=l(),qn=a("p"),IWr=o("The model class to instantiate is selected based on the "),MLe=a("code"),NWr=o("model_type"),qWr=o(` property of the config object (either
passed as an argument or loaded from `),ELe=a("code"),jWr=o("pretrained_model_name_or_path"),DWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CLe=a("code"),GWr=o("pretrained_model_name_or_path"),OWr=o(":"),VWr=l(),ye=a("ul"),Mw=a("li"),wLe=a("strong"),XWr=o("convnext"),zWr=o(" \u2014 "),Hte=a("a"),QWr=o("TFConvNextForImageClassification"),WWr=o(" (ConvNeXT model)"),UWr=l(),Ew=a("li"),ALe=a("strong"),HWr=o("cvt"),JWr=o(" \u2014 "),Jte=a("a"),YWr=o("TFCvtForImageClassification"),ZWr=o(" (CvT model)"),KWr=l(),Cw=a("li"),LLe=a("strong"),eUr=o("data2vec-vision"),oUr=o(" \u2014 "),Yte=a("a"),rUr=o("TFData2VecVisionForImageClassification"),tUr=o(" (Data2VecVision model)"),aUr=l(),Sl=a("li"),yLe=a("strong"),nUr=o("deit"),sUr=o(" \u2014 "),Zte=a("a"),lUr=o("TFDeiTForImageClassification"),iUr=o(" or "),Kte=a("a"),dUr=o("TFDeiTForImageClassificationWithTeacher"),mUr=o(" (DeiT model)"),cUr=l(),ww=a("li"),xLe=a("strong"),fUr=o("mobilevit"),gUr=o(" \u2014 "),eae=a("a"),hUr=o("TFMobileViTForImageClassification"),uUr=o(" (MobileViT model)"),pUr=l(),Aw=a("li"),$Le=a("strong"),_Ur=o("regnet"),bUr=o(" \u2014 "),oae=a("a"),vUr=o("TFRegNetForImageClassification"),FUr=o(" (RegNet model)"),TUr=l(),Lw=a("li"),kLe=a("strong"),MUr=o("resnet"),EUr=o(" \u2014 "),rae=a("a"),CUr=o("TFResNetForImageClassification"),wUr=o(" (ResNet model)"),AUr=l(),yw=a("li"),SLe=a("strong"),LUr=o("segformer"),yUr=o(" \u2014 "),tae=a("a"),xUr=o("TFSegformerForImageClassification"),$Ur=o(" (SegFormer model)"),kUr=l(),xw=a("li"),RLe=a("strong"),SUr=o("swin"),RUr=o(" \u2014 "),aae=a("a"),PUr=o("TFSwinForImageClassification"),BUr=o(" (Swin Transformer model)"),IUr=l(),$w=a("li"),PLe=a("strong"),NUr=o("vit"),qUr=o(" \u2014 "),nae=a("a"),jUr=o("TFViTForImageClassification"),DUr=o(" (ViT model)"),GUr=l(),F(kw.$$.fragment),kao=l(),Fc=a("h2"),Sw=a("a"),BLe=a("span"),F($R.$$.fragment),OUr=l(),ILe=a("span"),VUr=o("TFAutoModelForSemanticSegmentation"),Sao=l(),hr=a("div"),F(kR.$$.fragment),XUr=l(),Tc=a("p"),zUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),sae=a("a"),QUr=o("from_pretrained()"),WUr=o(" class method or the "),lae=a("a"),UUr=o("from_config()"),HUr=o(` class
method.`),JUr=l(),SR=a("p"),YUr=o("This class cannot be instantiated directly using "),NLe=a("code"),ZUr=o("__init__()"),KUr=o(" (throws an error)."),eHr=l(),ea=a("div"),F(RR.$$.fragment),oHr=l(),qLe=a("p"),rHr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),tHr=l(),Mc=a("p"),aHr=o(`Note:
Loading a model from its configuration file does `),jLe=a("strong"),nHr=o("not"),sHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iae=a("a"),lHr=o("from_pretrained()"),iHr=o(" to load the model weights."),dHr=l(),F(Rw.$$.fragment),mHr=l(),Xr=a("div"),F(PR.$$.fragment),cHr=l(),DLe=a("p"),fHr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),gHr=l(),jn=a("p"),hHr=o("The model class to instantiate is selected based on the "),GLe=a("code"),uHr=o("model_type"),pHr=o(` property of the config object (either
passed as an argument or loaded from `),OLe=a("code"),_Hr=o("pretrained_model_name_or_path"),bHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VLe=a("code"),vHr=o("pretrained_model_name_or_path"),FHr=o(":"),THr=l(),Ec=a("ul"),Pw=a("li"),XLe=a("strong"),MHr=o("data2vec-vision"),EHr=o(" \u2014 "),dae=a("a"),CHr=o("TFData2VecVisionForSemanticSegmentation"),wHr=o(" (Data2VecVision model)"),AHr=l(),Bw=a("li"),zLe=a("strong"),LHr=o("mobilevit"),yHr=o(" \u2014 "),mae=a("a"),xHr=o("TFMobileViTForSemanticSegmentation"),$Hr=o(" (MobileViT model)"),kHr=l(),Iw=a("li"),QLe=a("strong"),SHr=o("segformer"),RHr=o(" \u2014 "),cae=a("a"),PHr=o("TFSegformerForSemanticSegmentation"),BHr=o(" (SegFormer model)"),IHr=l(),F(Nw.$$.fragment),Rao=l(),Cc=a("h2"),qw=a("a"),WLe=a("span"),F(BR.$$.fragment),NHr=l(),ULe=a("span"),qHr=o("TFAutoModelForMaskedLM"),Pao=l(),ur=a("div"),F(IR.$$.fragment),jHr=l(),wc=a("p"),DHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),fae=a("a"),GHr=o("from_pretrained()"),OHr=o(" class method or the "),gae=a("a"),VHr=o("from_config()"),XHr=o(` class
method.`),zHr=l(),NR=a("p"),QHr=o("This class cannot be instantiated directly using "),HLe=a("code"),WHr=o("__init__()"),UHr=o(" (throws an error)."),HHr=l(),oa=a("div"),F(qR.$$.fragment),JHr=l(),JLe=a("p"),YHr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ZHr=l(),Ac=a("p"),KHr=o(`Note:
Loading a model from its configuration file does `),YLe=a("strong"),eJr=o("not"),oJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hae=a("a"),rJr=o("from_pretrained()"),tJr=o(" to load the model weights."),aJr=l(),F(jw.$$.fragment),nJr=l(),zr=a("div"),F(jR.$$.fragment),sJr=l(),ZLe=a("p"),lJr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),iJr=l(),Dn=a("p"),dJr=o("The model class to instantiate is selected based on the "),KLe=a("code"),mJr=o("model_type"),cJr=o(` property of the config object (either
passed as an argument or loaded from `),eye=a("code"),fJr=o("pretrained_model_name_or_path"),gJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oye=a("code"),hJr=o("pretrained_model_name_or_path"),uJr=o(":"),pJr=l(),ce=a("ul"),Dw=a("li"),rye=a("strong"),_Jr=o("albert"),bJr=o(" \u2014 "),uae=a("a"),vJr=o("TFAlbertForMaskedLM"),FJr=o(" (ALBERT model)"),TJr=l(),Gw=a("li"),tye=a("strong"),MJr=o("bert"),EJr=o(" \u2014 "),pae=a("a"),CJr=o("TFBertForMaskedLM"),wJr=o(" (BERT model)"),AJr=l(),Ow=a("li"),aye=a("strong"),LJr=o("camembert"),yJr=o(" \u2014 "),_ae=a("a"),xJr=o("TFCamembertForMaskedLM"),$Jr=o(" (CamemBERT model)"),kJr=l(),Vw=a("li"),nye=a("strong"),SJr=o("convbert"),RJr=o(" \u2014 "),bae=a("a"),PJr=o("TFConvBertForMaskedLM"),BJr=o(" (ConvBERT model)"),IJr=l(),Xw=a("li"),sye=a("strong"),NJr=o("deberta"),qJr=o(" \u2014 "),vae=a("a"),jJr=o("TFDebertaForMaskedLM"),DJr=o(" (DeBERTa model)"),GJr=l(),zw=a("li"),lye=a("strong"),OJr=o("deberta-v2"),VJr=o(" \u2014 "),Fae=a("a"),XJr=o("TFDebertaV2ForMaskedLM"),zJr=o(" (DeBERTa-v2 model)"),QJr=l(),Qw=a("li"),iye=a("strong"),WJr=o("distilbert"),UJr=o(" \u2014 "),Tae=a("a"),HJr=o("TFDistilBertForMaskedLM"),JJr=o(" (DistilBERT model)"),YJr=l(),Ww=a("li"),dye=a("strong"),ZJr=o("electra"),KJr=o(" \u2014 "),Mae=a("a"),eYr=o("TFElectraForMaskedLM"),oYr=o(" (ELECTRA model)"),rYr=l(),Uw=a("li"),mye=a("strong"),tYr=o("esm"),aYr=o(" \u2014 "),Eae=a("a"),nYr=o("TFEsmForMaskedLM"),sYr=o(" (ESM model)"),lYr=l(),Hw=a("li"),cye=a("strong"),iYr=o("flaubert"),dYr=o(" \u2014 "),Cae=a("a"),mYr=o("TFFlaubertWithLMHeadModel"),cYr=o(" (FlauBERT model)"),fYr=l(),Jw=a("li"),fye=a("strong"),gYr=o("funnel"),hYr=o(" \u2014 "),wae=a("a"),uYr=o("TFFunnelForMaskedLM"),pYr=o(" (Funnel Transformer model)"),_Yr=l(),Yw=a("li"),gye=a("strong"),bYr=o("layoutlm"),vYr=o(" \u2014 "),Aae=a("a"),FYr=o("TFLayoutLMForMaskedLM"),TYr=o(" (LayoutLM model)"),MYr=l(),Zw=a("li"),hye=a("strong"),EYr=o("longformer"),CYr=o(" \u2014 "),Lae=a("a"),wYr=o("TFLongformerForMaskedLM"),AYr=o(" (Longformer model)"),LYr=l(),Kw=a("li"),uye=a("strong"),yYr=o("mobilebert"),xYr=o(" \u2014 "),yae=a("a"),$Yr=o("TFMobileBertForMaskedLM"),kYr=o(" (MobileBERT model)"),SYr=l(),eA=a("li"),pye=a("strong"),RYr=o("mpnet"),PYr=o(" \u2014 "),xae=a("a"),BYr=o("TFMPNetForMaskedLM"),IYr=o(" (MPNet model)"),NYr=l(),oA=a("li"),_ye=a("strong"),qYr=o("rembert"),jYr=o(" \u2014 "),$ae=a("a"),DYr=o("TFRemBertForMaskedLM"),GYr=o(" (RemBERT model)"),OYr=l(),rA=a("li"),bye=a("strong"),VYr=o("roberta"),XYr=o(" \u2014 "),kae=a("a"),zYr=o("TFRobertaForMaskedLM"),QYr=o(" (RoBERTa model)"),WYr=l(),tA=a("li"),vye=a("strong"),UYr=o("roformer"),HYr=o(" \u2014 "),Sae=a("a"),JYr=o("TFRoFormerForMaskedLM"),YYr=o(" (RoFormer model)"),ZYr=l(),aA=a("li"),Fye=a("strong"),KYr=o("tapas"),eZr=o(" \u2014 "),Rae=a("a"),oZr=o("TFTapasForMaskedLM"),rZr=o(" (TAPAS model)"),tZr=l(),nA=a("li"),Tye=a("strong"),aZr=o("xlm"),nZr=o(" \u2014 "),Pae=a("a"),sZr=o("TFXLMWithLMHeadModel"),lZr=o(" (XLM model)"),iZr=l(),sA=a("li"),Mye=a("strong"),dZr=o("xlm-roberta"),mZr=o(" \u2014 "),Bae=a("a"),cZr=o("TFXLMRobertaForMaskedLM"),fZr=o(" (XLM-RoBERTa model)"),gZr=l(),F(lA.$$.fragment),Bao=l(),Lc=a("h2"),iA=a("a"),Eye=a("span"),F(DR.$$.fragment),hZr=l(),Cye=a("span"),uZr=o("TFAutoModelForSeq2SeqLM"),Iao=l(),pr=a("div"),F(GR.$$.fragment),pZr=l(),yc=a("p"),_Zr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Iae=a("a"),bZr=o("from_pretrained()"),vZr=o(" class method or the "),Nae=a("a"),FZr=o("from_config()"),TZr=o(` class
method.`),MZr=l(),OR=a("p"),EZr=o("This class cannot be instantiated directly using "),wye=a("code"),CZr=o("__init__()"),wZr=o(" (throws an error)."),AZr=l(),ra=a("div"),F(VR.$$.fragment),LZr=l(),Aye=a("p"),yZr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),xZr=l(),xc=a("p"),$Zr=o(`Note:
Loading a model from its configuration file does `),Lye=a("strong"),kZr=o("not"),SZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qae=a("a"),RZr=o("from_pretrained()"),PZr=o(" to load the model weights."),BZr=l(),F(dA.$$.fragment),IZr=l(),Qr=a("div"),F(XR.$$.fragment),NZr=l(),yye=a("p"),qZr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),jZr=l(),Gn=a("p"),DZr=o("The model class to instantiate is selected based on the "),xye=a("code"),GZr=o("model_type"),OZr=o(` property of the config object (either
passed as an argument or loaded from `),$ye=a("code"),VZr=o("pretrained_model_name_or_path"),XZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kye=a("code"),zZr=o("pretrained_model_name_or_path"),QZr=o(":"),WZr=l(),xe=a("ul"),mA=a("li"),Sye=a("strong"),UZr=o("bart"),HZr=o(" \u2014 "),jae=a("a"),JZr=o("TFBartForConditionalGeneration"),YZr=o(" (BART model)"),ZZr=l(),cA=a("li"),Rye=a("strong"),KZr=o("blenderbot"),eKr=o(" \u2014 "),Dae=a("a"),oKr=o("TFBlenderbotForConditionalGeneration"),rKr=o(" (Blenderbot model)"),tKr=l(),fA=a("li"),Pye=a("strong"),aKr=o("blenderbot-small"),nKr=o(" \u2014 "),Gae=a("a"),sKr=o("TFBlenderbotSmallForConditionalGeneration"),lKr=o(" (BlenderbotSmall model)"),iKr=l(),gA=a("li"),Bye=a("strong"),dKr=o("encoder-decoder"),mKr=o(" \u2014 "),Oae=a("a"),cKr=o("TFEncoderDecoderModel"),fKr=o(" (Encoder decoder model)"),gKr=l(),hA=a("li"),Iye=a("strong"),hKr=o("led"),uKr=o(" \u2014 "),Vae=a("a"),pKr=o("TFLEDForConditionalGeneration"),_Kr=o(" (LED model)"),bKr=l(),uA=a("li"),Nye=a("strong"),vKr=o("marian"),FKr=o(" \u2014 "),Xae=a("a"),TKr=o("TFMarianMTModel"),MKr=o(" (Marian model)"),EKr=l(),pA=a("li"),qye=a("strong"),CKr=o("mbart"),wKr=o(" \u2014 "),zae=a("a"),AKr=o("TFMBartForConditionalGeneration"),LKr=o(" (mBART model)"),yKr=l(),_A=a("li"),jye=a("strong"),xKr=o("mt5"),$Kr=o(" \u2014 "),Qae=a("a"),kKr=o("TFMT5ForConditionalGeneration"),SKr=o(" (MT5 model)"),RKr=l(),bA=a("li"),Dye=a("strong"),PKr=o("pegasus"),BKr=o(" \u2014 "),Wae=a("a"),IKr=o("TFPegasusForConditionalGeneration"),NKr=o(" (Pegasus model)"),qKr=l(),vA=a("li"),Gye=a("strong"),jKr=o("t5"),DKr=o(" \u2014 "),Uae=a("a"),GKr=o("TFT5ForConditionalGeneration"),OKr=o(" (T5 model)"),VKr=l(),F(FA.$$.fragment),Nao=l(),$c=a("h2"),TA=a("a"),Oye=a("span"),F(zR.$$.fragment),XKr=l(),Vye=a("span"),zKr=o("TFAutoModelForSequenceClassification"),qao=l(),_r=a("div"),F(QR.$$.fragment),QKr=l(),kc=a("p"),WKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Hae=a("a"),UKr=o("from_pretrained()"),HKr=o(" class method or the "),Jae=a("a"),JKr=o("from_config()"),YKr=o(` class
method.`),ZKr=l(),WR=a("p"),KKr=o("This class cannot be instantiated directly using "),Xye=a("code"),eet=o("__init__()"),oet=o(" (throws an error)."),ret=l(),ta=a("div"),F(UR.$$.fragment),tet=l(),zye=a("p"),aet=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),net=l(),Sc=a("p"),set=o(`Note:
Loading a model from its configuration file does `),Qye=a("strong"),iet=o("not"),det=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yae=a("a"),met=o("from_pretrained()"),cet=o(" to load the model weights."),fet=l(),F(MA.$$.fragment),get=l(),Wr=a("div"),F(HR.$$.fragment),het=l(),Wye=a("p"),uet=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),pet=l(),On=a("p"),_et=o("The model class to instantiate is selected based on the "),Uye=a("code"),bet=o("model_type"),vet=o(` property of the config object (either
passed as an argument or loaded from `),Hye=a("code"),Fet=o("pretrained_model_name_or_path"),Tet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jye=a("code"),Met=o("pretrained_model_name_or_path"),Eet=o(":"),Cet=l(),re=a("ul"),EA=a("li"),Yye=a("strong"),wet=o("albert"),Aet=o(" \u2014 "),Zae=a("a"),Let=o("TFAlbertForSequenceClassification"),yet=o(" (ALBERT model)"),xet=l(),CA=a("li"),Zye=a("strong"),$et=o("bert"),ket=o(" \u2014 "),Kae=a("a"),Set=o("TFBertForSequenceClassification"),Ret=o(" (BERT model)"),Pet=l(),wA=a("li"),Kye=a("strong"),Bet=o("camembert"),Iet=o(" \u2014 "),ene=a("a"),Net=o("TFCamembertForSequenceClassification"),qet=o(" (CamemBERT model)"),jet=l(),AA=a("li"),e9e=a("strong"),Det=o("convbert"),Get=o(" \u2014 "),one=a("a"),Oet=o("TFConvBertForSequenceClassification"),Vet=o(" (ConvBERT model)"),Xet=l(),LA=a("li"),o9e=a("strong"),zet=o("ctrl"),Qet=o(" \u2014 "),rne=a("a"),Wet=o("TFCTRLForSequenceClassification"),Uet=o(" (CTRL model)"),Het=l(),yA=a("li"),r9e=a("strong"),Jet=o("deberta"),Yet=o(" \u2014 "),tne=a("a"),Zet=o("TFDebertaForSequenceClassification"),Ket=o(" (DeBERTa model)"),eot=l(),xA=a("li"),t9e=a("strong"),oot=o("deberta-v2"),rot=o(" \u2014 "),ane=a("a"),tot=o("TFDebertaV2ForSequenceClassification"),aot=o(" (DeBERTa-v2 model)"),not=l(),$A=a("li"),a9e=a("strong"),sot=o("distilbert"),lot=o(" \u2014 "),nne=a("a"),iot=o("TFDistilBertForSequenceClassification"),dot=o(" (DistilBERT model)"),mot=l(),kA=a("li"),n9e=a("strong"),cot=o("electra"),fot=o(" \u2014 "),sne=a("a"),got=o("TFElectraForSequenceClassification"),hot=o(" (ELECTRA model)"),uot=l(),SA=a("li"),s9e=a("strong"),pot=o("esm"),_ot=o(" \u2014 "),lne=a("a"),bot=o("TFEsmForSequenceClassification"),vot=o(" (ESM model)"),Fot=l(),RA=a("li"),l9e=a("strong"),Tot=o("flaubert"),Mot=o(" \u2014 "),ine=a("a"),Eot=o("TFFlaubertForSequenceClassification"),Cot=o(" (FlauBERT model)"),wot=l(),PA=a("li"),i9e=a("strong"),Aot=o("funnel"),Lot=o(" \u2014 "),dne=a("a"),yot=o("TFFunnelForSequenceClassification"),xot=o(" (Funnel Transformer model)"),$ot=l(),BA=a("li"),d9e=a("strong"),kot=o("gpt2"),Sot=o(" \u2014 "),mne=a("a"),Rot=o("TFGPT2ForSequenceClassification"),Pot=o(" (OpenAI GPT-2 model)"),Bot=l(),IA=a("li"),m9e=a("strong"),Iot=o("gptj"),Not=o(" \u2014 "),cne=a("a"),qot=o("TFGPTJForSequenceClassification"),jot=o(" (GPT-J model)"),Dot=l(),NA=a("li"),c9e=a("strong"),Got=o("layoutlm"),Oot=o(" \u2014 "),fne=a("a"),Vot=o("TFLayoutLMForSequenceClassification"),Xot=o(" (LayoutLM model)"),zot=l(),qA=a("li"),f9e=a("strong"),Qot=o("layoutlmv3"),Wot=o(" \u2014 "),gne=a("a"),Uot=o("TFLayoutLMv3ForSequenceClassification"),Hot=o(" (LayoutLMv3 model)"),Jot=l(),jA=a("li"),g9e=a("strong"),Yot=o("longformer"),Zot=o(" \u2014 "),hne=a("a"),Kot=o("TFLongformerForSequenceClassification"),ert=o(" (Longformer model)"),ort=l(),DA=a("li"),h9e=a("strong"),rrt=o("mobilebert"),trt=o(" \u2014 "),une=a("a"),art=o("TFMobileBertForSequenceClassification"),nrt=o(" (MobileBERT model)"),srt=l(),GA=a("li"),u9e=a("strong"),lrt=o("mpnet"),irt=o(" \u2014 "),pne=a("a"),drt=o("TFMPNetForSequenceClassification"),mrt=o(" (MPNet model)"),crt=l(),OA=a("li"),p9e=a("strong"),frt=o("openai-gpt"),grt=o(" \u2014 "),_ne=a("a"),hrt=o("TFOpenAIGPTForSequenceClassification"),urt=o(" (OpenAI GPT model)"),prt=l(),VA=a("li"),_9e=a("strong"),_rt=o("rembert"),brt=o(" \u2014 "),bne=a("a"),vrt=o("TFRemBertForSequenceClassification"),Frt=o(" (RemBERT model)"),Trt=l(),XA=a("li"),b9e=a("strong"),Mrt=o("roberta"),Ert=o(" \u2014 "),vne=a("a"),Crt=o("TFRobertaForSequenceClassification"),wrt=o(" (RoBERTa model)"),Art=l(),zA=a("li"),v9e=a("strong"),Lrt=o("roformer"),yrt=o(" \u2014 "),Fne=a("a"),xrt=o("TFRoFormerForSequenceClassification"),$rt=o(" (RoFormer model)"),krt=l(),QA=a("li"),F9e=a("strong"),Srt=o("tapas"),Rrt=o(" \u2014 "),Tne=a("a"),Prt=o("TFTapasForSequenceClassification"),Brt=o(" (TAPAS model)"),Irt=l(),WA=a("li"),T9e=a("strong"),Nrt=o("transfo-xl"),qrt=o(" \u2014 "),Mne=a("a"),jrt=o("TFTransfoXLForSequenceClassification"),Drt=o(" (Transformer-XL model)"),Grt=l(),UA=a("li"),M9e=a("strong"),Ort=o("xlm"),Vrt=o(" \u2014 "),Ene=a("a"),Xrt=o("TFXLMForSequenceClassification"),zrt=o(" (XLM model)"),Qrt=l(),HA=a("li"),E9e=a("strong"),Wrt=o("xlm-roberta"),Urt=o(" \u2014 "),Cne=a("a"),Hrt=o("TFXLMRobertaForSequenceClassification"),Jrt=o(" (XLM-RoBERTa model)"),Yrt=l(),JA=a("li"),C9e=a("strong"),Zrt=o("xlnet"),Krt=o(" \u2014 "),wne=a("a"),ett=o("TFXLNetForSequenceClassification"),ott=o(" (XLNet model)"),rtt=l(),F(YA.$$.fragment),jao=l(),Rc=a("h2"),ZA=a("a"),w9e=a("span"),F(JR.$$.fragment),ttt=l(),A9e=a("span"),att=o("TFAutoModelForMultipleChoice"),Dao=l(),br=a("div"),F(YR.$$.fragment),ntt=l(),Pc=a("p"),stt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ane=a("a"),ltt=o("from_pretrained()"),itt=o(" class method or the "),Lne=a("a"),dtt=o("from_config()"),mtt=o(` class
method.`),ctt=l(),ZR=a("p"),ftt=o("This class cannot be instantiated directly using "),L9e=a("code"),gtt=o("__init__()"),htt=o(" (throws an error)."),utt=l(),aa=a("div"),F(KR.$$.fragment),ptt=l(),y9e=a("p"),_tt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),btt=l(),Bc=a("p"),vtt=o(`Note:
Loading a model from its configuration file does `),x9e=a("strong"),Ftt=o("not"),Ttt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=a("a"),Mtt=o("from_pretrained()"),Ett=o(" to load the model weights."),Ctt=l(),F(KA.$$.fragment),wtt=l(),Ur=a("div"),F(eP.$$.fragment),Att=l(),$9e=a("p"),Ltt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ytt=l(),Vn=a("p"),xtt=o("The model class to instantiate is selected based on the "),k9e=a("code"),$tt=o("model_type"),ktt=o(` property of the config object (either
passed as an argument or loaded from `),S9e=a("code"),Stt=o("pretrained_model_name_or_path"),Rtt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R9e=a("code"),Ptt=o("pretrained_model_name_or_path"),Btt=o(":"),Itt=l(),ve=a("ul"),e6=a("li"),P9e=a("strong"),Ntt=o("albert"),qtt=o(" \u2014 "),xne=a("a"),jtt=o("TFAlbertForMultipleChoice"),Dtt=o(" (ALBERT model)"),Gtt=l(),o6=a("li"),B9e=a("strong"),Ott=o("bert"),Vtt=o(" \u2014 "),$ne=a("a"),Xtt=o("TFBertForMultipleChoice"),ztt=o(" (BERT model)"),Qtt=l(),r6=a("li"),I9e=a("strong"),Wtt=o("camembert"),Utt=o(" \u2014 "),kne=a("a"),Htt=o("TFCamembertForMultipleChoice"),Jtt=o(" (CamemBERT model)"),Ytt=l(),t6=a("li"),N9e=a("strong"),Ztt=o("convbert"),Ktt=o(" \u2014 "),Sne=a("a"),eat=o("TFConvBertForMultipleChoice"),oat=o(" (ConvBERT model)"),rat=l(),a6=a("li"),q9e=a("strong"),tat=o("distilbert"),aat=o(" \u2014 "),Rne=a("a"),nat=o("TFDistilBertForMultipleChoice"),sat=o(" (DistilBERT model)"),lat=l(),n6=a("li"),j9e=a("strong"),iat=o("electra"),dat=o(" \u2014 "),Pne=a("a"),mat=o("TFElectraForMultipleChoice"),cat=o(" (ELECTRA model)"),fat=l(),s6=a("li"),D9e=a("strong"),gat=o("flaubert"),hat=o(" \u2014 "),Bne=a("a"),uat=o("TFFlaubertForMultipleChoice"),pat=o(" (FlauBERT model)"),_at=l(),l6=a("li"),G9e=a("strong"),bat=o("funnel"),vat=o(" \u2014 "),Ine=a("a"),Fat=o("TFFunnelForMultipleChoice"),Tat=o(" (Funnel Transformer model)"),Mat=l(),i6=a("li"),O9e=a("strong"),Eat=o("longformer"),Cat=o(" \u2014 "),Nne=a("a"),wat=o("TFLongformerForMultipleChoice"),Aat=o(" (Longformer model)"),Lat=l(),d6=a("li"),V9e=a("strong"),yat=o("mobilebert"),xat=o(" \u2014 "),qne=a("a"),$at=o("TFMobileBertForMultipleChoice"),kat=o(" (MobileBERT model)"),Sat=l(),m6=a("li"),X9e=a("strong"),Rat=o("mpnet"),Pat=o(" \u2014 "),jne=a("a"),Bat=o("TFMPNetForMultipleChoice"),Iat=o(" (MPNet model)"),Nat=l(),c6=a("li"),z9e=a("strong"),qat=o("rembert"),jat=o(" \u2014 "),Dne=a("a"),Dat=o("TFRemBertForMultipleChoice"),Gat=o(" (RemBERT model)"),Oat=l(),f6=a("li"),Q9e=a("strong"),Vat=o("roberta"),Xat=o(" \u2014 "),Gne=a("a"),zat=o("TFRobertaForMultipleChoice"),Qat=o(" (RoBERTa model)"),Wat=l(),g6=a("li"),W9e=a("strong"),Uat=o("roformer"),Hat=o(" \u2014 "),One=a("a"),Jat=o("TFRoFormerForMultipleChoice"),Yat=o(" (RoFormer model)"),Zat=l(),h6=a("li"),U9e=a("strong"),Kat=o("xlm"),ent=o(" \u2014 "),Vne=a("a"),ont=o("TFXLMForMultipleChoice"),rnt=o(" (XLM model)"),tnt=l(),u6=a("li"),H9e=a("strong"),ant=o("xlm-roberta"),nnt=o(" \u2014 "),Xne=a("a"),snt=o("TFXLMRobertaForMultipleChoice"),lnt=o(" (XLM-RoBERTa model)"),int=l(),p6=a("li"),J9e=a("strong"),dnt=o("xlnet"),mnt=o(" \u2014 "),zne=a("a"),cnt=o("TFXLNetForMultipleChoice"),fnt=o(" (XLNet model)"),gnt=l(),F(_6.$$.fragment),Gao=l(),Ic=a("h2"),b6=a("a"),Y9e=a("span"),F(oP.$$.fragment),hnt=l(),Z9e=a("span"),unt=o("TFAutoModelForNextSentencePrediction"),Oao=l(),vr=a("div"),F(rP.$$.fragment),pnt=l(),Nc=a("p"),_nt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Qne=a("a"),bnt=o("from_pretrained()"),vnt=o(" class method or the "),Wne=a("a"),Fnt=o("from_config()"),Tnt=o(` class
method.`),Mnt=l(),tP=a("p"),Ent=o("This class cannot be instantiated directly using "),K9e=a("code"),Cnt=o("__init__()"),wnt=o(" (throws an error)."),Ant=l(),na=a("div"),F(aP.$$.fragment),Lnt=l(),exe=a("p"),ynt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),xnt=l(),qc=a("p"),$nt=o(`Note:
Loading a model from its configuration file does `),oxe=a("strong"),knt=o("not"),Snt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=a("a"),Rnt=o("from_pretrained()"),Pnt=o(" to load the model weights."),Bnt=l(),F(v6.$$.fragment),Int=l(),Hr=a("div"),F(nP.$$.fragment),Nnt=l(),rxe=a("p"),qnt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),jnt=l(),Xn=a("p"),Dnt=o("The model class to instantiate is selected based on the "),txe=a("code"),Gnt=o("model_type"),Ont=o(` property of the config object (either
passed as an argument or loaded from `),axe=a("code"),Vnt=o("pretrained_model_name_or_path"),Xnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nxe=a("code"),znt=o("pretrained_model_name_or_path"),Qnt=o(":"),Wnt=l(),sP=a("ul"),F6=a("li"),sxe=a("strong"),Unt=o("bert"),Hnt=o(" \u2014 "),Hne=a("a"),Jnt=o("TFBertForNextSentencePrediction"),Ynt=o(" (BERT model)"),Znt=l(),T6=a("li"),lxe=a("strong"),Knt=o("mobilebert"),est=o(" \u2014 "),Jne=a("a"),ost=o("TFMobileBertForNextSentencePrediction"),rst=o(" (MobileBERT model)"),tst=l(),F(M6.$$.fragment),Vao=l(),jc=a("h2"),E6=a("a"),ixe=a("span"),F(lP.$$.fragment),ast=l(),dxe=a("span"),nst=o("TFAutoModelForTableQuestionAnswering"),Xao=l(),Fr=a("div"),F(iP.$$.fragment),sst=l(),Dc=a("p"),lst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Yne=a("a"),ist=o("from_pretrained()"),dst=o(" class method or the "),Zne=a("a"),mst=o("from_config()"),cst=o(` class
method.`),fst=l(),dP=a("p"),gst=o("This class cannot be instantiated directly using "),mxe=a("code"),hst=o("__init__()"),ust=o(" (throws an error)."),pst=l(),sa=a("div"),F(mP.$$.fragment),_st=l(),cxe=a("p"),bst=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),vst=l(),Gc=a("p"),Fst=o(`Note:
Loading a model from its configuration file does `),fxe=a("strong"),Tst=o("not"),Mst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kne=a("a"),Est=o("from_pretrained()"),Cst=o(" to load the model weights."),wst=l(),F(C6.$$.fragment),Ast=l(),Jr=a("div"),F(cP.$$.fragment),Lst=l(),gxe=a("p"),yst=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),xst=l(),zn=a("p"),$st=o("The model class to instantiate is selected based on the "),hxe=a("code"),kst=o("model_type"),Sst=o(` property of the config object (either
passed as an argument or loaded from `),uxe=a("code"),Rst=o("pretrained_model_name_or_path"),Pst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pxe=a("code"),Bst=o("pretrained_model_name_or_path"),Ist=o(":"),Nst=l(),_xe=a("ul"),w6=a("li"),bxe=a("strong"),qst=o("tapas"),jst=o(" \u2014 "),ese=a("a"),Dst=o("TFTapasForQuestionAnswering"),Gst=o(" (TAPAS model)"),Ost=l(),F(A6.$$.fragment),zao=l(),Oc=a("h2"),L6=a("a"),vxe=a("span"),F(fP.$$.fragment),Vst=l(),Fxe=a("span"),Xst=o("TFAutoModelForDocumentQuestionAnswering"),Qao=l(),Tr=a("div"),F(gP.$$.fragment),zst=l(),Vc=a("p"),Qst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),ose=a("a"),Wst=o("from_pretrained()"),Ust=o(" class method or the "),rse=a("a"),Hst=o("from_config()"),Jst=o(` class
method.`),Yst=l(),hP=a("p"),Zst=o("This class cannot be instantiated directly using "),Txe=a("code"),Kst=o("__init__()"),elt=o(" (throws an error)."),olt=l(),la=a("div"),F(uP.$$.fragment),rlt=l(),Mxe=a("p"),tlt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),alt=l(),Xc=a("p"),nlt=o(`Note:
Loading a model from its configuration file does `),Exe=a("strong"),slt=o("not"),llt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tse=a("a"),ilt=o("from_pretrained()"),dlt=o(" to load the model weights."),mlt=l(),F(y6.$$.fragment),clt=l(),Yr=a("div"),F(pP.$$.fragment),flt=l(),Cxe=a("p"),glt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),hlt=l(),Qn=a("p"),ult=o("The model class to instantiate is selected based on the "),wxe=a("code"),plt=o("model_type"),_lt=o(` property of the config object (either
passed as an argument or loaded from `),Axe=a("code"),blt=o("pretrained_model_name_or_path"),vlt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lxe=a("code"),Flt=o("pretrained_model_name_or_path"),Tlt=o(":"),Mlt=l(),yxe=a("ul"),x6=a("li"),xxe=a("strong"),Elt=o("layoutlm"),Clt=o(" \u2014 "),ase=a("a"),wlt=o("TFLayoutLMForQuestionAnswering"),Alt=o(" (LayoutLM model)"),Llt=l(),F($6.$$.fragment),Wao=l(),zc=a("h2"),k6=a("a"),$xe=a("span"),F(_P.$$.fragment),ylt=l(),kxe=a("span"),xlt=o("TFAutoModelForTokenClassification"),Uao=l(),Mr=a("div"),F(bP.$$.fragment),$lt=l(),Qc=a("p"),klt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),nse=a("a"),Slt=o("from_pretrained()"),Rlt=o(" class method or the "),sse=a("a"),Plt=o("from_config()"),Blt=o(` class
method.`),Ilt=l(),vP=a("p"),Nlt=o("This class cannot be instantiated directly using "),Sxe=a("code"),qlt=o("__init__()"),jlt=o(" (throws an error)."),Dlt=l(),ia=a("div"),F(FP.$$.fragment),Glt=l(),Rxe=a("p"),Olt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Vlt=l(),Wc=a("p"),Xlt=o(`Note:
Loading a model from its configuration file does `),Pxe=a("strong"),zlt=o("not"),Qlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=a("a"),Wlt=o("from_pretrained()"),Ult=o(" to load the model weights."),Hlt=l(),F(S6.$$.fragment),Jlt=l(),Zr=a("div"),F(TP.$$.fragment),Ylt=l(),Bxe=a("p"),Zlt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Klt=l(),Wn=a("p"),eit=o("The model class to instantiate is selected based on the "),Ixe=a("code"),oit=o("model_type"),rit=o(` property of the config object (either
passed as an argument or loaded from `),Nxe=a("code"),tit=o("pretrained_model_name_or_path"),ait=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qxe=a("code"),nit=o("pretrained_model_name_or_path"),sit=o(":"),lit=l(),ie=a("ul"),R6=a("li"),jxe=a("strong"),iit=o("albert"),dit=o(" \u2014 "),ise=a("a"),mit=o("TFAlbertForTokenClassification"),cit=o(" (ALBERT model)"),fit=l(),P6=a("li"),Dxe=a("strong"),git=o("bert"),hit=o(" \u2014 "),dse=a("a"),uit=o("TFBertForTokenClassification"),pit=o(" (BERT model)"),_it=l(),B6=a("li"),Gxe=a("strong"),bit=o("camembert"),vit=o(" \u2014 "),mse=a("a"),Fit=o("TFCamembertForTokenClassification"),Tit=o(" (CamemBERT model)"),Mit=l(),I6=a("li"),Oxe=a("strong"),Eit=o("convbert"),Cit=o(" \u2014 "),cse=a("a"),wit=o("TFConvBertForTokenClassification"),Ait=o(" (ConvBERT model)"),Lit=l(),N6=a("li"),Vxe=a("strong"),yit=o("deberta"),xit=o(" \u2014 "),fse=a("a"),$it=o("TFDebertaForTokenClassification"),kit=o(" (DeBERTa model)"),Sit=l(),q6=a("li"),Xxe=a("strong"),Rit=o("deberta-v2"),Pit=o(" \u2014 "),gse=a("a"),Bit=o("TFDebertaV2ForTokenClassification"),Iit=o(" (DeBERTa-v2 model)"),Nit=l(),j6=a("li"),zxe=a("strong"),qit=o("distilbert"),jit=o(" \u2014 "),hse=a("a"),Dit=o("TFDistilBertForTokenClassification"),Git=o(" (DistilBERT model)"),Oit=l(),D6=a("li"),Qxe=a("strong"),Vit=o("electra"),Xit=o(" \u2014 "),use=a("a"),zit=o("TFElectraForTokenClassification"),Qit=o(" (ELECTRA model)"),Wit=l(),G6=a("li"),Wxe=a("strong"),Uit=o("esm"),Hit=o(" \u2014 "),pse=a("a"),Jit=o("TFEsmForTokenClassification"),Yit=o(" (ESM model)"),Zit=l(),O6=a("li"),Uxe=a("strong"),Kit=o("flaubert"),edt=o(" \u2014 "),_se=a("a"),odt=o("TFFlaubertForTokenClassification"),rdt=o(" (FlauBERT model)"),tdt=l(),V6=a("li"),Hxe=a("strong"),adt=o("funnel"),ndt=o(" \u2014 "),bse=a("a"),sdt=o("TFFunnelForTokenClassification"),ldt=o(" (Funnel Transformer model)"),idt=l(),X6=a("li"),Jxe=a("strong"),ddt=o("layoutlm"),mdt=o(" \u2014 "),vse=a("a"),cdt=o("TFLayoutLMForTokenClassification"),fdt=o(" (LayoutLM model)"),gdt=l(),z6=a("li"),Yxe=a("strong"),hdt=o("layoutlmv3"),udt=o(" \u2014 "),Fse=a("a"),pdt=o("TFLayoutLMv3ForTokenClassification"),_dt=o(" (LayoutLMv3 model)"),bdt=l(),Q6=a("li"),Zxe=a("strong"),vdt=o("longformer"),Fdt=o(" \u2014 "),Tse=a("a"),Tdt=o("TFLongformerForTokenClassification"),Mdt=o(" (Longformer model)"),Edt=l(),W6=a("li"),Kxe=a("strong"),Cdt=o("mobilebert"),wdt=o(" \u2014 "),Mse=a("a"),Adt=o("TFMobileBertForTokenClassification"),Ldt=o(" (MobileBERT model)"),ydt=l(),U6=a("li"),e$e=a("strong"),xdt=o("mpnet"),$dt=o(" \u2014 "),Ese=a("a"),kdt=o("TFMPNetForTokenClassification"),Sdt=o(" (MPNet model)"),Rdt=l(),H6=a("li"),o$e=a("strong"),Pdt=o("rembert"),Bdt=o(" \u2014 "),Cse=a("a"),Idt=o("TFRemBertForTokenClassification"),Ndt=o(" (RemBERT model)"),qdt=l(),J6=a("li"),r$e=a("strong"),jdt=o("roberta"),Ddt=o(" \u2014 "),wse=a("a"),Gdt=o("TFRobertaForTokenClassification"),Odt=o(" (RoBERTa model)"),Vdt=l(),Y6=a("li"),t$e=a("strong"),Xdt=o("roformer"),zdt=o(" \u2014 "),Ase=a("a"),Qdt=o("TFRoFormerForTokenClassification"),Wdt=o(" (RoFormer model)"),Udt=l(),Z6=a("li"),a$e=a("strong"),Hdt=o("xlm"),Jdt=o(" \u2014 "),Lse=a("a"),Ydt=o("TFXLMForTokenClassification"),Zdt=o(" (XLM model)"),Kdt=l(),K6=a("li"),n$e=a("strong"),emt=o("xlm-roberta"),omt=o(" \u2014 "),yse=a("a"),rmt=o("TFXLMRobertaForTokenClassification"),tmt=o(" (XLM-RoBERTa model)"),amt=l(),e7=a("li"),s$e=a("strong"),nmt=o("xlnet"),smt=o(" \u2014 "),xse=a("a"),lmt=o("TFXLNetForTokenClassification"),imt=o(" (XLNet model)"),dmt=l(),F(o7.$$.fragment),Hao=l(),Uc=a("h2"),r7=a("a"),l$e=a("span"),F(MP.$$.fragment),mmt=l(),i$e=a("span"),cmt=o("TFAutoModelForQuestionAnswering"),Jao=l(),Er=a("div"),F(EP.$$.fragment),fmt=l(),Hc=a("p"),gmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$se=a("a"),hmt=o("from_pretrained()"),umt=o(" class method or the "),kse=a("a"),pmt=o("from_config()"),_mt=o(` class
method.`),bmt=l(),CP=a("p"),vmt=o("This class cannot be instantiated directly using "),d$e=a("code"),Fmt=o("__init__()"),Tmt=o(" (throws an error)."),Mmt=l(),da=a("div"),F(wP.$$.fragment),Emt=l(),m$e=a("p"),Cmt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),wmt=l(),Jc=a("p"),Amt=o(`Note:
Loading a model from its configuration file does `),c$e=a("strong"),Lmt=o("not"),ymt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sse=a("a"),xmt=o("from_pretrained()"),$mt=o(" to load the model weights."),kmt=l(),F(t7.$$.fragment),Smt=l(),Kr=a("div"),F(AP.$$.fragment),Rmt=l(),f$e=a("p"),Pmt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Bmt=l(),Un=a("p"),Imt=o("The model class to instantiate is selected based on the "),g$e=a("code"),Nmt=o("model_type"),qmt=o(` property of the config object (either
passed as an argument or loaded from `),h$e=a("code"),jmt=o("pretrained_model_name_or_path"),Dmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u$e=a("code"),Gmt=o("pretrained_model_name_or_path"),Omt=o(":"),Vmt=l(),fe=a("ul"),a7=a("li"),p$e=a("strong"),Xmt=o("albert"),zmt=o(" \u2014 "),Rse=a("a"),Qmt=o("TFAlbertForQuestionAnswering"),Wmt=o(" (ALBERT model)"),Umt=l(),n7=a("li"),_$e=a("strong"),Hmt=o("bert"),Jmt=o(" \u2014 "),Pse=a("a"),Ymt=o("TFBertForQuestionAnswering"),Zmt=o(" (BERT model)"),Kmt=l(),s7=a("li"),b$e=a("strong"),ect=o("camembert"),oct=o(" \u2014 "),Bse=a("a"),rct=o("TFCamembertForQuestionAnswering"),tct=o(" (CamemBERT model)"),act=l(),l7=a("li"),v$e=a("strong"),nct=o("convbert"),sct=o(" \u2014 "),Ise=a("a"),lct=o("TFConvBertForQuestionAnswering"),ict=o(" (ConvBERT model)"),dct=l(),i7=a("li"),F$e=a("strong"),mct=o("deberta"),cct=o(" \u2014 "),Nse=a("a"),fct=o("TFDebertaForQuestionAnswering"),gct=o(" (DeBERTa model)"),hct=l(),d7=a("li"),T$e=a("strong"),uct=o("deberta-v2"),pct=o(" \u2014 "),qse=a("a"),_ct=o("TFDebertaV2ForQuestionAnswering"),bct=o(" (DeBERTa-v2 model)"),vct=l(),m7=a("li"),M$e=a("strong"),Fct=o("distilbert"),Tct=o(" \u2014 "),jse=a("a"),Mct=o("TFDistilBertForQuestionAnswering"),Ect=o(" (DistilBERT model)"),Cct=l(),c7=a("li"),E$e=a("strong"),wct=o("electra"),Act=o(" \u2014 "),Dse=a("a"),Lct=o("TFElectraForQuestionAnswering"),yct=o(" (ELECTRA model)"),xct=l(),f7=a("li"),C$e=a("strong"),$ct=o("flaubert"),kct=o(" \u2014 "),Gse=a("a"),Sct=o("TFFlaubertForQuestionAnsweringSimple"),Rct=o(" (FlauBERT model)"),Pct=l(),g7=a("li"),w$e=a("strong"),Bct=o("funnel"),Ict=o(" \u2014 "),Ose=a("a"),Nct=o("TFFunnelForQuestionAnswering"),qct=o(" (Funnel Transformer model)"),jct=l(),h7=a("li"),A$e=a("strong"),Dct=o("gptj"),Gct=o(" \u2014 "),Vse=a("a"),Oct=o("TFGPTJForQuestionAnswering"),Vct=o(" (GPT-J model)"),Xct=l(),u7=a("li"),L$e=a("strong"),zct=o("layoutlmv3"),Qct=o(" \u2014 "),Xse=a("a"),Wct=o("TFLayoutLMv3ForQuestionAnswering"),Uct=o(" (LayoutLMv3 model)"),Hct=l(),p7=a("li"),y$e=a("strong"),Jct=o("longformer"),Yct=o(" \u2014 "),zse=a("a"),Zct=o("TFLongformerForQuestionAnswering"),Kct=o(" (Longformer model)"),eft=l(),_7=a("li"),x$e=a("strong"),oft=o("mobilebert"),rft=o(" \u2014 "),Qse=a("a"),tft=o("TFMobileBertForQuestionAnswering"),aft=o(" (MobileBERT model)"),nft=l(),b7=a("li"),$$e=a("strong"),sft=o("mpnet"),lft=o(" \u2014 "),Wse=a("a"),ift=o("TFMPNetForQuestionAnswering"),dft=o(" (MPNet model)"),mft=l(),v7=a("li"),k$e=a("strong"),cft=o("rembert"),fft=o(" \u2014 "),Use=a("a"),gft=o("TFRemBertForQuestionAnswering"),hft=o(" (RemBERT model)"),uft=l(),F7=a("li"),S$e=a("strong"),pft=o("roberta"),_ft=o(" \u2014 "),Hse=a("a"),bft=o("TFRobertaForQuestionAnswering"),vft=o(" (RoBERTa model)"),Fft=l(),T7=a("li"),R$e=a("strong"),Tft=o("roformer"),Mft=o(" \u2014 "),Jse=a("a"),Eft=o("TFRoFormerForQuestionAnswering"),Cft=o(" (RoFormer model)"),wft=l(),M7=a("li"),P$e=a("strong"),Aft=o("xlm"),Lft=o(" \u2014 "),Yse=a("a"),yft=o("TFXLMForQuestionAnsweringSimple"),xft=o(" (XLM model)"),$ft=l(),E7=a("li"),B$e=a("strong"),kft=o("xlm-roberta"),Sft=o(" \u2014 "),Zse=a("a"),Rft=o("TFXLMRobertaForQuestionAnswering"),Pft=o(" (XLM-RoBERTa model)"),Bft=l(),C7=a("li"),I$e=a("strong"),Ift=o("xlnet"),Nft=o(" \u2014 "),Kse=a("a"),qft=o("TFXLNetForQuestionAnsweringSimple"),jft=o(" (XLNet model)"),Dft=l(),F(w7.$$.fragment),Yao=l(),Yc=a("h2"),A7=a("a"),N$e=a("span"),F(LP.$$.fragment),Gft=l(),q$e=a("span"),Oft=o("TFAutoModelForVision2Seq"),Zao=l(),Cr=a("div"),F(yP.$$.fragment),Vft=l(),Zc=a("p"),Xft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ele=a("a"),zft=o("from_pretrained()"),Qft=o(" class method or the "),ole=a("a"),Wft=o("from_config()"),Uft=o(` class
method.`),Hft=l(),xP=a("p"),Jft=o("This class cannot be instantiated directly using "),j$e=a("code"),Yft=o("__init__()"),Zft=o(" (throws an error)."),Kft=l(),ma=a("div"),F($P.$$.fragment),egt=l(),D$e=a("p"),ogt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),rgt=l(),Kc=a("p"),tgt=o(`Note:
Loading a model from its configuration file does `),G$e=a("strong"),agt=o("not"),ngt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rle=a("a"),sgt=o("from_pretrained()"),lgt=o(" to load the model weights."),igt=l(),F(L7.$$.fragment),dgt=l(),et=a("div"),F(kP.$$.fragment),mgt=l(),O$e=a("p"),cgt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fgt=l(),Hn=a("p"),ggt=o("The model class to instantiate is selected based on the "),V$e=a("code"),hgt=o("model_type"),ugt=o(` property of the config object (either
passed as an argument or loaded from `),X$e=a("code"),pgt=o("pretrained_model_name_or_path"),_gt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z$e=a("code"),bgt=o("pretrained_model_name_or_path"),vgt=o(":"),Fgt=l(),Q$e=a("ul"),y7=a("li"),W$e=a("strong"),Tgt=o("vision-encoder-decoder"),Mgt=o(" \u2014 "),tle=a("a"),Egt=o("TFVisionEncoderDecoderModel"),Cgt=o(" (Vision Encoder decoder model)"),wgt=l(),F(x7.$$.fragment),Kao=l(),ef=a("h2"),$7=a("a"),U$e=a("span"),F(SP.$$.fragment),Agt=l(),H$e=a("span"),Lgt=o("TFAutoModelForSpeechSeq2Seq"),eno=l(),wr=a("div"),F(RP.$$.fragment),ygt=l(),of=a("p"),xgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ale=a("a"),$gt=o("from_pretrained()"),kgt=o(" class method or the "),nle=a("a"),Sgt=o("from_config()"),Rgt=o(` class
method.`),Pgt=l(),PP=a("p"),Bgt=o("This class cannot be instantiated directly using "),J$e=a("code"),Igt=o("__init__()"),Ngt=o(" (throws an error)."),qgt=l(),ca=a("div"),F(BP.$$.fragment),jgt=l(),Y$e=a("p"),Dgt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ggt=l(),rf=a("p"),Ogt=o(`Note:
Loading a model from its configuration file does `),Z$e=a("strong"),Vgt=o("not"),Xgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sle=a("a"),zgt=o("from_pretrained()"),Qgt=o(" to load the model weights."),Wgt=l(),F(k7.$$.fragment),Ugt=l(),ot=a("div"),F(IP.$$.fragment),Hgt=l(),K$e=a("p"),Jgt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Ygt=l(),Jn=a("p"),Zgt=o("The model class to instantiate is selected based on the "),eke=a("code"),Kgt=o("model_type"),eht=o(` property of the config object (either
passed as an argument or loaded from `),oke=a("code"),oht=o("pretrained_model_name_or_path"),rht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rke=a("code"),tht=o("pretrained_model_name_or_path"),aht=o(":"),nht=l(),NP=a("ul"),S7=a("li"),tke=a("strong"),sht=o("speech_to_text"),lht=o(" \u2014 "),lle=a("a"),iht=o("TFSpeech2TextForConditionalGeneration"),dht=o(" (Speech2Text model)"),mht=l(),R7=a("li"),ake=a("strong"),cht=o("whisper"),fht=o(" \u2014 "),ile=a("a"),ght=o("TFWhisperForConditionalGeneration"),hht=o(" (Whisper model)"),uht=l(),F(P7.$$.fragment),ono=l(),tf=a("h2"),B7=a("a"),nke=a("span"),F(qP.$$.fragment),pht=l(),ske=a("span"),_ht=o("FlaxAutoModel"),rno=l(),Ar=a("div"),F(jP.$$.fragment),bht=l(),af=a("p"),vht=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),dle=a("a"),Fht=o("from_pretrained()"),Tht=o(" class method or the "),mle=a("a"),Mht=o("from_config()"),Eht=o(` class
method.`),Cht=l(),DP=a("p"),wht=o("This class cannot be instantiated directly using "),lke=a("code"),Aht=o("__init__()"),Lht=o(" (throws an error)."),yht=l(),fa=a("div"),F(GP.$$.fragment),xht=l(),ike=a("p"),$ht=o("Instantiates one of the base model classes of the library from a configuration."),kht=l(),nf=a("p"),Sht=o(`Note:
Loading a model from its configuration file does `),dke=a("strong"),Rht=o("not"),Pht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cle=a("a"),Bht=o("from_pretrained()"),Iht=o(" to load the model weights."),Nht=l(),F(I7.$$.fragment),qht=l(),rt=a("div"),F(OP.$$.fragment),jht=l(),mke=a("p"),Dht=o("Instantiate one of the base model classes of the library from a pretrained model."),Ght=l(),Yn=a("p"),Oht=o("The model class to instantiate is selected based on the "),cke=a("code"),Vht=o("model_type"),Xht=o(` property of the config object (either
passed as an argument or loaded from `),fke=a("code"),zht=o("pretrained_model_name_or_path"),Qht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gke=a("code"),Wht=o("pretrained_model_name_or_path"),Uht=o(":"),Hht=l(),te=a("ul"),N7=a("li"),hke=a("strong"),Jht=o("albert"),Yht=o(" \u2014 "),fle=a("a"),Zht=o("FlaxAlbertModel"),Kht=o(" (ALBERT model)"),eut=l(),q7=a("li"),uke=a("strong"),out=o("bart"),rut=o(" \u2014 "),gle=a("a"),tut=o("FlaxBartModel"),aut=o(" (BART model)"),nut=l(),j7=a("li"),pke=a("strong"),sut=o("beit"),lut=o(" \u2014 "),hle=a("a"),iut=o("FlaxBeitModel"),dut=o(" (BEiT model)"),mut=l(),D7=a("li"),_ke=a("strong"),cut=o("bert"),fut=o(" \u2014 "),ule=a("a"),gut=o("FlaxBertModel"),hut=o(" (BERT model)"),uut=l(),G7=a("li"),bke=a("strong"),put=o("big_bird"),_ut=o(" \u2014 "),ple=a("a"),but=o("FlaxBigBirdModel"),vut=o(" (BigBird model)"),Fut=l(),O7=a("li"),vke=a("strong"),Tut=o("blenderbot"),Mut=o(" \u2014 "),_le=a("a"),Eut=o("FlaxBlenderbotModel"),Cut=o(" (Blenderbot model)"),wut=l(),V7=a("li"),Fke=a("strong"),Aut=o("blenderbot-small"),Lut=o(" \u2014 "),ble=a("a"),yut=o("FlaxBlenderbotSmallModel"),xut=o(" (BlenderbotSmall model)"),$ut=l(),X7=a("li"),Tke=a("strong"),kut=o("clip"),Sut=o(" \u2014 "),vle=a("a"),Rut=o("FlaxCLIPModel"),Put=o(" (CLIP model)"),But=l(),z7=a("li"),Mke=a("strong"),Iut=o("distilbert"),Nut=o(" \u2014 "),Fle=a("a"),qut=o("FlaxDistilBertModel"),jut=o(" (DistilBERT model)"),Dut=l(),Q7=a("li"),Eke=a("strong"),Gut=o("electra"),Out=o(" \u2014 "),Tle=a("a"),Vut=o("FlaxElectraModel"),Xut=o(" (ELECTRA model)"),zut=l(),W7=a("li"),Cke=a("strong"),Qut=o("gpt2"),Wut=o(" \u2014 "),Mle=a("a"),Uut=o("FlaxGPT2Model"),Hut=o(" (OpenAI GPT-2 model)"),Jut=l(),U7=a("li"),wke=a("strong"),Yut=o("gpt_neo"),Zut=o(" \u2014 "),Ele=a("a"),Kut=o("FlaxGPTNeoModel"),ept=o(" (GPT Neo model)"),opt=l(),H7=a("li"),Ake=a("strong"),rpt=o("gptj"),tpt=o(" \u2014 "),Cle=a("a"),apt=o("FlaxGPTJModel"),npt=o(" (GPT-J model)"),spt=l(),J7=a("li"),Lke=a("strong"),lpt=o("longt5"),ipt=o(" \u2014 "),wle=a("a"),dpt=o("FlaxLongT5Model"),mpt=o(" (LongT5 model)"),cpt=l(),Y7=a("li"),yke=a("strong"),fpt=o("marian"),gpt=o(" \u2014 "),Ale=a("a"),hpt=o("FlaxMarianModel"),upt=o(" (Marian model)"),ppt=l(),Z7=a("li"),xke=a("strong"),_pt=o("mbart"),bpt=o(" \u2014 "),Lle=a("a"),vpt=o("FlaxMBartModel"),Fpt=o(" (mBART model)"),Tpt=l(),K7=a("li"),$ke=a("strong"),Mpt=o("mt5"),Ept=o(" \u2014 "),yle=a("a"),Cpt=o("FlaxMT5Model"),wpt=o(" (MT5 model)"),Apt=l(),e8=a("li"),kke=a("strong"),Lpt=o("opt"),ypt=o(" \u2014 "),xle=a("a"),xpt=o("FlaxOPTModel"),$pt=o(" (OPT model)"),kpt=l(),o8=a("li"),Ske=a("strong"),Spt=o("pegasus"),Rpt=o(" \u2014 "),$le=a("a"),Ppt=o("FlaxPegasusModel"),Bpt=o(" (Pegasus model)"),Ipt=l(),r8=a("li"),Rke=a("strong"),Npt=o("roberta"),qpt=o(" \u2014 "),kle=a("a"),jpt=o("FlaxRobertaModel"),Dpt=o(" (RoBERTa model)"),Gpt=l(),t8=a("li"),Pke=a("strong"),Opt=o("roformer"),Vpt=o(" \u2014 "),Sle=a("a"),Xpt=o("FlaxRoFormerModel"),zpt=o(" (RoFormer model)"),Qpt=l(),a8=a("li"),Bke=a("strong"),Wpt=o("t5"),Upt=o(" \u2014 "),Rle=a("a"),Hpt=o("FlaxT5Model"),Jpt=o(" (T5 model)"),Ypt=l(),n8=a("li"),Ike=a("strong"),Zpt=o("vision-text-dual-encoder"),Kpt=o(" \u2014 "),Ple=a("a"),e_t=o("FlaxVisionTextDualEncoderModel"),o_t=o(" (VisionTextDualEncoder model)"),r_t=l(),s8=a("li"),Nke=a("strong"),t_t=o("vit"),a_t=o(" \u2014 "),Ble=a("a"),n_t=o("FlaxViTModel"),s_t=o(" (ViT model)"),l_t=l(),l8=a("li"),qke=a("strong"),i_t=o("wav2vec2"),d_t=o(" \u2014 "),Ile=a("a"),m_t=o("FlaxWav2Vec2Model"),c_t=o(" (Wav2Vec2 model)"),f_t=l(),i8=a("li"),jke=a("strong"),g_t=o("xglm"),h_t=o(" \u2014 "),Nle=a("a"),u_t=o("FlaxXGLMModel"),p_t=o(" (XGLM model)"),__t=l(),d8=a("li"),Dke=a("strong"),b_t=o("xlm-roberta"),v_t=o(" \u2014 "),qle=a("a"),F_t=o("FlaxXLMRobertaModel"),T_t=o(" (XLM-RoBERTa model)"),M_t=l(),F(m8.$$.fragment),tno=l(),sf=a("h2"),c8=a("a"),Gke=a("span"),F(VP.$$.fragment),E_t=l(),Oke=a("span"),C_t=o("FlaxAutoModelForCausalLM"),ano=l(),Lr=a("div"),F(XP.$$.fragment),w_t=l(),lf=a("p"),A_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jle=a("a"),L_t=o("from_pretrained()"),y_t=o(" class method or the "),Dle=a("a"),x_t=o("from_config()"),$_t=o(` class
method.`),k_t=l(),zP=a("p"),S_t=o("This class cannot be instantiated directly using "),Vke=a("code"),R_t=o("__init__()"),P_t=o(" (throws an error)."),B_t=l(),ga=a("div"),F(QP.$$.fragment),I_t=l(),Xke=a("p"),N_t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),q_t=l(),df=a("p"),j_t=o(`Note:
Loading a model from its configuration file does `),zke=a("strong"),D_t=o("not"),G_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gle=a("a"),O_t=o("from_pretrained()"),V_t=o(" to load the model weights."),X_t=l(),F(f8.$$.fragment),z_t=l(),tt=a("div"),F(WP.$$.fragment),Q_t=l(),Qke=a("p"),W_t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),U_t=l(),Zn=a("p"),H_t=o("The model class to instantiate is selected based on the "),Wke=a("code"),J_t=o("model_type"),Y_t=o(` property of the config object (either
passed as an argument or loaded from `),Uke=a("code"),Z_t=o("pretrained_model_name_or_path"),K_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hke=a("code"),e1t=o("pretrained_model_name_or_path"),o1t=o(":"),r1t=l(),$e=a("ul"),g8=a("li"),Jke=a("strong"),t1t=o("bart"),a1t=o(" \u2014 "),Ole=a("a"),n1t=o("FlaxBartForCausalLM"),s1t=o(" (BART model)"),l1t=l(),h8=a("li"),Yke=a("strong"),i1t=o("bert"),d1t=o(" \u2014 "),Vle=a("a"),m1t=o("FlaxBertForCausalLM"),c1t=o(" (BERT model)"),f1t=l(),u8=a("li"),Zke=a("strong"),g1t=o("big_bird"),h1t=o(" \u2014 "),Xle=a("a"),u1t=o("FlaxBigBirdForCausalLM"),p1t=o(" (BigBird model)"),_1t=l(),p8=a("li"),Kke=a("strong"),b1t=o("electra"),v1t=o(" \u2014 "),zle=a("a"),F1t=o("FlaxElectraForCausalLM"),T1t=o(" (ELECTRA model)"),M1t=l(),_8=a("li"),eSe=a("strong"),E1t=o("gpt2"),C1t=o(" \u2014 "),Qle=a("a"),w1t=o("FlaxGPT2LMHeadModel"),A1t=o(" (OpenAI GPT-2 model)"),L1t=l(),b8=a("li"),oSe=a("strong"),y1t=o("gpt_neo"),x1t=o(" \u2014 "),Wle=a("a"),$1t=o("FlaxGPTNeoForCausalLM"),k1t=o(" (GPT Neo model)"),S1t=l(),v8=a("li"),rSe=a("strong"),R1t=o("gptj"),P1t=o(" \u2014 "),Ule=a("a"),B1t=o("FlaxGPTJForCausalLM"),I1t=o(" (GPT-J model)"),N1t=l(),F8=a("li"),tSe=a("strong"),q1t=o("opt"),j1t=o(" \u2014 "),Hle=a("a"),D1t=o("FlaxOPTForCausalLM"),G1t=o(" (OPT model)"),O1t=l(),T8=a("li"),aSe=a("strong"),V1t=o("roberta"),X1t=o(" \u2014 "),Jle=a("a"),z1t=o("FlaxRobertaForCausalLM"),Q1t=o(" (RoBERTa model)"),W1t=l(),M8=a("li"),nSe=a("strong"),U1t=o("xglm"),H1t=o(" \u2014 "),Yle=a("a"),J1t=o("FlaxXGLMForCausalLM"),Y1t=o(" (XGLM model)"),Z1t=l(),F(E8.$$.fragment),nno=l(),mf=a("h2"),C8=a("a"),sSe=a("span"),F(UP.$$.fragment),K1t=l(),lSe=a("span"),e2t=o("FlaxAutoModelForPreTraining"),sno=l(),yr=a("div"),F(HP.$$.fragment),o2t=l(),cf=a("p"),r2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Zle=a("a"),t2t=o("from_pretrained()"),a2t=o(" class method or the "),Kle=a("a"),n2t=o("from_config()"),s2t=o(` class
method.`),l2t=l(),JP=a("p"),i2t=o("This class cannot be instantiated directly using "),iSe=a("code"),d2t=o("__init__()"),m2t=o(" (throws an error)."),c2t=l(),ha=a("div"),F(YP.$$.fragment),f2t=l(),dSe=a("p"),g2t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),h2t=l(),ff=a("p"),u2t=o(`Note:
Loading a model from its configuration file does `),mSe=a("strong"),p2t=o("not"),_2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eie=a("a"),b2t=o("from_pretrained()"),v2t=o(" to load the model weights."),F2t=l(),F(w8.$$.fragment),T2t=l(),at=a("div"),F(ZP.$$.fragment),M2t=l(),cSe=a("p"),E2t=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),C2t=l(),Kn=a("p"),w2t=o("The model class to instantiate is selected based on the "),fSe=a("code"),A2t=o("model_type"),L2t=o(` property of the config object (either
passed as an argument or loaded from `),gSe=a("code"),y2t=o("pretrained_model_name_or_path"),x2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hSe=a("code"),$2t=o("pretrained_model_name_or_path"),k2t=o(":"),S2t=l(),Ee=a("ul"),A8=a("li"),uSe=a("strong"),R2t=o("albert"),P2t=o(" \u2014 "),oie=a("a"),B2t=o("FlaxAlbertForPreTraining"),I2t=o(" (ALBERT model)"),N2t=l(),L8=a("li"),pSe=a("strong"),q2t=o("bart"),j2t=o(" \u2014 "),rie=a("a"),D2t=o("FlaxBartForConditionalGeneration"),G2t=o(" (BART model)"),O2t=l(),y8=a("li"),_Se=a("strong"),V2t=o("bert"),X2t=o(" \u2014 "),tie=a("a"),z2t=o("FlaxBertForPreTraining"),Q2t=o(" (BERT model)"),W2t=l(),x8=a("li"),bSe=a("strong"),U2t=o("big_bird"),H2t=o(" \u2014 "),aie=a("a"),J2t=o("FlaxBigBirdForPreTraining"),Y2t=o(" (BigBird model)"),Z2t=l(),$8=a("li"),vSe=a("strong"),K2t=o("electra"),ebt=o(" \u2014 "),nie=a("a"),obt=o("FlaxElectraForPreTraining"),rbt=o(" (ELECTRA model)"),tbt=l(),k8=a("li"),FSe=a("strong"),abt=o("longt5"),nbt=o(" \u2014 "),sie=a("a"),sbt=o("FlaxLongT5ForConditionalGeneration"),lbt=o(" (LongT5 model)"),ibt=l(),S8=a("li"),TSe=a("strong"),dbt=o("mbart"),mbt=o(" \u2014 "),lie=a("a"),cbt=o("FlaxMBartForConditionalGeneration"),fbt=o(" (mBART model)"),gbt=l(),R8=a("li"),MSe=a("strong"),hbt=o("mt5"),ubt=o(" \u2014 "),iie=a("a"),pbt=o("FlaxMT5ForConditionalGeneration"),_bt=o(" (MT5 model)"),bbt=l(),P8=a("li"),ESe=a("strong"),vbt=o("roberta"),Fbt=o(" \u2014 "),die=a("a"),Tbt=o("FlaxRobertaForMaskedLM"),Mbt=o(" (RoBERTa model)"),Ebt=l(),B8=a("li"),CSe=a("strong"),Cbt=o("roformer"),wbt=o(" \u2014 "),mie=a("a"),Abt=o("FlaxRoFormerForMaskedLM"),Lbt=o(" (RoFormer model)"),ybt=l(),I8=a("li"),wSe=a("strong"),xbt=o("t5"),$bt=o(" \u2014 "),cie=a("a"),kbt=o("FlaxT5ForConditionalGeneration"),Sbt=o(" (T5 model)"),Rbt=l(),N8=a("li"),ASe=a("strong"),Pbt=o("wav2vec2"),Bbt=o(" \u2014 "),fie=a("a"),Ibt=o("FlaxWav2Vec2ForPreTraining"),Nbt=o(" (Wav2Vec2 model)"),qbt=l(),q8=a("li"),LSe=a("strong"),jbt=o("xlm-roberta"),Dbt=o(" \u2014 "),gie=a("a"),Gbt=o("FlaxXLMRobertaForMaskedLM"),Obt=o(" (XLM-RoBERTa model)"),Vbt=l(),F(j8.$$.fragment),lno=l(),gf=a("h2"),D8=a("a"),ySe=a("span"),F(KP.$$.fragment),Xbt=l(),xSe=a("span"),zbt=o("FlaxAutoModelForMaskedLM"),ino=l(),xr=a("div"),F(eB.$$.fragment),Qbt=l(),hf=a("p"),Wbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),hie=a("a"),Ubt=o("from_pretrained()"),Hbt=o(" class method or the "),uie=a("a"),Jbt=o("from_config()"),Ybt=o(` class
method.`),Zbt=l(),oB=a("p"),Kbt=o("This class cannot be instantiated directly using "),$Se=a("code"),evt=o("__init__()"),ovt=o(" (throws an error)."),rvt=l(),ua=a("div"),F(rB.$$.fragment),tvt=l(),kSe=a("p"),avt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),nvt=l(),uf=a("p"),svt=o(`Note:
Loading a model from its configuration file does `),SSe=a("strong"),lvt=o("not"),ivt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pie=a("a"),dvt=o("from_pretrained()"),mvt=o(" to load the model weights."),cvt=l(),F(G8.$$.fragment),fvt=l(),nt=a("div"),F(tB.$$.fragment),gvt=l(),RSe=a("p"),hvt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),uvt=l(),es=a("p"),pvt=o("The model class to instantiate is selected based on the "),PSe=a("code"),_vt=o("model_type"),bvt=o(` property of the config object (either
passed as an argument or loaded from `),BSe=a("code"),vvt=o("pretrained_model_name_or_path"),Fvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ISe=a("code"),Tvt=o("pretrained_model_name_or_path"),Mvt=o(":"),Evt=l(),ke=a("ul"),O8=a("li"),NSe=a("strong"),Cvt=o("albert"),wvt=o(" \u2014 "),_ie=a("a"),Avt=o("FlaxAlbertForMaskedLM"),Lvt=o(" (ALBERT model)"),yvt=l(),V8=a("li"),qSe=a("strong"),xvt=o("bart"),$vt=o(" \u2014 "),bie=a("a"),kvt=o("FlaxBartForConditionalGeneration"),Svt=o(" (BART model)"),Rvt=l(),X8=a("li"),jSe=a("strong"),Pvt=o("bert"),Bvt=o(" \u2014 "),vie=a("a"),Ivt=o("FlaxBertForMaskedLM"),Nvt=o(" (BERT model)"),qvt=l(),z8=a("li"),DSe=a("strong"),jvt=o("big_bird"),Dvt=o(" \u2014 "),Fie=a("a"),Gvt=o("FlaxBigBirdForMaskedLM"),Ovt=o(" (BigBird model)"),Vvt=l(),Q8=a("li"),GSe=a("strong"),Xvt=o("distilbert"),zvt=o(" \u2014 "),Tie=a("a"),Qvt=o("FlaxDistilBertForMaskedLM"),Wvt=o(" (DistilBERT model)"),Uvt=l(),W8=a("li"),OSe=a("strong"),Hvt=o("electra"),Jvt=o(" \u2014 "),Mie=a("a"),Yvt=o("FlaxElectraForMaskedLM"),Zvt=o(" (ELECTRA model)"),Kvt=l(),U8=a("li"),VSe=a("strong"),eFt=o("mbart"),oFt=o(" \u2014 "),Eie=a("a"),rFt=o("FlaxMBartForConditionalGeneration"),tFt=o(" (mBART model)"),aFt=l(),H8=a("li"),XSe=a("strong"),nFt=o("roberta"),sFt=o(" \u2014 "),Cie=a("a"),lFt=o("FlaxRobertaForMaskedLM"),iFt=o(" (RoBERTa model)"),dFt=l(),J8=a("li"),zSe=a("strong"),mFt=o("roformer"),cFt=o(" \u2014 "),wie=a("a"),fFt=o("FlaxRoFormerForMaskedLM"),gFt=o(" (RoFormer model)"),hFt=l(),Y8=a("li"),QSe=a("strong"),uFt=o("xlm-roberta"),pFt=o(" \u2014 "),Aie=a("a"),_Ft=o("FlaxXLMRobertaForMaskedLM"),bFt=o(" (XLM-RoBERTa model)"),vFt=l(),F(Z8.$$.fragment),dno=l(),pf=a("h2"),K8=a("a"),WSe=a("span"),F(aB.$$.fragment),FFt=l(),USe=a("span"),TFt=o("FlaxAutoModelForSeq2SeqLM"),mno=l(),$r=a("div"),F(nB.$$.fragment),MFt=l(),_f=a("p"),EFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Lie=a("a"),CFt=o("from_pretrained()"),wFt=o(" class method or the "),yie=a("a"),AFt=o("from_config()"),LFt=o(` class
method.`),yFt=l(),sB=a("p"),xFt=o("This class cannot be instantiated directly using "),HSe=a("code"),$Ft=o("__init__()"),kFt=o(" (throws an error)."),SFt=l(),pa=a("div"),F(lB.$$.fragment),RFt=l(),JSe=a("p"),PFt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BFt=l(),bf=a("p"),IFt=o(`Note:
Loading a model from its configuration file does `),YSe=a("strong"),NFt=o("not"),qFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xie=a("a"),jFt=o("from_pretrained()"),DFt=o(" to load the model weights."),GFt=l(),F(eL.$$.fragment),OFt=l(),st=a("div"),F(iB.$$.fragment),VFt=l(),ZSe=a("p"),XFt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),zFt=l(),os=a("p"),QFt=o("The model class to instantiate is selected based on the "),KSe=a("code"),WFt=o("model_type"),UFt=o(` property of the config object (either
passed as an argument or loaded from `),eRe=a("code"),HFt=o("pretrained_model_name_or_path"),JFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oRe=a("code"),YFt=o("pretrained_model_name_or_path"),ZFt=o(":"),KFt=l(),Se=a("ul"),oL=a("li"),rRe=a("strong"),eTt=o("bart"),oTt=o(" \u2014 "),$ie=a("a"),rTt=o("FlaxBartForConditionalGeneration"),tTt=o(" (BART model)"),aTt=l(),rL=a("li"),tRe=a("strong"),nTt=o("blenderbot"),sTt=o(" \u2014 "),kie=a("a"),lTt=o("FlaxBlenderbotForConditionalGeneration"),iTt=o(" (Blenderbot model)"),dTt=l(),tL=a("li"),aRe=a("strong"),mTt=o("blenderbot-small"),cTt=o(" \u2014 "),Sie=a("a"),fTt=o("FlaxBlenderbotSmallForConditionalGeneration"),gTt=o(" (BlenderbotSmall model)"),hTt=l(),aL=a("li"),nRe=a("strong"),uTt=o("encoder-decoder"),pTt=o(" \u2014 "),Rie=a("a"),_Tt=o("FlaxEncoderDecoderModel"),bTt=o(" (Encoder decoder model)"),vTt=l(),nL=a("li"),sRe=a("strong"),FTt=o("longt5"),TTt=o(" \u2014 "),Pie=a("a"),MTt=o("FlaxLongT5ForConditionalGeneration"),ETt=o(" (LongT5 model)"),CTt=l(),sL=a("li"),lRe=a("strong"),wTt=o("marian"),ATt=o(" \u2014 "),Bie=a("a"),LTt=o("FlaxMarianMTModel"),yTt=o(" (Marian model)"),xTt=l(),lL=a("li"),iRe=a("strong"),$Tt=o("mbart"),kTt=o(" \u2014 "),Iie=a("a"),STt=o("FlaxMBartForConditionalGeneration"),RTt=o(" (mBART model)"),PTt=l(),iL=a("li"),dRe=a("strong"),BTt=o("mt5"),ITt=o(" \u2014 "),Nie=a("a"),NTt=o("FlaxMT5ForConditionalGeneration"),qTt=o(" (MT5 model)"),jTt=l(),dL=a("li"),mRe=a("strong"),DTt=o("pegasus"),GTt=o(" \u2014 "),qie=a("a"),OTt=o("FlaxPegasusForConditionalGeneration"),VTt=o(" (Pegasus model)"),XTt=l(),mL=a("li"),cRe=a("strong"),zTt=o("t5"),QTt=o(" \u2014 "),jie=a("a"),WTt=o("FlaxT5ForConditionalGeneration"),UTt=o(" (T5 model)"),HTt=l(),F(cL.$$.fragment),cno=l(),vf=a("h2"),fL=a("a"),fRe=a("span"),F(dB.$$.fragment),JTt=l(),gRe=a("span"),YTt=o("FlaxAutoModelForSequenceClassification"),fno=l(),kr=a("div"),F(mB.$$.fragment),ZTt=l(),Ff=a("p"),KTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Die=a("a"),eMt=o("from_pretrained()"),oMt=o(" class method or the "),Gie=a("a"),rMt=o("from_config()"),tMt=o(` class
method.`),aMt=l(),cB=a("p"),nMt=o("This class cannot be instantiated directly using "),hRe=a("code"),sMt=o("__init__()"),lMt=o(" (throws an error)."),iMt=l(),_a=a("div"),F(fB.$$.fragment),dMt=l(),uRe=a("p"),mMt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),cMt=l(),Tf=a("p"),fMt=o(`Note:
Loading a model from its configuration file does `),pRe=a("strong"),gMt=o("not"),hMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Oie=a("a"),uMt=o("from_pretrained()"),pMt=o(" to load the model weights."),_Mt=l(),F(gL.$$.fragment),bMt=l(),lt=a("div"),F(gB.$$.fragment),vMt=l(),_Re=a("p"),FMt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TMt=l(),rs=a("p"),MMt=o("The model class to instantiate is selected based on the "),bRe=a("code"),EMt=o("model_type"),CMt=o(` property of the config object (either
passed as an argument or loaded from `),vRe=a("code"),wMt=o("pretrained_model_name_or_path"),AMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FRe=a("code"),LMt=o("pretrained_model_name_or_path"),yMt=o(":"),xMt=l(),Re=a("ul"),hL=a("li"),TRe=a("strong"),$Mt=o("albert"),kMt=o(" \u2014 "),Vie=a("a"),SMt=o("FlaxAlbertForSequenceClassification"),RMt=o(" (ALBERT model)"),PMt=l(),uL=a("li"),MRe=a("strong"),BMt=o("bart"),IMt=o(" \u2014 "),Xie=a("a"),NMt=o("FlaxBartForSequenceClassification"),qMt=o(" (BART model)"),jMt=l(),pL=a("li"),ERe=a("strong"),DMt=o("bert"),GMt=o(" \u2014 "),zie=a("a"),OMt=o("FlaxBertForSequenceClassification"),VMt=o(" (BERT model)"),XMt=l(),_L=a("li"),CRe=a("strong"),zMt=o("big_bird"),QMt=o(" \u2014 "),Qie=a("a"),WMt=o("FlaxBigBirdForSequenceClassification"),UMt=o(" (BigBird model)"),HMt=l(),bL=a("li"),wRe=a("strong"),JMt=o("distilbert"),YMt=o(" \u2014 "),Wie=a("a"),ZMt=o("FlaxDistilBertForSequenceClassification"),KMt=o(" (DistilBERT model)"),eEt=l(),vL=a("li"),ARe=a("strong"),oEt=o("electra"),rEt=o(" \u2014 "),Uie=a("a"),tEt=o("FlaxElectraForSequenceClassification"),aEt=o(" (ELECTRA model)"),nEt=l(),FL=a("li"),LRe=a("strong"),sEt=o("mbart"),lEt=o(" \u2014 "),Hie=a("a"),iEt=o("FlaxMBartForSequenceClassification"),dEt=o(" (mBART model)"),mEt=l(),TL=a("li"),yRe=a("strong"),cEt=o("roberta"),fEt=o(" \u2014 "),Jie=a("a"),gEt=o("FlaxRobertaForSequenceClassification"),hEt=o(" (RoBERTa model)"),uEt=l(),ML=a("li"),xRe=a("strong"),pEt=o("roformer"),_Et=o(" \u2014 "),Yie=a("a"),bEt=o("FlaxRoFormerForSequenceClassification"),vEt=o(" (RoFormer model)"),FEt=l(),EL=a("li"),$Re=a("strong"),TEt=o("xlm-roberta"),MEt=o(" \u2014 "),Zie=a("a"),EEt=o("FlaxXLMRobertaForSequenceClassification"),CEt=o(" (XLM-RoBERTa model)"),wEt=l(),F(CL.$$.fragment),gno=l(),Mf=a("h2"),wL=a("a"),kRe=a("span"),F(hB.$$.fragment),AEt=l(),SRe=a("span"),LEt=o("FlaxAutoModelForQuestionAnswering"),hno=l(),Sr=a("div"),F(uB.$$.fragment),yEt=l(),Ef=a("p"),xEt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kie=a("a"),$Et=o("from_pretrained()"),kEt=o(" class method or the "),ede=a("a"),SEt=o("from_config()"),REt=o(` class
method.`),PEt=l(),pB=a("p"),BEt=o("This class cannot be instantiated directly using "),RRe=a("code"),IEt=o("__init__()"),NEt=o(" (throws an error)."),qEt=l(),ba=a("div"),F(_B.$$.fragment),jEt=l(),PRe=a("p"),DEt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),GEt=l(),Cf=a("p"),OEt=o(`Note:
Loading a model from its configuration file does `),BRe=a("strong"),VEt=o("not"),XEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ode=a("a"),zEt=o("from_pretrained()"),QEt=o(" to load the model weights."),WEt=l(),F(AL.$$.fragment),UEt=l(),it=a("div"),F(bB.$$.fragment),HEt=l(),IRe=a("p"),JEt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),YEt=l(),ts=a("p"),ZEt=o("The model class to instantiate is selected based on the "),NRe=a("code"),KEt=o("model_type"),e4t=o(` property of the config object (either
passed as an argument or loaded from `),qRe=a("code"),o4t=o("pretrained_model_name_or_path"),r4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jRe=a("code"),t4t=o("pretrained_model_name_or_path"),a4t=o(":"),n4t=l(),Pe=a("ul"),LL=a("li"),DRe=a("strong"),s4t=o("albert"),l4t=o(" \u2014 "),rde=a("a"),i4t=o("FlaxAlbertForQuestionAnswering"),d4t=o(" (ALBERT model)"),m4t=l(),yL=a("li"),GRe=a("strong"),c4t=o("bart"),f4t=o(" \u2014 "),tde=a("a"),g4t=o("FlaxBartForQuestionAnswering"),h4t=o(" (BART model)"),u4t=l(),xL=a("li"),ORe=a("strong"),p4t=o("bert"),_4t=o(" \u2014 "),ade=a("a"),b4t=o("FlaxBertForQuestionAnswering"),v4t=o(" (BERT model)"),F4t=l(),$L=a("li"),VRe=a("strong"),T4t=o("big_bird"),M4t=o(" \u2014 "),nde=a("a"),E4t=o("FlaxBigBirdForQuestionAnswering"),C4t=o(" (BigBird model)"),w4t=l(),kL=a("li"),XRe=a("strong"),A4t=o("distilbert"),L4t=o(" \u2014 "),sde=a("a"),y4t=o("FlaxDistilBertForQuestionAnswering"),x4t=o(" (DistilBERT model)"),$4t=l(),SL=a("li"),zRe=a("strong"),k4t=o("electra"),S4t=o(" \u2014 "),lde=a("a"),R4t=o("FlaxElectraForQuestionAnswering"),P4t=o(" (ELECTRA model)"),B4t=l(),RL=a("li"),QRe=a("strong"),I4t=o("mbart"),N4t=o(" \u2014 "),ide=a("a"),q4t=o("FlaxMBartForQuestionAnswering"),j4t=o(" (mBART model)"),D4t=l(),PL=a("li"),WRe=a("strong"),G4t=o("roberta"),O4t=o(" \u2014 "),dde=a("a"),V4t=o("FlaxRobertaForQuestionAnswering"),X4t=o(" (RoBERTa model)"),z4t=l(),BL=a("li"),URe=a("strong"),Q4t=o("roformer"),W4t=o(" \u2014 "),mde=a("a"),U4t=o("FlaxRoFormerForQuestionAnswering"),H4t=o(" (RoFormer model)"),J4t=l(),IL=a("li"),HRe=a("strong"),Y4t=o("xlm-roberta"),Z4t=o(" \u2014 "),cde=a("a"),K4t=o("FlaxXLMRobertaForQuestionAnswering"),eCt=o(" (XLM-RoBERTa model)"),oCt=l(),F(NL.$$.fragment),uno=l(),wf=a("h2"),qL=a("a"),JRe=a("span"),F(vB.$$.fragment),rCt=l(),YRe=a("span"),tCt=o("FlaxAutoModelForTokenClassification"),pno=l(),Rr=a("div"),F(FB.$$.fragment),aCt=l(),Af=a("p"),nCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fde=a("a"),sCt=o("from_pretrained()"),lCt=o(" class method or the "),gde=a("a"),iCt=o("from_config()"),dCt=o(` class
method.`),mCt=l(),TB=a("p"),cCt=o("This class cannot be instantiated directly using "),ZRe=a("code"),fCt=o("__init__()"),gCt=o(" (throws an error)."),hCt=l(),va=a("div"),F(MB.$$.fragment),uCt=l(),KRe=a("p"),pCt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),_Ct=l(),Lf=a("p"),bCt=o(`Note:
Loading a model from its configuration file does `),ePe=a("strong"),vCt=o("not"),FCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hde=a("a"),TCt=o("from_pretrained()"),MCt=o(" to load the model weights."),ECt=l(),F(jL.$$.fragment),CCt=l(),dt=a("div"),F(EB.$$.fragment),wCt=l(),oPe=a("p"),ACt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),LCt=l(),as=a("p"),yCt=o("The model class to instantiate is selected based on the "),rPe=a("code"),xCt=o("model_type"),$Ct=o(` property of the config object (either
passed as an argument or loaded from `),tPe=a("code"),kCt=o("pretrained_model_name_or_path"),SCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aPe=a("code"),RCt=o("pretrained_model_name_or_path"),PCt=o(":"),BCt=l(),ze=a("ul"),DL=a("li"),nPe=a("strong"),ICt=o("albert"),NCt=o(" \u2014 "),ude=a("a"),qCt=o("FlaxAlbertForTokenClassification"),jCt=o(" (ALBERT model)"),DCt=l(),GL=a("li"),sPe=a("strong"),GCt=o("bert"),OCt=o(" \u2014 "),pde=a("a"),VCt=o("FlaxBertForTokenClassification"),XCt=o(" (BERT model)"),zCt=l(),OL=a("li"),lPe=a("strong"),QCt=o("big_bird"),WCt=o(" \u2014 "),_de=a("a"),UCt=o("FlaxBigBirdForTokenClassification"),HCt=o(" (BigBird model)"),JCt=l(),VL=a("li"),iPe=a("strong"),YCt=o("distilbert"),ZCt=o(" \u2014 "),bde=a("a"),KCt=o("FlaxDistilBertForTokenClassification"),e3t=o(" (DistilBERT model)"),o3t=l(),XL=a("li"),dPe=a("strong"),r3t=o("electra"),t3t=o(" \u2014 "),vde=a("a"),a3t=o("FlaxElectraForTokenClassification"),n3t=o(" (ELECTRA model)"),s3t=l(),zL=a("li"),mPe=a("strong"),l3t=o("roberta"),i3t=o(" \u2014 "),Fde=a("a"),d3t=o("FlaxRobertaForTokenClassification"),m3t=o(" (RoBERTa model)"),c3t=l(),QL=a("li"),cPe=a("strong"),f3t=o("roformer"),g3t=o(" \u2014 "),Tde=a("a"),h3t=o("FlaxRoFormerForTokenClassification"),u3t=o(" (RoFormer model)"),p3t=l(),WL=a("li"),fPe=a("strong"),_3t=o("xlm-roberta"),b3t=o(" \u2014 "),Mde=a("a"),v3t=o("FlaxXLMRobertaForTokenClassification"),F3t=o(" (XLM-RoBERTa model)"),T3t=l(),F(UL.$$.fragment),_no=l(),yf=a("h2"),HL=a("a"),gPe=a("span"),F(CB.$$.fragment),M3t=l(),hPe=a("span"),E3t=o("FlaxAutoModelForMultipleChoice"),bno=l(),Pr=a("div"),F(wB.$$.fragment),C3t=l(),xf=a("p"),w3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ede=a("a"),A3t=o("from_pretrained()"),L3t=o(" class method or the "),Cde=a("a"),y3t=o("from_config()"),x3t=o(` class
method.`),$3t=l(),AB=a("p"),k3t=o("This class cannot be instantiated directly using "),uPe=a("code"),S3t=o("__init__()"),R3t=o(" (throws an error)."),P3t=l(),Fa=a("div"),F(LB.$$.fragment),B3t=l(),pPe=a("p"),I3t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),N3t=l(),$f=a("p"),q3t=o(`Note:
Loading a model from its configuration file does `),_Pe=a("strong"),j3t=o("not"),D3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wde=a("a"),G3t=o("from_pretrained()"),O3t=o(" to load the model weights."),V3t=l(),F(JL.$$.fragment),X3t=l(),mt=a("div"),F(yB.$$.fragment),z3t=l(),bPe=a("p"),Q3t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),W3t=l(),ns=a("p"),U3t=o("The model class to instantiate is selected based on the "),vPe=a("code"),H3t=o("model_type"),J3t=o(` property of the config object (either
passed as an argument or loaded from `),FPe=a("code"),Y3t=o("pretrained_model_name_or_path"),Z3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TPe=a("code"),K3t=o("pretrained_model_name_or_path"),e5t=o(":"),o5t=l(),Qe=a("ul"),YL=a("li"),MPe=a("strong"),r5t=o("albert"),t5t=o(" \u2014 "),Ade=a("a"),a5t=o("FlaxAlbertForMultipleChoice"),n5t=o(" (ALBERT model)"),s5t=l(),ZL=a("li"),EPe=a("strong"),l5t=o("bert"),i5t=o(" \u2014 "),Lde=a("a"),d5t=o("FlaxBertForMultipleChoice"),m5t=o(" (BERT model)"),c5t=l(),KL=a("li"),CPe=a("strong"),f5t=o("big_bird"),g5t=o(" \u2014 "),yde=a("a"),h5t=o("FlaxBigBirdForMultipleChoice"),u5t=o(" (BigBird model)"),p5t=l(),ey=a("li"),wPe=a("strong"),_5t=o("distilbert"),b5t=o(" \u2014 "),xde=a("a"),v5t=o("FlaxDistilBertForMultipleChoice"),F5t=o(" (DistilBERT model)"),T5t=l(),oy=a("li"),APe=a("strong"),M5t=o("electra"),E5t=o(" \u2014 "),$de=a("a"),C5t=o("FlaxElectraForMultipleChoice"),w5t=o(" (ELECTRA model)"),A5t=l(),ry=a("li"),LPe=a("strong"),L5t=o("roberta"),y5t=o(" \u2014 "),kde=a("a"),x5t=o("FlaxRobertaForMultipleChoice"),$5t=o(" (RoBERTa model)"),k5t=l(),ty=a("li"),yPe=a("strong"),S5t=o("roformer"),R5t=o(" \u2014 "),Sde=a("a"),P5t=o("FlaxRoFormerForMultipleChoice"),B5t=o(" (RoFormer model)"),I5t=l(),ay=a("li"),xPe=a("strong"),N5t=o("xlm-roberta"),q5t=o(" \u2014 "),Rde=a("a"),j5t=o("FlaxXLMRobertaForMultipleChoice"),D5t=o(" (XLM-RoBERTa model)"),G5t=l(),F(ny.$$.fragment),vno=l(),kf=a("h2"),sy=a("a"),$Pe=a("span"),F(xB.$$.fragment),O5t=l(),kPe=a("span"),V5t=o("FlaxAutoModelForNextSentencePrediction"),Fno=l(),Br=a("div"),F($B.$$.fragment),X5t=l(),Sf=a("p"),z5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Pde=a("a"),Q5t=o("from_pretrained()"),W5t=o(" class method or the "),Bde=a("a"),U5t=o("from_config()"),H5t=o(` class
method.`),J5t=l(),kB=a("p"),Y5t=o("This class cannot be instantiated directly using "),SPe=a("code"),Z5t=o("__init__()"),K5t=o(" (throws an error)."),e0t=l(),Ta=a("div"),F(SB.$$.fragment),o0t=l(),RPe=a("p"),r0t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),t0t=l(),Rf=a("p"),a0t=o(`Note:
Loading a model from its configuration file does `),PPe=a("strong"),n0t=o("not"),s0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ide=a("a"),l0t=o("from_pretrained()"),i0t=o(" to load the model weights."),d0t=l(),F(ly.$$.fragment),m0t=l(),ct=a("div"),F(RB.$$.fragment),c0t=l(),BPe=a("p"),f0t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),g0t=l(),ss=a("p"),h0t=o("The model class to instantiate is selected based on the "),IPe=a("code"),u0t=o("model_type"),p0t=o(` property of the config object (either
passed as an argument or loaded from `),NPe=a("code"),_0t=o("pretrained_model_name_or_path"),b0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qPe=a("code"),v0t=o("pretrained_model_name_or_path"),F0t=o(":"),T0t=l(),jPe=a("ul"),iy=a("li"),DPe=a("strong"),M0t=o("bert"),E0t=o(" \u2014 "),Nde=a("a"),C0t=o("FlaxBertForNextSentencePrediction"),w0t=o(" (BERT model)"),A0t=l(),F(dy.$$.fragment),Tno=l(),Pf=a("h2"),my=a("a"),GPe=a("span"),F(PB.$$.fragment),L0t=l(),OPe=a("span"),y0t=o("FlaxAutoModelForImageClassification"),Mno=l(),Ir=a("div"),F(BB.$$.fragment),x0t=l(),Bf=a("p"),$0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),qde=a("a"),k0t=o("from_pretrained()"),S0t=o(" class method or the "),jde=a("a"),R0t=o("from_config()"),P0t=o(` class
method.`),B0t=l(),IB=a("p"),I0t=o("This class cannot be instantiated directly using "),VPe=a("code"),N0t=o("__init__()"),q0t=o(" (throws an error)."),j0t=l(),Ma=a("div"),F(NB.$$.fragment),D0t=l(),XPe=a("p"),G0t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),O0t=l(),If=a("p"),V0t=o(`Note:
Loading a model from its configuration file does `),zPe=a("strong"),X0t=o("not"),z0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dde=a("a"),Q0t=o("from_pretrained()"),W0t=o(" to load the model weights."),U0t=l(),F(cy.$$.fragment),H0t=l(),ft=a("div"),F(qB.$$.fragment),J0t=l(),QPe=a("p"),Y0t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Z0t=l(),ls=a("p"),K0t=o("The model class to instantiate is selected based on the "),WPe=a("code"),ewt=o("model_type"),owt=o(` property of the config object (either
passed as an argument or loaded from `),UPe=a("code"),rwt=o("pretrained_model_name_or_path"),twt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HPe=a("code"),awt=o("pretrained_model_name_or_path"),nwt=o(":"),swt=l(),jB=a("ul"),fy=a("li"),JPe=a("strong"),lwt=o("beit"),iwt=o(" \u2014 "),Gde=a("a"),dwt=o("FlaxBeitForImageClassification"),mwt=o(" (BEiT model)"),cwt=l(),gy=a("li"),YPe=a("strong"),fwt=o("vit"),gwt=o(" \u2014 "),Ode=a("a"),hwt=o("FlaxViTForImageClassification"),uwt=o(" (ViT model)"),pwt=l(),F(hy.$$.fragment),Eno=l(),Nf=a("h2"),uy=a("a"),ZPe=a("span"),F(DB.$$.fragment),_wt=l(),KPe=a("span"),bwt=o("FlaxAutoModelForVision2Seq"),Cno=l(),Nr=a("div"),F(GB.$$.fragment),vwt=l(),qf=a("p"),Fwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Vde=a("a"),Twt=o("from_pretrained()"),Mwt=o(" class method or the "),Xde=a("a"),Ewt=o("from_config()"),Cwt=o(` class
method.`),wwt=l(),OB=a("p"),Awt=o("This class cannot be instantiated directly using "),eBe=a("code"),Lwt=o("__init__()"),ywt=o(" (throws an error)."),xwt=l(),Ea=a("div"),F(VB.$$.fragment),$wt=l(),oBe=a("p"),kwt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Swt=l(),jf=a("p"),Rwt=o(`Note:
Loading a model from its configuration file does `),rBe=a("strong"),Pwt=o("not"),Bwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zde=a("a"),Iwt=o("from_pretrained()"),Nwt=o(" to load the model weights."),qwt=l(),F(py.$$.fragment),jwt=l(),gt=a("div"),F(XB.$$.fragment),Dwt=l(),tBe=a("p"),Gwt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Owt=l(),is=a("p"),Vwt=o("The model class to instantiate is selected based on the "),aBe=a("code"),Xwt=o("model_type"),zwt=o(` property of the config object (either
passed as an argument or loaded from `),nBe=a("code"),Qwt=o("pretrained_model_name_or_path"),Wwt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sBe=a("code"),Uwt=o("pretrained_model_name_or_path"),Hwt=o(":"),Jwt=l(),lBe=a("ul"),_y=a("li"),iBe=a("strong"),Ywt=o("vision-encoder-decoder"),Zwt=o(" \u2014 "),Qde=a("a"),Kwt=o("FlaxVisionEncoderDecoderModel"),eAt=o(" (Vision Encoder decoder model)"),oAt=l(),F(by.$$.fragment),this.h()},l(c){const _=SCa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var zB=s(u);f=n(zB,"A",{id:!0,class:!0,href:!0});var dBe=s(f);p=n(dBe,"SPAN",{});var mBe=s(p);T(d.$$.fragment,mBe),mBe.forEach(t),dBe.forEach(t),h=i(zB),$o=n(zB,"SPAN",{});var cBe=s($o);pd=r(cBe,"Auto Classes"),cBe.forEach(t),zB.forEach(t),Vf=i(c),Ft=n(c,"P",{});var QB=s(Ft);_d=r(QB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),bd=n(QB,"CODE",{});var fBe=s(bd);o$=r(fBe,"from_pretrained()"),fBe.forEach(t),Xf=r(QB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),QB.forEach(t),Xe=i(c),He=n(c,"P",{});var ds=s(He);vd=r(ds,"Instantiating one of "),ms=n(ds,"A",{href:!0});var gBe=s(ms);r$=r(gBe,"AutoConfig"),gBe.forEach(t),cs=r(ds,", "),fs=n(ds,"A",{href:!0});var hBe=s(fs);t$=r(hBe,"AutoModel"),hBe.forEach(t),Fd=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var uBe=s(gs);a$=r(uBe,"AutoTokenizer"),uBe.forEach(t),Td=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),zf=i(c),T(en.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var WB=s(Ae);_N=r(WB,"will create a model that is an instance of "),Md=n(WB,"A",{href:!0});var pBe=s(Md);bN=r(pBe,"BertModel"),pBe.forEach(t),vN=r(WB,"."),WB.forEach(t),ko=i(c),on=n(c,"P",{});var UB=s(on);FN=r(UB,"There is one class of "),Qf=n(UB,"CODE",{});var _Be=s(Qf);TN=r(_Be,"AutoModel"),_Be.forEach(t),Wlo=r(UB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),UB.forEach(t),ito=i(c),Ed=n(c,"H2",{class:!0});var HB=s(Ed);Wf=n(HB,"A",{id:!0,class:!0,href:!0});var bBe=s(Wf);ofe=n(bBe,"SPAN",{});var vBe=s(ofe);T(n$.$$.fragment,vBe),vBe.forEach(t),bBe.forEach(t),Ulo=i(HB),rfe=n(HB,"SPAN",{});var FBe=s(rfe);Hlo=r(FBe,"Extending the Auto Classes"),FBe.forEach(t),HB.forEach(t),dto=i(c),hs=n(c,"P",{});var Df=s(hs);Jlo=r(Df,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),tfe=n(Df,"CODE",{});var TBe=s(tfe);Ylo=r(TBe,"NewModel"),TBe.forEach(t),Zlo=r(Df,", make sure you have a "),afe=n(Df,"CODE",{});var MBe=s(afe);Klo=r(MBe,"NewModelConfig"),MBe.forEach(t),eio=r(Df,` then you can add those to the auto
classes like this:`),Df.forEach(t),mto=i(c),T(s$.$$.fragment,c),cto=i(c),MN=n(c,"P",{});var EBe=s(MN);oio=r(EBe,"You will then be able to use the auto classes like you would usually do!"),EBe.forEach(t),fto=i(c),T(Uf.$$.fragment,c),gto=i(c),Cd=n(c,"H2",{class:!0});var JB=s(Cd);Hf=n(JB,"A",{id:!0,class:!0,href:!0});var CBe=s(Hf);nfe=n(CBe,"SPAN",{});var wBe=s(nfe);T(l$.$$.fragment,wBe),wBe.forEach(t),CBe.forEach(t),rio=i(JB),sfe=n(JB,"SPAN",{});var ABe=s(sfe);tio=r(ABe,"AutoConfig"),ABe.forEach(t),JB.forEach(t),hto=i(c),So=n(c,"DIV",{class:!0});var bt=s(So);T(i$.$$.fragment,bt),aio=i(bt),d$=n(bt,"P",{});var YB=s(d$);nio=r(YB,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),EN=n(YB,"A",{href:!0});var LBe=s(EN);sio=r(LBe,"from_pretrained()"),LBe.forEach(t),lio=r(YB," class method."),YB.forEach(t),iio=i(bt),m$=n(bt,"P",{});var ZB=s(m$);dio=r(ZB,"This class cannot be instantiated directly using "),lfe=n(ZB,"CODE",{});var yBe=s(lfe);mio=r(yBe,"__init__()"),yBe.forEach(t),cio=r(ZB," (throws an error)."),ZB.forEach(t),fio=i(bt),qr=n(bt,"DIV",{class:!0});var vt=s(qr);T(c$.$$.fragment,vt),gio=i(vt),ife=n(vt,"P",{});var xBe=s(ife);hio=r(xBe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),xBe.forEach(t),uio=i(vt),wd=n(vt,"P",{});var Gf=s(wd);pio=r(Gf,"The configuration class to instantiate is selected based on the "),dfe=n(Gf,"CODE",{});var $Be=s(dfe);_io=r($Be,"model_type"),$Be.forEach(t),bio=r(Gf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),mfe=n(Gf,"CODE",{});var kBe=s(mfe);vio=r(kBe,"pretrained_model_name_or_path"),kBe.forEach(t),Fio=r(Gf,":"),Gf.forEach(t),Tio=i(vt),A=n(vt,"UL",{});var L=s(A);Jf=n(L,"LI",{});var vy=s(Jf);cfe=n(vy,"STRONG",{});var SBe=s(cfe);Mio=r(SBe,"albert"),SBe.forEach(t),Eio=r(vy," \u2014 "),CN=n(vy,"A",{href:!0});var RBe=s(CN);Cio=r(RBe,"AlbertConfig"),RBe.forEach(t),wio=r(vy," (ALBERT model)"),vy.forEach(t),Aio=i(L),Yf=n(L,"LI",{});var Fy=s(Yf);ffe=n(Fy,"STRONG",{});var PBe=s(ffe);Lio=r(PBe,"bart"),PBe.forEach(t),yio=r(Fy," \u2014 "),wN=n(Fy,"A",{href:!0});var BBe=s(wN);xio=r(BBe,"BartConfig"),BBe.forEach(t),$io=r(Fy," (BART model)"),Fy.forEach(t),kio=i(L),Zf=n(L,"LI",{});var Ty=s(Zf);gfe=n(Ty,"STRONG",{});var IBe=s(gfe);Sio=r(IBe,"beit"),IBe.forEach(t),Rio=r(Ty," \u2014 "),AN=n(Ty,"A",{href:!0});var NBe=s(AN);Pio=r(NBe,"BeitConfig"),NBe.forEach(t),Bio=r(Ty," (BEiT model)"),Ty.forEach(t),Iio=i(L),Kf=n(L,"LI",{});var My=s(Kf);hfe=n(My,"STRONG",{});var qBe=s(hfe);Nio=r(qBe,"bert"),qBe.forEach(t),qio=r(My," \u2014 "),LN=n(My,"A",{href:!0});var jBe=s(LN);jio=r(jBe,"BertConfig"),jBe.forEach(t),Dio=r(My," (BERT model)"),My.forEach(t),Gio=i(L),eg=n(L,"LI",{});var Ey=s(eg);ufe=n(Ey,"STRONG",{});var DBe=s(ufe);Oio=r(DBe,"bert-generation"),DBe.forEach(t),Vio=r(Ey," \u2014 "),yN=n(Ey,"A",{href:!0});var GBe=s(yN);Xio=r(GBe,"BertGenerationConfig"),GBe.forEach(t),zio=r(Ey," (Bert Generation model)"),Ey.forEach(t),Qio=i(L),og=n(L,"LI",{});var Cy=s(og);pfe=n(Cy,"STRONG",{});var OBe=s(pfe);Wio=r(OBe,"big_bird"),OBe.forEach(t),Uio=r(Cy," \u2014 "),xN=n(Cy,"A",{href:!0});var VBe=s(xN);Hio=r(VBe,"BigBirdConfig"),VBe.forEach(t),Jio=r(Cy," (BigBird model)"),Cy.forEach(t),Yio=i(L),rg=n(L,"LI",{});var wy=s(rg);_fe=n(wy,"STRONG",{});var XBe=s(_fe);Zio=r(XBe,"bigbird_pegasus"),XBe.forEach(t),Kio=r(wy," \u2014 "),$N=n(wy,"A",{href:!0});var zBe=s($N);edo=r(zBe,"BigBirdPegasusConfig"),zBe.forEach(t),odo=r(wy," (BigBird-Pegasus model)"),wy.forEach(t),rdo=i(L),tg=n(L,"LI",{});var Ay=s(tg);bfe=n(Ay,"STRONG",{});var QBe=s(bfe);tdo=r(QBe,"blenderbot"),QBe.forEach(t),ado=r(Ay," \u2014 "),kN=n(Ay,"A",{href:!0});var WBe=s(kN);ndo=r(WBe,"BlenderbotConfig"),WBe.forEach(t),sdo=r(Ay," (Blenderbot model)"),Ay.forEach(t),ldo=i(L),ag=n(L,"LI",{});var Ly=s(ag);vfe=n(Ly,"STRONG",{});var UBe=s(vfe);ido=r(UBe,"blenderbot-small"),UBe.forEach(t),ddo=r(Ly," \u2014 "),SN=n(Ly,"A",{href:!0});var HBe=s(SN);mdo=r(HBe,"BlenderbotSmallConfig"),HBe.forEach(t),cdo=r(Ly," (BlenderbotSmall model)"),Ly.forEach(t),fdo=i(L),ng=n(L,"LI",{});var yy=s(ng);Ffe=n(yy,"STRONG",{});var JBe=s(Ffe);gdo=r(JBe,"bloom"),JBe.forEach(t),hdo=r(yy," \u2014 "),RN=n(yy,"A",{href:!0});var YBe=s(RN);udo=r(YBe,"BloomConfig"),YBe.forEach(t),pdo=r(yy," (BLOOM model)"),yy.forEach(t),_do=i(L),sg=n(L,"LI",{});var xy=s(sg);Tfe=n(xy,"STRONG",{});var ZBe=s(Tfe);bdo=r(ZBe,"camembert"),ZBe.forEach(t),vdo=r(xy," \u2014 "),PN=n(xy,"A",{href:!0});var KBe=s(PN);Fdo=r(KBe,"CamembertConfig"),KBe.forEach(t),Tdo=r(xy," (CamemBERT model)"),xy.forEach(t),Mdo=i(L),lg=n(L,"LI",{});var $y=s(lg);Mfe=n($y,"STRONG",{});var eIe=s(Mfe);Edo=r(eIe,"canine"),eIe.forEach(t),Cdo=r($y," \u2014 "),BN=n($y,"A",{href:!0});var oIe=s(BN);wdo=r(oIe,"CanineConfig"),oIe.forEach(t),Ado=r($y," (CANINE model)"),$y.forEach(t),Ldo=i(L),ig=n(L,"LI",{});var ky=s(ig);Efe=n(ky,"STRONG",{});var rIe=s(Efe);ydo=r(rIe,"clip"),rIe.forEach(t),xdo=r(ky," \u2014 "),IN=n(ky,"A",{href:!0});var tIe=s(IN);$do=r(tIe,"CLIPConfig"),tIe.forEach(t),kdo=r(ky," (CLIP model)"),ky.forEach(t),Sdo=i(L),dg=n(L,"LI",{});var Sy=s(dg);Cfe=n(Sy,"STRONG",{});var aIe=s(Cfe);Rdo=r(aIe,"codegen"),aIe.forEach(t),Pdo=r(Sy," \u2014 "),NN=n(Sy,"A",{href:!0});var nIe=s(NN);Bdo=r(nIe,"CodeGenConfig"),nIe.forEach(t),Ido=r(Sy," (CodeGen model)"),Sy.forEach(t),Ndo=i(L),mg=n(L,"LI",{});var Ry=s(mg);wfe=n(Ry,"STRONG",{});var sIe=s(wfe);qdo=r(sIe,"conditional_detr"),sIe.forEach(t),jdo=r(Ry," \u2014 "),qN=n(Ry,"A",{href:!0});var lIe=s(qN);Ddo=r(lIe,"ConditionalDetrConfig"),lIe.forEach(t),Gdo=r(Ry," (Conditional DETR model)"),Ry.forEach(t),Odo=i(L),cg=n(L,"LI",{});var Py=s(cg);Afe=n(Py,"STRONG",{});var iIe=s(Afe);Vdo=r(iIe,"convbert"),iIe.forEach(t),Xdo=r(Py," \u2014 "),jN=n(Py,"A",{href:!0});var dIe=s(jN);zdo=r(dIe,"ConvBertConfig"),dIe.forEach(t),Qdo=r(Py," (ConvBERT model)"),Py.forEach(t),Wdo=i(L),fg=n(L,"LI",{});var By=s(fg);Lfe=n(By,"STRONG",{});var mIe=s(Lfe);Udo=r(mIe,"convnext"),mIe.forEach(t),Hdo=r(By," \u2014 "),DN=n(By,"A",{href:!0});var cIe=s(DN);Jdo=r(cIe,"ConvNextConfig"),cIe.forEach(t),Ydo=r(By," (ConvNeXT model)"),By.forEach(t),Zdo=i(L),gg=n(L,"LI",{});var Iy=s(gg);yfe=n(Iy,"STRONG",{});var fIe=s(yfe);Kdo=r(fIe,"ctrl"),fIe.forEach(t),emo=r(Iy," \u2014 "),GN=n(Iy,"A",{href:!0});var gIe=s(GN);omo=r(gIe,"CTRLConfig"),gIe.forEach(t),rmo=r(Iy," (CTRL model)"),Iy.forEach(t),tmo=i(L),hg=n(L,"LI",{});var Ny=s(hg);xfe=n(Ny,"STRONG",{});var hIe=s(xfe);amo=r(hIe,"cvt"),hIe.forEach(t),nmo=r(Ny," \u2014 "),ON=n(Ny,"A",{href:!0});var uIe=s(ON);smo=r(uIe,"CvtConfig"),uIe.forEach(t),lmo=r(Ny," (CvT model)"),Ny.forEach(t),imo=i(L),ug=n(L,"LI",{});var qy=s(ug);$fe=n(qy,"STRONG",{});var pIe=s($fe);dmo=r(pIe,"data2vec-audio"),pIe.forEach(t),mmo=r(qy," \u2014 "),VN=n(qy,"A",{href:!0});var _Ie=s(VN);cmo=r(_Ie,"Data2VecAudioConfig"),_Ie.forEach(t),fmo=r(qy," (Data2VecAudio model)"),qy.forEach(t),gmo=i(L),pg=n(L,"LI",{});var jy=s(pg);kfe=n(jy,"STRONG",{});var bIe=s(kfe);hmo=r(bIe,"data2vec-text"),bIe.forEach(t),umo=r(jy," \u2014 "),XN=n(jy,"A",{href:!0});var vIe=s(XN);pmo=r(vIe,"Data2VecTextConfig"),vIe.forEach(t),_mo=r(jy," (Data2VecText model)"),jy.forEach(t),bmo=i(L),_g=n(L,"LI",{});var Dy=s(_g);Sfe=n(Dy,"STRONG",{});var FIe=s(Sfe);vmo=r(FIe,"data2vec-vision"),FIe.forEach(t),Fmo=r(Dy," \u2014 "),zN=n(Dy,"A",{href:!0});var TIe=s(zN);Tmo=r(TIe,"Data2VecVisionConfig"),TIe.forEach(t),Mmo=r(Dy," (Data2VecVision model)"),Dy.forEach(t),Emo=i(L),bg=n(L,"LI",{});var Gy=s(bg);Rfe=n(Gy,"STRONG",{});var MIe=s(Rfe);Cmo=r(MIe,"deberta"),MIe.forEach(t),wmo=r(Gy," \u2014 "),QN=n(Gy,"A",{href:!0});var EIe=s(QN);Amo=r(EIe,"DebertaConfig"),EIe.forEach(t),Lmo=r(Gy," (DeBERTa model)"),Gy.forEach(t),ymo=i(L),vg=n(L,"LI",{});var Oy=s(vg);Pfe=n(Oy,"STRONG",{});var CIe=s(Pfe);xmo=r(CIe,"deberta-v2"),CIe.forEach(t),$mo=r(Oy," \u2014 "),WN=n(Oy,"A",{href:!0});var wIe=s(WN);kmo=r(wIe,"DebertaV2Config"),wIe.forEach(t),Smo=r(Oy," (DeBERTa-v2 model)"),Oy.forEach(t),Rmo=i(L),Fg=n(L,"LI",{});var Vy=s(Fg);Bfe=n(Vy,"STRONG",{});var AIe=s(Bfe);Pmo=r(AIe,"decision_transformer"),AIe.forEach(t),Bmo=r(Vy," \u2014 "),UN=n(Vy,"A",{href:!0});var LIe=s(UN);Imo=r(LIe,"DecisionTransformerConfig"),LIe.forEach(t),Nmo=r(Vy," (Decision Transformer model)"),Vy.forEach(t),qmo=i(L),Tg=n(L,"LI",{});var Xy=s(Tg);Ife=n(Xy,"STRONG",{});var yIe=s(Ife);jmo=r(yIe,"deformable_detr"),yIe.forEach(t),Dmo=r(Xy," \u2014 "),HN=n(Xy,"A",{href:!0});var xIe=s(HN);Gmo=r(xIe,"DeformableDetrConfig"),xIe.forEach(t),Omo=r(Xy," (Deformable DETR model)"),Xy.forEach(t),Vmo=i(L),Mg=n(L,"LI",{});var zy=s(Mg);Nfe=n(zy,"STRONG",{});var $Ie=s(Nfe);Xmo=r($Ie,"deit"),$Ie.forEach(t),zmo=r(zy," \u2014 "),JN=n(zy,"A",{href:!0});var kIe=s(JN);Qmo=r(kIe,"DeiTConfig"),kIe.forEach(t),Wmo=r(zy," (DeiT model)"),zy.forEach(t),Umo=i(L),Eg=n(L,"LI",{});var Qy=s(Eg);qfe=n(Qy,"STRONG",{});var tAt=s(qfe);Hmo=r(tAt,"detr"),tAt.forEach(t),Jmo=r(Qy," \u2014 "),YN=n(Qy,"A",{href:!0});var aAt=s(YN);Ymo=r(aAt,"DetrConfig"),aAt.forEach(t),Zmo=r(Qy," (DETR model)"),Qy.forEach(t),Kmo=i(L),Cg=n(L,"LI",{});var SIe=s(Cg);jfe=n(SIe,"STRONG",{});var nAt=s(jfe);eco=r(nAt,"distilbert"),nAt.forEach(t),oco=r(SIe," \u2014 "),ZN=n(SIe,"A",{href:!0});var sAt=s(ZN);rco=r(sAt,"DistilBertConfig"),sAt.forEach(t),tco=r(SIe," (DistilBERT model)"),SIe.forEach(t),aco=i(L),wg=n(L,"LI",{});var RIe=s(wg);Dfe=n(RIe,"STRONG",{});var lAt=s(Dfe);nco=r(lAt,"donut-swin"),lAt.forEach(t),sco=r(RIe," \u2014 "),KN=n(RIe,"A",{href:!0});var iAt=s(KN);lco=r(iAt,"DonutSwinConfig"),iAt.forEach(t),ico=r(RIe," (DonutSwin model)"),RIe.forEach(t),dco=i(L),Ag=n(L,"LI",{});var PIe=s(Ag);Gfe=n(PIe,"STRONG",{});var dAt=s(Gfe);mco=r(dAt,"dpr"),dAt.forEach(t),cco=r(PIe," \u2014 "),eq=n(PIe,"A",{href:!0});var mAt=s(eq);fco=r(mAt,"DPRConfig"),mAt.forEach(t),gco=r(PIe," (DPR model)"),PIe.forEach(t),hco=i(L),Lg=n(L,"LI",{});var BIe=s(Lg);Ofe=n(BIe,"STRONG",{});var cAt=s(Ofe);uco=r(cAt,"dpt"),cAt.forEach(t),pco=r(BIe," \u2014 "),oq=n(BIe,"A",{href:!0});var fAt=s(oq);_co=r(fAt,"DPTConfig"),fAt.forEach(t),bco=r(BIe," (DPT model)"),BIe.forEach(t),vco=i(L),yg=n(L,"LI",{});var IIe=s(yg);Vfe=n(IIe,"STRONG",{});var gAt=s(Vfe);Fco=r(gAt,"electra"),gAt.forEach(t),Tco=r(IIe," \u2014 "),rq=n(IIe,"A",{href:!0});var hAt=s(rq);Mco=r(hAt,"ElectraConfig"),hAt.forEach(t),Eco=r(IIe," (ELECTRA model)"),IIe.forEach(t),Cco=i(L),xg=n(L,"LI",{});var NIe=s(xg);Xfe=n(NIe,"STRONG",{});var uAt=s(Xfe);wco=r(uAt,"encoder-decoder"),uAt.forEach(t),Aco=r(NIe," \u2014 "),tq=n(NIe,"A",{href:!0});var pAt=s(tq);Lco=r(pAt,"EncoderDecoderConfig"),pAt.forEach(t),yco=r(NIe," (Encoder decoder model)"),NIe.forEach(t),xco=i(L),$g=n(L,"LI",{});var qIe=s($g);zfe=n(qIe,"STRONG",{});var _At=s(zfe);$co=r(_At,"ernie"),_At.forEach(t),kco=r(qIe," \u2014 "),aq=n(qIe,"A",{href:!0});var bAt=s(aq);Sco=r(bAt,"ErnieConfig"),bAt.forEach(t),Rco=r(qIe," (ERNIE model)"),qIe.forEach(t),Pco=i(L),kg=n(L,"LI",{});var jIe=s(kg);Qfe=n(jIe,"STRONG",{});var vAt=s(Qfe);Bco=r(vAt,"esm"),vAt.forEach(t),Ico=r(jIe," \u2014 "),nq=n(jIe,"A",{href:!0});var FAt=s(nq);Nco=r(FAt,"EsmConfig"),FAt.forEach(t),qco=r(jIe," (ESM model)"),jIe.forEach(t),jco=i(L),Sg=n(L,"LI",{});var DIe=s(Sg);Wfe=n(DIe,"STRONG",{});var TAt=s(Wfe);Dco=r(TAt,"flaubert"),TAt.forEach(t),Gco=r(DIe," \u2014 "),sq=n(DIe,"A",{href:!0});var MAt=s(sq);Oco=r(MAt,"FlaubertConfig"),MAt.forEach(t),Vco=r(DIe," (FlauBERT model)"),DIe.forEach(t),Xco=i(L),Rg=n(L,"LI",{});var GIe=s(Rg);Ufe=n(GIe,"STRONG",{});var EAt=s(Ufe);zco=r(EAt,"flava"),EAt.forEach(t),Qco=r(GIe," \u2014 "),lq=n(GIe,"A",{href:!0});var CAt=s(lq);Wco=r(CAt,"FlavaConfig"),CAt.forEach(t),Uco=r(GIe," (FLAVA model)"),GIe.forEach(t),Hco=i(L),Pg=n(L,"LI",{});var OIe=s(Pg);Hfe=n(OIe,"STRONG",{});var wAt=s(Hfe);Jco=r(wAt,"fnet"),wAt.forEach(t),Yco=r(OIe," \u2014 "),iq=n(OIe,"A",{href:!0});var AAt=s(iq);Zco=r(AAt,"FNetConfig"),AAt.forEach(t),Kco=r(OIe," (FNet model)"),OIe.forEach(t),efo=i(L),Bg=n(L,"LI",{});var VIe=s(Bg);Jfe=n(VIe,"STRONG",{});var LAt=s(Jfe);ofo=r(LAt,"fsmt"),LAt.forEach(t),rfo=r(VIe," \u2014 "),dq=n(VIe,"A",{href:!0});var yAt=s(dq);tfo=r(yAt,"FSMTConfig"),yAt.forEach(t),afo=r(VIe," (FairSeq Machine-Translation model)"),VIe.forEach(t),nfo=i(L),Ig=n(L,"LI",{});var XIe=s(Ig);Yfe=n(XIe,"STRONG",{});var xAt=s(Yfe);sfo=r(xAt,"funnel"),xAt.forEach(t),lfo=r(XIe," \u2014 "),mq=n(XIe,"A",{href:!0});var $At=s(mq);ifo=r($At,"FunnelConfig"),$At.forEach(t),dfo=r(XIe," (Funnel Transformer model)"),XIe.forEach(t),mfo=i(L),Ng=n(L,"LI",{});var zIe=s(Ng);Zfe=n(zIe,"STRONG",{});var kAt=s(Zfe);cfo=r(kAt,"glpn"),kAt.forEach(t),ffo=r(zIe," \u2014 "),cq=n(zIe,"A",{href:!0});var SAt=s(cq);gfo=r(SAt,"GLPNConfig"),SAt.forEach(t),hfo=r(zIe," (GLPN model)"),zIe.forEach(t),ufo=i(L),qg=n(L,"LI",{});var QIe=s(qg);Kfe=n(QIe,"STRONG",{});var RAt=s(Kfe);pfo=r(RAt,"gpt2"),RAt.forEach(t),_fo=r(QIe," \u2014 "),fq=n(QIe,"A",{href:!0});var PAt=s(fq);bfo=r(PAt,"GPT2Config"),PAt.forEach(t),vfo=r(QIe," (OpenAI GPT-2 model)"),QIe.forEach(t),Ffo=i(L),jg=n(L,"LI",{});var WIe=s(jg);ege=n(WIe,"STRONG",{});var BAt=s(ege);Tfo=r(BAt,"gpt_neo"),BAt.forEach(t),Mfo=r(WIe," \u2014 "),gq=n(WIe,"A",{href:!0});var IAt=s(gq);Efo=r(IAt,"GPTNeoConfig"),IAt.forEach(t),Cfo=r(WIe," (GPT Neo model)"),WIe.forEach(t),wfo=i(L),Dg=n(L,"LI",{});var UIe=s(Dg);oge=n(UIe,"STRONG",{});var NAt=s(oge);Afo=r(NAt,"gpt_neox"),NAt.forEach(t),Lfo=r(UIe," \u2014 "),hq=n(UIe,"A",{href:!0});var qAt=s(hq);yfo=r(qAt,"GPTNeoXConfig"),qAt.forEach(t),xfo=r(UIe," (GPT NeoX model)"),UIe.forEach(t),$fo=i(L),Gg=n(L,"LI",{});var HIe=s(Gg);rge=n(HIe,"STRONG",{});var jAt=s(rge);kfo=r(jAt,"gpt_neox_japanese"),jAt.forEach(t),Sfo=r(HIe," \u2014 "),uq=n(HIe,"A",{href:!0});var DAt=s(uq);Rfo=r(DAt,"GPTNeoXJapaneseConfig"),DAt.forEach(t),Pfo=r(HIe," (GPT NeoX Japanese model)"),HIe.forEach(t),Bfo=i(L),Og=n(L,"LI",{});var JIe=s(Og);tge=n(JIe,"STRONG",{});var GAt=s(tge);Ifo=r(GAt,"gptj"),GAt.forEach(t),Nfo=r(JIe," \u2014 "),pq=n(JIe,"A",{href:!0});var OAt=s(pq);qfo=r(OAt,"GPTJConfig"),OAt.forEach(t),jfo=r(JIe," (GPT-J model)"),JIe.forEach(t),Dfo=i(L),Vg=n(L,"LI",{});var YIe=s(Vg);age=n(YIe,"STRONG",{});var VAt=s(age);Gfo=r(VAt,"groupvit"),VAt.forEach(t),Ofo=r(YIe," \u2014 "),_q=n(YIe,"A",{href:!0});var XAt=s(_q);Vfo=r(XAt,"GroupViTConfig"),XAt.forEach(t),Xfo=r(YIe," (GroupViT model)"),YIe.forEach(t),zfo=i(L),Xg=n(L,"LI",{});var ZIe=s(Xg);nge=n(ZIe,"STRONG",{});var zAt=s(nge);Qfo=r(zAt,"hubert"),zAt.forEach(t),Wfo=r(ZIe," \u2014 "),bq=n(ZIe,"A",{href:!0});var QAt=s(bq);Ufo=r(QAt,"HubertConfig"),QAt.forEach(t),Hfo=r(ZIe," (Hubert model)"),ZIe.forEach(t),Jfo=i(L),zg=n(L,"LI",{});var KIe=s(zg);sge=n(KIe,"STRONG",{});var WAt=s(sge);Yfo=r(WAt,"ibert"),WAt.forEach(t),Zfo=r(KIe," \u2014 "),vq=n(KIe,"A",{href:!0});var UAt=s(vq);Kfo=r(UAt,"IBertConfig"),UAt.forEach(t),ego=r(KIe," (I-BERT model)"),KIe.forEach(t),ogo=i(L),Qg=n(L,"LI",{});var eNe=s(Qg);lge=n(eNe,"STRONG",{});var HAt=s(lge);rgo=r(HAt,"imagegpt"),HAt.forEach(t),tgo=r(eNe," \u2014 "),Fq=n(eNe,"A",{href:!0});var JAt=s(Fq);ago=r(JAt,"ImageGPTConfig"),JAt.forEach(t),ngo=r(eNe," (ImageGPT model)"),eNe.forEach(t),sgo=i(L),Wg=n(L,"LI",{});var oNe=s(Wg);ige=n(oNe,"STRONG",{});var YAt=s(ige);lgo=r(YAt,"layoutlm"),YAt.forEach(t),igo=r(oNe," \u2014 "),Tq=n(oNe,"A",{href:!0});var ZAt=s(Tq);dgo=r(ZAt,"LayoutLMConfig"),ZAt.forEach(t),mgo=r(oNe," (LayoutLM model)"),oNe.forEach(t),cgo=i(L),Ug=n(L,"LI",{});var rNe=s(Ug);dge=n(rNe,"STRONG",{});var KAt=s(dge);fgo=r(KAt,"layoutlmv2"),KAt.forEach(t),ggo=r(rNe," \u2014 "),Mq=n(rNe,"A",{href:!0});var e6t=s(Mq);hgo=r(e6t,"LayoutLMv2Config"),e6t.forEach(t),ugo=r(rNe," (LayoutLMv2 model)"),rNe.forEach(t),pgo=i(L),Hg=n(L,"LI",{});var tNe=s(Hg);mge=n(tNe,"STRONG",{});var o6t=s(mge);_go=r(o6t,"layoutlmv3"),o6t.forEach(t),bgo=r(tNe," \u2014 "),Eq=n(tNe,"A",{href:!0});var r6t=s(Eq);vgo=r(r6t,"LayoutLMv3Config"),r6t.forEach(t),Fgo=r(tNe," (LayoutLMv3 model)"),tNe.forEach(t),Tgo=i(L),Jg=n(L,"LI",{});var aNe=s(Jg);cge=n(aNe,"STRONG",{});var t6t=s(cge);Mgo=r(t6t,"led"),t6t.forEach(t),Ego=r(aNe," \u2014 "),Cq=n(aNe,"A",{href:!0});var a6t=s(Cq);Cgo=r(a6t,"LEDConfig"),a6t.forEach(t),wgo=r(aNe," (LED model)"),aNe.forEach(t),Ago=i(L),Yg=n(L,"LI",{});var nNe=s(Yg);fge=n(nNe,"STRONG",{});var n6t=s(fge);Lgo=r(n6t,"levit"),n6t.forEach(t),ygo=r(nNe," \u2014 "),wq=n(nNe,"A",{href:!0});var s6t=s(wq);xgo=r(s6t,"LevitConfig"),s6t.forEach(t),$go=r(nNe," (LeViT model)"),nNe.forEach(t),kgo=i(L),Zg=n(L,"LI",{});var sNe=s(Zg);gge=n(sNe,"STRONG",{});var l6t=s(gge);Sgo=r(l6t,"lilt"),l6t.forEach(t),Rgo=r(sNe," \u2014 "),Aq=n(sNe,"A",{href:!0});var i6t=s(Aq);Pgo=r(i6t,"LiltConfig"),i6t.forEach(t),Bgo=r(sNe," (LiLT model)"),sNe.forEach(t),Igo=i(L),Kg=n(L,"LI",{});var lNe=s(Kg);hge=n(lNe,"STRONG",{});var d6t=s(hge);Ngo=r(d6t,"longformer"),d6t.forEach(t),qgo=r(lNe," \u2014 "),Lq=n(lNe,"A",{href:!0});var m6t=s(Lq);jgo=r(m6t,"LongformerConfig"),m6t.forEach(t),Dgo=r(lNe," (Longformer model)"),lNe.forEach(t),Ggo=i(L),eh=n(L,"LI",{});var iNe=s(eh);uge=n(iNe,"STRONG",{});var c6t=s(uge);Ogo=r(c6t,"longt5"),c6t.forEach(t),Vgo=r(iNe," \u2014 "),yq=n(iNe,"A",{href:!0});var f6t=s(yq);Xgo=r(f6t,"LongT5Config"),f6t.forEach(t),zgo=r(iNe," (LongT5 model)"),iNe.forEach(t),Qgo=i(L),oh=n(L,"LI",{});var dNe=s(oh);pge=n(dNe,"STRONG",{});var g6t=s(pge);Wgo=r(g6t,"luke"),g6t.forEach(t),Ugo=r(dNe," \u2014 "),xq=n(dNe,"A",{href:!0});var h6t=s(xq);Hgo=r(h6t,"LukeConfig"),h6t.forEach(t),Jgo=r(dNe," (LUKE model)"),dNe.forEach(t),Ygo=i(L),rh=n(L,"LI",{});var mNe=s(rh);_ge=n(mNe,"STRONG",{});var u6t=s(_ge);Zgo=r(u6t,"lxmert"),u6t.forEach(t),Kgo=r(mNe," \u2014 "),$q=n(mNe,"A",{href:!0});var p6t=s($q);eho=r(p6t,"LxmertConfig"),p6t.forEach(t),oho=r(mNe," (LXMERT model)"),mNe.forEach(t),rho=i(L),th=n(L,"LI",{});var cNe=s(th);bge=n(cNe,"STRONG",{});var _6t=s(bge);tho=r(_6t,"m2m_100"),_6t.forEach(t),aho=r(cNe," \u2014 "),kq=n(cNe,"A",{href:!0});var b6t=s(kq);nho=r(b6t,"M2M100Config"),b6t.forEach(t),sho=r(cNe," (M2M100 model)"),cNe.forEach(t),lho=i(L),ah=n(L,"LI",{});var fNe=s(ah);vge=n(fNe,"STRONG",{});var v6t=s(vge);iho=r(v6t,"marian"),v6t.forEach(t),dho=r(fNe," \u2014 "),Sq=n(fNe,"A",{href:!0});var F6t=s(Sq);mho=r(F6t,"MarianConfig"),F6t.forEach(t),cho=r(fNe," (Marian model)"),fNe.forEach(t),fho=i(L),nh=n(L,"LI",{});var gNe=s(nh);Fge=n(gNe,"STRONG",{});var T6t=s(Fge);gho=r(T6t,"markuplm"),T6t.forEach(t),hho=r(gNe," \u2014 "),Rq=n(gNe,"A",{href:!0});var M6t=s(Rq);uho=r(M6t,"MarkupLMConfig"),M6t.forEach(t),pho=r(gNe," (MarkupLM model)"),gNe.forEach(t),_ho=i(L),sh=n(L,"LI",{});var hNe=s(sh);Tge=n(hNe,"STRONG",{});var E6t=s(Tge);bho=r(E6t,"maskformer"),E6t.forEach(t),vho=r(hNe," \u2014 "),Pq=n(hNe,"A",{href:!0});var C6t=s(Pq);Fho=r(C6t,"MaskFormerConfig"),C6t.forEach(t),Tho=r(hNe," (MaskFormer model)"),hNe.forEach(t),Mho=i(L),lh=n(L,"LI",{});var uNe=s(lh);Mge=n(uNe,"STRONG",{});var w6t=s(Mge);Eho=r(w6t,"mbart"),w6t.forEach(t),Cho=r(uNe," \u2014 "),Bq=n(uNe,"A",{href:!0});var A6t=s(Bq);who=r(A6t,"MBartConfig"),A6t.forEach(t),Aho=r(uNe," (mBART model)"),uNe.forEach(t),Lho=i(L),ih=n(L,"LI",{});var pNe=s(ih);Ege=n(pNe,"STRONG",{});var L6t=s(Ege);yho=r(L6t,"mctct"),L6t.forEach(t),xho=r(pNe," \u2014 "),Iq=n(pNe,"A",{href:!0});var y6t=s(Iq);$ho=r(y6t,"MCTCTConfig"),y6t.forEach(t),kho=r(pNe," (M-CTC-T model)"),pNe.forEach(t),Sho=i(L),dh=n(L,"LI",{});var _Ne=s(dh);Cge=n(_Ne,"STRONG",{});var x6t=s(Cge);Rho=r(x6t,"megatron-bert"),x6t.forEach(t),Pho=r(_Ne," \u2014 "),Nq=n(_Ne,"A",{href:!0});var $6t=s(Nq);Bho=r($6t,"MegatronBertConfig"),$6t.forEach(t),Iho=r(_Ne," (Megatron-BERT model)"),_Ne.forEach(t),Nho=i(L),mh=n(L,"LI",{});var bNe=s(mh);wge=n(bNe,"STRONG",{});var k6t=s(wge);qho=r(k6t,"mobilebert"),k6t.forEach(t),jho=r(bNe," \u2014 "),qq=n(bNe,"A",{href:!0});var S6t=s(qq);Dho=r(S6t,"MobileBertConfig"),S6t.forEach(t),Gho=r(bNe," (MobileBERT model)"),bNe.forEach(t),Oho=i(L),ch=n(L,"LI",{});var vNe=s(ch);Age=n(vNe,"STRONG",{});var R6t=s(Age);Vho=r(R6t,"mobilevit"),R6t.forEach(t),Xho=r(vNe," \u2014 "),jq=n(vNe,"A",{href:!0});var P6t=s(jq);zho=r(P6t,"MobileViTConfig"),P6t.forEach(t),Qho=r(vNe," (MobileViT model)"),vNe.forEach(t),Who=i(L),fh=n(L,"LI",{});var FNe=s(fh);Lge=n(FNe,"STRONG",{});var B6t=s(Lge);Uho=r(B6t,"mpnet"),B6t.forEach(t),Hho=r(FNe," \u2014 "),Dq=n(FNe,"A",{href:!0});var I6t=s(Dq);Jho=r(I6t,"MPNetConfig"),I6t.forEach(t),Yho=r(FNe," (MPNet model)"),FNe.forEach(t),Zho=i(L),gh=n(L,"LI",{});var TNe=s(gh);yge=n(TNe,"STRONG",{});var N6t=s(yge);Kho=r(N6t,"mt5"),N6t.forEach(t),euo=r(TNe," \u2014 "),Gq=n(TNe,"A",{href:!0});var q6t=s(Gq);ouo=r(q6t,"MT5Config"),q6t.forEach(t),ruo=r(TNe," (MT5 model)"),TNe.forEach(t),tuo=i(L),hh=n(L,"LI",{});var MNe=s(hh);xge=n(MNe,"STRONG",{});var j6t=s(xge);auo=r(j6t,"mvp"),j6t.forEach(t),nuo=r(MNe," \u2014 "),Oq=n(MNe,"A",{href:!0});var D6t=s(Oq);suo=r(D6t,"MvpConfig"),D6t.forEach(t),luo=r(MNe," (MVP model)"),MNe.forEach(t),iuo=i(L),uh=n(L,"LI",{});var ENe=s(uh);$ge=n(ENe,"STRONG",{});var G6t=s($ge);duo=r(G6t,"nezha"),G6t.forEach(t),muo=r(ENe," \u2014 "),Vq=n(ENe,"A",{href:!0});var O6t=s(Vq);cuo=r(O6t,"NezhaConfig"),O6t.forEach(t),fuo=r(ENe," (Nezha model)"),ENe.forEach(t),guo=i(L),ph=n(L,"LI",{});var CNe=s(ph);kge=n(CNe,"STRONG",{});var V6t=s(kge);huo=r(V6t,"nystromformer"),V6t.forEach(t),uuo=r(CNe," \u2014 "),Xq=n(CNe,"A",{href:!0});var X6t=s(Xq);puo=r(X6t,"NystromformerConfig"),X6t.forEach(t),_uo=r(CNe," (Nystr\xF6mformer model)"),CNe.forEach(t),buo=i(L),_h=n(L,"LI",{});var wNe=s(_h);Sge=n(wNe,"STRONG",{});var z6t=s(Sge);vuo=r(z6t,"openai-gpt"),z6t.forEach(t),Fuo=r(wNe," \u2014 "),zq=n(wNe,"A",{href:!0});var Q6t=s(zq);Tuo=r(Q6t,"OpenAIGPTConfig"),Q6t.forEach(t),Muo=r(wNe," (OpenAI GPT model)"),wNe.forEach(t),Euo=i(L),bh=n(L,"LI",{});var ANe=s(bh);Rge=n(ANe,"STRONG",{});var W6t=s(Rge);Cuo=r(W6t,"opt"),W6t.forEach(t),wuo=r(ANe," \u2014 "),Qq=n(ANe,"A",{href:!0});var U6t=s(Qq);Auo=r(U6t,"OPTConfig"),U6t.forEach(t),Luo=r(ANe," (OPT model)"),ANe.forEach(t),yuo=i(L),vh=n(L,"LI",{});var LNe=s(vh);Pge=n(LNe,"STRONG",{});var H6t=s(Pge);xuo=r(H6t,"owlvit"),H6t.forEach(t),$uo=r(LNe," \u2014 "),Wq=n(LNe,"A",{href:!0});var J6t=s(Wq);kuo=r(J6t,"OwlViTConfig"),J6t.forEach(t),Suo=r(LNe," (OWL-ViT model)"),LNe.forEach(t),Ruo=i(L),Fh=n(L,"LI",{});var yNe=s(Fh);Bge=n(yNe,"STRONG",{});var Y6t=s(Bge);Puo=r(Y6t,"pegasus"),Y6t.forEach(t),Buo=r(yNe," \u2014 "),Uq=n(yNe,"A",{href:!0});var Z6t=s(Uq);Iuo=r(Z6t,"PegasusConfig"),Z6t.forEach(t),Nuo=r(yNe," (Pegasus model)"),yNe.forEach(t),quo=i(L),Th=n(L,"LI",{});var xNe=s(Th);Ige=n(xNe,"STRONG",{});var K6t=s(Ige);juo=r(K6t,"pegasus_x"),K6t.forEach(t),Duo=r(xNe," \u2014 "),Hq=n(xNe,"A",{href:!0});var e7t=s(Hq);Guo=r(e7t,"PegasusXConfig"),e7t.forEach(t),Ouo=r(xNe," (PEGASUS-X model)"),xNe.forEach(t),Vuo=i(L),Mh=n(L,"LI",{});var $Ne=s(Mh);Nge=n($Ne,"STRONG",{});var o7t=s(Nge);Xuo=r(o7t,"perceiver"),o7t.forEach(t),zuo=r($Ne," \u2014 "),Jq=n($Ne,"A",{href:!0});var r7t=s(Jq);Quo=r(r7t,"PerceiverConfig"),r7t.forEach(t),Wuo=r($Ne," (Perceiver model)"),$Ne.forEach(t),Uuo=i(L),Eh=n(L,"LI",{});var kNe=s(Eh);qge=n(kNe,"STRONG",{});var t7t=s(qge);Huo=r(t7t,"plbart"),t7t.forEach(t),Juo=r(kNe," \u2014 "),Yq=n(kNe,"A",{href:!0});var a7t=s(Yq);Yuo=r(a7t,"PLBartConfig"),a7t.forEach(t),Zuo=r(kNe," (PLBart model)"),kNe.forEach(t),Kuo=i(L),Ch=n(L,"LI",{});var SNe=s(Ch);jge=n(SNe,"STRONG",{});var n7t=s(jge);epo=r(n7t,"poolformer"),n7t.forEach(t),opo=r(SNe," \u2014 "),Zq=n(SNe,"A",{href:!0});var s7t=s(Zq);rpo=r(s7t,"PoolFormerConfig"),s7t.forEach(t),tpo=r(SNe," (PoolFormer model)"),SNe.forEach(t),apo=i(L),wh=n(L,"LI",{});var RNe=s(wh);Dge=n(RNe,"STRONG",{});var l7t=s(Dge);npo=r(l7t,"prophetnet"),l7t.forEach(t),spo=r(RNe," \u2014 "),Kq=n(RNe,"A",{href:!0});var i7t=s(Kq);lpo=r(i7t,"ProphetNetConfig"),i7t.forEach(t),ipo=r(RNe," (ProphetNet model)"),RNe.forEach(t),dpo=i(L),Ah=n(L,"LI",{});var PNe=s(Ah);Gge=n(PNe,"STRONG",{});var d7t=s(Gge);mpo=r(d7t,"qdqbert"),d7t.forEach(t),cpo=r(PNe," \u2014 "),ej=n(PNe,"A",{href:!0});var m7t=s(ej);fpo=r(m7t,"QDQBertConfig"),m7t.forEach(t),gpo=r(PNe," (QDQBert model)"),PNe.forEach(t),hpo=i(L),Lh=n(L,"LI",{});var BNe=s(Lh);Oge=n(BNe,"STRONG",{});var c7t=s(Oge);upo=r(c7t,"rag"),c7t.forEach(t),ppo=r(BNe," \u2014 "),oj=n(BNe,"A",{href:!0});var f7t=s(oj);_po=r(f7t,"RagConfig"),f7t.forEach(t),bpo=r(BNe," (RAG model)"),BNe.forEach(t),vpo=i(L),yh=n(L,"LI",{});var INe=s(yh);Vge=n(INe,"STRONG",{});var g7t=s(Vge);Fpo=r(g7t,"realm"),g7t.forEach(t),Tpo=r(INe," \u2014 "),rj=n(INe,"A",{href:!0});var h7t=s(rj);Mpo=r(h7t,"RealmConfig"),h7t.forEach(t),Epo=r(INe," (REALM model)"),INe.forEach(t),Cpo=i(L),xh=n(L,"LI",{});var NNe=s(xh);Xge=n(NNe,"STRONG",{});var u7t=s(Xge);wpo=r(u7t,"reformer"),u7t.forEach(t),Apo=r(NNe," \u2014 "),tj=n(NNe,"A",{href:!0});var p7t=s(tj);Lpo=r(p7t,"ReformerConfig"),p7t.forEach(t),ypo=r(NNe," (Reformer model)"),NNe.forEach(t),xpo=i(L),$h=n(L,"LI",{});var qNe=s($h);zge=n(qNe,"STRONG",{});var _7t=s(zge);$po=r(_7t,"regnet"),_7t.forEach(t),kpo=r(qNe," \u2014 "),aj=n(qNe,"A",{href:!0});var b7t=s(aj);Spo=r(b7t,"RegNetConfig"),b7t.forEach(t),Rpo=r(qNe," (RegNet model)"),qNe.forEach(t),Ppo=i(L),kh=n(L,"LI",{});var jNe=s(kh);Qge=n(jNe,"STRONG",{});var v7t=s(Qge);Bpo=r(v7t,"rembert"),v7t.forEach(t),Ipo=r(jNe," \u2014 "),nj=n(jNe,"A",{href:!0});var F7t=s(nj);Npo=r(F7t,"RemBertConfig"),F7t.forEach(t),qpo=r(jNe," (RemBERT model)"),jNe.forEach(t),jpo=i(L),Sh=n(L,"LI",{});var DNe=s(Sh);Wge=n(DNe,"STRONG",{});var T7t=s(Wge);Dpo=r(T7t,"resnet"),T7t.forEach(t),Gpo=r(DNe," \u2014 "),sj=n(DNe,"A",{href:!0});var M7t=s(sj);Opo=r(M7t,"ResNetConfig"),M7t.forEach(t),Vpo=r(DNe," (ResNet model)"),DNe.forEach(t),Xpo=i(L),Rh=n(L,"LI",{});var GNe=s(Rh);Uge=n(GNe,"STRONG",{});var E7t=s(Uge);zpo=r(E7t,"retribert"),E7t.forEach(t),Qpo=r(GNe," \u2014 "),lj=n(GNe,"A",{href:!0});var C7t=s(lj);Wpo=r(C7t,"RetriBertConfig"),C7t.forEach(t),Upo=r(GNe," (RetriBERT model)"),GNe.forEach(t),Hpo=i(L),Ph=n(L,"LI",{});var ONe=s(Ph);Hge=n(ONe,"STRONG",{});var w7t=s(Hge);Jpo=r(w7t,"roberta"),w7t.forEach(t),Ypo=r(ONe," \u2014 "),ij=n(ONe,"A",{href:!0});var A7t=s(ij);Zpo=r(A7t,"RobertaConfig"),A7t.forEach(t),Kpo=r(ONe," (RoBERTa model)"),ONe.forEach(t),e_o=i(L),Bh=n(L,"LI",{});var VNe=s(Bh);Jge=n(VNe,"STRONG",{});var L7t=s(Jge);o_o=r(L7t,"roformer"),L7t.forEach(t),r_o=r(VNe," \u2014 "),dj=n(VNe,"A",{href:!0});var y7t=s(dj);t_o=r(y7t,"RoFormerConfig"),y7t.forEach(t),a_o=r(VNe," (RoFormer model)"),VNe.forEach(t),n_o=i(L),Ih=n(L,"LI",{});var XNe=s(Ih);Yge=n(XNe,"STRONG",{});var x7t=s(Yge);s_o=r(x7t,"segformer"),x7t.forEach(t),l_o=r(XNe," \u2014 "),mj=n(XNe,"A",{href:!0});var $7t=s(mj);i_o=r($7t,"SegformerConfig"),$7t.forEach(t),d_o=r(XNe," (SegFormer model)"),XNe.forEach(t),m_o=i(L),Nh=n(L,"LI",{});var zNe=s(Nh);Zge=n(zNe,"STRONG",{});var k7t=s(Zge);c_o=r(k7t,"sew"),k7t.forEach(t),f_o=r(zNe," \u2014 "),cj=n(zNe,"A",{href:!0});var S7t=s(cj);g_o=r(S7t,"SEWConfig"),S7t.forEach(t),h_o=r(zNe," (SEW model)"),zNe.forEach(t),u_o=i(L),qh=n(L,"LI",{});var QNe=s(qh);Kge=n(QNe,"STRONG",{});var R7t=s(Kge);p_o=r(R7t,"sew-d"),R7t.forEach(t),__o=r(QNe," \u2014 "),fj=n(QNe,"A",{href:!0});var P7t=s(fj);b_o=r(P7t,"SEWDConfig"),P7t.forEach(t),v_o=r(QNe," (SEW-D model)"),QNe.forEach(t),F_o=i(L),jh=n(L,"LI",{});var WNe=s(jh);ehe=n(WNe,"STRONG",{});var B7t=s(ehe);T_o=r(B7t,"speech-encoder-decoder"),B7t.forEach(t),M_o=r(WNe," \u2014 "),gj=n(WNe,"A",{href:!0});var I7t=s(gj);E_o=r(I7t,"SpeechEncoderDecoderConfig"),I7t.forEach(t),C_o=r(WNe," (Speech Encoder decoder model)"),WNe.forEach(t),w_o=i(L),Dh=n(L,"LI",{});var UNe=s(Dh);ohe=n(UNe,"STRONG",{});var N7t=s(ohe);A_o=r(N7t,"speech_to_text"),N7t.forEach(t),L_o=r(UNe," \u2014 "),hj=n(UNe,"A",{href:!0});var q7t=s(hj);y_o=r(q7t,"Speech2TextConfig"),q7t.forEach(t),x_o=r(UNe," (Speech2Text model)"),UNe.forEach(t),$_o=i(L),Gh=n(L,"LI",{});var HNe=s(Gh);rhe=n(HNe,"STRONG",{});var j7t=s(rhe);k_o=r(j7t,"speech_to_text_2"),j7t.forEach(t),S_o=r(HNe," \u2014 "),uj=n(HNe,"A",{href:!0});var D7t=s(uj);R_o=r(D7t,"Speech2Text2Config"),D7t.forEach(t),P_o=r(HNe," (Speech2Text2 model)"),HNe.forEach(t),B_o=i(L),Oh=n(L,"LI",{});var JNe=s(Oh);the=n(JNe,"STRONG",{});var G7t=s(the);I_o=r(G7t,"splinter"),G7t.forEach(t),N_o=r(JNe," \u2014 "),pj=n(JNe,"A",{href:!0});var O7t=s(pj);q_o=r(O7t,"SplinterConfig"),O7t.forEach(t),j_o=r(JNe," (Splinter model)"),JNe.forEach(t),D_o=i(L),Vh=n(L,"LI",{});var YNe=s(Vh);ahe=n(YNe,"STRONG",{});var V7t=s(ahe);G_o=r(V7t,"squeezebert"),V7t.forEach(t),O_o=r(YNe," \u2014 "),_j=n(YNe,"A",{href:!0});var X7t=s(_j);V_o=r(X7t,"SqueezeBertConfig"),X7t.forEach(t),X_o=r(YNe," (SqueezeBERT model)"),YNe.forEach(t),z_o=i(L),Xh=n(L,"LI",{});var ZNe=s(Xh);nhe=n(ZNe,"STRONG",{});var z7t=s(nhe);Q_o=r(z7t,"swin"),z7t.forEach(t),W_o=r(ZNe," \u2014 "),bj=n(ZNe,"A",{href:!0});var Q7t=s(bj);U_o=r(Q7t,"SwinConfig"),Q7t.forEach(t),H_o=r(ZNe," (Swin Transformer model)"),ZNe.forEach(t),J_o=i(L),zh=n(L,"LI",{});var KNe=s(zh);she=n(KNe,"STRONG",{});var W7t=s(she);Y_o=r(W7t,"swinv2"),W7t.forEach(t),Z_o=r(KNe," \u2014 "),vj=n(KNe,"A",{href:!0});var U7t=s(vj);K_o=r(U7t,"Swinv2Config"),U7t.forEach(t),e1o=r(KNe," (Swin Transformer V2 model)"),KNe.forEach(t),o1o=i(L),Qh=n(L,"LI",{});var eqe=s(Qh);lhe=n(eqe,"STRONG",{});var H7t=s(lhe);r1o=r(H7t,"t5"),H7t.forEach(t),t1o=r(eqe," \u2014 "),Fj=n(eqe,"A",{href:!0});var J7t=s(Fj);a1o=r(J7t,"T5Config"),J7t.forEach(t),n1o=r(eqe," (T5 model)"),eqe.forEach(t),s1o=i(L),Wh=n(L,"LI",{});var oqe=s(Wh);ihe=n(oqe,"STRONG",{});var Y7t=s(ihe);l1o=r(Y7t,"tapas"),Y7t.forEach(t),i1o=r(oqe," \u2014 "),Tj=n(oqe,"A",{href:!0});var Z7t=s(Tj);d1o=r(Z7t,"TapasConfig"),Z7t.forEach(t),m1o=r(oqe," (TAPAS model)"),oqe.forEach(t),c1o=i(L),Uh=n(L,"LI",{});var rqe=s(Uh);dhe=n(rqe,"STRONG",{});var K7t=s(dhe);f1o=r(K7t,"time_series_transformer"),K7t.forEach(t),g1o=r(rqe," \u2014 "),Mj=n(rqe,"A",{href:!0});var e8t=s(Mj);h1o=r(e8t,"TimeSeriesTransformerConfig"),e8t.forEach(t),u1o=r(rqe," (Time Series Transformer model)"),rqe.forEach(t),p1o=i(L),Hh=n(L,"LI",{});var tqe=s(Hh);mhe=n(tqe,"STRONG",{});var o8t=s(mhe);_1o=r(o8t,"trajectory_transformer"),o8t.forEach(t),b1o=r(tqe," \u2014 "),Ej=n(tqe,"A",{href:!0});var r8t=s(Ej);v1o=r(r8t,"TrajectoryTransformerConfig"),r8t.forEach(t),F1o=r(tqe," (Trajectory Transformer model)"),tqe.forEach(t),T1o=i(L),Jh=n(L,"LI",{});var aqe=s(Jh);che=n(aqe,"STRONG",{});var t8t=s(che);M1o=r(t8t,"transfo-xl"),t8t.forEach(t),E1o=r(aqe," \u2014 "),Cj=n(aqe,"A",{href:!0});var a8t=s(Cj);C1o=r(a8t,"TransfoXLConfig"),a8t.forEach(t),w1o=r(aqe," (Transformer-XL model)"),aqe.forEach(t),A1o=i(L),Yh=n(L,"LI",{});var nqe=s(Yh);fhe=n(nqe,"STRONG",{});var n8t=s(fhe);L1o=r(n8t,"trocr"),n8t.forEach(t),y1o=r(nqe," \u2014 "),wj=n(nqe,"A",{href:!0});var s8t=s(wj);x1o=r(s8t,"TrOCRConfig"),s8t.forEach(t),$1o=r(nqe," (TrOCR model)"),nqe.forEach(t),k1o=i(L),Zh=n(L,"LI",{});var sqe=s(Zh);ghe=n(sqe,"STRONG",{});var l8t=s(ghe);S1o=r(l8t,"unispeech"),l8t.forEach(t),R1o=r(sqe," \u2014 "),Aj=n(sqe,"A",{href:!0});var i8t=s(Aj);P1o=r(i8t,"UniSpeechConfig"),i8t.forEach(t),B1o=r(sqe," (UniSpeech model)"),sqe.forEach(t),I1o=i(L),Kh=n(L,"LI",{});var lqe=s(Kh);hhe=n(lqe,"STRONG",{});var d8t=s(hhe);N1o=r(d8t,"unispeech-sat"),d8t.forEach(t),q1o=r(lqe," \u2014 "),Lj=n(lqe,"A",{href:!0});var m8t=s(Lj);j1o=r(m8t,"UniSpeechSatConfig"),m8t.forEach(t),D1o=r(lqe," (UniSpeechSat model)"),lqe.forEach(t),G1o=i(L),eu=n(L,"LI",{});var iqe=s(eu);uhe=n(iqe,"STRONG",{});var c8t=s(uhe);O1o=r(c8t,"van"),c8t.forEach(t),V1o=r(iqe," \u2014 "),yj=n(iqe,"A",{href:!0});var f8t=s(yj);X1o=r(f8t,"VanConfig"),f8t.forEach(t),z1o=r(iqe," (VAN model)"),iqe.forEach(t),Q1o=i(L),ou=n(L,"LI",{});var dqe=s(ou);phe=n(dqe,"STRONG",{});var g8t=s(phe);W1o=r(g8t,"videomae"),g8t.forEach(t),U1o=r(dqe," \u2014 "),xj=n(dqe,"A",{href:!0});var h8t=s(xj);H1o=r(h8t,"VideoMAEConfig"),h8t.forEach(t),J1o=r(dqe," (VideoMAE model)"),dqe.forEach(t),Y1o=i(L),ru=n(L,"LI",{});var mqe=s(ru);_he=n(mqe,"STRONG",{});var u8t=s(_he);Z1o=r(u8t,"vilt"),u8t.forEach(t),K1o=r(mqe," \u2014 "),$j=n(mqe,"A",{href:!0});var p8t=s($j);e2o=r(p8t,"ViltConfig"),p8t.forEach(t),o2o=r(mqe," (ViLT model)"),mqe.forEach(t),r2o=i(L),tu=n(L,"LI",{});var cqe=s(tu);bhe=n(cqe,"STRONG",{});var _8t=s(bhe);t2o=r(_8t,"vision-encoder-decoder"),_8t.forEach(t),a2o=r(cqe," \u2014 "),kj=n(cqe,"A",{href:!0});var b8t=s(kj);n2o=r(b8t,"VisionEncoderDecoderConfig"),b8t.forEach(t),s2o=r(cqe," (Vision Encoder decoder model)"),cqe.forEach(t),l2o=i(L),au=n(L,"LI",{});var fqe=s(au);vhe=n(fqe,"STRONG",{});var v8t=s(vhe);i2o=r(v8t,"vision-text-dual-encoder"),v8t.forEach(t),d2o=r(fqe," \u2014 "),Sj=n(fqe,"A",{href:!0});var F8t=s(Sj);m2o=r(F8t,"VisionTextDualEncoderConfig"),F8t.forEach(t),c2o=r(fqe," (VisionTextDualEncoder model)"),fqe.forEach(t),f2o=i(L),nu=n(L,"LI",{});var gqe=s(nu);Fhe=n(gqe,"STRONG",{});var T8t=s(Fhe);g2o=r(T8t,"visual_bert"),T8t.forEach(t),h2o=r(gqe," \u2014 "),Rj=n(gqe,"A",{href:!0});var M8t=s(Rj);u2o=r(M8t,"VisualBertConfig"),M8t.forEach(t),p2o=r(gqe," (VisualBERT model)"),gqe.forEach(t),_2o=i(L),su=n(L,"LI",{});var hqe=s(su);The=n(hqe,"STRONG",{});var E8t=s(The);b2o=r(E8t,"vit"),E8t.forEach(t),v2o=r(hqe," \u2014 "),Pj=n(hqe,"A",{href:!0});var C8t=s(Pj);F2o=r(C8t,"ViTConfig"),C8t.forEach(t),T2o=r(hqe," (ViT model)"),hqe.forEach(t),M2o=i(L),lu=n(L,"LI",{});var uqe=s(lu);Mhe=n(uqe,"STRONG",{});var w8t=s(Mhe);E2o=r(w8t,"vit_mae"),w8t.forEach(t),C2o=r(uqe," \u2014 "),Bj=n(uqe,"A",{href:!0});var A8t=s(Bj);w2o=r(A8t,"ViTMAEConfig"),A8t.forEach(t),A2o=r(uqe," (ViTMAE model)"),uqe.forEach(t),L2o=i(L),iu=n(L,"LI",{});var pqe=s(iu);Ehe=n(pqe,"STRONG",{});var L8t=s(Ehe);y2o=r(L8t,"vit_msn"),L8t.forEach(t),x2o=r(pqe," \u2014 "),Ij=n(pqe,"A",{href:!0});var y8t=s(Ij);$2o=r(y8t,"ViTMSNConfig"),y8t.forEach(t),k2o=r(pqe," (ViTMSN model)"),pqe.forEach(t),S2o=i(L),du=n(L,"LI",{});var _qe=s(du);Che=n(_qe,"STRONG",{});var x8t=s(Che);R2o=r(x8t,"wav2vec2"),x8t.forEach(t),P2o=r(_qe," \u2014 "),Nj=n(_qe,"A",{href:!0});var $8t=s(Nj);B2o=r($8t,"Wav2Vec2Config"),$8t.forEach(t),I2o=r(_qe," (Wav2Vec2 model)"),_qe.forEach(t),N2o=i(L),mu=n(L,"LI",{});var bqe=s(mu);whe=n(bqe,"STRONG",{});var k8t=s(whe);q2o=r(k8t,"wav2vec2-conformer"),k8t.forEach(t),j2o=r(bqe," \u2014 "),qj=n(bqe,"A",{href:!0});var S8t=s(qj);D2o=r(S8t,"Wav2Vec2ConformerConfig"),S8t.forEach(t),G2o=r(bqe," (Wav2Vec2-Conformer model)"),bqe.forEach(t),O2o=i(L),cu=n(L,"LI",{});var vqe=s(cu);Ahe=n(vqe,"STRONG",{});var R8t=s(Ahe);V2o=r(R8t,"wavlm"),R8t.forEach(t),X2o=r(vqe," \u2014 "),jj=n(vqe,"A",{href:!0});var P8t=s(jj);z2o=r(P8t,"WavLMConfig"),P8t.forEach(t),Q2o=r(vqe," (WavLM model)"),vqe.forEach(t),W2o=i(L),fu=n(L,"LI",{});var Fqe=s(fu);Lhe=n(Fqe,"STRONG",{});var B8t=s(Lhe);U2o=r(B8t,"whisper"),B8t.forEach(t),H2o=r(Fqe," \u2014 "),Dj=n(Fqe,"A",{href:!0});var I8t=s(Dj);J2o=r(I8t,"WhisperConfig"),I8t.forEach(t),Y2o=r(Fqe," (Whisper model)"),Fqe.forEach(t),Z2o=i(L),gu=n(L,"LI",{});var Tqe=s(gu);yhe=n(Tqe,"STRONG",{});var N8t=s(yhe);K2o=r(N8t,"xclip"),N8t.forEach(t),ebo=r(Tqe," \u2014 "),Gj=n(Tqe,"A",{href:!0});var q8t=s(Gj);obo=r(q8t,"XCLIPConfig"),q8t.forEach(t),rbo=r(Tqe," (X-CLIP model)"),Tqe.forEach(t),tbo=i(L),hu=n(L,"LI",{});var Mqe=s(hu);xhe=n(Mqe,"STRONG",{});var j8t=s(xhe);abo=r(j8t,"xglm"),j8t.forEach(t),nbo=r(Mqe," \u2014 "),Oj=n(Mqe,"A",{href:!0});var D8t=s(Oj);sbo=r(D8t,"XGLMConfig"),D8t.forEach(t),lbo=r(Mqe," (XGLM model)"),Mqe.forEach(t),ibo=i(L),uu=n(L,"LI",{});var Eqe=s(uu);$he=n(Eqe,"STRONG",{});var G8t=s($he);dbo=r(G8t,"xlm"),G8t.forEach(t),mbo=r(Eqe," \u2014 "),Vj=n(Eqe,"A",{href:!0});var O8t=s(Vj);cbo=r(O8t,"XLMConfig"),O8t.forEach(t),fbo=r(Eqe," (XLM model)"),Eqe.forEach(t),gbo=i(L),pu=n(L,"LI",{});var Cqe=s(pu);khe=n(Cqe,"STRONG",{});var V8t=s(khe);hbo=r(V8t,"xlm-prophetnet"),V8t.forEach(t),ubo=r(Cqe," \u2014 "),Xj=n(Cqe,"A",{href:!0});var X8t=s(Xj);pbo=r(X8t,"XLMProphetNetConfig"),X8t.forEach(t),_bo=r(Cqe," (XLM-ProphetNet model)"),Cqe.forEach(t),bbo=i(L),_u=n(L,"LI",{});var wqe=s(_u);She=n(wqe,"STRONG",{});var z8t=s(She);vbo=r(z8t,"xlm-roberta"),z8t.forEach(t),Fbo=r(wqe," \u2014 "),zj=n(wqe,"A",{href:!0});var Q8t=s(zj);Tbo=r(Q8t,"XLMRobertaConfig"),Q8t.forEach(t),Mbo=r(wqe," (XLM-RoBERTa model)"),wqe.forEach(t),Ebo=i(L),bu=n(L,"LI",{});var Aqe=s(bu);Rhe=n(Aqe,"STRONG",{});var W8t=s(Rhe);Cbo=r(W8t,"xlm-roberta-xl"),W8t.forEach(t),wbo=r(Aqe," \u2014 "),Qj=n(Aqe,"A",{href:!0});var U8t=s(Qj);Abo=r(U8t,"XLMRobertaXLConfig"),U8t.forEach(t),Lbo=r(Aqe," (XLM-RoBERTa-XL model)"),Aqe.forEach(t),ybo=i(L),vu=n(L,"LI",{});var Lqe=s(vu);Phe=n(Lqe,"STRONG",{});var H8t=s(Phe);xbo=r(H8t,"xlnet"),H8t.forEach(t),$bo=r(Lqe," \u2014 "),Wj=n(Lqe,"A",{href:!0});var J8t=s(Wj);kbo=r(J8t,"XLNetConfig"),J8t.forEach(t),Sbo=r(Lqe," (XLNet model)"),Lqe.forEach(t),Rbo=i(L),Fu=n(L,"LI",{});var yqe=s(Fu);Bhe=n(yqe,"STRONG",{});var Y8t=s(Bhe);Pbo=r(Y8t,"yolos"),Y8t.forEach(t),Bbo=r(yqe," \u2014 "),Uj=n(yqe,"A",{href:!0});var Z8t=s(Uj);Ibo=r(Z8t,"YolosConfig"),Z8t.forEach(t),Nbo=r(yqe," (YOLOS model)"),yqe.forEach(t),qbo=i(L),Tu=n(L,"LI",{});var xqe=s(Tu);Ihe=n(xqe,"STRONG",{});var K8t=s(Ihe);jbo=r(K8t,"yoso"),K8t.forEach(t),Dbo=r(xqe," \u2014 "),Hj=n(xqe,"A",{href:!0});var eLt=s(Hj);Gbo=r(eLt,"YosoConfig"),eLt.forEach(t),Obo=r(xqe," (YOSO model)"),xqe.forEach(t),L.forEach(t),Vbo=i(vt),T(Mu.$$.fragment,vt),vt.forEach(t),Xbo=i(bt),Eu=n(bt,"DIV",{class:!0});var Ano=s(Eu);T(f$.$$.fragment,Ano),zbo=i(Ano),Nhe=n(Ano,"P",{});var oLt=s(Nhe);Qbo=r(oLt,"Register a new configuration for this class."),oLt.forEach(t),Ano.forEach(t),bt.forEach(t),uto=i(c),Ad=n(c,"H2",{class:!0});var Lno=s(Ad);Cu=n(Lno,"A",{id:!0,class:!0,href:!0});var rLt=s(Cu);qhe=n(rLt,"SPAN",{});var tLt=s(qhe);T(g$.$$.fragment,tLt),tLt.forEach(t),rLt.forEach(t),Wbo=i(Lno),jhe=n(Lno,"SPAN",{});var aLt=s(jhe);Ubo=r(aLt,"AutoTokenizer"),aLt.forEach(t),Lno.forEach(t),pto=i(c),Ro=n(c,"DIV",{class:!0});var Rl=s(Ro);T(h$.$$.fragment,Rl),Hbo=i(Rl),u$=n(Rl,"P",{});var yno=s(u$);Jbo=r(yno,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),Jj=n(yno,"A",{href:!0});var nLt=s(Jj);Ybo=r(nLt,"AutoTokenizer.from_pretrained()"),nLt.forEach(t),Zbo=r(yno," class method."),yno.forEach(t),Kbo=i(Rl),p$=n(Rl,"P",{});var xno=s(p$);evo=r(xno,"This class cannot be instantiated directly using "),Dhe=n(xno,"CODE",{});var sLt=s(Dhe);ovo=r(sLt,"__init__()"),sLt.forEach(t),rvo=r(xno," (throws an error)."),xno.forEach(t),tvo=i(Rl),jr=n(Rl,"DIV",{class:!0});var Pl=s(jr);T(_$.$$.fragment,Pl),avo=i(Pl),Ghe=n(Pl,"P",{});var lLt=s(Ghe);nvo=r(lLt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),lLt.forEach(t),svo=i(Pl),rn=n(Pl,"P",{});var Wy=s(rn);lvo=r(Wy,"The tokenizer class to instantiate is selected based on the "),Ohe=n(Wy,"CODE",{});var iLt=s(Ohe);ivo=r(iLt,"model_type"),iLt.forEach(t),dvo=r(Wy,` property of the config object (either
passed as an argument or loaded from `),Vhe=n(Wy,"CODE",{});var dLt=s(Vhe);mvo=r(dLt,"pretrained_model_name_or_path"),dLt.forEach(t),cvo=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xhe=n(Wy,"CODE",{});var mLt=s(Xhe);fvo=r(mLt,"pretrained_model_name_or_path"),mLt.forEach(t),gvo=r(Wy,":"),Wy.forEach(t),hvo=i(Pl),k=n(Pl,"UL",{});var S=s(k);us=n(S,"LI",{});var KB=s(us);zhe=n(KB,"STRONG",{});var cLt=s(zhe);uvo=r(cLt,"albert"),cLt.forEach(t),pvo=r(KB," \u2014 "),Yj=n(KB,"A",{href:!0});var fLt=s(Yj);_vo=r(fLt,"AlbertTokenizer"),fLt.forEach(t),bvo=r(KB," or "),Zj=n(KB,"A",{href:!0});var gLt=s(Zj);vvo=r(gLt,"AlbertTokenizerFast"),gLt.forEach(t),Fvo=r(KB," (ALBERT model)"),KB.forEach(t),Tvo=i(S),ps=n(S,"LI",{});var eI=s(ps);Qhe=n(eI,"STRONG",{});var hLt=s(Qhe);Mvo=r(hLt,"bart"),hLt.forEach(t),Evo=r(eI," \u2014 "),Kj=n(eI,"A",{href:!0});var uLt=s(Kj);Cvo=r(uLt,"BartTokenizer"),uLt.forEach(t),wvo=r(eI," or "),eD=n(eI,"A",{href:!0});var pLt=s(eD);Avo=r(pLt,"BartTokenizerFast"),pLt.forEach(t),Lvo=r(eI," (BART model)"),eI.forEach(t),yvo=i(S),_s=n(S,"LI",{});var oI=s(_s);Whe=n(oI,"STRONG",{});var _Lt=s(Whe);xvo=r(_Lt,"barthez"),_Lt.forEach(t),$vo=r(oI," \u2014 "),oD=n(oI,"A",{href:!0});var bLt=s(oD);kvo=r(bLt,"BarthezTokenizer"),bLt.forEach(t),Svo=r(oI," or "),rD=n(oI,"A",{href:!0});var vLt=s(rD);Rvo=r(vLt,"BarthezTokenizerFast"),vLt.forEach(t),Pvo=r(oI," (BARThez model)"),oI.forEach(t),Bvo=i(S),wu=n(S,"LI",{});var $qe=s(wu);Uhe=n($qe,"STRONG",{});var FLt=s(Uhe);Ivo=r(FLt,"bartpho"),FLt.forEach(t),Nvo=r($qe," \u2014 "),tD=n($qe,"A",{href:!0});var TLt=s(tD);qvo=r(TLt,"BartphoTokenizer"),TLt.forEach(t),jvo=r($qe," (BARTpho model)"),$qe.forEach(t),Dvo=i(S),bs=n(S,"LI",{});var rI=s(bs);Hhe=n(rI,"STRONG",{});var MLt=s(Hhe);Gvo=r(MLt,"bert"),MLt.forEach(t),Ovo=r(rI," \u2014 "),aD=n(rI,"A",{href:!0});var ELt=s(aD);Vvo=r(ELt,"BertTokenizer"),ELt.forEach(t),Xvo=r(rI," or "),nD=n(rI,"A",{href:!0});var CLt=s(nD);zvo=r(CLt,"BertTokenizerFast"),CLt.forEach(t),Qvo=r(rI," (BERT model)"),rI.forEach(t),Wvo=i(S),Au=n(S,"LI",{});var kqe=s(Au);Jhe=n(kqe,"STRONG",{});var wLt=s(Jhe);Uvo=r(wLt,"bert-generation"),wLt.forEach(t),Hvo=r(kqe," \u2014 "),sD=n(kqe,"A",{href:!0});var ALt=s(sD);Jvo=r(ALt,"BertGenerationTokenizer"),ALt.forEach(t),Yvo=r(kqe," (Bert Generation model)"),kqe.forEach(t),Zvo=i(S),Lu=n(S,"LI",{});var Sqe=s(Lu);Yhe=n(Sqe,"STRONG",{});var LLt=s(Yhe);Kvo=r(LLt,"bert-japanese"),LLt.forEach(t),eFo=r(Sqe," \u2014 "),lD=n(Sqe,"A",{href:!0});var yLt=s(lD);oFo=r(yLt,"BertJapaneseTokenizer"),yLt.forEach(t),rFo=r(Sqe," (BertJapanese model)"),Sqe.forEach(t),tFo=i(S),yu=n(S,"LI",{});var Rqe=s(yu);Zhe=n(Rqe,"STRONG",{});var xLt=s(Zhe);aFo=r(xLt,"bertweet"),xLt.forEach(t),nFo=r(Rqe," \u2014 "),iD=n(Rqe,"A",{href:!0});var $Lt=s(iD);sFo=r($Lt,"BertweetTokenizer"),$Lt.forEach(t),lFo=r(Rqe," (BERTweet model)"),Rqe.forEach(t),iFo=i(S),vs=n(S,"LI",{});var tI=s(vs);Khe=n(tI,"STRONG",{});var kLt=s(Khe);dFo=r(kLt,"big_bird"),kLt.forEach(t),mFo=r(tI," \u2014 "),dD=n(tI,"A",{href:!0});var SLt=s(dD);cFo=r(SLt,"BigBirdTokenizer"),SLt.forEach(t),fFo=r(tI," or "),mD=n(tI,"A",{href:!0});var RLt=s(mD);gFo=r(RLt,"BigBirdTokenizerFast"),RLt.forEach(t),hFo=r(tI," (BigBird model)"),tI.forEach(t),uFo=i(S),Fs=n(S,"LI",{});var aI=s(Fs);eue=n(aI,"STRONG",{});var PLt=s(eue);pFo=r(PLt,"bigbird_pegasus"),PLt.forEach(t),_Fo=r(aI," \u2014 "),cD=n(aI,"A",{href:!0});var BLt=s(cD);bFo=r(BLt,"PegasusTokenizer"),BLt.forEach(t),vFo=r(aI," or "),fD=n(aI,"A",{href:!0});var ILt=s(fD);FFo=r(ILt,"PegasusTokenizerFast"),ILt.forEach(t),TFo=r(aI," (BigBird-Pegasus model)"),aI.forEach(t),MFo=i(S),Ts=n(S,"LI",{});var nI=s(Ts);oue=n(nI,"STRONG",{});var NLt=s(oue);EFo=r(NLt,"blenderbot"),NLt.forEach(t),CFo=r(nI," \u2014 "),gD=n(nI,"A",{href:!0});var qLt=s(gD);wFo=r(qLt,"BlenderbotTokenizer"),qLt.forEach(t),AFo=r(nI," or "),hD=n(nI,"A",{href:!0});var jLt=s(hD);LFo=r(jLt,"BlenderbotTokenizerFast"),jLt.forEach(t),yFo=r(nI," (Blenderbot model)"),nI.forEach(t),xFo=i(S),xu=n(S,"LI",{});var Pqe=s(xu);rue=n(Pqe,"STRONG",{});var DLt=s(rue);$Fo=r(DLt,"blenderbot-small"),DLt.forEach(t),kFo=r(Pqe," \u2014 "),uD=n(Pqe,"A",{href:!0});var GLt=s(uD);SFo=r(GLt,"BlenderbotSmallTokenizer"),GLt.forEach(t),RFo=r(Pqe," (BlenderbotSmall model)"),Pqe.forEach(t),PFo=i(S),$u=n(S,"LI",{});var Bqe=s($u);tue=n(Bqe,"STRONG",{});var OLt=s(tue);BFo=r(OLt,"bloom"),OLt.forEach(t),IFo=r(Bqe," \u2014 "),pD=n(Bqe,"A",{href:!0});var VLt=s(pD);NFo=r(VLt,"BloomTokenizerFast"),VLt.forEach(t),qFo=r(Bqe," (BLOOM model)"),Bqe.forEach(t),jFo=i(S),ku=n(S,"LI",{});var Iqe=s(ku);aue=n(Iqe,"STRONG",{});var XLt=s(aue);DFo=r(XLt,"byt5"),XLt.forEach(t),GFo=r(Iqe," \u2014 "),_D=n(Iqe,"A",{href:!0});var zLt=s(_D);OFo=r(zLt,"ByT5Tokenizer"),zLt.forEach(t),VFo=r(Iqe," (ByT5 model)"),Iqe.forEach(t),XFo=i(S),Ms=n(S,"LI",{});var sI=s(Ms);nue=n(sI,"STRONG",{});var QLt=s(nue);zFo=r(QLt,"camembert"),QLt.forEach(t),QFo=r(sI," \u2014 "),bD=n(sI,"A",{href:!0});var WLt=s(bD);WFo=r(WLt,"CamembertTokenizer"),WLt.forEach(t),UFo=r(sI," or "),vD=n(sI,"A",{href:!0});var ULt=s(vD);HFo=r(ULt,"CamembertTokenizerFast"),ULt.forEach(t),JFo=r(sI," (CamemBERT model)"),sI.forEach(t),YFo=i(S),Su=n(S,"LI",{});var Nqe=s(Su);sue=n(Nqe,"STRONG",{});var HLt=s(sue);ZFo=r(HLt,"canine"),HLt.forEach(t),KFo=r(Nqe," \u2014 "),FD=n(Nqe,"A",{href:!0});var JLt=s(FD);eTo=r(JLt,"CanineTokenizer"),JLt.forEach(t),oTo=r(Nqe," (CANINE model)"),Nqe.forEach(t),rTo=i(S),Es=n(S,"LI",{});var lI=s(Es);lue=n(lI,"STRONG",{});var YLt=s(lue);tTo=r(YLt,"clip"),YLt.forEach(t),aTo=r(lI," \u2014 "),TD=n(lI,"A",{href:!0});var ZLt=s(TD);nTo=r(ZLt,"CLIPTokenizer"),ZLt.forEach(t),sTo=r(lI," or "),MD=n(lI,"A",{href:!0});var KLt=s(MD);lTo=r(KLt,"CLIPTokenizerFast"),KLt.forEach(t),iTo=r(lI," (CLIP model)"),lI.forEach(t),dTo=i(S),Cs=n(S,"LI",{});var iI=s(Cs);iue=n(iI,"STRONG",{});var eyt=s(iue);mTo=r(eyt,"codegen"),eyt.forEach(t),cTo=r(iI," \u2014 "),ED=n(iI,"A",{href:!0});var oyt=s(ED);fTo=r(oyt,"CodeGenTokenizer"),oyt.forEach(t),gTo=r(iI," or "),CD=n(iI,"A",{href:!0});var ryt=s(CD);hTo=r(ryt,"CodeGenTokenizerFast"),ryt.forEach(t),uTo=r(iI," (CodeGen model)"),iI.forEach(t),pTo=i(S),ws=n(S,"LI",{});var dI=s(ws);due=n(dI,"STRONG",{});var tyt=s(due);_To=r(tyt,"convbert"),tyt.forEach(t),bTo=r(dI," \u2014 "),wD=n(dI,"A",{href:!0});var ayt=s(wD);vTo=r(ayt,"ConvBertTokenizer"),ayt.forEach(t),FTo=r(dI," or "),AD=n(dI,"A",{href:!0});var nyt=s(AD);TTo=r(nyt,"ConvBertTokenizerFast"),nyt.forEach(t),MTo=r(dI," (ConvBERT model)"),dI.forEach(t),ETo=i(S),As=n(S,"LI",{});var mI=s(As);mue=n(mI,"STRONG",{});var syt=s(mue);CTo=r(syt,"cpm"),syt.forEach(t),wTo=r(mI," \u2014 "),LD=n(mI,"A",{href:!0});var lyt=s(LD);ATo=r(lyt,"CpmTokenizer"),lyt.forEach(t),LTo=r(mI," or "),yD=n(mI,"A",{href:!0});var iyt=s(yD);yTo=r(iyt,"CpmTokenizerFast"),iyt.forEach(t),xTo=r(mI," (CPM model)"),mI.forEach(t),$To=i(S),Ru=n(S,"LI",{});var qqe=s(Ru);cue=n(qqe,"STRONG",{});var dyt=s(cue);kTo=r(dyt,"ctrl"),dyt.forEach(t),STo=r(qqe," \u2014 "),xD=n(qqe,"A",{href:!0});var myt=s(xD);RTo=r(myt,"CTRLTokenizer"),myt.forEach(t),PTo=r(qqe," (CTRL model)"),qqe.forEach(t),BTo=i(S),Ls=n(S,"LI",{});var cI=s(Ls);fue=n(cI,"STRONG",{});var cyt=s(fue);ITo=r(cyt,"data2vec-text"),cyt.forEach(t),NTo=r(cI," \u2014 "),$D=n(cI,"A",{href:!0});var fyt=s($D);qTo=r(fyt,"RobertaTokenizer"),fyt.forEach(t),jTo=r(cI," or "),kD=n(cI,"A",{href:!0});var gyt=s(kD);DTo=r(gyt,"RobertaTokenizerFast"),gyt.forEach(t),GTo=r(cI," (Data2VecText model)"),cI.forEach(t),OTo=i(S),ys=n(S,"LI",{});var fI=s(ys);gue=n(fI,"STRONG",{});var hyt=s(gue);VTo=r(hyt,"deberta"),hyt.forEach(t),XTo=r(fI," \u2014 "),SD=n(fI,"A",{href:!0});var uyt=s(SD);zTo=r(uyt,"DebertaTokenizer"),uyt.forEach(t),QTo=r(fI," or "),RD=n(fI,"A",{href:!0});var pyt=s(RD);WTo=r(pyt,"DebertaTokenizerFast"),pyt.forEach(t),UTo=r(fI," (DeBERTa model)"),fI.forEach(t),HTo=i(S),xs=n(S,"LI",{});var gI=s(xs);hue=n(gI,"STRONG",{});var _yt=s(hue);JTo=r(_yt,"deberta-v2"),_yt.forEach(t),YTo=r(gI," \u2014 "),PD=n(gI,"A",{href:!0});var byt=s(PD);ZTo=r(byt,"DebertaV2Tokenizer"),byt.forEach(t),KTo=r(gI," or "),BD=n(gI,"A",{href:!0});var vyt=s(BD);eMo=r(vyt,"DebertaV2TokenizerFast"),vyt.forEach(t),oMo=r(gI," (DeBERTa-v2 model)"),gI.forEach(t),rMo=i(S),$s=n(S,"LI",{});var hI=s($s);uue=n(hI,"STRONG",{});var Fyt=s(uue);tMo=r(Fyt,"distilbert"),Fyt.forEach(t),aMo=r(hI," \u2014 "),ID=n(hI,"A",{href:!0});var Tyt=s(ID);nMo=r(Tyt,"DistilBertTokenizer"),Tyt.forEach(t),sMo=r(hI," or "),ND=n(hI,"A",{href:!0});var Myt=s(ND);lMo=r(Myt,"DistilBertTokenizerFast"),Myt.forEach(t),iMo=r(hI," (DistilBERT model)"),hI.forEach(t),dMo=i(S),ks=n(S,"LI",{});var uI=s(ks);pue=n(uI,"STRONG",{});var Eyt=s(pue);mMo=r(Eyt,"dpr"),Eyt.forEach(t),cMo=r(uI," \u2014 "),qD=n(uI,"A",{href:!0});var Cyt=s(qD);fMo=r(Cyt,"DPRQuestionEncoderTokenizer"),Cyt.forEach(t),gMo=r(uI," or "),jD=n(uI,"A",{href:!0});var wyt=s(jD);hMo=r(wyt,"DPRQuestionEncoderTokenizerFast"),wyt.forEach(t),uMo=r(uI," (DPR model)"),uI.forEach(t),pMo=i(S),Ss=n(S,"LI",{});var pI=s(Ss);_ue=n(pI,"STRONG",{});var Ayt=s(_ue);_Mo=r(Ayt,"electra"),Ayt.forEach(t),bMo=r(pI," \u2014 "),DD=n(pI,"A",{href:!0});var Lyt=s(DD);vMo=r(Lyt,"ElectraTokenizer"),Lyt.forEach(t),FMo=r(pI," or "),GD=n(pI,"A",{href:!0});var yyt=s(GD);TMo=r(yyt,"ElectraTokenizerFast"),yyt.forEach(t),MMo=r(pI," (ELECTRA model)"),pI.forEach(t),EMo=i(S),Rs=n(S,"LI",{});var _I=s(Rs);bue=n(_I,"STRONG",{});var xyt=s(bue);CMo=r(xyt,"ernie"),xyt.forEach(t),wMo=r(_I," \u2014 "),OD=n(_I,"A",{href:!0});var $yt=s(OD);AMo=r($yt,"BertTokenizer"),$yt.forEach(t),LMo=r(_I," or "),VD=n(_I,"A",{href:!0});var kyt=s(VD);yMo=r(kyt,"BertTokenizerFast"),kyt.forEach(t),xMo=r(_I," (ERNIE model)"),_I.forEach(t),$Mo=i(S),Pu=n(S,"LI",{});var jqe=s(Pu);vue=n(jqe,"STRONG",{});var Syt=s(vue);kMo=r(Syt,"esm"),Syt.forEach(t),SMo=r(jqe," \u2014 "),XD=n(jqe,"A",{href:!0});var Ryt=s(XD);RMo=r(Ryt,"EsmTokenizer"),Ryt.forEach(t),PMo=r(jqe," (ESM model)"),jqe.forEach(t),BMo=i(S),Bu=n(S,"LI",{});var Dqe=s(Bu);Fue=n(Dqe,"STRONG",{});var Pyt=s(Fue);IMo=r(Pyt,"flaubert"),Pyt.forEach(t),NMo=r(Dqe," \u2014 "),zD=n(Dqe,"A",{href:!0});var Byt=s(zD);qMo=r(Byt,"FlaubertTokenizer"),Byt.forEach(t),jMo=r(Dqe," (FlauBERT model)"),Dqe.forEach(t),DMo=i(S),Ps=n(S,"LI",{});var bI=s(Ps);Tue=n(bI,"STRONG",{});var Iyt=s(Tue);GMo=r(Iyt,"fnet"),Iyt.forEach(t),OMo=r(bI," \u2014 "),QD=n(bI,"A",{href:!0});var Nyt=s(QD);VMo=r(Nyt,"FNetTokenizer"),Nyt.forEach(t),XMo=r(bI," or "),WD=n(bI,"A",{href:!0});var qyt=s(WD);zMo=r(qyt,"FNetTokenizerFast"),qyt.forEach(t),QMo=r(bI," (FNet model)"),bI.forEach(t),WMo=i(S),Iu=n(S,"LI",{});var Gqe=s(Iu);Mue=n(Gqe,"STRONG",{});var jyt=s(Mue);UMo=r(jyt,"fsmt"),jyt.forEach(t),HMo=r(Gqe," \u2014 "),UD=n(Gqe,"A",{href:!0});var Dyt=s(UD);JMo=r(Dyt,"FSMTTokenizer"),Dyt.forEach(t),YMo=r(Gqe," (FairSeq Machine-Translation model)"),Gqe.forEach(t),ZMo=i(S),Bs=n(S,"LI",{});var vI=s(Bs);Eue=n(vI,"STRONG",{});var Gyt=s(Eue);KMo=r(Gyt,"funnel"),Gyt.forEach(t),eEo=r(vI," \u2014 "),HD=n(vI,"A",{href:!0});var Oyt=s(HD);oEo=r(Oyt,"FunnelTokenizer"),Oyt.forEach(t),rEo=r(vI," or "),JD=n(vI,"A",{href:!0});var Vyt=s(JD);tEo=r(Vyt,"FunnelTokenizerFast"),Vyt.forEach(t),aEo=r(vI," (Funnel Transformer model)"),vI.forEach(t),nEo=i(S),Is=n(S,"LI",{});var FI=s(Is);Cue=n(FI,"STRONG",{});var Xyt=s(Cue);sEo=r(Xyt,"gpt2"),Xyt.forEach(t),lEo=r(FI," \u2014 "),YD=n(FI,"A",{href:!0});var zyt=s(YD);iEo=r(zyt,"GPT2Tokenizer"),zyt.forEach(t),dEo=r(FI," or "),ZD=n(FI,"A",{href:!0});var Qyt=s(ZD);mEo=r(Qyt,"GPT2TokenizerFast"),Qyt.forEach(t),cEo=r(FI," (OpenAI GPT-2 model)"),FI.forEach(t),fEo=i(S),Ns=n(S,"LI",{});var TI=s(Ns);wue=n(TI,"STRONG",{});var Wyt=s(wue);gEo=r(Wyt,"gpt_neo"),Wyt.forEach(t),hEo=r(TI," \u2014 "),KD=n(TI,"A",{href:!0});var Uyt=s(KD);uEo=r(Uyt,"GPT2Tokenizer"),Uyt.forEach(t),pEo=r(TI," or "),eG=n(TI,"A",{href:!0});var Hyt=s(eG);_Eo=r(Hyt,"GPT2TokenizerFast"),Hyt.forEach(t),bEo=r(TI," (GPT Neo model)"),TI.forEach(t),vEo=i(S),Nu=n(S,"LI",{});var Oqe=s(Nu);Aue=n(Oqe,"STRONG",{});var Jyt=s(Aue);FEo=r(Jyt,"gpt_neox"),Jyt.forEach(t),TEo=r(Oqe," \u2014 "),oG=n(Oqe,"A",{href:!0});var Yyt=s(oG);MEo=r(Yyt,"GPTNeoXTokenizerFast"),Yyt.forEach(t),EEo=r(Oqe," (GPT NeoX model)"),Oqe.forEach(t),CEo=i(S),qu=n(S,"LI",{});var Vqe=s(qu);Lue=n(Vqe,"STRONG",{});var Zyt=s(Lue);wEo=r(Zyt,"gpt_neox_japanese"),Zyt.forEach(t),AEo=r(Vqe," \u2014 "),rG=n(Vqe,"A",{href:!0});var Kyt=s(rG);LEo=r(Kyt,"GPTNeoXJapaneseTokenizer"),Kyt.forEach(t),yEo=r(Vqe," (GPT NeoX Japanese model)"),Vqe.forEach(t),xEo=i(S),qs=n(S,"LI",{});var MI=s(qs);yue=n(MI,"STRONG",{});var e9t=s(yue);$Eo=r(e9t,"gptj"),e9t.forEach(t),kEo=r(MI," \u2014 "),tG=n(MI,"A",{href:!0});var o9t=s(tG);SEo=r(o9t,"GPT2Tokenizer"),o9t.forEach(t),REo=r(MI," or "),aG=n(MI,"A",{href:!0});var r9t=s(aG);PEo=r(r9t,"GPT2TokenizerFast"),r9t.forEach(t),BEo=r(MI," (GPT-J model)"),MI.forEach(t),IEo=i(S),js=n(S,"LI",{});var EI=s(js);xue=n(EI,"STRONG",{});var t9t=s(xue);NEo=r(t9t,"groupvit"),t9t.forEach(t),qEo=r(EI," \u2014 "),nG=n(EI,"A",{href:!0});var a9t=s(nG);jEo=r(a9t,"CLIPTokenizer"),a9t.forEach(t),DEo=r(EI," or "),sG=n(EI,"A",{href:!0});var n9t=s(sG);GEo=r(n9t,"CLIPTokenizerFast"),n9t.forEach(t),OEo=r(EI," (GroupViT model)"),EI.forEach(t),VEo=i(S),Ds=n(S,"LI",{});var CI=s(Ds);$ue=n(CI,"STRONG",{});var s9t=s($ue);XEo=r(s9t,"herbert"),s9t.forEach(t),zEo=r(CI," \u2014 "),lG=n(CI,"A",{href:!0});var l9t=s(lG);QEo=r(l9t,"HerbertTokenizer"),l9t.forEach(t),WEo=r(CI," or "),iG=n(CI,"A",{href:!0});var i9t=s(iG);UEo=r(i9t,"HerbertTokenizerFast"),i9t.forEach(t),HEo=r(CI," (HerBERT model)"),CI.forEach(t),JEo=i(S),ju=n(S,"LI",{});var Xqe=s(ju);kue=n(Xqe,"STRONG",{});var d9t=s(kue);YEo=r(d9t,"hubert"),d9t.forEach(t),ZEo=r(Xqe," \u2014 "),dG=n(Xqe,"A",{href:!0});var m9t=s(dG);KEo=r(m9t,"Wav2Vec2CTCTokenizer"),m9t.forEach(t),e4o=r(Xqe," (Hubert model)"),Xqe.forEach(t),o4o=i(S),Gs=n(S,"LI",{});var wI=s(Gs);Sue=n(wI,"STRONG",{});var c9t=s(Sue);r4o=r(c9t,"ibert"),c9t.forEach(t),t4o=r(wI," \u2014 "),mG=n(wI,"A",{href:!0});var f9t=s(mG);a4o=r(f9t,"RobertaTokenizer"),f9t.forEach(t),n4o=r(wI," or "),cG=n(wI,"A",{href:!0});var g9t=s(cG);s4o=r(g9t,"RobertaTokenizerFast"),g9t.forEach(t),l4o=r(wI," (I-BERT model)"),wI.forEach(t),i4o=i(S),Os=n(S,"LI",{});var AI=s(Os);Rue=n(AI,"STRONG",{});var h9t=s(Rue);d4o=r(h9t,"layoutlm"),h9t.forEach(t),m4o=r(AI," \u2014 "),fG=n(AI,"A",{href:!0});var u9t=s(fG);c4o=r(u9t,"LayoutLMTokenizer"),u9t.forEach(t),f4o=r(AI," or "),gG=n(AI,"A",{href:!0});var p9t=s(gG);g4o=r(p9t,"LayoutLMTokenizerFast"),p9t.forEach(t),h4o=r(AI," (LayoutLM model)"),AI.forEach(t),u4o=i(S),Vs=n(S,"LI",{});var LI=s(Vs);Pue=n(LI,"STRONG",{});var _9t=s(Pue);p4o=r(_9t,"layoutlmv2"),_9t.forEach(t),_4o=r(LI," \u2014 "),hG=n(LI,"A",{href:!0});var b9t=s(hG);b4o=r(b9t,"LayoutLMv2Tokenizer"),b9t.forEach(t),v4o=r(LI," or "),uG=n(LI,"A",{href:!0});var v9t=s(uG);F4o=r(v9t,"LayoutLMv2TokenizerFast"),v9t.forEach(t),T4o=r(LI," (LayoutLMv2 model)"),LI.forEach(t),M4o=i(S),Xs=n(S,"LI",{});var yI=s(Xs);Bue=n(yI,"STRONG",{});var F9t=s(Bue);E4o=r(F9t,"layoutlmv3"),F9t.forEach(t),C4o=r(yI," \u2014 "),pG=n(yI,"A",{href:!0});var T9t=s(pG);w4o=r(T9t,"LayoutLMv3Tokenizer"),T9t.forEach(t),A4o=r(yI," or "),_G=n(yI,"A",{href:!0});var M9t=s(_G);L4o=r(M9t,"LayoutLMv3TokenizerFast"),M9t.forEach(t),y4o=r(yI," (LayoutLMv3 model)"),yI.forEach(t),x4o=i(S),zs=n(S,"LI",{});var xI=s(zs);Iue=n(xI,"STRONG",{});var E9t=s(Iue);$4o=r(E9t,"layoutxlm"),E9t.forEach(t),k4o=r(xI," \u2014 "),bG=n(xI,"A",{href:!0});var C9t=s(bG);S4o=r(C9t,"LayoutXLMTokenizer"),C9t.forEach(t),R4o=r(xI," or "),vG=n(xI,"A",{href:!0});var w9t=s(vG);P4o=r(w9t,"LayoutXLMTokenizerFast"),w9t.forEach(t),B4o=r(xI," (LayoutXLM model)"),xI.forEach(t),I4o=i(S),Qs=n(S,"LI",{});var $I=s(Qs);Nue=n($I,"STRONG",{});var A9t=s(Nue);N4o=r(A9t,"led"),A9t.forEach(t),q4o=r($I," \u2014 "),FG=n($I,"A",{href:!0});var L9t=s(FG);j4o=r(L9t,"LEDTokenizer"),L9t.forEach(t),D4o=r($I," or "),TG=n($I,"A",{href:!0});var y9t=s(TG);G4o=r(y9t,"LEDTokenizerFast"),y9t.forEach(t),O4o=r($I," (LED model)"),$I.forEach(t),V4o=i(S),Ws=n(S,"LI",{});var kI=s(Ws);que=n(kI,"STRONG",{});var x9t=s(que);X4o=r(x9t,"lilt"),x9t.forEach(t),z4o=r(kI," \u2014 "),MG=n(kI,"A",{href:!0});var $9t=s(MG);Q4o=r($9t,"LayoutLMv3Tokenizer"),$9t.forEach(t),W4o=r(kI," or "),EG=n(kI,"A",{href:!0});var k9t=s(EG);U4o=r(k9t,"LayoutLMv3TokenizerFast"),k9t.forEach(t),H4o=r(kI," (LiLT model)"),kI.forEach(t),J4o=i(S),Us=n(S,"LI",{});var SI=s(Us);jue=n(SI,"STRONG",{});var S9t=s(jue);Y4o=r(S9t,"longformer"),S9t.forEach(t),Z4o=r(SI," \u2014 "),CG=n(SI,"A",{href:!0});var R9t=s(CG);K4o=r(R9t,"LongformerTokenizer"),R9t.forEach(t),eCo=r(SI," or "),wG=n(SI,"A",{href:!0});var P9t=s(wG);oCo=r(P9t,"LongformerTokenizerFast"),P9t.forEach(t),rCo=r(SI," (Longformer model)"),SI.forEach(t),tCo=i(S),Hs=n(S,"LI",{});var RI=s(Hs);Due=n(RI,"STRONG",{});var B9t=s(Due);aCo=r(B9t,"longt5"),B9t.forEach(t),nCo=r(RI," \u2014 "),AG=n(RI,"A",{href:!0});var I9t=s(AG);sCo=r(I9t,"T5Tokenizer"),I9t.forEach(t),lCo=r(RI," or "),LG=n(RI,"A",{href:!0});var N9t=s(LG);iCo=r(N9t,"T5TokenizerFast"),N9t.forEach(t),dCo=r(RI," (LongT5 model)"),RI.forEach(t),mCo=i(S),Du=n(S,"LI",{});var zqe=s(Du);Gue=n(zqe,"STRONG",{});var q9t=s(Gue);cCo=r(q9t,"luke"),q9t.forEach(t),fCo=r(zqe," \u2014 "),yG=n(zqe,"A",{href:!0});var j9t=s(yG);gCo=r(j9t,"LukeTokenizer"),j9t.forEach(t),hCo=r(zqe," (LUKE model)"),zqe.forEach(t),uCo=i(S),Js=n(S,"LI",{});var PI=s(Js);Oue=n(PI,"STRONG",{});var D9t=s(Oue);pCo=r(D9t,"lxmert"),D9t.forEach(t),_Co=r(PI," \u2014 "),xG=n(PI,"A",{href:!0});var G9t=s(xG);bCo=r(G9t,"LxmertTokenizer"),G9t.forEach(t),vCo=r(PI," or "),$G=n(PI,"A",{href:!0});var O9t=s($G);FCo=r(O9t,"LxmertTokenizerFast"),O9t.forEach(t),TCo=r(PI," (LXMERT model)"),PI.forEach(t),MCo=i(S),Gu=n(S,"LI",{});var Qqe=s(Gu);Vue=n(Qqe,"STRONG",{});var V9t=s(Vue);ECo=r(V9t,"m2m_100"),V9t.forEach(t),CCo=r(Qqe," \u2014 "),kG=n(Qqe,"A",{href:!0});var X9t=s(kG);wCo=r(X9t,"M2M100Tokenizer"),X9t.forEach(t),ACo=r(Qqe," (M2M100 model)"),Qqe.forEach(t),LCo=i(S),Ou=n(S,"LI",{});var Wqe=s(Ou);Xue=n(Wqe,"STRONG",{});var z9t=s(Xue);yCo=r(z9t,"marian"),z9t.forEach(t),xCo=r(Wqe," \u2014 "),SG=n(Wqe,"A",{href:!0});var Q9t=s(SG);$Co=r(Q9t,"MarianTokenizer"),Q9t.forEach(t),kCo=r(Wqe," (Marian model)"),Wqe.forEach(t),SCo=i(S),Ys=n(S,"LI",{});var BI=s(Ys);zue=n(BI,"STRONG",{});var W9t=s(zue);RCo=r(W9t,"mbart"),W9t.forEach(t),PCo=r(BI," \u2014 "),RG=n(BI,"A",{href:!0});var U9t=s(RG);BCo=r(U9t,"MBartTokenizer"),U9t.forEach(t),ICo=r(BI," or "),PG=n(BI,"A",{href:!0});var H9t=s(PG);NCo=r(H9t,"MBartTokenizerFast"),H9t.forEach(t),qCo=r(BI," (mBART model)"),BI.forEach(t),jCo=i(S),Zs=n(S,"LI",{});var II=s(Zs);Que=n(II,"STRONG",{});var J9t=s(Que);DCo=r(J9t,"mbart50"),J9t.forEach(t),GCo=r(II," \u2014 "),BG=n(II,"A",{href:!0});var Y9t=s(BG);OCo=r(Y9t,"MBart50Tokenizer"),Y9t.forEach(t),VCo=r(II," or "),IG=n(II,"A",{href:!0});var Z9t=s(IG);XCo=r(Z9t,"MBart50TokenizerFast"),Z9t.forEach(t),zCo=r(II," (mBART-50 model)"),II.forEach(t),QCo=i(S),Ks=n(S,"LI",{});var NI=s(Ks);Wue=n(NI,"STRONG",{});var K9t=s(Wue);WCo=r(K9t,"megatron-bert"),K9t.forEach(t),UCo=r(NI," \u2014 "),NG=n(NI,"A",{href:!0});var ext=s(NG);HCo=r(ext,"BertTokenizer"),ext.forEach(t),JCo=r(NI," or "),qG=n(NI,"A",{href:!0});var oxt=s(qG);YCo=r(oxt,"BertTokenizerFast"),oxt.forEach(t),ZCo=r(NI," (Megatron-BERT model)"),NI.forEach(t),KCo=i(S),Vu=n(S,"LI",{});var Uqe=s(Vu);Uue=n(Uqe,"STRONG",{});var rxt=s(Uue);e3o=r(rxt,"mluke"),rxt.forEach(t),o3o=r(Uqe," \u2014 "),jG=n(Uqe,"A",{href:!0});var txt=s(jG);r3o=r(txt,"MLukeTokenizer"),txt.forEach(t),t3o=r(Uqe," (mLUKE model)"),Uqe.forEach(t),a3o=i(S),el=n(S,"LI",{});var qI=s(el);Hue=n(qI,"STRONG",{});var axt=s(Hue);n3o=r(axt,"mobilebert"),axt.forEach(t),s3o=r(qI," \u2014 "),DG=n(qI,"A",{href:!0});var nxt=s(DG);l3o=r(nxt,"MobileBertTokenizer"),nxt.forEach(t),i3o=r(qI," or "),GG=n(qI,"A",{href:!0});var sxt=s(GG);d3o=r(sxt,"MobileBertTokenizerFast"),sxt.forEach(t),m3o=r(qI," (MobileBERT model)"),qI.forEach(t),c3o=i(S),ol=n(S,"LI",{});var jI=s(ol);Jue=n(jI,"STRONG",{});var lxt=s(Jue);f3o=r(lxt,"mpnet"),lxt.forEach(t),g3o=r(jI," \u2014 "),OG=n(jI,"A",{href:!0});var ixt=s(OG);h3o=r(ixt,"MPNetTokenizer"),ixt.forEach(t),u3o=r(jI," or "),VG=n(jI,"A",{href:!0});var dxt=s(VG);p3o=r(dxt,"MPNetTokenizerFast"),dxt.forEach(t),_3o=r(jI," (MPNet model)"),jI.forEach(t),b3o=i(S),rl=n(S,"LI",{});var DI=s(rl);Yue=n(DI,"STRONG",{});var mxt=s(Yue);v3o=r(mxt,"mt5"),mxt.forEach(t),F3o=r(DI," \u2014 "),XG=n(DI,"A",{href:!0});var cxt=s(XG);T3o=r(cxt,"MT5Tokenizer"),cxt.forEach(t),M3o=r(DI," or "),zG=n(DI,"A",{href:!0});var fxt=s(zG);E3o=r(fxt,"MT5TokenizerFast"),fxt.forEach(t),C3o=r(DI," (MT5 model)"),DI.forEach(t),w3o=i(S),tl=n(S,"LI",{});var GI=s(tl);Zue=n(GI,"STRONG",{});var gxt=s(Zue);A3o=r(gxt,"mvp"),gxt.forEach(t),L3o=r(GI," \u2014 "),QG=n(GI,"A",{href:!0});var hxt=s(QG);y3o=r(hxt,"MvpTokenizer"),hxt.forEach(t),x3o=r(GI," or "),WG=n(GI,"A",{href:!0});var uxt=s(WG);$3o=r(uxt,"MvpTokenizerFast"),uxt.forEach(t),k3o=r(GI," (MVP model)"),GI.forEach(t),S3o=i(S),al=n(S,"LI",{});var OI=s(al);Kue=n(OI,"STRONG",{});var pxt=s(Kue);R3o=r(pxt,"nezha"),pxt.forEach(t),P3o=r(OI," \u2014 "),UG=n(OI,"A",{href:!0});var _xt=s(UG);B3o=r(_xt,"BertTokenizer"),_xt.forEach(t),I3o=r(OI," or "),HG=n(OI,"A",{href:!0});var bxt=s(HG);N3o=r(bxt,"BertTokenizerFast"),bxt.forEach(t),q3o=r(OI," (Nezha model)"),OI.forEach(t),j3o=i(S),nl=n(S,"LI",{});var VI=s(nl);epe=n(VI,"STRONG",{});var vxt=s(epe);D3o=r(vxt,"nllb"),vxt.forEach(t),G3o=r(VI," \u2014 "),JG=n(VI,"A",{href:!0});var Fxt=s(JG);O3o=r(Fxt,"NllbTokenizer"),Fxt.forEach(t),V3o=r(VI," or "),YG=n(VI,"A",{href:!0});var Txt=s(YG);X3o=r(Txt,"NllbTokenizerFast"),Txt.forEach(t),z3o=r(VI," (NLLB model)"),VI.forEach(t),Q3o=i(S),sl=n(S,"LI",{});var XI=s(sl);ope=n(XI,"STRONG",{});var Mxt=s(ope);W3o=r(Mxt,"nystromformer"),Mxt.forEach(t),U3o=r(XI," \u2014 "),ZG=n(XI,"A",{href:!0});var Ext=s(ZG);H3o=r(Ext,"AlbertTokenizer"),Ext.forEach(t),J3o=r(XI," or "),KG=n(XI,"A",{href:!0});var Cxt=s(KG);Y3o=r(Cxt,"AlbertTokenizerFast"),Cxt.forEach(t),Z3o=r(XI," (Nystr\xF6mformer model)"),XI.forEach(t),K3o=i(S),ll=n(S,"LI",{});var zI=s(ll);rpe=n(zI,"STRONG",{});var wxt=s(rpe);e5o=r(wxt,"openai-gpt"),wxt.forEach(t),o5o=r(zI," \u2014 "),eO=n(zI,"A",{href:!0});var Axt=s(eO);r5o=r(Axt,"OpenAIGPTTokenizer"),Axt.forEach(t),t5o=r(zI," or "),oO=n(zI,"A",{href:!0});var Lxt=s(oO);a5o=r(Lxt,"OpenAIGPTTokenizerFast"),Lxt.forEach(t),n5o=r(zI," (OpenAI GPT model)"),zI.forEach(t),s5o=i(S),Xu=n(S,"LI",{});var Hqe=s(Xu);tpe=n(Hqe,"STRONG",{});var yxt=s(tpe);l5o=r(yxt,"opt"),yxt.forEach(t),i5o=r(Hqe," \u2014 "),rO=n(Hqe,"A",{href:!0});var xxt=s(rO);d5o=r(xxt,"GPT2Tokenizer"),xxt.forEach(t),m5o=r(Hqe," (OPT model)"),Hqe.forEach(t),c5o=i(S),il=n(S,"LI",{});var QI=s(il);ape=n(QI,"STRONG",{});var $xt=s(ape);f5o=r($xt,"owlvit"),$xt.forEach(t),g5o=r(QI," \u2014 "),tO=n(QI,"A",{href:!0});var kxt=s(tO);h5o=r(kxt,"CLIPTokenizer"),kxt.forEach(t),u5o=r(QI," or "),aO=n(QI,"A",{href:!0});var Sxt=s(aO);p5o=r(Sxt,"CLIPTokenizerFast"),Sxt.forEach(t),_5o=r(QI," (OWL-ViT model)"),QI.forEach(t),b5o=i(S),dl=n(S,"LI",{});var WI=s(dl);npe=n(WI,"STRONG",{});var Rxt=s(npe);v5o=r(Rxt,"pegasus"),Rxt.forEach(t),F5o=r(WI," \u2014 "),nO=n(WI,"A",{href:!0});var Pxt=s(nO);T5o=r(Pxt,"PegasusTokenizer"),Pxt.forEach(t),M5o=r(WI," or "),sO=n(WI,"A",{href:!0});var Bxt=s(sO);E5o=r(Bxt,"PegasusTokenizerFast"),Bxt.forEach(t),C5o=r(WI," (Pegasus model)"),WI.forEach(t),w5o=i(S),zu=n(S,"LI",{});var Jqe=s(zu);spe=n(Jqe,"STRONG",{});var Ixt=s(spe);A5o=r(Ixt,"perceiver"),Ixt.forEach(t),L5o=r(Jqe," \u2014 "),lO=n(Jqe,"A",{href:!0});var Nxt=s(lO);y5o=r(Nxt,"PerceiverTokenizer"),Nxt.forEach(t),x5o=r(Jqe," (Perceiver model)"),Jqe.forEach(t),$5o=i(S),Qu=n(S,"LI",{});var Yqe=s(Qu);lpe=n(Yqe,"STRONG",{});var qxt=s(lpe);k5o=r(qxt,"phobert"),qxt.forEach(t),S5o=r(Yqe," \u2014 "),iO=n(Yqe,"A",{href:!0});var jxt=s(iO);R5o=r(jxt,"PhobertTokenizer"),jxt.forEach(t),P5o=r(Yqe," (PhoBERT model)"),Yqe.forEach(t),B5o=i(S),Wu=n(S,"LI",{});var Zqe=s(Wu);ipe=n(Zqe,"STRONG",{});var Dxt=s(ipe);I5o=r(Dxt,"plbart"),Dxt.forEach(t),N5o=r(Zqe," \u2014 "),dO=n(Zqe,"A",{href:!0});var Gxt=s(dO);q5o=r(Gxt,"PLBartTokenizer"),Gxt.forEach(t),j5o=r(Zqe," (PLBart model)"),Zqe.forEach(t),D5o=i(S),Uu=n(S,"LI",{});var Kqe=s(Uu);dpe=n(Kqe,"STRONG",{});var Oxt=s(dpe);G5o=r(Oxt,"prophetnet"),Oxt.forEach(t),O5o=r(Kqe," \u2014 "),mO=n(Kqe,"A",{href:!0});var Vxt=s(mO);V5o=r(Vxt,"ProphetNetTokenizer"),Vxt.forEach(t),X5o=r(Kqe," (ProphetNet model)"),Kqe.forEach(t),z5o=i(S),ml=n(S,"LI",{});var UI=s(ml);mpe=n(UI,"STRONG",{});var Xxt=s(mpe);Q5o=r(Xxt,"qdqbert"),Xxt.forEach(t),W5o=r(UI," \u2014 "),cO=n(UI,"A",{href:!0});var zxt=s(cO);U5o=r(zxt,"BertTokenizer"),zxt.forEach(t),H5o=r(UI," or "),fO=n(UI,"A",{href:!0});var Qxt=s(fO);J5o=r(Qxt,"BertTokenizerFast"),Qxt.forEach(t),Y5o=r(UI," (QDQBert model)"),UI.forEach(t),Z5o=i(S),Hu=n(S,"LI",{});var eje=s(Hu);cpe=n(eje,"STRONG",{});var Wxt=s(cpe);K5o=r(Wxt,"rag"),Wxt.forEach(t),e0o=r(eje," \u2014 "),gO=n(eje,"A",{href:!0});var Uxt=s(gO);o0o=r(Uxt,"RagTokenizer"),Uxt.forEach(t),r0o=r(eje," (RAG model)"),eje.forEach(t),t0o=i(S),cl=n(S,"LI",{});var HI=s(cl);fpe=n(HI,"STRONG",{});var Hxt=s(fpe);a0o=r(Hxt,"realm"),Hxt.forEach(t),n0o=r(HI," \u2014 "),hO=n(HI,"A",{href:!0});var Jxt=s(hO);s0o=r(Jxt,"RealmTokenizer"),Jxt.forEach(t),l0o=r(HI," or "),uO=n(HI,"A",{href:!0});var Yxt=s(uO);i0o=r(Yxt,"RealmTokenizerFast"),Yxt.forEach(t),d0o=r(HI," (REALM model)"),HI.forEach(t),m0o=i(S),fl=n(S,"LI",{});var JI=s(fl);gpe=n(JI,"STRONG",{});var Zxt=s(gpe);c0o=r(Zxt,"reformer"),Zxt.forEach(t),f0o=r(JI," \u2014 "),pO=n(JI,"A",{href:!0});var Kxt=s(pO);g0o=r(Kxt,"ReformerTokenizer"),Kxt.forEach(t),h0o=r(JI," or "),_O=n(JI,"A",{href:!0});var e$t=s(_O);u0o=r(e$t,"ReformerTokenizerFast"),e$t.forEach(t),p0o=r(JI," (Reformer model)"),JI.forEach(t),_0o=i(S),gl=n(S,"LI",{});var YI=s(gl);hpe=n(YI,"STRONG",{});var o$t=s(hpe);b0o=r(o$t,"rembert"),o$t.forEach(t),v0o=r(YI," \u2014 "),bO=n(YI,"A",{href:!0});var r$t=s(bO);F0o=r(r$t,"RemBertTokenizer"),r$t.forEach(t),T0o=r(YI," or "),vO=n(YI,"A",{href:!0});var t$t=s(vO);M0o=r(t$t,"RemBertTokenizerFast"),t$t.forEach(t),E0o=r(YI," (RemBERT model)"),YI.forEach(t),C0o=i(S),hl=n(S,"LI",{});var ZI=s(hl);upe=n(ZI,"STRONG",{});var a$t=s(upe);w0o=r(a$t,"retribert"),a$t.forEach(t),A0o=r(ZI," \u2014 "),FO=n(ZI,"A",{href:!0});var n$t=s(FO);L0o=r(n$t,"RetriBertTokenizer"),n$t.forEach(t),y0o=r(ZI," or "),TO=n(ZI,"A",{href:!0});var s$t=s(TO);x0o=r(s$t,"RetriBertTokenizerFast"),s$t.forEach(t),$0o=r(ZI," (RetriBERT model)"),ZI.forEach(t),k0o=i(S),ul=n(S,"LI",{});var KI=s(ul);ppe=n(KI,"STRONG",{});var l$t=s(ppe);S0o=r(l$t,"roberta"),l$t.forEach(t),R0o=r(KI," \u2014 "),MO=n(KI,"A",{href:!0});var i$t=s(MO);P0o=r(i$t,"RobertaTokenizer"),i$t.forEach(t),B0o=r(KI," or "),EO=n(KI,"A",{href:!0});var d$t=s(EO);I0o=r(d$t,"RobertaTokenizerFast"),d$t.forEach(t),N0o=r(KI," (RoBERTa model)"),KI.forEach(t),q0o=i(S),pl=n(S,"LI",{});var eN=s(pl);_pe=n(eN,"STRONG",{});var m$t=s(_pe);j0o=r(m$t,"roformer"),m$t.forEach(t),D0o=r(eN," \u2014 "),CO=n(eN,"A",{href:!0});var c$t=s(CO);G0o=r(c$t,"RoFormerTokenizer"),c$t.forEach(t),O0o=r(eN," or "),wO=n(eN,"A",{href:!0});var f$t=s(wO);V0o=r(f$t,"RoFormerTokenizerFast"),f$t.forEach(t),X0o=r(eN," (RoFormer model)"),eN.forEach(t),z0o=i(S),Ju=n(S,"LI",{});var oje=s(Ju);bpe=n(oje,"STRONG",{});var g$t=s(bpe);Q0o=r(g$t,"speech_to_text"),g$t.forEach(t),W0o=r(oje," \u2014 "),AO=n(oje,"A",{href:!0});var h$t=s(AO);U0o=r(h$t,"Speech2TextTokenizer"),h$t.forEach(t),H0o=r(oje," (Speech2Text model)"),oje.forEach(t),J0o=i(S),Yu=n(S,"LI",{});var rje=s(Yu);vpe=n(rje,"STRONG",{});var u$t=s(vpe);Y0o=r(u$t,"speech_to_text_2"),u$t.forEach(t),Z0o=r(rje," \u2014 "),LO=n(rje,"A",{href:!0});var p$t=s(LO);K0o=r(p$t,"Speech2Text2Tokenizer"),p$t.forEach(t),ewo=r(rje," (Speech2Text2 model)"),rje.forEach(t),owo=i(S),_l=n(S,"LI",{});var oN=s(_l);Fpe=n(oN,"STRONG",{});var _$t=s(Fpe);rwo=r(_$t,"splinter"),_$t.forEach(t),two=r(oN," \u2014 "),yO=n(oN,"A",{href:!0});var b$t=s(yO);awo=r(b$t,"SplinterTokenizer"),b$t.forEach(t),nwo=r(oN," or "),xO=n(oN,"A",{href:!0});var v$t=s(xO);swo=r(v$t,"SplinterTokenizerFast"),v$t.forEach(t),lwo=r(oN," (Splinter model)"),oN.forEach(t),iwo=i(S),bl=n(S,"LI",{});var rN=s(bl);Tpe=n(rN,"STRONG",{});var F$t=s(Tpe);dwo=r(F$t,"squeezebert"),F$t.forEach(t),mwo=r(rN," \u2014 "),$O=n(rN,"A",{href:!0});var T$t=s($O);cwo=r(T$t,"SqueezeBertTokenizer"),T$t.forEach(t),fwo=r(rN," or "),kO=n(rN,"A",{href:!0});var M$t=s(kO);gwo=r(M$t,"SqueezeBertTokenizerFast"),M$t.forEach(t),hwo=r(rN," (SqueezeBERT model)"),rN.forEach(t),uwo=i(S),vl=n(S,"LI",{});var tN=s(vl);Mpe=n(tN,"STRONG",{});var E$t=s(Mpe);pwo=r(E$t,"t5"),E$t.forEach(t),_wo=r(tN," \u2014 "),SO=n(tN,"A",{href:!0});var C$t=s(SO);bwo=r(C$t,"T5Tokenizer"),C$t.forEach(t),vwo=r(tN," or "),RO=n(tN,"A",{href:!0});var w$t=s(RO);Fwo=r(w$t,"T5TokenizerFast"),w$t.forEach(t),Two=r(tN," (T5 model)"),tN.forEach(t),Mwo=i(S),Zu=n(S,"LI",{});var tje=s(Zu);Epe=n(tje,"STRONG",{});var A$t=s(Epe);Ewo=r(A$t,"tapas"),A$t.forEach(t),Cwo=r(tje," \u2014 "),PO=n(tje,"A",{href:!0});var L$t=s(PO);wwo=r(L$t,"TapasTokenizer"),L$t.forEach(t),Awo=r(tje," (TAPAS model)"),tje.forEach(t),Lwo=i(S),Ku=n(S,"LI",{});var aje=s(Ku);Cpe=n(aje,"STRONG",{});var y$t=s(Cpe);ywo=r(y$t,"tapex"),y$t.forEach(t),xwo=r(aje," \u2014 "),BO=n(aje,"A",{href:!0});var x$t=s(BO);$wo=r(x$t,"TapexTokenizer"),x$t.forEach(t),kwo=r(aje," (TAPEX model)"),aje.forEach(t),Swo=i(S),ep=n(S,"LI",{});var nje=s(ep);wpe=n(nje,"STRONG",{});var $$t=s(wpe);Rwo=r($$t,"transfo-xl"),$$t.forEach(t),Pwo=r(nje," \u2014 "),IO=n(nje,"A",{href:!0});var k$t=s(IO);Bwo=r(k$t,"TransfoXLTokenizer"),k$t.forEach(t),Iwo=r(nje," (Transformer-XL model)"),nje.forEach(t),Nwo=i(S),Fl=n(S,"LI",{});var aN=s(Fl);Ape=n(aN,"STRONG",{});var S$t=s(Ape);qwo=r(S$t,"vilt"),S$t.forEach(t),jwo=r(aN," \u2014 "),NO=n(aN,"A",{href:!0});var R$t=s(NO);Dwo=r(R$t,"BertTokenizer"),R$t.forEach(t),Gwo=r(aN," or "),qO=n(aN,"A",{href:!0});var P$t=s(qO);Owo=r(P$t,"BertTokenizerFast"),P$t.forEach(t),Vwo=r(aN," (ViLT model)"),aN.forEach(t),Xwo=i(S),Tl=n(S,"LI",{});var nN=s(Tl);Lpe=n(nN,"STRONG",{});var B$t=s(Lpe);zwo=r(B$t,"visual_bert"),B$t.forEach(t),Qwo=r(nN," \u2014 "),jO=n(nN,"A",{href:!0});var I$t=s(jO);Wwo=r(I$t,"BertTokenizer"),I$t.forEach(t),Uwo=r(nN," or "),DO=n(nN,"A",{href:!0});var N$t=s(DO);Hwo=r(N$t,"BertTokenizerFast"),N$t.forEach(t),Jwo=r(nN," (VisualBERT model)"),nN.forEach(t),Ywo=i(S),op=n(S,"LI",{});var sje=s(op);ype=n(sje,"STRONG",{});var q$t=s(ype);Zwo=r(q$t,"wav2vec2"),q$t.forEach(t),Kwo=r(sje," \u2014 "),GO=n(sje,"A",{href:!0});var j$t=s(GO);eAo=r(j$t,"Wav2Vec2CTCTokenizer"),j$t.forEach(t),oAo=r(sje," (Wav2Vec2 model)"),sje.forEach(t),rAo=i(S),rp=n(S,"LI",{});var lje=s(rp);xpe=n(lje,"STRONG",{});var D$t=s(xpe);tAo=r(D$t,"wav2vec2-conformer"),D$t.forEach(t),aAo=r(lje," \u2014 "),OO=n(lje,"A",{href:!0});var G$t=s(OO);nAo=r(G$t,"Wav2Vec2CTCTokenizer"),G$t.forEach(t),sAo=r(lje," (Wav2Vec2-Conformer model)"),lje.forEach(t),lAo=i(S),tp=n(S,"LI",{});var ije=s(tp);$pe=n(ije,"STRONG",{});var O$t=s($pe);iAo=r(O$t,"wav2vec2_phoneme"),O$t.forEach(t),dAo=r(ije," \u2014 "),VO=n(ije,"A",{href:!0});var V$t=s(VO);mAo=r(V$t,"Wav2Vec2PhonemeCTCTokenizer"),V$t.forEach(t),cAo=r(ije," (Wav2Vec2Phoneme model)"),ije.forEach(t),fAo=i(S),ap=n(S,"LI",{});var dje=s(ap);kpe=n(dje,"STRONG",{});var X$t=s(kpe);gAo=r(X$t,"whisper"),X$t.forEach(t),hAo=r(dje," \u2014 "),XO=n(dje,"A",{href:!0});var z$t=s(XO);uAo=r(z$t,"WhisperTokenizer"),z$t.forEach(t),pAo=r(dje," (Whisper model)"),dje.forEach(t),_Ao=i(S),Ml=n(S,"LI",{});var sN=s(Ml);Spe=n(sN,"STRONG",{});var Q$t=s(Spe);bAo=r(Q$t,"xclip"),Q$t.forEach(t),vAo=r(sN," \u2014 "),zO=n(sN,"A",{href:!0});var W$t=s(zO);FAo=r(W$t,"CLIPTokenizer"),W$t.forEach(t),TAo=r(sN," or "),QO=n(sN,"A",{href:!0});var U$t=s(QO);MAo=r(U$t,"CLIPTokenizerFast"),U$t.forEach(t),EAo=r(sN," (X-CLIP model)"),sN.forEach(t),CAo=i(S),El=n(S,"LI",{});var lN=s(El);Rpe=n(lN,"STRONG",{});var H$t=s(Rpe);wAo=r(H$t,"xglm"),H$t.forEach(t),AAo=r(lN," \u2014 "),WO=n(lN,"A",{href:!0});var J$t=s(WO);LAo=r(J$t,"XGLMTokenizer"),J$t.forEach(t),yAo=r(lN," or "),UO=n(lN,"A",{href:!0});var Y$t=s(UO);xAo=r(Y$t,"XGLMTokenizerFast"),Y$t.forEach(t),$Ao=r(lN," (XGLM model)"),lN.forEach(t),kAo=i(S),np=n(S,"LI",{});var mje=s(np);Ppe=n(mje,"STRONG",{});var Z$t=s(Ppe);SAo=r(Z$t,"xlm"),Z$t.forEach(t),RAo=r(mje," \u2014 "),HO=n(mje,"A",{href:!0});var K$t=s(HO);PAo=r(K$t,"XLMTokenizer"),K$t.forEach(t),BAo=r(mje," (XLM model)"),mje.forEach(t),IAo=i(S),sp=n(S,"LI",{});var cje=s(sp);Bpe=n(cje,"STRONG",{});var ekt=s(Bpe);NAo=r(ekt,"xlm-prophetnet"),ekt.forEach(t),qAo=r(cje," \u2014 "),JO=n(cje,"A",{href:!0});var okt=s(JO);jAo=r(okt,"XLMProphetNetTokenizer"),okt.forEach(t),DAo=r(cje," (XLM-ProphetNet model)"),cje.forEach(t),GAo=i(S),Cl=n(S,"LI",{});var iN=s(Cl);Ipe=n(iN,"STRONG",{});var rkt=s(Ipe);OAo=r(rkt,"xlm-roberta"),rkt.forEach(t),VAo=r(iN," \u2014 "),YO=n(iN,"A",{href:!0});var tkt=s(YO);XAo=r(tkt,"XLMRobertaTokenizer"),tkt.forEach(t),zAo=r(iN," or "),ZO=n(iN,"A",{href:!0});var akt=s(ZO);QAo=r(akt,"XLMRobertaTokenizerFast"),akt.forEach(t),WAo=r(iN," (XLM-RoBERTa model)"),iN.forEach(t),UAo=i(S),wl=n(S,"LI",{});var dN=s(wl);Npe=n(dN,"STRONG",{});var nkt=s(Npe);HAo=r(nkt,"xlm-roberta-xl"),nkt.forEach(t),JAo=r(dN," \u2014 "),KO=n(dN,"A",{href:!0});var skt=s(KO);YAo=r(skt,"XLMRobertaTokenizer"),skt.forEach(t),ZAo=r(dN," or "),eV=n(dN,"A",{href:!0});var lkt=s(eV);KAo=r(lkt,"XLMRobertaTokenizerFast"),lkt.forEach(t),e6o=r(dN," (XLM-RoBERTa-XL model)"),dN.forEach(t),o6o=i(S),Al=n(S,"LI",{});var mN=s(Al);qpe=n(mN,"STRONG",{});var ikt=s(qpe);r6o=r(ikt,"xlnet"),ikt.forEach(t),t6o=r(mN," \u2014 "),oV=n(mN,"A",{href:!0});var dkt=s(oV);a6o=r(dkt,"XLNetTokenizer"),dkt.forEach(t),n6o=r(mN," or "),rV=n(mN,"A",{href:!0});var mkt=s(rV);s6o=r(mkt,"XLNetTokenizerFast"),mkt.forEach(t),l6o=r(mN," (XLNet model)"),mN.forEach(t),i6o=i(S),Ll=n(S,"LI",{});var cN=s(Ll);jpe=n(cN,"STRONG",{});var ckt=s(jpe);d6o=r(ckt,"yoso"),ckt.forEach(t),m6o=r(cN," \u2014 "),tV=n(cN,"A",{href:!0});var fkt=s(tV);c6o=r(fkt,"AlbertTokenizer"),fkt.forEach(t),f6o=r(cN," or "),aV=n(cN,"A",{href:!0});var gkt=s(aV);g6o=r(gkt,"AlbertTokenizerFast"),gkt.forEach(t),h6o=r(cN," (YOSO model)"),cN.forEach(t),S.forEach(t),u6o=i(Pl),T(lp.$$.fragment,Pl),Pl.forEach(t),p6o=i(Rl),ip=n(Rl,"DIV",{class:!0});var $no=s(ip);T(b$.$$.fragment,$no),_6o=i($no),Dpe=n($no,"P",{});var hkt=s(Dpe);b6o=r(hkt,"Register a new tokenizer in this mapping."),hkt.forEach(t),$no.forEach(t),Rl.forEach(t),_to=i(c),Ld=n(c,"H2",{class:!0});var kno=s(Ld);dp=n(kno,"A",{id:!0,class:!0,href:!0});var ukt=s(dp);Gpe=n(ukt,"SPAN",{});var pkt=s(Gpe);T(v$.$$.fragment,pkt),pkt.forEach(t),ukt.forEach(t),v6o=i(kno),Ope=n(kno,"SPAN",{});var _kt=s(Ope);F6o=r(_kt,"AutoFeatureExtractor"),_kt.forEach(t),kno.forEach(t),bto=i(c),Po=n(c,"DIV",{class:!0});var Bl=s(Po);T(F$.$$.fragment,Bl),T6o=i(Bl),T$=n(Bl,"P",{});var Sno=s(T$);M6o=r(Sno,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nV=n(Sno,"A",{href:!0});var bkt=s(nV);E6o=r(bkt,"AutoFeatureExtractor.from_pretrained()"),bkt.forEach(t),C6o=r(Sno," class method."),Sno.forEach(t),w6o=i(Bl),M$=n(Bl,"P",{});var Rno=s(M$);A6o=r(Rno,"This class cannot be instantiated directly using "),Vpe=n(Rno,"CODE",{});var vkt=s(Vpe);L6o=r(vkt,"__init__()"),vkt.forEach(t),y6o=r(Rno," (throws an error)."),Rno.forEach(t),x6o=i(Bl),Ye=n(Bl,"DIV",{class:!0});var Ca=s(Ye);T(E$.$$.fragment,Ca),$6o=i(Ca),Xpe=n(Ca,"P",{});var Fkt=s(Xpe);k6o=r(Fkt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Fkt.forEach(t),S6o=i(Ca),tn=n(Ca,"P",{});var Uy=s(tn);R6o=r(Uy,"The feature extractor class to instantiate is selected based on the "),zpe=n(Uy,"CODE",{});var Tkt=s(zpe);P6o=r(Tkt,"model_type"),Tkt.forEach(t),B6o=r(Uy,` property of the config object
(either passed as an argument or loaded from `),Qpe=n(Uy,"CODE",{});var Mkt=s(Qpe);I6o=r(Mkt,"pretrained_model_name_or_path"),Mkt.forEach(t),N6o=r(Uy,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Wpe=n(Uy,"CODE",{});var Ekt=s(Wpe);q6o=r(Ekt,"pretrained_model_name_or_path"),Ekt.forEach(t),j6o=r(Uy,":"),Uy.forEach(t),D6o=i(Ca),z=n(Ca,"UL",{});var W=s(z);mp=n(W,"LI",{});var fje=s(mp);Upe=n(fje,"STRONG",{});var Ckt=s(Upe);G6o=r(Ckt,"beit"),Ckt.forEach(t),O6o=r(fje," \u2014 "),sV=n(fje,"A",{href:!0});var wkt=s(sV);V6o=r(wkt,"BeitFeatureExtractor"),wkt.forEach(t),X6o=r(fje," (BEiT model)"),fje.forEach(t),z6o=i(W),cp=n(W,"LI",{});var gje=s(cp);Hpe=n(gje,"STRONG",{});var Akt=s(Hpe);Q6o=r(Akt,"clip"),Akt.forEach(t),W6o=r(gje," \u2014 "),lV=n(gje,"A",{href:!0});var Lkt=s(lV);U6o=r(Lkt,"CLIPFeatureExtractor"),Lkt.forEach(t),H6o=r(gje," (CLIP model)"),gje.forEach(t),J6o=i(W),fp=n(W,"LI",{});var hje=s(fp);Jpe=n(hje,"STRONG",{});var ykt=s(Jpe);Y6o=r(ykt,"conditional_detr"),ykt.forEach(t),Z6o=r(hje," \u2014 "),iV=n(hje,"A",{href:!0});var xkt=s(iV);K6o=r(xkt,"ConditionalDetrFeatureExtractor"),xkt.forEach(t),e7o=r(hje," (Conditional DETR model)"),hje.forEach(t),o7o=i(W),gp=n(W,"LI",{});var uje=s(gp);Ype=n(uje,"STRONG",{});var $kt=s(Ype);r7o=r($kt,"convnext"),$kt.forEach(t),t7o=r(uje," \u2014 "),dV=n(uje,"A",{href:!0});var kkt=s(dV);a7o=r(kkt,"ConvNextFeatureExtractor"),kkt.forEach(t),n7o=r(uje," (ConvNeXT model)"),uje.forEach(t),s7o=i(W),hp=n(W,"LI",{});var pje=s(hp);Zpe=n(pje,"STRONG",{});var Skt=s(Zpe);l7o=r(Skt,"cvt"),Skt.forEach(t),i7o=r(pje," \u2014 "),mV=n(pje,"A",{href:!0});var Rkt=s(mV);d7o=r(Rkt,"ConvNextFeatureExtractor"),Rkt.forEach(t),m7o=r(pje," (CvT model)"),pje.forEach(t),c7o=i(W),up=n(W,"LI",{});var _je=s(up);Kpe=n(_je,"STRONG",{});var Pkt=s(Kpe);f7o=r(Pkt,"data2vec-audio"),Pkt.forEach(t),g7o=r(_je," \u2014 "),cV=n(_je,"A",{href:!0});var Bkt=s(cV);h7o=r(Bkt,"Wav2Vec2FeatureExtractor"),Bkt.forEach(t),u7o=r(_je," (Data2VecAudio model)"),_je.forEach(t),p7o=i(W),pp=n(W,"LI",{});var bje=s(pp);e_e=n(bje,"STRONG",{});var Ikt=s(e_e);_7o=r(Ikt,"data2vec-vision"),Ikt.forEach(t),b7o=r(bje," \u2014 "),fV=n(bje,"A",{href:!0});var Nkt=s(fV);v7o=r(Nkt,"BeitFeatureExtractor"),Nkt.forEach(t),F7o=r(bje," (Data2VecVision model)"),bje.forEach(t),T7o=i(W),_p=n(W,"LI",{});var vje=s(_p);o_e=n(vje,"STRONG",{});var qkt=s(o_e);M7o=r(qkt,"deformable_detr"),qkt.forEach(t),E7o=r(vje," \u2014 "),gV=n(vje,"A",{href:!0});var jkt=s(gV);C7o=r(jkt,"DeformableDetrFeatureExtractor"),jkt.forEach(t),w7o=r(vje," (Deformable DETR model)"),vje.forEach(t),A7o=i(W),bp=n(W,"LI",{});var Fje=s(bp);r_e=n(Fje,"STRONG",{});var Dkt=s(r_e);L7o=r(Dkt,"deit"),Dkt.forEach(t),y7o=r(Fje," \u2014 "),hV=n(Fje,"A",{href:!0});var Gkt=s(hV);x7o=r(Gkt,"DeiTFeatureExtractor"),Gkt.forEach(t),$7o=r(Fje," (DeiT model)"),Fje.forEach(t),k7o=i(W),vp=n(W,"LI",{});var Tje=s(vp);t_e=n(Tje,"STRONG",{});var Okt=s(t_e);S7o=r(Okt,"detr"),Okt.forEach(t),R7o=r(Tje," \u2014 "),uV=n(Tje,"A",{href:!0});var Vkt=s(uV);P7o=r(Vkt,"DetrFeatureExtractor"),Vkt.forEach(t),B7o=r(Tje," (DETR model)"),Tje.forEach(t),I7o=i(W),Fp=n(W,"LI",{});var Mje=s(Fp);a_e=n(Mje,"STRONG",{});var Xkt=s(a_e);N7o=r(Xkt,"donut"),Xkt.forEach(t),q7o=r(Mje," \u2014 "),pV=n(Mje,"A",{href:!0});var zkt=s(pV);j7o=r(zkt,"DonutFeatureExtractor"),zkt.forEach(t),D7o=r(Mje," (Donut model)"),Mje.forEach(t),G7o=i(W),Tp=n(W,"LI",{});var Eje=s(Tp);n_e=n(Eje,"STRONG",{});var Qkt=s(n_e);O7o=r(Qkt,"dpt"),Qkt.forEach(t),V7o=r(Eje," \u2014 "),_V=n(Eje,"A",{href:!0});var Wkt=s(_V);X7o=r(Wkt,"DPTFeatureExtractor"),Wkt.forEach(t),z7o=r(Eje," (DPT model)"),Eje.forEach(t),Q7o=i(W),Mp=n(W,"LI",{});var Cje=s(Mp);s_e=n(Cje,"STRONG",{});var Ukt=s(s_e);W7o=r(Ukt,"flava"),Ukt.forEach(t),U7o=r(Cje," \u2014 "),bV=n(Cje,"A",{href:!0});var Hkt=s(bV);H7o=r(Hkt,"FlavaFeatureExtractor"),Hkt.forEach(t),J7o=r(Cje," (FLAVA model)"),Cje.forEach(t),Y7o=i(W),Ep=n(W,"LI",{});var wje=s(Ep);l_e=n(wje,"STRONG",{});var Jkt=s(l_e);Z7o=r(Jkt,"glpn"),Jkt.forEach(t),K7o=r(wje," \u2014 "),vV=n(wje,"A",{href:!0});var Ykt=s(vV);e8o=r(Ykt,"GLPNFeatureExtractor"),Ykt.forEach(t),o8o=r(wje," (GLPN model)"),wje.forEach(t),r8o=i(W),Cp=n(W,"LI",{});var Aje=s(Cp);i_e=n(Aje,"STRONG",{});var Zkt=s(i_e);t8o=r(Zkt,"groupvit"),Zkt.forEach(t),a8o=r(Aje," \u2014 "),FV=n(Aje,"A",{href:!0});var Kkt=s(FV);n8o=r(Kkt,"CLIPFeatureExtractor"),Kkt.forEach(t),s8o=r(Aje," (GroupViT model)"),Aje.forEach(t),l8o=i(W),wp=n(W,"LI",{});var Lje=s(wp);d_e=n(Lje,"STRONG",{});var eSt=s(d_e);i8o=r(eSt,"hubert"),eSt.forEach(t),d8o=r(Lje," \u2014 "),TV=n(Lje,"A",{href:!0});var oSt=s(TV);m8o=r(oSt,"Wav2Vec2FeatureExtractor"),oSt.forEach(t),c8o=r(Lje," (Hubert model)"),Lje.forEach(t),f8o=i(W),Ap=n(W,"LI",{});var yje=s(Ap);m_e=n(yje,"STRONG",{});var rSt=s(m_e);g8o=r(rSt,"imagegpt"),rSt.forEach(t),h8o=r(yje," \u2014 "),MV=n(yje,"A",{href:!0});var tSt=s(MV);u8o=r(tSt,"ImageGPTFeatureExtractor"),tSt.forEach(t),p8o=r(yje," (ImageGPT model)"),yje.forEach(t),_8o=i(W),Lp=n(W,"LI",{});var xje=s(Lp);c_e=n(xje,"STRONG",{});var aSt=s(c_e);b8o=r(aSt,"layoutlmv2"),aSt.forEach(t),v8o=r(xje," \u2014 "),EV=n(xje,"A",{href:!0});var nSt=s(EV);F8o=r(nSt,"LayoutLMv2FeatureExtractor"),nSt.forEach(t),T8o=r(xje," (LayoutLMv2 model)"),xje.forEach(t),M8o=i(W),yp=n(W,"LI",{});var $je=s(yp);f_e=n($je,"STRONG",{});var sSt=s(f_e);E8o=r(sSt,"layoutlmv3"),sSt.forEach(t),C8o=r($je," \u2014 "),CV=n($je,"A",{href:!0});var lSt=s(CV);w8o=r(lSt,"LayoutLMv3FeatureExtractor"),lSt.forEach(t),A8o=r($je," (LayoutLMv3 model)"),$je.forEach(t),L8o=i(W),xp=n(W,"LI",{});var kje=s(xp);g_e=n(kje,"STRONG",{});var iSt=s(g_e);y8o=r(iSt,"levit"),iSt.forEach(t),x8o=r(kje," \u2014 "),wV=n(kje,"A",{href:!0});var dSt=s(wV);$8o=r(dSt,"LevitFeatureExtractor"),dSt.forEach(t),k8o=r(kje," (LeViT model)"),kje.forEach(t),S8o=i(W),$p=n(W,"LI",{});var Sje=s($p);h_e=n(Sje,"STRONG",{});var mSt=s(h_e);R8o=r(mSt,"maskformer"),mSt.forEach(t),P8o=r(Sje," \u2014 "),AV=n(Sje,"A",{href:!0});var cSt=s(AV);B8o=r(cSt,"MaskFormerFeatureExtractor"),cSt.forEach(t),I8o=r(Sje," (MaskFormer model)"),Sje.forEach(t),N8o=i(W),kp=n(W,"LI",{});var Rje=s(kp);u_e=n(Rje,"STRONG",{});var fSt=s(u_e);q8o=r(fSt,"mctct"),fSt.forEach(t),j8o=r(Rje," \u2014 "),LV=n(Rje,"A",{href:!0});var gSt=s(LV);D8o=r(gSt,"MCTCTFeatureExtractor"),gSt.forEach(t),G8o=r(Rje," (M-CTC-T model)"),Rje.forEach(t),O8o=i(W),Sp=n(W,"LI",{});var Pje=s(Sp);p_e=n(Pje,"STRONG",{});var hSt=s(p_e);V8o=r(hSt,"mobilevit"),hSt.forEach(t),X8o=r(Pje," \u2014 "),yV=n(Pje,"A",{href:!0});var uSt=s(yV);z8o=r(uSt,"MobileViTFeatureExtractor"),uSt.forEach(t),Q8o=r(Pje," (MobileViT model)"),Pje.forEach(t),W8o=i(W),Rp=n(W,"LI",{});var Bje=s(Rp);__e=n(Bje,"STRONG",{});var pSt=s(__e);U8o=r(pSt,"owlvit"),pSt.forEach(t),H8o=r(Bje," \u2014 "),xV=n(Bje,"A",{href:!0});var _St=s(xV);J8o=r(_St,"OwlViTFeatureExtractor"),_St.forEach(t),Y8o=r(Bje," (OWL-ViT model)"),Bje.forEach(t),Z8o=i(W),Pp=n(W,"LI",{});var Ije=s(Pp);b_e=n(Ije,"STRONG",{});var bSt=s(b_e);K8o=r(bSt,"perceiver"),bSt.forEach(t),eLo=r(Ije," \u2014 "),$V=n(Ije,"A",{href:!0});var vSt=s($V);oLo=r(vSt,"PerceiverFeatureExtractor"),vSt.forEach(t),rLo=r(Ije," (Perceiver model)"),Ije.forEach(t),tLo=i(W),Bp=n(W,"LI",{});var Nje=s(Bp);v_e=n(Nje,"STRONG",{});var FSt=s(v_e);aLo=r(FSt,"poolformer"),FSt.forEach(t),nLo=r(Nje," \u2014 "),kV=n(Nje,"A",{href:!0});var TSt=s(kV);sLo=r(TSt,"PoolFormerFeatureExtractor"),TSt.forEach(t),lLo=r(Nje," (PoolFormer model)"),Nje.forEach(t),iLo=i(W),Ip=n(W,"LI",{});var qje=s(Ip);F_e=n(qje,"STRONG",{});var MSt=s(F_e);dLo=r(MSt,"regnet"),MSt.forEach(t),mLo=r(qje," \u2014 "),SV=n(qje,"A",{href:!0});var ESt=s(SV);cLo=r(ESt,"ConvNextFeatureExtractor"),ESt.forEach(t),fLo=r(qje," (RegNet model)"),qje.forEach(t),gLo=i(W),Np=n(W,"LI",{});var jje=s(Np);T_e=n(jje,"STRONG",{});var CSt=s(T_e);hLo=r(CSt,"resnet"),CSt.forEach(t),uLo=r(jje," \u2014 "),RV=n(jje,"A",{href:!0});var wSt=s(RV);pLo=r(wSt,"ConvNextFeatureExtractor"),wSt.forEach(t),_Lo=r(jje," (ResNet model)"),jje.forEach(t),bLo=i(W),qp=n(W,"LI",{});var Dje=s(qp);M_e=n(Dje,"STRONG",{});var ASt=s(M_e);vLo=r(ASt,"segformer"),ASt.forEach(t),FLo=r(Dje," \u2014 "),PV=n(Dje,"A",{href:!0});var LSt=s(PV);TLo=r(LSt,"SegformerFeatureExtractor"),LSt.forEach(t),MLo=r(Dje," (SegFormer model)"),Dje.forEach(t),ELo=i(W),jp=n(W,"LI",{});var Gje=s(jp);E_e=n(Gje,"STRONG",{});var ySt=s(E_e);CLo=r(ySt,"speech_to_text"),ySt.forEach(t),wLo=r(Gje," \u2014 "),BV=n(Gje,"A",{href:!0});var xSt=s(BV);ALo=r(xSt,"Speech2TextFeatureExtractor"),xSt.forEach(t),LLo=r(Gje," (Speech2Text model)"),Gje.forEach(t),yLo=i(W),Dp=n(W,"LI",{});var Oje=s(Dp);C_e=n(Oje,"STRONG",{});var $St=s(C_e);xLo=r($St,"swin"),$St.forEach(t),$Lo=r(Oje," \u2014 "),IV=n(Oje,"A",{href:!0});var kSt=s(IV);kLo=r(kSt,"ViTFeatureExtractor"),kSt.forEach(t),SLo=r(Oje," (Swin Transformer model)"),Oje.forEach(t),RLo=i(W),Gp=n(W,"LI",{});var Vje=s(Gp);w_e=n(Vje,"STRONG",{});var SSt=s(w_e);PLo=r(SSt,"swinv2"),SSt.forEach(t),BLo=r(Vje," \u2014 "),NV=n(Vje,"A",{href:!0});var RSt=s(NV);ILo=r(RSt,"ViTFeatureExtractor"),RSt.forEach(t),NLo=r(Vje," (Swin Transformer V2 model)"),Vje.forEach(t),qLo=i(W),Op=n(W,"LI",{});var Xje=s(Op);A_e=n(Xje,"STRONG",{});var PSt=s(A_e);jLo=r(PSt,"van"),PSt.forEach(t),DLo=r(Xje," \u2014 "),qV=n(Xje,"A",{href:!0});var BSt=s(qV);GLo=r(BSt,"ConvNextFeatureExtractor"),BSt.forEach(t),OLo=r(Xje," (VAN model)"),Xje.forEach(t),VLo=i(W),Vp=n(W,"LI",{});var zje=s(Vp);L_e=n(zje,"STRONG",{});var ISt=s(L_e);XLo=r(ISt,"videomae"),ISt.forEach(t),zLo=r(zje," \u2014 "),jV=n(zje,"A",{href:!0});var NSt=s(jV);QLo=r(NSt,"VideoMAEFeatureExtractor"),NSt.forEach(t),WLo=r(zje," (VideoMAE model)"),zje.forEach(t),ULo=i(W),Xp=n(W,"LI",{});var Qje=s(Xp);y_e=n(Qje,"STRONG",{});var qSt=s(y_e);HLo=r(qSt,"vilt"),qSt.forEach(t),JLo=r(Qje," \u2014 "),DV=n(Qje,"A",{href:!0});var jSt=s(DV);YLo=r(jSt,"ViltFeatureExtractor"),jSt.forEach(t),ZLo=r(Qje," (ViLT model)"),Qje.forEach(t),KLo=i(W),zp=n(W,"LI",{});var Wje=s(zp);x_e=n(Wje,"STRONG",{});var DSt=s(x_e);eyo=r(DSt,"vit"),DSt.forEach(t),oyo=r(Wje," \u2014 "),GV=n(Wje,"A",{href:!0});var GSt=s(GV);ryo=r(GSt,"ViTFeatureExtractor"),GSt.forEach(t),tyo=r(Wje," (ViT model)"),Wje.forEach(t),ayo=i(W),Qp=n(W,"LI",{});var Uje=s(Qp);$_e=n(Uje,"STRONG",{});var OSt=s($_e);nyo=r(OSt,"vit_mae"),OSt.forEach(t),syo=r(Uje," \u2014 "),OV=n(Uje,"A",{href:!0});var VSt=s(OV);lyo=r(VSt,"ViTFeatureExtractor"),VSt.forEach(t),iyo=r(Uje," (ViTMAE model)"),Uje.forEach(t),dyo=i(W),Wp=n(W,"LI",{});var Hje=s(Wp);k_e=n(Hje,"STRONG",{});var XSt=s(k_e);myo=r(XSt,"vit_msn"),XSt.forEach(t),cyo=r(Hje," \u2014 "),VV=n(Hje,"A",{href:!0});var zSt=s(VV);fyo=r(zSt,"ViTFeatureExtractor"),zSt.forEach(t),gyo=r(Hje," (ViTMSN model)"),Hje.forEach(t),hyo=i(W),Up=n(W,"LI",{});var Jje=s(Up);S_e=n(Jje,"STRONG",{});var QSt=s(S_e);uyo=r(QSt,"wav2vec2"),QSt.forEach(t),pyo=r(Jje," \u2014 "),XV=n(Jje,"A",{href:!0});var WSt=s(XV);_yo=r(WSt,"Wav2Vec2FeatureExtractor"),WSt.forEach(t),byo=r(Jje," (Wav2Vec2 model)"),Jje.forEach(t),vyo=i(W),Hp=n(W,"LI",{});var Yje=s(Hp);R_e=n(Yje,"STRONG",{});var USt=s(R_e);Fyo=r(USt,"wav2vec2-conformer"),USt.forEach(t),Tyo=r(Yje," \u2014 "),zV=n(Yje,"A",{href:!0});var HSt=s(zV);Myo=r(HSt,"Wav2Vec2FeatureExtractor"),HSt.forEach(t),Eyo=r(Yje," (Wav2Vec2-Conformer model)"),Yje.forEach(t),Cyo=i(W),Jp=n(W,"LI",{});var Zje=s(Jp);P_e=n(Zje,"STRONG",{});var JSt=s(P_e);wyo=r(JSt,"whisper"),JSt.forEach(t),Ayo=r(Zje," \u2014 "),QV=n(Zje,"A",{href:!0});var YSt=s(QV);Lyo=r(YSt,"WhisperFeatureExtractor"),YSt.forEach(t),yyo=r(Zje," (Whisper model)"),Zje.forEach(t),xyo=i(W),Yp=n(W,"LI",{});var Kje=s(Yp);B_e=n(Kje,"STRONG",{});var ZSt=s(B_e);$yo=r(ZSt,"xclip"),ZSt.forEach(t),kyo=r(Kje," \u2014 "),WV=n(Kje,"A",{href:!0});var KSt=s(WV);Syo=r(KSt,"CLIPFeatureExtractor"),KSt.forEach(t),Ryo=r(Kje," (X-CLIP model)"),Kje.forEach(t),Pyo=i(W),Zp=n(W,"LI",{});var eDe=s(Zp);I_e=n(eDe,"STRONG",{});var eRt=s(I_e);Byo=r(eRt,"yolos"),eRt.forEach(t),Iyo=r(eDe," \u2014 "),UV=n(eDe,"A",{href:!0});var oRt=s(UV);Nyo=r(oRt,"YolosFeatureExtractor"),oRt.forEach(t),qyo=r(eDe," (YOLOS model)"),eDe.forEach(t),W.forEach(t),jyo=i(Ca),T(Kp.$$.fragment,Ca),Dyo=i(Ca),T(e_.$$.fragment,Ca),Ca.forEach(t),Gyo=i(Bl),o_=n(Bl,"DIV",{class:!0});var Pno=s(o_);T(C$.$$.fragment,Pno),Oyo=i(Pno),N_e=n(Pno,"P",{});var rRt=s(N_e);Vyo=r(rRt,"Register a new feature extractor for this class."),rRt.forEach(t),Pno.forEach(t),Bl.forEach(t),vto=i(c),yd=n(c,"H2",{class:!0});var Bno=s(yd);r_=n(Bno,"A",{id:!0,class:!0,href:!0});var tRt=s(r_);q_e=n(tRt,"SPAN",{});var aRt=s(q_e);T(w$.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),Xyo=i(Bno),j_e=n(Bno,"SPAN",{});var nRt=s(j_e);zyo=r(nRt,"AutoProcessor"),nRt.forEach(t),Bno.forEach(t),Fto=i(c),Bo=n(c,"DIV",{class:!0});var Il=s(Bo);T(A$.$$.fragment,Il),Qyo=i(Il),L$=n(Il,"P",{});var Ino=s(L$);Wyo=r(Ino,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),HV=n(Ino,"A",{href:!0});var sRt=s(HV);Uyo=r(sRt,"AutoProcessor.from_pretrained()"),sRt.forEach(t),Hyo=r(Ino," class method."),Ino.forEach(t),Jyo=i(Il),y$=n(Il,"P",{});var Nno=s(y$);Yyo=r(Nno,"This class cannot be instantiated directly using "),D_e=n(Nno,"CODE",{});var lRt=s(D_e);Zyo=r(lRt,"__init__()"),lRt.forEach(t),Kyo=r(Nno," (throws an error)."),Nno.forEach(t),e9o=i(Il),Ze=n(Il,"DIV",{class:!0});var wa=s(Ze);T(x$.$$.fragment,wa),o9o=i(wa),G_e=n(wa,"P",{});var iRt=s(G_e);r9o=r(iRt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),iRt.forEach(t),t9o=i(wa),xd=n(wa,"P",{});var Wde=s(xd);a9o=r(Wde,"The processor class to instantiate is selected based on the "),O_e=n(Wde,"CODE",{});var dRt=s(O_e);n9o=r(dRt,"model_type"),dRt.forEach(t),s9o=r(Wde,` property of the config object (either
passed as an argument or loaded from `),V_e=n(Wde,"CODE",{});var mRt=s(V_e);l9o=r(mRt,"pretrained_model_name_or_path"),mRt.forEach(t),i9o=r(Wde," if possible):"),Wde.forEach(t),d9o=i(wa),se=n(wa,"UL",{});var de=s(se);t_=n(de,"LI",{});var oDe=s(t_);X_e=n(oDe,"STRONG",{});var cRt=s(X_e);m9o=r(cRt,"clip"),cRt.forEach(t),c9o=r(oDe," \u2014 "),JV=n(oDe,"A",{href:!0});var fRt=s(JV);f9o=r(fRt,"CLIPProcessor"),fRt.forEach(t),g9o=r(oDe," (CLIP model)"),oDe.forEach(t),h9o=i(de),a_=n(de,"LI",{});var rDe=s(a_);z_e=n(rDe,"STRONG",{});var gRt=s(z_e);u9o=r(gRt,"donut"),gRt.forEach(t),p9o=r(rDe," \u2014 "),YV=n(rDe,"A",{href:!0});var hRt=s(YV);_9o=r(hRt,"DonutProcessor"),hRt.forEach(t),b9o=r(rDe," (Donut model)"),rDe.forEach(t),v9o=i(de),n_=n(de,"LI",{});var tDe=s(n_);Q_e=n(tDe,"STRONG",{});var uRt=s(Q_e);F9o=r(uRt,"flava"),uRt.forEach(t),T9o=r(tDe," \u2014 "),ZV=n(tDe,"A",{href:!0});var pRt=s(ZV);M9o=r(pRt,"FlavaProcessor"),pRt.forEach(t),E9o=r(tDe," (FLAVA model)"),tDe.forEach(t),C9o=i(de),s_=n(de,"LI",{});var aDe=s(s_);W_e=n(aDe,"STRONG",{});var _Rt=s(W_e);w9o=r(_Rt,"groupvit"),_Rt.forEach(t),A9o=r(aDe," \u2014 "),KV=n(aDe,"A",{href:!0});var bRt=s(KV);L9o=r(bRt,"CLIPProcessor"),bRt.forEach(t),y9o=r(aDe," (GroupViT model)"),aDe.forEach(t),x9o=i(de),l_=n(de,"LI",{});var nDe=s(l_);U_e=n(nDe,"STRONG",{});var vRt=s(U_e);$9o=r(vRt,"layoutlmv2"),vRt.forEach(t),k9o=r(nDe," \u2014 "),eX=n(nDe,"A",{href:!0});var FRt=s(eX);S9o=r(FRt,"LayoutLMv2Processor"),FRt.forEach(t),R9o=r(nDe," (LayoutLMv2 model)"),nDe.forEach(t),P9o=i(de),i_=n(de,"LI",{});var sDe=s(i_);H_e=n(sDe,"STRONG",{});var TRt=s(H_e);B9o=r(TRt,"layoutlmv3"),TRt.forEach(t),I9o=r(sDe," \u2014 "),oX=n(sDe,"A",{href:!0});var MRt=s(oX);N9o=r(MRt,"LayoutLMv3Processor"),MRt.forEach(t),q9o=r(sDe," (LayoutLMv3 model)"),sDe.forEach(t),j9o=i(de),d_=n(de,"LI",{});var lDe=s(d_);J_e=n(lDe,"STRONG",{});var ERt=s(J_e);D9o=r(ERt,"layoutxlm"),ERt.forEach(t),G9o=r(lDe," \u2014 "),rX=n(lDe,"A",{href:!0});var CRt=s(rX);O9o=r(CRt,"LayoutXLMProcessor"),CRt.forEach(t),V9o=r(lDe," (LayoutXLM model)"),lDe.forEach(t),X9o=i(de),m_=n(de,"LI",{});var iDe=s(m_);Y_e=n(iDe,"STRONG",{});var wRt=s(Y_e);z9o=r(wRt,"markuplm"),wRt.forEach(t),Q9o=r(iDe," \u2014 "),tX=n(iDe,"A",{href:!0});var ARt=s(tX);W9o=r(ARt,"MarkupLMProcessor"),ARt.forEach(t),U9o=r(iDe," (MarkupLM model)"),iDe.forEach(t),H9o=i(de),c_=n(de,"LI",{});var dDe=s(c_);Z_e=n(dDe,"STRONG",{});var LRt=s(Z_e);J9o=r(LRt,"owlvit"),LRt.forEach(t),Y9o=r(dDe," \u2014 "),aX=n(dDe,"A",{href:!0});var yRt=s(aX);Z9o=r(yRt,"OwlViTProcessor"),yRt.forEach(t),K9o=r(dDe," (OWL-ViT model)"),dDe.forEach(t),exo=i(de),f_=n(de,"LI",{});var mDe=s(f_);K_e=n(mDe,"STRONG",{});var xRt=s(K_e);oxo=r(xRt,"sew"),xRt.forEach(t),rxo=r(mDe," \u2014 "),nX=n(mDe,"A",{href:!0});var $Rt=s(nX);txo=r($Rt,"Wav2Vec2Processor"),$Rt.forEach(t),axo=r(mDe," (SEW model)"),mDe.forEach(t),nxo=i(de),g_=n(de,"LI",{});var cDe=s(g_);e1e=n(cDe,"STRONG",{});var kRt=s(e1e);sxo=r(kRt,"sew-d"),kRt.forEach(t),lxo=r(cDe," \u2014 "),sX=n(cDe,"A",{href:!0});var SRt=s(sX);ixo=r(SRt,"Wav2Vec2Processor"),SRt.forEach(t),dxo=r(cDe," (SEW-D model)"),cDe.forEach(t),mxo=i(de),h_=n(de,"LI",{});var fDe=s(h_);o1e=n(fDe,"STRONG",{});var RRt=s(o1e);cxo=r(RRt,"speech_to_text"),RRt.forEach(t),fxo=r(fDe," \u2014 "),lX=n(fDe,"A",{href:!0});var PRt=s(lX);gxo=r(PRt,"Speech2TextProcessor"),PRt.forEach(t),hxo=r(fDe," (Speech2Text model)"),fDe.forEach(t),uxo=i(de),u_=n(de,"LI",{});var gDe=s(u_);r1e=n(gDe,"STRONG",{});var BRt=s(r1e);pxo=r(BRt,"speech_to_text_2"),BRt.forEach(t),_xo=r(gDe," \u2014 "),iX=n(gDe,"A",{href:!0});var IRt=s(iX);bxo=r(IRt,"Speech2Text2Processor"),IRt.forEach(t),vxo=r(gDe," (Speech2Text2 model)"),gDe.forEach(t),Fxo=i(de),p_=n(de,"LI",{});var hDe=s(p_);t1e=n(hDe,"STRONG",{});var NRt=s(t1e);Txo=r(NRt,"trocr"),NRt.forEach(t),Mxo=r(hDe," \u2014 "),dX=n(hDe,"A",{href:!0});var qRt=s(dX);Exo=r(qRt,"TrOCRProcessor"),qRt.forEach(t),Cxo=r(hDe," (TrOCR model)"),hDe.forEach(t),wxo=i(de),__=n(de,"LI",{});var uDe=s(__);a1e=n(uDe,"STRONG",{});var jRt=s(a1e);Axo=r(jRt,"unispeech"),jRt.forEach(t),Lxo=r(uDe," \u2014 "),mX=n(uDe,"A",{href:!0});var DRt=s(mX);yxo=r(DRt,"Wav2Vec2Processor"),DRt.forEach(t),xxo=r(uDe," (UniSpeech model)"),uDe.forEach(t),$xo=i(de),b_=n(de,"LI",{});var pDe=s(b_);n1e=n(pDe,"STRONG",{});var GRt=s(n1e);kxo=r(GRt,"unispeech-sat"),GRt.forEach(t),Sxo=r(pDe," \u2014 "),cX=n(pDe,"A",{href:!0});var ORt=s(cX);Rxo=r(ORt,"Wav2Vec2Processor"),ORt.forEach(t),Pxo=r(pDe," (UniSpeechSat model)"),pDe.forEach(t),Bxo=i(de),v_=n(de,"LI",{});var _De=s(v_);s1e=n(_De,"STRONG",{});var VRt=s(s1e);Ixo=r(VRt,"vilt"),VRt.forEach(t),Nxo=r(_De," \u2014 "),fX=n(_De,"A",{href:!0});var XRt=s(fX);qxo=r(XRt,"ViltProcessor"),XRt.forEach(t),jxo=r(_De," (ViLT model)"),_De.forEach(t),Dxo=i(de),F_=n(de,"LI",{});var bDe=s(F_);l1e=n(bDe,"STRONG",{});var zRt=s(l1e);Gxo=r(zRt,"vision-text-dual-encoder"),zRt.forEach(t),Oxo=r(bDe," \u2014 "),gX=n(bDe,"A",{href:!0});var QRt=s(gX);Vxo=r(QRt,"VisionTextDualEncoderProcessor"),QRt.forEach(t),Xxo=r(bDe," (VisionTextDualEncoder model)"),bDe.forEach(t),zxo=i(de),T_=n(de,"LI",{});var vDe=s(T_);i1e=n(vDe,"STRONG",{});var WRt=s(i1e);Qxo=r(WRt,"wav2vec2"),WRt.forEach(t),Wxo=r(vDe," \u2014 "),hX=n(vDe,"A",{href:!0});var URt=s(hX);Uxo=r(URt,"Wav2Vec2Processor"),URt.forEach(t),Hxo=r(vDe," (Wav2Vec2 model)"),vDe.forEach(t),Jxo=i(de),M_=n(de,"LI",{});var FDe=s(M_);d1e=n(FDe,"STRONG",{});var HRt=s(d1e);Yxo=r(HRt,"wav2vec2-conformer"),HRt.forEach(t),Zxo=r(FDe," \u2014 "),uX=n(FDe,"A",{href:!0});var JRt=s(uX);Kxo=r(JRt,"Wav2Vec2Processor"),JRt.forEach(t),e$o=r(FDe," (Wav2Vec2-Conformer model)"),FDe.forEach(t),o$o=i(de),E_=n(de,"LI",{});var TDe=s(E_);m1e=n(TDe,"STRONG",{});var YRt=s(m1e);r$o=r(YRt,"wavlm"),YRt.forEach(t),t$o=r(TDe," \u2014 "),pX=n(TDe,"A",{href:!0});var ZRt=s(pX);a$o=r(ZRt,"Wav2Vec2Processor"),ZRt.forEach(t),n$o=r(TDe," (WavLM model)"),TDe.forEach(t),s$o=i(de),C_=n(de,"LI",{});var MDe=s(C_);c1e=n(MDe,"STRONG",{});var KRt=s(c1e);l$o=r(KRt,"whisper"),KRt.forEach(t),i$o=r(MDe," \u2014 "),_X=n(MDe,"A",{href:!0});var ePt=s(_X);d$o=r(ePt,"WhisperProcessor"),ePt.forEach(t),m$o=r(MDe," (Whisper model)"),MDe.forEach(t),c$o=i(de),w_=n(de,"LI",{});var EDe=s(w_);f1e=n(EDe,"STRONG",{});var oPt=s(f1e);f$o=r(oPt,"xclip"),oPt.forEach(t),g$o=r(EDe," \u2014 "),bX=n(EDe,"A",{href:!0});var rPt=s(bX);h$o=r(rPt,"XCLIPProcessor"),rPt.forEach(t),u$o=r(EDe," (X-CLIP model)"),EDe.forEach(t),de.forEach(t),p$o=i(wa),T(A_.$$.fragment,wa),_$o=i(wa),T(L_.$$.fragment,wa),wa.forEach(t),b$o=i(Il),y_=n(Il,"DIV",{class:!0});var qno=s(y_);T($$.$$.fragment,qno),v$o=i(qno),g1e=n(qno,"P",{});var tPt=s(g1e);F$o=r(tPt,"Register a new processor for this class."),tPt.forEach(t),qno.forEach(t),Il.forEach(t),Tto=i(c),$d=n(c,"H2",{class:!0});var jno=s($d);x_=n(jno,"A",{id:!0,class:!0,href:!0});var aPt=s(x_);h1e=n(aPt,"SPAN",{});var nPt=s(h1e);T(k$.$$.fragment,nPt),nPt.forEach(t),aPt.forEach(t),T$o=i(jno),u1e=n(jno,"SPAN",{});var sPt=s(u1e);M$o=r(sPt,"AutoModel"),sPt.forEach(t),jno.forEach(t),Mto=i(c),Io=n(c,"DIV",{class:!0});var Nl=s(Io);T(S$.$$.fragment,Nl),E$o=i(Nl),kd=n(Nl,"P",{});var Ude=s(kd);C$o=r(Ude,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),vX=n(Ude,"A",{href:!0});var lPt=s(vX);w$o=r(lPt,"from_pretrained()"),lPt.forEach(t),A$o=r(Ude," class method or the "),FX=n(Ude,"A",{href:!0});var iPt=s(FX);L$o=r(iPt,"from_config()"),iPt.forEach(t),y$o=r(Ude,` class
method.`),Ude.forEach(t),x$o=i(Nl),R$=n(Nl,"P",{});var Dno=s(R$);$$o=r(Dno,"This class cannot be instantiated directly using "),p1e=n(Dno,"CODE",{});var dPt=s(p1e);k$o=r(dPt,"__init__()"),dPt.forEach(t),S$o=r(Dno," (throws an error)."),Dno.forEach(t),R$o=i(Nl),Tt=n(Nl,"DIV",{class:!0});var Hy=s(Tt);T(P$.$$.fragment,Hy),P$o=i(Hy),_1e=n(Hy,"P",{});var mPt=s(_1e);B$o=r(mPt,"Instantiates one of the base model classes of the library from a configuration."),mPt.forEach(t),I$o=i(Hy),Sd=n(Hy,"P",{});var Hde=s(Sd);N$o=r(Hde,`Note:
Loading a model from its configuration file does `),b1e=n(Hde,"STRONG",{});var cPt=s(b1e);q$o=r(cPt,"not"),cPt.forEach(t),j$o=r(Hde,` load the model weights. It only affects the
model\u2019s configuration. Use `),TX=n(Hde,"A",{href:!0});var fPt=s(TX);D$o=r(fPt,"from_pretrained()"),fPt.forEach(t),G$o=r(Hde," to load the model weights."),Hde.forEach(t),O$o=i(Hy),T($_.$$.fragment,Hy),Hy.forEach(t),V$o=i(Nl),Ke=n(Nl,"DIV",{class:!0});var Aa=s(Ke);T(B$.$$.fragment,Aa),X$o=i(Aa),v1e=n(Aa,"P",{});var gPt=s(v1e);z$o=r(gPt,"Instantiate one of the base model classes of the library from a pretrained model."),gPt.forEach(t),Q$o=i(Aa),an=n(Aa,"P",{});var Jy=s(an);W$o=r(Jy,"The model class to instantiate is selected based on the "),F1e=n(Jy,"CODE",{});var hPt=s(F1e);U$o=r(hPt,"model_type"),hPt.forEach(t),H$o=r(Jy,` property of the config object (either
passed as an argument or loaded from `),T1e=n(Jy,"CODE",{});var uPt=s(T1e);J$o=r(uPt,"pretrained_model_name_or_path"),uPt.forEach(t),Y$o=r(Jy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M1e=n(Jy,"CODE",{});var pPt=s(M1e);Z$o=r(pPt,"pretrained_model_name_or_path"),pPt.forEach(t),K$o=r(Jy,":"),Jy.forEach(t),eko=i(Aa),y=n(Aa,"UL",{});var x=s(y);k_=n(x,"LI",{});var CDe=s(k_);E1e=n(CDe,"STRONG",{});var _Pt=s(E1e);oko=r(_Pt,"albert"),_Pt.forEach(t),rko=r(CDe," \u2014 "),MX=n(CDe,"A",{href:!0});var bPt=s(MX);tko=r(bPt,"AlbertModel"),bPt.forEach(t),ako=r(CDe," (ALBERT model)"),CDe.forEach(t),nko=i(x),S_=n(x,"LI",{});var wDe=s(S_);C1e=n(wDe,"STRONG",{});var vPt=s(C1e);sko=r(vPt,"bart"),vPt.forEach(t),lko=r(wDe," \u2014 "),EX=n(wDe,"A",{href:!0});var FPt=s(EX);iko=r(FPt,"BartModel"),FPt.forEach(t),dko=r(wDe," (BART model)"),wDe.forEach(t),mko=i(x),R_=n(x,"LI",{});var ADe=s(R_);w1e=n(ADe,"STRONG",{});var TPt=s(w1e);cko=r(TPt,"beit"),TPt.forEach(t),fko=r(ADe," \u2014 "),CX=n(ADe,"A",{href:!0});var MPt=s(CX);gko=r(MPt,"BeitModel"),MPt.forEach(t),hko=r(ADe," (BEiT model)"),ADe.forEach(t),uko=i(x),P_=n(x,"LI",{});var LDe=s(P_);A1e=n(LDe,"STRONG",{});var EPt=s(A1e);pko=r(EPt,"bert"),EPt.forEach(t),_ko=r(LDe," \u2014 "),wX=n(LDe,"A",{href:!0});var CPt=s(wX);bko=r(CPt,"BertModel"),CPt.forEach(t),vko=r(LDe," (BERT model)"),LDe.forEach(t),Fko=i(x),B_=n(x,"LI",{});var yDe=s(B_);L1e=n(yDe,"STRONG",{});var wPt=s(L1e);Tko=r(wPt,"bert-generation"),wPt.forEach(t),Mko=r(yDe," \u2014 "),AX=n(yDe,"A",{href:!0});var APt=s(AX);Eko=r(APt,"BertGenerationEncoder"),APt.forEach(t),Cko=r(yDe," (Bert Generation model)"),yDe.forEach(t),wko=i(x),I_=n(x,"LI",{});var xDe=s(I_);y1e=n(xDe,"STRONG",{});var LPt=s(y1e);Ako=r(LPt,"big_bird"),LPt.forEach(t),Lko=r(xDe," \u2014 "),LX=n(xDe,"A",{href:!0});var yPt=s(LX);yko=r(yPt,"BigBirdModel"),yPt.forEach(t),xko=r(xDe," (BigBird model)"),xDe.forEach(t),$ko=i(x),N_=n(x,"LI",{});var $De=s(N_);x1e=n($De,"STRONG",{});var xPt=s(x1e);kko=r(xPt,"bigbird_pegasus"),xPt.forEach(t),Sko=r($De," \u2014 "),yX=n($De,"A",{href:!0});var $Pt=s(yX);Rko=r($Pt,"BigBirdPegasusModel"),$Pt.forEach(t),Pko=r($De," (BigBird-Pegasus model)"),$De.forEach(t),Bko=i(x),q_=n(x,"LI",{});var kDe=s(q_);$1e=n(kDe,"STRONG",{});var kPt=s($1e);Iko=r(kPt,"blenderbot"),kPt.forEach(t),Nko=r(kDe," \u2014 "),xX=n(kDe,"A",{href:!0});var SPt=s(xX);qko=r(SPt,"BlenderbotModel"),SPt.forEach(t),jko=r(kDe," (Blenderbot model)"),kDe.forEach(t),Dko=i(x),j_=n(x,"LI",{});var SDe=s(j_);k1e=n(SDe,"STRONG",{});var RPt=s(k1e);Gko=r(RPt,"blenderbot-small"),RPt.forEach(t),Oko=r(SDe," \u2014 "),$X=n(SDe,"A",{href:!0});var PPt=s($X);Vko=r(PPt,"BlenderbotSmallModel"),PPt.forEach(t),Xko=r(SDe," (BlenderbotSmall model)"),SDe.forEach(t),zko=i(x),D_=n(x,"LI",{});var RDe=s(D_);S1e=n(RDe,"STRONG",{});var BPt=s(S1e);Qko=r(BPt,"bloom"),BPt.forEach(t),Wko=r(RDe," \u2014 "),kX=n(RDe,"A",{href:!0});var IPt=s(kX);Uko=r(IPt,"BloomModel"),IPt.forEach(t),Hko=r(RDe," (BLOOM model)"),RDe.forEach(t),Jko=i(x),G_=n(x,"LI",{});var PDe=s(G_);R1e=n(PDe,"STRONG",{});var NPt=s(R1e);Yko=r(NPt,"camembert"),NPt.forEach(t),Zko=r(PDe," \u2014 "),SX=n(PDe,"A",{href:!0});var qPt=s(SX);Kko=r(qPt,"CamembertModel"),qPt.forEach(t),eSo=r(PDe," (CamemBERT model)"),PDe.forEach(t),oSo=i(x),O_=n(x,"LI",{});var BDe=s(O_);P1e=n(BDe,"STRONG",{});var jPt=s(P1e);rSo=r(jPt,"canine"),jPt.forEach(t),tSo=r(BDe," \u2014 "),RX=n(BDe,"A",{href:!0});var DPt=s(RX);aSo=r(DPt,"CanineModel"),DPt.forEach(t),nSo=r(BDe," (CANINE model)"),BDe.forEach(t),sSo=i(x),V_=n(x,"LI",{});var IDe=s(V_);B1e=n(IDe,"STRONG",{});var GPt=s(B1e);lSo=r(GPt,"clip"),GPt.forEach(t),iSo=r(IDe," \u2014 "),PX=n(IDe,"A",{href:!0});var OPt=s(PX);dSo=r(OPt,"CLIPModel"),OPt.forEach(t),mSo=r(IDe," (CLIP model)"),IDe.forEach(t),cSo=i(x),X_=n(x,"LI",{});var NDe=s(X_);I1e=n(NDe,"STRONG",{});var VPt=s(I1e);fSo=r(VPt,"codegen"),VPt.forEach(t),gSo=r(NDe," \u2014 "),BX=n(NDe,"A",{href:!0});var XPt=s(BX);hSo=r(XPt,"CodeGenModel"),XPt.forEach(t),uSo=r(NDe," (CodeGen model)"),NDe.forEach(t),pSo=i(x),z_=n(x,"LI",{});var qDe=s(z_);N1e=n(qDe,"STRONG",{});var zPt=s(N1e);_So=r(zPt,"conditional_detr"),zPt.forEach(t),bSo=r(qDe," \u2014 "),IX=n(qDe,"A",{href:!0});var QPt=s(IX);vSo=r(QPt,"ConditionalDetrModel"),QPt.forEach(t),FSo=r(qDe," (Conditional DETR model)"),qDe.forEach(t),TSo=i(x),Q_=n(x,"LI",{});var jDe=s(Q_);q1e=n(jDe,"STRONG",{});var WPt=s(q1e);MSo=r(WPt,"convbert"),WPt.forEach(t),ESo=r(jDe," \u2014 "),NX=n(jDe,"A",{href:!0});var UPt=s(NX);CSo=r(UPt,"ConvBertModel"),UPt.forEach(t),wSo=r(jDe," (ConvBERT model)"),jDe.forEach(t),ASo=i(x),W_=n(x,"LI",{});var DDe=s(W_);j1e=n(DDe,"STRONG",{});var HPt=s(j1e);LSo=r(HPt,"convnext"),HPt.forEach(t),ySo=r(DDe," \u2014 "),qX=n(DDe,"A",{href:!0});var JPt=s(qX);xSo=r(JPt,"ConvNextModel"),JPt.forEach(t),$So=r(DDe," (ConvNeXT model)"),DDe.forEach(t),kSo=i(x),U_=n(x,"LI",{});var GDe=s(U_);D1e=n(GDe,"STRONG",{});var YPt=s(D1e);SSo=r(YPt,"ctrl"),YPt.forEach(t),RSo=r(GDe," \u2014 "),jX=n(GDe,"A",{href:!0});var ZPt=s(jX);PSo=r(ZPt,"CTRLModel"),ZPt.forEach(t),BSo=r(GDe," (CTRL model)"),GDe.forEach(t),ISo=i(x),H_=n(x,"LI",{});var ODe=s(H_);G1e=n(ODe,"STRONG",{});var KPt=s(G1e);NSo=r(KPt,"cvt"),KPt.forEach(t),qSo=r(ODe," \u2014 "),DX=n(ODe,"A",{href:!0});var eBt=s(DX);jSo=r(eBt,"CvtModel"),eBt.forEach(t),DSo=r(ODe," (CvT model)"),ODe.forEach(t),GSo=i(x),J_=n(x,"LI",{});var VDe=s(J_);O1e=n(VDe,"STRONG",{});var oBt=s(O1e);OSo=r(oBt,"data2vec-audio"),oBt.forEach(t),VSo=r(VDe," \u2014 "),GX=n(VDe,"A",{href:!0});var rBt=s(GX);XSo=r(rBt,"Data2VecAudioModel"),rBt.forEach(t),zSo=r(VDe," (Data2VecAudio model)"),VDe.forEach(t),QSo=i(x),Y_=n(x,"LI",{});var XDe=s(Y_);V1e=n(XDe,"STRONG",{});var tBt=s(V1e);WSo=r(tBt,"data2vec-text"),tBt.forEach(t),USo=r(XDe," \u2014 "),OX=n(XDe,"A",{href:!0});var aBt=s(OX);HSo=r(aBt,"Data2VecTextModel"),aBt.forEach(t),JSo=r(XDe," (Data2VecText model)"),XDe.forEach(t),YSo=i(x),Z_=n(x,"LI",{});var zDe=s(Z_);X1e=n(zDe,"STRONG",{});var nBt=s(X1e);ZSo=r(nBt,"data2vec-vision"),nBt.forEach(t),KSo=r(zDe," \u2014 "),VX=n(zDe,"A",{href:!0});var sBt=s(VX);eRo=r(sBt,"Data2VecVisionModel"),sBt.forEach(t),oRo=r(zDe," (Data2VecVision model)"),zDe.forEach(t),rRo=i(x),K_=n(x,"LI",{});var QDe=s(K_);z1e=n(QDe,"STRONG",{});var lBt=s(z1e);tRo=r(lBt,"deberta"),lBt.forEach(t),aRo=r(QDe," \u2014 "),XX=n(QDe,"A",{href:!0});var iBt=s(XX);nRo=r(iBt,"DebertaModel"),iBt.forEach(t),sRo=r(QDe," (DeBERTa model)"),QDe.forEach(t),lRo=i(x),e1=n(x,"LI",{});var WDe=s(e1);Q1e=n(WDe,"STRONG",{});var dBt=s(Q1e);iRo=r(dBt,"deberta-v2"),dBt.forEach(t),dRo=r(WDe," \u2014 "),zX=n(WDe,"A",{href:!0});var mBt=s(zX);mRo=r(mBt,"DebertaV2Model"),mBt.forEach(t),cRo=r(WDe," (DeBERTa-v2 model)"),WDe.forEach(t),fRo=i(x),o1=n(x,"LI",{});var UDe=s(o1);W1e=n(UDe,"STRONG",{});var cBt=s(W1e);gRo=r(cBt,"decision_transformer"),cBt.forEach(t),hRo=r(UDe," \u2014 "),QX=n(UDe,"A",{href:!0});var fBt=s(QX);uRo=r(fBt,"DecisionTransformerModel"),fBt.forEach(t),pRo=r(UDe," (Decision Transformer model)"),UDe.forEach(t),_Ro=i(x),r1=n(x,"LI",{});var HDe=s(r1);U1e=n(HDe,"STRONG",{});var gBt=s(U1e);bRo=r(gBt,"deformable_detr"),gBt.forEach(t),vRo=r(HDe," \u2014 "),WX=n(HDe,"A",{href:!0});var hBt=s(WX);FRo=r(hBt,"DeformableDetrModel"),hBt.forEach(t),TRo=r(HDe," (Deformable DETR model)"),HDe.forEach(t),MRo=i(x),t1=n(x,"LI",{});var JDe=s(t1);H1e=n(JDe,"STRONG",{});var uBt=s(H1e);ERo=r(uBt,"deit"),uBt.forEach(t),CRo=r(JDe," \u2014 "),UX=n(JDe,"A",{href:!0});var pBt=s(UX);wRo=r(pBt,"DeiTModel"),pBt.forEach(t),ARo=r(JDe," (DeiT model)"),JDe.forEach(t),LRo=i(x),a1=n(x,"LI",{});var YDe=s(a1);J1e=n(YDe,"STRONG",{});var _Bt=s(J1e);yRo=r(_Bt,"detr"),_Bt.forEach(t),xRo=r(YDe," \u2014 "),HX=n(YDe,"A",{href:!0});var bBt=s(HX);$Ro=r(bBt,"DetrModel"),bBt.forEach(t),kRo=r(YDe," (DETR model)"),YDe.forEach(t),SRo=i(x),n1=n(x,"LI",{});var ZDe=s(n1);Y1e=n(ZDe,"STRONG",{});var vBt=s(Y1e);RRo=r(vBt,"distilbert"),vBt.forEach(t),PRo=r(ZDe," \u2014 "),JX=n(ZDe,"A",{href:!0});var FBt=s(JX);BRo=r(FBt,"DistilBertModel"),FBt.forEach(t),IRo=r(ZDe," (DistilBERT model)"),ZDe.forEach(t),NRo=i(x),s1=n(x,"LI",{});var KDe=s(s1);Z1e=n(KDe,"STRONG",{});var TBt=s(Z1e);qRo=r(TBt,"donut-swin"),TBt.forEach(t),jRo=r(KDe," \u2014 "),YX=n(KDe,"A",{href:!0});var MBt=s(YX);DRo=r(MBt,"DonutSwinModel"),MBt.forEach(t),GRo=r(KDe," (DonutSwin model)"),KDe.forEach(t),ORo=i(x),l1=n(x,"LI",{});var eGe=s(l1);K1e=n(eGe,"STRONG",{});var EBt=s(K1e);VRo=r(EBt,"dpr"),EBt.forEach(t),XRo=r(eGe," \u2014 "),ZX=n(eGe,"A",{href:!0});var CBt=s(ZX);zRo=r(CBt,"DPRQuestionEncoder"),CBt.forEach(t),QRo=r(eGe," (DPR model)"),eGe.forEach(t),WRo=i(x),i1=n(x,"LI",{});var oGe=s(i1);e2e=n(oGe,"STRONG",{});var wBt=s(e2e);URo=r(wBt,"dpt"),wBt.forEach(t),HRo=r(oGe," \u2014 "),KX=n(oGe,"A",{href:!0});var ABt=s(KX);JRo=r(ABt,"DPTModel"),ABt.forEach(t),YRo=r(oGe," (DPT model)"),oGe.forEach(t),ZRo=i(x),d1=n(x,"LI",{});var rGe=s(d1);o2e=n(rGe,"STRONG",{});var LBt=s(o2e);KRo=r(LBt,"electra"),LBt.forEach(t),ePo=r(rGe," \u2014 "),ez=n(rGe,"A",{href:!0});var yBt=s(ez);oPo=r(yBt,"ElectraModel"),yBt.forEach(t),rPo=r(rGe," (ELECTRA model)"),rGe.forEach(t),tPo=i(x),m1=n(x,"LI",{});var tGe=s(m1);r2e=n(tGe,"STRONG",{});var xBt=s(r2e);aPo=r(xBt,"ernie"),xBt.forEach(t),nPo=r(tGe," \u2014 "),oz=n(tGe,"A",{href:!0});var $Bt=s(oz);sPo=r($Bt,"ErnieModel"),$Bt.forEach(t),lPo=r(tGe," (ERNIE model)"),tGe.forEach(t),iPo=i(x),c1=n(x,"LI",{});var aGe=s(c1);t2e=n(aGe,"STRONG",{});var kBt=s(t2e);dPo=r(kBt,"esm"),kBt.forEach(t),mPo=r(aGe," \u2014 "),rz=n(aGe,"A",{href:!0});var SBt=s(rz);cPo=r(SBt,"EsmModel"),SBt.forEach(t),fPo=r(aGe," (ESM model)"),aGe.forEach(t),gPo=i(x),f1=n(x,"LI",{});var nGe=s(f1);a2e=n(nGe,"STRONG",{});var RBt=s(a2e);hPo=r(RBt,"flaubert"),RBt.forEach(t),uPo=r(nGe," \u2014 "),tz=n(nGe,"A",{href:!0});var PBt=s(tz);pPo=r(PBt,"FlaubertModel"),PBt.forEach(t),_Po=r(nGe," (FlauBERT model)"),nGe.forEach(t),bPo=i(x),g1=n(x,"LI",{});var sGe=s(g1);n2e=n(sGe,"STRONG",{});var BBt=s(n2e);vPo=r(BBt,"flava"),BBt.forEach(t),FPo=r(sGe," \u2014 "),az=n(sGe,"A",{href:!0});var IBt=s(az);TPo=r(IBt,"FlavaModel"),IBt.forEach(t),MPo=r(sGe," (FLAVA model)"),sGe.forEach(t),EPo=i(x),h1=n(x,"LI",{});var lGe=s(h1);s2e=n(lGe,"STRONG",{});var NBt=s(s2e);CPo=r(NBt,"fnet"),NBt.forEach(t),wPo=r(lGe," \u2014 "),nz=n(lGe,"A",{href:!0});var qBt=s(nz);APo=r(qBt,"FNetModel"),qBt.forEach(t),LPo=r(lGe," (FNet model)"),lGe.forEach(t),yPo=i(x),u1=n(x,"LI",{});var iGe=s(u1);l2e=n(iGe,"STRONG",{});var jBt=s(l2e);xPo=r(jBt,"fsmt"),jBt.forEach(t),$Po=r(iGe," \u2014 "),sz=n(iGe,"A",{href:!0});var DBt=s(sz);kPo=r(DBt,"FSMTModel"),DBt.forEach(t),SPo=r(iGe," (FairSeq Machine-Translation model)"),iGe.forEach(t),RPo=i(x),yl=n(x,"LI",{});var fN=s(yl);i2e=n(fN,"STRONG",{});var GBt=s(i2e);PPo=r(GBt,"funnel"),GBt.forEach(t),BPo=r(fN," \u2014 "),lz=n(fN,"A",{href:!0});var OBt=s(lz);IPo=r(OBt,"FunnelModel"),OBt.forEach(t),NPo=r(fN," or "),iz=n(fN,"A",{href:!0});var VBt=s(iz);qPo=r(VBt,"FunnelBaseModel"),VBt.forEach(t),jPo=r(fN," (Funnel Transformer model)"),fN.forEach(t),DPo=i(x),p1=n(x,"LI",{});var dGe=s(p1);d2e=n(dGe,"STRONG",{});var XBt=s(d2e);GPo=r(XBt,"glpn"),XBt.forEach(t),OPo=r(dGe," \u2014 "),dz=n(dGe,"A",{href:!0});var zBt=s(dz);VPo=r(zBt,"GLPNModel"),zBt.forEach(t),XPo=r(dGe," (GLPN model)"),dGe.forEach(t),zPo=i(x),_1=n(x,"LI",{});var mGe=s(_1);m2e=n(mGe,"STRONG",{});var QBt=s(m2e);QPo=r(QBt,"gpt2"),QBt.forEach(t),WPo=r(mGe," \u2014 "),mz=n(mGe,"A",{href:!0});var WBt=s(mz);UPo=r(WBt,"GPT2Model"),WBt.forEach(t),HPo=r(mGe," (OpenAI GPT-2 model)"),mGe.forEach(t),JPo=i(x),b1=n(x,"LI",{});var cGe=s(b1);c2e=n(cGe,"STRONG",{});var UBt=s(c2e);YPo=r(UBt,"gpt_neo"),UBt.forEach(t),ZPo=r(cGe," \u2014 "),cz=n(cGe,"A",{href:!0});var HBt=s(cz);KPo=r(HBt,"GPTNeoModel"),HBt.forEach(t),eBo=r(cGe," (GPT Neo model)"),cGe.forEach(t),oBo=i(x),v1=n(x,"LI",{});var fGe=s(v1);f2e=n(fGe,"STRONG",{});var JBt=s(f2e);rBo=r(JBt,"gpt_neox"),JBt.forEach(t),tBo=r(fGe," \u2014 "),fz=n(fGe,"A",{href:!0});var YBt=s(fz);aBo=r(YBt,"GPTNeoXModel"),YBt.forEach(t),nBo=r(fGe," (GPT NeoX model)"),fGe.forEach(t),sBo=i(x),F1=n(x,"LI",{});var gGe=s(F1);g2e=n(gGe,"STRONG",{});var ZBt=s(g2e);lBo=r(ZBt,"gpt_neox_japanese"),ZBt.forEach(t),iBo=r(gGe," \u2014 "),gz=n(gGe,"A",{href:!0});var KBt=s(gz);dBo=r(KBt,"GPTNeoXJapaneseModel"),KBt.forEach(t),mBo=r(gGe," (GPT NeoX Japanese model)"),gGe.forEach(t),cBo=i(x),T1=n(x,"LI",{});var hGe=s(T1);h2e=n(hGe,"STRONG",{});var eIt=s(h2e);fBo=r(eIt,"gptj"),eIt.forEach(t),gBo=r(hGe," \u2014 "),hz=n(hGe,"A",{href:!0});var oIt=s(hz);hBo=r(oIt,"GPTJModel"),oIt.forEach(t),uBo=r(hGe," (GPT-J model)"),hGe.forEach(t),pBo=i(x),M1=n(x,"LI",{});var uGe=s(M1);u2e=n(uGe,"STRONG",{});var rIt=s(u2e);_Bo=r(rIt,"groupvit"),rIt.forEach(t),bBo=r(uGe," \u2014 "),uz=n(uGe,"A",{href:!0});var tIt=s(uz);vBo=r(tIt,"GroupViTModel"),tIt.forEach(t),FBo=r(uGe," (GroupViT model)"),uGe.forEach(t),TBo=i(x),E1=n(x,"LI",{});var pGe=s(E1);p2e=n(pGe,"STRONG",{});var aIt=s(p2e);MBo=r(aIt,"hubert"),aIt.forEach(t),EBo=r(pGe," \u2014 "),pz=n(pGe,"A",{href:!0});var nIt=s(pz);CBo=r(nIt,"HubertModel"),nIt.forEach(t),wBo=r(pGe," (Hubert model)"),pGe.forEach(t),ABo=i(x),C1=n(x,"LI",{});var _Ge=s(C1);_2e=n(_Ge,"STRONG",{});var sIt=s(_2e);LBo=r(sIt,"ibert"),sIt.forEach(t),yBo=r(_Ge," \u2014 "),_z=n(_Ge,"A",{href:!0});var lIt=s(_z);xBo=r(lIt,"IBertModel"),lIt.forEach(t),$Bo=r(_Ge," (I-BERT model)"),_Ge.forEach(t),kBo=i(x),w1=n(x,"LI",{});var bGe=s(w1);b2e=n(bGe,"STRONG",{});var iIt=s(b2e);SBo=r(iIt,"imagegpt"),iIt.forEach(t),RBo=r(bGe," \u2014 "),bz=n(bGe,"A",{href:!0});var dIt=s(bz);PBo=r(dIt,"ImageGPTModel"),dIt.forEach(t),BBo=r(bGe," (ImageGPT model)"),bGe.forEach(t),IBo=i(x),A1=n(x,"LI",{});var vGe=s(A1);v2e=n(vGe,"STRONG",{});var mIt=s(v2e);NBo=r(mIt,"layoutlm"),mIt.forEach(t),qBo=r(vGe," \u2014 "),vz=n(vGe,"A",{href:!0});var cIt=s(vz);jBo=r(cIt,"LayoutLMModel"),cIt.forEach(t),DBo=r(vGe," (LayoutLM model)"),vGe.forEach(t),GBo=i(x),L1=n(x,"LI",{});var FGe=s(L1);F2e=n(FGe,"STRONG",{});var fIt=s(F2e);OBo=r(fIt,"layoutlmv2"),fIt.forEach(t),VBo=r(FGe," \u2014 "),Fz=n(FGe,"A",{href:!0});var gIt=s(Fz);XBo=r(gIt,"LayoutLMv2Model"),gIt.forEach(t),zBo=r(FGe," (LayoutLMv2 model)"),FGe.forEach(t),QBo=i(x),y1=n(x,"LI",{});var TGe=s(y1);T2e=n(TGe,"STRONG",{});var hIt=s(T2e);WBo=r(hIt,"layoutlmv3"),hIt.forEach(t),UBo=r(TGe," \u2014 "),Tz=n(TGe,"A",{href:!0});var uIt=s(Tz);HBo=r(uIt,"LayoutLMv3Model"),uIt.forEach(t),JBo=r(TGe," (LayoutLMv3 model)"),TGe.forEach(t),YBo=i(x),x1=n(x,"LI",{});var MGe=s(x1);M2e=n(MGe,"STRONG",{});var pIt=s(M2e);ZBo=r(pIt,"led"),pIt.forEach(t),KBo=r(MGe," \u2014 "),Mz=n(MGe,"A",{href:!0});var _It=s(Mz);eIo=r(_It,"LEDModel"),_It.forEach(t),oIo=r(MGe," (LED model)"),MGe.forEach(t),rIo=i(x),$1=n(x,"LI",{});var EGe=s($1);E2e=n(EGe,"STRONG",{});var bIt=s(E2e);tIo=r(bIt,"levit"),bIt.forEach(t),aIo=r(EGe," \u2014 "),Ez=n(EGe,"A",{href:!0});var vIt=s(Ez);nIo=r(vIt,"LevitModel"),vIt.forEach(t),sIo=r(EGe," (LeViT model)"),EGe.forEach(t),lIo=i(x),k1=n(x,"LI",{});var CGe=s(k1);C2e=n(CGe,"STRONG",{});var FIt=s(C2e);iIo=r(FIt,"lilt"),FIt.forEach(t),dIo=r(CGe," \u2014 "),Cz=n(CGe,"A",{href:!0});var TIt=s(Cz);mIo=r(TIt,"LiltModel"),TIt.forEach(t),cIo=r(CGe," (LiLT model)"),CGe.forEach(t),fIo=i(x),S1=n(x,"LI",{});var wGe=s(S1);w2e=n(wGe,"STRONG",{});var MIt=s(w2e);gIo=r(MIt,"longformer"),MIt.forEach(t),hIo=r(wGe," \u2014 "),wz=n(wGe,"A",{href:!0});var EIt=s(wz);uIo=r(EIt,"LongformerModel"),EIt.forEach(t),pIo=r(wGe," (Longformer model)"),wGe.forEach(t),_Io=i(x),R1=n(x,"LI",{});var AGe=s(R1);A2e=n(AGe,"STRONG",{});var CIt=s(A2e);bIo=r(CIt,"longt5"),CIt.forEach(t),vIo=r(AGe," \u2014 "),Az=n(AGe,"A",{href:!0});var wIt=s(Az);FIo=r(wIt,"LongT5Model"),wIt.forEach(t),TIo=r(AGe," (LongT5 model)"),AGe.forEach(t),MIo=i(x),P1=n(x,"LI",{});var LGe=s(P1);L2e=n(LGe,"STRONG",{});var AIt=s(L2e);EIo=r(AIt,"luke"),AIt.forEach(t),CIo=r(LGe," \u2014 "),Lz=n(LGe,"A",{href:!0});var LIt=s(Lz);wIo=r(LIt,"LukeModel"),LIt.forEach(t),AIo=r(LGe," (LUKE model)"),LGe.forEach(t),LIo=i(x),B1=n(x,"LI",{});var yGe=s(B1);y2e=n(yGe,"STRONG",{});var yIt=s(y2e);yIo=r(yIt,"lxmert"),yIt.forEach(t),xIo=r(yGe," \u2014 "),yz=n(yGe,"A",{href:!0});var xIt=s(yz);$Io=r(xIt,"LxmertModel"),xIt.forEach(t),kIo=r(yGe," (LXMERT model)"),yGe.forEach(t),SIo=i(x),I1=n(x,"LI",{});var xGe=s(I1);x2e=n(xGe,"STRONG",{});var $It=s(x2e);RIo=r($It,"m2m_100"),$It.forEach(t),PIo=r(xGe," \u2014 "),xz=n(xGe,"A",{href:!0});var kIt=s(xz);BIo=r(kIt,"M2M100Model"),kIt.forEach(t),IIo=r(xGe," (M2M100 model)"),xGe.forEach(t),NIo=i(x),N1=n(x,"LI",{});var $Ge=s(N1);$2e=n($Ge,"STRONG",{});var SIt=s($2e);qIo=r(SIt,"marian"),SIt.forEach(t),jIo=r($Ge," \u2014 "),$z=n($Ge,"A",{href:!0});var RIt=s($z);DIo=r(RIt,"MarianModel"),RIt.forEach(t),GIo=r($Ge," (Marian model)"),$Ge.forEach(t),OIo=i(x),q1=n(x,"LI",{});var kGe=s(q1);k2e=n(kGe,"STRONG",{});var PIt=s(k2e);VIo=r(PIt,"markuplm"),PIt.forEach(t),XIo=r(kGe," \u2014 "),kz=n(kGe,"A",{href:!0});var BIt=s(kz);zIo=r(BIt,"MarkupLMModel"),BIt.forEach(t),QIo=r(kGe," (MarkupLM model)"),kGe.forEach(t),WIo=i(x),j1=n(x,"LI",{});var SGe=s(j1);S2e=n(SGe,"STRONG",{});var IIt=s(S2e);UIo=r(IIt,"maskformer"),IIt.forEach(t),HIo=r(SGe," \u2014 "),Sz=n(SGe,"A",{href:!0});var NIt=s(Sz);JIo=r(NIt,"MaskFormerModel"),NIt.forEach(t),YIo=r(SGe," (MaskFormer model)"),SGe.forEach(t),ZIo=i(x),D1=n(x,"LI",{});var RGe=s(D1);R2e=n(RGe,"STRONG",{});var qIt=s(R2e);KIo=r(qIt,"mbart"),qIt.forEach(t),eNo=r(RGe," \u2014 "),Rz=n(RGe,"A",{href:!0});var jIt=s(Rz);oNo=r(jIt,"MBartModel"),jIt.forEach(t),rNo=r(RGe," (mBART model)"),RGe.forEach(t),tNo=i(x),G1=n(x,"LI",{});var PGe=s(G1);P2e=n(PGe,"STRONG",{});var DIt=s(P2e);aNo=r(DIt,"mctct"),DIt.forEach(t),nNo=r(PGe," \u2014 "),Pz=n(PGe,"A",{href:!0});var GIt=s(Pz);sNo=r(GIt,"MCTCTModel"),GIt.forEach(t),lNo=r(PGe," (M-CTC-T model)"),PGe.forEach(t),iNo=i(x),O1=n(x,"LI",{});var BGe=s(O1);B2e=n(BGe,"STRONG",{});var OIt=s(B2e);dNo=r(OIt,"megatron-bert"),OIt.forEach(t),mNo=r(BGe," \u2014 "),Bz=n(BGe,"A",{href:!0});var VIt=s(Bz);cNo=r(VIt,"MegatronBertModel"),VIt.forEach(t),fNo=r(BGe," (Megatron-BERT model)"),BGe.forEach(t),gNo=i(x),V1=n(x,"LI",{});var IGe=s(V1);I2e=n(IGe,"STRONG",{});var XIt=s(I2e);hNo=r(XIt,"mobilebert"),XIt.forEach(t),uNo=r(IGe," \u2014 "),Iz=n(IGe,"A",{href:!0});var zIt=s(Iz);pNo=r(zIt,"MobileBertModel"),zIt.forEach(t),_No=r(IGe," (MobileBERT model)"),IGe.forEach(t),bNo=i(x),X1=n(x,"LI",{});var NGe=s(X1);N2e=n(NGe,"STRONG",{});var QIt=s(N2e);vNo=r(QIt,"mobilevit"),QIt.forEach(t),FNo=r(NGe," \u2014 "),Nz=n(NGe,"A",{href:!0});var WIt=s(Nz);TNo=r(WIt,"MobileViTModel"),WIt.forEach(t),MNo=r(NGe," (MobileViT model)"),NGe.forEach(t),ENo=i(x),z1=n(x,"LI",{});var qGe=s(z1);q2e=n(qGe,"STRONG",{});var UIt=s(q2e);CNo=r(UIt,"mpnet"),UIt.forEach(t),wNo=r(qGe," \u2014 "),qz=n(qGe,"A",{href:!0});var HIt=s(qz);ANo=r(HIt,"MPNetModel"),HIt.forEach(t),LNo=r(qGe," (MPNet model)"),qGe.forEach(t),yNo=i(x),Q1=n(x,"LI",{});var jGe=s(Q1);j2e=n(jGe,"STRONG",{});var JIt=s(j2e);xNo=r(JIt,"mt5"),JIt.forEach(t),$No=r(jGe," \u2014 "),jz=n(jGe,"A",{href:!0});var YIt=s(jz);kNo=r(YIt,"MT5Model"),YIt.forEach(t),SNo=r(jGe," (MT5 model)"),jGe.forEach(t),RNo=i(x),W1=n(x,"LI",{});var DGe=s(W1);D2e=n(DGe,"STRONG",{});var ZIt=s(D2e);PNo=r(ZIt,"mvp"),ZIt.forEach(t),BNo=r(DGe," \u2014 "),Dz=n(DGe,"A",{href:!0});var KIt=s(Dz);INo=r(KIt,"MvpModel"),KIt.forEach(t),NNo=r(DGe," (MVP model)"),DGe.forEach(t),qNo=i(x),U1=n(x,"LI",{});var GGe=s(U1);G2e=n(GGe,"STRONG",{});var eNt=s(G2e);jNo=r(eNt,"nezha"),eNt.forEach(t),DNo=r(GGe," \u2014 "),Gz=n(GGe,"A",{href:!0});var oNt=s(Gz);GNo=r(oNt,"NezhaModel"),oNt.forEach(t),ONo=r(GGe," (Nezha model)"),GGe.forEach(t),VNo=i(x),H1=n(x,"LI",{});var OGe=s(H1);O2e=n(OGe,"STRONG",{});var rNt=s(O2e);XNo=r(rNt,"nllb"),rNt.forEach(t),zNo=r(OGe," \u2014 "),Oz=n(OGe,"A",{href:!0});var tNt=s(Oz);QNo=r(tNt,"M2M100Model"),tNt.forEach(t),WNo=r(OGe," (NLLB model)"),OGe.forEach(t),UNo=i(x),J1=n(x,"LI",{});var VGe=s(J1);V2e=n(VGe,"STRONG",{});var aNt=s(V2e);HNo=r(aNt,"nystromformer"),aNt.forEach(t),JNo=r(VGe," \u2014 "),Vz=n(VGe,"A",{href:!0});var nNt=s(Vz);YNo=r(nNt,"NystromformerModel"),nNt.forEach(t),ZNo=r(VGe," (Nystr\xF6mformer model)"),VGe.forEach(t),KNo=i(x),Y1=n(x,"LI",{});var XGe=s(Y1);X2e=n(XGe,"STRONG",{});var sNt=s(X2e);eqo=r(sNt,"openai-gpt"),sNt.forEach(t),oqo=r(XGe," \u2014 "),Xz=n(XGe,"A",{href:!0});var lNt=s(Xz);rqo=r(lNt,"OpenAIGPTModel"),lNt.forEach(t),tqo=r(XGe," (OpenAI GPT model)"),XGe.forEach(t),aqo=i(x),Z1=n(x,"LI",{});var zGe=s(Z1);z2e=n(zGe,"STRONG",{});var iNt=s(z2e);nqo=r(iNt,"opt"),iNt.forEach(t),sqo=r(zGe," \u2014 "),zz=n(zGe,"A",{href:!0});var dNt=s(zz);lqo=r(dNt,"OPTModel"),dNt.forEach(t),iqo=r(zGe," (OPT model)"),zGe.forEach(t),dqo=i(x),K1=n(x,"LI",{});var QGe=s(K1);Q2e=n(QGe,"STRONG",{});var mNt=s(Q2e);mqo=r(mNt,"owlvit"),mNt.forEach(t),cqo=r(QGe," \u2014 "),Qz=n(QGe,"A",{href:!0});var cNt=s(Qz);fqo=r(cNt,"OwlViTModel"),cNt.forEach(t),gqo=r(QGe," (OWL-ViT model)"),QGe.forEach(t),hqo=i(x),e2=n(x,"LI",{});var WGe=s(e2);W2e=n(WGe,"STRONG",{});var fNt=s(W2e);uqo=r(fNt,"pegasus"),fNt.forEach(t),pqo=r(WGe," \u2014 "),Wz=n(WGe,"A",{href:!0});var gNt=s(Wz);_qo=r(gNt,"PegasusModel"),gNt.forEach(t),bqo=r(WGe," (Pegasus model)"),WGe.forEach(t),vqo=i(x),o2=n(x,"LI",{});var UGe=s(o2);U2e=n(UGe,"STRONG",{});var hNt=s(U2e);Fqo=r(hNt,"pegasus_x"),hNt.forEach(t),Tqo=r(UGe," \u2014 "),Uz=n(UGe,"A",{href:!0});var uNt=s(Uz);Mqo=r(uNt,"PegasusXModel"),uNt.forEach(t),Eqo=r(UGe," (PEGASUS-X model)"),UGe.forEach(t),Cqo=i(x),r2=n(x,"LI",{});var HGe=s(r2);H2e=n(HGe,"STRONG",{});var pNt=s(H2e);wqo=r(pNt,"perceiver"),pNt.forEach(t),Aqo=r(HGe," \u2014 "),Hz=n(HGe,"A",{href:!0});var _Nt=s(Hz);Lqo=r(_Nt,"PerceiverModel"),_Nt.forEach(t),yqo=r(HGe," (Perceiver model)"),HGe.forEach(t),xqo=i(x),t2=n(x,"LI",{});var JGe=s(t2);J2e=n(JGe,"STRONG",{});var bNt=s(J2e);$qo=r(bNt,"plbart"),bNt.forEach(t),kqo=r(JGe," \u2014 "),Jz=n(JGe,"A",{href:!0});var vNt=s(Jz);Sqo=r(vNt,"PLBartModel"),vNt.forEach(t),Rqo=r(JGe," (PLBart model)"),JGe.forEach(t),Pqo=i(x),a2=n(x,"LI",{});var YGe=s(a2);Y2e=n(YGe,"STRONG",{});var FNt=s(Y2e);Bqo=r(FNt,"poolformer"),FNt.forEach(t),Iqo=r(YGe," \u2014 "),Yz=n(YGe,"A",{href:!0});var TNt=s(Yz);Nqo=r(TNt,"PoolFormerModel"),TNt.forEach(t),qqo=r(YGe," (PoolFormer model)"),YGe.forEach(t),jqo=i(x),n2=n(x,"LI",{});var ZGe=s(n2);Z2e=n(ZGe,"STRONG",{});var MNt=s(Z2e);Dqo=r(MNt,"prophetnet"),MNt.forEach(t),Gqo=r(ZGe," \u2014 "),Zz=n(ZGe,"A",{href:!0});var ENt=s(Zz);Oqo=r(ENt,"ProphetNetModel"),ENt.forEach(t),Vqo=r(ZGe," (ProphetNet model)"),ZGe.forEach(t),Xqo=i(x),s2=n(x,"LI",{});var KGe=s(s2);K2e=n(KGe,"STRONG",{});var CNt=s(K2e);zqo=r(CNt,"qdqbert"),CNt.forEach(t),Qqo=r(KGe," \u2014 "),Kz=n(KGe,"A",{href:!0});var wNt=s(Kz);Wqo=r(wNt,"QDQBertModel"),wNt.forEach(t),Uqo=r(KGe," (QDQBert model)"),KGe.forEach(t),Hqo=i(x),l2=n(x,"LI",{});var eOe=s(l2);ebe=n(eOe,"STRONG",{});var ANt=s(ebe);Jqo=r(ANt,"reformer"),ANt.forEach(t),Yqo=r(eOe," \u2014 "),eQ=n(eOe,"A",{href:!0});var LNt=s(eQ);Zqo=r(LNt,"ReformerModel"),LNt.forEach(t),Kqo=r(eOe," (Reformer model)"),eOe.forEach(t),ejo=i(x),i2=n(x,"LI",{});var oOe=s(i2);obe=n(oOe,"STRONG",{});var yNt=s(obe);ojo=r(yNt,"regnet"),yNt.forEach(t),rjo=r(oOe," \u2014 "),oQ=n(oOe,"A",{href:!0});var xNt=s(oQ);tjo=r(xNt,"RegNetModel"),xNt.forEach(t),ajo=r(oOe," (RegNet model)"),oOe.forEach(t),njo=i(x),d2=n(x,"LI",{});var rOe=s(d2);rbe=n(rOe,"STRONG",{});var $Nt=s(rbe);sjo=r($Nt,"rembert"),$Nt.forEach(t),ljo=r(rOe," \u2014 "),rQ=n(rOe,"A",{href:!0});var kNt=s(rQ);ijo=r(kNt,"RemBertModel"),kNt.forEach(t),djo=r(rOe," (RemBERT model)"),rOe.forEach(t),mjo=i(x),m2=n(x,"LI",{});var tOe=s(m2);tbe=n(tOe,"STRONG",{});var SNt=s(tbe);cjo=r(SNt,"resnet"),SNt.forEach(t),fjo=r(tOe," \u2014 "),tQ=n(tOe,"A",{href:!0});var RNt=s(tQ);gjo=r(RNt,"ResNetModel"),RNt.forEach(t),hjo=r(tOe," (ResNet model)"),tOe.forEach(t),ujo=i(x),c2=n(x,"LI",{});var aOe=s(c2);abe=n(aOe,"STRONG",{});var PNt=s(abe);pjo=r(PNt,"retribert"),PNt.forEach(t),_jo=r(aOe," \u2014 "),aQ=n(aOe,"A",{href:!0});var BNt=s(aQ);bjo=r(BNt,"RetriBertModel"),BNt.forEach(t),vjo=r(aOe," (RetriBERT model)"),aOe.forEach(t),Fjo=i(x),f2=n(x,"LI",{});var nOe=s(f2);nbe=n(nOe,"STRONG",{});var INt=s(nbe);Tjo=r(INt,"roberta"),INt.forEach(t),Mjo=r(nOe," \u2014 "),nQ=n(nOe,"A",{href:!0});var NNt=s(nQ);Ejo=r(NNt,"RobertaModel"),NNt.forEach(t),Cjo=r(nOe," (RoBERTa model)"),nOe.forEach(t),wjo=i(x),g2=n(x,"LI",{});var sOe=s(g2);sbe=n(sOe,"STRONG",{});var qNt=s(sbe);Ajo=r(qNt,"roformer"),qNt.forEach(t),Ljo=r(sOe," \u2014 "),sQ=n(sOe,"A",{href:!0});var jNt=s(sQ);yjo=r(jNt,"RoFormerModel"),jNt.forEach(t),xjo=r(sOe," (RoFormer model)"),sOe.forEach(t),$jo=i(x),h2=n(x,"LI",{});var lOe=s(h2);lbe=n(lOe,"STRONG",{});var DNt=s(lbe);kjo=r(DNt,"segformer"),DNt.forEach(t),Sjo=r(lOe," \u2014 "),lQ=n(lOe,"A",{href:!0});var GNt=s(lQ);Rjo=r(GNt,"SegformerModel"),GNt.forEach(t),Pjo=r(lOe," (SegFormer model)"),lOe.forEach(t),Bjo=i(x),u2=n(x,"LI",{});var iOe=s(u2);ibe=n(iOe,"STRONG",{});var ONt=s(ibe);Ijo=r(ONt,"sew"),ONt.forEach(t),Njo=r(iOe," \u2014 "),iQ=n(iOe,"A",{href:!0});var VNt=s(iQ);qjo=r(VNt,"SEWModel"),VNt.forEach(t),jjo=r(iOe," (SEW model)"),iOe.forEach(t),Djo=i(x),p2=n(x,"LI",{});var dOe=s(p2);dbe=n(dOe,"STRONG",{});var XNt=s(dbe);Gjo=r(XNt,"sew-d"),XNt.forEach(t),Ojo=r(dOe," \u2014 "),dQ=n(dOe,"A",{href:!0});var zNt=s(dQ);Vjo=r(zNt,"SEWDModel"),zNt.forEach(t),Xjo=r(dOe," (SEW-D model)"),dOe.forEach(t),zjo=i(x),_2=n(x,"LI",{});var mOe=s(_2);mbe=n(mOe,"STRONG",{});var QNt=s(mbe);Qjo=r(QNt,"speech_to_text"),QNt.forEach(t),Wjo=r(mOe," \u2014 "),mQ=n(mOe,"A",{href:!0});var WNt=s(mQ);Ujo=r(WNt,"Speech2TextModel"),WNt.forEach(t),Hjo=r(mOe," (Speech2Text model)"),mOe.forEach(t),Jjo=i(x),b2=n(x,"LI",{});var cOe=s(b2);cbe=n(cOe,"STRONG",{});var UNt=s(cbe);Yjo=r(UNt,"splinter"),UNt.forEach(t),Zjo=r(cOe," \u2014 "),cQ=n(cOe,"A",{href:!0});var HNt=s(cQ);Kjo=r(HNt,"SplinterModel"),HNt.forEach(t),eDo=r(cOe," (Splinter model)"),cOe.forEach(t),oDo=i(x),v2=n(x,"LI",{});var fOe=s(v2);fbe=n(fOe,"STRONG",{});var JNt=s(fbe);rDo=r(JNt,"squeezebert"),JNt.forEach(t),tDo=r(fOe," \u2014 "),fQ=n(fOe,"A",{href:!0});var YNt=s(fQ);aDo=r(YNt,"SqueezeBertModel"),YNt.forEach(t),nDo=r(fOe," (SqueezeBERT model)"),fOe.forEach(t),sDo=i(x),F2=n(x,"LI",{});var gOe=s(F2);gbe=n(gOe,"STRONG",{});var ZNt=s(gbe);lDo=r(ZNt,"swin"),ZNt.forEach(t),iDo=r(gOe," \u2014 "),gQ=n(gOe,"A",{href:!0});var KNt=s(gQ);dDo=r(KNt,"SwinModel"),KNt.forEach(t),mDo=r(gOe," (Swin Transformer model)"),gOe.forEach(t),cDo=i(x),T2=n(x,"LI",{});var hOe=s(T2);hbe=n(hOe,"STRONG",{});var eqt=s(hbe);fDo=r(eqt,"swinv2"),eqt.forEach(t),gDo=r(hOe," \u2014 "),hQ=n(hOe,"A",{href:!0});var oqt=s(hQ);hDo=r(oqt,"Swinv2Model"),oqt.forEach(t),uDo=r(hOe," (Swin Transformer V2 model)"),hOe.forEach(t),pDo=i(x),M2=n(x,"LI",{});var uOe=s(M2);ube=n(uOe,"STRONG",{});var rqt=s(ube);_Do=r(rqt,"t5"),rqt.forEach(t),bDo=r(uOe," \u2014 "),uQ=n(uOe,"A",{href:!0});var tqt=s(uQ);vDo=r(tqt,"T5Model"),tqt.forEach(t),FDo=r(uOe," (T5 model)"),uOe.forEach(t),TDo=i(x),E2=n(x,"LI",{});var pOe=s(E2);pbe=n(pOe,"STRONG",{});var aqt=s(pbe);MDo=r(aqt,"tapas"),aqt.forEach(t),EDo=r(pOe," \u2014 "),pQ=n(pOe,"A",{href:!0});var nqt=s(pQ);CDo=r(nqt,"TapasModel"),nqt.forEach(t),wDo=r(pOe," (TAPAS model)"),pOe.forEach(t),ADo=i(x),C2=n(x,"LI",{});var _Oe=s(C2);_be=n(_Oe,"STRONG",{});var sqt=s(_be);LDo=r(sqt,"time_series_transformer"),sqt.forEach(t),yDo=r(_Oe," \u2014 "),_Q=n(_Oe,"A",{href:!0});var lqt=s(_Q);xDo=r(lqt,"TimeSeriesTransformerModel"),lqt.forEach(t),$Do=r(_Oe," (Time Series Transformer model)"),_Oe.forEach(t),kDo=i(x),w2=n(x,"LI",{});var bOe=s(w2);bbe=n(bOe,"STRONG",{});var iqt=s(bbe);SDo=r(iqt,"trajectory_transformer"),iqt.forEach(t),RDo=r(bOe," \u2014 "),bQ=n(bOe,"A",{href:!0});var dqt=s(bQ);PDo=r(dqt,"TrajectoryTransformerModel"),dqt.forEach(t),BDo=r(bOe," (Trajectory Transformer model)"),bOe.forEach(t),IDo=i(x),A2=n(x,"LI",{});var vOe=s(A2);vbe=n(vOe,"STRONG",{});var mqt=s(vbe);NDo=r(mqt,"transfo-xl"),mqt.forEach(t),qDo=r(vOe," \u2014 "),vQ=n(vOe,"A",{href:!0});var cqt=s(vQ);jDo=r(cqt,"TransfoXLModel"),cqt.forEach(t),DDo=r(vOe," (Transformer-XL model)"),vOe.forEach(t),GDo=i(x),L2=n(x,"LI",{});var FOe=s(L2);Fbe=n(FOe,"STRONG",{});var fqt=s(Fbe);ODo=r(fqt,"unispeech"),fqt.forEach(t),VDo=r(FOe," \u2014 "),FQ=n(FOe,"A",{href:!0});var gqt=s(FQ);XDo=r(gqt,"UniSpeechModel"),gqt.forEach(t),zDo=r(FOe," (UniSpeech model)"),FOe.forEach(t),QDo=i(x),y2=n(x,"LI",{});var TOe=s(y2);Tbe=n(TOe,"STRONG",{});var hqt=s(Tbe);WDo=r(hqt,"unispeech-sat"),hqt.forEach(t),UDo=r(TOe," \u2014 "),TQ=n(TOe,"A",{href:!0});var uqt=s(TQ);HDo=r(uqt,"UniSpeechSatModel"),uqt.forEach(t),JDo=r(TOe," (UniSpeechSat model)"),TOe.forEach(t),YDo=i(x),x2=n(x,"LI",{});var MOe=s(x2);Mbe=n(MOe,"STRONG",{});var pqt=s(Mbe);ZDo=r(pqt,"van"),pqt.forEach(t),KDo=r(MOe," \u2014 "),MQ=n(MOe,"A",{href:!0});var _qt=s(MQ);eGo=r(_qt,"VanModel"),_qt.forEach(t),oGo=r(MOe," (VAN model)"),MOe.forEach(t),rGo=i(x),$2=n(x,"LI",{});var EOe=s($2);Ebe=n(EOe,"STRONG",{});var bqt=s(Ebe);tGo=r(bqt,"videomae"),bqt.forEach(t),aGo=r(EOe," \u2014 "),EQ=n(EOe,"A",{href:!0});var vqt=s(EQ);nGo=r(vqt,"VideoMAEModel"),vqt.forEach(t),sGo=r(EOe," (VideoMAE model)"),EOe.forEach(t),lGo=i(x),k2=n(x,"LI",{});var COe=s(k2);Cbe=n(COe,"STRONG",{});var Fqt=s(Cbe);iGo=r(Fqt,"vilt"),Fqt.forEach(t),dGo=r(COe," \u2014 "),CQ=n(COe,"A",{href:!0});var Tqt=s(CQ);mGo=r(Tqt,"ViltModel"),Tqt.forEach(t),cGo=r(COe," (ViLT model)"),COe.forEach(t),fGo=i(x),S2=n(x,"LI",{});var wOe=s(S2);wbe=n(wOe,"STRONG",{});var Mqt=s(wbe);gGo=r(Mqt,"vision-text-dual-encoder"),Mqt.forEach(t),hGo=r(wOe," \u2014 "),wQ=n(wOe,"A",{href:!0});var Eqt=s(wQ);uGo=r(Eqt,"VisionTextDualEncoderModel"),Eqt.forEach(t),pGo=r(wOe," (VisionTextDualEncoder model)"),wOe.forEach(t),_Go=i(x),R2=n(x,"LI",{});var AOe=s(R2);Abe=n(AOe,"STRONG",{});var Cqt=s(Abe);bGo=r(Cqt,"visual_bert"),Cqt.forEach(t),vGo=r(AOe," \u2014 "),AQ=n(AOe,"A",{href:!0});var wqt=s(AQ);FGo=r(wqt,"VisualBertModel"),wqt.forEach(t),TGo=r(AOe," (VisualBERT model)"),AOe.forEach(t),MGo=i(x),P2=n(x,"LI",{});var LOe=s(P2);Lbe=n(LOe,"STRONG",{});var Aqt=s(Lbe);EGo=r(Aqt,"vit"),Aqt.forEach(t),CGo=r(LOe," \u2014 "),LQ=n(LOe,"A",{href:!0});var Lqt=s(LQ);wGo=r(Lqt,"ViTModel"),Lqt.forEach(t),AGo=r(LOe," (ViT model)"),LOe.forEach(t),LGo=i(x),B2=n(x,"LI",{});var yOe=s(B2);ybe=n(yOe,"STRONG",{});var yqt=s(ybe);yGo=r(yqt,"vit_mae"),yqt.forEach(t),xGo=r(yOe," \u2014 "),yQ=n(yOe,"A",{href:!0});var xqt=s(yQ);$Go=r(xqt,"ViTMAEModel"),xqt.forEach(t),kGo=r(yOe," (ViTMAE model)"),yOe.forEach(t),SGo=i(x),I2=n(x,"LI",{});var xOe=s(I2);xbe=n(xOe,"STRONG",{});var $qt=s(xbe);RGo=r($qt,"vit_msn"),$qt.forEach(t),PGo=r(xOe," \u2014 "),xQ=n(xOe,"A",{href:!0});var kqt=s(xQ);BGo=r(kqt,"ViTMSNModel"),kqt.forEach(t),IGo=r(xOe," (ViTMSN model)"),xOe.forEach(t),NGo=i(x),N2=n(x,"LI",{});var $Oe=s(N2);$be=n($Oe,"STRONG",{});var Sqt=s($be);qGo=r(Sqt,"wav2vec2"),Sqt.forEach(t),jGo=r($Oe," \u2014 "),$Q=n($Oe,"A",{href:!0});var Rqt=s($Q);DGo=r(Rqt,"Wav2Vec2Model"),Rqt.forEach(t),GGo=r($Oe," (Wav2Vec2 model)"),$Oe.forEach(t),OGo=i(x),q2=n(x,"LI",{});var kOe=s(q2);kbe=n(kOe,"STRONG",{});var Pqt=s(kbe);VGo=r(Pqt,"wav2vec2-conformer"),Pqt.forEach(t),XGo=r(kOe," \u2014 "),kQ=n(kOe,"A",{href:!0});var Bqt=s(kQ);zGo=r(Bqt,"Wav2Vec2ConformerModel"),Bqt.forEach(t),QGo=r(kOe," (Wav2Vec2-Conformer model)"),kOe.forEach(t),WGo=i(x),j2=n(x,"LI",{});var SOe=s(j2);Sbe=n(SOe,"STRONG",{});var Iqt=s(Sbe);UGo=r(Iqt,"wavlm"),Iqt.forEach(t),HGo=r(SOe," \u2014 "),SQ=n(SOe,"A",{href:!0});var Nqt=s(SQ);JGo=r(Nqt,"WavLMModel"),Nqt.forEach(t),YGo=r(SOe," (WavLM model)"),SOe.forEach(t),ZGo=i(x),D2=n(x,"LI",{});var ROe=s(D2);Rbe=n(ROe,"STRONG",{});var qqt=s(Rbe);KGo=r(qqt,"whisper"),qqt.forEach(t),eOo=r(ROe," \u2014 "),RQ=n(ROe,"A",{href:!0});var jqt=s(RQ);oOo=r(jqt,"WhisperModel"),jqt.forEach(t),rOo=r(ROe," (Whisper model)"),ROe.forEach(t),tOo=i(x),G2=n(x,"LI",{});var POe=s(G2);Pbe=n(POe,"STRONG",{});var Dqt=s(Pbe);aOo=r(Dqt,"xclip"),Dqt.forEach(t),nOo=r(POe," \u2014 "),PQ=n(POe,"A",{href:!0});var Gqt=s(PQ);sOo=r(Gqt,"XCLIPModel"),Gqt.forEach(t),lOo=r(POe," (X-CLIP model)"),POe.forEach(t),iOo=i(x),O2=n(x,"LI",{});var BOe=s(O2);Bbe=n(BOe,"STRONG",{});var Oqt=s(Bbe);dOo=r(Oqt,"xglm"),Oqt.forEach(t),mOo=r(BOe," \u2014 "),BQ=n(BOe,"A",{href:!0});var Vqt=s(BQ);cOo=r(Vqt,"XGLMModel"),Vqt.forEach(t),fOo=r(BOe," (XGLM model)"),BOe.forEach(t),gOo=i(x),V2=n(x,"LI",{});var IOe=s(V2);Ibe=n(IOe,"STRONG",{});var Xqt=s(Ibe);hOo=r(Xqt,"xlm"),Xqt.forEach(t),uOo=r(IOe," \u2014 "),IQ=n(IOe,"A",{href:!0});var zqt=s(IQ);pOo=r(zqt,"XLMModel"),zqt.forEach(t),_Oo=r(IOe," (XLM model)"),IOe.forEach(t),bOo=i(x),X2=n(x,"LI",{});var NOe=s(X2);Nbe=n(NOe,"STRONG",{});var Qqt=s(Nbe);vOo=r(Qqt,"xlm-prophetnet"),Qqt.forEach(t),FOo=r(NOe," \u2014 "),NQ=n(NOe,"A",{href:!0});var Wqt=s(NQ);TOo=r(Wqt,"XLMProphetNetModel"),Wqt.forEach(t),MOo=r(NOe," (XLM-ProphetNet model)"),NOe.forEach(t),EOo=i(x),z2=n(x,"LI",{});var qOe=s(z2);qbe=n(qOe,"STRONG",{});var Uqt=s(qbe);COo=r(Uqt,"xlm-roberta"),Uqt.forEach(t),wOo=r(qOe," \u2014 "),qQ=n(qOe,"A",{href:!0});var Hqt=s(qQ);AOo=r(Hqt,"XLMRobertaModel"),Hqt.forEach(t),LOo=r(qOe," (XLM-RoBERTa model)"),qOe.forEach(t),yOo=i(x),Q2=n(x,"LI",{});var jOe=s(Q2);jbe=n(jOe,"STRONG",{});var Jqt=s(jbe);xOo=r(Jqt,"xlm-roberta-xl"),Jqt.forEach(t),$Oo=r(jOe," \u2014 "),jQ=n(jOe,"A",{href:!0});var Yqt=s(jQ);kOo=r(Yqt,"XLMRobertaXLModel"),Yqt.forEach(t),SOo=r(jOe," (XLM-RoBERTa-XL model)"),jOe.forEach(t),ROo=i(x),W2=n(x,"LI",{});var DOe=s(W2);Dbe=n(DOe,"STRONG",{});var Zqt=s(Dbe);POo=r(Zqt,"xlnet"),Zqt.forEach(t),BOo=r(DOe," \u2014 "),DQ=n(DOe,"A",{href:!0});var Kqt=s(DQ);IOo=r(Kqt,"XLNetModel"),Kqt.forEach(t),NOo=r(DOe," (XLNet model)"),DOe.forEach(t),qOo=i(x),U2=n(x,"LI",{});var GOe=s(U2);Gbe=n(GOe,"STRONG",{});var ejt=s(Gbe);jOo=r(ejt,"yolos"),ejt.forEach(t),DOo=r(GOe," \u2014 "),GQ=n(GOe,"A",{href:!0});var ojt=s(GQ);GOo=r(ojt,"YolosModel"),ojt.forEach(t),OOo=r(GOe," (YOLOS model)"),GOe.forEach(t),VOo=i(x),H2=n(x,"LI",{});var OOe=s(H2);Obe=n(OOe,"STRONG",{});var rjt=s(Obe);XOo=r(rjt,"yoso"),rjt.forEach(t),zOo=r(OOe," \u2014 "),OQ=n(OOe,"A",{href:!0});var tjt=s(OQ);QOo=r(tjt,"YosoModel"),tjt.forEach(t),WOo=r(OOe," (YOSO model)"),OOe.forEach(t),x.forEach(t),UOo=i(Aa),J2=n(Aa,"P",{});var VOe=s(J2);HOo=r(VOe,"The model is set in evaluation mode by default using "),Vbe=n(VOe,"CODE",{});var ajt=s(Vbe);JOo=r(ajt,"model.eval()"),ajt.forEach(t),YOo=r(VOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xbe=n(VOe,"CODE",{});var njt=s(Xbe);ZOo=r(njt,"model.train()"),njt.forEach(t),VOe.forEach(t),KOo=i(Aa),T(Y2.$$.fragment,Aa),Aa.forEach(t),Nl.forEach(t),Eto=i(c),Rd=n(c,"H2",{class:!0});var Gno=s(Rd);Z2=n(Gno,"A",{id:!0,class:!0,href:!0});var sjt=s(Z2);zbe=n(sjt,"SPAN",{});var ljt=s(zbe);T(I$.$$.fragment,ljt),ljt.forEach(t),sjt.forEach(t),eVo=i(Gno),Qbe=n(Gno,"SPAN",{});var ijt=s(Qbe);oVo=r(ijt,"AutoModelForPreTraining"),ijt.forEach(t),Gno.forEach(t),Cto=i(c),No=n(c,"DIV",{class:!0});var ql=s(No);T(N$.$$.fragment,ql),rVo=i(ql),Pd=n(ql,"P",{});var Jde=s(Pd);tVo=r(Jde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VQ=n(Jde,"A",{href:!0});var djt=s(VQ);aVo=r(djt,"from_pretrained()"),djt.forEach(t),nVo=r(Jde," class method or the "),XQ=n(Jde,"A",{href:!0});var mjt=s(XQ);sVo=r(mjt,"from_config()"),mjt.forEach(t),lVo=r(Jde,` class
method.`),Jde.forEach(t),iVo=i(ql),q$=n(ql,"P",{});var Ono=s(q$);dVo=r(Ono,"This class cannot be instantiated directly using "),Wbe=n(Ono,"CODE",{});var cjt=s(Wbe);mVo=r(cjt,"__init__()"),cjt.forEach(t),cVo=r(Ono," (throws an error)."),Ono.forEach(t),fVo=i(ql),Mt=n(ql,"DIV",{class:!0});var Yy=s(Mt);T(j$.$$.fragment,Yy),gVo=i(Yy),Ube=n(Yy,"P",{});var fjt=s(Ube);hVo=r(fjt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),fjt.forEach(t),uVo=i(Yy),Bd=n(Yy,"P",{});var Yde=s(Bd);pVo=r(Yde,`Note:
Loading a model from its configuration file does `),Hbe=n(Yde,"STRONG",{});var gjt=s(Hbe);_Vo=r(gjt,"not"),gjt.forEach(t),bVo=r(Yde,` load the model weights. It only affects the
model\u2019s configuration. Use `),zQ=n(Yde,"A",{href:!0});var hjt=s(zQ);vVo=r(hjt,"from_pretrained()"),hjt.forEach(t),FVo=r(Yde," to load the model weights."),Yde.forEach(t),TVo=i(Yy),T(K2.$$.fragment,Yy),Yy.forEach(t),MVo=i(ql),eo=n(ql,"DIV",{class:!0});var La=s(eo);T(D$.$$.fragment,La),EVo=i(La),Jbe=n(La,"P",{});var ujt=s(Jbe);CVo=r(ujt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ujt.forEach(t),wVo=i(La),nn=n(La,"P",{});var Zy=s(nn);AVo=r(Zy,"The model class to instantiate is selected based on the "),Ybe=n(Zy,"CODE",{});var pjt=s(Ybe);LVo=r(pjt,"model_type"),pjt.forEach(t),yVo=r(Zy,` property of the config object (either
passed as an argument or loaded from `),Zbe=n(Zy,"CODE",{});var _jt=s(Zbe);xVo=r(_jt,"pretrained_model_name_or_path"),_jt.forEach(t),$Vo=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kbe=n(Zy,"CODE",{});var bjt=s(Kbe);kVo=r(bjt,"pretrained_model_name_or_path"),bjt.forEach(t),SVo=r(Zy,":"),Zy.forEach(t),RVo=i(La),G=n(La,"UL",{});var V=s(G);eb=n(V,"LI",{});var XOe=s(eb);eve=n(XOe,"STRONG",{});var vjt=s(eve);PVo=r(vjt,"albert"),vjt.forEach(t),BVo=r(XOe," \u2014 "),QQ=n(XOe,"A",{href:!0});var Fjt=s(QQ);IVo=r(Fjt,"AlbertForPreTraining"),Fjt.forEach(t),NVo=r(XOe," (ALBERT model)"),XOe.forEach(t),qVo=i(V),ob=n(V,"LI",{});var zOe=s(ob);ove=n(zOe,"STRONG",{});var Tjt=s(ove);jVo=r(Tjt,"bart"),Tjt.forEach(t),DVo=r(zOe," \u2014 "),WQ=n(zOe,"A",{href:!0});var Mjt=s(WQ);GVo=r(Mjt,"BartForConditionalGeneration"),Mjt.forEach(t),OVo=r(zOe," (BART model)"),zOe.forEach(t),VVo=i(V),rb=n(V,"LI",{});var QOe=s(rb);rve=n(QOe,"STRONG",{});var Ejt=s(rve);XVo=r(Ejt,"bert"),Ejt.forEach(t),zVo=r(QOe," \u2014 "),UQ=n(QOe,"A",{href:!0});var Cjt=s(UQ);QVo=r(Cjt,"BertForPreTraining"),Cjt.forEach(t),WVo=r(QOe," (BERT model)"),QOe.forEach(t),UVo=i(V),tb=n(V,"LI",{});var WOe=s(tb);tve=n(WOe,"STRONG",{});var wjt=s(tve);HVo=r(wjt,"big_bird"),wjt.forEach(t),JVo=r(WOe," \u2014 "),HQ=n(WOe,"A",{href:!0});var Ajt=s(HQ);YVo=r(Ajt,"BigBirdForPreTraining"),Ajt.forEach(t),ZVo=r(WOe," (BigBird model)"),WOe.forEach(t),KVo=i(V),ab=n(V,"LI",{});var UOe=s(ab);ave=n(UOe,"STRONG",{});var Ljt=s(ave);eXo=r(Ljt,"bloom"),Ljt.forEach(t),oXo=r(UOe," \u2014 "),JQ=n(UOe,"A",{href:!0});var yjt=s(JQ);rXo=r(yjt,"BloomForCausalLM"),yjt.forEach(t),tXo=r(UOe," (BLOOM model)"),UOe.forEach(t),aXo=i(V),nb=n(V,"LI",{});var HOe=s(nb);nve=n(HOe,"STRONG",{});var xjt=s(nve);nXo=r(xjt,"camembert"),xjt.forEach(t),sXo=r(HOe," \u2014 "),YQ=n(HOe,"A",{href:!0});var $jt=s(YQ);lXo=r($jt,"CamembertForMaskedLM"),$jt.forEach(t),iXo=r(HOe," (CamemBERT model)"),HOe.forEach(t),dXo=i(V),sb=n(V,"LI",{});var JOe=s(sb);sve=n(JOe,"STRONG",{});var kjt=s(sve);mXo=r(kjt,"ctrl"),kjt.forEach(t),cXo=r(JOe," \u2014 "),ZQ=n(JOe,"A",{href:!0});var Sjt=s(ZQ);fXo=r(Sjt,"CTRLLMHeadModel"),Sjt.forEach(t),gXo=r(JOe," (CTRL model)"),JOe.forEach(t),hXo=i(V),lb=n(V,"LI",{});var YOe=s(lb);lve=n(YOe,"STRONG",{});var Rjt=s(lve);uXo=r(Rjt,"data2vec-text"),Rjt.forEach(t),pXo=r(YOe," \u2014 "),KQ=n(YOe,"A",{href:!0});var Pjt=s(KQ);_Xo=r(Pjt,"Data2VecTextForMaskedLM"),Pjt.forEach(t),bXo=r(YOe," (Data2VecText model)"),YOe.forEach(t),vXo=i(V),ib=n(V,"LI",{});var ZOe=s(ib);ive=n(ZOe,"STRONG",{});var Bjt=s(ive);FXo=r(Bjt,"deberta"),Bjt.forEach(t),TXo=r(ZOe," \u2014 "),eW=n(ZOe,"A",{href:!0});var Ijt=s(eW);MXo=r(Ijt,"DebertaForMaskedLM"),Ijt.forEach(t),EXo=r(ZOe," (DeBERTa model)"),ZOe.forEach(t),CXo=i(V),db=n(V,"LI",{});var KOe=s(db);dve=n(KOe,"STRONG",{});var Njt=s(dve);wXo=r(Njt,"deberta-v2"),Njt.forEach(t),AXo=r(KOe," \u2014 "),oW=n(KOe,"A",{href:!0});var qjt=s(oW);LXo=r(qjt,"DebertaV2ForMaskedLM"),qjt.forEach(t),yXo=r(KOe," (DeBERTa-v2 model)"),KOe.forEach(t),xXo=i(V),mb=n(V,"LI",{});var eVe=s(mb);mve=n(eVe,"STRONG",{});var jjt=s(mve);$Xo=r(jjt,"distilbert"),jjt.forEach(t),kXo=r(eVe," \u2014 "),rW=n(eVe,"A",{href:!0});var Djt=s(rW);SXo=r(Djt,"DistilBertForMaskedLM"),Djt.forEach(t),RXo=r(eVe," (DistilBERT model)"),eVe.forEach(t),PXo=i(V),cb=n(V,"LI",{});var oVe=s(cb);cve=n(oVe,"STRONG",{});var Gjt=s(cve);BXo=r(Gjt,"electra"),Gjt.forEach(t),IXo=r(oVe," \u2014 "),tW=n(oVe,"A",{href:!0});var Ojt=s(tW);NXo=r(Ojt,"ElectraForPreTraining"),Ojt.forEach(t),qXo=r(oVe," (ELECTRA model)"),oVe.forEach(t),jXo=i(V),fb=n(V,"LI",{});var rVe=s(fb);fve=n(rVe,"STRONG",{});var Vjt=s(fve);DXo=r(Vjt,"ernie"),Vjt.forEach(t),GXo=r(rVe," \u2014 "),aW=n(rVe,"A",{href:!0});var Xjt=s(aW);OXo=r(Xjt,"ErnieForPreTraining"),Xjt.forEach(t),VXo=r(rVe," (ERNIE model)"),rVe.forEach(t),XXo=i(V),gb=n(V,"LI",{});var tVe=s(gb);gve=n(tVe,"STRONG",{});var zjt=s(gve);zXo=r(zjt,"flaubert"),zjt.forEach(t),QXo=r(tVe," \u2014 "),nW=n(tVe,"A",{href:!0});var Qjt=s(nW);WXo=r(Qjt,"FlaubertWithLMHeadModel"),Qjt.forEach(t),UXo=r(tVe," (FlauBERT model)"),tVe.forEach(t),HXo=i(V),hb=n(V,"LI",{});var aVe=s(hb);hve=n(aVe,"STRONG",{});var Wjt=s(hve);JXo=r(Wjt,"flava"),Wjt.forEach(t),YXo=r(aVe," \u2014 "),sW=n(aVe,"A",{href:!0});var Ujt=s(sW);ZXo=r(Ujt,"FlavaForPreTraining"),Ujt.forEach(t),KXo=r(aVe," (FLAVA model)"),aVe.forEach(t),ezo=i(V),ub=n(V,"LI",{});var nVe=s(ub);uve=n(nVe,"STRONG",{});var Hjt=s(uve);ozo=r(Hjt,"fnet"),Hjt.forEach(t),rzo=r(nVe," \u2014 "),lW=n(nVe,"A",{href:!0});var Jjt=s(lW);tzo=r(Jjt,"FNetForPreTraining"),Jjt.forEach(t),azo=r(nVe," (FNet model)"),nVe.forEach(t),nzo=i(V),pb=n(V,"LI",{});var sVe=s(pb);pve=n(sVe,"STRONG",{});var Yjt=s(pve);szo=r(Yjt,"fsmt"),Yjt.forEach(t),lzo=r(sVe," \u2014 "),iW=n(sVe,"A",{href:!0});var Zjt=s(iW);izo=r(Zjt,"FSMTForConditionalGeneration"),Zjt.forEach(t),dzo=r(sVe," (FairSeq Machine-Translation model)"),sVe.forEach(t),mzo=i(V),_b=n(V,"LI",{});var lVe=s(_b);_ve=n(lVe,"STRONG",{});var Kjt=s(_ve);czo=r(Kjt,"funnel"),Kjt.forEach(t),fzo=r(lVe," \u2014 "),dW=n(lVe,"A",{href:!0});var eDt=s(dW);gzo=r(eDt,"FunnelForPreTraining"),eDt.forEach(t),hzo=r(lVe," (Funnel Transformer model)"),lVe.forEach(t),uzo=i(V),bb=n(V,"LI",{});var iVe=s(bb);bve=n(iVe,"STRONG",{});var oDt=s(bve);pzo=r(oDt,"gpt2"),oDt.forEach(t),_zo=r(iVe," \u2014 "),mW=n(iVe,"A",{href:!0});var rDt=s(mW);bzo=r(rDt,"GPT2LMHeadModel"),rDt.forEach(t),vzo=r(iVe," (OpenAI GPT-2 model)"),iVe.forEach(t),Fzo=i(V),vb=n(V,"LI",{});var dVe=s(vb);vve=n(dVe,"STRONG",{});var tDt=s(vve);Tzo=r(tDt,"ibert"),tDt.forEach(t),Mzo=r(dVe," \u2014 "),cW=n(dVe,"A",{href:!0});var aDt=s(cW);Ezo=r(aDt,"IBertForMaskedLM"),aDt.forEach(t),Czo=r(dVe," (I-BERT model)"),dVe.forEach(t),wzo=i(V),Fb=n(V,"LI",{});var mVe=s(Fb);Fve=n(mVe,"STRONG",{});var nDt=s(Fve);Azo=r(nDt,"layoutlm"),nDt.forEach(t),Lzo=r(mVe," \u2014 "),fW=n(mVe,"A",{href:!0});var sDt=s(fW);yzo=r(sDt,"LayoutLMForMaskedLM"),sDt.forEach(t),xzo=r(mVe," (LayoutLM model)"),mVe.forEach(t),$zo=i(V),Tb=n(V,"LI",{});var cVe=s(Tb);Tve=n(cVe,"STRONG",{});var lDt=s(Tve);kzo=r(lDt,"longformer"),lDt.forEach(t),Szo=r(cVe," \u2014 "),gW=n(cVe,"A",{href:!0});var iDt=s(gW);Rzo=r(iDt,"LongformerForMaskedLM"),iDt.forEach(t),Pzo=r(cVe," (Longformer model)"),cVe.forEach(t),Bzo=i(V),Mb=n(V,"LI",{});var fVe=s(Mb);Mve=n(fVe,"STRONG",{});var dDt=s(Mve);Izo=r(dDt,"luke"),dDt.forEach(t),Nzo=r(fVe," \u2014 "),hW=n(fVe,"A",{href:!0});var mDt=s(hW);qzo=r(mDt,"LukeForMaskedLM"),mDt.forEach(t),jzo=r(fVe," (LUKE model)"),fVe.forEach(t),Dzo=i(V),Eb=n(V,"LI",{});var gVe=s(Eb);Eve=n(gVe,"STRONG",{});var cDt=s(Eve);Gzo=r(cDt,"lxmert"),cDt.forEach(t),Ozo=r(gVe," \u2014 "),uW=n(gVe,"A",{href:!0});var fDt=s(uW);Vzo=r(fDt,"LxmertForPreTraining"),fDt.forEach(t),Xzo=r(gVe," (LXMERT model)"),gVe.forEach(t),zzo=i(V),Cb=n(V,"LI",{});var hVe=s(Cb);Cve=n(hVe,"STRONG",{});var gDt=s(Cve);Qzo=r(gDt,"megatron-bert"),gDt.forEach(t),Wzo=r(hVe," \u2014 "),pW=n(hVe,"A",{href:!0});var hDt=s(pW);Uzo=r(hDt,"MegatronBertForPreTraining"),hDt.forEach(t),Hzo=r(hVe," (Megatron-BERT model)"),hVe.forEach(t),Jzo=i(V),wb=n(V,"LI",{});var uVe=s(wb);wve=n(uVe,"STRONG",{});var uDt=s(wve);Yzo=r(uDt,"mobilebert"),uDt.forEach(t),Zzo=r(uVe," \u2014 "),_W=n(uVe,"A",{href:!0});var pDt=s(_W);Kzo=r(pDt,"MobileBertForPreTraining"),pDt.forEach(t),eQo=r(uVe," (MobileBERT model)"),uVe.forEach(t),oQo=i(V),Ab=n(V,"LI",{});var pVe=s(Ab);Ave=n(pVe,"STRONG",{});var _Dt=s(Ave);rQo=r(_Dt,"mpnet"),_Dt.forEach(t),tQo=r(pVe," \u2014 "),bW=n(pVe,"A",{href:!0});var bDt=s(bW);aQo=r(bDt,"MPNetForMaskedLM"),bDt.forEach(t),nQo=r(pVe," (MPNet model)"),pVe.forEach(t),sQo=i(V),Lb=n(V,"LI",{});var _Ve=s(Lb);Lve=n(_Ve,"STRONG",{});var vDt=s(Lve);lQo=r(vDt,"mvp"),vDt.forEach(t),iQo=r(_Ve," \u2014 "),vW=n(_Ve,"A",{href:!0});var FDt=s(vW);dQo=r(FDt,"MvpForConditionalGeneration"),FDt.forEach(t),mQo=r(_Ve," (MVP model)"),_Ve.forEach(t),cQo=i(V),yb=n(V,"LI",{});var bVe=s(yb);yve=n(bVe,"STRONG",{});var TDt=s(yve);fQo=r(TDt,"nezha"),TDt.forEach(t),gQo=r(bVe," \u2014 "),FW=n(bVe,"A",{href:!0});var MDt=s(FW);hQo=r(MDt,"NezhaForPreTraining"),MDt.forEach(t),uQo=r(bVe," (Nezha model)"),bVe.forEach(t),pQo=i(V),xb=n(V,"LI",{});var vVe=s(xb);xve=n(vVe,"STRONG",{});var EDt=s(xve);_Qo=r(EDt,"openai-gpt"),EDt.forEach(t),bQo=r(vVe," \u2014 "),TW=n(vVe,"A",{href:!0});var CDt=s(TW);vQo=r(CDt,"OpenAIGPTLMHeadModel"),CDt.forEach(t),FQo=r(vVe," (OpenAI GPT model)"),vVe.forEach(t),TQo=i(V),$b=n(V,"LI",{});var FVe=s($b);$ve=n(FVe,"STRONG",{});var wDt=s($ve);MQo=r(wDt,"retribert"),wDt.forEach(t),EQo=r(FVe," \u2014 "),MW=n(FVe,"A",{href:!0});var ADt=s(MW);CQo=r(ADt,"RetriBertModel"),ADt.forEach(t),wQo=r(FVe," (RetriBERT model)"),FVe.forEach(t),AQo=i(V),kb=n(V,"LI",{});var TVe=s(kb);kve=n(TVe,"STRONG",{});var LDt=s(kve);LQo=r(LDt,"roberta"),LDt.forEach(t),yQo=r(TVe," \u2014 "),EW=n(TVe,"A",{href:!0});var yDt=s(EW);xQo=r(yDt,"RobertaForMaskedLM"),yDt.forEach(t),$Qo=r(TVe," (RoBERTa model)"),TVe.forEach(t),kQo=i(V),Sb=n(V,"LI",{});var MVe=s(Sb);Sve=n(MVe,"STRONG",{});var xDt=s(Sve);SQo=r(xDt,"splinter"),xDt.forEach(t),RQo=r(MVe," \u2014 "),CW=n(MVe,"A",{href:!0});var $Dt=s(CW);PQo=r($Dt,"SplinterForPreTraining"),$Dt.forEach(t),BQo=r(MVe," (Splinter model)"),MVe.forEach(t),IQo=i(V),Rb=n(V,"LI",{});var EVe=s(Rb);Rve=n(EVe,"STRONG",{});var kDt=s(Rve);NQo=r(kDt,"squeezebert"),kDt.forEach(t),qQo=r(EVe," \u2014 "),wW=n(EVe,"A",{href:!0});var SDt=s(wW);jQo=r(SDt,"SqueezeBertForMaskedLM"),SDt.forEach(t),DQo=r(EVe," (SqueezeBERT model)"),EVe.forEach(t),GQo=i(V),Pb=n(V,"LI",{});var CVe=s(Pb);Pve=n(CVe,"STRONG",{});var RDt=s(Pve);OQo=r(RDt,"t5"),RDt.forEach(t),VQo=r(CVe," \u2014 "),AW=n(CVe,"A",{href:!0});var PDt=s(AW);XQo=r(PDt,"T5ForConditionalGeneration"),PDt.forEach(t),zQo=r(CVe," (T5 model)"),CVe.forEach(t),QQo=i(V),Bb=n(V,"LI",{});var wVe=s(Bb);Bve=n(wVe,"STRONG",{});var BDt=s(Bve);WQo=r(BDt,"tapas"),BDt.forEach(t),UQo=r(wVe," \u2014 "),LW=n(wVe,"A",{href:!0});var IDt=s(LW);HQo=r(IDt,"TapasForMaskedLM"),IDt.forEach(t),JQo=r(wVe," (TAPAS model)"),wVe.forEach(t),YQo=i(V),Ib=n(V,"LI",{});var AVe=s(Ib);Ive=n(AVe,"STRONG",{});var NDt=s(Ive);ZQo=r(NDt,"transfo-xl"),NDt.forEach(t),KQo=r(AVe," \u2014 "),yW=n(AVe,"A",{href:!0});var qDt=s(yW);eWo=r(qDt,"TransfoXLLMHeadModel"),qDt.forEach(t),oWo=r(AVe," (Transformer-XL model)"),AVe.forEach(t),rWo=i(V),Nb=n(V,"LI",{});var LVe=s(Nb);Nve=n(LVe,"STRONG",{});var jDt=s(Nve);tWo=r(jDt,"unispeech"),jDt.forEach(t),aWo=r(LVe," \u2014 "),xW=n(LVe,"A",{href:!0});var DDt=s(xW);nWo=r(DDt,"UniSpeechForPreTraining"),DDt.forEach(t),sWo=r(LVe," (UniSpeech model)"),LVe.forEach(t),lWo=i(V),qb=n(V,"LI",{});var yVe=s(qb);qve=n(yVe,"STRONG",{});var GDt=s(qve);iWo=r(GDt,"unispeech-sat"),GDt.forEach(t),dWo=r(yVe," \u2014 "),$W=n(yVe,"A",{href:!0});var ODt=s($W);mWo=r(ODt,"UniSpeechSatForPreTraining"),ODt.forEach(t),cWo=r(yVe," (UniSpeechSat model)"),yVe.forEach(t),fWo=i(V),jb=n(V,"LI",{});var xVe=s(jb);jve=n(xVe,"STRONG",{});var VDt=s(jve);gWo=r(VDt,"videomae"),VDt.forEach(t),hWo=r(xVe," \u2014 "),kW=n(xVe,"A",{href:!0});var XDt=s(kW);uWo=r(XDt,"VideoMAEForPreTraining"),XDt.forEach(t),pWo=r(xVe," (VideoMAE model)"),xVe.forEach(t),_Wo=i(V),Db=n(V,"LI",{});var $Ve=s(Db);Dve=n($Ve,"STRONG",{});var zDt=s(Dve);bWo=r(zDt,"visual_bert"),zDt.forEach(t),vWo=r($Ve," \u2014 "),SW=n($Ve,"A",{href:!0});var QDt=s(SW);FWo=r(QDt,"VisualBertForPreTraining"),QDt.forEach(t),TWo=r($Ve," (VisualBERT model)"),$Ve.forEach(t),MWo=i(V),Gb=n(V,"LI",{});var kVe=s(Gb);Gve=n(kVe,"STRONG",{});var WDt=s(Gve);EWo=r(WDt,"vit_mae"),WDt.forEach(t),CWo=r(kVe," \u2014 "),RW=n(kVe,"A",{href:!0});var UDt=s(RW);wWo=r(UDt,"ViTMAEForPreTraining"),UDt.forEach(t),AWo=r(kVe," (ViTMAE model)"),kVe.forEach(t),LWo=i(V),Ob=n(V,"LI",{});var SVe=s(Ob);Ove=n(SVe,"STRONG",{});var HDt=s(Ove);yWo=r(HDt,"wav2vec2"),HDt.forEach(t),xWo=r(SVe," \u2014 "),PW=n(SVe,"A",{href:!0});var JDt=s(PW);$Wo=r(JDt,"Wav2Vec2ForPreTraining"),JDt.forEach(t),kWo=r(SVe," (Wav2Vec2 model)"),SVe.forEach(t),SWo=i(V),Vb=n(V,"LI",{});var RVe=s(Vb);Vve=n(RVe,"STRONG",{});var YDt=s(Vve);RWo=r(YDt,"wav2vec2-conformer"),YDt.forEach(t),PWo=r(RVe," \u2014 "),BW=n(RVe,"A",{href:!0});var ZDt=s(BW);BWo=r(ZDt,"Wav2Vec2ConformerForPreTraining"),ZDt.forEach(t),IWo=r(RVe," (Wav2Vec2-Conformer model)"),RVe.forEach(t),NWo=i(V),Xb=n(V,"LI",{});var PVe=s(Xb);Xve=n(PVe,"STRONG",{});var KDt=s(Xve);qWo=r(KDt,"xlm"),KDt.forEach(t),jWo=r(PVe," \u2014 "),IW=n(PVe,"A",{href:!0});var eGt=s(IW);DWo=r(eGt,"XLMWithLMHeadModel"),eGt.forEach(t),GWo=r(PVe," (XLM model)"),PVe.forEach(t),OWo=i(V),zb=n(V,"LI",{});var BVe=s(zb);zve=n(BVe,"STRONG",{});var oGt=s(zve);VWo=r(oGt,"xlm-roberta"),oGt.forEach(t),XWo=r(BVe," \u2014 "),NW=n(BVe,"A",{href:!0});var rGt=s(NW);zWo=r(rGt,"XLMRobertaForMaskedLM"),rGt.forEach(t),QWo=r(BVe," (XLM-RoBERTa model)"),BVe.forEach(t),WWo=i(V),Qb=n(V,"LI",{});var IVe=s(Qb);Qve=n(IVe,"STRONG",{});var tGt=s(Qve);UWo=r(tGt,"xlm-roberta-xl"),tGt.forEach(t),HWo=r(IVe," \u2014 "),qW=n(IVe,"A",{href:!0});var aGt=s(qW);JWo=r(aGt,"XLMRobertaXLForMaskedLM"),aGt.forEach(t),YWo=r(IVe," (XLM-RoBERTa-XL model)"),IVe.forEach(t),ZWo=i(V),Wb=n(V,"LI",{});var NVe=s(Wb);Wve=n(NVe,"STRONG",{});var nGt=s(Wve);KWo=r(nGt,"xlnet"),nGt.forEach(t),eUo=r(NVe," \u2014 "),jW=n(NVe,"A",{href:!0});var sGt=s(jW);oUo=r(sGt,"XLNetLMHeadModel"),sGt.forEach(t),rUo=r(NVe," (XLNet model)"),NVe.forEach(t),V.forEach(t),tUo=i(La),Ub=n(La,"P",{});var qVe=s(Ub);aUo=r(qVe,"The model is set in evaluation mode by default using "),Uve=n(qVe,"CODE",{});var lGt=s(Uve);nUo=r(lGt,"model.eval()"),lGt.forEach(t),sUo=r(qVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hve=n(qVe,"CODE",{});var iGt=s(Hve);lUo=r(iGt,"model.train()"),iGt.forEach(t),qVe.forEach(t),iUo=i(La),T(Hb.$$.fragment,La),La.forEach(t),ql.forEach(t),wto=i(c),Id=n(c,"H2",{class:!0});var Vno=s(Id);Jb=n(Vno,"A",{id:!0,class:!0,href:!0});var dGt=s(Jb);Jve=n(dGt,"SPAN",{});var mGt=s(Jve);T(G$.$$.fragment,mGt),mGt.forEach(t),dGt.forEach(t),dUo=i(Vno),Yve=n(Vno,"SPAN",{});var cGt=s(Yve);mUo=r(cGt,"AutoModelForCausalLM"),cGt.forEach(t),Vno.forEach(t),Ato=i(c),qo=n(c,"DIV",{class:!0});var jl=s(qo);T(O$.$$.fragment,jl),cUo=i(jl),Nd=n(jl,"P",{});var Zde=s(Nd);fUo=r(Zde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),DW=n(Zde,"A",{href:!0});var fGt=s(DW);gUo=r(fGt,"from_pretrained()"),fGt.forEach(t),hUo=r(Zde," class method or the "),GW=n(Zde,"A",{href:!0});var gGt=s(GW);uUo=r(gGt,"from_config()"),gGt.forEach(t),pUo=r(Zde,` class
method.`),Zde.forEach(t),_Uo=i(jl),V$=n(jl,"P",{});var Xno=s(V$);bUo=r(Xno,"This class cannot be instantiated directly using "),Zve=n(Xno,"CODE",{});var hGt=s(Zve);vUo=r(hGt,"__init__()"),hGt.forEach(t),FUo=r(Xno," (throws an error)."),Xno.forEach(t),TUo=i(jl),Et=n(jl,"DIV",{class:!0});var Ky=s(Et);T(X$.$$.fragment,Ky),MUo=i(Ky),Kve=n(Ky,"P",{});var uGt=s(Kve);EUo=r(uGt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),uGt.forEach(t),CUo=i(Ky),qd=n(Ky,"P",{});var Kde=s(qd);wUo=r(Kde,`Note:
Loading a model from its configuration file does `),eFe=n(Kde,"STRONG",{});var pGt=s(eFe);AUo=r(pGt,"not"),pGt.forEach(t),LUo=r(Kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=n(Kde,"A",{href:!0});var _Gt=s(OW);yUo=r(_Gt,"from_pretrained()"),_Gt.forEach(t),xUo=r(Kde," to load the model weights."),Kde.forEach(t),$Uo=i(Ky),T(Yb.$$.fragment,Ky),Ky.forEach(t),kUo=i(jl),oo=n(jl,"DIV",{class:!0});var ya=s(oo);T(z$.$$.fragment,ya),SUo=i(ya),oFe=n(ya,"P",{});var bGt=s(oFe);RUo=r(bGt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),bGt.forEach(t),PUo=i(ya),sn=n(ya,"P",{});var e9=s(sn);BUo=r(e9,"The model class to instantiate is selected based on the "),rFe=n(e9,"CODE",{});var vGt=s(rFe);IUo=r(vGt,"model_type"),vGt.forEach(t),NUo=r(e9,` property of the config object (either
passed as an argument or loaded from `),tFe=n(e9,"CODE",{});var FGt=s(tFe);qUo=r(FGt,"pretrained_model_name_or_path"),FGt.forEach(t),jUo=r(e9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aFe=n(e9,"CODE",{});var TGt=s(aFe);DUo=r(TGt,"pretrained_model_name_or_path"),TGt.forEach(t),GUo=r(e9,":"),e9.forEach(t),OUo=i(ya),Q=n(ya,"UL",{});var H=s(Q);Zb=n(H,"LI",{});var jVe=s(Zb);nFe=n(jVe,"STRONG",{});var MGt=s(nFe);VUo=r(MGt,"bart"),MGt.forEach(t),XUo=r(jVe," \u2014 "),VW=n(jVe,"A",{href:!0});var EGt=s(VW);zUo=r(EGt,"BartForCausalLM"),EGt.forEach(t),QUo=r(jVe," (BART model)"),jVe.forEach(t),WUo=i(H),Kb=n(H,"LI",{});var DVe=s(Kb);sFe=n(DVe,"STRONG",{});var CGt=s(sFe);UUo=r(CGt,"bert"),CGt.forEach(t),HUo=r(DVe," \u2014 "),XW=n(DVe,"A",{href:!0});var wGt=s(XW);JUo=r(wGt,"BertLMHeadModel"),wGt.forEach(t),YUo=r(DVe," (BERT model)"),DVe.forEach(t),ZUo=i(H),ev=n(H,"LI",{});var GVe=s(ev);lFe=n(GVe,"STRONG",{});var AGt=s(lFe);KUo=r(AGt,"bert-generation"),AGt.forEach(t),eHo=r(GVe," \u2014 "),zW=n(GVe,"A",{href:!0});var LGt=s(zW);oHo=r(LGt,"BertGenerationDecoder"),LGt.forEach(t),rHo=r(GVe," (Bert Generation model)"),GVe.forEach(t),tHo=i(H),ov=n(H,"LI",{});var OVe=s(ov);iFe=n(OVe,"STRONG",{});var yGt=s(iFe);aHo=r(yGt,"big_bird"),yGt.forEach(t),nHo=r(OVe," \u2014 "),QW=n(OVe,"A",{href:!0});var xGt=s(QW);sHo=r(xGt,"BigBirdForCausalLM"),xGt.forEach(t),lHo=r(OVe," (BigBird model)"),OVe.forEach(t),iHo=i(H),rv=n(H,"LI",{});var VVe=s(rv);dFe=n(VVe,"STRONG",{});var $Gt=s(dFe);dHo=r($Gt,"bigbird_pegasus"),$Gt.forEach(t),mHo=r(VVe," \u2014 "),WW=n(VVe,"A",{href:!0});var kGt=s(WW);cHo=r(kGt,"BigBirdPegasusForCausalLM"),kGt.forEach(t),fHo=r(VVe," (BigBird-Pegasus model)"),VVe.forEach(t),gHo=i(H),tv=n(H,"LI",{});var XVe=s(tv);mFe=n(XVe,"STRONG",{});var SGt=s(mFe);hHo=r(SGt,"blenderbot"),SGt.forEach(t),uHo=r(XVe," \u2014 "),UW=n(XVe,"A",{href:!0});var RGt=s(UW);pHo=r(RGt,"BlenderbotForCausalLM"),RGt.forEach(t),_Ho=r(XVe," (Blenderbot model)"),XVe.forEach(t),bHo=i(H),av=n(H,"LI",{});var zVe=s(av);cFe=n(zVe,"STRONG",{});var PGt=s(cFe);vHo=r(PGt,"blenderbot-small"),PGt.forEach(t),FHo=r(zVe," \u2014 "),HW=n(zVe,"A",{href:!0});var BGt=s(HW);THo=r(BGt,"BlenderbotSmallForCausalLM"),BGt.forEach(t),MHo=r(zVe," (BlenderbotSmall model)"),zVe.forEach(t),EHo=i(H),nv=n(H,"LI",{});var QVe=s(nv);fFe=n(QVe,"STRONG",{});var IGt=s(fFe);CHo=r(IGt,"bloom"),IGt.forEach(t),wHo=r(QVe," \u2014 "),JW=n(QVe,"A",{href:!0});var NGt=s(JW);AHo=r(NGt,"BloomForCausalLM"),NGt.forEach(t),LHo=r(QVe," (BLOOM model)"),QVe.forEach(t),yHo=i(H),sv=n(H,"LI",{});var WVe=s(sv);gFe=n(WVe,"STRONG",{});var qGt=s(gFe);xHo=r(qGt,"camembert"),qGt.forEach(t),$Ho=r(WVe," \u2014 "),YW=n(WVe,"A",{href:!0});var jGt=s(YW);kHo=r(jGt,"CamembertForCausalLM"),jGt.forEach(t),SHo=r(WVe," (CamemBERT model)"),WVe.forEach(t),RHo=i(H),lv=n(H,"LI",{});var UVe=s(lv);hFe=n(UVe,"STRONG",{});var DGt=s(hFe);PHo=r(DGt,"codegen"),DGt.forEach(t),BHo=r(UVe," \u2014 "),ZW=n(UVe,"A",{href:!0});var GGt=s(ZW);IHo=r(GGt,"CodeGenForCausalLM"),GGt.forEach(t),NHo=r(UVe," (CodeGen model)"),UVe.forEach(t),qHo=i(H),iv=n(H,"LI",{});var HVe=s(iv);uFe=n(HVe,"STRONG",{});var OGt=s(uFe);jHo=r(OGt,"ctrl"),OGt.forEach(t),DHo=r(HVe," \u2014 "),KW=n(HVe,"A",{href:!0});var VGt=s(KW);GHo=r(VGt,"CTRLLMHeadModel"),VGt.forEach(t),OHo=r(HVe," (CTRL model)"),HVe.forEach(t),VHo=i(H),dv=n(H,"LI",{});var JVe=s(dv);pFe=n(JVe,"STRONG",{});var XGt=s(pFe);XHo=r(XGt,"data2vec-text"),XGt.forEach(t),zHo=r(JVe," \u2014 "),eU=n(JVe,"A",{href:!0});var zGt=s(eU);QHo=r(zGt,"Data2VecTextForCausalLM"),zGt.forEach(t),WHo=r(JVe," (Data2VecText model)"),JVe.forEach(t),UHo=i(H),mv=n(H,"LI",{});var YVe=s(mv);_Fe=n(YVe,"STRONG",{});var QGt=s(_Fe);HHo=r(QGt,"electra"),QGt.forEach(t),JHo=r(YVe," \u2014 "),oU=n(YVe,"A",{href:!0});var WGt=s(oU);YHo=r(WGt,"ElectraForCausalLM"),WGt.forEach(t),ZHo=r(YVe," (ELECTRA model)"),YVe.forEach(t),KHo=i(H),cv=n(H,"LI",{});var ZVe=s(cv);bFe=n(ZVe,"STRONG",{});var UGt=s(bFe);eJo=r(UGt,"ernie"),UGt.forEach(t),oJo=r(ZVe," \u2014 "),rU=n(ZVe,"A",{href:!0});var HGt=s(rU);rJo=r(HGt,"ErnieForCausalLM"),HGt.forEach(t),tJo=r(ZVe," (ERNIE model)"),ZVe.forEach(t),aJo=i(H),fv=n(H,"LI",{});var KVe=s(fv);vFe=n(KVe,"STRONG",{});var JGt=s(vFe);nJo=r(JGt,"gpt2"),JGt.forEach(t),sJo=r(KVe," \u2014 "),tU=n(KVe,"A",{href:!0});var YGt=s(tU);lJo=r(YGt,"GPT2LMHeadModel"),YGt.forEach(t),iJo=r(KVe," (OpenAI GPT-2 model)"),KVe.forEach(t),dJo=i(H),gv=n(H,"LI",{});var eXe=s(gv);FFe=n(eXe,"STRONG",{});var ZGt=s(FFe);mJo=r(ZGt,"gpt_neo"),ZGt.forEach(t),cJo=r(eXe," \u2014 "),aU=n(eXe,"A",{href:!0});var KGt=s(aU);fJo=r(KGt,"GPTNeoForCausalLM"),KGt.forEach(t),gJo=r(eXe," (GPT Neo model)"),eXe.forEach(t),hJo=i(H),hv=n(H,"LI",{});var oXe=s(hv);TFe=n(oXe,"STRONG",{});var eOt=s(TFe);uJo=r(eOt,"gpt_neox"),eOt.forEach(t),pJo=r(oXe," \u2014 "),nU=n(oXe,"A",{href:!0});var oOt=s(nU);_Jo=r(oOt,"GPTNeoXForCausalLM"),oOt.forEach(t),bJo=r(oXe," (GPT NeoX model)"),oXe.forEach(t),vJo=i(H),uv=n(H,"LI",{});var rXe=s(uv);MFe=n(rXe,"STRONG",{});var rOt=s(MFe);FJo=r(rOt,"gpt_neox_japanese"),rOt.forEach(t),TJo=r(rXe," \u2014 "),sU=n(rXe,"A",{href:!0});var tOt=s(sU);MJo=r(tOt,"GPTNeoXJapaneseForCausalLM"),tOt.forEach(t),EJo=r(rXe," (GPT NeoX Japanese model)"),rXe.forEach(t),CJo=i(H),pv=n(H,"LI",{});var tXe=s(pv);EFe=n(tXe,"STRONG",{});var aOt=s(EFe);wJo=r(aOt,"gptj"),aOt.forEach(t),AJo=r(tXe," \u2014 "),lU=n(tXe,"A",{href:!0});var nOt=s(lU);LJo=r(nOt,"GPTJForCausalLM"),nOt.forEach(t),yJo=r(tXe," (GPT-J model)"),tXe.forEach(t),xJo=i(H),_v=n(H,"LI",{});var aXe=s(_v);CFe=n(aXe,"STRONG",{});var sOt=s(CFe);$Jo=r(sOt,"marian"),sOt.forEach(t),kJo=r(aXe," \u2014 "),iU=n(aXe,"A",{href:!0});var lOt=s(iU);SJo=r(lOt,"MarianForCausalLM"),lOt.forEach(t),RJo=r(aXe," (Marian model)"),aXe.forEach(t),PJo=i(H),bv=n(H,"LI",{});var nXe=s(bv);wFe=n(nXe,"STRONG",{});var iOt=s(wFe);BJo=r(iOt,"mbart"),iOt.forEach(t),IJo=r(nXe," \u2014 "),dU=n(nXe,"A",{href:!0});var dOt=s(dU);NJo=r(dOt,"MBartForCausalLM"),dOt.forEach(t),qJo=r(nXe," (mBART model)"),nXe.forEach(t),jJo=i(H),vv=n(H,"LI",{});var sXe=s(vv);AFe=n(sXe,"STRONG",{});var mOt=s(AFe);DJo=r(mOt,"megatron-bert"),mOt.forEach(t),GJo=r(sXe," \u2014 "),mU=n(sXe,"A",{href:!0});var cOt=s(mU);OJo=r(cOt,"MegatronBertForCausalLM"),cOt.forEach(t),VJo=r(sXe," (Megatron-BERT model)"),sXe.forEach(t),XJo=i(H),Fv=n(H,"LI",{});var lXe=s(Fv);LFe=n(lXe,"STRONG",{});var fOt=s(LFe);zJo=r(fOt,"mvp"),fOt.forEach(t),QJo=r(lXe," \u2014 "),cU=n(lXe,"A",{href:!0});var gOt=s(cU);WJo=r(gOt,"MvpForCausalLM"),gOt.forEach(t),UJo=r(lXe," (MVP model)"),lXe.forEach(t),HJo=i(H),Tv=n(H,"LI",{});var iXe=s(Tv);yFe=n(iXe,"STRONG",{});var hOt=s(yFe);JJo=r(hOt,"openai-gpt"),hOt.forEach(t),YJo=r(iXe," \u2014 "),fU=n(iXe,"A",{href:!0});var uOt=s(fU);ZJo=r(uOt,"OpenAIGPTLMHeadModel"),uOt.forEach(t),KJo=r(iXe," (OpenAI GPT model)"),iXe.forEach(t),eYo=i(H),Mv=n(H,"LI",{});var dXe=s(Mv);xFe=n(dXe,"STRONG",{});var pOt=s(xFe);oYo=r(pOt,"opt"),pOt.forEach(t),rYo=r(dXe," \u2014 "),gU=n(dXe,"A",{href:!0});var _Ot=s(gU);tYo=r(_Ot,"OPTForCausalLM"),_Ot.forEach(t),aYo=r(dXe," (OPT model)"),dXe.forEach(t),nYo=i(H),Ev=n(H,"LI",{});var mXe=s(Ev);$Fe=n(mXe,"STRONG",{});var bOt=s($Fe);sYo=r(bOt,"pegasus"),bOt.forEach(t),lYo=r(mXe," \u2014 "),hU=n(mXe,"A",{href:!0});var vOt=s(hU);iYo=r(vOt,"PegasusForCausalLM"),vOt.forEach(t),dYo=r(mXe," (Pegasus model)"),mXe.forEach(t),mYo=i(H),Cv=n(H,"LI",{});var cXe=s(Cv);kFe=n(cXe,"STRONG",{});var FOt=s(kFe);cYo=r(FOt,"plbart"),FOt.forEach(t),fYo=r(cXe," \u2014 "),uU=n(cXe,"A",{href:!0});var TOt=s(uU);gYo=r(TOt,"PLBartForCausalLM"),TOt.forEach(t),hYo=r(cXe," (PLBart model)"),cXe.forEach(t),uYo=i(H),wv=n(H,"LI",{});var fXe=s(wv);SFe=n(fXe,"STRONG",{});var MOt=s(SFe);pYo=r(MOt,"prophetnet"),MOt.forEach(t),_Yo=r(fXe," \u2014 "),pU=n(fXe,"A",{href:!0});var EOt=s(pU);bYo=r(EOt,"ProphetNetForCausalLM"),EOt.forEach(t),vYo=r(fXe," (ProphetNet model)"),fXe.forEach(t),FYo=i(H),Av=n(H,"LI",{});var gXe=s(Av);RFe=n(gXe,"STRONG",{});var COt=s(RFe);TYo=r(COt,"qdqbert"),COt.forEach(t),MYo=r(gXe," \u2014 "),_U=n(gXe,"A",{href:!0});var wOt=s(_U);EYo=r(wOt,"QDQBertLMHeadModel"),wOt.forEach(t),CYo=r(gXe," (QDQBert model)"),gXe.forEach(t),wYo=i(H),Lv=n(H,"LI",{});var hXe=s(Lv);PFe=n(hXe,"STRONG",{});var AOt=s(PFe);AYo=r(AOt,"reformer"),AOt.forEach(t),LYo=r(hXe," \u2014 "),bU=n(hXe,"A",{href:!0});var LOt=s(bU);yYo=r(LOt,"ReformerModelWithLMHead"),LOt.forEach(t),xYo=r(hXe," (Reformer model)"),hXe.forEach(t),$Yo=i(H),yv=n(H,"LI",{});var uXe=s(yv);BFe=n(uXe,"STRONG",{});var yOt=s(BFe);kYo=r(yOt,"rembert"),yOt.forEach(t),SYo=r(uXe," \u2014 "),vU=n(uXe,"A",{href:!0});var xOt=s(vU);RYo=r(xOt,"RemBertForCausalLM"),xOt.forEach(t),PYo=r(uXe," (RemBERT model)"),uXe.forEach(t),BYo=i(H),xv=n(H,"LI",{});var pXe=s(xv);IFe=n(pXe,"STRONG",{});var $Ot=s(IFe);IYo=r($Ot,"roberta"),$Ot.forEach(t),NYo=r(pXe," \u2014 "),FU=n(pXe,"A",{href:!0});var kOt=s(FU);qYo=r(kOt,"RobertaForCausalLM"),kOt.forEach(t),jYo=r(pXe," (RoBERTa model)"),pXe.forEach(t),DYo=i(H),$v=n(H,"LI",{});var _Xe=s($v);NFe=n(_Xe,"STRONG",{});var SOt=s(NFe);GYo=r(SOt,"roformer"),SOt.forEach(t),OYo=r(_Xe," \u2014 "),TU=n(_Xe,"A",{href:!0});var ROt=s(TU);VYo=r(ROt,"RoFormerForCausalLM"),ROt.forEach(t),XYo=r(_Xe," (RoFormer model)"),_Xe.forEach(t),zYo=i(H),kv=n(H,"LI",{});var bXe=s(kv);qFe=n(bXe,"STRONG",{});var POt=s(qFe);QYo=r(POt,"speech_to_text_2"),POt.forEach(t),WYo=r(bXe," \u2014 "),MU=n(bXe,"A",{href:!0});var BOt=s(MU);UYo=r(BOt,"Speech2Text2ForCausalLM"),BOt.forEach(t),HYo=r(bXe," (Speech2Text2 model)"),bXe.forEach(t),JYo=i(H),Sv=n(H,"LI",{});var vXe=s(Sv);jFe=n(vXe,"STRONG",{});var IOt=s(jFe);YYo=r(IOt,"transfo-xl"),IOt.forEach(t),ZYo=r(vXe," \u2014 "),EU=n(vXe,"A",{href:!0});var NOt=s(EU);KYo=r(NOt,"TransfoXLLMHeadModel"),NOt.forEach(t),eZo=r(vXe," (Transformer-XL model)"),vXe.forEach(t),oZo=i(H),Rv=n(H,"LI",{});var FXe=s(Rv);DFe=n(FXe,"STRONG",{});var qOt=s(DFe);rZo=r(qOt,"trocr"),qOt.forEach(t),tZo=r(FXe," \u2014 "),CU=n(FXe,"A",{href:!0});var jOt=s(CU);aZo=r(jOt,"TrOCRForCausalLM"),jOt.forEach(t),nZo=r(FXe," (TrOCR model)"),FXe.forEach(t),sZo=i(H),Pv=n(H,"LI",{});var TXe=s(Pv);GFe=n(TXe,"STRONG",{});var DOt=s(GFe);lZo=r(DOt,"xglm"),DOt.forEach(t),iZo=r(TXe," \u2014 "),wU=n(TXe,"A",{href:!0});var GOt=s(wU);dZo=r(GOt,"XGLMForCausalLM"),GOt.forEach(t),mZo=r(TXe," (XGLM model)"),TXe.forEach(t),cZo=i(H),Bv=n(H,"LI",{});var MXe=s(Bv);OFe=n(MXe,"STRONG",{});var OOt=s(OFe);fZo=r(OOt,"xlm"),OOt.forEach(t),gZo=r(MXe," \u2014 "),AU=n(MXe,"A",{href:!0});var VOt=s(AU);hZo=r(VOt,"XLMWithLMHeadModel"),VOt.forEach(t),uZo=r(MXe," (XLM model)"),MXe.forEach(t),pZo=i(H),Iv=n(H,"LI",{});var EXe=s(Iv);VFe=n(EXe,"STRONG",{});var XOt=s(VFe);_Zo=r(XOt,"xlm-prophetnet"),XOt.forEach(t),bZo=r(EXe," \u2014 "),LU=n(EXe,"A",{href:!0});var zOt=s(LU);vZo=r(zOt,"XLMProphetNetForCausalLM"),zOt.forEach(t),FZo=r(EXe," (XLM-ProphetNet model)"),EXe.forEach(t),TZo=i(H),Nv=n(H,"LI",{});var CXe=s(Nv);XFe=n(CXe,"STRONG",{});var QOt=s(XFe);MZo=r(QOt,"xlm-roberta"),QOt.forEach(t),EZo=r(CXe," \u2014 "),yU=n(CXe,"A",{href:!0});var WOt=s(yU);CZo=r(WOt,"XLMRobertaForCausalLM"),WOt.forEach(t),wZo=r(CXe," (XLM-RoBERTa model)"),CXe.forEach(t),AZo=i(H),qv=n(H,"LI",{});var wXe=s(qv);zFe=n(wXe,"STRONG",{});var UOt=s(zFe);LZo=r(UOt,"xlm-roberta-xl"),UOt.forEach(t),yZo=r(wXe," \u2014 "),xU=n(wXe,"A",{href:!0});var HOt=s(xU);xZo=r(HOt,"XLMRobertaXLForCausalLM"),HOt.forEach(t),$Zo=r(wXe," (XLM-RoBERTa-XL model)"),wXe.forEach(t),kZo=i(H),jv=n(H,"LI",{});var AXe=s(jv);QFe=n(AXe,"STRONG",{});var JOt=s(QFe);SZo=r(JOt,"xlnet"),JOt.forEach(t),RZo=r(AXe," \u2014 "),$U=n(AXe,"A",{href:!0});var YOt=s($U);PZo=r(YOt,"XLNetLMHeadModel"),YOt.forEach(t),BZo=r(AXe," (XLNet model)"),AXe.forEach(t),H.forEach(t),IZo=i(ya),Dv=n(ya,"P",{});var LXe=s(Dv);NZo=r(LXe,"The model is set in evaluation mode by default using "),WFe=n(LXe,"CODE",{});var ZOt=s(WFe);qZo=r(ZOt,"model.eval()"),ZOt.forEach(t),jZo=r(LXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UFe=n(LXe,"CODE",{});var KOt=s(UFe);DZo=r(KOt,"model.train()"),KOt.forEach(t),LXe.forEach(t),GZo=i(ya),T(Gv.$$.fragment,ya),ya.forEach(t),jl.forEach(t),Lto=i(c),jd=n(c,"H2",{class:!0});var zno=s(jd);Ov=n(zno,"A",{id:!0,class:!0,href:!0});var eVt=s(Ov);HFe=n(eVt,"SPAN",{});var oVt=s(HFe);T(Q$.$$.fragment,oVt),oVt.forEach(t),eVt.forEach(t),OZo=i(zno),JFe=n(zno,"SPAN",{});var rVt=s(JFe);VZo=r(rVt,"AutoModelForDepthEstimation"),rVt.forEach(t),zno.forEach(t),yto=i(c),jo=n(c,"DIV",{class:!0});var Dl=s(jo);T(W$.$$.fragment,Dl),XZo=i(Dl),Dd=n(Dl,"P",{});var eme=s(Dd);zZo=r(eme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),kU=n(eme,"A",{href:!0});var tVt=s(kU);QZo=r(tVt,"from_pretrained()"),tVt.forEach(t),WZo=r(eme," class method or the "),SU=n(eme,"A",{href:!0});var aVt=s(SU);UZo=r(aVt,"from_config()"),aVt.forEach(t),HZo=r(eme,` class
method.`),eme.forEach(t),JZo=i(Dl),U$=n(Dl,"P",{});var Qno=s(U$);YZo=r(Qno,"This class cannot be instantiated directly using "),YFe=n(Qno,"CODE",{});var nVt=s(YFe);ZZo=r(nVt,"__init__()"),nVt.forEach(t),KZo=r(Qno," (throws an error)."),Qno.forEach(t),eKo=i(Dl),Ct=n(Dl,"DIV",{class:!0});var o9=s(Ct);T(H$.$$.fragment,o9),oKo=i(o9),ZFe=n(o9,"P",{});var sVt=s(ZFe);rKo=r(sVt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),sVt.forEach(t),tKo=i(o9),Gd=n(o9,"P",{});var ome=s(Gd);aKo=r(ome,`Note:
Loading a model from its configuration file does `),KFe=n(ome,"STRONG",{});var lVt=s(KFe);nKo=r(lVt,"not"),lVt.forEach(t),sKo=r(ome,` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=n(ome,"A",{href:!0});var iVt=s(RU);lKo=r(iVt,"from_pretrained()"),iVt.forEach(t),iKo=r(ome," to load the model weights."),ome.forEach(t),dKo=i(o9),T(Vv.$$.fragment,o9),o9.forEach(t),mKo=i(Dl),ro=n(Dl,"DIV",{class:!0});var xa=s(ro);T(J$.$$.fragment,xa),cKo=i(xa),eTe=n(xa,"P",{});var dVt=s(eTe);fKo=r(dVt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),dVt.forEach(t),gKo=i(xa),ln=n(xa,"P",{});var r9=s(ln);hKo=r(r9,"The model class to instantiate is selected based on the "),oTe=n(r9,"CODE",{});var mVt=s(oTe);uKo=r(mVt,"model_type"),mVt.forEach(t),pKo=r(r9,` property of the config object (either
passed as an argument or loaded from `),rTe=n(r9,"CODE",{});var cVt=s(rTe);_Ko=r(cVt,"pretrained_model_name_or_path"),cVt.forEach(t),bKo=r(r9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tTe=n(r9,"CODE",{});var fVt=s(tTe);vKo=r(fVt,"pretrained_model_name_or_path"),fVt.forEach(t),FKo=r(r9,":"),r9.forEach(t),TKo=i(xa),Y$=n(xa,"UL",{});var Wno=s(Y$);Xv=n(Wno,"LI",{});var yXe=s(Xv);aTe=n(yXe,"STRONG",{});var gVt=s(aTe);MKo=r(gVt,"dpt"),gVt.forEach(t),EKo=r(yXe," \u2014 "),PU=n(yXe,"A",{href:!0});var hVt=s(PU);CKo=r(hVt,"DPTForDepthEstimation"),hVt.forEach(t),wKo=r(yXe," (DPT model)"),yXe.forEach(t),AKo=i(Wno),zv=n(Wno,"LI",{});var xXe=s(zv);nTe=n(xXe,"STRONG",{});var uVt=s(nTe);LKo=r(uVt,"glpn"),uVt.forEach(t),yKo=r(xXe," \u2014 "),BU=n(xXe,"A",{href:!0});var pVt=s(BU);xKo=r(pVt,"GLPNForDepthEstimation"),pVt.forEach(t),$Ko=r(xXe," (GLPN model)"),xXe.forEach(t),Wno.forEach(t),kKo=i(xa),Qv=n(xa,"P",{});var $Xe=s(Qv);SKo=r($Xe,"The model is set in evaluation mode by default using "),sTe=n($Xe,"CODE",{});var _Vt=s(sTe);RKo=r(_Vt,"model.eval()"),_Vt.forEach(t),PKo=r($Xe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lTe=n($Xe,"CODE",{});var bVt=s(lTe);BKo=r(bVt,"model.train()"),bVt.forEach(t),$Xe.forEach(t),IKo=i(xa),T(Wv.$$.fragment,xa),xa.forEach(t),Dl.forEach(t),xto=i(c),Od=n(c,"H2",{class:!0});var Uno=s(Od);Uv=n(Uno,"A",{id:!0,class:!0,href:!0});var vVt=s(Uv);iTe=n(vVt,"SPAN",{});var FVt=s(iTe);T(Z$.$$.fragment,FVt),FVt.forEach(t),vVt.forEach(t),NKo=i(Uno),dTe=n(Uno,"SPAN",{});var TVt=s(dTe);qKo=r(TVt,"AutoModelForMaskedLM"),TVt.forEach(t),Uno.forEach(t),$to=i(c),Do=n(c,"DIV",{class:!0});var Gl=s(Do);T(K$.$$.fragment,Gl),jKo=i(Gl),Vd=n(Gl,"P",{});var rme=s(Vd);DKo=r(rme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),IU=n(rme,"A",{href:!0});var MVt=s(IU);GKo=r(MVt,"from_pretrained()"),MVt.forEach(t),OKo=r(rme," class method or the "),NU=n(rme,"A",{href:!0});var EVt=s(NU);VKo=r(EVt,"from_config()"),EVt.forEach(t),XKo=r(rme,` class
method.`),rme.forEach(t),zKo=i(Gl),ek=n(Gl,"P",{});var Hno=s(ek);QKo=r(Hno,"This class cannot be instantiated directly using "),mTe=n(Hno,"CODE",{});var CVt=s(mTe);WKo=r(CVt,"__init__()"),CVt.forEach(t),UKo=r(Hno," (throws an error)."),Hno.forEach(t),HKo=i(Gl),wt=n(Gl,"DIV",{class:!0});var t9=s(wt);T(ok.$$.fragment,t9),JKo=i(t9),cTe=n(t9,"P",{});var wVt=s(cTe);YKo=r(wVt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wVt.forEach(t),ZKo=i(t9),Xd=n(t9,"P",{});var tme=s(Xd);KKo=r(tme,`Note:
Loading a model from its configuration file does `),fTe=n(tme,"STRONG",{});var AVt=s(fTe);eer=r(AVt,"not"),AVt.forEach(t),oer=r(tme,` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=n(tme,"A",{href:!0});var LVt=s(qU);rer=r(LVt,"from_pretrained()"),LVt.forEach(t),ter=r(tme," to load the model weights."),tme.forEach(t),aer=i(t9),T(Hv.$$.fragment,t9),t9.forEach(t),ner=i(Gl),to=n(Gl,"DIV",{class:!0});var $a=s(to);T(rk.$$.fragment,$a),ser=i($a),gTe=n($a,"P",{});var yVt=s(gTe);ler=r(yVt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),yVt.forEach(t),ier=i($a),dn=n($a,"P",{});var a9=s(dn);der=r(a9,"The model class to instantiate is selected based on the "),hTe=n(a9,"CODE",{});var xVt=s(hTe);mer=r(xVt,"model_type"),xVt.forEach(t),cer=r(a9,` property of the config object (either
passed as an argument or loaded from `),uTe=n(a9,"CODE",{});var $Vt=s(uTe);fer=r($Vt,"pretrained_model_name_or_path"),$Vt.forEach(t),ger=r(a9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=n(a9,"CODE",{});var kVt=s(pTe);her=r(kVt,"pretrained_model_name_or_path"),kVt.forEach(t),uer=r(a9,":"),a9.forEach(t),per=i($a),Y=n($a,"UL",{});var Z=s(Y);Jv=n(Z,"LI",{});var kXe=s(Jv);_Te=n(kXe,"STRONG",{});var SVt=s(_Te);_er=r(SVt,"albert"),SVt.forEach(t),ber=r(kXe," \u2014 "),jU=n(kXe,"A",{href:!0});var RVt=s(jU);ver=r(RVt,"AlbertForMaskedLM"),RVt.forEach(t),Fer=r(kXe," (ALBERT model)"),kXe.forEach(t),Ter=i(Z),Yv=n(Z,"LI",{});var SXe=s(Yv);bTe=n(SXe,"STRONG",{});var PVt=s(bTe);Mer=r(PVt,"bart"),PVt.forEach(t),Eer=r(SXe," \u2014 "),DU=n(SXe,"A",{href:!0});var BVt=s(DU);Cer=r(BVt,"BartForConditionalGeneration"),BVt.forEach(t),wer=r(SXe," (BART model)"),SXe.forEach(t),Aer=i(Z),Zv=n(Z,"LI",{});var RXe=s(Zv);vTe=n(RXe,"STRONG",{});var IVt=s(vTe);Ler=r(IVt,"bert"),IVt.forEach(t),yer=r(RXe," \u2014 "),GU=n(RXe,"A",{href:!0});var NVt=s(GU);xer=r(NVt,"BertForMaskedLM"),NVt.forEach(t),$er=r(RXe," (BERT model)"),RXe.forEach(t),ker=i(Z),Kv=n(Z,"LI",{});var PXe=s(Kv);FTe=n(PXe,"STRONG",{});var qVt=s(FTe);Ser=r(qVt,"big_bird"),qVt.forEach(t),Rer=r(PXe," \u2014 "),OU=n(PXe,"A",{href:!0});var jVt=s(OU);Per=r(jVt,"BigBirdForMaskedLM"),jVt.forEach(t),Ber=r(PXe," (BigBird model)"),PXe.forEach(t),Ier=i(Z),eF=n(Z,"LI",{});var BXe=s(eF);TTe=n(BXe,"STRONG",{});var DVt=s(TTe);Ner=r(DVt,"camembert"),DVt.forEach(t),qer=r(BXe," \u2014 "),VU=n(BXe,"A",{href:!0});var GVt=s(VU);jer=r(GVt,"CamembertForMaskedLM"),GVt.forEach(t),Der=r(BXe," (CamemBERT model)"),BXe.forEach(t),Ger=i(Z),oF=n(Z,"LI",{});var IXe=s(oF);MTe=n(IXe,"STRONG",{});var OVt=s(MTe);Oer=r(OVt,"convbert"),OVt.forEach(t),Ver=r(IXe," \u2014 "),XU=n(IXe,"A",{href:!0});var VVt=s(XU);Xer=r(VVt,"ConvBertForMaskedLM"),VVt.forEach(t),zer=r(IXe," (ConvBERT model)"),IXe.forEach(t),Qer=i(Z),rF=n(Z,"LI",{});var NXe=s(rF);ETe=n(NXe,"STRONG",{});var XVt=s(ETe);Wer=r(XVt,"data2vec-text"),XVt.forEach(t),Uer=r(NXe," \u2014 "),zU=n(NXe,"A",{href:!0});var zVt=s(zU);Her=r(zVt,"Data2VecTextForMaskedLM"),zVt.forEach(t),Jer=r(NXe," (Data2VecText model)"),NXe.forEach(t),Yer=i(Z),tF=n(Z,"LI",{});var qXe=s(tF);CTe=n(qXe,"STRONG",{});var QVt=s(CTe);Zer=r(QVt,"deberta"),QVt.forEach(t),Ker=r(qXe," \u2014 "),QU=n(qXe,"A",{href:!0});var WVt=s(QU);eor=r(WVt,"DebertaForMaskedLM"),WVt.forEach(t),oor=r(qXe," (DeBERTa model)"),qXe.forEach(t),ror=i(Z),aF=n(Z,"LI",{});var jXe=s(aF);wTe=n(jXe,"STRONG",{});var UVt=s(wTe);tor=r(UVt,"deberta-v2"),UVt.forEach(t),aor=r(jXe," \u2014 "),WU=n(jXe,"A",{href:!0});var HVt=s(WU);nor=r(HVt,"DebertaV2ForMaskedLM"),HVt.forEach(t),sor=r(jXe," (DeBERTa-v2 model)"),jXe.forEach(t),lor=i(Z),nF=n(Z,"LI",{});var DXe=s(nF);ATe=n(DXe,"STRONG",{});var JVt=s(ATe);ior=r(JVt,"distilbert"),JVt.forEach(t),dor=r(DXe," \u2014 "),UU=n(DXe,"A",{href:!0});var YVt=s(UU);mor=r(YVt,"DistilBertForMaskedLM"),YVt.forEach(t),cor=r(DXe," (DistilBERT model)"),DXe.forEach(t),gor=i(Z),sF=n(Z,"LI",{});var GXe=s(sF);LTe=n(GXe,"STRONG",{});var ZVt=s(LTe);hor=r(ZVt,"electra"),ZVt.forEach(t),uor=r(GXe," \u2014 "),HU=n(GXe,"A",{href:!0});var KVt=s(HU);por=r(KVt,"ElectraForMaskedLM"),KVt.forEach(t),_or=r(GXe," (ELECTRA model)"),GXe.forEach(t),bor=i(Z),lF=n(Z,"LI",{});var OXe=s(lF);yTe=n(OXe,"STRONG",{});var eXt=s(yTe);vor=r(eXt,"ernie"),eXt.forEach(t),For=r(OXe," \u2014 "),JU=n(OXe,"A",{href:!0});var oXt=s(JU);Tor=r(oXt,"ErnieForMaskedLM"),oXt.forEach(t),Mor=r(OXe," (ERNIE model)"),OXe.forEach(t),Eor=i(Z),iF=n(Z,"LI",{});var VXe=s(iF);xTe=n(VXe,"STRONG",{});var rXt=s(xTe);Cor=r(rXt,"flaubert"),rXt.forEach(t),wor=r(VXe," \u2014 "),YU=n(VXe,"A",{href:!0});var tXt=s(YU);Aor=r(tXt,"FlaubertWithLMHeadModel"),tXt.forEach(t),Lor=r(VXe," (FlauBERT model)"),VXe.forEach(t),yor=i(Z),dF=n(Z,"LI",{});var XXe=s(dF);$Te=n(XXe,"STRONG",{});var aXt=s($Te);xor=r(aXt,"fnet"),aXt.forEach(t),$or=r(XXe," \u2014 "),ZU=n(XXe,"A",{href:!0});var nXt=s(ZU);kor=r(nXt,"FNetForMaskedLM"),nXt.forEach(t),Sor=r(XXe," (FNet model)"),XXe.forEach(t),Ror=i(Z),mF=n(Z,"LI",{});var zXe=s(mF);kTe=n(zXe,"STRONG",{});var sXt=s(kTe);Por=r(sXt,"funnel"),sXt.forEach(t),Bor=r(zXe," \u2014 "),KU=n(zXe,"A",{href:!0});var lXt=s(KU);Ior=r(lXt,"FunnelForMaskedLM"),lXt.forEach(t),Nor=r(zXe," (Funnel Transformer model)"),zXe.forEach(t),qor=i(Z),cF=n(Z,"LI",{});var QXe=s(cF);STe=n(QXe,"STRONG",{});var iXt=s(STe);jor=r(iXt,"ibert"),iXt.forEach(t),Dor=r(QXe," \u2014 "),eH=n(QXe,"A",{href:!0});var dXt=s(eH);Gor=r(dXt,"IBertForMaskedLM"),dXt.forEach(t),Oor=r(QXe," (I-BERT model)"),QXe.forEach(t),Vor=i(Z),fF=n(Z,"LI",{});var WXe=s(fF);RTe=n(WXe,"STRONG",{});var mXt=s(RTe);Xor=r(mXt,"layoutlm"),mXt.forEach(t),zor=r(WXe," \u2014 "),oH=n(WXe,"A",{href:!0});var cXt=s(oH);Qor=r(cXt,"LayoutLMForMaskedLM"),cXt.forEach(t),Wor=r(WXe," (LayoutLM model)"),WXe.forEach(t),Uor=i(Z),gF=n(Z,"LI",{});var UXe=s(gF);PTe=n(UXe,"STRONG",{});var fXt=s(PTe);Hor=r(fXt,"longformer"),fXt.forEach(t),Jor=r(UXe," \u2014 "),rH=n(UXe,"A",{href:!0});var gXt=s(rH);Yor=r(gXt,"LongformerForMaskedLM"),gXt.forEach(t),Zor=r(UXe," (Longformer model)"),UXe.forEach(t),Kor=i(Z),hF=n(Z,"LI",{});var HXe=s(hF);BTe=n(HXe,"STRONG",{});var hXt=s(BTe);err=r(hXt,"luke"),hXt.forEach(t),orr=r(HXe," \u2014 "),tH=n(HXe,"A",{href:!0});var uXt=s(tH);rrr=r(uXt,"LukeForMaskedLM"),uXt.forEach(t),trr=r(HXe," (LUKE model)"),HXe.forEach(t),arr=i(Z),uF=n(Z,"LI",{});var JXe=s(uF);ITe=n(JXe,"STRONG",{});var pXt=s(ITe);nrr=r(pXt,"mbart"),pXt.forEach(t),srr=r(JXe," \u2014 "),aH=n(JXe,"A",{href:!0});var _Xt=s(aH);lrr=r(_Xt,"MBartForConditionalGeneration"),_Xt.forEach(t),irr=r(JXe," (mBART model)"),JXe.forEach(t),drr=i(Z),pF=n(Z,"LI",{});var YXe=s(pF);NTe=n(YXe,"STRONG",{});var bXt=s(NTe);mrr=r(bXt,"megatron-bert"),bXt.forEach(t),crr=r(YXe," \u2014 "),nH=n(YXe,"A",{href:!0});var vXt=s(nH);frr=r(vXt,"MegatronBertForMaskedLM"),vXt.forEach(t),grr=r(YXe," (Megatron-BERT model)"),YXe.forEach(t),hrr=i(Z),_F=n(Z,"LI",{});var ZXe=s(_F);qTe=n(ZXe,"STRONG",{});var FXt=s(qTe);urr=r(FXt,"mobilebert"),FXt.forEach(t),prr=r(ZXe," \u2014 "),sH=n(ZXe,"A",{href:!0});var TXt=s(sH);_rr=r(TXt,"MobileBertForMaskedLM"),TXt.forEach(t),brr=r(ZXe," (MobileBERT model)"),ZXe.forEach(t),vrr=i(Z),bF=n(Z,"LI",{});var KXe=s(bF);jTe=n(KXe,"STRONG",{});var MXt=s(jTe);Frr=r(MXt,"mpnet"),MXt.forEach(t),Trr=r(KXe," \u2014 "),lH=n(KXe,"A",{href:!0});var EXt=s(lH);Mrr=r(EXt,"MPNetForMaskedLM"),EXt.forEach(t),Err=r(KXe," (MPNet model)"),KXe.forEach(t),Crr=i(Z),vF=n(Z,"LI",{});var eze=s(vF);DTe=n(eze,"STRONG",{});var CXt=s(DTe);wrr=r(CXt,"mvp"),CXt.forEach(t),Arr=r(eze," \u2014 "),iH=n(eze,"A",{href:!0});var wXt=s(iH);Lrr=r(wXt,"MvpForConditionalGeneration"),wXt.forEach(t),yrr=r(eze," (MVP model)"),eze.forEach(t),xrr=i(Z),FF=n(Z,"LI",{});var oze=s(FF);GTe=n(oze,"STRONG",{});var AXt=s(GTe);$rr=r(AXt,"nezha"),AXt.forEach(t),krr=r(oze," \u2014 "),dH=n(oze,"A",{href:!0});var LXt=s(dH);Srr=r(LXt,"NezhaForMaskedLM"),LXt.forEach(t),Rrr=r(oze," (Nezha model)"),oze.forEach(t),Prr=i(Z),TF=n(Z,"LI",{});var rze=s(TF);OTe=n(rze,"STRONG",{});var yXt=s(OTe);Brr=r(yXt,"nystromformer"),yXt.forEach(t),Irr=r(rze," \u2014 "),mH=n(rze,"A",{href:!0});var xXt=s(mH);Nrr=r(xXt,"NystromformerForMaskedLM"),xXt.forEach(t),qrr=r(rze," (Nystr\xF6mformer model)"),rze.forEach(t),jrr=i(Z),MF=n(Z,"LI",{});var tze=s(MF);VTe=n(tze,"STRONG",{});var $Xt=s(VTe);Drr=r($Xt,"perceiver"),$Xt.forEach(t),Grr=r(tze," \u2014 "),cH=n(tze,"A",{href:!0});var kXt=s(cH);Orr=r(kXt,"PerceiverForMaskedLM"),kXt.forEach(t),Vrr=r(tze," (Perceiver model)"),tze.forEach(t),Xrr=i(Z),EF=n(Z,"LI",{});var aze=s(EF);XTe=n(aze,"STRONG",{});var SXt=s(XTe);zrr=r(SXt,"qdqbert"),SXt.forEach(t),Qrr=r(aze," \u2014 "),fH=n(aze,"A",{href:!0});var RXt=s(fH);Wrr=r(RXt,"QDQBertForMaskedLM"),RXt.forEach(t),Urr=r(aze," (QDQBert model)"),aze.forEach(t),Hrr=i(Z),CF=n(Z,"LI",{});var nze=s(CF);zTe=n(nze,"STRONG",{});var PXt=s(zTe);Jrr=r(PXt,"reformer"),PXt.forEach(t),Yrr=r(nze," \u2014 "),gH=n(nze,"A",{href:!0});var BXt=s(gH);Zrr=r(BXt,"ReformerForMaskedLM"),BXt.forEach(t),Krr=r(nze," (Reformer model)"),nze.forEach(t),etr=i(Z),wF=n(Z,"LI",{});var sze=s(wF);QTe=n(sze,"STRONG",{});var IXt=s(QTe);otr=r(IXt,"rembert"),IXt.forEach(t),rtr=r(sze," \u2014 "),hH=n(sze,"A",{href:!0});var NXt=s(hH);ttr=r(NXt,"RemBertForMaskedLM"),NXt.forEach(t),atr=r(sze," (RemBERT model)"),sze.forEach(t),ntr=i(Z),AF=n(Z,"LI",{});var lze=s(AF);WTe=n(lze,"STRONG",{});var qXt=s(WTe);str=r(qXt,"roberta"),qXt.forEach(t),ltr=r(lze," \u2014 "),uH=n(lze,"A",{href:!0});var jXt=s(uH);itr=r(jXt,"RobertaForMaskedLM"),jXt.forEach(t),dtr=r(lze," (RoBERTa model)"),lze.forEach(t),mtr=i(Z),LF=n(Z,"LI",{});var ize=s(LF);UTe=n(ize,"STRONG",{});var DXt=s(UTe);ctr=r(DXt,"roformer"),DXt.forEach(t),ftr=r(ize," \u2014 "),pH=n(ize,"A",{href:!0});var GXt=s(pH);gtr=r(GXt,"RoFormerForMaskedLM"),GXt.forEach(t),htr=r(ize," (RoFormer model)"),ize.forEach(t),utr=i(Z),yF=n(Z,"LI",{});var dze=s(yF);HTe=n(dze,"STRONG",{});var OXt=s(HTe);ptr=r(OXt,"squeezebert"),OXt.forEach(t),_tr=r(dze," \u2014 "),_H=n(dze,"A",{href:!0});var VXt=s(_H);btr=r(VXt,"SqueezeBertForMaskedLM"),VXt.forEach(t),vtr=r(dze," (SqueezeBERT model)"),dze.forEach(t),Ftr=i(Z),xF=n(Z,"LI",{});var mze=s(xF);JTe=n(mze,"STRONG",{});var XXt=s(JTe);Ttr=r(XXt,"tapas"),XXt.forEach(t),Mtr=r(mze," \u2014 "),bH=n(mze,"A",{href:!0});var zXt=s(bH);Etr=r(zXt,"TapasForMaskedLM"),zXt.forEach(t),Ctr=r(mze," (TAPAS model)"),mze.forEach(t),wtr=i(Z),$F=n(Z,"LI",{});var cze=s($F);YTe=n(cze,"STRONG",{});var QXt=s(YTe);Atr=r(QXt,"wav2vec2"),QXt.forEach(t),Ltr=r(cze," \u2014 "),ZTe=n(cze,"CODE",{});var WXt=s(ZTe);ytr=r(WXt,"Wav2Vec2ForMaskedLM"),WXt.forEach(t),xtr=r(cze," (Wav2Vec2 model)"),cze.forEach(t),$tr=i(Z),kF=n(Z,"LI",{});var fze=s(kF);KTe=n(fze,"STRONG",{});var UXt=s(KTe);ktr=r(UXt,"xlm"),UXt.forEach(t),Str=r(fze," \u2014 "),vH=n(fze,"A",{href:!0});var HXt=s(vH);Rtr=r(HXt,"XLMWithLMHeadModel"),HXt.forEach(t),Ptr=r(fze," (XLM model)"),fze.forEach(t),Btr=i(Z),SF=n(Z,"LI",{});var gze=s(SF);eMe=n(gze,"STRONG",{});var JXt=s(eMe);Itr=r(JXt,"xlm-roberta"),JXt.forEach(t),Ntr=r(gze," \u2014 "),FH=n(gze,"A",{href:!0});var YXt=s(FH);qtr=r(YXt,"XLMRobertaForMaskedLM"),YXt.forEach(t),jtr=r(gze," (XLM-RoBERTa model)"),gze.forEach(t),Dtr=i(Z),RF=n(Z,"LI",{});var hze=s(RF);oMe=n(hze,"STRONG",{});var ZXt=s(oMe);Gtr=r(ZXt,"xlm-roberta-xl"),ZXt.forEach(t),Otr=r(hze," \u2014 "),TH=n(hze,"A",{href:!0});var KXt=s(TH);Vtr=r(KXt,"XLMRobertaXLForMaskedLM"),KXt.forEach(t),Xtr=r(hze," (XLM-RoBERTa-XL model)"),hze.forEach(t),ztr=i(Z),PF=n(Z,"LI",{});var uze=s(PF);rMe=n(uze,"STRONG",{});var ezt=s(rMe);Qtr=r(ezt,"yoso"),ezt.forEach(t),Wtr=r(uze," \u2014 "),MH=n(uze,"A",{href:!0});var ozt=s(MH);Utr=r(ozt,"YosoForMaskedLM"),ozt.forEach(t),Htr=r(uze," (YOSO model)"),uze.forEach(t),Z.forEach(t),Jtr=i($a),BF=n($a,"P",{});var pze=s(BF);Ytr=r(pze,"The model is set in evaluation mode by default using "),tMe=n(pze,"CODE",{});var rzt=s(tMe);Ztr=r(rzt,"model.eval()"),rzt.forEach(t),Ktr=r(pze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aMe=n(pze,"CODE",{});var tzt=s(aMe);ear=r(tzt,"model.train()"),tzt.forEach(t),pze.forEach(t),oar=i($a),T(IF.$$.fragment,$a),$a.forEach(t),Gl.forEach(t),kto=i(c),zd=n(c,"H2",{class:!0});var Jno=s(zd);NF=n(Jno,"A",{id:!0,class:!0,href:!0});var azt=s(NF);nMe=n(azt,"SPAN",{});var nzt=s(nMe);T(tk.$$.fragment,nzt),nzt.forEach(t),azt.forEach(t),rar=i(Jno),sMe=n(Jno,"SPAN",{});var szt=s(sMe);tar=r(szt,"AutoModelForSeq2SeqLM"),szt.forEach(t),Jno.forEach(t),Sto=i(c),Go=n(c,"DIV",{class:!0});var Ol=s(Go);T(ak.$$.fragment,Ol),aar=i(Ol),Qd=n(Ol,"P",{});var ame=s(Qd);nar=r(ame,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EH=n(ame,"A",{href:!0});var lzt=s(EH);sar=r(lzt,"from_pretrained()"),lzt.forEach(t),lar=r(ame," class method or the "),CH=n(ame,"A",{href:!0});var izt=s(CH);iar=r(izt,"from_config()"),izt.forEach(t),dar=r(ame,` class
method.`),ame.forEach(t),mar=i(Ol),nk=n(Ol,"P",{});var Yno=s(nk);car=r(Yno,"This class cannot be instantiated directly using "),lMe=n(Yno,"CODE",{});var dzt=s(lMe);far=r(dzt,"__init__()"),dzt.forEach(t),gar=r(Yno," (throws an error)."),Yno.forEach(t),har=i(Ol),At=n(Ol,"DIV",{class:!0});var n9=s(At);T(sk.$$.fragment,n9),uar=i(n9),iMe=n(n9,"P",{});var mzt=s(iMe);par=r(mzt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),mzt.forEach(t),_ar=i(n9),Wd=n(n9,"P",{});var nme=s(Wd);bar=r(nme,`Note:
Loading a model from its configuration file does `),dMe=n(nme,"STRONG",{});var czt=s(dMe);Far=r(czt,"not"),czt.forEach(t),Tar=r(nme,` load the model weights. It only affects the
model\u2019s configuration. Use `),wH=n(nme,"A",{href:!0});var fzt=s(wH);Mar=r(fzt,"from_pretrained()"),fzt.forEach(t),Ear=r(nme," to load the model weights."),nme.forEach(t),Car=i(n9),T(qF.$$.fragment,n9),n9.forEach(t),war=i(Ol),ao=n(Ol,"DIV",{class:!0});var ka=s(ao);T(lk.$$.fragment,ka),Aar=i(ka),mMe=n(ka,"P",{});var gzt=s(mMe);Lar=r(gzt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),gzt.forEach(t),yar=i(ka),mn=n(ka,"P",{});var s9=s(mn);xar=r(s9,"The model class to instantiate is selected based on the "),cMe=n(s9,"CODE",{});var hzt=s(cMe);$ar=r(hzt,"model_type"),hzt.forEach(t),kar=r(s9,` property of the config object (either
passed as an argument or loaded from `),fMe=n(s9,"CODE",{});var uzt=s(fMe);Sar=r(uzt,"pretrained_model_name_or_path"),uzt.forEach(t),Rar=r(s9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gMe=n(s9,"CODE",{});var pzt=s(gMe);Par=r(pzt,"pretrained_model_name_or_path"),pzt.forEach(t),Bar=r(s9,":"),s9.forEach(t),Iar=i(ka),he=n(ka,"UL",{});var _e=s(he);jF=n(_e,"LI",{});var _ze=s(jF);hMe=n(_ze,"STRONG",{});var _zt=s(hMe);Nar=r(_zt,"bart"),_zt.forEach(t),qar=r(_ze," \u2014 "),AH=n(_ze,"A",{href:!0});var bzt=s(AH);jar=r(bzt,"BartForConditionalGeneration"),bzt.forEach(t),Dar=r(_ze," (BART model)"),_ze.forEach(t),Gar=i(_e),DF=n(_e,"LI",{});var bze=s(DF);uMe=n(bze,"STRONG",{});var vzt=s(uMe);Oar=r(vzt,"bigbird_pegasus"),vzt.forEach(t),Var=r(bze," \u2014 "),LH=n(bze,"A",{href:!0});var Fzt=s(LH);Xar=r(Fzt,"BigBirdPegasusForConditionalGeneration"),Fzt.forEach(t),zar=r(bze," (BigBird-Pegasus model)"),bze.forEach(t),Qar=i(_e),GF=n(_e,"LI",{});var vze=s(GF);pMe=n(vze,"STRONG",{});var Tzt=s(pMe);War=r(Tzt,"blenderbot"),Tzt.forEach(t),Uar=r(vze," \u2014 "),yH=n(vze,"A",{href:!0});var Mzt=s(yH);Har=r(Mzt,"BlenderbotForConditionalGeneration"),Mzt.forEach(t),Jar=r(vze," (Blenderbot model)"),vze.forEach(t),Yar=i(_e),OF=n(_e,"LI",{});var Fze=s(OF);_Me=n(Fze,"STRONG",{});var Ezt=s(_Me);Zar=r(Ezt,"blenderbot-small"),Ezt.forEach(t),Kar=r(Fze," \u2014 "),xH=n(Fze,"A",{href:!0});var Czt=s(xH);enr=r(Czt,"BlenderbotSmallForConditionalGeneration"),Czt.forEach(t),onr=r(Fze," (BlenderbotSmall model)"),Fze.forEach(t),rnr=i(_e),VF=n(_e,"LI",{});var Tze=s(VF);bMe=n(Tze,"STRONG",{});var wzt=s(bMe);tnr=r(wzt,"encoder-decoder"),wzt.forEach(t),anr=r(Tze," \u2014 "),$H=n(Tze,"A",{href:!0});var Azt=s($H);nnr=r(Azt,"EncoderDecoderModel"),Azt.forEach(t),snr=r(Tze," (Encoder decoder model)"),Tze.forEach(t),lnr=i(_e),XF=n(_e,"LI",{});var Mze=s(XF);vMe=n(Mze,"STRONG",{});var Lzt=s(vMe);inr=r(Lzt,"fsmt"),Lzt.forEach(t),dnr=r(Mze," \u2014 "),kH=n(Mze,"A",{href:!0});var yzt=s(kH);mnr=r(yzt,"FSMTForConditionalGeneration"),yzt.forEach(t),cnr=r(Mze," (FairSeq Machine-Translation model)"),Mze.forEach(t),fnr=i(_e),zF=n(_e,"LI",{});var Eze=s(zF);FMe=n(Eze,"STRONG",{});var xzt=s(FMe);gnr=r(xzt,"led"),xzt.forEach(t),hnr=r(Eze," \u2014 "),SH=n(Eze,"A",{href:!0});var $zt=s(SH);unr=r($zt,"LEDForConditionalGeneration"),$zt.forEach(t),pnr=r(Eze," (LED model)"),Eze.forEach(t),_nr=i(_e),QF=n(_e,"LI",{});var Cze=s(QF);TMe=n(Cze,"STRONG",{});var kzt=s(TMe);bnr=r(kzt,"longt5"),kzt.forEach(t),vnr=r(Cze," \u2014 "),RH=n(Cze,"A",{href:!0});var Szt=s(RH);Fnr=r(Szt,"LongT5ForConditionalGeneration"),Szt.forEach(t),Tnr=r(Cze," (LongT5 model)"),Cze.forEach(t),Mnr=i(_e),WF=n(_e,"LI",{});var wze=s(WF);MMe=n(wze,"STRONG",{});var Rzt=s(MMe);Enr=r(Rzt,"m2m_100"),Rzt.forEach(t),Cnr=r(wze," \u2014 "),PH=n(wze,"A",{href:!0});var Pzt=s(PH);wnr=r(Pzt,"M2M100ForConditionalGeneration"),Pzt.forEach(t),Anr=r(wze," (M2M100 model)"),wze.forEach(t),Lnr=i(_e),UF=n(_e,"LI",{});var Aze=s(UF);EMe=n(Aze,"STRONG",{});var Bzt=s(EMe);ynr=r(Bzt,"marian"),Bzt.forEach(t),xnr=r(Aze," \u2014 "),BH=n(Aze,"A",{href:!0});var Izt=s(BH);$nr=r(Izt,"MarianMTModel"),Izt.forEach(t),knr=r(Aze," (Marian model)"),Aze.forEach(t),Snr=i(_e),HF=n(_e,"LI",{});var Lze=s(HF);CMe=n(Lze,"STRONG",{});var Nzt=s(CMe);Rnr=r(Nzt,"mbart"),Nzt.forEach(t),Pnr=r(Lze," \u2014 "),IH=n(Lze,"A",{href:!0});var qzt=s(IH);Bnr=r(qzt,"MBartForConditionalGeneration"),qzt.forEach(t),Inr=r(Lze," (mBART model)"),Lze.forEach(t),Nnr=i(_e),JF=n(_e,"LI",{});var yze=s(JF);wMe=n(yze,"STRONG",{});var jzt=s(wMe);qnr=r(jzt,"mt5"),jzt.forEach(t),jnr=r(yze," \u2014 "),NH=n(yze,"A",{href:!0});var Dzt=s(NH);Dnr=r(Dzt,"MT5ForConditionalGeneration"),Dzt.forEach(t),Gnr=r(yze," (MT5 model)"),yze.forEach(t),Onr=i(_e),YF=n(_e,"LI",{});var xze=s(YF);AMe=n(xze,"STRONG",{});var Gzt=s(AMe);Vnr=r(Gzt,"mvp"),Gzt.forEach(t),Xnr=r(xze," \u2014 "),qH=n(xze,"A",{href:!0});var Ozt=s(qH);znr=r(Ozt,"MvpForConditionalGeneration"),Ozt.forEach(t),Qnr=r(xze," (MVP model)"),xze.forEach(t),Wnr=i(_e),ZF=n(_e,"LI",{});var $ze=s(ZF);LMe=n($ze,"STRONG",{});var Vzt=s(LMe);Unr=r(Vzt,"nllb"),Vzt.forEach(t),Hnr=r($ze," \u2014 "),jH=n($ze,"A",{href:!0});var Xzt=s(jH);Jnr=r(Xzt,"M2M100ForConditionalGeneration"),Xzt.forEach(t),Ynr=r($ze," (NLLB model)"),$ze.forEach(t),Znr=i(_e),KF=n(_e,"LI",{});var kze=s(KF);yMe=n(kze,"STRONG",{});var zzt=s(yMe);Knr=r(zzt,"pegasus"),zzt.forEach(t),esr=r(kze," \u2014 "),DH=n(kze,"A",{href:!0});var Qzt=s(DH);osr=r(Qzt,"PegasusForConditionalGeneration"),Qzt.forEach(t),rsr=r(kze," (Pegasus model)"),kze.forEach(t),tsr=i(_e),eT=n(_e,"LI",{});var Sze=s(eT);xMe=n(Sze,"STRONG",{});var Wzt=s(xMe);asr=r(Wzt,"pegasus_x"),Wzt.forEach(t),nsr=r(Sze," \u2014 "),GH=n(Sze,"A",{href:!0});var Uzt=s(GH);ssr=r(Uzt,"PegasusXForConditionalGeneration"),Uzt.forEach(t),lsr=r(Sze," (PEGASUS-X model)"),Sze.forEach(t),isr=i(_e),oT=n(_e,"LI",{});var Rze=s(oT);$Me=n(Rze,"STRONG",{});var Hzt=s($Me);dsr=r(Hzt,"plbart"),Hzt.forEach(t),msr=r(Rze," \u2014 "),OH=n(Rze,"A",{href:!0});var Jzt=s(OH);csr=r(Jzt,"PLBartForConditionalGeneration"),Jzt.forEach(t),fsr=r(Rze," (PLBart model)"),Rze.forEach(t),gsr=i(_e),rT=n(_e,"LI",{});var Pze=s(rT);kMe=n(Pze,"STRONG",{});var Yzt=s(kMe);hsr=r(Yzt,"prophetnet"),Yzt.forEach(t),usr=r(Pze," \u2014 "),VH=n(Pze,"A",{href:!0});var Zzt=s(VH);psr=r(Zzt,"ProphetNetForConditionalGeneration"),Zzt.forEach(t),_sr=r(Pze," (ProphetNet model)"),Pze.forEach(t),bsr=i(_e),tT=n(_e,"LI",{});var Bze=s(tT);SMe=n(Bze,"STRONG",{});var Kzt=s(SMe);vsr=r(Kzt,"t5"),Kzt.forEach(t),Fsr=r(Bze," \u2014 "),XH=n(Bze,"A",{href:!0});var eQt=s(XH);Tsr=r(eQt,"T5ForConditionalGeneration"),eQt.forEach(t),Msr=r(Bze," (T5 model)"),Bze.forEach(t),Esr=i(_e),aT=n(_e,"LI",{});var Ize=s(aT);RMe=n(Ize,"STRONG",{});var oQt=s(RMe);Csr=r(oQt,"xlm-prophetnet"),oQt.forEach(t),wsr=r(Ize," \u2014 "),zH=n(Ize,"A",{href:!0});var rQt=s(zH);Asr=r(rQt,"XLMProphetNetForConditionalGeneration"),rQt.forEach(t),Lsr=r(Ize," (XLM-ProphetNet model)"),Ize.forEach(t),_e.forEach(t),ysr=i(ka),nT=n(ka,"P",{});var Nze=s(nT);xsr=r(Nze,"The model is set in evaluation mode by default using "),PMe=n(Nze,"CODE",{});var tQt=s(PMe);$sr=r(tQt,"model.eval()"),tQt.forEach(t),ksr=r(Nze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),BMe=n(Nze,"CODE",{});var aQt=s(BMe);Ssr=r(aQt,"model.train()"),aQt.forEach(t),Nze.forEach(t),Rsr=i(ka),T(sT.$$.fragment,ka),ka.forEach(t),Ol.forEach(t),Rto=i(c),Ud=n(c,"H2",{class:!0});var Zno=s(Ud);lT=n(Zno,"A",{id:!0,class:!0,href:!0});var nQt=s(lT);IMe=n(nQt,"SPAN",{});var sQt=s(IMe);T(ik.$$.fragment,sQt),sQt.forEach(t),nQt.forEach(t),Psr=i(Zno),NMe=n(Zno,"SPAN",{});var lQt=s(NMe);Bsr=r(lQt,"AutoModelForSequenceClassification"),lQt.forEach(t),Zno.forEach(t),Pto=i(c),Oo=n(c,"DIV",{class:!0});var Vl=s(Oo);T(dk.$$.fragment,Vl),Isr=i(Vl),Hd=n(Vl,"P",{});var sme=s(Hd);Nsr=r(sme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),QH=n(sme,"A",{href:!0});var iQt=s(QH);qsr=r(iQt,"from_pretrained()"),iQt.forEach(t),jsr=r(sme," class method or the "),WH=n(sme,"A",{href:!0});var dQt=s(WH);Dsr=r(dQt,"from_config()"),dQt.forEach(t),Gsr=r(sme,` class
method.`),sme.forEach(t),Osr=i(Vl),mk=n(Vl,"P",{});var Kno=s(mk);Vsr=r(Kno,"This class cannot be instantiated directly using "),qMe=n(Kno,"CODE",{});var mQt=s(qMe);Xsr=r(mQt,"__init__()"),mQt.forEach(t),zsr=r(Kno," (throws an error)."),Kno.forEach(t),Qsr=i(Vl),Lt=n(Vl,"DIV",{class:!0});var l9=s(Lt);T(ck.$$.fragment,l9),Wsr=i(l9),jMe=n(l9,"P",{});var cQt=s(jMe);Usr=r(cQt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),cQt.forEach(t),Hsr=i(l9),Jd=n(l9,"P",{});var lme=s(Jd);Jsr=r(lme,`Note:
Loading a model from its configuration file does `),DMe=n(lme,"STRONG",{});var fQt=s(DMe);Ysr=r(fQt,"not"),fQt.forEach(t),Zsr=r(lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),UH=n(lme,"A",{href:!0});var gQt=s(UH);Ksr=r(gQt,"from_pretrained()"),gQt.forEach(t),elr=r(lme," to load the model weights."),lme.forEach(t),olr=i(l9),T(iT.$$.fragment,l9),l9.forEach(t),rlr=i(Vl),no=n(Vl,"DIV",{class:!0});var Sa=s(no);T(fk.$$.fragment,Sa),tlr=i(Sa),GMe=n(Sa,"P",{});var hQt=s(GMe);alr=r(hQt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hQt.forEach(t),nlr=i(Sa),cn=n(Sa,"P",{});var i9=s(cn);slr=r(i9,"The model class to instantiate is selected based on the "),OMe=n(i9,"CODE",{});var uQt=s(OMe);llr=r(uQt,"model_type"),uQt.forEach(t),ilr=r(i9,` property of the config object (either
passed as an argument or loaded from `),VMe=n(i9,"CODE",{});var pQt=s(VMe);dlr=r(pQt,"pretrained_model_name_or_path"),pQt.forEach(t),mlr=r(i9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XMe=n(i9,"CODE",{});var _Qt=s(XMe);clr=r(_Qt,"pretrained_model_name_or_path"),_Qt.forEach(t),flr=r(i9,":"),i9.forEach(t),glr=i(Sa),j=n(Sa,"UL",{});var D=s(j);dT=n(D,"LI",{});var qze=s(dT);zMe=n(qze,"STRONG",{});var bQt=s(zMe);hlr=r(bQt,"albert"),bQt.forEach(t),ulr=r(qze," \u2014 "),HH=n(qze,"A",{href:!0});var vQt=s(HH);plr=r(vQt,"AlbertForSequenceClassification"),vQt.forEach(t),_lr=r(qze," (ALBERT model)"),qze.forEach(t),blr=i(D),mT=n(D,"LI",{});var jze=s(mT);QMe=n(jze,"STRONG",{});var FQt=s(QMe);vlr=r(FQt,"bart"),FQt.forEach(t),Flr=r(jze," \u2014 "),JH=n(jze,"A",{href:!0});var TQt=s(JH);Tlr=r(TQt,"BartForSequenceClassification"),TQt.forEach(t),Mlr=r(jze," (BART model)"),jze.forEach(t),Elr=i(D),cT=n(D,"LI",{});var Dze=s(cT);WMe=n(Dze,"STRONG",{});var MQt=s(WMe);Clr=r(MQt,"bert"),MQt.forEach(t),wlr=r(Dze," \u2014 "),YH=n(Dze,"A",{href:!0});var EQt=s(YH);Alr=r(EQt,"BertForSequenceClassification"),EQt.forEach(t),Llr=r(Dze," (BERT model)"),Dze.forEach(t),ylr=i(D),fT=n(D,"LI",{});var Gze=s(fT);UMe=n(Gze,"STRONG",{});var CQt=s(UMe);xlr=r(CQt,"big_bird"),CQt.forEach(t),$lr=r(Gze," \u2014 "),ZH=n(Gze,"A",{href:!0});var wQt=s(ZH);klr=r(wQt,"BigBirdForSequenceClassification"),wQt.forEach(t),Slr=r(Gze," (BigBird model)"),Gze.forEach(t),Rlr=i(D),gT=n(D,"LI",{});var Oze=s(gT);HMe=n(Oze,"STRONG",{});var AQt=s(HMe);Plr=r(AQt,"bigbird_pegasus"),AQt.forEach(t),Blr=r(Oze," \u2014 "),KH=n(Oze,"A",{href:!0});var LQt=s(KH);Ilr=r(LQt,"BigBirdPegasusForSequenceClassification"),LQt.forEach(t),Nlr=r(Oze," (BigBird-Pegasus model)"),Oze.forEach(t),qlr=i(D),hT=n(D,"LI",{});var Vze=s(hT);JMe=n(Vze,"STRONG",{});var yQt=s(JMe);jlr=r(yQt,"bloom"),yQt.forEach(t),Dlr=r(Vze," \u2014 "),eJ=n(Vze,"A",{href:!0});var xQt=s(eJ);Glr=r(xQt,"BloomForSequenceClassification"),xQt.forEach(t),Olr=r(Vze," (BLOOM model)"),Vze.forEach(t),Vlr=i(D),uT=n(D,"LI",{});var Xze=s(uT);YMe=n(Xze,"STRONG",{});var $Qt=s(YMe);Xlr=r($Qt,"camembert"),$Qt.forEach(t),zlr=r(Xze," \u2014 "),oJ=n(Xze,"A",{href:!0});var kQt=s(oJ);Qlr=r(kQt,"CamembertForSequenceClassification"),kQt.forEach(t),Wlr=r(Xze," (CamemBERT model)"),Xze.forEach(t),Ulr=i(D),pT=n(D,"LI",{});var zze=s(pT);ZMe=n(zze,"STRONG",{});var SQt=s(ZMe);Hlr=r(SQt,"canine"),SQt.forEach(t),Jlr=r(zze," \u2014 "),rJ=n(zze,"A",{href:!0});var RQt=s(rJ);Ylr=r(RQt,"CanineForSequenceClassification"),RQt.forEach(t),Zlr=r(zze," (CANINE model)"),zze.forEach(t),Klr=i(D),_T=n(D,"LI",{});var Qze=s(_T);KMe=n(Qze,"STRONG",{});var PQt=s(KMe);eir=r(PQt,"convbert"),PQt.forEach(t),oir=r(Qze," \u2014 "),tJ=n(Qze,"A",{href:!0});var BQt=s(tJ);rir=r(BQt,"ConvBertForSequenceClassification"),BQt.forEach(t),tir=r(Qze," (ConvBERT model)"),Qze.forEach(t),air=i(D),bT=n(D,"LI",{});var Wze=s(bT);eEe=n(Wze,"STRONG",{});var IQt=s(eEe);nir=r(IQt,"ctrl"),IQt.forEach(t),sir=r(Wze," \u2014 "),aJ=n(Wze,"A",{href:!0});var NQt=s(aJ);lir=r(NQt,"CTRLForSequenceClassification"),NQt.forEach(t),iir=r(Wze," (CTRL model)"),Wze.forEach(t),dir=i(D),vT=n(D,"LI",{});var Uze=s(vT);oEe=n(Uze,"STRONG",{});var qQt=s(oEe);mir=r(qQt,"data2vec-text"),qQt.forEach(t),cir=r(Uze," \u2014 "),nJ=n(Uze,"A",{href:!0});var jQt=s(nJ);fir=r(jQt,"Data2VecTextForSequenceClassification"),jQt.forEach(t),gir=r(Uze," (Data2VecText model)"),Uze.forEach(t),hir=i(D),FT=n(D,"LI",{});var Hze=s(FT);rEe=n(Hze,"STRONG",{});var DQt=s(rEe);uir=r(DQt,"deberta"),DQt.forEach(t),pir=r(Hze," \u2014 "),sJ=n(Hze,"A",{href:!0});var GQt=s(sJ);_ir=r(GQt,"DebertaForSequenceClassification"),GQt.forEach(t),bir=r(Hze," (DeBERTa model)"),Hze.forEach(t),vir=i(D),TT=n(D,"LI",{});var Jze=s(TT);tEe=n(Jze,"STRONG",{});var OQt=s(tEe);Fir=r(OQt,"deberta-v2"),OQt.forEach(t),Tir=r(Jze," \u2014 "),lJ=n(Jze,"A",{href:!0});var VQt=s(lJ);Mir=r(VQt,"DebertaV2ForSequenceClassification"),VQt.forEach(t),Eir=r(Jze," (DeBERTa-v2 model)"),Jze.forEach(t),Cir=i(D),MT=n(D,"LI",{});var Yze=s(MT);aEe=n(Yze,"STRONG",{});var XQt=s(aEe);wir=r(XQt,"distilbert"),XQt.forEach(t),Air=r(Yze," \u2014 "),iJ=n(Yze,"A",{href:!0});var zQt=s(iJ);Lir=r(zQt,"DistilBertForSequenceClassification"),zQt.forEach(t),yir=r(Yze," (DistilBERT model)"),Yze.forEach(t),xir=i(D),ET=n(D,"LI",{});var Zze=s(ET);nEe=n(Zze,"STRONG",{});var QQt=s(nEe);$ir=r(QQt,"electra"),QQt.forEach(t),kir=r(Zze," \u2014 "),dJ=n(Zze,"A",{href:!0});var WQt=s(dJ);Sir=r(WQt,"ElectraForSequenceClassification"),WQt.forEach(t),Rir=r(Zze," (ELECTRA model)"),Zze.forEach(t),Pir=i(D),CT=n(D,"LI",{});var Kze=s(CT);sEe=n(Kze,"STRONG",{});var UQt=s(sEe);Bir=r(UQt,"ernie"),UQt.forEach(t),Iir=r(Kze," \u2014 "),mJ=n(Kze,"A",{href:!0});var HQt=s(mJ);Nir=r(HQt,"ErnieForSequenceClassification"),HQt.forEach(t),qir=r(Kze," (ERNIE model)"),Kze.forEach(t),jir=i(D),wT=n(D,"LI",{});var eQe=s(wT);lEe=n(eQe,"STRONG",{});var JQt=s(lEe);Dir=r(JQt,"esm"),JQt.forEach(t),Gir=r(eQe," \u2014 "),cJ=n(eQe,"A",{href:!0});var YQt=s(cJ);Oir=r(YQt,"EsmForSequenceClassification"),YQt.forEach(t),Vir=r(eQe," (ESM model)"),eQe.forEach(t),Xir=i(D),AT=n(D,"LI",{});var oQe=s(AT);iEe=n(oQe,"STRONG",{});var ZQt=s(iEe);zir=r(ZQt,"flaubert"),ZQt.forEach(t),Qir=r(oQe," \u2014 "),fJ=n(oQe,"A",{href:!0});var KQt=s(fJ);Wir=r(KQt,"FlaubertForSequenceClassification"),KQt.forEach(t),Uir=r(oQe," (FlauBERT model)"),oQe.forEach(t),Hir=i(D),LT=n(D,"LI",{});var rQe=s(LT);dEe=n(rQe,"STRONG",{});var eWt=s(dEe);Jir=r(eWt,"fnet"),eWt.forEach(t),Yir=r(rQe," \u2014 "),gJ=n(rQe,"A",{href:!0});var oWt=s(gJ);Zir=r(oWt,"FNetForSequenceClassification"),oWt.forEach(t),Kir=r(rQe," (FNet model)"),rQe.forEach(t),edr=i(D),yT=n(D,"LI",{});var tQe=s(yT);mEe=n(tQe,"STRONG",{});var rWt=s(mEe);odr=r(rWt,"funnel"),rWt.forEach(t),rdr=r(tQe," \u2014 "),hJ=n(tQe,"A",{href:!0});var tWt=s(hJ);tdr=r(tWt,"FunnelForSequenceClassification"),tWt.forEach(t),adr=r(tQe," (Funnel Transformer model)"),tQe.forEach(t),ndr=i(D),xT=n(D,"LI",{});var aQe=s(xT);cEe=n(aQe,"STRONG",{});var aWt=s(cEe);sdr=r(aWt,"gpt2"),aWt.forEach(t),ldr=r(aQe," \u2014 "),uJ=n(aQe,"A",{href:!0});var nWt=s(uJ);idr=r(nWt,"GPT2ForSequenceClassification"),nWt.forEach(t),ddr=r(aQe," (OpenAI GPT-2 model)"),aQe.forEach(t),mdr=i(D),$T=n(D,"LI",{});var nQe=s($T);fEe=n(nQe,"STRONG",{});var sWt=s(fEe);cdr=r(sWt,"gpt_neo"),sWt.forEach(t),fdr=r(nQe," \u2014 "),pJ=n(nQe,"A",{href:!0});var lWt=s(pJ);gdr=r(lWt,"GPTNeoForSequenceClassification"),lWt.forEach(t),hdr=r(nQe," (GPT Neo model)"),nQe.forEach(t),udr=i(D),kT=n(D,"LI",{});var sQe=s(kT);gEe=n(sQe,"STRONG",{});var iWt=s(gEe);pdr=r(iWt,"gptj"),iWt.forEach(t),_dr=r(sQe," \u2014 "),_J=n(sQe,"A",{href:!0});var dWt=s(_J);bdr=r(dWt,"GPTJForSequenceClassification"),dWt.forEach(t),vdr=r(sQe," (GPT-J model)"),sQe.forEach(t),Fdr=i(D),ST=n(D,"LI",{});var lQe=s(ST);hEe=n(lQe,"STRONG",{});var mWt=s(hEe);Tdr=r(mWt,"ibert"),mWt.forEach(t),Mdr=r(lQe," \u2014 "),bJ=n(lQe,"A",{href:!0});var cWt=s(bJ);Edr=r(cWt,"IBertForSequenceClassification"),cWt.forEach(t),Cdr=r(lQe," (I-BERT model)"),lQe.forEach(t),wdr=i(D),RT=n(D,"LI",{});var iQe=s(RT);uEe=n(iQe,"STRONG",{});var fWt=s(uEe);Adr=r(fWt,"layoutlm"),fWt.forEach(t),Ldr=r(iQe," \u2014 "),vJ=n(iQe,"A",{href:!0});var gWt=s(vJ);ydr=r(gWt,"LayoutLMForSequenceClassification"),gWt.forEach(t),xdr=r(iQe," (LayoutLM model)"),iQe.forEach(t),$dr=i(D),PT=n(D,"LI",{});var dQe=s(PT);pEe=n(dQe,"STRONG",{});var hWt=s(pEe);kdr=r(hWt,"layoutlmv2"),hWt.forEach(t),Sdr=r(dQe," \u2014 "),FJ=n(dQe,"A",{href:!0});var uWt=s(FJ);Rdr=r(uWt,"LayoutLMv2ForSequenceClassification"),uWt.forEach(t),Pdr=r(dQe," (LayoutLMv2 model)"),dQe.forEach(t),Bdr=i(D),BT=n(D,"LI",{});var mQe=s(BT);_Ee=n(mQe,"STRONG",{});var pWt=s(_Ee);Idr=r(pWt,"layoutlmv3"),pWt.forEach(t),Ndr=r(mQe," \u2014 "),TJ=n(mQe,"A",{href:!0});var _Wt=s(TJ);qdr=r(_Wt,"LayoutLMv3ForSequenceClassification"),_Wt.forEach(t),jdr=r(mQe," (LayoutLMv3 model)"),mQe.forEach(t),Ddr=i(D),IT=n(D,"LI",{});var cQe=s(IT);bEe=n(cQe,"STRONG",{});var bWt=s(bEe);Gdr=r(bWt,"led"),bWt.forEach(t),Odr=r(cQe," \u2014 "),MJ=n(cQe,"A",{href:!0});var vWt=s(MJ);Vdr=r(vWt,"LEDForSequenceClassification"),vWt.forEach(t),Xdr=r(cQe," (LED model)"),cQe.forEach(t),zdr=i(D),NT=n(D,"LI",{});var fQe=s(NT);vEe=n(fQe,"STRONG",{});var FWt=s(vEe);Qdr=r(FWt,"lilt"),FWt.forEach(t),Wdr=r(fQe," \u2014 "),EJ=n(fQe,"A",{href:!0});var TWt=s(EJ);Udr=r(TWt,"LiltForSequenceClassification"),TWt.forEach(t),Hdr=r(fQe," (LiLT model)"),fQe.forEach(t),Jdr=i(D),qT=n(D,"LI",{});var gQe=s(qT);FEe=n(gQe,"STRONG",{});var MWt=s(FEe);Ydr=r(MWt,"longformer"),MWt.forEach(t),Zdr=r(gQe," \u2014 "),CJ=n(gQe,"A",{href:!0});var EWt=s(CJ);Kdr=r(EWt,"LongformerForSequenceClassification"),EWt.forEach(t),emr=r(gQe," (Longformer model)"),gQe.forEach(t),omr=i(D),jT=n(D,"LI",{});var hQe=s(jT);TEe=n(hQe,"STRONG",{});var CWt=s(TEe);rmr=r(CWt,"luke"),CWt.forEach(t),tmr=r(hQe," \u2014 "),wJ=n(hQe,"A",{href:!0});var wWt=s(wJ);amr=r(wWt,"LukeForSequenceClassification"),wWt.forEach(t),nmr=r(hQe," (LUKE model)"),hQe.forEach(t),smr=i(D),DT=n(D,"LI",{});var uQe=s(DT);MEe=n(uQe,"STRONG",{});var AWt=s(MEe);lmr=r(AWt,"markuplm"),AWt.forEach(t),imr=r(uQe," \u2014 "),AJ=n(uQe,"A",{href:!0});var LWt=s(AJ);dmr=r(LWt,"MarkupLMForSequenceClassification"),LWt.forEach(t),mmr=r(uQe," (MarkupLM model)"),uQe.forEach(t),cmr=i(D),GT=n(D,"LI",{});var pQe=s(GT);EEe=n(pQe,"STRONG",{});var yWt=s(EEe);fmr=r(yWt,"mbart"),yWt.forEach(t),gmr=r(pQe," \u2014 "),LJ=n(pQe,"A",{href:!0});var xWt=s(LJ);hmr=r(xWt,"MBartForSequenceClassification"),xWt.forEach(t),umr=r(pQe," (mBART model)"),pQe.forEach(t),pmr=i(D),OT=n(D,"LI",{});var _Qe=s(OT);CEe=n(_Qe,"STRONG",{});var $Wt=s(CEe);_mr=r($Wt,"megatron-bert"),$Wt.forEach(t),bmr=r(_Qe," \u2014 "),yJ=n(_Qe,"A",{href:!0});var kWt=s(yJ);vmr=r(kWt,"MegatronBertForSequenceClassification"),kWt.forEach(t),Fmr=r(_Qe," (Megatron-BERT model)"),_Qe.forEach(t),Tmr=i(D),VT=n(D,"LI",{});var bQe=s(VT);wEe=n(bQe,"STRONG",{});var SWt=s(wEe);Mmr=r(SWt,"mobilebert"),SWt.forEach(t),Emr=r(bQe," \u2014 "),xJ=n(bQe,"A",{href:!0});var RWt=s(xJ);Cmr=r(RWt,"MobileBertForSequenceClassification"),RWt.forEach(t),wmr=r(bQe," (MobileBERT model)"),bQe.forEach(t),Amr=i(D),XT=n(D,"LI",{});var vQe=s(XT);AEe=n(vQe,"STRONG",{});var PWt=s(AEe);Lmr=r(PWt,"mpnet"),PWt.forEach(t),ymr=r(vQe," \u2014 "),$J=n(vQe,"A",{href:!0});var BWt=s($J);xmr=r(BWt,"MPNetForSequenceClassification"),BWt.forEach(t),$mr=r(vQe," (MPNet model)"),vQe.forEach(t),kmr=i(D),zT=n(D,"LI",{});var FQe=s(zT);LEe=n(FQe,"STRONG",{});var IWt=s(LEe);Smr=r(IWt,"mvp"),IWt.forEach(t),Rmr=r(FQe," \u2014 "),kJ=n(FQe,"A",{href:!0});var NWt=s(kJ);Pmr=r(NWt,"MvpForSequenceClassification"),NWt.forEach(t),Bmr=r(FQe," (MVP model)"),FQe.forEach(t),Imr=i(D),QT=n(D,"LI",{});var TQe=s(QT);yEe=n(TQe,"STRONG",{});var qWt=s(yEe);Nmr=r(qWt,"nezha"),qWt.forEach(t),qmr=r(TQe," \u2014 "),SJ=n(TQe,"A",{href:!0});var jWt=s(SJ);jmr=r(jWt,"NezhaForSequenceClassification"),jWt.forEach(t),Dmr=r(TQe," (Nezha model)"),TQe.forEach(t),Gmr=i(D),WT=n(D,"LI",{});var MQe=s(WT);xEe=n(MQe,"STRONG",{});var DWt=s(xEe);Omr=r(DWt,"nystromformer"),DWt.forEach(t),Vmr=r(MQe," \u2014 "),RJ=n(MQe,"A",{href:!0});var GWt=s(RJ);Xmr=r(GWt,"NystromformerForSequenceClassification"),GWt.forEach(t),zmr=r(MQe," (Nystr\xF6mformer model)"),MQe.forEach(t),Qmr=i(D),UT=n(D,"LI",{});var EQe=s(UT);$Ee=n(EQe,"STRONG",{});var OWt=s($Ee);Wmr=r(OWt,"openai-gpt"),OWt.forEach(t),Umr=r(EQe," \u2014 "),PJ=n(EQe,"A",{href:!0});var VWt=s(PJ);Hmr=r(VWt,"OpenAIGPTForSequenceClassification"),VWt.forEach(t),Jmr=r(EQe," (OpenAI GPT model)"),EQe.forEach(t),Ymr=i(D),HT=n(D,"LI",{});var CQe=s(HT);kEe=n(CQe,"STRONG",{});var XWt=s(kEe);Zmr=r(XWt,"opt"),XWt.forEach(t),Kmr=r(CQe," \u2014 "),BJ=n(CQe,"A",{href:!0});var zWt=s(BJ);ecr=r(zWt,"OPTForSequenceClassification"),zWt.forEach(t),ocr=r(CQe," (OPT model)"),CQe.forEach(t),rcr=i(D),JT=n(D,"LI",{});var wQe=s(JT);SEe=n(wQe,"STRONG",{});var QWt=s(SEe);tcr=r(QWt,"perceiver"),QWt.forEach(t),acr=r(wQe," \u2014 "),IJ=n(wQe,"A",{href:!0});var WWt=s(IJ);ncr=r(WWt,"PerceiverForSequenceClassification"),WWt.forEach(t),scr=r(wQe," (Perceiver model)"),wQe.forEach(t),lcr=i(D),YT=n(D,"LI",{});var AQe=s(YT);REe=n(AQe,"STRONG",{});var UWt=s(REe);icr=r(UWt,"plbart"),UWt.forEach(t),dcr=r(AQe," \u2014 "),NJ=n(AQe,"A",{href:!0});var HWt=s(NJ);mcr=r(HWt,"PLBartForSequenceClassification"),HWt.forEach(t),ccr=r(AQe," (PLBart model)"),AQe.forEach(t),fcr=i(D),ZT=n(D,"LI",{});var LQe=s(ZT);PEe=n(LQe,"STRONG",{});var JWt=s(PEe);gcr=r(JWt,"qdqbert"),JWt.forEach(t),hcr=r(LQe," \u2014 "),qJ=n(LQe,"A",{href:!0});var YWt=s(qJ);ucr=r(YWt,"QDQBertForSequenceClassification"),YWt.forEach(t),pcr=r(LQe," (QDQBert model)"),LQe.forEach(t),_cr=i(D),KT=n(D,"LI",{});var yQe=s(KT);BEe=n(yQe,"STRONG",{});var ZWt=s(BEe);bcr=r(ZWt,"reformer"),ZWt.forEach(t),vcr=r(yQe," \u2014 "),jJ=n(yQe,"A",{href:!0});var KWt=s(jJ);Fcr=r(KWt,"ReformerForSequenceClassification"),KWt.forEach(t),Tcr=r(yQe," (Reformer model)"),yQe.forEach(t),Mcr=i(D),eM=n(D,"LI",{});var xQe=s(eM);IEe=n(xQe,"STRONG",{});var eUt=s(IEe);Ecr=r(eUt,"rembert"),eUt.forEach(t),Ccr=r(xQe," \u2014 "),DJ=n(xQe,"A",{href:!0});var oUt=s(DJ);wcr=r(oUt,"RemBertForSequenceClassification"),oUt.forEach(t),Acr=r(xQe," (RemBERT model)"),xQe.forEach(t),Lcr=i(D),oM=n(D,"LI",{});var $Qe=s(oM);NEe=n($Qe,"STRONG",{});var rUt=s(NEe);ycr=r(rUt,"roberta"),rUt.forEach(t),xcr=r($Qe," \u2014 "),GJ=n($Qe,"A",{href:!0});var tUt=s(GJ);$cr=r(tUt,"RobertaForSequenceClassification"),tUt.forEach(t),kcr=r($Qe," (RoBERTa model)"),$Qe.forEach(t),Scr=i(D),rM=n(D,"LI",{});var kQe=s(rM);qEe=n(kQe,"STRONG",{});var aUt=s(qEe);Rcr=r(aUt,"roformer"),aUt.forEach(t),Pcr=r(kQe," \u2014 "),OJ=n(kQe,"A",{href:!0});var nUt=s(OJ);Bcr=r(nUt,"RoFormerForSequenceClassification"),nUt.forEach(t),Icr=r(kQe," (RoFormer model)"),kQe.forEach(t),Ncr=i(D),tM=n(D,"LI",{});var SQe=s(tM);jEe=n(SQe,"STRONG",{});var sUt=s(jEe);qcr=r(sUt,"squeezebert"),sUt.forEach(t),jcr=r(SQe," \u2014 "),VJ=n(SQe,"A",{href:!0});var lUt=s(VJ);Dcr=r(lUt,"SqueezeBertForSequenceClassification"),lUt.forEach(t),Gcr=r(SQe," (SqueezeBERT model)"),SQe.forEach(t),Ocr=i(D),aM=n(D,"LI",{});var RQe=s(aM);DEe=n(RQe,"STRONG",{});var iUt=s(DEe);Vcr=r(iUt,"tapas"),iUt.forEach(t),Xcr=r(RQe," \u2014 "),XJ=n(RQe,"A",{href:!0});var dUt=s(XJ);zcr=r(dUt,"TapasForSequenceClassification"),dUt.forEach(t),Qcr=r(RQe," (TAPAS model)"),RQe.forEach(t),Wcr=i(D),nM=n(D,"LI",{});var PQe=s(nM);GEe=n(PQe,"STRONG",{});var mUt=s(GEe);Ucr=r(mUt,"transfo-xl"),mUt.forEach(t),Hcr=r(PQe," \u2014 "),zJ=n(PQe,"A",{href:!0});var cUt=s(zJ);Jcr=r(cUt,"TransfoXLForSequenceClassification"),cUt.forEach(t),Ycr=r(PQe," (Transformer-XL model)"),PQe.forEach(t),Zcr=i(D),sM=n(D,"LI",{});var BQe=s(sM);OEe=n(BQe,"STRONG",{});var fUt=s(OEe);Kcr=r(fUt,"xlm"),fUt.forEach(t),efr=r(BQe," \u2014 "),QJ=n(BQe,"A",{href:!0});var gUt=s(QJ);ofr=r(gUt,"XLMForSequenceClassification"),gUt.forEach(t),rfr=r(BQe," (XLM model)"),BQe.forEach(t),tfr=i(D),lM=n(D,"LI",{});var IQe=s(lM);VEe=n(IQe,"STRONG",{});var hUt=s(VEe);afr=r(hUt,"xlm-roberta"),hUt.forEach(t),nfr=r(IQe," \u2014 "),WJ=n(IQe,"A",{href:!0});var uUt=s(WJ);sfr=r(uUt,"XLMRobertaForSequenceClassification"),uUt.forEach(t),lfr=r(IQe," (XLM-RoBERTa model)"),IQe.forEach(t),ifr=i(D),iM=n(D,"LI",{});var NQe=s(iM);XEe=n(NQe,"STRONG",{});var pUt=s(XEe);dfr=r(pUt,"xlm-roberta-xl"),pUt.forEach(t),mfr=r(NQe," \u2014 "),UJ=n(NQe,"A",{href:!0});var _Ut=s(UJ);cfr=r(_Ut,"XLMRobertaXLForSequenceClassification"),_Ut.forEach(t),ffr=r(NQe," (XLM-RoBERTa-XL model)"),NQe.forEach(t),gfr=i(D),dM=n(D,"LI",{});var qQe=s(dM);zEe=n(qQe,"STRONG",{});var bUt=s(zEe);hfr=r(bUt,"xlnet"),bUt.forEach(t),ufr=r(qQe," \u2014 "),HJ=n(qQe,"A",{href:!0});var vUt=s(HJ);pfr=r(vUt,"XLNetForSequenceClassification"),vUt.forEach(t),_fr=r(qQe," (XLNet model)"),qQe.forEach(t),bfr=i(D),mM=n(D,"LI",{});var jQe=s(mM);QEe=n(jQe,"STRONG",{});var FUt=s(QEe);vfr=r(FUt,"yoso"),FUt.forEach(t),Ffr=r(jQe," \u2014 "),JJ=n(jQe,"A",{href:!0});var TUt=s(JJ);Tfr=r(TUt,"YosoForSequenceClassification"),TUt.forEach(t),Mfr=r(jQe," (YOSO model)"),jQe.forEach(t),D.forEach(t),Efr=i(Sa),cM=n(Sa,"P",{});var DQe=s(cM);Cfr=r(DQe,"The model is set in evaluation mode by default using "),WEe=n(DQe,"CODE",{});var MUt=s(WEe);wfr=r(MUt,"model.eval()"),MUt.forEach(t),Afr=r(DQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UEe=n(DQe,"CODE",{});var EUt=s(UEe);Lfr=r(EUt,"model.train()"),EUt.forEach(t),DQe.forEach(t),yfr=i(Sa),T(fM.$$.fragment,Sa),Sa.forEach(t),Vl.forEach(t),Bto=i(c),Yd=n(c,"H2",{class:!0});var eso=s(Yd);gM=n(eso,"A",{id:!0,class:!0,href:!0});var CUt=s(gM);HEe=n(CUt,"SPAN",{});var wUt=s(HEe);T(gk.$$.fragment,wUt),wUt.forEach(t),CUt.forEach(t),xfr=i(eso),JEe=n(eso,"SPAN",{});var AUt=s(JEe);$fr=r(AUt,"AutoModelForMultipleChoice"),AUt.forEach(t),eso.forEach(t),Ito=i(c),Vo=n(c,"DIV",{class:!0});var Xl=s(Vo);T(hk.$$.fragment,Xl),kfr=i(Xl),Zd=n(Xl,"P",{});var ime=s(Zd);Sfr=r(ime,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),YJ=n(ime,"A",{href:!0});var LUt=s(YJ);Rfr=r(LUt,"from_pretrained()"),LUt.forEach(t),Pfr=r(ime," class method or the "),ZJ=n(ime,"A",{href:!0});var yUt=s(ZJ);Bfr=r(yUt,"from_config()"),yUt.forEach(t),Ifr=r(ime,` class
method.`),ime.forEach(t),Nfr=i(Xl),uk=n(Xl,"P",{});var oso=s(uk);qfr=r(oso,"This class cannot be instantiated directly using "),YEe=n(oso,"CODE",{});var xUt=s(YEe);jfr=r(xUt,"__init__()"),xUt.forEach(t),Dfr=r(oso," (throws an error)."),oso.forEach(t),Gfr=i(Xl),yt=n(Xl,"DIV",{class:!0});var d9=s(yt);T(pk.$$.fragment,d9),Ofr=i(d9),ZEe=n(d9,"P",{});var $Ut=s(ZEe);Vfr=r($Ut,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$Ut.forEach(t),Xfr=i(d9),Kd=n(d9,"P",{});var dme=s(Kd);zfr=r(dme,`Note:
Loading a model from its configuration file does `),KEe=n(dme,"STRONG",{});var kUt=s(KEe);Qfr=r(kUt,"not"),kUt.forEach(t),Wfr=r(dme,` load the model weights. It only affects the
model\u2019s configuration. Use `),KJ=n(dme,"A",{href:!0});var SUt=s(KJ);Ufr=r(SUt,"from_pretrained()"),SUt.forEach(t),Hfr=r(dme," to load the model weights."),dme.forEach(t),Jfr=i(d9),T(hM.$$.fragment,d9),d9.forEach(t),Yfr=i(Xl),so=n(Xl,"DIV",{class:!0});var Ra=s(so);T(_k.$$.fragment,Ra),Zfr=i(Ra),e4e=n(Ra,"P",{});var RUt=s(e4e);Kfr=r(RUt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),RUt.forEach(t),egr=i(Ra),fn=n(Ra,"P",{});var m9=s(fn);ogr=r(m9,"The model class to instantiate is selected based on the "),o4e=n(m9,"CODE",{});var PUt=s(o4e);rgr=r(PUt,"model_type"),PUt.forEach(t),tgr=r(m9,` property of the config object (either
passed as an argument or loaded from `),r4e=n(m9,"CODE",{});var BUt=s(r4e);agr=r(BUt,"pretrained_model_name_or_path"),BUt.forEach(t),ngr=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t4e=n(m9,"CODE",{});var IUt=s(t4e);sgr=r(IUt,"pretrained_model_name_or_path"),IUt.forEach(t),lgr=r(m9,":"),m9.forEach(t),igr=i(Ra),K=n(Ra,"UL",{});var ee=s(K);uM=n(ee,"LI",{});var GQe=s(uM);a4e=n(GQe,"STRONG",{});var NUt=s(a4e);dgr=r(NUt,"albert"),NUt.forEach(t),mgr=r(GQe," \u2014 "),eY=n(GQe,"A",{href:!0});var qUt=s(eY);cgr=r(qUt,"AlbertForMultipleChoice"),qUt.forEach(t),fgr=r(GQe," (ALBERT model)"),GQe.forEach(t),ggr=i(ee),pM=n(ee,"LI",{});var OQe=s(pM);n4e=n(OQe,"STRONG",{});var jUt=s(n4e);hgr=r(jUt,"bert"),jUt.forEach(t),ugr=r(OQe," \u2014 "),oY=n(OQe,"A",{href:!0});var DUt=s(oY);pgr=r(DUt,"BertForMultipleChoice"),DUt.forEach(t),_gr=r(OQe," (BERT model)"),OQe.forEach(t),bgr=i(ee),_M=n(ee,"LI",{});var VQe=s(_M);s4e=n(VQe,"STRONG",{});var GUt=s(s4e);vgr=r(GUt,"big_bird"),GUt.forEach(t),Fgr=r(VQe," \u2014 "),rY=n(VQe,"A",{href:!0});var OUt=s(rY);Tgr=r(OUt,"BigBirdForMultipleChoice"),OUt.forEach(t),Mgr=r(VQe," (BigBird model)"),VQe.forEach(t),Egr=i(ee),bM=n(ee,"LI",{});var XQe=s(bM);l4e=n(XQe,"STRONG",{});var VUt=s(l4e);Cgr=r(VUt,"camembert"),VUt.forEach(t),wgr=r(XQe," \u2014 "),tY=n(XQe,"A",{href:!0});var XUt=s(tY);Agr=r(XUt,"CamembertForMultipleChoice"),XUt.forEach(t),Lgr=r(XQe," (CamemBERT model)"),XQe.forEach(t),ygr=i(ee),vM=n(ee,"LI",{});var zQe=s(vM);i4e=n(zQe,"STRONG",{});var zUt=s(i4e);xgr=r(zUt,"canine"),zUt.forEach(t),$gr=r(zQe," \u2014 "),aY=n(zQe,"A",{href:!0});var QUt=s(aY);kgr=r(QUt,"CanineForMultipleChoice"),QUt.forEach(t),Sgr=r(zQe," (CANINE model)"),zQe.forEach(t),Rgr=i(ee),FM=n(ee,"LI",{});var QQe=s(FM);d4e=n(QQe,"STRONG",{});var WUt=s(d4e);Pgr=r(WUt,"convbert"),WUt.forEach(t),Bgr=r(QQe," \u2014 "),nY=n(QQe,"A",{href:!0});var UUt=s(nY);Igr=r(UUt,"ConvBertForMultipleChoice"),UUt.forEach(t),Ngr=r(QQe," (ConvBERT model)"),QQe.forEach(t),qgr=i(ee),TM=n(ee,"LI",{});var WQe=s(TM);m4e=n(WQe,"STRONG",{});var HUt=s(m4e);jgr=r(HUt,"data2vec-text"),HUt.forEach(t),Dgr=r(WQe," \u2014 "),sY=n(WQe,"A",{href:!0});var JUt=s(sY);Ggr=r(JUt,"Data2VecTextForMultipleChoice"),JUt.forEach(t),Ogr=r(WQe," (Data2VecText model)"),WQe.forEach(t),Vgr=i(ee),MM=n(ee,"LI",{});var UQe=s(MM);c4e=n(UQe,"STRONG",{});var YUt=s(c4e);Xgr=r(YUt,"deberta-v2"),YUt.forEach(t),zgr=r(UQe," \u2014 "),lY=n(UQe,"A",{href:!0});var ZUt=s(lY);Qgr=r(ZUt,"DebertaV2ForMultipleChoice"),ZUt.forEach(t),Wgr=r(UQe," (DeBERTa-v2 model)"),UQe.forEach(t),Ugr=i(ee),EM=n(ee,"LI",{});var HQe=s(EM);f4e=n(HQe,"STRONG",{});var KUt=s(f4e);Hgr=r(KUt,"distilbert"),KUt.forEach(t),Jgr=r(HQe," \u2014 "),iY=n(HQe,"A",{href:!0});var eHt=s(iY);Ygr=r(eHt,"DistilBertForMultipleChoice"),eHt.forEach(t),Zgr=r(HQe," (DistilBERT model)"),HQe.forEach(t),Kgr=i(ee),CM=n(ee,"LI",{});var JQe=s(CM);g4e=n(JQe,"STRONG",{});var oHt=s(g4e);ehr=r(oHt,"electra"),oHt.forEach(t),ohr=r(JQe," \u2014 "),dY=n(JQe,"A",{href:!0});var rHt=s(dY);rhr=r(rHt,"ElectraForMultipleChoice"),rHt.forEach(t),thr=r(JQe," (ELECTRA model)"),JQe.forEach(t),ahr=i(ee),wM=n(ee,"LI",{});var YQe=s(wM);h4e=n(YQe,"STRONG",{});var tHt=s(h4e);nhr=r(tHt,"ernie"),tHt.forEach(t),shr=r(YQe," \u2014 "),mY=n(YQe,"A",{href:!0});var aHt=s(mY);lhr=r(aHt,"ErnieForMultipleChoice"),aHt.forEach(t),ihr=r(YQe," (ERNIE model)"),YQe.forEach(t),dhr=i(ee),AM=n(ee,"LI",{});var ZQe=s(AM);u4e=n(ZQe,"STRONG",{});var nHt=s(u4e);mhr=r(nHt,"flaubert"),nHt.forEach(t),chr=r(ZQe," \u2014 "),cY=n(ZQe,"A",{href:!0});var sHt=s(cY);fhr=r(sHt,"FlaubertForMultipleChoice"),sHt.forEach(t),ghr=r(ZQe," (FlauBERT model)"),ZQe.forEach(t),hhr=i(ee),LM=n(ee,"LI",{});var KQe=s(LM);p4e=n(KQe,"STRONG",{});var lHt=s(p4e);uhr=r(lHt,"fnet"),lHt.forEach(t),phr=r(KQe," \u2014 "),fY=n(KQe,"A",{href:!0});var iHt=s(fY);_hr=r(iHt,"FNetForMultipleChoice"),iHt.forEach(t),bhr=r(KQe," (FNet model)"),KQe.forEach(t),vhr=i(ee),yM=n(ee,"LI",{});var eWe=s(yM);_4e=n(eWe,"STRONG",{});var dHt=s(_4e);Fhr=r(dHt,"funnel"),dHt.forEach(t),Thr=r(eWe," \u2014 "),gY=n(eWe,"A",{href:!0});var mHt=s(gY);Mhr=r(mHt,"FunnelForMultipleChoice"),mHt.forEach(t),Ehr=r(eWe," (Funnel Transformer model)"),eWe.forEach(t),Chr=i(ee),xM=n(ee,"LI",{});var oWe=s(xM);b4e=n(oWe,"STRONG",{});var cHt=s(b4e);whr=r(cHt,"ibert"),cHt.forEach(t),Ahr=r(oWe," \u2014 "),hY=n(oWe,"A",{href:!0});var fHt=s(hY);Lhr=r(fHt,"IBertForMultipleChoice"),fHt.forEach(t),yhr=r(oWe," (I-BERT model)"),oWe.forEach(t),xhr=i(ee),$M=n(ee,"LI",{});var rWe=s($M);v4e=n(rWe,"STRONG",{});var gHt=s(v4e);$hr=r(gHt,"longformer"),gHt.forEach(t),khr=r(rWe," \u2014 "),uY=n(rWe,"A",{href:!0});var hHt=s(uY);Shr=r(hHt,"LongformerForMultipleChoice"),hHt.forEach(t),Rhr=r(rWe," (Longformer model)"),rWe.forEach(t),Phr=i(ee),kM=n(ee,"LI",{});var tWe=s(kM);F4e=n(tWe,"STRONG",{});var uHt=s(F4e);Bhr=r(uHt,"luke"),uHt.forEach(t),Ihr=r(tWe," \u2014 "),pY=n(tWe,"A",{href:!0});var pHt=s(pY);Nhr=r(pHt,"LukeForMultipleChoice"),pHt.forEach(t),qhr=r(tWe," (LUKE model)"),tWe.forEach(t),jhr=i(ee),SM=n(ee,"LI",{});var aWe=s(SM);T4e=n(aWe,"STRONG",{});var _Ht=s(T4e);Dhr=r(_Ht,"megatron-bert"),_Ht.forEach(t),Ghr=r(aWe," \u2014 "),_Y=n(aWe,"A",{href:!0});var bHt=s(_Y);Ohr=r(bHt,"MegatronBertForMultipleChoice"),bHt.forEach(t),Vhr=r(aWe," (Megatron-BERT model)"),aWe.forEach(t),Xhr=i(ee),RM=n(ee,"LI",{});var nWe=s(RM);M4e=n(nWe,"STRONG",{});var vHt=s(M4e);zhr=r(vHt,"mobilebert"),vHt.forEach(t),Qhr=r(nWe," \u2014 "),bY=n(nWe,"A",{href:!0});var FHt=s(bY);Whr=r(FHt,"MobileBertForMultipleChoice"),FHt.forEach(t),Uhr=r(nWe," (MobileBERT model)"),nWe.forEach(t),Hhr=i(ee),PM=n(ee,"LI",{});var sWe=s(PM);E4e=n(sWe,"STRONG",{});var THt=s(E4e);Jhr=r(THt,"mpnet"),THt.forEach(t),Yhr=r(sWe," \u2014 "),vY=n(sWe,"A",{href:!0});var MHt=s(vY);Zhr=r(MHt,"MPNetForMultipleChoice"),MHt.forEach(t),Khr=r(sWe," (MPNet model)"),sWe.forEach(t),eur=i(ee),BM=n(ee,"LI",{});var lWe=s(BM);C4e=n(lWe,"STRONG",{});var EHt=s(C4e);our=r(EHt,"nezha"),EHt.forEach(t),rur=r(lWe," \u2014 "),FY=n(lWe,"A",{href:!0});var CHt=s(FY);tur=r(CHt,"NezhaForMultipleChoice"),CHt.forEach(t),aur=r(lWe," (Nezha model)"),lWe.forEach(t),nur=i(ee),IM=n(ee,"LI",{});var iWe=s(IM);w4e=n(iWe,"STRONG",{});var wHt=s(w4e);sur=r(wHt,"nystromformer"),wHt.forEach(t),lur=r(iWe," \u2014 "),TY=n(iWe,"A",{href:!0});var AHt=s(TY);iur=r(AHt,"NystromformerForMultipleChoice"),AHt.forEach(t),dur=r(iWe," (Nystr\xF6mformer model)"),iWe.forEach(t),mur=i(ee),NM=n(ee,"LI",{});var dWe=s(NM);A4e=n(dWe,"STRONG",{});var LHt=s(A4e);cur=r(LHt,"qdqbert"),LHt.forEach(t),fur=r(dWe," \u2014 "),MY=n(dWe,"A",{href:!0});var yHt=s(MY);gur=r(yHt,"QDQBertForMultipleChoice"),yHt.forEach(t),hur=r(dWe," (QDQBert model)"),dWe.forEach(t),uur=i(ee),qM=n(ee,"LI",{});var mWe=s(qM);L4e=n(mWe,"STRONG",{});var xHt=s(L4e);pur=r(xHt,"rembert"),xHt.forEach(t),_ur=r(mWe," \u2014 "),EY=n(mWe,"A",{href:!0});var $Ht=s(EY);bur=r($Ht,"RemBertForMultipleChoice"),$Ht.forEach(t),vur=r(mWe," (RemBERT model)"),mWe.forEach(t),Fur=i(ee),jM=n(ee,"LI",{});var cWe=s(jM);y4e=n(cWe,"STRONG",{});var kHt=s(y4e);Tur=r(kHt,"roberta"),kHt.forEach(t),Mur=r(cWe," \u2014 "),CY=n(cWe,"A",{href:!0});var SHt=s(CY);Eur=r(SHt,"RobertaForMultipleChoice"),SHt.forEach(t),Cur=r(cWe," (RoBERTa model)"),cWe.forEach(t),wur=i(ee),DM=n(ee,"LI",{});var fWe=s(DM);x4e=n(fWe,"STRONG",{});var RHt=s(x4e);Aur=r(RHt,"roformer"),RHt.forEach(t),Lur=r(fWe," \u2014 "),wY=n(fWe,"A",{href:!0});var PHt=s(wY);yur=r(PHt,"RoFormerForMultipleChoice"),PHt.forEach(t),xur=r(fWe," (RoFormer model)"),fWe.forEach(t),$ur=i(ee),GM=n(ee,"LI",{});var gWe=s(GM);$4e=n(gWe,"STRONG",{});var BHt=s($4e);kur=r(BHt,"squeezebert"),BHt.forEach(t),Sur=r(gWe," \u2014 "),AY=n(gWe,"A",{href:!0});var IHt=s(AY);Rur=r(IHt,"SqueezeBertForMultipleChoice"),IHt.forEach(t),Pur=r(gWe," (SqueezeBERT model)"),gWe.forEach(t),Bur=i(ee),OM=n(ee,"LI",{});var hWe=s(OM);k4e=n(hWe,"STRONG",{});var NHt=s(k4e);Iur=r(NHt,"xlm"),NHt.forEach(t),Nur=r(hWe," \u2014 "),LY=n(hWe,"A",{href:!0});var qHt=s(LY);qur=r(qHt,"XLMForMultipleChoice"),qHt.forEach(t),jur=r(hWe," (XLM model)"),hWe.forEach(t),Dur=i(ee),VM=n(ee,"LI",{});var uWe=s(VM);S4e=n(uWe,"STRONG",{});var jHt=s(S4e);Gur=r(jHt,"xlm-roberta"),jHt.forEach(t),Our=r(uWe," \u2014 "),yY=n(uWe,"A",{href:!0});var DHt=s(yY);Vur=r(DHt,"XLMRobertaForMultipleChoice"),DHt.forEach(t),Xur=r(uWe," (XLM-RoBERTa model)"),uWe.forEach(t),zur=i(ee),XM=n(ee,"LI",{});var pWe=s(XM);R4e=n(pWe,"STRONG",{});var GHt=s(R4e);Qur=r(GHt,"xlm-roberta-xl"),GHt.forEach(t),Wur=r(pWe," \u2014 "),xY=n(pWe,"A",{href:!0});var OHt=s(xY);Uur=r(OHt,"XLMRobertaXLForMultipleChoice"),OHt.forEach(t),Hur=r(pWe," (XLM-RoBERTa-XL model)"),pWe.forEach(t),Jur=i(ee),zM=n(ee,"LI",{});var _We=s(zM);P4e=n(_We,"STRONG",{});var VHt=s(P4e);Yur=r(VHt,"xlnet"),VHt.forEach(t),Zur=r(_We," \u2014 "),$Y=n(_We,"A",{href:!0});var XHt=s($Y);Kur=r(XHt,"XLNetForMultipleChoice"),XHt.forEach(t),epr=r(_We," (XLNet model)"),_We.forEach(t),opr=i(ee),QM=n(ee,"LI",{});var bWe=s(QM);B4e=n(bWe,"STRONG",{});var zHt=s(B4e);rpr=r(zHt,"yoso"),zHt.forEach(t),tpr=r(bWe," \u2014 "),kY=n(bWe,"A",{href:!0});var QHt=s(kY);apr=r(QHt,"YosoForMultipleChoice"),QHt.forEach(t),npr=r(bWe," (YOSO model)"),bWe.forEach(t),ee.forEach(t),spr=i(Ra),WM=n(Ra,"P",{});var vWe=s(WM);lpr=r(vWe,"The model is set in evaluation mode by default using "),I4e=n(vWe,"CODE",{});var WHt=s(I4e);ipr=r(WHt,"model.eval()"),WHt.forEach(t),dpr=r(vWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N4e=n(vWe,"CODE",{});var UHt=s(N4e);mpr=r(UHt,"model.train()"),UHt.forEach(t),vWe.forEach(t),cpr=i(Ra),T(UM.$$.fragment,Ra),Ra.forEach(t),Xl.forEach(t),Nto=i(c),em=n(c,"H2",{class:!0});var rso=s(em);HM=n(rso,"A",{id:!0,class:!0,href:!0});var HHt=s(HM);q4e=n(HHt,"SPAN",{});var JHt=s(q4e);T(bk.$$.fragment,JHt),JHt.forEach(t),HHt.forEach(t),fpr=i(rso),j4e=n(rso,"SPAN",{});var YHt=s(j4e);gpr=r(YHt,"AutoModelForNextSentencePrediction"),YHt.forEach(t),rso.forEach(t),qto=i(c),Xo=n(c,"DIV",{class:!0});var zl=s(Xo);T(vk.$$.fragment,zl),hpr=i(zl),om=n(zl,"P",{});var mme=s(om);upr=r(mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),SY=n(mme,"A",{href:!0});var ZHt=s(SY);ppr=r(ZHt,"from_pretrained()"),ZHt.forEach(t),_pr=r(mme," class method or the "),RY=n(mme,"A",{href:!0});var KHt=s(RY);bpr=r(KHt,"from_config()"),KHt.forEach(t),vpr=r(mme,` class
method.`),mme.forEach(t),Fpr=i(zl),Fk=n(zl,"P",{});var tso=s(Fk);Tpr=r(tso,"This class cannot be instantiated directly using "),D4e=n(tso,"CODE",{});var eJt=s(D4e);Mpr=r(eJt,"__init__()"),eJt.forEach(t),Epr=r(tso," (throws an error)."),tso.forEach(t),Cpr=i(zl),xt=n(zl,"DIV",{class:!0});var c9=s(xt);T(Tk.$$.fragment,c9),wpr=i(c9),G4e=n(c9,"P",{});var oJt=s(G4e);Apr=r(oJt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),oJt.forEach(t),Lpr=i(c9),rm=n(c9,"P",{});var cme=s(rm);ypr=r(cme,`Note:
Loading a model from its configuration file does `),O4e=n(cme,"STRONG",{});var rJt=s(O4e);xpr=r(rJt,"not"),rJt.forEach(t),$pr=r(cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=n(cme,"A",{href:!0});var tJt=s(PY);kpr=r(tJt,"from_pretrained()"),tJt.forEach(t),Spr=r(cme," to load the model weights."),cme.forEach(t),Rpr=i(c9),T(JM.$$.fragment,c9),c9.forEach(t),Ppr=i(zl),lo=n(zl,"DIV",{class:!0});var Pa=s(lo);T(Mk.$$.fragment,Pa),Bpr=i(Pa),V4e=n(Pa,"P",{});var aJt=s(V4e);Ipr=r(aJt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),aJt.forEach(t),Npr=i(Pa),gn=n(Pa,"P",{});var f9=s(gn);qpr=r(f9,"The model class to instantiate is selected based on the "),X4e=n(f9,"CODE",{});var nJt=s(X4e);jpr=r(nJt,"model_type"),nJt.forEach(t),Dpr=r(f9,` property of the config object (either
passed as an argument or loaded from `),z4e=n(f9,"CODE",{});var sJt=s(z4e);Gpr=r(sJt,"pretrained_model_name_or_path"),sJt.forEach(t),Opr=r(f9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q4e=n(f9,"CODE",{});var lJt=s(Q4e);Vpr=r(lJt,"pretrained_model_name_or_path"),lJt.forEach(t),Xpr=r(f9,":"),f9.forEach(t),zpr=i(Pa),Ue=n(Pa,"UL",{});var ht=s(Ue);YM=n(ht,"LI",{});var FWe=s(YM);W4e=n(FWe,"STRONG",{});var iJt=s(W4e);Qpr=r(iJt,"bert"),iJt.forEach(t),Wpr=r(FWe," \u2014 "),BY=n(FWe,"A",{href:!0});var dJt=s(BY);Upr=r(dJt,"BertForNextSentencePrediction"),dJt.forEach(t),Hpr=r(FWe," (BERT model)"),FWe.forEach(t),Jpr=i(ht),ZM=n(ht,"LI",{});var TWe=s(ZM);U4e=n(TWe,"STRONG",{});var mJt=s(U4e);Ypr=r(mJt,"ernie"),mJt.forEach(t),Zpr=r(TWe," \u2014 "),IY=n(TWe,"A",{href:!0});var cJt=s(IY);Kpr=r(cJt,"ErnieForNextSentencePrediction"),cJt.forEach(t),e_r=r(TWe," (ERNIE model)"),TWe.forEach(t),o_r=i(ht),KM=n(ht,"LI",{});var MWe=s(KM);H4e=n(MWe,"STRONG",{});var fJt=s(H4e);r_r=r(fJt,"fnet"),fJt.forEach(t),t_r=r(MWe," \u2014 "),NY=n(MWe,"A",{href:!0});var gJt=s(NY);a_r=r(gJt,"FNetForNextSentencePrediction"),gJt.forEach(t),n_r=r(MWe," (FNet model)"),MWe.forEach(t),s_r=i(ht),eE=n(ht,"LI",{});var EWe=s(eE);J4e=n(EWe,"STRONG",{});var hJt=s(J4e);l_r=r(hJt,"megatron-bert"),hJt.forEach(t),i_r=r(EWe," \u2014 "),qY=n(EWe,"A",{href:!0});var uJt=s(qY);d_r=r(uJt,"MegatronBertForNextSentencePrediction"),uJt.forEach(t),m_r=r(EWe," (Megatron-BERT model)"),EWe.forEach(t),c_r=i(ht),oE=n(ht,"LI",{});var CWe=s(oE);Y4e=n(CWe,"STRONG",{});var pJt=s(Y4e);f_r=r(pJt,"mobilebert"),pJt.forEach(t),g_r=r(CWe," \u2014 "),jY=n(CWe,"A",{href:!0});var _Jt=s(jY);h_r=r(_Jt,"MobileBertForNextSentencePrediction"),_Jt.forEach(t),u_r=r(CWe," (MobileBERT model)"),CWe.forEach(t),p_r=i(ht),rE=n(ht,"LI",{});var wWe=s(rE);Z4e=n(wWe,"STRONG",{});var bJt=s(Z4e);__r=r(bJt,"nezha"),bJt.forEach(t),b_r=r(wWe," \u2014 "),DY=n(wWe,"A",{href:!0});var vJt=s(DY);v_r=r(vJt,"NezhaForNextSentencePrediction"),vJt.forEach(t),F_r=r(wWe," (Nezha model)"),wWe.forEach(t),T_r=i(ht),tE=n(ht,"LI",{});var AWe=s(tE);K4e=n(AWe,"STRONG",{});var FJt=s(K4e);M_r=r(FJt,"qdqbert"),FJt.forEach(t),E_r=r(AWe," \u2014 "),GY=n(AWe,"A",{href:!0});var TJt=s(GY);C_r=r(TJt,"QDQBertForNextSentencePrediction"),TJt.forEach(t),w_r=r(AWe," (QDQBert model)"),AWe.forEach(t),ht.forEach(t),A_r=i(Pa),aE=n(Pa,"P",{});var LWe=s(aE);L_r=r(LWe,"The model is set in evaluation mode by default using "),eCe=n(LWe,"CODE",{});var MJt=s(eCe);y_r=r(MJt,"model.eval()"),MJt.forEach(t),x_r=r(LWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oCe=n(LWe,"CODE",{});var EJt=s(oCe);$_r=r(EJt,"model.train()"),EJt.forEach(t),LWe.forEach(t),k_r=i(Pa),T(nE.$$.fragment,Pa),Pa.forEach(t),zl.forEach(t),jto=i(c),tm=n(c,"H2",{class:!0});var aso=s(tm);sE=n(aso,"A",{id:!0,class:!0,href:!0});var CJt=s(sE);rCe=n(CJt,"SPAN",{});var wJt=s(rCe);T(Ek.$$.fragment,wJt),wJt.forEach(t),CJt.forEach(t),S_r=i(aso),tCe=n(aso,"SPAN",{});var AJt=s(tCe);R_r=r(AJt,"AutoModelForTokenClassification"),AJt.forEach(t),aso.forEach(t),Dto=i(c),zo=n(c,"DIV",{class:!0});var Ql=s(zo);T(Ck.$$.fragment,Ql),P_r=i(Ql),am=n(Ql,"P",{});var fme=s(am);B_r=r(fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),OY=n(fme,"A",{href:!0});var LJt=s(OY);I_r=r(LJt,"from_pretrained()"),LJt.forEach(t),N_r=r(fme," class method or the "),VY=n(fme,"A",{href:!0});var yJt=s(VY);q_r=r(yJt,"from_config()"),yJt.forEach(t),j_r=r(fme,` class
method.`),fme.forEach(t),D_r=i(Ql),wk=n(Ql,"P",{});var nso=s(wk);G_r=r(nso,"This class cannot be instantiated directly using "),aCe=n(nso,"CODE",{});var xJt=s(aCe);O_r=r(xJt,"__init__()"),xJt.forEach(t),V_r=r(nso," (throws an error)."),nso.forEach(t),X_r=i(Ql),$t=n(Ql,"DIV",{class:!0});var g9=s($t);T(Ak.$$.fragment,g9),z_r=i(g9),nCe=n(g9,"P",{});var $Jt=s(nCe);Q_r=r($Jt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$Jt.forEach(t),W_r=i(g9),nm=n(g9,"P",{});var gme=s(nm);U_r=r(gme,`Note:
Loading a model from its configuration file does `),sCe=n(gme,"STRONG",{});var kJt=s(sCe);H_r=r(kJt,"not"),kJt.forEach(t),J_r=r(gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),XY=n(gme,"A",{href:!0});var SJt=s(XY);Y_r=r(SJt,"from_pretrained()"),SJt.forEach(t),Z_r=r(gme," to load the model weights."),gme.forEach(t),K_r=i(g9),T(lE.$$.fragment,g9),g9.forEach(t),e1r=i(Ql),io=n(Ql,"DIV",{class:!0});var Ba=s(io);T(Lk.$$.fragment,Ba),o1r=i(Ba),lCe=n(Ba,"P",{});var RJt=s(lCe);r1r=r(RJt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),RJt.forEach(t),t1r=i(Ba),hn=n(Ba,"P",{});var h9=s(hn);a1r=r(h9,"The model class to instantiate is selected based on the "),iCe=n(h9,"CODE",{});var PJt=s(iCe);n1r=r(PJt,"model_type"),PJt.forEach(t),s1r=r(h9,` property of the config object (either
passed as an argument or loaded from `),dCe=n(h9,"CODE",{});var BJt=s(dCe);l1r=r(BJt,"pretrained_model_name_or_path"),BJt.forEach(t),i1r=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mCe=n(h9,"CODE",{});var IJt=s(mCe);d1r=r(IJt,"pretrained_model_name_or_path"),IJt.forEach(t),m1r=r(h9,":"),h9.forEach(t),c1r=i(Ba),U=n(Ba,"UL",{});var J=s(U);iE=n(J,"LI",{});var yWe=s(iE);cCe=n(yWe,"STRONG",{});var NJt=s(cCe);f1r=r(NJt,"albert"),NJt.forEach(t),g1r=r(yWe," \u2014 "),zY=n(yWe,"A",{href:!0});var qJt=s(zY);h1r=r(qJt,"AlbertForTokenClassification"),qJt.forEach(t),u1r=r(yWe," (ALBERT model)"),yWe.forEach(t),p1r=i(J),dE=n(J,"LI",{});var xWe=s(dE);fCe=n(xWe,"STRONG",{});var jJt=s(fCe);_1r=r(jJt,"bert"),jJt.forEach(t),b1r=r(xWe," \u2014 "),QY=n(xWe,"A",{href:!0});var DJt=s(QY);v1r=r(DJt,"BertForTokenClassification"),DJt.forEach(t),F1r=r(xWe," (BERT model)"),xWe.forEach(t),T1r=i(J),mE=n(J,"LI",{});var $We=s(mE);gCe=n($We,"STRONG",{});var GJt=s(gCe);M1r=r(GJt,"big_bird"),GJt.forEach(t),E1r=r($We," \u2014 "),WY=n($We,"A",{href:!0});var OJt=s(WY);C1r=r(OJt,"BigBirdForTokenClassification"),OJt.forEach(t),w1r=r($We," (BigBird model)"),$We.forEach(t),A1r=i(J),cE=n(J,"LI",{});var kWe=s(cE);hCe=n(kWe,"STRONG",{});var VJt=s(hCe);L1r=r(VJt,"bloom"),VJt.forEach(t),y1r=r(kWe," \u2014 "),UY=n(kWe,"A",{href:!0});var XJt=s(UY);x1r=r(XJt,"BloomForTokenClassification"),XJt.forEach(t),$1r=r(kWe," (BLOOM model)"),kWe.forEach(t),k1r=i(J),fE=n(J,"LI",{});var SWe=s(fE);uCe=n(SWe,"STRONG",{});var zJt=s(uCe);S1r=r(zJt,"camembert"),zJt.forEach(t),R1r=r(SWe," \u2014 "),HY=n(SWe,"A",{href:!0});var QJt=s(HY);P1r=r(QJt,"CamembertForTokenClassification"),QJt.forEach(t),B1r=r(SWe," (CamemBERT model)"),SWe.forEach(t),I1r=i(J),gE=n(J,"LI",{});var RWe=s(gE);pCe=n(RWe,"STRONG",{});var WJt=s(pCe);N1r=r(WJt,"canine"),WJt.forEach(t),q1r=r(RWe," \u2014 "),JY=n(RWe,"A",{href:!0});var UJt=s(JY);j1r=r(UJt,"CanineForTokenClassification"),UJt.forEach(t),D1r=r(RWe," (CANINE model)"),RWe.forEach(t),G1r=i(J),hE=n(J,"LI",{});var PWe=s(hE);_Ce=n(PWe,"STRONG",{});var HJt=s(_Ce);O1r=r(HJt,"convbert"),HJt.forEach(t),V1r=r(PWe," \u2014 "),YY=n(PWe,"A",{href:!0});var JJt=s(YY);X1r=r(JJt,"ConvBertForTokenClassification"),JJt.forEach(t),z1r=r(PWe," (ConvBERT model)"),PWe.forEach(t),Q1r=i(J),uE=n(J,"LI",{});var BWe=s(uE);bCe=n(BWe,"STRONG",{});var YJt=s(bCe);W1r=r(YJt,"data2vec-text"),YJt.forEach(t),U1r=r(BWe," \u2014 "),ZY=n(BWe,"A",{href:!0});var ZJt=s(ZY);H1r=r(ZJt,"Data2VecTextForTokenClassification"),ZJt.forEach(t),J1r=r(BWe," (Data2VecText model)"),BWe.forEach(t),Y1r=i(J),pE=n(J,"LI",{});var IWe=s(pE);vCe=n(IWe,"STRONG",{});var KJt=s(vCe);Z1r=r(KJt,"deberta"),KJt.forEach(t),K1r=r(IWe," \u2014 "),KY=n(IWe,"A",{href:!0});var eYt=s(KY);e2r=r(eYt,"DebertaForTokenClassification"),eYt.forEach(t),o2r=r(IWe," (DeBERTa model)"),IWe.forEach(t),r2r=i(J),_E=n(J,"LI",{});var NWe=s(_E);FCe=n(NWe,"STRONG",{});var oYt=s(FCe);t2r=r(oYt,"deberta-v2"),oYt.forEach(t),a2r=r(NWe," \u2014 "),eZ=n(NWe,"A",{href:!0});var rYt=s(eZ);n2r=r(rYt,"DebertaV2ForTokenClassification"),rYt.forEach(t),s2r=r(NWe," (DeBERTa-v2 model)"),NWe.forEach(t),l2r=i(J),bE=n(J,"LI",{});var qWe=s(bE);TCe=n(qWe,"STRONG",{});var tYt=s(TCe);i2r=r(tYt,"distilbert"),tYt.forEach(t),d2r=r(qWe," \u2014 "),oZ=n(qWe,"A",{href:!0});var aYt=s(oZ);m2r=r(aYt,"DistilBertForTokenClassification"),aYt.forEach(t),c2r=r(qWe," (DistilBERT model)"),qWe.forEach(t),f2r=i(J),vE=n(J,"LI",{});var jWe=s(vE);MCe=n(jWe,"STRONG",{});var nYt=s(MCe);g2r=r(nYt,"electra"),nYt.forEach(t),h2r=r(jWe," \u2014 "),rZ=n(jWe,"A",{href:!0});var sYt=s(rZ);u2r=r(sYt,"ElectraForTokenClassification"),sYt.forEach(t),p2r=r(jWe," (ELECTRA model)"),jWe.forEach(t),_2r=i(J),FE=n(J,"LI",{});var DWe=s(FE);ECe=n(DWe,"STRONG",{});var lYt=s(ECe);b2r=r(lYt,"ernie"),lYt.forEach(t),v2r=r(DWe," \u2014 "),tZ=n(DWe,"A",{href:!0});var iYt=s(tZ);F2r=r(iYt,"ErnieForTokenClassification"),iYt.forEach(t),T2r=r(DWe," (ERNIE model)"),DWe.forEach(t),M2r=i(J),TE=n(J,"LI",{});var GWe=s(TE);CCe=n(GWe,"STRONG",{});var dYt=s(CCe);E2r=r(dYt,"esm"),dYt.forEach(t),C2r=r(GWe," \u2014 "),aZ=n(GWe,"A",{href:!0});var mYt=s(aZ);w2r=r(mYt,"EsmForTokenClassification"),mYt.forEach(t),A2r=r(GWe," (ESM model)"),GWe.forEach(t),L2r=i(J),ME=n(J,"LI",{});var OWe=s(ME);wCe=n(OWe,"STRONG",{});var cYt=s(wCe);y2r=r(cYt,"flaubert"),cYt.forEach(t),x2r=r(OWe," \u2014 "),nZ=n(OWe,"A",{href:!0});var fYt=s(nZ);$2r=r(fYt,"FlaubertForTokenClassification"),fYt.forEach(t),k2r=r(OWe," (FlauBERT model)"),OWe.forEach(t),S2r=i(J),EE=n(J,"LI",{});var VWe=s(EE);ACe=n(VWe,"STRONG",{});var gYt=s(ACe);R2r=r(gYt,"fnet"),gYt.forEach(t),P2r=r(VWe," \u2014 "),sZ=n(VWe,"A",{href:!0});var hYt=s(sZ);B2r=r(hYt,"FNetForTokenClassification"),hYt.forEach(t),I2r=r(VWe," (FNet model)"),VWe.forEach(t),N2r=i(J),CE=n(J,"LI",{});var XWe=s(CE);LCe=n(XWe,"STRONG",{});var uYt=s(LCe);q2r=r(uYt,"funnel"),uYt.forEach(t),j2r=r(XWe," \u2014 "),lZ=n(XWe,"A",{href:!0});var pYt=s(lZ);D2r=r(pYt,"FunnelForTokenClassification"),pYt.forEach(t),G2r=r(XWe," (Funnel Transformer model)"),XWe.forEach(t),O2r=i(J),wE=n(J,"LI",{});var zWe=s(wE);yCe=n(zWe,"STRONG",{});var _Yt=s(yCe);V2r=r(_Yt,"gpt2"),_Yt.forEach(t),X2r=r(zWe," \u2014 "),iZ=n(zWe,"A",{href:!0});var bYt=s(iZ);z2r=r(bYt,"GPT2ForTokenClassification"),bYt.forEach(t),Q2r=r(zWe," (OpenAI GPT-2 model)"),zWe.forEach(t),W2r=i(J),AE=n(J,"LI",{});var QWe=s(AE);xCe=n(QWe,"STRONG",{});var vYt=s(xCe);U2r=r(vYt,"ibert"),vYt.forEach(t),H2r=r(QWe," \u2014 "),dZ=n(QWe,"A",{href:!0});var FYt=s(dZ);J2r=r(FYt,"IBertForTokenClassification"),FYt.forEach(t),Y2r=r(QWe," (I-BERT model)"),QWe.forEach(t),Z2r=i(J),LE=n(J,"LI",{});var WWe=s(LE);$Ce=n(WWe,"STRONG",{});var TYt=s($Ce);K2r=r(TYt,"layoutlm"),TYt.forEach(t),ebr=r(WWe," \u2014 "),mZ=n(WWe,"A",{href:!0});var MYt=s(mZ);obr=r(MYt,"LayoutLMForTokenClassification"),MYt.forEach(t),rbr=r(WWe," (LayoutLM model)"),WWe.forEach(t),tbr=i(J),yE=n(J,"LI",{});var UWe=s(yE);kCe=n(UWe,"STRONG",{});var EYt=s(kCe);abr=r(EYt,"layoutlmv2"),EYt.forEach(t),nbr=r(UWe," \u2014 "),cZ=n(UWe,"A",{href:!0});var CYt=s(cZ);sbr=r(CYt,"LayoutLMv2ForTokenClassification"),CYt.forEach(t),lbr=r(UWe," (LayoutLMv2 model)"),UWe.forEach(t),ibr=i(J),xE=n(J,"LI",{});var HWe=s(xE);SCe=n(HWe,"STRONG",{});var wYt=s(SCe);dbr=r(wYt,"layoutlmv3"),wYt.forEach(t),mbr=r(HWe," \u2014 "),fZ=n(HWe,"A",{href:!0});var AYt=s(fZ);cbr=r(AYt,"LayoutLMv3ForTokenClassification"),AYt.forEach(t),fbr=r(HWe," (LayoutLMv3 model)"),HWe.forEach(t),gbr=i(J),$E=n(J,"LI",{});var JWe=s($E);RCe=n(JWe,"STRONG",{});var LYt=s(RCe);hbr=r(LYt,"lilt"),LYt.forEach(t),ubr=r(JWe," \u2014 "),gZ=n(JWe,"A",{href:!0});var yYt=s(gZ);pbr=r(yYt,"LiltForTokenClassification"),yYt.forEach(t),_br=r(JWe," (LiLT model)"),JWe.forEach(t),bbr=i(J),kE=n(J,"LI",{});var YWe=s(kE);PCe=n(YWe,"STRONG",{});var xYt=s(PCe);vbr=r(xYt,"longformer"),xYt.forEach(t),Fbr=r(YWe," \u2014 "),hZ=n(YWe,"A",{href:!0});var $Yt=s(hZ);Tbr=r($Yt,"LongformerForTokenClassification"),$Yt.forEach(t),Mbr=r(YWe," (Longformer model)"),YWe.forEach(t),Ebr=i(J),SE=n(J,"LI",{});var ZWe=s(SE);BCe=n(ZWe,"STRONG",{});var kYt=s(BCe);Cbr=r(kYt,"luke"),kYt.forEach(t),wbr=r(ZWe," \u2014 "),uZ=n(ZWe,"A",{href:!0});var SYt=s(uZ);Abr=r(SYt,"LukeForTokenClassification"),SYt.forEach(t),Lbr=r(ZWe," (LUKE model)"),ZWe.forEach(t),ybr=i(J),RE=n(J,"LI",{});var KWe=s(RE);ICe=n(KWe,"STRONG",{});var RYt=s(ICe);xbr=r(RYt,"markuplm"),RYt.forEach(t),$br=r(KWe," \u2014 "),pZ=n(KWe,"A",{href:!0});var PYt=s(pZ);kbr=r(PYt,"MarkupLMForTokenClassification"),PYt.forEach(t),Sbr=r(KWe," (MarkupLM model)"),KWe.forEach(t),Rbr=i(J),PE=n(J,"LI",{});var eUe=s(PE);NCe=n(eUe,"STRONG",{});var BYt=s(NCe);Pbr=r(BYt,"megatron-bert"),BYt.forEach(t),Bbr=r(eUe," \u2014 "),_Z=n(eUe,"A",{href:!0});var IYt=s(_Z);Ibr=r(IYt,"MegatronBertForTokenClassification"),IYt.forEach(t),Nbr=r(eUe," (Megatron-BERT model)"),eUe.forEach(t),qbr=i(J),BE=n(J,"LI",{});var oUe=s(BE);qCe=n(oUe,"STRONG",{});var NYt=s(qCe);jbr=r(NYt,"mobilebert"),NYt.forEach(t),Dbr=r(oUe," \u2014 "),bZ=n(oUe,"A",{href:!0});var qYt=s(bZ);Gbr=r(qYt,"MobileBertForTokenClassification"),qYt.forEach(t),Obr=r(oUe," (MobileBERT model)"),oUe.forEach(t),Vbr=i(J),IE=n(J,"LI",{});var rUe=s(IE);jCe=n(rUe,"STRONG",{});var jYt=s(jCe);Xbr=r(jYt,"mpnet"),jYt.forEach(t),zbr=r(rUe," \u2014 "),vZ=n(rUe,"A",{href:!0});var DYt=s(vZ);Qbr=r(DYt,"MPNetForTokenClassification"),DYt.forEach(t),Wbr=r(rUe," (MPNet model)"),rUe.forEach(t),Ubr=i(J),NE=n(J,"LI",{});var tUe=s(NE);DCe=n(tUe,"STRONG",{});var GYt=s(DCe);Hbr=r(GYt,"nezha"),GYt.forEach(t),Jbr=r(tUe," \u2014 "),FZ=n(tUe,"A",{href:!0});var OYt=s(FZ);Ybr=r(OYt,"NezhaForTokenClassification"),OYt.forEach(t),Zbr=r(tUe," (Nezha model)"),tUe.forEach(t),Kbr=i(J),qE=n(J,"LI",{});var aUe=s(qE);GCe=n(aUe,"STRONG",{});var VYt=s(GCe);evr=r(VYt,"nystromformer"),VYt.forEach(t),ovr=r(aUe," \u2014 "),TZ=n(aUe,"A",{href:!0});var XYt=s(TZ);rvr=r(XYt,"NystromformerForTokenClassification"),XYt.forEach(t),tvr=r(aUe," (Nystr\xF6mformer model)"),aUe.forEach(t),avr=i(J),jE=n(J,"LI",{});var nUe=s(jE);OCe=n(nUe,"STRONG",{});var zYt=s(OCe);nvr=r(zYt,"qdqbert"),zYt.forEach(t),svr=r(nUe," \u2014 "),MZ=n(nUe,"A",{href:!0});var QYt=s(MZ);lvr=r(QYt,"QDQBertForTokenClassification"),QYt.forEach(t),ivr=r(nUe," (QDQBert model)"),nUe.forEach(t),dvr=i(J),DE=n(J,"LI",{});var sUe=s(DE);VCe=n(sUe,"STRONG",{});var WYt=s(VCe);mvr=r(WYt,"rembert"),WYt.forEach(t),cvr=r(sUe," \u2014 "),EZ=n(sUe,"A",{href:!0});var UYt=s(EZ);fvr=r(UYt,"RemBertForTokenClassification"),UYt.forEach(t),gvr=r(sUe," (RemBERT model)"),sUe.forEach(t),hvr=i(J),GE=n(J,"LI",{});var lUe=s(GE);XCe=n(lUe,"STRONG",{});var HYt=s(XCe);uvr=r(HYt,"roberta"),HYt.forEach(t),pvr=r(lUe," \u2014 "),CZ=n(lUe,"A",{href:!0});var JYt=s(CZ);_vr=r(JYt,"RobertaForTokenClassification"),JYt.forEach(t),bvr=r(lUe," (RoBERTa model)"),lUe.forEach(t),vvr=i(J),OE=n(J,"LI",{});var iUe=s(OE);zCe=n(iUe,"STRONG",{});var YYt=s(zCe);Fvr=r(YYt,"roformer"),YYt.forEach(t),Tvr=r(iUe," \u2014 "),wZ=n(iUe,"A",{href:!0});var ZYt=s(wZ);Mvr=r(ZYt,"RoFormerForTokenClassification"),ZYt.forEach(t),Evr=r(iUe," (RoFormer model)"),iUe.forEach(t),Cvr=i(J),VE=n(J,"LI",{});var dUe=s(VE);QCe=n(dUe,"STRONG",{});var KYt=s(QCe);wvr=r(KYt,"squeezebert"),KYt.forEach(t),Avr=r(dUe," \u2014 "),AZ=n(dUe,"A",{href:!0});var eZt=s(AZ);Lvr=r(eZt,"SqueezeBertForTokenClassification"),eZt.forEach(t),yvr=r(dUe," (SqueezeBERT model)"),dUe.forEach(t),xvr=i(J),XE=n(J,"LI",{});var mUe=s(XE);WCe=n(mUe,"STRONG",{});var oZt=s(WCe);$vr=r(oZt,"xlm"),oZt.forEach(t),kvr=r(mUe," \u2014 "),LZ=n(mUe,"A",{href:!0});var rZt=s(LZ);Svr=r(rZt,"XLMForTokenClassification"),rZt.forEach(t),Rvr=r(mUe," (XLM model)"),mUe.forEach(t),Pvr=i(J),zE=n(J,"LI",{});var cUe=s(zE);UCe=n(cUe,"STRONG",{});var tZt=s(UCe);Bvr=r(tZt,"xlm-roberta"),tZt.forEach(t),Ivr=r(cUe," \u2014 "),yZ=n(cUe,"A",{href:!0});var aZt=s(yZ);Nvr=r(aZt,"XLMRobertaForTokenClassification"),aZt.forEach(t),qvr=r(cUe," (XLM-RoBERTa model)"),cUe.forEach(t),jvr=i(J),QE=n(J,"LI",{});var fUe=s(QE);HCe=n(fUe,"STRONG",{});var nZt=s(HCe);Dvr=r(nZt,"xlm-roberta-xl"),nZt.forEach(t),Gvr=r(fUe," \u2014 "),xZ=n(fUe,"A",{href:!0});var sZt=s(xZ);Ovr=r(sZt,"XLMRobertaXLForTokenClassification"),sZt.forEach(t),Vvr=r(fUe," (XLM-RoBERTa-XL model)"),fUe.forEach(t),Xvr=i(J),WE=n(J,"LI",{});var gUe=s(WE);JCe=n(gUe,"STRONG",{});var lZt=s(JCe);zvr=r(lZt,"xlnet"),lZt.forEach(t),Qvr=r(gUe," \u2014 "),$Z=n(gUe,"A",{href:!0});var iZt=s($Z);Wvr=r(iZt,"XLNetForTokenClassification"),iZt.forEach(t),Uvr=r(gUe," (XLNet model)"),gUe.forEach(t),Hvr=i(J),UE=n(J,"LI",{});var hUe=s(UE);YCe=n(hUe,"STRONG",{});var dZt=s(YCe);Jvr=r(dZt,"yoso"),dZt.forEach(t),Yvr=r(hUe," \u2014 "),kZ=n(hUe,"A",{href:!0});var mZt=s(kZ);Zvr=r(mZt,"YosoForTokenClassification"),mZt.forEach(t),Kvr=r(hUe," (YOSO model)"),hUe.forEach(t),J.forEach(t),eFr=i(Ba),HE=n(Ba,"P",{});var uUe=s(HE);oFr=r(uUe,"The model is set in evaluation mode by default using "),ZCe=n(uUe,"CODE",{});var cZt=s(ZCe);rFr=r(cZt,"model.eval()"),cZt.forEach(t),tFr=r(uUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KCe=n(uUe,"CODE",{});var fZt=s(KCe);aFr=r(fZt,"model.train()"),fZt.forEach(t),uUe.forEach(t),nFr=i(Ba),T(JE.$$.fragment,Ba),Ba.forEach(t),Ql.forEach(t),Gto=i(c),sm=n(c,"H2",{class:!0});var sso=s(sm);YE=n(sso,"A",{id:!0,class:!0,href:!0});var gZt=s(YE);e3e=n(gZt,"SPAN",{});var hZt=s(e3e);T(yk.$$.fragment,hZt),hZt.forEach(t),gZt.forEach(t),sFr=i(sso),o3e=n(sso,"SPAN",{});var uZt=s(o3e);lFr=r(uZt,"AutoModelForQuestionAnswering"),uZt.forEach(t),sso.forEach(t),Oto=i(c),Qo=n(c,"DIV",{class:!0});var Wl=s(Qo);T(xk.$$.fragment,Wl),iFr=i(Wl),lm=n(Wl,"P",{});var hme=s(lm);dFr=r(hme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),SZ=n(hme,"A",{href:!0});var pZt=s(SZ);mFr=r(pZt,"from_pretrained()"),pZt.forEach(t),cFr=r(hme," class method or the "),RZ=n(hme,"A",{href:!0});var _Zt=s(RZ);fFr=r(_Zt,"from_config()"),_Zt.forEach(t),gFr=r(hme,` class
method.`),hme.forEach(t),hFr=i(Wl),$k=n(Wl,"P",{});var lso=s($k);uFr=r(lso,"This class cannot be instantiated directly using "),r3e=n(lso,"CODE",{});var bZt=s(r3e);pFr=r(bZt,"__init__()"),bZt.forEach(t),_Fr=r(lso," (throws an error)."),lso.forEach(t),bFr=i(Wl),kt=n(Wl,"DIV",{class:!0});var u9=s(kt);T(kk.$$.fragment,u9),vFr=i(u9),t3e=n(u9,"P",{});var vZt=s(t3e);FFr=r(vZt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),vZt.forEach(t),TFr=i(u9),im=n(u9,"P",{});var ume=s(im);MFr=r(ume,`Note:
Loading a model from its configuration file does `),a3e=n(ume,"STRONG",{});var FZt=s(a3e);EFr=r(FZt,"not"),FZt.forEach(t),CFr=r(ume,` load the model weights. It only affects the
model\u2019s configuration. Use `),PZ=n(ume,"A",{href:!0});var TZt=s(PZ);wFr=r(TZt,"from_pretrained()"),TZt.forEach(t),AFr=r(ume," to load the model weights."),ume.forEach(t),LFr=i(u9),T(ZE.$$.fragment,u9),u9.forEach(t),yFr=i(Wl),mo=n(Wl,"DIV",{class:!0});var Ia=s(mo);T(Sk.$$.fragment,Ia),xFr=i(Ia),n3e=n(Ia,"P",{});var MZt=s(n3e);$Fr=r(MZt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),MZt.forEach(t),kFr=i(Ia),un=n(Ia,"P",{});var p9=s(un);SFr=r(p9,"The model class to instantiate is selected based on the "),s3e=n(p9,"CODE",{});var EZt=s(s3e);RFr=r(EZt,"model_type"),EZt.forEach(t),PFr=r(p9,` property of the config object (either
passed as an argument or loaded from `),l3e=n(p9,"CODE",{});var CZt=s(l3e);BFr=r(CZt,"pretrained_model_name_or_path"),CZt.forEach(t),IFr=r(p9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=n(p9,"CODE",{});var wZt=s(i3e);NFr=r(wZt,"pretrained_model_name_or_path"),wZt.forEach(t),qFr=r(p9,":"),p9.forEach(t),jFr=i(Ia),O=n(Ia,"UL",{});var X=s(O);KE=n(X,"LI",{});var pUe=s(KE);d3e=n(pUe,"STRONG",{});var AZt=s(d3e);DFr=r(AZt,"albert"),AZt.forEach(t),GFr=r(pUe," \u2014 "),BZ=n(pUe,"A",{href:!0});var LZt=s(BZ);OFr=r(LZt,"AlbertForQuestionAnswering"),LZt.forEach(t),VFr=r(pUe," (ALBERT model)"),pUe.forEach(t),XFr=i(X),e4=n(X,"LI",{});var _Ue=s(e4);m3e=n(_Ue,"STRONG",{});var yZt=s(m3e);zFr=r(yZt,"bart"),yZt.forEach(t),QFr=r(_Ue," \u2014 "),IZ=n(_Ue,"A",{href:!0});var xZt=s(IZ);WFr=r(xZt,"BartForQuestionAnswering"),xZt.forEach(t),UFr=r(_Ue," (BART model)"),_Ue.forEach(t),HFr=i(X),o4=n(X,"LI",{});var bUe=s(o4);c3e=n(bUe,"STRONG",{});var $Zt=s(c3e);JFr=r($Zt,"bert"),$Zt.forEach(t),YFr=r(bUe," \u2014 "),NZ=n(bUe,"A",{href:!0});var kZt=s(NZ);ZFr=r(kZt,"BertForQuestionAnswering"),kZt.forEach(t),KFr=r(bUe," (BERT model)"),bUe.forEach(t),eTr=i(X),r4=n(X,"LI",{});var vUe=s(r4);f3e=n(vUe,"STRONG",{});var SZt=s(f3e);oTr=r(SZt,"big_bird"),SZt.forEach(t),rTr=r(vUe," \u2014 "),qZ=n(vUe,"A",{href:!0});var RZt=s(qZ);tTr=r(RZt,"BigBirdForQuestionAnswering"),RZt.forEach(t),aTr=r(vUe," (BigBird model)"),vUe.forEach(t),nTr=i(X),t4=n(X,"LI",{});var FUe=s(t4);g3e=n(FUe,"STRONG",{});var PZt=s(g3e);sTr=r(PZt,"bigbird_pegasus"),PZt.forEach(t),lTr=r(FUe," \u2014 "),jZ=n(FUe,"A",{href:!0});var BZt=s(jZ);iTr=r(BZt,"BigBirdPegasusForQuestionAnswering"),BZt.forEach(t),dTr=r(FUe," (BigBird-Pegasus model)"),FUe.forEach(t),mTr=i(X),a4=n(X,"LI",{});var TUe=s(a4);h3e=n(TUe,"STRONG",{});var IZt=s(h3e);cTr=r(IZt,"bloom"),IZt.forEach(t),fTr=r(TUe," \u2014 "),DZ=n(TUe,"A",{href:!0});var NZt=s(DZ);gTr=r(NZt,"BloomForQuestionAnswering"),NZt.forEach(t),hTr=r(TUe," (BLOOM model)"),TUe.forEach(t),uTr=i(X),n4=n(X,"LI",{});var MUe=s(n4);u3e=n(MUe,"STRONG",{});var qZt=s(u3e);pTr=r(qZt,"camembert"),qZt.forEach(t),_Tr=r(MUe," \u2014 "),GZ=n(MUe,"A",{href:!0});var jZt=s(GZ);bTr=r(jZt,"CamembertForQuestionAnswering"),jZt.forEach(t),vTr=r(MUe," (CamemBERT model)"),MUe.forEach(t),FTr=i(X),s4=n(X,"LI",{});var EUe=s(s4);p3e=n(EUe,"STRONG",{});var DZt=s(p3e);TTr=r(DZt,"canine"),DZt.forEach(t),MTr=r(EUe," \u2014 "),OZ=n(EUe,"A",{href:!0});var GZt=s(OZ);ETr=r(GZt,"CanineForQuestionAnswering"),GZt.forEach(t),CTr=r(EUe," (CANINE model)"),EUe.forEach(t),wTr=i(X),l4=n(X,"LI",{});var CUe=s(l4);_3e=n(CUe,"STRONG",{});var OZt=s(_3e);ATr=r(OZt,"convbert"),OZt.forEach(t),LTr=r(CUe," \u2014 "),VZ=n(CUe,"A",{href:!0});var VZt=s(VZ);yTr=r(VZt,"ConvBertForQuestionAnswering"),VZt.forEach(t),xTr=r(CUe," (ConvBERT model)"),CUe.forEach(t),$Tr=i(X),i4=n(X,"LI",{});var wUe=s(i4);b3e=n(wUe,"STRONG",{});var XZt=s(b3e);kTr=r(XZt,"data2vec-text"),XZt.forEach(t),STr=r(wUe," \u2014 "),XZ=n(wUe,"A",{href:!0});var zZt=s(XZ);RTr=r(zZt,"Data2VecTextForQuestionAnswering"),zZt.forEach(t),PTr=r(wUe," (Data2VecText model)"),wUe.forEach(t),BTr=i(X),d4=n(X,"LI",{});var AUe=s(d4);v3e=n(AUe,"STRONG",{});var QZt=s(v3e);ITr=r(QZt,"deberta"),QZt.forEach(t),NTr=r(AUe," \u2014 "),zZ=n(AUe,"A",{href:!0});var WZt=s(zZ);qTr=r(WZt,"DebertaForQuestionAnswering"),WZt.forEach(t),jTr=r(AUe," (DeBERTa model)"),AUe.forEach(t),DTr=i(X),m4=n(X,"LI",{});var LUe=s(m4);F3e=n(LUe,"STRONG",{});var UZt=s(F3e);GTr=r(UZt,"deberta-v2"),UZt.forEach(t),OTr=r(LUe," \u2014 "),QZ=n(LUe,"A",{href:!0});var HZt=s(QZ);VTr=r(HZt,"DebertaV2ForQuestionAnswering"),HZt.forEach(t),XTr=r(LUe," (DeBERTa-v2 model)"),LUe.forEach(t),zTr=i(X),c4=n(X,"LI",{});var yUe=s(c4);T3e=n(yUe,"STRONG",{});var JZt=s(T3e);QTr=r(JZt,"distilbert"),JZt.forEach(t),WTr=r(yUe," \u2014 "),WZ=n(yUe,"A",{href:!0});var YZt=s(WZ);UTr=r(YZt,"DistilBertForQuestionAnswering"),YZt.forEach(t),HTr=r(yUe," (DistilBERT model)"),yUe.forEach(t),JTr=i(X),f4=n(X,"LI",{});var xUe=s(f4);M3e=n(xUe,"STRONG",{});var ZZt=s(M3e);YTr=r(ZZt,"electra"),ZZt.forEach(t),ZTr=r(xUe," \u2014 "),UZ=n(xUe,"A",{href:!0});var KZt=s(UZ);KTr=r(KZt,"ElectraForQuestionAnswering"),KZt.forEach(t),eMr=r(xUe," (ELECTRA model)"),xUe.forEach(t),oMr=i(X),g4=n(X,"LI",{});var $Ue=s(g4);E3e=n($Ue,"STRONG",{});var eKt=s(E3e);rMr=r(eKt,"ernie"),eKt.forEach(t),tMr=r($Ue," \u2014 "),HZ=n($Ue,"A",{href:!0});var oKt=s(HZ);aMr=r(oKt,"ErnieForQuestionAnswering"),oKt.forEach(t),nMr=r($Ue," (ERNIE model)"),$Ue.forEach(t),sMr=i(X),h4=n(X,"LI",{});var kUe=s(h4);C3e=n(kUe,"STRONG",{});var rKt=s(C3e);lMr=r(rKt,"flaubert"),rKt.forEach(t),iMr=r(kUe," \u2014 "),JZ=n(kUe,"A",{href:!0});var tKt=s(JZ);dMr=r(tKt,"FlaubertForQuestionAnsweringSimple"),tKt.forEach(t),mMr=r(kUe," (FlauBERT model)"),kUe.forEach(t),cMr=i(X),u4=n(X,"LI",{});var SUe=s(u4);w3e=n(SUe,"STRONG",{});var aKt=s(w3e);fMr=r(aKt,"fnet"),aKt.forEach(t),gMr=r(SUe," \u2014 "),YZ=n(SUe,"A",{href:!0});var nKt=s(YZ);hMr=r(nKt,"FNetForQuestionAnswering"),nKt.forEach(t),uMr=r(SUe," (FNet model)"),SUe.forEach(t),pMr=i(X),p4=n(X,"LI",{});var RUe=s(p4);A3e=n(RUe,"STRONG",{});var sKt=s(A3e);_Mr=r(sKt,"funnel"),sKt.forEach(t),bMr=r(RUe," \u2014 "),ZZ=n(RUe,"A",{href:!0});var lKt=s(ZZ);vMr=r(lKt,"FunnelForQuestionAnswering"),lKt.forEach(t),FMr=r(RUe," (Funnel Transformer model)"),RUe.forEach(t),TMr=i(X),_4=n(X,"LI",{});var PUe=s(_4);L3e=n(PUe,"STRONG",{});var iKt=s(L3e);MMr=r(iKt,"gptj"),iKt.forEach(t),EMr=r(PUe," \u2014 "),KZ=n(PUe,"A",{href:!0});var dKt=s(KZ);CMr=r(dKt,"GPTJForQuestionAnswering"),dKt.forEach(t),wMr=r(PUe," (GPT-J model)"),PUe.forEach(t),AMr=i(X),b4=n(X,"LI",{});var BUe=s(b4);y3e=n(BUe,"STRONG",{});var mKt=s(y3e);LMr=r(mKt,"ibert"),mKt.forEach(t),yMr=r(BUe," \u2014 "),eK=n(BUe,"A",{href:!0});var cKt=s(eK);xMr=r(cKt,"IBertForQuestionAnswering"),cKt.forEach(t),$Mr=r(BUe," (I-BERT model)"),BUe.forEach(t),kMr=i(X),v4=n(X,"LI",{});var IUe=s(v4);x3e=n(IUe,"STRONG",{});var fKt=s(x3e);SMr=r(fKt,"layoutlmv2"),fKt.forEach(t),RMr=r(IUe," \u2014 "),oK=n(IUe,"A",{href:!0});var gKt=s(oK);PMr=r(gKt,"LayoutLMv2ForQuestionAnswering"),gKt.forEach(t),BMr=r(IUe," (LayoutLMv2 model)"),IUe.forEach(t),IMr=i(X),F4=n(X,"LI",{});var NUe=s(F4);$3e=n(NUe,"STRONG",{});var hKt=s($3e);NMr=r(hKt,"layoutlmv3"),hKt.forEach(t),qMr=r(NUe," \u2014 "),rK=n(NUe,"A",{href:!0});var uKt=s(rK);jMr=r(uKt,"LayoutLMv3ForQuestionAnswering"),uKt.forEach(t),DMr=r(NUe," (LayoutLMv3 model)"),NUe.forEach(t),GMr=i(X),T4=n(X,"LI",{});var qUe=s(T4);k3e=n(qUe,"STRONG",{});var pKt=s(k3e);OMr=r(pKt,"led"),pKt.forEach(t),VMr=r(qUe," \u2014 "),tK=n(qUe,"A",{href:!0});var _Kt=s(tK);XMr=r(_Kt,"LEDForQuestionAnswering"),_Kt.forEach(t),zMr=r(qUe," (LED model)"),qUe.forEach(t),QMr=i(X),M4=n(X,"LI",{});var jUe=s(M4);S3e=n(jUe,"STRONG",{});var bKt=s(S3e);WMr=r(bKt,"lilt"),bKt.forEach(t),UMr=r(jUe," \u2014 "),aK=n(jUe,"A",{href:!0});var vKt=s(aK);HMr=r(vKt,"LiltForQuestionAnswering"),vKt.forEach(t),JMr=r(jUe," (LiLT model)"),jUe.forEach(t),YMr=i(X),E4=n(X,"LI",{});var DUe=s(E4);R3e=n(DUe,"STRONG",{});var FKt=s(R3e);ZMr=r(FKt,"longformer"),FKt.forEach(t),KMr=r(DUe," \u2014 "),nK=n(DUe,"A",{href:!0});var TKt=s(nK);eEr=r(TKt,"LongformerForQuestionAnswering"),TKt.forEach(t),oEr=r(DUe," (Longformer model)"),DUe.forEach(t),rEr=i(X),C4=n(X,"LI",{});var GUe=s(C4);P3e=n(GUe,"STRONG",{});var MKt=s(P3e);tEr=r(MKt,"luke"),MKt.forEach(t),aEr=r(GUe," \u2014 "),sK=n(GUe,"A",{href:!0});var EKt=s(sK);nEr=r(EKt,"LukeForQuestionAnswering"),EKt.forEach(t),sEr=r(GUe," (LUKE model)"),GUe.forEach(t),lEr=i(X),w4=n(X,"LI",{});var OUe=s(w4);B3e=n(OUe,"STRONG",{});var CKt=s(B3e);iEr=r(CKt,"lxmert"),CKt.forEach(t),dEr=r(OUe," \u2014 "),lK=n(OUe,"A",{href:!0});var wKt=s(lK);mEr=r(wKt,"LxmertForQuestionAnswering"),wKt.forEach(t),cEr=r(OUe," (LXMERT model)"),OUe.forEach(t),fEr=i(X),A4=n(X,"LI",{});var VUe=s(A4);I3e=n(VUe,"STRONG",{});var AKt=s(I3e);gEr=r(AKt,"markuplm"),AKt.forEach(t),hEr=r(VUe," \u2014 "),iK=n(VUe,"A",{href:!0});var LKt=s(iK);uEr=r(LKt,"MarkupLMForQuestionAnswering"),LKt.forEach(t),pEr=r(VUe," (MarkupLM model)"),VUe.forEach(t),_Er=i(X),L4=n(X,"LI",{});var XUe=s(L4);N3e=n(XUe,"STRONG",{});var yKt=s(N3e);bEr=r(yKt,"mbart"),yKt.forEach(t),vEr=r(XUe," \u2014 "),dK=n(XUe,"A",{href:!0});var xKt=s(dK);FEr=r(xKt,"MBartForQuestionAnswering"),xKt.forEach(t),TEr=r(XUe," (mBART model)"),XUe.forEach(t),MEr=i(X),y4=n(X,"LI",{});var zUe=s(y4);q3e=n(zUe,"STRONG",{});var $Kt=s(q3e);EEr=r($Kt,"megatron-bert"),$Kt.forEach(t),CEr=r(zUe," \u2014 "),mK=n(zUe,"A",{href:!0});var kKt=s(mK);wEr=r(kKt,"MegatronBertForQuestionAnswering"),kKt.forEach(t),AEr=r(zUe," (Megatron-BERT model)"),zUe.forEach(t),LEr=i(X),x4=n(X,"LI",{});var QUe=s(x4);j3e=n(QUe,"STRONG",{});var SKt=s(j3e);yEr=r(SKt,"mobilebert"),SKt.forEach(t),xEr=r(QUe," \u2014 "),cK=n(QUe,"A",{href:!0});var RKt=s(cK);$Er=r(RKt,"MobileBertForQuestionAnswering"),RKt.forEach(t),kEr=r(QUe," (MobileBERT model)"),QUe.forEach(t),SEr=i(X),$4=n(X,"LI",{});var WUe=s($4);D3e=n(WUe,"STRONG",{});var PKt=s(D3e);REr=r(PKt,"mpnet"),PKt.forEach(t),PEr=r(WUe," \u2014 "),fK=n(WUe,"A",{href:!0});var BKt=s(fK);BEr=r(BKt,"MPNetForQuestionAnswering"),BKt.forEach(t),IEr=r(WUe," (MPNet model)"),WUe.forEach(t),NEr=i(X),k4=n(X,"LI",{});var UUe=s(k4);G3e=n(UUe,"STRONG",{});var IKt=s(G3e);qEr=r(IKt,"mvp"),IKt.forEach(t),jEr=r(UUe," \u2014 "),gK=n(UUe,"A",{href:!0});var NKt=s(gK);DEr=r(NKt,"MvpForQuestionAnswering"),NKt.forEach(t),GEr=r(UUe," (MVP model)"),UUe.forEach(t),OEr=i(X),S4=n(X,"LI",{});var HUe=s(S4);O3e=n(HUe,"STRONG",{});var qKt=s(O3e);VEr=r(qKt,"nezha"),qKt.forEach(t),XEr=r(HUe," \u2014 "),hK=n(HUe,"A",{href:!0});var jKt=s(hK);zEr=r(jKt,"NezhaForQuestionAnswering"),jKt.forEach(t),QEr=r(HUe," (Nezha model)"),HUe.forEach(t),WEr=i(X),R4=n(X,"LI",{});var JUe=s(R4);V3e=n(JUe,"STRONG",{});var DKt=s(V3e);UEr=r(DKt,"nystromformer"),DKt.forEach(t),HEr=r(JUe," \u2014 "),uK=n(JUe,"A",{href:!0});var GKt=s(uK);JEr=r(GKt,"NystromformerForQuestionAnswering"),GKt.forEach(t),YEr=r(JUe," (Nystr\xF6mformer model)"),JUe.forEach(t),ZEr=i(X),P4=n(X,"LI",{});var YUe=s(P4);X3e=n(YUe,"STRONG",{});var OKt=s(X3e);KEr=r(OKt,"opt"),OKt.forEach(t),e4r=r(YUe," \u2014 "),pK=n(YUe,"A",{href:!0});var VKt=s(pK);o4r=r(VKt,"OPTForQuestionAnswering"),VKt.forEach(t),r4r=r(YUe," (OPT model)"),YUe.forEach(t),t4r=i(X),B4=n(X,"LI",{});var ZUe=s(B4);z3e=n(ZUe,"STRONG",{});var XKt=s(z3e);a4r=r(XKt,"qdqbert"),XKt.forEach(t),n4r=r(ZUe," \u2014 "),_K=n(ZUe,"A",{href:!0});var zKt=s(_K);s4r=r(zKt,"QDQBertForQuestionAnswering"),zKt.forEach(t),l4r=r(ZUe," (QDQBert model)"),ZUe.forEach(t),i4r=i(X),I4=n(X,"LI",{});var KUe=s(I4);Q3e=n(KUe,"STRONG",{});var QKt=s(Q3e);d4r=r(QKt,"reformer"),QKt.forEach(t),m4r=r(KUe," \u2014 "),bK=n(KUe,"A",{href:!0});var WKt=s(bK);c4r=r(WKt,"ReformerForQuestionAnswering"),WKt.forEach(t),f4r=r(KUe," (Reformer model)"),KUe.forEach(t),g4r=i(X),N4=n(X,"LI",{});var eHe=s(N4);W3e=n(eHe,"STRONG",{});var UKt=s(W3e);h4r=r(UKt,"rembert"),UKt.forEach(t),u4r=r(eHe," \u2014 "),vK=n(eHe,"A",{href:!0});var HKt=s(vK);p4r=r(HKt,"RemBertForQuestionAnswering"),HKt.forEach(t),_4r=r(eHe," (RemBERT model)"),eHe.forEach(t),b4r=i(X),q4=n(X,"LI",{});var oHe=s(q4);U3e=n(oHe,"STRONG",{});var JKt=s(U3e);v4r=r(JKt,"roberta"),JKt.forEach(t),F4r=r(oHe," \u2014 "),FK=n(oHe,"A",{href:!0});var YKt=s(FK);T4r=r(YKt,"RobertaForQuestionAnswering"),YKt.forEach(t),M4r=r(oHe," (RoBERTa model)"),oHe.forEach(t),E4r=i(X),j4=n(X,"LI",{});var rHe=s(j4);H3e=n(rHe,"STRONG",{});var ZKt=s(H3e);C4r=r(ZKt,"roformer"),ZKt.forEach(t),w4r=r(rHe," \u2014 "),TK=n(rHe,"A",{href:!0});var KKt=s(TK);A4r=r(KKt,"RoFormerForQuestionAnswering"),KKt.forEach(t),L4r=r(rHe," (RoFormer model)"),rHe.forEach(t),y4r=i(X),D4=n(X,"LI",{});var tHe=s(D4);J3e=n(tHe,"STRONG",{});var eea=s(J3e);x4r=r(eea,"splinter"),eea.forEach(t),$4r=r(tHe," \u2014 "),MK=n(tHe,"A",{href:!0});var oea=s(MK);k4r=r(oea,"SplinterForQuestionAnswering"),oea.forEach(t),S4r=r(tHe," (Splinter model)"),tHe.forEach(t),R4r=i(X),G4=n(X,"LI",{});var aHe=s(G4);Y3e=n(aHe,"STRONG",{});var rea=s(Y3e);P4r=r(rea,"squeezebert"),rea.forEach(t),B4r=r(aHe," \u2014 "),EK=n(aHe,"A",{href:!0});var tea=s(EK);I4r=r(tea,"SqueezeBertForQuestionAnswering"),tea.forEach(t),N4r=r(aHe," (SqueezeBERT model)"),aHe.forEach(t),q4r=i(X),O4=n(X,"LI",{});var nHe=s(O4);Z3e=n(nHe,"STRONG",{});var aea=s(Z3e);j4r=r(aea,"xlm"),aea.forEach(t),D4r=r(nHe," \u2014 "),CK=n(nHe,"A",{href:!0});var nea=s(CK);G4r=r(nea,"XLMForQuestionAnsweringSimple"),nea.forEach(t),O4r=r(nHe," (XLM model)"),nHe.forEach(t),V4r=i(X),V4=n(X,"LI",{});var sHe=s(V4);K3e=n(sHe,"STRONG",{});var sea=s(K3e);X4r=r(sea,"xlm-roberta"),sea.forEach(t),z4r=r(sHe," \u2014 "),wK=n(sHe,"A",{href:!0});var lea=s(wK);Q4r=r(lea,"XLMRobertaForQuestionAnswering"),lea.forEach(t),W4r=r(sHe," (XLM-RoBERTa model)"),sHe.forEach(t),U4r=i(X),X4=n(X,"LI",{});var lHe=s(X4);e5e=n(lHe,"STRONG",{});var iea=s(e5e);H4r=r(iea,"xlm-roberta-xl"),iea.forEach(t),J4r=r(lHe," \u2014 "),AK=n(lHe,"A",{href:!0});var dea=s(AK);Y4r=r(dea,"XLMRobertaXLForQuestionAnswering"),dea.forEach(t),Z4r=r(lHe," (XLM-RoBERTa-XL model)"),lHe.forEach(t),K4r=i(X),z4=n(X,"LI",{});var iHe=s(z4);o5e=n(iHe,"STRONG",{});var mea=s(o5e);eCr=r(mea,"xlnet"),mea.forEach(t),oCr=r(iHe," \u2014 "),LK=n(iHe,"A",{href:!0});var cea=s(LK);rCr=r(cea,"XLNetForQuestionAnsweringSimple"),cea.forEach(t),tCr=r(iHe," (XLNet model)"),iHe.forEach(t),aCr=i(X),Q4=n(X,"LI",{});var dHe=s(Q4);r5e=n(dHe,"STRONG",{});var fea=s(r5e);nCr=r(fea,"yoso"),fea.forEach(t),sCr=r(dHe," \u2014 "),yK=n(dHe,"A",{href:!0});var gea=s(yK);lCr=r(gea,"YosoForQuestionAnswering"),gea.forEach(t),iCr=r(dHe," (YOSO model)"),dHe.forEach(t),X.forEach(t),dCr=i(Ia),W4=n(Ia,"P",{});var mHe=s(W4);mCr=r(mHe,"The model is set in evaluation mode by default using "),t5e=n(mHe,"CODE",{});var hea=s(t5e);cCr=r(hea,"model.eval()"),hea.forEach(t),fCr=r(mHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a5e=n(mHe,"CODE",{});var uea=s(a5e);gCr=r(uea,"model.train()"),uea.forEach(t),mHe.forEach(t),hCr=i(Ia),T(U4.$$.fragment,Ia),Ia.forEach(t),Wl.forEach(t),Vto=i(c),dm=n(c,"H2",{class:!0});var iso=s(dm);H4=n(iso,"A",{id:!0,class:!0,href:!0});var pea=s(H4);n5e=n(pea,"SPAN",{});var _ea=s(n5e);T(Rk.$$.fragment,_ea),_ea.forEach(t),pea.forEach(t),uCr=i(iso),s5e=n(iso,"SPAN",{});var bea=s(s5e);pCr=r(bea,"AutoModelForTableQuestionAnswering"),bea.forEach(t),iso.forEach(t),Xto=i(c),Wo=n(c,"DIV",{class:!0});var Ul=s(Wo);T(Pk.$$.fragment,Ul),_Cr=i(Ul),mm=n(Ul,"P",{});var pme=s(mm);bCr=r(pme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),xK=n(pme,"A",{href:!0});var vea=s(xK);vCr=r(vea,"from_pretrained()"),vea.forEach(t),FCr=r(pme," class method or the "),$K=n(pme,"A",{href:!0});var Fea=s($K);TCr=r(Fea,"from_config()"),Fea.forEach(t),MCr=r(pme,` class
method.`),pme.forEach(t),ECr=i(Ul),Bk=n(Ul,"P",{});var dso=s(Bk);CCr=r(dso,"This class cannot be instantiated directly using "),l5e=n(dso,"CODE",{});var Tea=s(l5e);wCr=r(Tea,"__init__()"),Tea.forEach(t),ACr=r(dso," (throws an error)."),dso.forEach(t),LCr=i(Ul),St=n(Ul,"DIV",{class:!0});var _9=s(St);T(Ik.$$.fragment,_9),yCr=i(_9),i5e=n(_9,"P",{});var Mea=s(i5e);xCr=r(Mea,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Mea.forEach(t),$Cr=i(_9),cm=n(_9,"P",{});var _me=s(cm);kCr=r(_me,`Note:
Loading a model from its configuration file does `),d5e=n(_me,"STRONG",{});var Eea=s(d5e);SCr=r(Eea,"not"),Eea.forEach(t),RCr=r(_me,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(_me,"A",{href:!0});var Cea=s(kK);PCr=r(Cea,"from_pretrained()"),Cea.forEach(t),BCr=r(_me," to load the model weights."),_me.forEach(t),ICr=i(_9),T(J4.$$.fragment,_9),_9.forEach(t),NCr=i(Ul),co=n(Ul,"DIV",{class:!0});var Na=s(co);T(Nk.$$.fragment,Na),qCr=i(Na),m5e=n(Na,"P",{});var wea=s(m5e);jCr=r(wea,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),wea.forEach(t),DCr=i(Na),pn=n(Na,"P",{});var b9=s(pn);GCr=r(b9,"The model class to instantiate is selected based on the "),c5e=n(b9,"CODE",{});var Aea=s(c5e);OCr=r(Aea,"model_type"),Aea.forEach(t),VCr=r(b9,` property of the config object (either
passed as an argument or loaded from `),f5e=n(b9,"CODE",{});var Lea=s(f5e);XCr=r(Lea,"pretrained_model_name_or_path"),Lea.forEach(t),zCr=r(b9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=n(b9,"CODE",{});var yea=s(g5e);QCr=r(yea,"pretrained_model_name_or_path"),yea.forEach(t),WCr=r(b9,":"),b9.forEach(t),UCr=i(Na),h5e=n(Na,"UL",{});var xea=s(h5e);Y4=n(xea,"LI",{});var cHe=s(Y4);u5e=n(cHe,"STRONG",{});var $ea=s(u5e);HCr=r($ea,"tapas"),$ea.forEach(t),JCr=r(cHe," \u2014 "),SK=n(cHe,"A",{href:!0});var kea=s(SK);YCr=r(kea,"TapasForQuestionAnswering"),kea.forEach(t),ZCr=r(cHe," (TAPAS model)"),cHe.forEach(t),xea.forEach(t),KCr=i(Na),Z4=n(Na,"P",{});var fHe=s(Z4);e3r=r(fHe,"The model is set in evaluation mode by default using "),p5e=n(fHe,"CODE",{});var Sea=s(p5e);o3r=r(Sea,"model.eval()"),Sea.forEach(t),r3r=r(fHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_5e=n(fHe,"CODE",{});var Rea=s(_5e);t3r=r(Rea,"model.train()"),Rea.forEach(t),fHe.forEach(t),a3r=i(Na),T(K4.$$.fragment,Na),Na.forEach(t),Ul.forEach(t),zto=i(c),fm=n(c,"H2",{class:!0});var mso=s(fm);eC=n(mso,"A",{id:!0,class:!0,href:!0});var Pea=s(eC);b5e=n(Pea,"SPAN",{});var Bea=s(b5e);T(qk.$$.fragment,Bea),Bea.forEach(t),Pea.forEach(t),n3r=i(mso),v5e=n(mso,"SPAN",{});var Iea=s(v5e);s3r=r(Iea,"AutoModelForDocumentQuestionAnswering"),Iea.forEach(t),mso.forEach(t),Qto=i(c),Uo=n(c,"DIV",{class:!0});var Hl=s(Uo);T(jk.$$.fragment,Hl),l3r=i(Hl),gm=n(Hl,"P",{});var bme=s(gm);i3r=r(bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),RK=n(bme,"A",{href:!0});var Nea=s(RK);d3r=r(Nea,"from_pretrained()"),Nea.forEach(t),m3r=r(bme," class method or the "),PK=n(bme,"A",{href:!0});var qea=s(PK);c3r=r(qea,"from_config()"),qea.forEach(t),f3r=r(bme,` class
method.`),bme.forEach(t),g3r=i(Hl),Dk=n(Hl,"P",{});var cso=s(Dk);h3r=r(cso,"This class cannot be instantiated directly using "),F5e=n(cso,"CODE",{});var jea=s(F5e);u3r=r(jea,"__init__()"),jea.forEach(t),p3r=r(cso," (throws an error)."),cso.forEach(t),_3r=i(Hl),Rt=n(Hl,"DIV",{class:!0});var v9=s(Rt);T(Gk.$$.fragment,v9),b3r=i(v9),T5e=n(v9,"P",{});var Dea=s(T5e);v3r=r(Dea,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Dea.forEach(t),F3r=i(v9),hm=n(v9,"P",{});var vme=s(hm);T3r=r(vme,`Note:
Loading a model from its configuration file does `),M5e=n(vme,"STRONG",{});var Gea=s(M5e);M3r=r(Gea,"not"),Gea.forEach(t),E3r=r(vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),BK=n(vme,"A",{href:!0});var Oea=s(BK);C3r=r(Oea,"from_pretrained()"),Oea.forEach(t),w3r=r(vme," to load the model weights."),vme.forEach(t),A3r=i(v9),T(oC.$$.fragment,v9),v9.forEach(t),L3r=i(Hl),fo=n(Hl,"DIV",{class:!0});var qa=s(fo);T(Ok.$$.fragment,qa),y3r=i(qa),E5e=n(qa,"P",{});var Vea=s(E5e);x3r=r(Vea,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Vea.forEach(t),$3r=i(qa),_n=n(qa,"P",{});var F9=s(_n);k3r=r(F9,"The model class to instantiate is selected based on the "),C5e=n(F9,"CODE",{});var Xea=s(C5e);S3r=r(Xea,"model_type"),Xea.forEach(t),R3r=r(F9,` property of the config object (either
passed as an argument or loaded from `),w5e=n(F9,"CODE",{});var zea=s(w5e);P3r=r(zea,"pretrained_model_name_or_path"),zea.forEach(t),B3r=r(F9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A5e=n(F9,"CODE",{});var Qea=s(A5e);I3r=r(Qea,"pretrained_model_name_or_path"),Qea.forEach(t),N3r=r(F9,":"),F9.forEach(t),q3r=i(qa),um=n(qa,"UL",{});var Fme=s(um);rC=n(Fme,"LI",{});var gHe=s(rC);L5e=n(gHe,"STRONG",{});var Wea=s(L5e);j3r=r(Wea,"layoutlm"),Wea.forEach(t),D3r=r(gHe," \u2014 "),IK=n(gHe,"A",{href:!0});var Uea=s(IK);G3r=r(Uea,"LayoutLMForQuestionAnswering"),Uea.forEach(t),O3r=r(gHe," (LayoutLM model)"),gHe.forEach(t),V3r=i(Fme),tC=n(Fme,"LI",{});var hHe=s(tC);y5e=n(hHe,"STRONG",{});var Hea=s(y5e);X3r=r(Hea,"layoutlmv2"),Hea.forEach(t),z3r=r(hHe," \u2014 "),NK=n(hHe,"A",{href:!0});var Jea=s(NK);Q3r=r(Jea,"LayoutLMv2ForQuestionAnswering"),Jea.forEach(t),W3r=r(hHe," (LayoutLMv2 model)"),hHe.forEach(t),U3r=i(Fme),aC=n(Fme,"LI",{});var uHe=s(aC);x5e=n(uHe,"STRONG",{});var Yea=s(x5e);H3r=r(Yea,"layoutlmv3"),Yea.forEach(t),J3r=r(uHe," \u2014 "),qK=n(uHe,"A",{href:!0});var Zea=s(qK);Y3r=r(Zea,"LayoutLMv3ForQuestionAnswering"),Zea.forEach(t),Z3r=r(uHe," (LayoutLMv3 model)"),uHe.forEach(t),Fme.forEach(t),K3r=i(qa),nC=n(qa,"P",{});var pHe=s(nC);e5r=r(pHe,"The model is set in evaluation mode by default using "),$5e=n(pHe,"CODE",{});var Kea=s($5e);o5r=r(Kea,"model.eval()"),Kea.forEach(t),r5r=r(pHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k5e=n(pHe,"CODE",{});var eoa=s(k5e);t5r=r(eoa,"model.train()"),eoa.forEach(t),pHe.forEach(t),a5r=i(qa),T(sC.$$.fragment,qa),qa.forEach(t),Hl.forEach(t),Wto=i(c),pm=n(c,"H2",{class:!0});var fso=s(pm);lC=n(fso,"A",{id:!0,class:!0,href:!0});var ooa=s(lC);S5e=n(ooa,"SPAN",{});var roa=s(S5e);T(Vk.$$.fragment,roa),roa.forEach(t),ooa.forEach(t),n5r=i(fso),R5e=n(fso,"SPAN",{});var toa=s(R5e);s5r=r(toa,"AutoModelForImageClassification"),toa.forEach(t),fso.forEach(t),Uto=i(c),Ho=n(c,"DIV",{class:!0});var Jl=s(Ho);T(Xk.$$.fragment,Jl),l5r=i(Jl),_m=n(Jl,"P",{});var Tme=s(_m);i5r=r(Tme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jK=n(Tme,"A",{href:!0});var aoa=s(jK);d5r=r(aoa,"from_pretrained()"),aoa.forEach(t),m5r=r(Tme," class method or the "),DK=n(Tme,"A",{href:!0});var noa=s(DK);c5r=r(noa,"from_config()"),noa.forEach(t),f5r=r(Tme,` class
method.`),Tme.forEach(t),g5r=i(Jl),zk=n(Jl,"P",{});var gso=s(zk);h5r=r(gso,"This class cannot be instantiated directly using "),P5e=n(gso,"CODE",{});var soa=s(P5e);u5r=r(soa,"__init__()"),soa.forEach(t),p5r=r(gso," (throws an error)."),gso.forEach(t),_5r=i(Jl),Pt=n(Jl,"DIV",{class:!0});var T9=s(Pt);T(Qk.$$.fragment,T9),b5r=i(T9),B5e=n(T9,"P",{});var loa=s(B5e);v5r=r(loa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),loa.forEach(t),F5r=i(T9),bm=n(T9,"P",{});var Mme=s(bm);T5r=r(Mme,`Note:
Loading a model from its configuration file does `),I5e=n(Mme,"STRONG",{});var ioa=s(I5e);M5r=r(ioa,"not"),ioa.forEach(t),E5r=r(Mme,` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=n(Mme,"A",{href:!0});var doa=s(GK);C5r=r(doa,"from_pretrained()"),doa.forEach(t),w5r=r(Mme," to load the model weights."),Mme.forEach(t),A5r=i(T9),T(iC.$$.fragment,T9),T9.forEach(t),L5r=i(Jl),go=n(Jl,"DIV",{class:!0});var ja=s(go);T(Wk.$$.fragment,ja),y5r=i(ja),N5e=n(ja,"P",{});var moa=s(N5e);x5r=r(moa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),moa.forEach(t),$5r=i(ja),bn=n(ja,"P",{});var M9=s(bn);k5r=r(M9,"The model class to instantiate is selected based on the "),q5e=n(M9,"CODE",{});var coa=s(q5e);S5r=r(coa,"model_type"),coa.forEach(t),R5r=r(M9,` property of the config object (either
passed as an argument or loaded from `),j5e=n(M9,"CODE",{});var foa=s(j5e);P5r=r(foa,"pretrained_model_name_or_path"),foa.forEach(t),B5r=r(M9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D5e=n(M9,"CODE",{});var goa=s(D5e);I5r=r(goa,"pretrained_model_name_or_path"),goa.forEach(t),N5r=r(M9,":"),M9.forEach(t),q5r=i(ja),be=n(ja,"UL",{});var Fe=s(be);dC=n(Fe,"LI",{});var _He=s(dC);G5e=n(_He,"STRONG",{});var hoa=s(G5e);j5r=r(hoa,"beit"),hoa.forEach(t),D5r=r(_He," \u2014 "),OK=n(_He,"A",{href:!0});var uoa=s(OK);G5r=r(uoa,"BeitForImageClassification"),uoa.forEach(t),O5r=r(_He," (BEiT model)"),_He.forEach(t),V5r=i(Fe),mC=n(Fe,"LI",{});var bHe=s(mC);O5e=n(bHe,"STRONG",{});var poa=s(O5e);X5r=r(poa,"convnext"),poa.forEach(t),z5r=r(bHe," \u2014 "),VK=n(bHe,"A",{href:!0});var _oa=s(VK);Q5r=r(_oa,"ConvNextForImageClassification"),_oa.forEach(t),W5r=r(bHe," (ConvNeXT model)"),bHe.forEach(t),U5r=i(Fe),cC=n(Fe,"LI",{});var vHe=s(cC);V5e=n(vHe,"STRONG",{});var boa=s(V5e);H5r=r(boa,"cvt"),boa.forEach(t),J5r=r(vHe," \u2014 "),XK=n(vHe,"A",{href:!0});var voa=s(XK);Y5r=r(voa,"CvtForImageClassification"),voa.forEach(t),Z5r=r(vHe," (CvT model)"),vHe.forEach(t),K5r=i(Fe),fC=n(Fe,"LI",{});var FHe=s(fC);X5e=n(FHe,"STRONG",{});var Foa=s(X5e);e0r=r(Foa,"data2vec-vision"),Foa.forEach(t),o0r=r(FHe," \u2014 "),zK=n(FHe,"A",{href:!0});var Toa=s(zK);r0r=r(Toa,"Data2VecVisionForImageClassification"),Toa.forEach(t),t0r=r(FHe," (Data2VecVision model)"),FHe.forEach(t),a0r=i(Fe),xl=n(Fe,"LI",{});var gN=s(xl);z5e=n(gN,"STRONG",{});var Moa=s(z5e);n0r=r(Moa,"deit"),Moa.forEach(t),s0r=r(gN," \u2014 "),QK=n(gN,"A",{href:!0});var Eoa=s(QK);l0r=r(Eoa,"DeiTForImageClassification"),Eoa.forEach(t),i0r=r(gN," or "),WK=n(gN,"A",{href:!0});var Coa=s(WK);d0r=r(Coa,"DeiTForImageClassificationWithTeacher"),Coa.forEach(t),m0r=r(gN," (DeiT model)"),gN.forEach(t),c0r=i(Fe),gC=n(Fe,"LI",{});var THe=s(gC);Q5e=n(THe,"STRONG",{});var woa=s(Q5e);f0r=r(woa,"imagegpt"),woa.forEach(t),g0r=r(THe," \u2014 "),UK=n(THe,"A",{href:!0});var Aoa=s(UK);h0r=r(Aoa,"ImageGPTForImageClassification"),Aoa.forEach(t),u0r=r(THe," (ImageGPT model)"),THe.forEach(t),p0r=i(Fe),$l=n(Fe,"LI",{});var hN=s($l);W5e=n(hN,"STRONG",{});var Loa=s(W5e);_0r=r(Loa,"levit"),Loa.forEach(t),b0r=r(hN," \u2014 "),HK=n(hN,"A",{href:!0});var yoa=s(HK);v0r=r(yoa,"LevitForImageClassification"),yoa.forEach(t),F0r=r(hN," or "),JK=n(hN,"A",{href:!0});var xoa=s(JK);T0r=r(xoa,"LevitForImageClassificationWithTeacher"),xoa.forEach(t),M0r=r(hN," (LeViT model)"),hN.forEach(t),E0r=i(Fe),hC=n(Fe,"LI",{});var MHe=s(hC);U5e=n(MHe,"STRONG",{});var $oa=s(U5e);C0r=r($oa,"mobilevit"),$oa.forEach(t),w0r=r(MHe," \u2014 "),YK=n(MHe,"A",{href:!0});var koa=s(YK);A0r=r(koa,"MobileViTForImageClassification"),koa.forEach(t),L0r=r(MHe," (MobileViT model)"),MHe.forEach(t),y0r=i(Fe),Bt=n(Fe,"LI",{});var Of=s(Bt);H5e=n(Of,"STRONG",{});var Soa=s(H5e);x0r=r(Soa,"perceiver"),Soa.forEach(t),$0r=r(Of," \u2014 "),ZK=n(Of,"A",{href:!0});var Roa=s(ZK);k0r=r(Roa,"PerceiverForImageClassificationLearned"),Roa.forEach(t),S0r=r(Of," or "),KK=n(Of,"A",{href:!0});var Poa=s(KK);R0r=r(Poa,"PerceiverForImageClassificationFourier"),Poa.forEach(t),P0r=r(Of," or "),eee=n(Of,"A",{href:!0});var Boa=s(eee);B0r=r(Boa,"PerceiverForImageClassificationConvProcessing"),Boa.forEach(t),I0r=r(Of," (Perceiver model)"),Of.forEach(t),N0r=i(Fe),uC=n(Fe,"LI",{});var EHe=s(uC);J5e=n(EHe,"STRONG",{});var Ioa=s(J5e);q0r=r(Ioa,"poolformer"),Ioa.forEach(t),j0r=r(EHe," \u2014 "),oee=n(EHe,"A",{href:!0});var Noa=s(oee);D0r=r(Noa,"PoolFormerForImageClassification"),Noa.forEach(t),G0r=r(EHe," (PoolFormer model)"),EHe.forEach(t),O0r=i(Fe),pC=n(Fe,"LI",{});var CHe=s(pC);Y5e=n(CHe,"STRONG",{});var qoa=s(Y5e);V0r=r(qoa,"regnet"),qoa.forEach(t),X0r=r(CHe," \u2014 "),ree=n(CHe,"A",{href:!0});var joa=s(ree);z0r=r(joa,"RegNetForImageClassification"),joa.forEach(t),Q0r=r(CHe," (RegNet model)"),CHe.forEach(t),W0r=i(Fe),_C=n(Fe,"LI",{});var wHe=s(_C);Z5e=n(wHe,"STRONG",{});var Doa=s(Z5e);U0r=r(Doa,"resnet"),Doa.forEach(t),H0r=r(wHe," \u2014 "),tee=n(wHe,"A",{href:!0});var Goa=s(tee);J0r=r(Goa,"ResNetForImageClassification"),Goa.forEach(t),Y0r=r(wHe," (ResNet model)"),wHe.forEach(t),Z0r=i(Fe),bC=n(Fe,"LI",{});var AHe=s(bC);K5e=n(AHe,"STRONG",{});var Ooa=s(K5e);K0r=r(Ooa,"segformer"),Ooa.forEach(t),ewr=r(AHe," \u2014 "),aee=n(AHe,"A",{href:!0});var Voa=s(aee);owr=r(Voa,"SegformerForImageClassification"),Voa.forEach(t),rwr=r(AHe," (SegFormer model)"),AHe.forEach(t),twr=i(Fe),vC=n(Fe,"LI",{});var LHe=s(vC);e0e=n(LHe,"STRONG",{});var Xoa=s(e0e);awr=r(Xoa,"swin"),Xoa.forEach(t),nwr=r(LHe," \u2014 "),nee=n(LHe,"A",{href:!0});var zoa=s(nee);swr=r(zoa,"SwinForImageClassification"),zoa.forEach(t),lwr=r(LHe," (Swin Transformer model)"),LHe.forEach(t),iwr=i(Fe),FC=n(Fe,"LI",{});var yHe=s(FC);o0e=n(yHe,"STRONG",{});var Qoa=s(o0e);dwr=r(Qoa,"swinv2"),Qoa.forEach(t),mwr=r(yHe," \u2014 "),see=n(yHe,"A",{href:!0});var Woa=s(see);cwr=r(Woa,"Swinv2ForImageClassification"),Woa.forEach(t),fwr=r(yHe," (Swin Transformer V2 model)"),yHe.forEach(t),gwr=i(Fe),TC=n(Fe,"LI",{});var xHe=s(TC);r0e=n(xHe,"STRONG",{});var Uoa=s(r0e);hwr=r(Uoa,"van"),Uoa.forEach(t),uwr=r(xHe," \u2014 "),lee=n(xHe,"A",{href:!0});var Hoa=s(lee);pwr=r(Hoa,"VanForImageClassification"),Hoa.forEach(t),_wr=r(xHe," (VAN model)"),xHe.forEach(t),bwr=i(Fe),MC=n(Fe,"LI",{});var $He=s(MC);t0e=n($He,"STRONG",{});var Joa=s(t0e);vwr=r(Joa,"vit"),Joa.forEach(t),Fwr=r($He," \u2014 "),iee=n($He,"A",{href:!0});var Yoa=s(iee);Twr=r(Yoa,"ViTForImageClassification"),Yoa.forEach(t),Mwr=r($He," (ViT model)"),$He.forEach(t),Ewr=i(Fe),EC=n(Fe,"LI",{});var kHe=s(EC);a0e=n(kHe,"STRONG",{});var Zoa=s(a0e);Cwr=r(Zoa,"vit_msn"),Zoa.forEach(t),wwr=r(kHe," \u2014 "),dee=n(kHe,"A",{href:!0});var Koa=s(dee);Awr=r(Koa,"ViTMSNForImageClassification"),Koa.forEach(t),Lwr=r(kHe," (ViTMSN model)"),kHe.forEach(t),Fe.forEach(t),ywr=i(ja),CC=n(ja,"P",{});var SHe=s(CC);xwr=r(SHe,"The model is set in evaluation mode by default using "),n0e=n(SHe,"CODE",{});var era=s(n0e);$wr=r(era,"model.eval()"),era.forEach(t),kwr=r(SHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s0e=n(SHe,"CODE",{});var ora=s(s0e);Swr=r(ora,"model.train()"),ora.forEach(t),SHe.forEach(t),Rwr=i(ja),T(wC.$$.fragment,ja),ja.forEach(t),Jl.forEach(t),Hto=i(c),vm=n(c,"H2",{class:!0});var hso=s(vm);AC=n(hso,"A",{id:!0,class:!0,href:!0});var rra=s(AC);l0e=n(rra,"SPAN",{});var tra=s(l0e);T(Uk.$$.fragment,tra),tra.forEach(t),rra.forEach(t),Pwr=i(hso),i0e=n(hso,"SPAN",{});var ara=s(i0e);Bwr=r(ara,"AutoModelForVideoClassification"),ara.forEach(t),hso.forEach(t),Jto=i(c),Jo=n(c,"DIV",{class:!0});var Yl=s(Jo);T(Hk.$$.fragment,Yl),Iwr=i(Yl),Fm=n(Yl,"P",{});var Eme=s(Fm);Nwr=r(Eme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),mee=n(Eme,"A",{href:!0});var nra=s(mee);qwr=r(nra,"from_pretrained()"),nra.forEach(t),jwr=r(Eme," class method or the "),cee=n(Eme,"A",{href:!0});var sra=s(cee);Dwr=r(sra,"from_config()"),sra.forEach(t),Gwr=r(Eme,` class
method.`),Eme.forEach(t),Owr=i(Yl),Jk=n(Yl,"P",{});var uso=s(Jk);Vwr=r(uso,"This class cannot be instantiated directly using "),d0e=n(uso,"CODE",{});var lra=s(d0e);Xwr=r(lra,"__init__()"),lra.forEach(t),zwr=r(uso," (throws an error)."),uso.forEach(t),Qwr=i(Yl),It=n(Yl,"DIV",{class:!0});var E9=s(It);T(Yk.$$.fragment,E9),Wwr=i(E9),m0e=n(E9,"P",{});var ira=s(m0e);Uwr=r(ira,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),ira.forEach(t),Hwr=i(E9),Tm=n(E9,"P",{});var Cme=s(Tm);Jwr=r(Cme,`Note:
Loading a model from its configuration file does `),c0e=n(Cme,"STRONG",{});var dra=s(c0e);Ywr=r(dra,"not"),dra.forEach(t),Zwr=r(Cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),fee=n(Cme,"A",{href:!0});var mra=s(fee);Kwr=r(mra,"from_pretrained()"),mra.forEach(t),eAr=r(Cme," to load the model weights."),Cme.forEach(t),oAr=i(E9),T(LC.$$.fragment,E9),E9.forEach(t),rAr=i(Yl),ho=n(Yl,"DIV",{class:!0});var Da=s(ho);T(Zk.$$.fragment,Da),tAr=i(Da),f0e=n(Da,"P",{});var cra=s(f0e);aAr=r(cra,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),cra.forEach(t),nAr=i(Da),vn=n(Da,"P",{});var C9=s(vn);sAr=r(C9,"The model class to instantiate is selected based on the "),g0e=n(C9,"CODE",{});var fra=s(g0e);lAr=r(fra,"model_type"),fra.forEach(t),iAr=r(C9,` property of the config object (either
passed as an argument or loaded from `),h0e=n(C9,"CODE",{});var gra=s(h0e);dAr=r(gra,"pretrained_model_name_or_path"),gra.forEach(t),mAr=r(C9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u0e=n(C9,"CODE",{});var hra=s(u0e);cAr=r(hra,"pretrained_model_name_or_path"),hra.forEach(t),fAr=r(C9,":"),C9.forEach(t),gAr=i(Da),p0e=n(Da,"UL",{});var ura=s(p0e);yC=n(ura,"LI",{});var RHe=s(yC);_0e=n(RHe,"STRONG",{});var pra=s(_0e);hAr=r(pra,"videomae"),pra.forEach(t),uAr=r(RHe," \u2014 "),gee=n(RHe,"A",{href:!0});var _ra=s(gee);pAr=r(_ra,"VideoMAEForVideoClassification"),_ra.forEach(t),_Ar=r(RHe," (VideoMAE model)"),RHe.forEach(t),ura.forEach(t),bAr=i(Da),xC=n(Da,"P",{});var PHe=s(xC);vAr=r(PHe,"The model is set in evaluation mode by default using "),b0e=n(PHe,"CODE",{});var bra=s(b0e);FAr=r(bra,"model.eval()"),bra.forEach(t),TAr=r(PHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v0e=n(PHe,"CODE",{});var vra=s(v0e);MAr=r(vra,"model.train()"),vra.forEach(t),PHe.forEach(t),EAr=i(Da),T($C.$$.fragment,Da),Da.forEach(t),Yl.forEach(t),Yto=i(c),Mm=n(c,"H2",{class:!0});var pso=s(Mm);kC=n(pso,"A",{id:!0,class:!0,href:!0});var Fra=s(kC);F0e=n(Fra,"SPAN",{});var Tra=s(F0e);T(Kk.$$.fragment,Tra),Tra.forEach(t),Fra.forEach(t),CAr=i(pso),T0e=n(pso,"SPAN",{});var Mra=s(T0e);wAr=r(Mra,"AutoModelForVision2Seq"),Mra.forEach(t),pso.forEach(t),Zto=i(c),Yo=n(c,"DIV",{class:!0});var Zl=s(Yo);T(eS.$$.fragment,Zl),AAr=i(Zl),Em=n(Zl,"P",{});var wme=s(Em);LAr=r(wme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hee=n(wme,"A",{href:!0});var Era=s(hee);yAr=r(Era,"from_pretrained()"),Era.forEach(t),xAr=r(wme," class method or the "),uee=n(wme,"A",{href:!0});var Cra=s(uee);$Ar=r(Cra,"from_config()"),Cra.forEach(t),kAr=r(wme,` class
method.`),wme.forEach(t),SAr=i(Zl),oS=n(Zl,"P",{});var _so=s(oS);RAr=r(_so,"This class cannot be instantiated directly using "),M0e=n(_so,"CODE",{});var wra=s(M0e);PAr=r(wra,"__init__()"),wra.forEach(t),BAr=r(_so," (throws an error)."),_so.forEach(t),IAr=i(Zl),Nt=n(Zl,"DIV",{class:!0});var w9=s(Nt);T(rS.$$.fragment,w9),NAr=i(w9),E0e=n(w9,"P",{});var Ara=s(E0e);qAr=r(Ara,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ara.forEach(t),jAr=i(w9),Cm=n(w9,"P",{});var Ame=s(Cm);DAr=r(Ame,`Note:
Loading a model from its configuration file does `),C0e=n(Ame,"STRONG",{});var Lra=s(C0e);GAr=r(Lra,"not"),Lra.forEach(t),OAr=r(Ame,` load the model weights. It only affects the
model\u2019s configuration. Use `),pee=n(Ame,"A",{href:!0});var yra=s(pee);VAr=r(yra,"from_pretrained()"),yra.forEach(t),XAr=r(Ame," to load the model weights."),Ame.forEach(t),zAr=i(w9),T(SC.$$.fragment,w9),w9.forEach(t),QAr=i(Zl),uo=n(Zl,"DIV",{class:!0});var Ga=s(uo);T(tS.$$.fragment,Ga),WAr=i(Ga),w0e=n(Ga,"P",{});var xra=s(w0e);UAr=r(xra,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xra.forEach(t),HAr=i(Ga),Fn=n(Ga,"P",{});var A9=s(Fn);JAr=r(A9,"The model class to instantiate is selected based on the "),A0e=n(A9,"CODE",{});var $ra=s(A0e);YAr=r($ra,"model_type"),$ra.forEach(t),ZAr=r(A9,` property of the config object (either
passed as an argument or loaded from `),L0e=n(A9,"CODE",{});var kra=s(L0e);KAr=r(kra,"pretrained_model_name_or_path"),kra.forEach(t),e6r=r(A9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y0e=n(A9,"CODE",{});var Sra=s(y0e);o6r=r(Sra,"pretrained_model_name_or_path"),Sra.forEach(t),r6r=r(A9,":"),A9.forEach(t),t6r=i(Ga),x0e=n(Ga,"UL",{});var Rra=s(x0e);RC=n(Rra,"LI",{});var BHe=s(RC);$0e=n(BHe,"STRONG",{});var Pra=s($0e);a6r=r(Pra,"vision-encoder-decoder"),Pra.forEach(t),n6r=r(BHe," \u2014 "),_ee=n(BHe,"A",{href:!0});var Bra=s(_ee);s6r=r(Bra,"VisionEncoderDecoderModel"),Bra.forEach(t),l6r=r(BHe," (Vision Encoder decoder model)"),BHe.forEach(t),Rra.forEach(t),i6r=i(Ga),PC=n(Ga,"P",{});var IHe=s(PC);d6r=r(IHe,"The model is set in evaluation mode by default using "),k0e=n(IHe,"CODE",{});var Ira=s(k0e);m6r=r(Ira,"model.eval()"),Ira.forEach(t),c6r=r(IHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=n(IHe,"CODE",{});var Nra=s(S0e);f6r=r(Nra,"model.train()"),Nra.forEach(t),IHe.forEach(t),g6r=i(Ga),T(BC.$$.fragment,Ga),Ga.forEach(t),Zl.forEach(t),Kto=i(c),wm=n(c,"H2",{class:!0});var bso=s(wm);IC=n(bso,"A",{id:!0,class:!0,href:!0});var qra=s(IC);R0e=n(qra,"SPAN",{});var jra=s(R0e);T(aS.$$.fragment,jra),jra.forEach(t),qra.forEach(t),h6r=i(bso),P0e=n(bso,"SPAN",{});var Dra=s(P0e);u6r=r(Dra,"AutoModelForVisualQuestionAnswering"),Dra.forEach(t),bso.forEach(t),eao=i(c),Zo=n(c,"DIV",{class:!0});var Kl=s(Zo);T(nS.$$.fragment,Kl),p6r=i(Kl),Am=n(Kl,"P",{});var Lme=s(Am);_6r=r(Lme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),bee=n(Lme,"A",{href:!0});var Gra=s(bee);b6r=r(Gra,"from_pretrained()"),Gra.forEach(t),v6r=r(Lme," class method or the "),vee=n(Lme,"A",{href:!0});var Ora=s(vee);F6r=r(Ora,"from_config()"),Ora.forEach(t),T6r=r(Lme,` class
method.`),Lme.forEach(t),M6r=i(Kl),sS=n(Kl,"P",{});var vso=s(sS);E6r=r(vso,"This class cannot be instantiated directly using "),B0e=n(vso,"CODE",{});var Vra=s(B0e);C6r=r(Vra,"__init__()"),Vra.forEach(t),w6r=r(vso," (throws an error)."),vso.forEach(t),A6r=i(Kl),qt=n(Kl,"DIV",{class:!0});var L9=s(qt);T(lS.$$.fragment,L9),L6r=i(L9),I0e=n(L9,"P",{});var Xra=s(I0e);y6r=r(Xra,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Xra.forEach(t),x6r=i(L9),Lm=n(L9,"P",{});var yme=s(Lm);$6r=r(yme,`Note:
Loading a model from its configuration file does `),N0e=n(yme,"STRONG",{});var zra=s(N0e);k6r=r(zra,"not"),zra.forEach(t),S6r=r(yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fee=n(yme,"A",{href:!0});var Qra=s(Fee);R6r=r(Qra,"from_pretrained()"),Qra.forEach(t),P6r=r(yme," to load the model weights."),yme.forEach(t),B6r=i(L9),T(NC.$$.fragment,L9),L9.forEach(t),I6r=i(Kl),po=n(Kl,"DIV",{class:!0});var Oa=s(po);T(iS.$$.fragment,Oa),N6r=i(Oa),q0e=n(Oa,"P",{});var Wra=s(q0e);q6r=r(Wra,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Wra.forEach(t),j6r=i(Oa),Tn=n(Oa,"P",{});var y9=s(Tn);D6r=r(y9,"The model class to instantiate is selected based on the "),j0e=n(y9,"CODE",{});var Ura=s(j0e);G6r=r(Ura,"model_type"),Ura.forEach(t),O6r=r(y9,` property of the config object (either
passed as an argument or loaded from `),D0e=n(y9,"CODE",{});var Hra=s(D0e);V6r=r(Hra,"pretrained_model_name_or_path"),Hra.forEach(t),X6r=r(y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=n(y9,"CODE",{});var Jra=s(G0e);z6r=r(Jra,"pretrained_model_name_or_path"),Jra.forEach(t),Q6r=r(y9,":"),y9.forEach(t),W6r=i(Oa),O0e=n(Oa,"UL",{});var Yra=s(O0e);qC=n(Yra,"LI",{});var NHe=s(qC);V0e=n(NHe,"STRONG",{});var Zra=s(V0e);U6r=r(Zra,"vilt"),Zra.forEach(t),H6r=r(NHe," \u2014 "),Tee=n(NHe,"A",{href:!0});var Kra=s(Tee);J6r=r(Kra,"ViltForQuestionAnswering"),Kra.forEach(t),Y6r=r(NHe," (ViLT model)"),NHe.forEach(t),Yra.forEach(t),Z6r=i(Oa),jC=n(Oa,"P",{});var qHe=s(jC);K6r=r(qHe,"The model is set in evaluation mode by default using "),X0e=n(qHe,"CODE",{});var eta=s(X0e);e7r=r(eta,"model.eval()"),eta.forEach(t),o7r=r(qHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z0e=n(qHe,"CODE",{});var ota=s(z0e);r7r=r(ota,"model.train()"),ota.forEach(t),qHe.forEach(t),t7r=i(Oa),T(DC.$$.fragment,Oa),Oa.forEach(t),Kl.forEach(t),oao=i(c),ym=n(c,"H2",{class:!0});var Fso=s(ym);GC=n(Fso,"A",{id:!0,class:!0,href:!0});var rta=s(GC);Q0e=n(rta,"SPAN",{});var tta=s(Q0e);T(dS.$$.fragment,tta),tta.forEach(t),rta.forEach(t),a7r=i(Fso),W0e=n(Fso,"SPAN",{});var ata=s(W0e);n7r=r(ata,"AutoModelForAudioClassification"),ata.forEach(t),Fso.forEach(t),rao=i(c),Ko=n(c,"DIV",{class:!0});var ei=s(Ko);T(mS.$$.fragment,ei),s7r=i(ei),xm=n(ei,"P",{});var xme=s(xm);l7r=r(xme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Mee=n(xme,"A",{href:!0});var nta=s(Mee);i7r=r(nta,"from_pretrained()"),nta.forEach(t),d7r=r(xme," class method or the "),Eee=n(xme,"A",{href:!0});var sta=s(Eee);m7r=r(sta,"from_config()"),sta.forEach(t),c7r=r(xme,` class
method.`),xme.forEach(t),f7r=i(ei),cS=n(ei,"P",{});var Tso=s(cS);g7r=r(Tso,"This class cannot be instantiated directly using "),U0e=n(Tso,"CODE",{});var lta=s(U0e);h7r=r(lta,"__init__()"),lta.forEach(t),u7r=r(Tso," (throws an error)."),Tso.forEach(t),p7r=i(ei),jt=n(ei,"DIV",{class:!0});var x9=s(jt);T(fS.$$.fragment,x9),_7r=i(x9),H0e=n(x9,"P",{});var ita=s(H0e);b7r=r(ita,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),ita.forEach(t),v7r=i(x9),$m=n(x9,"P",{});var $me=s($m);F7r=r($me,`Note:
Loading a model from its configuration file does `),J0e=n($me,"STRONG",{});var dta=s(J0e);T7r=r(dta,"not"),dta.forEach(t),M7r=r($me,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cee=n($me,"A",{href:!0});var mta=s(Cee);E7r=r(mta,"from_pretrained()"),mta.forEach(t),C7r=r($me," to load the model weights."),$me.forEach(t),w7r=i(x9),T(OC.$$.fragment,x9),x9.forEach(t),A7r=i(ei),_o=n(ei,"DIV",{class:!0});var Va=s(_o);T(gS.$$.fragment,Va),L7r=i(Va),Y0e=n(Va,"P",{});var cta=s(Y0e);y7r=r(cta,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),cta.forEach(t),x7r=i(Va),Mn=n(Va,"P",{});var $9=s(Mn);$7r=r($9,"The model class to instantiate is selected based on the "),Z0e=n($9,"CODE",{});var fta=s(Z0e);k7r=r(fta,"model_type"),fta.forEach(t),S7r=r($9,` property of the config object (either
passed as an argument or loaded from `),K0e=n($9,"CODE",{});var gta=s(K0e);R7r=r(gta,"pretrained_model_name_or_path"),gta.forEach(t),P7r=r($9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=n($9,"CODE",{});var hta=s(ewe);B7r=r(hta,"pretrained_model_name_or_path"),hta.forEach(t),I7r=r($9,":"),$9.forEach(t),N7r=i(Va),Be=n(Va,"UL",{});var We=s(Be);VC=n(We,"LI",{});var jHe=s(VC);owe=n(jHe,"STRONG",{});var uta=s(owe);q7r=r(uta,"data2vec-audio"),uta.forEach(t),j7r=r(jHe," \u2014 "),wee=n(jHe,"A",{href:!0});var pta=s(wee);D7r=r(pta,"Data2VecAudioForSequenceClassification"),pta.forEach(t),G7r=r(jHe," (Data2VecAudio model)"),jHe.forEach(t),O7r=i(We),XC=n(We,"LI",{});var DHe=s(XC);rwe=n(DHe,"STRONG",{});var _ta=s(rwe);V7r=r(_ta,"hubert"),_ta.forEach(t),X7r=r(DHe," \u2014 "),Aee=n(DHe,"A",{href:!0});var bta=s(Aee);z7r=r(bta,"HubertForSequenceClassification"),bta.forEach(t),Q7r=r(DHe," (Hubert model)"),DHe.forEach(t),W7r=i(We),zC=n(We,"LI",{});var GHe=s(zC);twe=n(GHe,"STRONG",{});var vta=s(twe);U7r=r(vta,"sew"),vta.forEach(t),H7r=r(GHe," \u2014 "),Lee=n(GHe,"A",{href:!0});var Fta=s(Lee);J7r=r(Fta,"SEWForSequenceClassification"),Fta.forEach(t),Y7r=r(GHe," (SEW model)"),GHe.forEach(t),Z7r=i(We),QC=n(We,"LI",{});var OHe=s(QC);awe=n(OHe,"STRONG",{});var Tta=s(awe);K7r=r(Tta,"sew-d"),Tta.forEach(t),e8r=r(OHe," \u2014 "),yee=n(OHe,"A",{href:!0});var Mta=s(yee);o8r=r(Mta,"SEWDForSequenceClassification"),Mta.forEach(t),r8r=r(OHe," (SEW-D model)"),OHe.forEach(t),t8r=i(We),WC=n(We,"LI",{});var VHe=s(WC);nwe=n(VHe,"STRONG",{});var Eta=s(nwe);a8r=r(Eta,"unispeech"),Eta.forEach(t),n8r=r(VHe," \u2014 "),xee=n(VHe,"A",{href:!0});var Cta=s(xee);s8r=r(Cta,"UniSpeechForSequenceClassification"),Cta.forEach(t),l8r=r(VHe," (UniSpeech model)"),VHe.forEach(t),i8r=i(We),UC=n(We,"LI",{});var XHe=s(UC);swe=n(XHe,"STRONG",{});var wta=s(swe);d8r=r(wta,"unispeech-sat"),wta.forEach(t),m8r=r(XHe," \u2014 "),$ee=n(XHe,"A",{href:!0});var Ata=s($ee);c8r=r(Ata,"UniSpeechSatForSequenceClassification"),Ata.forEach(t),f8r=r(XHe," (UniSpeechSat model)"),XHe.forEach(t),g8r=i(We),HC=n(We,"LI",{});var zHe=s(HC);lwe=n(zHe,"STRONG",{});var Lta=s(lwe);h8r=r(Lta,"wav2vec2"),Lta.forEach(t),u8r=r(zHe," \u2014 "),kee=n(zHe,"A",{href:!0});var yta=s(kee);p8r=r(yta,"Wav2Vec2ForSequenceClassification"),yta.forEach(t),_8r=r(zHe," (Wav2Vec2 model)"),zHe.forEach(t),b8r=i(We),JC=n(We,"LI",{});var QHe=s(JC);iwe=n(QHe,"STRONG",{});var xta=s(iwe);v8r=r(xta,"wav2vec2-conformer"),xta.forEach(t),F8r=r(QHe," \u2014 "),See=n(QHe,"A",{href:!0});var $ta=s(See);T8r=r($ta,"Wav2Vec2ConformerForSequenceClassification"),$ta.forEach(t),M8r=r(QHe," (Wav2Vec2-Conformer model)"),QHe.forEach(t),E8r=i(We),YC=n(We,"LI",{});var WHe=s(YC);dwe=n(WHe,"STRONG",{});var kta=s(dwe);C8r=r(kta,"wavlm"),kta.forEach(t),w8r=r(WHe," \u2014 "),Ree=n(WHe,"A",{href:!0});var Sta=s(Ree);A8r=r(Sta,"WavLMForSequenceClassification"),Sta.forEach(t),L8r=r(WHe," (WavLM model)"),WHe.forEach(t),We.forEach(t),y8r=i(Va),ZC=n(Va,"P",{});var UHe=s(ZC);x8r=r(UHe,"The model is set in evaluation mode by default using "),mwe=n(UHe,"CODE",{});var Rta=s(mwe);$8r=r(Rta,"model.eval()"),Rta.forEach(t),k8r=r(UHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cwe=n(UHe,"CODE",{});var Pta=s(cwe);S8r=r(Pta,"model.train()"),Pta.forEach(t),UHe.forEach(t),R8r=i(Va),T(KC.$$.fragment,Va),Va.forEach(t),ei.forEach(t),tao=i(c),km=n(c,"H2",{class:!0});var Mso=s(km);e3=n(Mso,"A",{id:!0,class:!0,href:!0});var Bta=s(e3);fwe=n(Bta,"SPAN",{});var Ita=s(fwe);T(hS.$$.fragment,Ita),Ita.forEach(t),Bta.forEach(t),P8r=i(Mso),gwe=n(Mso,"SPAN",{});var Nta=s(gwe);B8r=r(Nta,"AutoModelForAudioFrameClassification"),Nta.forEach(t),Mso.forEach(t),aao=i(c),er=n(c,"DIV",{class:!0});var oi=s(er);T(uS.$$.fragment,oi),I8r=i(oi),Sm=n(oi,"P",{});var kme=s(Sm);N8r=r(kme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Pee=n(kme,"A",{href:!0});var qta=s(Pee);q8r=r(qta,"from_pretrained()"),qta.forEach(t),j8r=r(kme," class method or the "),Bee=n(kme,"A",{href:!0});var jta=s(Bee);D8r=r(jta,"from_config()"),jta.forEach(t),G8r=r(kme,` class
method.`),kme.forEach(t),O8r=i(oi),pS=n(oi,"P",{});var Eso=s(pS);V8r=r(Eso,"This class cannot be instantiated directly using "),hwe=n(Eso,"CODE",{});var Dta=s(hwe);X8r=r(Dta,"__init__()"),Dta.forEach(t),z8r=r(Eso," (throws an error)."),Eso.forEach(t),Q8r=i(oi),Dt=n(oi,"DIV",{class:!0});var k9=s(Dt);T(_S.$$.fragment,k9),W8r=i(k9),uwe=n(k9,"P",{});var Gta=s(uwe);U8r=r(Gta,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Gta.forEach(t),H8r=i(k9),Rm=n(k9,"P",{});var Sme=s(Rm);J8r=r(Sme,`Note:
Loading a model from its configuration file does `),pwe=n(Sme,"STRONG",{});var Ota=s(pwe);Y8r=r(Ota,"not"),Ota.forEach(t),Z8r=r(Sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=n(Sme,"A",{href:!0});var Vta=s(Iee);K8r=r(Vta,"from_pretrained()"),Vta.forEach(t),eLr=r(Sme," to load the model weights."),Sme.forEach(t),oLr=i(k9),T(o3.$$.fragment,k9),k9.forEach(t),rLr=i(oi),bo=n(oi,"DIV",{class:!0});var Xa=s(bo);T(bS.$$.fragment,Xa),tLr=i(Xa),_we=n(Xa,"P",{});var Xta=s(_we);aLr=r(Xta,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Xta.forEach(t),nLr=i(Xa),En=n(Xa,"P",{});var S9=s(En);sLr=r(S9,"The model class to instantiate is selected based on the "),bwe=n(S9,"CODE",{});var zta=s(bwe);lLr=r(zta,"model_type"),zta.forEach(t),iLr=r(S9,` property of the config object (either
passed as an argument or loaded from `),vwe=n(S9,"CODE",{});var Qta=s(vwe);dLr=r(Qta,"pretrained_model_name_or_path"),Qta.forEach(t),mLr=r(S9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=n(S9,"CODE",{});var Wta=s(Fwe);cLr=r(Wta,"pretrained_model_name_or_path"),Wta.forEach(t),fLr=r(S9,":"),S9.forEach(t),gLr=i(Xa),ut=n(Xa,"UL",{});var ri=s(ut);r3=n(ri,"LI",{});var HHe=s(r3);Twe=n(HHe,"STRONG",{});var Uta=s(Twe);hLr=r(Uta,"data2vec-audio"),Uta.forEach(t),uLr=r(HHe," \u2014 "),Nee=n(HHe,"A",{href:!0});var Hta=s(Nee);pLr=r(Hta,"Data2VecAudioForAudioFrameClassification"),Hta.forEach(t),_Lr=r(HHe," (Data2VecAudio model)"),HHe.forEach(t),bLr=i(ri),t3=n(ri,"LI",{});var JHe=s(t3);Mwe=n(JHe,"STRONG",{});var Jta=s(Mwe);vLr=r(Jta,"unispeech-sat"),Jta.forEach(t),FLr=r(JHe," \u2014 "),qee=n(JHe,"A",{href:!0});var Yta=s(qee);TLr=r(Yta,"UniSpeechSatForAudioFrameClassification"),Yta.forEach(t),MLr=r(JHe," (UniSpeechSat model)"),JHe.forEach(t),ELr=i(ri),a3=n(ri,"LI",{});var YHe=s(a3);Ewe=n(YHe,"STRONG",{});var Zta=s(Ewe);CLr=r(Zta,"wav2vec2"),Zta.forEach(t),wLr=r(YHe," \u2014 "),jee=n(YHe,"A",{href:!0});var Kta=s(jee);ALr=r(Kta,"Wav2Vec2ForAudioFrameClassification"),Kta.forEach(t),LLr=r(YHe," (Wav2Vec2 model)"),YHe.forEach(t),yLr=i(ri),n3=n(ri,"LI",{});var ZHe=s(n3);Cwe=n(ZHe,"STRONG",{});var eaa=s(Cwe);xLr=r(eaa,"wav2vec2-conformer"),eaa.forEach(t),$Lr=r(ZHe," \u2014 "),Dee=n(ZHe,"A",{href:!0});var oaa=s(Dee);kLr=r(oaa,"Wav2Vec2ConformerForAudioFrameClassification"),oaa.forEach(t),SLr=r(ZHe," (Wav2Vec2-Conformer model)"),ZHe.forEach(t),RLr=i(ri),s3=n(ri,"LI",{});var KHe=s(s3);wwe=n(KHe,"STRONG",{});var raa=s(wwe);PLr=r(raa,"wavlm"),raa.forEach(t),BLr=r(KHe," \u2014 "),Gee=n(KHe,"A",{href:!0});var taa=s(Gee);ILr=r(taa,"WavLMForAudioFrameClassification"),taa.forEach(t),NLr=r(KHe," (WavLM model)"),KHe.forEach(t),ri.forEach(t),qLr=i(Xa),l3=n(Xa,"P",{});var eJe=s(l3);jLr=r(eJe,"The model is set in evaluation mode by default using "),Awe=n(eJe,"CODE",{});var aaa=s(Awe);DLr=r(aaa,"model.eval()"),aaa.forEach(t),GLr=r(eJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lwe=n(eJe,"CODE",{});var naa=s(Lwe);OLr=r(naa,"model.train()"),naa.forEach(t),eJe.forEach(t),VLr=i(Xa),T(i3.$$.fragment,Xa),Xa.forEach(t),oi.forEach(t),nao=i(c),Pm=n(c,"H2",{class:!0});var Cso=s(Pm);d3=n(Cso,"A",{id:!0,class:!0,href:!0});var saa=s(d3);ywe=n(saa,"SPAN",{});var laa=s(ywe);T(vS.$$.fragment,laa),laa.forEach(t),saa.forEach(t),XLr=i(Cso),xwe=n(Cso,"SPAN",{});var iaa=s(xwe);zLr=r(iaa,"AutoModelForCTC"),iaa.forEach(t),Cso.forEach(t),sao=i(c),or=n(c,"DIV",{class:!0});var ti=s(or);T(FS.$$.fragment,ti),QLr=i(ti),Bm=n(ti,"P",{});var Rme=s(Bm);WLr=r(Rme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Oee=n(Rme,"A",{href:!0});var daa=s(Oee);ULr=r(daa,"from_pretrained()"),daa.forEach(t),HLr=r(Rme," class method or the "),Vee=n(Rme,"A",{href:!0});var maa=s(Vee);JLr=r(maa,"from_config()"),maa.forEach(t),YLr=r(Rme,` class
method.`),Rme.forEach(t),ZLr=i(ti),TS=n(ti,"P",{});var wso=s(TS);KLr=r(wso,"This class cannot be instantiated directly using "),$we=n(wso,"CODE",{});var caa=s($we);eyr=r(caa,"__init__()"),caa.forEach(t),oyr=r(wso," (throws an error)."),wso.forEach(t),ryr=i(ti),Gt=n(ti,"DIV",{class:!0});var R9=s(Gt);T(MS.$$.fragment,R9),tyr=i(R9),kwe=n(R9,"P",{});var faa=s(kwe);ayr=r(faa,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),faa.forEach(t),nyr=i(R9),Im=n(R9,"P",{});var Pme=s(Im);syr=r(Pme,`Note:
Loading a model from its configuration file does `),Swe=n(Pme,"STRONG",{});var gaa=s(Swe);lyr=r(gaa,"not"),gaa.forEach(t),iyr=r(Pme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xee=n(Pme,"A",{href:!0});var haa=s(Xee);dyr=r(haa,"from_pretrained()"),haa.forEach(t),myr=r(Pme," to load the model weights."),Pme.forEach(t),cyr=i(R9),T(m3.$$.fragment,R9),R9.forEach(t),fyr=i(ti),vo=n(ti,"DIV",{class:!0});var za=s(vo);T(ES.$$.fragment,za),gyr=i(za),Rwe=n(za,"P",{});var uaa=s(Rwe);hyr=r(uaa,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),uaa.forEach(t),uyr=i(za),Cn=n(za,"P",{});var P9=s(Cn);pyr=r(P9,"The model class to instantiate is selected based on the "),Pwe=n(P9,"CODE",{});var paa=s(Pwe);_yr=r(paa,"model_type"),paa.forEach(t),byr=r(P9,` property of the config object (either
passed as an argument or loaded from `),Bwe=n(P9,"CODE",{});var _aa=s(Bwe);vyr=r(_aa,"pretrained_model_name_or_path"),_aa.forEach(t),Fyr=r(P9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iwe=n(P9,"CODE",{});var baa=s(Iwe);Tyr=r(baa,"pretrained_model_name_or_path"),baa.forEach(t),Myr=r(P9,":"),P9.forEach(t),Eyr=i(za),Le=n(za,"UL",{});var Ie=s(Le);c3=n(Ie,"LI",{});var oJe=s(c3);Nwe=n(oJe,"STRONG",{});var vaa=s(Nwe);Cyr=r(vaa,"data2vec-audio"),vaa.forEach(t),wyr=r(oJe," \u2014 "),zee=n(oJe,"A",{href:!0});var Faa=s(zee);Ayr=r(Faa,"Data2VecAudioForCTC"),Faa.forEach(t),Lyr=r(oJe," (Data2VecAudio model)"),oJe.forEach(t),yyr=i(Ie),f3=n(Ie,"LI",{});var rJe=s(f3);qwe=n(rJe,"STRONG",{});var Taa=s(qwe);xyr=r(Taa,"hubert"),Taa.forEach(t),$yr=r(rJe," \u2014 "),Qee=n(rJe,"A",{href:!0});var Maa=s(Qee);kyr=r(Maa,"HubertForCTC"),Maa.forEach(t),Syr=r(rJe," (Hubert model)"),rJe.forEach(t),Ryr=i(Ie),g3=n(Ie,"LI",{});var tJe=s(g3);jwe=n(tJe,"STRONG",{});var Eaa=s(jwe);Pyr=r(Eaa,"mctct"),Eaa.forEach(t),Byr=r(tJe," \u2014 "),Wee=n(tJe,"A",{href:!0});var Caa=s(Wee);Iyr=r(Caa,"MCTCTForCTC"),Caa.forEach(t),Nyr=r(tJe," (M-CTC-T model)"),tJe.forEach(t),qyr=i(Ie),h3=n(Ie,"LI",{});var aJe=s(h3);Dwe=n(aJe,"STRONG",{});var waa=s(Dwe);jyr=r(waa,"sew"),waa.forEach(t),Dyr=r(aJe," \u2014 "),Uee=n(aJe,"A",{href:!0});var Aaa=s(Uee);Gyr=r(Aaa,"SEWForCTC"),Aaa.forEach(t),Oyr=r(aJe," (SEW model)"),aJe.forEach(t),Vyr=i(Ie),u3=n(Ie,"LI",{});var nJe=s(u3);Gwe=n(nJe,"STRONG",{});var Laa=s(Gwe);Xyr=r(Laa,"sew-d"),Laa.forEach(t),zyr=r(nJe," \u2014 "),Hee=n(nJe,"A",{href:!0});var yaa=s(Hee);Qyr=r(yaa,"SEWDForCTC"),yaa.forEach(t),Wyr=r(nJe," (SEW-D model)"),nJe.forEach(t),Uyr=i(Ie),p3=n(Ie,"LI",{});var sJe=s(p3);Owe=n(sJe,"STRONG",{});var xaa=s(Owe);Hyr=r(xaa,"unispeech"),xaa.forEach(t),Jyr=r(sJe," \u2014 "),Jee=n(sJe,"A",{href:!0});var $aa=s(Jee);Yyr=r($aa,"UniSpeechForCTC"),$aa.forEach(t),Zyr=r(sJe," (UniSpeech model)"),sJe.forEach(t),Kyr=i(Ie),_3=n(Ie,"LI",{});var lJe=s(_3);Vwe=n(lJe,"STRONG",{});var kaa=s(Vwe);e9r=r(kaa,"unispeech-sat"),kaa.forEach(t),o9r=r(lJe," \u2014 "),Yee=n(lJe,"A",{href:!0});var Saa=s(Yee);r9r=r(Saa,"UniSpeechSatForCTC"),Saa.forEach(t),t9r=r(lJe," (UniSpeechSat model)"),lJe.forEach(t),a9r=i(Ie),b3=n(Ie,"LI",{});var iJe=s(b3);Xwe=n(iJe,"STRONG",{});var Raa=s(Xwe);n9r=r(Raa,"wav2vec2"),Raa.forEach(t),s9r=r(iJe," \u2014 "),Zee=n(iJe,"A",{href:!0});var Paa=s(Zee);l9r=r(Paa,"Wav2Vec2ForCTC"),Paa.forEach(t),i9r=r(iJe," (Wav2Vec2 model)"),iJe.forEach(t),d9r=i(Ie),v3=n(Ie,"LI",{});var dJe=s(v3);zwe=n(dJe,"STRONG",{});var Baa=s(zwe);m9r=r(Baa,"wav2vec2-conformer"),Baa.forEach(t),c9r=r(dJe," \u2014 "),Kee=n(dJe,"A",{href:!0});var Iaa=s(Kee);f9r=r(Iaa,"Wav2Vec2ConformerForCTC"),Iaa.forEach(t),g9r=r(dJe," (Wav2Vec2-Conformer model)"),dJe.forEach(t),h9r=i(Ie),F3=n(Ie,"LI",{});var mJe=s(F3);Qwe=n(mJe,"STRONG",{});var Naa=s(Qwe);u9r=r(Naa,"wavlm"),Naa.forEach(t),p9r=r(mJe," \u2014 "),eoe=n(mJe,"A",{href:!0});var qaa=s(eoe);_9r=r(qaa,"WavLMForCTC"),qaa.forEach(t),b9r=r(mJe," (WavLM model)"),mJe.forEach(t),Ie.forEach(t),v9r=i(za),T3=n(za,"P",{});var cJe=s(T3);F9r=r(cJe,"The model is set in evaluation mode by default using "),Wwe=n(cJe,"CODE",{});var jaa=s(Wwe);T9r=r(jaa,"model.eval()"),jaa.forEach(t),M9r=r(cJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uwe=n(cJe,"CODE",{});var Daa=s(Uwe);E9r=r(Daa,"model.train()"),Daa.forEach(t),cJe.forEach(t),C9r=i(za),T(M3.$$.fragment,za),za.forEach(t),ti.forEach(t),lao=i(c),Nm=n(c,"H2",{class:!0});var Aso=s(Nm);E3=n(Aso,"A",{id:!0,class:!0,href:!0});var Gaa=s(E3);Hwe=n(Gaa,"SPAN",{});var Oaa=s(Hwe);T(CS.$$.fragment,Oaa),Oaa.forEach(t),Gaa.forEach(t),w9r=i(Aso),Jwe=n(Aso,"SPAN",{});var Vaa=s(Jwe);A9r=r(Vaa,"AutoModelForSpeechSeq2Seq"),Vaa.forEach(t),Aso.forEach(t),iao=i(c),rr=n(c,"DIV",{class:!0});var ai=s(rr);T(wS.$$.fragment,ai),L9r=i(ai),qm=n(ai,"P",{});var Bme=s(qm);y9r=r(Bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ooe=n(Bme,"A",{href:!0});var Xaa=s(ooe);x9r=r(Xaa,"from_pretrained()"),Xaa.forEach(t),$9r=r(Bme," class method or the "),roe=n(Bme,"A",{href:!0});var zaa=s(roe);k9r=r(zaa,"from_config()"),zaa.forEach(t),S9r=r(Bme,` class
method.`),Bme.forEach(t),R9r=i(ai),AS=n(ai,"P",{});var Lso=s(AS);P9r=r(Lso,"This class cannot be instantiated directly using "),Ywe=n(Lso,"CODE",{});var Qaa=s(Ywe);B9r=r(Qaa,"__init__()"),Qaa.forEach(t),I9r=r(Lso," (throws an error)."),Lso.forEach(t),N9r=i(ai),Ot=n(ai,"DIV",{class:!0});var B9=s(Ot);T(LS.$$.fragment,B9),q9r=i(B9),Zwe=n(B9,"P",{});var Waa=s(Zwe);j9r=r(Waa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Waa.forEach(t),D9r=i(B9),jm=n(B9,"P",{});var Ime=s(jm);G9r=r(Ime,`Note:
Loading a model from its configuration file does `),Kwe=n(Ime,"STRONG",{});var Uaa=s(Kwe);O9r=r(Uaa,"not"),Uaa.forEach(t),V9r=r(Ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=n(Ime,"A",{href:!0});var Haa=s(toe);X9r=r(Haa,"from_pretrained()"),Haa.forEach(t),z9r=r(Ime," to load the model weights."),Ime.forEach(t),Q9r=i(B9),T(C3.$$.fragment,B9),B9.forEach(t),W9r=i(ai),Fo=n(ai,"DIV",{class:!0});var Qa=s(Fo);T(yS.$$.fragment,Qa),U9r=i(Qa),eAe=n(Qa,"P",{});var Jaa=s(eAe);H9r=r(Jaa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Jaa.forEach(t),J9r=i(Qa),wn=n(Qa,"P",{});var I9=s(wn);Y9r=r(I9,"The model class to instantiate is selected based on the "),oAe=n(I9,"CODE",{});var Yaa=s(oAe);Z9r=r(Yaa,"model_type"),Yaa.forEach(t),K9r=r(I9,` property of the config object (either
passed as an argument or loaded from `),rAe=n(I9,"CODE",{});var Zaa=s(rAe);exr=r(Zaa,"pretrained_model_name_or_path"),Zaa.forEach(t),oxr=r(I9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tAe=n(I9,"CODE",{});var Kaa=s(tAe);rxr=r(Kaa,"pretrained_model_name_or_path"),Kaa.forEach(t),txr=r(I9,":"),I9.forEach(t),axr=i(Qa),Dm=n(Qa,"UL",{});var Nme=s(Dm);w3=n(Nme,"LI",{});var fJe=s(w3);aAe=n(fJe,"STRONG",{});var ena=s(aAe);nxr=r(ena,"speech-encoder-decoder"),ena.forEach(t),sxr=r(fJe," \u2014 "),aoe=n(fJe,"A",{href:!0});var ona=s(aoe);lxr=r(ona,"SpeechEncoderDecoderModel"),ona.forEach(t),ixr=r(fJe," (Speech Encoder decoder model)"),fJe.forEach(t),dxr=i(Nme),A3=n(Nme,"LI",{});var gJe=s(A3);nAe=n(gJe,"STRONG",{});var rna=s(nAe);mxr=r(rna,"speech_to_text"),rna.forEach(t),cxr=r(gJe," \u2014 "),noe=n(gJe,"A",{href:!0});var tna=s(noe);fxr=r(tna,"Speech2TextForConditionalGeneration"),tna.forEach(t),gxr=r(gJe," (Speech2Text model)"),gJe.forEach(t),hxr=i(Nme),L3=n(Nme,"LI",{});var hJe=s(L3);sAe=n(hJe,"STRONG",{});var ana=s(sAe);uxr=r(ana,"whisper"),ana.forEach(t),pxr=r(hJe," \u2014 "),soe=n(hJe,"A",{href:!0});var nna=s(soe);_xr=r(nna,"WhisperForConditionalGeneration"),nna.forEach(t),bxr=r(hJe," (Whisper model)"),hJe.forEach(t),Nme.forEach(t),vxr=i(Qa),y3=n(Qa,"P",{});var uJe=s(y3);Fxr=r(uJe,"The model is set in evaluation mode by default using "),lAe=n(uJe,"CODE",{});var sna=s(lAe);Txr=r(sna,"model.eval()"),sna.forEach(t),Mxr=r(uJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iAe=n(uJe,"CODE",{});var lna=s(iAe);Exr=r(lna,"model.train()"),lna.forEach(t),uJe.forEach(t),Cxr=i(Qa),T(x3.$$.fragment,Qa),Qa.forEach(t),ai.forEach(t),dao=i(c),Gm=n(c,"H2",{class:!0});var yso=s(Gm);$3=n(yso,"A",{id:!0,class:!0,href:!0});var ina=s($3);dAe=n(ina,"SPAN",{});var dna=s(dAe);T(xS.$$.fragment,dna),dna.forEach(t),ina.forEach(t),wxr=i(yso),mAe=n(yso,"SPAN",{});var mna=s(mAe);Axr=r(mna,"AutoModelForAudioXVector"),mna.forEach(t),yso.forEach(t),mao=i(c),tr=n(c,"DIV",{class:!0});var ni=s(tr);T($S.$$.fragment,ni),Lxr=i(ni),Om=n(ni,"P",{});var qme=s(Om);yxr=r(qme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),loe=n(qme,"A",{href:!0});var cna=s(loe);xxr=r(cna,"from_pretrained()"),cna.forEach(t),$xr=r(qme," class method or the "),ioe=n(qme,"A",{href:!0});var fna=s(ioe);kxr=r(fna,"from_config()"),fna.forEach(t),Sxr=r(qme,` class
method.`),qme.forEach(t),Rxr=i(ni),kS=n(ni,"P",{});var xso=s(kS);Pxr=r(xso,"This class cannot be instantiated directly using "),cAe=n(xso,"CODE",{});var gna=s(cAe);Bxr=r(gna,"__init__()"),gna.forEach(t),Ixr=r(xso," (throws an error)."),xso.forEach(t),Nxr=i(ni),Vt=n(ni,"DIV",{class:!0});var N9=s(Vt);T(SS.$$.fragment,N9),qxr=i(N9),fAe=n(N9,"P",{});var hna=s(fAe);jxr=r(hna,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),hna.forEach(t),Dxr=i(N9),Vm=n(N9,"P",{});var jme=s(Vm);Gxr=r(jme,`Note:
Loading a model from its configuration file does `),gAe=n(jme,"STRONG",{});var una=s(gAe);Oxr=r(una,"not"),una.forEach(t),Vxr=r(jme,` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=n(jme,"A",{href:!0});var pna=s(doe);Xxr=r(pna,"from_pretrained()"),pna.forEach(t),zxr=r(jme," to load the model weights."),jme.forEach(t),Qxr=i(N9),T(k3.$$.fragment,N9),N9.forEach(t),Wxr=i(ni),To=n(ni,"DIV",{class:!0});var Wa=s(To);T(RS.$$.fragment,Wa),Uxr=i(Wa),hAe=n(Wa,"P",{});var _na=s(hAe);Hxr=r(_na,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),_na.forEach(t),Jxr=i(Wa),An=n(Wa,"P",{});var q9=s(An);Yxr=r(q9,"The model class to instantiate is selected based on the "),uAe=n(q9,"CODE",{});var bna=s(uAe);Zxr=r(bna,"model_type"),bna.forEach(t),Kxr=r(q9,` property of the config object (either
passed as an argument or loaded from `),pAe=n(q9,"CODE",{});var vna=s(pAe);e$r=r(vna,"pretrained_model_name_or_path"),vna.forEach(t),o$r=r(q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=n(q9,"CODE",{});var Fna=s(_Ae);r$r=r(Fna,"pretrained_model_name_or_path"),Fna.forEach(t),t$r=r(q9,":"),q9.forEach(t),a$r=i(Wa),pt=n(Wa,"UL",{});var si=s(pt);S3=n(si,"LI",{});var pJe=s(S3);bAe=n(pJe,"STRONG",{});var Tna=s(bAe);n$r=r(Tna,"data2vec-audio"),Tna.forEach(t),s$r=r(pJe," \u2014 "),moe=n(pJe,"A",{href:!0});var Mna=s(moe);l$r=r(Mna,"Data2VecAudioForXVector"),Mna.forEach(t),i$r=r(pJe," (Data2VecAudio model)"),pJe.forEach(t),d$r=i(si),R3=n(si,"LI",{});var _Je=s(R3);vAe=n(_Je,"STRONG",{});var Ena=s(vAe);m$r=r(Ena,"unispeech-sat"),Ena.forEach(t),c$r=r(_Je," \u2014 "),coe=n(_Je,"A",{href:!0});var Cna=s(coe);f$r=r(Cna,"UniSpeechSatForXVector"),Cna.forEach(t),g$r=r(_Je," (UniSpeechSat model)"),_Je.forEach(t),h$r=i(si),P3=n(si,"LI",{});var bJe=s(P3);FAe=n(bJe,"STRONG",{});var wna=s(FAe);u$r=r(wna,"wav2vec2"),wna.forEach(t),p$r=r(bJe," \u2014 "),foe=n(bJe,"A",{href:!0});var Ana=s(foe);_$r=r(Ana,"Wav2Vec2ForXVector"),Ana.forEach(t),b$r=r(bJe," (Wav2Vec2 model)"),bJe.forEach(t),v$r=i(si),B3=n(si,"LI",{});var vJe=s(B3);TAe=n(vJe,"STRONG",{});var Lna=s(TAe);F$r=r(Lna,"wav2vec2-conformer"),Lna.forEach(t),T$r=r(vJe," \u2014 "),goe=n(vJe,"A",{href:!0});var yna=s(goe);M$r=r(yna,"Wav2Vec2ConformerForXVector"),yna.forEach(t),E$r=r(vJe," (Wav2Vec2-Conformer model)"),vJe.forEach(t),C$r=i(si),I3=n(si,"LI",{});var FJe=s(I3);MAe=n(FJe,"STRONG",{});var xna=s(MAe);w$r=r(xna,"wavlm"),xna.forEach(t),A$r=r(FJe," \u2014 "),hoe=n(FJe,"A",{href:!0});var $na=s(hoe);L$r=r($na,"WavLMForXVector"),$na.forEach(t),y$r=r(FJe," (WavLM model)"),FJe.forEach(t),si.forEach(t),x$r=i(Wa),N3=n(Wa,"P",{});var TJe=s(N3);$$r=r(TJe,"The model is set in evaluation mode by default using "),EAe=n(TJe,"CODE",{});var kna=s(EAe);k$r=r(kna,"model.eval()"),kna.forEach(t),S$r=r(TJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CAe=n(TJe,"CODE",{});var Sna=s(CAe);R$r=r(Sna,"model.train()"),Sna.forEach(t),TJe.forEach(t),P$r=i(Wa),T(q3.$$.fragment,Wa),Wa.forEach(t),ni.forEach(t),cao=i(c),Xm=n(c,"H2",{class:!0});var $so=s(Xm);j3=n($so,"A",{id:!0,class:!0,href:!0});var Rna=s(j3);wAe=n(Rna,"SPAN",{});var Pna=s(wAe);T(PS.$$.fragment,Pna),Pna.forEach(t),Rna.forEach(t),B$r=i($so),AAe=n($so,"SPAN",{});var Bna=s(AAe);I$r=r(Bna,"AutoModelForMaskedImageModeling"),Bna.forEach(t),$so.forEach(t),fao=i(c),ar=n(c,"DIV",{class:!0});var li=s(ar);T(BS.$$.fragment,li),N$r=i(li),zm=n(li,"P",{});var Dme=s(zm);q$r=r(Dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),uoe=n(Dme,"A",{href:!0});var Ina=s(uoe);j$r=r(Ina,"from_pretrained()"),Ina.forEach(t),D$r=r(Dme," class method or the "),poe=n(Dme,"A",{href:!0});var Nna=s(poe);G$r=r(Nna,"from_config()"),Nna.forEach(t),O$r=r(Dme,` class
method.`),Dme.forEach(t),V$r=i(li),IS=n(li,"P",{});var kso=s(IS);X$r=r(kso,"This class cannot be instantiated directly using "),LAe=n(kso,"CODE",{});var qna=s(LAe);z$r=r(qna,"__init__()"),qna.forEach(t),Q$r=r(kso," (throws an error)."),kso.forEach(t),W$r=i(li),Xt=n(li,"DIV",{class:!0});var j9=s(Xt);T(NS.$$.fragment,j9),U$r=i(j9),yAe=n(j9,"P",{});var jna=s(yAe);H$r=r(jna,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),jna.forEach(t),J$r=i(j9),Qm=n(j9,"P",{});var Gme=s(Qm);Y$r=r(Gme,`Note:
Loading a model from its configuration file does `),xAe=n(Gme,"STRONG",{});var Dna=s(xAe);Z$r=r(Dna,"not"),Dna.forEach(t),K$r=r(Gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(Gme,"A",{href:!0});var Gna=s(_oe);ekr=r(Gna,"from_pretrained()"),Gna.forEach(t),okr=r(Gme," to load the model weights."),Gme.forEach(t),rkr=i(j9),T(D3.$$.fragment,j9),j9.forEach(t),tkr=i(li),Mo=n(li,"DIV",{class:!0});var Ua=s(Mo);T(qS.$$.fragment,Ua),akr=i(Ua),$Ae=n(Ua,"P",{});var Ona=s($Ae);nkr=r(Ona,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Ona.forEach(t),skr=i(Ua),Ln=n(Ua,"P",{});var D9=s(Ln);lkr=r(D9,"The model class to instantiate is selected based on the "),kAe=n(D9,"CODE",{});var Vna=s(kAe);ikr=r(Vna,"model_type"),Vna.forEach(t),dkr=r(D9,` property of the config object (either
passed as an argument or loaded from `),SAe=n(D9,"CODE",{});var Xna=s(SAe);mkr=r(Xna,"pretrained_model_name_or_path"),Xna.forEach(t),ckr=r(D9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RAe=n(D9,"CODE",{});var zna=s(RAe);fkr=r(zna,"pretrained_model_name_or_path"),zna.forEach(t),gkr=r(D9,":"),D9.forEach(t),hkr=i(Ua),yn=n(Ua,"UL",{});var G9=s(yn);G3=n(G9,"LI",{});var MJe=s(G3);PAe=n(MJe,"STRONG",{});var Qna=s(PAe);ukr=r(Qna,"deit"),Qna.forEach(t),pkr=r(MJe," \u2014 "),boe=n(MJe,"A",{href:!0});var Wna=s(boe);_kr=r(Wna,"DeiTForMaskedImageModeling"),Wna.forEach(t),bkr=r(MJe," (DeiT model)"),MJe.forEach(t),vkr=i(G9),O3=n(G9,"LI",{});var EJe=s(O3);BAe=n(EJe,"STRONG",{});var Una=s(BAe);Fkr=r(Una,"swin"),Una.forEach(t),Tkr=r(EJe," \u2014 "),voe=n(EJe,"A",{href:!0});var Hna=s(voe);Mkr=r(Hna,"SwinForMaskedImageModeling"),Hna.forEach(t),Ekr=r(EJe," (Swin Transformer model)"),EJe.forEach(t),Ckr=i(G9),V3=n(G9,"LI",{});var CJe=s(V3);IAe=n(CJe,"STRONG",{});var Jna=s(IAe);wkr=r(Jna,"swinv2"),Jna.forEach(t),Akr=r(CJe," \u2014 "),Foe=n(CJe,"A",{href:!0});var Yna=s(Foe);Lkr=r(Yna,"Swinv2ForMaskedImageModeling"),Yna.forEach(t),ykr=r(CJe," (Swin Transformer V2 model)"),CJe.forEach(t),xkr=i(G9),X3=n(G9,"LI",{});var wJe=s(X3);NAe=n(wJe,"STRONG",{});var Zna=s(NAe);$kr=r(Zna,"vit"),Zna.forEach(t),kkr=r(wJe," \u2014 "),Toe=n(wJe,"A",{href:!0});var Kna=s(Toe);Skr=r(Kna,"ViTForMaskedImageModeling"),Kna.forEach(t),Rkr=r(wJe," (ViT model)"),wJe.forEach(t),G9.forEach(t),Pkr=i(Ua),z3=n(Ua,"P",{});var AJe=s(z3);Bkr=r(AJe,"The model is set in evaluation mode by default using "),qAe=n(AJe,"CODE",{});var esa=s(qAe);Ikr=r(esa,"model.eval()"),esa.forEach(t),Nkr=r(AJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jAe=n(AJe,"CODE",{});var osa=s(jAe);qkr=r(osa,"model.train()"),osa.forEach(t),AJe.forEach(t),jkr=i(Ua),T(Q3.$$.fragment,Ua),Ua.forEach(t),li.forEach(t),gao=i(c),Wm=n(c,"H2",{class:!0});var Sso=s(Wm);W3=n(Sso,"A",{id:!0,class:!0,href:!0});var rsa=s(W3);DAe=n(rsa,"SPAN",{});var tsa=s(DAe);T(jS.$$.fragment,tsa),tsa.forEach(t),rsa.forEach(t),Dkr=i(Sso),GAe=n(Sso,"SPAN",{});var asa=s(GAe);Gkr=r(asa,"AutoModelForObjectDetection"),asa.forEach(t),Sso.forEach(t),hao=i(c),nr=n(c,"DIV",{class:!0});var ii=s(nr);T(DS.$$.fragment,ii),Okr=i(ii),Um=n(ii,"P",{});var Ome=s(Um);Vkr=r(Ome,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Moe=n(Ome,"A",{href:!0});var nsa=s(Moe);Xkr=r(nsa,"from_pretrained()"),nsa.forEach(t),zkr=r(Ome," class method or the "),Eoe=n(Ome,"A",{href:!0});var ssa=s(Eoe);Qkr=r(ssa,"from_config()"),ssa.forEach(t),Wkr=r(Ome,` class
method.`),Ome.forEach(t),Ukr=i(ii),GS=n(ii,"P",{});var Rso=s(GS);Hkr=r(Rso,"This class cannot be instantiated directly using "),OAe=n(Rso,"CODE",{});var lsa=s(OAe);Jkr=r(lsa,"__init__()"),lsa.forEach(t),Ykr=r(Rso," (throws an error)."),Rso.forEach(t),Zkr=i(ii),zt=n(ii,"DIV",{class:!0});var O9=s(zt);T(OS.$$.fragment,O9),Kkr=i(O9),VAe=n(O9,"P",{});var isa=s(VAe);eSr=r(isa,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),isa.forEach(t),oSr=i(O9),Hm=n(O9,"P",{});var Vme=s(Hm);rSr=r(Vme,`Note:
Loading a model from its configuration file does `),XAe=n(Vme,"STRONG",{});var dsa=s(XAe);tSr=r(dsa,"not"),dsa.forEach(t),aSr=r(Vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Coe=n(Vme,"A",{href:!0});var msa=s(Coe);nSr=r(msa,"from_pretrained()"),msa.forEach(t),sSr=r(Vme," to load the model weights."),Vme.forEach(t),lSr=i(O9),T(U3.$$.fragment,O9),O9.forEach(t),iSr=i(ii),Eo=n(ii,"DIV",{class:!0});var Ha=s(Eo);T(VS.$$.fragment,Ha),dSr=i(Ha),zAe=n(Ha,"P",{});var csa=s(zAe);mSr=r(csa,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),csa.forEach(t),cSr=i(Ha),xn=n(Ha,"P",{});var V9=s(xn);fSr=r(V9,"The model class to instantiate is selected based on the "),QAe=n(V9,"CODE",{});var fsa=s(QAe);gSr=r(fsa,"model_type"),fsa.forEach(t),hSr=r(V9,` property of the config object (either
passed as an argument or loaded from `),WAe=n(V9,"CODE",{});var gsa=s(WAe);uSr=r(gsa,"pretrained_model_name_or_path"),gsa.forEach(t),pSr=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UAe=n(V9,"CODE",{});var hsa=s(UAe);_Sr=r(hsa,"pretrained_model_name_or_path"),hsa.forEach(t),bSr=r(V9,":"),V9.forEach(t),vSr=i(Ha),$n=n(Ha,"UL",{});var X9=s($n);H3=n(X9,"LI",{});var LJe=s(H3);HAe=n(LJe,"STRONG",{});var usa=s(HAe);FSr=r(usa,"conditional_detr"),usa.forEach(t),TSr=r(LJe," \u2014 "),woe=n(LJe,"A",{href:!0});var psa=s(woe);MSr=r(psa,"ConditionalDetrForObjectDetection"),psa.forEach(t),ESr=r(LJe," (Conditional DETR model)"),LJe.forEach(t),CSr=i(X9),J3=n(X9,"LI",{});var yJe=s(J3);JAe=n(yJe,"STRONG",{});var _sa=s(JAe);wSr=r(_sa,"deformable_detr"),_sa.forEach(t),ASr=r(yJe," \u2014 "),Aoe=n(yJe,"A",{href:!0});var bsa=s(Aoe);LSr=r(bsa,"DeformableDetrForObjectDetection"),bsa.forEach(t),ySr=r(yJe," (Deformable DETR model)"),yJe.forEach(t),xSr=i(X9),Y3=n(X9,"LI",{});var xJe=s(Y3);YAe=n(xJe,"STRONG",{});var vsa=s(YAe);$Sr=r(vsa,"detr"),vsa.forEach(t),kSr=r(xJe," \u2014 "),Loe=n(xJe,"A",{href:!0});var Fsa=s(Loe);SSr=r(Fsa,"DetrForObjectDetection"),Fsa.forEach(t),RSr=r(xJe," (DETR model)"),xJe.forEach(t),PSr=i(X9),Z3=n(X9,"LI",{});var $Je=s(Z3);ZAe=n($Je,"STRONG",{});var Tsa=s(ZAe);BSr=r(Tsa,"yolos"),Tsa.forEach(t),ISr=r($Je," \u2014 "),yoe=n($Je,"A",{href:!0});var Msa=s(yoe);NSr=r(Msa,"YolosForObjectDetection"),Msa.forEach(t),qSr=r($Je," (YOLOS model)"),$Je.forEach(t),X9.forEach(t),jSr=i(Ha),K3=n(Ha,"P",{});var kJe=s(K3);DSr=r(kJe,"The model is set in evaluation mode by default using "),KAe=n(kJe,"CODE",{});var Esa=s(KAe);GSr=r(Esa,"model.eval()"),Esa.forEach(t),OSr=r(kJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e6e=n(kJe,"CODE",{});var Csa=s(e6e);VSr=r(Csa,"model.train()"),Csa.forEach(t),kJe.forEach(t),XSr=i(Ha),T(e5.$$.fragment,Ha),Ha.forEach(t),ii.forEach(t),uao=i(c),Jm=n(c,"H2",{class:!0});var Pso=s(Jm);o5=n(Pso,"A",{id:!0,class:!0,href:!0});var wsa=s(o5);o6e=n(wsa,"SPAN",{});var Asa=s(o6e);T(XS.$$.fragment,Asa),Asa.forEach(t),wsa.forEach(t),zSr=i(Pso),r6e=n(Pso,"SPAN",{});var Lsa=s(r6e);QSr=r(Lsa,"AutoModelForImageSegmentation"),Lsa.forEach(t),Pso.forEach(t),pao=i(c),sr=n(c,"DIV",{class:!0});var di=s(sr);T(zS.$$.fragment,di),WSr=i(di),Ym=n(di,"P",{});var Xme=s(Ym);USr=r(Xme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),xoe=n(Xme,"A",{href:!0});var ysa=s(xoe);HSr=r(ysa,"from_pretrained()"),ysa.forEach(t),JSr=r(Xme," class method or the "),$oe=n(Xme,"A",{href:!0});var xsa=s($oe);YSr=r(xsa,"from_config()"),xsa.forEach(t),ZSr=r(Xme,` class
method.`),Xme.forEach(t),KSr=i(di),QS=n(di,"P",{});var Bso=s(QS);eRr=r(Bso,"This class cannot be instantiated directly using "),t6e=n(Bso,"CODE",{});var $sa=s(t6e);oRr=r($sa,"__init__()"),$sa.forEach(t),rRr=r(Bso," (throws an error)."),Bso.forEach(t),tRr=i(di),Qt=n(di,"DIV",{class:!0});var z9=s(Qt);T(WS.$$.fragment,z9),aRr=i(z9),a6e=n(z9,"P",{});var ksa=s(a6e);nRr=r(ksa,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),ksa.forEach(t),sRr=i(z9),Zm=n(z9,"P",{});var zme=s(Zm);lRr=r(zme,`Note:
Loading a model from its configuration file does `),n6e=n(zme,"STRONG",{});var Ssa=s(n6e);iRr=r(Ssa,"not"),Ssa.forEach(t),dRr=r(zme,` load the model weights. It only affects the
model\u2019s configuration. Use `),koe=n(zme,"A",{href:!0});var Rsa=s(koe);mRr=r(Rsa,"from_pretrained()"),Rsa.forEach(t),cRr=r(zme," to load the model weights."),zme.forEach(t),fRr=i(z9),T(r5.$$.fragment,z9),z9.forEach(t),gRr=i(di),Co=n(di,"DIV",{class:!0});var Ja=s(Co);T(US.$$.fragment,Ja),hRr=i(Ja),s6e=n(Ja,"P",{});var Psa=s(s6e);uRr=r(Psa,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Psa.forEach(t),pRr=i(Ja),kn=n(Ja,"P",{});var Q9=s(kn);_Rr=r(Q9,"The model class to instantiate is selected based on the "),l6e=n(Q9,"CODE",{});var Bsa=s(l6e);bRr=r(Bsa,"model_type"),Bsa.forEach(t),vRr=r(Q9,` property of the config object (either
passed as an argument or loaded from `),i6e=n(Q9,"CODE",{});var Isa=s(i6e);FRr=r(Isa,"pretrained_model_name_or_path"),Isa.forEach(t),TRr=r(Q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d6e=n(Q9,"CODE",{});var Nsa=s(d6e);MRr=r(Nsa,"pretrained_model_name_or_path"),Nsa.forEach(t),ERr=r(Q9,":"),Q9.forEach(t),CRr=i(Ja),m6e=n(Ja,"UL",{});var qsa=s(m6e);t5=n(qsa,"LI",{});var SJe=s(t5);c6e=n(SJe,"STRONG",{});var jsa=s(c6e);wRr=r(jsa,"detr"),jsa.forEach(t),ARr=r(SJe," \u2014 "),Soe=n(SJe,"A",{href:!0});var Dsa=s(Soe);LRr=r(Dsa,"DetrForSegmentation"),Dsa.forEach(t),yRr=r(SJe," (DETR model)"),SJe.forEach(t),qsa.forEach(t),xRr=i(Ja),a5=n(Ja,"P",{});var RJe=s(a5);$Rr=r(RJe,"The model is set in evaluation mode by default using "),f6e=n(RJe,"CODE",{});var Gsa=s(f6e);kRr=r(Gsa,"model.eval()"),Gsa.forEach(t),SRr=r(RJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g6e=n(RJe,"CODE",{});var Osa=s(g6e);RRr=r(Osa,"model.train()"),Osa.forEach(t),RJe.forEach(t),PRr=i(Ja),T(n5.$$.fragment,Ja),Ja.forEach(t),di.forEach(t),_ao=i(c),Km=n(c,"H2",{class:!0});var Iso=s(Km);s5=n(Iso,"A",{id:!0,class:!0,href:!0});var Vsa=s(s5);h6e=n(Vsa,"SPAN",{});var Xsa=s(h6e);T(HS.$$.fragment,Xsa),Xsa.forEach(t),Vsa.forEach(t),BRr=i(Iso),u6e=n(Iso,"SPAN",{});var zsa=s(u6e);IRr=r(zsa,"AutoModelForSemanticSegmentation"),zsa.forEach(t),Iso.forEach(t),bao=i(c),lr=n(c,"DIV",{class:!0});var mi=s(lr);T(JS.$$.fragment,mi),NRr=i(mi),ec=n(mi,"P",{});var Qme=s(ec);qRr=r(Qme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Roe=n(Qme,"A",{href:!0});var Qsa=s(Roe);jRr=r(Qsa,"from_pretrained()"),Qsa.forEach(t),DRr=r(Qme," class method or the "),Poe=n(Qme,"A",{href:!0});var Wsa=s(Poe);GRr=r(Wsa,"from_config()"),Wsa.forEach(t),ORr=r(Qme,` class
method.`),Qme.forEach(t),VRr=i(mi),YS=n(mi,"P",{});var Nso=s(YS);XRr=r(Nso,"This class cannot be instantiated directly using "),p6e=n(Nso,"CODE",{});var Usa=s(p6e);zRr=r(Usa,"__init__()"),Usa.forEach(t),QRr=r(Nso," (throws an error)."),Nso.forEach(t),WRr=i(mi),Wt=n(mi,"DIV",{class:!0});var W9=s(Wt);T(ZS.$$.fragment,W9),URr=i(W9),_6e=n(W9,"P",{});var Hsa=s(_6e);HRr=r(Hsa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Hsa.forEach(t),JRr=i(W9),oc=n(W9,"P",{});var Wme=s(oc);YRr=r(Wme,`Note:
Loading a model from its configuration file does `),b6e=n(Wme,"STRONG",{});var Jsa=s(b6e);ZRr=r(Jsa,"not"),Jsa.forEach(t),KRr=r(Wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Boe=n(Wme,"A",{href:!0});var Ysa=s(Boe);ePr=r(Ysa,"from_pretrained()"),Ysa.forEach(t),oPr=r(Wme," to load the model weights."),Wme.forEach(t),rPr=i(W9),T(l5.$$.fragment,W9),W9.forEach(t),tPr=i(mi),wo=n(mi,"DIV",{class:!0});var Ya=s(wo);T(KS.$$.fragment,Ya),aPr=i(Ya),v6e=n(Ya,"P",{});var Zsa=s(v6e);nPr=r(Zsa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Zsa.forEach(t),sPr=i(Ya),Sn=n(Ya,"P",{});var U9=s(Sn);lPr=r(U9,"The model class to instantiate is selected based on the "),F6e=n(U9,"CODE",{});var Ksa=s(F6e);iPr=r(Ksa,"model_type"),Ksa.forEach(t),dPr=r(U9,` property of the config object (either
passed as an argument or loaded from `),T6e=n(U9,"CODE",{});var ela=s(T6e);mPr=r(ela,"pretrained_model_name_or_path"),ela.forEach(t),cPr=r(U9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M6e=n(U9,"CODE",{});var ola=s(M6e);fPr=r(ola,"pretrained_model_name_or_path"),ola.forEach(t),gPr=r(U9,":"),U9.forEach(t),hPr=i(Ya),_t=n(Ya,"UL",{});var ci=s(_t);i5=n(ci,"LI",{});var PJe=s(i5);E6e=n(PJe,"STRONG",{});var rla=s(E6e);uPr=r(rla,"beit"),rla.forEach(t),pPr=r(PJe," \u2014 "),Ioe=n(PJe,"A",{href:!0});var tla=s(Ioe);_Pr=r(tla,"BeitForSemanticSegmentation"),tla.forEach(t),bPr=r(PJe," (BEiT model)"),PJe.forEach(t),vPr=i(ci),d5=n(ci,"LI",{});var BJe=s(d5);C6e=n(BJe,"STRONG",{});var ala=s(C6e);FPr=r(ala,"data2vec-vision"),ala.forEach(t),TPr=r(BJe," \u2014 "),Noe=n(BJe,"A",{href:!0});var nla=s(Noe);MPr=r(nla,"Data2VecVisionForSemanticSegmentation"),nla.forEach(t),EPr=r(BJe," (Data2VecVision model)"),BJe.forEach(t),CPr=i(ci),m5=n(ci,"LI",{});var IJe=s(m5);w6e=n(IJe,"STRONG",{});var sla=s(w6e);wPr=r(sla,"dpt"),sla.forEach(t),APr=r(IJe," \u2014 "),qoe=n(IJe,"A",{href:!0});var lla=s(qoe);LPr=r(lla,"DPTForSemanticSegmentation"),lla.forEach(t),yPr=r(IJe," (DPT model)"),IJe.forEach(t),xPr=i(ci),c5=n(ci,"LI",{});var NJe=s(c5);A6e=n(NJe,"STRONG",{});var ila=s(A6e);$Pr=r(ila,"mobilevit"),ila.forEach(t),kPr=r(NJe," \u2014 "),joe=n(NJe,"A",{href:!0});var dla=s(joe);SPr=r(dla,"MobileViTForSemanticSegmentation"),dla.forEach(t),RPr=r(NJe," (MobileViT model)"),NJe.forEach(t),PPr=i(ci),f5=n(ci,"LI",{});var qJe=s(f5);L6e=n(qJe,"STRONG",{});var mla=s(L6e);BPr=r(mla,"segformer"),mla.forEach(t),IPr=r(qJe," \u2014 "),Doe=n(qJe,"A",{href:!0});var cla=s(Doe);NPr=r(cla,"SegformerForSemanticSegmentation"),cla.forEach(t),qPr=r(qJe," (SegFormer model)"),qJe.forEach(t),ci.forEach(t),jPr=i(Ya),g5=n(Ya,"P",{});var jJe=s(g5);DPr=r(jJe,"The model is set in evaluation mode by default using "),y6e=n(jJe,"CODE",{});var fla=s(y6e);GPr=r(fla,"model.eval()"),fla.forEach(t),OPr=r(jJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x6e=n(jJe,"CODE",{});var gla=s(x6e);VPr=r(gla,"model.train()"),gla.forEach(t),jJe.forEach(t),XPr=i(Ya),T(h5.$$.fragment,Ya),Ya.forEach(t),mi.forEach(t),vao=i(c),rc=n(c,"H2",{class:!0});var qso=s(rc);u5=n(qso,"A",{id:!0,class:!0,href:!0});var hla=s(u5);$6e=n(hla,"SPAN",{});var ula=s($6e);T(eR.$$.fragment,ula),ula.forEach(t),hla.forEach(t),zPr=i(qso),k6e=n(qso,"SPAN",{});var pla=s(k6e);QPr=r(pla,"AutoModelForInstanceSegmentation"),pla.forEach(t),qso.forEach(t),Fao=i(c),ir=n(c,"DIV",{class:!0});var fi=s(ir);T(oR.$$.fragment,fi),WPr=i(fi),tc=n(fi,"P",{});var Ume=s(tc);UPr=r(Ume,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Goe=n(Ume,"A",{href:!0});var _la=s(Goe);HPr=r(_la,"from_pretrained()"),_la.forEach(t),JPr=r(Ume," class method or the "),Ooe=n(Ume,"A",{href:!0});var bla=s(Ooe);YPr=r(bla,"from_config()"),bla.forEach(t),ZPr=r(Ume,` class
method.`),Ume.forEach(t),KPr=i(fi),rR=n(fi,"P",{});var jso=s(rR);eBr=r(jso,"This class cannot be instantiated directly using "),S6e=n(jso,"CODE",{});var vla=s(S6e);oBr=r(vla,"__init__()"),vla.forEach(t),rBr=r(jso," (throws an error)."),jso.forEach(t),tBr=i(fi),Ut=n(fi,"DIV",{class:!0});var H9=s(Ut);T(tR.$$.fragment,H9),aBr=i(H9),R6e=n(H9,"P",{});var Fla=s(R6e);nBr=r(Fla,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Fla.forEach(t),sBr=i(H9),ac=n(H9,"P",{});var Hme=s(ac);lBr=r(Hme,`Note:
Loading a model from its configuration file does `),P6e=n(Hme,"STRONG",{});var Tla=s(P6e);iBr=r(Tla,"not"),Tla.forEach(t),dBr=r(Hme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=n(Hme,"A",{href:!0});var Mla=s(Voe);mBr=r(Mla,"from_pretrained()"),Mla.forEach(t),cBr=r(Hme," to load the model weights."),Hme.forEach(t),fBr=i(H9),T(p5.$$.fragment,H9),H9.forEach(t),gBr=i(fi),Ao=n(fi,"DIV",{class:!0});var Za=s(Ao);T(aR.$$.fragment,Za),hBr=i(Za),B6e=n(Za,"P",{});var Ela=s(B6e);uBr=r(Ela,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Ela.forEach(t),pBr=i(Za),Rn=n(Za,"P",{});var J9=s(Rn);_Br=r(J9,"The model class to instantiate is selected based on the "),I6e=n(J9,"CODE",{});var Cla=s(I6e);bBr=r(Cla,"model_type"),Cla.forEach(t),vBr=r(J9,` property of the config object (either
passed as an argument or loaded from `),N6e=n(J9,"CODE",{});var wla=s(N6e);FBr=r(wla,"pretrained_model_name_or_path"),wla.forEach(t),TBr=r(J9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q6e=n(J9,"CODE",{});var Ala=s(q6e);MBr=r(Ala,"pretrained_model_name_or_path"),Ala.forEach(t),EBr=r(J9,":"),J9.forEach(t),CBr=i(Za),j6e=n(Za,"UL",{});var Lla=s(j6e);_5=n(Lla,"LI",{});var DJe=s(_5);D6e=n(DJe,"STRONG",{});var yla=s(D6e);wBr=r(yla,"maskformer"),yla.forEach(t),ABr=r(DJe," \u2014 "),Xoe=n(DJe,"A",{href:!0});var xla=s(Xoe);LBr=r(xla,"MaskFormerForInstanceSegmentation"),xla.forEach(t),yBr=r(DJe," (MaskFormer model)"),DJe.forEach(t),Lla.forEach(t),xBr=i(Za),b5=n(Za,"P",{});var GJe=s(b5);$Br=r(GJe,"The model is set in evaluation mode by default using "),G6e=n(GJe,"CODE",{});var $la=s(G6e);kBr=r($la,"model.eval()"),$la.forEach(t),SBr=r(GJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O6e=n(GJe,"CODE",{});var kla=s(O6e);RBr=r(kla,"model.train()"),kla.forEach(t),GJe.forEach(t),PBr=i(Za),T(v5.$$.fragment,Za),Za.forEach(t),fi.forEach(t),Tao=i(c),nc=n(c,"H2",{class:!0});var Dso=s(nc);F5=n(Dso,"A",{id:!0,class:!0,href:!0});var Sla=s(F5);V6e=n(Sla,"SPAN",{});var Rla=s(V6e);T(nR.$$.fragment,Rla),Rla.forEach(t),Sla.forEach(t),BBr=i(Dso),X6e=n(Dso,"SPAN",{});var Pla=s(X6e);IBr=r(Pla,"AutoModelForZeroShotObjectDetection"),Pla.forEach(t),Dso.forEach(t),Mao=i(c),dr=n(c,"DIV",{class:!0});var gi=s(dr);T(sR.$$.fragment,gi),NBr=i(gi),sc=n(gi,"P",{});var Jme=s(sc);qBr=r(Jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),zoe=n(Jme,"A",{href:!0});var Bla=s(zoe);jBr=r(Bla,"from_pretrained()"),Bla.forEach(t),DBr=r(Jme," class method or the "),Qoe=n(Jme,"A",{href:!0});var Ila=s(Qoe);GBr=r(Ila,"from_config()"),Ila.forEach(t),OBr=r(Jme,` class
method.`),Jme.forEach(t),VBr=i(gi),lR=n(gi,"P",{});var Gso=s(lR);XBr=r(Gso,"This class cannot be instantiated directly using "),z6e=n(Gso,"CODE",{});var Nla=s(z6e);zBr=r(Nla,"__init__()"),Nla.forEach(t),QBr=r(Gso," (throws an error)."),Gso.forEach(t),WBr=i(gi),Ht=n(gi,"DIV",{class:!0});var Y9=s(Ht);T(iR.$$.fragment,Y9),UBr=i(Y9),Q6e=n(Y9,"P",{});var qla=s(Q6e);HBr=r(qla,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),qla.forEach(t),JBr=i(Y9),lc=n(Y9,"P",{});var Yme=s(lc);YBr=r(Yme,`Note:
Loading a model from its configuration file does `),W6e=n(Yme,"STRONG",{});var jla=s(W6e);ZBr=r(jla,"not"),jla.forEach(t),KBr=r(Yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Woe=n(Yme,"A",{href:!0});var Dla=s(Woe);eIr=r(Dla,"from_pretrained()"),Dla.forEach(t),oIr=r(Yme," to load the model weights."),Yme.forEach(t),rIr=i(Y9),T(T5.$$.fragment,Y9),Y9.forEach(t),tIr=i(gi),Lo=n(gi,"DIV",{class:!0});var Ka=s(Lo);T(dR.$$.fragment,Ka),aIr=i(Ka),U6e=n(Ka,"P",{});var Gla=s(U6e);nIr=r(Gla,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Gla.forEach(t),sIr=i(Ka),Pn=n(Ka,"P",{});var Z9=s(Pn);lIr=r(Z9,"The model class to instantiate is selected based on the "),H6e=n(Z9,"CODE",{});var Ola=s(H6e);iIr=r(Ola,"model_type"),Ola.forEach(t),dIr=r(Z9,` property of the config object (either
passed as an argument or loaded from `),J6e=n(Z9,"CODE",{});var Vla=s(J6e);mIr=r(Vla,"pretrained_model_name_or_path"),Vla.forEach(t),cIr=r(Z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=n(Z9,"CODE",{});var Xla=s(Y6e);fIr=r(Xla,"pretrained_model_name_or_path"),Xla.forEach(t),gIr=r(Z9,":"),Z9.forEach(t),hIr=i(Ka),Z6e=n(Ka,"UL",{});var zla=s(Z6e);M5=n(zla,"LI",{});var OJe=s(M5);K6e=n(OJe,"STRONG",{});var Qla=s(K6e);uIr=r(Qla,"owlvit"),Qla.forEach(t),pIr=r(OJe," \u2014 "),Uoe=n(OJe,"A",{href:!0});var Wla=s(Uoe);_Ir=r(Wla,"OwlViTForObjectDetection"),Wla.forEach(t),bIr=r(OJe," (OWL-ViT model)"),OJe.forEach(t),zla.forEach(t),vIr=i(Ka),E5=n(Ka,"P",{});var VJe=s(E5);FIr=r(VJe,"The model is set in evaluation mode by default using "),e7e=n(VJe,"CODE",{});var Ula=s(e7e);TIr=r(Ula,"model.eval()"),Ula.forEach(t),MIr=r(VJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o7e=n(VJe,"CODE",{});var Hla=s(o7e);EIr=r(Hla,"model.train()"),Hla.forEach(t),VJe.forEach(t),CIr=i(Ka),T(C5.$$.fragment,Ka),Ka.forEach(t),gi.forEach(t),Eao=i(c),ic=n(c,"H2",{class:!0});var Oso=s(ic);w5=n(Oso,"A",{id:!0,class:!0,href:!0});var Jla=s(w5);r7e=n(Jla,"SPAN",{});var Yla=s(r7e);T(mR.$$.fragment,Yla),Yla.forEach(t),Jla.forEach(t),wIr=i(Oso),t7e=n(Oso,"SPAN",{});var Zla=s(t7e);AIr=r(Zla,"TFAutoModel"),Zla.forEach(t),Oso.forEach(t),Cao=i(c),mr=n(c,"DIV",{class:!0});var hi=s(mr);T(cR.$$.fragment,hi),LIr=i(hi),dc=n(hi,"P",{});var Zme=s(dc);yIr=r(Zme,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Hoe=n(Zme,"A",{href:!0});var Kla=s(Hoe);xIr=r(Kla,"from_pretrained()"),Kla.forEach(t),$Ir=r(Zme," class method or the "),Joe=n(Zme,"A",{href:!0});var eia=s(Joe);kIr=r(eia,"from_config()"),eia.forEach(t),SIr=r(Zme,` class
method.`),Zme.forEach(t),RIr=i(hi),fR=n(hi,"P",{});var Vso=s(fR);PIr=r(Vso,"This class cannot be instantiated directly using "),a7e=n(Vso,"CODE",{});var oia=s(a7e);BIr=r(oia,"__init__()"),oia.forEach(t),IIr=r(Vso," (throws an error)."),Vso.forEach(t),NIr=i(hi),Jt=n(hi,"DIV",{class:!0});var K9=s(Jt);T(gR.$$.fragment,K9),qIr=i(K9),n7e=n(K9,"P",{});var ria=s(n7e);jIr=r(ria,"Instantiates one of the base model classes of the library from a configuration."),ria.forEach(t),DIr=i(K9),mc=n(K9,"P",{});var Kme=s(mc);GIr=r(Kme,`Note:
Loading a model from its configuration file does `),s7e=n(Kme,"STRONG",{});var tia=s(s7e);OIr=r(tia,"not"),tia.forEach(t),VIr=r(Kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yoe=n(Kme,"A",{href:!0});var aia=s(Yoe);XIr=r(aia,"from_pretrained()"),aia.forEach(t),zIr=r(Kme," to load the model weights."),Kme.forEach(t),QIr=i(K9),T(A5.$$.fragment,K9),K9.forEach(t),WIr=i(hi),Dr=n(hi,"DIV",{class:!0});var ui=s(Dr);T(hR.$$.fragment,ui),UIr=i(ui),l7e=n(ui,"P",{});var nia=s(l7e);HIr=r(nia,"Instantiate one of the base model classes of the library from a pretrained model."),nia.forEach(t),JIr=i(ui),Bn=n(ui,"P",{});var ex=s(Bn);YIr=r(ex,"The model class to instantiate is selected based on the "),i7e=n(ex,"CODE",{});var sia=s(i7e);ZIr=r(sia,"model_type"),sia.forEach(t),KIr=r(ex,` property of the config object (either
passed as an argument or loaded from `),d7e=n(ex,"CODE",{});var lia=s(d7e);eNr=r(lia,"pretrained_model_name_or_path"),lia.forEach(t),oNr=r(ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m7e=n(ex,"CODE",{});var iia=s(m7e);rNr=r(iia,"pretrained_model_name_or_path"),iia.forEach(t),tNr=r(ex,":"),ex.forEach(t),aNr=i(ui),P=n(ui,"UL",{});var I=s(P);L5=n(I,"LI",{});var XJe=s(L5);c7e=n(XJe,"STRONG",{});var dia=s(c7e);nNr=r(dia,"albert"),dia.forEach(t),sNr=r(XJe," \u2014 "),Zoe=n(XJe,"A",{href:!0});var mia=s(Zoe);lNr=r(mia,"TFAlbertModel"),mia.forEach(t),iNr=r(XJe," (ALBERT model)"),XJe.forEach(t),dNr=i(I),y5=n(I,"LI",{});var zJe=s(y5);f7e=n(zJe,"STRONG",{});var cia=s(f7e);mNr=r(cia,"bart"),cia.forEach(t),cNr=r(zJe," \u2014 "),Koe=n(zJe,"A",{href:!0});var fia=s(Koe);fNr=r(fia,"TFBartModel"),fia.forEach(t),gNr=r(zJe," (BART model)"),zJe.forEach(t),hNr=i(I),x5=n(I,"LI",{});var QJe=s(x5);g7e=n(QJe,"STRONG",{});var gia=s(g7e);uNr=r(gia,"bert"),gia.forEach(t),pNr=r(QJe," \u2014 "),ere=n(QJe,"A",{href:!0});var hia=s(ere);_Nr=r(hia,"TFBertModel"),hia.forEach(t),bNr=r(QJe," (BERT model)"),QJe.forEach(t),vNr=i(I),$5=n(I,"LI",{});var WJe=s($5);h7e=n(WJe,"STRONG",{});var uia=s(h7e);FNr=r(uia,"blenderbot"),uia.forEach(t),TNr=r(WJe," \u2014 "),ore=n(WJe,"A",{href:!0});var pia=s(ore);MNr=r(pia,"TFBlenderbotModel"),pia.forEach(t),ENr=r(WJe," (Blenderbot model)"),WJe.forEach(t),CNr=i(I),k5=n(I,"LI",{});var UJe=s(k5);u7e=n(UJe,"STRONG",{});var _ia=s(u7e);wNr=r(_ia,"blenderbot-small"),_ia.forEach(t),ANr=r(UJe," \u2014 "),rre=n(UJe,"A",{href:!0});var bia=s(rre);LNr=r(bia,"TFBlenderbotSmallModel"),bia.forEach(t),yNr=r(UJe," (BlenderbotSmall model)"),UJe.forEach(t),xNr=i(I),S5=n(I,"LI",{});var HJe=s(S5);p7e=n(HJe,"STRONG",{});var via=s(p7e);$Nr=r(via,"camembert"),via.forEach(t),kNr=r(HJe," \u2014 "),tre=n(HJe,"A",{href:!0});var Fia=s(tre);SNr=r(Fia,"TFCamembertModel"),Fia.forEach(t),RNr=r(HJe," (CamemBERT model)"),HJe.forEach(t),PNr=i(I),R5=n(I,"LI",{});var JJe=s(R5);_7e=n(JJe,"STRONG",{});var Tia=s(_7e);BNr=r(Tia,"clip"),Tia.forEach(t),INr=r(JJe," \u2014 "),are=n(JJe,"A",{href:!0});var Mia=s(are);NNr=r(Mia,"TFCLIPModel"),Mia.forEach(t),qNr=r(JJe," (CLIP model)"),JJe.forEach(t),jNr=i(I),P5=n(I,"LI",{});var YJe=s(P5);b7e=n(YJe,"STRONG",{});var Eia=s(b7e);DNr=r(Eia,"convbert"),Eia.forEach(t),GNr=r(YJe," \u2014 "),nre=n(YJe,"A",{href:!0});var Cia=s(nre);ONr=r(Cia,"TFConvBertModel"),Cia.forEach(t),VNr=r(YJe," (ConvBERT model)"),YJe.forEach(t),XNr=i(I),B5=n(I,"LI",{});var ZJe=s(B5);v7e=n(ZJe,"STRONG",{});var wia=s(v7e);zNr=r(wia,"convnext"),wia.forEach(t),QNr=r(ZJe," \u2014 "),sre=n(ZJe,"A",{href:!0});var Aia=s(sre);WNr=r(Aia,"TFConvNextModel"),Aia.forEach(t),UNr=r(ZJe," (ConvNeXT model)"),ZJe.forEach(t),HNr=i(I),I5=n(I,"LI",{});var KJe=s(I5);F7e=n(KJe,"STRONG",{});var Lia=s(F7e);JNr=r(Lia,"ctrl"),Lia.forEach(t),YNr=r(KJe," \u2014 "),lre=n(KJe,"A",{href:!0});var yia=s(lre);ZNr=r(yia,"TFCTRLModel"),yia.forEach(t),KNr=r(KJe," (CTRL model)"),KJe.forEach(t),eqr=i(I),N5=n(I,"LI",{});var eYe=s(N5);T7e=n(eYe,"STRONG",{});var xia=s(T7e);oqr=r(xia,"cvt"),xia.forEach(t),rqr=r(eYe," \u2014 "),ire=n(eYe,"A",{href:!0});var $ia=s(ire);tqr=r($ia,"TFCvtModel"),$ia.forEach(t),aqr=r(eYe," (CvT model)"),eYe.forEach(t),nqr=i(I),q5=n(I,"LI",{});var oYe=s(q5);M7e=n(oYe,"STRONG",{});var kia=s(M7e);sqr=r(kia,"data2vec-vision"),kia.forEach(t),lqr=r(oYe," \u2014 "),dre=n(oYe,"A",{href:!0});var Sia=s(dre);iqr=r(Sia,"TFData2VecVisionModel"),Sia.forEach(t),dqr=r(oYe," (Data2VecVision model)"),oYe.forEach(t),mqr=i(I),j5=n(I,"LI",{});var rYe=s(j5);E7e=n(rYe,"STRONG",{});var Ria=s(E7e);cqr=r(Ria,"deberta"),Ria.forEach(t),fqr=r(rYe," \u2014 "),mre=n(rYe,"A",{href:!0});var Pia=s(mre);gqr=r(Pia,"TFDebertaModel"),Pia.forEach(t),hqr=r(rYe," (DeBERTa model)"),rYe.forEach(t),uqr=i(I),D5=n(I,"LI",{});var tYe=s(D5);C7e=n(tYe,"STRONG",{});var Bia=s(C7e);pqr=r(Bia,"deberta-v2"),Bia.forEach(t),_qr=r(tYe," \u2014 "),cre=n(tYe,"A",{href:!0});var Iia=s(cre);bqr=r(Iia,"TFDebertaV2Model"),Iia.forEach(t),vqr=r(tYe," (DeBERTa-v2 model)"),tYe.forEach(t),Fqr=i(I),G5=n(I,"LI",{});var aYe=s(G5);w7e=n(aYe,"STRONG",{});var Nia=s(w7e);Tqr=r(Nia,"deit"),Nia.forEach(t),Mqr=r(aYe," \u2014 "),fre=n(aYe,"A",{href:!0});var qia=s(fre);Eqr=r(qia,"TFDeiTModel"),qia.forEach(t),Cqr=r(aYe," (DeiT model)"),aYe.forEach(t),wqr=i(I),O5=n(I,"LI",{});var nYe=s(O5);A7e=n(nYe,"STRONG",{});var jia=s(A7e);Aqr=r(jia,"distilbert"),jia.forEach(t),Lqr=r(nYe," \u2014 "),gre=n(nYe,"A",{href:!0});var Dia=s(gre);yqr=r(Dia,"TFDistilBertModel"),Dia.forEach(t),xqr=r(nYe," (DistilBERT model)"),nYe.forEach(t),$qr=i(I),V5=n(I,"LI",{});var sYe=s(V5);L7e=n(sYe,"STRONG",{});var Gia=s(L7e);kqr=r(Gia,"dpr"),Gia.forEach(t),Sqr=r(sYe," \u2014 "),hre=n(sYe,"A",{href:!0});var Oia=s(hre);Rqr=r(Oia,"TFDPRQuestionEncoder"),Oia.forEach(t),Pqr=r(sYe," (DPR model)"),sYe.forEach(t),Bqr=i(I),X5=n(I,"LI",{});var lYe=s(X5);y7e=n(lYe,"STRONG",{});var Via=s(y7e);Iqr=r(Via,"electra"),Via.forEach(t),Nqr=r(lYe," \u2014 "),ure=n(lYe,"A",{href:!0});var Xia=s(ure);qqr=r(Xia,"TFElectraModel"),Xia.forEach(t),jqr=r(lYe," (ELECTRA model)"),lYe.forEach(t),Dqr=i(I),z5=n(I,"LI",{});var iYe=s(z5);x7e=n(iYe,"STRONG",{});var zia=s(x7e);Gqr=r(zia,"esm"),zia.forEach(t),Oqr=r(iYe," \u2014 "),pre=n(iYe,"A",{href:!0});var Qia=s(pre);Vqr=r(Qia,"TFEsmModel"),Qia.forEach(t),Xqr=r(iYe," (ESM model)"),iYe.forEach(t),zqr=i(I),Q5=n(I,"LI",{});var dYe=s(Q5);$7e=n(dYe,"STRONG",{});var Wia=s($7e);Qqr=r(Wia,"flaubert"),Wia.forEach(t),Wqr=r(dYe," \u2014 "),_re=n(dYe,"A",{href:!0});var Uia=s(_re);Uqr=r(Uia,"TFFlaubertModel"),Uia.forEach(t),Hqr=r(dYe," (FlauBERT model)"),dYe.forEach(t),Jqr=i(I),kl=n(I,"LI",{});var uN=s(kl);k7e=n(uN,"STRONG",{});var Hia=s(k7e);Yqr=r(Hia,"funnel"),Hia.forEach(t),Zqr=r(uN," \u2014 "),bre=n(uN,"A",{href:!0});var Jia=s(bre);Kqr=r(Jia,"TFFunnelModel"),Jia.forEach(t),ejr=r(uN," or "),vre=n(uN,"A",{href:!0});var Yia=s(vre);ojr=r(Yia,"TFFunnelBaseModel"),Yia.forEach(t),rjr=r(uN," (Funnel Transformer model)"),uN.forEach(t),tjr=i(I),W5=n(I,"LI",{});var mYe=s(W5);S7e=n(mYe,"STRONG",{});var Zia=s(S7e);ajr=r(Zia,"gpt2"),Zia.forEach(t),njr=r(mYe," \u2014 "),Fre=n(mYe,"A",{href:!0});var Kia=s(Fre);sjr=r(Kia,"TFGPT2Model"),Kia.forEach(t),ljr=r(mYe," (OpenAI GPT-2 model)"),mYe.forEach(t),ijr=i(I),U5=n(I,"LI",{});var cYe=s(U5);R7e=n(cYe,"STRONG",{});var eda=s(R7e);djr=r(eda,"gptj"),eda.forEach(t),mjr=r(cYe," \u2014 "),Tre=n(cYe,"A",{href:!0});var oda=s(Tre);cjr=r(oda,"TFGPTJModel"),oda.forEach(t),fjr=r(cYe," (GPT-J model)"),cYe.forEach(t),gjr=i(I),H5=n(I,"LI",{});var fYe=s(H5);P7e=n(fYe,"STRONG",{});var rda=s(P7e);hjr=r(rda,"groupvit"),rda.forEach(t),ujr=r(fYe," \u2014 "),Mre=n(fYe,"A",{href:!0});var tda=s(Mre);pjr=r(tda,"TFGroupViTModel"),tda.forEach(t),_jr=r(fYe," (GroupViT model)"),fYe.forEach(t),bjr=i(I),J5=n(I,"LI",{});var gYe=s(J5);B7e=n(gYe,"STRONG",{});var ada=s(B7e);vjr=r(ada,"hubert"),ada.forEach(t),Fjr=r(gYe," \u2014 "),Ere=n(gYe,"A",{href:!0});var nda=s(Ere);Tjr=r(nda,"TFHubertModel"),nda.forEach(t),Mjr=r(gYe," (Hubert model)"),gYe.forEach(t),Ejr=i(I),Y5=n(I,"LI",{});var hYe=s(Y5);I7e=n(hYe,"STRONG",{});var sda=s(I7e);Cjr=r(sda,"layoutlm"),sda.forEach(t),wjr=r(hYe," \u2014 "),Cre=n(hYe,"A",{href:!0});var lda=s(Cre);Ajr=r(lda,"TFLayoutLMModel"),lda.forEach(t),Ljr=r(hYe," (LayoutLM model)"),hYe.forEach(t),yjr=i(I),Z5=n(I,"LI",{});var uYe=s(Z5);N7e=n(uYe,"STRONG",{});var ida=s(N7e);xjr=r(ida,"layoutlmv3"),ida.forEach(t),$jr=r(uYe," \u2014 "),wre=n(uYe,"A",{href:!0});var dda=s(wre);kjr=r(dda,"TFLayoutLMv3Model"),dda.forEach(t),Sjr=r(uYe," (LayoutLMv3 model)"),uYe.forEach(t),Rjr=i(I),K5=n(I,"LI",{});var pYe=s(K5);q7e=n(pYe,"STRONG",{});var mda=s(q7e);Pjr=r(mda,"led"),mda.forEach(t),Bjr=r(pYe," \u2014 "),Are=n(pYe,"A",{href:!0});var cda=s(Are);Ijr=r(cda,"TFLEDModel"),cda.forEach(t),Njr=r(pYe," (LED model)"),pYe.forEach(t),qjr=i(I),e0=n(I,"LI",{});var _Ye=s(e0);j7e=n(_Ye,"STRONG",{});var fda=s(j7e);jjr=r(fda,"longformer"),fda.forEach(t),Djr=r(_Ye," \u2014 "),Lre=n(_Ye,"A",{href:!0});var gda=s(Lre);Gjr=r(gda,"TFLongformerModel"),gda.forEach(t),Ojr=r(_Ye," (Longformer model)"),_Ye.forEach(t),Vjr=i(I),o0=n(I,"LI",{});var bYe=s(o0);D7e=n(bYe,"STRONG",{});var hda=s(D7e);Xjr=r(hda,"lxmert"),hda.forEach(t),zjr=r(bYe," \u2014 "),yre=n(bYe,"A",{href:!0});var uda=s(yre);Qjr=r(uda,"TFLxmertModel"),uda.forEach(t),Wjr=r(bYe," (LXMERT model)"),bYe.forEach(t),Ujr=i(I),r0=n(I,"LI",{});var vYe=s(r0);G7e=n(vYe,"STRONG",{});var pda=s(G7e);Hjr=r(pda,"marian"),pda.forEach(t),Jjr=r(vYe," \u2014 "),xre=n(vYe,"A",{href:!0});var _da=s(xre);Yjr=r(_da,"TFMarianModel"),_da.forEach(t),Zjr=r(vYe," (Marian model)"),vYe.forEach(t),Kjr=i(I),t0=n(I,"LI",{});var FYe=s(t0);O7e=n(FYe,"STRONG",{});var bda=s(O7e);eDr=r(bda,"mbart"),bda.forEach(t),oDr=r(FYe," \u2014 "),$re=n(FYe,"A",{href:!0});var vda=s($re);rDr=r(vda,"TFMBartModel"),vda.forEach(t),tDr=r(FYe," (mBART model)"),FYe.forEach(t),aDr=i(I),a0=n(I,"LI",{});var TYe=s(a0);V7e=n(TYe,"STRONG",{});var Fda=s(V7e);nDr=r(Fda,"mobilebert"),Fda.forEach(t),sDr=r(TYe," \u2014 "),kre=n(TYe,"A",{href:!0});var Tda=s(kre);lDr=r(Tda,"TFMobileBertModel"),Tda.forEach(t),iDr=r(TYe," (MobileBERT model)"),TYe.forEach(t),dDr=i(I),n0=n(I,"LI",{});var MYe=s(n0);X7e=n(MYe,"STRONG",{});var Mda=s(X7e);mDr=r(Mda,"mobilevit"),Mda.forEach(t),cDr=r(MYe," \u2014 "),Sre=n(MYe,"A",{href:!0});var Eda=s(Sre);fDr=r(Eda,"TFMobileViTModel"),Eda.forEach(t),gDr=r(MYe," (MobileViT model)"),MYe.forEach(t),hDr=i(I),s0=n(I,"LI",{});var EYe=s(s0);z7e=n(EYe,"STRONG",{});var Cda=s(z7e);uDr=r(Cda,"mpnet"),Cda.forEach(t),pDr=r(EYe," \u2014 "),Rre=n(EYe,"A",{href:!0});var wda=s(Rre);_Dr=r(wda,"TFMPNetModel"),wda.forEach(t),bDr=r(EYe," (MPNet model)"),EYe.forEach(t),vDr=i(I),l0=n(I,"LI",{});var CYe=s(l0);Q7e=n(CYe,"STRONG",{});var Ada=s(Q7e);FDr=r(Ada,"mt5"),Ada.forEach(t),TDr=r(CYe," \u2014 "),Pre=n(CYe,"A",{href:!0});var Lda=s(Pre);MDr=r(Lda,"TFMT5Model"),Lda.forEach(t),EDr=r(CYe," (MT5 model)"),CYe.forEach(t),CDr=i(I),i0=n(I,"LI",{});var wYe=s(i0);W7e=n(wYe,"STRONG",{});var yda=s(W7e);wDr=r(yda,"openai-gpt"),yda.forEach(t),ADr=r(wYe," \u2014 "),Bre=n(wYe,"A",{href:!0});var xda=s(Bre);LDr=r(xda,"TFOpenAIGPTModel"),xda.forEach(t),yDr=r(wYe," (OpenAI GPT model)"),wYe.forEach(t),xDr=i(I),d0=n(I,"LI",{});var AYe=s(d0);U7e=n(AYe,"STRONG",{});var $da=s(U7e);$Dr=r($da,"opt"),$da.forEach(t),kDr=r(AYe," \u2014 "),Ire=n(AYe,"A",{href:!0});var kda=s(Ire);SDr=r(kda,"TFOPTModel"),kda.forEach(t),RDr=r(AYe," (OPT model)"),AYe.forEach(t),PDr=i(I),m0=n(I,"LI",{});var LYe=s(m0);H7e=n(LYe,"STRONG",{});var Sda=s(H7e);BDr=r(Sda,"pegasus"),Sda.forEach(t),IDr=r(LYe," \u2014 "),Nre=n(LYe,"A",{href:!0});var Rda=s(Nre);NDr=r(Rda,"TFPegasusModel"),Rda.forEach(t),qDr=r(LYe," (Pegasus model)"),LYe.forEach(t),jDr=i(I),c0=n(I,"LI",{});var yYe=s(c0);J7e=n(yYe,"STRONG",{});var Pda=s(J7e);DDr=r(Pda,"regnet"),Pda.forEach(t),GDr=r(yYe," \u2014 "),qre=n(yYe,"A",{href:!0});var Bda=s(qre);ODr=r(Bda,"TFRegNetModel"),Bda.forEach(t),VDr=r(yYe," (RegNet model)"),yYe.forEach(t),XDr=i(I),f0=n(I,"LI",{});var xYe=s(f0);Y7e=n(xYe,"STRONG",{});var Ida=s(Y7e);zDr=r(Ida,"rembert"),Ida.forEach(t),QDr=r(xYe," \u2014 "),jre=n(xYe,"A",{href:!0});var Nda=s(jre);WDr=r(Nda,"TFRemBertModel"),Nda.forEach(t),UDr=r(xYe," (RemBERT model)"),xYe.forEach(t),HDr=i(I),g0=n(I,"LI",{});var $Ye=s(g0);Z7e=n($Ye,"STRONG",{});var qda=s(Z7e);JDr=r(qda,"resnet"),qda.forEach(t),YDr=r($Ye," \u2014 "),Dre=n($Ye,"A",{href:!0});var jda=s(Dre);ZDr=r(jda,"TFResNetModel"),jda.forEach(t),KDr=r($Ye," (ResNet model)"),$Ye.forEach(t),eGr=i(I),h0=n(I,"LI",{});var kYe=s(h0);K7e=n(kYe,"STRONG",{});var Dda=s(K7e);oGr=r(Dda,"roberta"),Dda.forEach(t),rGr=r(kYe," \u2014 "),Gre=n(kYe,"A",{href:!0});var Gda=s(Gre);tGr=r(Gda,"TFRobertaModel"),Gda.forEach(t),aGr=r(kYe," (RoBERTa model)"),kYe.forEach(t),nGr=i(I),u0=n(I,"LI",{});var SYe=s(u0);e8e=n(SYe,"STRONG",{});var Oda=s(e8e);sGr=r(Oda,"roformer"),Oda.forEach(t),lGr=r(SYe," \u2014 "),Ore=n(SYe,"A",{href:!0});var Vda=s(Ore);iGr=r(Vda,"TFRoFormerModel"),Vda.forEach(t),dGr=r(SYe," (RoFormer model)"),SYe.forEach(t),mGr=i(I),p0=n(I,"LI",{});var RYe=s(p0);o8e=n(RYe,"STRONG",{});var Xda=s(o8e);cGr=r(Xda,"segformer"),Xda.forEach(t),fGr=r(RYe," \u2014 "),Vre=n(RYe,"A",{href:!0});var zda=s(Vre);gGr=r(zda,"TFSegformerModel"),zda.forEach(t),hGr=r(RYe," (SegFormer model)"),RYe.forEach(t),uGr=i(I),_0=n(I,"LI",{});var PYe=s(_0);r8e=n(PYe,"STRONG",{});var Qda=s(r8e);pGr=r(Qda,"speech_to_text"),Qda.forEach(t),_Gr=r(PYe," \u2014 "),Xre=n(PYe,"A",{href:!0});var Wda=s(Xre);bGr=r(Wda,"TFSpeech2TextModel"),Wda.forEach(t),vGr=r(PYe," (Speech2Text model)"),PYe.forEach(t),FGr=i(I),b0=n(I,"LI",{});var BYe=s(b0);t8e=n(BYe,"STRONG",{});var Uda=s(t8e);TGr=r(Uda,"swin"),Uda.forEach(t),MGr=r(BYe," \u2014 "),zre=n(BYe,"A",{href:!0});var Hda=s(zre);EGr=r(Hda,"TFSwinModel"),Hda.forEach(t),CGr=r(BYe," (Swin Transformer model)"),BYe.forEach(t),wGr=i(I),v0=n(I,"LI",{});var IYe=s(v0);a8e=n(IYe,"STRONG",{});var Jda=s(a8e);AGr=r(Jda,"t5"),Jda.forEach(t),LGr=r(IYe," \u2014 "),Qre=n(IYe,"A",{href:!0});var Yda=s(Qre);yGr=r(Yda,"TFT5Model"),Yda.forEach(t),xGr=r(IYe," (T5 model)"),IYe.forEach(t),$Gr=i(I),F0=n(I,"LI",{});var NYe=s(F0);n8e=n(NYe,"STRONG",{});var Zda=s(n8e);kGr=r(Zda,"tapas"),Zda.forEach(t),SGr=r(NYe," \u2014 "),Wre=n(NYe,"A",{href:!0});var Kda=s(Wre);RGr=r(Kda,"TFTapasModel"),Kda.forEach(t),PGr=r(NYe," (TAPAS model)"),NYe.forEach(t),BGr=i(I),T0=n(I,"LI",{});var qYe=s(T0);s8e=n(qYe,"STRONG",{});var ema=s(s8e);IGr=r(ema,"transfo-xl"),ema.forEach(t),NGr=r(qYe," \u2014 "),Ure=n(qYe,"A",{href:!0});var oma=s(Ure);qGr=r(oma,"TFTransfoXLModel"),oma.forEach(t),jGr=r(qYe," (Transformer-XL model)"),qYe.forEach(t),DGr=i(I),M0=n(I,"LI",{});var jYe=s(M0);l8e=n(jYe,"STRONG",{});var rma=s(l8e);GGr=r(rma,"vit"),rma.forEach(t),OGr=r(jYe," \u2014 "),Hre=n(jYe,"A",{href:!0});var tma=s(Hre);VGr=r(tma,"TFViTModel"),tma.forEach(t),XGr=r(jYe," (ViT model)"),jYe.forEach(t),zGr=i(I),E0=n(I,"LI",{});var DYe=s(E0);i8e=n(DYe,"STRONG",{});var ama=s(i8e);QGr=r(ama,"vit_mae"),ama.forEach(t),WGr=r(DYe," \u2014 "),Jre=n(DYe,"A",{href:!0});var nma=s(Jre);UGr=r(nma,"TFViTMAEModel"),nma.forEach(t),HGr=r(DYe," (ViTMAE model)"),DYe.forEach(t),JGr=i(I),C0=n(I,"LI",{});var GYe=s(C0);d8e=n(GYe,"STRONG",{});var sma=s(d8e);YGr=r(sma,"wav2vec2"),sma.forEach(t),ZGr=r(GYe," \u2014 "),Yre=n(GYe,"A",{href:!0});var lma=s(Yre);KGr=r(lma,"TFWav2Vec2Model"),lma.forEach(t),eOr=r(GYe," (Wav2Vec2 model)"),GYe.forEach(t),oOr=i(I),w0=n(I,"LI",{});var OYe=s(w0);m8e=n(OYe,"STRONG",{});var ima=s(m8e);rOr=r(ima,"whisper"),ima.forEach(t),tOr=r(OYe," \u2014 "),Zre=n(OYe,"A",{href:!0});var dma=s(Zre);aOr=r(dma,"TFWhisperModel"),dma.forEach(t),nOr=r(OYe," (Whisper model)"),OYe.forEach(t),sOr=i(I),A0=n(I,"LI",{});var VYe=s(A0);c8e=n(VYe,"STRONG",{});var mma=s(c8e);lOr=r(mma,"xglm"),mma.forEach(t),iOr=r(VYe," \u2014 "),Kre=n(VYe,"A",{href:!0});var cma=s(Kre);dOr=r(cma,"TFXGLMModel"),cma.forEach(t),mOr=r(VYe," (XGLM model)"),VYe.forEach(t),cOr=i(I),L0=n(I,"LI",{});var XYe=s(L0);f8e=n(XYe,"STRONG",{});var fma=s(f8e);fOr=r(fma,"xlm"),fma.forEach(t),gOr=r(XYe," \u2014 "),ete=n(XYe,"A",{href:!0});var gma=s(ete);hOr=r(gma,"TFXLMModel"),gma.forEach(t),uOr=r(XYe," (XLM model)"),XYe.forEach(t),pOr=i(I),y0=n(I,"LI",{});var zYe=s(y0);g8e=n(zYe,"STRONG",{});var hma=s(g8e);_Or=r(hma,"xlm-roberta"),hma.forEach(t),bOr=r(zYe," \u2014 "),ote=n(zYe,"A",{href:!0});var uma=s(ote);vOr=r(uma,"TFXLMRobertaModel"),uma.forEach(t),FOr=r(zYe," (XLM-RoBERTa model)"),zYe.forEach(t),TOr=i(I),x0=n(I,"LI",{});var QYe=s(x0);h8e=n(QYe,"STRONG",{});var pma=s(h8e);MOr=r(pma,"xlnet"),pma.forEach(t),EOr=r(QYe," \u2014 "),rte=n(QYe,"A",{href:!0});var _ma=s(rte);COr=r(_ma,"TFXLNetModel"),_ma.forEach(t),wOr=r(QYe," (XLNet model)"),QYe.forEach(t),I.forEach(t),AOr=i(ui),T($0.$$.fragment,ui),ui.forEach(t),hi.forEach(t),wao=i(c),cc=n(c,"H2",{class:!0});var Xso=s(cc);k0=n(Xso,"A",{id:!0,class:!0,href:!0});var bma=s(k0);u8e=n(bma,"SPAN",{});var vma=s(u8e);T(uR.$$.fragment,vma),vma.forEach(t),bma.forEach(t),LOr=i(Xso),p8e=n(Xso,"SPAN",{});var Fma=s(p8e);yOr=r(Fma,"TFAutoModelForPreTraining"),Fma.forEach(t),Xso.forEach(t),Aao=i(c),cr=n(c,"DIV",{class:!0});var pi=s(cr);T(pR.$$.fragment,pi),xOr=i(pi),fc=n(pi,"P",{});var ece=s(fc);$Or=r(ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),tte=n(ece,"A",{href:!0});var Tma=s(tte);kOr=r(Tma,"from_pretrained()"),Tma.forEach(t),SOr=r(ece," class method or the "),ate=n(ece,"A",{href:!0});var Mma=s(ate);ROr=r(Mma,"from_config()"),Mma.forEach(t),POr=r(ece,` class
method.`),ece.forEach(t),BOr=i(pi),_R=n(pi,"P",{});var zso=s(_R);IOr=r(zso,"This class cannot be instantiated directly using "),_8e=n(zso,"CODE",{});var Ema=s(_8e);NOr=r(Ema,"__init__()"),Ema.forEach(t),qOr=r(zso," (throws an error)."),zso.forEach(t),jOr=i(pi),Yt=n(pi,"DIV",{class:!0});var ox=s(Yt);T(bR.$$.fragment,ox),DOr=i(ox),b8e=n(ox,"P",{});var Cma=s(b8e);GOr=r(Cma,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Cma.forEach(t),OOr=i(ox),gc=n(ox,"P",{});var oce=s(gc);VOr=r(oce,`Note:
Loading a model from its configuration file does `),v8e=n(oce,"STRONG",{});var wma=s(v8e);XOr=r(wma,"not"),wma.forEach(t),zOr=r(oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),nte=n(oce,"A",{href:!0});var Ama=s(nte);QOr=r(Ama,"from_pretrained()"),Ama.forEach(t),WOr=r(oce," to load the model weights."),oce.forEach(t),UOr=i(ox),T(S0.$$.fragment,ox),ox.forEach(t),HOr=i(pi),Gr=n(pi,"DIV",{class:!0});var _i=s(Gr);T(vR.$$.fragment,_i),JOr=i(_i),F8e=n(_i,"P",{});var Lma=s(F8e);YOr=r(Lma,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Lma.forEach(t),ZOr=i(_i),In=n(_i,"P",{});var rx=s(In);KOr=r(rx,"The model class to instantiate is selected based on the "),T8e=n(rx,"CODE",{});var yma=s(T8e);eVr=r(yma,"model_type"),yma.forEach(t),oVr=r(rx,` property of the config object (either
passed as an argument or loaded from `),M8e=n(rx,"CODE",{});var xma=s(M8e);rVr=r(xma,"pretrained_model_name_or_path"),xma.forEach(t),tVr=r(rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E8e=n(rx,"CODE",{});var $ma=s(E8e);aVr=r($ma,"pretrained_model_name_or_path"),$ma.forEach(t),nVr=r(rx,":"),rx.forEach(t),sVr=i(_i),le=n(_i,"UL",{});var me=s(le);R0=n(me,"LI",{});var WYe=s(R0);C8e=n(WYe,"STRONG",{});var kma=s(C8e);lVr=r(kma,"albert"),kma.forEach(t),iVr=r(WYe," \u2014 "),ste=n(WYe,"A",{href:!0});var Sma=s(ste);dVr=r(Sma,"TFAlbertForPreTraining"),Sma.forEach(t),mVr=r(WYe," (ALBERT model)"),WYe.forEach(t),cVr=i(me),P0=n(me,"LI",{});var UYe=s(P0);w8e=n(UYe,"STRONG",{});var Rma=s(w8e);fVr=r(Rma,"bart"),Rma.forEach(t),gVr=r(UYe," \u2014 "),lte=n(UYe,"A",{href:!0});var Pma=s(lte);hVr=r(Pma,"TFBartForConditionalGeneration"),Pma.forEach(t),uVr=r(UYe," (BART model)"),UYe.forEach(t),pVr=i(me),B0=n(me,"LI",{});var HYe=s(B0);A8e=n(HYe,"STRONG",{});var Bma=s(A8e);_Vr=r(Bma,"bert"),Bma.forEach(t),bVr=r(HYe," \u2014 "),ite=n(HYe,"A",{href:!0});var Ima=s(ite);vVr=r(Ima,"TFBertForPreTraining"),Ima.forEach(t),FVr=r(HYe," (BERT model)"),HYe.forEach(t),TVr=i(me),I0=n(me,"LI",{});var JYe=s(I0);L8e=n(JYe,"STRONG",{});var Nma=s(L8e);MVr=r(Nma,"camembert"),Nma.forEach(t),EVr=r(JYe," \u2014 "),dte=n(JYe,"A",{href:!0});var qma=s(dte);CVr=r(qma,"TFCamembertForMaskedLM"),qma.forEach(t),wVr=r(JYe," (CamemBERT model)"),JYe.forEach(t),AVr=i(me),N0=n(me,"LI",{});var YYe=s(N0);y8e=n(YYe,"STRONG",{});var jma=s(y8e);LVr=r(jma,"ctrl"),jma.forEach(t),yVr=r(YYe," \u2014 "),mte=n(YYe,"A",{href:!0});var Dma=s(mte);xVr=r(Dma,"TFCTRLLMHeadModel"),Dma.forEach(t),$Vr=r(YYe," (CTRL model)"),YYe.forEach(t),kVr=i(me),q0=n(me,"LI",{});var ZYe=s(q0);x8e=n(ZYe,"STRONG",{});var Gma=s(x8e);SVr=r(Gma,"distilbert"),Gma.forEach(t),RVr=r(ZYe," \u2014 "),cte=n(ZYe,"A",{href:!0});var Oma=s(cte);PVr=r(Oma,"TFDistilBertForMaskedLM"),Oma.forEach(t),BVr=r(ZYe," (DistilBERT model)"),ZYe.forEach(t),IVr=i(me),j0=n(me,"LI",{});var KYe=s(j0);$8e=n(KYe,"STRONG",{});var Vma=s($8e);NVr=r(Vma,"electra"),Vma.forEach(t),qVr=r(KYe," \u2014 "),fte=n(KYe,"A",{href:!0});var Xma=s(fte);jVr=r(Xma,"TFElectraForPreTraining"),Xma.forEach(t),DVr=r(KYe," (ELECTRA model)"),KYe.forEach(t),GVr=i(me),D0=n(me,"LI",{});var eZe=s(D0);k8e=n(eZe,"STRONG",{});var zma=s(k8e);OVr=r(zma,"flaubert"),zma.forEach(t),VVr=r(eZe," \u2014 "),gte=n(eZe,"A",{href:!0});var Qma=s(gte);XVr=r(Qma,"TFFlaubertWithLMHeadModel"),Qma.forEach(t),zVr=r(eZe," (FlauBERT model)"),eZe.forEach(t),QVr=i(me),G0=n(me,"LI",{});var oZe=s(G0);S8e=n(oZe,"STRONG",{});var Wma=s(S8e);WVr=r(Wma,"funnel"),Wma.forEach(t),UVr=r(oZe," \u2014 "),hte=n(oZe,"A",{href:!0});var Uma=s(hte);HVr=r(Uma,"TFFunnelForPreTraining"),Uma.forEach(t),JVr=r(oZe," (Funnel Transformer model)"),oZe.forEach(t),YVr=i(me),O0=n(me,"LI",{});var rZe=s(O0);R8e=n(rZe,"STRONG",{});var Hma=s(R8e);ZVr=r(Hma,"gpt2"),Hma.forEach(t),KVr=r(rZe," \u2014 "),ute=n(rZe,"A",{href:!0});var Jma=s(ute);eXr=r(Jma,"TFGPT2LMHeadModel"),Jma.forEach(t),oXr=r(rZe," (OpenAI GPT-2 model)"),rZe.forEach(t),rXr=i(me),V0=n(me,"LI",{});var tZe=s(V0);P8e=n(tZe,"STRONG",{});var Yma=s(P8e);tXr=r(Yma,"layoutlm"),Yma.forEach(t),aXr=r(tZe," \u2014 "),pte=n(tZe,"A",{href:!0});var Zma=s(pte);nXr=r(Zma,"TFLayoutLMForMaskedLM"),Zma.forEach(t),sXr=r(tZe," (LayoutLM model)"),tZe.forEach(t),lXr=i(me),X0=n(me,"LI",{});var aZe=s(X0);B8e=n(aZe,"STRONG",{});var Kma=s(B8e);iXr=r(Kma,"lxmert"),Kma.forEach(t),dXr=r(aZe," \u2014 "),_te=n(aZe,"A",{href:!0});var eca=s(_te);mXr=r(eca,"TFLxmertForPreTraining"),eca.forEach(t),cXr=r(aZe," (LXMERT model)"),aZe.forEach(t),fXr=i(me),z0=n(me,"LI",{});var nZe=s(z0);I8e=n(nZe,"STRONG",{});var oca=s(I8e);gXr=r(oca,"mobilebert"),oca.forEach(t),hXr=r(nZe," \u2014 "),bte=n(nZe,"A",{href:!0});var rca=s(bte);uXr=r(rca,"TFMobileBertForPreTraining"),rca.forEach(t),pXr=r(nZe," (MobileBERT model)"),nZe.forEach(t),_Xr=i(me),Q0=n(me,"LI",{});var sZe=s(Q0);N8e=n(sZe,"STRONG",{});var tca=s(N8e);bXr=r(tca,"mpnet"),tca.forEach(t),vXr=r(sZe," \u2014 "),vte=n(sZe,"A",{href:!0});var aca=s(vte);FXr=r(aca,"TFMPNetForMaskedLM"),aca.forEach(t),TXr=r(sZe," (MPNet model)"),sZe.forEach(t),MXr=i(me),W0=n(me,"LI",{});var lZe=s(W0);q8e=n(lZe,"STRONG",{});var nca=s(q8e);EXr=r(nca,"openai-gpt"),nca.forEach(t),CXr=r(lZe," \u2014 "),Fte=n(lZe,"A",{href:!0});var sca=s(Fte);wXr=r(sca,"TFOpenAIGPTLMHeadModel"),sca.forEach(t),AXr=r(lZe," (OpenAI GPT model)"),lZe.forEach(t),LXr=i(me),U0=n(me,"LI",{});var iZe=s(U0);j8e=n(iZe,"STRONG",{});var lca=s(j8e);yXr=r(lca,"roberta"),lca.forEach(t),xXr=r(iZe," \u2014 "),Tte=n(iZe,"A",{href:!0});var ica=s(Tte);$Xr=r(ica,"TFRobertaForMaskedLM"),ica.forEach(t),kXr=r(iZe," (RoBERTa model)"),iZe.forEach(t),SXr=i(me),H0=n(me,"LI",{});var dZe=s(H0);D8e=n(dZe,"STRONG",{});var dca=s(D8e);RXr=r(dca,"t5"),dca.forEach(t),PXr=r(dZe," \u2014 "),Mte=n(dZe,"A",{href:!0});var mca=s(Mte);BXr=r(mca,"TFT5ForConditionalGeneration"),mca.forEach(t),IXr=r(dZe," (T5 model)"),dZe.forEach(t),NXr=i(me),J0=n(me,"LI",{});var mZe=s(J0);G8e=n(mZe,"STRONG",{});var cca=s(G8e);qXr=r(cca,"tapas"),cca.forEach(t),jXr=r(mZe," \u2014 "),Ete=n(mZe,"A",{href:!0});var fca=s(Ete);DXr=r(fca,"TFTapasForMaskedLM"),fca.forEach(t),GXr=r(mZe," (TAPAS model)"),mZe.forEach(t),OXr=i(me),Y0=n(me,"LI",{});var cZe=s(Y0);O8e=n(cZe,"STRONG",{});var gca=s(O8e);VXr=r(gca,"transfo-xl"),gca.forEach(t),XXr=r(cZe," \u2014 "),Cte=n(cZe,"A",{href:!0});var hca=s(Cte);zXr=r(hca,"TFTransfoXLLMHeadModel"),hca.forEach(t),QXr=r(cZe," (Transformer-XL model)"),cZe.forEach(t),WXr=i(me),Z0=n(me,"LI",{});var fZe=s(Z0);V8e=n(fZe,"STRONG",{});var uca=s(V8e);UXr=r(uca,"vit_mae"),uca.forEach(t),HXr=r(fZe," \u2014 "),wte=n(fZe,"A",{href:!0});var pca=s(wte);JXr=r(pca,"TFViTMAEForPreTraining"),pca.forEach(t),YXr=r(fZe," (ViTMAE model)"),fZe.forEach(t),ZXr=i(me),K0=n(me,"LI",{});var gZe=s(K0);X8e=n(gZe,"STRONG",{});var _ca=s(X8e);KXr=r(_ca,"xlm"),_ca.forEach(t),ezr=r(gZe," \u2014 "),Ate=n(gZe,"A",{href:!0});var bca=s(Ate);ozr=r(bca,"TFXLMWithLMHeadModel"),bca.forEach(t),rzr=r(gZe," (XLM model)"),gZe.forEach(t),tzr=i(me),ew=n(me,"LI",{});var hZe=s(ew);z8e=n(hZe,"STRONG",{});var vca=s(z8e);azr=r(vca,"xlm-roberta"),vca.forEach(t),nzr=r(hZe," \u2014 "),Lte=n(hZe,"A",{href:!0});var Fca=s(Lte);szr=r(Fca,"TFXLMRobertaForMaskedLM"),Fca.forEach(t),lzr=r(hZe," (XLM-RoBERTa model)"),hZe.forEach(t),izr=i(me),ow=n(me,"LI",{});var uZe=s(ow);Q8e=n(uZe,"STRONG",{});var Tca=s(Q8e);dzr=r(Tca,"xlnet"),Tca.forEach(t),mzr=r(uZe," \u2014 "),yte=n(uZe,"A",{href:!0});var Mca=s(yte);czr=r(Mca,"TFXLNetLMHeadModel"),Mca.forEach(t),fzr=r(uZe," (XLNet model)"),uZe.forEach(t),me.forEach(t),gzr=i(_i),T(rw.$$.fragment,_i),_i.forEach(t),pi.forEach(t),Lao=i(c),hc=n(c,"H2",{class:!0});var Qso=s(hc);tw=n(Qso,"A",{id:!0,class:!0,href:!0});var Eca=s(tw);W8e=n(Eca,"SPAN",{});var Cca=s(W8e);T(FR.$$.fragment,Cca),Cca.forEach(t),Eca.forEach(t),hzr=i(Qso),U8e=n(Qso,"SPAN",{});var wca=s(U8e);uzr=r(wca,"TFAutoModelForCausalLM"),wca.forEach(t),Qso.forEach(t),yao=i(c),fr=n(c,"DIV",{class:!0});var bi=s(fr);T(TR.$$.fragment,bi),pzr=i(bi),uc=n(bi,"P",{});var rce=s(uc);_zr=r(rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),xte=n(rce,"A",{href:!0});var Aca=s(xte);bzr=r(Aca,"from_pretrained()"),Aca.forEach(t),vzr=r(rce," class method or the "),$te=n(rce,"A",{href:!0});var Lca=s($te);Fzr=r(Lca,"from_config()"),Lca.forEach(t),Tzr=r(rce,` class
method.`),rce.forEach(t),Mzr=i(bi),MR=n(bi,"P",{});var Wso=s(MR);Ezr=r(Wso,"This class cannot be instantiated directly using "),H8e=n(Wso,"CODE",{});var yca=s(H8e);Czr=r(yca,"__init__()"),yca.forEach(t),wzr=r(Wso," (throws an error)."),Wso.forEach(t),Azr=i(bi),Zt=n(bi,"DIV",{class:!0});var tx=s(Zt);T(ER.$$.fragment,tx),Lzr=i(tx),J8e=n(tx,"P",{});var xca=s(J8e);yzr=r(xca,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),xca.forEach(t),xzr=i(tx),pc=n(tx,"P",{});var tce=s(pc);$zr=r(tce,`Note:
Loading a model from its configuration file does `),Y8e=n(tce,"STRONG",{});var $ca=s(Y8e);kzr=r($ca,"not"),$ca.forEach(t),Szr=r(tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),kte=n(tce,"A",{href:!0});var kca=s(kte);Rzr=r(kca,"from_pretrained()"),kca.forEach(t),Pzr=r(tce," to load the model weights."),tce.forEach(t),Bzr=i(tx),T(aw.$$.fragment,tx),tx.forEach(t),Izr=i(bi),Or=n(bi,"DIV",{class:!0});var vi=s(Or);T(CR.$$.fragment,vi),Nzr=i(vi),Z8e=n(vi,"P",{});var Sca=s(Z8e);qzr=r(Sca,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Sca.forEach(t),jzr=i(vi),Nn=n(vi,"P",{});var ax=s(Nn);Dzr=r(ax,"The model class to instantiate is selected based on the "),K8e=n(ax,"CODE",{});var Rca=s(K8e);Gzr=r(Rca,"model_type"),Rca.forEach(t),Ozr=r(ax,` property of the config object (either
passed as an argument or loaded from `),eLe=n(ax,"CODE",{});var Pca=s(eLe);Vzr=r(Pca,"pretrained_model_name_or_path"),Pca.forEach(t),Xzr=r(ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=n(ax,"CODE",{});var Bca=s(oLe);zzr=r(Bca,"pretrained_model_name_or_path"),Bca.forEach(t),Qzr=r(ax,":"),ax.forEach(t),Wzr=i(vi),Me=n(vi,"UL",{});var Ce=s(Me);nw=n(Ce,"LI",{});var pZe=s(nw);rLe=n(pZe,"STRONG",{});var Ica=s(rLe);Uzr=r(Ica,"bert"),Ica.forEach(t),Hzr=r(pZe," \u2014 "),Ste=n(pZe,"A",{href:!0});var Nca=s(Ste);Jzr=r(Nca,"TFBertLMHeadModel"),Nca.forEach(t),Yzr=r(pZe," (BERT model)"),pZe.forEach(t),Zzr=i(Ce),sw=n(Ce,"LI",{});var _Ze=s(sw);tLe=n(_Ze,"STRONG",{});var qca=s(tLe);Kzr=r(qca,"camembert"),qca.forEach(t),eQr=r(_Ze," \u2014 "),Rte=n(_Ze,"A",{href:!0});var jca=s(Rte);oQr=r(jca,"TFCamembertForCausalLM"),jca.forEach(t),rQr=r(_Ze," (CamemBERT model)"),_Ze.forEach(t),tQr=i(Ce),lw=n(Ce,"LI",{});var bZe=s(lw);aLe=n(bZe,"STRONG",{});var Dca=s(aLe);aQr=r(Dca,"ctrl"),Dca.forEach(t),nQr=r(bZe," \u2014 "),Pte=n(bZe,"A",{href:!0});var Gca=s(Pte);sQr=r(Gca,"TFCTRLLMHeadModel"),Gca.forEach(t),lQr=r(bZe," (CTRL model)"),bZe.forEach(t),iQr=i(Ce),iw=n(Ce,"LI",{});var vZe=s(iw);nLe=n(vZe,"STRONG",{});var Oca=s(nLe);dQr=r(Oca,"gpt2"),Oca.forEach(t),mQr=r(vZe," \u2014 "),Bte=n(vZe,"A",{href:!0});var Vca=s(Bte);cQr=r(Vca,"TFGPT2LMHeadModel"),Vca.forEach(t),fQr=r(vZe," (OpenAI GPT-2 model)"),vZe.forEach(t),gQr=i(Ce),dw=n(Ce,"LI",{});var FZe=s(dw);sLe=n(FZe,"STRONG",{});var Xca=s(sLe);hQr=r(Xca,"gptj"),Xca.forEach(t),uQr=r(FZe," \u2014 "),Ite=n(FZe,"A",{href:!0});var zca=s(Ite);pQr=r(zca,"TFGPTJForCausalLM"),zca.forEach(t),_Qr=r(FZe," (GPT-J model)"),FZe.forEach(t),bQr=i(Ce),mw=n(Ce,"LI",{});var TZe=s(mw);lLe=n(TZe,"STRONG",{});var Qca=s(lLe);vQr=r(Qca,"openai-gpt"),Qca.forEach(t),FQr=r(TZe," \u2014 "),Nte=n(TZe,"A",{href:!0});var Wca=s(Nte);TQr=r(Wca,"TFOpenAIGPTLMHeadModel"),Wca.forEach(t),MQr=r(TZe," (OpenAI GPT model)"),TZe.forEach(t),EQr=i(Ce),cw=n(Ce,"LI",{});var MZe=s(cw);iLe=n(MZe,"STRONG",{});var Uca=s(iLe);CQr=r(Uca,"opt"),Uca.forEach(t),wQr=r(MZe," \u2014 "),qte=n(MZe,"A",{href:!0});var Hca=s(qte);AQr=r(Hca,"TFOPTForCausalLM"),Hca.forEach(t),LQr=r(MZe," (OPT model)"),MZe.forEach(t),yQr=i(Ce),fw=n(Ce,"LI",{});var EZe=s(fw);dLe=n(EZe,"STRONG",{});var Jca=s(dLe);xQr=r(Jca,"rembert"),Jca.forEach(t),$Qr=r(EZe," \u2014 "),jte=n(EZe,"A",{href:!0});var Yca=s(jte);kQr=r(Yca,"TFRemBertForCausalLM"),Yca.forEach(t),SQr=r(EZe," (RemBERT model)"),EZe.forEach(t),RQr=i(Ce),gw=n(Ce,"LI",{});var CZe=s(gw);mLe=n(CZe,"STRONG",{});var Zca=s(mLe);PQr=r(Zca,"roberta"),Zca.forEach(t),BQr=r(CZe," \u2014 "),Dte=n(CZe,"A",{href:!0});var Kca=s(Dte);IQr=r(Kca,"TFRobertaForCausalLM"),Kca.forEach(t),NQr=r(CZe," (RoBERTa model)"),CZe.forEach(t),qQr=i(Ce),hw=n(Ce,"LI",{});var wZe=s(hw);cLe=n(wZe,"STRONG",{});var efa=s(cLe);jQr=r(efa,"roformer"),efa.forEach(t),DQr=r(wZe," \u2014 "),Gte=n(wZe,"A",{href:!0});var ofa=s(Gte);GQr=r(ofa,"TFRoFormerForCausalLM"),ofa.forEach(t),OQr=r(wZe," (RoFormer model)"),wZe.forEach(t),VQr=i(Ce),uw=n(Ce,"LI",{});var AZe=s(uw);fLe=n(AZe,"STRONG",{});var rfa=s(fLe);XQr=r(rfa,"transfo-xl"),rfa.forEach(t),zQr=r(AZe," \u2014 "),Ote=n(AZe,"A",{href:!0});var tfa=s(Ote);QQr=r(tfa,"TFTransfoXLLMHeadModel"),tfa.forEach(t),WQr=r(AZe," (Transformer-XL model)"),AZe.forEach(t),UQr=i(Ce),pw=n(Ce,"LI",{});var LZe=s(pw);gLe=n(LZe,"STRONG",{});var afa=s(gLe);HQr=r(afa,"xglm"),afa.forEach(t),JQr=r(LZe," \u2014 "),Vte=n(LZe,"A",{href:!0});var nfa=s(Vte);YQr=r(nfa,"TFXGLMForCausalLM"),nfa.forEach(t),ZQr=r(LZe," (XGLM model)"),LZe.forEach(t),KQr=i(Ce),_w=n(Ce,"LI",{});var yZe=s(_w);hLe=n(yZe,"STRONG",{});var sfa=s(hLe);eWr=r(sfa,"xlm"),sfa.forEach(t),oWr=r(yZe," \u2014 "),Xte=n(yZe,"A",{href:!0});var lfa=s(Xte);rWr=r(lfa,"TFXLMWithLMHeadModel"),lfa.forEach(t),tWr=r(yZe," (XLM model)"),yZe.forEach(t),aWr=i(Ce),bw=n(Ce,"LI",{});var xZe=s(bw);uLe=n(xZe,"STRONG",{});var ifa=s(uLe);nWr=r(ifa,"xlnet"),ifa.forEach(t),sWr=r(xZe," \u2014 "),zte=n(xZe,"A",{href:!0});var dfa=s(zte);lWr=r(dfa,"TFXLNetLMHeadModel"),dfa.forEach(t),iWr=r(xZe," (XLNet model)"),xZe.forEach(t),Ce.forEach(t),dWr=i(vi),T(vw.$$.fragment,vi),vi.forEach(t),bi.forEach(t),xao=i(c),_c=n(c,"H2",{class:!0});var Uso=s(_c);Fw=n(Uso,"A",{id:!0,class:!0,href:!0});var mfa=s(Fw);pLe=n(mfa,"SPAN",{});var cfa=s(pLe);T(wR.$$.fragment,cfa),cfa.forEach(t),mfa.forEach(t),mWr=i(Uso),_Le=n(Uso,"SPAN",{});var ffa=s(_Le);cWr=r(ffa,"TFAutoModelForImageClassification"),ffa.forEach(t),Uso.forEach(t),$ao=i(c),gr=n(c,"DIV",{class:!0});var Fi=s(gr);T(AR.$$.fragment,Fi),fWr=i(Fi),bc=n(Fi,"P",{});var ace=s(bc);gWr=r(ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Qte=n(ace,"A",{href:!0});var gfa=s(Qte);hWr=r(gfa,"from_pretrained()"),gfa.forEach(t),uWr=r(ace," class method or the "),Wte=n(ace,"A",{href:!0});var hfa=s(Wte);pWr=r(hfa,"from_config()"),hfa.forEach(t),_Wr=r(ace,` class
method.`),ace.forEach(t),bWr=i(Fi),LR=n(Fi,"P",{});var Hso=s(LR);vWr=r(Hso,"This class cannot be instantiated directly using "),bLe=n(Hso,"CODE",{});var ufa=s(bLe);FWr=r(ufa,"__init__()"),ufa.forEach(t),TWr=r(Hso," (throws an error)."),Hso.forEach(t),MWr=i(Fi),Kt=n(Fi,"DIV",{class:!0});var nx=s(Kt);T(yR.$$.fragment,nx),EWr=i(nx),vLe=n(nx,"P",{});var pfa=s(vLe);CWr=r(pfa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),pfa.forEach(t),wWr=i(nx),vc=n(nx,"P",{});var nce=s(vc);AWr=r(nce,`Note:
Loading a model from its configuration file does `),FLe=n(nce,"STRONG",{});var _fa=s(FLe);LWr=r(_fa,"not"),_fa.forEach(t),yWr=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ute=n(nce,"A",{href:!0});var bfa=s(Ute);xWr=r(bfa,"from_pretrained()"),bfa.forEach(t),$Wr=r(nce," to load the model weights."),nce.forEach(t),kWr=i(nx),T(Tw.$$.fragment,nx),nx.forEach(t),SWr=i(Fi),Vr=n(Fi,"DIV",{class:!0});var Ti=s(Vr);T(xR.$$.fragment,Ti),RWr=i(Ti),TLe=n(Ti,"P",{});var vfa=s(TLe);PWr=r(vfa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),vfa.forEach(t),BWr=i(Ti),qn=n(Ti,"P",{});var sx=s(qn);IWr=r(sx,"The model class to instantiate is selected based on the "),MLe=n(sx,"CODE",{});var Ffa=s(MLe);NWr=r(Ffa,"model_type"),Ffa.forEach(t),qWr=r(sx,` property of the config object (either
passed as an argument or loaded from `),ELe=n(sx,"CODE",{});var Tfa=s(ELe);jWr=r(Tfa,"pretrained_model_name_or_path"),Tfa.forEach(t),DWr=r(sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CLe=n(sx,"CODE",{});var Mfa=s(CLe);GWr=r(Mfa,"pretrained_model_name_or_path"),Mfa.forEach(t),OWr=r(sx,":"),sx.forEach(t),VWr=i(Ti),ye=n(Ti,"UL",{});var Ne=s(ye);Mw=n(Ne,"LI",{});var $Ze=s(Mw);wLe=n($Ze,"STRONG",{});var Efa=s(wLe);XWr=r(Efa,"convnext"),Efa.forEach(t),zWr=r($Ze," \u2014 "),Hte=n($Ze,"A",{href:!0});var Cfa=s(Hte);QWr=r(Cfa,"TFConvNextForImageClassification"),Cfa.forEach(t),WWr=r($Ze," (ConvNeXT model)"),$Ze.forEach(t),UWr=i(Ne),Ew=n(Ne,"LI",{});var kZe=s(Ew);ALe=n(kZe,"STRONG",{});var wfa=s(ALe);HWr=r(wfa,"cvt"),wfa.forEach(t),JWr=r(kZe," \u2014 "),Jte=n(kZe,"A",{href:!0});var Afa=s(Jte);YWr=r(Afa,"TFCvtForImageClassification"),Afa.forEach(t),ZWr=r(kZe," (CvT model)"),kZe.forEach(t),KWr=i(Ne),Cw=n(Ne,"LI",{});var SZe=s(Cw);LLe=n(SZe,"STRONG",{});var Lfa=s(LLe);eUr=r(Lfa,"data2vec-vision"),Lfa.forEach(t),oUr=r(SZe," \u2014 "),Yte=n(SZe,"A",{href:!0});var yfa=s(Yte);rUr=r(yfa,"TFData2VecVisionForImageClassification"),yfa.forEach(t),tUr=r(SZe," (Data2VecVision model)"),SZe.forEach(t),aUr=i(Ne),Sl=n(Ne,"LI",{});var pN=s(Sl);yLe=n(pN,"STRONG",{});var xfa=s(yLe);nUr=r(xfa,"deit"),xfa.forEach(t),sUr=r(pN," \u2014 "),Zte=n(pN,"A",{href:!0});var $fa=s(Zte);lUr=r($fa,"TFDeiTForImageClassification"),$fa.forEach(t),iUr=r(pN," or "),Kte=n(pN,"A",{href:!0});var kfa=s(Kte);dUr=r(kfa,"TFDeiTForImageClassificationWithTeacher"),kfa.forEach(t),mUr=r(pN," (DeiT model)"),pN.forEach(t),cUr=i(Ne),ww=n(Ne,"LI",{});var RZe=s(ww);xLe=n(RZe,"STRONG",{});var Sfa=s(xLe);fUr=r(Sfa,"mobilevit"),Sfa.forEach(t),gUr=r(RZe," \u2014 "),eae=n(RZe,"A",{href:!0});var Rfa=s(eae);hUr=r(Rfa,"TFMobileViTForImageClassification"),Rfa.forEach(t),uUr=r(RZe," (MobileViT model)"),RZe.forEach(t),pUr=i(Ne),Aw=n(Ne,"LI",{});var PZe=s(Aw);$Le=n(PZe,"STRONG",{});var Pfa=s($Le);_Ur=r(Pfa,"regnet"),Pfa.forEach(t),bUr=r(PZe," \u2014 "),oae=n(PZe,"A",{href:!0});var Bfa=s(oae);vUr=r(Bfa,"TFRegNetForImageClassification"),Bfa.forEach(t),FUr=r(PZe," (RegNet model)"),PZe.forEach(t),TUr=i(Ne),Lw=n(Ne,"LI",{});var BZe=s(Lw);kLe=n(BZe,"STRONG",{});var Ifa=s(kLe);MUr=r(Ifa,"resnet"),Ifa.forEach(t),EUr=r(BZe," \u2014 "),rae=n(BZe,"A",{href:!0});var Nfa=s(rae);CUr=r(Nfa,"TFResNetForImageClassification"),Nfa.forEach(t),wUr=r(BZe," (ResNet model)"),BZe.forEach(t),AUr=i(Ne),yw=n(Ne,"LI",{});var IZe=s(yw);SLe=n(IZe,"STRONG",{});var qfa=s(SLe);LUr=r(qfa,"segformer"),qfa.forEach(t),yUr=r(IZe," \u2014 "),tae=n(IZe,"A",{href:!0});var jfa=s(tae);xUr=r(jfa,"TFSegformerForImageClassification"),jfa.forEach(t),$Ur=r(IZe," (SegFormer model)"),IZe.forEach(t),kUr=i(Ne),xw=n(Ne,"LI",{});var NZe=s(xw);RLe=n(NZe,"STRONG",{});var Dfa=s(RLe);SUr=r(Dfa,"swin"),Dfa.forEach(t),RUr=r(NZe," \u2014 "),aae=n(NZe,"A",{href:!0});var Gfa=s(aae);PUr=r(Gfa,"TFSwinForImageClassification"),Gfa.forEach(t),BUr=r(NZe," (Swin Transformer model)"),NZe.forEach(t),IUr=i(Ne),$w=n(Ne,"LI",{});var qZe=s($w);PLe=n(qZe,"STRONG",{});var Ofa=s(PLe);NUr=r(Ofa,"vit"),Ofa.forEach(t),qUr=r(qZe," \u2014 "),nae=n(qZe,"A",{href:!0});var Vfa=s(nae);jUr=r(Vfa,"TFViTForImageClassification"),Vfa.forEach(t),DUr=r(qZe," (ViT model)"),qZe.forEach(t),Ne.forEach(t),GUr=i(Ti),T(kw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),kao=i(c),Fc=n(c,"H2",{class:!0});var Jso=s(Fc);Sw=n(Jso,"A",{id:!0,class:!0,href:!0});var Xfa=s(Sw);BLe=n(Xfa,"SPAN",{});var zfa=s(BLe);T($R.$$.fragment,zfa),zfa.forEach(t),Xfa.forEach(t),OUr=i(Jso),ILe=n(Jso,"SPAN",{});var Qfa=s(ILe);VUr=r(Qfa,"TFAutoModelForSemanticSegmentation"),Qfa.forEach(t),Jso.forEach(t),Sao=i(c),hr=n(c,"DIV",{class:!0});var Mi=s(hr);T(kR.$$.fragment,Mi),XUr=i(Mi),Tc=n(Mi,"P",{});var sce=s(Tc);zUr=r(sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),sae=n(sce,"A",{href:!0});var Wfa=s(sae);QUr=r(Wfa,"from_pretrained()"),Wfa.forEach(t),WUr=r(sce," class method or the "),lae=n(sce,"A",{href:!0});var Ufa=s(lae);UUr=r(Ufa,"from_config()"),Ufa.forEach(t),HUr=r(sce,` class
method.`),sce.forEach(t),JUr=i(Mi),SR=n(Mi,"P",{});var Yso=s(SR);YUr=r(Yso,"This class cannot be instantiated directly using "),NLe=n(Yso,"CODE",{});var Hfa=s(NLe);ZUr=r(Hfa,"__init__()"),Hfa.forEach(t),KUr=r(Yso," (throws an error)."),Yso.forEach(t),eHr=i(Mi),ea=n(Mi,"DIV",{class:!0});var lx=s(ea);T(RR.$$.fragment,lx),oHr=i(lx),qLe=n(lx,"P",{});var Jfa=s(qLe);rHr=r(Jfa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Jfa.forEach(t),tHr=i(lx),Mc=n(lx,"P",{});var lce=s(Mc);aHr=r(lce,`Note:
Loading a model from its configuration file does `),jLe=n(lce,"STRONG",{});var Yfa=s(jLe);nHr=r(Yfa,"not"),Yfa.forEach(t),sHr=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),iae=n(lce,"A",{href:!0});var Zfa=s(iae);lHr=r(Zfa,"from_pretrained()"),Zfa.forEach(t),iHr=r(lce," to load the model weights."),lce.forEach(t),dHr=i(lx),T(Rw.$$.fragment,lx),lx.forEach(t),mHr=i(Mi),Xr=n(Mi,"DIV",{class:!0});var Ei=s(Xr);T(PR.$$.fragment,Ei),cHr=i(Ei),DLe=n(Ei,"P",{});var Kfa=s(DLe);fHr=r(Kfa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Kfa.forEach(t),gHr=i(Ei),jn=n(Ei,"P",{});var ix=s(jn);hHr=r(ix,"The model class to instantiate is selected based on the "),GLe=n(ix,"CODE",{});var ega=s(GLe);uHr=r(ega,"model_type"),ega.forEach(t),pHr=r(ix,` property of the config object (either
passed as an argument or loaded from `),OLe=n(ix,"CODE",{});var oga=s(OLe);_Hr=r(oga,"pretrained_model_name_or_path"),oga.forEach(t),bHr=r(ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VLe=n(ix,"CODE",{});var rga=s(VLe);vHr=r(rga,"pretrained_model_name_or_path"),rga.forEach(t),FHr=r(ix,":"),ix.forEach(t),THr=i(Ei),Ec=n(Ei,"UL",{});var ice=s(Ec);Pw=n(ice,"LI",{});var jZe=s(Pw);XLe=n(jZe,"STRONG",{});var tga=s(XLe);MHr=r(tga,"data2vec-vision"),tga.forEach(t),EHr=r(jZe," \u2014 "),dae=n(jZe,"A",{href:!0});var aga=s(dae);CHr=r(aga,"TFData2VecVisionForSemanticSegmentation"),aga.forEach(t),wHr=r(jZe," (Data2VecVision model)"),jZe.forEach(t),AHr=i(ice),Bw=n(ice,"LI",{});var DZe=s(Bw);zLe=n(DZe,"STRONG",{});var nga=s(zLe);LHr=r(nga,"mobilevit"),nga.forEach(t),yHr=r(DZe," \u2014 "),mae=n(DZe,"A",{href:!0});var sga=s(mae);xHr=r(sga,"TFMobileViTForSemanticSegmentation"),sga.forEach(t),$Hr=r(DZe," (MobileViT model)"),DZe.forEach(t),kHr=i(ice),Iw=n(ice,"LI",{});var GZe=s(Iw);QLe=n(GZe,"STRONG",{});var lga=s(QLe);SHr=r(lga,"segformer"),lga.forEach(t),RHr=r(GZe," \u2014 "),cae=n(GZe,"A",{href:!0});var iga=s(cae);PHr=r(iga,"TFSegformerForSemanticSegmentation"),iga.forEach(t),BHr=r(GZe," (SegFormer model)"),GZe.forEach(t),ice.forEach(t),IHr=i(Ei),T(Nw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),Rao=i(c),Cc=n(c,"H2",{class:!0});var Zso=s(Cc);qw=n(Zso,"A",{id:!0,class:!0,href:!0});var dga=s(qw);WLe=n(dga,"SPAN",{});var mga=s(WLe);T(BR.$$.fragment,mga),mga.forEach(t),dga.forEach(t),NHr=i(Zso),ULe=n(Zso,"SPAN",{});var cga=s(ULe);qHr=r(cga,"TFAutoModelForMaskedLM"),cga.forEach(t),Zso.forEach(t),Pao=i(c),ur=n(c,"DIV",{class:!0});var Ci=s(ur);T(IR.$$.fragment,Ci),jHr=i(Ci),wc=n(Ci,"P",{});var dce=s(wc);DHr=r(dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),fae=n(dce,"A",{href:!0});var fga=s(fae);GHr=r(fga,"from_pretrained()"),fga.forEach(t),OHr=r(dce," class method or the "),gae=n(dce,"A",{href:!0});var gga=s(gae);VHr=r(gga,"from_config()"),gga.forEach(t),XHr=r(dce,` class
method.`),dce.forEach(t),zHr=i(Ci),NR=n(Ci,"P",{});var Kso=s(NR);QHr=r(Kso,"This class cannot be instantiated directly using "),HLe=n(Kso,"CODE",{});var hga=s(HLe);WHr=r(hga,"__init__()"),hga.forEach(t),UHr=r(Kso," (throws an error)."),Kso.forEach(t),HHr=i(Ci),oa=n(Ci,"DIV",{class:!0});var dx=s(oa);T(qR.$$.fragment,dx),JHr=i(dx),JLe=n(dx,"P",{});var uga=s(JLe);YHr=r(uga,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uga.forEach(t),ZHr=i(dx),Ac=n(dx,"P",{});var mce=s(Ac);KHr=r(mce,`Note:
Loading a model from its configuration file does `),YLe=n(mce,"STRONG",{});var pga=s(YLe);eJr=r(pga,"not"),pga.forEach(t),oJr=r(mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),hae=n(mce,"A",{href:!0});var _ga=s(hae);rJr=r(_ga,"from_pretrained()"),_ga.forEach(t),tJr=r(mce," to load the model weights."),mce.forEach(t),aJr=i(dx),T(jw.$$.fragment,dx),dx.forEach(t),nJr=i(Ci),zr=n(Ci,"DIV",{class:!0});var wi=s(zr);T(jR.$$.fragment,wi),sJr=i(wi),ZLe=n(wi,"P",{});var bga=s(ZLe);lJr=r(bga,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),bga.forEach(t),iJr=i(wi),Dn=n(wi,"P",{});var mx=s(Dn);dJr=r(mx,"The model class to instantiate is selected based on the "),KLe=n(mx,"CODE",{});var vga=s(KLe);mJr=r(vga,"model_type"),vga.forEach(t),cJr=r(mx,` property of the config object (either
passed as an argument or loaded from `),eye=n(mx,"CODE",{});var Fga=s(eye);fJr=r(Fga,"pretrained_model_name_or_path"),Fga.forEach(t),gJr=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oye=n(mx,"CODE",{});var Tga=s(oye);hJr=r(Tga,"pretrained_model_name_or_path"),Tga.forEach(t),uJr=r(mx,":"),mx.forEach(t),pJr=i(wi),ce=n(wi,"UL",{});var ue=s(ce);Dw=n(ue,"LI",{});var OZe=s(Dw);rye=n(OZe,"STRONG",{});var Mga=s(rye);_Jr=r(Mga,"albert"),Mga.forEach(t),bJr=r(OZe," \u2014 "),uae=n(OZe,"A",{href:!0});var Ega=s(uae);vJr=r(Ega,"TFAlbertForMaskedLM"),Ega.forEach(t),FJr=r(OZe," (ALBERT model)"),OZe.forEach(t),TJr=i(ue),Gw=n(ue,"LI",{});var VZe=s(Gw);tye=n(VZe,"STRONG",{});var Cga=s(tye);MJr=r(Cga,"bert"),Cga.forEach(t),EJr=r(VZe," \u2014 "),pae=n(VZe,"A",{href:!0});var wga=s(pae);CJr=r(wga,"TFBertForMaskedLM"),wga.forEach(t),wJr=r(VZe," (BERT model)"),VZe.forEach(t),AJr=i(ue),Ow=n(ue,"LI",{});var XZe=s(Ow);aye=n(XZe,"STRONG",{});var Aga=s(aye);LJr=r(Aga,"camembert"),Aga.forEach(t),yJr=r(XZe," \u2014 "),_ae=n(XZe,"A",{href:!0});var Lga=s(_ae);xJr=r(Lga,"TFCamembertForMaskedLM"),Lga.forEach(t),$Jr=r(XZe," (CamemBERT model)"),XZe.forEach(t),kJr=i(ue),Vw=n(ue,"LI",{});var zZe=s(Vw);nye=n(zZe,"STRONG",{});var yga=s(nye);SJr=r(yga,"convbert"),yga.forEach(t),RJr=r(zZe," \u2014 "),bae=n(zZe,"A",{href:!0});var xga=s(bae);PJr=r(xga,"TFConvBertForMaskedLM"),xga.forEach(t),BJr=r(zZe," (ConvBERT model)"),zZe.forEach(t),IJr=i(ue),Xw=n(ue,"LI",{});var QZe=s(Xw);sye=n(QZe,"STRONG",{});var $ga=s(sye);NJr=r($ga,"deberta"),$ga.forEach(t),qJr=r(QZe," \u2014 "),vae=n(QZe,"A",{href:!0});var kga=s(vae);jJr=r(kga,"TFDebertaForMaskedLM"),kga.forEach(t),DJr=r(QZe," (DeBERTa model)"),QZe.forEach(t),GJr=i(ue),zw=n(ue,"LI",{});var WZe=s(zw);lye=n(WZe,"STRONG",{});var Sga=s(lye);OJr=r(Sga,"deberta-v2"),Sga.forEach(t),VJr=r(WZe," \u2014 "),Fae=n(WZe,"A",{href:!0});var Rga=s(Fae);XJr=r(Rga,"TFDebertaV2ForMaskedLM"),Rga.forEach(t),zJr=r(WZe," (DeBERTa-v2 model)"),WZe.forEach(t),QJr=i(ue),Qw=n(ue,"LI",{});var UZe=s(Qw);iye=n(UZe,"STRONG",{});var Pga=s(iye);WJr=r(Pga,"distilbert"),Pga.forEach(t),UJr=r(UZe," \u2014 "),Tae=n(UZe,"A",{href:!0});var Bga=s(Tae);HJr=r(Bga,"TFDistilBertForMaskedLM"),Bga.forEach(t),JJr=r(UZe," (DistilBERT model)"),UZe.forEach(t),YJr=i(ue),Ww=n(ue,"LI",{});var HZe=s(Ww);dye=n(HZe,"STRONG",{});var Iga=s(dye);ZJr=r(Iga,"electra"),Iga.forEach(t),KJr=r(HZe," \u2014 "),Mae=n(HZe,"A",{href:!0});var Nga=s(Mae);eYr=r(Nga,"TFElectraForMaskedLM"),Nga.forEach(t),oYr=r(HZe," (ELECTRA model)"),HZe.forEach(t),rYr=i(ue),Uw=n(ue,"LI",{});var JZe=s(Uw);mye=n(JZe,"STRONG",{});var qga=s(mye);tYr=r(qga,"esm"),qga.forEach(t),aYr=r(JZe," \u2014 "),Eae=n(JZe,"A",{href:!0});var jga=s(Eae);nYr=r(jga,"TFEsmForMaskedLM"),jga.forEach(t),sYr=r(JZe," (ESM model)"),JZe.forEach(t),lYr=i(ue),Hw=n(ue,"LI",{});var YZe=s(Hw);cye=n(YZe,"STRONG",{});var Dga=s(cye);iYr=r(Dga,"flaubert"),Dga.forEach(t),dYr=r(YZe," \u2014 "),Cae=n(YZe,"A",{href:!0});var Gga=s(Cae);mYr=r(Gga,"TFFlaubertWithLMHeadModel"),Gga.forEach(t),cYr=r(YZe," (FlauBERT model)"),YZe.forEach(t),fYr=i(ue),Jw=n(ue,"LI",{});var ZZe=s(Jw);fye=n(ZZe,"STRONG",{});var Oga=s(fye);gYr=r(Oga,"funnel"),Oga.forEach(t),hYr=r(ZZe," \u2014 "),wae=n(ZZe,"A",{href:!0});var Vga=s(wae);uYr=r(Vga,"TFFunnelForMaskedLM"),Vga.forEach(t),pYr=r(ZZe," (Funnel Transformer model)"),ZZe.forEach(t),_Yr=i(ue),Yw=n(ue,"LI",{});var KZe=s(Yw);gye=n(KZe,"STRONG",{});var Xga=s(gye);bYr=r(Xga,"layoutlm"),Xga.forEach(t),vYr=r(KZe," \u2014 "),Aae=n(KZe,"A",{href:!0});var zga=s(Aae);FYr=r(zga,"TFLayoutLMForMaskedLM"),zga.forEach(t),TYr=r(KZe," (LayoutLM model)"),KZe.forEach(t),MYr=i(ue),Zw=n(ue,"LI",{});var eKe=s(Zw);hye=n(eKe,"STRONG",{});var Qga=s(hye);EYr=r(Qga,"longformer"),Qga.forEach(t),CYr=r(eKe," \u2014 "),Lae=n(eKe,"A",{href:!0});var Wga=s(Lae);wYr=r(Wga,"TFLongformerForMaskedLM"),Wga.forEach(t),AYr=r(eKe," (Longformer model)"),eKe.forEach(t),LYr=i(ue),Kw=n(ue,"LI",{});var oKe=s(Kw);uye=n(oKe,"STRONG",{});var Uga=s(uye);yYr=r(Uga,"mobilebert"),Uga.forEach(t),xYr=r(oKe," \u2014 "),yae=n(oKe,"A",{href:!0});var Hga=s(yae);$Yr=r(Hga,"TFMobileBertForMaskedLM"),Hga.forEach(t),kYr=r(oKe," (MobileBERT model)"),oKe.forEach(t),SYr=i(ue),eA=n(ue,"LI",{});var rKe=s(eA);pye=n(rKe,"STRONG",{});var Jga=s(pye);RYr=r(Jga,"mpnet"),Jga.forEach(t),PYr=r(rKe," \u2014 "),xae=n(rKe,"A",{href:!0});var Yga=s(xae);BYr=r(Yga,"TFMPNetForMaskedLM"),Yga.forEach(t),IYr=r(rKe," (MPNet model)"),rKe.forEach(t),NYr=i(ue),oA=n(ue,"LI",{});var tKe=s(oA);_ye=n(tKe,"STRONG",{});var Zga=s(_ye);qYr=r(Zga,"rembert"),Zga.forEach(t),jYr=r(tKe," \u2014 "),$ae=n(tKe,"A",{href:!0});var Kga=s($ae);DYr=r(Kga,"TFRemBertForMaskedLM"),Kga.forEach(t),GYr=r(tKe," (RemBERT model)"),tKe.forEach(t),OYr=i(ue),rA=n(ue,"LI",{});var aKe=s(rA);bye=n(aKe,"STRONG",{});var eha=s(bye);VYr=r(eha,"roberta"),eha.forEach(t),XYr=r(aKe," \u2014 "),kae=n(aKe,"A",{href:!0});var oha=s(kae);zYr=r(oha,"TFRobertaForMaskedLM"),oha.forEach(t),QYr=r(aKe," (RoBERTa model)"),aKe.forEach(t),WYr=i(ue),tA=n(ue,"LI",{});var nKe=s(tA);vye=n(nKe,"STRONG",{});var rha=s(vye);UYr=r(rha,"roformer"),rha.forEach(t),HYr=r(nKe," \u2014 "),Sae=n(nKe,"A",{href:!0});var tha=s(Sae);JYr=r(tha,"TFRoFormerForMaskedLM"),tha.forEach(t),YYr=r(nKe," (RoFormer model)"),nKe.forEach(t),ZYr=i(ue),aA=n(ue,"LI",{});var sKe=s(aA);Fye=n(sKe,"STRONG",{});var aha=s(Fye);KYr=r(aha,"tapas"),aha.forEach(t),eZr=r(sKe," \u2014 "),Rae=n(sKe,"A",{href:!0});var nha=s(Rae);oZr=r(nha,"TFTapasForMaskedLM"),nha.forEach(t),rZr=r(sKe," (TAPAS model)"),sKe.forEach(t),tZr=i(ue),nA=n(ue,"LI",{});var lKe=s(nA);Tye=n(lKe,"STRONG",{});var sha=s(Tye);aZr=r(sha,"xlm"),sha.forEach(t),nZr=r(lKe," \u2014 "),Pae=n(lKe,"A",{href:!0});var lha=s(Pae);sZr=r(lha,"TFXLMWithLMHeadModel"),lha.forEach(t),lZr=r(lKe," (XLM model)"),lKe.forEach(t),iZr=i(ue),sA=n(ue,"LI",{});var iKe=s(sA);Mye=n(iKe,"STRONG",{});var iha=s(Mye);dZr=r(iha,"xlm-roberta"),iha.forEach(t),mZr=r(iKe," \u2014 "),Bae=n(iKe,"A",{href:!0});var dha=s(Bae);cZr=r(dha,"TFXLMRobertaForMaskedLM"),dha.forEach(t),fZr=r(iKe," (XLM-RoBERTa model)"),iKe.forEach(t),ue.forEach(t),gZr=i(wi),T(lA.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),Bao=i(c),Lc=n(c,"H2",{class:!0});var elo=s(Lc);iA=n(elo,"A",{id:!0,class:!0,href:!0});var mha=s(iA);Eye=n(mha,"SPAN",{});var cha=s(Eye);T(DR.$$.fragment,cha),cha.forEach(t),mha.forEach(t),hZr=i(elo),Cye=n(elo,"SPAN",{});var fha=s(Cye);uZr=r(fha,"TFAutoModelForSeq2SeqLM"),fha.forEach(t),elo.forEach(t),Iao=i(c),pr=n(c,"DIV",{class:!0});var Ai=s(pr);T(GR.$$.fragment,Ai),pZr=i(Ai),yc=n(Ai,"P",{});var cce=s(yc);_Zr=r(cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Iae=n(cce,"A",{href:!0});var gha=s(Iae);bZr=r(gha,"from_pretrained()"),gha.forEach(t),vZr=r(cce," class method or the "),Nae=n(cce,"A",{href:!0});var hha=s(Nae);FZr=r(hha,"from_config()"),hha.forEach(t),TZr=r(cce,` class
method.`),cce.forEach(t),MZr=i(Ai),OR=n(Ai,"P",{});var olo=s(OR);EZr=r(olo,"This class cannot be instantiated directly using "),wye=n(olo,"CODE",{});var uha=s(wye);CZr=r(uha,"__init__()"),uha.forEach(t),wZr=r(olo," (throws an error)."),olo.forEach(t),AZr=i(Ai),ra=n(Ai,"DIV",{class:!0});var cx=s(ra);T(VR.$$.fragment,cx),LZr=i(cx),Aye=n(cx,"P",{});var pha=s(Aye);yZr=r(pha,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),pha.forEach(t),xZr=i(cx),xc=n(cx,"P",{});var fce=s(xc);$Zr=r(fce,`Note:
Loading a model from its configuration file does `),Lye=n(fce,"STRONG",{});var _ha=s(Lye);kZr=r(_ha,"not"),_ha.forEach(t),SZr=r(fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),qae=n(fce,"A",{href:!0});var bha=s(qae);RZr=r(bha,"from_pretrained()"),bha.forEach(t),PZr=r(fce," to load the model weights."),fce.forEach(t),BZr=i(cx),T(dA.$$.fragment,cx),cx.forEach(t),IZr=i(Ai),Qr=n(Ai,"DIV",{class:!0});var Li=s(Qr);T(XR.$$.fragment,Li),NZr=i(Li),yye=n(Li,"P",{});var vha=s(yye);qZr=r(vha,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),vha.forEach(t),jZr=i(Li),Gn=n(Li,"P",{});var fx=s(Gn);DZr=r(fx,"The model class to instantiate is selected based on the "),xye=n(fx,"CODE",{});var Fha=s(xye);GZr=r(Fha,"model_type"),Fha.forEach(t),OZr=r(fx,` property of the config object (either
passed as an argument or loaded from `),$ye=n(fx,"CODE",{});var Tha=s($ye);VZr=r(Tha,"pretrained_model_name_or_path"),Tha.forEach(t),XZr=r(fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kye=n(fx,"CODE",{});var Mha=s(kye);zZr=r(Mha,"pretrained_model_name_or_path"),Mha.forEach(t),QZr=r(fx,":"),fx.forEach(t),WZr=i(Li),xe=n(Li,"UL",{});var qe=s(xe);mA=n(qe,"LI",{});var dKe=s(mA);Sye=n(dKe,"STRONG",{});var Eha=s(Sye);UZr=r(Eha,"bart"),Eha.forEach(t),HZr=r(dKe," \u2014 "),jae=n(dKe,"A",{href:!0});var Cha=s(jae);JZr=r(Cha,"TFBartForConditionalGeneration"),Cha.forEach(t),YZr=r(dKe," (BART model)"),dKe.forEach(t),ZZr=i(qe),cA=n(qe,"LI",{});var mKe=s(cA);Rye=n(mKe,"STRONG",{});var wha=s(Rye);KZr=r(wha,"blenderbot"),wha.forEach(t),eKr=r(mKe," \u2014 "),Dae=n(mKe,"A",{href:!0});var Aha=s(Dae);oKr=r(Aha,"TFBlenderbotForConditionalGeneration"),Aha.forEach(t),rKr=r(mKe," (Blenderbot model)"),mKe.forEach(t),tKr=i(qe),fA=n(qe,"LI",{});var cKe=s(fA);Pye=n(cKe,"STRONG",{});var Lha=s(Pye);aKr=r(Lha,"blenderbot-small"),Lha.forEach(t),nKr=r(cKe," \u2014 "),Gae=n(cKe,"A",{href:!0});var yha=s(Gae);sKr=r(yha,"TFBlenderbotSmallForConditionalGeneration"),yha.forEach(t),lKr=r(cKe," (BlenderbotSmall model)"),cKe.forEach(t),iKr=i(qe),gA=n(qe,"LI",{});var fKe=s(gA);Bye=n(fKe,"STRONG",{});var xha=s(Bye);dKr=r(xha,"encoder-decoder"),xha.forEach(t),mKr=r(fKe," \u2014 "),Oae=n(fKe,"A",{href:!0});var $ha=s(Oae);cKr=r($ha,"TFEncoderDecoderModel"),$ha.forEach(t),fKr=r(fKe," (Encoder decoder model)"),fKe.forEach(t),gKr=i(qe),hA=n(qe,"LI",{});var gKe=s(hA);Iye=n(gKe,"STRONG",{});var kha=s(Iye);hKr=r(kha,"led"),kha.forEach(t),uKr=r(gKe," \u2014 "),Vae=n(gKe,"A",{href:!0});var Sha=s(Vae);pKr=r(Sha,"TFLEDForConditionalGeneration"),Sha.forEach(t),_Kr=r(gKe," (LED model)"),gKe.forEach(t),bKr=i(qe),uA=n(qe,"LI",{});var hKe=s(uA);Nye=n(hKe,"STRONG",{});var Rha=s(Nye);vKr=r(Rha,"marian"),Rha.forEach(t),FKr=r(hKe," \u2014 "),Xae=n(hKe,"A",{href:!0});var Pha=s(Xae);TKr=r(Pha,"TFMarianMTModel"),Pha.forEach(t),MKr=r(hKe," (Marian model)"),hKe.forEach(t),EKr=i(qe),pA=n(qe,"LI",{});var uKe=s(pA);qye=n(uKe,"STRONG",{});var Bha=s(qye);CKr=r(Bha,"mbart"),Bha.forEach(t),wKr=r(uKe," \u2014 "),zae=n(uKe,"A",{href:!0});var Iha=s(zae);AKr=r(Iha,"TFMBartForConditionalGeneration"),Iha.forEach(t),LKr=r(uKe," (mBART model)"),uKe.forEach(t),yKr=i(qe),_A=n(qe,"LI",{});var pKe=s(_A);jye=n(pKe,"STRONG",{});var Nha=s(jye);xKr=r(Nha,"mt5"),Nha.forEach(t),$Kr=r(pKe," \u2014 "),Qae=n(pKe,"A",{href:!0});var qha=s(Qae);kKr=r(qha,"TFMT5ForConditionalGeneration"),qha.forEach(t),SKr=r(pKe," (MT5 model)"),pKe.forEach(t),RKr=i(qe),bA=n(qe,"LI",{});var _Ke=s(bA);Dye=n(_Ke,"STRONG",{});var jha=s(Dye);PKr=r(jha,"pegasus"),jha.forEach(t),BKr=r(_Ke," \u2014 "),Wae=n(_Ke,"A",{href:!0});var Dha=s(Wae);IKr=r(Dha,"TFPegasusForConditionalGeneration"),Dha.forEach(t),NKr=r(_Ke," (Pegasus model)"),_Ke.forEach(t),qKr=i(qe),vA=n(qe,"LI",{});var bKe=s(vA);Gye=n(bKe,"STRONG",{});var Gha=s(Gye);jKr=r(Gha,"t5"),Gha.forEach(t),DKr=r(bKe," \u2014 "),Uae=n(bKe,"A",{href:!0});var Oha=s(Uae);GKr=r(Oha,"TFT5ForConditionalGeneration"),Oha.forEach(t),OKr=r(bKe," (T5 model)"),bKe.forEach(t),qe.forEach(t),VKr=i(Li),T(FA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),Nao=i(c),$c=n(c,"H2",{class:!0});var rlo=s($c);TA=n(rlo,"A",{id:!0,class:!0,href:!0});var Vha=s(TA);Oye=n(Vha,"SPAN",{});var Xha=s(Oye);T(zR.$$.fragment,Xha),Xha.forEach(t),Vha.forEach(t),XKr=i(rlo),Vye=n(rlo,"SPAN",{});var zha=s(Vye);zKr=r(zha,"TFAutoModelForSequenceClassification"),zha.forEach(t),rlo.forEach(t),qao=i(c),_r=n(c,"DIV",{class:!0});var yi=s(_r);T(QR.$$.fragment,yi),QKr=i(yi),kc=n(yi,"P",{});var gce=s(kc);WKr=r(gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Hae=n(gce,"A",{href:!0});var Qha=s(Hae);UKr=r(Qha,"from_pretrained()"),Qha.forEach(t),HKr=r(gce," class method or the "),Jae=n(gce,"A",{href:!0});var Wha=s(Jae);JKr=r(Wha,"from_config()"),Wha.forEach(t),YKr=r(gce,` class
method.`),gce.forEach(t),ZKr=i(yi),WR=n(yi,"P",{});var tlo=s(WR);KKr=r(tlo,"This class cannot be instantiated directly using "),Xye=n(tlo,"CODE",{});var Uha=s(Xye);eet=r(Uha,"__init__()"),Uha.forEach(t),oet=r(tlo," (throws an error)."),tlo.forEach(t),ret=i(yi),ta=n(yi,"DIV",{class:!0});var gx=s(ta);T(UR.$$.fragment,gx),tet=i(gx),zye=n(gx,"P",{});var Hha=s(zye);aet=r(Hha,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hha.forEach(t),net=i(gx),Sc=n(gx,"P",{});var hce=s(Sc);set=r(hce,`Note:
Loading a model from its configuration file does `),Qye=n(hce,"STRONG",{});var Jha=s(Qye);iet=r(Jha,"not"),Jha.forEach(t),det=r(hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yae=n(hce,"A",{href:!0});var Yha=s(Yae);met=r(Yha,"from_pretrained()"),Yha.forEach(t),cet=r(hce," to load the model weights."),hce.forEach(t),fet=i(gx),T(MA.$$.fragment,gx),gx.forEach(t),get=i(yi),Wr=n(yi,"DIV",{class:!0});var xi=s(Wr);T(HR.$$.fragment,xi),het=i(xi),Wye=n(xi,"P",{});var Zha=s(Wye);uet=r(Zha,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Zha.forEach(t),pet=i(xi),On=n(xi,"P",{});var hx=s(On);_et=r(hx,"The model class to instantiate is selected based on the "),Uye=n(hx,"CODE",{});var Kha=s(Uye);bet=r(Kha,"model_type"),Kha.forEach(t),vet=r(hx,` property of the config object (either
passed as an argument or loaded from `),Hye=n(hx,"CODE",{});var eua=s(Hye);Fet=r(eua,"pretrained_model_name_or_path"),eua.forEach(t),Tet=r(hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jye=n(hx,"CODE",{});var oua=s(Jye);Met=r(oua,"pretrained_model_name_or_path"),oua.forEach(t),Eet=r(hx,":"),hx.forEach(t),Cet=i(xi),re=n(xi,"UL",{});var ae=s(re);EA=n(ae,"LI",{});var vKe=s(EA);Yye=n(vKe,"STRONG",{});var rua=s(Yye);wet=r(rua,"albert"),rua.forEach(t),Aet=r(vKe," \u2014 "),Zae=n(vKe,"A",{href:!0});var tua=s(Zae);Let=r(tua,"TFAlbertForSequenceClassification"),tua.forEach(t),yet=r(vKe," (ALBERT model)"),vKe.forEach(t),xet=i(ae),CA=n(ae,"LI",{});var FKe=s(CA);Zye=n(FKe,"STRONG",{});var aua=s(Zye);$et=r(aua,"bert"),aua.forEach(t),ket=r(FKe," \u2014 "),Kae=n(FKe,"A",{href:!0});var nua=s(Kae);Set=r(nua,"TFBertForSequenceClassification"),nua.forEach(t),Ret=r(FKe," (BERT model)"),FKe.forEach(t),Pet=i(ae),wA=n(ae,"LI",{});var TKe=s(wA);Kye=n(TKe,"STRONG",{});var sua=s(Kye);Bet=r(sua,"camembert"),sua.forEach(t),Iet=r(TKe," \u2014 "),ene=n(TKe,"A",{href:!0});var lua=s(ene);Net=r(lua,"TFCamembertForSequenceClassification"),lua.forEach(t),qet=r(TKe," (CamemBERT model)"),TKe.forEach(t),jet=i(ae),AA=n(ae,"LI",{});var MKe=s(AA);e9e=n(MKe,"STRONG",{});var iua=s(e9e);Det=r(iua,"convbert"),iua.forEach(t),Get=r(MKe," \u2014 "),one=n(MKe,"A",{href:!0});var dua=s(one);Oet=r(dua,"TFConvBertForSequenceClassification"),dua.forEach(t),Vet=r(MKe," (ConvBERT model)"),MKe.forEach(t),Xet=i(ae),LA=n(ae,"LI",{});var EKe=s(LA);o9e=n(EKe,"STRONG",{});var mua=s(o9e);zet=r(mua,"ctrl"),mua.forEach(t),Qet=r(EKe," \u2014 "),rne=n(EKe,"A",{href:!0});var cua=s(rne);Wet=r(cua,"TFCTRLForSequenceClassification"),cua.forEach(t),Uet=r(EKe," (CTRL model)"),EKe.forEach(t),Het=i(ae),yA=n(ae,"LI",{});var CKe=s(yA);r9e=n(CKe,"STRONG",{});var fua=s(r9e);Jet=r(fua,"deberta"),fua.forEach(t),Yet=r(CKe," \u2014 "),tne=n(CKe,"A",{href:!0});var gua=s(tne);Zet=r(gua,"TFDebertaForSequenceClassification"),gua.forEach(t),Ket=r(CKe," (DeBERTa model)"),CKe.forEach(t),eot=i(ae),xA=n(ae,"LI",{});var wKe=s(xA);t9e=n(wKe,"STRONG",{});var hua=s(t9e);oot=r(hua,"deberta-v2"),hua.forEach(t),rot=r(wKe," \u2014 "),ane=n(wKe,"A",{href:!0});var uua=s(ane);tot=r(uua,"TFDebertaV2ForSequenceClassification"),uua.forEach(t),aot=r(wKe," (DeBERTa-v2 model)"),wKe.forEach(t),not=i(ae),$A=n(ae,"LI",{});var AKe=s($A);a9e=n(AKe,"STRONG",{});var pua=s(a9e);sot=r(pua,"distilbert"),pua.forEach(t),lot=r(AKe," \u2014 "),nne=n(AKe,"A",{href:!0});var _ua=s(nne);iot=r(_ua,"TFDistilBertForSequenceClassification"),_ua.forEach(t),dot=r(AKe," (DistilBERT model)"),AKe.forEach(t),mot=i(ae),kA=n(ae,"LI",{});var LKe=s(kA);n9e=n(LKe,"STRONG",{});var bua=s(n9e);cot=r(bua,"electra"),bua.forEach(t),fot=r(LKe," \u2014 "),sne=n(LKe,"A",{href:!0});var vua=s(sne);got=r(vua,"TFElectraForSequenceClassification"),vua.forEach(t),hot=r(LKe," (ELECTRA model)"),LKe.forEach(t),uot=i(ae),SA=n(ae,"LI",{});var yKe=s(SA);s9e=n(yKe,"STRONG",{});var Fua=s(s9e);pot=r(Fua,"esm"),Fua.forEach(t),_ot=r(yKe," \u2014 "),lne=n(yKe,"A",{href:!0});var Tua=s(lne);bot=r(Tua,"TFEsmForSequenceClassification"),Tua.forEach(t),vot=r(yKe," (ESM model)"),yKe.forEach(t),Fot=i(ae),RA=n(ae,"LI",{});var xKe=s(RA);l9e=n(xKe,"STRONG",{});var Mua=s(l9e);Tot=r(Mua,"flaubert"),Mua.forEach(t),Mot=r(xKe," \u2014 "),ine=n(xKe,"A",{href:!0});var Eua=s(ine);Eot=r(Eua,"TFFlaubertForSequenceClassification"),Eua.forEach(t),Cot=r(xKe," (FlauBERT model)"),xKe.forEach(t),wot=i(ae),PA=n(ae,"LI",{});var $Ke=s(PA);i9e=n($Ke,"STRONG",{});var Cua=s(i9e);Aot=r(Cua,"funnel"),Cua.forEach(t),Lot=r($Ke," \u2014 "),dne=n($Ke,"A",{href:!0});var wua=s(dne);yot=r(wua,"TFFunnelForSequenceClassification"),wua.forEach(t),xot=r($Ke," (Funnel Transformer model)"),$Ke.forEach(t),$ot=i(ae),BA=n(ae,"LI",{});var kKe=s(BA);d9e=n(kKe,"STRONG",{});var Aua=s(d9e);kot=r(Aua,"gpt2"),Aua.forEach(t),Sot=r(kKe," \u2014 "),mne=n(kKe,"A",{href:!0});var Lua=s(mne);Rot=r(Lua,"TFGPT2ForSequenceClassification"),Lua.forEach(t),Pot=r(kKe," (OpenAI GPT-2 model)"),kKe.forEach(t),Bot=i(ae),IA=n(ae,"LI",{});var SKe=s(IA);m9e=n(SKe,"STRONG",{});var yua=s(m9e);Iot=r(yua,"gptj"),yua.forEach(t),Not=r(SKe," \u2014 "),cne=n(SKe,"A",{href:!0});var xua=s(cne);qot=r(xua,"TFGPTJForSequenceClassification"),xua.forEach(t),jot=r(SKe," (GPT-J model)"),SKe.forEach(t),Dot=i(ae),NA=n(ae,"LI",{});var RKe=s(NA);c9e=n(RKe,"STRONG",{});var $ua=s(c9e);Got=r($ua,"layoutlm"),$ua.forEach(t),Oot=r(RKe," \u2014 "),fne=n(RKe,"A",{href:!0});var kua=s(fne);Vot=r(kua,"TFLayoutLMForSequenceClassification"),kua.forEach(t),Xot=r(RKe," (LayoutLM model)"),RKe.forEach(t),zot=i(ae),qA=n(ae,"LI",{});var PKe=s(qA);f9e=n(PKe,"STRONG",{});var Sua=s(f9e);Qot=r(Sua,"layoutlmv3"),Sua.forEach(t),Wot=r(PKe," \u2014 "),gne=n(PKe,"A",{href:!0});var Rua=s(gne);Uot=r(Rua,"TFLayoutLMv3ForSequenceClassification"),Rua.forEach(t),Hot=r(PKe," (LayoutLMv3 model)"),PKe.forEach(t),Jot=i(ae),jA=n(ae,"LI",{});var BKe=s(jA);g9e=n(BKe,"STRONG",{});var Pua=s(g9e);Yot=r(Pua,"longformer"),Pua.forEach(t),Zot=r(BKe," \u2014 "),hne=n(BKe,"A",{href:!0});var Bua=s(hne);Kot=r(Bua,"TFLongformerForSequenceClassification"),Bua.forEach(t),ert=r(BKe," (Longformer model)"),BKe.forEach(t),ort=i(ae),DA=n(ae,"LI",{});var IKe=s(DA);h9e=n(IKe,"STRONG",{});var Iua=s(h9e);rrt=r(Iua,"mobilebert"),Iua.forEach(t),trt=r(IKe," \u2014 "),une=n(IKe,"A",{href:!0});var Nua=s(une);art=r(Nua,"TFMobileBertForSequenceClassification"),Nua.forEach(t),nrt=r(IKe," (MobileBERT model)"),IKe.forEach(t),srt=i(ae),GA=n(ae,"LI",{});var NKe=s(GA);u9e=n(NKe,"STRONG",{});var qua=s(u9e);lrt=r(qua,"mpnet"),qua.forEach(t),irt=r(NKe," \u2014 "),pne=n(NKe,"A",{href:!0});var jua=s(pne);drt=r(jua,"TFMPNetForSequenceClassification"),jua.forEach(t),mrt=r(NKe," (MPNet model)"),NKe.forEach(t),crt=i(ae),OA=n(ae,"LI",{});var qKe=s(OA);p9e=n(qKe,"STRONG",{});var Dua=s(p9e);frt=r(Dua,"openai-gpt"),Dua.forEach(t),grt=r(qKe," \u2014 "),_ne=n(qKe,"A",{href:!0});var Gua=s(_ne);hrt=r(Gua,"TFOpenAIGPTForSequenceClassification"),Gua.forEach(t),urt=r(qKe," (OpenAI GPT model)"),qKe.forEach(t),prt=i(ae),VA=n(ae,"LI",{});var jKe=s(VA);_9e=n(jKe,"STRONG",{});var Oua=s(_9e);_rt=r(Oua,"rembert"),Oua.forEach(t),brt=r(jKe," \u2014 "),bne=n(jKe,"A",{href:!0});var Vua=s(bne);vrt=r(Vua,"TFRemBertForSequenceClassification"),Vua.forEach(t),Frt=r(jKe," (RemBERT model)"),jKe.forEach(t),Trt=i(ae),XA=n(ae,"LI",{});var DKe=s(XA);b9e=n(DKe,"STRONG",{});var Xua=s(b9e);Mrt=r(Xua,"roberta"),Xua.forEach(t),Ert=r(DKe," \u2014 "),vne=n(DKe,"A",{href:!0});var zua=s(vne);Crt=r(zua,"TFRobertaForSequenceClassification"),zua.forEach(t),wrt=r(DKe," (RoBERTa model)"),DKe.forEach(t),Art=i(ae),zA=n(ae,"LI",{});var GKe=s(zA);v9e=n(GKe,"STRONG",{});var Qua=s(v9e);Lrt=r(Qua,"roformer"),Qua.forEach(t),yrt=r(GKe," \u2014 "),Fne=n(GKe,"A",{href:!0});var Wua=s(Fne);xrt=r(Wua,"TFRoFormerForSequenceClassification"),Wua.forEach(t),$rt=r(GKe," (RoFormer model)"),GKe.forEach(t),krt=i(ae),QA=n(ae,"LI",{});var OKe=s(QA);F9e=n(OKe,"STRONG",{});var Uua=s(F9e);Srt=r(Uua,"tapas"),Uua.forEach(t),Rrt=r(OKe," \u2014 "),Tne=n(OKe,"A",{href:!0});var Hua=s(Tne);Prt=r(Hua,"TFTapasForSequenceClassification"),Hua.forEach(t),Brt=r(OKe," (TAPAS model)"),OKe.forEach(t),Irt=i(ae),WA=n(ae,"LI",{});var VKe=s(WA);T9e=n(VKe,"STRONG",{});var Jua=s(T9e);Nrt=r(Jua,"transfo-xl"),Jua.forEach(t),qrt=r(VKe," \u2014 "),Mne=n(VKe,"A",{href:!0});var Yua=s(Mne);jrt=r(Yua,"TFTransfoXLForSequenceClassification"),Yua.forEach(t),Drt=r(VKe," (Transformer-XL model)"),VKe.forEach(t),Grt=i(ae),UA=n(ae,"LI",{});var XKe=s(UA);M9e=n(XKe,"STRONG",{});var Zua=s(M9e);Ort=r(Zua,"xlm"),Zua.forEach(t),Vrt=r(XKe," \u2014 "),Ene=n(XKe,"A",{href:!0});var Kua=s(Ene);Xrt=r(Kua,"TFXLMForSequenceClassification"),Kua.forEach(t),zrt=r(XKe," (XLM model)"),XKe.forEach(t),Qrt=i(ae),HA=n(ae,"LI",{});var zKe=s(HA);E9e=n(zKe,"STRONG",{});var epa=s(E9e);Wrt=r(epa,"xlm-roberta"),epa.forEach(t),Urt=r(zKe," \u2014 "),Cne=n(zKe,"A",{href:!0});var opa=s(Cne);Hrt=r(opa,"TFXLMRobertaForSequenceClassification"),opa.forEach(t),Jrt=r(zKe," (XLM-RoBERTa model)"),zKe.forEach(t),Yrt=i(ae),JA=n(ae,"LI",{});var QKe=s(JA);C9e=n(QKe,"STRONG",{});var rpa=s(C9e);Zrt=r(rpa,"xlnet"),rpa.forEach(t),Krt=r(QKe," \u2014 "),wne=n(QKe,"A",{href:!0});var tpa=s(wne);ett=r(tpa,"TFXLNetForSequenceClassification"),tpa.forEach(t),ott=r(QKe," (XLNet model)"),QKe.forEach(t),ae.forEach(t),rtt=i(xi),T(YA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),jao=i(c),Rc=n(c,"H2",{class:!0});var alo=s(Rc);ZA=n(alo,"A",{id:!0,class:!0,href:!0});var apa=s(ZA);w9e=n(apa,"SPAN",{});var npa=s(w9e);T(JR.$$.fragment,npa),npa.forEach(t),apa.forEach(t),ttt=i(alo),A9e=n(alo,"SPAN",{});var spa=s(A9e);att=r(spa,"TFAutoModelForMultipleChoice"),spa.forEach(t),alo.forEach(t),Dao=i(c),br=n(c,"DIV",{class:!0});var $i=s(br);T(YR.$$.fragment,$i),ntt=i($i),Pc=n($i,"P",{});var uce=s(Pc);stt=r(uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ane=n(uce,"A",{href:!0});var lpa=s(Ane);ltt=r(lpa,"from_pretrained()"),lpa.forEach(t),itt=r(uce," class method or the "),Lne=n(uce,"A",{href:!0});var ipa=s(Lne);dtt=r(ipa,"from_config()"),ipa.forEach(t),mtt=r(uce,` class
method.`),uce.forEach(t),ctt=i($i),ZR=n($i,"P",{});var nlo=s(ZR);ftt=r(nlo,"This class cannot be instantiated directly using "),L9e=n(nlo,"CODE",{});var dpa=s(L9e);gtt=r(dpa,"__init__()"),dpa.forEach(t),htt=r(nlo," (throws an error)."),nlo.forEach(t),utt=i($i),aa=n($i,"DIV",{class:!0});var ux=s(aa);T(KR.$$.fragment,ux),ptt=i(ux),y9e=n(ux,"P",{});var mpa=s(y9e);_tt=r(mpa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),mpa.forEach(t),btt=i(ux),Bc=n(ux,"P",{});var pce=s(Bc);vtt=r(pce,`Note:
Loading a model from its configuration file does `),x9e=n(pce,"STRONG",{});var cpa=s(x9e);Ftt=r(cpa,"not"),cpa.forEach(t),Ttt=r(pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=n(pce,"A",{href:!0});var fpa=s(yne);Mtt=r(fpa,"from_pretrained()"),fpa.forEach(t),Ett=r(pce," to load the model weights."),pce.forEach(t),Ctt=i(ux),T(KA.$$.fragment,ux),ux.forEach(t),wtt=i($i),Ur=n($i,"DIV",{class:!0});var ki=s(Ur);T(eP.$$.fragment,ki),Att=i(ki),$9e=n(ki,"P",{});var gpa=s($9e);Ltt=r(gpa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gpa.forEach(t),ytt=i(ki),Vn=n(ki,"P",{});var px=s(Vn);xtt=r(px,"The model class to instantiate is selected based on the "),k9e=n(px,"CODE",{});var hpa=s(k9e);$tt=r(hpa,"model_type"),hpa.forEach(t),ktt=r(px,` property of the config object (either
passed as an argument or loaded from `),S9e=n(px,"CODE",{});var upa=s(S9e);Stt=r(upa,"pretrained_model_name_or_path"),upa.forEach(t),Rtt=r(px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R9e=n(px,"CODE",{});var ppa=s(R9e);Ptt=r(ppa,"pretrained_model_name_or_path"),ppa.forEach(t),Btt=r(px,":"),px.forEach(t),Itt=i(ki),ve=n(ki,"UL",{});var Te=s(ve);e6=n(Te,"LI",{});var WKe=s(e6);P9e=n(WKe,"STRONG",{});var _pa=s(P9e);Ntt=r(_pa,"albert"),_pa.forEach(t),qtt=r(WKe," \u2014 "),xne=n(WKe,"A",{href:!0});var bpa=s(xne);jtt=r(bpa,"TFAlbertForMultipleChoice"),bpa.forEach(t),Dtt=r(WKe," (ALBERT model)"),WKe.forEach(t),Gtt=i(Te),o6=n(Te,"LI",{});var UKe=s(o6);B9e=n(UKe,"STRONG",{});var vpa=s(B9e);Ott=r(vpa,"bert"),vpa.forEach(t),Vtt=r(UKe," \u2014 "),$ne=n(UKe,"A",{href:!0});var Fpa=s($ne);Xtt=r(Fpa,"TFBertForMultipleChoice"),Fpa.forEach(t),ztt=r(UKe," (BERT model)"),UKe.forEach(t),Qtt=i(Te),r6=n(Te,"LI",{});var HKe=s(r6);I9e=n(HKe,"STRONG",{});var Tpa=s(I9e);Wtt=r(Tpa,"camembert"),Tpa.forEach(t),Utt=r(HKe," \u2014 "),kne=n(HKe,"A",{href:!0});var Mpa=s(kne);Htt=r(Mpa,"TFCamembertForMultipleChoice"),Mpa.forEach(t),Jtt=r(HKe," (CamemBERT model)"),HKe.forEach(t),Ytt=i(Te),t6=n(Te,"LI",{});var JKe=s(t6);N9e=n(JKe,"STRONG",{});var Epa=s(N9e);Ztt=r(Epa,"convbert"),Epa.forEach(t),Ktt=r(JKe," \u2014 "),Sne=n(JKe,"A",{href:!0});var Cpa=s(Sne);eat=r(Cpa,"TFConvBertForMultipleChoice"),Cpa.forEach(t),oat=r(JKe," (ConvBERT model)"),JKe.forEach(t),rat=i(Te),a6=n(Te,"LI",{});var YKe=s(a6);q9e=n(YKe,"STRONG",{});var wpa=s(q9e);tat=r(wpa,"distilbert"),wpa.forEach(t),aat=r(YKe," \u2014 "),Rne=n(YKe,"A",{href:!0});var Apa=s(Rne);nat=r(Apa,"TFDistilBertForMultipleChoice"),Apa.forEach(t),sat=r(YKe," (DistilBERT model)"),YKe.forEach(t),lat=i(Te),n6=n(Te,"LI",{});var ZKe=s(n6);j9e=n(ZKe,"STRONG",{});var Lpa=s(j9e);iat=r(Lpa,"electra"),Lpa.forEach(t),dat=r(ZKe," \u2014 "),Pne=n(ZKe,"A",{href:!0});var ypa=s(Pne);mat=r(ypa,"TFElectraForMultipleChoice"),ypa.forEach(t),cat=r(ZKe," (ELECTRA model)"),ZKe.forEach(t),fat=i(Te),s6=n(Te,"LI",{});var KKe=s(s6);D9e=n(KKe,"STRONG",{});var xpa=s(D9e);gat=r(xpa,"flaubert"),xpa.forEach(t),hat=r(KKe," \u2014 "),Bne=n(KKe,"A",{href:!0});var $pa=s(Bne);uat=r($pa,"TFFlaubertForMultipleChoice"),$pa.forEach(t),pat=r(KKe," (FlauBERT model)"),KKe.forEach(t),_at=i(Te),l6=n(Te,"LI",{});var eeo=s(l6);G9e=n(eeo,"STRONG",{});var kpa=s(G9e);bat=r(kpa,"funnel"),kpa.forEach(t),vat=r(eeo," \u2014 "),Ine=n(eeo,"A",{href:!0});var Spa=s(Ine);Fat=r(Spa,"TFFunnelForMultipleChoice"),Spa.forEach(t),Tat=r(eeo," (Funnel Transformer model)"),eeo.forEach(t),Mat=i(Te),i6=n(Te,"LI",{});var oeo=s(i6);O9e=n(oeo,"STRONG",{});var Rpa=s(O9e);Eat=r(Rpa,"longformer"),Rpa.forEach(t),Cat=r(oeo," \u2014 "),Nne=n(oeo,"A",{href:!0});var Ppa=s(Nne);wat=r(Ppa,"TFLongformerForMultipleChoice"),Ppa.forEach(t),Aat=r(oeo," (Longformer model)"),oeo.forEach(t),Lat=i(Te),d6=n(Te,"LI",{});var reo=s(d6);V9e=n(reo,"STRONG",{});var Bpa=s(V9e);yat=r(Bpa,"mobilebert"),Bpa.forEach(t),xat=r(reo," \u2014 "),qne=n(reo,"A",{href:!0});var Ipa=s(qne);$at=r(Ipa,"TFMobileBertForMultipleChoice"),Ipa.forEach(t),kat=r(reo," (MobileBERT model)"),reo.forEach(t),Sat=i(Te),m6=n(Te,"LI",{});var teo=s(m6);X9e=n(teo,"STRONG",{});var Npa=s(X9e);Rat=r(Npa,"mpnet"),Npa.forEach(t),Pat=r(teo," \u2014 "),jne=n(teo,"A",{href:!0});var qpa=s(jne);Bat=r(qpa,"TFMPNetForMultipleChoice"),qpa.forEach(t),Iat=r(teo," (MPNet model)"),teo.forEach(t),Nat=i(Te),c6=n(Te,"LI",{});var aeo=s(c6);z9e=n(aeo,"STRONG",{});var jpa=s(z9e);qat=r(jpa,"rembert"),jpa.forEach(t),jat=r(aeo," \u2014 "),Dne=n(aeo,"A",{href:!0});var Dpa=s(Dne);Dat=r(Dpa,"TFRemBertForMultipleChoice"),Dpa.forEach(t),Gat=r(aeo," (RemBERT model)"),aeo.forEach(t),Oat=i(Te),f6=n(Te,"LI",{});var neo=s(f6);Q9e=n(neo,"STRONG",{});var Gpa=s(Q9e);Vat=r(Gpa,"roberta"),Gpa.forEach(t),Xat=r(neo," \u2014 "),Gne=n(neo,"A",{href:!0});var Opa=s(Gne);zat=r(Opa,"TFRobertaForMultipleChoice"),Opa.forEach(t),Qat=r(neo," (RoBERTa model)"),neo.forEach(t),Wat=i(Te),g6=n(Te,"LI",{});var seo=s(g6);W9e=n(seo,"STRONG",{});var Vpa=s(W9e);Uat=r(Vpa,"roformer"),Vpa.forEach(t),Hat=r(seo," \u2014 "),One=n(seo,"A",{href:!0});var Xpa=s(One);Jat=r(Xpa,"TFRoFormerForMultipleChoice"),Xpa.forEach(t),Yat=r(seo," (RoFormer model)"),seo.forEach(t),Zat=i(Te),h6=n(Te,"LI",{});var leo=s(h6);U9e=n(leo,"STRONG",{});var zpa=s(U9e);Kat=r(zpa,"xlm"),zpa.forEach(t),ent=r(leo," \u2014 "),Vne=n(leo,"A",{href:!0});var Qpa=s(Vne);ont=r(Qpa,"TFXLMForMultipleChoice"),Qpa.forEach(t),rnt=r(leo," (XLM model)"),leo.forEach(t),tnt=i(Te),u6=n(Te,"LI",{});var ieo=s(u6);H9e=n(ieo,"STRONG",{});var Wpa=s(H9e);ant=r(Wpa,"xlm-roberta"),Wpa.forEach(t),nnt=r(ieo," \u2014 "),Xne=n(ieo,"A",{href:!0});var Upa=s(Xne);snt=r(Upa,"TFXLMRobertaForMultipleChoice"),Upa.forEach(t),lnt=r(ieo," (XLM-RoBERTa model)"),ieo.forEach(t),int=i(Te),p6=n(Te,"LI",{});var deo=s(p6);J9e=n(deo,"STRONG",{});var Hpa=s(J9e);dnt=r(Hpa,"xlnet"),Hpa.forEach(t),mnt=r(deo," \u2014 "),zne=n(deo,"A",{href:!0});var Jpa=s(zne);cnt=r(Jpa,"TFXLNetForMultipleChoice"),Jpa.forEach(t),fnt=r(deo," (XLNet model)"),deo.forEach(t),Te.forEach(t),gnt=i(ki),T(_6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),Gao=i(c),Ic=n(c,"H2",{class:!0});var slo=s(Ic);b6=n(slo,"A",{id:!0,class:!0,href:!0});var Ypa=s(b6);Y9e=n(Ypa,"SPAN",{});var Zpa=s(Y9e);T(oP.$$.fragment,Zpa),Zpa.forEach(t),Ypa.forEach(t),hnt=i(slo),Z9e=n(slo,"SPAN",{});var Kpa=s(Z9e);unt=r(Kpa,"TFAutoModelForNextSentencePrediction"),Kpa.forEach(t),slo.forEach(t),Oao=i(c),vr=n(c,"DIV",{class:!0});var Si=s(vr);T(rP.$$.fragment,Si),pnt=i(Si),Nc=n(Si,"P",{});var _ce=s(Nc);_nt=r(_ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Qne=n(_ce,"A",{href:!0});var e_a=s(Qne);bnt=r(e_a,"from_pretrained()"),e_a.forEach(t),vnt=r(_ce," class method or the "),Wne=n(_ce,"A",{href:!0});var o_a=s(Wne);Fnt=r(o_a,"from_config()"),o_a.forEach(t),Tnt=r(_ce,` class
method.`),_ce.forEach(t),Mnt=i(Si),tP=n(Si,"P",{});var llo=s(tP);Ent=r(llo,"This class cannot be instantiated directly using "),K9e=n(llo,"CODE",{});var r_a=s(K9e);Cnt=r(r_a,"__init__()"),r_a.forEach(t),wnt=r(llo," (throws an error)."),llo.forEach(t),Ant=i(Si),na=n(Si,"DIV",{class:!0});var _x=s(na);T(aP.$$.fragment,_x),Lnt=i(_x),exe=n(_x,"P",{});var t_a=s(exe);ynt=r(t_a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),t_a.forEach(t),xnt=i(_x),qc=n(_x,"P",{});var bce=s(qc);$nt=r(bce,`Note:
Loading a model from its configuration file does `),oxe=n(bce,"STRONG",{});var a_a=s(oxe);knt=r(a_a,"not"),a_a.forEach(t),Snt=r(bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=n(bce,"A",{href:!0});var n_a=s(Une);Rnt=r(n_a,"from_pretrained()"),n_a.forEach(t),Pnt=r(bce," to load the model weights."),bce.forEach(t),Bnt=i(_x),T(v6.$$.fragment,_x),_x.forEach(t),Int=i(Si),Hr=n(Si,"DIV",{class:!0});var Ri=s(Hr);T(nP.$$.fragment,Ri),Nnt=i(Ri),rxe=n(Ri,"P",{});var s_a=s(rxe);qnt=r(s_a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),s_a.forEach(t),jnt=i(Ri),Xn=n(Ri,"P",{});var bx=s(Xn);Dnt=r(bx,"The model class to instantiate is selected based on the "),txe=n(bx,"CODE",{});var l_a=s(txe);Gnt=r(l_a,"model_type"),l_a.forEach(t),Ont=r(bx,` property of the config object (either
passed as an argument or loaded from `),axe=n(bx,"CODE",{});var i_a=s(axe);Vnt=r(i_a,"pretrained_model_name_or_path"),i_a.forEach(t),Xnt=r(bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nxe=n(bx,"CODE",{});var d_a=s(nxe);znt=r(d_a,"pretrained_model_name_or_path"),d_a.forEach(t),Qnt=r(bx,":"),bx.forEach(t),Wnt=i(Ri),sP=n(Ri,"UL",{});var ilo=s(sP);F6=n(ilo,"LI",{});var meo=s(F6);sxe=n(meo,"STRONG",{});var m_a=s(sxe);Unt=r(m_a,"bert"),m_a.forEach(t),Hnt=r(meo," \u2014 "),Hne=n(meo,"A",{href:!0});var c_a=s(Hne);Jnt=r(c_a,"TFBertForNextSentencePrediction"),c_a.forEach(t),Ynt=r(meo," (BERT model)"),meo.forEach(t),Znt=i(ilo),T6=n(ilo,"LI",{});var ceo=s(T6);lxe=n(ceo,"STRONG",{});var f_a=s(lxe);Knt=r(f_a,"mobilebert"),f_a.forEach(t),est=r(ceo," \u2014 "),Jne=n(ceo,"A",{href:!0});var g_a=s(Jne);ost=r(g_a,"TFMobileBertForNextSentencePrediction"),g_a.forEach(t),rst=r(ceo," (MobileBERT model)"),ceo.forEach(t),ilo.forEach(t),tst=i(Ri),T(M6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),Vao=i(c),jc=n(c,"H2",{class:!0});var dlo=s(jc);E6=n(dlo,"A",{id:!0,class:!0,href:!0});var h_a=s(E6);ixe=n(h_a,"SPAN",{});var u_a=s(ixe);T(lP.$$.fragment,u_a),u_a.forEach(t),h_a.forEach(t),ast=i(dlo),dxe=n(dlo,"SPAN",{});var p_a=s(dxe);nst=r(p_a,"TFAutoModelForTableQuestionAnswering"),p_a.forEach(t),dlo.forEach(t),Xao=i(c),Fr=n(c,"DIV",{class:!0});var Pi=s(Fr);T(iP.$$.fragment,Pi),sst=i(Pi),Dc=n(Pi,"P",{});var vce=s(Dc);lst=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Yne=n(vce,"A",{href:!0});var __a=s(Yne);ist=r(__a,"from_pretrained()"),__a.forEach(t),dst=r(vce," class method or the "),Zne=n(vce,"A",{href:!0});var b_a=s(Zne);mst=r(b_a,"from_config()"),b_a.forEach(t),cst=r(vce,` class
method.`),vce.forEach(t),fst=i(Pi),dP=n(Pi,"P",{});var mlo=s(dP);gst=r(mlo,"This class cannot be instantiated directly using "),mxe=n(mlo,"CODE",{});var v_a=s(mxe);hst=r(v_a,"__init__()"),v_a.forEach(t),ust=r(mlo," (throws an error)."),mlo.forEach(t),pst=i(Pi),sa=n(Pi,"DIV",{class:!0});var vx=s(sa);T(mP.$$.fragment,vx),_st=i(vx),cxe=n(vx,"P",{});var F_a=s(cxe);bst=r(F_a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),F_a.forEach(t),vst=i(vx),Gc=n(vx,"P",{});var Fce=s(Gc);Fst=r(Fce,`Note:
Loading a model from its configuration file does `),fxe=n(Fce,"STRONG",{});var T_a=s(fxe);Tst=r(T_a,"not"),T_a.forEach(t),Mst=r(Fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kne=n(Fce,"A",{href:!0});var M_a=s(Kne);Est=r(M_a,"from_pretrained()"),M_a.forEach(t),Cst=r(Fce," to load the model weights."),Fce.forEach(t),wst=i(vx),T(C6.$$.fragment,vx),vx.forEach(t),Ast=i(Pi),Jr=n(Pi,"DIV",{class:!0});var Bi=s(Jr);T(cP.$$.fragment,Bi),Lst=i(Bi),gxe=n(Bi,"P",{});var E_a=s(gxe);yst=r(E_a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),E_a.forEach(t),xst=i(Bi),zn=n(Bi,"P",{});var Fx=s(zn);$st=r(Fx,"The model class to instantiate is selected based on the "),hxe=n(Fx,"CODE",{});var C_a=s(hxe);kst=r(C_a,"model_type"),C_a.forEach(t),Sst=r(Fx,` property of the config object (either
passed as an argument or loaded from `),uxe=n(Fx,"CODE",{});var w_a=s(uxe);Rst=r(w_a,"pretrained_model_name_or_path"),w_a.forEach(t),Pst=r(Fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pxe=n(Fx,"CODE",{});var A_a=s(pxe);Bst=r(A_a,"pretrained_model_name_or_path"),A_a.forEach(t),Ist=r(Fx,":"),Fx.forEach(t),Nst=i(Bi),_xe=n(Bi,"UL",{});var L_a=s(_xe);w6=n(L_a,"LI",{});var feo=s(w6);bxe=n(feo,"STRONG",{});var y_a=s(bxe);qst=r(y_a,"tapas"),y_a.forEach(t),jst=r(feo," \u2014 "),ese=n(feo,"A",{href:!0});var x_a=s(ese);Dst=r(x_a,"TFTapasForQuestionAnswering"),x_a.forEach(t),Gst=r(feo," (TAPAS model)"),feo.forEach(t),L_a.forEach(t),Ost=i(Bi),T(A6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),zao=i(c),Oc=n(c,"H2",{class:!0});var clo=s(Oc);L6=n(clo,"A",{id:!0,class:!0,href:!0});var $_a=s(L6);vxe=n($_a,"SPAN",{});var k_a=s(vxe);T(fP.$$.fragment,k_a),k_a.forEach(t),$_a.forEach(t),Vst=i(clo),Fxe=n(clo,"SPAN",{});var S_a=s(Fxe);Xst=r(S_a,"TFAutoModelForDocumentQuestionAnswering"),S_a.forEach(t),clo.forEach(t),Qao=i(c),Tr=n(c,"DIV",{class:!0});var Ii=s(Tr);T(gP.$$.fragment,Ii),zst=i(Ii),Vc=n(Ii,"P",{});var Tce=s(Vc);Qst=r(Tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),ose=n(Tce,"A",{href:!0});var R_a=s(ose);Wst=r(R_a,"from_pretrained()"),R_a.forEach(t),Ust=r(Tce," class method or the "),rse=n(Tce,"A",{href:!0});var P_a=s(rse);Hst=r(P_a,"from_config()"),P_a.forEach(t),Jst=r(Tce,` class
method.`),Tce.forEach(t),Yst=i(Ii),hP=n(Ii,"P",{});var flo=s(hP);Zst=r(flo,"This class cannot be instantiated directly using "),Txe=n(flo,"CODE",{});var B_a=s(Txe);Kst=r(B_a,"__init__()"),B_a.forEach(t),elt=r(flo," (throws an error)."),flo.forEach(t),olt=i(Ii),la=n(Ii,"DIV",{class:!0});var Tx=s(la);T(uP.$$.fragment,Tx),rlt=i(Tx),Mxe=n(Tx,"P",{});var I_a=s(Mxe);tlt=r(I_a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),I_a.forEach(t),alt=i(Tx),Xc=n(Tx,"P",{});var Mce=s(Xc);nlt=r(Mce,`Note:
Loading a model from its configuration file does `),Exe=n(Mce,"STRONG",{});var N_a=s(Exe);slt=r(N_a,"not"),N_a.forEach(t),llt=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),tse=n(Mce,"A",{href:!0});var q_a=s(tse);ilt=r(q_a,"from_pretrained()"),q_a.forEach(t),dlt=r(Mce," to load the model weights."),Mce.forEach(t),mlt=i(Tx),T(y6.$$.fragment,Tx),Tx.forEach(t),clt=i(Ii),Yr=n(Ii,"DIV",{class:!0});var Ni=s(Yr);T(pP.$$.fragment,Ni),flt=i(Ni),Cxe=n(Ni,"P",{});var j_a=s(Cxe);glt=r(j_a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),j_a.forEach(t),hlt=i(Ni),Qn=n(Ni,"P",{});var Mx=s(Qn);ult=r(Mx,"The model class to instantiate is selected based on the "),wxe=n(Mx,"CODE",{});var D_a=s(wxe);plt=r(D_a,"model_type"),D_a.forEach(t),_lt=r(Mx,` property of the config object (either
passed as an argument or loaded from `),Axe=n(Mx,"CODE",{});var G_a=s(Axe);blt=r(G_a,"pretrained_model_name_or_path"),G_a.forEach(t),vlt=r(Mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lxe=n(Mx,"CODE",{});var O_a=s(Lxe);Flt=r(O_a,"pretrained_model_name_or_path"),O_a.forEach(t),Tlt=r(Mx,":"),Mx.forEach(t),Mlt=i(Ni),yxe=n(Ni,"UL",{});var V_a=s(yxe);x6=n(V_a,"LI",{});var geo=s(x6);xxe=n(geo,"STRONG",{});var X_a=s(xxe);Elt=r(X_a,"layoutlm"),X_a.forEach(t),Clt=r(geo," \u2014 "),ase=n(geo,"A",{href:!0});var z_a=s(ase);wlt=r(z_a,"TFLayoutLMForQuestionAnswering"),z_a.forEach(t),Alt=r(geo," (LayoutLM model)"),geo.forEach(t),V_a.forEach(t),Llt=i(Ni),T($6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),Wao=i(c),zc=n(c,"H2",{class:!0});var glo=s(zc);k6=n(glo,"A",{id:!0,class:!0,href:!0});var Q_a=s(k6);$xe=n(Q_a,"SPAN",{});var W_a=s($xe);T(_P.$$.fragment,W_a),W_a.forEach(t),Q_a.forEach(t),ylt=i(glo),kxe=n(glo,"SPAN",{});var U_a=s(kxe);xlt=r(U_a,"TFAutoModelForTokenClassification"),U_a.forEach(t),glo.forEach(t),Uao=i(c),Mr=n(c,"DIV",{class:!0});var qi=s(Mr);T(bP.$$.fragment,qi),$lt=i(qi),Qc=n(qi,"P",{});var Ece=s(Qc);klt=r(Ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),nse=n(Ece,"A",{href:!0});var H_a=s(nse);Slt=r(H_a,"from_pretrained()"),H_a.forEach(t),Rlt=r(Ece," class method or the "),sse=n(Ece,"A",{href:!0});var J_a=s(sse);Plt=r(J_a,"from_config()"),J_a.forEach(t),Blt=r(Ece,` class
method.`),Ece.forEach(t),Ilt=i(qi),vP=n(qi,"P",{});var hlo=s(vP);Nlt=r(hlo,"This class cannot be instantiated directly using "),Sxe=n(hlo,"CODE",{});var Y_a=s(Sxe);qlt=r(Y_a,"__init__()"),Y_a.forEach(t),jlt=r(hlo," (throws an error)."),hlo.forEach(t),Dlt=i(qi),ia=n(qi,"DIV",{class:!0});var Ex=s(ia);T(FP.$$.fragment,Ex),Glt=i(Ex),Rxe=n(Ex,"P",{});var Z_a=s(Rxe);Olt=r(Z_a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Z_a.forEach(t),Vlt=i(Ex),Wc=n(Ex,"P",{});var Cce=s(Wc);Xlt=r(Cce,`Note:
Loading a model from its configuration file does `),Pxe=n(Cce,"STRONG",{});var K_a=s(Pxe);zlt=r(K_a,"not"),K_a.forEach(t),Qlt=r(Cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=n(Cce,"A",{href:!0});var e1a=s(lse);Wlt=r(e1a,"from_pretrained()"),e1a.forEach(t),Ult=r(Cce," to load the model weights."),Cce.forEach(t),Hlt=i(Ex),T(S6.$$.fragment,Ex),Ex.forEach(t),Jlt=i(qi),Zr=n(qi,"DIV",{class:!0});var ji=s(Zr);T(TP.$$.fragment,ji),Ylt=i(ji),Bxe=n(ji,"P",{});var o1a=s(Bxe);Zlt=r(o1a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),o1a.forEach(t),Klt=i(ji),Wn=n(ji,"P",{});var Cx=s(Wn);eit=r(Cx,"The model class to instantiate is selected based on the "),Ixe=n(Cx,"CODE",{});var r1a=s(Ixe);oit=r(r1a,"model_type"),r1a.forEach(t),rit=r(Cx,` property of the config object (either
passed as an argument or loaded from `),Nxe=n(Cx,"CODE",{});var t1a=s(Nxe);tit=r(t1a,"pretrained_model_name_or_path"),t1a.forEach(t),ait=r(Cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qxe=n(Cx,"CODE",{});var a1a=s(qxe);nit=r(a1a,"pretrained_model_name_or_path"),a1a.forEach(t),sit=r(Cx,":"),Cx.forEach(t),lit=i(ji),ie=n(ji,"UL",{});var ge=s(ie);R6=n(ge,"LI",{});var heo=s(R6);jxe=n(heo,"STRONG",{});var n1a=s(jxe);iit=r(n1a,"albert"),n1a.forEach(t),dit=r(heo," \u2014 "),ise=n(heo,"A",{href:!0});var s1a=s(ise);mit=r(s1a,"TFAlbertForTokenClassification"),s1a.forEach(t),cit=r(heo," (ALBERT model)"),heo.forEach(t),fit=i(ge),P6=n(ge,"LI",{});var ueo=s(P6);Dxe=n(ueo,"STRONG",{});var l1a=s(Dxe);git=r(l1a,"bert"),l1a.forEach(t),hit=r(ueo," \u2014 "),dse=n(ueo,"A",{href:!0});var i1a=s(dse);uit=r(i1a,"TFBertForTokenClassification"),i1a.forEach(t),pit=r(ueo," (BERT model)"),ueo.forEach(t),_it=i(ge),B6=n(ge,"LI",{});var peo=s(B6);Gxe=n(peo,"STRONG",{});var d1a=s(Gxe);bit=r(d1a,"camembert"),d1a.forEach(t),vit=r(peo," \u2014 "),mse=n(peo,"A",{href:!0});var m1a=s(mse);Fit=r(m1a,"TFCamembertForTokenClassification"),m1a.forEach(t),Tit=r(peo," (CamemBERT model)"),peo.forEach(t),Mit=i(ge),I6=n(ge,"LI",{});var _eo=s(I6);Oxe=n(_eo,"STRONG",{});var c1a=s(Oxe);Eit=r(c1a,"convbert"),c1a.forEach(t),Cit=r(_eo," \u2014 "),cse=n(_eo,"A",{href:!0});var f1a=s(cse);wit=r(f1a,"TFConvBertForTokenClassification"),f1a.forEach(t),Ait=r(_eo," (ConvBERT model)"),_eo.forEach(t),Lit=i(ge),N6=n(ge,"LI",{});var beo=s(N6);Vxe=n(beo,"STRONG",{});var g1a=s(Vxe);yit=r(g1a,"deberta"),g1a.forEach(t),xit=r(beo," \u2014 "),fse=n(beo,"A",{href:!0});var h1a=s(fse);$it=r(h1a,"TFDebertaForTokenClassification"),h1a.forEach(t),kit=r(beo," (DeBERTa model)"),beo.forEach(t),Sit=i(ge),q6=n(ge,"LI",{});var veo=s(q6);Xxe=n(veo,"STRONG",{});var u1a=s(Xxe);Rit=r(u1a,"deberta-v2"),u1a.forEach(t),Pit=r(veo," \u2014 "),gse=n(veo,"A",{href:!0});var p1a=s(gse);Bit=r(p1a,"TFDebertaV2ForTokenClassification"),p1a.forEach(t),Iit=r(veo," (DeBERTa-v2 model)"),veo.forEach(t),Nit=i(ge),j6=n(ge,"LI",{});var Feo=s(j6);zxe=n(Feo,"STRONG",{});var _1a=s(zxe);qit=r(_1a,"distilbert"),_1a.forEach(t),jit=r(Feo," \u2014 "),hse=n(Feo,"A",{href:!0});var b1a=s(hse);Dit=r(b1a,"TFDistilBertForTokenClassification"),b1a.forEach(t),Git=r(Feo," (DistilBERT model)"),Feo.forEach(t),Oit=i(ge),D6=n(ge,"LI",{});var Teo=s(D6);Qxe=n(Teo,"STRONG",{});var v1a=s(Qxe);Vit=r(v1a,"electra"),v1a.forEach(t),Xit=r(Teo," \u2014 "),use=n(Teo,"A",{href:!0});var F1a=s(use);zit=r(F1a,"TFElectraForTokenClassification"),F1a.forEach(t),Qit=r(Teo," (ELECTRA model)"),Teo.forEach(t),Wit=i(ge),G6=n(ge,"LI",{});var Meo=s(G6);Wxe=n(Meo,"STRONG",{});var T1a=s(Wxe);Uit=r(T1a,"esm"),T1a.forEach(t),Hit=r(Meo," \u2014 "),pse=n(Meo,"A",{href:!0});var M1a=s(pse);Jit=r(M1a,"TFEsmForTokenClassification"),M1a.forEach(t),Yit=r(Meo," (ESM model)"),Meo.forEach(t),Zit=i(ge),O6=n(ge,"LI",{});var Eeo=s(O6);Uxe=n(Eeo,"STRONG",{});var E1a=s(Uxe);Kit=r(E1a,"flaubert"),E1a.forEach(t),edt=r(Eeo," \u2014 "),_se=n(Eeo,"A",{href:!0});var C1a=s(_se);odt=r(C1a,"TFFlaubertForTokenClassification"),C1a.forEach(t),rdt=r(Eeo," (FlauBERT model)"),Eeo.forEach(t),tdt=i(ge),V6=n(ge,"LI",{});var Ceo=s(V6);Hxe=n(Ceo,"STRONG",{});var w1a=s(Hxe);adt=r(w1a,"funnel"),w1a.forEach(t),ndt=r(Ceo," \u2014 "),bse=n(Ceo,"A",{href:!0});var A1a=s(bse);sdt=r(A1a,"TFFunnelForTokenClassification"),A1a.forEach(t),ldt=r(Ceo," (Funnel Transformer model)"),Ceo.forEach(t),idt=i(ge),X6=n(ge,"LI",{});var weo=s(X6);Jxe=n(weo,"STRONG",{});var L1a=s(Jxe);ddt=r(L1a,"layoutlm"),L1a.forEach(t),mdt=r(weo," \u2014 "),vse=n(weo,"A",{href:!0});var y1a=s(vse);cdt=r(y1a,"TFLayoutLMForTokenClassification"),y1a.forEach(t),fdt=r(weo," (LayoutLM model)"),weo.forEach(t),gdt=i(ge),z6=n(ge,"LI",{});var Aeo=s(z6);Yxe=n(Aeo,"STRONG",{});var x1a=s(Yxe);hdt=r(x1a,"layoutlmv3"),x1a.forEach(t),udt=r(Aeo," \u2014 "),Fse=n(Aeo,"A",{href:!0});var $1a=s(Fse);pdt=r($1a,"TFLayoutLMv3ForTokenClassification"),$1a.forEach(t),_dt=r(Aeo," (LayoutLMv3 model)"),Aeo.forEach(t),bdt=i(ge),Q6=n(ge,"LI",{});var Leo=s(Q6);Zxe=n(Leo,"STRONG",{});var k1a=s(Zxe);vdt=r(k1a,"longformer"),k1a.forEach(t),Fdt=r(Leo," \u2014 "),Tse=n(Leo,"A",{href:!0});var S1a=s(Tse);Tdt=r(S1a,"TFLongformerForTokenClassification"),S1a.forEach(t),Mdt=r(Leo," (Longformer model)"),Leo.forEach(t),Edt=i(ge),W6=n(ge,"LI",{});var yeo=s(W6);Kxe=n(yeo,"STRONG",{});var R1a=s(Kxe);Cdt=r(R1a,"mobilebert"),R1a.forEach(t),wdt=r(yeo," \u2014 "),Mse=n(yeo,"A",{href:!0});var P1a=s(Mse);Adt=r(P1a,"TFMobileBertForTokenClassification"),P1a.forEach(t),Ldt=r(yeo," (MobileBERT model)"),yeo.forEach(t),ydt=i(ge),U6=n(ge,"LI",{});var xeo=s(U6);e$e=n(xeo,"STRONG",{});var B1a=s(e$e);xdt=r(B1a,"mpnet"),B1a.forEach(t),$dt=r(xeo," \u2014 "),Ese=n(xeo,"A",{href:!0});var I1a=s(Ese);kdt=r(I1a,"TFMPNetForTokenClassification"),I1a.forEach(t),Sdt=r(xeo," (MPNet model)"),xeo.forEach(t),Rdt=i(ge),H6=n(ge,"LI",{});var $eo=s(H6);o$e=n($eo,"STRONG",{});var N1a=s(o$e);Pdt=r(N1a,"rembert"),N1a.forEach(t),Bdt=r($eo," \u2014 "),Cse=n($eo,"A",{href:!0});var q1a=s(Cse);Idt=r(q1a,"TFRemBertForTokenClassification"),q1a.forEach(t),Ndt=r($eo," (RemBERT model)"),$eo.forEach(t),qdt=i(ge),J6=n(ge,"LI",{});var keo=s(J6);r$e=n(keo,"STRONG",{});var j1a=s(r$e);jdt=r(j1a,"roberta"),j1a.forEach(t),Ddt=r(keo," \u2014 "),wse=n(keo,"A",{href:!0});var D1a=s(wse);Gdt=r(D1a,"TFRobertaForTokenClassification"),D1a.forEach(t),Odt=r(keo," (RoBERTa model)"),keo.forEach(t),Vdt=i(ge),Y6=n(ge,"LI",{});var Seo=s(Y6);t$e=n(Seo,"STRONG",{});var G1a=s(t$e);Xdt=r(G1a,"roformer"),G1a.forEach(t),zdt=r(Seo," \u2014 "),Ase=n(Seo,"A",{href:!0});var O1a=s(Ase);Qdt=r(O1a,"TFRoFormerForTokenClassification"),O1a.forEach(t),Wdt=r(Seo," (RoFormer model)"),Seo.forEach(t),Udt=i(ge),Z6=n(ge,"LI",{});var Reo=s(Z6);a$e=n(Reo,"STRONG",{});var V1a=s(a$e);Hdt=r(V1a,"xlm"),V1a.forEach(t),Jdt=r(Reo," \u2014 "),Lse=n(Reo,"A",{href:!0});var X1a=s(Lse);Ydt=r(X1a,"TFXLMForTokenClassification"),X1a.forEach(t),Zdt=r(Reo," (XLM model)"),Reo.forEach(t),Kdt=i(ge),K6=n(ge,"LI",{});var Peo=s(K6);n$e=n(Peo,"STRONG",{});var z1a=s(n$e);emt=r(z1a,"xlm-roberta"),z1a.forEach(t),omt=r(Peo," \u2014 "),yse=n(Peo,"A",{href:!0});var Q1a=s(yse);rmt=r(Q1a,"TFXLMRobertaForTokenClassification"),Q1a.forEach(t),tmt=r(Peo," (XLM-RoBERTa model)"),Peo.forEach(t),amt=i(ge),e7=n(ge,"LI",{});var Beo=s(e7);s$e=n(Beo,"STRONG",{});var W1a=s(s$e);nmt=r(W1a,"xlnet"),W1a.forEach(t),smt=r(Beo," \u2014 "),xse=n(Beo,"A",{href:!0});var U1a=s(xse);lmt=r(U1a,"TFXLNetForTokenClassification"),U1a.forEach(t),imt=r(Beo," (XLNet model)"),Beo.forEach(t),ge.forEach(t),dmt=i(ji),T(o7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),Hao=i(c),Uc=n(c,"H2",{class:!0});var ulo=s(Uc);r7=n(ulo,"A",{id:!0,class:!0,href:!0});var H1a=s(r7);l$e=n(H1a,"SPAN",{});var J1a=s(l$e);T(MP.$$.fragment,J1a),J1a.forEach(t),H1a.forEach(t),mmt=i(ulo),i$e=n(ulo,"SPAN",{});var Y1a=s(i$e);cmt=r(Y1a,"TFAutoModelForQuestionAnswering"),Y1a.forEach(t),ulo.forEach(t),Jao=i(c),Er=n(c,"DIV",{class:!0});var Di=s(Er);T(EP.$$.fragment,Di),fmt=i(Di),Hc=n(Di,"P",{});var wce=s(Hc);gmt=r(wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$se=n(wce,"A",{href:!0});var Z1a=s($se);hmt=r(Z1a,"from_pretrained()"),Z1a.forEach(t),umt=r(wce," class method or the "),kse=n(wce,"A",{href:!0});var K1a=s(kse);pmt=r(K1a,"from_config()"),K1a.forEach(t),_mt=r(wce,` class
method.`),wce.forEach(t),bmt=i(Di),CP=n(Di,"P",{});var plo=s(CP);vmt=r(plo,"This class cannot be instantiated directly using "),d$e=n(plo,"CODE",{});var e2a=s(d$e);Fmt=r(e2a,"__init__()"),e2a.forEach(t),Tmt=r(plo," (throws an error)."),plo.forEach(t),Mmt=i(Di),da=n(Di,"DIV",{class:!0});var wx=s(da);T(wP.$$.fragment,wx),Emt=i(wx),m$e=n(wx,"P",{});var o2a=s(m$e);Cmt=r(o2a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),o2a.forEach(t),wmt=i(wx),Jc=n(wx,"P",{});var Ace=s(Jc);Amt=r(Ace,`Note:
Loading a model from its configuration file does `),c$e=n(Ace,"STRONG",{});var r2a=s(c$e);Lmt=r(r2a,"not"),r2a.forEach(t),ymt=r(Ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sse=n(Ace,"A",{href:!0});var t2a=s(Sse);xmt=r(t2a,"from_pretrained()"),t2a.forEach(t),$mt=r(Ace," to load the model weights."),Ace.forEach(t),kmt=i(wx),T(t7.$$.fragment,wx),wx.forEach(t),Smt=i(Di),Kr=n(Di,"DIV",{class:!0});var Gi=s(Kr);T(AP.$$.fragment,Gi),Rmt=i(Gi),f$e=n(Gi,"P",{});var a2a=s(f$e);Pmt=r(a2a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),a2a.forEach(t),Bmt=i(Gi),Un=n(Gi,"P",{});var Ax=s(Un);Imt=r(Ax,"The model class to instantiate is selected based on the "),g$e=n(Ax,"CODE",{});var n2a=s(g$e);Nmt=r(n2a,"model_type"),n2a.forEach(t),qmt=r(Ax,` property of the config object (either
passed as an argument or loaded from `),h$e=n(Ax,"CODE",{});var s2a=s(h$e);jmt=r(s2a,"pretrained_model_name_or_path"),s2a.forEach(t),Dmt=r(Ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u$e=n(Ax,"CODE",{});var l2a=s(u$e);Gmt=r(l2a,"pretrained_model_name_or_path"),l2a.forEach(t),Omt=r(Ax,":"),Ax.forEach(t),Vmt=i(Gi),fe=n(Gi,"UL",{});var pe=s(fe);a7=n(pe,"LI",{});var Ieo=s(a7);p$e=n(Ieo,"STRONG",{});var i2a=s(p$e);Xmt=r(i2a,"albert"),i2a.forEach(t),zmt=r(Ieo," \u2014 "),Rse=n(Ieo,"A",{href:!0});var d2a=s(Rse);Qmt=r(d2a,"TFAlbertForQuestionAnswering"),d2a.forEach(t),Wmt=r(Ieo," (ALBERT model)"),Ieo.forEach(t),Umt=i(pe),n7=n(pe,"LI",{});var Neo=s(n7);_$e=n(Neo,"STRONG",{});var m2a=s(_$e);Hmt=r(m2a,"bert"),m2a.forEach(t),Jmt=r(Neo," \u2014 "),Pse=n(Neo,"A",{href:!0});var c2a=s(Pse);Ymt=r(c2a,"TFBertForQuestionAnswering"),c2a.forEach(t),Zmt=r(Neo," (BERT model)"),Neo.forEach(t),Kmt=i(pe),s7=n(pe,"LI",{});var qeo=s(s7);b$e=n(qeo,"STRONG",{});var f2a=s(b$e);ect=r(f2a,"camembert"),f2a.forEach(t),oct=r(qeo," \u2014 "),Bse=n(qeo,"A",{href:!0});var g2a=s(Bse);rct=r(g2a,"TFCamembertForQuestionAnswering"),g2a.forEach(t),tct=r(qeo," (CamemBERT model)"),qeo.forEach(t),act=i(pe),l7=n(pe,"LI",{});var jeo=s(l7);v$e=n(jeo,"STRONG",{});var h2a=s(v$e);nct=r(h2a,"convbert"),h2a.forEach(t),sct=r(jeo," \u2014 "),Ise=n(jeo,"A",{href:!0});var u2a=s(Ise);lct=r(u2a,"TFConvBertForQuestionAnswering"),u2a.forEach(t),ict=r(jeo," (ConvBERT model)"),jeo.forEach(t),dct=i(pe),i7=n(pe,"LI",{});var Deo=s(i7);F$e=n(Deo,"STRONG",{});var p2a=s(F$e);mct=r(p2a,"deberta"),p2a.forEach(t),cct=r(Deo," \u2014 "),Nse=n(Deo,"A",{href:!0});var _2a=s(Nse);fct=r(_2a,"TFDebertaForQuestionAnswering"),_2a.forEach(t),gct=r(Deo," (DeBERTa model)"),Deo.forEach(t),hct=i(pe),d7=n(pe,"LI",{});var Geo=s(d7);T$e=n(Geo,"STRONG",{});var b2a=s(T$e);uct=r(b2a,"deberta-v2"),b2a.forEach(t),pct=r(Geo," \u2014 "),qse=n(Geo,"A",{href:!0});var v2a=s(qse);_ct=r(v2a,"TFDebertaV2ForQuestionAnswering"),v2a.forEach(t),bct=r(Geo," (DeBERTa-v2 model)"),Geo.forEach(t),vct=i(pe),m7=n(pe,"LI",{});var Oeo=s(m7);M$e=n(Oeo,"STRONG",{});var F2a=s(M$e);Fct=r(F2a,"distilbert"),F2a.forEach(t),Tct=r(Oeo," \u2014 "),jse=n(Oeo,"A",{href:!0});var T2a=s(jse);Mct=r(T2a,"TFDistilBertForQuestionAnswering"),T2a.forEach(t),Ect=r(Oeo," (DistilBERT model)"),Oeo.forEach(t),Cct=i(pe),c7=n(pe,"LI",{});var Veo=s(c7);E$e=n(Veo,"STRONG",{});var M2a=s(E$e);wct=r(M2a,"electra"),M2a.forEach(t),Act=r(Veo," \u2014 "),Dse=n(Veo,"A",{href:!0});var E2a=s(Dse);Lct=r(E2a,"TFElectraForQuestionAnswering"),E2a.forEach(t),yct=r(Veo," (ELECTRA model)"),Veo.forEach(t),xct=i(pe),f7=n(pe,"LI",{});var Xeo=s(f7);C$e=n(Xeo,"STRONG",{});var C2a=s(C$e);$ct=r(C2a,"flaubert"),C2a.forEach(t),kct=r(Xeo," \u2014 "),Gse=n(Xeo,"A",{href:!0});var w2a=s(Gse);Sct=r(w2a,"TFFlaubertForQuestionAnsweringSimple"),w2a.forEach(t),Rct=r(Xeo," (FlauBERT model)"),Xeo.forEach(t),Pct=i(pe),g7=n(pe,"LI",{});var zeo=s(g7);w$e=n(zeo,"STRONG",{});var A2a=s(w$e);Bct=r(A2a,"funnel"),A2a.forEach(t),Ict=r(zeo," \u2014 "),Ose=n(zeo,"A",{href:!0});var L2a=s(Ose);Nct=r(L2a,"TFFunnelForQuestionAnswering"),L2a.forEach(t),qct=r(zeo," (Funnel Transformer model)"),zeo.forEach(t),jct=i(pe),h7=n(pe,"LI",{});var Qeo=s(h7);A$e=n(Qeo,"STRONG",{});var y2a=s(A$e);Dct=r(y2a,"gptj"),y2a.forEach(t),Gct=r(Qeo," \u2014 "),Vse=n(Qeo,"A",{href:!0});var x2a=s(Vse);Oct=r(x2a,"TFGPTJForQuestionAnswering"),x2a.forEach(t),Vct=r(Qeo," (GPT-J model)"),Qeo.forEach(t),Xct=i(pe),u7=n(pe,"LI",{});var Weo=s(u7);L$e=n(Weo,"STRONG",{});var $2a=s(L$e);zct=r($2a,"layoutlmv3"),$2a.forEach(t),Qct=r(Weo," \u2014 "),Xse=n(Weo,"A",{href:!0});var k2a=s(Xse);Wct=r(k2a,"TFLayoutLMv3ForQuestionAnswering"),k2a.forEach(t),Uct=r(Weo," (LayoutLMv3 model)"),Weo.forEach(t),Hct=i(pe),p7=n(pe,"LI",{});var Ueo=s(p7);y$e=n(Ueo,"STRONG",{});var S2a=s(y$e);Jct=r(S2a,"longformer"),S2a.forEach(t),Yct=r(Ueo," \u2014 "),zse=n(Ueo,"A",{href:!0});var R2a=s(zse);Zct=r(R2a,"TFLongformerForQuestionAnswering"),R2a.forEach(t),Kct=r(Ueo," (Longformer model)"),Ueo.forEach(t),eft=i(pe),_7=n(pe,"LI",{});var Heo=s(_7);x$e=n(Heo,"STRONG",{});var P2a=s(x$e);oft=r(P2a,"mobilebert"),P2a.forEach(t),rft=r(Heo," \u2014 "),Qse=n(Heo,"A",{href:!0});var B2a=s(Qse);tft=r(B2a,"TFMobileBertForQuestionAnswering"),B2a.forEach(t),aft=r(Heo," (MobileBERT model)"),Heo.forEach(t),nft=i(pe),b7=n(pe,"LI",{});var Jeo=s(b7);$$e=n(Jeo,"STRONG",{});var I2a=s($$e);sft=r(I2a,"mpnet"),I2a.forEach(t),lft=r(Jeo," \u2014 "),Wse=n(Jeo,"A",{href:!0});var N2a=s(Wse);ift=r(N2a,"TFMPNetForQuestionAnswering"),N2a.forEach(t),dft=r(Jeo," (MPNet model)"),Jeo.forEach(t),mft=i(pe),v7=n(pe,"LI",{});var Yeo=s(v7);k$e=n(Yeo,"STRONG",{});var q2a=s(k$e);cft=r(q2a,"rembert"),q2a.forEach(t),fft=r(Yeo," \u2014 "),Use=n(Yeo,"A",{href:!0});var j2a=s(Use);gft=r(j2a,"TFRemBertForQuestionAnswering"),j2a.forEach(t),hft=r(Yeo," (RemBERT model)"),Yeo.forEach(t),uft=i(pe),F7=n(pe,"LI",{});var Zeo=s(F7);S$e=n(Zeo,"STRONG",{});var D2a=s(S$e);pft=r(D2a,"roberta"),D2a.forEach(t),_ft=r(Zeo," \u2014 "),Hse=n(Zeo,"A",{href:!0});var G2a=s(Hse);bft=r(G2a,"TFRobertaForQuestionAnswering"),G2a.forEach(t),vft=r(Zeo," (RoBERTa model)"),Zeo.forEach(t),Fft=i(pe),T7=n(pe,"LI",{});var Keo=s(T7);R$e=n(Keo,"STRONG",{});var O2a=s(R$e);Tft=r(O2a,"roformer"),O2a.forEach(t),Mft=r(Keo," \u2014 "),Jse=n(Keo,"A",{href:!0});var V2a=s(Jse);Eft=r(V2a,"TFRoFormerForQuestionAnswering"),V2a.forEach(t),Cft=r(Keo," (RoFormer model)"),Keo.forEach(t),wft=i(pe),M7=n(pe,"LI",{});var eoo=s(M7);P$e=n(eoo,"STRONG",{});var X2a=s(P$e);Aft=r(X2a,"xlm"),X2a.forEach(t),Lft=r(eoo," \u2014 "),Yse=n(eoo,"A",{href:!0});var z2a=s(Yse);yft=r(z2a,"TFXLMForQuestionAnsweringSimple"),z2a.forEach(t),xft=r(eoo," (XLM model)"),eoo.forEach(t),$ft=i(pe),E7=n(pe,"LI",{});var ooo=s(E7);B$e=n(ooo,"STRONG",{});var Q2a=s(B$e);kft=r(Q2a,"xlm-roberta"),Q2a.forEach(t),Sft=r(ooo," \u2014 "),Zse=n(ooo,"A",{href:!0});var W2a=s(Zse);Rft=r(W2a,"TFXLMRobertaForQuestionAnswering"),W2a.forEach(t),Pft=r(ooo," (XLM-RoBERTa model)"),ooo.forEach(t),Bft=i(pe),C7=n(pe,"LI",{});var roo=s(C7);I$e=n(roo,"STRONG",{});var U2a=s(I$e);Ift=r(U2a,"xlnet"),U2a.forEach(t),Nft=r(roo," \u2014 "),Kse=n(roo,"A",{href:!0});var H2a=s(Kse);qft=r(H2a,"TFXLNetForQuestionAnsweringSimple"),H2a.forEach(t),jft=r(roo," (XLNet model)"),roo.forEach(t),pe.forEach(t),Dft=i(Gi),T(w7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),Yao=i(c),Yc=n(c,"H2",{class:!0});var _lo=s(Yc);A7=n(_lo,"A",{id:!0,class:!0,href:!0});var J2a=s(A7);N$e=n(J2a,"SPAN",{});var Y2a=s(N$e);T(LP.$$.fragment,Y2a),Y2a.forEach(t),J2a.forEach(t),Gft=i(_lo),q$e=n(_lo,"SPAN",{});var Z2a=s(q$e);Oft=r(Z2a,"TFAutoModelForVision2Seq"),Z2a.forEach(t),_lo.forEach(t),Zao=i(c),Cr=n(c,"DIV",{class:!0});var Oi=s(Cr);T(yP.$$.fragment,Oi),Vft=i(Oi),Zc=n(Oi,"P",{});var Lce=s(Zc);Xft=r(Lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ele=n(Lce,"A",{href:!0});var K2a=s(ele);zft=r(K2a,"from_pretrained()"),K2a.forEach(t),Qft=r(Lce," class method or the "),ole=n(Lce,"A",{href:!0});var eba=s(ole);Wft=r(eba,"from_config()"),eba.forEach(t),Uft=r(Lce,` class
method.`),Lce.forEach(t),Hft=i(Oi),xP=n(Oi,"P",{});var blo=s(xP);Jft=r(blo,"This class cannot be instantiated directly using "),j$e=n(blo,"CODE",{});var oba=s(j$e);Yft=r(oba,"__init__()"),oba.forEach(t),Zft=r(blo," (throws an error)."),blo.forEach(t),Kft=i(Oi),ma=n(Oi,"DIV",{class:!0});var Lx=s(ma);T($P.$$.fragment,Lx),egt=i(Lx),D$e=n(Lx,"P",{});var rba=s(D$e);ogt=r(rba,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),rba.forEach(t),rgt=i(Lx),Kc=n(Lx,"P",{});var yce=s(Kc);tgt=r(yce,`Note:
Loading a model from its configuration file does `),G$e=n(yce,"STRONG",{});var tba=s(G$e);agt=r(tba,"not"),tba.forEach(t),ngt=r(yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),rle=n(yce,"A",{href:!0});var aba=s(rle);sgt=r(aba,"from_pretrained()"),aba.forEach(t),lgt=r(yce," to load the model weights."),yce.forEach(t),igt=i(Lx),T(L7.$$.fragment,Lx),Lx.forEach(t),dgt=i(Oi),et=n(Oi,"DIV",{class:!0});var Vi=s(et);T(kP.$$.fragment,Vi),mgt=i(Vi),O$e=n(Vi,"P",{});var nba=s(O$e);cgt=r(nba,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nba.forEach(t),fgt=i(Vi),Hn=n(Vi,"P",{});var yx=s(Hn);ggt=r(yx,"The model class to instantiate is selected based on the "),V$e=n(yx,"CODE",{});var sba=s(V$e);hgt=r(sba,"model_type"),sba.forEach(t),ugt=r(yx,` property of the config object (either
passed as an argument or loaded from `),X$e=n(yx,"CODE",{});var lba=s(X$e);pgt=r(lba,"pretrained_model_name_or_path"),lba.forEach(t),_gt=r(yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z$e=n(yx,"CODE",{});var iba=s(z$e);bgt=r(iba,"pretrained_model_name_or_path"),iba.forEach(t),vgt=r(yx,":"),yx.forEach(t),Fgt=i(Vi),Q$e=n(Vi,"UL",{});var dba=s(Q$e);y7=n(dba,"LI",{});var too=s(y7);W$e=n(too,"STRONG",{});var mba=s(W$e);Tgt=r(mba,"vision-encoder-decoder"),mba.forEach(t),Mgt=r(too," \u2014 "),tle=n(too,"A",{href:!0});var cba=s(tle);Egt=r(cba,"TFVisionEncoderDecoderModel"),cba.forEach(t),Cgt=r(too," (Vision Encoder decoder model)"),too.forEach(t),dba.forEach(t),wgt=i(Vi),T(x7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),Kao=i(c),ef=n(c,"H2",{class:!0});var vlo=s(ef);$7=n(vlo,"A",{id:!0,class:!0,href:!0});var fba=s($7);U$e=n(fba,"SPAN",{});var gba=s(U$e);T(SP.$$.fragment,gba),gba.forEach(t),fba.forEach(t),Agt=i(vlo),H$e=n(vlo,"SPAN",{});var hba=s(H$e);Lgt=r(hba,"TFAutoModelForSpeechSeq2Seq"),hba.forEach(t),vlo.forEach(t),eno=i(c),wr=n(c,"DIV",{class:!0});var Xi=s(wr);T(RP.$$.fragment,Xi),ygt=i(Xi),of=n(Xi,"P",{});var xce=s(of);xgt=r(xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ale=n(xce,"A",{href:!0});var uba=s(ale);$gt=r(uba,"from_pretrained()"),uba.forEach(t),kgt=r(xce," class method or the "),nle=n(xce,"A",{href:!0});var pba=s(nle);Sgt=r(pba,"from_config()"),pba.forEach(t),Rgt=r(xce,` class
method.`),xce.forEach(t),Pgt=i(Xi),PP=n(Xi,"P",{});var Flo=s(PP);Bgt=r(Flo,"This class cannot be instantiated directly using "),J$e=n(Flo,"CODE",{});var _ba=s(J$e);Igt=r(_ba,"__init__()"),_ba.forEach(t),Ngt=r(Flo," (throws an error)."),Flo.forEach(t),qgt=i(Xi),ca=n(Xi,"DIV",{class:!0});var xx=s(ca);T(BP.$$.fragment,xx),jgt=i(xx),Y$e=n(xx,"P",{});var bba=s(Y$e);Dgt=r(bba,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),bba.forEach(t),Ggt=i(xx),rf=n(xx,"P",{});var $ce=s(rf);Ogt=r($ce,`Note:
Loading a model from its configuration file does `),Z$e=n($ce,"STRONG",{});var vba=s(Z$e);Vgt=r(vba,"not"),vba.forEach(t),Xgt=r($ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),sle=n($ce,"A",{href:!0});var Fba=s(sle);zgt=r(Fba,"from_pretrained()"),Fba.forEach(t),Qgt=r($ce," to load the model weights."),$ce.forEach(t),Wgt=i(xx),T(k7.$$.fragment,xx),xx.forEach(t),Ugt=i(Xi),ot=n(Xi,"DIV",{class:!0});var zi=s(ot);T(IP.$$.fragment,zi),Hgt=i(zi),K$e=n(zi,"P",{});var Tba=s(K$e);Jgt=r(Tba,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Tba.forEach(t),Ygt=i(zi),Jn=n(zi,"P",{});var $x=s(Jn);Zgt=r($x,"The model class to instantiate is selected based on the "),eke=n($x,"CODE",{});var Mba=s(eke);Kgt=r(Mba,"model_type"),Mba.forEach(t),eht=r($x,` property of the config object (either
passed as an argument or loaded from `),oke=n($x,"CODE",{});var Eba=s(oke);oht=r(Eba,"pretrained_model_name_or_path"),Eba.forEach(t),rht=r($x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rke=n($x,"CODE",{});var Cba=s(rke);tht=r(Cba,"pretrained_model_name_or_path"),Cba.forEach(t),aht=r($x,":"),$x.forEach(t),nht=i(zi),NP=n(zi,"UL",{});var Tlo=s(NP);S7=n(Tlo,"LI",{});var aoo=s(S7);tke=n(aoo,"STRONG",{});var wba=s(tke);sht=r(wba,"speech_to_text"),wba.forEach(t),lht=r(aoo," \u2014 "),lle=n(aoo,"A",{href:!0});var Aba=s(lle);iht=r(Aba,"TFSpeech2TextForConditionalGeneration"),Aba.forEach(t),dht=r(aoo," (Speech2Text model)"),aoo.forEach(t),mht=i(Tlo),R7=n(Tlo,"LI",{});var noo=s(R7);ake=n(noo,"STRONG",{});var Lba=s(ake);cht=r(Lba,"whisper"),Lba.forEach(t),fht=r(noo," \u2014 "),ile=n(noo,"A",{href:!0});var yba=s(ile);ght=r(yba,"TFWhisperForConditionalGeneration"),yba.forEach(t),hht=r(noo," (Whisper model)"),noo.forEach(t),Tlo.forEach(t),uht=i(zi),T(P7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),ono=i(c),tf=n(c,"H2",{class:!0});var Mlo=s(tf);B7=n(Mlo,"A",{id:!0,class:!0,href:!0});var xba=s(B7);nke=n(xba,"SPAN",{});var $ba=s(nke);T(qP.$$.fragment,$ba),$ba.forEach(t),xba.forEach(t),pht=i(Mlo),ske=n(Mlo,"SPAN",{});var kba=s(ske);_ht=r(kba,"FlaxAutoModel"),kba.forEach(t),Mlo.forEach(t),rno=i(c),Ar=n(c,"DIV",{class:!0});var Qi=s(Ar);T(jP.$$.fragment,Qi),bht=i(Qi),af=n(Qi,"P",{});var kce=s(af);vht=r(kce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),dle=n(kce,"A",{href:!0});var Sba=s(dle);Fht=r(Sba,"from_pretrained()"),Sba.forEach(t),Tht=r(kce," class method or the "),mle=n(kce,"A",{href:!0});var Rba=s(mle);Mht=r(Rba,"from_config()"),Rba.forEach(t),Eht=r(kce,` class
method.`),kce.forEach(t),Cht=i(Qi),DP=n(Qi,"P",{});var Elo=s(DP);wht=r(Elo,"This class cannot be instantiated directly using "),lke=n(Elo,"CODE",{});var Pba=s(lke);Aht=r(Pba,"__init__()"),Pba.forEach(t),Lht=r(Elo," (throws an error)."),Elo.forEach(t),yht=i(Qi),fa=n(Qi,"DIV",{class:!0});var kx=s(fa);T(GP.$$.fragment,kx),xht=i(kx),ike=n(kx,"P",{});var Bba=s(ike);$ht=r(Bba,"Instantiates one of the base model classes of the library from a configuration."),Bba.forEach(t),kht=i(kx),nf=n(kx,"P",{});var Sce=s(nf);Sht=r(Sce,`Note:
Loading a model from its configuration file does `),dke=n(Sce,"STRONG",{});var Iba=s(dke);Rht=r(Iba,"not"),Iba.forEach(t),Pht=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),cle=n(Sce,"A",{href:!0});var Nba=s(cle);Bht=r(Nba,"from_pretrained()"),Nba.forEach(t),Iht=r(Sce," to load the model weights."),Sce.forEach(t),Nht=i(kx),T(I7.$$.fragment,kx),kx.forEach(t),qht=i(Qi),rt=n(Qi,"DIV",{class:!0});var Wi=s(rt);T(OP.$$.fragment,Wi),jht=i(Wi),mke=n(Wi,"P",{});var qba=s(mke);Dht=r(qba,"Instantiate one of the base model classes of the library from a pretrained model."),qba.forEach(t),Ght=i(Wi),Yn=n(Wi,"P",{});var Sx=s(Yn);Oht=r(Sx,"The model class to instantiate is selected based on the "),cke=n(Sx,"CODE",{});var jba=s(cke);Vht=r(jba,"model_type"),jba.forEach(t),Xht=r(Sx,` property of the config object (either
passed as an argument or loaded from `),fke=n(Sx,"CODE",{});var Dba=s(fke);zht=r(Dba,"pretrained_model_name_or_path"),Dba.forEach(t),Qht=r(Sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gke=n(Sx,"CODE",{});var Gba=s(gke);Wht=r(Gba,"pretrained_model_name_or_path"),Gba.forEach(t),Uht=r(Sx,":"),Sx.forEach(t),Hht=i(Wi),te=n(Wi,"UL",{});var ne=s(te);N7=n(ne,"LI",{});var soo=s(N7);hke=n(soo,"STRONG",{});var Oba=s(hke);Jht=r(Oba,"albert"),Oba.forEach(t),Yht=r(soo," \u2014 "),fle=n(soo,"A",{href:!0});var Vba=s(fle);Zht=r(Vba,"FlaxAlbertModel"),Vba.forEach(t),Kht=r(soo," (ALBERT model)"),soo.forEach(t),eut=i(ne),q7=n(ne,"LI",{});var loo=s(q7);uke=n(loo,"STRONG",{});var Xba=s(uke);out=r(Xba,"bart"),Xba.forEach(t),rut=r(loo," \u2014 "),gle=n(loo,"A",{href:!0});var zba=s(gle);tut=r(zba,"FlaxBartModel"),zba.forEach(t),aut=r(loo," (BART model)"),loo.forEach(t),nut=i(ne),j7=n(ne,"LI",{});var ioo=s(j7);pke=n(ioo,"STRONG",{});var Qba=s(pke);sut=r(Qba,"beit"),Qba.forEach(t),lut=r(ioo," \u2014 "),hle=n(ioo,"A",{href:!0});var Wba=s(hle);iut=r(Wba,"FlaxBeitModel"),Wba.forEach(t),dut=r(ioo," (BEiT model)"),ioo.forEach(t),mut=i(ne),D7=n(ne,"LI",{});var doo=s(D7);_ke=n(doo,"STRONG",{});var Uba=s(_ke);cut=r(Uba,"bert"),Uba.forEach(t),fut=r(doo," \u2014 "),ule=n(doo,"A",{href:!0});var Hba=s(ule);gut=r(Hba,"FlaxBertModel"),Hba.forEach(t),hut=r(doo," (BERT model)"),doo.forEach(t),uut=i(ne),G7=n(ne,"LI",{});var moo=s(G7);bke=n(moo,"STRONG",{});var Jba=s(bke);put=r(Jba,"big_bird"),Jba.forEach(t),_ut=r(moo," \u2014 "),ple=n(moo,"A",{href:!0});var Yba=s(ple);but=r(Yba,"FlaxBigBirdModel"),Yba.forEach(t),vut=r(moo," (BigBird model)"),moo.forEach(t),Fut=i(ne),O7=n(ne,"LI",{});var coo=s(O7);vke=n(coo,"STRONG",{});var Zba=s(vke);Tut=r(Zba,"blenderbot"),Zba.forEach(t),Mut=r(coo," \u2014 "),_le=n(coo,"A",{href:!0});var Kba=s(_le);Eut=r(Kba,"FlaxBlenderbotModel"),Kba.forEach(t),Cut=r(coo," (Blenderbot model)"),coo.forEach(t),wut=i(ne),V7=n(ne,"LI",{});var foo=s(V7);Fke=n(foo,"STRONG",{});var eva=s(Fke);Aut=r(eva,"blenderbot-small"),eva.forEach(t),Lut=r(foo," \u2014 "),ble=n(foo,"A",{href:!0});var ova=s(ble);yut=r(ova,"FlaxBlenderbotSmallModel"),ova.forEach(t),xut=r(foo," (BlenderbotSmall model)"),foo.forEach(t),$ut=i(ne),X7=n(ne,"LI",{});var goo=s(X7);Tke=n(goo,"STRONG",{});var rva=s(Tke);kut=r(rva,"clip"),rva.forEach(t),Sut=r(goo," \u2014 "),vle=n(goo,"A",{href:!0});var tva=s(vle);Rut=r(tva,"FlaxCLIPModel"),tva.forEach(t),Put=r(goo," (CLIP model)"),goo.forEach(t),But=i(ne),z7=n(ne,"LI",{});var hoo=s(z7);Mke=n(hoo,"STRONG",{});var ava=s(Mke);Iut=r(ava,"distilbert"),ava.forEach(t),Nut=r(hoo," \u2014 "),Fle=n(hoo,"A",{href:!0});var nva=s(Fle);qut=r(nva,"FlaxDistilBertModel"),nva.forEach(t),jut=r(hoo," (DistilBERT model)"),hoo.forEach(t),Dut=i(ne),Q7=n(ne,"LI",{});var uoo=s(Q7);Eke=n(uoo,"STRONG",{});var sva=s(Eke);Gut=r(sva,"electra"),sva.forEach(t),Out=r(uoo," \u2014 "),Tle=n(uoo,"A",{href:!0});var lva=s(Tle);Vut=r(lva,"FlaxElectraModel"),lva.forEach(t),Xut=r(uoo," (ELECTRA model)"),uoo.forEach(t),zut=i(ne),W7=n(ne,"LI",{});var poo=s(W7);Cke=n(poo,"STRONG",{});var iva=s(Cke);Qut=r(iva,"gpt2"),iva.forEach(t),Wut=r(poo," \u2014 "),Mle=n(poo,"A",{href:!0});var dva=s(Mle);Uut=r(dva,"FlaxGPT2Model"),dva.forEach(t),Hut=r(poo," (OpenAI GPT-2 model)"),poo.forEach(t),Jut=i(ne),U7=n(ne,"LI",{});var _oo=s(U7);wke=n(_oo,"STRONG",{});var mva=s(wke);Yut=r(mva,"gpt_neo"),mva.forEach(t),Zut=r(_oo," \u2014 "),Ele=n(_oo,"A",{href:!0});var cva=s(Ele);Kut=r(cva,"FlaxGPTNeoModel"),cva.forEach(t),ept=r(_oo," (GPT Neo model)"),_oo.forEach(t),opt=i(ne),H7=n(ne,"LI",{});var boo=s(H7);Ake=n(boo,"STRONG",{});var fva=s(Ake);rpt=r(fva,"gptj"),fva.forEach(t),tpt=r(boo," \u2014 "),Cle=n(boo,"A",{href:!0});var gva=s(Cle);apt=r(gva,"FlaxGPTJModel"),gva.forEach(t),npt=r(boo," (GPT-J model)"),boo.forEach(t),spt=i(ne),J7=n(ne,"LI",{});var voo=s(J7);Lke=n(voo,"STRONG",{});var hva=s(Lke);lpt=r(hva,"longt5"),hva.forEach(t),ipt=r(voo," \u2014 "),wle=n(voo,"A",{href:!0});var uva=s(wle);dpt=r(uva,"FlaxLongT5Model"),uva.forEach(t),mpt=r(voo," (LongT5 model)"),voo.forEach(t),cpt=i(ne),Y7=n(ne,"LI",{});var Foo=s(Y7);yke=n(Foo,"STRONG",{});var pva=s(yke);fpt=r(pva,"marian"),pva.forEach(t),gpt=r(Foo," \u2014 "),Ale=n(Foo,"A",{href:!0});var _va=s(Ale);hpt=r(_va,"FlaxMarianModel"),_va.forEach(t),upt=r(Foo," (Marian model)"),Foo.forEach(t),ppt=i(ne),Z7=n(ne,"LI",{});var Too=s(Z7);xke=n(Too,"STRONG",{});var bva=s(xke);_pt=r(bva,"mbart"),bva.forEach(t),bpt=r(Too," \u2014 "),Lle=n(Too,"A",{href:!0});var vva=s(Lle);vpt=r(vva,"FlaxMBartModel"),vva.forEach(t),Fpt=r(Too," (mBART model)"),Too.forEach(t),Tpt=i(ne),K7=n(ne,"LI",{});var Moo=s(K7);$ke=n(Moo,"STRONG",{});var Fva=s($ke);Mpt=r(Fva,"mt5"),Fva.forEach(t),Ept=r(Moo," \u2014 "),yle=n(Moo,"A",{href:!0});var Tva=s(yle);Cpt=r(Tva,"FlaxMT5Model"),Tva.forEach(t),wpt=r(Moo," (MT5 model)"),Moo.forEach(t),Apt=i(ne),e8=n(ne,"LI",{});var Eoo=s(e8);kke=n(Eoo,"STRONG",{});var Mva=s(kke);Lpt=r(Mva,"opt"),Mva.forEach(t),ypt=r(Eoo," \u2014 "),xle=n(Eoo,"A",{href:!0});var Eva=s(xle);xpt=r(Eva,"FlaxOPTModel"),Eva.forEach(t),$pt=r(Eoo," (OPT model)"),Eoo.forEach(t),kpt=i(ne),o8=n(ne,"LI",{});var Coo=s(o8);Ske=n(Coo,"STRONG",{});var Cva=s(Ske);Spt=r(Cva,"pegasus"),Cva.forEach(t),Rpt=r(Coo," \u2014 "),$le=n(Coo,"A",{href:!0});var wva=s($le);Ppt=r(wva,"FlaxPegasusModel"),wva.forEach(t),Bpt=r(Coo," (Pegasus model)"),Coo.forEach(t),Ipt=i(ne),r8=n(ne,"LI",{});var woo=s(r8);Rke=n(woo,"STRONG",{});var Ava=s(Rke);Npt=r(Ava,"roberta"),Ava.forEach(t),qpt=r(woo," \u2014 "),kle=n(woo,"A",{href:!0});var Lva=s(kle);jpt=r(Lva,"FlaxRobertaModel"),Lva.forEach(t),Dpt=r(woo," (RoBERTa model)"),woo.forEach(t),Gpt=i(ne),t8=n(ne,"LI",{});var Aoo=s(t8);Pke=n(Aoo,"STRONG",{});var yva=s(Pke);Opt=r(yva,"roformer"),yva.forEach(t),Vpt=r(Aoo," \u2014 "),Sle=n(Aoo,"A",{href:!0});var xva=s(Sle);Xpt=r(xva,"FlaxRoFormerModel"),xva.forEach(t),zpt=r(Aoo," (RoFormer model)"),Aoo.forEach(t),Qpt=i(ne),a8=n(ne,"LI",{});var Loo=s(a8);Bke=n(Loo,"STRONG",{});var $va=s(Bke);Wpt=r($va,"t5"),$va.forEach(t),Upt=r(Loo," \u2014 "),Rle=n(Loo,"A",{href:!0});var kva=s(Rle);Hpt=r(kva,"FlaxT5Model"),kva.forEach(t),Jpt=r(Loo," (T5 model)"),Loo.forEach(t),Ypt=i(ne),n8=n(ne,"LI",{});var yoo=s(n8);Ike=n(yoo,"STRONG",{});var Sva=s(Ike);Zpt=r(Sva,"vision-text-dual-encoder"),Sva.forEach(t),Kpt=r(yoo," \u2014 "),Ple=n(yoo,"A",{href:!0});var Rva=s(Ple);e_t=r(Rva,"FlaxVisionTextDualEncoderModel"),Rva.forEach(t),o_t=r(yoo," (VisionTextDualEncoder model)"),yoo.forEach(t),r_t=i(ne),s8=n(ne,"LI",{});var xoo=s(s8);Nke=n(xoo,"STRONG",{});var Pva=s(Nke);t_t=r(Pva,"vit"),Pva.forEach(t),a_t=r(xoo," \u2014 "),Ble=n(xoo,"A",{href:!0});var Bva=s(Ble);n_t=r(Bva,"FlaxViTModel"),Bva.forEach(t),s_t=r(xoo," (ViT model)"),xoo.forEach(t),l_t=i(ne),l8=n(ne,"LI",{});var $oo=s(l8);qke=n($oo,"STRONG",{});var Iva=s(qke);i_t=r(Iva,"wav2vec2"),Iva.forEach(t),d_t=r($oo," \u2014 "),Ile=n($oo,"A",{href:!0});var Nva=s(Ile);m_t=r(Nva,"FlaxWav2Vec2Model"),Nva.forEach(t),c_t=r($oo," (Wav2Vec2 model)"),$oo.forEach(t),f_t=i(ne),i8=n(ne,"LI",{});var koo=s(i8);jke=n(koo,"STRONG",{});var qva=s(jke);g_t=r(qva,"xglm"),qva.forEach(t),h_t=r(koo," \u2014 "),Nle=n(koo,"A",{href:!0});var jva=s(Nle);u_t=r(jva,"FlaxXGLMModel"),jva.forEach(t),p_t=r(koo," (XGLM model)"),koo.forEach(t),__t=i(ne),d8=n(ne,"LI",{});var Soo=s(d8);Dke=n(Soo,"STRONG",{});var Dva=s(Dke);b_t=r(Dva,"xlm-roberta"),Dva.forEach(t),v_t=r(Soo," \u2014 "),qle=n(Soo,"A",{href:!0});var Gva=s(qle);F_t=r(Gva,"FlaxXLMRobertaModel"),Gva.forEach(t),T_t=r(Soo," (XLM-RoBERTa model)"),Soo.forEach(t),ne.forEach(t),M_t=i(Wi),T(m8.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),tno=i(c),sf=n(c,"H2",{class:!0});var Clo=s(sf);c8=n(Clo,"A",{id:!0,class:!0,href:!0});var Ova=s(c8);Gke=n(Ova,"SPAN",{});var Vva=s(Gke);T(VP.$$.fragment,Vva),Vva.forEach(t),Ova.forEach(t),E_t=i(Clo),Oke=n(Clo,"SPAN",{});var Xva=s(Oke);C_t=r(Xva,"FlaxAutoModelForCausalLM"),Xva.forEach(t),Clo.forEach(t),ano=i(c),Lr=n(c,"DIV",{class:!0});var Ui=s(Lr);T(XP.$$.fragment,Ui),w_t=i(Ui),lf=n(Ui,"P",{});var Rce=s(lf);A_t=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jle=n(Rce,"A",{href:!0});var zva=s(jle);L_t=r(zva,"from_pretrained()"),zva.forEach(t),y_t=r(Rce," class method or the "),Dle=n(Rce,"A",{href:!0});var Qva=s(Dle);x_t=r(Qva,"from_config()"),Qva.forEach(t),$_t=r(Rce,` class
method.`),Rce.forEach(t),k_t=i(Ui),zP=n(Ui,"P",{});var wlo=s(zP);S_t=r(wlo,"This class cannot be instantiated directly using "),Vke=n(wlo,"CODE",{});var Wva=s(Vke);R_t=r(Wva,"__init__()"),Wva.forEach(t),P_t=r(wlo," (throws an error)."),wlo.forEach(t),B_t=i(Ui),ga=n(Ui,"DIV",{class:!0});var Rx=s(ga);T(QP.$$.fragment,Rx),I_t=i(Rx),Xke=n(Rx,"P",{});var Uva=s(Xke);N_t=r(Uva,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Uva.forEach(t),q_t=i(Rx),df=n(Rx,"P",{});var Pce=s(df);j_t=r(Pce,`Note:
Loading a model from its configuration file does `),zke=n(Pce,"STRONG",{});var Hva=s(zke);D_t=r(Hva,"not"),Hva.forEach(t),G_t=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gle=n(Pce,"A",{href:!0});var Jva=s(Gle);O_t=r(Jva,"from_pretrained()"),Jva.forEach(t),V_t=r(Pce," to load the model weights."),Pce.forEach(t),X_t=i(Rx),T(f8.$$.fragment,Rx),Rx.forEach(t),z_t=i(Ui),tt=n(Ui,"DIV",{class:!0});var Hi=s(tt);T(WP.$$.fragment,Hi),Q_t=i(Hi),Qke=n(Hi,"P",{});var Yva=s(Qke);W_t=r(Yva,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Yva.forEach(t),U_t=i(Hi),Zn=n(Hi,"P",{});var Px=s(Zn);H_t=r(Px,"The model class to instantiate is selected based on the "),Wke=n(Px,"CODE",{});var Zva=s(Wke);J_t=r(Zva,"model_type"),Zva.forEach(t),Y_t=r(Px,` property of the config object (either
passed as an argument or loaded from `),Uke=n(Px,"CODE",{});var Kva=s(Uke);Z_t=r(Kva,"pretrained_model_name_or_path"),Kva.forEach(t),K_t=r(Px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hke=n(Px,"CODE",{});var eFa=s(Hke);e1t=r(eFa,"pretrained_model_name_or_path"),eFa.forEach(t),o1t=r(Px,":"),Px.forEach(t),r1t=i(Hi),$e=n(Hi,"UL",{});var je=s($e);g8=n(je,"LI",{});var Roo=s(g8);Jke=n(Roo,"STRONG",{});var oFa=s(Jke);t1t=r(oFa,"bart"),oFa.forEach(t),a1t=r(Roo," \u2014 "),Ole=n(Roo,"A",{href:!0});var rFa=s(Ole);n1t=r(rFa,"FlaxBartForCausalLM"),rFa.forEach(t),s1t=r(Roo," (BART model)"),Roo.forEach(t),l1t=i(je),h8=n(je,"LI",{});var Poo=s(h8);Yke=n(Poo,"STRONG",{});var tFa=s(Yke);i1t=r(tFa,"bert"),tFa.forEach(t),d1t=r(Poo," \u2014 "),Vle=n(Poo,"A",{href:!0});var aFa=s(Vle);m1t=r(aFa,"FlaxBertForCausalLM"),aFa.forEach(t),c1t=r(Poo," (BERT model)"),Poo.forEach(t),f1t=i(je),u8=n(je,"LI",{});var Boo=s(u8);Zke=n(Boo,"STRONG",{});var nFa=s(Zke);g1t=r(nFa,"big_bird"),nFa.forEach(t),h1t=r(Boo," \u2014 "),Xle=n(Boo,"A",{href:!0});var sFa=s(Xle);u1t=r(sFa,"FlaxBigBirdForCausalLM"),sFa.forEach(t),p1t=r(Boo," (BigBird model)"),Boo.forEach(t),_1t=i(je),p8=n(je,"LI",{});var Ioo=s(p8);Kke=n(Ioo,"STRONG",{});var lFa=s(Kke);b1t=r(lFa,"electra"),lFa.forEach(t),v1t=r(Ioo," \u2014 "),zle=n(Ioo,"A",{href:!0});var iFa=s(zle);F1t=r(iFa,"FlaxElectraForCausalLM"),iFa.forEach(t),T1t=r(Ioo," (ELECTRA model)"),Ioo.forEach(t),M1t=i(je),_8=n(je,"LI",{});var Noo=s(_8);eSe=n(Noo,"STRONG",{});var dFa=s(eSe);E1t=r(dFa,"gpt2"),dFa.forEach(t),C1t=r(Noo," \u2014 "),Qle=n(Noo,"A",{href:!0});var mFa=s(Qle);w1t=r(mFa,"FlaxGPT2LMHeadModel"),mFa.forEach(t),A1t=r(Noo," (OpenAI GPT-2 model)"),Noo.forEach(t),L1t=i(je),b8=n(je,"LI",{});var qoo=s(b8);oSe=n(qoo,"STRONG",{});var cFa=s(oSe);y1t=r(cFa,"gpt_neo"),cFa.forEach(t),x1t=r(qoo," \u2014 "),Wle=n(qoo,"A",{href:!0});var fFa=s(Wle);$1t=r(fFa,"FlaxGPTNeoForCausalLM"),fFa.forEach(t),k1t=r(qoo," (GPT Neo model)"),qoo.forEach(t),S1t=i(je),v8=n(je,"LI",{});var joo=s(v8);rSe=n(joo,"STRONG",{});var gFa=s(rSe);R1t=r(gFa,"gptj"),gFa.forEach(t),P1t=r(joo," \u2014 "),Ule=n(joo,"A",{href:!0});var hFa=s(Ule);B1t=r(hFa,"FlaxGPTJForCausalLM"),hFa.forEach(t),I1t=r(joo," (GPT-J model)"),joo.forEach(t),N1t=i(je),F8=n(je,"LI",{});var Doo=s(F8);tSe=n(Doo,"STRONG",{});var uFa=s(tSe);q1t=r(uFa,"opt"),uFa.forEach(t),j1t=r(Doo," \u2014 "),Hle=n(Doo,"A",{href:!0});var pFa=s(Hle);D1t=r(pFa,"FlaxOPTForCausalLM"),pFa.forEach(t),G1t=r(Doo," (OPT model)"),Doo.forEach(t),O1t=i(je),T8=n(je,"LI",{});var Goo=s(T8);aSe=n(Goo,"STRONG",{});var _Fa=s(aSe);V1t=r(_Fa,"roberta"),_Fa.forEach(t),X1t=r(Goo," \u2014 "),Jle=n(Goo,"A",{href:!0});var bFa=s(Jle);z1t=r(bFa,"FlaxRobertaForCausalLM"),bFa.forEach(t),Q1t=r(Goo," (RoBERTa model)"),Goo.forEach(t),W1t=i(je),M8=n(je,"LI",{});var Ooo=s(M8);nSe=n(Ooo,"STRONG",{});var vFa=s(nSe);U1t=r(vFa,"xglm"),vFa.forEach(t),H1t=r(Ooo," \u2014 "),Yle=n(Ooo,"A",{href:!0});var FFa=s(Yle);J1t=r(FFa,"FlaxXGLMForCausalLM"),FFa.forEach(t),Y1t=r(Ooo," (XGLM model)"),Ooo.forEach(t),je.forEach(t),Z1t=i(Hi),T(E8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),nno=i(c),mf=n(c,"H2",{class:!0});var Alo=s(mf);C8=n(Alo,"A",{id:!0,class:!0,href:!0});var TFa=s(C8);sSe=n(TFa,"SPAN",{});var MFa=s(sSe);T(UP.$$.fragment,MFa),MFa.forEach(t),TFa.forEach(t),K1t=i(Alo),lSe=n(Alo,"SPAN",{});var EFa=s(lSe);e2t=r(EFa,"FlaxAutoModelForPreTraining"),EFa.forEach(t),Alo.forEach(t),sno=i(c),yr=n(c,"DIV",{class:!0});var Ji=s(yr);T(HP.$$.fragment,Ji),o2t=i(Ji),cf=n(Ji,"P",{});var Bce=s(cf);r2t=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Zle=n(Bce,"A",{href:!0});var CFa=s(Zle);t2t=r(CFa,"from_pretrained()"),CFa.forEach(t),a2t=r(Bce," class method or the "),Kle=n(Bce,"A",{href:!0});var wFa=s(Kle);n2t=r(wFa,"from_config()"),wFa.forEach(t),s2t=r(Bce,` class
method.`),Bce.forEach(t),l2t=i(Ji),JP=n(Ji,"P",{});var Llo=s(JP);i2t=r(Llo,"This class cannot be instantiated directly using "),iSe=n(Llo,"CODE",{});var AFa=s(iSe);d2t=r(AFa,"__init__()"),AFa.forEach(t),m2t=r(Llo," (throws an error)."),Llo.forEach(t),c2t=i(Ji),ha=n(Ji,"DIV",{class:!0});var Bx=s(ha);T(YP.$$.fragment,Bx),f2t=i(Bx),dSe=n(Bx,"P",{});var LFa=s(dSe);g2t=r(LFa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LFa.forEach(t),h2t=i(Bx),ff=n(Bx,"P",{});var Ice=s(ff);u2t=r(Ice,`Note:
Loading a model from its configuration file does `),mSe=n(Ice,"STRONG",{});var yFa=s(mSe);p2t=r(yFa,"not"),yFa.forEach(t),_2t=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),eie=n(Ice,"A",{href:!0});var xFa=s(eie);b2t=r(xFa,"from_pretrained()"),xFa.forEach(t),v2t=r(Ice," to load the model weights."),Ice.forEach(t),F2t=i(Bx),T(w8.$$.fragment,Bx),Bx.forEach(t),T2t=i(Ji),at=n(Ji,"DIV",{class:!0});var Yi=s(at);T(ZP.$$.fragment,Yi),M2t=i(Yi),cSe=n(Yi,"P",{});var $Fa=s(cSe);E2t=r($Fa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),$Fa.forEach(t),C2t=i(Yi),Kn=n(Yi,"P",{});var Ix=s(Kn);w2t=r(Ix,"The model class to instantiate is selected based on the "),fSe=n(Ix,"CODE",{});var kFa=s(fSe);A2t=r(kFa,"model_type"),kFa.forEach(t),L2t=r(Ix,` property of the config object (either
passed as an argument or loaded from `),gSe=n(Ix,"CODE",{});var SFa=s(gSe);y2t=r(SFa,"pretrained_model_name_or_path"),SFa.forEach(t),x2t=r(Ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hSe=n(Ix,"CODE",{});var RFa=s(hSe);$2t=r(RFa,"pretrained_model_name_or_path"),RFa.forEach(t),k2t=r(Ix,":"),Ix.forEach(t),S2t=i(Yi),Ee=n(Yi,"UL",{});var we=s(Ee);A8=n(we,"LI",{});var Voo=s(A8);uSe=n(Voo,"STRONG",{});var PFa=s(uSe);R2t=r(PFa,"albert"),PFa.forEach(t),P2t=r(Voo," \u2014 "),oie=n(Voo,"A",{href:!0});var BFa=s(oie);B2t=r(BFa,"FlaxAlbertForPreTraining"),BFa.forEach(t),I2t=r(Voo," (ALBERT model)"),Voo.forEach(t),N2t=i(we),L8=n(we,"LI",{});var Xoo=s(L8);pSe=n(Xoo,"STRONG",{});var IFa=s(pSe);q2t=r(IFa,"bart"),IFa.forEach(t),j2t=r(Xoo," \u2014 "),rie=n(Xoo,"A",{href:!0});var NFa=s(rie);D2t=r(NFa,"FlaxBartForConditionalGeneration"),NFa.forEach(t),G2t=r(Xoo," (BART model)"),Xoo.forEach(t),O2t=i(we),y8=n(we,"LI",{});var zoo=s(y8);_Se=n(zoo,"STRONG",{});var qFa=s(_Se);V2t=r(qFa,"bert"),qFa.forEach(t),X2t=r(zoo," \u2014 "),tie=n(zoo,"A",{href:!0});var jFa=s(tie);z2t=r(jFa,"FlaxBertForPreTraining"),jFa.forEach(t),Q2t=r(zoo," (BERT model)"),zoo.forEach(t),W2t=i(we),x8=n(we,"LI",{});var Qoo=s(x8);bSe=n(Qoo,"STRONG",{});var DFa=s(bSe);U2t=r(DFa,"big_bird"),DFa.forEach(t),H2t=r(Qoo," \u2014 "),aie=n(Qoo,"A",{href:!0});var GFa=s(aie);J2t=r(GFa,"FlaxBigBirdForPreTraining"),GFa.forEach(t),Y2t=r(Qoo," (BigBird model)"),Qoo.forEach(t),Z2t=i(we),$8=n(we,"LI",{});var Woo=s($8);vSe=n(Woo,"STRONG",{});var OFa=s(vSe);K2t=r(OFa,"electra"),OFa.forEach(t),ebt=r(Woo," \u2014 "),nie=n(Woo,"A",{href:!0});var VFa=s(nie);obt=r(VFa,"FlaxElectraForPreTraining"),VFa.forEach(t),rbt=r(Woo," (ELECTRA model)"),Woo.forEach(t),tbt=i(we),k8=n(we,"LI",{});var Uoo=s(k8);FSe=n(Uoo,"STRONG",{});var XFa=s(FSe);abt=r(XFa,"longt5"),XFa.forEach(t),nbt=r(Uoo," \u2014 "),sie=n(Uoo,"A",{href:!0});var zFa=s(sie);sbt=r(zFa,"FlaxLongT5ForConditionalGeneration"),zFa.forEach(t),lbt=r(Uoo," (LongT5 model)"),Uoo.forEach(t),ibt=i(we),S8=n(we,"LI",{});var Hoo=s(S8);TSe=n(Hoo,"STRONG",{});var QFa=s(TSe);dbt=r(QFa,"mbart"),QFa.forEach(t),mbt=r(Hoo," \u2014 "),lie=n(Hoo,"A",{href:!0});var WFa=s(lie);cbt=r(WFa,"FlaxMBartForConditionalGeneration"),WFa.forEach(t),fbt=r(Hoo," (mBART model)"),Hoo.forEach(t),gbt=i(we),R8=n(we,"LI",{});var Joo=s(R8);MSe=n(Joo,"STRONG",{});var UFa=s(MSe);hbt=r(UFa,"mt5"),UFa.forEach(t),ubt=r(Joo," \u2014 "),iie=n(Joo,"A",{href:!0});var HFa=s(iie);pbt=r(HFa,"FlaxMT5ForConditionalGeneration"),HFa.forEach(t),_bt=r(Joo," (MT5 model)"),Joo.forEach(t),bbt=i(we),P8=n(we,"LI",{});var Yoo=s(P8);ESe=n(Yoo,"STRONG",{});var JFa=s(ESe);vbt=r(JFa,"roberta"),JFa.forEach(t),Fbt=r(Yoo," \u2014 "),die=n(Yoo,"A",{href:!0});var YFa=s(die);Tbt=r(YFa,"FlaxRobertaForMaskedLM"),YFa.forEach(t),Mbt=r(Yoo," (RoBERTa model)"),Yoo.forEach(t),Ebt=i(we),B8=n(we,"LI",{});var Zoo=s(B8);CSe=n(Zoo,"STRONG",{});var ZFa=s(CSe);Cbt=r(ZFa,"roformer"),ZFa.forEach(t),wbt=r(Zoo," \u2014 "),mie=n(Zoo,"A",{href:!0});var KFa=s(mie);Abt=r(KFa,"FlaxRoFormerForMaskedLM"),KFa.forEach(t),Lbt=r(Zoo," (RoFormer model)"),Zoo.forEach(t),ybt=i(we),I8=n(we,"LI",{});var Koo=s(I8);wSe=n(Koo,"STRONG",{});var eTa=s(wSe);xbt=r(eTa,"t5"),eTa.forEach(t),$bt=r(Koo," \u2014 "),cie=n(Koo,"A",{href:!0});var oTa=s(cie);kbt=r(oTa,"FlaxT5ForConditionalGeneration"),oTa.forEach(t),Sbt=r(Koo," (T5 model)"),Koo.forEach(t),Rbt=i(we),N8=n(we,"LI",{});var ero=s(N8);ASe=n(ero,"STRONG",{});var rTa=s(ASe);Pbt=r(rTa,"wav2vec2"),rTa.forEach(t),Bbt=r(ero," \u2014 "),fie=n(ero,"A",{href:!0});var tTa=s(fie);Ibt=r(tTa,"FlaxWav2Vec2ForPreTraining"),tTa.forEach(t),Nbt=r(ero," (Wav2Vec2 model)"),ero.forEach(t),qbt=i(we),q8=n(we,"LI",{});var oro=s(q8);LSe=n(oro,"STRONG",{});var aTa=s(LSe);jbt=r(aTa,"xlm-roberta"),aTa.forEach(t),Dbt=r(oro," \u2014 "),gie=n(oro,"A",{href:!0});var nTa=s(gie);Gbt=r(nTa,"FlaxXLMRobertaForMaskedLM"),nTa.forEach(t),Obt=r(oro," (XLM-RoBERTa model)"),oro.forEach(t),we.forEach(t),Vbt=i(Yi),T(j8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),lno=i(c),gf=n(c,"H2",{class:!0});var ylo=s(gf);D8=n(ylo,"A",{id:!0,class:!0,href:!0});var sTa=s(D8);ySe=n(sTa,"SPAN",{});var lTa=s(ySe);T(KP.$$.fragment,lTa),lTa.forEach(t),sTa.forEach(t),Xbt=i(ylo),xSe=n(ylo,"SPAN",{});var iTa=s(xSe);zbt=r(iTa,"FlaxAutoModelForMaskedLM"),iTa.forEach(t),ylo.forEach(t),ino=i(c),xr=n(c,"DIV",{class:!0});var Zi=s(xr);T(eB.$$.fragment,Zi),Qbt=i(Zi),hf=n(Zi,"P",{});var Nce=s(hf);Wbt=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),hie=n(Nce,"A",{href:!0});var dTa=s(hie);Ubt=r(dTa,"from_pretrained()"),dTa.forEach(t),Hbt=r(Nce," class method or the "),uie=n(Nce,"A",{href:!0});var mTa=s(uie);Jbt=r(mTa,"from_config()"),mTa.forEach(t),Ybt=r(Nce,` class
method.`),Nce.forEach(t),Zbt=i(Zi),oB=n(Zi,"P",{});var xlo=s(oB);Kbt=r(xlo,"This class cannot be instantiated directly using "),$Se=n(xlo,"CODE",{});var cTa=s($Se);evt=r(cTa,"__init__()"),cTa.forEach(t),ovt=r(xlo," (throws an error)."),xlo.forEach(t),rvt=i(Zi),ua=n(Zi,"DIV",{class:!0});var Nx=s(ua);T(rB.$$.fragment,Nx),tvt=i(Nx),kSe=n(Nx,"P",{});var fTa=s(kSe);avt=r(fTa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),fTa.forEach(t),nvt=i(Nx),uf=n(Nx,"P",{});var qce=s(uf);svt=r(qce,`Note:
Loading a model from its configuration file does `),SSe=n(qce,"STRONG",{});var gTa=s(SSe);lvt=r(gTa,"not"),gTa.forEach(t),ivt=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),pie=n(qce,"A",{href:!0});var hTa=s(pie);dvt=r(hTa,"from_pretrained()"),hTa.forEach(t),mvt=r(qce," to load the model weights."),qce.forEach(t),cvt=i(Nx),T(G8.$$.fragment,Nx),Nx.forEach(t),fvt=i(Zi),nt=n(Zi,"DIV",{class:!0});var Ki=s(nt);T(tB.$$.fragment,Ki),gvt=i(Ki),RSe=n(Ki,"P",{});var uTa=s(RSe);hvt=r(uTa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),uTa.forEach(t),uvt=i(Ki),es=n(Ki,"P",{});var qx=s(es);pvt=r(qx,"The model class to instantiate is selected based on the "),PSe=n(qx,"CODE",{});var pTa=s(PSe);_vt=r(pTa,"model_type"),pTa.forEach(t),bvt=r(qx,` property of the config object (either
passed as an argument or loaded from `),BSe=n(qx,"CODE",{});var _Ta=s(BSe);vvt=r(_Ta,"pretrained_model_name_or_path"),_Ta.forEach(t),Fvt=r(qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ISe=n(qx,"CODE",{});var bTa=s(ISe);Tvt=r(bTa,"pretrained_model_name_or_path"),bTa.forEach(t),Mvt=r(qx,":"),qx.forEach(t),Evt=i(Ki),ke=n(Ki,"UL",{});var De=s(ke);O8=n(De,"LI",{});var rro=s(O8);NSe=n(rro,"STRONG",{});var vTa=s(NSe);Cvt=r(vTa,"albert"),vTa.forEach(t),wvt=r(rro," \u2014 "),_ie=n(rro,"A",{href:!0});var FTa=s(_ie);Avt=r(FTa,"FlaxAlbertForMaskedLM"),FTa.forEach(t),Lvt=r(rro," (ALBERT model)"),rro.forEach(t),yvt=i(De),V8=n(De,"LI",{});var tro=s(V8);qSe=n(tro,"STRONG",{});var TTa=s(qSe);xvt=r(TTa,"bart"),TTa.forEach(t),$vt=r(tro," \u2014 "),bie=n(tro,"A",{href:!0});var MTa=s(bie);kvt=r(MTa,"FlaxBartForConditionalGeneration"),MTa.forEach(t),Svt=r(tro," (BART model)"),tro.forEach(t),Rvt=i(De),X8=n(De,"LI",{});var aro=s(X8);jSe=n(aro,"STRONG",{});var ETa=s(jSe);Pvt=r(ETa,"bert"),ETa.forEach(t),Bvt=r(aro," \u2014 "),vie=n(aro,"A",{href:!0});var CTa=s(vie);Ivt=r(CTa,"FlaxBertForMaskedLM"),CTa.forEach(t),Nvt=r(aro," (BERT model)"),aro.forEach(t),qvt=i(De),z8=n(De,"LI",{});var nro=s(z8);DSe=n(nro,"STRONG",{});var wTa=s(DSe);jvt=r(wTa,"big_bird"),wTa.forEach(t),Dvt=r(nro," \u2014 "),Fie=n(nro,"A",{href:!0});var ATa=s(Fie);Gvt=r(ATa,"FlaxBigBirdForMaskedLM"),ATa.forEach(t),Ovt=r(nro," (BigBird model)"),nro.forEach(t),Vvt=i(De),Q8=n(De,"LI",{});var sro=s(Q8);GSe=n(sro,"STRONG",{});var LTa=s(GSe);Xvt=r(LTa,"distilbert"),LTa.forEach(t),zvt=r(sro," \u2014 "),Tie=n(sro,"A",{href:!0});var yTa=s(Tie);Qvt=r(yTa,"FlaxDistilBertForMaskedLM"),yTa.forEach(t),Wvt=r(sro," (DistilBERT model)"),sro.forEach(t),Uvt=i(De),W8=n(De,"LI",{});var lro=s(W8);OSe=n(lro,"STRONG",{});var xTa=s(OSe);Hvt=r(xTa,"electra"),xTa.forEach(t),Jvt=r(lro," \u2014 "),Mie=n(lro,"A",{href:!0});var $Ta=s(Mie);Yvt=r($Ta,"FlaxElectraForMaskedLM"),$Ta.forEach(t),Zvt=r(lro," (ELECTRA model)"),lro.forEach(t),Kvt=i(De),U8=n(De,"LI",{});var iro=s(U8);VSe=n(iro,"STRONG",{});var kTa=s(VSe);eFt=r(kTa,"mbart"),kTa.forEach(t),oFt=r(iro," \u2014 "),Eie=n(iro,"A",{href:!0});var STa=s(Eie);rFt=r(STa,"FlaxMBartForConditionalGeneration"),STa.forEach(t),tFt=r(iro," (mBART model)"),iro.forEach(t),aFt=i(De),H8=n(De,"LI",{});var dro=s(H8);XSe=n(dro,"STRONG",{});var RTa=s(XSe);nFt=r(RTa,"roberta"),RTa.forEach(t),sFt=r(dro," \u2014 "),Cie=n(dro,"A",{href:!0});var PTa=s(Cie);lFt=r(PTa,"FlaxRobertaForMaskedLM"),PTa.forEach(t),iFt=r(dro," (RoBERTa model)"),dro.forEach(t),dFt=i(De),J8=n(De,"LI",{});var mro=s(J8);zSe=n(mro,"STRONG",{});var BTa=s(zSe);mFt=r(BTa,"roformer"),BTa.forEach(t),cFt=r(mro," \u2014 "),wie=n(mro,"A",{href:!0});var ITa=s(wie);fFt=r(ITa,"FlaxRoFormerForMaskedLM"),ITa.forEach(t),gFt=r(mro," (RoFormer model)"),mro.forEach(t),hFt=i(De),Y8=n(De,"LI",{});var cro=s(Y8);QSe=n(cro,"STRONG",{});var NTa=s(QSe);uFt=r(NTa,"xlm-roberta"),NTa.forEach(t),pFt=r(cro," \u2014 "),Aie=n(cro,"A",{href:!0});var qTa=s(Aie);_Ft=r(qTa,"FlaxXLMRobertaForMaskedLM"),qTa.forEach(t),bFt=r(cro," (XLM-RoBERTa model)"),cro.forEach(t),De.forEach(t),vFt=i(Ki),T(Z8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),dno=i(c),pf=n(c,"H2",{class:!0});var $lo=s(pf);K8=n($lo,"A",{id:!0,class:!0,href:!0});var jTa=s(K8);WSe=n(jTa,"SPAN",{});var DTa=s(WSe);T(aB.$$.fragment,DTa),DTa.forEach(t),jTa.forEach(t),FFt=i($lo),USe=n($lo,"SPAN",{});var GTa=s(USe);TFt=r(GTa,"FlaxAutoModelForSeq2SeqLM"),GTa.forEach(t),$lo.forEach(t),mno=i(c),$r=n(c,"DIV",{class:!0});var ed=s($r);T(nB.$$.fragment,ed),MFt=i(ed),_f=n(ed,"P",{});var jce=s(_f);EFt=r(jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Lie=n(jce,"A",{href:!0});var OTa=s(Lie);CFt=r(OTa,"from_pretrained()"),OTa.forEach(t),wFt=r(jce," class method or the "),yie=n(jce,"A",{href:!0});var VTa=s(yie);AFt=r(VTa,"from_config()"),VTa.forEach(t),LFt=r(jce,` class
method.`),jce.forEach(t),yFt=i(ed),sB=n(ed,"P",{});var klo=s(sB);xFt=r(klo,"This class cannot be instantiated directly using "),HSe=n(klo,"CODE",{});var XTa=s(HSe);$Ft=r(XTa,"__init__()"),XTa.forEach(t),kFt=r(klo," (throws an error)."),klo.forEach(t),SFt=i(ed),pa=n(ed,"DIV",{class:!0});var jx=s(pa);T(lB.$$.fragment,jx),RFt=i(jx),JSe=n(jx,"P",{});var zTa=s(JSe);PFt=r(zTa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),zTa.forEach(t),BFt=i(jx),bf=n(jx,"P",{});var Dce=s(bf);IFt=r(Dce,`Note:
Loading a model from its configuration file does `),YSe=n(Dce,"STRONG",{});var QTa=s(YSe);NFt=r(QTa,"not"),QTa.forEach(t),qFt=r(Dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xie=n(Dce,"A",{href:!0});var WTa=s(xie);jFt=r(WTa,"from_pretrained()"),WTa.forEach(t),DFt=r(Dce," to load the model weights."),Dce.forEach(t),GFt=i(jx),T(eL.$$.fragment,jx),jx.forEach(t),OFt=i(ed),st=n(ed,"DIV",{class:!0});var od=s(st);T(iB.$$.fragment,od),VFt=i(od),ZSe=n(od,"P",{});var UTa=s(ZSe);XFt=r(UTa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),UTa.forEach(t),zFt=i(od),os=n(od,"P",{});var Dx=s(os);QFt=r(Dx,"The model class to instantiate is selected based on the "),KSe=n(Dx,"CODE",{});var HTa=s(KSe);WFt=r(HTa,"model_type"),HTa.forEach(t),UFt=r(Dx,` property of the config object (either
passed as an argument or loaded from `),eRe=n(Dx,"CODE",{});var JTa=s(eRe);HFt=r(JTa,"pretrained_model_name_or_path"),JTa.forEach(t),JFt=r(Dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oRe=n(Dx,"CODE",{});var YTa=s(oRe);YFt=r(YTa,"pretrained_model_name_or_path"),YTa.forEach(t),ZFt=r(Dx,":"),Dx.forEach(t),KFt=i(od),Se=n(od,"UL",{});var Ge=s(Se);oL=n(Ge,"LI",{});var fro=s(oL);rRe=n(fro,"STRONG",{});var ZTa=s(rRe);eTt=r(ZTa,"bart"),ZTa.forEach(t),oTt=r(fro," \u2014 "),$ie=n(fro,"A",{href:!0});var KTa=s($ie);rTt=r(KTa,"FlaxBartForConditionalGeneration"),KTa.forEach(t),tTt=r(fro," (BART model)"),fro.forEach(t),aTt=i(Ge),rL=n(Ge,"LI",{});var gro=s(rL);tRe=n(gro,"STRONG",{});var eMa=s(tRe);nTt=r(eMa,"blenderbot"),eMa.forEach(t),sTt=r(gro," \u2014 "),kie=n(gro,"A",{href:!0});var oMa=s(kie);lTt=r(oMa,"FlaxBlenderbotForConditionalGeneration"),oMa.forEach(t),iTt=r(gro," (Blenderbot model)"),gro.forEach(t),dTt=i(Ge),tL=n(Ge,"LI",{});var hro=s(tL);aRe=n(hro,"STRONG",{});var rMa=s(aRe);mTt=r(rMa,"blenderbot-small"),rMa.forEach(t),cTt=r(hro," \u2014 "),Sie=n(hro,"A",{href:!0});var tMa=s(Sie);fTt=r(tMa,"FlaxBlenderbotSmallForConditionalGeneration"),tMa.forEach(t),gTt=r(hro," (BlenderbotSmall model)"),hro.forEach(t),hTt=i(Ge),aL=n(Ge,"LI",{});var uro=s(aL);nRe=n(uro,"STRONG",{});var aMa=s(nRe);uTt=r(aMa,"encoder-decoder"),aMa.forEach(t),pTt=r(uro," \u2014 "),Rie=n(uro,"A",{href:!0});var nMa=s(Rie);_Tt=r(nMa,"FlaxEncoderDecoderModel"),nMa.forEach(t),bTt=r(uro," (Encoder decoder model)"),uro.forEach(t),vTt=i(Ge),nL=n(Ge,"LI",{});var pro=s(nL);sRe=n(pro,"STRONG",{});var sMa=s(sRe);FTt=r(sMa,"longt5"),sMa.forEach(t),TTt=r(pro," \u2014 "),Pie=n(pro,"A",{href:!0});var lMa=s(Pie);MTt=r(lMa,"FlaxLongT5ForConditionalGeneration"),lMa.forEach(t),ETt=r(pro," (LongT5 model)"),pro.forEach(t),CTt=i(Ge),sL=n(Ge,"LI",{});var _ro=s(sL);lRe=n(_ro,"STRONG",{});var iMa=s(lRe);wTt=r(iMa,"marian"),iMa.forEach(t),ATt=r(_ro," \u2014 "),Bie=n(_ro,"A",{href:!0});var dMa=s(Bie);LTt=r(dMa,"FlaxMarianMTModel"),dMa.forEach(t),yTt=r(_ro," (Marian model)"),_ro.forEach(t),xTt=i(Ge),lL=n(Ge,"LI",{});var bro=s(lL);iRe=n(bro,"STRONG",{});var mMa=s(iRe);$Tt=r(mMa,"mbart"),mMa.forEach(t),kTt=r(bro," \u2014 "),Iie=n(bro,"A",{href:!0});var cMa=s(Iie);STt=r(cMa,"FlaxMBartForConditionalGeneration"),cMa.forEach(t),RTt=r(bro," (mBART model)"),bro.forEach(t),PTt=i(Ge),iL=n(Ge,"LI",{});var vro=s(iL);dRe=n(vro,"STRONG",{});var fMa=s(dRe);BTt=r(fMa,"mt5"),fMa.forEach(t),ITt=r(vro," \u2014 "),Nie=n(vro,"A",{href:!0});var gMa=s(Nie);NTt=r(gMa,"FlaxMT5ForConditionalGeneration"),gMa.forEach(t),qTt=r(vro," (MT5 model)"),vro.forEach(t),jTt=i(Ge),dL=n(Ge,"LI",{});var Fro=s(dL);mRe=n(Fro,"STRONG",{});var hMa=s(mRe);DTt=r(hMa,"pegasus"),hMa.forEach(t),GTt=r(Fro," \u2014 "),qie=n(Fro,"A",{href:!0});var uMa=s(qie);OTt=r(uMa,"FlaxPegasusForConditionalGeneration"),uMa.forEach(t),VTt=r(Fro," (Pegasus model)"),Fro.forEach(t),XTt=i(Ge),mL=n(Ge,"LI",{});var Tro=s(mL);cRe=n(Tro,"STRONG",{});var pMa=s(cRe);zTt=r(pMa,"t5"),pMa.forEach(t),QTt=r(Tro," \u2014 "),jie=n(Tro,"A",{href:!0});var _Ma=s(jie);WTt=r(_Ma,"FlaxT5ForConditionalGeneration"),_Ma.forEach(t),UTt=r(Tro," (T5 model)"),Tro.forEach(t),Ge.forEach(t),HTt=i(od),T(cL.$$.fragment,od),od.forEach(t),ed.forEach(t),cno=i(c),vf=n(c,"H2",{class:!0});var Slo=s(vf);fL=n(Slo,"A",{id:!0,class:!0,href:!0});var bMa=s(fL);fRe=n(bMa,"SPAN",{});var vMa=s(fRe);T(dB.$$.fragment,vMa),vMa.forEach(t),bMa.forEach(t),JTt=i(Slo),gRe=n(Slo,"SPAN",{});var FMa=s(gRe);YTt=r(FMa,"FlaxAutoModelForSequenceClassification"),FMa.forEach(t),Slo.forEach(t),fno=i(c),kr=n(c,"DIV",{class:!0});var rd=s(kr);T(mB.$$.fragment,rd),ZTt=i(rd),Ff=n(rd,"P",{});var Gce=s(Ff);KTt=r(Gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Die=n(Gce,"A",{href:!0});var TMa=s(Die);eMt=r(TMa,"from_pretrained()"),TMa.forEach(t),oMt=r(Gce," class method or the "),Gie=n(Gce,"A",{href:!0});var MMa=s(Gie);rMt=r(MMa,"from_config()"),MMa.forEach(t),tMt=r(Gce,` class
method.`),Gce.forEach(t),aMt=i(rd),cB=n(rd,"P",{});var Rlo=s(cB);nMt=r(Rlo,"This class cannot be instantiated directly using "),hRe=n(Rlo,"CODE",{});var EMa=s(hRe);sMt=r(EMa,"__init__()"),EMa.forEach(t),lMt=r(Rlo," (throws an error)."),Rlo.forEach(t),iMt=i(rd),_a=n(rd,"DIV",{class:!0});var Gx=s(_a);T(fB.$$.fragment,Gx),dMt=i(Gx),uRe=n(Gx,"P",{});var CMa=s(uRe);mMt=r(CMa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),CMa.forEach(t),cMt=i(Gx),Tf=n(Gx,"P",{});var Oce=s(Tf);fMt=r(Oce,`Note:
Loading a model from its configuration file does `),pRe=n(Oce,"STRONG",{});var wMa=s(pRe);gMt=r(wMa,"not"),wMa.forEach(t),hMt=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Oie=n(Oce,"A",{href:!0});var AMa=s(Oie);uMt=r(AMa,"from_pretrained()"),AMa.forEach(t),pMt=r(Oce," to load the model weights."),Oce.forEach(t),_Mt=i(Gx),T(gL.$$.fragment,Gx),Gx.forEach(t),bMt=i(rd),lt=n(rd,"DIV",{class:!0});var td=s(lt);T(gB.$$.fragment,td),vMt=i(td),_Re=n(td,"P",{});var LMa=s(_Re);FMt=r(LMa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),LMa.forEach(t),TMt=i(td),rs=n(td,"P",{});var Ox=s(rs);MMt=r(Ox,"The model class to instantiate is selected based on the "),bRe=n(Ox,"CODE",{});var yMa=s(bRe);EMt=r(yMa,"model_type"),yMa.forEach(t),CMt=r(Ox,` property of the config object (either
passed as an argument or loaded from `),vRe=n(Ox,"CODE",{});var xMa=s(vRe);wMt=r(xMa,"pretrained_model_name_or_path"),xMa.forEach(t),AMt=r(Ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FRe=n(Ox,"CODE",{});var $Ma=s(FRe);LMt=r($Ma,"pretrained_model_name_or_path"),$Ma.forEach(t),yMt=r(Ox,":"),Ox.forEach(t),xMt=i(td),Re=n(td,"UL",{});var Oe=s(Re);hL=n(Oe,"LI",{});var Mro=s(hL);TRe=n(Mro,"STRONG",{});var kMa=s(TRe);$Mt=r(kMa,"albert"),kMa.forEach(t),kMt=r(Mro," \u2014 "),Vie=n(Mro,"A",{href:!0});var SMa=s(Vie);SMt=r(SMa,"FlaxAlbertForSequenceClassification"),SMa.forEach(t),RMt=r(Mro," (ALBERT model)"),Mro.forEach(t),PMt=i(Oe),uL=n(Oe,"LI",{});var Ero=s(uL);MRe=n(Ero,"STRONG",{});var RMa=s(MRe);BMt=r(RMa,"bart"),RMa.forEach(t),IMt=r(Ero," \u2014 "),Xie=n(Ero,"A",{href:!0});var PMa=s(Xie);NMt=r(PMa,"FlaxBartForSequenceClassification"),PMa.forEach(t),qMt=r(Ero," (BART model)"),Ero.forEach(t),jMt=i(Oe),pL=n(Oe,"LI",{});var Cro=s(pL);ERe=n(Cro,"STRONG",{});var BMa=s(ERe);DMt=r(BMa,"bert"),BMa.forEach(t),GMt=r(Cro," \u2014 "),zie=n(Cro,"A",{href:!0});var IMa=s(zie);OMt=r(IMa,"FlaxBertForSequenceClassification"),IMa.forEach(t),VMt=r(Cro," (BERT model)"),Cro.forEach(t),XMt=i(Oe),_L=n(Oe,"LI",{});var wro=s(_L);CRe=n(wro,"STRONG",{});var NMa=s(CRe);zMt=r(NMa,"big_bird"),NMa.forEach(t),QMt=r(wro," \u2014 "),Qie=n(wro,"A",{href:!0});var qMa=s(Qie);WMt=r(qMa,"FlaxBigBirdForSequenceClassification"),qMa.forEach(t),UMt=r(wro," (BigBird model)"),wro.forEach(t),HMt=i(Oe),bL=n(Oe,"LI",{});var Aro=s(bL);wRe=n(Aro,"STRONG",{});var jMa=s(wRe);JMt=r(jMa,"distilbert"),jMa.forEach(t),YMt=r(Aro," \u2014 "),Wie=n(Aro,"A",{href:!0});var DMa=s(Wie);ZMt=r(DMa,"FlaxDistilBertForSequenceClassification"),DMa.forEach(t),KMt=r(Aro," (DistilBERT model)"),Aro.forEach(t),eEt=i(Oe),vL=n(Oe,"LI",{});var Lro=s(vL);ARe=n(Lro,"STRONG",{});var GMa=s(ARe);oEt=r(GMa,"electra"),GMa.forEach(t),rEt=r(Lro," \u2014 "),Uie=n(Lro,"A",{href:!0});var OMa=s(Uie);tEt=r(OMa,"FlaxElectraForSequenceClassification"),OMa.forEach(t),aEt=r(Lro," (ELECTRA model)"),Lro.forEach(t),nEt=i(Oe),FL=n(Oe,"LI",{});var yro=s(FL);LRe=n(yro,"STRONG",{});var VMa=s(LRe);sEt=r(VMa,"mbart"),VMa.forEach(t),lEt=r(yro," \u2014 "),Hie=n(yro,"A",{href:!0});var XMa=s(Hie);iEt=r(XMa,"FlaxMBartForSequenceClassification"),XMa.forEach(t),dEt=r(yro," (mBART model)"),yro.forEach(t),mEt=i(Oe),TL=n(Oe,"LI",{});var xro=s(TL);yRe=n(xro,"STRONG",{});var zMa=s(yRe);cEt=r(zMa,"roberta"),zMa.forEach(t),fEt=r(xro," \u2014 "),Jie=n(xro,"A",{href:!0});var QMa=s(Jie);gEt=r(QMa,"FlaxRobertaForSequenceClassification"),QMa.forEach(t),hEt=r(xro," (RoBERTa model)"),xro.forEach(t),uEt=i(Oe),ML=n(Oe,"LI",{});var $ro=s(ML);xRe=n($ro,"STRONG",{});var WMa=s(xRe);pEt=r(WMa,"roformer"),WMa.forEach(t),_Et=r($ro," \u2014 "),Yie=n($ro,"A",{href:!0});var UMa=s(Yie);bEt=r(UMa,"FlaxRoFormerForSequenceClassification"),UMa.forEach(t),vEt=r($ro," (RoFormer model)"),$ro.forEach(t),FEt=i(Oe),EL=n(Oe,"LI",{});var kro=s(EL);$Re=n(kro,"STRONG",{});var HMa=s($Re);TEt=r(HMa,"xlm-roberta"),HMa.forEach(t),MEt=r(kro," \u2014 "),Zie=n(kro,"A",{href:!0});var JMa=s(Zie);EEt=r(JMa,"FlaxXLMRobertaForSequenceClassification"),JMa.forEach(t),CEt=r(kro," (XLM-RoBERTa model)"),kro.forEach(t),Oe.forEach(t),wEt=i(td),T(CL.$$.fragment,td),td.forEach(t),rd.forEach(t),gno=i(c),Mf=n(c,"H2",{class:!0});var Plo=s(Mf);wL=n(Plo,"A",{id:!0,class:!0,href:!0});var YMa=s(wL);kRe=n(YMa,"SPAN",{});var ZMa=s(kRe);T(hB.$$.fragment,ZMa),ZMa.forEach(t),YMa.forEach(t),AEt=i(Plo),SRe=n(Plo,"SPAN",{});var KMa=s(SRe);LEt=r(KMa,"FlaxAutoModelForQuestionAnswering"),KMa.forEach(t),Plo.forEach(t),hno=i(c),Sr=n(c,"DIV",{class:!0});var ad=s(Sr);T(uB.$$.fragment,ad),yEt=i(ad),Ef=n(ad,"P",{});var Vce=s(Ef);xEt=r(Vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kie=n(Vce,"A",{href:!0});var eEa=s(Kie);$Et=r(eEa,"from_pretrained()"),eEa.forEach(t),kEt=r(Vce," class method or the "),ede=n(Vce,"A",{href:!0});var oEa=s(ede);SEt=r(oEa,"from_config()"),oEa.forEach(t),REt=r(Vce,` class
method.`),Vce.forEach(t),PEt=i(ad),pB=n(ad,"P",{});var Blo=s(pB);BEt=r(Blo,"This class cannot be instantiated directly using "),RRe=n(Blo,"CODE",{});var rEa=s(RRe);IEt=r(rEa,"__init__()"),rEa.forEach(t),NEt=r(Blo," (throws an error)."),Blo.forEach(t),qEt=i(ad),ba=n(ad,"DIV",{class:!0});var Vx=s(ba);T(_B.$$.fragment,Vx),jEt=i(Vx),PRe=n(Vx,"P",{});var tEa=s(PRe);DEt=r(tEa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),tEa.forEach(t),GEt=i(Vx),Cf=n(Vx,"P",{});var Xce=s(Cf);OEt=r(Xce,`Note:
Loading a model from its configuration file does `),BRe=n(Xce,"STRONG",{});var aEa=s(BRe);VEt=r(aEa,"not"),aEa.forEach(t),XEt=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ode=n(Xce,"A",{href:!0});var nEa=s(ode);zEt=r(nEa,"from_pretrained()"),nEa.forEach(t),QEt=r(Xce," to load the model weights."),Xce.forEach(t),WEt=i(Vx),T(AL.$$.fragment,Vx),Vx.forEach(t),UEt=i(ad),it=n(ad,"DIV",{class:!0});var nd=s(it);T(bB.$$.fragment,nd),HEt=i(nd),IRe=n(nd,"P",{});var sEa=s(IRe);JEt=r(sEa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),sEa.forEach(t),YEt=i(nd),ts=n(nd,"P",{});var Xx=s(ts);ZEt=r(Xx,"The model class to instantiate is selected based on the "),NRe=n(Xx,"CODE",{});var lEa=s(NRe);KEt=r(lEa,"model_type"),lEa.forEach(t),e4t=r(Xx,` property of the config object (either
passed as an argument or loaded from `),qRe=n(Xx,"CODE",{});var iEa=s(qRe);o4t=r(iEa,"pretrained_model_name_or_path"),iEa.forEach(t),r4t=r(Xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jRe=n(Xx,"CODE",{});var dEa=s(jRe);t4t=r(dEa,"pretrained_model_name_or_path"),dEa.forEach(t),a4t=r(Xx,":"),Xx.forEach(t),n4t=i(nd),Pe=n(nd,"UL",{});var Ve=s(Pe);LL=n(Ve,"LI",{});var Sro=s(LL);DRe=n(Sro,"STRONG",{});var mEa=s(DRe);s4t=r(mEa,"albert"),mEa.forEach(t),l4t=r(Sro," \u2014 "),rde=n(Sro,"A",{href:!0});var cEa=s(rde);i4t=r(cEa,"FlaxAlbertForQuestionAnswering"),cEa.forEach(t),d4t=r(Sro," (ALBERT model)"),Sro.forEach(t),m4t=i(Ve),yL=n(Ve,"LI",{});var Rro=s(yL);GRe=n(Rro,"STRONG",{});var fEa=s(GRe);c4t=r(fEa,"bart"),fEa.forEach(t),f4t=r(Rro," \u2014 "),tde=n(Rro,"A",{href:!0});var gEa=s(tde);g4t=r(gEa,"FlaxBartForQuestionAnswering"),gEa.forEach(t),h4t=r(Rro," (BART model)"),Rro.forEach(t),u4t=i(Ve),xL=n(Ve,"LI",{});var Pro=s(xL);ORe=n(Pro,"STRONG",{});var hEa=s(ORe);p4t=r(hEa,"bert"),hEa.forEach(t),_4t=r(Pro," \u2014 "),ade=n(Pro,"A",{href:!0});var uEa=s(ade);b4t=r(uEa,"FlaxBertForQuestionAnswering"),uEa.forEach(t),v4t=r(Pro," (BERT model)"),Pro.forEach(t),F4t=i(Ve),$L=n(Ve,"LI",{});var Bro=s($L);VRe=n(Bro,"STRONG",{});var pEa=s(VRe);T4t=r(pEa,"big_bird"),pEa.forEach(t),M4t=r(Bro," \u2014 "),nde=n(Bro,"A",{href:!0});var _Ea=s(nde);E4t=r(_Ea,"FlaxBigBirdForQuestionAnswering"),_Ea.forEach(t),C4t=r(Bro," (BigBird model)"),Bro.forEach(t),w4t=i(Ve),kL=n(Ve,"LI",{});var Iro=s(kL);XRe=n(Iro,"STRONG",{});var bEa=s(XRe);A4t=r(bEa,"distilbert"),bEa.forEach(t),L4t=r(Iro," \u2014 "),sde=n(Iro,"A",{href:!0});var vEa=s(sde);y4t=r(vEa,"FlaxDistilBertForQuestionAnswering"),vEa.forEach(t),x4t=r(Iro," (DistilBERT model)"),Iro.forEach(t),$4t=i(Ve),SL=n(Ve,"LI",{});var Nro=s(SL);zRe=n(Nro,"STRONG",{});var FEa=s(zRe);k4t=r(FEa,"electra"),FEa.forEach(t),S4t=r(Nro," \u2014 "),lde=n(Nro,"A",{href:!0});var TEa=s(lde);R4t=r(TEa,"FlaxElectraForQuestionAnswering"),TEa.forEach(t),P4t=r(Nro," (ELECTRA model)"),Nro.forEach(t),B4t=i(Ve),RL=n(Ve,"LI",{});var qro=s(RL);QRe=n(qro,"STRONG",{});var MEa=s(QRe);I4t=r(MEa,"mbart"),MEa.forEach(t),N4t=r(qro," \u2014 "),ide=n(qro,"A",{href:!0});var EEa=s(ide);q4t=r(EEa,"FlaxMBartForQuestionAnswering"),EEa.forEach(t),j4t=r(qro," (mBART model)"),qro.forEach(t),D4t=i(Ve),PL=n(Ve,"LI",{});var jro=s(PL);WRe=n(jro,"STRONG",{});var CEa=s(WRe);G4t=r(CEa,"roberta"),CEa.forEach(t),O4t=r(jro," \u2014 "),dde=n(jro,"A",{href:!0});var wEa=s(dde);V4t=r(wEa,"FlaxRobertaForQuestionAnswering"),wEa.forEach(t),X4t=r(jro," (RoBERTa model)"),jro.forEach(t),z4t=i(Ve),BL=n(Ve,"LI",{});var Dro=s(BL);URe=n(Dro,"STRONG",{});var AEa=s(URe);Q4t=r(AEa,"roformer"),AEa.forEach(t),W4t=r(Dro," \u2014 "),mde=n(Dro,"A",{href:!0});var LEa=s(mde);U4t=r(LEa,"FlaxRoFormerForQuestionAnswering"),LEa.forEach(t),H4t=r(Dro," (RoFormer model)"),Dro.forEach(t),J4t=i(Ve),IL=n(Ve,"LI",{});var Gro=s(IL);HRe=n(Gro,"STRONG",{});var yEa=s(HRe);Y4t=r(yEa,"xlm-roberta"),yEa.forEach(t),Z4t=r(Gro," \u2014 "),cde=n(Gro,"A",{href:!0});var xEa=s(cde);K4t=r(xEa,"FlaxXLMRobertaForQuestionAnswering"),xEa.forEach(t),eCt=r(Gro," (XLM-RoBERTa model)"),Gro.forEach(t),Ve.forEach(t),oCt=i(nd),T(NL.$$.fragment,nd),nd.forEach(t),ad.forEach(t),uno=i(c),wf=n(c,"H2",{class:!0});var Ilo=s(wf);qL=n(Ilo,"A",{id:!0,class:!0,href:!0});var $Ea=s(qL);JRe=n($Ea,"SPAN",{});var kEa=s(JRe);T(vB.$$.fragment,kEa),kEa.forEach(t),$Ea.forEach(t),rCt=i(Ilo),YRe=n(Ilo,"SPAN",{});var SEa=s(YRe);tCt=r(SEa,"FlaxAutoModelForTokenClassification"),SEa.forEach(t),Ilo.forEach(t),pno=i(c),Rr=n(c,"DIV",{class:!0});var sd=s(Rr);T(FB.$$.fragment,sd),aCt=i(sd),Af=n(sd,"P",{});var zce=s(Af);nCt=r(zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fde=n(zce,"A",{href:!0});var REa=s(fde);sCt=r(REa,"from_pretrained()"),REa.forEach(t),lCt=r(zce," class method or the "),gde=n(zce,"A",{href:!0});var PEa=s(gde);iCt=r(PEa,"from_config()"),PEa.forEach(t),dCt=r(zce,` class
method.`),zce.forEach(t),mCt=i(sd),TB=n(sd,"P",{});var Nlo=s(TB);cCt=r(Nlo,"This class cannot be instantiated directly using "),ZRe=n(Nlo,"CODE",{});var BEa=s(ZRe);fCt=r(BEa,"__init__()"),BEa.forEach(t),gCt=r(Nlo," (throws an error)."),Nlo.forEach(t),hCt=i(sd),va=n(sd,"DIV",{class:!0});var zx=s(va);T(MB.$$.fragment,zx),uCt=i(zx),KRe=n(zx,"P",{});var IEa=s(KRe);pCt=r(IEa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),IEa.forEach(t),_Ct=i(zx),Lf=n(zx,"P",{});var Qce=s(Lf);bCt=r(Qce,`Note:
Loading a model from its configuration file does `),ePe=n(Qce,"STRONG",{});var NEa=s(ePe);vCt=r(NEa,"not"),NEa.forEach(t),FCt=r(Qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),hde=n(Qce,"A",{href:!0});var qEa=s(hde);TCt=r(qEa,"from_pretrained()"),qEa.forEach(t),MCt=r(Qce," to load the model weights."),Qce.forEach(t),ECt=i(zx),T(jL.$$.fragment,zx),zx.forEach(t),CCt=i(sd),dt=n(sd,"DIV",{class:!0});var ld=s(dt);T(EB.$$.fragment,ld),wCt=i(ld),oPe=n(ld,"P",{});var jEa=s(oPe);ACt=r(jEa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),jEa.forEach(t),LCt=i(ld),as=n(ld,"P",{});var Qx=s(as);yCt=r(Qx,"The model class to instantiate is selected based on the "),rPe=n(Qx,"CODE",{});var DEa=s(rPe);xCt=r(DEa,"model_type"),DEa.forEach(t),$Ct=r(Qx,` property of the config object (either
passed as an argument or loaded from `),tPe=n(Qx,"CODE",{});var GEa=s(tPe);kCt=r(GEa,"pretrained_model_name_or_path"),GEa.forEach(t),SCt=r(Qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aPe=n(Qx,"CODE",{});var OEa=s(aPe);RCt=r(OEa,"pretrained_model_name_or_path"),OEa.forEach(t),PCt=r(Qx,":"),Qx.forEach(t),BCt=i(ld),ze=n(ld,"UL",{});var yo=s(ze);DL=n(yo,"LI",{});var Oro=s(DL);nPe=n(Oro,"STRONG",{});var VEa=s(nPe);ICt=r(VEa,"albert"),VEa.forEach(t),NCt=r(Oro," \u2014 "),ude=n(Oro,"A",{href:!0});var XEa=s(ude);qCt=r(XEa,"FlaxAlbertForTokenClassification"),XEa.forEach(t),jCt=r(Oro," (ALBERT model)"),Oro.forEach(t),DCt=i(yo),GL=n(yo,"LI",{});var Vro=s(GL);sPe=n(Vro,"STRONG",{});var zEa=s(sPe);GCt=r(zEa,"bert"),zEa.forEach(t),OCt=r(Vro," \u2014 "),pde=n(Vro,"A",{href:!0});var QEa=s(pde);VCt=r(QEa,"FlaxBertForTokenClassification"),QEa.forEach(t),XCt=r(Vro," (BERT model)"),Vro.forEach(t),zCt=i(yo),OL=n(yo,"LI",{});var Xro=s(OL);lPe=n(Xro,"STRONG",{});var WEa=s(lPe);QCt=r(WEa,"big_bird"),WEa.forEach(t),WCt=r(Xro," \u2014 "),_de=n(Xro,"A",{href:!0});var UEa=s(_de);UCt=r(UEa,"FlaxBigBirdForTokenClassification"),UEa.forEach(t),HCt=r(Xro," (BigBird model)"),Xro.forEach(t),JCt=i(yo),VL=n(yo,"LI",{});var zro=s(VL);iPe=n(zro,"STRONG",{});var HEa=s(iPe);YCt=r(HEa,"distilbert"),HEa.forEach(t),ZCt=r(zro," \u2014 "),bde=n(zro,"A",{href:!0});var JEa=s(bde);KCt=r(JEa,"FlaxDistilBertForTokenClassification"),JEa.forEach(t),e3t=r(zro," (DistilBERT model)"),zro.forEach(t),o3t=i(yo),XL=n(yo,"LI",{});var Qro=s(XL);dPe=n(Qro,"STRONG",{});var YEa=s(dPe);r3t=r(YEa,"electra"),YEa.forEach(t),t3t=r(Qro," \u2014 "),vde=n(Qro,"A",{href:!0});var ZEa=s(vde);a3t=r(ZEa,"FlaxElectraForTokenClassification"),ZEa.forEach(t),n3t=r(Qro," (ELECTRA model)"),Qro.forEach(t),s3t=i(yo),zL=n(yo,"LI",{});var Wro=s(zL);mPe=n(Wro,"STRONG",{});var KEa=s(mPe);l3t=r(KEa,"roberta"),KEa.forEach(t),i3t=r(Wro," \u2014 "),Fde=n(Wro,"A",{href:!0});var e4a=s(Fde);d3t=r(e4a,"FlaxRobertaForTokenClassification"),e4a.forEach(t),m3t=r(Wro," (RoBERTa model)"),Wro.forEach(t),c3t=i(yo),QL=n(yo,"LI",{});var Uro=s(QL);cPe=n(Uro,"STRONG",{});var o4a=s(cPe);f3t=r(o4a,"roformer"),o4a.forEach(t),g3t=r(Uro," \u2014 "),Tde=n(Uro,"A",{href:!0});var r4a=s(Tde);h3t=r(r4a,"FlaxRoFormerForTokenClassification"),r4a.forEach(t),u3t=r(Uro," (RoFormer model)"),Uro.forEach(t),p3t=i(yo),WL=n(yo,"LI",{});var Hro=s(WL);fPe=n(Hro,"STRONG",{});var t4a=s(fPe);_3t=r(t4a,"xlm-roberta"),t4a.forEach(t),b3t=r(Hro," \u2014 "),Mde=n(Hro,"A",{href:!0});var a4a=s(Mde);v3t=r(a4a,"FlaxXLMRobertaForTokenClassification"),a4a.forEach(t),F3t=r(Hro," (XLM-RoBERTa model)"),Hro.forEach(t),yo.forEach(t),T3t=i(ld),T(UL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),_no=i(c),yf=n(c,"H2",{class:!0});var qlo=s(yf);HL=n(qlo,"A",{id:!0,class:!0,href:!0});var n4a=s(HL);gPe=n(n4a,"SPAN",{});var s4a=s(gPe);T(CB.$$.fragment,s4a),s4a.forEach(t),n4a.forEach(t),M3t=i(qlo),hPe=n(qlo,"SPAN",{});var l4a=s(hPe);E3t=r(l4a,"FlaxAutoModelForMultipleChoice"),l4a.forEach(t),qlo.forEach(t),bno=i(c),Pr=n(c,"DIV",{class:!0});var id=s(Pr);T(wB.$$.fragment,id),C3t=i(id),xf=n(id,"P",{});var Wce=s(xf);w3t=r(Wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ede=n(Wce,"A",{href:!0});var i4a=s(Ede);A3t=r(i4a,"from_pretrained()"),i4a.forEach(t),L3t=r(Wce," class method or the "),Cde=n(Wce,"A",{href:!0});var d4a=s(Cde);y3t=r(d4a,"from_config()"),d4a.forEach(t),x3t=r(Wce,` class
method.`),Wce.forEach(t),$3t=i(id),AB=n(id,"P",{});var jlo=s(AB);k3t=r(jlo,"This class cannot be instantiated directly using "),uPe=n(jlo,"CODE",{});var m4a=s(uPe);S3t=r(m4a,"__init__()"),m4a.forEach(t),R3t=r(jlo," (throws an error)."),jlo.forEach(t),P3t=i(id),Fa=n(id,"DIV",{class:!0});var Wx=s(Fa);T(LB.$$.fragment,Wx),B3t=i(Wx),pPe=n(Wx,"P",{});var c4a=s(pPe);I3t=r(c4a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),c4a.forEach(t),N3t=i(Wx),$f=n(Wx,"P",{});var Uce=s($f);q3t=r(Uce,`Note:
Loading a model from its configuration file does `),_Pe=n(Uce,"STRONG",{});var f4a=s(_Pe);j3t=r(f4a,"not"),f4a.forEach(t),D3t=r(Uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),wde=n(Uce,"A",{href:!0});var g4a=s(wde);G3t=r(g4a,"from_pretrained()"),g4a.forEach(t),O3t=r(Uce," to load the model weights."),Uce.forEach(t),V3t=i(Wx),T(JL.$$.fragment,Wx),Wx.forEach(t),X3t=i(id),mt=n(id,"DIV",{class:!0});var dd=s(mt);T(yB.$$.fragment,dd),z3t=i(dd),bPe=n(dd,"P",{});var h4a=s(bPe);Q3t=r(h4a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),h4a.forEach(t),W3t=i(dd),ns=n(dd,"P",{});var Ux=s(ns);U3t=r(Ux,"The model class to instantiate is selected based on the "),vPe=n(Ux,"CODE",{});var u4a=s(vPe);H3t=r(u4a,"model_type"),u4a.forEach(t),J3t=r(Ux,` property of the config object (either
passed as an argument or loaded from `),FPe=n(Ux,"CODE",{});var p4a=s(FPe);Y3t=r(p4a,"pretrained_model_name_or_path"),p4a.forEach(t),Z3t=r(Ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TPe=n(Ux,"CODE",{});var _4a=s(TPe);K3t=r(_4a,"pretrained_model_name_or_path"),_4a.forEach(t),e5t=r(Ux,":"),Ux.forEach(t),o5t=i(dd),Qe=n(dd,"UL",{});var xo=s(Qe);YL=n(xo,"LI",{});var Jro=s(YL);MPe=n(Jro,"STRONG",{});var b4a=s(MPe);r5t=r(b4a,"albert"),b4a.forEach(t),t5t=r(Jro," \u2014 "),Ade=n(Jro,"A",{href:!0});var v4a=s(Ade);a5t=r(v4a,"FlaxAlbertForMultipleChoice"),v4a.forEach(t),n5t=r(Jro," (ALBERT model)"),Jro.forEach(t),s5t=i(xo),ZL=n(xo,"LI",{});var Yro=s(ZL);EPe=n(Yro,"STRONG",{});var F4a=s(EPe);l5t=r(F4a,"bert"),F4a.forEach(t),i5t=r(Yro," \u2014 "),Lde=n(Yro,"A",{href:!0});var T4a=s(Lde);d5t=r(T4a,"FlaxBertForMultipleChoice"),T4a.forEach(t),m5t=r(Yro," (BERT model)"),Yro.forEach(t),c5t=i(xo),KL=n(xo,"LI",{});var Zro=s(KL);CPe=n(Zro,"STRONG",{});var M4a=s(CPe);f5t=r(M4a,"big_bird"),M4a.forEach(t),g5t=r(Zro," \u2014 "),yde=n(Zro,"A",{href:!0});var E4a=s(yde);h5t=r(E4a,"FlaxBigBirdForMultipleChoice"),E4a.forEach(t),u5t=r(Zro," (BigBird model)"),Zro.forEach(t),p5t=i(xo),ey=n(xo,"LI",{});var Kro=s(ey);wPe=n(Kro,"STRONG",{});var C4a=s(wPe);_5t=r(C4a,"distilbert"),C4a.forEach(t),b5t=r(Kro," \u2014 "),xde=n(Kro,"A",{href:!0});var w4a=s(xde);v5t=r(w4a,"FlaxDistilBertForMultipleChoice"),w4a.forEach(t),F5t=r(Kro," (DistilBERT model)"),Kro.forEach(t),T5t=i(xo),oy=n(xo,"LI",{});var eto=s(oy);APe=n(eto,"STRONG",{});var A4a=s(APe);M5t=r(A4a,"electra"),A4a.forEach(t),E5t=r(eto," \u2014 "),$de=n(eto,"A",{href:!0});var L4a=s($de);C5t=r(L4a,"FlaxElectraForMultipleChoice"),L4a.forEach(t),w5t=r(eto," (ELECTRA model)"),eto.forEach(t),A5t=i(xo),ry=n(xo,"LI",{});var oto=s(ry);LPe=n(oto,"STRONG",{});var y4a=s(LPe);L5t=r(y4a,"roberta"),y4a.forEach(t),y5t=r(oto," \u2014 "),kde=n(oto,"A",{href:!0});var x4a=s(kde);x5t=r(x4a,"FlaxRobertaForMultipleChoice"),x4a.forEach(t),$5t=r(oto," (RoBERTa model)"),oto.forEach(t),k5t=i(xo),ty=n(xo,"LI",{});var rto=s(ty);yPe=n(rto,"STRONG",{});var $4a=s(yPe);S5t=r($4a,"roformer"),$4a.forEach(t),R5t=r(rto," \u2014 "),Sde=n(rto,"A",{href:!0});var k4a=s(Sde);P5t=r(k4a,"FlaxRoFormerForMultipleChoice"),k4a.forEach(t),B5t=r(rto," (RoFormer model)"),rto.forEach(t),I5t=i(xo),ay=n(xo,"LI",{});var tto=s(ay);xPe=n(tto,"STRONG",{});var S4a=s(xPe);N5t=r(S4a,"xlm-roberta"),S4a.forEach(t),q5t=r(tto," \u2014 "),Rde=n(tto,"A",{href:!0});var R4a=s(Rde);j5t=r(R4a,"FlaxXLMRobertaForMultipleChoice"),R4a.forEach(t),D5t=r(tto," (XLM-RoBERTa model)"),tto.forEach(t),xo.forEach(t),G5t=i(dd),T(ny.$$.fragment,dd),dd.forEach(t),id.forEach(t),vno=i(c),kf=n(c,"H2",{class:!0});var Dlo=s(kf);sy=n(Dlo,"A",{id:!0,class:!0,href:!0});var P4a=s(sy);$Pe=n(P4a,"SPAN",{});var B4a=s($Pe);T(xB.$$.fragment,B4a),B4a.forEach(t),P4a.forEach(t),O5t=i(Dlo),kPe=n(Dlo,"SPAN",{});var I4a=s(kPe);V5t=r(I4a,"FlaxAutoModelForNextSentencePrediction"),I4a.forEach(t),Dlo.forEach(t),Fno=i(c),Br=n(c,"DIV",{class:!0});var md=s(Br);T($B.$$.fragment,md),X5t=i(md),Sf=n(md,"P",{});var Hce=s(Sf);z5t=r(Hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Pde=n(Hce,"A",{href:!0});var N4a=s(Pde);Q5t=r(N4a,"from_pretrained()"),N4a.forEach(t),W5t=r(Hce," class method or the "),Bde=n(Hce,"A",{href:!0});var q4a=s(Bde);U5t=r(q4a,"from_config()"),q4a.forEach(t),H5t=r(Hce,` class
method.`),Hce.forEach(t),J5t=i(md),kB=n(md,"P",{});var Glo=s(kB);Y5t=r(Glo,"This class cannot be instantiated directly using "),SPe=n(Glo,"CODE",{});var j4a=s(SPe);Z5t=r(j4a,"__init__()"),j4a.forEach(t),K5t=r(Glo," (throws an error)."),Glo.forEach(t),e0t=i(md),Ta=n(md,"DIV",{class:!0});var Hx=s(Ta);T(SB.$$.fragment,Hx),o0t=i(Hx),RPe=n(Hx,"P",{});var D4a=s(RPe);r0t=r(D4a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),D4a.forEach(t),t0t=i(Hx),Rf=n(Hx,"P",{});var Jce=s(Rf);a0t=r(Jce,`Note:
Loading a model from its configuration file does `),PPe=n(Jce,"STRONG",{});var G4a=s(PPe);n0t=r(G4a,"not"),G4a.forEach(t),s0t=r(Jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ide=n(Jce,"A",{href:!0});var O4a=s(Ide);l0t=r(O4a,"from_pretrained()"),O4a.forEach(t),i0t=r(Jce," to load the model weights."),Jce.forEach(t),d0t=i(Hx),T(ly.$$.fragment,Hx),Hx.forEach(t),m0t=i(md),ct=n(md,"DIV",{class:!0});var cd=s(ct);T(RB.$$.fragment,cd),c0t=i(cd),BPe=n(cd,"P",{});var V4a=s(BPe);f0t=r(V4a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),V4a.forEach(t),g0t=i(cd),ss=n(cd,"P",{});var Jx=s(ss);h0t=r(Jx,"The model class to instantiate is selected based on the "),IPe=n(Jx,"CODE",{});var X4a=s(IPe);u0t=r(X4a,"model_type"),X4a.forEach(t),p0t=r(Jx,` property of the config object (either
passed as an argument or loaded from `),NPe=n(Jx,"CODE",{});var z4a=s(NPe);_0t=r(z4a,"pretrained_model_name_or_path"),z4a.forEach(t),b0t=r(Jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qPe=n(Jx,"CODE",{});var Q4a=s(qPe);v0t=r(Q4a,"pretrained_model_name_or_path"),Q4a.forEach(t),F0t=r(Jx,":"),Jx.forEach(t),T0t=i(cd),jPe=n(cd,"UL",{});var W4a=s(jPe);iy=n(W4a,"LI",{});var ato=s(iy);DPe=n(ato,"STRONG",{});var U4a=s(DPe);M0t=r(U4a,"bert"),U4a.forEach(t),E0t=r(ato," \u2014 "),Nde=n(ato,"A",{href:!0});var H4a=s(Nde);C0t=r(H4a,"FlaxBertForNextSentencePrediction"),H4a.forEach(t),w0t=r(ato," (BERT model)"),ato.forEach(t),W4a.forEach(t),A0t=i(cd),T(dy.$$.fragment,cd),cd.forEach(t),md.forEach(t),Tno=i(c),Pf=n(c,"H2",{class:!0});var Olo=s(Pf);my=n(Olo,"A",{id:!0,class:!0,href:!0});var J4a=s(my);GPe=n(J4a,"SPAN",{});var Y4a=s(GPe);T(PB.$$.fragment,Y4a),Y4a.forEach(t),J4a.forEach(t),L0t=i(Olo),OPe=n(Olo,"SPAN",{});var Z4a=s(OPe);y0t=r(Z4a,"FlaxAutoModelForImageClassification"),Z4a.forEach(t),Olo.forEach(t),Mno=i(c),Ir=n(c,"DIV",{class:!0});var fd=s(Ir);T(BB.$$.fragment,fd),x0t=i(fd),Bf=n(fd,"P",{});var Yce=s(Bf);$0t=r(Yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),qde=n(Yce,"A",{href:!0});var K4a=s(qde);k0t=r(K4a,"from_pretrained()"),K4a.forEach(t),S0t=r(Yce," class method or the "),jde=n(Yce,"A",{href:!0});var eCa=s(jde);R0t=r(eCa,"from_config()"),eCa.forEach(t),P0t=r(Yce,` class
method.`),Yce.forEach(t),B0t=i(fd),IB=n(fd,"P",{});var Vlo=s(IB);I0t=r(Vlo,"This class cannot be instantiated directly using "),VPe=n(Vlo,"CODE",{});var oCa=s(VPe);N0t=r(oCa,"__init__()"),oCa.forEach(t),q0t=r(Vlo," (throws an error)."),Vlo.forEach(t),j0t=i(fd),Ma=n(fd,"DIV",{class:!0});var Yx=s(Ma);T(NB.$$.fragment,Yx),D0t=i(Yx),XPe=n(Yx,"P",{});var rCa=s(XPe);G0t=r(rCa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),rCa.forEach(t),O0t=i(Yx),If=n(Yx,"P",{});var Zce=s(If);V0t=r(Zce,`Note:
Loading a model from its configuration file does `),zPe=n(Zce,"STRONG",{});var tCa=s(zPe);X0t=r(tCa,"not"),tCa.forEach(t),z0t=r(Zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dde=n(Zce,"A",{href:!0});var aCa=s(Dde);Q0t=r(aCa,"from_pretrained()"),aCa.forEach(t),W0t=r(Zce," to load the model weights."),Zce.forEach(t),U0t=i(Yx),T(cy.$$.fragment,Yx),Yx.forEach(t),H0t=i(fd),ft=n(fd,"DIV",{class:!0});var gd=s(ft);T(qB.$$.fragment,gd),J0t=i(gd),QPe=n(gd,"P",{});var nCa=s(QPe);Y0t=r(nCa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),nCa.forEach(t),Z0t=i(gd),ls=n(gd,"P",{});var Zx=s(ls);K0t=r(Zx,"The model class to instantiate is selected based on the "),WPe=n(Zx,"CODE",{});var sCa=s(WPe);ewt=r(sCa,"model_type"),sCa.forEach(t),owt=r(Zx,` property of the config object (either
passed as an argument or loaded from `),UPe=n(Zx,"CODE",{});var lCa=s(UPe);rwt=r(lCa,"pretrained_model_name_or_path"),lCa.forEach(t),twt=r(Zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HPe=n(Zx,"CODE",{});var iCa=s(HPe);awt=r(iCa,"pretrained_model_name_or_path"),iCa.forEach(t),nwt=r(Zx,":"),Zx.forEach(t),swt=i(gd),jB=n(gd,"UL",{});var Xlo=s(jB);fy=n(Xlo,"LI",{});var nto=s(fy);JPe=n(nto,"STRONG",{});var dCa=s(JPe);lwt=r(dCa,"beit"),dCa.forEach(t),iwt=r(nto," \u2014 "),Gde=n(nto,"A",{href:!0});var mCa=s(Gde);dwt=r(mCa,"FlaxBeitForImageClassification"),mCa.forEach(t),mwt=r(nto," (BEiT model)"),nto.forEach(t),cwt=i(Xlo),gy=n(Xlo,"LI",{});var sto=s(gy);YPe=n(sto,"STRONG",{});var cCa=s(YPe);fwt=r(cCa,"vit"),cCa.forEach(t),gwt=r(sto," \u2014 "),Ode=n(sto,"A",{href:!0});var fCa=s(Ode);hwt=r(fCa,"FlaxViTForImageClassification"),fCa.forEach(t),uwt=r(sto," (ViT model)"),sto.forEach(t),Xlo.forEach(t),pwt=i(gd),T(hy.$$.fragment,gd),gd.forEach(t),fd.forEach(t),Eno=i(c),Nf=n(c,"H2",{class:!0});var zlo=s(Nf);uy=n(zlo,"A",{id:!0,class:!0,href:!0});var gCa=s(uy);ZPe=n(gCa,"SPAN",{});var hCa=s(ZPe);T(DB.$$.fragment,hCa),hCa.forEach(t),gCa.forEach(t),_wt=i(zlo),KPe=n(zlo,"SPAN",{});var uCa=s(KPe);bwt=r(uCa,"FlaxAutoModelForVision2Seq"),uCa.forEach(t),zlo.forEach(t),Cno=i(c),Nr=n(c,"DIV",{class:!0});var hd=s(Nr);T(GB.$$.fragment,hd),vwt=i(hd),qf=n(hd,"P",{});var Kce=s(qf);Fwt=r(Kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Vde=n(Kce,"A",{href:!0});var pCa=s(Vde);Twt=r(pCa,"from_pretrained()"),pCa.forEach(t),Mwt=r(Kce," class method or the "),Xde=n(Kce,"A",{href:!0});var _Ca=s(Xde);Ewt=r(_Ca,"from_config()"),_Ca.forEach(t),Cwt=r(Kce,` class
method.`),Kce.forEach(t),wwt=i(hd),OB=n(hd,"P",{});var Qlo=s(OB);Awt=r(Qlo,"This class cannot be instantiated directly using "),eBe=n(Qlo,"CODE",{});var bCa=s(eBe);Lwt=r(bCa,"__init__()"),bCa.forEach(t),ywt=r(Qlo," (throws an error)."),Qlo.forEach(t),xwt=i(hd),Ea=n(hd,"DIV",{class:!0});var Kx=s(Ea);T(VB.$$.fragment,Kx),$wt=i(Kx),oBe=n(Kx,"P",{});var vCa=s(oBe);kwt=r(vCa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),vCa.forEach(t),Swt=i(Kx),jf=n(Kx,"P",{});var efe=s(jf);Rwt=r(efe,`Note:
Loading a model from its configuration file does `),rBe=n(efe,"STRONG",{});var FCa=s(rBe);Pwt=r(FCa,"not"),FCa.forEach(t),Bwt=r(efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zde=n(efe,"A",{href:!0});var TCa=s(zde);Iwt=r(TCa,"from_pretrained()"),TCa.forEach(t),Nwt=r(efe," to load the model weights."),efe.forEach(t),qwt=i(Kx),T(py.$$.fragment,Kx),Kx.forEach(t),jwt=i(hd),gt=n(hd,"DIV",{class:!0});var ud=s(gt);T(XB.$$.fragment,ud),Dwt=i(ud),tBe=n(ud,"P",{});var MCa=s(tBe);Gwt=r(MCa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),MCa.forEach(t),Owt=i(ud),is=n(ud,"P",{});var e$=s(is);Vwt=r(e$,"The model class to instantiate is selected based on the "),aBe=n(e$,"CODE",{});var ECa=s(aBe);Xwt=r(ECa,"model_type"),ECa.forEach(t),zwt=r(e$,` property of the config object (either
passed as an argument or loaded from `),nBe=n(e$,"CODE",{});var CCa=s(nBe);Qwt=r(CCa,"pretrained_model_name_or_path"),CCa.forEach(t),Wwt=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sBe=n(e$,"CODE",{});var wCa=s(sBe);Uwt=r(wCa,"pretrained_model_name_or_path"),wCa.forEach(t),Hwt=r(e$,":"),e$.forEach(t),Jwt=i(ud),lBe=n(ud,"UL",{});var ACa=s(lBe);_y=n(ACa,"LI",{});var lto=s(_y);iBe=n(lto,"STRONG",{});var LCa=s(iBe);Ywt=r(LCa,"vision-encoder-decoder"),LCa.forEach(t),Zwt=r(lto," \u2014 "),Qde=n(lto,"A",{href:!0});var yCa=s(Qde);Kwt=r(yCa,"FlaxVisionEncoderDecoderModel"),yCa.forEach(t),eAt=r(lto," (Vision Encoder decoder model)"),lto.forEach(t),ACa.forEach(t),oAt=i(ud),T(by.$$.fragment,ud),ud.forEach(t),hd.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(Q5a)),m(f,"id","auto-classes"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#auto-classes"),m(u,"class","relative group"),m(ms,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),m(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),m(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),m(Md,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(Wf,"id","extending-the-auto-classes"),m(Wf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Wf,"href","#extending-the-auto-classes"),m(Ed,"class","relative group"),m(Hf,"id","transformers.AutoConfig"),m(Hf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Hf,"href","#transformers.AutoConfig"),m(Cd,"class","relative group"),m(EN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m(CN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),m(wN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),m(AN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),m(LN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),m(yN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),m(xN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),m($N,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(kN,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(SN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),m(RN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),m(PN,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),m(BN,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),m(IN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),m(NN,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),m(qN,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),m(jN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),m(DN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),m(GN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),m(ON,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),m(VN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),m(XN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),m(zN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),m(QN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),m(WN,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),m(UN,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),m(HN,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),m(JN,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),m(YN,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),m(ZN,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),m(KN,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),m(eq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),m(oq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),m(rq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),m(tq,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),m(aq,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),m(nq,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),m(sq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),m(lq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),m(iq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),m(dq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),m(mq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),m(cq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),m(fq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),m(gq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(hq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),m(uq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),m(pq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),m(_q,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),m(bq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),m(vq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),m(Fq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(Tq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(Mq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(Eq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),m(Cq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),m(wq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),m(Aq,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),m(Lq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),m(yq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),m(xq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),m($q,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),m(kq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),m(Sq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),m(Rq,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),m(Pq,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),m(Bq,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),m(Iq,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),m(Nq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),m(qq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(jq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),m(Dq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),m(Gq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),m(Oq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),m(Vq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),m(Xq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),m(zq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),m(Qq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),m(Wq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),m(Uq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),m(Hq,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),m(Jq,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),m(Yq,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),m(Zq,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),m(Kq,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(ej,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(oj,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),m(rj,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),m(tj,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),m(aj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),m(nj,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),m(sj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),m(lj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),m(ij,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),m(dj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),m(mj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),m(cj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),m(fj,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),m(gj,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),m(hj,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(uj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(pj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),m(_j,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m(bj,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),m(vj,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),m(Fj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),m(Tj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),m(Mj,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),m(Ej,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),m(Cj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),m(wj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),m(Aj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(Lj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),m(yj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),m(xj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),m($j,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),m(kj,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),m(Sj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),m(Rj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(Pj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),m(Bj,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),m(Ij,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),m(Nj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(qj,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),m(jj,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),m(Dj,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),m(Gj,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),m(Oj,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),m(Vj,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),m(Xj,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),m(zj,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),m(Qj,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),m(Wj,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),m(Uj,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),m(Hj,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),m(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Eu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cu,"id","transformers.AutoTokenizer"),m(Cu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Cu,"href","#transformers.AutoTokenizer"),m(Ad,"class","relative group"),m(Jj,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(Yj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(Zj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(Kj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),m(eD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),m(oD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),m(rD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(tD,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(aD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(nD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(sD,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),m(lD,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),m(iD,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(dD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),m(mD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),m(cD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(fD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(gD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(hD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(uD,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),m(pD,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),m(_D,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(bD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),m(vD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(FD,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),m(TD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(MD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(ED,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),m(CD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),m(wD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(AD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(LD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),m(yD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),m(xD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),m($D,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(kD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(SD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),m(RD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(PD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),m(BD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),m(ID,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(ND,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(qD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(jD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(DD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),m(GD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(OD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(VD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(XD,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),m(zD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(QD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),m(WD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(UD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(HD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),m(JD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(YD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(ZD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(KD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(eG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(oG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),m(rG,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),m(tG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(aG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(nG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(sG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(lG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),m(iG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),m(dG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(mG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(cG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(fG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(gG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(hG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m(uG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(pG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(_G,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(bG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),m(vG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),m(FG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),m(TG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),m(MG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(EG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(CG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),m(wG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(AG,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),m(LG,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),m(yG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),m(xG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),m($G,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(kG,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(SG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),m(RG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),m(PG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(BG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(IG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(NG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(qG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(jG,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),m(DG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(GG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(OG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(VG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(XG,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),m(zG,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),m(QG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),m(WG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),m(UG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(HG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(JG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),m(YG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),m(ZG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(KG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(eO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),m(oO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),m(rO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(tO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(aO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(nO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(sO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(lO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(iO,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),m(dO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),m(mO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(cO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(fO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(gO,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),m(hO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),m(uO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),m(pO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),m(_O,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(bO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),m(vO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(FO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),m(TO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m(MO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(EO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(CO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),m(wO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(AO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(LO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(yO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),m(xO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m($O,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(kO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(SO,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer"),m(RO,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5TokenizerFast"),m(PO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),m(BO,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),m(IO,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),m(NO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(qO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(jO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(DO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(GO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(OO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(VO,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),m(XO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),m(zO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(QO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(WO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),m(UO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),m(HO,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),m(JO,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),m(YO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(ZO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(KO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(eV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(oV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(rV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(tV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(aV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ip,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dp,"id","transformers.AutoFeatureExtractor"),m(dp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(dp,"href","#transformers.AutoFeatureExtractor"),m(Ld,"class","relative group"),m(nV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(sV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(lV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(iV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),m(dV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(mV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(cV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(fV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(gV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),m(hV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),m(uV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(pV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),m(_V,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),m(bV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),m(vV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),m(FV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(TV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(MV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),m(EV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),m(CV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),m(wV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),m(AV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),m(LV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),m(yV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),m(xV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),m($V,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),m(kV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),m(SV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(RV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(PV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),m(BV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(IV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(NV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(qV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(jV,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),m(DV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),m(GV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(OV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(VV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(XV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(zV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(QV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),m(WV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(UV,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(o_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(r_,"id","transformers.AutoProcessor"),m(r_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(r_,"href","#transformers.AutoProcessor"),m(yd,"class","relative group"),m(HV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(JV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(YV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),m(ZV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),m(KV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(eX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(oX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),m(rX,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),m(tX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),m(aX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),m(nX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(sX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(lX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(iX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m(dX,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),m(mX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(cX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(fX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),m(gX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),m(hX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(uX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(pX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(_X,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),m(bX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),m(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(x_,"id","transformers.AutoModel"),m(x_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x_,"href","#transformers.AutoModel"),m($d,"class","relative group"),m(vX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(FX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(TX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(MX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),m(EX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),m(CX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),m(wX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(AX,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),m(LX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),m(yX,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(xX,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),m($X,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),m(kX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),m(SX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),m(RX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),m(PX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),m(BX,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),m(IX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),m(NX,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),m(qX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),m(jX,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),m(DX,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),m(GX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),m(OX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),m(VX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),m(XX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),m(zX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),m(QX,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),m(WX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),m(UX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),m(HX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),m(JX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),m(YX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),m(ZX,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(KX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),m(ez,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),m(oz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),m(rz,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),m(tz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),m(az,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),m(nz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),m(sz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),m(lz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),m(iz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),m(dz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),m(mz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),m(cz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(fz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),m(gz,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),m(hz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),m(uz,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),m(pz,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),m(_z,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),m(bz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(vz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),m(Fz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(Tz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),m(Mz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),m(Ez,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),m(Cz,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),m(wz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),m(Az,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),m(Lz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),m(yz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),m(xz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m($z,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),m(kz,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),m(Sz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),m(Rz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),m(Pz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),m(Bz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),m(Iz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),m(Nz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),m(qz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),m(jz,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),m(Dz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),m(Gz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),m(Oz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(Vz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),m(Xz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),m(zz,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),m(Qz,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),m(Wz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),m(Uz,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),m(Hz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),m(Jz,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),m(Yz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),m(Zz,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(Kz,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),m(eQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),m(oQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),m(rQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),m(tQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),m(aQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(nQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),m(sQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),m(lQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),m(iQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),m(dQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),m(mQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(cQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),m(fQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(gQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),m(hQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),m(uQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),m(pQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),m(_Q,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),m(bQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),m(vQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),m(FQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),m(TQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),m(MQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),m(EQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),m(CQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),m(wQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),m(AQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),m(LQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),m(yQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),m(xQ,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),m($Q,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(kQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),m(SQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),m(RQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),m(PQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),m(BQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),m(IQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),m(NQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),m(qQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),m(jQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),m(DQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),m(GQ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),m(OQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),m(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Z2,"id","transformers.AutoModelForPreTraining"),m(Z2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Z2,"href","#transformers.AutoModelForPreTraining"),m(Rd,"class","relative group"),m(VQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(XQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(QQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),m(WQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(UQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),m(HQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),m(JQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(YQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(ZQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(KQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(eW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(oW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(rW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(tW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),m(aW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),m(nW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(sW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),m(lW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),m(iW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(dW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(mW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(cW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(fW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(gW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(hW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(uW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(pW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),m(_W,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(bW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(vW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(FW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),m(TW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(MW,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(EW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(CW,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),m(wW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(AW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(LW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(yW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(xW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m($W,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),m(kW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),m(SW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(RW,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),m(PW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(BW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),m(IW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(NW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(qW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(jW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jb,"id","transformers.AutoModelForCausalLM"),m(Jb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Jb,"href","#transformers.AutoModelForCausalLM"),m(Id,"class","relative group"),m(DW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(GW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(OW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(VW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),m(XW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),m(zW,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),m(QW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),m(WW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(UW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(HW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),m(JW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(YW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(ZW,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),m(KW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(eU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),m(oU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),m(rU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),m(tU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(aU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(nU,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),m(sU,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),m(lU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(iU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),m(dU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),m(mU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),m(cU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),m(fU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(gU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),m(hU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(uU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),m(pU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(_U,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(bU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m(vU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(FU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),m(TU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(MU,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m(EU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(CU,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(wU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),m(AU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(LU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),m(yU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),m(xU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),m($U,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ov,"id","transformers.AutoModelForDepthEstimation"),m(Ov,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ov,"href","#transformers.AutoModelForDepthEstimation"),m(jd,"class","relative group"),m(kU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(SU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(RU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(PU,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),m(BU,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),m(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uv,"id","transformers.AutoModelForMaskedLM"),m(Uv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Uv,"href","#transformers.AutoModelForMaskedLM"),m(Od,"class","relative group"),m(IU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(NU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(qU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(DU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(GU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),m(OU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),m(VU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(XU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(zU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(QU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(WU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(UU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(HU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(JU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),m(YU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(ZU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(KU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(eH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(oH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(rH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(tH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(aH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(nH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),m(sH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(lH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(iH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(dH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),m(mH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),m(cH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(fH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(gH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(hH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(uH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(pH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(_H,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(bH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(vH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(FH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(TH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(MH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),m(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(NF,"id","transformers.AutoModelForSeq2SeqLM"),m(NF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(NF,"href","#transformers.AutoModelForSeq2SeqLM"),m(zd,"class","relative group"),m(EH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(CH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(wH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(LH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(yH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(xH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),m($H,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),m(kH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(SH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(RH,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),m(PH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(BH,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),m(IH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(NH,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(qH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(jH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(DH,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(GH,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),m(OH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),m(VH,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(XH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(zH,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lT,"id","transformers.AutoModelForSequenceClassification"),m(lT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(lT,"href","#transformers.AutoModelForSequenceClassification"),m(Ud,"class","relative group"),m(QH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(WH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(UH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(HH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(JH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),m(YH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),m(ZH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),m(KH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(eJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),m(oJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(rJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(tJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(aJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(nJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),m(sJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(lJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),m(iJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m(dJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(mJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),m(cJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),m(fJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(gJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(hJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(uJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(pJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(_J,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(bJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m(vJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(FJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m(TJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),m(MJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),m(EJ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),m(CJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(wJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),m(AJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),m(LJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(yJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),m(xJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m($J,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(kJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),m(SJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),m(RJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),m(PJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),m(BJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),m(IJ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(NJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),m(qJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(jJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(DJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(GJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(OJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(VJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(XJ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(zJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),m(QJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(WJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),m(UJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),m(HJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(JJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),m(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gM,"id","transformers.AutoModelForMultipleChoice"),m(gM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gM,"href","#transformers.AutoModelForMultipleChoice"),m(Yd,"class","relative group"),m(YJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ZJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(KJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(oY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),m(rY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),m(tY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(aY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(nY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(sY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),m(lY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),m(iY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m(dY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(mY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),m(cY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(fY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(gY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(hY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(uY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(pY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),m(_Y,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),m(bY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m(vY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(FY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),m(TY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),m(MY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m(EY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(CY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(wY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(AY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(LY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(yY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),m(xY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),m($Y,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(kY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),m(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(HM,"id","transformers.AutoModelForNextSentencePrediction"),m(HM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(HM,"href","#transformers.AutoModelForNextSentencePrediction"),m(em,"class","relative group"),m(SY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(RY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(IY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),m(NY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(qY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),m(jY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(DY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),m(GY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sE,"id","transformers.AutoModelForTokenClassification"),m(sE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(sE,"href","#transformers.AutoModelForTokenClassification"),m(tm,"class","relative group"),m(OY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(VY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(XY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(QY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),m(WY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),m(UY,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),m(HY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(JY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),m(YY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(ZY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),m(KY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(eZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),m(oZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(rZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(tZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),m(aZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),m(nZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m(sZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(lZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(iZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m(dZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(mZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(cZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(fZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),m(gZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),m(hZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(uZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),m(pZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),m(_Z,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),m(bZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m(vZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(FZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),m(TZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),m(MZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m(EZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(CZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(wZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(AZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(LZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(yZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),m(xZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),m($Z,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(kZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),m(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(YE,"id","transformers.AutoModelForQuestionAnswering"),m(YE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(YE,"href","#transformers.AutoModelForQuestionAnswering"),m(sm,"class","relative group"),m(SZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(RZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(PZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(IZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(NZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(qZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),m(jZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(DZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),m(GZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(OZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(VZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(XZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),m(zZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(QZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),m(WZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(UZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(HZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),m(JZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(YZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(ZZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(KZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(eK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(oK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(rK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(tK,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(aK,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),m(nK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(sK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),m(lK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(iK,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),m(dK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(mK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),m(cK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m(fK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(gK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),m(hK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),m(uK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),m(pK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),m(_K,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(bK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m(vK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(FK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m(TK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(MK,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m(EK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(CK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(wK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),m(AK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),m(LK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(yK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),m(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(H4,"id","transformers.AutoModelForTableQuestionAnswering"),m(H4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(H4,"href","#transformers.AutoModelForTableQuestionAnswering"),m(dm,"class","relative group"),m(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(kK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(SK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eC,"id","transformers.AutoModelForDocumentQuestionAnswering"),m(eC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(eC,"href","#transformers.AutoModelForDocumentQuestionAnswering"),m(fm,"class","relative group"),m(RK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(PK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(BK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(IK,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),m(NK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(qK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lC,"id","transformers.AutoModelForImageClassification"),m(lC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(lC,"href","#transformers.AutoModelForImageClassification"),m(pm,"class","relative group"),m(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(OK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),m(VK,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),m(XK,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),m(zK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),m(QK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),m(WK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(UK,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(HK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),m(JK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),m(YK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),m(ZK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(KK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(eee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(oee,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),m(ree,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),m(tee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),m(aee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(nee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),m(see,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),m(lee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),m(iee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),m(dee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),m(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AC,"id","transformers.AutoModelForVideoClassification"),m(AC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(AC,"href","#transformers.AutoModelForVideoClassification"),m(vm,"class","relative group"),m(mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),m(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kC,"id","transformers.AutoModelForVision2Seq"),m(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(kC,"href","#transformers.AutoModelForVision2Seq"),m(Mm,"class","relative group"),m(hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_ee,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),m(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(IC,"id","transformers.AutoModelForVisualQuestionAnswering"),m(IC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(IC,"href","#transformers.AutoModelForVisualQuestionAnswering"),m(wm,"class","relative group"),m(bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tee,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),m(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GC,"id","transformers.AutoModelForAudioClassification"),m(GC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(GC,"href","#transformers.AutoModelForAudioClassification"),m(ym,"class","relative group"),m(Mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),m(Aee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(Lee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(yee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),m(xee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m($ee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),m(kee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(See,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),m(Ree,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(e3,"id","transformers.AutoModelForAudioFrameClassification"),m(e3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(e3,"href","#transformers.AutoModelForAudioFrameClassification"),m(km,"class","relative group"),m(Pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),m(qee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),m(jee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(Dee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),m(Gee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(d3,"id","transformers.AutoModelForCTC"),m(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(d3,"href","#transformers.AutoModelForCTC"),m(Pm,"class","relative group"),m(Oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),m(Qee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),m(Wee,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),m(Uee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),m(Hee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),m(Jee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(Yee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),m(Zee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(Kee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),m(eoe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),m(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(E3,"id","transformers.AutoModelForSpeechSeq2Seq"),m(E3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E3,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(Nm,"class","relative group"),m(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(toe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aoe,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),m(noe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(soe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),m(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($3,"id","transformers.AutoModelForAudioXVector"),m($3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($3,"href","#transformers.AutoModelForAudioXVector"),m(Gm,"class","relative group"),m(loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ioe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(moe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),m(coe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),m(foe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(goe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),m(hoe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),m(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(j3,"id","transformers.AutoModelForMaskedImageModeling"),m(j3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(j3,"href","#transformers.AutoModelForMaskedImageModeling"),m(Xm,"class","relative group"),m(uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(_oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(boe,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),m(voe,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),m(Foe,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),m(Toe,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),m(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(W3,"id","transformers.AutoModelForObjectDetection"),m(W3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(W3,"href","#transformers.AutoModelForObjectDetection"),m(Wm,"class","relative group"),m(Moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(woe,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),m(Aoe,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),m(Loe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),m(yoe,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),m(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(o5,"id","transformers.AutoModelForImageSegmentation"),m(o5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(o5,"href","#transformers.AutoModelForImageSegmentation"),m(Jm,"class","relative group"),m(xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Soe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),m(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(s5,"id","transformers.AutoModelForSemanticSegmentation"),m(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s5,"href","#transformers.AutoModelForSemanticSegmentation"),m(Km,"class","relative group"),m(Roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ioe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),m(Noe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),m(qoe,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),m(joe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),m(Doe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),m(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(u5,"id","transformers.AutoModelForInstanceSegmentation"),m(u5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(u5,"href","#transformers.AutoModelForInstanceSegmentation"),m(rc,"class","relative group"),m(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xoe,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),m(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F5,"id","transformers.AutoModelForZeroShotObjectDetection"),m(F5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(F5,"href","#transformers.AutoModelForZeroShotObjectDetection"),m(nc,"class","relative group"),m(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uoe,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),m(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(w5,"id","transformers.TFAutoModel"),m(w5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w5,"href","#transformers.TFAutoModel"),m(ic,"class","relative group"),m(Hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zoe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),m(Koe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),m(ere,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),m(ore,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(rre,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),m(tre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),m(are,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),m(nre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),m(sre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),m(lre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),m(ire,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),m(dre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),m(mre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),m(cre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),m(fre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),m(gre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(hre,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(ure,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),m(pre,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),m(_re,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),m(bre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),m(vre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m(Fre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),m(Tre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),m(Mre,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),m(Ere,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),m(Cre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(wre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),m(Are,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),m(Lre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),m(yre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),m(xre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),m($re,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),m(kre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(Sre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),m(Rre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),m(Pre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),m(Bre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),m(Ire,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),m(Nre,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),m(qre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),m(jre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),m(Dre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),m(Gre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),m(Ore,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),m(Vre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),m(Xre,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),m(zre,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),m(Qre,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),m(Wre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),m(Ure,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),m(Hre,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),m(Jre,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),m(Yre,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(Zre,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),m(Kre,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),m(ete,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),m(ote,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),m(rte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),m(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k0,"id","transformers.TFAutoModelForPreTraining"),m(k0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(k0,"href","#transformers.TFAutoModelForPreTraining"),m(cc,"class","relative group"),m(tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ste,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(lte,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(ite,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),m(dte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(mte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(cte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(fte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(gte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(hte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(ute,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(pte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(_te,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m(bte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(vte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Fte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Tte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Mte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Ete,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Cte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(wte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),m(Ate,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Lte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(yte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tw,"id","transformers.TFAutoModelForCausalLM"),m(tw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(tw,"href","#transformers.TFAutoModelForCausalLM"),m(hc,"class","relative group"),m(xte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ste,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(Rte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),m(Pte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Bte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(Ite,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),m(Nte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(qte,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),m(jte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(Dte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(Gte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(Ote,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Vte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),m(Xte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(zte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fw,"id","transformers.TFAutoModelForImageClassification"),m(Fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Fw,"href","#transformers.TFAutoModelForImageClassification"),m(_c,"class","relative group"),m(Qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ute,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Hte,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),m(Jte,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),m(Yte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),m(Zte,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),m(Kte,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),m(eae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),m(oae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),m(rae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),m(tae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),m(aae,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),m(nae,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),m(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sw,"id","transformers.TFAutoModelForSemanticSegmentation"),m(Sw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Sw,"href","#transformers.TFAutoModelForSemanticSegmentation"),m(Fc,"class","relative group"),m(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),m(mae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),m(cae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),m(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qw,"id","transformers.TFAutoModelForMaskedLM"),m(qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(qw,"href","#transformers.TFAutoModelForMaskedLM"),m(Cc,"class","relative group"),m(fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m(pae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(_ae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(bae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(vae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m(Fae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),m(Tae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Mae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(Eae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),m(Cae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(wae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(Aae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Lae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(yae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(xae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m($ae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(kae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Sae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(Rae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Pae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Bae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(iA,"id","transformers.TFAutoModelForSeq2SeqLM"),m(iA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(iA,"href","#transformers.TFAutoModelForSeq2SeqLM"),m(Lc,"class","relative group"),m(Iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(Dae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(Gae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(Oae,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),m(Vae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(Xae,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),m(zae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(Qae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(Wae,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(Uae,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(TA,"id","transformers.TFAutoModelForSequenceClassification"),m(TA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(TA,"href","#transformers.TFAutoModelForSequenceClassification"),m($c,"class","relative group"),m(Hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(Kae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(ene,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(one,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(rne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(tne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(ane,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),m(nne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(sne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(lne,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),m(ine,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(dne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(mne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(cne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),m(fne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(gne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),m(hne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(une,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(pne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(_ne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),m(bne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(vne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m(Fne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(Tne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m(Mne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),m(Ene,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m(Cne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),m(wne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ZA,"id","transformers.TFAutoModelForMultipleChoice"),m(ZA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ZA,"href","#transformers.TFAutoModelForMultipleChoice"),m(Rc,"class","relative group"),m(Ane,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(yne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m($ne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(kne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(Sne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(Rne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(Pne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(Bne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(Ine,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(Nne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(qne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(jne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(Dne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(Gne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(One,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(Vne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(Xne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),m(zne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(b6,"id","transformers.TFAutoModelForNextSentencePrediction"),m(b6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(b6,"href","#transformers.TFAutoModelForNextSentencePrediction"),m(Ic,"class","relative group"),m(Qne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Hne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),m(Jne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),m(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(E6,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(E6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(jc,"class","relative group"),m(Yne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Kne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ese,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(L6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),m(L6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(L6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),m(Oc,"class","relative group"),m(ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ase,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),m(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k6,"id","transformers.TFAutoModelForTokenClassification"),m(k6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(k6,"href","#transformers.TFAutoModelForTokenClassification"),m(zc,"class","relative group"),m(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ise,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(dse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(mse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(cse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(fse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(gse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),m(hse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(use,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(pse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),m(_se,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m(bse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(vse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m(Fse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),m(Tse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m(Mse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(Ese,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(Cse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m(wse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(Ase,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(Lse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(yse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),m(xse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(r7,"id","transformers.TFAutoModelForQuestionAnswering"),m(r7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(r7,"href","#transformers.TFAutoModelForQuestionAnswering"),m(Uc,"class","relative group"),m($se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(Pse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(Bse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(Ise,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(Nse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(qse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),m(jse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(Dse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(Gse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(Ose,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(Vse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),m(Xse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),m(zse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(Qse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(Wse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(Use,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(Hse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(Jse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m(Yse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(Zse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),m(Kse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(A7,"id","transformers.TFAutoModelForVision2Seq"),m(A7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(A7,"href","#transformers.TFAutoModelForVision2Seq"),m(Yc,"class","relative group"),m(ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(rle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),m(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),m($7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),m(ef,"class","relative group"),m(ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lle,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),m(ile,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B7,"id","transformers.FlaxAutoModel"),m(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(B7,"href","#transformers.FlaxAutoModel"),m(tf,"class","relative group"),m(dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),m(gle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),m(hle,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),m(ule,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),m(ple,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),m(_le,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m(ble,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),m(vle,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),m(Fle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(Tle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),m(Mle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(Ele,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(Cle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(wle,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),m(Ale,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),m(Lle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),m(yle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),m(xle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),m($le,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(kle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(Sle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),m(Rle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),m(Ple,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),m(Ble,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),m(Ile,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(Nle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),m(qle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),m(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(c8,"id","transformers.FlaxAutoModelForCausalLM"),m(c8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(c8,"href","#transformers.FlaxAutoModelForCausalLM"),m(sf,"class","relative group"),m(jle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ole,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),m(Vle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),m(Xle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),m(zle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),m(Qle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(Wle,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(Ule,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(Hle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),m(Jle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),m(Yle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),m(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(C8,"id","transformers.FlaxAutoModelForPreTraining"),m(C8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(C8,"href","#transformers.FlaxAutoModelForPreTraining"),m(mf,"class","relative group"),m(Zle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(eie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(rie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(tie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(aie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),m(nie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(sie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(lie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(iie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(die,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(mie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(cie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(fie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(gie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(D8,"id","transformers.FlaxAutoModelForMaskedLM"),m(D8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(D8,"href","#transformers.FlaxAutoModelForMaskedLM"),m(gf,"class","relative group"),m(hie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_ie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m(bie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(vie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m(Fie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),m(Tie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m(Mie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(Eie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Cie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(wie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Aie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(K8,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(K8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(K8,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(pf,"class","relative group"),m(Lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(xie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($ie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(kie,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(Sie,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(Rie,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),m(Pie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(Bie,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(Iie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Nie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(qie,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m(jie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fL,"id","transformers.FlaxAutoModelForSequenceClassification"),m(fL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fL,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(vf,"class","relative group"),m(Die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Oie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(Xie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(zie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(Qie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),m(Wie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(Uie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(Hie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(Jie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(Yie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),m(Zie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),m(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wL,"id","transformers.FlaxAutoModelForQuestionAnswering"),m(wL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(wL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(Mf,"class","relative group"),m(Kie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ode,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(tde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(ade,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(nde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),m(sde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(lde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m(ide,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(dde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(mde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),m(cde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),m(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qL,"id","transformers.FlaxAutoModelForTokenClassification"),m(qL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(qL,"href","#transformers.FlaxAutoModelForTokenClassification"),m(wf,"class","relative group"),m(fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ude,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(pde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(_de,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),m(bde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(vde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m(Fde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(Tde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),m(Mde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),m(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(HL,"id","transformers.FlaxAutoModelForMultipleChoice"),m(HL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(HL,"href","#transformers.FlaxAutoModelForMultipleChoice"),m(yf,"class","relative group"),m(Ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(wde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ade,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(Lde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(yde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),m(xde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m($de,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(kde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(Sde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),m(Rde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),m(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(sy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(sy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(kf,"class","relative group"),m(Pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(my,"id","transformers.FlaxAutoModelForImageClassification"),m(my,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(my,"href","#transformers.FlaxAutoModelForImageClassification"),m(Pf,"class","relative group"),m(qde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Dde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Gde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(Ode,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uy,"id","transformers.FlaxAutoModelForVision2Seq"),m(uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(uy,"href","#transformers.FlaxAutoModelForVision2Seq"),m(Nf,"class","relative group"),m(Vde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qde,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),m(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,$o),e($o,pd),b(c,Vf,_),b(c,Ft,_),e(Ft,_d),e(Ft,bd),e(bd,o$),e(Ft,Xf),b(c,Xe,_),b(c,He,_),e(He,vd),e(He,ms),e(ms,r$),e(He,cs),e(He,fs),e(fs,t$),e(He,Fd),e(He,gs),e(gs,a$),e(He,Td),b(c,zf,_),M(en,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,_N),e(Ae,Md),e(Md,bN),e(Ae,vN),b(c,ko,_),b(c,on,_),e(on,FN),e(on,Qf),e(Qf,TN),e(on,Wlo),b(c,ito,_),b(c,Ed,_),e(Ed,Wf),e(Wf,ofe),M(n$,ofe,null),e(Ed,Ulo),e(Ed,rfe),e(rfe,Hlo),b(c,dto,_),b(c,hs,_),e(hs,Jlo),e(hs,tfe),e(tfe,Ylo),e(hs,Zlo),e(hs,afe),e(afe,Klo),e(hs,eio),b(c,mto,_),M(s$,c,_),b(c,cto,_),b(c,MN,_),e(MN,oio),b(c,fto,_),M(Uf,c,_),b(c,gto,_),b(c,Cd,_),e(Cd,Hf),e(Hf,nfe),M(l$,nfe,null),e(Cd,rio),e(Cd,sfe),e(sfe,tio),b(c,hto,_),b(c,So,_),M(i$,So,null),e(So,aio),e(So,d$),e(d$,nio),e(d$,EN),e(EN,sio),e(d$,lio),e(So,iio),e(So,m$),e(m$,dio),e(m$,lfe),e(lfe,mio),e(m$,cio),e(So,fio),e(So,qr),M(c$,qr,null),e(qr,gio),e(qr,ife),e(ife,hio),e(qr,uio),e(qr,wd),e(wd,pio),e(wd,dfe),e(dfe,_io),e(wd,bio),e(wd,mfe),e(mfe,vio),e(wd,Fio),e(qr,Tio),e(qr,A),e(A,Jf),e(Jf,cfe),e(cfe,Mio),e(Jf,Eio),e(Jf,CN),e(CN,Cio),e(Jf,wio),e(A,Aio),e(A,Yf),e(Yf,ffe),e(ffe,Lio),e(Yf,yio),e(Yf,wN),e(wN,xio),e(Yf,$io),e(A,kio),e(A,Zf),e(Zf,gfe),e(gfe,Sio),e(Zf,Rio),e(Zf,AN),e(AN,Pio),e(Zf,Bio),e(A,Iio),e(A,Kf),e(Kf,hfe),e(hfe,Nio),e(Kf,qio),e(Kf,LN),e(LN,jio),e(Kf,Dio),e(A,Gio),e(A,eg),e(eg,ufe),e(ufe,Oio),e(eg,Vio),e(eg,yN),e(yN,Xio),e(eg,zio),e(A,Qio),e(A,og),e(og,pfe),e(pfe,Wio),e(og,Uio),e(og,xN),e(xN,Hio),e(og,Jio),e(A,Yio),e(A,rg),e(rg,_fe),e(_fe,Zio),e(rg,Kio),e(rg,$N),e($N,edo),e(rg,odo),e(A,rdo),e(A,tg),e(tg,bfe),e(bfe,tdo),e(tg,ado),e(tg,kN),e(kN,ndo),e(tg,sdo),e(A,ldo),e(A,ag),e(ag,vfe),e(vfe,ido),e(ag,ddo),e(ag,SN),e(SN,mdo),e(ag,cdo),e(A,fdo),e(A,ng),e(ng,Ffe),e(Ffe,gdo),e(ng,hdo),e(ng,RN),e(RN,udo),e(ng,pdo),e(A,_do),e(A,sg),e(sg,Tfe),e(Tfe,bdo),e(sg,vdo),e(sg,PN),e(PN,Fdo),e(sg,Tdo),e(A,Mdo),e(A,lg),e(lg,Mfe),e(Mfe,Edo),e(lg,Cdo),e(lg,BN),e(BN,wdo),e(lg,Ado),e(A,Ldo),e(A,ig),e(ig,Efe),e(Efe,ydo),e(ig,xdo),e(ig,IN),e(IN,$do),e(ig,kdo),e(A,Sdo),e(A,dg),e(dg,Cfe),e(Cfe,Rdo),e(dg,Pdo),e(dg,NN),e(NN,Bdo),e(dg,Ido),e(A,Ndo),e(A,mg),e(mg,wfe),e(wfe,qdo),e(mg,jdo),e(mg,qN),e(qN,Ddo),e(mg,Gdo),e(A,Odo),e(A,cg),e(cg,Afe),e(Afe,Vdo),e(cg,Xdo),e(cg,jN),e(jN,zdo),e(cg,Qdo),e(A,Wdo),e(A,fg),e(fg,Lfe),e(Lfe,Udo),e(fg,Hdo),e(fg,DN),e(DN,Jdo),e(fg,Ydo),e(A,Zdo),e(A,gg),e(gg,yfe),e(yfe,Kdo),e(gg,emo),e(gg,GN),e(GN,omo),e(gg,rmo),e(A,tmo),e(A,hg),e(hg,xfe),e(xfe,amo),e(hg,nmo),e(hg,ON),e(ON,smo),e(hg,lmo),e(A,imo),e(A,ug),e(ug,$fe),e($fe,dmo),e(ug,mmo),e(ug,VN),e(VN,cmo),e(ug,fmo),e(A,gmo),e(A,pg),e(pg,kfe),e(kfe,hmo),e(pg,umo),e(pg,XN),e(XN,pmo),e(pg,_mo),e(A,bmo),e(A,_g),e(_g,Sfe),e(Sfe,vmo),e(_g,Fmo),e(_g,zN),e(zN,Tmo),e(_g,Mmo),e(A,Emo),e(A,bg),e(bg,Rfe),e(Rfe,Cmo),e(bg,wmo),e(bg,QN),e(QN,Amo),e(bg,Lmo),e(A,ymo),e(A,vg),e(vg,Pfe),e(Pfe,xmo),e(vg,$mo),e(vg,WN),e(WN,kmo),e(vg,Smo),e(A,Rmo),e(A,Fg),e(Fg,Bfe),e(Bfe,Pmo),e(Fg,Bmo),e(Fg,UN),e(UN,Imo),e(Fg,Nmo),e(A,qmo),e(A,Tg),e(Tg,Ife),e(Ife,jmo),e(Tg,Dmo),e(Tg,HN),e(HN,Gmo),e(Tg,Omo),e(A,Vmo),e(A,Mg),e(Mg,Nfe),e(Nfe,Xmo),e(Mg,zmo),e(Mg,JN),e(JN,Qmo),e(Mg,Wmo),e(A,Umo),e(A,Eg),e(Eg,qfe),e(qfe,Hmo),e(Eg,Jmo),e(Eg,YN),e(YN,Ymo),e(Eg,Zmo),e(A,Kmo),e(A,Cg),e(Cg,jfe),e(jfe,eco),e(Cg,oco),e(Cg,ZN),e(ZN,rco),e(Cg,tco),e(A,aco),e(A,wg),e(wg,Dfe),e(Dfe,nco),e(wg,sco),e(wg,KN),e(KN,lco),e(wg,ico),e(A,dco),e(A,Ag),e(Ag,Gfe),e(Gfe,mco),e(Ag,cco),e(Ag,eq),e(eq,fco),e(Ag,gco),e(A,hco),e(A,Lg),e(Lg,Ofe),e(Ofe,uco),e(Lg,pco),e(Lg,oq),e(oq,_co),e(Lg,bco),e(A,vco),e(A,yg),e(yg,Vfe),e(Vfe,Fco),e(yg,Tco),e(yg,rq),e(rq,Mco),e(yg,Eco),e(A,Cco),e(A,xg),e(xg,Xfe),e(Xfe,wco),e(xg,Aco),e(xg,tq),e(tq,Lco),e(xg,yco),e(A,xco),e(A,$g),e($g,zfe),e(zfe,$co),e($g,kco),e($g,aq),e(aq,Sco),e($g,Rco),e(A,Pco),e(A,kg),e(kg,Qfe),e(Qfe,Bco),e(kg,Ico),e(kg,nq),e(nq,Nco),e(kg,qco),e(A,jco),e(A,Sg),e(Sg,Wfe),e(Wfe,Dco),e(Sg,Gco),e(Sg,sq),e(sq,Oco),e(Sg,Vco),e(A,Xco),e(A,Rg),e(Rg,Ufe),e(Ufe,zco),e(Rg,Qco),e(Rg,lq),e(lq,Wco),e(Rg,Uco),e(A,Hco),e(A,Pg),e(Pg,Hfe),e(Hfe,Jco),e(Pg,Yco),e(Pg,iq),e(iq,Zco),e(Pg,Kco),e(A,efo),e(A,Bg),e(Bg,Jfe),e(Jfe,ofo),e(Bg,rfo),e(Bg,dq),e(dq,tfo),e(Bg,afo),e(A,nfo),e(A,Ig),e(Ig,Yfe),e(Yfe,sfo),e(Ig,lfo),e(Ig,mq),e(mq,ifo),e(Ig,dfo),e(A,mfo),e(A,Ng),e(Ng,Zfe),e(Zfe,cfo),e(Ng,ffo),e(Ng,cq),e(cq,gfo),e(Ng,hfo),e(A,ufo),e(A,qg),e(qg,Kfe),e(Kfe,pfo),e(qg,_fo),e(qg,fq),e(fq,bfo),e(qg,vfo),e(A,Ffo),e(A,jg),e(jg,ege),e(ege,Tfo),e(jg,Mfo),e(jg,gq),e(gq,Efo),e(jg,Cfo),e(A,wfo),e(A,Dg),e(Dg,oge),e(oge,Afo),e(Dg,Lfo),e(Dg,hq),e(hq,yfo),e(Dg,xfo),e(A,$fo),e(A,Gg),e(Gg,rge),e(rge,kfo),e(Gg,Sfo),e(Gg,uq),e(uq,Rfo),e(Gg,Pfo),e(A,Bfo),e(A,Og),e(Og,tge),e(tge,Ifo),e(Og,Nfo),e(Og,pq),e(pq,qfo),e(Og,jfo),e(A,Dfo),e(A,Vg),e(Vg,age),e(age,Gfo),e(Vg,Ofo),e(Vg,_q),e(_q,Vfo),e(Vg,Xfo),e(A,zfo),e(A,Xg),e(Xg,nge),e(nge,Qfo),e(Xg,Wfo),e(Xg,bq),e(bq,Ufo),e(Xg,Hfo),e(A,Jfo),e(A,zg),e(zg,sge),e(sge,Yfo),e(zg,Zfo),e(zg,vq),e(vq,Kfo),e(zg,ego),e(A,ogo),e(A,Qg),e(Qg,lge),e(lge,rgo),e(Qg,tgo),e(Qg,Fq),e(Fq,ago),e(Qg,ngo),e(A,sgo),e(A,Wg),e(Wg,ige),e(ige,lgo),e(Wg,igo),e(Wg,Tq),e(Tq,dgo),e(Wg,mgo),e(A,cgo),e(A,Ug),e(Ug,dge),e(dge,fgo),e(Ug,ggo),e(Ug,Mq),e(Mq,hgo),e(Ug,ugo),e(A,pgo),e(A,Hg),e(Hg,mge),e(mge,_go),e(Hg,bgo),e(Hg,Eq),e(Eq,vgo),e(Hg,Fgo),e(A,Tgo),e(A,Jg),e(Jg,cge),e(cge,Mgo),e(Jg,Ego),e(Jg,Cq),e(Cq,Cgo),e(Jg,wgo),e(A,Ago),e(A,Yg),e(Yg,fge),e(fge,Lgo),e(Yg,ygo),e(Yg,wq),e(wq,xgo),e(Yg,$go),e(A,kgo),e(A,Zg),e(Zg,gge),e(gge,Sgo),e(Zg,Rgo),e(Zg,Aq),e(Aq,Pgo),e(Zg,Bgo),e(A,Igo),e(A,Kg),e(Kg,hge),e(hge,Ngo),e(Kg,qgo),e(Kg,Lq),e(Lq,jgo),e(Kg,Dgo),e(A,Ggo),e(A,eh),e(eh,uge),e(uge,Ogo),e(eh,Vgo),e(eh,yq),e(yq,Xgo),e(eh,zgo),e(A,Qgo),e(A,oh),e(oh,pge),e(pge,Wgo),e(oh,Ugo),e(oh,xq),e(xq,Hgo),e(oh,Jgo),e(A,Ygo),e(A,rh),e(rh,_ge),e(_ge,Zgo),e(rh,Kgo),e(rh,$q),e($q,eho),e(rh,oho),e(A,rho),e(A,th),e(th,bge),e(bge,tho),e(th,aho),e(th,kq),e(kq,nho),e(th,sho),e(A,lho),e(A,ah),e(ah,vge),e(vge,iho),e(ah,dho),e(ah,Sq),e(Sq,mho),e(ah,cho),e(A,fho),e(A,nh),e(nh,Fge),e(Fge,gho),e(nh,hho),e(nh,Rq),e(Rq,uho),e(nh,pho),e(A,_ho),e(A,sh),e(sh,Tge),e(Tge,bho),e(sh,vho),e(sh,Pq),e(Pq,Fho),e(sh,Tho),e(A,Mho),e(A,lh),e(lh,Mge),e(Mge,Eho),e(lh,Cho),e(lh,Bq),e(Bq,who),e(lh,Aho),e(A,Lho),e(A,ih),e(ih,Ege),e(Ege,yho),e(ih,xho),e(ih,Iq),e(Iq,$ho),e(ih,kho),e(A,Sho),e(A,dh),e(dh,Cge),e(Cge,Rho),e(dh,Pho),e(dh,Nq),e(Nq,Bho),e(dh,Iho),e(A,Nho),e(A,mh),e(mh,wge),e(wge,qho),e(mh,jho),e(mh,qq),e(qq,Dho),e(mh,Gho),e(A,Oho),e(A,ch),e(ch,Age),e(Age,Vho),e(ch,Xho),e(ch,jq),e(jq,zho),e(ch,Qho),e(A,Who),e(A,fh),e(fh,Lge),e(Lge,Uho),e(fh,Hho),e(fh,Dq),e(Dq,Jho),e(fh,Yho),e(A,Zho),e(A,gh),e(gh,yge),e(yge,Kho),e(gh,euo),e(gh,Gq),e(Gq,ouo),e(gh,ruo),e(A,tuo),e(A,hh),e(hh,xge),e(xge,auo),e(hh,nuo),e(hh,Oq),e(Oq,suo),e(hh,luo),e(A,iuo),e(A,uh),e(uh,$ge),e($ge,duo),e(uh,muo),e(uh,Vq),e(Vq,cuo),e(uh,fuo),e(A,guo),e(A,ph),e(ph,kge),e(kge,huo),e(ph,uuo),e(ph,Xq),e(Xq,puo),e(ph,_uo),e(A,buo),e(A,_h),e(_h,Sge),e(Sge,vuo),e(_h,Fuo),e(_h,zq),e(zq,Tuo),e(_h,Muo),e(A,Euo),e(A,bh),e(bh,Rge),e(Rge,Cuo),e(bh,wuo),e(bh,Qq),e(Qq,Auo),e(bh,Luo),e(A,yuo),e(A,vh),e(vh,Pge),e(Pge,xuo),e(vh,$uo),e(vh,Wq),e(Wq,kuo),e(vh,Suo),e(A,Ruo),e(A,Fh),e(Fh,Bge),e(Bge,Puo),e(Fh,Buo),e(Fh,Uq),e(Uq,Iuo),e(Fh,Nuo),e(A,quo),e(A,Th),e(Th,Ige),e(Ige,juo),e(Th,Duo),e(Th,Hq),e(Hq,Guo),e(Th,Ouo),e(A,Vuo),e(A,Mh),e(Mh,Nge),e(Nge,Xuo),e(Mh,zuo),e(Mh,Jq),e(Jq,Quo),e(Mh,Wuo),e(A,Uuo),e(A,Eh),e(Eh,qge),e(qge,Huo),e(Eh,Juo),e(Eh,Yq),e(Yq,Yuo),e(Eh,Zuo),e(A,Kuo),e(A,Ch),e(Ch,jge),e(jge,epo),e(Ch,opo),e(Ch,Zq),e(Zq,rpo),e(Ch,tpo),e(A,apo),e(A,wh),e(wh,Dge),e(Dge,npo),e(wh,spo),e(wh,Kq),e(Kq,lpo),e(wh,ipo),e(A,dpo),e(A,Ah),e(Ah,Gge),e(Gge,mpo),e(Ah,cpo),e(Ah,ej),e(ej,fpo),e(Ah,gpo),e(A,hpo),e(A,Lh),e(Lh,Oge),e(Oge,upo),e(Lh,ppo),e(Lh,oj),e(oj,_po),e(Lh,bpo),e(A,vpo),e(A,yh),e(yh,Vge),e(Vge,Fpo),e(yh,Tpo),e(yh,rj),e(rj,Mpo),e(yh,Epo),e(A,Cpo),e(A,xh),e(xh,Xge),e(Xge,wpo),e(xh,Apo),e(xh,tj),e(tj,Lpo),e(xh,ypo),e(A,xpo),e(A,$h),e($h,zge),e(zge,$po),e($h,kpo),e($h,aj),e(aj,Spo),e($h,Rpo),e(A,Ppo),e(A,kh),e(kh,Qge),e(Qge,Bpo),e(kh,Ipo),e(kh,nj),e(nj,Npo),e(kh,qpo),e(A,jpo),e(A,Sh),e(Sh,Wge),e(Wge,Dpo),e(Sh,Gpo),e(Sh,sj),e(sj,Opo),e(Sh,Vpo),e(A,Xpo),e(A,Rh),e(Rh,Uge),e(Uge,zpo),e(Rh,Qpo),e(Rh,lj),e(lj,Wpo),e(Rh,Upo),e(A,Hpo),e(A,Ph),e(Ph,Hge),e(Hge,Jpo),e(Ph,Ypo),e(Ph,ij),e(ij,Zpo),e(Ph,Kpo),e(A,e_o),e(A,Bh),e(Bh,Jge),e(Jge,o_o),e(Bh,r_o),e(Bh,dj),e(dj,t_o),e(Bh,a_o),e(A,n_o),e(A,Ih),e(Ih,Yge),e(Yge,s_o),e(Ih,l_o),e(Ih,mj),e(mj,i_o),e(Ih,d_o),e(A,m_o),e(A,Nh),e(Nh,Zge),e(Zge,c_o),e(Nh,f_o),e(Nh,cj),e(cj,g_o),e(Nh,h_o),e(A,u_o),e(A,qh),e(qh,Kge),e(Kge,p_o),e(qh,__o),e(qh,fj),e(fj,b_o),e(qh,v_o),e(A,F_o),e(A,jh),e(jh,ehe),e(ehe,T_o),e(jh,M_o),e(jh,gj),e(gj,E_o),e(jh,C_o),e(A,w_o),e(A,Dh),e(Dh,ohe),e(ohe,A_o),e(Dh,L_o),e(Dh,hj),e(hj,y_o),e(Dh,x_o),e(A,$_o),e(A,Gh),e(Gh,rhe),e(rhe,k_o),e(Gh,S_o),e(Gh,uj),e(uj,R_o),e(Gh,P_o),e(A,B_o),e(A,Oh),e(Oh,the),e(the,I_o),e(Oh,N_o),e(Oh,pj),e(pj,q_o),e(Oh,j_o),e(A,D_o),e(A,Vh),e(Vh,ahe),e(ahe,G_o),e(Vh,O_o),e(Vh,_j),e(_j,V_o),e(Vh,X_o),e(A,z_o),e(A,Xh),e(Xh,nhe),e(nhe,Q_o),e(Xh,W_o),e(Xh,bj),e(bj,U_o),e(Xh,H_o),e(A,J_o),e(A,zh),e(zh,she),e(she,Y_o),e(zh,Z_o),e(zh,vj),e(vj,K_o),e(zh,e1o),e(A,o1o),e(A,Qh),e(Qh,lhe),e(lhe,r1o),e(Qh,t1o),e(Qh,Fj),e(Fj,a1o),e(Qh,n1o),e(A,s1o),e(A,Wh),e(Wh,ihe),e(ihe,l1o),e(Wh,i1o),e(Wh,Tj),e(Tj,d1o),e(Wh,m1o),e(A,c1o),e(A,Uh),e(Uh,dhe),e(dhe,f1o),e(Uh,g1o),e(Uh,Mj),e(Mj,h1o),e(Uh,u1o),e(A,p1o),e(A,Hh),e(Hh,mhe),e(mhe,_1o),e(Hh,b1o),e(Hh,Ej),e(Ej,v1o),e(Hh,F1o),e(A,T1o),e(A,Jh),e(Jh,che),e(che,M1o),e(Jh,E1o),e(Jh,Cj),e(Cj,C1o),e(Jh,w1o),e(A,A1o),e(A,Yh),e(Yh,fhe),e(fhe,L1o),e(Yh,y1o),e(Yh,wj),e(wj,x1o),e(Yh,$1o),e(A,k1o),e(A,Zh),e(Zh,ghe),e(ghe,S1o),e(Zh,R1o),e(Zh,Aj),e(Aj,P1o),e(Zh,B1o),e(A,I1o),e(A,Kh),e(Kh,hhe),e(hhe,N1o),e(Kh,q1o),e(Kh,Lj),e(Lj,j1o),e(Kh,D1o),e(A,G1o),e(A,eu),e(eu,uhe),e(uhe,O1o),e(eu,V1o),e(eu,yj),e(yj,X1o),e(eu,z1o),e(A,Q1o),e(A,ou),e(ou,phe),e(phe,W1o),e(ou,U1o),e(ou,xj),e(xj,H1o),e(ou,J1o),e(A,Y1o),e(A,ru),e(ru,_he),e(_he,Z1o),e(ru,K1o),e(ru,$j),e($j,e2o),e(ru,o2o),e(A,r2o),e(A,tu),e(tu,bhe),e(bhe,t2o),e(tu,a2o),e(tu,kj),e(kj,n2o),e(tu,s2o),e(A,l2o),e(A,au),e(au,vhe),e(vhe,i2o),e(au,d2o),e(au,Sj),e(Sj,m2o),e(au,c2o),e(A,f2o),e(A,nu),e(nu,Fhe),e(Fhe,g2o),e(nu,h2o),e(nu,Rj),e(Rj,u2o),e(nu,p2o),e(A,_2o),e(A,su),e(su,The),e(The,b2o),e(su,v2o),e(su,Pj),e(Pj,F2o),e(su,T2o),e(A,M2o),e(A,lu),e(lu,Mhe),e(Mhe,E2o),e(lu,C2o),e(lu,Bj),e(Bj,w2o),e(lu,A2o),e(A,L2o),e(A,iu),e(iu,Ehe),e(Ehe,y2o),e(iu,x2o),e(iu,Ij),e(Ij,$2o),e(iu,k2o),e(A,S2o),e(A,du),e(du,Che),e(Che,R2o),e(du,P2o),e(du,Nj),e(Nj,B2o),e(du,I2o),e(A,N2o),e(A,mu),e(mu,whe),e(whe,q2o),e(mu,j2o),e(mu,qj),e(qj,D2o),e(mu,G2o),e(A,O2o),e(A,cu),e(cu,Ahe),e(Ahe,V2o),e(cu,X2o),e(cu,jj),e(jj,z2o),e(cu,Q2o),e(A,W2o),e(A,fu),e(fu,Lhe),e(Lhe,U2o),e(fu,H2o),e(fu,Dj),e(Dj,J2o),e(fu,Y2o),e(A,Z2o),e(A,gu),e(gu,yhe),e(yhe,K2o),e(gu,ebo),e(gu,Gj),e(Gj,obo),e(gu,rbo),e(A,tbo),e(A,hu),e(hu,xhe),e(xhe,abo),e(hu,nbo),e(hu,Oj),e(Oj,sbo),e(hu,lbo),e(A,ibo),e(A,uu),e(uu,$he),e($he,dbo),e(uu,mbo),e(uu,Vj),e(Vj,cbo),e(uu,fbo),e(A,gbo),e(A,pu),e(pu,khe),e(khe,hbo),e(pu,ubo),e(pu,Xj),e(Xj,pbo),e(pu,_bo),e(A,bbo),e(A,_u),e(_u,She),e(She,vbo),e(_u,Fbo),e(_u,zj),e(zj,Tbo),e(_u,Mbo),e(A,Ebo),e(A,bu),e(bu,Rhe),e(Rhe,Cbo),e(bu,wbo),e(bu,Qj),e(Qj,Abo),e(bu,Lbo),e(A,ybo),e(A,vu),e(vu,Phe),e(Phe,xbo),e(vu,$bo),e(vu,Wj),e(Wj,kbo),e(vu,Sbo),e(A,Rbo),e(A,Fu),e(Fu,Bhe),e(Bhe,Pbo),e(Fu,Bbo),e(Fu,Uj),e(Uj,Ibo),e(Fu,Nbo),e(A,qbo),e(A,Tu),e(Tu,Ihe),e(Ihe,jbo),e(Tu,Dbo),e(Tu,Hj),e(Hj,Gbo),e(Tu,Obo),e(qr,Vbo),M(Mu,qr,null),e(So,Xbo),e(So,Eu),M(f$,Eu,null),e(Eu,zbo),e(Eu,Nhe),e(Nhe,Qbo),b(c,uto,_),b(c,Ad,_),e(Ad,Cu),e(Cu,qhe),M(g$,qhe,null),e(Ad,Wbo),e(Ad,jhe),e(jhe,Ubo),b(c,pto,_),b(c,Ro,_),M(h$,Ro,null),e(Ro,Hbo),e(Ro,u$),e(u$,Jbo),e(u$,Jj),e(Jj,Ybo),e(u$,Zbo),e(Ro,Kbo),e(Ro,p$),e(p$,evo),e(p$,Dhe),e(Dhe,ovo),e(p$,rvo),e(Ro,tvo),e(Ro,jr),M(_$,jr,null),e(jr,avo),e(jr,Ghe),e(Ghe,nvo),e(jr,svo),e(jr,rn),e(rn,lvo),e(rn,Ohe),e(Ohe,ivo),e(rn,dvo),e(rn,Vhe),e(Vhe,mvo),e(rn,cvo),e(rn,Xhe),e(Xhe,fvo),e(rn,gvo),e(jr,hvo),e(jr,k),e(k,us),e(us,zhe),e(zhe,uvo),e(us,pvo),e(us,Yj),e(Yj,_vo),e(us,bvo),e(us,Zj),e(Zj,vvo),e(us,Fvo),e(k,Tvo),e(k,ps),e(ps,Qhe),e(Qhe,Mvo),e(ps,Evo),e(ps,Kj),e(Kj,Cvo),e(ps,wvo),e(ps,eD),e(eD,Avo),e(ps,Lvo),e(k,yvo),e(k,_s),e(_s,Whe),e(Whe,xvo),e(_s,$vo),e(_s,oD),e(oD,kvo),e(_s,Svo),e(_s,rD),e(rD,Rvo),e(_s,Pvo),e(k,Bvo),e(k,wu),e(wu,Uhe),e(Uhe,Ivo),e(wu,Nvo),e(wu,tD),e(tD,qvo),e(wu,jvo),e(k,Dvo),e(k,bs),e(bs,Hhe),e(Hhe,Gvo),e(bs,Ovo),e(bs,aD),e(aD,Vvo),e(bs,Xvo),e(bs,nD),e(nD,zvo),e(bs,Qvo),e(k,Wvo),e(k,Au),e(Au,Jhe),e(Jhe,Uvo),e(Au,Hvo),e(Au,sD),e(sD,Jvo),e(Au,Yvo),e(k,Zvo),e(k,Lu),e(Lu,Yhe),e(Yhe,Kvo),e(Lu,eFo),e(Lu,lD),e(lD,oFo),e(Lu,rFo),e(k,tFo),e(k,yu),e(yu,Zhe),e(Zhe,aFo),e(yu,nFo),e(yu,iD),e(iD,sFo),e(yu,lFo),e(k,iFo),e(k,vs),e(vs,Khe),e(Khe,dFo),e(vs,mFo),e(vs,dD),e(dD,cFo),e(vs,fFo),e(vs,mD),e(mD,gFo),e(vs,hFo),e(k,uFo),e(k,Fs),e(Fs,eue),e(eue,pFo),e(Fs,_Fo),e(Fs,cD),e(cD,bFo),e(Fs,vFo),e(Fs,fD),e(fD,FFo),e(Fs,TFo),e(k,MFo),e(k,Ts),e(Ts,oue),e(oue,EFo),e(Ts,CFo),e(Ts,gD),e(gD,wFo),e(Ts,AFo),e(Ts,hD),e(hD,LFo),e(Ts,yFo),e(k,xFo),e(k,xu),e(xu,rue),e(rue,$Fo),e(xu,kFo),e(xu,uD),e(uD,SFo),e(xu,RFo),e(k,PFo),e(k,$u),e($u,tue),e(tue,BFo),e($u,IFo),e($u,pD),e(pD,NFo),e($u,qFo),e(k,jFo),e(k,ku),e(ku,aue),e(aue,DFo),e(ku,GFo),e(ku,_D),e(_D,OFo),e(ku,VFo),e(k,XFo),e(k,Ms),e(Ms,nue),e(nue,zFo),e(Ms,QFo),e(Ms,bD),e(bD,WFo),e(Ms,UFo),e(Ms,vD),e(vD,HFo),e(Ms,JFo),e(k,YFo),e(k,Su),e(Su,sue),e(sue,ZFo),e(Su,KFo),e(Su,FD),e(FD,eTo),e(Su,oTo),e(k,rTo),e(k,Es),e(Es,lue),e(lue,tTo),e(Es,aTo),e(Es,TD),e(TD,nTo),e(Es,sTo),e(Es,MD),e(MD,lTo),e(Es,iTo),e(k,dTo),e(k,Cs),e(Cs,iue),e(iue,mTo),e(Cs,cTo),e(Cs,ED),e(ED,fTo),e(Cs,gTo),e(Cs,CD),e(CD,hTo),e(Cs,uTo),e(k,pTo),e(k,ws),e(ws,due),e(due,_To),e(ws,bTo),e(ws,wD),e(wD,vTo),e(ws,FTo),e(ws,AD),e(AD,TTo),e(ws,MTo),e(k,ETo),e(k,As),e(As,mue),e(mue,CTo),e(As,wTo),e(As,LD),e(LD,ATo),e(As,LTo),e(As,yD),e(yD,yTo),e(As,xTo),e(k,$To),e(k,Ru),e(Ru,cue),e(cue,kTo),e(Ru,STo),e(Ru,xD),e(xD,RTo),e(Ru,PTo),e(k,BTo),e(k,Ls),e(Ls,fue),e(fue,ITo),e(Ls,NTo),e(Ls,$D),e($D,qTo),e(Ls,jTo),e(Ls,kD),e(kD,DTo),e(Ls,GTo),e(k,OTo),e(k,ys),e(ys,gue),e(gue,VTo),e(ys,XTo),e(ys,SD),e(SD,zTo),e(ys,QTo),e(ys,RD),e(RD,WTo),e(ys,UTo),e(k,HTo),e(k,xs),e(xs,hue),e(hue,JTo),e(xs,YTo),e(xs,PD),e(PD,ZTo),e(xs,KTo),e(xs,BD),e(BD,eMo),e(xs,oMo),e(k,rMo),e(k,$s),e($s,uue),e(uue,tMo),e($s,aMo),e($s,ID),e(ID,nMo),e($s,sMo),e($s,ND),e(ND,lMo),e($s,iMo),e(k,dMo),e(k,ks),e(ks,pue),e(pue,mMo),e(ks,cMo),e(ks,qD),e(qD,fMo),e(ks,gMo),e(ks,jD),e(jD,hMo),e(ks,uMo),e(k,pMo),e(k,Ss),e(Ss,_ue),e(_ue,_Mo),e(Ss,bMo),e(Ss,DD),e(DD,vMo),e(Ss,FMo),e(Ss,GD),e(GD,TMo),e(Ss,MMo),e(k,EMo),e(k,Rs),e(Rs,bue),e(bue,CMo),e(Rs,wMo),e(Rs,OD),e(OD,AMo),e(Rs,LMo),e(Rs,VD),e(VD,yMo),e(Rs,xMo),e(k,$Mo),e(k,Pu),e(Pu,vue),e(vue,kMo),e(Pu,SMo),e(Pu,XD),e(XD,RMo),e(Pu,PMo),e(k,BMo),e(k,Bu),e(Bu,Fue),e(Fue,IMo),e(Bu,NMo),e(Bu,zD),e(zD,qMo),e(Bu,jMo),e(k,DMo),e(k,Ps),e(Ps,Tue),e(Tue,GMo),e(Ps,OMo),e(Ps,QD),e(QD,VMo),e(Ps,XMo),e(Ps,WD),e(WD,zMo),e(Ps,QMo),e(k,WMo),e(k,Iu),e(Iu,Mue),e(Mue,UMo),e(Iu,HMo),e(Iu,UD),e(UD,JMo),e(Iu,YMo),e(k,ZMo),e(k,Bs),e(Bs,Eue),e(Eue,KMo),e(Bs,eEo),e(Bs,HD),e(HD,oEo),e(Bs,rEo),e(Bs,JD),e(JD,tEo),e(Bs,aEo),e(k,nEo),e(k,Is),e(Is,Cue),e(Cue,sEo),e(Is,lEo),e(Is,YD),e(YD,iEo),e(Is,dEo),e(Is,ZD),e(ZD,mEo),e(Is,cEo),e(k,fEo),e(k,Ns),e(Ns,wue),e(wue,gEo),e(Ns,hEo),e(Ns,KD),e(KD,uEo),e(Ns,pEo),e(Ns,eG),e(eG,_Eo),e(Ns,bEo),e(k,vEo),e(k,Nu),e(Nu,Aue),e(Aue,FEo),e(Nu,TEo),e(Nu,oG),e(oG,MEo),e(Nu,EEo),e(k,CEo),e(k,qu),e(qu,Lue),e(Lue,wEo),e(qu,AEo),e(qu,rG),e(rG,LEo),e(qu,yEo),e(k,xEo),e(k,qs),e(qs,yue),e(yue,$Eo),e(qs,kEo),e(qs,tG),e(tG,SEo),e(qs,REo),e(qs,aG),e(aG,PEo),e(qs,BEo),e(k,IEo),e(k,js),e(js,xue),e(xue,NEo),e(js,qEo),e(js,nG),e(nG,jEo),e(js,DEo),e(js,sG),e(sG,GEo),e(js,OEo),e(k,VEo),e(k,Ds),e(Ds,$ue),e($ue,XEo),e(Ds,zEo),e(Ds,lG),e(lG,QEo),e(Ds,WEo),e(Ds,iG),e(iG,UEo),e(Ds,HEo),e(k,JEo),e(k,ju),e(ju,kue),e(kue,YEo),e(ju,ZEo),e(ju,dG),e(dG,KEo),e(ju,e4o),e(k,o4o),e(k,Gs),e(Gs,Sue),e(Sue,r4o),e(Gs,t4o),e(Gs,mG),e(mG,a4o),e(Gs,n4o),e(Gs,cG),e(cG,s4o),e(Gs,l4o),e(k,i4o),e(k,Os),e(Os,Rue),e(Rue,d4o),e(Os,m4o),e(Os,fG),e(fG,c4o),e(Os,f4o),e(Os,gG),e(gG,g4o),e(Os,h4o),e(k,u4o),e(k,Vs),e(Vs,Pue),e(Pue,p4o),e(Vs,_4o),e(Vs,hG),e(hG,b4o),e(Vs,v4o),e(Vs,uG),e(uG,F4o),e(Vs,T4o),e(k,M4o),e(k,Xs),e(Xs,Bue),e(Bue,E4o),e(Xs,C4o),e(Xs,pG),e(pG,w4o),e(Xs,A4o),e(Xs,_G),e(_G,L4o),e(Xs,y4o),e(k,x4o),e(k,zs),e(zs,Iue),e(Iue,$4o),e(zs,k4o),e(zs,bG),e(bG,S4o),e(zs,R4o),e(zs,vG),e(vG,P4o),e(zs,B4o),e(k,I4o),e(k,Qs),e(Qs,Nue),e(Nue,N4o),e(Qs,q4o),e(Qs,FG),e(FG,j4o),e(Qs,D4o),e(Qs,TG),e(TG,G4o),e(Qs,O4o),e(k,V4o),e(k,Ws),e(Ws,que),e(que,X4o),e(Ws,z4o),e(Ws,MG),e(MG,Q4o),e(Ws,W4o),e(Ws,EG),e(EG,U4o),e(Ws,H4o),e(k,J4o),e(k,Us),e(Us,jue),e(jue,Y4o),e(Us,Z4o),e(Us,CG),e(CG,K4o),e(Us,eCo),e(Us,wG),e(wG,oCo),e(Us,rCo),e(k,tCo),e(k,Hs),e(Hs,Due),e(Due,aCo),e(Hs,nCo),e(Hs,AG),e(AG,sCo),e(Hs,lCo),e(Hs,LG),e(LG,iCo),e(Hs,dCo),e(k,mCo),e(k,Du),e(Du,Gue),e(Gue,cCo),e(Du,fCo),e(Du,yG),e(yG,gCo),e(Du,hCo),e(k,uCo),e(k,Js),e(Js,Oue),e(Oue,pCo),e(Js,_Co),e(Js,xG),e(xG,bCo),e(Js,vCo),e(Js,$G),e($G,FCo),e(Js,TCo),e(k,MCo),e(k,Gu),e(Gu,Vue),e(Vue,ECo),e(Gu,CCo),e(Gu,kG),e(kG,wCo),e(Gu,ACo),e(k,LCo),e(k,Ou),e(Ou,Xue),e(Xue,yCo),e(Ou,xCo),e(Ou,SG),e(SG,$Co),e(Ou,kCo),e(k,SCo),e(k,Ys),e(Ys,zue),e(zue,RCo),e(Ys,PCo),e(Ys,RG),e(RG,BCo),e(Ys,ICo),e(Ys,PG),e(PG,NCo),e(Ys,qCo),e(k,jCo),e(k,Zs),e(Zs,Que),e(Que,DCo),e(Zs,GCo),e(Zs,BG),e(BG,OCo),e(Zs,VCo),e(Zs,IG),e(IG,XCo),e(Zs,zCo),e(k,QCo),e(k,Ks),e(Ks,Wue),e(Wue,WCo),e(Ks,UCo),e(Ks,NG),e(NG,HCo),e(Ks,JCo),e(Ks,qG),e(qG,YCo),e(Ks,ZCo),e(k,KCo),e(k,Vu),e(Vu,Uue),e(Uue,e3o),e(Vu,o3o),e(Vu,jG),e(jG,r3o),e(Vu,t3o),e(k,a3o),e(k,el),e(el,Hue),e(Hue,n3o),e(el,s3o),e(el,DG),e(DG,l3o),e(el,i3o),e(el,GG),e(GG,d3o),e(el,m3o),e(k,c3o),e(k,ol),e(ol,Jue),e(Jue,f3o),e(ol,g3o),e(ol,OG),e(OG,h3o),e(ol,u3o),e(ol,VG),e(VG,p3o),e(ol,_3o),e(k,b3o),e(k,rl),e(rl,Yue),e(Yue,v3o),e(rl,F3o),e(rl,XG),e(XG,T3o),e(rl,M3o),e(rl,zG),e(zG,E3o),e(rl,C3o),e(k,w3o),e(k,tl),e(tl,Zue),e(Zue,A3o),e(tl,L3o),e(tl,QG),e(QG,y3o),e(tl,x3o),e(tl,WG),e(WG,$3o),e(tl,k3o),e(k,S3o),e(k,al),e(al,Kue),e(Kue,R3o),e(al,P3o),e(al,UG),e(UG,B3o),e(al,I3o),e(al,HG),e(HG,N3o),e(al,q3o),e(k,j3o),e(k,nl),e(nl,epe),e(epe,D3o),e(nl,G3o),e(nl,JG),e(JG,O3o),e(nl,V3o),e(nl,YG),e(YG,X3o),e(nl,z3o),e(k,Q3o),e(k,sl),e(sl,ope),e(ope,W3o),e(sl,U3o),e(sl,ZG),e(ZG,H3o),e(sl,J3o),e(sl,KG),e(KG,Y3o),e(sl,Z3o),e(k,K3o),e(k,ll),e(ll,rpe),e(rpe,e5o),e(ll,o5o),e(ll,eO),e(eO,r5o),e(ll,t5o),e(ll,oO),e(oO,a5o),e(ll,n5o),e(k,s5o),e(k,Xu),e(Xu,tpe),e(tpe,l5o),e(Xu,i5o),e(Xu,rO),e(rO,d5o),e(Xu,m5o),e(k,c5o),e(k,il),e(il,ape),e(ape,f5o),e(il,g5o),e(il,tO),e(tO,h5o),e(il,u5o),e(il,aO),e(aO,p5o),e(il,_5o),e(k,b5o),e(k,dl),e(dl,npe),e(npe,v5o),e(dl,F5o),e(dl,nO),e(nO,T5o),e(dl,M5o),e(dl,sO),e(sO,E5o),e(dl,C5o),e(k,w5o),e(k,zu),e(zu,spe),e(spe,A5o),e(zu,L5o),e(zu,lO),e(lO,y5o),e(zu,x5o),e(k,$5o),e(k,Qu),e(Qu,lpe),e(lpe,k5o),e(Qu,S5o),e(Qu,iO),e(iO,R5o),e(Qu,P5o),e(k,B5o),e(k,Wu),e(Wu,ipe),e(ipe,I5o),e(Wu,N5o),e(Wu,dO),e(dO,q5o),e(Wu,j5o),e(k,D5o),e(k,Uu),e(Uu,dpe),e(dpe,G5o),e(Uu,O5o),e(Uu,mO),e(mO,V5o),e(Uu,X5o),e(k,z5o),e(k,ml),e(ml,mpe),e(mpe,Q5o),e(ml,W5o),e(ml,cO),e(cO,U5o),e(ml,H5o),e(ml,fO),e(fO,J5o),e(ml,Y5o),e(k,Z5o),e(k,Hu),e(Hu,cpe),e(cpe,K5o),e(Hu,e0o),e(Hu,gO),e(gO,o0o),e(Hu,r0o),e(k,t0o),e(k,cl),e(cl,fpe),e(fpe,a0o),e(cl,n0o),e(cl,hO),e(hO,s0o),e(cl,l0o),e(cl,uO),e(uO,i0o),e(cl,d0o),e(k,m0o),e(k,fl),e(fl,gpe),e(gpe,c0o),e(fl,f0o),e(fl,pO),e(pO,g0o),e(fl,h0o),e(fl,_O),e(_O,u0o),e(fl,p0o),e(k,_0o),e(k,gl),e(gl,hpe),e(hpe,b0o),e(gl,v0o),e(gl,bO),e(bO,F0o),e(gl,T0o),e(gl,vO),e(vO,M0o),e(gl,E0o),e(k,C0o),e(k,hl),e(hl,upe),e(upe,w0o),e(hl,A0o),e(hl,FO),e(FO,L0o),e(hl,y0o),e(hl,TO),e(TO,x0o),e(hl,$0o),e(k,k0o),e(k,ul),e(ul,ppe),e(ppe,S0o),e(ul,R0o),e(ul,MO),e(MO,P0o),e(ul,B0o),e(ul,EO),e(EO,I0o),e(ul,N0o),e(k,q0o),e(k,pl),e(pl,_pe),e(_pe,j0o),e(pl,D0o),e(pl,CO),e(CO,G0o),e(pl,O0o),e(pl,wO),e(wO,V0o),e(pl,X0o),e(k,z0o),e(k,Ju),e(Ju,bpe),e(bpe,Q0o),e(Ju,W0o),e(Ju,AO),e(AO,U0o),e(Ju,H0o),e(k,J0o),e(k,Yu),e(Yu,vpe),e(vpe,Y0o),e(Yu,Z0o),e(Yu,LO),e(LO,K0o),e(Yu,ewo),e(k,owo),e(k,_l),e(_l,Fpe),e(Fpe,rwo),e(_l,two),e(_l,yO),e(yO,awo),e(_l,nwo),e(_l,xO),e(xO,swo),e(_l,lwo),e(k,iwo),e(k,bl),e(bl,Tpe),e(Tpe,dwo),e(bl,mwo),e(bl,$O),e($O,cwo),e(bl,fwo),e(bl,kO),e(kO,gwo),e(bl,hwo),e(k,uwo),e(k,vl),e(vl,Mpe),e(Mpe,pwo),e(vl,_wo),e(vl,SO),e(SO,bwo),e(vl,vwo),e(vl,RO),e(RO,Fwo),e(vl,Two),e(k,Mwo),e(k,Zu),e(Zu,Epe),e(Epe,Ewo),e(Zu,Cwo),e(Zu,PO),e(PO,wwo),e(Zu,Awo),e(k,Lwo),e(k,Ku),e(Ku,Cpe),e(Cpe,ywo),e(Ku,xwo),e(Ku,BO),e(BO,$wo),e(Ku,kwo),e(k,Swo),e(k,ep),e(ep,wpe),e(wpe,Rwo),e(ep,Pwo),e(ep,IO),e(IO,Bwo),e(ep,Iwo),e(k,Nwo),e(k,Fl),e(Fl,Ape),e(Ape,qwo),e(Fl,jwo),e(Fl,NO),e(NO,Dwo),e(Fl,Gwo),e(Fl,qO),e(qO,Owo),e(Fl,Vwo),e(k,Xwo),e(k,Tl),e(Tl,Lpe),e(Lpe,zwo),e(Tl,Qwo),e(Tl,jO),e(jO,Wwo),e(Tl,Uwo),e(Tl,DO),e(DO,Hwo),e(Tl,Jwo),e(k,Ywo),e(k,op),e(op,ype),e(ype,Zwo),e(op,Kwo),e(op,GO),e(GO,eAo),e(op,oAo),e(k,rAo),e(k,rp),e(rp,xpe),e(xpe,tAo),e(rp,aAo),e(rp,OO),e(OO,nAo),e(rp,sAo),e(k,lAo),e(k,tp),e(tp,$pe),e($pe,iAo),e(tp,dAo),e(tp,VO),e(VO,mAo),e(tp,cAo),e(k,fAo),e(k,ap),e(ap,kpe),e(kpe,gAo),e(ap,hAo),e(ap,XO),e(XO,uAo),e(ap,pAo),e(k,_Ao),e(k,Ml),e(Ml,Spe),e(Spe,bAo),e(Ml,vAo),e(Ml,zO),e(zO,FAo),e(Ml,TAo),e(Ml,QO),e(QO,MAo),e(Ml,EAo),e(k,CAo),e(k,El),e(El,Rpe),e(Rpe,wAo),e(El,AAo),e(El,WO),e(WO,LAo),e(El,yAo),e(El,UO),e(UO,xAo),e(El,$Ao),e(k,kAo),e(k,np),e(np,Ppe),e(Ppe,SAo),e(np,RAo),e(np,HO),e(HO,PAo),e(np,BAo),e(k,IAo),e(k,sp),e(sp,Bpe),e(Bpe,NAo),e(sp,qAo),e(sp,JO),e(JO,jAo),e(sp,DAo),e(k,GAo),e(k,Cl),e(Cl,Ipe),e(Ipe,OAo),e(Cl,VAo),e(Cl,YO),e(YO,XAo),e(Cl,zAo),e(Cl,ZO),e(ZO,QAo),e(Cl,WAo),e(k,UAo),e(k,wl),e(wl,Npe),e(Npe,HAo),e(wl,JAo),e(wl,KO),e(KO,YAo),e(wl,ZAo),e(wl,eV),e(eV,KAo),e(wl,e6o),e(k,o6o),e(k,Al),e(Al,qpe),e(qpe,r6o),e(Al,t6o),e(Al,oV),e(oV,a6o),e(Al,n6o),e(Al,rV),e(rV,s6o),e(Al,l6o),e(k,i6o),e(k,Ll),e(Ll,jpe),e(jpe,d6o),e(Ll,m6o),e(Ll,tV),e(tV,c6o),e(Ll,f6o),e(Ll,aV),e(aV,g6o),e(Ll,h6o),e(jr,u6o),M(lp,jr,null),e(Ro,p6o),e(Ro,ip),M(b$,ip,null),e(ip,_6o),e(ip,Dpe),e(Dpe,b6o),b(c,_to,_),b(c,Ld,_),e(Ld,dp),e(dp,Gpe),M(v$,Gpe,null),e(Ld,v6o),e(Ld,Ope),e(Ope,F6o),b(c,bto,_),b(c,Po,_),M(F$,Po,null),e(Po,T6o),e(Po,T$),e(T$,M6o),e(T$,nV),e(nV,E6o),e(T$,C6o),e(Po,w6o),e(Po,M$),e(M$,A6o),e(M$,Vpe),e(Vpe,L6o),e(M$,y6o),e(Po,x6o),e(Po,Ye),M(E$,Ye,null),e(Ye,$6o),e(Ye,Xpe),e(Xpe,k6o),e(Ye,S6o),e(Ye,tn),e(tn,R6o),e(tn,zpe),e(zpe,P6o),e(tn,B6o),e(tn,Qpe),e(Qpe,I6o),e(tn,N6o),e(tn,Wpe),e(Wpe,q6o),e(tn,j6o),e(Ye,D6o),e(Ye,z),e(z,mp),e(mp,Upe),e(Upe,G6o),e(mp,O6o),e(mp,sV),e(sV,V6o),e(mp,X6o),e(z,z6o),e(z,cp),e(cp,Hpe),e(Hpe,Q6o),e(cp,W6o),e(cp,lV),e(lV,U6o),e(cp,H6o),e(z,J6o),e(z,fp),e(fp,Jpe),e(Jpe,Y6o),e(fp,Z6o),e(fp,iV),e(iV,K6o),e(fp,e7o),e(z,o7o),e(z,gp),e(gp,Ype),e(Ype,r7o),e(gp,t7o),e(gp,dV),e(dV,a7o),e(gp,n7o),e(z,s7o),e(z,hp),e(hp,Zpe),e(Zpe,l7o),e(hp,i7o),e(hp,mV),e(mV,d7o),e(hp,m7o),e(z,c7o),e(z,up),e(up,Kpe),e(Kpe,f7o),e(up,g7o),e(up,cV),e(cV,h7o),e(up,u7o),e(z,p7o),e(z,pp),e(pp,e_e),e(e_e,_7o),e(pp,b7o),e(pp,fV),e(fV,v7o),e(pp,F7o),e(z,T7o),e(z,_p),e(_p,o_e),e(o_e,M7o),e(_p,E7o),e(_p,gV),e(gV,C7o),e(_p,w7o),e(z,A7o),e(z,bp),e(bp,r_e),e(r_e,L7o),e(bp,y7o),e(bp,hV),e(hV,x7o),e(bp,$7o),e(z,k7o),e(z,vp),e(vp,t_e),e(t_e,S7o),e(vp,R7o),e(vp,uV),e(uV,P7o),e(vp,B7o),e(z,I7o),e(z,Fp),e(Fp,a_e),e(a_e,N7o),e(Fp,q7o),e(Fp,pV),e(pV,j7o),e(Fp,D7o),e(z,G7o),e(z,Tp),e(Tp,n_e),e(n_e,O7o),e(Tp,V7o),e(Tp,_V),e(_V,X7o),e(Tp,z7o),e(z,Q7o),e(z,Mp),e(Mp,s_e),e(s_e,W7o),e(Mp,U7o),e(Mp,bV),e(bV,H7o),e(Mp,J7o),e(z,Y7o),e(z,Ep),e(Ep,l_e),e(l_e,Z7o),e(Ep,K7o),e(Ep,vV),e(vV,e8o),e(Ep,o8o),e(z,r8o),e(z,Cp),e(Cp,i_e),e(i_e,t8o),e(Cp,a8o),e(Cp,FV),e(FV,n8o),e(Cp,s8o),e(z,l8o),e(z,wp),e(wp,d_e),e(d_e,i8o),e(wp,d8o),e(wp,TV),e(TV,m8o),e(wp,c8o),e(z,f8o),e(z,Ap),e(Ap,m_e),e(m_e,g8o),e(Ap,h8o),e(Ap,MV),e(MV,u8o),e(Ap,p8o),e(z,_8o),e(z,Lp),e(Lp,c_e),e(c_e,b8o),e(Lp,v8o),e(Lp,EV),e(EV,F8o),e(Lp,T8o),e(z,M8o),e(z,yp),e(yp,f_e),e(f_e,E8o),e(yp,C8o),e(yp,CV),e(CV,w8o),e(yp,A8o),e(z,L8o),e(z,xp),e(xp,g_e),e(g_e,y8o),e(xp,x8o),e(xp,wV),e(wV,$8o),e(xp,k8o),e(z,S8o),e(z,$p),e($p,h_e),e(h_e,R8o),e($p,P8o),e($p,AV),e(AV,B8o),e($p,I8o),e(z,N8o),e(z,kp),e(kp,u_e),e(u_e,q8o),e(kp,j8o),e(kp,LV),e(LV,D8o),e(kp,G8o),e(z,O8o),e(z,Sp),e(Sp,p_e),e(p_e,V8o),e(Sp,X8o),e(Sp,yV),e(yV,z8o),e(Sp,Q8o),e(z,W8o),e(z,Rp),e(Rp,__e),e(__e,U8o),e(Rp,H8o),e(Rp,xV),e(xV,J8o),e(Rp,Y8o),e(z,Z8o),e(z,Pp),e(Pp,b_e),e(b_e,K8o),e(Pp,eLo),e(Pp,$V),e($V,oLo),e(Pp,rLo),e(z,tLo),e(z,Bp),e(Bp,v_e),e(v_e,aLo),e(Bp,nLo),e(Bp,kV),e(kV,sLo),e(Bp,lLo),e(z,iLo),e(z,Ip),e(Ip,F_e),e(F_e,dLo),e(Ip,mLo),e(Ip,SV),e(SV,cLo),e(Ip,fLo),e(z,gLo),e(z,Np),e(Np,T_e),e(T_e,hLo),e(Np,uLo),e(Np,RV),e(RV,pLo),e(Np,_Lo),e(z,bLo),e(z,qp),e(qp,M_e),e(M_e,vLo),e(qp,FLo),e(qp,PV),e(PV,TLo),e(qp,MLo),e(z,ELo),e(z,jp),e(jp,E_e),e(E_e,CLo),e(jp,wLo),e(jp,BV),e(BV,ALo),e(jp,LLo),e(z,yLo),e(z,Dp),e(Dp,C_e),e(C_e,xLo),e(Dp,$Lo),e(Dp,IV),e(IV,kLo),e(Dp,SLo),e(z,RLo),e(z,Gp),e(Gp,w_e),e(w_e,PLo),e(Gp,BLo),e(Gp,NV),e(NV,ILo),e(Gp,NLo),e(z,qLo),e(z,Op),e(Op,A_e),e(A_e,jLo),e(Op,DLo),e(Op,qV),e(qV,GLo),e(Op,OLo),e(z,VLo),e(z,Vp),e(Vp,L_e),e(L_e,XLo),e(Vp,zLo),e(Vp,jV),e(jV,QLo),e(Vp,WLo),e(z,ULo),e(z,Xp),e(Xp,y_e),e(y_e,HLo),e(Xp,JLo),e(Xp,DV),e(DV,YLo),e(Xp,ZLo),e(z,KLo),e(z,zp),e(zp,x_e),e(x_e,eyo),e(zp,oyo),e(zp,GV),e(GV,ryo),e(zp,tyo),e(z,ayo),e(z,Qp),e(Qp,$_e),e($_e,nyo),e(Qp,syo),e(Qp,OV),e(OV,lyo),e(Qp,iyo),e(z,dyo),e(z,Wp),e(Wp,k_e),e(k_e,myo),e(Wp,cyo),e(Wp,VV),e(VV,fyo),e(Wp,gyo),e(z,hyo),e(z,Up),e(Up,S_e),e(S_e,uyo),e(Up,pyo),e(Up,XV),e(XV,_yo),e(Up,byo),e(z,vyo),e(z,Hp),e(Hp,R_e),e(R_e,Fyo),e(Hp,Tyo),e(Hp,zV),e(zV,Myo),e(Hp,Eyo),e(z,Cyo),e(z,Jp),e(Jp,P_e),e(P_e,wyo),e(Jp,Ayo),e(Jp,QV),e(QV,Lyo),e(Jp,yyo),e(z,xyo),e(z,Yp),e(Yp,B_e),e(B_e,$yo),e(Yp,kyo),e(Yp,WV),e(WV,Syo),e(Yp,Ryo),e(z,Pyo),e(z,Zp),e(Zp,I_e),e(I_e,Byo),e(Zp,Iyo),e(Zp,UV),e(UV,Nyo),e(Zp,qyo),e(Ye,jyo),M(Kp,Ye,null),e(Ye,Dyo),M(e_,Ye,null),e(Po,Gyo),e(Po,o_),M(C$,o_,null),e(o_,Oyo),e(o_,N_e),e(N_e,Vyo),b(c,vto,_),b(c,yd,_),e(yd,r_),e(r_,q_e),M(w$,q_e,null),e(yd,Xyo),e(yd,j_e),e(j_e,zyo),b(c,Fto,_),b(c,Bo,_),M(A$,Bo,null),e(Bo,Qyo),e(Bo,L$),e(L$,Wyo),e(L$,HV),e(HV,Uyo),e(L$,Hyo),e(Bo,Jyo),e(Bo,y$),e(y$,Yyo),e(y$,D_e),e(D_e,Zyo),e(y$,Kyo),e(Bo,e9o),e(Bo,Ze),M(x$,Ze,null),e(Ze,o9o),e(Ze,G_e),e(G_e,r9o),e(Ze,t9o),e(Ze,xd),e(xd,a9o),e(xd,O_e),e(O_e,n9o),e(xd,s9o),e(xd,V_e),e(V_e,l9o),e(xd,i9o),e(Ze,d9o),e(Ze,se),e(se,t_),e(t_,X_e),e(X_e,m9o),e(t_,c9o),e(t_,JV),e(JV,f9o),e(t_,g9o),e(se,h9o),e(se,a_),e(a_,z_e),e(z_e,u9o),e(a_,p9o),e(a_,YV),e(YV,_9o),e(a_,b9o),e(se,v9o),e(se,n_),e(n_,Q_e),e(Q_e,F9o),e(n_,T9o),e(n_,ZV),e(ZV,M9o),e(n_,E9o),e(se,C9o),e(se,s_),e(s_,W_e),e(W_e,w9o),e(s_,A9o),e(s_,KV),e(KV,L9o),e(s_,y9o),e(se,x9o),e(se,l_),e(l_,U_e),e(U_e,$9o),e(l_,k9o),e(l_,eX),e(eX,S9o),e(l_,R9o),e(se,P9o),e(se,i_),e(i_,H_e),e(H_e,B9o),e(i_,I9o),e(i_,oX),e(oX,N9o),e(i_,q9o),e(se,j9o),e(se,d_),e(d_,J_e),e(J_e,D9o),e(d_,G9o),e(d_,rX),e(rX,O9o),e(d_,V9o),e(se,X9o),e(se,m_),e(m_,Y_e),e(Y_e,z9o),e(m_,Q9o),e(m_,tX),e(tX,W9o),e(m_,U9o),e(se,H9o),e(se,c_),e(c_,Z_e),e(Z_e,J9o),e(c_,Y9o),e(c_,aX),e(aX,Z9o),e(c_,K9o),e(se,exo),e(se,f_),e(f_,K_e),e(K_e,oxo),e(f_,rxo),e(f_,nX),e(nX,txo),e(f_,axo),e(se,nxo),e(se,g_),e(g_,e1e),e(e1e,sxo),e(g_,lxo),e(g_,sX),e(sX,ixo),e(g_,dxo),e(se,mxo),e(se,h_),e(h_,o1e),e(o1e,cxo),e(h_,fxo),e(h_,lX),e(lX,gxo),e(h_,hxo),e(se,uxo),e(se,u_),e(u_,r1e),e(r1e,pxo),e(u_,_xo),e(u_,iX),e(iX,bxo),e(u_,vxo),e(se,Fxo),e(se,p_),e(p_,t1e),e(t1e,Txo),e(p_,Mxo),e(p_,dX),e(dX,Exo),e(p_,Cxo),e(se,wxo),e(se,__),e(__,a1e),e(a1e,Axo),e(__,Lxo),e(__,mX),e(mX,yxo),e(__,xxo),e(se,$xo),e(se,b_),e(b_,n1e),e(n1e,kxo),e(b_,Sxo),e(b_,cX),e(cX,Rxo),e(b_,Pxo),e(se,Bxo),e(se,v_),e(v_,s1e),e(s1e,Ixo),e(v_,Nxo),e(v_,fX),e(fX,qxo),e(v_,jxo),e(se,Dxo),e(se,F_),e(F_,l1e),e(l1e,Gxo),e(F_,Oxo),e(F_,gX),e(gX,Vxo),e(F_,Xxo),e(se,zxo),e(se,T_),e(T_,i1e),e(i1e,Qxo),e(T_,Wxo),e(T_,hX),e(hX,Uxo),e(T_,Hxo),e(se,Jxo),e(se,M_),e(M_,d1e),e(d1e,Yxo),e(M_,Zxo),e(M_,uX),e(uX,Kxo),e(M_,e$o),e(se,o$o),e(se,E_),e(E_,m1e),e(m1e,r$o),e(E_,t$o),e(E_,pX),e(pX,a$o),e(E_,n$o),e(se,s$o),e(se,C_),e(C_,c1e),e(c1e,l$o),e(C_,i$o),e(C_,_X),e(_X,d$o),e(C_,m$o),e(se,c$o),e(se,w_),e(w_,f1e),e(f1e,f$o),e(w_,g$o),e(w_,bX),e(bX,h$o),e(w_,u$o),e(Ze,p$o),M(A_,Ze,null),e(Ze,_$o),M(L_,Ze,null),e(Bo,b$o),e(Bo,y_),M($$,y_,null),e(y_,v$o),e(y_,g1e),e(g1e,F$o),b(c,Tto,_),b(c,$d,_),e($d,x_),e(x_,h1e),M(k$,h1e,null),e($d,T$o),e($d,u1e),e(u1e,M$o),b(c,Mto,_),b(c,Io,_),M(S$,Io,null),e(Io,E$o),e(Io,kd),e(kd,C$o),e(kd,vX),e(vX,w$o),e(kd,A$o),e(kd,FX),e(FX,L$o),e(kd,y$o),e(Io,x$o),e(Io,R$),e(R$,$$o),e(R$,p1e),e(p1e,k$o),e(R$,S$o),e(Io,R$o),e(Io,Tt),M(P$,Tt,null),e(Tt,P$o),e(Tt,_1e),e(_1e,B$o),e(Tt,I$o),e(Tt,Sd),e(Sd,N$o),e(Sd,b1e),e(b1e,q$o),e(Sd,j$o),e(Sd,TX),e(TX,D$o),e(Sd,G$o),e(Tt,O$o),M($_,Tt,null),e(Io,V$o),e(Io,Ke),M(B$,Ke,null),e(Ke,X$o),e(Ke,v1e),e(v1e,z$o),e(Ke,Q$o),e(Ke,an),e(an,W$o),e(an,F1e),e(F1e,U$o),e(an,H$o),e(an,T1e),e(T1e,J$o),e(an,Y$o),e(an,M1e),e(M1e,Z$o),e(an,K$o),e(Ke,eko),e(Ke,y),e(y,k_),e(k_,E1e),e(E1e,oko),e(k_,rko),e(k_,MX),e(MX,tko),e(k_,ako),e(y,nko),e(y,S_),e(S_,C1e),e(C1e,sko),e(S_,lko),e(S_,EX),e(EX,iko),e(S_,dko),e(y,mko),e(y,R_),e(R_,w1e),e(w1e,cko),e(R_,fko),e(R_,CX),e(CX,gko),e(R_,hko),e(y,uko),e(y,P_),e(P_,A1e),e(A1e,pko),e(P_,_ko),e(P_,wX),e(wX,bko),e(P_,vko),e(y,Fko),e(y,B_),e(B_,L1e),e(L1e,Tko),e(B_,Mko),e(B_,AX),e(AX,Eko),e(B_,Cko),e(y,wko),e(y,I_),e(I_,y1e),e(y1e,Ako),e(I_,Lko),e(I_,LX),e(LX,yko),e(I_,xko),e(y,$ko),e(y,N_),e(N_,x1e),e(x1e,kko),e(N_,Sko),e(N_,yX),e(yX,Rko),e(N_,Pko),e(y,Bko),e(y,q_),e(q_,$1e),e($1e,Iko),e(q_,Nko),e(q_,xX),e(xX,qko),e(q_,jko),e(y,Dko),e(y,j_),e(j_,k1e),e(k1e,Gko),e(j_,Oko),e(j_,$X),e($X,Vko),e(j_,Xko),e(y,zko),e(y,D_),e(D_,S1e),e(S1e,Qko),e(D_,Wko),e(D_,kX),e(kX,Uko),e(D_,Hko),e(y,Jko),e(y,G_),e(G_,R1e),e(R1e,Yko),e(G_,Zko),e(G_,SX),e(SX,Kko),e(G_,eSo),e(y,oSo),e(y,O_),e(O_,P1e),e(P1e,rSo),e(O_,tSo),e(O_,RX),e(RX,aSo),e(O_,nSo),e(y,sSo),e(y,V_),e(V_,B1e),e(B1e,lSo),e(V_,iSo),e(V_,PX),e(PX,dSo),e(V_,mSo),e(y,cSo),e(y,X_),e(X_,I1e),e(I1e,fSo),e(X_,gSo),e(X_,BX),e(BX,hSo),e(X_,uSo),e(y,pSo),e(y,z_),e(z_,N1e),e(N1e,_So),e(z_,bSo),e(z_,IX),e(IX,vSo),e(z_,FSo),e(y,TSo),e(y,Q_),e(Q_,q1e),e(q1e,MSo),e(Q_,ESo),e(Q_,NX),e(NX,CSo),e(Q_,wSo),e(y,ASo),e(y,W_),e(W_,j1e),e(j1e,LSo),e(W_,ySo),e(W_,qX),e(qX,xSo),e(W_,$So),e(y,kSo),e(y,U_),e(U_,D1e),e(D1e,SSo),e(U_,RSo),e(U_,jX),e(jX,PSo),e(U_,BSo),e(y,ISo),e(y,H_),e(H_,G1e),e(G1e,NSo),e(H_,qSo),e(H_,DX),e(DX,jSo),e(H_,DSo),e(y,GSo),e(y,J_),e(J_,O1e),e(O1e,OSo),e(J_,VSo),e(J_,GX),e(GX,XSo),e(J_,zSo),e(y,QSo),e(y,Y_),e(Y_,V1e),e(V1e,WSo),e(Y_,USo),e(Y_,OX),e(OX,HSo),e(Y_,JSo),e(y,YSo),e(y,Z_),e(Z_,X1e),e(X1e,ZSo),e(Z_,KSo),e(Z_,VX),e(VX,eRo),e(Z_,oRo),e(y,rRo),e(y,K_),e(K_,z1e),e(z1e,tRo),e(K_,aRo),e(K_,XX),e(XX,nRo),e(K_,sRo),e(y,lRo),e(y,e1),e(e1,Q1e),e(Q1e,iRo),e(e1,dRo),e(e1,zX),e(zX,mRo),e(e1,cRo),e(y,fRo),e(y,o1),e(o1,W1e),e(W1e,gRo),e(o1,hRo),e(o1,QX),e(QX,uRo),e(o1,pRo),e(y,_Ro),e(y,r1),e(r1,U1e),e(U1e,bRo),e(r1,vRo),e(r1,WX),e(WX,FRo),e(r1,TRo),e(y,MRo),e(y,t1),e(t1,H1e),e(H1e,ERo),e(t1,CRo),e(t1,UX),e(UX,wRo),e(t1,ARo),e(y,LRo),e(y,a1),e(a1,J1e),e(J1e,yRo),e(a1,xRo),e(a1,HX),e(HX,$Ro),e(a1,kRo),e(y,SRo),e(y,n1),e(n1,Y1e),e(Y1e,RRo),e(n1,PRo),e(n1,JX),e(JX,BRo),e(n1,IRo),e(y,NRo),e(y,s1),e(s1,Z1e),e(Z1e,qRo),e(s1,jRo),e(s1,YX),e(YX,DRo),e(s1,GRo),e(y,ORo),e(y,l1),e(l1,K1e),e(K1e,VRo),e(l1,XRo),e(l1,ZX),e(ZX,zRo),e(l1,QRo),e(y,WRo),e(y,i1),e(i1,e2e),e(e2e,URo),e(i1,HRo),e(i1,KX),e(KX,JRo),e(i1,YRo),e(y,ZRo),e(y,d1),e(d1,o2e),e(o2e,KRo),e(d1,ePo),e(d1,ez),e(ez,oPo),e(d1,rPo),e(y,tPo),e(y,m1),e(m1,r2e),e(r2e,aPo),e(m1,nPo),e(m1,oz),e(oz,sPo),e(m1,lPo),e(y,iPo),e(y,c1),e(c1,t2e),e(t2e,dPo),e(c1,mPo),e(c1,rz),e(rz,cPo),e(c1,fPo),e(y,gPo),e(y,f1),e(f1,a2e),e(a2e,hPo),e(f1,uPo),e(f1,tz),e(tz,pPo),e(f1,_Po),e(y,bPo),e(y,g1),e(g1,n2e),e(n2e,vPo),e(g1,FPo),e(g1,az),e(az,TPo),e(g1,MPo),e(y,EPo),e(y,h1),e(h1,s2e),e(s2e,CPo),e(h1,wPo),e(h1,nz),e(nz,APo),e(h1,LPo),e(y,yPo),e(y,u1),e(u1,l2e),e(l2e,xPo),e(u1,$Po),e(u1,sz),e(sz,kPo),e(u1,SPo),e(y,RPo),e(y,yl),e(yl,i2e),e(i2e,PPo),e(yl,BPo),e(yl,lz),e(lz,IPo),e(yl,NPo),e(yl,iz),e(iz,qPo),e(yl,jPo),e(y,DPo),e(y,p1),e(p1,d2e),e(d2e,GPo),e(p1,OPo),e(p1,dz),e(dz,VPo),e(p1,XPo),e(y,zPo),e(y,_1),e(_1,m2e),e(m2e,QPo),e(_1,WPo),e(_1,mz),e(mz,UPo),e(_1,HPo),e(y,JPo),e(y,b1),e(b1,c2e),e(c2e,YPo),e(b1,ZPo),e(b1,cz),e(cz,KPo),e(b1,eBo),e(y,oBo),e(y,v1),e(v1,f2e),e(f2e,rBo),e(v1,tBo),e(v1,fz),e(fz,aBo),e(v1,nBo),e(y,sBo),e(y,F1),e(F1,g2e),e(g2e,lBo),e(F1,iBo),e(F1,gz),e(gz,dBo),e(F1,mBo),e(y,cBo),e(y,T1),e(T1,h2e),e(h2e,fBo),e(T1,gBo),e(T1,hz),e(hz,hBo),e(T1,uBo),e(y,pBo),e(y,M1),e(M1,u2e),e(u2e,_Bo),e(M1,bBo),e(M1,uz),e(uz,vBo),e(M1,FBo),e(y,TBo),e(y,E1),e(E1,p2e),e(p2e,MBo),e(E1,EBo),e(E1,pz),e(pz,CBo),e(E1,wBo),e(y,ABo),e(y,C1),e(C1,_2e),e(_2e,LBo),e(C1,yBo),e(C1,_z),e(_z,xBo),e(C1,$Bo),e(y,kBo),e(y,w1),e(w1,b2e),e(b2e,SBo),e(w1,RBo),e(w1,bz),e(bz,PBo),e(w1,BBo),e(y,IBo),e(y,A1),e(A1,v2e),e(v2e,NBo),e(A1,qBo),e(A1,vz),e(vz,jBo),e(A1,DBo),e(y,GBo),e(y,L1),e(L1,F2e),e(F2e,OBo),e(L1,VBo),e(L1,Fz),e(Fz,XBo),e(L1,zBo),e(y,QBo),e(y,y1),e(y1,T2e),e(T2e,WBo),e(y1,UBo),e(y1,Tz),e(Tz,HBo),e(y1,JBo),e(y,YBo),e(y,x1),e(x1,M2e),e(M2e,ZBo),e(x1,KBo),e(x1,Mz),e(Mz,eIo),e(x1,oIo),e(y,rIo),e(y,$1),e($1,E2e),e(E2e,tIo),e($1,aIo),e($1,Ez),e(Ez,nIo),e($1,sIo),e(y,lIo),e(y,k1),e(k1,C2e),e(C2e,iIo),e(k1,dIo),e(k1,Cz),e(Cz,mIo),e(k1,cIo),e(y,fIo),e(y,S1),e(S1,w2e),e(w2e,gIo),e(S1,hIo),e(S1,wz),e(wz,uIo),e(S1,pIo),e(y,_Io),e(y,R1),e(R1,A2e),e(A2e,bIo),e(R1,vIo),e(R1,Az),e(Az,FIo),e(R1,TIo),e(y,MIo),e(y,P1),e(P1,L2e),e(L2e,EIo),e(P1,CIo),e(P1,Lz),e(Lz,wIo),e(P1,AIo),e(y,LIo),e(y,B1),e(B1,y2e),e(y2e,yIo),e(B1,xIo),e(B1,yz),e(yz,$Io),e(B1,kIo),e(y,SIo),e(y,I1),e(I1,x2e),e(x2e,RIo),e(I1,PIo),e(I1,xz),e(xz,BIo),e(I1,IIo),e(y,NIo),e(y,N1),e(N1,$2e),e($2e,qIo),e(N1,jIo),e(N1,$z),e($z,DIo),e(N1,GIo),e(y,OIo),e(y,q1),e(q1,k2e),e(k2e,VIo),e(q1,XIo),e(q1,kz),e(kz,zIo),e(q1,QIo),e(y,WIo),e(y,j1),e(j1,S2e),e(S2e,UIo),e(j1,HIo),e(j1,Sz),e(Sz,JIo),e(j1,YIo),e(y,ZIo),e(y,D1),e(D1,R2e),e(R2e,KIo),e(D1,eNo),e(D1,Rz),e(Rz,oNo),e(D1,rNo),e(y,tNo),e(y,G1),e(G1,P2e),e(P2e,aNo),e(G1,nNo),e(G1,Pz),e(Pz,sNo),e(G1,lNo),e(y,iNo),e(y,O1),e(O1,B2e),e(B2e,dNo),e(O1,mNo),e(O1,Bz),e(Bz,cNo),e(O1,fNo),e(y,gNo),e(y,V1),e(V1,I2e),e(I2e,hNo),e(V1,uNo),e(V1,Iz),e(Iz,pNo),e(V1,_No),e(y,bNo),e(y,X1),e(X1,N2e),e(N2e,vNo),e(X1,FNo),e(X1,Nz),e(Nz,TNo),e(X1,MNo),e(y,ENo),e(y,z1),e(z1,q2e),e(q2e,CNo),e(z1,wNo),e(z1,qz),e(qz,ANo),e(z1,LNo),e(y,yNo),e(y,Q1),e(Q1,j2e),e(j2e,xNo),e(Q1,$No),e(Q1,jz),e(jz,kNo),e(Q1,SNo),e(y,RNo),e(y,W1),e(W1,D2e),e(D2e,PNo),e(W1,BNo),e(W1,Dz),e(Dz,INo),e(W1,NNo),e(y,qNo),e(y,U1),e(U1,G2e),e(G2e,jNo),e(U1,DNo),e(U1,Gz),e(Gz,GNo),e(U1,ONo),e(y,VNo),e(y,H1),e(H1,O2e),e(O2e,XNo),e(H1,zNo),e(H1,Oz),e(Oz,QNo),e(H1,WNo),e(y,UNo),e(y,J1),e(J1,V2e),e(V2e,HNo),e(J1,JNo),e(J1,Vz),e(Vz,YNo),e(J1,ZNo),e(y,KNo),e(y,Y1),e(Y1,X2e),e(X2e,eqo),e(Y1,oqo),e(Y1,Xz),e(Xz,rqo),e(Y1,tqo),e(y,aqo),e(y,Z1),e(Z1,z2e),e(z2e,nqo),e(Z1,sqo),e(Z1,zz),e(zz,lqo),e(Z1,iqo),e(y,dqo),e(y,K1),e(K1,Q2e),e(Q2e,mqo),e(K1,cqo),e(K1,Qz),e(Qz,fqo),e(K1,gqo),e(y,hqo),e(y,e2),e(e2,W2e),e(W2e,uqo),e(e2,pqo),e(e2,Wz),e(Wz,_qo),e(e2,bqo),e(y,vqo),e(y,o2),e(o2,U2e),e(U2e,Fqo),e(o2,Tqo),e(o2,Uz),e(Uz,Mqo),e(o2,Eqo),e(y,Cqo),e(y,r2),e(r2,H2e),e(H2e,wqo),e(r2,Aqo),e(r2,Hz),e(Hz,Lqo),e(r2,yqo),e(y,xqo),e(y,t2),e(t2,J2e),e(J2e,$qo),e(t2,kqo),e(t2,Jz),e(Jz,Sqo),e(t2,Rqo),e(y,Pqo),e(y,a2),e(a2,Y2e),e(Y2e,Bqo),e(a2,Iqo),e(a2,Yz),e(Yz,Nqo),e(a2,qqo),e(y,jqo),e(y,n2),e(n2,Z2e),e(Z2e,Dqo),e(n2,Gqo),e(n2,Zz),e(Zz,Oqo),e(n2,Vqo),e(y,Xqo),e(y,s2),e(s2,K2e),e(K2e,zqo),e(s2,Qqo),e(s2,Kz),e(Kz,Wqo),e(s2,Uqo),e(y,Hqo),e(y,l2),e(l2,ebe),e(ebe,Jqo),e(l2,Yqo),e(l2,eQ),e(eQ,Zqo),e(l2,Kqo),e(y,ejo),e(y,i2),e(i2,obe),e(obe,ojo),e(i2,rjo),e(i2,oQ),e(oQ,tjo),e(i2,ajo),e(y,njo),e(y,d2),e(d2,rbe),e(rbe,sjo),e(d2,ljo),e(d2,rQ),e(rQ,ijo),e(d2,djo),e(y,mjo),e(y,m2),e(m2,tbe),e(tbe,cjo),e(m2,fjo),e(m2,tQ),e(tQ,gjo),e(m2,hjo),e(y,ujo),e(y,c2),e(c2,abe),e(abe,pjo),e(c2,_jo),e(c2,aQ),e(aQ,bjo),e(c2,vjo),e(y,Fjo),e(y,f2),e(f2,nbe),e(nbe,Tjo),e(f2,Mjo),e(f2,nQ),e(nQ,Ejo),e(f2,Cjo),e(y,wjo),e(y,g2),e(g2,sbe),e(sbe,Ajo),e(g2,Ljo),e(g2,sQ),e(sQ,yjo),e(g2,xjo),e(y,$jo),e(y,h2),e(h2,lbe),e(lbe,kjo),e(h2,Sjo),e(h2,lQ),e(lQ,Rjo),e(h2,Pjo),e(y,Bjo),e(y,u2),e(u2,ibe),e(ibe,Ijo),e(u2,Njo),e(u2,iQ),e(iQ,qjo),e(u2,jjo),e(y,Djo),e(y,p2),e(p2,dbe),e(dbe,Gjo),e(p2,Ojo),e(p2,dQ),e(dQ,Vjo),e(p2,Xjo),e(y,zjo),e(y,_2),e(_2,mbe),e(mbe,Qjo),e(_2,Wjo),e(_2,mQ),e(mQ,Ujo),e(_2,Hjo),e(y,Jjo),e(y,b2),e(b2,cbe),e(cbe,Yjo),e(b2,Zjo),e(b2,cQ),e(cQ,Kjo),e(b2,eDo),e(y,oDo),e(y,v2),e(v2,fbe),e(fbe,rDo),e(v2,tDo),e(v2,fQ),e(fQ,aDo),e(v2,nDo),e(y,sDo),e(y,F2),e(F2,gbe),e(gbe,lDo),e(F2,iDo),e(F2,gQ),e(gQ,dDo),e(F2,mDo),e(y,cDo),e(y,T2),e(T2,hbe),e(hbe,fDo),e(T2,gDo),e(T2,hQ),e(hQ,hDo),e(T2,uDo),e(y,pDo),e(y,M2),e(M2,ube),e(ube,_Do),e(M2,bDo),e(M2,uQ),e(uQ,vDo),e(M2,FDo),e(y,TDo),e(y,E2),e(E2,pbe),e(pbe,MDo),e(E2,EDo),e(E2,pQ),e(pQ,CDo),e(E2,wDo),e(y,ADo),e(y,C2),e(C2,_be),e(_be,LDo),e(C2,yDo),e(C2,_Q),e(_Q,xDo),e(C2,$Do),e(y,kDo),e(y,w2),e(w2,bbe),e(bbe,SDo),e(w2,RDo),e(w2,bQ),e(bQ,PDo),e(w2,BDo),e(y,IDo),e(y,A2),e(A2,vbe),e(vbe,NDo),e(A2,qDo),e(A2,vQ),e(vQ,jDo),e(A2,DDo),e(y,GDo),e(y,L2),e(L2,Fbe),e(Fbe,ODo),e(L2,VDo),e(L2,FQ),e(FQ,XDo),e(L2,zDo),e(y,QDo),e(y,y2),e(y2,Tbe),e(Tbe,WDo),e(y2,UDo),e(y2,TQ),e(TQ,HDo),e(y2,JDo),e(y,YDo),e(y,x2),e(x2,Mbe),e(Mbe,ZDo),e(x2,KDo),e(x2,MQ),e(MQ,eGo),e(x2,oGo),e(y,rGo),e(y,$2),e($2,Ebe),e(Ebe,tGo),e($2,aGo),e($2,EQ),e(EQ,nGo),e($2,sGo),e(y,lGo),e(y,k2),e(k2,Cbe),e(Cbe,iGo),e(k2,dGo),e(k2,CQ),e(CQ,mGo),e(k2,cGo),e(y,fGo),e(y,S2),e(S2,wbe),e(wbe,gGo),e(S2,hGo),e(S2,wQ),e(wQ,uGo),e(S2,pGo),e(y,_Go),e(y,R2),e(R2,Abe),e(Abe,bGo),e(R2,vGo),e(R2,AQ),e(AQ,FGo),e(R2,TGo),e(y,MGo),e(y,P2),e(P2,Lbe),e(Lbe,EGo),e(P2,CGo),e(P2,LQ),e(LQ,wGo),e(P2,AGo),e(y,LGo),e(y,B2),e(B2,ybe),e(ybe,yGo),e(B2,xGo),e(B2,yQ),e(yQ,$Go),e(B2,kGo),e(y,SGo),e(y,I2),e(I2,xbe),e(xbe,RGo),e(I2,PGo),e(I2,xQ),e(xQ,BGo),e(I2,IGo),e(y,NGo),e(y,N2),e(N2,$be),e($be,qGo),e(N2,jGo),e(N2,$Q),e($Q,DGo),e(N2,GGo),e(y,OGo),e(y,q2),e(q2,kbe),e(kbe,VGo),e(q2,XGo),e(q2,kQ),e(kQ,zGo),e(q2,QGo),e(y,WGo),e(y,j2),e(j2,Sbe),e(Sbe,UGo),e(j2,HGo),e(j2,SQ),e(SQ,JGo),e(j2,YGo),e(y,ZGo),e(y,D2),e(D2,Rbe),e(Rbe,KGo),e(D2,eOo),e(D2,RQ),e(RQ,oOo),e(D2,rOo),e(y,tOo),e(y,G2),e(G2,Pbe),e(Pbe,aOo),e(G2,nOo),e(G2,PQ),e(PQ,sOo),e(G2,lOo),e(y,iOo),e(y,O2),e(O2,Bbe),e(Bbe,dOo),e(O2,mOo),e(O2,BQ),e(BQ,cOo),e(O2,fOo),e(y,gOo),e(y,V2),e(V2,Ibe),e(Ibe,hOo),e(V2,uOo),e(V2,IQ),e(IQ,pOo),e(V2,_Oo),e(y,bOo),e(y,X2),e(X2,Nbe),e(Nbe,vOo),e(X2,FOo),e(X2,NQ),e(NQ,TOo),e(X2,MOo),e(y,EOo),e(y,z2),e(z2,qbe),e(qbe,COo),e(z2,wOo),e(z2,qQ),e(qQ,AOo),e(z2,LOo),e(y,yOo),e(y,Q2),e(Q2,jbe),e(jbe,xOo),e(Q2,$Oo),e(Q2,jQ),e(jQ,kOo),e(Q2,SOo),e(y,ROo),e(y,W2),e(W2,Dbe),e(Dbe,POo),e(W2,BOo),e(W2,DQ),e(DQ,IOo),e(W2,NOo),e(y,qOo),e(y,U2),e(U2,Gbe),e(Gbe,jOo),e(U2,DOo),e(U2,GQ),e(GQ,GOo),e(U2,OOo),e(y,VOo),e(y,H2),e(H2,Obe),e(Obe,XOo),e(H2,zOo),e(H2,OQ),e(OQ,QOo),e(H2,WOo),e(Ke,UOo),e(Ke,J2),e(J2,HOo),e(J2,Vbe),e(Vbe,JOo),e(J2,YOo),e(J2,Xbe),e(Xbe,ZOo),e(Ke,KOo),M(Y2,Ke,null),b(c,Eto,_),b(c,Rd,_),e(Rd,Z2),e(Z2,zbe),M(I$,zbe,null),e(Rd,eVo),e(Rd,Qbe),e(Qbe,oVo),b(c,Cto,_),b(c,No,_),M(N$,No,null),e(No,rVo),e(No,Pd),e(Pd,tVo),e(Pd,VQ),e(VQ,aVo),e(Pd,nVo),e(Pd,XQ),e(XQ,sVo),e(Pd,lVo),e(No,iVo),e(No,q$),e(q$,dVo),e(q$,Wbe),e(Wbe,mVo),e(q$,cVo),e(No,fVo),e(No,Mt),M(j$,Mt,null),e(Mt,gVo),e(Mt,Ube),e(Ube,hVo),e(Mt,uVo),e(Mt,Bd),e(Bd,pVo),e(Bd,Hbe),e(Hbe,_Vo),e(Bd,bVo),e(Bd,zQ),e(zQ,vVo),e(Bd,FVo),e(Mt,TVo),M(K2,Mt,null),e(No,MVo),e(No,eo),M(D$,eo,null),e(eo,EVo),e(eo,Jbe),e(Jbe,CVo),e(eo,wVo),e(eo,nn),e(nn,AVo),e(nn,Ybe),e(Ybe,LVo),e(nn,yVo),e(nn,Zbe),e(Zbe,xVo),e(nn,$Vo),e(nn,Kbe),e(Kbe,kVo),e(nn,SVo),e(eo,RVo),e(eo,G),e(G,eb),e(eb,eve),e(eve,PVo),e(eb,BVo),e(eb,QQ),e(QQ,IVo),e(eb,NVo),e(G,qVo),e(G,ob),e(ob,ove),e(ove,jVo),e(ob,DVo),e(ob,WQ),e(WQ,GVo),e(ob,OVo),e(G,VVo),e(G,rb),e(rb,rve),e(rve,XVo),e(rb,zVo),e(rb,UQ),e(UQ,QVo),e(rb,WVo),e(G,UVo),e(G,tb),e(tb,tve),e(tve,HVo),e(tb,JVo),e(tb,HQ),e(HQ,YVo),e(tb,ZVo),e(G,KVo),e(G,ab),e(ab,ave),e(ave,eXo),e(ab,oXo),e(ab,JQ),e(JQ,rXo),e(ab,tXo),e(G,aXo),e(G,nb),e(nb,nve),e(nve,nXo),e(nb,sXo),e(nb,YQ),e(YQ,lXo),e(nb,iXo),e(G,dXo),e(G,sb),e(sb,sve),e(sve,mXo),e(sb,cXo),e(sb,ZQ),e(ZQ,fXo),e(sb,gXo),e(G,hXo),e(G,lb),e(lb,lve),e(lve,uXo),e(lb,pXo),e(lb,KQ),e(KQ,_Xo),e(lb,bXo),e(G,vXo),e(G,ib),e(ib,ive),e(ive,FXo),e(ib,TXo),e(ib,eW),e(eW,MXo),e(ib,EXo),e(G,CXo),e(G,db),e(db,dve),e(dve,wXo),e(db,AXo),e(db,oW),e(oW,LXo),e(db,yXo),e(G,xXo),e(G,mb),e(mb,mve),e(mve,$Xo),e(mb,kXo),e(mb,rW),e(rW,SXo),e(mb,RXo),e(G,PXo),e(G,cb),e(cb,cve),e(cve,BXo),e(cb,IXo),e(cb,tW),e(tW,NXo),e(cb,qXo),e(G,jXo),e(G,fb),e(fb,fve),e(fve,DXo),e(fb,GXo),e(fb,aW),e(aW,OXo),e(fb,VXo),e(G,XXo),e(G,gb),e(gb,gve),e(gve,zXo),e(gb,QXo),e(gb,nW),e(nW,WXo),e(gb,UXo),e(G,HXo),e(G,hb),e(hb,hve),e(hve,JXo),e(hb,YXo),e(hb,sW),e(sW,ZXo),e(hb,KXo),e(G,ezo),e(G,ub),e(ub,uve),e(uve,ozo),e(ub,rzo),e(ub,lW),e(lW,tzo),e(ub,azo),e(G,nzo),e(G,pb),e(pb,pve),e(pve,szo),e(pb,lzo),e(pb,iW),e(iW,izo),e(pb,dzo),e(G,mzo),e(G,_b),e(_b,_ve),e(_ve,czo),e(_b,fzo),e(_b,dW),e(dW,gzo),e(_b,hzo),e(G,uzo),e(G,bb),e(bb,bve),e(bve,pzo),e(bb,_zo),e(bb,mW),e(mW,bzo),e(bb,vzo),e(G,Fzo),e(G,vb),e(vb,vve),e(vve,Tzo),e(vb,Mzo),e(vb,cW),e(cW,Ezo),e(vb,Czo),e(G,wzo),e(G,Fb),e(Fb,Fve),e(Fve,Azo),e(Fb,Lzo),e(Fb,fW),e(fW,yzo),e(Fb,xzo),e(G,$zo),e(G,Tb),e(Tb,Tve),e(Tve,kzo),e(Tb,Szo),e(Tb,gW),e(gW,Rzo),e(Tb,Pzo),e(G,Bzo),e(G,Mb),e(Mb,Mve),e(Mve,Izo),e(Mb,Nzo),e(Mb,hW),e(hW,qzo),e(Mb,jzo),e(G,Dzo),e(G,Eb),e(Eb,Eve),e(Eve,Gzo),e(Eb,Ozo),e(Eb,uW),e(uW,Vzo),e(Eb,Xzo),e(G,zzo),e(G,Cb),e(Cb,Cve),e(Cve,Qzo),e(Cb,Wzo),e(Cb,pW),e(pW,Uzo),e(Cb,Hzo),e(G,Jzo),e(G,wb),e(wb,wve),e(wve,Yzo),e(wb,Zzo),e(wb,_W),e(_W,Kzo),e(wb,eQo),e(G,oQo),e(G,Ab),e(Ab,Ave),e(Ave,rQo),e(Ab,tQo),e(Ab,bW),e(bW,aQo),e(Ab,nQo),e(G,sQo),e(G,Lb),e(Lb,Lve),e(Lve,lQo),e(Lb,iQo),e(Lb,vW),e(vW,dQo),e(Lb,mQo),e(G,cQo),e(G,yb),e(yb,yve),e(yve,fQo),e(yb,gQo),e(yb,FW),e(FW,hQo),e(yb,uQo),e(G,pQo),e(G,xb),e(xb,xve),e(xve,_Qo),e(xb,bQo),e(xb,TW),e(TW,vQo),e(xb,FQo),e(G,TQo),e(G,$b),e($b,$ve),e($ve,MQo),e($b,EQo),e($b,MW),e(MW,CQo),e($b,wQo),e(G,AQo),e(G,kb),e(kb,kve),e(kve,LQo),e(kb,yQo),e(kb,EW),e(EW,xQo),e(kb,$Qo),e(G,kQo),e(G,Sb),e(Sb,Sve),e(Sve,SQo),e(Sb,RQo),e(Sb,CW),e(CW,PQo),e(Sb,BQo),e(G,IQo),e(G,Rb),e(Rb,Rve),e(Rve,NQo),e(Rb,qQo),e(Rb,wW),e(wW,jQo),e(Rb,DQo),e(G,GQo),e(G,Pb),e(Pb,Pve),e(Pve,OQo),e(Pb,VQo),e(Pb,AW),e(AW,XQo),e(Pb,zQo),e(G,QQo),e(G,Bb),e(Bb,Bve),e(Bve,WQo),e(Bb,UQo),e(Bb,LW),e(LW,HQo),e(Bb,JQo),e(G,YQo),e(G,Ib),e(Ib,Ive),e(Ive,ZQo),e(Ib,KQo),e(Ib,yW),e(yW,eWo),e(Ib,oWo),e(G,rWo),e(G,Nb),e(Nb,Nve),e(Nve,tWo),e(Nb,aWo),e(Nb,xW),e(xW,nWo),e(Nb,sWo),e(G,lWo),e(G,qb),e(qb,qve),e(qve,iWo),e(qb,dWo),e(qb,$W),e($W,mWo),e(qb,cWo),e(G,fWo),e(G,jb),e(jb,jve),e(jve,gWo),e(jb,hWo),e(jb,kW),e(kW,uWo),e(jb,pWo),e(G,_Wo),e(G,Db),e(Db,Dve),e(Dve,bWo),e(Db,vWo),e(Db,SW),e(SW,FWo),e(Db,TWo),e(G,MWo),e(G,Gb),e(Gb,Gve),e(Gve,EWo),e(Gb,CWo),e(Gb,RW),e(RW,wWo),e(Gb,AWo),e(G,LWo),e(G,Ob),e(Ob,Ove),e(Ove,yWo),e(Ob,xWo),e(Ob,PW),e(PW,$Wo),e(Ob,kWo),e(G,SWo),e(G,Vb),e(Vb,Vve),e(Vve,RWo),e(Vb,PWo),e(Vb,BW),e(BW,BWo),e(Vb,IWo),e(G,NWo),e(G,Xb),e(Xb,Xve),e(Xve,qWo),e(Xb,jWo),e(Xb,IW),e(IW,DWo),e(Xb,GWo),e(G,OWo),e(G,zb),e(zb,zve),e(zve,VWo),e(zb,XWo),e(zb,NW),e(NW,zWo),e(zb,QWo),e(G,WWo),e(G,Qb),e(Qb,Qve),e(Qve,UWo),e(Qb,HWo),e(Qb,qW),e(qW,JWo),e(Qb,YWo),e(G,ZWo),e(G,Wb),e(Wb,Wve),e(Wve,KWo),e(Wb,eUo),e(Wb,jW),e(jW,oUo),e(Wb,rUo),e(eo,tUo),e(eo,Ub),e(Ub,aUo),e(Ub,Uve),e(Uve,nUo),e(Ub,sUo),e(Ub,Hve),e(Hve,lUo),e(eo,iUo),M(Hb,eo,null),b(c,wto,_),b(c,Id,_),e(Id,Jb),e(Jb,Jve),M(G$,Jve,null),e(Id,dUo),e(Id,Yve),e(Yve,mUo),b(c,Ato,_),b(c,qo,_),M(O$,qo,null),e(qo,cUo),e(qo,Nd),e(Nd,fUo),e(Nd,DW),e(DW,gUo),e(Nd,hUo),e(Nd,GW),e(GW,uUo),e(Nd,pUo),e(qo,_Uo),e(qo,V$),e(V$,bUo),e(V$,Zve),e(Zve,vUo),e(V$,FUo),e(qo,TUo),e(qo,Et),M(X$,Et,null),e(Et,MUo),e(Et,Kve),e(Kve,EUo),e(Et,CUo),e(Et,qd),e(qd,wUo),e(qd,eFe),e(eFe,AUo),e(qd,LUo),e(qd,OW),e(OW,yUo),e(qd,xUo),e(Et,$Uo),M(Yb,Et,null),e(qo,kUo),e(qo,oo),M(z$,oo,null),e(oo,SUo),e(oo,oFe),e(oFe,RUo),e(oo,PUo),e(oo,sn),e(sn,BUo),e(sn,rFe),e(rFe,IUo),e(sn,NUo),e(sn,tFe),e(tFe,qUo),e(sn,jUo),e(sn,aFe),e(aFe,DUo),e(sn,GUo),e(oo,OUo),e(oo,Q),e(Q,Zb),e(Zb,nFe),e(nFe,VUo),e(Zb,XUo),e(Zb,VW),e(VW,zUo),e(Zb,QUo),e(Q,WUo),e(Q,Kb),e(Kb,sFe),e(sFe,UUo),e(Kb,HUo),e(Kb,XW),e(XW,JUo),e(Kb,YUo),e(Q,ZUo),e(Q,ev),e(ev,lFe),e(lFe,KUo),e(ev,eHo),e(ev,zW),e(zW,oHo),e(ev,rHo),e(Q,tHo),e(Q,ov),e(ov,iFe),e(iFe,aHo),e(ov,nHo),e(ov,QW),e(QW,sHo),e(ov,lHo),e(Q,iHo),e(Q,rv),e(rv,dFe),e(dFe,dHo),e(rv,mHo),e(rv,WW),e(WW,cHo),e(rv,fHo),e(Q,gHo),e(Q,tv),e(tv,mFe),e(mFe,hHo),e(tv,uHo),e(tv,UW),e(UW,pHo),e(tv,_Ho),e(Q,bHo),e(Q,av),e(av,cFe),e(cFe,vHo),e(av,FHo),e(av,HW),e(HW,THo),e(av,MHo),e(Q,EHo),e(Q,nv),e(nv,fFe),e(fFe,CHo),e(nv,wHo),e(nv,JW),e(JW,AHo),e(nv,LHo),e(Q,yHo),e(Q,sv),e(sv,gFe),e(gFe,xHo),e(sv,$Ho),e(sv,YW),e(YW,kHo),e(sv,SHo),e(Q,RHo),e(Q,lv),e(lv,hFe),e(hFe,PHo),e(lv,BHo),e(lv,ZW),e(ZW,IHo),e(lv,NHo),e(Q,qHo),e(Q,iv),e(iv,uFe),e(uFe,jHo),e(iv,DHo),e(iv,KW),e(KW,GHo),e(iv,OHo),e(Q,VHo),e(Q,dv),e(dv,pFe),e(pFe,XHo),e(dv,zHo),e(dv,eU),e(eU,QHo),e(dv,WHo),e(Q,UHo),e(Q,mv),e(mv,_Fe),e(_Fe,HHo),e(mv,JHo),e(mv,oU),e(oU,YHo),e(mv,ZHo),e(Q,KHo),e(Q,cv),e(cv,bFe),e(bFe,eJo),e(cv,oJo),e(cv,rU),e(rU,rJo),e(cv,tJo),e(Q,aJo),e(Q,fv),e(fv,vFe),e(vFe,nJo),e(fv,sJo),e(fv,tU),e(tU,lJo),e(fv,iJo),e(Q,dJo),e(Q,gv),e(gv,FFe),e(FFe,mJo),e(gv,cJo),e(gv,aU),e(aU,fJo),e(gv,gJo),e(Q,hJo),e(Q,hv),e(hv,TFe),e(TFe,uJo),e(hv,pJo),e(hv,nU),e(nU,_Jo),e(hv,bJo),e(Q,vJo),e(Q,uv),e(uv,MFe),e(MFe,FJo),e(uv,TJo),e(uv,sU),e(sU,MJo),e(uv,EJo),e(Q,CJo),e(Q,pv),e(pv,EFe),e(EFe,wJo),e(pv,AJo),e(pv,lU),e(lU,LJo),e(pv,yJo),e(Q,xJo),e(Q,_v),e(_v,CFe),e(CFe,$Jo),e(_v,kJo),e(_v,iU),e(iU,SJo),e(_v,RJo),e(Q,PJo),e(Q,bv),e(bv,wFe),e(wFe,BJo),e(bv,IJo),e(bv,dU),e(dU,NJo),e(bv,qJo),e(Q,jJo),e(Q,vv),e(vv,AFe),e(AFe,DJo),e(vv,GJo),e(vv,mU),e(mU,OJo),e(vv,VJo),e(Q,XJo),e(Q,Fv),e(Fv,LFe),e(LFe,zJo),e(Fv,QJo),e(Fv,cU),e(cU,WJo),e(Fv,UJo),e(Q,HJo),e(Q,Tv),e(Tv,yFe),e(yFe,JJo),e(Tv,YJo),e(Tv,fU),e(fU,ZJo),e(Tv,KJo),e(Q,eYo),e(Q,Mv),e(Mv,xFe),e(xFe,oYo),e(Mv,rYo),e(Mv,gU),e(gU,tYo),e(Mv,aYo),e(Q,nYo),e(Q,Ev),e(Ev,$Fe),e($Fe,sYo),e(Ev,lYo),e(Ev,hU),e(hU,iYo),e(Ev,dYo),e(Q,mYo),e(Q,Cv),e(Cv,kFe),e(kFe,cYo),e(Cv,fYo),e(Cv,uU),e(uU,gYo),e(Cv,hYo),e(Q,uYo),e(Q,wv),e(wv,SFe),e(SFe,pYo),e(wv,_Yo),e(wv,pU),e(pU,bYo),e(wv,vYo),e(Q,FYo),e(Q,Av),e(Av,RFe),e(RFe,TYo),e(Av,MYo),e(Av,_U),e(_U,EYo),e(Av,CYo),e(Q,wYo),e(Q,Lv),e(Lv,PFe),e(PFe,AYo),e(Lv,LYo),e(Lv,bU),e(bU,yYo),e(Lv,xYo),e(Q,$Yo),e(Q,yv),e(yv,BFe),e(BFe,kYo),e(yv,SYo),e(yv,vU),e(vU,RYo),e(yv,PYo),e(Q,BYo),e(Q,xv),e(xv,IFe),e(IFe,IYo),e(xv,NYo),e(xv,FU),e(FU,qYo),e(xv,jYo),e(Q,DYo),e(Q,$v),e($v,NFe),e(NFe,GYo),e($v,OYo),e($v,TU),e(TU,VYo),e($v,XYo),e(Q,zYo),e(Q,kv),e(kv,qFe),e(qFe,QYo),e(kv,WYo),e(kv,MU),e(MU,UYo),e(kv,HYo),e(Q,JYo),e(Q,Sv),e(Sv,jFe),e(jFe,YYo),e(Sv,ZYo),e(Sv,EU),e(EU,KYo),e(Sv,eZo),e(Q,oZo),e(Q,Rv),e(Rv,DFe),e(DFe,rZo),e(Rv,tZo),e(Rv,CU),e(CU,aZo),e(Rv,nZo),e(Q,sZo),e(Q,Pv),e(Pv,GFe),e(GFe,lZo),e(Pv,iZo),e(Pv,wU),e(wU,dZo),e(Pv,mZo),e(Q,cZo),e(Q,Bv),e(Bv,OFe),e(OFe,fZo),e(Bv,gZo),e(Bv,AU),e(AU,hZo),e(Bv,uZo),e(Q,pZo),e(Q,Iv),e(Iv,VFe),e(VFe,_Zo),e(Iv,bZo),e(Iv,LU),e(LU,vZo),e(Iv,FZo),e(Q,TZo),e(Q,Nv),e(Nv,XFe),e(XFe,MZo),e(Nv,EZo),e(Nv,yU),e(yU,CZo),e(Nv,wZo),e(Q,AZo),e(Q,qv),e(qv,zFe),e(zFe,LZo),e(qv,yZo),e(qv,xU),e(xU,xZo),e(qv,$Zo),e(Q,kZo),e(Q,jv),e(jv,QFe),e(QFe,SZo),e(jv,RZo),e(jv,$U),e($U,PZo),e(jv,BZo),e(oo,IZo),e(oo,Dv),e(Dv,NZo),e(Dv,WFe),e(WFe,qZo),e(Dv,jZo),e(Dv,UFe),e(UFe,DZo),e(oo,GZo),M(Gv,oo,null),b(c,Lto,_),b(c,jd,_),e(jd,Ov),e(Ov,HFe),M(Q$,HFe,null),e(jd,OZo),e(jd,JFe),e(JFe,VZo),b(c,yto,_),b(c,jo,_),M(W$,jo,null),e(jo,XZo),e(jo,Dd),e(Dd,zZo),e(Dd,kU),e(kU,QZo),e(Dd,WZo),e(Dd,SU),e(SU,UZo),e(Dd,HZo),e(jo,JZo),e(jo,U$),e(U$,YZo),e(U$,YFe),e(YFe,ZZo),e(U$,KZo),e(jo,eKo),e(jo,Ct),M(H$,Ct,null),e(Ct,oKo),e(Ct,ZFe),e(ZFe,rKo),e(Ct,tKo),e(Ct,Gd),e(Gd,aKo),e(Gd,KFe),e(KFe,nKo),e(Gd,sKo),e(Gd,RU),e(RU,lKo),e(Gd,iKo),e(Ct,dKo),M(Vv,Ct,null),e(jo,mKo),e(jo,ro),M(J$,ro,null),e(ro,cKo),e(ro,eTe),e(eTe,fKo),e(ro,gKo),e(ro,ln),e(ln,hKo),e(ln,oTe),e(oTe,uKo),e(ln,pKo),e(ln,rTe),e(rTe,_Ko),e(ln,bKo),e(ln,tTe),e(tTe,vKo),e(ln,FKo),e(ro,TKo),e(ro,Y$),e(Y$,Xv),e(Xv,aTe),e(aTe,MKo),e(Xv,EKo),e(Xv,PU),e(PU,CKo),e(Xv,wKo),e(Y$,AKo),e(Y$,zv),e(zv,nTe),e(nTe,LKo),e(zv,yKo),e(zv,BU),e(BU,xKo),e(zv,$Ko),e(ro,kKo),e(ro,Qv),e(Qv,SKo),e(Qv,sTe),e(sTe,RKo),e(Qv,PKo),e(Qv,lTe),e(lTe,BKo),e(ro,IKo),M(Wv,ro,null),b(c,xto,_),b(c,Od,_),e(Od,Uv),e(Uv,iTe),M(Z$,iTe,null),e(Od,NKo),e(Od,dTe),e(dTe,qKo),b(c,$to,_),b(c,Do,_),M(K$,Do,null),e(Do,jKo),e(Do,Vd),e(Vd,DKo),e(Vd,IU),e(IU,GKo),e(Vd,OKo),e(Vd,NU),e(NU,VKo),e(Vd,XKo),e(Do,zKo),e(Do,ek),e(ek,QKo),e(ek,mTe),e(mTe,WKo),e(ek,UKo),e(Do,HKo),e(Do,wt),M(ok,wt,null),e(wt,JKo),e(wt,cTe),e(cTe,YKo),e(wt,ZKo),e(wt,Xd),e(Xd,KKo),e(Xd,fTe),e(fTe,eer),e(Xd,oer),e(Xd,qU),e(qU,rer),e(Xd,ter),e(wt,aer),M(Hv,wt,null),e(Do,ner),e(Do,to),M(rk,to,null),e(to,ser),e(to,gTe),e(gTe,ler),e(to,ier),e(to,dn),e(dn,der),e(dn,hTe),e(hTe,mer),e(dn,cer),e(dn,uTe),e(uTe,fer),e(dn,ger),e(dn,pTe),e(pTe,her),e(dn,uer),e(to,per),e(to,Y),e(Y,Jv),e(Jv,_Te),e(_Te,_er),e(Jv,ber),e(Jv,jU),e(jU,ver),e(Jv,Fer),e(Y,Ter),e(Y,Yv),e(Yv,bTe),e(bTe,Mer),e(Yv,Eer),e(Yv,DU),e(DU,Cer),e(Yv,wer),e(Y,Aer),e(Y,Zv),e(Zv,vTe),e(vTe,Ler),e(Zv,yer),e(Zv,GU),e(GU,xer),e(Zv,$er),e(Y,ker),e(Y,Kv),e(Kv,FTe),e(FTe,Ser),e(Kv,Rer),e(Kv,OU),e(OU,Per),e(Kv,Ber),e(Y,Ier),e(Y,eF),e(eF,TTe),e(TTe,Ner),e(eF,qer),e(eF,VU),e(VU,jer),e(eF,Der),e(Y,Ger),e(Y,oF),e(oF,MTe),e(MTe,Oer),e(oF,Ver),e(oF,XU),e(XU,Xer),e(oF,zer),e(Y,Qer),e(Y,rF),e(rF,ETe),e(ETe,Wer),e(rF,Uer),e(rF,zU),e(zU,Her),e(rF,Jer),e(Y,Yer),e(Y,tF),e(tF,CTe),e(CTe,Zer),e(tF,Ker),e(tF,QU),e(QU,eor),e(tF,oor),e(Y,ror),e(Y,aF),e(aF,wTe),e(wTe,tor),e(aF,aor),e(aF,WU),e(WU,nor),e(aF,sor),e(Y,lor),e(Y,nF),e(nF,ATe),e(ATe,ior),e(nF,dor),e(nF,UU),e(UU,mor),e(nF,cor),e(Y,gor),e(Y,sF),e(sF,LTe),e(LTe,hor),e(sF,uor),e(sF,HU),e(HU,por),e(sF,_or),e(Y,bor),e(Y,lF),e(lF,yTe),e(yTe,vor),e(lF,For),e(lF,JU),e(JU,Tor),e(lF,Mor),e(Y,Eor),e(Y,iF),e(iF,xTe),e(xTe,Cor),e(iF,wor),e(iF,YU),e(YU,Aor),e(iF,Lor),e(Y,yor),e(Y,dF),e(dF,$Te),e($Te,xor),e(dF,$or),e(dF,ZU),e(ZU,kor),e(dF,Sor),e(Y,Ror),e(Y,mF),e(mF,kTe),e(kTe,Por),e(mF,Bor),e(mF,KU),e(KU,Ior),e(mF,Nor),e(Y,qor),e(Y,cF),e(cF,STe),e(STe,jor),e(cF,Dor),e(cF,eH),e(eH,Gor),e(cF,Oor),e(Y,Vor),e(Y,fF),e(fF,RTe),e(RTe,Xor),e(fF,zor),e(fF,oH),e(oH,Qor),e(fF,Wor),e(Y,Uor),e(Y,gF),e(gF,PTe),e(PTe,Hor),e(gF,Jor),e(gF,rH),e(rH,Yor),e(gF,Zor),e(Y,Kor),e(Y,hF),e(hF,BTe),e(BTe,err),e(hF,orr),e(hF,tH),e(tH,rrr),e(hF,trr),e(Y,arr),e(Y,uF),e(uF,ITe),e(ITe,nrr),e(uF,srr),e(uF,aH),e(aH,lrr),e(uF,irr),e(Y,drr),e(Y,pF),e(pF,NTe),e(NTe,mrr),e(pF,crr),e(pF,nH),e(nH,frr),e(pF,grr),e(Y,hrr),e(Y,_F),e(_F,qTe),e(qTe,urr),e(_F,prr),e(_F,sH),e(sH,_rr),e(_F,brr),e(Y,vrr),e(Y,bF),e(bF,jTe),e(jTe,Frr),e(bF,Trr),e(bF,lH),e(lH,Mrr),e(bF,Err),e(Y,Crr),e(Y,vF),e(vF,DTe),e(DTe,wrr),e(vF,Arr),e(vF,iH),e(iH,Lrr),e(vF,yrr),e(Y,xrr),e(Y,FF),e(FF,GTe),e(GTe,$rr),e(FF,krr),e(FF,dH),e(dH,Srr),e(FF,Rrr),e(Y,Prr),e(Y,TF),e(TF,OTe),e(OTe,Brr),e(TF,Irr),e(TF,mH),e(mH,Nrr),e(TF,qrr),e(Y,jrr),e(Y,MF),e(MF,VTe),e(VTe,Drr),e(MF,Grr),e(MF,cH),e(cH,Orr),e(MF,Vrr),e(Y,Xrr),e(Y,EF),e(EF,XTe),e(XTe,zrr),e(EF,Qrr),e(EF,fH),e(fH,Wrr),e(EF,Urr),e(Y,Hrr),e(Y,CF),e(CF,zTe),e(zTe,Jrr),e(CF,Yrr),e(CF,gH),e(gH,Zrr),e(CF,Krr),e(Y,etr),e(Y,wF),e(wF,QTe),e(QTe,otr),e(wF,rtr),e(wF,hH),e(hH,ttr),e(wF,atr),e(Y,ntr),e(Y,AF),e(AF,WTe),e(WTe,str),e(AF,ltr),e(AF,uH),e(uH,itr),e(AF,dtr),e(Y,mtr),e(Y,LF),e(LF,UTe),e(UTe,ctr),e(LF,ftr),e(LF,pH),e(pH,gtr),e(LF,htr),e(Y,utr),e(Y,yF),e(yF,HTe),e(HTe,ptr),e(yF,_tr),e(yF,_H),e(_H,btr),e(yF,vtr),e(Y,Ftr),e(Y,xF),e(xF,JTe),e(JTe,Ttr),e(xF,Mtr),e(xF,bH),e(bH,Etr),e(xF,Ctr),e(Y,wtr),e(Y,$F),e($F,YTe),e(YTe,Atr),e($F,Ltr),e($F,ZTe),e(ZTe,ytr),e($F,xtr),e(Y,$tr),e(Y,kF),e(kF,KTe),e(KTe,ktr),e(kF,Str),e(kF,vH),e(vH,Rtr),e(kF,Ptr),e(Y,Btr),e(Y,SF),e(SF,eMe),e(eMe,Itr),e(SF,Ntr),e(SF,FH),e(FH,qtr),e(SF,jtr),e(Y,Dtr),e(Y,RF),e(RF,oMe),e(oMe,Gtr),e(RF,Otr),e(RF,TH),e(TH,Vtr),e(RF,Xtr),e(Y,ztr),e(Y,PF),e(PF,rMe),e(rMe,Qtr),e(PF,Wtr),e(PF,MH),e(MH,Utr),e(PF,Htr),e(to,Jtr),e(to,BF),e(BF,Ytr),e(BF,tMe),e(tMe,Ztr),e(BF,Ktr),e(BF,aMe),e(aMe,ear),e(to,oar),M(IF,to,null),b(c,kto,_),b(c,zd,_),e(zd,NF),e(NF,nMe),M(tk,nMe,null),e(zd,rar),e(zd,sMe),e(sMe,tar),b(c,Sto,_),b(c,Go,_),M(ak,Go,null),e(Go,aar),e(Go,Qd),e(Qd,nar),e(Qd,EH),e(EH,sar),e(Qd,lar),e(Qd,CH),e(CH,iar),e(Qd,dar),e(Go,mar),e(Go,nk),e(nk,car),e(nk,lMe),e(lMe,far),e(nk,gar),e(Go,har),e(Go,At),M(sk,At,null),e(At,uar),e(At,iMe),e(iMe,par),e(At,_ar),e(At,Wd),e(Wd,bar),e(Wd,dMe),e(dMe,Far),e(Wd,Tar),e(Wd,wH),e(wH,Mar),e(Wd,Ear),e(At,Car),M(qF,At,null),e(Go,war),e(Go,ao),M(lk,ao,null),e(ao,Aar),e(ao,mMe),e(mMe,Lar),e(ao,yar),e(ao,mn),e(mn,xar),e(mn,cMe),e(cMe,$ar),e(mn,kar),e(mn,fMe),e(fMe,Sar),e(mn,Rar),e(mn,gMe),e(gMe,Par),e(mn,Bar),e(ao,Iar),e(ao,he),e(he,jF),e(jF,hMe),e(hMe,Nar),e(jF,qar),e(jF,AH),e(AH,jar),e(jF,Dar),e(he,Gar),e(he,DF),e(DF,uMe),e(uMe,Oar),e(DF,Var),e(DF,LH),e(LH,Xar),e(DF,zar),e(he,Qar),e(he,GF),e(GF,pMe),e(pMe,War),e(GF,Uar),e(GF,yH),e(yH,Har),e(GF,Jar),e(he,Yar),e(he,OF),e(OF,_Me),e(_Me,Zar),e(OF,Kar),e(OF,xH),e(xH,enr),e(OF,onr),e(he,rnr),e(he,VF),e(VF,bMe),e(bMe,tnr),e(VF,anr),e(VF,$H),e($H,nnr),e(VF,snr),e(he,lnr),e(he,XF),e(XF,vMe),e(vMe,inr),e(XF,dnr),e(XF,kH),e(kH,mnr),e(XF,cnr),e(he,fnr),e(he,zF),e(zF,FMe),e(FMe,gnr),e(zF,hnr),e(zF,SH),e(SH,unr),e(zF,pnr),e(he,_nr),e(he,QF),e(QF,TMe),e(TMe,bnr),e(QF,vnr),e(QF,RH),e(RH,Fnr),e(QF,Tnr),e(he,Mnr),e(he,WF),e(WF,MMe),e(MMe,Enr),e(WF,Cnr),e(WF,PH),e(PH,wnr),e(WF,Anr),e(he,Lnr),e(he,UF),e(UF,EMe),e(EMe,ynr),e(UF,xnr),e(UF,BH),e(BH,$nr),e(UF,knr),e(he,Snr),e(he,HF),e(HF,CMe),e(CMe,Rnr),e(HF,Pnr),e(HF,IH),e(IH,Bnr),e(HF,Inr),e(he,Nnr),e(he,JF),e(JF,wMe),e(wMe,qnr),e(JF,jnr),e(JF,NH),e(NH,Dnr),e(JF,Gnr),e(he,Onr),e(he,YF),e(YF,AMe),e(AMe,Vnr),e(YF,Xnr),e(YF,qH),e(qH,znr),e(YF,Qnr),e(he,Wnr),e(he,ZF),e(ZF,LMe),e(LMe,Unr),e(ZF,Hnr),e(ZF,jH),e(jH,Jnr),e(ZF,Ynr),e(he,Znr),e(he,KF),e(KF,yMe),e(yMe,Knr),e(KF,esr),e(KF,DH),e(DH,osr),e(KF,rsr),e(he,tsr),e(he,eT),e(eT,xMe),e(xMe,asr),e(eT,nsr),e(eT,GH),e(GH,ssr),e(eT,lsr),e(he,isr),e(he,oT),e(oT,$Me),e($Me,dsr),e(oT,msr),e(oT,OH),e(OH,csr),e(oT,fsr),e(he,gsr),e(he,rT),e(rT,kMe),e(kMe,hsr),e(rT,usr),e(rT,VH),e(VH,psr),e(rT,_sr),e(he,bsr),e(he,tT),e(tT,SMe),e(SMe,vsr),e(tT,Fsr),e(tT,XH),e(XH,Tsr),e(tT,Msr),e(he,Esr),e(he,aT),e(aT,RMe),e(RMe,Csr),e(aT,wsr),e(aT,zH),e(zH,Asr),e(aT,Lsr),e(ao,ysr),e(ao,nT),e(nT,xsr),e(nT,PMe),e(PMe,$sr),e(nT,ksr),e(nT,BMe),e(BMe,Ssr),e(ao,Rsr),M(sT,ao,null),b(c,Rto,_),b(c,Ud,_),e(Ud,lT),e(lT,IMe),M(ik,IMe,null),e(Ud,Psr),e(Ud,NMe),e(NMe,Bsr),b(c,Pto,_),b(c,Oo,_),M(dk,Oo,null),e(Oo,Isr),e(Oo,Hd),e(Hd,Nsr),e(Hd,QH),e(QH,qsr),e(Hd,jsr),e(Hd,WH),e(WH,Dsr),e(Hd,Gsr),e(Oo,Osr),e(Oo,mk),e(mk,Vsr),e(mk,qMe),e(qMe,Xsr),e(mk,zsr),e(Oo,Qsr),e(Oo,Lt),M(ck,Lt,null),e(Lt,Wsr),e(Lt,jMe),e(jMe,Usr),e(Lt,Hsr),e(Lt,Jd),e(Jd,Jsr),e(Jd,DMe),e(DMe,Ysr),e(Jd,Zsr),e(Jd,UH),e(UH,Ksr),e(Jd,elr),e(Lt,olr),M(iT,Lt,null),e(Oo,rlr),e(Oo,no),M(fk,no,null),e(no,tlr),e(no,GMe),e(GMe,alr),e(no,nlr),e(no,cn),e(cn,slr),e(cn,OMe),e(OMe,llr),e(cn,ilr),e(cn,VMe),e(VMe,dlr),e(cn,mlr),e(cn,XMe),e(XMe,clr),e(cn,flr),e(no,glr),e(no,j),e(j,dT),e(dT,zMe),e(zMe,hlr),e(dT,ulr),e(dT,HH),e(HH,plr),e(dT,_lr),e(j,blr),e(j,mT),e(mT,QMe),e(QMe,vlr),e(mT,Flr),e(mT,JH),e(JH,Tlr),e(mT,Mlr),e(j,Elr),e(j,cT),e(cT,WMe),e(WMe,Clr),e(cT,wlr),e(cT,YH),e(YH,Alr),e(cT,Llr),e(j,ylr),e(j,fT),e(fT,UMe),e(UMe,xlr),e(fT,$lr),e(fT,ZH),e(ZH,klr),e(fT,Slr),e(j,Rlr),e(j,gT),e(gT,HMe),e(HMe,Plr),e(gT,Blr),e(gT,KH),e(KH,Ilr),e(gT,Nlr),e(j,qlr),e(j,hT),e(hT,JMe),e(JMe,jlr),e(hT,Dlr),e(hT,eJ),e(eJ,Glr),e(hT,Olr),e(j,Vlr),e(j,uT),e(uT,YMe),e(YMe,Xlr),e(uT,zlr),e(uT,oJ),e(oJ,Qlr),e(uT,Wlr),e(j,Ulr),e(j,pT),e(pT,ZMe),e(ZMe,Hlr),e(pT,Jlr),e(pT,rJ),e(rJ,Ylr),e(pT,Zlr),e(j,Klr),e(j,_T),e(_T,KMe),e(KMe,eir),e(_T,oir),e(_T,tJ),e(tJ,rir),e(_T,tir),e(j,air),e(j,bT),e(bT,eEe),e(eEe,nir),e(bT,sir),e(bT,aJ),e(aJ,lir),e(bT,iir),e(j,dir),e(j,vT),e(vT,oEe),e(oEe,mir),e(vT,cir),e(vT,nJ),e(nJ,fir),e(vT,gir),e(j,hir),e(j,FT),e(FT,rEe),e(rEe,uir),e(FT,pir),e(FT,sJ),e(sJ,_ir),e(FT,bir),e(j,vir),e(j,TT),e(TT,tEe),e(tEe,Fir),e(TT,Tir),e(TT,lJ),e(lJ,Mir),e(TT,Eir),e(j,Cir),e(j,MT),e(MT,aEe),e(aEe,wir),e(MT,Air),e(MT,iJ),e(iJ,Lir),e(MT,yir),e(j,xir),e(j,ET),e(ET,nEe),e(nEe,$ir),e(ET,kir),e(ET,dJ),e(dJ,Sir),e(ET,Rir),e(j,Pir),e(j,CT),e(CT,sEe),e(sEe,Bir),e(CT,Iir),e(CT,mJ),e(mJ,Nir),e(CT,qir),e(j,jir),e(j,wT),e(wT,lEe),e(lEe,Dir),e(wT,Gir),e(wT,cJ),e(cJ,Oir),e(wT,Vir),e(j,Xir),e(j,AT),e(AT,iEe),e(iEe,zir),e(AT,Qir),e(AT,fJ),e(fJ,Wir),e(AT,Uir),e(j,Hir),e(j,LT),e(LT,dEe),e(dEe,Jir),e(LT,Yir),e(LT,gJ),e(gJ,Zir),e(LT,Kir),e(j,edr),e(j,yT),e(yT,mEe),e(mEe,odr),e(yT,rdr),e(yT,hJ),e(hJ,tdr),e(yT,adr),e(j,ndr),e(j,xT),e(xT,cEe),e(cEe,sdr),e(xT,ldr),e(xT,uJ),e(uJ,idr),e(xT,ddr),e(j,mdr),e(j,$T),e($T,fEe),e(fEe,cdr),e($T,fdr),e($T,pJ),e(pJ,gdr),e($T,hdr),e(j,udr),e(j,kT),e(kT,gEe),e(gEe,pdr),e(kT,_dr),e(kT,_J),e(_J,bdr),e(kT,vdr),e(j,Fdr),e(j,ST),e(ST,hEe),e(hEe,Tdr),e(ST,Mdr),e(ST,bJ),e(bJ,Edr),e(ST,Cdr),e(j,wdr),e(j,RT),e(RT,uEe),e(uEe,Adr),e(RT,Ldr),e(RT,vJ),e(vJ,ydr),e(RT,xdr),e(j,$dr),e(j,PT),e(PT,pEe),e(pEe,kdr),e(PT,Sdr),e(PT,FJ),e(FJ,Rdr),e(PT,Pdr),e(j,Bdr),e(j,BT),e(BT,_Ee),e(_Ee,Idr),e(BT,Ndr),e(BT,TJ),e(TJ,qdr),e(BT,jdr),e(j,Ddr),e(j,IT),e(IT,bEe),e(bEe,Gdr),e(IT,Odr),e(IT,MJ),e(MJ,Vdr),e(IT,Xdr),e(j,zdr),e(j,NT),e(NT,vEe),e(vEe,Qdr),e(NT,Wdr),e(NT,EJ),e(EJ,Udr),e(NT,Hdr),e(j,Jdr),e(j,qT),e(qT,FEe),e(FEe,Ydr),e(qT,Zdr),e(qT,CJ),e(CJ,Kdr),e(qT,emr),e(j,omr),e(j,jT),e(jT,TEe),e(TEe,rmr),e(jT,tmr),e(jT,wJ),e(wJ,amr),e(jT,nmr),e(j,smr),e(j,DT),e(DT,MEe),e(MEe,lmr),e(DT,imr),e(DT,AJ),e(AJ,dmr),e(DT,mmr),e(j,cmr),e(j,GT),e(GT,EEe),e(EEe,fmr),e(GT,gmr),e(GT,LJ),e(LJ,hmr),e(GT,umr),e(j,pmr),e(j,OT),e(OT,CEe),e(CEe,_mr),e(OT,bmr),e(OT,yJ),e(yJ,vmr),e(OT,Fmr),e(j,Tmr),e(j,VT),e(VT,wEe),e(wEe,Mmr),e(VT,Emr),e(VT,xJ),e(xJ,Cmr),e(VT,wmr),e(j,Amr),e(j,XT),e(XT,AEe),e(AEe,Lmr),e(XT,ymr),e(XT,$J),e($J,xmr),e(XT,$mr),e(j,kmr),e(j,zT),e(zT,LEe),e(LEe,Smr),e(zT,Rmr),e(zT,kJ),e(kJ,Pmr),e(zT,Bmr),e(j,Imr),e(j,QT),e(QT,yEe),e(yEe,Nmr),e(QT,qmr),e(QT,SJ),e(SJ,jmr),e(QT,Dmr),e(j,Gmr),e(j,WT),e(WT,xEe),e(xEe,Omr),e(WT,Vmr),e(WT,RJ),e(RJ,Xmr),e(WT,zmr),e(j,Qmr),e(j,UT),e(UT,$Ee),e($Ee,Wmr),e(UT,Umr),e(UT,PJ),e(PJ,Hmr),e(UT,Jmr),e(j,Ymr),e(j,HT),e(HT,kEe),e(kEe,Zmr),e(HT,Kmr),e(HT,BJ),e(BJ,ecr),e(HT,ocr),e(j,rcr),e(j,JT),e(JT,SEe),e(SEe,tcr),e(JT,acr),e(JT,IJ),e(IJ,ncr),e(JT,scr),e(j,lcr),e(j,YT),e(YT,REe),e(REe,icr),e(YT,dcr),e(YT,NJ),e(NJ,mcr),e(YT,ccr),e(j,fcr),e(j,ZT),e(ZT,PEe),e(PEe,gcr),e(ZT,hcr),e(ZT,qJ),e(qJ,ucr),e(ZT,pcr),e(j,_cr),e(j,KT),e(KT,BEe),e(BEe,bcr),e(KT,vcr),e(KT,jJ),e(jJ,Fcr),e(KT,Tcr),e(j,Mcr),e(j,eM),e(eM,IEe),e(IEe,Ecr),e(eM,Ccr),e(eM,DJ),e(DJ,wcr),e(eM,Acr),e(j,Lcr),e(j,oM),e(oM,NEe),e(NEe,ycr),e(oM,xcr),e(oM,GJ),e(GJ,$cr),e(oM,kcr),e(j,Scr),e(j,rM),e(rM,qEe),e(qEe,Rcr),e(rM,Pcr),e(rM,OJ),e(OJ,Bcr),e(rM,Icr),e(j,Ncr),e(j,tM),e(tM,jEe),e(jEe,qcr),e(tM,jcr),e(tM,VJ),e(VJ,Dcr),e(tM,Gcr),e(j,Ocr),e(j,aM),e(aM,DEe),e(DEe,Vcr),e(aM,Xcr),e(aM,XJ),e(XJ,zcr),e(aM,Qcr),e(j,Wcr),e(j,nM),e(nM,GEe),e(GEe,Ucr),e(nM,Hcr),e(nM,zJ),e(zJ,Jcr),e(nM,Ycr),e(j,Zcr),e(j,sM),e(sM,OEe),e(OEe,Kcr),e(sM,efr),e(sM,QJ),e(QJ,ofr),e(sM,rfr),e(j,tfr),e(j,lM),e(lM,VEe),e(VEe,afr),e(lM,nfr),e(lM,WJ),e(WJ,sfr),e(lM,lfr),e(j,ifr),e(j,iM),e(iM,XEe),e(XEe,dfr),e(iM,mfr),e(iM,UJ),e(UJ,cfr),e(iM,ffr),e(j,gfr),e(j,dM),e(dM,zEe),e(zEe,hfr),e(dM,ufr),e(dM,HJ),e(HJ,pfr),e(dM,_fr),e(j,bfr),e(j,mM),e(mM,QEe),e(QEe,vfr),e(mM,Ffr),e(mM,JJ),e(JJ,Tfr),e(mM,Mfr),e(no,Efr),e(no,cM),e(cM,Cfr),e(cM,WEe),e(WEe,wfr),e(cM,Afr),e(cM,UEe),e(UEe,Lfr),e(no,yfr),M(fM,no,null),b(c,Bto,_),b(c,Yd,_),e(Yd,gM),e(gM,HEe),M(gk,HEe,null),e(Yd,xfr),e(Yd,JEe),e(JEe,$fr),b(c,Ito,_),b(c,Vo,_),M(hk,Vo,null),e(Vo,kfr),e(Vo,Zd),e(Zd,Sfr),e(Zd,YJ),e(YJ,Rfr),e(Zd,Pfr),e(Zd,ZJ),e(ZJ,Bfr),e(Zd,Ifr),e(Vo,Nfr),e(Vo,uk),e(uk,qfr),e(uk,YEe),e(YEe,jfr),e(uk,Dfr),e(Vo,Gfr),e(Vo,yt),M(pk,yt,null),e(yt,Ofr),e(yt,ZEe),e(ZEe,Vfr),e(yt,Xfr),e(yt,Kd),e(Kd,zfr),e(Kd,KEe),e(KEe,Qfr),e(Kd,Wfr),e(Kd,KJ),e(KJ,Ufr),e(Kd,Hfr),e(yt,Jfr),M(hM,yt,null),e(Vo,Yfr),e(Vo,so),M(_k,so,null),e(so,Zfr),e(so,e4e),e(e4e,Kfr),e(so,egr),e(so,fn),e(fn,ogr),e(fn,o4e),e(o4e,rgr),e(fn,tgr),e(fn,r4e),e(r4e,agr),e(fn,ngr),e(fn,t4e),e(t4e,sgr),e(fn,lgr),e(so,igr),e(so,K),e(K,uM),e(uM,a4e),e(a4e,dgr),e(uM,mgr),e(uM,eY),e(eY,cgr),e(uM,fgr),e(K,ggr),e(K,pM),e(pM,n4e),e(n4e,hgr),e(pM,ugr),e(pM,oY),e(oY,pgr),e(pM,_gr),e(K,bgr),e(K,_M),e(_M,s4e),e(s4e,vgr),e(_M,Fgr),e(_M,rY),e(rY,Tgr),e(_M,Mgr),e(K,Egr),e(K,bM),e(bM,l4e),e(l4e,Cgr),e(bM,wgr),e(bM,tY),e(tY,Agr),e(bM,Lgr),e(K,ygr),e(K,vM),e(vM,i4e),e(i4e,xgr),e(vM,$gr),e(vM,aY),e(aY,kgr),e(vM,Sgr),e(K,Rgr),e(K,FM),e(FM,d4e),e(d4e,Pgr),e(FM,Bgr),e(FM,nY),e(nY,Igr),e(FM,Ngr),e(K,qgr),e(K,TM),e(TM,m4e),e(m4e,jgr),e(TM,Dgr),e(TM,sY),e(sY,Ggr),e(TM,Ogr),e(K,Vgr),e(K,MM),e(MM,c4e),e(c4e,Xgr),e(MM,zgr),e(MM,lY),e(lY,Qgr),e(MM,Wgr),e(K,Ugr),e(K,EM),e(EM,f4e),e(f4e,Hgr),e(EM,Jgr),e(EM,iY),e(iY,Ygr),e(EM,Zgr),e(K,Kgr),e(K,CM),e(CM,g4e),e(g4e,ehr),e(CM,ohr),e(CM,dY),e(dY,rhr),e(CM,thr),e(K,ahr),e(K,wM),e(wM,h4e),e(h4e,nhr),e(wM,shr),e(wM,mY),e(mY,lhr),e(wM,ihr),e(K,dhr),e(K,AM),e(AM,u4e),e(u4e,mhr),e(AM,chr),e(AM,cY),e(cY,fhr),e(AM,ghr),e(K,hhr),e(K,LM),e(LM,p4e),e(p4e,uhr),e(LM,phr),e(LM,fY),e(fY,_hr),e(LM,bhr),e(K,vhr),e(K,yM),e(yM,_4e),e(_4e,Fhr),e(yM,Thr),e(yM,gY),e(gY,Mhr),e(yM,Ehr),e(K,Chr),e(K,xM),e(xM,b4e),e(b4e,whr),e(xM,Ahr),e(xM,hY),e(hY,Lhr),e(xM,yhr),e(K,xhr),e(K,$M),e($M,v4e),e(v4e,$hr),e($M,khr),e($M,uY),e(uY,Shr),e($M,Rhr),e(K,Phr),e(K,kM),e(kM,F4e),e(F4e,Bhr),e(kM,Ihr),e(kM,pY),e(pY,Nhr),e(kM,qhr),e(K,jhr),e(K,SM),e(SM,T4e),e(T4e,Dhr),e(SM,Ghr),e(SM,_Y),e(_Y,Ohr),e(SM,Vhr),e(K,Xhr),e(K,RM),e(RM,M4e),e(M4e,zhr),e(RM,Qhr),e(RM,bY),e(bY,Whr),e(RM,Uhr),e(K,Hhr),e(K,PM),e(PM,E4e),e(E4e,Jhr),e(PM,Yhr),e(PM,vY),e(vY,Zhr),e(PM,Khr),e(K,eur),e(K,BM),e(BM,C4e),e(C4e,our),e(BM,rur),e(BM,FY),e(FY,tur),e(BM,aur),e(K,nur),e(K,IM),e(IM,w4e),e(w4e,sur),e(IM,lur),e(IM,TY),e(TY,iur),e(IM,dur),e(K,mur),e(K,NM),e(NM,A4e),e(A4e,cur),e(NM,fur),e(NM,MY),e(MY,gur),e(NM,hur),e(K,uur),e(K,qM),e(qM,L4e),e(L4e,pur),e(qM,_ur),e(qM,EY),e(EY,bur),e(qM,vur),e(K,Fur),e(K,jM),e(jM,y4e),e(y4e,Tur),e(jM,Mur),e(jM,CY),e(CY,Eur),e(jM,Cur),e(K,wur),e(K,DM),e(DM,x4e),e(x4e,Aur),e(DM,Lur),e(DM,wY),e(wY,yur),e(DM,xur),e(K,$ur),e(K,GM),e(GM,$4e),e($4e,kur),e(GM,Sur),e(GM,AY),e(AY,Rur),e(GM,Pur),e(K,Bur),e(K,OM),e(OM,k4e),e(k4e,Iur),e(OM,Nur),e(OM,LY),e(LY,qur),e(OM,jur),e(K,Dur),e(K,VM),e(VM,S4e),e(S4e,Gur),e(VM,Our),e(VM,yY),e(yY,Vur),e(VM,Xur),e(K,zur),e(K,XM),e(XM,R4e),e(R4e,Qur),e(XM,Wur),e(XM,xY),e(xY,Uur),e(XM,Hur),e(K,Jur),e(K,zM),e(zM,P4e),e(P4e,Yur),e(zM,Zur),e(zM,$Y),e($Y,Kur),e(zM,epr),e(K,opr),e(K,QM),e(QM,B4e),e(B4e,rpr),e(QM,tpr),e(QM,kY),e(kY,apr),e(QM,npr),e(so,spr),e(so,WM),e(WM,lpr),e(WM,I4e),e(I4e,ipr),e(WM,dpr),e(WM,N4e),e(N4e,mpr),e(so,cpr),M(UM,so,null),b(c,Nto,_),b(c,em,_),e(em,HM),e(HM,q4e),M(bk,q4e,null),e(em,fpr),e(em,j4e),e(j4e,gpr),b(c,qto,_),b(c,Xo,_),M(vk,Xo,null),e(Xo,hpr),e(Xo,om),e(om,upr),e(om,SY),e(SY,ppr),e(om,_pr),e(om,RY),e(RY,bpr),e(om,vpr),e(Xo,Fpr),e(Xo,Fk),e(Fk,Tpr),e(Fk,D4e),e(D4e,Mpr),e(Fk,Epr),e(Xo,Cpr),e(Xo,xt),M(Tk,xt,null),e(xt,wpr),e(xt,G4e),e(G4e,Apr),e(xt,Lpr),e(xt,rm),e(rm,ypr),e(rm,O4e),e(O4e,xpr),e(rm,$pr),e(rm,PY),e(PY,kpr),e(rm,Spr),e(xt,Rpr),M(JM,xt,null),e(Xo,Ppr),e(Xo,lo),M(Mk,lo,null),e(lo,Bpr),e(lo,V4e),e(V4e,Ipr),e(lo,Npr),e(lo,gn),e(gn,qpr),e(gn,X4e),e(X4e,jpr),e(gn,Dpr),e(gn,z4e),e(z4e,Gpr),e(gn,Opr),e(gn,Q4e),e(Q4e,Vpr),e(gn,Xpr),e(lo,zpr),e(lo,Ue),e(Ue,YM),e(YM,W4e),e(W4e,Qpr),e(YM,Wpr),e(YM,BY),e(BY,Upr),e(YM,Hpr),e(Ue,Jpr),e(Ue,ZM),e(ZM,U4e),e(U4e,Ypr),e(ZM,Zpr),e(ZM,IY),e(IY,Kpr),e(ZM,e_r),e(Ue,o_r),e(Ue,KM),e(KM,H4e),e(H4e,r_r),e(KM,t_r),e(KM,NY),e(NY,a_r),e(KM,n_r),e(Ue,s_r),e(Ue,eE),e(eE,J4e),e(J4e,l_r),e(eE,i_r),e(eE,qY),e(qY,d_r),e(eE,m_r),e(Ue,c_r),e(Ue,oE),e(oE,Y4e),e(Y4e,f_r),e(oE,g_r),e(oE,jY),e(jY,h_r),e(oE,u_r),e(Ue,p_r),e(Ue,rE),e(rE,Z4e),e(Z4e,__r),e(rE,b_r),e(rE,DY),e(DY,v_r),e(rE,F_r),e(Ue,T_r),e(Ue,tE),e(tE,K4e),e(K4e,M_r),e(tE,E_r),e(tE,GY),e(GY,C_r),e(tE,w_r),e(lo,A_r),e(lo,aE),e(aE,L_r),e(aE,eCe),e(eCe,y_r),e(aE,x_r),e(aE,oCe),e(oCe,$_r),e(lo,k_r),M(nE,lo,null),b(c,jto,_),b(c,tm,_),e(tm,sE),e(sE,rCe),M(Ek,rCe,null),e(tm,S_r),e(tm,tCe),e(tCe,R_r),b(c,Dto,_),b(c,zo,_),M(Ck,zo,null),e(zo,P_r),e(zo,am),e(am,B_r),e(am,OY),e(OY,I_r),e(am,N_r),e(am,VY),e(VY,q_r),e(am,j_r),e(zo,D_r),e(zo,wk),e(wk,G_r),e(wk,aCe),e(aCe,O_r),e(wk,V_r),e(zo,X_r),e(zo,$t),M(Ak,$t,null),e($t,z_r),e($t,nCe),e(nCe,Q_r),e($t,W_r),e($t,nm),e(nm,U_r),e(nm,sCe),e(sCe,H_r),e(nm,J_r),e(nm,XY),e(XY,Y_r),e(nm,Z_r),e($t,K_r),M(lE,$t,null),e(zo,e1r),e(zo,io),M(Lk,io,null),e(io,o1r),e(io,lCe),e(lCe,r1r),e(io,t1r),e(io,hn),e(hn,a1r),e(hn,iCe),e(iCe,n1r),e(hn,s1r),e(hn,dCe),e(dCe,l1r),e(hn,i1r),e(hn,mCe),e(mCe,d1r),e(hn,m1r),e(io,c1r),e(io,U),e(U,iE),e(iE,cCe),e(cCe,f1r),e(iE,g1r),e(iE,zY),e(zY,h1r),e(iE,u1r),e(U,p1r),e(U,dE),e(dE,fCe),e(fCe,_1r),e(dE,b1r),e(dE,QY),e(QY,v1r),e(dE,F1r),e(U,T1r),e(U,mE),e(mE,gCe),e(gCe,M1r),e(mE,E1r),e(mE,WY),e(WY,C1r),e(mE,w1r),e(U,A1r),e(U,cE),e(cE,hCe),e(hCe,L1r),e(cE,y1r),e(cE,UY),e(UY,x1r),e(cE,$1r),e(U,k1r),e(U,fE),e(fE,uCe),e(uCe,S1r),e(fE,R1r),e(fE,HY),e(HY,P1r),e(fE,B1r),e(U,I1r),e(U,gE),e(gE,pCe),e(pCe,N1r),e(gE,q1r),e(gE,JY),e(JY,j1r),e(gE,D1r),e(U,G1r),e(U,hE),e(hE,_Ce),e(_Ce,O1r),e(hE,V1r),e(hE,YY),e(YY,X1r),e(hE,z1r),e(U,Q1r),e(U,uE),e(uE,bCe),e(bCe,W1r),e(uE,U1r),e(uE,ZY),e(ZY,H1r),e(uE,J1r),e(U,Y1r),e(U,pE),e(pE,vCe),e(vCe,Z1r),e(pE,K1r),e(pE,KY),e(KY,e2r),e(pE,o2r),e(U,r2r),e(U,_E),e(_E,FCe),e(FCe,t2r),e(_E,a2r),e(_E,eZ),e(eZ,n2r),e(_E,s2r),e(U,l2r),e(U,bE),e(bE,TCe),e(TCe,i2r),e(bE,d2r),e(bE,oZ),e(oZ,m2r),e(bE,c2r),e(U,f2r),e(U,vE),e(vE,MCe),e(MCe,g2r),e(vE,h2r),e(vE,rZ),e(rZ,u2r),e(vE,p2r),e(U,_2r),e(U,FE),e(FE,ECe),e(ECe,b2r),e(FE,v2r),e(FE,tZ),e(tZ,F2r),e(FE,T2r),e(U,M2r),e(U,TE),e(TE,CCe),e(CCe,E2r),e(TE,C2r),e(TE,aZ),e(aZ,w2r),e(TE,A2r),e(U,L2r),e(U,ME),e(ME,wCe),e(wCe,y2r),e(ME,x2r),e(ME,nZ),e(nZ,$2r),e(ME,k2r),e(U,S2r),e(U,EE),e(EE,ACe),e(ACe,R2r),e(EE,P2r),e(EE,sZ),e(sZ,B2r),e(EE,I2r),e(U,N2r),e(U,CE),e(CE,LCe),e(LCe,q2r),e(CE,j2r),e(CE,lZ),e(lZ,D2r),e(CE,G2r),e(U,O2r),e(U,wE),e(wE,yCe),e(yCe,V2r),e(wE,X2r),e(wE,iZ),e(iZ,z2r),e(wE,Q2r),e(U,W2r),e(U,AE),e(AE,xCe),e(xCe,U2r),e(AE,H2r),e(AE,dZ),e(dZ,J2r),e(AE,Y2r),e(U,Z2r),e(U,LE),e(LE,$Ce),e($Ce,K2r),e(LE,ebr),e(LE,mZ),e(mZ,obr),e(LE,rbr),e(U,tbr),e(U,yE),e(yE,kCe),e(kCe,abr),e(yE,nbr),e(yE,cZ),e(cZ,sbr),e(yE,lbr),e(U,ibr),e(U,xE),e(xE,SCe),e(SCe,dbr),e(xE,mbr),e(xE,fZ),e(fZ,cbr),e(xE,fbr),e(U,gbr),e(U,$E),e($E,RCe),e(RCe,hbr),e($E,ubr),e($E,gZ),e(gZ,pbr),e($E,_br),e(U,bbr),e(U,kE),e(kE,PCe),e(PCe,vbr),e(kE,Fbr),e(kE,hZ),e(hZ,Tbr),e(kE,Mbr),e(U,Ebr),e(U,SE),e(SE,BCe),e(BCe,Cbr),e(SE,wbr),e(SE,uZ),e(uZ,Abr),e(SE,Lbr),e(U,ybr),e(U,RE),e(RE,ICe),e(ICe,xbr),e(RE,$br),e(RE,pZ),e(pZ,kbr),e(RE,Sbr),e(U,Rbr),e(U,PE),e(PE,NCe),e(NCe,Pbr),e(PE,Bbr),e(PE,_Z),e(_Z,Ibr),e(PE,Nbr),e(U,qbr),e(U,BE),e(BE,qCe),e(qCe,jbr),e(BE,Dbr),e(BE,bZ),e(bZ,Gbr),e(BE,Obr),e(U,Vbr),e(U,IE),e(IE,jCe),e(jCe,Xbr),e(IE,zbr),e(IE,vZ),e(vZ,Qbr),e(IE,Wbr),e(U,Ubr),e(U,NE),e(NE,DCe),e(DCe,Hbr),e(NE,Jbr),e(NE,FZ),e(FZ,Ybr),e(NE,Zbr),e(U,Kbr),e(U,qE),e(qE,GCe),e(GCe,evr),e(qE,ovr),e(qE,TZ),e(TZ,rvr),e(qE,tvr),e(U,avr),e(U,jE),e(jE,OCe),e(OCe,nvr),e(jE,svr),e(jE,MZ),e(MZ,lvr),e(jE,ivr),e(U,dvr),e(U,DE),e(DE,VCe),e(VCe,mvr),e(DE,cvr),e(DE,EZ),e(EZ,fvr),e(DE,gvr),e(U,hvr),e(U,GE),e(GE,XCe),e(XCe,uvr),e(GE,pvr),e(GE,CZ),e(CZ,_vr),e(GE,bvr),e(U,vvr),e(U,OE),e(OE,zCe),e(zCe,Fvr),e(OE,Tvr),e(OE,wZ),e(wZ,Mvr),e(OE,Evr),e(U,Cvr),e(U,VE),e(VE,QCe),e(QCe,wvr),e(VE,Avr),e(VE,AZ),e(AZ,Lvr),e(VE,yvr),e(U,xvr),e(U,XE),e(XE,WCe),e(WCe,$vr),e(XE,kvr),e(XE,LZ),e(LZ,Svr),e(XE,Rvr),e(U,Pvr),e(U,zE),e(zE,UCe),e(UCe,Bvr),e(zE,Ivr),e(zE,yZ),e(yZ,Nvr),e(zE,qvr),e(U,jvr),e(U,QE),e(QE,HCe),e(HCe,Dvr),e(QE,Gvr),e(QE,xZ),e(xZ,Ovr),e(QE,Vvr),e(U,Xvr),e(U,WE),e(WE,JCe),e(JCe,zvr),e(WE,Qvr),e(WE,$Z),e($Z,Wvr),e(WE,Uvr),e(U,Hvr),e(U,UE),e(UE,YCe),e(YCe,Jvr),e(UE,Yvr),e(UE,kZ),e(kZ,Zvr),e(UE,Kvr),e(io,eFr),e(io,HE),e(HE,oFr),e(HE,ZCe),e(ZCe,rFr),e(HE,tFr),e(HE,KCe),e(KCe,aFr),e(io,nFr),M(JE,io,null),b(c,Gto,_),b(c,sm,_),e(sm,YE),e(YE,e3e),M(yk,e3e,null),e(sm,sFr),e(sm,o3e),e(o3e,lFr),b(c,Oto,_),b(c,Qo,_),M(xk,Qo,null),e(Qo,iFr),e(Qo,lm),e(lm,dFr),e(lm,SZ),e(SZ,mFr),e(lm,cFr),e(lm,RZ),e(RZ,fFr),e(lm,gFr),e(Qo,hFr),e(Qo,$k),e($k,uFr),e($k,r3e),e(r3e,pFr),e($k,_Fr),e(Qo,bFr),e(Qo,kt),M(kk,kt,null),e(kt,vFr),e(kt,t3e),e(t3e,FFr),e(kt,TFr),e(kt,im),e(im,MFr),e(im,a3e),e(a3e,EFr),e(im,CFr),e(im,PZ),e(PZ,wFr),e(im,AFr),e(kt,LFr),M(ZE,kt,null),e(Qo,yFr),e(Qo,mo),M(Sk,mo,null),e(mo,xFr),e(mo,n3e),e(n3e,$Fr),e(mo,kFr),e(mo,un),e(un,SFr),e(un,s3e),e(s3e,RFr),e(un,PFr),e(un,l3e),e(l3e,BFr),e(un,IFr),e(un,i3e),e(i3e,NFr),e(un,qFr),e(mo,jFr),e(mo,O),e(O,KE),e(KE,d3e),e(d3e,DFr),e(KE,GFr),e(KE,BZ),e(BZ,OFr),e(KE,VFr),e(O,XFr),e(O,e4),e(e4,m3e),e(m3e,zFr),e(e4,QFr),e(e4,IZ),e(IZ,WFr),e(e4,UFr),e(O,HFr),e(O,o4),e(o4,c3e),e(c3e,JFr),e(o4,YFr),e(o4,NZ),e(NZ,ZFr),e(o4,KFr),e(O,eTr),e(O,r4),e(r4,f3e),e(f3e,oTr),e(r4,rTr),e(r4,qZ),e(qZ,tTr),e(r4,aTr),e(O,nTr),e(O,t4),e(t4,g3e),e(g3e,sTr),e(t4,lTr),e(t4,jZ),e(jZ,iTr),e(t4,dTr),e(O,mTr),e(O,a4),e(a4,h3e),e(h3e,cTr),e(a4,fTr),e(a4,DZ),e(DZ,gTr),e(a4,hTr),e(O,uTr),e(O,n4),e(n4,u3e),e(u3e,pTr),e(n4,_Tr),e(n4,GZ),e(GZ,bTr),e(n4,vTr),e(O,FTr),e(O,s4),e(s4,p3e),e(p3e,TTr),e(s4,MTr),e(s4,OZ),e(OZ,ETr),e(s4,CTr),e(O,wTr),e(O,l4),e(l4,_3e),e(_3e,ATr),e(l4,LTr),e(l4,VZ),e(VZ,yTr),e(l4,xTr),e(O,$Tr),e(O,i4),e(i4,b3e),e(b3e,kTr),e(i4,STr),e(i4,XZ),e(XZ,RTr),e(i4,PTr),e(O,BTr),e(O,d4),e(d4,v3e),e(v3e,ITr),e(d4,NTr),e(d4,zZ),e(zZ,qTr),e(d4,jTr),e(O,DTr),e(O,m4),e(m4,F3e),e(F3e,GTr),e(m4,OTr),e(m4,QZ),e(QZ,VTr),e(m4,XTr),e(O,zTr),e(O,c4),e(c4,T3e),e(T3e,QTr),e(c4,WTr),e(c4,WZ),e(WZ,UTr),e(c4,HTr),e(O,JTr),e(O,f4),e(f4,M3e),e(M3e,YTr),e(f4,ZTr),e(f4,UZ),e(UZ,KTr),e(f4,eMr),e(O,oMr),e(O,g4),e(g4,E3e),e(E3e,rMr),e(g4,tMr),e(g4,HZ),e(HZ,aMr),e(g4,nMr),e(O,sMr),e(O,h4),e(h4,C3e),e(C3e,lMr),e(h4,iMr),e(h4,JZ),e(JZ,dMr),e(h4,mMr),e(O,cMr),e(O,u4),e(u4,w3e),e(w3e,fMr),e(u4,gMr),e(u4,YZ),e(YZ,hMr),e(u4,uMr),e(O,pMr),e(O,p4),e(p4,A3e),e(A3e,_Mr),e(p4,bMr),e(p4,ZZ),e(ZZ,vMr),e(p4,FMr),e(O,TMr),e(O,_4),e(_4,L3e),e(L3e,MMr),e(_4,EMr),e(_4,KZ),e(KZ,CMr),e(_4,wMr),e(O,AMr),e(O,b4),e(b4,y3e),e(y3e,LMr),e(b4,yMr),e(b4,eK),e(eK,xMr),e(b4,$Mr),e(O,kMr),e(O,v4),e(v4,x3e),e(x3e,SMr),e(v4,RMr),e(v4,oK),e(oK,PMr),e(v4,BMr),e(O,IMr),e(O,F4),e(F4,$3e),e($3e,NMr),e(F4,qMr),e(F4,rK),e(rK,jMr),e(F4,DMr),e(O,GMr),e(O,T4),e(T4,k3e),e(k3e,OMr),e(T4,VMr),e(T4,tK),e(tK,XMr),e(T4,zMr),e(O,QMr),e(O,M4),e(M4,S3e),e(S3e,WMr),e(M4,UMr),e(M4,aK),e(aK,HMr),e(M4,JMr),e(O,YMr),e(O,E4),e(E4,R3e),e(R3e,ZMr),e(E4,KMr),e(E4,nK),e(nK,eEr),e(E4,oEr),e(O,rEr),e(O,C4),e(C4,P3e),e(P3e,tEr),e(C4,aEr),e(C4,sK),e(sK,nEr),e(C4,sEr),e(O,lEr),e(O,w4),e(w4,B3e),e(B3e,iEr),e(w4,dEr),e(w4,lK),e(lK,mEr),e(w4,cEr),e(O,fEr),e(O,A4),e(A4,I3e),e(I3e,gEr),e(A4,hEr),e(A4,iK),e(iK,uEr),e(A4,pEr),e(O,_Er),e(O,L4),e(L4,N3e),e(N3e,bEr),e(L4,vEr),e(L4,dK),e(dK,FEr),e(L4,TEr),e(O,MEr),e(O,y4),e(y4,q3e),e(q3e,EEr),e(y4,CEr),e(y4,mK),e(mK,wEr),e(y4,AEr),e(O,LEr),e(O,x4),e(x4,j3e),e(j3e,yEr),e(x4,xEr),e(x4,cK),e(cK,$Er),e(x4,kEr),e(O,SEr),e(O,$4),e($4,D3e),e(D3e,REr),e($4,PEr),e($4,fK),e(fK,BEr),e($4,IEr),e(O,NEr),e(O,k4),e(k4,G3e),e(G3e,qEr),e(k4,jEr),e(k4,gK),e(gK,DEr),e(k4,GEr),e(O,OEr),e(O,S4),e(S4,O3e),e(O3e,VEr),e(S4,XEr),e(S4,hK),e(hK,zEr),e(S4,QEr),e(O,WEr),e(O,R4),e(R4,V3e),e(V3e,UEr),e(R4,HEr),e(R4,uK),e(uK,JEr),e(R4,YEr),e(O,ZEr),e(O,P4),e(P4,X3e),e(X3e,KEr),e(P4,e4r),e(P4,pK),e(pK,o4r),e(P4,r4r),e(O,t4r),e(O,B4),e(B4,z3e),e(z3e,a4r),e(B4,n4r),e(B4,_K),e(_K,s4r),e(B4,l4r),e(O,i4r),e(O,I4),e(I4,Q3e),e(Q3e,d4r),e(I4,m4r),e(I4,bK),e(bK,c4r),e(I4,f4r),e(O,g4r),e(O,N4),e(N4,W3e),e(W3e,h4r),e(N4,u4r),e(N4,vK),e(vK,p4r),e(N4,_4r),e(O,b4r),e(O,q4),e(q4,U3e),e(U3e,v4r),e(q4,F4r),e(q4,FK),e(FK,T4r),e(q4,M4r),e(O,E4r),e(O,j4),e(j4,H3e),e(H3e,C4r),e(j4,w4r),e(j4,TK),e(TK,A4r),e(j4,L4r),e(O,y4r),e(O,D4),e(D4,J3e),e(J3e,x4r),e(D4,$4r),e(D4,MK),e(MK,k4r),e(D4,S4r),e(O,R4r),e(O,G4),e(G4,Y3e),e(Y3e,P4r),e(G4,B4r),e(G4,EK),e(EK,I4r),e(G4,N4r),e(O,q4r),e(O,O4),e(O4,Z3e),e(Z3e,j4r),e(O4,D4r),e(O4,CK),e(CK,G4r),e(O4,O4r),e(O,V4r),e(O,V4),e(V4,K3e),e(K3e,X4r),e(V4,z4r),e(V4,wK),e(wK,Q4r),e(V4,W4r),e(O,U4r),e(O,X4),e(X4,e5e),e(e5e,H4r),e(X4,J4r),e(X4,AK),e(AK,Y4r),e(X4,Z4r),e(O,K4r),e(O,z4),e(z4,o5e),e(o5e,eCr),e(z4,oCr),e(z4,LK),e(LK,rCr),e(z4,tCr),e(O,aCr),e(O,Q4),e(Q4,r5e),e(r5e,nCr),e(Q4,sCr),e(Q4,yK),e(yK,lCr),e(Q4,iCr),e(mo,dCr),e(mo,W4),e(W4,mCr),e(W4,t5e),e(t5e,cCr),e(W4,fCr),e(W4,a5e),e(a5e,gCr),e(mo,hCr),M(U4,mo,null),b(c,Vto,_),b(c,dm,_),e(dm,H4),e(H4,n5e),M(Rk,n5e,null),e(dm,uCr),e(dm,s5e),e(s5e,pCr),b(c,Xto,_),b(c,Wo,_),M(Pk,Wo,null),e(Wo,_Cr),e(Wo,mm),e(mm,bCr),e(mm,xK),e(xK,vCr),e(mm,FCr),e(mm,$K),e($K,TCr),e(mm,MCr),e(Wo,ECr),e(Wo,Bk),e(Bk,CCr),e(Bk,l5e),e(l5e,wCr),e(Bk,ACr),e(Wo,LCr),e(Wo,St),M(Ik,St,null),e(St,yCr),e(St,i5e),e(i5e,xCr),e(St,$Cr),e(St,cm),e(cm,kCr),e(cm,d5e),e(d5e,SCr),e(cm,RCr),e(cm,kK),e(kK,PCr),e(cm,BCr),e(St,ICr),M(J4,St,null),e(Wo,NCr),e(Wo,co),M(Nk,co,null),e(co,qCr),e(co,m5e),e(m5e,jCr),e(co,DCr),e(co,pn),e(pn,GCr),e(pn,c5e),e(c5e,OCr),e(pn,VCr),e(pn,f5e),e(f5e,XCr),e(pn,zCr),e(pn,g5e),e(g5e,QCr),e(pn,WCr),e(co,UCr),e(co,h5e),e(h5e,Y4),e(Y4,u5e),e(u5e,HCr),e(Y4,JCr),e(Y4,SK),e(SK,YCr),e(Y4,ZCr),e(co,KCr),e(co,Z4),e(Z4,e3r),e(Z4,p5e),e(p5e,o3r),e(Z4,r3r),e(Z4,_5e),e(_5e,t3r),e(co,a3r),M(K4,co,null),b(c,zto,_),b(c,fm,_),e(fm,eC),e(eC,b5e),M(qk,b5e,null),e(fm,n3r),e(fm,v5e),e(v5e,s3r),b(c,Qto,_),b(c,Uo,_),M(jk,Uo,null),e(Uo,l3r),e(Uo,gm),e(gm,i3r),e(gm,RK),e(RK,d3r),e(gm,m3r),e(gm,PK),e(PK,c3r),e(gm,f3r),e(Uo,g3r),e(Uo,Dk),e(Dk,h3r),e(Dk,F5e),e(F5e,u3r),e(Dk,p3r),e(Uo,_3r),e(Uo,Rt),M(Gk,Rt,null),e(Rt,b3r),e(Rt,T5e),e(T5e,v3r),e(Rt,F3r),e(Rt,hm),e(hm,T3r),e(hm,M5e),e(M5e,M3r),e(hm,E3r),e(hm,BK),e(BK,C3r),e(hm,w3r),e(Rt,A3r),M(oC,Rt,null),e(Uo,L3r),e(Uo,fo),M(Ok,fo,null),e(fo,y3r),e(fo,E5e),e(E5e,x3r),e(fo,$3r),e(fo,_n),e(_n,k3r),e(_n,C5e),e(C5e,S3r),e(_n,R3r),e(_n,w5e),e(w5e,P3r),e(_n,B3r),e(_n,A5e),e(A5e,I3r),e(_n,N3r),e(fo,q3r),e(fo,um),e(um,rC),e(rC,L5e),e(L5e,j3r),e(rC,D3r),e(rC,IK),e(IK,G3r),e(rC,O3r),e(um,V3r),e(um,tC),e(tC,y5e),e(y5e,X3r),e(tC,z3r),e(tC,NK),e(NK,Q3r),e(tC,W3r),e(um,U3r),e(um,aC),e(aC,x5e),e(x5e,H3r),e(aC,J3r),e(aC,qK),e(qK,Y3r),e(aC,Z3r),e(fo,K3r),e(fo,nC),e(nC,e5r),e(nC,$5e),e($5e,o5r),e(nC,r5r),e(nC,k5e),e(k5e,t5r),e(fo,a5r),M(sC,fo,null),b(c,Wto,_),b(c,pm,_),e(pm,lC),e(lC,S5e),M(Vk,S5e,null),e(pm,n5r),e(pm,R5e),e(R5e,s5r),b(c,Uto,_),b(c,Ho,_),M(Xk,Ho,null),e(Ho,l5r),e(Ho,_m),e(_m,i5r),e(_m,jK),e(jK,d5r),e(_m,m5r),e(_m,DK),e(DK,c5r),e(_m,f5r),e(Ho,g5r),e(Ho,zk),e(zk,h5r),e(zk,P5e),e(P5e,u5r),e(zk,p5r),e(Ho,_5r),e(Ho,Pt),M(Qk,Pt,null),e(Pt,b5r),e(Pt,B5e),e(B5e,v5r),e(Pt,F5r),e(Pt,bm),e(bm,T5r),e(bm,I5e),e(I5e,M5r),e(bm,E5r),e(bm,GK),e(GK,C5r),e(bm,w5r),e(Pt,A5r),M(iC,Pt,null),e(Ho,L5r),e(Ho,go),M(Wk,go,null),e(go,y5r),e(go,N5e),e(N5e,x5r),e(go,$5r),e(go,bn),e(bn,k5r),e(bn,q5e),e(q5e,S5r),e(bn,R5r),e(bn,j5e),e(j5e,P5r),e(bn,B5r),e(bn,D5e),e(D5e,I5r),e(bn,N5r),e(go,q5r),e(go,be),e(be,dC),e(dC,G5e),e(G5e,j5r),e(dC,D5r),e(dC,OK),e(OK,G5r),e(dC,O5r),e(be,V5r),e(be,mC),e(mC,O5e),e(O5e,X5r),e(mC,z5r),e(mC,VK),e(VK,Q5r),e(mC,W5r),e(be,U5r),e(be,cC),e(cC,V5e),e(V5e,H5r),e(cC,J5r),e(cC,XK),e(XK,Y5r),e(cC,Z5r),e(be,K5r),e(be,fC),e(fC,X5e),e(X5e,e0r),e(fC,o0r),e(fC,zK),e(zK,r0r),e(fC,t0r),e(be,a0r),e(be,xl),e(xl,z5e),e(z5e,n0r),e(xl,s0r),e(xl,QK),e(QK,l0r),e(xl,i0r),e(xl,WK),e(WK,d0r),e(xl,m0r),e(be,c0r),e(be,gC),e(gC,Q5e),e(Q5e,f0r),e(gC,g0r),e(gC,UK),e(UK,h0r),e(gC,u0r),e(be,p0r),e(be,$l),e($l,W5e),e(W5e,_0r),e($l,b0r),e($l,HK),e(HK,v0r),e($l,F0r),e($l,JK),e(JK,T0r),e($l,M0r),e(be,E0r),e(be,hC),e(hC,U5e),e(U5e,C0r),e(hC,w0r),e(hC,YK),e(YK,A0r),e(hC,L0r),e(be,y0r),e(be,Bt),e(Bt,H5e),e(H5e,x0r),e(Bt,$0r),e(Bt,ZK),e(ZK,k0r),e(Bt,S0r),e(Bt,KK),e(KK,R0r),e(Bt,P0r),e(Bt,eee),e(eee,B0r),e(Bt,I0r),e(be,N0r),e(be,uC),e(uC,J5e),e(J5e,q0r),e(uC,j0r),e(uC,oee),e(oee,D0r),e(uC,G0r),e(be,O0r),e(be,pC),e(pC,Y5e),e(Y5e,V0r),e(pC,X0r),e(pC,ree),e(ree,z0r),e(pC,Q0r),e(be,W0r),e(be,_C),e(_C,Z5e),e(Z5e,U0r),e(_C,H0r),e(_C,tee),e(tee,J0r),e(_C,Y0r),e(be,Z0r),e(be,bC),e(bC,K5e),e(K5e,K0r),e(bC,ewr),e(bC,aee),e(aee,owr),e(bC,rwr),e(be,twr),e(be,vC),e(vC,e0e),e(e0e,awr),e(vC,nwr),e(vC,nee),e(nee,swr),e(vC,lwr),e(be,iwr),e(be,FC),e(FC,o0e),e(o0e,dwr),e(FC,mwr),e(FC,see),e(see,cwr),e(FC,fwr),e(be,gwr),e(be,TC),e(TC,r0e),e(r0e,hwr),e(TC,uwr),e(TC,lee),e(lee,pwr),e(TC,_wr),e(be,bwr),e(be,MC),e(MC,t0e),e(t0e,vwr),e(MC,Fwr),e(MC,iee),e(iee,Twr),e(MC,Mwr),e(be,Ewr),e(be,EC),e(EC,a0e),e(a0e,Cwr),e(EC,wwr),e(EC,dee),e(dee,Awr),e(EC,Lwr),e(go,ywr),e(go,CC),e(CC,xwr),e(CC,n0e),e(n0e,$wr),e(CC,kwr),e(CC,s0e),e(s0e,Swr),e(go,Rwr),M(wC,go,null),b(c,Hto,_),b(c,vm,_),e(vm,AC),e(AC,l0e),M(Uk,l0e,null),e(vm,Pwr),e(vm,i0e),e(i0e,Bwr),b(c,Jto,_),b(c,Jo,_),M(Hk,Jo,null),e(Jo,Iwr),e(Jo,Fm),e(Fm,Nwr),e(Fm,mee),e(mee,qwr),e(Fm,jwr),e(Fm,cee),e(cee,Dwr),e(Fm,Gwr),e(Jo,Owr),e(Jo,Jk),e(Jk,Vwr),e(Jk,d0e),e(d0e,Xwr),e(Jk,zwr),e(Jo,Qwr),e(Jo,It),M(Yk,It,null),e(It,Wwr),e(It,m0e),e(m0e,Uwr),e(It,Hwr),e(It,Tm),e(Tm,Jwr),e(Tm,c0e),e(c0e,Ywr),e(Tm,Zwr),e(Tm,fee),e(fee,Kwr),e(Tm,eAr),e(It,oAr),M(LC,It,null),e(Jo,rAr),e(Jo,ho),M(Zk,ho,null),e(ho,tAr),e(ho,f0e),e(f0e,aAr),e(ho,nAr),e(ho,vn),e(vn,sAr),e(vn,g0e),e(g0e,lAr),e(vn,iAr),e(vn,h0e),e(h0e,dAr),e(vn,mAr),e(vn,u0e),e(u0e,cAr),e(vn,fAr),e(ho,gAr),e(ho,p0e),e(p0e,yC),e(yC,_0e),e(_0e,hAr),e(yC,uAr),e(yC,gee),e(gee,pAr),e(yC,_Ar),e(ho,bAr),e(ho,xC),e(xC,vAr),e(xC,b0e),e(b0e,FAr),e(xC,TAr),e(xC,v0e),e(v0e,MAr),e(ho,EAr),M($C,ho,null),b(c,Yto,_),b(c,Mm,_),e(Mm,kC),e(kC,F0e),M(Kk,F0e,null),e(Mm,CAr),e(Mm,T0e),e(T0e,wAr),b(c,Zto,_),b(c,Yo,_),M(eS,Yo,null),e(Yo,AAr),e(Yo,Em),e(Em,LAr),e(Em,hee),e(hee,yAr),e(Em,xAr),e(Em,uee),e(uee,$Ar),e(Em,kAr),e(Yo,SAr),e(Yo,oS),e(oS,RAr),e(oS,M0e),e(M0e,PAr),e(oS,BAr),e(Yo,IAr),e(Yo,Nt),M(rS,Nt,null),e(Nt,NAr),e(Nt,E0e),e(E0e,qAr),e(Nt,jAr),e(Nt,Cm),e(Cm,DAr),e(Cm,C0e),e(C0e,GAr),e(Cm,OAr),e(Cm,pee),e(pee,VAr),e(Cm,XAr),e(Nt,zAr),M(SC,Nt,null),e(Yo,QAr),e(Yo,uo),M(tS,uo,null),e(uo,WAr),e(uo,w0e),e(w0e,UAr),e(uo,HAr),e(uo,Fn),e(Fn,JAr),e(Fn,A0e),e(A0e,YAr),e(Fn,ZAr),e(Fn,L0e),e(L0e,KAr),e(Fn,e6r),e(Fn,y0e),e(y0e,o6r),e(Fn,r6r),e(uo,t6r),e(uo,x0e),e(x0e,RC),e(RC,$0e),e($0e,a6r),e(RC,n6r),e(RC,_ee),e(_ee,s6r),e(RC,l6r),e(uo,i6r),e(uo,PC),e(PC,d6r),e(PC,k0e),e(k0e,m6r),e(PC,c6r),e(PC,S0e),e(S0e,f6r),e(uo,g6r),M(BC,uo,null),b(c,Kto,_),b(c,wm,_),e(wm,IC),e(IC,R0e),M(aS,R0e,null),e(wm,h6r),e(wm,P0e),e(P0e,u6r),b(c,eao,_),b(c,Zo,_),M(nS,Zo,null),e(Zo,p6r),e(Zo,Am),e(Am,_6r),e(Am,bee),e(bee,b6r),e(Am,v6r),e(Am,vee),e(vee,F6r),e(Am,T6r),e(Zo,M6r),e(Zo,sS),e(sS,E6r),e(sS,B0e),e(B0e,C6r),e(sS,w6r),e(Zo,A6r),e(Zo,qt),M(lS,qt,null),e(qt,L6r),e(qt,I0e),e(I0e,y6r),e(qt,x6r),e(qt,Lm),e(Lm,$6r),e(Lm,N0e),e(N0e,k6r),e(Lm,S6r),e(Lm,Fee),e(Fee,R6r),e(Lm,P6r),e(qt,B6r),M(NC,qt,null),e(Zo,I6r),e(Zo,po),M(iS,po,null),e(po,N6r),e(po,q0e),e(q0e,q6r),e(po,j6r),e(po,Tn),e(Tn,D6r),e(Tn,j0e),e(j0e,G6r),e(Tn,O6r),e(Tn,D0e),e(D0e,V6r),e(Tn,X6r),e(Tn,G0e),e(G0e,z6r),e(Tn,Q6r),e(po,W6r),e(po,O0e),e(O0e,qC),e(qC,V0e),e(V0e,U6r),e(qC,H6r),e(qC,Tee),e(Tee,J6r),e(qC,Y6r),e(po,Z6r),e(po,jC),e(jC,K6r),e(jC,X0e),e(X0e,e7r),e(jC,o7r),e(jC,z0e),e(z0e,r7r),e(po,t7r),M(DC,po,null),b(c,oao,_),b(c,ym,_),e(ym,GC),e(GC,Q0e),M(dS,Q0e,null),e(ym,a7r),e(ym,W0e),e(W0e,n7r),b(c,rao,_),b(c,Ko,_),M(mS,Ko,null),e(Ko,s7r),e(Ko,xm),e(xm,l7r),e(xm,Mee),e(Mee,i7r),e(xm,d7r),e(xm,Eee),e(Eee,m7r),e(xm,c7r),e(Ko,f7r),e(Ko,cS),e(cS,g7r),e(cS,U0e),e(U0e,h7r),e(cS,u7r),e(Ko,p7r),e(Ko,jt),M(fS,jt,null),e(jt,_7r),e(jt,H0e),e(H0e,b7r),e(jt,v7r),e(jt,$m),e($m,F7r),e($m,J0e),e(J0e,T7r),e($m,M7r),e($m,Cee),e(Cee,E7r),e($m,C7r),e(jt,w7r),M(OC,jt,null),e(Ko,A7r),e(Ko,_o),M(gS,_o,null),e(_o,L7r),e(_o,Y0e),e(Y0e,y7r),e(_o,x7r),e(_o,Mn),e(Mn,$7r),e(Mn,Z0e),e(Z0e,k7r),e(Mn,S7r),e(Mn,K0e),e(K0e,R7r),e(Mn,P7r),e(Mn,ewe),e(ewe,B7r),e(Mn,I7r),e(_o,N7r),e(_o,Be),e(Be,VC),e(VC,owe),e(owe,q7r),e(VC,j7r),e(VC,wee),e(wee,D7r),e(VC,G7r),e(Be,O7r),e(Be,XC),e(XC,rwe),e(rwe,V7r),e(XC,X7r),e(XC,Aee),e(Aee,z7r),e(XC,Q7r),e(Be,W7r),e(Be,zC),e(zC,twe),e(twe,U7r),e(zC,H7r),e(zC,Lee),e(Lee,J7r),e(zC,Y7r),e(Be,Z7r),e(Be,QC),e(QC,awe),e(awe,K7r),e(QC,e8r),e(QC,yee),e(yee,o8r),e(QC,r8r),e(Be,t8r),e(Be,WC),e(WC,nwe),e(nwe,a8r),e(WC,n8r),e(WC,xee),e(xee,s8r),e(WC,l8r),e(Be,i8r),e(Be,UC),e(UC,swe),e(swe,d8r),e(UC,m8r),e(UC,$ee),e($ee,c8r),e(UC,f8r),e(Be,g8r),e(Be,HC),e(HC,lwe),e(lwe,h8r),e(HC,u8r),e(HC,kee),e(kee,p8r),e(HC,_8r),e(Be,b8r),e(Be,JC),e(JC,iwe),e(iwe,v8r),e(JC,F8r),e(JC,See),e(See,T8r),e(JC,M8r),e(Be,E8r),e(Be,YC),e(YC,dwe),e(dwe,C8r),e(YC,w8r),e(YC,Ree),e(Ree,A8r),e(YC,L8r),e(_o,y8r),e(_o,ZC),e(ZC,x8r),e(ZC,mwe),e(mwe,$8r),e(ZC,k8r),e(ZC,cwe),e(cwe,S8r),e(_o,R8r),M(KC,_o,null),b(c,tao,_),b(c,km,_),e(km,e3),e(e3,fwe),M(hS,fwe,null),e(km,P8r),e(km,gwe),e(gwe,B8r),b(c,aao,_),b(c,er,_),M(uS,er,null),e(er,I8r),e(er,Sm),e(Sm,N8r),e(Sm,Pee),e(Pee,q8r),e(Sm,j8r),e(Sm,Bee),e(Bee,D8r),e(Sm,G8r),e(er,O8r),e(er,pS),e(pS,V8r),e(pS,hwe),e(hwe,X8r),e(pS,z8r),e(er,Q8r),e(er,Dt),M(_S,Dt,null),e(Dt,W8r),e(Dt,uwe),e(uwe,U8r),e(Dt,H8r),e(Dt,Rm),e(Rm,J8r),e(Rm,pwe),e(pwe,Y8r),e(Rm,Z8r),e(Rm,Iee),e(Iee,K8r),e(Rm,eLr),e(Dt,oLr),M(o3,Dt,null),e(er,rLr),e(er,bo),M(bS,bo,null),e(bo,tLr),e(bo,_we),e(_we,aLr),e(bo,nLr),e(bo,En),e(En,sLr),e(En,bwe),e(bwe,lLr),e(En,iLr),e(En,vwe),e(vwe,dLr),e(En,mLr),e(En,Fwe),e(Fwe,cLr),e(En,fLr),e(bo,gLr),e(bo,ut),e(ut,r3),e(r3,Twe),e(Twe,hLr),e(r3,uLr),e(r3,Nee),e(Nee,pLr),e(r3,_Lr),e(ut,bLr),e(ut,t3),e(t3,Mwe),e(Mwe,vLr),e(t3,FLr),e(t3,qee),e(qee,TLr),e(t3,MLr),e(ut,ELr),e(ut,a3),e(a3,Ewe),e(Ewe,CLr),e(a3,wLr),e(a3,jee),e(jee,ALr),e(a3,LLr),e(ut,yLr),e(ut,n3),e(n3,Cwe),e(Cwe,xLr),e(n3,$Lr),e(n3,Dee),e(Dee,kLr),e(n3,SLr),e(ut,RLr),e(ut,s3),e(s3,wwe),e(wwe,PLr),e(s3,BLr),e(s3,Gee),e(Gee,ILr),e(s3,NLr),e(bo,qLr),e(bo,l3),e(l3,jLr),e(l3,Awe),e(Awe,DLr),e(l3,GLr),e(l3,Lwe),e(Lwe,OLr),e(bo,VLr),M(i3,bo,null),b(c,nao,_),b(c,Pm,_),e(Pm,d3),e(d3,ywe),M(vS,ywe,null),e(Pm,XLr),e(Pm,xwe),e(xwe,zLr),b(c,sao,_),b(c,or,_),M(FS,or,null),e(or,QLr),e(or,Bm),e(Bm,WLr),e(Bm,Oee),e(Oee,ULr),e(Bm,HLr),e(Bm,Vee),e(Vee,JLr),e(Bm,YLr),e(or,ZLr),e(or,TS),e(TS,KLr),e(TS,$we),e($we,eyr),e(TS,oyr),e(or,ryr),e(or,Gt),M(MS,Gt,null),e(Gt,tyr),e(Gt,kwe),e(kwe,ayr),e(Gt,nyr),e(Gt,Im),e(Im,syr),e(Im,Swe),e(Swe,lyr),e(Im,iyr),e(Im,Xee),e(Xee,dyr),e(Im,myr),e(Gt,cyr),M(m3,Gt,null),e(or,fyr),e(or,vo),M(ES,vo,null),e(vo,gyr),e(vo,Rwe),e(Rwe,hyr),e(vo,uyr),e(vo,Cn),e(Cn,pyr),e(Cn,Pwe),e(Pwe,_yr),e(Cn,byr),e(Cn,Bwe),e(Bwe,vyr),e(Cn,Fyr),e(Cn,Iwe),e(Iwe,Tyr),e(Cn,Myr),e(vo,Eyr),e(vo,Le),e(Le,c3),e(c3,Nwe),e(Nwe,Cyr),e(c3,wyr),e(c3,zee),e(zee,Ayr),e(c3,Lyr),e(Le,yyr),e(Le,f3),e(f3,qwe),e(qwe,xyr),e(f3,$yr),e(f3,Qee),e(Qee,kyr),e(f3,Syr),e(Le,Ryr),e(Le,g3),e(g3,jwe),e(jwe,Pyr),e(g3,Byr),e(g3,Wee),e(Wee,Iyr),e(g3,Nyr),e(Le,qyr),e(Le,h3),e(h3,Dwe),e(Dwe,jyr),e(h3,Dyr),e(h3,Uee),e(Uee,Gyr),e(h3,Oyr),e(Le,Vyr),e(Le,u3),e(u3,Gwe),e(Gwe,Xyr),e(u3,zyr),e(u3,Hee),e(Hee,Qyr),e(u3,Wyr),e(Le,Uyr),e(Le,p3),e(p3,Owe),e(Owe,Hyr),e(p3,Jyr),e(p3,Jee),e(Jee,Yyr),e(p3,Zyr),e(Le,Kyr),e(Le,_3),e(_3,Vwe),e(Vwe,e9r),e(_3,o9r),e(_3,Yee),e(Yee,r9r),e(_3,t9r),e(Le,a9r),e(Le,b3),e(b3,Xwe),e(Xwe,n9r),e(b3,s9r),e(b3,Zee),e(Zee,l9r),e(b3,i9r),e(Le,d9r),e(Le,v3),e(v3,zwe),e(zwe,m9r),e(v3,c9r),e(v3,Kee),e(Kee,f9r),e(v3,g9r),e(Le,h9r),e(Le,F3),e(F3,Qwe),e(Qwe,u9r),e(F3,p9r),e(F3,eoe),e(eoe,_9r),e(F3,b9r),e(vo,v9r),e(vo,T3),e(T3,F9r),e(T3,Wwe),e(Wwe,T9r),e(T3,M9r),e(T3,Uwe),e(Uwe,E9r),e(vo,C9r),M(M3,vo,null),b(c,lao,_),b(c,Nm,_),e(Nm,E3),e(E3,Hwe),M(CS,Hwe,null),e(Nm,w9r),e(Nm,Jwe),e(Jwe,A9r),b(c,iao,_),b(c,rr,_),M(wS,rr,null),e(rr,L9r),e(rr,qm),e(qm,y9r),e(qm,ooe),e(ooe,x9r),e(qm,$9r),e(qm,roe),e(roe,k9r),e(qm,S9r),e(rr,R9r),e(rr,AS),e(AS,P9r),e(AS,Ywe),e(Ywe,B9r),e(AS,I9r),e(rr,N9r),e(rr,Ot),M(LS,Ot,null),e(Ot,q9r),e(Ot,Zwe),e(Zwe,j9r),e(Ot,D9r),e(Ot,jm),e(jm,G9r),e(jm,Kwe),e(Kwe,O9r),e(jm,V9r),e(jm,toe),e(toe,X9r),e(jm,z9r),e(Ot,Q9r),M(C3,Ot,null),e(rr,W9r),e(rr,Fo),M(yS,Fo,null),e(Fo,U9r),e(Fo,eAe),e(eAe,H9r),e(Fo,J9r),e(Fo,wn),e(wn,Y9r),e(wn,oAe),e(oAe,Z9r),e(wn,K9r),e(wn,rAe),e(rAe,exr),e(wn,oxr),e(wn,tAe),e(tAe,rxr),e(wn,txr),e(Fo,axr),e(Fo,Dm),e(Dm,w3),e(w3,aAe),e(aAe,nxr),e(w3,sxr),e(w3,aoe),e(aoe,lxr),e(w3,ixr),e(Dm,dxr),e(Dm,A3),e(A3,nAe),e(nAe,mxr),e(A3,cxr),e(A3,noe),e(noe,fxr),e(A3,gxr),e(Dm,hxr),e(Dm,L3),e(L3,sAe),e(sAe,uxr),e(L3,pxr),e(L3,soe),e(soe,_xr),e(L3,bxr),e(Fo,vxr),e(Fo,y3),e(y3,Fxr),e(y3,lAe),e(lAe,Txr),e(y3,Mxr),e(y3,iAe),e(iAe,Exr),e(Fo,Cxr),M(x3,Fo,null),b(c,dao,_),b(c,Gm,_),e(Gm,$3),e($3,dAe),M(xS,dAe,null),e(Gm,wxr),e(Gm,mAe),e(mAe,Axr),b(c,mao,_),b(c,tr,_),M($S,tr,null),e(tr,Lxr),e(tr,Om),e(Om,yxr),e(Om,loe),e(loe,xxr),e(Om,$xr),e(Om,ioe),e(ioe,kxr),e(Om,Sxr),e(tr,Rxr),e(tr,kS),e(kS,Pxr),e(kS,cAe),e(cAe,Bxr),e(kS,Ixr),e(tr,Nxr),e(tr,Vt),M(SS,Vt,null),e(Vt,qxr),e(Vt,fAe),e(fAe,jxr),e(Vt,Dxr),e(Vt,Vm),e(Vm,Gxr),e(Vm,gAe),e(gAe,Oxr),e(Vm,Vxr),e(Vm,doe),e(doe,Xxr),e(Vm,zxr),e(Vt,Qxr),M(k3,Vt,null),e(tr,Wxr),e(tr,To),M(RS,To,null),e(To,Uxr),e(To,hAe),e(hAe,Hxr),e(To,Jxr),e(To,An),e(An,Yxr),e(An,uAe),e(uAe,Zxr),e(An,Kxr),e(An,pAe),e(pAe,e$r),e(An,o$r),e(An,_Ae),e(_Ae,r$r),e(An,t$r),e(To,a$r),e(To,pt),e(pt,S3),e(S3,bAe),e(bAe,n$r),e(S3,s$r),e(S3,moe),e(moe,l$r),e(S3,i$r),e(pt,d$r),e(pt,R3),e(R3,vAe),e(vAe,m$r),e(R3,c$r),e(R3,coe),e(coe,f$r),e(R3,g$r),e(pt,h$r),e(pt,P3),e(P3,FAe),e(FAe,u$r),e(P3,p$r),e(P3,foe),e(foe,_$r),e(P3,b$r),e(pt,v$r),e(pt,B3),e(B3,TAe),e(TAe,F$r),e(B3,T$r),e(B3,goe),e(goe,M$r),e(B3,E$r),e(pt,C$r),e(pt,I3),e(I3,MAe),e(MAe,w$r),e(I3,A$r),e(I3,hoe),e(hoe,L$r),e(I3,y$r),e(To,x$r),e(To,N3),e(N3,$$r),e(N3,EAe),e(EAe,k$r),e(N3,S$r),e(N3,CAe),e(CAe,R$r),e(To,P$r),M(q3,To,null),b(c,cao,_),b(c,Xm,_),e(Xm,j3),e(j3,wAe),M(PS,wAe,null),e(Xm,B$r),e(Xm,AAe),e(AAe,I$r),b(c,fao,_),b(c,ar,_),M(BS,ar,null),e(ar,N$r),e(ar,zm),e(zm,q$r),e(zm,uoe),e(uoe,j$r),e(zm,D$r),e(zm,poe),e(poe,G$r),e(zm,O$r),e(ar,V$r),e(ar,IS),e(IS,X$r),e(IS,LAe),e(LAe,z$r),e(IS,Q$r),e(ar,W$r),e(ar,Xt),M(NS,Xt,null),e(Xt,U$r),e(Xt,yAe),e(yAe,H$r),e(Xt,J$r),e(Xt,Qm),e(Qm,Y$r),e(Qm,xAe),e(xAe,Z$r),e(Qm,K$r),e(Qm,_oe),e(_oe,ekr),e(Qm,okr),e(Xt,rkr),M(D3,Xt,null),e(ar,tkr),e(ar,Mo),M(qS,Mo,null),e(Mo,akr),e(Mo,$Ae),e($Ae,nkr),e(Mo,skr),e(Mo,Ln),e(Ln,lkr),e(Ln,kAe),e(kAe,ikr),e(Ln,dkr),e(Ln,SAe),e(SAe,mkr),e(Ln,ckr),e(Ln,RAe),e(RAe,fkr),e(Ln,gkr),e(Mo,hkr),e(Mo,yn),e(yn,G3),e(G3,PAe),e(PAe,ukr),e(G3,pkr),e(G3,boe),e(boe,_kr),e(G3,bkr),e(yn,vkr),e(yn,O3),e(O3,BAe),e(BAe,Fkr),e(O3,Tkr),e(O3,voe),e(voe,Mkr),e(O3,Ekr),e(yn,Ckr),e(yn,V3),e(V3,IAe),e(IAe,wkr),e(V3,Akr),e(V3,Foe),e(Foe,Lkr),e(V3,ykr),e(yn,xkr),e(yn,X3),e(X3,NAe),e(NAe,$kr),e(X3,kkr),e(X3,Toe),e(Toe,Skr),e(X3,Rkr),e(Mo,Pkr),e(Mo,z3),e(z3,Bkr),e(z3,qAe),e(qAe,Ikr),e(z3,Nkr),e(z3,jAe),e(jAe,qkr),e(Mo,jkr),M(Q3,Mo,null),b(c,gao,_),b(c,Wm,_),e(Wm,W3),e(W3,DAe),M(jS,DAe,null),e(Wm,Dkr),e(Wm,GAe),e(GAe,Gkr),b(c,hao,_),b(c,nr,_),M(DS,nr,null),e(nr,Okr),e(nr,Um),e(Um,Vkr),e(Um,Moe),e(Moe,Xkr),e(Um,zkr),e(Um,Eoe),e(Eoe,Qkr),e(Um,Wkr),e(nr,Ukr),e(nr,GS),e(GS,Hkr),e(GS,OAe),e(OAe,Jkr),e(GS,Ykr),e(nr,Zkr),e(nr,zt),M(OS,zt,null),e(zt,Kkr),e(zt,VAe),e(VAe,eSr),e(zt,oSr),e(zt,Hm),e(Hm,rSr),e(Hm,XAe),e(XAe,tSr),e(Hm,aSr),e(Hm,Coe),e(Coe,nSr),e(Hm,sSr),e(zt,lSr),M(U3,zt,null),e(nr,iSr),e(nr,Eo),M(VS,Eo,null),e(Eo,dSr),e(Eo,zAe),e(zAe,mSr),e(Eo,cSr),e(Eo,xn),e(xn,fSr),e(xn,QAe),e(QAe,gSr),e(xn,hSr),e(xn,WAe),e(WAe,uSr),e(xn,pSr),e(xn,UAe),e(UAe,_Sr),e(xn,bSr),e(Eo,vSr),e(Eo,$n),e($n,H3),e(H3,HAe),e(HAe,FSr),e(H3,TSr),e(H3,woe),e(woe,MSr),e(H3,ESr),e($n,CSr),e($n,J3),e(J3,JAe),e(JAe,wSr),e(J3,ASr),e(J3,Aoe),e(Aoe,LSr),e(J3,ySr),e($n,xSr),e($n,Y3),e(Y3,YAe),e(YAe,$Sr),e(Y3,kSr),e(Y3,Loe),e(Loe,SSr),e(Y3,RSr),e($n,PSr),e($n,Z3),e(Z3,ZAe),e(ZAe,BSr),e(Z3,ISr),e(Z3,yoe),e(yoe,NSr),e(Z3,qSr),e(Eo,jSr),e(Eo,K3),e(K3,DSr),e(K3,KAe),e(KAe,GSr),e(K3,OSr),e(K3,e6e),e(e6e,VSr),e(Eo,XSr),M(e5,Eo,null),b(c,uao,_),b(c,Jm,_),e(Jm,o5),e(o5,o6e),M(XS,o6e,null),e(Jm,zSr),e(Jm,r6e),e(r6e,QSr),b(c,pao,_),b(c,sr,_),M(zS,sr,null),e(sr,WSr),e(sr,Ym),e(Ym,USr),e(Ym,xoe),e(xoe,HSr),e(Ym,JSr),e(Ym,$oe),e($oe,YSr),e(Ym,ZSr),e(sr,KSr),e(sr,QS),e(QS,eRr),e(QS,t6e),e(t6e,oRr),e(QS,rRr),e(sr,tRr),e(sr,Qt),M(WS,Qt,null),e(Qt,aRr),e(Qt,a6e),e(a6e,nRr),e(Qt,sRr),e(Qt,Zm),e(Zm,lRr),e(Zm,n6e),e(n6e,iRr),e(Zm,dRr),e(Zm,koe),e(koe,mRr),e(Zm,cRr),e(Qt,fRr),M(r5,Qt,null),e(sr,gRr),e(sr,Co),M(US,Co,null),e(Co,hRr),e(Co,s6e),e(s6e,uRr),e(Co,pRr),e(Co,kn),e(kn,_Rr),e(kn,l6e),e(l6e,bRr),e(kn,vRr),e(kn,i6e),e(i6e,FRr),e(kn,TRr),e(kn,d6e),e(d6e,MRr),e(kn,ERr),e(Co,CRr),e(Co,m6e),e(m6e,t5),e(t5,c6e),e(c6e,wRr),e(t5,ARr),e(t5,Soe),e(Soe,LRr),e(t5,yRr),e(Co,xRr),e(Co,a5),e(a5,$Rr),e(a5,f6e),e(f6e,kRr),e(a5,SRr),e(a5,g6e),e(g6e,RRr),e(Co,PRr),M(n5,Co,null),b(c,_ao,_),b(c,Km,_),e(Km,s5),e(s5,h6e),M(HS,h6e,null),e(Km,BRr),e(Km,u6e),e(u6e,IRr),b(c,bao,_),b(c,lr,_),M(JS,lr,null),e(lr,NRr),e(lr,ec),e(ec,qRr),e(ec,Roe),e(Roe,jRr),e(ec,DRr),e(ec,Poe),e(Poe,GRr),e(ec,ORr),e(lr,VRr),e(lr,YS),e(YS,XRr),e(YS,p6e),e(p6e,zRr),e(YS,QRr),e(lr,WRr),e(lr,Wt),M(ZS,Wt,null),e(Wt,URr),e(Wt,_6e),e(_6e,HRr),e(Wt,JRr),e(Wt,oc),e(oc,YRr),e(oc,b6e),e(b6e,ZRr),e(oc,KRr),e(oc,Boe),e(Boe,ePr),e(oc,oPr),e(Wt,rPr),M(l5,Wt,null),e(lr,tPr),e(lr,wo),M(KS,wo,null),e(wo,aPr),e(wo,v6e),e(v6e,nPr),e(wo,sPr),e(wo,Sn),e(Sn,lPr),e(Sn,F6e),e(F6e,iPr),e(Sn,dPr),e(Sn,T6e),e(T6e,mPr),e(Sn,cPr),e(Sn,M6e),e(M6e,fPr),e(Sn,gPr),e(wo,hPr),e(wo,_t),e(_t,i5),e(i5,E6e),e(E6e,uPr),e(i5,pPr),e(i5,Ioe),e(Ioe,_Pr),e(i5,bPr),e(_t,vPr),e(_t,d5),e(d5,C6e),e(C6e,FPr),e(d5,TPr),e(d5,Noe),e(Noe,MPr),e(d5,EPr),e(_t,CPr),e(_t,m5),e(m5,w6e),e(w6e,wPr),e(m5,APr),e(m5,qoe),e(qoe,LPr),e(m5,yPr),e(_t,xPr),e(_t,c5),e(c5,A6e),e(A6e,$Pr),e(c5,kPr),e(c5,joe),e(joe,SPr),e(c5,RPr),e(_t,PPr),e(_t,f5),e(f5,L6e),e(L6e,BPr),e(f5,IPr),e(f5,Doe),e(Doe,NPr),e(f5,qPr),e(wo,jPr),e(wo,g5),e(g5,DPr),e(g5,y6e),e(y6e,GPr),e(g5,OPr),e(g5,x6e),e(x6e,VPr),e(wo,XPr),M(h5,wo,null),b(c,vao,_),b(c,rc,_),e(rc,u5),e(u5,$6e),M(eR,$6e,null),e(rc,zPr),e(rc,k6e),e(k6e,QPr),b(c,Fao,_),b(c,ir,_),M(oR,ir,null),e(ir,WPr),e(ir,tc),e(tc,UPr),e(tc,Goe),e(Goe,HPr),e(tc,JPr),e(tc,Ooe),e(Ooe,YPr),e(tc,ZPr),e(ir,KPr),e(ir,rR),e(rR,eBr),e(rR,S6e),e(S6e,oBr),e(rR,rBr),e(ir,tBr),e(ir,Ut),M(tR,Ut,null),e(Ut,aBr),e(Ut,R6e),e(R6e,nBr),e(Ut,sBr),e(Ut,ac),e(ac,lBr),e(ac,P6e),e(P6e,iBr),e(ac,dBr),e(ac,Voe),e(Voe,mBr),e(ac,cBr),e(Ut,fBr),M(p5,Ut,null),e(ir,gBr),e(ir,Ao),M(aR,Ao,null),e(Ao,hBr),e(Ao,B6e),e(B6e,uBr),e(Ao,pBr),e(Ao,Rn),e(Rn,_Br),e(Rn,I6e),e(I6e,bBr),e(Rn,vBr),e(Rn,N6e),e(N6e,FBr),e(Rn,TBr),e(Rn,q6e),e(q6e,MBr),e(Rn,EBr),e(Ao,CBr),e(Ao,j6e),e(j6e,_5),e(_5,D6e),e(D6e,wBr),e(_5,ABr),e(_5,Xoe),e(Xoe,LBr),e(_5,yBr),e(Ao,xBr),e(Ao,b5),e(b5,$Br),e(b5,G6e),e(G6e,kBr),e(b5,SBr),e(b5,O6e),e(O6e,RBr),e(Ao,PBr),M(v5,Ao,null),b(c,Tao,_),b(c,nc,_),e(nc,F5),e(F5,V6e),M(nR,V6e,null),e(nc,BBr),e(nc,X6e),e(X6e,IBr),b(c,Mao,_),b(c,dr,_),M(sR,dr,null),e(dr,NBr),e(dr,sc),e(sc,qBr),e(sc,zoe),e(zoe,jBr),e(sc,DBr),e(sc,Qoe),e(Qoe,GBr),e(sc,OBr),e(dr,VBr),e(dr,lR),e(lR,XBr),e(lR,z6e),e(z6e,zBr),e(lR,QBr),e(dr,WBr),e(dr,Ht),M(iR,Ht,null),e(Ht,UBr),e(Ht,Q6e),e(Q6e,HBr),e(Ht,JBr),e(Ht,lc),e(lc,YBr),e(lc,W6e),e(W6e,ZBr),e(lc,KBr),e(lc,Woe),e(Woe,eIr),e(lc,oIr),e(Ht,rIr),M(T5,Ht,null),e(dr,tIr),e(dr,Lo),M(dR,Lo,null),e(Lo,aIr),e(Lo,U6e),e(U6e,nIr),e(Lo,sIr),e(Lo,Pn),e(Pn,lIr),e(Pn,H6e),e(H6e,iIr),e(Pn,dIr),e(Pn,J6e),e(J6e,mIr),e(Pn,cIr),e(Pn,Y6e),e(Y6e,fIr),e(Pn,gIr),e(Lo,hIr),e(Lo,Z6e),e(Z6e,M5),e(M5,K6e),e(K6e,uIr),e(M5,pIr),e(M5,Uoe),e(Uoe,_Ir),e(M5,bIr),e(Lo,vIr),e(Lo,E5),e(E5,FIr),e(E5,e7e),e(e7e,TIr),e(E5,MIr),e(E5,o7e),e(o7e,EIr),e(Lo,CIr),M(C5,Lo,null),b(c,Eao,_),b(c,ic,_),e(ic,w5),e(w5,r7e),M(mR,r7e,null),e(ic,wIr),e(ic,t7e),e(t7e,AIr),b(c,Cao,_),b(c,mr,_),M(cR,mr,null),e(mr,LIr),e(mr,dc),e(dc,yIr),e(dc,Hoe),e(Hoe,xIr),e(dc,$Ir),e(dc,Joe),e(Joe,kIr),e(dc,SIr),e(mr,RIr),e(mr,fR),e(fR,PIr),e(fR,a7e),e(a7e,BIr),e(fR,IIr),e(mr,NIr),e(mr,Jt),M(gR,Jt,null),e(Jt,qIr),e(Jt,n7e),e(n7e,jIr),e(Jt,DIr),e(Jt,mc),e(mc,GIr),e(mc,s7e),e(s7e,OIr),e(mc,VIr),e(mc,Yoe),e(Yoe,XIr),e(mc,zIr),e(Jt,QIr),M(A5,Jt,null),e(mr,WIr),e(mr,Dr),M(hR,Dr,null),e(Dr,UIr),e(Dr,l7e),e(l7e,HIr),e(Dr,JIr),e(Dr,Bn),e(Bn,YIr),e(Bn,i7e),e(i7e,ZIr),e(Bn,KIr),e(Bn,d7e),e(d7e,eNr),e(Bn,oNr),e(Bn,m7e),e(m7e,rNr),e(Bn,tNr),e(Dr,aNr),e(Dr,P),e(P,L5),e(L5,c7e),e(c7e,nNr),e(L5,sNr),e(L5,Zoe),e(Zoe,lNr),e(L5,iNr),e(P,dNr),e(P,y5),e(y5,f7e),e(f7e,mNr),e(y5,cNr),e(y5,Koe),e(Koe,fNr),e(y5,gNr),e(P,hNr),e(P,x5),e(x5,g7e),e(g7e,uNr),e(x5,pNr),e(x5,ere),e(ere,_Nr),e(x5,bNr),e(P,vNr),e(P,$5),e($5,h7e),e(h7e,FNr),e($5,TNr),e($5,ore),e(ore,MNr),e($5,ENr),e(P,CNr),e(P,k5),e(k5,u7e),e(u7e,wNr),e(k5,ANr),e(k5,rre),e(rre,LNr),e(k5,yNr),e(P,xNr),e(P,S5),e(S5,p7e),e(p7e,$Nr),e(S5,kNr),e(S5,tre),e(tre,SNr),e(S5,RNr),e(P,PNr),e(P,R5),e(R5,_7e),e(_7e,BNr),e(R5,INr),e(R5,are),e(are,NNr),e(R5,qNr),e(P,jNr),e(P,P5),e(P5,b7e),e(b7e,DNr),e(P5,GNr),e(P5,nre),e(nre,ONr),e(P5,VNr),e(P,XNr),e(P,B5),e(B5,v7e),e(v7e,zNr),e(B5,QNr),e(B5,sre),e(sre,WNr),e(B5,UNr),e(P,HNr),e(P,I5),e(I5,F7e),e(F7e,JNr),e(I5,YNr),e(I5,lre),e(lre,ZNr),e(I5,KNr),e(P,eqr),e(P,N5),e(N5,T7e),e(T7e,oqr),e(N5,rqr),e(N5,ire),e(ire,tqr),e(N5,aqr),e(P,nqr),e(P,q5),e(q5,M7e),e(M7e,sqr),e(q5,lqr),e(q5,dre),e(dre,iqr),e(q5,dqr),e(P,mqr),e(P,j5),e(j5,E7e),e(E7e,cqr),e(j5,fqr),e(j5,mre),e(mre,gqr),e(j5,hqr),e(P,uqr),e(P,D5),e(D5,C7e),e(C7e,pqr),e(D5,_qr),e(D5,cre),e(cre,bqr),e(D5,vqr),e(P,Fqr),e(P,G5),e(G5,w7e),e(w7e,Tqr),e(G5,Mqr),e(G5,fre),e(fre,Eqr),e(G5,Cqr),e(P,wqr),e(P,O5),e(O5,A7e),e(A7e,Aqr),e(O5,Lqr),e(O5,gre),e(gre,yqr),e(O5,xqr),e(P,$qr),e(P,V5),e(V5,L7e),e(L7e,kqr),e(V5,Sqr),e(V5,hre),e(hre,Rqr),e(V5,Pqr),e(P,Bqr),e(P,X5),e(X5,y7e),e(y7e,Iqr),e(X5,Nqr),e(X5,ure),e(ure,qqr),e(X5,jqr),e(P,Dqr),e(P,z5),e(z5,x7e),e(x7e,Gqr),e(z5,Oqr),e(z5,pre),e(pre,Vqr),e(z5,Xqr),e(P,zqr),e(P,Q5),e(Q5,$7e),e($7e,Qqr),e(Q5,Wqr),e(Q5,_re),e(_re,Uqr),e(Q5,Hqr),e(P,Jqr),e(P,kl),e(kl,k7e),e(k7e,Yqr),e(kl,Zqr),e(kl,bre),e(bre,Kqr),e(kl,ejr),e(kl,vre),e(vre,ojr),e(kl,rjr),e(P,tjr),e(P,W5),e(W5,S7e),e(S7e,ajr),e(W5,njr),e(W5,Fre),e(Fre,sjr),e(W5,ljr),e(P,ijr),e(P,U5),e(U5,R7e),e(R7e,djr),e(U5,mjr),e(U5,Tre),e(Tre,cjr),e(U5,fjr),e(P,gjr),e(P,H5),e(H5,P7e),e(P7e,hjr),e(H5,ujr),e(H5,Mre),e(Mre,pjr),e(H5,_jr),e(P,bjr),e(P,J5),e(J5,B7e),e(B7e,vjr),e(J5,Fjr),e(J5,Ere),e(Ere,Tjr),e(J5,Mjr),e(P,Ejr),e(P,Y5),e(Y5,I7e),e(I7e,Cjr),e(Y5,wjr),e(Y5,Cre),e(Cre,Ajr),e(Y5,Ljr),e(P,yjr),e(P,Z5),e(Z5,N7e),e(N7e,xjr),e(Z5,$jr),e(Z5,wre),e(wre,kjr),e(Z5,Sjr),e(P,Rjr),e(P,K5),e(K5,q7e),e(q7e,Pjr),e(K5,Bjr),e(K5,Are),e(Are,Ijr),e(K5,Njr),e(P,qjr),e(P,e0),e(e0,j7e),e(j7e,jjr),e(e0,Djr),e(e0,Lre),e(Lre,Gjr),e(e0,Ojr),e(P,Vjr),e(P,o0),e(o0,D7e),e(D7e,Xjr),e(o0,zjr),e(o0,yre),e(yre,Qjr),e(o0,Wjr),e(P,Ujr),e(P,r0),e(r0,G7e),e(G7e,Hjr),e(r0,Jjr),e(r0,xre),e(xre,Yjr),e(r0,Zjr),e(P,Kjr),e(P,t0),e(t0,O7e),e(O7e,eDr),e(t0,oDr),e(t0,$re),e($re,rDr),e(t0,tDr),e(P,aDr),e(P,a0),e(a0,V7e),e(V7e,nDr),e(a0,sDr),e(a0,kre),e(kre,lDr),e(a0,iDr),e(P,dDr),e(P,n0),e(n0,X7e),e(X7e,mDr),e(n0,cDr),e(n0,Sre),e(Sre,fDr),e(n0,gDr),e(P,hDr),e(P,s0),e(s0,z7e),e(z7e,uDr),e(s0,pDr),e(s0,Rre),e(Rre,_Dr),e(s0,bDr),e(P,vDr),e(P,l0),e(l0,Q7e),e(Q7e,FDr),e(l0,TDr),e(l0,Pre),e(Pre,MDr),e(l0,EDr),e(P,CDr),e(P,i0),e(i0,W7e),e(W7e,wDr),e(i0,ADr),e(i0,Bre),e(Bre,LDr),e(i0,yDr),e(P,xDr),e(P,d0),e(d0,U7e),e(U7e,$Dr),e(d0,kDr),e(d0,Ire),e(Ire,SDr),e(d0,RDr),e(P,PDr),e(P,m0),e(m0,H7e),e(H7e,BDr),e(m0,IDr),e(m0,Nre),e(Nre,NDr),e(m0,qDr),e(P,jDr),e(P,c0),e(c0,J7e),e(J7e,DDr),e(c0,GDr),e(c0,qre),e(qre,ODr),e(c0,VDr),e(P,XDr),e(P,f0),e(f0,Y7e),e(Y7e,zDr),e(f0,QDr),e(f0,jre),e(jre,WDr),e(f0,UDr),e(P,HDr),e(P,g0),e(g0,Z7e),e(Z7e,JDr),e(g0,YDr),e(g0,Dre),e(Dre,ZDr),e(g0,KDr),e(P,eGr),e(P,h0),e(h0,K7e),e(K7e,oGr),e(h0,rGr),e(h0,Gre),e(Gre,tGr),e(h0,aGr),e(P,nGr),e(P,u0),e(u0,e8e),e(e8e,sGr),e(u0,lGr),e(u0,Ore),e(Ore,iGr),e(u0,dGr),e(P,mGr),e(P,p0),e(p0,o8e),e(o8e,cGr),e(p0,fGr),e(p0,Vre),e(Vre,gGr),e(p0,hGr),e(P,uGr),e(P,_0),e(_0,r8e),e(r8e,pGr),e(_0,_Gr),e(_0,Xre),e(Xre,bGr),e(_0,vGr),e(P,FGr),e(P,b0),e(b0,t8e),e(t8e,TGr),e(b0,MGr),e(b0,zre),e(zre,EGr),e(b0,CGr),e(P,wGr),e(P,v0),e(v0,a8e),e(a8e,AGr),e(v0,LGr),e(v0,Qre),e(Qre,yGr),e(v0,xGr),e(P,$Gr),e(P,F0),e(F0,n8e),e(n8e,kGr),e(F0,SGr),e(F0,Wre),e(Wre,RGr),e(F0,PGr),e(P,BGr),e(P,T0),e(T0,s8e),e(s8e,IGr),e(T0,NGr),e(T0,Ure),e(Ure,qGr),e(T0,jGr),e(P,DGr),e(P,M0),e(M0,l8e),e(l8e,GGr),e(M0,OGr),e(M0,Hre),e(Hre,VGr),e(M0,XGr),e(P,zGr),e(P,E0),e(E0,i8e),e(i8e,QGr),e(E0,WGr),e(E0,Jre),e(Jre,UGr),e(E0,HGr),e(P,JGr),e(P,C0),e(C0,d8e),e(d8e,YGr),e(C0,ZGr),e(C0,Yre),e(Yre,KGr),e(C0,eOr),e(P,oOr),e(P,w0),e(w0,m8e),e(m8e,rOr),e(w0,tOr),e(w0,Zre),e(Zre,aOr),e(w0,nOr),e(P,sOr),e(P,A0),e(A0,c8e),e(c8e,lOr),e(A0,iOr),e(A0,Kre),e(Kre,dOr),e(A0,mOr),e(P,cOr),e(P,L0),e(L0,f8e),e(f8e,fOr),e(L0,gOr),e(L0,ete),e(ete,hOr),e(L0,uOr),e(P,pOr),e(P,y0),e(y0,g8e),e(g8e,_Or),e(y0,bOr),e(y0,ote),e(ote,vOr),e(y0,FOr),e(P,TOr),e(P,x0),e(x0,h8e),e(h8e,MOr),e(x0,EOr),e(x0,rte),e(rte,COr),e(x0,wOr),e(Dr,AOr),M($0,Dr,null),b(c,wao,_),b(c,cc,_),e(cc,k0),e(k0,u8e),M(uR,u8e,null),e(cc,LOr),e(cc,p8e),e(p8e,yOr),b(c,Aao,_),b(c,cr,_),M(pR,cr,null),e(cr,xOr),e(cr,fc),e(fc,$Or),e(fc,tte),e(tte,kOr),e(fc,SOr),e(fc,ate),e(ate,ROr),e(fc,POr),e(cr,BOr),e(cr,_R),e(_R,IOr),e(_R,_8e),e(_8e,NOr),e(_R,qOr),e(cr,jOr),e(cr,Yt),M(bR,Yt,null),e(Yt,DOr),e(Yt,b8e),e(b8e,GOr),e(Yt,OOr),e(Yt,gc),e(gc,VOr),e(gc,v8e),e(v8e,XOr),e(gc,zOr),e(gc,nte),e(nte,QOr),e(gc,WOr),e(Yt,UOr),M(S0,Yt,null),e(cr,HOr),e(cr,Gr),M(vR,Gr,null),e(Gr,JOr),e(Gr,F8e),e(F8e,YOr),e(Gr,ZOr),e(Gr,In),e(In,KOr),e(In,T8e),e(T8e,eVr),e(In,oVr),e(In,M8e),e(M8e,rVr),e(In,tVr),e(In,E8e),e(E8e,aVr),e(In,nVr),e(Gr,sVr),e(Gr,le),e(le,R0),e(R0,C8e),e(C8e,lVr),e(R0,iVr),e(R0,ste),e(ste,dVr),e(R0,mVr),e(le,cVr),e(le,P0),e(P0,w8e),e(w8e,fVr),e(P0,gVr),e(P0,lte),e(lte,hVr),e(P0,uVr),e(le,pVr),e(le,B0),e(B0,A8e),e(A8e,_Vr),e(B0,bVr),e(B0,ite),e(ite,vVr),e(B0,FVr),e(le,TVr),e(le,I0),e(I0,L8e),e(L8e,MVr),e(I0,EVr),e(I0,dte),e(dte,CVr),e(I0,wVr),e(le,AVr),e(le,N0),e(N0,y8e),e(y8e,LVr),e(N0,yVr),e(N0,mte),e(mte,xVr),e(N0,$Vr),e(le,kVr),e(le,q0),e(q0,x8e),e(x8e,SVr),e(q0,RVr),e(q0,cte),e(cte,PVr),e(q0,BVr),e(le,IVr),e(le,j0),e(j0,$8e),e($8e,NVr),e(j0,qVr),e(j0,fte),e(fte,jVr),e(j0,DVr),e(le,GVr),e(le,D0),e(D0,k8e),e(k8e,OVr),e(D0,VVr),e(D0,gte),e(gte,XVr),e(D0,zVr),e(le,QVr),e(le,G0),e(G0,S8e),e(S8e,WVr),e(G0,UVr),e(G0,hte),e(hte,HVr),e(G0,JVr),e(le,YVr),e(le,O0),e(O0,R8e),e(R8e,ZVr),e(O0,KVr),e(O0,ute),e(ute,eXr),e(O0,oXr),e(le,rXr),e(le,V0),e(V0,P8e),e(P8e,tXr),e(V0,aXr),e(V0,pte),e(pte,nXr),e(V0,sXr),e(le,lXr),e(le,X0),e(X0,B8e),e(B8e,iXr),e(X0,dXr),e(X0,_te),e(_te,mXr),e(X0,cXr),e(le,fXr),e(le,z0),e(z0,I8e),e(I8e,gXr),e(z0,hXr),e(z0,bte),e(bte,uXr),e(z0,pXr),e(le,_Xr),e(le,Q0),e(Q0,N8e),e(N8e,bXr),e(Q0,vXr),e(Q0,vte),e(vte,FXr),e(Q0,TXr),e(le,MXr),e(le,W0),e(W0,q8e),e(q8e,EXr),e(W0,CXr),e(W0,Fte),e(Fte,wXr),e(W0,AXr),e(le,LXr),e(le,U0),e(U0,j8e),e(j8e,yXr),e(U0,xXr),e(U0,Tte),e(Tte,$Xr),e(U0,kXr),e(le,SXr),e(le,H0),e(H0,D8e),e(D8e,RXr),e(H0,PXr),e(H0,Mte),e(Mte,BXr),e(H0,IXr),e(le,NXr),e(le,J0),e(J0,G8e),e(G8e,qXr),e(J0,jXr),e(J0,Ete),e(Ete,DXr),e(J0,GXr),e(le,OXr),e(le,Y0),e(Y0,O8e),e(O8e,VXr),e(Y0,XXr),e(Y0,Cte),e(Cte,zXr),e(Y0,QXr),e(le,WXr),e(le,Z0),e(Z0,V8e),e(V8e,UXr),e(Z0,HXr),e(Z0,wte),e(wte,JXr),e(Z0,YXr),e(le,ZXr),e(le,K0),e(K0,X8e),e(X8e,KXr),e(K0,ezr),e(K0,Ate),e(Ate,ozr),e(K0,rzr),e(le,tzr),e(le,ew),e(ew,z8e),e(z8e,azr),e(ew,nzr),e(ew,Lte),e(Lte,szr),e(ew,lzr),e(le,izr),e(le,ow),e(ow,Q8e),e(Q8e,dzr),e(ow,mzr),e(ow,yte),e(yte,czr),e(ow,fzr),e(Gr,gzr),M(rw,Gr,null),b(c,Lao,_),b(c,hc,_),e(hc,tw),e(tw,W8e),M(FR,W8e,null),e(hc,hzr),e(hc,U8e),e(U8e,uzr),b(c,yao,_),b(c,fr,_),M(TR,fr,null),e(fr,pzr),e(fr,uc),e(uc,_zr),e(uc,xte),e(xte,bzr),e(uc,vzr),e(uc,$te),e($te,Fzr),e(uc,Tzr),e(fr,Mzr),e(fr,MR),e(MR,Ezr),e(MR,H8e),e(H8e,Czr),e(MR,wzr),e(fr,Azr),e(fr,Zt),M(ER,Zt,null),e(Zt,Lzr),e(Zt,J8e),e(J8e,yzr),e(Zt,xzr),e(Zt,pc),e(pc,$zr),e(pc,Y8e),e(Y8e,kzr),e(pc,Szr),e(pc,kte),e(kte,Rzr),e(pc,Pzr),e(Zt,Bzr),M(aw,Zt,null),e(fr,Izr),e(fr,Or),M(CR,Or,null),e(Or,Nzr),e(Or,Z8e),e(Z8e,qzr),e(Or,jzr),e(Or,Nn),e(Nn,Dzr),e(Nn,K8e),e(K8e,Gzr),e(Nn,Ozr),e(Nn,eLe),e(eLe,Vzr),e(Nn,Xzr),e(Nn,oLe),e(oLe,zzr),e(Nn,Qzr),e(Or,Wzr),e(Or,Me),e(Me,nw),e(nw,rLe),e(rLe,Uzr),e(nw,Hzr),e(nw,Ste),e(Ste,Jzr),e(nw,Yzr),e(Me,Zzr),e(Me,sw),e(sw,tLe),e(tLe,Kzr),e(sw,eQr),e(sw,Rte),e(Rte,oQr),e(sw,rQr),e(Me,tQr),e(Me,lw),e(lw,aLe),e(aLe,aQr),e(lw,nQr),e(lw,Pte),e(Pte,sQr),e(lw,lQr),e(Me,iQr),e(Me,iw),e(iw,nLe),e(nLe,dQr),e(iw,mQr),e(iw,Bte),e(Bte,cQr),e(iw,fQr),e(Me,gQr),e(Me,dw),e(dw,sLe),e(sLe,hQr),e(dw,uQr),e(dw,Ite),e(Ite,pQr),e(dw,_Qr),e(Me,bQr),e(Me,mw),e(mw,lLe),e(lLe,vQr),e(mw,FQr),e(mw,Nte),e(Nte,TQr),e(mw,MQr),e(Me,EQr),e(Me,cw),e(cw,iLe),e(iLe,CQr),e(cw,wQr),e(cw,qte),e(qte,AQr),e(cw,LQr),e(Me,yQr),e(Me,fw),e(fw,dLe),e(dLe,xQr),e(fw,$Qr),e(fw,jte),e(jte,kQr),e(fw,SQr),e(Me,RQr),e(Me,gw),e(gw,mLe),e(mLe,PQr),e(gw,BQr),e(gw,Dte),e(Dte,IQr),e(gw,NQr),e(Me,qQr),e(Me,hw),e(hw,cLe),e(cLe,jQr),e(hw,DQr),e(hw,Gte),e(Gte,GQr),e(hw,OQr),e(Me,VQr),e(Me,uw),e(uw,fLe),e(fLe,XQr),e(uw,zQr),e(uw,Ote),e(Ote,QQr),e(uw,WQr),e(Me,UQr),e(Me,pw),e(pw,gLe),e(gLe,HQr),e(pw,JQr),e(pw,Vte),e(Vte,YQr),e(pw,ZQr),e(Me,KQr),e(Me,_w),e(_w,hLe),e(hLe,eWr),e(_w,oWr),e(_w,Xte),e(Xte,rWr),e(_w,tWr),e(Me,aWr),e(Me,bw),e(bw,uLe),e(uLe,nWr),e(bw,sWr),e(bw,zte),e(zte,lWr),e(bw,iWr),e(Or,dWr),M(vw,Or,null),b(c,xao,_),b(c,_c,_),e(_c,Fw),e(Fw,pLe),M(wR,pLe,null),e(_c,mWr),e(_c,_Le),e(_Le,cWr),b(c,$ao,_),b(c,gr,_),M(AR,gr,null),e(gr,fWr),e(gr,bc),e(bc,gWr),e(bc,Qte),e(Qte,hWr),e(bc,uWr),e(bc,Wte),e(Wte,pWr),e(bc,_Wr),e(gr,bWr),e(gr,LR),e(LR,vWr),e(LR,bLe),e(bLe,FWr),e(LR,TWr),e(gr,MWr),e(gr,Kt),M(yR,Kt,null),e(Kt,EWr),e(Kt,vLe),e(vLe,CWr),e(Kt,wWr),e(Kt,vc),e(vc,AWr),e(vc,FLe),e(FLe,LWr),e(vc,yWr),e(vc,Ute),e(Ute,xWr),e(vc,$Wr),e(Kt,kWr),M(Tw,Kt,null),e(gr,SWr),e(gr,Vr),M(xR,Vr,null),e(Vr,RWr),e(Vr,TLe),e(TLe,PWr),e(Vr,BWr),e(Vr,qn),e(qn,IWr),e(qn,MLe),e(MLe,NWr),e(qn,qWr),e(qn,ELe),e(ELe,jWr),e(qn,DWr),e(qn,CLe),e(CLe,GWr),e(qn,OWr),e(Vr,VWr),e(Vr,ye),e(ye,Mw),e(Mw,wLe),e(wLe,XWr),e(Mw,zWr),e(Mw,Hte),e(Hte,QWr),e(Mw,WWr),e(ye,UWr),e(ye,Ew),e(Ew,ALe),e(ALe,HWr),e(Ew,JWr),e(Ew,Jte),e(Jte,YWr),e(Ew,ZWr),e(ye,KWr),e(ye,Cw),e(Cw,LLe),e(LLe,eUr),e(Cw,oUr),e(Cw,Yte),e(Yte,rUr),e(Cw,tUr),e(ye,aUr),e(ye,Sl),e(Sl,yLe),e(yLe,nUr),e(Sl,sUr),e(Sl,Zte),e(Zte,lUr),e(Sl,iUr),e(Sl,Kte),e(Kte,dUr),e(Sl,mUr),e(ye,cUr),e(ye,ww),e(ww,xLe),e(xLe,fUr),e(ww,gUr),e(ww,eae),e(eae,hUr),e(ww,uUr),e(ye,pUr),e(ye,Aw),e(Aw,$Le),e($Le,_Ur),e(Aw,bUr),e(Aw,oae),e(oae,vUr),e(Aw,FUr),e(ye,TUr),e(ye,Lw),e(Lw,kLe),e(kLe,MUr),e(Lw,EUr),e(Lw,rae),e(rae,CUr),e(Lw,wUr),e(ye,AUr),e(ye,yw),e(yw,SLe),e(SLe,LUr),e(yw,yUr),e(yw,tae),e(tae,xUr),e(yw,$Ur),e(ye,kUr),e(ye,xw),e(xw,RLe),e(RLe,SUr),e(xw,RUr),e(xw,aae),e(aae,PUr),e(xw,BUr),e(ye,IUr),e(ye,$w),e($w,PLe),e(PLe,NUr),e($w,qUr),e($w,nae),e(nae,jUr),e($w,DUr),e(Vr,GUr),M(kw,Vr,null),b(c,kao,_),b(c,Fc,_),e(Fc,Sw),e(Sw,BLe),M($R,BLe,null),e(Fc,OUr),e(Fc,ILe),e(ILe,VUr),b(c,Sao,_),b(c,hr,_),M(kR,hr,null),e(hr,XUr),e(hr,Tc),e(Tc,zUr),e(Tc,sae),e(sae,QUr),e(Tc,WUr),e(Tc,lae),e(lae,UUr),e(Tc,HUr),e(hr,JUr),e(hr,SR),e(SR,YUr),e(SR,NLe),e(NLe,ZUr),e(SR,KUr),e(hr,eHr),e(hr,ea),M(RR,ea,null),e(ea,oHr),e(ea,qLe),e(qLe,rHr),e(ea,tHr),e(ea,Mc),e(Mc,aHr),e(Mc,jLe),e(jLe,nHr),e(Mc,sHr),e(Mc,iae),e(iae,lHr),e(Mc,iHr),e(ea,dHr),M(Rw,ea,null),e(hr,mHr),e(hr,Xr),M(PR,Xr,null),e(Xr,cHr),e(Xr,DLe),e(DLe,fHr),e(Xr,gHr),e(Xr,jn),e(jn,hHr),e(jn,GLe),e(GLe,uHr),e(jn,pHr),e(jn,OLe),e(OLe,_Hr),e(jn,bHr),e(jn,VLe),e(VLe,vHr),e(jn,FHr),e(Xr,THr),e(Xr,Ec),e(Ec,Pw),e(Pw,XLe),e(XLe,MHr),e(Pw,EHr),e(Pw,dae),e(dae,CHr),e(Pw,wHr),e(Ec,AHr),e(Ec,Bw),e(Bw,zLe),e(zLe,LHr),e(Bw,yHr),e(Bw,mae),e(mae,xHr),e(Bw,$Hr),e(Ec,kHr),e(Ec,Iw),e(Iw,QLe),e(QLe,SHr),e(Iw,RHr),e(Iw,cae),e(cae,PHr),e(Iw,BHr),e(Xr,IHr),M(Nw,Xr,null),b(c,Rao,_),b(c,Cc,_),e(Cc,qw),e(qw,WLe),M(BR,WLe,null),e(Cc,NHr),e(Cc,ULe),e(ULe,qHr),b(c,Pao,_),b(c,ur,_),M(IR,ur,null),e(ur,jHr),e(ur,wc),e(wc,DHr),e(wc,fae),e(fae,GHr),e(wc,OHr),e(wc,gae),e(gae,VHr),e(wc,XHr),e(ur,zHr),e(ur,NR),e(NR,QHr),e(NR,HLe),e(HLe,WHr),e(NR,UHr),e(ur,HHr),e(ur,oa),M(qR,oa,null),e(oa,JHr),e(oa,JLe),e(JLe,YHr),e(oa,ZHr),e(oa,Ac),e(Ac,KHr),e(Ac,YLe),e(YLe,eJr),e(Ac,oJr),e(Ac,hae),e(hae,rJr),e(Ac,tJr),e(oa,aJr),M(jw,oa,null),e(ur,nJr),e(ur,zr),M(jR,zr,null),e(zr,sJr),e(zr,ZLe),e(ZLe,lJr),e(zr,iJr),e(zr,Dn),e(Dn,dJr),e(Dn,KLe),e(KLe,mJr),e(Dn,cJr),e(Dn,eye),e(eye,fJr),e(Dn,gJr),e(Dn,oye),e(oye,hJr),e(Dn,uJr),e(zr,pJr),e(zr,ce),e(ce,Dw),e(Dw,rye),e(rye,_Jr),e(Dw,bJr),e(Dw,uae),e(uae,vJr),e(Dw,FJr),e(ce,TJr),e(ce,Gw),e(Gw,tye),e(tye,MJr),e(Gw,EJr),e(Gw,pae),e(pae,CJr),e(Gw,wJr),e(ce,AJr),e(ce,Ow),e(Ow,aye),e(aye,LJr),e(Ow,yJr),e(Ow,_ae),e(_ae,xJr),e(Ow,$Jr),e(ce,kJr),e(ce,Vw),e(Vw,nye),e(nye,SJr),e(Vw,RJr),e(Vw,bae),e(bae,PJr),e(Vw,BJr),e(ce,IJr),e(ce,Xw),e(Xw,sye),e(sye,NJr),e(Xw,qJr),e(Xw,vae),e(vae,jJr),e(Xw,DJr),e(ce,GJr),e(ce,zw),e(zw,lye),e(lye,OJr),e(zw,VJr),e(zw,Fae),e(Fae,XJr),e(zw,zJr),e(ce,QJr),e(ce,Qw),e(Qw,iye),e(iye,WJr),e(Qw,UJr),e(Qw,Tae),e(Tae,HJr),e(Qw,JJr),e(ce,YJr),e(ce,Ww),e(Ww,dye),e(dye,ZJr),e(Ww,KJr),e(Ww,Mae),e(Mae,eYr),e(Ww,oYr),e(ce,rYr),e(ce,Uw),e(Uw,mye),e(mye,tYr),e(Uw,aYr),e(Uw,Eae),e(Eae,nYr),e(Uw,sYr),e(ce,lYr),e(ce,Hw),e(Hw,cye),e(cye,iYr),e(Hw,dYr),e(Hw,Cae),e(Cae,mYr),e(Hw,cYr),e(ce,fYr),e(ce,Jw),e(Jw,fye),e(fye,gYr),e(Jw,hYr),e(Jw,wae),e(wae,uYr),e(Jw,pYr),e(ce,_Yr),e(ce,Yw),e(Yw,gye),e(gye,bYr),e(Yw,vYr),e(Yw,Aae),e(Aae,FYr),e(Yw,TYr),e(ce,MYr),e(ce,Zw),e(Zw,hye),e(hye,EYr),e(Zw,CYr),e(Zw,Lae),e(Lae,wYr),e(Zw,AYr),e(ce,LYr),e(ce,Kw),e(Kw,uye),e(uye,yYr),e(Kw,xYr),e(Kw,yae),e(yae,$Yr),e(Kw,kYr),e(ce,SYr),e(ce,eA),e(eA,pye),e(pye,RYr),e(eA,PYr),e(eA,xae),e(xae,BYr),e(eA,IYr),e(ce,NYr),e(ce,oA),e(oA,_ye),e(_ye,qYr),e(oA,jYr),e(oA,$ae),e($ae,DYr),e(oA,GYr),e(ce,OYr),e(ce,rA),e(rA,bye),e(bye,VYr),e(rA,XYr),e(rA,kae),e(kae,zYr),e(rA,QYr),e(ce,WYr),e(ce,tA),e(tA,vye),e(vye,UYr),e(tA,HYr),e(tA,Sae),e(Sae,JYr),e(tA,YYr),e(ce,ZYr),e(ce,aA),e(aA,Fye),e(Fye,KYr),e(aA,eZr),e(aA,Rae),e(Rae,oZr),e(aA,rZr),e(ce,tZr),e(ce,nA),e(nA,Tye),e(Tye,aZr),e(nA,nZr),e(nA,Pae),e(Pae,sZr),e(nA,lZr),e(ce,iZr),e(ce,sA),e(sA,Mye),e(Mye,dZr),e(sA,mZr),e(sA,Bae),e(Bae,cZr),e(sA,fZr),e(zr,gZr),M(lA,zr,null),b(c,Bao,_),b(c,Lc,_),e(Lc,iA),e(iA,Eye),M(DR,Eye,null),e(Lc,hZr),e(Lc,Cye),e(Cye,uZr),b(c,Iao,_),b(c,pr,_),M(GR,pr,null),e(pr,pZr),e(pr,yc),e(yc,_Zr),e(yc,Iae),e(Iae,bZr),e(yc,vZr),e(yc,Nae),e(Nae,FZr),e(yc,TZr),e(pr,MZr),e(pr,OR),e(OR,EZr),e(OR,wye),e(wye,CZr),e(OR,wZr),e(pr,AZr),e(pr,ra),M(VR,ra,null),e(ra,LZr),e(ra,Aye),e(Aye,yZr),e(ra,xZr),e(ra,xc),e(xc,$Zr),e(xc,Lye),e(Lye,kZr),e(xc,SZr),e(xc,qae),e(qae,RZr),e(xc,PZr),e(ra,BZr),M(dA,ra,null),e(pr,IZr),e(pr,Qr),M(XR,Qr,null),e(Qr,NZr),e(Qr,yye),e(yye,qZr),e(Qr,jZr),e(Qr,Gn),e(Gn,DZr),e(Gn,xye),e(xye,GZr),e(Gn,OZr),e(Gn,$ye),e($ye,VZr),e(Gn,XZr),e(Gn,kye),e(kye,zZr),e(Gn,QZr),e(Qr,WZr),e(Qr,xe),e(xe,mA),e(mA,Sye),e(Sye,UZr),e(mA,HZr),e(mA,jae),e(jae,JZr),e(mA,YZr),e(xe,ZZr),e(xe,cA),e(cA,Rye),e(Rye,KZr),e(cA,eKr),e(cA,Dae),e(Dae,oKr),e(cA,rKr),e(xe,tKr),e(xe,fA),e(fA,Pye),e(Pye,aKr),e(fA,nKr),e(fA,Gae),e(Gae,sKr),e(fA,lKr),e(xe,iKr),e(xe,gA),e(gA,Bye),e(Bye,dKr),e(gA,mKr),e(gA,Oae),e(Oae,cKr),e(gA,fKr),e(xe,gKr),e(xe,hA),e(hA,Iye),e(Iye,hKr),e(hA,uKr),e(hA,Vae),e(Vae,pKr),e(hA,_Kr),e(xe,bKr),e(xe,uA),e(uA,Nye),e(Nye,vKr),e(uA,FKr),e(uA,Xae),e(Xae,TKr),e(uA,MKr),e(xe,EKr),e(xe,pA),e(pA,qye),e(qye,CKr),e(pA,wKr),e(pA,zae),e(zae,AKr),e(pA,LKr),e(xe,yKr),e(xe,_A),e(_A,jye),e(jye,xKr),e(_A,$Kr),e(_A,Qae),e(Qae,kKr),e(_A,SKr),e(xe,RKr),e(xe,bA),e(bA,Dye),e(Dye,PKr),e(bA,BKr),e(bA,Wae),e(Wae,IKr),e(bA,NKr),e(xe,qKr),e(xe,vA),e(vA,Gye),e(Gye,jKr),e(vA,DKr),e(vA,Uae),e(Uae,GKr),e(vA,OKr),e(Qr,VKr),M(FA,Qr,null),b(c,Nao,_),b(c,$c,_),e($c,TA),e(TA,Oye),M(zR,Oye,null),e($c,XKr),e($c,Vye),e(Vye,zKr),b(c,qao,_),b(c,_r,_),M(QR,_r,null),e(_r,QKr),e(_r,kc),e(kc,WKr),e(kc,Hae),e(Hae,UKr),e(kc,HKr),e(kc,Jae),e(Jae,JKr),e(kc,YKr),e(_r,ZKr),e(_r,WR),e(WR,KKr),e(WR,Xye),e(Xye,eet),e(WR,oet),e(_r,ret),e(_r,ta),M(UR,ta,null),e(ta,tet),e(ta,zye),e(zye,aet),e(ta,net),e(ta,Sc),e(Sc,set),e(Sc,Qye),e(Qye,iet),e(Sc,det),e(Sc,Yae),e(Yae,met),e(Sc,cet),e(ta,fet),M(MA,ta,null),e(_r,get),e(_r,Wr),M(HR,Wr,null),e(Wr,het),e(Wr,Wye),e(Wye,uet),e(Wr,pet),e(Wr,On),e(On,_et),e(On,Uye),e(Uye,bet),e(On,vet),e(On,Hye),e(Hye,Fet),e(On,Tet),e(On,Jye),e(Jye,Met),e(On,Eet),e(Wr,Cet),e(Wr,re),e(re,EA),e(EA,Yye),e(Yye,wet),e(EA,Aet),e(EA,Zae),e(Zae,Let),e(EA,yet),e(re,xet),e(re,CA),e(CA,Zye),e(Zye,$et),e(CA,ket),e(CA,Kae),e(Kae,Set),e(CA,Ret),e(re,Pet),e(re,wA),e(wA,Kye),e(Kye,Bet),e(wA,Iet),e(wA,ene),e(ene,Net),e(wA,qet),e(re,jet),e(re,AA),e(AA,e9e),e(e9e,Det),e(AA,Get),e(AA,one),e(one,Oet),e(AA,Vet),e(re,Xet),e(re,LA),e(LA,o9e),e(o9e,zet),e(LA,Qet),e(LA,rne),e(rne,Wet),e(LA,Uet),e(re,Het),e(re,yA),e(yA,r9e),e(r9e,Jet),e(yA,Yet),e(yA,tne),e(tne,Zet),e(yA,Ket),e(re,eot),e(re,xA),e(xA,t9e),e(t9e,oot),e(xA,rot),e(xA,ane),e(ane,tot),e(xA,aot),e(re,not),e(re,$A),e($A,a9e),e(a9e,sot),e($A,lot),e($A,nne),e(nne,iot),e($A,dot),e(re,mot),e(re,kA),e(kA,n9e),e(n9e,cot),e(kA,fot),e(kA,sne),e(sne,got),e(kA,hot),e(re,uot),e(re,SA),e(SA,s9e),e(s9e,pot),e(SA,_ot),e(SA,lne),e(lne,bot),e(SA,vot),e(re,Fot),e(re,RA),e(RA,l9e),e(l9e,Tot),e(RA,Mot),e(RA,ine),e(ine,Eot),e(RA,Cot),e(re,wot),e(re,PA),e(PA,i9e),e(i9e,Aot),e(PA,Lot),e(PA,dne),e(dne,yot),e(PA,xot),e(re,$ot),e(re,BA),e(BA,d9e),e(d9e,kot),e(BA,Sot),e(BA,mne),e(mne,Rot),e(BA,Pot),e(re,Bot),e(re,IA),e(IA,m9e),e(m9e,Iot),e(IA,Not),e(IA,cne),e(cne,qot),e(IA,jot),e(re,Dot),e(re,NA),e(NA,c9e),e(c9e,Got),e(NA,Oot),e(NA,fne),e(fne,Vot),e(NA,Xot),e(re,zot),e(re,qA),e(qA,f9e),e(f9e,Qot),e(qA,Wot),e(qA,gne),e(gne,Uot),e(qA,Hot),e(re,Jot),e(re,jA),e(jA,g9e),e(g9e,Yot),e(jA,Zot),e(jA,hne),e(hne,Kot),e(jA,ert),e(re,ort),e(re,DA),e(DA,h9e),e(h9e,rrt),e(DA,trt),e(DA,une),e(une,art),e(DA,nrt),e(re,srt),e(re,GA),e(GA,u9e),e(u9e,lrt),e(GA,irt),e(GA,pne),e(pne,drt),e(GA,mrt),e(re,crt),e(re,OA),e(OA,p9e),e(p9e,frt),e(OA,grt),e(OA,_ne),e(_ne,hrt),e(OA,urt),e(re,prt),e(re,VA),e(VA,_9e),e(_9e,_rt),e(VA,brt),e(VA,bne),e(bne,vrt),e(VA,Frt),e(re,Trt),e(re,XA),e(XA,b9e),e(b9e,Mrt),e(XA,Ert),e(XA,vne),e(vne,Crt),e(XA,wrt),e(re,Art),e(re,zA),e(zA,v9e),e(v9e,Lrt),e(zA,yrt),e(zA,Fne),e(Fne,xrt),e(zA,$rt),e(re,krt),e(re,QA),e(QA,F9e),e(F9e,Srt),e(QA,Rrt),e(QA,Tne),e(Tne,Prt),e(QA,Brt),e(re,Irt),e(re,WA),e(WA,T9e),e(T9e,Nrt),e(WA,qrt),e(WA,Mne),e(Mne,jrt),e(WA,Drt),e(re,Grt),e(re,UA),e(UA,M9e),e(M9e,Ort),e(UA,Vrt),e(UA,Ene),e(Ene,Xrt),e(UA,zrt),e(re,Qrt),e(re,HA),e(HA,E9e),e(E9e,Wrt),e(HA,Urt),e(HA,Cne),e(Cne,Hrt),e(HA,Jrt),e(re,Yrt),e(re,JA),e(JA,C9e),e(C9e,Zrt),e(JA,Krt),e(JA,wne),e(wne,ett),e(JA,ott),e(Wr,rtt),M(YA,Wr,null),b(c,jao,_),b(c,Rc,_),e(Rc,ZA),e(ZA,w9e),M(JR,w9e,null),e(Rc,ttt),e(Rc,A9e),e(A9e,att),b(c,Dao,_),b(c,br,_),M(YR,br,null),e(br,ntt),e(br,Pc),e(Pc,stt),e(Pc,Ane),e(Ane,ltt),e(Pc,itt),e(Pc,Lne),e(Lne,dtt),e(Pc,mtt),e(br,ctt),e(br,ZR),e(ZR,ftt),e(ZR,L9e),e(L9e,gtt),e(ZR,htt),e(br,utt),e(br,aa),M(KR,aa,null),e(aa,ptt),e(aa,y9e),e(y9e,_tt),e(aa,btt),e(aa,Bc),e(Bc,vtt),e(Bc,x9e),e(x9e,Ftt),e(Bc,Ttt),e(Bc,yne),e(yne,Mtt),e(Bc,Ett),e(aa,Ctt),M(KA,aa,null),e(br,wtt),e(br,Ur),M(eP,Ur,null),e(Ur,Att),e(Ur,$9e),e($9e,Ltt),e(Ur,ytt),e(Ur,Vn),e(Vn,xtt),e(Vn,k9e),e(k9e,$tt),e(Vn,ktt),e(Vn,S9e),e(S9e,Stt),e(Vn,Rtt),e(Vn,R9e),e(R9e,Ptt),e(Vn,Btt),e(Ur,Itt),e(Ur,ve),e(ve,e6),e(e6,P9e),e(P9e,Ntt),e(e6,qtt),e(e6,xne),e(xne,jtt),e(e6,Dtt),e(ve,Gtt),e(ve,o6),e(o6,B9e),e(B9e,Ott),e(o6,Vtt),e(o6,$ne),e($ne,Xtt),e(o6,ztt),e(ve,Qtt),e(ve,r6),e(r6,I9e),e(I9e,Wtt),e(r6,Utt),e(r6,kne),e(kne,Htt),e(r6,Jtt),e(ve,Ytt),e(ve,t6),e(t6,N9e),e(N9e,Ztt),e(t6,Ktt),e(t6,Sne),e(Sne,eat),e(t6,oat),e(ve,rat),e(ve,a6),e(a6,q9e),e(q9e,tat),e(a6,aat),e(a6,Rne),e(Rne,nat),e(a6,sat),e(ve,lat),e(ve,n6),e(n6,j9e),e(j9e,iat),e(n6,dat),e(n6,Pne),e(Pne,mat),e(n6,cat),e(ve,fat),e(ve,s6),e(s6,D9e),e(D9e,gat),e(s6,hat),e(s6,Bne),e(Bne,uat),e(s6,pat),e(ve,_at),e(ve,l6),e(l6,G9e),e(G9e,bat),e(l6,vat),e(l6,Ine),e(Ine,Fat),e(l6,Tat),e(ve,Mat),e(ve,i6),e(i6,O9e),e(O9e,Eat),e(i6,Cat),e(i6,Nne),e(Nne,wat),e(i6,Aat),e(ve,Lat),e(ve,d6),e(d6,V9e),e(V9e,yat),e(d6,xat),e(d6,qne),e(qne,$at),e(d6,kat),e(ve,Sat),e(ve,m6),e(m6,X9e),e(X9e,Rat),e(m6,Pat),e(m6,jne),e(jne,Bat),e(m6,Iat),e(ve,Nat),e(ve,c6),e(c6,z9e),e(z9e,qat),e(c6,jat),e(c6,Dne),e(Dne,Dat),e(c6,Gat),e(ve,Oat),e(ve,f6),e(f6,Q9e),e(Q9e,Vat),e(f6,Xat),e(f6,Gne),e(Gne,zat),e(f6,Qat),e(ve,Wat),e(ve,g6),e(g6,W9e),e(W9e,Uat),e(g6,Hat),e(g6,One),e(One,Jat),e(g6,Yat),e(ve,Zat),e(ve,h6),e(h6,U9e),e(U9e,Kat),e(h6,ent),e(h6,Vne),e(Vne,ont),e(h6,rnt),e(ve,tnt),e(ve,u6),e(u6,H9e),e(H9e,ant),e(u6,nnt),e(u6,Xne),e(Xne,snt),e(u6,lnt),e(ve,int),e(ve,p6),e(p6,J9e),e(J9e,dnt),e(p6,mnt),e(p6,zne),e(zne,cnt),e(p6,fnt),e(Ur,gnt),M(_6,Ur,null),b(c,Gao,_),b(c,Ic,_),e(Ic,b6),e(b6,Y9e),M(oP,Y9e,null),e(Ic,hnt),e(Ic,Z9e),e(Z9e,unt),b(c,Oao,_),b(c,vr,_),M(rP,vr,null),e(vr,pnt),e(vr,Nc),e(Nc,_nt),e(Nc,Qne),e(Qne,bnt),e(Nc,vnt),e(Nc,Wne),e(Wne,Fnt),e(Nc,Tnt),e(vr,Mnt),e(vr,tP),e(tP,Ent),e(tP,K9e),e(K9e,Cnt),e(tP,wnt),e(vr,Ant),e(vr,na),M(aP,na,null),e(na,Lnt),e(na,exe),e(exe,ynt),e(na,xnt),e(na,qc),e(qc,$nt),e(qc,oxe),e(oxe,knt),e(qc,Snt),e(qc,Une),e(Une,Rnt),e(qc,Pnt),e(na,Bnt),M(v6,na,null),e(vr,Int),e(vr,Hr),M(nP,Hr,null),e(Hr,Nnt),e(Hr,rxe),e(rxe,qnt),e(Hr,jnt),e(Hr,Xn),e(Xn,Dnt),e(Xn,txe),e(txe,Gnt),e(Xn,Ont),e(Xn,axe),e(axe,Vnt),e(Xn,Xnt),e(Xn,nxe),e(nxe,znt),e(Xn,Qnt),e(Hr,Wnt),e(Hr,sP),e(sP,F6),e(F6,sxe),e(sxe,Unt),e(F6,Hnt),e(F6,Hne),e(Hne,Jnt),e(F6,Ynt),e(sP,Znt),e(sP,T6),e(T6,lxe),e(lxe,Knt),e(T6,est),e(T6,Jne),e(Jne,ost),e(T6,rst),e(Hr,tst),M(M6,Hr,null),b(c,Vao,_),b(c,jc,_),e(jc,E6),e(E6,ixe),M(lP,ixe,null),e(jc,ast),e(jc,dxe),e(dxe,nst),b(c,Xao,_),b(c,Fr,_),M(iP,Fr,null),e(Fr,sst),e(Fr,Dc),e(Dc,lst),e(Dc,Yne),e(Yne,ist),e(Dc,dst),e(Dc,Zne),e(Zne,mst),e(Dc,cst),e(Fr,fst),e(Fr,dP),e(dP,gst),e(dP,mxe),e(mxe,hst),e(dP,ust),e(Fr,pst),e(Fr,sa),M(mP,sa,null),e(sa,_st),e(sa,cxe),e(cxe,bst),e(sa,vst),e(sa,Gc),e(Gc,Fst),e(Gc,fxe),e(fxe,Tst),e(Gc,Mst),e(Gc,Kne),e(Kne,Est),e(Gc,Cst),e(sa,wst),M(C6,sa,null),e(Fr,Ast),e(Fr,Jr),M(cP,Jr,null),e(Jr,Lst),e(Jr,gxe),e(gxe,yst),e(Jr,xst),e(Jr,zn),e(zn,$st),e(zn,hxe),e(hxe,kst),e(zn,Sst),e(zn,uxe),e(uxe,Rst),e(zn,Pst),e(zn,pxe),e(pxe,Bst),e(zn,Ist),e(Jr,Nst),e(Jr,_xe),e(_xe,w6),e(w6,bxe),e(bxe,qst),e(w6,jst),e(w6,ese),e(ese,Dst),e(w6,Gst),e(Jr,Ost),M(A6,Jr,null),b(c,zao,_),b(c,Oc,_),e(Oc,L6),e(L6,vxe),M(fP,vxe,null),e(Oc,Vst),e(Oc,Fxe),e(Fxe,Xst),b(c,Qao,_),b(c,Tr,_),M(gP,Tr,null),e(Tr,zst),e(Tr,Vc),e(Vc,Qst),e(Vc,ose),e(ose,Wst),e(Vc,Ust),e(Vc,rse),e(rse,Hst),e(Vc,Jst),e(Tr,Yst),e(Tr,hP),e(hP,Zst),e(hP,Txe),e(Txe,Kst),e(hP,elt),e(Tr,olt),e(Tr,la),M(uP,la,null),e(la,rlt),e(la,Mxe),e(Mxe,tlt),e(la,alt),e(la,Xc),e(Xc,nlt),e(Xc,Exe),e(Exe,slt),e(Xc,llt),e(Xc,tse),e(tse,ilt),e(Xc,dlt),e(la,mlt),M(y6,la,null),e(Tr,clt),e(Tr,Yr),M(pP,Yr,null),e(Yr,flt),e(Yr,Cxe),e(Cxe,glt),e(Yr,hlt),e(Yr,Qn),e(Qn,ult),e(Qn,wxe),e(wxe,plt),e(Qn,_lt),e(Qn,Axe),e(Axe,blt),e(Qn,vlt),e(Qn,Lxe),e(Lxe,Flt),e(Qn,Tlt),e(Yr,Mlt),e(Yr,yxe),e(yxe,x6),e(x6,xxe),e(xxe,Elt),e(x6,Clt),e(x6,ase),e(ase,wlt),e(x6,Alt),e(Yr,Llt),M($6,Yr,null),b(c,Wao,_),b(c,zc,_),e(zc,k6),e(k6,$xe),M(_P,$xe,null),e(zc,ylt),e(zc,kxe),e(kxe,xlt),b(c,Uao,_),b(c,Mr,_),M(bP,Mr,null),e(Mr,$lt),e(Mr,Qc),e(Qc,klt),e(Qc,nse),e(nse,Slt),e(Qc,Rlt),e(Qc,sse),e(sse,Plt),e(Qc,Blt),e(Mr,Ilt),e(Mr,vP),e(vP,Nlt),e(vP,Sxe),e(Sxe,qlt),e(vP,jlt),e(Mr,Dlt),e(Mr,ia),M(FP,ia,null),e(ia,Glt),e(ia,Rxe),e(Rxe,Olt),e(ia,Vlt),e(ia,Wc),e(Wc,Xlt),e(Wc,Pxe),e(Pxe,zlt),e(Wc,Qlt),e(Wc,lse),e(lse,Wlt),e(Wc,Ult),e(ia,Hlt),M(S6,ia,null),e(Mr,Jlt),e(Mr,Zr),M(TP,Zr,null),e(Zr,Ylt),e(Zr,Bxe),e(Bxe,Zlt),e(Zr,Klt),e(Zr,Wn),e(Wn,eit),e(Wn,Ixe),e(Ixe,oit),e(Wn,rit),e(Wn,Nxe),e(Nxe,tit),e(Wn,ait),e(Wn,qxe),e(qxe,nit),e(Wn,sit),e(Zr,lit),e(Zr,ie),e(ie,R6),e(R6,jxe),e(jxe,iit),e(R6,dit),e(R6,ise),e(ise,mit),e(R6,cit),e(ie,fit),e(ie,P6),e(P6,Dxe),e(Dxe,git),e(P6,hit),e(P6,dse),e(dse,uit),e(P6,pit),e(ie,_it),e(ie,B6),e(B6,Gxe),e(Gxe,bit),e(B6,vit),e(B6,mse),e(mse,Fit),e(B6,Tit),e(ie,Mit),e(ie,I6),e(I6,Oxe),e(Oxe,Eit),e(I6,Cit),e(I6,cse),e(cse,wit),e(I6,Ait),e(ie,Lit),e(ie,N6),e(N6,Vxe),e(Vxe,yit),e(N6,xit),e(N6,fse),e(fse,$it),e(N6,kit),e(ie,Sit),e(ie,q6),e(q6,Xxe),e(Xxe,Rit),e(q6,Pit),e(q6,gse),e(gse,Bit),e(q6,Iit),e(ie,Nit),e(ie,j6),e(j6,zxe),e(zxe,qit),e(j6,jit),e(j6,hse),e(hse,Dit),e(j6,Git),e(ie,Oit),e(ie,D6),e(D6,Qxe),e(Qxe,Vit),e(D6,Xit),e(D6,use),e(use,zit),e(D6,Qit),e(ie,Wit),e(ie,G6),e(G6,Wxe),e(Wxe,Uit),e(G6,Hit),e(G6,pse),e(pse,Jit),e(G6,Yit),e(ie,Zit),e(ie,O6),e(O6,Uxe),e(Uxe,Kit),e(O6,edt),e(O6,_se),e(_se,odt),e(O6,rdt),e(ie,tdt),e(ie,V6),e(V6,Hxe),e(Hxe,adt),e(V6,ndt),e(V6,bse),e(bse,sdt),e(V6,ldt),e(ie,idt),e(ie,X6),e(X6,Jxe),e(Jxe,ddt),e(X6,mdt),e(X6,vse),e(vse,cdt),e(X6,fdt),e(ie,gdt),e(ie,z6),e(z6,Yxe),e(Yxe,hdt),e(z6,udt),e(z6,Fse),e(Fse,pdt),e(z6,_dt),e(ie,bdt),e(ie,Q6),e(Q6,Zxe),e(Zxe,vdt),e(Q6,Fdt),e(Q6,Tse),e(Tse,Tdt),e(Q6,Mdt),e(ie,Edt),e(ie,W6),e(W6,Kxe),e(Kxe,Cdt),e(W6,wdt),e(W6,Mse),e(Mse,Adt),e(W6,Ldt),e(ie,ydt),e(ie,U6),e(U6,e$e),e(e$e,xdt),e(U6,$dt),e(U6,Ese),e(Ese,kdt),e(U6,Sdt),e(ie,Rdt),e(ie,H6),e(H6,o$e),e(o$e,Pdt),e(H6,Bdt),e(H6,Cse),e(Cse,Idt),e(H6,Ndt),e(ie,qdt),e(ie,J6),e(J6,r$e),e(r$e,jdt),e(J6,Ddt),e(J6,wse),e(wse,Gdt),e(J6,Odt),e(ie,Vdt),e(ie,Y6),e(Y6,t$e),e(t$e,Xdt),e(Y6,zdt),e(Y6,Ase),e(Ase,Qdt),e(Y6,Wdt),e(ie,Udt),e(ie,Z6),e(Z6,a$e),e(a$e,Hdt),e(Z6,Jdt),e(Z6,Lse),e(Lse,Ydt),e(Z6,Zdt),e(ie,Kdt),e(ie,K6),e(K6,n$e),e(n$e,emt),e(K6,omt),e(K6,yse),e(yse,rmt),e(K6,tmt),e(ie,amt),e(ie,e7),e(e7,s$e),e(s$e,nmt),e(e7,smt),e(e7,xse),e(xse,lmt),e(e7,imt),e(Zr,dmt),M(o7,Zr,null),b(c,Hao,_),b(c,Uc,_),e(Uc,r7),e(r7,l$e),M(MP,l$e,null),e(Uc,mmt),e(Uc,i$e),e(i$e,cmt),b(c,Jao,_),b(c,Er,_),M(EP,Er,null),e(Er,fmt),e(Er,Hc),e(Hc,gmt),e(Hc,$se),e($se,hmt),e(Hc,umt),e(Hc,kse),e(kse,pmt),e(Hc,_mt),e(Er,bmt),e(Er,CP),e(CP,vmt),e(CP,d$e),e(d$e,Fmt),e(CP,Tmt),e(Er,Mmt),e(Er,da),M(wP,da,null),e(da,Emt),e(da,m$e),e(m$e,Cmt),e(da,wmt),e(da,Jc),e(Jc,Amt),e(Jc,c$e),e(c$e,Lmt),e(Jc,ymt),e(Jc,Sse),e(Sse,xmt),e(Jc,$mt),e(da,kmt),M(t7,da,null),e(Er,Smt),e(Er,Kr),M(AP,Kr,null),e(Kr,Rmt),e(Kr,f$e),e(f$e,Pmt),e(Kr,Bmt),e(Kr,Un),e(Un,Imt),e(Un,g$e),e(g$e,Nmt),e(Un,qmt),e(Un,h$e),e(h$e,jmt),e(Un,Dmt),e(Un,u$e),e(u$e,Gmt),e(Un,Omt),e(Kr,Vmt),e(Kr,fe),e(fe,a7),e(a7,p$e),e(p$e,Xmt),e(a7,zmt),e(a7,Rse),e(Rse,Qmt),e(a7,Wmt),e(fe,Umt),e(fe,n7),e(n7,_$e),e(_$e,Hmt),e(n7,Jmt),e(n7,Pse),e(Pse,Ymt),e(n7,Zmt),e(fe,Kmt),e(fe,s7),e(s7,b$e),e(b$e,ect),e(s7,oct),e(s7,Bse),e(Bse,rct),e(s7,tct),e(fe,act),e(fe,l7),e(l7,v$e),e(v$e,nct),e(l7,sct),e(l7,Ise),e(Ise,lct),e(l7,ict),e(fe,dct),e(fe,i7),e(i7,F$e),e(F$e,mct),e(i7,cct),e(i7,Nse),e(Nse,fct),e(i7,gct),e(fe,hct),e(fe,d7),e(d7,T$e),e(T$e,uct),e(d7,pct),e(d7,qse),e(qse,_ct),e(d7,bct),e(fe,vct),e(fe,m7),e(m7,M$e),e(M$e,Fct),e(m7,Tct),e(m7,jse),e(jse,Mct),e(m7,Ect),e(fe,Cct),e(fe,c7),e(c7,E$e),e(E$e,wct),e(c7,Act),e(c7,Dse),e(Dse,Lct),e(c7,yct),e(fe,xct),e(fe,f7),e(f7,C$e),e(C$e,$ct),e(f7,kct),e(f7,Gse),e(Gse,Sct),e(f7,Rct),e(fe,Pct),e(fe,g7),e(g7,w$e),e(w$e,Bct),e(g7,Ict),e(g7,Ose),e(Ose,Nct),e(g7,qct),e(fe,jct),e(fe,h7),e(h7,A$e),e(A$e,Dct),e(h7,Gct),e(h7,Vse),e(Vse,Oct),e(h7,Vct),e(fe,Xct),e(fe,u7),e(u7,L$e),e(L$e,zct),e(u7,Qct),e(u7,Xse),e(Xse,Wct),e(u7,Uct),e(fe,Hct),e(fe,p7),e(p7,y$e),e(y$e,Jct),e(p7,Yct),e(p7,zse),e(zse,Zct),e(p7,Kct),e(fe,eft),e(fe,_7),e(_7,x$e),e(x$e,oft),e(_7,rft),e(_7,Qse),e(Qse,tft),e(_7,aft),e(fe,nft),e(fe,b7),e(b7,$$e),e($$e,sft),e(b7,lft),e(b7,Wse),e(Wse,ift),e(b7,dft),e(fe,mft),e(fe,v7),e(v7,k$e),e(k$e,cft),e(v7,fft),e(v7,Use),e(Use,gft),e(v7,hft),e(fe,uft),e(fe,F7),e(F7,S$e),e(S$e,pft),e(F7,_ft),e(F7,Hse),e(Hse,bft),e(F7,vft),e(fe,Fft),e(fe,T7),e(T7,R$e),e(R$e,Tft),e(T7,Mft),e(T7,Jse),e(Jse,Eft),e(T7,Cft),e(fe,wft),e(fe,M7),e(M7,P$e),e(P$e,Aft),e(M7,Lft),e(M7,Yse),e(Yse,yft),e(M7,xft),e(fe,$ft),e(fe,E7),e(E7,B$e),e(B$e,kft),e(E7,Sft),e(E7,Zse),e(Zse,Rft),e(E7,Pft),e(fe,Bft),e(fe,C7),e(C7,I$e),e(I$e,Ift),e(C7,Nft),e(C7,Kse),e(Kse,qft),e(C7,jft),e(Kr,Dft),M(w7,Kr,null),b(c,Yao,_),b(c,Yc,_),e(Yc,A7),e(A7,N$e),M(LP,N$e,null),e(Yc,Gft),e(Yc,q$e),e(q$e,Oft),b(c,Zao,_),b(c,Cr,_),M(yP,Cr,null),e(Cr,Vft),e(Cr,Zc),e(Zc,Xft),e(Zc,ele),e(ele,zft),e(Zc,Qft),e(Zc,ole),e(ole,Wft),e(Zc,Uft),e(Cr,Hft),e(Cr,xP),e(xP,Jft),e(xP,j$e),e(j$e,Yft),e(xP,Zft),e(Cr,Kft),e(Cr,ma),M($P,ma,null),e(ma,egt),e(ma,D$e),e(D$e,ogt),e(ma,rgt),e(ma,Kc),e(Kc,tgt),e(Kc,G$e),e(G$e,agt),e(Kc,ngt),e(Kc,rle),e(rle,sgt),e(Kc,lgt),e(ma,igt),M(L7,ma,null),e(Cr,dgt),e(Cr,et),M(kP,et,null),e(et,mgt),e(et,O$e),e(O$e,cgt),e(et,fgt),e(et,Hn),e(Hn,ggt),e(Hn,V$e),e(V$e,hgt),e(Hn,ugt),e(Hn,X$e),e(X$e,pgt),e(Hn,_gt),e(Hn,z$e),e(z$e,bgt),e(Hn,vgt),e(et,Fgt),e(et,Q$e),e(Q$e,y7),e(y7,W$e),e(W$e,Tgt),e(y7,Mgt),e(y7,tle),e(tle,Egt),e(y7,Cgt),e(et,wgt),M(x7,et,null),b(c,Kao,_),b(c,ef,_),e(ef,$7),e($7,U$e),M(SP,U$e,null),e(ef,Agt),e(ef,H$e),e(H$e,Lgt),b(c,eno,_),b(c,wr,_),M(RP,wr,null),e(wr,ygt),e(wr,of),e(of,xgt),e(of,ale),e(ale,$gt),e(of,kgt),e(of,nle),e(nle,Sgt),e(of,Rgt),e(wr,Pgt),e(wr,PP),e(PP,Bgt),e(PP,J$e),e(J$e,Igt),e(PP,Ngt),e(wr,qgt),e(wr,ca),M(BP,ca,null),e(ca,jgt),e(ca,Y$e),e(Y$e,Dgt),e(ca,Ggt),e(ca,rf),e(rf,Ogt),e(rf,Z$e),e(Z$e,Vgt),e(rf,Xgt),e(rf,sle),e(sle,zgt),e(rf,Qgt),e(ca,Wgt),M(k7,ca,null),e(wr,Ugt),e(wr,ot),M(IP,ot,null),e(ot,Hgt),e(ot,K$e),e(K$e,Jgt),e(ot,Ygt),e(ot,Jn),e(Jn,Zgt),e(Jn,eke),e(eke,Kgt),e(Jn,eht),e(Jn,oke),e(oke,oht),e(Jn,rht),e(Jn,rke),e(rke,tht),e(Jn,aht),e(ot,nht),e(ot,NP),e(NP,S7),e(S7,tke),e(tke,sht),e(S7,lht),e(S7,lle),e(lle,iht),e(S7,dht),e(NP,mht),e(NP,R7),e(R7,ake),e(ake,cht),e(R7,fht),e(R7,ile),e(ile,ght),e(R7,hht),e(ot,uht),M(P7,ot,null),b(c,ono,_),b(c,tf,_),e(tf,B7),e(B7,nke),M(qP,nke,null),e(tf,pht),e(tf,ske),e(ske,_ht),b(c,rno,_),b(c,Ar,_),M(jP,Ar,null),e(Ar,bht),e(Ar,af),e(af,vht),e(af,dle),e(dle,Fht),e(af,Tht),e(af,mle),e(mle,Mht),e(af,Eht),e(Ar,Cht),e(Ar,DP),e(DP,wht),e(DP,lke),e(lke,Aht),e(DP,Lht),e(Ar,yht),e(Ar,fa),M(GP,fa,null),e(fa,xht),e(fa,ike),e(ike,$ht),e(fa,kht),e(fa,nf),e(nf,Sht),e(nf,dke),e(dke,Rht),e(nf,Pht),e(nf,cle),e(cle,Bht),e(nf,Iht),e(fa,Nht),M(I7,fa,null),e(Ar,qht),e(Ar,rt),M(OP,rt,null),e(rt,jht),e(rt,mke),e(mke,Dht),e(rt,Ght),e(rt,Yn),e(Yn,Oht),e(Yn,cke),e(cke,Vht),e(Yn,Xht),e(Yn,fke),e(fke,zht),e(Yn,Qht),e(Yn,gke),e(gke,Wht),e(Yn,Uht),e(rt,Hht),e(rt,te),e(te,N7),e(N7,hke),e(hke,Jht),e(N7,Yht),e(N7,fle),e(fle,Zht),e(N7,Kht),e(te,eut),e(te,q7),e(q7,uke),e(uke,out),e(q7,rut),e(q7,gle),e(gle,tut),e(q7,aut),e(te,nut),e(te,j7),e(j7,pke),e(pke,sut),e(j7,lut),e(j7,hle),e(hle,iut),e(j7,dut),e(te,mut),e(te,D7),e(D7,_ke),e(_ke,cut),e(D7,fut),e(D7,ule),e(ule,gut),e(D7,hut),e(te,uut),e(te,G7),e(G7,bke),e(bke,put),e(G7,_ut),e(G7,ple),e(ple,but),e(G7,vut),e(te,Fut),e(te,O7),e(O7,vke),e(vke,Tut),e(O7,Mut),e(O7,_le),e(_le,Eut),e(O7,Cut),e(te,wut),e(te,V7),e(V7,Fke),e(Fke,Aut),e(V7,Lut),e(V7,ble),e(ble,yut),e(V7,xut),e(te,$ut),e(te,X7),e(X7,Tke),e(Tke,kut),e(X7,Sut),e(X7,vle),e(vle,Rut),e(X7,Put),e(te,But),e(te,z7),e(z7,Mke),e(Mke,Iut),e(z7,Nut),e(z7,Fle),e(Fle,qut),e(z7,jut),e(te,Dut),e(te,Q7),e(Q7,Eke),e(Eke,Gut),e(Q7,Out),e(Q7,Tle),e(Tle,Vut),e(Q7,Xut),e(te,zut),e(te,W7),e(W7,Cke),e(Cke,Qut),e(W7,Wut),e(W7,Mle),e(Mle,Uut),e(W7,Hut),e(te,Jut),e(te,U7),e(U7,wke),e(wke,Yut),e(U7,Zut),e(U7,Ele),e(Ele,Kut),e(U7,ept),e(te,opt),e(te,H7),e(H7,Ake),e(Ake,rpt),e(H7,tpt),e(H7,Cle),e(Cle,apt),e(H7,npt),e(te,spt),e(te,J7),e(J7,Lke),e(Lke,lpt),e(J7,ipt),e(J7,wle),e(wle,dpt),e(J7,mpt),e(te,cpt),e(te,Y7),e(Y7,yke),e(yke,fpt),e(Y7,gpt),e(Y7,Ale),e(Ale,hpt),e(Y7,upt),e(te,ppt),e(te,Z7),e(Z7,xke),e(xke,_pt),e(Z7,bpt),e(Z7,Lle),e(Lle,vpt),e(Z7,Fpt),e(te,Tpt),e(te,K7),e(K7,$ke),e($ke,Mpt),e(K7,Ept),e(K7,yle),e(yle,Cpt),e(K7,wpt),e(te,Apt),e(te,e8),e(e8,kke),e(kke,Lpt),e(e8,ypt),e(e8,xle),e(xle,xpt),e(e8,$pt),e(te,kpt),e(te,o8),e(o8,Ske),e(Ske,Spt),e(o8,Rpt),e(o8,$le),e($le,Ppt),e(o8,Bpt),e(te,Ipt),e(te,r8),e(r8,Rke),e(Rke,Npt),e(r8,qpt),e(r8,kle),e(kle,jpt),e(r8,Dpt),e(te,Gpt),e(te,t8),e(t8,Pke),e(Pke,Opt),e(t8,Vpt),e(t8,Sle),e(Sle,Xpt),e(t8,zpt),e(te,Qpt),e(te,a8),e(a8,Bke),e(Bke,Wpt),e(a8,Upt),e(a8,Rle),e(Rle,Hpt),e(a8,Jpt),e(te,Ypt),e(te,n8),e(n8,Ike),e(Ike,Zpt),e(n8,Kpt),e(n8,Ple),e(Ple,e_t),e(n8,o_t),e(te,r_t),e(te,s8),e(s8,Nke),e(Nke,t_t),e(s8,a_t),e(s8,Ble),e(Ble,n_t),e(s8,s_t),e(te,l_t),e(te,l8),e(l8,qke),e(qke,i_t),e(l8,d_t),e(l8,Ile),e(Ile,m_t),e(l8,c_t),e(te,f_t),e(te,i8),e(i8,jke),e(jke,g_t),e(i8,h_t),e(i8,Nle),e(Nle,u_t),e(i8,p_t),e(te,__t),e(te,d8),e(d8,Dke),e(Dke,b_t),e(d8,v_t),e(d8,qle),e(qle,F_t),e(d8,T_t),e(rt,M_t),M(m8,rt,null),b(c,tno,_),b(c,sf,_),e(sf,c8),e(c8,Gke),M(VP,Gke,null),e(sf,E_t),e(sf,Oke),e(Oke,C_t),b(c,ano,_),b(c,Lr,_),M(XP,Lr,null),e(Lr,w_t),e(Lr,lf),e(lf,A_t),e(lf,jle),e(jle,L_t),e(lf,y_t),e(lf,Dle),e(Dle,x_t),e(lf,$_t),e(Lr,k_t),e(Lr,zP),e(zP,S_t),e(zP,Vke),e(Vke,R_t),e(zP,P_t),e(Lr,B_t),e(Lr,ga),M(QP,ga,null),e(ga,I_t),e(ga,Xke),e(Xke,N_t),e(ga,q_t),e(ga,df),e(df,j_t),e(df,zke),e(zke,D_t),e(df,G_t),e(df,Gle),e(Gle,O_t),e(df,V_t),e(ga,X_t),M(f8,ga,null),e(Lr,z_t),e(Lr,tt),M(WP,tt,null),e(tt,Q_t),e(tt,Qke),e(Qke,W_t),e(tt,U_t),e(tt,Zn),e(Zn,H_t),e(Zn,Wke),e(Wke,J_t),e(Zn,Y_t),e(Zn,Uke),e(Uke,Z_t),e(Zn,K_t),e(Zn,Hke),e(Hke,e1t),e(Zn,o1t),e(tt,r1t),e(tt,$e),e($e,g8),e(g8,Jke),e(Jke,t1t),e(g8,a1t),e(g8,Ole),e(Ole,n1t),e(g8,s1t),e($e,l1t),e($e,h8),e(h8,Yke),e(Yke,i1t),e(h8,d1t),e(h8,Vle),e(Vle,m1t),e(h8,c1t),e($e,f1t),e($e,u8),e(u8,Zke),e(Zke,g1t),e(u8,h1t),e(u8,Xle),e(Xle,u1t),e(u8,p1t),e($e,_1t),e($e,p8),e(p8,Kke),e(Kke,b1t),e(p8,v1t),e(p8,zle),e(zle,F1t),e(p8,T1t),e($e,M1t),e($e,_8),e(_8,eSe),e(eSe,E1t),e(_8,C1t),e(_8,Qle),e(Qle,w1t),e(_8,A1t),e($e,L1t),e($e,b8),e(b8,oSe),e(oSe,y1t),e(b8,x1t),e(b8,Wle),e(Wle,$1t),e(b8,k1t),e($e,S1t),e($e,v8),e(v8,rSe),e(rSe,R1t),e(v8,P1t),e(v8,Ule),e(Ule,B1t),e(v8,I1t),e($e,N1t),e($e,F8),e(F8,tSe),e(tSe,q1t),e(F8,j1t),e(F8,Hle),e(Hle,D1t),e(F8,G1t),e($e,O1t),e($e,T8),e(T8,aSe),e(aSe,V1t),e(T8,X1t),e(T8,Jle),e(Jle,z1t),e(T8,Q1t),e($e,W1t),e($e,M8),e(M8,nSe),e(nSe,U1t),e(M8,H1t),e(M8,Yle),e(Yle,J1t),e(M8,Y1t),e(tt,Z1t),M(E8,tt,null),b(c,nno,_),b(c,mf,_),e(mf,C8),e(C8,sSe),M(UP,sSe,null),e(mf,K1t),e(mf,lSe),e(lSe,e2t),b(c,sno,_),b(c,yr,_),M(HP,yr,null),e(yr,o2t),e(yr,cf),e(cf,r2t),e(cf,Zle),e(Zle,t2t),e(cf,a2t),e(cf,Kle),e(Kle,n2t),e(cf,s2t),e(yr,l2t),e(yr,JP),e(JP,i2t),e(JP,iSe),e(iSe,d2t),e(JP,m2t),e(yr,c2t),e(yr,ha),M(YP,ha,null),e(ha,f2t),e(ha,dSe),e(dSe,g2t),e(ha,h2t),e(ha,ff),e(ff,u2t),e(ff,mSe),e(mSe,p2t),e(ff,_2t),e(ff,eie),e(eie,b2t),e(ff,v2t),e(ha,F2t),M(w8,ha,null),e(yr,T2t),e(yr,at),M(ZP,at,null),e(at,M2t),e(at,cSe),e(cSe,E2t),e(at,C2t),e(at,Kn),e(Kn,w2t),e(Kn,fSe),e(fSe,A2t),e(Kn,L2t),e(Kn,gSe),e(gSe,y2t),e(Kn,x2t),e(Kn,hSe),e(hSe,$2t),e(Kn,k2t),e(at,S2t),e(at,Ee),e(Ee,A8),e(A8,uSe),e(uSe,R2t),e(A8,P2t),e(A8,oie),e(oie,B2t),e(A8,I2t),e(Ee,N2t),e(Ee,L8),e(L8,pSe),e(pSe,q2t),e(L8,j2t),e(L8,rie),e(rie,D2t),e(L8,G2t),e(Ee,O2t),e(Ee,y8),e(y8,_Se),e(_Se,V2t),e(y8,X2t),e(y8,tie),e(tie,z2t),e(y8,Q2t),e(Ee,W2t),e(Ee,x8),e(x8,bSe),e(bSe,U2t),e(x8,H2t),e(x8,aie),e(aie,J2t),e(x8,Y2t),e(Ee,Z2t),e(Ee,$8),e($8,vSe),e(vSe,K2t),e($8,ebt),e($8,nie),e(nie,obt),e($8,rbt),e(Ee,tbt),e(Ee,k8),e(k8,FSe),e(FSe,abt),e(k8,nbt),e(k8,sie),e(sie,sbt),e(k8,lbt),e(Ee,ibt),e(Ee,S8),e(S8,TSe),e(TSe,dbt),e(S8,mbt),e(S8,lie),e(lie,cbt),e(S8,fbt),e(Ee,gbt),e(Ee,R8),e(R8,MSe),e(MSe,hbt),e(R8,ubt),e(R8,iie),e(iie,pbt),e(R8,_bt),e(Ee,bbt),e(Ee,P8),e(P8,ESe),e(ESe,vbt),e(P8,Fbt),e(P8,die),e(die,Tbt),e(P8,Mbt),e(Ee,Ebt),e(Ee,B8),e(B8,CSe),e(CSe,Cbt),e(B8,wbt),e(B8,mie),e(mie,Abt),e(B8,Lbt),e(Ee,ybt),e(Ee,I8),e(I8,wSe),e(wSe,xbt),e(I8,$bt),e(I8,cie),e(cie,kbt),e(I8,Sbt),e(Ee,Rbt),e(Ee,N8),e(N8,ASe),e(ASe,Pbt),e(N8,Bbt),e(N8,fie),e(fie,Ibt),e(N8,Nbt),e(Ee,qbt),e(Ee,q8),e(q8,LSe),e(LSe,jbt),e(q8,Dbt),e(q8,gie),e(gie,Gbt),e(q8,Obt),e(at,Vbt),M(j8,at,null),b(c,lno,_),b(c,gf,_),e(gf,D8),e(D8,ySe),M(KP,ySe,null),e(gf,Xbt),e(gf,xSe),e(xSe,zbt),b(c,ino,_),b(c,xr,_),M(eB,xr,null),e(xr,Qbt),e(xr,hf),e(hf,Wbt),e(hf,hie),e(hie,Ubt),e(hf,Hbt),e(hf,uie),e(uie,Jbt),e(hf,Ybt),e(xr,Zbt),e(xr,oB),e(oB,Kbt),e(oB,$Se),e($Se,evt),e(oB,ovt),e(xr,rvt),e(xr,ua),M(rB,ua,null),e(ua,tvt),e(ua,kSe),e(kSe,avt),e(ua,nvt),e(ua,uf),e(uf,svt),e(uf,SSe),e(SSe,lvt),e(uf,ivt),e(uf,pie),e(pie,dvt),e(uf,mvt),e(ua,cvt),M(G8,ua,null),e(xr,fvt),e(xr,nt),M(tB,nt,null),e(nt,gvt),e(nt,RSe),e(RSe,hvt),e(nt,uvt),e(nt,es),e(es,pvt),e(es,PSe),e(PSe,_vt),e(es,bvt),e(es,BSe),e(BSe,vvt),e(es,Fvt),e(es,ISe),e(ISe,Tvt),e(es,Mvt),e(nt,Evt),e(nt,ke),e(ke,O8),e(O8,NSe),e(NSe,Cvt),e(O8,wvt),e(O8,_ie),e(_ie,Avt),e(O8,Lvt),e(ke,yvt),e(ke,V8),e(V8,qSe),e(qSe,xvt),e(V8,$vt),e(V8,bie),e(bie,kvt),e(V8,Svt),e(ke,Rvt),e(ke,X8),e(X8,jSe),e(jSe,Pvt),e(X8,Bvt),e(X8,vie),e(vie,Ivt),e(X8,Nvt),e(ke,qvt),e(ke,z8),e(z8,DSe),e(DSe,jvt),e(z8,Dvt),e(z8,Fie),e(Fie,Gvt),e(z8,Ovt),e(ke,Vvt),e(ke,Q8),e(Q8,GSe),e(GSe,Xvt),e(Q8,zvt),e(Q8,Tie),e(Tie,Qvt),e(Q8,Wvt),e(ke,Uvt),e(ke,W8),e(W8,OSe),e(OSe,Hvt),e(W8,Jvt),e(W8,Mie),e(Mie,Yvt),e(W8,Zvt),e(ke,Kvt),e(ke,U8),e(U8,VSe),e(VSe,eFt),e(U8,oFt),e(U8,Eie),e(Eie,rFt),e(U8,tFt),e(ke,aFt),e(ke,H8),e(H8,XSe),e(XSe,nFt),e(H8,sFt),e(H8,Cie),e(Cie,lFt),e(H8,iFt),e(ke,dFt),e(ke,J8),e(J8,zSe),e(zSe,mFt),e(J8,cFt),e(J8,wie),e(wie,fFt),e(J8,gFt),e(ke,hFt),e(ke,Y8),e(Y8,QSe),e(QSe,uFt),e(Y8,pFt),e(Y8,Aie),e(Aie,_Ft),e(Y8,bFt),e(nt,vFt),M(Z8,nt,null),b(c,dno,_),b(c,pf,_),e(pf,K8),e(K8,WSe),M(aB,WSe,null),e(pf,FFt),e(pf,USe),e(USe,TFt),b(c,mno,_),b(c,$r,_),M(nB,$r,null),e($r,MFt),e($r,_f),e(_f,EFt),e(_f,Lie),e(Lie,CFt),e(_f,wFt),e(_f,yie),e(yie,AFt),e(_f,LFt),e($r,yFt),e($r,sB),e(sB,xFt),e(sB,HSe),e(HSe,$Ft),e(sB,kFt),e($r,SFt),e($r,pa),M(lB,pa,null),e(pa,RFt),e(pa,JSe),e(JSe,PFt),e(pa,BFt),e(pa,bf),e(bf,IFt),e(bf,YSe),e(YSe,NFt),e(bf,qFt),e(bf,xie),e(xie,jFt),e(bf,DFt),e(pa,GFt),M(eL,pa,null),e($r,OFt),e($r,st),M(iB,st,null),e(st,VFt),e(st,ZSe),e(ZSe,XFt),e(st,zFt),e(st,os),e(os,QFt),e(os,KSe),e(KSe,WFt),e(os,UFt),e(os,eRe),e(eRe,HFt),e(os,JFt),e(os,oRe),e(oRe,YFt),e(os,ZFt),e(st,KFt),e(st,Se),e(Se,oL),e(oL,rRe),e(rRe,eTt),e(oL,oTt),e(oL,$ie),e($ie,rTt),e(oL,tTt),e(Se,aTt),e(Se,rL),e(rL,tRe),e(tRe,nTt),e(rL,sTt),e(rL,kie),e(kie,lTt),e(rL,iTt),e(Se,dTt),e(Se,tL),e(tL,aRe),e(aRe,mTt),e(tL,cTt),e(tL,Sie),e(Sie,fTt),e(tL,gTt),e(Se,hTt),e(Se,aL),e(aL,nRe),e(nRe,uTt),e(aL,pTt),e(aL,Rie),e(Rie,_Tt),e(aL,bTt),e(Se,vTt),e(Se,nL),e(nL,sRe),e(sRe,FTt),e(nL,TTt),e(nL,Pie),e(Pie,MTt),e(nL,ETt),e(Se,CTt),e(Se,sL),e(sL,lRe),e(lRe,wTt),e(sL,ATt),e(sL,Bie),e(Bie,LTt),e(sL,yTt),e(Se,xTt),e(Se,lL),e(lL,iRe),e(iRe,$Tt),e(lL,kTt),e(lL,Iie),e(Iie,STt),e(lL,RTt),e(Se,PTt),e(Se,iL),e(iL,dRe),e(dRe,BTt),e(iL,ITt),e(iL,Nie),e(Nie,NTt),e(iL,qTt),e(Se,jTt),e(Se,dL),e(dL,mRe),e(mRe,DTt),e(dL,GTt),e(dL,qie),e(qie,OTt),e(dL,VTt),e(Se,XTt),e(Se,mL),e(mL,cRe),e(cRe,zTt),e(mL,QTt),e(mL,jie),e(jie,WTt),e(mL,UTt),e(st,HTt),M(cL,st,null),b(c,cno,_),b(c,vf,_),e(vf,fL),e(fL,fRe),M(dB,fRe,null),e(vf,JTt),e(vf,gRe),e(gRe,YTt),b(c,fno,_),b(c,kr,_),M(mB,kr,null),e(kr,ZTt),e(kr,Ff),e(Ff,KTt),e(Ff,Die),e(Die,eMt),e(Ff,oMt),e(Ff,Gie),e(Gie,rMt),e(Ff,tMt),e(kr,aMt),e(kr,cB),e(cB,nMt),e(cB,hRe),e(hRe,sMt),e(cB,lMt),e(kr,iMt),e(kr,_a),M(fB,_a,null),e(_a,dMt),e(_a,uRe),e(uRe,mMt),e(_a,cMt),e(_a,Tf),e(Tf,fMt),e(Tf,pRe),e(pRe,gMt),e(Tf,hMt),e(Tf,Oie),e(Oie,uMt),e(Tf,pMt),e(_a,_Mt),M(gL,_a,null),e(kr,bMt),e(kr,lt),M(gB,lt,null),e(lt,vMt),e(lt,_Re),e(_Re,FMt),e(lt,TMt),e(lt,rs),e(rs,MMt),e(rs,bRe),e(bRe,EMt),e(rs,CMt),e(rs,vRe),e(vRe,wMt),e(rs,AMt),e(rs,FRe),e(FRe,LMt),e(rs,yMt),e(lt,xMt),e(lt,Re),e(Re,hL),e(hL,TRe),e(TRe,$Mt),e(hL,kMt),e(hL,Vie),e(Vie,SMt),e(hL,RMt),e(Re,PMt),e(Re,uL),e(uL,MRe),e(MRe,BMt),e(uL,IMt),e(uL,Xie),e(Xie,NMt),e(uL,qMt),e(Re,jMt),e(Re,pL),e(pL,ERe),e(ERe,DMt),e(pL,GMt),e(pL,zie),e(zie,OMt),e(pL,VMt),e(Re,XMt),e(Re,_L),e(_L,CRe),e(CRe,zMt),e(_L,QMt),e(_L,Qie),e(Qie,WMt),e(_L,UMt),e(Re,HMt),e(Re,bL),e(bL,wRe),e(wRe,JMt),e(bL,YMt),e(bL,Wie),e(Wie,ZMt),e(bL,KMt),e(Re,eEt),e(Re,vL),e(vL,ARe),e(ARe,oEt),e(vL,rEt),e(vL,Uie),e(Uie,tEt),e(vL,aEt),e(Re,nEt),e(Re,FL),e(FL,LRe),e(LRe,sEt),e(FL,lEt),e(FL,Hie),e(Hie,iEt),e(FL,dEt),e(Re,mEt),e(Re,TL),e(TL,yRe),e(yRe,cEt),e(TL,fEt),e(TL,Jie),e(Jie,gEt),e(TL,hEt),e(Re,uEt),e(Re,ML),e(ML,xRe),e(xRe,pEt),e(ML,_Et),e(ML,Yie),e(Yie,bEt),e(ML,vEt),e(Re,FEt),e(Re,EL),e(EL,$Re),e($Re,TEt),e(EL,MEt),e(EL,Zie),e(Zie,EEt),e(EL,CEt),e(lt,wEt),M(CL,lt,null),b(c,gno,_),b(c,Mf,_),e(Mf,wL),e(wL,kRe),M(hB,kRe,null),e(Mf,AEt),e(Mf,SRe),e(SRe,LEt),b(c,hno,_),b(c,Sr,_),M(uB,Sr,null),e(Sr,yEt),e(Sr,Ef),e(Ef,xEt),e(Ef,Kie),e(Kie,$Et),e(Ef,kEt),e(Ef,ede),e(ede,SEt),e(Ef,REt),e(Sr,PEt),e(Sr,pB),e(pB,BEt),e(pB,RRe),e(RRe,IEt),e(pB,NEt),e(Sr,qEt),e(Sr,ba),M(_B,ba,null),e(ba,jEt),e(ba,PRe),e(PRe,DEt),e(ba,GEt),e(ba,Cf),e(Cf,OEt),e(Cf,BRe),e(BRe,VEt),e(Cf,XEt),e(Cf,ode),e(ode,zEt),e(Cf,QEt),e(ba,WEt),M(AL,ba,null),e(Sr,UEt),e(Sr,it),M(bB,it,null),e(it,HEt),e(it,IRe),e(IRe,JEt),e(it,YEt),e(it,ts),e(ts,ZEt),e(ts,NRe),e(NRe,KEt),e(ts,e4t),e(ts,qRe),e(qRe,o4t),e(ts,r4t),e(ts,jRe),e(jRe,t4t),e(ts,a4t),e(it,n4t),e(it,Pe),e(Pe,LL),e(LL,DRe),e(DRe,s4t),e(LL,l4t),e(LL,rde),e(rde,i4t),e(LL,d4t),e(Pe,m4t),e(Pe,yL),e(yL,GRe),e(GRe,c4t),e(yL,f4t),e(yL,tde),e(tde,g4t),e(yL,h4t),e(Pe,u4t),e(Pe,xL),e(xL,ORe),e(ORe,p4t),e(xL,_4t),e(xL,ade),e(ade,b4t),e(xL,v4t),e(Pe,F4t),e(Pe,$L),e($L,VRe),e(VRe,T4t),e($L,M4t),e($L,nde),e(nde,E4t),e($L,C4t),e(Pe,w4t),e(Pe,kL),e(kL,XRe),e(XRe,A4t),e(kL,L4t),e(kL,sde),e(sde,y4t),e(kL,x4t),e(Pe,$4t),e(Pe,SL),e(SL,zRe),e(zRe,k4t),e(SL,S4t),e(SL,lde),e(lde,R4t),e(SL,P4t),e(Pe,B4t),e(Pe,RL),e(RL,QRe),e(QRe,I4t),e(RL,N4t),e(RL,ide),e(ide,q4t),e(RL,j4t),e(Pe,D4t),e(Pe,PL),e(PL,WRe),e(WRe,G4t),e(PL,O4t),e(PL,dde),e(dde,V4t),e(PL,X4t),e(Pe,z4t),e(Pe,BL),e(BL,URe),e(URe,Q4t),e(BL,W4t),e(BL,mde),e(mde,U4t),e(BL,H4t),e(Pe,J4t),e(Pe,IL),e(IL,HRe),e(HRe,Y4t),e(IL,Z4t),e(IL,cde),e(cde,K4t),e(IL,eCt),e(it,oCt),M(NL,it,null),b(c,uno,_),b(c,wf,_),e(wf,qL),e(qL,JRe),M(vB,JRe,null),e(wf,rCt),e(wf,YRe),e(YRe,tCt),b(c,pno,_),b(c,Rr,_),M(FB,Rr,null),e(Rr,aCt),e(Rr,Af),e(Af,nCt),e(Af,fde),e(fde,sCt),e(Af,lCt),e(Af,gde),e(gde,iCt),e(Af,dCt),e(Rr,mCt),e(Rr,TB),e(TB,cCt),e(TB,ZRe),e(ZRe,fCt),e(TB,gCt),e(Rr,hCt),e(Rr,va),M(MB,va,null),e(va,uCt),e(va,KRe),e(KRe,pCt),e(va,_Ct),e(va,Lf),e(Lf,bCt),e(Lf,ePe),e(ePe,vCt),e(Lf,FCt),e(Lf,hde),e(hde,TCt),e(Lf,MCt),e(va,ECt),M(jL,va,null),e(Rr,CCt),e(Rr,dt),M(EB,dt,null),e(dt,wCt),e(dt,oPe),e(oPe,ACt),e(dt,LCt),e(dt,as),e(as,yCt),e(as,rPe),e(rPe,xCt),e(as,$Ct),e(as,tPe),e(tPe,kCt),e(as,SCt),e(as,aPe),e(aPe,RCt),e(as,PCt),e(dt,BCt),e(dt,ze),e(ze,DL),e(DL,nPe),e(nPe,ICt),e(DL,NCt),e(DL,ude),e(ude,qCt),e(DL,jCt),e(ze,DCt),e(ze,GL),e(GL,sPe),e(sPe,GCt),e(GL,OCt),e(GL,pde),e(pde,VCt),e(GL,XCt),e(ze,zCt),e(ze,OL),e(OL,lPe),e(lPe,QCt),e(OL,WCt),e(OL,_de),e(_de,UCt),e(OL,HCt),e(ze,JCt),e(ze,VL),e(VL,iPe),e(iPe,YCt),e(VL,ZCt),e(VL,bde),e(bde,KCt),e(VL,e3t),e(ze,o3t),e(ze,XL),e(XL,dPe),e(dPe,r3t),e(XL,t3t),e(XL,vde),e(vde,a3t),e(XL,n3t),e(ze,s3t),e(ze,zL),e(zL,mPe),e(mPe,l3t),e(zL,i3t),e(zL,Fde),e(Fde,d3t),e(zL,m3t),e(ze,c3t),e(ze,QL),e(QL,cPe),e(cPe,f3t),e(QL,g3t),e(QL,Tde),e(Tde,h3t),e(QL,u3t),e(ze,p3t),e(ze,WL),e(WL,fPe),e(fPe,_3t),e(WL,b3t),e(WL,Mde),e(Mde,v3t),e(WL,F3t),e(dt,T3t),M(UL,dt,null),b(c,_no,_),b(c,yf,_),e(yf,HL),e(HL,gPe),M(CB,gPe,null),e(yf,M3t),e(yf,hPe),e(hPe,E3t),b(c,bno,_),b(c,Pr,_),M(wB,Pr,null),e(Pr,C3t),e(Pr,xf),e(xf,w3t),e(xf,Ede),e(Ede,A3t),e(xf,L3t),e(xf,Cde),e(Cde,y3t),e(xf,x3t),e(Pr,$3t),e(Pr,AB),e(AB,k3t),e(AB,uPe),e(uPe,S3t),e(AB,R3t),e(Pr,P3t),e(Pr,Fa),M(LB,Fa,null),e(Fa,B3t),e(Fa,pPe),e(pPe,I3t),e(Fa,N3t),e(Fa,$f),e($f,q3t),e($f,_Pe),e(_Pe,j3t),e($f,D3t),e($f,wde),e(wde,G3t),e($f,O3t),e(Fa,V3t),M(JL,Fa,null),e(Pr,X3t),e(Pr,mt),M(yB,mt,null),e(mt,z3t),e(mt,bPe),e(bPe,Q3t),e(mt,W3t),e(mt,ns),e(ns,U3t),e(ns,vPe),e(vPe,H3t),e(ns,J3t),e(ns,FPe),e(FPe,Y3t),e(ns,Z3t),e(ns,TPe),e(TPe,K3t),e(ns,e5t),e(mt,o5t),e(mt,Qe),e(Qe,YL),e(YL,MPe),e(MPe,r5t),e(YL,t5t),e(YL,Ade),e(Ade,a5t),e(YL,n5t),e(Qe,s5t),e(Qe,ZL),e(ZL,EPe),e(EPe,l5t),e(ZL,i5t),e(ZL,Lde),e(Lde,d5t),e(ZL,m5t),e(Qe,c5t),e(Qe,KL),e(KL,CPe),e(CPe,f5t),e(KL,g5t),e(KL,yde),e(yde,h5t),e(KL,u5t),e(Qe,p5t),e(Qe,ey),e(ey,wPe),e(wPe,_5t),e(ey,b5t),e(ey,xde),e(xde,v5t),e(ey,F5t),e(Qe,T5t),e(Qe,oy),e(oy,APe),e(APe,M5t),e(oy,E5t),e(oy,$de),e($de,C5t),e(oy,w5t),e(Qe,A5t),e(Qe,ry),e(ry,LPe),e(LPe,L5t),e(ry,y5t),e(ry,kde),e(kde,x5t),e(ry,$5t),e(Qe,k5t),e(Qe,ty),e(ty,yPe),e(yPe,S5t),e(ty,R5t),e(ty,Sde),e(Sde,P5t),e(ty,B5t),e(Qe,I5t),e(Qe,ay),e(ay,xPe),e(xPe,N5t),e(ay,q5t),e(ay,Rde),e(Rde,j5t),e(ay,D5t),e(mt,G5t),M(ny,mt,null),b(c,vno,_),b(c,kf,_),e(kf,sy),e(sy,$Pe),M(xB,$Pe,null),e(kf,O5t),e(kf,kPe),e(kPe,V5t),b(c,Fno,_),b(c,Br,_),M($B,Br,null),e(Br,X5t),e(Br,Sf),e(Sf,z5t),e(Sf,Pde),e(Pde,Q5t),e(Sf,W5t),e(Sf,Bde),e(Bde,U5t),e(Sf,H5t),e(Br,J5t),e(Br,kB),e(kB,Y5t),e(kB,SPe),e(SPe,Z5t),e(kB,K5t),e(Br,e0t),e(Br,Ta),M(SB,Ta,null),e(Ta,o0t),e(Ta,RPe),e(RPe,r0t),e(Ta,t0t),e(Ta,Rf),e(Rf,a0t),e(Rf,PPe),e(PPe,n0t),e(Rf,s0t),e(Rf,Ide),e(Ide,l0t),e(Rf,i0t),e(Ta,d0t),M(ly,Ta,null),e(Br,m0t),e(Br,ct),M(RB,ct,null),e(ct,c0t),e(ct,BPe),e(BPe,f0t),e(ct,g0t),e(ct,ss),e(ss,h0t),e(ss,IPe),e(IPe,u0t),e(ss,p0t),e(ss,NPe),e(NPe,_0t),e(ss,b0t),e(ss,qPe),e(qPe,v0t),e(ss,F0t),e(ct,T0t),e(ct,jPe),e(jPe,iy),e(iy,DPe),e(DPe,M0t),e(iy,E0t),e(iy,Nde),e(Nde,C0t),e(iy,w0t),e(ct,A0t),M(dy,ct,null),b(c,Tno,_),b(c,Pf,_),e(Pf,my),e(my,GPe),M(PB,GPe,null),e(Pf,L0t),e(Pf,OPe),e(OPe,y0t),b(c,Mno,_),b(c,Ir,_),M(BB,Ir,null),e(Ir,x0t),e(Ir,Bf),e(Bf,$0t),e(Bf,qde),e(qde,k0t),e(Bf,S0t),e(Bf,jde),e(jde,R0t),e(Bf,P0t),e(Ir,B0t),e(Ir,IB),e(IB,I0t),e(IB,VPe),e(VPe,N0t),e(IB,q0t),e(Ir,j0t),e(Ir,Ma),M(NB,Ma,null),e(Ma,D0t),e(Ma,XPe),e(XPe,G0t),e(Ma,O0t),e(Ma,If),e(If,V0t),e(If,zPe),e(zPe,X0t),e(If,z0t),e(If,Dde),e(Dde,Q0t),e(If,W0t),e(Ma,U0t),M(cy,Ma,null),e(Ir,H0t),e(Ir,ft),M(qB,ft,null),e(ft,J0t),e(ft,QPe),e(QPe,Y0t),e(ft,Z0t),e(ft,ls),e(ls,K0t),e(ls,WPe),e(WPe,ewt),e(ls,owt),e(ls,UPe),e(UPe,rwt),e(ls,twt),e(ls,HPe),e(HPe,awt),e(ls,nwt),e(ft,swt),e(ft,jB),e(jB,fy),e(fy,JPe),e(JPe,lwt),e(fy,iwt),e(fy,Gde),e(Gde,dwt),e(fy,mwt),e(jB,cwt),e(jB,gy),e(gy,YPe),e(YPe,fwt),e(gy,gwt),e(gy,Ode),e(Ode,hwt),e(gy,uwt),e(ft,pwt),M(hy,ft,null),b(c,Eno,_),b(c,Nf,_),e(Nf,uy),e(uy,ZPe),M(DB,ZPe,null),e(Nf,_wt),e(Nf,KPe),e(KPe,bwt),b(c,Cno,_),b(c,Nr,_),M(GB,Nr,null),e(Nr,vwt),e(Nr,qf),e(qf,Fwt),e(qf,Vde),e(Vde,Twt),e(qf,Mwt),e(qf,Xde),e(Xde,Ewt),e(qf,Cwt),e(Nr,wwt),e(Nr,OB),e(OB,Awt),e(OB,eBe),e(eBe,Lwt),e(OB,ywt),e(Nr,xwt),e(Nr,Ea),M(VB,Ea,null),e(Ea,$wt),e(Ea,oBe),e(oBe,kwt),e(Ea,Swt),e(Ea,jf),e(jf,Rwt),e(jf,rBe),e(rBe,Pwt),e(jf,Bwt),e(jf,zde),e(zde,Iwt),e(jf,Nwt),e(Ea,qwt),M(py,Ea,null),e(Nr,jwt),e(Nr,gt),M(XB,gt,null),e(gt,Dwt),e(gt,tBe),e(tBe,Gwt),e(gt,Owt),e(gt,is),e(is,Vwt),e(is,aBe),e(aBe,Xwt),e(is,zwt),e(is,nBe),e(nBe,Qwt),e(is,Wwt),e(is,sBe),e(sBe,Uwt),e(is,Hwt),e(gt,Jwt),e(gt,lBe),e(lBe,_y),e(_y,iBe),e(iBe,Ywt),e(_y,Zwt),e(_y,Qde),e(Qde,Kwt),e(_y,eAt),e(gt,oAt),M(by,gt,null),wno=!0},p(c,[_]){const zB={};_&2&&(zB.$$scope={dirty:_,ctx:c}),Uf.$set(zB);const dBe={};_&2&&(dBe.$$scope={dirty:_,ctx:c}),Mu.$set(dBe);const mBe={};_&2&&(mBe.$$scope={dirty:_,ctx:c}),lp.$set(mBe);const cBe={};_&2&&(cBe.$$scope={dirty:_,ctx:c}),Kp.$set(cBe);const QB={};_&2&&(QB.$$scope={dirty:_,ctx:c}),e_.$set(QB);const fBe={};_&2&&(fBe.$$scope={dirty:_,ctx:c}),A_.$set(fBe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:c}),L_.$set(ds);const gBe={};_&2&&(gBe.$$scope={dirty:_,ctx:c}),$_.$set(gBe);const hBe={};_&2&&(hBe.$$scope={dirty:_,ctx:c}),Y2.$set(hBe);const uBe={};_&2&&(uBe.$$scope={dirty:_,ctx:c}),K2.$set(uBe);const WB={};_&2&&(WB.$$scope={dirty:_,ctx:c}),Hb.$set(WB);const pBe={};_&2&&(pBe.$$scope={dirty:_,ctx:c}),Yb.$set(pBe);const UB={};_&2&&(UB.$$scope={dirty:_,ctx:c}),Gv.$set(UB);const _Be={};_&2&&(_Be.$$scope={dirty:_,ctx:c}),Vv.$set(_Be);const HB={};_&2&&(HB.$$scope={dirty:_,ctx:c}),Wv.$set(HB);const bBe={};_&2&&(bBe.$$scope={dirty:_,ctx:c}),Hv.$set(bBe);const vBe={};_&2&&(vBe.$$scope={dirty:_,ctx:c}),IF.$set(vBe);const FBe={};_&2&&(FBe.$$scope={dirty:_,ctx:c}),qF.$set(FBe);const Df={};_&2&&(Df.$$scope={dirty:_,ctx:c}),sT.$set(Df);const TBe={};_&2&&(TBe.$$scope={dirty:_,ctx:c}),iT.$set(TBe);const MBe={};_&2&&(MBe.$$scope={dirty:_,ctx:c}),fM.$set(MBe);const EBe={};_&2&&(EBe.$$scope={dirty:_,ctx:c}),hM.$set(EBe);const JB={};_&2&&(JB.$$scope={dirty:_,ctx:c}),UM.$set(JB);const CBe={};_&2&&(CBe.$$scope={dirty:_,ctx:c}),JM.$set(CBe);const wBe={};_&2&&(wBe.$$scope={dirty:_,ctx:c}),nE.$set(wBe);const ABe={};_&2&&(ABe.$$scope={dirty:_,ctx:c}),lE.$set(ABe);const bt={};_&2&&(bt.$$scope={dirty:_,ctx:c}),JE.$set(bt);const YB={};_&2&&(YB.$$scope={dirty:_,ctx:c}),ZE.$set(YB);const LBe={};_&2&&(LBe.$$scope={dirty:_,ctx:c}),U4.$set(LBe);const ZB={};_&2&&(ZB.$$scope={dirty:_,ctx:c}),J4.$set(ZB);const yBe={};_&2&&(yBe.$$scope={dirty:_,ctx:c}),K4.$set(yBe);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:c}),oC.$set(vt);const xBe={};_&2&&(xBe.$$scope={dirty:_,ctx:c}),sC.$set(xBe);const Gf={};_&2&&(Gf.$$scope={dirty:_,ctx:c}),iC.$set(Gf);const $Be={};_&2&&($Be.$$scope={dirty:_,ctx:c}),wC.$set($Be);const kBe={};_&2&&(kBe.$$scope={dirty:_,ctx:c}),LC.$set(kBe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),$C.$set(L);const vy={};_&2&&(vy.$$scope={dirty:_,ctx:c}),SC.$set(vy);const SBe={};_&2&&(SBe.$$scope={dirty:_,ctx:c}),BC.$set(SBe);const RBe={};_&2&&(RBe.$$scope={dirty:_,ctx:c}),NC.$set(RBe);const Fy={};_&2&&(Fy.$$scope={dirty:_,ctx:c}),DC.$set(Fy);const PBe={};_&2&&(PBe.$$scope={dirty:_,ctx:c}),OC.$set(PBe);const BBe={};_&2&&(BBe.$$scope={dirty:_,ctx:c}),KC.$set(BBe);const Ty={};_&2&&(Ty.$$scope={dirty:_,ctx:c}),o3.$set(Ty);const IBe={};_&2&&(IBe.$$scope={dirty:_,ctx:c}),i3.$set(IBe);const NBe={};_&2&&(NBe.$$scope={dirty:_,ctx:c}),m3.$set(NBe);const My={};_&2&&(My.$$scope={dirty:_,ctx:c}),M3.$set(My);const qBe={};_&2&&(qBe.$$scope={dirty:_,ctx:c}),C3.$set(qBe);const jBe={};_&2&&(jBe.$$scope={dirty:_,ctx:c}),x3.$set(jBe);const Ey={};_&2&&(Ey.$$scope={dirty:_,ctx:c}),k3.$set(Ey);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:c}),q3.$set(DBe);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:c}),D3.$set(GBe);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:c}),Q3.$set(Cy);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:c}),U3.$set(OBe);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:c}),e5.$set(VBe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:c}),r5.$set(wy);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:c}),n5.$set(XBe);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:c}),l5.$set(zBe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:c}),h5.$set(Ay);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:c}),p5.$set(QBe);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:c}),v5.$set(WBe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:c}),T5.$set(Ly);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:c}),C5.$set(UBe);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:c}),A5.$set(HBe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:c}),$0.$set(yy);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:c}),S0.$set(JBe);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:c}),rw.$set(YBe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),aw.$set(xy);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:c}),vw.$set(ZBe);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:c}),Tw.$set(KBe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),kw.$set($y);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:c}),Rw.$set(eIe);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:c}),Nw.$set(oIe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),jw.$set(ky);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:c}),lA.$set(rIe);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:c}),dA.$set(tIe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),FA.$set(Sy);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:c}),MA.$set(aIe);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:c}),YA.$set(nIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),KA.$set(Ry);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:c}),_6.$set(sIe);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:c}),v6.$set(lIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),M6.$set(Py);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:c}),C6.$set(iIe);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:c}),A6.$set(dIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),y6.$set(By);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:c}),$6.$set(mIe);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:c}),S6.$set(cIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),o7.$set(Iy);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:c}),t7.$set(fIe);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:c}),w7.$set(gIe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),L7.$set(Ny);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:c}),x7.$set(hIe);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:c}),k7.$set(uIe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),P7.$set(qy);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:c}),I7.$set(pIe);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:c}),m8.$set(_Ie);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),f8.$set(jy);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:c}),E8.$set(bIe);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:c}),w8.$set(vIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),j8.$set(Dy);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:c}),G8.$set(FIe);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:c}),Z8.$set(TIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),eL.$set(Gy);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:c}),cL.$set(MIe);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:c}),gL.$set(EIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),CL.$set(Oy);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:c}),AL.$set(CIe);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:c}),NL.$set(wIe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),jL.$set(Vy);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:c}),UL.$set(AIe);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:c}),JL.$set(LIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),ny.$set(Xy);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:c}),ly.$set(yIe);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:c}),dy.$set(xIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),cy.$set(zy);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:c}),hy.$set($Ie);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:c}),py.$set(kIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),by.$set(Qy)},i(c){wno||(E(d.$$.fragment,c),E(en.$$.fragment,c),E(n$.$$.fragment,c),E(s$.$$.fragment,c),E(Uf.$$.fragment,c),E(l$.$$.fragment,c),E(i$.$$.fragment,c),E(c$.$$.fragment,c),E(Mu.$$.fragment,c),E(f$.$$.fragment,c),E(g$.$$.fragment,c),E(h$.$$.fragment,c),E(_$.$$.fragment,c),E(lp.$$.fragment,c),E(b$.$$.fragment,c),E(v$.$$.fragment,c),E(F$.$$.fragment,c),E(E$.$$.fragment,c),E(Kp.$$.fragment,c),E(e_.$$.fragment,c),E(C$.$$.fragment,c),E(w$.$$.fragment,c),E(A$.$$.fragment,c),E(x$.$$.fragment,c),E(A_.$$.fragment,c),E(L_.$$.fragment,c),E($$.$$.fragment,c),E(k$.$$.fragment,c),E(S$.$$.fragment,c),E(P$.$$.fragment,c),E($_.$$.fragment,c),E(B$.$$.fragment,c),E(Y2.$$.fragment,c),E(I$.$$.fragment,c),E(N$.$$.fragment,c),E(j$.$$.fragment,c),E(K2.$$.fragment,c),E(D$.$$.fragment,c),E(Hb.$$.fragment,c),E(G$.$$.fragment,c),E(O$.$$.fragment,c),E(X$.$$.fragment,c),E(Yb.$$.fragment,c),E(z$.$$.fragment,c),E(Gv.$$.fragment,c),E(Q$.$$.fragment,c),E(W$.$$.fragment,c),E(H$.$$.fragment,c),E(Vv.$$.fragment,c),E(J$.$$.fragment,c),E(Wv.$$.fragment,c),E(Z$.$$.fragment,c),E(K$.$$.fragment,c),E(ok.$$.fragment,c),E(Hv.$$.fragment,c),E(rk.$$.fragment,c),E(IF.$$.fragment,c),E(tk.$$.fragment,c),E(ak.$$.fragment,c),E(sk.$$.fragment,c),E(qF.$$.fragment,c),E(lk.$$.fragment,c),E(sT.$$.fragment,c),E(ik.$$.fragment,c),E(dk.$$.fragment,c),E(ck.$$.fragment,c),E(iT.$$.fragment,c),E(fk.$$.fragment,c),E(fM.$$.fragment,c),E(gk.$$.fragment,c),E(hk.$$.fragment,c),E(pk.$$.fragment,c),E(hM.$$.fragment,c),E(_k.$$.fragment,c),E(UM.$$.fragment,c),E(bk.$$.fragment,c),E(vk.$$.fragment,c),E(Tk.$$.fragment,c),E(JM.$$.fragment,c),E(Mk.$$.fragment,c),E(nE.$$.fragment,c),E(Ek.$$.fragment,c),E(Ck.$$.fragment,c),E(Ak.$$.fragment,c),E(lE.$$.fragment,c),E(Lk.$$.fragment,c),E(JE.$$.fragment,c),E(yk.$$.fragment,c),E(xk.$$.fragment,c),E(kk.$$.fragment,c),E(ZE.$$.fragment,c),E(Sk.$$.fragment,c),E(U4.$$.fragment,c),E(Rk.$$.fragment,c),E(Pk.$$.fragment,c),E(Ik.$$.fragment,c),E(J4.$$.fragment,c),E(Nk.$$.fragment,c),E(K4.$$.fragment,c),E(qk.$$.fragment,c),E(jk.$$.fragment,c),E(Gk.$$.fragment,c),E(oC.$$.fragment,c),E(Ok.$$.fragment,c),E(sC.$$.fragment,c),E(Vk.$$.fragment,c),E(Xk.$$.fragment,c),E(Qk.$$.fragment,c),E(iC.$$.fragment,c),E(Wk.$$.fragment,c),E(wC.$$.fragment,c),E(Uk.$$.fragment,c),E(Hk.$$.fragment,c),E(Yk.$$.fragment,c),E(LC.$$.fragment,c),E(Zk.$$.fragment,c),E($C.$$.fragment,c),E(Kk.$$.fragment,c),E(eS.$$.fragment,c),E(rS.$$.fragment,c),E(SC.$$.fragment,c),E(tS.$$.fragment,c),E(BC.$$.fragment,c),E(aS.$$.fragment,c),E(nS.$$.fragment,c),E(lS.$$.fragment,c),E(NC.$$.fragment,c),E(iS.$$.fragment,c),E(DC.$$.fragment,c),E(dS.$$.fragment,c),E(mS.$$.fragment,c),E(fS.$$.fragment,c),E(OC.$$.fragment,c),E(gS.$$.fragment,c),E(KC.$$.fragment,c),E(hS.$$.fragment,c),E(uS.$$.fragment,c),E(_S.$$.fragment,c),E(o3.$$.fragment,c),E(bS.$$.fragment,c),E(i3.$$.fragment,c),E(vS.$$.fragment,c),E(FS.$$.fragment,c),E(MS.$$.fragment,c),E(m3.$$.fragment,c),E(ES.$$.fragment,c),E(M3.$$.fragment,c),E(CS.$$.fragment,c),E(wS.$$.fragment,c),E(LS.$$.fragment,c),E(C3.$$.fragment,c),E(yS.$$.fragment,c),E(x3.$$.fragment,c),E(xS.$$.fragment,c),E($S.$$.fragment,c),E(SS.$$.fragment,c),E(k3.$$.fragment,c),E(RS.$$.fragment,c),E(q3.$$.fragment,c),E(PS.$$.fragment,c),E(BS.$$.fragment,c),E(NS.$$.fragment,c),E(D3.$$.fragment,c),E(qS.$$.fragment,c),E(Q3.$$.fragment,c),E(jS.$$.fragment,c),E(DS.$$.fragment,c),E(OS.$$.fragment,c),E(U3.$$.fragment,c),E(VS.$$.fragment,c),E(e5.$$.fragment,c),E(XS.$$.fragment,c),E(zS.$$.fragment,c),E(WS.$$.fragment,c),E(r5.$$.fragment,c),E(US.$$.fragment,c),E(n5.$$.fragment,c),E(HS.$$.fragment,c),E(JS.$$.fragment,c),E(ZS.$$.fragment,c),E(l5.$$.fragment,c),E(KS.$$.fragment,c),E(h5.$$.fragment,c),E(eR.$$.fragment,c),E(oR.$$.fragment,c),E(tR.$$.fragment,c),E(p5.$$.fragment,c),E(aR.$$.fragment,c),E(v5.$$.fragment,c),E(nR.$$.fragment,c),E(sR.$$.fragment,c),E(iR.$$.fragment,c),E(T5.$$.fragment,c),E(dR.$$.fragment,c),E(C5.$$.fragment,c),E(mR.$$.fragment,c),E(cR.$$.fragment,c),E(gR.$$.fragment,c),E(A5.$$.fragment,c),E(hR.$$.fragment,c),E($0.$$.fragment,c),E(uR.$$.fragment,c),E(pR.$$.fragment,c),E(bR.$$.fragment,c),E(S0.$$.fragment,c),E(vR.$$.fragment,c),E(rw.$$.fragment,c),E(FR.$$.fragment,c),E(TR.$$.fragment,c),E(ER.$$.fragment,c),E(aw.$$.fragment,c),E(CR.$$.fragment,c),E(vw.$$.fragment,c),E(wR.$$.fragment,c),E(AR.$$.fragment,c),E(yR.$$.fragment,c),E(Tw.$$.fragment,c),E(xR.$$.fragment,c),E(kw.$$.fragment,c),E($R.$$.fragment,c),E(kR.$$.fragment,c),E(RR.$$.fragment,c),E(Rw.$$.fragment,c),E(PR.$$.fragment,c),E(Nw.$$.fragment,c),E(BR.$$.fragment,c),E(IR.$$.fragment,c),E(qR.$$.fragment,c),E(jw.$$.fragment,c),E(jR.$$.fragment,c),E(lA.$$.fragment,c),E(DR.$$.fragment,c),E(GR.$$.fragment,c),E(VR.$$.fragment,c),E(dA.$$.fragment,c),E(XR.$$.fragment,c),E(FA.$$.fragment,c),E(zR.$$.fragment,c),E(QR.$$.fragment,c),E(UR.$$.fragment,c),E(MA.$$.fragment,c),E(HR.$$.fragment,c),E(YA.$$.fragment,c),E(JR.$$.fragment,c),E(YR.$$.fragment,c),E(KR.$$.fragment,c),E(KA.$$.fragment,c),E(eP.$$.fragment,c),E(_6.$$.fragment,c),E(oP.$$.fragment,c),E(rP.$$.fragment,c),E(aP.$$.fragment,c),E(v6.$$.fragment,c),E(nP.$$.fragment,c),E(M6.$$.fragment,c),E(lP.$$.fragment,c),E(iP.$$.fragment,c),E(mP.$$.fragment,c),E(C6.$$.fragment,c),E(cP.$$.fragment,c),E(A6.$$.fragment,c),E(fP.$$.fragment,c),E(gP.$$.fragment,c),E(uP.$$.fragment,c),E(y6.$$.fragment,c),E(pP.$$.fragment,c),E($6.$$.fragment,c),E(_P.$$.fragment,c),E(bP.$$.fragment,c),E(FP.$$.fragment,c),E(S6.$$.fragment,c),E(TP.$$.fragment,c),E(o7.$$.fragment,c),E(MP.$$.fragment,c),E(EP.$$.fragment,c),E(wP.$$.fragment,c),E(t7.$$.fragment,c),E(AP.$$.fragment,c),E(w7.$$.fragment,c),E(LP.$$.fragment,c),E(yP.$$.fragment,c),E($P.$$.fragment,c),E(L7.$$.fragment,c),E(kP.$$.fragment,c),E(x7.$$.fragment,c),E(SP.$$.fragment,c),E(RP.$$.fragment,c),E(BP.$$.fragment,c),E(k7.$$.fragment,c),E(IP.$$.fragment,c),E(P7.$$.fragment,c),E(qP.$$.fragment,c),E(jP.$$.fragment,c),E(GP.$$.fragment,c),E(I7.$$.fragment,c),E(OP.$$.fragment,c),E(m8.$$.fragment,c),E(VP.$$.fragment,c),E(XP.$$.fragment,c),E(QP.$$.fragment,c),E(f8.$$.fragment,c),E(WP.$$.fragment,c),E(E8.$$.fragment,c),E(UP.$$.fragment,c),E(HP.$$.fragment,c),E(YP.$$.fragment,c),E(w8.$$.fragment,c),E(ZP.$$.fragment,c),E(j8.$$.fragment,c),E(KP.$$.fragment,c),E(eB.$$.fragment,c),E(rB.$$.fragment,c),E(G8.$$.fragment,c),E(tB.$$.fragment,c),E(Z8.$$.fragment,c),E(aB.$$.fragment,c),E(nB.$$.fragment,c),E(lB.$$.fragment,c),E(eL.$$.fragment,c),E(iB.$$.fragment,c),E(cL.$$.fragment,c),E(dB.$$.fragment,c),E(mB.$$.fragment,c),E(fB.$$.fragment,c),E(gL.$$.fragment,c),E(gB.$$.fragment,c),E(CL.$$.fragment,c),E(hB.$$.fragment,c),E(uB.$$.fragment,c),E(_B.$$.fragment,c),E(AL.$$.fragment,c),E(bB.$$.fragment,c),E(NL.$$.fragment,c),E(vB.$$.fragment,c),E(FB.$$.fragment,c),E(MB.$$.fragment,c),E(jL.$$.fragment,c),E(EB.$$.fragment,c),E(UL.$$.fragment,c),E(CB.$$.fragment,c),E(wB.$$.fragment,c),E(LB.$$.fragment,c),E(JL.$$.fragment,c),E(yB.$$.fragment,c),E(ny.$$.fragment,c),E(xB.$$.fragment,c),E($B.$$.fragment,c),E(SB.$$.fragment,c),E(ly.$$.fragment,c),E(RB.$$.fragment,c),E(dy.$$.fragment,c),E(PB.$$.fragment,c),E(BB.$$.fragment,c),E(NB.$$.fragment,c),E(cy.$$.fragment,c),E(qB.$$.fragment,c),E(hy.$$.fragment,c),E(DB.$$.fragment,c),E(GB.$$.fragment,c),E(VB.$$.fragment,c),E(py.$$.fragment,c),E(XB.$$.fragment,c),E(by.$$.fragment,c),wno=!0)},o(c){C(d.$$.fragment,c),C(en.$$.fragment,c),C(n$.$$.fragment,c),C(s$.$$.fragment,c),C(Uf.$$.fragment,c),C(l$.$$.fragment,c),C(i$.$$.fragment,c),C(c$.$$.fragment,c),C(Mu.$$.fragment,c),C(f$.$$.fragment,c),C(g$.$$.fragment,c),C(h$.$$.fragment,c),C(_$.$$.fragment,c),C(lp.$$.fragment,c),C(b$.$$.fragment,c),C(v$.$$.fragment,c),C(F$.$$.fragment,c),C(E$.$$.fragment,c),C(Kp.$$.fragment,c),C(e_.$$.fragment,c),C(C$.$$.fragment,c),C(w$.$$.fragment,c),C(A$.$$.fragment,c),C(x$.$$.fragment,c),C(A_.$$.fragment,c),C(L_.$$.fragment,c),C($$.$$.fragment,c),C(k$.$$.fragment,c),C(S$.$$.fragment,c),C(P$.$$.fragment,c),C($_.$$.fragment,c),C(B$.$$.fragment,c),C(Y2.$$.fragment,c),C(I$.$$.fragment,c),C(N$.$$.fragment,c),C(j$.$$.fragment,c),C(K2.$$.fragment,c),C(D$.$$.fragment,c),C(Hb.$$.fragment,c),C(G$.$$.fragment,c),C(O$.$$.fragment,c),C(X$.$$.fragment,c),C(Yb.$$.fragment,c),C(z$.$$.fragment,c),C(Gv.$$.fragment,c),C(Q$.$$.fragment,c),C(W$.$$.fragment,c),C(H$.$$.fragment,c),C(Vv.$$.fragment,c),C(J$.$$.fragment,c),C(Wv.$$.fragment,c),C(Z$.$$.fragment,c),C(K$.$$.fragment,c),C(ok.$$.fragment,c),C(Hv.$$.fragment,c),C(rk.$$.fragment,c),C(IF.$$.fragment,c),C(tk.$$.fragment,c),C(ak.$$.fragment,c),C(sk.$$.fragment,c),C(qF.$$.fragment,c),C(lk.$$.fragment,c),C(sT.$$.fragment,c),C(ik.$$.fragment,c),C(dk.$$.fragment,c),C(ck.$$.fragment,c),C(iT.$$.fragment,c),C(fk.$$.fragment,c),C(fM.$$.fragment,c),C(gk.$$.fragment,c),C(hk.$$.fragment,c),C(pk.$$.fragment,c),C(hM.$$.fragment,c),C(_k.$$.fragment,c),C(UM.$$.fragment,c),C(bk.$$.fragment,c),C(vk.$$.fragment,c),C(Tk.$$.fragment,c),C(JM.$$.fragment,c),C(Mk.$$.fragment,c),C(nE.$$.fragment,c),C(Ek.$$.fragment,c),C(Ck.$$.fragment,c),C(Ak.$$.fragment,c),C(lE.$$.fragment,c),C(Lk.$$.fragment,c),C(JE.$$.fragment,c),C(yk.$$.fragment,c),C(xk.$$.fragment,c),C(kk.$$.fragment,c),C(ZE.$$.fragment,c),C(Sk.$$.fragment,c),C(U4.$$.fragment,c),C(Rk.$$.fragment,c),C(Pk.$$.fragment,c),C(Ik.$$.fragment,c),C(J4.$$.fragment,c),C(Nk.$$.fragment,c),C(K4.$$.fragment,c),C(qk.$$.fragment,c),C(jk.$$.fragment,c),C(Gk.$$.fragment,c),C(oC.$$.fragment,c),C(Ok.$$.fragment,c),C(sC.$$.fragment,c),C(Vk.$$.fragment,c),C(Xk.$$.fragment,c),C(Qk.$$.fragment,c),C(iC.$$.fragment,c),C(Wk.$$.fragment,c),C(wC.$$.fragment,c),C(Uk.$$.fragment,c),C(Hk.$$.fragment,c),C(Yk.$$.fragment,c),C(LC.$$.fragment,c),C(Zk.$$.fragment,c),C($C.$$.fragment,c),C(Kk.$$.fragment,c),C(eS.$$.fragment,c),C(rS.$$.fragment,c),C(SC.$$.fragment,c),C(tS.$$.fragment,c),C(BC.$$.fragment,c),C(aS.$$.fragment,c),C(nS.$$.fragment,c),C(lS.$$.fragment,c),C(NC.$$.fragment,c),C(iS.$$.fragment,c),C(DC.$$.fragment,c),C(dS.$$.fragment,c),C(mS.$$.fragment,c),C(fS.$$.fragment,c),C(OC.$$.fragment,c),C(gS.$$.fragment,c),C(KC.$$.fragment,c),C(hS.$$.fragment,c),C(uS.$$.fragment,c),C(_S.$$.fragment,c),C(o3.$$.fragment,c),C(bS.$$.fragment,c),C(i3.$$.fragment,c),C(vS.$$.fragment,c),C(FS.$$.fragment,c),C(MS.$$.fragment,c),C(m3.$$.fragment,c),C(ES.$$.fragment,c),C(M3.$$.fragment,c),C(CS.$$.fragment,c),C(wS.$$.fragment,c),C(LS.$$.fragment,c),C(C3.$$.fragment,c),C(yS.$$.fragment,c),C(x3.$$.fragment,c),C(xS.$$.fragment,c),C($S.$$.fragment,c),C(SS.$$.fragment,c),C(k3.$$.fragment,c),C(RS.$$.fragment,c),C(q3.$$.fragment,c),C(PS.$$.fragment,c),C(BS.$$.fragment,c),C(NS.$$.fragment,c),C(D3.$$.fragment,c),C(qS.$$.fragment,c),C(Q3.$$.fragment,c),C(jS.$$.fragment,c),C(DS.$$.fragment,c),C(OS.$$.fragment,c),C(U3.$$.fragment,c),C(VS.$$.fragment,c),C(e5.$$.fragment,c),C(XS.$$.fragment,c),C(zS.$$.fragment,c),C(WS.$$.fragment,c),C(r5.$$.fragment,c),C(US.$$.fragment,c),C(n5.$$.fragment,c),C(HS.$$.fragment,c),C(JS.$$.fragment,c),C(ZS.$$.fragment,c),C(l5.$$.fragment,c),C(KS.$$.fragment,c),C(h5.$$.fragment,c),C(eR.$$.fragment,c),C(oR.$$.fragment,c),C(tR.$$.fragment,c),C(p5.$$.fragment,c),C(aR.$$.fragment,c),C(v5.$$.fragment,c),C(nR.$$.fragment,c),C(sR.$$.fragment,c),C(iR.$$.fragment,c),C(T5.$$.fragment,c),C(dR.$$.fragment,c),C(C5.$$.fragment,c),C(mR.$$.fragment,c),C(cR.$$.fragment,c),C(gR.$$.fragment,c),C(A5.$$.fragment,c),C(hR.$$.fragment,c),C($0.$$.fragment,c),C(uR.$$.fragment,c),C(pR.$$.fragment,c),C(bR.$$.fragment,c),C(S0.$$.fragment,c),C(vR.$$.fragment,c),C(rw.$$.fragment,c),C(FR.$$.fragment,c),C(TR.$$.fragment,c),C(ER.$$.fragment,c),C(aw.$$.fragment,c),C(CR.$$.fragment,c),C(vw.$$.fragment,c),C(wR.$$.fragment,c),C(AR.$$.fragment,c),C(yR.$$.fragment,c),C(Tw.$$.fragment,c),C(xR.$$.fragment,c),C(kw.$$.fragment,c),C($R.$$.fragment,c),C(kR.$$.fragment,c),C(RR.$$.fragment,c),C(Rw.$$.fragment,c),C(PR.$$.fragment,c),C(Nw.$$.fragment,c),C(BR.$$.fragment,c),C(IR.$$.fragment,c),C(qR.$$.fragment,c),C(jw.$$.fragment,c),C(jR.$$.fragment,c),C(lA.$$.fragment,c),C(DR.$$.fragment,c),C(GR.$$.fragment,c),C(VR.$$.fragment,c),C(dA.$$.fragment,c),C(XR.$$.fragment,c),C(FA.$$.fragment,c),C(zR.$$.fragment,c),C(QR.$$.fragment,c),C(UR.$$.fragment,c),C(MA.$$.fragment,c),C(HR.$$.fragment,c),C(YA.$$.fragment,c),C(JR.$$.fragment,c),C(YR.$$.fragment,c),C(KR.$$.fragment,c),C(KA.$$.fragment,c),C(eP.$$.fragment,c),C(_6.$$.fragment,c),C(oP.$$.fragment,c),C(rP.$$.fragment,c),C(aP.$$.fragment,c),C(v6.$$.fragment,c),C(nP.$$.fragment,c),C(M6.$$.fragment,c),C(lP.$$.fragment,c),C(iP.$$.fragment,c),C(mP.$$.fragment,c),C(C6.$$.fragment,c),C(cP.$$.fragment,c),C(A6.$$.fragment,c),C(fP.$$.fragment,c),C(gP.$$.fragment,c),C(uP.$$.fragment,c),C(y6.$$.fragment,c),C(pP.$$.fragment,c),C($6.$$.fragment,c),C(_P.$$.fragment,c),C(bP.$$.fragment,c),C(FP.$$.fragment,c),C(S6.$$.fragment,c),C(TP.$$.fragment,c),C(o7.$$.fragment,c),C(MP.$$.fragment,c),C(EP.$$.fragment,c),C(wP.$$.fragment,c),C(t7.$$.fragment,c),C(AP.$$.fragment,c),C(w7.$$.fragment,c),C(LP.$$.fragment,c),C(yP.$$.fragment,c),C($P.$$.fragment,c),C(L7.$$.fragment,c),C(kP.$$.fragment,c),C(x7.$$.fragment,c),C(SP.$$.fragment,c),C(RP.$$.fragment,c),C(BP.$$.fragment,c),C(k7.$$.fragment,c),C(IP.$$.fragment,c),C(P7.$$.fragment,c),C(qP.$$.fragment,c),C(jP.$$.fragment,c),C(GP.$$.fragment,c),C(I7.$$.fragment,c),C(OP.$$.fragment,c),C(m8.$$.fragment,c),C(VP.$$.fragment,c),C(XP.$$.fragment,c),C(QP.$$.fragment,c),C(f8.$$.fragment,c),C(WP.$$.fragment,c),C(E8.$$.fragment,c),C(UP.$$.fragment,c),C(HP.$$.fragment,c),C(YP.$$.fragment,c),C(w8.$$.fragment,c),C(ZP.$$.fragment,c),C(j8.$$.fragment,c),C(KP.$$.fragment,c),C(eB.$$.fragment,c),C(rB.$$.fragment,c),C(G8.$$.fragment,c),C(tB.$$.fragment,c),C(Z8.$$.fragment,c),C(aB.$$.fragment,c),C(nB.$$.fragment,c),C(lB.$$.fragment,c),C(eL.$$.fragment,c),C(iB.$$.fragment,c),C(cL.$$.fragment,c),C(dB.$$.fragment,c),C(mB.$$.fragment,c),C(fB.$$.fragment,c),C(gL.$$.fragment,c),C(gB.$$.fragment,c),C(CL.$$.fragment,c),C(hB.$$.fragment,c),C(uB.$$.fragment,c),C(_B.$$.fragment,c),C(AL.$$.fragment,c),C(bB.$$.fragment,c),C(NL.$$.fragment,c),C(vB.$$.fragment,c),C(FB.$$.fragment,c),C(MB.$$.fragment,c),C(jL.$$.fragment,c),C(EB.$$.fragment,c),C(UL.$$.fragment,c),C(CB.$$.fragment,c),C(wB.$$.fragment,c),C(LB.$$.fragment,c),C(JL.$$.fragment,c),C(yB.$$.fragment,c),C(ny.$$.fragment,c),C(xB.$$.fragment,c),C($B.$$.fragment,c),C(SB.$$.fragment,c),C(ly.$$.fragment,c),C(RB.$$.fragment,c),C(dy.$$.fragment,c),C(PB.$$.fragment,c),C(BB.$$.fragment,c),C(NB.$$.fragment,c),C(cy.$$.fragment,c),C(qB.$$.fragment,c),C(hy.$$.fragment,c),C(DB.$$.fragment,c),C(GB.$$.fragment,c),C(VB.$$.fragment,c),C(py.$$.fragment,c),C(XB.$$.fragment,c),C(by.$$.fragment,c),wno=!1},d(c){t(g),c&&t(v),c&&t(u),w(d),c&&t(Vf),c&&t(Ft),c&&t(Xe),c&&t(He),c&&t(zf),w(en,c),c&&t(Je),c&&t(Ae),c&&t(ko),c&&t(on),c&&t(ito),c&&t(Ed),w(n$),c&&t(dto),c&&t(hs),c&&t(mto),w(s$,c),c&&t(cto),c&&t(MN),c&&t(fto),w(Uf,c),c&&t(gto),c&&t(Cd),w(l$),c&&t(hto),c&&t(So),w(i$),w(c$),w(Mu),w(f$),c&&t(uto),c&&t(Ad),w(g$),c&&t(pto),c&&t(Ro),w(h$),w(_$),w(lp),w(b$),c&&t(_to),c&&t(Ld),w(v$),c&&t(bto),c&&t(Po),w(F$),w(E$),w(Kp),w(e_),w(C$),c&&t(vto),c&&t(yd),w(w$),c&&t(Fto),c&&t(Bo),w(A$),w(x$),w(A_),w(L_),w($$),c&&t(Tto),c&&t($d),w(k$),c&&t(Mto),c&&t(Io),w(S$),w(P$),w($_),w(B$),w(Y2),c&&t(Eto),c&&t(Rd),w(I$),c&&t(Cto),c&&t(No),w(N$),w(j$),w(K2),w(D$),w(Hb),c&&t(wto),c&&t(Id),w(G$),c&&t(Ato),c&&t(qo),w(O$),w(X$),w(Yb),w(z$),w(Gv),c&&t(Lto),c&&t(jd),w(Q$),c&&t(yto),c&&t(jo),w(W$),w(H$),w(Vv),w(J$),w(Wv),c&&t(xto),c&&t(Od),w(Z$),c&&t($to),c&&t(Do),w(K$),w(ok),w(Hv),w(rk),w(IF),c&&t(kto),c&&t(zd),w(tk),c&&t(Sto),c&&t(Go),w(ak),w(sk),w(qF),w(lk),w(sT),c&&t(Rto),c&&t(Ud),w(ik),c&&t(Pto),c&&t(Oo),w(dk),w(ck),w(iT),w(fk),w(fM),c&&t(Bto),c&&t(Yd),w(gk),c&&t(Ito),c&&t(Vo),w(hk),w(pk),w(hM),w(_k),w(UM),c&&t(Nto),c&&t(em),w(bk),c&&t(qto),c&&t(Xo),w(vk),w(Tk),w(JM),w(Mk),w(nE),c&&t(jto),c&&t(tm),w(Ek),c&&t(Dto),c&&t(zo),w(Ck),w(Ak),w(lE),w(Lk),w(JE),c&&t(Gto),c&&t(sm),w(yk),c&&t(Oto),c&&t(Qo),w(xk),w(kk),w(ZE),w(Sk),w(U4),c&&t(Vto),c&&t(dm),w(Rk),c&&t(Xto),c&&t(Wo),w(Pk),w(Ik),w(J4),w(Nk),w(K4),c&&t(zto),c&&t(fm),w(qk),c&&t(Qto),c&&t(Uo),w(jk),w(Gk),w(oC),w(Ok),w(sC),c&&t(Wto),c&&t(pm),w(Vk),c&&t(Uto),c&&t(Ho),w(Xk),w(Qk),w(iC),w(Wk),w(wC),c&&t(Hto),c&&t(vm),w(Uk),c&&t(Jto),c&&t(Jo),w(Hk),w(Yk),w(LC),w(Zk),w($C),c&&t(Yto),c&&t(Mm),w(Kk),c&&t(Zto),c&&t(Yo),w(eS),w(rS),w(SC),w(tS),w(BC),c&&t(Kto),c&&t(wm),w(aS),c&&t(eao),c&&t(Zo),w(nS),w(lS),w(NC),w(iS),w(DC),c&&t(oao),c&&t(ym),w(dS),c&&t(rao),c&&t(Ko),w(mS),w(fS),w(OC),w(gS),w(KC),c&&t(tao),c&&t(km),w(hS),c&&t(aao),c&&t(er),w(uS),w(_S),w(o3),w(bS),w(i3),c&&t(nao),c&&t(Pm),w(vS),c&&t(sao),c&&t(or),w(FS),w(MS),w(m3),w(ES),w(M3),c&&t(lao),c&&t(Nm),w(CS),c&&t(iao),c&&t(rr),w(wS),w(LS),w(C3),w(yS),w(x3),c&&t(dao),c&&t(Gm),w(xS),c&&t(mao),c&&t(tr),w($S),w(SS),w(k3),w(RS),w(q3),c&&t(cao),c&&t(Xm),w(PS),c&&t(fao),c&&t(ar),w(BS),w(NS),w(D3),w(qS),w(Q3),c&&t(gao),c&&t(Wm),w(jS),c&&t(hao),c&&t(nr),w(DS),w(OS),w(U3),w(VS),w(e5),c&&t(uao),c&&t(Jm),w(XS),c&&t(pao),c&&t(sr),w(zS),w(WS),w(r5),w(US),w(n5),c&&t(_ao),c&&t(Km),w(HS),c&&t(bao),c&&t(lr),w(JS),w(ZS),w(l5),w(KS),w(h5),c&&t(vao),c&&t(rc),w(eR),c&&t(Fao),c&&t(ir),w(oR),w(tR),w(p5),w(aR),w(v5),c&&t(Tao),c&&t(nc),w(nR),c&&t(Mao),c&&t(dr),w(sR),w(iR),w(T5),w(dR),w(C5),c&&t(Eao),c&&t(ic),w(mR),c&&t(Cao),c&&t(mr),w(cR),w(gR),w(A5),w(hR),w($0),c&&t(wao),c&&t(cc),w(uR),c&&t(Aao),c&&t(cr),w(pR),w(bR),w(S0),w(vR),w(rw),c&&t(Lao),c&&t(hc),w(FR),c&&t(yao),c&&t(fr),w(TR),w(ER),w(aw),w(CR),w(vw),c&&t(xao),c&&t(_c),w(wR),c&&t($ao),c&&t(gr),w(AR),w(yR),w(Tw),w(xR),w(kw),c&&t(kao),c&&t(Fc),w($R),c&&t(Sao),c&&t(hr),w(kR),w(RR),w(Rw),w(PR),w(Nw),c&&t(Rao),c&&t(Cc),w(BR),c&&t(Pao),c&&t(ur),w(IR),w(qR),w(jw),w(jR),w(lA),c&&t(Bao),c&&t(Lc),w(DR),c&&t(Iao),c&&t(pr),w(GR),w(VR),w(dA),w(XR),w(FA),c&&t(Nao),c&&t($c),w(zR),c&&t(qao),c&&t(_r),w(QR),w(UR),w(MA),w(HR),w(YA),c&&t(jao),c&&t(Rc),w(JR),c&&t(Dao),c&&t(br),w(YR),w(KR),w(KA),w(eP),w(_6),c&&t(Gao),c&&t(Ic),w(oP),c&&t(Oao),c&&t(vr),w(rP),w(aP),w(v6),w(nP),w(M6),c&&t(Vao),c&&t(jc),w(lP),c&&t(Xao),c&&t(Fr),w(iP),w(mP),w(C6),w(cP),w(A6),c&&t(zao),c&&t(Oc),w(fP),c&&t(Qao),c&&t(Tr),w(gP),w(uP),w(y6),w(pP),w($6),c&&t(Wao),c&&t(zc),w(_P),c&&t(Uao),c&&t(Mr),w(bP),w(FP),w(S6),w(TP),w(o7),c&&t(Hao),c&&t(Uc),w(MP),c&&t(Jao),c&&t(Er),w(EP),w(wP),w(t7),w(AP),w(w7),c&&t(Yao),c&&t(Yc),w(LP),c&&t(Zao),c&&t(Cr),w(yP),w($P),w(L7),w(kP),w(x7),c&&t(Kao),c&&t(ef),w(SP),c&&t(eno),c&&t(wr),w(RP),w(BP),w(k7),w(IP),w(P7),c&&t(ono),c&&t(tf),w(qP),c&&t(rno),c&&t(Ar),w(jP),w(GP),w(I7),w(OP),w(m8),c&&t(tno),c&&t(sf),w(VP),c&&t(ano),c&&t(Lr),w(XP),w(QP),w(f8),w(WP),w(E8),c&&t(nno),c&&t(mf),w(UP),c&&t(sno),c&&t(yr),w(HP),w(YP),w(w8),w(ZP),w(j8),c&&t(lno),c&&t(gf),w(KP),c&&t(ino),c&&t(xr),w(eB),w(rB),w(G8),w(tB),w(Z8),c&&t(dno),c&&t(pf),w(aB),c&&t(mno),c&&t($r),w(nB),w(lB),w(eL),w(iB),w(cL),c&&t(cno),c&&t(vf),w(dB),c&&t(fno),c&&t(kr),w(mB),w(fB),w(gL),w(gB),w(CL),c&&t(gno),c&&t(Mf),w(hB),c&&t(hno),c&&t(Sr),w(uB),w(_B),w(AL),w(bB),w(NL),c&&t(uno),c&&t(wf),w(vB),c&&t(pno),c&&t(Rr),w(FB),w(MB),w(jL),w(EB),w(UL),c&&t(_no),c&&t(yf),w(CB),c&&t(bno),c&&t(Pr),w(wB),w(LB),w(JL),w(yB),w(ny),c&&t(vno),c&&t(kf),w(xB),c&&t(Fno),c&&t(Br),w($B),w(SB),w(ly),w(RB),w(dy),c&&t(Tno),c&&t(Pf),w(PB),c&&t(Mno),c&&t(Ir),w(BB),w(NB),w(cy),w(qB),w(hy),c&&t(Eno),c&&t(Nf),w(DB),c&&t(Cno),c&&t(Nr),w(GB),w(VB),w(py),w(XB),w(by)}}}const Q5a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function W5a($){return RCa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class e0a extends xCa{constructor(g){super();$Ca(this,g,W5a,z5a,kCa,{})}}export{e0a as default,Q5a as metadata};
