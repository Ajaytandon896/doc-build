import{S as mFa,i as fFa,s as gFa,e as a,k as l,w as F,t as o,M as hFa,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as uFa,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as SCt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function pFa($){let g,v,u,f,p,d,h,xo,dd,Rf,bt,cd,md,Mx,Pf,Ve,He,fd,ns,Ex,ss,ls,Cx,gd,is,wx,hd,Bf,Ja;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),xo=o(`, make sure its
`),dd=a("code"),Rf=o("model_type"),bt=o(" attribute is set to the same key you use when registering the config (here "),cd=a("code"),md=o('"new-model"'),Mx=o(")."),Pf=l(),Ve=a("p"),He=o("Likewise, if your "),fd=a("code"),ns=o("NewModel"),Ex=o(" is a subclass of "),ss=a("a"),ls=o("PreTrainedModel"),Cx=o(`, make sure its
`),gd=a("code"),is=o("config_class"),wx=o(` attribute is set to the same class you use when registering the model (here
`),hd=a("code"),Bf=o("NewModelConfig"),Ja=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var $I=s(u);f=r($I,"NewModelConfig"),$I.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var ud=s(d);h=r(ud,"~transformer.PretrainedConfig"),ud.forEach(t),xo=r(Ae,`, make sure its
`),dd=n(Ae,"CODE",{});var kI=s(dd);Rf=r(kI,"model_type"),kI.forEach(t),bt=r(Ae," attribute is set to the same key you use when registering the config (here "),cd=n(Ae,"CODE",{});var SI=s(cd);md=r(SI,'"new-model"'),SI.forEach(t),Mx=r(Ae,")."),Ae.forEach(t),Pf=i(Je),Ve=n(Je,"P",{});var $o=s(Ve);He=r($o,"Likewise, if your "),fd=n($o,"CODE",{});var Ya=s(fd);ns=r(Ya,"NewModel"),Ya.forEach(t),Ex=r($o," is a subclass of "),ss=n($o,"A",{href:!0});var RI=s(ss);ls=r(RI,"PreTrainedModel"),RI.forEach(t),Cx=r($o,`, make sure its
`),gd=n($o,"CODE",{});var If=s(gd);is=r(If,"config_class"),If.forEach(t),wx=r($o,` attribute is set to the same class you use when registering the model (here
`),hd=n($o,"CODE",{});var PI=s(hd);Bf=r(PI,"NewModelConfig"),PI.forEach(t),Ja=r($o,")."),$o.forEach(t),this.h()},h(){c(ss,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,xo),e(g,dd),e(dd,Rf),e(g,bt),e(g,cd),e(cd,md),e(g,Mx),b(Je,Pf,Ae),b(Je,Ve,Ae),e(Ve,He),e(Ve,fd),e(fd,ns),e(Ve,Ex),e(Ve,ss),e(ss,ls),e(Ve,Cx),e(Ve,gd),e(gd,is),e(Ve,wx),e(Ve,hd),e(hd,Bf),e(Ve,Ja)},d(Je){Je&&t(g),Je&&t(Pf),Je&&t(Ve)}}}function _Fa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vFa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var xo=s(u);f=r(xo,"use_auth_token=True"),xo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function FFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TFa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var xo=s(u);f=r(xo,"use_auth_token=True"),xo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function MFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function EFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function AFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $Fa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function SFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function IFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KFa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Ta($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ETa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ATa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $Ta($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function STa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ITa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KTa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Ma($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function EMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CMa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:I,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wMa($){let g,v,u,f,p,d,h,xo,dd,Rf,bt,cd,md,Mx,Pf,Ve,He,fd,ns,Ex,ss,ls,Cx,gd,is,wx,hd,Bf,Ja,Je,Ae,$I,ud,kI,SI,$o,Ya,RI,If,PI,Gno,ioo,pd,Nf,zce,Ax,Ono,Qce,Vno,doo,ds,Xno,Wce,zno,Qno,Uce,Wno,Uno,coo,Lx,moo,BI,Hno,foo,qf,goo,_d,jf,Hce,yx,Jno,Jce,Yno,hoo,ko,xx,Zno,$x,Kno,II,eso,oso,rso,kx,tso,Yce,aso,nso,sso,Ir,Sx,lso,Zce,iso,dso,bd,cso,Kce,mso,fso,eme,gso,hso,uso,A,Df,ome,pso,_so,NI,bso,vso,Fso,Gf,rme,Tso,Mso,qI,Eso,Cso,wso,Of,tme,Aso,Lso,jI,yso,xso,$so,Vf,ame,kso,Sso,DI,Rso,Pso,Bso,Xf,nme,Iso,Nso,GI,qso,jso,Dso,zf,sme,Gso,Oso,OI,Vso,Xso,zso,Qf,lme,Qso,Wso,VI,Uso,Hso,Jso,Wf,ime,Yso,Zso,XI,Kso,elo,olo,Uf,dme,rlo,tlo,zI,alo,nlo,slo,Hf,cme,llo,ilo,QI,dlo,clo,mlo,Jf,mme,flo,glo,WI,hlo,ulo,plo,Yf,fme,_lo,blo,UI,vlo,Flo,Tlo,Zf,gme,Mlo,Elo,HI,Clo,wlo,Alo,Kf,hme,Llo,ylo,JI,xlo,$lo,klo,eg,ume,Slo,Rlo,YI,Plo,Blo,Ilo,og,pme,Nlo,qlo,ZI,jlo,Dlo,Glo,rg,_me,Olo,Vlo,KI,Xlo,zlo,Qlo,tg,bme,Wlo,Ulo,eN,Hlo,Jlo,Ylo,ag,vme,Zlo,Klo,oN,eio,oio,rio,ng,Fme,tio,aio,rN,nio,sio,lio,sg,Tme,iio,dio,tN,cio,mio,fio,lg,Mme,gio,hio,aN,uio,pio,_io,ig,Eme,bio,vio,nN,Fio,Tio,Mio,dg,Cme,Eio,Cio,sN,wio,Aio,Lio,cg,wme,yio,xio,lN,$io,kio,Sio,mg,Ame,Rio,Pio,iN,Bio,Iio,Nio,fg,Lme,qio,jio,dN,Dio,Gio,Oio,gg,yme,Vio,Xio,cN,zio,Qio,Wio,hg,xme,Uio,Hio,mN,Jio,Yio,Zio,ug,$me,Kio,edo,fN,odo,rdo,tdo,pg,kme,ado,ndo,gN,sdo,ldo,ido,_g,Sme,ddo,cdo,hN,mdo,fdo,gdo,bg,Rme,hdo,udo,uN,pdo,_do,bdo,vg,Pme,vdo,Fdo,pN,Tdo,Mdo,Edo,Fg,Bme,Cdo,wdo,_N,Ado,Ldo,ydo,Tg,Ime,xdo,$do,bN,kdo,Sdo,Rdo,Mg,Nme,Pdo,Bdo,vN,Ido,Ndo,qdo,Eg,qme,jdo,Ddo,FN,Gdo,Odo,Vdo,Cg,jme,Xdo,zdo,TN,Qdo,Wdo,Udo,wg,Dme,Hdo,Jdo,MN,Ydo,Zdo,Kdo,Ag,Gme,eco,oco,EN,rco,tco,aco,Lg,Ome,nco,sco,CN,lco,ico,dco,yg,Vme,cco,mco,wN,fco,gco,hco,xg,Xme,uco,pco,AN,_co,bco,vco,$g,zme,Fco,Tco,LN,Mco,Eco,Cco,kg,Qme,wco,Aco,yN,Lco,yco,xco,Sg,Wme,$co,kco,xN,Sco,Rco,Pco,Rg,Ume,Bco,Ico,$N,Nco,qco,jco,Pg,Hme,Dco,Gco,kN,Oco,Vco,Xco,Bg,Jme,zco,Qco,SN,Wco,Uco,Hco,Ig,Yme,Jco,Yco,RN,Zco,Kco,emo,Ng,Zme,omo,rmo,PN,tmo,amo,nmo,qg,Kme,smo,lmo,BN,imo,dmo,cmo,jg,efe,mmo,fmo,IN,gmo,hmo,umo,Dg,ofe,pmo,_mo,NN,bmo,vmo,Fmo,Gg,rfe,Tmo,Mmo,qN,Emo,Cmo,wmo,Og,tfe,Amo,Lmo,jN,ymo,xmo,$mo,Vg,afe,kmo,Smo,DN,Rmo,Pmo,Bmo,Xg,nfe,Imo,Nmo,GN,qmo,jmo,Dmo,zg,sfe,Gmo,Omo,ON,Vmo,Xmo,zmo,Qg,lfe,Qmo,Wmo,VN,Umo,Hmo,Jmo,Wg,ife,Ymo,Zmo,XN,Kmo,efo,ofo,Ug,dfe,rfo,tfo,zN,afo,nfo,sfo,Hg,cfe,lfo,ifo,QN,dfo,cfo,mfo,Jg,mfe,ffo,gfo,WN,hfo,ufo,pfo,Yg,ffe,_fo,bfo,UN,vfo,Ffo,Tfo,Zg,gfe,Mfo,Efo,HN,Cfo,wfo,Afo,Kg,hfe,Lfo,yfo,JN,xfo,$fo,kfo,eh,ufe,Sfo,Rfo,YN,Pfo,Bfo,Ifo,oh,pfe,Nfo,qfo,ZN,jfo,Dfo,Gfo,rh,_fe,Ofo,Vfo,KN,Xfo,zfo,Qfo,th,bfe,Wfo,Ufo,eq,Hfo,Jfo,Yfo,ah,vfe,Zfo,Kfo,oq,ego,ogo,rgo,nh,Ffe,tgo,ago,rq,ngo,sgo,lgo,sh,Tfe,igo,dgo,tq,cgo,mgo,fgo,lh,Mfe,ggo,hgo,aq,ugo,pgo,_go,ih,Efe,bgo,vgo,nq,Fgo,Tgo,Mgo,dh,Cfe,Ego,Cgo,sq,wgo,Ago,Lgo,ch,wfe,ygo,xgo,lq,$go,kgo,Sgo,mh,Afe,Rgo,Pgo,iq,Bgo,Igo,Ngo,fh,Lfe,qgo,jgo,dq,Dgo,Ggo,Ogo,gh,yfe,Vgo,Xgo,cq,zgo,Qgo,Wgo,hh,xfe,Ugo,Hgo,mq,Jgo,Ygo,Zgo,uh,$fe,Kgo,eho,fq,oho,rho,tho,ph,kfe,aho,nho,gq,sho,lho,iho,_h,Sfe,dho,cho,hq,mho,fho,gho,bh,Rfe,hho,uho,uq,pho,_ho,bho,vh,Pfe,vho,Fho,pq,Tho,Mho,Eho,Fh,Bfe,Cho,who,_q,Aho,Lho,yho,Th,Ife,xho,$ho,bq,kho,Sho,Rho,Mh,Nfe,Pho,Bho,vq,Iho,Nho,qho,Eh,qfe,jho,Dho,Fq,Gho,Oho,Vho,Ch,jfe,Xho,zho,Tq,Qho,Who,Uho,wh,Dfe,Hho,Jho,Mq,Yho,Zho,Kho,Ah,Gfe,euo,ouo,Eq,ruo,tuo,auo,Lh,Ofe,nuo,suo,Cq,luo,iuo,duo,yh,Vfe,cuo,muo,wq,fuo,guo,huo,xh,Xfe,uuo,puo,Aq,_uo,buo,vuo,$h,zfe,Fuo,Tuo,Lq,Muo,Euo,Cuo,kh,Qfe,wuo,Auo,yq,Luo,yuo,xuo,Sh,Wfe,$uo,kuo,xq,Suo,Ruo,Puo,Rh,Ufe,Buo,Iuo,$q,Nuo,quo,juo,Ph,Hfe,Duo,Guo,kq,Ouo,Vuo,Xuo,Bh,Jfe,zuo,Quo,Sq,Wuo,Uuo,Huo,Ih,Yfe,Juo,Yuo,Rq,Zuo,Kuo,epo,Nh,Zfe,opo,rpo,Pq,tpo,apo,npo,qh,Kfe,spo,lpo,Bq,ipo,dpo,cpo,jh,ege,mpo,fpo,Iq,gpo,hpo,upo,Dh,oge,ppo,_po,Nq,bpo,vpo,Fpo,Gh,rge,Tpo,Mpo,qq,Epo,Cpo,wpo,Oh,tge,Apo,Lpo,jq,ypo,xpo,$po,Vh,age,kpo,Spo,Dq,Rpo,Ppo,Bpo,Xh,nge,Ipo,Npo,Gq,qpo,jpo,Dpo,zh,sge,Gpo,Opo,Oq,Vpo,Xpo,zpo,Qh,lge,Qpo,Wpo,Vq,Upo,Hpo,Jpo,Wh,ige,Ypo,Zpo,Xq,Kpo,e_o,o_o,Uh,dge,r_o,t_o,zq,a_o,n_o,s_o,Hh,cge,l_o,i_o,Qq,d_o,c_o,m_o,Jh,mge,f_o,g_o,Wq,h_o,u_o,p_o,Yh,fge,__o,b_o,Uq,v_o,F_o,T_o,Zh,gge,M_o,E_o,Hq,C_o,w_o,A_o,Kh,hge,L_o,y_o,Jq,x_o,$_o,k_o,eu,uge,S_o,R_o,Yq,P_o,B_o,I_o,ou,pge,N_o,q_o,Zq,j_o,D_o,G_o,ru,_ge,O_o,V_o,Kq,X_o,z_o,Q_o,tu,bge,W_o,U_o,ej,H_o,J_o,Y_o,au,vge,Z_o,K_o,oj,e1o,o1o,r1o,nu,Fge,t1o,a1o,rj,n1o,s1o,l1o,su,Tge,i1o,d1o,tj,c1o,m1o,f1o,lu,Mge,g1o,h1o,aj,u1o,p1o,_1o,iu,Ege,b1o,v1o,nj,F1o,T1o,M1o,du,Cge,E1o,C1o,sj,w1o,A1o,L1o,cu,wge,y1o,x1o,lj,$1o,k1o,S1o,mu,R1o,fu,Rx,P1o,Age,B1o,uoo,vd,gu,Lge,Px,I1o,yge,N1o,poo,So,Bx,q1o,Ix,j1o,ij,D1o,G1o,O1o,Nx,V1o,xge,X1o,z1o,Q1o,Nr,qx,W1o,$ge,U1o,H1o,Za,J1o,kge,Y1o,Z1o,Sge,K1o,ebo,Rge,obo,rbo,tbo,k,cs,Pge,abo,nbo,dj,sbo,lbo,cj,ibo,dbo,cbo,ms,Bge,mbo,fbo,mj,gbo,hbo,fj,ubo,pbo,_bo,fs,Ige,bbo,vbo,gj,Fbo,Tbo,hj,Mbo,Ebo,Cbo,hu,Nge,wbo,Abo,uj,Lbo,ybo,xbo,gs,qge,$bo,kbo,pj,Sbo,Rbo,_j,Pbo,Bbo,Ibo,uu,jge,Nbo,qbo,bj,jbo,Dbo,Gbo,pu,Dge,Obo,Vbo,vj,Xbo,zbo,Qbo,_u,Gge,Wbo,Ubo,Fj,Hbo,Jbo,Ybo,hs,Oge,Zbo,Kbo,Tj,e2o,o2o,Mj,r2o,t2o,a2o,us,Vge,n2o,s2o,Ej,l2o,i2o,Cj,d2o,c2o,m2o,ps,Xge,f2o,g2o,wj,h2o,u2o,Aj,p2o,_2o,b2o,bu,zge,v2o,F2o,Lj,T2o,M2o,E2o,vu,Qge,C2o,w2o,yj,A2o,L2o,y2o,Fu,Wge,x2o,$2o,xj,k2o,S2o,R2o,_s,Uge,P2o,B2o,$j,I2o,N2o,kj,q2o,j2o,D2o,Tu,Hge,G2o,O2o,Sj,V2o,X2o,z2o,bs,Jge,Q2o,W2o,Rj,U2o,H2o,Pj,J2o,Y2o,Z2o,vs,Yge,K2o,evo,Bj,ovo,rvo,Ij,tvo,avo,nvo,Fs,Zge,svo,lvo,Nj,ivo,dvo,qj,cvo,mvo,fvo,Ts,Kge,gvo,hvo,jj,uvo,pvo,Dj,_vo,bvo,vvo,Mu,ehe,Fvo,Tvo,Gj,Mvo,Evo,Cvo,Ms,ohe,wvo,Avo,Oj,Lvo,yvo,Vj,xvo,$vo,kvo,Es,rhe,Svo,Rvo,Xj,Pvo,Bvo,zj,Ivo,Nvo,qvo,Cs,the,jvo,Dvo,Qj,Gvo,Ovo,Wj,Vvo,Xvo,zvo,ws,ahe,Qvo,Wvo,Uj,Uvo,Hvo,Hj,Jvo,Yvo,Zvo,As,nhe,Kvo,eFo,Jj,oFo,rFo,Yj,tFo,aFo,nFo,Ls,she,sFo,lFo,Zj,iFo,dFo,Kj,cFo,mFo,fFo,ys,lhe,gFo,hFo,eD,uFo,pFo,oD,_Fo,bFo,vFo,Eu,ihe,FFo,TFo,rD,MFo,EFo,CFo,xs,dhe,wFo,AFo,tD,LFo,yFo,aD,xFo,$Fo,kFo,Cu,che,SFo,RFo,nD,PFo,BFo,IFo,$s,mhe,NFo,qFo,sD,jFo,DFo,lD,GFo,OFo,VFo,ks,fhe,XFo,zFo,iD,QFo,WFo,dD,UFo,HFo,JFo,Ss,ghe,YFo,ZFo,cD,KFo,eTo,mD,oTo,rTo,tTo,wu,hhe,aTo,nTo,fD,sTo,lTo,iTo,Au,uhe,dTo,cTo,gD,mTo,fTo,gTo,Rs,phe,hTo,uTo,hD,pTo,_To,uD,bTo,vTo,FTo,Ps,_he,TTo,MTo,pD,ETo,CTo,_D,wTo,ATo,LTo,Bs,bhe,yTo,xTo,bD,$To,kTo,vD,STo,RTo,PTo,Lu,vhe,BTo,ITo,FD,NTo,qTo,jTo,Is,Fhe,DTo,GTo,TD,OTo,VTo,MD,XTo,zTo,QTo,Ns,The,WTo,UTo,ED,HTo,JTo,CD,YTo,ZTo,KTo,qs,Mhe,eMo,oMo,wD,rMo,tMo,AD,aMo,nMo,sMo,js,Ehe,lMo,iMo,LD,dMo,cMo,yD,mMo,fMo,gMo,Ds,Che,hMo,uMo,xD,pMo,_Mo,$D,bMo,vMo,FMo,Gs,whe,TMo,MMo,kD,EMo,CMo,SD,wMo,AMo,LMo,Os,Ahe,yMo,xMo,RD,$Mo,kMo,PD,SMo,RMo,PMo,Vs,Lhe,BMo,IMo,BD,NMo,qMo,ID,jMo,DMo,GMo,yu,yhe,OMo,VMo,ND,XMo,zMo,QMo,Xs,xhe,WMo,UMo,qD,HMo,JMo,jD,YMo,ZMo,KMo,xu,$he,eEo,oEo,DD,rEo,tEo,aEo,$u,khe,nEo,sEo,GD,lEo,iEo,dEo,zs,She,cEo,mEo,OD,fEo,gEo,VD,hEo,uEo,pEo,Qs,Rhe,_Eo,bEo,XD,vEo,FEo,zD,TEo,MEo,EEo,Ws,Phe,CEo,wEo,QD,AEo,LEo,WD,yEo,xEo,$Eo,ku,Bhe,kEo,SEo,UD,REo,PEo,BEo,Us,Ihe,IEo,NEo,HD,qEo,jEo,JD,DEo,GEo,OEo,Hs,Nhe,VEo,XEo,YD,zEo,QEo,ZD,WEo,UEo,HEo,Js,qhe,JEo,YEo,KD,ZEo,KEo,eG,e4o,o4o,r4o,Ys,jhe,t4o,a4o,oG,n4o,s4o,rG,l4o,i4o,d4o,Zs,Dhe,c4o,m4o,tG,f4o,g4o,aG,h4o,u4o,p4o,Ks,Ghe,_4o,b4o,nG,v4o,F4o,sG,T4o,M4o,E4o,el,Ohe,C4o,w4o,lG,A4o,L4o,iG,y4o,x4o,$4o,ol,Vhe,k4o,S4o,dG,R4o,P4o,cG,B4o,I4o,N4o,Su,Xhe,q4o,j4o,mG,D4o,G4o,O4o,rl,zhe,V4o,X4o,fG,z4o,Q4o,gG,W4o,U4o,H4o,tl,Qhe,J4o,Y4o,hG,Z4o,K4o,uG,eCo,oCo,rCo,Ru,Whe,tCo,aCo,pG,nCo,sCo,lCo,Pu,Uhe,iCo,dCo,_G,cCo,mCo,fCo,Bu,Hhe,gCo,hCo,bG,uCo,pCo,_Co,Iu,Jhe,bCo,vCo,vG,FCo,TCo,MCo,al,Yhe,ECo,CCo,FG,wCo,ACo,TG,LCo,yCo,xCo,Nu,Zhe,$Co,kCo,MG,SCo,RCo,PCo,nl,Khe,BCo,ICo,EG,NCo,qCo,CG,jCo,DCo,GCo,sl,eue,OCo,VCo,wG,XCo,zCo,AG,QCo,WCo,UCo,ll,oue,HCo,JCo,LG,YCo,ZCo,yG,KCo,e3o,o3o,il,rue,r3o,t3o,xG,a3o,n3o,$G,s3o,l3o,i3o,dl,tue,d3o,c3o,kG,m3o,f3o,SG,g3o,h3o,u3o,cl,aue,p3o,_3o,RG,b3o,v3o,PG,F3o,T3o,M3o,qu,nue,E3o,C3o,BG,w3o,A3o,L3o,ju,sue,y3o,x3o,IG,$3o,k3o,S3o,ml,lue,R3o,P3o,NG,B3o,I3o,qG,N3o,q3o,j3o,fl,iue,D3o,G3o,jG,O3o,V3o,DG,X3o,z3o,Q3o,gl,due,W3o,U3o,GG,H3o,J3o,OG,Y3o,Z3o,K3o,Du,cue,e5o,o5o,VG,r5o,t5o,a5o,Gu,mue,n5o,s5o,XG,l5o,i5o,d5o,Ou,fue,c5o,m5o,zG,f5o,g5o,h5o,hl,gue,u5o,p5o,QG,_5o,b5o,WG,v5o,F5o,T5o,ul,hue,M5o,E5o,UG,C5o,w5o,HG,A5o,L5o,y5o,Vu,uue,x5o,$5o,JG,k5o,S5o,R5o,Xu,pue,P5o,B5o,YG,I5o,N5o,q5o,zu,_ue,j5o,D5o,ZG,G5o,O5o,V5o,Qu,bue,X5o,z5o,KG,Q5o,W5o,U5o,pl,vue,H5o,J5o,eO,Y5o,Z5o,oO,K5o,e0o,o0o,_l,Fue,r0o,t0o,rO,a0o,n0o,tO,s0o,l0o,i0o,Wu,Tue,d0o,c0o,aO,m0o,f0o,g0o,Uu,Mue,h0o,u0o,nO,p0o,_0o,b0o,bl,Eue,v0o,F0o,sO,T0o,M0o,lO,E0o,C0o,w0o,vl,Cue,A0o,L0o,iO,y0o,x0o,dO,$0o,k0o,S0o,Fl,wue,R0o,P0o,cO,B0o,I0o,mO,N0o,q0o,j0o,Tl,Aue,D0o,G0o,fO,O0o,V0o,gO,X0o,z0o,Q0o,Hu,W0o,Ju,jx,U0o,Lue,H0o,_oo,Fd,Yu,yue,Dx,J0o,xue,Y0o,boo,Ro,Gx,Z0o,Ox,K0o,hO,ewo,owo,rwo,Vx,two,$ue,awo,nwo,swo,Ye,Xx,lwo,kue,iwo,dwo,Ka,cwo,Sue,mwo,fwo,Rue,gwo,hwo,Pue,uwo,pwo,_wo,z,Zu,Bue,bwo,vwo,uO,Fwo,Two,Mwo,Ku,Iue,Ewo,Cwo,pO,wwo,Awo,Lwo,ep,Nue,ywo,xwo,_O,$wo,kwo,Swo,op,que,Rwo,Pwo,bO,Bwo,Iwo,Nwo,rp,jue,qwo,jwo,vO,Dwo,Gwo,Owo,tp,Due,Vwo,Xwo,FO,zwo,Qwo,Wwo,ap,Gue,Uwo,Hwo,TO,Jwo,Ywo,Zwo,np,Oue,Kwo,eAo,MO,oAo,rAo,tAo,sp,Vue,aAo,nAo,EO,sAo,lAo,iAo,lp,Xue,dAo,cAo,CO,mAo,fAo,gAo,ip,zue,hAo,uAo,wO,pAo,_Ao,bAo,dp,Que,vAo,FAo,AO,TAo,MAo,EAo,cp,Wue,CAo,wAo,LO,AAo,LAo,yAo,mp,Uue,xAo,$Ao,yO,kAo,SAo,RAo,fp,Hue,PAo,BAo,xO,IAo,NAo,qAo,gp,Jue,jAo,DAo,$O,GAo,OAo,VAo,hp,Yue,XAo,zAo,kO,QAo,WAo,UAo,up,Zue,HAo,JAo,SO,YAo,ZAo,KAo,pp,Kue,e6o,o6o,RO,r6o,t6o,a6o,_p,epe,n6o,s6o,PO,l6o,i6o,d6o,bp,ope,c6o,m6o,BO,f6o,g6o,h6o,vp,rpe,u6o,p6o,IO,_6o,b6o,v6o,Fp,tpe,F6o,T6o,NO,M6o,E6o,C6o,Tp,ape,w6o,A6o,qO,L6o,y6o,x6o,Mp,npe,$6o,k6o,jO,S6o,R6o,P6o,Ep,spe,B6o,I6o,DO,N6o,q6o,j6o,Cp,lpe,D6o,G6o,GO,O6o,V6o,X6o,wp,ipe,z6o,Q6o,OO,W6o,U6o,H6o,Ap,dpe,J6o,Y6o,VO,Z6o,K6o,e7o,Lp,cpe,o7o,r7o,XO,t7o,a7o,n7o,yp,mpe,s7o,l7o,zO,i7o,d7o,c7o,xp,fpe,m7o,f7o,QO,g7o,h7o,u7o,$p,gpe,p7o,_7o,WO,b7o,v7o,F7o,kp,hpe,T7o,M7o,UO,E7o,C7o,w7o,Sp,upe,A7o,L7o,HO,y7o,x7o,$7o,Rp,ppe,k7o,S7o,JO,R7o,P7o,B7o,Pp,_pe,I7o,N7o,YO,q7o,j7o,D7o,Bp,bpe,G7o,O7o,ZO,V7o,X7o,z7o,Ip,vpe,Q7o,W7o,KO,U7o,H7o,J7o,Np,Fpe,Y7o,Z7o,eV,K7o,eLo,oLo,qp,Tpe,rLo,tLo,oV,aLo,nLo,sLo,jp,Mpe,lLo,iLo,rV,dLo,cLo,mLo,Dp,Epe,fLo,gLo,tV,hLo,uLo,pLo,Gp,_Lo,Op,bLo,Vp,zx,vLo,Cpe,FLo,voo,Td,Xp,wpe,Qx,TLo,Ape,MLo,Foo,Po,Wx,ELo,Ux,CLo,aV,wLo,ALo,LLo,Hx,yLo,Lpe,xLo,$Lo,kLo,Ze,Jx,SLo,ype,RLo,PLo,Md,BLo,xpe,ILo,NLo,$pe,qLo,jLo,DLo,se,zp,kpe,GLo,OLo,nV,VLo,XLo,zLo,Qp,Spe,QLo,WLo,sV,ULo,HLo,JLo,Wp,Rpe,YLo,ZLo,lV,KLo,eyo,oyo,Up,Ppe,ryo,tyo,iV,ayo,nyo,syo,Hp,Bpe,lyo,iyo,dV,dyo,cyo,myo,Jp,Ipe,fyo,gyo,cV,hyo,uyo,pyo,Yp,Npe,_yo,byo,mV,vyo,Fyo,Tyo,Zp,qpe,Myo,Eyo,fV,Cyo,wyo,Ayo,Kp,jpe,Lyo,yyo,gV,xyo,$yo,kyo,e_,Dpe,Syo,Ryo,hV,Pyo,Byo,Iyo,o_,Gpe,Nyo,qyo,uV,jyo,Dyo,Gyo,r_,Ope,Oyo,Vyo,pV,Xyo,zyo,Qyo,t_,Vpe,Wyo,Uyo,_V,Hyo,Jyo,Yyo,a_,Xpe,Zyo,Kyo,bV,e8o,o8o,r8o,n_,zpe,t8o,a8o,vV,n8o,s8o,l8o,s_,Qpe,i8o,d8o,FV,c8o,m8o,f8o,l_,Wpe,g8o,h8o,TV,u8o,p8o,_8o,i_,Upe,b8o,v8o,MV,F8o,T8o,M8o,d_,Hpe,E8o,C8o,EV,w8o,A8o,L8o,c_,Jpe,y8o,x8o,CV,$8o,k8o,S8o,m_,Ype,R8o,P8o,wV,B8o,I8o,N8o,f_,Zpe,q8o,j8o,AV,D8o,G8o,O8o,g_,Kpe,V8o,X8o,LV,z8o,Q8o,W8o,h_,U8o,u_,H8o,p_,Yx,J8o,e_e,Y8o,Too,Ed,__,o_e,Zx,Z8o,r_e,K8o,Moo,Bo,Kx,e9o,Cd,o9o,yV,r9o,t9o,xV,a9o,n9o,s9o,e$,l9o,t_e,i9o,d9o,c9o,vt,o$,m9o,a_e,f9o,g9o,wd,h9o,n_e,u9o,p9o,$V,_9o,b9o,v9o,b_,F9o,Ke,r$,T9o,s_e,M9o,E9o,en,C9o,l_e,w9o,A9o,i_e,L9o,y9o,d_e,x9o,$9o,k9o,y,v_,c_e,S9o,R9o,kV,P9o,B9o,I9o,F_,m_e,N9o,q9o,SV,j9o,D9o,G9o,T_,f_e,O9o,V9o,RV,X9o,z9o,Q9o,M_,g_e,W9o,U9o,PV,H9o,J9o,Y9o,E_,h_e,Z9o,K9o,BV,exo,oxo,rxo,C_,u_e,txo,axo,IV,nxo,sxo,lxo,w_,p_e,ixo,dxo,NV,cxo,mxo,fxo,A_,__e,gxo,hxo,qV,uxo,pxo,_xo,L_,b_e,bxo,vxo,jV,Fxo,Txo,Mxo,y_,v_e,Exo,Cxo,DV,wxo,Axo,Lxo,x_,F_e,yxo,xxo,GV,$xo,kxo,Sxo,$_,T_e,Rxo,Pxo,OV,Bxo,Ixo,Nxo,k_,M_e,qxo,jxo,VV,Dxo,Gxo,Oxo,S_,E_e,Vxo,Xxo,XV,zxo,Qxo,Wxo,R_,C_e,Uxo,Hxo,zV,Jxo,Yxo,Zxo,P_,w_e,Kxo,e$o,QV,o$o,r$o,t$o,B_,A_e,a$o,n$o,WV,s$o,l$o,i$o,I_,L_e,d$o,c$o,UV,m$o,f$o,g$o,N_,y_e,h$o,u$o,HV,p$o,_$o,b$o,q_,x_e,v$o,F$o,JV,T$o,M$o,E$o,j_,$_e,C$o,w$o,YV,A$o,L$o,y$o,D_,k_e,x$o,$$o,ZV,k$o,S$o,R$o,G_,S_e,P$o,B$o,KV,I$o,N$o,q$o,O_,R_e,j$o,D$o,eX,G$o,O$o,V$o,V_,P_e,X$o,z$o,oX,Q$o,W$o,U$o,X_,B_e,H$o,J$o,rX,Y$o,Z$o,K$o,z_,I_e,eko,oko,tX,rko,tko,ako,Q_,N_e,nko,sko,aX,lko,iko,dko,W_,q_e,cko,mko,nX,fko,gko,hko,U_,j_e,uko,pko,sX,_ko,bko,vko,H_,D_e,Fko,Tko,lX,Mko,Eko,Cko,J_,G_e,wko,Ako,iX,Lko,yko,xko,Y_,O_e,$ko,kko,dX,Sko,Rko,Pko,Z_,V_e,Bko,Iko,cX,Nko,qko,jko,K_,X_e,Dko,Gko,mX,Oko,Vko,Xko,e1,z_e,zko,Qko,fX,Wko,Uko,Hko,o1,Q_e,Jko,Yko,gX,Zko,Kko,eSo,r1,W_e,oSo,rSo,hX,tSo,aSo,nSo,t1,U_e,sSo,lSo,uX,iSo,dSo,cSo,Ml,H_e,mSo,fSo,pX,gSo,hSo,_X,uSo,pSo,_So,a1,J_e,bSo,vSo,bX,FSo,TSo,MSo,n1,Y_e,ESo,CSo,vX,wSo,ASo,LSo,s1,Z_e,ySo,xSo,FX,$So,kSo,SSo,l1,K_e,RSo,PSo,TX,BSo,ISo,NSo,i1,e1e,qSo,jSo,MX,DSo,GSo,OSo,d1,o1e,VSo,XSo,EX,zSo,QSo,WSo,c1,r1e,USo,HSo,CX,JSo,YSo,ZSo,m1,t1e,KSo,eRo,wX,oRo,rRo,tRo,f1,a1e,aRo,nRo,AX,sRo,lRo,iRo,g1,n1e,dRo,cRo,LX,mRo,fRo,gRo,h1,s1e,hRo,uRo,yX,pRo,_Ro,bRo,u1,l1e,vRo,FRo,xX,TRo,MRo,ERo,p1,i1e,CRo,wRo,$X,ARo,LRo,yRo,_1,d1e,xRo,$Ro,kX,kRo,SRo,RRo,b1,c1e,PRo,BRo,SX,IRo,NRo,qRo,v1,m1e,jRo,DRo,RX,GRo,ORo,VRo,F1,f1e,XRo,zRo,PX,QRo,WRo,URo,T1,g1e,HRo,JRo,BX,YRo,ZRo,KRo,M1,h1e,ePo,oPo,IX,rPo,tPo,aPo,E1,u1e,nPo,sPo,NX,lPo,iPo,dPo,C1,p1e,cPo,mPo,qX,fPo,gPo,hPo,w1,_1e,uPo,pPo,jX,_Po,bPo,vPo,A1,b1e,FPo,TPo,DX,MPo,EPo,CPo,L1,v1e,wPo,APo,GX,LPo,yPo,xPo,y1,F1e,$Po,kPo,OX,SPo,RPo,PPo,x1,T1e,BPo,IPo,VX,NPo,qPo,jPo,$1,M1e,DPo,GPo,XX,OPo,VPo,XPo,k1,E1e,zPo,QPo,zX,WPo,UPo,HPo,S1,C1e,JPo,YPo,QX,ZPo,KPo,eBo,R1,w1e,oBo,rBo,WX,tBo,aBo,nBo,P1,A1e,sBo,lBo,UX,iBo,dBo,cBo,B1,L1e,mBo,fBo,HX,gBo,hBo,uBo,I1,y1e,pBo,_Bo,JX,bBo,vBo,FBo,N1,x1e,TBo,MBo,YX,EBo,CBo,wBo,q1,$1e,ABo,LBo,ZX,yBo,xBo,$Bo,j1,k1e,kBo,SBo,KX,RBo,PBo,BBo,D1,S1e,IBo,NBo,ez,qBo,jBo,DBo,G1,R1e,GBo,OBo,oz,VBo,XBo,zBo,O1,P1e,QBo,WBo,rz,UBo,HBo,JBo,V1,B1e,YBo,ZBo,tz,KBo,eIo,oIo,X1,I1e,rIo,tIo,az,aIo,nIo,sIo,z1,N1e,lIo,iIo,nz,dIo,cIo,mIo,Q1,q1e,fIo,gIo,sz,hIo,uIo,pIo,W1,j1e,_Io,bIo,lz,vIo,FIo,TIo,U1,D1e,MIo,EIo,iz,CIo,wIo,AIo,H1,G1e,LIo,yIo,dz,xIo,$Io,kIo,J1,O1e,SIo,RIo,cz,PIo,BIo,IIo,Y1,V1e,NIo,qIo,mz,jIo,DIo,GIo,Z1,X1e,OIo,VIo,fz,XIo,zIo,QIo,K1,z1e,WIo,UIo,gz,HIo,JIo,YIo,eb,Q1e,ZIo,KIo,hz,eNo,oNo,rNo,ob,W1e,tNo,aNo,uz,nNo,sNo,lNo,rb,U1e,iNo,dNo,pz,cNo,mNo,fNo,tb,H1e,gNo,hNo,_z,uNo,pNo,_No,ab,J1e,bNo,vNo,bz,FNo,TNo,MNo,nb,Y1e,ENo,CNo,vz,wNo,ANo,LNo,sb,Z1e,yNo,xNo,Fz,$No,kNo,SNo,lb,K1e,RNo,PNo,Tz,BNo,INo,NNo,ib,ebe,qNo,jNo,Mz,DNo,GNo,ONo,db,obe,VNo,XNo,Ez,zNo,QNo,WNo,cb,rbe,UNo,HNo,Cz,JNo,YNo,ZNo,mb,tbe,KNo,eqo,wz,oqo,rqo,tqo,fb,abe,aqo,nqo,Az,sqo,lqo,iqo,gb,nbe,dqo,cqo,Lz,mqo,fqo,gqo,hb,sbe,hqo,uqo,yz,pqo,_qo,bqo,ub,lbe,vqo,Fqo,xz,Tqo,Mqo,Eqo,pb,ibe,Cqo,wqo,$z,Aqo,Lqo,yqo,_b,dbe,xqo,$qo,kz,kqo,Sqo,Rqo,bb,cbe,Pqo,Bqo,Sz,Iqo,Nqo,qqo,vb,mbe,jqo,Dqo,Rz,Gqo,Oqo,Vqo,Fb,fbe,Xqo,zqo,Pz,Qqo,Wqo,Uqo,Tb,gbe,Hqo,Jqo,Bz,Yqo,Zqo,Kqo,Mb,hbe,ejo,ojo,Iz,rjo,tjo,ajo,Eb,ube,njo,sjo,Nz,ljo,ijo,djo,Cb,pbe,cjo,mjo,qz,fjo,gjo,hjo,wb,_be,ujo,pjo,jz,_jo,bjo,vjo,Ab,bbe,Fjo,Tjo,Dz,Mjo,Ejo,Cjo,Lb,vbe,wjo,Ajo,Gz,Ljo,yjo,xjo,yb,Fbe,$jo,kjo,Oz,Sjo,Rjo,Pjo,xb,Tbe,Bjo,Ijo,Vz,Njo,qjo,jjo,$b,Mbe,Djo,Gjo,Xz,Ojo,Vjo,Xjo,kb,Ebe,zjo,Qjo,zz,Wjo,Ujo,Hjo,Sb,Cbe,Jjo,Yjo,Qz,Zjo,Kjo,eDo,Rb,wbe,oDo,rDo,Wz,tDo,aDo,nDo,Pb,Abe,sDo,lDo,Uz,iDo,dDo,cDo,Bb,Lbe,mDo,fDo,Hz,gDo,hDo,uDo,Ib,ybe,pDo,_Do,Jz,bDo,vDo,FDo,Nb,TDo,xbe,MDo,EDo,$be,CDo,wDo,qb,Eoo,Ad,jb,kbe,t$,ADo,Sbe,LDo,Coo,Io,a$,yDo,Ld,xDo,Yz,$Do,kDo,Zz,SDo,RDo,PDo,n$,BDo,Rbe,IDo,NDo,qDo,Ft,s$,jDo,Pbe,DDo,GDo,yd,ODo,Bbe,VDo,XDo,Kz,zDo,QDo,WDo,Db,UDo,eo,l$,HDo,Ibe,JDo,YDo,on,ZDo,Nbe,KDo,eGo,qbe,oGo,rGo,jbe,tGo,aGo,nGo,G,Gb,Dbe,sGo,lGo,eQ,iGo,dGo,cGo,Ob,Gbe,mGo,fGo,oQ,gGo,hGo,uGo,Vb,Obe,pGo,_Go,rQ,bGo,vGo,FGo,Xb,Vbe,TGo,MGo,tQ,EGo,CGo,wGo,zb,Xbe,AGo,LGo,aQ,yGo,xGo,$Go,Qb,zbe,kGo,SGo,nQ,RGo,PGo,BGo,Wb,Qbe,IGo,NGo,sQ,qGo,jGo,DGo,Ub,Wbe,GGo,OGo,lQ,VGo,XGo,zGo,Hb,Ube,QGo,WGo,iQ,UGo,HGo,JGo,Jb,Hbe,YGo,ZGo,dQ,KGo,eOo,oOo,Yb,Jbe,rOo,tOo,cQ,aOo,nOo,sOo,Zb,Ybe,lOo,iOo,mQ,dOo,cOo,mOo,Kb,Zbe,fOo,gOo,fQ,hOo,uOo,pOo,e2,Kbe,_Oo,bOo,gQ,vOo,FOo,TOo,o2,e2e,MOo,EOo,hQ,COo,wOo,AOo,r2,o2e,LOo,yOo,uQ,xOo,$Oo,kOo,t2,r2e,SOo,ROo,pQ,POo,BOo,IOo,a2,t2e,NOo,qOo,_Q,jOo,DOo,GOo,n2,a2e,OOo,VOo,bQ,XOo,zOo,QOo,s2,n2e,WOo,UOo,vQ,HOo,JOo,YOo,l2,s2e,ZOo,KOo,FQ,eVo,oVo,rVo,i2,l2e,tVo,aVo,TQ,nVo,sVo,lVo,d2,i2e,iVo,dVo,MQ,cVo,mVo,fVo,c2,d2e,gVo,hVo,EQ,uVo,pVo,_Vo,m2,c2e,bVo,vVo,CQ,FVo,TVo,MVo,f2,m2e,EVo,CVo,wQ,wVo,AVo,LVo,g2,f2e,yVo,xVo,AQ,$Vo,kVo,SVo,h2,g2e,RVo,PVo,LQ,BVo,IVo,NVo,u2,h2e,qVo,jVo,yQ,DVo,GVo,OVo,p2,u2e,VVo,XVo,xQ,zVo,QVo,WVo,_2,p2e,UVo,HVo,$Q,JVo,YVo,ZVo,b2,_2e,KVo,eXo,kQ,oXo,rXo,tXo,v2,b2e,aXo,nXo,SQ,sXo,lXo,iXo,F2,v2e,dXo,cXo,RQ,mXo,fXo,gXo,T2,F2e,hXo,uXo,PQ,pXo,_Xo,bXo,M2,T2e,vXo,FXo,BQ,TXo,MXo,EXo,E2,M2e,CXo,wXo,IQ,AXo,LXo,yXo,C2,E2e,xXo,$Xo,NQ,kXo,SXo,RXo,w2,C2e,PXo,BXo,qQ,IXo,NXo,qXo,A2,w2e,jXo,DXo,jQ,GXo,OXo,VXo,L2,A2e,XXo,zXo,DQ,QXo,WXo,UXo,y2,L2e,HXo,JXo,GQ,YXo,ZXo,KXo,x2,y2e,ezo,ozo,OQ,rzo,tzo,azo,$2,x2e,nzo,szo,VQ,lzo,izo,dzo,k2,$2e,czo,mzo,XQ,fzo,gzo,hzo,S2,k2e,uzo,pzo,zQ,_zo,bzo,vzo,R2,S2e,Fzo,Tzo,QQ,Mzo,Ezo,Czo,P2,R2e,wzo,Azo,WQ,Lzo,yzo,xzo,B2,$zo,P2e,kzo,Szo,B2e,Rzo,Pzo,I2,woo,xd,N2,I2e,i$,Bzo,N2e,Izo,Aoo,No,d$,Nzo,$d,qzo,UQ,jzo,Dzo,HQ,Gzo,Ozo,Vzo,c$,Xzo,q2e,zzo,Qzo,Wzo,Tt,m$,Uzo,j2e,Hzo,Jzo,kd,Yzo,D2e,Zzo,Kzo,JQ,eQo,oQo,rQo,q2,tQo,oo,f$,aQo,G2e,nQo,sQo,rn,lQo,O2e,iQo,dQo,V2e,cQo,mQo,X2e,fQo,gQo,hQo,Q,j2,z2e,uQo,pQo,YQ,_Qo,bQo,vQo,D2,Q2e,FQo,TQo,ZQ,MQo,EQo,CQo,G2,W2e,wQo,AQo,KQ,LQo,yQo,xQo,O2,U2e,$Qo,kQo,eW,SQo,RQo,PQo,V2,H2e,BQo,IQo,oW,NQo,qQo,jQo,X2,J2e,DQo,GQo,rW,OQo,VQo,XQo,z2,Y2e,zQo,QQo,tW,WQo,UQo,HQo,Q2,Z2e,JQo,YQo,aW,ZQo,KQo,eWo,W2,K2e,oWo,rWo,nW,tWo,aWo,nWo,U2,eve,sWo,lWo,sW,iWo,dWo,cWo,H2,ove,mWo,fWo,lW,gWo,hWo,uWo,J2,rve,pWo,_Wo,iW,bWo,vWo,FWo,Y2,tve,TWo,MWo,dW,EWo,CWo,wWo,Z2,ave,AWo,LWo,cW,yWo,xWo,$Wo,K2,nve,kWo,SWo,mW,RWo,PWo,BWo,ev,sve,IWo,NWo,fW,qWo,jWo,DWo,ov,lve,GWo,OWo,gW,VWo,XWo,zWo,rv,ive,QWo,WWo,hW,UWo,HWo,JWo,tv,dve,YWo,ZWo,uW,KWo,eUo,oUo,av,cve,rUo,tUo,pW,aUo,nUo,sUo,nv,mve,lUo,iUo,_W,dUo,cUo,mUo,sv,fve,fUo,gUo,bW,hUo,uUo,pUo,lv,gve,_Uo,bUo,vW,vUo,FUo,TUo,iv,hve,MUo,EUo,FW,CUo,wUo,AUo,dv,uve,LUo,yUo,TW,xUo,$Uo,kUo,cv,pve,SUo,RUo,MW,PUo,BUo,IUo,mv,_ve,NUo,qUo,EW,jUo,DUo,GUo,fv,bve,OUo,VUo,CW,XUo,zUo,QUo,gv,vve,WUo,UUo,wW,HUo,JUo,YUo,hv,Fve,ZUo,KUo,AW,eHo,oHo,rHo,uv,Tve,tHo,aHo,LW,nHo,sHo,lHo,pv,Mve,iHo,dHo,yW,cHo,mHo,fHo,_v,Eve,gHo,hHo,xW,uHo,pHo,_Ho,bv,Cve,bHo,vHo,$W,FHo,THo,MHo,vv,wve,EHo,CHo,kW,wHo,AHo,LHo,Fv,Ave,yHo,xHo,SW,$Ho,kHo,SHo,Tv,Lve,RHo,PHo,RW,BHo,IHo,NHo,Mv,yve,qHo,jHo,PW,DHo,GHo,OHo,Ev,xve,VHo,XHo,BW,zHo,QHo,WHo,Cv,$ve,UHo,HHo,IW,JHo,YHo,ZHo,wv,kve,KHo,eJo,NW,oJo,rJo,tJo,Av,Sve,aJo,nJo,qW,sJo,lJo,iJo,Lv,dJo,Rve,cJo,mJo,Pve,fJo,gJo,yv,Loo,Sd,xv,Bve,g$,hJo,Ive,uJo,yoo,qo,h$,pJo,Rd,_Jo,jW,bJo,vJo,DW,FJo,TJo,MJo,u$,EJo,Nve,CJo,wJo,AJo,Mt,p$,LJo,qve,yJo,xJo,Pd,$Jo,jve,kJo,SJo,GW,RJo,PJo,BJo,$v,IJo,ro,_$,NJo,Dve,qJo,jJo,tn,DJo,Gve,GJo,OJo,Ove,VJo,XJo,Vve,zJo,QJo,WJo,J,kv,Xve,UJo,HJo,OW,JJo,YJo,ZJo,Sv,zve,KJo,eYo,VW,oYo,rYo,tYo,Rv,Qve,aYo,nYo,XW,sYo,lYo,iYo,Pv,Wve,dYo,cYo,zW,mYo,fYo,gYo,Bv,Uve,hYo,uYo,QW,pYo,_Yo,bYo,Iv,Hve,vYo,FYo,WW,TYo,MYo,EYo,Nv,Jve,CYo,wYo,UW,AYo,LYo,yYo,qv,Yve,xYo,$Yo,HW,kYo,SYo,RYo,jv,Zve,PYo,BYo,JW,IYo,NYo,qYo,Dv,Kve,jYo,DYo,YW,GYo,OYo,VYo,Gv,eFe,XYo,zYo,ZW,QYo,WYo,UYo,Ov,oFe,HYo,JYo,KW,YYo,ZYo,KYo,Vv,rFe,eZo,oZo,eU,rZo,tZo,aZo,Xv,tFe,nZo,sZo,oU,lZo,iZo,dZo,zv,aFe,cZo,mZo,rU,fZo,gZo,hZo,Qv,nFe,uZo,pZo,tU,_Zo,bZo,vZo,Wv,sFe,FZo,TZo,aU,MZo,EZo,CZo,Uv,lFe,wZo,AZo,nU,LZo,yZo,xZo,Hv,iFe,$Zo,kZo,sU,SZo,RZo,PZo,Jv,dFe,BZo,IZo,lU,NZo,qZo,jZo,Yv,cFe,DZo,GZo,iU,OZo,VZo,XZo,Zv,mFe,zZo,QZo,dU,WZo,UZo,HZo,Kv,fFe,JZo,YZo,cU,ZZo,KZo,eKo,eF,gFe,oKo,rKo,mU,tKo,aKo,nKo,oF,hFe,sKo,lKo,fU,iKo,dKo,cKo,rF,uFe,mKo,fKo,gU,gKo,hKo,uKo,tF,pFe,pKo,_Ko,hU,bKo,vKo,FKo,aF,_Fe,TKo,MKo,uU,EKo,CKo,wKo,nF,bFe,AKo,LKo,pU,yKo,xKo,$Ko,sF,vFe,kKo,SKo,_U,RKo,PKo,BKo,lF,FFe,IKo,NKo,bU,qKo,jKo,DKo,iF,TFe,GKo,OKo,vU,VKo,XKo,zKo,dF,MFe,QKo,WKo,FU,UKo,HKo,JKo,cF,EFe,YKo,ZKo,TU,KKo,eer,oer,mF,CFe,rer,ter,wFe,aer,ner,ser,fF,AFe,ler,ier,MU,der,cer,mer,gF,LFe,fer,ger,EU,her,uer,per,hF,yFe,_er,ber,CU,ver,Fer,Ter,uF,xFe,Mer,Eer,wU,Cer,wer,Aer,pF,Ler,$Fe,yer,xer,kFe,$er,ker,_F,xoo,Bd,bF,SFe,b$,Ser,RFe,Rer,$oo,jo,v$,Per,Id,Ber,AU,Ier,Ner,LU,qer,jer,Der,F$,Ger,PFe,Oer,Ver,Xer,Et,T$,zer,BFe,Qer,Wer,Nd,Uer,IFe,Her,Jer,yU,Yer,Zer,Ker,vF,eor,to,M$,oor,NFe,ror,tor,an,aor,qFe,nor,sor,jFe,lor,ior,DFe,dor,cor,mor,fe,FF,GFe,gor,hor,xU,uor,por,_or,TF,OFe,bor,vor,$U,For,Tor,Mor,MF,VFe,Eor,Cor,kU,wor,Aor,Lor,EF,XFe,yor,xor,SU,$or,kor,Sor,CF,zFe,Ror,Por,RU,Bor,Ior,Nor,wF,QFe,qor,jor,PU,Dor,Gor,Oor,AF,WFe,Vor,Xor,BU,zor,Qor,Wor,LF,UFe,Uor,Hor,IU,Jor,Yor,Zor,yF,HFe,Kor,err,NU,orr,rrr,trr,xF,JFe,arr,nrr,qU,srr,lrr,irr,$F,YFe,drr,crr,jU,mrr,frr,grr,kF,ZFe,hrr,urr,DU,prr,_rr,brr,SF,KFe,vrr,Frr,GU,Trr,Mrr,Err,RF,eTe,Crr,wrr,OU,Arr,Lrr,yrr,PF,oTe,xrr,$rr,VU,krr,Srr,Rrr,BF,rTe,Prr,Brr,XU,Irr,Nrr,qrr,IF,tTe,jrr,Drr,zU,Grr,Orr,Vrr,NF,aTe,Xrr,zrr,QU,Qrr,Wrr,Urr,qF,nTe,Hrr,Jrr,WU,Yrr,Zrr,Krr,jF,sTe,etr,otr,UU,rtr,ttr,atr,DF,ntr,lTe,str,ltr,iTe,itr,dtr,GF,koo,qd,OF,dTe,E$,ctr,cTe,mtr,Soo,Do,C$,ftr,jd,gtr,HU,htr,utr,JU,ptr,_tr,btr,w$,vtr,mTe,Ftr,Ttr,Mtr,Ct,A$,Etr,fTe,Ctr,wtr,Dd,Atr,gTe,Ltr,ytr,YU,xtr,$tr,ktr,VF,Str,ao,L$,Rtr,hTe,Ptr,Btr,nn,Itr,uTe,Ntr,qtr,pTe,jtr,Dtr,_Te,Gtr,Otr,Vtr,N,XF,bTe,Xtr,ztr,ZU,Qtr,Wtr,Utr,zF,vTe,Htr,Jtr,KU,Ytr,Ztr,Ktr,QF,FTe,ear,oar,eH,rar,tar,aar,WF,TTe,nar,sar,oH,lar,iar,dar,UF,MTe,car,mar,rH,far,gar,har,HF,ETe,uar,par,tH,_ar,bar,Far,JF,CTe,Tar,Mar,aH,Ear,Car,war,YF,wTe,Aar,Lar,nH,yar,xar,$ar,ZF,ATe,kar,Sar,sH,Rar,Par,Bar,KF,LTe,Iar,Nar,lH,qar,jar,Dar,eT,yTe,Gar,Oar,iH,Var,Xar,zar,oT,xTe,Qar,War,dH,Uar,Har,Jar,rT,$Te,Yar,Zar,cH,Kar,enr,onr,tT,kTe,rnr,tnr,mH,anr,nnr,snr,aT,STe,lnr,inr,fH,dnr,cnr,mnr,nT,RTe,fnr,gnr,gH,hnr,unr,pnr,sT,PTe,_nr,bnr,hH,vnr,Fnr,Tnr,lT,BTe,Mnr,Enr,uH,Cnr,wnr,Anr,iT,ITe,Lnr,ynr,pH,xnr,$nr,knr,dT,NTe,Snr,Rnr,_H,Pnr,Bnr,Inr,cT,qTe,Nnr,qnr,bH,jnr,Dnr,Gnr,mT,jTe,Onr,Vnr,vH,Xnr,znr,Qnr,fT,DTe,Wnr,Unr,FH,Hnr,Jnr,Ynr,gT,GTe,Znr,Knr,TH,esr,osr,rsr,hT,OTe,tsr,asr,MH,nsr,ssr,lsr,uT,VTe,isr,dsr,EH,csr,msr,fsr,pT,XTe,gsr,hsr,CH,usr,psr,_sr,_T,zTe,bsr,vsr,wH,Fsr,Tsr,Msr,bT,QTe,Esr,Csr,AH,wsr,Asr,Lsr,vT,WTe,ysr,xsr,LH,$sr,ksr,Ssr,FT,UTe,Rsr,Psr,yH,Bsr,Isr,Nsr,TT,HTe,qsr,jsr,xH,Dsr,Gsr,Osr,MT,JTe,Vsr,Xsr,$H,zsr,Qsr,Wsr,ET,YTe,Usr,Hsr,kH,Jsr,Ysr,Zsr,CT,ZTe,Ksr,elr,SH,olr,rlr,tlr,wT,KTe,alr,nlr,RH,slr,llr,ilr,AT,eMe,dlr,clr,PH,mlr,flr,glr,LT,oMe,hlr,ulr,BH,plr,_lr,blr,yT,rMe,vlr,Flr,IH,Tlr,Mlr,Elr,xT,tMe,Clr,wlr,NH,Alr,Llr,ylr,$T,aMe,xlr,$lr,qH,klr,Slr,Rlr,kT,nMe,Plr,Blr,jH,Ilr,Nlr,qlr,ST,sMe,jlr,Dlr,DH,Glr,Olr,Vlr,RT,lMe,Xlr,zlr,GH,Qlr,Wlr,Ulr,PT,iMe,Hlr,Jlr,OH,Ylr,Zlr,Klr,BT,dMe,eir,oir,VH,rir,tir,air,IT,cMe,nir,sir,XH,lir,iir,dir,NT,mMe,cir,mir,zH,fir,gir,hir,qT,fMe,uir,pir,QH,_ir,bir,vir,jT,gMe,Fir,Tir,WH,Mir,Eir,Cir,DT,hMe,wir,Air,UH,Lir,yir,xir,GT,uMe,$ir,kir,HH,Sir,Rir,Pir,OT,pMe,Bir,Iir,JH,Nir,qir,jir,VT,_Me,Dir,Gir,YH,Oir,Vir,Xir,XT,bMe,zir,Qir,ZH,Wir,Uir,Hir,zT,Jir,vMe,Yir,Zir,FMe,Kir,edr,QT,Roo,Gd,WT,TMe,y$,odr,MMe,rdr,Poo,Go,x$,tdr,Od,adr,KH,ndr,sdr,eJ,ldr,idr,ddr,$$,cdr,EMe,mdr,fdr,gdr,wt,k$,hdr,CMe,udr,pdr,Vd,_dr,wMe,bdr,vdr,oJ,Fdr,Tdr,Mdr,UT,Edr,no,S$,Cdr,AMe,wdr,Adr,sn,Ldr,LMe,ydr,xdr,yMe,$dr,kdr,xMe,Sdr,Rdr,Pdr,K,HT,$Me,Bdr,Idr,rJ,Ndr,qdr,jdr,JT,kMe,Ddr,Gdr,tJ,Odr,Vdr,Xdr,YT,SMe,zdr,Qdr,aJ,Wdr,Udr,Hdr,ZT,RMe,Jdr,Ydr,nJ,Zdr,Kdr,ecr,KT,PMe,ocr,rcr,sJ,tcr,acr,ncr,eM,BMe,scr,lcr,lJ,icr,dcr,ccr,oM,IMe,mcr,fcr,iJ,gcr,hcr,ucr,rM,NMe,pcr,_cr,dJ,bcr,vcr,Fcr,tM,qMe,Tcr,Mcr,cJ,Ecr,Ccr,wcr,aM,jMe,Acr,Lcr,mJ,ycr,xcr,$cr,nM,DMe,kcr,Scr,fJ,Rcr,Pcr,Bcr,sM,GMe,Icr,Ncr,gJ,qcr,jcr,Dcr,lM,OMe,Gcr,Ocr,hJ,Vcr,Xcr,zcr,iM,VMe,Qcr,Wcr,uJ,Ucr,Hcr,Jcr,dM,XMe,Ycr,Zcr,pJ,Kcr,emr,omr,cM,zMe,rmr,tmr,_J,amr,nmr,smr,mM,QMe,lmr,imr,bJ,dmr,cmr,mmr,fM,WMe,fmr,gmr,vJ,hmr,umr,pmr,gM,UMe,_mr,bmr,FJ,vmr,Fmr,Tmr,hM,HMe,Mmr,Emr,TJ,Cmr,wmr,Amr,uM,JMe,Lmr,ymr,MJ,xmr,$mr,kmr,pM,YMe,Smr,Rmr,EJ,Pmr,Bmr,Imr,_M,ZMe,Nmr,qmr,CJ,jmr,Dmr,Gmr,bM,KMe,Omr,Vmr,wJ,Xmr,zmr,Qmr,vM,eEe,Wmr,Umr,AJ,Hmr,Jmr,Ymr,FM,oEe,Zmr,Kmr,LJ,efr,ofr,rfr,TM,rEe,tfr,afr,yJ,nfr,sfr,lfr,MM,tEe,ifr,dfr,xJ,cfr,mfr,ffr,EM,aEe,gfr,hfr,$J,ufr,pfr,_fr,CM,nEe,bfr,vfr,kJ,Ffr,Tfr,Mfr,wM,sEe,Efr,Cfr,SJ,wfr,Afr,Lfr,AM,lEe,yfr,xfr,RJ,$fr,kfr,Sfr,LM,Rfr,iEe,Pfr,Bfr,dEe,Ifr,Nfr,yM,Boo,Xd,xM,cEe,R$,qfr,mEe,jfr,Ioo,Oo,P$,Dfr,zd,Gfr,PJ,Ofr,Vfr,BJ,Xfr,zfr,Qfr,B$,Wfr,fEe,Ufr,Hfr,Jfr,At,I$,Yfr,gEe,Zfr,Kfr,Qd,egr,hEe,ogr,rgr,IJ,tgr,agr,ngr,$M,sgr,so,N$,lgr,uEe,igr,dgr,ln,cgr,pEe,mgr,fgr,_Ee,ggr,hgr,bEe,ugr,pgr,_gr,Ue,kM,vEe,bgr,vgr,NJ,Fgr,Tgr,Mgr,SM,FEe,Egr,Cgr,qJ,wgr,Agr,Lgr,RM,TEe,ygr,xgr,jJ,$gr,kgr,Sgr,PM,MEe,Rgr,Pgr,DJ,Bgr,Igr,Ngr,BM,EEe,qgr,jgr,GJ,Dgr,Ggr,Ogr,IM,CEe,Vgr,Xgr,OJ,zgr,Qgr,Wgr,NM,wEe,Ugr,Hgr,VJ,Jgr,Ygr,Zgr,qM,Kgr,AEe,ehr,ohr,LEe,rhr,thr,jM,Noo,Wd,DM,yEe,q$,ahr,xEe,nhr,qoo,Vo,j$,shr,Ud,lhr,XJ,ihr,dhr,zJ,chr,mhr,fhr,D$,ghr,$Ee,hhr,uhr,phr,Lt,G$,_hr,kEe,bhr,vhr,Hd,Fhr,SEe,Thr,Mhr,QJ,Ehr,Chr,whr,GM,Ahr,lo,O$,Lhr,REe,yhr,xhr,dn,$hr,PEe,khr,Shr,BEe,Rhr,Phr,IEe,Bhr,Ihr,Nhr,H,OM,NEe,qhr,jhr,WJ,Dhr,Ghr,Ohr,VM,qEe,Vhr,Xhr,UJ,zhr,Qhr,Whr,XM,jEe,Uhr,Hhr,HJ,Jhr,Yhr,Zhr,zM,DEe,Khr,eur,JJ,our,rur,tur,QM,GEe,aur,nur,YJ,sur,lur,iur,WM,OEe,dur,cur,ZJ,mur,fur,gur,UM,VEe,hur,uur,KJ,pur,_ur,bur,HM,XEe,vur,Fur,eY,Tur,Mur,Eur,JM,zEe,Cur,wur,oY,Aur,Lur,yur,YM,QEe,xur,$ur,rY,kur,Sur,Rur,ZM,WEe,Pur,Bur,tY,Iur,Nur,qur,KM,UEe,jur,Dur,aY,Gur,Our,Vur,eE,HEe,Xur,zur,nY,Qur,Wur,Uur,oE,JEe,Hur,Jur,sY,Yur,Zur,Kur,rE,YEe,epr,opr,lY,rpr,tpr,apr,tE,ZEe,npr,spr,iY,lpr,ipr,dpr,aE,KEe,cpr,mpr,dY,fpr,gpr,hpr,nE,e4e,upr,ppr,cY,_pr,bpr,vpr,sE,o4e,Fpr,Tpr,mY,Mpr,Epr,Cpr,lE,r4e,wpr,Apr,fY,Lpr,ypr,xpr,iE,t4e,$pr,kpr,gY,Spr,Rpr,Ppr,dE,a4e,Bpr,Ipr,hY,Npr,qpr,jpr,cE,n4e,Dpr,Gpr,uY,Opr,Vpr,Xpr,mE,s4e,zpr,Qpr,pY,Wpr,Upr,Hpr,fE,l4e,Jpr,Ypr,_Y,Zpr,Kpr,e_r,gE,i4e,o_r,r_r,bY,t_r,a_r,n_r,hE,d4e,s_r,l_r,vY,i_r,d_r,c_r,uE,c4e,m_r,f_r,FY,g_r,h_r,u_r,pE,m4e,p_r,__r,TY,b_r,v_r,F_r,_E,f4e,T_r,M_r,MY,E_r,C_r,w_r,bE,g4e,A_r,L_r,EY,y_r,x_r,$_r,vE,h4e,k_r,S_r,CY,R_r,P_r,B_r,FE,u4e,I_r,N_r,wY,q_r,j_r,D_r,TE,p4e,G_r,O_r,AY,V_r,X_r,z_r,ME,_4e,Q_r,W_r,LY,U_r,H_r,J_r,EE,b4e,Y_r,Z_r,yY,K_r,e1r,o1r,CE,v4e,r1r,t1r,xY,a1r,n1r,s1r,wE,F4e,l1r,i1r,$Y,d1r,c1r,m1r,AE,T4e,f1r,g1r,kY,h1r,u1r,p1r,LE,M4e,_1r,b1r,SY,v1r,F1r,T1r,yE,M1r,E4e,E1r,C1r,C4e,w1r,A1r,xE,joo,Jd,$E,w4e,V$,L1r,A4e,y1r,Doo,Xo,X$,x1r,Yd,$1r,RY,k1r,S1r,PY,R1r,P1r,B1r,z$,I1r,L4e,N1r,q1r,j1r,yt,Q$,D1r,y4e,G1r,O1r,Zd,V1r,x4e,X1r,z1r,BY,Q1r,W1r,U1r,kE,H1r,io,W$,J1r,$4e,Y1r,Z1r,cn,K1r,k4e,ebr,obr,S4e,rbr,tbr,R4e,abr,nbr,sbr,O,SE,P4e,lbr,ibr,IY,dbr,cbr,mbr,RE,B4e,fbr,gbr,NY,hbr,ubr,pbr,PE,I4e,_br,bbr,qY,vbr,Fbr,Tbr,BE,N4e,Mbr,Ebr,jY,Cbr,wbr,Abr,IE,q4e,Lbr,ybr,DY,xbr,$br,kbr,NE,j4e,Sbr,Rbr,GY,Pbr,Bbr,Ibr,qE,D4e,Nbr,qbr,OY,jbr,Dbr,Gbr,jE,G4e,Obr,Vbr,VY,Xbr,zbr,Qbr,DE,O4e,Wbr,Ubr,XY,Hbr,Jbr,Ybr,GE,V4e,Zbr,Kbr,zY,e2r,o2r,r2r,OE,X4e,t2r,a2r,QY,n2r,s2r,l2r,VE,z4e,i2r,d2r,WY,c2r,m2r,f2r,XE,Q4e,g2r,h2r,UY,u2r,p2r,_2r,zE,W4e,b2r,v2r,HY,F2r,T2r,M2r,QE,U4e,E2r,C2r,JY,w2r,A2r,L2r,WE,H4e,y2r,x2r,YY,$2r,k2r,S2r,UE,J4e,R2r,P2r,ZY,B2r,I2r,N2r,HE,Y4e,q2r,j2r,KY,D2r,G2r,O2r,JE,Z4e,V2r,X2r,eZ,z2r,Q2r,W2r,YE,K4e,U2r,H2r,oZ,J2r,Y2r,Z2r,ZE,eCe,K2r,evr,rZ,ovr,rvr,tvr,KE,oCe,avr,nvr,tZ,svr,lvr,ivr,e4,rCe,dvr,cvr,aZ,mvr,fvr,gvr,o4,tCe,hvr,uvr,nZ,pvr,_vr,bvr,r4,aCe,vvr,Fvr,sZ,Tvr,Mvr,Evr,t4,nCe,Cvr,wvr,lZ,Avr,Lvr,yvr,a4,sCe,xvr,$vr,iZ,kvr,Svr,Rvr,n4,lCe,Pvr,Bvr,dZ,Ivr,Nvr,qvr,s4,iCe,jvr,Dvr,cZ,Gvr,Ovr,Vvr,l4,dCe,Xvr,zvr,mZ,Qvr,Wvr,Uvr,i4,cCe,Hvr,Jvr,fZ,Yvr,Zvr,Kvr,d4,mCe,eFr,oFr,gZ,rFr,tFr,aFr,c4,fCe,nFr,sFr,hZ,lFr,iFr,dFr,m4,gCe,cFr,mFr,uZ,fFr,gFr,hFr,f4,hCe,uFr,pFr,pZ,_Fr,bFr,vFr,g4,uCe,FFr,TFr,_Z,MFr,EFr,CFr,h4,pCe,wFr,AFr,bZ,LFr,yFr,xFr,u4,_Ce,$Fr,kFr,vZ,SFr,RFr,PFr,p4,bCe,BFr,IFr,FZ,NFr,qFr,jFr,_4,vCe,DFr,GFr,TZ,OFr,VFr,XFr,b4,FCe,zFr,QFr,MZ,WFr,UFr,HFr,v4,TCe,JFr,YFr,EZ,ZFr,KFr,eTr,F4,MCe,oTr,rTr,CZ,tTr,aTr,nTr,T4,ECe,sTr,lTr,wZ,iTr,dTr,cTr,M4,CCe,mTr,fTr,AZ,gTr,hTr,uTr,E4,wCe,pTr,_Tr,LZ,bTr,vTr,FTr,C4,ACe,TTr,MTr,yZ,ETr,CTr,wTr,w4,ATr,LCe,LTr,yTr,yCe,xTr,$Tr,A4,Goo,Kd,L4,xCe,U$,kTr,$Ce,STr,Ooo,zo,H$,RTr,ec,PTr,xZ,BTr,ITr,$Z,NTr,qTr,jTr,J$,DTr,kCe,GTr,OTr,VTr,xt,Y$,XTr,SCe,zTr,QTr,oc,WTr,RCe,UTr,HTr,kZ,JTr,YTr,ZTr,y4,KTr,co,Z$,eMr,PCe,oMr,rMr,mn,tMr,BCe,aMr,nMr,ICe,sMr,lMr,NCe,iMr,dMr,cMr,qCe,x4,jCe,mMr,fMr,SZ,gMr,hMr,uMr,$4,pMr,DCe,_Mr,bMr,GCe,vMr,FMr,k4,Voo,rc,S4,OCe,K$,TMr,VCe,MMr,Xoo,Qo,ek,EMr,tc,CMr,RZ,wMr,AMr,PZ,LMr,yMr,xMr,ok,$Mr,XCe,kMr,SMr,RMr,$t,rk,PMr,zCe,BMr,IMr,ac,NMr,QCe,qMr,jMr,BZ,DMr,GMr,OMr,R4,VMr,mo,tk,XMr,WCe,zMr,QMr,fn,WMr,UCe,UMr,HMr,HCe,JMr,YMr,JCe,ZMr,KMr,eEr,nc,P4,YCe,oEr,rEr,IZ,tEr,aEr,nEr,B4,ZCe,sEr,lEr,NZ,iEr,dEr,cEr,I4,KCe,mEr,fEr,qZ,gEr,hEr,uEr,N4,pEr,e3e,_Er,bEr,o3e,vEr,FEr,q4,zoo,sc,j4,r3e,ak,TEr,t3e,MEr,Qoo,Wo,nk,EEr,lc,CEr,jZ,wEr,AEr,DZ,LEr,yEr,xEr,sk,$Er,a3e,kEr,SEr,REr,kt,lk,PEr,n3e,BEr,IEr,ic,NEr,s3e,qEr,jEr,GZ,DEr,GEr,OEr,D4,VEr,fo,ik,XEr,l3e,zEr,QEr,gn,WEr,i3e,UEr,HEr,d3e,JEr,YEr,c3e,ZEr,KEr,e4r,be,G4,m3e,o4r,r4r,OZ,t4r,a4r,n4r,O4,f3e,s4r,l4r,VZ,i4r,d4r,c4r,V4,g3e,m4r,f4r,XZ,g4r,h4r,u4r,X4,h3e,p4r,_4r,zZ,b4r,v4r,F4r,El,u3e,T4r,M4r,QZ,E4r,C4r,WZ,w4r,A4r,L4r,z4,p3e,y4r,x4r,UZ,$4r,k4r,S4r,Cl,_3e,R4r,P4r,HZ,B4r,I4r,JZ,N4r,q4r,j4r,Q4,b3e,D4r,G4r,YZ,O4r,V4r,X4r,St,v3e,z4r,Q4r,ZZ,W4r,U4r,KZ,H4r,J4r,eK,Y4r,Z4r,K4r,W4,F3e,eCr,oCr,oK,rCr,tCr,aCr,U4,T3e,nCr,sCr,rK,lCr,iCr,dCr,H4,M3e,cCr,mCr,tK,fCr,gCr,hCr,J4,E3e,uCr,pCr,aK,_Cr,bCr,vCr,Y4,C3e,FCr,TCr,nK,MCr,ECr,CCr,Z4,w3e,wCr,ACr,sK,LCr,yCr,xCr,K4,A3e,$Cr,kCr,lK,SCr,RCr,PCr,eC,L3e,BCr,ICr,iK,NCr,qCr,jCr,oC,y3e,DCr,GCr,dK,OCr,VCr,XCr,rC,zCr,x3e,QCr,WCr,$3e,UCr,HCr,tC,Woo,dc,aC,k3e,dk,JCr,S3e,YCr,Uoo,Uo,ck,ZCr,cc,KCr,cK,e3r,o3r,mK,r3r,t3r,a3r,mk,n3r,R3e,s3r,l3r,i3r,Rt,fk,d3r,P3e,c3r,m3r,mc,f3r,B3e,g3r,h3r,fK,u3r,p3r,_3r,nC,b3r,go,gk,v3r,I3e,F3r,T3r,hn,M3r,N3e,E3r,C3r,q3e,w3r,A3r,j3e,L3r,y3r,x3r,D3e,sC,G3e,$3r,k3r,gK,S3r,R3r,P3r,lC,B3r,O3e,I3r,N3r,V3e,q3r,j3r,iC,Hoo,fc,dC,X3e,hk,D3r,z3e,G3r,Joo,Ho,uk,O3r,gc,V3r,hK,X3r,z3r,uK,Q3r,W3r,U3r,pk,H3r,Q3e,J3r,Y3r,Z3r,Pt,_k,K3r,W3e,e5r,o5r,hc,r5r,U3e,t5r,a5r,pK,n5r,s5r,l5r,cC,i5r,ho,bk,d5r,H3e,c5r,m5r,un,f5r,J3e,g5r,h5r,Y3e,u5r,p5r,Z3e,_5r,b5r,v5r,K3e,mC,e5e,F5r,T5r,_K,M5r,E5r,C5r,fC,w5r,o5e,A5r,L5r,r5e,y5r,x5r,gC,Yoo,uc,hC,t5e,vk,$5r,a5e,k5r,Zoo,Jo,Fk,S5r,pc,R5r,bK,P5r,B5r,vK,I5r,N5r,q5r,Tk,j5r,n5e,D5r,G5r,O5r,Bt,Mk,V5r,s5e,X5r,z5r,_c,Q5r,l5e,W5r,U5r,FK,H5r,J5r,Y5r,uC,Z5r,uo,Ek,K5r,i5e,e0r,o0r,pn,r0r,d5e,t0r,a0r,c5e,n0r,s0r,m5e,l0r,i0r,d0r,f5e,pC,g5e,c0r,m0r,TK,f0r,g0r,h0r,_C,u0r,h5e,p0r,_0r,u5e,b0r,v0r,bC,Koo,bc,vC,p5e,Ck,F0r,_5e,T0r,ero,Yo,wk,M0r,vc,E0r,MK,C0r,w0r,EK,A0r,L0r,y0r,Ak,x0r,b5e,$0r,k0r,S0r,It,Lk,R0r,v5e,P0r,B0r,Fc,I0r,F5e,N0r,q0r,CK,j0r,D0r,G0r,FC,O0r,po,yk,V0r,T5e,X0r,z0r,_n,Q0r,M5e,W0r,U0r,E5e,H0r,J0r,C5e,Y0r,Z0r,K0r,Pe,TC,w5e,ewr,owr,wK,rwr,twr,awr,MC,A5e,nwr,swr,AK,lwr,iwr,dwr,EC,L5e,cwr,mwr,LK,fwr,gwr,hwr,CC,y5e,uwr,pwr,yK,_wr,bwr,vwr,wC,x5e,Fwr,Twr,xK,Mwr,Ewr,Cwr,AC,$5e,wwr,Awr,$K,Lwr,ywr,xwr,LC,k5e,$wr,kwr,kK,Swr,Rwr,Pwr,yC,S5e,Bwr,Iwr,SK,Nwr,qwr,jwr,xC,R5e,Dwr,Gwr,RK,Owr,Vwr,Xwr,$C,zwr,P5e,Qwr,Wwr,B5e,Uwr,Hwr,kC,oro,Tc,SC,I5e,xk,Jwr,N5e,Ywr,rro,Zo,$k,Zwr,Mc,Kwr,PK,eAr,oAr,BK,rAr,tAr,aAr,kk,nAr,q5e,sAr,lAr,iAr,Nt,Sk,dAr,j5e,cAr,mAr,Ec,fAr,D5e,gAr,hAr,IK,uAr,pAr,_Ar,RC,bAr,_o,Rk,vAr,G5e,FAr,TAr,bn,MAr,O5e,EAr,CAr,V5e,wAr,AAr,X5e,LAr,yAr,xAr,gt,PC,z5e,$Ar,kAr,NK,SAr,RAr,PAr,BC,Q5e,BAr,IAr,qK,NAr,qAr,jAr,IC,W5e,DAr,GAr,jK,OAr,VAr,XAr,NC,U5e,zAr,QAr,DK,WAr,UAr,HAr,qC,H5e,JAr,YAr,GK,ZAr,KAr,e6r,jC,o6r,J5e,r6r,t6r,Y5e,a6r,n6r,DC,tro,Cc,GC,Z5e,Pk,s6r,K5e,l6r,aro,Ko,Bk,i6r,wc,d6r,OK,c6r,m6r,VK,f6r,g6r,h6r,Ik,u6r,e0e,p6r,_6r,b6r,qt,Nk,v6r,o0e,F6r,T6r,Ac,M6r,r0e,E6r,C6r,XK,w6r,A6r,L6r,OC,y6r,bo,qk,x6r,t0e,$6r,k6r,vn,S6r,a0e,R6r,P6r,n0e,B6r,I6r,s0e,N6r,q6r,j6r,Le,VC,l0e,D6r,G6r,zK,O6r,V6r,X6r,XC,i0e,z6r,Q6r,QK,W6r,U6r,H6r,zC,d0e,J6r,Y6r,WK,Z6r,K6r,e7r,QC,c0e,o7r,r7r,UK,t7r,a7r,n7r,WC,m0e,s7r,l7r,HK,i7r,d7r,c7r,UC,f0e,m7r,f7r,JK,g7r,h7r,u7r,HC,g0e,p7r,_7r,YK,b7r,v7r,F7r,JC,h0e,T7r,M7r,ZK,E7r,C7r,w7r,YC,u0e,A7r,L7r,KK,y7r,x7r,$7r,ZC,p0e,k7r,S7r,eee,R7r,P7r,B7r,KC,I7r,_0e,N7r,q7r,b0e,j7r,D7r,e3,nro,Lc,o3,v0e,jk,G7r,F0e,O7r,sro,er,Dk,V7r,yc,X7r,oee,z7r,Q7r,ree,W7r,U7r,H7r,Gk,J7r,T0e,Y7r,Z7r,K7r,jt,Ok,eLr,M0e,oLr,rLr,xc,tLr,E0e,aLr,nLr,tee,sLr,lLr,iLr,r3,dLr,vo,Vk,cLr,C0e,mLr,fLr,Fn,gLr,w0e,hLr,uLr,A0e,pLr,_Lr,L0e,bLr,vLr,FLr,$c,t3,y0e,TLr,MLr,aee,ELr,CLr,wLr,a3,x0e,ALr,LLr,nee,yLr,xLr,$Lr,n3,$0e,kLr,SLr,see,RLr,PLr,BLr,s3,ILr,k0e,NLr,qLr,S0e,jLr,DLr,l3,lro,kc,i3,R0e,Xk,GLr,P0e,OLr,iro,or,zk,VLr,Sc,XLr,lee,zLr,QLr,iee,WLr,ULr,HLr,Qk,JLr,B0e,YLr,ZLr,KLr,Dt,Wk,eyr,I0e,oyr,ryr,Rc,tyr,N0e,ayr,nyr,dee,syr,lyr,iyr,d3,dyr,Fo,Uk,cyr,q0e,myr,fyr,Tn,gyr,j0e,hyr,uyr,D0e,pyr,_yr,G0e,byr,vyr,Fyr,ht,c3,O0e,Tyr,Myr,cee,Eyr,Cyr,wyr,m3,V0e,Ayr,Lyr,mee,yyr,xyr,$yr,f3,X0e,kyr,Syr,fee,Ryr,Pyr,Byr,g3,z0e,Iyr,Nyr,gee,qyr,jyr,Dyr,h3,Q0e,Gyr,Oyr,hee,Vyr,Xyr,zyr,u3,Qyr,W0e,Wyr,Uyr,U0e,Hyr,Jyr,p3,dro,Pc,_3,H0e,Hk,Yyr,J0e,Zyr,cro,rr,Jk,Kyr,Bc,e8r,uee,o8r,r8r,pee,t8r,a8r,n8r,Yk,s8r,Y0e,l8r,i8r,d8r,Gt,Zk,c8r,Z0e,m8r,f8r,Ic,g8r,K0e,h8r,u8r,_ee,p8r,_8r,b8r,b3,v8r,To,Kk,F8r,ewe,T8r,M8r,Mn,E8r,owe,C8r,w8r,rwe,A8r,L8r,twe,y8r,x8r,$8r,En,v3,awe,k8r,S8r,bee,R8r,P8r,B8r,F3,nwe,I8r,N8r,vee,q8r,j8r,D8r,T3,swe,G8r,O8r,Fee,V8r,X8r,z8r,M3,lwe,Q8r,W8r,Tee,U8r,H8r,J8r,E3,Y8r,iwe,Z8r,K8r,dwe,e9r,o9r,C3,mro,Nc,w3,cwe,eS,r9r,mwe,t9r,fro,tr,oS,a9r,qc,n9r,Mee,s9r,l9r,Eee,i9r,d9r,c9r,rS,m9r,fwe,f9r,g9r,h9r,Ot,tS,u9r,gwe,p9r,_9r,jc,b9r,hwe,v9r,F9r,Cee,T9r,M9r,E9r,A3,C9r,Mo,aS,w9r,uwe,A9r,L9r,Cn,y9r,pwe,x9r,$9r,_we,k9r,S9r,bwe,R9r,P9r,B9r,wn,L3,vwe,I9r,N9r,wee,q9r,j9r,D9r,y3,Fwe,G9r,O9r,Aee,V9r,X9r,z9r,x3,Twe,Q9r,W9r,Lee,U9r,H9r,J9r,$3,Mwe,Y9r,Z9r,yee,K9r,exr,oxr,k3,rxr,Ewe,txr,axr,Cwe,nxr,sxr,S3,gro,Dc,R3,wwe,nS,lxr,Awe,ixr,hro,ar,sS,dxr,Gc,cxr,xee,mxr,fxr,$ee,gxr,hxr,uxr,lS,pxr,Lwe,_xr,bxr,vxr,Vt,iS,Fxr,ywe,Txr,Mxr,Oc,Exr,xwe,Cxr,wxr,kee,Axr,Lxr,yxr,P3,xxr,Eo,dS,$xr,$we,kxr,Sxr,An,Rxr,kwe,Pxr,Bxr,Swe,Ixr,Nxr,Rwe,qxr,jxr,Dxr,Pwe,B3,Bwe,Gxr,Oxr,See,Vxr,Xxr,zxr,I3,Qxr,Iwe,Wxr,Uxr,Nwe,Hxr,Jxr,N3,uro,Vc,q3,qwe,cS,Yxr,jwe,Zxr,pro,nr,mS,Kxr,Xc,e$r,Ree,o$r,r$r,Pee,t$r,a$r,n$r,fS,s$r,Dwe,l$r,i$r,d$r,Xt,gS,c$r,Gwe,m$r,f$r,zc,g$r,Owe,h$r,u$r,Bee,p$r,_$r,b$r,j3,v$r,Co,hS,F$r,Vwe,T$r,M$r,Ln,E$r,Xwe,C$r,w$r,zwe,A$r,L$r,Qwe,y$r,x$r,$$r,ut,D3,Wwe,k$r,S$r,Iee,R$r,P$r,B$r,G3,Uwe,I$r,N$r,Nee,q$r,j$r,D$r,O3,Hwe,G$r,O$r,qee,V$r,X$r,z$r,V3,Jwe,Q$r,W$r,jee,U$r,H$r,J$r,X3,Ywe,Y$r,Z$r,Dee,K$r,ekr,okr,z3,rkr,Zwe,tkr,akr,Kwe,nkr,skr,Q3,_ro,Qc,W3,eAe,uS,lkr,oAe,ikr,bro,sr,pS,dkr,Wc,ckr,Gee,mkr,fkr,Oee,gkr,hkr,ukr,_S,pkr,rAe,_kr,bkr,vkr,zt,bS,Fkr,tAe,Tkr,Mkr,Uc,Ekr,aAe,Ckr,wkr,Vee,Akr,Lkr,ykr,U3,xkr,wo,vS,$kr,nAe,kkr,Skr,yn,Rkr,sAe,Pkr,Bkr,lAe,Ikr,Nkr,iAe,qkr,jkr,Dkr,dAe,H3,cAe,Gkr,Okr,Xee,Vkr,Xkr,zkr,J3,Qkr,mAe,Wkr,Ukr,fAe,Hkr,Jkr,Y3,vro,Hc,Z3,gAe,FS,Ykr,hAe,Zkr,Fro,lr,TS,Kkr,Jc,eSr,zee,oSr,rSr,Qee,tSr,aSr,nSr,MS,sSr,uAe,lSr,iSr,dSr,Qt,ES,cSr,pAe,mSr,fSr,Yc,gSr,_Ae,hSr,uSr,Wee,pSr,_Sr,bSr,K3,vSr,Ao,CS,FSr,bAe,TSr,MSr,xn,ESr,vAe,CSr,wSr,FAe,ASr,LSr,TAe,ySr,xSr,$Sr,MAe,e5,EAe,kSr,SSr,Uee,RSr,PSr,BSr,o5,ISr,CAe,NSr,qSr,wAe,jSr,DSr,r5,Tro,Zc,t5,AAe,wS,GSr,LAe,OSr,Mro,ir,AS,VSr,Kc,XSr,Hee,zSr,QSr,Jee,WSr,USr,HSr,LS,JSr,yAe,YSr,ZSr,KSr,Wt,yS,eRr,xAe,oRr,rRr,em,tRr,$Ae,aRr,nRr,Yee,sRr,lRr,iRr,a5,dRr,qr,xS,cRr,kAe,mRr,fRr,$n,gRr,SAe,hRr,uRr,RAe,pRr,_Rr,PAe,bRr,vRr,FRr,q,n5,BAe,TRr,MRr,Zee,ERr,CRr,wRr,s5,IAe,ARr,LRr,Kee,yRr,xRr,$Rr,l5,NAe,kRr,SRr,eoe,RRr,PRr,BRr,i5,qAe,IRr,NRr,ooe,qRr,jRr,DRr,d5,jAe,GRr,ORr,roe,VRr,XRr,zRr,c5,DAe,QRr,WRr,toe,URr,HRr,JRr,m5,GAe,YRr,ZRr,aoe,KRr,ePr,oPr,f5,OAe,rPr,tPr,noe,aPr,nPr,sPr,g5,VAe,lPr,iPr,soe,dPr,cPr,mPr,h5,XAe,fPr,gPr,loe,hPr,uPr,pPr,u5,zAe,_Pr,bPr,ioe,vPr,FPr,TPr,p5,QAe,MPr,EPr,doe,CPr,wPr,APr,_5,WAe,LPr,yPr,coe,xPr,$Pr,kPr,b5,UAe,SPr,RPr,moe,PPr,BPr,IPr,v5,HAe,NPr,qPr,foe,jPr,DPr,GPr,F5,JAe,OPr,VPr,goe,XPr,zPr,QPr,T5,YAe,WPr,UPr,hoe,HPr,JPr,YPr,M5,ZAe,ZPr,KPr,uoe,eBr,oBr,rBr,wl,KAe,tBr,aBr,poe,nBr,sBr,_oe,lBr,iBr,dBr,E5,e6e,cBr,mBr,boe,fBr,gBr,hBr,C5,o6e,uBr,pBr,voe,_Br,bBr,vBr,w5,r6e,FBr,TBr,Foe,MBr,EBr,CBr,A5,t6e,wBr,ABr,Toe,LBr,yBr,xBr,L5,a6e,$Br,kBr,Moe,SBr,RBr,PBr,y5,n6e,BBr,IBr,Eoe,NBr,qBr,jBr,x5,s6e,DBr,GBr,Coe,OBr,VBr,XBr,$5,l6e,zBr,QBr,woe,WBr,UBr,HBr,k5,i6e,JBr,YBr,Aoe,ZBr,KBr,eIr,S5,d6e,oIr,rIr,Loe,tIr,aIr,nIr,R5,c6e,sIr,lIr,yoe,iIr,dIr,cIr,P5,m6e,mIr,fIr,xoe,gIr,hIr,uIr,B5,f6e,pIr,_Ir,$oe,bIr,vIr,FIr,I5,g6e,TIr,MIr,koe,EIr,CIr,wIr,N5,h6e,AIr,LIr,Soe,yIr,xIr,$Ir,q5,u6e,kIr,SIr,Roe,RIr,PIr,BIr,j5,p6e,IIr,NIr,Poe,qIr,jIr,DIr,D5,_6e,GIr,OIr,Boe,VIr,XIr,zIr,G5,b6e,QIr,WIr,Ioe,UIr,HIr,JIr,O5,v6e,YIr,ZIr,Noe,KIr,eNr,oNr,V5,F6e,rNr,tNr,qoe,aNr,nNr,sNr,X5,T6e,lNr,iNr,joe,dNr,cNr,mNr,z5,M6e,fNr,gNr,Doe,hNr,uNr,pNr,Q5,E6e,_Nr,bNr,Goe,vNr,FNr,TNr,W5,C6e,MNr,ENr,Ooe,CNr,wNr,ANr,U5,w6e,LNr,yNr,Voe,xNr,$Nr,kNr,H5,A6e,SNr,RNr,Xoe,PNr,BNr,INr,J5,L6e,NNr,qNr,zoe,jNr,DNr,GNr,Y5,y6e,ONr,VNr,Qoe,XNr,zNr,QNr,Z5,x6e,WNr,UNr,Woe,HNr,JNr,YNr,K5,$6e,ZNr,KNr,Uoe,eqr,oqr,rqr,e0,k6e,tqr,aqr,Hoe,nqr,sqr,lqr,o0,S6e,iqr,dqr,Joe,cqr,mqr,fqr,r0,R6e,gqr,hqr,Yoe,uqr,pqr,_qr,t0,P6e,bqr,vqr,Zoe,Fqr,Tqr,Mqr,a0,B6e,Eqr,Cqr,Koe,wqr,Aqr,Lqr,n0,Ero,om,s0,I6e,$S,yqr,N6e,xqr,Cro,dr,kS,$qr,rm,kqr,ere,Sqr,Rqr,ore,Pqr,Bqr,Iqr,SS,Nqr,q6e,qqr,jqr,Dqr,Ut,RS,Gqr,j6e,Oqr,Vqr,tm,Xqr,D6e,zqr,Qqr,rre,Wqr,Uqr,Hqr,l0,Jqr,jr,PS,Yqr,G6e,Zqr,Kqr,kn,ejr,O6e,ojr,rjr,V6e,tjr,ajr,X6e,njr,sjr,ljr,le,i0,z6e,ijr,djr,tre,cjr,mjr,fjr,d0,Q6e,gjr,hjr,are,ujr,pjr,_jr,c0,W6e,bjr,vjr,nre,Fjr,Tjr,Mjr,m0,U6e,Ejr,Cjr,sre,wjr,Ajr,Ljr,f0,H6e,yjr,xjr,lre,$jr,kjr,Sjr,g0,J6e,Rjr,Pjr,ire,Bjr,Ijr,Njr,h0,Y6e,qjr,jjr,dre,Djr,Gjr,Ojr,u0,Z6e,Vjr,Xjr,cre,zjr,Qjr,Wjr,p0,K6e,Ujr,Hjr,mre,Jjr,Yjr,Zjr,_0,e7e,Kjr,eDr,fre,oDr,rDr,tDr,b0,o7e,aDr,nDr,gre,sDr,lDr,iDr,v0,r7e,dDr,cDr,hre,mDr,fDr,gDr,F0,t7e,hDr,uDr,ure,pDr,_Dr,bDr,T0,a7e,vDr,FDr,pre,TDr,MDr,EDr,M0,n7e,CDr,wDr,_re,ADr,LDr,yDr,E0,s7e,xDr,$Dr,bre,kDr,SDr,RDr,C0,l7e,PDr,BDr,vre,IDr,NDr,qDr,w0,i7e,jDr,DDr,Fre,GDr,ODr,VDr,A0,d7e,XDr,zDr,Tre,QDr,WDr,UDr,L0,c7e,HDr,JDr,Mre,YDr,ZDr,KDr,y0,m7e,eGr,oGr,Ere,rGr,tGr,aGr,x0,f7e,nGr,sGr,Cre,lGr,iGr,dGr,$0,g7e,cGr,mGr,wre,fGr,gGr,hGr,k0,wro,am,S0,h7e,BS,uGr,u7e,pGr,Aro,cr,IS,_Gr,nm,bGr,Are,vGr,FGr,Lre,TGr,MGr,EGr,NS,CGr,p7e,wGr,AGr,LGr,Ht,qS,yGr,_7e,xGr,$Gr,sm,kGr,b7e,SGr,RGr,yre,PGr,BGr,IGr,R0,NGr,Dr,jS,qGr,v7e,jGr,DGr,Sn,GGr,F7e,OGr,VGr,T7e,XGr,zGr,M7e,QGr,WGr,UGr,Me,P0,E7e,HGr,JGr,xre,YGr,ZGr,KGr,B0,C7e,eOr,oOr,$re,rOr,tOr,aOr,I0,w7e,nOr,sOr,kre,lOr,iOr,dOr,N0,A7e,cOr,mOr,Sre,fOr,gOr,hOr,q0,L7e,uOr,pOr,Rre,_Or,bOr,vOr,j0,y7e,FOr,TOr,Pre,MOr,EOr,COr,D0,x7e,wOr,AOr,Bre,LOr,yOr,xOr,G0,$7e,$Or,kOr,Ire,SOr,ROr,POr,O0,k7e,BOr,IOr,Nre,NOr,qOr,jOr,V0,S7e,DOr,GOr,qre,OOr,VOr,XOr,X0,R7e,zOr,QOr,jre,WOr,UOr,HOr,z0,P7e,JOr,YOr,Dre,ZOr,KOr,eVr,Q0,B7e,oVr,rVr,Gre,tVr,aVr,nVr,W0,I7e,sVr,lVr,Ore,iVr,dVr,cVr,U0,Lro,lm,H0,N7e,DS,mVr,q7e,fVr,yro,mr,GS,gVr,im,hVr,Vre,uVr,pVr,Xre,_Vr,bVr,vVr,OS,FVr,j7e,TVr,MVr,EVr,Jt,VS,CVr,D7e,wVr,AVr,dm,LVr,G7e,yVr,xVr,zre,$Vr,kVr,SVr,J0,RVr,Gr,XS,PVr,O7e,BVr,IVr,Rn,NVr,V7e,qVr,jVr,X7e,DVr,GVr,z7e,OVr,VVr,XVr,Be,Y0,Q7e,zVr,QVr,Qre,WVr,UVr,HVr,Z0,W7e,JVr,YVr,Wre,ZVr,KVr,eXr,Al,U7e,oXr,rXr,Ure,tXr,aXr,Hre,nXr,sXr,lXr,K0,H7e,iXr,dXr,Jre,cXr,mXr,fXr,ew,J7e,gXr,hXr,Yre,uXr,pXr,_Xr,ow,Y7e,bXr,vXr,Zre,FXr,TXr,MXr,rw,Z7e,EXr,CXr,Kre,wXr,AXr,LXr,tw,K7e,yXr,xXr,ete,$Xr,kXr,SXr,aw,eLe,RXr,PXr,ote,BXr,IXr,NXr,nw,xro,cm,sw,oLe,zS,qXr,rLe,jXr,$ro,fr,QS,DXr,mm,GXr,rte,OXr,VXr,tte,XXr,zXr,QXr,WS,WXr,tLe,UXr,HXr,JXr,Yt,US,YXr,aLe,ZXr,KXr,fm,ezr,nLe,ozr,rzr,ate,tzr,azr,nzr,lw,szr,Or,HS,lzr,sLe,izr,dzr,Pn,czr,lLe,mzr,fzr,iLe,gzr,hzr,dLe,uzr,pzr,_zr,gm,iw,cLe,bzr,vzr,nte,Fzr,Tzr,Mzr,dw,mLe,Ezr,Czr,ste,wzr,Azr,Lzr,cw,fLe,yzr,xzr,lte,$zr,kzr,Szr,mw,kro,hm,fw,gLe,JS,Rzr,hLe,Pzr,Sro,gr,YS,Bzr,um,Izr,ite,Nzr,qzr,dte,jzr,Dzr,Gzr,ZS,Ozr,uLe,Vzr,Xzr,zzr,Zt,KS,Qzr,pLe,Wzr,Uzr,pm,Hzr,_Le,Jzr,Yzr,cte,Zzr,Kzr,eQr,gw,oQr,Vr,eR,rQr,bLe,tQr,aQr,Bn,nQr,vLe,sQr,lQr,FLe,iQr,dQr,TLe,cQr,mQr,fQr,ge,hw,MLe,gQr,hQr,mte,uQr,pQr,_Qr,uw,ELe,bQr,vQr,fte,FQr,TQr,MQr,pw,CLe,EQr,CQr,gte,wQr,AQr,LQr,_w,wLe,yQr,xQr,hte,$Qr,kQr,SQr,bw,ALe,RQr,PQr,ute,BQr,IQr,NQr,vw,LLe,qQr,jQr,pte,DQr,GQr,OQr,Fw,yLe,VQr,XQr,_te,zQr,QQr,WQr,Tw,xLe,UQr,HQr,bte,JQr,YQr,ZQr,Mw,$Le,KQr,eWr,vte,oWr,rWr,tWr,Ew,kLe,aWr,nWr,Fte,sWr,lWr,iWr,Cw,SLe,dWr,cWr,Tte,mWr,fWr,gWr,ww,RLe,hWr,uWr,Mte,pWr,_Wr,bWr,Aw,PLe,vWr,FWr,Ete,TWr,MWr,EWr,Lw,BLe,CWr,wWr,Cte,AWr,LWr,yWr,yw,ILe,xWr,$Wr,wte,kWr,SWr,RWr,xw,NLe,PWr,BWr,Ate,IWr,NWr,qWr,$w,qLe,jWr,DWr,Lte,GWr,OWr,VWr,kw,jLe,XWr,zWr,yte,QWr,WWr,UWr,Sw,DLe,HWr,JWr,xte,YWr,ZWr,KWr,Rw,GLe,eUr,oUr,$te,rUr,tUr,aUr,Pw,Rro,_m,Bw,OLe,oR,nUr,VLe,sUr,Pro,hr,rR,lUr,bm,iUr,kte,dUr,cUr,Ste,mUr,fUr,gUr,tR,hUr,XLe,uUr,pUr,_Ur,Kt,aR,bUr,zLe,vUr,FUr,vm,TUr,QLe,MUr,EUr,Rte,CUr,wUr,AUr,Iw,LUr,Xr,nR,yUr,WLe,xUr,$Ur,In,kUr,ULe,SUr,RUr,HLe,PUr,BUr,JLe,IUr,NUr,qUr,ye,Nw,YLe,jUr,DUr,Pte,GUr,OUr,VUr,qw,ZLe,XUr,zUr,Bte,QUr,WUr,UUr,jw,KLe,HUr,JUr,Ite,YUr,ZUr,KUr,Dw,eye,eHr,oHr,Nte,rHr,tHr,aHr,Gw,oye,nHr,sHr,qte,lHr,iHr,dHr,Ow,rye,cHr,mHr,jte,fHr,gHr,hHr,Vw,tye,uHr,pHr,Dte,_Hr,bHr,vHr,Xw,aye,FHr,THr,Gte,MHr,EHr,CHr,zw,nye,wHr,AHr,Ote,LHr,yHr,xHr,Qw,sye,$Hr,kHr,Vte,SHr,RHr,PHr,Ww,Bro,Fm,Uw,lye,sR,BHr,iye,IHr,Iro,ur,lR,NHr,Tm,qHr,Xte,jHr,DHr,zte,GHr,OHr,VHr,iR,XHr,dye,zHr,QHr,WHr,ea,dR,UHr,cye,HHr,JHr,Mm,YHr,mye,ZHr,KHr,Qte,eJr,oJr,rJr,Hw,tJr,zr,cR,aJr,fye,nJr,sJr,Nn,lJr,gye,iJr,dJr,hye,cJr,mJr,uye,fJr,gJr,hJr,re,Jw,pye,uJr,pJr,Wte,_Jr,bJr,vJr,Yw,_ye,FJr,TJr,Ute,MJr,EJr,CJr,Zw,bye,wJr,AJr,Hte,LJr,yJr,xJr,Kw,vye,$Jr,kJr,Jte,SJr,RJr,PJr,eA,Fye,BJr,IJr,Yte,NJr,qJr,jJr,oA,Tye,DJr,GJr,Zte,OJr,VJr,XJr,rA,Mye,zJr,QJr,Kte,WJr,UJr,HJr,tA,Eye,JJr,YJr,eae,ZJr,KJr,eYr,aA,Cye,oYr,rYr,oae,tYr,aYr,nYr,nA,wye,sYr,lYr,rae,iYr,dYr,cYr,sA,Aye,mYr,fYr,tae,gYr,hYr,uYr,lA,Lye,pYr,_Yr,aae,bYr,vYr,FYr,iA,yye,TYr,MYr,nae,EYr,CYr,wYr,dA,xye,AYr,LYr,sae,yYr,xYr,$Yr,cA,$ye,kYr,SYr,lae,RYr,PYr,BYr,mA,kye,IYr,NYr,iae,qYr,jYr,DYr,fA,Sye,GYr,OYr,dae,VYr,XYr,zYr,gA,Rye,QYr,WYr,cae,UYr,HYr,JYr,hA,Pye,YYr,ZYr,mae,KYr,eZr,oZr,uA,Bye,rZr,tZr,fae,aZr,nZr,sZr,pA,Iye,lZr,iZr,gae,dZr,cZr,mZr,_A,Nye,fZr,gZr,hae,hZr,uZr,pZr,bA,qye,_Zr,bZr,uae,vZr,FZr,TZr,vA,jye,MZr,EZr,pae,CZr,wZr,AZr,FA,Dye,LZr,yZr,_ae,xZr,$Zr,kZr,TA,Gye,SZr,RZr,bae,PZr,BZr,IZr,MA,Oye,NZr,qZr,vae,jZr,DZr,GZr,EA,Nro,Em,CA,Vye,mR,OZr,Xye,VZr,qro,pr,fR,XZr,Cm,zZr,Fae,QZr,WZr,Tae,UZr,HZr,JZr,gR,YZr,zye,ZZr,KZr,eKr,oa,hR,oKr,Qye,rKr,tKr,wm,aKr,Wye,nKr,sKr,Mae,lKr,iKr,dKr,wA,cKr,Qr,uR,mKr,Uye,fKr,gKr,qn,hKr,Hye,uKr,pKr,Jye,_Kr,bKr,Yye,vKr,FKr,TKr,ve,AA,Zye,MKr,EKr,Eae,CKr,wKr,AKr,LA,Kye,LKr,yKr,Cae,xKr,$Kr,kKr,yA,e8e,SKr,RKr,wae,PKr,BKr,IKr,xA,o8e,NKr,qKr,Aae,jKr,DKr,GKr,$A,r8e,OKr,VKr,Lae,XKr,zKr,QKr,kA,t8e,WKr,UKr,yae,HKr,JKr,YKr,SA,a8e,ZKr,KKr,xae,eet,oet,ret,RA,n8e,tet,aet,$ae,net,set,iet,PA,s8e,det,cet,kae,met,fet,get,BA,l8e,het,uet,Sae,pet,_et,bet,IA,i8e,vet,Fet,Rae,Tet,Met,Eet,NA,d8e,Cet,wet,Pae,Aet,Let,yet,qA,c8e,xet,$et,Bae,ket,Set,Ret,jA,m8e,Pet,Bet,Iae,Iet,Net,qet,DA,f8e,jet,Det,Nae,Get,Oet,Vet,GA,g8e,Xet,zet,qae,Qet,Wet,Uet,OA,h8e,Het,Jet,jae,Yet,Zet,Ket,VA,jro,Am,XA,u8e,pR,eot,p8e,oot,Dro,_r,_R,rot,Lm,tot,Dae,aot,not,Gae,sot,lot,iot,bR,dot,_8e,cot,mot,fot,ra,vR,got,b8e,hot,uot,ym,pot,v8e,_ot,bot,Oae,vot,Fot,Tot,zA,Mot,Wr,FR,Eot,F8e,Cot,wot,jn,Aot,T8e,Lot,yot,M8e,xot,$ot,E8e,kot,Sot,Rot,TR,QA,C8e,Pot,Bot,Vae,Iot,Not,qot,WA,w8e,jot,Dot,Xae,Got,Oot,Vot,UA,Gro,xm,HA,A8e,MR,Xot,L8e,zot,Oro,br,ER,Qot,$m,Wot,zae,Uot,Hot,Qae,Jot,Yot,Zot,CR,Kot,y8e,ert,ort,rrt,ta,wR,trt,x8e,art,nrt,km,srt,$8e,lrt,irt,Wae,drt,crt,mrt,JA,frt,Ur,AR,grt,k8e,hrt,urt,Dn,prt,S8e,_rt,brt,R8e,vrt,Frt,P8e,Trt,Mrt,Ert,B8e,YA,I8e,Crt,wrt,Uae,Art,Lrt,yrt,ZA,Vro,Sm,KA,N8e,LR,xrt,q8e,$rt,Xro,vr,yR,krt,Rm,Srt,Hae,Rrt,Prt,Jae,Brt,Irt,Nrt,xR,qrt,j8e,jrt,Drt,Grt,aa,$R,Ort,D8e,Vrt,Xrt,Pm,zrt,G8e,Qrt,Wrt,Yae,Urt,Hrt,Jrt,e6,Yrt,Hr,kR,Zrt,O8e,Krt,ett,Gn,ott,V8e,rtt,ttt,X8e,att,ntt,z8e,stt,ltt,itt,Q8e,o6,W8e,dtt,ctt,Zae,mtt,ftt,gtt,r6,zro,Bm,t6,U8e,SR,htt,H8e,utt,Qro,Fr,RR,ptt,Im,_tt,Kae,btt,vtt,ene,Ftt,Ttt,Mtt,PR,Ett,J8e,Ctt,wtt,Att,na,BR,Ltt,Y8e,ytt,xtt,Nm,$tt,Z8e,ktt,Stt,one,Rtt,Ptt,Btt,a6,Itt,Jr,IR,Ntt,K8e,qtt,jtt,On,Dtt,e9e,Gtt,Ott,o9e,Vtt,Xtt,r9e,ztt,Qtt,Wtt,ce,n6,t9e,Utt,Htt,rne,Jtt,Ytt,Ztt,s6,a9e,Ktt,eat,tne,oat,rat,tat,l6,n9e,aat,nat,ane,sat,lat,iat,i6,s9e,dat,cat,nne,mat,fat,gat,d6,l9e,hat,uat,sne,pat,_at,bat,c6,i9e,vat,Fat,lne,Tat,Mat,Eat,m6,d9e,Cat,wat,ine,Aat,Lat,yat,f6,c9e,xat,$at,dne,kat,Sat,Rat,g6,m9e,Pat,Bat,cne,Iat,Nat,qat,h6,f9e,jat,Dat,mne,Gat,Oat,Vat,u6,g9e,Xat,zat,fne,Qat,Wat,Uat,p6,h9e,Hat,Jat,gne,Yat,Zat,Kat,_6,u9e,ent,ont,hne,rnt,tnt,ant,b6,p9e,nnt,snt,une,lnt,int,dnt,v6,_9e,cnt,mnt,pne,fnt,gnt,hnt,F6,b9e,unt,pnt,_ne,_nt,bnt,vnt,T6,v9e,Fnt,Tnt,bne,Mnt,Ent,Cnt,M6,F9e,wnt,Ant,vne,Lnt,ynt,xnt,E6,T9e,$nt,knt,Fne,Snt,Rnt,Pnt,C6,M9e,Bnt,Int,Tne,Nnt,qnt,jnt,w6,E9e,Dnt,Gnt,Mne,Ont,Vnt,Xnt,A6,Wro,qm,L6,C9e,NR,znt,w9e,Qnt,Uro,Tr,qR,Wnt,jm,Unt,Ene,Hnt,Jnt,Cne,Ynt,Znt,Knt,jR,est,A9e,ost,rst,tst,sa,DR,ast,L9e,nst,sst,Dm,lst,y9e,ist,dst,wne,cst,mst,fst,y6,gst,Yr,GR,hst,x9e,ust,pst,Vn,_st,$9e,bst,vst,k9e,Fst,Tst,S9e,Mst,Est,Cst,me,x6,R9e,wst,Ast,Ane,Lst,yst,xst,$6,P9e,$st,kst,Lne,Sst,Rst,Pst,k6,B9e,Bst,Ist,yne,Nst,qst,jst,S6,I9e,Dst,Gst,xne,Ost,Vst,Xst,R6,N9e,zst,Qst,$ne,Wst,Ust,Hst,P6,q9e,Jst,Yst,kne,Zst,Kst,elt,B6,j9e,olt,rlt,Sne,tlt,alt,nlt,I6,D9e,slt,llt,Rne,ilt,dlt,clt,N6,G9e,mlt,flt,Pne,glt,hlt,ult,q6,O9e,plt,_lt,Bne,blt,vlt,Flt,j6,V9e,Tlt,Mlt,Ine,Elt,Clt,wlt,D6,X9e,Alt,Llt,Nne,ylt,xlt,$lt,G6,z9e,klt,Slt,qne,Rlt,Plt,Blt,O6,Q9e,Ilt,Nlt,jne,qlt,jlt,Dlt,V6,W9e,Glt,Olt,Dne,Vlt,Xlt,zlt,X6,U9e,Qlt,Wlt,Gne,Ult,Hlt,Jlt,z6,H9e,Ylt,Zlt,One,Klt,eit,oit,Q6,J9e,rit,tit,Vne,ait,nit,sit,W6,Y9e,lit,iit,Xne,dit,cit,mit,U6,Z9e,fit,git,zne,hit,uit,pit,H6,K9e,_it,bit,Qne,vit,Fit,Tit,J6,Hro,Gm,Y6,exe,OR,Mit,oxe,Eit,Jro,Mr,VR,Cit,Om,wit,Wne,Ait,Lit,Une,yit,xit,$it,XR,kit,rxe,Sit,Rit,Pit,la,zR,Bit,txe,Iit,Nit,Vm,qit,axe,jit,Dit,Hne,Git,Oit,Vit,Z6,Xit,Zr,QR,zit,nxe,Qit,Wit,Xn,Uit,sxe,Hit,Jit,lxe,Yit,Zit,ixe,Kit,edt,odt,dxe,K6,cxe,rdt,tdt,Jne,adt,ndt,sdt,e7,Yro,Xm,o7,mxe,WR,ldt,fxe,idt,Zro,Er,UR,ddt,zm,cdt,Yne,mdt,fdt,Zne,gdt,hdt,udt,HR,pdt,gxe,_dt,bdt,vdt,ia,JR,Fdt,hxe,Tdt,Mdt,Qm,Edt,uxe,Cdt,wdt,Kne,Adt,Ldt,ydt,r7,xdt,Kr,YR,$dt,pxe,kdt,Sdt,zn,Rdt,_xe,Pdt,Bdt,bxe,Idt,Ndt,vxe,qdt,jdt,Ddt,Fxe,t7,Txe,Gdt,Odt,ese,Vdt,Xdt,zdt,a7,Kro,Wm,n7,Mxe,ZR,Qdt,Exe,Wdt,eto,Cr,KR,Udt,Um,Hdt,ose,Jdt,Ydt,rse,Zdt,Kdt,ect,eP,oct,Cxe,rct,tct,act,da,oP,nct,wxe,sct,lct,Hm,ict,Axe,dct,cct,tse,mct,fct,gct,s7,hct,et,rP,uct,Lxe,pct,_ct,Qn,bct,yxe,vct,Fct,xxe,Tct,Mct,$xe,Ect,Cct,wct,te,l7,kxe,Act,Lct,ase,yct,xct,$ct,i7,Sxe,kct,Sct,nse,Rct,Pct,Bct,d7,Rxe,Ict,Nct,sse,qct,jct,Dct,c7,Pxe,Gct,Oct,lse,Vct,Xct,zct,m7,Bxe,Qct,Wct,ise,Uct,Hct,Jct,f7,Ixe,Yct,Zct,dse,Kct,emt,omt,g7,Nxe,rmt,tmt,cse,amt,nmt,smt,h7,qxe,lmt,imt,mse,dmt,cmt,mmt,u7,jxe,fmt,gmt,fse,hmt,umt,pmt,p7,Dxe,_mt,bmt,gse,vmt,Fmt,Tmt,_7,Gxe,Mmt,Emt,hse,Cmt,wmt,Amt,b7,Oxe,Lmt,ymt,use,xmt,$mt,kmt,v7,Vxe,Smt,Rmt,pse,Pmt,Bmt,Imt,F7,Xxe,Nmt,qmt,_se,jmt,Dmt,Gmt,T7,zxe,Omt,Vmt,bse,Xmt,zmt,Qmt,M7,Qxe,Wmt,Umt,vse,Hmt,Jmt,Ymt,E7,Wxe,Zmt,Kmt,Fse,eft,oft,rft,C7,Uxe,tft,aft,Tse,nft,sft,lft,w7,Hxe,ift,dft,Mse,cft,mft,fft,A7,Jxe,gft,hft,Ese,uft,pft,_ft,L7,Yxe,bft,vft,Cse,Fft,Tft,Mft,y7,Zxe,Eft,Cft,wse,wft,Aft,Lft,x7,Kxe,yft,xft,Ase,$ft,kft,Sft,$7,e$e,Rft,Pft,Lse,Bft,Ift,Nft,k7,o$e,qft,jft,yse,Dft,Gft,Oft,S7,r$e,Vft,Xft,xse,zft,Qft,Wft,R7,t$e,Uft,Hft,$se,Jft,Yft,Zft,P7,oto,Jm,B7,a$e,tP,Kft,n$e,egt,rto,wr,aP,ogt,Ym,rgt,kse,tgt,agt,Sse,ngt,sgt,lgt,nP,igt,s$e,dgt,cgt,mgt,ca,sP,fgt,l$e,ggt,hgt,Zm,ugt,i$e,pgt,_gt,Rse,bgt,vgt,Fgt,I7,Tgt,ot,lP,Mgt,d$e,Egt,Cgt,Wn,wgt,c$e,Agt,Lgt,m$e,ygt,xgt,f$e,$gt,kgt,Sgt,xe,N7,g$e,Rgt,Pgt,Pse,Bgt,Igt,Ngt,q7,h$e,qgt,jgt,Bse,Dgt,Ggt,Ogt,j7,u$e,Vgt,Xgt,Ise,zgt,Qgt,Wgt,D7,p$e,Ugt,Hgt,Nse,Jgt,Ygt,Zgt,G7,_$e,Kgt,eht,qse,oht,rht,tht,O7,b$e,aht,nht,jse,sht,lht,iht,V7,v$e,dht,cht,Dse,mht,fht,ght,X7,F$e,hht,uht,Gse,pht,_ht,bht,z7,T$e,vht,Fht,Ose,Tht,Mht,Eht,Q7,M$e,Cht,wht,Vse,Aht,Lht,yht,W7,tto,Km,U7,E$e,iP,xht,C$e,$ht,ato,Ar,dP,kht,ef,Sht,Xse,Rht,Pht,zse,Bht,Iht,Nht,cP,qht,w$e,jht,Dht,Ght,ma,mP,Oht,A$e,Vht,Xht,of,zht,L$e,Qht,Wht,Qse,Uht,Hht,Jht,H7,Yht,rt,fP,Zht,y$e,Kht,eut,Un,out,x$e,rut,tut,$$e,aut,nut,k$e,sut,lut,iut,Ee,J7,S$e,dut,cut,Wse,mut,fut,gut,Y7,R$e,hut,uut,Use,put,_ut,but,Z7,P$e,vut,Fut,Hse,Tut,Mut,Eut,K7,B$e,Cut,wut,Jse,Aut,Lut,yut,eL,I$e,xut,$ut,Yse,kut,Sut,Rut,oL,N$e,Put,But,Zse,Iut,Nut,qut,rL,q$e,jut,Dut,Kse,Gut,Out,Vut,tL,j$e,Xut,zut,ele,Qut,Wut,Uut,aL,D$e,Hut,Jut,ole,Yut,Zut,Kut,nL,G$e,ept,opt,rle,rpt,tpt,apt,sL,O$e,npt,spt,tle,lpt,ipt,dpt,lL,V$e,cpt,mpt,ale,fpt,gpt,hpt,iL,X$e,upt,ppt,nle,_pt,bpt,vpt,dL,nto,rf,cL,z$e,gP,Fpt,Q$e,Tpt,sto,Lr,hP,Mpt,tf,Ept,sle,Cpt,wpt,lle,Apt,Lpt,ypt,uP,xpt,W$e,$pt,kpt,Spt,fa,pP,Rpt,U$e,Ppt,Bpt,af,Ipt,H$e,Npt,qpt,ile,jpt,Dpt,Gpt,mL,Opt,tt,_P,Vpt,J$e,Xpt,zpt,Hn,Qpt,Y$e,Wpt,Upt,Z$e,Hpt,Jpt,K$e,Ypt,Zpt,Kpt,$e,fL,eke,e_t,o_t,dle,r_t,t_t,a_t,gL,oke,n_t,s_t,cle,l_t,i_t,d_t,hL,rke,c_t,m_t,mle,f_t,g_t,h_t,uL,tke,u_t,p_t,fle,__t,b_t,v_t,pL,ake,F_t,T_t,gle,M_t,E_t,C_t,_L,nke,w_t,A_t,hle,L_t,y_t,x_t,bL,ske,$_t,k_t,ule,S_t,R_t,P_t,vL,lke,B_t,I_t,ple,N_t,q_t,j_t,FL,ike,D_t,G_t,_le,O_t,V_t,X_t,TL,dke,z_t,Q_t,ble,W_t,U_t,H_t,ML,lto,nf,EL,cke,bP,J_t,mke,Y_t,ito,yr,vP,Z_t,sf,K_t,vle,e1t,o1t,Fle,r1t,t1t,a1t,FP,n1t,fke,s1t,l1t,i1t,ga,TP,d1t,gke,c1t,m1t,lf,f1t,hke,g1t,h1t,Tle,u1t,p1t,_1t,CL,b1t,at,MP,v1t,uke,F1t,T1t,Jn,M1t,pke,E1t,C1t,_ke,w1t,A1t,bke,L1t,y1t,x1t,ke,wL,vke,$1t,k1t,Mle,S1t,R1t,P1t,AL,Fke,B1t,I1t,Ele,N1t,q1t,j1t,LL,Tke,D1t,G1t,Cle,O1t,V1t,X1t,yL,Mke,z1t,Q1t,wle,W1t,U1t,H1t,xL,Eke,J1t,Y1t,Ale,Z1t,K1t,ebt,$L,Cke,obt,rbt,Lle,tbt,abt,nbt,kL,wke,sbt,lbt,yle,ibt,dbt,cbt,SL,Ake,mbt,fbt,xle,gbt,hbt,ubt,RL,Lke,pbt,_bt,$le,bbt,vbt,Fbt,PL,yke,Tbt,Mbt,kle,Ebt,Cbt,wbt,BL,dto,df,IL,xke,EP,Abt,$ke,Lbt,cto,xr,CP,ybt,cf,xbt,Sle,$bt,kbt,Rle,Sbt,Rbt,Pbt,wP,Bbt,kke,Ibt,Nbt,qbt,ha,AP,jbt,Ske,Dbt,Gbt,mf,Obt,Rke,Vbt,Xbt,Ple,zbt,Qbt,Wbt,NL,Ubt,nt,LP,Hbt,Pke,Jbt,Ybt,Yn,Zbt,Bke,Kbt,e2t,Ike,o2t,r2t,Nke,t2t,a2t,n2t,Se,qL,qke,s2t,l2t,Ble,i2t,d2t,c2t,jL,jke,m2t,f2t,Ile,g2t,h2t,u2t,DL,Dke,p2t,_2t,Nle,b2t,v2t,F2t,GL,Gke,T2t,M2t,qle,E2t,C2t,w2t,OL,Oke,A2t,L2t,jle,y2t,x2t,$2t,VL,Vke,k2t,S2t,Dle,R2t,P2t,B2t,XL,Xke,I2t,N2t,Gle,q2t,j2t,D2t,zL,zke,G2t,O2t,Ole,V2t,X2t,z2t,QL,Qke,Q2t,W2t,Vle,U2t,H2t,J2t,WL,Wke,Y2t,Z2t,Xle,K2t,evt,ovt,UL,mto,ff,HL,Uke,yP,rvt,Hke,tvt,fto,$r,xP,avt,gf,nvt,zle,svt,lvt,Qle,ivt,dvt,cvt,$P,mvt,Jke,fvt,gvt,hvt,ua,kP,uvt,Yke,pvt,_vt,hf,bvt,Zke,vvt,Fvt,Wle,Tvt,Mvt,Evt,JL,Cvt,st,SP,wvt,Kke,Avt,Lvt,Zn,yvt,eSe,xvt,$vt,oSe,kvt,Svt,rSe,Rvt,Pvt,Bvt,Re,YL,tSe,Ivt,Nvt,Ule,qvt,jvt,Dvt,ZL,aSe,Gvt,Ovt,Hle,Vvt,Xvt,zvt,KL,nSe,Qvt,Wvt,Jle,Uvt,Hvt,Jvt,ey,sSe,Yvt,Zvt,Yle,Kvt,eFt,oFt,oy,lSe,rFt,tFt,Zle,aFt,nFt,sFt,ry,iSe,lFt,iFt,Kle,dFt,cFt,mFt,ty,dSe,fFt,gFt,eie,hFt,uFt,pFt,ay,cSe,_Ft,bFt,oie,vFt,FFt,TFt,ny,mSe,MFt,EFt,rie,CFt,wFt,AFt,sy,fSe,LFt,yFt,tie,xFt,$Ft,kFt,ly,gto,uf,iy,gSe,RP,SFt,hSe,RFt,hto,kr,PP,PFt,pf,BFt,aie,IFt,NFt,nie,qFt,jFt,DFt,BP,GFt,uSe,OFt,VFt,XFt,pa,IP,zFt,pSe,QFt,WFt,_f,UFt,_Se,HFt,JFt,sie,YFt,ZFt,KFt,dy,eTt,lt,NP,oTt,bSe,rTt,tTt,Kn,aTt,vSe,nTt,sTt,FSe,lTt,iTt,TSe,dTt,cTt,mTt,Xe,cy,MSe,fTt,gTt,lie,hTt,uTt,pTt,my,ESe,_Tt,bTt,iie,vTt,FTt,TTt,fy,CSe,MTt,ETt,die,CTt,wTt,ATt,gy,wSe,LTt,yTt,cie,xTt,$Tt,kTt,hy,ASe,STt,RTt,mie,PTt,BTt,ITt,uy,LSe,NTt,qTt,fie,jTt,DTt,GTt,py,ySe,OTt,VTt,gie,XTt,zTt,QTt,_y,xSe,WTt,UTt,hie,HTt,JTt,YTt,by,uto,bf,vy,$Se,qP,ZTt,kSe,KTt,pto,Sr,jP,eMt,vf,oMt,uie,rMt,tMt,pie,aMt,nMt,sMt,DP,lMt,SSe,iMt,dMt,cMt,_a,GP,mMt,RSe,fMt,gMt,Ff,hMt,PSe,uMt,pMt,_ie,_Mt,bMt,vMt,Fy,FMt,it,OP,TMt,BSe,MMt,EMt,es,CMt,ISe,wMt,AMt,NSe,LMt,yMt,qSe,xMt,$Mt,kMt,ze,Ty,jSe,SMt,RMt,bie,PMt,BMt,IMt,My,DSe,NMt,qMt,vie,jMt,DMt,GMt,Ey,GSe,OMt,VMt,Fie,XMt,zMt,QMt,Cy,OSe,WMt,UMt,Tie,HMt,JMt,YMt,wy,VSe,ZMt,KMt,Mie,eEt,oEt,rEt,Ay,XSe,tEt,aEt,Eie,nEt,sEt,lEt,Ly,zSe,iEt,dEt,Cie,cEt,mEt,fEt,yy,QSe,gEt,hEt,wie,uEt,pEt,_Et,xy,_to,Tf,$y,WSe,VP,bEt,USe,vEt,bto,Rr,XP,FEt,Mf,TEt,Aie,MEt,EEt,Lie,CEt,wEt,AEt,zP,LEt,HSe,yEt,xEt,$Et,ba,QP,kEt,JSe,SEt,REt,Ef,PEt,YSe,BEt,IEt,yie,NEt,qEt,jEt,ky,DEt,dt,WP,GEt,ZSe,OEt,VEt,os,XEt,KSe,zEt,QEt,eRe,WEt,UEt,oRe,HEt,JEt,YEt,rRe,Sy,tRe,ZEt,KEt,xie,e4t,o4t,r4t,Ry,vto,Cf,Py,aRe,UP,t4t,nRe,a4t,Fto,Pr,HP,n4t,wf,s4t,$ie,l4t,i4t,kie,d4t,c4t,m4t,JP,f4t,sRe,g4t,h4t,u4t,va,YP,p4t,lRe,_4t,b4t,Af,v4t,iRe,F4t,T4t,Sie,M4t,E4t,C4t,By,w4t,ct,ZP,A4t,dRe,L4t,y4t,rs,x4t,cRe,$4t,k4t,mRe,S4t,R4t,fRe,P4t,B4t,I4t,KP,Iy,gRe,N4t,q4t,Rie,j4t,D4t,G4t,Ny,hRe,O4t,V4t,Pie,X4t,z4t,Q4t,qy,Tto,Lf,jy,uRe,eB,W4t,pRe,U4t,Mto,Br,oB,H4t,yf,J4t,Bie,Y4t,Z4t,Iie,K4t,eCt,oCt,rB,rCt,_Re,tCt,aCt,nCt,Fa,tB,sCt,bRe,lCt,iCt,xf,dCt,vRe,cCt,mCt,Nie,fCt,gCt,hCt,Dy,uCt,mt,aB,pCt,FRe,_Ct,bCt,ts,vCt,TRe,FCt,TCt,MRe,MCt,ECt,ERe,CCt,wCt,ACt,CRe,Gy,wRe,LCt,yCt,qie,xCt,$Ct,kCt,Oy,Eto;return d=new oe({}),Ja=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),Ax=new oe({}),Lx=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),qf=new SCt({props:{warning:!0,$$slots:{default:[pFa]},$$scope:{ctx:$}}}),yx=new oe({}),xx=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L659"}}),Sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L682"}}),mu=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[_Fa]},$$scope:{ctx:$}}}),Rx=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L805"}}),Px=new oe({}),Bx=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L428"}}),qx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L442"}}),Hu=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[bFa]},$$scope:{ctx:$}}}),jx=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L643"}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L203"}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L217"}}),Gp=new SCt({props:{$$slots:{default:[vFa]},$$scope:{ctx:$}}}),Op=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[FFa]},$$scope:{ctx:$}}}),zx=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L344"}}),Qx=new oe({}),Wx=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),Jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),h_=new SCt({props:{$$slots:{default:[TFa]},$$scope:{ctx:$}}}),u_=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[MFa]},$$scope:{ctx:$}}}),Yx=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),Zx=new oe({}),Kx=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L874"}}),o$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b_=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[EFa]},$$scope:{ctx:$}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qb=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[CFa]},$$scope:{ctx:$}}}),t$=new oe({}),a$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L881"}}),s$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Db=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[wFa]},$$scope:{ctx:$}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I2=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[AFa]},$$scope:{ctx:$}}}),i$=new oe({}),d$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L896"}}),m$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[LFa]},$$scope:{ctx:$}}}),f$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yv=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[yFa]},$$scope:{ctx:$}}}),g$=new oe({}),h$=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L903"}}),p$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$v=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[xFa]},$$scope:{ctx:$}}}),_$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_F=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[$Fa]},$$scope:{ctx:$}}}),b$=new oe({}),v$=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L910"}}),T$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vF=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[kFa]},$$scope:{ctx:$}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GF=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[SFa]},$$scope:{ctx:$}}}),E$=new oe({}),C$=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L919"}}),A$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VF=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[RFa]},$$scope:{ctx:$}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QT=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[PFa]},$$scope:{ctx:$}}}),y$=new oe({}),x$=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L975"}}),k$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UT=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[BFa]},$$scope:{ctx:$}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yM=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[IFa]},$$scope:{ctx:$}}}),R$=new oe({}),P$=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L982"}}),I$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$M=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[NFa]},$$scope:{ctx:$}}}),N$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jM=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[qFa]},$$scope:{ctx:$}}}),q$=new oe({}),j$=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L968"}}),G$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GM=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[jFa]},$$scope:{ctx:$}}}),O$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xE=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[DFa]},$$scope:{ctx:$}}}),V$=new oe({}),X$=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L928"}}),Q$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kE=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[GFa]},$$scope:{ctx:$}}}),W$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A4=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[OFa]},$$scope:{ctx:$}}}),U$=new oe({}),H$=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L935"}}),Y$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y4=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VFa]},$$scope:{ctx:$}}}),Z$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k4=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XFa]},$$scope:{ctx:$}}}),K$=new oe({}),ek=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L957"}}),rk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R4=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[zFa]},$$scope:{ctx:$}}}),tk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q4=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[QFa]},$$scope:{ctx:$}}}),ak=new oe({}),nk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L991"}}),lk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D4=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[WFa]},$$scope:{ctx:$}}}),ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[UFa]},$$scope:{ctx:$}}}),dk=new oe({}),ck=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1039"}}),fk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[HFa]},$$scope:{ctx:$}}}),gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[JFa]},$$scope:{ctx:$}}}),hk=new oe({}),uk=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1046"}}),_k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cC=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[YFa]},$$scope:{ctx:$}}}),bk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gC=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[ZFa]},$$scope:{ctx:$}}}),vk=new oe({}),Fk=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L946"}}),Mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uC=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[KFa]},$$scope:{ctx:$}}}),Ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bC=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[eTa]},$$scope:{ctx:$}}}),Ck=new oe({}),wk=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1053"}}),Lk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),FC=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[oTa]},$$scope:{ctx:$}}}),yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),kC=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[rTa]},$$scope:{ctx:$}}}),xk=new oe({}),$k=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1076"}}),Sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),RC=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[tTa]},$$scope:{ctx:$}}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),DC=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[aTa]},$$scope:{ctx:$}}}),Pk=new oe({}),Bk=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1060"}}),Nk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),OC=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[nTa]},$$scope:{ctx:$}}}),qk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[sTa]},$$scope:{ctx:$}}}),jk=new oe({}),Dk=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1067"}}),Ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[lTa]},$$scope:{ctx:$}}}),Vk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l3=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[iTa]},$$scope:{ctx:$}}}),Xk=new oe({}),zk=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1085"}}),Wk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d3=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[dTa]},$$scope:{ctx:$}}}),Uk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p3=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[cTa]},$$scope:{ctx:$}}}),Hk=new oe({}),Jk=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1092"}}),Zk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b3=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[mTa]},$$scope:{ctx:$}}}),Kk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C3=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[fTa]},$$scope:{ctx:$}}}),eS=new oe({}),oS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1023"}}),tS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A3=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[gTa]},$$scope:{ctx:$}}}),aS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S3=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[hTa]},$$scope:{ctx:$}}}),nS=new oe({}),sS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L998"}}),iS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P3=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[uTa]},$$scope:{ctx:$}}}),dS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[pTa]},$$scope:{ctx:$}}}),cS=new oe({}),mS=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1005"}}),gS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),j3=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[_Ta]},$$scope:{ctx:$}}}),hS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q3=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[bTa]},$$scope:{ctx:$}}}),uS=new oe({}),pS=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1014"}}),bS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),U3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[vTa]},$$scope:{ctx:$}}}),vS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Y3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[FTa]},$$scope:{ctx:$}}}),FS=new oe({}),TS=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1030"}}),ES=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K3=new B({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[TTa]},$$scope:{ctx:$}}}),CS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r5=new B({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[MTa]},$$scope:{ctx:$}}}),wS=new oe({}),AS=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L434"}}),yS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a5=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[ETa]},$$scope:{ctx:$}}}),xS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n0=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[CTa]},$$scope:{ctx:$}}}),$S=new oe({}),kS=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),RS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l0=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[wTa]},$$scope:{ctx:$}}}),PS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k0=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[ATa]},$$scope:{ctx:$}}}),BS=new oe({}),IS=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),qS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R0=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[LTa]},$$scope:{ctx:$}}}),jS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),U0=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[yTa]},$$scope:{ctx:$}}}),DS=new oe({}),GS=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),VS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J0=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[xTa]},$$scope:{ctx:$}}}),XS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nw=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[$Ta]},$$scope:{ctx:$}}}),zS=new oe({}),QS=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),US=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lw=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[kTa]},$$scope:{ctx:$}}}),HS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mw=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[STa]},$$scope:{ctx:$}}}),JS=new oe({}),YS=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L497"}}),KS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gw=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[RTa]},$$scope:{ctx:$}}}),eR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Pw=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PTa]},$$scope:{ctx:$}}}),oR=new oe({}),rR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),aR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Iw=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BTa]},$$scope:{ctx:$}}}),nR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ww=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[ITa]},$$scope:{ctx:$}}}),sR=new oe({}),lR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L513"}}),dR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Hw=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NTa]},$$scope:{ctx:$}}}),cR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),EA=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qTa]},$$scope:{ctx:$}}}),mR=new oe({}),fR=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L560"}}),hR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),wA=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[jTa]},$$scope:{ctx:$}}}),uR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VA=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[DTa]},$$scope:{ctx:$}}}),pR=new oe({}),_R=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L567"}}),vR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zA=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[GTa]},$$scope:{ctx:$}}}),FR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UA=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[OTa]},$$scope:{ctx:$}}}),MR=new oe({}),ER=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L540"}}),wR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JA=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VTa]},$$scope:{ctx:$}}}),AR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZA=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XTa]},$$scope:{ctx:$}}}),LR=new oe({}),yR=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L529"}}),$R=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e6=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[zTa]},$$scope:{ctx:$}}}),kR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[QTa]},$$scope:{ctx:$}}}),SR=new oe({}),RR=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L551"}}),BR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[WTa]},$$scope:{ctx:$}}}),IR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A6=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[UTa]},$$scope:{ctx:$}}}),NR=new oe({}),qR=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),DR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y6=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[HTa]},$$scope:{ctx:$}}}),GR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J6=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JTa]},$$scope:{ctx:$}}}),OR=new oe({}),VR=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L490"}}),zR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z6=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[YTa]},$$scope:{ctx:$}}}),QR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e7=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[ZTa]},$$scope:{ctx:$}}}),WR=new oe({}),UR=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L576"}}),JR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r7=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[KTa]},$$scope:{ctx:$}}}),YR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a7=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[eMa]},$$scope:{ctx:$}}}),ZR=new oe({}),KR=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),oP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s7=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[oMa]},$$scope:{ctx:$}}}),rP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[rMa]},$$scope:{ctx:$}}}),tP=new oe({}),aP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),sP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[tMa]},$$scope:{ctx:$}}}),lP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W7=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[aMa]},$$scope:{ctx:$}}}),iP=new oe({}),dP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),mP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H7=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[nMa]},$$scope:{ctx:$}}}),fP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dL=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[sMa]},$$scope:{ctx:$}}}),gP=new oe({}),hP=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),pP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mL=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[lMa]},$$scope:{ctx:$}}}),_P=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ML=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[iMa]},$$scope:{ctx:$}}}),bP=new oe({}),vP=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),TP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),CL=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[dMa]},$$scope:{ctx:$}}}),MP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),BL=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[cMa]},$$scope:{ctx:$}}}),EP=new oe({}),CP=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),AP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),NL=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[mMa]},$$scope:{ctx:$}}}),LP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UL=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[fMa]},$$scope:{ctx:$}}}),yP=new oe({}),xP=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),kP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JL=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[gMa]},$$scope:{ctx:$}}}),SP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ly=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[hMa]},$$scope:{ctx:$}}}),RP=new oe({}),PP=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),IP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dy=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[uMa]},$$scope:{ctx:$}}}),NP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),by=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[pMa]},$$scope:{ctx:$}}}),qP=new oe({}),jP=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),GP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Fy=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[_Ma]},$$scope:{ctx:$}}}),OP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xy=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[bMa]},$$scope:{ctx:$}}}),VP=new oe({}),XP=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),QP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ky=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[vMa]},$$scope:{ctx:$}}}),WP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ry=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[FMa]},$$scope:{ctx:$}}}),UP=new oe({}),HP=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),YP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),By=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[TMa]},$$scope:{ctx:$}}}),ZP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qy=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[MMa]},$$scope:{ctx:$}}}),eB=new oe({}),oB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),tB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Dy=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[EMa]},$$scope:{ctx:$}}}),aB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Oy=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[CMa]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),xo=a("span"),dd=o("Auto Classes"),Rf=l(),bt=a("p"),cd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),md=a("code"),Mx=o("from_pretrained()"),Pf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),fd=o("Instantiating one of "),ns=a("a"),Ex=o("AutoConfig"),ss=o(", "),ls=a("a"),Cx=o("AutoModel"),gd=o(`, and
`),is=a("a"),wx=o("AutoTokenizer"),hd=o(" will directly create a class of the relevant architecture. For instance"),Bf=l(),F(Ja.$$.fragment),Je=l(),Ae=a("p"),$I=o("will create a model that is an instance of "),ud=a("a"),kI=o("BertModel"),SI=o("."),$o=l(),Ya=a("p"),RI=o("There is one class of "),If=a("code"),PI=o("AutoModel"),Gno=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ioo=l(),pd=a("h2"),Nf=a("a"),zce=a("span"),F(Ax.$$.fragment),Ono=l(),Qce=a("span"),Vno=o("Extending the Auto Classes"),doo=l(),ds=a("p"),Xno=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Wce=a("code"),zno=o("NewModel"),Qno=o(", make sure you have a "),Uce=a("code"),Wno=o("NewModelConfig"),Uno=o(` then you can add those to the auto
classes like this:`),coo=l(),F(Lx.$$.fragment),moo=l(),BI=a("p"),Hno=o("You will then be able to use the auto classes like you would usually do!"),foo=l(),F(qf.$$.fragment),goo=l(),_d=a("h2"),jf=a("a"),Hce=a("span"),F(yx.$$.fragment),Jno=l(),Jce=a("span"),Yno=o("AutoConfig"),hoo=l(),ko=a("div"),F(xx.$$.fragment),Zno=l(),$x=a("p"),Kno=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),II=a("a"),eso=o("from_pretrained()"),oso=o(" class method."),rso=l(),kx=a("p"),tso=o("This class cannot be instantiated directly using "),Yce=a("code"),aso=o("__init__()"),nso=o(" (throws an error)."),sso=l(),Ir=a("div"),F(Sx.$$.fragment),lso=l(),Zce=a("p"),iso=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),dso=l(),bd=a("p"),cso=o("The configuration class to instantiate is selected based on the "),Kce=a("code"),mso=o("model_type"),fso=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),eme=a("code"),gso=o("pretrained_model_name_or_path"),hso=o(":"),uso=l(),A=a("ul"),Df=a("li"),ome=a("strong"),pso=o("albert"),_so=o(" \u2014 "),NI=a("a"),bso=o("AlbertConfig"),vso=o(" (ALBERT model)"),Fso=l(),Gf=a("li"),rme=a("strong"),Tso=o("bart"),Mso=o(" \u2014 "),qI=a("a"),Eso=o("BartConfig"),Cso=o(" (BART model)"),wso=l(),Of=a("li"),tme=a("strong"),Aso=o("beit"),Lso=o(" \u2014 "),jI=a("a"),yso=o("BeitConfig"),xso=o(" (BEiT model)"),$so=l(),Vf=a("li"),ame=a("strong"),kso=o("bert"),Sso=o(" \u2014 "),DI=a("a"),Rso=o("BertConfig"),Pso=o(" (BERT model)"),Bso=l(),Xf=a("li"),nme=a("strong"),Iso=o("bert-generation"),Nso=o(" \u2014 "),GI=a("a"),qso=o("BertGenerationConfig"),jso=o(" (Bert Generation model)"),Dso=l(),zf=a("li"),sme=a("strong"),Gso=o("big_bird"),Oso=o(" \u2014 "),OI=a("a"),Vso=o("BigBirdConfig"),Xso=o(" (BigBird model)"),zso=l(),Qf=a("li"),lme=a("strong"),Qso=o("bigbird_pegasus"),Wso=o(" \u2014 "),VI=a("a"),Uso=o("BigBirdPegasusConfig"),Hso=o(" (BigBird-Pegasus model)"),Jso=l(),Wf=a("li"),ime=a("strong"),Yso=o("blenderbot"),Zso=o(" \u2014 "),XI=a("a"),Kso=o("BlenderbotConfig"),elo=o(" (Blenderbot model)"),olo=l(),Uf=a("li"),dme=a("strong"),rlo=o("blenderbot-small"),tlo=o(" \u2014 "),zI=a("a"),alo=o("BlenderbotSmallConfig"),nlo=o(" (BlenderbotSmall model)"),slo=l(),Hf=a("li"),cme=a("strong"),llo=o("bloom"),ilo=o(" \u2014 "),QI=a("a"),dlo=o("BloomConfig"),clo=o(" (BLOOM model)"),mlo=l(),Jf=a("li"),mme=a("strong"),flo=o("camembert"),glo=o(" \u2014 "),WI=a("a"),hlo=o("CamembertConfig"),ulo=o(" (CamemBERT model)"),plo=l(),Yf=a("li"),fme=a("strong"),_lo=o("canine"),blo=o(" \u2014 "),UI=a("a"),vlo=o("CanineConfig"),Flo=o(" (CANINE model)"),Tlo=l(),Zf=a("li"),gme=a("strong"),Mlo=o("clip"),Elo=o(" \u2014 "),HI=a("a"),Clo=o("CLIPConfig"),wlo=o(" (CLIP model)"),Alo=l(),Kf=a("li"),hme=a("strong"),Llo=o("codegen"),ylo=o(" \u2014 "),JI=a("a"),xlo=o("CodeGenConfig"),$lo=o(" (CodeGen model)"),klo=l(),eg=a("li"),ume=a("strong"),Slo=o("conditional_detr"),Rlo=o(" \u2014 "),YI=a("a"),Plo=o("ConditionalDetrConfig"),Blo=o(" (Conditional DETR model)"),Ilo=l(),og=a("li"),pme=a("strong"),Nlo=o("convbert"),qlo=o(" \u2014 "),ZI=a("a"),jlo=o("ConvBertConfig"),Dlo=o(" (ConvBERT model)"),Glo=l(),rg=a("li"),_me=a("strong"),Olo=o("convnext"),Vlo=o(" \u2014 "),KI=a("a"),Xlo=o("ConvNextConfig"),zlo=o(" (ConvNeXT model)"),Qlo=l(),tg=a("li"),bme=a("strong"),Wlo=o("ctrl"),Ulo=o(" \u2014 "),eN=a("a"),Hlo=o("CTRLConfig"),Jlo=o(" (CTRL model)"),Ylo=l(),ag=a("li"),vme=a("strong"),Zlo=o("cvt"),Klo=o(" \u2014 "),oN=a("a"),eio=o("CvtConfig"),oio=o(" (CvT model)"),rio=l(),ng=a("li"),Fme=a("strong"),tio=o("data2vec-audio"),aio=o(" \u2014 "),rN=a("a"),nio=o("Data2VecAudioConfig"),sio=o(" (Data2VecAudio model)"),lio=l(),sg=a("li"),Tme=a("strong"),iio=o("data2vec-text"),dio=o(" \u2014 "),tN=a("a"),cio=o("Data2VecTextConfig"),mio=o(" (Data2VecText model)"),fio=l(),lg=a("li"),Mme=a("strong"),gio=o("data2vec-vision"),hio=o(" \u2014 "),aN=a("a"),uio=o("Data2VecVisionConfig"),pio=o(" (Data2VecVision model)"),_io=l(),ig=a("li"),Eme=a("strong"),bio=o("deberta"),vio=o(" \u2014 "),nN=a("a"),Fio=o("DebertaConfig"),Tio=o(" (DeBERTa model)"),Mio=l(),dg=a("li"),Cme=a("strong"),Eio=o("deberta-v2"),Cio=o(" \u2014 "),sN=a("a"),wio=o("DebertaV2Config"),Aio=o(" (DeBERTa-v2 model)"),Lio=l(),cg=a("li"),wme=a("strong"),yio=o("decision_transformer"),xio=o(" \u2014 "),lN=a("a"),$io=o("DecisionTransformerConfig"),kio=o(" (Decision Transformer model)"),Sio=l(),mg=a("li"),Ame=a("strong"),Rio=o("deformable_detr"),Pio=o(" \u2014 "),iN=a("a"),Bio=o("DeformableDetrConfig"),Iio=o(" (Deformable DETR model)"),Nio=l(),fg=a("li"),Lme=a("strong"),qio=o("deit"),jio=o(" \u2014 "),dN=a("a"),Dio=o("DeiTConfig"),Gio=o(" (DeiT model)"),Oio=l(),gg=a("li"),yme=a("strong"),Vio=o("detr"),Xio=o(" \u2014 "),cN=a("a"),zio=o("DetrConfig"),Qio=o(" (DETR model)"),Wio=l(),hg=a("li"),xme=a("strong"),Uio=o("distilbert"),Hio=o(" \u2014 "),mN=a("a"),Jio=o("DistilBertConfig"),Yio=o(" (DistilBERT model)"),Zio=l(),ug=a("li"),$me=a("strong"),Kio=o("donut-swin"),edo=o(" \u2014 "),fN=a("a"),odo=o("DonutSwinConfig"),rdo=o(" (DonutSwin model)"),tdo=l(),pg=a("li"),kme=a("strong"),ado=o("dpr"),ndo=o(" \u2014 "),gN=a("a"),sdo=o("DPRConfig"),ldo=o(" (DPR model)"),ido=l(),_g=a("li"),Sme=a("strong"),ddo=o("dpt"),cdo=o(" \u2014 "),hN=a("a"),mdo=o("DPTConfig"),fdo=o(" (DPT model)"),gdo=l(),bg=a("li"),Rme=a("strong"),hdo=o("electra"),udo=o(" \u2014 "),uN=a("a"),pdo=o("ElectraConfig"),_do=o(" (ELECTRA model)"),bdo=l(),vg=a("li"),Pme=a("strong"),vdo=o("encoder-decoder"),Fdo=o(" \u2014 "),pN=a("a"),Tdo=o("EncoderDecoderConfig"),Mdo=o(" (Encoder decoder model)"),Edo=l(),Fg=a("li"),Bme=a("strong"),Cdo=o("ernie"),wdo=o(" \u2014 "),_N=a("a"),Ado=o("ErnieConfig"),Ldo=o(" (ERNIE model)"),ydo=l(),Tg=a("li"),Ime=a("strong"),xdo=o("esm"),$do=o(" \u2014 "),bN=a("a"),kdo=o("EsmConfig"),Sdo=o(" (ESM model)"),Rdo=l(),Mg=a("li"),Nme=a("strong"),Pdo=o("flaubert"),Bdo=o(" \u2014 "),vN=a("a"),Ido=o("FlaubertConfig"),Ndo=o(" (FlauBERT model)"),qdo=l(),Eg=a("li"),qme=a("strong"),jdo=o("flava"),Ddo=o(" \u2014 "),FN=a("a"),Gdo=o("FlavaConfig"),Odo=o(" (FLAVA model)"),Vdo=l(),Cg=a("li"),jme=a("strong"),Xdo=o("fnet"),zdo=o(" \u2014 "),TN=a("a"),Qdo=o("FNetConfig"),Wdo=o(" (FNet model)"),Udo=l(),wg=a("li"),Dme=a("strong"),Hdo=o("fsmt"),Jdo=o(" \u2014 "),MN=a("a"),Ydo=o("FSMTConfig"),Zdo=o(" (FairSeq Machine-Translation model)"),Kdo=l(),Ag=a("li"),Gme=a("strong"),eco=o("funnel"),oco=o(" \u2014 "),EN=a("a"),rco=o("FunnelConfig"),tco=o(" (Funnel Transformer model)"),aco=l(),Lg=a("li"),Ome=a("strong"),nco=o("glpn"),sco=o(" \u2014 "),CN=a("a"),lco=o("GLPNConfig"),ico=o(" (GLPN model)"),dco=l(),yg=a("li"),Vme=a("strong"),cco=o("gpt2"),mco=o(" \u2014 "),wN=a("a"),fco=o("GPT2Config"),gco=o(" (OpenAI GPT-2 model)"),hco=l(),xg=a("li"),Xme=a("strong"),uco=o("gpt_neo"),pco=o(" \u2014 "),AN=a("a"),_co=o("GPTNeoConfig"),bco=o(" (GPT Neo model)"),vco=l(),$g=a("li"),zme=a("strong"),Fco=o("gpt_neox"),Tco=o(" \u2014 "),LN=a("a"),Mco=o("GPTNeoXConfig"),Eco=o(" (GPT NeoX model)"),Cco=l(),kg=a("li"),Qme=a("strong"),wco=o("gpt_neox_japanese"),Aco=o(" \u2014 "),yN=a("a"),Lco=o("GPTNeoXJapaneseConfig"),yco=o(" (GPT NeoX Japanese model)"),xco=l(),Sg=a("li"),Wme=a("strong"),$co=o("gptj"),kco=o(" \u2014 "),xN=a("a"),Sco=o("GPTJConfig"),Rco=o(" (GPT-J model)"),Pco=l(),Rg=a("li"),Ume=a("strong"),Bco=o("groupvit"),Ico=o(" \u2014 "),$N=a("a"),Nco=o("GroupViTConfig"),qco=o(" (GroupViT model)"),jco=l(),Pg=a("li"),Hme=a("strong"),Dco=o("hubert"),Gco=o(" \u2014 "),kN=a("a"),Oco=o("HubertConfig"),Vco=o(" (Hubert model)"),Xco=l(),Bg=a("li"),Jme=a("strong"),zco=o("ibert"),Qco=o(" \u2014 "),SN=a("a"),Wco=o("IBertConfig"),Uco=o(" (I-BERT model)"),Hco=l(),Ig=a("li"),Yme=a("strong"),Jco=o("imagegpt"),Yco=o(" \u2014 "),RN=a("a"),Zco=o("ImageGPTConfig"),Kco=o(" (ImageGPT model)"),emo=l(),Ng=a("li"),Zme=a("strong"),omo=o("layoutlm"),rmo=o(" \u2014 "),PN=a("a"),tmo=o("LayoutLMConfig"),amo=o(" (LayoutLM model)"),nmo=l(),qg=a("li"),Kme=a("strong"),smo=o("layoutlmv2"),lmo=o(" \u2014 "),BN=a("a"),imo=o("LayoutLMv2Config"),dmo=o(" (LayoutLMv2 model)"),cmo=l(),jg=a("li"),efe=a("strong"),mmo=o("layoutlmv3"),fmo=o(" \u2014 "),IN=a("a"),gmo=o("LayoutLMv3Config"),hmo=o(" (LayoutLMv3 model)"),umo=l(),Dg=a("li"),ofe=a("strong"),pmo=o("led"),_mo=o(" \u2014 "),NN=a("a"),bmo=o("LEDConfig"),vmo=o(" (LED model)"),Fmo=l(),Gg=a("li"),rfe=a("strong"),Tmo=o("levit"),Mmo=o(" \u2014 "),qN=a("a"),Emo=o("LevitConfig"),Cmo=o(" (LeViT model)"),wmo=l(),Og=a("li"),tfe=a("strong"),Amo=o("longformer"),Lmo=o(" \u2014 "),jN=a("a"),ymo=o("LongformerConfig"),xmo=o(" (Longformer model)"),$mo=l(),Vg=a("li"),afe=a("strong"),kmo=o("longt5"),Smo=o(" \u2014 "),DN=a("a"),Rmo=o("LongT5Config"),Pmo=o(" (LongT5 model)"),Bmo=l(),Xg=a("li"),nfe=a("strong"),Imo=o("luke"),Nmo=o(" \u2014 "),GN=a("a"),qmo=o("LukeConfig"),jmo=o(" (LUKE model)"),Dmo=l(),zg=a("li"),sfe=a("strong"),Gmo=o("lxmert"),Omo=o(" \u2014 "),ON=a("a"),Vmo=o("LxmertConfig"),Xmo=o(" (LXMERT model)"),zmo=l(),Qg=a("li"),lfe=a("strong"),Qmo=o("m2m_100"),Wmo=o(" \u2014 "),VN=a("a"),Umo=o("M2M100Config"),Hmo=o(" (M2M100 model)"),Jmo=l(),Wg=a("li"),ife=a("strong"),Ymo=o("marian"),Zmo=o(" \u2014 "),XN=a("a"),Kmo=o("MarianConfig"),efo=o(" (Marian model)"),ofo=l(),Ug=a("li"),dfe=a("strong"),rfo=o("markuplm"),tfo=o(" \u2014 "),zN=a("a"),afo=o("MarkupLMConfig"),nfo=o(" (MarkupLM model)"),sfo=l(),Hg=a("li"),cfe=a("strong"),lfo=o("maskformer"),ifo=o(" \u2014 "),QN=a("a"),dfo=o("MaskFormerConfig"),cfo=o(" (MaskFormer model)"),mfo=l(),Jg=a("li"),mfe=a("strong"),ffo=o("mbart"),gfo=o(" \u2014 "),WN=a("a"),hfo=o("MBartConfig"),ufo=o(" (mBART model)"),pfo=l(),Yg=a("li"),ffe=a("strong"),_fo=o("mctct"),bfo=o(" \u2014 "),UN=a("a"),vfo=o("MCTCTConfig"),Ffo=o(" (M-CTC-T model)"),Tfo=l(),Zg=a("li"),gfe=a("strong"),Mfo=o("megatron-bert"),Efo=o(" \u2014 "),HN=a("a"),Cfo=o("MegatronBertConfig"),wfo=o(" (Megatron-BERT model)"),Afo=l(),Kg=a("li"),hfe=a("strong"),Lfo=o("mobilebert"),yfo=o(" \u2014 "),JN=a("a"),xfo=o("MobileBertConfig"),$fo=o(" (MobileBERT model)"),kfo=l(),eh=a("li"),ufe=a("strong"),Sfo=o("mobilevit"),Rfo=o(" \u2014 "),YN=a("a"),Pfo=o("MobileViTConfig"),Bfo=o(" (MobileViT model)"),Ifo=l(),oh=a("li"),pfe=a("strong"),Nfo=o("mpnet"),qfo=o(" \u2014 "),ZN=a("a"),jfo=o("MPNetConfig"),Dfo=o(" (MPNet model)"),Gfo=l(),rh=a("li"),_fe=a("strong"),Ofo=o("mt5"),Vfo=o(" \u2014 "),KN=a("a"),Xfo=o("MT5Config"),zfo=o(" (MT5 model)"),Qfo=l(),th=a("li"),bfe=a("strong"),Wfo=o("mvp"),Ufo=o(" \u2014 "),eq=a("a"),Hfo=o("MvpConfig"),Jfo=o(" (MVP model)"),Yfo=l(),ah=a("li"),vfe=a("strong"),Zfo=o("nezha"),Kfo=o(" \u2014 "),oq=a("a"),ego=o("NezhaConfig"),ogo=o(" (Nezha model)"),rgo=l(),nh=a("li"),Ffe=a("strong"),tgo=o("nystromformer"),ago=o(" \u2014 "),rq=a("a"),ngo=o("NystromformerConfig"),sgo=o(" (Nystr\xF6mformer model)"),lgo=l(),sh=a("li"),Tfe=a("strong"),igo=o("openai-gpt"),dgo=o(" \u2014 "),tq=a("a"),cgo=o("OpenAIGPTConfig"),mgo=o(" (OpenAI GPT model)"),fgo=l(),lh=a("li"),Mfe=a("strong"),ggo=o("opt"),hgo=o(" \u2014 "),aq=a("a"),ugo=o("OPTConfig"),pgo=o(" (OPT model)"),_go=l(),ih=a("li"),Efe=a("strong"),bgo=o("owlvit"),vgo=o(" \u2014 "),nq=a("a"),Fgo=o("OwlViTConfig"),Tgo=o(" (OWL-ViT model)"),Mgo=l(),dh=a("li"),Cfe=a("strong"),Ego=o("pegasus"),Cgo=o(" \u2014 "),sq=a("a"),wgo=o("PegasusConfig"),Ago=o(" (Pegasus model)"),Lgo=l(),ch=a("li"),wfe=a("strong"),ygo=o("pegasus_x"),xgo=o(" \u2014 "),lq=a("a"),$go=o("PegasusXConfig"),kgo=o(" (PEGASUS-X model)"),Sgo=l(),mh=a("li"),Afe=a("strong"),Rgo=o("perceiver"),Pgo=o(" \u2014 "),iq=a("a"),Bgo=o("PerceiverConfig"),Igo=o(" (Perceiver model)"),Ngo=l(),fh=a("li"),Lfe=a("strong"),qgo=o("plbart"),jgo=o(" \u2014 "),dq=a("a"),Dgo=o("PLBartConfig"),Ggo=o(" (PLBart model)"),Ogo=l(),gh=a("li"),yfe=a("strong"),Vgo=o("poolformer"),Xgo=o(" \u2014 "),cq=a("a"),zgo=o("PoolFormerConfig"),Qgo=o(" (PoolFormer model)"),Wgo=l(),hh=a("li"),xfe=a("strong"),Ugo=o("prophetnet"),Hgo=o(" \u2014 "),mq=a("a"),Jgo=o("ProphetNetConfig"),Ygo=o(" (ProphetNet model)"),Zgo=l(),uh=a("li"),$fe=a("strong"),Kgo=o("qdqbert"),eho=o(" \u2014 "),fq=a("a"),oho=o("QDQBertConfig"),rho=o(" (QDQBert model)"),tho=l(),ph=a("li"),kfe=a("strong"),aho=o("rag"),nho=o(" \u2014 "),gq=a("a"),sho=o("RagConfig"),lho=o(" (RAG model)"),iho=l(),_h=a("li"),Sfe=a("strong"),dho=o("realm"),cho=o(" \u2014 "),hq=a("a"),mho=o("RealmConfig"),fho=o(" (REALM model)"),gho=l(),bh=a("li"),Rfe=a("strong"),hho=o("reformer"),uho=o(" \u2014 "),uq=a("a"),pho=o("ReformerConfig"),_ho=o(" (Reformer model)"),bho=l(),vh=a("li"),Pfe=a("strong"),vho=o("regnet"),Fho=o(" \u2014 "),pq=a("a"),Tho=o("RegNetConfig"),Mho=o(" (RegNet model)"),Eho=l(),Fh=a("li"),Bfe=a("strong"),Cho=o("rembert"),who=o(" \u2014 "),_q=a("a"),Aho=o("RemBertConfig"),Lho=o(" (RemBERT model)"),yho=l(),Th=a("li"),Ife=a("strong"),xho=o("resnet"),$ho=o(" \u2014 "),bq=a("a"),kho=o("ResNetConfig"),Sho=o(" (ResNet model)"),Rho=l(),Mh=a("li"),Nfe=a("strong"),Pho=o("retribert"),Bho=o(" \u2014 "),vq=a("a"),Iho=o("RetriBertConfig"),Nho=o(" (RetriBERT model)"),qho=l(),Eh=a("li"),qfe=a("strong"),jho=o("roberta"),Dho=o(" \u2014 "),Fq=a("a"),Gho=o("RobertaConfig"),Oho=o(" (RoBERTa model)"),Vho=l(),Ch=a("li"),jfe=a("strong"),Xho=o("roformer"),zho=o(" \u2014 "),Tq=a("a"),Qho=o("RoFormerConfig"),Who=o(" (RoFormer model)"),Uho=l(),wh=a("li"),Dfe=a("strong"),Hho=o("segformer"),Jho=o(" \u2014 "),Mq=a("a"),Yho=o("SegformerConfig"),Zho=o(" (SegFormer model)"),Kho=l(),Ah=a("li"),Gfe=a("strong"),euo=o("sew"),ouo=o(" \u2014 "),Eq=a("a"),ruo=o("SEWConfig"),tuo=o(" (SEW model)"),auo=l(),Lh=a("li"),Ofe=a("strong"),nuo=o("sew-d"),suo=o(" \u2014 "),Cq=a("a"),luo=o("SEWDConfig"),iuo=o(" (SEW-D model)"),duo=l(),yh=a("li"),Vfe=a("strong"),cuo=o("speech-encoder-decoder"),muo=o(" \u2014 "),wq=a("a"),fuo=o("SpeechEncoderDecoderConfig"),guo=o(" (Speech Encoder decoder model)"),huo=l(),xh=a("li"),Xfe=a("strong"),uuo=o("speech_to_text"),puo=o(" \u2014 "),Aq=a("a"),_uo=o("Speech2TextConfig"),buo=o(" (Speech2Text model)"),vuo=l(),$h=a("li"),zfe=a("strong"),Fuo=o("speech_to_text_2"),Tuo=o(" \u2014 "),Lq=a("a"),Muo=o("Speech2Text2Config"),Euo=o(" (Speech2Text2 model)"),Cuo=l(),kh=a("li"),Qfe=a("strong"),wuo=o("splinter"),Auo=o(" \u2014 "),yq=a("a"),Luo=o("SplinterConfig"),yuo=o(" (Splinter model)"),xuo=l(),Sh=a("li"),Wfe=a("strong"),$uo=o("squeezebert"),kuo=o(" \u2014 "),xq=a("a"),Suo=o("SqueezeBertConfig"),Ruo=o(" (SqueezeBERT model)"),Puo=l(),Rh=a("li"),Ufe=a("strong"),Buo=o("swin"),Iuo=o(" \u2014 "),$q=a("a"),Nuo=o("SwinConfig"),quo=o(" (Swin Transformer model)"),juo=l(),Ph=a("li"),Hfe=a("strong"),Duo=o("swinv2"),Guo=o(" \u2014 "),kq=a("a"),Ouo=o("Swinv2Config"),Vuo=o(" (Swin Transformer V2 model)"),Xuo=l(),Bh=a("li"),Jfe=a("strong"),zuo=o("t5"),Quo=o(" \u2014 "),Sq=a("a"),Wuo=o("T5Config"),Uuo=o(" (T5 model)"),Huo=l(),Ih=a("li"),Yfe=a("strong"),Juo=o("tapas"),Yuo=o(" \u2014 "),Rq=a("a"),Zuo=o("TapasConfig"),Kuo=o(" (TAPAS model)"),epo=l(),Nh=a("li"),Zfe=a("strong"),opo=o("time_series_transformer"),rpo=o(" \u2014 "),Pq=a("a"),tpo=o("TimeSeriesTransformerConfig"),apo=o(" (Time Series Transformer model)"),npo=l(),qh=a("li"),Kfe=a("strong"),spo=o("trajectory_transformer"),lpo=o(" \u2014 "),Bq=a("a"),ipo=o("TrajectoryTransformerConfig"),dpo=o(" (Trajectory Transformer model)"),cpo=l(),jh=a("li"),ege=a("strong"),mpo=o("transfo-xl"),fpo=o(" \u2014 "),Iq=a("a"),gpo=o("TransfoXLConfig"),hpo=o(" (Transformer-XL model)"),upo=l(),Dh=a("li"),oge=a("strong"),ppo=o("trocr"),_po=o(" \u2014 "),Nq=a("a"),bpo=o("TrOCRConfig"),vpo=o(" (TrOCR model)"),Fpo=l(),Gh=a("li"),rge=a("strong"),Tpo=o("unispeech"),Mpo=o(" \u2014 "),qq=a("a"),Epo=o("UniSpeechConfig"),Cpo=o(" (UniSpeech model)"),wpo=l(),Oh=a("li"),tge=a("strong"),Apo=o("unispeech-sat"),Lpo=o(" \u2014 "),jq=a("a"),ypo=o("UniSpeechSatConfig"),xpo=o(" (UniSpeechSat model)"),$po=l(),Vh=a("li"),age=a("strong"),kpo=o("van"),Spo=o(" \u2014 "),Dq=a("a"),Rpo=o("VanConfig"),Ppo=o(" (VAN model)"),Bpo=l(),Xh=a("li"),nge=a("strong"),Ipo=o("videomae"),Npo=o(" \u2014 "),Gq=a("a"),qpo=o("VideoMAEConfig"),jpo=o(" (VideoMAE model)"),Dpo=l(),zh=a("li"),sge=a("strong"),Gpo=o("vilt"),Opo=o(" \u2014 "),Oq=a("a"),Vpo=o("ViltConfig"),Xpo=o(" (ViLT model)"),zpo=l(),Qh=a("li"),lge=a("strong"),Qpo=o("vision-encoder-decoder"),Wpo=o(" \u2014 "),Vq=a("a"),Upo=o("VisionEncoderDecoderConfig"),Hpo=o(" (Vision Encoder decoder model)"),Jpo=l(),Wh=a("li"),ige=a("strong"),Ypo=o("vision-text-dual-encoder"),Zpo=o(" \u2014 "),Xq=a("a"),Kpo=o("VisionTextDualEncoderConfig"),e_o=o(" (VisionTextDualEncoder model)"),o_o=l(),Uh=a("li"),dge=a("strong"),r_o=o("visual_bert"),t_o=o(" \u2014 "),zq=a("a"),a_o=o("VisualBertConfig"),n_o=o(" (VisualBERT model)"),s_o=l(),Hh=a("li"),cge=a("strong"),l_o=o("vit"),i_o=o(" \u2014 "),Qq=a("a"),d_o=o("ViTConfig"),c_o=o(" (ViT model)"),m_o=l(),Jh=a("li"),mge=a("strong"),f_o=o("vit_mae"),g_o=o(" \u2014 "),Wq=a("a"),h_o=o("ViTMAEConfig"),u_o=o(" (ViTMAE model)"),p_o=l(),Yh=a("li"),fge=a("strong"),__o=o("vit_msn"),b_o=o(" \u2014 "),Uq=a("a"),v_o=o("ViTMSNConfig"),F_o=o(" (ViTMSN model)"),T_o=l(),Zh=a("li"),gge=a("strong"),M_o=o("wav2vec2"),E_o=o(" \u2014 "),Hq=a("a"),C_o=o("Wav2Vec2Config"),w_o=o(" (Wav2Vec2 model)"),A_o=l(),Kh=a("li"),hge=a("strong"),L_o=o("wav2vec2-conformer"),y_o=o(" \u2014 "),Jq=a("a"),x_o=o("Wav2Vec2ConformerConfig"),$_o=o(" (Wav2Vec2-Conformer model)"),k_o=l(),eu=a("li"),uge=a("strong"),S_o=o("wavlm"),R_o=o(" \u2014 "),Yq=a("a"),P_o=o("WavLMConfig"),B_o=o(" (WavLM model)"),I_o=l(),ou=a("li"),pge=a("strong"),N_o=o("whisper"),q_o=o(" \u2014 "),Zq=a("a"),j_o=o("WhisperConfig"),D_o=o(" (Whisper model)"),G_o=l(),ru=a("li"),_ge=a("strong"),O_o=o("xclip"),V_o=o(" \u2014 "),Kq=a("a"),X_o=o("XCLIPConfig"),z_o=o(" (X-CLIP model)"),Q_o=l(),tu=a("li"),bge=a("strong"),W_o=o("xglm"),U_o=o(" \u2014 "),ej=a("a"),H_o=o("XGLMConfig"),J_o=o(" (XGLM model)"),Y_o=l(),au=a("li"),vge=a("strong"),Z_o=o("xlm"),K_o=o(" \u2014 "),oj=a("a"),e1o=o("XLMConfig"),o1o=o(" (XLM model)"),r1o=l(),nu=a("li"),Fge=a("strong"),t1o=o("xlm-prophetnet"),a1o=o(" \u2014 "),rj=a("a"),n1o=o("XLMProphetNetConfig"),s1o=o(" (XLM-ProphetNet model)"),l1o=l(),su=a("li"),Tge=a("strong"),i1o=o("xlm-roberta"),d1o=o(" \u2014 "),tj=a("a"),c1o=o("XLMRobertaConfig"),m1o=o(" (XLM-RoBERTa model)"),f1o=l(),lu=a("li"),Mge=a("strong"),g1o=o("xlm-roberta-xl"),h1o=o(" \u2014 "),aj=a("a"),u1o=o("XLMRobertaXLConfig"),p1o=o(" (XLM-RoBERTa-XL model)"),_1o=l(),iu=a("li"),Ege=a("strong"),b1o=o("xlnet"),v1o=o(" \u2014 "),nj=a("a"),F1o=o("XLNetConfig"),T1o=o(" (XLNet model)"),M1o=l(),du=a("li"),Cge=a("strong"),E1o=o("yolos"),C1o=o(" \u2014 "),sj=a("a"),w1o=o("YolosConfig"),A1o=o(" (YOLOS model)"),L1o=l(),cu=a("li"),wge=a("strong"),y1o=o("yoso"),x1o=o(" \u2014 "),lj=a("a"),$1o=o("YosoConfig"),k1o=o(" (YOSO model)"),S1o=l(),F(mu.$$.fragment),R1o=l(),fu=a("div"),F(Rx.$$.fragment),P1o=l(),Age=a("p"),B1o=o("Register a new configuration for this class."),uoo=l(),vd=a("h2"),gu=a("a"),Lge=a("span"),F(Px.$$.fragment),I1o=l(),yge=a("span"),N1o=o("AutoTokenizer"),poo=l(),So=a("div"),F(Bx.$$.fragment),q1o=l(),Ix=a("p"),j1o=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ij=a("a"),D1o=o("AutoTokenizer.from_pretrained()"),G1o=o(" class method."),O1o=l(),Nx=a("p"),V1o=o("This class cannot be instantiated directly using "),xge=a("code"),X1o=o("__init__()"),z1o=o(" (throws an error)."),Q1o=l(),Nr=a("div"),F(qx.$$.fragment),W1o=l(),$ge=a("p"),U1o=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),H1o=l(),Za=a("p"),J1o=o("The tokenizer class to instantiate is selected based on the "),kge=a("code"),Y1o=o("model_type"),Z1o=o(` property of the config object (either
passed as an argument or loaded from `),Sge=a("code"),K1o=o("pretrained_model_name_or_path"),ebo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rge=a("code"),obo=o("pretrained_model_name_or_path"),rbo=o(":"),tbo=l(),k=a("ul"),cs=a("li"),Pge=a("strong"),abo=o("albert"),nbo=o(" \u2014 "),dj=a("a"),sbo=o("AlbertTokenizer"),lbo=o(" or "),cj=a("a"),ibo=o("AlbertTokenizerFast"),dbo=o(" (ALBERT model)"),cbo=l(),ms=a("li"),Bge=a("strong"),mbo=o("bart"),fbo=o(" \u2014 "),mj=a("a"),gbo=o("BartTokenizer"),hbo=o(" or "),fj=a("a"),ubo=o("BartTokenizerFast"),pbo=o(" (BART model)"),_bo=l(),fs=a("li"),Ige=a("strong"),bbo=o("barthez"),vbo=o(" \u2014 "),gj=a("a"),Fbo=o("BarthezTokenizer"),Tbo=o(" or "),hj=a("a"),Mbo=o("BarthezTokenizerFast"),Ebo=o(" (BARThez model)"),Cbo=l(),hu=a("li"),Nge=a("strong"),wbo=o("bartpho"),Abo=o(" \u2014 "),uj=a("a"),Lbo=o("BartphoTokenizer"),ybo=o(" (BARTpho model)"),xbo=l(),gs=a("li"),qge=a("strong"),$bo=o("bert"),kbo=o(" \u2014 "),pj=a("a"),Sbo=o("BertTokenizer"),Rbo=o(" or "),_j=a("a"),Pbo=o("BertTokenizerFast"),Bbo=o(" (BERT model)"),Ibo=l(),uu=a("li"),jge=a("strong"),Nbo=o("bert-generation"),qbo=o(" \u2014 "),bj=a("a"),jbo=o("BertGenerationTokenizer"),Dbo=o(" (Bert Generation model)"),Gbo=l(),pu=a("li"),Dge=a("strong"),Obo=o("bert-japanese"),Vbo=o(" \u2014 "),vj=a("a"),Xbo=o("BertJapaneseTokenizer"),zbo=o(" (BertJapanese model)"),Qbo=l(),_u=a("li"),Gge=a("strong"),Wbo=o("bertweet"),Ubo=o(" \u2014 "),Fj=a("a"),Hbo=o("BertweetTokenizer"),Jbo=o(" (BERTweet model)"),Ybo=l(),hs=a("li"),Oge=a("strong"),Zbo=o("big_bird"),Kbo=o(" \u2014 "),Tj=a("a"),e2o=o("BigBirdTokenizer"),o2o=o(" or "),Mj=a("a"),r2o=o("BigBirdTokenizerFast"),t2o=o(" (BigBird model)"),a2o=l(),us=a("li"),Vge=a("strong"),n2o=o("bigbird_pegasus"),s2o=o(" \u2014 "),Ej=a("a"),l2o=o("PegasusTokenizer"),i2o=o(" or "),Cj=a("a"),d2o=o("PegasusTokenizerFast"),c2o=o(" (BigBird-Pegasus model)"),m2o=l(),ps=a("li"),Xge=a("strong"),f2o=o("blenderbot"),g2o=o(" \u2014 "),wj=a("a"),h2o=o("BlenderbotTokenizer"),u2o=o(" or "),Aj=a("a"),p2o=o("BlenderbotTokenizerFast"),_2o=o(" (Blenderbot model)"),b2o=l(),bu=a("li"),zge=a("strong"),v2o=o("blenderbot-small"),F2o=o(" \u2014 "),Lj=a("a"),T2o=o("BlenderbotSmallTokenizer"),M2o=o(" (BlenderbotSmall model)"),E2o=l(),vu=a("li"),Qge=a("strong"),C2o=o("bloom"),w2o=o(" \u2014 "),yj=a("a"),A2o=o("BloomTokenizerFast"),L2o=o(" (BLOOM model)"),y2o=l(),Fu=a("li"),Wge=a("strong"),x2o=o("byt5"),$2o=o(" \u2014 "),xj=a("a"),k2o=o("ByT5Tokenizer"),S2o=o(" (ByT5 model)"),R2o=l(),_s=a("li"),Uge=a("strong"),P2o=o("camembert"),B2o=o(" \u2014 "),$j=a("a"),I2o=o("CamembertTokenizer"),N2o=o(" or "),kj=a("a"),q2o=o("CamembertTokenizerFast"),j2o=o(" (CamemBERT model)"),D2o=l(),Tu=a("li"),Hge=a("strong"),G2o=o("canine"),O2o=o(" \u2014 "),Sj=a("a"),V2o=o("CanineTokenizer"),X2o=o(" (CANINE model)"),z2o=l(),bs=a("li"),Jge=a("strong"),Q2o=o("clip"),W2o=o(" \u2014 "),Rj=a("a"),U2o=o("CLIPTokenizer"),H2o=o(" or "),Pj=a("a"),J2o=o("CLIPTokenizerFast"),Y2o=o(" (CLIP model)"),Z2o=l(),vs=a("li"),Yge=a("strong"),K2o=o("codegen"),evo=o(" \u2014 "),Bj=a("a"),ovo=o("CodeGenTokenizer"),rvo=o(" or "),Ij=a("a"),tvo=o("CodeGenTokenizerFast"),avo=o(" (CodeGen model)"),nvo=l(),Fs=a("li"),Zge=a("strong"),svo=o("convbert"),lvo=o(" \u2014 "),Nj=a("a"),ivo=o("ConvBertTokenizer"),dvo=o(" or "),qj=a("a"),cvo=o("ConvBertTokenizerFast"),mvo=o(" (ConvBERT model)"),fvo=l(),Ts=a("li"),Kge=a("strong"),gvo=o("cpm"),hvo=o(" \u2014 "),jj=a("a"),uvo=o("CpmTokenizer"),pvo=o(" or "),Dj=a("a"),_vo=o("CpmTokenizerFast"),bvo=o(" (CPM model)"),vvo=l(),Mu=a("li"),ehe=a("strong"),Fvo=o("ctrl"),Tvo=o(" \u2014 "),Gj=a("a"),Mvo=o("CTRLTokenizer"),Evo=o(" (CTRL model)"),Cvo=l(),Ms=a("li"),ohe=a("strong"),wvo=o("data2vec-text"),Avo=o(" \u2014 "),Oj=a("a"),Lvo=o("RobertaTokenizer"),yvo=o(" or "),Vj=a("a"),xvo=o("RobertaTokenizerFast"),$vo=o(" (Data2VecText model)"),kvo=l(),Es=a("li"),rhe=a("strong"),Svo=o("deberta"),Rvo=o(" \u2014 "),Xj=a("a"),Pvo=o("DebertaTokenizer"),Bvo=o(" or "),zj=a("a"),Ivo=o("DebertaTokenizerFast"),Nvo=o(" (DeBERTa model)"),qvo=l(),Cs=a("li"),the=a("strong"),jvo=o("deberta-v2"),Dvo=o(" \u2014 "),Qj=a("a"),Gvo=o("DebertaV2Tokenizer"),Ovo=o(" or "),Wj=a("a"),Vvo=o("DebertaV2TokenizerFast"),Xvo=o(" (DeBERTa-v2 model)"),zvo=l(),ws=a("li"),ahe=a("strong"),Qvo=o("distilbert"),Wvo=o(" \u2014 "),Uj=a("a"),Uvo=o("DistilBertTokenizer"),Hvo=o(" or "),Hj=a("a"),Jvo=o("DistilBertTokenizerFast"),Yvo=o(" (DistilBERT model)"),Zvo=l(),As=a("li"),nhe=a("strong"),Kvo=o("dpr"),eFo=o(" \u2014 "),Jj=a("a"),oFo=o("DPRQuestionEncoderTokenizer"),rFo=o(" or "),Yj=a("a"),tFo=o("DPRQuestionEncoderTokenizerFast"),aFo=o(" (DPR model)"),nFo=l(),Ls=a("li"),she=a("strong"),sFo=o("electra"),lFo=o(" \u2014 "),Zj=a("a"),iFo=o("ElectraTokenizer"),dFo=o(" or "),Kj=a("a"),cFo=o("ElectraTokenizerFast"),mFo=o(" (ELECTRA model)"),fFo=l(),ys=a("li"),lhe=a("strong"),gFo=o("ernie"),hFo=o(" \u2014 "),eD=a("a"),uFo=o("BertTokenizer"),pFo=o(" or "),oD=a("a"),_Fo=o("BertTokenizerFast"),bFo=o(" (ERNIE model)"),vFo=l(),Eu=a("li"),ihe=a("strong"),FFo=o("flaubert"),TFo=o(" \u2014 "),rD=a("a"),MFo=o("FlaubertTokenizer"),EFo=o(" (FlauBERT model)"),CFo=l(),xs=a("li"),dhe=a("strong"),wFo=o("fnet"),AFo=o(" \u2014 "),tD=a("a"),LFo=o("FNetTokenizer"),yFo=o(" or "),aD=a("a"),xFo=o("FNetTokenizerFast"),$Fo=o(" (FNet model)"),kFo=l(),Cu=a("li"),che=a("strong"),SFo=o("fsmt"),RFo=o(" \u2014 "),nD=a("a"),PFo=o("FSMTTokenizer"),BFo=o(" (FairSeq Machine-Translation model)"),IFo=l(),$s=a("li"),mhe=a("strong"),NFo=o("funnel"),qFo=o(" \u2014 "),sD=a("a"),jFo=o("FunnelTokenizer"),DFo=o(" or "),lD=a("a"),GFo=o("FunnelTokenizerFast"),OFo=o(" (Funnel Transformer model)"),VFo=l(),ks=a("li"),fhe=a("strong"),XFo=o("gpt2"),zFo=o(" \u2014 "),iD=a("a"),QFo=o("GPT2Tokenizer"),WFo=o(" or "),dD=a("a"),UFo=o("GPT2TokenizerFast"),HFo=o(" (OpenAI GPT-2 model)"),JFo=l(),Ss=a("li"),ghe=a("strong"),YFo=o("gpt_neo"),ZFo=o(" \u2014 "),cD=a("a"),KFo=o("GPT2Tokenizer"),eTo=o(" or "),mD=a("a"),oTo=o("GPT2TokenizerFast"),rTo=o(" (GPT Neo model)"),tTo=l(),wu=a("li"),hhe=a("strong"),aTo=o("gpt_neox"),nTo=o(" \u2014 "),fD=a("a"),sTo=o("GPTNeoXTokenizerFast"),lTo=o(" (GPT NeoX model)"),iTo=l(),Au=a("li"),uhe=a("strong"),dTo=o("gpt_neox_japanese"),cTo=o(" \u2014 "),gD=a("a"),mTo=o("GPTNeoXJapaneseTokenizer"),fTo=o(" (GPT NeoX Japanese model)"),gTo=l(),Rs=a("li"),phe=a("strong"),hTo=o("gptj"),uTo=o(" \u2014 "),hD=a("a"),pTo=o("GPT2Tokenizer"),_To=o(" or "),uD=a("a"),bTo=o("GPT2TokenizerFast"),vTo=o(" (GPT-J model)"),FTo=l(),Ps=a("li"),_he=a("strong"),TTo=o("groupvit"),MTo=o(" \u2014 "),pD=a("a"),ETo=o("CLIPTokenizer"),CTo=o(" or "),_D=a("a"),wTo=o("CLIPTokenizerFast"),ATo=o(" (GroupViT model)"),LTo=l(),Bs=a("li"),bhe=a("strong"),yTo=o("herbert"),xTo=o(" \u2014 "),bD=a("a"),$To=o("HerbertTokenizer"),kTo=o(" or "),vD=a("a"),STo=o("HerbertTokenizerFast"),RTo=o(" (HerBERT model)"),PTo=l(),Lu=a("li"),vhe=a("strong"),BTo=o("hubert"),ITo=o(" \u2014 "),FD=a("a"),NTo=o("Wav2Vec2CTCTokenizer"),qTo=o(" (Hubert model)"),jTo=l(),Is=a("li"),Fhe=a("strong"),DTo=o("ibert"),GTo=o(" \u2014 "),TD=a("a"),OTo=o("RobertaTokenizer"),VTo=o(" or "),MD=a("a"),XTo=o("RobertaTokenizerFast"),zTo=o(" (I-BERT model)"),QTo=l(),Ns=a("li"),The=a("strong"),WTo=o("layoutlm"),UTo=o(" \u2014 "),ED=a("a"),HTo=o("LayoutLMTokenizer"),JTo=o(" or "),CD=a("a"),YTo=o("LayoutLMTokenizerFast"),ZTo=o(" (LayoutLM model)"),KTo=l(),qs=a("li"),Mhe=a("strong"),eMo=o("layoutlmv2"),oMo=o(" \u2014 "),wD=a("a"),rMo=o("LayoutLMv2Tokenizer"),tMo=o(" or "),AD=a("a"),aMo=o("LayoutLMv2TokenizerFast"),nMo=o(" (LayoutLMv2 model)"),sMo=l(),js=a("li"),Ehe=a("strong"),lMo=o("layoutlmv3"),iMo=o(" \u2014 "),LD=a("a"),dMo=o("LayoutLMv3Tokenizer"),cMo=o(" or "),yD=a("a"),mMo=o("LayoutLMv3TokenizerFast"),fMo=o(" (LayoutLMv3 model)"),gMo=l(),Ds=a("li"),Che=a("strong"),hMo=o("layoutxlm"),uMo=o(" \u2014 "),xD=a("a"),pMo=o("LayoutXLMTokenizer"),_Mo=o(" or "),$D=a("a"),bMo=o("LayoutXLMTokenizerFast"),vMo=o(" (LayoutXLM model)"),FMo=l(),Gs=a("li"),whe=a("strong"),TMo=o("led"),MMo=o(" \u2014 "),kD=a("a"),EMo=o("LEDTokenizer"),CMo=o(" or "),SD=a("a"),wMo=o("LEDTokenizerFast"),AMo=o(" (LED model)"),LMo=l(),Os=a("li"),Ahe=a("strong"),yMo=o("longformer"),xMo=o(" \u2014 "),RD=a("a"),$Mo=o("LongformerTokenizer"),kMo=o(" or "),PD=a("a"),SMo=o("LongformerTokenizerFast"),RMo=o(" (Longformer model)"),PMo=l(),Vs=a("li"),Lhe=a("strong"),BMo=o("longt5"),IMo=o(" \u2014 "),BD=a("a"),NMo=o("T5Tokenizer"),qMo=o(" or "),ID=a("a"),jMo=o("T5TokenizerFast"),DMo=o(" (LongT5 model)"),GMo=l(),yu=a("li"),yhe=a("strong"),OMo=o("luke"),VMo=o(" \u2014 "),ND=a("a"),XMo=o("LukeTokenizer"),zMo=o(" (LUKE model)"),QMo=l(),Xs=a("li"),xhe=a("strong"),WMo=o("lxmert"),UMo=o(" \u2014 "),qD=a("a"),HMo=o("LxmertTokenizer"),JMo=o(" or "),jD=a("a"),YMo=o("LxmertTokenizerFast"),ZMo=o(" (LXMERT model)"),KMo=l(),xu=a("li"),$he=a("strong"),eEo=o("m2m_100"),oEo=o(" \u2014 "),DD=a("a"),rEo=o("M2M100Tokenizer"),tEo=o(" (M2M100 model)"),aEo=l(),$u=a("li"),khe=a("strong"),nEo=o("marian"),sEo=o(" \u2014 "),GD=a("a"),lEo=o("MarianTokenizer"),iEo=o(" (Marian model)"),dEo=l(),zs=a("li"),She=a("strong"),cEo=o("mbart"),mEo=o(" \u2014 "),OD=a("a"),fEo=o("MBartTokenizer"),gEo=o(" or "),VD=a("a"),hEo=o("MBartTokenizerFast"),uEo=o(" (mBART model)"),pEo=l(),Qs=a("li"),Rhe=a("strong"),_Eo=o("mbart50"),bEo=o(" \u2014 "),XD=a("a"),vEo=o("MBart50Tokenizer"),FEo=o(" or "),zD=a("a"),TEo=o("MBart50TokenizerFast"),MEo=o(" (mBART-50 model)"),EEo=l(),Ws=a("li"),Phe=a("strong"),CEo=o("megatron-bert"),wEo=o(" \u2014 "),QD=a("a"),AEo=o("BertTokenizer"),LEo=o(" or "),WD=a("a"),yEo=o("BertTokenizerFast"),xEo=o(" (Megatron-BERT model)"),$Eo=l(),ku=a("li"),Bhe=a("strong"),kEo=o("mluke"),SEo=o(" \u2014 "),UD=a("a"),REo=o("MLukeTokenizer"),PEo=o(" (mLUKE model)"),BEo=l(),Us=a("li"),Ihe=a("strong"),IEo=o("mobilebert"),NEo=o(" \u2014 "),HD=a("a"),qEo=o("MobileBertTokenizer"),jEo=o(" or "),JD=a("a"),DEo=o("MobileBertTokenizerFast"),GEo=o(" (MobileBERT model)"),OEo=l(),Hs=a("li"),Nhe=a("strong"),VEo=o("mpnet"),XEo=o(" \u2014 "),YD=a("a"),zEo=o("MPNetTokenizer"),QEo=o(" or "),ZD=a("a"),WEo=o("MPNetTokenizerFast"),UEo=o(" (MPNet model)"),HEo=l(),Js=a("li"),qhe=a("strong"),JEo=o("mt5"),YEo=o(" \u2014 "),KD=a("a"),ZEo=o("MT5Tokenizer"),KEo=o(" or "),eG=a("a"),e4o=o("MT5TokenizerFast"),o4o=o(" (MT5 model)"),r4o=l(),Ys=a("li"),jhe=a("strong"),t4o=o("mvp"),a4o=o(" \u2014 "),oG=a("a"),n4o=o("MvpTokenizer"),s4o=o(" or "),rG=a("a"),l4o=o("MvpTokenizerFast"),i4o=o(" (MVP model)"),d4o=l(),Zs=a("li"),Dhe=a("strong"),c4o=o("nezha"),m4o=o(" \u2014 "),tG=a("a"),f4o=o("BertTokenizer"),g4o=o(" or "),aG=a("a"),h4o=o("BertTokenizerFast"),u4o=o(" (Nezha model)"),p4o=l(),Ks=a("li"),Ghe=a("strong"),_4o=o("nllb"),b4o=o(" \u2014 "),nG=a("a"),v4o=o("NllbTokenizer"),F4o=o(" or "),sG=a("a"),T4o=o("NllbTokenizerFast"),M4o=o(" (NLLB model)"),E4o=l(),el=a("li"),Ohe=a("strong"),C4o=o("nystromformer"),w4o=o(" \u2014 "),lG=a("a"),A4o=o("AlbertTokenizer"),L4o=o(" or "),iG=a("a"),y4o=o("AlbertTokenizerFast"),x4o=o(" (Nystr\xF6mformer model)"),$4o=l(),ol=a("li"),Vhe=a("strong"),k4o=o("openai-gpt"),S4o=o(" \u2014 "),dG=a("a"),R4o=o("OpenAIGPTTokenizer"),P4o=o(" or "),cG=a("a"),B4o=o("OpenAIGPTTokenizerFast"),I4o=o(" (OpenAI GPT model)"),N4o=l(),Su=a("li"),Xhe=a("strong"),q4o=o("opt"),j4o=o(" \u2014 "),mG=a("a"),D4o=o("GPT2Tokenizer"),G4o=o(" (OPT model)"),O4o=l(),rl=a("li"),zhe=a("strong"),V4o=o("owlvit"),X4o=o(" \u2014 "),fG=a("a"),z4o=o("CLIPTokenizer"),Q4o=o(" or "),gG=a("a"),W4o=o("CLIPTokenizerFast"),U4o=o(" (OWL-ViT model)"),H4o=l(),tl=a("li"),Qhe=a("strong"),J4o=o("pegasus"),Y4o=o(" \u2014 "),hG=a("a"),Z4o=o("PegasusTokenizer"),K4o=o(" or "),uG=a("a"),eCo=o("PegasusTokenizerFast"),oCo=o(" (Pegasus model)"),rCo=l(),Ru=a("li"),Whe=a("strong"),tCo=o("perceiver"),aCo=o(" \u2014 "),pG=a("a"),nCo=o("PerceiverTokenizer"),sCo=o(" (Perceiver model)"),lCo=l(),Pu=a("li"),Uhe=a("strong"),iCo=o("phobert"),dCo=o(" \u2014 "),_G=a("a"),cCo=o("PhobertTokenizer"),mCo=o(" (PhoBERT model)"),fCo=l(),Bu=a("li"),Hhe=a("strong"),gCo=o("plbart"),hCo=o(" \u2014 "),bG=a("a"),uCo=o("PLBartTokenizer"),pCo=o(" (PLBart model)"),_Co=l(),Iu=a("li"),Jhe=a("strong"),bCo=o("prophetnet"),vCo=o(" \u2014 "),vG=a("a"),FCo=o("ProphetNetTokenizer"),TCo=o(" (ProphetNet model)"),MCo=l(),al=a("li"),Yhe=a("strong"),ECo=o("qdqbert"),CCo=o(" \u2014 "),FG=a("a"),wCo=o("BertTokenizer"),ACo=o(" or "),TG=a("a"),LCo=o("BertTokenizerFast"),yCo=o(" (QDQBert model)"),xCo=l(),Nu=a("li"),Zhe=a("strong"),$Co=o("rag"),kCo=o(" \u2014 "),MG=a("a"),SCo=o("RagTokenizer"),RCo=o(" (RAG model)"),PCo=l(),nl=a("li"),Khe=a("strong"),BCo=o("realm"),ICo=o(" \u2014 "),EG=a("a"),NCo=o("RealmTokenizer"),qCo=o(" or "),CG=a("a"),jCo=o("RealmTokenizerFast"),DCo=o(" (REALM model)"),GCo=l(),sl=a("li"),eue=a("strong"),OCo=o("reformer"),VCo=o(" \u2014 "),wG=a("a"),XCo=o("ReformerTokenizer"),zCo=o(" or "),AG=a("a"),QCo=o("ReformerTokenizerFast"),WCo=o(" (Reformer model)"),UCo=l(),ll=a("li"),oue=a("strong"),HCo=o("rembert"),JCo=o(" \u2014 "),LG=a("a"),YCo=o("RemBertTokenizer"),ZCo=o(" or "),yG=a("a"),KCo=o("RemBertTokenizerFast"),e3o=o(" (RemBERT model)"),o3o=l(),il=a("li"),rue=a("strong"),r3o=o("retribert"),t3o=o(" \u2014 "),xG=a("a"),a3o=o("RetriBertTokenizer"),n3o=o(" or "),$G=a("a"),s3o=o("RetriBertTokenizerFast"),l3o=o(" (RetriBERT model)"),i3o=l(),dl=a("li"),tue=a("strong"),d3o=o("roberta"),c3o=o(" \u2014 "),kG=a("a"),m3o=o("RobertaTokenizer"),f3o=o(" or "),SG=a("a"),g3o=o("RobertaTokenizerFast"),h3o=o(" (RoBERTa model)"),u3o=l(),cl=a("li"),aue=a("strong"),p3o=o("roformer"),_3o=o(" \u2014 "),RG=a("a"),b3o=o("RoFormerTokenizer"),v3o=o(" or "),PG=a("a"),F3o=o("RoFormerTokenizerFast"),T3o=o(" (RoFormer model)"),M3o=l(),qu=a("li"),nue=a("strong"),E3o=o("speech_to_text"),C3o=o(" \u2014 "),BG=a("a"),w3o=o("Speech2TextTokenizer"),A3o=o(" (Speech2Text model)"),L3o=l(),ju=a("li"),sue=a("strong"),y3o=o("speech_to_text_2"),x3o=o(" \u2014 "),IG=a("a"),$3o=o("Speech2Text2Tokenizer"),k3o=o(" (Speech2Text2 model)"),S3o=l(),ml=a("li"),lue=a("strong"),R3o=o("splinter"),P3o=o(" \u2014 "),NG=a("a"),B3o=o("SplinterTokenizer"),I3o=o(" or "),qG=a("a"),N3o=o("SplinterTokenizerFast"),q3o=o(" (Splinter model)"),j3o=l(),fl=a("li"),iue=a("strong"),D3o=o("squeezebert"),G3o=o(" \u2014 "),jG=a("a"),O3o=o("SqueezeBertTokenizer"),V3o=o(" or "),DG=a("a"),X3o=o("SqueezeBertTokenizerFast"),z3o=o(" (SqueezeBERT model)"),Q3o=l(),gl=a("li"),due=a("strong"),W3o=o("t5"),U3o=o(" \u2014 "),GG=a("a"),H3o=o("T5Tokenizer"),J3o=o(" or "),OG=a("a"),Y3o=o("T5TokenizerFast"),Z3o=o(" (T5 model)"),K3o=l(),Du=a("li"),cue=a("strong"),e5o=o("tapas"),o5o=o(" \u2014 "),VG=a("a"),r5o=o("TapasTokenizer"),t5o=o(" (TAPAS model)"),a5o=l(),Gu=a("li"),mue=a("strong"),n5o=o("tapex"),s5o=o(" \u2014 "),XG=a("a"),l5o=o("TapexTokenizer"),i5o=o(" (TAPEX model)"),d5o=l(),Ou=a("li"),fue=a("strong"),c5o=o("transfo-xl"),m5o=o(" \u2014 "),zG=a("a"),f5o=o("TransfoXLTokenizer"),g5o=o(" (Transformer-XL model)"),h5o=l(),hl=a("li"),gue=a("strong"),u5o=o("vilt"),p5o=o(" \u2014 "),QG=a("a"),_5o=o("BertTokenizer"),b5o=o(" or "),WG=a("a"),v5o=o("BertTokenizerFast"),F5o=o(" (ViLT model)"),T5o=l(),ul=a("li"),hue=a("strong"),M5o=o("visual_bert"),E5o=o(" \u2014 "),UG=a("a"),C5o=o("BertTokenizer"),w5o=o(" or "),HG=a("a"),A5o=o("BertTokenizerFast"),L5o=o(" (VisualBERT model)"),y5o=l(),Vu=a("li"),uue=a("strong"),x5o=o("wav2vec2"),$5o=o(" \u2014 "),JG=a("a"),k5o=o("Wav2Vec2CTCTokenizer"),S5o=o(" (Wav2Vec2 model)"),R5o=l(),Xu=a("li"),pue=a("strong"),P5o=o("wav2vec2-conformer"),B5o=o(" \u2014 "),YG=a("a"),I5o=o("Wav2Vec2CTCTokenizer"),N5o=o(" (Wav2Vec2-Conformer model)"),q5o=l(),zu=a("li"),_ue=a("strong"),j5o=o("wav2vec2_phoneme"),D5o=o(" \u2014 "),ZG=a("a"),G5o=o("Wav2Vec2PhonemeCTCTokenizer"),O5o=o(" (Wav2Vec2Phoneme model)"),V5o=l(),Qu=a("li"),bue=a("strong"),X5o=o("whisper"),z5o=o(" \u2014 "),KG=a("a"),Q5o=o("WhisperTokenizer"),W5o=o(" (Whisper model)"),U5o=l(),pl=a("li"),vue=a("strong"),H5o=o("xclip"),J5o=o(" \u2014 "),eO=a("a"),Y5o=o("CLIPTokenizer"),Z5o=o(" or "),oO=a("a"),K5o=o("CLIPTokenizerFast"),e0o=o(" (X-CLIP model)"),o0o=l(),_l=a("li"),Fue=a("strong"),r0o=o("xglm"),t0o=o(" \u2014 "),rO=a("a"),a0o=o("XGLMTokenizer"),n0o=o(" or "),tO=a("a"),s0o=o("XGLMTokenizerFast"),l0o=o(" (XGLM model)"),i0o=l(),Wu=a("li"),Tue=a("strong"),d0o=o("xlm"),c0o=o(" \u2014 "),aO=a("a"),m0o=o("XLMTokenizer"),f0o=o(" (XLM model)"),g0o=l(),Uu=a("li"),Mue=a("strong"),h0o=o("xlm-prophetnet"),u0o=o(" \u2014 "),nO=a("a"),p0o=o("XLMProphetNetTokenizer"),_0o=o(" (XLM-ProphetNet model)"),b0o=l(),bl=a("li"),Eue=a("strong"),v0o=o("xlm-roberta"),F0o=o(" \u2014 "),sO=a("a"),T0o=o("XLMRobertaTokenizer"),M0o=o(" or "),lO=a("a"),E0o=o("XLMRobertaTokenizerFast"),C0o=o(" (XLM-RoBERTa model)"),w0o=l(),vl=a("li"),Cue=a("strong"),A0o=o("xlm-roberta-xl"),L0o=o(" \u2014 "),iO=a("a"),y0o=o("XLMRobertaTokenizer"),x0o=o(" or "),dO=a("a"),$0o=o("XLMRobertaTokenizerFast"),k0o=o(" (XLM-RoBERTa-XL model)"),S0o=l(),Fl=a("li"),wue=a("strong"),R0o=o("xlnet"),P0o=o(" \u2014 "),cO=a("a"),B0o=o("XLNetTokenizer"),I0o=o(" or "),mO=a("a"),N0o=o("XLNetTokenizerFast"),q0o=o(" (XLNet model)"),j0o=l(),Tl=a("li"),Aue=a("strong"),D0o=o("yoso"),G0o=o(" \u2014 "),fO=a("a"),O0o=o("AlbertTokenizer"),V0o=o(" or "),gO=a("a"),X0o=o("AlbertTokenizerFast"),z0o=o(" (YOSO model)"),Q0o=l(),F(Hu.$$.fragment),W0o=l(),Ju=a("div"),F(jx.$$.fragment),U0o=l(),Lue=a("p"),H0o=o("Register a new tokenizer in this mapping."),_oo=l(),Fd=a("h2"),Yu=a("a"),yue=a("span"),F(Dx.$$.fragment),J0o=l(),xue=a("span"),Y0o=o("AutoFeatureExtractor"),boo=l(),Ro=a("div"),F(Gx.$$.fragment),Z0o=l(),Ox=a("p"),K0o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),hO=a("a"),ewo=o("AutoFeatureExtractor.from_pretrained()"),owo=o(" class method."),rwo=l(),Vx=a("p"),two=o("This class cannot be instantiated directly using "),$ue=a("code"),awo=o("__init__()"),nwo=o(" (throws an error)."),swo=l(),Ye=a("div"),F(Xx.$$.fragment),lwo=l(),kue=a("p"),iwo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dwo=l(),Ka=a("p"),cwo=o("The feature extractor class to instantiate is selected based on the "),Sue=a("code"),mwo=o("model_type"),fwo=o(` property of the config object
(either passed as an argument or loaded from `),Rue=a("code"),gwo=o("pretrained_model_name_or_path"),hwo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Pue=a("code"),uwo=o("pretrained_model_name_or_path"),pwo=o(":"),_wo=l(),z=a("ul"),Zu=a("li"),Bue=a("strong"),bwo=o("beit"),vwo=o(" \u2014 "),uO=a("a"),Fwo=o("BeitFeatureExtractor"),Two=o(" (BEiT model)"),Mwo=l(),Ku=a("li"),Iue=a("strong"),Ewo=o("clip"),Cwo=o(" \u2014 "),pO=a("a"),wwo=o("CLIPFeatureExtractor"),Awo=o(" (CLIP model)"),Lwo=l(),ep=a("li"),Nue=a("strong"),ywo=o("conditional_detr"),xwo=o(" \u2014 "),_O=a("a"),$wo=o("ConditionalDetrFeatureExtractor"),kwo=o(" (Conditional DETR model)"),Swo=l(),op=a("li"),que=a("strong"),Rwo=o("convnext"),Pwo=o(" \u2014 "),bO=a("a"),Bwo=o("ConvNextFeatureExtractor"),Iwo=o(" (ConvNeXT model)"),Nwo=l(),rp=a("li"),jue=a("strong"),qwo=o("cvt"),jwo=o(" \u2014 "),vO=a("a"),Dwo=o("ConvNextFeatureExtractor"),Gwo=o(" (CvT model)"),Owo=l(),tp=a("li"),Due=a("strong"),Vwo=o("data2vec-audio"),Xwo=o(" \u2014 "),FO=a("a"),zwo=o("Wav2Vec2FeatureExtractor"),Qwo=o(" (Data2VecAudio model)"),Wwo=l(),ap=a("li"),Gue=a("strong"),Uwo=o("data2vec-vision"),Hwo=o(" \u2014 "),TO=a("a"),Jwo=o("BeitFeatureExtractor"),Ywo=o(" (Data2VecVision model)"),Zwo=l(),np=a("li"),Oue=a("strong"),Kwo=o("deformable_detr"),eAo=o(" \u2014 "),MO=a("a"),oAo=o("DeformableDetrFeatureExtractor"),rAo=o(" (Deformable DETR model)"),tAo=l(),sp=a("li"),Vue=a("strong"),aAo=o("deit"),nAo=o(" \u2014 "),EO=a("a"),sAo=o("DeiTFeatureExtractor"),lAo=o(" (DeiT model)"),iAo=l(),lp=a("li"),Xue=a("strong"),dAo=o("detr"),cAo=o(" \u2014 "),CO=a("a"),mAo=o("DetrFeatureExtractor"),fAo=o(" (DETR model)"),gAo=l(),ip=a("li"),zue=a("strong"),hAo=o("donut"),uAo=o(" \u2014 "),wO=a("a"),pAo=o("DonutFeatureExtractor"),_Ao=o(" (Donut model)"),bAo=l(),dp=a("li"),Que=a("strong"),vAo=o("dpt"),FAo=o(" \u2014 "),AO=a("a"),TAo=o("DPTFeatureExtractor"),MAo=o(" (DPT model)"),EAo=l(),cp=a("li"),Wue=a("strong"),CAo=o("flava"),wAo=o(" \u2014 "),LO=a("a"),AAo=o("FlavaFeatureExtractor"),LAo=o(" (FLAVA model)"),yAo=l(),mp=a("li"),Uue=a("strong"),xAo=o("glpn"),$Ao=o(" \u2014 "),yO=a("a"),kAo=o("GLPNFeatureExtractor"),SAo=o(" (GLPN model)"),RAo=l(),fp=a("li"),Hue=a("strong"),PAo=o("groupvit"),BAo=o(" \u2014 "),xO=a("a"),IAo=o("CLIPFeatureExtractor"),NAo=o(" (GroupViT model)"),qAo=l(),gp=a("li"),Jue=a("strong"),jAo=o("hubert"),DAo=o(" \u2014 "),$O=a("a"),GAo=o("Wav2Vec2FeatureExtractor"),OAo=o(" (Hubert model)"),VAo=l(),hp=a("li"),Yue=a("strong"),XAo=o("imagegpt"),zAo=o(" \u2014 "),kO=a("a"),QAo=o("ImageGPTFeatureExtractor"),WAo=o(" (ImageGPT model)"),UAo=l(),up=a("li"),Zue=a("strong"),HAo=o("layoutlmv2"),JAo=o(" \u2014 "),SO=a("a"),YAo=o("LayoutLMv2FeatureExtractor"),ZAo=o(" (LayoutLMv2 model)"),KAo=l(),pp=a("li"),Kue=a("strong"),e6o=o("layoutlmv3"),o6o=o(" \u2014 "),RO=a("a"),r6o=o("LayoutLMv3FeatureExtractor"),t6o=o(" (LayoutLMv3 model)"),a6o=l(),_p=a("li"),epe=a("strong"),n6o=o("levit"),s6o=o(" \u2014 "),PO=a("a"),l6o=o("LevitFeatureExtractor"),i6o=o(" (LeViT model)"),d6o=l(),bp=a("li"),ope=a("strong"),c6o=o("maskformer"),m6o=o(" \u2014 "),BO=a("a"),f6o=o("MaskFormerFeatureExtractor"),g6o=o(" (MaskFormer model)"),h6o=l(),vp=a("li"),rpe=a("strong"),u6o=o("mctct"),p6o=o(" \u2014 "),IO=a("a"),_6o=o("MCTCTFeatureExtractor"),b6o=o(" (M-CTC-T model)"),v6o=l(),Fp=a("li"),tpe=a("strong"),F6o=o("mobilevit"),T6o=o(" \u2014 "),NO=a("a"),M6o=o("MobileViTFeatureExtractor"),E6o=o(" (MobileViT model)"),C6o=l(),Tp=a("li"),ape=a("strong"),w6o=o("owlvit"),A6o=o(" \u2014 "),qO=a("a"),L6o=o("OwlViTFeatureExtractor"),y6o=o(" (OWL-ViT model)"),x6o=l(),Mp=a("li"),npe=a("strong"),$6o=o("perceiver"),k6o=o(" \u2014 "),jO=a("a"),S6o=o("PerceiverFeatureExtractor"),R6o=o(" (Perceiver model)"),P6o=l(),Ep=a("li"),spe=a("strong"),B6o=o("poolformer"),I6o=o(" \u2014 "),DO=a("a"),N6o=o("PoolFormerFeatureExtractor"),q6o=o(" (PoolFormer model)"),j6o=l(),Cp=a("li"),lpe=a("strong"),D6o=o("regnet"),G6o=o(" \u2014 "),GO=a("a"),O6o=o("ConvNextFeatureExtractor"),V6o=o(" (RegNet model)"),X6o=l(),wp=a("li"),ipe=a("strong"),z6o=o("resnet"),Q6o=o(" \u2014 "),OO=a("a"),W6o=o("ConvNextFeatureExtractor"),U6o=o(" (ResNet model)"),H6o=l(),Ap=a("li"),dpe=a("strong"),J6o=o("segformer"),Y6o=o(" \u2014 "),VO=a("a"),Z6o=o("SegformerFeatureExtractor"),K6o=o(" (SegFormer model)"),e7o=l(),Lp=a("li"),cpe=a("strong"),o7o=o("speech_to_text"),r7o=o(" \u2014 "),XO=a("a"),t7o=o("Speech2TextFeatureExtractor"),a7o=o(" (Speech2Text model)"),n7o=l(),yp=a("li"),mpe=a("strong"),s7o=o("swin"),l7o=o(" \u2014 "),zO=a("a"),i7o=o("ViTFeatureExtractor"),d7o=o(" (Swin Transformer model)"),c7o=l(),xp=a("li"),fpe=a("strong"),m7o=o("swinv2"),f7o=o(" \u2014 "),QO=a("a"),g7o=o("ViTFeatureExtractor"),h7o=o(" (Swin Transformer V2 model)"),u7o=l(),$p=a("li"),gpe=a("strong"),p7o=o("van"),_7o=o(" \u2014 "),WO=a("a"),b7o=o("ConvNextFeatureExtractor"),v7o=o(" (VAN model)"),F7o=l(),kp=a("li"),hpe=a("strong"),T7o=o("videomae"),M7o=o(" \u2014 "),UO=a("a"),E7o=o("VideoMAEFeatureExtractor"),C7o=o(" (VideoMAE model)"),w7o=l(),Sp=a("li"),upe=a("strong"),A7o=o("vilt"),L7o=o(" \u2014 "),HO=a("a"),y7o=o("ViltFeatureExtractor"),x7o=o(" (ViLT model)"),$7o=l(),Rp=a("li"),ppe=a("strong"),k7o=o("vit"),S7o=o(" \u2014 "),JO=a("a"),R7o=o("ViTFeatureExtractor"),P7o=o(" (ViT model)"),B7o=l(),Pp=a("li"),_pe=a("strong"),I7o=o("vit_mae"),N7o=o(" \u2014 "),YO=a("a"),q7o=o("ViTFeatureExtractor"),j7o=o(" (ViTMAE model)"),D7o=l(),Bp=a("li"),bpe=a("strong"),G7o=o("vit_msn"),O7o=o(" \u2014 "),ZO=a("a"),V7o=o("ViTFeatureExtractor"),X7o=o(" (ViTMSN model)"),z7o=l(),Ip=a("li"),vpe=a("strong"),Q7o=o("wav2vec2"),W7o=o(" \u2014 "),KO=a("a"),U7o=o("Wav2Vec2FeatureExtractor"),H7o=o(" (Wav2Vec2 model)"),J7o=l(),Np=a("li"),Fpe=a("strong"),Y7o=o("wav2vec2-conformer"),Z7o=o(" \u2014 "),eV=a("a"),K7o=o("Wav2Vec2FeatureExtractor"),eLo=o(" (Wav2Vec2-Conformer model)"),oLo=l(),qp=a("li"),Tpe=a("strong"),rLo=o("whisper"),tLo=o(" \u2014 "),oV=a("a"),aLo=o("WhisperFeatureExtractor"),nLo=o(" (Whisper model)"),sLo=l(),jp=a("li"),Mpe=a("strong"),lLo=o("xclip"),iLo=o(" \u2014 "),rV=a("a"),dLo=o("CLIPFeatureExtractor"),cLo=o(" (X-CLIP model)"),mLo=l(),Dp=a("li"),Epe=a("strong"),fLo=o("yolos"),gLo=o(" \u2014 "),tV=a("a"),hLo=o("YolosFeatureExtractor"),uLo=o(" (YOLOS model)"),pLo=l(),F(Gp.$$.fragment),_Lo=l(),F(Op.$$.fragment),bLo=l(),Vp=a("div"),F(zx.$$.fragment),vLo=l(),Cpe=a("p"),FLo=o("Register a new feature extractor for this class."),voo=l(),Td=a("h2"),Xp=a("a"),wpe=a("span"),F(Qx.$$.fragment),TLo=l(),Ape=a("span"),MLo=o("AutoProcessor"),Foo=l(),Po=a("div"),F(Wx.$$.fragment),ELo=l(),Ux=a("p"),CLo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),aV=a("a"),wLo=o("AutoProcessor.from_pretrained()"),ALo=o(" class method."),LLo=l(),Hx=a("p"),yLo=o("This class cannot be instantiated directly using "),Lpe=a("code"),xLo=o("__init__()"),$Lo=o(" (throws an error)."),kLo=l(),Ze=a("div"),F(Jx.$$.fragment),SLo=l(),ype=a("p"),RLo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),PLo=l(),Md=a("p"),BLo=o("The processor class to instantiate is selected based on the "),xpe=a("code"),ILo=o("model_type"),NLo=o(` property of the config object (either
passed as an argument or loaded from `),$pe=a("code"),qLo=o("pretrained_model_name_or_path"),jLo=o(" if possible):"),DLo=l(),se=a("ul"),zp=a("li"),kpe=a("strong"),GLo=o("clip"),OLo=o(" \u2014 "),nV=a("a"),VLo=o("CLIPProcessor"),XLo=o(" (CLIP model)"),zLo=l(),Qp=a("li"),Spe=a("strong"),QLo=o("donut"),WLo=o(" \u2014 "),sV=a("a"),ULo=o("DonutProcessor"),HLo=o(" (Donut model)"),JLo=l(),Wp=a("li"),Rpe=a("strong"),YLo=o("flava"),ZLo=o(" \u2014 "),lV=a("a"),KLo=o("FlavaProcessor"),eyo=o(" (FLAVA model)"),oyo=l(),Up=a("li"),Ppe=a("strong"),ryo=o("groupvit"),tyo=o(" \u2014 "),iV=a("a"),ayo=o("CLIPProcessor"),nyo=o(" (GroupViT model)"),syo=l(),Hp=a("li"),Bpe=a("strong"),lyo=o("layoutlmv2"),iyo=o(" \u2014 "),dV=a("a"),dyo=o("LayoutLMv2Processor"),cyo=o(" (LayoutLMv2 model)"),myo=l(),Jp=a("li"),Ipe=a("strong"),fyo=o("layoutlmv3"),gyo=o(" \u2014 "),cV=a("a"),hyo=o("LayoutLMv3Processor"),uyo=o(" (LayoutLMv3 model)"),pyo=l(),Yp=a("li"),Npe=a("strong"),_yo=o("layoutxlm"),byo=o(" \u2014 "),mV=a("a"),vyo=o("LayoutXLMProcessor"),Fyo=o(" (LayoutXLM model)"),Tyo=l(),Zp=a("li"),qpe=a("strong"),Myo=o("markuplm"),Eyo=o(" \u2014 "),fV=a("a"),Cyo=o("MarkupLMProcessor"),wyo=o(" (MarkupLM model)"),Ayo=l(),Kp=a("li"),jpe=a("strong"),Lyo=o("owlvit"),yyo=o(" \u2014 "),gV=a("a"),xyo=o("OwlViTProcessor"),$yo=o(" (OWL-ViT model)"),kyo=l(),e_=a("li"),Dpe=a("strong"),Syo=o("sew"),Ryo=o(" \u2014 "),hV=a("a"),Pyo=o("Wav2Vec2Processor"),Byo=o(" (SEW model)"),Iyo=l(),o_=a("li"),Gpe=a("strong"),Nyo=o("sew-d"),qyo=o(" \u2014 "),uV=a("a"),jyo=o("Wav2Vec2Processor"),Dyo=o(" (SEW-D model)"),Gyo=l(),r_=a("li"),Ope=a("strong"),Oyo=o("speech_to_text"),Vyo=o(" \u2014 "),pV=a("a"),Xyo=o("Speech2TextProcessor"),zyo=o(" (Speech2Text model)"),Qyo=l(),t_=a("li"),Vpe=a("strong"),Wyo=o("speech_to_text_2"),Uyo=o(" \u2014 "),_V=a("a"),Hyo=o("Speech2Text2Processor"),Jyo=o(" (Speech2Text2 model)"),Yyo=l(),a_=a("li"),Xpe=a("strong"),Zyo=o("trocr"),Kyo=o(" \u2014 "),bV=a("a"),e8o=o("TrOCRProcessor"),o8o=o(" (TrOCR model)"),r8o=l(),n_=a("li"),zpe=a("strong"),t8o=o("unispeech"),a8o=o(" \u2014 "),vV=a("a"),n8o=o("Wav2Vec2Processor"),s8o=o(" (UniSpeech model)"),l8o=l(),s_=a("li"),Qpe=a("strong"),i8o=o("unispeech-sat"),d8o=o(" \u2014 "),FV=a("a"),c8o=o("Wav2Vec2Processor"),m8o=o(" (UniSpeechSat model)"),f8o=l(),l_=a("li"),Wpe=a("strong"),g8o=o("vilt"),h8o=o(" \u2014 "),TV=a("a"),u8o=o("ViltProcessor"),p8o=o(" (ViLT model)"),_8o=l(),i_=a("li"),Upe=a("strong"),b8o=o("vision-text-dual-encoder"),v8o=o(" \u2014 "),MV=a("a"),F8o=o("VisionTextDualEncoderProcessor"),T8o=o(" (VisionTextDualEncoder model)"),M8o=l(),d_=a("li"),Hpe=a("strong"),E8o=o("wav2vec2"),C8o=o(" \u2014 "),EV=a("a"),w8o=o("Wav2Vec2Processor"),A8o=o(" (Wav2Vec2 model)"),L8o=l(),c_=a("li"),Jpe=a("strong"),y8o=o("wav2vec2-conformer"),x8o=o(" \u2014 "),CV=a("a"),$8o=o("Wav2Vec2Processor"),k8o=o(" (Wav2Vec2-Conformer model)"),S8o=l(),m_=a("li"),Ype=a("strong"),R8o=o("wavlm"),P8o=o(" \u2014 "),wV=a("a"),B8o=o("Wav2Vec2Processor"),I8o=o(" (WavLM model)"),N8o=l(),f_=a("li"),Zpe=a("strong"),q8o=o("whisper"),j8o=o(" \u2014 "),AV=a("a"),D8o=o("WhisperProcessor"),G8o=o(" (Whisper model)"),O8o=l(),g_=a("li"),Kpe=a("strong"),V8o=o("xclip"),X8o=o(" \u2014 "),LV=a("a"),z8o=o("CLIPProcessor"),Q8o=o(" (X-CLIP model)"),W8o=l(),F(h_.$$.fragment),U8o=l(),F(u_.$$.fragment),H8o=l(),p_=a("div"),F(Yx.$$.fragment),J8o=l(),e_e=a("p"),Y8o=o("Register a new processor for this class."),Too=l(),Ed=a("h2"),__=a("a"),o_e=a("span"),F(Zx.$$.fragment),Z8o=l(),r_e=a("span"),K8o=o("AutoModel"),Moo=l(),Bo=a("div"),F(Kx.$$.fragment),e9o=l(),Cd=a("p"),o9o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),yV=a("a"),r9o=o("from_pretrained()"),t9o=o(" class method or the "),xV=a("a"),a9o=o("from_config()"),n9o=o(` class
method.`),s9o=l(),e$=a("p"),l9o=o("This class cannot be instantiated directly using "),t_e=a("code"),i9o=o("__init__()"),d9o=o(" (throws an error)."),c9o=l(),vt=a("div"),F(o$.$$.fragment),m9o=l(),a_e=a("p"),f9o=o("Instantiates one of the base model classes of the library from a configuration."),g9o=l(),wd=a("p"),h9o=o(`Note:
Loading a model from its configuration file does `),n_e=a("strong"),u9o=o("not"),p9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$V=a("a"),_9o=o("from_pretrained()"),b9o=o(" to load the model weights."),v9o=l(),F(b_.$$.fragment),F9o=l(),Ke=a("div"),F(r$.$$.fragment),T9o=l(),s_e=a("p"),M9o=o("Instantiate one of the base model classes of the library from a pretrained model."),E9o=l(),en=a("p"),C9o=o("The model class to instantiate is selected based on the "),l_e=a("code"),w9o=o("model_type"),A9o=o(` property of the config object (either
passed as an argument or loaded from `),i_e=a("code"),L9o=o("pretrained_model_name_or_path"),y9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d_e=a("code"),x9o=o("pretrained_model_name_or_path"),$9o=o(":"),k9o=l(),y=a("ul"),v_=a("li"),c_e=a("strong"),S9o=o("albert"),R9o=o(" \u2014 "),kV=a("a"),P9o=o("AlbertModel"),B9o=o(" (ALBERT model)"),I9o=l(),F_=a("li"),m_e=a("strong"),N9o=o("bart"),q9o=o(" \u2014 "),SV=a("a"),j9o=o("BartModel"),D9o=o(" (BART model)"),G9o=l(),T_=a("li"),f_e=a("strong"),O9o=o("beit"),V9o=o(" \u2014 "),RV=a("a"),X9o=o("BeitModel"),z9o=o(" (BEiT model)"),Q9o=l(),M_=a("li"),g_e=a("strong"),W9o=o("bert"),U9o=o(" \u2014 "),PV=a("a"),H9o=o("BertModel"),J9o=o(" (BERT model)"),Y9o=l(),E_=a("li"),h_e=a("strong"),Z9o=o("bert-generation"),K9o=o(" \u2014 "),BV=a("a"),exo=o("BertGenerationEncoder"),oxo=o(" (Bert Generation model)"),rxo=l(),C_=a("li"),u_e=a("strong"),txo=o("big_bird"),axo=o(" \u2014 "),IV=a("a"),nxo=o("BigBirdModel"),sxo=o(" (BigBird model)"),lxo=l(),w_=a("li"),p_e=a("strong"),ixo=o("bigbird_pegasus"),dxo=o(" \u2014 "),NV=a("a"),cxo=o("BigBirdPegasusModel"),mxo=o(" (BigBird-Pegasus model)"),fxo=l(),A_=a("li"),__e=a("strong"),gxo=o("blenderbot"),hxo=o(" \u2014 "),qV=a("a"),uxo=o("BlenderbotModel"),pxo=o(" (Blenderbot model)"),_xo=l(),L_=a("li"),b_e=a("strong"),bxo=o("blenderbot-small"),vxo=o(" \u2014 "),jV=a("a"),Fxo=o("BlenderbotSmallModel"),Txo=o(" (BlenderbotSmall model)"),Mxo=l(),y_=a("li"),v_e=a("strong"),Exo=o("bloom"),Cxo=o(" \u2014 "),DV=a("a"),wxo=o("BloomModel"),Axo=o(" (BLOOM model)"),Lxo=l(),x_=a("li"),F_e=a("strong"),yxo=o("camembert"),xxo=o(" \u2014 "),GV=a("a"),$xo=o("CamembertModel"),kxo=o(" (CamemBERT model)"),Sxo=l(),$_=a("li"),T_e=a("strong"),Rxo=o("canine"),Pxo=o(" \u2014 "),OV=a("a"),Bxo=o("CanineModel"),Ixo=o(" (CANINE model)"),Nxo=l(),k_=a("li"),M_e=a("strong"),qxo=o("clip"),jxo=o(" \u2014 "),VV=a("a"),Dxo=o("CLIPModel"),Gxo=o(" (CLIP model)"),Oxo=l(),S_=a("li"),E_e=a("strong"),Vxo=o("codegen"),Xxo=o(" \u2014 "),XV=a("a"),zxo=o("CodeGenModel"),Qxo=o(" (CodeGen model)"),Wxo=l(),R_=a("li"),C_e=a("strong"),Uxo=o("conditional_detr"),Hxo=o(" \u2014 "),zV=a("a"),Jxo=o("ConditionalDetrModel"),Yxo=o(" (Conditional DETR model)"),Zxo=l(),P_=a("li"),w_e=a("strong"),Kxo=o("convbert"),e$o=o(" \u2014 "),QV=a("a"),o$o=o("ConvBertModel"),r$o=o(" (ConvBERT model)"),t$o=l(),B_=a("li"),A_e=a("strong"),a$o=o("convnext"),n$o=o(" \u2014 "),WV=a("a"),s$o=o("ConvNextModel"),l$o=o(" (ConvNeXT model)"),i$o=l(),I_=a("li"),L_e=a("strong"),d$o=o("ctrl"),c$o=o(" \u2014 "),UV=a("a"),m$o=o("CTRLModel"),f$o=o(" (CTRL model)"),g$o=l(),N_=a("li"),y_e=a("strong"),h$o=o("cvt"),u$o=o(" \u2014 "),HV=a("a"),p$o=o("CvtModel"),_$o=o(" (CvT model)"),b$o=l(),q_=a("li"),x_e=a("strong"),v$o=o("data2vec-audio"),F$o=o(" \u2014 "),JV=a("a"),T$o=o("Data2VecAudioModel"),M$o=o(" (Data2VecAudio model)"),E$o=l(),j_=a("li"),$_e=a("strong"),C$o=o("data2vec-text"),w$o=o(" \u2014 "),YV=a("a"),A$o=o("Data2VecTextModel"),L$o=o(" (Data2VecText model)"),y$o=l(),D_=a("li"),k_e=a("strong"),x$o=o("data2vec-vision"),$$o=o(" \u2014 "),ZV=a("a"),k$o=o("Data2VecVisionModel"),S$o=o(" (Data2VecVision model)"),R$o=l(),G_=a("li"),S_e=a("strong"),P$o=o("deberta"),B$o=o(" \u2014 "),KV=a("a"),I$o=o("DebertaModel"),N$o=o(" (DeBERTa model)"),q$o=l(),O_=a("li"),R_e=a("strong"),j$o=o("deberta-v2"),D$o=o(" \u2014 "),eX=a("a"),G$o=o("DebertaV2Model"),O$o=o(" (DeBERTa-v2 model)"),V$o=l(),V_=a("li"),P_e=a("strong"),X$o=o("decision_transformer"),z$o=o(" \u2014 "),oX=a("a"),Q$o=o("DecisionTransformerModel"),W$o=o(" (Decision Transformer model)"),U$o=l(),X_=a("li"),B_e=a("strong"),H$o=o("deformable_detr"),J$o=o(" \u2014 "),rX=a("a"),Y$o=o("DeformableDetrModel"),Z$o=o(" (Deformable DETR model)"),K$o=l(),z_=a("li"),I_e=a("strong"),eko=o("deit"),oko=o(" \u2014 "),tX=a("a"),rko=o("DeiTModel"),tko=o(" (DeiT model)"),ako=l(),Q_=a("li"),N_e=a("strong"),nko=o("detr"),sko=o(" \u2014 "),aX=a("a"),lko=o("DetrModel"),iko=o(" (DETR model)"),dko=l(),W_=a("li"),q_e=a("strong"),cko=o("distilbert"),mko=o(" \u2014 "),nX=a("a"),fko=o("DistilBertModel"),gko=o(" (DistilBERT model)"),hko=l(),U_=a("li"),j_e=a("strong"),uko=o("donut-swin"),pko=o(" \u2014 "),sX=a("a"),_ko=o("DonutSwinModel"),bko=o(" (DonutSwin model)"),vko=l(),H_=a("li"),D_e=a("strong"),Fko=o("dpr"),Tko=o(" \u2014 "),lX=a("a"),Mko=o("DPRQuestionEncoder"),Eko=o(" (DPR model)"),Cko=l(),J_=a("li"),G_e=a("strong"),wko=o("dpt"),Ako=o(" \u2014 "),iX=a("a"),Lko=o("DPTModel"),yko=o(" (DPT model)"),xko=l(),Y_=a("li"),O_e=a("strong"),$ko=o("electra"),kko=o(" \u2014 "),dX=a("a"),Sko=o("ElectraModel"),Rko=o(" (ELECTRA model)"),Pko=l(),Z_=a("li"),V_e=a("strong"),Bko=o("ernie"),Iko=o(" \u2014 "),cX=a("a"),Nko=o("ErnieModel"),qko=o(" (ERNIE model)"),jko=l(),K_=a("li"),X_e=a("strong"),Dko=o("esm"),Gko=o(" \u2014 "),mX=a("a"),Oko=o("EsmModel"),Vko=o(" (ESM model)"),Xko=l(),e1=a("li"),z_e=a("strong"),zko=o("flaubert"),Qko=o(" \u2014 "),fX=a("a"),Wko=o("FlaubertModel"),Uko=o(" (FlauBERT model)"),Hko=l(),o1=a("li"),Q_e=a("strong"),Jko=o("flava"),Yko=o(" \u2014 "),gX=a("a"),Zko=o("FlavaModel"),Kko=o(" (FLAVA model)"),eSo=l(),r1=a("li"),W_e=a("strong"),oSo=o("fnet"),rSo=o(" \u2014 "),hX=a("a"),tSo=o("FNetModel"),aSo=o(" (FNet model)"),nSo=l(),t1=a("li"),U_e=a("strong"),sSo=o("fsmt"),lSo=o(" \u2014 "),uX=a("a"),iSo=o("FSMTModel"),dSo=o(" (FairSeq Machine-Translation model)"),cSo=l(),Ml=a("li"),H_e=a("strong"),mSo=o("funnel"),fSo=o(" \u2014 "),pX=a("a"),gSo=o("FunnelModel"),hSo=o(" or "),_X=a("a"),uSo=o("FunnelBaseModel"),pSo=o(" (Funnel Transformer model)"),_So=l(),a1=a("li"),J_e=a("strong"),bSo=o("glpn"),vSo=o(" \u2014 "),bX=a("a"),FSo=o("GLPNModel"),TSo=o(" (GLPN model)"),MSo=l(),n1=a("li"),Y_e=a("strong"),ESo=o("gpt2"),CSo=o(" \u2014 "),vX=a("a"),wSo=o("GPT2Model"),ASo=o(" (OpenAI GPT-2 model)"),LSo=l(),s1=a("li"),Z_e=a("strong"),ySo=o("gpt_neo"),xSo=o(" \u2014 "),FX=a("a"),$So=o("GPTNeoModel"),kSo=o(" (GPT Neo model)"),SSo=l(),l1=a("li"),K_e=a("strong"),RSo=o("gpt_neox"),PSo=o(" \u2014 "),TX=a("a"),BSo=o("GPTNeoXModel"),ISo=o(" (GPT NeoX model)"),NSo=l(),i1=a("li"),e1e=a("strong"),qSo=o("gpt_neox_japanese"),jSo=o(" \u2014 "),MX=a("a"),DSo=o("GPTNeoXJapaneseModel"),GSo=o(" (GPT NeoX Japanese model)"),OSo=l(),d1=a("li"),o1e=a("strong"),VSo=o("gptj"),XSo=o(" \u2014 "),EX=a("a"),zSo=o("GPTJModel"),QSo=o(" (GPT-J model)"),WSo=l(),c1=a("li"),r1e=a("strong"),USo=o("groupvit"),HSo=o(" \u2014 "),CX=a("a"),JSo=o("GroupViTModel"),YSo=o(" (GroupViT model)"),ZSo=l(),m1=a("li"),t1e=a("strong"),KSo=o("hubert"),eRo=o(" \u2014 "),wX=a("a"),oRo=o("HubertModel"),rRo=o(" (Hubert model)"),tRo=l(),f1=a("li"),a1e=a("strong"),aRo=o("ibert"),nRo=o(" \u2014 "),AX=a("a"),sRo=o("IBertModel"),lRo=o(" (I-BERT model)"),iRo=l(),g1=a("li"),n1e=a("strong"),dRo=o("imagegpt"),cRo=o(" \u2014 "),LX=a("a"),mRo=o("ImageGPTModel"),fRo=o(" (ImageGPT model)"),gRo=l(),h1=a("li"),s1e=a("strong"),hRo=o("layoutlm"),uRo=o(" \u2014 "),yX=a("a"),pRo=o("LayoutLMModel"),_Ro=o(" (LayoutLM model)"),bRo=l(),u1=a("li"),l1e=a("strong"),vRo=o("layoutlmv2"),FRo=o(" \u2014 "),xX=a("a"),TRo=o("LayoutLMv2Model"),MRo=o(" (LayoutLMv2 model)"),ERo=l(),p1=a("li"),i1e=a("strong"),CRo=o("layoutlmv3"),wRo=o(" \u2014 "),$X=a("a"),ARo=o("LayoutLMv3Model"),LRo=o(" (LayoutLMv3 model)"),yRo=l(),_1=a("li"),d1e=a("strong"),xRo=o("led"),$Ro=o(" \u2014 "),kX=a("a"),kRo=o("LEDModel"),SRo=o(" (LED model)"),RRo=l(),b1=a("li"),c1e=a("strong"),PRo=o("levit"),BRo=o(" \u2014 "),SX=a("a"),IRo=o("LevitModel"),NRo=o(" (LeViT model)"),qRo=l(),v1=a("li"),m1e=a("strong"),jRo=o("longformer"),DRo=o(" \u2014 "),RX=a("a"),GRo=o("LongformerModel"),ORo=o(" (Longformer model)"),VRo=l(),F1=a("li"),f1e=a("strong"),XRo=o("longt5"),zRo=o(" \u2014 "),PX=a("a"),QRo=o("LongT5Model"),WRo=o(" (LongT5 model)"),URo=l(),T1=a("li"),g1e=a("strong"),HRo=o("luke"),JRo=o(" \u2014 "),BX=a("a"),YRo=o("LukeModel"),ZRo=o(" (LUKE model)"),KRo=l(),M1=a("li"),h1e=a("strong"),ePo=o("lxmert"),oPo=o(" \u2014 "),IX=a("a"),rPo=o("LxmertModel"),tPo=o(" (LXMERT model)"),aPo=l(),E1=a("li"),u1e=a("strong"),nPo=o("m2m_100"),sPo=o(" \u2014 "),NX=a("a"),lPo=o("M2M100Model"),iPo=o(" (M2M100 model)"),dPo=l(),C1=a("li"),p1e=a("strong"),cPo=o("marian"),mPo=o(" \u2014 "),qX=a("a"),fPo=o("MarianModel"),gPo=o(" (Marian model)"),hPo=l(),w1=a("li"),_1e=a("strong"),uPo=o("markuplm"),pPo=o(" \u2014 "),jX=a("a"),_Po=o("MarkupLMModel"),bPo=o(" (MarkupLM model)"),vPo=l(),A1=a("li"),b1e=a("strong"),FPo=o("maskformer"),TPo=o(" \u2014 "),DX=a("a"),MPo=o("MaskFormerModel"),EPo=o(" (MaskFormer model)"),CPo=l(),L1=a("li"),v1e=a("strong"),wPo=o("mbart"),APo=o(" \u2014 "),GX=a("a"),LPo=o("MBartModel"),yPo=o(" (mBART model)"),xPo=l(),y1=a("li"),F1e=a("strong"),$Po=o("mctct"),kPo=o(" \u2014 "),OX=a("a"),SPo=o("MCTCTModel"),RPo=o(" (M-CTC-T model)"),PPo=l(),x1=a("li"),T1e=a("strong"),BPo=o("megatron-bert"),IPo=o(" \u2014 "),VX=a("a"),NPo=o("MegatronBertModel"),qPo=o(" (Megatron-BERT model)"),jPo=l(),$1=a("li"),M1e=a("strong"),DPo=o("mobilebert"),GPo=o(" \u2014 "),XX=a("a"),OPo=o("MobileBertModel"),VPo=o(" (MobileBERT model)"),XPo=l(),k1=a("li"),E1e=a("strong"),zPo=o("mobilevit"),QPo=o(" \u2014 "),zX=a("a"),WPo=o("MobileViTModel"),UPo=o(" (MobileViT model)"),HPo=l(),S1=a("li"),C1e=a("strong"),JPo=o("mpnet"),YPo=o(" \u2014 "),QX=a("a"),ZPo=o("MPNetModel"),KPo=o(" (MPNet model)"),eBo=l(),R1=a("li"),w1e=a("strong"),oBo=o("mt5"),rBo=o(" \u2014 "),WX=a("a"),tBo=o("MT5Model"),aBo=o(" (MT5 model)"),nBo=l(),P1=a("li"),A1e=a("strong"),sBo=o("mvp"),lBo=o(" \u2014 "),UX=a("a"),iBo=o("MvpModel"),dBo=o(" (MVP model)"),cBo=l(),B1=a("li"),L1e=a("strong"),mBo=o("nezha"),fBo=o(" \u2014 "),HX=a("a"),gBo=o("NezhaModel"),hBo=o(" (Nezha model)"),uBo=l(),I1=a("li"),y1e=a("strong"),pBo=o("nllb"),_Bo=o(" \u2014 "),JX=a("a"),bBo=o("M2M100Model"),vBo=o(" (NLLB model)"),FBo=l(),N1=a("li"),x1e=a("strong"),TBo=o("nystromformer"),MBo=o(" \u2014 "),YX=a("a"),EBo=o("NystromformerModel"),CBo=o(" (Nystr\xF6mformer model)"),wBo=l(),q1=a("li"),$1e=a("strong"),ABo=o("openai-gpt"),LBo=o(" \u2014 "),ZX=a("a"),yBo=o("OpenAIGPTModel"),xBo=o(" (OpenAI GPT model)"),$Bo=l(),j1=a("li"),k1e=a("strong"),kBo=o("opt"),SBo=o(" \u2014 "),KX=a("a"),RBo=o("OPTModel"),PBo=o(" (OPT model)"),BBo=l(),D1=a("li"),S1e=a("strong"),IBo=o("owlvit"),NBo=o(" \u2014 "),ez=a("a"),qBo=o("OwlViTModel"),jBo=o(" (OWL-ViT model)"),DBo=l(),G1=a("li"),R1e=a("strong"),GBo=o("pegasus"),OBo=o(" \u2014 "),oz=a("a"),VBo=o("PegasusModel"),XBo=o(" (Pegasus model)"),zBo=l(),O1=a("li"),P1e=a("strong"),QBo=o("pegasus_x"),WBo=o(" \u2014 "),rz=a("a"),UBo=o("PegasusXModel"),HBo=o(" (PEGASUS-X model)"),JBo=l(),V1=a("li"),B1e=a("strong"),YBo=o("perceiver"),ZBo=o(" \u2014 "),tz=a("a"),KBo=o("PerceiverModel"),eIo=o(" (Perceiver model)"),oIo=l(),X1=a("li"),I1e=a("strong"),rIo=o("plbart"),tIo=o(" \u2014 "),az=a("a"),aIo=o("PLBartModel"),nIo=o(" (PLBart model)"),sIo=l(),z1=a("li"),N1e=a("strong"),lIo=o("poolformer"),iIo=o(" \u2014 "),nz=a("a"),dIo=o("PoolFormerModel"),cIo=o(" (PoolFormer model)"),mIo=l(),Q1=a("li"),q1e=a("strong"),fIo=o("prophetnet"),gIo=o(" \u2014 "),sz=a("a"),hIo=o("ProphetNetModel"),uIo=o(" (ProphetNet model)"),pIo=l(),W1=a("li"),j1e=a("strong"),_Io=o("qdqbert"),bIo=o(" \u2014 "),lz=a("a"),vIo=o("QDQBertModel"),FIo=o(" (QDQBert model)"),TIo=l(),U1=a("li"),D1e=a("strong"),MIo=o("reformer"),EIo=o(" \u2014 "),iz=a("a"),CIo=o("ReformerModel"),wIo=o(" (Reformer model)"),AIo=l(),H1=a("li"),G1e=a("strong"),LIo=o("regnet"),yIo=o(" \u2014 "),dz=a("a"),xIo=o("RegNetModel"),$Io=o(" (RegNet model)"),kIo=l(),J1=a("li"),O1e=a("strong"),SIo=o("rembert"),RIo=o(" \u2014 "),cz=a("a"),PIo=o("RemBertModel"),BIo=o(" (RemBERT model)"),IIo=l(),Y1=a("li"),V1e=a("strong"),NIo=o("resnet"),qIo=o(" \u2014 "),mz=a("a"),jIo=o("ResNetModel"),DIo=o(" (ResNet model)"),GIo=l(),Z1=a("li"),X1e=a("strong"),OIo=o("retribert"),VIo=o(" \u2014 "),fz=a("a"),XIo=o("RetriBertModel"),zIo=o(" (RetriBERT model)"),QIo=l(),K1=a("li"),z1e=a("strong"),WIo=o("roberta"),UIo=o(" \u2014 "),gz=a("a"),HIo=o("RobertaModel"),JIo=o(" (RoBERTa model)"),YIo=l(),eb=a("li"),Q1e=a("strong"),ZIo=o("roformer"),KIo=o(" \u2014 "),hz=a("a"),eNo=o("RoFormerModel"),oNo=o(" (RoFormer model)"),rNo=l(),ob=a("li"),W1e=a("strong"),tNo=o("segformer"),aNo=o(" \u2014 "),uz=a("a"),nNo=o("SegformerModel"),sNo=o(" (SegFormer model)"),lNo=l(),rb=a("li"),U1e=a("strong"),iNo=o("sew"),dNo=o(" \u2014 "),pz=a("a"),cNo=o("SEWModel"),mNo=o(" (SEW model)"),fNo=l(),tb=a("li"),H1e=a("strong"),gNo=o("sew-d"),hNo=o(" \u2014 "),_z=a("a"),uNo=o("SEWDModel"),pNo=o(" (SEW-D model)"),_No=l(),ab=a("li"),J1e=a("strong"),bNo=o("speech_to_text"),vNo=o(" \u2014 "),bz=a("a"),FNo=o("Speech2TextModel"),TNo=o(" (Speech2Text model)"),MNo=l(),nb=a("li"),Y1e=a("strong"),ENo=o("splinter"),CNo=o(" \u2014 "),vz=a("a"),wNo=o("SplinterModel"),ANo=o(" (Splinter model)"),LNo=l(),sb=a("li"),Z1e=a("strong"),yNo=o("squeezebert"),xNo=o(" \u2014 "),Fz=a("a"),$No=o("SqueezeBertModel"),kNo=o(" (SqueezeBERT model)"),SNo=l(),lb=a("li"),K1e=a("strong"),RNo=o("swin"),PNo=o(" \u2014 "),Tz=a("a"),BNo=o("SwinModel"),INo=o(" (Swin Transformer model)"),NNo=l(),ib=a("li"),ebe=a("strong"),qNo=o("swinv2"),jNo=o(" \u2014 "),Mz=a("a"),DNo=o("Swinv2Model"),GNo=o(" (Swin Transformer V2 model)"),ONo=l(),db=a("li"),obe=a("strong"),VNo=o("t5"),XNo=o(" \u2014 "),Ez=a("a"),zNo=o("T5Model"),QNo=o(" (T5 model)"),WNo=l(),cb=a("li"),rbe=a("strong"),UNo=o("tapas"),HNo=o(" \u2014 "),Cz=a("a"),JNo=o("TapasModel"),YNo=o(" (TAPAS model)"),ZNo=l(),mb=a("li"),tbe=a("strong"),KNo=o("time_series_transformer"),eqo=o(" \u2014 "),wz=a("a"),oqo=o("TimeSeriesTransformerModel"),rqo=o(" (Time Series Transformer model)"),tqo=l(),fb=a("li"),abe=a("strong"),aqo=o("trajectory_transformer"),nqo=o(" \u2014 "),Az=a("a"),sqo=o("TrajectoryTransformerModel"),lqo=o(" (Trajectory Transformer model)"),iqo=l(),gb=a("li"),nbe=a("strong"),dqo=o("transfo-xl"),cqo=o(" \u2014 "),Lz=a("a"),mqo=o("TransfoXLModel"),fqo=o(" (Transformer-XL model)"),gqo=l(),hb=a("li"),sbe=a("strong"),hqo=o("unispeech"),uqo=o(" \u2014 "),yz=a("a"),pqo=o("UniSpeechModel"),_qo=o(" (UniSpeech model)"),bqo=l(),ub=a("li"),lbe=a("strong"),vqo=o("unispeech-sat"),Fqo=o(" \u2014 "),xz=a("a"),Tqo=o("UniSpeechSatModel"),Mqo=o(" (UniSpeechSat model)"),Eqo=l(),pb=a("li"),ibe=a("strong"),Cqo=o("van"),wqo=o(" \u2014 "),$z=a("a"),Aqo=o("VanModel"),Lqo=o(" (VAN model)"),yqo=l(),_b=a("li"),dbe=a("strong"),xqo=o("videomae"),$qo=o(" \u2014 "),kz=a("a"),kqo=o("VideoMAEModel"),Sqo=o(" (VideoMAE model)"),Rqo=l(),bb=a("li"),cbe=a("strong"),Pqo=o("vilt"),Bqo=o(" \u2014 "),Sz=a("a"),Iqo=o("ViltModel"),Nqo=o(" (ViLT model)"),qqo=l(),vb=a("li"),mbe=a("strong"),jqo=o("vision-text-dual-encoder"),Dqo=o(" \u2014 "),Rz=a("a"),Gqo=o("VisionTextDualEncoderModel"),Oqo=o(" (VisionTextDualEncoder model)"),Vqo=l(),Fb=a("li"),fbe=a("strong"),Xqo=o("visual_bert"),zqo=o(" \u2014 "),Pz=a("a"),Qqo=o("VisualBertModel"),Wqo=o(" (VisualBERT model)"),Uqo=l(),Tb=a("li"),gbe=a("strong"),Hqo=o("vit"),Jqo=o(" \u2014 "),Bz=a("a"),Yqo=o("ViTModel"),Zqo=o(" (ViT model)"),Kqo=l(),Mb=a("li"),hbe=a("strong"),ejo=o("vit_mae"),ojo=o(" \u2014 "),Iz=a("a"),rjo=o("ViTMAEModel"),tjo=o(" (ViTMAE model)"),ajo=l(),Eb=a("li"),ube=a("strong"),njo=o("vit_msn"),sjo=o(" \u2014 "),Nz=a("a"),ljo=o("ViTMSNModel"),ijo=o(" (ViTMSN model)"),djo=l(),Cb=a("li"),pbe=a("strong"),cjo=o("wav2vec2"),mjo=o(" \u2014 "),qz=a("a"),fjo=o("Wav2Vec2Model"),gjo=o(" (Wav2Vec2 model)"),hjo=l(),wb=a("li"),_be=a("strong"),ujo=o("wav2vec2-conformer"),pjo=o(" \u2014 "),jz=a("a"),_jo=o("Wav2Vec2ConformerModel"),bjo=o(" (Wav2Vec2-Conformer model)"),vjo=l(),Ab=a("li"),bbe=a("strong"),Fjo=o("wavlm"),Tjo=o(" \u2014 "),Dz=a("a"),Mjo=o("WavLMModel"),Ejo=o(" (WavLM model)"),Cjo=l(),Lb=a("li"),vbe=a("strong"),wjo=o("whisper"),Ajo=o(" \u2014 "),Gz=a("a"),Ljo=o("WhisperModel"),yjo=o(" (Whisper model)"),xjo=l(),yb=a("li"),Fbe=a("strong"),$jo=o("xclip"),kjo=o(" \u2014 "),Oz=a("a"),Sjo=o("XCLIPModel"),Rjo=o(" (X-CLIP model)"),Pjo=l(),xb=a("li"),Tbe=a("strong"),Bjo=o("xglm"),Ijo=o(" \u2014 "),Vz=a("a"),Njo=o("XGLMModel"),qjo=o(" (XGLM model)"),jjo=l(),$b=a("li"),Mbe=a("strong"),Djo=o("xlm"),Gjo=o(" \u2014 "),Xz=a("a"),Ojo=o("XLMModel"),Vjo=o(" (XLM model)"),Xjo=l(),kb=a("li"),Ebe=a("strong"),zjo=o("xlm-prophetnet"),Qjo=o(" \u2014 "),zz=a("a"),Wjo=o("XLMProphetNetModel"),Ujo=o(" (XLM-ProphetNet model)"),Hjo=l(),Sb=a("li"),Cbe=a("strong"),Jjo=o("xlm-roberta"),Yjo=o(" \u2014 "),Qz=a("a"),Zjo=o("XLMRobertaModel"),Kjo=o(" (XLM-RoBERTa model)"),eDo=l(),Rb=a("li"),wbe=a("strong"),oDo=o("xlm-roberta-xl"),rDo=o(" \u2014 "),Wz=a("a"),tDo=o("XLMRobertaXLModel"),aDo=o(" (XLM-RoBERTa-XL model)"),nDo=l(),Pb=a("li"),Abe=a("strong"),sDo=o("xlnet"),lDo=o(" \u2014 "),Uz=a("a"),iDo=o("XLNetModel"),dDo=o(" (XLNet model)"),cDo=l(),Bb=a("li"),Lbe=a("strong"),mDo=o("yolos"),fDo=o(" \u2014 "),Hz=a("a"),gDo=o("YolosModel"),hDo=o(" (YOLOS model)"),uDo=l(),Ib=a("li"),ybe=a("strong"),pDo=o("yoso"),_Do=o(" \u2014 "),Jz=a("a"),bDo=o("YosoModel"),vDo=o(" (YOSO model)"),FDo=l(),Nb=a("p"),TDo=o("The model is set in evaluation mode by default using "),xbe=a("code"),MDo=o("model.eval()"),EDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$be=a("code"),CDo=o("model.train()"),wDo=l(),F(qb.$$.fragment),Eoo=l(),Ad=a("h2"),jb=a("a"),kbe=a("span"),F(t$.$$.fragment),ADo=l(),Sbe=a("span"),LDo=o("AutoModelForPreTraining"),Coo=l(),Io=a("div"),F(a$.$$.fragment),yDo=l(),Ld=a("p"),xDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yz=a("a"),$Do=o("from_pretrained()"),kDo=o(" class method or the "),Zz=a("a"),SDo=o("from_config()"),RDo=o(` class
method.`),PDo=l(),n$=a("p"),BDo=o("This class cannot be instantiated directly using "),Rbe=a("code"),IDo=o("__init__()"),NDo=o(" (throws an error)."),qDo=l(),Ft=a("div"),F(s$.$$.fragment),jDo=l(),Pbe=a("p"),DDo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),GDo=l(),yd=a("p"),ODo=o(`Note:
Loading a model from its configuration file does `),Bbe=a("strong"),VDo=o("not"),XDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kz=a("a"),zDo=o("from_pretrained()"),QDo=o(" to load the model weights."),WDo=l(),F(Db.$$.fragment),UDo=l(),eo=a("div"),F(l$.$$.fragment),HDo=l(),Ibe=a("p"),JDo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),YDo=l(),on=a("p"),ZDo=o("The model class to instantiate is selected based on the "),Nbe=a("code"),KDo=o("model_type"),eGo=o(` property of the config object (either
passed as an argument or loaded from `),qbe=a("code"),oGo=o("pretrained_model_name_or_path"),rGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jbe=a("code"),tGo=o("pretrained_model_name_or_path"),aGo=o(":"),nGo=l(),G=a("ul"),Gb=a("li"),Dbe=a("strong"),sGo=o("albert"),lGo=o(" \u2014 "),eQ=a("a"),iGo=o("AlbertForPreTraining"),dGo=o(" (ALBERT model)"),cGo=l(),Ob=a("li"),Gbe=a("strong"),mGo=o("bart"),fGo=o(" \u2014 "),oQ=a("a"),gGo=o("BartForConditionalGeneration"),hGo=o(" (BART model)"),uGo=l(),Vb=a("li"),Obe=a("strong"),pGo=o("bert"),_Go=o(" \u2014 "),rQ=a("a"),bGo=o("BertForPreTraining"),vGo=o(" (BERT model)"),FGo=l(),Xb=a("li"),Vbe=a("strong"),TGo=o("big_bird"),MGo=o(" \u2014 "),tQ=a("a"),EGo=o("BigBirdForPreTraining"),CGo=o(" (BigBird model)"),wGo=l(),zb=a("li"),Xbe=a("strong"),AGo=o("bloom"),LGo=o(" \u2014 "),aQ=a("a"),yGo=o("BloomForCausalLM"),xGo=o(" (BLOOM model)"),$Go=l(),Qb=a("li"),zbe=a("strong"),kGo=o("camembert"),SGo=o(" \u2014 "),nQ=a("a"),RGo=o("CamembertForMaskedLM"),PGo=o(" (CamemBERT model)"),BGo=l(),Wb=a("li"),Qbe=a("strong"),IGo=o("ctrl"),NGo=o(" \u2014 "),sQ=a("a"),qGo=o("CTRLLMHeadModel"),jGo=o(" (CTRL model)"),DGo=l(),Ub=a("li"),Wbe=a("strong"),GGo=o("data2vec-text"),OGo=o(" \u2014 "),lQ=a("a"),VGo=o("Data2VecTextForMaskedLM"),XGo=o(" (Data2VecText model)"),zGo=l(),Hb=a("li"),Ube=a("strong"),QGo=o("deberta"),WGo=o(" \u2014 "),iQ=a("a"),UGo=o("DebertaForMaskedLM"),HGo=o(" (DeBERTa model)"),JGo=l(),Jb=a("li"),Hbe=a("strong"),YGo=o("deberta-v2"),ZGo=o(" \u2014 "),dQ=a("a"),KGo=o("DebertaV2ForMaskedLM"),eOo=o(" (DeBERTa-v2 model)"),oOo=l(),Yb=a("li"),Jbe=a("strong"),rOo=o("distilbert"),tOo=o(" \u2014 "),cQ=a("a"),aOo=o("DistilBertForMaskedLM"),nOo=o(" (DistilBERT model)"),sOo=l(),Zb=a("li"),Ybe=a("strong"),lOo=o("electra"),iOo=o(" \u2014 "),mQ=a("a"),dOo=o("ElectraForPreTraining"),cOo=o(" (ELECTRA model)"),mOo=l(),Kb=a("li"),Zbe=a("strong"),fOo=o("ernie"),gOo=o(" \u2014 "),fQ=a("a"),hOo=o("ErnieForPreTraining"),uOo=o(" (ERNIE model)"),pOo=l(),e2=a("li"),Kbe=a("strong"),_Oo=o("flaubert"),bOo=o(" \u2014 "),gQ=a("a"),vOo=o("FlaubertWithLMHeadModel"),FOo=o(" (FlauBERT model)"),TOo=l(),o2=a("li"),e2e=a("strong"),MOo=o("flava"),EOo=o(" \u2014 "),hQ=a("a"),COo=o("FlavaForPreTraining"),wOo=o(" (FLAVA model)"),AOo=l(),r2=a("li"),o2e=a("strong"),LOo=o("fnet"),yOo=o(" \u2014 "),uQ=a("a"),xOo=o("FNetForPreTraining"),$Oo=o(" (FNet model)"),kOo=l(),t2=a("li"),r2e=a("strong"),SOo=o("fsmt"),ROo=o(" \u2014 "),pQ=a("a"),POo=o("FSMTForConditionalGeneration"),BOo=o(" (FairSeq Machine-Translation model)"),IOo=l(),a2=a("li"),t2e=a("strong"),NOo=o("funnel"),qOo=o(" \u2014 "),_Q=a("a"),jOo=o("FunnelForPreTraining"),DOo=o(" (Funnel Transformer model)"),GOo=l(),n2=a("li"),a2e=a("strong"),OOo=o("gpt2"),VOo=o(" \u2014 "),bQ=a("a"),XOo=o("GPT2LMHeadModel"),zOo=o(" (OpenAI GPT-2 model)"),QOo=l(),s2=a("li"),n2e=a("strong"),WOo=o("ibert"),UOo=o(" \u2014 "),vQ=a("a"),HOo=o("IBertForMaskedLM"),JOo=o(" (I-BERT model)"),YOo=l(),l2=a("li"),s2e=a("strong"),ZOo=o("layoutlm"),KOo=o(" \u2014 "),FQ=a("a"),eVo=o("LayoutLMForMaskedLM"),oVo=o(" (LayoutLM model)"),rVo=l(),i2=a("li"),l2e=a("strong"),tVo=o("longformer"),aVo=o(" \u2014 "),TQ=a("a"),nVo=o("LongformerForMaskedLM"),sVo=o(" (Longformer model)"),lVo=l(),d2=a("li"),i2e=a("strong"),iVo=o("luke"),dVo=o(" \u2014 "),MQ=a("a"),cVo=o("LukeForMaskedLM"),mVo=o(" (LUKE model)"),fVo=l(),c2=a("li"),d2e=a("strong"),gVo=o("lxmert"),hVo=o(" \u2014 "),EQ=a("a"),uVo=o("LxmertForPreTraining"),pVo=o(" (LXMERT model)"),_Vo=l(),m2=a("li"),c2e=a("strong"),bVo=o("megatron-bert"),vVo=o(" \u2014 "),CQ=a("a"),FVo=o("MegatronBertForPreTraining"),TVo=o(" (Megatron-BERT model)"),MVo=l(),f2=a("li"),m2e=a("strong"),EVo=o("mobilebert"),CVo=o(" \u2014 "),wQ=a("a"),wVo=o("MobileBertForPreTraining"),AVo=o(" (MobileBERT model)"),LVo=l(),g2=a("li"),f2e=a("strong"),yVo=o("mpnet"),xVo=o(" \u2014 "),AQ=a("a"),$Vo=o("MPNetForMaskedLM"),kVo=o(" (MPNet model)"),SVo=l(),h2=a("li"),g2e=a("strong"),RVo=o("mvp"),PVo=o(" \u2014 "),LQ=a("a"),BVo=o("MvpForConditionalGeneration"),IVo=o(" (MVP model)"),NVo=l(),u2=a("li"),h2e=a("strong"),qVo=o("nezha"),jVo=o(" \u2014 "),yQ=a("a"),DVo=o("NezhaForPreTraining"),GVo=o(" (Nezha model)"),OVo=l(),p2=a("li"),u2e=a("strong"),VVo=o("openai-gpt"),XVo=o(" \u2014 "),xQ=a("a"),zVo=o("OpenAIGPTLMHeadModel"),QVo=o(" (OpenAI GPT model)"),WVo=l(),_2=a("li"),p2e=a("strong"),UVo=o("retribert"),HVo=o(" \u2014 "),$Q=a("a"),JVo=o("RetriBertModel"),YVo=o(" (RetriBERT model)"),ZVo=l(),b2=a("li"),_2e=a("strong"),KVo=o("roberta"),eXo=o(" \u2014 "),kQ=a("a"),oXo=o("RobertaForMaskedLM"),rXo=o(" (RoBERTa model)"),tXo=l(),v2=a("li"),b2e=a("strong"),aXo=o("splinter"),nXo=o(" \u2014 "),SQ=a("a"),sXo=o("SplinterForPreTraining"),lXo=o(" (Splinter model)"),iXo=l(),F2=a("li"),v2e=a("strong"),dXo=o("squeezebert"),cXo=o(" \u2014 "),RQ=a("a"),mXo=o("SqueezeBertForMaskedLM"),fXo=o(" (SqueezeBERT model)"),gXo=l(),T2=a("li"),F2e=a("strong"),hXo=o("t5"),uXo=o(" \u2014 "),PQ=a("a"),pXo=o("T5ForConditionalGeneration"),_Xo=o(" (T5 model)"),bXo=l(),M2=a("li"),T2e=a("strong"),vXo=o("tapas"),FXo=o(" \u2014 "),BQ=a("a"),TXo=o("TapasForMaskedLM"),MXo=o(" (TAPAS model)"),EXo=l(),E2=a("li"),M2e=a("strong"),CXo=o("transfo-xl"),wXo=o(" \u2014 "),IQ=a("a"),AXo=o("TransfoXLLMHeadModel"),LXo=o(" (Transformer-XL model)"),yXo=l(),C2=a("li"),E2e=a("strong"),xXo=o("unispeech"),$Xo=o(" \u2014 "),NQ=a("a"),kXo=o("UniSpeechForPreTraining"),SXo=o(" (UniSpeech model)"),RXo=l(),w2=a("li"),C2e=a("strong"),PXo=o("unispeech-sat"),BXo=o(" \u2014 "),qQ=a("a"),IXo=o("UniSpeechSatForPreTraining"),NXo=o(" (UniSpeechSat model)"),qXo=l(),A2=a("li"),w2e=a("strong"),jXo=o("videomae"),DXo=o(" \u2014 "),jQ=a("a"),GXo=o("VideoMAEForPreTraining"),OXo=o(" (VideoMAE model)"),VXo=l(),L2=a("li"),A2e=a("strong"),XXo=o("visual_bert"),zXo=o(" \u2014 "),DQ=a("a"),QXo=o("VisualBertForPreTraining"),WXo=o(" (VisualBERT model)"),UXo=l(),y2=a("li"),L2e=a("strong"),HXo=o("vit_mae"),JXo=o(" \u2014 "),GQ=a("a"),YXo=o("ViTMAEForPreTraining"),ZXo=o(" (ViTMAE model)"),KXo=l(),x2=a("li"),y2e=a("strong"),ezo=o("wav2vec2"),ozo=o(" \u2014 "),OQ=a("a"),rzo=o("Wav2Vec2ForPreTraining"),tzo=o(" (Wav2Vec2 model)"),azo=l(),$2=a("li"),x2e=a("strong"),nzo=o("wav2vec2-conformer"),szo=o(" \u2014 "),VQ=a("a"),lzo=o("Wav2Vec2ConformerForPreTraining"),izo=o(" (Wav2Vec2-Conformer model)"),dzo=l(),k2=a("li"),$2e=a("strong"),czo=o("xlm"),mzo=o(" \u2014 "),XQ=a("a"),fzo=o("XLMWithLMHeadModel"),gzo=o(" (XLM model)"),hzo=l(),S2=a("li"),k2e=a("strong"),uzo=o("xlm-roberta"),pzo=o(" \u2014 "),zQ=a("a"),_zo=o("XLMRobertaForMaskedLM"),bzo=o(" (XLM-RoBERTa model)"),vzo=l(),R2=a("li"),S2e=a("strong"),Fzo=o("xlm-roberta-xl"),Tzo=o(" \u2014 "),QQ=a("a"),Mzo=o("XLMRobertaXLForMaskedLM"),Ezo=o(" (XLM-RoBERTa-XL model)"),Czo=l(),P2=a("li"),R2e=a("strong"),wzo=o("xlnet"),Azo=o(" \u2014 "),WQ=a("a"),Lzo=o("XLNetLMHeadModel"),yzo=o(" (XLNet model)"),xzo=l(),B2=a("p"),$zo=o("The model is set in evaluation mode by default using "),P2e=a("code"),kzo=o("model.eval()"),Szo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B2e=a("code"),Rzo=o("model.train()"),Pzo=l(),F(I2.$$.fragment),woo=l(),xd=a("h2"),N2=a("a"),I2e=a("span"),F(i$.$$.fragment),Bzo=l(),N2e=a("span"),Izo=o("AutoModelForCausalLM"),Aoo=l(),No=a("div"),F(d$.$$.fragment),Nzo=l(),$d=a("p"),qzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),UQ=a("a"),jzo=o("from_pretrained()"),Dzo=o(" class method or the "),HQ=a("a"),Gzo=o("from_config()"),Ozo=o(` class
method.`),Vzo=l(),c$=a("p"),Xzo=o("This class cannot be instantiated directly using "),q2e=a("code"),zzo=o("__init__()"),Qzo=o(" (throws an error)."),Wzo=l(),Tt=a("div"),F(m$.$$.fragment),Uzo=l(),j2e=a("p"),Hzo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Jzo=l(),kd=a("p"),Yzo=o(`Note:
Loading a model from its configuration file does `),D2e=a("strong"),Zzo=o("not"),Kzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JQ=a("a"),eQo=o("from_pretrained()"),oQo=o(" to load the model weights."),rQo=l(),F(q2.$$.fragment),tQo=l(),oo=a("div"),F(f$.$$.fragment),aQo=l(),G2e=a("p"),nQo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),sQo=l(),rn=a("p"),lQo=o("The model class to instantiate is selected based on the "),O2e=a("code"),iQo=o("model_type"),dQo=o(` property of the config object (either
passed as an argument or loaded from `),V2e=a("code"),cQo=o("pretrained_model_name_or_path"),mQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X2e=a("code"),fQo=o("pretrained_model_name_or_path"),gQo=o(":"),hQo=l(),Q=a("ul"),j2=a("li"),z2e=a("strong"),uQo=o("bart"),pQo=o(" \u2014 "),YQ=a("a"),_Qo=o("BartForCausalLM"),bQo=o(" (BART model)"),vQo=l(),D2=a("li"),Q2e=a("strong"),FQo=o("bert"),TQo=o(" \u2014 "),ZQ=a("a"),MQo=o("BertLMHeadModel"),EQo=o(" (BERT model)"),CQo=l(),G2=a("li"),W2e=a("strong"),wQo=o("bert-generation"),AQo=o(" \u2014 "),KQ=a("a"),LQo=o("BertGenerationDecoder"),yQo=o(" (Bert Generation model)"),xQo=l(),O2=a("li"),U2e=a("strong"),$Qo=o("big_bird"),kQo=o(" \u2014 "),eW=a("a"),SQo=o("BigBirdForCausalLM"),RQo=o(" (BigBird model)"),PQo=l(),V2=a("li"),H2e=a("strong"),BQo=o("bigbird_pegasus"),IQo=o(" \u2014 "),oW=a("a"),NQo=o("BigBirdPegasusForCausalLM"),qQo=o(" (BigBird-Pegasus model)"),jQo=l(),X2=a("li"),J2e=a("strong"),DQo=o("blenderbot"),GQo=o(" \u2014 "),rW=a("a"),OQo=o("BlenderbotForCausalLM"),VQo=o(" (Blenderbot model)"),XQo=l(),z2=a("li"),Y2e=a("strong"),zQo=o("blenderbot-small"),QQo=o(" \u2014 "),tW=a("a"),WQo=o("BlenderbotSmallForCausalLM"),UQo=o(" (BlenderbotSmall model)"),HQo=l(),Q2=a("li"),Z2e=a("strong"),JQo=o("bloom"),YQo=o(" \u2014 "),aW=a("a"),ZQo=o("BloomForCausalLM"),KQo=o(" (BLOOM model)"),eWo=l(),W2=a("li"),K2e=a("strong"),oWo=o("camembert"),rWo=o(" \u2014 "),nW=a("a"),tWo=o("CamembertForCausalLM"),aWo=o(" (CamemBERT model)"),nWo=l(),U2=a("li"),eve=a("strong"),sWo=o("codegen"),lWo=o(" \u2014 "),sW=a("a"),iWo=o("CodeGenForCausalLM"),dWo=o(" (CodeGen model)"),cWo=l(),H2=a("li"),ove=a("strong"),mWo=o("ctrl"),fWo=o(" \u2014 "),lW=a("a"),gWo=o("CTRLLMHeadModel"),hWo=o(" (CTRL model)"),uWo=l(),J2=a("li"),rve=a("strong"),pWo=o("data2vec-text"),_Wo=o(" \u2014 "),iW=a("a"),bWo=o("Data2VecTextForCausalLM"),vWo=o(" (Data2VecText model)"),FWo=l(),Y2=a("li"),tve=a("strong"),TWo=o("electra"),MWo=o(" \u2014 "),dW=a("a"),EWo=o("ElectraForCausalLM"),CWo=o(" (ELECTRA model)"),wWo=l(),Z2=a("li"),ave=a("strong"),AWo=o("ernie"),LWo=o(" \u2014 "),cW=a("a"),yWo=o("ErnieForCausalLM"),xWo=o(" (ERNIE model)"),$Wo=l(),K2=a("li"),nve=a("strong"),kWo=o("gpt2"),SWo=o(" \u2014 "),mW=a("a"),RWo=o("GPT2LMHeadModel"),PWo=o(" (OpenAI GPT-2 model)"),BWo=l(),ev=a("li"),sve=a("strong"),IWo=o("gpt_neo"),NWo=o(" \u2014 "),fW=a("a"),qWo=o("GPTNeoForCausalLM"),jWo=o(" (GPT Neo model)"),DWo=l(),ov=a("li"),lve=a("strong"),GWo=o("gpt_neox"),OWo=o(" \u2014 "),gW=a("a"),VWo=o("GPTNeoXForCausalLM"),XWo=o(" (GPT NeoX model)"),zWo=l(),rv=a("li"),ive=a("strong"),QWo=o("gpt_neox_japanese"),WWo=o(" \u2014 "),hW=a("a"),UWo=o("GPTNeoXJapaneseForCausalLM"),HWo=o(" (GPT NeoX Japanese model)"),JWo=l(),tv=a("li"),dve=a("strong"),YWo=o("gptj"),ZWo=o(" \u2014 "),uW=a("a"),KWo=o("GPTJForCausalLM"),eUo=o(" (GPT-J model)"),oUo=l(),av=a("li"),cve=a("strong"),rUo=o("marian"),tUo=o(" \u2014 "),pW=a("a"),aUo=o("MarianForCausalLM"),nUo=o(" (Marian model)"),sUo=l(),nv=a("li"),mve=a("strong"),lUo=o("mbart"),iUo=o(" \u2014 "),_W=a("a"),dUo=o("MBartForCausalLM"),cUo=o(" (mBART model)"),mUo=l(),sv=a("li"),fve=a("strong"),fUo=o("megatron-bert"),gUo=o(" \u2014 "),bW=a("a"),hUo=o("MegatronBertForCausalLM"),uUo=o(" (Megatron-BERT model)"),pUo=l(),lv=a("li"),gve=a("strong"),_Uo=o("mvp"),bUo=o(" \u2014 "),vW=a("a"),vUo=o("MvpForCausalLM"),FUo=o(" (MVP model)"),TUo=l(),iv=a("li"),hve=a("strong"),MUo=o("openai-gpt"),EUo=o(" \u2014 "),FW=a("a"),CUo=o("OpenAIGPTLMHeadModel"),wUo=o(" (OpenAI GPT model)"),AUo=l(),dv=a("li"),uve=a("strong"),LUo=o("opt"),yUo=o(" \u2014 "),TW=a("a"),xUo=o("OPTForCausalLM"),$Uo=o(" (OPT model)"),kUo=l(),cv=a("li"),pve=a("strong"),SUo=o("pegasus"),RUo=o(" \u2014 "),MW=a("a"),PUo=o("PegasusForCausalLM"),BUo=o(" (Pegasus model)"),IUo=l(),mv=a("li"),_ve=a("strong"),NUo=o("plbart"),qUo=o(" \u2014 "),EW=a("a"),jUo=o("PLBartForCausalLM"),DUo=o(" (PLBart model)"),GUo=l(),fv=a("li"),bve=a("strong"),OUo=o("prophetnet"),VUo=o(" \u2014 "),CW=a("a"),XUo=o("ProphetNetForCausalLM"),zUo=o(" (ProphetNet model)"),QUo=l(),gv=a("li"),vve=a("strong"),WUo=o("qdqbert"),UUo=o(" \u2014 "),wW=a("a"),HUo=o("QDQBertLMHeadModel"),JUo=o(" (QDQBert model)"),YUo=l(),hv=a("li"),Fve=a("strong"),ZUo=o("reformer"),KUo=o(" \u2014 "),AW=a("a"),eHo=o("ReformerModelWithLMHead"),oHo=o(" (Reformer model)"),rHo=l(),uv=a("li"),Tve=a("strong"),tHo=o("rembert"),aHo=o(" \u2014 "),LW=a("a"),nHo=o("RemBertForCausalLM"),sHo=o(" (RemBERT model)"),lHo=l(),pv=a("li"),Mve=a("strong"),iHo=o("roberta"),dHo=o(" \u2014 "),yW=a("a"),cHo=o("RobertaForCausalLM"),mHo=o(" (RoBERTa model)"),fHo=l(),_v=a("li"),Eve=a("strong"),gHo=o("roformer"),hHo=o(" \u2014 "),xW=a("a"),uHo=o("RoFormerForCausalLM"),pHo=o(" (RoFormer model)"),_Ho=l(),bv=a("li"),Cve=a("strong"),bHo=o("speech_to_text_2"),vHo=o(" \u2014 "),$W=a("a"),FHo=o("Speech2Text2ForCausalLM"),THo=o(" (Speech2Text2 model)"),MHo=l(),vv=a("li"),wve=a("strong"),EHo=o("transfo-xl"),CHo=o(" \u2014 "),kW=a("a"),wHo=o("TransfoXLLMHeadModel"),AHo=o(" (Transformer-XL model)"),LHo=l(),Fv=a("li"),Ave=a("strong"),yHo=o("trocr"),xHo=o(" \u2014 "),SW=a("a"),$Ho=o("TrOCRForCausalLM"),kHo=o(" (TrOCR model)"),SHo=l(),Tv=a("li"),Lve=a("strong"),RHo=o("xglm"),PHo=o(" \u2014 "),RW=a("a"),BHo=o("XGLMForCausalLM"),IHo=o(" (XGLM model)"),NHo=l(),Mv=a("li"),yve=a("strong"),qHo=o("xlm"),jHo=o(" \u2014 "),PW=a("a"),DHo=o("XLMWithLMHeadModel"),GHo=o(" (XLM model)"),OHo=l(),Ev=a("li"),xve=a("strong"),VHo=o("xlm-prophetnet"),XHo=o(" \u2014 "),BW=a("a"),zHo=o("XLMProphetNetForCausalLM"),QHo=o(" (XLM-ProphetNet model)"),WHo=l(),Cv=a("li"),$ve=a("strong"),UHo=o("xlm-roberta"),HHo=o(" \u2014 "),IW=a("a"),JHo=o("XLMRobertaForCausalLM"),YHo=o(" (XLM-RoBERTa model)"),ZHo=l(),wv=a("li"),kve=a("strong"),KHo=o("xlm-roberta-xl"),eJo=o(" \u2014 "),NW=a("a"),oJo=o("XLMRobertaXLForCausalLM"),rJo=o(" (XLM-RoBERTa-XL model)"),tJo=l(),Av=a("li"),Sve=a("strong"),aJo=o("xlnet"),nJo=o(" \u2014 "),qW=a("a"),sJo=o("XLNetLMHeadModel"),lJo=o(" (XLNet model)"),iJo=l(),Lv=a("p"),dJo=o("The model is set in evaluation mode by default using "),Rve=a("code"),cJo=o("model.eval()"),mJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pve=a("code"),fJo=o("model.train()"),gJo=l(),F(yv.$$.fragment),Loo=l(),Sd=a("h2"),xv=a("a"),Bve=a("span"),F(g$.$$.fragment),hJo=l(),Ive=a("span"),uJo=o("AutoModelForMaskedLM"),yoo=l(),qo=a("div"),F(h$.$$.fragment),pJo=l(),Rd=a("p"),_Jo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jW=a("a"),bJo=o("from_pretrained()"),vJo=o(" class method or the "),DW=a("a"),FJo=o("from_config()"),TJo=o(` class
method.`),MJo=l(),u$=a("p"),EJo=o("This class cannot be instantiated directly using "),Nve=a("code"),CJo=o("__init__()"),wJo=o(" (throws an error)."),AJo=l(),Mt=a("div"),F(p$.$$.fragment),LJo=l(),qve=a("p"),yJo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xJo=l(),Pd=a("p"),$Jo=o(`Note:
Loading a model from its configuration file does `),jve=a("strong"),kJo=o("not"),SJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GW=a("a"),RJo=o("from_pretrained()"),PJo=o(" to load the model weights."),BJo=l(),F($v.$$.fragment),IJo=l(),ro=a("div"),F(_$.$$.fragment),NJo=l(),Dve=a("p"),qJo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),jJo=l(),tn=a("p"),DJo=o("The model class to instantiate is selected based on the "),Gve=a("code"),GJo=o("model_type"),OJo=o(` property of the config object (either
passed as an argument or loaded from `),Ove=a("code"),VJo=o("pretrained_model_name_or_path"),XJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=a("code"),zJo=o("pretrained_model_name_or_path"),QJo=o(":"),WJo=l(),J=a("ul"),kv=a("li"),Xve=a("strong"),UJo=o("albert"),HJo=o(" \u2014 "),OW=a("a"),JJo=o("AlbertForMaskedLM"),YJo=o(" (ALBERT model)"),ZJo=l(),Sv=a("li"),zve=a("strong"),KJo=o("bart"),eYo=o(" \u2014 "),VW=a("a"),oYo=o("BartForConditionalGeneration"),rYo=o(" (BART model)"),tYo=l(),Rv=a("li"),Qve=a("strong"),aYo=o("bert"),nYo=o(" \u2014 "),XW=a("a"),sYo=o("BertForMaskedLM"),lYo=o(" (BERT model)"),iYo=l(),Pv=a("li"),Wve=a("strong"),dYo=o("big_bird"),cYo=o(" \u2014 "),zW=a("a"),mYo=o("BigBirdForMaskedLM"),fYo=o(" (BigBird model)"),gYo=l(),Bv=a("li"),Uve=a("strong"),hYo=o("camembert"),uYo=o(" \u2014 "),QW=a("a"),pYo=o("CamembertForMaskedLM"),_Yo=o(" (CamemBERT model)"),bYo=l(),Iv=a("li"),Hve=a("strong"),vYo=o("convbert"),FYo=o(" \u2014 "),WW=a("a"),TYo=o("ConvBertForMaskedLM"),MYo=o(" (ConvBERT model)"),EYo=l(),Nv=a("li"),Jve=a("strong"),CYo=o("data2vec-text"),wYo=o(" \u2014 "),UW=a("a"),AYo=o("Data2VecTextForMaskedLM"),LYo=o(" (Data2VecText model)"),yYo=l(),qv=a("li"),Yve=a("strong"),xYo=o("deberta"),$Yo=o(" \u2014 "),HW=a("a"),kYo=o("DebertaForMaskedLM"),SYo=o(" (DeBERTa model)"),RYo=l(),jv=a("li"),Zve=a("strong"),PYo=o("deberta-v2"),BYo=o(" \u2014 "),JW=a("a"),IYo=o("DebertaV2ForMaskedLM"),NYo=o(" (DeBERTa-v2 model)"),qYo=l(),Dv=a("li"),Kve=a("strong"),jYo=o("distilbert"),DYo=o(" \u2014 "),YW=a("a"),GYo=o("DistilBertForMaskedLM"),OYo=o(" (DistilBERT model)"),VYo=l(),Gv=a("li"),eFe=a("strong"),XYo=o("electra"),zYo=o(" \u2014 "),ZW=a("a"),QYo=o("ElectraForMaskedLM"),WYo=o(" (ELECTRA model)"),UYo=l(),Ov=a("li"),oFe=a("strong"),HYo=o("ernie"),JYo=o(" \u2014 "),KW=a("a"),YYo=o("ErnieForMaskedLM"),ZYo=o(" (ERNIE model)"),KYo=l(),Vv=a("li"),rFe=a("strong"),eZo=o("flaubert"),oZo=o(" \u2014 "),eU=a("a"),rZo=o("FlaubertWithLMHeadModel"),tZo=o(" (FlauBERT model)"),aZo=l(),Xv=a("li"),tFe=a("strong"),nZo=o("fnet"),sZo=o(" \u2014 "),oU=a("a"),lZo=o("FNetForMaskedLM"),iZo=o(" (FNet model)"),dZo=l(),zv=a("li"),aFe=a("strong"),cZo=o("funnel"),mZo=o(" \u2014 "),rU=a("a"),fZo=o("FunnelForMaskedLM"),gZo=o(" (Funnel Transformer model)"),hZo=l(),Qv=a("li"),nFe=a("strong"),uZo=o("ibert"),pZo=o(" \u2014 "),tU=a("a"),_Zo=o("IBertForMaskedLM"),bZo=o(" (I-BERT model)"),vZo=l(),Wv=a("li"),sFe=a("strong"),FZo=o("layoutlm"),TZo=o(" \u2014 "),aU=a("a"),MZo=o("LayoutLMForMaskedLM"),EZo=o(" (LayoutLM model)"),CZo=l(),Uv=a("li"),lFe=a("strong"),wZo=o("longformer"),AZo=o(" \u2014 "),nU=a("a"),LZo=o("LongformerForMaskedLM"),yZo=o(" (Longformer model)"),xZo=l(),Hv=a("li"),iFe=a("strong"),$Zo=o("luke"),kZo=o(" \u2014 "),sU=a("a"),SZo=o("LukeForMaskedLM"),RZo=o(" (LUKE model)"),PZo=l(),Jv=a("li"),dFe=a("strong"),BZo=o("mbart"),IZo=o(" \u2014 "),lU=a("a"),NZo=o("MBartForConditionalGeneration"),qZo=o(" (mBART model)"),jZo=l(),Yv=a("li"),cFe=a("strong"),DZo=o("megatron-bert"),GZo=o(" \u2014 "),iU=a("a"),OZo=o("MegatronBertForMaskedLM"),VZo=o(" (Megatron-BERT model)"),XZo=l(),Zv=a("li"),mFe=a("strong"),zZo=o("mobilebert"),QZo=o(" \u2014 "),dU=a("a"),WZo=o("MobileBertForMaskedLM"),UZo=o(" (MobileBERT model)"),HZo=l(),Kv=a("li"),fFe=a("strong"),JZo=o("mpnet"),YZo=o(" \u2014 "),cU=a("a"),ZZo=o("MPNetForMaskedLM"),KZo=o(" (MPNet model)"),eKo=l(),eF=a("li"),gFe=a("strong"),oKo=o("mvp"),rKo=o(" \u2014 "),mU=a("a"),tKo=o("MvpForConditionalGeneration"),aKo=o(" (MVP model)"),nKo=l(),oF=a("li"),hFe=a("strong"),sKo=o("nezha"),lKo=o(" \u2014 "),fU=a("a"),iKo=o("NezhaForMaskedLM"),dKo=o(" (Nezha model)"),cKo=l(),rF=a("li"),uFe=a("strong"),mKo=o("nystromformer"),fKo=o(" \u2014 "),gU=a("a"),gKo=o("NystromformerForMaskedLM"),hKo=o(" (Nystr\xF6mformer model)"),uKo=l(),tF=a("li"),pFe=a("strong"),pKo=o("perceiver"),_Ko=o(" \u2014 "),hU=a("a"),bKo=o("PerceiverForMaskedLM"),vKo=o(" (Perceiver model)"),FKo=l(),aF=a("li"),_Fe=a("strong"),TKo=o("qdqbert"),MKo=o(" \u2014 "),uU=a("a"),EKo=o("QDQBertForMaskedLM"),CKo=o(" (QDQBert model)"),wKo=l(),nF=a("li"),bFe=a("strong"),AKo=o("reformer"),LKo=o(" \u2014 "),pU=a("a"),yKo=o("ReformerForMaskedLM"),xKo=o(" (Reformer model)"),$Ko=l(),sF=a("li"),vFe=a("strong"),kKo=o("rembert"),SKo=o(" \u2014 "),_U=a("a"),RKo=o("RemBertForMaskedLM"),PKo=o(" (RemBERT model)"),BKo=l(),lF=a("li"),FFe=a("strong"),IKo=o("roberta"),NKo=o(" \u2014 "),bU=a("a"),qKo=o("RobertaForMaskedLM"),jKo=o(" (RoBERTa model)"),DKo=l(),iF=a("li"),TFe=a("strong"),GKo=o("roformer"),OKo=o(" \u2014 "),vU=a("a"),VKo=o("RoFormerForMaskedLM"),XKo=o(" (RoFormer model)"),zKo=l(),dF=a("li"),MFe=a("strong"),QKo=o("squeezebert"),WKo=o(" \u2014 "),FU=a("a"),UKo=o("SqueezeBertForMaskedLM"),HKo=o(" (SqueezeBERT model)"),JKo=l(),cF=a("li"),EFe=a("strong"),YKo=o("tapas"),ZKo=o(" \u2014 "),TU=a("a"),KKo=o("TapasForMaskedLM"),eer=o(" (TAPAS model)"),oer=l(),mF=a("li"),CFe=a("strong"),rer=o("wav2vec2"),ter=o(" \u2014 "),wFe=a("code"),aer=o("Wav2Vec2ForMaskedLM"),ner=o(" (Wav2Vec2 model)"),ser=l(),fF=a("li"),AFe=a("strong"),ler=o("xlm"),ier=o(" \u2014 "),MU=a("a"),der=o("XLMWithLMHeadModel"),cer=o(" (XLM model)"),mer=l(),gF=a("li"),LFe=a("strong"),fer=o("xlm-roberta"),ger=o(" \u2014 "),EU=a("a"),her=o("XLMRobertaForMaskedLM"),uer=o(" (XLM-RoBERTa model)"),per=l(),hF=a("li"),yFe=a("strong"),_er=o("xlm-roberta-xl"),ber=o(" \u2014 "),CU=a("a"),ver=o("XLMRobertaXLForMaskedLM"),Fer=o(" (XLM-RoBERTa-XL model)"),Ter=l(),uF=a("li"),xFe=a("strong"),Mer=o("yoso"),Eer=o(" \u2014 "),wU=a("a"),Cer=o("YosoForMaskedLM"),wer=o(" (YOSO model)"),Aer=l(),pF=a("p"),Ler=o("The model is set in evaluation mode by default using "),$Fe=a("code"),yer=o("model.eval()"),xer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kFe=a("code"),$er=o("model.train()"),ker=l(),F(_F.$$.fragment),xoo=l(),Bd=a("h2"),bF=a("a"),SFe=a("span"),F(b$.$$.fragment),Ser=l(),RFe=a("span"),Rer=o("AutoModelForSeq2SeqLM"),$oo=l(),jo=a("div"),F(v$.$$.fragment),Per=l(),Id=a("p"),Ber=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),AU=a("a"),Ier=o("from_pretrained()"),Ner=o(" class method or the "),LU=a("a"),qer=o("from_config()"),jer=o(` class
method.`),Der=l(),F$=a("p"),Ger=o("This class cannot be instantiated directly using "),PFe=a("code"),Oer=o("__init__()"),Ver=o(" (throws an error)."),Xer=l(),Et=a("div"),F(T$.$$.fragment),zer=l(),BFe=a("p"),Qer=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Wer=l(),Nd=a("p"),Uer=o(`Note:
Loading a model from its configuration file does `),IFe=a("strong"),Her=o("not"),Jer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yU=a("a"),Yer=o("from_pretrained()"),Zer=o(" to load the model weights."),Ker=l(),F(vF.$$.fragment),eor=l(),to=a("div"),F(M$.$$.fragment),oor=l(),NFe=a("p"),ror=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),tor=l(),an=a("p"),aor=o("The model class to instantiate is selected based on the "),qFe=a("code"),nor=o("model_type"),sor=o(` property of the config object (either
passed as an argument or loaded from `),jFe=a("code"),lor=o("pretrained_model_name_or_path"),ior=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DFe=a("code"),dor=o("pretrained_model_name_or_path"),cor=o(":"),mor=l(),fe=a("ul"),FF=a("li"),GFe=a("strong"),gor=o("bart"),hor=o(" \u2014 "),xU=a("a"),uor=o("BartForConditionalGeneration"),por=o(" (BART model)"),_or=l(),TF=a("li"),OFe=a("strong"),bor=o("bigbird_pegasus"),vor=o(" \u2014 "),$U=a("a"),For=o("BigBirdPegasusForConditionalGeneration"),Tor=o(" (BigBird-Pegasus model)"),Mor=l(),MF=a("li"),VFe=a("strong"),Eor=o("blenderbot"),Cor=o(" \u2014 "),kU=a("a"),wor=o("BlenderbotForConditionalGeneration"),Aor=o(" (Blenderbot model)"),Lor=l(),EF=a("li"),XFe=a("strong"),yor=o("blenderbot-small"),xor=o(" \u2014 "),SU=a("a"),$or=o("BlenderbotSmallForConditionalGeneration"),kor=o(" (BlenderbotSmall model)"),Sor=l(),CF=a("li"),zFe=a("strong"),Ror=o("encoder-decoder"),Por=o(" \u2014 "),RU=a("a"),Bor=o("EncoderDecoderModel"),Ior=o(" (Encoder decoder model)"),Nor=l(),wF=a("li"),QFe=a("strong"),qor=o("fsmt"),jor=o(" \u2014 "),PU=a("a"),Dor=o("FSMTForConditionalGeneration"),Gor=o(" (FairSeq Machine-Translation model)"),Oor=l(),AF=a("li"),WFe=a("strong"),Vor=o("led"),Xor=o(" \u2014 "),BU=a("a"),zor=o("LEDForConditionalGeneration"),Qor=o(" (LED model)"),Wor=l(),LF=a("li"),UFe=a("strong"),Uor=o("longt5"),Hor=o(" \u2014 "),IU=a("a"),Jor=o("LongT5ForConditionalGeneration"),Yor=o(" (LongT5 model)"),Zor=l(),yF=a("li"),HFe=a("strong"),Kor=o("m2m_100"),err=o(" \u2014 "),NU=a("a"),orr=o("M2M100ForConditionalGeneration"),rrr=o(" (M2M100 model)"),trr=l(),xF=a("li"),JFe=a("strong"),arr=o("marian"),nrr=o(" \u2014 "),qU=a("a"),srr=o("MarianMTModel"),lrr=o(" (Marian model)"),irr=l(),$F=a("li"),YFe=a("strong"),drr=o("mbart"),crr=o(" \u2014 "),jU=a("a"),mrr=o("MBartForConditionalGeneration"),frr=o(" (mBART model)"),grr=l(),kF=a("li"),ZFe=a("strong"),hrr=o("mt5"),urr=o(" \u2014 "),DU=a("a"),prr=o("MT5ForConditionalGeneration"),_rr=o(" (MT5 model)"),brr=l(),SF=a("li"),KFe=a("strong"),vrr=o("mvp"),Frr=o(" \u2014 "),GU=a("a"),Trr=o("MvpForConditionalGeneration"),Mrr=o(" (MVP model)"),Err=l(),RF=a("li"),eTe=a("strong"),Crr=o("nllb"),wrr=o(" \u2014 "),OU=a("a"),Arr=o("M2M100ForConditionalGeneration"),Lrr=o(" (NLLB model)"),yrr=l(),PF=a("li"),oTe=a("strong"),xrr=o("pegasus"),$rr=o(" \u2014 "),VU=a("a"),krr=o("PegasusForConditionalGeneration"),Srr=o(" (Pegasus model)"),Rrr=l(),BF=a("li"),rTe=a("strong"),Prr=o("pegasus_x"),Brr=o(" \u2014 "),XU=a("a"),Irr=o("PegasusXForConditionalGeneration"),Nrr=o(" (PEGASUS-X model)"),qrr=l(),IF=a("li"),tTe=a("strong"),jrr=o("plbart"),Drr=o(" \u2014 "),zU=a("a"),Grr=o("PLBartForConditionalGeneration"),Orr=o(" (PLBart model)"),Vrr=l(),NF=a("li"),aTe=a("strong"),Xrr=o("prophetnet"),zrr=o(" \u2014 "),QU=a("a"),Qrr=o("ProphetNetForConditionalGeneration"),Wrr=o(" (ProphetNet model)"),Urr=l(),qF=a("li"),nTe=a("strong"),Hrr=o("t5"),Jrr=o(" \u2014 "),WU=a("a"),Yrr=o("T5ForConditionalGeneration"),Zrr=o(" (T5 model)"),Krr=l(),jF=a("li"),sTe=a("strong"),etr=o("xlm-prophetnet"),otr=o(" \u2014 "),UU=a("a"),rtr=o("XLMProphetNetForConditionalGeneration"),ttr=o(" (XLM-ProphetNet model)"),atr=l(),DF=a("p"),ntr=o("The model is set in evaluation mode by default using "),lTe=a("code"),str=o("model.eval()"),ltr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iTe=a("code"),itr=o("model.train()"),dtr=l(),F(GF.$$.fragment),koo=l(),qd=a("h2"),OF=a("a"),dTe=a("span"),F(E$.$$.fragment),ctr=l(),cTe=a("span"),mtr=o("AutoModelForSequenceClassification"),Soo=l(),Do=a("div"),F(C$.$$.fragment),ftr=l(),jd=a("p"),gtr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),HU=a("a"),htr=o("from_pretrained()"),utr=o(" class method or the "),JU=a("a"),ptr=o("from_config()"),_tr=o(` class
method.`),btr=l(),w$=a("p"),vtr=o("This class cannot be instantiated directly using "),mTe=a("code"),Ftr=o("__init__()"),Ttr=o(" (throws an error)."),Mtr=l(),Ct=a("div"),F(A$.$$.fragment),Etr=l(),fTe=a("p"),Ctr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),wtr=l(),Dd=a("p"),Atr=o(`Note:
Loading a model from its configuration file does `),gTe=a("strong"),Ltr=o("not"),ytr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YU=a("a"),xtr=o("from_pretrained()"),$tr=o(" to load the model weights."),ktr=l(),F(VF.$$.fragment),Str=l(),ao=a("div"),F(L$.$$.fragment),Rtr=l(),hTe=a("p"),Ptr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Btr=l(),nn=a("p"),Itr=o("The model class to instantiate is selected based on the "),uTe=a("code"),Ntr=o("model_type"),qtr=o(` property of the config object (either
passed as an argument or loaded from `),pTe=a("code"),jtr=o("pretrained_model_name_or_path"),Dtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Te=a("code"),Gtr=o("pretrained_model_name_or_path"),Otr=o(":"),Vtr=l(),N=a("ul"),XF=a("li"),bTe=a("strong"),Xtr=o("albert"),ztr=o(" \u2014 "),ZU=a("a"),Qtr=o("AlbertForSequenceClassification"),Wtr=o(" (ALBERT model)"),Utr=l(),zF=a("li"),vTe=a("strong"),Htr=o("bart"),Jtr=o(" \u2014 "),KU=a("a"),Ytr=o("BartForSequenceClassification"),Ztr=o(" (BART model)"),Ktr=l(),QF=a("li"),FTe=a("strong"),ear=o("bert"),oar=o(" \u2014 "),eH=a("a"),rar=o("BertForSequenceClassification"),tar=o(" (BERT model)"),aar=l(),WF=a("li"),TTe=a("strong"),nar=o("big_bird"),sar=o(" \u2014 "),oH=a("a"),lar=o("BigBirdForSequenceClassification"),iar=o(" (BigBird model)"),dar=l(),UF=a("li"),MTe=a("strong"),car=o("bigbird_pegasus"),mar=o(" \u2014 "),rH=a("a"),far=o("BigBirdPegasusForSequenceClassification"),gar=o(" (BigBird-Pegasus model)"),har=l(),HF=a("li"),ETe=a("strong"),uar=o("bloom"),par=o(" \u2014 "),tH=a("a"),_ar=o("BloomForSequenceClassification"),bar=o(" (BLOOM model)"),Far=l(),JF=a("li"),CTe=a("strong"),Tar=o("camembert"),Mar=o(" \u2014 "),aH=a("a"),Ear=o("CamembertForSequenceClassification"),Car=o(" (CamemBERT model)"),war=l(),YF=a("li"),wTe=a("strong"),Aar=o("canine"),Lar=o(" \u2014 "),nH=a("a"),yar=o("CanineForSequenceClassification"),xar=o(" (CANINE model)"),$ar=l(),ZF=a("li"),ATe=a("strong"),kar=o("convbert"),Sar=o(" \u2014 "),sH=a("a"),Rar=o("ConvBertForSequenceClassification"),Par=o(" (ConvBERT model)"),Bar=l(),KF=a("li"),LTe=a("strong"),Iar=o("ctrl"),Nar=o(" \u2014 "),lH=a("a"),qar=o("CTRLForSequenceClassification"),jar=o(" (CTRL model)"),Dar=l(),eT=a("li"),yTe=a("strong"),Gar=o("data2vec-text"),Oar=o(" \u2014 "),iH=a("a"),Var=o("Data2VecTextForSequenceClassification"),Xar=o(" (Data2VecText model)"),zar=l(),oT=a("li"),xTe=a("strong"),Qar=o("deberta"),War=o(" \u2014 "),dH=a("a"),Uar=o("DebertaForSequenceClassification"),Har=o(" (DeBERTa model)"),Jar=l(),rT=a("li"),$Te=a("strong"),Yar=o("deberta-v2"),Zar=o(" \u2014 "),cH=a("a"),Kar=o("DebertaV2ForSequenceClassification"),enr=o(" (DeBERTa-v2 model)"),onr=l(),tT=a("li"),kTe=a("strong"),rnr=o("distilbert"),tnr=o(" \u2014 "),mH=a("a"),anr=o("DistilBertForSequenceClassification"),nnr=o(" (DistilBERT model)"),snr=l(),aT=a("li"),STe=a("strong"),lnr=o("electra"),inr=o(" \u2014 "),fH=a("a"),dnr=o("ElectraForSequenceClassification"),cnr=o(" (ELECTRA model)"),mnr=l(),nT=a("li"),RTe=a("strong"),fnr=o("ernie"),gnr=o(" \u2014 "),gH=a("a"),hnr=o("ErnieForSequenceClassification"),unr=o(" (ERNIE model)"),pnr=l(),sT=a("li"),PTe=a("strong"),_nr=o("esm"),bnr=o(" \u2014 "),hH=a("a"),vnr=o("EsmForSequenceClassification"),Fnr=o(" (ESM model)"),Tnr=l(),lT=a("li"),BTe=a("strong"),Mnr=o("flaubert"),Enr=o(" \u2014 "),uH=a("a"),Cnr=o("FlaubertForSequenceClassification"),wnr=o(" (FlauBERT model)"),Anr=l(),iT=a("li"),ITe=a("strong"),Lnr=o("fnet"),ynr=o(" \u2014 "),pH=a("a"),xnr=o("FNetForSequenceClassification"),$nr=o(" (FNet model)"),knr=l(),dT=a("li"),NTe=a("strong"),Snr=o("funnel"),Rnr=o(" \u2014 "),_H=a("a"),Pnr=o("FunnelForSequenceClassification"),Bnr=o(" (Funnel Transformer model)"),Inr=l(),cT=a("li"),qTe=a("strong"),Nnr=o("gpt2"),qnr=o(" \u2014 "),bH=a("a"),jnr=o("GPT2ForSequenceClassification"),Dnr=o(" (OpenAI GPT-2 model)"),Gnr=l(),mT=a("li"),jTe=a("strong"),Onr=o("gpt_neo"),Vnr=o(" \u2014 "),vH=a("a"),Xnr=o("GPTNeoForSequenceClassification"),znr=o(" (GPT Neo model)"),Qnr=l(),fT=a("li"),DTe=a("strong"),Wnr=o("gptj"),Unr=o(" \u2014 "),FH=a("a"),Hnr=o("GPTJForSequenceClassification"),Jnr=o(" (GPT-J model)"),Ynr=l(),gT=a("li"),GTe=a("strong"),Znr=o("ibert"),Knr=o(" \u2014 "),TH=a("a"),esr=o("IBertForSequenceClassification"),osr=o(" (I-BERT model)"),rsr=l(),hT=a("li"),OTe=a("strong"),tsr=o("layoutlm"),asr=o(" \u2014 "),MH=a("a"),nsr=o("LayoutLMForSequenceClassification"),ssr=o(" (LayoutLM model)"),lsr=l(),uT=a("li"),VTe=a("strong"),isr=o("layoutlmv2"),dsr=o(" \u2014 "),EH=a("a"),csr=o("LayoutLMv2ForSequenceClassification"),msr=o(" (LayoutLMv2 model)"),fsr=l(),pT=a("li"),XTe=a("strong"),gsr=o("layoutlmv3"),hsr=o(" \u2014 "),CH=a("a"),usr=o("LayoutLMv3ForSequenceClassification"),psr=o(" (LayoutLMv3 model)"),_sr=l(),_T=a("li"),zTe=a("strong"),bsr=o("led"),vsr=o(" \u2014 "),wH=a("a"),Fsr=o("LEDForSequenceClassification"),Tsr=o(" (LED model)"),Msr=l(),bT=a("li"),QTe=a("strong"),Esr=o("longformer"),Csr=o(" \u2014 "),AH=a("a"),wsr=o("LongformerForSequenceClassification"),Asr=o(" (Longformer model)"),Lsr=l(),vT=a("li"),WTe=a("strong"),ysr=o("luke"),xsr=o(" \u2014 "),LH=a("a"),$sr=o("LukeForSequenceClassification"),ksr=o(" (LUKE model)"),Ssr=l(),FT=a("li"),UTe=a("strong"),Rsr=o("markuplm"),Psr=o(" \u2014 "),yH=a("a"),Bsr=o("MarkupLMForSequenceClassification"),Isr=o(" (MarkupLM model)"),Nsr=l(),TT=a("li"),HTe=a("strong"),qsr=o("mbart"),jsr=o(" \u2014 "),xH=a("a"),Dsr=o("MBartForSequenceClassification"),Gsr=o(" (mBART model)"),Osr=l(),MT=a("li"),JTe=a("strong"),Vsr=o("megatron-bert"),Xsr=o(" \u2014 "),$H=a("a"),zsr=o("MegatronBertForSequenceClassification"),Qsr=o(" (Megatron-BERT model)"),Wsr=l(),ET=a("li"),YTe=a("strong"),Usr=o("mobilebert"),Hsr=o(" \u2014 "),kH=a("a"),Jsr=o("MobileBertForSequenceClassification"),Ysr=o(" (MobileBERT model)"),Zsr=l(),CT=a("li"),ZTe=a("strong"),Ksr=o("mpnet"),elr=o(" \u2014 "),SH=a("a"),olr=o("MPNetForSequenceClassification"),rlr=o(" (MPNet model)"),tlr=l(),wT=a("li"),KTe=a("strong"),alr=o("mvp"),nlr=o(" \u2014 "),RH=a("a"),slr=o("MvpForSequenceClassification"),llr=o(" (MVP model)"),ilr=l(),AT=a("li"),eMe=a("strong"),dlr=o("nezha"),clr=o(" \u2014 "),PH=a("a"),mlr=o("NezhaForSequenceClassification"),flr=o(" (Nezha model)"),glr=l(),LT=a("li"),oMe=a("strong"),hlr=o("nystromformer"),ulr=o(" \u2014 "),BH=a("a"),plr=o("NystromformerForSequenceClassification"),_lr=o(" (Nystr\xF6mformer model)"),blr=l(),yT=a("li"),rMe=a("strong"),vlr=o("openai-gpt"),Flr=o(" \u2014 "),IH=a("a"),Tlr=o("OpenAIGPTForSequenceClassification"),Mlr=o(" (OpenAI GPT model)"),Elr=l(),xT=a("li"),tMe=a("strong"),Clr=o("opt"),wlr=o(" \u2014 "),NH=a("a"),Alr=o("OPTForSequenceClassification"),Llr=o(" (OPT model)"),ylr=l(),$T=a("li"),aMe=a("strong"),xlr=o("perceiver"),$lr=o(" \u2014 "),qH=a("a"),klr=o("PerceiverForSequenceClassification"),Slr=o(" (Perceiver model)"),Rlr=l(),kT=a("li"),nMe=a("strong"),Plr=o("plbart"),Blr=o(" \u2014 "),jH=a("a"),Ilr=o("PLBartForSequenceClassification"),Nlr=o(" (PLBart model)"),qlr=l(),ST=a("li"),sMe=a("strong"),jlr=o("qdqbert"),Dlr=o(" \u2014 "),DH=a("a"),Glr=o("QDQBertForSequenceClassification"),Olr=o(" (QDQBert model)"),Vlr=l(),RT=a("li"),lMe=a("strong"),Xlr=o("reformer"),zlr=o(" \u2014 "),GH=a("a"),Qlr=o("ReformerForSequenceClassification"),Wlr=o(" (Reformer model)"),Ulr=l(),PT=a("li"),iMe=a("strong"),Hlr=o("rembert"),Jlr=o(" \u2014 "),OH=a("a"),Ylr=o("RemBertForSequenceClassification"),Zlr=o(" (RemBERT model)"),Klr=l(),BT=a("li"),dMe=a("strong"),eir=o("roberta"),oir=o(" \u2014 "),VH=a("a"),rir=o("RobertaForSequenceClassification"),tir=o(" (RoBERTa model)"),air=l(),IT=a("li"),cMe=a("strong"),nir=o("roformer"),sir=o(" \u2014 "),XH=a("a"),lir=o("RoFormerForSequenceClassification"),iir=o(" (RoFormer model)"),dir=l(),NT=a("li"),mMe=a("strong"),cir=o("squeezebert"),mir=o(" \u2014 "),zH=a("a"),fir=o("SqueezeBertForSequenceClassification"),gir=o(" (SqueezeBERT model)"),hir=l(),qT=a("li"),fMe=a("strong"),uir=o("tapas"),pir=o(" \u2014 "),QH=a("a"),_ir=o("TapasForSequenceClassification"),bir=o(" (TAPAS model)"),vir=l(),jT=a("li"),gMe=a("strong"),Fir=o("transfo-xl"),Tir=o(" \u2014 "),WH=a("a"),Mir=o("TransfoXLForSequenceClassification"),Eir=o(" (Transformer-XL model)"),Cir=l(),DT=a("li"),hMe=a("strong"),wir=o("xlm"),Air=o(" \u2014 "),UH=a("a"),Lir=o("XLMForSequenceClassification"),yir=o(" (XLM model)"),xir=l(),GT=a("li"),uMe=a("strong"),$ir=o("xlm-roberta"),kir=o(" \u2014 "),HH=a("a"),Sir=o("XLMRobertaForSequenceClassification"),Rir=o(" (XLM-RoBERTa model)"),Pir=l(),OT=a("li"),pMe=a("strong"),Bir=o("xlm-roberta-xl"),Iir=o(" \u2014 "),JH=a("a"),Nir=o("XLMRobertaXLForSequenceClassification"),qir=o(" (XLM-RoBERTa-XL model)"),jir=l(),VT=a("li"),_Me=a("strong"),Dir=o("xlnet"),Gir=o(" \u2014 "),YH=a("a"),Oir=o("XLNetForSequenceClassification"),Vir=o(" (XLNet model)"),Xir=l(),XT=a("li"),bMe=a("strong"),zir=o("yoso"),Qir=o(" \u2014 "),ZH=a("a"),Wir=o("YosoForSequenceClassification"),Uir=o(" (YOSO model)"),Hir=l(),zT=a("p"),Jir=o("The model is set in evaluation mode by default using "),vMe=a("code"),Yir=o("model.eval()"),Zir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),FMe=a("code"),Kir=o("model.train()"),edr=l(),F(QT.$$.fragment),Roo=l(),Gd=a("h2"),WT=a("a"),TMe=a("span"),F(y$.$$.fragment),odr=l(),MMe=a("span"),rdr=o("AutoModelForMultipleChoice"),Poo=l(),Go=a("div"),F(x$.$$.fragment),tdr=l(),Od=a("p"),adr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),KH=a("a"),ndr=o("from_pretrained()"),sdr=o(" class method or the "),eJ=a("a"),ldr=o("from_config()"),idr=o(` class
method.`),ddr=l(),$$=a("p"),cdr=o("This class cannot be instantiated directly using "),EMe=a("code"),mdr=o("__init__()"),fdr=o(" (throws an error)."),gdr=l(),wt=a("div"),F(k$.$$.fragment),hdr=l(),CMe=a("p"),udr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),pdr=l(),Vd=a("p"),_dr=o(`Note:
Loading a model from its configuration file does `),wMe=a("strong"),bdr=o("not"),vdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=a("a"),Fdr=o("from_pretrained()"),Tdr=o(" to load the model weights."),Mdr=l(),F(UT.$$.fragment),Edr=l(),no=a("div"),F(S$.$$.fragment),Cdr=l(),AMe=a("p"),wdr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Adr=l(),sn=a("p"),Ldr=o("The model class to instantiate is selected based on the "),LMe=a("code"),ydr=o("model_type"),xdr=o(` property of the config object (either
passed as an argument or loaded from `),yMe=a("code"),$dr=o("pretrained_model_name_or_path"),kdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=a("code"),Sdr=o("pretrained_model_name_or_path"),Rdr=o(":"),Pdr=l(),K=a("ul"),HT=a("li"),$Me=a("strong"),Bdr=o("albert"),Idr=o(" \u2014 "),rJ=a("a"),Ndr=o("AlbertForMultipleChoice"),qdr=o(" (ALBERT model)"),jdr=l(),JT=a("li"),kMe=a("strong"),Ddr=o("bert"),Gdr=o(" \u2014 "),tJ=a("a"),Odr=o("BertForMultipleChoice"),Vdr=o(" (BERT model)"),Xdr=l(),YT=a("li"),SMe=a("strong"),zdr=o("big_bird"),Qdr=o(" \u2014 "),aJ=a("a"),Wdr=o("BigBirdForMultipleChoice"),Udr=o(" (BigBird model)"),Hdr=l(),ZT=a("li"),RMe=a("strong"),Jdr=o("camembert"),Ydr=o(" \u2014 "),nJ=a("a"),Zdr=o("CamembertForMultipleChoice"),Kdr=o(" (CamemBERT model)"),ecr=l(),KT=a("li"),PMe=a("strong"),ocr=o("canine"),rcr=o(" \u2014 "),sJ=a("a"),tcr=o("CanineForMultipleChoice"),acr=o(" (CANINE model)"),ncr=l(),eM=a("li"),BMe=a("strong"),scr=o("convbert"),lcr=o(" \u2014 "),lJ=a("a"),icr=o("ConvBertForMultipleChoice"),dcr=o(" (ConvBERT model)"),ccr=l(),oM=a("li"),IMe=a("strong"),mcr=o("data2vec-text"),fcr=o(" \u2014 "),iJ=a("a"),gcr=o("Data2VecTextForMultipleChoice"),hcr=o(" (Data2VecText model)"),ucr=l(),rM=a("li"),NMe=a("strong"),pcr=o("deberta-v2"),_cr=o(" \u2014 "),dJ=a("a"),bcr=o("DebertaV2ForMultipleChoice"),vcr=o(" (DeBERTa-v2 model)"),Fcr=l(),tM=a("li"),qMe=a("strong"),Tcr=o("distilbert"),Mcr=o(" \u2014 "),cJ=a("a"),Ecr=o("DistilBertForMultipleChoice"),Ccr=o(" (DistilBERT model)"),wcr=l(),aM=a("li"),jMe=a("strong"),Acr=o("electra"),Lcr=o(" \u2014 "),mJ=a("a"),ycr=o("ElectraForMultipleChoice"),xcr=o(" (ELECTRA model)"),$cr=l(),nM=a("li"),DMe=a("strong"),kcr=o("ernie"),Scr=o(" \u2014 "),fJ=a("a"),Rcr=o("ErnieForMultipleChoice"),Pcr=o(" (ERNIE model)"),Bcr=l(),sM=a("li"),GMe=a("strong"),Icr=o("flaubert"),Ncr=o(" \u2014 "),gJ=a("a"),qcr=o("FlaubertForMultipleChoice"),jcr=o(" (FlauBERT model)"),Dcr=l(),lM=a("li"),OMe=a("strong"),Gcr=o("fnet"),Ocr=o(" \u2014 "),hJ=a("a"),Vcr=o("FNetForMultipleChoice"),Xcr=o(" (FNet model)"),zcr=l(),iM=a("li"),VMe=a("strong"),Qcr=o("funnel"),Wcr=o(" \u2014 "),uJ=a("a"),Ucr=o("FunnelForMultipleChoice"),Hcr=o(" (Funnel Transformer model)"),Jcr=l(),dM=a("li"),XMe=a("strong"),Ycr=o("ibert"),Zcr=o(" \u2014 "),pJ=a("a"),Kcr=o("IBertForMultipleChoice"),emr=o(" (I-BERT model)"),omr=l(),cM=a("li"),zMe=a("strong"),rmr=o("longformer"),tmr=o(" \u2014 "),_J=a("a"),amr=o("LongformerForMultipleChoice"),nmr=o(" (Longformer model)"),smr=l(),mM=a("li"),QMe=a("strong"),lmr=o("luke"),imr=o(" \u2014 "),bJ=a("a"),dmr=o("LukeForMultipleChoice"),cmr=o(" (LUKE model)"),mmr=l(),fM=a("li"),WMe=a("strong"),fmr=o("megatron-bert"),gmr=o(" \u2014 "),vJ=a("a"),hmr=o("MegatronBertForMultipleChoice"),umr=o(" (Megatron-BERT model)"),pmr=l(),gM=a("li"),UMe=a("strong"),_mr=o("mobilebert"),bmr=o(" \u2014 "),FJ=a("a"),vmr=o("MobileBertForMultipleChoice"),Fmr=o(" (MobileBERT model)"),Tmr=l(),hM=a("li"),HMe=a("strong"),Mmr=o("mpnet"),Emr=o(" \u2014 "),TJ=a("a"),Cmr=o("MPNetForMultipleChoice"),wmr=o(" (MPNet model)"),Amr=l(),uM=a("li"),JMe=a("strong"),Lmr=o("nezha"),ymr=o(" \u2014 "),MJ=a("a"),xmr=o("NezhaForMultipleChoice"),$mr=o(" (Nezha model)"),kmr=l(),pM=a("li"),YMe=a("strong"),Smr=o("nystromformer"),Rmr=o(" \u2014 "),EJ=a("a"),Pmr=o("NystromformerForMultipleChoice"),Bmr=o(" (Nystr\xF6mformer model)"),Imr=l(),_M=a("li"),ZMe=a("strong"),Nmr=o("qdqbert"),qmr=o(" \u2014 "),CJ=a("a"),jmr=o("QDQBertForMultipleChoice"),Dmr=o(" (QDQBert model)"),Gmr=l(),bM=a("li"),KMe=a("strong"),Omr=o("rembert"),Vmr=o(" \u2014 "),wJ=a("a"),Xmr=o("RemBertForMultipleChoice"),zmr=o(" (RemBERT model)"),Qmr=l(),vM=a("li"),eEe=a("strong"),Wmr=o("roberta"),Umr=o(" \u2014 "),AJ=a("a"),Hmr=o("RobertaForMultipleChoice"),Jmr=o(" (RoBERTa model)"),Ymr=l(),FM=a("li"),oEe=a("strong"),Zmr=o("roformer"),Kmr=o(" \u2014 "),LJ=a("a"),efr=o("RoFormerForMultipleChoice"),ofr=o(" (RoFormer model)"),rfr=l(),TM=a("li"),rEe=a("strong"),tfr=o("squeezebert"),afr=o(" \u2014 "),yJ=a("a"),nfr=o("SqueezeBertForMultipleChoice"),sfr=o(" (SqueezeBERT model)"),lfr=l(),MM=a("li"),tEe=a("strong"),ifr=o("xlm"),dfr=o(" \u2014 "),xJ=a("a"),cfr=o("XLMForMultipleChoice"),mfr=o(" (XLM model)"),ffr=l(),EM=a("li"),aEe=a("strong"),gfr=o("xlm-roberta"),hfr=o(" \u2014 "),$J=a("a"),ufr=o("XLMRobertaForMultipleChoice"),pfr=o(" (XLM-RoBERTa model)"),_fr=l(),CM=a("li"),nEe=a("strong"),bfr=o("xlm-roberta-xl"),vfr=o(" \u2014 "),kJ=a("a"),Ffr=o("XLMRobertaXLForMultipleChoice"),Tfr=o(" (XLM-RoBERTa-XL model)"),Mfr=l(),wM=a("li"),sEe=a("strong"),Efr=o("xlnet"),Cfr=o(" \u2014 "),SJ=a("a"),wfr=o("XLNetForMultipleChoice"),Afr=o(" (XLNet model)"),Lfr=l(),AM=a("li"),lEe=a("strong"),yfr=o("yoso"),xfr=o(" \u2014 "),RJ=a("a"),$fr=o("YosoForMultipleChoice"),kfr=o(" (YOSO model)"),Sfr=l(),LM=a("p"),Rfr=o("The model is set in evaluation mode by default using "),iEe=a("code"),Pfr=o("model.eval()"),Bfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dEe=a("code"),Ifr=o("model.train()"),Nfr=l(),F(yM.$$.fragment),Boo=l(),Xd=a("h2"),xM=a("a"),cEe=a("span"),F(R$.$$.fragment),qfr=l(),mEe=a("span"),jfr=o("AutoModelForNextSentencePrediction"),Ioo=l(),Oo=a("div"),F(P$.$$.fragment),Dfr=l(),zd=a("p"),Gfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),PJ=a("a"),Ofr=o("from_pretrained()"),Vfr=o(" class method or the "),BJ=a("a"),Xfr=o("from_config()"),zfr=o(` class
method.`),Qfr=l(),B$=a("p"),Wfr=o("This class cannot be instantiated directly using "),fEe=a("code"),Ufr=o("__init__()"),Hfr=o(" (throws an error)."),Jfr=l(),At=a("div"),F(I$.$$.fragment),Yfr=l(),gEe=a("p"),Zfr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Kfr=l(),Qd=a("p"),egr=o(`Note:
Loading a model from its configuration file does `),hEe=a("strong"),ogr=o("not"),rgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=a("a"),tgr=o("from_pretrained()"),agr=o(" to load the model weights."),ngr=l(),F($M.$$.fragment),sgr=l(),so=a("div"),F(N$.$$.fragment),lgr=l(),uEe=a("p"),igr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),dgr=l(),ln=a("p"),cgr=o("The model class to instantiate is selected based on the "),pEe=a("code"),mgr=o("model_type"),fgr=o(` property of the config object (either
passed as an argument or loaded from `),_Ee=a("code"),ggr=o("pretrained_model_name_or_path"),hgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bEe=a("code"),ugr=o("pretrained_model_name_or_path"),pgr=o(":"),_gr=l(),Ue=a("ul"),kM=a("li"),vEe=a("strong"),bgr=o("bert"),vgr=o(" \u2014 "),NJ=a("a"),Fgr=o("BertForNextSentencePrediction"),Tgr=o(" (BERT model)"),Mgr=l(),SM=a("li"),FEe=a("strong"),Egr=o("ernie"),Cgr=o(" \u2014 "),qJ=a("a"),wgr=o("ErnieForNextSentencePrediction"),Agr=o(" (ERNIE model)"),Lgr=l(),RM=a("li"),TEe=a("strong"),ygr=o("fnet"),xgr=o(" \u2014 "),jJ=a("a"),$gr=o("FNetForNextSentencePrediction"),kgr=o(" (FNet model)"),Sgr=l(),PM=a("li"),MEe=a("strong"),Rgr=o("megatron-bert"),Pgr=o(" \u2014 "),DJ=a("a"),Bgr=o("MegatronBertForNextSentencePrediction"),Igr=o(" (Megatron-BERT model)"),Ngr=l(),BM=a("li"),EEe=a("strong"),qgr=o("mobilebert"),jgr=o(" \u2014 "),GJ=a("a"),Dgr=o("MobileBertForNextSentencePrediction"),Ggr=o(" (MobileBERT model)"),Ogr=l(),IM=a("li"),CEe=a("strong"),Vgr=o("nezha"),Xgr=o(" \u2014 "),OJ=a("a"),zgr=o("NezhaForNextSentencePrediction"),Qgr=o(" (Nezha model)"),Wgr=l(),NM=a("li"),wEe=a("strong"),Ugr=o("qdqbert"),Hgr=o(" \u2014 "),VJ=a("a"),Jgr=o("QDQBertForNextSentencePrediction"),Ygr=o(" (QDQBert model)"),Zgr=l(),qM=a("p"),Kgr=o("The model is set in evaluation mode by default using "),AEe=a("code"),ehr=o("model.eval()"),ohr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=a("code"),rhr=o("model.train()"),thr=l(),F(jM.$$.fragment),Noo=l(),Wd=a("h2"),DM=a("a"),yEe=a("span"),F(q$.$$.fragment),ahr=l(),xEe=a("span"),nhr=o("AutoModelForTokenClassification"),qoo=l(),Vo=a("div"),F(j$.$$.fragment),shr=l(),Ud=a("p"),lhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),XJ=a("a"),ihr=o("from_pretrained()"),dhr=o(" class method or the "),zJ=a("a"),chr=o("from_config()"),mhr=o(` class
method.`),fhr=l(),D$=a("p"),ghr=o("This class cannot be instantiated directly using "),$Ee=a("code"),hhr=o("__init__()"),uhr=o(" (throws an error)."),phr=l(),Lt=a("div"),F(G$.$$.fragment),_hr=l(),kEe=a("p"),bhr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),vhr=l(),Hd=a("p"),Fhr=o(`Note:
Loading a model from its configuration file does `),SEe=a("strong"),Thr=o("not"),Mhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),Ehr=o("from_pretrained()"),Chr=o(" to load the model weights."),whr=l(),F(GM.$$.fragment),Ahr=l(),lo=a("div"),F(O$.$$.fragment),Lhr=l(),REe=a("p"),yhr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xhr=l(),dn=a("p"),$hr=o("The model class to instantiate is selected based on the "),PEe=a("code"),khr=o("model_type"),Shr=o(` property of the config object (either
passed as an argument or loaded from `),BEe=a("code"),Rhr=o("pretrained_model_name_or_path"),Phr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=a("code"),Bhr=o("pretrained_model_name_or_path"),Ihr=o(":"),Nhr=l(),H=a("ul"),OM=a("li"),NEe=a("strong"),qhr=o("albert"),jhr=o(" \u2014 "),WJ=a("a"),Dhr=o("AlbertForTokenClassification"),Ghr=o(" (ALBERT model)"),Ohr=l(),VM=a("li"),qEe=a("strong"),Vhr=o("bert"),Xhr=o(" \u2014 "),UJ=a("a"),zhr=o("BertForTokenClassification"),Qhr=o(" (BERT model)"),Whr=l(),XM=a("li"),jEe=a("strong"),Uhr=o("big_bird"),Hhr=o(" \u2014 "),HJ=a("a"),Jhr=o("BigBirdForTokenClassification"),Yhr=o(" (BigBird model)"),Zhr=l(),zM=a("li"),DEe=a("strong"),Khr=o("bloom"),eur=o(" \u2014 "),JJ=a("a"),our=o("BloomForTokenClassification"),rur=o(" (BLOOM model)"),tur=l(),QM=a("li"),GEe=a("strong"),aur=o("camembert"),nur=o(" \u2014 "),YJ=a("a"),sur=o("CamembertForTokenClassification"),lur=o(" (CamemBERT model)"),iur=l(),WM=a("li"),OEe=a("strong"),dur=o("canine"),cur=o(" \u2014 "),ZJ=a("a"),mur=o("CanineForTokenClassification"),fur=o(" (CANINE model)"),gur=l(),UM=a("li"),VEe=a("strong"),hur=o("convbert"),uur=o(" \u2014 "),KJ=a("a"),pur=o("ConvBertForTokenClassification"),_ur=o(" (ConvBERT model)"),bur=l(),HM=a("li"),XEe=a("strong"),vur=o("data2vec-text"),Fur=o(" \u2014 "),eY=a("a"),Tur=o("Data2VecTextForTokenClassification"),Mur=o(" (Data2VecText model)"),Eur=l(),JM=a("li"),zEe=a("strong"),Cur=o("deberta"),wur=o(" \u2014 "),oY=a("a"),Aur=o("DebertaForTokenClassification"),Lur=o(" (DeBERTa model)"),yur=l(),YM=a("li"),QEe=a("strong"),xur=o("deberta-v2"),$ur=o(" \u2014 "),rY=a("a"),kur=o("DebertaV2ForTokenClassification"),Sur=o(" (DeBERTa-v2 model)"),Rur=l(),ZM=a("li"),WEe=a("strong"),Pur=o("distilbert"),Bur=o(" \u2014 "),tY=a("a"),Iur=o("DistilBertForTokenClassification"),Nur=o(" (DistilBERT model)"),qur=l(),KM=a("li"),UEe=a("strong"),jur=o("electra"),Dur=o(" \u2014 "),aY=a("a"),Gur=o("ElectraForTokenClassification"),Our=o(" (ELECTRA model)"),Vur=l(),eE=a("li"),HEe=a("strong"),Xur=o("ernie"),zur=o(" \u2014 "),nY=a("a"),Qur=o("ErnieForTokenClassification"),Wur=o(" (ERNIE model)"),Uur=l(),oE=a("li"),JEe=a("strong"),Hur=o("esm"),Jur=o(" \u2014 "),sY=a("a"),Yur=o("EsmForTokenClassification"),Zur=o(" (ESM model)"),Kur=l(),rE=a("li"),YEe=a("strong"),epr=o("flaubert"),opr=o(" \u2014 "),lY=a("a"),rpr=o("FlaubertForTokenClassification"),tpr=o(" (FlauBERT model)"),apr=l(),tE=a("li"),ZEe=a("strong"),npr=o("fnet"),spr=o(" \u2014 "),iY=a("a"),lpr=o("FNetForTokenClassification"),ipr=o(" (FNet model)"),dpr=l(),aE=a("li"),KEe=a("strong"),cpr=o("funnel"),mpr=o(" \u2014 "),dY=a("a"),fpr=o("FunnelForTokenClassification"),gpr=o(" (Funnel Transformer model)"),hpr=l(),nE=a("li"),e4e=a("strong"),upr=o("gpt2"),ppr=o(" \u2014 "),cY=a("a"),_pr=o("GPT2ForTokenClassification"),bpr=o(" (OpenAI GPT-2 model)"),vpr=l(),sE=a("li"),o4e=a("strong"),Fpr=o("ibert"),Tpr=o(" \u2014 "),mY=a("a"),Mpr=o("IBertForTokenClassification"),Epr=o(" (I-BERT model)"),Cpr=l(),lE=a("li"),r4e=a("strong"),wpr=o("layoutlm"),Apr=o(" \u2014 "),fY=a("a"),Lpr=o("LayoutLMForTokenClassification"),ypr=o(" (LayoutLM model)"),xpr=l(),iE=a("li"),t4e=a("strong"),$pr=o("layoutlmv2"),kpr=o(" \u2014 "),gY=a("a"),Spr=o("LayoutLMv2ForTokenClassification"),Rpr=o(" (LayoutLMv2 model)"),Ppr=l(),dE=a("li"),a4e=a("strong"),Bpr=o("layoutlmv3"),Ipr=o(" \u2014 "),hY=a("a"),Npr=o("LayoutLMv3ForTokenClassification"),qpr=o(" (LayoutLMv3 model)"),jpr=l(),cE=a("li"),n4e=a("strong"),Dpr=o("longformer"),Gpr=o(" \u2014 "),uY=a("a"),Opr=o("LongformerForTokenClassification"),Vpr=o(" (Longformer model)"),Xpr=l(),mE=a("li"),s4e=a("strong"),zpr=o("luke"),Qpr=o(" \u2014 "),pY=a("a"),Wpr=o("LukeForTokenClassification"),Upr=o(" (LUKE model)"),Hpr=l(),fE=a("li"),l4e=a("strong"),Jpr=o("markuplm"),Ypr=o(" \u2014 "),_Y=a("a"),Zpr=o("MarkupLMForTokenClassification"),Kpr=o(" (MarkupLM model)"),e_r=l(),gE=a("li"),i4e=a("strong"),o_r=o("megatron-bert"),r_r=o(" \u2014 "),bY=a("a"),t_r=o("MegatronBertForTokenClassification"),a_r=o(" (Megatron-BERT model)"),n_r=l(),hE=a("li"),d4e=a("strong"),s_r=o("mobilebert"),l_r=o(" \u2014 "),vY=a("a"),i_r=o("MobileBertForTokenClassification"),d_r=o(" (MobileBERT model)"),c_r=l(),uE=a("li"),c4e=a("strong"),m_r=o("mpnet"),f_r=o(" \u2014 "),FY=a("a"),g_r=o("MPNetForTokenClassification"),h_r=o(" (MPNet model)"),u_r=l(),pE=a("li"),m4e=a("strong"),p_r=o("nezha"),__r=o(" \u2014 "),TY=a("a"),b_r=o("NezhaForTokenClassification"),v_r=o(" (Nezha model)"),F_r=l(),_E=a("li"),f4e=a("strong"),T_r=o("nystromformer"),M_r=o(" \u2014 "),MY=a("a"),E_r=o("NystromformerForTokenClassification"),C_r=o(" (Nystr\xF6mformer model)"),w_r=l(),bE=a("li"),g4e=a("strong"),A_r=o("qdqbert"),L_r=o(" \u2014 "),EY=a("a"),y_r=o("QDQBertForTokenClassification"),x_r=o(" (QDQBert model)"),$_r=l(),vE=a("li"),h4e=a("strong"),k_r=o("rembert"),S_r=o(" \u2014 "),CY=a("a"),R_r=o("RemBertForTokenClassification"),P_r=o(" (RemBERT model)"),B_r=l(),FE=a("li"),u4e=a("strong"),I_r=o("roberta"),N_r=o(" \u2014 "),wY=a("a"),q_r=o("RobertaForTokenClassification"),j_r=o(" (RoBERTa model)"),D_r=l(),TE=a("li"),p4e=a("strong"),G_r=o("roformer"),O_r=o(" \u2014 "),AY=a("a"),V_r=o("RoFormerForTokenClassification"),X_r=o(" (RoFormer model)"),z_r=l(),ME=a("li"),_4e=a("strong"),Q_r=o("squeezebert"),W_r=o(" \u2014 "),LY=a("a"),U_r=o("SqueezeBertForTokenClassification"),H_r=o(" (SqueezeBERT model)"),J_r=l(),EE=a("li"),b4e=a("strong"),Y_r=o("xlm"),Z_r=o(" \u2014 "),yY=a("a"),K_r=o("XLMForTokenClassification"),e1r=o(" (XLM model)"),o1r=l(),CE=a("li"),v4e=a("strong"),r1r=o("xlm-roberta"),t1r=o(" \u2014 "),xY=a("a"),a1r=o("XLMRobertaForTokenClassification"),n1r=o(" (XLM-RoBERTa model)"),s1r=l(),wE=a("li"),F4e=a("strong"),l1r=o("xlm-roberta-xl"),i1r=o(" \u2014 "),$Y=a("a"),d1r=o("XLMRobertaXLForTokenClassification"),c1r=o(" (XLM-RoBERTa-XL model)"),m1r=l(),AE=a("li"),T4e=a("strong"),f1r=o("xlnet"),g1r=o(" \u2014 "),kY=a("a"),h1r=o("XLNetForTokenClassification"),u1r=o(" (XLNet model)"),p1r=l(),LE=a("li"),M4e=a("strong"),_1r=o("yoso"),b1r=o(" \u2014 "),SY=a("a"),v1r=o("YosoForTokenClassification"),F1r=o(" (YOSO model)"),T1r=l(),yE=a("p"),M1r=o("The model is set in evaluation mode by default using "),E4e=a("code"),E1r=o("model.eval()"),C1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C4e=a("code"),w1r=o("model.train()"),A1r=l(),F(xE.$$.fragment),joo=l(),Jd=a("h2"),$E=a("a"),w4e=a("span"),F(V$.$$.fragment),L1r=l(),A4e=a("span"),y1r=o("AutoModelForQuestionAnswering"),Doo=l(),Xo=a("div"),F(X$.$$.fragment),x1r=l(),Yd=a("p"),$1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),RY=a("a"),k1r=o("from_pretrained()"),S1r=o(" class method or the "),PY=a("a"),R1r=o("from_config()"),P1r=o(` class
method.`),B1r=l(),z$=a("p"),I1r=o("This class cannot be instantiated directly using "),L4e=a("code"),N1r=o("__init__()"),q1r=o(" (throws an error)."),j1r=l(),yt=a("div"),F(Q$.$$.fragment),D1r=l(),y4e=a("p"),G1r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),O1r=l(),Zd=a("p"),V1r=o(`Note:
Loading a model from its configuration file does `),x4e=a("strong"),X1r=o("not"),z1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=a("a"),Q1r=o("from_pretrained()"),W1r=o(" to load the model weights."),U1r=l(),F(kE.$$.fragment),H1r=l(),io=a("div"),F(W$.$$.fragment),J1r=l(),$4e=a("p"),Y1r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Z1r=l(),cn=a("p"),K1r=o("The model class to instantiate is selected based on the "),k4e=a("code"),ebr=o("model_type"),obr=o(` property of the config object (either
passed as an argument or loaded from `),S4e=a("code"),rbr=o("pretrained_model_name_or_path"),tbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=a("code"),abr=o("pretrained_model_name_or_path"),nbr=o(":"),sbr=l(),O=a("ul"),SE=a("li"),P4e=a("strong"),lbr=o("albert"),ibr=o(" \u2014 "),IY=a("a"),dbr=o("AlbertForQuestionAnswering"),cbr=o(" (ALBERT model)"),mbr=l(),RE=a("li"),B4e=a("strong"),fbr=o("bart"),gbr=o(" \u2014 "),NY=a("a"),hbr=o("BartForQuestionAnswering"),ubr=o(" (BART model)"),pbr=l(),PE=a("li"),I4e=a("strong"),_br=o("bert"),bbr=o(" \u2014 "),qY=a("a"),vbr=o("BertForQuestionAnswering"),Fbr=o(" (BERT model)"),Tbr=l(),BE=a("li"),N4e=a("strong"),Mbr=o("big_bird"),Ebr=o(" \u2014 "),jY=a("a"),Cbr=o("BigBirdForQuestionAnswering"),wbr=o(" (BigBird model)"),Abr=l(),IE=a("li"),q4e=a("strong"),Lbr=o("bigbird_pegasus"),ybr=o(" \u2014 "),DY=a("a"),xbr=o("BigBirdPegasusForQuestionAnswering"),$br=o(" (BigBird-Pegasus model)"),kbr=l(),NE=a("li"),j4e=a("strong"),Sbr=o("bloom"),Rbr=o(" \u2014 "),GY=a("a"),Pbr=o("BloomForQuestionAnswering"),Bbr=o(" (BLOOM model)"),Ibr=l(),qE=a("li"),D4e=a("strong"),Nbr=o("camembert"),qbr=o(" \u2014 "),OY=a("a"),jbr=o("CamembertForQuestionAnswering"),Dbr=o(" (CamemBERT model)"),Gbr=l(),jE=a("li"),G4e=a("strong"),Obr=o("canine"),Vbr=o(" \u2014 "),VY=a("a"),Xbr=o("CanineForQuestionAnswering"),zbr=o(" (CANINE model)"),Qbr=l(),DE=a("li"),O4e=a("strong"),Wbr=o("convbert"),Ubr=o(" \u2014 "),XY=a("a"),Hbr=o("ConvBertForQuestionAnswering"),Jbr=o(" (ConvBERT model)"),Ybr=l(),GE=a("li"),V4e=a("strong"),Zbr=o("data2vec-text"),Kbr=o(" \u2014 "),zY=a("a"),e2r=o("Data2VecTextForQuestionAnswering"),o2r=o(" (Data2VecText model)"),r2r=l(),OE=a("li"),X4e=a("strong"),t2r=o("deberta"),a2r=o(" \u2014 "),QY=a("a"),n2r=o("DebertaForQuestionAnswering"),s2r=o(" (DeBERTa model)"),l2r=l(),VE=a("li"),z4e=a("strong"),i2r=o("deberta-v2"),d2r=o(" \u2014 "),WY=a("a"),c2r=o("DebertaV2ForQuestionAnswering"),m2r=o(" (DeBERTa-v2 model)"),f2r=l(),XE=a("li"),Q4e=a("strong"),g2r=o("distilbert"),h2r=o(" \u2014 "),UY=a("a"),u2r=o("DistilBertForQuestionAnswering"),p2r=o(" (DistilBERT model)"),_2r=l(),zE=a("li"),W4e=a("strong"),b2r=o("electra"),v2r=o(" \u2014 "),HY=a("a"),F2r=o("ElectraForQuestionAnswering"),T2r=o(" (ELECTRA model)"),M2r=l(),QE=a("li"),U4e=a("strong"),E2r=o("ernie"),C2r=o(" \u2014 "),JY=a("a"),w2r=o("ErnieForQuestionAnswering"),A2r=o(" (ERNIE model)"),L2r=l(),WE=a("li"),H4e=a("strong"),y2r=o("flaubert"),x2r=o(" \u2014 "),YY=a("a"),$2r=o("FlaubertForQuestionAnsweringSimple"),k2r=o(" (FlauBERT model)"),S2r=l(),UE=a("li"),J4e=a("strong"),R2r=o("fnet"),P2r=o(" \u2014 "),ZY=a("a"),B2r=o("FNetForQuestionAnswering"),I2r=o(" (FNet model)"),N2r=l(),HE=a("li"),Y4e=a("strong"),q2r=o("funnel"),j2r=o(" \u2014 "),KY=a("a"),D2r=o("FunnelForQuestionAnswering"),G2r=o(" (Funnel Transformer model)"),O2r=l(),JE=a("li"),Z4e=a("strong"),V2r=o("gptj"),X2r=o(" \u2014 "),eZ=a("a"),z2r=o("GPTJForQuestionAnswering"),Q2r=o(" (GPT-J model)"),W2r=l(),YE=a("li"),K4e=a("strong"),U2r=o("ibert"),H2r=o(" \u2014 "),oZ=a("a"),J2r=o("IBertForQuestionAnswering"),Y2r=o(" (I-BERT model)"),Z2r=l(),ZE=a("li"),eCe=a("strong"),K2r=o("layoutlmv2"),evr=o(" \u2014 "),rZ=a("a"),ovr=o("LayoutLMv2ForQuestionAnswering"),rvr=o(" (LayoutLMv2 model)"),tvr=l(),KE=a("li"),oCe=a("strong"),avr=o("layoutlmv3"),nvr=o(" \u2014 "),tZ=a("a"),svr=o("LayoutLMv3ForQuestionAnswering"),lvr=o(" (LayoutLMv3 model)"),ivr=l(),e4=a("li"),rCe=a("strong"),dvr=o("led"),cvr=o(" \u2014 "),aZ=a("a"),mvr=o("LEDForQuestionAnswering"),fvr=o(" (LED model)"),gvr=l(),o4=a("li"),tCe=a("strong"),hvr=o("longformer"),uvr=o(" \u2014 "),nZ=a("a"),pvr=o("LongformerForQuestionAnswering"),_vr=o(" (Longformer model)"),bvr=l(),r4=a("li"),aCe=a("strong"),vvr=o("luke"),Fvr=o(" \u2014 "),sZ=a("a"),Tvr=o("LukeForQuestionAnswering"),Mvr=o(" (LUKE model)"),Evr=l(),t4=a("li"),nCe=a("strong"),Cvr=o("lxmert"),wvr=o(" \u2014 "),lZ=a("a"),Avr=o("LxmertForQuestionAnswering"),Lvr=o(" (LXMERT model)"),yvr=l(),a4=a("li"),sCe=a("strong"),xvr=o("markuplm"),$vr=o(" \u2014 "),iZ=a("a"),kvr=o("MarkupLMForQuestionAnswering"),Svr=o(" (MarkupLM model)"),Rvr=l(),n4=a("li"),lCe=a("strong"),Pvr=o("mbart"),Bvr=o(" \u2014 "),dZ=a("a"),Ivr=o("MBartForQuestionAnswering"),Nvr=o(" (mBART model)"),qvr=l(),s4=a("li"),iCe=a("strong"),jvr=o("megatron-bert"),Dvr=o(" \u2014 "),cZ=a("a"),Gvr=o("MegatronBertForQuestionAnswering"),Ovr=o(" (Megatron-BERT model)"),Vvr=l(),l4=a("li"),dCe=a("strong"),Xvr=o("mobilebert"),zvr=o(" \u2014 "),mZ=a("a"),Qvr=o("MobileBertForQuestionAnswering"),Wvr=o(" (MobileBERT model)"),Uvr=l(),i4=a("li"),cCe=a("strong"),Hvr=o("mpnet"),Jvr=o(" \u2014 "),fZ=a("a"),Yvr=o("MPNetForQuestionAnswering"),Zvr=o(" (MPNet model)"),Kvr=l(),d4=a("li"),mCe=a("strong"),eFr=o("mvp"),oFr=o(" \u2014 "),gZ=a("a"),rFr=o("MvpForQuestionAnswering"),tFr=o(" (MVP model)"),aFr=l(),c4=a("li"),fCe=a("strong"),nFr=o("nezha"),sFr=o(" \u2014 "),hZ=a("a"),lFr=o("NezhaForQuestionAnswering"),iFr=o(" (Nezha model)"),dFr=l(),m4=a("li"),gCe=a("strong"),cFr=o("nystromformer"),mFr=o(" \u2014 "),uZ=a("a"),fFr=o("NystromformerForQuestionAnswering"),gFr=o(" (Nystr\xF6mformer model)"),hFr=l(),f4=a("li"),hCe=a("strong"),uFr=o("opt"),pFr=o(" \u2014 "),pZ=a("a"),_Fr=o("OPTForQuestionAnswering"),bFr=o(" (OPT model)"),vFr=l(),g4=a("li"),uCe=a("strong"),FFr=o("qdqbert"),TFr=o(" \u2014 "),_Z=a("a"),MFr=o("QDQBertForQuestionAnswering"),EFr=o(" (QDQBert model)"),CFr=l(),h4=a("li"),pCe=a("strong"),wFr=o("reformer"),AFr=o(" \u2014 "),bZ=a("a"),LFr=o("ReformerForQuestionAnswering"),yFr=o(" (Reformer model)"),xFr=l(),u4=a("li"),_Ce=a("strong"),$Fr=o("rembert"),kFr=o(" \u2014 "),vZ=a("a"),SFr=o("RemBertForQuestionAnswering"),RFr=o(" (RemBERT model)"),PFr=l(),p4=a("li"),bCe=a("strong"),BFr=o("roberta"),IFr=o(" \u2014 "),FZ=a("a"),NFr=o("RobertaForQuestionAnswering"),qFr=o(" (RoBERTa model)"),jFr=l(),_4=a("li"),vCe=a("strong"),DFr=o("roformer"),GFr=o(" \u2014 "),TZ=a("a"),OFr=o("RoFormerForQuestionAnswering"),VFr=o(" (RoFormer model)"),XFr=l(),b4=a("li"),FCe=a("strong"),zFr=o("splinter"),QFr=o(" \u2014 "),MZ=a("a"),WFr=o("SplinterForQuestionAnswering"),UFr=o(" (Splinter model)"),HFr=l(),v4=a("li"),TCe=a("strong"),JFr=o("squeezebert"),YFr=o(" \u2014 "),EZ=a("a"),ZFr=o("SqueezeBertForQuestionAnswering"),KFr=o(" (SqueezeBERT model)"),eTr=l(),F4=a("li"),MCe=a("strong"),oTr=o("xlm"),rTr=o(" \u2014 "),CZ=a("a"),tTr=o("XLMForQuestionAnsweringSimple"),aTr=o(" (XLM model)"),nTr=l(),T4=a("li"),ECe=a("strong"),sTr=o("xlm-roberta"),lTr=o(" \u2014 "),wZ=a("a"),iTr=o("XLMRobertaForQuestionAnswering"),dTr=o(" (XLM-RoBERTa model)"),cTr=l(),M4=a("li"),CCe=a("strong"),mTr=o("xlm-roberta-xl"),fTr=o(" \u2014 "),AZ=a("a"),gTr=o("XLMRobertaXLForQuestionAnswering"),hTr=o(" (XLM-RoBERTa-XL model)"),uTr=l(),E4=a("li"),wCe=a("strong"),pTr=o("xlnet"),_Tr=o(" \u2014 "),LZ=a("a"),bTr=o("XLNetForQuestionAnsweringSimple"),vTr=o(" (XLNet model)"),FTr=l(),C4=a("li"),ACe=a("strong"),TTr=o("yoso"),MTr=o(" \u2014 "),yZ=a("a"),ETr=o("YosoForQuestionAnswering"),CTr=o(" (YOSO model)"),wTr=l(),w4=a("p"),ATr=o("The model is set in evaluation mode by default using "),LCe=a("code"),LTr=o("model.eval()"),yTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yCe=a("code"),xTr=o("model.train()"),$Tr=l(),F(A4.$$.fragment),Goo=l(),Kd=a("h2"),L4=a("a"),xCe=a("span"),F(U$.$$.fragment),kTr=l(),$Ce=a("span"),STr=o("AutoModelForTableQuestionAnswering"),Ooo=l(),zo=a("div"),F(H$.$$.fragment),RTr=l(),ec=a("p"),PTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),xZ=a("a"),BTr=o("from_pretrained()"),ITr=o(" class method or the "),$Z=a("a"),NTr=o("from_config()"),qTr=o(` class
method.`),jTr=l(),J$=a("p"),DTr=o("This class cannot be instantiated directly using "),kCe=a("code"),GTr=o("__init__()"),OTr=o(" (throws an error)."),VTr=l(),xt=a("div"),F(Y$.$$.fragment),XTr=l(),SCe=a("p"),zTr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),QTr=l(),oc=a("p"),WTr=o(`Note:
Loading a model from its configuration file does `),RCe=a("strong"),UTr=o("not"),HTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kZ=a("a"),JTr=o("from_pretrained()"),YTr=o(" to load the model weights."),ZTr=l(),F(y4.$$.fragment),KTr=l(),co=a("div"),F(Z$.$$.fragment),eMr=l(),PCe=a("p"),oMr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),rMr=l(),mn=a("p"),tMr=o("The model class to instantiate is selected based on the "),BCe=a("code"),aMr=o("model_type"),nMr=o(` property of the config object (either
passed as an argument or loaded from `),ICe=a("code"),sMr=o("pretrained_model_name_or_path"),lMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=a("code"),iMr=o("pretrained_model_name_or_path"),dMr=o(":"),cMr=l(),qCe=a("ul"),x4=a("li"),jCe=a("strong"),mMr=o("tapas"),fMr=o(" \u2014 "),SZ=a("a"),gMr=o("TapasForQuestionAnswering"),hMr=o(" (TAPAS model)"),uMr=l(),$4=a("p"),pMr=o("The model is set in evaluation mode by default using "),DCe=a("code"),_Mr=o("model.eval()"),bMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GCe=a("code"),vMr=o("model.train()"),FMr=l(),F(k4.$$.fragment),Voo=l(),rc=a("h2"),S4=a("a"),OCe=a("span"),F(K$.$$.fragment),TMr=l(),VCe=a("span"),MMr=o("AutoModelForDocumentQuestionAnswering"),Xoo=l(),Qo=a("div"),F(ek.$$.fragment),EMr=l(),tc=a("p"),CMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),RZ=a("a"),wMr=o("from_pretrained()"),AMr=o(" class method or the "),PZ=a("a"),LMr=o("from_config()"),yMr=o(` class
method.`),xMr=l(),ok=a("p"),$Mr=o("This class cannot be instantiated directly using "),XCe=a("code"),kMr=o("__init__()"),SMr=o(" (throws an error)."),RMr=l(),$t=a("div"),F(rk.$$.fragment),PMr=l(),zCe=a("p"),BMr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),IMr=l(),ac=a("p"),NMr=o(`Note:
Loading a model from its configuration file does `),QCe=a("strong"),qMr=o("not"),jMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BZ=a("a"),DMr=o("from_pretrained()"),GMr=o(" to load the model weights."),OMr=l(),F(R4.$$.fragment),VMr=l(),mo=a("div"),F(tk.$$.fragment),XMr=l(),WCe=a("p"),zMr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),QMr=l(),fn=a("p"),WMr=o("The model class to instantiate is selected based on the "),UCe=a("code"),UMr=o("model_type"),HMr=o(` property of the config object (either
passed as an argument or loaded from `),HCe=a("code"),JMr=o("pretrained_model_name_or_path"),YMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=a("code"),ZMr=o("pretrained_model_name_or_path"),KMr=o(":"),eEr=l(),nc=a("ul"),P4=a("li"),YCe=a("strong"),oEr=o("layoutlm"),rEr=o(" \u2014 "),IZ=a("a"),tEr=o("LayoutLMForQuestionAnswering"),aEr=o(" (LayoutLM model)"),nEr=l(),B4=a("li"),ZCe=a("strong"),sEr=o("layoutlmv2"),lEr=o(" \u2014 "),NZ=a("a"),iEr=o("LayoutLMv2ForQuestionAnswering"),dEr=o(" (LayoutLMv2 model)"),cEr=l(),I4=a("li"),KCe=a("strong"),mEr=o("layoutlmv3"),fEr=o(" \u2014 "),qZ=a("a"),gEr=o("LayoutLMv3ForQuestionAnswering"),hEr=o(" (LayoutLMv3 model)"),uEr=l(),N4=a("p"),pEr=o("The model is set in evaluation mode by default using "),e3e=a("code"),_Er=o("model.eval()"),bEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o3e=a("code"),vEr=o("model.train()"),FEr=l(),F(q4.$$.fragment),zoo=l(),sc=a("h2"),j4=a("a"),r3e=a("span"),F(ak.$$.fragment),TEr=l(),t3e=a("span"),MEr=o("AutoModelForImageClassification"),Qoo=l(),Wo=a("div"),F(nk.$$.fragment),EEr=l(),lc=a("p"),CEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jZ=a("a"),wEr=o("from_pretrained()"),AEr=o(" class method or the "),DZ=a("a"),LEr=o("from_config()"),yEr=o(` class
method.`),xEr=l(),sk=a("p"),$Er=o("This class cannot be instantiated directly using "),a3e=a("code"),kEr=o("__init__()"),SEr=o(" (throws an error)."),REr=l(),kt=a("div"),F(lk.$$.fragment),PEr=l(),n3e=a("p"),BEr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),IEr=l(),ic=a("p"),NEr=o(`Note:
Loading a model from its configuration file does `),s3e=a("strong"),qEr=o("not"),jEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),DEr=o("from_pretrained()"),GEr=o(" to load the model weights."),OEr=l(),F(D4.$$.fragment),VEr=l(),fo=a("div"),F(ik.$$.fragment),XEr=l(),l3e=a("p"),zEr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),QEr=l(),gn=a("p"),WEr=o("The model class to instantiate is selected based on the "),i3e=a("code"),UEr=o("model_type"),HEr=o(` property of the config object (either
passed as an argument or loaded from `),d3e=a("code"),JEr=o("pretrained_model_name_or_path"),YEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=a("code"),ZEr=o("pretrained_model_name_or_path"),KEr=o(":"),e4r=l(),be=a("ul"),G4=a("li"),m3e=a("strong"),o4r=o("beit"),r4r=o(" \u2014 "),OZ=a("a"),t4r=o("BeitForImageClassification"),a4r=o(" (BEiT model)"),n4r=l(),O4=a("li"),f3e=a("strong"),s4r=o("convnext"),l4r=o(" \u2014 "),VZ=a("a"),i4r=o("ConvNextForImageClassification"),d4r=o(" (ConvNeXT model)"),c4r=l(),V4=a("li"),g3e=a("strong"),m4r=o("cvt"),f4r=o(" \u2014 "),XZ=a("a"),g4r=o("CvtForImageClassification"),h4r=o(" (CvT model)"),u4r=l(),X4=a("li"),h3e=a("strong"),p4r=o("data2vec-vision"),_4r=o(" \u2014 "),zZ=a("a"),b4r=o("Data2VecVisionForImageClassification"),v4r=o(" (Data2VecVision model)"),F4r=l(),El=a("li"),u3e=a("strong"),T4r=o("deit"),M4r=o(" \u2014 "),QZ=a("a"),E4r=o("DeiTForImageClassification"),C4r=o(" or "),WZ=a("a"),w4r=o("DeiTForImageClassificationWithTeacher"),A4r=o(" (DeiT model)"),L4r=l(),z4=a("li"),p3e=a("strong"),y4r=o("imagegpt"),x4r=o(" \u2014 "),UZ=a("a"),$4r=o("ImageGPTForImageClassification"),k4r=o(" (ImageGPT model)"),S4r=l(),Cl=a("li"),_3e=a("strong"),R4r=o("levit"),P4r=o(" \u2014 "),HZ=a("a"),B4r=o("LevitForImageClassification"),I4r=o(" or "),JZ=a("a"),N4r=o("LevitForImageClassificationWithTeacher"),q4r=o(" (LeViT model)"),j4r=l(),Q4=a("li"),b3e=a("strong"),D4r=o("mobilevit"),G4r=o(" \u2014 "),YZ=a("a"),O4r=o("MobileViTForImageClassification"),V4r=o(" (MobileViT model)"),X4r=l(),St=a("li"),v3e=a("strong"),z4r=o("perceiver"),Q4r=o(" \u2014 "),ZZ=a("a"),W4r=o("PerceiverForImageClassificationLearned"),U4r=o(" or "),KZ=a("a"),H4r=o("PerceiverForImageClassificationFourier"),J4r=o(" or "),eK=a("a"),Y4r=o("PerceiverForImageClassificationConvProcessing"),Z4r=o(" (Perceiver model)"),K4r=l(),W4=a("li"),F3e=a("strong"),eCr=o("poolformer"),oCr=o(" \u2014 "),oK=a("a"),rCr=o("PoolFormerForImageClassification"),tCr=o(" (PoolFormer model)"),aCr=l(),U4=a("li"),T3e=a("strong"),nCr=o("regnet"),sCr=o(" \u2014 "),rK=a("a"),lCr=o("RegNetForImageClassification"),iCr=o(" (RegNet model)"),dCr=l(),H4=a("li"),M3e=a("strong"),cCr=o("resnet"),mCr=o(" \u2014 "),tK=a("a"),fCr=o("ResNetForImageClassification"),gCr=o(" (ResNet model)"),hCr=l(),J4=a("li"),E3e=a("strong"),uCr=o("segformer"),pCr=o(" \u2014 "),aK=a("a"),_Cr=o("SegformerForImageClassification"),bCr=o(" (SegFormer model)"),vCr=l(),Y4=a("li"),C3e=a("strong"),FCr=o("swin"),TCr=o(" \u2014 "),nK=a("a"),MCr=o("SwinForImageClassification"),ECr=o(" (Swin Transformer model)"),CCr=l(),Z4=a("li"),w3e=a("strong"),wCr=o("swinv2"),ACr=o(" \u2014 "),sK=a("a"),LCr=o("Swinv2ForImageClassification"),yCr=o(" (Swin Transformer V2 model)"),xCr=l(),K4=a("li"),A3e=a("strong"),$Cr=o("van"),kCr=o(" \u2014 "),lK=a("a"),SCr=o("VanForImageClassification"),RCr=o(" (VAN model)"),PCr=l(),eC=a("li"),L3e=a("strong"),BCr=o("vit"),ICr=o(" \u2014 "),iK=a("a"),NCr=o("ViTForImageClassification"),qCr=o(" (ViT model)"),jCr=l(),oC=a("li"),y3e=a("strong"),DCr=o("vit_msn"),GCr=o(" \u2014 "),dK=a("a"),OCr=o("ViTMSNForImageClassification"),VCr=o(" (ViTMSN model)"),XCr=l(),rC=a("p"),zCr=o("The model is set in evaluation mode by default using "),x3e=a("code"),QCr=o("model.eval()"),WCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$3e=a("code"),UCr=o("model.train()"),HCr=l(),F(tC.$$.fragment),Woo=l(),dc=a("h2"),aC=a("a"),k3e=a("span"),F(dk.$$.fragment),JCr=l(),S3e=a("span"),YCr=o("AutoModelForVideoClassification"),Uoo=l(),Uo=a("div"),F(ck.$$.fragment),ZCr=l(),cc=a("p"),KCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),cK=a("a"),e3r=o("from_pretrained()"),o3r=o(" class method or the "),mK=a("a"),r3r=o("from_config()"),t3r=o(` class
method.`),a3r=l(),mk=a("p"),n3r=o("This class cannot be instantiated directly using "),R3e=a("code"),s3r=o("__init__()"),l3r=o(" (throws an error)."),i3r=l(),Rt=a("div"),F(fk.$$.fragment),d3r=l(),P3e=a("p"),c3r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),m3r=l(),mc=a("p"),f3r=o(`Note:
Loading a model from its configuration file does `),B3e=a("strong"),g3r=o("not"),h3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fK=a("a"),u3r=o("from_pretrained()"),p3r=o(" to load the model weights."),_3r=l(),F(nC.$$.fragment),b3r=l(),go=a("div"),F(gk.$$.fragment),v3r=l(),I3e=a("p"),F3r=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),T3r=l(),hn=a("p"),M3r=o("The model class to instantiate is selected based on the "),N3e=a("code"),E3r=o("model_type"),C3r=o(` property of the config object (either
passed as an argument or loaded from `),q3e=a("code"),w3r=o("pretrained_model_name_or_path"),A3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=a("code"),L3r=o("pretrained_model_name_or_path"),y3r=o(":"),x3r=l(),D3e=a("ul"),sC=a("li"),G3e=a("strong"),$3r=o("videomae"),k3r=o(" \u2014 "),gK=a("a"),S3r=o("VideoMAEForVideoClassification"),R3r=o(" (VideoMAE model)"),P3r=l(),lC=a("p"),B3r=o("The model is set in evaluation mode by default using "),O3e=a("code"),I3r=o("model.eval()"),N3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V3e=a("code"),q3r=o("model.train()"),j3r=l(),F(iC.$$.fragment),Hoo=l(),fc=a("h2"),dC=a("a"),X3e=a("span"),F(hk.$$.fragment),D3r=l(),z3e=a("span"),G3r=o("AutoModelForVision2Seq"),Joo=l(),Ho=a("div"),F(uk.$$.fragment),O3r=l(),gc=a("p"),V3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hK=a("a"),X3r=o("from_pretrained()"),z3r=o(" class method or the "),uK=a("a"),Q3r=o("from_config()"),W3r=o(` class
method.`),U3r=l(),pk=a("p"),H3r=o("This class cannot be instantiated directly using "),Q3e=a("code"),J3r=o("__init__()"),Y3r=o(" (throws an error)."),Z3r=l(),Pt=a("div"),F(_k.$$.fragment),K3r=l(),W3e=a("p"),e5r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),o5r=l(),hc=a("p"),r5r=o(`Note:
Loading a model from its configuration file does `),U3e=a("strong"),t5r=o("not"),a5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pK=a("a"),n5r=o("from_pretrained()"),s5r=o(" to load the model weights."),l5r=l(),F(cC.$$.fragment),i5r=l(),ho=a("div"),F(bk.$$.fragment),d5r=l(),H3e=a("p"),c5r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),m5r=l(),un=a("p"),f5r=o("The model class to instantiate is selected based on the "),J3e=a("code"),g5r=o("model_type"),h5r=o(` property of the config object (either
passed as an argument or loaded from `),Y3e=a("code"),u5r=o("pretrained_model_name_or_path"),p5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z3e=a("code"),_5r=o("pretrained_model_name_or_path"),b5r=o(":"),v5r=l(),K3e=a("ul"),mC=a("li"),e5e=a("strong"),F5r=o("vision-encoder-decoder"),T5r=o(" \u2014 "),_K=a("a"),M5r=o("VisionEncoderDecoderModel"),E5r=o(" (Vision Encoder decoder model)"),C5r=l(),fC=a("p"),w5r=o("The model is set in evaluation mode by default using "),o5e=a("code"),A5r=o("model.eval()"),L5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r5e=a("code"),y5r=o("model.train()"),x5r=l(),F(gC.$$.fragment),Yoo=l(),uc=a("h2"),hC=a("a"),t5e=a("span"),F(vk.$$.fragment),$5r=l(),a5e=a("span"),k5r=o("AutoModelForVisualQuestionAnswering"),Zoo=l(),Jo=a("div"),F(Fk.$$.fragment),S5r=l(),pc=a("p"),R5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),bK=a("a"),P5r=o("from_pretrained()"),B5r=o(" class method or the "),vK=a("a"),I5r=o("from_config()"),N5r=o(` class
method.`),q5r=l(),Tk=a("p"),j5r=o("This class cannot be instantiated directly using "),n5e=a("code"),D5r=o("__init__()"),G5r=o(" (throws an error)."),O5r=l(),Bt=a("div"),F(Mk.$$.fragment),V5r=l(),s5e=a("p"),X5r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),z5r=l(),_c=a("p"),Q5r=o(`Note:
Loading a model from its configuration file does `),l5e=a("strong"),W5r=o("not"),U5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FK=a("a"),H5r=o("from_pretrained()"),J5r=o(" to load the model weights."),Y5r=l(),F(uC.$$.fragment),Z5r=l(),uo=a("div"),F(Ek.$$.fragment),K5r=l(),i5e=a("p"),e0r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),o0r=l(),pn=a("p"),r0r=o("The model class to instantiate is selected based on the "),d5e=a("code"),t0r=o("model_type"),a0r=o(` property of the config object (either
passed as an argument or loaded from `),c5e=a("code"),n0r=o("pretrained_model_name_or_path"),s0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=a("code"),l0r=o("pretrained_model_name_or_path"),i0r=o(":"),d0r=l(),f5e=a("ul"),pC=a("li"),g5e=a("strong"),c0r=o("vilt"),m0r=o(" \u2014 "),TK=a("a"),f0r=o("ViltForQuestionAnswering"),g0r=o(" (ViLT model)"),h0r=l(),_C=a("p"),u0r=o("The model is set in evaluation mode by default using "),h5e=a("code"),p0r=o("model.eval()"),_0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u5e=a("code"),b0r=o("model.train()"),v0r=l(),F(bC.$$.fragment),Koo=l(),bc=a("h2"),vC=a("a"),p5e=a("span"),F(Ck.$$.fragment),F0r=l(),_5e=a("span"),T0r=o("AutoModelForAudioClassification"),ero=l(),Yo=a("div"),F(wk.$$.fragment),M0r=l(),vc=a("p"),E0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),MK=a("a"),C0r=o("from_pretrained()"),w0r=o(" class method or the "),EK=a("a"),A0r=o("from_config()"),L0r=o(` class
method.`),y0r=l(),Ak=a("p"),x0r=o("This class cannot be instantiated directly using "),b5e=a("code"),$0r=o("__init__()"),k0r=o(" (throws an error)."),S0r=l(),It=a("div"),F(Lk.$$.fragment),R0r=l(),v5e=a("p"),P0r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),B0r=l(),Fc=a("p"),I0r=o(`Note:
Loading a model from its configuration file does `),F5e=a("strong"),N0r=o("not"),q0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CK=a("a"),j0r=o("from_pretrained()"),D0r=o(" to load the model weights."),G0r=l(),F(FC.$$.fragment),O0r=l(),po=a("div"),F(yk.$$.fragment),V0r=l(),T5e=a("p"),X0r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),z0r=l(),_n=a("p"),Q0r=o("The model class to instantiate is selected based on the "),M5e=a("code"),W0r=o("model_type"),U0r=o(` property of the config object (either
passed as an argument or loaded from `),E5e=a("code"),H0r=o("pretrained_model_name_or_path"),J0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C5e=a("code"),Y0r=o("pretrained_model_name_or_path"),Z0r=o(":"),K0r=l(),Pe=a("ul"),TC=a("li"),w5e=a("strong"),ewr=o("data2vec-audio"),owr=o(" \u2014 "),wK=a("a"),rwr=o("Data2VecAudioForSequenceClassification"),twr=o(" (Data2VecAudio model)"),awr=l(),MC=a("li"),A5e=a("strong"),nwr=o("hubert"),swr=o(" \u2014 "),AK=a("a"),lwr=o("HubertForSequenceClassification"),iwr=o(" (Hubert model)"),dwr=l(),EC=a("li"),L5e=a("strong"),cwr=o("sew"),mwr=o(" \u2014 "),LK=a("a"),fwr=o("SEWForSequenceClassification"),gwr=o(" (SEW model)"),hwr=l(),CC=a("li"),y5e=a("strong"),uwr=o("sew-d"),pwr=o(" \u2014 "),yK=a("a"),_wr=o("SEWDForSequenceClassification"),bwr=o(" (SEW-D model)"),vwr=l(),wC=a("li"),x5e=a("strong"),Fwr=o("unispeech"),Twr=o(" \u2014 "),xK=a("a"),Mwr=o("UniSpeechForSequenceClassification"),Ewr=o(" (UniSpeech model)"),Cwr=l(),AC=a("li"),$5e=a("strong"),wwr=o("unispeech-sat"),Awr=o(" \u2014 "),$K=a("a"),Lwr=o("UniSpeechSatForSequenceClassification"),ywr=o(" (UniSpeechSat model)"),xwr=l(),LC=a("li"),k5e=a("strong"),$wr=o("wav2vec2"),kwr=o(" \u2014 "),kK=a("a"),Swr=o("Wav2Vec2ForSequenceClassification"),Rwr=o(" (Wav2Vec2 model)"),Pwr=l(),yC=a("li"),S5e=a("strong"),Bwr=o("wav2vec2-conformer"),Iwr=o(" \u2014 "),SK=a("a"),Nwr=o("Wav2Vec2ConformerForSequenceClassification"),qwr=o(" (Wav2Vec2-Conformer model)"),jwr=l(),xC=a("li"),R5e=a("strong"),Dwr=o("wavlm"),Gwr=o(" \u2014 "),RK=a("a"),Owr=o("WavLMForSequenceClassification"),Vwr=o(" (WavLM model)"),Xwr=l(),$C=a("p"),zwr=o("The model is set in evaluation mode by default using "),P5e=a("code"),Qwr=o("model.eval()"),Wwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B5e=a("code"),Uwr=o("model.train()"),Hwr=l(),F(kC.$$.fragment),oro=l(),Tc=a("h2"),SC=a("a"),I5e=a("span"),F(xk.$$.fragment),Jwr=l(),N5e=a("span"),Ywr=o("AutoModelForAudioFrameClassification"),rro=l(),Zo=a("div"),F($k.$$.fragment),Zwr=l(),Mc=a("p"),Kwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),PK=a("a"),eAr=o("from_pretrained()"),oAr=o(" class method or the "),BK=a("a"),rAr=o("from_config()"),tAr=o(` class
method.`),aAr=l(),kk=a("p"),nAr=o("This class cannot be instantiated directly using "),q5e=a("code"),sAr=o("__init__()"),lAr=o(" (throws an error)."),iAr=l(),Nt=a("div"),F(Sk.$$.fragment),dAr=l(),j5e=a("p"),cAr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),mAr=l(),Ec=a("p"),fAr=o(`Note:
Loading a model from its configuration file does `),D5e=a("strong"),gAr=o("not"),hAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),uAr=o("from_pretrained()"),pAr=o(" to load the model weights."),_Ar=l(),F(RC.$$.fragment),bAr=l(),_o=a("div"),F(Rk.$$.fragment),vAr=l(),G5e=a("p"),FAr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),TAr=l(),bn=a("p"),MAr=o("The model class to instantiate is selected based on the "),O5e=a("code"),EAr=o("model_type"),CAr=o(` property of the config object (either
passed as an argument or loaded from `),V5e=a("code"),wAr=o("pretrained_model_name_or_path"),AAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X5e=a("code"),LAr=o("pretrained_model_name_or_path"),yAr=o(":"),xAr=l(),gt=a("ul"),PC=a("li"),z5e=a("strong"),$Ar=o("data2vec-audio"),kAr=o(" \u2014 "),NK=a("a"),SAr=o("Data2VecAudioForAudioFrameClassification"),RAr=o(" (Data2VecAudio model)"),PAr=l(),BC=a("li"),Q5e=a("strong"),BAr=o("unispeech-sat"),IAr=o(" \u2014 "),qK=a("a"),NAr=o("UniSpeechSatForAudioFrameClassification"),qAr=o(" (UniSpeechSat model)"),jAr=l(),IC=a("li"),W5e=a("strong"),DAr=o("wav2vec2"),GAr=o(" \u2014 "),jK=a("a"),OAr=o("Wav2Vec2ForAudioFrameClassification"),VAr=o(" (Wav2Vec2 model)"),XAr=l(),NC=a("li"),U5e=a("strong"),zAr=o("wav2vec2-conformer"),QAr=o(" \u2014 "),DK=a("a"),WAr=o("Wav2Vec2ConformerForAudioFrameClassification"),UAr=o(" (Wav2Vec2-Conformer model)"),HAr=l(),qC=a("li"),H5e=a("strong"),JAr=o("wavlm"),YAr=o(" \u2014 "),GK=a("a"),ZAr=o("WavLMForAudioFrameClassification"),KAr=o(" (WavLM model)"),e6r=l(),jC=a("p"),o6r=o("The model is set in evaluation mode by default using "),J5e=a("code"),r6r=o("model.eval()"),t6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y5e=a("code"),a6r=o("model.train()"),n6r=l(),F(DC.$$.fragment),tro=l(),Cc=a("h2"),GC=a("a"),Z5e=a("span"),F(Pk.$$.fragment),s6r=l(),K5e=a("span"),l6r=o("AutoModelForCTC"),aro=l(),Ko=a("div"),F(Bk.$$.fragment),i6r=l(),wc=a("p"),d6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),OK=a("a"),c6r=o("from_pretrained()"),m6r=o(" class method or the "),VK=a("a"),f6r=o("from_config()"),g6r=o(` class
method.`),h6r=l(),Ik=a("p"),u6r=o("This class cannot be instantiated directly using "),e0e=a("code"),p6r=o("__init__()"),_6r=o(" (throws an error)."),b6r=l(),qt=a("div"),F(Nk.$$.fragment),v6r=l(),o0e=a("p"),F6r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),T6r=l(),Ac=a("p"),M6r=o(`Note:
Loading a model from its configuration file does `),r0e=a("strong"),E6r=o("not"),C6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=a("a"),w6r=o("from_pretrained()"),A6r=o(" to load the model weights."),L6r=l(),F(OC.$$.fragment),y6r=l(),bo=a("div"),F(qk.$$.fragment),x6r=l(),t0e=a("p"),$6r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),k6r=l(),vn=a("p"),S6r=o("The model class to instantiate is selected based on the "),a0e=a("code"),R6r=o("model_type"),P6r=o(` property of the config object (either
passed as an argument or loaded from `),n0e=a("code"),B6r=o("pretrained_model_name_or_path"),I6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=a("code"),N6r=o("pretrained_model_name_or_path"),q6r=o(":"),j6r=l(),Le=a("ul"),VC=a("li"),l0e=a("strong"),D6r=o("data2vec-audio"),G6r=o(" \u2014 "),zK=a("a"),O6r=o("Data2VecAudioForCTC"),V6r=o(" (Data2VecAudio model)"),X6r=l(),XC=a("li"),i0e=a("strong"),z6r=o("hubert"),Q6r=o(" \u2014 "),QK=a("a"),W6r=o("HubertForCTC"),U6r=o(" (Hubert model)"),H6r=l(),zC=a("li"),d0e=a("strong"),J6r=o("mctct"),Y6r=o(" \u2014 "),WK=a("a"),Z6r=o("MCTCTForCTC"),K6r=o(" (M-CTC-T model)"),e7r=l(),QC=a("li"),c0e=a("strong"),o7r=o("sew"),r7r=o(" \u2014 "),UK=a("a"),t7r=o("SEWForCTC"),a7r=o(" (SEW model)"),n7r=l(),WC=a("li"),m0e=a("strong"),s7r=o("sew-d"),l7r=o(" \u2014 "),HK=a("a"),i7r=o("SEWDForCTC"),d7r=o(" (SEW-D model)"),c7r=l(),UC=a("li"),f0e=a("strong"),m7r=o("unispeech"),f7r=o(" \u2014 "),JK=a("a"),g7r=o("UniSpeechForCTC"),h7r=o(" (UniSpeech model)"),u7r=l(),HC=a("li"),g0e=a("strong"),p7r=o("unispeech-sat"),_7r=o(" \u2014 "),YK=a("a"),b7r=o("UniSpeechSatForCTC"),v7r=o(" (UniSpeechSat model)"),F7r=l(),JC=a("li"),h0e=a("strong"),T7r=o("wav2vec2"),M7r=o(" \u2014 "),ZK=a("a"),E7r=o("Wav2Vec2ForCTC"),C7r=o(" (Wav2Vec2 model)"),w7r=l(),YC=a("li"),u0e=a("strong"),A7r=o("wav2vec2-conformer"),L7r=o(" \u2014 "),KK=a("a"),y7r=o("Wav2Vec2ConformerForCTC"),x7r=o(" (Wav2Vec2-Conformer model)"),$7r=l(),ZC=a("li"),p0e=a("strong"),k7r=o("wavlm"),S7r=o(" \u2014 "),eee=a("a"),R7r=o("WavLMForCTC"),P7r=o(" (WavLM model)"),B7r=l(),KC=a("p"),I7r=o("The model is set in evaluation mode by default using "),_0e=a("code"),N7r=o("model.eval()"),q7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b0e=a("code"),j7r=o("model.train()"),D7r=l(),F(e3.$$.fragment),nro=l(),Lc=a("h2"),o3=a("a"),v0e=a("span"),F(jk.$$.fragment),G7r=l(),F0e=a("span"),O7r=o("AutoModelForSpeechSeq2Seq"),sro=l(),er=a("div"),F(Dk.$$.fragment),V7r=l(),yc=a("p"),X7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),oee=a("a"),z7r=o("from_pretrained()"),Q7r=o(" class method or the "),ree=a("a"),W7r=o("from_config()"),U7r=o(` class
method.`),H7r=l(),Gk=a("p"),J7r=o("This class cannot be instantiated directly using "),T0e=a("code"),Y7r=o("__init__()"),Z7r=o(" (throws an error)."),K7r=l(),jt=a("div"),F(Ok.$$.fragment),eLr=l(),M0e=a("p"),oLr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),rLr=l(),xc=a("p"),tLr=o(`Note:
Loading a model from its configuration file does `),E0e=a("strong"),aLr=o("not"),nLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tee=a("a"),sLr=o("from_pretrained()"),lLr=o(" to load the model weights."),iLr=l(),F(r3.$$.fragment),dLr=l(),vo=a("div"),F(Vk.$$.fragment),cLr=l(),C0e=a("p"),mLr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fLr=l(),Fn=a("p"),gLr=o("The model class to instantiate is selected based on the "),w0e=a("code"),hLr=o("model_type"),uLr=o(` property of the config object (either
passed as an argument or loaded from `),A0e=a("code"),pLr=o("pretrained_model_name_or_path"),_Lr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L0e=a("code"),bLr=o("pretrained_model_name_or_path"),vLr=o(":"),FLr=l(),$c=a("ul"),t3=a("li"),y0e=a("strong"),TLr=o("speech-encoder-decoder"),MLr=o(" \u2014 "),aee=a("a"),ELr=o("SpeechEncoderDecoderModel"),CLr=o(" (Speech Encoder decoder model)"),wLr=l(),a3=a("li"),x0e=a("strong"),ALr=o("speech_to_text"),LLr=o(" \u2014 "),nee=a("a"),yLr=o("Speech2TextForConditionalGeneration"),xLr=o(" (Speech2Text model)"),$Lr=l(),n3=a("li"),$0e=a("strong"),kLr=o("whisper"),SLr=o(" \u2014 "),see=a("a"),RLr=o("WhisperForConditionalGeneration"),PLr=o(" (Whisper model)"),BLr=l(),s3=a("p"),ILr=o("The model is set in evaluation mode by default using "),k0e=a("code"),NLr=o("model.eval()"),qLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=a("code"),jLr=o("model.train()"),DLr=l(),F(l3.$$.fragment),lro=l(),kc=a("h2"),i3=a("a"),R0e=a("span"),F(Xk.$$.fragment),GLr=l(),P0e=a("span"),OLr=o("AutoModelForAudioXVector"),iro=l(),or=a("div"),F(zk.$$.fragment),VLr=l(),Sc=a("p"),XLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),lee=a("a"),zLr=o("from_pretrained()"),QLr=o(" class method or the "),iee=a("a"),WLr=o("from_config()"),ULr=o(` class
method.`),HLr=l(),Qk=a("p"),JLr=o("This class cannot be instantiated directly using "),B0e=a("code"),YLr=o("__init__()"),ZLr=o(" (throws an error)."),KLr=l(),Dt=a("div"),F(Wk.$$.fragment),eyr=l(),I0e=a("p"),oyr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ryr=l(),Rc=a("p"),tyr=o(`Note:
Loading a model from its configuration file does `),N0e=a("strong"),ayr=o("not"),nyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=a("a"),syr=o("from_pretrained()"),lyr=o(" to load the model weights."),iyr=l(),F(d3.$$.fragment),dyr=l(),Fo=a("div"),F(Uk.$$.fragment),cyr=l(),q0e=a("p"),myr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),fyr=l(),Tn=a("p"),gyr=o("The model class to instantiate is selected based on the "),j0e=a("code"),hyr=o("model_type"),uyr=o(` property of the config object (either
passed as an argument or loaded from `),D0e=a("code"),pyr=o("pretrained_model_name_or_path"),_yr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=a("code"),byr=o("pretrained_model_name_or_path"),vyr=o(":"),Fyr=l(),ht=a("ul"),c3=a("li"),O0e=a("strong"),Tyr=o("data2vec-audio"),Myr=o(" \u2014 "),cee=a("a"),Eyr=o("Data2VecAudioForXVector"),Cyr=o(" (Data2VecAudio model)"),wyr=l(),m3=a("li"),V0e=a("strong"),Ayr=o("unispeech-sat"),Lyr=o(" \u2014 "),mee=a("a"),yyr=o("UniSpeechSatForXVector"),xyr=o(" (UniSpeechSat model)"),$yr=l(),f3=a("li"),X0e=a("strong"),kyr=o("wav2vec2"),Syr=o(" \u2014 "),fee=a("a"),Ryr=o("Wav2Vec2ForXVector"),Pyr=o(" (Wav2Vec2 model)"),Byr=l(),g3=a("li"),z0e=a("strong"),Iyr=o("wav2vec2-conformer"),Nyr=o(" \u2014 "),gee=a("a"),qyr=o("Wav2Vec2ConformerForXVector"),jyr=o(" (Wav2Vec2-Conformer model)"),Dyr=l(),h3=a("li"),Q0e=a("strong"),Gyr=o("wavlm"),Oyr=o(" \u2014 "),hee=a("a"),Vyr=o("WavLMForXVector"),Xyr=o(" (WavLM model)"),zyr=l(),u3=a("p"),Qyr=o("The model is set in evaluation mode by default using "),W0e=a("code"),Wyr=o("model.eval()"),Uyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U0e=a("code"),Hyr=o("model.train()"),Jyr=l(),F(p3.$$.fragment),dro=l(),Pc=a("h2"),_3=a("a"),H0e=a("span"),F(Hk.$$.fragment),Yyr=l(),J0e=a("span"),Zyr=o("AutoModelForMaskedImageModeling"),cro=l(),rr=a("div"),F(Jk.$$.fragment),Kyr=l(),Bc=a("p"),e8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),uee=a("a"),o8r=o("from_pretrained()"),r8r=o(" class method or the "),pee=a("a"),t8r=o("from_config()"),a8r=o(` class
method.`),n8r=l(),Yk=a("p"),s8r=o("This class cannot be instantiated directly using "),Y0e=a("code"),l8r=o("__init__()"),i8r=o(" (throws an error)."),d8r=l(),Gt=a("div"),F(Zk.$$.fragment),c8r=l(),Z0e=a("p"),m8r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),f8r=l(),Ic=a("p"),g8r=o(`Note:
Loading a model from its configuration file does `),K0e=a("strong"),h8r=o("not"),u8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=a("a"),p8r=o("from_pretrained()"),_8r=o(" to load the model weights."),b8r=l(),F(b3.$$.fragment),v8r=l(),To=a("div"),F(Kk.$$.fragment),F8r=l(),ewe=a("p"),T8r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),M8r=l(),Mn=a("p"),E8r=o("The model class to instantiate is selected based on the "),owe=a("code"),C8r=o("model_type"),w8r=o(` property of the config object (either
passed as an argument or loaded from `),rwe=a("code"),A8r=o("pretrained_model_name_or_path"),L8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),twe=a("code"),y8r=o("pretrained_model_name_or_path"),x8r=o(":"),$8r=l(),En=a("ul"),v3=a("li"),awe=a("strong"),k8r=o("deit"),S8r=o(" \u2014 "),bee=a("a"),R8r=o("DeiTForMaskedImageModeling"),P8r=o(" (DeiT model)"),B8r=l(),F3=a("li"),nwe=a("strong"),I8r=o("swin"),N8r=o(" \u2014 "),vee=a("a"),q8r=o("SwinForMaskedImageModeling"),j8r=o(" (Swin Transformer model)"),D8r=l(),T3=a("li"),swe=a("strong"),G8r=o("swinv2"),O8r=o(" \u2014 "),Fee=a("a"),V8r=o("Swinv2ForMaskedImageModeling"),X8r=o(" (Swin Transformer V2 model)"),z8r=l(),M3=a("li"),lwe=a("strong"),Q8r=o("vit"),W8r=o(" \u2014 "),Tee=a("a"),U8r=o("ViTForMaskedImageModeling"),H8r=o(" (ViT model)"),J8r=l(),E3=a("p"),Y8r=o("The model is set in evaluation mode by default using "),iwe=a("code"),Z8r=o("model.eval()"),K8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dwe=a("code"),e9r=o("model.train()"),o9r=l(),F(C3.$$.fragment),mro=l(),Nc=a("h2"),w3=a("a"),cwe=a("span"),F(eS.$$.fragment),r9r=l(),mwe=a("span"),t9r=o("AutoModelForObjectDetection"),fro=l(),tr=a("div"),F(oS.$$.fragment),a9r=l(),qc=a("p"),n9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Mee=a("a"),s9r=o("from_pretrained()"),l9r=o(" class method or the "),Eee=a("a"),i9r=o("from_config()"),d9r=o(` class
method.`),c9r=l(),rS=a("p"),m9r=o("This class cannot be instantiated directly using "),fwe=a("code"),f9r=o("__init__()"),g9r=o(" (throws an error)."),h9r=l(),Ot=a("div"),F(tS.$$.fragment),u9r=l(),gwe=a("p"),p9r=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),_9r=l(),jc=a("p"),b9r=o(`Note:
Loading a model from its configuration file does `),hwe=a("strong"),v9r=o("not"),F9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cee=a("a"),T9r=o("from_pretrained()"),M9r=o(" to load the model weights."),E9r=l(),F(A3.$$.fragment),C9r=l(),Mo=a("div"),F(aS.$$.fragment),w9r=l(),uwe=a("p"),A9r=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),L9r=l(),Cn=a("p"),y9r=o("The model class to instantiate is selected based on the "),pwe=a("code"),x9r=o("model_type"),$9r=o(` property of the config object (either
passed as an argument or loaded from `),_we=a("code"),k9r=o("pretrained_model_name_or_path"),S9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bwe=a("code"),R9r=o("pretrained_model_name_or_path"),P9r=o(":"),B9r=l(),wn=a("ul"),L3=a("li"),vwe=a("strong"),I9r=o("conditional_detr"),N9r=o(" \u2014 "),wee=a("a"),q9r=o("ConditionalDetrForObjectDetection"),j9r=o(" (Conditional DETR model)"),D9r=l(),y3=a("li"),Fwe=a("strong"),G9r=o("deformable_detr"),O9r=o(" \u2014 "),Aee=a("a"),V9r=o("DeformableDetrForObjectDetection"),X9r=o(" (Deformable DETR model)"),z9r=l(),x3=a("li"),Twe=a("strong"),Q9r=o("detr"),W9r=o(" \u2014 "),Lee=a("a"),U9r=o("DetrForObjectDetection"),H9r=o(" (DETR model)"),J9r=l(),$3=a("li"),Mwe=a("strong"),Y9r=o("yolos"),Z9r=o(" \u2014 "),yee=a("a"),K9r=o("YolosForObjectDetection"),exr=o(" (YOLOS model)"),oxr=l(),k3=a("p"),rxr=o("The model is set in evaluation mode by default using "),Ewe=a("code"),txr=o("model.eval()"),axr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cwe=a("code"),nxr=o("model.train()"),sxr=l(),F(S3.$$.fragment),gro=l(),Dc=a("h2"),R3=a("a"),wwe=a("span"),F(nS.$$.fragment),lxr=l(),Awe=a("span"),ixr=o("AutoModelForImageSegmentation"),hro=l(),ar=a("div"),F(sS.$$.fragment),dxr=l(),Gc=a("p"),cxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),xee=a("a"),mxr=o("from_pretrained()"),fxr=o(" class method or the "),$ee=a("a"),gxr=o("from_config()"),hxr=o(` class
method.`),uxr=l(),lS=a("p"),pxr=o("This class cannot be instantiated directly using "),Lwe=a("code"),_xr=o("__init__()"),bxr=o(" (throws an error)."),vxr=l(),Vt=a("div"),F(iS.$$.fragment),Fxr=l(),ywe=a("p"),Txr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Mxr=l(),Oc=a("p"),Exr=o(`Note:
Loading a model from its configuration file does `),xwe=a("strong"),Cxr=o("not"),wxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kee=a("a"),Axr=o("from_pretrained()"),Lxr=o(" to load the model weights."),yxr=l(),F(P3.$$.fragment),xxr=l(),Eo=a("div"),F(dS.$$.fragment),$xr=l(),$we=a("p"),kxr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Sxr=l(),An=a("p"),Rxr=o("The model class to instantiate is selected based on the "),kwe=a("code"),Pxr=o("model_type"),Bxr=o(` property of the config object (either
passed as an argument or loaded from `),Swe=a("code"),Ixr=o("pretrained_model_name_or_path"),Nxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=a("code"),qxr=o("pretrained_model_name_or_path"),jxr=o(":"),Dxr=l(),Pwe=a("ul"),B3=a("li"),Bwe=a("strong"),Gxr=o("detr"),Oxr=o(" \u2014 "),See=a("a"),Vxr=o("DetrForSegmentation"),Xxr=o(" (DETR model)"),zxr=l(),I3=a("p"),Qxr=o("The model is set in evaluation mode by default using "),Iwe=a("code"),Wxr=o("model.eval()"),Uxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nwe=a("code"),Hxr=o("model.train()"),Jxr=l(),F(N3.$$.fragment),uro=l(),Vc=a("h2"),q3=a("a"),qwe=a("span"),F(cS.$$.fragment),Yxr=l(),jwe=a("span"),Zxr=o("AutoModelForSemanticSegmentation"),pro=l(),nr=a("div"),F(mS.$$.fragment),Kxr=l(),Xc=a("p"),e$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Ree=a("a"),o$r=o("from_pretrained()"),r$r=o(" class method or the "),Pee=a("a"),t$r=o("from_config()"),a$r=o(` class
method.`),n$r=l(),fS=a("p"),s$r=o("This class cannot be instantiated directly using "),Dwe=a("code"),l$r=o("__init__()"),i$r=o(" (throws an error)."),d$r=l(),Xt=a("div"),F(gS.$$.fragment),c$r=l(),Gwe=a("p"),m$r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),f$r=l(),zc=a("p"),g$r=o(`Note:
Loading a model from its configuration file does `),Owe=a("strong"),h$r=o("not"),u$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=a("a"),p$r=o("from_pretrained()"),_$r=o(" to load the model weights."),b$r=l(),F(j3.$$.fragment),v$r=l(),Co=a("div"),F(hS.$$.fragment),F$r=l(),Vwe=a("p"),T$r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),M$r=l(),Ln=a("p"),E$r=o("The model class to instantiate is selected based on the "),Xwe=a("code"),C$r=o("model_type"),w$r=o(` property of the config object (either
passed as an argument or loaded from `),zwe=a("code"),A$r=o("pretrained_model_name_or_path"),L$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qwe=a("code"),y$r=o("pretrained_model_name_or_path"),x$r=o(":"),$$r=l(),ut=a("ul"),D3=a("li"),Wwe=a("strong"),k$r=o("beit"),S$r=o(" \u2014 "),Iee=a("a"),R$r=o("BeitForSemanticSegmentation"),P$r=o(" (BEiT model)"),B$r=l(),G3=a("li"),Uwe=a("strong"),I$r=o("data2vec-vision"),N$r=o(" \u2014 "),Nee=a("a"),q$r=o("Data2VecVisionForSemanticSegmentation"),j$r=o(" (Data2VecVision model)"),D$r=l(),O3=a("li"),Hwe=a("strong"),G$r=o("dpt"),O$r=o(" \u2014 "),qee=a("a"),V$r=o("DPTForSemanticSegmentation"),X$r=o(" (DPT model)"),z$r=l(),V3=a("li"),Jwe=a("strong"),Q$r=o("mobilevit"),W$r=o(" \u2014 "),jee=a("a"),U$r=o("MobileViTForSemanticSegmentation"),H$r=o(" (MobileViT model)"),J$r=l(),X3=a("li"),Ywe=a("strong"),Y$r=o("segformer"),Z$r=o(" \u2014 "),Dee=a("a"),K$r=o("SegformerForSemanticSegmentation"),ekr=o(" (SegFormer model)"),okr=l(),z3=a("p"),rkr=o("The model is set in evaluation mode by default using "),Zwe=a("code"),tkr=o("model.eval()"),akr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kwe=a("code"),nkr=o("model.train()"),skr=l(),F(Q3.$$.fragment),_ro=l(),Qc=a("h2"),W3=a("a"),eAe=a("span"),F(uS.$$.fragment),lkr=l(),oAe=a("span"),ikr=o("AutoModelForInstanceSegmentation"),bro=l(),sr=a("div"),F(pS.$$.fragment),dkr=l(),Wc=a("p"),ckr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Gee=a("a"),mkr=o("from_pretrained()"),fkr=o(" class method or the "),Oee=a("a"),gkr=o("from_config()"),hkr=o(` class
method.`),ukr=l(),_S=a("p"),pkr=o("This class cannot be instantiated directly using "),rAe=a("code"),_kr=o("__init__()"),bkr=o(" (throws an error)."),vkr=l(),zt=a("div"),F(bS.$$.fragment),Fkr=l(),tAe=a("p"),Tkr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Mkr=l(),Uc=a("p"),Ekr=o(`Note:
Loading a model from its configuration file does `),aAe=a("strong"),Ckr=o("not"),wkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=a("a"),Akr=o("from_pretrained()"),Lkr=o(" to load the model weights."),ykr=l(),F(U3.$$.fragment),xkr=l(),wo=a("div"),F(vS.$$.fragment),$kr=l(),nAe=a("p"),kkr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Skr=l(),yn=a("p"),Rkr=o("The model class to instantiate is selected based on the "),sAe=a("code"),Pkr=o("model_type"),Bkr=o(` property of the config object (either
passed as an argument or loaded from `),lAe=a("code"),Ikr=o("pretrained_model_name_or_path"),Nkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iAe=a("code"),qkr=o("pretrained_model_name_or_path"),jkr=o(":"),Dkr=l(),dAe=a("ul"),H3=a("li"),cAe=a("strong"),Gkr=o("maskformer"),Okr=o(" \u2014 "),Xee=a("a"),Vkr=o("MaskFormerForInstanceSegmentation"),Xkr=o(" (MaskFormer model)"),zkr=l(),J3=a("p"),Qkr=o("The model is set in evaluation mode by default using "),mAe=a("code"),Wkr=o("model.eval()"),Ukr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fAe=a("code"),Hkr=o("model.train()"),Jkr=l(),F(Y3.$$.fragment),vro=l(),Hc=a("h2"),Z3=a("a"),gAe=a("span"),F(FS.$$.fragment),Ykr=l(),hAe=a("span"),Zkr=o("AutoModelForZeroShotObjectDetection"),Fro=l(),lr=a("div"),F(TS.$$.fragment),Kkr=l(),Jc=a("p"),eSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),zee=a("a"),oSr=o("from_pretrained()"),rSr=o(" class method or the "),Qee=a("a"),tSr=o("from_config()"),aSr=o(` class
method.`),nSr=l(),MS=a("p"),sSr=o("This class cannot be instantiated directly using "),uAe=a("code"),lSr=o("__init__()"),iSr=o(" (throws an error)."),dSr=l(),Qt=a("div"),F(ES.$$.fragment),cSr=l(),pAe=a("p"),mSr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),fSr=l(),Yc=a("p"),gSr=o(`Note:
Loading a model from its configuration file does `),_Ae=a("strong"),hSr=o("not"),uSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wee=a("a"),pSr=o("from_pretrained()"),_Sr=o(" to load the model weights."),bSr=l(),F(K3.$$.fragment),vSr=l(),Ao=a("div"),F(CS.$$.fragment),FSr=l(),bAe=a("p"),TSr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),MSr=l(),xn=a("p"),ESr=o("The model class to instantiate is selected based on the "),vAe=a("code"),CSr=o("model_type"),wSr=o(` property of the config object (either
passed as an argument or loaded from `),FAe=a("code"),ASr=o("pretrained_model_name_or_path"),LSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TAe=a("code"),ySr=o("pretrained_model_name_or_path"),xSr=o(":"),$Sr=l(),MAe=a("ul"),e5=a("li"),EAe=a("strong"),kSr=o("owlvit"),SSr=o(" \u2014 "),Uee=a("a"),RSr=o("OwlViTForObjectDetection"),PSr=o(" (OWL-ViT model)"),BSr=l(),o5=a("p"),ISr=o("The model is set in evaluation mode by default using "),CAe=a("code"),NSr=o("model.eval()"),qSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wAe=a("code"),jSr=o("model.train()"),DSr=l(),F(r5.$$.fragment),Tro=l(),Zc=a("h2"),t5=a("a"),AAe=a("span"),F(wS.$$.fragment),GSr=l(),LAe=a("span"),OSr=o("TFAutoModel"),Mro=l(),ir=a("div"),F(AS.$$.fragment),VSr=l(),Kc=a("p"),XSr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Hee=a("a"),zSr=o("from_pretrained()"),QSr=o(" class method or the "),Jee=a("a"),WSr=o("from_config()"),USr=o(` class
method.`),HSr=l(),LS=a("p"),JSr=o("This class cannot be instantiated directly using "),yAe=a("code"),YSr=o("__init__()"),ZSr=o(" (throws an error)."),KSr=l(),Wt=a("div"),F(yS.$$.fragment),eRr=l(),xAe=a("p"),oRr=o("Instantiates one of the base model classes of the library from a configuration."),rRr=l(),em=a("p"),tRr=o(`Note:
Loading a model from its configuration file does `),$Ae=a("strong"),aRr=o("not"),nRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=a("a"),sRr=o("from_pretrained()"),lRr=o(" to load the model weights."),iRr=l(),F(a5.$$.fragment),dRr=l(),qr=a("div"),F(xS.$$.fragment),cRr=l(),kAe=a("p"),mRr=o("Instantiate one of the base model classes of the library from a pretrained model."),fRr=l(),$n=a("p"),gRr=o("The model class to instantiate is selected based on the "),SAe=a("code"),hRr=o("model_type"),uRr=o(` property of the config object (either
passed as an argument or loaded from `),RAe=a("code"),pRr=o("pretrained_model_name_or_path"),_Rr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PAe=a("code"),bRr=o("pretrained_model_name_or_path"),vRr=o(":"),FRr=l(),q=a("ul"),n5=a("li"),BAe=a("strong"),TRr=o("albert"),MRr=o(" \u2014 "),Zee=a("a"),ERr=o("TFAlbertModel"),CRr=o(" (ALBERT model)"),wRr=l(),s5=a("li"),IAe=a("strong"),ARr=o("bart"),LRr=o(" \u2014 "),Kee=a("a"),yRr=o("TFBartModel"),xRr=o(" (BART model)"),$Rr=l(),l5=a("li"),NAe=a("strong"),kRr=o("bert"),SRr=o(" \u2014 "),eoe=a("a"),RRr=o("TFBertModel"),PRr=o(" (BERT model)"),BRr=l(),i5=a("li"),qAe=a("strong"),IRr=o("blenderbot"),NRr=o(" \u2014 "),ooe=a("a"),qRr=o("TFBlenderbotModel"),jRr=o(" (Blenderbot model)"),DRr=l(),d5=a("li"),jAe=a("strong"),GRr=o("blenderbot-small"),ORr=o(" \u2014 "),roe=a("a"),VRr=o("TFBlenderbotSmallModel"),XRr=o(" (BlenderbotSmall model)"),zRr=l(),c5=a("li"),DAe=a("strong"),QRr=o("camembert"),WRr=o(" \u2014 "),toe=a("a"),URr=o("TFCamembertModel"),HRr=o(" (CamemBERT model)"),JRr=l(),m5=a("li"),GAe=a("strong"),YRr=o("clip"),ZRr=o(" \u2014 "),aoe=a("a"),KRr=o("TFCLIPModel"),ePr=o(" (CLIP model)"),oPr=l(),f5=a("li"),OAe=a("strong"),rPr=o("convbert"),tPr=o(" \u2014 "),noe=a("a"),aPr=o("TFConvBertModel"),nPr=o(" (ConvBERT model)"),sPr=l(),g5=a("li"),VAe=a("strong"),lPr=o("convnext"),iPr=o(" \u2014 "),soe=a("a"),dPr=o("TFConvNextModel"),cPr=o(" (ConvNeXT model)"),mPr=l(),h5=a("li"),XAe=a("strong"),fPr=o("ctrl"),gPr=o(" \u2014 "),loe=a("a"),hPr=o("TFCTRLModel"),uPr=o(" (CTRL model)"),pPr=l(),u5=a("li"),zAe=a("strong"),_Pr=o("data2vec-vision"),bPr=o(" \u2014 "),ioe=a("a"),vPr=o("TFData2VecVisionModel"),FPr=o(" (Data2VecVision model)"),TPr=l(),p5=a("li"),QAe=a("strong"),MPr=o("deberta"),EPr=o(" \u2014 "),doe=a("a"),CPr=o("TFDebertaModel"),wPr=o(" (DeBERTa model)"),APr=l(),_5=a("li"),WAe=a("strong"),LPr=o("deberta-v2"),yPr=o(" \u2014 "),coe=a("a"),xPr=o("TFDebertaV2Model"),$Pr=o(" (DeBERTa-v2 model)"),kPr=l(),b5=a("li"),UAe=a("strong"),SPr=o("deit"),RPr=o(" \u2014 "),moe=a("a"),PPr=o("TFDeiTModel"),BPr=o(" (DeiT model)"),IPr=l(),v5=a("li"),HAe=a("strong"),NPr=o("distilbert"),qPr=o(" \u2014 "),foe=a("a"),jPr=o("TFDistilBertModel"),DPr=o(" (DistilBERT model)"),GPr=l(),F5=a("li"),JAe=a("strong"),OPr=o("dpr"),VPr=o(" \u2014 "),goe=a("a"),XPr=o("TFDPRQuestionEncoder"),zPr=o(" (DPR model)"),QPr=l(),T5=a("li"),YAe=a("strong"),WPr=o("electra"),UPr=o(" \u2014 "),hoe=a("a"),HPr=o("TFElectraModel"),JPr=o(" (ELECTRA model)"),YPr=l(),M5=a("li"),ZAe=a("strong"),ZPr=o("flaubert"),KPr=o(" \u2014 "),uoe=a("a"),eBr=o("TFFlaubertModel"),oBr=o(" (FlauBERT model)"),rBr=l(),wl=a("li"),KAe=a("strong"),tBr=o("funnel"),aBr=o(" \u2014 "),poe=a("a"),nBr=o("TFFunnelModel"),sBr=o(" or "),_oe=a("a"),lBr=o("TFFunnelBaseModel"),iBr=o(" (Funnel Transformer model)"),dBr=l(),E5=a("li"),e6e=a("strong"),cBr=o("gpt2"),mBr=o(" \u2014 "),boe=a("a"),fBr=o("TFGPT2Model"),gBr=o(" (OpenAI GPT-2 model)"),hBr=l(),C5=a("li"),o6e=a("strong"),uBr=o("gptj"),pBr=o(" \u2014 "),voe=a("a"),_Br=o("TFGPTJModel"),bBr=o(" (GPT-J model)"),vBr=l(),w5=a("li"),r6e=a("strong"),FBr=o("groupvit"),TBr=o(" \u2014 "),Foe=a("a"),MBr=o("TFGroupViTModel"),EBr=o(" (GroupViT model)"),CBr=l(),A5=a("li"),t6e=a("strong"),wBr=o("hubert"),ABr=o(" \u2014 "),Toe=a("a"),LBr=o("TFHubertModel"),yBr=o(" (Hubert model)"),xBr=l(),L5=a("li"),a6e=a("strong"),$Br=o("layoutlm"),kBr=o(" \u2014 "),Moe=a("a"),SBr=o("TFLayoutLMModel"),RBr=o(" (LayoutLM model)"),PBr=l(),y5=a("li"),n6e=a("strong"),BBr=o("layoutlmv3"),IBr=o(" \u2014 "),Eoe=a("a"),NBr=o("TFLayoutLMv3Model"),qBr=o(" (LayoutLMv3 model)"),jBr=l(),x5=a("li"),s6e=a("strong"),DBr=o("led"),GBr=o(" \u2014 "),Coe=a("a"),OBr=o("TFLEDModel"),VBr=o(" (LED model)"),XBr=l(),$5=a("li"),l6e=a("strong"),zBr=o("longformer"),QBr=o(" \u2014 "),woe=a("a"),WBr=o("TFLongformerModel"),UBr=o(" (Longformer model)"),HBr=l(),k5=a("li"),i6e=a("strong"),JBr=o("lxmert"),YBr=o(" \u2014 "),Aoe=a("a"),ZBr=o("TFLxmertModel"),KBr=o(" (LXMERT model)"),eIr=l(),S5=a("li"),d6e=a("strong"),oIr=o("marian"),rIr=o(" \u2014 "),Loe=a("a"),tIr=o("TFMarianModel"),aIr=o(" (Marian model)"),nIr=l(),R5=a("li"),c6e=a("strong"),sIr=o("mbart"),lIr=o(" \u2014 "),yoe=a("a"),iIr=o("TFMBartModel"),dIr=o(" (mBART model)"),cIr=l(),P5=a("li"),m6e=a("strong"),mIr=o("mobilebert"),fIr=o(" \u2014 "),xoe=a("a"),gIr=o("TFMobileBertModel"),hIr=o(" (MobileBERT model)"),uIr=l(),B5=a("li"),f6e=a("strong"),pIr=o("mobilevit"),_Ir=o(" \u2014 "),$oe=a("a"),bIr=o("TFMobileViTModel"),vIr=o(" (MobileViT model)"),FIr=l(),I5=a("li"),g6e=a("strong"),TIr=o("mpnet"),MIr=o(" \u2014 "),koe=a("a"),EIr=o("TFMPNetModel"),CIr=o(" (MPNet model)"),wIr=l(),N5=a("li"),h6e=a("strong"),AIr=o("mt5"),LIr=o(" \u2014 "),Soe=a("a"),yIr=o("TFMT5Model"),xIr=o(" (MT5 model)"),$Ir=l(),q5=a("li"),u6e=a("strong"),kIr=o("openai-gpt"),SIr=o(" \u2014 "),Roe=a("a"),RIr=o("TFOpenAIGPTModel"),PIr=o(" (OpenAI GPT model)"),BIr=l(),j5=a("li"),p6e=a("strong"),IIr=o("opt"),NIr=o(" \u2014 "),Poe=a("a"),qIr=o("TFOPTModel"),jIr=o(" (OPT model)"),DIr=l(),D5=a("li"),_6e=a("strong"),GIr=o("pegasus"),OIr=o(" \u2014 "),Boe=a("a"),VIr=o("TFPegasusModel"),XIr=o(" (Pegasus model)"),zIr=l(),G5=a("li"),b6e=a("strong"),QIr=o("regnet"),WIr=o(" \u2014 "),Ioe=a("a"),UIr=o("TFRegNetModel"),HIr=o(" (RegNet model)"),JIr=l(),O5=a("li"),v6e=a("strong"),YIr=o("rembert"),ZIr=o(" \u2014 "),Noe=a("a"),KIr=o("TFRemBertModel"),eNr=o(" (RemBERT model)"),oNr=l(),V5=a("li"),F6e=a("strong"),rNr=o("resnet"),tNr=o(" \u2014 "),qoe=a("a"),aNr=o("TFResNetModel"),nNr=o(" (ResNet model)"),sNr=l(),X5=a("li"),T6e=a("strong"),lNr=o("roberta"),iNr=o(" \u2014 "),joe=a("a"),dNr=o("TFRobertaModel"),cNr=o(" (RoBERTa model)"),mNr=l(),z5=a("li"),M6e=a("strong"),fNr=o("roformer"),gNr=o(" \u2014 "),Doe=a("a"),hNr=o("TFRoFormerModel"),uNr=o(" (RoFormer model)"),pNr=l(),Q5=a("li"),E6e=a("strong"),_Nr=o("segformer"),bNr=o(" \u2014 "),Goe=a("a"),vNr=o("TFSegformerModel"),FNr=o(" (SegFormer model)"),TNr=l(),W5=a("li"),C6e=a("strong"),MNr=o("speech_to_text"),ENr=o(" \u2014 "),Ooe=a("a"),CNr=o("TFSpeech2TextModel"),wNr=o(" (Speech2Text model)"),ANr=l(),U5=a("li"),w6e=a("strong"),LNr=o("swin"),yNr=o(" \u2014 "),Voe=a("a"),xNr=o("TFSwinModel"),$Nr=o(" (Swin Transformer model)"),kNr=l(),H5=a("li"),A6e=a("strong"),SNr=o("t5"),RNr=o(" \u2014 "),Xoe=a("a"),PNr=o("TFT5Model"),BNr=o(" (T5 model)"),INr=l(),J5=a("li"),L6e=a("strong"),NNr=o("tapas"),qNr=o(" \u2014 "),zoe=a("a"),jNr=o("TFTapasModel"),DNr=o(" (TAPAS model)"),GNr=l(),Y5=a("li"),y6e=a("strong"),ONr=o("transfo-xl"),VNr=o(" \u2014 "),Qoe=a("a"),XNr=o("TFTransfoXLModel"),zNr=o(" (Transformer-XL model)"),QNr=l(),Z5=a("li"),x6e=a("strong"),WNr=o("vit"),UNr=o(" \u2014 "),Woe=a("a"),HNr=o("TFViTModel"),JNr=o(" (ViT model)"),YNr=l(),K5=a("li"),$6e=a("strong"),ZNr=o("vit_mae"),KNr=o(" \u2014 "),Uoe=a("a"),eqr=o("TFViTMAEModel"),oqr=o(" (ViTMAE model)"),rqr=l(),e0=a("li"),k6e=a("strong"),tqr=o("wav2vec2"),aqr=o(" \u2014 "),Hoe=a("a"),nqr=o("TFWav2Vec2Model"),sqr=o(" (Wav2Vec2 model)"),lqr=l(),o0=a("li"),S6e=a("strong"),iqr=o("xglm"),dqr=o(" \u2014 "),Joe=a("a"),cqr=o("TFXGLMModel"),mqr=o(" (XGLM model)"),fqr=l(),r0=a("li"),R6e=a("strong"),gqr=o("xlm"),hqr=o(" \u2014 "),Yoe=a("a"),uqr=o("TFXLMModel"),pqr=o(" (XLM model)"),_qr=l(),t0=a("li"),P6e=a("strong"),bqr=o("xlm-roberta"),vqr=o(" \u2014 "),Zoe=a("a"),Fqr=o("TFXLMRobertaModel"),Tqr=o(" (XLM-RoBERTa model)"),Mqr=l(),a0=a("li"),B6e=a("strong"),Eqr=o("xlnet"),Cqr=o(" \u2014 "),Koe=a("a"),wqr=o("TFXLNetModel"),Aqr=o(" (XLNet model)"),Lqr=l(),F(n0.$$.fragment),Ero=l(),om=a("h2"),s0=a("a"),I6e=a("span"),F($S.$$.fragment),yqr=l(),N6e=a("span"),xqr=o("TFAutoModelForPreTraining"),Cro=l(),dr=a("div"),F(kS.$$.fragment),$qr=l(),rm=a("p"),kqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ere=a("a"),Sqr=o("from_pretrained()"),Rqr=o(" class method or the "),ore=a("a"),Pqr=o("from_config()"),Bqr=o(` class
method.`),Iqr=l(),SS=a("p"),Nqr=o("This class cannot be instantiated directly using "),q6e=a("code"),qqr=o("__init__()"),jqr=o(" (throws an error)."),Dqr=l(),Ut=a("div"),F(RS.$$.fragment),Gqr=l(),j6e=a("p"),Oqr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Vqr=l(),tm=a("p"),Xqr=o(`Note:
Loading a model from its configuration file does `),D6e=a("strong"),zqr=o("not"),Qqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rre=a("a"),Wqr=o("from_pretrained()"),Uqr=o(" to load the model weights."),Hqr=l(),F(l0.$$.fragment),Jqr=l(),jr=a("div"),F(PS.$$.fragment),Yqr=l(),G6e=a("p"),Zqr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Kqr=l(),kn=a("p"),ejr=o("The model class to instantiate is selected based on the "),O6e=a("code"),ojr=o("model_type"),rjr=o(` property of the config object (either
passed as an argument or loaded from `),V6e=a("code"),tjr=o("pretrained_model_name_or_path"),ajr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X6e=a("code"),njr=o("pretrained_model_name_or_path"),sjr=o(":"),ljr=l(),le=a("ul"),i0=a("li"),z6e=a("strong"),ijr=o("albert"),djr=o(" \u2014 "),tre=a("a"),cjr=o("TFAlbertForPreTraining"),mjr=o(" (ALBERT model)"),fjr=l(),d0=a("li"),Q6e=a("strong"),gjr=o("bart"),hjr=o(" \u2014 "),are=a("a"),ujr=o("TFBartForConditionalGeneration"),pjr=o(" (BART model)"),_jr=l(),c0=a("li"),W6e=a("strong"),bjr=o("bert"),vjr=o(" \u2014 "),nre=a("a"),Fjr=o("TFBertForPreTraining"),Tjr=o(" (BERT model)"),Mjr=l(),m0=a("li"),U6e=a("strong"),Ejr=o("camembert"),Cjr=o(" \u2014 "),sre=a("a"),wjr=o("TFCamembertForMaskedLM"),Ajr=o(" (CamemBERT model)"),Ljr=l(),f0=a("li"),H6e=a("strong"),yjr=o("ctrl"),xjr=o(" \u2014 "),lre=a("a"),$jr=o("TFCTRLLMHeadModel"),kjr=o(" (CTRL model)"),Sjr=l(),g0=a("li"),J6e=a("strong"),Rjr=o("distilbert"),Pjr=o(" \u2014 "),ire=a("a"),Bjr=o("TFDistilBertForMaskedLM"),Ijr=o(" (DistilBERT model)"),Njr=l(),h0=a("li"),Y6e=a("strong"),qjr=o("electra"),jjr=o(" \u2014 "),dre=a("a"),Djr=o("TFElectraForPreTraining"),Gjr=o(" (ELECTRA model)"),Ojr=l(),u0=a("li"),Z6e=a("strong"),Vjr=o("flaubert"),Xjr=o(" \u2014 "),cre=a("a"),zjr=o("TFFlaubertWithLMHeadModel"),Qjr=o(" (FlauBERT model)"),Wjr=l(),p0=a("li"),K6e=a("strong"),Ujr=o("funnel"),Hjr=o(" \u2014 "),mre=a("a"),Jjr=o("TFFunnelForPreTraining"),Yjr=o(" (Funnel Transformer model)"),Zjr=l(),_0=a("li"),e7e=a("strong"),Kjr=o("gpt2"),eDr=o(" \u2014 "),fre=a("a"),oDr=o("TFGPT2LMHeadModel"),rDr=o(" (OpenAI GPT-2 model)"),tDr=l(),b0=a("li"),o7e=a("strong"),aDr=o("layoutlm"),nDr=o(" \u2014 "),gre=a("a"),sDr=o("TFLayoutLMForMaskedLM"),lDr=o(" (LayoutLM model)"),iDr=l(),v0=a("li"),r7e=a("strong"),dDr=o("lxmert"),cDr=o(" \u2014 "),hre=a("a"),mDr=o("TFLxmertForPreTraining"),fDr=o(" (LXMERT model)"),gDr=l(),F0=a("li"),t7e=a("strong"),hDr=o("mobilebert"),uDr=o(" \u2014 "),ure=a("a"),pDr=o("TFMobileBertForPreTraining"),_Dr=o(" (MobileBERT model)"),bDr=l(),T0=a("li"),a7e=a("strong"),vDr=o("mpnet"),FDr=o(" \u2014 "),pre=a("a"),TDr=o("TFMPNetForMaskedLM"),MDr=o(" (MPNet model)"),EDr=l(),M0=a("li"),n7e=a("strong"),CDr=o("openai-gpt"),wDr=o(" \u2014 "),_re=a("a"),ADr=o("TFOpenAIGPTLMHeadModel"),LDr=o(" (OpenAI GPT model)"),yDr=l(),E0=a("li"),s7e=a("strong"),xDr=o("roberta"),$Dr=o(" \u2014 "),bre=a("a"),kDr=o("TFRobertaForMaskedLM"),SDr=o(" (RoBERTa model)"),RDr=l(),C0=a("li"),l7e=a("strong"),PDr=o("t5"),BDr=o(" \u2014 "),vre=a("a"),IDr=o("TFT5ForConditionalGeneration"),NDr=o(" (T5 model)"),qDr=l(),w0=a("li"),i7e=a("strong"),jDr=o("tapas"),DDr=o(" \u2014 "),Fre=a("a"),GDr=o("TFTapasForMaskedLM"),ODr=o(" (TAPAS model)"),VDr=l(),A0=a("li"),d7e=a("strong"),XDr=o("transfo-xl"),zDr=o(" \u2014 "),Tre=a("a"),QDr=o("TFTransfoXLLMHeadModel"),WDr=o(" (Transformer-XL model)"),UDr=l(),L0=a("li"),c7e=a("strong"),HDr=o("vit_mae"),JDr=o(" \u2014 "),Mre=a("a"),YDr=o("TFViTMAEForPreTraining"),ZDr=o(" (ViTMAE model)"),KDr=l(),y0=a("li"),m7e=a("strong"),eGr=o("xlm"),oGr=o(" \u2014 "),Ere=a("a"),rGr=o("TFXLMWithLMHeadModel"),tGr=o(" (XLM model)"),aGr=l(),x0=a("li"),f7e=a("strong"),nGr=o("xlm-roberta"),sGr=o(" \u2014 "),Cre=a("a"),lGr=o("TFXLMRobertaForMaskedLM"),iGr=o(" (XLM-RoBERTa model)"),dGr=l(),$0=a("li"),g7e=a("strong"),cGr=o("xlnet"),mGr=o(" \u2014 "),wre=a("a"),fGr=o("TFXLNetLMHeadModel"),gGr=o(" (XLNet model)"),hGr=l(),F(k0.$$.fragment),wro=l(),am=a("h2"),S0=a("a"),h7e=a("span"),F(BS.$$.fragment),uGr=l(),u7e=a("span"),pGr=o("TFAutoModelForCausalLM"),Aro=l(),cr=a("div"),F(IS.$$.fragment),_Gr=l(),nm=a("p"),bGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Are=a("a"),vGr=o("from_pretrained()"),FGr=o(" class method or the "),Lre=a("a"),TGr=o("from_config()"),MGr=o(` class
method.`),EGr=l(),NS=a("p"),CGr=o("This class cannot be instantiated directly using "),p7e=a("code"),wGr=o("__init__()"),AGr=o(" (throws an error)."),LGr=l(),Ht=a("div"),F(qS.$$.fragment),yGr=l(),_7e=a("p"),xGr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$Gr=l(),sm=a("p"),kGr=o(`Note:
Loading a model from its configuration file does `),b7e=a("strong"),SGr=o("not"),RGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yre=a("a"),PGr=o("from_pretrained()"),BGr=o(" to load the model weights."),IGr=l(),F(R0.$$.fragment),NGr=l(),Dr=a("div"),F(jS.$$.fragment),qGr=l(),v7e=a("p"),jGr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),DGr=l(),Sn=a("p"),GGr=o("The model class to instantiate is selected based on the "),F7e=a("code"),OGr=o("model_type"),VGr=o(` property of the config object (either
passed as an argument or loaded from `),T7e=a("code"),XGr=o("pretrained_model_name_or_path"),zGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M7e=a("code"),QGr=o("pretrained_model_name_or_path"),WGr=o(":"),UGr=l(),Me=a("ul"),P0=a("li"),E7e=a("strong"),HGr=o("bert"),JGr=o(" \u2014 "),xre=a("a"),YGr=o("TFBertLMHeadModel"),ZGr=o(" (BERT model)"),KGr=l(),B0=a("li"),C7e=a("strong"),eOr=o("camembert"),oOr=o(" \u2014 "),$re=a("a"),rOr=o("TFCamembertForCausalLM"),tOr=o(" (CamemBERT model)"),aOr=l(),I0=a("li"),w7e=a("strong"),nOr=o("ctrl"),sOr=o(" \u2014 "),kre=a("a"),lOr=o("TFCTRLLMHeadModel"),iOr=o(" (CTRL model)"),dOr=l(),N0=a("li"),A7e=a("strong"),cOr=o("gpt2"),mOr=o(" \u2014 "),Sre=a("a"),fOr=o("TFGPT2LMHeadModel"),gOr=o(" (OpenAI GPT-2 model)"),hOr=l(),q0=a("li"),L7e=a("strong"),uOr=o("gptj"),pOr=o(" \u2014 "),Rre=a("a"),_Or=o("TFGPTJForCausalLM"),bOr=o(" (GPT-J model)"),vOr=l(),j0=a("li"),y7e=a("strong"),FOr=o("openai-gpt"),TOr=o(" \u2014 "),Pre=a("a"),MOr=o("TFOpenAIGPTLMHeadModel"),EOr=o(" (OpenAI GPT model)"),COr=l(),D0=a("li"),x7e=a("strong"),wOr=o("opt"),AOr=o(" \u2014 "),Bre=a("a"),LOr=o("TFOPTForCausalLM"),yOr=o(" (OPT model)"),xOr=l(),G0=a("li"),$7e=a("strong"),$Or=o("rembert"),kOr=o(" \u2014 "),Ire=a("a"),SOr=o("TFRemBertForCausalLM"),ROr=o(" (RemBERT model)"),POr=l(),O0=a("li"),k7e=a("strong"),BOr=o("roberta"),IOr=o(" \u2014 "),Nre=a("a"),NOr=o("TFRobertaForCausalLM"),qOr=o(" (RoBERTa model)"),jOr=l(),V0=a("li"),S7e=a("strong"),DOr=o("roformer"),GOr=o(" \u2014 "),qre=a("a"),OOr=o("TFRoFormerForCausalLM"),VOr=o(" (RoFormer model)"),XOr=l(),X0=a("li"),R7e=a("strong"),zOr=o("transfo-xl"),QOr=o(" \u2014 "),jre=a("a"),WOr=o("TFTransfoXLLMHeadModel"),UOr=o(" (Transformer-XL model)"),HOr=l(),z0=a("li"),P7e=a("strong"),JOr=o("xglm"),YOr=o(" \u2014 "),Dre=a("a"),ZOr=o("TFXGLMForCausalLM"),KOr=o(" (XGLM model)"),eVr=l(),Q0=a("li"),B7e=a("strong"),oVr=o("xlm"),rVr=o(" \u2014 "),Gre=a("a"),tVr=o("TFXLMWithLMHeadModel"),aVr=o(" (XLM model)"),nVr=l(),W0=a("li"),I7e=a("strong"),sVr=o("xlnet"),lVr=o(" \u2014 "),Ore=a("a"),iVr=o("TFXLNetLMHeadModel"),dVr=o(" (XLNet model)"),cVr=l(),F(U0.$$.fragment),Lro=l(),lm=a("h2"),H0=a("a"),N7e=a("span"),F(DS.$$.fragment),mVr=l(),q7e=a("span"),fVr=o("TFAutoModelForImageClassification"),yro=l(),mr=a("div"),F(GS.$$.fragment),gVr=l(),im=a("p"),hVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Vre=a("a"),uVr=o("from_pretrained()"),pVr=o(" class method or the "),Xre=a("a"),_Vr=o("from_config()"),bVr=o(` class
method.`),vVr=l(),OS=a("p"),FVr=o("This class cannot be instantiated directly using "),j7e=a("code"),TVr=o("__init__()"),MVr=o(" (throws an error)."),EVr=l(),Jt=a("div"),F(VS.$$.fragment),CVr=l(),D7e=a("p"),wVr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),AVr=l(),dm=a("p"),LVr=o(`Note:
Loading a model from its configuration file does `),G7e=a("strong"),yVr=o("not"),xVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=a("a"),$Vr=o("from_pretrained()"),kVr=o(" to load the model weights."),SVr=l(),F(J0.$$.fragment),RVr=l(),Gr=a("div"),F(XS.$$.fragment),PVr=l(),O7e=a("p"),BVr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),IVr=l(),Rn=a("p"),NVr=o("The model class to instantiate is selected based on the "),V7e=a("code"),qVr=o("model_type"),jVr=o(` property of the config object (either
passed as an argument or loaded from `),X7e=a("code"),DVr=o("pretrained_model_name_or_path"),GVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z7e=a("code"),OVr=o("pretrained_model_name_or_path"),VVr=o(":"),XVr=l(),Be=a("ul"),Y0=a("li"),Q7e=a("strong"),zVr=o("convnext"),QVr=o(" \u2014 "),Qre=a("a"),WVr=o("TFConvNextForImageClassification"),UVr=o(" (ConvNeXT model)"),HVr=l(),Z0=a("li"),W7e=a("strong"),JVr=o("data2vec-vision"),YVr=o(" \u2014 "),Wre=a("a"),ZVr=o("TFData2VecVisionForImageClassification"),KVr=o(" (Data2VecVision model)"),eXr=l(),Al=a("li"),U7e=a("strong"),oXr=o("deit"),rXr=o(" \u2014 "),Ure=a("a"),tXr=o("TFDeiTForImageClassification"),aXr=o(" or "),Hre=a("a"),nXr=o("TFDeiTForImageClassificationWithTeacher"),sXr=o(" (DeiT model)"),lXr=l(),K0=a("li"),H7e=a("strong"),iXr=o("mobilevit"),dXr=o(" \u2014 "),Jre=a("a"),cXr=o("TFMobileViTForImageClassification"),mXr=o(" (MobileViT model)"),fXr=l(),ew=a("li"),J7e=a("strong"),gXr=o("regnet"),hXr=o(" \u2014 "),Yre=a("a"),uXr=o("TFRegNetForImageClassification"),pXr=o(" (RegNet model)"),_Xr=l(),ow=a("li"),Y7e=a("strong"),bXr=o("resnet"),vXr=o(" \u2014 "),Zre=a("a"),FXr=o("TFResNetForImageClassification"),TXr=o(" (ResNet model)"),MXr=l(),rw=a("li"),Z7e=a("strong"),EXr=o("segformer"),CXr=o(" \u2014 "),Kre=a("a"),wXr=o("TFSegformerForImageClassification"),AXr=o(" (SegFormer model)"),LXr=l(),tw=a("li"),K7e=a("strong"),yXr=o("swin"),xXr=o(" \u2014 "),ete=a("a"),$Xr=o("TFSwinForImageClassification"),kXr=o(" (Swin Transformer model)"),SXr=l(),aw=a("li"),eLe=a("strong"),RXr=o("vit"),PXr=o(" \u2014 "),ote=a("a"),BXr=o("TFViTForImageClassification"),IXr=o(" (ViT model)"),NXr=l(),F(nw.$$.fragment),xro=l(),cm=a("h2"),sw=a("a"),oLe=a("span"),F(zS.$$.fragment),qXr=l(),rLe=a("span"),jXr=o("TFAutoModelForSemanticSegmentation"),$ro=l(),fr=a("div"),F(QS.$$.fragment),DXr=l(),mm=a("p"),GXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),rte=a("a"),OXr=o("from_pretrained()"),VXr=o(" class method or the "),tte=a("a"),XXr=o("from_config()"),zXr=o(` class
method.`),QXr=l(),WS=a("p"),WXr=o("This class cannot be instantiated directly using "),tLe=a("code"),UXr=o("__init__()"),HXr=o(" (throws an error)."),JXr=l(),Yt=a("div"),F(US.$$.fragment),YXr=l(),aLe=a("p"),ZXr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),KXr=l(),fm=a("p"),ezr=o(`Note:
Loading a model from its configuration file does `),nLe=a("strong"),ozr=o("not"),rzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=a("a"),tzr=o("from_pretrained()"),azr=o(" to load the model weights."),nzr=l(),F(lw.$$.fragment),szr=l(),Or=a("div"),F(HS.$$.fragment),lzr=l(),sLe=a("p"),izr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),dzr=l(),Pn=a("p"),czr=o("The model class to instantiate is selected based on the "),lLe=a("code"),mzr=o("model_type"),fzr=o(` property of the config object (either
passed as an argument or loaded from `),iLe=a("code"),gzr=o("pretrained_model_name_or_path"),hzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dLe=a("code"),uzr=o("pretrained_model_name_or_path"),pzr=o(":"),_zr=l(),gm=a("ul"),iw=a("li"),cLe=a("strong"),bzr=o("data2vec-vision"),vzr=o(" \u2014 "),nte=a("a"),Fzr=o("TFData2VecVisionForSemanticSegmentation"),Tzr=o(" (Data2VecVision model)"),Mzr=l(),dw=a("li"),mLe=a("strong"),Ezr=o("mobilevit"),Czr=o(" \u2014 "),ste=a("a"),wzr=o("TFMobileViTForSemanticSegmentation"),Azr=o(" (MobileViT model)"),Lzr=l(),cw=a("li"),fLe=a("strong"),yzr=o("segformer"),xzr=o(" \u2014 "),lte=a("a"),$zr=o("TFSegformerForSemanticSegmentation"),kzr=o(" (SegFormer model)"),Szr=l(),F(mw.$$.fragment),kro=l(),hm=a("h2"),fw=a("a"),gLe=a("span"),F(JS.$$.fragment),Rzr=l(),hLe=a("span"),Pzr=o("TFAutoModelForMaskedLM"),Sro=l(),gr=a("div"),F(YS.$$.fragment),Bzr=l(),um=a("p"),Izr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ite=a("a"),Nzr=o("from_pretrained()"),qzr=o(" class method or the "),dte=a("a"),jzr=o("from_config()"),Dzr=o(` class
method.`),Gzr=l(),ZS=a("p"),Ozr=o("This class cannot be instantiated directly using "),uLe=a("code"),Vzr=o("__init__()"),Xzr=o(" (throws an error)."),zzr=l(),Zt=a("div"),F(KS.$$.fragment),Qzr=l(),pLe=a("p"),Wzr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Uzr=l(),pm=a("p"),Hzr=o(`Note:
Loading a model from its configuration file does `),_Le=a("strong"),Jzr=o("not"),Yzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cte=a("a"),Zzr=o("from_pretrained()"),Kzr=o(" to load the model weights."),eQr=l(),F(gw.$$.fragment),oQr=l(),Vr=a("div"),F(eR.$$.fragment),rQr=l(),bLe=a("p"),tQr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),aQr=l(),Bn=a("p"),nQr=o("The model class to instantiate is selected based on the "),vLe=a("code"),sQr=o("model_type"),lQr=o(` property of the config object (either
passed as an argument or loaded from `),FLe=a("code"),iQr=o("pretrained_model_name_or_path"),dQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TLe=a("code"),cQr=o("pretrained_model_name_or_path"),mQr=o(":"),fQr=l(),ge=a("ul"),hw=a("li"),MLe=a("strong"),gQr=o("albert"),hQr=o(" \u2014 "),mte=a("a"),uQr=o("TFAlbertForMaskedLM"),pQr=o(" (ALBERT model)"),_Qr=l(),uw=a("li"),ELe=a("strong"),bQr=o("bert"),vQr=o(" \u2014 "),fte=a("a"),FQr=o("TFBertForMaskedLM"),TQr=o(" (BERT model)"),MQr=l(),pw=a("li"),CLe=a("strong"),EQr=o("camembert"),CQr=o(" \u2014 "),gte=a("a"),wQr=o("TFCamembertForMaskedLM"),AQr=o(" (CamemBERT model)"),LQr=l(),_w=a("li"),wLe=a("strong"),yQr=o("convbert"),xQr=o(" \u2014 "),hte=a("a"),$Qr=o("TFConvBertForMaskedLM"),kQr=o(" (ConvBERT model)"),SQr=l(),bw=a("li"),ALe=a("strong"),RQr=o("deberta"),PQr=o(" \u2014 "),ute=a("a"),BQr=o("TFDebertaForMaskedLM"),IQr=o(" (DeBERTa model)"),NQr=l(),vw=a("li"),LLe=a("strong"),qQr=o("deberta-v2"),jQr=o(" \u2014 "),pte=a("a"),DQr=o("TFDebertaV2ForMaskedLM"),GQr=o(" (DeBERTa-v2 model)"),OQr=l(),Fw=a("li"),yLe=a("strong"),VQr=o("distilbert"),XQr=o(" \u2014 "),_te=a("a"),zQr=o("TFDistilBertForMaskedLM"),QQr=o(" (DistilBERT model)"),WQr=l(),Tw=a("li"),xLe=a("strong"),UQr=o("electra"),HQr=o(" \u2014 "),bte=a("a"),JQr=o("TFElectraForMaskedLM"),YQr=o(" (ELECTRA model)"),ZQr=l(),Mw=a("li"),$Le=a("strong"),KQr=o("flaubert"),eWr=o(" \u2014 "),vte=a("a"),oWr=o("TFFlaubertWithLMHeadModel"),rWr=o(" (FlauBERT model)"),tWr=l(),Ew=a("li"),kLe=a("strong"),aWr=o("funnel"),nWr=o(" \u2014 "),Fte=a("a"),sWr=o("TFFunnelForMaskedLM"),lWr=o(" (Funnel Transformer model)"),iWr=l(),Cw=a("li"),SLe=a("strong"),dWr=o("layoutlm"),cWr=o(" \u2014 "),Tte=a("a"),mWr=o("TFLayoutLMForMaskedLM"),fWr=o(" (LayoutLM model)"),gWr=l(),ww=a("li"),RLe=a("strong"),hWr=o("longformer"),uWr=o(" \u2014 "),Mte=a("a"),pWr=o("TFLongformerForMaskedLM"),_Wr=o(" (Longformer model)"),bWr=l(),Aw=a("li"),PLe=a("strong"),vWr=o("mobilebert"),FWr=o(" \u2014 "),Ete=a("a"),TWr=o("TFMobileBertForMaskedLM"),MWr=o(" (MobileBERT model)"),EWr=l(),Lw=a("li"),BLe=a("strong"),CWr=o("mpnet"),wWr=o(" \u2014 "),Cte=a("a"),AWr=o("TFMPNetForMaskedLM"),LWr=o(" (MPNet model)"),yWr=l(),yw=a("li"),ILe=a("strong"),xWr=o("rembert"),$Wr=o(" \u2014 "),wte=a("a"),kWr=o("TFRemBertForMaskedLM"),SWr=o(" (RemBERT model)"),RWr=l(),xw=a("li"),NLe=a("strong"),PWr=o("roberta"),BWr=o(" \u2014 "),Ate=a("a"),IWr=o("TFRobertaForMaskedLM"),NWr=o(" (RoBERTa model)"),qWr=l(),$w=a("li"),qLe=a("strong"),jWr=o("roformer"),DWr=o(" \u2014 "),Lte=a("a"),GWr=o("TFRoFormerForMaskedLM"),OWr=o(" (RoFormer model)"),VWr=l(),kw=a("li"),jLe=a("strong"),XWr=o("tapas"),zWr=o(" \u2014 "),yte=a("a"),QWr=o("TFTapasForMaskedLM"),WWr=o(" (TAPAS model)"),UWr=l(),Sw=a("li"),DLe=a("strong"),HWr=o("xlm"),JWr=o(" \u2014 "),xte=a("a"),YWr=o("TFXLMWithLMHeadModel"),ZWr=o(" (XLM model)"),KWr=l(),Rw=a("li"),GLe=a("strong"),eUr=o("xlm-roberta"),oUr=o(" \u2014 "),$te=a("a"),rUr=o("TFXLMRobertaForMaskedLM"),tUr=o(" (XLM-RoBERTa model)"),aUr=l(),F(Pw.$$.fragment),Rro=l(),_m=a("h2"),Bw=a("a"),OLe=a("span"),F(oR.$$.fragment),nUr=l(),VLe=a("span"),sUr=o("TFAutoModelForSeq2SeqLM"),Pro=l(),hr=a("div"),F(rR.$$.fragment),lUr=l(),bm=a("p"),iUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kte=a("a"),dUr=o("from_pretrained()"),cUr=o(" class method or the "),Ste=a("a"),mUr=o("from_config()"),fUr=o(` class
method.`),gUr=l(),tR=a("p"),hUr=o("This class cannot be instantiated directly using "),XLe=a("code"),uUr=o("__init__()"),pUr=o(" (throws an error)."),_Ur=l(),Kt=a("div"),F(aR.$$.fragment),bUr=l(),zLe=a("p"),vUr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),FUr=l(),vm=a("p"),TUr=o(`Note:
Loading a model from its configuration file does `),QLe=a("strong"),MUr=o("not"),EUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rte=a("a"),CUr=o("from_pretrained()"),wUr=o(" to load the model weights."),AUr=l(),F(Iw.$$.fragment),LUr=l(),Xr=a("div"),F(nR.$$.fragment),yUr=l(),WLe=a("p"),xUr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$Ur=l(),In=a("p"),kUr=o("The model class to instantiate is selected based on the "),ULe=a("code"),SUr=o("model_type"),RUr=o(` property of the config object (either
passed as an argument or loaded from `),HLe=a("code"),PUr=o("pretrained_model_name_or_path"),BUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JLe=a("code"),IUr=o("pretrained_model_name_or_path"),NUr=o(":"),qUr=l(),ye=a("ul"),Nw=a("li"),YLe=a("strong"),jUr=o("bart"),DUr=o(" \u2014 "),Pte=a("a"),GUr=o("TFBartForConditionalGeneration"),OUr=o(" (BART model)"),VUr=l(),qw=a("li"),ZLe=a("strong"),XUr=o("blenderbot"),zUr=o(" \u2014 "),Bte=a("a"),QUr=o("TFBlenderbotForConditionalGeneration"),WUr=o(" (Blenderbot model)"),UUr=l(),jw=a("li"),KLe=a("strong"),HUr=o("blenderbot-small"),JUr=o(" \u2014 "),Ite=a("a"),YUr=o("TFBlenderbotSmallForConditionalGeneration"),ZUr=o(" (BlenderbotSmall model)"),KUr=l(),Dw=a("li"),eye=a("strong"),eHr=o("encoder-decoder"),oHr=o(" \u2014 "),Nte=a("a"),rHr=o("TFEncoderDecoderModel"),tHr=o(" (Encoder decoder model)"),aHr=l(),Gw=a("li"),oye=a("strong"),nHr=o("led"),sHr=o(" \u2014 "),qte=a("a"),lHr=o("TFLEDForConditionalGeneration"),iHr=o(" (LED model)"),dHr=l(),Ow=a("li"),rye=a("strong"),cHr=o("marian"),mHr=o(" \u2014 "),jte=a("a"),fHr=o("TFMarianMTModel"),gHr=o(" (Marian model)"),hHr=l(),Vw=a("li"),tye=a("strong"),uHr=o("mbart"),pHr=o(" \u2014 "),Dte=a("a"),_Hr=o("TFMBartForConditionalGeneration"),bHr=o(" (mBART model)"),vHr=l(),Xw=a("li"),aye=a("strong"),FHr=o("mt5"),THr=o(" \u2014 "),Gte=a("a"),MHr=o("TFMT5ForConditionalGeneration"),EHr=o(" (MT5 model)"),CHr=l(),zw=a("li"),nye=a("strong"),wHr=o("pegasus"),AHr=o(" \u2014 "),Ote=a("a"),LHr=o("TFPegasusForConditionalGeneration"),yHr=o(" (Pegasus model)"),xHr=l(),Qw=a("li"),sye=a("strong"),$Hr=o("t5"),kHr=o(" \u2014 "),Vte=a("a"),SHr=o("TFT5ForConditionalGeneration"),RHr=o(" (T5 model)"),PHr=l(),F(Ww.$$.fragment),Bro=l(),Fm=a("h2"),Uw=a("a"),lye=a("span"),F(sR.$$.fragment),BHr=l(),iye=a("span"),IHr=o("TFAutoModelForSequenceClassification"),Iro=l(),ur=a("div"),F(lR.$$.fragment),NHr=l(),Tm=a("p"),qHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Xte=a("a"),jHr=o("from_pretrained()"),DHr=o(" class method or the "),zte=a("a"),GHr=o("from_config()"),OHr=o(` class
method.`),VHr=l(),iR=a("p"),XHr=o("This class cannot be instantiated directly using "),dye=a("code"),zHr=o("__init__()"),QHr=o(" (throws an error)."),WHr=l(),ea=a("div"),F(dR.$$.fragment),UHr=l(),cye=a("p"),HHr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),JHr=l(),Mm=a("p"),YHr=o(`Note:
Loading a model from its configuration file does `),mye=a("strong"),ZHr=o("not"),KHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qte=a("a"),eJr=o("from_pretrained()"),oJr=o(" to load the model weights."),rJr=l(),F(Hw.$$.fragment),tJr=l(),zr=a("div"),F(cR.$$.fragment),aJr=l(),fye=a("p"),nJr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sJr=l(),Nn=a("p"),lJr=o("The model class to instantiate is selected based on the "),gye=a("code"),iJr=o("model_type"),dJr=o(` property of the config object (either
passed as an argument or loaded from `),hye=a("code"),cJr=o("pretrained_model_name_or_path"),mJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=a("code"),fJr=o("pretrained_model_name_or_path"),gJr=o(":"),hJr=l(),re=a("ul"),Jw=a("li"),pye=a("strong"),uJr=o("albert"),pJr=o(" \u2014 "),Wte=a("a"),_Jr=o("TFAlbertForSequenceClassification"),bJr=o(" (ALBERT model)"),vJr=l(),Yw=a("li"),_ye=a("strong"),FJr=o("bert"),TJr=o(" \u2014 "),Ute=a("a"),MJr=o("TFBertForSequenceClassification"),EJr=o(" (BERT model)"),CJr=l(),Zw=a("li"),bye=a("strong"),wJr=o("camembert"),AJr=o(" \u2014 "),Hte=a("a"),LJr=o("TFCamembertForSequenceClassification"),yJr=o(" (CamemBERT model)"),xJr=l(),Kw=a("li"),vye=a("strong"),$Jr=o("convbert"),kJr=o(" \u2014 "),Jte=a("a"),SJr=o("TFConvBertForSequenceClassification"),RJr=o(" (ConvBERT model)"),PJr=l(),eA=a("li"),Fye=a("strong"),BJr=o("ctrl"),IJr=o(" \u2014 "),Yte=a("a"),NJr=o("TFCTRLForSequenceClassification"),qJr=o(" (CTRL model)"),jJr=l(),oA=a("li"),Tye=a("strong"),DJr=o("deberta"),GJr=o(" \u2014 "),Zte=a("a"),OJr=o("TFDebertaForSequenceClassification"),VJr=o(" (DeBERTa model)"),XJr=l(),rA=a("li"),Mye=a("strong"),zJr=o("deberta-v2"),QJr=o(" \u2014 "),Kte=a("a"),WJr=o("TFDebertaV2ForSequenceClassification"),UJr=o(" (DeBERTa-v2 model)"),HJr=l(),tA=a("li"),Eye=a("strong"),JJr=o("distilbert"),YJr=o(" \u2014 "),eae=a("a"),ZJr=o("TFDistilBertForSequenceClassification"),KJr=o(" (DistilBERT model)"),eYr=l(),aA=a("li"),Cye=a("strong"),oYr=o("electra"),rYr=o(" \u2014 "),oae=a("a"),tYr=o("TFElectraForSequenceClassification"),aYr=o(" (ELECTRA model)"),nYr=l(),nA=a("li"),wye=a("strong"),sYr=o("flaubert"),lYr=o(" \u2014 "),rae=a("a"),iYr=o("TFFlaubertForSequenceClassification"),dYr=o(" (FlauBERT model)"),cYr=l(),sA=a("li"),Aye=a("strong"),mYr=o("funnel"),fYr=o(" \u2014 "),tae=a("a"),gYr=o("TFFunnelForSequenceClassification"),hYr=o(" (Funnel Transformer model)"),uYr=l(),lA=a("li"),Lye=a("strong"),pYr=o("gpt2"),_Yr=o(" \u2014 "),aae=a("a"),bYr=o("TFGPT2ForSequenceClassification"),vYr=o(" (OpenAI GPT-2 model)"),FYr=l(),iA=a("li"),yye=a("strong"),TYr=o("gptj"),MYr=o(" \u2014 "),nae=a("a"),EYr=o("TFGPTJForSequenceClassification"),CYr=o(" (GPT-J model)"),wYr=l(),dA=a("li"),xye=a("strong"),AYr=o("layoutlm"),LYr=o(" \u2014 "),sae=a("a"),yYr=o("TFLayoutLMForSequenceClassification"),xYr=o(" (LayoutLM model)"),$Yr=l(),cA=a("li"),$ye=a("strong"),kYr=o("layoutlmv3"),SYr=o(" \u2014 "),lae=a("a"),RYr=o("TFLayoutLMv3ForSequenceClassification"),PYr=o(" (LayoutLMv3 model)"),BYr=l(),mA=a("li"),kye=a("strong"),IYr=o("longformer"),NYr=o(" \u2014 "),iae=a("a"),qYr=o("TFLongformerForSequenceClassification"),jYr=o(" (Longformer model)"),DYr=l(),fA=a("li"),Sye=a("strong"),GYr=o("mobilebert"),OYr=o(" \u2014 "),dae=a("a"),VYr=o("TFMobileBertForSequenceClassification"),XYr=o(" (MobileBERT model)"),zYr=l(),gA=a("li"),Rye=a("strong"),QYr=o("mpnet"),WYr=o(" \u2014 "),cae=a("a"),UYr=o("TFMPNetForSequenceClassification"),HYr=o(" (MPNet model)"),JYr=l(),hA=a("li"),Pye=a("strong"),YYr=o("openai-gpt"),ZYr=o(" \u2014 "),mae=a("a"),KYr=o("TFOpenAIGPTForSequenceClassification"),eZr=o(" (OpenAI GPT model)"),oZr=l(),uA=a("li"),Bye=a("strong"),rZr=o("rembert"),tZr=o(" \u2014 "),fae=a("a"),aZr=o("TFRemBertForSequenceClassification"),nZr=o(" (RemBERT model)"),sZr=l(),pA=a("li"),Iye=a("strong"),lZr=o("roberta"),iZr=o(" \u2014 "),gae=a("a"),dZr=o("TFRobertaForSequenceClassification"),cZr=o(" (RoBERTa model)"),mZr=l(),_A=a("li"),Nye=a("strong"),fZr=o("roformer"),gZr=o(" \u2014 "),hae=a("a"),hZr=o("TFRoFormerForSequenceClassification"),uZr=o(" (RoFormer model)"),pZr=l(),bA=a("li"),qye=a("strong"),_Zr=o("tapas"),bZr=o(" \u2014 "),uae=a("a"),vZr=o("TFTapasForSequenceClassification"),FZr=o(" (TAPAS model)"),TZr=l(),vA=a("li"),jye=a("strong"),MZr=o("transfo-xl"),EZr=o(" \u2014 "),pae=a("a"),CZr=o("TFTransfoXLForSequenceClassification"),wZr=o(" (Transformer-XL model)"),AZr=l(),FA=a("li"),Dye=a("strong"),LZr=o("xlm"),yZr=o(" \u2014 "),_ae=a("a"),xZr=o("TFXLMForSequenceClassification"),$Zr=o(" (XLM model)"),kZr=l(),TA=a("li"),Gye=a("strong"),SZr=o("xlm-roberta"),RZr=o(" \u2014 "),bae=a("a"),PZr=o("TFXLMRobertaForSequenceClassification"),BZr=o(" (XLM-RoBERTa model)"),IZr=l(),MA=a("li"),Oye=a("strong"),NZr=o("xlnet"),qZr=o(" \u2014 "),vae=a("a"),jZr=o("TFXLNetForSequenceClassification"),DZr=o(" (XLNet model)"),GZr=l(),F(EA.$$.fragment),Nro=l(),Em=a("h2"),CA=a("a"),Vye=a("span"),F(mR.$$.fragment),OZr=l(),Xye=a("span"),VZr=o("TFAutoModelForMultipleChoice"),qro=l(),pr=a("div"),F(fR.$$.fragment),XZr=l(),Cm=a("p"),zZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Fae=a("a"),QZr=o("from_pretrained()"),WZr=o(" class method or the "),Tae=a("a"),UZr=o("from_config()"),HZr=o(` class
method.`),JZr=l(),gR=a("p"),YZr=o("This class cannot be instantiated directly using "),zye=a("code"),ZZr=o("__init__()"),KZr=o(" (throws an error)."),eKr=l(),oa=a("div"),F(hR.$$.fragment),oKr=l(),Qye=a("p"),rKr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),tKr=l(),wm=a("p"),aKr=o(`Note:
Loading a model from its configuration file does `),Wye=a("strong"),nKr=o("not"),sKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mae=a("a"),lKr=o("from_pretrained()"),iKr=o(" to load the model weights."),dKr=l(),F(wA.$$.fragment),cKr=l(),Qr=a("div"),F(uR.$$.fragment),mKr=l(),Uye=a("p"),fKr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gKr=l(),qn=a("p"),hKr=o("The model class to instantiate is selected based on the "),Hye=a("code"),uKr=o("model_type"),pKr=o(` property of the config object (either
passed as an argument or loaded from `),Jye=a("code"),_Kr=o("pretrained_model_name_or_path"),bKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yye=a("code"),vKr=o("pretrained_model_name_or_path"),FKr=o(":"),TKr=l(),ve=a("ul"),AA=a("li"),Zye=a("strong"),MKr=o("albert"),EKr=o(" \u2014 "),Eae=a("a"),CKr=o("TFAlbertForMultipleChoice"),wKr=o(" (ALBERT model)"),AKr=l(),LA=a("li"),Kye=a("strong"),LKr=o("bert"),yKr=o(" \u2014 "),Cae=a("a"),xKr=o("TFBertForMultipleChoice"),$Kr=o(" (BERT model)"),kKr=l(),yA=a("li"),e8e=a("strong"),SKr=o("camembert"),RKr=o(" \u2014 "),wae=a("a"),PKr=o("TFCamembertForMultipleChoice"),BKr=o(" (CamemBERT model)"),IKr=l(),xA=a("li"),o8e=a("strong"),NKr=o("convbert"),qKr=o(" \u2014 "),Aae=a("a"),jKr=o("TFConvBertForMultipleChoice"),DKr=o(" (ConvBERT model)"),GKr=l(),$A=a("li"),r8e=a("strong"),OKr=o("distilbert"),VKr=o(" \u2014 "),Lae=a("a"),XKr=o("TFDistilBertForMultipleChoice"),zKr=o(" (DistilBERT model)"),QKr=l(),kA=a("li"),t8e=a("strong"),WKr=o("electra"),UKr=o(" \u2014 "),yae=a("a"),HKr=o("TFElectraForMultipleChoice"),JKr=o(" (ELECTRA model)"),YKr=l(),SA=a("li"),a8e=a("strong"),ZKr=o("flaubert"),KKr=o(" \u2014 "),xae=a("a"),eet=o("TFFlaubertForMultipleChoice"),oet=o(" (FlauBERT model)"),ret=l(),RA=a("li"),n8e=a("strong"),tet=o("funnel"),aet=o(" \u2014 "),$ae=a("a"),net=o("TFFunnelForMultipleChoice"),set=o(" (Funnel Transformer model)"),iet=l(),PA=a("li"),s8e=a("strong"),det=o("longformer"),cet=o(" \u2014 "),kae=a("a"),met=o("TFLongformerForMultipleChoice"),fet=o(" (Longformer model)"),get=l(),BA=a("li"),l8e=a("strong"),het=o("mobilebert"),uet=o(" \u2014 "),Sae=a("a"),pet=o("TFMobileBertForMultipleChoice"),_et=o(" (MobileBERT model)"),bet=l(),IA=a("li"),i8e=a("strong"),vet=o("mpnet"),Fet=o(" \u2014 "),Rae=a("a"),Tet=o("TFMPNetForMultipleChoice"),Met=o(" (MPNet model)"),Eet=l(),NA=a("li"),d8e=a("strong"),Cet=o("rembert"),wet=o(" \u2014 "),Pae=a("a"),Aet=o("TFRemBertForMultipleChoice"),Let=o(" (RemBERT model)"),yet=l(),qA=a("li"),c8e=a("strong"),xet=o("roberta"),$et=o(" \u2014 "),Bae=a("a"),ket=o("TFRobertaForMultipleChoice"),Set=o(" (RoBERTa model)"),Ret=l(),jA=a("li"),m8e=a("strong"),Pet=o("roformer"),Bet=o(" \u2014 "),Iae=a("a"),Iet=o("TFRoFormerForMultipleChoice"),Net=o(" (RoFormer model)"),qet=l(),DA=a("li"),f8e=a("strong"),jet=o("xlm"),Det=o(" \u2014 "),Nae=a("a"),Get=o("TFXLMForMultipleChoice"),Oet=o(" (XLM model)"),Vet=l(),GA=a("li"),g8e=a("strong"),Xet=o("xlm-roberta"),zet=o(" \u2014 "),qae=a("a"),Qet=o("TFXLMRobertaForMultipleChoice"),Wet=o(" (XLM-RoBERTa model)"),Uet=l(),OA=a("li"),h8e=a("strong"),Het=o("xlnet"),Jet=o(" \u2014 "),jae=a("a"),Yet=o("TFXLNetForMultipleChoice"),Zet=o(" (XLNet model)"),Ket=l(),F(VA.$$.fragment),jro=l(),Am=a("h2"),XA=a("a"),u8e=a("span"),F(pR.$$.fragment),eot=l(),p8e=a("span"),oot=o("TFAutoModelForNextSentencePrediction"),Dro=l(),_r=a("div"),F(_R.$$.fragment),rot=l(),Lm=a("p"),tot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Dae=a("a"),aot=o("from_pretrained()"),not=o(" class method or the "),Gae=a("a"),sot=o("from_config()"),lot=o(` class
method.`),iot=l(),bR=a("p"),dot=o("This class cannot be instantiated directly using "),_8e=a("code"),cot=o("__init__()"),mot=o(" (throws an error)."),fot=l(),ra=a("div"),F(vR.$$.fragment),got=l(),b8e=a("p"),hot=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),uot=l(),ym=a("p"),pot=o(`Note:
Loading a model from its configuration file does `),v8e=a("strong"),_ot=o("not"),bot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Oae=a("a"),vot=o("from_pretrained()"),Fot=o(" to load the model weights."),Tot=l(),F(zA.$$.fragment),Mot=l(),Wr=a("div"),F(FR.$$.fragment),Eot=l(),F8e=a("p"),Cot=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),wot=l(),jn=a("p"),Aot=o("The model class to instantiate is selected based on the "),T8e=a("code"),Lot=o("model_type"),yot=o(` property of the config object (either
passed as an argument or loaded from `),M8e=a("code"),xot=o("pretrained_model_name_or_path"),$ot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E8e=a("code"),kot=o("pretrained_model_name_or_path"),Sot=o(":"),Rot=l(),TR=a("ul"),QA=a("li"),C8e=a("strong"),Pot=o("bert"),Bot=o(" \u2014 "),Vae=a("a"),Iot=o("TFBertForNextSentencePrediction"),Not=o(" (BERT model)"),qot=l(),WA=a("li"),w8e=a("strong"),jot=o("mobilebert"),Dot=o(" \u2014 "),Xae=a("a"),Got=o("TFMobileBertForNextSentencePrediction"),Oot=o(" (MobileBERT model)"),Vot=l(),F(UA.$$.fragment),Gro=l(),xm=a("h2"),HA=a("a"),A8e=a("span"),F(MR.$$.fragment),Xot=l(),L8e=a("span"),zot=o("TFAutoModelForTableQuestionAnswering"),Oro=l(),br=a("div"),F(ER.$$.fragment),Qot=l(),$m=a("p"),Wot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zae=a("a"),Uot=o("from_pretrained()"),Hot=o(" class method or the "),Qae=a("a"),Jot=o("from_config()"),Yot=o(` class
method.`),Zot=l(),CR=a("p"),Kot=o("This class cannot be instantiated directly using "),y8e=a("code"),ert=o("__init__()"),ort=o(" (throws an error)."),rrt=l(),ta=a("div"),F(wR.$$.fragment),trt=l(),x8e=a("p"),art=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),nrt=l(),km=a("p"),srt=o(`Note:
Loading a model from its configuration file does `),$8e=a("strong"),lrt=o("not"),irt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wae=a("a"),drt=o("from_pretrained()"),crt=o(" to load the model weights."),mrt=l(),F(JA.$$.fragment),frt=l(),Ur=a("div"),F(AR.$$.fragment),grt=l(),k8e=a("p"),hrt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),urt=l(),Dn=a("p"),prt=o("The model class to instantiate is selected based on the "),S8e=a("code"),_rt=o("model_type"),brt=o(` property of the config object (either
passed as an argument or loaded from `),R8e=a("code"),vrt=o("pretrained_model_name_or_path"),Frt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P8e=a("code"),Trt=o("pretrained_model_name_or_path"),Mrt=o(":"),Ert=l(),B8e=a("ul"),YA=a("li"),I8e=a("strong"),Crt=o("tapas"),wrt=o(" \u2014 "),Uae=a("a"),Art=o("TFTapasForQuestionAnswering"),Lrt=o(" (TAPAS model)"),yrt=l(),F(ZA.$$.fragment),Vro=l(),Sm=a("h2"),KA=a("a"),N8e=a("span"),F(LR.$$.fragment),xrt=l(),q8e=a("span"),$rt=o("TFAutoModelForDocumentQuestionAnswering"),Xro=l(),vr=a("div"),F(yR.$$.fragment),krt=l(),Rm=a("p"),Srt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Hae=a("a"),Rrt=o("from_pretrained()"),Prt=o(" class method or the "),Jae=a("a"),Brt=o("from_config()"),Irt=o(` class
method.`),Nrt=l(),xR=a("p"),qrt=o("This class cannot be instantiated directly using "),j8e=a("code"),jrt=o("__init__()"),Drt=o(" (throws an error)."),Grt=l(),aa=a("div"),F($R.$$.fragment),Ort=l(),D8e=a("p"),Vrt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Xrt=l(),Pm=a("p"),zrt=o(`Note:
Loading a model from its configuration file does `),G8e=a("strong"),Qrt=o("not"),Wrt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yae=a("a"),Urt=o("from_pretrained()"),Hrt=o(" to load the model weights."),Jrt=l(),F(e6.$$.fragment),Yrt=l(),Hr=a("div"),F(kR.$$.fragment),Zrt=l(),O8e=a("p"),Krt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),ett=l(),Gn=a("p"),ott=o("The model class to instantiate is selected based on the "),V8e=a("code"),rtt=o("model_type"),ttt=o(` property of the config object (either
passed as an argument or loaded from `),X8e=a("code"),att=o("pretrained_model_name_or_path"),ntt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z8e=a("code"),stt=o("pretrained_model_name_or_path"),ltt=o(":"),itt=l(),Q8e=a("ul"),o6=a("li"),W8e=a("strong"),dtt=o("layoutlm"),ctt=o(" \u2014 "),Zae=a("a"),mtt=o("TFLayoutLMForQuestionAnswering"),ftt=o(" (LayoutLM model)"),gtt=l(),F(r6.$$.fragment),zro=l(),Bm=a("h2"),t6=a("a"),U8e=a("span"),F(SR.$$.fragment),htt=l(),H8e=a("span"),utt=o("TFAutoModelForTokenClassification"),Qro=l(),Fr=a("div"),F(RR.$$.fragment),ptt=l(),Im=a("p"),_tt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Kae=a("a"),btt=o("from_pretrained()"),vtt=o(" class method or the "),ene=a("a"),Ftt=o("from_config()"),Ttt=o(` class
method.`),Mtt=l(),PR=a("p"),Ett=o("This class cannot be instantiated directly using "),J8e=a("code"),Ctt=o("__init__()"),wtt=o(" (throws an error)."),Att=l(),na=a("div"),F(BR.$$.fragment),Ltt=l(),Y8e=a("p"),ytt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),xtt=l(),Nm=a("p"),$tt=o(`Note:
Loading a model from its configuration file does `),Z8e=a("strong"),ktt=o("not"),Stt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),one=a("a"),Rtt=o("from_pretrained()"),Ptt=o(" to load the model weights."),Btt=l(),F(a6.$$.fragment),Itt=l(),Jr=a("div"),F(IR.$$.fragment),Ntt=l(),K8e=a("p"),qtt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),jtt=l(),On=a("p"),Dtt=o("The model class to instantiate is selected based on the "),e9e=a("code"),Gtt=o("model_type"),Ott=o(` property of the config object (either
passed as an argument or loaded from `),o9e=a("code"),Vtt=o("pretrained_model_name_or_path"),Xtt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r9e=a("code"),ztt=o("pretrained_model_name_or_path"),Qtt=o(":"),Wtt=l(),ce=a("ul"),n6=a("li"),t9e=a("strong"),Utt=o("albert"),Htt=o(" \u2014 "),rne=a("a"),Jtt=o("TFAlbertForTokenClassification"),Ytt=o(" (ALBERT model)"),Ztt=l(),s6=a("li"),a9e=a("strong"),Ktt=o("bert"),eat=o(" \u2014 "),tne=a("a"),oat=o("TFBertForTokenClassification"),rat=o(" (BERT model)"),tat=l(),l6=a("li"),n9e=a("strong"),aat=o("camembert"),nat=o(" \u2014 "),ane=a("a"),sat=o("TFCamembertForTokenClassification"),lat=o(" (CamemBERT model)"),iat=l(),i6=a("li"),s9e=a("strong"),dat=o("convbert"),cat=o(" \u2014 "),nne=a("a"),mat=o("TFConvBertForTokenClassification"),fat=o(" (ConvBERT model)"),gat=l(),d6=a("li"),l9e=a("strong"),hat=o("deberta"),uat=o(" \u2014 "),sne=a("a"),pat=o("TFDebertaForTokenClassification"),_at=o(" (DeBERTa model)"),bat=l(),c6=a("li"),i9e=a("strong"),vat=o("deberta-v2"),Fat=o(" \u2014 "),lne=a("a"),Tat=o("TFDebertaV2ForTokenClassification"),Mat=o(" (DeBERTa-v2 model)"),Eat=l(),m6=a("li"),d9e=a("strong"),Cat=o("distilbert"),wat=o(" \u2014 "),ine=a("a"),Aat=o("TFDistilBertForTokenClassification"),Lat=o(" (DistilBERT model)"),yat=l(),f6=a("li"),c9e=a("strong"),xat=o("electra"),$at=o(" \u2014 "),dne=a("a"),kat=o("TFElectraForTokenClassification"),Sat=o(" (ELECTRA model)"),Rat=l(),g6=a("li"),m9e=a("strong"),Pat=o("flaubert"),Bat=o(" \u2014 "),cne=a("a"),Iat=o("TFFlaubertForTokenClassification"),Nat=o(" (FlauBERT model)"),qat=l(),h6=a("li"),f9e=a("strong"),jat=o("funnel"),Dat=o(" \u2014 "),mne=a("a"),Gat=o("TFFunnelForTokenClassification"),Oat=o(" (Funnel Transformer model)"),Vat=l(),u6=a("li"),g9e=a("strong"),Xat=o("layoutlm"),zat=o(" \u2014 "),fne=a("a"),Qat=o("TFLayoutLMForTokenClassification"),Wat=o(" (LayoutLM model)"),Uat=l(),p6=a("li"),h9e=a("strong"),Hat=o("layoutlmv3"),Jat=o(" \u2014 "),gne=a("a"),Yat=o("TFLayoutLMv3ForTokenClassification"),Zat=o(" (LayoutLMv3 model)"),Kat=l(),_6=a("li"),u9e=a("strong"),ent=o("longformer"),ont=o(" \u2014 "),hne=a("a"),rnt=o("TFLongformerForTokenClassification"),tnt=o(" (Longformer model)"),ant=l(),b6=a("li"),p9e=a("strong"),nnt=o("mobilebert"),snt=o(" \u2014 "),une=a("a"),lnt=o("TFMobileBertForTokenClassification"),int=o(" (MobileBERT model)"),dnt=l(),v6=a("li"),_9e=a("strong"),cnt=o("mpnet"),mnt=o(" \u2014 "),pne=a("a"),fnt=o("TFMPNetForTokenClassification"),gnt=o(" (MPNet model)"),hnt=l(),F6=a("li"),b9e=a("strong"),unt=o("rembert"),pnt=o(" \u2014 "),_ne=a("a"),_nt=o("TFRemBertForTokenClassification"),bnt=o(" (RemBERT model)"),vnt=l(),T6=a("li"),v9e=a("strong"),Fnt=o("roberta"),Tnt=o(" \u2014 "),bne=a("a"),Mnt=o("TFRobertaForTokenClassification"),Ent=o(" (RoBERTa model)"),Cnt=l(),M6=a("li"),F9e=a("strong"),wnt=o("roformer"),Ant=o(" \u2014 "),vne=a("a"),Lnt=o("TFRoFormerForTokenClassification"),ynt=o(" (RoFormer model)"),xnt=l(),E6=a("li"),T9e=a("strong"),$nt=o("xlm"),knt=o(" \u2014 "),Fne=a("a"),Snt=o("TFXLMForTokenClassification"),Rnt=o(" (XLM model)"),Pnt=l(),C6=a("li"),M9e=a("strong"),Bnt=o("xlm-roberta"),Int=o(" \u2014 "),Tne=a("a"),Nnt=o("TFXLMRobertaForTokenClassification"),qnt=o(" (XLM-RoBERTa model)"),jnt=l(),w6=a("li"),E9e=a("strong"),Dnt=o("xlnet"),Gnt=o(" \u2014 "),Mne=a("a"),Ont=o("TFXLNetForTokenClassification"),Vnt=o(" (XLNet model)"),Xnt=l(),F(A6.$$.fragment),Wro=l(),qm=a("h2"),L6=a("a"),C9e=a("span"),F(NR.$$.fragment),znt=l(),w9e=a("span"),Qnt=o("TFAutoModelForQuestionAnswering"),Uro=l(),Tr=a("div"),F(qR.$$.fragment),Wnt=l(),jm=a("p"),Unt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Ene=a("a"),Hnt=o("from_pretrained()"),Jnt=o(" class method or the "),Cne=a("a"),Ynt=o("from_config()"),Znt=o(` class
method.`),Knt=l(),jR=a("p"),est=o("This class cannot be instantiated directly using "),A9e=a("code"),ost=o("__init__()"),rst=o(" (throws an error)."),tst=l(),sa=a("div"),F(DR.$$.fragment),ast=l(),L9e=a("p"),nst=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),sst=l(),Dm=a("p"),lst=o(`Note:
Loading a model from its configuration file does `),y9e=a("strong"),ist=o("not"),dst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wne=a("a"),cst=o("from_pretrained()"),mst=o(" to load the model weights."),fst=l(),F(y6.$$.fragment),gst=l(),Yr=a("div"),F(GR.$$.fragment),hst=l(),x9e=a("p"),ust=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),pst=l(),Vn=a("p"),_st=o("The model class to instantiate is selected based on the "),$9e=a("code"),bst=o("model_type"),vst=o(` property of the config object (either
passed as an argument or loaded from `),k9e=a("code"),Fst=o("pretrained_model_name_or_path"),Tst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S9e=a("code"),Mst=o("pretrained_model_name_or_path"),Est=o(":"),Cst=l(),me=a("ul"),x6=a("li"),R9e=a("strong"),wst=o("albert"),Ast=o(" \u2014 "),Ane=a("a"),Lst=o("TFAlbertForQuestionAnswering"),yst=o(" (ALBERT model)"),xst=l(),$6=a("li"),P9e=a("strong"),$st=o("bert"),kst=o(" \u2014 "),Lne=a("a"),Sst=o("TFBertForQuestionAnswering"),Rst=o(" (BERT model)"),Pst=l(),k6=a("li"),B9e=a("strong"),Bst=o("camembert"),Ist=o(" \u2014 "),yne=a("a"),Nst=o("TFCamembertForQuestionAnswering"),qst=o(" (CamemBERT model)"),jst=l(),S6=a("li"),I9e=a("strong"),Dst=o("convbert"),Gst=o(" \u2014 "),xne=a("a"),Ost=o("TFConvBertForQuestionAnswering"),Vst=o(" (ConvBERT model)"),Xst=l(),R6=a("li"),N9e=a("strong"),zst=o("deberta"),Qst=o(" \u2014 "),$ne=a("a"),Wst=o("TFDebertaForQuestionAnswering"),Ust=o(" (DeBERTa model)"),Hst=l(),P6=a("li"),q9e=a("strong"),Jst=o("deberta-v2"),Yst=o(" \u2014 "),kne=a("a"),Zst=o("TFDebertaV2ForQuestionAnswering"),Kst=o(" (DeBERTa-v2 model)"),elt=l(),B6=a("li"),j9e=a("strong"),olt=o("distilbert"),rlt=o(" \u2014 "),Sne=a("a"),tlt=o("TFDistilBertForQuestionAnswering"),alt=o(" (DistilBERT model)"),nlt=l(),I6=a("li"),D9e=a("strong"),slt=o("electra"),llt=o(" \u2014 "),Rne=a("a"),ilt=o("TFElectraForQuestionAnswering"),dlt=o(" (ELECTRA model)"),clt=l(),N6=a("li"),G9e=a("strong"),mlt=o("flaubert"),flt=o(" \u2014 "),Pne=a("a"),glt=o("TFFlaubertForQuestionAnsweringSimple"),hlt=o(" (FlauBERT model)"),ult=l(),q6=a("li"),O9e=a("strong"),plt=o("funnel"),_lt=o(" \u2014 "),Bne=a("a"),blt=o("TFFunnelForQuestionAnswering"),vlt=o(" (Funnel Transformer model)"),Flt=l(),j6=a("li"),V9e=a("strong"),Tlt=o("gptj"),Mlt=o(" \u2014 "),Ine=a("a"),Elt=o("TFGPTJForQuestionAnswering"),Clt=o(" (GPT-J model)"),wlt=l(),D6=a("li"),X9e=a("strong"),Alt=o("layoutlmv3"),Llt=o(" \u2014 "),Nne=a("a"),ylt=o("TFLayoutLMv3ForQuestionAnswering"),xlt=o(" (LayoutLMv3 model)"),$lt=l(),G6=a("li"),z9e=a("strong"),klt=o("longformer"),Slt=o(" \u2014 "),qne=a("a"),Rlt=o("TFLongformerForQuestionAnswering"),Plt=o(" (Longformer model)"),Blt=l(),O6=a("li"),Q9e=a("strong"),Ilt=o("mobilebert"),Nlt=o(" \u2014 "),jne=a("a"),qlt=o("TFMobileBertForQuestionAnswering"),jlt=o(" (MobileBERT model)"),Dlt=l(),V6=a("li"),W9e=a("strong"),Glt=o("mpnet"),Olt=o(" \u2014 "),Dne=a("a"),Vlt=o("TFMPNetForQuestionAnswering"),Xlt=o(" (MPNet model)"),zlt=l(),X6=a("li"),U9e=a("strong"),Qlt=o("rembert"),Wlt=o(" \u2014 "),Gne=a("a"),Ult=o("TFRemBertForQuestionAnswering"),Hlt=o(" (RemBERT model)"),Jlt=l(),z6=a("li"),H9e=a("strong"),Ylt=o("roberta"),Zlt=o(" \u2014 "),One=a("a"),Klt=o("TFRobertaForQuestionAnswering"),eit=o(" (RoBERTa model)"),oit=l(),Q6=a("li"),J9e=a("strong"),rit=o("roformer"),tit=o(" \u2014 "),Vne=a("a"),ait=o("TFRoFormerForQuestionAnswering"),nit=o(" (RoFormer model)"),sit=l(),W6=a("li"),Y9e=a("strong"),lit=o("xlm"),iit=o(" \u2014 "),Xne=a("a"),dit=o("TFXLMForQuestionAnsweringSimple"),cit=o(" (XLM model)"),mit=l(),U6=a("li"),Z9e=a("strong"),fit=o("xlm-roberta"),git=o(" \u2014 "),zne=a("a"),hit=o("TFXLMRobertaForQuestionAnswering"),uit=o(" (XLM-RoBERTa model)"),pit=l(),H6=a("li"),K9e=a("strong"),_it=o("xlnet"),bit=o(" \u2014 "),Qne=a("a"),vit=o("TFXLNetForQuestionAnsweringSimple"),Fit=o(" (XLNet model)"),Tit=l(),F(J6.$$.fragment),Hro=l(),Gm=a("h2"),Y6=a("a"),exe=a("span"),F(OR.$$.fragment),Mit=l(),oxe=a("span"),Eit=o("TFAutoModelForVision2Seq"),Jro=l(),Mr=a("div"),F(VR.$$.fragment),Cit=l(),Om=a("p"),wit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wne=a("a"),Ait=o("from_pretrained()"),Lit=o(" class method or the "),Une=a("a"),yit=o("from_config()"),xit=o(` class
method.`),$it=l(),XR=a("p"),kit=o("This class cannot be instantiated directly using "),rxe=a("code"),Sit=o("__init__()"),Rit=o(" (throws an error)."),Pit=l(),la=a("div"),F(zR.$$.fragment),Bit=l(),txe=a("p"),Iit=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Nit=l(),Vm=a("p"),qit=o(`Note:
Loading a model from its configuration file does `),axe=a("strong"),jit=o("not"),Dit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hne=a("a"),Git=o("from_pretrained()"),Oit=o(" to load the model weights."),Vit=l(),F(Z6.$$.fragment),Xit=l(),Zr=a("div"),F(QR.$$.fragment),zit=l(),nxe=a("p"),Qit=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Wit=l(),Xn=a("p"),Uit=o("The model class to instantiate is selected based on the "),sxe=a("code"),Hit=o("model_type"),Jit=o(` property of the config object (either
passed as an argument or loaded from `),lxe=a("code"),Yit=o("pretrained_model_name_or_path"),Zit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ixe=a("code"),Kit=o("pretrained_model_name_or_path"),edt=o(":"),odt=l(),dxe=a("ul"),K6=a("li"),cxe=a("strong"),rdt=o("vision-encoder-decoder"),tdt=o(" \u2014 "),Jne=a("a"),adt=o("TFVisionEncoderDecoderModel"),ndt=o(" (Vision Encoder decoder model)"),sdt=l(),F(e7.$$.fragment),Yro=l(),Xm=a("h2"),o7=a("a"),mxe=a("span"),F(WR.$$.fragment),ldt=l(),fxe=a("span"),idt=o("TFAutoModelForSpeechSeq2Seq"),Zro=l(),Er=a("div"),F(UR.$$.fragment),ddt=l(),zm=a("p"),cdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Yne=a("a"),mdt=o("from_pretrained()"),fdt=o(" class method or the "),Zne=a("a"),gdt=o("from_config()"),hdt=o(` class
method.`),udt=l(),HR=a("p"),pdt=o("This class cannot be instantiated directly using "),gxe=a("code"),_dt=o("__init__()"),bdt=o(" (throws an error)."),vdt=l(),ia=a("div"),F(JR.$$.fragment),Fdt=l(),hxe=a("p"),Tdt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Mdt=l(),Qm=a("p"),Edt=o(`Note:
Loading a model from its configuration file does `),uxe=a("strong"),Cdt=o("not"),wdt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kne=a("a"),Adt=o("from_pretrained()"),Ldt=o(" to load the model weights."),ydt=l(),F(r7.$$.fragment),xdt=l(),Kr=a("div"),F(YR.$$.fragment),$dt=l(),pxe=a("p"),kdt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Sdt=l(),zn=a("p"),Rdt=o("The model class to instantiate is selected based on the "),_xe=a("code"),Pdt=o("model_type"),Bdt=o(` property of the config object (either
passed as an argument or loaded from `),bxe=a("code"),Idt=o("pretrained_model_name_or_path"),Ndt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vxe=a("code"),qdt=o("pretrained_model_name_or_path"),jdt=o(":"),Ddt=l(),Fxe=a("ul"),t7=a("li"),Txe=a("strong"),Gdt=o("speech_to_text"),Odt=o(" \u2014 "),ese=a("a"),Vdt=o("TFSpeech2TextForConditionalGeneration"),Xdt=o(" (Speech2Text model)"),zdt=l(),F(a7.$$.fragment),Kro=l(),Wm=a("h2"),n7=a("a"),Mxe=a("span"),F(ZR.$$.fragment),Qdt=l(),Exe=a("span"),Wdt=o("FlaxAutoModel"),eto=l(),Cr=a("div"),F(KR.$$.fragment),Udt=l(),Um=a("p"),Hdt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ose=a("a"),Jdt=o("from_pretrained()"),Ydt=o(" class method or the "),rse=a("a"),Zdt=o("from_config()"),Kdt=o(` class
method.`),ect=l(),eP=a("p"),oct=o("This class cannot be instantiated directly using "),Cxe=a("code"),rct=o("__init__()"),tct=o(" (throws an error)."),act=l(),da=a("div"),F(oP.$$.fragment),nct=l(),wxe=a("p"),sct=o("Instantiates one of the base model classes of the library from a configuration."),lct=l(),Hm=a("p"),ict=o(`Note:
Loading a model from its configuration file does `),Axe=a("strong"),dct=o("not"),cct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tse=a("a"),mct=o("from_pretrained()"),fct=o(" to load the model weights."),gct=l(),F(s7.$$.fragment),hct=l(),et=a("div"),F(rP.$$.fragment),uct=l(),Lxe=a("p"),pct=o("Instantiate one of the base model classes of the library from a pretrained model."),_ct=l(),Qn=a("p"),bct=o("The model class to instantiate is selected based on the "),yxe=a("code"),vct=o("model_type"),Fct=o(` property of the config object (either
passed as an argument or loaded from `),xxe=a("code"),Tct=o("pretrained_model_name_or_path"),Mct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$xe=a("code"),Ect=o("pretrained_model_name_or_path"),Cct=o(":"),wct=l(),te=a("ul"),l7=a("li"),kxe=a("strong"),Act=o("albert"),Lct=o(" \u2014 "),ase=a("a"),yct=o("FlaxAlbertModel"),xct=o(" (ALBERT model)"),$ct=l(),i7=a("li"),Sxe=a("strong"),kct=o("bart"),Sct=o(" \u2014 "),nse=a("a"),Rct=o("FlaxBartModel"),Pct=o(" (BART model)"),Bct=l(),d7=a("li"),Rxe=a("strong"),Ict=o("beit"),Nct=o(" \u2014 "),sse=a("a"),qct=o("FlaxBeitModel"),jct=o(" (BEiT model)"),Dct=l(),c7=a("li"),Pxe=a("strong"),Gct=o("bert"),Oct=o(" \u2014 "),lse=a("a"),Vct=o("FlaxBertModel"),Xct=o(" (BERT model)"),zct=l(),m7=a("li"),Bxe=a("strong"),Qct=o("big_bird"),Wct=o(" \u2014 "),ise=a("a"),Uct=o("FlaxBigBirdModel"),Hct=o(" (BigBird model)"),Jct=l(),f7=a("li"),Ixe=a("strong"),Yct=o("blenderbot"),Zct=o(" \u2014 "),dse=a("a"),Kct=o("FlaxBlenderbotModel"),emt=o(" (Blenderbot model)"),omt=l(),g7=a("li"),Nxe=a("strong"),rmt=o("blenderbot-small"),tmt=o(" \u2014 "),cse=a("a"),amt=o("FlaxBlenderbotSmallModel"),nmt=o(" (BlenderbotSmall model)"),smt=l(),h7=a("li"),qxe=a("strong"),lmt=o("clip"),imt=o(" \u2014 "),mse=a("a"),dmt=o("FlaxCLIPModel"),cmt=o(" (CLIP model)"),mmt=l(),u7=a("li"),jxe=a("strong"),fmt=o("distilbert"),gmt=o(" \u2014 "),fse=a("a"),hmt=o("FlaxDistilBertModel"),umt=o(" (DistilBERT model)"),pmt=l(),p7=a("li"),Dxe=a("strong"),_mt=o("electra"),bmt=o(" \u2014 "),gse=a("a"),vmt=o("FlaxElectraModel"),Fmt=o(" (ELECTRA model)"),Tmt=l(),_7=a("li"),Gxe=a("strong"),Mmt=o("gpt2"),Emt=o(" \u2014 "),hse=a("a"),Cmt=o("FlaxGPT2Model"),wmt=o(" (OpenAI GPT-2 model)"),Amt=l(),b7=a("li"),Oxe=a("strong"),Lmt=o("gpt_neo"),ymt=o(" \u2014 "),use=a("a"),xmt=o("FlaxGPTNeoModel"),$mt=o(" (GPT Neo model)"),kmt=l(),v7=a("li"),Vxe=a("strong"),Smt=o("gptj"),Rmt=o(" \u2014 "),pse=a("a"),Pmt=o("FlaxGPTJModel"),Bmt=o(" (GPT-J model)"),Imt=l(),F7=a("li"),Xxe=a("strong"),Nmt=o("longt5"),qmt=o(" \u2014 "),_se=a("a"),jmt=o("FlaxLongT5Model"),Dmt=o(" (LongT5 model)"),Gmt=l(),T7=a("li"),zxe=a("strong"),Omt=o("marian"),Vmt=o(" \u2014 "),bse=a("a"),Xmt=o("FlaxMarianModel"),zmt=o(" (Marian model)"),Qmt=l(),M7=a("li"),Qxe=a("strong"),Wmt=o("mbart"),Umt=o(" \u2014 "),vse=a("a"),Hmt=o("FlaxMBartModel"),Jmt=o(" (mBART model)"),Ymt=l(),E7=a("li"),Wxe=a("strong"),Zmt=o("mt5"),Kmt=o(" \u2014 "),Fse=a("a"),eft=o("FlaxMT5Model"),oft=o(" (MT5 model)"),rft=l(),C7=a("li"),Uxe=a("strong"),tft=o("opt"),aft=o(" \u2014 "),Tse=a("a"),nft=o("FlaxOPTModel"),sft=o(" (OPT model)"),lft=l(),w7=a("li"),Hxe=a("strong"),ift=o("pegasus"),dft=o(" \u2014 "),Mse=a("a"),cft=o("FlaxPegasusModel"),mft=o(" (Pegasus model)"),fft=l(),A7=a("li"),Jxe=a("strong"),gft=o("roberta"),hft=o(" \u2014 "),Ese=a("a"),uft=o("FlaxRobertaModel"),pft=o(" (RoBERTa model)"),_ft=l(),L7=a("li"),Yxe=a("strong"),bft=o("roformer"),vft=o(" \u2014 "),Cse=a("a"),Fft=o("FlaxRoFormerModel"),Tft=o(" (RoFormer model)"),Mft=l(),y7=a("li"),Zxe=a("strong"),Eft=o("t5"),Cft=o(" \u2014 "),wse=a("a"),wft=o("FlaxT5Model"),Aft=o(" (T5 model)"),Lft=l(),x7=a("li"),Kxe=a("strong"),yft=o("vision-text-dual-encoder"),xft=o(" \u2014 "),Ase=a("a"),$ft=o("FlaxVisionTextDualEncoderModel"),kft=o(" (VisionTextDualEncoder model)"),Sft=l(),$7=a("li"),e$e=a("strong"),Rft=o("vit"),Pft=o(" \u2014 "),Lse=a("a"),Bft=o("FlaxViTModel"),Ift=o(" (ViT model)"),Nft=l(),k7=a("li"),o$e=a("strong"),qft=o("wav2vec2"),jft=o(" \u2014 "),yse=a("a"),Dft=o("FlaxWav2Vec2Model"),Gft=o(" (Wav2Vec2 model)"),Oft=l(),S7=a("li"),r$e=a("strong"),Vft=o("xglm"),Xft=o(" \u2014 "),xse=a("a"),zft=o("FlaxXGLMModel"),Qft=o(" (XGLM model)"),Wft=l(),R7=a("li"),t$e=a("strong"),Uft=o("xlm-roberta"),Hft=o(" \u2014 "),$se=a("a"),Jft=o("FlaxXLMRobertaModel"),Yft=o(" (XLM-RoBERTa model)"),Zft=l(),F(P7.$$.fragment),oto=l(),Jm=a("h2"),B7=a("a"),a$e=a("span"),F(tP.$$.fragment),Kft=l(),n$e=a("span"),egt=o("FlaxAutoModelForCausalLM"),rto=l(),wr=a("div"),F(aP.$$.fragment),ogt=l(),Ym=a("p"),rgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),kse=a("a"),tgt=o("from_pretrained()"),agt=o(" class method or the "),Sse=a("a"),ngt=o("from_config()"),sgt=o(` class
method.`),lgt=l(),nP=a("p"),igt=o("This class cannot be instantiated directly using "),s$e=a("code"),dgt=o("__init__()"),cgt=o(" (throws an error)."),mgt=l(),ca=a("div"),F(sP.$$.fragment),fgt=l(),l$e=a("p"),ggt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),hgt=l(),Zm=a("p"),ugt=o(`Note:
Loading a model from its configuration file does `),i$e=a("strong"),pgt=o("not"),_gt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rse=a("a"),bgt=o("from_pretrained()"),vgt=o(" to load the model weights."),Fgt=l(),F(I7.$$.fragment),Tgt=l(),ot=a("div"),F(lP.$$.fragment),Mgt=l(),d$e=a("p"),Egt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Cgt=l(),Wn=a("p"),wgt=o("The model class to instantiate is selected based on the "),c$e=a("code"),Agt=o("model_type"),Lgt=o(` property of the config object (either
passed as an argument or loaded from `),m$e=a("code"),ygt=o("pretrained_model_name_or_path"),xgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f$e=a("code"),$gt=o("pretrained_model_name_or_path"),kgt=o(":"),Sgt=l(),xe=a("ul"),N7=a("li"),g$e=a("strong"),Rgt=o("bart"),Pgt=o(" \u2014 "),Pse=a("a"),Bgt=o("FlaxBartForCausalLM"),Igt=o(" (BART model)"),Ngt=l(),q7=a("li"),h$e=a("strong"),qgt=o("bert"),jgt=o(" \u2014 "),Bse=a("a"),Dgt=o("FlaxBertForCausalLM"),Ggt=o(" (BERT model)"),Ogt=l(),j7=a("li"),u$e=a("strong"),Vgt=o("big_bird"),Xgt=o(" \u2014 "),Ise=a("a"),zgt=o("FlaxBigBirdForCausalLM"),Qgt=o(" (BigBird model)"),Wgt=l(),D7=a("li"),p$e=a("strong"),Ugt=o("electra"),Hgt=o(" \u2014 "),Nse=a("a"),Jgt=o("FlaxElectraForCausalLM"),Ygt=o(" (ELECTRA model)"),Zgt=l(),G7=a("li"),_$e=a("strong"),Kgt=o("gpt2"),eht=o(" \u2014 "),qse=a("a"),oht=o("FlaxGPT2LMHeadModel"),rht=o(" (OpenAI GPT-2 model)"),tht=l(),O7=a("li"),b$e=a("strong"),aht=o("gpt_neo"),nht=o(" \u2014 "),jse=a("a"),sht=o("FlaxGPTNeoForCausalLM"),lht=o(" (GPT Neo model)"),iht=l(),V7=a("li"),v$e=a("strong"),dht=o("gptj"),cht=o(" \u2014 "),Dse=a("a"),mht=o("FlaxGPTJForCausalLM"),fht=o(" (GPT-J model)"),ght=l(),X7=a("li"),F$e=a("strong"),hht=o("opt"),uht=o(" \u2014 "),Gse=a("a"),pht=o("FlaxOPTForCausalLM"),_ht=o(" (OPT model)"),bht=l(),z7=a("li"),T$e=a("strong"),vht=o("roberta"),Fht=o(" \u2014 "),Ose=a("a"),Tht=o("FlaxRobertaForCausalLM"),Mht=o(" (RoBERTa model)"),Eht=l(),Q7=a("li"),M$e=a("strong"),Cht=o("xglm"),wht=o(" \u2014 "),Vse=a("a"),Aht=o("FlaxXGLMForCausalLM"),Lht=o(" (XGLM model)"),yht=l(),F(W7.$$.fragment),tto=l(),Km=a("h2"),U7=a("a"),E$e=a("span"),F(iP.$$.fragment),xht=l(),C$e=a("span"),$ht=o("FlaxAutoModelForPreTraining"),ato=l(),Ar=a("div"),F(dP.$$.fragment),kht=l(),ef=a("p"),Sht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Xse=a("a"),Rht=o("from_pretrained()"),Pht=o(" class method or the "),zse=a("a"),Bht=o("from_config()"),Iht=o(` class
method.`),Nht=l(),cP=a("p"),qht=o("This class cannot be instantiated directly using "),w$e=a("code"),jht=o("__init__()"),Dht=o(" (throws an error)."),Ght=l(),ma=a("div"),F(mP.$$.fragment),Oht=l(),A$e=a("p"),Vht=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Xht=l(),of=a("p"),zht=o(`Note:
Loading a model from its configuration file does `),L$e=a("strong"),Qht=o("not"),Wht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qse=a("a"),Uht=o("from_pretrained()"),Hht=o(" to load the model weights."),Jht=l(),F(H7.$$.fragment),Yht=l(),rt=a("div"),F(fP.$$.fragment),Zht=l(),y$e=a("p"),Kht=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),eut=l(),Un=a("p"),out=o("The model class to instantiate is selected based on the "),x$e=a("code"),rut=o("model_type"),tut=o(` property of the config object (either
passed as an argument or loaded from `),$$e=a("code"),aut=o("pretrained_model_name_or_path"),nut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=a("code"),sut=o("pretrained_model_name_or_path"),lut=o(":"),iut=l(),Ee=a("ul"),J7=a("li"),S$e=a("strong"),dut=o("albert"),cut=o(" \u2014 "),Wse=a("a"),mut=o("FlaxAlbertForPreTraining"),fut=o(" (ALBERT model)"),gut=l(),Y7=a("li"),R$e=a("strong"),hut=o("bart"),uut=o(" \u2014 "),Use=a("a"),put=o("FlaxBartForConditionalGeneration"),_ut=o(" (BART model)"),but=l(),Z7=a("li"),P$e=a("strong"),vut=o("bert"),Fut=o(" \u2014 "),Hse=a("a"),Tut=o("FlaxBertForPreTraining"),Mut=o(" (BERT model)"),Eut=l(),K7=a("li"),B$e=a("strong"),Cut=o("big_bird"),wut=o(" \u2014 "),Jse=a("a"),Aut=o("FlaxBigBirdForPreTraining"),Lut=o(" (BigBird model)"),yut=l(),eL=a("li"),I$e=a("strong"),xut=o("electra"),$ut=o(" \u2014 "),Yse=a("a"),kut=o("FlaxElectraForPreTraining"),Sut=o(" (ELECTRA model)"),Rut=l(),oL=a("li"),N$e=a("strong"),Put=o("longt5"),But=o(" \u2014 "),Zse=a("a"),Iut=o("FlaxLongT5ForConditionalGeneration"),Nut=o(" (LongT5 model)"),qut=l(),rL=a("li"),q$e=a("strong"),jut=o("mbart"),Dut=o(" \u2014 "),Kse=a("a"),Gut=o("FlaxMBartForConditionalGeneration"),Out=o(" (mBART model)"),Vut=l(),tL=a("li"),j$e=a("strong"),Xut=o("mt5"),zut=o(" \u2014 "),ele=a("a"),Qut=o("FlaxMT5ForConditionalGeneration"),Wut=o(" (MT5 model)"),Uut=l(),aL=a("li"),D$e=a("strong"),Hut=o("roberta"),Jut=o(" \u2014 "),ole=a("a"),Yut=o("FlaxRobertaForMaskedLM"),Zut=o(" (RoBERTa model)"),Kut=l(),nL=a("li"),G$e=a("strong"),ept=o("roformer"),opt=o(" \u2014 "),rle=a("a"),rpt=o("FlaxRoFormerForMaskedLM"),tpt=o(" (RoFormer model)"),apt=l(),sL=a("li"),O$e=a("strong"),npt=o("t5"),spt=o(" \u2014 "),tle=a("a"),lpt=o("FlaxT5ForConditionalGeneration"),ipt=o(" (T5 model)"),dpt=l(),lL=a("li"),V$e=a("strong"),cpt=o("wav2vec2"),mpt=o(" \u2014 "),ale=a("a"),fpt=o("FlaxWav2Vec2ForPreTraining"),gpt=o(" (Wav2Vec2 model)"),hpt=l(),iL=a("li"),X$e=a("strong"),upt=o("xlm-roberta"),ppt=o(" \u2014 "),nle=a("a"),_pt=o("FlaxXLMRobertaForMaskedLM"),bpt=o(" (XLM-RoBERTa model)"),vpt=l(),F(dL.$$.fragment),nto=l(),rf=a("h2"),cL=a("a"),z$e=a("span"),F(gP.$$.fragment),Fpt=l(),Q$e=a("span"),Tpt=o("FlaxAutoModelForMaskedLM"),sto=l(),Lr=a("div"),F(hP.$$.fragment),Mpt=l(),tf=a("p"),Ept=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sle=a("a"),Cpt=o("from_pretrained()"),wpt=o(" class method or the "),lle=a("a"),Apt=o("from_config()"),Lpt=o(` class
method.`),ypt=l(),uP=a("p"),xpt=o("This class cannot be instantiated directly using "),W$e=a("code"),$pt=o("__init__()"),kpt=o(" (throws an error)."),Spt=l(),fa=a("div"),F(pP.$$.fragment),Rpt=l(),U$e=a("p"),Ppt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Bpt=l(),af=a("p"),Ipt=o(`Note:
Loading a model from its configuration file does `),H$e=a("strong"),Npt=o("not"),qpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ile=a("a"),jpt=o("from_pretrained()"),Dpt=o(" to load the model weights."),Gpt=l(),F(mL.$$.fragment),Opt=l(),tt=a("div"),F(_P.$$.fragment),Vpt=l(),J$e=a("p"),Xpt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),zpt=l(),Hn=a("p"),Qpt=o("The model class to instantiate is selected based on the "),Y$e=a("code"),Wpt=o("model_type"),Upt=o(` property of the config object (either
passed as an argument or loaded from `),Z$e=a("code"),Hpt=o("pretrained_model_name_or_path"),Jpt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K$e=a("code"),Ypt=o("pretrained_model_name_or_path"),Zpt=o(":"),Kpt=l(),$e=a("ul"),fL=a("li"),eke=a("strong"),e_t=o("albert"),o_t=o(" \u2014 "),dle=a("a"),r_t=o("FlaxAlbertForMaskedLM"),t_t=o(" (ALBERT model)"),a_t=l(),gL=a("li"),oke=a("strong"),n_t=o("bart"),s_t=o(" \u2014 "),cle=a("a"),l_t=o("FlaxBartForConditionalGeneration"),i_t=o(" (BART model)"),d_t=l(),hL=a("li"),rke=a("strong"),c_t=o("bert"),m_t=o(" \u2014 "),mle=a("a"),f_t=o("FlaxBertForMaskedLM"),g_t=o(" (BERT model)"),h_t=l(),uL=a("li"),tke=a("strong"),u_t=o("big_bird"),p_t=o(" \u2014 "),fle=a("a"),__t=o("FlaxBigBirdForMaskedLM"),b_t=o(" (BigBird model)"),v_t=l(),pL=a("li"),ake=a("strong"),F_t=o("distilbert"),T_t=o(" \u2014 "),gle=a("a"),M_t=o("FlaxDistilBertForMaskedLM"),E_t=o(" (DistilBERT model)"),C_t=l(),_L=a("li"),nke=a("strong"),w_t=o("electra"),A_t=o(" \u2014 "),hle=a("a"),L_t=o("FlaxElectraForMaskedLM"),y_t=o(" (ELECTRA model)"),x_t=l(),bL=a("li"),ske=a("strong"),$_t=o("mbart"),k_t=o(" \u2014 "),ule=a("a"),S_t=o("FlaxMBartForConditionalGeneration"),R_t=o(" (mBART model)"),P_t=l(),vL=a("li"),lke=a("strong"),B_t=o("roberta"),I_t=o(" \u2014 "),ple=a("a"),N_t=o("FlaxRobertaForMaskedLM"),q_t=o(" (RoBERTa model)"),j_t=l(),FL=a("li"),ike=a("strong"),D_t=o("roformer"),G_t=o(" \u2014 "),_le=a("a"),O_t=o("FlaxRoFormerForMaskedLM"),V_t=o(" (RoFormer model)"),X_t=l(),TL=a("li"),dke=a("strong"),z_t=o("xlm-roberta"),Q_t=o(" \u2014 "),ble=a("a"),W_t=o("FlaxXLMRobertaForMaskedLM"),U_t=o(" (XLM-RoBERTa model)"),H_t=l(),F(ML.$$.fragment),lto=l(),nf=a("h2"),EL=a("a"),cke=a("span"),F(bP.$$.fragment),J_t=l(),mke=a("span"),Y_t=o("FlaxAutoModelForSeq2SeqLM"),ito=l(),yr=a("div"),F(vP.$$.fragment),Z_t=l(),sf=a("p"),K_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),vle=a("a"),e1t=o("from_pretrained()"),o1t=o(" class method or the "),Fle=a("a"),r1t=o("from_config()"),t1t=o(` class
method.`),a1t=l(),FP=a("p"),n1t=o("This class cannot be instantiated directly using "),fke=a("code"),s1t=o("__init__()"),l1t=o(" (throws an error)."),i1t=l(),ga=a("div"),F(TP.$$.fragment),d1t=l(),gke=a("p"),c1t=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),m1t=l(),lf=a("p"),f1t=o(`Note:
Loading a model from its configuration file does `),hke=a("strong"),g1t=o("not"),h1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tle=a("a"),u1t=o("from_pretrained()"),p1t=o(" to load the model weights."),_1t=l(),F(CL.$$.fragment),b1t=l(),at=a("div"),F(MP.$$.fragment),v1t=l(),uke=a("p"),F1t=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),T1t=l(),Jn=a("p"),M1t=o("The model class to instantiate is selected based on the "),pke=a("code"),E1t=o("model_type"),C1t=o(` property of the config object (either
passed as an argument or loaded from `),_ke=a("code"),w1t=o("pretrained_model_name_or_path"),A1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bke=a("code"),L1t=o("pretrained_model_name_or_path"),y1t=o(":"),x1t=l(),ke=a("ul"),wL=a("li"),vke=a("strong"),$1t=o("bart"),k1t=o(" \u2014 "),Mle=a("a"),S1t=o("FlaxBartForConditionalGeneration"),R1t=o(" (BART model)"),P1t=l(),AL=a("li"),Fke=a("strong"),B1t=o("blenderbot"),I1t=o(" \u2014 "),Ele=a("a"),N1t=o("FlaxBlenderbotForConditionalGeneration"),q1t=o(" (Blenderbot model)"),j1t=l(),LL=a("li"),Tke=a("strong"),D1t=o("blenderbot-small"),G1t=o(" \u2014 "),Cle=a("a"),O1t=o("FlaxBlenderbotSmallForConditionalGeneration"),V1t=o(" (BlenderbotSmall model)"),X1t=l(),yL=a("li"),Mke=a("strong"),z1t=o("encoder-decoder"),Q1t=o(" \u2014 "),wle=a("a"),W1t=o("FlaxEncoderDecoderModel"),U1t=o(" (Encoder decoder model)"),H1t=l(),xL=a("li"),Eke=a("strong"),J1t=o("longt5"),Y1t=o(" \u2014 "),Ale=a("a"),Z1t=o("FlaxLongT5ForConditionalGeneration"),K1t=o(" (LongT5 model)"),ebt=l(),$L=a("li"),Cke=a("strong"),obt=o("marian"),rbt=o(" \u2014 "),Lle=a("a"),tbt=o("FlaxMarianMTModel"),abt=o(" (Marian model)"),nbt=l(),kL=a("li"),wke=a("strong"),sbt=o("mbart"),lbt=o(" \u2014 "),yle=a("a"),ibt=o("FlaxMBartForConditionalGeneration"),dbt=o(" (mBART model)"),cbt=l(),SL=a("li"),Ake=a("strong"),mbt=o("mt5"),fbt=o(" \u2014 "),xle=a("a"),gbt=o("FlaxMT5ForConditionalGeneration"),hbt=o(" (MT5 model)"),ubt=l(),RL=a("li"),Lke=a("strong"),pbt=o("pegasus"),_bt=o(" \u2014 "),$le=a("a"),bbt=o("FlaxPegasusForConditionalGeneration"),vbt=o(" (Pegasus model)"),Fbt=l(),PL=a("li"),yke=a("strong"),Tbt=o("t5"),Mbt=o(" \u2014 "),kle=a("a"),Ebt=o("FlaxT5ForConditionalGeneration"),Cbt=o(" (T5 model)"),wbt=l(),F(BL.$$.fragment),dto=l(),df=a("h2"),IL=a("a"),xke=a("span"),F(EP.$$.fragment),Abt=l(),$ke=a("span"),Lbt=o("FlaxAutoModelForSequenceClassification"),cto=l(),xr=a("div"),F(CP.$$.fragment),ybt=l(),cf=a("p"),xbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Sle=a("a"),$bt=o("from_pretrained()"),kbt=o(" class method or the "),Rle=a("a"),Sbt=o("from_config()"),Rbt=o(` class
method.`),Pbt=l(),wP=a("p"),Bbt=o("This class cannot be instantiated directly using "),kke=a("code"),Ibt=o("__init__()"),Nbt=o(" (throws an error)."),qbt=l(),ha=a("div"),F(AP.$$.fragment),jbt=l(),Ske=a("p"),Dbt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Gbt=l(),mf=a("p"),Obt=o(`Note:
Loading a model from its configuration file does `),Rke=a("strong"),Vbt=o("not"),Xbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ple=a("a"),zbt=o("from_pretrained()"),Qbt=o(" to load the model weights."),Wbt=l(),F(NL.$$.fragment),Ubt=l(),nt=a("div"),F(LP.$$.fragment),Hbt=l(),Pke=a("p"),Jbt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ybt=l(),Yn=a("p"),Zbt=o("The model class to instantiate is selected based on the "),Bke=a("code"),Kbt=o("model_type"),e2t=o(` property of the config object (either
passed as an argument or loaded from `),Ike=a("code"),o2t=o("pretrained_model_name_or_path"),r2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nke=a("code"),t2t=o("pretrained_model_name_or_path"),a2t=o(":"),n2t=l(),Se=a("ul"),qL=a("li"),qke=a("strong"),s2t=o("albert"),l2t=o(" \u2014 "),Ble=a("a"),i2t=o("FlaxAlbertForSequenceClassification"),d2t=o(" (ALBERT model)"),c2t=l(),jL=a("li"),jke=a("strong"),m2t=o("bart"),f2t=o(" \u2014 "),Ile=a("a"),g2t=o("FlaxBartForSequenceClassification"),h2t=o(" (BART model)"),u2t=l(),DL=a("li"),Dke=a("strong"),p2t=o("bert"),_2t=o(" \u2014 "),Nle=a("a"),b2t=o("FlaxBertForSequenceClassification"),v2t=o(" (BERT model)"),F2t=l(),GL=a("li"),Gke=a("strong"),T2t=o("big_bird"),M2t=o(" \u2014 "),qle=a("a"),E2t=o("FlaxBigBirdForSequenceClassification"),C2t=o(" (BigBird model)"),w2t=l(),OL=a("li"),Oke=a("strong"),A2t=o("distilbert"),L2t=o(" \u2014 "),jle=a("a"),y2t=o("FlaxDistilBertForSequenceClassification"),x2t=o(" (DistilBERT model)"),$2t=l(),VL=a("li"),Vke=a("strong"),k2t=o("electra"),S2t=o(" \u2014 "),Dle=a("a"),R2t=o("FlaxElectraForSequenceClassification"),P2t=o(" (ELECTRA model)"),B2t=l(),XL=a("li"),Xke=a("strong"),I2t=o("mbart"),N2t=o(" \u2014 "),Gle=a("a"),q2t=o("FlaxMBartForSequenceClassification"),j2t=o(" (mBART model)"),D2t=l(),zL=a("li"),zke=a("strong"),G2t=o("roberta"),O2t=o(" \u2014 "),Ole=a("a"),V2t=o("FlaxRobertaForSequenceClassification"),X2t=o(" (RoBERTa model)"),z2t=l(),QL=a("li"),Qke=a("strong"),Q2t=o("roformer"),W2t=o(" \u2014 "),Vle=a("a"),U2t=o("FlaxRoFormerForSequenceClassification"),H2t=o(" (RoFormer model)"),J2t=l(),WL=a("li"),Wke=a("strong"),Y2t=o("xlm-roberta"),Z2t=o(" \u2014 "),Xle=a("a"),K2t=o("FlaxXLMRobertaForSequenceClassification"),evt=o(" (XLM-RoBERTa model)"),ovt=l(),F(UL.$$.fragment),mto=l(),ff=a("h2"),HL=a("a"),Uke=a("span"),F(yP.$$.fragment),rvt=l(),Hke=a("span"),tvt=o("FlaxAutoModelForQuestionAnswering"),fto=l(),$r=a("div"),F(xP.$$.fragment),avt=l(),gf=a("p"),nvt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),zle=a("a"),svt=o("from_pretrained()"),lvt=o(" class method or the "),Qle=a("a"),ivt=o("from_config()"),dvt=o(` class
method.`),cvt=l(),$P=a("p"),mvt=o("This class cannot be instantiated directly using "),Jke=a("code"),fvt=o("__init__()"),gvt=o(" (throws an error)."),hvt=l(),ua=a("div"),F(kP.$$.fragment),uvt=l(),Yke=a("p"),pvt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_vt=l(),hf=a("p"),bvt=o(`Note:
Loading a model from its configuration file does `),Zke=a("strong"),vvt=o("not"),Fvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wle=a("a"),Tvt=o("from_pretrained()"),Mvt=o(" to load the model weights."),Evt=l(),F(JL.$$.fragment),Cvt=l(),st=a("div"),F(SP.$$.fragment),wvt=l(),Kke=a("p"),Avt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Lvt=l(),Zn=a("p"),yvt=o("The model class to instantiate is selected based on the "),eSe=a("code"),xvt=o("model_type"),$vt=o(` property of the config object (either
passed as an argument or loaded from `),oSe=a("code"),kvt=o("pretrained_model_name_or_path"),Svt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rSe=a("code"),Rvt=o("pretrained_model_name_or_path"),Pvt=o(":"),Bvt=l(),Re=a("ul"),YL=a("li"),tSe=a("strong"),Ivt=o("albert"),Nvt=o(" \u2014 "),Ule=a("a"),qvt=o("FlaxAlbertForQuestionAnswering"),jvt=o(" (ALBERT model)"),Dvt=l(),ZL=a("li"),aSe=a("strong"),Gvt=o("bart"),Ovt=o(" \u2014 "),Hle=a("a"),Vvt=o("FlaxBartForQuestionAnswering"),Xvt=o(" (BART model)"),zvt=l(),KL=a("li"),nSe=a("strong"),Qvt=o("bert"),Wvt=o(" \u2014 "),Jle=a("a"),Uvt=o("FlaxBertForQuestionAnswering"),Hvt=o(" (BERT model)"),Jvt=l(),ey=a("li"),sSe=a("strong"),Yvt=o("big_bird"),Zvt=o(" \u2014 "),Yle=a("a"),Kvt=o("FlaxBigBirdForQuestionAnswering"),eFt=o(" (BigBird model)"),oFt=l(),oy=a("li"),lSe=a("strong"),rFt=o("distilbert"),tFt=o(" \u2014 "),Zle=a("a"),aFt=o("FlaxDistilBertForQuestionAnswering"),nFt=o(" (DistilBERT model)"),sFt=l(),ry=a("li"),iSe=a("strong"),lFt=o("electra"),iFt=o(" \u2014 "),Kle=a("a"),dFt=o("FlaxElectraForQuestionAnswering"),cFt=o(" (ELECTRA model)"),mFt=l(),ty=a("li"),dSe=a("strong"),fFt=o("mbart"),gFt=o(" \u2014 "),eie=a("a"),hFt=o("FlaxMBartForQuestionAnswering"),uFt=o(" (mBART model)"),pFt=l(),ay=a("li"),cSe=a("strong"),_Ft=o("roberta"),bFt=o(" \u2014 "),oie=a("a"),vFt=o("FlaxRobertaForQuestionAnswering"),FFt=o(" (RoBERTa model)"),TFt=l(),ny=a("li"),mSe=a("strong"),MFt=o("roformer"),EFt=o(" \u2014 "),rie=a("a"),CFt=o("FlaxRoFormerForQuestionAnswering"),wFt=o(" (RoFormer model)"),AFt=l(),sy=a("li"),fSe=a("strong"),LFt=o("xlm-roberta"),yFt=o(" \u2014 "),tie=a("a"),xFt=o("FlaxXLMRobertaForQuestionAnswering"),$Ft=o(" (XLM-RoBERTa model)"),kFt=l(),F(ly.$$.fragment),gto=l(),uf=a("h2"),iy=a("a"),gSe=a("span"),F(RP.$$.fragment),SFt=l(),hSe=a("span"),RFt=o("FlaxAutoModelForTokenClassification"),hto=l(),kr=a("div"),F(PP.$$.fragment),PFt=l(),pf=a("p"),BFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),aie=a("a"),IFt=o("from_pretrained()"),NFt=o(" class method or the "),nie=a("a"),qFt=o("from_config()"),jFt=o(` class
method.`),DFt=l(),BP=a("p"),GFt=o("This class cannot be instantiated directly using "),uSe=a("code"),OFt=o("__init__()"),VFt=o(" (throws an error)."),XFt=l(),pa=a("div"),F(IP.$$.fragment),zFt=l(),pSe=a("p"),QFt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),WFt=l(),_f=a("p"),UFt=o(`Note:
Loading a model from its configuration file does `),_Se=a("strong"),HFt=o("not"),JFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=a("a"),YFt=o("from_pretrained()"),ZFt=o(" to load the model weights."),KFt=l(),F(dy.$$.fragment),eTt=l(),lt=a("div"),F(NP.$$.fragment),oTt=l(),bSe=a("p"),rTt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),tTt=l(),Kn=a("p"),aTt=o("The model class to instantiate is selected based on the "),vSe=a("code"),nTt=o("model_type"),sTt=o(` property of the config object (either
passed as an argument or loaded from `),FSe=a("code"),lTt=o("pretrained_model_name_or_path"),iTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TSe=a("code"),dTt=o("pretrained_model_name_or_path"),cTt=o(":"),mTt=l(),Xe=a("ul"),cy=a("li"),MSe=a("strong"),fTt=o("albert"),gTt=o(" \u2014 "),lie=a("a"),hTt=o("FlaxAlbertForTokenClassification"),uTt=o(" (ALBERT model)"),pTt=l(),my=a("li"),ESe=a("strong"),_Tt=o("bert"),bTt=o(" \u2014 "),iie=a("a"),vTt=o("FlaxBertForTokenClassification"),FTt=o(" (BERT model)"),TTt=l(),fy=a("li"),CSe=a("strong"),MTt=o("big_bird"),ETt=o(" \u2014 "),die=a("a"),CTt=o("FlaxBigBirdForTokenClassification"),wTt=o(" (BigBird model)"),ATt=l(),gy=a("li"),wSe=a("strong"),LTt=o("distilbert"),yTt=o(" \u2014 "),cie=a("a"),xTt=o("FlaxDistilBertForTokenClassification"),$Tt=o(" (DistilBERT model)"),kTt=l(),hy=a("li"),ASe=a("strong"),STt=o("electra"),RTt=o(" \u2014 "),mie=a("a"),PTt=o("FlaxElectraForTokenClassification"),BTt=o(" (ELECTRA model)"),ITt=l(),uy=a("li"),LSe=a("strong"),NTt=o("roberta"),qTt=o(" \u2014 "),fie=a("a"),jTt=o("FlaxRobertaForTokenClassification"),DTt=o(" (RoBERTa model)"),GTt=l(),py=a("li"),ySe=a("strong"),OTt=o("roformer"),VTt=o(" \u2014 "),gie=a("a"),XTt=o("FlaxRoFormerForTokenClassification"),zTt=o(" (RoFormer model)"),QTt=l(),_y=a("li"),xSe=a("strong"),WTt=o("xlm-roberta"),UTt=o(" \u2014 "),hie=a("a"),HTt=o("FlaxXLMRobertaForTokenClassification"),JTt=o(" (XLM-RoBERTa model)"),YTt=l(),F(by.$$.fragment),uto=l(),bf=a("h2"),vy=a("a"),$Se=a("span"),F(qP.$$.fragment),ZTt=l(),kSe=a("span"),KTt=o("FlaxAutoModelForMultipleChoice"),pto=l(),Sr=a("div"),F(jP.$$.fragment),eMt=l(),vf=a("p"),oMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),uie=a("a"),rMt=o("from_pretrained()"),tMt=o(" class method or the "),pie=a("a"),aMt=o("from_config()"),nMt=o(` class
method.`),sMt=l(),DP=a("p"),lMt=o("This class cannot be instantiated directly using "),SSe=a("code"),iMt=o("__init__()"),dMt=o(" (throws an error)."),cMt=l(),_a=a("div"),F(GP.$$.fragment),mMt=l(),RSe=a("p"),fMt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),gMt=l(),Ff=a("p"),hMt=o(`Note:
Loading a model from its configuration file does `),PSe=a("strong"),uMt=o("not"),pMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=a("a"),_Mt=o("from_pretrained()"),bMt=o(" to load the model weights."),vMt=l(),F(Fy.$$.fragment),FMt=l(),it=a("div"),F(OP.$$.fragment),TMt=l(),BSe=a("p"),MMt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),EMt=l(),es=a("p"),CMt=o("The model class to instantiate is selected based on the "),ISe=a("code"),wMt=o("model_type"),AMt=o(` property of the config object (either
passed as an argument or loaded from `),NSe=a("code"),LMt=o("pretrained_model_name_or_path"),yMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qSe=a("code"),xMt=o("pretrained_model_name_or_path"),$Mt=o(":"),kMt=l(),ze=a("ul"),Ty=a("li"),jSe=a("strong"),SMt=o("albert"),RMt=o(" \u2014 "),bie=a("a"),PMt=o("FlaxAlbertForMultipleChoice"),BMt=o(" (ALBERT model)"),IMt=l(),My=a("li"),DSe=a("strong"),NMt=o("bert"),qMt=o(" \u2014 "),vie=a("a"),jMt=o("FlaxBertForMultipleChoice"),DMt=o(" (BERT model)"),GMt=l(),Ey=a("li"),GSe=a("strong"),OMt=o("big_bird"),VMt=o(" \u2014 "),Fie=a("a"),XMt=o("FlaxBigBirdForMultipleChoice"),zMt=o(" (BigBird model)"),QMt=l(),Cy=a("li"),OSe=a("strong"),WMt=o("distilbert"),UMt=o(" \u2014 "),Tie=a("a"),HMt=o("FlaxDistilBertForMultipleChoice"),JMt=o(" (DistilBERT model)"),YMt=l(),wy=a("li"),VSe=a("strong"),ZMt=o("electra"),KMt=o(" \u2014 "),Mie=a("a"),eEt=o("FlaxElectraForMultipleChoice"),oEt=o(" (ELECTRA model)"),rEt=l(),Ay=a("li"),XSe=a("strong"),tEt=o("roberta"),aEt=o(" \u2014 "),Eie=a("a"),nEt=o("FlaxRobertaForMultipleChoice"),sEt=o(" (RoBERTa model)"),lEt=l(),Ly=a("li"),zSe=a("strong"),iEt=o("roformer"),dEt=o(" \u2014 "),Cie=a("a"),cEt=o("FlaxRoFormerForMultipleChoice"),mEt=o(" (RoFormer model)"),fEt=l(),yy=a("li"),QSe=a("strong"),gEt=o("xlm-roberta"),hEt=o(" \u2014 "),wie=a("a"),uEt=o("FlaxXLMRobertaForMultipleChoice"),pEt=o(" (XLM-RoBERTa model)"),_Et=l(),F(xy.$$.fragment),_to=l(),Tf=a("h2"),$y=a("a"),WSe=a("span"),F(VP.$$.fragment),bEt=l(),USe=a("span"),vEt=o("FlaxAutoModelForNextSentencePrediction"),bto=l(),Rr=a("div"),F(XP.$$.fragment),FEt=l(),Mf=a("p"),TEt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Aie=a("a"),MEt=o("from_pretrained()"),EEt=o(" class method or the "),Lie=a("a"),CEt=o("from_config()"),wEt=o(` class
method.`),AEt=l(),zP=a("p"),LEt=o("This class cannot be instantiated directly using "),HSe=a("code"),yEt=o("__init__()"),xEt=o(" (throws an error)."),$Et=l(),ba=a("div"),F(QP.$$.fragment),kEt=l(),JSe=a("p"),SEt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),REt=l(),Ef=a("p"),PEt=o(`Note:
Loading a model from its configuration file does `),YSe=a("strong"),BEt=o("not"),IEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yie=a("a"),NEt=o("from_pretrained()"),qEt=o(" to load the model weights."),jEt=l(),F(ky.$$.fragment),DEt=l(),dt=a("div"),F(WP.$$.fragment),GEt=l(),ZSe=a("p"),OEt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),VEt=l(),os=a("p"),XEt=o("The model class to instantiate is selected based on the "),KSe=a("code"),zEt=o("model_type"),QEt=o(` property of the config object (either
passed as an argument or loaded from `),eRe=a("code"),WEt=o("pretrained_model_name_or_path"),UEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oRe=a("code"),HEt=o("pretrained_model_name_or_path"),JEt=o(":"),YEt=l(),rRe=a("ul"),Sy=a("li"),tRe=a("strong"),ZEt=o("bert"),KEt=o(" \u2014 "),xie=a("a"),e4t=o("FlaxBertForNextSentencePrediction"),o4t=o(" (BERT model)"),r4t=l(),F(Ry.$$.fragment),vto=l(),Cf=a("h2"),Py=a("a"),aRe=a("span"),F(UP.$$.fragment),t4t=l(),nRe=a("span"),a4t=o("FlaxAutoModelForImageClassification"),Fto=l(),Pr=a("div"),F(HP.$$.fragment),n4t=l(),wf=a("p"),s4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),$ie=a("a"),l4t=o("from_pretrained()"),i4t=o(" class method or the "),kie=a("a"),d4t=o("from_config()"),c4t=o(` class
method.`),m4t=l(),JP=a("p"),f4t=o("This class cannot be instantiated directly using "),sRe=a("code"),g4t=o("__init__()"),h4t=o(" (throws an error)."),u4t=l(),va=a("div"),F(YP.$$.fragment),p4t=l(),lRe=a("p"),_4t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),b4t=l(),Af=a("p"),v4t=o(`Note:
Loading a model from its configuration file does `),iRe=a("strong"),F4t=o("not"),T4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sie=a("a"),M4t=o("from_pretrained()"),E4t=o(" to load the model weights."),C4t=l(),F(By.$$.fragment),w4t=l(),ct=a("div"),F(ZP.$$.fragment),A4t=l(),dRe=a("p"),L4t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),y4t=l(),rs=a("p"),x4t=o("The model class to instantiate is selected based on the "),cRe=a("code"),$4t=o("model_type"),k4t=o(` property of the config object (either
passed as an argument or loaded from `),mRe=a("code"),S4t=o("pretrained_model_name_or_path"),R4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fRe=a("code"),P4t=o("pretrained_model_name_or_path"),B4t=o(":"),I4t=l(),KP=a("ul"),Iy=a("li"),gRe=a("strong"),N4t=o("beit"),q4t=o(" \u2014 "),Rie=a("a"),j4t=o("FlaxBeitForImageClassification"),D4t=o(" (BEiT model)"),G4t=l(),Ny=a("li"),hRe=a("strong"),O4t=o("vit"),V4t=o(" \u2014 "),Pie=a("a"),X4t=o("FlaxViTForImageClassification"),z4t=o(" (ViT model)"),Q4t=l(),F(qy.$$.fragment),Tto=l(),Lf=a("h2"),jy=a("a"),uRe=a("span"),F(eB.$$.fragment),W4t=l(),pRe=a("span"),U4t=o("FlaxAutoModelForVision2Seq"),Mto=l(),Br=a("div"),F(oB.$$.fragment),H4t=l(),yf=a("p"),J4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Bie=a("a"),Y4t=o("from_pretrained()"),Z4t=o(" class method or the "),Iie=a("a"),K4t=o("from_config()"),eCt=o(` class
method.`),oCt=l(),rB=a("p"),rCt=o("This class cannot be instantiated directly using "),_Re=a("code"),tCt=o("__init__()"),aCt=o(" (throws an error)."),nCt=l(),Fa=a("div"),F(tB.$$.fragment),sCt=l(),bRe=a("p"),lCt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),iCt=l(),xf=a("p"),dCt=o(`Note:
Loading a model from its configuration file does `),vRe=a("strong"),cCt=o("not"),mCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=a("a"),fCt=o("from_pretrained()"),gCt=o(" to load the model weights."),hCt=l(),F(Dy.$$.fragment),uCt=l(),mt=a("div"),F(aB.$$.fragment),pCt=l(),FRe=a("p"),_Ct=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),bCt=l(),ts=a("p"),vCt=o("The model class to instantiate is selected based on the "),TRe=a("code"),FCt=o("model_type"),TCt=o(` property of the config object (either
passed as an argument or loaded from `),MRe=a("code"),MCt=o("pretrained_model_name_or_path"),ECt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ERe=a("code"),CCt=o("pretrained_model_name_or_path"),wCt=o(":"),ACt=l(),CRe=a("ul"),Gy=a("li"),wRe=a("strong"),LCt=o("vision-encoder-decoder"),yCt=o(" \u2014 "),qie=a("a"),xCt=o("FlaxVisionEncoderDecoderModel"),$Ct=o(" (Vision Encoder decoder model)"),kCt=l(),F(Oy.$$.fragment),this.h()},l(m){const _=hFa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var nB=s(u);f=n(nB,"A",{id:!0,class:!0,href:!0});var ARe=s(f);p=n(ARe,"SPAN",{});var LRe=s(p);T(d.$$.fragment,LRe),LRe.forEach(t),ARe.forEach(t),h=i(nB),xo=n(nB,"SPAN",{});var yRe=s(xo);dd=r(yRe,"Auto Classes"),yRe.forEach(t),nB.forEach(t),Rf=i(m),bt=n(m,"P",{});var sB=s(bt);cd=r(sB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),md=n(sB,"CODE",{});var xRe=s(md);Mx=r(xRe,"from_pretrained()"),xRe.forEach(t),Pf=r(sB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),sB.forEach(t),Ve=i(m),He=n(m,"P",{});var as=s(He);fd=r(as,"Instantiating one of "),ns=n(as,"A",{href:!0});var $Re=s(ns);Ex=r($Re,"AutoConfig"),$Re.forEach(t),ss=r(as,", "),ls=n(as,"A",{href:!0});var kRe=s(ls);Cx=r(kRe,"AutoModel"),kRe.forEach(t),gd=r(as,`, and
`),is=n(as,"A",{href:!0});var SRe=s(is);wx=r(SRe,"AutoTokenizer"),SRe.forEach(t),hd=r(as," will directly create a class of the relevant architecture. For instance"),as.forEach(t),Bf=i(m),T(Ja.$$.fragment,m),Je=i(m),Ae=n(m,"P",{});var lB=s(Ae);$I=r(lB,"will create a model that is an instance of "),ud=n(lB,"A",{href:!0});var RRe=s(ud);kI=r(RRe,"BertModel"),RRe.forEach(t),SI=r(lB,"."),lB.forEach(t),$o=i(m),Ya=n(m,"P",{});var iB=s(Ya);RI=r(iB,"There is one class of "),If=n(iB,"CODE",{});var PRe=s(If);PI=r(PRe,"AutoModel"),PRe.forEach(t),Gno=r(iB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),iB.forEach(t),ioo=i(m),pd=n(m,"H2",{class:!0});var dB=s(pd);Nf=n(dB,"A",{id:!0,class:!0,href:!0});var BRe=s(Nf);zce=n(BRe,"SPAN",{});var IRe=s(zce);T(Ax.$$.fragment,IRe),IRe.forEach(t),BRe.forEach(t),Ono=i(dB),Qce=n(dB,"SPAN",{});var NRe=s(Qce);Vno=r(NRe,"Extending the Auto Classes"),NRe.forEach(t),dB.forEach(t),doo=i(m),ds=n(m,"P",{});var $f=s(ds);Xno=r($f,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Wce=n($f,"CODE",{});var qRe=s(Wce);zno=r(qRe,"NewModel"),qRe.forEach(t),Qno=r($f,", make sure you have a "),Uce=n($f,"CODE",{});var jRe=s(Uce);Wno=r(jRe,"NewModelConfig"),jRe.forEach(t),Uno=r($f,` then you can add those to the auto
classes like this:`),$f.forEach(t),coo=i(m),T(Lx.$$.fragment,m),moo=i(m),BI=n(m,"P",{});var DRe=s(BI);Hno=r(DRe,"You will then be able to use the auto classes like you would usually do!"),DRe.forEach(t),foo=i(m),T(qf.$$.fragment,m),goo=i(m),_d=n(m,"H2",{class:!0});var cB=s(_d);jf=n(cB,"A",{id:!0,class:!0,href:!0});var GRe=s(jf);Hce=n(GRe,"SPAN",{});var ORe=s(Hce);T(yx.$$.fragment,ORe),ORe.forEach(t),GRe.forEach(t),Jno=i(cB),Jce=n(cB,"SPAN",{});var VRe=s(Jce);Yno=r(VRe,"AutoConfig"),VRe.forEach(t),cB.forEach(t),hoo=i(m),ko=n(m,"DIV",{class:!0});var pt=s(ko);T(xx.$$.fragment,pt),Zno=i(pt),$x=n(pt,"P",{});var mB=s($x);Kno=r(mB,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),II=n(mB,"A",{href:!0});var XRe=s(II);eso=r(XRe,"from_pretrained()"),XRe.forEach(t),oso=r(mB," class method."),mB.forEach(t),rso=i(pt),kx=n(pt,"P",{});var fB=s(kx);tso=r(fB,"This class cannot be instantiated directly using "),Yce=n(fB,"CODE",{});var zRe=s(Yce);aso=r(zRe,"__init__()"),zRe.forEach(t),nso=r(fB," (throws an error)."),fB.forEach(t),sso=i(pt),Ir=n(pt,"DIV",{class:!0});var _t=s(Ir);T(Sx.$$.fragment,_t),lso=i(_t),Zce=n(_t,"P",{});var QRe=s(Zce);iso=r(QRe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),QRe.forEach(t),dso=i(_t),bd=n(_t,"P",{});var kf=s(bd);cso=r(kf,"The configuration class to instantiate is selected based on the "),Kce=n(kf,"CODE",{});var WRe=s(Kce);mso=r(WRe,"model_type"),WRe.forEach(t),fso=r(kf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),eme=n(kf,"CODE",{});var URe=s(eme);gso=r(URe,"pretrained_model_name_or_path"),URe.forEach(t),hso=r(kf,":"),kf.forEach(t),uso=i(_t),A=n(_t,"UL",{});var L=s(A);Df=n(L,"LI",{});var Vy=s(Df);ome=n(Vy,"STRONG",{});var HRe=s(ome);pso=r(HRe,"albert"),HRe.forEach(t),_so=r(Vy," \u2014 "),NI=n(Vy,"A",{href:!0});var JRe=s(NI);bso=r(JRe,"AlbertConfig"),JRe.forEach(t),vso=r(Vy," (ALBERT model)"),Vy.forEach(t),Fso=i(L),Gf=n(L,"LI",{});var Xy=s(Gf);rme=n(Xy,"STRONG",{});var YRe=s(rme);Tso=r(YRe,"bart"),YRe.forEach(t),Mso=r(Xy," \u2014 "),qI=n(Xy,"A",{href:!0});var ZRe=s(qI);Eso=r(ZRe,"BartConfig"),ZRe.forEach(t),Cso=r(Xy," (BART model)"),Xy.forEach(t),wso=i(L),Of=n(L,"LI",{});var zy=s(Of);tme=n(zy,"STRONG",{});var KRe=s(tme);Aso=r(KRe,"beit"),KRe.forEach(t),Lso=r(zy," \u2014 "),jI=n(zy,"A",{href:!0});var ePe=s(jI);yso=r(ePe,"BeitConfig"),ePe.forEach(t),xso=r(zy," (BEiT model)"),zy.forEach(t),$so=i(L),Vf=n(L,"LI",{});var Qy=s(Vf);ame=n(Qy,"STRONG",{});var oPe=s(ame);kso=r(oPe,"bert"),oPe.forEach(t),Sso=r(Qy," \u2014 "),DI=n(Qy,"A",{href:!0});var rPe=s(DI);Rso=r(rPe,"BertConfig"),rPe.forEach(t),Pso=r(Qy," (BERT model)"),Qy.forEach(t),Bso=i(L),Xf=n(L,"LI",{});var Wy=s(Xf);nme=n(Wy,"STRONG",{});var tPe=s(nme);Iso=r(tPe,"bert-generation"),tPe.forEach(t),Nso=r(Wy," \u2014 "),GI=n(Wy,"A",{href:!0});var aPe=s(GI);qso=r(aPe,"BertGenerationConfig"),aPe.forEach(t),jso=r(Wy," (Bert Generation model)"),Wy.forEach(t),Dso=i(L),zf=n(L,"LI",{});var Uy=s(zf);sme=n(Uy,"STRONG",{});var nPe=s(sme);Gso=r(nPe,"big_bird"),nPe.forEach(t),Oso=r(Uy," \u2014 "),OI=n(Uy,"A",{href:!0});var sPe=s(OI);Vso=r(sPe,"BigBirdConfig"),sPe.forEach(t),Xso=r(Uy," (BigBird model)"),Uy.forEach(t),zso=i(L),Qf=n(L,"LI",{});var Hy=s(Qf);lme=n(Hy,"STRONG",{});var lPe=s(lme);Qso=r(lPe,"bigbird_pegasus"),lPe.forEach(t),Wso=r(Hy," \u2014 "),VI=n(Hy,"A",{href:!0});var iPe=s(VI);Uso=r(iPe,"BigBirdPegasusConfig"),iPe.forEach(t),Hso=r(Hy," (BigBird-Pegasus model)"),Hy.forEach(t),Jso=i(L),Wf=n(L,"LI",{});var Jy=s(Wf);ime=n(Jy,"STRONG",{});var dPe=s(ime);Yso=r(dPe,"blenderbot"),dPe.forEach(t),Zso=r(Jy," \u2014 "),XI=n(Jy,"A",{href:!0});var cPe=s(XI);Kso=r(cPe,"BlenderbotConfig"),cPe.forEach(t),elo=r(Jy," (Blenderbot model)"),Jy.forEach(t),olo=i(L),Uf=n(L,"LI",{});var Yy=s(Uf);dme=n(Yy,"STRONG",{});var mPe=s(dme);rlo=r(mPe,"blenderbot-small"),mPe.forEach(t),tlo=r(Yy," \u2014 "),zI=n(Yy,"A",{href:!0});var fPe=s(zI);alo=r(fPe,"BlenderbotSmallConfig"),fPe.forEach(t),nlo=r(Yy," (BlenderbotSmall model)"),Yy.forEach(t),slo=i(L),Hf=n(L,"LI",{});var Zy=s(Hf);cme=n(Zy,"STRONG",{});var gPe=s(cme);llo=r(gPe,"bloom"),gPe.forEach(t),ilo=r(Zy," \u2014 "),QI=n(Zy,"A",{href:!0});var hPe=s(QI);dlo=r(hPe,"BloomConfig"),hPe.forEach(t),clo=r(Zy," (BLOOM model)"),Zy.forEach(t),mlo=i(L),Jf=n(L,"LI",{});var Ky=s(Jf);mme=n(Ky,"STRONG",{});var uPe=s(mme);flo=r(uPe,"camembert"),uPe.forEach(t),glo=r(Ky," \u2014 "),WI=n(Ky,"A",{href:!0});var pPe=s(WI);hlo=r(pPe,"CamembertConfig"),pPe.forEach(t),ulo=r(Ky," (CamemBERT model)"),Ky.forEach(t),plo=i(L),Yf=n(L,"LI",{});var e8=s(Yf);fme=n(e8,"STRONG",{});var _Pe=s(fme);_lo=r(_Pe,"canine"),_Pe.forEach(t),blo=r(e8," \u2014 "),UI=n(e8,"A",{href:!0});var bPe=s(UI);vlo=r(bPe,"CanineConfig"),bPe.forEach(t),Flo=r(e8," (CANINE model)"),e8.forEach(t),Tlo=i(L),Zf=n(L,"LI",{});var o8=s(Zf);gme=n(o8,"STRONG",{});var vPe=s(gme);Mlo=r(vPe,"clip"),vPe.forEach(t),Elo=r(o8," \u2014 "),HI=n(o8,"A",{href:!0});var FPe=s(HI);Clo=r(FPe,"CLIPConfig"),FPe.forEach(t),wlo=r(o8," (CLIP model)"),o8.forEach(t),Alo=i(L),Kf=n(L,"LI",{});var r8=s(Kf);hme=n(r8,"STRONG",{});var TPe=s(hme);Llo=r(TPe,"codegen"),TPe.forEach(t),ylo=r(r8," \u2014 "),JI=n(r8,"A",{href:!0});var MPe=s(JI);xlo=r(MPe,"CodeGenConfig"),MPe.forEach(t),$lo=r(r8," (CodeGen model)"),r8.forEach(t),klo=i(L),eg=n(L,"LI",{});var t8=s(eg);ume=n(t8,"STRONG",{});var EPe=s(ume);Slo=r(EPe,"conditional_detr"),EPe.forEach(t),Rlo=r(t8," \u2014 "),YI=n(t8,"A",{href:!0});var CPe=s(YI);Plo=r(CPe,"ConditionalDetrConfig"),CPe.forEach(t),Blo=r(t8," (Conditional DETR model)"),t8.forEach(t),Ilo=i(L),og=n(L,"LI",{});var a8=s(og);pme=n(a8,"STRONG",{});var wPe=s(pme);Nlo=r(wPe,"convbert"),wPe.forEach(t),qlo=r(a8," \u2014 "),ZI=n(a8,"A",{href:!0});var APe=s(ZI);jlo=r(APe,"ConvBertConfig"),APe.forEach(t),Dlo=r(a8," (ConvBERT model)"),a8.forEach(t),Glo=i(L),rg=n(L,"LI",{});var n8=s(rg);_me=n(n8,"STRONG",{});var LPe=s(_me);Olo=r(LPe,"convnext"),LPe.forEach(t),Vlo=r(n8," \u2014 "),KI=n(n8,"A",{href:!0});var yPe=s(KI);Xlo=r(yPe,"ConvNextConfig"),yPe.forEach(t),zlo=r(n8," (ConvNeXT model)"),n8.forEach(t),Qlo=i(L),tg=n(L,"LI",{});var s8=s(tg);bme=n(s8,"STRONG",{});var xPe=s(bme);Wlo=r(xPe,"ctrl"),xPe.forEach(t),Ulo=r(s8," \u2014 "),eN=n(s8,"A",{href:!0});var $Pe=s(eN);Hlo=r($Pe,"CTRLConfig"),$Pe.forEach(t),Jlo=r(s8," (CTRL model)"),s8.forEach(t),Ylo=i(L),ag=n(L,"LI",{});var l8=s(ag);vme=n(l8,"STRONG",{});var kPe=s(vme);Zlo=r(kPe,"cvt"),kPe.forEach(t),Klo=r(l8," \u2014 "),oN=n(l8,"A",{href:!0});var SPe=s(oN);eio=r(SPe,"CvtConfig"),SPe.forEach(t),oio=r(l8," (CvT model)"),l8.forEach(t),rio=i(L),ng=n(L,"LI",{});var i8=s(ng);Fme=n(i8,"STRONG",{});var RPe=s(Fme);tio=r(RPe,"data2vec-audio"),RPe.forEach(t),aio=r(i8," \u2014 "),rN=n(i8,"A",{href:!0});var PPe=s(rN);nio=r(PPe,"Data2VecAudioConfig"),PPe.forEach(t),sio=r(i8," (Data2VecAudio model)"),i8.forEach(t),lio=i(L),sg=n(L,"LI",{});var d8=s(sg);Tme=n(d8,"STRONG",{});var BPe=s(Tme);iio=r(BPe,"data2vec-text"),BPe.forEach(t),dio=r(d8," \u2014 "),tN=n(d8,"A",{href:!0});var IPe=s(tN);cio=r(IPe,"Data2VecTextConfig"),IPe.forEach(t),mio=r(d8," (Data2VecText model)"),d8.forEach(t),fio=i(L),lg=n(L,"LI",{});var c8=s(lg);Mme=n(c8,"STRONG",{});var NPe=s(Mme);gio=r(NPe,"data2vec-vision"),NPe.forEach(t),hio=r(c8," \u2014 "),aN=n(c8,"A",{href:!0});var qPe=s(aN);uio=r(qPe,"Data2VecVisionConfig"),qPe.forEach(t),pio=r(c8," (Data2VecVision model)"),c8.forEach(t),_io=i(L),ig=n(L,"LI",{});var m8=s(ig);Eme=n(m8,"STRONG",{});var jPe=s(Eme);bio=r(jPe,"deberta"),jPe.forEach(t),vio=r(m8," \u2014 "),nN=n(m8,"A",{href:!0});var DPe=s(nN);Fio=r(DPe,"DebertaConfig"),DPe.forEach(t),Tio=r(m8," (DeBERTa model)"),m8.forEach(t),Mio=i(L),dg=n(L,"LI",{});var f8=s(dg);Cme=n(f8,"STRONG",{});var GPe=s(Cme);Eio=r(GPe,"deberta-v2"),GPe.forEach(t),Cio=r(f8," \u2014 "),sN=n(f8,"A",{href:!0});var OPe=s(sN);wio=r(OPe,"DebertaV2Config"),OPe.forEach(t),Aio=r(f8," (DeBERTa-v2 model)"),f8.forEach(t),Lio=i(L),cg=n(L,"LI",{});var g8=s(cg);wme=n(g8,"STRONG",{});var VPe=s(wme);yio=r(VPe,"decision_transformer"),VPe.forEach(t),xio=r(g8," \u2014 "),lN=n(g8,"A",{href:!0});var XPe=s(lN);$io=r(XPe,"DecisionTransformerConfig"),XPe.forEach(t),kio=r(g8," (Decision Transformer model)"),g8.forEach(t),Sio=i(L),mg=n(L,"LI",{});var h8=s(mg);Ame=n(h8,"STRONG",{});var zPe=s(Ame);Rio=r(zPe,"deformable_detr"),zPe.forEach(t),Pio=r(h8," \u2014 "),iN=n(h8,"A",{href:!0});var QPe=s(iN);Bio=r(QPe,"DeformableDetrConfig"),QPe.forEach(t),Iio=r(h8," (Deformable DETR model)"),h8.forEach(t),Nio=i(L),fg=n(L,"LI",{});var u8=s(fg);Lme=n(u8,"STRONG",{});var WPe=s(Lme);qio=r(WPe,"deit"),WPe.forEach(t),jio=r(u8," \u2014 "),dN=n(u8,"A",{href:!0});var RCt=s(dN);Dio=r(RCt,"DeiTConfig"),RCt.forEach(t),Gio=r(u8," (DeiT model)"),u8.forEach(t),Oio=i(L),gg=n(L,"LI",{});var UPe=s(gg);yme=n(UPe,"STRONG",{});var PCt=s(yme);Vio=r(PCt,"detr"),PCt.forEach(t),Xio=r(UPe," \u2014 "),cN=n(UPe,"A",{href:!0});var BCt=s(cN);zio=r(BCt,"DetrConfig"),BCt.forEach(t),Qio=r(UPe," (DETR model)"),UPe.forEach(t),Wio=i(L),hg=n(L,"LI",{});var HPe=s(hg);xme=n(HPe,"STRONG",{});var ICt=s(xme);Uio=r(ICt,"distilbert"),ICt.forEach(t),Hio=r(HPe," \u2014 "),mN=n(HPe,"A",{href:!0});var NCt=s(mN);Jio=r(NCt,"DistilBertConfig"),NCt.forEach(t),Yio=r(HPe," (DistilBERT model)"),HPe.forEach(t),Zio=i(L),ug=n(L,"LI",{});var JPe=s(ug);$me=n(JPe,"STRONG",{});var qCt=s($me);Kio=r(qCt,"donut-swin"),qCt.forEach(t),edo=r(JPe," \u2014 "),fN=n(JPe,"A",{href:!0});var jCt=s(fN);odo=r(jCt,"DonutSwinConfig"),jCt.forEach(t),rdo=r(JPe," (DonutSwin model)"),JPe.forEach(t),tdo=i(L),pg=n(L,"LI",{});var YPe=s(pg);kme=n(YPe,"STRONG",{});var DCt=s(kme);ado=r(DCt,"dpr"),DCt.forEach(t),ndo=r(YPe," \u2014 "),gN=n(YPe,"A",{href:!0});var GCt=s(gN);sdo=r(GCt,"DPRConfig"),GCt.forEach(t),ldo=r(YPe," (DPR model)"),YPe.forEach(t),ido=i(L),_g=n(L,"LI",{});var ZPe=s(_g);Sme=n(ZPe,"STRONG",{});var OCt=s(Sme);ddo=r(OCt,"dpt"),OCt.forEach(t),cdo=r(ZPe," \u2014 "),hN=n(ZPe,"A",{href:!0});var VCt=s(hN);mdo=r(VCt,"DPTConfig"),VCt.forEach(t),fdo=r(ZPe," (DPT model)"),ZPe.forEach(t),gdo=i(L),bg=n(L,"LI",{});var KPe=s(bg);Rme=n(KPe,"STRONG",{});var XCt=s(Rme);hdo=r(XCt,"electra"),XCt.forEach(t),udo=r(KPe," \u2014 "),uN=n(KPe,"A",{href:!0});var zCt=s(uN);pdo=r(zCt,"ElectraConfig"),zCt.forEach(t),_do=r(KPe," (ELECTRA model)"),KPe.forEach(t),bdo=i(L),vg=n(L,"LI",{});var eBe=s(vg);Pme=n(eBe,"STRONG",{});var QCt=s(Pme);vdo=r(QCt,"encoder-decoder"),QCt.forEach(t),Fdo=r(eBe," \u2014 "),pN=n(eBe,"A",{href:!0});var WCt=s(pN);Tdo=r(WCt,"EncoderDecoderConfig"),WCt.forEach(t),Mdo=r(eBe," (Encoder decoder model)"),eBe.forEach(t),Edo=i(L),Fg=n(L,"LI",{});var oBe=s(Fg);Bme=n(oBe,"STRONG",{});var UCt=s(Bme);Cdo=r(UCt,"ernie"),UCt.forEach(t),wdo=r(oBe," \u2014 "),_N=n(oBe,"A",{href:!0});var HCt=s(_N);Ado=r(HCt,"ErnieConfig"),HCt.forEach(t),Ldo=r(oBe," (ERNIE model)"),oBe.forEach(t),ydo=i(L),Tg=n(L,"LI",{});var rBe=s(Tg);Ime=n(rBe,"STRONG",{});var JCt=s(Ime);xdo=r(JCt,"esm"),JCt.forEach(t),$do=r(rBe," \u2014 "),bN=n(rBe,"A",{href:!0});var YCt=s(bN);kdo=r(YCt,"EsmConfig"),YCt.forEach(t),Sdo=r(rBe," (ESM model)"),rBe.forEach(t),Rdo=i(L),Mg=n(L,"LI",{});var tBe=s(Mg);Nme=n(tBe,"STRONG",{});var ZCt=s(Nme);Pdo=r(ZCt,"flaubert"),ZCt.forEach(t),Bdo=r(tBe," \u2014 "),vN=n(tBe,"A",{href:!0});var KCt=s(vN);Ido=r(KCt,"FlaubertConfig"),KCt.forEach(t),Ndo=r(tBe," (FlauBERT model)"),tBe.forEach(t),qdo=i(L),Eg=n(L,"LI",{});var aBe=s(Eg);qme=n(aBe,"STRONG",{});var e3t=s(qme);jdo=r(e3t,"flava"),e3t.forEach(t),Ddo=r(aBe," \u2014 "),FN=n(aBe,"A",{href:!0});var o3t=s(FN);Gdo=r(o3t,"FlavaConfig"),o3t.forEach(t),Odo=r(aBe," (FLAVA model)"),aBe.forEach(t),Vdo=i(L),Cg=n(L,"LI",{});var nBe=s(Cg);jme=n(nBe,"STRONG",{});var r3t=s(jme);Xdo=r(r3t,"fnet"),r3t.forEach(t),zdo=r(nBe," \u2014 "),TN=n(nBe,"A",{href:!0});var t3t=s(TN);Qdo=r(t3t,"FNetConfig"),t3t.forEach(t),Wdo=r(nBe," (FNet model)"),nBe.forEach(t),Udo=i(L),wg=n(L,"LI",{});var sBe=s(wg);Dme=n(sBe,"STRONG",{});var a3t=s(Dme);Hdo=r(a3t,"fsmt"),a3t.forEach(t),Jdo=r(sBe," \u2014 "),MN=n(sBe,"A",{href:!0});var n3t=s(MN);Ydo=r(n3t,"FSMTConfig"),n3t.forEach(t),Zdo=r(sBe," (FairSeq Machine-Translation model)"),sBe.forEach(t),Kdo=i(L),Ag=n(L,"LI",{});var lBe=s(Ag);Gme=n(lBe,"STRONG",{});var s3t=s(Gme);eco=r(s3t,"funnel"),s3t.forEach(t),oco=r(lBe," \u2014 "),EN=n(lBe,"A",{href:!0});var l3t=s(EN);rco=r(l3t,"FunnelConfig"),l3t.forEach(t),tco=r(lBe," (Funnel Transformer model)"),lBe.forEach(t),aco=i(L),Lg=n(L,"LI",{});var iBe=s(Lg);Ome=n(iBe,"STRONG",{});var i3t=s(Ome);nco=r(i3t,"glpn"),i3t.forEach(t),sco=r(iBe," \u2014 "),CN=n(iBe,"A",{href:!0});var d3t=s(CN);lco=r(d3t,"GLPNConfig"),d3t.forEach(t),ico=r(iBe," (GLPN model)"),iBe.forEach(t),dco=i(L),yg=n(L,"LI",{});var dBe=s(yg);Vme=n(dBe,"STRONG",{});var c3t=s(Vme);cco=r(c3t,"gpt2"),c3t.forEach(t),mco=r(dBe," \u2014 "),wN=n(dBe,"A",{href:!0});var m3t=s(wN);fco=r(m3t,"GPT2Config"),m3t.forEach(t),gco=r(dBe," (OpenAI GPT-2 model)"),dBe.forEach(t),hco=i(L),xg=n(L,"LI",{});var cBe=s(xg);Xme=n(cBe,"STRONG",{});var f3t=s(Xme);uco=r(f3t,"gpt_neo"),f3t.forEach(t),pco=r(cBe," \u2014 "),AN=n(cBe,"A",{href:!0});var g3t=s(AN);_co=r(g3t,"GPTNeoConfig"),g3t.forEach(t),bco=r(cBe," (GPT Neo model)"),cBe.forEach(t),vco=i(L),$g=n(L,"LI",{});var mBe=s($g);zme=n(mBe,"STRONG",{});var h3t=s(zme);Fco=r(h3t,"gpt_neox"),h3t.forEach(t),Tco=r(mBe," \u2014 "),LN=n(mBe,"A",{href:!0});var u3t=s(LN);Mco=r(u3t,"GPTNeoXConfig"),u3t.forEach(t),Eco=r(mBe," (GPT NeoX model)"),mBe.forEach(t),Cco=i(L),kg=n(L,"LI",{});var fBe=s(kg);Qme=n(fBe,"STRONG",{});var p3t=s(Qme);wco=r(p3t,"gpt_neox_japanese"),p3t.forEach(t),Aco=r(fBe," \u2014 "),yN=n(fBe,"A",{href:!0});var _3t=s(yN);Lco=r(_3t,"GPTNeoXJapaneseConfig"),_3t.forEach(t),yco=r(fBe," (GPT NeoX Japanese model)"),fBe.forEach(t),xco=i(L),Sg=n(L,"LI",{});var gBe=s(Sg);Wme=n(gBe,"STRONG",{});var b3t=s(Wme);$co=r(b3t,"gptj"),b3t.forEach(t),kco=r(gBe," \u2014 "),xN=n(gBe,"A",{href:!0});var v3t=s(xN);Sco=r(v3t,"GPTJConfig"),v3t.forEach(t),Rco=r(gBe," (GPT-J model)"),gBe.forEach(t),Pco=i(L),Rg=n(L,"LI",{});var hBe=s(Rg);Ume=n(hBe,"STRONG",{});var F3t=s(Ume);Bco=r(F3t,"groupvit"),F3t.forEach(t),Ico=r(hBe," \u2014 "),$N=n(hBe,"A",{href:!0});var T3t=s($N);Nco=r(T3t,"GroupViTConfig"),T3t.forEach(t),qco=r(hBe," (GroupViT model)"),hBe.forEach(t),jco=i(L),Pg=n(L,"LI",{});var uBe=s(Pg);Hme=n(uBe,"STRONG",{});var M3t=s(Hme);Dco=r(M3t,"hubert"),M3t.forEach(t),Gco=r(uBe," \u2014 "),kN=n(uBe,"A",{href:!0});var E3t=s(kN);Oco=r(E3t,"HubertConfig"),E3t.forEach(t),Vco=r(uBe," (Hubert model)"),uBe.forEach(t),Xco=i(L),Bg=n(L,"LI",{});var pBe=s(Bg);Jme=n(pBe,"STRONG",{});var C3t=s(Jme);zco=r(C3t,"ibert"),C3t.forEach(t),Qco=r(pBe," \u2014 "),SN=n(pBe,"A",{href:!0});var w3t=s(SN);Wco=r(w3t,"IBertConfig"),w3t.forEach(t),Uco=r(pBe," (I-BERT model)"),pBe.forEach(t),Hco=i(L),Ig=n(L,"LI",{});var _Be=s(Ig);Yme=n(_Be,"STRONG",{});var A3t=s(Yme);Jco=r(A3t,"imagegpt"),A3t.forEach(t),Yco=r(_Be," \u2014 "),RN=n(_Be,"A",{href:!0});var L3t=s(RN);Zco=r(L3t,"ImageGPTConfig"),L3t.forEach(t),Kco=r(_Be," (ImageGPT model)"),_Be.forEach(t),emo=i(L),Ng=n(L,"LI",{});var bBe=s(Ng);Zme=n(bBe,"STRONG",{});var y3t=s(Zme);omo=r(y3t,"layoutlm"),y3t.forEach(t),rmo=r(bBe," \u2014 "),PN=n(bBe,"A",{href:!0});var x3t=s(PN);tmo=r(x3t,"LayoutLMConfig"),x3t.forEach(t),amo=r(bBe," (LayoutLM model)"),bBe.forEach(t),nmo=i(L),qg=n(L,"LI",{});var vBe=s(qg);Kme=n(vBe,"STRONG",{});var $3t=s(Kme);smo=r($3t,"layoutlmv2"),$3t.forEach(t),lmo=r(vBe," \u2014 "),BN=n(vBe,"A",{href:!0});var k3t=s(BN);imo=r(k3t,"LayoutLMv2Config"),k3t.forEach(t),dmo=r(vBe," (LayoutLMv2 model)"),vBe.forEach(t),cmo=i(L),jg=n(L,"LI",{});var FBe=s(jg);efe=n(FBe,"STRONG",{});var S3t=s(efe);mmo=r(S3t,"layoutlmv3"),S3t.forEach(t),fmo=r(FBe," \u2014 "),IN=n(FBe,"A",{href:!0});var R3t=s(IN);gmo=r(R3t,"LayoutLMv3Config"),R3t.forEach(t),hmo=r(FBe," (LayoutLMv3 model)"),FBe.forEach(t),umo=i(L),Dg=n(L,"LI",{});var TBe=s(Dg);ofe=n(TBe,"STRONG",{});var P3t=s(ofe);pmo=r(P3t,"led"),P3t.forEach(t),_mo=r(TBe," \u2014 "),NN=n(TBe,"A",{href:!0});var B3t=s(NN);bmo=r(B3t,"LEDConfig"),B3t.forEach(t),vmo=r(TBe," (LED model)"),TBe.forEach(t),Fmo=i(L),Gg=n(L,"LI",{});var MBe=s(Gg);rfe=n(MBe,"STRONG",{});var I3t=s(rfe);Tmo=r(I3t,"levit"),I3t.forEach(t),Mmo=r(MBe," \u2014 "),qN=n(MBe,"A",{href:!0});var N3t=s(qN);Emo=r(N3t,"LevitConfig"),N3t.forEach(t),Cmo=r(MBe," (LeViT model)"),MBe.forEach(t),wmo=i(L),Og=n(L,"LI",{});var EBe=s(Og);tfe=n(EBe,"STRONG",{});var q3t=s(tfe);Amo=r(q3t,"longformer"),q3t.forEach(t),Lmo=r(EBe," \u2014 "),jN=n(EBe,"A",{href:!0});var j3t=s(jN);ymo=r(j3t,"LongformerConfig"),j3t.forEach(t),xmo=r(EBe," (Longformer model)"),EBe.forEach(t),$mo=i(L),Vg=n(L,"LI",{});var CBe=s(Vg);afe=n(CBe,"STRONG",{});var D3t=s(afe);kmo=r(D3t,"longt5"),D3t.forEach(t),Smo=r(CBe," \u2014 "),DN=n(CBe,"A",{href:!0});var G3t=s(DN);Rmo=r(G3t,"LongT5Config"),G3t.forEach(t),Pmo=r(CBe," (LongT5 model)"),CBe.forEach(t),Bmo=i(L),Xg=n(L,"LI",{});var wBe=s(Xg);nfe=n(wBe,"STRONG",{});var O3t=s(nfe);Imo=r(O3t,"luke"),O3t.forEach(t),Nmo=r(wBe," \u2014 "),GN=n(wBe,"A",{href:!0});var V3t=s(GN);qmo=r(V3t,"LukeConfig"),V3t.forEach(t),jmo=r(wBe," (LUKE model)"),wBe.forEach(t),Dmo=i(L),zg=n(L,"LI",{});var ABe=s(zg);sfe=n(ABe,"STRONG",{});var X3t=s(sfe);Gmo=r(X3t,"lxmert"),X3t.forEach(t),Omo=r(ABe," \u2014 "),ON=n(ABe,"A",{href:!0});var z3t=s(ON);Vmo=r(z3t,"LxmertConfig"),z3t.forEach(t),Xmo=r(ABe," (LXMERT model)"),ABe.forEach(t),zmo=i(L),Qg=n(L,"LI",{});var LBe=s(Qg);lfe=n(LBe,"STRONG",{});var Q3t=s(lfe);Qmo=r(Q3t,"m2m_100"),Q3t.forEach(t),Wmo=r(LBe," \u2014 "),VN=n(LBe,"A",{href:!0});var W3t=s(VN);Umo=r(W3t,"M2M100Config"),W3t.forEach(t),Hmo=r(LBe," (M2M100 model)"),LBe.forEach(t),Jmo=i(L),Wg=n(L,"LI",{});var yBe=s(Wg);ife=n(yBe,"STRONG",{});var U3t=s(ife);Ymo=r(U3t,"marian"),U3t.forEach(t),Zmo=r(yBe," \u2014 "),XN=n(yBe,"A",{href:!0});var H3t=s(XN);Kmo=r(H3t,"MarianConfig"),H3t.forEach(t),efo=r(yBe," (Marian model)"),yBe.forEach(t),ofo=i(L),Ug=n(L,"LI",{});var xBe=s(Ug);dfe=n(xBe,"STRONG",{});var J3t=s(dfe);rfo=r(J3t,"markuplm"),J3t.forEach(t),tfo=r(xBe," \u2014 "),zN=n(xBe,"A",{href:!0});var Y3t=s(zN);afo=r(Y3t,"MarkupLMConfig"),Y3t.forEach(t),nfo=r(xBe," (MarkupLM model)"),xBe.forEach(t),sfo=i(L),Hg=n(L,"LI",{});var $Be=s(Hg);cfe=n($Be,"STRONG",{});var Z3t=s(cfe);lfo=r(Z3t,"maskformer"),Z3t.forEach(t),ifo=r($Be," \u2014 "),QN=n($Be,"A",{href:!0});var K3t=s(QN);dfo=r(K3t,"MaskFormerConfig"),K3t.forEach(t),cfo=r($Be," (MaskFormer model)"),$Be.forEach(t),mfo=i(L),Jg=n(L,"LI",{});var kBe=s(Jg);mfe=n(kBe,"STRONG",{});var e5t=s(mfe);ffo=r(e5t,"mbart"),e5t.forEach(t),gfo=r(kBe," \u2014 "),WN=n(kBe,"A",{href:!0});var o5t=s(WN);hfo=r(o5t,"MBartConfig"),o5t.forEach(t),ufo=r(kBe," (mBART model)"),kBe.forEach(t),pfo=i(L),Yg=n(L,"LI",{});var SBe=s(Yg);ffe=n(SBe,"STRONG",{});var r5t=s(ffe);_fo=r(r5t,"mctct"),r5t.forEach(t),bfo=r(SBe," \u2014 "),UN=n(SBe,"A",{href:!0});var t5t=s(UN);vfo=r(t5t,"MCTCTConfig"),t5t.forEach(t),Ffo=r(SBe," (M-CTC-T model)"),SBe.forEach(t),Tfo=i(L),Zg=n(L,"LI",{});var RBe=s(Zg);gfe=n(RBe,"STRONG",{});var a5t=s(gfe);Mfo=r(a5t,"megatron-bert"),a5t.forEach(t),Efo=r(RBe," \u2014 "),HN=n(RBe,"A",{href:!0});var n5t=s(HN);Cfo=r(n5t,"MegatronBertConfig"),n5t.forEach(t),wfo=r(RBe," (Megatron-BERT model)"),RBe.forEach(t),Afo=i(L),Kg=n(L,"LI",{});var PBe=s(Kg);hfe=n(PBe,"STRONG",{});var s5t=s(hfe);Lfo=r(s5t,"mobilebert"),s5t.forEach(t),yfo=r(PBe," \u2014 "),JN=n(PBe,"A",{href:!0});var l5t=s(JN);xfo=r(l5t,"MobileBertConfig"),l5t.forEach(t),$fo=r(PBe," (MobileBERT model)"),PBe.forEach(t),kfo=i(L),eh=n(L,"LI",{});var BBe=s(eh);ufe=n(BBe,"STRONG",{});var i5t=s(ufe);Sfo=r(i5t,"mobilevit"),i5t.forEach(t),Rfo=r(BBe," \u2014 "),YN=n(BBe,"A",{href:!0});var d5t=s(YN);Pfo=r(d5t,"MobileViTConfig"),d5t.forEach(t),Bfo=r(BBe," (MobileViT model)"),BBe.forEach(t),Ifo=i(L),oh=n(L,"LI",{});var IBe=s(oh);pfe=n(IBe,"STRONG",{});var c5t=s(pfe);Nfo=r(c5t,"mpnet"),c5t.forEach(t),qfo=r(IBe," \u2014 "),ZN=n(IBe,"A",{href:!0});var m5t=s(ZN);jfo=r(m5t,"MPNetConfig"),m5t.forEach(t),Dfo=r(IBe," (MPNet model)"),IBe.forEach(t),Gfo=i(L),rh=n(L,"LI",{});var NBe=s(rh);_fe=n(NBe,"STRONG",{});var f5t=s(_fe);Ofo=r(f5t,"mt5"),f5t.forEach(t),Vfo=r(NBe," \u2014 "),KN=n(NBe,"A",{href:!0});var g5t=s(KN);Xfo=r(g5t,"MT5Config"),g5t.forEach(t),zfo=r(NBe," (MT5 model)"),NBe.forEach(t),Qfo=i(L),th=n(L,"LI",{});var qBe=s(th);bfe=n(qBe,"STRONG",{});var h5t=s(bfe);Wfo=r(h5t,"mvp"),h5t.forEach(t),Ufo=r(qBe," \u2014 "),eq=n(qBe,"A",{href:!0});var u5t=s(eq);Hfo=r(u5t,"MvpConfig"),u5t.forEach(t),Jfo=r(qBe," (MVP model)"),qBe.forEach(t),Yfo=i(L),ah=n(L,"LI",{});var jBe=s(ah);vfe=n(jBe,"STRONG",{});var p5t=s(vfe);Zfo=r(p5t,"nezha"),p5t.forEach(t),Kfo=r(jBe," \u2014 "),oq=n(jBe,"A",{href:!0});var _5t=s(oq);ego=r(_5t,"NezhaConfig"),_5t.forEach(t),ogo=r(jBe," (Nezha model)"),jBe.forEach(t),rgo=i(L),nh=n(L,"LI",{});var DBe=s(nh);Ffe=n(DBe,"STRONG",{});var b5t=s(Ffe);tgo=r(b5t,"nystromformer"),b5t.forEach(t),ago=r(DBe," \u2014 "),rq=n(DBe,"A",{href:!0});var v5t=s(rq);ngo=r(v5t,"NystromformerConfig"),v5t.forEach(t),sgo=r(DBe," (Nystr\xF6mformer model)"),DBe.forEach(t),lgo=i(L),sh=n(L,"LI",{});var GBe=s(sh);Tfe=n(GBe,"STRONG",{});var F5t=s(Tfe);igo=r(F5t,"openai-gpt"),F5t.forEach(t),dgo=r(GBe," \u2014 "),tq=n(GBe,"A",{href:!0});var T5t=s(tq);cgo=r(T5t,"OpenAIGPTConfig"),T5t.forEach(t),mgo=r(GBe," (OpenAI GPT model)"),GBe.forEach(t),fgo=i(L),lh=n(L,"LI",{});var OBe=s(lh);Mfe=n(OBe,"STRONG",{});var M5t=s(Mfe);ggo=r(M5t,"opt"),M5t.forEach(t),hgo=r(OBe," \u2014 "),aq=n(OBe,"A",{href:!0});var E5t=s(aq);ugo=r(E5t,"OPTConfig"),E5t.forEach(t),pgo=r(OBe," (OPT model)"),OBe.forEach(t),_go=i(L),ih=n(L,"LI",{});var VBe=s(ih);Efe=n(VBe,"STRONG",{});var C5t=s(Efe);bgo=r(C5t,"owlvit"),C5t.forEach(t),vgo=r(VBe," \u2014 "),nq=n(VBe,"A",{href:!0});var w5t=s(nq);Fgo=r(w5t,"OwlViTConfig"),w5t.forEach(t),Tgo=r(VBe," (OWL-ViT model)"),VBe.forEach(t),Mgo=i(L),dh=n(L,"LI",{});var XBe=s(dh);Cfe=n(XBe,"STRONG",{});var A5t=s(Cfe);Ego=r(A5t,"pegasus"),A5t.forEach(t),Cgo=r(XBe," \u2014 "),sq=n(XBe,"A",{href:!0});var L5t=s(sq);wgo=r(L5t,"PegasusConfig"),L5t.forEach(t),Ago=r(XBe," (Pegasus model)"),XBe.forEach(t),Lgo=i(L),ch=n(L,"LI",{});var zBe=s(ch);wfe=n(zBe,"STRONG",{});var y5t=s(wfe);ygo=r(y5t,"pegasus_x"),y5t.forEach(t),xgo=r(zBe," \u2014 "),lq=n(zBe,"A",{href:!0});var x5t=s(lq);$go=r(x5t,"PegasusXConfig"),x5t.forEach(t),kgo=r(zBe," (PEGASUS-X model)"),zBe.forEach(t),Sgo=i(L),mh=n(L,"LI",{});var QBe=s(mh);Afe=n(QBe,"STRONG",{});var $5t=s(Afe);Rgo=r($5t,"perceiver"),$5t.forEach(t),Pgo=r(QBe," \u2014 "),iq=n(QBe,"A",{href:!0});var k5t=s(iq);Bgo=r(k5t,"PerceiverConfig"),k5t.forEach(t),Igo=r(QBe," (Perceiver model)"),QBe.forEach(t),Ngo=i(L),fh=n(L,"LI",{});var WBe=s(fh);Lfe=n(WBe,"STRONG",{});var S5t=s(Lfe);qgo=r(S5t,"plbart"),S5t.forEach(t),jgo=r(WBe," \u2014 "),dq=n(WBe,"A",{href:!0});var R5t=s(dq);Dgo=r(R5t,"PLBartConfig"),R5t.forEach(t),Ggo=r(WBe," (PLBart model)"),WBe.forEach(t),Ogo=i(L),gh=n(L,"LI",{});var UBe=s(gh);yfe=n(UBe,"STRONG",{});var P5t=s(yfe);Vgo=r(P5t,"poolformer"),P5t.forEach(t),Xgo=r(UBe," \u2014 "),cq=n(UBe,"A",{href:!0});var B5t=s(cq);zgo=r(B5t,"PoolFormerConfig"),B5t.forEach(t),Qgo=r(UBe," (PoolFormer model)"),UBe.forEach(t),Wgo=i(L),hh=n(L,"LI",{});var HBe=s(hh);xfe=n(HBe,"STRONG",{});var I5t=s(xfe);Ugo=r(I5t,"prophetnet"),I5t.forEach(t),Hgo=r(HBe," \u2014 "),mq=n(HBe,"A",{href:!0});var N5t=s(mq);Jgo=r(N5t,"ProphetNetConfig"),N5t.forEach(t),Ygo=r(HBe," (ProphetNet model)"),HBe.forEach(t),Zgo=i(L),uh=n(L,"LI",{});var JBe=s(uh);$fe=n(JBe,"STRONG",{});var q5t=s($fe);Kgo=r(q5t,"qdqbert"),q5t.forEach(t),eho=r(JBe," \u2014 "),fq=n(JBe,"A",{href:!0});var j5t=s(fq);oho=r(j5t,"QDQBertConfig"),j5t.forEach(t),rho=r(JBe," (QDQBert model)"),JBe.forEach(t),tho=i(L),ph=n(L,"LI",{});var YBe=s(ph);kfe=n(YBe,"STRONG",{});var D5t=s(kfe);aho=r(D5t,"rag"),D5t.forEach(t),nho=r(YBe," \u2014 "),gq=n(YBe,"A",{href:!0});var G5t=s(gq);sho=r(G5t,"RagConfig"),G5t.forEach(t),lho=r(YBe," (RAG model)"),YBe.forEach(t),iho=i(L),_h=n(L,"LI",{});var ZBe=s(_h);Sfe=n(ZBe,"STRONG",{});var O5t=s(Sfe);dho=r(O5t,"realm"),O5t.forEach(t),cho=r(ZBe," \u2014 "),hq=n(ZBe,"A",{href:!0});var V5t=s(hq);mho=r(V5t,"RealmConfig"),V5t.forEach(t),fho=r(ZBe," (REALM model)"),ZBe.forEach(t),gho=i(L),bh=n(L,"LI",{});var KBe=s(bh);Rfe=n(KBe,"STRONG",{});var X5t=s(Rfe);hho=r(X5t,"reformer"),X5t.forEach(t),uho=r(KBe," \u2014 "),uq=n(KBe,"A",{href:!0});var z5t=s(uq);pho=r(z5t,"ReformerConfig"),z5t.forEach(t),_ho=r(KBe," (Reformer model)"),KBe.forEach(t),bho=i(L),vh=n(L,"LI",{});var eIe=s(vh);Pfe=n(eIe,"STRONG",{});var Q5t=s(Pfe);vho=r(Q5t,"regnet"),Q5t.forEach(t),Fho=r(eIe," \u2014 "),pq=n(eIe,"A",{href:!0});var W5t=s(pq);Tho=r(W5t,"RegNetConfig"),W5t.forEach(t),Mho=r(eIe," (RegNet model)"),eIe.forEach(t),Eho=i(L),Fh=n(L,"LI",{});var oIe=s(Fh);Bfe=n(oIe,"STRONG",{});var U5t=s(Bfe);Cho=r(U5t,"rembert"),U5t.forEach(t),who=r(oIe," \u2014 "),_q=n(oIe,"A",{href:!0});var H5t=s(_q);Aho=r(H5t,"RemBertConfig"),H5t.forEach(t),Lho=r(oIe," (RemBERT model)"),oIe.forEach(t),yho=i(L),Th=n(L,"LI",{});var rIe=s(Th);Ife=n(rIe,"STRONG",{});var J5t=s(Ife);xho=r(J5t,"resnet"),J5t.forEach(t),$ho=r(rIe," \u2014 "),bq=n(rIe,"A",{href:!0});var Y5t=s(bq);kho=r(Y5t,"ResNetConfig"),Y5t.forEach(t),Sho=r(rIe," (ResNet model)"),rIe.forEach(t),Rho=i(L),Mh=n(L,"LI",{});var tIe=s(Mh);Nfe=n(tIe,"STRONG",{});var Z5t=s(Nfe);Pho=r(Z5t,"retribert"),Z5t.forEach(t),Bho=r(tIe," \u2014 "),vq=n(tIe,"A",{href:!0});var K5t=s(vq);Iho=r(K5t,"RetriBertConfig"),K5t.forEach(t),Nho=r(tIe," (RetriBERT model)"),tIe.forEach(t),qho=i(L),Eh=n(L,"LI",{});var aIe=s(Eh);qfe=n(aIe,"STRONG",{});var e0t=s(qfe);jho=r(e0t,"roberta"),e0t.forEach(t),Dho=r(aIe," \u2014 "),Fq=n(aIe,"A",{href:!0});var o0t=s(Fq);Gho=r(o0t,"RobertaConfig"),o0t.forEach(t),Oho=r(aIe," (RoBERTa model)"),aIe.forEach(t),Vho=i(L),Ch=n(L,"LI",{});var nIe=s(Ch);jfe=n(nIe,"STRONG",{});var r0t=s(jfe);Xho=r(r0t,"roformer"),r0t.forEach(t),zho=r(nIe," \u2014 "),Tq=n(nIe,"A",{href:!0});var t0t=s(Tq);Qho=r(t0t,"RoFormerConfig"),t0t.forEach(t),Who=r(nIe," (RoFormer model)"),nIe.forEach(t),Uho=i(L),wh=n(L,"LI",{});var sIe=s(wh);Dfe=n(sIe,"STRONG",{});var a0t=s(Dfe);Hho=r(a0t,"segformer"),a0t.forEach(t),Jho=r(sIe," \u2014 "),Mq=n(sIe,"A",{href:!0});var n0t=s(Mq);Yho=r(n0t,"SegformerConfig"),n0t.forEach(t),Zho=r(sIe," (SegFormer model)"),sIe.forEach(t),Kho=i(L),Ah=n(L,"LI",{});var lIe=s(Ah);Gfe=n(lIe,"STRONG",{});var s0t=s(Gfe);euo=r(s0t,"sew"),s0t.forEach(t),ouo=r(lIe," \u2014 "),Eq=n(lIe,"A",{href:!0});var l0t=s(Eq);ruo=r(l0t,"SEWConfig"),l0t.forEach(t),tuo=r(lIe," (SEW model)"),lIe.forEach(t),auo=i(L),Lh=n(L,"LI",{});var iIe=s(Lh);Ofe=n(iIe,"STRONG",{});var i0t=s(Ofe);nuo=r(i0t,"sew-d"),i0t.forEach(t),suo=r(iIe," \u2014 "),Cq=n(iIe,"A",{href:!0});var d0t=s(Cq);luo=r(d0t,"SEWDConfig"),d0t.forEach(t),iuo=r(iIe," (SEW-D model)"),iIe.forEach(t),duo=i(L),yh=n(L,"LI",{});var dIe=s(yh);Vfe=n(dIe,"STRONG",{});var c0t=s(Vfe);cuo=r(c0t,"speech-encoder-decoder"),c0t.forEach(t),muo=r(dIe," \u2014 "),wq=n(dIe,"A",{href:!0});var m0t=s(wq);fuo=r(m0t,"SpeechEncoderDecoderConfig"),m0t.forEach(t),guo=r(dIe," (Speech Encoder decoder model)"),dIe.forEach(t),huo=i(L),xh=n(L,"LI",{});var cIe=s(xh);Xfe=n(cIe,"STRONG",{});var f0t=s(Xfe);uuo=r(f0t,"speech_to_text"),f0t.forEach(t),puo=r(cIe," \u2014 "),Aq=n(cIe,"A",{href:!0});var g0t=s(Aq);_uo=r(g0t,"Speech2TextConfig"),g0t.forEach(t),buo=r(cIe," (Speech2Text model)"),cIe.forEach(t),vuo=i(L),$h=n(L,"LI",{});var mIe=s($h);zfe=n(mIe,"STRONG",{});var h0t=s(zfe);Fuo=r(h0t,"speech_to_text_2"),h0t.forEach(t),Tuo=r(mIe," \u2014 "),Lq=n(mIe,"A",{href:!0});var u0t=s(Lq);Muo=r(u0t,"Speech2Text2Config"),u0t.forEach(t),Euo=r(mIe," (Speech2Text2 model)"),mIe.forEach(t),Cuo=i(L),kh=n(L,"LI",{});var fIe=s(kh);Qfe=n(fIe,"STRONG",{});var p0t=s(Qfe);wuo=r(p0t,"splinter"),p0t.forEach(t),Auo=r(fIe," \u2014 "),yq=n(fIe,"A",{href:!0});var _0t=s(yq);Luo=r(_0t,"SplinterConfig"),_0t.forEach(t),yuo=r(fIe," (Splinter model)"),fIe.forEach(t),xuo=i(L),Sh=n(L,"LI",{});var gIe=s(Sh);Wfe=n(gIe,"STRONG",{});var b0t=s(Wfe);$uo=r(b0t,"squeezebert"),b0t.forEach(t),kuo=r(gIe," \u2014 "),xq=n(gIe,"A",{href:!0});var v0t=s(xq);Suo=r(v0t,"SqueezeBertConfig"),v0t.forEach(t),Ruo=r(gIe," (SqueezeBERT model)"),gIe.forEach(t),Puo=i(L),Rh=n(L,"LI",{});var hIe=s(Rh);Ufe=n(hIe,"STRONG",{});var F0t=s(Ufe);Buo=r(F0t,"swin"),F0t.forEach(t),Iuo=r(hIe," \u2014 "),$q=n(hIe,"A",{href:!0});var T0t=s($q);Nuo=r(T0t,"SwinConfig"),T0t.forEach(t),quo=r(hIe," (Swin Transformer model)"),hIe.forEach(t),juo=i(L),Ph=n(L,"LI",{});var uIe=s(Ph);Hfe=n(uIe,"STRONG",{});var M0t=s(Hfe);Duo=r(M0t,"swinv2"),M0t.forEach(t),Guo=r(uIe," \u2014 "),kq=n(uIe,"A",{href:!0});var E0t=s(kq);Ouo=r(E0t,"Swinv2Config"),E0t.forEach(t),Vuo=r(uIe," (Swin Transformer V2 model)"),uIe.forEach(t),Xuo=i(L),Bh=n(L,"LI",{});var pIe=s(Bh);Jfe=n(pIe,"STRONG",{});var C0t=s(Jfe);zuo=r(C0t,"t5"),C0t.forEach(t),Quo=r(pIe," \u2014 "),Sq=n(pIe,"A",{href:!0});var w0t=s(Sq);Wuo=r(w0t,"T5Config"),w0t.forEach(t),Uuo=r(pIe," (T5 model)"),pIe.forEach(t),Huo=i(L),Ih=n(L,"LI",{});var _Ie=s(Ih);Yfe=n(_Ie,"STRONG",{});var A0t=s(Yfe);Juo=r(A0t,"tapas"),A0t.forEach(t),Yuo=r(_Ie," \u2014 "),Rq=n(_Ie,"A",{href:!0});var L0t=s(Rq);Zuo=r(L0t,"TapasConfig"),L0t.forEach(t),Kuo=r(_Ie," (TAPAS model)"),_Ie.forEach(t),epo=i(L),Nh=n(L,"LI",{});var bIe=s(Nh);Zfe=n(bIe,"STRONG",{});var y0t=s(Zfe);opo=r(y0t,"time_series_transformer"),y0t.forEach(t),rpo=r(bIe," \u2014 "),Pq=n(bIe,"A",{href:!0});var x0t=s(Pq);tpo=r(x0t,"TimeSeriesTransformerConfig"),x0t.forEach(t),apo=r(bIe," (Time Series Transformer model)"),bIe.forEach(t),npo=i(L),qh=n(L,"LI",{});var vIe=s(qh);Kfe=n(vIe,"STRONG",{});var $0t=s(Kfe);spo=r($0t,"trajectory_transformer"),$0t.forEach(t),lpo=r(vIe," \u2014 "),Bq=n(vIe,"A",{href:!0});var k0t=s(Bq);ipo=r(k0t,"TrajectoryTransformerConfig"),k0t.forEach(t),dpo=r(vIe," (Trajectory Transformer model)"),vIe.forEach(t),cpo=i(L),jh=n(L,"LI",{});var FIe=s(jh);ege=n(FIe,"STRONG",{});var S0t=s(ege);mpo=r(S0t,"transfo-xl"),S0t.forEach(t),fpo=r(FIe," \u2014 "),Iq=n(FIe,"A",{href:!0});var R0t=s(Iq);gpo=r(R0t,"TransfoXLConfig"),R0t.forEach(t),hpo=r(FIe," (Transformer-XL model)"),FIe.forEach(t),upo=i(L),Dh=n(L,"LI",{});var TIe=s(Dh);oge=n(TIe,"STRONG",{});var P0t=s(oge);ppo=r(P0t,"trocr"),P0t.forEach(t),_po=r(TIe," \u2014 "),Nq=n(TIe,"A",{href:!0});var B0t=s(Nq);bpo=r(B0t,"TrOCRConfig"),B0t.forEach(t),vpo=r(TIe," (TrOCR model)"),TIe.forEach(t),Fpo=i(L),Gh=n(L,"LI",{});var MIe=s(Gh);rge=n(MIe,"STRONG",{});var I0t=s(rge);Tpo=r(I0t,"unispeech"),I0t.forEach(t),Mpo=r(MIe," \u2014 "),qq=n(MIe,"A",{href:!0});var N0t=s(qq);Epo=r(N0t,"UniSpeechConfig"),N0t.forEach(t),Cpo=r(MIe," (UniSpeech model)"),MIe.forEach(t),wpo=i(L),Oh=n(L,"LI",{});var EIe=s(Oh);tge=n(EIe,"STRONG",{});var q0t=s(tge);Apo=r(q0t,"unispeech-sat"),q0t.forEach(t),Lpo=r(EIe," \u2014 "),jq=n(EIe,"A",{href:!0});var j0t=s(jq);ypo=r(j0t,"UniSpeechSatConfig"),j0t.forEach(t),xpo=r(EIe," (UniSpeechSat model)"),EIe.forEach(t),$po=i(L),Vh=n(L,"LI",{});var CIe=s(Vh);age=n(CIe,"STRONG",{});var D0t=s(age);kpo=r(D0t,"van"),D0t.forEach(t),Spo=r(CIe," \u2014 "),Dq=n(CIe,"A",{href:!0});var G0t=s(Dq);Rpo=r(G0t,"VanConfig"),G0t.forEach(t),Ppo=r(CIe," (VAN model)"),CIe.forEach(t),Bpo=i(L),Xh=n(L,"LI",{});var wIe=s(Xh);nge=n(wIe,"STRONG",{});var O0t=s(nge);Ipo=r(O0t,"videomae"),O0t.forEach(t),Npo=r(wIe," \u2014 "),Gq=n(wIe,"A",{href:!0});var V0t=s(Gq);qpo=r(V0t,"VideoMAEConfig"),V0t.forEach(t),jpo=r(wIe," (VideoMAE model)"),wIe.forEach(t),Dpo=i(L),zh=n(L,"LI",{});var AIe=s(zh);sge=n(AIe,"STRONG",{});var X0t=s(sge);Gpo=r(X0t,"vilt"),X0t.forEach(t),Opo=r(AIe," \u2014 "),Oq=n(AIe,"A",{href:!0});var z0t=s(Oq);Vpo=r(z0t,"ViltConfig"),z0t.forEach(t),Xpo=r(AIe," (ViLT model)"),AIe.forEach(t),zpo=i(L),Qh=n(L,"LI",{});var LIe=s(Qh);lge=n(LIe,"STRONG",{});var Q0t=s(lge);Qpo=r(Q0t,"vision-encoder-decoder"),Q0t.forEach(t),Wpo=r(LIe," \u2014 "),Vq=n(LIe,"A",{href:!0});var W0t=s(Vq);Upo=r(W0t,"VisionEncoderDecoderConfig"),W0t.forEach(t),Hpo=r(LIe," (Vision Encoder decoder model)"),LIe.forEach(t),Jpo=i(L),Wh=n(L,"LI",{});var yIe=s(Wh);ige=n(yIe,"STRONG",{});var U0t=s(ige);Ypo=r(U0t,"vision-text-dual-encoder"),U0t.forEach(t),Zpo=r(yIe," \u2014 "),Xq=n(yIe,"A",{href:!0});var H0t=s(Xq);Kpo=r(H0t,"VisionTextDualEncoderConfig"),H0t.forEach(t),e_o=r(yIe," (VisionTextDualEncoder model)"),yIe.forEach(t),o_o=i(L),Uh=n(L,"LI",{});var xIe=s(Uh);dge=n(xIe,"STRONG",{});var J0t=s(dge);r_o=r(J0t,"visual_bert"),J0t.forEach(t),t_o=r(xIe," \u2014 "),zq=n(xIe,"A",{href:!0});var Y0t=s(zq);a_o=r(Y0t,"VisualBertConfig"),Y0t.forEach(t),n_o=r(xIe," (VisualBERT model)"),xIe.forEach(t),s_o=i(L),Hh=n(L,"LI",{});var $Ie=s(Hh);cge=n($Ie,"STRONG",{});var Z0t=s(cge);l_o=r(Z0t,"vit"),Z0t.forEach(t),i_o=r($Ie," \u2014 "),Qq=n($Ie,"A",{href:!0});var K0t=s(Qq);d_o=r(K0t,"ViTConfig"),K0t.forEach(t),c_o=r($Ie," (ViT model)"),$Ie.forEach(t),m_o=i(L),Jh=n(L,"LI",{});var kIe=s(Jh);mge=n(kIe,"STRONG",{});var ewt=s(mge);f_o=r(ewt,"vit_mae"),ewt.forEach(t),g_o=r(kIe," \u2014 "),Wq=n(kIe,"A",{href:!0});var owt=s(Wq);h_o=r(owt,"ViTMAEConfig"),owt.forEach(t),u_o=r(kIe," (ViTMAE model)"),kIe.forEach(t),p_o=i(L),Yh=n(L,"LI",{});var SIe=s(Yh);fge=n(SIe,"STRONG",{});var rwt=s(fge);__o=r(rwt,"vit_msn"),rwt.forEach(t),b_o=r(SIe," \u2014 "),Uq=n(SIe,"A",{href:!0});var twt=s(Uq);v_o=r(twt,"ViTMSNConfig"),twt.forEach(t),F_o=r(SIe," (ViTMSN model)"),SIe.forEach(t),T_o=i(L),Zh=n(L,"LI",{});var RIe=s(Zh);gge=n(RIe,"STRONG",{});var awt=s(gge);M_o=r(awt,"wav2vec2"),awt.forEach(t),E_o=r(RIe," \u2014 "),Hq=n(RIe,"A",{href:!0});var nwt=s(Hq);C_o=r(nwt,"Wav2Vec2Config"),nwt.forEach(t),w_o=r(RIe," (Wav2Vec2 model)"),RIe.forEach(t),A_o=i(L),Kh=n(L,"LI",{});var PIe=s(Kh);hge=n(PIe,"STRONG",{});var swt=s(hge);L_o=r(swt,"wav2vec2-conformer"),swt.forEach(t),y_o=r(PIe," \u2014 "),Jq=n(PIe,"A",{href:!0});var lwt=s(Jq);x_o=r(lwt,"Wav2Vec2ConformerConfig"),lwt.forEach(t),$_o=r(PIe," (Wav2Vec2-Conformer model)"),PIe.forEach(t),k_o=i(L),eu=n(L,"LI",{});var BIe=s(eu);uge=n(BIe,"STRONG",{});var iwt=s(uge);S_o=r(iwt,"wavlm"),iwt.forEach(t),R_o=r(BIe," \u2014 "),Yq=n(BIe,"A",{href:!0});var dwt=s(Yq);P_o=r(dwt,"WavLMConfig"),dwt.forEach(t),B_o=r(BIe," (WavLM model)"),BIe.forEach(t),I_o=i(L),ou=n(L,"LI",{});var IIe=s(ou);pge=n(IIe,"STRONG",{});var cwt=s(pge);N_o=r(cwt,"whisper"),cwt.forEach(t),q_o=r(IIe," \u2014 "),Zq=n(IIe,"A",{href:!0});var mwt=s(Zq);j_o=r(mwt,"WhisperConfig"),mwt.forEach(t),D_o=r(IIe," (Whisper model)"),IIe.forEach(t),G_o=i(L),ru=n(L,"LI",{});var NIe=s(ru);_ge=n(NIe,"STRONG",{});var fwt=s(_ge);O_o=r(fwt,"xclip"),fwt.forEach(t),V_o=r(NIe," \u2014 "),Kq=n(NIe,"A",{href:!0});var gwt=s(Kq);X_o=r(gwt,"XCLIPConfig"),gwt.forEach(t),z_o=r(NIe," (X-CLIP model)"),NIe.forEach(t),Q_o=i(L),tu=n(L,"LI",{});var qIe=s(tu);bge=n(qIe,"STRONG",{});var hwt=s(bge);W_o=r(hwt,"xglm"),hwt.forEach(t),U_o=r(qIe," \u2014 "),ej=n(qIe,"A",{href:!0});var uwt=s(ej);H_o=r(uwt,"XGLMConfig"),uwt.forEach(t),J_o=r(qIe," (XGLM model)"),qIe.forEach(t),Y_o=i(L),au=n(L,"LI",{});var jIe=s(au);vge=n(jIe,"STRONG",{});var pwt=s(vge);Z_o=r(pwt,"xlm"),pwt.forEach(t),K_o=r(jIe," \u2014 "),oj=n(jIe,"A",{href:!0});var _wt=s(oj);e1o=r(_wt,"XLMConfig"),_wt.forEach(t),o1o=r(jIe," (XLM model)"),jIe.forEach(t),r1o=i(L),nu=n(L,"LI",{});var DIe=s(nu);Fge=n(DIe,"STRONG",{});var bwt=s(Fge);t1o=r(bwt,"xlm-prophetnet"),bwt.forEach(t),a1o=r(DIe," \u2014 "),rj=n(DIe,"A",{href:!0});var vwt=s(rj);n1o=r(vwt,"XLMProphetNetConfig"),vwt.forEach(t),s1o=r(DIe," (XLM-ProphetNet model)"),DIe.forEach(t),l1o=i(L),su=n(L,"LI",{});var GIe=s(su);Tge=n(GIe,"STRONG",{});var Fwt=s(Tge);i1o=r(Fwt,"xlm-roberta"),Fwt.forEach(t),d1o=r(GIe," \u2014 "),tj=n(GIe,"A",{href:!0});var Twt=s(tj);c1o=r(Twt,"XLMRobertaConfig"),Twt.forEach(t),m1o=r(GIe," (XLM-RoBERTa model)"),GIe.forEach(t),f1o=i(L),lu=n(L,"LI",{});var OIe=s(lu);Mge=n(OIe,"STRONG",{});var Mwt=s(Mge);g1o=r(Mwt,"xlm-roberta-xl"),Mwt.forEach(t),h1o=r(OIe," \u2014 "),aj=n(OIe,"A",{href:!0});var Ewt=s(aj);u1o=r(Ewt,"XLMRobertaXLConfig"),Ewt.forEach(t),p1o=r(OIe," (XLM-RoBERTa-XL model)"),OIe.forEach(t),_1o=i(L),iu=n(L,"LI",{});var VIe=s(iu);Ege=n(VIe,"STRONG",{});var Cwt=s(Ege);b1o=r(Cwt,"xlnet"),Cwt.forEach(t),v1o=r(VIe," \u2014 "),nj=n(VIe,"A",{href:!0});var wwt=s(nj);F1o=r(wwt,"XLNetConfig"),wwt.forEach(t),T1o=r(VIe," (XLNet model)"),VIe.forEach(t),M1o=i(L),du=n(L,"LI",{});var XIe=s(du);Cge=n(XIe,"STRONG",{});var Awt=s(Cge);E1o=r(Awt,"yolos"),Awt.forEach(t),C1o=r(XIe," \u2014 "),sj=n(XIe,"A",{href:!0});var Lwt=s(sj);w1o=r(Lwt,"YolosConfig"),Lwt.forEach(t),A1o=r(XIe," (YOLOS model)"),XIe.forEach(t),L1o=i(L),cu=n(L,"LI",{});var zIe=s(cu);wge=n(zIe,"STRONG",{});var ywt=s(wge);y1o=r(ywt,"yoso"),ywt.forEach(t),x1o=r(zIe," \u2014 "),lj=n(zIe,"A",{href:!0});var xwt=s(lj);$1o=r(xwt,"YosoConfig"),xwt.forEach(t),k1o=r(zIe," (YOSO model)"),zIe.forEach(t),L.forEach(t),S1o=i(_t),T(mu.$$.fragment,_t),_t.forEach(t),R1o=i(pt),fu=n(pt,"DIV",{class:!0});var Cto=s(fu);T(Rx.$$.fragment,Cto),P1o=i(Cto),Age=n(Cto,"P",{});var $wt=s(Age);B1o=r($wt,"Register a new configuration for this class."),$wt.forEach(t),Cto.forEach(t),pt.forEach(t),uoo=i(m),vd=n(m,"H2",{class:!0});var wto=s(vd);gu=n(wto,"A",{id:!0,class:!0,href:!0});var kwt=s(gu);Lge=n(kwt,"SPAN",{});var Swt=s(Lge);T(Px.$$.fragment,Swt),Swt.forEach(t),kwt.forEach(t),I1o=i(wto),yge=n(wto,"SPAN",{});var Rwt=s(yge);N1o=r(Rwt,"AutoTokenizer"),Rwt.forEach(t),wto.forEach(t),poo=i(m),So=n(m,"DIV",{class:!0});var Ll=s(So);T(Bx.$$.fragment,Ll),q1o=i(Ll),Ix=n(Ll,"P",{});var Ato=s(Ix);j1o=r(Ato,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ij=n(Ato,"A",{href:!0});var Pwt=s(ij);D1o=r(Pwt,"AutoTokenizer.from_pretrained()"),Pwt.forEach(t),G1o=r(Ato," class method."),Ato.forEach(t),O1o=i(Ll),Nx=n(Ll,"P",{});var Lto=s(Nx);V1o=r(Lto,"This class cannot be instantiated directly using "),xge=n(Lto,"CODE",{});var Bwt=s(xge);X1o=r(Bwt,"__init__()"),Bwt.forEach(t),z1o=r(Lto," (throws an error)."),Lto.forEach(t),Q1o=i(Ll),Nr=n(Ll,"DIV",{class:!0});var yl=s(Nr);T(qx.$$.fragment,yl),W1o=i(yl),$ge=n(yl,"P",{});var Iwt=s($ge);U1o=r(Iwt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Iwt.forEach(t),H1o=i(yl),Za=n(yl,"P",{});var p8=s(Za);J1o=r(p8,"The tokenizer class to instantiate is selected based on the "),kge=n(p8,"CODE",{});var Nwt=s(kge);Y1o=r(Nwt,"model_type"),Nwt.forEach(t),Z1o=r(p8,` property of the config object (either
passed as an argument or loaded from `),Sge=n(p8,"CODE",{});var qwt=s(Sge);K1o=r(qwt,"pretrained_model_name_or_path"),qwt.forEach(t),ebo=r(p8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rge=n(p8,"CODE",{});var jwt=s(Rge);obo=r(jwt,"pretrained_model_name_or_path"),jwt.forEach(t),rbo=r(p8,":"),p8.forEach(t),tbo=i(yl),k=n(yl,"UL",{});var S=s(k);cs=n(S,"LI",{});var gB=s(cs);Pge=n(gB,"STRONG",{});var Dwt=s(Pge);abo=r(Dwt,"albert"),Dwt.forEach(t),nbo=r(gB," \u2014 "),dj=n(gB,"A",{href:!0});var Gwt=s(dj);sbo=r(Gwt,"AlbertTokenizer"),Gwt.forEach(t),lbo=r(gB," or "),cj=n(gB,"A",{href:!0});var Owt=s(cj);ibo=r(Owt,"AlbertTokenizerFast"),Owt.forEach(t),dbo=r(gB," (ALBERT model)"),gB.forEach(t),cbo=i(S),ms=n(S,"LI",{});var hB=s(ms);Bge=n(hB,"STRONG",{});var Vwt=s(Bge);mbo=r(Vwt,"bart"),Vwt.forEach(t),fbo=r(hB," \u2014 "),mj=n(hB,"A",{href:!0});var Xwt=s(mj);gbo=r(Xwt,"BartTokenizer"),Xwt.forEach(t),hbo=r(hB," or "),fj=n(hB,"A",{href:!0});var zwt=s(fj);ubo=r(zwt,"BartTokenizerFast"),zwt.forEach(t),pbo=r(hB," (BART model)"),hB.forEach(t),_bo=i(S),fs=n(S,"LI",{});var uB=s(fs);Ige=n(uB,"STRONG",{});var Qwt=s(Ige);bbo=r(Qwt,"barthez"),Qwt.forEach(t),vbo=r(uB," \u2014 "),gj=n(uB,"A",{href:!0});var Wwt=s(gj);Fbo=r(Wwt,"BarthezTokenizer"),Wwt.forEach(t),Tbo=r(uB," or "),hj=n(uB,"A",{href:!0});var Uwt=s(hj);Mbo=r(Uwt,"BarthezTokenizerFast"),Uwt.forEach(t),Ebo=r(uB," (BARThez model)"),uB.forEach(t),Cbo=i(S),hu=n(S,"LI",{});var QIe=s(hu);Nge=n(QIe,"STRONG",{});var Hwt=s(Nge);wbo=r(Hwt,"bartpho"),Hwt.forEach(t),Abo=r(QIe," \u2014 "),uj=n(QIe,"A",{href:!0});var Jwt=s(uj);Lbo=r(Jwt,"BartphoTokenizer"),Jwt.forEach(t),ybo=r(QIe," (BARTpho model)"),QIe.forEach(t),xbo=i(S),gs=n(S,"LI",{});var pB=s(gs);qge=n(pB,"STRONG",{});var Ywt=s(qge);$bo=r(Ywt,"bert"),Ywt.forEach(t),kbo=r(pB," \u2014 "),pj=n(pB,"A",{href:!0});var Zwt=s(pj);Sbo=r(Zwt,"BertTokenizer"),Zwt.forEach(t),Rbo=r(pB," or "),_j=n(pB,"A",{href:!0});var Kwt=s(_j);Pbo=r(Kwt,"BertTokenizerFast"),Kwt.forEach(t),Bbo=r(pB," (BERT model)"),pB.forEach(t),Ibo=i(S),uu=n(S,"LI",{});var WIe=s(uu);jge=n(WIe,"STRONG",{});var eAt=s(jge);Nbo=r(eAt,"bert-generation"),eAt.forEach(t),qbo=r(WIe," \u2014 "),bj=n(WIe,"A",{href:!0});var oAt=s(bj);jbo=r(oAt,"BertGenerationTokenizer"),oAt.forEach(t),Dbo=r(WIe," (Bert Generation model)"),WIe.forEach(t),Gbo=i(S),pu=n(S,"LI",{});var UIe=s(pu);Dge=n(UIe,"STRONG",{});var rAt=s(Dge);Obo=r(rAt,"bert-japanese"),rAt.forEach(t),Vbo=r(UIe," \u2014 "),vj=n(UIe,"A",{href:!0});var tAt=s(vj);Xbo=r(tAt,"BertJapaneseTokenizer"),tAt.forEach(t),zbo=r(UIe," (BertJapanese model)"),UIe.forEach(t),Qbo=i(S),_u=n(S,"LI",{});var HIe=s(_u);Gge=n(HIe,"STRONG",{});var aAt=s(Gge);Wbo=r(aAt,"bertweet"),aAt.forEach(t),Ubo=r(HIe," \u2014 "),Fj=n(HIe,"A",{href:!0});var nAt=s(Fj);Hbo=r(nAt,"BertweetTokenizer"),nAt.forEach(t),Jbo=r(HIe," (BERTweet model)"),HIe.forEach(t),Ybo=i(S),hs=n(S,"LI",{});var _B=s(hs);Oge=n(_B,"STRONG",{});var sAt=s(Oge);Zbo=r(sAt,"big_bird"),sAt.forEach(t),Kbo=r(_B," \u2014 "),Tj=n(_B,"A",{href:!0});var lAt=s(Tj);e2o=r(lAt,"BigBirdTokenizer"),lAt.forEach(t),o2o=r(_B," or "),Mj=n(_B,"A",{href:!0});var iAt=s(Mj);r2o=r(iAt,"BigBirdTokenizerFast"),iAt.forEach(t),t2o=r(_B," (BigBird model)"),_B.forEach(t),a2o=i(S),us=n(S,"LI",{});var bB=s(us);Vge=n(bB,"STRONG",{});var dAt=s(Vge);n2o=r(dAt,"bigbird_pegasus"),dAt.forEach(t),s2o=r(bB," \u2014 "),Ej=n(bB,"A",{href:!0});var cAt=s(Ej);l2o=r(cAt,"PegasusTokenizer"),cAt.forEach(t),i2o=r(bB," or "),Cj=n(bB,"A",{href:!0});var mAt=s(Cj);d2o=r(mAt,"PegasusTokenizerFast"),mAt.forEach(t),c2o=r(bB," (BigBird-Pegasus model)"),bB.forEach(t),m2o=i(S),ps=n(S,"LI",{});var vB=s(ps);Xge=n(vB,"STRONG",{});var fAt=s(Xge);f2o=r(fAt,"blenderbot"),fAt.forEach(t),g2o=r(vB," \u2014 "),wj=n(vB,"A",{href:!0});var gAt=s(wj);h2o=r(gAt,"BlenderbotTokenizer"),gAt.forEach(t),u2o=r(vB," or "),Aj=n(vB,"A",{href:!0});var hAt=s(Aj);p2o=r(hAt,"BlenderbotTokenizerFast"),hAt.forEach(t),_2o=r(vB," (Blenderbot model)"),vB.forEach(t),b2o=i(S),bu=n(S,"LI",{});var JIe=s(bu);zge=n(JIe,"STRONG",{});var uAt=s(zge);v2o=r(uAt,"blenderbot-small"),uAt.forEach(t),F2o=r(JIe," \u2014 "),Lj=n(JIe,"A",{href:!0});var pAt=s(Lj);T2o=r(pAt,"BlenderbotSmallTokenizer"),pAt.forEach(t),M2o=r(JIe," (BlenderbotSmall model)"),JIe.forEach(t),E2o=i(S),vu=n(S,"LI",{});var YIe=s(vu);Qge=n(YIe,"STRONG",{});var _At=s(Qge);C2o=r(_At,"bloom"),_At.forEach(t),w2o=r(YIe," \u2014 "),yj=n(YIe,"A",{href:!0});var bAt=s(yj);A2o=r(bAt,"BloomTokenizerFast"),bAt.forEach(t),L2o=r(YIe," (BLOOM model)"),YIe.forEach(t),y2o=i(S),Fu=n(S,"LI",{});var ZIe=s(Fu);Wge=n(ZIe,"STRONG",{});var vAt=s(Wge);x2o=r(vAt,"byt5"),vAt.forEach(t),$2o=r(ZIe," \u2014 "),xj=n(ZIe,"A",{href:!0});var FAt=s(xj);k2o=r(FAt,"ByT5Tokenizer"),FAt.forEach(t),S2o=r(ZIe," (ByT5 model)"),ZIe.forEach(t),R2o=i(S),_s=n(S,"LI",{});var FB=s(_s);Uge=n(FB,"STRONG",{});var TAt=s(Uge);P2o=r(TAt,"camembert"),TAt.forEach(t),B2o=r(FB," \u2014 "),$j=n(FB,"A",{href:!0});var MAt=s($j);I2o=r(MAt,"CamembertTokenizer"),MAt.forEach(t),N2o=r(FB," or "),kj=n(FB,"A",{href:!0});var EAt=s(kj);q2o=r(EAt,"CamembertTokenizerFast"),EAt.forEach(t),j2o=r(FB," (CamemBERT model)"),FB.forEach(t),D2o=i(S),Tu=n(S,"LI",{});var KIe=s(Tu);Hge=n(KIe,"STRONG",{});var CAt=s(Hge);G2o=r(CAt,"canine"),CAt.forEach(t),O2o=r(KIe," \u2014 "),Sj=n(KIe,"A",{href:!0});var wAt=s(Sj);V2o=r(wAt,"CanineTokenizer"),wAt.forEach(t),X2o=r(KIe," (CANINE model)"),KIe.forEach(t),z2o=i(S),bs=n(S,"LI",{});var TB=s(bs);Jge=n(TB,"STRONG",{});var AAt=s(Jge);Q2o=r(AAt,"clip"),AAt.forEach(t),W2o=r(TB," \u2014 "),Rj=n(TB,"A",{href:!0});var LAt=s(Rj);U2o=r(LAt,"CLIPTokenizer"),LAt.forEach(t),H2o=r(TB," or "),Pj=n(TB,"A",{href:!0});var yAt=s(Pj);J2o=r(yAt,"CLIPTokenizerFast"),yAt.forEach(t),Y2o=r(TB," (CLIP model)"),TB.forEach(t),Z2o=i(S),vs=n(S,"LI",{});var MB=s(vs);Yge=n(MB,"STRONG",{});var xAt=s(Yge);K2o=r(xAt,"codegen"),xAt.forEach(t),evo=r(MB," \u2014 "),Bj=n(MB,"A",{href:!0});var $At=s(Bj);ovo=r($At,"CodeGenTokenizer"),$At.forEach(t),rvo=r(MB," or "),Ij=n(MB,"A",{href:!0});var kAt=s(Ij);tvo=r(kAt,"CodeGenTokenizerFast"),kAt.forEach(t),avo=r(MB," (CodeGen model)"),MB.forEach(t),nvo=i(S),Fs=n(S,"LI",{});var EB=s(Fs);Zge=n(EB,"STRONG",{});var SAt=s(Zge);svo=r(SAt,"convbert"),SAt.forEach(t),lvo=r(EB," \u2014 "),Nj=n(EB,"A",{href:!0});var RAt=s(Nj);ivo=r(RAt,"ConvBertTokenizer"),RAt.forEach(t),dvo=r(EB," or "),qj=n(EB,"A",{href:!0});var PAt=s(qj);cvo=r(PAt,"ConvBertTokenizerFast"),PAt.forEach(t),mvo=r(EB," (ConvBERT model)"),EB.forEach(t),fvo=i(S),Ts=n(S,"LI",{});var CB=s(Ts);Kge=n(CB,"STRONG",{});var BAt=s(Kge);gvo=r(BAt,"cpm"),BAt.forEach(t),hvo=r(CB," \u2014 "),jj=n(CB,"A",{href:!0});var IAt=s(jj);uvo=r(IAt,"CpmTokenizer"),IAt.forEach(t),pvo=r(CB," or "),Dj=n(CB,"A",{href:!0});var NAt=s(Dj);_vo=r(NAt,"CpmTokenizerFast"),NAt.forEach(t),bvo=r(CB," (CPM model)"),CB.forEach(t),vvo=i(S),Mu=n(S,"LI",{});var eNe=s(Mu);ehe=n(eNe,"STRONG",{});var qAt=s(ehe);Fvo=r(qAt,"ctrl"),qAt.forEach(t),Tvo=r(eNe," \u2014 "),Gj=n(eNe,"A",{href:!0});var jAt=s(Gj);Mvo=r(jAt,"CTRLTokenizer"),jAt.forEach(t),Evo=r(eNe," (CTRL model)"),eNe.forEach(t),Cvo=i(S),Ms=n(S,"LI",{});var wB=s(Ms);ohe=n(wB,"STRONG",{});var DAt=s(ohe);wvo=r(DAt,"data2vec-text"),DAt.forEach(t),Avo=r(wB," \u2014 "),Oj=n(wB,"A",{href:!0});var GAt=s(Oj);Lvo=r(GAt,"RobertaTokenizer"),GAt.forEach(t),yvo=r(wB," or "),Vj=n(wB,"A",{href:!0});var OAt=s(Vj);xvo=r(OAt,"RobertaTokenizerFast"),OAt.forEach(t),$vo=r(wB," (Data2VecText model)"),wB.forEach(t),kvo=i(S),Es=n(S,"LI",{});var AB=s(Es);rhe=n(AB,"STRONG",{});var VAt=s(rhe);Svo=r(VAt,"deberta"),VAt.forEach(t),Rvo=r(AB," \u2014 "),Xj=n(AB,"A",{href:!0});var XAt=s(Xj);Pvo=r(XAt,"DebertaTokenizer"),XAt.forEach(t),Bvo=r(AB," or "),zj=n(AB,"A",{href:!0});var zAt=s(zj);Ivo=r(zAt,"DebertaTokenizerFast"),zAt.forEach(t),Nvo=r(AB," (DeBERTa model)"),AB.forEach(t),qvo=i(S),Cs=n(S,"LI",{});var LB=s(Cs);the=n(LB,"STRONG",{});var QAt=s(the);jvo=r(QAt,"deberta-v2"),QAt.forEach(t),Dvo=r(LB," \u2014 "),Qj=n(LB,"A",{href:!0});var WAt=s(Qj);Gvo=r(WAt,"DebertaV2Tokenizer"),WAt.forEach(t),Ovo=r(LB," or "),Wj=n(LB,"A",{href:!0});var UAt=s(Wj);Vvo=r(UAt,"DebertaV2TokenizerFast"),UAt.forEach(t),Xvo=r(LB," (DeBERTa-v2 model)"),LB.forEach(t),zvo=i(S),ws=n(S,"LI",{});var yB=s(ws);ahe=n(yB,"STRONG",{});var HAt=s(ahe);Qvo=r(HAt,"distilbert"),HAt.forEach(t),Wvo=r(yB," \u2014 "),Uj=n(yB,"A",{href:!0});var JAt=s(Uj);Uvo=r(JAt,"DistilBertTokenizer"),JAt.forEach(t),Hvo=r(yB," or "),Hj=n(yB,"A",{href:!0});var YAt=s(Hj);Jvo=r(YAt,"DistilBertTokenizerFast"),YAt.forEach(t),Yvo=r(yB," (DistilBERT model)"),yB.forEach(t),Zvo=i(S),As=n(S,"LI",{});var xB=s(As);nhe=n(xB,"STRONG",{});var ZAt=s(nhe);Kvo=r(ZAt,"dpr"),ZAt.forEach(t),eFo=r(xB," \u2014 "),Jj=n(xB,"A",{href:!0});var KAt=s(Jj);oFo=r(KAt,"DPRQuestionEncoderTokenizer"),KAt.forEach(t),rFo=r(xB," or "),Yj=n(xB,"A",{href:!0});var e6t=s(Yj);tFo=r(e6t,"DPRQuestionEncoderTokenizerFast"),e6t.forEach(t),aFo=r(xB," (DPR model)"),xB.forEach(t),nFo=i(S),Ls=n(S,"LI",{});var $B=s(Ls);she=n($B,"STRONG",{});var o6t=s(she);sFo=r(o6t,"electra"),o6t.forEach(t),lFo=r($B," \u2014 "),Zj=n($B,"A",{href:!0});var r6t=s(Zj);iFo=r(r6t,"ElectraTokenizer"),r6t.forEach(t),dFo=r($B," or "),Kj=n($B,"A",{href:!0});var t6t=s(Kj);cFo=r(t6t,"ElectraTokenizerFast"),t6t.forEach(t),mFo=r($B," (ELECTRA model)"),$B.forEach(t),fFo=i(S),ys=n(S,"LI",{});var kB=s(ys);lhe=n(kB,"STRONG",{});var a6t=s(lhe);gFo=r(a6t,"ernie"),a6t.forEach(t),hFo=r(kB," \u2014 "),eD=n(kB,"A",{href:!0});var n6t=s(eD);uFo=r(n6t,"BertTokenizer"),n6t.forEach(t),pFo=r(kB," or "),oD=n(kB,"A",{href:!0});var s6t=s(oD);_Fo=r(s6t,"BertTokenizerFast"),s6t.forEach(t),bFo=r(kB," (ERNIE model)"),kB.forEach(t),vFo=i(S),Eu=n(S,"LI",{});var oNe=s(Eu);ihe=n(oNe,"STRONG",{});var l6t=s(ihe);FFo=r(l6t,"flaubert"),l6t.forEach(t),TFo=r(oNe," \u2014 "),rD=n(oNe,"A",{href:!0});var i6t=s(rD);MFo=r(i6t,"FlaubertTokenizer"),i6t.forEach(t),EFo=r(oNe," (FlauBERT model)"),oNe.forEach(t),CFo=i(S),xs=n(S,"LI",{});var SB=s(xs);dhe=n(SB,"STRONG",{});var d6t=s(dhe);wFo=r(d6t,"fnet"),d6t.forEach(t),AFo=r(SB," \u2014 "),tD=n(SB,"A",{href:!0});var c6t=s(tD);LFo=r(c6t,"FNetTokenizer"),c6t.forEach(t),yFo=r(SB," or "),aD=n(SB,"A",{href:!0});var m6t=s(aD);xFo=r(m6t,"FNetTokenizerFast"),m6t.forEach(t),$Fo=r(SB," (FNet model)"),SB.forEach(t),kFo=i(S),Cu=n(S,"LI",{});var rNe=s(Cu);che=n(rNe,"STRONG",{});var f6t=s(che);SFo=r(f6t,"fsmt"),f6t.forEach(t),RFo=r(rNe," \u2014 "),nD=n(rNe,"A",{href:!0});var g6t=s(nD);PFo=r(g6t,"FSMTTokenizer"),g6t.forEach(t),BFo=r(rNe," (FairSeq Machine-Translation model)"),rNe.forEach(t),IFo=i(S),$s=n(S,"LI",{});var RB=s($s);mhe=n(RB,"STRONG",{});var h6t=s(mhe);NFo=r(h6t,"funnel"),h6t.forEach(t),qFo=r(RB," \u2014 "),sD=n(RB,"A",{href:!0});var u6t=s(sD);jFo=r(u6t,"FunnelTokenizer"),u6t.forEach(t),DFo=r(RB," or "),lD=n(RB,"A",{href:!0});var p6t=s(lD);GFo=r(p6t,"FunnelTokenizerFast"),p6t.forEach(t),OFo=r(RB," (Funnel Transformer model)"),RB.forEach(t),VFo=i(S),ks=n(S,"LI",{});var PB=s(ks);fhe=n(PB,"STRONG",{});var _6t=s(fhe);XFo=r(_6t,"gpt2"),_6t.forEach(t),zFo=r(PB," \u2014 "),iD=n(PB,"A",{href:!0});var b6t=s(iD);QFo=r(b6t,"GPT2Tokenizer"),b6t.forEach(t),WFo=r(PB," or "),dD=n(PB,"A",{href:!0});var v6t=s(dD);UFo=r(v6t,"GPT2TokenizerFast"),v6t.forEach(t),HFo=r(PB," (OpenAI GPT-2 model)"),PB.forEach(t),JFo=i(S),Ss=n(S,"LI",{});var BB=s(Ss);ghe=n(BB,"STRONG",{});var F6t=s(ghe);YFo=r(F6t,"gpt_neo"),F6t.forEach(t),ZFo=r(BB," \u2014 "),cD=n(BB,"A",{href:!0});var T6t=s(cD);KFo=r(T6t,"GPT2Tokenizer"),T6t.forEach(t),eTo=r(BB," or "),mD=n(BB,"A",{href:!0});var M6t=s(mD);oTo=r(M6t,"GPT2TokenizerFast"),M6t.forEach(t),rTo=r(BB," (GPT Neo model)"),BB.forEach(t),tTo=i(S),wu=n(S,"LI",{});var tNe=s(wu);hhe=n(tNe,"STRONG",{});var E6t=s(hhe);aTo=r(E6t,"gpt_neox"),E6t.forEach(t),nTo=r(tNe," \u2014 "),fD=n(tNe,"A",{href:!0});var C6t=s(fD);sTo=r(C6t,"GPTNeoXTokenizerFast"),C6t.forEach(t),lTo=r(tNe," (GPT NeoX model)"),tNe.forEach(t),iTo=i(S),Au=n(S,"LI",{});var aNe=s(Au);uhe=n(aNe,"STRONG",{});var w6t=s(uhe);dTo=r(w6t,"gpt_neox_japanese"),w6t.forEach(t),cTo=r(aNe," \u2014 "),gD=n(aNe,"A",{href:!0});var A6t=s(gD);mTo=r(A6t,"GPTNeoXJapaneseTokenizer"),A6t.forEach(t),fTo=r(aNe," (GPT NeoX Japanese model)"),aNe.forEach(t),gTo=i(S),Rs=n(S,"LI",{});var IB=s(Rs);phe=n(IB,"STRONG",{});var L6t=s(phe);hTo=r(L6t,"gptj"),L6t.forEach(t),uTo=r(IB," \u2014 "),hD=n(IB,"A",{href:!0});var y6t=s(hD);pTo=r(y6t,"GPT2Tokenizer"),y6t.forEach(t),_To=r(IB," or "),uD=n(IB,"A",{href:!0});var x6t=s(uD);bTo=r(x6t,"GPT2TokenizerFast"),x6t.forEach(t),vTo=r(IB," (GPT-J model)"),IB.forEach(t),FTo=i(S),Ps=n(S,"LI",{});var NB=s(Ps);_he=n(NB,"STRONG",{});var $6t=s(_he);TTo=r($6t,"groupvit"),$6t.forEach(t),MTo=r(NB," \u2014 "),pD=n(NB,"A",{href:!0});var k6t=s(pD);ETo=r(k6t,"CLIPTokenizer"),k6t.forEach(t),CTo=r(NB," or "),_D=n(NB,"A",{href:!0});var S6t=s(_D);wTo=r(S6t,"CLIPTokenizerFast"),S6t.forEach(t),ATo=r(NB," (GroupViT model)"),NB.forEach(t),LTo=i(S),Bs=n(S,"LI",{});var qB=s(Bs);bhe=n(qB,"STRONG",{});var R6t=s(bhe);yTo=r(R6t,"herbert"),R6t.forEach(t),xTo=r(qB," \u2014 "),bD=n(qB,"A",{href:!0});var P6t=s(bD);$To=r(P6t,"HerbertTokenizer"),P6t.forEach(t),kTo=r(qB," or "),vD=n(qB,"A",{href:!0});var B6t=s(vD);STo=r(B6t,"HerbertTokenizerFast"),B6t.forEach(t),RTo=r(qB," (HerBERT model)"),qB.forEach(t),PTo=i(S),Lu=n(S,"LI",{});var nNe=s(Lu);vhe=n(nNe,"STRONG",{});var I6t=s(vhe);BTo=r(I6t,"hubert"),I6t.forEach(t),ITo=r(nNe," \u2014 "),FD=n(nNe,"A",{href:!0});var N6t=s(FD);NTo=r(N6t,"Wav2Vec2CTCTokenizer"),N6t.forEach(t),qTo=r(nNe," (Hubert model)"),nNe.forEach(t),jTo=i(S),Is=n(S,"LI",{});var jB=s(Is);Fhe=n(jB,"STRONG",{});var q6t=s(Fhe);DTo=r(q6t,"ibert"),q6t.forEach(t),GTo=r(jB," \u2014 "),TD=n(jB,"A",{href:!0});var j6t=s(TD);OTo=r(j6t,"RobertaTokenizer"),j6t.forEach(t),VTo=r(jB," or "),MD=n(jB,"A",{href:!0});var D6t=s(MD);XTo=r(D6t,"RobertaTokenizerFast"),D6t.forEach(t),zTo=r(jB," (I-BERT model)"),jB.forEach(t),QTo=i(S),Ns=n(S,"LI",{});var DB=s(Ns);The=n(DB,"STRONG",{});var G6t=s(The);WTo=r(G6t,"layoutlm"),G6t.forEach(t),UTo=r(DB," \u2014 "),ED=n(DB,"A",{href:!0});var O6t=s(ED);HTo=r(O6t,"LayoutLMTokenizer"),O6t.forEach(t),JTo=r(DB," or "),CD=n(DB,"A",{href:!0});var V6t=s(CD);YTo=r(V6t,"LayoutLMTokenizerFast"),V6t.forEach(t),ZTo=r(DB," (LayoutLM model)"),DB.forEach(t),KTo=i(S),qs=n(S,"LI",{});var GB=s(qs);Mhe=n(GB,"STRONG",{});var X6t=s(Mhe);eMo=r(X6t,"layoutlmv2"),X6t.forEach(t),oMo=r(GB," \u2014 "),wD=n(GB,"A",{href:!0});var z6t=s(wD);rMo=r(z6t,"LayoutLMv2Tokenizer"),z6t.forEach(t),tMo=r(GB," or "),AD=n(GB,"A",{href:!0});var Q6t=s(AD);aMo=r(Q6t,"LayoutLMv2TokenizerFast"),Q6t.forEach(t),nMo=r(GB," (LayoutLMv2 model)"),GB.forEach(t),sMo=i(S),js=n(S,"LI",{});var OB=s(js);Ehe=n(OB,"STRONG",{});var W6t=s(Ehe);lMo=r(W6t,"layoutlmv3"),W6t.forEach(t),iMo=r(OB," \u2014 "),LD=n(OB,"A",{href:!0});var U6t=s(LD);dMo=r(U6t,"LayoutLMv3Tokenizer"),U6t.forEach(t),cMo=r(OB," or "),yD=n(OB,"A",{href:!0});var H6t=s(yD);mMo=r(H6t,"LayoutLMv3TokenizerFast"),H6t.forEach(t),fMo=r(OB," (LayoutLMv3 model)"),OB.forEach(t),gMo=i(S),Ds=n(S,"LI",{});var VB=s(Ds);Che=n(VB,"STRONG",{});var J6t=s(Che);hMo=r(J6t,"layoutxlm"),J6t.forEach(t),uMo=r(VB," \u2014 "),xD=n(VB,"A",{href:!0});var Y6t=s(xD);pMo=r(Y6t,"LayoutXLMTokenizer"),Y6t.forEach(t),_Mo=r(VB," or "),$D=n(VB,"A",{href:!0});var Z6t=s($D);bMo=r(Z6t,"LayoutXLMTokenizerFast"),Z6t.forEach(t),vMo=r(VB," (LayoutXLM model)"),VB.forEach(t),FMo=i(S),Gs=n(S,"LI",{});var XB=s(Gs);whe=n(XB,"STRONG",{});var K6t=s(whe);TMo=r(K6t,"led"),K6t.forEach(t),MMo=r(XB," \u2014 "),kD=n(XB,"A",{href:!0});var e7t=s(kD);EMo=r(e7t,"LEDTokenizer"),e7t.forEach(t),CMo=r(XB," or "),SD=n(XB,"A",{href:!0});var o7t=s(SD);wMo=r(o7t,"LEDTokenizerFast"),o7t.forEach(t),AMo=r(XB," (LED model)"),XB.forEach(t),LMo=i(S),Os=n(S,"LI",{});var zB=s(Os);Ahe=n(zB,"STRONG",{});var r7t=s(Ahe);yMo=r(r7t,"longformer"),r7t.forEach(t),xMo=r(zB," \u2014 "),RD=n(zB,"A",{href:!0});var t7t=s(RD);$Mo=r(t7t,"LongformerTokenizer"),t7t.forEach(t),kMo=r(zB," or "),PD=n(zB,"A",{href:!0});var a7t=s(PD);SMo=r(a7t,"LongformerTokenizerFast"),a7t.forEach(t),RMo=r(zB," (Longformer model)"),zB.forEach(t),PMo=i(S),Vs=n(S,"LI",{});var QB=s(Vs);Lhe=n(QB,"STRONG",{});var n7t=s(Lhe);BMo=r(n7t,"longt5"),n7t.forEach(t),IMo=r(QB," \u2014 "),BD=n(QB,"A",{href:!0});var s7t=s(BD);NMo=r(s7t,"T5Tokenizer"),s7t.forEach(t),qMo=r(QB," or "),ID=n(QB,"A",{href:!0});var l7t=s(ID);jMo=r(l7t,"T5TokenizerFast"),l7t.forEach(t),DMo=r(QB," (LongT5 model)"),QB.forEach(t),GMo=i(S),yu=n(S,"LI",{});var sNe=s(yu);yhe=n(sNe,"STRONG",{});var i7t=s(yhe);OMo=r(i7t,"luke"),i7t.forEach(t),VMo=r(sNe," \u2014 "),ND=n(sNe,"A",{href:!0});var d7t=s(ND);XMo=r(d7t,"LukeTokenizer"),d7t.forEach(t),zMo=r(sNe," (LUKE model)"),sNe.forEach(t),QMo=i(S),Xs=n(S,"LI",{});var WB=s(Xs);xhe=n(WB,"STRONG",{});var c7t=s(xhe);WMo=r(c7t,"lxmert"),c7t.forEach(t),UMo=r(WB," \u2014 "),qD=n(WB,"A",{href:!0});var m7t=s(qD);HMo=r(m7t,"LxmertTokenizer"),m7t.forEach(t),JMo=r(WB," or "),jD=n(WB,"A",{href:!0});var f7t=s(jD);YMo=r(f7t,"LxmertTokenizerFast"),f7t.forEach(t),ZMo=r(WB," (LXMERT model)"),WB.forEach(t),KMo=i(S),xu=n(S,"LI",{});var lNe=s(xu);$he=n(lNe,"STRONG",{});var g7t=s($he);eEo=r(g7t,"m2m_100"),g7t.forEach(t),oEo=r(lNe," \u2014 "),DD=n(lNe,"A",{href:!0});var h7t=s(DD);rEo=r(h7t,"M2M100Tokenizer"),h7t.forEach(t),tEo=r(lNe," (M2M100 model)"),lNe.forEach(t),aEo=i(S),$u=n(S,"LI",{});var iNe=s($u);khe=n(iNe,"STRONG",{});var u7t=s(khe);nEo=r(u7t,"marian"),u7t.forEach(t),sEo=r(iNe," \u2014 "),GD=n(iNe,"A",{href:!0});var p7t=s(GD);lEo=r(p7t,"MarianTokenizer"),p7t.forEach(t),iEo=r(iNe," (Marian model)"),iNe.forEach(t),dEo=i(S),zs=n(S,"LI",{});var UB=s(zs);She=n(UB,"STRONG",{});var _7t=s(She);cEo=r(_7t,"mbart"),_7t.forEach(t),mEo=r(UB," \u2014 "),OD=n(UB,"A",{href:!0});var b7t=s(OD);fEo=r(b7t,"MBartTokenizer"),b7t.forEach(t),gEo=r(UB," or "),VD=n(UB,"A",{href:!0});var v7t=s(VD);hEo=r(v7t,"MBartTokenizerFast"),v7t.forEach(t),uEo=r(UB," (mBART model)"),UB.forEach(t),pEo=i(S),Qs=n(S,"LI",{});var HB=s(Qs);Rhe=n(HB,"STRONG",{});var F7t=s(Rhe);_Eo=r(F7t,"mbart50"),F7t.forEach(t),bEo=r(HB," \u2014 "),XD=n(HB,"A",{href:!0});var T7t=s(XD);vEo=r(T7t,"MBart50Tokenizer"),T7t.forEach(t),FEo=r(HB," or "),zD=n(HB,"A",{href:!0});var M7t=s(zD);TEo=r(M7t,"MBart50TokenizerFast"),M7t.forEach(t),MEo=r(HB," (mBART-50 model)"),HB.forEach(t),EEo=i(S),Ws=n(S,"LI",{});var JB=s(Ws);Phe=n(JB,"STRONG",{});var E7t=s(Phe);CEo=r(E7t,"megatron-bert"),E7t.forEach(t),wEo=r(JB," \u2014 "),QD=n(JB,"A",{href:!0});var C7t=s(QD);AEo=r(C7t,"BertTokenizer"),C7t.forEach(t),LEo=r(JB," or "),WD=n(JB,"A",{href:!0});var w7t=s(WD);yEo=r(w7t,"BertTokenizerFast"),w7t.forEach(t),xEo=r(JB," (Megatron-BERT model)"),JB.forEach(t),$Eo=i(S),ku=n(S,"LI",{});var dNe=s(ku);Bhe=n(dNe,"STRONG",{});var A7t=s(Bhe);kEo=r(A7t,"mluke"),A7t.forEach(t),SEo=r(dNe," \u2014 "),UD=n(dNe,"A",{href:!0});var L7t=s(UD);REo=r(L7t,"MLukeTokenizer"),L7t.forEach(t),PEo=r(dNe," (mLUKE model)"),dNe.forEach(t),BEo=i(S),Us=n(S,"LI",{});var YB=s(Us);Ihe=n(YB,"STRONG",{});var y7t=s(Ihe);IEo=r(y7t,"mobilebert"),y7t.forEach(t),NEo=r(YB," \u2014 "),HD=n(YB,"A",{href:!0});var x7t=s(HD);qEo=r(x7t,"MobileBertTokenizer"),x7t.forEach(t),jEo=r(YB," or "),JD=n(YB,"A",{href:!0});var $7t=s(JD);DEo=r($7t,"MobileBertTokenizerFast"),$7t.forEach(t),GEo=r(YB," (MobileBERT model)"),YB.forEach(t),OEo=i(S),Hs=n(S,"LI",{});var ZB=s(Hs);Nhe=n(ZB,"STRONG",{});var k7t=s(Nhe);VEo=r(k7t,"mpnet"),k7t.forEach(t),XEo=r(ZB," \u2014 "),YD=n(ZB,"A",{href:!0});var S7t=s(YD);zEo=r(S7t,"MPNetTokenizer"),S7t.forEach(t),QEo=r(ZB," or "),ZD=n(ZB,"A",{href:!0});var R7t=s(ZD);WEo=r(R7t,"MPNetTokenizerFast"),R7t.forEach(t),UEo=r(ZB," (MPNet model)"),ZB.forEach(t),HEo=i(S),Js=n(S,"LI",{});var KB=s(Js);qhe=n(KB,"STRONG",{});var P7t=s(qhe);JEo=r(P7t,"mt5"),P7t.forEach(t),YEo=r(KB," \u2014 "),KD=n(KB,"A",{href:!0});var B7t=s(KD);ZEo=r(B7t,"MT5Tokenizer"),B7t.forEach(t),KEo=r(KB," or "),eG=n(KB,"A",{href:!0});var I7t=s(eG);e4o=r(I7t,"MT5TokenizerFast"),I7t.forEach(t),o4o=r(KB," (MT5 model)"),KB.forEach(t),r4o=i(S),Ys=n(S,"LI",{});var eI=s(Ys);jhe=n(eI,"STRONG",{});var N7t=s(jhe);t4o=r(N7t,"mvp"),N7t.forEach(t),a4o=r(eI," \u2014 "),oG=n(eI,"A",{href:!0});var q7t=s(oG);n4o=r(q7t,"MvpTokenizer"),q7t.forEach(t),s4o=r(eI," or "),rG=n(eI,"A",{href:!0});var j7t=s(rG);l4o=r(j7t,"MvpTokenizerFast"),j7t.forEach(t),i4o=r(eI," (MVP model)"),eI.forEach(t),d4o=i(S),Zs=n(S,"LI",{});var oI=s(Zs);Dhe=n(oI,"STRONG",{});var D7t=s(Dhe);c4o=r(D7t,"nezha"),D7t.forEach(t),m4o=r(oI," \u2014 "),tG=n(oI,"A",{href:!0});var G7t=s(tG);f4o=r(G7t,"BertTokenizer"),G7t.forEach(t),g4o=r(oI," or "),aG=n(oI,"A",{href:!0});var O7t=s(aG);h4o=r(O7t,"BertTokenizerFast"),O7t.forEach(t),u4o=r(oI," (Nezha model)"),oI.forEach(t),p4o=i(S),Ks=n(S,"LI",{});var rI=s(Ks);Ghe=n(rI,"STRONG",{});var V7t=s(Ghe);_4o=r(V7t,"nllb"),V7t.forEach(t),b4o=r(rI," \u2014 "),nG=n(rI,"A",{href:!0});var X7t=s(nG);v4o=r(X7t,"NllbTokenizer"),X7t.forEach(t),F4o=r(rI," or "),sG=n(rI,"A",{href:!0});var z7t=s(sG);T4o=r(z7t,"NllbTokenizerFast"),z7t.forEach(t),M4o=r(rI," (NLLB model)"),rI.forEach(t),E4o=i(S),el=n(S,"LI",{});var tI=s(el);Ohe=n(tI,"STRONG",{});var Q7t=s(Ohe);C4o=r(Q7t,"nystromformer"),Q7t.forEach(t),w4o=r(tI," \u2014 "),lG=n(tI,"A",{href:!0});var W7t=s(lG);A4o=r(W7t,"AlbertTokenizer"),W7t.forEach(t),L4o=r(tI," or "),iG=n(tI,"A",{href:!0});var U7t=s(iG);y4o=r(U7t,"AlbertTokenizerFast"),U7t.forEach(t),x4o=r(tI," (Nystr\xF6mformer model)"),tI.forEach(t),$4o=i(S),ol=n(S,"LI",{});var aI=s(ol);Vhe=n(aI,"STRONG",{});var H7t=s(Vhe);k4o=r(H7t,"openai-gpt"),H7t.forEach(t),S4o=r(aI," \u2014 "),dG=n(aI,"A",{href:!0});var J7t=s(dG);R4o=r(J7t,"OpenAIGPTTokenizer"),J7t.forEach(t),P4o=r(aI," or "),cG=n(aI,"A",{href:!0});var Y7t=s(cG);B4o=r(Y7t,"OpenAIGPTTokenizerFast"),Y7t.forEach(t),I4o=r(aI," (OpenAI GPT model)"),aI.forEach(t),N4o=i(S),Su=n(S,"LI",{});var cNe=s(Su);Xhe=n(cNe,"STRONG",{});var Z7t=s(Xhe);q4o=r(Z7t,"opt"),Z7t.forEach(t),j4o=r(cNe," \u2014 "),mG=n(cNe,"A",{href:!0});var K7t=s(mG);D4o=r(K7t,"GPT2Tokenizer"),K7t.forEach(t),G4o=r(cNe," (OPT model)"),cNe.forEach(t),O4o=i(S),rl=n(S,"LI",{});var nI=s(rl);zhe=n(nI,"STRONG",{});var eLt=s(zhe);V4o=r(eLt,"owlvit"),eLt.forEach(t),X4o=r(nI," \u2014 "),fG=n(nI,"A",{href:!0});var oLt=s(fG);z4o=r(oLt,"CLIPTokenizer"),oLt.forEach(t),Q4o=r(nI," or "),gG=n(nI,"A",{href:!0});var rLt=s(gG);W4o=r(rLt,"CLIPTokenizerFast"),rLt.forEach(t),U4o=r(nI," (OWL-ViT model)"),nI.forEach(t),H4o=i(S),tl=n(S,"LI",{});var sI=s(tl);Qhe=n(sI,"STRONG",{});var tLt=s(Qhe);J4o=r(tLt,"pegasus"),tLt.forEach(t),Y4o=r(sI," \u2014 "),hG=n(sI,"A",{href:!0});var aLt=s(hG);Z4o=r(aLt,"PegasusTokenizer"),aLt.forEach(t),K4o=r(sI," or "),uG=n(sI,"A",{href:!0});var nLt=s(uG);eCo=r(nLt,"PegasusTokenizerFast"),nLt.forEach(t),oCo=r(sI," (Pegasus model)"),sI.forEach(t),rCo=i(S),Ru=n(S,"LI",{});var mNe=s(Ru);Whe=n(mNe,"STRONG",{});var sLt=s(Whe);tCo=r(sLt,"perceiver"),sLt.forEach(t),aCo=r(mNe," \u2014 "),pG=n(mNe,"A",{href:!0});var lLt=s(pG);nCo=r(lLt,"PerceiverTokenizer"),lLt.forEach(t),sCo=r(mNe," (Perceiver model)"),mNe.forEach(t),lCo=i(S),Pu=n(S,"LI",{});var fNe=s(Pu);Uhe=n(fNe,"STRONG",{});var iLt=s(Uhe);iCo=r(iLt,"phobert"),iLt.forEach(t),dCo=r(fNe," \u2014 "),_G=n(fNe,"A",{href:!0});var dLt=s(_G);cCo=r(dLt,"PhobertTokenizer"),dLt.forEach(t),mCo=r(fNe," (PhoBERT model)"),fNe.forEach(t),fCo=i(S),Bu=n(S,"LI",{});var gNe=s(Bu);Hhe=n(gNe,"STRONG",{});var cLt=s(Hhe);gCo=r(cLt,"plbart"),cLt.forEach(t),hCo=r(gNe," \u2014 "),bG=n(gNe,"A",{href:!0});var mLt=s(bG);uCo=r(mLt,"PLBartTokenizer"),mLt.forEach(t),pCo=r(gNe," (PLBart model)"),gNe.forEach(t),_Co=i(S),Iu=n(S,"LI",{});var hNe=s(Iu);Jhe=n(hNe,"STRONG",{});var fLt=s(Jhe);bCo=r(fLt,"prophetnet"),fLt.forEach(t),vCo=r(hNe," \u2014 "),vG=n(hNe,"A",{href:!0});var gLt=s(vG);FCo=r(gLt,"ProphetNetTokenizer"),gLt.forEach(t),TCo=r(hNe," (ProphetNet model)"),hNe.forEach(t),MCo=i(S),al=n(S,"LI",{});var lI=s(al);Yhe=n(lI,"STRONG",{});var hLt=s(Yhe);ECo=r(hLt,"qdqbert"),hLt.forEach(t),CCo=r(lI," \u2014 "),FG=n(lI,"A",{href:!0});var uLt=s(FG);wCo=r(uLt,"BertTokenizer"),uLt.forEach(t),ACo=r(lI," or "),TG=n(lI,"A",{href:!0});var pLt=s(TG);LCo=r(pLt,"BertTokenizerFast"),pLt.forEach(t),yCo=r(lI," (QDQBert model)"),lI.forEach(t),xCo=i(S),Nu=n(S,"LI",{});var uNe=s(Nu);Zhe=n(uNe,"STRONG",{});var _Lt=s(Zhe);$Co=r(_Lt,"rag"),_Lt.forEach(t),kCo=r(uNe," \u2014 "),MG=n(uNe,"A",{href:!0});var bLt=s(MG);SCo=r(bLt,"RagTokenizer"),bLt.forEach(t),RCo=r(uNe," (RAG model)"),uNe.forEach(t),PCo=i(S),nl=n(S,"LI",{});var iI=s(nl);Khe=n(iI,"STRONG",{});var vLt=s(Khe);BCo=r(vLt,"realm"),vLt.forEach(t),ICo=r(iI," \u2014 "),EG=n(iI,"A",{href:!0});var FLt=s(EG);NCo=r(FLt,"RealmTokenizer"),FLt.forEach(t),qCo=r(iI," or "),CG=n(iI,"A",{href:!0});var TLt=s(CG);jCo=r(TLt,"RealmTokenizerFast"),TLt.forEach(t),DCo=r(iI," (REALM model)"),iI.forEach(t),GCo=i(S),sl=n(S,"LI",{});var dI=s(sl);eue=n(dI,"STRONG",{});var MLt=s(eue);OCo=r(MLt,"reformer"),MLt.forEach(t),VCo=r(dI," \u2014 "),wG=n(dI,"A",{href:!0});var ELt=s(wG);XCo=r(ELt,"ReformerTokenizer"),ELt.forEach(t),zCo=r(dI," or "),AG=n(dI,"A",{href:!0});var CLt=s(AG);QCo=r(CLt,"ReformerTokenizerFast"),CLt.forEach(t),WCo=r(dI," (Reformer model)"),dI.forEach(t),UCo=i(S),ll=n(S,"LI",{});var cI=s(ll);oue=n(cI,"STRONG",{});var wLt=s(oue);HCo=r(wLt,"rembert"),wLt.forEach(t),JCo=r(cI," \u2014 "),LG=n(cI,"A",{href:!0});var ALt=s(LG);YCo=r(ALt,"RemBertTokenizer"),ALt.forEach(t),ZCo=r(cI," or "),yG=n(cI,"A",{href:!0});var LLt=s(yG);KCo=r(LLt,"RemBertTokenizerFast"),LLt.forEach(t),e3o=r(cI," (RemBERT model)"),cI.forEach(t),o3o=i(S),il=n(S,"LI",{});var mI=s(il);rue=n(mI,"STRONG",{});var yLt=s(rue);r3o=r(yLt,"retribert"),yLt.forEach(t),t3o=r(mI," \u2014 "),xG=n(mI,"A",{href:!0});var xLt=s(xG);a3o=r(xLt,"RetriBertTokenizer"),xLt.forEach(t),n3o=r(mI," or "),$G=n(mI,"A",{href:!0});var $Lt=s($G);s3o=r($Lt,"RetriBertTokenizerFast"),$Lt.forEach(t),l3o=r(mI," (RetriBERT model)"),mI.forEach(t),i3o=i(S),dl=n(S,"LI",{});var fI=s(dl);tue=n(fI,"STRONG",{});var kLt=s(tue);d3o=r(kLt,"roberta"),kLt.forEach(t),c3o=r(fI," \u2014 "),kG=n(fI,"A",{href:!0});var SLt=s(kG);m3o=r(SLt,"RobertaTokenizer"),SLt.forEach(t),f3o=r(fI," or "),SG=n(fI,"A",{href:!0});var RLt=s(SG);g3o=r(RLt,"RobertaTokenizerFast"),RLt.forEach(t),h3o=r(fI," (RoBERTa model)"),fI.forEach(t),u3o=i(S),cl=n(S,"LI",{});var gI=s(cl);aue=n(gI,"STRONG",{});var PLt=s(aue);p3o=r(PLt,"roformer"),PLt.forEach(t),_3o=r(gI," \u2014 "),RG=n(gI,"A",{href:!0});var BLt=s(RG);b3o=r(BLt,"RoFormerTokenizer"),BLt.forEach(t),v3o=r(gI," or "),PG=n(gI,"A",{href:!0});var ILt=s(PG);F3o=r(ILt,"RoFormerTokenizerFast"),ILt.forEach(t),T3o=r(gI," (RoFormer model)"),gI.forEach(t),M3o=i(S),qu=n(S,"LI",{});var pNe=s(qu);nue=n(pNe,"STRONG",{});var NLt=s(nue);E3o=r(NLt,"speech_to_text"),NLt.forEach(t),C3o=r(pNe," \u2014 "),BG=n(pNe,"A",{href:!0});var qLt=s(BG);w3o=r(qLt,"Speech2TextTokenizer"),qLt.forEach(t),A3o=r(pNe," (Speech2Text model)"),pNe.forEach(t),L3o=i(S),ju=n(S,"LI",{});var _Ne=s(ju);sue=n(_Ne,"STRONG",{});var jLt=s(sue);y3o=r(jLt,"speech_to_text_2"),jLt.forEach(t),x3o=r(_Ne," \u2014 "),IG=n(_Ne,"A",{href:!0});var DLt=s(IG);$3o=r(DLt,"Speech2Text2Tokenizer"),DLt.forEach(t),k3o=r(_Ne," (Speech2Text2 model)"),_Ne.forEach(t),S3o=i(S),ml=n(S,"LI",{});var hI=s(ml);lue=n(hI,"STRONG",{});var GLt=s(lue);R3o=r(GLt,"splinter"),GLt.forEach(t),P3o=r(hI," \u2014 "),NG=n(hI,"A",{href:!0});var OLt=s(NG);B3o=r(OLt,"SplinterTokenizer"),OLt.forEach(t),I3o=r(hI," or "),qG=n(hI,"A",{href:!0});var VLt=s(qG);N3o=r(VLt,"SplinterTokenizerFast"),VLt.forEach(t),q3o=r(hI," (Splinter model)"),hI.forEach(t),j3o=i(S),fl=n(S,"LI",{});var uI=s(fl);iue=n(uI,"STRONG",{});var XLt=s(iue);D3o=r(XLt,"squeezebert"),XLt.forEach(t),G3o=r(uI," \u2014 "),jG=n(uI,"A",{href:!0});var zLt=s(jG);O3o=r(zLt,"SqueezeBertTokenizer"),zLt.forEach(t),V3o=r(uI," or "),DG=n(uI,"A",{href:!0});var QLt=s(DG);X3o=r(QLt,"SqueezeBertTokenizerFast"),QLt.forEach(t),z3o=r(uI," (SqueezeBERT model)"),uI.forEach(t),Q3o=i(S),gl=n(S,"LI",{});var pI=s(gl);due=n(pI,"STRONG",{});var WLt=s(due);W3o=r(WLt,"t5"),WLt.forEach(t),U3o=r(pI," \u2014 "),GG=n(pI,"A",{href:!0});var ULt=s(GG);H3o=r(ULt,"T5Tokenizer"),ULt.forEach(t),J3o=r(pI," or "),OG=n(pI,"A",{href:!0});var HLt=s(OG);Y3o=r(HLt,"T5TokenizerFast"),HLt.forEach(t),Z3o=r(pI," (T5 model)"),pI.forEach(t),K3o=i(S),Du=n(S,"LI",{});var bNe=s(Du);cue=n(bNe,"STRONG",{});var JLt=s(cue);e5o=r(JLt,"tapas"),JLt.forEach(t),o5o=r(bNe," \u2014 "),VG=n(bNe,"A",{href:!0});var YLt=s(VG);r5o=r(YLt,"TapasTokenizer"),YLt.forEach(t),t5o=r(bNe," (TAPAS model)"),bNe.forEach(t),a5o=i(S),Gu=n(S,"LI",{});var vNe=s(Gu);mue=n(vNe,"STRONG",{});var ZLt=s(mue);n5o=r(ZLt,"tapex"),ZLt.forEach(t),s5o=r(vNe," \u2014 "),XG=n(vNe,"A",{href:!0});var KLt=s(XG);l5o=r(KLt,"TapexTokenizer"),KLt.forEach(t),i5o=r(vNe," (TAPEX model)"),vNe.forEach(t),d5o=i(S),Ou=n(S,"LI",{});var FNe=s(Ou);fue=n(FNe,"STRONG",{});var eyt=s(fue);c5o=r(eyt,"transfo-xl"),eyt.forEach(t),m5o=r(FNe," \u2014 "),zG=n(FNe,"A",{href:!0});var oyt=s(zG);f5o=r(oyt,"TransfoXLTokenizer"),oyt.forEach(t),g5o=r(FNe," (Transformer-XL model)"),FNe.forEach(t),h5o=i(S),hl=n(S,"LI",{});var _I=s(hl);gue=n(_I,"STRONG",{});var ryt=s(gue);u5o=r(ryt,"vilt"),ryt.forEach(t),p5o=r(_I," \u2014 "),QG=n(_I,"A",{href:!0});var tyt=s(QG);_5o=r(tyt,"BertTokenizer"),tyt.forEach(t),b5o=r(_I," or "),WG=n(_I,"A",{href:!0});var ayt=s(WG);v5o=r(ayt,"BertTokenizerFast"),ayt.forEach(t),F5o=r(_I," (ViLT model)"),_I.forEach(t),T5o=i(S),ul=n(S,"LI",{});var bI=s(ul);hue=n(bI,"STRONG",{});var nyt=s(hue);M5o=r(nyt,"visual_bert"),nyt.forEach(t),E5o=r(bI," \u2014 "),UG=n(bI,"A",{href:!0});var syt=s(UG);C5o=r(syt,"BertTokenizer"),syt.forEach(t),w5o=r(bI," or "),HG=n(bI,"A",{href:!0});var lyt=s(HG);A5o=r(lyt,"BertTokenizerFast"),lyt.forEach(t),L5o=r(bI," (VisualBERT model)"),bI.forEach(t),y5o=i(S),Vu=n(S,"LI",{});var TNe=s(Vu);uue=n(TNe,"STRONG",{});var iyt=s(uue);x5o=r(iyt,"wav2vec2"),iyt.forEach(t),$5o=r(TNe," \u2014 "),JG=n(TNe,"A",{href:!0});var dyt=s(JG);k5o=r(dyt,"Wav2Vec2CTCTokenizer"),dyt.forEach(t),S5o=r(TNe," (Wav2Vec2 model)"),TNe.forEach(t),R5o=i(S),Xu=n(S,"LI",{});var MNe=s(Xu);pue=n(MNe,"STRONG",{});var cyt=s(pue);P5o=r(cyt,"wav2vec2-conformer"),cyt.forEach(t),B5o=r(MNe," \u2014 "),YG=n(MNe,"A",{href:!0});var myt=s(YG);I5o=r(myt,"Wav2Vec2CTCTokenizer"),myt.forEach(t),N5o=r(MNe," (Wav2Vec2-Conformer model)"),MNe.forEach(t),q5o=i(S),zu=n(S,"LI",{});var ENe=s(zu);_ue=n(ENe,"STRONG",{});var fyt=s(_ue);j5o=r(fyt,"wav2vec2_phoneme"),fyt.forEach(t),D5o=r(ENe," \u2014 "),ZG=n(ENe,"A",{href:!0});var gyt=s(ZG);G5o=r(gyt,"Wav2Vec2PhonemeCTCTokenizer"),gyt.forEach(t),O5o=r(ENe," (Wav2Vec2Phoneme model)"),ENe.forEach(t),V5o=i(S),Qu=n(S,"LI",{});var CNe=s(Qu);bue=n(CNe,"STRONG",{});var hyt=s(bue);X5o=r(hyt,"whisper"),hyt.forEach(t),z5o=r(CNe," \u2014 "),KG=n(CNe,"A",{href:!0});var uyt=s(KG);Q5o=r(uyt,"WhisperTokenizer"),uyt.forEach(t),W5o=r(CNe," (Whisper model)"),CNe.forEach(t),U5o=i(S),pl=n(S,"LI",{});var vI=s(pl);vue=n(vI,"STRONG",{});var pyt=s(vue);H5o=r(pyt,"xclip"),pyt.forEach(t),J5o=r(vI," \u2014 "),eO=n(vI,"A",{href:!0});var _yt=s(eO);Y5o=r(_yt,"CLIPTokenizer"),_yt.forEach(t),Z5o=r(vI," or "),oO=n(vI,"A",{href:!0});var byt=s(oO);K5o=r(byt,"CLIPTokenizerFast"),byt.forEach(t),e0o=r(vI," (X-CLIP model)"),vI.forEach(t),o0o=i(S),_l=n(S,"LI",{});var FI=s(_l);Fue=n(FI,"STRONG",{});var vyt=s(Fue);r0o=r(vyt,"xglm"),vyt.forEach(t),t0o=r(FI," \u2014 "),rO=n(FI,"A",{href:!0});var Fyt=s(rO);a0o=r(Fyt,"XGLMTokenizer"),Fyt.forEach(t),n0o=r(FI," or "),tO=n(FI,"A",{href:!0});var Tyt=s(tO);s0o=r(Tyt,"XGLMTokenizerFast"),Tyt.forEach(t),l0o=r(FI," (XGLM model)"),FI.forEach(t),i0o=i(S),Wu=n(S,"LI",{});var wNe=s(Wu);Tue=n(wNe,"STRONG",{});var Myt=s(Tue);d0o=r(Myt,"xlm"),Myt.forEach(t),c0o=r(wNe," \u2014 "),aO=n(wNe,"A",{href:!0});var Eyt=s(aO);m0o=r(Eyt,"XLMTokenizer"),Eyt.forEach(t),f0o=r(wNe," (XLM model)"),wNe.forEach(t),g0o=i(S),Uu=n(S,"LI",{});var ANe=s(Uu);Mue=n(ANe,"STRONG",{});var Cyt=s(Mue);h0o=r(Cyt,"xlm-prophetnet"),Cyt.forEach(t),u0o=r(ANe," \u2014 "),nO=n(ANe,"A",{href:!0});var wyt=s(nO);p0o=r(wyt,"XLMProphetNetTokenizer"),wyt.forEach(t),_0o=r(ANe," (XLM-ProphetNet model)"),ANe.forEach(t),b0o=i(S),bl=n(S,"LI",{});var TI=s(bl);Eue=n(TI,"STRONG",{});var Ayt=s(Eue);v0o=r(Ayt,"xlm-roberta"),Ayt.forEach(t),F0o=r(TI," \u2014 "),sO=n(TI,"A",{href:!0});var Lyt=s(sO);T0o=r(Lyt,"XLMRobertaTokenizer"),Lyt.forEach(t),M0o=r(TI," or "),lO=n(TI,"A",{href:!0});var yyt=s(lO);E0o=r(yyt,"XLMRobertaTokenizerFast"),yyt.forEach(t),C0o=r(TI," (XLM-RoBERTa model)"),TI.forEach(t),w0o=i(S),vl=n(S,"LI",{});var MI=s(vl);Cue=n(MI,"STRONG",{});var xyt=s(Cue);A0o=r(xyt,"xlm-roberta-xl"),xyt.forEach(t),L0o=r(MI," \u2014 "),iO=n(MI,"A",{href:!0});var $yt=s(iO);y0o=r($yt,"XLMRobertaTokenizer"),$yt.forEach(t),x0o=r(MI," or "),dO=n(MI,"A",{href:!0});var kyt=s(dO);$0o=r(kyt,"XLMRobertaTokenizerFast"),kyt.forEach(t),k0o=r(MI," (XLM-RoBERTa-XL model)"),MI.forEach(t),S0o=i(S),Fl=n(S,"LI",{});var EI=s(Fl);wue=n(EI,"STRONG",{});var Syt=s(wue);R0o=r(Syt,"xlnet"),Syt.forEach(t),P0o=r(EI," \u2014 "),cO=n(EI,"A",{href:!0});var Ryt=s(cO);B0o=r(Ryt,"XLNetTokenizer"),Ryt.forEach(t),I0o=r(EI," or "),mO=n(EI,"A",{href:!0});var Pyt=s(mO);N0o=r(Pyt,"XLNetTokenizerFast"),Pyt.forEach(t),q0o=r(EI," (XLNet model)"),EI.forEach(t),j0o=i(S),Tl=n(S,"LI",{});var CI=s(Tl);Aue=n(CI,"STRONG",{});var Byt=s(Aue);D0o=r(Byt,"yoso"),Byt.forEach(t),G0o=r(CI," \u2014 "),fO=n(CI,"A",{href:!0});var Iyt=s(fO);O0o=r(Iyt,"AlbertTokenizer"),Iyt.forEach(t),V0o=r(CI," or "),gO=n(CI,"A",{href:!0});var Nyt=s(gO);X0o=r(Nyt,"AlbertTokenizerFast"),Nyt.forEach(t),z0o=r(CI," (YOSO model)"),CI.forEach(t),S.forEach(t),Q0o=i(yl),T(Hu.$$.fragment,yl),yl.forEach(t),W0o=i(Ll),Ju=n(Ll,"DIV",{class:!0});var yto=s(Ju);T(jx.$$.fragment,yto),U0o=i(yto),Lue=n(yto,"P",{});var qyt=s(Lue);H0o=r(qyt,"Register a new tokenizer in this mapping."),qyt.forEach(t),yto.forEach(t),Ll.forEach(t),_oo=i(m),Fd=n(m,"H2",{class:!0});var xto=s(Fd);Yu=n(xto,"A",{id:!0,class:!0,href:!0});var jyt=s(Yu);yue=n(jyt,"SPAN",{});var Dyt=s(yue);T(Dx.$$.fragment,Dyt),Dyt.forEach(t),jyt.forEach(t),J0o=i(xto),xue=n(xto,"SPAN",{});var Gyt=s(xue);Y0o=r(Gyt,"AutoFeatureExtractor"),Gyt.forEach(t),xto.forEach(t),boo=i(m),Ro=n(m,"DIV",{class:!0});var xl=s(Ro);T(Gx.$$.fragment,xl),Z0o=i(xl),Ox=n(xl,"P",{});var $to=s(Ox);K0o=r($to,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),hO=n($to,"A",{href:!0});var Oyt=s(hO);ewo=r(Oyt,"AutoFeatureExtractor.from_pretrained()"),Oyt.forEach(t),owo=r($to," class method."),$to.forEach(t),rwo=i(xl),Vx=n(xl,"P",{});var kto=s(Vx);two=r(kto,"This class cannot be instantiated directly using "),$ue=n(kto,"CODE",{});var Vyt=s($ue);awo=r(Vyt,"__init__()"),Vyt.forEach(t),nwo=r(kto," (throws an error)."),kto.forEach(t),swo=i(xl),Ye=n(xl,"DIV",{class:!0});var Ta=s(Ye);T(Xx.$$.fragment,Ta),lwo=i(Ta),kue=n(Ta,"P",{});var Xyt=s(kue);iwo=r(Xyt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Xyt.forEach(t),dwo=i(Ta),Ka=n(Ta,"P",{});var _8=s(Ka);cwo=r(_8,"The feature extractor class to instantiate is selected based on the "),Sue=n(_8,"CODE",{});var zyt=s(Sue);mwo=r(zyt,"model_type"),zyt.forEach(t),fwo=r(_8,` property of the config object
(either passed as an argument or loaded from `),Rue=n(_8,"CODE",{});var Qyt=s(Rue);gwo=r(Qyt,"pretrained_model_name_or_path"),Qyt.forEach(t),hwo=r(_8,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Pue=n(_8,"CODE",{});var Wyt=s(Pue);uwo=r(Wyt,"pretrained_model_name_or_path"),Wyt.forEach(t),pwo=r(_8,":"),_8.forEach(t),_wo=i(Ta),z=n(Ta,"UL",{});var W=s(z);Zu=n(W,"LI",{});var LNe=s(Zu);Bue=n(LNe,"STRONG",{});var Uyt=s(Bue);bwo=r(Uyt,"beit"),Uyt.forEach(t),vwo=r(LNe," \u2014 "),uO=n(LNe,"A",{href:!0});var Hyt=s(uO);Fwo=r(Hyt,"BeitFeatureExtractor"),Hyt.forEach(t),Two=r(LNe," (BEiT model)"),LNe.forEach(t),Mwo=i(W),Ku=n(W,"LI",{});var yNe=s(Ku);Iue=n(yNe,"STRONG",{});var Jyt=s(Iue);Ewo=r(Jyt,"clip"),Jyt.forEach(t),Cwo=r(yNe," \u2014 "),pO=n(yNe,"A",{href:!0});var Yyt=s(pO);wwo=r(Yyt,"CLIPFeatureExtractor"),Yyt.forEach(t),Awo=r(yNe," (CLIP model)"),yNe.forEach(t),Lwo=i(W),ep=n(W,"LI",{});var xNe=s(ep);Nue=n(xNe,"STRONG",{});var Zyt=s(Nue);ywo=r(Zyt,"conditional_detr"),Zyt.forEach(t),xwo=r(xNe," \u2014 "),_O=n(xNe,"A",{href:!0});var Kyt=s(_O);$wo=r(Kyt,"ConditionalDetrFeatureExtractor"),Kyt.forEach(t),kwo=r(xNe," (Conditional DETR model)"),xNe.forEach(t),Swo=i(W),op=n(W,"LI",{});var $Ne=s(op);que=n($Ne,"STRONG",{});var e8t=s(que);Rwo=r(e8t,"convnext"),e8t.forEach(t),Pwo=r($Ne," \u2014 "),bO=n($Ne,"A",{href:!0});var o8t=s(bO);Bwo=r(o8t,"ConvNextFeatureExtractor"),o8t.forEach(t),Iwo=r($Ne," (ConvNeXT model)"),$Ne.forEach(t),Nwo=i(W),rp=n(W,"LI",{});var kNe=s(rp);jue=n(kNe,"STRONG",{});var r8t=s(jue);qwo=r(r8t,"cvt"),r8t.forEach(t),jwo=r(kNe," \u2014 "),vO=n(kNe,"A",{href:!0});var t8t=s(vO);Dwo=r(t8t,"ConvNextFeatureExtractor"),t8t.forEach(t),Gwo=r(kNe," (CvT model)"),kNe.forEach(t),Owo=i(W),tp=n(W,"LI",{});var SNe=s(tp);Due=n(SNe,"STRONG",{});var a8t=s(Due);Vwo=r(a8t,"data2vec-audio"),a8t.forEach(t),Xwo=r(SNe," \u2014 "),FO=n(SNe,"A",{href:!0});var n8t=s(FO);zwo=r(n8t,"Wav2Vec2FeatureExtractor"),n8t.forEach(t),Qwo=r(SNe," (Data2VecAudio model)"),SNe.forEach(t),Wwo=i(W),ap=n(W,"LI",{});var RNe=s(ap);Gue=n(RNe,"STRONG",{});var s8t=s(Gue);Uwo=r(s8t,"data2vec-vision"),s8t.forEach(t),Hwo=r(RNe," \u2014 "),TO=n(RNe,"A",{href:!0});var l8t=s(TO);Jwo=r(l8t,"BeitFeatureExtractor"),l8t.forEach(t),Ywo=r(RNe," (Data2VecVision model)"),RNe.forEach(t),Zwo=i(W),np=n(W,"LI",{});var PNe=s(np);Oue=n(PNe,"STRONG",{});var i8t=s(Oue);Kwo=r(i8t,"deformable_detr"),i8t.forEach(t),eAo=r(PNe," \u2014 "),MO=n(PNe,"A",{href:!0});var d8t=s(MO);oAo=r(d8t,"DeformableDetrFeatureExtractor"),d8t.forEach(t),rAo=r(PNe," (Deformable DETR model)"),PNe.forEach(t),tAo=i(W),sp=n(W,"LI",{});var BNe=s(sp);Vue=n(BNe,"STRONG",{});var c8t=s(Vue);aAo=r(c8t,"deit"),c8t.forEach(t),nAo=r(BNe," \u2014 "),EO=n(BNe,"A",{href:!0});var m8t=s(EO);sAo=r(m8t,"DeiTFeatureExtractor"),m8t.forEach(t),lAo=r(BNe," (DeiT model)"),BNe.forEach(t),iAo=i(W),lp=n(W,"LI",{});var INe=s(lp);Xue=n(INe,"STRONG",{});var f8t=s(Xue);dAo=r(f8t,"detr"),f8t.forEach(t),cAo=r(INe," \u2014 "),CO=n(INe,"A",{href:!0});var g8t=s(CO);mAo=r(g8t,"DetrFeatureExtractor"),g8t.forEach(t),fAo=r(INe," (DETR model)"),INe.forEach(t),gAo=i(W),ip=n(W,"LI",{});var NNe=s(ip);zue=n(NNe,"STRONG",{});var h8t=s(zue);hAo=r(h8t,"donut"),h8t.forEach(t),uAo=r(NNe," \u2014 "),wO=n(NNe,"A",{href:!0});var u8t=s(wO);pAo=r(u8t,"DonutFeatureExtractor"),u8t.forEach(t),_Ao=r(NNe," (Donut model)"),NNe.forEach(t),bAo=i(W),dp=n(W,"LI",{});var qNe=s(dp);Que=n(qNe,"STRONG",{});var p8t=s(Que);vAo=r(p8t,"dpt"),p8t.forEach(t),FAo=r(qNe," \u2014 "),AO=n(qNe,"A",{href:!0});var _8t=s(AO);TAo=r(_8t,"DPTFeatureExtractor"),_8t.forEach(t),MAo=r(qNe," (DPT model)"),qNe.forEach(t),EAo=i(W),cp=n(W,"LI",{});var jNe=s(cp);Wue=n(jNe,"STRONG",{});var b8t=s(Wue);CAo=r(b8t,"flava"),b8t.forEach(t),wAo=r(jNe," \u2014 "),LO=n(jNe,"A",{href:!0});var v8t=s(LO);AAo=r(v8t,"FlavaFeatureExtractor"),v8t.forEach(t),LAo=r(jNe," (FLAVA model)"),jNe.forEach(t),yAo=i(W),mp=n(W,"LI",{});var DNe=s(mp);Uue=n(DNe,"STRONG",{});var F8t=s(Uue);xAo=r(F8t,"glpn"),F8t.forEach(t),$Ao=r(DNe," \u2014 "),yO=n(DNe,"A",{href:!0});var T8t=s(yO);kAo=r(T8t,"GLPNFeatureExtractor"),T8t.forEach(t),SAo=r(DNe," (GLPN model)"),DNe.forEach(t),RAo=i(W),fp=n(W,"LI",{});var GNe=s(fp);Hue=n(GNe,"STRONG",{});var M8t=s(Hue);PAo=r(M8t,"groupvit"),M8t.forEach(t),BAo=r(GNe," \u2014 "),xO=n(GNe,"A",{href:!0});var E8t=s(xO);IAo=r(E8t,"CLIPFeatureExtractor"),E8t.forEach(t),NAo=r(GNe," (GroupViT model)"),GNe.forEach(t),qAo=i(W),gp=n(W,"LI",{});var ONe=s(gp);Jue=n(ONe,"STRONG",{});var C8t=s(Jue);jAo=r(C8t,"hubert"),C8t.forEach(t),DAo=r(ONe," \u2014 "),$O=n(ONe,"A",{href:!0});var w8t=s($O);GAo=r(w8t,"Wav2Vec2FeatureExtractor"),w8t.forEach(t),OAo=r(ONe," (Hubert model)"),ONe.forEach(t),VAo=i(W),hp=n(W,"LI",{});var VNe=s(hp);Yue=n(VNe,"STRONG",{});var A8t=s(Yue);XAo=r(A8t,"imagegpt"),A8t.forEach(t),zAo=r(VNe," \u2014 "),kO=n(VNe,"A",{href:!0});var L8t=s(kO);QAo=r(L8t,"ImageGPTFeatureExtractor"),L8t.forEach(t),WAo=r(VNe," (ImageGPT model)"),VNe.forEach(t),UAo=i(W),up=n(W,"LI",{});var XNe=s(up);Zue=n(XNe,"STRONG",{});var y8t=s(Zue);HAo=r(y8t,"layoutlmv2"),y8t.forEach(t),JAo=r(XNe," \u2014 "),SO=n(XNe,"A",{href:!0});var x8t=s(SO);YAo=r(x8t,"LayoutLMv2FeatureExtractor"),x8t.forEach(t),ZAo=r(XNe," (LayoutLMv2 model)"),XNe.forEach(t),KAo=i(W),pp=n(W,"LI",{});var zNe=s(pp);Kue=n(zNe,"STRONG",{});var $8t=s(Kue);e6o=r($8t,"layoutlmv3"),$8t.forEach(t),o6o=r(zNe," \u2014 "),RO=n(zNe,"A",{href:!0});var k8t=s(RO);r6o=r(k8t,"LayoutLMv3FeatureExtractor"),k8t.forEach(t),t6o=r(zNe," (LayoutLMv3 model)"),zNe.forEach(t),a6o=i(W),_p=n(W,"LI",{});var QNe=s(_p);epe=n(QNe,"STRONG",{});var S8t=s(epe);n6o=r(S8t,"levit"),S8t.forEach(t),s6o=r(QNe," \u2014 "),PO=n(QNe,"A",{href:!0});var R8t=s(PO);l6o=r(R8t,"LevitFeatureExtractor"),R8t.forEach(t),i6o=r(QNe," (LeViT model)"),QNe.forEach(t),d6o=i(W),bp=n(W,"LI",{});var WNe=s(bp);ope=n(WNe,"STRONG",{});var P8t=s(ope);c6o=r(P8t,"maskformer"),P8t.forEach(t),m6o=r(WNe," \u2014 "),BO=n(WNe,"A",{href:!0});var B8t=s(BO);f6o=r(B8t,"MaskFormerFeatureExtractor"),B8t.forEach(t),g6o=r(WNe," (MaskFormer model)"),WNe.forEach(t),h6o=i(W),vp=n(W,"LI",{});var UNe=s(vp);rpe=n(UNe,"STRONG",{});var I8t=s(rpe);u6o=r(I8t,"mctct"),I8t.forEach(t),p6o=r(UNe," \u2014 "),IO=n(UNe,"A",{href:!0});var N8t=s(IO);_6o=r(N8t,"MCTCTFeatureExtractor"),N8t.forEach(t),b6o=r(UNe," (M-CTC-T model)"),UNe.forEach(t),v6o=i(W),Fp=n(W,"LI",{});var HNe=s(Fp);tpe=n(HNe,"STRONG",{});var q8t=s(tpe);F6o=r(q8t,"mobilevit"),q8t.forEach(t),T6o=r(HNe," \u2014 "),NO=n(HNe,"A",{href:!0});var j8t=s(NO);M6o=r(j8t,"MobileViTFeatureExtractor"),j8t.forEach(t),E6o=r(HNe," (MobileViT model)"),HNe.forEach(t),C6o=i(W),Tp=n(W,"LI",{});var JNe=s(Tp);ape=n(JNe,"STRONG",{});var D8t=s(ape);w6o=r(D8t,"owlvit"),D8t.forEach(t),A6o=r(JNe," \u2014 "),qO=n(JNe,"A",{href:!0});var G8t=s(qO);L6o=r(G8t,"OwlViTFeatureExtractor"),G8t.forEach(t),y6o=r(JNe," (OWL-ViT model)"),JNe.forEach(t),x6o=i(W),Mp=n(W,"LI",{});var YNe=s(Mp);npe=n(YNe,"STRONG",{});var O8t=s(npe);$6o=r(O8t,"perceiver"),O8t.forEach(t),k6o=r(YNe," \u2014 "),jO=n(YNe,"A",{href:!0});var V8t=s(jO);S6o=r(V8t,"PerceiverFeatureExtractor"),V8t.forEach(t),R6o=r(YNe," (Perceiver model)"),YNe.forEach(t),P6o=i(W),Ep=n(W,"LI",{});var ZNe=s(Ep);spe=n(ZNe,"STRONG",{});var X8t=s(spe);B6o=r(X8t,"poolformer"),X8t.forEach(t),I6o=r(ZNe," \u2014 "),DO=n(ZNe,"A",{href:!0});var z8t=s(DO);N6o=r(z8t,"PoolFormerFeatureExtractor"),z8t.forEach(t),q6o=r(ZNe," (PoolFormer model)"),ZNe.forEach(t),j6o=i(W),Cp=n(W,"LI",{});var KNe=s(Cp);lpe=n(KNe,"STRONG",{});var Q8t=s(lpe);D6o=r(Q8t,"regnet"),Q8t.forEach(t),G6o=r(KNe," \u2014 "),GO=n(KNe,"A",{href:!0});var W8t=s(GO);O6o=r(W8t,"ConvNextFeatureExtractor"),W8t.forEach(t),V6o=r(KNe," (RegNet model)"),KNe.forEach(t),X6o=i(W),wp=n(W,"LI",{});var eqe=s(wp);ipe=n(eqe,"STRONG",{});var U8t=s(ipe);z6o=r(U8t,"resnet"),U8t.forEach(t),Q6o=r(eqe," \u2014 "),OO=n(eqe,"A",{href:!0});var H8t=s(OO);W6o=r(H8t,"ConvNextFeatureExtractor"),H8t.forEach(t),U6o=r(eqe," (ResNet model)"),eqe.forEach(t),H6o=i(W),Ap=n(W,"LI",{});var oqe=s(Ap);dpe=n(oqe,"STRONG",{});var J8t=s(dpe);J6o=r(J8t,"segformer"),J8t.forEach(t),Y6o=r(oqe," \u2014 "),VO=n(oqe,"A",{href:!0});var Y8t=s(VO);Z6o=r(Y8t,"SegformerFeatureExtractor"),Y8t.forEach(t),K6o=r(oqe," (SegFormer model)"),oqe.forEach(t),e7o=i(W),Lp=n(W,"LI",{});var rqe=s(Lp);cpe=n(rqe,"STRONG",{});var Z8t=s(cpe);o7o=r(Z8t,"speech_to_text"),Z8t.forEach(t),r7o=r(rqe," \u2014 "),XO=n(rqe,"A",{href:!0});var K8t=s(XO);t7o=r(K8t,"Speech2TextFeatureExtractor"),K8t.forEach(t),a7o=r(rqe," (Speech2Text model)"),rqe.forEach(t),n7o=i(W),yp=n(W,"LI",{});var tqe=s(yp);mpe=n(tqe,"STRONG",{});var e9t=s(mpe);s7o=r(e9t,"swin"),e9t.forEach(t),l7o=r(tqe," \u2014 "),zO=n(tqe,"A",{href:!0});var o9t=s(zO);i7o=r(o9t,"ViTFeatureExtractor"),o9t.forEach(t),d7o=r(tqe," (Swin Transformer model)"),tqe.forEach(t),c7o=i(W),xp=n(W,"LI",{});var aqe=s(xp);fpe=n(aqe,"STRONG",{});var r9t=s(fpe);m7o=r(r9t,"swinv2"),r9t.forEach(t),f7o=r(aqe," \u2014 "),QO=n(aqe,"A",{href:!0});var t9t=s(QO);g7o=r(t9t,"ViTFeatureExtractor"),t9t.forEach(t),h7o=r(aqe," (Swin Transformer V2 model)"),aqe.forEach(t),u7o=i(W),$p=n(W,"LI",{});var nqe=s($p);gpe=n(nqe,"STRONG",{});var a9t=s(gpe);p7o=r(a9t,"van"),a9t.forEach(t),_7o=r(nqe," \u2014 "),WO=n(nqe,"A",{href:!0});var n9t=s(WO);b7o=r(n9t,"ConvNextFeatureExtractor"),n9t.forEach(t),v7o=r(nqe," (VAN model)"),nqe.forEach(t),F7o=i(W),kp=n(W,"LI",{});var sqe=s(kp);hpe=n(sqe,"STRONG",{});var s9t=s(hpe);T7o=r(s9t,"videomae"),s9t.forEach(t),M7o=r(sqe," \u2014 "),UO=n(sqe,"A",{href:!0});var l9t=s(UO);E7o=r(l9t,"VideoMAEFeatureExtractor"),l9t.forEach(t),C7o=r(sqe," (VideoMAE model)"),sqe.forEach(t),w7o=i(W),Sp=n(W,"LI",{});var lqe=s(Sp);upe=n(lqe,"STRONG",{});var i9t=s(upe);A7o=r(i9t,"vilt"),i9t.forEach(t),L7o=r(lqe," \u2014 "),HO=n(lqe,"A",{href:!0});var d9t=s(HO);y7o=r(d9t,"ViltFeatureExtractor"),d9t.forEach(t),x7o=r(lqe," (ViLT model)"),lqe.forEach(t),$7o=i(W),Rp=n(W,"LI",{});var iqe=s(Rp);ppe=n(iqe,"STRONG",{});var c9t=s(ppe);k7o=r(c9t,"vit"),c9t.forEach(t),S7o=r(iqe," \u2014 "),JO=n(iqe,"A",{href:!0});var m9t=s(JO);R7o=r(m9t,"ViTFeatureExtractor"),m9t.forEach(t),P7o=r(iqe," (ViT model)"),iqe.forEach(t),B7o=i(W),Pp=n(W,"LI",{});var dqe=s(Pp);_pe=n(dqe,"STRONG",{});var f9t=s(_pe);I7o=r(f9t,"vit_mae"),f9t.forEach(t),N7o=r(dqe," \u2014 "),YO=n(dqe,"A",{href:!0});var g9t=s(YO);q7o=r(g9t,"ViTFeatureExtractor"),g9t.forEach(t),j7o=r(dqe," (ViTMAE model)"),dqe.forEach(t),D7o=i(W),Bp=n(W,"LI",{});var cqe=s(Bp);bpe=n(cqe,"STRONG",{});var h9t=s(bpe);G7o=r(h9t,"vit_msn"),h9t.forEach(t),O7o=r(cqe," \u2014 "),ZO=n(cqe,"A",{href:!0});var u9t=s(ZO);V7o=r(u9t,"ViTFeatureExtractor"),u9t.forEach(t),X7o=r(cqe," (ViTMSN model)"),cqe.forEach(t),z7o=i(W),Ip=n(W,"LI",{});var mqe=s(Ip);vpe=n(mqe,"STRONG",{});var p9t=s(vpe);Q7o=r(p9t,"wav2vec2"),p9t.forEach(t),W7o=r(mqe," \u2014 "),KO=n(mqe,"A",{href:!0});var _9t=s(KO);U7o=r(_9t,"Wav2Vec2FeatureExtractor"),_9t.forEach(t),H7o=r(mqe," (Wav2Vec2 model)"),mqe.forEach(t),J7o=i(W),Np=n(W,"LI",{});var fqe=s(Np);Fpe=n(fqe,"STRONG",{});var b9t=s(Fpe);Y7o=r(b9t,"wav2vec2-conformer"),b9t.forEach(t),Z7o=r(fqe," \u2014 "),eV=n(fqe,"A",{href:!0});var v9t=s(eV);K7o=r(v9t,"Wav2Vec2FeatureExtractor"),v9t.forEach(t),eLo=r(fqe," (Wav2Vec2-Conformer model)"),fqe.forEach(t),oLo=i(W),qp=n(W,"LI",{});var gqe=s(qp);Tpe=n(gqe,"STRONG",{});var F9t=s(Tpe);rLo=r(F9t,"whisper"),F9t.forEach(t),tLo=r(gqe," \u2014 "),oV=n(gqe,"A",{href:!0});var T9t=s(oV);aLo=r(T9t,"WhisperFeatureExtractor"),T9t.forEach(t),nLo=r(gqe," (Whisper model)"),gqe.forEach(t),sLo=i(W),jp=n(W,"LI",{});var hqe=s(jp);Mpe=n(hqe,"STRONG",{});var M9t=s(Mpe);lLo=r(M9t,"xclip"),M9t.forEach(t),iLo=r(hqe," \u2014 "),rV=n(hqe,"A",{href:!0});var E9t=s(rV);dLo=r(E9t,"CLIPFeatureExtractor"),E9t.forEach(t),cLo=r(hqe," (X-CLIP model)"),hqe.forEach(t),mLo=i(W),Dp=n(W,"LI",{});var uqe=s(Dp);Epe=n(uqe,"STRONG",{});var C9t=s(Epe);fLo=r(C9t,"yolos"),C9t.forEach(t),gLo=r(uqe," \u2014 "),tV=n(uqe,"A",{href:!0});var w9t=s(tV);hLo=r(w9t,"YolosFeatureExtractor"),w9t.forEach(t),uLo=r(uqe," (YOLOS model)"),uqe.forEach(t),W.forEach(t),pLo=i(Ta),T(Gp.$$.fragment,Ta),_Lo=i(Ta),T(Op.$$.fragment,Ta),Ta.forEach(t),bLo=i(xl),Vp=n(xl,"DIV",{class:!0});var Sto=s(Vp);T(zx.$$.fragment,Sto),vLo=i(Sto),Cpe=n(Sto,"P",{});var A9t=s(Cpe);FLo=r(A9t,"Register a new feature extractor for this class."),A9t.forEach(t),Sto.forEach(t),xl.forEach(t),voo=i(m),Td=n(m,"H2",{class:!0});var Rto=s(Td);Xp=n(Rto,"A",{id:!0,class:!0,href:!0});var L9t=s(Xp);wpe=n(L9t,"SPAN",{});var y9t=s(wpe);T(Qx.$$.fragment,y9t),y9t.forEach(t),L9t.forEach(t),TLo=i(Rto),Ape=n(Rto,"SPAN",{});var x9t=s(Ape);MLo=r(x9t,"AutoProcessor"),x9t.forEach(t),Rto.forEach(t),Foo=i(m),Po=n(m,"DIV",{class:!0});var $l=s(Po);T(Wx.$$.fragment,$l),ELo=i($l),Ux=n($l,"P",{});var Pto=s(Ux);CLo=r(Pto,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),aV=n(Pto,"A",{href:!0});var $9t=s(aV);wLo=r($9t,"AutoProcessor.from_pretrained()"),$9t.forEach(t),ALo=r(Pto," class method."),Pto.forEach(t),LLo=i($l),Hx=n($l,"P",{});var Bto=s(Hx);yLo=r(Bto,"This class cannot be instantiated directly using "),Lpe=n(Bto,"CODE",{});var k9t=s(Lpe);xLo=r(k9t,"__init__()"),k9t.forEach(t),$Lo=r(Bto," (throws an error)."),Bto.forEach(t),kLo=i($l),Ze=n($l,"DIV",{class:!0});var Ma=s(Ze);T(Jx.$$.fragment,Ma),SLo=i(Ma),ype=n(Ma,"P",{});var S9t=s(ype);RLo=r(S9t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),S9t.forEach(t),PLo=i(Ma),Md=n(Ma,"P",{});var jie=s(Md);BLo=r(jie,"The processor class to instantiate is selected based on the "),xpe=n(jie,"CODE",{});var R9t=s(xpe);ILo=r(R9t,"model_type"),R9t.forEach(t),NLo=r(jie,` property of the config object (either
passed as an argument or loaded from `),$pe=n(jie,"CODE",{});var P9t=s($pe);qLo=r(P9t,"pretrained_model_name_or_path"),P9t.forEach(t),jLo=r(jie," if possible):"),jie.forEach(t),DLo=i(Ma),se=n(Ma,"UL",{});var ie=s(se);zp=n(ie,"LI",{});var pqe=s(zp);kpe=n(pqe,"STRONG",{});var B9t=s(kpe);GLo=r(B9t,"clip"),B9t.forEach(t),OLo=r(pqe," \u2014 "),nV=n(pqe,"A",{href:!0});var I9t=s(nV);VLo=r(I9t,"CLIPProcessor"),I9t.forEach(t),XLo=r(pqe," (CLIP model)"),pqe.forEach(t),zLo=i(ie),Qp=n(ie,"LI",{});var _qe=s(Qp);Spe=n(_qe,"STRONG",{});var N9t=s(Spe);QLo=r(N9t,"donut"),N9t.forEach(t),WLo=r(_qe," \u2014 "),sV=n(_qe,"A",{href:!0});var q9t=s(sV);ULo=r(q9t,"DonutProcessor"),q9t.forEach(t),HLo=r(_qe," (Donut model)"),_qe.forEach(t),JLo=i(ie),Wp=n(ie,"LI",{});var bqe=s(Wp);Rpe=n(bqe,"STRONG",{});var j9t=s(Rpe);YLo=r(j9t,"flava"),j9t.forEach(t),ZLo=r(bqe," \u2014 "),lV=n(bqe,"A",{href:!0});var D9t=s(lV);KLo=r(D9t,"FlavaProcessor"),D9t.forEach(t),eyo=r(bqe," (FLAVA model)"),bqe.forEach(t),oyo=i(ie),Up=n(ie,"LI",{});var vqe=s(Up);Ppe=n(vqe,"STRONG",{});var G9t=s(Ppe);ryo=r(G9t,"groupvit"),G9t.forEach(t),tyo=r(vqe," \u2014 "),iV=n(vqe,"A",{href:!0});var O9t=s(iV);ayo=r(O9t,"CLIPProcessor"),O9t.forEach(t),nyo=r(vqe," (GroupViT model)"),vqe.forEach(t),syo=i(ie),Hp=n(ie,"LI",{});var Fqe=s(Hp);Bpe=n(Fqe,"STRONG",{});var V9t=s(Bpe);lyo=r(V9t,"layoutlmv2"),V9t.forEach(t),iyo=r(Fqe," \u2014 "),dV=n(Fqe,"A",{href:!0});var X9t=s(dV);dyo=r(X9t,"LayoutLMv2Processor"),X9t.forEach(t),cyo=r(Fqe," (LayoutLMv2 model)"),Fqe.forEach(t),myo=i(ie),Jp=n(ie,"LI",{});var Tqe=s(Jp);Ipe=n(Tqe,"STRONG",{});var z9t=s(Ipe);fyo=r(z9t,"layoutlmv3"),z9t.forEach(t),gyo=r(Tqe," \u2014 "),cV=n(Tqe,"A",{href:!0});var Q9t=s(cV);hyo=r(Q9t,"LayoutLMv3Processor"),Q9t.forEach(t),uyo=r(Tqe," (LayoutLMv3 model)"),Tqe.forEach(t),pyo=i(ie),Yp=n(ie,"LI",{});var Mqe=s(Yp);Npe=n(Mqe,"STRONG",{});var W9t=s(Npe);_yo=r(W9t,"layoutxlm"),W9t.forEach(t),byo=r(Mqe," \u2014 "),mV=n(Mqe,"A",{href:!0});var U9t=s(mV);vyo=r(U9t,"LayoutXLMProcessor"),U9t.forEach(t),Fyo=r(Mqe," (LayoutXLM model)"),Mqe.forEach(t),Tyo=i(ie),Zp=n(ie,"LI",{});var Eqe=s(Zp);qpe=n(Eqe,"STRONG",{});var H9t=s(qpe);Myo=r(H9t,"markuplm"),H9t.forEach(t),Eyo=r(Eqe," \u2014 "),fV=n(Eqe,"A",{href:!0});var J9t=s(fV);Cyo=r(J9t,"MarkupLMProcessor"),J9t.forEach(t),wyo=r(Eqe," (MarkupLM model)"),Eqe.forEach(t),Ayo=i(ie),Kp=n(ie,"LI",{});var Cqe=s(Kp);jpe=n(Cqe,"STRONG",{});var Y9t=s(jpe);Lyo=r(Y9t,"owlvit"),Y9t.forEach(t),yyo=r(Cqe," \u2014 "),gV=n(Cqe,"A",{href:!0});var Z9t=s(gV);xyo=r(Z9t,"OwlViTProcessor"),Z9t.forEach(t),$yo=r(Cqe," (OWL-ViT model)"),Cqe.forEach(t),kyo=i(ie),e_=n(ie,"LI",{});var wqe=s(e_);Dpe=n(wqe,"STRONG",{});var K9t=s(Dpe);Syo=r(K9t,"sew"),K9t.forEach(t),Ryo=r(wqe," \u2014 "),hV=n(wqe,"A",{href:!0});var ext=s(hV);Pyo=r(ext,"Wav2Vec2Processor"),ext.forEach(t),Byo=r(wqe," (SEW model)"),wqe.forEach(t),Iyo=i(ie),o_=n(ie,"LI",{});var Aqe=s(o_);Gpe=n(Aqe,"STRONG",{});var oxt=s(Gpe);Nyo=r(oxt,"sew-d"),oxt.forEach(t),qyo=r(Aqe," \u2014 "),uV=n(Aqe,"A",{href:!0});var rxt=s(uV);jyo=r(rxt,"Wav2Vec2Processor"),rxt.forEach(t),Dyo=r(Aqe," (SEW-D model)"),Aqe.forEach(t),Gyo=i(ie),r_=n(ie,"LI",{});var Lqe=s(r_);Ope=n(Lqe,"STRONG",{});var txt=s(Ope);Oyo=r(txt,"speech_to_text"),txt.forEach(t),Vyo=r(Lqe," \u2014 "),pV=n(Lqe,"A",{href:!0});var axt=s(pV);Xyo=r(axt,"Speech2TextProcessor"),axt.forEach(t),zyo=r(Lqe," (Speech2Text model)"),Lqe.forEach(t),Qyo=i(ie),t_=n(ie,"LI",{});var yqe=s(t_);Vpe=n(yqe,"STRONG",{});var nxt=s(Vpe);Wyo=r(nxt,"speech_to_text_2"),nxt.forEach(t),Uyo=r(yqe," \u2014 "),_V=n(yqe,"A",{href:!0});var sxt=s(_V);Hyo=r(sxt,"Speech2Text2Processor"),sxt.forEach(t),Jyo=r(yqe," (Speech2Text2 model)"),yqe.forEach(t),Yyo=i(ie),a_=n(ie,"LI",{});var xqe=s(a_);Xpe=n(xqe,"STRONG",{});var lxt=s(Xpe);Zyo=r(lxt,"trocr"),lxt.forEach(t),Kyo=r(xqe," \u2014 "),bV=n(xqe,"A",{href:!0});var ixt=s(bV);e8o=r(ixt,"TrOCRProcessor"),ixt.forEach(t),o8o=r(xqe," (TrOCR model)"),xqe.forEach(t),r8o=i(ie),n_=n(ie,"LI",{});var $qe=s(n_);zpe=n($qe,"STRONG",{});var dxt=s(zpe);t8o=r(dxt,"unispeech"),dxt.forEach(t),a8o=r($qe," \u2014 "),vV=n($qe,"A",{href:!0});var cxt=s(vV);n8o=r(cxt,"Wav2Vec2Processor"),cxt.forEach(t),s8o=r($qe," (UniSpeech model)"),$qe.forEach(t),l8o=i(ie),s_=n(ie,"LI",{});var kqe=s(s_);Qpe=n(kqe,"STRONG",{});var mxt=s(Qpe);i8o=r(mxt,"unispeech-sat"),mxt.forEach(t),d8o=r(kqe," \u2014 "),FV=n(kqe,"A",{href:!0});var fxt=s(FV);c8o=r(fxt,"Wav2Vec2Processor"),fxt.forEach(t),m8o=r(kqe," (UniSpeechSat model)"),kqe.forEach(t),f8o=i(ie),l_=n(ie,"LI",{});var Sqe=s(l_);Wpe=n(Sqe,"STRONG",{});var gxt=s(Wpe);g8o=r(gxt,"vilt"),gxt.forEach(t),h8o=r(Sqe," \u2014 "),TV=n(Sqe,"A",{href:!0});var hxt=s(TV);u8o=r(hxt,"ViltProcessor"),hxt.forEach(t),p8o=r(Sqe," (ViLT model)"),Sqe.forEach(t),_8o=i(ie),i_=n(ie,"LI",{});var Rqe=s(i_);Upe=n(Rqe,"STRONG",{});var uxt=s(Upe);b8o=r(uxt,"vision-text-dual-encoder"),uxt.forEach(t),v8o=r(Rqe," \u2014 "),MV=n(Rqe,"A",{href:!0});var pxt=s(MV);F8o=r(pxt,"VisionTextDualEncoderProcessor"),pxt.forEach(t),T8o=r(Rqe," (VisionTextDualEncoder model)"),Rqe.forEach(t),M8o=i(ie),d_=n(ie,"LI",{});var Pqe=s(d_);Hpe=n(Pqe,"STRONG",{});var _xt=s(Hpe);E8o=r(_xt,"wav2vec2"),_xt.forEach(t),C8o=r(Pqe," \u2014 "),EV=n(Pqe,"A",{href:!0});var bxt=s(EV);w8o=r(bxt,"Wav2Vec2Processor"),bxt.forEach(t),A8o=r(Pqe," (Wav2Vec2 model)"),Pqe.forEach(t),L8o=i(ie),c_=n(ie,"LI",{});var Bqe=s(c_);Jpe=n(Bqe,"STRONG",{});var vxt=s(Jpe);y8o=r(vxt,"wav2vec2-conformer"),vxt.forEach(t),x8o=r(Bqe," \u2014 "),CV=n(Bqe,"A",{href:!0});var Fxt=s(CV);$8o=r(Fxt,"Wav2Vec2Processor"),Fxt.forEach(t),k8o=r(Bqe," (Wav2Vec2-Conformer model)"),Bqe.forEach(t),S8o=i(ie),m_=n(ie,"LI",{});var Iqe=s(m_);Ype=n(Iqe,"STRONG",{});var Txt=s(Ype);R8o=r(Txt,"wavlm"),Txt.forEach(t),P8o=r(Iqe," \u2014 "),wV=n(Iqe,"A",{href:!0});var Mxt=s(wV);B8o=r(Mxt,"Wav2Vec2Processor"),Mxt.forEach(t),I8o=r(Iqe," (WavLM model)"),Iqe.forEach(t),N8o=i(ie),f_=n(ie,"LI",{});var Nqe=s(f_);Zpe=n(Nqe,"STRONG",{});var Ext=s(Zpe);q8o=r(Ext,"whisper"),Ext.forEach(t),j8o=r(Nqe," \u2014 "),AV=n(Nqe,"A",{href:!0});var Cxt=s(AV);D8o=r(Cxt,"WhisperProcessor"),Cxt.forEach(t),G8o=r(Nqe," (Whisper model)"),Nqe.forEach(t),O8o=i(ie),g_=n(ie,"LI",{});var qqe=s(g_);Kpe=n(qqe,"STRONG",{});var wxt=s(Kpe);V8o=r(wxt,"xclip"),wxt.forEach(t),X8o=r(qqe," \u2014 "),LV=n(qqe,"A",{href:!0});var Axt=s(LV);z8o=r(Axt,"CLIPProcessor"),Axt.forEach(t),Q8o=r(qqe," (X-CLIP model)"),qqe.forEach(t),ie.forEach(t),W8o=i(Ma),T(h_.$$.fragment,Ma),U8o=i(Ma),T(u_.$$.fragment,Ma),Ma.forEach(t),H8o=i($l),p_=n($l,"DIV",{class:!0});var Ito=s(p_);T(Yx.$$.fragment,Ito),J8o=i(Ito),e_e=n(Ito,"P",{});var Lxt=s(e_e);Y8o=r(Lxt,"Register a new processor for this class."),Lxt.forEach(t),Ito.forEach(t),$l.forEach(t),Too=i(m),Ed=n(m,"H2",{class:!0});var Nto=s(Ed);__=n(Nto,"A",{id:!0,class:!0,href:!0});var yxt=s(__);o_e=n(yxt,"SPAN",{});var xxt=s(o_e);T(Zx.$$.fragment,xxt),xxt.forEach(t),yxt.forEach(t),Z8o=i(Nto),r_e=n(Nto,"SPAN",{});var $xt=s(r_e);K8o=r($xt,"AutoModel"),$xt.forEach(t),Nto.forEach(t),Moo=i(m),Bo=n(m,"DIV",{class:!0});var kl=s(Bo);T(Kx.$$.fragment,kl),e9o=i(kl),Cd=n(kl,"P",{});var Die=s(Cd);o9o=r(Die,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),yV=n(Die,"A",{href:!0});var kxt=s(yV);r9o=r(kxt,"from_pretrained()"),kxt.forEach(t),t9o=r(Die," class method or the "),xV=n(Die,"A",{href:!0});var Sxt=s(xV);a9o=r(Sxt,"from_config()"),Sxt.forEach(t),n9o=r(Die,` class
method.`),Die.forEach(t),s9o=i(kl),e$=n(kl,"P",{});var qto=s(e$);l9o=r(qto,"This class cannot be instantiated directly using "),t_e=n(qto,"CODE",{});var Rxt=s(t_e);i9o=r(Rxt,"__init__()"),Rxt.forEach(t),d9o=r(qto," (throws an error)."),qto.forEach(t),c9o=i(kl),vt=n(kl,"DIV",{class:!0});var b8=s(vt);T(o$.$$.fragment,b8),m9o=i(b8),a_e=n(b8,"P",{});var Pxt=s(a_e);f9o=r(Pxt,"Instantiates one of the base model classes of the library from a configuration."),Pxt.forEach(t),g9o=i(b8),wd=n(b8,"P",{});var Gie=s(wd);h9o=r(Gie,`Note:
Loading a model from its configuration file does `),n_e=n(Gie,"STRONG",{});var Bxt=s(n_e);u9o=r(Bxt,"not"),Bxt.forEach(t),p9o=r(Gie,` load the model weights. It only affects the
model\u2019s configuration. Use `),$V=n(Gie,"A",{href:!0});var Ixt=s($V);_9o=r(Ixt,"from_pretrained()"),Ixt.forEach(t),b9o=r(Gie," to load the model weights."),Gie.forEach(t),v9o=i(b8),T(b_.$$.fragment,b8),b8.forEach(t),F9o=i(kl),Ke=n(kl,"DIV",{class:!0});var Ea=s(Ke);T(r$.$$.fragment,Ea),T9o=i(Ea),s_e=n(Ea,"P",{});var Nxt=s(s_e);M9o=r(Nxt,"Instantiate one of the base model classes of the library from a pretrained model."),Nxt.forEach(t),E9o=i(Ea),en=n(Ea,"P",{});var v8=s(en);C9o=r(v8,"The model class to instantiate is selected based on the "),l_e=n(v8,"CODE",{});var qxt=s(l_e);w9o=r(qxt,"model_type"),qxt.forEach(t),A9o=r(v8,` property of the config object (either
passed as an argument or loaded from `),i_e=n(v8,"CODE",{});var jxt=s(i_e);L9o=r(jxt,"pretrained_model_name_or_path"),jxt.forEach(t),y9o=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d_e=n(v8,"CODE",{});var Dxt=s(d_e);x9o=r(Dxt,"pretrained_model_name_or_path"),Dxt.forEach(t),$9o=r(v8,":"),v8.forEach(t),k9o=i(Ea),y=n(Ea,"UL",{});var x=s(y);v_=n(x,"LI",{});var jqe=s(v_);c_e=n(jqe,"STRONG",{});var Gxt=s(c_e);S9o=r(Gxt,"albert"),Gxt.forEach(t),R9o=r(jqe," \u2014 "),kV=n(jqe,"A",{href:!0});var Oxt=s(kV);P9o=r(Oxt,"AlbertModel"),Oxt.forEach(t),B9o=r(jqe," (ALBERT model)"),jqe.forEach(t),I9o=i(x),F_=n(x,"LI",{});var Dqe=s(F_);m_e=n(Dqe,"STRONG",{});var Vxt=s(m_e);N9o=r(Vxt,"bart"),Vxt.forEach(t),q9o=r(Dqe," \u2014 "),SV=n(Dqe,"A",{href:!0});var Xxt=s(SV);j9o=r(Xxt,"BartModel"),Xxt.forEach(t),D9o=r(Dqe," (BART model)"),Dqe.forEach(t),G9o=i(x),T_=n(x,"LI",{});var Gqe=s(T_);f_e=n(Gqe,"STRONG",{});var zxt=s(f_e);O9o=r(zxt,"beit"),zxt.forEach(t),V9o=r(Gqe," \u2014 "),RV=n(Gqe,"A",{href:!0});var Qxt=s(RV);X9o=r(Qxt,"BeitModel"),Qxt.forEach(t),z9o=r(Gqe," (BEiT model)"),Gqe.forEach(t),Q9o=i(x),M_=n(x,"LI",{});var Oqe=s(M_);g_e=n(Oqe,"STRONG",{});var Wxt=s(g_e);W9o=r(Wxt,"bert"),Wxt.forEach(t),U9o=r(Oqe," \u2014 "),PV=n(Oqe,"A",{href:!0});var Uxt=s(PV);H9o=r(Uxt,"BertModel"),Uxt.forEach(t),J9o=r(Oqe," (BERT model)"),Oqe.forEach(t),Y9o=i(x),E_=n(x,"LI",{});var Vqe=s(E_);h_e=n(Vqe,"STRONG",{});var Hxt=s(h_e);Z9o=r(Hxt,"bert-generation"),Hxt.forEach(t),K9o=r(Vqe," \u2014 "),BV=n(Vqe,"A",{href:!0});var Jxt=s(BV);exo=r(Jxt,"BertGenerationEncoder"),Jxt.forEach(t),oxo=r(Vqe," (Bert Generation model)"),Vqe.forEach(t),rxo=i(x),C_=n(x,"LI",{});var Xqe=s(C_);u_e=n(Xqe,"STRONG",{});var Yxt=s(u_e);txo=r(Yxt,"big_bird"),Yxt.forEach(t),axo=r(Xqe," \u2014 "),IV=n(Xqe,"A",{href:!0});var Zxt=s(IV);nxo=r(Zxt,"BigBirdModel"),Zxt.forEach(t),sxo=r(Xqe," (BigBird model)"),Xqe.forEach(t),lxo=i(x),w_=n(x,"LI",{});var zqe=s(w_);p_e=n(zqe,"STRONG",{});var Kxt=s(p_e);ixo=r(Kxt,"bigbird_pegasus"),Kxt.forEach(t),dxo=r(zqe," \u2014 "),NV=n(zqe,"A",{href:!0});var e$t=s(NV);cxo=r(e$t,"BigBirdPegasusModel"),e$t.forEach(t),mxo=r(zqe," (BigBird-Pegasus model)"),zqe.forEach(t),fxo=i(x),A_=n(x,"LI",{});var Qqe=s(A_);__e=n(Qqe,"STRONG",{});var o$t=s(__e);gxo=r(o$t,"blenderbot"),o$t.forEach(t),hxo=r(Qqe," \u2014 "),qV=n(Qqe,"A",{href:!0});var r$t=s(qV);uxo=r(r$t,"BlenderbotModel"),r$t.forEach(t),pxo=r(Qqe," (Blenderbot model)"),Qqe.forEach(t),_xo=i(x),L_=n(x,"LI",{});var Wqe=s(L_);b_e=n(Wqe,"STRONG",{});var t$t=s(b_e);bxo=r(t$t,"blenderbot-small"),t$t.forEach(t),vxo=r(Wqe," \u2014 "),jV=n(Wqe,"A",{href:!0});var a$t=s(jV);Fxo=r(a$t,"BlenderbotSmallModel"),a$t.forEach(t),Txo=r(Wqe," (BlenderbotSmall model)"),Wqe.forEach(t),Mxo=i(x),y_=n(x,"LI",{});var Uqe=s(y_);v_e=n(Uqe,"STRONG",{});var n$t=s(v_e);Exo=r(n$t,"bloom"),n$t.forEach(t),Cxo=r(Uqe," \u2014 "),DV=n(Uqe,"A",{href:!0});var s$t=s(DV);wxo=r(s$t,"BloomModel"),s$t.forEach(t),Axo=r(Uqe," (BLOOM model)"),Uqe.forEach(t),Lxo=i(x),x_=n(x,"LI",{});var Hqe=s(x_);F_e=n(Hqe,"STRONG",{});var l$t=s(F_e);yxo=r(l$t,"camembert"),l$t.forEach(t),xxo=r(Hqe," \u2014 "),GV=n(Hqe,"A",{href:!0});var i$t=s(GV);$xo=r(i$t,"CamembertModel"),i$t.forEach(t),kxo=r(Hqe," (CamemBERT model)"),Hqe.forEach(t),Sxo=i(x),$_=n(x,"LI",{});var Jqe=s($_);T_e=n(Jqe,"STRONG",{});var d$t=s(T_e);Rxo=r(d$t,"canine"),d$t.forEach(t),Pxo=r(Jqe," \u2014 "),OV=n(Jqe,"A",{href:!0});var c$t=s(OV);Bxo=r(c$t,"CanineModel"),c$t.forEach(t),Ixo=r(Jqe," (CANINE model)"),Jqe.forEach(t),Nxo=i(x),k_=n(x,"LI",{});var Yqe=s(k_);M_e=n(Yqe,"STRONG",{});var m$t=s(M_e);qxo=r(m$t,"clip"),m$t.forEach(t),jxo=r(Yqe," \u2014 "),VV=n(Yqe,"A",{href:!0});var f$t=s(VV);Dxo=r(f$t,"CLIPModel"),f$t.forEach(t),Gxo=r(Yqe," (CLIP model)"),Yqe.forEach(t),Oxo=i(x),S_=n(x,"LI",{});var Zqe=s(S_);E_e=n(Zqe,"STRONG",{});var g$t=s(E_e);Vxo=r(g$t,"codegen"),g$t.forEach(t),Xxo=r(Zqe," \u2014 "),XV=n(Zqe,"A",{href:!0});var h$t=s(XV);zxo=r(h$t,"CodeGenModel"),h$t.forEach(t),Qxo=r(Zqe," (CodeGen model)"),Zqe.forEach(t),Wxo=i(x),R_=n(x,"LI",{});var Kqe=s(R_);C_e=n(Kqe,"STRONG",{});var u$t=s(C_e);Uxo=r(u$t,"conditional_detr"),u$t.forEach(t),Hxo=r(Kqe," \u2014 "),zV=n(Kqe,"A",{href:!0});var p$t=s(zV);Jxo=r(p$t,"ConditionalDetrModel"),p$t.forEach(t),Yxo=r(Kqe," (Conditional DETR model)"),Kqe.forEach(t),Zxo=i(x),P_=n(x,"LI",{});var eje=s(P_);w_e=n(eje,"STRONG",{});var _$t=s(w_e);Kxo=r(_$t,"convbert"),_$t.forEach(t),e$o=r(eje," \u2014 "),QV=n(eje,"A",{href:!0});var b$t=s(QV);o$o=r(b$t,"ConvBertModel"),b$t.forEach(t),r$o=r(eje," (ConvBERT model)"),eje.forEach(t),t$o=i(x),B_=n(x,"LI",{});var oje=s(B_);A_e=n(oje,"STRONG",{});var v$t=s(A_e);a$o=r(v$t,"convnext"),v$t.forEach(t),n$o=r(oje," \u2014 "),WV=n(oje,"A",{href:!0});var F$t=s(WV);s$o=r(F$t,"ConvNextModel"),F$t.forEach(t),l$o=r(oje," (ConvNeXT model)"),oje.forEach(t),i$o=i(x),I_=n(x,"LI",{});var rje=s(I_);L_e=n(rje,"STRONG",{});var T$t=s(L_e);d$o=r(T$t,"ctrl"),T$t.forEach(t),c$o=r(rje," \u2014 "),UV=n(rje,"A",{href:!0});var M$t=s(UV);m$o=r(M$t,"CTRLModel"),M$t.forEach(t),f$o=r(rje," (CTRL model)"),rje.forEach(t),g$o=i(x),N_=n(x,"LI",{});var tje=s(N_);y_e=n(tje,"STRONG",{});var E$t=s(y_e);h$o=r(E$t,"cvt"),E$t.forEach(t),u$o=r(tje," \u2014 "),HV=n(tje,"A",{href:!0});var C$t=s(HV);p$o=r(C$t,"CvtModel"),C$t.forEach(t),_$o=r(tje," (CvT model)"),tje.forEach(t),b$o=i(x),q_=n(x,"LI",{});var aje=s(q_);x_e=n(aje,"STRONG",{});var w$t=s(x_e);v$o=r(w$t,"data2vec-audio"),w$t.forEach(t),F$o=r(aje," \u2014 "),JV=n(aje,"A",{href:!0});var A$t=s(JV);T$o=r(A$t,"Data2VecAudioModel"),A$t.forEach(t),M$o=r(aje," (Data2VecAudio model)"),aje.forEach(t),E$o=i(x),j_=n(x,"LI",{});var nje=s(j_);$_e=n(nje,"STRONG",{});var L$t=s($_e);C$o=r(L$t,"data2vec-text"),L$t.forEach(t),w$o=r(nje," \u2014 "),YV=n(nje,"A",{href:!0});var y$t=s(YV);A$o=r(y$t,"Data2VecTextModel"),y$t.forEach(t),L$o=r(nje," (Data2VecText model)"),nje.forEach(t),y$o=i(x),D_=n(x,"LI",{});var sje=s(D_);k_e=n(sje,"STRONG",{});var x$t=s(k_e);x$o=r(x$t,"data2vec-vision"),x$t.forEach(t),$$o=r(sje," \u2014 "),ZV=n(sje,"A",{href:!0});var $$t=s(ZV);k$o=r($$t,"Data2VecVisionModel"),$$t.forEach(t),S$o=r(sje," (Data2VecVision model)"),sje.forEach(t),R$o=i(x),G_=n(x,"LI",{});var lje=s(G_);S_e=n(lje,"STRONG",{});var k$t=s(S_e);P$o=r(k$t,"deberta"),k$t.forEach(t),B$o=r(lje," \u2014 "),KV=n(lje,"A",{href:!0});var S$t=s(KV);I$o=r(S$t,"DebertaModel"),S$t.forEach(t),N$o=r(lje," (DeBERTa model)"),lje.forEach(t),q$o=i(x),O_=n(x,"LI",{});var ije=s(O_);R_e=n(ije,"STRONG",{});var R$t=s(R_e);j$o=r(R$t,"deberta-v2"),R$t.forEach(t),D$o=r(ije," \u2014 "),eX=n(ije,"A",{href:!0});var P$t=s(eX);G$o=r(P$t,"DebertaV2Model"),P$t.forEach(t),O$o=r(ije," (DeBERTa-v2 model)"),ije.forEach(t),V$o=i(x),V_=n(x,"LI",{});var dje=s(V_);P_e=n(dje,"STRONG",{});var B$t=s(P_e);X$o=r(B$t,"decision_transformer"),B$t.forEach(t),z$o=r(dje," \u2014 "),oX=n(dje,"A",{href:!0});var I$t=s(oX);Q$o=r(I$t,"DecisionTransformerModel"),I$t.forEach(t),W$o=r(dje," (Decision Transformer model)"),dje.forEach(t),U$o=i(x),X_=n(x,"LI",{});var cje=s(X_);B_e=n(cje,"STRONG",{});var N$t=s(B_e);H$o=r(N$t,"deformable_detr"),N$t.forEach(t),J$o=r(cje," \u2014 "),rX=n(cje,"A",{href:!0});var q$t=s(rX);Y$o=r(q$t,"DeformableDetrModel"),q$t.forEach(t),Z$o=r(cje," (Deformable DETR model)"),cje.forEach(t),K$o=i(x),z_=n(x,"LI",{});var mje=s(z_);I_e=n(mje,"STRONG",{});var j$t=s(I_e);eko=r(j$t,"deit"),j$t.forEach(t),oko=r(mje," \u2014 "),tX=n(mje,"A",{href:!0});var D$t=s(tX);rko=r(D$t,"DeiTModel"),D$t.forEach(t),tko=r(mje," (DeiT model)"),mje.forEach(t),ako=i(x),Q_=n(x,"LI",{});var fje=s(Q_);N_e=n(fje,"STRONG",{});var G$t=s(N_e);nko=r(G$t,"detr"),G$t.forEach(t),sko=r(fje," \u2014 "),aX=n(fje,"A",{href:!0});var O$t=s(aX);lko=r(O$t,"DetrModel"),O$t.forEach(t),iko=r(fje," (DETR model)"),fje.forEach(t),dko=i(x),W_=n(x,"LI",{});var gje=s(W_);q_e=n(gje,"STRONG",{});var V$t=s(q_e);cko=r(V$t,"distilbert"),V$t.forEach(t),mko=r(gje," \u2014 "),nX=n(gje,"A",{href:!0});var X$t=s(nX);fko=r(X$t,"DistilBertModel"),X$t.forEach(t),gko=r(gje," (DistilBERT model)"),gje.forEach(t),hko=i(x),U_=n(x,"LI",{});var hje=s(U_);j_e=n(hje,"STRONG",{});var z$t=s(j_e);uko=r(z$t,"donut-swin"),z$t.forEach(t),pko=r(hje," \u2014 "),sX=n(hje,"A",{href:!0});var Q$t=s(sX);_ko=r(Q$t,"DonutSwinModel"),Q$t.forEach(t),bko=r(hje," (DonutSwin model)"),hje.forEach(t),vko=i(x),H_=n(x,"LI",{});var uje=s(H_);D_e=n(uje,"STRONG",{});var W$t=s(D_e);Fko=r(W$t,"dpr"),W$t.forEach(t),Tko=r(uje," \u2014 "),lX=n(uje,"A",{href:!0});var U$t=s(lX);Mko=r(U$t,"DPRQuestionEncoder"),U$t.forEach(t),Eko=r(uje," (DPR model)"),uje.forEach(t),Cko=i(x),J_=n(x,"LI",{});var pje=s(J_);G_e=n(pje,"STRONG",{});var H$t=s(G_e);wko=r(H$t,"dpt"),H$t.forEach(t),Ako=r(pje," \u2014 "),iX=n(pje,"A",{href:!0});var J$t=s(iX);Lko=r(J$t,"DPTModel"),J$t.forEach(t),yko=r(pje," (DPT model)"),pje.forEach(t),xko=i(x),Y_=n(x,"LI",{});var _je=s(Y_);O_e=n(_je,"STRONG",{});var Y$t=s(O_e);$ko=r(Y$t,"electra"),Y$t.forEach(t),kko=r(_je," \u2014 "),dX=n(_je,"A",{href:!0});var Z$t=s(dX);Sko=r(Z$t,"ElectraModel"),Z$t.forEach(t),Rko=r(_je," (ELECTRA model)"),_je.forEach(t),Pko=i(x),Z_=n(x,"LI",{});var bje=s(Z_);V_e=n(bje,"STRONG",{});var K$t=s(V_e);Bko=r(K$t,"ernie"),K$t.forEach(t),Iko=r(bje," \u2014 "),cX=n(bje,"A",{href:!0});var ekt=s(cX);Nko=r(ekt,"ErnieModel"),ekt.forEach(t),qko=r(bje," (ERNIE model)"),bje.forEach(t),jko=i(x),K_=n(x,"LI",{});var vje=s(K_);X_e=n(vje,"STRONG",{});var okt=s(X_e);Dko=r(okt,"esm"),okt.forEach(t),Gko=r(vje," \u2014 "),mX=n(vje,"A",{href:!0});var rkt=s(mX);Oko=r(rkt,"EsmModel"),rkt.forEach(t),Vko=r(vje," (ESM model)"),vje.forEach(t),Xko=i(x),e1=n(x,"LI",{});var Fje=s(e1);z_e=n(Fje,"STRONG",{});var tkt=s(z_e);zko=r(tkt,"flaubert"),tkt.forEach(t),Qko=r(Fje," \u2014 "),fX=n(Fje,"A",{href:!0});var akt=s(fX);Wko=r(akt,"FlaubertModel"),akt.forEach(t),Uko=r(Fje," (FlauBERT model)"),Fje.forEach(t),Hko=i(x),o1=n(x,"LI",{});var Tje=s(o1);Q_e=n(Tje,"STRONG",{});var nkt=s(Q_e);Jko=r(nkt,"flava"),nkt.forEach(t),Yko=r(Tje," \u2014 "),gX=n(Tje,"A",{href:!0});var skt=s(gX);Zko=r(skt,"FlavaModel"),skt.forEach(t),Kko=r(Tje," (FLAVA model)"),Tje.forEach(t),eSo=i(x),r1=n(x,"LI",{});var Mje=s(r1);W_e=n(Mje,"STRONG",{});var lkt=s(W_e);oSo=r(lkt,"fnet"),lkt.forEach(t),rSo=r(Mje," \u2014 "),hX=n(Mje,"A",{href:!0});var ikt=s(hX);tSo=r(ikt,"FNetModel"),ikt.forEach(t),aSo=r(Mje," (FNet model)"),Mje.forEach(t),nSo=i(x),t1=n(x,"LI",{});var Eje=s(t1);U_e=n(Eje,"STRONG",{});var dkt=s(U_e);sSo=r(dkt,"fsmt"),dkt.forEach(t),lSo=r(Eje," \u2014 "),uX=n(Eje,"A",{href:!0});var ckt=s(uX);iSo=r(ckt,"FSMTModel"),ckt.forEach(t),dSo=r(Eje," (FairSeq Machine-Translation model)"),Eje.forEach(t),cSo=i(x),Ml=n(x,"LI",{});var wI=s(Ml);H_e=n(wI,"STRONG",{});var mkt=s(H_e);mSo=r(mkt,"funnel"),mkt.forEach(t),fSo=r(wI," \u2014 "),pX=n(wI,"A",{href:!0});var fkt=s(pX);gSo=r(fkt,"FunnelModel"),fkt.forEach(t),hSo=r(wI," or "),_X=n(wI,"A",{href:!0});var gkt=s(_X);uSo=r(gkt,"FunnelBaseModel"),gkt.forEach(t),pSo=r(wI," (Funnel Transformer model)"),wI.forEach(t),_So=i(x),a1=n(x,"LI",{});var Cje=s(a1);J_e=n(Cje,"STRONG",{});var hkt=s(J_e);bSo=r(hkt,"glpn"),hkt.forEach(t),vSo=r(Cje," \u2014 "),bX=n(Cje,"A",{href:!0});var ukt=s(bX);FSo=r(ukt,"GLPNModel"),ukt.forEach(t),TSo=r(Cje," (GLPN model)"),Cje.forEach(t),MSo=i(x),n1=n(x,"LI",{});var wje=s(n1);Y_e=n(wje,"STRONG",{});var pkt=s(Y_e);ESo=r(pkt,"gpt2"),pkt.forEach(t),CSo=r(wje," \u2014 "),vX=n(wje,"A",{href:!0});var _kt=s(vX);wSo=r(_kt,"GPT2Model"),_kt.forEach(t),ASo=r(wje," (OpenAI GPT-2 model)"),wje.forEach(t),LSo=i(x),s1=n(x,"LI",{});var Aje=s(s1);Z_e=n(Aje,"STRONG",{});var bkt=s(Z_e);ySo=r(bkt,"gpt_neo"),bkt.forEach(t),xSo=r(Aje," \u2014 "),FX=n(Aje,"A",{href:!0});var vkt=s(FX);$So=r(vkt,"GPTNeoModel"),vkt.forEach(t),kSo=r(Aje," (GPT Neo model)"),Aje.forEach(t),SSo=i(x),l1=n(x,"LI",{});var Lje=s(l1);K_e=n(Lje,"STRONG",{});var Fkt=s(K_e);RSo=r(Fkt,"gpt_neox"),Fkt.forEach(t),PSo=r(Lje," \u2014 "),TX=n(Lje,"A",{href:!0});var Tkt=s(TX);BSo=r(Tkt,"GPTNeoXModel"),Tkt.forEach(t),ISo=r(Lje," (GPT NeoX model)"),Lje.forEach(t),NSo=i(x),i1=n(x,"LI",{});var yje=s(i1);e1e=n(yje,"STRONG",{});var Mkt=s(e1e);qSo=r(Mkt,"gpt_neox_japanese"),Mkt.forEach(t),jSo=r(yje," \u2014 "),MX=n(yje,"A",{href:!0});var Ekt=s(MX);DSo=r(Ekt,"GPTNeoXJapaneseModel"),Ekt.forEach(t),GSo=r(yje," (GPT NeoX Japanese model)"),yje.forEach(t),OSo=i(x),d1=n(x,"LI",{});var xje=s(d1);o1e=n(xje,"STRONG",{});var Ckt=s(o1e);VSo=r(Ckt,"gptj"),Ckt.forEach(t),XSo=r(xje," \u2014 "),EX=n(xje,"A",{href:!0});var wkt=s(EX);zSo=r(wkt,"GPTJModel"),wkt.forEach(t),QSo=r(xje," (GPT-J model)"),xje.forEach(t),WSo=i(x),c1=n(x,"LI",{});var $je=s(c1);r1e=n($je,"STRONG",{});var Akt=s(r1e);USo=r(Akt,"groupvit"),Akt.forEach(t),HSo=r($je," \u2014 "),CX=n($je,"A",{href:!0});var Lkt=s(CX);JSo=r(Lkt,"GroupViTModel"),Lkt.forEach(t),YSo=r($je," (GroupViT model)"),$je.forEach(t),ZSo=i(x),m1=n(x,"LI",{});var kje=s(m1);t1e=n(kje,"STRONG",{});var ykt=s(t1e);KSo=r(ykt,"hubert"),ykt.forEach(t),eRo=r(kje," \u2014 "),wX=n(kje,"A",{href:!0});var xkt=s(wX);oRo=r(xkt,"HubertModel"),xkt.forEach(t),rRo=r(kje," (Hubert model)"),kje.forEach(t),tRo=i(x),f1=n(x,"LI",{});var Sje=s(f1);a1e=n(Sje,"STRONG",{});var $kt=s(a1e);aRo=r($kt,"ibert"),$kt.forEach(t),nRo=r(Sje," \u2014 "),AX=n(Sje,"A",{href:!0});var kkt=s(AX);sRo=r(kkt,"IBertModel"),kkt.forEach(t),lRo=r(Sje," (I-BERT model)"),Sje.forEach(t),iRo=i(x),g1=n(x,"LI",{});var Rje=s(g1);n1e=n(Rje,"STRONG",{});var Skt=s(n1e);dRo=r(Skt,"imagegpt"),Skt.forEach(t),cRo=r(Rje," \u2014 "),LX=n(Rje,"A",{href:!0});var Rkt=s(LX);mRo=r(Rkt,"ImageGPTModel"),Rkt.forEach(t),fRo=r(Rje," (ImageGPT model)"),Rje.forEach(t),gRo=i(x),h1=n(x,"LI",{});var Pje=s(h1);s1e=n(Pje,"STRONG",{});var Pkt=s(s1e);hRo=r(Pkt,"layoutlm"),Pkt.forEach(t),uRo=r(Pje," \u2014 "),yX=n(Pje,"A",{href:!0});var Bkt=s(yX);pRo=r(Bkt,"LayoutLMModel"),Bkt.forEach(t),_Ro=r(Pje," (LayoutLM model)"),Pje.forEach(t),bRo=i(x),u1=n(x,"LI",{});var Bje=s(u1);l1e=n(Bje,"STRONG",{});var Ikt=s(l1e);vRo=r(Ikt,"layoutlmv2"),Ikt.forEach(t),FRo=r(Bje," \u2014 "),xX=n(Bje,"A",{href:!0});var Nkt=s(xX);TRo=r(Nkt,"LayoutLMv2Model"),Nkt.forEach(t),MRo=r(Bje," (LayoutLMv2 model)"),Bje.forEach(t),ERo=i(x),p1=n(x,"LI",{});var Ije=s(p1);i1e=n(Ije,"STRONG",{});var qkt=s(i1e);CRo=r(qkt,"layoutlmv3"),qkt.forEach(t),wRo=r(Ije," \u2014 "),$X=n(Ije,"A",{href:!0});var jkt=s($X);ARo=r(jkt,"LayoutLMv3Model"),jkt.forEach(t),LRo=r(Ije," (LayoutLMv3 model)"),Ije.forEach(t),yRo=i(x),_1=n(x,"LI",{});var Nje=s(_1);d1e=n(Nje,"STRONG",{});var Dkt=s(d1e);xRo=r(Dkt,"led"),Dkt.forEach(t),$Ro=r(Nje," \u2014 "),kX=n(Nje,"A",{href:!0});var Gkt=s(kX);kRo=r(Gkt,"LEDModel"),Gkt.forEach(t),SRo=r(Nje," (LED model)"),Nje.forEach(t),RRo=i(x),b1=n(x,"LI",{});var qje=s(b1);c1e=n(qje,"STRONG",{});var Okt=s(c1e);PRo=r(Okt,"levit"),Okt.forEach(t),BRo=r(qje," \u2014 "),SX=n(qje,"A",{href:!0});var Vkt=s(SX);IRo=r(Vkt,"LevitModel"),Vkt.forEach(t),NRo=r(qje," (LeViT model)"),qje.forEach(t),qRo=i(x),v1=n(x,"LI",{});var jje=s(v1);m1e=n(jje,"STRONG",{});var Xkt=s(m1e);jRo=r(Xkt,"longformer"),Xkt.forEach(t),DRo=r(jje," \u2014 "),RX=n(jje,"A",{href:!0});var zkt=s(RX);GRo=r(zkt,"LongformerModel"),zkt.forEach(t),ORo=r(jje," (Longformer model)"),jje.forEach(t),VRo=i(x),F1=n(x,"LI",{});var Dje=s(F1);f1e=n(Dje,"STRONG",{});var Qkt=s(f1e);XRo=r(Qkt,"longt5"),Qkt.forEach(t),zRo=r(Dje," \u2014 "),PX=n(Dje,"A",{href:!0});var Wkt=s(PX);QRo=r(Wkt,"LongT5Model"),Wkt.forEach(t),WRo=r(Dje," (LongT5 model)"),Dje.forEach(t),URo=i(x),T1=n(x,"LI",{});var Gje=s(T1);g1e=n(Gje,"STRONG",{});var Ukt=s(g1e);HRo=r(Ukt,"luke"),Ukt.forEach(t),JRo=r(Gje," \u2014 "),BX=n(Gje,"A",{href:!0});var Hkt=s(BX);YRo=r(Hkt,"LukeModel"),Hkt.forEach(t),ZRo=r(Gje," (LUKE model)"),Gje.forEach(t),KRo=i(x),M1=n(x,"LI",{});var Oje=s(M1);h1e=n(Oje,"STRONG",{});var Jkt=s(h1e);ePo=r(Jkt,"lxmert"),Jkt.forEach(t),oPo=r(Oje," \u2014 "),IX=n(Oje,"A",{href:!0});var Ykt=s(IX);rPo=r(Ykt,"LxmertModel"),Ykt.forEach(t),tPo=r(Oje," (LXMERT model)"),Oje.forEach(t),aPo=i(x),E1=n(x,"LI",{});var Vje=s(E1);u1e=n(Vje,"STRONG",{});var Zkt=s(u1e);nPo=r(Zkt,"m2m_100"),Zkt.forEach(t),sPo=r(Vje," \u2014 "),NX=n(Vje,"A",{href:!0});var Kkt=s(NX);lPo=r(Kkt,"M2M100Model"),Kkt.forEach(t),iPo=r(Vje," (M2M100 model)"),Vje.forEach(t),dPo=i(x),C1=n(x,"LI",{});var Xje=s(C1);p1e=n(Xje,"STRONG",{});var eSt=s(p1e);cPo=r(eSt,"marian"),eSt.forEach(t),mPo=r(Xje," \u2014 "),qX=n(Xje,"A",{href:!0});var oSt=s(qX);fPo=r(oSt,"MarianModel"),oSt.forEach(t),gPo=r(Xje," (Marian model)"),Xje.forEach(t),hPo=i(x),w1=n(x,"LI",{});var zje=s(w1);_1e=n(zje,"STRONG",{});var rSt=s(_1e);uPo=r(rSt,"markuplm"),rSt.forEach(t),pPo=r(zje," \u2014 "),jX=n(zje,"A",{href:!0});var tSt=s(jX);_Po=r(tSt,"MarkupLMModel"),tSt.forEach(t),bPo=r(zje," (MarkupLM model)"),zje.forEach(t),vPo=i(x),A1=n(x,"LI",{});var Qje=s(A1);b1e=n(Qje,"STRONG",{});var aSt=s(b1e);FPo=r(aSt,"maskformer"),aSt.forEach(t),TPo=r(Qje," \u2014 "),DX=n(Qje,"A",{href:!0});var nSt=s(DX);MPo=r(nSt,"MaskFormerModel"),nSt.forEach(t),EPo=r(Qje," (MaskFormer model)"),Qje.forEach(t),CPo=i(x),L1=n(x,"LI",{});var Wje=s(L1);v1e=n(Wje,"STRONG",{});var sSt=s(v1e);wPo=r(sSt,"mbart"),sSt.forEach(t),APo=r(Wje," \u2014 "),GX=n(Wje,"A",{href:!0});var lSt=s(GX);LPo=r(lSt,"MBartModel"),lSt.forEach(t),yPo=r(Wje," (mBART model)"),Wje.forEach(t),xPo=i(x),y1=n(x,"LI",{});var Uje=s(y1);F1e=n(Uje,"STRONG",{});var iSt=s(F1e);$Po=r(iSt,"mctct"),iSt.forEach(t),kPo=r(Uje," \u2014 "),OX=n(Uje,"A",{href:!0});var dSt=s(OX);SPo=r(dSt,"MCTCTModel"),dSt.forEach(t),RPo=r(Uje," (M-CTC-T model)"),Uje.forEach(t),PPo=i(x),x1=n(x,"LI",{});var Hje=s(x1);T1e=n(Hje,"STRONG",{});var cSt=s(T1e);BPo=r(cSt,"megatron-bert"),cSt.forEach(t),IPo=r(Hje," \u2014 "),VX=n(Hje,"A",{href:!0});var mSt=s(VX);NPo=r(mSt,"MegatronBertModel"),mSt.forEach(t),qPo=r(Hje," (Megatron-BERT model)"),Hje.forEach(t),jPo=i(x),$1=n(x,"LI",{});var Jje=s($1);M1e=n(Jje,"STRONG",{});var fSt=s(M1e);DPo=r(fSt,"mobilebert"),fSt.forEach(t),GPo=r(Jje," \u2014 "),XX=n(Jje,"A",{href:!0});var gSt=s(XX);OPo=r(gSt,"MobileBertModel"),gSt.forEach(t),VPo=r(Jje," (MobileBERT model)"),Jje.forEach(t),XPo=i(x),k1=n(x,"LI",{});var Yje=s(k1);E1e=n(Yje,"STRONG",{});var hSt=s(E1e);zPo=r(hSt,"mobilevit"),hSt.forEach(t),QPo=r(Yje," \u2014 "),zX=n(Yje,"A",{href:!0});var uSt=s(zX);WPo=r(uSt,"MobileViTModel"),uSt.forEach(t),UPo=r(Yje," (MobileViT model)"),Yje.forEach(t),HPo=i(x),S1=n(x,"LI",{});var Zje=s(S1);C1e=n(Zje,"STRONG",{});var pSt=s(C1e);JPo=r(pSt,"mpnet"),pSt.forEach(t),YPo=r(Zje," \u2014 "),QX=n(Zje,"A",{href:!0});var _St=s(QX);ZPo=r(_St,"MPNetModel"),_St.forEach(t),KPo=r(Zje," (MPNet model)"),Zje.forEach(t),eBo=i(x),R1=n(x,"LI",{});var Kje=s(R1);w1e=n(Kje,"STRONG",{});var bSt=s(w1e);oBo=r(bSt,"mt5"),bSt.forEach(t),rBo=r(Kje," \u2014 "),WX=n(Kje,"A",{href:!0});var vSt=s(WX);tBo=r(vSt,"MT5Model"),vSt.forEach(t),aBo=r(Kje," (MT5 model)"),Kje.forEach(t),nBo=i(x),P1=n(x,"LI",{});var eDe=s(P1);A1e=n(eDe,"STRONG",{});var FSt=s(A1e);sBo=r(FSt,"mvp"),FSt.forEach(t),lBo=r(eDe," \u2014 "),UX=n(eDe,"A",{href:!0});var TSt=s(UX);iBo=r(TSt,"MvpModel"),TSt.forEach(t),dBo=r(eDe," (MVP model)"),eDe.forEach(t),cBo=i(x),B1=n(x,"LI",{});var oDe=s(B1);L1e=n(oDe,"STRONG",{});var MSt=s(L1e);mBo=r(MSt,"nezha"),MSt.forEach(t),fBo=r(oDe," \u2014 "),HX=n(oDe,"A",{href:!0});var ESt=s(HX);gBo=r(ESt,"NezhaModel"),ESt.forEach(t),hBo=r(oDe," (Nezha model)"),oDe.forEach(t),uBo=i(x),I1=n(x,"LI",{});var rDe=s(I1);y1e=n(rDe,"STRONG",{});var CSt=s(y1e);pBo=r(CSt,"nllb"),CSt.forEach(t),_Bo=r(rDe," \u2014 "),JX=n(rDe,"A",{href:!0});var wSt=s(JX);bBo=r(wSt,"M2M100Model"),wSt.forEach(t),vBo=r(rDe," (NLLB model)"),rDe.forEach(t),FBo=i(x),N1=n(x,"LI",{});var tDe=s(N1);x1e=n(tDe,"STRONG",{});var ASt=s(x1e);TBo=r(ASt,"nystromformer"),ASt.forEach(t),MBo=r(tDe," \u2014 "),YX=n(tDe,"A",{href:!0});var LSt=s(YX);EBo=r(LSt,"NystromformerModel"),LSt.forEach(t),CBo=r(tDe," (Nystr\xF6mformer model)"),tDe.forEach(t),wBo=i(x),q1=n(x,"LI",{});var aDe=s(q1);$1e=n(aDe,"STRONG",{});var ySt=s($1e);ABo=r(ySt,"openai-gpt"),ySt.forEach(t),LBo=r(aDe," \u2014 "),ZX=n(aDe,"A",{href:!0});var xSt=s(ZX);yBo=r(xSt,"OpenAIGPTModel"),xSt.forEach(t),xBo=r(aDe," (OpenAI GPT model)"),aDe.forEach(t),$Bo=i(x),j1=n(x,"LI",{});var nDe=s(j1);k1e=n(nDe,"STRONG",{});var $St=s(k1e);kBo=r($St,"opt"),$St.forEach(t),SBo=r(nDe," \u2014 "),KX=n(nDe,"A",{href:!0});var kSt=s(KX);RBo=r(kSt,"OPTModel"),kSt.forEach(t),PBo=r(nDe," (OPT model)"),nDe.forEach(t),BBo=i(x),D1=n(x,"LI",{});var sDe=s(D1);S1e=n(sDe,"STRONG",{});var SSt=s(S1e);IBo=r(SSt,"owlvit"),SSt.forEach(t),NBo=r(sDe," \u2014 "),ez=n(sDe,"A",{href:!0});var RSt=s(ez);qBo=r(RSt,"OwlViTModel"),RSt.forEach(t),jBo=r(sDe," (OWL-ViT model)"),sDe.forEach(t),DBo=i(x),G1=n(x,"LI",{});var lDe=s(G1);R1e=n(lDe,"STRONG",{});var PSt=s(R1e);GBo=r(PSt,"pegasus"),PSt.forEach(t),OBo=r(lDe," \u2014 "),oz=n(lDe,"A",{href:!0});var BSt=s(oz);VBo=r(BSt,"PegasusModel"),BSt.forEach(t),XBo=r(lDe," (Pegasus model)"),lDe.forEach(t),zBo=i(x),O1=n(x,"LI",{});var iDe=s(O1);P1e=n(iDe,"STRONG",{});var ISt=s(P1e);QBo=r(ISt,"pegasus_x"),ISt.forEach(t),WBo=r(iDe," \u2014 "),rz=n(iDe,"A",{href:!0});var NSt=s(rz);UBo=r(NSt,"PegasusXModel"),NSt.forEach(t),HBo=r(iDe," (PEGASUS-X model)"),iDe.forEach(t),JBo=i(x),V1=n(x,"LI",{});var dDe=s(V1);B1e=n(dDe,"STRONG",{});var qSt=s(B1e);YBo=r(qSt,"perceiver"),qSt.forEach(t),ZBo=r(dDe," \u2014 "),tz=n(dDe,"A",{href:!0});var jSt=s(tz);KBo=r(jSt,"PerceiverModel"),jSt.forEach(t),eIo=r(dDe," (Perceiver model)"),dDe.forEach(t),oIo=i(x),X1=n(x,"LI",{});var cDe=s(X1);I1e=n(cDe,"STRONG",{});var DSt=s(I1e);rIo=r(DSt,"plbart"),DSt.forEach(t),tIo=r(cDe," \u2014 "),az=n(cDe,"A",{href:!0});var GSt=s(az);aIo=r(GSt,"PLBartModel"),GSt.forEach(t),nIo=r(cDe," (PLBart model)"),cDe.forEach(t),sIo=i(x),z1=n(x,"LI",{});var mDe=s(z1);N1e=n(mDe,"STRONG",{});var OSt=s(N1e);lIo=r(OSt,"poolformer"),OSt.forEach(t),iIo=r(mDe," \u2014 "),nz=n(mDe,"A",{href:!0});var VSt=s(nz);dIo=r(VSt,"PoolFormerModel"),VSt.forEach(t),cIo=r(mDe," (PoolFormer model)"),mDe.forEach(t),mIo=i(x),Q1=n(x,"LI",{});var fDe=s(Q1);q1e=n(fDe,"STRONG",{});var XSt=s(q1e);fIo=r(XSt,"prophetnet"),XSt.forEach(t),gIo=r(fDe," \u2014 "),sz=n(fDe,"A",{href:!0});var zSt=s(sz);hIo=r(zSt,"ProphetNetModel"),zSt.forEach(t),uIo=r(fDe," (ProphetNet model)"),fDe.forEach(t),pIo=i(x),W1=n(x,"LI",{});var gDe=s(W1);j1e=n(gDe,"STRONG",{});var QSt=s(j1e);_Io=r(QSt,"qdqbert"),QSt.forEach(t),bIo=r(gDe," \u2014 "),lz=n(gDe,"A",{href:!0});var WSt=s(lz);vIo=r(WSt,"QDQBertModel"),WSt.forEach(t),FIo=r(gDe," (QDQBert model)"),gDe.forEach(t),TIo=i(x),U1=n(x,"LI",{});var hDe=s(U1);D1e=n(hDe,"STRONG",{});var USt=s(D1e);MIo=r(USt,"reformer"),USt.forEach(t),EIo=r(hDe," \u2014 "),iz=n(hDe,"A",{href:!0});var HSt=s(iz);CIo=r(HSt,"ReformerModel"),HSt.forEach(t),wIo=r(hDe," (Reformer model)"),hDe.forEach(t),AIo=i(x),H1=n(x,"LI",{});var uDe=s(H1);G1e=n(uDe,"STRONG",{});var JSt=s(G1e);LIo=r(JSt,"regnet"),JSt.forEach(t),yIo=r(uDe," \u2014 "),dz=n(uDe,"A",{href:!0});var YSt=s(dz);xIo=r(YSt,"RegNetModel"),YSt.forEach(t),$Io=r(uDe," (RegNet model)"),uDe.forEach(t),kIo=i(x),J1=n(x,"LI",{});var pDe=s(J1);O1e=n(pDe,"STRONG",{});var ZSt=s(O1e);SIo=r(ZSt,"rembert"),ZSt.forEach(t),RIo=r(pDe," \u2014 "),cz=n(pDe,"A",{href:!0});var KSt=s(cz);PIo=r(KSt,"RemBertModel"),KSt.forEach(t),BIo=r(pDe," (RemBERT model)"),pDe.forEach(t),IIo=i(x),Y1=n(x,"LI",{});var _De=s(Y1);V1e=n(_De,"STRONG",{});var eRt=s(V1e);NIo=r(eRt,"resnet"),eRt.forEach(t),qIo=r(_De," \u2014 "),mz=n(_De,"A",{href:!0});var oRt=s(mz);jIo=r(oRt,"ResNetModel"),oRt.forEach(t),DIo=r(_De," (ResNet model)"),_De.forEach(t),GIo=i(x),Z1=n(x,"LI",{});var bDe=s(Z1);X1e=n(bDe,"STRONG",{});var rRt=s(X1e);OIo=r(rRt,"retribert"),rRt.forEach(t),VIo=r(bDe," \u2014 "),fz=n(bDe,"A",{href:!0});var tRt=s(fz);XIo=r(tRt,"RetriBertModel"),tRt.forEach(t),zIo=r(bDe," (RetriBERT model)"),bDe.forEach(t),QIo=i(x),K1=n(x,"LI",{});var vDe=s(K1);z1e=n(vDe,"STRONG",{});var aRt=s(z1e);WIo=r(aRt,"roberta"),aRt.forEach(t),UIo=r(vDe," \u2014 "),gz=n(vDe,"A",{href:!0});var nRt=s(gz);HIo=r(nRt,"RobertaModel"),nRt.forEach(t),JIo=r(vDe," (RoBERTa model)"),vDe.forEach(t),YIo=i(x),eb=n(x,"LI",{});var FDe=s(eb);Q1e=n(FDe,"STRONG",{});var sRt=s(Q1e);ZIo=r(sRt,"roformer"),sRt.forEach(t),KIo=r(FDe," \u2014 "),hz=n(FDe,"A",{href:!0});var lRt=s(hz);eNo=r(lRt,"RoFormerModel"),lRt.forEach(t),oNo=r(FDe," (RoFormer model)"),FDe.forEach(t),rNo=i(x),ob=n(x,"LI",{});var TDe=s(ob);W1e=n(TDe,"STRONG",{});var iRt=s(W1e);tNo=r(iRt,"segformer"),iRt.forEach(t),aNo=r(TDe," \u2014 "),uz=n(TDe,"A",{href:!0});var dRt=s(uz);nNo=r(dRt,"SegformerModel"),dRt.forEach(t),sNo=r(TDe," (SegFormer model)"),TDe.forEach(t),lNo=i(x),rb=n(x,"LI",{});var MDe=s(rb);U1e=n(MDe,"STRONG",{});var cRt=s(U1e);iNo=r(cRt,"sew"),cRt.forEach(t),dNo=r(MDe," \u2014 "),pz=n(MDe,"A",{href:!0});var mRt=s(pz);cNo=r(mRt,"SEWModel"),mRt.forEach(t),mNo=r(MDe," (SEW model)"),MDe.forEach(t),fNo=i(x),tb=n(x,"LI",{});var EDe=s(tb);H1e=n(EDe,"STRONG",{});var fRt=s(H1e);gNo=r(fRt,"sew-d"),fRt.forEach(t),hNo=r(EDe," \u2014 "),_z=n(EDe,"A",{href:!0});var gRt=s(_z);uNo=r(gRt,"SEWDModel"),gRt.forEach(t),pNo=r(EDe," (SEW-D model)"),EDe.forEach(t),_No=i(x),ab=n(x,"LI",{});var CDe=s(ab);J1e=n(CDe,"STRONG",{});var hRt=s(J1e);bNo=r(hRt,"speech_to_text"),hRt.forEach(t),vNo=r(CDe," \u2014 "),bz=n(CDe,"A",{href:!0});var uRt=s(bz);FNo=r(uRt,"Speech2TextModel"),uRt.forEach(t),TNo=r(CDe," (Speech2Text model)"),CDe.forEach(t),MNo=i(x),nb=n(x,"LI",{});var wDe=s(nb);Y1e=n(wDe,"STRONG",{});var pRt=s(Y1e);ENo=r(pRt,"splinter"),pRt.forEach(t),CNo=r(wDe," \u2014 "),vz=n(wDe,"A",{href:!0});var _Rt=s(vz);wNo=r(_Rt,"SplinterModel"),_Rt.forEach(t),ANo=r(wDe," (Splinter model)"),wDe.forEach(t),LNo=i(x),sb=n(x,"LI",{});var ADe=s(sb);Z1e=n(ADe,"STRONG",{});var bRt=s(Z1e);yNo=r(bRt,"squeezebert"),bRt.forEach(t),xNo=r(ADe," \u2014 "),Fz=n(ADe,"A",{href:!0});var vRt=s(Fz);$No=r(vRt,"SqueezeBertModel"),vRt.forEach(t),kNo=r(ADe," (SqueezeBERT model)"),ADe.forEach(t),SNo=i(x),lb=n(x,"LI",{});var LDe=s(lb);K1e=n(LDe,"STRONG",{});var FRt=s(K1e);RNo=r(FRt,"swin"),FRt.forEach(t),PNo=r(LDe," \u2014 "),Tz=n(LDe,"A",{href:!0});var TRt=s(Tz);BNo=r(TRt,"SwinModel"),TRt.forEach(t),INo=r(LDe," (Swin Transformer model)"),LDe.forEach(t),NNo=i(x),ib=n(x,"LI",{});var yDe=s(ib);ebe=n(yDe,"STRONG",{});var MRt=s(ebe);qNo=r(MRt,"swinv2"),MRt.forEach(t),jNo=r(yDe," \u2014 "),Mz=n(yDe,"A",{href:!0});var ERt=s(Mz);DNo=r(ERt,"Swinv2Model"),ERt.forEach(t),GNo=r(yDe," (Swin Transformer V2 model)"),yDe.forEach(t),ONo=i(x),db=n(x,"LI",{});var xDe=s(db);obe=n(xDe,"STRONG",{});var CRt=s(obe);VNo=r(CRt,"t5"),CRt.forEach(t),XNo=r(xDe," \u2014 "),Ez=n(xDe,"A",{href:!0});var wRt=s(Ez);zNo=r(wRt,"T5Model"),wRt.forEach(t),QNo=r(xDe," (T5 model)"),xDe.forEach(t),WNo=i(x),cb=n(x,"LI",{});var $De=s(cb);rbe=n($De,"STRONG",{});var ARt=s(rbe);UNo=r(ARt,"tapas"),ARt.forEach(t),HNo=r($De," \u2014 "),Cz=n($De,"A",{href:!0});var LRt=s(Cz);JNo=r(LRt,"TapasModel"),LRt.forEach(t),YNo=r($De," (TAPAS model)"),$De.forEach(t),ZNo=i(x),mb=n(x,"LI",{});var kDe=s(mb);tbe=n(kDe,"STRONG",{});var yRt=s(tbe);KNo=r(yRt,"time_series_transformer"),yRt.forEach(t),eqo=r(kDe," \u2014 "),wz=n(kDe,"A",{href:!0});var xRt=s(wz);oqo=r(xRt,"TimeSeriesTransformerModel"),xRt.forEach(t),rqo=r(kDe," (Time Series Transformer model)"),kDe.forEach(t),tqo=i(x),fb=n(x,"LI",{});var SDe=s(fb);abe=n(SDe,"STRONG",{});var $Rt=s(abe);aqo=r($Rt,"trajectory_transformer"),$Rt.forEach(t),nqo=r(SDe," \u2014 "),Az=n(SDe,"A",{href:!0});var kRt=s(Az);sqo=r(kRt,"TrajectoryTransformerModel"),kRt.forEach(t),lqo=r(SDe," (Trajectory Transformer model)"),SDe.forEach(t),iqo=i(x),gb=n(x,"LI",{});var RDe=s(gb);nbe=n(RDe,"STRONG",{});var SRt=s(nbe);dqo=r(SRt,"transfo-xl"),SRt.forEach(t),cqo=r(RDe," \u2014 "),Lz=n(RDe,"A",{href:!0});var RRt=s(Lz);mqo=r(RRt,"TransfoXLModel"),RRt.forEach(t),fqo=r(RDe," (Transformer-XL model)"),RDe.forEach(t),gqo=i(x),hb=n(x,"LI",{});var PDe=s(hb);sbe=n(PDe,"STRONG",{});var PRt=s(sbe);hqo=r(PRt,"unispeech"),PRt.forEach(t),uqo=r(PDe," \u2014 "),yz=n(PDe,"A",{href:!0});var BRt=s(yz);pqo=r(BRt,"UniSpeechModel"),BRt.forEach(t),_qo=r(PDe," (UniSpeech model)"),PDe.forEach(t),bqo=i(x),ub=n(x,"LI",{});var BDe=s(ub);lbe=n(BDe,"STRONG",{});var IRt=s(lbe);vqo=r(IRt,"unispeech-sat"),IRt.forEach(t),Fqo=r(BDe," \u2014 "),xz=n(BDe,"A",{href:!0});var NRt=s(xz);Tqo=r(NRt,"UniSpeechSatModel"),NRt.forEach(t),Mqo=r(BDe," (UniSpeechSat model)"),BDe.forEach(t),Eqo=i(x),pb=n(x,"LI",{});var IDe=s(pb);ibe=n(IDe,"STRONG",{});var qRt=s(ibe);Cqo=r(qRt,"van"),qRt.forEach(t),wqo=r(IDe," \u2014 "),$z=n(IDe,"A",{href:!0});var jRt=s($z);Aqo=r(jRt,"VanModel"),jRt.forEach(t),Lqo=r(IDe," (VAN model)"),IDe.forEach(t),yqo=i(x),_b=n(x,"LI",{});var NDe=s(_b);dbe=n(NDe,"STRONG",{});var DRt=s(dbe);xqo=r(DRt,"videomae"),DRt.forEach(t),$qo=r(NDe," \u2014 "),kz=n(NDe,"A",{href:!0});var GRt=s(kz);kqo=r(GRt,"VideoMAEModel"),GRt.forEach(t),Sqo=r(NDe," (VideoMAE model)"),NDe.forEach(t),Rqo=i(x),bb=n(x,"LI",{});var qDe=s(bb);cbe=n(qDe,"STRONG",{});var ORt=s(cbe);Pqo=r(ORt,"vilt"),ORt.forEach(t),Bqo=r(qDe," \u2014 "),Sz=n(qDe,"A",{href:!0});var VRt=s(Sz);Iqo=r(VRt,"ViltModel"),VRt.forEach(t),Nqo=r(qDe," (ViLT model)"),qDe.forEach(t),qqo=i(x),vb=n(x,"LI",{});var jDe=s(vb);mbe=n(jDe,"STRONG",{});var XRt=s(mbe);jqo=r(XRt,"vision-text-dual-encoder"),XRt.forEach(t),Dqo=r(jDe," \u2014 "),Rz=n(jDe,"A",{href:!0});var zRt=s(Rz);Gqo=r(zRt,"VisionTextDualEncoderModel"),zRt.forEach(t),Oqo=r(jDe," (VisionTextDualEncoder model)"),jDe.forEach(t),Vqo=i(x),Fb=n(x,"LI",{});var DDe=s(Fb);fbe=n(DDe,"STRONG",{});var QRt=s(fbe);Xqo=r(QRt,"visual_bert"),QRt.forEach(t),zqo=r(DDe," \u2014 "),Pz=n(DDe,"A",{href:!0});var WRt=s(Pz);Qqo=r(WRt,"VisualBertModel"),WRt.forEach(t),Wqo=r(DDe," (VisualBERT model)"),DDe.forEach(t),Uqo=i(x),Tb=n(x,"LI",{});var GDe=s(Tb);gbe=n(GDe,"STRONG",{});var URt=s(gbe);Hqo=r(URt,"vit"),URt.forEach(t),Jqo=r(GDe," \u2014 "),Bz=n(GDe,"A",{href:!0});var HRt=s(Bz);Yqo=r(HRt,"ViTModel"),HRt.forEach(t),Zqo=r(GDe," (ViT model)"),GDe.forEach(t),Kqo=i(x),Mb=n(x,"LI",{});var ODe=s(Mb);hbe=n(ODe,"STRONG",{});var JRt=s(hbe);ejo=r(JRt,"vit_mae"),JRt.forEach(t),ojo=r(ODe," \u2014 "),Iz=n(ODe,"A",{href:!0});var YRt=s(Iz);rjo=r(YRt,"ViTMAEModel"),YRt.forEach(t),tjo=r(ODe," (ViTMAE model)"),ODe.forEach(t),ajo=i(x),Eb=n(x,"LI",{});var VDe=s(Eb);ube=n(VDe,"STRONG",{});var ZRt=s(ube);njo=r(ZRt,"vit_msn"),ZRt.forEach(t),sjo=r(VDe," \u2014 "),Nz=n(VDe,"A",{href:!0});var KRt=s(Nz);ljo=r(KRt,"ViTMSNModel"),KRt.forEach(t),ijo=r(VDe," (ViTMSN model)"),VDe.forEach(t),djo=i(x),Cb=n(x,"LI",{});var XDe=s(Cb);pbe=n(XDe,"STRONG",{});var ePt=s(pbe);cjo=r(ePt,"wav2vec2"),ePt.forEach(t),mjo=r(XDe," \u2014 "),qz=n(XDe,"A",{href:!0});var oPt=s(qz);fjo=r(oPt,"Wav2Vec2Model"),oPt.forEach(t),gjo=r(XDe," (Wav2Vec2 model)"),XDe.forEach(t),hjo=i(x),wb=n(x,"LI",{});var zDe=s(wb);_be=n(zDe,"STRONG",{});var rPt=s(_be);ujo=r(rPt,"wav2vec2-conformer"),rPt.forEach(t),pjo=r(zDe," \u2014 "),jz=n(zDe,"A",{href:!0});var tPt=s(jz);_jo=r(tPt,"Wav2Vec2ConformerModel"),tPt.forEach(t),bjo=r(zDe," (Wav2Vec2-Conformer model)"),zDe.forEach(t),vjo=i(x),Ab=n(x,"LI",{});var QDe=s(Ab);bbe=n(QDe,"STRONG",{});var aPt=s(bbe);Fjo=r(aPt,"wavlm"),aPt.forEach(t),Tjo=r(QDe," \u2014 "),Dz=n(QDe,"A",{href:!0});var nPt=s(Dz);Mjo=r(nPt,"WavLMModel"),nPt.forEach(t),Ejo=r(QDe," (WavLM model)"),QDe.forEach(t),Cjo=i(x),Lb=n(x,"LI",{});var WDe=s(Lb);vbe=n(WDe,"STRONG",{});var sPt=s(vbe);wjo=r(sPt,"whisper"),sPt.forEach(t),Ajo=r(WDe," \u2014 "),Gz=n(WDe,"A",{href:!0});var lPt=s(Gz);Ljo=r(lPt,"WhisperModel"),lPt.forEach(t),yjo=r(WDe," (Whisper model)"),WDe.forEach(t),xjo=i(x),yb=n(x,"LI",{});var UDe=s(yb);Fbe=n(UDe,"STRONG",{});var iPt=s(Fbe);$jo=r(iPt,"xclip"),iPt.forEach(t),kjo=r(UDe," \u2014 "),Oz=n(UDe,"A",{href:!0});var dPt=s(Oz);Sjo=r(dPt,"XCLIPModel"),dPt.forEach(t),Rjo=r(UDe," (X-CLIP model)"),UDe.forEach(t),Pjo=i(x),xb=n(x,"LI",{});var HDe=s(xb);Tbe=n(HDe,"STRONG",{});var cPt=s(Tbe);Bjo=r(cPt,"xglm"),cPt.forEach(t),Ijo=r(HDe," \u2014 "),Vz=n(HDe,"A",{href:!0});var mPt=s(Vz);Njo=r(mPt,"XGLMModel"),mPt.forEach(t),qjo=r(HDe," (XGLM model)"),HDe.forEach(t),jjo=i(x),$b=n(x,"LI",{});var JDe=s($b);Mbe=n(JDe,"STRONG",{});var fPt=s(Mbe);Djo=r(fPt,"xlm"),fPt.forEach(t),Gjo=r(JDe," \u2014 "),Xz=n(JDe,"A",{href:!0});var gPt=s(Xz);Ojo=r(gPt,"XLMModel"),gPt.forEach(t),Vjo=r(JDe," (XLM model)"),JDe.forEach(t),Xjo=i(x),kb=n(x,"LI",{});var YDe=s(kb);Ebe=n(YDe,"STRONG",{});var hPt=s(Ebe);zjo=r(hPt,"xlm-prophetnet"),hPt.forEach(t),Qjo=r(YDe," \u2014 "),zz=n(YDe,"A",{href:!0});var uPt=s(zz);Wjo=r(uPt,"XLMProphetNetModel"),uPt.forEach(t),Ujo=r(YDe," (XLM-ProphetNet model)"),YDe.forEach(t),Hjo=i(x),Sb=n(x,"LI",{});var ZDe=s(Sb);Cbe=n(ZDe,"STRONG",{});var pPt=s(Cbe);Jjo=r(pPt,"xlm-roberta"),pPt.forEach(t),Yjo=r(ZDe," \u2014 "),Qz=n(ZDe,"A",{href:!0});var _Pt=s(Qz);Zjo=r(_Pt,"XLMRobertaModel"),_Pt.forEach(t),Kjo=r(ZDe," (XLM-RoBERTa model)"),ZDe.forEach(t),eDo=i(x),Rb=n(x,"LI",{});var KDe=s(Rb);wbe=n(KDe,"STRONG",{});var bPt=s(wbe);oDo=r(bPt,"xlm-roberta-xl"),bPt.forEach(t),rDo=r(KDe," \u2014 "),Wz=n(KDe,"A",{href:!0});var vPt=s(Wz);tDo=r(vPt,"XLMRobertaXLModel"),vPt.forEach(t),aDo=r(KDe," (XLM-RoBERTa-XL model)"),KDe.forEach(t),nDo=i(x),Pb=n(x,"LI",{});var eGe=s(Pb);Abe=n(eGe,"STRONG",{});var FPt=s(Abe);sDo=r(FPt,"xlnet"),FPt.forEach(t),lDo=r(eGe," \u2014 "),Uz=n(eGe,"A",{href:!0});var TPt=s(Uz);iDo=r(TPt,"XLNetModel"),TPt.forEach(t),dDo=r(eGe," (XLNet model)"),eGe.forEach(t),cDo=i(x),Bb=n(x,"LI",{});var oGe=s(Bb);Lbe=n(oGe,"STRONG",{});var MPt=s(Lbe);mDo=r(MPt,"yolos"),MPt.forEach(t),fDo=r(oGe," \u2014 "),Hz=n(oGe,"A",{href:!0});var EPt=s(Hz);gDo=r(EPt,"YolosModel"),EPt.forEach(t),hDo=r(oGe," (YOLOS model)"),oGe.forEach(t),uDo=i(x),Ib=n(x,"LI",{});var rGe=s(Ib);ybe=n(rGe,"STRONG",{});var CPt=s(ybe);pDo=r(CPt,"yoso"),CPt.forEach(t),_Do=r(rGe," \u2014 "),Jz=n(rGe,"A",{href:!0});var wPt=s(Jz);bDo=r(wPt,"YosoModel"),wPt.forEach(t),vDo=r(rGe," (YOSO model)"),rGe.forEach(t),x.forEach(t),FDo=i(Ea),Nb=n(Ea,"P",{});var tGe=s(Nb);TDo=r(tGe,"The model is set in evaluation mode by default using "),xbe=n(tGe,"CODE",{});var APt=s(xbe);MDo=r(APt,"model.eval()"),APt.forEach(t),EDo=r(tGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$be=n(tGe,"CODE",{});var LPt=s($be);CDo=r(LPt,"model.train()"),LPt.forEach(t),tGe.forEach(t),wDo=i(Ea),T(qb.$$.fragment,Ea),Ea.forEach(t),kl.forEach(t),Eoo=i(m),Ad=n(m,"H2",{class:!0});var jto=s(Ad);jb=n(jto,"A",{id:!0,class:!0,href:!0});var yPt=s(jb);kbe=n(yPt,"SPAN",{});var xPt=s(kbe);T(t$.$$.fragment,xPt),xPt.forEach(t),yPt.forEach(t),ADo=i(jto),Sbe=n(jto,"SPAN",{});var $Pt=s(Sbe);LDo=r($Pt,"AutoModelForPreTraining"),$Pt.forEach(t),jto.forEach(t),Coo=i(m),Io=n(m,"DIV",{class:!0});var Sl=s(Io);T(a$.$$.fragment,Sl),yDo=i(Sl),Ld=n(Sl,"P",{});var Oie=s(Ld);xDo=r(Oie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yz=n(Oie,"A",{href:!0});var kPt=s(Yz);$Do=r(kPt,"from_pretrained()"),kPt.forEach(t),kDo=r(Oie," class method or the "),Zz=n(Oie,"A",{href:!0});var SPt=s(Zz);SDo=r(SPt,"from_config()"),SPt.forEach(t),RDo=r(Oie,` class
method.`),Oie.forEach(t),PDo=i(Sl),n$=n(Sl,"P",{});var Dto=s(n$);BDo=r(Dto,"This class cannot be instantiated directly using "),Rbe=n(Dto,"CODE",{});var RPt=s(Rbe);IDo=r(RPt,"__init__()"),RPt.forEach(t),NDo=r(Dto," (throws an error)."),Dto.forEach(t),qDo=i(Sl),Ft=n(Sl,"DIV",{class:!0});var F8=s(Ft);T(s$.$$.fragment,F8),jDo=i(F8),Pbe=n(F8,"P",{});var PPt=s(Pbe);DDo=r(PPt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),PPt.forEach(t),GDo=i(F8),yd=n(F8,"P",{});var Vie=s(yd);ODo=r(Vie,`Note:
Loading a model from its configuration file does `),Bbe=n(Vie,"STRONG",{});var BPt=s(Bbe);VDo=r(BPt,"not"),BPt.forEach(t),XDo=r(Vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kz=n(Vie,"A",{href:!0});var IPt=s(Kz);zDo=r(IPt,"from_pretrained()"),IPt.forEach(t),QDo=r(Vie," to load the model weights."),Vie.forEach(t),WDo=i(F8),T(Db.$$.fragment,F8),F8.forEach(t),UDo=i(Sl),eo=n(Sl,"DIV",{class:!0});var Ca=s(eo);T(l$.$$.fragment,Ca),HDo=i(Ca),Ibe=n(Ca,"P",{});var NPt=s(Ibe);JDo=r(NPt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),NPt.forEach(t),YDo=i(Ca),on=n(Ca,"P",{});var T8=s(on);ZDo=r(T8,"The model class to instantiate is selected based on the "),Nbe=n(T8,"CODE",{});var qPt=s(Nbe);KDo=r(qPt,"model_type"),qPt.forEach(t),eGo=r(T8,` property of the config object (either
passed as an argument or loaded from `),qbe=n(T8,"CODE",{});var jPt=s(qbe);oGo=r(jPt,"pretrained_model_name_or_path"),jPt.forEach(t),rGo=r(T8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jbe=n(T8,"CODE",{});var DPt=s(jbe);tGo=r(DPt,"pretrained_model_name_or_path"),DPt.forEach(t),aGo=r(T8,":"),T8.forEach(t),nGo=i(Ca),G=n(Ca,"UL",{});var V=s(G);Gb=n(V,"LI",{});var aGe=s(Gb);Dbe=n(aGe,"STRONG",{});var GPt=s(Dbe);sGo=r(GPt,"albert"),GPt.forEach(t),lGo=r(aGe," \u2014 "),eQ=n(aGe,"A",{href:!0});var OPt=s(eQ);iGo=r(OPt,"AlbertForPreTraining"),OPt.forEach(t),dGo=r(aGe," (ALBERT model)"),aGe.forEach(t),cGo=i(V),Ob=n(V,"LI",{});var nGe=s(Ob);Gbe=n(nGe,"STRONG",{});var VPt=s(Gbe);mGo=r(VPt,"bart"),VPt.forEach(t),fGo=r(nGe," \u2014 "),oQ=n(nGe,"A",{href:!0});var XPt=s(oQ);gGo=r(XPt,"BartForConditionalGeneration"),XPt.forEach(t),hGo=r(nGe," (BART model)"),nGe.forEach(t),uGo=i(V),Vb=n(V,"LI",{});var sGe=s(Vb);Obe=n(sGe,"STRONG",{});var zPt=s(Obe);pGo=r(zPt,"bert"),zPt.forEach(t),_Go=r(sGe," \u2014 "),rQ=n(sGe,"A",{href:!0});var QPt=s(rQ);bGo=r(QPt,"BertForPreTraining"),QPt.forEach(t),vGo=r(sGe," (BERT model)"),sGe.forEach(t),FGo=i(V),Xb=n(V,"LI",{});var lGe=s(Xb);Vbe=n(lGe,"STRONG",{});var WPt=s(Vbe);TGo=r(WPt,"big_bird"),WPt.forEach(t),MGo=r(lGe," \u2014 "),tQ=n(lGe,"A",{href:!0});var UPt=s(tQ);EGo=r(UPt,"BigBirdForPreTraining"),UPt.forEach(t),CGo=r(lGe," (BigBird model)"),lGe.forEach(t),wGo=i(V),zb=n(V,"LI",{});var iGe=s(zb);Xbe=n(iGe,"STRONG",{});var HPt=s(Xbe);AGo=r(HPt,"bloom"),HPt.forEach(t),LGo=r(iGe," \u2014 "),aQ=n(iGe,"A",{href:!0});var JPt=s(aQ);yGo=r(JPt,"BloomForCausalLM"),JPt.forEach(t),xGo=r(iGe," (BLOOM model)"),iGe.forEach(t),$Go=i(V),Qb=n(V,"LI",{});var dGe=s(Qb);zbe=n(dGe,"STRONG",{});var YPt=s(zbe);kGo=r(YPt,"camembert"),YPt.forEach(t),SGo=r(dGe," \u2014 "),nQ=n(dGe,"A",{href:!0});var ZPt=s(nQ);RGo=r(ZPt,"CamembertForMaskedLM"),ZPt.forEach(t),PGo=r(dGe," (CamemBERT model)"),dGe.forEach(t),BGo=i(V),Wb=n(V,"LI",{});var cGe=s(Wb);Qbe=n(cGe,"STRONG",{});var KPt=s(Qbe);IGo=r(KPt,"ctrl"),KPt.forEach(t),NGo=r(cGe," \u2014 "),sQ=n(cGe,"A",{href:!0});var eBt=s(sQ);qGo=r(eBt,"CTRLLMHeadModel"),eBt.forEach(t),jGo=r(cGe," (CTRL model)"),cGe.forEach(t),DGo=i(V),Ub=n(V,"LI",{});var mGe=s(Ub);Wbe=n(mGe,"STRONG",{});var oBt=s(Wbe);GGo=r(oBt,"data2vec-text"),oBt.forEach(t),OGo=r(mGe," \u2014 "),lQ=n(mGe,"A",{href:!0});var rBt=s(lQ);VGo=r(rBt,"Data2VecTextForMaskedLM"),rBt.forEach(t),XGo=r(mGe," (Data2VecText model)"),mGe.forEach(t),zGo=i(V),Hb=n(V,"LI",{});var fGe=s(Hb);Ube=n(fGe,"STRONG",{});var tBt=s(Ube);QGo=r(tBt,"deberta"),tBt.forEach(t),WGo=r(fGe," \u2014 "),iQ=n(fGe,"A",{href:!0});var aBt=s(iQ);UGo=r(aBt,"DebertaForMaskedLM"),aBt.forEach(t),HGo=r(fGe," (DeBERTa model)"),fGe.forEach(t),JGo=i(V),Jb=n(V,"LI",{});var gGe=s(Jb);Hbe=n(gGe,"STRONG",{});var nBt=s(Hbe);YGo=r(nBt,"deberta-v2"),nBt.forEach(t),ZGo=r(gGe," \u2014 "),dQ=n(gGe,"A",{href:!0});var sBt=s(dQ);KGo=r(sBt,"DebertaV2ForMaskedLM"),sBt.forEach(t),eOo=r(gGe," (DeBERTa-v2 model)"),gGe.forEach(t),oOo=i(V),Yb=n(V,"LI",{});var hGe=s(Yb);Jbe=n(hGe,"STRONG",{});var lBt=s(Jbe);rOo=r(lBt,"distilbert"),lBt.forEach(t),tOo=r(hGe," \u2014 "),cQ=n(hGe,"A",{href:!0});var iBt=s(cQ);aOo=r(iBt,"DistilBertForMaskedLM"),iBt.forEach(t),nOo=r(hGe," (DistilBERT model)"),hGe.forEach(t),sOo=i(V),Zb=n(V,"LI",{});var uGe=s(Zb);Ybe=n(uGe,"STRONG",{});var dBt=s(Ybe);lOo=r(dBt,"electra"),dBt.forEach(t),iOo=r(uGe," \u2014 "),mQ=n(uGe,"A",{href:!0});var cBt=s(mQ);dOo=r(cBt,"ElectraForPreTraining"),cBt.forEach(t),cOo=r(uGe," (ELECTRA model)"),uGe.forEach(t),mOo=i(V),Kb=n(V,"LI",{});var pGe=s(Kb);Zbe=n(pGe,"STRONG",{});var mBt=s(Zbe);fOo=r(mBt,"ernie"),mBt.forEach(t),gOo=r(pGe," \u2014 "),fQ=n(pGe,"A",{href:!0});var fBt=s(fQ);hOo=r(fBt,"ErnieForPreTraining"),fBt.forEach(t),uOo=r(pGe," (ERNIE model)"),pGe.forEach(t),pOo=i(V),e2=n(V,"LI",{});var _Ge=s(e2);Kbe=n(_Ge,"STRONG",{});var gBt=s(Kbe);_Oo=r(gBt,"flaubert"),gBt.forEach(t),bOo=r(_Ge," \u2014 "),gQ=n(_Ge,"A",{href:!0});var hBt=s(gQ);vOo=r(hBt,"FlaubertWithLMHeadModel"),hBt.forEach(t),FOo=r(_Ge," (FlauBERT model)"),_Ge.forEach(t),TOo=i(V),o2=n(V,"LI",{});var bGe=s(o2);e2e=n(bGe,"STRONG",{});var uBt=s(e2e);MOo=r(uBt,"flava"),uBt.forEach(t),EOo=r(bGe," \u2014 "),hQ=n(bGe,"A",{href:!0});var pBt=s(hQ);COo=r(pBt,"FlavaForPreTraining"),pBt.forEach(t),wOo=r(bGe," (FLAVA model)"),bGe.forEach(t),AOo=i(V),r2=n(V,"LI",{});var vGe=s(r2);o2e=n(vGe,"STRONG",{});var _Bt=s(o2e);LOo=r(_Bt,"fnet"),_Bt.forEach(t),yOo=r(vGe," \u2014 "),uQ=n(vGe,"A",{href:!0});var bBt=s(uQ);xOo=r(bBt,"FNetForPreTraining"),bBt.forEach(t),$Oo=r(vGe," (FNet model)"),vGe.forEach(t),kOo=i(V),t2=n(V,"LI",{});var FGe=s(t2);r2e=n(FGe,"STRONG",{});var vBt=s(r2e);SOo=r(vBt,"fsmt"),vBt.forEach(t),ROo=r(FGe," \u2014 "),pQ=n(FGe,"A",{href:!0});var FBt=s(pQ);POo=r(FBt,"FSMTForConditionalGeneration"),FBt.forEach(t),BOo=r(FGe," (FairSeq Machine-Translation model)"),FGe.forEach(t),IOo=i(V),a2=n(V,"LI",{});var TGe=s(a2);t2e=n(TGe,"STRONG",{});var TBt=s(t2e);NOo=r(TBt,"funnel"),TBt.forEach(t),qOo=r(TGe," \u2014 "),_Q=n(TGe,"A",{href:!0});var MBt=s(_Q);jOo=r(MBt,"FunnelForPreTraining"),MBt.forEach(t),DOo=r(TGe," (Funnel Transformer model)"),TGe.forEach(t),GOo=i(V),n2=n(V,"LI",{});var MGe=s(n2);a2e=n(MGe,"STRONG",{});var EBt=s(a2e);OOo=r(EBt,"gpt2"),EBt.forEach(t),VOo=r(MGe," \u2014 "),bQ=n(MGe,"A",{href:!0});var CBt=s(bQ);XOo=r(CBt,"GPT2LMHeadModel"),CBt.forEach(t),zOo=r(MGe," (OpenAI GPT-2 model)"),MGe.forEach(t),QOo=i(V),s2=n(V,"LI",{});var EGe=s(s2);n2e=n(EGe,"STRONG",{});var wBt=s(n2e);WOo=r(wBt,"ibert"),wBt.forEach(t),UOo=r(EGe," \u2014 "),vQ=n(EGe,"A",{href:!0});var ABt=s(vQ);HOo=r(ABt,"IBertForMaskedLM"),ABt.forEach(t),JOo=r(EGe," (I-BERT model)"),EGe.forEach(t),YOo=i(V),l2=n(V,"LI",{});var CGe=s(l2);s2e=n(CGe,"STRONG",{});var LBt=s(s2e);ZOo=r(LBt,"layoutlm"),LBt.forEach(t),KOo=r(CGe," \u2014 "),FQ=n(CGe,"A",{href:!0});var yBt=s(FQ);eVo=r(yBt,"LayoutLMForMaskedLM"),yBt.forEach(t),oVo=r(CGe," (LayoutLM model)"),CGe.forEach(t),rVo=i(V),i2=n(V,"LI",{});var wGe=s(i2);l2e=n(wGe,"STRONG",{});var xBt=s(l2e);tVo=r(xBt,"longformer"),xBt.forEach(t),aVo=r(wGe," \u2014 "),TQ=n(wGe,"A",{href:!0});var $Bt=s(TQ);nVo=r($Bt,"LongformerForMaskedLM"),$Bt.forEach(t),sVo=r(wGe," (Longformer model)"),wGe.forEach(t),lVo=i(V),d2=n(V,"LI",{});var AGe=s(d2);i2e=n(AGe,"STRONG",{});var kBt=s(i2e);iVo=r(kBt,"luke"),kBt.forEach(t),dVo=r(AGe," \u2014 "),MQ=n(AGe,"A",{href:!0});var SBt=s(MQ);cVo=r(SBt,"LukeForMaskedLM"),SBt.forEach(t),mVo=r(AGe," (LUKE model)"),AGe.forEach(t),fVo=i(V),c2=n(V,"LI",{});var LGe=s(c2);d2e=n(LGe,"STRONG",{});var RBt=s(d2e);gVo=r(RBt,"lxmert"),RBt.forEach(t),hVo=r(LGe," \u2014 "),EQ=n(LGe,"A",{href:!0});var PBt=s(EQ);uVo=r(PBt,"LxmertForPreTraining"),PBt.forEach(t),pVo=r(LGe," (LXMERT model)"),LGe.forEach(t),_Vo=i(V),m2=n(V,"LI",{});var yGe=s(m2);c2e=n(yGe,"STRONG",{});var BBt=s(c2e);bVo=r(BBt,"megatron-bert"),BBt.forEach(t),vVo=r(yGe," \u2014 "),CQ=n(yGe,"A",{href:!0});var IBt=s(CQ);FVo=r(IBt,"MegatronBertForPreTraining"),IBt.forEach(t),TVo=r(yGe," (Megatron-BERT model)"),yGe.forEach(t),MVo=i(V),f2=n(V,"LI",{});var xGe=s(f2);m2e=n(xGe,"STRONG",{});var NBt=s(m2e);EVo=r(NBt,"mobilebert"),NBt.forEach(t),CVo=r(xGe," \u2014 "),wQ=n(xGe,"A",{href:!0});var qBt=s(wQ);wVo=r(qBt,"MobileBertForPreTraining"),qBt.forEach(t),AVo=r(xGe," (MobileBERT model)"),xGe.forEach(t),LVo=i(V),g2=n(V,"LI",{});var $Ge=s(g2);f2e=n($Ge,"STRONG",{});var jBt=s(f2e);yVo=r(jBt,"mpnet"),jBt.forEach(t),xVo=r($Ge," \u2014 "),AQ=n($Ge,"A",{href:!0});var DBt=s(AQ);$Vo=r(DBt,"MPNetForMaskedLM"),DBt.forEach(t),kVo=r($Ge," (MPNet model)"),$Ge.forEach(t),SVo=i(V),h2=n(V,"LI",{});var kGe=s(h2);g2e=n(kGe,"STRONG",{});var GBt=s(g2e);RVo=r(GBt,"mvp"),GBt.forEach(t),PVo=r(kGe," \u2014 "),LQ=n(kGe,"A",{href:!0});var OBt=s(LQ);BVo=r(OBt,"MvpForConditionalGeneration"),OBt.forEach(t),IVo=r(kGe," (MVP model)"),kGe.forEach(t),NVo=i(V),u2=n(V,"LI",{});var SGe=s(u2);h2e=n(SGe,"STRONG",{});var VBt=s(h2e);qVo=r(VBt,"nezha"),VBt.forEach(t),jVo=r(SGe," \u2014 "),yQ=n(SGe,"A",{href:!0});var XBt=s(yQ);DVo=r(XBt,"NezhaForPreTraining"),XBt.forEach(t),GVo=r(SGe," (Nezha model)"),SGe.forEach(t),OVo=i(V),p2=n(V,"LI",{});var RGe=s(p2);u2e=n(RGe,"STRONG",{});var zBt=s(u2e);VVo=r(zBt,"openai-gpt"),zBt.forEach(t),XVo=r(RGe," \u2014 "),xQ=n(RGe,"A",{href:!0});var QBt=s(xQ);zVo=r(QBt,"OpenAIGPTLMHeadModel"),QBt.forEach(t),QVo=r(RGe," (OpenAI GPT model)"),RGe.forEach(t),WVo=i(V),_2=n(V,"LI",{});var PGe=s(_2);p2e=n(PGe,"STRONG",{});var WBt=s(p2e);UVo=r(WBt,"retribert"),WBt.forEach(t),HVo=r(PGe," \u2014 "),$Q=n(PGe,"A",{href:!0});var UBt=s($Q);JVo=r(UBt,"RetriBertModel"),UBt.forEach(t),YVo=r(PGe," (RetriBERT model)"),PGe.forEach(t),ZVo=i(V),b2=n(V,"LI",{});var BGe=s(b2);_2e=n(BGe,"STRONG",{});var HBt=s(_2e);KVo=r(HBt,"roberta"),HBt.forEach(t),eXo=r(BGe," \u2014 "),kQ=n(BGe,"A",{href:!0});var JBt=s(kQ);oXo=r(JBt,"RobertaForMaskedLM"),JBt.forEach(t),rXo=r(BGe," (RoBERTa model)"),BGe.forEach(t),tXo=i(V),v2=n(V,"LI",{});var IGe=s(v2);b2e=n(IGe,"STRONG",{});var YBt=s(b2e);aXo=r(YBt,"splinter"),YBt.forEach(t),nXo=r(IGe," \u2014 "),SQ=n(IGe,"A",{href:!0});var ZBt=s(SQ);sXo=r(ZBt,"SplinterForPreTraining"),ZBt.forEach(t),lXo=r(IGe," (Splinter model)"),IGe.forEach(t),iXo=i(V),F2=n(V,"LI",{});var NGe=s(F2);v2e=n(NGe,"STRONG",{});var KBt=s(v2e);dXo=r(KBt,"squeezebert"),KBt.forEach(t),cXo=r(NGe," \u2014 "),RQ=n(NGe,"A",{href:!0});var eIt=s(RQ);mXo=r(eIt,"SqueezeBertForMaskedLM"),eIt.forEach(t),fXo=r(NGe," (SqueezeBERT model)"),NGe.forEach(t),gXo=i(V),T2=n(V,"LI",{});var qGe=s(T2);F2e=n(qGe,"STRONG",{});var oIt=s(F2e);hXo=r(oIt,"t5"),oIt.forEach(t),uXo=r(qGe," \u2014 "),PQ=n(qGe,"A",{href:!0});var rIt=s(PQ);pXo=r(rIt,"T5ForConditionalGeneration"),rIt.forEach(t),_Xo=r(qGe," (T5 model)"),qGe.forEach(t),bXo=i(V),M2=n(V,"LI",{});var jGe=s(M2);T2e=n(jGe,"STRONG",{});var tIt=s(T2e);vXo=r(tIt,"tapas"),tIt.forEach(t),FXo=r(jGe," \u2014 "),BQ=n(jGe,"A",{href:!0});var aIt=s(BQ);TXo=r(aIt,"TapasForMaskedLM"),aIt.forEach(t),MXo=r(jGe," (TAPAS model)"),jGe.forEach(t),EXo=i(V),E2=n(V,"LI",{});var DGe=s(E2);M2e=n(DGe,"STRONG",{});var nIt=s(M2e);CXo=r(nIt,"transfo-xl"),nIt.forEach(t),wXo=r(DGe," \u2014 "),IQ=n(DGe,"A",{href:!0});var sIt=s(IQ);AXo=r(sIt,"TransfoXLLMHeadModel"),sIt.forEach(t),LXo=r(DGe," (Transformer-XL model)"),DGe.forEach(t),yXo=i(V),C2=n(V,"LI",{});var GGe=s(C2);E2e=n(GGe,"STRONG",{});var lIt=s(E2e);xXo=r(lIt,"unispeech"),lIt.forEach(t),$Xo=r(GGe," \u2014 "),NQ=n(GGe,"A",{href:!0});var iIt=s(NQ);kXo=r(iIt,"UniSpeechForPreTraining"),iIt.forEach(t),SXo=r(GGe," (UniSpeech model)"),GGe.forEach(t),RXo=i(V),w2=n(V,"LI",{});var OGe=s(w2);C2e=n(OGe,"STRONG",{});var dIt=s(C2e);PXo=r(dIt,"unispeech-sat"),dIt.forEach(t),BXo=r(OGe," \u2014 "),qQ=n(OGe,"A",{href:!0});var cIt=s(qQ);IXo=r(cIt,"UniSpeechSatForPreTraining"),cIt.forEach(t),NXo=r(OGe," (UniSpeechSat model)"),OGe.forEach(t),qXo=i(V),A2=n(V,"LI",{});var VGe=s(A2);w2e=n(VGe,"STRONG",{});var mIt=s(w2e);jXo=r(mIt,"videomae"),mIt.forEach(t),DXo=r(VGe," \u2014 "),jQ=n(VGe,"A",{href:!0});var fIt=s(jQ);GXo=r(fIt,"VideoMAEForPreTraining"),fIt.forEach(t),OXo=r(VGe," (VideoMAE model)"),VGe.forEach(t),VXo=i(V),L2=n(V,"LI",{});var XGe=s(L2);A2e=n(XGe,"STRONG",{});var gIt=s(A2e);XXo=r(gIt,"visual_bert"),gIt.forEach(t),zXo=r(XGe," \u2014 "),DQ=n(XGe,"A",{href:!0});var hIt=s(DQ);QXo=r(hIt,"VisualBertForPreTraining"),hIt.forEach(t),WXo=r(XGe," (VisualBERT model)"),XGe.forEach(t),UXo=i(V),y2=n(V,"LI",{});var zGe=s(y2);L2e=n(zGe,"STRONG",{});var uIt=s(L2e);HXo=r(uIt,"vit_mae"),uIt.forEach(t),JXo=r(zGe," \u2014 "),GQ=n(zGe,"A",{href:!0});var pIt=s(GQ);YXo=r(pIt,"ViTMAEForPreTraining"),pIt.forEach(t),ZXo=r(zGe," (ViTMAE model)"),zGe.forEach(t),KXo=i(V),x2=n(V,"LI",{});var QGe=s(x2);y2e=n(QGe,"STRONG",{});var _It=s(y2e);ezo=r(_It,"wav2vec2"),_It.forEach(t),ozo=r(QGe," \u2014 "),OQ=n(QGe,"A",{href:!0});var bIt=s(OQ);rzo=r(bIt,"Wav2Vec2ForPreTraining"),bIt.forEach(t),tzo=r(QGe," (Wav2Vec2 model)"),QGe.forEach(t),azo=i(V),$2=n(V,"LI",{});var WGe=s($2);x2e=n(WGe,"STRONG",{});var vIt=s(x2e);nzo=r(vIt,"wav2vec2-conformer"),vIt.forEach(t),szo=r(WGe," \u2014 "),VQ=n(WGe,"A",{href:!0});var FIt=s(VQ);lzo=r(FIt,"Wav2Vec2ConformerForPreTraining"),FIt.forEach(t),izo=r(WGe," (Wav2Vec2-Conformer model)"),WGe.forEach(t),dzo=i(V),k2=n(V,"LI",{});var UGe=s(k2);$2e=n(UGe,"STRONG",{});var TIt=s($2e);czo=r(TIt,"xlm"),TIt.forEach(t),mzo=r(UGe," \u2014 "),XQ=n(UGe,"A",{href:!0});var MIt=s(XQ);fzo=r(MIt,"XLMWithLMHeadModel"),MIt.forEach(t),gzo=r(UGe," (XLM model)"),UGe.forEach(t),hzo=i(V),S2=n(V,"LI",{});var HGe=s(S2);k2e=n(HGe,"STRONG",{});var EIt=s(k2e);uzo=r(EIt,"xlm-roberta"),EIt.forEach(t),pzo=r(HGe," \u2014 "),zQ=n(HGe,"A",{href:!0});var CIt=s(zQ);_zo=r(CIt,"XLMRobertaForMaskedLM"),CIt.forEach(t),bzo=r(HGe," (XLM-RoBERTa model)"),HGe.forEach(t),vzo=i(V),R2=n(V,"LI",{});var JGe=s(R2);S2e=n(JGe,"STRONG",{});var wIt=s(S2e);Fzo=r(wIt,"xlm-roberta-xl"),wIt.forEach(t),Tzo=r(JGe," \u2014 "),QQ=n(JGe,"A",{href:!0});var AIt=s(QQ);Mzo=r(AIt,"XLMRobertaXLForMaskedLM"),AIt.forEach(t),Ezo=r(JGe," (XLM-RoBERTa-XL model)"),JGe.forEach(t),Czo=i(V),P2=n(V,"LI",{});var YGe=s(P2);R2e=n(YGe,"STRONG",{});var LIt=s(R2e);wzo=r(LIt,"xlnet"),LIt.forEach(t),Azo=r(YGe," \u2014 "),WQ=n(YGe,"A",{href:!0});var yIt=s(WQ);Lzo=r(yIt,"XLNetLMHeadModel"),yIt.forEach(t),yzo=r(YGe," (XLNet model)"),YGe.forEach(t),V.forEach(t),xzo=i(Ca),B2=n(Ca,"P",{});var ZGe=s(B2);$zo=r(ZGe,"The model is set in evaluation mode by default using "),P2e=n(ZGe,"CODE",{});var xIt=s(P2e);kzo=r(xIt,"model.eval()"),xIt.forEach(t),Szo=r(ZGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B2e=n(ZGe,"CODE",{});var $It=s(B2e);Rzo=r($It,"model.train()"),$It.forEach(t),ZGe.forEach(t),Pzo=i(Ca),T(I2.$$.fragment,Ca),Ca.forEach(t),Sl.forEach(t),woo=i(m),xd=n(m,"H2",{class:!0});var Gto=s(xd);N2=n(Gto,"A",{id:!0,class:!0,href:!0});var kIt=s(N2);I2e=n(kIt,"SPAN",{});var SIt=s(I2e);T(i$.$$.fragment,SIt),SIt.forEach(t),kIt.forEach(t),Bzo=i(Gto),N2e=n(Gto,"SPAN",{});var RIt=s(N2e);Izo=r(RIt,"AutoModelForCausalLM"),RIt.forEach(t),Gto.forEach(t),Aoo=i(m),No=n(m,"DIV",{class:!0});var Rl=s(No);T(d$.$$.fragment,Rl),Nzo=i(Rl),$d=n(Rl,"P",{});var Xie=s($d);qzo=r(Xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),UQ=n(Xie,"A",{href:!0});var PIt=s(UQ);jzo=r(PIt,"from_pretrained()"),PIt.forEach(t),Dzo=r(Xie," class method or the "),HQ=n(Xie,"A",{href:!0});var BIt=s(HQ);Gzo=r(BIt,"from_config()"),BIt.forEach(t),Ozo=r(Xie,` class
method.`),Xie.forEach(t),Vzo=i(Rl),c$=n(Rl,"P",{});var Oto=s(c$);Xzo=r(Oto,"This class cannot be instantiated directly using "),q2e=n(Oto,"CODE",{});var IIt=s(q2e);zzo=r(IIt,"__init__()"),IIt.forEach(t),Qzo=r(Oto," (throws an error)."),Oto.forEach(t),Wzo=i(Rl),Tt=n(Rl,"DIV",{class:!0});var M8=s(Tt);T(m$.$$.fragment,M8),Uzo=i(M8),j2e=n(M8,"P",{});var NIt=s(j2e);Hzo=r(NIt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),NIt.forEach(t),Jzo=i(M8),kd=n(M8,"P",{});var zie=s(kd);Yzo=r(zie,`Note:
Loading a model from its configuration file does `),D2e=n(zie,"STRONG",{});var qIt=s(D2e);Zzo=r(qIt,"not"),qIt.forEach(t),Kzo=r(zie,` load the model weights. It only affects the
model\u2019s configuration. Use `),JQ=n(zie,"A",{href:!0});var jIt=s(JQ);eQo=r(jIt,"from_pretrained()"),jIt.forEach(t),oQo=r(zie," to load the model weights."),zie.forEach(t),rQo=i(M8),T(q2.$$.fragment,M8),M8.forEach(t),tQo=i(Rl),oo=n(Rl,"DIV",{class:!0});var wa=s(oo);T(f$.$$.fragment,wa),aQo=i(wa),G2e=n(wa,"P",{});var DIt=s(G2e);nQo=r(DIt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),DIt.forEach(t),sQo=i(wa),rn=n(wa,"P",{});var E8=s(rn);lQo=r(E8,"The model class to instantiate is selected based on the "),O2e=n(E8,"CODE",{});var GIt=s(O2e);iQo=r(GIt,"model_type"),GIt.forEach(t),dQo=r(E8,` property of the config object (either
passed as an argument or loaded from `),V2e=n(E8,"CODE",{});var OIt=s(V2e);cQo=r(OIt,"pretrained_model_name_or_path"),OIt.forEach(t),mQo=r(E8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X2e=n(E8,"CODE",{});var VIt=s(X2e);fQo=r(VIt,"pretrained_model_name_or_path"),VIt.forEach(t),gQo=r(E8,":"),E8.forEach(t),hQo=i(wa),Q=n(wa,"UL",{});var U=s(Q);j2=n(U,"LI",{});var KGe=s(j2);z2e=n(KGe,"STRONG",{});var XIt=s(z2e);uQo=r(XIt,"bart"),XIt.forEach(t),pQo=r(KGe," \u2014 "),YQ=n(KGe,"A",{href:!0});var zIt=s(YQ);_Qo=r(zIt,"BartForCausalLM"),zIt.forEach(t),bQo=r(KGe," (BART model)"),KGe.forEach(t),vQo=i(U),D2=n(U,"LI",{});var eOe=s(D2);Q2e=n(eOe,"STRONG",{});var QIt=s(Q2e);FQo=r(QIt,"bert"),QIt.forEach(t),TQo=r(eOe," \u2014 "),ZQ=n(eOe,"A",{href:!0});var WIt=s(ZQ);MQo=r(WIt,"BertLMHeadModel"),WIt.forEach(t),EQo=r(eOe," (BERT model)"),eOe.forEach(t),CQo=i(U),G2=n(U,"LI",{});var oOe=s(G2);W2e=n(oOe,"STRONG",{});var UIt=s(W2e);wQo=r(UIt,"bert-generation"),UIt.forEach(t),AQo=r(oOe," \u2014 "),KQ=n(oOe,"A",{href:!0});var HIt=s(KQ);LQo=r(HIt,"BertGenerationDecoder"),HIt.forEach(t),yQo=r(oOe," (Bert Generation model)"),oOe.forEach(t),xQo=i(U),O2=n(U,"LI",{});var rOe=s(O2);U2e=n(rOe,"STRONG",{});var JIt=s(U2e);$Qo=r(JIt,"big_bird"),JIt.forEach(t),kQo=r(rOe," \u2014 "),eW=n(rOe,"A",{href:!0});var YIt=s(eW);SQo=r(YIt,"BigBirdForCausalLM"),YIt.forEach(t),RQo=r(rOe," (BigBird model)"),rOe.forEach(t),PQo=i(U),V2=n(U,"LI",{});var tOe=s(V2);H2e=n(tOe,"STRONG",{});var ZIt=s(H2e);BQo=r(ZIt,"bigbird_pegasus"),ZIt.forEach(t),IQo=r(tOe," \u2014 "),oW=n(tOe,"A",{href:!0});var KIt=s(oW);NQo=r(KIt,"BigBirdPegasusForCausalLM"),KIt.forEach(t),qQo=r(tOe," (BigBird-Pegasus model)"),tOe.forEach(t),jQo=i(U),X2=n(U,"LI",{});var aOe=s(X2);J2e=n(aOe,"STRONG",{});var eNt=s(J2e);DQo=r(eNt,"blenderbot"),eNt.forEach(t),GQo=r(aOe," \u2014 "),rW=n(aOe,"A",{href:!0});var oNt=s(rW);OQo=r(oNt,"BlenderbotForCausalLM"),oNt.forEach(t),VQo=r(aOe," (Blenderbot model)"),aOe.forEach(t),XQo=i(U),z2=n(U,"LI",{});var nOe=s(z2);Y2e=n(nOe,"STRONG",{});var rNt=s(Y2e);zQo=r(rNt,"blenderbot-small"),rNt.forEach(t),QQo=r(nOe," \u2014 "),tW=n(nOe,"A",{href:!0});var tNt=s(tW);WQo=r(tNt,"BlenderbotSmallForCausalLM"),tNt.forEach(t),UQo=r(nOe," (BlenderbotSmall model)"),nOe.forEach(t),HQo=i(U),Q2=n(U,"LI",{});var sOe=s(Q2);Z2e=n(sOe,"STRONG",{});var aNt=s(Z2e);JQo=r(aNt,"bloom"),aNt.forEach(t),YQo=r(sOe," \u2014 "),aW=n(sOe,"A",{href:!0});var nNt=s(aW);ZQo=r(nNt,"BloomForCausalLM"),nNt.forEach(t),KQo=r(sOe," (BLOOM model)"),sOe.forEach(t),eWo=i(U),W2=n(U,"LI",{});var lOe=s(W2);K2e=n(lOe,"STRONG",{});var sNt=s(K2e);oWo=r(sNt,"camembert"),sNt.forEach(t),rWo=r(lOe," \u2014 "),nW=n(lOe,"A",{href:!0});var lNt=s(nW);tWo=r(lNt,"CamembertForCausalLM"),lNt.forEach(t),aWo=r(lOe," (CamemBERT model)"),lOe.forEach(t),nWo=i(U),U2=n(U,"LI",{});var iOe=s(U2);eve=n(iOe,"STRONG",{});var iNt=s(eve);sWo=r(iNt,"codegen"),iNt.forEach(t),lWo=r(iOe," \u2014 "),sW=n(iOe,"A",{href:!0});var dNt=s(sW);iWo=r(dNt,"CodeGenForCausalLM"),dNt.forEach(t),dWo=r(iOe," (CodeGen model)"),iOe.forEach(t),cWo=i(U),H2=n(U,"LI",{});var dOe=s(H2);ove=n(dOe,"STRONG",{});var cNt=s(ove);mWo=r(cNt,"ctrl"),cNt.forEach(t),fWo=r(dOe," \u2014 "),lW=n(dOe,"A",{href:!0});var mNt=s(lW);gWo=r(mNt,"CTRLLMHeadModel"),mNt.forEach(t),hWo=r(dOe," (CTRL model)"),dOe.forEach(t),uWo=i(U),J2=n(U,"LI",{});var cOe=s(J2);rve=n(cOe,"STRONG",{});var fNt=s(rve);pWo=r(fNt,"data2vec-text"),fNt.forEach(t),_Wo=r(cOe," \u2014 "),iW=n(cOe,"A",{href:!0});var gNt=s(iW);bWo=r(gNt,"Data2VecTextForCausalLM"),gNt.forEach(t),vWo=r(cOe," (Data2VecText model)"),cOe.forEach(t),FWo=i(U),Y2=n(U,"LI",{});var mOe=s(Y2);tve=n(mOe,"STRONG",{});var hNt=s(tve);TWo=r(hNt,"electra"),hNt.forEach(t),MWo=r(mOe," \u2014 "),dW=n(mOe,"A",{href:!0});var uNt=s(dW);EWo=r(uNt,"ElectraForCausalLM"),uNt.forEach(t),CWo=r(mOe," (ELECTRA model)"),mOe.forEach(t),wWo=i(U),Z2=n(U,"LI",{});var fOe=s(Z2);ave=n(fOe,"STRONG",{});var pNt=s(ave);AWo=r(pNt,"ernie"),pNt.forEach(t),LWo=r(fOe," \u2014 "),cW=n(fOe,"A",{href:!0});var _Nt=s(cW);yWo=r(_Nt,"ErnieForCausalLM"),_Nt.forEach(t),xWo=r(fOe," (ERNIE model)"),fOe.forEach(t),$Wo=i(U),K2=n(U,"LI",{});var gOe=s(K2);nve=n(gOe,"STRONG",{});var bNt=s(nve);kWo=r(bNt,"gpt2"),bNt.forEach(t),SWo=r(gOe," \u2014 "),mW=n(gOe,"A",{href:!0});var vNt=s(mW);RWo=r(vNt,"GPT2LMHeadModel"),vNt.forEach(t),PWo=r(gOe," (OpenAI GPT-2 model)"),gOe.forEach(t),BWo=i(U),ev=n(U,"LI",{});var hOe=s(ev);sve=n(hOe,"STRONG",{});var FNt=s(sve);IWo=r(FNt,"gpt_neo"),FNt.forEach(t),NWo=r(hOe," \u2014 "),fW=n(hOe,"A",{href:!0});var TNt=s(fW);qWo=r(TNt,"GPTNeoForCausalLM"),TNt.forEach(t),jWo=r(hOe," (GPT Neo model)"),hOe.forEach(t),DWo=i(U),ov=n(U,"LI",{});var uOe=s(ov);lve=n(uOe,"STRONG",{});var MNt=s(lve);GWo=r(MNt,"gpt_neox"),MNt.forEach(t),OWo=r(uOe," \u2014 "),gW=n(uOe,"A",{href:!0});var ENt=s(gW);VWo=r(ENt,"GPTNeoXForCausalLM"),ENt.forEach(t),XWo=r(uOe," (GPT NeoX model)"),uOe.forEach(t),zWo=i(U),rv=n(U,"LI",{});var pOe=s(rv);ive=n(pOe,"STRONG",{});var CNt=s(ive);QWo=r(CNt,"gpt_neox_japanese"),CNt.forEach(t),WWo=r(pOe," \u2014 "),hW=n(pOe,"A",{href:!0});var wNt=s(hW);UWo=r(wNt,"GPTNeoXJapaneseForCausalLM"),wNt.forEach(t),HWo=r(pOe," (GPT NeoX Japanese model)"),pOe.forEach(t),JWo=i(U),tv=n(U,"LI",{});var _Oe=s(tv);dve=n(_Oe,"STRONG",{});var ANt=s(dve);YWo=r(ANt,"gptj"),ANt.forEach(t),ZWo=r(_Oe," \u2014 "),uW=n(_Oe,"A",{href:!0});var LNt=s(uW);KWo=r(LNt,"GPTJForCausalLM"),LNt.forEach(t),eUo=r(_Oe," (GPT-J model)"),_Oe.forEach(t),oUo=i(U),av=n(U,"LI",{});var bOe=s(av);cve=n(bOe,"STRONG",{});var yNt=s(cve);rUo=r(yNt,"marian"),yNt.forEach(t),tUo=r(bOe," \u2014 "),pW=n(bOe,"A",{href:!0});var xNt=s(pW);aUo=r(xNt,"MarianForCausalLM"),xNt.forEach(t),nUo=r(bOe," (Marian model)"),bOe.forEach(t),sUo=i(U),nv=n(U,"LI",{});var vOe=s(nv);mve=n(vOe,"STRONG",{});var $Nt=s(mve);lUo=r($Nt,"mbart"),$Nt.forEach(t),iUo=r(vOe," \u2014 "),_W=n(vOe,"A",{href:!0});var kNt=s(_W);dUo=r(kNt,"MBartForCausalLM"),kNt.forEach(t),cUo=r(vOe," (mBART model)"),vOe.forEach(t),mUo=i(U),sv=n(U,"LI",{});var FOe=s(sv);fve=n(FOe,"STRONG",{});var SNt=s(fve);fUo=r(SNt,"megatron-bert"),SNt.forEach(t),gUo=r(FOe," \u2014 "),bW=n(FOe,"A",{href:!0});var RNt=s(bW);hUo=r(RNt,"MegatronBertForCausalLM"),RNt.forEach(t),uUo=r(FOe," (Megatron-BERT model)"),FOe.forEach(t),pUo=i(U),lv=n(U,"LI",{});var TOe=s(lv);gve=n(TOe,"STRONG",{});var PNt=s(gve);_Uo=r(PNt,"mvp"),PNt.forEach(t),bUo=r(TOe," \u2014 "),vW=n(TOe,"A",{href:!0});var BNt=s(vW);vUo=r(BNt,"MvpForCausalLM"),BNt.forEach(t),FUo=r(TOe," (MVP model)"),TOe.forEach(t),TUo=i(U),iv=n(U,"LI",{});var MOe=s(iv);hve=n(MOe,"STRONG",{});var INt=s(hve);MUo=r(INt,"openai-gpt"),INt.forEach(t),EUo=r(MOe," \u2014 "),FW=n(MOe,"A",{href:!0});var NNt=s(FW);CUo=r(NNt,"OpenAIGPTLMHeadModel"),NNt.forEach(t),wUo=r(MOe," (OpenAI GPT model)"),MOe.forEach(t),AUo=i(U),dv=n(U,"LI",{});var EOe=s(dv);uve=n(EOe,"STRONG",{});var qNt=s(uve);LUo=r(qNt,"opt"),qNt.forEach(t),yUo=r(EOe," \u2014 "),TW=n(EOe,"A",{href:!0});var jNt=s(TW);xUo=r(jNt,"OPTForCausalLM"),jNt.forEach(t),$Uo=r(EOe," (OPT model)"),EOe.forEach(t),kUo=i(U),cv=n(U,"LI",{});var COe=s(cv);pve=n(COe,"STRONG",{});var DNt=s(pve);SUo=r(DNt,"pegasus"),DNt.forEach(t),RUo=r(COe," \u2014 "),MW=n(COe,"A",{href:!0});var GNt=s(MW);PUo=r(GNt,"PegasusForCausalLM"),GNt.forEach(t),BUo=r(COe," (Pegasus model)"),COe.forEach(t),IUo=i(U),mv=n(U,"LI",{});var wOe=s(mv);_ve=n(wOe,"STRONG",{});var ONt=s(_ve);NUo=r(ONt,"plbart"),ONt.forEach(t),qUo=r(wOe," \u2014 "),EW=n(wOe,"A",{href:!0});var VNt=s(EW);jUo=r(VNt,"PLBartForCausalLM"),VNt.forEach(t),DUo=r(wOe," (PLBart model)"),wOe.forEach(t),GUo=i(U),fv=n(U,"LI",{});var AOe=s(fv);bve=n(AOe,"STRONG",{});var XNt=s(bve);OUo=r(XNt,"prophetnet"),XNt.forEach(t),VUo=r(AOe," \u2014 "),CW=n(AOe,"A",{href:!0});var zNt=s(CW);XUo=r(zNt,"ProphetNetForCausalLM"),zNt.forEach(t),zUo=r(AOe," (ProphetNet model)"),AOe.forEach(t),QUo=i(U),gv=n(U,"LI",{});var LOe=s(gv);vve=n(LOe,"STRONG",{});var QNt=s(vve);WUo=r(QNt,"qdqbert"),QNt.forEach(t),UUo=r(LOe," \u2014 "),wW=n(LOe,"A",{href:!0});var WNt=s(wW);HUo=r(WNt,"QDQBertLMHeadModel"),WNt.forEach(t),JUo=r(LOe," (QDQBert model)"),LOe.forEach(t),YUo=i(U),hv=n(U,"LI",{});var yOe=s(hv);Fve=n(yOe,"STRONG",{});var UNt=s(Fve);ZUo=r(UNt,"reformer"),UNt.forEach(t),KUo=r(yOe," \u2014 "),AW=n(yOe,"A",{href:!0});var HNt=s(AW);eHo=r(HNt,"ReformerModelWithLMHead"),HNt.forEach(t),oHo=r(yOe," (Reformer model)"),yOe.forEach(t),rHo=i(U),uv=n(U,"LI",{});var xOe=s(uv);Tve=n(xOe,"STRONG",{});var JNt=s(Tve);tHo=r(JNt,"rembert"),JNt.forEach(t),aHo=r(xOe," \u2014 "),LW=n(xOe,"A",{href:!0});var YNt=s(LW);nHo=r(YNt,"RemBertForCausalLM"),YNt.forEach(t),sHo=r(xOe," (RemBERT model)"),xOe.forEach(t),lHo=i(U),pv=n(U,"LI",{});var $Oe=s(pv);Mve=n($Oe,"STRONG",{});var ZNt=s(Mve);iHo=r(ZNt,"roberta"),ZNt.forEach(t),dHo=r($Oe," \u2014 "),yW=n($Oe,"A",{href:!0});var KNt=s(yW);cHo=r(KNt,"RobertaForCausalLM"),KNt.forEach(t),mHo=r($Oe," (RoBERTa model)"),$Oe.forEach(t),fHo=i(U),_v=n(U,"LI",{});var kOe=s(_v);Eve=n(kOe,"STRONG",{});var eqt=s(Eve);gHo=r(eqt,"roformer"),eqt.forEach(t),hHo=r(kOe," \u2014 "),xW=n(kOe,"A",{href:!0});var oqt=s(xW);uHo=r(oqt,"RoFormerForCausalLM"),oqt.forEach(t),pHo=r(kOe," (RoFormer model)"),kOe.forEach(t),_Ho=i(U),bv=n(U,"LI",{});var SOe=s(bv);Cve=n(SOe,"STRONG",{});var rqt=s(Cve);bHo=r(rqt,"speech_to_text_2"),rqt.forEach(t),vHo=r(SOe," \u2014 "),$W=n(SOe,"A",{href:!0});var tqt=s($W);FHo=r(tqt,"Speech2Text2ForCausalLM"),tqt.forEach(t),THo=r(SOe," (Speech2Text2 model)"),SOe.forEach(t),MHo=i(U),vv=n(U,"LI",{});var ROe=s(vv);wve=n(ROe,"STRONG",{});var aqt=s(wve);EHo=r(aqt,"transfo-xl"),aqt.forEach(t),CHo=r(ROe," \u2014 "),kW=n(ROe,"A",{href:!0});var nqt=s(kW);wHo=r(nqt,"TransfoXLLMHeadModel"),nqt.forEach(t),AHo=r(ROe," (Transformer-XL model)"),ROe.forEach(t),LHo=i(U),Fv=n(U,"LI",{});var POe=s(Fv);Ave=n(POe,"STRONG",{});var sqt=s(Ave);yHo=r(sqt,"trocr"),sqt.forEach(t),xHo=r(POe," \u2014 "),SW=n(POe,"A",{href:!0});var lqt=s(SW);$Ho=r(lqt,"TrOCRForCausalLM"),lqt.forEach(t),kHo=r(POe," (TrOCR model)"),POe.forEach(t),SHo=i(U),Tv=n(U,"LI",{});var BOe=s(Tv);Lve=n(BOe,"STRONG",{});var iqt=s(Lve);RHo=r(iqt,"xglm"),iqt.forEach(t),PHo=r(BOe," \u2014 "),RW=n(BOe,"A",{href:!0});var dqt=s(RW);BHo=r(dqt,"XGLMForCausalLM"),dqt.forEach(t),IHo=r(BOe," (XGLM model)"),BOe.forEach(t),NHo=i(U),Mv=n(U,"LI",{});var IOe=s(Mv);yve=n(IOe,"STRONG",{});var cqt=s(yve);qHo=r(cqt,"xlm"),cqt.forEach(t),jHo=r(IOe," \u2014 "),PW=n(IOe,"A",{href:!0});var mqt=s(PW);DHo=r(mqt,"XLMWithLMHeadModel"),mqt.forEach(t),GHo=r(IOe," (XLM model)"),IOe.forEach(t),OHo=i(U),Ev=n(U,"LI",{});var NOe=s(Ev);xve=n(NOe,"STRONG",{});var fqt=s(xve);VHo=r(fqt,"xlm-prophetnet"),fqt.forEach(t),XHo=r(NOe," \u2014 "),BW=n(NOe,"A",{href:!0});var gqt=s(BW);zHo=r(gqt,"XLMProphetNetForCausalLM"),gqt.forEach(t),QHo=r(NOe," (XLM-ProphetNet model)"),NOe.forEach(t),WHo=i(U),Cv=n(U,"LI",{});var qOe=s(Cv);$ve=n(qOe,"STRONG",{});var hqt=s($ve);UHo=r(hqt,"xlm-roberta"),hqt.forEach(t),HHo=r(qOe," \u2014 "),IW=n(qOe,"A",{href:!0});var uqt=s(IW);JHo=r(uqt,"XLMRobertaForCausalLM"),uqt.forEach(t),YHo=r(qOe," (XLM-RoBERTa model)"),qOe.forEach(t),ZHo=i(U),wv=n(U,"LI",{});var jOe=s(wv);kve=n(jOe,"STRONG",{});var pqt=s(kve);KHo=r(pqt,"xlm-roberta-xl"),pqt.forEach(t),eJo=r(jOe," \u2014 "),NW=n(jOe,"A",{href:!0});var _qt=s(NW);oJo=r(_qt,"XLMRobertaXLForCausalLM"),_qt.forEach(t),rJo=r(jOe," (XLM-RoBERTa-XL model)"),jOe.forEach(t),tJo=i(U),Av=n(U,"LI",{});var DOe=s(Av);Sve=n(DOe,"STRONG",{});var bqt=s(Sve);aJo=r(bqt,"xlnet"),bqt.forEach(t),nJo=r(DOe," \u2014 "),qW=n(DOe,"A",{href:!0});var vqt=s(qW);sJo=r(vqt,"XLNetLMHeadModel"),vqt.forEach(t),lJo=r(DOe," (XLNet model)"),DOe.forEach(t),U.forEach(t),iJo=i(wa),Lv=n(wa,"P",{});var GOe=s(Lv);dJo=r(GOe,"The model is set in evaluation mode by default using "),Rve=n(GOe,"CODE",{});var Fqt=s(Rve);cJo=r(Fqt,"model.eval()"),Fqt.forEach(t),mJo=r(GOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pve=n(GOe,"CODE",{});var Tqt=s(Pve);fJo=r(Tqt,"model.train()"),Tqt.forEach(t),GOe.forEach(t),gJo=i(wa),T(yv.$$.fragment,wa),wa.forEach(t),Rl.forEach(t),Loo=i(m),Sd=n(m,"H2",{class:!0});var Vto=s(Sd);xv=n(Vto,"A",{id:!0,class:!0,href:!0});var Mqt=s(xv);Bve=n(Mqt,"SPAN",{});var Eqt=s(Bve);T(g$.$$.fragment,Eqt),Eqt.forEach(t),Mqt.forEach(t),hJo=i(Vto),Ive=n(Vto,"SPAN",{});var Cqt=s(Ive);uJo=r(Cqt,"AutoModelForMaskedLM"),Cqt.forEach(t),Vto.forEach(t),yoo=i(m),qo=n(m,"DIV",{class:!0});var Pl=s(qo);T(h$.$$.fragment,Pl),pJo=i(Pl),Rd=n(Pl,"P",{});var Qie=s(Rd);_Jo=r(Qie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jW=n(Qie,"A",{href:!0});var wqt=s(jW);bJo=r(wqt,"from_pretrained()"),wqt.forEach(t),vJo=r(Qie," class method or the "),DW=n(Qie,"A",{href:!0});var Aqt=s(DW);FJo=r(Aqt,"from_config()"),Aqt.forEach(t),TJo=r(Qie,` class
method.`),Qie.forEach(t),MJo=i(Pl),u$=n(Pl,"P",{});var Xto=s(u$);EJo=r(Xto,"This class cannot be instantiated directly using "),Nve=n(Xto,"CODE",{});var Lqt=s(Nve);CJo=r(Lqt,"__init__()"),Lqt.forEach(t),wJo=r(Xto," (throws an error)."),Xto.forEach(t),AJo=i(Pl),Mt=n(Pl,"DIV",{class:!0});var C8=s(Mt);T(p$.$$.fragment,C8),LJo=i(C8),qve=n(C8,"P",{});var yqt=s(qve);yJo=r(yqt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),yqt.forEach(t),xJo=i(C8),Pd=n(C8,"P",{});var Wie=s(Pd);$Jo=r(Wie,`Note:
Loading a model from its configuration file does `),jve=n(Wie,"STRONG",{});var xqt=s(jve);kJo=r(xqt,"not"),xqt.forEach(t),SJo=r(Wie,` load the model weights. It only affects the
model\u2019s configuration. Use `),GW=n(Wie,"A",{href:!0});var $qt=s(GW);RJo=r($qt,"from_pretrained()"),$qt.forEach(t),PJo=r(Wie," to load the model weights."),Wie.forEach(t),BJo=i(C8),T($v.$$.fragment,C8),C8.forEach(t),IJo=i(Pl),ro=n(Pl,"DIV",{class:!0});var Aa=s(ro);T(_$.$$.fragment,Aa),NJo=i(Aa),Dve=n(Aa,"P",{});var kqt=s(Dve);qJo=r(kqt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),kqt.forEach(t),jJo=i(Aa),tn=n(Aa,"P",{});var w8=s(tn);DJo=r(w8,"The model class to instantiate is selected based on the "),Gve=n(w8,"CODE",{});var Sqt=s(Gve);GJo=r(Sqt,"model_type"),Sqt.forEach(t),OJo=r(w8,` property of the config object (either
passed as an argument or loaded from `),Ove=n(w8,"CODE",{});var Rqt=s(Ove);VJo=r(Rqt,"pretrained_model_name_or_path"),Rqt.forEach(t),XJo=r(w8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=n(w8,"CODE",{});var Pqt=s(Vve);zJo=r(Pqt,"pretrained_model_name_or_path"),Pqt.forEach(t),QJo=r(w8,":"),w8.forEach(t),WJo=i(Aa),J=n(Aa,"UL",{});var Z=s(J);kv=n(Z,"LI",{});var OOe=s(kv);Xve=n(OOe,"STRONG",{});var Bqt=s(Xve);UJo=r(Bqt,"albert"),Bqt.forEach(t),HJo=r(OOe," \u2014 "),OW=n(OOe,"A",{href:!0});var Iqt=s(OW);JJo=r(Iqt,"AlbertForMaskedLM"),Iqt.forEach(t),YJo=r(OOe," (ALBERT model)"),OOe.forEach(t),ZJo=i(Z),Sv=n(Z,"LI",{});var VOe=s(Sv);zve=n(VOe,"STRONG",{});var Nqt=s(zve);KJo=r(Nqt,"bart"),Nqt.forEach(t),eYo=r(VOe," \u2014 "),VW=n(VOe,"A",{href:!0});var qqt=s(VW);oYo=r(qqt,"BartForConditionalGeneration"),qqt.forEach(t),rYo=r(VOe," (BART model)"),VOe.forEach(t),tYo=i(Z),Rv=n(Z,"LI",{});var XOe=s(Rv);Qve=n(XOe,"STRONG",{});var jqt=s(Qve);aYo=r(jqt,"bert"),jqt.forEach(t),nYo=r(XOe," \u2014 "),XW=n(XOe,"A",{href:!0});var Dqt=s(XW);sYo=r(Dqt,"BertForMaskedLM"),Dqt.forEach(t),lYo=r(XOe," (BERT model)"),XOe.forEach(t),iYo=i(Z),Pv=n(Z,"LI",{});var zOe=s(Pv);Wve=n(zOe,"STRONG",{});var Gqt=s(Wve);dYo=r(Gqt,"big_bird"),Gqt.forEach(t),cYo=r(zOe," \u2014 "),zW=n(zOe,"A",{href:!0});var Oqt=s(zW);mYo=r(Oqt,"BigBirdForMaskedLM"),Oqt.forEach(t),fYo=r(zOe," (BigBird model)"),zOe.forEach(t),gYo=i(Z),Bv=n(Z,"LI",{});var QOe=s(Bv);Uve=n(QOe,"STRONG",{});var Vqt=s(Uve);hYo=r(Vqt,"camembert"),Vqt.forEach(t),uYo=r(QOe," \u2014 "),QW=n(QOe,"A",{href:!0});var Xqt=s(QW);pYo=r(Xqt,"CamembertForMaskedLM"),Xqt.forEach(t),_Yo=r(QOe," (CamemBERT model)"),QOe.forEach(t),bYo=i(Z),Iv=n(Z,"LI",{});var WOe=s(Iv);Hve=n(WOe,"STRONG",{});var zqt=s(Hve);vYo=r(zqt,"convbert"),zqt.forEach(t),FYo=r(WOe," \u2014 "),WW=n(WOe,"A",{href:!0});var Qqt=s(WW);TYo=r(Qqt,"ConvBertForMaskedLM"),Qqt.forEach(t),MYo=r(WOe," (ConvBERT model)"),WOe.forEach(t),EYo=i(Z),Nv=n(Z,"LI",{});var UOe=s(Nv);Jve=n(UOe,"STRONG",{});var Wqt=s(Jve);CYo=r(Wqt,"data2vec-text"),Wqt.forEach(t),wYo=r(UOe," \u2014 "),UW=n(UOe,"A",{href:!0});var Uqt=s(UW);AYo=r(Uqt,"Data2VecTextForMaskedLM"),Uqt.forEach(t),LYo=r(UOe," (Data2VecText model)"),UOe.forEach(t),yYo=i(Z),qv=n(Z,"LI",{});var HOe=s(qv);Yve=n(HOe,"STRONG",{});var Hqt=s(Yve);xYo=r(Hqt,"deberta"),Hqt.forEach(t),$Yo=r(HOe," \u2014 "),HW=n(HOe,"A",{href:!0});var Jqt=s(HW);kYo=r(Jqt,"DebertaForMaskedLM"),Jqt.forEach(t),SYo=r(HOe," (DeBERTa model)"),HOe.forEach(t),RYo=i(Z),jv=n(Z,"LI",{});var JOe=s(jv);Zve=n(JOe,"STRONG",{});var Yqt=s(Zve);PYo=r(Yqt,"deberta-v2"),Yqt.forEach(t),BYo=r(JOe," \u2014 "),JW=n(JOe,"A",{href:!0});var Zqt=s(JW);IYo=r(Zqt,"DebertaV2ForMaskedLM"),Zqt.forEach(t),NYo=r(JOe," (DeBERTa-v2 model)"),JOe.forEach(t),qYo=i(Z),Dv=n(Z,"LI",{});var YOe=s(Dv);Kve=n(YOe,"STRONG",{});var Kqt=s(Kve);jYo=r(Kqt,"distilbert"),Kqt.forEach(t),DYo=r(YOe," \u2014 "),YW=n(YOe,"A",{href:!0});var ejt=s(YW);GYo=r(ejt,"DistilBertForMaskedLM"),ejt.forEach(t),OYo=r(YOe," (DistilBERT model)"),YOe.forEach(t),VYo=i(Z),Gv=n(Z,"LI",{});var ZOe=s(Gv);eFe=n(ZOe,"STRONG",{});var ojt=s(eFe);XYo=r(ojt,"electra"),ojt.forEach(t),zYo=r(ZOe," \u2014 "),ZW=n(ZOe,"A",{href:!0});var rjt=s(ZW);QYo=r(rjt,"ElectraForMaskedLM"),rjt.forEach(t),WYo=r(ZOe," (ELECTRA model)"),ZOe.forEach(t),UYo=i(Z),Ov=n(Z,"LI",{});var KOe=s(Ov);oFe=n(KOe,"STRONG",{});var tjt=s(oFe);HYo=r(tjt,"ernie"),tjt.forEach(t),JYo=r(KOe," \u2014 "),KW=n(KOe,"A",{href:!0});var ajt=s(KW);YYo=r(ajt,"ErnieForMaskedLM"),ajt.forEach(t),ZYo=r(KOe," (ERNIE model)"),KOe.forEach(t),KYo=i(Z),Vv=n(Z,"LI",{});var eVe=s(Vv);rFe=n(eVe,"STRONG",{});var njt=s(rFe);eZo=r(njt,"flaubert"),njt.forEach(t),oZo=r(eVe," \u2014 "),eU=n(eVe,"A",{href:!0});var sjt=s(eU);rZo=r(sjt,"FlaubertWithLMHeadModel"),sjt.forEach(t),tZo=r(eVe," (FlauBERT model)"),eVe.forEach(t),aZo=i(Z),Xv=n(Z,"LI",{});var oVe=s(Xv);tFe=n(oVe,"STRONG",{});var ljt=s(tFe);nZo=r(ljt,"fnet"),ljt.forEach(t),sZo=r(oVe," \u2014 "),oU=n(oVe,"A",{href:!0});var ijt=s(oU);lZo=r(ijt,"FNetForMaskedLM"),ijt.forEach(t),iZo=r(oVe," (FNet model)"),oVe.forEach(t),dZo=i(Z),zv=n(Z,"LI",{});var rVe=s(zv);aFe=n(rVe,"STRONG",{});var djt=s(aFe);cZo=r(djt,"funnel"),djt.forEach(t),mZo=r(rVe," \u2014 "),rU=n(rVe,"A",{href:!0});var cjt=s(rU);fZo=r(cjt,"FunnelForMaskedLM"),cjt.forEach(t),gZo=r(rVe," (Funnel Transformer model)"),rVe.forEach(t),hZo=i(Z),Qv=n(Z,"LI",{});var tVe=s(Qv);nFe=n(tVe,"STRONG",{});var mjt=s(nFe);uZo=r(mjt,"ibert"),mjt.forEach(t),pZo=r(tVe," \u2014 "),tU=n(tVe,"A",{href:!0});var fjt=s(tU);_Zo=r(fjt,"IBertForMaskedLM"),fjt.forEach(t),bZo=r(tVe," (I-BERT model)"),tVe.forEach(t),vZo=i(Z),Wv=n(Z,"LI",{});var aVe=s(Wv);sFe=n(aVe,"STRONG",{});var gjt=s(sFe);FZo=r(gjt,"layoutlm"),gjt.forEach(t),TZo=r(aVe," \u2014 "),aU=n(aVe,"A",{href:!0});var hjt=s(aU);MZo=r(hjt,"LayoutLMForMaskedLM"),hjt.forEach(t),EZo=r(aVe," (LayoutLM model)"),aVe.forEach(t),CZo=i(Z),Uv=n(Z,"LI",{});var nVe=s(Uv);lFe=n(nVe,"STRONG",{});var ujt=s(lFe);wZo=r(ujt,"longformer"),ujt.forEach(t),AZo=r(nVe," \u2014 "),nU=n(nVe,"A",{href:!0});var pjt=s(nU);LZo=r(pjt,"LongformerForMaskedLM"),pjt.forEach(t),yZo=r(nVe," (Longformer model)"),nVe.forEach(t),xZo=i(Z),Hv=n(Z,"LI",{});var sVe=s(Hv);iFe=n(sVe,"STRONG",{});var _jt=s(iFe);$Zo=r(_jt,"luke"),_jt.forEach(t),kZo=r(sVe," \u2014 "),sU=n(sVe,"A",{href:!0});var bjt=s(sU);SZo=r(bjt,"LukeForMaskedLM"),bjt.forEach(t),RZo=r(sVe," (LUKE model)"),sVe.forEach(t),PZo=i(Z),Jv=n(Z,"LI",{});var lVe=s(Jv);dFe=n(lVe,"STRONG",{});var vjt=s(dFe);BZo=r(vjt,"mbart"),vjt.forEach(t),IZo=r(lVe," \u2014 "),lU=n(lVe,"A",{href:!0});var Fjt=s(lU);NZo=r(Fjt,"MBartForConditionalGeneration"),Fjt.forEach(t),qZo=r(lVe," (mBART model)"),lVe.forEach(t),jZo=i(Z),Yv=n(Z,"LI",{});var iVe=s(Yv);cFe=n(iVe,"STRONG",{});var Tjt=s(cFe);DZo=r(Tjt,"megatron-bert"),Tjt.forEach(t),GZo=r(iVe," \u2014 "),iU=n(iVe,"A",{href:!0});var Mjt=s(iU);OZo=r(Mjt,"MegatronBertForMaskedLM"),Mjt.forEach(t),VZo=r(iVe," (Megatron-BERT model)"),iVe.forEach(t),XZo=i(Z),Zv=n(Z,"LI",{});var dVe=s(Zv);mFe=n(dVe,"STRONG",{});var Ejt=s(mFe);zZo=r(Ejt,"mobilebert"),Ejt.forEach(t),QZo=r(dVe," \u2014 "),dU=n(dVe,"A",{href:!0});var Cjt=s(dU);WZo=r(Cjt,"MobileBertForMaskedLM"),Cjt.forEach(t),UZo=r(dVe," (MobileBERT model)"),dVe.forEach(t),HZo=i(Z),Kv=n(Z,"LI",{});var cVe=s(Kv);fFe=n(cVe,"STRONG",{});var wjt=s(fFe);JZo=r(wjt,"mpnet"),wjt.forEach(t),YZo=r(cVe," \u2014 "),cU=n(cVe,"A",{href:!0});var Ajt=s(cU);ZZo=r(Ajt,"MPNetForMaskedLM"),Ajt.forEach(t),KZo=r(cVe," (MPNet model)"),cVe.forEach(t),eKo=i(Z),eF=n(Z,"LI",{});var mVe=s(eF);gFe=n(mVe,"STRONG",{});var Ljt=s(gFe);oKo=r(Ljt,"mvp"),Ljt.forEach(t),rKo=r(mVe," \u2014 "),mU=n(mVe,"A",{href:!0});var yjt=s(mU);tKo=r(yjt,"MvpForConditionalGeneration"),yjt.forEach(t),aKo=r(mVe," (MVP model)"),mVe.forEach(t),nKo=i(Z),oF=n(Z,"LI",{});var fVe=s(oF);hFe=n(fVe,"STRONG",{});var xjt=s(hFe);sKo=r(xjt,"nezha"),xjt.forEach(t),lKo=r(fVe," \u2014 "),fU=n(fVe,"A",{href:!0});var $jt=s(fU);iKo=r($jt,"NezhaForMaskedLM"),$jt.forEach(t),dKo=r(fVe," (Nezha model)"),fVe.forEach(t),cKo=i(Z),rF=n(Z,"LI",{});var gVe=s(rF);uFe=n(gVe,"STRONG",{});var kjt=s(uFe);mKo=r(kjt,"nystromformer"),kjt.forEach(t),fKo=r(gVe," \u2014 "),gU=n(gVe,"A",{href:!0});var Sjt=s(gU);gKo=r(Sjt,"NystromformerForMaskedLM"),Sjt.forEach(t),hKo=r(gVe," (Nystr\xF6mformer model)"),gVe.forEach(t),uKo=i(Z),tF=n(Z,"LI",{});var hVe=s(tF);pFe=n(hVe,"STRONG",{});var Rjt=s(pFe);pKo=r(Rjt,"perceiver"),Rjt.forEach(t),_Ko=r(hVe," \u2014 "),hU=n(hVe,"A",{href:!0});var Pjt=s(hU);bKo=r(Pjt,"PerceiverForMaskedLM"),Pjt.forEach(t),vKo=r(hVe," (Perceiver model)"),hVe.forEach(t),FKo=i(Z),aF=n(Z,"LI",{});var uVe=s(aF);_Fe=n(uVe,"STRONG",{});var Bjt=s(_Fe);TKo=r(Bjt,"qdqbert"),Bjt.forEach(t),MKo=r(uVe," \u2014 "),uU=n(uVe,"A",{href:!0});var Ijt=s(uU);EKo=r(Ijt,"QDQBertForMaskedLM"),Ijt.forEach(t),CKo=r(uVe," (QDQBert model)"),uVe.forEach(t),wKo=i(Z),nF=n(Z,"LI",{});var pVe=s(nF);bFe=n(pVe,"STRONG",{});var Njt=s(bFe);AKo=r(Njt,"reformer"),Njt.forEach(t),LKo=r(pVe," \u2014 "),pU=n(pVe,"A",{href:!0});var qjt=s(pU);yKo=r(qjt,"ReformerForMaskedLM"),qjt.forEach(t),xKo=r(pVe," (Reformer model)"),pVe.forEach(t),$Ko=i(Z),sF=n(Z,"LI",{});var _Ve=s(sF);vFe=n(_Ve,"STRONG",{});var jjt=s(vFe);kKo=r(jjt,"rembert"),jjt.forEach(t),SKo=r(_Ve," \u2014 "),_U=n(_Ve,"A",{href:!0});var Djt=s(_U);RKo=r(Djt,"RemBertForMaskedLM"),Djt.forEach(t),PKo=r(_Ve," (RemBERT model)"),_Ve.forEach(t),BKo=i(Z),lF=n(Z,"LI",{});var bVe=s(lF);FFe=n(bVe,"STRONG",{});var Gjt=s(FFe);IKo=r(Gjt,"roberta"),Gjt.forEach(t),NKo=r(bVe," \u2014 "),bU=n(bVe,"A",{href:!0});var Ojt=s(bU);qKo=r(Ojt,"RobertaForMaskedLM"),Ojt.forEach(t),jKo=r(bVe," (RoBERTa model)"),bVe.forEach(t),DKo=i(Z),iF=n(Z,"LI",{});var vVe=s(iF);TFe=n(vVe,"STRONG",{});var Vjt=s(TFe);GKo=r(Vjt,"roformer"),Vjt.forEach(t),OKo=r(vVe," \u2014 "),vU=n(vVe,"A",{href:!0});var Xjt=s(vU);VKo=r(Xjt,"RoFormerForMaskedLM"),Xjt.forEach(t),XKo=r(vVe," (RoFormer model)"),vVe.forEach(t),zKo=i(Z),dF=n(Z,"LI",{});var FVe=s(dF);MFe=n(FVe,"STRONG",{});var zjt=s(MFe);QKo=r(zjt,"squeezebert"),zjt.forEach(t),WKo=r(FVe," \u2014 "),FU=n(FVe,"A",{href:!0});var Qjt=s(FU);UKo=r(Qjt,"SqueezeBertForMaskedLM"),Qjt.forEach(t),HKo=r(FVe," (SqueezeBERT model)"),FVe.forEach(t),JKo=i(Z),cF=n(Z,"LI",{});var TVe=s(cF);EFe=n(TVe,"STRONG",{});var Wjt=s(EFe);YKo=r(Wjt,"tapas"),Wjt.forEach(t),ZKo=r(TVe," \u2014 "),TU=n(TVe,"A",{href:!0});var Ujt=s(TU);KKo=r(Ujt,"TapasForMaskedLM"),Ujt.forEach(t),eer=r(TVe," (TAPAS model)"),TVe.forEach(t),oer=i(Z),mF=n(Z,"LI",{});var MVe=s(mF);CFe=n(MVe,"STRONG",{});var Hjt=s(CFe);rer=r(Hjt,"wav2vec2"),Hjt.forEach(t),ter=r(MVe," \u2014 "),wFe=n(MVe,"CODE",{});var Jjt=s(wFe);aer=r(Jjt,"Wav2Vec2ForMaskedLM"),Jjt.forEach(t),ner=r(MVe," (Wav2Vec2 model)"),MVe.forEach(t),ser=i(Z),fF=n(Z,"LI",{});var EVe=s(fF);AFe=n(EVe,"STRONG",{});var Yjt=s(AFe);ler=r(Yjt,"xlm"),Yjt.forEach(t),ier=r(EVe," \u2014 "),MU=n(EVe,"A",{href:!0});var Zjt=s(MU);der=r(Zjt,"XLMWithLMHeadModel"),Zjt.forEach(t),cer=r(EVe," (XLM model)"),EVe.forEach(t),mer=i(Z),gF=n(Z,"LI",{});var CVe=s(gF);LFe=n(CVe,"STRONG",{});var Kjt=s(LFe);fer=r(Kjt,"xlm-roberta"),Kjt.forEach(t),ger=r(CVe," \u2014 "),EU=n(CVe,"A",{href:!0});var eDt=s(EU);her=r(eDt,"XLMRobertaForMaskedLM"),eDt.forEach(t),uer=r(CVe," (XLM-RoBERTa model)"),CVe.forEach(t),per=i(Z),hF=n(Z,"LI",{});var wVe=s(hF);yFe=n(wVe,"STRONG",{});var oDt=s(yFe);_er=r(oDt,"xlm-roberta-xl"),oDt.forEach(t),ber=r(wVe," \u2014 "),CU=n(wVe,"A",{href:!0});var rDt=s(CU);ver=r(rDt,"XLMRobertaXLForMaskedLM"),rDt.forEach(t),Fer=r(wVe," (XLM-RoBERTa-XL model)"),wVe.forEach(t),Ter=i(Z),uF=n(Z,"LI",{});var AVe=s(uF);xFe=n(AVe,"STRONG",{});var tDt=s(xFe);Mer=r(tDt,"yoso"),tDt.forEach(t),Eer=r(AVe," \u2014 "),wU=n(AVe,"A",{href:!0});var aDt=s(wU);Cer=r(aDt,"YosoForMaskedLM"),aDt.forEach(t),wer=r(AVe," (YOSO model)"),AVe.forEach(t),Z.forEach(t),Aer=i(Aa),pF=n(Aa,"P",{});var LVe=s(pF);Ler=r(LVe,"The model is set in evaluation mode by default using "),$Fe=n(LVe,"CODE",{});var nDt=s($Fe);yer=r(nDt,"model.eval()"),nDt.forEach(t),xer=r(LVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kFe=n(LVe,"CODE",{});var sDt=s(kFe);$er=r(sDt,"model.train()"),sDt.forEach(t),LVe.forEach(t),ker=i(Aa),T(_F.$$.fragment,Aa),Aa.forEach(t),Pl.forEach(t),xoo=i(m),Bd=n(m,"H2",{class:!0});var zto=s(Bd);bF=n(zto,"A",{id:!0,class:!0,href:!0});var lDt=s(bF);SFe=n(lDt,"SPAN",{});var iDt=s(SFe);T(b$.$$.fragment,iDt),iDt.forEach(t),lDt.forEach(t),Ser=i(zto),RFe=n(zto,"SPAN",{});var dDt=s(RFe);Rer=r(dDt,"AutoModelForSeq2SeqLM"),dDt.forEach(t),zto.forEach(t),$oo=i(m),jo=n(m,"DIV",{class:!0});var Bl=s(jo);T(v$.$$.fragment,Bl),Per=i(Bl),Id=n(Bl,"P",{});var Uie=s(Id);Ber=r(Uie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),AU=n(Uie,"A",{href:!0});var cDt=s(AU);Ier=r(cDt,"from_pretrained()"),cDt.forEach(t),Ner=r(Uie," class method or the "),LU=n(Uie,"A",{href:!0});var mDt=s(LU);qer=r(mDt,"from_config()"),mDt.forEach(t),jer=r(Uie,` class
method.`),Uie.forEach(t),Der=i(Bl),F$=n(Bl,"P",{});var Qto=s(F$);Ger=r(Qto,"This class cannot be instantiated directly using "),PFe=n(Qto,"CODE",{});var fDt=s(PFe);Oer=r(fDt,"__init__()"),fDt.forEach(t),Ver=r(Qto," (throws an error)."),Qto.forEach(t),Xer=i(Bl),Et=n(Bl,"DIV",{class:!0});var A8=s(Et);T(T$.$$.fragment,A8),zer=i(A8),BFe=n(A8,"P",{});var gDt=s(BFe);Qer=r(gDt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),gDt.forEach(t),Wer=i(A8),Nd=n(A8,"P",{});var Hie=s(Nd);Uer=r(Hie,`Note:
Loading a model from its configuration file does `),IFe=n(Hie,"STRONG",{});var hDt=s(IFe);Her=r(hDt,"not"),hDt.forEach(t),Jer=r(Hie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yU=n(Hie,"A",{href:!0});var uDt=s(yU);Yer=r(uDt,"from_pretrained()"),uDt.forEach(t),Zer=r(Hie," to load the model weights."),Hie.forEach(t),Ker=i(A8),T(vF.$$.fragment,A8),A8.forEach(t),eor=i(Bl),to=n(Bl,"DIV",{class:!0});var La=s(to);T(M$.$$.fragment,La),oor=i(La),NFe=n(La,"P",{});var pDt=s(NFe);ror=r(pDt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),pDt.forEach(t),tor=i(La),an=n(La,"P",{});var L8=s(an);aor=r(L8,"The model class to instantiate is selected based on the "),qFe=n(L8,"CODE",{});var _Dt=s(qFe);nor=r(_Dt,"model_type"),_Dt.forEach(t),sor=r(L8,` property of the config object (either
passed as an argument or loaded from `),jFe=n(L8,"CODE",{});var bDt=s(jFe);lor=r(bDt,"pretrained_model_name_or_path"),bDt.forEach(t),ior=r(L8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DFe=n(L8,"CODE",{});var vDt=s(DFe);dor=r(vDt,"pretrained_model_name_or_path"),vDt.forEach(t),cor=r(L8,":"),L8.forEach(t),mor=i(La),fe=n(La,"UL",{});var pe=s(fe);FF=n(pe,"LI",{});var yVe=s(FF);GFe=n(yVe,"STRONG",{});var FDt=s(GFe);gor=r(FDt,"bart"),FDt.forEach(t),hor=r(yVe," \u2014 "),xU=n(yVe,"A",{href:!0});var TDt=s(xU);uor=r(TDt,"BartForConditionalGeneration"),TDt.forEach(t),por=r(yVe," (BART model)"),yVe.forEach(t),_or=i(pe),TF=n(pe,"LI",{});var xVe=s(TF);OFe=n(xVe,"STRONG",{});var MDt=s(OFe);bor=r(MDt,"bigbird_pegasus"),MDt.forEach(t),vor=r(xVe," \u2014 "),$U=n(xVe,"A",{href:!0});var EDt=s($U);For=r(EDt,"BigBirdPegasusForConditionalGeneration"),EDt.forEach(t),Tor=r(xVe," (BigBird-Pegasus model)"),xVe.forEach(t),Mor=i(pe),MF=n(pe,"LI",{});var $Ve=s(MF);VFe=n($Ve,"STRONG",{});var CDt=s(VFe);Eor=r(CDt,"blenderbot"),CDt.forEach(t),Cor=r($Ve," \u2014 "),kU=n($Ve,"A",{href:!0});var wDt=s(kU);wor=r(wDt,"BlenderbotForConditionalGeneration"),wDt.forEach(t),Aor=r($Ve," (Blenderbot model)"),$Ve.forEach(t),Lor=i(pe),EF=n(pe,"LI",{});var kVe=s(EF);XFe=n(kVe,"STRONG",{});var ADt=s(XFe);yor=r(ADt,"blenderbot-small"),ADt.forEach(t),xor=r(kVe," \u2014 "),SU=n(kVe,"A",{href:!0});var LDt=s(SU);$or=r(LDt,"BlenderbotSmallForConditionalGeneration"),LDt.forEach(t),kor=r(kVe," (BlenderbotSmall model)"),kVe.forEach(t),Sor=i(pe),CF=n(pe,"LI",{});var SVe=s(CF);zFe=n(SVe,"STRONG",{});var yDt=s(zFe);Ror=r(yDt,"encoder-decoder"),yDt.forEach(t),Por=r(SVe," \u2014 "),RU=n(SVe,"A",{href:!0});var xDt=s(RU);Bor=r(xDt,"EncoderDecoderModel"),xDt.forEach(t),Ior=r(SVe," (Encoder decoder model)"),SVe.forEach(t),Nor=i(pe),wF=n(pe,"LI",{});var RVe=s(wF);QFe=n(RVe,"STRONG",{});var $Dt=s(QFe);qor=r($Dt,"fsmt"),$Dt.forEach(t),jor=r(RVe," \u2014 "),PU=n(RVe,"A",{href:!0});var kDt=s(PU);Dor=r(kDt,"FSMTForConditionalGeneration"),kDt.forEach(t),Gor=r(RVe," (FairSeq Machine-Translation model)"),RVe.forEach(t),Oor=i(pe),AF=n(pe,"LI",{});var PVe=s(AF);WFe=n(PVe,"STRONG",{});var SDt=s(WFe);Vor=r(SDt,"led"),SDt.forEach(t),Xor=r(PVe," \u2014 "),BU=n(PVe,"A",{href:!0});var RDt=s(BU);zor=r(RDt,"LEDForConditionalGeneration"),RDt.forEach(t),Qor=r(PVe," (LED model)"),PVe.forEach(t),Wor=i(pe),LF=n(pe,"LI",{});var BVe=s(LF);UFe=n(BVe,"STRONG",{});var PDt=s(UFe);Uor=r(PDt,"longt5"),PDt.forEach(t),Hor=r(BVe," \u2014 "),IU=n(BVe,"A",{href:!0});var BDt=s(IU);Jor=r(BDt,"LongT5ForConditionalGeneration"),BDt.forEach(t),Yor=r(BVe," (LongT5 model)"),BVe.forEach(t),Zor=i(pe),yF=n(pe,"LI",{});var IVe=s(yF);HFe=n(IVe,"STRONG",{});var IDt=s(HFe);Kor=r(IDt,"m2m_100"),IDt.forEach(t),err=r(IVe," \u2014 "),NU=n(IVe,"A",{href:!0});var NDt=s(NU);orr=r(NDt,"M2M100ForConditionalGeneration"),NDt.forEach(t),rrr=r(IVe," (M2M100 model)"),IVe.forEach(t),trr=i(pe),xF=n(pe,"LI",{});var NVe=s(xF);JFe=n(NVe,"STRONG",{});var qDt=s(JFe);arr=r(qDt,"marian"),qDt.forEach(t),nrr=r(NVe," \u2014 "),qU=n(NVe,"A",{href:!0});var jDt=s(qU);srr=r(jDt,"MarianMTModel"),jDt.forEach(t),lrr=r(NVe," (Marian model)"),NVe.forEach(t),irr=i(pe),$F=n(pe,"LI",{});var qVe=s($F);YFe=n(qVe,"STRONG",{});var DDt=s(YFe);drr=r(DDt,"mbart"),DDt.forEach(t),crr=r(qVe," \u2014 "),jU=n(qVe,"A",{href:!0});var GDt=s(jU);mrr=r(GDt,"MBartForConditionalGeneration"),GDt.forEach(t),frr=r(qVe," (mBART model)"),qVe.forEach(t),grr=i(pe),kF=n(pe,"LI",{});var jVe=s(kF);ZFe=n(jVe,"STRONG",{});var ODt=s(ZFe);hrr=r(ODt,"mt5"),ODt.forEach(t),urr=r(jVe," \u2014 "),DU=n(jVe,"A",{href:!0});var VDt=s(DU);prr=r(VDt,"MT5ForConditionalGeneration"),VDt.forEach(t),_rr=r(jVe," (MT5 model)"),jVe.forEach(t),brr=i(pe),SF=n(pe,"LI",{});var DVe=s(SF);KFe=n(DVe,"STRONG",{});var XDt=s(KFe);vrr=r(XDt,"mvp"),XDt.forEach(t),Frr=r(DVe," \u2014 "),GU=n(DVe,"A",{href:!0});var zDt=s(GU);Trr=r(zDt,"MvpForConditionalGeneration"),zDt.forEach(t),Mrr=r(DVe," (MVP model)"),DVe.forEach(t),Err=i(pe),RF=n(pe,"LI",{});var GVe=s(RF);eTe=n(GVe,"STRONG",{});var QDt=s(eTe);Crr=r(QDt,"nllb"),QDt.forEach(t),wrr=r(GVe," \u2014 "),OU=n(GVe,"A",{href:!0});var WDt=s(OU);Arr=r(WDt,"M2M100ForConditionalGeneration"),WDt.forEach(t),Lrr=r(GVe," (NLLB model)"),GVe.forEach(t),yrr=i(pe),PF=n(pe,"LI",{});var OVe=s(PF);oTe=n(OVe,"STRONG",{});var UDt=s(oTe);xrr=r(UDt,"pegasus"),UDt.forEach(t),$rr=r(OVe," \u2014 "),VU=n(OVe,"A",{href:!0});var HDt=s(VU);krr=r(HDt,"PegasusForConditionalGeneration"),HDt.forEach(t),Srr=r(OVe," (Pegasus model)"),OVe.forEach(t),Rrr=i(pe),BF=n(pe,"LI",{});var VVe=s(BF);rTe=n(VVe,"STRONG",{});var JDt=s(rTe);Prr=r(JDt,"pegasus_x"),JDt.forEach(t),Brr=r(VVe," \u2014 "),XU=n(VVe,"A",{href:!0});var YDt=s(XU);Irr=r(YDt,"PegasusXForConditionalGeneration"),YDt.forEach(t),Nrr=r(VVe," (PEGASUS-X model)"),VVe.forEach(t),qrr=i(pe),IF=n(pe,"LI",{});var XVe=s(IF);tTe=n(XVe,"STRONG",{});var ZDt=s(tTe);jrr=r(ZDt,"plbart"),ZDt.forEach(t),Drr=r(XVe," \u2014 "),zU=n(XVe,"A",{href:!0});var KDt=s(zU);Grr=r(KDt,"PLBartForConditionalGeneration"),KDt.forEach(t),Orr=r(XVe," (PLBart model)"),XVe.forEach(t),Vrr=i(pe),NF=n(pe,"LI",{});var zVe=s(NF);aTe=n(zVe,"STRONG",{});var eGt=s(aTe);Xrr=r(eGt,"prophetnet"),eGt.forEach(t),zrr=r(zVe," \u2014 "),QU=n(zVe,"A",{href:!0});var oGt=s(QU);Qrr=r(oGt,"ProphetNetForConditionalGeneration"),oGt.forEach(t),Wrr=r(zVe," (ProphetNet model)"),zVe.forEach(t),Urr=i(pe),qF=n(pe,"LI",{});var QVe=s(qF);nTe=n(QVe,"STRONG",{});var rGt=s(nTe);Hrr=r(rGt,"t5"),rGt.forEach(t),Jrr=r(QVe," \u2014 "),WU=n(QVe,"A",{href:!0});var tGt=s(WU);Yrr=r(tGt,"T5ForConditionalGeneration"),tGt.forEach(t),Zrr=r(QVe," (T5 model)"),QVe.forEach(t),Krr=i(pe),jF=n(pe,"LI",{});var WVe=s(jF);sTe=n(WVe,"STRONG",{});var aGt=s(sTe);etr=r(aGt,"xlm-prophetnet"),aGt.forEach(t),otr=r(WVe," \u2014 "),UU=n(WVe,"A",{href:!0});var nGt=s(UU);rtr=r(nGt,"XLMProphetNetForConditionalGeneration"),nGt.forEach(t),ttr=r(WVe," (XLM-ProphetNet model)"),WVe.forEach(t),pe.forEach(t),atr=i(La),DF=n(La,"P",{});var UVe=s(DF);ntr=r(UVe,"The model is set in evaluation mode by default using "),lTe=n(UVe,"CODE",{});var sGt=s(lTe);str=r(sGt,"model.eval()"),sGt.forEach(t),ltr=r(UVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iTe=n(UVe,"CODE",{});var lGt=s(iTe);itr=r(lGt,"model.train()"),lGt.forEach(t),UVe.forEach(t),dtr=i(La),T(GF.$$.fragment,La),La.forEach(t),Bl.forEach(t),koo=i(m),qd=n(m,"H2",{class:!0});var Wto=s(qd);OF=n(Wto,"A",{id:!0,class:!0,href:!0});var iGt=s(OF);dTe=n(iGt,"SPAN",{});var dGt=s(dTe);T(E$.$$.fragment,dGt),dGt.forEach(t),iGt.forEach(t),ctr=i(Wto),cTe=n(Wto,"SPAN",{});var cGt=s(cTe);mtr=r(cGt,"AutoModelForSequenceClassification"),cGt.forEach(t),Wto.forEach(t),Soo=i(m),Do=n(m,"DIV",{class:!0});var Il=s(Do);T(C$.$$.fragment,Il),ftr=i(Il),jd=n(Il,"P",{});var Jie=s(jd);gtr=r(Jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),HU=n(Jie,"A",{href:!0});var mGt=s(HU);htr=r(mGt,"from_pretrained()"),mGt.forEach(t),utr=r(Jie," class method or the "),JU=n(Jie,"A",{href:!0});var fGt=s(JU);ptr=r(fGt,"from_config()"),fGt.forEach(t),_tr=r(Jie,` class
method.`),Jie.forEach(t),btr=i(Il),w$=n(Il,"P",{});var Uto=s(w$);vtr=r(Uto,"This class cannot be instantiated directly using "),mTe=n(Uto,"CODE",{});var gGt=s(mTe);Ftr=r(gGt,"__init__()"),gGt.forEach(t),Ttr=r(Uto," (throws an error)."),Uto.forEach(t),Mtr=i(Il),Ct=n(Il,"DIV",{class:!0});var y8=s(Ct);T(A$.$$.fragment,y8),Etr=i(y8),fTe=n(y8,"P",{});var hGt=s(fTe);Ctr=r(hGt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hGt.forEach(t),wtr=i(y8),Dd=n(y8,"P",{});var Yie=s(Dd);Atr=r(Yie,`Note:
Loading a model from its configuration file does `),gTe=n(Yie,"STRONG",{});var uGt=s(gTe);Ltr=r(uGt,"not"),uGt.forEach(t),ytr=r(Yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),YU=n(Yie,"A",{href:!0});var pGt=s(YU);xtr=r(pGt,"from_pretrained()"),pGt.forEach(t),$tr=r(Yie," to load the model weights."),Yie.forEach(t),ktr=i(y8),T(VF.$$.fragment,y8),y8.forEach(t),Str=i(Il),ao=n(Il,"DIV",{class:!0});var ya=s(ao);T(L$.$$.fragment,ya),Rtr=i(ya),hTe=n(ya,"P",{});var _Gt=s(hTe);Ptr=r(_Gt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_Gt.forEach(t),Btr=i(ya),nn=n(ya,"P",{});var x8=s(nn);Itr=r(x8,"The model class to instantiate is selected based on the "),uTe=n(x8,"CODE",{});var bGt=s(uTe);Ntr=r(bGt,"model_type"),bGt.forEach(t),qtr=r(x8,` property of the config object (either
passed as an argument or loaded from `),pTe=n(x8,"CODE",{});var vGt=s(pTe);jtr=r(vGt,"pretrained_model_name_or_path"),vGt.forEach(t),Dtr=r(x8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Te=n(x8,"CODE",{});var FGt=s(_Te);Gtr=r(FGt,"pretrained_model_name_or_path"),FGt.forEach(t),Otr=r(x8,":"),x8.forEach(t),Vtr=i(ya),N=n(ya,"UL",{});var j=s(N);XF=n(j,"LI",{});var HVe=s(XF);bTe=n(HVe,"STRONG",{});var TGt=s(bTe);Xtr=r(TGt,"albert"),TGt.forEach(t),ztr=r(HVe," \u2014 "),ZU=n(HVe,"A",{href:!0});var MGt=s(ZU);Qtr=r(MGt,"AlbertForSequenceClassification"),MGt.forEach(t),Wtr=r(HVe," (ALBERT model)"),HVe.forEach(t),Utr=i(j),zF=n(j,"LI",{});var JVe=s(zF);vTe=n(JVe,"STRONG",{});var EGt=s(vTe);Htr=r(EGt,"bart"),EGt.forEach(t),Jtr=r(JVe," \u2014 "),KU=n(JVe,"A",{href:!0});var CGt=s(KU);Ytr=r(CGt,"BartForSequenceClassification"),CGt.forEach(t),Ztr=r(JVe," (BART model)"),JVe.forEach(t),Ktr=i(j),QF=n(j,"LI",{});var YVe=s(QF);FTe=n(YVe,"STRONG",{});var wGt=s(FTe);ear=r(wGt,"bert"),wGt.forEach(t),oar=r(YVe," \u2014 "),eH=n(YVe,"A",{href:!0});var AGt=s(eH);rar=r(AGt,"BertForSequenceClassification"),AGt.forEach(t),tar=r(YVe," (BERT model)"),YVe.forEach(t),aar=i(j),WF=n(j,"LI",{});var ZVe=s(WF);TTe=n(ZVe,"STRONG",{});var LGt=s(TTe);nar=r(LGt,"big_bird"),LGt.forEach(t),sar=r(ZVe," \u2014 "),oH=n(ZVe,"A",{href:!0});var yGt=s(oH);lar=r(yGt,"BigBirdForSequenceClassification"),yGt.forEach(t),iar=r(ZVe," (BigBird model)"),ZVe.forEach(t),dar=i(j),UF=n(j,"LI",{});var KVe=s(UF);MTe=n(KVe,"STRONG",{});var xGt=s(MTe);car=r(xGt,"bigbird_pegasus"),xGt.forEach(t),mar=r(KVe," \u2014 "),rH=n(KVe,"A",{href:!0});var $Gt=s(rH);far=r($Gt,"BigBirdPegasusForSequenceClassification"),$Gt.forEach(t),gar=r(KVe," (BigBird-Pegasus model)"),KVe.forEach(t),har=i(j),HF=n(j,"LI",{});var eXe=s(HF);ETe=n(eXe,"STRONG",{});var kGt=s(ETe);uar=r(kGt,"bloom"),kGt.forEach(t),par=r(eXe," \u2014 "),tH=n(eXe,"A",{href:!0});var SGt=s(tH);_ar=r(SGt,"BloomForSequenceClassification"),SGt.forEach(t),bar=r(eXe," (BLOOM model)"),eXe.forEach(t),Far=i(j),JF=n(j,"LI",{});var oXe=s(JF);CTe=n(oXe,"STRONG",{});var RGt=s(CTe);Tar=r(RGt,"camembert"),RGt.forEach(t),Mar=r(oXe," \u2014 "),aH=n(oXe,"A",{href:!0});var PGt=s(aH);Ear=r(PGt,"CamembertForSequenceClassification"),PGt.forEach(t),Car=r(oXe," (CamemBERT model)"),oXe.forEach(t),war=i(j),YF=n(j,"LI",{});var rXe=s(YF);wTe=n(rXe,"STRONG",{});var BGt=s(wTe);Aar=r(BGt,"canine"),BGt.forEach(t),Lar=r(rXe," \u2014 "),nH=n(rXe,"A",{href:!0});var IGt=s(nH);yar=r(IGt,"CanineForSequenceClassification"),IGt.forEach(t),xar=r(rXe," (CANINE model)"),rXe.forEach(t),$ar=i(j),ZF=n(j,"LI",{});var tXe=s(ZF);ATe=n(tXe,"STRONG",{});var NGt=s(ATe);kar=r(NGt,"convbert"),NGt.forEach(t),Sar=r(tXe," \u2014 "),sH=n(tXe,"A",{href:!0});var qGt=s(sH);Rar=r(qGt,"ConvBertForSequenceClassification"),qGt.forEach(t),Par=r(tXe," (ConvBERT model)"),tXe.forEach(t),Bar=i(j),KF=n(j,"LI",{});var aXe=s(KF);LTe=n(aXe,"STRONG",{});var jGt=s(LTe);Iar=r(jGt,"ctrl"),jGt.forEach(t),Nar=r(aXe," \u2014 "),lH=n(aXe,"A",{href:!0});var DGt=s(lH);qar=r(DGt,"CTRLForSequenceClassification"),DGt.forEach(t),jar=r(aXe," (CTRL model)"),aXe.forEach(t),Dar=i(j),eT=n(j,"LI",{});var nXe=s(eT);yTe=n(nXe,"STRONG",{});var GGt=s(yTe);Gar=r(GGt,"data2vec-text"),GGt.forEach(t),Oar=r(nXe," \u2014 "),iH=n(nXe,"A",{href:!0});var OGt=s(iH);Var=r(OGt,"Data2VecTextForSequenceClassification"),OGt.forEach(t),Xar=r(nXe," (Data2VecText model)"),nXe.forEach(t),zar=i(j),oT=n(j,"LI",{});var sXe=s(oT);xTe=n(sXe,"STRONG",{});var VGt=s(xTe);Qar=r(VGt,"deberta"),VGt.forEach(t),War=r(sXe," \u2014 "),dH=n(sXe,"A",{href:!0});var XGt=s(dH);Uar=r(XGt,"DebertaForSequenceClassification"),XGt.forEach(t),Har=r(sXe," (DeBERTa model)"),sXe.forEach(t),Jar=i(j),rT=n(j,"LI",{});var lXe=s(rT);$Te=n(lXe,"STRONG",{});var zGt=s($Te);Yar=r(zGt,"deberta-v2"),zGt.forEach(t),Zar=r(lXe," \u2014 "),cH=n(lXe,"A",{href:!0});var QGt=s(cH);Kar=r(QGt,"DebertaV2ForSequenceClassification"),QGt.forEach(t),enr=r(lXe," (DeBERTa-v2 model)"),lXe.forEach(t),onr=i(j),tT=n(j,"LI",{});var iXe=s(tT);kTe=n(iXe,"STRONG",{});var WGt=s(kTe);rnr=r(WGt,"distilbert"),WGt.forEach(t),tnr=r(iXe," \u2014 "),mH=n(iXe,"A",{href:!0});var UGt=s(mH);anr=r(UGt,"DistilBertForSequenceClassification"),UGt.forEach(t),nnr=r(iXe," (DistilBERT model)"),iXe.forEach(t),snr=i(j),aT=n(j,"LI",{});var dXe=s(aT);STe=n(dXe,"STRONG",{});var HGt=s(STe);lnr=r(HGt,"electra"),HGt.forEach(t),inr=r(dXe," \u2014 "),fH=n(dXe,"A",{href:!0});var JGt=s(fH);dnr=r(JGt,"ElectraForSequenceClassification"),JGt.forEach(t),cnr=r(dXe," (ELECTRA model)"),dXe.forEach(t),mnr=i(j),nT=n(j,"LI",{});var cXe=s(nT);RTe=n(cXe,"STRONG",{});var YGt=s(RTe);fnr=r(YGt,"ernie"),YGt.forEach(t),gnr=r(cXe," \u2014 "),gH=n(cXe,"A",{href:!0});var ZGt=s(gH);hnr=r(ZGt,"ErnieForSequenceClassification"),ZGt.forEach(t),unr=r(cXe," (ERNIE model)"),cXe.forEach(t),pnr=i(j),sT=n(j,"LI",{});var mXe=s(sT);PTe=n(mXe,"STRONG",{});var KGt=s(PTe);_nr=r(KGt,"esm"),KGt.forEach(t),bnr=r(mXe," \u2014 "),hH=n(mXe,"A",{href:!0});var eOt=s(hH);vnr=r(eOt,"EsmForSequenceClassification"),eOt.forEach(t),Fnr=r(mXe," (ESM model)"),mXe.forEach(t),Tnr=i(j),lT=n(j,"LI",{});var fXe=s(lT);BTe=n(fXe,"STRONG",{});var oOt=s(BTe);Mnr=r(oOt,"flaubert"),oOt.forEach(t),Enr=r(fXe," \u2014 "),uH=n(fXe,"A",{href:!0});var rOt=s(uH);Cnr=r(rOt,"FlaubertForSequenceClassification"),rOt.forEach(t),wnr=r(fXe," (FlauBERT model)"),fXe.forEach(t),Anr=i(j),iT=n(j,"LI",{});var gXe=s(iT);ITe=n(gXe,"STRONG",{});var tOt=s(ITe);Lnr=r(tOt,"fnet"),tOt.forEach(t),ynr=r(gXe," \u2014 "),pH=n(gXe,"A",{href:!0});var aOt=s(pH);xnr=r(aOt,"FNetForSequenceClassification"),aOt.forEach(t),$nr=r(gXe," (FNet model)"),gXe.forEach(t),knr=i(j),dT=n(j,"LI",{});var hXe=s(dT);NTe=n(hXe,"STRONG",{});var nOt=s(NTe);Snr=r(nOt,"funnel"),nOt.forEach(t),Rnr=r(hXe," \u2014 "),_H=n(hXe,"A",{href:!0});var sOt=s(_H);Pnr=r(sOt,"FunnelForSequenceClassification"),sOt.forEach(t),Bnr=r(hXe," (Funnel Transformer model)"),hXe.forEach(t),Inr=i(j),cT=n(j,"LI",{});var uXe=s(cT);qTe=n(uXe,"STRONG",{});var lOt=s(qTe);Nnr=r(lOt,"gpt2"),lOt.forEach(t),qnr=r(uXe," \u2014 "),bH=n(uXe,"A",{href:!0});var iOt=s(bH);jnr=r(iOt,"GPT2ForSequenceClassification"),iOt.forEach(t),Dnr=r(uXe," (OpenAI GPT-2 model)"),uXe.forEach(t),Gnr=i(j),mT=n(j,"LI",{});var pXe=s(mT);jTe=n(pXe,"STRONG",{});var dOt=s(jTe);Onr=r(dOt,"gpt_neo"),dOt.forEach(t),Vnr=r(pXe," \u2014 "),vH=n(pXe,"A",{href:!0});var cOt=s(vH);Xnr=r(cOt,"GPTNeoForSequenceClassification"),cOt.forEach(t),znr=r(pXe," (GPT Neo model)"),pXe.forEach(t),Qnr=i(j),fT=n(j,"LI",{});var _Xe=s(fT);DTe=n(_Xe,"STRONG",{});var mOt=s(DTe);Wnr=r(mOt,"gptj"),mOt.forEach(t),Unr=r(_Xe," \u2014 "),FH=n(_Xe,"A",{href:!0});var fOt=s(FH);Hnr=r(fOt,"GPTJForSequenceClassification"),fOt.forEach(t),Jnr=r(_Xe," (GPT-J model)"),_Xe.forEach(t),Ynr=i(j),gT=n(j,"LI",{});var bXe=s(gT);GTe=n(bXe,"STRONG",{});var gOt=s(GTe);Znr=r(gOt,"ibert"),gOt.forEach(t),Knr=r(bXe," \u2014 "),TH=n(bXe,"A",{href:!0});var hOt=s(TH);esr=r(hOt,"IBertForSequenceClassification"),hOt.forEach(t),osr=r(bXe," (I-BERT model)"),bXe.forEach(t),rsr=i(j),hT=n(j,"LI",{});var vXe=s(hT);OTe=n(vXe,"STRONG",{});var uOt=s(OTe);tsr=r(uOt,"layoutlm"),uOt.forEach(t),asr=r(vXe," \u2014 "),MH=n(vXe,"A",{href:!0});var pOt=s(MH);nsr=r(pOt,"LayoutLMForSequenceClassification"),pOt.forEach(t),ssr=r(vXe," (LayoutLM model)"),vXe.forEach(t),lsr=i(j),uT=n(j,"LI",{});var FXe=s(uT);VTe=n(FXe,"STRONG",{});var _Ot=s(VTe);isr=r(_Ot,"layoutlmv2"),_Ot.forEach(t),dsr=r(FXe," \u2014 "),EH=n(FXe,"A",{href:!0});var bOt=s(EH);csr=r(bOt,"LayoutLMv2ForSequenceClassification"),bOt.forEach(t),msr=r(FXe," (LayoutLMv2 model)"),FXe.forEach(t),fsr=i(j),pT=n(j,"LI",{});var TXe=s(pT);XTe=n(TXe,"STRONG",{});var vOt=s(XTe);gsr=r(vOt,"layoutlmv3"),vOt.forEach(t),hsr=r(TXe," \u2014 "),CH=n(TXe,"A",{href:!0});var FOt=s(CH);usr=r(FOt,"LayoutLMv3ForSequenceClassification"),FOt.forEach(t),psr=r(TXe," (LayoutLMv3 model)"),TXe.forEach(t),_sr=i(j),_T=n(j,"LI",{});var MXe=s(_T);zTe=n(MXe,"STRONG",{});var TOt=s(zTe);bsr=r(TOt,"led"),TOt.forEach(t),vsr=r(MXe," \u2014 "),wH=n(MXe,"A",{href:!0});var MOt=s(wH);Fsr=r(MOt,"LEDForSequenceClassification"),MOt.forEach(t),Tsr=r(MXe," (LED model)"),MXe.forEach(t),Msr=i(j),bT=n(j,"LI",{});var EXe=s(bT);QTe=n(EXe,"STRONG",{});var EOt=s(QTe);Esr=r(EOt,"longformer"),EOt.forEach(t),Csr=r(EXe," \u2014 "),AH=n(EXe,"A",{href:!0});var COt=s(AH);wsr=r(COt,"LongformerForSequenceClassification"),COt.forEach(t),Asr=r(EXe," (Longformer model)"),EXe.forEach(t),Lsr=i(j),vT=n(j,"LI",{});var CXe=s(vT);WTe=n(CXe,"STRONG",{});var wOt=s(WTe);ysr=r(wOt,"luke"),wOt.forEach(t),xsr=r(CXe," \u2014 "),LH=n(CXe,"A",{href:!0});var AOt=s(LH);$sr=r(AOt,"LukeForSequenceClassification"),AOt.forEach(t),ksr=r(CXe," (LUKE model)"),CXe.forEach(t),Ssr=i(j),FT=n(j,"LI",{});var wXe=s(FT);UTe=n(wXe,"STRONG",{});var LOt=s(UTe);Rsr=r(LOt,"markuplm"),LOt.forEach(t),Psr=r(wXe," \u2014 "),yH=n(wXe,"A",{href:!0});var yOt=s(yH);Bsr=r(yOt,"MarkupLMForSequenceClassification"),yOt.forEach(t),Isr=r(wXe," (MarkupLM model)"),wXe.forEach(t),Nsr=i(j),TT=n(j,"LI",{});var AXe=s(TT);HTe=n(AXe,"STRONG",{});var xOt=s(HTe);qsr=r(xOt,"mbart"),xOt.forEach(t),jsr=r(AXe," \u2014 "),xH=n(AXe,"A",{href:!0});var $Ot=s(xH);Dsr=r($Ot,"MBartForSequenceClassification"),$Ot.forEach(t),Gsr=r(AXe," (mBART model)"),AXe.forEach(t),Osr=i(j),MT=n(j,"LI",{});var LXe=s(MT);JTe=n(LXe,"STRONG",{});var kOt=s(JTe);Vsr=r(kOt,"megatron-bert"),kOt.forEach(t),Xsr=r(LXe," \u2014 "),$H=n(LXe,"A",{href:!0});var SOt=s($H);zsr=r(SOt,"MegatronBertForSequenceClassification"),SOt.forEach(t),Qsr=r(LXe," (Megatron-BERT model)"),LXe.forEach(t),Wsr=i(j),ET=n(j,"LI",{});var yXe=s(ET);YTe=n(yXe,"STRONG",{});var ROt=s(YTe);Usr=r(ROt,"mobilebert"),ROt.forEach(t),Hsr=r(yXe," \u2014 "),kH=n(yXe,"A",{href:!0});var POt=s(kH);Jsr=r(POt,"MobileBertForSequenceClassification"),POt.forEach(t),Ysr=r(yXe," (MobileBERT model)"),yXe.forEach(t),Zsr=i(j),CT=n(j,"LI",{});var xXe=s(CT);ZTe=n(xXe,"STRONG",{});var BOt=s(ZTe);Ksr=r(BOt,"mpnet"),BOt.forEach(t),elr=r(xXe," \u2014 "),SH=n(xXe,"A",{href:!0});var IOt=s(SH);olr=r(IOt,"MPNetForSequenceClassification"),IOt.forEach(t),rlr=r(xXe," (MPNet model)"),xXe.forEach(t),tlr=i(j),wT=n(j,"LI",{});var $Xe=s(wT);KTe=n($Xe,"STRONG",{});var NOt=s(KTe);alr=r(NOt,"mvp"),NOt.forEach(t),nlr=r($Xe," \u2014 "),RH=n($Xe,"A",{href:!0});var qOt=s(RH);slr=r(qOt,"MvpForSequenceClassification"),qOt.forEach(t),llr=r($Xe," (MVP model)"),$Xe.forEach(t),ilr=i(j),AT=n(j,"LI",{});var kXe=s(AT);eMe=n(kXe,"STRONG",{});var jOt=s(eMe);dlr=r(jOt,"nezha"),jOt.forEach(t),clr=r(kXe," \u2014 "),PH=n(kXe,"A",{href:!0});var DOt=s(PH);mlr=r(DOt,"NezhaForSequenceClassification"),DOt.forEach(t),flr=r(kXe," (Nezha model)"),kXe.forEach(t),glr=i(j),LT=n(j,"LI",{});var SXe=s(LT);oMe=n(SXe,"STRONG",{});var GOt=s(oMe);hlr=r(GOt,"nystromformer"),GOt.forEach(t),ulr=r(SXe," \u2014 "),BH=n(SXe,"A",{href:!0});var OOt=s(BH);plr=r(OOt,"NystromformerForSequenceClassification"),OOt.forEach(t),_lr=r(SXe," (Nystr\xF6mformer model)"),SXe.forEach(t),blr=i(j),yT=n(j,"LI",{});var RXe=s(yT);rMe=n(RXe,"STRONG",{});var VOt=s(rMe);vlr=r(VOt,"openai-gpt"),VOt.forEach(t),Flr=r(RXe," \u2014 "),IH=n(RXe,"A",{href:!0});var XOt=s(IH);Tlr=r(XOt,"OpenAIGPTForSequenceClassification"),XOt.forEach(t),Mlr=r(RXe," (OpenAI GPT model)"),RXe.forEach(t),Elr=i(j),xT=n(j,"LI",{});var PXe=s(xT);tMe=n(PXe,"STRONG",{});var zOt=s(tMe);Clr=r(zOt,"opt"),zOt.forEach(t),wlr=r(PXe," \u2014 "),NH=n(PXe,"A",{href:!0});var QOt=s(NH);Alr=r(QOt,"OPTForSequenceClassification"),QOt.forEach(t),Llr=r(PXe," (OPT model)"),PXe.forEach(t),ylr=i(j),$T=n(j,"LI",{});var BXe=s($T);aMe=n(BXe,"STRONG",{});var WOt=s(aMe);xlr=r(WOt,"perceiver"),WOt.forEach(t),$lr=r(BXe," \u2014 "),qH=n(BXe,"A",{href:!0});var UOt=s(qH);klr=r(UOt,"PerceiverForSequenceClassification"),UOt.forEach(t),Slr=r(BXe," (Perceiver model)"),BXe.forEach(t),Rlr=i(j),kT=n(j,"LI",{});var IXe=s(kT);nMe=n(IXe,"STRONG",{});var HOt=s(nMe);Plr=r(HOt,"plbart"),HOt.forEach(t),Blr=r(IXe," \u2014 "),jH=n(IXe,"A",{href:!0});var JOt=s(jH);Ilr=r(JOt,"PLBartForSequenceClassification"),JOt.forEach(t),Nlr=r(IXe," (PLBart model)"),IXe.forEach(t),qlr=i(j),ST=n(j,"LI",{});var NXe=s(ST);sMe=n(NXe,"STRONG",{});var YOt=s(sMe);jlr=r(YOt,"qdqbert"),YOt.forEach(t),Dlr=r(NXe," \u2014 "),DH=n(NXe,"A",{href:!0});var ZOt=s(DH);Glr=r(ZOt,"QDQBertForSequenceClassification"),ZOt.forEach(t),Olr=r(NXe," (QDQBert model)"),NXe.forEach(t),Vlr=i(j),RT=n(j,"LI",{});var qXe=s(RT);lMe=n(qXe,"STRONG",{});var KOt=s(lMe);Xlr=r(KOt,"reformer"),KOt.forEach(t),zlr=r(qXe," \u2014 "),GH=n(qXe,"A",{href:!0});var eVt=s(GH);Qlr=r(eVt,"ReformerForSequenceClassification"),eVt.forEach(t),Wlr=r(qXe," (Reformer model)"),qXe.forEach(t),Ulr=i(j),PT=n(j,"LI",{});var jXe=s(PT);iMe=n(jXe,"STRONG",{});var oVt=s(iMe);Hlr=r(oVt,"rembert"),oVt.forEach(t),Jlr=r(jXe," \u2014 "),OH=n(jXe,"A",{href:!0});var rVt=s(OH);Ylr=r(rVt,"RemBertForSequenceClassification"),rVt.forEach(t),Zlr=r(jXe," (RemBERT model)"),jXe.forEach(t),Klr=i(j),BT=n(j,"LI",{});var DXe=s(BT);dMe=n(DXe,"STRONG",{});var tVt=s(dMe);eir=r(tVt,"roberta"),tVt.forEach(t),oir=r(DXe," \u2014 "),VH=n(DXe,"A",{href:!0});var aVt=s(VH);rir=r(aVt,"RobertaForSequenceClassification"),aVt.forEach(t),tir=r(DXe," (RoBERTa model)"),DXe.forEach(t),air=i(j),IT=n(j,"LI",{});var GXe=s(IT);cMe=n(GXe,"STRONG",{});var nVt=s(cMe);nir=r(nVt,"roformer"),nVt.forEach(t),sir=r(GXe," \u2014 "),XH=n(GXe,"A",{href:!0});var sVt=s(XH);lir=r(sVt,"RoFormerForSequenceClassification"),sVt.forEach(t),iir=r(GXe," (RoFormer model)"),GXe.forEach(t),dir=i(j),NT=n(j,"LI",{});var OXe=s(NT);mMe=n(OXe,"STRONG",{});var lVt=s(mMe);cir=r(lVt,"squeezebert"),lVt.forEach(t),mir=r(OXe," \u2014 "),zH=n(OXe,"A",{href:!0});var iVt=s(zH);fir=r(iVt,"SqueezeBertForSequenceClassification"),iVt.forEach(t),gir=r(OXe," (SqueezeBERT model)"),OXe.forEach(t),hir=i(j),qT=n(j,"LI",{});var VXe=s(qT);fMe=n(VXe,"STRONG",{});var dVt=s(fMe);uir=r(dVt,"tapas"),dVt.forEach(t),pir=r(VXe," \u2014 "),QH=n(VXe,"A",{href:!0});var cVt=s(QH);_ir=r(cVt,"TapasForSequenceClassification"),cVt.forEach(t),bir=r(VXe," (TAPAS model)"),VXe.forEach(t),vir=i(j),jT=n(j,"LI",{});var XXe=s(jT);gMe=n(XXe,"STRONG",{});var mVt=s(gMe);Fir=r(mVt,"transfo-xl"),mVt.forEach(t),Tir=r(XXe," \u2014 "),WH=n(XXe,"A",{href:!0});var fVt=s(WH);Mir=r(fVt,"TransfoXLForSequenceClassification"),fVt.forEach(t),Eir=r(XXe," (Transformer-XL model)"),XXe.forEach(t),Cir=i(j),DT=n(j,"LI",{});var zXe=s(DT);hMe=n(zXe,"STRONG",{});var gVt=s(hMe);wir=r(gVt,"xlm"),gVt.forEach(t),Air=r(zXe," \u2014 "),UH=n(zXe,"A",{href:!0});var hVt=s(UH);Lir=r(hVt,"XLMForSequenceClassification"),hVt.forEach(t),yir=r(zXe," (XLM model)"),zXe.forEach(t),xir=i(j),GT=n(j,"LI",{});var QXe=s(GT);uMe=n(QXe,"STRONG",{});var uVt=s(uMe);$ir=r(uVt,"xlm-roberta"),uVt.forEach(t),kir=r(QXe," \u2014 "),HH=n(QXe,"A",{href:!0});var pVt=s(HH);Sir=r(pVt,"XLMRobertaForSequenceClassification"),pVt.forEach(t),Rir=r(QXe," (XLM-RoBERTa model)"),QXe.forEach(t),Pir=i(j),OT=n(j,"LI",{});var WXe=s(OT);pMe=n(WXe,"STRONG",{});var _Vt=s(pMe);Bir=r(_Vt,"xlm-roberta-xl"),_Vt.forEach(t),Iir=r(WXe," \u2014 "),JH=n(WXe,"A",{href:!0});var bVt=s(JH);Nir=r(bVt,"XLMRobertaXLForSequenceClassification"),bVt.forEach(t),qir=r(WXe," (XLM-RoBERTa-XL model)"),WXe.forEach(t),jir=i(j),VT=n(j,"LI",{});var UXe=s(VT);_Me=n(UXe,"STRONG",{});var vVt=s(_Me);Dir=r(vVt,"xlnet"),vVt.forEach(t),Gir=r(UXe," \u2014 "),YH=n(UXe,"A",{href:!0});var FVt=s(YH);Oir=r(FVt,"XLNetForSequenceClassification"),FVt.forEach(t),Vir=r(UXe," (XLNet model)"),UXe.forEach(t),Xir=i(j),XT=n(j,"LI",{});var HXe=s(XT);bMe=n(HXe,"STRONG",{});var TVt=s(bMe);zir=r(TVt,"yoso"),TVt.forEach(t),Qir=r(HXe," \u2014 "),ZH=n(HXe,"A",{href:!0});var MVt=s(ZH);Wir=r(MVt,"YosoForSequenceClassification"),MVt.forEach(t),Uir=r(HXe," (YOSO model)"),HXe.forEach(t),j.forEach(t),Hir=i(ya),zT=n(ya,"P",{});var JXe=s(zT);Jir=r(JXe,"The model is set in evaluation mode by default using "),vMe=n(JXe,"CODE",{});var EVt=s(vMe);Yir=r(EVt,"model.eval()"),EVt.forEach(t),Zir=r(JXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),FMe=n(JXe,"CODE",{});var CVt=s(FMe);Kir=r(CVt,"model.train()"),CVt.forEach(t),JXe.forEach(t),edr=i(ya),T(QT.$$.fragment,ya),ya.forEach(t),Il.forEach(t),Roo=i(m),Gd=n(m,"H2",{class:!0});var Hto=s(Gd);WT=n(Hto,"A",{id:!0,class:!0,href:!0});var wVt=s(WT);TMe=n(wVt,"SPAN",{});var AVt=s(TMe);T(y$.$$.fragment,AVt),AVt.forEach(t),wVt.forEach(t),odr=i(Hto),MMe=n(Hto,"SPAN",{});var LVt=s(MMe);rdr=r(LVt,"AutoModelForMultipleChoice"),LVt.forEach(t),Hto.forEach(t),Poo=i(m),Go=n(m,"DIV",{class:!0});var Nl=s(Go);T(x$.$$.fragment,Nl),tdr=i(Nl),Od=n(Nl,"P",{});var Zie=s(Od);adr=r(Zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),KH=n(Zie,"A",{href:!0});var yVt=s(KH);ndr=r(yVt,"from_pretrained()"),yVt.forEach(t),sdr=r(Zie," class method or the "),eJ=n(Zie,"A",{href:!0});var xVt=s(eJ);ldr=r(xVt,"from_config()"),xVt.forEach(t),idr=r(Zie,` class
method.`),Zie.forEach(t),ddr=i(Nl),$$=n(Nl,"P",{});var Jto=s($$);cdr=r(Jto,"This class cannot be instantiated directly using "),EMe=n(Jto,"CODE",{});var $Vt=s(EMe);mdr=r($Vt,"__init__()"),$Vt.forEach(t),fdr=r(Jto," (throws an error)."),Jto.forEach(t),gdr=i(Nl),wt=n(Nl,"DIV",{class:!0});var $8=s(wt);T(k$.$$.fragment,$8),hdr=i($8),CMe=n($8,"P",{});var kVt=s(CMe);udr=r(kVt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),kVt.forEach(t),pdr=i($8),Vd=n($8,"P",{});var Kie=s(Vd);_dr=r(Kie,`Note:
Loading a model from its configuration file does `),wMe=n(Kie,"STRONG",{});var SVt=s(wMe);bdr=r(SVt,"not"),SVt.forEach(t),vdr=r(Kie,` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=n(Kie,"A",{href:!0});var RVt=s(oJ);Fdr=r(RVt,"from_pretrained()"),RVt.forEach(t),Tdr=r(Kie," to load the model weights."),Kie.forEach(t),Mdr=i($8),T(UT.$$.fragment,$8),$8.forEach(t),Edr=i(Nl),no=n(Nl,"DIV",{class:!0});var xa=s(no);T(S$.$$.fragment,xa),Cdr=i(xa),AMe=n(xa,"P",{});var PVt=s(AMe);wdr=r(PVt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),PVt.forEach(t),Adr=i(xa),sn=n(xa,"P",{});var k8=s(sn);Ldr=r(k8,"The model class to instantiate is selected based on the "),LMe=n(k8,"CODE",{});var BVt=s(LMe);ydr=r(BVt,"model_type"),BVt.forEach(t),xdr=r(k8,` property of the config object (either
passed as an argument or loaded from `),yMe=n(k8,"CODE",{});var IVt=s(yMe);$dr=r(IVt,"pretrained_model_name_or_path"),IVt.forEach(t),kdr=r(k8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=n(k8,"CODE",{});var NVt=s(xMe);Sdr=r(NVt,"pretrained_model_name_or_path"),NVt.forEach(t),Rdr=r(k8,":"),k8.forEach(t),Pdr=i(xa),K=n(xa,"UL",{});var ee=s(K);HT=n(ee,"LI",{});var YXe=s(HT);$Me=n(YXe,"STRONG",{});var qVt=s($Me);Bdr=r(qVt,"albert"),qVt.forEach(t),Idr=r(YXe," \u2014 "),rJ=n(YXe,"A",{href:!0});var jVt=s(rJ);Ndr=r(jVt,"AlbertForMultipleChoice"),jVt.forEach(t),qdr=r(YXe," (ALBERT model)"),YXe.forEach(t),jdr=i(ee),JT=n(ee,"LI",{});var ZXe=s(JT);kMe=n(ZXe,"STRONG",{});var DVt=s(kMe);Ddr=r(DVt,"bert"),DVt.forEach(t),Gdr=r(ZXe," \u2014 "),tJ=n(ZXe,"A",{href:!0});var GVt=s(tJ);Odr=r(GVt,"BertForMultipleChoice"),GVt.forEach(t),Vdr=r(ZXe," (BERT model)"),ZXe.forEach(t),Xdr=i(ee),YT=n(ee,"LI",{});var KXe=s(YT);SMe=n(KXe,"STRONG",{});var OVt=s(SMe);zdr=r(OVt,"big_bird"),OVt.forEach(t),Qdr=r(KXe," \u2014 "),aJ=n(KXe,"A",{href:!0});var VVt=s(aJ);Wdr=r(VVt,"BigBirdForMultipleChoice"),VVt.forEach(t),Udr=r(KXe," (BigBird model)"),KXe.forEach(t),Hdr=i(ee),ZT=n(ee,"LI",{});var eze=s(ZT);RMe=n(eze,"STRONG",{});var XVt=s(RMe);Jdr=r(XVt,"camembert"),XVt.forEach(t),Ydr=r(eze," \u2014 "),nJ=n(eze,"A",{href:!0});var zVt=s(nJ);Zdr=r(zVt,"CamembertForMultipleChoice"),zVt.forEach(t),Kdr=r(eze," (CamemBERT model)"),eze.forEach(t),ecr=i(ee),KT=n(ee,"LI",{});var oze=s(KT);PMe=n(oze,"STRONG",{});var QVt=s(PMe);ocr=r(QVt,"canine"),QVt.forEach(t),rcr=r(oze," \u2014 "),sJ=n(oze,"A",{href:!0});var WVt=s(sJ);tcr=r(WVt,"CanineForMultipleChoice"),WVt.forEach(t),acr=r(oze," (CANINE model)"),oze.forEach(t),ncr=i(ee),eM=n(ee,"LI",{});var rze=s(eM);BMe=n(rze,"STRONG",{});var UVt=s(BMe);scr=r(UVt,"convbert"),UVt.forEach(t),lcr=r(rze," \u2014 "),lJ=n(rze,"A",{href:!0});var HVt=s(lJ);icr=r(HVt,"ConvBertForMultipleChoice"),HVt.forEach(t),dcr=r(rze," (ConvBERT model)"),rze.forEach(t),ccr=i(ee),oM=n(ee,"LI",{});var tze=s(oM);IMe=n(tze,"STRONG",{});var JVt=s(IMe);mcr=r(JVt,"data2vec-text"),JVt.forEach(t),fcr=r(tze," \u2014 "),iJ=n(tze,"A",{href:!0});var YVt=s(iJ);gcr=r(YVt,"Data2VecTextForMultipleChoice"),YVt.forEach(t),hcr=r(tze," (Data2VecText model)"),tze.forEach(t),ucr=i(ee),rM=n(ee,"LI",{});var aze=s(rM);NMe=n(aze,"STRONG",{});var ZVt=s(NMe);pcr=r(ZVt,"deberta-v2"),ZVt.forEach(t),_cr=r(aze," \u2014 "),dJ=n(aze,"A",{href:!0});var KVt=s(dJ);bcr=r(KVt,"DebertaV2ForMultipleChoice"),KVt.forEach(t),vcr=r(aze," (DeBERTa-v2 model)"),aze.forEach(t),Fcr=i(ee),tM=n(ee,"LI",{});var nze=s(tM);qMe=n(nze,"STRONG",{});var eXt=s(qMe);Tcr=r(eXt,"distilbert"),eXt.forEach(t),Mcr=r(nze," \u2014 "),cJ=n(nze,"A",{href:!0});var oXt=s(cJ);Ecr=r(oXt,"DistilBertForMultipleChoice"),oXt.forEach(t),Ccr=r(nze," (DistilBERT model)"),nze.forEach(t),wcr=i(ee),aM=n(ee,"LI",{});var sze=s(aM);jMe=n(sze,"STRONG",{});var rXt=s(jMe);Acr=r(rXt,"electra"),rXt.forEach(t),Lcr=r(sze," \u2014 "),mJ=n(sze,"A",{href:!0});var tXt=s(mJ);ycr=r(tXt,"ElectraForMultipleChoice"),tXt.forEach(t),xcr=r(sze," (ELECTRA model)"),sze.forEach(t),$cr=i(ee),nM=n(ee,"LI",{});var lze=s(nM);DMe=n(lze,"STRONG",{});var aXt=s(DMe);kcr=r(aXt,"ernie"),aXt.forEach(t),Scr=r(lze," \u2014 "),fJ=n(lze,"A",{href:!0});var nXt=s(fJ);Rcr=r(nXt,"ErnieForMultipleChoice"),nXt.forEach(t),Pcr=r(lze," (ERNIE model)"),lze.forEach(t),Bcr=i(ee),sM=n(ee,"LI",{});var ize=s(sM);GMe=n(ize,"STRONG",{});var sXt=s(GMe);Icr=r(sXt,"flaubert"),sXt.forEach(t),Ncr=r(ize," \u2014 "),gJ=n(ize,"A",{href:!0});var lXt=s(gJ);qcr=r(lXt,"FlaubertForMultipleChoice"),lXt.forEach(t),jcr=r(ize," (FlauBERT model)"),ize.forEach(t),Dcr=i(ee),lM=n(ee,"LI",{});var dze=s(lM);OMe=n(dze,"STRONG",{});var iXt=s(OMe);Gcr=r(iXt,"fnet"),iXt.forEach(t),Ocr=r(dze," \u2014 "),hJ=n(dze,"A",{href:!0});var dXt=s(hJ);Vcr=r(dXt,"FNetForMultipleChoice"),dXt.forEach(t),Xcr=r(dze," (FNet model)"),dze.forEach(t),zcr=i(ee),iM=n(ee,"LI",{});var cze=s(iM);VMe=n(cze,"STRONG",{});var cXt=s(VMe);Qcr=r(cXt,"funnel"),cXt.forEach(t),Wcr=r(cze," \u2014 "),uJ=n(cze,"A",{href:!0});var mXt=s(uJ);Ucr=r(mXt,"FunnelForMultipleChoice"),mXt.forEach(t),Hcr=r(cze," (Funnel Transformer model)"),cze.forEach(t),Jcr=i(ee),dM=n(ee,"LI",{});var mze=s(dM);XMe=n(mze,"STRONG",{});var fXt=s(XMe);Ycr=r(fXt,"ibert"),fXt.forEach(t),Zcr=r(mze," \u2014 "),pJ=n(mze,"A",{href:!0});var gXt=s(pJ);Kcr=r(gXt,"IBertForMultipleChoice"),gXt.forEach(t),emr=r(mze," (I-BERT model)"),mze.forEach(t),omr=i(ee),cM=n(ee,"LI",{});var fze=s(cM);zMe=n(fze,"STRONG",{});var hXt=s(zMe);rmr=r(hXt,"longformer"),hXt.forEach(t),tmr=r(fze," \u2014 "),_J=n(fze,"A",{href:!0});var uXt=s(_J);amr=r(uXt,"LongformerForMultipleChoice"),uXt.forEach(t),nmr=r(fze," (Longformer model)"),fze.forEach(t),smr=i(ee),mM=n(ee,"LI",{});var gze=s(mM);QMe=n(gze,"STRONG",{});var pXt=s(QMe);lmr=r(pXt,"luke"),pXt.forEach(t),imr=r(gze," \u2014 "),bJ=n(gze,"A",{href:!0});var _Xt=s(bJ);dmr=r(_Xt,"LukeForMultipleChoice"),_Xt.forEach(t),cmr=r(gze," (LUKE model)"),gze.forEach(t),mmr=i(ee),fM=n(ee,"LI",{});var hze=s(fM);WMe=n(hze,"STRONG",{});var bXt=s(WMe);fmr=r(bXt,"megatron-bert"),bXt.forEach(t),gmr=r(hze," \u2014 "),vJ=n(hze,"A",{href:!0});var vXt=s(vJ);hmr=r(vXt,"MegatronBertForMultipleChoice"),vXt.forEach(t),umr=r(hze," (Megatron-BERT model)"),hze.forEach(t),pmr=i(ee),gM=n(ee,"LI",{});var uze=s(gM);UMe=n(uze,"STRONG",{});var FXt=s(UMe);_mr=r(FXt,"mobilebert"),FXt.forEach(t),bmr=r(uze," \u2014 "),FJ=n(uze,"A",{href:!0});var TXt=s(FJ);vmr=r(TXt,"MobileBertForMultipleChoice"),TXt.forEach(t),Fmr=r(uze," (MobileBERT model)"),uze.forEach(t),Tmr=i(ee),hM=n(ee,"LI",{});var pze=s(hM);HMe=n(pze,"STRONG",{});var MXt=s(HMe);Mmr=r(MXt,"mpnet"),MXt.forEach(t),Emr=r(pze," \u2014 "),TJ=n(pze,"A",{href:!0});var EXt=s(TJ);Cmr=r(EXt,"MPNetForMultipleChoice"),EXt.forEach(t),wmr=r(pze," (MPNet model)"),pze.forEach(t),Amr=i(ee),uM=n(ee,"LI",{});var _ze=s(uM);JMe=n(_ze,"STRONG",{});var CXt=s(JMe);Lmr=r(CXt,"nezha"),CXt.forEach(t),ymr=r(_ze," \u2014 "),MJ=n(_ze,"A",{href:!0});var wXt=s(MJ);xmr=r(wXt,"NezhaForMultipleChoice"),wXt.forEach(t),$mr=r(_ze," (Nezha model)"),_ze.forEach(t),kmr=i(ee),pM=n(ee,"LI",{});var bze=s(pM);YMe=n(bze,"STRONG",{});var AXt=s(YMe);Smr=r(AXt,"nystromformer"),AXt.forEach(t),Rmr=r(bze," \u2014 "),EJ=n(bze,"A",{href:!0});var LXt=s(EJ);Pmr=r(LXt,"NystromformerForMultipleChoice"),LXt.forEach(t),Bmr=r(bze," (Nystr\xF6mformer model)"),bze.forEach(t),Imr=i(ee),_M=n(ee,"LI",{});var vze=s(_M);ZMe=n(vze,"STRONG",{});var yXt=s(ZMe);Nmr=r(yXt,"qdqbert"),yXt.forEach(t),qmr=r(vze," \u2014 "),CJ=n(vze,"A",{href:!0});var xXt=s(CJ);jmr=r(xXt,"QDQBertForMultipleChoice"),xXt.forEach(t),Dmr=r(vze," (QDQBert model)"),vze.forEach(t),Gmr=i(ee),bM=n(ee,"LI",{});var Fze=s(bM);KMe=n(Fze,"STRONG",{});var $Xt=s(KMe);Omr=r($Xt,"rembert"),$Xt.forEach(t),Vmr=r(Fze," \u2014 "),wJ=n(Fze,"A",{href:!0});var kXt=s(wJ);Xmr=r(kXt,"RemBertForMultipleChoice"),kXt.forEach(t),zmr=r(Fze," (RemBERT model)"),Fze.forEach(t),Qmr=i(ee),vM=n(ee,"LI",{});var Tze=s(vM);eEe=n(Tze,"STRONG",{});var SXt=s(eEe);Wmr=r(SXt,"roberta"),SXt.forEach(t),Umr=r(Tze," \u2014 "),AJ=n(Tze,"A",{href:!0});var RXt=s(AJ);Hmr=r(RXt,"RobertaForMultipleChoice"),RXt.forEach(t),Jmr=r(Tze," (RoBERTa model)"),Tze.forEach(t),Ymr=i(ee),FM=n(ee,"LI",{});var Mze=s(FM);oEe=n(Mze,"STRONG",{});var PXt=s(oEe);Zmr=r(PXt,"roformer"),PXt.forEach(t),Kmr=r(Mze," \u2014 "),LJ=n(Mze,"A",{href:!0});var BXt=s(LJ);efr=r(BXt,"RoFormerForMultipleChoice"),BXt.forEach(t),ofr=r(Mze," (RoFormer model)"),Mze.forEach(t),rfr=i(ee),TM=n(ee,"LI",{});var Eze=s(TM);rEe=n(Eze,"STRONG",{});var IXt=s(rEe);tfr=r(IXt,"squeezebert"),IXt.forEach(t),afr=r(Eze," \u2014 "),yJ=n(Eze,"A",{href:!0});var NXt=s(yJ);nfr=r(NXt,"SqueezeBertForMultipleChoice"),NXt.forEach(t),sfr=r(Eze," (SqueezeBERT model)"),Eze.forEach(t),lfr=i(ee),MM=n(ee,"LI",{});var Cze=s(MM);tEe=n(Cze,"STRONG",{});var qXt=s(tEe);ifr=r(qXt,"xlm"),qXt.forEach(t),dfr=r(Cze," \u2014 "),xJ=n(Cze,"A",{href:!0});var jXt=s(xJ);cfr=r(jXt,"XLMForMultipleChoice"),jXt.forEach(t),mfr=r(Cze," (XLM model)"),Cze.forEach(t),ffr=i(ee),EM=n(ee,"LI",{});var wze=s(EM);aEe=n(wze,"STRONG",{});var DXt=s(aEe);gfr=r(DXt,"xlm-roberta"),DXt.forEach(t),hfr=r(wze," \u2014 "),$J=n(wze,"A",{href:!0});var GXt=s($J);ufr=r(GXt,"XLMRobertaForMultipleChoice"),GXt.forEach(t),pfr=r(wze," (XLM-RoBERTa model)"),wze.forEach(t),_fr=i(ee),CM=n(ee,"LI",{});var Aze=s(CM);nEe=n(Aze,"STRONG",{});var OXt=s(nEe);bfr=r(OXt,"xlm-roberta-xl"),OXt.forEach(t),vfr=r(Aze," \u2014 "),kJ=n(Aze,"A",{href:!0});var VXt=s(kJ);Ffr=r(VXt,"XLMRobertaXLForMultipleChoice"),VXt.forEach(t),Tfr=r(Aze," (XLM-RoBERTa-XL model)"),Aze.forEach(t),Mfr=i(ee),wM=n(ee,"LI",{});var Lze=s(wM);sEe=n(Lze,"STRONG",{});var XXt=s(sEe);Efr=r(XXt,"xlnet"),XXt.forEach(t),Cfr=r(Lze," \u2014 "),SJ=n(Lze,"A",{href:!0});var zXt=s(SJ);wfr=r(zXt,"XLNetForMultipleChoice"),zXt.forEach(t),Afr=r(Lze," (XLNet model)"),Lze.forEach(t),Lfr=i(ee),AM=n(ee,"LI",{});var yze=s(AM);lEe=n(yze,"STRONG",{});var QXt=s(lEe);yfr=r(QXt,"yoso"),QXt.forEach(t),xfr=r(yze," \u2014 "),RJ=n(yze,"A",{href:!0});var WXt=s(RJ);$fr=r(WXt,"YosoForMultipleChoice"),WXt.forEach(t),kfr=r(yze," (YOSO model)"),yze.forEach(t),ee.forEach(t),Sfr=i(xa),LM=n(xa,"P",{});var xze=s(LM);Rfr=r(xze,"The model is set in evaluation mode by default using "),iEe=n(xze,"CODE",{});var UXt=s(iEe);Pfr=r(UXt,"model.eval()"),UXt.forEach(t),Bfr=r(xze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dEe=n(xze,"CODE",{});var HXt=s(dEe);Ifr=r(HXt,"model.train()"),HXt.forEach(t),xze.forEach(t),Nfr=i(xa),T(yM.$$.fragment,xa),xa.forEach(t),Nl.forEach(t),Boo=i(m),Xd=n(m,"H2",{class:!0});var Yto=s(Xd);xM=n(Yto,"A",{id:!0,class:!0,href:!0});var JXt=s(xM);cEe=n(JXt,"SPAN",{});var YXt=s(cEe);T(R$.$$.fragment,YXt),YXt.forEach(t),JXt.forEach(t),qfr=i(Yto),mEe=n(Yto,"SPAN",{});var ZXt=s(mEe);jfr=r(ZXt,"AutoModelForNextSentencePrediction"),ZXt.forEach(t),Yto.forEach(t),Ioo=i(m),Oo=n(m,"DIV",{class:!0});var ql=s(Oo);T(P$.$$.fragment,ql),Dfr=i(ql),zd=n(ql,"P",{});var ede=s(zd);Gfr=r(ede,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),PJ=n(ede,"A",{href:!0});var KXt=s(PJ);Ofr=r(KXt,"from_pretrained()"),KXt.forEach(t),Vfr=r(ede," class method or the "),BJ=n(ede,"A",{href:!0});var ezt=s(BJ);Xfr=r(ezt,"from_config()"),ezt.forEach(t),zfr=r(ede,` class
method.`),ede.forEach(t),Qfr=i(ql),B$=n(ql,"P",{});var Zto=s(B$);Wfr=r(Zto,"This class cannot be instantiated directly using "),fEe=n(Zto,"CODE",{});var ozt=s(fEe);Ufr=r(ozt,"__init__()"),ozt.forEach(t),Hfr=r(Zto," (throws an error)."),Zto.forEach(t),Jfr=i(ql),At=n(ql,"DIV",{class:!0});var S8=s(At);T(I$.$$.fragment,S8),Yfr=i(S8),gEe=n(S8,"P",{});var rzt=s(gEe);Zfr=r(rzt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),rzt.forEach(t),Kfr=i(S8),Qd=n(S8,"P",{});var ode=s(Qd);egr=r(ode,`Note:
Loading a model from its configuration file does `),hEe=n(ode,"STRONG",{});var tzt=s(hEe);ogr=r(tzt,"not"),tzt.forEach(t),rgr=r(ode,` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=n(ode,"A",{href:!0});var azt=s(IJ);tgr=r(azt,"from_pretrained()"),azt.forEach(t),agr=r(ode," to load the model weights."),ode.forEach(t),ngr=i(S8),T($M.$$.fragment,S8),S8.forEach(t),sgr=i(ql),so=n(ql,"DIV",{class:!0});var $a=s(so);T(N$.$$.fragment,$a),lgr=i($a),uEe=n($a,"P",{});var nzt=s(uEe);igr=r(nzt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),nzt.forEach(t),dgr=i($a),ln=n($a,"P",{});var R8=s(ln);cgr=r(R8,"The model class to instantiate is selected based on the "),pEe=n(R8,"CODE",{});var szt=s(pEe);mgr=r(szt,"model_type"),szt.forEach(t),fgr=r(R8,` property of the config object (either
passed as an argument or loaded from `),_Ee=n(R8,"CODE",{});var lzt=s(_Ee);ggr=r(lzt,"pretrained_model_name_or_path"),lzt.forEach(t),hgr=r(R8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bEe=n(R8,"CODE",{});var izt=s(bEe);ugr=r(izt,"pretrained_model_name_or_path"),izt.forEach(t),pgr=r(R8,":"),R8.forEach(t),_gr=i($a),Ue=n($a,"UL",{});var ft=s(Ue);kM=n(ft,"LI",{});var $ze=s(kM);vEe=n($ze,"STRONG",{});var dzt=s(vEe);bgr=r(dzt,"bert"),dzt.forEach(t),vgr=r($ze," \u2014 "),NJ=n($ze,"A",{href:!0});var czt=s(NJ);Fgr=r(czt,"BertForNextSentencePrediction"),czt.forEach(t),Tgr=r($ze," (BERT model)"),$ze.forEach(t),Mgr=i(ft),SM=n(ft,"LI",{});var kze=s(SM);FEe=n(kze,"STRONG",{});var mzt=s(FEe);Egr=r(mzt,"ernie"),mzt.forEach(t),Cgr=r(kze," \u2014 "),qJ=n(kze,"A",{href:!0});var fzt=s(qJ);wgr=r(fzt,"ErnieForNextSentencePrediction"),fzt.forEach(t),Agr=r(kze," (ERNIE model)"),kze.forEach(t),Lgr=i(ft),RM=n(ft,"LI",{});var Sze=s(RM);TEe=n(Sze,"STRONG",{});var gzt=s(TEe);ygr=r(gzt,"fnet"),gzt.forEach(t),xgr=r(Sze," \u2014 "),jJ=n(Sze,"A",{href:!0});var hzt=s(jJ);$gr=r(hzt,"FNetForNextSentencePrediction"),hzt.forEach(t),kgr=r(Sze," (FNet model)"),Sze.forEach(t),Sgr=i(ft),PM=n(ft,"LI",{});var Rze=s(PM);MEe=n(Rze,"STRONG",{});var uzt=s(MEe);Rgr=r(uzt,"megatron-bert"),uzt.forEach(t),Pgr=r(Rze," \u2014 "),DJ=n(Rze,"A",{href:!0});var pzt=s(DJ);Bgr=r(pzt,"MegatronBertForNextSentencePrediction"),pzt.forEach(t),Igr=r(Rze," (Megatron-BERT model)"),Rze.forEach(t),Ngr=i(ft),BM=n(ft,"LI",{});var Pze=s(BM);EEe=n(Pze,"STRONG",{});var _zt=s(EEe);qgr=r(_zt,"mobilebert"),_zt.forEach(t),jgr=r(Pze," \u2014 "),GJ=n(Pze,"A",{href:!0});var bzt=s(GJ);Dgr=r(bzt,"MobileBertForNextSentencePrediction"),bzt.forEach(t),Ggr=r(Pze," (MobileBERT model)"),Pze.forEach(t),Ogr=i(ft),IM=n(ft,"LI",{});var Bze=s(IM);CEe=n(Bze,"STRONG",{});var vzt=s(CEe);Vgr=r(vzt,"nezha"),vzt.forEach(t),Xgr=r(Bze," \u2014 "),OJ=n(Bze,"A",{href:!0});var Fzt=s(OJ);zgr=r(Fzt,"NezhaForNextSentencePrediction"),Fzt.forEach(t),Qgr=r(Bze," (Nezha model)"),Bze.forEach(t),Wgr=i(ft),NM=n(ft,"LI",{});var Ize=s(NM);wEe=n(Ize,"STRONG",{});var Tzt=s(wEe);Ugr=r(Tzt,"qdqbert"),Tzt.forEach(t),Hgr=r(Ize," \u2014 "),VJ=n(Ize,"A",{href:!0});var Mzt=s(VJ);Jgr=r(Mzt,"QDQBertForNextSentencePrediction"),Mzt.forEach(t),Ygr=r(Ize," (QDQBert model)"),Ize.forEach(t),ft.forEach(t),Zgr=i($a),qM=n($a,"P",{});var Nze=s(qM);Kgr=r(Nze,"The model is set in evaluation mode by default using "),AEe=n(Nze,"CODE",{});var Ezt=s(AEe);ehr=r(Ezt,"model.eval()"),Ezt.forEach(t),ohr=r(Nze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=n(Nze,"CODE",{});var Czt=s(LEe);rhr=r(Czt,"model.train()"),Czt.forEach(t),Nze.forEach(t),thr=i($a),T(jM.$$.fragment,$a),$a.forEach(t),ql.forEach(t),Noo=i(m),Wd=n(m,"H2",{class:!0});var Kto=s(Wd);DM=n(Kto,"A",{id:!0,class:!0,href:!0});var wzt=s(DM);yEe=n(wzt,"SPAN",{});var Azt=s(yEe);T(q$.$$.fragment,Azt),Azt.forEach(t),wzt.forEach(t),ahr=i(Kto),xEe=n(Kto,"SPAN",{});var Lzt=s(xEe);nhr=r(Lzt,"AutoModelForTokenClassification"),Lzt.forEach(t),Kto.forEach(t),qoo=i(m),Vo=n(m,"DIV",{class:!0});var jl=s(Vo);T(j$.$$.fragment,jl),shr=i(jl),Ud=n(jl,"P",{});var rde=s(Ud);lhr=r(rde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),XJ=n(rde,"A",{href:!0});var yzt=s(XJ);ihr=r(yzt,"from_pretrained()"),yzt.forEach(t),dhr=r(rde," class method or the "),zJ=n(rde,"A",{href:!0});var xzt=s(zJ);chr=r(xzt,"from_config()"),xzt.forEach(t),mhr=r(rde,` class
method.`),rde.forEach(t),fhr=i(jl),D$=n(jl,"P",{});var eao=s(D$);ghr=r(eao,"This class cannot be instantiated directly using "),$Ee=n(eao,"CODE",{});var $zt=s($Ee);hhr=r($zt,"__init__()"),$zt.forEach(t),uhr=r(eao," (throws an error)."),eao.forEach(t),phr=i(jl),Lt=n(jl,"DIV",{class:!0});var P8=s(Lt);T(G$.$$.fragment,P8),_hr=i(P8),kEe=n(P8,"P",{});var kzt=s(kEe);bhr=r(kzt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),kzt.forEach(t),vhr=i(P8),Hd=n(P8,"P",{});var tde=s(Hd);Fhr=r(tde,`Note:
Loading a model from its configuration file does `),SEe=n(tde,"STRONG",{});var Szt=s(SEe);Thr=r(Szt,"not"),Szt.forEach(t),Mhr=r(tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(tde,"A",{href:!0});var Rzt=s(QJ);Ehr=r(Rzt,"from_pretrained()"),Rzt.forEach(t),Chr=r(tde," to load the model weights."),tde.forEach(t),whr=i(P8),T(GM.$$.fragment,P8),P8.forEach(t),Ahr=i(jl),lo=n(jl,"DIV",{class:!0});var ka=s(lo);T(O$.$$.fragment,ka),Lhr=i(ka),REe=n(ka,"P",{});var Pzt=s(REe);yhr=r(Pzt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Pzt.forEach(t),xhr=i(ka),dn=n(ka,"P",{});var B8=s(dn);$hr=r(B8,"The model class to instantiate is selected based on the "),PEe=n(B8,"CODE",{});var Bzt=s(PEe);khr=r(Bzt,"model_type"),Bzt.forEach(t),Shr=r(B8,` property of the config object (either
passed as an argument or loaded from `),BEe=n(B8,"CODE",{});var Izt=s(BEe);Rhr=r(Izt,"pretrained_model_name_or_path"),Izt.forEach(t),Phr=r(B8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=n(B8,"CODE",{});var Nzt=s(IEe);Bhr=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),Ihr=r(B8,":"),B8.forEach(t),Nhr=i(ka),H=n(ka,"UL",{});var Y=s(H);OM=n(Y,"LI",{});var qze=s(OM);NEe=n(qze,"STRONG",{});var qzt=s(NEe);qhr=r(qzt,"albert"),qzt.forEach(t),jhr=r(qze," \u2014 "),WJ=n(qze,"A",{href:!0});var jzt=s(WJ);Dhr=r(jzt,"AlbertForTokenClassification"),jzt.forEach(t),Ghr=r(qze," (ALBERT model)"),qze.forEach(t),Ohr=i(Y),VM=n(Y,"LI",{});var jze=s(VM);qEe=n(jze,"STRONG",{});var Dzt=s(qEe);Vhr=r(Dzt,"bert"),Dzt.forEach(t),Xhr=r(jze," \u2014 "),UJ=n(jze,"A",{href:!0});var Gzt=s(UJ);zhr=r(Gzt,"BertForTokenClassification"),Gzt.forEach(t),Qhr=r(jze," (BERT model)"),jze.forEach(t),Whr=i(Y),XM=n(Y,"LI",{});var Dze=s(XM);jEe=n(Dze,"STRONG",{});var Ozt=s(jEe);Uhr=r(Ozt,"big_bird"),Ozt.forEach(t),Hhr=r(Dze," \u2014 "),HJ=n(Dze,"A",{href:!0});var Vzt=s(HJ);Jhr=r(Vzt,"BigBirdForTokenClassification"),Vzt.forEach(t),Yhr=r(Dze," (BigBird model)"),Dze.forEach(t),Zhr=i(Y),zM=n(Y,"LI",{});var Gze=s(zM);DEe=n(Gze,"STRONG",{});var Xzt=s(DEe);Khr=r(Xzt,"bloom"),Xzt.forEach(t),eur=r(Gze," \u2014 "),JJ=n(Gze,"A",{href:!0});var zzt=s(JJ);our=r(zzt,"BloomForTokenClassification"),zzt.forEach(t),rur=r(Gze," (BLOOM model)"),Gze.forEach(t),tur=i(Y),QM=n(Y,"LI",{});var Oze=s(QM);GEe=n(Oze,"STRONG",{});var Qzt=s(GEe);aur=r(Qzt,"camembert"),Qzt.forEach(t),nur=r(Oze," \u2014 "),YJ=n(Oze,"A",{href:!0});var Wzt=s(YJ);sur=r(Wzt,"CamembertForTokenClassification"),Wzt.forEach(t),lur=r(Oze," (CamemBERT model)"),Oze.forEach(t),iur=i(Y),WM=n(Y,"LI",{});var Vze=s(WM);OEe=n(Vze,"STRONG",{});var Uzt=s(OEe);dur=r(Uzt,"canine"),Uzt.forEach(t),cur=r(Vze," \u2014 "),ZJ=n(Vze,"A",{href:!0});var Hzt=s(ZJ);mur=r(Hzt,"CanineForTokenClassification"),Hzt.forEach(t),fur=r(Vze," (CANINE model)"),Vze.forEach(t),gur=i(Y),UM=n(Y,"LI",{});var Xze=s(UM);VEe=n(Xze,"STRONG",{});var Jzt=s(VEe);hur=r(Jzt,"convbert"),Jzt.forEach(t),uur=r(Xze," \u2014 "),KJ=n(Xze,"A",{href:!0});var Yzt=s(KJ);pur=r(Yzt,"ConvBertForTokenClassification"),Yzt.forEach(t),_ur=r(Xze," (ConvBERT model)"),Xze.forEach(t),bur=i(Y),HM=n(Y,"LI",{});var zze=s(HM);XEe=n(zze,"STRONG",{});var Zzt=s(XEe);vur=r(Zzt,"data2vec-text"),Zzt.forEach(t),Fur=r(zze," \u2014 "),eY=n(zze,"A",{href:!0});var Kzt=s(eY);Tur=r(Kzt,"Data2VecTextForTokenClassification"),Kzt.forEach(t),Mur=r(zze," (Data2VecText model)"),zze.forEach(t),Eur=i(Y),JM=n(Y,"LI",{});var Qze=s(JM);zEe=n(Qze,"STRONG",{});var eQt=s(zEe);Cur=r(eQt,"deberta"),eQt.forEach(t),wur=r(Qze," \u2014 "),oY=n(Qze,"A",{href:!0});var oQt=s(oY);Aur=r(oQt,"DebertaForTokenClassification"),oQt.forEach(t),Lur=r(Qze," (DeBERTa model)"),Qze.forEach(t),yur=i(Y),YM=n(Y,"LI",{});var Wze=s(YM);QEe=n(Wze,"STRONG",{});var rQt=s(QEe);xur=r(rQt,"deberta-v2"),rQt.forEach(t),$ur=r(Wze," \u2014 "),rY=n(Wze,"A",{href:!0});var tQt=s(rY);kur=r(tQt,"DebertaV2ForTokenClassification"),tQt.forEach(t),Sur=r(Wze," (DeBERTa-v2 model)"),Wze.forEach(t),Rur=i(Y),ZM=n(Y,"LI",{});var Uze=s(ZM);WEe=n(Uze,"STRONG",{});var aQt=s(WEe);Pur=r(aQt,"distilbert"),aQt.forEach(t),Bur=r(Uze," \u2014 "),tY=n(Uze,"A",{href:!0});var nQt=s(tY);Iur=r(nQt,"DistilBertForTokenClassification"),nQt.forEach(t),Nur=r(Uze," (DistilBERT model)"),Uze.forEach(t),qur=i(Y),KM=n(Y,"LI",{});var Hze=s(KM);UEe=n(Hze,"STRONG",{});var sQt=s(UEe);jur=r(sQt,"electra"),sQt.forEach(t),Dur=r(Hze," \u2014 "),aY=n(Hze,"A",{href:!0});var lQt=s(aY);Gur=r(lQt,"ElectraForTokenClassification"),lQt.forEach(t),Our=r(Hze," (ELECTRA model)"),Hze.forEach(t),Vur=i(Y),eE=n(Y,"LI",{});var Jze=s(eE);HEe=n(Jze,"STRONG",{});var iQt=s(HEe);Xur=r(iQt,"ernie"),iQt.forEach(t),zur=r(Jze," \u2014 "),nY=n(Jze,"A",{href:!0});var dQt=s(nY);Qur=r(dQt,"ErnieForTokenClassification"),dQt.forEach(t),Wur=r(Jze," (ERNIE model)"),Jze.forEach(t),Uur=i(Y),oE=n(Y,"LI",{});var Yze=s(oE);JEe=n(Yze,"STRONG",{});var cQt=s(JEe);Hur=r(cQt,"esm"),cQt.forEach(t),Jur=r(Yze," \u2014 "),sY=n(Yze,"A",{href:!0});var mQt=s(sY);Yur=r(mQt,"EsmForTokenClassification"),mQt.forEach(t),Zur=r(Yze," (ESM model)"),Yze.forEach(t),Kur=i(Y),rE=n(Y,"LI",{});var Zze=s(rE);YEe=n(Zze,"STRONG",{});var fQt=s(YEe);epr=r(fQt,"flaubert"),fQt.forEach(t),opr=r(Zze," \u2014 "),lY=n(Zze,"A",{href:!0});var gQt=s(lY);rpr=r(gQt,"FlaubertForTokenClassification"),gQt.forEach(t),tpr=r(Zze," (FlauBERT model)"),Zze.forEach(t),apr=i(Y),tE=n(Y,"LI",{});var Kze=s(tE);ZEe=n(Kze,"STRONG",{});var hQt=s(ZEe);npr=r(hQt,"fnet"),hQt.forEach(t),spr=r(Kze," \u2014 "),iY=n(Kze,"A",{href:!0});var uQt=s(iY);lpr=r(uQt,"FNetForTokenClassification"),uQt.forEach(t),ipr=r(Kze," (FNet model)"),Kze.forEach(t),dpr=i(Y),aE=n(Y,"LI",{});var eQe=s(aE);KEe=n(eQe,"STRONG",{});var pQt=s(KEe);cpr=r(pQt,"funnel"),pQt.forEach(t),mpr=r(eQe," \u2014 "),dY=n(eQe,"A",{href:!0});var _Qt=s(dY);fpr=r(_Qt,"FunnelForTokenClassification"),_Qt.forEach(t),gpr=r(eQe," (Funnel Transformer model)"),eQe.forEach(t),hpr=i(Y),nE=n(Y,"LI",{});var oQe=s(nE);e4e=n(oQe,"STRONG",{});var bQt=s(e4e);upr=r(bQt,"gpt2"),bQt.forEach(t),ppr=r(oQe," \u2014 "),cY=n(oQe,"A",{href:!0});var vQt=s(cY);_pr=r(vQt,"GPT2ForTokenClassification"),vQt.forEach(t),bpr=r(oQe," (OpenAI GPT-2 model)"),oQe.forEach(t),vpr=i(Y),sE=n(Y,"LI",{});var rQe=s(sE);o4e=n(rQe,"STRONG",{});var FQt=s(o4e);Fpr=r(FQt,"ibert"),FQt.forEach(t),Tpr=r(rQe," \u2014 "),mY=n(rQe,"A",{href:!0});var TQt=s(mY);Mpr=r(TQt,"IBertForTokenClassification"),TQt.forEach(t),Epr=r(rQe," (I-BERT model)"),rQe.forEach(t),Cpr=i(Y),lE=n(Y,"LI",{});var tQe=s(lE);r4e=n(tQe,"STRONG",{});var MQt=s(r4e);wpr=r(MQt,"layoutlm"),MQt.forEach(t),Apr=r(tQe," \u2014 "),fY=n(tQe,"A",{href:!0});var EQt=s(fY);Lpr=r(EQt,"LayoutLMForTokenClassification"),EQt.forEach(t),ypr=r(tQe," (LayoutLM model)"),tQe.forEach(t),xpr=i(Y),iE=n(Y,"LI",{});var aQe=s(iE);t4e=n(aQe,"STRONG",{});var CQt=s(t4e);$pr=r(CQt,"layoutlmv2"),CQt.forEach(t),kpr=r(aQe," \u2014 "),gY=n(aQe,"A",{href:!0});var wQt=s(gY);Spr=r(wQt,"LayoutLMv2ForTokenClassification"),wQt.forEach(t),Rpr=r(aQe," (LayoutLMv2 model)"),aQe.forEach(t),Ppr=i(Y),dE=n(Y,"LI",{});var nQe=s(dE);a4e=n(nQe,"STRONG",{});var AQt=s(a4e);Bpr=r(AQt,"layoutlmv3"),AQt.forEach(t),Ipr=r(nQe," \u2014 "),hY=n(nQe,"A",{href:!0});var LQt=s(hY);Npr=r(LQt,"LayoutLMv3ForTokenClassification"),LQt.forEach(t),qpr=r(nQe," (LayoutLMv3 model)"),nQe.forEach(t),jpr=i(Y),cE=n(Y,"LI",{});var sQe=s(cE);n4e=n(sQe,"STRONG",{});var yQt=s(n4e);Dpr=r(yQt,"longformer"),yQt.forEach(t),Gpr=r(sQe," \u2014 "),uY=n(sQe,"A",{href:!0});var xQt=s(uY);Opr=r(xQt,"LongformerForTokenClassification"),xQt.forEach(t),Vpr=r(sQe," (Longformer model)"),sQe.forEach(t),Xpr=i(Y),mE=n(Y,"LI",{});var lQe=s(mE);s4e=n(lQe,"STRONG",{});var $Qt=s(s4e);zpr=r($Qt,"luke"),$Qt.forEach(t),Qpr=r(lQe," \u2014 "),pY=n(lQe,"A",{href:!0});var kQt=s(pY);Wpr=r(kQt,"LukeForTokenClassification"),kQt.forEach(t),Upr=r(lQe," (LUKE model)"),lQe.forEach(t),Hpr=i(Y),fE=n(Y,"LI",{});var iQe=s(fE);l4e=n(iQe,"STRONG",{});var SQt=s(l4e);Jpr=r(SQt,"markuplm"),SQt.forEach(t),Ypr=r(iQe," \u2014 "),_Y=n(iQe,"A",{href:!0});var RQt=s(_Y);Zpr=r(RQt,"MarkupLMForTokenClassification"),RQt.forEach(t),Kpr=r(iQe," (MarkupLM model)"),iQe.forEach(t),e_r=i(Y),gE=n(Y,"LI",{});var dQe=s(gE);i4e=n(dQe,"STRONG",{});var PQt=s(i4e);o_r=r(PQt,"megatron-bert"),PQt.forEach(t),r_r=r(dQe," \u2014 "),bY=n(dQe,"A",{href:!0});var BQt=s(bY);t_r=r(BQt,"MegatronBertForTokenClassification"),BQt.forEach(t),a_r=r(dQe," (Megatron-BERT model)"),dQe.forEach(t),n_r=i(Y),hE=n(Y,"LI",{});var cQe=s(hE);d4e=n(cQe,"STRONG",{});var IQt=s(d4e);s_r=r(IQt,"mobilebert"),IQt.forEach(t),l_r=r(cQe," \u2014 "),vY=n(cQe,"A",{href:!0});var NQt=s(vY);i_r=r(NQt,"MobileBertForTokenClassification"),NQt.forEach(t),d_r=r(cQe," (MobileBERT model)"),cQe.forEach(t),c_r=i(Y),uE=n(Y,"LI",{});var mQe=s(uE);c4e=n(mQe,"STRONG",{});var qQt=s(c4e);m_r=r(qQt,"mpnet"),qQt.forEach(t),f_r=r(mQe," \u2014 "),FY=n(mQe,"A",{href:!0});var jQt=s(FY);g_r=r(jQt,"MPNetForTokenClassification"),jQt.forEach(t),h_r=r(mQe," (MPNet model)"),mQe.forEach(t),u_r=i(Y),pE=n(Y,"LI",{});var fQe=s(pE);m4e=n(fQe,"STRONG",{});var DQt=s(m4e);p_r=r(DQt,"nezha"),DQt.forEach(t),__r=r(fQe," \u2014 "),TY=n(fQe,"A",{href:!0});var GQt=s(TY);b_r=r(GQt,"NezhaForTokenClassification"),GQt.forEach(t),v_r=r(fQe," (Nezha model)"),fQe.forEach(t),F_r=i(Y),_E=n(Y,"LI",{});var gQe=s(_E);f4e=n(gQe,"STRONG",{});var OQt=s(f4e);T_r=r(OQt,"nystromformer"),OQt.forEach(t),M_r=r(gQe," \u2014 "),MY=n(gQe,"A",{href:!0});var VQt=s(MY);E_r=r(VQt,"NystromformerForTokenClassification"),VQt.forEach(t),C_r=r(gQe," (Nystr\xF6mformer model)"),gQe.forEach(t),w_r=i(Y),bE=n(Y,"LI",{});var hQe=s(bE);g4e=n(hQe,"STRONG",{});var XQt=s(g4e);A_r=r(XQt,"qdqbert"),XQt.forEach(t),L_r=r(hQe," \u2014 "),EY=n(hQe,"A",{href:!0});var zQt=s(EY);y_r=r(zQt,"QDQBertForTokenClassification"),zQt.forEach(t),x_r=r(hQe," (QDQBert model)"),hQe.forEach(t),$_r=i(Y),vE=n(Y,"LI",{});var uQe=s(vE);h4e=n(uQe,"STRONG",{});var QQt=s(h4e);k_r=r(QQt,"rembert"),QQt.forEach(t),S_r=r(uQe," \u2014 "),CY=n(uQe,"A",{href:!0});var WQt=s(CY);R_r=r(WQt,"RemBertForTokenClassification"),WQt.forEach(t),P_r=r(uQe," (RemBERT model)"),uQe.forEach(t),B_r=i(Y),FE=n(Y,"LI",{});var pQe=s(FE);u4e=n(pQe,"STRONG",{});var UQt=s(u4e);I_r=r(UQt,"roberta"),UQt.forEach(t),N_r=r(pQe," \u2014 "),wY=n(pQe,"A",{href:!0});var HQt=s(wY);q_r=r(HQt,"RobertaForTokenClassification"),HQt.forEach(t),j_r=r(pQe," (RoBERTa model)"),pQe.forEach(t),D_r=i(Y),TE=n(Y,"LI",{});var _Qe=s(TE);p4e=n(_Qe,"STRONG",{});var JQt=s(p4e);G_r=r(JQt,"roformer"),JQt.forEach(t),O_r=r(_Qe," \u2014 "),AY=n(_Qe,"A",{href:!0});var YQt=s(AY);V_r=r(YQt,"RoFormerForTokenClassification"),YQt.forEach(t),X_r=r(_Qe," (RoFormer model)"),_Qe.forEach(t),z_r=i(Y),ME=n(Y,"LI",{});var bQe=s(ME);_4e=n(bQe,"STRONG",{});var ZQt=s(_4e);Q_r=r(ZQt,"squeezebert"),ZQt.forEach(t),W_r=r(bQe," \u2014 "),LY=n(bQe,"A",{href:!0});var KQt=s(LY);U_r=r(KQt,"SqueezeBertForTokenClassification"),KQt.forEach(t),H_r=r(bQe," (SqueezeBERT model)"),bQe.forEach(t),J_r=i(Y),EE=n(Y,"LI",{});var vQe=s(EE);b4e=n(vQe,"STRONG",{});var eWt=s(b4e);Y_r=r(eWt,"xlm"),eWt.forEach(t),Z_r=r(vQe," \u2014 "),yY=n(vQe,"A",{href:!0});var oWt=s(yY);K_r=r(oWt,"XLMForTokenClassification"),oWt.forEach(t),e1r=r(vQe," (XLM model)"),vQe.forEach(t),o1r=i(Y),CE=n(Y,"LI",{});var FQe=s(CE);v4e=n(FQe,"STRONG",{});var rWt=s(v4e);r1r=r(rWt,"xlm-roberta"),rWt.forEach(t),t1r=r(FQe," \u2014 "),xY=n(FQe,"A",{href:!0});var tWt=s(xY);a1r=r(tWt,"XLMRobertaForTokenClassification"),tWt.forEach(t),n1r=r(FQe," (XLM-RoBERTa model)"),FQe.forEach(t),s1r=i(Y),wE=n(Y,"LI",{});var TQe=s(wE);F4e=n(TQe,"STRONG",{});var aWt=s(F4e);l1r=r(aWt,"xlm-roberta-xl"),aWt.forEach(t),i1r=r(TQe," \u2014 "),$Y=n(TQe,"A",{href:!0});var nWt=s($Y);d1r=r(nWt,"XLMRobertaXLForTokenClassification"),nWt.forEach(t),c1r=r(TQe," (XLM-RoBERTa-XL model)"),TQe.forEach(t),m1r=i(Y),AE=n(Y,"LI",{});var MQe=s(AE);T4e=n(MQe,"STRONG",{});var sWt=s(T4e);f1r=r(sWt,"xlnet"),sWt.forEach(t),g1r=r(MQe," \u2014 "),kY=n(MQe,"A",{href:!0});var lWt=s(kY);h1r=r(lWt,"XLNetForTokenClassification"),lWt.forEach(t),u1r=r(MQe," (XLNet model)"),MQe.forEach(t),p1r=i(Y),LE=n(Y,"LI",{});var EQe=s(LE);M4e=n(EQe,"STRONG",{});var iWt=s(M4e);_1r=r(iWt,"yoso"),iWt.forEach(t),b1r=r(EQe," \u2014 "),SY=n(EQe,"A",{href:!0});var dWt=s(SY);v1r=r(dWt,"YosoForTokenClassification"),dWt.forEach(t),F1r=r(EQe," (YOSO model)"),EQe.forEach(t),Y.forEach(t),T1r=i(ka),yE=n(ka,"P",{});var CQe=s(yE);M1r=r(CQe,"The model is set in evaluation mode by default using "),E4e=n(CQe,"CODE",{});var cWt=s(E4e);E1r=r(cWt,"model.eval()"),cWt.forEach(t),C1r=r(CQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C4e=n(CQe,"CODE",{});var mWt=s(C4e);w1r=r(mWt,"model.train()"),mWt.forEach(t),CQe.forEach(t),A1r=i(ka),T(xE.$$.fragment,ka),ka.forEach(t),jl.forEach(t),joo=i(m),Jd=n(m,"H2",{class:!0});var oao=s(Jd);$E=n(oao,"A",{id:!0,class:!0,href:!0});var fWt=s($E);w4e=n(fWt,"SPAN",{});var gWt=s(w4e);T(V$.$$.fragment,gWt),gWt.forEach(t),fWt.forEach(t),L1r=i(oao),A4e=n(oao,"SPAN",{});var hWt=s(A4e);y1r=r(hWt,"AutoModelForQuestionAnswering"),hWt.forEach(t),oao.forEach(t),Doo=i(m),Xo=n(m,"DIV",{class:!0});var Dl=s(Xo);T(X$.$$.fragment,Dl),x1r=i(Dl),Yd=n(Dl,"P",{});var ade=s(Yd);$1r=r(ade,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),RY=n(ade,"A",{href:!0});var uWt=s(RY);k1r=r(uWt,"from_pretrained()"),uWt.forEach(t),S1r=r(ade," class method or the "),PY=n(ade,"A",{href:!0});var pWt=s(PY);R1r=r(pWt,"from_config()"),pWt.forEach(t),P1r=r(ade,` class
method.`),ade.forEach(t),B1r=i(Dl),z$=n(Dl,"P",{});var rao=s(z$);I1r=r(rao,"This class cannot be instantiated directly using "),L4e=n(rao,"CODE",{});var _Wt=s(L4e);N1r=r(_Wt,"__init__()"),_Wt.forEach(t),q1r=r(rao," (throws an error)."),rao.forEach(t),j1r=i(Dl),yt=n(Dl,"DIV",{class:!0});var I8=s(yt);T(Q$.$$.fragment,I8),D1r=i(I8),y4e=n(I8,"P",{});var bWt=s(y4e);G1r=r(bWt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),bWt.forEach(t),O1r=i(I8),Zd=n(I8,"P",{});var nde=s(Zd);V1r=r(nde,`Note:
Loading a model from its configuration file does `),x4e=n(nde,"STRONG",{});var vWt=s(x4e);X1r=r(vWt,"not"),vWt.forEach(t),z1r=r(nde,` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=n(nde,"A",{href:!0});var FWt=s(BY);Q1r=r(FWt,"from_pretrained()"),FWt.forEach(t),W1r=r(nde," to load the model weights."),nde.forEach(t),U1r=i(I8),T(kE.$$.fragment,I8),I8.forEach(t),H1r=i(Dl),io=n(Dl,"DIV",{class:!0});var Sa=s(io);T(W$.$$.fragment,Sa),J1r=i(Sa),$4e=n(Sa,"P",{});var TWt=s($4e);Y1r=r(TWt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),TWt.forEach(t),Z1r=i(Sa),cn=n(Sa,"P",{});var N8=s(cn);K1r=r(N8,"The model class to instantiate is selected based on the "),k4e=n(N8,"CODE",{});var MWt=s(k4e);ebr=r(MWt,"model_type"),MWt.forEach(t),obr=r(N8,` property of the config object (either
passed as an argument or loaded from `),S4e=n(N8,"CODE",{});var EWt=s(S4e);rbr=r(EWt,"pretrained_model_name_or_path"),EWt.forEach(t),tbr=r(N8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=n(N8,"CODE",{});var CWt=s(R4e);abr=r(CWt,"pretrained_model_name_or_path"),CWt.forEach(t),nbr=r(N8,":"),N8.forEach(t),sbr=i(Sa),O=n(Sa,"UL",{});var X=s(O);SE=n(X,"LI",{});var wQe=s(SE);P4e=n(wQe,"STRONG",{});var wWt=s(P4e);lbr=r(wWt,"albert"),wWt.forEach(t),ibr=r(wQe," \u2014 "),IY=n(wQe,"A",{href:!0});var AWt=s(IY);dbr=r(AWt,"AlbertForQuestionAnswering"),AWt.forEach(t),cbr=r(wQe," (ALBERT model)"),wQe.forEach(t),mbr=i(X),RE=n(X,"LI",{});var AQe=s(RE);B4e=n(AQe,"STRONG",{});var LWt=s(B4e);fbr=r(LWt,"bart"),LWt.forEach(t),gbr=r(AQe," \u2014 "),NY=n(AQe,"A",{href:!0});var yWt=s(NY);hbr=r(yWt,"BartForQuestionAnswering"),yWt.forEach(t),ubr=r(AQe," (BART model)"),AQe.forEach(t),pbr=i(X),PE=n(X,"LI",{});var LQe=s(PE);I4e=n(LQe,"STRONG",{});var xWt=s(I4e);_br=r(xWt,"bert"),xWt.forEach(t),bbr=r(LQe," \u2014 "),qY=n(LQe,"A",{href:!0});var $Wt=s(qY);vbr=r($Wt,"BertForQuestionAnswering"),$Wt.forEach(t),Fbr=r(LQe," (BERT model)"),LQe.forEach(t),Tbr=i(X),BE=n(X,"LI",{});var yQe=s(BE);N4e=n(yQe,"STRONG",{});var kWt=s(N4e);Mbr=r(kWt,"big_bird"),kWt.forEach(t),Ebr=r(yQe," \u2014 "),jY=n(yQe,"A",{href:!0});var SWt=s(jY);Cbr=r(SWt,"BigBirdForQuestionAnswering"),SWt.forEach(t),wbr=r(yQe," (BigBird model)"),yQe.forEach(t),Abr=i(X),IE=n(X,"LI",{});var xQe=s(IE);q4e=n(xQe,"STRONG",{});var RWt=s(q4e);Lbr=r(RWt,"bigbird_pegasus"),RWt.forEach(t),ybr=r(xQe," \u2014 "),DY=n(xQe,"A",{href:!0});var PWt=s(DY);xbr=r(PWt,"BigBirdPegasusForQuestionAnswering"),PWt.forEach(t),$br=r(xQe," (BigBird-Pegasus model)"),xQe.forEach(t),kbr=i(X),NE=n(X,"LI",{});var $Qe=s(NE);j4e=n($Qe,"STRONG",{});var BWt=s(j4e);Sbr=r(BWt,"bloom"),BWt.forEach(t),Rbr=r($Qe," \u2014 "),GY=n($Qe,"A",{href:!0});var IWt=s(GY);Pbr=r(IWt,"BloomForQuestionAnswering"),IWt.forEach(t),Bbr=r($Qe," (BLOOM model)"),$Qe.forEach(t),Ibr=i(X),qE=n(X,"LI",{});var kQe=s(qE);D4e=n(kQe,"STRONG",{});var NWt=s(D4e);Nbr=r(NWt,"camembert"),NWt.forEach(t),qbr=r(kQe," \u2014 "),OY=n(kQe,"A",{href:!0});var qWt=s(OY);jbr=r(qWt,"CamembertForQuestionAnswering"),qWt.forEach(t),Dbr=r(kQe," (CamemBERT model)"),kQe.forEach(t),Gbr=i(X),jE=n(X,"LI",{});var SQe=s(jE);G4e=n(SQe,"STRONG",{});var jWt=s(G4e);Obr=r(jWt,"canine"),jWt.forEach(t),Vbr=r(SQe," \u2014 "),VY=n(SQe,"A",{href:!0});var DWt=s(VY);Xbr=r(DWt,"CanineForQuestionAnswering"),DWt.forEach(t),zbr=r(SQe," (CANINE model)"),SQe.forEach(t),Qbr=i(X),DE=n(X,"LI",{});var RQe=s(DE);O4e=n(RQe,"STRONG",{});var GWt=s(O4e);Wbr=r(GWt,"convbert"),GWt.forEach(t),Ubr=r(RQe," \u2014 "),XY=n(RQe,"A",{href:!0});var OWt=s(XY);Hbr=r(OWt,"ConvBertForQuestionAnswering"),OWt.forEach(t),Jbr=r(RQe," (ConvBERT model)"),RQe.forEach(t),Ybr=i(X),GE=n(X,"LI",{});var PQe=s(GE);V4e=n(PQe,"STRONG",{});var VWt=s(V4e);Zbr=r(VWt,"data2vec-text"),VWt.forEach(t),Kbr=r(PQe," \u2014 "),zY=n(PQe,"A",{href:!0});var XWt=s(zY);e2r=r(XWt,"Data2VecTextForQuestionAnswering"),XWt.forEach(t),o2r=r(PQe," (Data2VecText model)"),PQe.forEach(t),r2r=i(X),OE=n(X,"LI",{});var BQe=s(OE);X4e=n(BQe,"STRONG",{});var zWt=s(X4e);t2r=r(zWt,"deberta"),zWt.forEach(t),a2r=r(BQe," \u2014 "),QY=n(BQe,"A",{href:!0});var QWt=s(QY);n2r=r(QWt,"DebertaForQuestionAnswering"),QWt.forEach(t),s2r=r(BQe," (DeBERTa model)"),BQe.forEach(t),l2r=i(X),VE=n(X,"LI",{});var IQe=s(VE);z4e=n(IQe,"STRONG",{});var WWt=s(z4e);i2r=r(WWt,"deberta-v2"),WWt.forEach(t),d2r=r(IQe," \u2014 "),WY=n(IQe,"A",{href:!0});var UWt=s(WY);c2r=r(UWt,"DebertaV2ForQuestionAnswering"),UWt.forEach(t),m2r=r(IQe," (DeBERTa-v2 model)"),IQe.forEach(t),f2r=i(X),XE=n(X,"LI",{});var NQe=s(XE);Q4e=n(NQe,"STRONG",{});var HWt=s(Q4e);g2r=r(HWt,"distilbert"),HWt.forEach(t),h2r=r(NQe," \u2014 "),UY=n(NQe,"A",{href:!0});var JWt=s(UY);u2r=r(JWt,"DistilBertForQuestionAnswering"),JWt.forEach(t),p2r=r(NQe," (DistilBERT model)"),NQe.forEach(t),_2r=i(X),zE=n(X,"LI",{});var qQe=s(zE);W4e=n(qQe,"STRONG",{});var YWt=s(W4e);b2r=r(YWt,"electra"),YWt.forEach(t),v2r=r(qQe," \u2014 "),HY=n(qQe,"A",{href:!0});var ZWt=s(HY);F2r=r(ZWt,"ElectraForQuestionAnswering"),ZWt.forEach(t),T2r=r(qQe," (ELECTRA model)"),qQe.forEach(t),M2r=i(X),QE=n(X,"LI",{});var jQe=s(QE);U4e=n(jQe,"STRONG",{});var KWt=s(U4e);E2r=r(KWt,"ernie"),KWt.forEach(t),C2r=r(jQe," \u2014 "),JY=n(jQe,"A",{href:!0});var eUt=s(JY);w2r=r(eUt,"ErnieForQuestionAnswering"),eUt.forEach(t),A2r=r(jQe," (ERNIE model)"),jQe.forEach(t),L2r=i(X),WE=n(X,"LI",{});var DQe=s(WE);H4e=n(DQe,"STRONG",{});var oUt=s(H4e);y2r=r(oUt,"flaubert"),oUt.forEach(t),x2r=r(DQe," \u2014 "),YY=n(DQe,"A",{href:!0});var rUt=s(YY);$2r=r(rUt,"FlaubertForQuestionAnsweringSimple"),rUt.forEach(t),k2r=r(DQe," (FlauBERT model)"),DQe.forEach(t),S2r=i(X),UE=n(X,"LI",{});var GQe=s(UE);J4e=n(GQe,"STRONG",{});var tUt=s(J4e);R2r=r(tUt,"fnet"),tUt.forEach(t),P2r=r(GQe," \u2014 "),ZY=n(GQe,"A",{href:!0});var aUt=s(ZY);B2r=r(aUt,"FNetForQuestionAnswering"),aUt.forEach(t),I2r=r(GQe," (FNet model)"),GQe.forEach(t),N2r=i(X),HE=n(X,"LI",{});var OQe=s(HE);Y4e=n(OQe,"STRONG",{});var nUt=s(Y4e);q2r=r(nUt,"funnel"),nUt.forEach(t),j2r=r(OQe," \u2014 "),KY=n(OQe,"A",{href:!0});var sUt=s(KY);D2r=r(sUt,"FunnelForQuestionAnswering"),sUt.forEach(t),G2r=r(OQe," (Funnel Transformer model)"),OQe.forEach(t),O2r=i(X),JE=n(X,"LI",{});var VQe=s(JE);Z4e=n(VQe,"STRONG",{});var lUt=s(Z4e);V2r=r(lUt,"gptj"),lUt.forEach(t),X2r=r(VQe," \u2014 "),eZ=n(VQe,"A",{href:!0});var iUt=s(eZ);z2r=r(iUt,"GPTJForQuestionAnswering"),iUt.forEach(t),Q2r=r(VQe," (GPT-J model)"),VQe.forEach(t),W2r=i(X),YE=n(X,"LI",{});var XQe=s(YE);K4e=n(XQe,"STRONG",{});var dUt=s(K4e);U2r=r(dUt,"ibert"),dUt.forEach(t),H2r=r(XQe," \u2014 "),oZ=n(XQe,"A",{href:!0});var cUt=s(oZ);J2r=r(cUt,"IBertForQuestionAnswering"),cUt.forEach(t),Y2r=r(XQe," (I-BERT model)"),XQe.forEach(t),Z2r=i(X),ZE=n(X,"LI",{});var zQe=s(ZE);eCe=n(zQe,"STRONG",{});var mUt=s(eCe);K2r=r(mUt,"layoutlmv2"),mUt.forEach(t),evr=r(zQe," \u2014 "),rZ=n(zQe,"A",{href:!0});var fUt=s(rZ);ovr=r(fUt,"LayoutLMv2ForQuestionAnswering"),fUt.forEach(t),rvr=r(zQe," (LayoutLMv2 model)"),zQe.forEach(t),tvr=i(X),KE=n(X,"LI",{});var QQe=s(KE);oCe=n(QQe,"STRONG",{});var gUt=s(oCe);avr=r(gUt,"layoutlmv3"),gUt.forEach(t),nvr=r(QQe," \u2014 "),tZ=n(QQe,"A",{href:!0});var hUt=s(tZ);svr=r(hUt,"LayoutLMv3ForQuestionAnswering"),hUt.forEach(t),lvr=r(QQe," (LayoutLMv3 model)"),QQe.forEach(t),ivr=i(X),e4=n(X,"LI",{});var WQe=s(e4);rCe=n(WQe,"STRONG",{});var uUt=s(rCe);dvr=r(uUt,"led"),uUt.forEach(t),cvr=r(WQe," \u2014 "),aZ=n(WQe,"A",{href:!0});var pUt=s(aZ);mvr=r(pUt,"LEDForQuestionAnswering"),pUt.forEach(t),fvr=r(WQe," (LED model)"),WQe.forEach(t),gvr=i(X),o4=n(X,"LI",{});var UQe=s(o4);tCe=n(UQe,"STRONG",{});var _Ut=s(tCe);hvr=r(_Ut,"longformer"),_Ut.forEach(t),uvr=r(UQe," \u2014 "),nZ=n(UQe,"A",{href:!0});var bUt=s(nZ);pvr=r(bUt,"LongformerForQuestionAnswering"),bUt.forEach(t),_vr=r(UQe," (Longformer model)"),UQe.forEach(t),bvr=i(X),r4=n(X,"LI",{});var HQe=s(r4);aCe=n(HQe,"STRONG",{});var vUt=s(aCe);vvr=r(vUt,"luke"),vUt.forEach(t),Fvr=r(HQe," \u2014 "),sZ=n(HQe,"A",{href:!0});var FUt=s(sZ);Tvr=r(FUt,"LukeForQuestionAnswering"),FUt.forEach(t),Mvr=r(HQe," (LUKE model)"),HQe.forEach(t),Evr=i(X),t4=n(X,"LI",{});var JQe=s(t4);nCe=n(JQe,"STRONG",{});var TUt=s(nCe);Cvr=r(TUt,"lxmert"),TUt.forEach(t),wvr=r(JQe," \u2014 "),lZ=n(JQe,"A",{href:!0});var MUt=s(lZ);Avr=r(MUt,"LxmertForQuestionAnswering"),MUt.forEach(t),Lvr=r(JQe," (LXMERT model)"),JQe.forEach(t),yvr=i(X),a4=n(X,"LI",{});var YQe=s(a4);sCe=n(YQe,"STRONG",{});var EUt=s(sCe);xvr=r(EUt,"markuplm"),EUt.forEach(t),$vr=r(YQe," \u2014 "),iZ=n(YQe,"A",{href:!0});var CUt=s(iZ);kvr=r(CUt,"MarkupLMForQuestionAnswering"),CUt.forEach(t),Svr=r(YQe," (MarkupLM model)"),YQe.forEach(t),Rvr=i(X),n4=n(X,"LI",{});var ZQe=s(n4);lCe=n(ZQe,"STRONG",{});var wUt=s(lCe);Pvr=r(wUt,"mbart"),wUt.forEach(t),Bvr=r(ZQe," \u2014 "),dZ=n(ZQe,"A",{href:!0});var AUt=s(dZ);Ivr=r(AUt,"MBartForQuestionAnswering"),AUt.forEach(t),Nvr=r(ZQe," (mBART model)"),ZQe.forEach(t),qvr=i(X),s4=n(X,"LI",{});var KQe=s(s4);iCe=n(KQe,"STRONG",{});var LUt=s(iCe);jvr=r(LUt,"megatron-bert"),LUt.forEach(t),Dvr=r(KQe," \u2014 "),cZ=n(KQe,"A",{href:!0});var yUt=s(cZ);Gvr=r(yUt,"MegatronBertForQuestionAnswering"),yUt.forEach(t),Ovr=r(KQe," (Megatron-BERT model)"),KQe.forEach(t),Vvr=i(X),l4=n(X,"LI",{});var eWe=s(l4);dCe=n(eWe,"STRONG",{});var xUt=s(dCe);Xvr=r(xUt,"mobilebert"),xUt.forEach(t),zvr=r(eWe," \u2014 "),mZ=n(eWe,"A",{href:!0});var $Ut=s(mZ);Qvr=r($Ut,"MobileBertForQuestionAnswering"),$Ut.forEach(t),Wvr=r(eWe," (MobileBERT model)"),eWe.forEach(t),Uvr=i(X),i4=n(X,"LI",{});var oWe=s(i4);cCe=n(oWe,"STRONG",{});var kUt=s(cCe);Hvr=r(kUt,"mpnet"),kUt.forEach(t),Jvr=r(oWe," \u2014 "),fZ=n(oWe,"A",{href:!0});var SUt=s(fZ);Yvr=r(SUt,"MPNetForQuestionAnswering"),SUt.forEach(t),Zvr=r(oWe," (MPNet model)"),oWe.forEach(t),Kvr=i(X),d4=n(X,"LI",{});var rWe=s(d4);mCe=n(rWe,"STRONG",{});var RUt=s(mCe);eFr=r(RUt,"mvp"),RUt.forEach(t),oFr=r(rWe," \u2014 "),gZ=n(rWe,"A",{href:!0});var PUt=s(gZ);rFr=r(PUt,"MvpForQuestionAnswering"),PUt.forEach(t),tFr=r(rWe," (MVP model)"),rWe.forEach(t),aFr=i(X),c4=n(X,"LI",{});var tWe=s(c4);fCe=n(tWe,"STRONG",{});var BUt=s(fCe);nFr=r(BUt,"nezha"),BUt.forEach(t),sFr=r(tWe," \u2014 "),hZ=n(tWe,"A",{href:!0});var IUt=s(hZ);lFr=r(IUt,"NezhaForQuestionAnswering"),IUt.forEach(t),iFr=r(tWe," (Nezha model)"),tWe.forEach(t),dFr=i(X),m4=n(X,"LI",{});var aWe=s(m4);gCe=n(aWe,"STRONG",{});var NUt=s(gCe);cFr=r(NUt,"nystromformer"),NUt.forEach(t),mFr=r(aWe," \u2014 "),uZ=n(aWe,"A",{href:!0});var qUt=s(uZ);fFr=r(qUt,"NystromformerForQuestionAnswering"),qUt.forEach(t),gFr=r(aWe," (Nystr\xF6mformer model)"),aWe.forEach(t),hFr=i(X),f4=n(X,"LI",{});var nWe=s(f4);hCe=n(nWe,"STRONG",{});var jUt=s(hCe);uFr=r(jUt,"opt"),jUt.forEach(t),pFr=r(nWe," \u2014 "),pZ=n(nWe,"A",{href:!0});var DUt=s(pZ);_Fr=r(DUt,"OPTForQuestionAnswering"),DUt.forEach(t),bFr=r(nWe," (OPT model)"),nWe.forEach(t),vFr=i(X),g4=n(X,"LI",{});var sWe=s(g4);uCe=n(sWe,"STRONG",{});var GUt=s(uCe);FFr=r(GUt,"qdqbert"),GUt.forEach(t),TFr=r(sWe," \u2014 "),_Z=n(sWe,"A",{href:!0});var OUt=s(_Z);MFr=r(OUt,"QDQBertForQuestionAnswering"),OUt.forEach(t),EFr=r(sWe," (QDQBert model)"),sWe.forEach(t),CFr=i(X),h4=n(X,"LI",{});var lWe=s(h4);pCe=n(lWe,"STRONG",{});var VUt=s(pCe);wFr=r(VUt,"reformer"),VUt.forEach(t),AFr=r(lWe," \u2014 "),bZ=n(lWe,"A",{href:!0});var XUt=s(bZ);LFr=r(XUt,"ReformerForQuestionAnswering"),XUt.forEach(t),yFr=r(lWe," (Reformer model)"),lWe.forEach(t),xFr=i(X),u4=n(X,"LI",{});var iWe=s(u4);_Ce=n(iWe,"STRONG",{});var zUt=s(_Ce);$Fr=r(zUt,"rembert"),zUt.forEach(t),kFr=r(iWe," \u2014 "),vZ=n(iWe,"A",{href:!0});var QUt=s(vZ);SFr=r(QUt,"RemBertForQuestionAnswering"),QUt.forEach(t),RFr=r(iWe," (RemBERT model)"),iWe.forEach(t),PFr=i(X),p4=n(X,"LI",{});var dWe=s(p4);bCe=n(dWe,"STRONG",{});var WUt=s(bCe);BFr=r(WUt,"roberta"),WUt.forEach(t),IFr=r(dWe," \u2014 "),FZ=n(dWe,"A",{href:!0});var UUt=s(FZ);NFr=r(UUt,"RobertaForQuestionAnswering"),UUt.forEach(t),qFr=r(dWe," (RoBERTa model)"),dWe.forEach(t),jFr=i(X),_4=n(X,"LI",{});var cWe=s(_4);vCe=n(cWe,"STRONG",{});var HUt=s(vCe);DFr=r(HUt,"roformer"),HUt.forEach(t),GFr=r(cWe," \u2014 "),TZ=n(cWe,"A",{href:!0});var JUt=s(TZ);OFr=r(JUt,"RoFormerForQuestionAnswering"),JUt.forEach(t),VFr=r(cWe," (RoFormer model)"),cWe.forEach(t),XFr=i(X),b4=n(X,"LI",{});var mWe=s(b4);FCe=n(mWe,"STRONG",{});var YUt=s(FCe);zFr=r(YUt,"splinter"),YUt.forEach(t),QFr=r(mWe," \u2014 "),MZ=n(mWe,"A",{href:!0});var ZUt=s(MZ);WFr=r(ZUt,"SplinterForQuestionAnswering"),ZUt.forEach(t),UFr=r(mWe," (Splinter model)"),mWe.forEach(t),HFr=i(X),v4=n(X,"LI",{});var fWe=s(v4);TCe=n(fWe,"STRONG",{});var KUt=s(TCe);JFr=r(KUt,"squeezebert"),KUt.forEach(t),YFr=r(fWe," \u2014 "),EZ=n(fWe,"A",{href:!0});var eHt=s(EZ);ZFr=r(eHt,"SqueezeBertForQuestionAnswering"),eHt.forEach(t),KFr=r(fWe," (SqueezeBERT model)"),fWe.forEach(t),eTr=i(X),F4=n(X,"LI",{});var gWe=s(F4);MCe=n(gWe,"STRONG",{});var oHt=s(MCe);oTr=r(oHt,"xlm"),oHt.forEach(t),rTr=r(gWe," \u2014 "),CZ=n(gWe,"A",{href:!0});var rHt=s(CZ);tTr=r(rHt,"XLMForQuestionAnsweringSimple"),rHt.forEach(t),aTr=r(gWe," (XLM model)"),gWe.forEach(t),nTr=i(X),T4=n(X,"LI",{});var hWe=s(T4);ECe=n(hWe,"STRONG",{});var tHt=s(ECe);sTr=r(tHt,"xlm-roberta"),tHt.forEach(t),lTr=r(hWe," \u2014 "),wZ=n(hWe,"A",{href:!0});var aHt=s(wZ);iTr=r(aHt,"XLMRobertaForQuestionAnswering"),aHt.forEach(t),dTr=r(hWe," (XLM-RoBERTa model)"),hWe.forEach(t),cTr=i(X),M4=n(X,"LI",{});var uWe=s(M4);CCe=n(uWe,"STRONG",{});var nHt=s(CCe);mTr=r(nHt,"xlm-roberta-xl"),nHt.forEach(t),fTr=r(uWe," \u2014 "),AZ=n(uWe,"A",{href:!0});var sHt=s(AZ);gTr=r(sHt,"XLMRobertaXLForQuestionAnswering"),sHt.forEach(t),hTr=r(uWe," (XLM-RoBERTa-XL model)"),uWe.forEach(t),uTr=i(X),E4=n(X,"LI",{});var pWe=s(E4);wCe=n(pWe,"STRONG",{});var lHt=s(wCe);pTr=r(lHt,"xlnet"),lHt.forEach(t),_Tr=r(pWe," \u2014 "),LZ=n(pWe,"A",{href:!0});var iHt=s(LZ);bTr=r(iHt,"XLNetForQuestionAnsweringSimple"),iHt.forEach(t),vTr=r(pWe," (XLNet model)"),pWe.forEach(t),FTr=i(X),C4=n(X,"LI",{});var _We=s(C4);ACe=n(_We,"STRONG",{});var dHt=s(ACe);TTr=r(dHt,"yoso"),dHt.forEach(t),MTr=r(_We," \u2014 "),yZ=n(_We,"A",{href:!0});var cHt=s(yZ);ETr=r(cHt,"YosoForQuestionAnswering"),cHt.forEach(t),CTr=r(_We," (YOSO model)"),_We.forEach(t),X.forEach(t),wTr=i(Sa),w4=n(Sa,"P",{});var bWe=s(w4);ATr=r(bWe,"The model is set in evaluation mode by default using "),LCe=n(bWe,"CODE",{});var mHt=s(LCe);LTr=r(mHt,"model.eval()"),mHt.forEach(t),yTr=r(bWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yCe=n(bWe,"CODE",{});var fHt=s(yCe);xTr=r(fHt,"model.train()"),fHt.forEach(t),bWe.forEach(t),$Tr=i(Sa),T(A4.$$.fragment,Sa),Sa.forEach(t),Dl.forEach(t),Goo=i(m),Kd=n(m,"H2",{class:!0});var tao=s(Kd);L4=n(tao,"A",{id:!0,class:!0,href:!0});var gHt=s(L4);xCe=n(gHt,"SPAN",{});var hHt=s(xCe);T(U$.$$.fragment,hHt),hHt.forEach(t),gHt.forEach(t),kTr=i(tao),$Ce=n(tao,"SPAN",{});var uHt=s($Ce);STr=r(uHt,"AutoModelForTableQuestionAnswering"),uHt.forEach(t),tao.forEach(t),Ooo=i(m),zo=n(m,"DIV",{class:!0});var Gl=s(zo);T(H$.$$.fragment,Gl),RTr=i(Gl),ec=n(Gl,"P",{});var sde=s(ec);PTr=r(sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),xZ=n(sde,"A",{href:!0});var pHt=s(xZ);BTr=r(pHt,"from_pretrained()"),pHt.forEach(t),ITr=r(sde," class method or the "),$Z=n(sde,"A",{href:!0});var _Ht=s($Z);NTr=r(_Ht,"from_config()"),_Ht.forEach(t),qTr=r(sde,` class
method.`),sde.forEach(t),jTr=i(Gl),J$=n(Gl,"P",{});var aao=s(J$);DTr=r(aao,"This class cannot be instantiated directly using "),kCe=n(aao,"CODE",{});var bHt=s(kCe);GTr=r(bHt,"__init__()"),bHt.forEach(t),OTr=r(aao," (throws an error)."),aao.forEach(t),VTr=i(Gl),xt=n(Gl,"DIV",{class:!0});var q8=s(xt);T(Y$.$$.fragment,q8),XTr=i(q8),SCe=n(q8,"P",{});var vHt=s(SCe);zTr=r(vHt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),vHt.forEach(t),QTr=i(q8),oc=n(q8,"P",{});var lde=s(oc);WTr=r(lde,`Note:
Loading a model from its configuration file does `),RCe=n(lde,"STRONG",{});var FHt=s(RCe);UTr=r(FHt,"not"),FHt.forEach(t),HTr=r(lde,` load the model weights. It only affects the
model\u2019s configuration. Use `),kZ=n(lde,"A",{href:!0});var THt=s(kZ);JTr=r(THt,"from_pretrained()"),THt.forEach(t),YTr=r(lde," to load the model weights."),lde.forEach(t),ZTr=i(q8),T(y4.$$.fragment,q8),q8.forEach(t),KTr=i(Gl),co=n(Gl,"DIV",{class:!0});var Ra=s(co);T(Z$.$$.fragment,Ra),eMr=i(Ra),PCe=n(Ra,"P",{});var MHt=s(PCe);oMr=r(MHt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),MHt.forEach(t),rMr=i(Ra),mn=n(Ra,"P",{});var j8=s(mn);tMr=r(j8,"The model class to instantiate is selected based on the "),BCe=n(j8,"CODE",{});var EHt=s(BCe);aMr=r(EHt,"model_type"),EHt.forEach(t),nMr=r(j8,` property of the config object (either
passed as an argument or loaded from `),ICe=n(j8,"CODE",{});var CHt=s(ICe);sMr=r(CHt,"pretrained_model_name_or_path"),CHt.forEach(t),lMr=r(j8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=n(j8,"CODE",{});var wHt=s(NCe);iMr=r(wHt,"pretrained_model_name_or_path"),wHt.forEach(t),dMr=r(j8,":"),j8.forEach(t),cMr=i(Ra),qCe=n(Ra,"UL",{});var AHt=s(qCe);x4=n(AHt,"LI",{});var vWe=s(x4);jCe=n(vWe,"STRONG",{});var LHt=s(jCe);mMr=r(LHt,"tapas"),LHt.forEach(t),fMr=r(vWe," \u2014 "),SZ=n(vWe,"A",{href:!0});var yHt=s(SZ);gMr=r(yHt,"TapasForQuestionAnswering"),yHt.forEach(t),hMr=r(vWe," (TAPAS model)"),vWe.forEach(t),AHt.forEach(t),uMr=i(Ra),$4=n(Ra,"P",{});var FWe=s($4);pMr=r(FWe,"The model is set in evaluation mode by default using "),DCe=n(FWe,"CODE",{});var xHt=s(DCe);_Mr=r(xHt,"model.eval()"),xHt.forEach(t),bMr=r(FWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GCe=n(FWe,"CODE",{});var $Ht=s(GCe);vMr=r($Ht,"model.train()"),$Ht.forEach(t),FWe.forEach(t),FMr=i(Ra),T(k4.$$.fragment,Ra),Ra.forEach(t),Gl.forEach(t),Voo=i(m),rc=n(m,"H2",{class:!0});var nao=s(rc);S4=n(nao,"A",{id:!0,class:!0,href:!0});var kHt=s(S4);OCe=n(kHt,"SPAN",{});var SHt=s(OCe);T(K$.$$.fragment,SHt),SHt.forEach(t),kHt.forEach(t),TMr=i(nao),VCe=n(nao,"SPAN",{});var RHt=s(VCe);MMr=r(RHt,"AutoModelForDocumentQuestionAnswering"),RHt.forEach(t),nao.forEach(t),Xoo=i(m),Qo=n(m,"DIV",{class:!0});var Ol=s(Qo);T(ek.$$.fragment,Ol),EMr=i(Ol),tc=n(Ol,"P",{});var ide=s(tc);CMr=r(ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),RZ=n(ide,"A",{href:!0});var PHt=s(RZ);wMr=r(PHt,"from_pretrained()"),PHt.forEach(t),AMr=r(ide," class method or the "),PZ=n(ide,"A",{href:!0});var BHt=s(PZ);LMr=r(BHt,"from_config()"),BHt.forEach(t),yMr=r(ide,` class
method.`),ide.forEach(t),xMr=i(Ol),ok=n(Ol,"P",{});var sao=s(ok);$Mr=r(sao,"This class cannot be instantiated directly using "),XCe=n(sao,"CODE",{});var IHt=s(XCe);kMr=r(IHt,"__init__()"),IHt.forEach(t),SMr=r(sao," (throws an error)."),sao.forEach(t),RMr=i(Ol),$t=n(Ol,"DIV",{class:!0});var D8=s($t);T(rk.$$.fragment,D8),PMr=i(D8),zCe=n(D8,"P",{});var NHt=s(zCe);BMr=r(NHt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),NHt.forEach(t),IMr=i(D8),ac=n(D8,"P",{});var dde=s(ac);NMr=r(dde,`Note:
Loading a model from its configuration file does `),QCe=n(dde,"STRONG",{});var qHt=s(QCe);qMr=r(qHt,"not"),qHt.forEach(t),jMr=r(dde,` load the model weights. It only affects the
model\u2019s configuration. Use `),BZ=n(dde,"A",{href:!0});var jHt=s(BZ);DMr=r(jHt,"from_pretrained()"),jHt.forEach(t),GMr=r(dde," to load the model weights."),dde.forEach(t),OMr=i(D8),T(R4.$$.fragment,D8),D8.forEach(t),VMr=i(Ol),mo=n(Ol,"DIV",{class:!0});var Pa=s(mo);T(tk.$$.fragment,Pa),XMr=i(Pa),WCe=n(Pa,"P",{});var DHt=s(WCe);zMr=r(DHt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),DHt.forEach(t),QMr=i(Pa),fn=n(Pa,"P",{});var G8=s(fn);WMr=r(G8,"The model class to instantiate is selected based on the "),UCe=n(G8,"CODE",{});var GHt=s(UCe);UMr=r(GHt,"model_type"),GHt.forEach(t),HMr=r(G8,` property of the config object (either
passed as an argument or loaded from `),HCe=n(G8,"CODE",{});var OHt=s(HCe);JMr=r(OHt,"pretrained_model_name_or_path"),OHt.forEach(t),YMr=r(G8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=n(G8,"CODE",{});var VHt=s(JCe);ZMr=r(VHt,"pretrained_model_name_or_path"),VHt.forEach(t),KMr=r(G8,":"),G8.forEach(t),eEr=i(Pa),nc=n(Pa,"UL",{});var cde=s(nc);P4=n(cde,"LI",{});var TWe=s(P4);YCe=n(TWe,"STRONG",{});var XHt=s(YCe);oEr=r(XHt,"layoutlm"),XHt.forEach(t),rEr=r(TWe," \u2014 "),IZ=n(TWe,"A",{href:!0});var zHt=s(IZ);tEr=r(zHt,"LayoutLMForQuestionAnswering"),zHt.forEach(t),aEr=r(TWe," (LayoutLM model)"),TWe.forEach(t),nEr=i(cde),B4=n(cde,"LI",{});var MWe=s(B4);ZCe=n(MWe,"STRONG",{});var QHt=s(ZCe);sEr=r(QHt,"layoutlmv2"),QHt.forEach(t),lEr=r(MWe," \u2014 "),NZ=n(MWe,"A",{href:!0});var WHt=s(NZ);iEr=r(WHt,"LayoutLMv2ForQuestionAnswering"),WHt.forEach(t),dEr=r(MWe," (LayoutLMv2 model)"),MWe.forEach(t),cEr=i(cde),I4=n(cde,"LI",{});var EWe=s(I4);KCe=n(EWe,"STRONG",{});var UHt=s(KCe);mEr=r(UHt,"layoutlmv3"),UHt.forEach(t),fEr=r(EWe," \u2014 "),qZ=n(EWe,"A",{href:!0});var HHt=s(qZ);gEr=r(HHt,"LayoutLMv3ForQuestionAnswering"),HHt.forEach(t),hEr=r(EWe," (LayoutLMv3 model)"),EWe.forEach(t),cde.forEach(t),uEr=i(Pa),N4=n(Pa,"P",{});var CWe=s(N4);pEr=r(CWe,"The model is set in evaluation mode by default using "),e3e=n(CWe,"CODE",{});var JHt=s(e3e);_Er=r(JHt,"model.eval()"),JHt.forEach(t),bEr=r(CWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o3e=n(CWe,"CODE",{});var YHt=s(o3e);vEr=r(YHt,"model.train()"),YHt.forEach(t),CWe.forEach(t),FEr=i(Pa),T(q4.$$.fragment,Pa),Pa.forEach(t),Ol.forEach(t),zoo=i(m),sc=n(m,"H2",{class:!0});var lao=s(sc);j4=n(lao,"A",{id:!0,class:!0,href:!0});var ZHt=s(j4);r3e=n(ZHt,"SPAN",{});var KHt=s(r3e);T(ak.$$.fragment,KHt),KHt.forEach(t),ZHt.forEach(t),TEr=i(lao),t3e=n(lao,"SPAN",{});var eJt=s(t3e);MEr=r(eJt,"AutoModelForImageClassification"),eJt.forEach(t),lao.forEach(t),Qoo=i(m),Wo=n(m,"DIV",{class:!0});var Vl=s(Wo);T(nk.$$.fragment,Vl),EEr=i(Vl),lc=n(Vl,"P",{});var mde=s(lc);CEr=r(mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jZ=n(mde,"A",{href:!0});var oJt=s(jZ);wEr=r(oJt,"from_pretrained()"),oJt.forEach(t),AEr=r(mde," class method or the "),DZ=n(mde,"A",{href:!0});var rJt=s(DZ);LEr=r(rJt,"from_config()"),rJt.forEach(t),yEr=r(mde,` class
method.`),mde.forEach(t),xEr=i(Vl),sk=n(Vl,"P",{});var iao=s(sk);$Er=r(iao,"This class cannot be instantiated directly using "),a3e=n(iao,"CODE",{});var tJt=s(a3e);kEr=r(tJt,"__init__()"),tJt.forEach(t),SEr=r(iao," (throws an error)."),iao.forEach(t),REr=i(Vl),kt=n(Vl,"DIV",{class:!0});var O8=s(kt);T(lk.$$.fragment,O8),PEr=i(O8),n3e=n(O8,"P",{});var aJt=s(n3e);BEr=r(aJt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aJt.forEach(t),IEr=i(O8),ic=n(O8,"P",{});var fde=s(ic);NEr=r(fde,`Note:
Loading a model from its configuration file does `),s3e=n(fde,"STRONG",{});var nJt=s(s3e);qEr=r(nJt,"not"),nJt.forEach(t),jEr=r(fde,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(fde,"A",{href:!0});var sJt=s(GZ);DEr=r(sJt,"from_pretrained()"),sJt.forEach(t),GEr=r(fde," to load the model weights."),fde.forEach(t),OEr=i(O8),T(D4.$$.fragment,O8),O8.forEach(t),VEr=i(Vl),fo=n(Vl,"DIV",{class:!0});var Ba=s(fo);T(ik.$$.fragment,Ba),XEr=i(Ba),l3e=n(Ba,"P",{});var lJt=s(l3e);zEr=r(lJt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lJt.forEach(t),QEr=i(Ba),gn=n(Ba,"P",{});var V8=s(gn);WEr=r(V8,"The model class to instantiate is selected based on the "),i3e=n(V8,"CODE",{});var iJt=s(i3e);UEr=r(iJt,"model_type"),iJt.forEach(t),HEr=r(V8,` property of the config object (either
passed as an argument or loaded from `),d3e=n(V8,"CODE",{});var dJt=s(d3e);JEr=r(dJt,"pretrained_model_name_or_path"),dJt.forEach(t),YEr=r(V8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=n(V8,"CODE",{});var cJt=s(c3e);ZEr=r(cJt,"pretrained_model_name_or_path"),cJt.forEach(t),KEr=r(V8,":"),V8.forEach(t),e4r=i(Ba),be=n(Ba,"UL",{});var Fe=s(be);G4=n(Fe,"LI",{});var wWe=s(G4);m3e=n(wWe,"STRONG",{});var mJt=s(m3e);o4r=r(mJt,"beit"),mJt.forEach(t),r4r=r(wWe," \u2014 "),OZ=n(wWe,"A",{href:!0});var fJt=s(OZ);t4r=r(fJt,"BeitForImageClassification"),fJt.forEach(t),a4r=r(wWe," (BEiT model)"),wWe.forEach(t),n4r=i(Fe),O4=n(Fe,"LI",{});var AWe=s(O4);f3e=n(AWe,"STRONG",{});var gJt=s(f3e);s4r=r(gJt,"convnext"),gJt.forEach(t),l4r=r(AWe," \u2014 "),VZ=n(AWe,"A",{href:!0});var hJt=s(VZ);i4r=r(hJt,"ConvNextForImageClassification"),hJt.forEach(t),d4r=r(AWe," (ConvNeXT model)"),AWe.forEach(t),c4r=i(Fe),V4=n(Fe,"LI",{});var LWe=s(V4);g3e=n(LWe,"STRONG",{});var uJt=s(g3e);m4r=r(uJt,"cvt"),uJt.forEach(t),f4r=r(LWe," \u2014 "),XZ=n(LWe,"A",{href:!0});var pJt=s(XZ);g4r=r(pJt,"CvtForImageClassification"),pJt.forEach(t),h4r=r(LWe," (CvT model)"),LWe.forEach(t),u4r=i(Fe),X4=n(Fe,"LI",{});var yWe=s(X4);h3e=n(yWe,"STRONG",{});var _Jt=s(h3e);p4r=r(_Jt,"data2vec-vision"),_Jt.forEach(t),_4r=r(yWe," \u2014 "),zZ=n(yWe,"A",{href:!0});var bJt=s(zZ);b4r=r(bJt,"Data2VecVisionForImageClassification"),bJt.forEach(t),v4r=r(yWe," (Data2VecVision model)"),yWe.forEach(t),F4r=i(Fe),El=n(Fe,"LI",{});var AI=s(El);u3e=n(AI,"STRONG",{});var vJt=s(u3e);T4r=r(vJt,"deit"),vJt.forEach(t),M4r=r(AI," \u2014 "),QZ=n(AI,"A",{href:!0});var FJt=s(QZ);E4r=r(FJt,"DeiTForImageClassification"),FJt.forEach(t),C4r=r(AI," or "),WZ=n(AI,"A",{href:!0});var TJt=s(WZ);w4r=r(TJt,"DeiTForImageClassificationWithTeacher"),TJt.forEach(t),A4r=r(AI," (DeiT model)"),AI.forEach(t),L4r=i(Fe),z4=n(Fe,"LI",{});var xWe=s(z4);p3e=n(xWe,"STRONG",{});var MJt=s(p3e);y4r=r(MJt,"imagegpt"),MJt.forEach(t),x4r=r(xWe," \u2014 "),UZ=n(xWe,"A",{href:!0});var EJt=s(UZ);$4r=r(EJt,"ImageGPTForImageClassification"),EJt.forEach(t),k4r=r(xWe," (ImageGPT model)"),xWe.forEach(t),S4r=i(Fe),Cl=n(Fe,"LI",{});var LI=s(Cl);_3e=n(LI,"STRONG",{});var CJt=s(_3e);R4r=r(CJt,"levit"),CJt.forEach(t),P4r=r(LI," \u2014 "),HZ=n(LI,"A",{href:!0});var wJt=s(HZ);B4r=r(wJt,"LevitForImageClassification"),wJt.forEach(t),I4r=r(LI," or "),JZ=n(LI,"A",{href:!0});var AJt=s(JZ);N4r=r(AJt,"LevitForImageClassificationWithTeacher"),AJt.forEach(t),q4r=r(LI," (LeViT model)"),LI.forEach(t),j4r=i(Fe),Q4=n(Fe,"LI",{});var $We=s(Q4);b3e=n($We,"STRONG",{});var LJt=s(b3e);D4r=r(LJt,"mobilevit"),LJt.forEach(t),G4r=r($We," \u2014 "),YZ=n($We,"A",{href:!0});var yJt=s(YZ);O4r=r(yJt,"MobileViTForImageClassification"),yJt.forEach(t),V4r=r($We," (MobileViT model)"),$We.forEach(t),X4r=i(Fe),St=n(Fe,"LI",{});var Sf=s(St);v3e=n(Sf,"STRONG",{});var xJt=s(v3e);z4r=r(xJt,"perceiver"),xJt.forEach(t),Q4r=r(Sf," \u2014 "),ZZ=n(Sf,"A",{href:!0});var $Jt=s(ZZ);W4r=r($Jt,"PerceiverForImageClassificationLearned"),$Jt.forEach(t),U4r=r(Sf," or "),KZ=n(Sf,"A",{href:!0});var kJt=s(KZ);H4r=r(kJt,"PerceiverForImageClassificationFourier"),kJt.forEach(t),J4r=r(Sf," or "),eK=n(Sf,"A",{href:!0});var SJt=s(eK);Y4r=r(SJt,"PerceiverForImageClassificationConvProcessing"),SJt.forEach(t),Z4r=r(Sf," (Perceiver model)"),Sf.forEach(t),K4r=i(Fe),W4=n(Fe,"LI",{});var kWe=s(W4);F3e=n(kWe,"STRONG",{});var RJt=s(F3e);eCr=r(RJt,"poolformer"),RJt.forEach(t),oCr=r(kWe," \u2014 "),oK=n(kWe,"A",{href:!0});var PJt=s(oK);rCr=r(PJt,"PoolFormerForImageClassification"),PJt.forEach(t),tCr=r(kWe," (PoolFormer model)"),kWe.forEach(t),aCr=i(Fe),U4=n(Fe,"LI",{});var SWe=s(U4);T3e=n(SWe,"STRONG",{});var BJt=s(T3e);nCr=r(BJt,"regnet"),BJt.forEach(t),sCr=r(SWe," \u2014 "),rK=n(SWe,"A",{href:!0});var IJt=s(rK);lCr=r(IJt,"RegNetForImageClassification"),IJt.forEach(t),iCr=r(SWe," (RegNet model)"),SWe.forEach(t),dCr=i(Fe),H4=n(Fe,"LI",{});var RWe=s(H4);M3e=n(RWe,"STRONG",{});var NJt=s(M3e);cCr=r(NJt,"resnet"),NJt.forEach(t),mCr=r(RWe," \u2014 "),tK=n(RWe,"A",{href:!0});var qJt=s(tK);fCr=r(qJt,"ResNetForImageClassification"),qJt.forEach(t),gCr=r(RWe," (ResNet model)"),RWe.forEach(t),hCr=i(Fe),J4=n(Fe,"LI",{});var PWe=s(J4);E3e=n(PWe,"STRONG",{});var jJt=s(E3e);uCr=r(jJt,"segformer"),jJt.forEach(t),pCr=r(PWe," \u2014 "),aK=n(PWe,"A",{href:!0});var DJt=s(aK);_Cr=r(DJt,"SegformerForImageClassification"),DJt.forEach(t),bCr=r(PWe," (SegFormer model)"),PWe.forEach(t),vCr=i(Fe),Y4=n(Fe,"LI",{});var BWe=s(Y4);C3e=n(BWe,"STRONG",{});var GJt=s(C3e);FCr=r(GJt,"swin"),GJt.forEach(t),TCr=r(BWe," \u2014 "),nK=n(BWe,"A",{href:!0});var OJt=s(nK);MCr=r(OJt,"SwinForImageClassification"),OJt.forEach(t),ECr=r(BWe," (Swin Transformer model)"),BWe.forEach(t),CCr=i(Fe),Z4=n(Fe,"LI",{});var IWe=s(Z4);w3e=n(IWe,"STRONG",{});var VJt=s(w3e);wCr=r(VJt,"swinv2"),VJt.forEach(t),ACr=r(IWe," \u2014 "),sK=n(IWe,"A",{href:!0});var XJt=s(sK);LCr=r(XJt,"Swinv2ForImageClassification"),XJt.forEach(t),yCr=r(IWe," (Swin Transformer V2 model)"),IWe.forEach(t),xCr=i(Fe),K4=n(Fe,"LI",{});var NWe=s(K4);A3e=n(NWe,"STRONG",{});var zJt=s(A3e);$Cr=r(zJt,"van"),zJt.forEach(t),kCr=r(NWe," \u2014 "),lK=n(NWe,"A",{href:!0});var QJt=s(lK);SCr=r(QJt,"VanForImageClassification"),QJt.forEach(t),RCr=r(NWe," (VAN model)"),NWe.forEach(t),PCr=i(Fe),eC=n(Fe,"LI",{});var qWe=s(eC);L3e=n(qWe,"STRONG",{});var WJt=s(L3e);BCr=r(WJt,"vit"),WJt.forEach(t),ICr=r(qWe," \u2014 "),iK=n(qWe,"A",{href:!0});var UJt=s(iK);NCr=r(UJt,"ViTForImageClassification"),UJt.forEach(t),qCr=r(qWe," (ViT model)"),qWe.forEach(t),jCr=i(Fe),oC=n(Fe,"LI",{});var jWe=s(oC);y3e=n(jWe,"STRONG",{});var HJt=s(y3e);DCr=r(HJt,"vit_msn"),HJt.forEach(t),GCr=r(jWe," \u2014 "),dK=n(jWe,"A",{href:!0});var JJt=s(dK);OCr=r(JJt,"ViTMSNForImageClassification"),JJt.forEach(t),VCr=r(jWe," (ViTMSN model)"),jWe.forEach(t),Fe.forEach(t),XCr=i(Ba),rC=n(Ba,"P",{});var DWe=s(rC);zCr=r(DWe,"The model is set in evaluation mode by default using "),x3e=n(DWe,"CODE",{});var YJt=s(x3e);QCr=r(YJt,"model.eval()"),YJt.forEach(t),WCr=r(DWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$3e=n(DWe,"CODE",{});var ZJt=s($3e);UCr=r(ZJt,"model.train()"),ZJt.forEach(t),DWe.forEach(t),HCr=i(Ba),T(tC.$$.fragment,Ba),Ba.forEach(t),Vl.forEach(t),Woo=i(m),dc=n(m,"H2",{class:!0});var dao=s(dc);aC=n(dao,"A",{id:!0,class:!0,href:!0});var KJt=s(aC);k3e=n(KJt,"SPAN",{});var eYt=s(k3e);T(dk.$$.fragment,eYt),eYt.forEach(t),KJt.forEach(t),JCr=i(dao),S3e=n(dao,"SPAN",{});var oYt=s(S3e);YCr=r(oYt,"AutoModelForVideoClassification"),oYt.forEach(t),dao.forEach(t),Uoo=i(m),Uo=n(m,"DIV",{class:!0});var Xl=s(Uo);T(ck.$$.fragment,Xl),ZCr=i(Xl),cc=n(Xl,"P",{});var gde=s(cc);KCr=r(gde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),cK=n(gde,"A",{href:!0});var rYt=s(cK);e3r=r(rYt,"from_pretrained()"),rYt.forEach(t),o3r=r(gde," class method or the "),mK=n(gde,"A",{href:!0});var tYt=s(mK);r3r=r(tYt,"from_config()"),tYt.forEach(t),t3r=r(gde,` class
method.`),gde.forEach(t),a3r=i(Xl),mk=n(Xl,"P",{});var cao=s(mk);n3r=r(cao,"This class cannot be instantiated directly using "),R3e=n(cao,"CODE",{});var aYt=s(R3e);s3r=r(aYt,"__init__()"),aYt.forEach(t),l3r=r(cao," (throws an error)."),cao.forEach(t),i3r=i(Xl),Rt=n(Xl,"DIV",{class:!0});var X8=s(Rt);T(fk.$$.fragment,X8),d3r=i(X8),P3e=n(X8,"P",{});var nYt=s(P3e);c3r=r(nYt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),nYt.forEach(t),m3r=i(X8),mc=n(X8,"P",{});var hde=s(mc);f3r=r(hde,`Note:
Loading a model from its configuration file does `),B3e=n(hde,"STRONG",{});var sYt=s(B3e);g3r=r(sYt,"not"),sYt.forEach(t),h3r=r(hde,` load the model weights. It only affects the
model\u2019s configuration. Use `),fK=n(hde,"A",{href:!0});var lYt=s(fK);u3r=r(lYt,"from_pretrained()"),lYt.forEach(t),p3r=r(hde," to load the model weights."),hde.forEach(t),_3r=i(X8),T(nC.$$.fragment,X8),X8.forEach(t),b3r=i(Xl),go=n(Xl,"DIV",{class:!0});var Ia=s(go);T(gk.$$.fragment,Ia),v3r=i(Ia),I3e=n(Ia,"P",{});var iYt=s(I3e);F3r=r(iYt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),iYt.forEach(t),T3r=i(Ia),hn=n(Ia,"P",{});var z8=s(hn);M3r=r(z8,"The model class to instantiate is selected based on the "),N3e=n(z8,"CODE",{});var dYt=s(N3e);E3r=r(dYt,"model_type"),dYt.forEach(t),C3r=r(z8,` property of the config object (either
passed as an argument or loaded from `),q3e=n(z8,"CODE",{});var cYt=s(q3e);w3r=r(cYt,"pretrained_model_name_or_path"),cYt.forEach(t),A3r=r(z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=n(z8,"CODE",{});var mYt=s(j3e);L3r=r(mYt,"pretrained_model_name_or_path"),mYt.forEach(t),y3r=r(z8,":"),z8.forEach(t),x3r=i(Ia),D3e=n(Ia,"UL",{});var fYt=s(D3e);sC=n(fYt,"LI",{});var GWe=s(sC);G3e=n(GWe,"STRONG",{});var gYt=s(G3e);$3r=r(gYt,"videomae"),gYt.forEach(t),k3r=r(GWe," \u2014 "),gK=n(GWe,"A",{href:!0});var hYt=s(gK);S3r=r(hYt,"VideoMAEForVideoClassification"),hYt.forEach(t),R3r=r(GWe," (VideoMAE model)"),GWe.forEach(t),fYt.forEach(t),P3r=i(Ia),lC=n(Ia,"P",{});var OWe=s(lC);B3r=r(OWe,"The model is set in evaluation mode by default using "),O3e=n(OWe,"CODE",{});var uYt=s(O3e);I3r=r(uYt,"model.eval()"),uYt.forEach(t),N3r=r(OWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V3e=n(OWe,"CODE",{});var pYt=s(V3e);q3r=r(pYt,"model.train()"),pYt.forEach(t),OWe.forEach(t),j3r=i(Ia),T(iC.$$.fragment,Ia),Ia.forEach(t),Xl.forEach(t),Hoo=i(m),fc=n(m,"H2",{class:!0});var mao=s(fc);dC=n(mao,"A",{id:!0,class:!0,href:!0});var _Yt=s(dC);X3e=n(_Yt,"SPAN",{});var bYt=s(X3e);T(hk.$$.fragment,bYt),bYt.forEach(t),_Yt.forEach(t),D3r=i(mao),z3e=n(mao,"SPAN",{});var vYt=s(z3e);G3r=r(vYt,"AutoModelForVision2Seq"),vYt.forEach(t),mao.forEach(t),Joo=i(m),Ho=n(m,"DIV",{class:!0});var zl=s(Ho);T(uk.$$.fragment,zl),O3r=i(zl),gc=n(zl,"P",{});var ude=s(gc);V3r=r(ude,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hK=n(ude,"A",{href:!0});var FYt=s(hK);X3r=r(FYt,"from_pretrained()"),FYt.forEach(t),z3r=r(ude," class method or the "),uK=n(ude,"A",{href:!0});var TYt=s(uK);Q3r=r(TYt,"from_config()"),TYt.forEach(t),W3r=r(ude,` class
method.`),ude.forEach(t),U3r=i(zl),pk=n(zl,"P",{});var fao=s(pk);H3r=r(fao,"This class cannot be instantiated directly using "),Q3e=n(fao,"CODE",{});var MYt=s(Q3e);J3r=r(MYt,"__init__()"),MYt.forEach(t),Y3r=r(fao," (throws an error)."),fao.forEach(t),Z3r=i(zl),Pt=n(zl,"DIV",{class:!0});var Q8=s(Pt);T(_k.$$.fragment,Q8),K3r=i(Q8),W3e=n(Q8,"P",{});var EYt=s(W3e);e5r=r(EYt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),EYt.forEach(t),o5r=i(Q8),hc=n(Q8,"P",{});var pde=s(hc);r5r=r(pde,`Note:
Loading a model from its configuration file does `),U3e=n(pde,"STRONG",{});var CYt=s(U3e);t5r=r(CYt,"not"),CYt.forEach(t),a5r=r(pde,` load the model weights. It only affects the
model\u2019s configuration. Use `),pK=n(pde,"A",{href:!0});var wYt=s(pK);n5r=r(wYt,"from_pretrained()"),wYt.forEach(t),s5r=r(pde," to load the model weights."),pde.forEach(t),l5r=i(Q8),T(cC.$$.fragment,Q8),Q8.forEach(t),i5r=i(zl),ho=n(zl,"DIV",{class:!0});var Na=s(ho);T(bk.$$.fragment,Na),d5r=i(Na),H3e=n(Na,"P",{});var AYt=s(H3e);c5r=r(AYt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),AYt.forEach(t),m5r=i(Na),un=n(Na,"P",{});var W8=s(un);f5r=r(W8,"The model class to instantiate is selected based on the "),J3e=n(W8,"CODE",{});var LYt=s(J3e);g5r=r(LYt,"model_type"),LYt.forEach(t),h5r=r(W8,` property of the config object (either
passed as an argument or loaded from `),Y3e=n(W8,"CODE",{});var yYt=s(Y3e);u5r=r(yYt,"pretrained_model_name_or_path"),yYt.forEach(t),p5r=r(W8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z3e=n(W8,"CODE",{});var xYt=s(Z3e);_5r=r(xYt,"pretrained_model_name_or_path"),xYt.forEach(t),b5r=r(W8,":"),W8.forEach(t),v5r=i(Na),K3e=n(Na,"UL",{});var $Yt=s(K3e);mC=n($Yt,"LI",{});var VWe=s(mC);e5e=n(VWe,"STRONG",{});var kYt=s(e5e);F5r=r(kYt,"vision-encoder-decoder"),kYt.forEach(t),T5r=r(VWe," \u2014 "),_K=n(VWe,"A",{href:!0});var SYt=s(_K);M5r=r(SYt,"VisionEncoderDecoderModel"),SYt.forEach(t),E5r=r(VWe," (Vision Encoder decoder model)"),VWe.forEach(t),$Yt.forEach(t),C5r=i(Na),fC=n(Na,"P",{});var XWe=s(fC);w5r=r(XWe,"The model is set in evaluation mode by default using "),o5e=n(XWe,"CODE",{});var RYt=s(o5e);A5r=r(RYt,"model.eval()"),RYt.forEach(t),L5r=r(XWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r5e=n(XWe,"CODE",{});var PYt=s(r5e);y5r=r(PYt,"model.train()"),PYt.forEach(t),XWe.forEach(t),x5r=i(Na),T(gC.$$.fragment,Na),Na.forEach(t),zl.forEach(t),Yoo=i(m),uc=n(m,"H2",{class:!0});var gao=s(uc);hC=n(gao,"A",{id:!0,class:!0,href:!0});var BYt=s(hC);t5e=n(BYt,"SPAN",{});var IYt=s(t5e);T(vk.$$.fragment,IYt),IYt.forEach(t),BYt.forEach(t),$5r=i(gao),a5e=n(gao,"SPAN",{});var NYt=s(a5e);k5r=r(NYt,"AutoModelForVisualQuestionAnswering"),NYt.forEach(t),gao.forEach(t),Zoo=i(m),Jo=n(m,"DIV",{class:!0});var Ql=s(Jo);T(Fk.$$.fragment,Ql),S5r=i(Ql),pc=n(Ql,"P",{});var _de=s(pc);R5r=r(_de,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),bK=n(_de,"A",{href:!0});var qYt=s(bK);P5r=r(qYt,"from_pretrained()"),qYt.forEach(t),B5r=r(_de," class method or the "),vK=n(_de,"A",{href:!0});var jYt=s(vK);I5r=r(jYt,"from_config()"),jYt.forEach(t),N5r=r(_de,` class
method.`),_de.forEach(t),q5r=i(Ql),Tk=n(Ql,"P",{});var hao=s(Tk);j5r=r(hao,"This class cannot be instantiated directly using "),n5e=n(hao,"CODE",{});var DYt=s(n5e);D5r=r(DYt,"__init__()"),DYt.forEach(t),G5r=r(hao," (throws an error)."),hao.forEach(t),O5r=i(Ql),Bt=n(Ql,"DIV",{class:!0});var U8=s(Bt);T(Mk.$$.fragment,U8),V5r=i(U8),s5e=n(U8,"P",{});var GYt=s(s5e);X5r=r(GYt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),GYt.forEach(t),z5r=i(U8),_c=n(U8,"P",{});var bde=s(_c);Q5r=r(bde,`Note:
Loading a model from its configuration file does `),l5e=n(bde,"STRONG",{});var OYt=s(l5e);W5r=r(OYt,"not"),OYt.forEach(t),U5r=r(bde,` load the model weights. It only affects the
model\u2019s configuration. Use `),FK=n(bde,"A",{href:!0});var VYt=s(FK);H5r=r(VYt,"from_pretrained()"),VYt.forEach(t),J5r=r(bde," to load the model weights."),bde.forEach(t),Y5r=i(U8),T(uC.$$.fragment,U8),U8.forEach(t),Z5r=i(Ql),uo=n(Ql,"DIV",{class:!0});var qa=s(uo);T(Ek.$$.fragment,qa),K5r=i(qa),i5e=n(qa,"P",{});var XYt=s(i5e);e0r=r(XYt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),XYt.forEach(t),o0r=i(qa),pn=n(qa,"P",{});var H8=s(pn);r0r=r(H8,"The model class to instantiate is selected based on the "),d5e=n(H8,"CODE",{});var zYt=s(d5e);t0r=r(zYt,"model_type"),zYt.forEach(t),a0r=r(H8,` property of the config object (either
passed as an argument or loaded from `),c5e=n(H8,"CODE",{});var QYt=s(c5e);n0r=r(QYt,"pretrained_model_name_or_path"),QYt.forEach(t),s0r=r(H8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=n(H8,"CODE",{});var WYt=s(m5e);l0r=r(WYt,"pretrained_model_name_or_path"),WYt.forEach(t),i0r=r(H8,":"),H8.forEach(t),d0r=i(qa),f5e=n(qa,"UL",{});var UYt=s(f5e);pC=n(UYt,"LI",{});var zWe=s(pC);g5e=n(zWe,"STRONG",{});var HYt=s(g5e);c0r=r(HYt,"vilt"),HYt.forEach(t),m0r=r(zWe," \u2014 "),TK=n(zWe,"A",{href:!0});var JYt=s(TK);f0r=r(JYt,"ViltForQuestionAnswering"),JYt.forEach(t),g0r=r(zWe," (ViLT model)"),zWe.forEach(t),UYt.forEach(t),h0r=i(qa),_C=n(qa,"P",{});var QWe=s(_C);u0r=r(QWe,"The model is set in evaluation mode by default using "),h5e=n(QWe,"CODE",{});var YYt=s(h5e);p0r=r(YYt,"model.eval()"),YYt.forEach(t),_0r=r(QWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u5e=n(QWe,"CODE",{});var ZYt=s(u5e);b0r=r(ZYt,"model.train()"),ZYt.forEach(t),QWe.forEach(t),v0r=i(qa),T(bC.$$.fragment,qa),qa.forEach(t),Ql.forEach(t),Koo=i(m),bc=n(m,"H2",{class:!0});var uao=s(bc);vC=n(uao,"A",{id:!0,class:!0,href:!0});var KYt=s(vC);p5e=n(KYt,"SPAN",{});var eZt=s(p5e);T(Ck.$$.fragment,eZt),eZt.forEach(t),KYt.forEach(t),F0r=i(uao),_5e=n(uao,"SPAN",{});var oZt=s(_5e);T0r=r(oZt,"AutoModelForAudioClassification"),oZt.forEach(t),uao.forEach(t),ero=i(m),Yo=n(m,"DIV",{class:!0});var Wl=s(Yo);T(wk.$$.fragment,Wl),M0r=i(Wl),vc=n(Wl,"P",{});var vde=s(vc);E0r=r(vde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),MK=n(vde,"A",{href:!0});var rZt=s(MK);C0r=r(rZt,"from_pretrained()"),rZt.forEach(t),w0r=r(vde," class method or the "),EK=n(vde,"A",{href:!0});var tZt=s(EK);A0r=r(tZt,"from_config()"),tZt.forEach(t),L0r=r(vde,` class
method.`),vde.forEach(t),y0r=i(Wl),Ak=n(Wl,"P",{});var pao=s(Ak);x0r=r(pao,"This class cannot be instantiated directly using "),b5e=n(pao,"CODE",{});var aZt=s(b5e);$0r=r(aZt,"__init__()"),aZt.forEach(t),k0r=r(pao," (throws an error)."),pao.forEach(t),S0r=i(Wl),It=n(Wl,"DIV",{class:!0});var J8=s(It);T(Lk.$$.fragment,J8),R0r=i(J8),v5e=n(J8,"P",{});var nZt=s(v5e);P0r=r(nZt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),nZt.forEach(t),B0r=i(J8),Fc=n(J8,"P",{});var Fde=s(Fc);I0r=r(Fde,`Note:
Loading a model from its configuration file does `),F5e=n(Fde,"STRONG",{});var sZt=s(F5e);N0r=r(sZt,"not"),sZt.forEach(t),q0r=r(Fde,` load the model weights. It only affects the
model\u2019s configuration. Use `),CK=n(Fde,"A",{href:!0});var lZt=s(CK);j0r=r(lZt,"from_pretrained()"),lZt.forEach(t),D0r=r(Fde," to load the model weights."),Fde.forEach(t),G0r=i(J8),T(FC.$$.fragment,J8),J8.forEach(t),O0r=i(Wl),po=n(Wl,"DIV",{class:!0});var ja=s(po);T(yk.$$.fragment,ja),V0r=i(ja),T5e=n(ja,"P",{});var iZt=s(T5e);X0r=r(iZt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),iZt.forEach(t),z0r=i(ja),_n=n(ja,"P",{});var Y8=s(_n);Q0r=r(Y8,"The model class to instantiate is selected based on the "),M5e=n(Y8,"CODE",{});var dZt=s(M5e);W0r=r(dZt,"model_type"),dZt.forEach(t),U0r=r(Y8,` property of the config object (either
passed as an argument or loaded from `),E5e=n(Y8,"CODE",{});var cZt=s(E5e);H0r=r(cZt,"pretrained_model_name_or_path"),cZt.forEach(t),J0r=r(Y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C5e=n(Y8,"CODE",{});var mZt=s(C5e);Y0r=r(mZt,"pretrained_model_name_or_path"),mZt.forEach(t),Z0r=r(Y8,":"),Y8.forEach(t),K0r=i(ja),Pe=n(ja,"UL",{});var Qe=s(Pe);TC=n(Qe,"LI",{});var WWe=s(TC);w5e=n(WWe,"STRONG",{});var fZt=s(w5e);ewr=r(fZt,"data2vec-audio"),fZt.forEach(t),owr=r(WWe," \u2014 "),wK=n(WWe,"A",{href:!0});var gZt=s(wK);rwr=r(gZt,"Data2VecAudioForSequenceClassification"),gZt.forEach(t),twr=r(WWe," (Data2VecAudio model)"),WWe.forEach(t),awr=i(Qe),MC=n(Qe,"LI",{});var UWe=s(MC);A5e=n(UWe,"STRONG",{});var hZt=s(A5e);nwr=r(hZt,"hubert"),hZt.forEach(t),swr=r(UWe," \u2014 "),AK=n(UWe,"A",{href:!0});var uZt=s(AK);lwr=r(uZt,"HubertForSequenceClassification"),uZt.forEach(t),iwr=r(UWe," (Hubert model)"),UWe.forEach(t),dwr=i(Qe),EC=n(Qe,"LI",{});var HWe=s(EC);L5e=n(HWe,"STRONG",{});var pZt=s(L5e);cwr=r(pZt,"sew"),pZt.forEach(t),mwr=r(HWe," \u2014 "),LK=n(HWe,"A",{href:!0});var _Zt=s(LK);fwr=r(_Zt,"SEWForSequenceClassification"),_Zt.forEach(t),gwr=r(HWe," (SEW model)"),HWe.forEach(t),hwr=i(Qe),CC=n(Qe,"LI",{});var JWe=s(CC);y5e=n(JWe,"STRONG",{});var bZt=s(y5e);uwr=r(bZt,"sew-d"),bZt.forEach(t),pwr=r(JWe," \u2014 "),yK=n(JWe,"A",{href:!0});var vZt=s(yK);_wr=r(vZt,"SEWDForSequenceClassification"),vZt.forEach(t),bwr=r(JWe," (SEW-D model)"),JWe.forEach(t),vwr=i(Qe),wC=n(Qe,"LI",{});var YWe=s(wC);x5e=n(YWe,"STRONG",{});var FZt=s(x5e);Fwr=r(FZt,"unispeech"),FZt.forEach(t),Twr=r(YWe," \u2014 "),xK=n(YWe,"A",{href:!0});var TZt=s(xK);Mwr=r(TZt,"UniSpeechForSequenceClassification"),TZt.forEach(t),Ewr=r(YWe," (UniSpeech model)"),YWe.forEach(t),Cwr=i(Qe),AC=n(Qe,"LI",{});var ZWe=s(AC);$5e=n(ZWe,"STRONG",{});var MZt=s($5e);wwr=r(MZt,"unispeech-sat"),MZt.forEach(t),Awr=r(ZWe," \u2014 "),$K=n(ZWe,"A",{href:!0});var EZt=s($K);Lwr=r(EZt,"UniSpeechSatForSequenceClassification"),EZt.forEach(t),ywr=r(ZWe," (UniSpeechSat model)"),ZWe.forEach(t),xwr=i(Qe),LC=n(Qe,"LI",{});var KWe=s(LC);k5e=n(KWe,"STRONG",{});var CZt=s(k5e);$wr=r(CZt,"wav2vec2"),CZt.forEach(t),kwr=r(KWe," \u2014 "),kK=n(KWe,"A",{href:!0});var wZt=s(kK);Swr=r(wZt,"Wav2Vec2ForSequenceClassification"),wZt.forEach(t),Rwr=r(KWe," (Wav2Vec2 model)"),KWe.forEach(t),Pwr=i(Qe),yC=n(Qe,"LI",{});var eUe=s(yC);S5e=n(eUe,"STRONG",{});var AZt=s(S5e);Bwr=r(AZt,"wav2vec2-conformer"),AZt.forEach(t),Iwr=r(eUe," \u2014 "),SK=n(eUe,"A",{href:!0});var LZt=s(SK);Nwr=r(LZt,"Wav2Vec2ConformerForSequenceClassification"),LZt.forEach(t),qwr=r(eUe," (Wav2Vec2-Conformer model)"),eUe.forEach(t),jwr=i(Qe),xC=n(Qe,"LI",{});var oUe=s(xC);R5e=n(oUe,"STRONG",{});var yZt=s(R5e);Dwr=r(yZt,"wavlm"),yZt.forEach(t),Gwr=r(oUe," \u2014 "),RK=n(oUe,"A",{href:!0});var xZt=s(RK);Owr=r(xZt,"WavLMForSequenceClassification"),xZt.forEach(t),Vwr=r(oUe," (WavLM model)"),oUe.forEach(t),Qe.forEach(t),Xwr=i(ja),$C=n(ja,"P",{});var rUe=s($C);zwr=r(rUe,"The model is set in evaluation mode by default using "),P5e=n(rUe,"CODE",{});var $Zt=s(P5e);Qwr=r($Zt,"model.eval()"),$Zt.forEach(t),Wwr=r(rUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B5e=n(rUe,"CODE",{});var kZt=s(B5e);Uwr=r(kZt,"model.train()"),kZt.forEach(t),rUe.forEach(t),Hwr=i(ja),T(kC.$$.fragment,ja),ja.forEach(t),Wl.forEach(t),oro=i(m),Tc=n(m,"H2",{class:!0});var _ao=s(Tc);SC=n(_ao,"A",{id:!0,class:!0,href:!0});var SZt=s(SC);I5e=n(SZt,"SPAN",{});var RZt=s(I5e);T(xk.$$.fragment,RZt),RZt.forEach(t),SZt.forEach(t),Jwr=i(_ao),N5e=n(_ao,"SPAN",{});var PZt=s(N5e);Ywr=r(PZt,"AutoModelForAudioFrameClassification"),PZt.forEach(t),_ao.forEach(t),rro=i(m),Zo=n(m,"DIV",{class:!0});var Ul=s(Zo);T($k.$$.fragment,Ul),Zwr=i(Ul),Mc=n(Ul,"P",{});var Tde=s(Mc);Kwr=r(Tde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),PK=n(Tde,"A",{href:!0});var BZt=s(PK);eAr=r(BZt,"from_pretrained()"),BZt.forEach(t),oAr=r(Tde," class method or the "),BK=n(Tde,"A",{href:!0});var IZt=s(BK);rAr=r(IZt,"from_config()"),IZt.forEach(t),tAr=r(Tde,` class
method.`),Tde.forEach(t),aAr=i(Ul),kk=n(Ul,"P",{});var bao=s(kk);nAr=r(bao,"This class cannot be instantiated directly using "),q5e=n(bao,"CODE",{});var NZt=s(q5e);sAr=r(NZt,"__init__()"),NZt.forEach(t),lAr=r(bao," (throws an error)."),bao.forEach(t),iAr=i(Ul),Nt=n(Ul,"DIV",{class:!0});var Z8=s(Nt);T(Sk.$$.fragment,Z8),dAr=i(Z8),j5e=n(Z8,"P",{});var qZt=s(j5e);cAr=r(qZt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),qZt.forEach(t),mAr=i(Z8),Ec=n(Z8,"P",{});var Mde=s(Ec);fAr=r(Mde,`Note:
Loading a model from its configuration file does `),D5e=n(Mde,"STRONG",{});var jZt=s(D5e);gAr=r(jZt,"not"),jZt.forEach(t),hAr=r(Mde,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Mde,"A",{href:!0});var DZt=s(IK);uAr=r(DZt,"from_pretrained()"),DZt.forEach(t),pAr=r(Mde," to load the model weights."),Mde.forEach(t),_Ar=i(Z8),T(RC.$$.fragment,Z8),Z8.forEach(t),bAr=i(Ul),_o=n(Ul,"DIV",{class:!0});var Da=s(_o);T(Rk.$$.fragment,Da),vAr=i(Da),G5e=n(Da,"P",{});var GZt=s(G5e);FAr=r(GZt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),GZt.forEach(t),TAr=i(Da),bn=n(Da,"P",{});var K8=s(bn);MAr=r(K8,"The model class to instantiate is selected based on the "),O5e=n(K8,"CODE",{});var OZt=s(O5e);EAr=r(OZt,"model_type"),OZt.forEach(t),CAr=r(K8,` property of the config object (either
passed as an argument or loaded from `),V5e=n(K8,"CODE",{});var VZt=s(V5e);wAr=r(VZt,"pretrained_model_name_or_path"),VZt.forEach(t),AAr=r(K8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X5e=n(K8,"CODE",{});var XZt=s(X5e);LAr=r(XZt,"pretrained_model_name_or_path"),XZt.forEach(t),yAr=r(K8,":"),K8.forEach(t),xAr=i(Da),gt=n(Da,"UL",{});var Hl=s(gt);PC=n(Hl,"LI",{});var tUe=s(PC);z5e=n(tUe,"STRONG",{});var zZt=s(z5e);$Ar=r(zZt,"data2vec-audio"),zZt.forEach(t),kAr=r(tUe," \u2014 "),NK=n(tUe,"A",{href:!0});var QZt=s(NK);SAr=r(QZt,"Data2VecAudioForAudioFrameClassification"),QZt.forEach(t),RAr=r(tUe," (Data2VecAudio model)"),tUe.forEach(t),PAr=i(Hl),BC=n(Hl,"LI",{});var aUe=s(BC);Q5e=n(aUe,"STRONG",{});var WZt=s(Q5e);BAr=r(WZt,"unispeech-sat"),WZt.forEach(t),IAr=r(aUe," \u2014 "),qK=n(aUe,"A",{href:!0});var UZt=s(qK);NAr=r(UZt,"UniSpeechSatForAudioFrameClassification"),UZt.forEach(t),qAr=r(aUe," (UniSpeechSat model)"),aUe.forEach(t),jAr=i(Hl),IC=n(Hl,"LI",{});var nUe=s(IC);W5e=n(nUe,"STRONG",{});var HZt=s(W5e);DAr=r(HZt,"wav2vec2"),HZt.forEach(t),GAr=r(nUe," \u2014 "),jK=n(nUe,"A",{href:!0});var JZt=s(jK);OAr=r(JZt,"Wav2Vec2ForAudioFrameClassification"),JZt.forEach(t),VAr=r(nUe," (Wav2Vec2 model)"),nUe.forEach(t),XAr=i(Hl),NC=n(Hl,"LI",{});var sUe=s(NC);U5e=n(sUe,"STRONG",{});var YZt=s(U5e);zAr=r(YZt,"wav2vec2-conformer"),YZt.forEach(t),QAr=r(sUe," \u2014 "),DK=n(sUe,"A",{href:!0});var ZZt=s(DK);WAr=r(ZZt,"Wav2Vec2ConformerForAudioFrameClassification"),ZZt.forEach(t),UAr=r(sUe," (Wav2Vec2-Conformer model)"),sUe.forEach(t),HAr=i(Hl),qC=n(Hl,"LI",{});var lUe=s(qC);H5e=n(lUe,"STRONG",{});var KZt=s(H5e);JAr=r(KZt,"wavlm"),KZt.forEach(t),YAr=r(lUe," \u2014 "),GK=n(lUe,"A",{href:!0});var eKt=s(GK);ZAr=r(eKt,"WavLMForAudioFrameClassification"),eKt.forEach(t),KAr=r(lUe," (WavLM model)"),lUe.forEach(t),Hl.forEach(t),e6r=i(Da),jC=n(Da,"P",{});var iUe=s(jC);o6r=r(iUe,"The model is set in evaluation mode by default using "),J5e=n(iUe,"CODE",{});var oKt=s(J5e);r6r=r(oKt,"model.eval()"),oKt.forEach(t),t6r=r(iUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y5e=n(iUe,"CODE",{});var rKt=s(Y5e);a6r=r(rKt,"model.train()"),rKt.forEach(t),iUe.forEach(t),n6r=i(Da),T(DC.$$.fragment,Da),Da.forEach(t),Ul.forEach(t),tro=i(m),Cc=n(m,"H2",{class:!0});var vao=s(Cc);GC=n(vao,"A",{id:!0,class:!0,href:!0});var tKt=s(GC);Z5e=n(tKt,"SPAN",{});var aKt=s(Z5e);T(Pk.$$.fragment,aKt),aKt.forEach(t),tKt.forEach(t),s6r=i(vao),K5e=n(vao,"SPAN",{});var nKt=s(K5e);l6r=r(nKt,"AutoModelForCTC"),nKt.forEach(t),vao.forEach(t),aro=i(m),Ko=n(m,"DIV",{class:!0});var Jl=s(Ko);T(Bk.$$.fragment,Jl),i6r=i(Jl),wc=n(Jl,"P",{});var Ede=s(wc);d6r=r(Ede,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),OK=n(Ede,"A",{href:!0});var sKt=s(OK);c6r=r(sKt,"from_pretrained()"),sKt.forEach(t),m6r=r(Ede," class method or the "),VK=n(Ede,"A",{href:!0});var lKt=s(VK);f6r=r(lKt,"from_config()"),lKt.forEach(t),g6r=r(Ede,` class
method.`),Ede.forEach(t),h6r=i(Jl),Ik=n(Jl,"P",{});var Fao=s(Ik);u6r=r(Fao,"This class cannot be instantiated directly using "),e0e=n(Fao,"CODE",{});var iKt=s(e0e);p6r=r(iKt,"__init__()"),iKt.forEach(t),_6r=r(Fao," (throws an error)."),Fao.forEach(t),b6r=i(Jl),qt=n(Jl,"DIV",{class:!0});var e9=s(qt);T(Nk.$$.fragment,e9),v6r=i(e9),o0e=n(e9,"P",{});var dKt=s(o0e);F6r=r(dKt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),dKt.forEach(t),T6r=i(e9),Ac=n(e9,"P",{});var Cde=s(Ac);M6r=r(Cde,`Note:
Loading a model from its configuration file does `),r0e=n(Cde,"STRONG",{});var cKt=s(r0e);E6r=r(cKt,"not"),cKt.forEach(t),C6r=r(Cde,` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=n(Cde,"A",{href:!0});var mKt=s(XK);w6r=r(mKt,"from_pretrained()"),mKt.forEach(t),A6r=r(Cde," to load the model weights."),Cde.forEach(t),L6r=i(e9),T(OC.$$.fragment,e9),e9.forEach(t),y6r=i(Jl),bo=n(Jl,"DIV",{class:!0});var Ga=s(bo);T(qk.$$.fragment,Ga),x6r=i(Ga),t0e=n(Ga,"P",{});var fKt=s(t0e);$6r=r(fKt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),fKt.forEach(t),k6r=i(Ga),vn=n(Ga,"P",{});var o9=s(vn);S6r=r(o9,"The model class to instantiate is selected based on the "),a0e=n(o9,"CODE",{});var gKt=s(a0e);R6r=r(gKt,"model_type"),gKt.forEach(t),P6r=r(o9,` property of the config object (either
passed as an argument or loaded from `),n0e=n(o9,"CODE",{});var hKt=s(n0e);B6r=r(hKt,"pretrained_model_name_or_path"),hKt.forEach(t),I6r=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=n(o9,"CODE",{});var uKt=s(s0e);N6r=r(uKt,"pretrained_model_name_or_path"),uKt.forEach(t),q6r=r(o9,":"),o9.forEach(t),j6r=i(Ga),Le=n(Ga,"UL",{});var Ie=s(Le);VC=n(Ie,"LI",{});var dUe=s(VC);l0e=n(dUe,"STRONG",{});var pKt=s(l0e);D6r=r(pKt,"data2vec-audio"),pKt.forEach(t),G6r=r(dUe," \u2014 "),zK=n(dUe,"A",{href:!0});var _Kt=s(zK);O6r=r(_Kt,"Data2VecAudioForCTC"),_Kt.forEach(t),V6r=r(dUe," (Data2VecAudio model)"),dUe.forEach(t),X6r=i(Ie),XC=n(Ie,"LI",{});var cUe=s(XC);i0e=n(cUe,"STRONG",{});var bKt=s(i0e);z6r=r(bKt,"hubert"),bKt.forEach(t),Q6r=r(cUe," \u2014 "),QK=n(cUe,"A",{href:!0});var vKt=s(QK);W6r=r(vKt,"HubertForCTC"),vKt.forEach(t),U6r=r(cUe," (Hubert model)"),cUe.forEach(t),H6r=i(Ie),zC=n(Ie,"LI",{});var mUe=s(zC);d0e=n(mUe,"STRONG",{});var FKt=s(d0e);J6r=r(FKt,"mctct"),FKt.forEach(t),Y6r=r(mUe," \u2014 "),WK=n(mUe,"A",{href:!0});var TKt=s(WK);Z6r=r(TKt,"MCTCTForCTC"),TKt.forEach(t),K6r=r(mUe," (M-CTC-T model)"),mUe.forEach(t),e7r=i(Ie),QC=n(Ie,"LI",{});var fUe=s(QC);c0e=n(fUe,"STRONG",{});var MKt=s(c0e);o7r=r(MKt,"sew"),MKt.forEach(t),r7r=r(fUe," \u2014 "),UK=n(fUe,"A",{href:!0});var EKt=s(UK);t7r=r(EKt,"SEWForCTC"),EKt.forEach(t),a7r=r(fUe," (SEW model)"),fUe.forEach(t),n7r=i(Ie),WC=n(Ie,"LI",{});var gUe=s(WC);m0e=n(gUe,"STRONG",{});var CKt=s(m0e);s7r=r(CKt,"sew-d"),CKt.forEach(t),l7r=r(gUe," \u2014 "),HK=n(gUe,"A",{href:!0});var wKt=s(HK);i7r=r(wKt,"SEWDForCTC"),wKt.forEach(t),d7r=r(gUe," (SEW-D model)"),gUe.forEach(t),c7r=i(Ie),UC=n(Ie,"LI",{});var hUe=s(UC);f0e=n(hUe,"STRONG",{});var AKt=s(f0e);m7r=r(AKt,"unispeech"),AKt.forEach(t),f7r=r(hUe," \u2014 "),JK=n(hUe,"A",{href:!0});var LKt=s(JK);g7r=r(LKt,"UniSpeechForCTC"),LKt.forEach(t),h7r=r(hUe," (UniSpeech model)"),hUe.forEach(t),u7r=i(Ie),HC=n(Ie,"LI",{});var uUe=s(HC);g0e=n(uUe,"STRONG",{});var yKt=s(g0e);p7r=r(yKt,"unispeech-sat"),yKt.forEach(t),_7r=r(uUe," \u2014 "),YK=n(uUe,"A",{href:!0});var xKt=s(YK);b7r=r(xKt,"UniSpeechSatForCTC"),xKt.forEach(t),v7r=r(uUe," (UniSpeechSat model)"),uUe.forEach(t),F7r=i(Ie),JC=n(Ie,"LI",{});var pUe=s(JC);h0e=n(pUe,"STRONG",{});var $Kt=s(h0e);T7r=r($Kt,"wav2vec2"),$Kt.forEach(t),M7r=r(pUe," \u2014 "),ZK=n(pUe,"A",{href:!0});var kKt=s(ZK);E7r=r(kKt,"Wav2Vec2ForCTC"),kKt.forEach(t),C7r=r(pUe," (Wav2Vec2 model)"),pUe.forEach(t),w7r=i(Ie),YC=n(Ie,"LI",{});var _Ue=s(YC);u0e=n(_Ue,"STRONG",{});var SKt=s(u0e);A7r=r(SKt,"wav2vec2-conformer"),SKt.forEach(t),L7r=r(_Ue," \u2014 "),KK=n(_Ue,"A",{href:!0});var RKt=s(KK);y7r=r(RKt,"Wav2Vec2ConformerForCTC"),RKt.forEach(t),x7r=r(_Ue," (Wav2Vec2-Conformer model)"),_Ue.forEach(t),$7r=i(Ie),ZC=n(Ie,"LI",{});var bUe=s(ZC);p0e=n(bUe,"STRONG",{});var PKt=s(p0e);k7r=r(PKt,"wavlm"),PKt.forEach(t),S7r=r(bUe," \u2014 "),eee=n(bUe,"A",{href:!0});var BKt=s(eee);R7r=r(BKt,"WavLMForCTC"),BKt.forEach(t),P7r=r(bUe," (WavLM model)"),bUe.forEach(t),Ie.forEach(t),B7r=i(Ga),KC=n(Ga,"P",{});var vUe=s(KC);I7r=r(vUe,"The model is set in evaluation mode by default using "),_0e=n(vUe,"CODE",{});var IKt=s(_0e);N7r=r(IKt,"model.eval()"),IKt.forEach(t),q7r=r(vUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b0e=n(vUe,"CODE",{});var NKt=s(b0e);j7r=r(NKt,"model.train()"),NKt.forEach(t),vUe.forEach(t),D7r=i(Ga),T(e3.$$.fragment,Ga),Ga.forEach(t),Jl.forEach(t),nro=i(m),Lc=n(m,"H2",{class:!0});var Tao=s(Lc);o3=n(Tao,"A",{id:!0,class:!0,href:!0});var qKt=s(o3);v0e=n(qKt,"SPAN",{});var jKt=s(v0e);T(jk.$$.fragment,jKt),jKt.forEach(t),qKt.forEach(t),G7r=i(Tao),F0e=n(Tao,"SPAN",{});var DKt=s(F0e);O7r=r(DKt,"AutoModelForSpeechSeq2Seq"),DKt.forEach(t),Tao.forEach(t),sro=i(m),er=n(m,"DIV",{class:!0});var Yl=s(er);T(Dk.$$.fragment,Yl),V7r=i(Yl),yc=n(Yl,"P",{});var wde=s(yc);X7r=r(wde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),oee=n(wde,"A",{href:!0});var GKt=s(oee);z7r=r(GKt,"from_pretrained()"),GKt.forEach(t),Q7r=r(wde," class method or the "),ree=n(wde,"A",{href:!0});var OKt=s(ree);W7r=r(OKt,"from_config()"),OKt.forEach(t),U7r=r(wde,` class
method.`),wde.forEach(t),H7r=i(Yl),Gk=n(Yl,"P",{});var Mao=s(Gk);J7r=r(Mao,"This class cannot be instantiated directly using "),T0e=n(Mao,"CODE",{});var VKt=s(T0e);Y7r=r(VKt,"__init__()"),VKt.forEach(t),Z7r=r(Mao," (throws an error)."),Mao.forEach(t),K7r=i(Yl),jt=n(Yl,"DIV",{class:!0});var r9=s(jt);T(Ok.$$.fragment,r9),eLr=i(r9),M0e=n(r9,"P",{});var XKt=s(M0e);oLr=r(XKt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),XKt.forEach(t),rLr=i(r9),xc=n(r9,"P",{});var Ade=s(xc);tLr=r(Ade,`Note:
Loading a model from its configuration file does `),E0e=n(Ade,"STRONG",{});var zKt=s(E0e);aLr=r(zKt,"not"),zKt.forEach(t),nLr=r(Ade,` load the model weights. It only affects the
model\u2019s configuration. Use `),tee=n(Ade,"A",{href:!0});var QKt=s(tee);sLr=r(QKt,"from_pretrained()"),QKt.forEach(t),lLr=r(Ade," to load the model weights."),Ade.forEach(t),iLr=i(r9),T(r3.$$.fragment,r9),r9.forEach(t),dLr=i(Yl),vo=n(Yl,"DIV",{class:!0});var Oa=s(vo);T(Vk.$$.fragment,Oa),cLr=i(Oa),C0e=n(Oa,"P",{});var WKt=s(C0e);mLr=r(WKt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),WKt.forEach(t),fLr=i(Oa),Fn=n(Oa,"P",{});var t9=s(Fn);gLr=r(t9,"The model class to instantiate is selected based on the "),w0e=n(t9,"CODE",{});var UKt=s(w0e);hLr=r(UKt,"model_type"),UKt.forEach(t),uLr=r(t9,` property of the config object (either
passed as an argument or loaded from `),A0e=n(t9,"CODE",{});var HKt=s(A0e);pLr=r(HKt,"pretrained_model_name_or_path"),HKt.forEach(t),_Lr=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L0e=n(t9,"CODE",{});var JKt=s(L0e);bLr=r(JKt,"pretrained_model_name_or_path"),JKt.forEach(t),vLr=r(t9,":"),t9.forEach(t),FLr=i(Oa),$c=n(Oa,"UL",{});var Lde=s($c);t3=n(Lde,"LI",{});var FUe=s(t3);y0e=n(FUe,"STRONG",{});var YKt=s(y0e);TLr=r(YKt,"speech-encoder-decoder"),YKt.forEach(t),MLr=r(FUe," \u2014 "),aee=n(FUe,"A",{href:!0});var ZKt=s(aee);ELr=r(ZKt,"SpeechEncoderDecoderModel"),ZKt.forEach(t),CLr=r(FUe," (Speech Encoder decoder model)"),FUe.forEach(t),wLr=i(Lde),a3=n(Lde,"LI",{});var TUe=s(a3);x0e=n(TUe,"STRONG",{});var KKt=s(x0e);ALr=r(KKt,"speech_to_text"),KKt.forEach(t),LLr=r(TUe," \u2014 "),nee=n(TUe,"A",{href:!0});var eea=s(nee);yLr=r(eea,"Speech2TextForConditionalGeneration"),eea.forEach(t),xLr=r(TUe," (Speech2Text model)"),TUe.forEach(t),$Lr=i(Lde),n3=n(Lde,"LI",{});var MUe=s(n3);$0e=n(MUe,"STRONG",{});var oea=s($0e);kLr=r(oea,"whisper"),oea.forEach(t),SLr=r(MUe," \u2014 "),see=n(MUe,"A",{href:!0});var rea=s(see);RLr=r(rea,"WhisperForConditionalGeneration"),rea.forEach(t),PLr=r(MUe," (Whisper model)"),MUe.forEach(t),Lde.forEach(t),BLr=i(Oa),s3=n(Oa,"P",{});var EUe=s(s3);ILr=r(EUe,"The model is set in evaluation mode by default using "),k0e=n(EUe,"CODE",{});var tea=s(k0e);NLr=r(tea,"model.eval()"),tea.forEach(t),qLr=r(EUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=n(EUe,"CODE",{});var aea=s(S0e);jLr=r(aea,"model.train()"),aea.forEach(t),EUe.forEach(t),DLr=i(Oa),T(l3.$$.fragment,Oa),Oa.forEach(t),Yl.forEach(t),lro=i(m),kc=n(m,"H2",{class:!0});var Eao=s(kc);i3=n(Eao,"A",{id:!0,class:!0,href:!0});var nea=s(i3);R0e=n(nea,"SPAN",{});var sea=s(R0e);T(Xk.$$.fragment,sea),sea.forEach(t),nea.forEach(t),GLr=i(Eao),P0e=n(Eao,"SPAN",{});var lea=s(P0e);OLr=r(lea,"AutoModelForAudioXVector"),lea.forEach(t),Eao.forEach(t),iro=i(m),or=n(m,"DIV",{class:!0});var Zl=s(or);T(zk.$$.fragment,Zl),VLr=i(Zl),Sc=n(Zl,"P",{});var yde=s(Sc);XLr=r(yde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),lee=n(yde,"A",{href:!0});var iea=s(lee);zLr=r(iea,"from_pretrained()"),iea.forEach(t),QLr=r(yde," class method or the "),iee=n(yde,"A",{href:!0});var dea=s(iee);WLr=r(dea,"from_config()"),dea.forEach(t),ULr=r(yde,` class
method.`),yde.forEach(t),HLr=i(Zl),Qk=n(Zl,"P",{});var Cao=s(Qk);JLr=r(Cao,"This class cannot be instantiated directly using "),B0e=n(Cao,"CODE",{});var cea=s(B0e);YLr=r(cea,"__init__()"),cea.forEach(t),ZLr=r(Cao," (throws an error)."),Cao.forEach(t),KLr=i(Zl),Dt=n(Zl,"DIV",{class:!0});var a9=s(Dt);T(Wk.$$.fragment,a9),eyr=i(a9),I0e=n(a9,"P",{});var mea=s(I0e);oyr=r(mea,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),mea.forEach(t),ryr=i(a9),Rc=n(a9,"P",{});var xde=s(Rc);tyr=r(xde,`Note:
Loading a model from its configuration file does `),N0e=n(xde,"STRONG",{});var fea=s(N0e);ayr=r(fea,"not"),fea.forEach(t),nyr=r(xde,` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=n(xde,"A",{href:!0});var gea=s(dee);syr=r(gea,"from_pretrained()"),gea.forEach(t),lyr=r(xde," to load the model weights."),xde.forEach(t),iyr=i(a9),T(d3.$$.fragment,a9),a9.forEach(t),dyr=i(Zl),Fo=n(Zl,"DIV",{class:!0});var Va=s(Fo);T(Uk.$$.fragment,Va),cyr=i(Va),q0e=n(Va,"P",{});var hea=s(q0e);myr=r(hea,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),hea.forEach(t),fyr=i(Va),Tn=n(Va,"P",{});var n9=s(Tn);gyr=r(n9,"The model class to instantiate is selected based on the "),j0e=n(n9,"CODE",{});var uea=s(j0e);hyr=r(uea,"model_type"),uea.forEach(t),uyr=r(n9,` property of the config object (either
passed as an argument or loaded from `),D0e=n(n9,"CODE",{});var pea=s(D0e);pyr=r(pea,"pretrained_model_name_or_path"),pea.forEach(t),_yr=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=n(n9,"CODE",{});var _ea=s(G0e);byr=r(_ea,"pretrained_model_name_or_path"),_ea.forEach(t),vyr=r(n9,":"),n9.forEach(t),Fyr=i(Va),ht=n(Va,"UL",{});var Kl=s(ht);c3=n(Kl,"LI",{});var CUe=s(c3);O0e=n(CUe,"STRONG",{});var bea=s(O0e);Tyr=r(bea,"data2vec-audio"),bea.forEach(t),Myr=r(CUe," \u2014 "),cee=n(CUe,"A",{href:!0});var vea=s(cee);Eyr=r(vea,"Data2VecAudioForXVector"),vea.forEach(t),Cyr=r(CUe," (Data2VecAudio model)"),CUe.forEach(t),wyr=i(Kl),m3=n(Kl,"LI",{});var wUe=s(m3);V0e=n(wUe,"STRONG",{});var Fea=s(V0e);Ayr=r(Fea,"unispeech-sat"),Fea.forEach(t),Lyr=r(wUe," \u2014 "),mee=n(wUe,"A",{href:!0});var Tea=s(mee);yyr=r(Tea,"UniSpeechSatForXVector"),Tea.forEach(t),xyr=r(wUe," (UniSpeechSat model)"),wUe.forEach(t),$yr=i(Kl),f3=n(Kl,"LI",{});var AUe=s(f3);X0e=n(AUe,"STRONG",{});var Mea=s(X0e);kyr=r(Mea,"wav2vec2"),Mea.forEach(t),Syr=r(AUe," \u2014 "),fee=n(AUe,"A",{href:!0});var Eea=s(fee);Ryr=r(Eea,"Wav2Vec2ForXVector"),Eea.forEach(t),Pyr=r(AUe," (Wav2Vec2 model)"),AUe.forEach(t),Byr=i(Kl),g3=n(Kl,"LI",{});var LUe=s(g3);z0e=n(LUe,"STRONG",{});var Cea=s(z0e);Iyr=r(Cea,"wav2vec2-conformer"),Cea.forEach(t),Nyr=r(LUe," \u2014 "),gee=n(LUe,"A",{href:!0});var wea=s(gee);qyr=r(wea,"Wav2Vec2ConformerForXVector"),wea.forEach(t),jyr=r(LUe," (Wav2Vec2-Conformer model)"),LUe.forEach(t),Dyr=i(Kl),h3=n(Kl,"LI",{});var yUe=s(h3);Q0e=n(yUe,"STRONG",{});var Aea=s(Q0e);Gyr=r(Aea,"wavlm"),Aea.forEach(t),Oyr=r(yUe," \u2014 "),hee=n(yUe,"A",{href:!0});var Lea=s(hee);Vyr=r(Lea,"WavLMForXVector"),Lea.forEach(t),Xyr=r(yUe," (WavLM model)"),yUe.forEach(t),Kl.forEach(t),zyr=i(Va),u3=n(Va,"P",{});var xUe=s(u3);Qyr=r(xUe,"The model is set in evaluation mode by default using "),W0e=n(xUe,"CODE",{});var yea=s(W0e);Wyr=r(yea,"model.eval()"),yea.forEach(t),Uyr=r(xUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U0e=n(xUe,"CODE",{});var xea=s(U0e);Hyr=r(xea,"model.train()"),xea.forEach(t),xUe.forEach(t),Jyr=i(Va),T(p3.$$.fragment,Va),Va.forEach(t),Zl.forEach(t),dro=i(m),Pc=n(m,"H2",{class:!0});var wao=s(Pc);_3=n(wao,"A",{id:!0,class:!0,href:!0});var $ea=s(_3);H0e=n($ea,"SPAN",{});var kea=s(H0e);T(Hk.$$.fragment,kea),kea.forEach(t),$ea.forEach(t),Yyr=i(wao),J0e=n(wao,"SPAN",{});var Sea=s(J0e);Zyr=r(Sea,"AutoModelForMaskedImageModeling"),Sea.forEach(t),wao.forEach(t),cro=i(m),rr=n(m,"DIV",{class:!0});var ei=s(rr);T(Jk.$$.fragment,ei),Kyr=i(ei),Bc=n(ei,"P",{});var $de=s(Bc);e8r=r($de,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),uee=n($de,"A",{href:!0});var Rea=s(uee);o8r=r(Rea,"from_pretrained()"),Rea.forEach(t),r8r=r($de," class method or the "),pee=n($de,"A",{href:!0});var Pea=s(pee);t8r=r(Pea,"from_config()"),Pea.forEach(t),a8r=r($de,` class
method.`),$de.forEach(t),n8r=i(ei),Yk=n(ei,"P",{});var Aao=s(Yk);s8r=r(Aao,"This class cannot be instantiated directly using "),Y0e=n(Aao,"CODE",{});var Bea=s(Y0e);l8r=r(Bea,"__init__()"),Bea.forEach(t),i8r=r(Aao," (throws an error)."),Aao.forEach(t),d8r=i(ei),Gt=n(ei,"DIV",{class:!0});var s9=s(Gt);T(Zk.$$.fragment,s9),c8r=i(s9),Z0e=n(s9,"P",{});var Iea=s(Z0e);m8r=r(Iea,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Iea.forEach(t),f8r=i(s9),Ic=n(s9,"P",{});var kde=s(Ic);g8r=r(kde,`Note:
Loading a model from its configuration file does `),K0e=n(kde,"STRONG",{});var Nea=s(K0e);h8r=r(Nea,"not"),Nea.forEach(t),u8r=r(kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=n(kde,"A",{href:!0});var qea=s(_ee);p8r=r(qea,"from_pretrained()"),qea.forEach(t),_8r=r(kde," to load the model weights."),kde.forEach(t),b8r=i(s9),T(b3.$$.fragment,s9),s9.forEach(t),v8r=i(ei),To=n(ei,"DIV",{class:!0});var Xa=s(To);T(Kk.$$.fragment,Xa),F8r=i(Xa),ewe=n(Xa,"P",{});var jea=s(ewe);T8r=r(jea,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),jea.forEach(t),M8r=i(Xa),Mn=n(Xa,"P",{});var l9=s(Mn);E8r=r(l9,"The model class to instantiate is selected based on the "),owe=n(l9,"CODE",{});var Dea=s(owe);C8r=r(Dea,"model_type"),Dea.forEach(t),w8r=r(l9,` property of the config object (either
passed as an argument or loaded from `),rwe=n(l9,"CODE",{});var Gea=s(rwe);A8r=r(Gea,"pretrained_model_name_or_path"),Gea.forEach(t),L8r=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),twe=n(l9,"CODE",{});var Oea=s(twe);y8r=r(Oea,"pretrained_model_name_or_path"),Oea.forEach(t),x8r=r(l9,":"),l9.forEach(t),$8r=i(Xa),En=n(Xa,"UL",{});var i9=s(En);v3=n(i9,"LI",{});var $Ue=s(v3);awe=n($Ue,"STRONG",{});var Vea=s(awe);k8r=r(Vea,"deit"),Vea.forEach(t),S8r=r($Ue," \u2014 "),bee=n($Ue,"A",{href:!0});var Xea=s(bee);R8r=r(Xea,"DeiTForMaskedImageModeling"),Xea.forEach(t),P8r=r($Ue," (DeiT model)"),$Ue.forEach(t),B8r=i(i9),F3=n(i9,"LI",{});var kUe=s(F3);nwe=n(kUe,"STRONG",{});var zea=s(nwe);I8r=r(zea,"swin"),zea.forEach(t),N8r=r(kUe," \u2014 "),vee=n(kUe,"A",{href:!0});var Qea=s(vee);q8r=r(Qea,"SwinForMaskedImageModeling"),Qea.forEach(t),j8r=r(kUe," (Swin Transformer model)"),kUe.forEach(t),D8r=i(i9),T3=n(i9,"LI",{});var SUe=s(T3);swe=n(SUe,"STRONG",{});var Wea=s(swe);G8r=r(Wea,"swinv2"),Wea.forEach(t),O8r=r(SUe," \u2014 "),Fee=n(SUe,"A",{href:!0});var Uea=s(Fee);V8r=r(Uea,"Swinv2ForMaskedImageModeling"),Uea.forEach(t),X8r=r(SUe," (Swin Transformer V2 model)"),SUe.forEach(t),z8r=i(i9),M3=n(i9,"LI",{});var RUe=s(M3);lwe=n(RUe,"STRONG",{});var Hea=s(lwe);Q8r=r(Hea,"vit"),Hea.forEach(t),W8r=r(RUe," \u2014 "),Tee=n(RUe,"A",{href:!0});var Jea=s(Tee);U8r=r(Jea,"ViTForMaskedImageModeling"),Jea.forEach(t),H8r=r(RUe," (ViT model)"),RUe.forEach(t),i9.forEach(t),J8r=i(Xa),E3=n(Xa,"P",{});var PUe=s(E3);Y8r=r(PUe,"The model is set in evaluation mode by default using "),iwe=n(PUe,"CODE",{});var Yea=s(iwe);Z8r=r(Yea,"model.eval()"),Yea.forEach(t),K8r=r(PUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dwe=n(PUe,"CODE",{});var Zea=s(dwe);e9r=r(Zea,"model.train()"),Zea.forEach(t),PUe.forEach(t),o9r=i(Xa),T(C3.$$.fragment,Xa),Xa.forEach(t),ei.forEach(t),mro=i(m),Nc=n(m,"H2",{class:!0});var Lao=s(Nc);w3=n(Lao,"A",{id:!0,class:!0,href:!0});var Kea=s(w3);cwe=n(Kea,"SPAN",{});var eoa=s(cwe);T(eS.$$.fragment,eoa),eoa.forEach(t),Kea.forEach(t),r9r=i(Lao),mwe=n(Lao,"SPAN",{});var ooa=s(mwe);t9r=r(ooa,"AutoModelForObjectDetection"),ooa.forEach(t),Lao.forEach(t),fro=i(m),tr=n(m,"DIV",{class:!0});var oi=s(tr);T(oS.$$.fragment,oi),a9r=i(oi),qc=n(oi,"P",{});var Sde=s(qc);n9r=r(Sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Mee=n(Sde,"A",{href:!0});var roa=s(Mee);s9r=r(roa,"from_pretrained()"),roa.forEach(t),l9r=r(Sde," class method or the "),Eee=n(Sde,"A",{href:!0});var toa=s(Eee);i9r=r(toa,"from_config()"),toa.forEach(t),d9r=r(Sde,` class
method.`),Sde.forEach(t),c9r=i(oi),rS=n(oi,"P",{});var yao=s(rS);m9r=r(yao,"This class cannot be instantiated directly using "),fwe=n(yao,"CODE",{});var aoa=s(fwe);f9r=r(aoa,"__init__()"),aoa.forEach(t),g9r=r(yao," (throws an error)."),yao.forEach(t),h9r=i(oi),Ot=n(oi,"DIV",{class:!0});var d9=s(Ot);T(tS.$$.fragment,d9),u9r=i(d9),gwe=n(d9,"P",{});var noa=s(gwe);p9r=r(noa,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),noa.forEach(t),_9r=i(d9),jc=n(d9,"P",{});var Rde=s(jc);b9r=r(Rde,`Note:
Loading a model from its configuration file does `),hwe=n(Rde,"STRONG",{});var soa=s(hwe);v9r=r(soa,"not"),soa.forEach(t),F9r=r(Rde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cee=n(Rde,"A",{href:!0});var loa=s(Cee);T9r=r(loa,"from_pretrained()"),loa.forEach(t),M9r=r(Rde," to load the model weights."),Rde.forEach(t),E9r=i(d9),T(A3.$$.fragment,d9),d9.forEach(t),C9r=i(oi),Mo=n(oi,"DIV",{class:!0});var za=s(Mo);T(aS.$$.fragment,za),w9r=i(za),uwe=n(za,"P",{});var ioa=s(uwe);A9r=r(ioa,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),ioa.forEach(t),L9r=i(za),Cn=n(za,"P",{});var c9=s(Cn);y9r=r(c9,"The model class to instantiate is selected based on the "),pwe=n(c9,"CODE",{});var doa=s(pwe);x9r=r(doa,"model_type"),doa.forEach(t),$9r=r(c9,` property of the config object (either
passed as an argument or loaded from `),_we=n(c9,"CODE",{});var coa=s(_we);k9r=r(coa,"pretrained_model_name_or_path"),coa.forEach(t),S9r=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bwe=n(c9,"CODE",{});var moa=s(bwe);R9r=r(moa,"pretrained_model_name_or_path"),moa.forEach(t),P9r=r(c9,":"),c9.forEach(t),B9r=i(za),wn=n(za,"UL",{});var m9=s(wn);L3=n(m9,"LI",{});var BUe=s(L3);vwe=n(BUe,"STRONG",{});var foa=s(vwe);I9r=r(foa,"conditional_detr"),foa.forEach(t),N9r=r(BUe," \u2014 "),wee=n(BUe,"A",{href:!0});var goa=s(wee);q9r=r(goa,"ConditionalDetrForObjectDetection"),goa.forEach(t),j9r=r(BUe," (Conditional DETR model)"),BUe.forEach(t),D9r=i(m9),y3=n(m9,"LI",{});var IUe=s(y3);Fwe=n(IUe,"STRONG",{});var hoa=s(Fwe);G9r=r(hoa,"deformable_detr"),hoa.forEach(t),O9r=r(IUe," \u2014 "),Aee=n(IUe,"A",{href:!0});var uoa=s(Aee);V9r=r(uoa,"DeformableDetrForObjectDetection"),uoa.forEach(t),X9r=r(IUe," (Deformable DETR model)"),IUe.forEach(t),z9r=i(m9),x3=n(m9,"LI",{});var NUe=s(x3);Twe=n(NUe,"STRONG",{});var poa=s(Twe);Q9r=r(poa,"detr"),poa.forEach(t),W9r=r(NUe," \u2014 "),Lee=n(NUe,"A",{href:!0});var _oa=s(Lee);U9r=r(_oa,"DetrForObjectDetection"),_oa.forEach(t),H9r=r(NUe," (DETR model)"),NUe.forEach(t),J9r=i(m9),$3=n(m9,"LI",{});var qUe=s($3);Mwe=n(qUe,"STRONG",{});var boa=s(Mwe);Y9r=r(boa,"yolos"),boa.forEach(t),Z9r=r(qUe," \u2014 "),yee=n(qUe,"A",{href:!0});var voa=s(yee);K9r=r(voa,"YolosForObjectDetection"),voa.forEach(t),exr=r(qUe," (YOLOS model)"),qUe.forEach(t),m9.forEach(t),oxr=i(za),k3=n(za,"P",{});var jUe=s(k3);rxr=r(jUe,"The model is set in evaluation mode by default using "),Ewe=n(jUe,"CODE",{});var Foa=s(Ewe);txr=r(Foa,"model.eval()"),Foa.forEach(t),axr=r(jUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cwe=n(jUe,"CODE",{});var Toa=s(Cwe);nxr=r(Toa,"model.train()"),Toa.forEach(t),jUe.forEach(t),sxr=i(za),T(S3.$$.fragment,za),za.forEach(t),oi.forEach(t),gro=i(m),Dc=n(m,"H2",{class:!0});var xao=s(Dc);R3=n(xao,"A",{id:!0,class:!0,href:!0});var Moa=s(R3);wwe=n(Moa,"SPAN",{});var Eoa=s(wwe);T(nS.$$.fragment,Eoa),Eoa.forEach(t),Moa.forEach(t),lxr=i(xao),Awe=n(xao,"SPAN",{});var Coa=s(Awe);ixr=r(Coa,"AutoModelForImageSegmentation"),Coa.forEach(t),xao.forEach(t),hro=i(m),ar=n(m,"DIV",{class:!0});var ri=s(ar);T(sS.$$.fragment,ri),dxr=i(ri),Gc=n(ri,"P",{});var Pde=s(Gc);cxr=r(Pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),xee=n(Pde,"A",{href:!0});var woa=s(xee);mxr=r(woa,"from_pretrained()"),woa.forEach(t),fxr=r(Pde," class method or the "),$ee=n(Pde,"A",{href:!0});var Aoa=s($ee);gxr=r(Aoa,"from_config()"),Aoa.forEach(t),hxr=r(Pde,` class
method.`),Pde.forEach(t),uxr=i(ri),lS=n(ri,"P",{});var $ao=s(lS);pxr=r($ao,"This class cannot be instantiated directly using "),Lwe=n($ao,"CODE",{});var Loa=s(Lwe);_xr=r(Loa,"__init__()"),Loa.forEach(t),bxr=r($ao," (throws an error)."),$ao.forEach(t),vxr=i(ri),Vt=n(ri,"DIV",{class:!0});var f9=s(Vt);T(iS.$$.fragment,f9),Fxr=i(f9),ywe=n(f9,"P",{});var yoa=s(ywe);Txr=r(yoa,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),yoa.forEach(t),Mxr=i(f9),Oc=n(f9,"P",{});var Bde=s(Oc);Exr=r(Bde,`Note:
Loading a model from its configuration file does `),xwe=n(Bde,"STRONG",{});var xoa=s(xwe);Cxr=r(xoa,"not"),xoa.forEach(t),wxr=r(Bde,` load the model weights. It only affects the
model\u2019s configuration. Use `),kee=n(Bde,"A",{href:!0});var $oa=s(kee);Axr=r($oa,"from_pretrained()"),$oa.forEach(t),Lxr=r(Bde," to load the model weights."),Bde.forEach(t),yxr=i(f9),T(P3.$$.fragment,f9),f9.forEach(t),xxr=i(ri),Eo=n(ri,"DIV",{class:!0});var Qa=s(Eo);T(dS.$$.fragment,Qa),$xr=i(Qa),$we=n(Qa,"P",{});var koa=s($we);kxr=r(koa,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),koa.forEach(t),Sxr=i(Qa),An=n(Qa,"P",{});var g9=s(An);Rxr=r(g9,"The model class to instantiate is selected based on the "),kwe=n(g9,"CODE",{});var Soa=s(kwe);Pxr=r(Soa,"model_type"),Soa.forEach(t),Bxr=r(g9,` property of the config object (either
passed as an argument or loaded from `),Swe=n(g9,"CODE",{});var Roa=s(Swe);Ixr=r(Roa,"pretrained_model_name_or_path"),Roa.forEach(t),Nxr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=n(g9,"CODE",{});var Poa=s(Rwe);qxr=r(Poa,"pretrained_model_name_or_path"),Poa.forEach(t),jxr=r(g9,":"),g9.forEach(t),Dxr=i(Qa),Pwe=n(Qa,"UL",{});var Boa=s(Pwe);B3=n(Boa,"LI",{});var DUe=s(B3);Bwe=n(DUe,"STRONG",{});var Ioa=s(Bwe);Gxr=r(Ioa,"detr"),Ioa.forEach(t),Oxr=r(DUe," \u2014 "),See=n(DUe,"A",{href:!0});var Noa=s(See);Vxr=r(Noa,"DetrForSegmentation"),Noa.forEach(t),Xxr=r(DUe," (DETR model)"),DUe.forEach(t),Boa.forEach(t),zxr=i(Qa),I3=n(Qa,"P",{});var GUe=s(I3);Qxr=r(GUe,"The model is set in evaluation mode by default using "),Iwe=n(GUe,"CODE",{});var qoa=s(Iwe);Wxr=r(qoa,"model.eval()"),qoa.forEach(t),Uxr=r(GUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nwe=n(GUe,"CODE",{});var joa=s(Nwe);Hxr=r(joa,"model.train()"),joa.forEach(t),GUe.forEach(t),Jxr=i(Qa),T(N3.$$.fragment,Qa),Qa.forEach(t),ri.forEach(t),uro=i(m),Vc=n(m,"H2",{class:!0});var kao=s(Vc);q3=n(kao,"A",{id:!0,class:!0,href:!0});var Doa=s(q3);qwe=n(Doa,"SPAN",{});var Goa=s(qwe);T(cS.$$.fragment,Goa),Goa.forEach(t),Doa.forEach(t),Yxr=i(kao),jwe=n(kao,"SPAN",{});var Ooa=s(jwe);Zxr=r(Ooa,"AutoModelForSemanticSegmentation"),Ooa.forEach(t),kao.forEach(t),pro=i(m),nr=n(m,"DIV",{class:!0});var ti=s(nr);T(mS.$$.fragment,ti),Kxr=i(ti),Xc=n(ti,"P",{});var Ide=s(Xc);e$r=r(Ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Ree=n(Ide,"A",{href:!0});var Voa=s(Ree);o$r=r(Voa,"from_pretrained()"),Voa.forEach(t),r$r=r(Ide," class method or the "),Pee=n(Ide,"A",{href:!0});var Xoa=s(Pee);t$r=r(Xoa,"from_config()"),Xoa.forEach(t),a$r=r(Ide,` class
method.`),Ide.forEach(t),n$r=i(ti),fS=n(ti,"P",{});var Sao=s(fS);s$r=r(Sao,"This class cannot be instantiated directly using "),Dwe=n(Sao,"CODE",{});var zoa=s(Dwe);l$r=r(zoa,"__init__()"),zoa.forEach(t),i$r=r(Sao," (throws an error)."),Sao.forEach(t),d$r=i(ti),Xt=n(ti,"DIV",{class:!0});var h9=s(Xt);T(gS.$$.fragment,h9),c$r=i(h9),Gwe=n(h9,"P",{});var Qoa=s(Gwe);m$r=r(Qoa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Qoa.forEach(t),f$r=i(h9),zc=n(h9,"P",{});var Nde=s(zc);g$r=r(Nde,`Note:
Loading a model from its configuration file does `),Owe=n(Nde,"STRONG",{});var Woa=s(Owe);h$r=r(Woa,"not"),Woa.forEach(t),u$r=r(Nde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=n(Nde,"A",{href:!0});var Uoa=s(Bee);p$r=r(Uoa,"from_pretrained()"),Uoa.forEach(t),_$r=r(Nde," to load the model weights."),Nde.forEach(t),b$r=i(h9),T(j3.$$.fragment,h9),h9.forEach(t),v$r=i(ti),Co=n(ti,"DIV",{class:!0});var Wa=s(Co);T(hS.$$.fragment,Wa),F$r=i(Wa),Vwe=n(Wa,"P",{});var Hoa=s(Vwe);T$r=r(Hoa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Hoa.forEach(t),M$r=i(Wa),Ln=n(Wa,"P",{});var u9=s(Ln);E$r=r(u9,"The model class to instantiate is selected based on the "),Xwe=n(u9,"CODE",{});var Joa=s(Xwe);C$r=r(Joa,"model_type"),Joa.forEach(t),w$r=r(u9,` property of the config object (either
passed as an argument or loaded from `),zwe=n(u9,"CODE",{});var Yoa=s(zwe);A$r=r(Yoa,"pretrained_model_name_or_path"),Yoa.forEach(t),L$r=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qwe=n(u9,"CODE",{});var Zoa=s(Qwe);y$r=r(Zoa,"pretrained_model_name_or_path"),Zoa.forEach(t),x$r=r(u9,":"),u9.forEach(t),$$r=i(Wa),ut=n(Wa,"UL",{});var ai=s(ut);D3=n(ai,"LI",{});var OUe=s(D3);Wwe=n(OUe,"STRONG",{});var Koa=s(Wwe);k$r=r(Koa,"beit"),Koa.forEach(t),S$r=r(OUe," \u2014 "),Iee=n(OUe,"A",{href:!0});var era=s(Iee);R$r=r(era,"BeitForSemanticSegmentation"),era.forEach(t),P$r=r(OUe," (BEiT model)"),OUe.forEach(t),B$r=i(ai),G3=n(ai,"LI",{});var VUe=s(G3);Uwe=n(VUe,"STRONG",{});var ora=s(Uwe);I$r=r(ora,"data2vec-vision"),ora.forEach(t),N$r=r(VUe," \u2014 "),Nee=n(VUe,"A",{href:!0});var rra=s(Nee);q$r=r(rra,"Data2VecVisionForSemanticSegmentation"),rra.forEach(t),j$r=r(VUe," (Data2VecVision model)"),VUe.forEach(t),D$r=i(ai),O3=n(ai,"LI",{});var XUe=s(O3);Hwe=n(XUe,"STRONG",{});var tra=s(Hwe);G$r=r(tra,"dpt"),tra.forEach(t),O$r=r(XUe," \u2014 "),qee=n(XUe,"A",{href:!0});var ara=s(qee);V$r=r(ara,"DPTForSemanticSegmentation"),ara.forEach(t),X$r=r(XUe," (DPT model)"),XUe.forEach(t),z$r=i(ai),V3=n(ai,"LI",{});var zUe=s(V3);Jwe=n(zUe,"STRONG",{});var nra=s(Jwe);Q$r=r(nra,"mobilevit"),nra.forEach(t),W$r=r(zUe," \u2014 "),jee=n(zUe,"A",{href:!0});var sra=s(jee);U$r=r(sra,"MobileViTForSemanticSegmentation"),sra.forEach(t),H$r=r(zUe," (MobileViT model)"),zUe.forEach(t),J$r=i(ai),X3=n(ai,"LI",{});var QUe=s(X3);Ywe=n(QUe,"STRONG",{});var lra=s(Ywe);Y$r=r(lra,"segformer"),lra.forEach(t),Z$r=r(QUe," \u2014 "),Dee=n(QUe,"A",{href:!0});var ira=s(Dee);K$r=r(ira,"SegformerForSemanticSegmentation"),ira.forEach(t),ekr=r(QUe," (SegFormer model)"),QUe.forEach(t),ai.forEach(t),okr=i(Wa),z3=n(Wa,"P",{});var WUe=s(z3);rkr=r(WUe,"The model is set in evaluation mode by default using "),Zwe=n(WUe,"CODE",{});var dra=s(Zwe);tkr=r(dra,"model.eval()"),dra.forEach(t),akr=r(WUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kwe=n(WUe,"CODE",{});var cra=s(Kwe);nkr=r(cra,"model.train()"),cra.forEach(t),WUe.forEach(t),skr=i(Wa),T(Q3.$$.fragment,Wa),Wa.forEach(t),ti.forEach(t),_ro=i(m),Qc=n(m,"H2",{class:!0});var Rao=s(Qc);W3=n(Rao,"A",{id:!0,class:!0,href:!0});var mra=s(W3);eAe=n(mra,"SPAN",{});var fra=s(eAe);T(uS.$$.fragment,fra),fra.forEach(t),mra.forEach(t),lkr=i(Rao),oAe=n(Rao,"SPAN",{});var gra=s(oAe);ikr=r(gra,"AutoModelForInstanceSegmentation"),gra.forEach(t),Rao.forEach(t),bro=i(m),sr=n(m,"DIV",{class:!0});var ni=s(sr);T(pS.$$.fragment,ni),dkr=i(ni),Wc=n(ni,"P",{});var qde=s(Wc);ckr=r(qde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Gee=n(qde,"A",{href:!0});var hra=s(Gee);mkr=r(hra,"from_pretrained()"),hra.forEach(t),fkr=r(qde," class method or the "),Oee=n(qde,"A",{href:!0});var ura=s(Oee);gkr=r(ura,"from_config()"),ura.forEach(t),hkr=r(qde,` class
method.`),qde.forEach(t),ukr=i(ni),_S=n(ni,"P",{});var Pao=s(_S);pkr=r(Pao,"This class cannot be instantiated directly using "),rAe=n(Pao,"CODE",{});var pra=s(rAe);_kr=r(pra,"__init__()"),pra.forEach(t),bkr=r(Pao," (throws an error)."),Pao.forEach(t),vkr=i(ni),zt=n(ni,"DIV",{class:!0});var p9=s(zt);T(bS.$$.fragment,p9),Fkr=i(p9),tAe=n(p9,"P",{});var _ra=s(tAe);Tkr=r(_ra,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),_ra.forEach(t),Mkr=i(p9),Uc=n(p9,"P",{});var jde=s(Uc);Ekr=r(jde,`Note:
Loading a model from its configuration file does `),aAe=n(jde,"STRONG",{});var bra=s(aAe);Ckr=r(bra,"not"),bra.forEach(t),wkr=r(jde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=n(jde,"A",{href:!0});var vra=s(Vee);Akr=r(vra,"from_pretrained()"),vra.forEach(t),Lkr=r(jde," to load the model weights."),jde.forEach(t),ykr=i(p9),T(U3.$$.fragment,p9),p9.forEach(t),xkr=i(ni),wo=n(ni,"DIV",{class:!0});var Ua=s(wo);T(vS.$$.fragment,Ua),$kr=i(Ua),nAe=n(Ua,"P",{});var Fra=s(nAe);kkr=r(Fra,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Fra.forEach(t),Skr=i(Ua),yn=n(Ua,"P",{});var _9=s(yn);Rkr=r(_9,"The model class to instantiate is selected based on the "),sAe=n(_9,"CODE",{});var Tra=s(sAe);Pkr=r(Tra,"model_type"),Tra.forEach(t),Bkr=r(_9,` property of the config object (either
passed as an argument or loaded from `),lAe=n(_9,"CODE",{});var Mra=s(lAe);Ikr=r(Mra,"pretrained_model_name_or_path"),Mra.forEach(t),Nkr=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iAe=n(_9,"CODE",{});var Era=s(iAe);qkr=r(Era,"pretrained_model_name_or_path"),Era.forEach(t),jkr=r(_9,":"),_9.forEach(t),Dkr=i(Ua),dAe=n(Ua,"UL",{});var Cra=s(dAe);H3=n(Cra,"LI",{});var UUe=s(H3);cAe=n(UUe,"STRONG",{});var wra=s(cAe);Gkr=r(wra,"maskformer"),wra.forEach(t),Okr=r(UUe," \u2014 "),Xee=n(UUe,"A",{href:!0});var Ara=s(Xee);Vkr=r(Ara,"MaskFormerForInstanceSegmentation"),Ara.forEach(t),Xkr=r(UUe," (MaskFormer model)"),UUe.forEach(t),Cra.forEach(t),zkr=i(Ua),J3=n(Ua,"P",{});var HUe=s(J3);Qkr=r(HUe,"The model is set in evaluation mode by default using "),mAe=n(HUe,"CODE",{});var Lra=s(mAe);Wkr=r(Lra,"model.eval()"),Lra.forEach(t),Ukr=r(HUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fAe=n(HUe,"CODE",{});var yra=s(fAe);Hkr=r(yra,"model.train()"),yra.forEach(t),HUe.forEach(t),Jkr=i(Ua),T(Y3.$$.fragment,Ua),Ua.forEach(t),ni.forEach(t),vro=i(m),Hc=n(m,"H2",{class:!0});var Bao=s(Hc);Z3=n(Bao,"A",{id:!0,class:!0,href:!0});var xra=s(Z3);gAe=n(xra,"SPAN",{});var $ra=s(gAe);T(FS.$$.fragment,$ra),$ra.forEach(t),xra.forEach(t),Ykr=i(Bao),hAe=n(Bao,"SPAN",{});var kra=s(hAe);Zkr=r(kra,"AutoModelForZeroShotObjectDetection"),kra.forEach(t),Bao.forEach(t),Fro=i(m),lr=n(m,"DIV",{class:!0});var si=s(lr);T(TS.$$.fragment,si),Kkr=i(si),Jc=n(si,"P",{});var Dde=s(Jc);eSr=r(Dde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),zee=n(Dde,"A",{href:!0});var Sra=s(zee);oSr=r(Sra,"from_pretrained()"),Sra.forEach(t),rSr=r(Dde," class method or the "),Qee=n(Dde,"A",{href:!0});var Rra=s(Qee);tSr=r(Rra,"from_config()"),Rra.forEach(t),aSr=r(Dde,` class
method.`),Dde.forEach(t),nSr=i(si),MS=n(si,"P",{});var Iao=s(MS);sSr=r(Iao,"This class cannot be instantiated directly using "),uAe=n(Iao,"CODE",{});var Pra=s(uAe);lSr=r(Pra,"__init__()"),Pra.forEach(t),iSr=r(Iao," (throws an error)."),Iao.forEach(t),dSr=i(si),Qt=n(si,"DIV",{class:!0});var b9=s(Qt);T(ES.$$.fragment,b9),cSr=i(b9),pAe=n(b9,"P",{});var Bra=s(pAe);mSr=r(Bra,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),Bra.forEach(t),fSr=i(b9),Yc=n(b9,"P",{});var Gde=s(Yc);gSr=r(Gde,`Note:
Loading a model from its configuration file does `),_Ae=n(Gde,"STRONG",{});var Ira=s(_Ae);hSr=r(Ira,"not"),Ira.forEach(t),uSr=r(Gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wee=n(Gde,"A",{href:!0});var Nra=s(Wee);pSr=r(Nra,"from_pretrained()"),Nra.forEach(t),_Sr=r(Gde," to load the model weights."),Gde.forEach(t),bSr=i(b9),T(K3.$$.fragment,b9),b9.forEach(t),vSr=i(si),Ao=n(si,"DIV",{class:!0});var Ha=s(Ao);T(CS.$$.fragment,Ha),FSr=i(Ha),bAe=n(Ha,"P",{});var qra=s(bAe);TSr=r(qra,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),qra.forEach(t),MSr=i(Ha),xn=n(Ha,"P",{});var v9=s(xn);ESr=r(v9,"The model class to instantiate is selected based on the "),vAe=n(v9,"CODE",{});var jra=s(vAe);CSr=r(jra,"model_type"),jra.forEach(t),wSr=r(v9,` property of the config object (either
passed as an argument or loaded from `),FAe=n(v9,"CODE",{});var Dra=s(FAe);ASr=r(Dra,"pretrained_model_name_or_path"),Dra.forEach(t),LSr=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TAe=n(v9,"CODE",{});var Gra=s(TAe);ySr=r(Gra,"pretrained_model_name_or_path"),Gra.forEach(t),xSr=r(v9,":"),v9.forEach(t),$Sr=i(Ha),MAe=n(Ha,"UL",{});var Ora=s(MAe);e5=n(Ora,"LI",{});var JUe=s(e5);EAe=n(JUe,"STRONG",{});var Vra=s(EAe);kSr=r(Vra,"owlvit"),Vra.forEach(t),SSr=r(JUe," \u2014 "),Uee=n(JUe,"A",{href:!0});var Xra=s(Uee);RSr=r(Xra,"OwlViTForObjectDetection"),Xra.forEach(t),PSr=r(JUe," (OWL-ViT model)"),JUe.forEach(t),Ora.forEach(t),BSr=i(Ha),o5=n(Ha,"P",{});var YUe=s(o5);ISr=r(YUe,"The model is set in evaluation mode by default using "),CAe=n(YUe,"CODE",{});var zra=s(CAe);NSr=r(zra,"model.eval()"),zra.forEach(t),qSr=r(YUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wAe=n(YUe,"CODE",{});var Qra=s(wAe);jSr=r(Qra,"model.train()"),Qra.forEach(t),YUe.forEach(t),DSr=i(Ha),T(r5.$$.fragment,Ha),Ha.forEach(t),si.forEach(t),Tro=i(m),Zc=n(m,"H2",{class:!0});var Nao=s(Zc);t5=n(Nao,"A",{id:!0,class:!0,href:!0});var Wra=s(t5);AAe=n(Wra,"SPAN",{});var Ura=s(AAe);T(wS.$$.fragment,Ura),Ura.forEach(t),Wra.forEach(t),GSr=i(Nao),LAe=n(Nao,"SPAN",{});var Hra=s(LAe);OSr=r(Hra,"TFAutoModel"),Hra.forEach(t),Nao.forEach(t),Mro=i(m),ir=n(m,"DIV",{class:!0});var li=s(ir);T(AS.$$.fragment,li),VSr=i(li),Kc=n(li,"P",{});var Ode=s(Kc);XSr=r(Ode,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Hee=n(Ode,"A",{href:!0});var Jra=s(Hee);zSr=r(Jra,"from_pretrained()"),Jra.forEach(t),QSr=r(Ode," class method or the "),Jee=n(Ode,"A",{href:!0});var Yra=s(Jee);WSr=r(Yra,"from_config()"),Yra.forEach(t),USr=r(Ode,` class
method.`),Ode.forEach(t),HSr=i(li),LS=n(li,"P",{});var qao=s(LS);JSr=r(qao,"This class cannot be instantiated directly using "),yAe=n(qao,"CODE",{});var Zra=s(yAe);YSr=r(Zra,"__init__()"),Zra.forEach(t),ZSr=r(qao," (throws an error)."),qao.forEach(t),KSr=i(li),Wt=n(li,"DIV",{class:!0});var F9=s(Wt);T(yS.$$.fragment,F9),eRr=i(F9),xAe=n(F9,"P",{});var Kra=s(xAe);oRr=r(Kra,"Instantiates one of the base model classes of the library from a configuration."),Kra.forEach(t),rRr=i(F9),em=n(F9,"P",{});var Vde=s(em);tRr=r(Vde,`Note:
Loading a model from its configuration file does `),$Ae=n(Vde,"STRONG",{});var eta=s($Ae);aRr=r(eta,"not"),eta.forEach(t),nRr=r(Vde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=n(Vde,"A",{href:!0});var ota=s(Yee);sRr=r(ota,"from_pretrained()"),ota.forEach(t),lRr=r(Vde," to load the model weights."),Vde.forEach(t),iRr=i(F9),T(a5.$$.fragment,F9),F9.forEach(t),dRr=i(li),qr=n(li,"DIV",{class:!0});var ii=s(qr);T(xS.$$.fragment,ii),cRr=i(ii),kAe=n(ii,"P",{});var rta=s(kAe);mRr=r(rta,"Instantiate one of the base model classes of the library from a pretrained model."),rta.forEach(t),fRr=i(ii),$n=n(ii,"P",{});var T9=s($n);gRr=r(T9,"The model class to instantiate is selected based on the "),SAe=n(T9,"CODE",{});var tta=s(SAe);hRr=r(tta,"model_type"),tta.forEach(t),uRr=r(T9,` property of the config object (either
passed as an argument or loaded from `),RAe=n(T9,"CODE",{});var ata=s(RAe);pRr=r(ata,"pretrained_model_name_or_path"),ata.forEach(t),_Rr=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PAe=n(T9,"CODE",{});var nta=s(PAe);bRr=r(nta,"pretrained_model_name_or_path"),nta.forEach(t),vRr=r(T9,":"),T9.forEach(t),FRr=i(ii),q=n(ii,"UL",{});var D=s(q);n5=n(D,"LI",{});var ZUe=s(n5);BAe=n(ZUe,"STRONG",{});var sta=s(BAe);TRr=r(sta,"albert"),sta.forEach(t),MRr=r(ZUe," \u2014 "),Zee=n(ZUe,"A",{href:!0});var lta=s(Zee);ERr=r(lta,"TFAlbertModel"),lta.forEach(t),CRr=r(ZUe," (ALBERT model)"),ZUe.forEach(t),wRr=i(D),s5=n(D,"LI",{});var KUe=s(s5);IAe=n(KUe,"STRONG",{});var ita=s(IAe);ARr=r(ita,"bart"),ita.forEach(t),LRr=r(KUe," \u2014 "),Kee=n(KUe,"A",{href:!0});var dta=s(Kee);yRr=r(dta,"TFBartModel"),dta.forEach(t),xRr=r(KUe," (BART model)"),KUe.forEach(t),$Rr=i(D),l5=n(D,"LI",{});var eHe=s(l5);NAe=n(eHe,"STRONG",{});var cta=s(NAe);kRr=r(cta,"bert"),cta.forEach(t),SRr=r(eHe," \u2014 "),eoe=n(eHe,"A",{href:!0});var mta=s(eoe);RRr=r(mta,"TFBertModel"),mta.forEach(t),PRr=r(eHe," (BERT model)"),eHe.forEach(t),BRr=i(D),i5=n(D,"LI",{});var oHe=s(i5);qAe=n(oHe,"STRONG",{});var fta=s(qAe);IRr=r(fta,"blenderbot"),fta.forEach(t),NRr=r(oHe," \u2014 "),ooe=n(oHe,"A",{href:!0});var gta=s(ooe);qRr=r(gta,"TFBlenderbotModel"),gta.forEach(t),jRr=r(oHe," (Blenderbot model)"),oHe.forEach(t),DRr=i(D),d5=n(D,"LI",{});var rHe=s(d5);jAe=n(rHe,"STRONG",{});var hta=s(jAe);GRr=r(hta,"blenderbot-small"),hta.forEach(t),ORr=r(rHe," \u2014 "),roe=n(rHe,"A",{href:!0});var uta=s(roe);VRr=r(uta,"TFBlenderbotSmallModel"),uta.forEach(t),XRr=r(rHe," (BlenderbotSmall model)"),rHe.forEach(t),zRr=i(D),c5=n(D,"LI",{});var tHe=s(c5);DAe=n(tHe,"STRONG",{});var pta=s(DAe);QRr=r(pta,"camembert"),pta.forEach(t),WRr=r(tHe," \u2014 "),toe=n(tHe,"A",{href:!0});var _ta=s(toe);URr=r(_ta,"TFCamembertModel"),_ta.forEach(t),HRr=r(tHe," (CamemBERT model)"),tHe.forEach(t),JRr=i(D),m5=n(D,"LI",{});var aHe=s(m5);GAe=n(aHe,"STRONG",{});var bta=s(GAe);YRr=r(bta,"clip"),bta.forEach(t),ZRr=r(aHe," \u2014 "),aoe=n(aHe,"A",{href:!0});var vta=s(aoe);KRr=r(vta,"TFCLIPModel"),vta.forEach(t),ePr=r(aHe," (CLIP model)"),aHe.forEach(t),oPr=i(D),f5=n(D,"LI",{});var nHe=s(f5);OAe=n(nHe,"STRONG",{});var Fta=s(OAe);rPr=r(Fta,"convbert"),Fta.forEach(t),tPr=r(nHe," \u2014 "),noe=n(nHe,"A",{href:!0});var Tta=s(noe);aPr=r(Tta,"TFConvBertModel"),Tta.forEach(t),nPr=r(nHe," (ConvBERT model)"),nHe.forEach(t),sPr=i(D),g5=n(D,"LI",{});var sHe=s(g5);VAe=n(sHe,"STRONG",{});var Mta=s(VAe);lPr=r(Mta,"convnext"),Mta.forEach(t),iPr=r(sHe," \u2014 "),soe=n(sHe,"A",{href:!0});var Eta=s(soe);dPr=r(Eta,"TFConvNextModel"),Eta.forEach(t),cPr=r(sHe," (ConvNeXT model)"),sHe.forEach(t),mPr=i(D),h5=n(D,"LI",{});var lHe=s(h5);XAe=n(lHe,"STRONG",{});var Cta=s(XAe);fPr=r(Cta,"ctrl"),Cta.forEach(t),gPr=r(lHe," \u2014 "),loe=n(lHe,"A",{href:!0});var wta=s(loe);hPr=r(wta,"TFCTRLModel"),wta.forEach(t),uPr=r(lHe," (CTRL model)"),lHe.forEach(t),pPr=i(D),u5=n(D,"LI",{});var iHe=s(u5);zAe=n(iHe,"STRONG",{});var Ata=s(zAe);_Pr=r(Ata,"data2vec-vision"),Ata.forEach(t),bPr=r(iHe," \u2014 "),ioe=n(iHe,"A",{href:!0});var Lta=s(ioe);vPr=r(Lta,"TFData2VecVisionModel"),Lta.forEach(t),FPr=r(iHe," (Data2VecVision model)"),iHe.forEach(t),TPr=i(D),p5=n(D,"LI",{});var dHe=s(p5);QAe=n(dHe,"STRONG",{});var yta=s(QAe);MPr=r(yta,"deberta"),yta.forEach(t),EPr=r(dHe," \u2014 "),doe=n(dHe,"A",{href:!0});var xta=s(doe);CPr=r(xta,"TFDebertaModel"),xta.forEach(t),wPr=r(dHe," (DeBERTa model)"),dHe.forEach(t),APr=i(D),_5=n(D,"LI",{});var cHe=s(_5);WAe=n(cHe,"STRONG",{});var $ta=s(WAe);LPr=r($ta,"deberta-v2"),$ta.forEach(t),yPr=r(cHe," \u2014 "),coe=n(cHe,"A",{href:!0});var kta=s(coe);xPr=r(kta,"TFDebertaV2Model"),kta.forEach(t),$Pr=r(cHe," (DeBERTa-v2 model)"),cHe.forEach(t),kPr=i(D),b5=n(D,"LI",{});var mHe=s(b5);UAe=n(mHe,"STRONG",{});var Sta=s(UAe);SPr=r(Sta,"deit"),Sta.forEach(t),RPr=r(mHe," \u2014 "),moe=n(mHe,"A",{href:!0});var Rta=s(moe);PPr=r(Rta,"TFDeiTModel"),Rta.forEach(t),BPr=r(mHe," (DeiT model)"),mHe.forEach(t),IPr=i(D),v5=n(D,"LI",{});var fHe=s(v5);HAe=n(fHe,"STRONG",{});var Pta=s(HAe);NPr=r(Pta,"distilbert"),Pta.forEach(t),qPr=r(fHe," \u2014 "),foe=n(fHe,"A",{href:!0});var Bta=s(foe);jPr=r(Bta,"TFDistilBertModel"),Bta.forEach(t),DPr=r(fHe," (DistilBERT model)"),fHe.forEach(t),GPr=i(D),F5=n(D,"LI",{});var gHe=s(F5);JAe=n(gHe,"STRONG",{});var Ita=s(JAe);OPr=r(Ita,"dpr"),Ita.forEach(t),VPr=r(gHe," \u2014 "),goe=n(gHe,"A",{href:!0});var Nta=s(goe);XPr=r(Nta,"TFDPRQuestionEncoder"),Nta.forEach(t),zPr=r(gHe," (DPR model)"),gHe.forEach(t),QPr=i(D),T5=n(D,"LI",{});var hHe=s(T5);YAe=n(hHe,"STRONG",{});var qta=s(YAe);WPr=r(qta,"electra"),qta.forEach(t),UPr=r(hHe," \u2014 "),hoe=n(hHe,"A",{href:!0});var jta=s(hoe);HPr=r(jta,"TFElectraModel"),jta.forEach(t),JPr=r(hHe," (ELECTRA model)"),hHe.forEach(t),YPr=i(D),M5=n(D,"LI",{});var uHe=s(M5);ZAe=n(uHe,"STRONG",{});var Dta=s(ZAe);ZPr=r(Dta,"flaubert"),Dta.forEach(t),KPr=r(uHe," \u2014 "),uoe=n(uHe,"A",{href:!0});var Gta=s(uoe);eBr=r(Gta,"TFFlaubertModel"),Gta.forEach(t),oBr=r(uHe," (FlauBERT model)"),uHe.forEach(t),rBr=i(D),wl=n(D,"LI",{});var yI=s(wl);KAe=n(yI,"STRONG",{});var Ota=s(KAe);tBr=r(Ota,"funnel"),Ota.forEach(t),aBr=r(yI," \u2014 "),poe=n(yI,"A",{href:!0});var Vta=s(poe);nBr=r(Vta,"TFFunnelModel"),Vta.forEach(t),sBr=r(yI," or "),_oe=n(yI,"A",{href:!0});var Xta=s(_oe);lBr=r(Xta,"TFFunnelBaseModel"),Xta.forEach(t),iBr=r(yI," (Funnel Transformer model)"),yI.forEach(t),dBr=i(D),E5=n(D,"LI",{});var pHe=s(E5);e6e=n(pHe,"STRONG",{});var zta=s(e6e);cBr=r(zta,"gpt2"),zta.forEach(t),mBr=r(pHe," \u2014 "),boe=n(pHe,"A",{href:!0});var Qta=s(boe);fBr=r(Qta,"TFGPT2Model"),Qta.forEach(t),gBr=r(pHe," (OpenAI GPT-2 model)"),pHe.forEach(t),hBr=i(D),C5=n(D,"LI",{});var _He=s(C5);o6e=n(_He,"STRONG",{});var Wta=s(o6e);uBr=r(Wta,"gptj"),Wta.forEach(t),pBr=r(_He," \u2014 "),voe=n(_He,"A",{href:!0});var Uta=s(voe);_Br=r(Uta,"TFGPTJModel"),Uta.forEach(t),bBr=r(_He," (GPT-J model)"),_He.forEach(t),vBr=i(D),w5=n(D,"LI",{});var bHe=s(w5);r6e=n(bHe,"STRONG",{});var Hta=s(r6e);FBr=r(Hta,"groupvit"),Hta.forEach(t),TBr=r(bHe," \u2014 "),Foe=n(bHe,"A",{href:!0});var Jta=s(Foe);MBr=r(Jta,"TFGroupViTModel"),Jta.forEach(t),EBr=r(bHe," (GroupViT model)"),bHe.forEach(t),CBr=i(D),A5=n(D,"LI",{});var vHe=s(A5);t6e=n(vHe,"STRONG",{});var Yta=s(t6e);wBr=r(Yta,"hubert"),Yta.forEach(t),ABr=r(vHe," \u2014 "),Toe=n(vHe,"A",{href:!0});var Zta=s(Toe);LBr=r(Zta,"TFHubertModel"),Zta.forEach(t),yBr=r(vHe," (Hubert model)"),vHe.forEach(t),xBr=i(D),L5=n(D,"LI",{});var FHe=s(L5);a6e=n(FHe,"STRONG",{});var Kta=s(a6e);$Br=r(Kta,"layoutlm"),Kta.forEach(t),kBr=r(FHe," \u2014 "),Moe=n(FHe,"A",{href:!0});var eaa=s(Moe);SBr=r(eaa,"TFLayoutLMModel"),eaa.forEach(t),RBr=r(FHe," (LayoutLM model)"),FHe.forEach(t),PBr=i(D),y5=n(D,"LI",{});var THe=s(y5);n6e=n(THe,"STRONG",{});var oaa=s(n6e);BBr=r(oaa,"layoutlmv3"),oaa.forEach(t),IBr=r(THe," \u2014 "),Eoe=n(THe,"A",{href:!0});var raa=s(Eoe);NBr=r(raa,"TFLayoutLMv3Model"),raa.forEach(t),qBr=r(THe," (LayoutLMv3 model)"),THe.forEach(t),jBr=i(D),x5=n(D,"LI",{});var MHe=s(x5);s6e=n(MHe,"STRONG",{});var taa=s(s6e);DBr=r(taa,"led"),taa.forEach(t),GBr=r(MHe," \u2014 "),Coe=n(MHe,"A",{href:!0});var aaa=s(Coe);OBr=r(aaa,"TFLEDModel"),aaa.forEach(t),VBr=r(MHe," (LED model)"),MHe.forEach(t),XBr=i(D),$5=n(D,"LI",{});var EHe=s($5);l6e=n(EHe,"STRONG",{});var naa=s(l6e);zBr=r(naa,"longformer"),naa.forEach(t),QBr=r(EHe," \u2014 "),woe=n(EHe,"A",{href:!0});var saa=s(woe);WBr=r(saa,"TFLongformerModel"),saa.forEach(t),UBr=r(EHe," (Longformer model)"),EHe.forEach(t),HBr=i(D),k5=n(D,"LI",{});var CHe=s(k5);i6e=n(CHe,"STRONG",{});var laa=s(i6e);JBr=r(laa,"lxmert"),laa.forEach(t),YBr=r(CHe," \u2014 "),Aoe=n(CHe,"A",{href:!0});var iaa=s(Aoe);ZBr=r(iaa,"TFLxmertModel"),iaa.forEach(t),KBr=r(CHe," (LXMERT model)"),CHe.forEach(t),eIr=i(D),S5=n(D,"LI",{});var wHe=s(S5);d6e=n(wHe,"STRONG",{});var daa=s(d6e);oIr=r(daa,"marian"),daa.forEach(t),rIr=r(wHe," \u2014 "),Loe=n(wHe,"A",{href:!0});var caa=s(Loe);tIr=r(caa,"TFMarianModel"),caa.forEach(t),aIr=r(wHe," (Marian model)"),wHe.forEach(t),nIr=i(D),R5=n(D,"LI",{});var AHe=s(R5);c6e=n(AHe,"STRONG",{});var maa=s(c6e);sIr=r(maa,"mbart"),maa.forEach(t),lIr=r(AHe," \u2014 "),yoe=n(AHe,"A",{href:!0});var faa=s(yoe);iIr=r(faa,"TFMBartModel"),faa.forEach(t),dIr=r(AHe," (mBART model)"),AHe.forEach(t),cIr=i(D),P5=n(D,"LI",{});var LHe=s(P5);m6e=n(LHe,"STRONG",{});var gaa=s(m6e);mIr=r(gaa,"mobilebert"),gaa.forEach(t),fIr=r(LHe," \u2014 "),xoe=n(LHe,"A",{href:!0});var haa=s(xoe);gIr=r(haa,"TFMobileBertModel"),haa.forEach(t),hIr=r(LHe," (MobileBERT model)"),LHe.forEach(t),uIr=i(D),B5=n(D,"LI",{});var yHe=s(B5);f6e=n(yHe,"STRONG",{});var uaa=s(f6e);pIr=r(uaa,"mobilevit"),uaa.forEach(t),_Ir=r(yHe," \u2014 "),$oe=n(yHe,"A",{href:!0});var paa=s($oe);bIr=r(paa,"TFMobileViTModel"),paa.forEach(t),vIr=r(yHe," (MobileViT model)"),yHe.forEach(t),FIr=i(D),I5=n(D,"LI",{});var xHe=s(I5);g6e=n(xHe,"STRONG",{});var _aa=s(g6e);TIr=r(_aa,"mpnet"),_aa.forEach(t),MIr=r(xHe," \u2014 "),koe=n(xHe,"A",{href:!0});var baa=s(koe);EIr=r(baa,"TFMPNetModel"),baa.forEach(t),CIr=r(xHe," (MPNet model)"),xHe.forEach(t),wIr=i(D),N5=n(D,"LI",{});var $He=s(N5);h6e=n($He,"STRONG",{});var vaa=s(h6e);AIr=r(vaa,"mt5"),vaa.forEach(t),LIr=r($He," \u2014 "),Soe=n($He,"A",{href:!0});var Faa=s(Soe);yIr=r(Faa,"TFMT5Model"),Faa.forEach(t),xIr=r($He," (MT5 model)"),$He.forEach(t),$Ir=i(D),q5=n(D,"LI",{});var kHe=s(q5);u6e=n(kHe,"STRONG",{});var Taa=s(u6e);kIr=r(Taa,"openai-gpt"),Taa.forEach(t),SIr=r(kHe," \u2014 "),Roe=n(kHe,"A",{href:!0});var Maa=s(Roe);RIr=r(Maa,"TFOpenAIGPTModel"),Maa.forEach(t),PIr=r(kHe," (OpenAI GPT model)"),kHe.forEach(t),BIr=i(D),j5=n(D,"LI",{});var SHe=s(j5);p6e=n(SHe,"STRONG",{});var Eaa=s(p6e);IIr=r(Eaa,"opt"),Eaa.forEach(t),NIr=r(SHe," \u2014 "),Poe=n(SHe,"A",{href:!0});var Caa=s(Poe);qIr=r(Caa,"TFOPTModel"),Caa.forEach(t),jIr=r(SHe," (OPT model)"),SHe.forEach(t),DIr=i(D),D5=n(D,"LI",{});var RHe=s(D5);_6e=n(RHe,"STRONG",{});var waa=s(_6e);GIr=r(waa,"pegasus"),waa.forEach(t),OIr=r(RHe," \u2014 "),Boe=n(RHe,"A",{href:!0});var Aaa=s(Boe);VIr=r(Aaa,"TFPegasusModel"),Aaa.forEach(t),XIr=r(RHe," (Pegasus model)"),RHe.forEach(t),zIr=i(D),G5=n(D,"LI",{});var PHe=s(G5);b6e=n(PHe,"STRONG",{});var Laa=s(b6e);QIr=r(Laa,"regnet"),Laa.forEach(t),WIr=r(PHe," \u2014 "),Ioe=n(PHe,"A",{href:!0});var yaa=s(Ioe);UIr=r(yaa,"TFRegNetModel"),yaa.forEach(t),HIr=r(PHe," (RegNet model)"),PHe.forEach(t),JIr=i(D),O5=n(D,"LI",{});var BHe=s(O5);v6e=n(BHe,"STRONG",{});var xaa=s(v6e);YIr=r(xaa,"rembert"),xaa.forEach(t),ZIr=r(BHe," \u2014 "),Noe=n(BHe,"A",{href:!0});var $aa=s(Noe);KIr=r($aa,"TFRemBertModel"),$aa.forEach(t),eNr=r(BHe," (RemBERT model)"),BHe.forEach(t),oNr=i(D),V5=n(D,"LI",{});var IHe=s(V5);F6e=n(IHe,"STRONG",{});var kaa=s(F6e);rNr=r(kaa,"resnet"),kaa.forEach(t),tNr=r(IHe," \u2014 "),qoe=n(IHe,"A",{href:!0});var Saa=s(qoe);aNr=r(Saa,"TFResNetModel"),Saa.forEach(t),nNr=r(IHe," (ResNet model)"),IHe.forEach(t),sNr=i(D),X5=n(D,"LI",{});var NHe=s(X5);T6e=n(NHe,"STRONG",{});var Raa=s(T6e);lNr=r(Raa,"roberta"),Raa.forEach(t),iNr=r(NHe," \u2014 "),joe=n(NHe,"A",{href:!0});var Paa=s(joe);dNr=r(Paa,"TFRobertaModel"),Paa.forEach(t),cNr=r(NHe," (RoBERTa model)"),NHe.forEach(t),mNr=i(D),z5=n(D,"LI",{});var qHe=s(z5);M6e=n(qHe,"STRONG",{});var Baa=s(M6e);fNr=r(Baa,"roformer"),Baa.forEach(t),gNr=r(qHe," \u2014 "),Doe=n(qHe,"A",{href:!0});var Iaa=s(Doe);hNr=r(Iaa,"TFRoFormerModel"),Iaa.forEach(t),uNr=r(qHe," (RoFormer model)"),qHe.forEach(t),pNr=i(D),Q5=n(D,"LI",{});var jHe=s(Q5);E6e=n(jHe,"STRONG",{});var Naa=s(E6e);_Nr=r(Naa,"segformer"),Naa.forEach(t),bNr=r(jHe," \u2014 "),Goe=n(jHe,"A",{href:!0});var qaa=s(Goe);vNr=r(qaa,"TFSegformerModel"),qaa.forEach(t),FNr=r(jHe," (SegFormer model)"),jHe.forEach(t),TNr=i(D),W5=n(D,"LI",{});var DHe=s(W5);C6e=n(DHe,"STRONG",{});var jaa=s(C6e);MNr=r(jaa,"speech_to_text"),jaa.forEach(t),ENr=r(DHe," \u2014 "),Ooe=n(DHe,"A",{href:!0});var Daa=s(Ooe);CNr=r(Daa,"TFSpeech2TextModel"),Daa.forEach(t),wNr=r(DHe," (Speech2Text model)"),DHe.forEach(t),ANr=i(D),U5=n(D,"LI",{});var GHe=s(U5);w6e=n(GHe,"STRONG",{});var Gaa=s(w6e);LNr=r(Gaa,"swin"),Gaa.forEach(t),yNr=r(GHe," \u2014 "),Voe=n(GHe,"A",{href:!0});var Oaa=s(Voe);xNr=r(Oaa,"TFSwinModel"),Oaa.forEach(t),$Nr=r(GHe," (Swin Transformer model)"),GHe.forEach(t),kNr=i(D),H5=n(D,"LI",{});var OHe=s(H5);A6e=n(OHe,"STRONG",{});var Vaa=s(A6e);SNr=r(Vaa,"t5"),Vaa.forEach(t),RNr=r(OHe," \u2014 "),Xoe=n(OHe,"A",{href:!0});var Xaa=s(Xoe);PNr=r(Xaa,"TFT5Model"),Xaa.forEach(t),BNr=r(OHe," (T5 model)"),OHe.forEach(t),INr=i(D),J5=n(D,"LI",{});var VHe=s(J5);L6e=n(VHe,"STRONG",{});var zaa=s(L6e);NNr=r(zaa,"tapas"),zaa.forEach(t),qNr=r(VHe," \u2014 "),zoe=n(VHe,"A",{href:!0});var Qaa=s(zoe);jNr=r(Qaa,"TFTapasModel"),Qaa.forEach(t),DNr=r(VHe," (TAPAS model)"),VHe.forEach(t),GNr=i(D),Y5=n(D,"LI",{});var XHe=s(Y5);y6e=n(XHe,"STRONG",{});var Waa=s(y6e);ONr=r(Waa,"transfo-xl"),Waa.forEach(t),VNr=r(XHe," \u2014 "),Qoe=n(XHe,"A",{href:!0});var Uaa=s(Qoe);XNr=r(Uaa,"TFTransfoXLModel"),Uaa.forEach(t),zNr=r(XHe," (Transformer-XL model)"),XHe.forEach(t),QNr=i(D),Z5=n(D,"LI",{});var zHe=s(Z5);x6e=n(zHe,"STRONG",{});var Haa=s(x6e);WNr=r(Haa,"vit"),Haa.forEach(t),UNr=r(zHe," \u2014 "),Woe=n(zHe,"A",{href:!0});var Jaa=s(Woe);HNr=r(Jaa,"TFViTModel"),Jaa.forEach(t),JNr=r(zHe," (ViT model)"),zHe.forEach(t),YNr=i(D),K5=n(D,"LI",{});var QHe=s(K5);$6e=n(QHe,"STRONG",{});var Yaa=s($6e);ZNr=r(Yaa,"vit_mae"),Yaa.forEach(t),KNr=r(QHe," \u2014 "),Uoe=n(QHe,"A",{href:!0});var Zaa=s(Uoe);eqr=r(Zaa,"TFViTMAEModel"),Zaa.forEach(t),oqr=r(QHe," (ViTMAE model)"),QHe.forEach(t),rqr=i(D),e0=n(D,"LI",{});var WHe=s(e0);k6e=n(WHe,"STRONG",{});var Kaa=s(k6e);tqr=r(Kaa,"wav2vec2"),Kaa.forEach(t),aqr=r(WHe," \u2014 "),Hoe=n(WHe,"A",{href:!0});var ena=s(Hoe);nqr=r(ena,"TFWav2Vec2Model"),ena.forEach(t),sqr=r(WHe," (Wav2Vec2 model)"),WHe.forEach(t),lqr=i(D),o0=n(D,"LI",{});var UHe=s(o0);S6e=n(UHe,"STRONG",{});var ona=s(S6e);iqr=r(ona,"xglm"),ona.forEach(t),dqr=r(UHe," \u2014 "),Joe=n(UHe,"A",{href:!0});var rna=s(Joe);cqr=r(rna,"TFXGLMModel"),rna.forEach(t),mqr=r(UHe," (XGLM model)"),UHe.forEach(t),fqr=i(D),r0=n(D,"LI",{});var HHe=s(r0);R6e=n(HHe,"STRONG",{});var tna=s(R6e);gqr=r(tna,"xlm"),tna.forEach(t),hqr=r(HHe," \u2014 "),Yoe=n(HHe,"A",{href:!0});var ana=s(Yoe);uqr=r(ana,"TFXLMModel"),ana.forEach(t),pqr=r(HHe," (XLM model)"),HHe.forEach(t),_qr=i(D),t0=n(D,"LI",{});var JHe=s(t0);P6e=n(JHe,"STRONG",{});var nna=s(P6e);bqr=r(nna,"xlm-roberta"),nna.forEach(t),vqr=r(JHe," \u2014 "),Zoe=n(JHe,"A",{href:!0});var sna=s(Zoe);Fqr=r(sna,"TFXLMRobertaModel"),sna.forEach(t),Tqr=r(JHe," (XLM-RoBERTa model)"),JHe.forEach(t),Mqr=i(D),a0=n(D,"LI",{});var YHe=s(a0);B6e=n(YHe,"STRONG",{});var lna=s(B6e);Eqr=r(lna,"xlnet"),lna.forEach(t),Cqr=r(YHe," \u2014 "),Koe=n(YHe,"A",{href:!0});var ina=s(Koe);wqr=r(ina,"TFXLNetModel"),ina.forEach(t),Aqr=r(YHe," (XLNet model)"),YHe.forEach(t),D.forEach(t),Lqr=i(ii),T(n0.$$.fragment,ii),ii.forEach(t),li.forEach(t),Ero=i(m),om=n(m,"H2",{class:!0});var jao=s(om);s0=n(jao,"A",{id:!0,class:!0,href:!0});var dna=s(s0);I6e=n(dna,"SPAN",{});var cna=s(I6e);T($S.$$.fragment,cna),cna.forEach(t),dna.forEach(t),yqr=i(jao),N6e=n(jao,"SPAN",{});var mna=s(N6e);xqr=r(mna,"TFAutoModelForPreTraining"),mna.forEach(t),jao.forEach(t),Cro=i(m),dr=n(m,"DIV",{class:!0});var di=s(dr);T(kS.$$.fragment,di),$qr=i(di),rm=n(di,"P",{});var Xde=s(rm);kqr=r(Xde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ere=n(Xde,"A",{href:!0});var fna=s(ere);Sqr=r(fna,"from_pretrained()"),fna.forEach(t),Rqr=r(Xde," class method or the "),ore=n(Xde,"A",{href:!0});var gna=s(ore);Pqr=r(gna,"from_config()"),gna.forEach(t),Bqr=r(Xde,` class
method.`),Xde.forEach(t),Iqr=i(di),SS=n(di,"P",{});var Dao=s(SS);Nqr=r(Dao,"This class cannot be instantiated directly using "),q6e=n(Dao,"CODE",{});var hna=s(q6e);qqr=r(hna,"__init__()"),hna.forEach(t),jqr=r(Dao," (throws an error)."),Dao.forEach(t),Dqr=i(di),Ut=n(di,"DIV",{class:!0});var M9=s(Ut);T(RS.$$.fragment,M9),Gqr=i(M9),j6e=n(M9,"P",{});var una=s(j6e);Oqr=r(una,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),una.forEach(t),Vqr=i(M9),tm=n(M9,"P",{});var zde=s(tm);Xqr=r(zde,`Note:
Loading a model from its configuration file does `),D6e=n(zde,"STRONG",{});var pna=s(D6e);zqr=r(pna,"not"),pna.forEach(t),Qqr=r(zde,` load the model weights. It only affects the
model\u2019s configuration. Use `),rre=n(zde,"A",{href:!0});var _na=s(rre);Wqr=r(_na,"from_pretrained()"),_na.forEach(t),Uqr=r(zde," to load the model weights."),zde.forEach(t),Hqr=i(M9),T(l0.$$.fragment,M9),M9.forEach(t),Jqr=i(di),jr=n(di,"DIV",{class:!0});var ci=s(jr);T(PS.$$.fragment,ci),Yqr=i(ci),G6e=n(ci,"P",{});var bna=s(G6e);Zqr=r(bna,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bna.forEach(t),Kqr=i(ci),kn=n(ci,"P",{});var E9=s(kn);ejr=r(E9,"The model class to instantiate is selected based on the "),O6e=n(E9,"CODE",{});var vna=s(O6e);ojr=r(vna,"model_type"),vna.forEach(t),rjr=r(E9,` property of the config object (either
passed as an argument or loaded from `),V6e=n(E9,"CODE",{});var Fna=s(V6e);tjr=r(Fna,"pretrained_model_name_or_path"),Fna.forEach(t),ajr=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X6e=n(E9,"CODE",{});var Tna=s(X6e);njr=r(Tna,"pretrained_model_name_or_path"),Tna.forEach(t),sjr=r(E9,":"),E9.forEach(t),ljr=i(ci),le=n(ci,"UL",{});var de=s(le);i0=n(de,"LI",{});var ZHe=s(i0);z6e=n(ZHe,"STRONG",{});var Mna=s(z6e);ijr=r(Mna,"albert"),Mna.forEach(t),djr=r(ZHe," \u2014 "),tre=n(ZHe,"A",{href:!0});var Ena=s(tre);cjr=r(Ena,"TFAlbertForPreTraining"),Ena.forEach(t),mjr=r(ZHe," (ALBERT model)"),ZHe.forEach(t),fjr=i(de),d0=n(de,"LI",{});var KHe=s(d0);Q6e=n(KHe,"STRONG",{});var Cna=s(Q6e);gjr=r(Cna,"bart"),Cna.forEach(t),hjr=r(KHe," \u2014 "),are=n(KHe,"A",{href:!0});var wna=s(are);ujr=r(wna,"TFBartForConditionalGeneration"),wna.forEach(t),pjr=r(KHe," (BART model)"),KHe.forEach(t),_jr=i(de),c0=n(de,"LI",{});var eJe=s(c0);W6e=n(eJe,"STRONG",{});var Ana=s(W6e);bjr=r(Ana,"bert"),Ana.forEach(t),vjr=r(eJe," \u2014 "),nre=n(eJe,"A",{href:!0});var Lna=s(nre);Fjr=r(Lna,"TFBertForPreTraining"),Lna.forEach(t),Tjr=r(eJe," (BERT model)"),eJe.forEach(t),Mjr=i(de),m0=n(de,"LI",{});var oJe=s(m0);U6e=n(oJe,"STRONG",{});var yna=s(U6e);Ejr=r(yna,"camembert"),yna.forEach(t),Cjr=r(oJe," \u2014 "),sre=n(oJe,"A",{href:!0});var xna=s(sre);wjr=r(xna,"TFCamembertForMaskedLM"),xna.forEach(t),Ajr=r(oJe," (CamemBERT model)"),oJe.forEach(t),Ljr=i(de),f0=n(de,"LI",{});var rJe=s(f0);H6e=n(rJe,"STRONG",{});var $na=s(H6e);yjr=r($na,"ctrl"),$na.forEach(t),xjr=r(rJe," \u2014 "),lre=n(rJe,"A",{href:!0});var kna=s(lre);$jr=r(kna,"TFCTRLLMHeadModel"),kna.forEach(t),kjr=r(rJe," (CTRL model)"),rJe.forEach(t),Sjr=i(de),g0=n(de,"LI",{});var tJe=s(g0);J6e=n(tJe,"STRONG",{});var Sna=s(J6e);Rjr=r(Sna,"distilbert"),Sna.forEach(t),Pjr=r(tJe," \u2014 "),ire=n(tJe,"A",{href:!0});var Rna=s(ire);Bjr=r(Rna,"TFDistilBertForMaskedLM"),Rna.forEach(t),Ijr=r(tJe," (DistilBERT model)"),tJe.forEach(t),Njr=i(de),h0=n(de,"LI",{});var aJe=s(h0);Y6e=n(aJe,"STRONG",{});var Pna=s(Y6e);qjr=r(Pna,"electra"),Pna.forEach(t),jjr=r(aJe," \u2014 "),dre=n(aJe,"A",{href:!0});var Bna=s(dre);Djr=r(Bna,"TFElectraForPreTraining"),Bna.forEach(t),Gjr=r(aJe," (ELECTRA model)"),aJe.forEach(t),Ojr=i(de),u0=n(de,"LI",{});var nJe=s(u0);Z6e=n(nJe,"STRONG",{});var Ina=s(Z6e);Vjr=r(Ina,"flaubert"),Ina.forEach(t),Xjr=r(nJe," \u2014 "),cre=n(nJe,"A",{href:!0});var Nna=s(cre);zjr=r(Nna,"TFFlaubertWithLMHeadModel"),Nna.forEach(t),Qjr=r(nJe," (FlauBERT model)"),nJe.forEach(t),Wjr=i(de),p0=n(de,"LI",{});var sJe=s(p0);K6e=n(sJe,"STRONG",{});var qna=s(K6e);Ujr=r(qna,"funnel"),qna.forEach(t),Hjr=r(sJe," \u2014 "),mre=n(sJe,"A",{href:!0});var jna=s(mre);Jjr=r(jna,"TFFunnelForPreTraining"),jna.forEach(t),Yjr=r(sJe," (Funnel Transformer model)"),sJe.forEach(t),Zjr=i(de),_0=n(de,"LI",{});var lJe=s(_0);e7e=n(lJe,"STRONG",{});var Dna=s(e7e);Kjr=r(Dna,"gpt2"),Dna.forEach(t),eDr=r(lJe," \u2014 "),fre=n(lJe,"A",{href:!0});var Gna=s(fre);oDr=r(Gna,"TFGPT2LMHeadModel"),Gna.forEach(t),rDr=r(lJe," (OpenAI GPT-2 model)"),lJe.forEach(t),tDr=i(de),b0=n(de,"LI",{});var iJe=s(b0);o7e=n(iJe,"STRONG",{});var Ona=s(o7e);aDr=r(Ona,"layoutlm"),Ona.forEach(t),nDr=r(iJe," \u2014 "),gre=n(iJe,"A",{href:!0});var Vna=s(gre);sDr=r(Vna,"TFLayoutLMForMaskedLM"),Vna.forEach(t),lDr=r(iJe," (LayoutLM model)"),iJe.forEach(t),iDr=i(de),v0=n(de,"LI",{});var dJe=s(v0);r7e=n(dJe,"STRONG",{});var Xna=s(r7e);dDr=r(Xna,"lxmert"),Xna.forEach(t),cDr=r(dJe," \u2014 "),hre=n(dJe,"A",{href:!0});var zna=s(hre);mDr=r(zna,"TFLxmertForPreTraining"),zna.forEach(t),fDr=r(dJe," (LXMERT model)"),dJe.forEach(t),gDr=i(de),F0=n(de,"LI",{});var cJe=s(F0);t7e=n(cJe,"STRONG",{});var Qna=s(t7e);hDr=r(Qna,"mobilebert"),Qna.forEach(t),uDr=r(cJe," \u2014 "),ure=n(cJe,"A",{href:!0});var Wna=s(ure);pDr=r(Wna,"TFMobileBertForPreTraining"),Wna.forEach(t),_Dr=r(cJe," (MobileBERT model)"),cJe.forEach(t),bDr=i(de),T0=n(de,"LI",{});var mJe=s(T0);a7e=n(mJe,"STRONG",{});var Una=s(a7e);vDr=r(Una,"mpnet"),Una.forEach(t),FDr=r(mJe," \u2014 "),pre=n(mJe,"A",{href:!0});var Hna=s(pre);TDr=r(Hna,"TFMPNetForMaskedLM"),Hna.forEach(t),MDr=r(mJe," (MPNet model)"),mJe.forEach(t),EDr=i(de),M0=n(de,"LI",{});var fJe=s(M0);n7e=n(fJe,"STRONG",{});var Jna=s(n7e);CDr=r(Jna,"openai-gpt"),Jna.forEach(t),wDr=r(fJe," \u2014 "),_re=n(fJe,"A",{href:!0});var Yna=s(_re);ADr=r(Yna,"TFOpenAIGPTLMHeadModel"),Yna.forEach(t),LDr=r(fJe," (OpenAI GPT model)"),fJe.forEach(t),yDr=i(de),E0=n(de,"LI",{});var gJe=s(E0);s7e=n(gJe,"STRONG",{});var Zna=s(s7e);xDr=r(Zna,"roberta"),Zna.forEach(t),$Dr=r(gJe," \u2014 "),bre=n(gJe,"A",{href:!0});var Kna=s(bre);kDr=r(Kna,"TFRobertaForMaskedLM"),Kna.forEach(t),SDr=r(gJe," (RoBERTa model)"),gJe.forEach(t),RDr=i(de),C0=n(de,"LI",{});var hJe=s(C0);l7e=n(hJe,"STRONG",{});var esa=s(l7e);PDr=r(esa,"t5"),esa.forEach(t),BDr=r(hJe," \u2014 "),vre=n(hJe,"A",{href:!0});var osa=s(vre);IDr=r(osa,"TFT5ForConditionalGeneration"),osa.forEach(t),NDr=r(hJe," (T5 model)"),hJe.forEach(t),qDr=i(de),w0=n(de,"LI",{});var uJe=s(w0);i7e=n(uJe,"STRONG",{});var rsa=s(i7e);jDr=r(rsa,"tapas"),rsa.forEach(t),DDr=r(uJe," \u2014 "),Fre=n(uJe,"A",{href:!0});var tsa=s(Fre);GDr=r(tsa,"TFTapasForMaskedLM"),tsa.forEach(t),ODr=r(uJe," (TAPAS model)"),uJe.forEach(t),VDr=i(de),A0=n(de,"LI",{});var pJe=s(A0);d7e=n(pJe,"STRONG",{});var asa=s(d7e);XDr=r(asa,"transfo-xl"),asa.forEach(t),zDr=r(pJe," \u2014 "),Tre=n(pJe,"A",{href:!0});var nsa=s(Tre);QDr=r(nsa,"TFTransfoXLLMHeadModel"),nsa.forEach(t),WDr=r(pJe," (Transformer-XL model)"),pJe.forEach(t),UDr=i(de),L0=n(de,"LI",{});var _Je=s(L0);c7e=n(_Je,"STRONG",{});var ssa=s(c7e);HDr=r(ssa,"vit_mae"),ssa.forEach(t),JDr=r(_Je," \u2014 "),Mre=n(_Je,"A",{href:!0});var lsa=s(Mre);YDr=r(lsa,"TFViTMAEForPreTraining"),lsa.forEach(t),ZDr=r(_Je," (ViTMAE model)"),_Je.forEach(t),KDr=i(de),y0=n(de,"LI",{});var bJe=s(y0);m7e=n(bJe,"STRONG",{});var isa=s(m7e);eGr=r(isa,"xlm"),isa.forEach(t),oGr=r(bJe," \u2014 "),Ere=n(bJe,"A",{href:!0});var dsa=s(Ere);rGr=r(dsa,"TFXLMWithLMHeadModel"),dsa.forEach(t),tGr=r(bJe," (XLM model)"),bJe.forEach(t),aGr=i(de),x0=n(de,"LI",{});var vJe=s(x0);f7e=n(vJe,"STRONG",{});var csa=s(f7e);nGr=r(csa,"xlm-roberta"),csa.forEach(t),sGr=r(vJe," \u2014 "),Cre=n(vJe,"A",{href:!0});var msa=s(Cre);lGr=r(msa,"TFXLMRobertaForMaskedLM"),msa.forEach(t),iGr=r(vJe," (XLM-RoBERTa model)"),vJe.forEach(t),dGr=i(de),$0=n(de,"LI",{});var FJe=s($0);g7e=n(FJe,"STRONG",{});var fsa=s(g7e);cGr=r(fsa,"xlnet"),fsa.forEach(t),mGr=r(FJe," \u2014 "),wre=n(FJe,"A",{href:!0});var gsa=s(wre);fGr=r(gsa,"TFXLNetLMHeadModel"),gsa.forEach(t),gGr=r(FJe," (XLNet model)"),FJe.forEach(t),de.forEach(t),hGr=i(ci),T(k0.$$.fragment,ci),ci.forEach(t),di.forEach(t),wro=i(m),am=n(m,"H2",{class:!0});var Gao=s(am);S0=n(Gao,"A",{id:!0,class:!0,href:!0});var hsa=s(S0);h7e=n(hsa,"SPAN",{});var usa=s(h7e);T(BS.$$.fragment,usa),usa.forEach(t),hsa.forEach(t),uGr=i(Gao),u7e=n(Gao,"SPAN",{});var psa=s(u7e);pGr=r(psa,"TFAutoModelForCausalLM"),psa.forEach(t),Gao.forEach(t),Aro=i(m),cr=n(m,"DIV",{class:!0});var mi=s(cr);T(IS.$$.fragment,mi),_Gr=i(mi),nm=n(mi,"P",{});var Qde=s(nm);bGr=r(Qde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Are=n(Qde,"A",{href:!0});var _sa=s(Are);vGr=r(_sa,"from_pretrained()"),_sa.forEach(t),FGr=r(Qde," class method or the "),Lre=n(Qde,"A",{href:!0});var bsa=s(Lre);TGr=r(bsa,"from_config()"),bsa.forEach(t),MGr=r(Qde,` class
method.`),Qde.forEach(t),EGr=i(mi),NS=n(mi,"P",{});var Oao=s(NS);CGr=r(Oao,"This class cannot be instantiated directly using "),p7e=n(Oao,"CODE",{});var vsa=s(p7e);wGr=r(vsa,"__init__()"),vsa.forEach(t),AGr=r(Oao," (throws an error)."),Oao.forEach(t),LGr=i(mi),Ht=n(mi,"DIV",{class:!0});var C9=s(Ht);T(qS.$$.fragment,C9),yGr=i(C9),_7e=n(C9,"P",{});var Fsa=s(_7e);xGr=r(Fsa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Fsa.forEach(t),$Gr=i(C9),sm=n(C9,"P",{});var Wde=s(sm);kGr=r(Wde,`Note:
Loading a model from its configuration file does `),b7e=n(Wde,"STRONG",{});var Tsa=s(b7e);SGr=r(Tsa,"not"),Tsa.forEach(t),RGr=r(Wde,` load the model weights. It only affects the
model\u2019s configuration. Use `),yre=n(Wde,"A",{href:!0});var Msa=s(yre);PGr=r(Msa,"from_pretrained()"),Msa.forEach(t),BGr=r(Wde," to load the model weights."),Wde.forEach(t),IGr=i(C9),T(R0.$$.fragment,C9),C9.forEach(t),NGr=i(mi),Dr=n(mi,"DIV",{class:!0});var fi=s(Dr);T(jS.$$.fragment,fi),qGr=i(fi),v7e=n(fi,"P",{});var Esa=s(v7e);jGr=r(Esa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Esa.forEach(t),DGr=i(fi),Sn=n(fi,"P",{});var w9=s(Sn);GGr=r(w9,"The model class to instantiate is selected based on the "),F7e=n(w9,"CODE",{});var Csa=s(F7e);OGr=r(Csa,"model_type"),Csa.forEach(t),VGr=r(w9,` property of the config object (either
passed as an argument or loaded from `),T7e=n(w9,"CODE",{});var wsa=s(T7e);XGr=r(wsa,"pretrained_model_name_or_path"),wsa.forEach(t),zGr=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M7e=n(w9,"CODE",{});var Asa=s(M7e);QGr=r(Asa,"pretrained_model_name_or_path"),Asa.forEach(t),WGr=r(w9,":"),w9.forEach(t),UGr=i(fi),Me=n(fi,"UL",{});var Ce=s(Me);P0=n(Ce,"LI",{});var TJe=s(P0);E7e=n(TJe,"STRONG",{});var Lsa=s(E7e);HGr=r(Lsa,"bert"),Lsa.forEach(t),JGr=r(TJe," \u2014 "),xre=n(TJe,"A",{href:!0});var ysa=s(xre);YGr=r(ysa,"TFBertLMHeadModel"),ysa.forEach(t),ZGr=r(TJe," (BERT model)"),TJe.forEach(t),KGr=i(Ce),B0=n(Ce,"LI",{});var MJe=s(B0);C7e=n(MJe,"STRONG",{});var xsa=s(C7e);eOr=r(xsa,"camembert"),xsa.forEach(t),oOr=r(MJe," \u2014 "),$re=n(MJe,"A",{href:!0});var $sa=s($re);rOr=r($sa,"TFCamembertForCausalLM"),$sa.forEach(t),tOr=r(MJe," (CamemBERT model)"),MJe.forEach(t),aOr=i(Ce),I0=n(Ce,"LI",{});var EJe=s(I0);w7e=n(EJe,"STRONG",{});var ksa=s(w7e);nOr=r(ksa,"ctrl"),ksa.forEach(t),sOr=r(EJe," \u2014 "),kre=n(EJe,"A",{href:!0});var Ssa=s(kre);lOr=r(Ssa,"TFCTRLLMHeadModel"),Ssa.forEach(t),iOr=r(EJe," (CTRL model)"),EJe.forEach(t),dOr=i(Ce),N0=n(Ce,"LI",{});var CJe=s(N0);A7e=n(CJe,"STRONG",{});var Rsa=s(A7e);cOr=r(Rsa,"gpt2"),Rsa.forEach(t),mOr=r(CJe," \u2014 "),Sre=n(CJe,"A",{href:!0});var Psa=s(Sre);fOr=r(Psa,"TFGPT2LMHeadModel"),Psa.forEach(t),gOr=r(CJe," (OpenAI GPT-2 model)"),CJe.forEach(t),hOr=i(Ce),q0=n(Ce,"LI",{});var wJe=s(q0);L7e=n(wJe,"STRONG",{});var Bsa=s(L7e);uOr=r(Bsa,"gptj"),Bsa.forEach(t),pOr=r(wJe," \u2014 "),Rre=n(wJe,"A",{href:!0});var Isa=s(Rre);_Or=r(Isa,"TFGPTJForCausalLM"),Isa.forEach(t),bOr=r(wJe," (GPT-J model)"),wJe.forEach(t),vOr=i(Ce),j0=n(Ce,"LI",{});var AJe=s(j0);y7e=n(AJe,"STRONG",{});var Nsa=s(y7e);FOr=r(Nsa,"openai-gpt"),Nsa.forEach(t),TOr=r(AJe," \u2014 "),Pre=n(AJe,"A",{href:!0});var qsa=s(Pre);MOr=r(qsa,"TFOpenAIGPTLMHeadModel"),qsa.forEach(t),EOr=r(AJe," (OpenAI GPT model)"),AJe.forEach(t),COr=i(Ce),D0=n(Ce,"LI",{});var LJe=s(D0);x7e=n(LJe,"STRONG",{});var jsa=s(x7e);wOr=r(jsa,"opt"),jsa.forEach(t),AOr=r(LJe," \u2014 "),Bre=n(LJe,"A",{href:!0});var Dsa=s(Bre);LOr=r(Dsa,"TFOPTForCausalLM"),Dsa.forEach(t),yOr=r(LJe," (OPT model)"),LJe.forEach(t),xOr=i(Ce),G0=n(Ce,"LI",{});var yJe=s(G0);$7e=n(yJe,"STRONG",{});var Gsa=s($7e);$Or=r(Gsa,"rembert"),Gsa.forEach(t),kOr=r(yJe," \u2014 "),Ire=n(yJe,"A",{href:!0});var Osa=s(Ire);SOr=r(Osa,"TFRemBertForCausalLM"),Osa.forEach(t),ROr=r(yJe," (RemBERT model)"),yJe.forEach(t),POr=i(Ce),O0=n(Ce,"LI",{});var xJe=s(O0);k7e=n(xJe,"STRONG",{});var Vsa=s(k7e);BOr=r(Vsa,"roberta"),Vsa.forEach(t),IOr=r(xJe," \u2014 "),Nre=n(xJe,"A",{href:!0});var Xsa=s(Nre);NOr=r(Xsa,"TFRobertaForCausalLM"),Xsa.forEach(t),qOr=r(xJe," (RoBERTa model)"),xJe.forEach(t),jOr=i(Ce),V0=n(Ce,"LI",{});var $Je=s(V0);S7e=n($Je,"STRONG",{});var zsa=s(S7e);DOr=r(zsa,"roformer"),zsa.forEach(t),GOr=r($Je," \u2014 "),qre=n($Je,"A",{href:!0});var Qsa=s(qre);OOr=r(Qsa,"TFRoFormerForCausalLM"),Qsa.forEach(t),VOr=r($Je," (RoFormer model)"),$Je.forEach(t),XOr=i(Ce),X0=n(Ce,"LI",{});var kJe=s(X0);R7e=n(kJe,"STRONG",{});var Wsa=s(R7e);zOr=r(Wsa,"transfo-xl"),Wsa.forEach(t),QOr=r(kJe," \u2014 "),jre=n(kJe,"A",{href:!0});var Usa=s(jre);WOr=r(Usa,"TFTransfoXLLMHeadModel"),Usa.forEach(t),UOr=r(kJe," (Transformer-XL model)"),kJe.forEach(t),HOr=i(Ce),z0=n(Ce,"LI",{});var SJe=s(z0);P7e=n(SJe,"STRONG",{});var Hsa=s(P7e);JOr=r(Hsa,"xglm"),Hsa.forEach(t),YOr=r(SJe," \u2014 "),Dre=n(SJe,"A",{href:!0});var Jsa=s(Dre);ZOr=r(Jsa,"TFXGLMForCausalLM"),Jsa.forEach(t),KOr=r(SJe," (XGLM model)"),SJe.forEach(t),eVr=i(Ce),Q0=n(Ce,"LI",{});var RJe=s(Q0);B7e=n(RJe,"STRONG",{});var Ysa=s(B7e);oVr=r(Ysa,"xlm"),Ysa.forEach(t),rVr=r(RJe," \u2014 "),Gre=n(RJe,"A",{href:!0});var Zsa=s(Gre);tVr=r(Zsa,"TFXLMWithLMHeadModel"),Zsa.forEach(t),aVr=r(RJe," (XLM model)"),RJe.forEach(t),nVr=i(Ce),W0=n(Ce,"LI",{});var PJe=s(W0);I7e=n(PJe,"STRONG",{});var Ksa=s(I7e);sVr=r(Ksa,"xlnet"),Ksa.forEach(t),lVr=r(PJe," \u2014 "),Ore=n(PJe,"A",{href:!0});var ela=s(Ore);iVr=r(ela,"TFXLNetLMHeadModel"),ela.forEach(t),dVr=r(PJe," (XLNet model)"),PJe.forEach(t),Ce.forEach(t),cVr=i(fi),T(U0.$$.fragment,fi),fi.forEach(t),mi.forEach(t),Lro=i(m),lm=n(m,"H2",{class:!0});var Vao=s(lm);H0=n(Vao,"A",{id:!0,class:!0,href:!0});var ola=s(H0);N7e=n(ola,"SPAN",{});var rla=s(N7e);T(DS.$$.fragment,rla),rla.forEach(t),ola.forEach(t),mVr=i(Vao),q7e=n(Vao,"SPAN",{});var tla=s(q7e);fVr=r(tla,"TFAutoModelForImageClassification"),tla.forEach(t),Vao.forEach(t),yro=i(m),mr=n(m,"DIV",{class:!0});var gi=s(mr);T(GS.$$.fragment,gi),gVr=i(gi),im=n(gi,"P",{});var Ude=s(im);hVr=r(Ude,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Vre=n(Ude,"A",{href:!0});var ala=s(Vre);uVr=r(ala,"from_pretrained()"),ala.forEach(t),pVr=r(Ude," class method or the "),Xre=n(Ude,"A",{href:!0});var nla=s(Xre);_Vr=r(nla,"from_config()"),nla.forEach(t),bVr=r(Ude,` class
method.`),Ude.forEach(t),vVr=i(gi),OS=n(gi,"P",{});var Xao=s(OS);FVr=r(Xao,"This class cannot be instantiated directly using "),j7e=n(Xao,"CODE",{});var sla=s(j7e);TVr=r(sla,"__init__()"),sla.forEach(t),MVr=r(Xao," (throws an error)."),Xao.forEach(t),EVr=i(gi),Jt=n(gi,"DIV",{class:!0});var A9=s(Jt);T(VS.$$.fragment,A9),CVr=i(A9),D7e=n(A9,"P",{});var lla=s(D7e);wVr=r(lla,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),lla.forEach(t),AVr=i(A9),dm=n(A9,"P",{});var Hde=s(dm);LVr=r(Hde,`Note:
Loading a model from its configuration file does `),G7e=n(Hde,"STRONG",{});var ila=s(G7e);yVr=r(ila,"not"),ila.forEach(t),xVr=r(Hde,` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=n(Hde,"A",{href:!0});var dla=s(zre);$Vr=r(dla,"from_pretrained()"),dla.forEach(t),kVr=r(Hde," to load the model weights."),Hde.forEach(t),SVr=i(A9),T(J0.$$.fragment,A9),A9.forEach(t),RVr=i(gi),Gr=n(gi,"DIV",{class:!0});var hi=s(Gr);T(XS.$$.fragment,hi),PVr=i(hi),O7e=n(hi,"P",{});var cla=s(O7e);BVr=r(cla,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),cla.forEach(t),IVr=i(hi),Rn=n(hi,"P",{});var L9=s(Rn);NVr=r(L9,"The model class to instantiate is selected based on the "),V7e=n(L9,"CODE",{});var mla=s(V7e);qVr=r(mla,"model_type"),mla.forEach(t),jVr=r(L9,` property of the config object (either
passed as an argument or loaded from `),X7e=n(L9,"CODE",{});var fla=s(X7e);DVr=r(fla,"pretrained_model_name_or_path"),fla.forEach(t),GVr=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z7e=n(L9,"CODE",{});var gla=s(z7e);OVr=r(gla,"pretrained_model_name_or_path"),gla.forEach(t),VVr=r(L9,":"),L9.forEach(t),XVr=i(hi),Be=n(hi,"UL",{});var We=s(Be);Y0=n(We,"LI",{});var BJe=s(Y0);Q7e=n(BJe,"STRONG",{});var hla=s(Q7e);zVr=r(hla,"convnext"),hla.forEach(t),QVr=r(BJe," \u2014 "),Qre=n(BJe,"A",{href:!0});var ula=s(Qre);WVr=r(ula,"TFConvNextForImageClassification"),ula.forEach(t),UVr=r(BJe," (ConvNeXT model)"),BJe.forEach(t),HVr=i(We),Z0=n(We,"LI",{});var IJe=s(Z0);W7e=n(IJe,"STRONG",{});var pla=s(W7e);JVr=r(pla,"data2vec-vision"),pla.forEach(t),YVr=r(IJe," \u2014 "),Wre=n(IJe,"A",{href:!0});var _la=s(Wre);ZVr=r(_la,"TFData2VecVisionForImageClassification"),_la.forEach(t),KVr=r(IJe," (Data2VecVision model)"),IJe.forEach(t),eXr=i(We),Al=n(We,"LI",{});var xI=s(Al);U7e=n(xI,"STRONG",{});var bla=s(U7e);oXr=r(bla,"deit"),bla.forEach(t),rXr=r(xI," \u2014 "),Ure=n(xI,"A",{href:!0});var vla=s(Ure);tXr=r(vla,"TFDeiTForImageClassification"),vla.forEach(t),aXr=r(xI," or "),Hre=n(xI,"A",{href:!0});var Fla=s(Hre);nXr=r(Fla,"TFDeiTForImageClassificationWithTeacher"),Fla.forEach(t),sXr=r(xI," (DeiT model)"),xI.forEach(t),lXr=i(We),K0=n(We,"LI",{});var NJe=s(K0);H7e=n(NJe,"STRONG",{});var Tla=s(H7e);iXr=r(Tla,"mobilevit"),Tla.forEach(t),dXr=r(NJe," \u2014 "),Jre=n(NJe,"A",{href:!0});var Mla=s(Jre);cXr=r(Mla,"TFMobileViTForImageClassification"),Mla.forEach(t),mXr=r(NJe," (MobileViT model)"),NJe.forEach(t),fXr=i(We),ew=n(We,"LI",{});var qJe=s(ew);J7e=n(qJe,"STRONG",{});var Ela=s(J7e);gXr=r(Ela,"regnet"),Ela.forEach(t),hXr=r(qJe," \u2014 "),Yre=n(qJe,"A",{href:!0});var Cla=s(Yre);uXr=r(Cla,"TFRegNetForImageClassification"),Cla.forEach(t),pXr=r(qJe," (RegNet model)"),qJe.forEach(t),_Xr=i(We),ow=n(We,"LI",{});var jJe=s(ow);Y7e=n(jJe,"STRONG",{});var wla=s(Y7e);bXr=r(wla,"resnet"),wla.forEach(t),vXr=r(jJe," \u2014 "),Zre=n(jJe,"A",{href:!0});var Ala=s(Zre);FXr=r(Ala,"TFResNetForImageClassification"),Ala.forEach(t),TXr=r(jJe," (ResNet model)"),jJe.forEach(t),MXr=i(We),rw=n(We,"LI",{});var DJe=s(rw);Z7e=n(DJe,"STRONG",{});var Lla=s(Z7e);EXr=r(Lla,"segformer"),Lla.forEach(t),CXr=r(DJe," \u2014 "),Kre=n(DJe,"A",{href:!0});var yla=s(Kre);wXr=r(yla,"TFSegformerForImageClassification"),yla.forEach(t),AXr=r(DJe," (SegFormer model)"),DJe.forEach(t),LXr=i(We),tw=n(We,"LI",{});var GJe=s(tw);K7e=n(GJe,"STRONG",{});var xla=s(K7e);yXr=r(xla,"swin"),xla.forEach(t),xXr=r(GJe," \u2014 "),ete=n(GJe,"A",{href:!0});var $la=s(ete);$Xr=r($la,"TFSwinForImageClassification"),$la.forEach(t),kXr=r(GJe," (Swin Transformer model)"),GJe.forEach(t),SXr=i(We),aw=n(We,"LI",{});var OJe=s(aw);eLe=n(OJe,"STRONG",{});var kla=s(eLe);RXr=r(kla,"vit"),kla.forEach(t),PXr=r(OJe," \u2014 "),ote=n(OJe,"A",{href:!0});var Sla=s(ote);BXr=r(Sla,"TFViTForImageClassification"),Sla.forEach(t),IXr=r(OJe," (ViT model)"),OJe.forEach(t),We.forEach(t),NXr=i(hi),T(nw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),xro=i(m),cm=n(m,"H2",{class:!0});var zao=s(cm);sw=n(zao,"A",{id:!0,class:!0,href:!0});var Rla=s(sw);oLe=n(Rla,"SPAN",{});var Pla=s(oLe);T(zS.$$.fragment,Pla),Pla.forEach(t),Rla.forEach(t),qXr=i(zao),rLe=n(zao,"SPAN",{});var Bla=s(rLe);jXr=r(Bla,"TFAutoModelForSemanticSegmentation"),Bla.forEach(t),zao.forEach(t),$ro=i(m),fr=n(m,"DIV",{class:!0});var ui=s(fr);T(QS.$$.fragment,ui),DXr=i(ui),mm=n(ui,"P",{});var Jde=s(mm);GXr=r(Jde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),rte=n(Jde,"A",{href:!0});var Ila=s(rte);OXr=r(Ila,"from_pretrained()"),Ila.forEach(t),VXr=r(Jde," class method or the "),tte=n(Jde,"A",{href:!0});var Nla=s(tte);XXr=r(Nla,"from_config()"),Nla.forEach(t),zXr=r(Jde,` class
method.`),Jde.forEach(t),QXr=i(ui),WS=n(ui,"P",{});var Qao=s(WS);WXr=r(Qao,"This class cannot be instantiated directly using "),tLe=n(Qao,"CODE",{});var qla=s(tLe);UXr=r(qla,"__init__()"),qla.forEach(t),HXr=r(Qao," (throws an error)."),Qao.forEach(t),JXr=i(ui),Yt=n(ui,"DIV",{class:!0});var y9=s(Yt);T(US.$$.fragment,y9),YXr=i(y9),aLe=n(y9,"P",{});var jla=s(aLe);ZXr=r(jla,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),jla.forEach(t),KXr=i(y9),fm=n(y9,"P",{});var Yde=s(fm);ezr=r(Yde,`Note:
Loading a model from its configuration file does `),nLe=n(Yde,"STRONG",{});var Dla=s(nLe);ozr=r(Dla,"not"),Dla.forEach(t),rzr=r(Yde,` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=n(Yde,"A",{href:!0});var Gla=s(ate);tzr=r(Gla,"from_pretrained()"),Gla.forEach(t),azr=r(Yde," to load the model weights."),Yde.forEach(t),nzr=i(y9),T(lw.$$.fragment,y9),y9.forEach(t),szr=i(ui),Or=n(ui,"DIV",{class:!0});var pi=s(Or);T(HS.$$.fragment,pi),lzr=i(pi),sLe=n(pi,"P",{});var Ola=s(sLe);izr=r(Ola,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Ola.forEach(t),dzr=i(pi),Pn=n(pi,"P",{});var x9=s(Pn);czr=r(x9,"The model class to instantiate is selected based on the "),lLe=n(x9,"CODE",{});var Vla=s(lLe);mzr=r(Vla,"model_type"),Vla.forEach(t),fzr=r(x9,` property of the config object (either
passed as an argument or loaded from `),iLe=n(x9,"CODE",{});var Xla=s(iLe);gzr=r(Xla,"pretrained_model_name_or_path"),Xla.forEach(t),hzr=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dLe=n(x9,"CODE",{});var zla=s(dLe);uzr=r(zla,"pretrained_model_name_or_path"),zla.forEach(t),pzr=r(x9,":"),x9.forEach(t),_zr=i(pi),gm=n(pi,"UL",{});var Zde=s(gm);iw=n(Zde,"LI",{});var VJe=s(iw);cLe=n(VJe,"STRONG",{});var Qla=s(cLe);bzr=r(Qla,"data2vec-vision"),Qla.forEach(t),vzr=r(VJe," \u2014 "),nte=n(VJe,"A",{href:!0});var Wla=s(nte);Fzr=r(Wla,"TFData2VecVisionForSemanticSegmentation"),Wla.forEach(t),Tzr=r(VJe," (Data2VecVision model)"),VJe.forEach(t),Mzr=i(Zde),dw=n(Zde,"LI",{});var XJe=s(dw);mLe=n(XJe,"STRONG",{});var Ula=s(mLe);Ezr=r(Ula,"mobilevit"),Ula.forEach(t),Czr=r(XJe," \u2014 "),ste=n(XJe,"A",{href:!0});var Hla=s(ste);wzr=r(Hla,"TFMobileViTForSemanticSegmentation"),Hla.forEach(t),Azr=r(XJe," (MobileViT model)"),XJe.forEach(t),Lzr=i(Zde),cw=n(Zde,"LI",{});var zJe=s(cw);fLe=n(zJe,"STRONG",{});var Jla=s(fLe);yzr=r(Jla,"segformer"),Jla.forEach(t),xzr=r(zJe," \u2014 "),lte=n(zJe,"A",{href:!0});var Yla=s(lte);$zr=r(Yla,"TFSegformerForSemanticSegmentation"),Yla.forEach(t),kzr=r(zJe," (SegFormer model)"),zJe.forEach(t),Zde.forEach(t),Szr=i(pi),T(mw.$$.fragment,pi),pi.forEach(t),ui.forEach(t),kro=i(m),hm=n(m,"H2",{class:!0});var Wao=s(hm);fw=n(Wao,"A",{id:!0,class:!0,href:!0});var Zla=s(fw);gLe=n(Zla,"SPAN",{});var Kla=s(gLe);T(JS.$$.fragment,Kla),Kla.forEach(t),Zla.forEach(t),Rzr=i(Wao),hLe=n(Wao,"SPAN",{});var eia=s(hLe);Pzr=r(eia,"TFAutoModelForMaskedLM"),eia.forEach(t),Wao.forEach(t),Sro=i(m),gr=n(m,"DIV",{class:!0});var _i=s(gr);T(YS.$$.fragment,_i),Bzr=i(_i),um=n(_i,"P",{});var Kde=s(um);Izr=r(Kde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ite=n(Kde,"A",{href:!0});var oia=s(ite);Nzr=r(oia,"from_pretrained()"),oia.forEach(t),qzr=r(Kde," class method or the "),dte=n(Kde,"A",{href:!0});var ria=s(dte);jzr=r(ria,"from_config()"),ria.forEach(t),Dzr=r(Kde,` class
method.`),Kde.forEach(t),Gzr=i(_i),ZS=n(_i,"P",{});var Uao=s(ZS);Ozr=r(Uao,"This class cannot be instantiated directly using "),uLe=n(Uao,"CODE",{});var tia=s(uLe);Vzr=r(tia,"__init__()"),tia.forEach(t),Xzr=r(Uao," (throws an error)."),Uao.forEach(t),zzr=i(_i),Zt=n(_i,"DIV",{class:!0});var $9=s(Zt);T(KS.$$.fragment,$9),Qzr=i($9),pLe=n($9,"P",{});var aia=s(pLe);Wzr=r(aia,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),aia.forEach(t),Uzr=i($9),pm=n($9,"P",{});var ece=s(pm);Hzr=r(ece,`Note:
Loading a model from its configuration file does `),_Le=n(ece,"STRONG",{});var nia=s(_Le);Jzr=r(nia,"not"),nia.forEach(t),Yzr=r(ece,` load the model weights. It only affects the
model\u2019s configuration. Use `),cte=n(ece,"A",{href:!0});var sia=s(cte);Zzr=r(sia,"from_pretrained()"),sia.forEach(t),Kzr=r(ece," to load the model weights."),ece.forEach(t),eQr=i($9),T(gw.$$.fragment,$9),$9.forEach(t),oQr=i(_i),Vr=n(_i,"DIV",{class:!0});var bi=s(Vr);T(eR.$$.fragment,bi),rQr=i(bi),bLe=n(bi,"P",{});var lia=s(bLe);tQr=r(lia,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),lia.forEach(t),aQr=i(bi),Bn=n(bi,"P",{});var k9=s(Bn);nQr=r(k9,"The model class to instantiate is selected based on the "),vLe=n(k9,"CODE",{});var iia=s(vLe);sQr=r(iia,"model_type"),iia.forEach(t),lQr=r(k9,` property of the config object (either
passed as an argument or loaded from `),FLe=n(k9,"CODE",{});var dia=s(FLe);iQr=r(dia,"pretrained_model_name_or_path"),dia.forEach(t),dQr=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TLe=n(k9,"CODE",{});var cia=s(TLe);cQr=r(cia,"pretrained_model_name_or_path"),cia.forEach(t),mQr=r(k9,":"),k9.forEach(t),fQr=i(bi),ge=n(bi,"UL",{});var _e=s(ge);hw=n(_e,"LI",{});var QJe=s(hw);MLe=n(QJe,"STRONG",{});var mia=s(MLe);gQr=r(mia,"albert"),mia.forEach(t),hQr=r(QJe," \u2014 "),mte=n(QJe,"A",{href:!0});var fia=s(mte);uQr=r(fia,"TFAlbertForMaskedLM"),fia.forEach(t),pQr=r(QJe," (ALBERT model)"),QJe.forEach(t),_Qr=i(_e),uw=n(_e,"LI",{});var WJe=s(uw);ELe=n(WJe,"STRONG",{});var gia=s(ELe);bQr=r(gia,"bert"),gia.forEach(t),vQr=r(WJe," \u2014 "),fte=n(WJe,"A",{href:!0});var hia=s(fte);FQr=r(hia,"TFBertForMaskedLM"),hia.forEach(t),TQr=r(WJe," (BERT model)"),WJe.forEach(t),MQr=i(_e),pw=n(_e,"LI",{});var UJe=s(pw);CLe=n(UJe,"STRONG",{});var uia=s(CLe);EQr=r(uia,"camembert"),uia.forEach(t),CQr=r(UJe," \u2014 "),gte=n(UJe,"A",{href:!0});var pia=s(gte);wQr=r(pia,"TFCamembertForMaskedLM"),pia.forEach(t),AQr=r(UJe," (CamemBERT model)"),UJe.forEach(t),LQr=i(_e),_w=n(_e,"LI",{});var HJe=s(_w);wLe=n(HJe,"STRONG",{});var _ia=s(wLe);yQr=r(_ia,"convbert"),_ia.forEach(t),xQr=r(HJe," \u2014 "),hte=n(HJe,"A",{href:!0});var bia=s(hte);$Qr=r(bia,"TFConvBertForMaskedLM"),bia.forEach(t),kQr=r(HJe," (ConvBERT model)"),HJe.forEach(t),SQr=i(_e),bw=n(_e,"LI",{});var JJe=s(bw);ALe=n(JJe,"STRONG",{});var via=s(ALe);RQr=r(via,"deberta"),via.forEach(t),PQr=r(JJe," \u2014 "),ute=n(JJe,"A",{href:!0});var Fia=s(ute);BQr=r(Fia,"TFDebertaForMaskedLM"),Fia.forEach(t),IQr=r(JJe," (DeBERTa model)"),JJe.forEach(t),NQr=i(_e),vw=n(_e,"LI",{});var YJe=s(vw);LLe=n(YJe,"STRONG",{});var Tia=s(LLe);qQr=r(Tia,"deberta-v2"),Tia.forEach(t),jQr=r(YJe," \u2014 "),pte=n(YJe,"A",{href:!0});var Mia=s(pte);DQr=r(Mia,"TFDebertaV2ForMaskedLM"),Mia.forEach(t),GQr=r(YJe," (DeBERTa-v2 model)"),YJe.forEach(t),OQr=i(_e),Fw=n(_e,"LI",{});var ZJe=s(Fw);yLe=n(ZJe,"STRONG",{});var Eia=s(yLe);VQr=r(Eia,"distilbert"),Eia.forEach(t),XQr=r(ZJe," \u2014 "),_te=n(ZJe,"A",{href:!0});var Cia=s(_te);zQr=r(Cia,"TFDistilBertForMaskedLM"),Cia.forEach(t),QQr=r(ZJe," (DistilBERT model)"),ZJe.forEach(t),WQr=i(_e),Tw=n(_e,"LI",{});var KJe=s(Tw);xLe=n(KJe,"STRONG",{});var wia=s(xLe);UQr=r(wia,"electra"),wia.forEach(t),HQr=r(KJe," \u2014 "),bte=n(KJe,"A",{href:!0});var Aia=s(bte);JQr=r(Aia,"TFElectraForMaskedLM"),Aia.forEach(t),YQr=r(KJe," (ELECTRA model)"),KJe.forEach(t),ZQr=i(_e),Mw=n(_e,"LI",{});var eYe=s(Mw);$Le=n(eYe,"STRONG",{});var Lia=s($Le);KQr=r(Lia,"flaubert"),Lia.forEach(t),eWr=r(eYe," \u2014 "),vte=n(eYe,"A",{href:!0});var yia=s(vte);oWr=r(yia,"TFFlaubertWithLMHeadModel"),yia.forEach(t),rWr=r(eYe," (FlauBERT model)"),eYe.forEach(t),tWr=i(_e),Ew=n(_e,"LI",{});var oYe=s(Ew);kLe=n(oYe,"STRONG",{});var xia=s(kLe);aWr=r(xia,"funnel"),xia.forEach(t),nWr=r(oYe," \u2014 "),Fte=n(oYe,"A",{href:!0});var $ia=s(Fte);sWr=r($ia,"TFFunnelForMaskedLM"),$ia.forEach(t),lWr=r(oYe," (Funnel Transformer model)"),oYe.forEach(t),iWr=i(_e),Cw=n(_e,"LI",{});var rYe=s(Cw);SLe=n(rYe,"STRONG",{});var kia=s(SLe);dWr=r(kia,"layoutlm"),kia.forEach(t),cWr=r(rYe," \u2014 "),Tte=n(rYe,"A",{href:!0});var Sia=s(Tte);mWr=r(Sia,"TFLayoutLMForMaskedLM"),Sia.forEach(t),fWr=r(rYe," (LayoutLM model)"),rYe.forEach(t),gWr=i(_e),ww=n(_e,"LI",{});var tYe=s(ww);RLe=n(tYe,"STRONG",{});var Ria=s(RLe);hWr=r(Ria,"longformer"),Ria.forEach(t),uWr=r(tYe," \u2014 "),Mte=n(tYe,"A",{href:!0});var Pia=s(Mte);pWr=r(Pia,"TFLongformerForMaskedLM"),Pia.forEach(t),_Wr=r(tYe," (Longformer model)"),tYe.forEach(t),bWr=i(_e),Aw=n(_e,"LI",{});var aYe=s(Aw);PLe=n(aYe,"STRONG",{});var Bia=s(PLe);vWr=r(Bia,"mobilebert"),Bia.forEach(t),FWr=r(aYe," \u2014 "),Ete=n(aYe,"A",{href:!0});var Iia=s(Ete);TWr=r(Iia,"TFMobileBertForMaskedLM"),Iia.forEach(t),MWr=r(aYe," (MobileBERT model)"),aYe.forEach(t),EWr=i(_e),Lw=n(_e,"LI",{});var nYe=s(Lw);BLe=n(nYe,"STRONG",{});var Nia=s(BLe);CWr=r(Nia,"mpnet"),Nia.forEach(t),wWr=r(nYe," \u2014 "),Cte=n(nYe,"A",{href:!0});var qia=s(Cte);AWr=r(qia,"TFMPNetForMaskedLM"),qia.forEach(t),LWr=r(nYe," (MPNet model)"),nYe.forEach(t),yWr=i(_e),yw=n(_e,"LI",{});var sYe=s(yw);ILe=n(sYe,"STRONG",{});var jia=s(ILe);xWr=r(jia,"rembert"),jia.forEach(t),$Wr=r(sYe," \u2014 "),wte=n(sYe,"A",{href:!0});var Dia=s(wte);kWr=r(Dia,"TFRemBertForMaskedLM"),Dia.forEach(t),SWr=r(sYe," (RemBERT model)"),sYe.forEach(t),RWr=i(_e),xw=n(_e,"LI",{});var lYe=s(xw);NLe=n(lYe,"STRONG",{});var Gia=s(NLe);PWr=r(Gia,"roberta"),Gia.forEach(t),BWr=r(lYe," \u2014 "),Ate=n(lYe,"A",{href:!0});var Oia=s(Ate);IWr=r(Oia,"TFRobertaForMaskedLM"),Oia.forEach(t),NWr=r(lYe," (RoBERTa model)"),lYe.forEach(t),qWr=i(_e),$w=n(_e,"LI",{});var iYe=s($w);qLe=n(iYe,"STRONG",{});var Via=s(qLe);jWr=r(Via,"roformer"),Via.forEach(t),DWr=r(iYe," \u2014 "),Lte=n(iYe,"A",{href:!0});var Xia=s(Lte);GWr=r(Xia,"TFRoFormerForMaskedLM"),Xia.forEach(t),OWr=r(iYe," (RoFormer model)"),iYe.forEach(t),VWr=i(_e),kw=n(_e,"LI",{});var dYe=s(kw);jLe=n(dYe,"STRONG",{});var zia=s(jLe);XWr=r(zia,"tapas"),zia.forEach(t),zWr=r(dYe," \u2014 "),yte=n(dYe,"A",{href:!0});var Qia=s(yte);QWr=r(Qia,"TFTapasForMaskedLM"),Qia.forEach(t),WWr=r(dYe," (TAPAS model)"),dYe.forEach(t),UWr=i(_e),Sw=n(_e,"LI",{});var cYe=s(Sw);DLe=n(cYe,"STRONG",{});var Wia=s(DLe);HWr=r(Wia,"xlm"),Wia.forEach(t),JWr=r(cYe," \u2014 "),xte=n(cYe,"A",{href:!0});var Uia=s(xte);YWr=r(Uia,"TFXLMWithLMHeadModel"),Uia.forEach(t),ZWr=r(cYe," (XLM model)"),cYe.forEach(t),KWr=i(_e),Rw=n(_e,"LI",{});var mYe=s(Rw);GLe=n(mYe,"STRONG",{});var Hia=s(GLe);eUr=r(Hia,"xlm-roberta"),Hia.forEach(t),oUr=r(mYe," \u2014 "),$te=n(mYe,"A",{href:!0});var Jia=s($te);rUr=r(Jia,"TFXLMRobertaForMaskedLM"),Jia.forEach(t),tUr=r(mYe," (XLM-RoBERTa model)"),mYe.forEach(t),_e.forEach(t),aUr=i(bi),T(Pw.$$.fragment,bi),bi.forEach(t),_i.forEach(t),Rro=i(m),_m=n(m,"H2",{class:!0});var Hao=s(_m);Bw=n(Hao,"A",{id:!0,class:!0,href:!0});var Yia=s(Bw);OLe=n(Yia,"SPAN",{});var Zia=s(OLe);T(oR.$$.fragment,Zia),Zia.forEach(t),Yia.forEach(t),nUr=i(Hao),VLe=n(Hao,"SPAN",{});var Kia=s(VLe);sUr=r(Kia,"TFAutoModelForSeq2SeqLM"),Kia.forEach(t),Hao.forEach(t),Pro=i(m),hr=n(m,"DIV",{class:!0});var vi=s(hr);T(rR.$$.fragment,vi),lUr=i(vi),bm=n(vi,"P",{});var oce=s(bm);iUr=r(oce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kte=n(oce,"A",{href:!0});var eda=s(kte);dUr=r(eda,"from_pretrained()"),eda.forEach(t),cUr=r(oce," class method or the "),Ste=n(oce,"A",{href:!0});var oda=s(Ste);mUr=r(oda,"from_config()"),oda.forEach(t),fUr=r(oce,` class
method.`),oce.forEach(t),gUr=i(vi),tR=n(vi,"P",{});var Jao=s(tR);hUr=r(Jao,"This class cannot be instantiated directly using "),XLe=n(Jao,"CODE",{});var rda=s(XLe);uUr=r(rda,"__init__()"),rda.forEach(t),pUr=r(Jao," (throws an error)."),Jao.forEach(t),_Ur=i(vi),Kt=n(vi,"DIV",{class:!0});var S9=s(Kt);T(aR.$$.fragment,S9),bUr=i(S9),zLe=n(S9,"P",{});var tda=s(zLe);vUr=r(tda,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),tda.forEach(t),FUr=i(S9),vm=n(S9,"P",{});var rce=s(vm);TUr=r(rce,`Note:
Loading a model from its configuration file does `),QLe=n(rce,"STRONG",{});var ada=s(QLe);MUr=r(ada,"not"),ada.forEach(t),EUr=r(rce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rte=n(rce,"A",{href:!0});var nda=s(Rte);CUr=r(nda,"from_pretrained()"),nda.forEach(t),wUr=r(rce," to load the model weights."),rce.forEach(t),AUr=i(S9),T(Iw.$$.fragment,S9),S9.forEach(t),LUr=i(vi),Xr=n(vi,"DIV",{class:!0});var Fi=s(Xr);T(nR.$$.fragment,Fi),yUr=i(Fi),WLe=n(Fi,"P",{});var sda=s(WLe);xUr=r(sda,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),sda.forEach(t),$Ur=i(Fi),In=n(Fi,"P",{});var R9=s(In);kUr=r(R9,"The model class to instantiate is selected based on the "),ULe=n(R9,"CODE",{});var lda=s(ULe);SUr=r(lda,"model_type"),lda.forEach(t),RUr=r(R9,` property of the config object (either
passed as an argument or loaded from `),HLe=n(R9,"CODE",{});var ida=s(HLe);PUr=r(ida,"pretrained_model_name_or_path"),ida.forEach(t),BUr=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JLe=n(R9,"CODE",{});var dda=s(JLe);IUr=r(dda,"pretrained_model_name_or_path"),dda.forEach(t),NUr=r(R9,":"),R9.forEach(t),qUr=i(Fi),ye=n(Fi,"UL",{});var Ne=s(ye);Nw=n(Ne,"LI",{});var fYe=s(Nw);YLe=n(fYe,"STRONG",{});var cda=s(YLe);jUr=r(cda,"bart"),cda.forEach(t),DUr=r(fYe," \u2014 "),Pte=n(fYe,"A",{href:!0});var mda=s(Pte);GUr=r(mda,"TFBartForConditionalGeneration"),mda.forEach(t),OUr=r(fYe," (BART model)"),fYe.forEach(t),VUr=i(Ne),qw=n(Ne,"LI",{});var gYe=s(qw);ZLe=n(gYe,"STRONG",{});var fda=s(ZLe);XUr=r(fda,"blenderbot"),fda.forEach(t),zUr=r(gYe," \u2014 "),Bte=n(gYe,"A",{href:!0});var gda=s(Bte);QUr=r(gda,"TFBlenderbotForConditionalGeneration"),gda.forEach(t),WUr=r(gYe," (Blenderbot model)"),gYe.forEach(t),UUr=i(Ne),jw=n(Ne,"LI",{});var hYe=s(jw);KLe=n(hYe,"STRONG",{});var hda=s(KLe);HUr=r(hda,"blenderbot-small"),hda.forEach(t),JUr=r(hYe," \u2014 "),Ite=n(hYe,"A",{href:!0});var uda=s(Ite);YUr=r(uda,"TFBlenderbotSmallForConditionalGeneration"),uda.forEach(t),ZUr=r(hYe," (BlenderbotSmall model)"),hYe.forEach(t),KUr=i(Ne),Dw=n(Ne,"LI",{});var uYe=s(Dw);eye=n(uYe,"STRONG",{});var pda=s(eye);eHr=r(pda,"encoder-decoder"),pda.forEach(t),oHr=r(uYe," \u2014 "),Nte=n(uYe,"A",{href:!0});var _da=s(Nte);rHr=r(_da,"TFEncoderDecoderModel"),_da.forEach(t),tHr=r(uYe," (Encoder decoder model)"),uYe.forEach(t),aHr=i(Ne),Gw=n(Ne,"LI",{});var pYe=s(Gw);oye=n(pYe,"STRONG",{});var bda=s(oye);nHr=r(bda,"led"),bda.forEach(t),sHr=r(pYe," \u2014 "),qte=n(pYe,"A",{href:!0});var vda=s(qte);lHr=r(vda,"TFLEDForConditionalGeneration"),vda.forEach(t),iHr=r(pYe," (LED model)"),pYe.forEach(t),dHr=i(Ne),Ow=n(Ne,"LI",{});var _Ye=s(Ow);rye=n(_Ye,"STRONG",{});var Fda=s(rye);cHr=r(Fda,"marian"),Fda.forEach(t),mHr=r(_Ye," \u2014 "),jte=n(_Ye,"A",{href:!0});var Tda=s(jte);fHr=r(Tda,"TFMarianMTModel"),Tda.forEach(t),gHr=r(_Ye," (Marian model)"),_Ye.forEach(t),hHr=i(Ne),Vw=n(Ne,"LI",{});var bYe=s(Vw);tye=n(bYe,"STRONG",{});var Mda=s(tye);uHr=r(Mda,"mbart"),Mda.forEach(t),pHr=r(bYe," \u2014 "),Dte=n(bYe,"A",{href:!0});var Eda=s(Dte);_Hr=r(Eda,"TFMBartForConditionalGeneration"),Eda.forEach(t),bHr=r(bYe," (mBART model)"),bYe.forEach(t),vHr=i(Ne),Xw=n(Ne,"LI",{});var vYe=s(Xw);aye=n(vYe,"STRONG",{});var Cda=s(aye);FHr=r(Cda,"mt5"),Cda.forEach(t),THr=r(vYe," \u2014 "),Gte=n(vYe,"A",{href:!0});var wda=s(Gte);MHr=r(wda,"TFMT5ForConditionalGeneration"),wda.forEach(t),EHr=r(vYe," (MT5 model)"),vYe.forEach(t),CHr=i(Ne),zw=n(Ne,"LI",{});var FYe=s(zw);nye=n(FYe,"STRONG",{});var Ada=s(nye);wHr=r(Ada,"pegasus"),Ada.forEach(t),AHr=r(FYe," \u2014 "),Ote=n(FYe,"A",{href:!0});var Lda=s(Ote);LHr=r(Lda,"TFPegasusForConditionalGeneration"),Lda.forEach(t),yHr=r(FYe," (Pegasus model)"),FYe.forEach(t),xHr=i(Ne),Qw=n(Ne,"LI",{});var TYe=s(Qw);sye=n(TYe,"STRONG",{});var yda=s(sye);$Hr=r(yda,"t5"),yda.forEach(t),kHr=r(TYe," \u2014 "),Vte=n(TYe,"A",{href:!0});var xda=s(Vte);SHr=r(xda,"TFT5ForConditionalGeneration"),xda.forEach(t),RHr=r(TYe," (T5 model)"),TYe.forEach(t),Ne.forEach(t),PHr=i(Fi),T(Ww.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),Bro=i(m),Fm=n(m,"H2",{class:!0});var Yao=s(Fm);Uw=n(Yao,"A",{id:!0,class:!0,href:!0});var $da=s(Uw);lye=n($da,"SPAN",{});var kda=s(lye);T(sR.$$.fragment,kda),kda.forEach(t),$da.forEach(t),BHr=i(Yao),iye=n(Yao,"SPAN",{});var Sda=s(iye);IHr=r(Sda,"TFAutoModelForSequenceClassification"),Sda.forEach(t),Yao.forEach(t),Iro=i(m),ur=n(m,"DIV",{class:!0});var Ti=s(ur);T(lR.$$.fragment,Ti),NHr=i(Ti),Tm=n(Ti,"P",{});var tce=s(Tm);qHr=r(tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Xte=n(tce,"A",{href:!0});var Rda=s(Xte);jHr=r(Rda,"from_pretrained()"),Rda.forEach(t),DHr=r(tce," class method or the "),zte=n(tce,"A",{href:!0});var Pda=s(zte);GHr=r(Pda,"from_config()"),Pda.forEach(t),OHr=r(tce,` class
method.`),tce.forEach(t),VHr=i(Ti),iR=n(Ti,"P",{});var Zao=s(iR);XHr=r(Zao,"This class cannot be instantiated directly using "),dye=n(Zao,"CODE",{});var Bda=s(dye);zHr=r(Bda,"__init__()"),Bda.forEach(t),QHr=r(Zao," (throws an error)."),Zao.forEach(t),WHr=i(Ti),ea=n(Ti,"DIV",{class:!0});var P9=s(ea);T(dR.$$.fragment,P9),UHr=i(P9),cye=n(P9,"P",{});var Ida=s(cye);HHr=r(Ida,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Ida.forEach(t),JHr=i(P9),Mm=n(P9,"P",{});var ace=s(Mm);YHr=r(ace,`Note:
Loading a model from its configuration file does `),mye=n(ace,"STRONG",{});var Nda=s(mye);ZHr=r(Nda,"not"),Nda.forEach(t),KHr=r(ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qte=n(ace,"A",{href:!0});var qda=s(Qte);eJr=r(qda,"from_pretrained()"),qda.forEach(t),oJr=r(ace," to load the model weights."),ace.forEach(t),rJr=i(P9),T(Hw.$$.fragment,P9),P9.forEach(t),tJr=i(Ti),zr=n(Ti,"DIV",{class:!0});var Mi=s(zr);T(cR.$$.fragment,Mi),aJr=i(Mi),fye=n(Mi,"P",{});var jda=s(fye);nJr=r(jda,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),jda.forEach(t),sJr=i(Mi),Nn=n(Mi,"P",{});var B9=s(Nn);lJr=r(B9,"The model class to instantiate is selected based on the "),gye=n(B9,"CODE",{});var Dda=s(gye);iJr=r(Dda,"model_type"),Dda.forEach(t),dJr=r(B9,` property of the config object (either
passed as an argument or loaded from `),hye=n(B9,"CODE",{});var Gda=s(hye);cJr=r(Gda,"pretrained_model_name_or_path"),Gda.forEach(t),mJr=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=n(B9,"CODE",{});var Oda=s(uye);fJr=r(Oda,"pretrained_model_name_or_path"),Oda.forEach(t),gJr=r(B9,":"),B9.forEach(t),hJr=i(Mi),re=n(Mi,"UL",{});var ae=s(re);Jw=n(ae,"LI",{});var MYe=s(Jw);pye=n(MYe,"STRONG",{});var Vda=s(pye);uJr=r(Vda,"albert"),Vda.forEach(t),pJr=r(MYe," \u2014 "),Wte=n(MYe,"A",{href:!0});var Xda=s(Wte);_Jr=r(Xda,"TFAlbertForSequenceClassification"),Xda.forEach(t),bJr=r(MYe," (ALBERT model)"),MYe.forEach(t),vJr=i(ae),Yw=n(ae,"LI",{});var EYe=s(Yw);_ye=n(EYe,"STRONG",{});var zda=s(_ye);FJr=r(zda,"bert"),zda.forEach(t),TJr=r(EYe," \u2014 "),Ute=n(EYe,"A",{href:!0});var Qda=s(Ute);MJr=r(Qda,"TFBertForSequenceClassification"),Qda.forEach(t),EJr=r(EYe," (BERT model)"),EYe.forEach(t),CJr=i(ae),Zw=n(ae,"LI",{});var CYe=s(Zw);bye=n(CYe,"STRONG",{});var Wda=s(bye);wJr=r(Wda,"camembert"),Wda.forEach(t),AJr=r(CYe," \u2014 "),Hte=n(CYe,"A",{href:!0});var Uda=s(Hte);LJr=r(Uda,"TFCamembertForSequenceClassification"),Uda.forEach(t),yJr=r(CYe," (CamemBERT model)"),CYe.forEach(t),xJr=i(ae),Kw=n(ae,"LI",{});var wYe=s(Kw);vye=n(wYe,"STRONG",{});var Hda=s(vye);$Jr=r(Hda,"convbert"),Hda.forEach(t),kJr=r(wYe," \u2014 "),Jte=n(wYe,"A",{href:!0});var Jda=s(Jte);SJr=r(Jda,"TFConvBertForSequenceClassification"),Jda.forEach(t),RJr=r(wYe," (ConvBERT model)"),wYe.forEach(t),PJr=i(ae),eA=n(ae,"LI",{});var AYe=s(eA);Fye=n(AYe,"STRONG",{});var Yda=s(Fye);BJr=r(Yda,"ctrl"),Yda.forEach(t),IJr=r(AYe," \u2014 "),Yte=n(AYe,"A",{href:!0});var Zda=s(Yte);NJr=r(Zda,"TFCTRLForSequenceClassification"),Zda.forEach(t),qJr=r(AYe," (CTRL model)"),AYe.forEach(t),jJr=i(ae),oA=n(ae,"LI",{});var LYe=s(oA);Tye=n(LYe,"STRONG",{});var Kda=s(Tye);DJr=r(Kda,"deberta"),Kda.forEach(t),GJr=r(LYe," \u2014 "),Zte=n(LYe,"A",{href:!0});var eca=s(Zte);OJr=r(eca,"TFDebertaForSequenceClassification"),eca.forEach(t),VJr=r(LYe," (DeBERTa model)"),LYe.forEach(t),XJr=i(ae),rA=n(ae,"LI",{});var yYe=s(rA);Mye=n(yYe,"STRONG",{});var oca=s(Mye);zJr=r(oca,"deberta-v2"),oca.forEach(t),QJr=r(yYe," \u2014 "),Kte=n(yYe,"A",{href:!0});var rca=s(Kte);WJr=r(rca,"TFDebertaV2ForSequenceClassification"),rca.forEach(t),UJr=r(yYe," (DeBERTa-v2 model)"),yYe.forEach(t),HJr=i(ae),tA=n(ae,"LI",{});var xYe=s(tA);Eye=n(xYe,"STRONG",{});var tca=s(Eye);JJr=r(tca,"distilbert"),tca.forEach(t),YJr=r(xYe," \u2014 "),eae=n(xYe,"A",{href:!0});var aca=s(eae);ZJr=r(aca,"TFDistilBertForSequenceClassification"),aca.forEach(t),KJr=r(xYe," (DistilBERT model)"),xYe.forEach(t),eYr=i(ae),aA=n(ae,"LI",{});var $Ye=s(aA);Cye=n($Ye,"STRONG",{});var nca=s(Cye);oYr=r(nca,"electra"),nca.forEach(t),rYr=r($Ye," \u2014 "),oae=n($Ye,"A",{href:!0});var sca=s(oae);tYr=r(sca,"TFElectraForSequenceClassification"),sca.forEach(t),aYr=r($Ye," (ELECTRA model)"),$Ye.forEach(t),nYr=i(ae),nA=n(ae,"LI",{});var kYe=s(nA);wye=n(kYe,"STRONG",{});var lca=s(wye);sYr=r(lca,"flaubert"),lca.forEach(t),lYr=r(kYe," \u2014 "),rae=n(kYe,"A",{href:!0});var ica=s(rae);iYr=r(ica,"TFFlaubertForSequenceClassification"),ica.forEach(t),dYr=r(kYe," (FlauBERT model)"),kYe.forEach(t),cYr=i(ae),sA=n(ae,"LI",{});var SYe=s(sA);Aye=n(SYe,"STRONG",{});var dca=s(Aye);mYr=r(dca,"funnel"),dca.forEach(t),fYr=r(SYe," \u2014 "),tae=n(SYe,"A",{href:!0});var cca=s(tae);gYr=r(cca,"TFFunnelForSequenceClassification"),cca.forEach(t),hYr=r(SYe," (Funnel Transformer model)"),SYe.forEach(t),uYr=i(ae),lA=n(ae,"LI",{});var RYe=s(lA);Lye=n(RYe,"STRONG",{});var mca=s(Lye);pYr=r(mca,"gpt2"),mca.forEach(t),_Yr=r(RYe," \u2014 "),aae=n(RYe,"A",{href:!0});var fca=s(aae);bYr=r(fca,"TFGPT2ForSequenceClassification"),fca.forEach(t),vYr=r(RYe," (OpenAI GPT-2 model)"),RYe.forEach(t),FYr=i(ae),iA=n(ae,"LI",{});var PYe=s(iA);yye=n(PYe,"STRONG",{});var gca=s(yye);TYr=r(gca,"gptj"),gca.forEach(t),MYr=r(PYe," \u2014 "),nae=n(PYe,"A",{href:!0});var hca=s(nae);EYr=r(hca,"TFGPTJForSequenceClassification"),hca.forEach(t),CYr=r(PYe," (GPT-J model)"),PYe.forEach(t),wYr=i(ae),dA=n(ae,"LI",{});var BYe=s(dA);xye=n(BYe,"STRONG",{});var uca=s(xye);AYr=r(uca,"layoutlm"),uca.forEach(t),LYr=r(BYe," \u2014 "),sae=n(BYe,"A",{href:!0});var pca=s(sae);yYr=r(pca,"TFLayoutLMForSequenceClassification"),pca.forEach(t),xYr=r(BYe," (LayoutLM model)"),BYe.forEach(t),$Yr=i(ae),cA=n(ae,"LI",{});var IYe=s(cA);$ye=n(IYe,"STRONG",{});var _ca=s($ye);kYr=r(_ca,"layoutlmv3"),_ca.forEach(t),SYr=r(IYe," \u2014 "),lae=n(IYe,"A",{href:!0});var bca=s(lae);RYr=r(bca,"TFLayoutLMv3ForSequenceClassification"),bca.forEach(t),PYr=r(IYe," (LayoutLMv3 model)"),IYe.forEach(t),BYr=i(ae),mA=n(ae,"LI",{});var NYe=s(mA);kye=n(NYe,"STRONG",{});var vca=s(kye);IYr=r(vca,"longformer"),vca.forEach(t),NYr=r(NYe," \u2014 "),iae=n(NYe,"A",{href:!0});var Fca=s(iae);qYr=r(Fca,"TFLongformerForSequenceClassification"),Fca.forEach(t),jYr=r(NYe," (Longformer model)"),NYe.forEach(t),DYr=i(ae),fA=n(ae,"LI",{});var qYe=s(fA);Sye=n(qYe,"STRONG",{});var Tca=s(Sye);GYr=r(Tca,"mobilebert"),Tca.forEach(t),OYr=r(qYe," \u2014 "),dae=n(qYe,"A",{href:!0});var Mca=s(dae);VYr=r(Mca,"TFMobileBertForSequenceClassification"),Mca.forEach(t),XYr=r(qYe," (MobileBERT model)"),qYe.forEach(t),zYr=i(ae),gA=n(ae,"LI",{});var jYe=s(gA);Rye=n(jYe,"STRONG",{});var Eca=s(Rye);QYr=r(Eca,"mpnet"),Eca.forEach(t),WYr=r(jYe," \u2014 "),cae=n(jYe,"A",{href:!0});var Cca=s(cae);UYr=r(Cca,"TFMPNetForSequenceClassification"),Cca.forEach(t),HYr=r(jYe," (MPNet model)"),jYe.forEach(t),JYr=i(ae),hA=n(ae,"LI",{});var DYe=s(hA);Pye=n(DYe,"STRONG",{});var wca=s(Pye);YYr=r(wca,"openai-gpt"),wca.forEach(t),ZYr=r(DYe," \u2014 "),mae=n(DYe,"A",{href:!0});var Aca=s(mae);KYr=r(Aca,"TFOpenAIGPTForSequenceClassification"),Aca.forEach(t),eZr=r(DYe," (OpenAI GPT model)"),DYe.forEach(t),oZr=i(ae),uA=n(ae,"LI",{});var GYe=s(uA);Bye=n(GYe,"STRONG",{});var Lca=s(Bye);rZr=r(Lca,"rembert"),Lca.forEach(t),tZr=r(GYe," \u2014 "),fae=n(GYe,"A",{href:!0});var yca=s(fae);aZr=r(yca,"TFRemBertForSequenceClassification"),yca.forEach(t),nZr=r(GYe," (RemBERT model)"),GYe.forEach(t),sZr=i(ae),pA=n(ae,"LI",{});var OYe=s(pA);Iye=n(OYe,"STRONG",{});var xca=s(Iye);lZr=r(xca,"roberta"),xca.forEach(t),iZr=r(OYe," \u2014 "),gae=n(OYe,"A",{href:!0});var $ca=s(gae);dZr=r($ca,"TFRobertaForSequenceClassification"),$ca.forEach(t),cZr=r(OYe," (RoBERTa model)"),OYe.forEach(t),mZr=i(ae),_A=n(ae,"LI",{});var VYe=s(_A);Nye=n(VYe,"STRONG",{});var kca=s(Nye);fZr=r(kca,"roformer"),kca.forEach(t),gZr=r(VYe," \u2014 "),hae=n(VYe,"A",{href:!0});var Sca=s(hae);hZr=r(Sca,"TFRoFormerForSequenceClassification"),Sca.forEach(t),uZr=r(VYe," (RoFormer model)"),VYe.forEach(t),pZr=i(ae),bA=n(ae,"LI",{});var XYe=s(bA);qye=n(XYe,"STRONG",{});var Rca=s(qye);_Zr=r(Rca,"tapas"),Rca.forEach(t),bZr=r(XYe," \u2014 "),uae=n(XYe,"A",{href:!0});var Pca=s(uae);vZr=r(Pca,"TFTapasForSequenceClassification"),Pca.forEach(t),FZr=r(XYe," (TAPAS model)"),XYe.forEach(t),TZr=i(ae),vA=n(ae,"LI",{});var zYe=s(vA);jye=n(zYe,"STRONG",{});var Bca=s(jye);MZr=r(Bca,"transfo-xl"),Bca.forEach(t),EZr=r(zYe," \u2014 "),pae=n(zYe,"A",{href:!0});var Ica=s(pae);CZr=r(Ica,"TFTransfoXLForSequenceClassification"),Ica.forEach(t),wZr=r(zYe," (Transformer-XL model)"),zYe.forEach(t),AZr=i(ae),FA=n(ae,"LI",{});var QYe=s(FA);Dye=n(QYe,"STRONG",{});var Nca=s(Dye);LZr=r(Nca,"xlm"),Nca.forEach(t),yZr=r(QYe," \u2014 "),_ae=n(QYe,"A",{href:!0});var qca=s(_ae);xZr=r(qca,"TFXLMForSequenceClassification"),qca.forEach(t),$Zr=r(QYe," (XLM model)"),QYe.forEach(t),kZr=i(ae),TA=n(ae,"LI",{});var WYe=s(TA);Gye=n(WYe,"STRONG",{});var jca=s(Gye);SZr=r(jca,"xlm-roberta"),jca.forEach(t),RZr=r(WYe," \u2014 "),bae=n(WYe,"A",{href:!0});var Dca=s(bae);PZr=r(Dca,"TFXLMRobertaForSequenceClassification"),Dca.forEach(t),BZr=r(WYe," (XLM-RoBERTa model)"),WYe.forEach(t),IZr=i(ae),MA=n(ae,"LI",{});var UYe=s(MA);Oye=n(UYe,"STRONG",{});var Gca=s(Oye);NZr=r(Gca,"xlnet"),Gca.forEach(t),qZr=r(UYe," \u2014 "),vae=n(UYe,"A",{href:!0});var Oca=s(vae);jZr=r(Oca,"TFXLNetForSequenceClassification"),Oca.forEach(t),DZr=r(UYe," (XLNet model)"),UYe.forEach(t),ae.forEach(t),GZr=i(Mi),T(EA.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),Nro=i(m),Em=n(m,"H2",{class:!0});var Kao=s(Em);CA=n(Kao,"A",{id:!0,class:!0,href:!0});var Vca=s(CA);Vye=n(Vca,"SPAN",{});var Xca=s(Vye);T(mR.$$.fragment,Xca),Xca.forEach(t),Vca.forEach(t),OZr=i(Kao),Xye=n(Kao,"SPAN",{});var zca=s(Xye);VZr=r(zca,"TFAutoModelForMultipleChoice"),zca.forEach(t),Kao.forEach(t),qro=i(m),pr=n(m,"DIV",{class:!0});var Ei=s(pr);T(fR.$$.fragment,Ei),XZr=i(Ei),Cm=n(Ei,"P",{});var nce=s(Cm);zZr=r(nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Fae=n(nce,"A",{href:!0});var Qca=s(Fae);QZr=r(Qca,"from_pretrained()"),Qca.forEach(t),WZr=r(nce," class method or the "),Tae=n(nce,"A",{href:!0});var Wca=s(Tae);UZr=r(Wca,"from_config()"),Wca.forEach(t),HZr=r(nce,` class
method.`),nce.forEach(t),JZr=i(Ei),gR=n(Ei,"P",{});var eno=s(gR);YZr=r(eno,"This class cannot be instantiated directly using "),zye=n(eno,"CODE",{});var Uca=s(zye);ZZr=r(Uca,"__init__()"),Uca.forEach(t),KZr=r(eno," (throws an error)."),eno.forEach(t),eKr=i(Ei),oa=n(Ei,"DIV",{class:!0});var I9=s(oa);T(hR.$$.fragment,I9),oKr=i(I9),Qye=n(I9,"P",{});var Hca=s(Qye);rKr=r(Hca,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Hca.forEach(t),tKr=i(I9),wm=n(I9,"P",{});var sce=s(wm);aKr=r(sce,`Note:
Loading a model from its configuration file does `),Wye=n(sce,"STRONG",{});var Jca=s(Wye);nKr=r(Jca,"not"),Jca.forEach(t),sKr=r(sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mae=n(sce,"A",{href:!0});var Yca=s(Mae);lKr=r(Yca,"from_pretrained()"),Yca.forEach(t),iKr=r(sce," to load the model weights."),sce.forEach(t),dKr=i(I9),T(wA.$$.fragment,I9),I9.forEach(t),cKr=i(Ei),Qr=n(Ei,"DIV",{class:!0});var Ci=s(Qr);T(uR.$$.fragment,Ci),mKr=i(Ci),Uye=n(Ci,"P",{});var Zca=s(Uye);fKr=r(Zca,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Zca.forEach(t),gKr=i(Ci),qn=n(Ci,"P",{});var N9=s(qn);hKr=r(N9,"The model class to instantiate is selected based on the "),Hye=n(N9,"CODE",{});var Kca=s(Hye);uKr=r(Kca,"model_type"),Kca.forEach(t),pKr=r(N9,` property of the config object (either
passed as an argument or loaded from `),Jye=n(N9,"CODE",{});var ema=s(Jye);_Kr=r(ema,"pretrained_model_name_or_path"),ema.forEach(t),bKr=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yye=n(N9,"CODE",{});var oma=s(Yye);vKr=r(oma,"pretrained_model_name_or_path"),oma.forEach(t),FKr=r(N9,":"),N9.forEach(t),TKr=i(Ci),ve=n(Ci,"UL",{});var Te=s(ve);AA=n(Te,"LI",{});var HYe=s(AA);Zye=n(HYe,"STRONG",{});var rma=s(Zye);MKr=r(rma,"albert"),rma.forEach(t),EKr=r(HYe," \u2014 "),Eae=n(HYe,"A",{href:!0});var tma=s(Eae);CKr=r(tma,"TFAlbertForMultipleChoice"),tma.forEach(t),wKr=r(HYe," (ALBERT model)"),HYe.forEach(t),AKr=i(Te),LA=n(Te,"LI",{});var JYe=s(LA);Kye=n(JYe,"STRONG",{});var ama=s(Kye);LKr=r(ama,"bert"),ama.forEach(t),yKr=r(JYe," \u2014 "),Cae=n(JYe,"A",{href:!0});var nma=s(Cae);xKr=r(nma,"TFBertForMultipleChoice"),nma.forEach(t),$Kr=r(JYe," (BERT model)"),JYe.forEach(t),kKr=i(Te),yA=n(Te,"LI",{});var YYe=s(yA);e8e=n(YYe,"STRONG",{});var sma=s(e8e);SKr=r(sma,"camembert"),sma.forEach(t),RKr=r(YYe," \u2014 "),wae=n(YYe,"A",{href:!0});var lma=s(wae);PKr=r(lma,"TFCamembertForMultipleChoice"),lma.forEach(t),BKr=r(YYe," (CamemBERT model)"),YYe.forEach(t),IKr=i(Te),xA=n(Te,"LI",{});var ZYe=s(xA);o8e=n(ZYe,"STRONG",{});var ima=s(o8e);NKr=r(ima,"convbert"),ima.forEach(t),qKr=r(ZYe," \u2014 "),Aae=n(ZYe,"A",{href:!0});var dma=s(Aae);jKr=r(dma,"TFConvBertForMultipleChoice"),dma.forEach(t),DKr=r(ZYe," (ConvBERT model)"),ZYe.forEach(t),GKr=i(Te),$A=n(Te,"LI",{});var KYe=s($A);r8e=n(KYe,"STRONG",{});var cma=s(r8e);OKr=r(cma,"distilbert"),cma.forEach(t),VKr=r(KYe," \u2014 "),Lae=n(KYe,"A",{href:!0});var mma=s(Lae);XKr=r(mma,"TFDistilBertForMultipleChoice"),mma.forEach(t),zKr=r(KYe," (DistilBERT model)"),KYe.forEach(t),QKr=i(Te),kA=n(Te,"LI",{});var eZe=s(kA);t8e=n(eZe,"STRONG",{});var fma=s(t8e);WKr=r(fma,"electra"),fma.forEach(t),UKr=r(eZe," \u2014 "),yae=n(eZe,"A",{href:!0});var gma=s(yae);HKr=r(gma,"TFElectraForMultipleChoice"),gma.forEach(t),JKr=r(eZe," (ELECTRA model)"),eZe.forEach(t),YKr=i(Te),SA=n(Te,"LI",{});var oZe=s(SA);a8e=n(oZe,"STRONG",{});var hma=s(a8e);ZKr=r(hma,"flaubert"),hma.forEach(t),KKr=r(oZe," \u2014 "),xae=n(oZe,"A",{href:!0});var uma=s(xae);eet=r(uma,"TFFlaubertForMultipleChoice"),uma.forEach(t),oet=r(oZe," (FlauBERT model)"),oZe.forEach(t),ret=i(Te),RA=n(Te,"LI",{});var rZe=s(RA);n8e=n(rZe,"STRONG",{});var pma=s(n8e);tet=r(pma,"funnel"),pma.forEach(t),aet=r(rZe," \u2014 "),$ae=n(rZe,"A",{href:!0});var _ma=s($ae);net=r(_ma,"TFFunnelForMultipleChoice"),_ma.forEach(t),set=r(rZe," (Funnel Transformer model)"),rZe.forEach(t),iet=i(Te),PA=n(Te,"LI",{});var tZe=s(PA);s8e=n(tZe,"STRONG",{});var bma=s(s8e);det=r(bma,"longformer"),bma.forEach(t),cet=r(tZe," \u2014 "),kae=n(tZe,"A",{href:!0});var vma=s(kae);met=r(vma,"TFLongformerForMultipleChoice"),vma.forEach(t),fet=r(tZe," (Longformer model)"),tZe.forEach(t),get=i(Te),BA=n(Te,"LI",{});var aZe=s(BA);l8e=n(aZe,"STRONG",{});var Fma=s(l8e);het=r(Fma,"mobilebert"),Fma.forEach(t),uet=r(aZe," \u2014 "),Sae=n(aZe,"A",{href:!0});var Tma=s(Sae);pet=r(Tma,"TFMobileBertForMultipleChoice"),Tma.forEach(t),_et=r(aZe," (MobileBERT model)"),aZe.forEach(t),bet=i(Te),IA=n(Te,"LI",{});var nZe=s(IA);i8e=n(nZe,"STRONG",{});var Mma=s(i8e);vet=r(Mma,"mpnet"),Mma.forEach(t),Fet=r(nZe," \u2014 "),Rae=n(nZe,"A",{href:!0});var Ema=s(Rae);Tet=r(Ema,"TFMPNetForMultipleChoice"),Ema.forEach(t),Met=r(nZe," (MPNet model)"),nZe.forEach(t),Eet=i(Te),NA=n(Te,"LI",{});var sZe=s(NA);d8e=n(sZe,"STRONG",{});var Cma=s(d8e);Cet=r(Cma,"rembert"),Cma.forEach(t),wet=r(sZe," \u2014 "),Pae=n(sZe,"A",{href:!0});var wma=s(Pae);Aet=r(wma,"TFRemBertForMultipleChoice"),wma.forEach(t),Let=r(sZe," (RemBERT model)"),sZe.forEach(t),yet=i(Te),qA=n(Te,"LI",{});var lZe=s(qA);c8e=n(lZe,"STRONG",{});var Ama=s(c8e);xet=r(Ama,"roberta"),Ama.forEach(t),$et=r(lZe," \u2014 "),Bae=n(lZe,"A",{href:!0});var Lma=s(Bae);ket=r(Lma,"TFRobertaForMultipleChoice"),Lma.forEach(t),Set=r(lZe," (RoBERTa model)"),lZe.forEach(t),Ret=i(Te),jA=n(Te,"LI",{});var iZe=s(jA);m8e=n(iZe,"STRONG",{});var yma=s(m8e);Pet=r(yma,"roformer"),yma.forEach(t),Bet=r(iZe," \u2014 "),Iae=n(iZe,"A",{href:!0});var xma=s(Iae);Iet=r(xma,"TFRoFormerForMultipleChoice"),xma.forEach(t),Net=r(iZe," (RoFormer model)"),iZe.forEach(t),qet=i(Te),DA=n(Te,"LI",{});var dZe=s(DA);f8e=n(dZe,"STRONG",{});var $ma=s(f8e);jet=r($ma,"xlm"),$ma.forEach(t),Det=r(dZe," \u2014 "),Nae=n(dZe,"A",{href:!0});var kma=s(Nae);Get=r(kma,"TFXLMForMultipleChoice"),kma.forEach(t),Oet=r(dZe," (XLM model)"),dZe.forEach(t),Vet=i(Te),GA=n(Te,"LI",{});var cZe=s(GA);g8e=n(cZe,"STRONG",{});var Sma=s(g8e);Xet=r(Sma,"xlm-roberta"),Sma.forEach(t),zet=r(cZe," \u2014 "),qae=n(cZe,"A",{href:!0});var Rma=s(qae);Qet=r(Rma,"TFXLMRobertaForMultipleChoice"),Rma.forEach(t),Wet=r(cZe," (XLM-RoBERTa model)"),cZe.forEach(t),Uet=i(Te),OA=n(Te,"LI",{});var mZe=s(OA);h8e=n(mZe,"STRONG",{});var Pma=s(h8e);Het=r(Pma,"xlnet"),Pma.forEach(t),Jet=r(mZe," \u2014 "),jae=n(mZe,"A",{href:!0});var Bma=s(jae);Yet=r(Bma,"TFXLNetForMultipleChoice"),Bma.forEach(t),Zet=r(mZe," (XLNet model)"),mZe.forEach(t),Te.forEach(t),Ket=i(Ci),T(VA.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),jro=i(m),Am=n(m,"H2",{class:!0});var ono=s(Am);XA=n(ono,"A",{id:!0,class:!0,href:!0});var Ima=s(XA);u8e=n(Ima,"SPAN",{});var Nma=s(u8e);T(pR.$$.fragment,Nma),Nma.forEach(t),Ima.forEach(t),eot=i(ono),p8e=n(ono,"SPAN",{});var qma=s(p8e);oot=r(qma,"TFAutoModelForNextSentencePrediction"),qma.forEach(t),ono.forEach(t),Dro=i(m),_r=n(m,"DIV",{class:!0});var wi=s(_r);T(_R.$$.fragment,wi),rot=i(wi),Lm=n(wi,"P",{});var lce=s(Lm);tot=r(lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Dae=n(lce,"A",{href:!0});var jma=s(Dae);aot=r(jma,"from_pretrained()"),jma.forEach(t),not=r(lce," class method or the "),Gae=n(lce,"A",{href:!0});var Dma=s(Gae);sot=r(Dma,"from_config()"),Dma.forEach(t),lot=r(lce,` class
method.`),lce.forEach(t),iot=i(wi),bR=n(wi,"P",{});var rno=s(bR);dot=r(rno,"This class cannot be instantiated directly using "),_8e=n(rno,"CODE",{});var Gma=s(_8e);cot=r(Gma,"__init__()"),Gma.forEach(t),mot=r(rno," (throws an error)."),rno.forEach(t),fot=i(wi),ra=n(wi,"DIV",{class:!0});var q9=s(ra);T(vR.$$.fragment,q9),got=i(q9),b8e=n(q9,"P",{});var Oma=s(b8e);hot=r(Oma,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Oma.forEach(t),uot=i(q9),ym=n(q9,"P",{});var ice=s(ym);pot=r(ice,`Note:
Loading a model from its configuration file does `),v8e=n(ice,"STRONG",{});var Vma=s(v8e);_ot=r(Vma,"not"),Vma.forEach(t),bot=r(ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),Oae=n(ice,"A",{href:!0});var Xma=s(Oae);vot=r(Xma,"from_pretrained()"),Xma.forEach(t),Fot=r(ice," to load the model weights."),ice.forEach(t),Tot=i(q9),T(zA.$$.fragment,q9),q9.forEach(t),Mot=i(wi),Wr=n(wi,"DIV",{class:!0});var Ai=s(Wr);T(FR.$$.fragment,Ai),Eot=i(Ai),F8e=n(Ai,"P",{});var zma=s(F8e);Cot=r(zma,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),zma.forEach(t),wot=i(Ai),jn=n(Ai,"P",{});var j9=s(jn);Aot=r(j9,"The model class to instantiate is selected based on the "),T8e=n(j9,"CODE",{});var Qma=s(T8e);Lot=r(Qma,"model_type"),Qma.forEach(t),yot=r(j9,` property of the config object (either
passed as an argument or loaded from `),M8e=n(j9,"CODE",{});var Wma=s(M8e);xot=r(Wma,"pretrained_model_name_or_path"),Wma.forEach(t),$ot=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E8e=n(j9,"CODE",{});var Uma=s(E8e);kot=r(Uma,"pretrained_model_name_or_path"),Uma.forEach(t),Sot=r(j9,":"),j9.forEach(t),Rot=i(Ai),TR=n(Ai,"UL",{});var tno=s(TR);QA=n(tno,"LI",{});var fZe=s(QA);C8e=n(fZe,"STRONG",{});var Hma=s(C8e);Pot=r(Hma,"bert"),Hma.forEach(t),Bot=r(fZe," \u2014 "),Vae=n(fZe,"A",{href:!0});var Jma=s(Vae);Iot=r(Jma,"TFBertForNextSentencePrediction"),Jma.forEach(t),Not=r(fZe," (BERT model)"),fZe.forEach(t),qot=i(tno),WA=n(tno,"LI",{});var gZe=s(WA);w8e=n(gZe,"STRONG",{});var Yma=s(w8e);jot=r(Yma,"mobilebert"),Yma.forEach(t),Dot=r(gZe," \u2014 "),Xae=n(gZe,"A",{href:!0});var Zma=s(Xae);Got=r(Zma,"TFMobileBertForNextSentencePrediction"),Zma.forEach(t),Oot=r(gZe," (MobileBERT model)"),gZe.forEach(t),tno.forEach(t),Vot=i(Ai),T(UA.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),Gro=i(m),xm=n(m,"H2",{class:!0});var ano=s(xm);HA=n(ano,"A",{id:!0,class:!0,href:!0});var Kma=s(HA);A8e=n(Kma,"SPAN",{});var efa=s(A8e);T(MR.$$.fragment,efa),efa.forEach(t),Kma.forEach(t),Xot=i(ano),L8e=n(ano,"SPAN",{});var ofa=s(L8e);zot=r(ofa,"TFAutoModelForTableQuestionAnswering"),ofa.forEach(t),ano.forEach(t),Oro=i(m),br=n(m,"DIV",{class:!0});var Li=s(br);T(ER.$$.fragment,Li),Qot=i(Li),$m=n(Li,"P",{});var dce=s($m);Wot=r(dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zae=n(dce,"A",{href:!0});var rfa=s(zae);Uot=r(rfa,"from_pretrained()"),rfa.forEach(t),Hot=r(dce," class method or the "),Qae=n(dce,"A",{href:!0});var tfa=s(Qae);Jot=r(tfa,"from_config()"),tfa.forEach(t),Yot=r(dce,` class
method.`),dce.forEach(t),Zot=i(Li),CR=n(Li,"P",{});var nno=s(CR);Kot=r(nno,"This class cannot be instantiated directly using "),y8e=n(nno,"CODE",{});var afa=s(y8e);ert=r(afa,"__init__()"),afa.forEach(t),ort=r(nno," (throws an error)."),nno.forEach(t),rrt=i(Li),ta=n(Li,"DIV",{class:!0});var D9=s(ta);T(wR.$$.fragment,D9),trt=i(D9),x8e=n(D9,"P",{});var nfa=s(x8e);art=r(nfa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),nfa.forEach(t),nrt=i(D9),km=n(D9,"P",{});var cce=s(km);srt=r(cce,`Note:
Loading a model from its configuration file does `),$8e=n(cce,"STRONG",{});var sfa=s($8e);lrt=r(sfa,"not"),sfa.forEach(t),irt=r(cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wae=n(cce,"A",{href:!0});var lfa=s(Wae);drt=r(lfa,"from_pretrained()"),lfa.forEach(t),crt=r(cce," to load the model weights."),cce.forEach(t),mrt=i(D9),T(JA.$$.fragment,D9),D9.forEach(t),frt=i(Li),Ur=n(Li,"DIV",{class:!0});var yi=s(Ur);T(AR.$$.fragment,yi),grt=i(yi),k8e=n(yi,"P",{});var ifa=s(k8e);hrt=r(ifa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),ifa.forEach(t),urt=i(yi),Dn=n(yi,"P",{});var G9=s(Dn);prt=r(G9,"The model class to instantiate is selected based on the "),S8e=n(G9,"CODE",{});var dfa=s(S8e);_rt=r(dfa,"model_type"),dfa.forEach(t),brt=r(G9,` property of the config object (either
passed as an argument or loaded from `),R8e=n(G9,"CODE",{});var cfa=s(R8e);vrt=r(cfa,"pretrained_model_name_or_path"),cfa.forEach(t),Frt=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P8e=n(G9,"CODE",{});var mfa=s(P8e);Trt=r(mfa,"pretrained_model_name_or_path"),mfa.forEach(t),Mrt=r(G9,":"),G9.forEach(t),Ert=i(yi),B8e=n(yi,"UL",{});var ffa=s(B8e);YA=n(ffa,"LI",{});var hZe=s(YA);I8e=n(hZe,"STRONG",{});var gfa=s(I8e);Crt=r(gfa,"tapas"),gfa.forEach(t),wrt=r(hZe," \u2014 "),Uae=n(hZe,"A",{href:!0});var hfa=s(Uae);Art=r(hfa,"TFTapasForQuestionAnswering"),hfa.forEach(t),Lrt=r(hZe," (TAPAS model)"),hZe.forEach(t),ffa.forEach(t),yrt=i(yi),T(ZA.$$.fragment,yi),yi.forEach(t),Li.forEach(t),Vro=i(m),Sm=n(m,"H2",{class:!0});var sno=s(Sm);KA=n(sno,"A",{id:!0,class:!0,href:!0});var ufa=s(KA);N8e=n(ufa,"SPAN",{});var pfa=s(N8e);T(LR.$$.fragment,pfa),pfa.forEach(t),ufa.forEach(t),xrt=i(sno),q8e=n(sno,"SPAN",{});var _fa=s(q8e);$rt=r(_fa,"TFAutoModelForDocumentQuestionAnswering"),_fa.forEach(t),sno.forEach(t),Xro=i(m),vr=n(m,"DIV",{class:!0});var xi=s(vr);T(yR.$$.fragment,xi),krt=i(xi),Rm=n(xi,"P",{});var mce=s(Rm);Srt=r(mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Hae=n(mce,"A",{href:!0});var bfa=s(Hae);Rrt=r(bfa,"from_pretrained()"),bfa.forEach(t),Prt=r(mce," class method or the "),Jae=n(mce,"A",{href:!0});var vfa=s(Jae);Brt=r(vfa,"from_config()"),vfa.forEach(t),Irt=r(mce,` class
method.`),mce.forEach(t),Nrt=i(xi),xR=n(xi,"P",{});var lno=s(xR);qrt=r(lno,"This class cannot be instantiated directly using "),j8e=n(lno,"CODE",{});var Ffa=s(j8e);jrt=r(Ffa,"__init__()"),Ffa.forEach(t),Drt=r(lno," (throws an error)."),lno.forEach(t),Grt=i(xi),aa=n(xi,"DIV",{class:!0});var O9=s(aa);T($R.$$.fragment,O9),Ort=i(O9),D8e=n(O9,"P",{});var Tfa=s(D8e);Vrt=r(Tfa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Tfa.forEach(t),Xrt=i(O9),Pm=n(O9,"P",{});var fce=s(Pm);zrt=r(fce,`Note:
Loading a model from its configuration file does `),G8e=n(fce,"STRONG",{});var Mfa=s(G8e);Qrt=r(Mfa,"not"),Mfa.forEach(t),Wrt=r(fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yae=n(fce,"A",{href:!0});var Efa=s(Yae);Urt=r(Efa,"from_pretrained()"),Efa.forEach(t),Hrt=r(fce," to load the model weights."),fce.forEach(t),Jrt=i(O9),T(e6.$$.fragment,O9),O9.forEach(t),Yrt=i(xi),Hr=n(xi,"DIV",{class:!0});var $i=s(Hr);T(kR.$$.fragment,$i),Zrt=i($i),O8e=n($i,"P",{});var Cfa=s(O8e);Krt=r(Cfa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Cfa.forEach(t),ett=i($i),Gn=n($i,"P",{});var V9=s(Gn);ott=r(V9,"The model class to instantiate is selected based on the "),V8e=n(V9,"CODE",{});var wfa=s(V8e);rtt=r(wfa,"model_type"),wfa.forEach(t),ttt=r(V9,` property of the config object (either
passed as an argument or loaded from `),X8e=n(V9,"CODE",{});var Afa=s(X8e);att=r(Afa,"pretrained_model_name_or_path"),Afa.forEach(t),ntt=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z8e=n(V9,"CODE",{});var Lfa=s(z8e);stt=r(Lfa,"pretrained_model_name_or_path"),Lfa.forEach(t),ltt=r(V9,":"),V9.forEach(t),itt=i($i),Q8e=n($i,"UL",{});var yfa=s(Q8e);o6=n(yfa,"LI",{});var uZe=s(o6);W8e=n(uZe,"STRONG",{});var xfa=s(W8e);dtt=r(xfa,"layoutlm"),xfa.forEach(t),ctt=r(uZe," \u2014 "),Zae=n(uZe,"A",{href:!0});var $fa=s(Zae);mtt=r($fa,"TFLayoutLMForQuestionAnswering"),$fa.forEach(t),ftt=r(uZe," (LayoutLM model)"),uZe.forEach(t),yfa.forEach(t),gtt=i($i),T(r6.$$.fragment,$i),$i.forEach(t),xi.forEach(t),zro=i(m),Bm=n(m,"H2",{class:!0});var ino=s(Bm);t6=n(ino,"A",{id:!0,class:!0,href:!0});var kfa=s(t6);U8e=n(kfa,"SPAN",{});var Sfa=s(U8e);T(SR.$$.fragment,Sfa),Sfa.forEach(t),kfa.forEach(t),htt=i(ino),H8e=n(ino,"SPAN",{});var Rfa=s(H8e);utt=r(Rfa,"TFAutoModelForTokenClassification"),Rfa.forEach(t),ino.forEach(t),Qro=i(m),Fr=n(m,"DIV",{class:!0});var ki=s(Fr);T(RR.$$.fragment,ki),ptt=i(ki),Im=n(ki,"P",{});var gce=s(Im);_tt=r(gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Kae=n(gce,"A",{href:!0});var Pfa=s(Kae);btt=r(Pfa,"from_pretrained()"),Pfa.forEach(t),vtt=r(gce," class method or the "),ene=n(gce,"A",{href:!0});var Bfa=s(ene);Ftt=r(Bfa,"from_config()"),Bfa.forEach(t),Ttt=r(gce,` class
method.`),gce.forEach(t),Mtt=i(ki),PR=n(ki,"P",{});var dno=s(PR);Ett=r(dno,"This class cannot be instantiated directly using "),J8e=n(dno,"CODE",{});var Ifa=s(J8e);Ctt=r(Ifa,"__init__()"),Ifa.forEach(t),wtt=r(dno," (throws an error)."),dno.forEach(t),Att=i(ki),na=n(ki,"DIV",{class:!0});var X9=s(na);T(BR.$$.fragment,X9),Ltt=i(X9),Y8e=n(X9,"P",{});var Nfa=s(Y8e);ytt=r(Nfa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Nfa.forEach(t),xtt=i(X9),Nm=n(X9,"P",{});var hce=s(Nm);$tt=r(hce,`Note:
Loading a model from its configuration file does `),Z8e=n(hce,"STRONG",{});var qfa=s(Z8e);ktt=r(qfa,"not"),qfa.forEach(t),Stt=r(hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),one=n(hce,"A",{href:!0});var jfa=s(one);Rtt=r(jfa,"from_pretrained()"),jfa.forEach(t),Ptt=r(hce," to load the model weights."),hce.forEach(t),Btt=i(X9),T(a6.$$.fragment,X9),X9.forEach(t),Itt=i(ki),Jr=n(ki,"DIV",{class:!0});var Si=s(Jr);T(IR.$$.fragment,Si),Ntt=i(Si),K8e=n(Si,"P",{});var Dfa=s(K8e);qtt=r(Dfa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Dfa.forEach(t),jtt=i(Si),On=n(Si,"P",{});var z9=s(On);Dtt=r(z9,"The model class to instantiate is selected based on the "),e9e=n(z9,"CODE",{});var Gfa=s(e9e);Gtt=r(Gfa,"model_type"),Gfa.forEach(t),Ott=r(z9,` property of the config object (either
passed as an argument or loaded from `),o9e=n(z9,"CODE",{});var Ofa=s(o9e);Vtt=r(Ofa,"pretrained_model_name_or_path"),Ofa.forEach(t),Xtt=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r9e=n(z9,"CODE",{});var Vfa=s(r9e);ztt=r(Vfa,"pretrained_model_name_or_path"),Vfa.forEach(t),Qtt=r(z9,":"),z9.forEach(t),Wtt=i(Si),ce=n(Si,"UL",{});var he=s(ce);n6=n(he,"LI",{});var pZe=s(n6);t9e=n(pZe,"STRONG",{});var Xfa=s(t9e);Utt=r(Xfa,"albert"),Xfa.forEach(t),Htt=r(pZe," \u2014 "),rne=n(pZe,"A",{href:!0});var zfa=s(rne);Jtt=r(zfa,"TFAlbertForTokenClassification"),zfa.forEach(t),Ytt=r(pZe," (ALBERT model)"),pZe.forEach(t),Ztt=i(he),s6=n(he,"LI",{});var _Ze=s(s6);a9e=n(_Ze,"STRONG",{});var Qfa=s(a9e);Ktt=r(Qfa,"bert"),Qfa.forEach(t),eat=r(_Ze," \u2014 "),tne=n(_Ze,"A",{href:!0});var Wfa=s(tne);oat=r(Wfa,"TFBertForTokenClassification"),Wfa.forEach(t),rat=r(_Ze," (BERT model)"),_Ze.forEach(t),tat=i(he),l6=n(he,"LI",{});var bZe=s(l6);n9e=n(bZe,"STRONG",{});var Ufa=s(n9e);aat=r(Ufa,"camembert"),Ufa.forEach(t),nat=r(bZe," \u2014 "),ane=n(bZe,"A",{href:!0});var Hfa=s(ane);sat=r(Hfa,"TFCamembertForTokenClassification"),Hfa.forEach(t),lat=r(bZe," (CamemBERT model)"),bZe.forEach(t),iat=i(he),i6=n(he,"LI",{});var vZe=s(i6);s9e=n(vZe,"STRONG",{});var Jfa=s(s9e);dat=r(Jfa,"convbert"),Jfa.forEach(t),cat=r(vZe," \u2014 "),nne=n(vZe,"A",{href:!0});var Yfa=s(nne);mat=r(Yfa,"TFConvBertForTokenClassification"),Yfa.forEach(t),fat=r(vZe," (ConvBERT model)"),vZe.forEach(t),gat=i(he),d6=n(he,"LI",{});var FZe=s(d6);l9e=n(FZe,"STRONG",{});var Zfa=s(l9e);hat=r(Zfa,"deberta"),Zfa.forEach(t),uat=r(FZe," \u2014 "),sne=n(FZe,"A",{href:!0});var Kfa=s(sne);pat=r(Kfa,"TFDebertaForTokenClassification"),Kfa.forEach(t),_at=r(FZe," (DeBERTa model)"),FZe.forEach(t),bat=i(he),c6=n(he,"LI",{});var TZe=s(c6);i9e=n(TZe,"STRONG",{});var ega=s(i9e);vat=r(ega,"deberta-v2"),ega.forEach(t),Fat=r(TZe," \u2014 "),lne=n(TZe,"A",{href:!0});var oga=s(lne);Tat=r(oga,"TFDebertaV2ForTokenClassification"),oga.forEach(t),Mat=r(TZe," (DeBERTa-v2 model)"),TZe.forEach(t),Eat=i(he),m6=n(he,"LI",{});var MZe=s(m6);d9e=n(MZe,"STRONG",{});var rga=s(d9e);Cat=r(rga,"distilbert"),rga.forEach(t),wat=r(MZe," \u2014 "),ine=n(MZe,"A",{href:!0});var tga=s(ine);Aat=r(tga,"TFDistilBertForTokenClassification"),tga.forEach(t),Lat=r(MZe," (DistilBERT model)"),MZe.forEach(t),yat=i(he),f6=n(he,"LI",{});var EZe=s(f6);c9e=n(EZe,"STRONG",{});var aga=s(c9e);xat=r(aga,"electra"),aga.forEach(t),$at=r(EZe," \u2014 "),dne=n(EZe,"A",{href:!0});var nga=s(dne);kat=r(nga,"TFElectraForTokenClassification"),nga.forEach(t),Sat=r(EZe," (ELECTRA model)"),EZe.forEach(t),Rat=i(he),g6=n(he,"LI",{});var CZe=s(g6);m9e=n(CZe,"STRONG",{});var sga=s(m9e);Pat=r(sga,"flaubert"),sga.forEach(t),Bat=r(CZe," \u2014 "),cne=n(CZe,"A",{href:!0});var lga=s(cne);Iat=r(lga,"TFFlaubertForTokenClassification"),lga.forEach(t),Nat=r(CZe," (FlauBERT model)"),CZe.forEach(t),qat=i(he),h6=n(he,"LI",{});var wZe=s(h6);f9e=n(wZe,"STRONG",{});var iga=s(f9e);jat=r(iga,"funnel"),iga.forEach(t),Dat=r(wZe," \u2014 "),mne=n(wZe,"A",{href:!0});var dga=s(mne);Gat=r(dga,"TFFunnelForTokenClassification"),dga.forEach(t),Oat=r(wZe," (Funnel Transformer model)"),wZe.forEach(t),Vat=i(he),u6=n(he,"LI",{});var AZe=s(u6);g9e=n(AZe,"STRONG",{});var cga=s(g9e);Xat=r(cga,"layoutlm"),cga.forEach(t),zat=r(AZe," \u2014 "),fne=n(AZe,"A",{href:!0});var mga=s(fne);Qat=r(mga,"TFLayoutLMForTokenClassification"),mga.forEach(t),Wat=r(AZe," (LayoutLM model)"),AZe.forEach(t),Uat=i(he),p6=n(he,"LI",{});var LZe=s(p6);h9e=n(LZe,"STRONG",{});var fga=s(h9e);Hat=r(fga,"layoutlmv3"),fga.forEach(t),Jat=r(LZe," \u2014 "),gne=n(LZe,"A",{href:!0});var gga=s(gne);Yat=r(gga,"TFLayoutLMv3ForTokenClassification"),gga.forEach(t),Zat=r(LZe," (LayoutLMv3 model)"),LZe.forEach(t),Kat=i(he),_6=n(he,"LI",{});var yZe=s(_6);u9e=n(yZe,"STRONG",{});var hga=s(u9e);ent=r(hga,"longformer"),hga.forEach(t),ont=r(yZe," \u2014 "),hne=n(yZe,"A",{href:!0});var uga=s(hne);rnt=r(uga,"TFLongformerForTokenClassification"),uga.forEach(t),tnt=r(yZe," (Longformer model)"),yZe.forEach(t),ant=i(he),b6=n(he,"LI",{});var xZe=s(b6);p9e=n(xZe,"STRONG",{});var pga=s(p9e);nnt=r(pga,"mobilebert"),pga.forEach(t),snt=r(xZe," \u2014 "),une=n(xZe,"A",{href:!0});var _ga=s(une);lnt=r(_ga,"TFMobileBertForTokenClassification"),_ga.forEach(t),int=r(xZe," (MobileBERT model)"),xZe.forEach(t),dnt=i(he),v6=n(he,"LI",{});var $Ze=s(v6);_9e=n($Ze,"STRONG",{});var bga=s(_9e);cnt=r(bga,"mpnet"),bga.forEach(t),mnt=r($Ze," \u2014 "),pne=n($Ze,"A",{href:!0});var vga=s(pne);fnt=r(vga,"TFMPNetForTokenClassification"),vga.forEach(t),gnt=r($Ze," (MPNet model)"),$Ze.forEach(t),hnt=i(he),F6=n(he,"LI",{});var kZe=s(F6);b9e=n(kZe,"STRONG",{});var Fga=s(b9e);unt=r(Fga,"rembert"),Fga.forEach(t),pnt=r(kZe," \u2014 "),_ne=n(kZe,"A",{href:!0});var Tga=s(_ne);_nt=r(Tga,"TFRemBertForTokenClassification"),Tga.forEach(t),bnt=r(kZe," (RemBERT model)"),kZe.forEach(t),vnt=i(he),T6=n(he,"LI",{});var SZe=s(T6);v9e=n(SZe,"STRONG",{});var Mga=s(v9e);Fnt=r(Mga,"roberta"),Mga.forEach(t),Tnt=r(SZe," \u2014 "),bne=n(SZe,"A",{href:!0});var Ega=s(bne);Mnt=r(Ega,"TFRobertaForTokenClassification"),Ega.forEach(t),Ent=r(SZe," (RoBERTa model)"),SZe.forEach(t),Cnt=i(he),M6=n(he,"LI",{});var RZe=s(M6);F9e=n(RZe,"STRONG",{});var Cga=s(F9e);wnt=r(Cga,"roformer"),Cga.forEach(t),Ant=r(RZe," \u2014 "),vne=n(RZe,"A",{href:!0});var wga=s(vne);Lnt=r(wga,"TFRoFormerForTokenClassification"),wga.forEach(t),ynt=r(RZe," (RoFormer model)"),RZe.forEach(t),xnt=i(he),E6=n(he,"LI",{});var PZe=s(E6);T9e=n(PZe,"STRONG",{});var Aga=s(T9e);$nt=r(Aga,"xlm"),Aga.forEach(t),knt=r(PZe," \u2014 "),Fne=n(PZe,"A",{href:!0});var Lga=s(Fne);Snt=r(Lga,"TFXLMForTokenClassification"),Lga.forEach(t),Rnt=r(PZe," (XLM model)"),PZe.forEach(t),Pnt=i(he),C6=n(he,"LI",{});var BZe=s(C6);M9e=n(BZe,"STRONG",{});var yga=s(M9e);Bnt=r(yga,"xlm-roberta"),yga.forEach(t),Int=r(BZe," \u2014 "),Tne=n(BZe,"A",{href:!0});var xga=s(Tne);Nnt=r(xga,"TFXLMRobertaForTokenClassification"),xga.forEach(t),qnt=r(BZe," (XLM-RoBERTa model)"),BZe.forEach(t),jnt=i(he),w6=n(he,"LI",{});var IZe=s(w6);E9e=n(IZe,"STRONG",{});var $ga=s(E9e);Dnt=r($ga,"xlnet"),$ga.forEach(t),Gnt=r(IZe," \u2014 "),Mne=n(IZe,"A",{href:!0});var kga=s(Mne);Ont=r(kga,"TFXLNetForTokenClassification"),kga.forEach(t),Vnt=r(IZe," (XLNet model)"),IZe.forEach(t),he.forEach(t),Xnt=i(Si),T(A6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),Wro=i(m),qm=n(m,"H2",{class:!0});var cno=s(qm);L6=n(cno,"A",{id:!0,class:!0,href:!0});var Sga=s(L6);C9e=n(Sga,"SPAN",{});var Rga=s(C9e);T(NR.$$.fragment,Rga),Rga.forEach(t),Sga.forEach(t),znt=i(cno),w9e=n(cno,"SPAN",{});var Pga=s(w9e);Qnt=r(Pga,"TFAutoModelForQuestionAnswering"),Pga.forEach(t),cno.forEach(t),Uro=i(m),Tr=n(m,"DIV",{class:!0});var Ri=s(Tr);T(qR.$$.fragment,Ri),Wnt=i(Ri),jm=n(Ri,"P",{});var uce=s(jm);Unt=r(uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Ene=n(uce,"A",{href:!0});var Bga=s(Ene);Hnt=r(Bga,"from_pretrained()"),Bga.forEach(t),Jnt=r(uce," class method or the "),Cne=n(uce,"A",{href:!0});var Iga=s(Cne);Ynt=r(Iga,"from_config()"),Iga.forEach(t),Znt=r(uce,` class
method.`),uce.forEach(t),Knt=i(Ri),jR=n(Ri,"P",{});var mno=s(jR);est=r(mno,"This class cannot be instantiated directly using "),A9e=n(mno,"CODE",{});var Nga=s(A9e);ost=r(Nga,"__init__()"),Nga.forEach(t),rst=r(mno," (throws an error)."),mno.forEach(t),tst=i(Ri),sa=n(Ri,"DIV",{class:!0});var Q9=s(sa);T(DR.$$.fragment,Q9),ast=i(Q9),L9e=n(Q9,"P",{});var qga=s(L9e);nst=r(qga,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),qga.forEach(t),sst=i(Q9),Dm=n(Q9,"P",{});var pce=s(Dm);lst=r(pce,`Note:
Loading a model from its configuration file does `),y9e=n(pce,"STRONG",{});var jga=s(y9e);ist=r(jga,"not"),jga.forEach(t),dst=r(pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),wne=n(pce,"A",{href:!0});var Dga=s(wne);cst=r(Dga,"from_pretrained()"),Dga.forEach(t),mst=r(pce," to load the model weights."),pce.forEach(t),fst=i(Q9),T(y6.$$.fragment,Q9),Q9.forEach(t),gst=i(Ri),Yr=n(Ri,"DIV",{class:!0});var Pi=s(Yr);T(GR.$$.fragment,Pi),hst=i(Pi),x9e=n(Pi,"P",{});var Gga=s(x9e);ust=r(Gga,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Gga.forEach(t),pst=i(Pi),Vn=n(Pi,"P",{});var W9=s(Vn);_st=r(W9,"The model class to instantiate is selected based on the "),$9e=n(W9,"CODE",{});var Oga=s($9e);bst=r(Oga,"model_type"),Oga.forEach(t),vst=r(W9,` property of the config object (either
passed as an argument or loaded from `),k9e=n(W9,"CODE",{});var Vga=s(k9e);Fst=r(Vga,"pretrained_model_name_or_path"),Vga.forEach(t),Tst=r(W9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S9e=n(W9,"CODE",{});var Xga=s(S9e);Mst=r(Xga,"pretrained_model_name_or_path"),Xga.forEach(t),Est=r(W9,":"),W9.forEach(t),Cst=i(Pi),me=n(Pi,"UL",{});var ue=s(me);x6=n(ue,"LI",{});var NZe=s(x6);R9e=n(NZe,"STRONG",{});var zga=s(R9e);wst=r(zga,"albert"),zga.forEach(t),Ast=r(NZe," \u2014 "),Ane=n(NZe,"A",{href:!0});var Qga=s(Ane);Lst=r(Qga,"TFAlbertForQuestionAnswering"),Qga.forEach(t),yst=r(NZe," (ALBERT model)"),NZe.forEach(t),xst=i(ue),$6=n(ue,"LI",{});var qZe=s($6);P9e=n(qZe,"STRONG",{});var Wga=s(P9e);$st=r(Wga,"bert"),Wga.forEach(t),kst=r(qZe," \u2014 "),Lne=n(qZe,"A",{href:!0});var Uga=s(Lne);Sst=r(Uga,"TFBertForQuestionAnswering"),Uga.forEach(t),Rst=r(qZe," (BERT model)"),qZe.forEach(t),Pst=i(ue),k6=n(ue,"LI",{});var jZe=s(k6);B9e=n(jZe,"STRONG",{});var Hga=s(B9e);Bst=r(Hga,"camembert"),Hga.forEach(t),Ist=r(jZe," \u2014 "),yne=n(jZe,"A",{href:!0});var Jga=s(yne);Nst=r(Jga,"TFCamembertForQuestionAnswering"),Jga.forEach(t),qst=r(jZe," (CamemBERT model)"),jZe.forEach(t),jst=i(ue),S6=n(ue,"LI",{});var DZe=s(S6);I9e=n(DZe,"STRONG",{});var Yga=s(I9e);Dst=r(Yga,"convbert"),Yga.forEach(t),Gst=r(DZe," \u2014 "),xne=n(DZe,"A",{href:!0});var Zga=s(xne);Ost=r(Zga,"TFConvBertForQuestionAnswering"),Zga.forEach(t),Vst=r(DZe," (ConvBERT model)"),DZe.forEach(t),Xst=i(ue),R6=n(ue,"LI",{});var GZe=s(R6);N9e=n(GZe,"STRONG",{});var Kga=s(N9e);zst=r(Kga,"deberta"),Kga.forEach(t),Qst=r(GZe," \u2014 "),$ne=n(GZe,"A",{href:!0});var eha=s($ne);Wst=r(eha,"TFDebertaForQuestionAnswering"),eha.forEach(t),Ust=r(GZe," (DeBERTa model)"),GZe.forEach(t),Hst=i(ue),P6=n(ue,"LI",{});var OZe=s(P6);q9e=n(OZe,"STRONG",{});var oha=s(q9e);Jst=r(oha,"deberta-v2"),oha.forEach(t),Yst=r(OZe," \u2014 "),kne=n(OZe,"A",{href:!0});var rha=s(kne);Zst=r(rha,"TFDebertaV2ForQuestionAnswering"),rha.forEach(t),Kst=r(OZe," (DeBERTa-v2 model)"),OZe.forEach(t),elt=i(ue),B6=n(ue,"LI",{});var VZe=s(B6);j9e=n(VZe,"STRONG",{});var tha=s(j9e);olt=r(tha,"distilbert"),tha.forEach(t),rlt=r(VZe," \u2014 "),Sne=n(VZe,"A",{href:!0});var aha=s(Sne);tlt=r(aha,"TFDistilBertForQuestionAnswering"),aha.forEach(t),alt=r(VZe," (DistilBERT model)"),VZe.forEach(t),nlt=i(ue),I6=n(ue,"LI",{});var XZe=s(I6);D9e=n(XZe,"STRONG",{});var nha=s(D9e);slt=r(nha,"electra"),nha.forEach(t),llt=r(XZe," \u2014 "),Rne=n(XZe,"A",{href:!0});var sha=s(Rne);ilt=r(sha,"TFElectraForQuestionAnswering"),sha.forEach(t),dlt=r(XZe," (ELECTRA model)"),XZe.forEach(t),clt=i(ue),N6=n(ue,"LI",{});var zZe=s(N6);G9e=n(zZe,"STRONG",{});var lha=s(G9e);mlt=r(lha,"flaubert"),lha.forEach(t),flt=r(zZe," \u2014 "),Pne=n(zZe,"A",{href:!0});var iha=s(Pne);glt=r(iha,"TFFlaubertForQuestionAnsweringSimple"),iha.forEach(t),hlt=r(zZe," (FlauBERT model)"),zZe.forEach(t),ult=i(ue),q6=n(ue,"LI",{});var QZe=s(q6);O9e=n(QZe,"STRONG",{});var dha=s(O9e);plt=r(dha,"funnel"),dha.forEach(t),_lt=r(QZe," \u2014 "),Bne=n(QZe,"A",{href:!0});var cha=s(Bne);blt=r(cha,"TFFunnelForQuestionAnswering"),cha.forEach(t),vlt=r(QZe," (Funnel Transformer model)"),QZe.forEach(t),Flt=i(ue),j6=n(ue,"LI",{});var WZe=s(j6);V9e=n(WZe,"STRONG",{});var mha=s(V9e);Tlt=r(mha,"gptj"),mha.forEach(t),Mlt=r(WZe," \u2014 "),Ine=n(WZe,"A",{href:!0});var fha=s(Ine);Elt=r(fha,"TFGPTJForQuestionAnswering"),fha.forEach(t),Clt=r(WZe," (GPT-J model)"),WZe.forEach(t),wlt=i(ue),D6=n(ue,"LI",{});var UZe=s(D6);X9e=n(UZe,"STRONG",{});var gha=s(X9e);Alt=r(gha,"layoutlmv3"),gha.forEach(t),Llt=r(UZe," \u2014 "),Nne=n(UZe,"A",{href:!0});var hha=s(Nne);ylt=r(hha,"TFLayoutLMv3ForQuestionAnswering"),hha.forEach(t),xlt=r(UZe," (LayoutLMv3 model)"),UZe.forEach(t),$lt=i(ue),G6=n(ue,"LI",{});var HZe=s(G6);z9e=n(HZe,"STRONG",{});var uha=s(z9e);klt=r(uha,"longformer"),uha.forEach(t),Slt=r(HZe," \u2014 "),qne=n(HZe,"A",{href:!0});var pha=s(qne);Rlt=r(pha,"TFLongformerForQuestionAnswering"),pha.forEach(t),Plt=r(HZe," (Longformer model)"),HZe.forEach(t),Blt=i(ue),O6=n(ue,"LI",{});var JZe=s(O6);Q9e=n(JZe,"STRONG",{});var _ha=s(Q9e);Ilt=r(_ha,"mobilebert"),_ha.forEach(t),Nlt=r(JZe," \u2014 "),jne=n(JZe,"A",{href:!0});var bha=s(jne);qlt=r(bha,"TFMobileBertForQuestionAnswering"),bha.forEach(t),jlt=r(JZe," (MobileBERT model)"),JZe.forEach(t),Dlt=i(ue),V6=n(ue,"LI",{});var YZe=s(V6);W9e=n(YZe,"STRONG",{});var vha=s(W9e);Glt=r(vha,"mpnet"),vha.forEach(t),Olt=r(YZe," \u2014 "),Dne=n(YZe,"A",{href:!0});var Fha=s(Dne);Vlt=r(Fha,"TFMPNetForQuestionAnswering"),Fha.forEach(t),Xlt=r(YZe," (MPNet model)"),YZe.forEach(t),zlt=i(ue),X6=n(ue,"LI",{});var ZZe=s(X6);U9e=n(ZZe,"STRONG",{});var Tha=s(U9e);Qlt=r(Tha,"rembert"),Tha.forEach(t),Wlt=r(ZZe," \u2014 "),Gne=n(ZZe,"A",{href:!0});var Mha=s(Gne);Ult=r(Mha,"TFRemBertForQuestionAnswering"),Mha.forEach(t),Hlt=r(ZZe," (RemBERT model)"),ZZe.forEach(t),Jlt=i(ue),z6=n(ue,"LI",{});var KZe=s(z6);H9e=n(KZe,"STRONG",{});var Eha=s(H9e);Ylt=r(Eha,"roberta"),Eha.forEach(t),Zlt=r(KZe," \u2014 "),One=n(KZe,"A",{href:!0});var Cha=s(One);Klt=r(Cha,"TFRobertaForQuestionAnswering"),Cha.forEach(t),eit=r(KZe," (RoBERTa model)"),KZe.forEach(t),oit=i(ue),Q6=n(ue,"LI",{});var eKe=s(Q6);J9e=n(eKe,"STRONG",{});var wha=s(J9e);rit=r(wha,"roformer"),wha.forEach(t),tit=r(eKe," \u2014 "),Vne=n(eKe,"A",{href:!0});var Aha=s(Vne);ait=r(Aha,"TFRoFormerForQuestionAnswering"),Aha.forEach(t),nit=r(eKe," (RoFormer model)"),eKe.forEach(t),sit=i(ue),W6=n(ue,"LI",{});var oKe=s(W6);Y9e=n(oKe,"STRONG",{});var Lha=s(Y9e);lit=r(Lha,"xlm"),Lha.forEach(t),iit=r(oKe," \u2014 "),Xne=n(oKe,"A",{href:!0});var yha=s(Xne);dit=r(yha,"TFXLMForQuestionAnsweringSimple"),yha.forEach(t),cit=r(oKe," (XLM model)"),oKe.forEach(t),mit=i(ue),U6=n(ue,"LI",{});var rKe=s(U6);Z9e=n(rKe,"STRONG",{});var xha=s(Z9e);fit=r(xha,"xlm-roberta"),xha.forEach(t),git=r(rKe," \u2014 "),zne=n(rKe,"A",{href:!0});var $ha=s(zne);hit=r($ha,"TFXLMRobertaForQuestionAnswering"),$ha.forEach(t),uit=r(rKe," (XLM-RoBERTa model)"),rKe.forEach(t),pit=i(ue),H6=n(ue,"LI",{});var tKe=s(H6);K9e=n(tKe,"STRONG",{});var kha=s(K9e);_it=r(kha,"xlnet"),kha.forEach(t),bit=r(tKe," \u2014 "),Qne=n(tKe,"A",{href:!0});var Sha=s(Qne);vit=r(Sha,"TFXLNetForQuestionAnsweringSimple"),Sha.forEach(t),Fit=r(tKe," (XLNet model)"),tKe.forEach(t),ue.forEach(t),Tit=i(Pi),T(J6.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),Hro=i(m),Gm=n(m,"H2",{class:!0});var fno=s(Gm);Y6=n(fno,"A",{id:!0,class:!0,href:!0});var Rha=s(Y6);exe=n(Rha,"SPAN",{});var Pha=s(exe);T(OR.$$.fragment,Pha),Pha.forEach(t),Rha.forEach(t),Mit=i(fno),oxe=n(fno,"SPAN",{});var Bha=s(oxe);Eit=r(Bha,"TFAutoModelForVision2Seq"),Bha.forEach(t),fno.forEach(t),Jro=i(m),Mr=n(m,"DIV",{class:!0});var Bi=s(Mr);T(VR.$$.fragment,Bi),Cit=i(Bi),Om=n(Bi,"P",{});var _ce=s(Om);wit=r(_ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wne=n(_ce,"A",{href:!0});var Iha=s(Wne);Ait=r(Iha,"from_pretrained()"),Iha.forEach(t),Lit=r(_ce," class method or the "),Une=n(_ce,"A",{href:!0});var Nha=s(Une);yit=r(Nha,"from_config()"),Nha.forEach(t),xit=r(_ce,` class
method.`),_ce.forEach(t),$it=i(Bi),XR=n(Bi,"P",{});var gno=s(XR);kit=r(gno,"This class cannot be instantiated directly using "),rxe=n(gno,"CODE",{});var qha=s(rxe);Sit=r(qha,"__init__()"),qha.forEach(t),Rit=r(gno," (throws an error)."),gno.forEach(t),Pit=i(Bi),la=n(Bi,"DIV",{class:!0});var U9=s(la);T(zR.$$.fragment,U9),Bit=i(U9),txe=n(U9,"P",{});var jha=s(txe);Iit=r(jha,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jha.forEach(t),Nit=i(U9),Vm=n(U9,"P",{});var bce=s(Vm);qit=r(bce,`Note:
Loading a model from its configuration file does `),axe=n(bce,"STRONG",{});var Dha=s(axe);jit=r(Dha,"not"),Dha.forEach(t),Dit=r(bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hne=n(bce,"A",{href:!0});var Gha=s(Hne);Git=r(Gha,"from_pretrained()"),Gha.forEach(t),Oit=r(bce," to load the model weights."),bce.forEach(t),Vit=i(U9),T(Z6.$$.fragment,U9),U9.forEach(t),Xit=i(Bi),Zr=n(Bi,"DIV",{class:!0});var Ii=s(Zr);T(QR.$$.fragment,Ii),zit=i(Ii),nxe=n(Ii,"P",{});var Oha=s(nxe);Qit=r(Oha,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Oha.forEach(t),Wit=i(Ii),Xn=n(Ii,"P",{});var H9=s(Xn);Uit=r(H9,"The model class to instantiate is selected based on the "),sxe=n(H9,"CODE",{});var Vha=s(sxe);Hit=r(Vha,"model_type"),Vha.forEach(t),Jit=r(H9,` property of the config object (either
passed as an argument or loaded from `),lxe=n(H9,"CODE",{});var Xha=s(lxe);Yit=r(Xha,"pretrained_model_name_or_path"),Xha.forEach(t),Zit=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ixe=n(H9,"CODE",{});var zha=s(ixe);Kit=r(zha,"pretrained_model_name_or_path"),zha.forEach(t),edt=r(H9,":"),H9.forEach(t),odt=i(Ii),dxe=n(Ii,"UL",{});var Qha=s(dxe);K6=n(Qha,"LI",{});var aKe=s(K6);cxe=n(aKe,"STRONG",{});var Wha=s(cxe);rdt=r(Wha,"vision-encoder-decoder"),Wha.forEach(t),tdt=r(aKe," \u2014 "),Jne=n(aKe,"A",{href:!0});var Uha=s(Jne);adt=r(Uha,"TFVisionEncoderDecoderModel"),Uha.forEach(t),ndt=r(aKe," (Vision Encoder decoder model)"),aKe.forEach(t),Qha.forEach(t),sdt=i(Ii),T(e7.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),Yro=i(m),Xm=n(m,"H2",{class:!0});var hno=s(Xm);o7=n(hno,"A",{id:!0,class:!0,href:!0});var Hha=s(o7);mxe=n(Hha,"SPAN",{});var Jha=s(mxe);T(WR.$$.fragment,Jha),Jha.forEach(t),Hha.forEach(t),ldt=i(hno),fxe=n(hno,"SPAN",{});var Yha=s(fxe);idt=r(Yha,"TFAutoModelForSpeechSeq2Seq"),Yha.forEach(t),hno.forEach(t),Zro=i(m),Er=n(m,"DIV",{class:!0});var Ni=s(Er);T(UR.$$.fragment,Ni),ddt=i(Ni),zm=n(Ni,"P",{});var vce=s(zm);cdt=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Yne=n(vce,"A",{href:!0});var Zha=s(Yne);mdt=r(Zha,"from_pretrained()"),Zha.forEach(t),fdt=r(vce," class method or the "),Zne=n(vce,"A",{href:!0});var Kha=s(Zne);gdt=r(Kha,"from_config()"),Kha.forEach(t),hdt=r(vce,` class
method.`),vce.forEach(t),udt=i(Ni),HR=n(Ni,"P",{});var uno=s(HR);pdt=r(uno,"This class cannot be instantiated directly using "),gxe=n(uno,"CODE",{});var eua=s(gxe);_dt=r(eua,"__init__()"),eua.forEach(t),bdt=r(uno," (throws an error)."),uno.forEach(t),vdt=i(Ni),ia=n(Ni,"DIV",{class:!0});var J9=s(ia);T(JR.$$.fragment,J9),Fdt=i(J9),hxe=n(J9,"P",{});var oua=s(hxe);Tdt=r(oua,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),oua.forEach(t),Mdt=i(J9),Qm=n(J9,"P",{});var Fce=s(Qm);Edt=r(Fce,`Note:
Loading a model from its configuration file does `),uxe=n(Fce,"STRONG",{});var rua=s(uxe);Cdt=r(rua,"not"),rua.forEach(t),wdt=r(Fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kne=n(Fce,"A",{href:!0});var tua=s(Kne);Adt=r(tua,"from_pretrained()"),tua.forEach(t),Ldt=r(Fce," to load the model weights."),Fce.forEach(t),ydt=i(J9),T(r7.$$.fragment,J9),J9.forEach(t),xdt=i(Ni),Kr=n(Ni,"DIV",{class:!0});var qi=s(Kr);T(YR.$$.fragment,qi),$dt=i(qi),pxe=n(qi,"P",{});var aua=s(pxe);kdt=r(aua,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),aua.forEach(t),Sdt=i(qi),zn=n(qi,"P",{});var Y9=s(zn);Rdt=r(Y9,"The model class to instantiate is selected based on the "),_xe=n(Y9,"CODE",{});var nua=s(_xe);Pdt=r(nua,"model_type"),nua.forEach(t),Bdt=r(Y9,` property of the config object (either
passed as an argument or loaded from `),bxe=n(Y9,"CODE",{});var sua=s(bxe);Idt=r(sua,"pretrained_model_name_or_path"),sua.forEach(t),Ndt=r(Y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vxe=n(Y9,"CODE",{});var lua=s(vxe);qdt=r(lua,"pretrained_model_name_or_path"),lua.forEach(t),jdt=r(Y9,":"),Y9.forEach(t),Ddt=i(qi),Fxe=n(qi,"UL",{});var iua=s(Fxe);t7=n(iua,"LI",{});var nKe=s(t7);Txe=n(nKe,"STRONG",{});var dua=s(Txe);Gdt=r(dua,"speech_to_text"),dua.forEach(t),Odt=r(nKe," \u2014 "),ese=n(nKe,"A",{href:!0});var cua=s(ese);Vdt=r(cua,"TFSpeech2TextForConditionalGeneration"),cua.forEach(t),Xdt=r(nKe," (Speech2Text model)"),nKe.forEach(t),iua.forEach(t),zdt=i(qi),T(a7.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),Kro=i(m),Wm=n(m,"H2",{class:!0});var pno=s(Wm);n7=n(pno,"A",{id:!0,class:!0,href:!0});var mua=s(n7);Mxe=n(mua,"SPAN",{});var fua=s(Mxe);T(ZR.$$.fragment,fua),fua.forEach(t),mua.forEach(t),Qdt=i(pno),Exe=n(pno,"SPAN",{});var gua=s(Exe);Wdt=r(gua,"FlaxAutoModel"),gua.forEach(t),pno.forEach(t),eto=i(m),Cr=n(m,"DIV",{class:!0});var ji=s(Cr);T(KR.$$.fragment,ji),Udt=i(ji),Um=n(ji,"P",{});var Tce=s(Um);Hdt=r(Tce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ose=n(Tce,"A",{href:!0});var hua=s(ose);Jdt=r(hua,"from_pretrained()"),hua.forEach(t),Ydt=r(Tce," class method or the "),rse=n(Tce,"A",{href:!0});var uua=s(rse);Zdt=r(uua,"from_config()"),uua.forEach(t),Kdt=r(Tce,` class
method.`),Tce.forEach(t),ect=i(ji),eP=n(ji,"P",{});var _no=s(eP);oct=r(_no,"This class cannot be instantiated directly using "),Cxe=n(_no,"CODE",{});var pua=s(Cxe);rct=r(pua,"__init__()"),pua.forEach(t),tct=r(_no," (throws an error)."),_no.forEach(t),act=i(ji),da=n(ji,"DIV",{class:!0});var Z9=s(da);T(oP.$$.fragment,Z9),nct=i(Z9),wxe=n(Z9,"P",{});var _ua=s(wxe);sct=r(_ua,"Instantiates one of the base model classes of the library from a configuration."),_ua.forEach(t),lct=i(Z9),Hm=n(Z9,"P",{});var Mce=s(Hm);ict=r(Mce,`Note:
Loading a model from its configuration file does `),Axe=n(Mce,"STRONG",{});var bua=s(Axe);dct=r(bua,"not"),bua.forEach(t),cct=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),tse=n(Mce,"A",{href:!0});var vua=s(tse);mct=r(vua,"from_pretrained()"),vua.forEach(t),fct=r(Mce," to load the model weights."),Mce.forEach(t),gct=i(Z9),T(s7.$$.fragment,Z9),Z9.forEach(t),hct=i(ji),et=n(ji,"DIV",{class:!0});var Di=s(et);T(rP.$$.fragment,Di),uct=i(Di),Lxe=n(Di,"P",{});var Fua=s(Lxe);pct=r(Fua,"Instantiate one of the base model classes of the library from a pretrained model."),Fua.forEach(t),_ct=i(Di),Qn=n(Di,"P",{});var K9=s(Qn);bct=r(K9,"The model class to instantiate is selected based on the "),yxe=n(K9,"CODE",{});var Tua=s(yxe);vct=r(Tua,"model_type"),Tua.forEach(t),Fct=r(K9,` property of the config object (either
passed as an argument or loaded from `),xxe=n(K9,"CODE",{});var Mua=s(xxe);Tct=r(Mua,"pretrained_model_name_or_path"),Mua.forEach(t),Mct=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$xe=n(K9,"CODE",{});var Eua=s($xe);Ect=r(Eua,"pretrained_model_name_or_path"),Eua.forEach(t),Cct=r(K9,":"),K9.forEach(t),wct=i(Di),te=n(Di,"UL",{});var ne=s(te);l7=n(ne,"LI",{});var sKe=s(l7);kxe=n(sKe,"STRONG",{});var Cua=s(kxe);Act=r(Cua,"albert"),Cua.forEach(t),Lct=r(sKe," \u2014 "),ase=n(sKe,"A",{href:!0});var wua=s(ase);yct=r(wua,"FlaxAlbertModel"),wua.forEach(t),xct=r(sKe," (ALBERT model)"),sKe.forEach(t),$ct=i(ne),i7=n(ne,"LI",{});var lKe=s(i7);Sxe=n(lKe,"STRONG",{});var Aua=s(Sxe);kct=r(Aua,"bart"),Aua.forEach(t),Sct=r(lKe," \u2014 "),nse=n(lKe,"A",{href:!0});var Lua=s(nse);Rct=r(Lua,"FlaxBartModel"),Lua.forEach(t),Pct=r(lKe," (BART model)"),lKe.forEach(t),Bct=i(ne),d7=n(ne,"LI",{});var iKe=s(d7);Rxe=n(iKe,"STRONG",{});var yua=s(Rxe);Ict=r(yua,"beit"),yua.forEach(t),Nct=r(iKe," \u2014 "),sse=n(iKe,"A",{href:!0});var xua=s(sse);qct=r(xua,"FlaxBeitModel"),xua.forEach(t),jct=r(iKe," (BEiT model)"),iKe.forEach(t),Dct=i(ne),c7=n(ne,"LI",{});var dKe=s(c7);Pxe=n(dKe,"STRONG",{});var $ua=s(Pxe);Gct=r($ua,"bert"),$ua.forEach(t),Oct=r(dKe," \u2014 "),lse=n(dKe,"A",{href:!0});var kua=s(lse);Vct=r(kua,"FlaxBertModel"),kua.forEach(t),Xct=r(dKe," (BERT model)"),dKe.forEach(t),zct=i(ne),m7=n(ne,"LI",{});var cKe=s(m7);Bxe=n(cKe,"STRONG",{});var Sua=s(Bxe);Qct=r(Sua,"big_bird"),Sua.forEach(t),Wct=r(cKe," \u2014 "),ise=n(cKe,"A",{href:!0});var Rua=s(ise);Uct=r(Rua,"FlaxBigBirdModel"),Rua.forEach(t),Hct=r(cKe," (BigBird model)"),cKe.forEach(t),Jct=i(ne),f7=n(ne,"LI",{});var mKe=s(f7);Ixe=n(mKe,"STRONG",{});var Pua=s(Ixe);Yct=r(Pua,"blenderbot"),Pua.forEach(t),Zct=r(mKe," \u2014 "),dse=n(mKe,"A",{href:!0});var Bua=s(dse);Kct=r(Bua,"FlaxBlenderbotModel"),Bua.forEach(t),emt=r(mKe," (Blenderbot model)"),mKe.forEach(t),omt=i(ne),g7=n(ne,"LI",{});var fKe=s(g7);Nxe=n(fKe,"STRONG",{});var Iua=s(Nxe);rmt=r(Iua,"blenderbot-small"),Iua.forEach(t),tmt=r(fKe," \u2014 "),cse=n(fKe,"A",{href:!0});var Nua=s(cse);amt=r(Nua,"FlaxBlenderbotSmallModel"),Nua.forEach(t),nmt=r(fKe," (BlenderbotSmall model)"),fKe.forEach(t),smt=i(ne),h7=n(ne,"LI",{});var gKe=s(h7);qxe=n(gKe,"STRONG",{});var qua=s(qxe);lmt=r(qua,"clip"),qua.forEach(t),imt=r(gKe," \u2014 "),mse=n(gKe,"A",{href:!0});var jua=s(mse);dmt=r(jua,"FlaxCLIPModel"),jua.forEach(t),cmt=r(gKe," (CLIP model)"),gKe.forEach(t),mmt=i(ne),u7=n(ne,"LI",{});var hKe=s(u7);jxe=n(hKe,"STRONG",{});var Dua=s(jxe);fmt=r(Dua,"distilbert"),Dua.forEach(t),gmt=r(hKe," \u2014 "),fse=n(hKe,"A",{href:!0});var Gua=s(fse);hmt=r(Gua,"FlaxDistilBertModel"),Gua.forEach(t),umt=r(hKe," (DistilBERT model)"),hKe.forEach(t),pmt=i(ne),p7=n(ne,"LI",{});var uKe=s(p7);Dxe=n(uKe,"STRONG",{});var Oua=s(Dxe);_mt=r(Oua,"electra"),Oua.forEach(t),bmt=r(uKe," \u2014 "),gse=n(uKe,"A",{href:!0});var Vua=s(gse);vmt=r(Vua,"FlaxElectraModel"),Vua.forEach(t),Fmt=r(uKe," (ELECTRA model)"),uKe.forEach(t),Tmt=i(ne),_7=n(ne,"LI",{});var pKe=s(_7);Gxe=n(pKe,"STRONG",{});var Xua=s(Gxe);Mmt=r(Xua,"gpt2"),Xua.forEach(t),Emt=r(pKe," \u2014 "),hse=n(pKe,"A",{href:!0});var zua=s(hse);Cmt=r(zua,"FlaxGPT2Model"),zua.forEach(t),wmt=r(pKe," (OpenAI GPT-2 model)"),pKe.forEach(t),Amt=i(ne),b7=n(ne,"LI",{});var _Ke=s(b7);Oxe=n(_Ke,"STRONG",{});var Qua=s(Oxe);Lmt=r(Qua,"gpt_neo"),Qua.forEach(t),ymt=r(_Ke," \u2014 "),use=n(_Ke,"A",{href:!0});var Wua=s(use);xmt=r(Wua,"FlaxGPTNeoModel"),Wua.forEach(t),$mt=r(_Ke," (GPT Neo model)"),_Ke.forEach(t),kmt=i(ne),v7=n(ne,"LI",{});var bKe=s(v7);Vxe=n(bKe,"STRONG",{});var Uua=s(Vxe);Smt=r(Uua,"gptj"),Uua.forEach(t),Rmt=r(bKe," \u2014 "),pse=n(bKe,"A",{href:!0});var Hua=s(pse);Pmt=r(Hua,"FlaxGPTJModel"),Hua.forEach(t),Bmt=r(bKe," (GPT-J model)"),bKe.forEach(t),Imt=i(ne),F7=n(ne,"LI",{});var vKe=s(F7);Xxe=n(vKe,"STRONG",{});var Jua=s(Xxe);Nmt=r(Jua,"longt5"),Jua.forEach(t),qmt=r(vKe," \u2014 "),_se=n(vKe,"A",{href:!0});var Yua=s(_se);jmt=r(Yua,"FlaxLongT5Model"),Yua.forEach(t),Dmt=r(vKe," (LongT5 model)"),vKe.forEach(t),Gmt=i(ne),T7=n(ne,"LI",{});var FKe=s(T7);zxe=n(FKe,"STRONG",{});var Zua=s(zxe);Omt=r(Zua,"marian"),Zua.forEach(t),Vmt=r(FKe," \u2014 "),bse=n(FKe,"A",{href:!0});var Kua=s(bse);Xmt=r(Kua,"FlaxMarianModel"),Kua.forEach(t),zmt=r(FKe," (Marian model)"),FKe.forEach(t),Qmt=i(ne),M7=n(ne,"LI",{});var TKe=s(M7);Qxe=n(TKe,"STRONG",{});var epa=s(Qxe);Wmt=r(epa,"mbart"),epa.forEach(t),Umt=r(TKe," \u2014 "),vse=n(TKe,"A",{href:!0});var opa=s(vse);Hmt=r(opa,"FlaxMBartModel"),opa.forEach(t),Jmt=r(TKe," (mBART model)"),TKe.forEach(t),Ymt=i(ne),E7=n(ne,"LI",{});var MKe=s(E7);Wxe=n(MKe,"STRONG",{});var rpa=s(Wxe);Zmt=r(rpa,"mt5"),rpa.forEach(t),Kmt=r(MKe," \u2014 "),Fse=n(MKe,"A",{href:!0});var tpa=s(Fse);eft=r(tpa,"FlaxMT5Model"),tpa.forEach(t),oft=r(MKe," (MT5 model)"),MKe.forEach(t),rft=i(ne),C7=n(ne,"LI",{});var EKe=s(C7);Uxe=n(EKe,"STRONG",{});var apa=s(Uxe);tft=r(apa,"opt"),apa.forEach(t),aft=r(EKe," \u2014 "),Tse=n(EKe,"A",{href:!0});var npa=s(Tse);nft=r(npa,"FlaxOPTModel"),npa.forEach(t),sft=r(EKe," (OPT model)"),EKe.forEach(t),lft=i(ne),w7=n(ne,"LI",{});var CKe=s(w7);Hxe=n(CKe,"STRONG",{});var spa=s(Hxe);ift=r(spa,"pegasus"),spa.forEach(t),dft=r(CKe," \u2014 "),Mse=n(CKe,"A",{href:!0});var lpa=s(Mse);cft=r(lpa,"FlaxPegasusModel"),lpa.forEach(t),mft=r(CKe," (Pegasus model)"),CKe.forEach(t),fft=i(ne),A7=n(ne,"LI",{});var wKe=s(A7);Jxe=n(wKe,"STRONG",{});var ipa=s(Jxe);gft=r(ipa,"roberta"),ipa.forEach(t),hft=r(wKe," \u2014 "),Ese=n(wKe,"A",{href:!0});var dpa=s(Ese);uft=r(dpa,"FlaxRobertaModel"),dpa.forEach(t),pft=r(wKe," (RoBERTa model)"),wKe.forEach(t),_ft=i(ne),L7=n(ne,"LI",{});var AKe=s(L7);Yxe=n(AKe,"STRONG",{});var cpa=s(Yxe);bft=r(cpa,"roformer"),cpa.forEach(t),vft=r(AKe," \u2014 "),Cse=n(AKe,"A",{href:!0});var mpa=s(Cse);Fft=r(mpa,"FlaxRoFormerModel"),mpa.forEach(t),Tft=r(AKe," (RoFormer model)"),AKe.forEach(t),Mft=i(ne),y7=n(ne,"LI",{});var LKe=s(y7);Zxe=n(LKe,"STRONG",{});var fpa=s(Zxe);Eft=r(fpa,"t5"),fpa.forEach(t),Cft=r(LKe," \u2014 "),wse=n(LKe,"A",{href:!0});var gpa=s(wse);wft=r(gpa,"FlaxT5Model"),gpa.forEach(t),Aft=r(LKe," (T5 model)"),LKe.forEach(t),Lft=i(ne),x7=n(ne,"LI",{});var yKe=s(x7);Kxe=n(yKe,"STRONG",{});var hpa=s(Kxe);yft=r(hpa,"vision-text-dual-encoder"),hpa.forEach(t),xft=r(yKe," \u2014 "),Ase=n(yKe,"A",{href:!0});var upa=s(Ase);$ft=r(upa,"FlaxVisionTextDualEncoderModel"),upa.forEach(t),kft=r(yKe," (VisionTextDualEncoder model)"),yKe.forEach(t),Sft=i(ne),$7=n(ne,"LI",{});var xKe=s($7);e$e=n(xKe,"STRONG",{});var ppa=s(e$e);Rft=r(ppa,"vit"),ppa.forEach(t),Pft=r(xKe," \u2014 "),Lse=n(xKe,"A",{href:!0});var _pa=s(Lse);Bft=r(_pa,"FlaxViTModel"),_pa.forEach(t),Ift=r(xKe," (ViT model)"),xKe.forEach(t),Nft=i(ne),k7=n(ne,"LI",{});var $Ke=s(k7);o$e=n($Ke,"STRONG",{});var bpa=s(o$e);qft=r(bpa,"wav2vec2"),bpa.forEach(t),jft=r($Ke," \u2014 "),yse=n($Ke,"A",{href:!0});var vpa=s(yse);Dft=r(vpa,"FlaxWav2Vec2Model"),vpa.forEach(t),Gft=r($Ke," (Wav2Vec2 model)"),$Ke.forEach(t),Oft=i(ne),S7=n(ne,"LI",{});var kKe=s(S7);r$e=n(kKe,"STRONG",{});var Fpa=s(r$e);Vft=r(Fpa,"xglm"),Fpa.forEach(t),Xft=r(kKe," \u2014 "),xse=n(kKe,"A",{href:!0});var Tpa=s(xse);zft=r(Tpa,"FlaxXGLMModel"),Tpa.forEach(t),Qft=r(kKe," (XGLM model)"),kKe.forEach(t),Wft=i(ne),R7=n(ne,"LI",{});var SKe=s(R7);t$e=n(SKe,"STRONG",{});var Mpa=s(t$e);Uft=r(Mpa,"xlm-roberta"),Mpa.forEach(t),Hft=r(SKe," \u2014 "),$se=n(SKe,"A",{href:!0});var Epa=s($se);Jft=r(Epa,"FlaxXLMRobertaModel"),Epa.forEach(t),Yft=r(SKe," (XLM-RoBERTa model)"),SKe.forEach(t),ne.forEach(t),Zft=i(Di),T(P7.$$.fragment,Di),Di.forEach(t),ji.forEach(t),oto=i(m),Jm=n(m,"H2",{class:!0});var bno=s(Jm);B7=n(bno,"A",{id:!0,class:!0,href:!0});var Cpa=s(B7);a$e=n(Cpa,"SPAN",{});var wpa=s(a$e);T(tP.$$.fragment,wpa),wpa.forEach(t),Cpa.forEach(t),Kft=i(bno),n$e=n(bno,"SPAN",{});var Apa=s(n$e);egt=r(Apa,"FlaxAutoModelForCausalLM"),Apa.forEach(t),bno.forEach(t),rto=i(m),wr=n(m,"DIV",{class:!0});var Gi=s(wr);T(aP.$$.fragment,Gi),ogt=i(Gi),Ym=n(Gi,"P",{});var Ece=s(Ym);rgt=r(Ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),kse=n(Ece,"A",{href:!0});var Lpa=s(kse);tgt=r(Lpa,"from_pretrained()"),Lpa.forEach(t),agt=r(Ece," class method or the "),Sse=n(Ece,"A",{href:!0});var ypa=s(Sse);ngt=r(ypa,"from_config()"),ypa.forEach(t),sgt=r(Ece,` class
method.`),Ece.forEach(t),lgt=i(Gi),nP=n(Gi,"P",{});var vno=s(nP);igt=r(vno,"This class cannot be instantiated directly using "),s$e=n(vno,"CODE",{});var xpa=s(s$e);dgt=r(xpa,"__init__()"),xpa.forEach(t),cgt=r(vno," (throws an error)."),vno.forEach(t),mgt=i(Gi),ca=n(Gi,"DIV",{class:!0});var ex=s(ca);T(sP.$$.fragment,ex),fgt=i(ex),l$e=n(ex,"P",{});var $pa=s(l$e);ggt=r($pa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$pa.forEach(t),hgt=i(ex),Zm=n(ex,"P",{});var Cce=s(Zm);ugt=r(Cce,`Note:
Loading a model from its configuration file does `),i$e=n(Cce,"STRONG",{});var kpa=s(i$e);pgt=r(kpa,"not"),kpa.forEach(t),_gt=r(Cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rse=n(Cce,"A",{href:!0});var Spa=s(Rse);bgt=r(Spa,"from_pretrained()"),Spa.forEach(t),vgt=r(Cce," to load the model weights."),Cce.forEach(t),Fgt=i(ex),T(I7.$$.fragment,ex),ex.forEach(t),Tgt=i(Gi),ot=n(Gi,"DIV",{class:!0});var Oi=s(ot);T(lP.$$.fragment,Oi),Mgt=i(Oi),d$e=n(Oi,"P",{});var Rpa=s(d$e);Egt=r(Rpa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Rpa.forEach(t),Cgt=i(Oi),Wn=n(Oi,"P",{});var ox=s(Wn);wgt=r(ox,"The model class to instantiate is selected based on the "),c$e=n(ox,"CODE",{});var Ppa=s(c$e);Agt=r(Ppa,"model_type"),Ppa.forEach(t),Lgt=r(ox,` property of the config object (either
passed as an argument or loaded from `),m$e=n(ox,"CODE",{});var Bpa=s(m$e);ygt=r(Bpa,"pretrained_model_name_or_path"),Bpa.forEach(t),xgt=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f$e=n(ox,"CODE",{});var Ipa=s(f$e);$gt=r(Ipa,"pretrained_model_name_or_path"),Ipa.forEach(t),kgt=r(ox,":"),ox.forEach(t),Sgt=i(Oi),xe=n(Oi,"UL",{});var qe=s(xe);N7=n(qe,"LI",{});var RKe=s(N7);g$e=n(RKe,"STRONG",{});var Npa=s(g$e);Rgt=r(Npa,"bart"),Npa.forEach(t),Pgt=r(RKe," \u2014 "),Pse=n(RKe,"A",{href:!0});var qpa=s(Pse);Bgt=r(qpa,"FlaxBartForCausalLM"),qpa.forEach(t),Igt=r(RKe," (BART model)"),RKe.forEach(t),Ngt=i(qe),q7=n(qe,"LI",{});var PKe=s(q7);h$e=n(PKe,"STRONG",{});var jpa=s(h$e);qgt=r(jpa,"bert"),jpa.forEach(t),jgt=r(PKe," \u2014 "),Bse=n(PKe,"A",{href:!0});var Dpa=s(Bse);Dgt=r(Dpa,"FlaxBertForCausalLM"),Dpa.forEach(t),Ggt=r(PKe," (BERT model)"),PKe.forEach(t),Ogt=i(qe),j7=n(qe,"LI",{});var BKe=s(j7);u$e=n(BKe,"STRONG",{});var Gpa=s(u$e);Vgt=r(Gpa,"big_bird"),Gpa.forEach(t),Xgt=r(BKe," \u2014 "),Ise=n(BKe,"A",{href:!0});var Opa=s(Ise);zgt=r(Opa,"FlaxBigBirdForCausalLM"),Opa.forEach(t),Qgt=r(BKe," (BigBird model)"),BKe.forEach(t),Wgt=i(qe),D7=n(qe,"LI",{});var IKe=s(D7);p$e=n(IKe,"STRONG",{});var Vpa=s(p$e);Ugt=r(Vpa,"electra"),Vpa.forEach(t),Hgt=r(IKe," \u2014 "),Nse=n(IKe,"A",{href:!0});var Xpa=s(Nse);Jgt=r(Xpa,"FlaxElectraForCausalLM"),Xpa.forEach(t),Ygt=r(IKe," (ELECTRA model)"),IKe.forEach(t),Zgt=i(qe),G7=n(qe,"LI",{});var NKe=s(G7);_$e=n(NKe,"STRONG",{});var zpa=s(_$e);Kgt=r(zpa,"gpt2"),zpa.forEach(t),eht=r(NKe," \u2014 "),qse=n(NKe,"A",{href:!0});var Qpa=s(qse);oht=r(Qpa,"FlaxGPT2LMHeadModel"),Qpa.forEach(t),rht=r(NKe," (OpenAI GPT-2 model)"),NKe.forEach(t),tht=i(qe),O7=n(qe,"LI",{});var qKe=s(O7);b$e=n(qKe,"STRONG",{});var Wpa=s(b$e);aht=r(Wpa,"gpt_neo"),Wpa.forEach(t),nht=r(qKe," \u2014 "),jse=n(qKe,"A",{href:!0});var Upa=s(jse);sht=r(Upa,"FlaxGPTNeoForCausalLM"),Upa.forEach(t),lht=r(qKe," (GPT Neo model)"),qKe.forEach(t),iht=i(qe),V7=n(qe,"LI",{});var jKe=s(V7);v$e=n(jKe,"STRONG",{});var Hpa=s(v$e);dht=r(Hpa,"gptj"),Hpa.forEach(t),cht=r(jKe," \u2014 "),Dse=n(jKe,"A",{href:!0});var Jpa=s(Dse);mht=r(Jpa,"FlaxGPTJForCausalLM"),Jpa.forEach(t),fht=r(jKe," (GPT-J model)"),jKe.forEach(t),ght=i(qe),X7=n(qe,"LI",{});var DKe=s(X7);F$e=n(DKe,"STRONG",{});var Ypa=s(F$e);hht=r(Ypa,"opt"),Ypa.forEach(t),uht=r(DKe," \u2014 "),Gse=n(DKe,"A",{href:!0});var Zpa=s(Gse);pht=r(Zpa,"FlaxOPTForCausalLM"),Zpa.forEach(t),_ht=r(DKe," (OPT model)"),DKe.forEach(t),bht=i(qe),z7=n(qe,"LI",{});var GKe=s(z7);T$e=n(GKe,"STRONG",{});var Kpa=s(T$e);vht=r(Kpa,"roberta"),Kpa.forEach(t),Fht=r(GKe," \u2014 "),Ose=n(GKe,"A",{href:!0});var e_a=s(Ose);Tht=r(e_a,"FlaxRobertaForCausalLM"),e_a.forEach(t),Mht=r(GKe," (RoBERTa model)"),GKe.forEach(t),Eht=i(qe),Q7=n(qe,"LI",{});var OKe=s(Q7);M$e=n(OKe,"STRONG",{});var o_a=s(M$e);Cht=r(o_a,"xglm"),o_a.forEach(t),wht=r(OKe," \u2014 "),Vse=n(OKe,"A",{href:!0});var r_a=s(Vse);Aht=r(r_a,"FlaxXGLMForCausalLM"),r_a.forEach(t),Lht=r(OKe," (XGLM model)"),OKe.forEach(t),qe.forEach(t),yht=i(Oi),T(W7.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),tto=i(m),Km=n(m,"H2",{class:!0});var Fno=s(Km);U7=n(Fno,"A",{id:!0,class:!0,href:!0});var t_a=s(U7);E$e=n(t_a,"SPAN",{});var a_a=s(E$e);T(iP.$$.fragment,a_a),a_a.forEach(t),t_a.forEach(t),xht=i(Fno),C$e=n(Fno,"SPAN",{});var n_a=s(C$e);$ht=r(n_a,"FlaxAutoModelForPreTraining"),n_a.forEach(t),Fno.forEach(t),ato=i(m),Ar=n(m,"DIV",{class:!0});var Vi=s(Ar);T(dP.$$.fragment,Vi),kht=i(Vi),ef=n(Vi,"P",{});var wce=s(ef);Sht=r(wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Xse=n(wce,"A",{href:!0});var s_a=s(Xse);Rht=r(s_a,"from_pretrained()"),s_a.forEach(t),Pht=r(wce," class method or the "),zse=n(wce,"A",{href:!0});var l_a=s(zse);Bht=r(l_a,"from_config()"),l_a.forEach(t),Iht=r(wce,` class
method.`),wce.forEach(t),Nht=i(Vi),cP=n(Vi,"P",{});var Tno=s(cP);qht=r(Tno,"This class cannot be instantiated directly using "),w$e=n(Tno,"CODE",{});var i_a=s(w$e);jht=r(i_a,"__init__()"),i_a.forEach(t),Dht=r(Tno," (throws an error)."),Tno.forEach(t),Ght=i(Vi),ma=n(Vi,"DIV",{class:!0});var rx=s(ma);T(mP.$$.fragment,rx),Oht=i(rx),A$e=n(rx,"P",{});var d_a=s(A$e);Vht=r(d_a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),d_a.forEach(t),Xht=i(rx),of=n(rx,"P",{});var Ace=s(of);zht=r(Ace,`Note:
Loading a model from its configuration file does `),L$e=n(Ace,"STRONG",{});var c_a=s(L$e);Qht=r(c_a,"not"),c_a.forEach(t),Wht=r(Ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qse=n(Ace,"A",{href:!0});var m_a=s(Qse);Uht=r(m_a,"from_pretrained()"),m_a.forEach(t),Hht=r(Ace," to load the model weights."),Ace.forEach(t),Jht=i(rx),T(H7.$$.fragment,rx),rx.forEach(t),Yht=i(Vi),rt=n(Vi,"DIV",{class:!0});var Xi=s(rt);T(fP.$$.fragment,Xi),Zht=i(Xi),y$e=n(Xi,"P",{});var f_a=s(y$e);Kht=r(f_a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),f_a.forEach(t),eut=i(Xi),Un=n(Xi,"P",{});var tx=s(Un);out=r(tx,"The model class to instantiate is selected based on the "),x$e=n(tx,"CODE",{});var g_a=s(x$e);rut=r(g_a,"model_type"),g_a.forEach(t),tut=r(tx,` property of the config object (either
passed as an argument or loaded from `),$$e=n(tx,"CODE",{});var h_a=s($$e);aut=r(h_a,"pretrained_model_name_or_path"),h_a.forEach(t),nut=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=n(tx,"CODE",{});var u_a=s(k$e);sut=r(u_a,"pretrained_model_name_or_path"),u_a.forEach(t),lut=r(tx,":"),tx.forEach(t),iut=i(Xi),Ee=n(Xi,"UL",{});var we=s(Ee);J7=n(we,"LI",{});var VKe=s(J7);S$e=n(VKe,"STRONG",{});var p_a=s(S$e);dut=r(p_a,"albert"),p_a.forEach(t),cut=r(VKe," \u2014 "),Wse=n(VKe,"A",{href:!0});var __a=s(Wse);mut=r(__a,"FlaxAlbertForPreTraining"),__a.forEach(t),fut=r(VKe," (ALBERT model)"),VKe.forEach(t),gut=i(we),Y7=n(we,"LI",{});var XKe=s(Y7);R$e=n(XKe,"STRONG",{});var b_a=s(R$e);hut=r(b_a,"bart"),b_a.forEach(t),uut=r(XKe," \u2014 "),Use=n(XKe,"A",{href:!0});var v_a=s(Use);put=r(v_a,"FlaxBartForConditionalGeneration"),v_a.forEach(t),_ut=r(XKe," (BART model)"),XKe.forEach(t),but=i(we),Z7=n(we,"LI",{});var zKe=s(Z7);P$e=n(zKe,"STRONG",{});var F_a=s(P$e);vut=r(F_a,"bert"),F_a.forEach(t),Fut=r(zKe," \u2014 "),Hse=n(zKe,"A",{href:!0});var T_a=s(Hse);Tut=r(T_a,"FlaxBertForPreTraining"),T_a.forEach(t),Mut=r(zKe," (BERT model)"),zKe.forEach(t),Eut=i(we),K7=n(we,"LI",{});var QKe=s(K7);B$e=n(QKe,"STRONG",{});var M_a=s(B$e);Cut=r(M_a,"big_bird"),M_a.forEach(t),wut=r(QKe," \u2014 "),Jse=n(QKe,"A",{href:!0});var E_a=s(Jse);Aut=r(E_a,"FlaxBigBirdForPreTraining"),E_a.forEach(t),Lut=r(QKe," (BigBird model)"),QKe.forEach(t),yut=i(we),eL=n(we,"LI",{});var WKe=s(eL);I$e=n(WKe,"STRONG",{});var C_a=s(I$e);xut=r(C_a,"electra"),C_a.forEach(t),$ut=r(WKe," \u2014 "),Yse=n(WKe,"A",{href:!0});var w_a=s(Yse);kut=r(w_a,"FlaxElectraForPreTraining"),w_a.forEach(t),Sut=r(WKe," (ELECTRA model)"),WKe.forEach(t),Rut=i(we),oL=n(we,"LI",{});var UKe=s(oL);N$e=n(UKe,"STRONG",{});var A_a=s(N$e);Put=r(A_a,"longt5"),A_a.forEach(t),But=r(UKe," \u2014 "),Zse=n(UKe,"A",{href:!0});var L_a=s(Zse);Iut=r(L_a,"FlaxLongT5ForConditionalGeneration"),L_a.forEach(t),Nut=r(UKe," (LongT5 model)"),UKe.forEach(t),qut=i(we),rL=n(we,"LI",{});var HKe=s(rL);q$e=n(HKe,"STRONG",{});var y_a=s(q$e);jut=r(y_a,"mbart"),y_a.forEach(t),Dut=r(HKe," \u2014 "),Kse=n(HKe,"A",{href:!0});var x_a=s(Kse);Gut=r(x_a,"FlaxMBartForConditionalGeneration"),x_a.forEach(t),Out=r(HKe," (mBART model)"),HKe.forEach(t),Vut=i(we),tL=n(we,"LI",{});var JKe=s(tL);j$e=n(JKe,"STRONG",{});var $_a=s(j$e);Xut=r($_a,"mt5"),$_a.forEach(t),zut=r(JKe," \u2014 "),ele=n(JKe,"A",{href:!0});var k_a=s(ele);Qut=r(k_a,"FlaxMT5ForConditionalGeneration"),k_a.forEach(t),Wut=r(JKe," (MT5 model)"),JKe.forEach(t),Uut=i(we),aL=n(we,"LI",{});var YKe=s(aL);D$e=n(YKe,"STRONG",{});var S_a=s(D$e);Hut=r(S_a,"roberta"),S_a.forEach(t),Jut=r(YKe," \u2014 "),ole=n(YKe,"A",{href:!0});var R_a=s(ole);Yut=r(R_a,"FlaxRobertaForMaskedLM"),R_a.forEach(t),Zut=r(YKe," (RoBERTa model)"),YKe.forEach(t),Kut=i(we),nL=n(we,"LI",{});var ZKe=s(nL);G$e=n(ZKe,"STRONG",{});var P_a=s(G$e);ept=r(P_a,"roformer"),P_a.forEach(t),opt=r(ZKe," \u2014 "),rle=n(ZKe,"A",{href:!0});var B_a=s(rle);rpt=r(B_a,"FlaxRoFormerForMaskedLM"),B_a.forEach(t),tpt=r(ZKe," (RoFormer model)"),ZKe.forEach(t),apt=i(we),sL=n(we,"LI",{});var KKe=s(sL);O$e=n(KKe,"STRONG",{});var I_a=s(O$e);npt=r(I_a,"t5"),I_a.forEach(t),spt=r(KKe," \u2014 "),tle=n(KKe,"A",{href:!0});var N_a=s(tle);lpt=r(N_a,"FlaxT5ForConditionalGeneration"),N_a.forEach(t),ipt=r(KKe," (T5 model)"),KKe.forEach(t),dpt=i(we),lL=n(we,"LI",{});var eeo=s(lL);V$e=n(eeo,"STRONG",{});var q_a=s(V$e);cpt=r(q_a,"wav2vec2"),q_a.forEach(t),mpt=r(eeo," \u2014 "),ale=n(eeo,"A",{href:!0});var j_a=s(ale);fpt=r(j_a,"FlaxWav2Vec2ForPreTraining"),j_a.forEach(t),gpt=r(eeo," (Wav2Vec2 model)"),eeo.forEach(t),hpt=i(we),iL=n(we,"LI",{});var oeo=s(iL);X$e=n(oeo,"STRONG",{});var D_a=s(X$e);upt=r(D_a,"xlm-roberta"),D_a.forEach(t),ppt=r(oeo," \u2014 "),nle=n(oeo,"A",{href:!0});var G_a=s(nle);_pt=r(G_a,"FlaxXLMRobertaForMaskedLM"),G_a.forEach(t),bpt=r(oeo," (XLM-RoBERTa model)"),oeo.forEach(t),we.forEach(t),vpt=i(Xi),T(dL.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),nto=i(m),rf=n(m,"H2",{class:!0});var Mno=s(rf);cL=n(Mno,"A",{id:!0,class:!0,href:!0});var O_a=s(cL);z$e=n(O_a,"SPAN",{});var V_a=s(z$e);T(gP.$$.fragment,V_a),V_a.forEach(t),O_a.forEach(t),Fpt=i(Mno),Q$e=n(Mno,"SPAN",{});var X_a=s(Q$e);Tpt=r(X_a,"FlaxAutoModelForMaskedLM"),X_a.forEach(t),Mno.forEach(t),sto=i(m),Lr=n(m,"DIV",{class:!0});var zi=s(Lr);T(hP.$$.fragment,zi),Mpt=i(zi),tf=n(zi,"P",{});var Lce=s(tf);Ept=r(Lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sle=n(Lce,"A",{href:!0});var z_a=s(sle);Cpt=r(z_a,"from_pretrained()"),z_a.forEach(t),wpt=r(Lce," class method or the "),lle=n(Lce,"A",{href:!0});var Q_a=s(lle);Apt=r(Q_a,"from_config()"),Q_a.forEach(t),Lpt=r(Lce,` class
method.`),Lce.forEach(t),ypt=i(zi),uP=n(zi,"P",{});var Eno=s(uP);xpt=r(Eno,"This class cannot be instantiated directly using "),W$e=n(Eno,"CODE",{});var W_a=s(W$e);$pt=r(W_a,"__init__()"),W_a.forEach(t),kpt=r(Eno," (throws an error)."),Eno.forEach(t),Spt=i(zi),fa=n(zi,"DIV",{class:!0});var ax=s(fa);T(pP.$$.fragment,ax),Rpt=i(ax),U$e=n(ax,"P",{});var U_a=s(U$e);Ppt=r(U_a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),U_a.forEach(t),Bpt=i(ax),af=n(ax,"P",{});var yce=s(af);Ipt=r(yce,`Note:
Loading a model from its configuration file does `),H$e=n(yce,"STRONG",{});var H_a=s(H$e);Npt=r(H_a,"not"),H_a.forEach(t),qpt=r(yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ile=n(yce,"A",{href:!0});var J_a=s(ile);jpt=r(J_a,"from_pretrained()"),J_a.forEach(t),Dpt=r(yce," to load the model weights."),yce.forEach(t),Gpt=i(ax),T(mL.$$.fragment,ax),ax.forEach(t),Opt=i(zi),tt=n(zi,"DIV",{class:!0});var Qi=s(tt);T(_P.$$.fragment,Qi),Vpt=i(Qi),J$e=n(Qi,"P",{});var Y_a=s(J$e);Xpt=r(Y_a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Y_a.forEach(t),zpt=i(Qi),Hn=n(Qi,"P",{});var nx=s(Hn);Qpt=r(nx,"The model class to instantiate is selected based on the "),Y$e=n(nx,"CODE",{});var Z_a=s(Y$e);Wpt=r(Z_a,"model_type"),Z_a.forEach(t),Upt=r(nx,` property of the config object (either
passed as an argument or loaded from `),Z$e=n(nx,"CODE",{});var K_a=s(Z$e);Hpt=r(K_a,"pretrained_model_name_or_path"),K_a.forEach(t),Jpt=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K$e=n(nx,"CODE",{});var e1a=s(K$e);Ypt=r(e1a,"pretrained_model_name_or_path"),e1a.forEach(t),Zpt=r(nx,":"),nx.forEach(t),Kpt=i(Qi),$e=n(Qi,"UL",{});var je=s($e);fL=n(je,"LI",{});var reo=s(fL);eke=n(reo,"STRONG",{});var o1a=s(eke);e_t=r(o1a,"albert"),o1a.forEach(t),o_t=r(reo," \u2014 "),dle=n(reo,"A",{href:!0});var r1a=s(dle);r_t=r(r1a,"FlaxAlbertForMaskedLM"),r1a.forEach(t),t_t=r(reo," (ALBERT model)"),reo.forEach(t),a_t=i(je),gL=n(je,"LI",{});var teo=s(gL);oke=n(teo,"STRONG",{});var t1a=s(oke);n_t=r(t1a,"bart"),t1a.forEach(t),s_t=r(teo," \u2014 "),cle=n(teo,"A",{href:!0});var a1a=s(cle);l_t=r(a1a,"FlaxBartForConditionalGeneration"),a1a.forEach(t),i_t=r(teo," (BART model)"),teo.forEach(t),d_t=i(je),hL=n(je,"LI",{});var aeo=s(hL);rke=n(aeo,"STRONG",{});var n1a=s(rke);c_t=r(n1a,"bert"),n1a.forEach(t),m_t=r(aeo," \u2014 "),mle=n(aeo,"A",{href:!0});var s1a=s(mle);f_t=r(s1a,"FlaxBertForMaskedLM"),s1a.forEach(t),g_t=r(aeo," (BERT model)"),aeo.forEach(t),h_t=i(je),uL=n(je,"LI",{});var neo=s(uL);tke=n(neo,"STRONG",{});var l1a=s(tke);u_t=r(l1a,"big_bird"),l1a.forEach(t),p_t=r(neo," \u2014 "),fle=n(neo,"A",{href:!0});var i1a=s(fle);__t=r(i1a,"FlaxBigBirdForMaskedLM"),i1a.forEach(t),b_t=r(neo," (BigBird model)"),neo.forEach(t),v_t=i(je),pL=n(je,"LI",{});var seo=s(pL);ake=n(seo,"STRONG",{});var d1a=s(ake);F_t=r(d1a,"distilbert"),d1a.forEach(t),T_t=r(seo," \u2014 "),gle=n(seo,"A",{href:!0});var c1a=s(gle);M_t=r(c1a,"FlaxDistilBertForMaskedLM"),c1a.forEach(t),E_t=r(seo," (DistilBERT model)"),seo.forEach(t),C_t=i(je),_L=n(je,"LI",{});var leo=s(_L);nke=n(leo,"STRONG",{});var m1a=s(nke);w_t=r(m1a,"electra"),m1a.forEach(t),A_t=r(leo," \u2014 "),hle=n(leo,"A",{href:!0});var f1a=s(hle);L_t=r(f1a,"FlaxElectraForMaskedLM"),f1a.forEach(t),y_t=r(leo," (ELECTRA model)"),leo.forEach(t),x_t=i(je),bL=n(je,"LI",{});var ieo=s(bL);ske=n(ieo,"STRONG",{});var g1a=s(ske);$_t=r(g1a,"mbart"),g1a.forEach(t),k_t=r(ieo," \u2014 "),ule=n(ieo,"A",{href:!0});var h1a=s(ule);S_t=r(h1a,"FlaxMBartForConditionalGeneration"),h1a.forEach(t),R_t=r(ieo," (mBART model)"),ieo.forEach(t),P_t=i(je),vL=n(je,"LI",{});var deo=s(vL);lke=n(deo,"STRONG",{});var u1a=s(lke);B_t=r(u1a,"roberta"),u1a.forEach(t),I_t=r(deo," \u2014 "),ple=n(deo,"A",{href:!0});var p1a=s(ple);N_t=r(p1a,"FlaxRobertaForMaskedLM"),p1a.forEach(t),q_t=r(deo," (RoBERTa model)"),deo.forEach(t),j_t=i(je),FL=n(je,"LI",{});var ceo=s(FL);ike=n(ceo,"STRONG",{});var _1a=s(ike);D_t=r(_1a,"roformer"),_1a.forEach(t),G_t=r(ceo," \u2014 "),_le=n(ceo,"A",{href:!0});var b1a=s(_le);O_t=r(b1a,"FlaxRoFormerForMaskedLM"),b1a.forEach(t),V_t=r(ceo," (RoFormer model)"),ceo.forEach(t),X_t=i(je),TL=n(je,"LI",{});var meo=s(TL);dke=n(meo,"STRONG",{});var v1a=s(dke);z_t=r(v1a,"xlm-roberta"),v1a.forEach(t),Q_t=r(meo," \u2014 "),ble=n(meo,"A",{href:!0});var F1a=s(ble);W_t=r(F1a,"FlaxXLMRobertaForMaskedLM"),F1a.forEach(t),U_t=r(meo," (XLM-RoBERTa model)"),meo.forEach(t),je.forEach(t),H_t=i(Qi),T(ML.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),lto=i(m),nf=n(m,"H2",{class:!0});var Cno=s(nf);EL=n(Cno,"A",{id:!0,class:!0,href:!0});var T1a=s(EL);cke=n(T1a,"SPAN",{});var M1a=s(cke);T(bP.$$.fragment,M1a),M1a.forEach(t),T1a.forEach(t),J_t=i(Cno),mke=n(Cno,"SPAN",{});var E1a=s(mke);Y_t=r(E1a,"FlaxAutoModelForSeq2SeqLM"),E1a.forEach(t),Cno.forEach(t),ito=i(m),yr=n(m,"DIV",{class:!0});var Wi=s(yr);T(vP.$$.fragment,Wi),Z_t=i(Wi),sf=n(Wi,"P",{});var xce=s(sf);K_t=r(xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),vle=n(xce,"A",{href:!0});var C1a=s(vle);e1t=r(C1a,"from_pretrained()"),C1a.forEach(t),o1t=r(xce," class method or the "),Fle=n(xce,"A",{href:!0});var w1a=s(Fle);r1t=r(w1a,"from_config()"),w1a.forEach(t),t1t=r(xce,` class
method.`),xce.forEach(t),a1t=i(Wi),FP=n(Wi,"P",{});var wno=s(FP);n1t=r(wno,"This class cannot be instantiated directly using "),fke=n(wno,"CODE",{});var A1a=s(fke);s1t=r(A1a,"__init__()"),A1a.forEach(t),l1t=r(wno," (throws an error)."),wno.forEach(t),i1t=i(Wi),ga=n(Wi,"DIV",{class:!0});var sx=s(ga);T(TP.$$.fragment,sx),d1t=i(sx),gke=n(sx,"P",{});var L1a=s(gke);c1t=r(L1a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),L1a.forEach(t),m1t=i(sx),lf=n(sx,"P",{});var $ce=s(lf);f1t=r($ce,`Note:
Loading a model from its configuration file does `),hke=n($ce,"STRONG",{});var y1a=s(hke);g1t=r(y1a,"not"),y1a.forEach(t),h1t=r($ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tle=n($ce,"A",{href:!0});var x1a=s(Tle);u1t=r(x1a,"from_pretrained()"),x1a.forEach(t),p1t=r($ce," to load the model weights."),$ce.forEach(t),_1t=i(sx),T(CL.$$.fragment,sx),sx.forEach(t),b1t=i(Wi),at=n(Wi,"DIV",{class:!0});var Ui=s(at);T(MP.$$.fragment,Ui),v1t=i(Ui),uke=n(Ui,"P",{});var $1a=s(uke);F1t=r($1a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$1a.forEach(t),T1t=i(Ui),Jn=n(Ui,"P",{});var lx=s(Jn);M1t=r(lx,"The model class to instantiate is selected based on the "),pke=n(lx,"CODE",{});var k1a=s(pke);E1t=r(k1a,"model_type"),k1a.forEach(t),C1t=r(lx,` property of the config object (either
passed as an argument or loaded from `),_ke=n(lx,"CODE",{});var S1a=s(_ke);w1t=r(S1a,"pretrained_model_name_or_path"),S1a.forEach(t),A1t=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bke=n(lx,"CODE",{});var R1a=s(bke);L1t=r(R1a,"pretrained_model_name_or_path"),R1a.forEach(t),y1t=r(lx,":"),lx.forEach(t),x1t=i(Ui),ke=n(Ui,"UL",{});var De=s(ke);wL=n(De,"LI",{});var feo=s(wL);vke=n(feo,"STRONG",{});var P1a=s(vke);$1t=r(P1a,"bart"),P1a.forEach(t),k1t=r(feo," \u2014 "),Mle=n(feo,"A",{href:!0});var B1a=s(Mle);S1t=r(B1a,"FlaxBartForConditionalGeneration"),B1a.forEach(t),R1t=r(feo," (BART model)"),feo.forEach(t),P1t=i(De),AL=n(De,"LI",{});var geo=s(AL);Fke=n(geo,"STRONG",{});var I1a=s(Fke);B1t=r(I1a,"blenderbot"),I1a.forEach(t),I1t=r(geo," \u2014 "),Ele=n(geo,"A",{href:!0});var N1a=s(Ele);N1t=r(N1a,"FlaxBlenderbotForConditionalGeneration"),N1a.forEach(t),q1t=r(geo," (Blenderbot model)"),geo.forEach(t),j1t=i(De),LL=n(De,"LI",{});var heo=s(LL);Tke=n(heo,"STRONG",{});var q1a=s(Tke);D1t=r(q1a,"blenderbot-small"),q1a.forEach(t),G1t=r(heo," \u2014 "),Cle=n(heo,"A",{href:!0});var j1a=s(Cle);O1t=r(j1a,"FlaxBlenderbotSmallForConditionalGeneration"),j1a.forEach(t),V1t=r(heo," (BlenderbotSmall model)"),heo.forEach(t),X1t=i(De),yL=n(De,"LI",{});var ueo=s(yL);Mke=n(ueo,"STRONG",{});var D1a=s(Mke);z1t=r(D1a,"encoder-decoder"),D1a.forEach(t),Q1t=r(ueo," \u2014 "),wle=n(ueo,"A",{href:!0});var G1a=s(wle);W1t=r(G1a,"FlaxEncoderDecoderModel"),G1a.forEach(t),U1t=r(ueo," (Encoder decoder model)"),ueo.forEach(t),H1t=i(De),xL=n(De,"LI",{});var peo=s(xL);Eke=n(peo,"STRONG",{});var O1a=s(Eke);J1t=r(O1a,"longt5"),O1a.forEach(t),Y1t=r(peo," \u2014 "),Ale=n(peo,"A",{href:!0});var V1a=s(Ale);Z1t=r(V1a,"FlaxLongT5ForConditionalGeneration"),V1a.forEach(t),K1t=r(peo," (LongT5 model)"),peo.forEach(t),ebt=i(De),$L=n(De,"LI",{});var _eo=s($L);Cke=n(_eo,"STRONG",{});var X1a=s(Cke);obt=r(X1a,"marian"),X1a.forEach(t),rbt=r(_eo," \u2014 "),Lle=n(_eo,"A",{href:!0});var z1a=s(Lle);tbt=r(z1a,"FlaxMarianMTModel"),z1a.forEach(t),abt=r(_eo," (Marian model)"),_eo.forEach(t),nbt=i(De),kL=n(De,"LI",{});var beo=s(kL);wke=n(beo,"STRONG",{});var Q1a=s(wke);sbt=r(Q1a,"mbart"),Q1a.forEach(t),lbt=r(beo," \u2014 "),yle=n(beo,"A",{href:!0});var W1a=s(yle);ibt=r(W1a,"FlaxMBartForConditionalGeneration"),W1a.forEach(t),dbt=r(beo," (mBART model)"),beo.forEach(t),cbt=i(De),SL=n(De,"LI",{});var veo=s(SL);Ake=n(veo,"STRONG",{});var U1a=s(Ake);mbt=r(U1a,"mt5"),U1a.forEach(t),fbt=r(veo," \u2014 "),xle=n(veo,"A",{href:!0});var H1a=s(xle);gbt=r(H1a,"FlaxMT5ForConditionalGeneration"),H1a.forEach(t),hbt=r(veo," (MT5 model)"),veo.forEach(t),ubt=i(De),RL=n(De,"LI",{});var Feo=s(RL);Lke=n(Feo,"STRONG",{});var J1a=s(Lke);pbt=r(J1a,"pegasus"),J1a.forEach(t),_bt=r(Feo," \u2014 "),$le=n(Feo,"A",{href:!0});var Y1a=s($le);bbt=r(Y1a,"FlaxPegasusForConditionalGeneration"),Y1a.forEach(t),vbt=r(Feo," (Pegasus model)"),Feo.forEach(t),Fbt=i(De),PL=n(De,"LI",{});var Teo=s(PL);yke=n(Teo,"STRONG",{});var Z1a=s(yke);Tbt=r(Z1a,"t5"),Z1a.forEach(t),Mbt=r(Teo," \u2014 "),kle=n(Teo,"A",{href:!0});var K1a=s(kle);Ebt=r(K1a,"FlaxT5ForConditionalGeneration"),K1a.forEach(t),Cbt=r(Teo," (T5 model)"),Teo.forEach(t),De.forEach(t),wbt=i(Ui),T(BL.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),dto=i(m),df=n(m,"H2",{class:!0});var Ano=s(df);IL=n(Ano,"A",{id:!0,class:!0,href:!0});var eba=s(IL);xke=n(eba,"SPAN",{});var oba=s(xke);T(EP.$$.fragment,oba),oba.forEach(t),eba.forEach(t),Abt=i(Ano),$ke=n(Ano,"SPAN",{});var rba=s($ke);Lbt=r(rba,"FlaxAutoModelForSequenceClassification"),rba.forEach(t),Ano.forEach(t),cto=i(m),xr=n(m,"DIV",{class:!0});var Hi=s(xr);T(CP.$$.fragment,Hi),ybt=i(Hi),cf=n(Hi,"P",{});var kce=s(cf);xbt=r(kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Sle=n(kce,"A",{href:!0});var tba=s(Sle);$bt=r(tba,"from_pretrained()"),tba.forEach(t),kbt=r(kce," class method or the "),Rle=n(kce,"A",{href:!0});var aba=s(Rle);Sbt=r(aba,"from_config()"),aba.forEach(t),Rbt=r(kce,` class
method.`),kce.forEach(t),Pbt=i(Hi),wP=n(Hi,"P",{});var Lno=s(wP);Bbt=r(Lno,"This class cannot be instantiated directly using "),kke=n(Lno,"CODE",{});var nba=s(kke);Ibt=r(nba,"__init__()"),nba.forEach(t),Nbt=r(Lno," (throws an error)."),Lno.forEach(t),qbt=i(Hi),ha=n(Hi,"DIV",{class:!0});var ix=s(ha);T(AP.$$.fragment,ix),jbt=i(ix),Ske=n(ix,"P",{});var sba=s(Ske);Dbt=r(sba,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),sba.forEach(t),Gbt=i(ix),mf=n(ix,"P",{});var Sce=s(mf);Obt=r(Sce,`Note:
Loading a model from its configuration file does `),Rke=n(Sce,"STRONG",{});var lba=s(Rke);Vbt=r(lba,"not"),lba.forEach(t),Xbt=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ple=n(Sce,"A",{href:!0});var iba=s(Ple);zbt=r(iba,"from_pretrained()"),iba.forEach(t),Qbt=r(Sce," to load the model weights."),Sce.forEach(t),Wbt=i(ix),T(NL.$$.fragment,ix),ix.forEach(t),Ubt=i(Hi),nt=n(Hi,"DIV",{class:!0});var Ji=s(nt);T(LP.$$.fragment,Ji),Hbt=i(Ji),Pke=n(Ji,"P",{});var dba=s(Pke);Jbt=r(dba,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),dba.forEach(t),Ybt=i(Ji),Yn=n(Ji,"P",{});var dx=s(Yn);Zbt=r(dx,"The model class to instantiate is selected based on the "),Bke=n(dx,"CODE",{});var cba=s(Bke);Kbt=r(cba,"model_type"),cba.forEach(t),e2t=r(dx,` property of the config object (either
passed as an argument or loaded from `),Ike=n(dx,"CODE",{});var mba=s(Ike);o2t=r(mba,"pretrained_model_name_or_path"),mba.forEach(t),r2t=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nke=n(dx,"CODE",{});var fba=s(Nke);t2t=r(fba,"pretrained_model_name_or_path"),fba.forEach(t),a2t=r(dx,":"),dx.forEach(t),n2t=i(Ji),Se=n(Ji,"UL",{});var Ge=s(Se);qL=n(Ge,"LI",{});var Meo=s(qL);qke=n(Meo,"STRONG",{});var gba=s(qke);s2t=r(gba,"albert"),gba.forEach(t),l2t=r(Meo," \u2014 "),Ble=n(Meo,"A",{href:!0});var hba=s(Ble);i2t=r(hba,"FlaxAlbertForSequenceClassification"),hba.forEach(t),d2t=r(Meo," (ALBERT model)"),Meo.forEach(t),c2t=i(Ge),jL=n(Ge,"LI",{});var Eeo=s(jL);jke=n(Eeo,"STRONG",{});var uba=s(jke);m2t=r(uba,"bart"),uba.forEach(t),f2t=r(Eeo," \u2014 "),Ile=n(Eeo,"A",{href:!0});var pba=s(Ile);g2t=r(pba,"FlaxBartForSequenceClassification"),pba.forEach(t),h2t=r(Eeo," (BART model)"),Eeo.forEach(t),u2t=i(Ge),DL=n(Ge,"LI",{});var Ceo=s(DL);Dke=n(Ceo,"STRONG",{});var _ba=s(Dke);p2t=r(_ba,"bert"),_ba.forEach(t),_2t=r(Ceo," \u2014 "),Nle=n(Ceo,"A",{href:!0});var bba=s(Nle);b2t=r(bba,"FlaxBertForSequenceClassification"),bba.forEach(t),v2t=r(Ceo," (BERT model)"),Ceo.forEach(t),F2t=i(Ge),GL=n(Ge,"LI",{});var weo=s(GL);Gke=n(weo,"STRONG",{});var vba=s(Gke);T2t=r(vba,"big_bird"),vba.forEach(t),M2t=r(weo," \u2014 "),qle=n(weo,"A",{href:!0});var Fba=s(qle);E2t=r(Fba,"FlaxBigBirdForSequenceClassification"),Fba.forEach(t),C2t=r(weo," (BigBird model)"),weo.forEach(t),w2t=i(Ge),OL=n(Ge,"LI",{});var Aeo=s(OL);Oke=n(Aeo,"STRONG",{});var Tba=s(Oke);A2t=r(Tba,"distilbert"),Tba.forEach(t),L2t=r(Aeo," \u2014 "),jle=n(Aeo,"A",{href:!0});var Mba=s(jle);y2t=r(Mba,"FlaxDistilBertForSequenceClassification"),Mba.forEach(t),x2t=r(Aeo," (DistilBERT model)"),Aeo.forEach(t),$2t=i(Ge),VL=n(Ge,"LI",{});var Leo=s(VL);Vke=n(Leo,"STRONG",{});var Eba=s(Vke);k2t=r(Eba,"electra"),Eba.forEach(t),S2t=r(Leo," \u2014 "),Dle=n(Leo,"A",{href:!0});var Cba=s(Dle);R2t=r(Cba,"FlaxElectraForSequenceClassification"),Cba.forEach(t),P2t=r(Leo," (ELECTRA model)"),Leo.forEach(t),B2t=i(Ge),XL=n(Ge,"LI",{});var yeo=s(XL);Xke=n(yeo,"STRONG",{});var wba=s(Xke);I2t=r(wba,"mbart"),wba.forEach(t),N2t=r(yeo," \u2014 "),Gle=n(yeo,"A",{href:!0});var Aba=s(Gle);q2t=r(Aba,"FlaxMBartForSequenceClassification"),Aba.forEach(t),j2t=r(yeo," (mBART model)"),yeo.forEach(t),D2t=i(Ge),zL=n(Ge,"LI",{});var xeo=s(zL);zke=n(xeo,"STRONG",{});var Lba=s(zke);G2t=r(Lba,"roberta"),Lba.forEach(t),O2t=r(xeo," \u2014 "),Ole=n(xeo,"A",{href:!0});var yba=s(Ole);V2t=r(yba,"FlaxRobertaForSequenceClassification"),yba.forEach(t),X2t=r(xeo," (RoBERTa model)"),xeo.forEach(t),z2t=i(Ge),QL=n(Ge,"LI",{});var $eo=s(QL);Qke=n($eo,"STRONG",{});var xba=s(Qke);Q2t=r(xba,"roformer"),xba.forEach(t),W2t=r($eo," \u2014 "),Vle=n($eo,"A",{href:!0});var $ba=s(Vle);U2t=r($ba,"FlaxRoFormerForSequenceClassification"),$ba.forEach(t),H2t=r($eo," (RoFormer model)"),$eo.forEach(t),J2t=i(Ge),WL=n(Ge,"LI",{});var keo=s(WL);Wke=n(keo,"STRONG",{});var kba=s(Wke);Y2t=r(kba,"xlm-roberta"),kba.forEach(t),Z2t=r(keo," \u2014 "),Xle=n(keo,"A",{href:!0});var Sba=s(Xle);K2t=r(Sba,"FlaxXLMRobertaForSequenceClassification"),Sba.forEach(t),evt=r(keo," (XLM-RoBERTa model)"),keo.forEach(t),Ge.forEach(t),ovt=i(Ji),T(UL.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),mto=i(m),ff=n(m,"H2",{class:!0});var yno=s(ff);HL=n(yno,"A",{id:!0,class:!0,href:!0});var Rba=s(HL);Uke=n(Rba,"SPAN",{});var Pba=s(Uke);T(yP.$$.fragment,Pba),Pba.forEach(t),Rba.forEach(t),rvt=i(yno),Hke=n(yno,"SPAN",{});var Bba=s(Hke);tvt=r(Bba,"FlaxAutoModelForQuestionAnswering"),Bba.forEach(t),yno.forEach(t),fto=i(m),$r=n(m,"DIV",{class:!0});var Yi=s($r);T(xP.$$.fragment,Yi),avt=i(Yi),gf=n(Yi,"P",{});var Rce=s(gf);nvt=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),zle=n(Rce,"A",{href:!0});var Iba=s(zle);svt=r(Iba,"from_pretrained()"),Iba.forEach(t),lvt=r(Rce," class method or the "),Qle=n(Rce,"A",{href:!0});var Nba=s(Qle);ivt=r(Nba,"from_config()"),Nba.forEach(t),dvt=r(Rce,` class
method.`),Rce.forEach(t),cvt=i(Yi),$P=n(Yi,"P",{});var xno=s($P);mvt=r(xno,"This class cannot be instantiated directly using "),Jke=n(xno,"CODE",{});var qba=s(Jke);fvt=r(qba,"__init__()"),qba.forEach(t),gvt=r(xno," (throws an error)."),xno.forEach(t),hvt=i(Yi),ua=n(Yi,"DIV",{class:!0});var cx=s(ua);T(kP.$$.fragment,cx),uvt=i(cx),Yke=n(cx,"P",{});var jba=s(Yke);pvt=r(jba,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),jba.forEach(t),_vt=i(cx),hf=n(cx,"P",{});var Pce=s(hf);bvt=r(Pce,`Note:
Loading a model from its configuration file does `),Zke=n(Pce,"STRONG",{});var Dba=s(Zke);vvt=r(Dba,"not"),Dba.forEach(t),Fvt=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wle=n(Pce,"A",{href:!0});var Gba=s(Wle);Tvt=r(Gba,"from_pretrained()"),Gba.forEach(t),Mvt=r(Pce," to load the model weights."),Pce.forEach(t),Evt=i(cx),T(JL.$$.fragment,cx),cx.forEach(t),Cvt=i(Yi),st=n(Yi,"DIV",{class:!0});var Zi=s(st);T(SP.$$.fragment,Zi),wvt=i(Zi),Kke=n(Zi,"P",{});var Oba=s(Kke);Avt=r(Oba,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Oba.forEach(t),Lvt=i(Zi),Zn=n(Zi,"P",{});var mx=s(Zn);yvt=r(mx,"The model class to instantiate is selected based on the "),eSe=n(mx,"CODE",{});var Vba=s(eSe);xvt=r(Vba,"model_type"),Vba.forEach(t),$vt=r(mx,` property of the config object (either
passed as an argument or loaded from `),oSe=n(mx,"CODE",{});var Xba=s(oSe);kvt=r(Xba,"pretrained_model_name_or_path"),Xba.forEach(t),Svt=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rSe=n(mx,"CODE",{});var zba=s(rSe);Rvt=r(zba,"pretrained_model_name_or_path"),zba.forEach(t),Pvt=r(mx,":"),mx.forEach(t),Bvt=i(Zi),Re=n(Zi,"UL",{});var Oe=s(Re);YL=n(Oe,"LI",{});var Seo=s(YL);tSe=n(Seo,"STRONG",{});var Qba=s(tSe);Ivt=r(Qba,"albert"),Qba.forEach(t),Nvt=r(Seo," \u2014 "),Ule=n(Seo,"A",{href:!0});var Wba=s(Ule);qvt=r(Wba,"FlaxAlbertForQuestionAnswering"),Wba.forEach(t),jvt=r(Seo," (ALBERT model)"),Seo.forEach(t),Dvt=i(Oe),ZL=n(Oe,"LI",{});var Reo=s(ZL);aSe=n(Reo,"STRONG",{});var Uba=s(aSe);Gvt=r(Uba,"bart"),Uba.forEach(t),Ovt=r(Reo," \u2014 "),Hle=n(Reo,"A",{href:!0});var Hba=s(Hle);Vvt=r(Hba,"FlaxBartForQuestionAnswering"),Hba.forEach(t),Xvt=r(Reo," (BART model)"),Reo.forEach(t),zvt=i(Oe),KL=n(Oe,"LI",{});var Peo=s(KL);nSe=n(Peo,"STRONG",{});var Jba=s(nSe);Qvt=r(Jba,"bert"),Jba.forEach(t),Wvt=r(Peo," \u2014 "),Jle=n(Peo,"A",{href:!0});var Yba=s(Jle);Uvt=r(Yba,"FlaxBertForQuestionAnswering"),Yba.forEach(t),Hvt=r(Peo," (BERT model)"),Peo.forEach(t),Jvt=i(Oe),ey=n(Oe,"LI",{});var Beo=s(ey);sSe=n(Beo,"STRONG",{});var Zba=s(sSe);Yvt=r(Zba,"big_bird"),Zba.forEach(t),Zvt=r(Beo," \u2014 "),Yle=n(Beo,"A",{href:!0});var Kba=s(Yle);Kvt=r(Kba,"FlaxBigBirdForQuestionAnswering"),Kba.forEach(t),eFt=r(Beo," (BigBird model)"),Beo.forEach(t),oFt=i(Oe),oy=n(Oe,"LI",{});var Ieo=s(oy);lSe=n(Ieo,"STRONG",{});var e2a=s(lSe);rFt=r(e2a,"distilbert"),e2a.forEach(t),tFt=r(Ieo," \u2014 "),Zle=n(Ieo,"A",{href:!0});var o2a=s(Zle);aFt=r(o2a,"FlaxDistilBertForQuestionAnswering"),o2a.forEach(t),nFt=r(Ieo," (DistilBERT model)"),Ieo.forEach(t),sFt=i(Oe),ry=n(Oe,"LI",{});var Neo=s(ry);iSe=n(Neo,"STRONG",{});var r2a=s(iSe);lFt=r(r2a,"electra"),r2a.forEach(t),iFt=r(Neo," \u2014 "),Kle=n(Neo,"A",{href:!0});var t2a=s(Kle);dFt=r(t2a,"FlaxElectraForQuestionAnswering"),t2a.forEach(t),cFt=r(Neo," (ELECTRA model)"),Neo.forEach(t),mFt=i(Oe),ty=n(Oe,"LI",{});var qeo=s(ty);dSe=n(qeo,"STRONG",{});var a2a=s(dSe);fFt=r(a2a,"mbart"),a2a.forEach(t),gFt=r(qeo," \u2014 "),eie=n(qeo,"A",{href:!0});var n2a=s(eie);hFt=r(n2a,"FlaxMBartForQuestionAnswering"),n2a.forEach(t),uFt=r(qeo," (mBART model)"),qeo.forEach(t),pFt=i(Oe),ay=n(Oe,"LI",{});var jeo=s(ay);cSe=n(jeo,"STRONG",{});var s2a=s(cSe);_Ft=r(s2a,"roberta"),s2a.forEach(t),bFt=r(jeo," \u2014 "),oie=n(jeo,"A",{href:!0});var l2a=s(oie);vFt=r(l2a,"FlaxRobertaForQuestionAnswering"),l2a.forEach(t),FFt=r(jeo," (RoBERTa model)"),jeo.forEach(t),TFt=i(Oe),ny=n(Oe,"LI",{});var Deo=s(ny);mSe=n(Deo,"STRONG",{});var i2a=s(mSe);MFt=r(i2a,"roformer"),i2a.forEach(t),EFt=r(Deo," \u2014 "),rie=n(Deo,"A",{href:!0});var d2a=s(rie);CFt=r(d2a,"FlaxRoFormerForQuestionAnswering"),d2a.forEach(t),wFt=r(Deo," (RoFormer model)"),Deo.forEach(t),AFt=i(Oe),sy=n(Oe,"LI",{});var Geo=s(sy);fSe=n(Geo,"STRONG",{});var c2a=s(fSe);LFt=r(c2a,"xlm-roberta"),c2a.forEach(t),yFt=r(Geo," \u2014 "),tie=n(Geo,"A",{href:!0});var m2a=s(tie);xFt=r(m2a,"FlaxXLMRobertaForQuestionAnswering"),m2a.forEach(t),$Ft=r(Geo," (XLM-RoBERTa model)"),Geo.forEach(t),Oe.forEach(t),kFt=i(Zi),T(ly.$$.fragment,Zi),Zi.forEach(t),Yi.forEach(t),gto=i(m),uf=n(m,"H2",{class:!0});var $no=s(uf);iy=n($no,"A",{id:!0,class:!0,href:!0});var f2a=s(iy);gSe=n(f2a,"SPAN",{});var g2a=s(gSe);T(RP.$$.fragment,g2a),g2a.forEach(t),f2a.forEach(t),SFt=i($no),hSe=n($no,"SPAN",{});var h2a=s(hSe);RFt=r(h2a,"FlaxAutoModelForTokenClassification"),h2a.forEach(t),$no.forEach(t),hto=i(m),kr=n(m,"DIV",{class:!0});var Ki=s(kr);T(PP.$$.fragment,Ki),PFt=i(Ki),pf=n(Ki,"P",{});var Bce=s(pf);BFt=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),aie=n(Bce,"A",{href:!0});var u2a=s(aie);IFt=r(u2a,"from_pretrained()"),u2a.forEach(t),NFt=r(Bce," class method or the "),nie=n(Bce,"A",{href:!0});var p2a=s(nie);qFt=r(p2a,"from_config()"),p2a.forEach(t),jFt=r(Bce,` class
method.`),Bce.forEach(t),DFt=i(Ki),BP=n(Ki,"P",{});var kno=s(BP);GFt=r(kno,"This class cannot be instantiated directly using "),uSe=n(kno,"CODE",{});var _2a=s(uSe);OFt=r(_2a,"__init__()"),_2a.forEach(t),VFt=r(kno," (throws an error)."),kno.forEach(t),XFt=i(Ki),pa=n(Ki,"DIV",{class:!0});var fx=s(pa);T(IP.$$.fragment,fx),zFt=i(fx),pSe=n(fx,"P",{});var b2a=s(pSe);QFt=r(b2a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),b2a.forEach(t),WFt=i(fx),_f=n(fx,"P",{});var Ice=s(_f);UFt=r(Ice,`Note:
Loading a model from its configuration file does `),_Se=n(Ice,"STRONG",{});var v2a=s(_Se);HFt=r(v2a,"not"),v2a.forEach(t),JFt=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=n(Ice,"A",{href:!0});var F2a=s(sie);YFt=r(F2a,"from_pretrained()"),F2a.forEach(t),ZFt=r(Ice," to load the model weights."),Ice.forEach(t),KFt=i(fx),T(dy.$$.fragment,fx),fx.forEach(t),eTt=i(Ki),lt=n(Ki,"DIV",{class:!0});var ed=s(lt);T(NP.$$.fragment,ed),oTt=i(ed),bSe=n(ed,"P",{});var T2a=s(bSe);rTt=r(T2a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),T2a.forEach(t),tTt=i(ed),Kn=n(ed,"P",{});var gx=s(Kn);aTt=r(gx,"The model class to instantiate is selected based on the "),vSe=n(gx,"CODE",{});var M2a=s(vSe);nTt=r(M2a,"model_type"),M2a.forEach(t),sTt=r(gx,` property of the config object (either
passed as an argument or loaded from `),FSe=n(gx,"CODE",{});var E2a=s(FSe);lTt=r(E2a,"pretrained_model_name_or_path"),E2a.forEach(t),iTt=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TSe=n(gx,"CODE",{});var C2a=s(TSe);dTt=r(C2a,"pretrained_model_name_or_path"),C2a.forEach(t),cTt=r(gx,":"),gx.forEach(t),mTt=i(ed),Xe=n(ed,"UL",{});var Lo=s(Xe);cy=n(Lo,"LI",{});var Oeo=s(cy);MSe=n(Oeo,"STRONG",{});var w2a=s(MSe);fTt=r(w2a,"albert"),w2a.forEach(t),gTt=r(Oeo," \u2014 "),lie=n(Oeo,"A",{href:!0});var A2a=s(lie);hTt=r(A2a,"FlaxAlbertForTokenClassification"),A2a.forEach(t),uTt=r(Oeo," (ALBERT model)"),Oeo.forEach(t),pTt=i(Lo),my=n(Lo,"LI",{});var Veo=s(my);ESe=n(Veo,"STRONG",{});var L2a=s(ESe);_Tt=r(L2a,"bert"),L2a.forEach(t),bTt=r(Veo," \u2014 "),iie=n(Veo,"A",{href:!0});var y2a=s(iie);vTt=r(y2a,"FlaxBertForTokenClassification"),y2a.forEach(t),FTt=r(Veo," (BERT model)"),Veo.forEach(t),TTt=i(Lo),fy=n(Lo,"LI",{});var Xeo=s(fy);CSe=n(Xeo,"STRONG",{});var x2a=s(CSe);MTt=r(x2a,"big_bird"),x2a.forEach(t),ETt=r(Xeo," \u2014 "),die=n(Xeo,"A",{href:!0});var $2a=s(die);CTt=r($2a,"FlaxBigBirdForTokenClassification"),$2a.forEach(t),wTt=r(Xeo," (BigBird model)"),Xeo.forEach(t),ATt=i(Lo),gy=n(Lo,"LI",{});var zeo=s(gy);wSe=n(zeo,"STRONG",{});var k2a=s(wSe);LTt=r(k2a,"distilbert"),k2a.forEach(t),yTt=r(zeo," \u2014 "),cie=n(zeo,"A",{href:!0});var S2a=s(cie);xTt=r(S2a,"FlaxDistilBertForTokenClassification"),S2a.forEach(t),$Tt=r(zeo," (DistilBERT model)"),zeo.forEach(t),kTt=i(Lo),hy=n(Lo,"LI",{});var Qeo=s(hy);ASe=n(Qeo,"STRONG",{});var R2a=s(ASe);STt=r(R2a,"electra"),R2a.forEach(t),RTt=r(Qeo," \u2014 "),mie=n(Qeo,"A",{href:!0});var P2a=s(mie);PTt=r(P2a,"FlaxElectraForTokenClassification"),P2a.forEach(t),BTt=r(Qeo," (ELECTRA model)"),Qeo.forEach(t),ITt=i(Lo),uy=n(Lo,"LI",{});var Weo=s(uy);LSe=n(Weo,"STRONG",{});var B2a=s(LSe);NTt=r(B2a,"roberta"),B2a.forEach(t),qTt=r(Weo," \u2014 "),fie=n(Weo,"A",{href:!0});var I2a=s(fie);jTt=r(I2a,"FlaxRobertaForTokenClassification"),I2a.forEach(t),DTt=r(Weo," (RoBERTa model)"),Weo.forEach(t),GTt=i(Lo),py=n(Lo,"LI",{});var Ueo=s(py);ySe=n(Ueo,"STRONG",{});var N2a=s(ySe);OTt=r(N2a,"roformer"),N2a.forEach(t),VTt=r(Ueo," \u2014 "),gie=n(Ueo,"A",{href:!0});var q2a=s(gie);XTt=r(q2a,"FlaxRoFormerForTokenClassification"),q2a.forEach(t),zTt=r(Ueo," (RoFormer model)"),Ueo.forEach(t),QTt=i(Lo),_y=n(Lo,"LI",{});var Heo=s(_y);xSe=n(Heo,"STRONG",{});var j2a=s(xSe);WTt=r(j2a,"xlm-roberta"),j2a.forEach(t),UTt=r(Heo," \u2014 "),hie=n(Heo,"A",{href:!0});var D2a=s(hie);HTt=r(D2a,"FlaxXLMRobertaForTokenClassification"),D2a.forEach(t),JTt=r(Heo," (XLM-RoBERTa model)"),Heo.forEach(t),Lo.forEach(t),YTt=i(ed),T(by.$$.fragment,ed),ed.forEach(t),Ki.forEach(t),uto=i(m),bf=n(m,"H2",{class:!0});var Sno=s(bf);vy=n(Sno,"A",{id:!0,class:!0,href:!0});var G2a=s(vy);$Se=n(G2a,"SPAN",{});var O2a=s($Se);T(qP.$$.fragment,O2a),O2a.forEach(t),G2a.forEach(t),ZTt=i(Sno),kSe=n(Sno,"SPAN",{});var V2a=s(kSe);KTt=r(V2a,"FlaxAutoModelForMultipleChoice"),V2a.forEach(t),Sno.forEach(t),pto=i(m),Sr=n(m,"DIV",{class:!0});var od=s(Sr);T(jP.$$.fragment,od),eMt=i(od),vf=n(od,"P",{});var Nce=s(vf);oMt=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),uie=n(Nce,"A",{href:!0});var X2a=s(uie);rMt=r(X2a,"from_pretrained()"),X2a.forEach(t),tMt=r(Nce," class method or the "),pie=n(Nce,"A",{href:!0});var z2a=s(pie);aMt=r(z2a,"from_config()"),z2a.forEach(t),nMt=r(Nce,` class
method.`),Nce.forEach(t),sMt=i(od),DP=n(od,"P",{});var Rno=s(DP);lMt=r(Rno,"This class cannot be instantiated directly using "),SSe=n(Rno,"CODE",{});var Q2a=s(SSe);iMt=r(Q2a,"__init__()"),Q2a.forEach(t),dMt=r(Rno," (throws an error)."),Rno.forEach(t),cMt=i(od),_a=n(od,"DIV",{class:!0});var hx=s(_a);T(GP.$$.fragment,hx),mMt=i(hx),RSe=n(hx,"P",{});var W2a=s(RSe);fMt=r(W2a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),W2a.forEach(t),gMt=i(hx),Ff=n(hx,"P",{});var qce=s(Ff);hMt=r(qce,`Note:
Loading a model from its configuration file does `),PSe=n(qce,"STRONG",{});var U2a=s(PSe);uMt=r(U2a,"not"),U2a.forEach(t),pMt=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=n(qce,"A",{href:!0});var H2a=s(_ie);_Mt=r(H2a,"from_pretrained()"),H2a.forEach(t),bMt=r(qce," to load the model weights."),qce.forEach(t),vMt=i(hx),T(Fy.$$.fragment,hx),hx.forEach(t),FMt=i(od),it=n(od,"DIV",{class:!0});var rd=s(it);T(OP.$$.fragment,rd),TMt=i(rd),BSe=n(rd,"P",{});var J2a=s(BSe);MMt=r(J2a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),J2a.forEach(t),EMt=i(rd),es=n(rd,"P",{});var ux=s(es);CMt=r(ux,"The model class to instantiate is selected based on the "),ISe=n(ux,"CODE",{});var Y2a=s(ISe);wMt=r(Y2a,"model_type"),Y2a.forEach(t),AMt=r(ux,` property of the config object (either
passed as an argument or loaded from `),NSe=n(ux,"CODE",{});var Z2a=s(NSe);LMt=r(Z2a,"pretrained_model_name_or_path"),Z2a.forEach(t),yMt=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qSe=n(ux,"CODE",{});var K2a=s(qSe);xMt=r(K2a,"pretrained_model_name_or_path"),K2a.forEach(t),$Mt=r(ux,":"),ux.forEach(t),kMt=i(rd),ze=n(rd,"UL",{});var yo=s(ze);Ty=n(yo,"LI",{});var Jeo=s(Ty);jSe=n(Jeo,"STRONG",{});var eva=s(jSe);SMt=r(eva,"albert"),eva.forEach(t),RMt=r(Jeo," \u2014 "),bie=n(Jeo,"A",{href:!0});var ova=s(bie);PMt=r(ova,"FlaxAlbertForMultipleChoice"),ova.forEach(t),BMt=r(Jeo," (ALBERT model)"),Jeo.forEach(t),IMt=i(yo),My=n(yo,"LI",{});var Yeo=s(My);DSe=n(Yeo,"STRONG",{});var rva=s(DSe);NMt=r(rva,"bert"),rva.forEach(t),qMt=r(Yeo," \u2014 "),vie=n(Yeo,"A",{href:!0});var tva=s(vie);jMt=r(tva,"FlaxBertForMultipleChoice"),tva.forEach(t),DMt=r(Yeo," (BERT model)"),Yeo.forEach(t),GMt=i(yo),Ey=n(yo,"LI",{});var Zeo=s(Ey);GSe=n(Zeo,"STRONG",{});var ava=s(GSe);OMt=r(ava,"big_bird"),ava.forEach(t),VMt=r(Zeo," \u2014 "),Fie=n(Zeo,"A",{href:!0});var nva=s(Fie);XMt=r(nva,"FlaxBigBirdForMultipleChoice"),nva.forEach(t),zMt=r(Zeo," (BigBird model)"),Zeo.forEach(t),QMt=i(yo),Cy=n(yo,"LI",{});var Keo=s(Cy);OSe=n(Keo,"STRONG",{});var sva=s(OSe);WMt=r(sva,"distilbert"),sva.forEach(t),UMt=r(Keo," \u2014 "),Tie=n(Keo,"A",{href:!0});var lva=s(Tie);HMt=r(lva,"FlaxDistilBertForMultipleChoice"),lva.forEach(t),JMt=r(Keo," (DistilBERT model)"),Keo.forEach(t),YMt=i(yo),wy=n(yo,"LI",{});var eoo=s(wy);VSe=n(eoo,"STRONG",{});var iva=s(VSe);ZMt=r(iva,"electra"),iva.forEach(t),KMt=r(eoo," \u2014 "),Mie=n(eoo,"A",{href:!0});var dva=s(Mie);eEt=r(dva,"FlaxElectraForMultipleChoice"),dva.forEach(t),oEt=r(eoo," (ELECTRA model)"),eoo.forEach(t),rEt=i(yo),Ay=n(yo,"LI",{});var ooo=s(Ay);XSe=n(ooo,"STRONG",{});var cva=s(XSe);tEt=r(cva,"roberta"),cva.forEach(t),aEt=r(ooo," \u2014 "),Eie=n(ooo,"A",{href:!0});var mva=s(Eie);nEt=r(mva,"FlaxRobertaForMultipleChoice"),mva.forEach(t),sEt=r(ooo," (RoBERTa model)"),ooo.forEach(t),lEt=i(yo),Ly=n(yo,"LI",{});var roo=s(Ly);zSe=n(roo,"STRONG",{});var fva=s(zSe);iEt=r(fva,"roformer"),fva.forEach(t),dEt=r(roo," \u2014 "),Cie=n(roo,"A",{href:!0});var gva=s(Cie);cEt=r(gva,"FlaxRoFormerForMultipleChoice"),gva.forEach(t),mEt=r(roo," (RoFormer model)"),roo.forEach(t),fEt=i(yo),yy=n(yo,"LI",{});var too=s(yy);QSe=n(too,"STRONG",{});var hva=s(QSe);gEt=r(hva,"xlm-roberta"),hva.forEach(t),hEt=r(too," \u2014 "),wie=n(too,"A",{href:!0});var uva=s(wie);uEt=r(uva,"FlaxXLMRobertaForMultipleChoice"),uva.forEach(t),pEt=r(too," (XLM-RoBERTa model)"),too.forEach(t),yo.forEach(t),_Et=i(rd),T(xy.$$.fragment,rd),rd.forEach(t),od.forEach(t),_to=i(m),Tf=n(m,"H2",{class:!0});var Pno=s(Tf);$y=n(Pno,"A",{id:!0,class:!0,href:!0});var pva=s($y);WSe=n(pva,"SPAN",{});var _va=s(WSe);T(VP.$$.fragment,_va),_va.forEach(t),pva.forEach(t),bEt=i(Pno),USe=n(Pno,"SPAN",{});var bva=s(USe);vEt=r(bva,"FlaxAutoModelForNextSentencePrediction"),bva.forEach(t),Pno.forEach(t),bto=i(m),Rr=n(m,"DIV",{class:!0});var td=s(Rr);T(XP.$$.fragment,td),FEt=i(td),Mf=n(td,"P",{});var jce=s(Mf);TEt=r(jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Aie=n(jce,"A",{href:!0});var vva=s(Aie);MEt=r(vva,"from_pretrained()"),vva.forEach(t),EEt=r(jce," class method or the "),Lie=n(jce,"A",{href:!0});var Fva=s(Lie);CEt=r(Fva,"from_config()"),Fva.forEach(t),wEt=r(jce,` class
method.`),jce.forEach(t),AEt=i(td),zP=n(td,"P",{});var Bno=s(zP);LEt=r(Bno,"This class cannot be instantiated directly using "),HSe=n(Bno,"CODE",{});var Tva=s(HSe);yEt=r(Tva,"__init__()"),Tva.forEach(t),xEt=r(Bno," (throws an error)."),Bno.forEach(t),$Et=i(td),ba=n(td,"DIV",{class:!0});var px=s(ba);T(QP.$$.fragment,px),kEt=i(px),JSe=n(px,"P",{});var Mva=s(JSe);SEt=r(Mva,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Mva.forEach(t),REt=i(px),Ef=n(px,"P",{});var Dce=s(Ef);PEt=r(Dce,`Note:
Loading a model from its configuration file does `),YSe=n(Dce,"STRONG",{});var Eva=s(YSe);BEt=r(Eva,"not"),Eva.forEach(t),IEt=r(Dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),yie=n(Dce,"A",{href:!0});var Cva=s(yie);NEt=r(Cva,"from_pretrained()"),Cva.forEach(t),qEt=r(Dce," to load the model weights."),Dce.forEach(t),jEt=i(px),T(ky.$$.fragment,px),px.forEach(t),DEt=i(td),dt=n(td,"DIV",{class:!0});var ad=s(dt);T(WP.$$.fragment,ad),GEt=i(ad),ZSe=n(ad,"P",{});var wva=s(ZSe);OEt=r(wva,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),wva.forEach(t),VEt=i(ad),os=n(ad,"P",{});var _x=s(os);XEt=r(_x,"The model class to instantiate is selected based on the "),KSe=n(_x,"CODE",{});var Ava=s(KSe);zEt=r(Ava,"model_type"),Ava.forEach(t),QEt=r(_x,` property of the config object (either
passed as an argument or loaded from `),eRe=n(_x,"CODE",{});var Lva=s(eRe);WEt=r(Lva,"pretrained_model_name_or_path"),Lva.forEach(t),UEt=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oRe=n(_x,"CODE",{});var yva=s(oRe);HEt=r(yva,"pretrained_model_name_or_path"),yva.forEach(t),JEt=r(_x,":"),_x.forEach(t),YEt=i(ad),rRe=n(ad,"UL",{});var xva=s(rRe);Sy=n(xva,"LI",{});var aoo=s(Sy);tRe=n(aoo,"STRONG",{});var $va=s(tRe);ZEt=r($va,"bert"),$va.forEach(t),KEt=r(aoo," \u2014 "),xie=n(aoo,"A",{href:!0});var kva=s(xie);e4t=r(kva,"FlaxBertForNextSentencePrediction"),kva.forEach(t),o4t=r(aoo," (BERT model)"),aoo.forEach(t),xva.forEach(t),r4t=i(ad),T(Ry.$$.fragment,ad),ad.forEach(t),td.forEach(t),vto=i(m),Cf=n(m,"H2",{class:!0});var Ino=s(Cf);Py=n(Ino,"A",{id:!0,class:!0,href:!0});var Sva=s(Py);aRe=n(Sva,"SPAN",{});var Rva=s(aRe);T(UP.$$.fragment,Rva),Rva.forEach(t),Sva.forEach(t),t4t=i(Ino),nRe=n(Ino,"SPAN",{});var Pva=s(nRe);a4t=r(Pva,"FlaxAutoModelForImageClassification"),Pva.forEach(t),Ino.forEach(t),Fto=i(m),Pr=n(m,"DIV",{class:!0});var nd=s(Pr);T(HP.$$.fragment,nd),n4t=i(nd),wf=n(nd,"P",{});var Gce=s(wf);s4t=r(Gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),$ie=n(Gce,"A",{href:!0});var Bva=s($ie);l4t=r(Bva,"from_pretrained()"),Bva.forEach(t),i4t=r(Gce," class method or the "),kie=n(Gce,"A",{href:!0});var Iva=s(kie);d4t=r(Iva,"from_config()"),Iva.forEach(t),c4t=r(Gce,` class
method.`),Gce.forEach(t),m4t=i(nd),JP=n(nd,"P",{});var Nno=s(JP);f4t=r(Nno,"This class cannot be instantiated directly using "),sRe=n(Nno,"CODE",{});var Nva=s(sRe);g4t=r(Nva,"__init__()"),Nva.forEach(t),h4t=r(Nno," (throws an error)."),Nno.forEach(t),u4t=i(nd),va=n(nd,"DIV",{class:!0});var bx=s(va);T(YP.$$.fragment,bx),p4t=i(bx),lRe=n(bx,"P",{});var qva=s(lRe);_4t=r(qva,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qva.forEach(t),b4t=i(bx),Af=n(bx,"P",{});var Oce=s(Af);v4t=r(Oce,`Note:
Loading a model from its configuration file does `),iRe=n(Oce,"STRONG",{});var jva=s(iRe);F4t=r(jva,"not"),jva.forEach(t),T4t=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sie=n(Oce,"A",{href:!0});var Dva=s(Sie);M4t=r(Dva,"from_pretrained()"),Dva.forEach(t),E4t=r(Oce," to load the model weights."),Oce.forEach(t),C4t=i(bx),T(By.$$.fragment,bx),bx.forEach(t),w4t=i(nd),ct=n(nd,"DIV",{class:!0});var sd=s(ct);T(ZP.$$.fragment,sd),A4t=i(sd),dRe=n(sd,"P",{});var Gva=s(dRe);L4t=r(Gva,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Gva.forEach(t),y4t=i(sd),rs=n(sd,"P",{});var vx=s(rs);x4t=r(vx,"The model class to instantiate is selected based on the "),cRe=n(vx,"CODE",{});var Ova=s(cRe);$4t=r(Ova,"model_type"),Ova.forEach(t),k4t=r(vx,` property of the config object (either
passed as an argument or loaded from `),mRe=n(vx,"CODE",{});var Vva=s(mRe);S4t=r(Vva,"pretrained_model_name_or_path"),Vva.forEach(t),R4t=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fRe=n(vx,"CODE",{});var Xva=s(fRe);P4t=r(Xva,"pretrained_model_name_or_path"),Xva.forEach(t),B4t=r(vx,":"),vx.forEach(t),I4t=i(sd),KP=n(sd,"UL",{});var qno=s(KP);Iy=n(qno,"LI",{});var noo=s(Iy);gRe=n(noo,"STRONG",{});var zva=s(gRe);N4t=r(zva,"beit"),zva.forEach(t),q4t=r(noo," \u2014 "),Rie=n(noo,"A",{href:!0});var Qva=s(Rie);j4t=r(Qva,"FlaxBeitForImageClassification"),Qva.forEach(t),D4t=r(noo," (BEiT model)"),noo.forEach(t),G4t=i(qno),Ny=n(qno,"LI",{});var soo=s(Ny);hRe=n(soo,"STRONG",{});var Wva=s(hRe);O4t=r(Wva,"vit"),Wva.forEach(t),V4t=r(soo," \u2014 "),Pie=n(soo,"A",{href:!0});var Uva=s(Pie);X4t=r(Uva,"FlaxViTForImageClassification"),Uva.forEach(t),z4t=r(soo," (ViT model)"),soo.forEach(t),qno.forEach(t),Q4t=i(sd),T(qy.$$.fragment,sd),sd.forEach(t),nd.forEach(t),Tto=i(m),Lf=n(m,"H2",{class:!0});var jno=s(Lf);jy=n(jno,"A",{id:!0,class:!0,href:!0});var Hva=s(jy);uRe=n(Hva,"SPAN",{});var Jva=s(uRe);T(eB.$$.fragment,Jva),Jva.forEach(t),Hva.forEach(t),W4t=i(jno),pRe=n(jno,"SPAN",{});var Yva=s(pRe);U4t=r(Yva,"FlaxAutoModelForVision2Seq"),Yva.forEach(t),jno.forEach(t),Mto=i(m),Br=n(m,"DIV",{class:!0});var ld=s(Br);T(oB.$$.fragment,ld),H4t=i(ld),yf=n(ld,"P",{});var Vce=s(yf);J4t=r(Vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Bie=n(Vce,"A",{href:!0});var Zva=s(Bie);Y4t=r(Zva,"from_pretrained()"),Zva.forEach(t),Z4t=r(Vce," class method or the "),Iie=n(Vce,"A",{href:!0});var Kva=s(Iie);K4t=r(Kva,"from_config()"),Kva.forEach(t),eCt=r(Vce,` class
method.`),Vce.forEach(t),oCt=i(ld),rB=n(ld,"P",{});var Dno=s(rB);rCt=r(Dno,"This class cannot be instantiated directly using "),_Re=n(Dno,"CODE",{});var eFa=s(_Re);tCt=r(eFa,"__init__()"),eFa.forEach(t),aCt=r(Dno," (throws an error)."),Dno.forEach(t),nCt=i(ld),Fa=n(ld,"DIV",{class:!0});var Fx=s(Fa);T(tB.$$.fragment,Fx),sCt=i(Fx),bRe=n(Fx,"P",{});var oFa=s(bRe);lCt=r(oFa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),oFa.forEach(t),iCt=i(Fx),xf=n(Fx,"P",{});var Xce=s(xf);dCt=r(Xce,`Note:
Loading a model from its configuration file does `),vRe=n(Xce,"STRONG",{});var rFa=s(vRe);cCt=r(rFa,"not"),rFa.forEach(t),mCt=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=n(Xce,"A",{href:!0});var tFa=s(Nie);fCt=r(tFa,"from_pretrained()"),tFa.forEach(t),gCt=r(Xce," to load the model weights."),Xce.forEach(t),hCt=i(Fx),T(Dy.$$.fragment,Fx),Fx.forEach(t),uCt=i(ld),mt=n(ld,"DIV",{class:!0});var id=s(mt);T(aB.$$.fragment,id),pCt=i(id),FRe=n(id,"P",{});var aFa=s(FRe);_Ct=r(aFa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),aFa.forEach(t),bCt=i(id),ts=n(id,"P",{});var Tx=s(ts);vCt=r(Tx,"The model class to instantiate is selected based on the "),TRe=n(Tx,"CODE",{});var nFa=s(TRe);FCt=r(nFa,"model_type"),nFa.forEach(t),TCt=r(Tx,` property of the config object (either
passed as an argument or loaded from `),MRe=n(Tx,"CODE",{});var sFa=s(MRe);MCt=r(sFa,"pretrained_model_name_or_path"),sFa.forEach(t),ECt=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ERe=n(Tx,"CODE",{});var lFa=s(ERe);CCt=r(lFa,"pretrained_model_name_or_path"),lFa.forEach(t),wCt=r(Tx,":"),Tx.forEach(t),ACt=i(id),CRe=n(id,"UL",{});var iFa=s(CRe);Gy=n(iFa,"LI",{});var loo=s(Gy);wRe=n(loo,"STRONG",{});var dFa=s(wRe);LCt=r(dFa,"vision-encoder-decoder"),dFa.forEach(t),yCt=r(loo," \u2014 "),qie=n(loo,"A",{href:!0});var cFa=s(qie);xCt=r(cFa,"FlaxVisionEncoderDecoderModel"),cFa.forEach(t),$Ct=r(loo," (Vision Encoder decoder model)"),loo.forEach(t),iFa.forEach(t),kCt=i(id),T(Oy.$$.fragment,id),id.forEach(t),ld.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(AMa)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(ns,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(ls,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(is,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(ud,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(Nf,"id","extending-the-auto-classes"),c(Nf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nf,"href","#extending-the-auto-classes"),c(pd,"class","relative group"),c(jf,"id","transformers.AutoConfig"),c(jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jf,"href","#transformers.AutoConfig"),c(_d,"class","relative group"),c(II,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(NI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(qI,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(jI,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(DI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(GI,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(OI,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(VI,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(XI,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(zI,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(QI,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(WI,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c(UI,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(HI,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(JI,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),c(YI,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),c(ZI,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(KI,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(eN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(oN,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(rN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(tN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(aN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(nN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c(sN,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(lN,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(iN,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(dN,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(cN,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(mN,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c(fN,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),c(gN,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(hN,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(uN,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(pN,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(_N,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),c(bN,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),c(vN,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(FN,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(TN,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(MN,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(EN,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(CN,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c(wN,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(AN,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(LN,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(yN,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),c(xN,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c($N,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),c(kN,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(SN,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(RN,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(PN,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(BN,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(IN,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(NN,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(qN,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(jN,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c(DN,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(GN,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(ON,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(VN,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(XN,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(zN,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),c(QN,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(WN,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(UN,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(HN,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(JN,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(YN,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(ZN,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(KN,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(eq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),c(oq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(rq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(tq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(aq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(nq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),c(sq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(lq,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(iq,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(dq,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(cq,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(mq,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(fq,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(gq,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(hq,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(uq,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(pq,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c(_q,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(bq,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(vq,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(Fq,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(Tq,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(Mq,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(Eq,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(Cq,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c(wq,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(Aq,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(Lq,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(yq,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(xq,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c($q,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(kq,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),c(Sq,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(Rq,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(Pq,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),c(Bq,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(Iq,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(Nq,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(qq,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(jq,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(Dq,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(Gq,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),c(Oq,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(Vq,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(Xq,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(zq,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(Qq,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c(Wq,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(Uq,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),c(Hq,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(Jq,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(Yq,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(Zq,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),c(Kq,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),c(ej,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(oj,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(rj,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(tj,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(aj,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(nj,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(sj,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(lj,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gu,"id","transformers.AutoTokenizer"),c(gu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gu,"href","#transformers.AutoTokenizer"),c(vd,"class","relative group"),c(ij,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(dj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(cj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(mj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(fj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(gj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(hj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(uj,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(pj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(_j,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(bj,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(vj,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(Fj,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(Tj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(Mj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(Ej,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(Cj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(wj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(Aj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(Lj,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(yj,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(xj,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c($j,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(kj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(Sj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(Rj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(Pj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Bj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Ij,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(Nj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(qj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(jj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(Dj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(Gj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(Oj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Vj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Xj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(zj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(Qj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(Wj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(Uj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Hj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(Jj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(Yj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(Zj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(Kj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(eD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(oD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(rD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(tD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(aD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(nD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(sD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(lD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(iD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(dD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(cD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(fD,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(gD,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),c(hD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(uD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(pD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(_D,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(bD,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(vD,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(FD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(ED,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(CD,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(wD,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(AD,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(LD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(yD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(xD,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c($D,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(kD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(SD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(RD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(PD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(BD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(ID,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(ND,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(qD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(jD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(DD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(GD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(OD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(VD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(XD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(zD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(QD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(WD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(UD,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(HD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(JD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(YD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(ZD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(KD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(eG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(oG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),c(rG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(tG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(aG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(nG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),c(sG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(lG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(iG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(dG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(cG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(mG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(fG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(gG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(hG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(uG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(pG,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(_G,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(bG,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(vG,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(FG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(TG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(MG,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(EG,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(CG,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c(wG,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(AG,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(LG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(yG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(xG,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c($G,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(kG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(SG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(RG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(PG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(BG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(IG,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(NG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(qG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(jG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(DG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(GG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(OG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(VG,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(XG,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c(zG,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(QG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(WG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(UG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(HG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(JG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(YG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ZG,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(KG,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),c(eO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(oO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(rO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(tO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(aO,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(nO,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(sO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(lO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(iO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(dO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(cO,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(mO,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(fO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(gO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ju,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yu,"id","transformers.AutoFeatureExtractor"),c(Yu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yu,"href","#transformers.AutoFeatureExtractor"),c(Fd,"class","relative group"),c(hO,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(uO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(pO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(_O,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),c(bO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(vO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(FO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(TO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(MO,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),c(EO,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(CO,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(wO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(AO,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(LO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(yO,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(xO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c($O,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(kO,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(SO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(RO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(PO,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(BO,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(IO,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(NO,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(qO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(jO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(DO,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(GO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(OO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(VO,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(XO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(zO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(QO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(WO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(UO,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(HO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(JO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(YO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(ZO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(KO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(eV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(oV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),c(rV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(tV,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xp,"id","transformers.AutoProcessor"),c(Xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xp,"href","#transformers.AutoProcessor"),c(Td,"class","relative group"),c(aV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(nV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(sV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),c(lV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),c(iV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(dV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(cV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(mV,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(fV,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),c(gV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(hV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(uV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(pV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(_V,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(bV,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(vV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(FV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(TV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(MV,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(EV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(CV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(wV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(AV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),c(LV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(__,"id","transformers.AutoModel"),c(__,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(__,"href","#transformers.AutoModel"),c(Ed,"class","relative group"),c(yV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($V,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(SV,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(RV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(PV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(BV,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(IV,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(NV,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(qV,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(jV,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(DV,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(GV,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(OV,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(VV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(XV,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),c(zV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),c(QV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c(WV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(UV,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(HV,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(JV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(YV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(ZV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(KV,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(eX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(oX,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(rX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),c(tX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(aX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(nX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c(sX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),c(lX,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(iX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(dX,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(cX,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),c(mX,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),c(fX,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(gX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(hX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(uX,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(pX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(_X,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(bX,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c(vX,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(FX,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(TX,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(MX,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),c(EX,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(CX,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),c(wX,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(AX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(LX,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(yX,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(xX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c($X,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(kX,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(SX,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(RX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(PX,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(BX,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(IX,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(NX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(qX,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(jX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),c(DX,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(GX,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(OX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(VX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(XX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(zX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),c(QX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(WX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(UX,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),c(HX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c(JX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(YX,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(ZX,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(KX,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(ez,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),c(oz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(rz,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),c(tz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(az,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(nz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(sz,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(lz,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(iz,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(dz,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(cz,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(mz,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(fz,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(gz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(hz,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(uz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(pz,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c(_z,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(bz,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(vz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(Fz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Tz,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(Mz,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),c(Ez,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(Cz,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c(wz,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),c(Az,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(Lz,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(yz,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(xz,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c($z,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(kz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),c(Sz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(Rz,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Pz,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Bz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(Iz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Nz,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),c(qz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(jz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Dz,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(Gz,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),c(Oz,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),c(Vz,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c(Xz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(zz,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Qz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Wz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Uz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(Hz,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(Jz,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jb,"id","transformers.AutoModelForPreTraining"),c(jb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jb,"href","#transformers.AutoModelForPreTraining"),c(Ad,"class","relative group"),c(Yz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(oQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(rQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(tQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(aQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(nQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(sQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(lQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(iQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(dQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(cQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(mQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(fQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(gQ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(hQ,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(uQ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(pQ,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(_Q,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(bQ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(vQ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(FQ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(TQ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(MQ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(EQ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(CQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(wQ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(AQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(LQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(yQ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(xQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c($Q,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(kQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(SQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(RQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(PQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(BQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(IQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(NQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(qQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(jQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(DQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(GQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(OQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(VQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(XQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(zQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(QQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(WQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N2,"id","transformers.AutoModelForCausalLM"),c(N2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N2,"href","#transformers.AutoModelForCausalLM"),c(xd,"class","relative group"),c(UQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(ZQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c(KQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(eW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(oW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(rW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(tW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(aW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(nW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(sW,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(lW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(iW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(dW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(cW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(mW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(fW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(gW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(hW,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),c(uW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(pW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(_W,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(vW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),c(FW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(TW,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(MW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(EW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(CW,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(wW,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(AW,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(LW,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(yW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(xW,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c($W,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(kW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(SW,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(RW,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(PW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(BW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(IW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(NW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(qW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xv,"id","transformers.AutoModelForMaskedLM"),c(xv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xv,"href","#transformers.AutoModelForMaskedLM"),c(Sd,"class","relative group"),c(jW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(VW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(XW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(zW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(QW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(WW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(UW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(HW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(JW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(YW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(ZW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(KW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(eU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(oU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(rU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(tU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(aU,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(nU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(sU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(lU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(iU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(dU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(cU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(mU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(fU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(gU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(hU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(uU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(pU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(_U,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(bU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(vU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(FU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(TU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(MU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(EU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(CU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(wU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bF,"id","transformers.AutoModelForSeq2SeqLM"),c(bF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bF,"href","#transformers.AutoModelForSeq2SeqLM"),c(Bd,"class","relative group"),c(AU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c($U,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(kU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(SU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(RU,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(PU,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(BU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(IU,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(NU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(qU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c(jU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(DU,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(GU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(OU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(VU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(XU,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(zU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(QU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(WU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(UU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OF,"id","transformers.AutoModelForSequenceClassification"),c(OF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OF,"href","#transformers.AutoModelForSequenceClassification"),c(qd,"class","relative group"),c(HU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(KU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c(eH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(oH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(rH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(tH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(aH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(nH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(sH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(lH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(iH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(dH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(cH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(mH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(fH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(gH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(hH,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),c(uH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(pH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(_H,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(bH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(vH,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(FH,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(TH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(MH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(EH,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(CH,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(wH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(AH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(LH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(yH,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),c(xH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c($H,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(kH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(SH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(RH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(PH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(BH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(IH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(NH,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(qH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(jH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(DH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(GH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(OH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(VH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(XH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(zH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(QH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(WH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(UH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(HH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(JH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(YH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(ZH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WT,"id","transformers.AutoModelForMultipleChoice"),c(WT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WT,"href","#transformers.AutoModelForMultipleChoice"),c(Gd,"class","relative group"),c(KH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(tJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(aJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(nJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(sJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(lJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(iJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(dJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(cJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(mJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(fJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(gJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(hJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(uJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(pJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(_J,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(bJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(vJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(FJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(TJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(MJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(EJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(CJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(wJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(AJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(LJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(yJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(xJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c($J,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(kJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(SJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(RJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xM,"id","transformers.AutoModelForNextSentencePrediction"),c(xM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xM,"href","#transformers.AutoModelForNextSentencePrediction"),c(Xd,"class","relative group"),c(PJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(qJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(jJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(DJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(GJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(OJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(VJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DM,"id","transformers.AutoModelForTokenClassification"),c(DM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DM,"href","#transformers.AutoModelForTokenClassification"),c(Wd,"class","relative group"),c(XJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(UJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(HJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(JJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(YJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(ZJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(KJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(eY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(oY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(rY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(tY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(aY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(nY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(sY,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),c(lY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(iY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(dY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(cY,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(mY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(fY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(gY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(hY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(uY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(pY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),c(_Y,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),c(bY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(vY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(FY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(TY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(MY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(EY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(CY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(wY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(AY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(LY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(yY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(xY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c($Y,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(kY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(SY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($E,"id","transformers.AutoModelForQuestionAnswering"),c($E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($E,"href","#transformers.AutoModelForQuestionAnswering"),c(Jd,"class","relative group"),c(RY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(NY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(qY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(jY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(DY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(GY,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),c(OY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(VY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(XY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(zY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(QY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(WY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(UY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(HY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(JY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(YY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(ZY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(KY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(eZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(oZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(rZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(tZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(aZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(nZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(sZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(lZ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(iZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),c(dZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(cZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(mZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(fZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(gZ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(hZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(uZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(pZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),c(_Z,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(bZ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(vZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(FZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(TZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(MZ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(EZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(CZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(wZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(AZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(LZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(yZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L4,"id","transformers.AutoModelForTableQuestionAnswering"),c(L4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L4,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Kd,"class","relative group"),c(xZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($Z,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SZ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S4,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(S4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S4,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(rc,"class","relative group"),c(RZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(NZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(qZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j4,"id","transformers.AutoModelForImageClassification"),c(j4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j4,"href","#transformers.AutoModelForImageClassification"),c(sc,"class","relative group"),c(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OZ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(VZ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(XZ,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(zZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(QZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(WZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(UZ,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(HZ,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(JZ,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(YZ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(ZZ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(KZ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(eK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(oK,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(rK,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(tK,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(aK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(nK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(sK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(lK,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(iK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(dK,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aC,"id","transformers.AutoModelForVideoClassification"),c(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aC,"href","#transformers.AutoModelForVideoClassification"),c(dc,"class","relative group"),c(cK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gK,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dC,"id","transformers.AutoModelForVision2Seq"),c(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dC,"href","#transformers.AutoModelForVision2Seq"),c(fc,"class","relative group"),c(hK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_K,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hC,"id","transformers.AutoModelForVisualQuestionAnswering"),c(hC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hC,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(uc,"class","relative group"),c(bK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TK,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vC,"id","transformers.AutoModelForAudioClassification"),c(vC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vC,"href","#transformers.AutoModelForAudioClassification"),c(bc,"class","relative group"),c(MK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(AK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(LK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(yK,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(xK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c($K,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(kK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(SK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(RK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SC,"id","transformers.AutoModelForAudioFrameClassification"),c(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SC,"href","#transformers.AutoModelForAudioFrameClassification"),c(Tc,"class","relative group"),c(PK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(qK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(jK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(DK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(GK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GC,"id","transformers.AutoModelForCTC"),c(GC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GC,"href","#transformers.AutoModelForCTC"),c(Cc,"class","relative group"),c(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(QK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(WK,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(UK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(HK,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(JK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(YK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(ZK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(KK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(eee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o3,"id","transformers.AutoModelForSpeechSeq2Seq"),c(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o3,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Lc,"class","relative group"),c(oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aee,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(nee,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(see,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i3,"id","transformers.AutoModelForAudioXVector"),c(i3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i3,"href","#transformers.AutoModelForAudioXVector"),c(kc,"class","relative group"),c(lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(mee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(fee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(gee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(hee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_3,"id","transformers.AutoModelForMaskedImageModeling"),c(_3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_3,"href","#transformers.AutoModelForMaskedImageModeling"),c(Pc,"class","relative group"),c(uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(vee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(Fee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(Tee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w3,"id","transformers.AutoModelForObjectDetection"),c(w3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w3,"href","#transformers.AutoModelForObjectDetection"),c(Nc,"class","relative group"),c(Mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wee,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),c(Aee,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),c(Lee,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(yee,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R3,"id","transformers.AutoModelForImageSegmentation"),c(R3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R3,"href","#transformers.AutoModelForImageSegmentation"),c(Dc,"class","relative group"),c(xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(See,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q3,"id","transformers.AutoModelForSemanticSegmentation"),c(q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q3,"href","#transformers.AutoModelForSemanticSegmentation"),c(Vc,"class","relative group"),c(Ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iee,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(Nee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(qee,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(jee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(Dee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W3,"id","transformers.AutoModelForInstanceSegmentation"),c(W3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W3,"href","#transformers.AutoModelForInstanceSegmentation"),c(Qc,"class","relative group"),c(Gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xee,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z3,"id","transformers.AutoModelForZeroShotObjectDetection"),c(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z3,"href","#transformers.AutoModelForZeroShotObjectDetection"),c(Hc,"class","relative group"),c(zee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uee,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t5,"id","transformers.TFAutoModel"),c(t5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t5,"href","#transformers.TFAutoModel"),c(Zc,"class","relative group"),c(Hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zee,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(Kee,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(eoe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(ooe,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(roe,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(toe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(aoe,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(noe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(soe,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(loe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(ioe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(doe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(coe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(moe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),c(foe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(goe,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(hoe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(uoe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(poe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(_oe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(boe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(voe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(Foe,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),c(Toe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(Moe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(Eoe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(Coe,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(woe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c(Aoe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Loe,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(yoe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(xoe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c($oe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(koe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(Soe,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(Roe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Poe,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c(Boe,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(Ioe,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),c(Noe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(qoe,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),c(joe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(Doe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(Goe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),c(Ooe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(Voe,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(Xoe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(zoe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(Qoe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(Woe,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(Uoe,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(Hoe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(Joe,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),c(Yoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(Zoe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(Koe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s0,"id","transformers.TFAutoModelForPreTraining"),c(s0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s0,"href","#transformers.TFAutoModelForPreTraining"),c(om,"class","relative group"),c(ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(are,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(nre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(sre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(lre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(ire,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(dre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(cre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(mre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(fre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(gre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(hre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(ure,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(pre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(_re,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(bre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(vre,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Fre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Tre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Mre,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(Ere,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Cre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(wre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S0,"id","transformers.TFAutoModelForCausalLM"),c(S0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S0,"href","#transformers.TFAutoModelForCausalLM"),c(am,"class","relative group"),c(Are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c($re,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(kre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(Sre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Rre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Pre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Bre,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Ire,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Nre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(qre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(jre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Dre,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Gre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Ore,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H0,"id","transformers.TFAutoModelForImageClassification"),c(H0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H0,"href","#transformers.TFAutoModelForImageClassification"),c(lm,"class","relative group"),c(Vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(Wre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(Ure,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(Hre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(Jre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(Yre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(Zre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(Kre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(ete,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(ote,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sw,"id","transformers.TFAutoModelForSemanticSegmentation"),c(sw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sw,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(cm,"class","relative group"),c(rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(ste,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(lte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fw,"id","transformers.TFAutoModelForMaskedLM"),c(fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fw,"href","#transformers.TFAutoModelForMaskedLM"),c(hm,"class","relative group"),c(ite,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(fte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(gte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(ute,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(pte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(_te,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(bte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(vte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Fte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(Tte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Mte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(Ete,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(Cte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(wte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Ate,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Lte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(yte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(xte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c($te,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bw,"id","transformers.TFAutoModelForSeq2SeqLM"),c(Bw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bw,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(_m,"class","relative group"),c(kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pte,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Bte,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Ite,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Nte,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(qte,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(jte,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(Dte,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Gte,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Ote,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Vte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uw,"id","transformers.TFAutoModelForSequenceClassification"),c(Uw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uw,"href","#transformers.TFAutoModelForSequenceClassification"),c(Fm,"class","relative group"),c(Xte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(Ute,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(Hte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(Jte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(Yte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(Zte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(Kte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(eae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(oae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(rae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(tae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(aae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(nae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(sae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(lae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(iae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(dae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(cae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(mae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(fae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(gae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(hae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(uae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(pae,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(_ae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(bae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(vae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CA,"id","transformers.TFAutoModelForMultipleChoice"),c(CA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CA,"href","#transformers.TFAutoModelForMultipleChoice"),c(Em,"class","relative group"),c(Fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(Cae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(wae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Aae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Lae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(yae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(xae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c($ae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(kae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(Sae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Rae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Pae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Bae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Iae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Nae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(qae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(jae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XA,"id","transformers.TFAutoModelForNextSentencePrediction"),c(XA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XA,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Am,"class","relative group"),c(Dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Xae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HA,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(HA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(HA,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(xm,"class","relative group"),c(zae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(KA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Sm,"class","relative group"),c(Hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t6,"id","transformers.TFAutoModelForTokenClassification"),c(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t6,"href","#transformers.TFAutoModelForTokenClassification"),c(Bm,"class","relative group"),c(Kae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(one,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(tne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(ane,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(nne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(sne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(lne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(ine,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(dne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(cne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(mne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(fne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(gne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(hne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(une,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(pne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(_ne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(bne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(vne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Fne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(Tne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(Mne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L6,"id","transformers.TFAutoModelForQuestionAnswering"),c(L6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L6,"href","#transformers.TFAutoModelForQuestionAnswering"),c(qm,"class","relative group"),c(Ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ane,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Lne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(yne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(xne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c($ne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(kne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Sne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Rne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Pne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Bne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Ine,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Nne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(qne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(jne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Dne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(Gne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(One,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Vne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Xne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(zne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(Qne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y6,"id","transformers.TFAutoModelForVision2Seq"),c(Y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y6,"href","#transformers.TFAutoModelForVision2Seq"),c(Gm,"class","relative group"),c(Wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jne,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(o7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Xm,"class","relative group"),c(Yne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ese,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n7,"id","transformers.FlaxAutoModel"),c(n7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n7,"href","#transformers.FlaxAutoModel"),c(Wm,"class","relative group"),c(ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ase,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(nse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(sse,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(lse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(ise,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(dse,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(cse,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(mse,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(fse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(gse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(hse,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(use,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(pse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(_se,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(bse,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(vse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Fse,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c(Tse,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(Mse,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Ese,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Cse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(wse,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(Ase,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Lse,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(yse,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(xse,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c($se,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B7,"id","transformers.FlaxAutoModelForCausalLM"),c(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B7,"href","#transformers.FlaxAutoModelForCausalLM"),c(Jm,"class","relative group"),c(kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Bse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Ise,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Nse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(qse,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(jse,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Dse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Gse,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(Ose,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Vse,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U7,"id","transformers.FlaxAutoModelForPreTraining"),c(U7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U7,"href","#transformers.FlaxAutoModelForPreTraining"),c(Km,"class","relative group"),c(Xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(Use,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Hse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(Jse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(Yse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(Zse,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Kse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(ele,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ole,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(rle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(tle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(ale,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(nle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cL,"id","transformers.FlaxAutoModelForMaskedLM"),c(cL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cL,"href","#transformers.FlaxAutoModelForMaskedLM"),c(rf,"class","relative group"),c(sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ile,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(cle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(mle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(fle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(gle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(hle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(ule,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(ple,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(_le,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(ble,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(EL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(nf,"class","relative group"),c(vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Ele,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Cle,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(wle,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Ale,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Lle,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(yle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(xle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c($le,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(kle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IL,"id","transformers.FlaxAutoModelForSequenceClassification"),c(IL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IL,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(df,"class","relative group"),c(Sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ble,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Ile,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Nle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(qle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(jle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Dle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Gle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Ole,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Vle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Xle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HL,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(HL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(HL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(ff,"class","relative group"),c(zle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ule,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(Hle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(Jle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Yle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Zle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Kle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(eie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(oie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(rie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(tie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iy,"id","transformers.FlaxAutoModelForTokenClassification"),c(iy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iy,"href","#transformers.FlaxAutoModelForTokenClassification"),c(uf,"class","relative group"),c(aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(iie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(die,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(cie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(mie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(fie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(gie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(hie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vy,"id","transformers.FlaxAutoModelForMultipleChoice"),c(vy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vy,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(bf,"class","relative group"),c(uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(vie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Fie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Tie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Mie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Eie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Cie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(wie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($y,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c($y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($y,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Tf,"class","relative group"),c(Aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Py,"id","transformers.FlaxAutoModelForImageClassification"),c(Py,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Py,"href","#transformers.FlaxAutoModelForImageClassification"),c(Cf,"class","relative group"),c($ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rie,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Pie,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jy,"id","transformers.FlaxAutoModelForVision2Seq"),c(jy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jy,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Lf,"class","relative group"),c(Bie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qie,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,xo),e(xo,dd),b(m,Rf,_),b(m,bt,_),e(bt,cd),e(bt,md),e(md,Mx),e(bt,Pf),b(m,Ve,_),b(m,He,_),e(He,fd),e(He,ns),e(ns,Ex),e(He,ss),e(He,ls),e(ls,Cx),e(He,gd),e(He,is),e(is,wx),e(He,hd),b(m,Bf,_),M(Ja,m,_),b(m,Je,_),b(m,Ae,_),e(Ae,$I),e(Ae,ud),e(ud,kI),e(Ae,SI),b(m,$o,_),b(m,Ya,_),e(Ya,RI),e(Ya,If),e(If,PI),e(Ya,Gno),b(m,ioo,_),b(m,pd,_),e(pd,Nf),e(Nf,zce),M(Ax,zce,null),e(pd,Ono),e(pd,Qce),e(Qce,Vno),b(m,doo,_),b(m,ds,_),e(ds,Xno),e(ds,Wce),e(Wce,zno),e(ds,Qno),e(ds,Uce),e(Uce,Wno),e(ds,Uno),b(m,coo,_),M(Lx,m,_),b(m,moo,_),b(m,BI,_),e(BI,Hno),b(m,foo,_),M(qf,m,_),b(m,goo,_),b(m,_d,_),e(_d,jf),e(jf,Hce),M(yx,Hce,null),e(_d,Jno),e(_d,Jce),e(Jce,Yno),b(m,hoo,_),b(m,ko,_),M(xx,ko,null),e(ko,Zno),e(ko,$x),e($x,Kno),e($x,II),e(II,eso),e($x,oso),e(ko,rso),e(ko,kx),e(kx,tso),e(kx,Yce),e(Yce,aso),e(kx,nso),e(ko,sso),e(ko,Ir),M(Sx,Ir,null),e(Ir,lso),e(Ir,Zce),e(Zce,iso),e(Ir,dso),e(Ir,bd),e(bd,cso),e(bd,Kce),e(Kce,mso),e(bd,fso),e(bd,eme),e(eme,gso),e(bd,hso),e(Ir,uso),e(Ir,A),e(A,Df),e(Df,ome),e(ome,pso),e(Df,_so),e(Df,NI),e(NI,bso),e(Df,vso),e(A,Fso),e(A,Gf),e(Gf,rme),e(rme,Tso),e(Gf,Mso),e(Gf,qI),e(qI,Eso),e(Gf,Cso),e(A,wso),e(A,Of),e(Of,tme),e(tme,Aso),e(Of,Lso),e(Of,jI),e(jI,yso),e(Of,xso),e(A,$so),e(A,Vf),e(Vf,ame),e(ame,kso),e(Vf,Sso),e(Vf,DI),e(DI,Rso),e(Vf,Pso),e(A,Bso),e(A,Xf),e(Xf,nme),e(nme,Iso),e(Xf,Nso),e(Xf,GI),e(GI,qso),e(Xf,jso),e(A,Dso),e(A,zf),e(zf,sme),e(sme,Gso),e(zf,Oso),e(zf,OI),e(OI,Vso),e(zf,Xso),e(A,zso),e(A,Qf),e(Qf,lme),e(lme,Qso),e(Qf,Wso),e(Qf,VI),e(VI,Uso),e(Qf,Hso),e(A,Jso),e(A,Wf),e(Wf,ime),e(ime,Yso),e(Wf,Zso),e(Wf,XI),e(XI,Kso),e(Wf,elo),e(A,olo),e(A,Uf),e(Uf,dme),e(dme,rlo),e(Uf,tlo),e(Uf,zI),e(zI,alo),e(Uf,nlo),e(A,slo),e(A,Hf),e(Hf,cme),e(cme,llo),e(Hf,ilo),e(Hf,QI),e(QI,dlo),e(Hf,clo),e(A,mlo),e(A,Jf),e(Jf,mme),e(mme,flo),e(Jf,glo),e(Jf,WI),e(WI,hlo),e(Jf,ulo),e(A,plo),e(A,Yf),e(Yf,fme),e(fme,_lo),e(Yf,blo),e(Yf,UI),e(UI,vlo),e(Yf,Flo),e(A,Tlo),e(A,Zf),e(Zf,gme),e(gme,Mlo),e(Zf,Elo),e(Zf,HI),e(HI,Clo),e(Zf,wlo),e(A,Alo),e(A,Kf),e(Kf,hme),e(hme,Llo),e(Kf,ylo),e(Kf,JI),e(JI,xlo),e(Kf,$lo),e(A,klo),e(A,eg),e(eg,ume),e(ume,Slo),e(eg,Rlo),e(eg,YI),e(YI,Plo),e(eg,Blo),e(A,Ilo),e(A,og),e(og,pme),e(pme,Nlo),e(og,qlo),e(og,ZI),e(ZI,jlo),e(og,Dlo),e(A,Glo),e(A,rg),e(rg,_me),e(_me,Olo),e(rg,Vlo),e(rg,KI),e(KI,Xlo),e(rg,zlo),e(A,Qlo),e(A,tg),e(tg,bme),e(bme,Wlo),e(tg,Ulo),e(tg,eN),e(eN,Hlo),e(tg,Jlo),e(A,Ylo),e(A,ag),e(ag,vme),e(vme,Zlo),e(ag,Klo),e(ag,oN),e(oN,eio),e(ag,oio),e(A,rio),e(A,ng),e(ng,Fme),e(Fme,tio),e(ng,aio),e(ng,rN),e(rN,nio),e(ng,sio),e(A,lio),e(A,sg),e(sg,Tme),e(Tme,iio),e(sg,dio),e(sg,tN),e(tN,cio),e(sg,mio),e(A,fio),e(A,lg),e(lg,Mme),e(Mme,gio),e(lg,hio),e(lg,aN),e(aN,uio),e(lg,pio),e(A,_io),e(A,ig),e(ig,Eme),e(Eme,bio),e(ig,vio),e(ig,nN),e(nN,Fio),e(ig,Tio),e(A,Mio),e(A,dg),e(dg,Cme),e(Cme,Eio),e(dg,Cio),e(dg,sN),e(sN,wio),e(dg,Aio),e(A,Lio),e(A,cg),e(cg,wme),e(wme,yio),e(cg,xio),e(cg,lN),e(lN,$io),e(cg,kio),e(A,Sio),e(A,mg),e(mg,Ame),e(Ame,Rio),e(mg,Pio),e(mg,iN),e(iN,Bio),e(mg,Iio),e(A,Nio),e(A,fg),e(fg,Lme),e(Lme,qio),e(fg,jio),e(fg,dN),e(dN,Dio),e(fg,Gio),e(A,Oio),e(A,gg),e(gg,yme),e(yme,Vio),e(gg,Xio),e(gg,cN),e(cN,zio),e(gg,Qio),e(A,Wio),e(A,hg),e(hg,xme),e(xme,Uio),e(hg,Hio),e(hg,mN),e(mN,Jio),e(hg,Yio),e(A,Zio),e(A,ug),e(ug,$me),e($me,Kio),e(ug,edo),e(ug,fN),e(fN,odo),e(ug,rdo),e(A,tdo),e(A,pg),e(pg,kme),e(kme,ado),e(pg,ndo),e(pg,gN),e(gN,sdo),e(pg,ldo),e(A,ido),e(A,_g),e(_g,Sme),e(Sme,ddo),e(_g,cdo),e(_g,hN),e(hN,mdo),e(_g,fdo),e(A,gdo),e(A,bg),e(bg,Rme),e(Rme,hdo),e(bg,udo),e(bg,uN),e(uN,pdo),e(bg,_do),e(A,bdo),e(A,vg),e(vg,Pme),e(Pme,vdo),e(vg,Fdo),e(vg,pN),e(pN,Tdo),e(vg,Mdo),e(A,Edo),e(A,Fg),e(Fg,Bme),e(Bme,Cdo),e(Fg,wdo),e(Fg,_N),e(_N,Ado),e(Fg,Ldo),e(A,ydo),e(A,Tg),e(Tg,Ime),e(Ime,xdo),e(Tg,$do),e(Tg,bN),e(bN,kdo),e(Tg,Sdo),e(A,Rdo),e(A,Mg),e(Mg,Nme),e(Nme,Pdo),e(Mg,Bdo),e(Mg,vN),e(vN,Ido),e(Mg,Ndo),e(A,qdo),e(A,Eg),e(Eg,qme),e(qme,jdo),e(Eg,Ddo),e(Eg,FN),e(FN,Gdo),e(Eg,Odo),e(A,Vdo),e(A,Cg),e(Cg,jme),e(jme,Xdo),e(Cg,zdo),e(Cg,TN),e(TN,Qdo),e(Cg,Wdo),e(A,Udo),e(A,wg),e(wg,Dme),e(Dme,Hdo),e(wg,Jdo),e(wg,MN),e(MN,Ydo),e(wg,Zdo),e(A,Kdo),e(A,Ag),e(Ag,Gme),e(Gme,eco),e(Ag,oco),e(Ag,EN),e(EN,rco),e(Ag,tco),e(A,aco),e(A,Lg),e(Lg,Ome),e(Ome,nco),e(Lg,sco),e(Lg,CN),e(CN,lco),e(Lg,ico),e(A,dco),e(A,yg),e(yg,Vme),e(Vme,cco),e(yg,mco),e(yg,wN),e(wN,fco),e(yg,gco),e(A,hco),e(A,xg),e(xg,Xme),e(Xme,uco),e(xg,pco),e(xg,AN),e(AN,_co),e(xg,bco),e(A,vco),e(A,$g),e($g,zme),e(zme,Fco),e($g,Tco),e($g,LN),e(LN,Mco),e($g,Eco),e(A,Cco),e(A,kg),e(kg,Qme),e(Qme,wco),e(kg,Aco),e(kg,yN),e(yN,Lco),e(kg,yco),e(A,xco),e(A,Sg),e(Sg,Wme),e(Wme,$co),e(Sg,kco),e(Sg,xN),e(xN,Sco),e(Sg,Rco),e(A,Pco),e(A,Rg),e(Rg,Ume),e(Ume,Bco),e(Rg,Ico),e(Rg,$N),e($N,Nco),e(Rg,qco),e(A,jco),e(A,Pg),e(Pg,Hme),e(Hme,Dco),e(Pg,Gco),e(Pg,kN),e(kN,Oco),e(Pg,Vco),e(A,Xco),e(A,Bg),e(Bg,Jme),e(Jme,zco),e(Bg,Qco),e(Bg,SN),e(SN,Wco),e(Bg,Uco),e(A,Hco),e(A,Ig),e(Ig,Yme),e(Yme,Jco),e(Ig,Yco),e(Ig,RN),e(RN,Zco),e(Ig,Kco),e(A,emo),e(A,Ng),e(Ng,Zme),e(Zme,omo),e(Ng,rmo),e(Ng,PN),e(PN,tmo),e(Ng,amo),e(A,nmo),e(A,qg),e(qg,Kme),e(Kme,smo),e(qg,lmo),e(qg,BN),e(BN,imo),e(qg,dmo),e(A,cmo),e(A,jg),e(jg,efe),e(efe,mmo),e(jg,fmo),e(jg,IN),e(IN,gmo),e(jg,hmo),e(A,umo),e(A,Dg),e(Dg,ofe),e(ofe,pmo),e(Dg,_mo),e(Dg,NN),e(NN,bmo),e(Dg,vmo),e(A,Fmo),e(A,Gg),e(Gg,rfe),e(rfe,Tmo),e(Gg,Mmo),e(Gg,qN),e(qN,Emo),e(Gg,Cmo),e(A,wmo),e(A,Og),e(Og,tfe),e(tfe,Amo),e(Og,Lmo),e(Og,jN),e(jN,ymo),e(Og,xmo),e(A,$mo),e(A,Vg),e(Vg,afe),e(afe,kmo),e(Vg,Smo),e(Vg,DN),e(DN,Rmo),e(Vg,Pmo),e(A,Bmo),e(A,Xg),e(Xg,nfe),e(nfe,Imo),e(Xg,Nmo),e(Xg,GN),e(GN,qmo),e(Xg,jmo),e(A,Dmo),e(A,zg),e(zg,sfe),e(sfe,Gmo),e(zg,Omo),e(zg,ON),e(ON,Vmo),e(zg,Xmo),e(A,zmo),e(A,Qg),e(Qg,lfe),e(lfe,Qmo),e(Qg,Wmo),e(Qg,VN),e(VN,Umo),e(Qg,Hmo),e(A,Jmo),e(A,Wg),e(Wg,ife),e(ife,Ymo),e(Wg,Zmo),e(Wg,XN),e(XN,Kmo),e(Wg,efo),e(A,ofo),e(A,Ug),e(Ug,dfe),e(dfe,rfo),e(Ug,tfo),e(Ug,zN),e(zN,afo),e(Ug,nfo),e(A,sfo),e(A,Hg),e(Hg,cfe),e(cfe,lfo),e(Hg,ifo),e(Hg,QN),e(QN,dfo),e(Hg,cfo),e(A,mfo),e(A,Jg),e(Jg,mfe),e(mfe,ffo),e(Jg,gfo),e(Jg,WN),e(WN,hfo),e(Jg,ufo),e(A,pfo),e(A,Yg),e(Yg,ffe),e(ffe,_fo),e(Yg,bfo),e(Yg,UN),e(UN,vfo),e(Yg,Ffo),e(A,Tfo),e(A,Zg),e(Zg,gfe),e(gfe,Mfo),e(Zg,Efo),e(Zg,HN),e(HN,Cfo),e(Zg,wfo),e(A,Afo),e(A,Kg),e(Kg,hfe),e(hfe,Lfo),e(Kg,yfo),e(Kg,JN),e(JN,xfo),e(Kg,$fo),e(A,kfo),e(A,eh),e(eh,ufe),e(ufe,Sfo),e(eh,Rfo),e(eh,YN),e(YN,Pfo),e(eh,Bfo),e(A,Ifo),e(A,oh),e(oh,pfe),e(pfe,Nfo),e(oh,qfo),e(oh,ZN),e(ZN,jfo),e(oh,Dfo),e(A,Gfo),e(A,rh),e(rh,_fe),e(_fe,Ofo),e(rh,Vfo),e(rh,KN),e(KN,Xfo),e(rh,zfo),e(A,Qfo),e(A,th),e(th,bfe),e(bfe,Wfo),e(th,Ufo),e(th,eq),e(eq,Hfo),e(th,Jfo),e(A,Yfo),e(A,ah),e(ah,vfe),e(vfe,Zfo),e(ah,Kfo),e(ah,oq),e(oq,ego),e(ah,ogo),e(A,rgo),e(A,nh),e(nh,Ffe),e(Ffe,tgo),e(nh,ago),e(nh,rq),e(rq,ngo),e(nh,sgo),e(A,lgo),e(A,sh),e(sh,Tfe),e(Tfe,igo),e(sh,dgo),e(sh,tq),e(tq,cgo),e(sh,mgo),e(A,fgo),e(A,lh),e(lh,Mfe),e(Mfe,ggo),e(lh,hgo),e(lh,aq),e(aq,ugo),e(lh,pgo),e(A,_go),e(A,ih),e(ih,Efe),e(Efe,bgo),e(ih,vgo),e(ih,nq),e(nq,Fgo),e(ih,Tgo),e(A,Mgo),e(A,dh),e(dh,Cfe),e(Cfe,Ego),e(dh,Cgo),e(dh,sq),e(sq,wgo),e(dh,Ago),e(A,Lgo),e(A,ch),e(ch,wfe),e(wfe,ygo),e(ch,xgo),e(ch,lq),e(lq,$go),e(ch,kgo),e(A,Sgo),e(A,mh),e(mh,Afe),e(Afe,Rgo),e(mh,Pgo),e(mh,iq),e(iq,Bgo),e(mh,Igo),e(A,Ngo),e(A,fh),e(fh,Lfe),e(Lfe,qgo),e(fh,jgo),e(fh,dq),e(dq,Dgo),e(fh,Ggo),e(A,Ogo),e(A,gh),e(gh,yfe),e(yfe,Vgo),e(gh,Xgo),e(gh,cq),e(cq,zgo),e(gh,Qgo),e(A,Wgo),e(A,hh),e(hh,xfe),e(xfe,Ugo),e(hh,Hgo),e(hh,mq),e(mq,Jgo),e(hh,Ygo),e(A,Zgo),e(A,uh),e(uh,$fe),e($fe,Kgo),e(uh,eho),e(uh,fq),e(fq,oho),e(uh,rho),e(A,tho),e(A,ph),e(ph,kfe),e(kfe,aho),e(ph,nho),e(ph,gq),e(gq,sho),e(ph,lho),e(A,iho),e(A,_h),e(_h,Sfe),e(Sfe,dho),e(_h,cho),e(_h,hq),e(hq,mho),e(_h,fho),e(A,gho),e(A,bh),e(bh,Rfe),e(Rfe,hho),e(bh,uho),e(bh,uq),e(uq,pho),e(bh,_ho),e(A,bho),e(A,vh),e(vh,Pfe),e(Pfe,vho),e(vh,Fho),e(vh,pq),e(pq,Tho),e(vh,Mho),e(A,Eho),e(A,Fh),e(Fh,Bfe),e(Bfe,Cho),e(Fh,who),e(Fh,_q),e(_q,Aho),e(Fh,Lho),e(A,yho),e(A,Th),e(Th,Ife),e(Ife,xho),e(Th,$ho),e(Th,bq),e(bq,kho),e(Th,Sho),e(A,Rho),e(A,Mh),e(Mh,Nfe),e(Nfe,Pho),e(Mh,Bho),e(Mh,vq),e(vq,Iho),e(Mh,Nho),e(A,qho),e(A,Eh),e(Eh,qfe),e(qfe,jho),e(Eh,Dho),e(Eh,Fq),e(Fq,Gho),e(Eh,Oho),e(A,Vho),e(A,Ch),e(Ch,jfe),e(jfe,Xho),e(Ch,zho),e(Ch,Tq),e(Tq,Qho),e(Ch,Who),e(A,Uho),e(A,wh),e(wh,Dfe),e(Dfe,Hho),e(wh,Jho),e(wh,Mq),e(Mq,Yho),e(wh,Zho),e(A,Kho),e(A,Ah),e(Ah,Gfe),e(Gfe,euo),e(Ah,ouo),e(Ah,Eq),e(Eq,ruo),e(Ah,tuo),e(A,auo),e(A,Lh),e(Lh,Ofe),e(Ofe,nuo),e(Lh,suo),e(Lh,Cq),e(Cq,luo),e(Lh,iuo),e(A,duo),e(A,yh),e(yh,Vfe),e(Vfe,cuo),e(yh,muo),e(yh,wq),e(wq,fuo),e(yh,guo),e(A,huo),e(A,xh),e(xh,Xfe),e(Xfe,uuo),e(xh,puo),e(xh,Aq),e(Aq,_uo),e(xh,buo),e(A,vuo),e(A,$h),e($h,zfe),e(zfe,Fuo),e($h,Tuo),e($h,Lq),e(Lq,Muo),e($h,Euo),e(A,Cuo),e(A,kh),e(kh,Qfe),e(Qfe,wuo),e(kh,Auo),e(kh,yq),e(yq,Luo),e(kh,yuo),e(A,xuo),e(A,Sh),e(Sh,Wfe),e(Wfe,$uo),e(Sh,kuo),e(Sh,xq),e(xq,Suo),e(Sh,Ruo),e(A,Puo),e(A,Rh),e(Rh,Ufe),e(Ufe,Buo),e(Rh,Iuo),e(Rh,$q),e($q,Nuo),e(Rh,quo),e(A,juo),e(A,Ph),e(Ph,Hfe),e(Hfe,Duo),e(Ph,Guo),e(Ph,kq),e(kq,Ouo),e(Ph,Vuo),e(A,Xuo),e(A,Bh),e(Bh,Jfe),e(Jfe,zuo),e(Bh,Quo),e(Bh,Sq),e(Sq,Wuo),e(Bh,Uuo),e(A,Huo),e(A,Ih),e(Ih,Yfe),e(Yfe,Juo),e(Ih,Yuo),e(Ih,Rq),e(Rq,Zuo),e(Ih,Kuo),e(A,epo),e(A,Nh),e(Nh,Zfe),e(Zfe,opo),e(Nh,rpo),e(Nh,Pq),e(Pq,tpo),e(Nh,apo),e(A,npo),e(A,qh),e(qh,Kfe),e(Kfe,spo),e(qh,lpo),e(qh,Bq),e(Bq,ipo),e(qh,dpo),e(A,cpo),e(A,jh),e(jh,ege),e(ege,mpo),e(jh,fpo),e(jh,Iq),e(Iq,gpo),e(jh,hpo),e(A,upo),e(A,Dh),e(Dh,oge),e(oge,ppo),e(Dh,_po),e(Dh,Nq),e(Nq,bpo),e(Dh,vpo),e(A,Fpo),e(A,Gh),e(Gh,rge),e(rge,Tpo),e(Gh,Mpo),e(Gh,qq),e(qq,Epo),e(Gh,Cpo),e(A,wpo),e(A,Oh),e(Oh,tge),e(tge,Apo),e(Oh,Lpo),e(Oh,jq),e(jq,ypo),e(Oh,xpo),e(A,$po),e(A,Vh),e(Vh,age),e(age,kpo),e(Vh,Spo),e(Vh,Dq),e(Dq,Rpo),e(Vh,Ppo),e(A,Bpo),e(A,Xh),e(Xh,nge),e(nge,Ipo),e(Xh,Npo),e(Xh,Gq),e(Gq,qpo),e(Xh,jpo),e(A,Dpo),e(A,zh),e(zh,sge),e(sge,Gpo),e(zh,Opo),e(zh,Oq),e(Oq,Vpo),e(zh,Xpo),e(A,zpo),e(A,Qh),e(Qh,lge),e(lge,Qpo),e(Qh,Wpo),e(Qh,Vq),e(Vq,Upo),e(Qh,Hpo),e(A,Jpo),e(A,Wh),e(Wh,ige),e(ige,Ypo),e(Wh,Zpo),e(Wh,Xq),e(Xq,Kpo),e(Wh,e_o),e(A,o_o),e(A,Uh),e(Uh,dge),e(dge,r_o),e(Uh,t_o),e(Uh,zq),e(zq,a_o),e(Uh,n_o),e(A,s_o),e(A,Hh),e(Hh,cge),e(cge,l_o),e(Hh,i_o),e(Hh,Qq),e(Qq,d_o),e(Hh,c_o),e(A,m_o),e(A,Jh),e(Jh,mge),e(mge,f_o),e(Jh,g_o),e(Jh,Wq),e(Wq,h_o),e(Jh,u_o),e(A,p_o),e(A,Yh),e(Yh,fge),e(fge,__o),e(Yh,b_o),e(Yh,Uq),e(Uq,v_o),e(Yh,F_o),e(A,T_o),e(A,Zh),e(Zh,gge),e(gge,M_o),e(Zh,E_o),e(Zh,Hq),e(Hq,C_o),e(Zh,w_o),e(A,A_o),e(A,Kh),e(Kh,hge),e(hge,L_o),e(Kh,y_o),e(Kh,Jq),e(Jq,x_o),e(Kh,$_o),e(A,k_o),e(A,eu),e(eu,uge),e(uge,S_o),e(eu,R_o),e(eu,Yq),e(Yq,P_o),e(eu,B_o),e(A,I_o),e(A,ou),e(ou,pge),e(pge,N_o),e(ou,q_o),e(ou,Zq),e(Zq,j_o),e(ou,D_o),e(A,G_o),e(A,ru),e(ru,_ge),e(_ge,O_o),e(ru,V_o),e(ru,Kq),e(Kq,X_o),e(ru,z_o),e(A,Q_o),e(A,tu),e(tu,bge),e(bge,W_o),e(tu,U_o),e(tu,ej),e(ej,H_o),e(tu,J_o),e(A,Y_o),e(A,au),e(au,vge),e(vge,Z_o),e(au,K_o),e(au,oj),e(oj,e1o),e(au,o1o),e(A,r1o),e(A,nu),e(nu,Fge),e(Fge,t1o),e(nu,a1o),e(nu,rj),e(rj,n1o),e(nu,s1o),e(A,l1o),e(A,su),e(su,Tge),e(Tge,i1o),e(su,d1o),e(su,tj),e(tj,c1o),e(su,m1o),e(A,f1o),e(A,lu),e(lu,Mge),e(Mge,g1o),e(lu,h1o),e(lu,aj),e(aj,u1o),e(lu,p1o),e(A,_1o),e(A,iu),e(iu,Ege),e(Ege,b1o),e(iu,v1o),e(iu,nj),e(nj,F1o),e(iu,T1o),e(A,M1o),e(A,du),e(du,Cge),e(Cge,E1o),e(du,C1o),e(du,sj),e(sj,w1o),e(du,A1o),e(A,L1o),e(A,cu),e(cu,wge),e(wge,y1o),e(cu,x1o),e(cu,lj),e(lj,$1o),e(cu,k1o),e(Ir,S1o),M(mu,Ir,null),e(ko,R1o),e(ko,fu),M(Rx,fu,null),e(fu,P1o),e(fu,Age),e(Age,B1o),b(m,uoo,_),b(m,vd,_),e(vd,gu),e(gu,Lge),M(Px,Lge,null),e(vd,I1o),e(vd,yge),e(yge,N1o),b(m,poo,_),b(m,So,_),M(Bx,So,null),e(So,q1o),e(So,Ix),e(Ix,j1o),e(Ix,ij),e(ij,D1o),e(Ix,G1o),e(So,O1o),e(So,Nx),e(Nx,V1o),e(Nx,xge),e(xge,X1o),e(Nx,z1o),e(So,Q1o),e(So,Nr),M(qx,Nr,null),e(Nr,W1o),e(Nr,$ge),e($ge,U1o),e(Nr,H1o),e(Nr,Za),e(Za,J1o),e(Za,kge),e(kge,Y1o),e(Za,Z1o),e(Za,Sge),e(Sge,K1o),e(Za,ebo),e(Za,Rge),e(Rge,obo),e(Za,rbo),e(Nr,tbo),e(Nr,k),e(k,cs),e(cs,Pge),e(Pge,abo),e(cs,nbo),e(cs,dj),e(dj,sbo),e(cs,lbo),e(cs,cj),e(cj,ibo),e(cs,dbo),e(k,cbo),e(k,ms),e(ms,Bge),e(Bge,mbo),e(ms,fbo),e(ms,mj),e(mj,gbo),e(ms,hbo),e(ms,fj),e(fj,ubo),e(ms,pbo),e(k,_bo),e(k,fs),e(fs,Ige),e(Ige,bbo),e(fs,vbo),e(fs,gj),e(gj,Fbo),e(fs,Tbo),e(fs,hj),e(hj,Mbo),e(fs,Ebo),e(k,Cbo),e(k,hu),e(hu,Nge),e(Nge,wbo),e(hu,Abo),e(hu,uj),e(uj,Lbo),e(hu,ybo),e(k,xbo),e(k,gs),e(gs,qge),e(qge,$bo),e(gs,kbo),e(gs,pj),e(pj,Sbo),e(gs,Rbo),e(gs,_j),e(_j,Pbo),e(gs,Bbo),e(k,Ibo),e(k,uu),e(uu,jge),e(jge,Nbo),e(uu,qbo),e(uu,bj),e(bj,jbo),e(uu,Dbo),e(k,Gbo),e(k,pu),e(pu,Dge),e(Dge,Obo),e(pu,Vbo),e(pu,vj),e(vj,Xbo),e(pu,zbo),e(k,Qbo),e(k,_u),e(_u,Gge),e(Gge,Wbo),e(_u,Ubo),e(_u,Fj),e(Fj,Hbo),e(_u,Jbo),e(k,Ybo),e(k,hs),e(hs,Oge),e(Oge,Zbo),e(hs,Kbo),e(hs,Tj),e(Tj,e2o),e(hs,o2o),e(hs,Mj),e(Mj,r2o),e(hs,t2o),e(k,a2o),e(k,us),e(us,Vge),e(Vge,n2o),e(us,s2o),e(us,Ej),e(Ej,l2o),e(us,i2o),e(us,Cj),e(Cj,d2o),e(us,c2o),e(k,m2o),e(k,ps),e(ps,Xge),e(Xge,f2o),e(ps,g2o),e(ps,wj),e(wj,h2o),e(ps,u2o),e(ps,Aj),e(Aj,p2o),e(ps,_2o),e(k,b2o),e(k,bu),e(bu,zge),e(zge,v2o),e(bu,F2o),e(bu,Lj),e(Lj,T2o),e(bu,M2o),e(k,E2o),e(k,vu),e(vu,Qge),e(Qge,C2o),e(vu,w2o),e(vu,yj),e(yj,A2o),e(vu,L2o),e(k,y2o),e(k,Fu),e(Fu,Wge),e(Wge,x2o),e(Fu,$2o),e(Fu,xj),e(xj,k2o),e(Fu,S2o),e(k,R2o),e(k,_s),e(_s,Uge),e(Uge,P2o),e(_s,B2o),e(_s,$j),e($j,I2o),e(_s,N2o),e(_s,kj),e(kj,q2o),e(_s,j2o),e(k,D2o),e(k,Tu),e(Tu,Hge),e(Hge,G2o),e(Tu,O2o),e(Tu,Sj),e(Sj,V2o),e(Tu,X2o),e(k,z2o),e(k,bs),e(bs,Jge),e(Jge,Q2o),e(bs,W2o),e(bs,Rj),e(Rj,U2o),e(bs,H2o),e(bs,Pj),e(Pj,J2o),e(bs,Y2o),e(k,Z2o),e(k,vs),e(vs,Yge),e(Yge,K2o),e(vs,evo),e(vs,Bj),e(Bj,ovo),e(vs,rvo),e(vs,Ij),e(Ij,tvo),e(vs,avo),e(k,nvo),e(k,Fs),e(Fs,Zge),e(Zge,svo),e(Fs,lvo),e(Fs,Nj),e(Nj,ivo),e(Fs,dvo),e(Fs,qj),e(qj,cvo),e(Fs,mvo),e(k,fvo),e(k,Ts),e(Ts,Kge),e(Kge,gvo),e(Ts,hvo),e(Ts,jj),e(jj,uvo),e(Ts,pvo),e(Ts,Dj),e(Dj,_vo),e(Ts,bvo),e(k,vvo),e(k,Mu),e(Mu,ehe),e(ehe,Fvo),e(Mu,Tvo),e(Mu,Gj),e(Gj,Mvo),e(Mu,Evo),e(k,Cvo),e(k,Ms),e(Ms,ohe),e(ohe,wvo),e(Ms,Avo),e(Ms,Oj),e(Oj,Lvo),e(Ms,yvo),e(Ms,Vj),e(Vj,xvo),e(Ms,$vo),e(k,kvo),e(k,Es),e(Es,rhe),e(rhe,Svo),e(Es,Rvo),e(Es,Xj),e(Xj,Pvo),e(Es,Bvo),e(Es,zj),e(zj,Ivo),e(Es,Nvo),e(k,qvo),e(k,Cs),e(Cs,the),e(the,jvo),e(Cs,Dvo),e(Cs,Qj),e(Qj,Gvo),e(Cs,Ovo),e(Cs,Wj),e(Wj,Vvo),e(Cs,Xvo),e(k,zvo),e(k,ws),e(ws,ahe),e(ahe,Qvo),e(ws,Wvo),e(ws,Uj),e(Uj,Uvo),e(ws,Hvo),e(ws,Hj),e(Hj,Jvo),e(ws,Yvo),e(k,Zvo),e(k,As),e(As,nhe),e(nhe,Kvo),e(As,eFo),e(As,Jj),e(Jj,oFo),e(As,rFo),e(As,Yj),e(Yj,tFo),e(As,aFo),e(k,nFo),e(k,Ls),e(Ls,she),e(she,sFo),e(Ls,lFo),e(Ls,Zj),e(Zj,iFo),e(Ls,dFo),e(Ls,Kj),e(Kj,cFo),e(Ls,mFo),e(k,fFo),e(k,ys),e(ys,lhe),e(lhe,gFo),e(ys,hFo),e(ys,eD),e(eD,uFo),e(ys,pFo),e(ys,oD),e(oD,_Fo),e(ys,bFo),e(k,vFo),e(k,Eu),e(Eu,ihe),e(ihe,FFo),e(Eu,TFo),e(Eu,rD),e(rD,MFo),e(Eu,EFo),e(k,CFo),e(k,xs),e(xs,dhe),e(dhe,wFo),e(xs,AFo),e(xs,tD),e(tD,LFo),e(xs,yFo),e(xs,aD),e(aD,xFo),e(xs,$Fo),e(k,kFo),e(k,Cu),e(Cu,che),e(che,SFo),e(Cu,RFo),e(Cu,nD),e(nD,PFo),e(Cu,BFo),e(k,IFo),e(k,$s),e($s,mhe),e(mhe,NFo),e($s,qFo),e($s,sD),e(sD,jFo),e($s,DFo),e($s,lD),e(lD,GFo),e($s,OFo),e(k,VFo),e(k,ks),e(ks,fhe),e(fhe,XFo),e(ks,zFo),e(ks,iD),e(iD,QFo),e(ks,WFo),e(ks,dD),e(dD,UFo),e(ks,HFo),e(k,JFo),e(k,Ss),e(Ss,ghe),e(ghe,YFo),e(Ss,ZFo),e(Ss,cD),e(cD,KFo),e(Ss,eTo),e(Ss,mD),e(mD,oTo),e(Ss,rTo),e(k,tTo),e(k,wu),e(wu,hhe),e(hhe,aTo),e(wu,nTo),e(wu,fD),e(fD,sTo),e(wu,lTo),e(k,iTo),e(k,Au),e(Au,uhe),e(uhe,dTo),e(Au,cTo),e(Au,gD),e(gD,mTo),e(Au,fTo),e(k,gTo),e(k,Rs),e(Rs,phe),e(phe,hTo),e(Rs,uTo),e(Rs,hD),e(hD,pTo),e(Rs,_To),e(Rs,uD),e(uD,bTo),e(Rs,vTo),e(k,FTo),e(k,Ps),e(Ps,_he),e(_he,TTo),e(Ps,MTo),e(Ps,pD),e(pD,ETo),e(Ps,CTo),e(Ps,_D),e(_D,wTo),e(Ps,ATo),e(k,LTo),e(k,Bs),e(Bs,bhe),e(bhe,yTo),e(Bs,xTo),e(Bs,bD),e(bD,$To),e(Bs,kTo),e(Bs,vD),e(vD,STo),e(Bs,RTo),e(k,PTo),e(k,Lu),e(Lu,vhe),e(vhe,BTo),e(Lu,ITo),e(Lu,FD),e(FD,NTo),e(Lu,qTo),e(k,jTo),e(k,Is),e(Is,Fhe),e(Fhe,DTo),e(Is,GTo),e(Is,TD),e(TD,OTo),e(Is,VTo),e(Is,MD),e(MD,XTo),e(Is,zTo),e(k,QTo),e(k,Ns),e(Ns,The),e(The,WTo),e(Ns,UTo),e(Ns,ED),e(ED,HTo),e(Ns,JTo),e(Ns,CD),e(CD,YTo),e(Ns,ZTo),e(k,KTo),e(k,qs),e(qs,Mhe),e(Mhe,eMo),e(qs,oMo),e(qs,wD),e(wD,rMo),e(qs,tMo),e(qs,AD),e(AD,aMo),e(qs,nMo),e(k,sMo),e(k,js),e(js,Ehe),e(Ehe,lMo),e(js,iMo),e(js,LD),e(LD,dMo),e(js,cMo),e(js,yD),e(yD,mMo),e(js,fMo),e(k,gMo),e(k,Ds),e(Ds,Che),e(Che,hMo),e(Ds,uMo),e(Ds,xD),e(xD,pMo),e(Ds,_Mo),e(Ds,$D),e($D,bMo),e(Ds,vMo),e(k,FMo),e(k,Gs),e(Gs,whe),e(whe,TMo),e(Gs,MMo),e(Gs,kD),e(kD,EMo),e(Gs,CMo),e(Gs,SD),e(SD,wMo),e(Gs,AMo),e(k,LMo),e(k,Os),e(Os,Ahe),e(Ahe,yMo),e(Os,xMo),e(Os,RD),e(RD,$Mo),e(Os,kMo),e(Os,PD),e(PD,SMo),e(Os,RMo),e(k,PMo),e(k,Vs),e(Vs,Lhe),e(Lhe,BMo),e(Vs,IMo),e(Vs,BD),e(BD,NMo),e(Vs,qMo),e(Vs,ID),e(ID,jMo),e(Vs,DMo),e(k,GMo),e(k,yu),e(yu,yhe),e(yhe,OMo),e(yu,VMo),e(yu,ND),e(ND,XMo),e(yu,zMo),e(k,QMo),e(k,Xs),e(Xs,xhe),e(xhe,WMo),e(Xs,UMo),e(Xs,qD),e(qD,HMo),e(Xs,JMo),e(Xs,jD),e(jD,YMo),e(Xs,ZMo),e(k,KMo),e(k,xu),e(xu,$he),e($he,eEo),e(xu,oEo),e(xu,DD),e(DD,rEo),e(xu,tEo),e(k,aEo),e(k,$u),e($u,khe),e(khe,nEo),e($u,sEo),e($u,GD),e(GD,lEo),e($u,iEo),e(k,dEo),e(k,zs),e(zs,She),e(She,cEo),e(zs,mEo),e(zs,OD),e(OD,fEo),e(zs,gEo),e(zs,VD),e(VD,hEo),e(zs,uEo),e(k,pEo),e(k,Qs),e(Qs,Rhe),e(Rhe,_Eo),e(Qs,bEo),e(Qs,XD),e(XD,vEo),e(Qs,FEo),e(Qs,zD),e(zD,TEo),e(Qs,MEo),e(k,EEo),e(k,Ws),e(Ws,Phe),e(Phe,CEo),e(Ws,wEo),e(Ws,QD),e(QD,AEo),e(Ws,LEo),e(Ws,WD),e(WD,yEo),e(Ws,xEo),e(k,$Eo),e(k,ku),e(ku,Bhe),e(Bhe,kEo),e(ku,SEo),e(ku,UD),e(UD,REo),e(ku,PEo),e(k,BEo),e(k,Us),e(Us,Ihe),e(Ihe,IEo),e(Us,NEo),e(Us,HD),e(HD,qEo),e(Us,jEo),e(Us,JD),e(JD,DEo),e(Us,GEo),e(k,OEo),e(k,Hs),e(Hs,Nhe),e(Nhe,VEo),e(Hs,XEo),e(Hs,YD),e(YD,zEo),e(Hs,QEo),e(Hs,ZD),e(ZD,WEo),e(Hs,UEo),e(k,HEo),e(k,Js),e(Js,qhe),e(qhe,JEo),e(Js,YEo),e(Js,KD),e(KD,ZEo),e(Js,KEo),e(Js,eG),e(eG,e4o),e(Js,o4o),e(k,r4o),e(k,Ys),e(Ys,jhe),e(jhe,t4o),e(Ys,a4o),e(Ys,oG),e(oG,n4o),e(Ys,s4o),e(Ys,rG),e(rG,l4o),e(Ys,i4o),e(k,d4o),e(k,Zs),e(Zs,Dhe),e(Dhe,c4o),e(Zs,m4o),e(Zs,tG),e(tG,f4o),e(Zs,g4o),e(Zs,aG),e(aG,h4o),e(Zs,u4o),e(k,p4o),e(k,Ks),e(Ks,Ghe),e(Ghe,_4o),e(Ks,b4o),e(Ks,nG),e(nG,v4o),e(Ks,F4o),e(Ks,sG),e(sG,T4o),e(Ks,M4o),e(k,E4o),e(k,el),e(el,Ohe),e(Ohe,C4o),e(el,w4o),e(el,lG),e(lG,A4o),e(el,L4o),e(el,iG),e(iG,y4o),e(el,x4o),e(k,$4o),e(k,ol),e(ol,Vhe),e(Vhe,k4o),e(ol,S4o),e(ol,dG),e(dG,R4o),e(ol,P4o),e(ol,cG),e(cG,B4o),e(ol,I4o),e(k,N4o),e(k,Su),e(Su,Xhe),e(Xhe,q4o),e(Su,j4o),e(Su,mG),e(mG,D4o),e(Su,G4o),e(k,O4o),e(k,rl),e(rl,zhe),e(zhe,V4o),e(rl,X4o),e(rl,fG),e(fG,z4o),e(rl,Q4o),e(rl,gG),e(gG,W4o),e(rl,U4o),e(k,H4o),e(k,tl),e(tl,Qhe),e(Qhe,J4o),e(tl,Y4o),e(tl,hG),e(hG,Z4o),e(tl,K4o),e(tl,uG),e(uG,eCo),e(tl,oCo),e(k,rCo),e(k,Ru),e(Ru,Whe),e(Whe,tCo),e(Ru,aCo),e(Ru,pG),e(pG,nCo),e(Ru,sCo),e(k,lCo),e(k,Pu),e(Pu,Uhe),e(Uhe,iCo),e(Pu,dCo),e(Pu,_G),e(_G,cCo),e(Pu,mCo),e(k,fCo),e(k,Bu),e(Bu,Hhe),e(Hhe,gCo),e(Bu,hCo),e(Bu,bG),e(bG,uCo),e(Bu,pCo),e(k,_Co),e(k,Iu),e(Iu,Jhe),e(Jhe,bCo),e(Iu,vCo),e(Iu,vG),e(vG,FCo),e(Iu,TCo),e(k,MCo),e(k,al),e(al,Yhe),e(Yhe,ECo),e(al,CCo),e(al,FG),e(FG,wCo),e(al,ACo),e(al,TG),e(TG,LCo),e(al,yCo),e(k,xCo),e(k,Nu),e(Nu,Zhe),e(Zhe,$Co),e(Nu,kCo),e(Nu,MG),e(MG,SCo),e(Nu,RCo),e(k,PCo),e(k,nl),e(nl,Khe),e(Khe,BCo),e(nl,ICo),e(nl,EG),e(EG,NCo),e(nl,qCo),e(nl,CG),e(CG,jCo),e(nl,DCo),e(k,GCo),e(k,sl),e(sl,eue),e(eue,OCo),e(sl,VCo),e(sl,wG),e(wG,XCo),e(sl,zCo),e(sl,AG),e(AG,QCo),e(sl,WCo),e(k,UCo),e(k,ll),e(ll,oue),e(oue,HCo),e(ll,JCo),e(ll,LG),e(LG,YCo),e(ll,ZCo),e(ll,yG),e(yG,KCo),e(ll,e3o),e(k,o3o),e(k,il),e(il,rue),e(rue,r3o),e(il,t3o),e(il,xG),e(xG,a3o),e(il,n3o),e(il,$G),e($G,s3o),e(il,l3o),e(k,i3o),e(k,dl),e(dl,tue),e(tue,d3o),e(dl,c3o),e(dl,kG),e(kG,m3o),e(dl,f3o),e(dl,SG),e(SG,g3o),e(dl,h3o),e(k,u3o),e(k,cl),e(cl,aue),e(aue,p3o),e(cl,_3o),e(cl,RG),e(RG,b3o),e(cl,v3o),e(cl,PG),e(PG,F3o),e(cl,T3o),e(k,M3o),e(k,qu),e(qu,nue),e(nue,E3o),e(qu,C3o),e(qu,BG),e(BG,w3o),e(qu,A3o),e(k,L3o),e(k,ju),e(ju,sue),e(sue,y3o),e(ju,x3o),e(ju,IG),e(IG,$3o),e(ju,k3o),e(k,S3o),e(k,ml),e(ml,lue),e(lue,R3o),e(ml,P3o),e(ml,NG),e(NG,B3o),e(ml,I3o),e(ml,qG),e(qG,N3o),e(ml,q3o),e(k,j3o),e(k,fl),e(fl,iue),e(iue,D3o),e(fl,G3o),e(fl,jG),e(jG,O3o),e(fl,V3o),e(fl,DG),e(DG,X3o),e(fl,z3o),e(k,Q3o),e(k,gl),e(gl,due),e(due,W3o),e(gl,U3o),e(gl,GG),e(GG,H3o),e(gl,J3o),e(gl,OG),e(OG,Y3o),e(gl,Z3o),e(k,K3o),e(k,Du),e(Du,cue),e(cue,e5o),e(Du,o5o),e(Du,VG),e(VG,r5o),e(Du,t5o),e(k,a5o),e(k,Gu),e(Gu,mue),e(mue,n5o),e(Gu,s5o),e(Gu,XG),e(XG,l5o),e(Gu,i5o),e(k,d5o),e(k,Ou),e(Ou,fue),e(fue,c5o),e(Ou,m5o),e(Ou,zG),e(zG,f5o),e(Ou,g5o),e(k,h5o),e(k,hl),e(hl,gue),e(gue,u5o),e(hl,p5o),e(hl,QG),e(QG,_5o),e(hl,b5o),e(hl,WG),e(WG,v5o),e(hl,F5o),e(k,T5o),e(k,ul),e(ul,hue),e(hue,M5o),e(ul,E5o),e(ul,UG),e(UG,C5o),e(ul,w5o),e(ul,HG),e(HG,A5o),e(ul,L5o),e(k,y5o),e(k,Vu),e(Vu,uue),e(uue,x5o),e(Vu,$5o),e(Vu,JG),e(JG,k5o),e(Vu,S5o),e(k,R5o),e(k,Xu),e(Xu,pue),e(pue,P5o),e(Xu,B5o),e(Xu,YG),e(YG,I5o),e(Xu,N5o),e(k,q5o),e(k,zu),e(zu,_ue),e(_ue,j5o),e(zu,D5o),e(zu,ZG),e(ZG,G5o),e(zu,O5o),e(k,V5o),e(k,Qu),e(Qu,bue),e(bue,X5o),e(Qu,z5o),e(Qu,KG),e(KG,Q5o),e(Qu,W5o),e(k,U5o),e(k,pl),e(pl,vue),e(vue,H5o),e(pl,J5o),e(pl,eO),e(eO,Y5o),e(pl,Z5o),e(pl,oO),e(oO,K5o),e(pl,e0o),e(k,o0o),e(k,_l),e(_l,Fue),e(Fue,r0o),e(_l,t0o),e(_l,rO),e(rO,a0o),e(_l,n0o),e(_l,tO),e(tO,s0o),e(_l,l0o),e(k,i0o),e(k,Wu),e(Wu,Tue),e(Tue,d0o),e(Wu,c0o),e(Wu,aO),e(aO,m0o),e(Wu,f0o),e(k,g0o),e(k,Uu),e(Uu,Mue),e(Mue,h0o),e(Uu,u0o),e(Uu,nO),e(nO,p0o),e(Uu,_0o),e(k,b0o),e(k,bl),e(bl,Eue),e(Eue,v0o),e(bl,F0o),e(bl,sO),e(sO,T0o),e(bl,M0o),e(bl,lO),e(lO,E0o),e(bl,C0o),e(k,w0o),e(k,vl),e(vl,Cue),e(Cue,A0o),e(vl,L0o),e(vl,iO),e(iO,y0o),e(vl,x0o),e(vl,dO),e(dO,$0o),e(vl,k0o),e(k,S0o),e(k,Fl),e(Fl,wue),e(wue,R0o),e(Fl,P0o),e(Fl,cO),e(cO,B0o),e(Fl,I0o),e(Fl,mO),e(mO,N0o),e(Fl,q0o),e(k,j0o),e(k,Tl),e(Tl,Aue),e(Aue,D0o),e(Tl,G0o),e(Tl,fO),e(fO,O0o),e(Tl,V0o),e(Tl,gO),e(gO,X0o),e(Tl,z0o),e(Nr,Q0o),M(Hu,Nr,null),e(So,W0o),e(So,Ju),M(jx,Ju,null),e(Ju,U0o),e(Ju,Lue),e(Lue,H0o),b(m,_oo,_),b(m,Fd,_),e(Fd,Yu),e(Yu,yue),M(Dx,yue,null),e(Fd,J0o),e(Fd,xue),e(xue,Y0o),b(m,boo,_),b(m,Ro,_),M(Gx,Ro,null),e(Ro,Z0o),e(Ro,Ox),e(Ox,K0o),e(Ox,hO),e(hO,ewo),e(Ox,owo),e(Ro,rwo),e(Ro,Vx),e(Vx,two),e(Vx,$ue),e($ue,awo),e(Vx,nwo),e(Ro,swo),e(Ro,Ye),M(Xx,Ye,null),e(Ye,lwo),e(Ye,kue),e(kue,iwo),e(Ye,dwo),e(Ye,Ka),e(Ka,cwo),e(Ka,Sue),e(Sue,mwo),e(Ka,fwo),e(Ka,Rue),e(Rue,gwo),e(Ka,hwo),e(Ka,Pue),e(Pue,uwo),e(Ka,pwo),e(Ye,_wo),e(Ye,z),e(z,Zu),e(Zu,Bue),e(Bue,bwo),e(Zu,vwo),e(Zu,uO),e(uO,Fwo),e(Zu,Two),e(z,Mwo),e(z,Ku),e(Ku,Iue),e(Iue,Ewo),e(Ku,Cwo),e(Ku,pO),e(pO,wwo),e(Ku,Awo),e(z,Lwo),e(z,ep),e(ep,Nue),e(Nue,ywo),e(ep,xwo),e(ep,_O),e(_O,$wo),e(ep,kwo),e(z,Swo),e(z,op),e(op,que),e(que,Rwo),e(op,Pwo),e(op,bO),e(bO,Bwo),e(op,Iwo),e(z,Nwo),e(z,rp),e(rp,jue),e(jue,qwo),e(rp,jwo),e(rp,vO),e(vO,Dwo),e(rp,Gwo),e(z,Owo),e(z,tp),e(tp,Due),e(Due,Vwo),e(tp,Xwo),e(tp,FO),e(FO,zwo),e(tp,Qwo),e(z,Wwo),e(z,ap),e(ap,Gue),e(Gue,Uwo),e(ap,Hwo),e(ap,TO),e(TO,Jwo),e(ap,Ywo),e(z,Zwo),e(z,np),e(np,Oue),e(Oue,Kwo),e(np,eAo),e(np,MO),e(MO,oAo),e(np,rAo),e(z,tAo),e(z,sp),e(sp,Vue),e(Vue,aAo),e(sp,nAo),e(sp,EO),e(EO,sAo),e(sp,lAo),e(z,iAo),e(z,lp),e(lp,Xue),e(Xue,dAo),e(lp,cAo),e(lp,CO),e(CO,mAo),e(lp,fAo),e(z,gAo),e(z,ip),e(ip,zue),e(zue,hAo),e(ip,uAo),e(ip,wO),e(wO,pAo),e(ip,_Ao),e(z,bAo),e(z,dp),e(dp,Que),e(Que,vAo),e(dp,FAo),e(dp,AO),e(AO,TAo),e(dp,MAo),e(z,EAo),e(z,cp),e(cp,Wue),e(Wue,CAo),e(cp,wAo),e(cp,LO),e(LO,AAo),e(cp,LAo),e(z,yAo),e(z,mp),e(mp,Uue),e(Uue,xAo),e(mp,$Ao),e(mp,yO),e(yO,kAo),e(mp,SAo),e(z,RAo),e(z,fp),e(fp,Hue),e(Hue,PAo),e(fp,BAo),e(fp,xO),e(xO,IAo),e(fp,NAo),e(z,qAo),e(z,gp),e(gp,Jue),e(Jue,jAo),e(gp,DAo),e(gp,$O),e($O,GAo),e(gp,OAo),e(z,VAo),e(z,hp),e(hp,Yue),e(Yue,XAo),e(hp,zAo),e(hp,kO),e(kO,QAo),e(hp,WAo),e(z,UAo),e(z,up),e(up,Zue),e(Zue,HAo),e(up,JAo),e(up,SO),e(SO,YAo),e(up,ZAo),e(z,KAo),e(z,pp),e(pp,Kue),e(Kue,e6o),e(pp,o6o),e(pp,RO),e(RO,r6o),e(pp,t6o),e(z,a6o),e(z,_p),e(_p,epe),e(epe,n6o),e(_p,s6o),e(_p,PO),e(PO,l6o),e(_p,i6o),e(z,d6o),e(z,bp),e(bp,ope),e(ope,c6o),e(bp,m6o),e(bp,BO),e(BO,f6o),e(bp,g6o),e(z,h6o),e(z,vp),e(vp,rpe),e(rpe,u6o),e(vp,p6o),e(vp,IO),e(IO,_6o),e(vp,b6o),e(z,v6o),e(z,Fp),e(Fp,tpe),e(tpe,F6o),e(Fp,T6o),e(Fp,NO),e(NO,M6o),e(Fp,E6o),e(z,C6o),e(z,Tp),e(Tp,ape),e(ape,w6o),e(Tp,A6o),e(Tp,qO),e(qO,L6o),e(Tp,y6o),e(z,x6o),e(z,Mp),e(Mp,npe),e(npe,$6o),e(Mp,k6o),e(Mp,jO),e(jO,S6o),e(Mp,R6o),e(z,P6o),e(z,Ep),e(Ep,spe),e(spe,B6o),e(Ep,I6o),e(Ep,DO),e(DO,N6o),e(Ep,q6o),e(z,j6o),e(z,Cp),e(Cp,lpe),e(lpe,D6o),e(Cp,G6o),e(Cp,GO),e(GO,O6o),e(Cp,V6o),e(z,X6o),e(z,wp),e(wp,ipe),e(ipe,z6o),e(wp,Q6o),e(wp,OO),e(OO,W6o),e(wp,U6o),e(z,H6o),e(z,Ap),e(Ap,dpe),e(dpe,J6o),e(Ap,Y6o),e(Ap,VO),e(VO,Z6o),e(Ap,K6o),e(z,e7o),e(z,Lp),e(Lp,cpe),e(cpe,o7o),e(Lp,r7o),e(Lp,XO),e(XO,t7o),e(Lp,a7o),e(z,n7o),e(z,yp),e(yp,mpe),e(mpe,s7o),e(yp,l7o),e(yp,zO),e(zO,i7o),e(yp,d7o),e(z,c7o),e(z,xp),e(xp,fpe),e(fpe,m7o),e(xp,f7o),e(xp,QO),e(QO,g7o),e(xp,h7o),e(z,u7o),e(z,$p),e($p,gpe),e(gpe,p7o),e($p,_7o),e($p,WO),e(WO,b7o),e($p,v7o),e(z,F7o),e(z,kp),e(kp,hpe),e(hpe,T7o),e(kp,M7o),e(kp,UO),e(UO,E7o),e(kp,C7o),e(z,w7o),e(z,Sp),e(Sp,upe),e(upe,A7o),e(Sp,L7o),e(Sp,HO),e(HO,y7o),e(Sp,x7o),e(z,$7o),e(z,Rp),e(Rp,ppe),e(ppe,k7o),e(Rp,S7o),e(Rp,JO),e(JO,R7o),e(Rp,P7o),e(z,B7o),e(z,Pp),e(Pp,_pe),e(_pe,I7o),e(Pp,N7o),e(Pp,YO),e(YO,q7o),e(Pp,j7o),e(z,D7o),e(z,Bp),e(Bp,bpe),e(bpe,G7o),e(Bp,O7o),e(Bp,ZO),e(ZO,V7o),e(Bp,X7o),e(z,z7o),e(z,Ip),e(Ip,vpe),e(vpe,Q7o),e(Ip,W7o),e(Ip,KO),e(KO,U7o),e(Ip,H7o),e(z,J7o),e(z,Np),e(Np,Fpe),e(Fpe,Y7o),e(Np,Z7o),e(Np,eV),e(eV,K7o),e(Np,eLo),e(z,oLo),e(z,qp),e(qp,Tpe),e(Tpe,rLo),e(qp,tLo),e(qp,oV),e(oV,aLo),e(qp,nLo),e(z,sLo),e(z,jp),e(jp,Mpe),e(Mpe,lLo),e(jp,iLo),e(jp,rV),e(rV,dLo),e(jp,cLo),e(z,mLo),e(z,Dp),e(Dp,Epe),e(Epe,fLo),e(Dp,gLo),e(Dp,tV),e(tV,hLo),e(Dp,uLo),e(Ye,pLo),M(Gp,Ye,null),e(Ye,_Lo),M(Op,Ye,null),e(Ro,bLo),e(Ro,Vp),M(zx,Vp,null),e(Vp,vLo),e(Vp,Cpe),e(Cpe,FLo),b(m,voo,_),b(m,Td,_),e(Td,Xp),e(Xp,wpe),M(Qx,wpe,null),e(Td,TLo),e(Td,Ape),e(Ape,MLo),b(m,Foo,_),b(m,Po,_),M(Wx,Po,null),e(Po,ELo),e(Po,Ux),e(Ux,CLo),e(Ux,aV),e(aV,wLo),e(Ux,ALo),e(Po,LLo),e(Po,Hx),e(Hx,yLo),e(Hx,Lpe),e(Lpe,xLo),e(Hx,$Lo),e(Po,kLo),e(Po,Ze),M(Jx,Ze,null),e(Ze,SLo),e(Ze,ype),e(ype,RLo),e(Ze,PLo),e(Ze,Md),e(Md,BLo),e(Md,xpe),e(xpe,ILo),e(Md,NLo),e(Md,$pe),e($pe,qLo),e(Md,jLo),e(Ze,DLo),e(Ze,se),e(se,zp),e(zp,kpe),e(kpe,GLo),e(zp,OLo),e(zp,nV),e(nV,VLo),e(zp,XLo),e(se,zLo),e(se,Qp),e(Qp,Spe),e(Spe,QLo),e(Qp,WLo),e(Qp,sV),e(sV,ULo),e(Qp,HLo),e(se,JLo),e(se,Wp),e(Wp,Rpe),e(Rpe,YLo),e(Wp,ZLo),e(Wp,lV),e(lV,KLo),e(Wp,eyo),e(se,oyo),e(se,Up),e(Up,Ppe),e(Ppe,ryo),e(Up,tyo),e(Up,iV),e(iV,ayo),e(Up,nyo),e(se,syo),e(se,Hp),e(Hp,Bpe),e(Bpe,lyo),e(Hp,iyo),e(Hp,dV),e(dV,dyo),e(Hp,cyo),e(se,myo),e(se,Jp),e(Jp,Ipe),e(Ipe,fyo),e(Jp,gyo),e(Jp,cV),e(cV,hyo),e(Jp,uyo),e(se,pyo),e(se,Yp),e(Yp,Npe),e(Npe,_yo),e(Yp,byo),e(Yp,mV),e(mV,vyo),e(Yp,Fyo),e(se,Tyo),e(se,Zp),e(Zp,qpe),e(qpe,Myo),e(Zp,Eyo),e(Zp,fV),e(fV,Cyo),e(Zp,wyo),e(se,Ayo),e(se,Kp),e(Kp,jpe),e(jpe,Lyo),e(Kp,yyo),e(Kp,gV),e(gV,xyo),e(Kp,$yo),e(se,kyo),e(se,e_),e(e_,Dpe),e(Dpe,Syo),e(e_,Ryo),e(e_,hV),e(hV,Pyo),e(e_,Byo),e(se,Iyo),e(se,o_),e(o_,Gpe),e(Gpe,Nyo),e(o_,qyo),e(o_,uV),e(uV,jyo),e(o_,Dyo),e(se,Gyo),e(se,r_),e(r_,Ope),e(Ope,Oyo),e(r_,Vyo),e(r_,pV),e(pV,Xyo),e(r_,zyo),e(se,Qyo),e(se,t_),e(t_,Vpe),e(Vpe,Wyo),e(t_,Uyo),e(t_,_V),e(_V,Hyo),e(t_,Jyo),e(se,Yyo),e(se,a_),e(a_,Xpe),e(Xpe,Zyo),e(a_,Kyo),e(a_,bV),e(bV,e8o),e(a_,o8o),e(se,r8o),e(se,n_),e(n_,zpe),e(zpe,t8o),e(n_,a8o),e(n_,vV),e(vV,n8o),e(n_,s8o),e(se,l8o),e(se,s_),e(s_,Qpe),e(Qpe,i8o),e(s_,d8o),e(s_,FV),e(FV,c8o),e(s_,m8o),e(se,f8o),e(se,l_),e(l_,Wpe),e(Wpe,g8o),e(l_,h8o),e(l_,TV),e(TV,u8o),e(l_,p8o),e(se,_8o),e(se,i_),e(i_,Upe),e(Upe,b8o),e(i_,v8o),e(i_,MV),e(MV,F8o),e(i_,T8o),e(se,M8o),e(se,d_),e(d_,Hpe),e(Hpe,E8o),e(d_,C8o),e(d_,EV),e(EV,w8o),e(d_,A8o),e(se,L8o),e(se,c_),e(c_,Jpe),e(Jpe,y8o),e(c_,x8o),e(c_,CV),e(CV,$8o),e(c_,k8o),e(se,S8o),e(se,m_),e(m_,Ype),e(Ype,R8o),e(m_,P8o),e(m_,wV),e(wV,B8o),e(m_,I8o),e(se,N8o),e(se,f_),e(f_,Zpe),e(Zpe,q8o),e(f_,j8o),e(f_,AV),e(AV,D8o),e(f_,G8o),e(se,O8o),e(se,g_),e(g_,Kpe),e(Kpe,V8o),e(g_,X8o),e(g_,LV),e(LV,z8o),e(g_,Q8o),e(Ze,W8o),M(h_,Ze,null),e(Ze,U8o),M(u_,Ze,null),e(Po,H8o),e(Po,p_),M(Yx,p_,null),e(p_,J8o),e(p_,e_e),e(e_e,Y8o),b(m,Too,_),b(m,Ed,_),e(Ed,__),e(__,o_e),M(Zx,o_e,null),e(Ed,Z8o),e(Ed,r_e),e(r_e,K8o),b(m,Moo,_),b(m,Bo,_),M(Kx,Bo,null),e(Bo,e9o),e(Bo,Cd),e(Cd,o9o),e(Cd,yV),e(yV,r9o),e(Cd,t9o),e(Cd,xV),e(xV,a9o),e(Cd,n9o),e(Bo,s9o),e(Bo,e$),e(e$,l9o),e(e$,t_e),e(t_e,i9o),e(e$,d9o),e(Bo,c9o),e(Bo,vt),M(o$,vt,null),e(vt,m9o),e(vt,a_e),e(a_e,f9o),e(vt,g9o),e(vt,wd),e(wd,h9o),e(wd,n_e),e(n_e,u9o),e(wd,p9o),e(wd,$V),e($V,_9o),e(wd,b9o),e(vt,v9o),M(b_,vt,null),e(Bo,F9o),e(Bo,Ke),M(r$,Ke,null),e(Ke,T9o),e(Ke,s_e),e(s_e,M9o),e(Ke,E9o),e(Ke,en),e(en,C9o),e(en,l_e),e(l_e,w9o),e(en,A9o),e(en,i_e),e(i_e,L9o),e(en,y9o),e(en,d_e),e(d_e,x9o),e(en,$9o),e(Ke,k9o),e(Ke,y),e(y,v_),e(v_,c_e),e(c_e,S9o),e(v_,R9o),e(v_,kV),e(kV,P9o),e(v_,B9o),e(y,I9o),e(y,F_),e(F_,m_e),e(m_e,N9o),e(F_,q9o),e(F_,SV),e(SV,j9o),e(F_,D9o),e(y,G9o),e(y,T_),e(T_,f_e),e(f_e,O9o),e(T_,V9o),e(T_,RV),e(RV,X9o),e(T_,z9o),e(y,Q9o),e(y,M_),e(M_,g_e),e(g_e,W9o),e(M_,U9o),e(M_,PV),e(PV,H9o),e(M_,J9o),e(y,Y9o),e(y,E_),e(E_,h_e),e(h_e,Z9o),e(E_,K9o),e(E_,BV),e(BV,exo),e(E_,oxo),e(y,rxo),e(y,C_),e(C_,u_e),e(u_e,txo),e(C_,axo),e(C_,IV),e(IV,nxo),e(C_,sxo),e(y,lxo),e(y,w_),e(w_,p_e),e(p_e,ixo),e(w_,dxo),e(w_,NV),e(NV,cxo),e(w_,mxo),e(y,fxo),e(y,A_),e(A_,__e),e(__e,gxo),e(A_,hxo),e(A_,qV),e(qV,uxo),e(A_,pxo),e(y,_xo),e(y,L_),e(L_,b_e),e(b_e,bxo),e(L_,vxo),e(L_,jV),e(jV,Fxo),e(L_,Txo),e(y,Mxo),e(y,y_),e(y_,v_e),e(v_e,Exo),e(y_,Cxo),e(y_,DV),e(DV,wxo),e(y_,Axo),e(y,Lxo),e(y,x_),e(x_,F_e),e(F_e,yxo),e(x_,xxo),e(x_,GV),e(GV,$xo),e(x_,kxo),e(y,Sxo),e(y,$_),e($_,T_e),e(T_e,Rxo),e($_,Pxo),e($_,OV),e(OV,Bxo),e($_,Ixo),e(y,Nxo),e(y,k_),e(k_,M_e),e(M_e,qxo),e(k_,jxo),e(k_,VV),e(VV,Dxo),e(k_,Gxo),e(y,Oxo),e(y,S_),e(S_,E_e),e(E_e,Vxo),e(S_,Xxo),e(S_,XV),e(XV,zxo),e(S_,Qxo),e(y,Wxo),e(y,R_),e(R_,C_e),e(C_e,Uxo),e(R_,Hxo),e(R_,zV),e(zV,Jxo),e(R_,Yxo),e(y,Zxo),e(y,P_),e(P_,w_e),e(w_e,Kxo),e(P_,e$o),e(P_,QV),e(QV,o$o),e(P_,r$o),e(y,t$o),e(y,B_),e(B_,A_e),e(A_e,a$o),e(B_,n$o),e(B_,WV),e(WV,s$o),e(B_,l$o),e(y,i$o),e(y,I_),e(I_,L_e),e(L_e,d$o),e(I_,c$o),e(I_,UV),e(UV,m$o),e(I_,f$o),e(y,g$o),e(y,N_),e(N_,y_e),e(y_e,h$o),e(N_,u$o),e(N_,HV),e(HV,p$o),e(N_,_$o),e(y,b$o),e(y,q_),e(q_,x_e),e(x_e,v$o),e(q_,F$o),e(q_,JV),e(JV,T$o),e(q_,M$o),e(y,E$o),e(y,j_),e(j_,$_e),e($_e,C$o),e(j_,w$o),e(j_,YV),e(YV,A$o),e(j_,L$o),e(y,y$o),e(y,D_),e(D_,k_e),e(k_e,x$o),e(D_,$$o),e(D_,ZV),e(ZV,k$o),e(D_,S$o),e(y,R$o),e(y,G_),e(G_,S_e),e(S_e,P$o),e(G_,B$o),e(G_,KV),e(KV,I$o),e(G_,N$o),e(y,q$o),e(y,O_),e(O_,R_e),e(R_e,j$o),e(O_,D$o),e(O_,eX),e(eX,G$o),e(O_,O$o),e(y,V$o),e(y,V_),e(V_,P_e),e(P_e,X$o),e(V_,z$o),e(V_,oX),e(oX,Q$o),e(V_,W$o),e(y,U$o),e(y,X_),e(X_,B_e),e(B_e,H$o),e(X_,J$o),e(X_,rX),e(rX,Y$o),e(X_,Z$o),e(y,K$o),e(y,z_),e(z_,I_e),e(I_e,eko),e(z_,oko),e(z_,tX),e(tX,rko),e(z_,tko),e(y,ako),e(y,Q_),e(Q_,N_e),e(N_e,nko),e(Q_,sko),e(Q_,aX),e(aX,lko),e(Q_,iko),e(y,dko),e(y,W_),e(W_,q_e),e(q_e,cko),e(W_,mko),e(W_,nX),e(nX,fko),e(W_,gko),e(y,hko),e(y,U_),e(U_,j_e),e(j_e,uko),e(U_,pko),e(U_,sX),e(sX,_ko),e(U_,bko),e(y,vko),e(y,H_),e(H_,D_e),e(D_e,Fko),e(H_,Tko),e(H_,lX),e(lX,Mko),e(H_,Eko),e(y,Cko),e(y,J_),e(J_,G_e),e(G_e,wko),e(J_,Ako),e(J_,iX),e(iX,Lko),e(J_,yko),e(y,xko),e(y,Y_),e(Y_,O_e),e(O_e,$ko),e(Y_,kko),e(Y_,dX),e(dX,Sko),e(Y_,Rko),e(y,Pko),e(y,Z_),e(Z_,V_e),e(V_e,Bko),e(Z_,Iko),e(Z_,cX),e(cX,Nko),e(Z_,qko),e(y,jko),e(y,K_),e(K_,X_e),e(X_e,Dko),e(K_,Gko),e(K_,mX),e(mX,Oko),e(K_,Vko),e(y,Xko),e(y,e1),e(e1,z_e),e(z_e,zko),e(e1,Qko),e(e1,fX),e(fX,Wko),e(e1,Uko),e(y,Hko),e(y,o1),e(o1,Q_e),e(Q_e,Jko),e(o1,Yko),e(o1,gX),e(gX,Zko),e(o1,Kko),e(y,eSo),e(y,r1),e(r1,W_e),e(W_e,oSo),e(r1,rSo),e(r1,hX),e(hX,tSo),e(r1,aSo),e(y,nSo),e(y,t1),e(t1,U_e),e(U_e,sSo),e(t1,lSo),e(t1,uX),e(uX,iSo),e(t1,dSo),e(y,cSo),e(y,Ml),e(Ml,H_e),e(H_e,mSo),e(Ml,fSo),e(Ml,pX),e(pX,gSo),e(Ml,hSo),e(Ml,_X),e(_X,uSo),e(Ml,pSo),e(y,_So),e(y,a1),e(a1,J_e),e(J_e,bSo),e(a1,vSo),e(a1,bX),e(bX,FSo),e(a1,TSo),e(y,MSo),e(y,n1),e(n1,Y_e),e(Y_e,ESo),e(n1,CSo),e(n1,vX),e(vX,wSo),e(n1,ASo),e(y,LSo),e(y,s1),e(s1,Z_e),e(Z_e,ySo),e(s1,xSo),e(s1,FX),e(FX,$So),e(s1,kSo),e(y,SSo),e(y,l1),e(l1,K_e),e(K_e,RSo),e(l1,PSo),e(l1,TX),e(TX,BSo),e(l1,ISo),e(y,NSo),e(y,i1),e(i1,e1e),e(e1e,qSo),e(i1,jSo),e(i1,MX),e(MX,DSo),e(i1,GSo),e(y,OSo),e(y,d1),e(d1,o1e),e(o1e,VSo),e(d1,XSo),e(d1,EX),e(EX,zSo),e(d1,QSo),e(y,WSo),e(y,c1),e(c1,r1e),e(r1e,USo),e(c1,HSo),e(c1,CX),e(CX,JSo),e(c1,YSo),e(y,ZSo),e(y,m1),e(m1,t1e),e(t1e,KSo),e(m1,eRo),e(m1,wX),e(wX,oRo),e(m1,rRo),e(y,tRo),e(y,f1),e(f1,a1e),e(a1e,aRo),e(f1,nRo),e(f1,AX),e(AX,sRo),e(f1,lRo),e(y,iRo),e(y,g1),e(g1,n1e),e(n1e,dRo),e(g1,cRo),e(g1,LX),e(LX,mRo),e(g1,fRo),e(y,gRo),e(y,h1),e(h1,s1e),e(s1e,hRo),e(h1,uRo),e(h1,yX),e(yX,pRo),e(h1,_Ro),e(y,bRo),e(y,u1),e(u1,l1e),e(l1e,vRo),e(u1,FRo),e(u1,xX),e(xX,TRo),e(u1,MRo),e(y,ERo),e(y,p1),e(p1,i1e),e(i1e,CRo),e(p1,wRo),e(p1,$X),e($X,ARo),e(p1,LRo),e(y,yRo),e(y,_1),e(_1,d1e),e(d1e,xRo),e(_1,$Ro),e(_1,kX),e(kX,kRo),e(_1,SRo),e(y,RRo),e(y,b1),e(b1,c1e),e(c1e,PRo),e(b1,BRo),e(b1,SX),e(SX,IRo),e(b1,NRo),e(y,qRo),e(y,v1),e(v1,m1e),e(m1e,jRo),e(v1,DRo),e(v1,RX),e(RX,GRo),e(v1,ORo),e(y,VRo),e(y,F1),e(F1,f1e),e(f1e,XRo),e(F1,zRo),e(F1,PX),e(PX,QRo),e(F1,WRo),e(y,URo),e(y,T1),e(T1,g1e),e(g1e,HRo),e(T1,JRo),e(T1,BX),e(BX,YRo),e(T1,ZRo),e(y,KRo),e(y,M1),e(M1,h1e),e(h1e,ePo),e(M1,oPo),e(M1,IX),e(IX,rPo),e(M1,tPo),e(y,aPo),e(y,E1),e(E1,u1e),e(u1e,nPo),e(E1,sPo),e(E1,NX),e(NX,lPo),e(E1,iPo),e(y,dPo),e(y,C1),e(C1,p1e),e(p1e,cPo),e(C1,mPo),e(C1,qX),e(qX,fPo),e(C1,gPo),e(y,hPo),e(y,w1),e(w1,_1e),e(_1e,uPo),e(w1,pPo),e(w1,jX),e(jX,_Po),e(w1,bPo),e(y,vPo),e(y,A1),e(A1,b1e),e(b1e,FPo),e(A1,TPo),e(A1,DX),e(DX,MPo),e(A1,EPo),e(y,CPo),e(y,L1),e(L1,v1e),e(v1e,wPo),e(L1,APo),e(L1,GX),e(GX,LPo),e(L1,yPo),e(y,xPo),e(y,y1),e(y1,F1e),e(F1e,$Po),e(y1,kPo),e(y1,OX),e(OX,SPo),e(y1,RPo),e(y,PPo),e(y,x1),e(x1,T1e),e(T1e,BPo),e(x1,IPo),e(x1,VX),e(VX,NPo),e(x1,qPo),e(y,jPo),e(y,$1),e($1,M1e),e(M1e,DPo),e($1,GPo),e($1,XX),e(XX,OPo),e($1,VPo),e(y,XPo),e(y,k1),e(k1,E1e),e(E1e,zPo),e(k1,QPo),e(k1,zX),e(zX,WPo),e(k1,UPo),e(y,HPo),e(y,S1),e(S1,C1e),e(C1e,JPo),e(S1,YPo),e(S1,QX),e(QX,ZPo),e(S1,KPo),e(y,eBo),e(y,R1),e(R1,w1e),e(w1e,oBo),e(R1,rBo),e(R1,WX),e(WX,tBo),e(R1,aBo),e(y,nBo),e(y,P1),e(P1,A1e),e(A1e,sBo),e(P1,lBo),e(P1,UX),e(UX,iBo),e(P1,dBo),e(y,cBo),e(y,B1),e(B1,L1e),e(L1e,mBo),e(B1,fBo),e(B1,HX),e(HX,gBo),e(B1,hBo),e(y,uBo),e(y,I1),e(I1,y1e),e(y1e,pBo),e(I1,_Bo),e(I1,JX),e(JX,bBo),e(I1,vBo),e(y,FBo),e(y,N1),e(N1,x1e),e(x1e,TBo),e(N1,MBo),e(N1,YX),e(YX,EBo),e(N1,CBo),e(y,wBo),e(y,q1),e(q1,$1e),e($1e,ABo),e(q1,LBo),e(q1,ZX),e(ZX,yBo),e(q1,xBo),e(y,$Bo),e(y,j1),e(j1,k1e),e(k1e,kBo),e(j1,SBo),e(j1,KX),e(KX,RBo),e(j1,PBo),e(y,BBo),e(y,D1),e(D1,S1e),e(S1e,IBo),e(D1,NBo),e(D1,ez),e(ez,qBo),e(D1,jBo),e(y,DBo),e(y,G1),e(G1,R1e),e(R1e,GBo),e(G1,OBo),e(G1,oz),e(oz,VBo),e(G1,XBo),e(y,zBo),e(y,O1),e(O1,P1e),e(P1e,QBo),e(O1,WBo),e(O1,rz),e(rz,UBo),e(O1,HBo),e(y,JBo),e(y,V1),e(V1,B1e),e(B1e,YBo),e(V1,ZBo),e(V1,tz),e(tz,KBo),e(V1,eIo),e(y,oIo),e(y,X1),e(X1,I1e),e(I1e,rIo),e(X1,tIo),e(X1,az),e(az,aIo),e(X1,nIo),e(y,sIo),e(y,z1),e(z1,N1e),e(N1e,lIo),e(z1,iIo),e(z1,nz),e(nz,dIo),e(z1,cIo),e(y,mIo),e(y,Q1),e(Q1,q1e),e(q1e,fIo),e(Q1,gIo),e(Q1,sz),e(sz,hIo),e(Q1,uIo),e(y,pIo),e(y,W1),e(W1,j1e),e(j1e,_Io),e(W1,bIo),e(W1,lz),e(lz,vIo),e(W1,FIo),e(y,TIo),e(y,U1),e(U1,D1e),e(D1e,MIo),e(U1,EIo),e(U1,iz),e(iz,CIo),e(U1,wIo),e(y,AIo),e(y,H1),e(H1,G1e),e(G1e,LIo),e(H1,yIo),e(H1,dz),e(dz,xIo),e(H1,$Io),e(y,kIo),e(y,J1),e(J1,O1e),e(O1e,SIo),e(J1,RIo),e(J1,cz),e(cz,PIo),e(J1,BIo),e(y,IIo),e(y,Y1),e(Y1,V1e),e(V1e,NIo),e(Y1,qIo),e(Y1,mz),e(mz,jIo),e(Y1,DIo),e(y,GIo),e(y,Z1),e(Z1,X1e),e(X1e,OIo),e(Z1,VIo),e(Z1,fz),e(fz,XIo),e(Z1,zIo),e(y,QIo),e(y,K1),e(K1,z1e),e(z1e,WIo),e(K1,UIo),e(K1,gz),e(gz,HIo),e(K1,JIo),e(y,YIo),e(y,eb),e(eb,Q1e),e(Q1e,ZIo),e(eb,KIo),e(eb,hz),e(hz,eNo),e(eb,oNo),e(y,rNo),e(y,ob),e(ob,W1e),e(W1e,tNo),e(ob,aNo),e(ob,uz),e(uz,nNo),e(ob,sNo),e(y,lNo),e(y,rb),e(rb,U1e),e(U1e,iNo),e(rb,dNo),e(rb,pz),e(pz,cNo),e(rb,mNo),e(y,fNo),e(y,tb),e(tb,H1e),e(H1e,gNo),e(tb,hNo),e(tb,_z),e(_z,uNo),e(tb,pNo),e(y,_No),e(y,ab),e(ab,J1e),e(J1e,bNo),e(ab,vNo),e(ab,bz),e(bz,FNo),e(ab,TNo),e(y,MNo),e(y,nb),e(nb,Y1e),e(Y1e,ENo),e(nb,CNo),e(nb,vz),e(vz,wNo),e(nb,ANo),e(y,LNo),e(y,sb),e(sb,Z1e),e(Z1e,yNo),e(sb,xNo),e(sb,Fz),e(Fz,$No),e(sb,kNo),e(y,SNo),e(y,lb),e(lb,K1e),e(K1e,RNo),e(lb,PNo),e(lb,Tz),e(Tz,BNo),e(lb,INo),e(y,NNo),e(y,ib),e(ib,ebe),e(ebe,qNo),e(ib,jNo),e(ib,Mz),e(Mz,DNo),e(ib,GNo),e(y,ONo),e(y,db),e(db,obe),e(obe,VNo),e(db,XNo),e(db,Ez),e(Ez,zNo),e(db,QNo),e(y,WNo),e(y,cb),e(cb,rbe),e(rbe,UNo),e(cb,HNo),e(cb,Cz),e(Cz,JNo),e(cb,YNo),e(y,ZNo),e(y,mb),e(mb,tbe),e(tbe,KNo),e(mb,eqo),e(mb,wz),e(wz,oqo),e(mb,rqo),e(y,tqo),e(y,fb),e(fb,abe),e(abe,aqo),e(fb,nqo),e(fb,Az),e(Az,sqo),e(fb,lqo),e(y,iqo),e(y,gb),e(gb,nbe),e(nbe,dqo),e(gb,cqo),e(gb,Lz),e(Lz,mqo),e(gb,fqo),e(y,gqo),e(y,hb),e(hb,sbe),e(sbe,hqo),e(hb,uqo),e(hb,yz),e(yz,pqo),e(hb,_qo),e(y,bqo),e(y,ub),e(ub,lbe),e(lbe,vqo),e(ub,Fqo),e(ub,xz),e(xz,Tqo),e(ub,Mqo),e(y,Eqo),e(y,pb),e(pb,ibe),e(ibe,Cqo),e(pb,wqo),e(pb,$z),e($z,Aqo),e(pb,Lqo),e(y,yqo),e(y,_b),e(_b,dbe),e(dbe,xqo),e(_b,$qo),e(_b,kz),e(kz,kqo),e(_b,Sqo),e(y,Rqo),e(y,bb),e(bb,cbe),e(cbe,Pqo),e(bb,Bqo),e(bb,Sz),e(Sz,Iqo),e(bb,Nqo),e(y,qqo),e(y,vb),e(vb,mbe),e(mbe,jqo),e(vb,Dqo),e(vb,Rz),e(Rz,Gqo),e(vb,Oqo),e(y,Vqo),e(y,Fb),e(Fb,fbe),e(fbe,Xqo),e(Fb,zqo),e(Fb,Pz),e(Pz,Qqo),e(Fb,Wqo),e(y,Uqo),e(y,Tb),e(Tb,gbe),e(gbe,Hqo),e(Tb,Jqo),e(Tb,Bz),e(Bz,Yqo),e(Tb,Zqo),e(y,Kqo),e(y,Mb),e(Mb,hbe),e(hbe,ejo),e(Mb,ojo),e(Mb,Iz),e(Iz,rjo),e(Mb,tjo),e(y,ajo),e(y,Eb),e(Eb,ube),e(ube,njo),e(Eb,sjo),e(Eb,Nz),e(Nz,ljo),e(Eb,ijo),e(y,djo),e(y,Cb),e(Cb,pbe),e(pbe,cjo),e(Cb,mjo),e(Cb,qz),e(qz,fjo),e(Cb,gjo),e(y,hjo),e(y,wb),e(wb,_be),e(_be,ujo),e(wb,pjo),e(wb,jz),e(jz,_jo),e(wb,bjo),e(y,vjo),e(y,Ab),e(Ab,bbe),e(bbe,Fjo),e(Ab,Tjo),e(Ab,Dz),e(Dz,Mjo),e(Ab,Ejo),e(y,Cjo),e(y,Lb),e(Lb,vbe),e(vbe,wjo),e(Lb,Ajo),e(Lb,Gz),e(Gz,Ljo),e(Lb,yjo),e(y,xjo),e(y,yb),e(yb,Fbe),e(Fbe,$jo),e(yb,kjo),e(yb,Oz),e(Oz,Sjo),e(yb,Rjo),e(y,Pjo),e(y,xb),e(xb,Tbe),e(Tbe,Bjo),e(xb,Ijo),e(xb,Vz),e(Vz,Njo),e(xb,qjo),e(y,jjo),e(y,$b),e($b,Mbe),e(Mbe,Djo),e($b,Gjo),e($b,Xz),e(Xz,Ojo),e($b,Vjo),e(y,Xjo),e(y,kb),e(kb,Ebe),e(Ebe,zjo),e(kb,Qjo),e(kb,zz),e(zz,Wjo),e(kb,Ujo),e(y,Hjo),e(y,Sb),e(Sb,Cbe),e(Cbe,Jjo),e(Sb,Yjo),e(Sb,Qz),e(Qz,Zjo),e(Sb,Kjo),e(y,eDo),e(y,Rb),e(Rb,wbe),e(wbe,oDo),e(Rb,rDo),e(Rb,Wz),e(Wz,tDo),e(Rb,aDo),e(y,nDo),e(y,Pb),e(Pb,Abe),e(Abe,sDo),e(Pb,lDo),e(Pb,Uz),e(Uz,iDo),e(Pb,dDo),e(y,cDo),e(y,Bb),e(Bb,Lbe),e(Lbe,mDo),e(Bb,fDo),e(Bb,Hz),e(Hz,gDo),e(Bb,hDo),e(y,uDo),e(y,Ib),e(Ib,ybe),e(ybe,pDo),e(Ib,_Do),e(Ib,Jz),e(Jz,bDo),e(Ib,vDo),e(Ke,FDo),e(Ke,Nb),e(Nb,TDo),e(Nb,xbe),e(xbe,MDo),e(Nb,EDo),e(Nb,$be),e($be,CDo),e(Ke,wDo),M(qb,Ke,null),b(m,Eoo,_),b(m,Ad,_),e(Ad,jb),e(jb,kbe),M(t$,kbe,null),e(Ad,ADo),e(Ad,Sbe),e(Sbe,LDo),b(m,Coo,_),b(m,Io,_),M(a$,Io,null),e(Io,yDo),e(Io,Ld),e(Ld,xDo),e(Ld,Yz),e(Yz,$Do),e(Ld,kDo),e(Ld,Zz),e(Zz,SDo),e(Ld,RDo),e(Io,PDo),e(Io,n$),e(n$,BDo),e(n$,Rbe),e(Rbe,IDo),e(n$,NDo),e(Io,qDo),e(Io,Ft),M(s$,Ft,null),e(Ft,jDo),e(Ft,Pbe),e(Pbe,DDo),e(Ft,GDo),e(Ft,yd),e(yd,ODo),e(yd,Bbe),e(Bbe,VDo),e(yd,XDo),e(yd,Kz),e(Kz,zDo),e(yd,QDo),e(Ft,WDo),M(Db,Ft,null),e(Io,UDo),e(Io,eo),M(l$,eo,null),e(eo,HDo),e(eo,Ibe),e(Ibe,JDo),e(eo,YDo),e(eo,on),e(on,ZDo),e(on,Nbe),e(Nbe,KDo),e(on,eGo),e(on,qbe),e(qbe,oGo),e(on,rGo),e(on,jbe),e(jbe,tGo),e(on,aGo),e(eo,nGo),e(eo,G),e(G,Gb),e(Gb,Dbe),e(Dbe,sGo),e(Gb,lGo),e(Gb,eQ),e(eQ,iGo),e(Gb,dGo),e(G,cGo),e(G,Ob),e(Ob,Gbe),e(Gbe,mGo),e(Ob,fGo),e(Ob,oQ),e(oQ,gGo),e(Ob,hGo),e(G,uGo),e(G,Vb),e(Vb,Obe),e(Obe,pGo),e(Vb,_Go),e(Vb,rQ),e(rQ,bGo),e(Vb,vGo),e(G,FGo),e(G,Xb),e(Xb,Vbe),e(Vbe,TGo),e(Xb,MGo),e(Xb,tQ),e(tQ,EGo),e(Xb,CGo),e(G,wGo),e(G,zb),e(zb,Xbe),e(Xbe,AGo),e(zb,LGo),e(zb,aQ),e(aQ,yGo),e(zb,xGo),e(G,$Go),e(G,Qb),e(Qb,zbe),e(zbe,kGo),e(Qb,SGo),e(Qb,nQ),e(nQ,RGo),e(Qb,PGo),e(G,BGo),e(G,Wb),e(Wb,Qbe),e(Qbe,IGo),e(Wb,NGo),e(Wb,sQ),e(sQ,qGo),e(Wb,jGo),e(G,DGo),e(G,Ub),e(Ub,Wbe),e(Wbe,GGo),e(Ub,OGo),e(Ub,lQ),e(lQ,VGo),e(Ub,XGo),e(G,zGo),e(G,Hb),e(Hb,Ube),e(Ube,QGo),e(Hb,WGo),e(Hb,iQ),e(iQ,UGo),e(Hb,HGo),e(G,JGo),e(G,Jb),e(Jb,Hbe),e(Hbe,YGo),e(Jb,ZGo),e(Jb,dQ),e(dQ,KGo),e(Jb,eOo),e(G,oOo),e(G,Yb),e(Yb,Jbe),e(Jbe,rOo),e(Yb,tOo),e(Yb,cQ),e(cQ,aOo),e(Yb,nOo),e(G,sOo),e(G,Zb),e(Zb,Ybe),e(Ybe,lOo),e(Zb,iOo),e(Zb,mQ),e(mQ,dOo),e(Zb,cOo),e(G,mOo),e(G,Kb),e(Kb,Zbe),e(Zbe,fOo),e(Kb,gOo),e(Kb,fQ),e(fQ,hOo),e(Kb,uOo),e(G,pOo),e(G,e2),e(e2,Kbe),e(Kbe,_Oo),e(e2,bOo),e(e2,gQ),e(gQ,vOo),e(e2,FOo),e(G,TOo),e(G,o2),e(o2,e2e),e(e2e,MOo),e(o2,EOo),e(o2,hQ),e(hQ,COo),e(o2,wOo),e(G,AOo),e(G,r2),e(r2,o2e),e(o2e,LOo),e(r2,yOo),e(r2,uQ),e(uQ,xOo),e(r2,$Oo),e(G,kOo),e(G,t2),e(t2,r2e),e(r2e,SOo),e(t2,ROo),e(t2,pQ),e(pQ,POo),e(t2,BOo),e(G,IOo),e(G,a2),e(a2,t2e),e(t2e,NOo),e(a2,qOo),e(a2,_Q),e(_Q,jOo),e(a2,DOo),e(G,GOo),e(G,n2),e(n2,a2e),e(a2e,OOo),e(n2,VOo),e(n2,bQ),e(bQ,XOo),e(n2,zOo),e(G,QOo),e(G,s2),e(s2,n2e),e(n2e,WOo),e(s2,UOo),e(s2,vQ),e(vQ,HOo),e(s2,JOo),e(G,YOo),e(G,l2),e(l2,s2e),e(s2e,ZOo),e(l2,KOo),e(l2,FQ),e(FQ,eVo),e(l2,oVo),e(G,rVo),e(G,i2),e(i2,l2e),e(l2e,tVo),e(i2,aVo),e(i2,TQ),e(TQ,nVo),e(i2,sVo),e(G,lVo),e(G,d2),e(d2,i2e),e(i2e,iVo),e(d2,dVo),e(d2,MQ),e(MQ,cVo),e(d2,mVo),e(G,fVo),e(G,c2),e(c2,d2e),e(d2e,gVo),e(c2,hVo),e(c2,EQ),e(EQ,uVo),e(c2,pVo),e(G,_Vo),e(G,m2),e(m2,c2e),e(c2e,bVo),e(m2,vVo),e(m2,CQ),e(CQ,FVo),e(m2,TVo),e(G,MVo),e(G,f2),e(f2,m2e),e(m2e,EVo),e(f2,CVo),e(f2,wQ),e(wQ,wVo),e(f2,AVo),e(G,LVo),e(G,g2),e(g2,f2e),e(f2e,yVo),e(g2,xVo),e(g2,AQ),e(AQ,$Vo),e(g2,kVo),e(G,SVo),e(G,h2),e(h2,g2e),e(g2e,RVo),e(h2,PVo),e(h2,LQ),e(LQ,BVo),e(h2,IVo),e(G,NVo),e(G,u2),e(u2,h2e),e(h2e,qVo),e(u2,jVo),e(u2,yQ),e(yQ,DVo),e(u2,GVo),e(G,OVo),e(G,p2),e(p2,u2e),e(u2e,VVo),e(p2,XVo),e(p2,xQ),e(xQ,zVo),e(p2,QVo),e(G,WVo),e(G,_2),e(_2,p2e),e(p2e,UVo),e(_2,HVo),e(_2,$Q),e($Q,JVo),e(_2,YVo),e(G,ZVo),e(G,b2),e(b2,_2e),e(_2e,KVo),e(b2,eXo),e(b2,kQ),e(kQ,oXo),e(b2,rXo),e(G,tXo),e(G,v2),e(v2,b2e),e(b2e,aXo),e(v2,nXo),e(v2,SQ),e(SQ,sXo),e(v2,lXo),e(G,iXo),e(G,F2),e(F2,v2e),e(v2e,dXo),e(F2,cXo),e(F2,RQ),e(RQ,mXo),e(F2,fXo),e(G,gXo),e(G,T2),e(T2,F2e),e(F2e,hXo),e(T2,uXo),e(T2,PQ),e(PQ,pXo),e(T2,_Xo),e(G,bXo),e(G,M2),e(M2,T2e),e(T2e,vXo),e(M2,FXo),e(M2,BQ),e(BQ,TXo),e(M2,MXo),e(G,EXo),e(G,E2),e(E2,M2e),e(M2e,CXo),e(E2,wXo),e(E2,IQ),e(IQ,AXo),e(E2,LXo),e(G,yXo),e(G,C2),e(C2,E2e),e(E2e,xXo),e(C2,$Xo),e(C2,NQ),e(NQ,kXo),e(C2,SXo),e(G,RXo),e(G,w2),e(w2,C2e),e(C2e,PXo),e(w2,BXo),e(w2,qQ),e(qQ,IXo),e(w2,NXo),e(G,qXo),e(G,A2),e(A2,w2e),e(w2e,jXo),e(A2,DXo),e(A2,jQ),e(jQ,GXo),e(A2,OXo),e(G,VXo),e(G,L2),e(L2,A2e),e(A2e,XXo),e(L2,zXo),e(L2,DQ),e(DQ,QXo),e(L2,WXo),e(G,UXo),e(G,y2),e(y2,L2e),e(L2e,HXo),e(y2,JXo),e(y2,GQ),e(GQ,YXo),e(y2,ZXo),e(G,KXo),e(G,x2),e(x2,y2e),e(y2e,ezo),e(x2,ozo),e(x2,OQ),e(OQ,rzo),e(x2,tzo),e(G,azo),e(G,$2),e($2,x2e),e(x2e,nzo),e($2,szo),e($2,VQ),e(VQ,lzo),e($2,izo),e(G,dzo),e(G,k2),e(k2,$2e),e($2e,czo),e(k2,mzo),e(k2,XQ),e(XQ,fzo),e(k2,gzo),e(G,hzo),e(G,S2),e(S2,k2e),e(k2e,uzo),e(S2,pzo),e(S2,zQ),e(zQ,_zo),e(S2,bzo),e(G,vzo),e(G,R2),e(R2,S2e),e(S2e,Fzo),e(R2,Tzo),e(R2,QQ),e(QQ,Mzo),e(R2,Ezo),e(G,Czo),e(G,P2),e(P2,R2e),e(R2e,wzo),e(P2,Azo),e(P2,WQ),e(WQ,Lzo),e(P2,yzo),e(eo,xzo),e(eo,B2),e(B2,$zo),e(B2,P2e),e(P2e,kzo),e(B2,Szo),e(B2,B2e),e(B2e,Rzo),e(eo,Pzo),M(I2,eo,null),b(m,woo,_),b(m,xd,_),e(xd,N2),e(N2,I2e),M(i$,I2e,null),e(xd,Bzo),e(xd,N2e),e(N2e,Izo),b(m,Aoo,_),b(m,No,_),M(d$,No,null),e(No,Nzo),e(No,$d),e($d,qzo),e($d,UQ),e(UQ,jzo),e($d,Dzo),e($d,HQ),e(HQ,Gzo),e($d,Ozo),e(No,Vzo),e(No,c$),e(c$,Xzo),e(c$,q2e),e(q2e,zzo),e(c$,Qzo),e(No,Wzo),e(No,Tt),M(m$,Tt,null),e(Tt,Uzo),e(Tt,j2e),e(j2e,Hzo),e(Tt,Jzo),e(Tt,kd),e(kd,Yzo),e(kd,D2e),e(D2e,Zzo),e(kd,Kzo),e(kd,JQ),e(JQ,eQo),e(kd,oQo),e(Tt,rQo),M(q2,Tt,null),e(No,tQo),e(No,oo),M(f$,oo,null),e(oo,aQo),e(oo,G2e),e(G2e,nQo),e(oo,sQo),e(oo,rn),e(rn,lQo),e(rn,O2e),e(O2e,iQo),e(rn,dQo),e(rn,V2e),e(V2e,cQo),e(rn,mQo),e(rn,X2e),e(X2e,fQo),e(rn,gQo),e(oo,hQo),e(oo,Q),e(Q,j2),e(j2,z2e),e(z2e,uQo),e(j2,pQo),e(j2,YQ),e(YQ,_Qo),e(j2,bQo),e(Q,vQo),e(Q,D2),e(D2,Q2e),e(Q2e,FQo),e(D2,TQo),e(D2,ZQ),e(ZQ,MQo),e(D2,EQo),e(Q,CQo),e(Q,G2),e(G2,W2e),e(W2e,wQo),e(G2,AQo),e(G2,KQ),e(KQ,LQo),e(G2,yQo),e(Q,xQo),e(Q,O2),e(O2,U2e),e(U2e,$Qo),e(O2,kQo),e(O2,eW),e(eW,SQo),e(O2,RQo),e(Q,PQo),e(Q,V2),e(V2,H2e),e(H2e,BQo),e(V2,IQo),e(V2,oW),e(oW,NQo),e(V2,qQo),e(Q,jQo),e(Q,X2),e(X2,J2e),e(J2e,DQo),e(X2,GQo),e(X2,rW),e(rW,OQo),e(X2,VQo),e(Q,XQo),e(Q,z2),e(z2,Y2e),e(Y2e,zQo),e(z2,QQo),e(z2,tW),e(tW,WQo),e(z2,UQo),e(Q,HQo),e(Q,Q2),e(Q2,Z2e),e(Z2e,JQo),e(Q2,YQo),e(Q2,aW),e(aW,ZQo),e(Q2,KQo),e(Q,eWo),e(Q,W2),e(W2,K2e),e(K2e,oWo),e(W2,rWo),e(W2,nW),e(nW,tWo),e(W2,aWo),e(Q,nWo),e(Q,U2),e(U2,eve),e(eve,sWo),e(U2,lWo),e(U2,sW),e(sW,iWo),e(U2,dWo),e(Q,cWo),e(Q,H2),e(H2,ove),e(ove,mWo),e(H2,fWo),e(H2,lW),e(lW,gWo),e(H2,hWo),e(Q,uWo),e(Q,J2),e(J2,rve),e(rve,pWo),e(J2,_Wo),e(J2,iW),e(iW,bWo),e(J2,vWo),e(Q,FWo),e(Q,Y2),e(Y2,tve),e(tve,TWo),e(Y2,MWo),e(Y2,dW),e(dW,EWo),e(Y2,CWo),e(Q,wWo),e(Q,Z2),e(Z2,ave),e(ave,AWo),e(Z2,LWo),e(Z2,cW),e(cW,yWo),e(Z2,xWo),e(Q,$Wo),e(Q,K2),e(K2,nve),e(nve,kWo),e(K2,SWo),e(K2,mW),e(mW,RWo),e(K2,PWo),e(Q,BWo),e(Q,ev),e(ev,sve),e(sve,IWo),e(ev,NWo),e(ev,fW),e(fW,qWo),e(ev,jWo),e(Q,DWo),e(Q,ov),e(ov,lve),e(lve,GWo),e(ov,OWo),e(ov,gW),e(gW,VWo),e(ov,XWo),e(Q,zWo),e(Q,rv),e(rv,ive),e(ive,QWo),e(rv,WWo),e(rv,hW),e(hW,UWo),e(rv,HWo),e(Q,JWo),e(Q,tv),e(tv,dve),e(dve,YWo),e(tv,ZWo),e(tv,uW),e(uW,KWo),e(tv,eUo),e(Q,oUo),e(Q,av),e(av,cve),e(cve,rUo),e(av,tUo),e(av,pW),e(pW,aUo),e(av,nUo),e(Q,sUo),e(Q,nv),e(nv,mve),e(mve,lUo),e(nv,iUo),e(nv,_W),e(_W,dUo),e(nv,cUo),e(Q,mUo),e(Q,sv),e(sv,fve),e(fve,fUo),e(sv,gUo),e(sv,bW),e(bW,hUo),e(sv,uUo),e(Q,pUo),e(Q,lv),e(lv,gve),e(gve,_Uo),e(lv,bUo),e(lv,vW),e(vW,vUo),e(lv,FUo),e(Q,TUo),e(Q,iv),e(iv,hve),e(hve,MUo),e(iv,EUo),e(iv,FW),e(FW,CUo),e(iv,wUo),e(Q,AUo),e(Q,dv),e(dv,uve),e(uve,LUo),e(dv,yUo),e(dv,TW),e(TW,xUo),e(dv,$Uo),e(Q,kUo),e(Q,cv),e(cv,pve),e(pve,SUo),e(cv,RUo),e(cv,MW),e(MW,PUo),e(cv,BUo),e(Q,IUo),e(Q,mv),e(mv,_ve),e(_ve,NUo),e(mv,qUo),e(mv,EW),e(EW,jUo),e(mv,DUo),e(Q,GUo),e(Q,fv),e(fv,bve),e(bve,OUo),e(fv,VUo),e(fv,CW),e(CW,XUo),e(fv,zUo),e(Q,QUo),e(Q,gv),e(gv,vve),e(vve,WUo),e(gv,UUo),e(gv,wW),e(wW,HUo),e(gv,JUo),e(Q,YUo),e(Q,hv),e(hv,Fve),e(Fve,ZUo),e(hv,KUo),e(hv,AW),e(AW,eHo),e(hv,oHo),e(Q,rHo),e(Q,uv),e(uv,Tve),e(Tve,tHo),e(uv,aHo),e(uv,LW),e(LW,nHo),e(uv,sHo),e(Q,lHo),e(Q,pv),e(pv,Mve),e(Mve,iHo),e(pv,dHo),e(pv,yW),e(yW,cHo),e(pv,mHo),e(Q,fHo),e(Q,_v),e(_v,Eve),e(Eve,gHo),e(_v,hHo),e(_v,xW),e(xW,uHo),e(_v,pHo),e(Q,_Ho),e(Q,bv),e(bv,Cve),e(Cve,bHo),e(bv,vHo),e(bv,$W),e($W,FHo),e(bv,THo),e(Q,MHo),e(Q,vv),e(vv,wve),e(wve,EHo),e(vv,CHo),e(vv,kW),e(kW,wHo),e(vv,AHo),e(Q,LHo),e(Q,Fv),e(Fv,Ave),e(Ave,yHo),e(Fv,xHo),e(Fv,SW),e(SW,$Ho),e(Fv,kHo),e(Q,SHo),e(Q,Tv),e(Tv,Lve),e(Lve,RHo),e(Tv,PHo),e(Tv,RW),e(RW,BHo),e(Tv,IHo),e(Q,NHo),e(Q,Mv),e(Mv,yve),e(yve,qHo),e(Mv,jHo),e(Mv,PW),e(PW,DHo),e(Mv,GHo),e(Q,OHo),e(Q,Ev),e(Ev,xve),e(xve,VHo),e(Ev,XHo),e(Ev,BW),e(BW,zHo),e(Ev,QHo),e(Q,WHo),e(Q,Cv),e(Cv,$ve),e($ve,UHo),e(Cv,HHo),e(Cv,IW),e(IW,JHo),e(Cv,YHo),e(Q,ZHo),e(Q,wv),e(wv,kve),e(kve,KHo),e(wv,eJo),e(wv,NW),e(NW,oJo),e(wv,rJo),e(Q,tJo),e(Q,Av),e(Av,Sve),e(Sve,aJo),e(Av,nJo),e(Av,qW),e(qW,sJo),e(Av,lJo),e(oo,iJo),e(oo,Lv),e(Lv,dJo),e(Lv,Rve),e(Rve,cJo),e(Lv,mJo),e(Lv,Pve),e(Pve,fJo),e(oo,gJo),M(yv,oo,null),b(m,Loo,_),b(m,Sd,_),e(Sd,xv),e(xv,Bve),M(g$,Bve,null),e(Sd,hJo),e(Sd,Ive),e(Ive,uJo),b(m,yoo,_),b(m,qo,_),M(h$,qo,null),e(qo,pJo),e(qo,Rd),e(Rd,_Jo),e(Rd,jW),e(jW,bJo),e(Rd,vJo),e(Rd,DW),e(DW,FJo),e(Rd,TJo),e(qo,MJo),e(qo,u$),e(u$,EJo),e(u$,Nve),e(Nve,CJo),e(u$,wJo),e(qo,AJo),e(qo,Mt),M(p$,Mt,null),e(Mt,LJo),e(Mt,qve),e(qve,yJo),e(Mt,xJo),e(Mt,Pd),e(Pd,$Jo),e(Pd,jve),e(jve,kJo),e(Pd,SJo),e(Pd,GW),e(GW,RJo),e(Pd,PJo),e(Mt,BJo),M($v,Mt,null),e(qo,IJo),e(qo,ro),M(_$,ro,null),e(ro,NJo),e(ro,Dve),e(Dve,qJo),e(ro,jJo),e(ro,tn),e(tn,DJo),e(tn,Gve),e(Gve,GJo),e(tn,OJo),e(tn,Ove),e(Ove,VJo),e(tn,XJo),e(tn,Vve),e(Vve,zJo),e(tn,QJo),e(ro,WJo),e(ro,J),e(J,kv),e(kv,Xve),e(Xve,UJo),e(kv,HJo),e(kv,OW),e(OW,JJo),e(kv,YJo),e(J,ZJo),e(J,Sv),e(Sv,zve),e(zve,KJo),e(Sv,eYo),e(Sv,VW),e(VW,oYo),e(Sv,rYo),e(J,tYo),e(J,Rv),e(Rv,Qve),e(Qve,aYo),e(Rv,nYo),e(Rv,XW),e(XW,sYo),e(Rv,lYo),e(J,iYo),e(J,Pv),e(Pv,Wve),e(Wve,dYo),e(Pv,cYo),e(Pv,zW),e(zW,mYo),e(Pv,fYo),e(J,gYo),e(J,Bv),e(Bv,Uve),e(Uve,hYo),e(Bv,uYo),e(Bv,QW),e(QW,pYo),e(Bv,_Yo),e(J,bYo),e(J,Iv),e(Iv,Hve),e(Hve,vYo),e(Iv,FYo),e(Iv,WW),e(WW,TYo),e(Iv,MYo),e(J,EYo),e(J,Nv),e(Nv,Jve),e(Jve,CYo),e(Nv,wYo),e(Nv,UW),e(UW,AYo),e(Nv,LYo),e(J,yYo),e(J,qv),e(qv,Yve),e(Yve,xYo),e(qv,$Yo),e(qv,HW),e(HW,kYo),e(qv,SYo),e(J,RYo),e(J,jv),e(jv,Zve),e(Zve,PYo),e(jv,BYo),e(jv,JW),e(JW,IYo),e(jv,NYo),e(J,qYo),e(J,Dv),e(Dv,Kve),e(Kve,jYo),e(Dv,DYo),e(Dv,YW),e(YW,GYo),e(Dv,OYo),e(J,VYo),e(J,Gv),e(Gv,eFe),e(eFe,XYo),e(Gv,zYo),e(Gv,ZW),e(ZW,QYo),e(Gv,WYo),e(J,UYo),e(J,Ov),e(Ov,oFe),e(oFe,HYo),e(Ov,JYo),e(Ov,KW),e(KW,YYo),e(Ov,ZYo),e(J,KYo),e(J,Vv),e(Vv,rFe),e(rFe,eZo),e(Vv,oZo),e(Vv,eU),e(eU,rZo),e(Vv,tZo),e(J,aZo),e(J,Xv),e(Xv,tFe),e(tFe,nZo),e(Xv,sZo),e(Xv,oU),e(oU,lZo),e(Xv,iZo),e(J,dZo),e(J,zv),e(zv,aFe),e(aFe,cZo),e(zv,mZo),e(zv,rU),e(rU,fZo),e(zv,gZo),e(J,hZo),e(J,Qv),e(Qv,nFe),e(nFe,uZo),e(Qv,pZo),e(Qv,tU),e(tU,_Zo),e(Qv,bZo),e(J,vZo),e(J,Wv),e(Wv,sFe),e(sFe,FZo),e(Wv,TZo),e(Wv,aU),e(aU,MZo),e(Wv,EZo),e(J,CZo),e(J,Uv),e(Uv,lFe),e(lFe,wZo),e(Uv,AZo),e(Uv,nU),e(nU,LZo),e(Uv,yZo),e(J,xZo),e(J,Hv),e(Hv,iFe),e(iFe,$Zo),e(Hv,kZo),e(Hv,sU),e(sU,SZo),e(Hv,RZo),e(J,PZo),e(J,Jv),e(Jv,dFe),e(dFe,BZo),e(Jv,IZo),e(Jv,lU),e(lU,NZo),e(Jv,qZo),e(J,jZo),e(J,Yv),e(Yv,cFe),e(cFe,DZo),e(Yv,GZo),e(Yv,iU),e(iU,OZo),e(Yv,VZo),e(J,XZo),e(J,Zv),e(Zv,mFe),e(mFe,zZo),e(Zv,QZo),e(Zv,dU),e(dU,WZo),e(Zv,UZo),e(J,HZo),e(J,Kv),e(Kv,fFe),e(fFe,JZo),e(Kv,YZo),e(Kv,cU),e(cU,ZZo),e(Kv,KZo),e(J,eKo),e(J,eF),e(eF,gFe),e(gFe,oKo),e(eF,rKo),e(eF,mU),e(mU,tKo),e(eF,aKo),e(J,nKo),e(J,oF),e(oF,hFe),e(hFe,sKo),e(oF,lKo),e(oF,fU),e(fU,iKo),e(oF,dKo),e(J,cKo),e(J,rF),e(rF,uFe),e(uFe,mKo),e(rF,fKo),e(rF,gU),e(gU,gKo),e(rF,hKo),e(J,uKo),e(J,tF),e(tF,pFe),e(pFe,pKo),e(tF,_Ko),e(tF,hU),e(hU,bKo),e(tF,vKo),e(J,FKo),e(J,aF),e(aF,_Fe),e(_Fe,TKo),e(aF,MKo),e(aF,uU),e(uU,EKo),e(aF,CKo),e(J,wKo),e(J,nF),e(nF,bFe),e(bFe,AKo),e(nF,LKo),e(nF,pU),e(pU,yKo),e(nF,xKo),e(J,$Ko),e(J,sF),e(sF,vFe),e(vFe,kKo),e(sF,SKo),e(sF,_U),e(_U,RKo),e(sF,PKo),e(J,BKo),e(J,lF),e(lF,FFe),e(FFe,IKo),e(lF,NKo),e(lF,bU),e(bU,qKo),e(lF,jKo),e(J,DKo),e(J,iF),e(iF,TFe),e(TFe,GKo),e(iF,OKo),e(iF,vU),e(vU,VKo),e(iF,XKo),e(J,zKo),e(J,dF),e(dF,MFe),e(MFe,QKo),e(dF,WKo),e(dF,FU),e(FU,UKo),e(dF,HKo),e(J,JKo),e(J,cF),e(cF,EFe),e(EFe,YKo),e(cF,ZKo),e(cF,TU),e(TU,KKo),e(cF,eer),e(J,oer),e(J,mF),e(mF,CFe),e(CFe,rer),e(mF,ter),e(mF,wFe),e(wFe,aer),e(mF,ner),e(J,ser),e(J,fF),e(fF,AFe),e(AFe,ler),e(fF,ier),e(fF,MU),e(MU,der),e(fF,cer),e(J,mer),e(J,gF),e(gF,LFe),e(LFe,fer),e(gF,ger),e(gF,EU),e(EU,her),e(gF,uer),e(J,per),e(J,hF),e(hF,yFe),e(yFe,_er),e(hF,ber),e(hF,CU),e(CU,ver),e(hF,Fer),e(J,Ter),e(J,uF),e(uF,xFe),e(xFe,Mer),e(uF,Eer),e(uF,wU),e(wU,Cer),e(uF,wer),e(ro,Aer),e(ro,pF),e(pF,Ler),e(pF,$Fe),e($Fe,yer),e(pF,xer),e(pF,kFe),e(kFe,$er),e(ro,ker),M(_F,ro,null),b(m,xoo,_),b(m,Bd,_),e(Bd,bF),e(bF,SFe),M(b$,SFe,null),e(Bd,Ser),e(Bd,RFe),e(RFe,Rer),b(m,$oo,_),b(m,jo,_),M(v$,jo,null),e(jo,Per),e(jo,Id),e(Id,Ber),e(Id,AU),e(AU,Ier),e(Id,Ner),e(Id,LU),e(LU,qer),e(Id,jer),e(jo,Der),e(jo,F$),e(F$,Ger),e(F$,PFe),e(PFe,Oer),e(F$,Ver),e(jo,Xer),e(jo,Et),M(T$,Et,null),e(Et,zer),e(Et,BFe),e(BFe,Qer),e(Et,Wer),e(Et,Nd),e(Nd,Uer),e(Nd,IFe),e(IFe,Her),e(Nd,Jer),e(Nd,yU),e(yU,Yer),e(Nd,Zer),e(Et,Ker),M(vF,Et,null),e(jo,eor),e(jo,to),M(M$,to,null),e(to,oor),e(to,NFe),e(NFe,ror),e(to,tor),e(to,an),e(an,aor),e(an,qFe),e(qFe,nor),e(an,sor),e(an,jFe),e(jFe,lor),e(an,ior),e(an,DFe),e(DFe,dor),e(an,cor),e(to,mor),e(to,fe),e(fe,FF),e(FF,GFe),e(GFe,gor),e(FF,hor),e(FF,xU),e(xU,uor),e(FF,por),e(fe,_or),e(fe,TF),e(TF,OFe),e(OFe,bor),e(TF,vor),e(TF,$U),e($U,For),e(TF,Tor),e(fe,Mor),e(fe,MF),e(MF,VFe),e(VFe,Eor),e(MF,Cor),e(MF,kU),e(kU,wor),e(MF,Aor),e(fe,Lor),e(fe,EF),e(EF,XFe),e(XFe,yor),e(EF,xor),e(EF,SU),e(SU,$or),e(EF,kor),e(fe,Sor),e(fe,CF),e(CF,zFe),e(zFe,Ror),e(CF,Por),e(CF,RU),e(RU,Bor),e(CF,Ior),e(fe,Nor),e(fe,wF),e(wF,QFe),e(QFe,qor),e(wF,jor),e(wF,PU),e(PU,Dor),e(wF,Gor),e(fe,Oor),e(fe,AF),e(AF,WFe),e(WFe,Vor),e(AF,Xor),e(AF,BU),e(BU,zor),e(AF,Qor),e(fe,Wor),e(fe,LF),e(LF,UFe),e(UFe,Uor),e(LF,Hor),e(LF,IU),e(IU,Jor),e(LF,Yor),e(fe,Zor),e(fe,yF),e(yF,HFe),e(HFe,Kor),e(yF,err),e(yF,NU),e(NU,orr),e(yF,rrr),e(fe,trr),e(fe,xF),e(xF,JFe),e(JFe,arr),e(xF,nrr),e(xF,qU),e(qU,srr),e(xF,lrr),e(fe,irr),e(fe,$F),e($F,YFe),e(YFe,drr),e($F,crr),e($F,jU),e(jU,mrr),e($F,frr),e(fe,grr),e(fe,kF),e(kF,ZFe),e(ZFe,hrr),e(kF,urr),e(kF,DU),e(DU,prr),e(kF,_rr),e(fe,brr),e(fe,SF),e(SF,KFe),e(KFe,vrr),e(SF,Frr),e(SF,GU),e(GU,Trr),e(SF,Mrr),e(fe,Err),e(fe,RF),e(RF,eTe),e(eTe,Crr),e(RF,wrr),e(RF,OU),e(OU,Arr),e(RF,Lrr),e(fe,yrr),e(fe,PF),e(PF,oTe),e(oTe,xrr),e(PF,$rr),e(PF,VU),e(VU,krr),e(PF,Srr),e(fe,Rrr),e(fe,BF),e(BF,rTe),e(rTe,Prr),e(BF,Brr),e(BF,XU),e(XU,Irr),e(BF,Nrr),e(fe,qrr),e(fe,IF),e(IF,tTe),e(tTe,jrr),e(IF,Drr),e(IF,zU),e(zU,Grr),e(IF,Orr),e(fe,Vrr),e(fe,NF),e(NF,aTe),e(aTe,Xrr),e(NF,zrr),e(NF,QU),e(QU,Qrr),e(NF,Wrr),e(fe,Urr),e(fe,qF),e(qF,nTe),e(nTe,Hrr),e(qF,Jrr),e(qF,WU),e(WU,Yrr),e(qF,Zrr),e(fe,Krr),e(fe,jF),e(jF,sTe),e(sTe,etr),e(jF,otr),e(jF,UU),e(UU,rtr),e(jF,ttr),e(to,atr),e(to,DF),e(DF,ntr),e(DF,lTe),e(lTe,str),e(DF,ltr),e(DF,iTe),e(iTe,itr),e(to,dtr),M(GF,to,null),b(m,koo,_),b(m,qd,_),e(qd,OF),e(OF,dTe),M(E$,dTe,null),e(qd,ctr),e(qd,cTe),e(cTe,mtr),b(m,Soo,_),b(m,Do,_),M(C$,Do,null),e(Do,ftr),e(Do,jd),e(jd,gtr),e(jd,HU),e(HU,htr),e(jd,utr),e(jd,JU),e(JU,ptr),e(jd,_tr),e(Do,btr),e(Do,w$),e(w$,vtr),e(w$,mTe),e(mTe,Ftr),e(w$,Ttr),e(Do,Mtr),e(Do,Ct),M(A$,Ct,null),e(Ct,Etr),e(Ct,fTe),e(fTe,Ctr),e(Ct,wtr),e(Ct,Dd),e(Dd,Atr),e(Dd,gTe),e(gTe,Ltr),e(Dd,ytr),e(Dd,YU),e(YU,xtr),e(Dd,$tr),e(Ct,ktr),M(VF,Ct,null),e(Do,Str),e(Do,ao),M(L$,ao,null),e(ao,Rtr),e(ao,hTe),e(hTe,Ptr),e(ao,Btr),e(ao,nn),e(nn,Itr),e(nn,uTe),e(uTe,Ntr),e(nn,qtr),e(nn,pTe),e(pTe,jtr),e(nn,Dtr),e(nn,_Te),e(_Te,Gtr),e(nn,Otr),e(ao,Vtr),e(ao,N),e(N,XF),e(XF,bTe),e(bTe,Xtr),e(XF,ztr),e(XF,ZU),e(ZU,Qtr),e(XF,Wtr),e(N,Utr),e(N,zF),e(zF,vTe),e(vTe,Htr),e(zF,Jtr),e(zF,KU),e(KU,Ytr),e(zF,Ztr),e(N,Ktr),e(N,QF),e(QF,FTe),e(FTe,ear),e(QF,oar),e(QF,eH),e(eH,rar),e(QF,tar),e(N,aar),e(N,WF),e(WF,TTe),e(TTe,nar),e(WF,sar),e(WF,oH),e(oH,lar),e(WF,iar),e(N,dar),e(N,UF),e(UF,MTe),e(MTe,car),e(UF,mar),e(UF,rH),e(rH,far),e(UF,gar),e(N,har),e(N,HF),e(HF,ETe),e(ETe,uar),e(HF,par),e(HF,tH),e(tH,_ar),e(HF,bar),e(N,Far),e(N,JF),e(JF,CTe),e(CTe,Tar),e(JF,Mar),e(JF,aH),e(aH,Ear),e(JF,Car),e(N,war),e(N,YF),e(YF,wTe),e(wTe,Aar),e(YF,Lar),e(YF,nH),e(nH,yar),e(YF,xar),e(N,$ar),e(N,ZF),e(ZF,ATe),e(ATe,kar),e(ZF,Sar),e(ZF,sH),e(sH,Rar),e(ZF,Par),e(N,Bar),e(N,KF),e(KF,LTe),e(LTe,Iar),e(KF,Nar),e(KF,lH),e(lH,qar),e(KF,jar),e(N,Dar),e(N,eT),e(eT,yTe),e(yTe,Gar),e(eT,Oar),e(eT,iH),e(iH,Var),e(eT,Xar),e(N,zar),e(N,oT),e(oT,xTe),e(xTe,Qar),e(oT,War),e(oT,dH),e(dH,Uar),e(oT,Har),e(N,Jar),e(N,rT),e(rT,$Te),e($Te,Yar),e(rT,Zar),e(rT,cH),e(cH,Kar),e(rT,enr),e(N,onr),e(N,tT),e(tT,kTe),e(kTe,rnr),e(tT,tnr),e(tT,mH),e(mH,anr),e(tT,nnr),e(N,snr),e(N,aT),e(aT,STe),e(STe,lnr),e(aT,inr),e(aT,fH),e(fH,dnr),e(aT,cnr),e(N,mnr),e(N,nT),e(nT,RTe),e(RTe,fnr),e(nT,gnr),e(nT,gH),e(gH,hnr),e(nT,unr),e(N,pnr),e(N,sT),e(sT,PTe),e(PTe,_nr),e(sT,bnr),e(sT,hH),e(hH,vnr),e(sT,Fnr),e(N,Tnr),e(N,lT),e(lT,BTe),e(BTe,Mnr),e(lT,Enr),e(lT,uH),e(uH,Cnr),e(lT,wnr),e(N,Anr),e(N,iT),e(iT,ITe),e(ITe,Lnr),e(iT,ynr),e(iT,pH),e(pH,xnr),e(iT,$nr),e(N,knr),e(N,dT),e(dT,NTe),e(NTe,Snr),e(dT,Rnr),e(dT,_H),e(_H,Pnr),e(dT,Bnr),e(N,Inr),e(N,cT),e(cT,qTe),e(qTe,Nnr),e(cT,qnr),e(cT,bH),e(bH,jnr),e(cT,Dnr),e(N,Gnr),e(N,mT),e(mT,jTe),e(jTe,Onr),e(mT,Vnr),e(mT,vH),e(vH,Xnr),e(mT,znr),e(N,Qnr),e(N,fT),e(fT,DTe),e(DTe,Wnr),e(fT,Unr),e(fT,FH),e(FH,Hnr),e(fT,Jnr),e(N,Ynr),e(N,gT),e(gT,GTe),e(GTe,Znr),e(gT,Knr),e(gT,TH),e(TH,esr),e(gT,osr),e(N,rsr),e(N,hT),e(hT,OTe),e(OTe,tsr),e(hT,asr),e(hT,MH),e(MH,nsr),e(hT,ssr),e(N,lsr),e(N,uT),e(uT,VTe),e(VTe,isr),e(uT,dsr),e(uT,EH),e(EH,csr),e(uT,msr),e(N,fsr),e(N,pT),e(pT,XTe),e(XTe,gsr),e(pT,hsr),e(pT,CH),e(CH,usr),e(pT,psr),e(N,_sr),e(N,_T),e(_T,zTe),e(zTe,bsr),e(_T,vsr),e(_T,wH),e(wH,Fsr),e(_T,Tsr),e(N,Msr),e(N,bT),e(bT,QTe),e(QTe,Esr),e(bT,Csr),e(bT,AH),e(AH,wsr),e(bT,Asr),e(N,Lsr),e(N,vT),e(vT,WTe),e(WTe,ysr),e(vT,xsr),e(vT,LH),e(LH,$sr),e(vT,ksr),e(N,Ssr),e(N,FT),e(FT,UTe),e(UTe,Rsr),e(FT,Psr),e(FT,yH),e(yH,Bsr),e(FT,Isr),e(N,Nsr),e(N,TT),e(TT,HTe),e(HTe,qsr),e(TT,jsr),e(TT,xH),e(xH,Dsr),e(TT,Gsr),e(N,Osr),e(N,MT),e(MT,JTe),e(JTe,Vsr),e(MT,Xsr),e(MT,$H),e($H,zsr),e(MT,Qsr),e(N,Wsr),e(N,ET),e(ET,YTe),e(YTe,Usr),e(ET,Hsr),e(ET,kH),e(kH,Jsr),e(ET,Ysr),e(N,Zsr),e(N,CT),e(CT,ZTe),e(ZTe,Ksr),e(CT,elr),e(CT,SH),e(SH,olr),e(CT,rlr),e(N,tlr),e(N,wT),e(wT,KTe),e(KTe,alr),e(wT,nlr),e(wT,RH),e(RH,slr),e(wT,llr),e(N,ilr),e(N,AT),e(AT,eMe),e(eMe,dlr),e(AT,clr),e(AT,PH),e(PH,mlr),e(AT,flr),e(N,glr),e(N,LT),e(LT,oMe),e(oMe,hlr),e(LT,ulr),e(LT,BH),e(BH,plr),e(LT,_lr),e(N,blr),e(N,yT),e(yT,rMe),e(rMe,vlr),e(yT,Flr),e(yT,IH),e(IH,Tlr),e(yT,Mlr),e(N,Elr),e(N,xT),e(xT,tMe),e(tMe,Clr),e(xT,wlr),e(xT,NH),e(NH,Alr),e(xT,Llr),e(N,ylr),e(N,$T),e($T,aMe),e(aMe,xlr),e($T,$lr),e($T,qH),e(qH,klr),e($T,Slr),e(N,Rlr),e(N,kT),e(kT,nMe),e(nMe,Plr),e(kT,Blr),e(kT,jH),e(jH,Ilr),e(kT,Nlr),e(N,qlr),e(N,ST),e(ST,sMe),e(sMe,jlr),e(ST,Dlr),e(ST,DH),e(DH,Glr),e(ST,Olr),e(N,Vlr),e(N,RT),e(RT,lMe),e(lMe,Xlr),e(RT,zlr),e(RT,GH),e(GH,Qlr),e(RT,Wlr),e(N,Ulr),e(N,PT),e(PT,iMe),e(iMe,Hlr),e(PT,Jlr),e(PT,OH),e(OH,Ylr),e(PT,Zlr),e(N,Klr),e(N,BT),e(BT,dMe),e(dMe,eir),e(BT,oir),e(BT,VH),e(VH,rir),e(BT,tir),e(N,air),e(N,IT),e(IT,cMe),e(cMe,nir),e(IT,sir),e(IT,XH),e(XH,lir),e(IT,iir),e(N,dir),e(N,NT),e(NT,mMe),e(mMe,cir),e(NT,mir),e(NT,zH),e(zH,fir),e(NT,gir),e(N,hir),e(N,qT),e(qT,fMe),e(fMe,uir),e(qT,pir),e(qT,QH),e(QH,_ir),e(qT,bir),e(N,vir),e(N,jT),e(jT,gMe),e(gMe,Fir),e(jT,Tir),e(jT,WH),e(WH,Mir),e(jT,Eir),e(N,Cir),e(N,DT),e(DT,hMe),e(hMe,wir),e(DT,Air),e(DT,UH),e(UH,Lir),e(DT,yir),e(N,xir),e(N,GT),e(GT,uMe),e(uMe,$ir),e(GT,kir),e(GT,HH),e(HH,Sir),e(GT,Rir),e(N,Pir),e(N,OT),e(OT,pMe),e(pMe,Bir),e(OT,Iir),e(OT,JH),e(JH,Nir),e(OT,qir),e(N,jir),e(N,VT),e(VT,_Me),e(_Me,Dir),e(VT,Gir),e(VT,YH),e(YH,Oir),e(VT,Vir),e(N,Xir),e(N,XT),e(XT,bMe),e(bMe,zir),e(XT,Qir),e(XT,ZH),e(ZH,Wir),e(XT,Uir),e(ao,Hir),e(ao,zT),e(zT,Jir),e(zT,vMe),e(vMe,Yir),e(zT,Zir),e(zT,FMe),e(FMe,Kir),e(ao,edr),M(QT,ao,null),b(m,Roo,_),b(m,Gd,_),e(Gd,WT),e(WT,TMe),M(y$,TMe,null),e(Gd,odr),e(Gd,MMe),e(MMe,rdr),b(m,Poo,_),b(m,Go,_),M(x$,Go,null),e(Go,tdr),e(Go,Od),e(Od,adr),e(Od,KH),e(KH,ndr),e(Od,sdr),e(Od,eJ),e(eJ,ldr),e(Od,idr),e(Go,ddr),e(Go,$$),e($$,cdr),e($$,EMe),e(EMe,mdr),e($$,fdr),e(Go,gdr),e(Go,wt),M(k$,wt,null),e(wt,hdr),e(wt,CMe),e(CMe,udr),e(wt,pdr),e(wt,Vd),e(Vd,_dr),e(Vd,wMe),e(wMe,bdr),e(Vd,vdr),e(Vd,oJ),e(oJ,Fdr),e(Vd,Tdr),e(wt,Mdr),M(UT,wt,null),e(Go,Edr),e(Go,no),M(S$,no,null),e(no,Cdr),e(no,AMe),e(AMe,wdr),e(no,Adr),e(no,sn),e(sn,Ldr),e(sn,LMe),e(LMe,ydr),e(sn,xdr),e(sn,yMe),e(yMe,$dr),e(sn,kdr),e(sn,xMe),e(xMe,Sdr),e(sn,Rdr),e(no,Pdr),e(no,K),e(K,HT),e(HT,$Me),e($Me,Bdr),e(HT,Idr),e(HT,rJ),e(rJ,Ndr),e(HT,qdr),e(K,jdr),e(K,JT),e(JT,kMe),e(kMe,Ddr),e(JT,Gdr),e(JT,tJ),e(tJ,Odr),e(JT,Vdr),e(K,Xdr),e(K,YT),e(YT,SMe),e(SMe,zdr),e(YT,Qdr),e(YT,aJ),e(aJ,Wdr),e(YT,Udr),e(K,Hdr),e(K,ZT),e(ZT,RMe),e(RMe,Jdr),e(ZT,Ydr),e(ZT,nJ),e(nJ,Zdr),e(ZT,Kdr),e(K,ecr),e(K,KT),e(KT,PMe),e(PMe,ocr),e(KT,rcr),e(KT,sJ),e(sJ,tcr),e(KT,acr),e(K,ncr),e(K,eM),e(eM,BMe),e(BMe,scr),e(eM,lcr),e(eM,lJ),e(lJ,icr),e(eM,dcr),e(K,ccr),e(K,oM),e(oM,IMe),e(IMe,mcr),e(oM,fcr),e(oM,iJ),e(iJ,gcr),e(oM,hcr),e(K,ucr),e(K,rM),e(rM,NMe),e(NMe,pcr),e(rM,_cr),e(rM,dJ),e(dJ,bcr),e(rM,vcr),e(K,Fcr),e(K,tM),e(tM,qMe),e(qMe,Tcr),e(tM,Mcr),e(tM,cJ),e(cJ,Ecr),e(tM,Ccr),e(K,wcr),e(K,aM),e(aM,jMe),e(jMe,Acr),e(aM,Lcr),e(aM,mJ),e(mJ,ycr),e(aM,xcr),e(K,$cr),e(K,nM),e(nM,DMe),e(DMe,kcr),e(nM,Scr),e(nM,fJ),e(fJ,Rcr),e(nM,Pcr),e(K,Bcr),e(K,sM),e(sM,GMe),e(GMe,Icr),e(sM,Ncr),e(sM,gJ),e(gJ,qcr),e(sM,jcr),e(K,Dcr),e(K,lM),e(lM,OMe),e(OMe,Gcr),e(lM,Ocr),e(lM,hJ),e(hJ,Vcr),e(lM,Xcr),e(K,zcr),e(K,iM),e(iM,VMe),e(VMe,Qcr),e(iM,Wcr),e(iM,uJ),e(uJ,Ucr),e(iM,Hcr),e(K,Jcr),e(K,dM),e(dM,XMe),e(XMe,Ycr),e(dM,Zcr),e(dM,pJ),e(pJ,Kcr),e(dM,emr),e(K,omr),e(K,cM),e(cM,zMe),e(zMe,rmr),e(cM,tmr),e(cM,_J),e(_J,amr),e(cM,nmr),e(K,smr),e(K,mM),e(mM,QMe),e(QMe,lmr),e(mM,imr),e(mM,bJ),e(bJ,dmr),e(mM,cmr),e(K,mmr),e(K,fM),e(fM,WMe),e(WMe,fmr),e(fM,gmr),e(fM,vJ),e(vJ,hmr),e(fM,umr),e(K,pmr),e(K,gM),e(gM,UMe),e(UMe,_mr),e(gM,bmr),e(gM,FJ),e(FJ,vmr),e(gM,Fmr),e(K,Tmr),e(K,hM),e(hM,HMe),e(HMe,Mmr),e(hM,Emr),e(hM,TJ),e(TJ,Cmr),e(hM,wmr),e(K,Amr),e(K,uM),e(uM,JMe),e(JMe,Lmr),e(uM,ymr),e(uM,MJ),e(MJ,xmr),e(uM,$mr),e(K,kmr),e(K,pM),e(pM,YMe),e(YMe,Smr),e(pM,Rmr),e(pM,EJ),e(EJ,Pmr),e(pM,Bmr),e(K,Imr),e(K,_M),e(_M,ZMe),e(ZMe,Nmr),e(_M,qmr),e(_M,CJ),e(CJ,jmr),e(_M,Dmr),e(K,Gmr),e(K,bM),e(bM,KMe),e(KMe,Omr),e(bM,Vmr),e(bM,wJ),e(wJ,Xmr),e(bM,zmr),e(K,Qmr),e(K,vM),e(vM,eEe),e(eEe,Wmr),e(vM,Umr),e(vM,AJ),e(AJ,Hmr),e(vM,Jmr),e(K,Ymr),e(K,FM),e(FM,oEe),e(oEe,Zmr),e(FM,Kmr),e(FM,LJ),e(LJ,efr),e(FM,ofr),e(K,rfr),e(K,TM),e(TM,rEe),e(rEe,tfr),e(TM,afr),e(TM,yJ),e(yJ,nfr),e(TM,sfr),e(K,lfr),e(K,MM),e(MM,tEe),e(tEe,ifr),e(MM,dfr),e(MM,xJ),e(xJ,cfr),e(MM,mfr),e(K,ffr),e(K,EM),e(EM,aEe),e(aEe,gfr),e(EM,hfr),e(EM,$J),e($J,ufr),e(EM,pfr),e(K,_fr),e(K,CM),e(CM,nEe),e(nEe,bfr),e(CM,vfr),e(CM,kJ),e(kJ,Ffr),e(CM,Tfr),e(K,Mfr),e(K,wM),e(wM,sEe),e(sEe,Efr),e(wM,Cfr),e(wM,SJ),e(SJ,wfr),e(wM,Afr),e(K,Lfr),e(K,AM),e(AM,lEe),e(lEe,yfr),e(AM,xfr),e(AM,RJ),e(RJ,$fr),e(AM,kfr),e(no,Sfr),e(no,LM),e(LM,Rfr),e(LM,iEe),e(iEe,Pfr),e(LM,Bfr),e(LM,dEe),e(dEe,Ifr),e(no,Nfr),M(yM,no,null),b(m,Boo,_),b(m,Xd,_),e(Xd,xM),e(xM,cEe),M(R$,cEe,null),e(Xd,qfr),e(Xd,mEe),e(mEe,jfr),b(m,Ioo,_),b(m,Oo,_),M(P$,Oo,null),e(Oo,Dfr),e(Oo,zd),e(zd,Gfr),e(zd,PJ),e(PJ,Ofr),e(zd,Vfr),e(zd,BJ),e(BJ,Xfr),e(zd,zfr),e(Oo,Qfr),e(Oo,B$),e(B$,Wfr),e(B$,fEe),e(fEe,Ufr),e(B$,Hfr),e(Oo,Jfr),e(Oo,At),M(I$,At,null),e(At,Yfr),e(At,gEe),e(gEe,Zfr),e(At,Kfr),e(At,Qd),e(Qd,egr),e(Qd,hEe),e(hEe,ogr),e(Qd,rgr),e(Qd,IJ),e(IJ,tgr),e(Qd,agr),e(At,ngr),M($M,At,null),e(Oo,sgr),e(Oo,so),M(N$,so,null),e(so,lgr),e(so,uEe),e(uEe,igr),e(so,dgr),e(so,ln),e(ln,cgr),e(ln,pEe),e(pEe,mgr),e(ln,fgr),e(ln,_Ee),e(_Ee,ggr),e(ln,hgr),e(ln,bEe),e(bEe,ugr),e(ln,pgr),e(so,_gr),e(so,Ue),e(Ue,kM),e(kM,vEe),e(vEe,bgr),e(kM,vgr),e(kM,NJ),e(NJ,Fgr),e(kM,Tgr),e(Ue,Mgr),e(Ue,SM),e(SM,FEe),e(FEe,Egr),e(SM,Cgr),e(SM,qJ),e(qJ,wgr),e(SM,Agr),e(Ue,Lgr),e(Ue,RM),e(RM,TEe),e(TEe,ygr),e(RM,xgr),e(RM,jJ),e(jJ,$gr),e(RM,kgr),e(Ue,Sgr),e(Ue,PM),e(PM,MEe),e(MEe,Rgr),e(PM,Pgr),e(PM,DJ),e(DJ,Bgr),e(PM,Igr),e(Ue,Ngr),e(Ue,BM),e(BM,EEe),e(EEe,qgr),e(BM,jgr),e(BM,GJ),e(GJ,Dgr),e(BM,Ggr),e(Ue,Ogr),e(Ue,IM),e(IM,CEe),e(CEe,Vgr),e(IM,Xgr),e(IM,OJ),e(OJ,zgr),e(IM,Qgr),e(Ue,Wgr),e(Ue,NM),e(NM,wEe),e(wEe,Ugr),e(NM,Hgr),e(NM,VJ),e(VJ,Jgr),e(NM,Ygr),e(so,Zgr),e(so,qM),e(qM,Kgr),e(qM,AEe),e(AEe,ehr),e(qM,ohr),e(qM,LEe),e(LEe,rhr),e(so,thr),M(jM,so,null),b(m,Noo,_),b(m,Wd,_),e(Wd,DM),e(DM,yEe),M(q$,yEe,null),e(Wd,ahr),e(Wd,xEe),e(xEe,nhr),b(m,qoo,_),b(m,Vo,_),M(j$,Vo,null),e(Vo,shr),e(Vo,Ud),e(Ud,lhr),e(Ud,XJ),e(XJ,ihr),e(Ud,dhr),e(Ud,zJ),e(zJ,chr),e(Ud,mhr),e(Vo,fhr),e(Vo,D$),e(D$,ghr),e(D$,$Ee),e($Ee,hhr),e(D$,uhr),e(Vo,phr),e(Vo,Lt),M(G$,Lt,null),e(Lt,_hr),e(Lt,kEe),e(kEe,bhr),e(Lt,vhr),e(Lt,Hd),e(Hd,Fhr),e(Hd,SEe),e(SEe,Thr),e(Hd,Mhr),e(Hd,QJ),e(QJ,Ehr),e(Hd,Chr),e(Lt,whr),M(GM,Lt,null),e(Vo,Ahr),e(Vo,lo),M(O$,lo,null),e(lo,Lhr),e(lo,REe),e(REe,yhr),e(lo,xhr),e(lo,dn),e(dn,$hr),e(dn,PEe),e(PEe,khr),e(dn,Shr),e(dn,BEe),e(BEe,Rhr),e(dn,Phr),e(dn,IEe),e(IEe,Bhr),e(dn,Ihr),e(lo,Nhr),e(lo,H),e(H,OM),e(OM,NEe),e(NEe,qhr),e(OM,jhr),e(OM,WJ),e(WJ,Dhr),e(OM,Ghr),e(H,Ohr),e(H,VM),e(VM,qEe),e(qEe,Vhr),e(VM,Xhr),e(VM,UJ),e(UJ,zhr),e(VM,Qhr),e(H,Whr),e(H,XM),e(XM,jEe),e(jEe,Uhr),e(XM,Hhr),e(XM,HJ),e(HJ,Jhr),e(XM,Yhr),e(H,Zhr),e(H,zM),e(zM,DEe),e(DEe,Khr),e(zM,eur),e(zM,JJ),e(JJ,our),e(zM,rur),e(H,tur),e(H,QM),e(QM,GEe),e(GEe,aur),e(QM,nur),e(QM,YJ),e(YJ,sur),e(QM,lur),e(H,iur),e(H,WM),e(WM,OEe),e(OEe,dur),e(WM,cur),e(WM,ZJ),e(ZJ,mur),e(WM,fur),e(H,gur),e(H,UM),e(UM,VEe),e(VEe,hur),e(UM,uur),e(UM,KJ),e(KJ,pur),e(UM,_ur),e(H,bur),e(H,HM),e(HM,XEe),e(XEe,vur),e(HM,Fur),e(HM,eY),e(eY,Tur),e(HM,Mur),e(H,Eur),e(H,JM),e(JM,zEe),e(zEe,Cur),e(JM,wur),e(JM,oY),e(oY,Aur),e(JM,Lur),e(H,yur),e(H,YM),e(YM,QEe),e(QEe,xur),e(YM,$ur),e(YM,rY),e(rY,kur),e(YM,Sur),e(H,Rur),e(H,ZM),e(ZM,WEe),e(WEe,Pur),e(ZM,Bur),e(ZM,tY),e(tY,Iur),e(ZM,Nur),e(H,qur),e(H,KM),e(KM,UEe),e(UEe,jur),e(KM,Dur),e(KM,aY),e(aY,Gur),e(KM,Our),e(H,Vur),e(H,eE),e(eE,HEe),e(HEe,Xur),e(eE,zur),e(eE,nY),e(nY,Qur),e(eE,Wur),e(H,Uur),e(H,oE),e(oE,JEe),e(JEe,Hur),e(oE,Jur),e(oE,sY),e(sY,Yur),e(oE,Zur),e(H,Kur),e(H,rE),e(rE,YEe),e(YEe,epr),e(rE,opr),e(rE,lY),e(lY,rpr),e(rE,tpr),e(H,apr),e(H,tE),e(tE,ZEe),e(ZEe,npr),e(tE,spr),e(tE,iY),e(iY,lpr),e(tE,ipr),e(H,dpr),e(H,aE),e(aE,KEe),e(KEe,cpr),e(aE,mpr),e(aE,dY),e(dY,fpr),e(aE,gpr),e(H,hpr),e(H,nE),e(nE,e4e),e(e4e,upr),e(nE,ppr),e(nE,cY),e(cY,_pr),e(nE,bpr),e(H,vpr),e(H,sE),e(sE,o4e),e(o4e,Fpr),e(sE,Tpr),e(sE,mY),e(mY,Mpr),e(sE,Epr),e(H,Cpr),e(H,lE),e(lE,r4e),e(r4e,wpr),e(lE,Apr),e(lE,fY),e(fY,Lpr),e(lE,ypr),e(H,xpr),e(H,iE),e(iE,t4e),e(t4e,$pr),e(iE,kpr),e(iE,gY),e(gY,Spr),e(iE,Rpr),e(H,Ppr),e(H,dE),e(dE,a4e),e(a4e,Bpr),e(dE,Ipr),e(dE,hY),e(hY,Npr),e(dE,qpr),e(H,jpr),e(H,cE),e(cE,n4e),e(n4e,Dpr),e(cE,Gpr),e(cE,uY),e(uY,Opr),e(cE,Vpr),e(H,Xpr),e(H,mE),e(mE,s4e),e(s4e,zpr),e(mE,Qpr),e(mE,pY),e(pY,Wpr),e(mE,Upr),e(H,Hpr),e(H,fE),e(fE,l4e),e(l4e,Jpr),e(fE,Ypr),e(fE,_Y),e(_Y,Zpr),e(fE,Kpr),e(H,e_r),e(H,gE),e(gE,i4e),e(i4e,o_r),e(gE,r_r),e(gE,bY),e(bY,t_r),e(gE,a_r),e(H,n_r),e(H,hE),e(hE,d4e),e(d4e,s_r),e(hE,l_r),e(hE,vY),e(vY,i_r),e(hE,d_r),e(H,c_r),e(H,uE),e(uE,c4e),e(c4e,m_r),e(uE,f_r),e(uE,FY),e(FY,g_r),e(uE,h_r),e(H,u_r),e(H,pE),e(pE,m4e),e(m4e,p_r),e(pE,__r),e(pE,TY),e(TY,b_r),e(pE,v_r),e(H,F_r),e(H,_E),e(_E,f4e),e(f4e,T_r),e(_E,M_r),e(_E,MY),e(MY,E_r),e(_E,C_r),e(H,w_r),e(H,bE),e(bE,g4e),e(g4e,A_r),e(bE,L_r),e(bE,EY),e(EY,y_r),e(bE,x_r),e(H,$_r),e(H,vE),e(vE,h4e),e(h4e,k_r),e(vE,S_r),e(vE,CY),e(CY,R_r),e(vE,P_r),e(H,B_r),e(H,FE),e(FE,u4e),e(u4e,I_r),e(FE,N_r),e(FE,wY),e(wY,q_r),e(FE,j_r),e(H,D_r),e(H,TE),e(TE,p4e),e(p4e,G_r),e(TE,O_r),e(TE,AY),e(AY,V_r),e(TE,X_r),e(H,z_r),e(H,ME),e(ME,_4e),e(_4e,Q_r),e(ME,W_r),e(ME,LY),e(LY,U_r),e(ME,H_r),e(H,J_r),e(H,EE),e(EE,b4e),e(b4e,Y_r),e(EE,Z_r),e(EE,yY),e(yY,K_r),e(EE,e1r),e(H,o1r),e(H,CE),e(CE,v4e),e(v4e,r1r),e(CE,t1r),e(CE,xY),e(xY,a1r),e(CE,n1r),e(H,s1r),e(H,wE),e(wE,F4e),e(F4e,l1r),e(wE,i1r),e(wE,$Y),e($Y,d1r),e(wE,c1r),e(H,m1r),e(H,AE),e(AE,T4e),e(T4e,f1r),e(AE,g1r),e(AE,kY),e(kY,h1r),e(AE,u1r),e(H,p1r),e(H,LE),e(LE,M4e),e(M4e,_1r),e(LE,b1r),e(LE,SY),e(SY,v1r),e(LE,F1r),e(lo,T1r),e(lo,yE),e(yE,M1r),e(yE,E4e),e(E4e,E1r),e(yE,C1r),e(yE,C4e),e(C4e,w1r),e(lo,A1r),M(xE,lo,null),b(m,joo,_),b(m,Jd,_),e(Jd,$E),e($E,w4e),M(V$,w4e,null),e(Jd,L1r),e(Jd,A4e),e(A4e,y1r),b(m,Doo,_),b(m,Xo,_),M(X$,Xo,null),e(Xo,x1r),e(Xo,Yd),e(Yd,$1r),e(Yd,RY),e(RY,k1r),e(Yd,S1r),e(Yd,PY),e(PY,R1r),e(Yd,P1r),e(Xo,B1r),e(Xo,z$),e(z$,I1r),e(z$,L4e),e(L4e,N1r),e(z$,q1r),e(Xo,j1r),e(Xo,yt),M(Q$,yt,null),e(yt,D1r),e(yt,y4e),e(y4e,G1r),e(yt,O1r),e(yt,Zd),e(Zd,V1r),e(Zd,x4e),e(x4e,X1r),e(Zd,z1r),e(Zd,BY),e(BY,Q1r),e(Zd,W1r),e(yt,U1r),M(kE,yt,null),e(Xo,H1r),e(Xo,io),M(W$,io,null),e(io,J1r),e(io,$4e),e($4e,Y1r),e(io,Z1r),e(io,cn),e(cn,K1r),e(cn,k4e),e(k4e,ebr),e(cn,obr),e(cn,S4e),e(S4e,rbr),e(cn,tbr),e(cn,R4e),e(R4e,abr),e(cn,nbr),e(io,sbr),e(io,O),e(O,SE),e(SE,P4e),e(P4e,lbr),e(SE,ibr),e(SE,IY),e(IY,dbr),e(SE,cbr),e(O,mbr),e(O,RE),e(RE,B4e),e(B4e,fbr),e(RE,gbr),e(RE,NY),e(NY,hbr),e(RE,ubr),e(O,pbr),e(O,PE),e(PE,I4e),e(I4e,_br),e(PE,bbr),e(PE,qY),e(qY,vbr),e(PE,Fbr),e(O,Tbr),e(O,BE),e(BE,N4e),e(N4e,Mbr),e(BE,Ebr),e(BE,jY),e(jY,Cbr),e(BE,wbr),e(O,Abr),e(O,IE),e(IE,q4e),e(q4e,Lbr),e(IE,ybr),e(IE,DY),e(DY,xbr),e(IE,$br),e(O,kbr),e(O,NE),e(NE,j4e),e(j4e,Sbr),e(NE,Rbr),e(NE,GY),e(GY,Pbr),e(NE,Bbr),e(O,Ibr),e(O,qE),e(qE,D4e),e(D4e,Nbr),e(qE,qbr),e(qE,OY),e(OY,jbr),e(qE,Dbr),e(O,Gbr),e(O,jE),e(jE,G4e),e(G4e,Obr),e(jE,Vbr),e(jE,VY),e(VY,Xbr),e(jE,zbr),e(O,Qbr),e(O,DE),e(DE,O4e),e(O4e,Wbr),e(DE,Ubr),e(DE,XY),e(XY,Hbr),e(DE,Jbr),e(O,Ybr),e(O,GE),e(GE,V4e),e(V4e,Zbr),e(GE,Kbr),e(GE,zY),e(zY,e2r),e(GE,o2r),e(O,r2r),e(O,OE),e(OE,X4e),e(X4e,t2r),e(OE,a2r),e(OE,QY),e(QY,n2r),e(OE,s2r),e(O,l2r),e(O,VE),e(VE,z4e),e(z4e,i2r),e(VE,d2r),e(VE,WY),e(WY,c2r),e(VE,m2r),e(O,f2r),e(O,XE),e(XE,Q4e),e(Q4e,g2r),e(XE,h2r),e(XE,UY),e(UY,u2r),e(XE,p2r),e(O,_2r),e(O,zE),e(zE,W4e),e(W4e,b2r),e(zE,v2r),e(zE,HY),e(HY,F2r),e(zE,T2r),e(O,M2r),e(O,QE),e(QE,U4e),e(U4e,E2r),e(QE,C2r),e(QE,JY),e(JY,w2r),e(QE,A2r),e(O,L2r),e(O,WE),e(WE,H4e),e(H4e,y2r),e(WE,x2r),e(WE,YY),e(YY,$2r),e(WE,k2r),e(O,S2r),e(O,UE),e(UE,J4e),e(J4e,R2r),e(UE,P2r),e(UE,ZY),e(ZY,B2r),e(UE,I2r),e(O,N2r),e(O,HE),e(HE,Y4e),e(Y4e,q2r),e(HE,j2r),e(HE,KY),e(KY,D2r),e(HE,G2r),e(O,O2r),e(O,JE),e(JE,Z4e),e(Z4e,V2r),e(JE,X2r),e(JE,eZ),e(eZ,z2r),e(JE,Q2r),e(O,W2r),e(O,YE),e(YE,K4e),e(K4e,U2r),e(YE,H2r),e(YE,oZ),e(oZ,J2r),e(YE,Y2r),e(O,Z2r),e(O,ZE),e(ZE,eCe),e(eCe,K2r),e(ZE,evr),e(ZE,rZ),e(rZ,ovr),e(ZE,rvr),e(O,tvr),e(O,KE),e(KE,oCe),e(oCe,avr),e(KE,nvr),e(KE,tZ),e(tZ,svr),e(KE,lvr),e(O,ivr),e(O,e4),e(e4,rCe),e(rCe,dvr),e(e4,cvr),e(e4,aZ),e(aZ,mvr),e(e4,fvr),e(O,gvr),e(O,o4),e(o4,tCe),e(tCe,hvr),e(o4,uvr),e(o4,nZ),e(nZ,pvr),e(o4,_vr),e(O,bvr),e(O,r4),e(r4,aCe),e(aCe,vvr),e(r4,Fvr),e(r4,sZ),e(sZ,Tvr),e(r4,Mvr),e(O,Evr),e(O,t4),e(t4,nCe),e(nCe,Cvr),e(t4,wvr),e(t4,lZ),e(lZ,Avr),e(t4,Lvr),e(O,yvr),e(O,a4),e(a4,sCe),e(sCe,xvr),e(a4,$vr),e(a4,iZ),e(iZ,kvr),e(a4,Svr),e(O,Rvr),e(O,n4),e(n4,lCe),e(lCe,Pvr),e(n4,Bvr),e(n4,dZ),e(dZ,Ivr),e(n4,Nvr),e(O,qvr),e(O,s4),e(s4,iCe),e(iCe,jvr),e(s4,Dvr),e(s4,cZ),e(cZ,Gvr),e(s4,Ovr),e(O,Vvr),e(O,l4),e(l4,dCe),e(dCe,Xvr),e(l4,zvr),e(l4,mZ),e(mZ,Qvr),e(l4,Wvr),e(O,Uvr),e(O,i4),e(i4,cCe),e(cCe,Hvr),e(i4,Jvr),e(i4,fZ),e(fZ,Yvr),e(i4,Zvr),e(O,Kvr),e(O,d4),e(d4,mCe),e(mCe,eFr),e(d4,oFr),e(d4,gZ),e(gZ,rFr),e(d4,tFr),e(O,aFr),e(O,c4),e(c4,fCe),e(fCe,nFr),e(c4,sFr),e(c4,hZ),e(hZ,lFr),e(c4,iFr),e(O,dFr),e(O,m4),e(m4,gCe),e(gCe,cFr),e(m4,mFr),e(m4,uZ),e(uZ,fFr),e(m4,gFr),e(O,hFr),e(O,f4),e(f4,hCe),e(hCe,uFr),e(f4,pFr),e(f4,pZ),e(pZ,_Fr),e(f4,bFr),e(O,vFr),e(O,g4),e(g4,uCe),e(uCe,FFr),e(g4,TFr),e(g4,_Z),e(_Z,MFr),e(g4,EFr),e(O,CFr),e(O,h4),e(h4,pCe),e(pCe,wFr),e(h4,AFr),e(h4,bZ),e(bZ,LFr),e(h4,yFr),e(O,xFr),e(O,u4),e(u4,_Ce),e(_Ce,$Fr),e(u4,kFr),e(u4,vZ),e(vZ,SFr),e(u4,RFr),e(O,PFr),e(O,p4),e(p4,bCe),e(bCe,BFr),e(p4,IFr),e(p4,FZ),e(FZ,NFr),e(p4,qFr),e(O,jFr),e(O,_4),e(_4,vCe),e(vCe,DFr),e(_4,GFr),e(_4,TZ),e(TZ,OFr),e(_4,VFr),e(O,XFr),e(O,b4),e(b4,FCe),e(FCe,zFr),e(b4,QFr),e(b4,MZ),e(MZ,WFr),e(b4,UFr),e(O,HFr),e(O,v4),e(v4,TCe),e(TCe,JFr),e(v4,YFr),e(v4,EZ),e(EZ,ZFr),e(v4,KFr),e(O,eTr),e(O,F4),e(F4,MCe),e(MCe,oTr),e(F4,rTr),e(F4,CZ),e(CZ,tTr),e(F4,aTr),e(O,nTr),e(O,T4),e(T4,ECe),e(ECe,sTr),e(T4,lTr),e(T4,wZ),e(wZ,iTr),e(T4,dTr),e(O,cTr),e(O,M4),e(M4,CCe),e(CCe,mTr),e(M4,fTr),e(M4,AZ),e(AZ,gTr),e(M4,hTr),e(O,uTr),e(O,E4),e(E4,wCe),e(wCe,pTr),e(E4,_Tr),e(E4,LZ),e(LZ,bTr),e(E4,vTr),e(O,FTr),e(O,C4),e(C4,ACe),e(ACe,TTr),e(C4,MTr),e(C4,yZ),e(yZ,ETr),e(C4,CTr),e(io,wTr),e(io,w4),e(w4,ATr),e(w4,LCe),e(LCe,LTr),e(w4,yTr),e(w4,yCe),e(yCe,xTr),e(io,$Tr),M(A4,io,null),b(m,Goo,_),b(m,Kd,_),e(Kd,L4),e(L4,xCe),M(U$,xCe,null),e(Kd,kTr),e(Kd,$Ce),e($Ce,STr),b(m,Ooo,_),b(m,zo,_),M(H$,zo,null),e(zo,RTr),e(zo,ec),e(ec,PTr),e(ec,xZ),e(xZ,BTr),e(ec,ITr),e(ec,$Z),e($Z,NTr),e(ec,qTr),e(zo,jTr),e(zo,J$),e(J$,DTr),e(J$,kCe),e(kCe,GTr),e(J$,OTr),e(zo,VTr),e(zo,xt),M(Y$,xt,null),e(xt,XTr),e(xt,SCe),e(SCe,zTr),e(xt,QTr),e(xt,oc),e(oc,WTr),e(oc,RCe),e(RCe,UTr),e(oc,HTr),e(oc,kZ),e(kZ,JTr),e(oc,YTr),e(xt,ZTr),M(y4,xt,null),e(zo,KTr),e(zo,co),M(Z$,co,null),e(co,eMr),e(co,PCe),e(PCe,oMr),e(co,rMr),e(co,mn),e(mn,tMr),e(mn,BCe),e(BCe,aMr),e(mn,nMr),e(mn,ICe),e(ICe,sMr),e(mn,lMr),e(mn,NCe),e(NCe,iMr),e(mn,dMr),e(co,cMr),e(co,qCe),e(qCe,x4),e(x4,jCe),e(jCe,mMr),e(x4,fMr),e(x4,SZ),e(SZ,gMr),e(x4,hMr),e(co,uMr),e(co,$4),e($4,pMr),e($4,DCe),e(DCe,_Mr),e($4,bMr),e($4,GCe),e(GCe,vMr),e(co,FMr),M(k4,co,null),b(m,Voo,_),b(m,rc,_),e(rc,S4),e(S4,OCe),M(K$,OCe,null),e(rc,TMr),e(rc,VCe),e(VCe,MMr),b(m,Xoo,_),b(m,Qo,_),M(ek,Qo,null),e(Qo,EMr),e(Qo,tc),e(tc,CMr),e(tc,RZ),e(RZ,wMr),e(tc,AMr),e(tc,PZ),e(PZ,LMr),e(tc,yMr),e(Qo,xMr),e(Qo,ok),e(ok,$Mr),e(ok,XCe),e(XCe,kMr),e(ok,SMr),e(Qo,RMr),e(Qo,$t),M(rk,$t,null),e($t,PMr),e($t,zCe),e(zCe,BMr),e($t,IMr),e($t,ac),e(ac,NMr),e(ac,QCe),e(QCe,qMr),e(ac,jMr),e(ac,BZ),e(BZ,DMr),e(ac,GMr),e($t,OMr),M(R4,$t,null),e(Qo,VMr),e(Qo,mo),M(tk,mo,null),e(mo,XMr),e(mo,WCe),e(WCe,zMr),e(mo,QMr),e(mo,fn),e(fn,WMr),e(fn,UCe),e(UCe,UMr),e(fn,HMr),e(fn,HCe),e(HCe,JMr),e(fn,YMr),e(fn,JCe),e(JCe,ZMr),e(fn,KMr),e(mo,eEr),e(mo,nc),e(nc,P4),e(P4,YCe),e(YCe,oEr),e(P4,rEr),e(P4,IZ),e(IZ,tEr),e(P4,aEr),e(nc,nEr),e(nc,B4),e(B4,ZCe),e(ZCe,sEr),e(B4,lEr),e(B4,NZ),e(NZ,iEr),e(B4,dEr),e(nc,cEr),e(nc,I4),e(I4,KCe),e(KCe,mEr),e(I4,fEr),e(I4,qZ),e(qZ,gEr),e(I4,hEr),e(mo,uEr),e(mo,N4),e(N4,pEr),e(N4,e3e),e(e3e,_Er),e(N4,bEr),e(N4,o3e),e(o3e,vEr),e(mo,FEr),M(q4,mo,null),b(m,zoo,_),b(m,sc,_),e(sc,j4),e(j4,r3e),M(ak,r3e,null),e(sc,TEr),e(sc,t3e),e(t3e,MEr),b(m,Qoo,_),b(m,Wo,_),M(nk,Wo,null),e(Wo,EEr),e(Wo,lc),e(lc,CEr),e(lc,jZ),e(jZ,wEr),e(lc,AEr),e(lc,DZ),e(DZ,LEr),e(lc,yEr),e(Wo,xEr),e(Wo,sk),e(sk,$Er),e(sk,a3e),e(a3e,kEr),e(sk,SEr),e(Wo,REr),e(Wo,kt),M(lk,kt,null),e(kt,PEr),e(kt,n3e),e(n3e,BEr),e(kt,IEr),e(kt,ic),e(ic,NEr),e(ic,s3e),e(s3e,qEr),e(ic,jEr),e(ic,GZ),e(GZ,DEr),e(ic,GEr),e(kt,OEr),M(D4,kt,null),e(Wo,VEr),e(Wo,fo),M(ik,fo,null),e(fo,XEr),e(fo,l3e),e(l3e,zEr),e(fo,QEr),e(fo,gn),e(gn,WEr),e(gn,i3e),e(i3e,UEr),e(gn,HEr),e(gn,d3e),e(d3e,JEr),e(gn,YEr),e(gn,c3e),e(c3e,ZEr),e(gn,KEr),e(fo,e4r),e(fo,be),e(be,G4),e(G4,m3e),e(m3e,o4r),e(G4,r4r),e(G4,OZ),e(OZ,t4r),e(G4,a4r),e(be,n4r),e(be,O4),e(O4,f3e),e(f3e,s4r),e(O4,l4r),e(O4,VZ),e(VZ,i4r),e(O4,d4r),e(be,c4r),e(be,V4),e(V4,g3e),e(g3e,m4r),e(V4,f4r),e(V4,XZ),e(XZ,g4r),e(V4,h4r),e(be,u4r),e(be,X4),e(X4,h3e),e(h3e,p4r),e(X4,_4r),e(X4,zZ),e(zZ,b4r),e(X4,v4r),e(be,F4r),e(be,El),e(El,u3e),e(u3e,T4r),e(El,M4r),e(El,QZ),e(QZ,E4r),e(El,C4r),e(El,WZ),e(WZ,w4r),e(El,A4r),e(be,L4r),e(be,z4),e(z4,p3e),e(p3e,y4r),e(z4,x4r),e(z4,UZ),e(UZ,$4r),e(z4,k4r),e(be,S4r),e(be,Cl),e(Cl,_3e),e(_3e,R4r),e(Cl,P4r),e(Cl,HZ),e(HZ,B4r),e(Cl,I4r),e(Cl,JZ),e(JZ,N4r),e(Cl,q4r),e(be,j4r),e(be,Q4),e(Q4,b3e),e(b3e,D4r),e(Q4,G4r),e(Q4,YZ),e(YZ,O4r),e(Q4,V4r),e(be,X4r),e(be,St),e(St,v3e),e(v3e,z4r),e(St,Q4r),e(St,ZZ),e(ZZ,W4r),e(St,U4r),e(St,KZ),e(KZ,H4r),e(St,J4r),e(St,eK),e(eK,Y4r),e(St,Z4r),e(be,K4r),e(be,W4),e(W4,F3e),e(F3e,eCr),e(W4,oCr),e(W4,oK),e(oK,rCr),e(W4,tCr),e(be,aCr),e(be,U4),e(U4,T3e),e(T3e,nCr),e(U4,sCr),e(U4,rK),e(rK,lCr),e(U4,iCr),e(be,dCr),e(be,H4),e(H4,M3e),e(M3e,cCr),e(H4,mCr),e(H4,tK),e(tK,fCr),e(H4,gCr),e(be,hCr),e(be,J4),e(J4,E3e),e(E3e,uCr),e(J4,pCr),e(J4,aK),e(aK,_Cr),e(J4,bCr),e(be,vCr),e(be,Y4),e(Y4,C3e),e(C3e,FCr),e(Y4,TCr),e(Y4,nK),e(nK,MCr),e(Y4,ECr),e(be,CCr),e(be,Z4),e(Z4,w3e),e(w3e,wCr),e(Z4,ACr),e(Z4,sK),e(sK,LCr),e(Z4,yCr),e(be,xCr),e(be,K4),e(K4,A3e),e(A3e,$Cr),e(K4,kCr),e(K4,lK),e(lK,SCr),e(K4,RCr),e(be,PCr),e(be,eC),e(eC,L3e),e(L3e,BCr),e(eC,ICr),e(eC,iK),e(iK,NCr),e(eC,qCr),e(be,jCr),e(be,oC),e(oC,y3e),e(y3e,DCr),e(oC,GCr),e(oC,dK),e(dK,OCr),e(oC,VCr),e(fo,XCr),e(fo,rC),e(rC,zCr),e(rC,x3e),e(x3e,QCr),e(rC,WCr),e(rC,$3e),e($3e,UCr),e(fo,HCr),M(tC,fo,null),b(m,Woo,_),b(m,dc,_),e(dc,aC),e(aC,k3e),M(dk,k3e,null),e(dc,JCr),e(dc,S3e),e(S3e,YCr),b(m,Uoo,_),b(m,Uo,_),M(ck,Uo,null),e(Uo,ZCr),e(Uo,cc),e(cc,KCr),e(cc,cK),e(cK,e3r),e(cc,o3r),e(cc,mK),e(mK,r3r),e(cc,t3r),e(Uo,a3r),e(Uo,mk),e(mk,n3r),e(mk,R3e),e(R3e,s3r),e(mk,l3r),e(Uo,i3r),e(Uo,Rt),M(fk,Rt,null),e(Rt,d3r),e(Rt,P3e),e(P3e,c3r),e(Rt,m3r),e(Rt,mc),e(mc,f3r),e(mc,B3e),e(B3e,g3r),e(mc,h3r),e(mc,fK),e(fK,u3r),e(mc,p3r),e(Rt,_3r),M(nC,Rt,null),e(Uo,b3r),e(Uo,go),M(gk,go,null),e(go,v3r),e(go,I3e),e(I3e,F3r),e(go,T3r),e(go,hn),e(hn,M3r),e(hn,N3e),e(N3e,E3r),e(hn,C3r),e(hn,q3e),e(q3e,w3r),e(hn,A3r),e(hn,j3e),e(j3e,L3r),e(hn,y3r),e(go,x3r),e(go,D3e),e(D3e,sC),e(sC,G3e),e(G3e,$3r),e(sC,k3r),e(sC,gK),e(gK,S3r),e(sC,R3r),e(go,P3r),e(go,lC),e(lC,B3r),e(lC,O3e),e(O3e,I3r),e(lC,N3r),e(lC,V3e),e(V3e,q3r),e(go,j3r),M(iC,go,null),b(m,Hoo,_),b(m,fc,_),e(fc,dC),e(dC,X3e),M(hk,X3e,null),e(fc,D3r),e(fc,z3e),e(z3e,G3r),b(m,Joo,_),b(m,Ho,_),M(uk,Ho,null),e(Ho,O3r),e(Ho,gc),e(gc,V3r),e(gc,hK),e(hK,X3r),e(gc,z3r),e(gc,uK),e(uK,Q3r),e(gc,W3r),e(Ho,U3r),e(Ho,pk),e(pk,H3r),e(pk,Q3e),e(Q3e,J3r),e(pk,Y3r),e(Ho,Z3r),e(Ho,Pt),M(_k,Pt,null),e(Pt,K3r),e(Pt,W3e),e(W3e,e5r),e(Pt,o5r),e(Pt,hc),e(hc,r5r),e(hc,U3e),e(U3e,t5r),e(hc,a5r),e(hc,pK),e(pK,n5r),e(hc,s5r),e(Pt,l5r),M(cC,Pt,null),e(Ho,i5r),e(Ho,ho),M(bk,ho,null),e(ho,d5r),e(ho,H3e),e(H3e,c5r),e(ho,m5r),e(ho,un),e(un,f5r),e(un,J3e),e(J3e,g5r),e(un,h5r),e(un,Y3e),e(Y3e,u5r),e(un,p5r),e(un,Z3e),e(Z3e,_5r),e(un,b5r),e(ho,v5r),e(ho,K3e),e(K3e,mC),e(mC,e5e),e(e5e,F5r),e(mC,T5r),e(mC,_K),e(_K,M5r),e(mC,E5r),e(ho,C5r),e(ho,fC),e(fC,w5r),e(fC,o5e),e(o5e,A5r),e(fC,L5r),e(fC,r5e),e(r5e,y5r),e(ho,x5r),M(gC,ho,null),b(m,Yoo,_),b(m,uc,_),e(uc,hC),e(hC,t5e),M(vk,t5e,null),e(uc,$5r),e(uc,a5e),e(a5e,k5r),b(m,Zoo,_),b(m,Jo,_),M(Fk,Jo,null),e(Jo,S5r),e(Jo,pc),e(pc,R5r),e(pc,bK),e(bK,P5r),e(pc,B5r),e(pc,vK),e(vK,I5r),e(pc,N5r),e(Jo,q5r),e(Jo,Tk),e(Tk,j5r),e(Tk,n5e),e(n5e,D5r),e(Tk,G5r),e(Jo,O5r),e(Jo,Bt),M(Mk,Bt,null),e(Bt,V5r),e(Bt,s5e),e(s5e,X5r),e(Bt,z5r),e(Bt,_c),e(_c,Q5r),e(_c,l5e),e(l5e,W5r),e(_c,U5r),e(_c,FK),e(FK,H5r),e(_c,J5r),e(Bt,Y5r),M(uC,Bt,null),e(Jo,Z5r),e(Jo,uo),M(Ek,uo,null),e(uo,K5r),e(uo,i5e),e(i5e,e0r),e(uo,o0r),e(uo,pn),e(pn,r0r),e(pn,d5e),e(d5e,t0r),e(pn,a0r),e(pn,c5e),e(c5e,n0r),e(pn,s0r),e(pn,m5e),e(m5e,l0r),e(pn,i0r),e(uo,d0r),e(uo,f5e),e(f5e,pC),e(pC,g5e),e(g5e,c0r),e(pC,m0r),e(pC,TK),e(TK,f0r),e(pC,g0r),e(uo,h0r),e(uo,_C),e(_C,u0r),e(_C,h5e),e(h5e,p0r),e(_C,_0r),e(_C,u5e),e(u5e,b0r),e(uo,v0r),M(bC,uo,null),b(m,Koo,_),b(m,bc,_),e(bc,vC),e(vC,p5e),M(Ck,p5e,null),e(bc,F0r),e(bc,_5e),e(_5e,T0r),b(m,ero,_),b(m,Yo,_),M(wk,Yo,null),e(Yo,M0r),e(Yo,vc),e(vc,E0r),e(vc,MK),e(MK,C0r),e(vc,w0r),e(vc,EK),e(EK,A0r),e(vc,L0r),e(Yo,y0r),e(Yo,Ak),e(Ak,x0r),e(Ak,b5e),e(b5e,$0r),e(Ak,k0r),e(Yo,S0r),e(Yo,It),M(Lk,It,null),e(It,R0r),e(It,v5e),e(v5e,P0r),e(It,B0r),e(It,Fc),e(Fc,I0r),e(Fc,F5e),e(F5e,N0r),e(Fc,q0r),e(Fc,CK),e(CK,j0r),e(Fc,D0r),e(It,G0r),M(FC,It,null),e(Yo,O0r),e(Yo,po),M(yk,po,null),e(po,V0r),e(po,T5e),e(T5e,X0r),e(po,z0r),e(po,_n),e(_n,Q0r),e(_n,M5e),e(M5e,W0r),e(_n,U0r),e(_n,E5e),e(E5e,H0r),e(_n,J0r),e(_n,C5e),e(C5e,Y0r),e(_n,Z0r),e(po,K0r),e(po,Pe),e(Pe,TC),e(TC,w5e),e(w5e,ewr),e(TC,owr),e(TC,wK),e(wK,rwr),e(TC,twr),e(Pe,awr),e(Pe,MC),e(MC,A5e),e(A5e,nwr),e(MC,swr),e(MC,AK),e(AK,lwr),e(MC,iwr),e(Pe,dwr),e(Pe,EC),e(EC,L5e),e(L5e,cwr),e(EC,mwr),e(EC,LK),e(LK,fwr),e(EC,gwr),e(Pe,hwr),e(Pe,CC),e(CC,y5e),e(y5e,uwr),e(CC,pwr),e(CC,yK),e(yK,_wr),e(CC,bwr),e(Pe,vwr),e(Pe,wC),e(wC,x5e),e(x5e,Fwr),e(wC,Twr),e(wC,xK),e(xK,Mwr),e(wC,Ewr),e(Pe,Cwr),e(Pe,AC),e(AC,$5e),e($5e,wwr),e(AC,Awr),e(AC,$K),e($K,Lwr),e(AC,ywr),e(Pe,xwr),e(Pe,LC),e(LC,k5e),e(k5e,$wr),e(LC,kwr),e(LC,kK),e(kK,Swr),e(LC,Rwr),e(Pe,Pwr),e(Pe,yC),e(yC,S5e),e(S5e,Bwr),e(yC,Iwr),e(yC,SK),e(SK,Nwr),e(yC,qwr),e(Pe,jwr),e(Pe,xC),e(xC,R5e),e(R5e,Dwr),e(xC,Gwr),e(xC,RK),e(RK,Owr),e(xC,Vwr),e(po,Xwr),e(po,$C),e($C,zwr),e($C,P5e),e(P5e,Qwr),e($C,Wwr),e($C,B5e),e(B5e,Uwr),e(po,Hwr),M(kC,po,null),b(m,oro,_),b(m,Tc,_),e(Tc,SC),e(SC,I5e),M(xk,I5e,null),e(Tc,Jwr),e(Tc,N5e),e(N5e,Ywr),b(m,rro,_),b(m,Zo,_),M($k,Zo,null),e(Zo,Zwr),e(Zo,Mc),e(Mc,Kwr),e(Mc,PK),e(PK,eAr),e(Mc,oAr),e(Mc,BK),e(BK,rAr),e(Mc,tAr),e(Zo,aAr),e(Zo,kk),e(kk,nAr),e(kk,q5e),e(q5e,sAr),e(kk,lAr),e(Zo,iAr),e(Zo,Nt),M(Sk,Nt,null),e(Nt,dAr),e(Nt,j5e),e(j5e,cAr),e(Nt,mAr),e(Nt,Ec),e(Ec,fAr),e(Ec,D5e),e(D5e,gAr),e(Ec,hAr),e(Ec,IK),e(IK,uAr),e(Ec,pAr),e(Nt,_Ar),M(RC,Nt,null),e(Zo,bAr),e(Zo,_o),M(Rk,_o,null),e(_o,vAr),e(_o,G5e),e(G5e,FAr),e(_o,TAr),e(_o,bn),e(bn,MAr),e(bn,O5e),e(O5e,EAr),e(bn,CAr),e(bn,V5e),e(V5e,wAr),e(bn,AAr),e(bn,X5e),e(X5e,LAr),e(bn,yAr),e(_o,xAr),e(_o,gt),e(gt,PC),e(PC,z5e),e(z5e,$Ar),e(PC,kAr),e(PC,NK),e(NK,SAr),e(PC,RAr),e(gt,PAr),e(gt,BC),e(BC,Q5e),e(Q5e,BAr),e(BC,IAr),e(BC,qK),e(qK,NAr),e(BC,qAr),e(gt,jAr),e(gt,IC),e(IC,W5e),e(W5e,DAr),e(IC,GAr),e(IC,jK),e(jK,OAr),e(IC,VAr),e(gt,XAr),e(gt,NC),e(NC,U5e),e(U5e,zAr),e(NC,QAr),e(NC,DK),e(DK,WAr),e(NC,UAr),e(gt,HAr),e(gt,qC),e(qC,H5e),e(H5e,JAr),e(qC,YAr),e(qC,GK),e(GK,ZAr),e(qC,KAr),e(_o,e6r),e(_o,jC),e(jC,o6r),e(jC,J5e),e(J5e,r6r),e(jC,t6r),e(jC,Y5e),e(Y5e,a6r),e(_o,n6r),M(DC,_o,null),b(m,tro,_),b(m,Cc,_),e(Cc,GC),e(GC,Z5e),M(Pk,Z5e,null),e(Cc,s6r),e(Cc,K5e),e(K5e,l6r),b(m,aro,_),b(m,Ko,_),M(Bk,Ko,null),e(Ko,i6r),e(Ko,wc),e(wc,d6r),e(wc,OK),e(OK,c6r),e(wc,m6r),e(wc,VK),e(VK,f6r),e(wc,g6r),e(Ko,h6r),e(Ko,Ik),e(Ik,u6r),e(Ik,e0e),e(e0e,p6r),e(Ik,_6r),e(Ko,b6r),e(Ko,qt),M(Nk,qt,null),e(qt,v6r),e(qt,o0e),e(o0e,F6r),e(qt,T6r),e(qt,Ac),e(Ac,M6r),e(Ac,r0e),e(r0e,E6r),e(Ac,C6r),e(Ac,XK),e(XK,w6r),e(Ac,A6r),e(qt,L6r),M(OC,qt,null),e(Ko,y6r),e(Ko,bo),M(qk,bo,null),e(bo,x6r),e(bo,t0e),e(t0e,$6r),e(bo,k6r),e(bo,vn),e(vn,S6r),e(vn,a0e),e(a0e,R6r),e(vn,P6r),e(vn,n0e),e(n0e,B6r),e(vn,I6r),e(vn,s0e),e(s0e,N6r),e(vn,q6r),e(bo,j6r),e(bo,Le),e(Le,VC),e(VC,l0e),e(l0e,D6r),e(VC,G6r),e(VC,zK),e(zK,O6r),e(VC,V6r),e(Le,X6r),e(Le,XC),e(XC,i0e),e(i0e,z6r),e(XC,Q6r),e(XC,QK),e(QK,W6r),e(XC,U6r),e(Le,H6r),e(Le,zC),e(zC,d0e),e(d0e,J6r),e(zC,Y6r),e(zC,WK),e(WK,Z6r),e(zC,K6r),e(Le,e7r),e(Le,QC),e(QC,c0e),e(c0e,o7r),e(QC,r7r),e(QC,UK),e(UK,t7r),e(QC,a7r),e(Le,n7r),e(Le,WC),e(WC,m0e),e(m0e,s7r),e(WC,l7r),e(WC,HK),e(HK,i7r),e(WC,d7r),e(Le,c7r),e(Le,UC),e(UC,f0e),e(f0e,m7r),e(UC,f7r),e(UC,JK),e(JK,g7r),e(UC,h7r),e(Le,u7r),e(Le,HC),e(HC,g0e),e(g0e,p7r),e(HC,_7r),e(HC,YK),e(YK,b7r),e(HC,v7r),e(Le,F7r),e(Le,JC),e(JC,h0e),e(h0e,T7r),e(JC,M7r),e(JC,ZK),e(ZK,E7r),e(JC,C7r),e(Le,w7r),e(Le,YC),e(YC,u0e),e(u0e,A7r),e(YC,L7r),e(YC,KK),e(KK,y7r),e(YC,x7r),e(Le,$7r),e(Le,ZC),e(ZC,p0e),e(p0e,k7r),e(ZC,S7r),e(ZC,eee),e(eee,R7r),e(ZC,P7r),e(bo,B7r),e(bo,KC),e(KC,I7r),e(KC,_0e),e(_0e,N7r),e(KC,q7r),e(KC,b0e),e(b0e,j7r),e(bo,D7r),M(e3,bo,null),b(m,nro,_),b(m,Lc,_),e(Lc,o3),e(o3,v0e),M(jk,v0e,null),e(Lc,G7r),e(Lc,F0e),e(F0e,O7r),b(m,sro,_),b(m,er,_),M(Dk,er,null),e(er,V7r),e(er,yc),e(yc,X7r),e(yc,oee),e(oee,z7r),e(yc,Q7r),e(yc,ree),e(ree,W7r),e(yc,U7r),e(er,H7r),e(er,Gk),e(Gk,J7r),e(Gk,T0e),e(T0e,Y7r),e(Gk,Z7r),e(er,K7r),e(er,jt),M(Ok,jt,null),e(jt,eLr),e(jt,M0e),e(M0e,oLr),e(jt,rLr),e(jt,xc),e(xc,tLr),e(xc,E0e),e(E0e,aLr),e(xc,nLr),e(xc,tee),e(tee,sLr),e(xc,lLr),e(jt,iLr),M(r3,jt,null),e(er,dLr),e(er,vo),M(Vk,vo,null),e(vo,cLr),e(vo,C0e),e(C0e,mLr),e(vo,fLr),e(vo,Fn),e(Fn,gLr),e(Fn,w0e),e(w0e,hLr),e(Fn,uLr),e(Fn,A0e),e(A0e,pLr),e(Fn,_Lr),e(Fn,L0e),e(L0e,bLr),e(Fn,vLr),e(vo,FLr),e(vo,$c),e($c,t3),e(t3,y0e),e(y0e,TLr),e(t3,MLr),e(t3,aee),e(aee,ELr),e(t3,CLr),e($c,wLr),e($c,a3),e(a3,x0e),e(x0e,ALr),e(a3,LLr),e(a3,nee),e(nee,yLr),e(a3,xLr),e($c,$Lr),e($c,n3),e(n3,$0e),e($0e,kLr),e(n3,SLr),e(n3,see),e(see,RLr),e(n3,PLr),e(vo,BLr),e(vo,s3),e(s3,ILr),e(s3,k0e),e(k0e,NLr),e(s3,qLr),e(s3,S0e),e(S0e,jLr),e(vo,DLr),M(l3,vo,null),b(m,lro,_),b(m,kc,_),e(kc,i3),e(i3,R0e),M(Xk,R0e,null),e(kc,GLr),e(kc,P0e),e(P0e,OLr),b(m,iro,_),b(m,or,_),M(zk,or,null),e(or,VLr),e(or,Sc),e(Sc,XLr),e(Sc,lee),e(lee,zLr),e(Sc,QLr),e(Sc,iee),e(iee,WLr),e(Sc,ULr),e(or,HLr),e(or,Qk),e(Qk,JLr),e(Qk,B0e),e(B0e,YLr),e(Qk,ZLr),e(or,KLr),e(or,Dt),M(Wk,Dt,null),e(Dt,eyr),e(Dt,I0e),e(I0e,oyr),e(Dt,ryr),e(Dt,Rc),e(Rc,tyr),e(Rc,N0e),e(N0e,ayr),e(Rc,nyr),e(Rc,dee),e(dee,syr),e(Rc,lyr),e(Dt,iyr),M(d3,Dt,null),e(or,dyr),e(or,Fo),M(Uk,Fo,null),e(Fo,cyr),e(Fo,q0e),e(q0e,myr),e(Fo,fyr),e(Fo,Tn),e(Tn,gyr),e(Tn,j0e),e(j0e,hyr),e(Tn,uyr),e(Tn,D0e),e(D0e,pyr),e(Tn,_yr),e(Tn,G0e),e(G0e,byr),e(Tn,vyr),e(Fo,Fyr),e(Fo,ht),e(ht,c3),e(c3,O0e),e(O0e,Tyr),e(c3,Myr),e(c3,cee),e(cee,Eyr),e(c3,Cyr),e(ht,wyr),e(ht,m3),e(m3,V0e),e(V0e,Ayr),e(m3,Lyr),e(m3,mee),e(mee,yyr),e(m3,xyr),e(ht,$yr),e(ht,f3),e(f3,X0e),e(X0e,kyr),e(f3,Syr),e(f3,fee),e(fee,Ryr),e(f3,Pyr),e(ht,Byr),e(ht,g3),e(g3,z0e),e(z0e,Iyr),e(g3,Nyr),e(g3,gee),e(gee,qyr),e(g3,jyr),e(ht,Dyr),e(ht,h3),e(h3,Q0e),e(Q0e,Gyr),e(h3,Oyr),e(h3,hee),e(hee,Vyr),e(h3,Xyr),e(Fo,zyr),e(Fo,u3),e(u3,Qyr),e(u3,W0e),e(W0e,Wyr),e(u3,Uyr),e(u3,U0e),e(U0e,Hyr),e(Fo,Jyr),M(p3,Fo,null),b(m,dro,_),b(m,Pc,_),e(Pc,_3),e(_3,H0e),M(Hk,H0e,null),e(Pc,Yyr),e(Pc,J0e),e(J0e,Zyr),b(m,cro,_),b(m,rr,_),M(Jk,rr,null),e(rr,Kyr),e(rr,Bc),e(Bc,e8r),e(Bc,uee),e(uee,o8r),e(Bc,r8r),e(Bc,pee),e(pee,t8r),e(Bc,a8r),e(rr,n8r),e(rr,Yk),e(Yk,s8r),e(Yk,Y0e),e(Y0e,l8r),e(Yk,i8r),e(rr,d8r),e(rr,Gt),M(Zk,Gt,null),e(Gt,c8r),e(Gt,Z0e),e(Z0e,m8r),e(Gt,f8r),e(Gt,Ic),e(Ic,g8r),e(Ic,K0e),e(K0e,h8r),e(Ic,u8r),e(Ic,_ee),e(_ee,p8r),e(Ic,_8r),e(Gt,b8r),M(b3,Gt,null),e(rr,v8r),e(rr,To),M(Kk,To,null),e(To,F8r),e(To,ewe),e(ewe,T8r),e(To,M8r),e(To,Mn),e(Mn,E8r),e(Mn,owe),e(owe,C8r),e(Mn,w8r),e(Mn,rwe),e(rwe,A8r),e(Mn,L8r),e(Mn,twe),e(twe,y8r),e(Mn,x8r),e(To,$8r),e(To,En),e(En,v3),e(v3,awe),e(awe,k8r),e(v3,S8r),e(v3,bee),e(bee,R8r),e(v3,P8r),e(En,B8r),e(En,F3),e(F3,nwe),e(nwe,I8r),e(F3,N8r),e(F3,vee),e(vee,q8r),e(F3,j8r),e(En,D8r),e(En,T3),e(T3,swe),e(swe,G8r),e(T3,O8r),e(T3,Fee),e(Fee,V8r),e(T3,X8r),e(En,z8r),e(En,M3),e(M3,lwe),e(lwe,Q8r),e(M3,W8r),e(M3,Tee),e(Tee,U8r),e(M3,H8r),e(To,J8r),e(To,E3),e(E3,Y8r),e(E3,iwe),e(iwe,Z8r),e(E3,K8r),e(E3,dwe),e(dwe,e9r),e(To,o9r),M(C3,To,null),b(m,mro,_),b(m,Nc,_),e(Nc,w3),e(w3,cwe),M(eS,cwe,null),e(Nc,r9r),e(Nc,mwe),e(mwe,t9r),b(m,fro,_),b(m,tr,_),M(oS,tr,null),e(tr,a9r),e(tr,qc),e(qc,n9r),e(qc,Mee),e(Mee,s9r),e(qc,l9r),e(qc,Eee),e(Eee,i9r),e(qc,d9r),e(tr,c9r),e(tr,rS),e(rS,m9r),e(rS,fwe),e(fwe,f9r),e(rS,g9r),e(tr,h9r),e(tr,Ot),M(tS,Ot,null),e(Ot,u9r),e(Ot,gwe),e(gwe,p9r),e(Ot,_9r),e(Ot,jc),e(jc,b9r),e(jc,hwe),e(hwe,v9r),e(jc,F9r),e(jc,Cee),e(Cee,T9r),e(jc,M9r),e(Ot,E9r),M(A3,Ot,null),e(tr,C9r),e(tr,Mo),M(aS,Mo,null),e(Mo,w9r),e(Mo,uwe),e(uwe,A9r),e(Mo,L9r),e(Mo,Cn),e(Cn,y9r),e(Cn,pwe),e(pwe,x9r),e(Cn,$9r),e(Cn,_we),e(_we,k9r),e(Cn,S9r),e(Cn,bwe),e(bwe,R9r),e(Cn,P9r),e(Mo,B9r),e(Mo,wn),e(wn,L3),e(L3,vwe),e(vwe,I9r),e(L3,N9r),e(L3,wee),e(wee,q9r),e(L3,j9r),e(wn,D9r),e(wn,y3),e(y3,Fwe),e(Fwe,G9r),e(y3,O9r),e(y3,Aee),e(Aee,V9r),e(y3,X9r),e(wn,z9r),e(wn,x3),e(x3,Twe),e(Twe,Q9r),e(x3,W9r),e(x3,Lee),e(Lee,U9r),e(x3,H9r),e(wn,J9r),e(wn,$3),e($3,Mwe),e(Mwe,Y9r),e($3,Z9r),e($3,yee),e(yee,K9r),e($3,exr),e(Mo,oxr),e(Mo,k3),e(k3,rxr),e(k3,Ewe),e(Ewe,txr),e(k3,axr),e(k3,Cwe),e(Cwe,nxr),e(Mo,sxr),M(S3,Mo,null),b(m,gro,_),b(m,Dc,_),e(Dc,R3),e(R3,wwe),M(nS,wwe,null),e(Dc,lxr),e(Dc,Awe),e(Awe,ixr),b(m,hro,_),b(m,ar,_),M(sS,ar,null),e(ar,dxr),e(ar,Gc),e(Gc,cxr),e(Gc,xee),e(xee,mxr),e(Gc,fxr),e(Gc,$ee),e($ee,gxr),e(Gc,hxr),e(ar,uxr),e(ar,lS),e(lS,pxr),e(lS,Lwe),e(Lwe,_xr),e(lS,bxr),e(ar,vxr),e(ar,Vt),M(iS,Vt,null),e(Vt,Fxr),e(Vt,ywe),e(ywe,Txr),e(Vt,Mxr),e(Vt,Oc),e(Oc,Exr),e(Oc,xwe),e(xwe,Cxr),e(Oc,wxr),e(Oc,kee),e(kee,Axr),e(Oc,Lxr),e(Vt,yxr),M(P3,Vt,null),e(ar,xxr),e(ar,Eo),M(dS,Eo,null),e(Eo,$xr),e(Eo,$we),e($we,kxr),e(Eo,Sxr),e(Eo,An),e(An,Rxr),e(An,kwe),e(kwe,Pxr),e(An,Bxr),e(An,Swe),e(Swe,Ixr),e(An,Nxr),e(An,Rwe),e(Rwe,qxr),e(An,jxr),e(Eo,Dxr),e(Eo,Pwe),e(Pwe,B3),e(B3,Bwe),e(Bwe,Gxr),e(B3,Oxr),e(B3,See),e(See,Vxr),e(B3,Xxr),e(Eo,zxr),e(Eo,I3),e(I3,Qxr),e(I3,Iwe),e(Iwe,Wxr),e(I3,Uxr),e(I3,Nwe),e(Nwe,Hxr),e(Eo,Jxr),M(N3,Eo,null),b(m,uro,_),b(m,Vc,_),e(Vc,q3),e(q3,qwe),M(cS,qwe,null),e(Vc,Yxr),e(Vc,jwe),e(jwe,Zxr),b(m,pro,_),b(m,nr,_),M(mS,nr,null),e(nr,Kxr),e(nr,Xc),e(Xc,e$r),e(Xc,Ree),e(Ree,o$r),e(Xc,r$r),e(Xc,Pee),e(Pee,t$r),e(Xc,a$r),e(nr,n$r),e(nr,fS),e(fS,s$r),e(fS,Dwe),e(Dwe,l$r),e(fS,i$r),e(nr,d$r),e(nr,Xt),M(gS,Xt,null),e(Xt,c$r),e(Xt,Gwe),e(Gwe,m$r),e(Xt,f$r),e(Xt,zc),e(zc,g$r),e(zc,Owe),e(Owe,h$r),e(zc,u$r),e(zc,Bee),e(Bee,p$r),e(zc,_$r),e(Xt,b$r),M(j3,Xt,null),e(nr,v$r),e(nr,Co),M(hS,Co,null),e(Co,F$r),e(Co,Vwe),e(Vwe,T$r),e(Co,M$r),e(Co,Ln),e(Ln,E$r),e(Ln,Xwe),e(Xwe,C$r),e(Ln,w$r),e(Ln,zwe),e(zwe,A$r),e(Ln,L$r),e(Ln,Qwe),e(Qwe,y$r),e(Ln,x$r),e(Co,$$r),e(Co,ut),e(ut,D3),e(D3,Wwe),e(Wwe,k$r),e(D3,S$r),e(D3,Iee),e(Iee,R$r),e(D3,P$r),e(ut,B$r),e(ut,G3),e(G3,Uwe),e(Uwe,I$r),e(G3,N$r),e(G3,Nee),e(Nee,q$r),e(G3,j$r),e(ut,D$r),e(ut,O3),e(O3,Hwe),e(Hwe,G$r),e(O3,O$r),e(O3,qee),e(qee,V$r),e(O3,X$r),e(ut,z$r),e(ut,V3),e(V3,Jwe),e(Jwe,Q$r),e(V3,W$r),e(V3,jee),e(jee,U$r),e(V3,H$r),e(ut,J$r),e(ut,X3),e(X3,Ywe),e(Ywe,Y$r),e(X3,Z$r),e(X3,Dee),e(Dee,K$r),e(X3,ekr),e(Co,okr),e(Co,z3),e(z3,rkr),e(z3,Zwe),e(Zwe,tkr),e(z3,akr),e(z3,Kwe),e(Kwe,nkr),e(Co,skr),M(Q3,Co,null),b(m,_ro,_),b(m,Qc,_),e(Qc,W3),e(W3,eAe),M(uS,eAe,null),e(Qc,lkr),e(Qc,oAe),e(oAe,ikr),b(m,bro,_),b(m,sr,_),M(pS,sr,null),e(sr,dkr),e(sr,Wc),e(Wc,ckr),e(Wc,Gee),e(Gee,mkr),e(Wc,fkr),e(Wc,Oee),e(Oee,gkr),e(Wc,hkr),e(sr,ukr),e(sr,_S),e(_S,pkr),e(_S,rAe),e(rAe,_kr),e(_S,bkr),e(sr,vkr),e(sr,zt),M(bS,zt,null),e(zt,Fkr),e(zt,tAe),e(tAe,Tkr),e(zt,Mkr),e(zt,Uc),e(Uc,Ekr),e(Uc,aAe),e(aAe,Ckr),e(Uc,wkr),e(Uc,Vee),e(Vee,Akr),e(Uc,Lkr),e(zt,ykr),M(U3,zt,null),e(sr,xkr),e(sr,wo),M(vS,wo,null),e(wo,$kr),e(wo,nAe),e(nAe,kkr),e(wo,Skr),e(wo,yn),e(yn,Rkr),e(yn,sAe),e(sAe,Pkr),e(yn,Bkr),e(yn,lAe),e(lAe,Ikr),e(yn,Nkr),e(yn,iAe),e(iAe,qkr),e(yn,jkr),e(wo,Dkr),e(wo,dAe),e(dAe,H3),e(H3,cAe),e(cAe,Gkr),e(H3,Okr),e(H3,Xee),e(Xee,Vkr),e(H3,Xkr),e(wo,zkr),e(wo,J3),e(J3,Qkr),e(J3,mAe),e(mAe,Wkr),e(J3,Ukr),e(J3,fAe),e(fAe,Hkr),e(wo,Jkr),M(Y3,wo,null),b(m,vro,_),b(m,Hc,_),e(Hc,Z3),e(Z3,gAe),M(FS,gAe,null),e(Hc,Ykr),e(Hc,hAe),e(hAe,Zkr),b(m,Fro,_),b(m,lr,_),M(TS,lr,null),e(lr,Kkr),e(lr,Jc),e(Jc,eSr),e(Jc,zee),e(zee,oSr),e(Jc,rSr),e(Jc,Qee),e(Qee,tSr),e(Jc,aSr),e(lr,nSr),e(lr,MS),e(MS,sSr),e(MS,uAe),e(uAe,lSr),e(MS,iSr),e(lr,dSr),e(lr,Qt),M(ES,Qt,null),e(Qt,cSr),e(Qt,pAe),e(pAe,mSr),e(Qt,fSr),e(Qt,Yc),e(Yc,gSr),e(Yc,_Ae),e(_Ae,hSr),e(Yc,uSr),e(Yc,Wee),e(Wee,pSr),e(Yc,_Sr),e(Qt,bSr),M(K3,Qt,null),e(lr,vSr),e(lr,Ao),M(CS,Ao,null),e(Ao,FSr),e(Ao,bAe),e(bAe,TSr),e(Ao,MSr),e(Ao,xn),e(xn,ESr),e(xn,vAe),e(vAe,CSr),e(xn,wSr),e(xn,FAe),e(FAe,ASr),e(xn,LSr),e(xn,TAe),e(TAe,ySr),e(xn,xSr),e(Ao,$Sr),e(Ao,MAe),e(MAe,e5),e(e5,EAe),e(EAe,kSr),e(e5,SSr),e(e5,Uee),e(Uee,RSr),e(e5,PSr),e(Ao,BSr),e(Ao,o5),e(o5,ISr),e(o5,CAe),e(CAe,NSr),e(o5,qSr),e(o5,wAe),e(wAe,jSr),e(Ao,DSr),M(r5,Ao,null),b(m,Tro,_),b(m,Zc,_),e(Zc,t5),e(t5,AAe),M(wS,AAe,null),e(Zc,GSr),e(Zc,LAe),e(LAe,OSr),b(m,Mro,_),b(m,ir,_),M(AS,ir,null),e(ir,VSr),e(ir,Kc),e(Kc,XSr),e(Kc,Hee),e(Hee,zSr),e(Kc,QSr),e(Kc,Jee),e(Jee,WSr),e(Kc,USr),e(ir,HSr),e(ir,LS),e(LS,JSr),e(LS,yAe),e(yAe,YSr),e(LS,ZSr),e(ir,KSr),e(ir,Wt),M(yS,Wt,null),e(Wt,eRr),e(Wt,xAe),e(xAe,oRr),e(Wt,rRr),e(Wt,em),e(em,tRr),e(em,$Ae),e($Ae,aRr),e(em,nRr),e(em,Yee),e(Yee,sRr),e(em,lRr),e(Wt,iRr),M(a5,Wt,null),e(ir,dRr),e(ir,qr),M(xS,qr,null),e(qr,cRr),e(qr,kAe),e(kAe,mRr),e(qr,fRr),e(qr,$n),e($n,gRr),e($n,SAe),e(SAe,hRr),e($n,uRr),e($n,RAe),e(RAe,pRr),e($n,_Rr),e($n,PAe),e(PAe,bRr),e($n,vRr),e(qr,FRr),e(qr,q),e(q,n5),e(n5,BAe),e(BAe,TRr),e(n5,MRr),e(n5,Zee),e(Zee,ERr),e(n5,CRr),e(q,wRr),e(q,s5),e(s5,IAe),e(IAe,ARr),e(s5,LRr),e(s5,Kee),e(Kee,yRr),e(s5,xRr),e(q,$Rr),e(q,l5),e(l5,NAe),e(NAe,kRr),e(l5,SRr),e(l5,eoe),e(eoe,RRr),e(l5,PRr),e(q,BRr),e(q,i5),e(i5,qAe),e(qAe,IRr),e(i5,NRr),e(i5,ooe),e(ooe,qRr),e(i5,jRr),e(q,DRr),e(q,d5),e(d5,jAe),e(jAe,GRr),e(d5,ORr),e(d5,roe),e(roe,VRr),e(d5,XRr),e(q,zRr),e(q,c5),e(c5,DAe),e(DAe,QRr),e(c5,WRr),e(c5,toe),e(toe,URr),e(c5,HRr),e(q,JRr),e(q,m5),e(m5,GAe),e(GAe,YRr),e(m5,ZRr),e(m5,aoe),e(aoe,KRr),e(m5,ePr),e(q,oPr),e(q,f5),e(f5,OAe),e(OAe,rPr),e(f5,tPr),e(f5,noe),e(noe,aPr),e(f5,nPr),e(q,sPr),e(q,g5),e(g5,VAe),e(VAe,lPr),e(g5,iPr),e(g5,soe),e(soe,dPr),e(g5,cPr),e(q,mPr),e(q,h5),e(h5,XAe),e(XAe,fPr),e(h5,gPr),e(h5,loe),e(loe,hPr),e(h5,uPr),e(q,pPr),e(q,u5),e(u5,zAe),e(zAe,_Pr),e(u5,bPr),e(u5,ioe),e(ioe,vPr),e(u5,FPr),e(q,TPr),e(q,p5),e(p5,QAe),e(QAe,MPr),e(p5,EPr),e(p5,doe),e(doe,CPr),e(p5,wPr),e(q,APr),e(q,_5),e(_5,WAe),e(WAe,LPr),e(_5,yPr),e(_5,coe),e(coe,xPr),e(_5,$Pr),e(q,kPr),e(q,b5),e(b5,UAe),e(UAe,SPr),e(b5,RPr),e(b5,moe),e(moe,PPr),e(b5,BPr),e(q,IPr),e(q,v5),e(v5,HAe),e(HAe,NPr),e(v5,qPr),e(v5,foe),e(foe,jPr),e(v5,DPr),e(q,GPr),e(q,F5),e(F5,JAe),e(JAe,OPr),e(F5,VPr),e(F5,goe),e(goe,XPr),e(F5,zPr),e(q,QPr),e(q,T5),e(T5,YAe),e(YAe,WPr),e(T5,UPr),e(T5,hoe),e(hoe,HPr),e(T5,JPr),e(q,YPr),e(q,M5),e(M5,ZAe),e(ZAe,ZPr),e(M5,KPr),e(M5,uoe),e(uoe,eBr),e(M5,oBr),e(q,rBr),e(q,wl),e(wl,KAe),e(KAe,tBr),e(wl,aBr),e(wl,poe),e(poe,nBr),e(wl,sBr),e(wl,_oe),e(_oe,lBr),e(wl,iBr),e(q,dBr),e(q,E5),e(E5,e6e),e(e6e,cBr),e(E5,mBr),e(E5,boe),e(boe,fBr),e(E5,gBr),e(q,hBr),e(q,C5),e(C5,o6e),e(o6e,uBr),e(C5,pBr),e(C5,voe),e(voe,_Br),e(C5,bBr),e(q,vBr),e(q,w5),e(w5,r6e),e(r6e,FBr),e(w5,TBr),e(w5,Foe),e(Foe,MBr),e(w5,EBr),e(q,CBr),e(q,A5),e(A5,t6e),e(t6e,wBr),e(A5,ABr),e(A5,Toe),e(Toe,LBr),e(A5,yBr),e(q,xBr),e(q,L5),e(L5,a6e),e(a6e,$Br),e(L5,kBr),e(L5,Moe),e(Moe,SBr),e(L5,RBr),e(q,PBr),e(q,y5),e(y5,n6e),e(n6e,BBr),e(y5,IBr),e(y5,Eoe),e(Eoe,NBr),e(y5,qBr),e(q,jBr),e(q,x5),e(x5,s6e),e(s6e,DBr),e(x5,GBr),e(x5,Coe),e(Coe,OBr),e(x5,VBr),e(q,XBr),e(q,$5),e($5,l6e),e(l6e,zBr),e($5,QBr),e($5,woe),e(woe,WBr),e($5,UBr),e(q,HBr),e(q,k5),e(k5,i6e),e(i6e,JBr),e(k5,YBr),e(k5,Aoe),e(Aoe,ZBr),e(k5,KBr),e(q,eIr),e(q,S5),e(S5,d6e),e(d6e,oIr),e(S5,rIr),e(S5,Loe),e(Loe,tIr),e(S5,aIr),e(q,nIr),e(q,R5),e(R5,c6e),e(c6e,sIr),e(R5,lIr),e(R5,yoe),e(yoe,iIr),e(R5,dIr),e(q,cIr),e(q,P5),e(P5,m6e),e(m6e,mIr),e(P5,fIr),e(P5,xoe),e(xoe,gIr),e(P5,hIr),e(q,uIr),e(q,B5),e(B5,f6e),e(f6e,pIr),e(B5,_Ir),e(B5,$oe),e($oe,bIr),e(B5,vIr),e(q,FIr),e(q,I5),e(I5,g6e),e(g6e,TIr),e(I5,MIr),e(I5,koe),e(koe,EIr),e(I5,CIr),e(q,wIr),e(q,N5),e(N5,h6e),e(h6e,AIr),e(N5,LIr),e(N5,Soe),e(Soe,yIr),e(N5,xIr),e(q,$Ir),e(q,q5),e(q5,u6e),e(u6e,kIr),e(q5,SIr),e(q5,Roe),e(Roe,RIr),e(q5,PIr),e(q,BIr),e(q,j5),e(j5,p6e),e(p6e,IIr),e(j5,NIr),e(j5,Poe),e(Poe,qIr),e(j5,jIr),e(q,DIr),e(q,D5),e(D5,_6e),e(_6e,GIr),e(D5,OIr),e(D5,Boe),e(Boe,VIr),e(D5,XIr),e(q,zIr),e(q,G5),e(G5,b6e),e(b6e,QIr),e(G5,WIr),e(G5,Ioe),e(Ioe,UIr),e(G5,HIr),e(q,JIr),e(q,O5),e(O5,v6e),e(v6e,YIr),e(O5,ZIr),e(O5,Noe),e(Noe,KIr),e(O5,eNr),e(q,oNr),e(q,V5),e(V5,F6e),e(F6e,rNr),e(V5,tNr),e(V5,qoe),e(qoe,aNr),e(V5,nNr),e(q,sNr),e(q,X5),e(X5,T6e),e(T6e,lNr),e(X5,iNr),e(X5,joe),e(joe,dNr),e(X5,cNr),e(q,mNr),e(q,z5),e(z5,M6e),e(M6e,fNr),e(z5,gNr),e(z5,Doe),e(Doe,hNr),e(z5,uNr),e(q,pNr),e(q,Q5),e(Q5,E6e),e(E6e,_Nr),e(Q5,bNr),e(Q5,Goe),e(Goe,vNr),e(Q5,FNr),e(q,TNr),e(q,W5),e(W5,C6e),e(C6e,MNr),e(W5,ENr),e(W5,Ooe),e(Ooe,CNr),e(W5,wNr),e(q,ANr),e(q,U5),e(U5,w6e),e(w6e,LNr),e(U5,yNr),e(U5,Voe),e(Voe,xNr),e(U5,$Nr),e(q,kNr),e(q,H5),e(H5,A6e),e(A6e,SNr),e(H5,RNr),e(H5,Xoe),e(Xoe,PNr),e(H5,BNr),e(q,INr),e(q,J5),e(J5,L6e),e(L6e,NNr),e(J5,qNr),e(J5,zoe),e(zoe,jNr),e(J5,DNr),e(q,GNr),e(q,Y5),e(Y5,y6e),e(y6e,ONr),e(Y5,VNr),e(Y5,Qoe),e(Qoe,XNr),e(Y5,zNr),e(q,QNr),e(q,Z5),e(Z5,x6e),e(x6e,WNr),e(Z5,UNr),e(Z5,Woe),e(Woe,HNr),e(Z5,JNr),e(q,YNr),e(q,K5),e(K5,$6e),e($6e,ZNr),e(K5,KNr),e(K5,Uoe),e(Uoe,eqr),e(K5,oqr),e(q,rqr),e(q,e0),e(e0,k6e),e(k6e,tqr),e(e0,aqr),e(e0,Hoe),e(Hoe,nqr),e(e0,sqr),e(q,lqr),e(q,o0),e(o0,S6e),e(S6e,iqr),e(o0,dqr),e(o0,Joe),e(Joe,cqr),e(o0,mqr),e(q,fqr),e(q,r0),e(r0,R6e),e(R6e,gqr),e(r0,hqr),e(r0,Yoe),e(Yoe,uqr),e(r0,pqr),e(q,_qr),e(q,t0),e(t0,P6e),e(P6e,bqr),e(t0,vqr),e(t0,Zoe),e(Zoe,Fqr),e(t0,Tqr),e(q,Mqr),e(q,a0),e(a0,B6e),e(B6e,Eqr),e(a0,Cqr),e(a0,Koe),e(Koe,wqr),e(a0,Aqr),e(qr,Lqr),M(n0,qr,null),b(m,Ero,_),b(m,om,_),e(om,s0),e(s0,I6e),M($S,I6e,null),e(om,yqr),e(om,N6e),e(N6e,xqr),b(m,Cro,_),b(m,dr,_),M(kS,dr,null),e(dr,$qr),e(dr,rm),e(rm,kqr),e(rm,ere),e(ere,Sqr),e(rm,Rqr),e(rm,ore),e(ore,Pqr),e(rm,Bqr),e(dr,Iqr),e(dr,SS),e(SS,Nqr),e(SS,q6e),e(q6e,qqr),e(SS,jqr),e(dr,Dqr),e(dr,Ut),M(RS,Ut,null),e(Ut,Gqr),e(Ut,j6e),e(j6e,Oqr),e(Ut,Vqr),e(Ut,tm),e(tm,Xqr),e(tm,D6e),e(D6e,zqr),e(tm,Qqr),e(tm,rre),e(rre,Wqr),e(tm,Uqr),e(Ut,Hqr),M(l0,Ut,null),e(dr,Jqr),e(dr,jr),M(PS,jr,null),e(jr,Yqr),e(jr,G6e),e(G6e,Zqr),e(jr,Kqr),e(jr,kn),e(kn,ejr),e(kn,O6e),e(O6e,ojr),e(kn,rjr),e(kn,V6e),e(V6e,tjr),e(kn,ajr),e(kn,X6e),e(X6e,njr),e(kn,sjr),e(jr,ljr),e(jr,le),e(le,i0),e(i0,z6e),e(z6e,ijr),e(i0,djr),e(i0,tre),e(tre,cjr),e(i0,mjr),e(le,fjr),e(le,d0),e(d0,Q6e),e(Q6e,gjr),e(d0,hjr),e(d0,are),e(are,ujr),e(d0,pjr),e(le,_jr),e(le,c0),e(c0,W6e),e(W6e,bjr),e(c0,vjr),e(c0,nre),e(nre,Fjr),e(c0,Tjr),e(le,Mjr),e(le,m0),e(m0,U6e),e(U6e,Ejr),e(m0,Cjr),e(m0,sre),e(sre,wjr),e(m0,Ajr),e(le,Ljr),e(le,f0),e(f0,H6e),e(H6e,yjr),e(f0,xjr),e(f0,lre),e(lre,$jr),e(f0,kjr),e(le,Sjr),e(le,g0),e(g0,J6e),e(J6e,Rjr),e(g0,Pjr),e(g0,ire),e(ire,Bjr),e(g0,Ijr),e(le,Njr),e(le,h0),e(h0,Y6e),e(Y6e,qjr),e(h0,jjr),e(h0,dre),e(dre,Djr),e(h0,Gjr),e(le,Ojr),e(le,u0),e(u0,Z6e),e(Z6e,Vjr),e(u0,Xjr),e(u0,cre),e(cre,zjr),e(u0,Qjr),e(le,Wjr),e(le,p0),e(p0,K6e),e(K6e,Ujr),e(p0,Hjr),e(p0,mre),e(mre,Jjr),e(p0,Yjr),e(le,Zjr),e(le,_0),e(_0,e7e),e(e7e,Kjr),e(_0,eDr),e(_0,fre),e(fre,oDr),e(_0,rDr),e(le,tDr),e(le,b0),e(b0,o7e),e(o7e,aDr),e(b0,nDr),e(b0,gre),e(gre,sDr),e(b0,lDr),e(le,iDr),e(le,v0),e(v0,r7e),e(r7e,dDr),e(v0,cDr),e(v0,hre),e(hre,mDr),e(v0,fDr),e(le,gDr),e(le,F0),e(F0,t7e),e(t7e,hDr),e(F0,uDr),e(F0,ure),e(ure,pDr),e(F0,_Dr),e(le,bDr),e(le,T0),e(T0,a7e),e(a7e,vDr),e(T0,FDr),e(T0,pre),e(pre,TDr),e(T0,MDr),e(le,EDr),e(le,M0),e(M0,n7e),e(n7e,CDr),e(M0,wDr),e(M0,_re),e(_re,ADr),e(M0,LDr),e(le,yDr),e(le,E0),e(E0,s7e),e(s7e,xDr),e(E0,$Dr),e(E0,bre),e(bre,kDr),e(E0,SDr),e(le,RDr),e(le,C0),e(C0,l7e),e(l7e,PDr),e(C0,BDr),e(C0,vre),e(vre,IDr),e(C0,NDr),e(le,qDr),e(le,w0),e(w0,i7e),e(i7e,jDr),e(w0,DDr),e(w0,Fre),e(Fre,GDr),e(w0,ODr),e(le,VDr),e(le,A0),e(A0,d7e),e(d7e,XDr),e(A0,zDr),e(A0,Tre),e(Tre,QDr),e(A0,WDr),e(le,UDr),e(le,L0),e(L0,c7e),e(c7e,HDr),e(L0,JDr),e(L0,Mre),e(Mre,YDr),e(L0,ZDr),e(le,KDr),e(le,y0),e(y0,m7e),e(m7e,eGr),e(y0,oGr),e(y0,Ere),e(Ere,rGr),e(y0,tGr),e(le,aGr),e(le,x0),e(x0,f7e),e(f7e,nGr),e(x0,sGr),e(x0,Cre),e(Cre,lGr),e(x0,iGr),e(le,dGr),e(le,$0),e($0,g7e),e(g7e,cGr),e($0,mGr),e($0,wre),e(wre,fGr),e($0,gGr),e(jr,hGr),M(k0,jr,null),b(m,wro,_),b(m,am,_),e(am,S0),e(S0,h7e),M(BS,h7e,null),e(am,uGr),e(am,u7e),e(u7e,pGr),b(m,Aro,_),b(m,cr,_),M(IS,cr,null),e(cr,_Gr),e(cr,nm),e(nm,bGr),e(nm,Are),e(Are,vGr),e(nm,FGr),e(nm,Lre),e(Lre,TGr),e(nm,MGr),e(cr,EGr),e(cr,NS),e(NS,CGr),e(NS,p7e),e(p7e,wGr),e(NS,AGr),e(cr,LGr),e(cr,Ht),M(qS,Ht,null),e(Ht,yGr),e(Ht,_7e),e(_7e,xGr),e(Ht,$Gr),e(Ht,sm),e(sm,kGr),e(sm,b7e),e(b7e,SGr),e(sm,RGr),e(sm,yre),e(yre,PGr),e(sm,BGr),e(Ht,IGr),M(R0,Ht,null),e(cr,NGr),e(cr,Dr),M(jS,Dr,null),e(Dr,qGr),e(Dr,v7e),e(v7e,jGr),e(Dr,DGr),e(Dr,Sn),e(Sn,GGr),e(Sn,F7e),e(F7e,OGr),e(Sn,VGr),e(Sn,T7e),e(T7e,XGr),e(Sn,zGr),e(Sn,M7e),e(M7e,QGr),e(Sn,WGr),e(Dr,UGr),e(Dr,Me),e(Me,P0),e(P0,E7e),e(E7e,HGr),e(P0,JGr),e(P0,xre),e(xre,YGr),e(P0,ZGr),e(Me,KGr),e(Me,B0),e(B0,C7e),e(C7e,eOr),e(B0,oOr),e(B0,$re),e($re,rOr),e(B0,tOr),e(Me,aOr),e(Me,I0),e(I0,w7e),e(w7e,nOr),e(I0,sOr),e(I0,kre),e(kre,lOr),e(I0,iOr),e(Me,dOr),e(Me,N0),e(N0,A7e),e(A7e,cOr),e(N0,mOr),e(N0,Sre),e(Sre,fOr),e(N0,gOr),e(Me,hOr),e(Me,q0),e(q0,L7e),e(L7e,uOr),e(q0,pOr),e(q0,Rre),e(Rre,_Or),e(q0,bOr),e(Me,vOr),e(Me,j0),e(j0,y7e),e(y7e,FOr),e(j0,TOr),e(j0,Pre),e(Pre,MOr),e(j0,EOr),e(Me,COr),e(Me,D0),e(D0,x7e),e(x7e,wOr),e(D0,AOr),e(D0,Bre),e(Bre,LOr),e(D0,yOr),e(Me,xOr),e(Me,G0),e(G0,$7e),e($7e,$Or),e(G0,kOr),e(G0,Ire),e(Ire,SOr),e(G0,ROr),e(Me,POr),e(Me,O0),e(O0,k7e),e(k7e,BOr),e(O0,IOr),e(O0,Nre),e(Nre,NOr),e(O0,qOr),e(Me,jOr),e(Me,V0),e(V0,S7e),e(S7e,DOr),e(V0,GOr),e(V0,qre),e(qre,OOr),e(V0,VOr),e(Me,XOr),e(Me,X0),e(X0,R7e),e(R7e,zOr),e(X0,QOr),e(X0,jre),e(jre,WOr),e(X0,UOr),e(Me,HOr),e(Me,z0),e(z0,P7e),e(P7e,JOr),e(z0,YOr),e(z0,Dre),e(Dre,ZOr),e(z0,KOr),e(Me,eVr),e(Me,Q0),e(Q0,B7e),e(B7e,oVr),e(Q0,rVr),e(Q0,Gre),e(Gre,tVr),e(Q0,aVr),e(Me,nVr),e(Me,W0),e(W0,I7e),e(I7e,sVr),e(W0,lVr),e(W0,Ore),e(Ore,iVr),e(W0,dVr),e(Dr,cVr),M(U0,Dr,null),b(m,Lro,_),b(m,lm,_),e(lm,H0),e(H0,N7e),M(DS,N7e,null),e(lm,mVr),e(lm,q7e),e(q7e,fVr),b(m,yro,_),b(m,mr,_),M(GS,mr,null),e(mr,gVr),e(mr,im),e(im,hVr),e(im,Vre),e(Vre,uVr),e(im,pVr),e(im,Xre),e(Xre,_Vr),e(im,bVr),e(mr,vVr),e(mr,OS),e(OS,FVr),e(OS,j7e),e(j7e,TVr),e(OS,MVr),e(mr,EVr),e(mr,Jt),M(VS,Jt,null),e(Jt,CVr),e(Jt,D7e),e(D7e,wVr),e(Jt,AVr),e(Jt,dm),e(dm,LVr),e(dm,G7e),e(G7e,yVr),e(dm,xVr),e(dm,zre),e(zre,$Vr),e(dm,kVr),e(Jt,SVr),M(J0,Jt,null),e(mr,RVr),e(mr,Gr),M(XS,Gr,null),e(Gr,PVr),e(Gr,O7e),e(O7e,BVr),e(Gr,IVr),e(Gr,Rn),e(Rn,NVr),e(Rn,V7e),e(V7e,qVr),e(Rn,jVr),e(Rn,X7e),e(X7e,DVr),e(Rn,GVr),e(Rn,z7e),e(z7e,OVr),e(Rn,VVr),e(Gr,XVr),e(Gr,Be),e(Be,Y0),e(Y0,Q7e),e(Q7e,zVr),e(Y0,QVr),e(Y0,Qre),e(Qre,WVr),e(Y0,UVr),e(Be,HVr),e(Be,Z0),e(Z0,W7e),e(W7e,JVr),e(Z0,YVr),e(Z0,Wre),e(Wre,ZVr),e(Z0,KVr),e(Be,eXr),e(Be,Al),e(Al,U7e),e(U7e,oXr),e(Al,rXr),e(Al,Ure),e(Ure,tXr),e(Al,aXr),e(Al,Hre),e(Hre,nXr),e(Al,sXr),e(Be,lXr),e(Be,K0),e(K0,H7e),e(H7e,iXr),e(K0,dXr),e(K0,Jre),e(Jre,cXr),e(K0,mXr),e(Be,fXr),e(Be,ew),e(ew,J7e),e(J7e,gXr),e(ew,hXr),e(ew,Yre),e(Yre,uXr),e(ew,pXr),e(Be,_Xr),e(Be,ow),e(ow,Y7e),e(Y7e,bXr),e(ow,vXr),e(ow,Zre),e(Zre,FXr),e(ow,TXr),e(Be,MXr),e(Be,rw),e(rw,Z7e),e(Z7e,EXr),e(rw,CXr),e(rw,Kre),e(Kre,wXr),e(rw,AXr),e(Be,LXr),e(Be,tw),e(tw,K7e),e(K7e,yXr),e(tw,xXr),e(tw,ete),e(ete,$Xr),e(tw,kXr),e(Be,SXr),e(Be,aw),e(aw,eLe),e(eLe,RXr),e(aw,PXr),e(aw,ote),e(ote,BXr),e(aw,IXr),e(Gr,NXr),M(nw,Gr,null),b(m,xro,_),b(m,cm,_),e(cm,sw),e(sw,oLe),M(zS,oLe,null),e(cm,qXr),e(cm,rLe),e(rLe,jXr),b(m,$ro,_),b(m,fr,_),M(QS,fr,null),e(fr,DXr),e(fr,mm),e(mm,GXr),e(mm,rte),e(rte,OXr),e(mm,VXr),e(mm,tte),e(tte,XXr),e(mm,zXr),e(fr,QXr),e(fr,WS),e(WS,WXr),e(WS,tLe),e(tLe,UXr),e(WS,HXr),e(fr,JXr),e(fr,Yt),M(US,Yt,null),e(Yt,YXr),e(Yt,aLe),e(aLe,ZXr),e(Yt,KXr),e(Yt,fm),e(fm,ezr),e(fm,nLe),e(nLe,ozr),e(fm,rzr),e(fm,ate),e(ate,tzr),e(fm,azr),e(Yt,nzr),M(lw,Yt,null),e(fr,szr),e(fr,Or),M(HS,Or,null),e(Or,lzr),e(Or,sLe),e(sLe,izr),e(Or,dzr),e(Or,Pn),e(Pn,czr),e(Pn,lLe),e(lLe,mzr),e(Pn,fzr),e(Pn,iLe),e(iLe,gzr),e(Pn,hzr),e(Pn,dLe),e(dLe,uzr),e(Pn,pzr),e(Or,_zr),e(Or,gm),e(gm,iw),e(iw,cLe),e(cLe,bzr),e(iw,vzr),e(iw,nte),e(nte,Fzr),e(iw,Tzr),e(gm,Mzr),e(gm,dw),e(dw,mLe),e(mLe,Ezr),e(dw,Czr),e(dw,ste),e(ste,wzr),e(dw,Azr),e(gm,Lzr),e(gm,cw),e(cw,fLe),e(fLe,yzr),e(cw,xzr),e(cw,lte),e(lte,$zr),e(cw,kzr),e(Or,Szr),M(mw,Or,null),b(m,kro,_),b(m,hm,_),e(hm,fw),e(fw,gLe),M(JS,gLe,null),e(hm,Rzr),e(hm,hLe),e(hLe,Pzr),b(m,Sro,_),b(m,gr,_),M(YS,gr,null),e(gr,Bzr),e(gr,um),e(um,Izr),e(um,ite),e(ite,Nzr),e(um,qzr),e(um,dte),e(dte,jzr),e(um,Dzr),e(gr,Gzr),e(gr,ZS),e(ZS,Ozr),e(ZS,uLe),e(uLe,Vzr),e(ZS,Xzr),e(gr,zzr),e(gr,Zt),M(KS,Zt,null),e(Zt,Qzr),e(Zt,pLe),e(pLe,Wzr),e(Zt,Uzr),e(Zt,pm),e(pm,Hzr),e(pm,_Le),e(_Le,Jzr),e(pm,Yzr),e(pm,cte),e(cte,Zzr),e(pm,Kzr),e(Zt,eQr),M(gw,Zt,null),e(gr,oQr),e(gr,Vr),M(eR,Vr,null),e(Vr,rQr),e(Vr,bLe),e(bLe,tQr),e(Vr,aQr),e(Vr,Bn),e(Bn,nQr),e(Bn,vLe),e(vLe,sQr),e(Bn,lQr),e(Bn,FLe),e(FLe,iQr),e(Bn,dQr),e(Bn,TLe),e(TLe,cQr),e(Bn,mQr),e(Vr,fQr),e(Vr,ge),e(ge,hw),e(hw,MLe),e(MLe,gQr),e(hw,hQr),e(hw,mte),e(mte,uQr),e(hw,pQr),e(ge,_Qr),e(ge,uw),e(uw,ELe),e(ELe,bQr),e(uw,vQr),e(uw,fte),e(fte,FQr),e(uw,TQr),e(ge,MQr),e(ge,pw),e(pw,CLe),e(CLe,EQr),e(pw,CQr),e(pw,gte),e(gte,wQr),e(pw,AQr),e(ge,LQr),e(ge,_w),e(_w,wLe),e(wLe,yQr),e(_w,xQr),e(_w,hte),e(hte,$Qr),e(_w,kQr),e(ge,SQr),e(ge,bw),e(bw,ALe),e(ALe,RQr),e(bw,PQr),e(bw,ute),e(ute,BQr),e(bw,IQr),e(ge,NQr),e(ge,vw),e(vw,LLe),e(LLe,qQr),e(vw,jQr),e(vw,pte),e(pte,DQr),e(vw,GQr),e(ge,OQr),e(ge,Fw),e(Fw,yLe),e(yLe,VQr),e(Fw,XQr),e(Fw,_te),e(_te,zQr),e(Fw,QQr),e(ge,WQr),e(ge,Tw),e(Tw,xLe),e(xLe,UQr),e(Tw,HQr),e(Tw,bte),e(bte,JQr),e(Tw,YQr),e(ge,ZQr),e(ge,Mw),e(Mw,$Le),e($Le,KQr),e(Mw,eWr),e(Mw,vte),e(vte,oWr),e(Mw,rWr),e(ge,tWr),e(ge,Ew),e(Ew,kLe),e(kLe,aWr),e(Ew,nWr),e(Ew,Fte),e(Fte,sWr),e(Ew,lWr),e(ge,iWr),e(ge,Cw),e(Cw,SLe),e(SLe,dWr),e(Cw,cWr),e(Cw,Tte),e(Tte,mWr),e(Cw,fWr),e(ge,gWr),e(ge,ww),e(ww,RLe),e(RLe,hWr),e(ww,uWr),e(ww,Mte),e(Mte,pWr),e(ww,_Wr),e(ge,bWr),e(ge,Aw),e(Aw,PLe),e(PLe,vWr),e(Aw,FWr),e(Aw,Ete),e(Ete,TWr),e(Aw,MWr),e(ge,EWr),e(ge,Lw),e(Lw,BLe),e(BLe,CWr),e(Lw,wWr),e(Lw,Cte),e(Cte,AWr),e(Lw,LWr),e(ge,yWr),e(ge,yw),e(yw,ILe),e(ILe,xWr),e(yw,$Wr),e(yw,wte),e(wte,kWr),e(yw,SWr),e(ge,RWr),e(ge,xw),e(xw,NLe),e(NLe,PWr),e(xw,BWr),e(xw,Ate),e(Ate,IWr),e(xw,NWr),e(ge,qWr),e(ge,$w),e($w,qLe),e(qLe,jWr),e($w,DWr),e($w,Lte),e(Lte,GWr),e($w,OWr),e(ge,VWr),e(ge,kw),e(kw,jLe),e(jLe,XWr),e(kw,zWr),e(kw,yte),e(yte,QWr),e(kw,WWr),e(ge,UWr),e(ge,Sw),e(Sw,DLe),e(DLe,HWr),e(Sw,JWr),e(Sw,xte),e(xte,YWr),e(Sw,ZWr),e(ge,KWr),e(ge,Rw),e(Rw,GLe),e(GLe,eUr),e(Rw,oUr),e(Rw,$te),e($te,rUr),e(Rw,tUr),e(Vr,aUr),M(Pw,Vr,null),b(m,Rro,_),b(m,_m,_),e(_m,Bw),e(Bw,OLe),M(oR,OLe,null),e(_m,nUr),e(_m,VLe),e(VLe,sUr),b(m,Pro,_),b(m,hr,_),M(rR,hr,null),e(hr,lUr),e(hr,bm),e(bm,iUr),e(bm,kte),e(kte,dUr),e(bm,cUr),e(bm,Ste),e(Ste,mUr),e(bm,fUr),e(hr,gUr),e(hr,tR),e(tR,hUr),e(tR,XLe),e(XLe,uUr),e(tR,pUr),e(hr,_Ur),e(hr,Kt),M(aR,Kt,null),e(Kt,bUr),e(Kt,zLe),e(zLe,vUr),e(Kt,FUr),e(Kt,vm),e(vm,TUr),e(vm,QLe),e(QLe,MUr),e(vm,EUr),e(vm,Rte),e(Rte,CUr),e(vm,wUr),e(Kt,AUr),M(Iw,Kt,null),e(hr,LUr),e(hr,Xr),M(nR,Xr,null),e(Xr,yUr),e(Xr,WLe),e(WLe,xUr),e(Xr,$Ur),e(Xr,In),e(In,kUr),e(In,ULe),e(ULe,SUr),e(In,RUr),e(In,HLe),e(HLe,PUr),e(In,BUr),e(In,JLe),e(JLe,IUr),e(In,NUr),e(Xr,qUr),e(Xr,ye),e(ye,Nw),e(Nw,YLe),e(YLe,jUr),e(Nw,DUr),e(Nw,Pte),e(Pte,GUr),e(Nw,OUr),e(ye,VUr),e(ye,qw),e(qw,ZLe),e(ZLe,XUr),e(qw,zUr),e(qw,Bte),e(Bte,QUr),e(qw,WUr),e(ye,UUr),e(ye,jw),e(jw,KLe),e(KLe,HUr),e(jw,JUr),e(jw,Ite),e(Ite,YUr),e(jw,ZUr),e(ye,KUr),e(ye,Dw),e(Dw,eye),e(eye,eHr),e(Dw,oHr),e(Dw,Nte),e(Nte,rHr),e(Dw,tHr),e(ye,aHr),e(ye,Gw),e(Gw,oye),e(oye,nHr),e(Gw,sHr),e(Gw,qte),e(qte,lHr),e(Gw,iHr),e(ye,dHr),e(ye,Ow),e(Ow,rye),e(rye,cHr),e(Ow,mHr),e(Ow,jte),e(jte,fHr),e(Ow,gHr),e(ye,hHr),e(ye,Vw),e(Vw,tye),e(tye,uHr),e(Vw,pHr),e(Vw,Dte),e(Dte,_Hr),e(Vw,bHr),e(ye,vHr),e(ye,Xw),e(Xw,aye),e(aye,FHr),e(Xw,THr),e(Xw,Gte),e(Gte,MHr),e(Xw,EHr),e(ye,CHr),e(ye,zw),e(zw,nye),e(nye,wHr),e(zw,AHr),e(zw,Ote),e(Ote,LHr),e(zw,yHr),e(ye,xHr),e(ye,Qw),e(Qw,sye),e(sye,$Hr),e(Qw,kHr),e(Qw,Vte),e(Vte,SHr),e(Qw,RHr),e(Xr,PHr),M(Ww,Xr,null),b(m,Bro,_),b(m,Fm,_),e(Fm,Uw),e(Uw,lye),M(sR,lye,null),e(Fm,BHr),e(Fm,iye),e(iye,IHr),b(m,Iro,_),b(m,ur,_),M(lR,ur,null),e(ur,NHr),e(ur,Tm),e(Tm,qHr),e(Tm,Xte),e(Xte,jHr),e(Tm,DHr),e(Tm,zte),e(zte,GHr),e(Tm,OHr),e(ur,VHr),e(ur,iR),e(iR,XHr),e(iR,dye),e(dye,zHr),e(iR,QHr),e(ur,WHr),e(ur,ea),M(dR,ea,null),e(ea,UHr),e(ea,cye),e(cye,HHr),e(ea,JHr),e(ea,Mm),e(Mm,YHr),e(Mm,mye),e(mye,ZHr),e(Mm,KHr),e(Mm,Qte),e(Qte,eJr),e(Mm,oJr),e(ea,rJr),M(Hw,ea,null),e(ur,tJr),e(ur,zr),M(cR,zr,null),e(zr,aJr),e(zr,fye),e(fye,nJr),e(zr,sJr),e(zr,Nn),e(Nn,lJr),e(Nn,gye),e(gye,iJr),e(Nn,dJr),e(Nn,hye),e(hye,cJr),e(Nn,mJr),e(Nn,uye),e(uye,fJr),e(Nn,gJr),e(zr,hJr),e(zr,re),e(re,Jw),e(Jw,pye),e(pye,uJr),e(Jw,pJr),e(Jw,Wte),e(Wte,_Jr),e(Jw,bJr),e(re,vJr),e(re,Yw),e(Yw,_ye),e(_ye,FJr),e(Yw,TJr),e(Yw,Ute),e(Ute,MJr),e(Yw,EJr),e(re,CJr),e(re,Zw),e(Zw,bye),e(bye,wJr),e(Zw,AJr),e(Zw,Hte),e(Hte,LJr),e(Zw,yJr),e(re,xJr),e(re,Kw),e(Kw,vye),e(vye,$Jr),e(Kw,kJr),e(Kw,Jte),e(Jte,SJr),e(Kw,RJr),e(re,PJr),e(re,eA),e(eA,Fye),e(Fye,BJr),e(eA,IJr),e(eA,Yte),e(Yte,NJr),e(eA,qJr),e(re,jJr),e(re,oA),e(oA,Tye),e(Tye,DJr),e(oA,GJr),e(oA,Zte),e(Zte,OJr),e(oA,VJr),e(re,XJr),e(re,rA),e(rA,Mye),e(Mye,zJr),e(rA,QJr),e(rA,Kte),e(Kte,WJr),e(rA,UJr),e(re,HJr),e(re,tA),e(tA,Eye),e(Eye,JJr),e(tA,YJr),e(tA,eae),e(eae,ZJr),e(tA,KJr),e(re,eYr),e(re,aA),e(aA,Cye),e(Cye,oYr),e(aA,rYr),e(aA,oae),e(oae,tYr),e(aA,aYr),e(re,nYr),e(re,nA),e(nA,wye),e(wye,sYr),e(nA,lYr),e(nA,rae),e(rae,iYr),e(nA,dYr),e(re,cYr),e(re,sA),e(sA,Aye),e(Aye,mYr),e(sA,fYr),e(sA,tae),e(tae,gYr),e(sA,hYr),e(re,uYr),e(re,lA),e(lA,Lye),e(Lye,pYr),e(lA,_Yr),e(lA,aae),e(aae,bYr),e(lA,vYr),e(re,FYr),e(re,iA),e(iA,yye),e(yye,TYr),e(iA,MYr),e(iA,nae),e(nae,EYr),e(iA,CYr),e(re,wYr),e(re,dA),e(dA,xye),e(xye,AYr),e(dA,LYr),e(dA,sae),e(sae,yYr),e(dA,xYr),e(re,$Yr),e(re,cA),e(cA,$ye),e($ye,kYr),e(cA,SYr),e(cA,lae),e(lae,RYr),e(cA,PYr),e(re,BYr),e(re,mA),e(mA,kye),e(kye,IYr),e(mA,NYr),e(mA,iae),e(iae,qYr),e(mA,jYr),e(re,DYr),e(re,fA),e(fA,Sye),e(Sye,GYr),e(fA,OYr),e(fA,dae),e(dae,VYr),e(fA,XYr),e(re,zYr),e(re,gA),e(gA,Rye),e(Rye,QYr),e(gA,WYr),e(gA,cae),e(cae,UYr),e(gA,HYr),e(re,JYr),e(re,hA),e(hA,Pye),e(Pye,YYr),e(hA,ZYr),e(hA,mae),e(mae,KYr),e(hA,eZr),e(re,oZr),e(re,uA),e(uA,Bye),e(Bye,rZr),e(uA,tZr),e(uA,fae),e(fae,aZr),e(uA,nZr),e(re,sZr),e(re,pA),e(pA,Iye),e(Iye,lZr),e(pA,iZr),e(pA,gae),e(gae,dZr),e(pA,cZr),e(re,mZr),e(re,_A),e(_A,Nye),e(Nye,fZr),e(_A,gZr),e(_A,hae),e(hae,hZr),e(_A,uZr),e(re,pZr),e(re,bA),e(bA,qye),e(qye,_Zr),e(bA,bZr),e(bA,uae),e(uae,vZr),e(bA,FZr),e(re,TZr),e(re,vA),e(vA,jye),e(jye,MZr),e(vA,EZr),e(vA,pae),e(pae,CZr),e(vA,wZr),e(re,AZr),e(re,FA),e(FA,Dye),e(Dye,LZr),e(FA,yZr),e(FA,_ae),e(_ae,xZr),e(FA,$Zr),e(re,kZr),e(re,TA),e(TA,Gye),e(Gye,SZr),e(TA,RZr),e(TA,bae),e(bae,PZr),e(TA,BZr),e(re,IZr),e(re,MA),e(MA,Oye),e(Oye,NZr),e(MA,qZr),e(MA,vae),e(vae,jZr),e(MA,DZr),e(zr,GZr),M(EA,zr,null),b(m,Nro,_),b(m,Em,_),e(Em,CA),e(CA,Vye),M(mR,Vye,null),e(Em,OZr),e(Em,Xye),e(Xye,VZr),b(m,qro,_),b(m,pr,_),M(fR,pr,null),e(pr,XZr),e(pr,Cm),e(Cm,zZr),e(Cm,Fae),e(Fae,QZr),e(Cm,WZr),e(Cm,Tae),e(Tae,UZr),e(Cm,HZr),e(pr,JZr),e(pr,gR),e(gR,YZr),e(gR,zye),e(zye,ZZr),e(gR,KZr),e(pr,eKr),e(pr,oa),M(hR,oa,null),e(oa,oKr),e(oa,Qye),e(Qye,rKr),e(oa,tKr),e(oa,wm),e(wm,aKr),e(wm,Wye),e(Wye,nKr),e(wm,sKr),e(wm,Mae),e(Mae,lKr),e(wm,iKr),e(oa,dKr),M(wA,oa,null),e(pr,cKr),e(pr,Qr),M(uR,Qr,null),e(Qr,mKr),e(Qr,Uye),e(Uye,fKr),e(Qr,gKr),e(Qr,qn),e(qn,hKr),e(qn,Hye),e(Hye,uKr),e(qn,pKr),e(qn,Jye),e(Jye,_Kr),e(qn,bKr),e(qn,Yye),e(Yye,vKr),e(qn,FKr),e(Qr,TKr),e(Qr,ve),e(ve,AA),e(AA,Zye),e(Zye,MKr),e(AA,EKr),e(AA,Eae),e(Eae,CKr),e(AA,wKr),e(ve,AKr),e(ve,LA),e(LA,Kye),e(Kye,LKr),e(LA,yKr),e(LA,Cae),e(Cae,xKr),e(LA,$Kr),e(ve,kKr),e(ve,yA),e(yA,e8e),e(e8e,SKr),e(yA,RKr),e(yA,wae),e(wae,PKr),e(yA,BKr),e(ve,IKr),e(ve,xA),e(xA,o8e),e(o8e,NKr),e(xA,qKr),e(xA,Aae),e(Aae,jKr),e(xA,DKr),e(ve,GKr),e(ve,$A),e($A,r8e),e(r8e,OKr),e($A,VKr),e($A,Lae),e(Lae,XKr),e($A,zKr),e(ve,QKr),e(ve,kA),e(kA,t8e),e(t8e,WKr),e(kA,UKr),e(kA,yae),e(yae,HKr),e(kA,JKr),e(ve,YKr),e(ve,SA),e(SA,a8e),e(a8e,ZKr),e(SA,KKr),e(SA,xae),e(xae,eet),e(SA,oet),e(ve,ret),e(ve,RA),e(RA,n8e),e(n8e,tet),e(RA,aet),e(RA,$ae),e($ae,net),e(RA,set),e(ve,iet),e(ve,PA),e(PA,s8e),e(s8e,det),e(PA,cet),e(PA,kae),e(kae,met),e(PA,fet),e(ve,get),e(ve,BA),e(BA,l8e),e(l8e,het),e(BA,uet),e(BA,Sae),e(Sae,pet),e(BA,_et),e(ve,bet),e(ve,IA),e(IA,i8e),e(i8e,vet),e(IA,Fet),e(IA,Rae),e(Rae,Tet),e(IA,Met),e(ve,Eet),e(ve,NA),e(NA,d8e),e(d8e,Cet),e(NA,wet),e(NA,Pae),e(Pae,Aet),e(NA,Let),e(ve,yet),e(ve,qA),e(qA,c8e),e(c8e,xet),e(qA,$et),e(qA,Bae),e(Bae,ket),e(qA,Set),e(ve,Ret),e(ve,jA),e(jA,m8e),e(m8e,Pet),e(jA,Bet),e(jA,Iae),e(Iae,Iet),e(jA,Net),e(ve,qet),e(ve,DA),e(DA,f8e),e(f8e,jet),e(DA,Det),e(DA,Nae),e(Nae,Get),e(DA,Oet),e(ve,Vet),e(ve,GA),e(GA,g8e),e(g8e,Xet),e(GA,zet),e(GA,qae),e(qae,Qet),e(GA,Wet),e(ve,Uet),e(ve,OA),e(OA,h8e),e(h8e,Het),e(OA,Jet),e(OA,jae),e(jae,Yet),e(OA,Zet),e(Qr,Ket),M(VA,Qr,null),b(m,jro,_),b(m,Am,_),e(Am,XA),e(XA,u8e),M(pR,u8e,null),e(Am,eot),e(Am,p8e),e(p8e,oot),b(m,Dro,_),b(m,_r,_),M(_R,_r,null),e(_r,rot),e(_r,Lm),e(Lm,tot),e(Lm,Dae),e(Dae,aot),e(Lm,not),e(Lm,Gae),e(Gae,sot),e(Lm,lot),e(_r,iot),e(_r,bR),e(bR,dot),e(bR,_8e),e(_8e,cot),e(bR,mot),e(_r,fot),e(_r,ra),M(vR,ra,null),e(ra,got),e(ra,b8e),e(b8e,hot),e(ra,uot),e(ra,ym),e(ym,pot),e(ym,v8e),e(v8e,_ot),e(ym,bot),e(ym,Oae),e(Oae,vot),e(ym,Fot),e(ra,Tot),M(zA,ra,null),e(_r,Mot),e(_r,Wr),M(FR,Wr,null),e(Wr,Eot),e(Wr,F8e),e(F8e,Cot),e(Wr,wot),e(Wr,jn),e(jn,Aot),e(jn,T8e),e(T8e,Lot),e(jn,yot),e(jn,M8e),e(M8e,xot),e(jn,$ot),e(jn,E8e),e(E8e,kot),e(jn,Sot),e(Wr,Rot),e(Wr,TR),e(TR,QA),e(QA,C8e),e(C8e,Pot),e(QA,Bot),e(QA,Vae),e(Vae,Iot),e(QA,Not),e(TR,qot),e(TR,WA),e(WA,w8e),e(w8e,jot),e(WA,Dot),e(WA,Xae),e(Xae,Got),e(WA,Oot),e(Wr,Vot),M(UA,Wr,null),b(m,Gro,_),b(m,xm,_),e(xm,HA),e(HA,A8e),M(MR,A8e,null),e(xm,Xot),e(xm,L8e),e(L8e,zot),b(m,Oro,_),b(m,br,_),M(ER,br,null),e(br,Qot),e(br,$m),e($m,Wot),e($m,zae),e(zae,Uot),e($m,Hot),e($m,Qae),e(Qae,Jot),e($m,Yot),e(br,Zot),e(br,CR),e(CR,Kot),e(CR,y8e),e(y8e,ert),e(CR,ort),e(br,rrt),e(br,ta),M(wR,ta,null),e(ta,trt),e(ta,x8e),e(x8e,art),e(ta,nrt),e(ta,km),e(km,srt),e(km,$8e),e($8e,lrt),e(km,irt),e(km,Wae),e(Wae,drt),e(km,crt),e(ta,mrt),M(JA,ta,null),e(br,frt),e(br,Ur),M(AR,Ur,null),e(Ur,grt),e(Ur,k8e),e(k8e,hrt),e(Ur,urt),e(Ur,Dn),e(Dn,prt),e(Dn,S8e),e(S8e,_rt),e(Dn,brt),e(Dn,R8e),e(R8e,vrt),e(Dn,Frt),e(Dn,P8e),e(P8e,Trt),e(Dn,Mrt),e(Ur,Ert),e(Ur,B8e),e(B8e,YA),e(YA,I8e),e(I8e,Crt),e(YA,wrt),e(YA,Uae),e(Uae,Art),e(YA,Lrt),e(Ur,yrt),M(ZA,Ur,null),b(m,Vro,_),b(m,Sm,_),e(Sm,KA),e(KA,N8e),M(LR,N8e,null),e(Sm,xrt),e(Sm,q8e),e(q8e,$rt),b(m,Xro,_),b(m,vr,_),M(yR,vr,null),e(vr,krt),e(vr,Rm),e(Rm,Srt),e(Rm,Hae),e(Hae,Rrt),e(Rm,Prt),e(Rm,Jae),e(Jae,Brt),e(Rm,Irt),e(vr,Nrt),e(vr,xR),e(xR,qrt),e(xR,j8e),e(j8e,jrt),e(xR,Drt),e(vr,Grt),e(vr,aa),M($R,aa,null),e(aa,Ort),e(aa,D8e),e(D8e,Vrt),e(aa,Xrt),e(aa,Pm),e(Pm,zrt),e(Pm,G8e),e(G8e,Qrt),e(Pm,Wrt),e(Pm,Yae),e(Yae,Urt),e(Pm,Hrt),e(aa,Jrt),M(e6,aa,null),e(vr,Yrt),e(vr,Hr),M(kR,Hr,null),e(Hr,Zrt),e(Hr,O8e),e(O8e,Krt),e(Hr,ett),e(Hr,Gn),e(Gn,ott),e(Gn,V8e),e(V8e,rtt),e(Gn,ttt),e(Gn,X8e),e(X8e,att),e(Gn,ntt),e(Gn,z8e),e(z8e,stt),e(Gn,ltt),e(Hr,itt),e(Hr,Q8e),e(Q8e,o6),e(o6,W8e),e(W8e,dtt),e(o6,ctt),e(o6,Zae),e(Zae,mtt),e(o6,ftt),e(Hr,gtt),M(r6,Hr,null),b(m,zro,_),b(m,Bm,_),e(Bm,t6),e(t6,U8e),M(SR,U8e,null),e(Bm,htt),e(Bm,H8e),e(H8e,utt),b(m,Qro,_),b(m,Fr,_),M(RR,Fr,null),e(Fr,ptt),e(Fr,Im),e(Im,_tt),e(Im,Kae),e(Kae,btt),e(Im,vtt),e(Im,ene),e(ene,Ftt),e(Im,Ttt),e(Fr,Mtt),e(Fr,PR),e(PR,Ett),e(PR,J8e),e(J8e,Ctt),e(PR,wtt),e(Fr,Att),e(Fr,na),M(BR,na,null),e(na,Ltt),e(na,Y8e),e(Y8e,ytt),e(na,xtt),e(na,Nm),e(Nm,$tt),e(Nm,Z8e),e(Z8e,ktt),e(Nm,Stt),e(Nm,one),e(one,Rtt),e(Nm,Ptt),e(na,Btt),M(a6,na,null),e(Fr,Itt),e(Fr,Jr),M(IR,Jr,null),e(Jr,Ntt),e(Jr,K8e),e(K8e,qtt),e(Jr,jtt),e(Jr,On),e(On,Dtt),e(On,e9e),e(e9e,Gtt),e(On,Ott),e(On,o9e),e(o9e,Vtt),e(On,Xtt),e(On,r9e),e(r9e,ztt),e(On,Qtt),e(Jr,Wtt),e(Jr,ce),e(ce,n6),e(n6,t9e),e(t9e,Utt),e(n6,Htt),e(n6,rne),e(rne,Jtt),e(n6,Ytt),e(ce,Ztt),e(ce,s6),e(s6,a9e),e(a9e,Ktt),e(s6,eat),e(s6,tne),e(tne,oat),e(s6,rat),e(ce,tat),e(ce,l6),e(l6,n9e),e(n9e,aat),e(l6,nat),e(l6,ane),e(ane,sat),e(l6,lat),e(ce,iat),e(ce,i6),e(i6,s9e),e(s9e,dat),e(i6,cat),e(i6,nne),e(nne,mat),e(i6,fat),e(ce,gat),e(ce,d6),e(d6,l9e),e(l9e,hat),e(d6,uat),e(d6,sne),e(sne,pat),e(d6,_at),e(ce,bat),e(ce,c6),e(c6,i9e),e(i9e,vat),e(c6,Fat),e(c6,lne),e(lne,Tat),e(c6,Mat),e(ce,Eat),e(ce,m6),e(m6,d9e),e(d9e,Cat),e(m6,wat),e(m6,ine),e(ine,Aat),e(m6,Lat),e(ce,yat),e(ce,f6),e(f6,c9e),e(c9e,xat),e(f6,$at),e(f6,dne),e(dne,kat),e(f6,Sat),e(ce,Rat),e(ce,g6),e(g6,m9e),e(m9e,Pat),e(g6,Bat),e(g6,cne),e(cne,Iat),e(g6,Nat),e(ce,qat),e(ce,h6),e(h6,f9e),e(f9e,jat),e(h6,Dat),e(h6,mne),e(mne,Gat),e(h6,Oat),e(ce,Vat),e(ce,u6),e(u6,g9e),e(g9e,Xat),e(u6,zat),e(u6,fne),e(fne,Qat),e(u6,Wat),e(ce,Uat),e(ce,p6),e(p6,h9e),e(h9e,Hat),e(p6,Jat),e(p6,gne),e(gne,Yat),e(p6,Zat),e(ce,Kat),e(ce,_6),e(_6,u9e),e(u9e,ent),e(_6,ont),e(_6,hne),e(hne,rnt),e(_6,tnt),e(ce,ant),e(ce,b6),e(b6,p9e),e(p9e,nnt),e(b6,snt),e(b6,une),e(une,lnt),e(b6,int),e(ce,dnt),e(ce,v6),e(v6,_9e),e(_9e,cnt),e(v6,mnt),e(v6,pne),e(pne,fnt),e(v6,gnt),e(ce,hnt),e(ce,F6),e(F6,b9e),e(b9e,unt),e(F6,pnt),e(F6,_ne),e(_ne,_nt),e(F6,bnt),e(ce,vnt),e(ce,T6),e(T6,v9e),e(v9e,Fnt),e(T6,Tnt),e(T6,bne),e(bne,Mnt),e(T6,Ent),e(ce,Cnt),e(ce,M6),e(M6,F9e),e(F9e,wnt),e(M6,Ant),e(M6,vne),e(vne,Lnt),e(M6,ynt),e(ce,xnt),e(ce,E6),e(E6,T9e),e(T9e,$nt),e(E6,knt),e(E6,Fne),e(Fne,Snt),e(E6,Rnt),e(ce,Pnt),e(ce,C6),e(C6,M9e),e(M9e,Bnt),e(C6,Int),e(C6,Tne),e(Tne,Nnt),e(C6,qnt),e(ce,jnt),e(ce,w6),e(w6,E9e),e(E9e,Dnt),e(w6,Gnt),e(w6,Mne),e(Mne,Ont),e(w6,Vnt),e(Jr,Xnt),M(A6,Jr,null),b(m,Wro,_),b(m,qm,_),e(qm,L6),e(L6,C9e),M(NR,C9e,null),e(qm,znt),e(qm,w9e),e(w9e,Qnt),b(m,Uro,_),b(m,Tr,_),M(qR,Tr,null),e(Tr,Wnt),e(Tr,jm),e(jm,Unt),e(jm,Ene),e(Ene,Hnt),e(jm,Jnt),e(jm,Cne),e(Cne,Ynt),e(jm,Znt),e(Tr,Knt),e(Tr,jR),e(jR,est),e(jR,A9e),e(A9e,ost),e(jR,rst),e(Tr,tst),e(Tr,sa),M(DR,sa,null),e(sa,ast),e(sa,L9e),e(L9e,nst),e(sa,sst),e(sa,Dm),e(Dm,lst),e(Dm,y9e),e(y9e,ist),e(Dm,dst),e(Dm,wne),e(wne,cst),e(Dm,mst),e(sa,fst),M(y6,sa,null),e(Tr,gst),e(Tr,Yr),M(GR,Yr,null),e(Yr,hst),e(Yr,x9e),e(x9e,ust),e(Yr,pst),e(Yr,Vn),e(Vn,_st),e(Vn,$9e),e($9e,bst),e(Vn,vst),e(Vn,k9e),e(k9e,Fst),e(Vn,Tst),e(Vn,S9e),e(S9e,Mst),e(Vn,Est),e(Yr,Cst),e(Yr,me),e(me,x6),e(x6,R9e),e(R9e,wst),e(x6,Ast),e(x6,Ane),e(Ane,Lst),e(x6,yst),e(me,xst),e(me,$6),e($6,P9e),e(P9e,$st),e($6,kst),e($6,Lne),e(Lne,Sst),e($6,Rst),e(me,Pst),e(me,k6),e(k6,B9e),e(B9e,Bst),e(k6,Ist),e(k6,yne),e(yne,Nst),e(k6,qst),e(me,jst),e(me,S6),e(S6,I9e),e(I9e,Dst),e(S6,Gst),e(S6,xne),e(xne,Ost),e(S6,Vst),e(me,Xst),e(me,R6),e(R6,N9e),e(N9e,zst),e(R6,Qst),e(R6,$ne),e($ne,Wst),e(R6,Ust),e(me,Hst),e(me,P6),e(P6,q9e),e(q9e,Jst),e(P6,Yst),e(P6,kne),e(kne,Zst),e(P6,Kst),e(me,elt),e(me,B6),e(B6,j9e),e(j9e,olt),e(B6,rlt),e(B6,Sne),e(Sne,tlt),e(B6,alt),e(me,nlt),e(me,I6),e(I6,D9e),e(D9e,slt),e(I6,llt),e(I6,Rne),e(Rne,ilt),e(I6,dlt),e(me,clt),e(me,N6),e(N6,G9e),e(G9e,mlt),e(N6,flt),e(N6,Pne),e(Pne,glt),e(N6,hlt),e(me,ult),e(me,q6),e(q6,O9e),e(O9e,plt),e(q6,_lt),e(q6,Bne),e(Bne,blt),e(q6,vlt),e(me,Flt),e(me,j6),e(j6,V9e),e(V9e,Tlt),e(j6,Mlt),e(j6,Ine),e(Ine,Elt),e(j6,Clt),e(me,wlt),e(me,D6),e(D6,X9e),e(X9e,Alt),e(D6,Llt),e(D6,Nne),e(Nne,ylt),e(D6,xlt),e(me,$lt),e(me,G6),e(G6,z9e),e(z9e,klt),e(G6,Slt),e(G6,qne),e(qne,Rlt),e(G6,Plt),e(me,Blt),e(me,O6),e(O6,Q9e),e(Q9e,Ilt),e(O6,Nlt),e(O6,jne),e(jne,qlt),e(O6,jlt),e(me,Dlt),e(me,V6),e(V6,W9e),e(W9e,Glt),e(V6,Olt),e(V6,Dne),e(Dne,Vlt),e(V6,Xlt),e(me,zlt),e(me,X6),e(X6,U9e),e(U9e,Qlt),e(X6,Wlt),e(X6,Gne),e(Gne,Ult),e(X6,Hlt),e(me,Jlt),e(me,z6),e(z6,H9e),e(H9e,Ylt),e(z6,Zlt),e(z6,One),e(One,Klt),e(z6,eit),e(me,oit),e(me,Q6),e(Q6,J9e),e(J9e,rit),e(Q6,tit),e(Q6,Vne),e(Vne,ait),e(Q6,nit),e(me,sit),e(me,W6),e(W6,Y9e),e(Y9e,lit),e(W6,iit),e(W6,Xne),e(Xne,dit),e(W6,cit),e(me,mit),e(me,U6),e(U6,Z9e),e(Z9e,fit),e(U6,git),e(U6,zne),e(zne,hit),e(U6,uit),e(me,pit),e(me,H6),e(H6,K9e),e(K9e,_it),e(H6,bit),e(H6,Qne),e(Qne,vit),e(H6,Fit),e(Yr,Tit),M(J6,Yr,null),b(m,Hro,_),b(m,Gm,_),e(Gm,Y6),e(Y6,exe),M(OR,exe,null),e(Gm,Mit),e(Gm,oxe),e(oxe,Eit),b(m,Jro,_),b(m,Mr,_),M(VR,Mr,null),e(Mr,Cit),e(Mr,Om),e(Om,wit),e(Om,Wne),e(Wne,Ait),e(Om,Lit),e(Om,Une),e(Une,yit),e(Om,xit),e(Mr,$it),e(Mr,XR),e(XR,kit),e(XR,rxe),e(rxe,Sit),e(XR,Rit),e(Mr,Pit),e(Mr,la),M(zR,la,null),e(la,Bit),e(la,txe),e(txe,Iit),e(la,Nit),e(la,Vm),e(Vm,qit),e(Vm,axe),e(axe,jit),e(Vm,Dit),e(Vm,Hne),e(Hne,Git),e(Vm,Oit),e(la,Vit),M(Z6,la,null),e(Mr,Xit),e(Mr,Zr),M(QR,Zr,null),e(Zr,zit),e(Zr,nxe),e(nxe,Qit),e(Zr,Wit),e(Zr,Xn),e(Xn,Uit),e(Xn,sxe),e(sxe,Hit),e(Xn,Jit),e(Xn,lxe),e(lxe,Yit),e(Xn,Zit),e(Xn,ixe),e(ixe,Kit),e(Xn,edt),e(Zr,odt),e(Zr,dxe),e(dxe,K6),e(K6,cxe),e(cxe,rdt),e(K6,tdt),e(K6,Jne),e(Jne,adt),e(K6,ndt),e(Zr,sdt),M(e7,Zr,null),b(m,Yro,_),b(m,Xm,_),e(Xm,o7),e(o7,mxe),M(WR,mxe,null),e(Xm,ldt),e(Xm,fxe),e(fxe,idt),b(m,Zro,_),b(m,Er,_),M(UR,Er,null),e(Er,ddt),e(Er,zm),e(zm,cdt),e(zm,Yne),e(Yne,mdt),e(zm,fdt),e(zm,Zne),e(Zne,gdt),e(zm,hdt),e(Er,udt),e(Er,HR),e(HR,pdt),e(HR,gxe),e(gxe,_dt),e(HR,bdt),e(Er,vdt),e(Er,ia),M(JR,ia,null),e(ia,Fdt),e(ia,hxe),e(hxe,Tdt),e(ia,Mdt),e(ia,Qm),e(Qm,Edt),e(Qm,uxe),e(uxe,Cdt),e(Qm,wdt),e(Qm,Kne),e(Kne,Adt),e(Qm,Ldt),e(ia,ydt),M(r7,ia,null),e(Er,xdt),e(Er,Kr),M(YR,Kr,null),e(Kr,$dt),e(Kr,pxe),e(pxe,kdt),e(Kr,Sdt),e(Kr,zn),e(zn,Rdt),e(zn,_xe),e(_xe,Pdt),e(zn,Bdt),e(zn,bxe),e(bxe,Idt),e(zn,Ndt),e(zn,vxe),e(vxe,qdt),e(zn,jdt),e(Kr,Ddt),e(Kr,Fxe),e(Fxe,t7),e(t7,Txe),e(Txe,Gdt),e(t7,Odt),e(t7,ese),e(ese,Vdt),e(t7,Xdt),e(Kr,zdt),M(a7,Kr,null),b(m,Kro,_),b(m,Wm,_),e(Wm,n7),e(n7,Mxe),M(ZR,Mxe,null),e(Wm,Qdt),e(Wm,Exe),e(Exe,Wdt),b(m,eto,_),b(m,Cr,_),M(KR,Cr,null),e(Cr,Udt),e(Cr,Um),e(Um,Hdt),e(Um,ose),e(ose,Jdt),e(Um,Ydt),e(Um,rse),e(rse,Zdt),e(Um,Kdt),e(Cr,ect),e(Cr,eP),e(eP,oct),e(eP,Cxe),e(Cxe,rct),e(eP,tct),e(Cr,act),e(Cr,da),M(oP,da,null),e(da,nct),e(da,wxe),e(wxe,sct),e(da,lct),e(da,Hm),e(Hm,ict),e(Hm,Axe),e(Axe,dct),e(Hm,cct),e(Hm,tse),e(tse,mct),e(Hm,fct),e(da,gct),M(s7,da,null),e(Cr,hct),e(Cr,et),M(rP,et,null),e(et,uct),e(et,Lxe),e(Lxe,pct),e(et,_ct),e(et,Qn),e(Qn,bct),e(Qn,yxe),e(yxe,vct),e(Qn,Fct),e(Qn,xxe),e(xxe,Tct),e(Qn,Mct),e(Qn,$xe),e($xe,Ect),e(Qn,Cct),e(et,wct),e(et,te),e(te,l7),e(l7,kxe),e(kxe,Act),e(l7,Lct),e(l7,ase),e(ase,yct),e(l7,xct),e(te,$ct),e(te,i7),e(i7,Sxe),e(Sxe,kct),e(i7,Sct),e(i7,nse),e(nse,Rct),e(i7,Pct),e(te,Bct),e(te,d7),e(d7,Rxe),e(Rxe,Ict),e(d7,Nct),e(d7,sse),e(sse,qct),e(d7,jct),e(te,Dct),e(te,c7),e(c7,Pxe),e(Pxe,Gct),e(c7,Oct),e(c7,lse),e(lse,Vct),e(c7,Xct),e(te,zct),e(te,m7),e(m7,Bxe),e(Bxe,Qct),e(m7,Wct),e(m7,ise),e(ise,Uct),e(m7,Hct),e(te,Jct),e(te,f7),e(f7,Ixe),e(Ixe,Yct),e(f7,Zct),e(f7,dse),e(dse,Kct),e(f7,emt),e(te,omt),e(te,g7),e(g7,Nxe),e(Nxe,rmt),e(g7,tmt),e(g7,cse),e(cse,amt),e(g7,nmt),e(te,smt),e(te,h7),e(h7,qxe),e(qxe,lmt),e(h7,imt),e(h7,mse),e(mse,dmt),e(h7,cmt),e(te,mmt),e(te,u7),e(u7,jxe),e(jxe,fmt),e(u7,gmt),e(u7,fse),e(fse,hmt),e(u7,umt),e(te,pmt),e(te,p7),e(p7,Dxe),e(Dxe,_mt),e(p7,bmt),e(p7,gse),e(gse,vmt),e(p7,Fmt),e(te,Tmt),e(te,_7),e(_7,Gxe),e(Gxe,Mmt),e(_7,Emt),e(_7,hse),e(hse,Cmt),e(_7,wmt),e(te,Amt),e(te,b7),e(b7,Oxe),e(Oxe,Lmt),e(b7,ymt),e(b7,use),e(use,xmt),e(b7,$mt),e(te,kmt),e(te,v7),e(v7,Vxe),e(Vxe,Smt),e(v7,Rmt),e(v7,pse),e(pse,Pmt),e(v7,Bmt),e(te,Imt),e(te,F7),e(F7,Xxe),e(Xxe,Nmt),e(F7,qmt),e(F7,_se),e(_se,jmt),e(F7,Dmt),e(te,Gmt),e(te,T7),e(T7,zxe),e(zxe,Omt),e(T7,Vmt),e(T7,bse),e(bse,Xmt),e(T7,zmt),e(te,Qmt),e(te,M7),e(M7,Qxe),e(Qxe,Wmt),e(M7,Umt),e(M7,vse),e(vse,Hmt),e(M7,Jmt),e(te,Ymt),e(te,E7),e(E7,Wxe),e(Wxe,Zmt),e(E7,Kmt),e(E7,Fse),e(Fse,eft),e(E7,oft),e(te,rft),e(te,C7),e(C7,Uxe),e(Uxe,tft),e(C7,aft),e(C7,Tse),e(Tse,nft),e(C7,sft),e(te,lft),e(te,w7),e(w7,Hxe),e(Hxe,ift),e(w7,dft),e(w7,Mse),e(Mse,cft),e(w7,mft),e(te,fft),e(te,A7),e(A7,Jxe),e(Jxe,gft),e(A7,hft),e(A7,Ese),e(Ese,uft),e(A7,pft),e(te,_ft),e(te,L7),e(L7,Yxe),e(Yxe,bft),e(L7,vft),e(L7,Cse),e(Cse,Fft),e(L7,Tft),e(te,Mft),e(te,y7),e(y7,Zxe),e(Zxe,Eft),e(y7,Cft),e(y7,wse),e(wse,wft),e(y7,Aft),e(te,Lft),e(te,x7),e(x7,Kxe),e(Kxe,yft),e(x7,xft),e(x7,Ase),e(Ase,$ft),e(x7,kft),e(te,Sft),e(te,$7),e($7,e$e),e(e$e,Rft),e($7,Pft),e($7,Lse),e(Lse,Bft),e($7,Ift),e(te,Nft),e(te,k7),e(k7,o$e),e(o$e,qft),e(k7,jft),e(k7,yse),e(yse,Dft),e(k7,Gft),e(te,Oft),e(te,S7),e(S7,r$e),e(r$e,Vft),e(S7,Xft),e(S7,xse),e(xse,zft),e(S7,Qft),e(te,Wft),e(te,R7),e(R7,t$e),e(t$e,Uft),e(R7,Hft),e(R7,$se),e($se,Jft),e(R7,Yft),e(et,Zft),M(P7,et,null),b(m,oto,_),b(m,Jm,_),e(Jm,B7),e(B7,a$e),M(tP,a$e,null),e(Jm,Kft),e(Jm,n$e),e(n$e,egt),b(m,rto,_),b(m,wr,_),M(aP,wr,null),e(wr,ogt),e(wr,Ym),e(Ym,rgt),e(Ym,kse),e(kse,tgt),e(Ym,agt),e(Ym,Sse),e(Sse,ngt),e(Ym,sgt),e(wr,lgt),e(wr,nP),e(nP,igt),e(nP,s$e),e(s$e,dgt),e(nP,cgt),e(wr,mgt),e(wr,ca),M(sP,ca,null),e(ca,fgt),e(ca,l$e),e(l$e,ggt),e(ca,hgt),e(ca,Zm),e(Zm,ugt),e(Zm,i$e),e(i$e,pgt),e(Zm,_gt),e(Zm,Rse),e(Rse,bgt),e(Zm,vgt),e(ca,Fgt),M(I7,ca,null),e(wr,Tgt),e(wr,ot),M(lP,ot,null),e(ot,Mgt),e(ot,d$e),e(d$e,Egt),e(ot,Cgt),e(ot,Wn),e(Wn,wgt),e(Wn,c$e),e(c$e,Agt),e(Wn,Lgt),e(Wn,m$e),e(m$e,ygt),e(Wn,xgt),e(Wn,f$e),e(f$e,$gt),e(Wn,kgt),e(ot,Sgt),e(ot,xe),e(xe,N7),e(N7,g$e),e(g$e,Rgt),e(N7,Pgt),e(N7,Pse),e(Pse,Bgt),e(N7,Igt),e(xe,Ngt),e(xe,q7),e(q7,h$e),e(h$e,qgt),e(q7,jgt),e(q7,Bse),e(Bse,Dgt),e(q7,Ggt),e(xe,Ogt),e(xe,j7),e(j7,u$e),e(u$e,Vgt),e(j7,Xgt),e(j7,Ise),e(Ise,zgt),e(j7,Qgt),e(xe,Wgt),e(xe,D7),e(D7,p$e),e(p$e,Ugt),e(D7,Hgt),e(D7,Nse),e(Nse,Jgt),e(D7,Ygt),e(xe,Zgt),e(xe,G7),e(G7,_$e),e(_$e,Kgt),e(G7,eht),e(G7,qse),e(qse,oht),e(G7,rht),e(xe,tht),e(xe,O7),e(O7,b$e),e(b$e,aht),e(O7,nht),e(O7,jse),e(jse,sht),e(O7,lht),e(xe,iht),e(xe,V7),e(V7,v$e),e(v$e,dht),e(V7,cht),e(V7,Dse),e(Dse,mht),e(V7,fht),e(xe,ght),e(xe,X7),e(X7,F$e),e(F$e,hht),e(X7,uht),e(X7,Gse),e(Gse,pht),e(X7,_ht),e(xe,bht),e(xe,z7),e(z7,T$e),e(T$e,vht),e(z7,Fht),e(z7,Ose),e(Ose,Tht),e(z7,Mht),e(xe,Eht),e(xe,Q7),e(Q7,M$e),e(M$e,Cht),e(Q7,wht),e(Q7,Vse),e(Vse,Aht),e(Q7,Lht),e(ot,yht),M(W7,ot,null),b(m,tto,_),b(m,Km,_),e(Km,U7),e(U7,E$e),M(iP,E$e,null),e(Km,xht),e(Km,C$e),e(C$e,$ht),b(m,ato,_),b(m,Ar,_),M(dP,Ar,null),e(Ar,kht),e(Ar,ef),e(ef,Sht),e(ef,Xse),e(Xse,Rht),e(ef,Pht),e(ef,zse),e(zse,Bht),e(ef,Iht),e(Ar,Nht),e(Ar,cP),e(cP,qht),e(cP,w$e),e(w$e,jht),e(cP,Dht),e(Ar,Ght),e(Ar,ma),M(mP,ma,null),e(ma,Oht),e(ma,A$e),e(A$e,Vht),e(ma,Xht),e(ma,of),e(of,zht),e(of,L$e),e(L$e,Qht),e(of,Wht),e(of,Qse),e(Qse,Uht),e(of,Hht),e(ma,Jht),M(H7,ma,null),e(Ar,Yht),e(Ar,rt),M(fP,rt,null),e(rt,Zht),e(rt,y$e),e(y$e,Kht),e(rt,eut),e(rt,Un),e(Un,out),e(Un,x$e),e(x$e,rut),e(Un,tut),e(Un,$$e),e($$e,aut),e(Un,nut),e(Un,k$e),e(k$e,sut),e(Un,lut),e(rt,iut),e(rt,Ee),e(Ee,J7),e(J7,S$e),e(S$e,dut),e(J7,cut),e(J7,Wse),e(Wse,mut),e(J7,fut),e(Ee,gut),e(Ee,Y7),e(Y7,R$e),e(R$e,hut),e(Y7,uut),e(Y7,Use),e(Use,put),e(Y7,_ut),e(Ee,but),e(Ee,Z7),e(Z7,P$e),e(P$e,vut),e(Z7,Fut),e(Z7,Hse),e(Hse,Tut),e(Z7,Mut),e(Ee,Eut),e(Ee,K7),e(K7,B$e),e(B$e,Cut),e(K7,wut),e(K7,Jse),e(Jse,Aut),e(K7,Lut),e(Ee,yut),e(Ee,eL),e(eL,I$e),e(I$e,xut),e(eL,$ut),e(eL,Yse),e(Yse,kut),e(eL,Sut),e(Ee,Rut),e(Ee,oL),e(oL,N$e),e(N$e,Put),e(oL,But),e(oL,Zse),e(Zse,Iut),e(oL,Nut),e(Ee,qut),e(Ee,rL),e(rL,q$e),e(q$e,jut),e(rL,Dut),e(rL,Kse),e(Kse,Gut),e(rL,Out),e(Ee,Vut),e(Ee,tL),e(tL,j$e),e(j$e,Xut),e(tL,zut),e(tL,ele),e(ele,Qut),e(tL,Wut),e(Ee,Uut),e(Ee,aL),e(aL,D$e),e(D$e,Hut),e(aL,Jut),e(aL,ole),e(ole,Yut),e(aL,Zut),e(Ee,Kut),e(Ee,nL),e(nL,G$e),e(G$e,ept),e(nL,opt),e(nL,rle),e(rle,rpt),e(nL,tpt),e(Ee,apt),e(Ee,sL),e(sL,O$e),e(O$e,npt),e(sL,spt),e(sL,tle),e(tle,lpt),e(sL,ipt),e(Ee,dpt),e(Ee,lL),e(lL,V$e),e(V$e,cpt),e(lL,mpt),e(lL,ale),e(ale,fpt),e(lL,gpt),e(Ee,hpt),e(Ee,iL),e(iL,X$e),e(X$e,upt),e(iL,ppt),e(iL,nle),e(nle,_pt),e(iL,bpt),e(rt,vpt),M(dL,rt,null),b(m,nto,_),b(m,rf,_),e(rf,cL),e(cL,z$e),M(gP,z$e,null),e(rf,Fpt),e(rf,Q$e),e(Q$e,Tpt),b(m,sto,_),b(m,Lr,_),M(hP,Lr,null),e(Lr,Mpt),e(Lr,tf),e(tf,Ept),e(tf,sle),e(sle,Cpt),e(tf,wpt),e(tf,lle),e(lle,Apt),e(tf,Lpt),e(Lr,ypt),e(Lr,uP),e(uP,xpt),e(uP,W$e),e(W$e,$pt),e(uP,kpt),e(Lr,Spt),e(Lr,fa),M(pP,fa,null),e(fa,Rpt),e(fa,U$e),e(U$e,Ppt),e(fa,Bpt),e(fa,af),e(af,Ipt),e(af,H$e),e(H$e,Npt),e(af,qpt),e(af,ile),e(ile,jpt),e(af,Dpt),e(fa,Gpt),M(mL,fa,null),e(Lr,Opt),e(Lr,tt),M(_P,tt,null),e(tt,Vpt),e(tt,J$e),e(J$e,Xpt),e(tt,zpt),e(tt,Hn),e(Hn,Qpt),e(Hn,Y$e),e(Y$e,Wpt),e(Hn,Upt),e(Hn,Z$e),e(Z$e,Hpt),e(Hn,Jpt),e(Hn,K$e),e(K$e,Ypt),e(Hn,Zpt),e(tt,Kpt),e(tt,$e),e($e,fL),e(fL,eke),e(eke,e_t),e(fL,o_t),e(fL,dle),e(dle,r_t),e(fL,t_t),e($e,a_t),e($e,gL),e(gL,oke),e(oke,n_t),e(gL,s_t),e(gL,cle),e(cle,l_t),e(gL,i_t),e($e,d_t),e($e,hL),e(hL,rke),e(rke,c_t),e(hL,m_t),e(hL,mle),e(mle,f_t),e(hL,g_t),e($e,h_t),e($e,uL),e(uL,tke),e(tke,u_t),e(uL,p_t),e(uL,fle),e(fle,__t),e(uL,b_t),e($e,v_t),e($e,pL),e(pL,ake),e(ake,F_t),e(pL,T_t),e(pL,gle),e(gle,M_t),e(pL,E_t),e($e,C_t),e($e,_L),e(_L,nke),e(nke,w_t),e(_L,A_t),e(_L,hle),e(hle,L_t),e(_L,y_t),e($e,x_t),e($e,bL),e(bL,ske),e(ske,$_t),e(bL,k_t),e(bL,ule),e(ule,S_t),e(bL,R_t),e($e,P_t),e($e,vL),e(vL,lke),e(lke,B_t),e(vL,I_t),e(vL,ple),e(ple,N_t),e(vL,q_t),e($e,j_t),e($e,FL),e(FL,ike),e(ike,D_t),e(FL,G_t),e(FL,_le),e(_le,O_t),e(FL,V_t),e($e,X_t),e($e,TL),e(TL,dke),e(dke,z_t),e(TL,Q_t),e(TL,ble),e(ble,W_t),e(TL,U_t),e(tt,H_t),M(ML,tt,null),b(m,lto,_),b(m,nf,_),e(nf,EL),e(EL,cke),M(bP,cke,null),e(nf,J_t),e(nf,mke),e(mke,Y_t),b(m,ito,_),b(m,yr,_),M(vP,yr,null),e(yr,Z_t),e(yr,sf),e(sf,K_t),e(sf,vle),e(vle,e1t),e(sf,o1t),e(sf,Fle),e(Fle,r1t),e(sf,t1t),e(yr,a1t),e(yr,FP),e(FP,n1t),e(FP,fke),e(fke,s1t),e(FP,l1t),e(yr,i1t),e(yr,ga),M(TP,ga,null),e(ga,d1t),e(ga,gke),e(gke,c1t),e(ga,m1t),e(ga,lf),e(lf,f1t),e(lf,hke),e(hke,g1t),e(lf,h1t),e(lf,Tle),e(Tle,u1t),e(lf,p1t),e(ga,_1t),M(CL,ga,null),e(yr,b1t),e(yr,at),M(MP,at,null),e(at,v1t),e(at,uke),e(uke,F1t),e(at,T1t),e(at,Jn),e(Jn,M1t),e(Jn,pke),e(pke,E1t),e(Jn,C1t),e(Jn,_ke),e(_ke,w1t),e(Jn,A1t),e(Jn,bke),e(bke,L1t),e(Jn,y1t),e(at,x1t),e(at,ke),e(ke,wL),e(wL,vke),e(vke,$1t),e(wL,k1t),e(wL,Mle),e(Mle,S1t),e(wL,R1t),e(ke,P1t),e(ke,AL),e(AL,Fke),e(Fke,B1t),e(AL,I1t),e(AL,Ele),e(Ele,N1t),e(AL,q1t),e(ke,j1t),e(ke,LL),e(LL,Tke),e(Tke,D1t),e(LL,G1t),e(LL,Cle),e(Cle,O1t),e(LL,V1t),e(ke,X1t),e(ke,yL),e(yL,Mke),e(Mke,z1t),e(yL,Q1t),e(yL,wle),e(wle,W1t),e(yL,U1t),e(ke,H1t),e(ke,xL),e(xL,Eke),e(Eke,J1t),e(xL,Y1t),e(xL,Ale),e(Ale,Z1t),e(xL,K1t),e(ke,ebt),e(ke,$L),e($L,Cke),e(Cke,obt),e($L,rbt),e($L,Lle),e(Lle,tbt),e($L,abt),e(ke,nbt),e(ke,kL),e(kL,wke),e(wke,sbt),e(kL,lbt),e(kL,yle),e(yle,ibt),e(kL,dbt),e(ke,cbt),e(ke,SL),e(SL,Ake),e(Ake,mbt),e(SL,fbt),e(SL,xle),e(xle,gbt),e(SL,hbt),e(ke,ubt),e(ke,RL),e(RL,Lke),e(Lke,pbt),e(RL,_bt),e(RL,$le),e($le,bbt),e(RL,vbt),e(ke,Fbt),e(ke,PL),e(PL,yke),e(yke,Tbt),e(PL,Mbt),e(PL,kle),e(kle,Ebt),e(PL,Cbt),e(at,wbt),M(BL,at,null),b(m,dto,_),b(m,df,_),e(df,IL),e(IL,xke),M(EP,xke,null),e(df,Abt),e(df,$ke),e($ke,Lbt),b(m,cto,_),b(m,xr,_),M(CP,xr,null),e(xr,ybt),e(xr,cf),e(cf,xbt),e(cf,Sle),e(Sle,$bt),e(cf,kbt),e(cf,Rle),e(Rle,Sbt),e(cf,Rbt),e(xr,Pbt),e(xr,wP),e(wP,Bbt),e(wP,kke),e(kke,Ibt),e(wP,Nbt),e(xr,qbt),e(xr,ha),M(AP,ha,null),e(ha,jbt),e(ha,Ske),e(Ske,Dbt),e(ha,Gbt),e(ha,mf),e(mf,Obt),e(mf,Rke),e(Rke,Vbt),e(mf,Xbt),e(mf,Ple),e(Ple,zbt),e(mf,Qbt),e(ha,Wbt),M(NL,ha,null),e(xr,Ubt),e(xr,nt),M(LP,nt,null),e(nt,Hbt),e(nt,Pke),e(Pke,Jbt),e(nt,Ybt),e(nt,Yn),e(Yn,Zbt),e(Yn,Bke),e(Bke,Kbt),e(Yn,e2t),e(Yn,Ike),e(Ike,o2t),e(Yn,r2t),e(Yn,Nke),e(Nke,t2t),e(Yn,a2t),e(nt,n2t),e(nt,Se),e(Se,qL),e(qL,qke),e(qke,s2t),e(qL,l2t),e(qL,Ble),e(Ble,i2t),e(qL,d2t),e(Se,c2t),e(Se,jL),e(jL,jke),e(jke,m2t),e(jL,f2t),e(jL,Ile),e(Ile,g2t),e(jL,h2t),e(Se,u2t),e(Se,DL),e(DL,Dke),e(Dke,p2t),e(DL,_2t),e(DL,Nle),e(Nle,b2t),e(DL,v2t),e(Se,F2t),e(Se,GL),e(GL,Gke),e(Gke,T2t),e(GL,M2t),e(GL,qle),e(qle,E2t),e(GL,C2t),e(Se,w2t),e(Se,OL),e(OL,Oke),e(Oke,A2t),e(OL,L2t),e(OL,jle),e(jle,y2t),e(OL,x2t),e(Se,$2t),e(Se,VL),e(VL,Vke),e(Vke,k2t),e(VL,S2t),e(VL,Dle),e(Dle,R2t),e(VL,P2t),e(Se,B2t),e(Se,XL),e(XL,Xke),e(Xke,I2t),e(XL,N2t),e(XL,Gle),e(Gle,q2t),e(XL,j2t),e(Se,D2t),e(Se,zL),e(zL,zke),e(zke,G2t),e(zL,O2t),e(zL,Ole),e(Ole,V2t),e(zL,X2t),e(Se,z2t),e(Se,QL),e(QL,Qke),e(Qke,Q2t),e(QL,W2t),e(QL,Vle),e(Vle,U2t),e(QL,H2t),e(Se,J2t),e(Se,WL),e(WL,Wke),e(Wke,Y2t),e(WL,Z2t),e(WL,Xle),e(Xle,K2t),e(WL,evt),e(nt,ovt),M(UL,nt,null),b(m,mto,_),b(m,ff,_),e(ff,HL),e(HL,Uke),M(yP,Uke,null),e(ff,rvt),e(ff,Hke),e(Hke,tvt),b(m,fto,_),b(m,$r,_),M(xP,$r,null),e($r,avt),e($r,gf),e(gf,nvt),e(gf,zle),e(zle,svt),e(gf,lvt),e(gf,Qle),e(Qle,ivt),e(gf,dvt),e($r,cvt),e($r,$P),e($P,mvt),e($P,Jke),e(Jke,fvt),e($P,gvt),e($r,hvt),e($r,ua),M(kP,ua,null),e(ua,uvt),e(ua,Yke),e(Yke,pvt),e(ua,_vt),e(ua,hf),e(hf,bvt),e(hf,Zke),e(Zke,vvt),e(hf,Fvt),e(hf,Wle),e(Wle,Tvt),e(hf,Mvt),e(ua,Evt),M(JL,ua,null),e($r,Cvt),e($r,st),M(SP,st,null),e(st,wvt),e(st,Kke),e(Kke,Avt),e(st,Lvt),e(st,Zn),e(Zn,yvt),e(Zn,eSe),e(eSe,xvt),e(Zn,$vt),e(Zn,oSe),e(oSe,kvt),e(Zn,Svt),e(Zn,rSe),e(rSe,Rvt),e(Zn,Pvt),e(st,Bvt),e(st,Re),e(Re,YL),e(YL,tSe),e(tSe,Ivt),e(YL,Nvt),e(YL,Ule),e(Ule,qvt),e(YL,jvt),e(Re,Dvt),e(Re,ZL),e(ZL,aSe),e(aSe,Gvt),e(ZL,Ovt),e(ZL,Hle),e(Hle,Vvt),e(ZL,Xvt),e(Re,zvt),e(Re,KL),e(KL,nSe),e(nSe,Qvt),e(KL,Wvt),e(KL,Jle),e(Jle,Uvt),e(KL,Hvt),e(Re,Jvt),e(Re,ey),e(ey,sSe),e(sSe,Yvt),e(ey,Zvt),e(ey,Yle),e(Yle,Kvt),e(ey,eFt),e(Re,oFt),e(Re,oy),e(oy,lSe),e(lSe,rFt),e(oy,tFt),e(oy,Zle),e(Zle,aFt),e(oy,nFt),e(Re,sFt),e(Re,ry),e(ry,iSe),e(iSe,lFt),e(ry,iFt),e(ry,Kle),e(Kle,dFt),e(ry,cFt),e(Re,mFt),e(Re,ty),e(ty,dSe),e(dSe,fFt),e(ty,gFt),e(ty,eie),e(eie,hFt),e(ty,uFt),e(Re,pFt),e(Re,ay),e(ay,cSe),e(cSe,_Ft),e(ay,bFt),e(ay,oie),e(oie,vFt),e(ay,FFt),e(Re,TFt),e(Re,ny),e(ny,mSe),e(mSe,MFt),e(ny,EFt),e(ny,rie),e(rie,CFt),e(ny,wFt),e(Re,AFt),e(Re,sy),e(sy,fSe),e(fSe,LFt),e(sy,yFt),e(sy,tie),e(tie,xFt),e(sy,$Ft),e(st,kFt),M(ly,st,null),b(m,gto,_),b(m,uf,_),e(uf,iy),e(iy,gSe),M(RP,gSe,null),e(uf,SFt),e(uf,hSe),e(hSe,RFt),b(m,hto,_),b(m,kr,_),M(PP,kr,null),e(kr,PFt),e(kr,pf),e(pf,BFt),e(pf,aie),e(aie,IFt),e(pf,NFt),e(pf,nie),e(nie,qFt),e(pf,jFt),e(kr,DFt),e(kr,BP),e(BP,GFt),e(BP,uSe),e(uSe,OFt),e(BP,VFt),e(kr,XFt),e(kr,pa),M(IP,pa,null),e(pa,zFt),e(pa,pSe),e(pSe,QFt),e(pa,WFt),e(pa,_f),e(_f,UFt),e(_f,_Se),e(_Se,HFt),e(_f,JFt),e(_f,sie),e(sie,YFt),e(_f,ZFt),e(pa,KFt),M(dy,pa,null),e(kr,eTt),e(kr,lt),M(NP,lt,null),e(lt,oTt),e(lt,bSe),e(bSe,rTt),e(lt,tTt),e(lt,Kn),e(Kn,aTt),e(Kn,vSe),e(vSe,nTt),e(Kn,sTt),e(Kn,FSe),e(FSe,lTt),e(Kn,iTt),e(Kn,TSe),e(TSe,dTt),e(Kn,cTt),e(lt,mTt),e(lt,Xe),e(Xe,cy),e(cy,MSe),e(MSe,fTt),e(cy,gTt),e(cy,lie),e(lie,hTt),e(cy,uTt),e(Xe,pTt),e(Xe,my),e(my,ESe),e(ESe,_Tt),e(my,bTt),e(my,iie),e(iie,vTt),e(my,FTt),e(Xe,TTt),e(Xe,fy),e(fy,CSe),e(CSe,MTt),e(fy,ETt),e(fy,die),e(die,CTt),e(fy,wTt),e(Xe,ATt),e(Xe,gy),e(gy,wSe),e(wSe,LTt),e(gy,yTt),e(gy,cie),e(cie,xTt),e(gy,$Tt),e(Xe,kTt),e(Xe,hy),e(hy,ASe),e(ASe,STt),e(hy,RTt),e(hy,mie),e(mie,PTt),e(hy,BTt),e(Xe,ITt),e(Xe,uy),e(uy,LSe),e(LSe,NTt),e(uy,qTt),e(uy,fie),e(fie,jTt),e(uy,DTt),e(Xe,GTt),e(Xe,py),e(py,ySe),e(ySe,OTt),e(py,VTt),e(py,gie),e(gie,XTt),e(py,zTt),e(Xe,QTt),e(Xe,_y),e(_y,xSe),e(xSe,WTt),e(_y,UTt),e(_y,hie),e(hie,HTt),e(_y,JTt),e(lt,YTt),M(by,lt,null),b(m,uto,_),b(m,bf,_),e(bf,vy),e(vy,$Se),M(qP,$Se,null),e(bf,ZTt),e(bf,kSe),e(kSe,KTt),b(m,pto,_),b(m,Sr,_),M(jP,Sr,null),e(Sr,eMt),e(Sr,vf),e(vf,oMt),e(vf,uie),e(uie,rMt),e(vf,tMt),e(vf,pie),e(pie,aMt),e(vf,nMt),e(Sr,sMt),e(Sr,DP),e(DP,lMt),e(DP,SSe),e(SSe,iMt),e(DP,dMt),e(Sr,cMt),e(Sr,_a),M(GP,_a,null),e(_a,mMt),e(_a,RSe),e(RSe,fMt),e(_a,gMt),e(_a,Ff),e(Ff,hMt),e(Ff,PSe),e(PSe,uMt),e(Ff,pMt),e(Ff,_ie),e(_ie,_Mt),e(Ff,bMt),e(_a,vMt),M(Fy,_a,null),e(Sr,FMt),e(Sr,it),M(OP,it,null),e(it,TMt),e(it,BSe),e(BSe,MMt),e(it,EMt),e(it,es),e(es,CMt),e(es,ISe),e(ISe,wMt),e(es,AMt),e(es,NSe),e(NSe,LMt),e(es,yMt),e(es,qSe),e(qSe,xMt),e(es,$Mt),e(it,kMt),e(it,ze),e(ze,Ty),e(Ty,jSe),e(jSe,SMt),e(Ty,RMt),e(Ty,bie),e(bie,PMt),e(Ty,BMt),e(ze,IMt),e(ze,My),e(My,DSe),e(DSe,NMt),e(My,qMt),e(My,vie),e(vie,jMt),e(My,DMt),e(ze,GMt),e(ze,Ey),e(Ey,GSe),e(GSe,OMt),e(Ey,VMt),e(Ey,Fie),e(Fie,XMt),e(Ey,zMt),e(ze,QMt),e(ze,Cy),e(Cy,OSe),e(OSe,WMt),e(Cy,UMt),e(Cy,Tie),e(Tie,HMt),e(Cy,JMt),e(ze,YMt),e(ze,wy),e(wy,VSe),e(VSe,ZMt),e(wy,KMt),e(wy,Mie),e(Mie,eEt),e(wy,oEt),e(ze,rEt),e(ze,Ay),e(Ay,XSe),e(XSe,tEt),e(Ay,aEt),e(Ay,Eie),e(Eie,nEt),e(Ay,sEt),e(ze,lEt),e(ze,Ly),e(Ly,zSe),e(zSe,iEt),e(Ly,dEt),e(Ly,Cie),e(Cie,cEt),e(Ly,mEt),e(ze,fEt),e(ze,yy),e(yy,QSe),e(QSe,gEt),e(yy,hEt),e(yy,wie),e(wie,uEt),e(yy,pEt),e(it,_Et),M(xy,it,null),b(m,_to,_),b(m,Tf,_),e(Tf,$y),e($y,WSe),M(VP,WSe,null),e(Tf,bEt),e(Tf,USe),e(USe,vEt),b(m,bto,_),b(m,Rr,_),M(XP,Rr,null),e(Rr,FEt),e(Rr,Mf),e(Mf,TEt),e(Mf,Aie),e(Aie,MEt),e(Mf,EEt),e(Mf,Lie),e(Lie,CEt),e(Mf,wEt),e(Rr,AEt),e(Rr,zP),e(zP,LEt),e(zP,HSe),e(HSe,yEt),e(zP,xEt),e(Rr,$Et),e(Rr,ba),M(QP,ba,null),e(ba,kEt),e(ba,JSe),e(JSe,SEt),e(ba,REt),e(ba,Ef),e(Ef,PEt),e(Ef,YSe),e(YSe,BEt),e(Ef,IEt),e(Ef,yie),e(yie,NEt),e(Ef,qEt),e(ba,jEt),M(ky,ba,null),e(Rr,DEt),e(Rr,dt),M(WP,dt,null),e(dt,GEt),e(dt,ZSe),e(ZSe,OEt),e(dt,VEt),e(dt,os),e(os,XEt),e(os,KSe),e(KSe,zEt),e(os,QEt),e(os,eRe),e(eRe,WEt),e(os,UEt),e(os,oRe),e(oRe,HEt),e(os,JEt),e(dt,YEt),e(dt,rRe),e(rRe,Sy),e(Sy,tRe),e(tRe,ZEt),e(Sy,KEt),e(Sy,xie),e(xie,e4t),e(Sy,o4t),e(dt,r4t),M(Ry,dt,null),b(m,vto,_),b(m,Cf,_),e(Cf,Py),e(Py,aRe),M(UP,aRe,null),e(Cf,t4t),e(Cf,nRe),e(nRe,a4t),b(m,Fto,_),b(m,Pr,_),M(HP,Pr,null),e(Pr,n4t),e(Pr,wf),e(wf,s4t),e(wf,$ie),e($ie,l4t),e(wf,i4t),e(wf,kie),e(kie,d4t),e(wf,c4t),e(Pr,m4t),e(Pr,JP),e(JP,f4t),e(JP,sRe),e(sRe,g4t),e(JP,h4t),e(Pr,u4t),e(Pr,va),M(YP,va,null),e(va,p4t),e(va,lRe),e(lRe,_4t),e(va,b4t),e(va,Af),e(Af,v4t),e(Af,iRe),e(iRe,F4t),e(Af,T4t),e(Af,Sie),e(Sie,M4t),e(Af,E4t),e(va,C4t),M(By,va,null),e(Pr,w4t),e(Pr,ct),M(ZP,ct,null),e(ct,A4t),e(ct,dRe),e(dRe,L4t),e(ct,y4t),e(ct,rs),e(rs,x4t),e(rs,cRe),e(cRe,$4t),e(rs,k4t),e(rs,mRe),e(mRe,S4t),e(rs,R4t),e(rs,fRe),e(fRe,P4t),e(rs,B4t),e(ct,I4t),e(ct,KP),e(KP,Iy),e(Iy,gRe),e(gRe,N4t),e(Iy,q4t),e(Iy,Rie),e(Rie,j4t),e(Iy,D4t),e(KP,G4t),e(KP,Ny),e(Ny,hRe),e(hRe,O4t),e(Ny,V4t),e(Ny,Pie),e(Pie,X4t),e(Ny,z4t),e(ct,Q4t),M(qy,ct,null),b(m,Tto,_),b(m,Lf,_),e(Lf,jy),e(jy,uRe),M(eB,uRe,null),e(Lf,W4t),e(Lf,pRe),e(pRe,U4t),b(m,Mto,_),b(m,Br,_),M(oB,Br,null),e(Br,H4t),e(Br,yf),e(yf,J4t),e(yf,Bie),e(Bie,Y4t),e(yf,Z4t),e(yf,Iie),e(Iie,K4t),e(yf,eCt),e(Br,oCt),e(Br,rB),e(rB,rCt),e(rB,_Re),e(_Re,tCt),e(rB,aCt),e(Br,nCt),e(Br,Fa),M(tB,Fa,null),e(Fa,sCt),e(Fa,bRe),e(bRe,lCt),e(Fa,iCt),e(Fa,xf),e(xf,dCt),e(xf,vRe),e(vRe,cCt),e(xf,mCt),e(xf,Nie),e(Nie,fCt),e(xf,gCt),e(Fa,hCt),M(Dy,Fa,null),e(Br,uCt),e(Br,mt),M(aB,mt,null),e(mt,pCt),e(mt,FRe),e(FRe,_Ct),e(mt,bCt),e(mt,ts),e(ts,vCt),e(ts,TRe),e(TRe,FCt),e(ts,TCt),e(ts,MRe),e(MRe,MCt),e(ts,ECt),e(ts,ERe),e(ERe,CCt),e(ts,wCt),e(mt,ACt),e(mt,CRe),e(CRe,Gy),e(Gy,wRe),e(wRe,LCt),e(Gy,yCt),e(Gy,qie),e(qie,xCt),e(Gy,$Ct),e(mt,kCt),M(Oy,mt,null),Eto=!0},p(m,[_]){const nB={};_&2&&(nB.$$scope={dirty:_,ctx:m}),qf.$set(nB);const ARe={};_&2&&(ARe.$$scope={dirty:_,ctx:m}),mu.$set(ARe);const LRe={};_&2&&(LRe.$$scope={dirty:_,ctx:m}),Hu.$set(LRe);const yRe={};_&2&&(yRe.$$scope={dirty:_,ctx:m}),Gp.$set(yRe);const sB={};_&2&&(sB.$$scope={dirty:_,ctx:m}),Op.$set(sB);const xRe={};_&2&&(xRe.$$scope={dirty:_,ctx:m}),h_.$set(xRe);const as={};_&2&&(as.$$scope={dirty:_,ctx:m}),u_.$set(as);const $Re={};_&2&&($Re.$$scope={dirty:_,ctx:m}),b_.$set($Re);const kRe={};_&2&&(kRe.$$scope={dirty:_,ctx:m}),qb.$set(kRe);const SRe={};_&2&&(SRe.$$scope={dirty:_,ctx:m}),Db.$set(SRe);const lB={};_&2&&(lB.$$scope={dirty:_,ctx:m}),I2.$set(lB);const RRe={};_&2&&(RRe.$$scope={dirty:_,ctx:m}),q2.$set(RRe);const iB={};_&2&&(iB.$$scope={dirty:_,ctx:m}),yv.$set(iB);const PRe={};_&2&&(PRe.$$scope={dirty:_,ctx:m}),$v.$set(PRe);const dB={};_&2&&(dB.$$scope={dirty:_,ctx:m}),_F.$set(dB);const BRe={};_&2&&(BRe.$$scope={dirty:_,ctx:m}),vF.$set(BRe);const IRe={};_&2&&(IRe.$$scope={dirty:_,ctx:m}),GF.$set(IRe);const NRe={};_&2&&(NRe.$$scope={dirty:_,ctx:m}),VF.$set(NRe);const $f={};_&2&&($f.$$scope={dirty:_,ctx:m}),QT.$set($f);const qRe={};_&2&&(qRe.$$scope={dirty:_,ctx:m}),UT.$set(qRe);const jRe={};_&2&&(jRe.$$scope={dirty:_,ctx:m}),yM.$set(jRe);const DRe={};_&2&&(DRe.$$scope={dirty:_,ctx:m}),$M.$set(DRe);const cB={};_&2&&(cB.$$scope={dirty:_,ctx:m}),jM.$set(cB);const GRe={};_&2&&(GRe.$$scope={dirty:_,ctx:m}),GM.$set(GRe);const ORe={};_&2&&(ORe.$$scope={dirty:_,ctx:m}),xE.$set(ORe);const VRe={};_&2&&(VRe.$$scope={dirty:_,ctx:m}),kE.$set(VRe);const pt={};_&2&&(pt.$$scope={dirty:_,ctx:m}),A4.$set(pt);const mB={};_&2&&(mB.$$scope={dirty:_,ctx:m}),y4.$set(mB);const XRe={};_&2&&(XRe.$$scope={dirty:_,ctx:m}),k4.$set(XRe);const fB={};_&2&&(fB.$$scope={dirty:_,ctx:m}),R4.$set(fB);const zRe={};_&2&&(zRe.$$scope={dirty:_,ctx:m}),q4.$set(zRe);const _t={};_&2&&(_t.$$scope={dirty:_,ctx:m}),D4.$set(_t);const QRe={};_&2&&(QRe.$$scope={dirty:_,ctx:m}),tC.$set(QRe);const kf={};_&2&&(kf.$$scope={dirty:_,ctx:m}),nC.$set(kf);const WRe={};_&2&&(WRe.$$scope={dirty:_,ctx:m}),iC.$set(WRe);const URe={};_&2&&(URe.$$scope={dirty:_,ctx:m}),cC.$set(URe);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),gC.$set(L);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:m}),uC.$set(Vy);const HRe={};_&2&&(HRe.$$scope={dirty:_,ctx:m}),bC.$set(HRe);const JRe={};_&2&&(JRe.$$scope={dirty:_,ctx:m}),FC.$set(JRe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:m}),kC.$set(Xy);const YRe={};_&2&&(YRe.$$scope={dirty:_,ctx:m}),RC.$set(YRe);const ZRe={};_&2&&(ZRe.$$scope={dirty:_,ctx:m}),DC.$set(ZRe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:m}),OC.$set(zy);const KRe={};_&2&&(KRe.$$scope={dirty:_,ctx:m}),e3.$set(KRe);const ePe={};_&2&&(ePe.$$scope={dirty:_,ctx:m}),r3.$set(ePe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:m}),l3.$set(Qy);const oPe={};_&2&&(oPe.$$scope={dirty:_,ctx:m}),d3.$set(oPe);const rPe={};_&2&&(rPe.$$scope={dirty:_,ctx:m}),p3.$set(rPe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:m}),b3.$set(Wy);const tPe={};_&2&&(tPe.$$scope={dirty:_,ctx:m}),C3.$set(tPe);const aPe={};_&2&&(aPe.$$scope={dirty:_,ctx:m}),A3.$set(aPe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:m}),S3.$set(Uy);const nPe={};_&2&&(nPe.$$scope={dirty:_,ctx:m}),P3.$set(nPe);const sPe={};_&2&&(sPe.$$scope={dirty:_,ctx:m}),N3.$set(sPe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:m}),j3.$set(Hy);const lPe={};_&2&&(lPe.$$scope={dirty:_,ctx:m}),Q3.$set(lPe);const iPe={};_&2&&(iPe.$$scope={dirty:_,ctx:m}),U3.$set(iPe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:m}),Y3.$set(Jy);const dPe={};_&2&&(dPe.$$scope={dirty:_,ctx:m}),K3.$set(dPe);const cPe={};_&2&&(cPe.$$scope={dirty:_,ctx:m}),r5.$set(cPe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:m}),a5.$set(Yy);const mPe={};_&2&&(mPe.$$scope={dirty:_,ctx:m}),n0.$set(mPe);const fPe={};_&2&&(fPe.$$scope={dirty:_,ctx:m}),l0.$set(fPe);const Zy={};_&2&&(Zy.$$scope={dirty:_,ctx:m}),k0.$set(Zy);const gPe={};_&2&&(gPe.$$scope={dirty:_,ctx:m}),R0.$set(gPe);const hPe={};_&2&&(hPe.$$scope={dirty:_,ctx:m}),U0.$set(hPe);const Ky={};_&2&&(Ky.$$scope={dirty:_,ctx:m}),J0.$set(Ky);const uPe={};_&2&&(uPe.$$scope={dirty:_,ctx:m}),nw.$set(uPe);const pPe={};_&2&&(pPe.$$scope={dirty:_,ctx:m}),lw.$set(pPe);const e8={};_&2&&(e8.$$scope={dirty:_,ctx:m}),mw.$set(e8);const _Pe={};_&2&&(_Pe.$$scope={dirty:_,ctx:m}),gw.$set(_Pe);const bPe={};_&2&&(bPe.$$scope={dirty:_,ctx:m}),Pw.$set(bPe);const o8={};_&2&&(o8.$$scope={dirty:_,ctx:m}),Iw.$set(o8);const vPe={};_&2&&(vPe.$$scope={dirty:_,ctx:m}),Ww.$set(vPe);const FPe={};_&2&&(FPe.$$scope={dirty:_,ctx:m}),Hw.$set(FPe);const r8={};_&2&&(r8.$$scope={dirty:_,ctx:m}),EA.$set(r8);const TPe={};_&2&&(TPe.$$scope={dirty:_,ctx:m}),wA.$set(TPe);const MPe={};_&2&&(MPe.$$scope={dirty:_,ctx:m}),VA.$set(MPe);const t8={};_&2&&(t8.$$scope={dirty:_,ctx:m}),zA.$set(t8);const EPe={};_&2&&(EPe.$$scope={dirty:_,ctx:m}),UA.$set(EPe);const CPe={};_&2&&(CPe.$$scope={dirty:_,ctx:m}),JA.$set(CPe);const a8={};_&2&&(a8.$$scope={dirty:_,ctx:m}),ZA.$set(a8);const wPe={};_&2&&(wPe.$$scope={dirty:_,ctx:m}),e6.$set(wPe);const APe={};_&2&&(APe.$$scope={dirty:_,ctx:m}),r6.$set(APe);const n8={};_&2&&(n8.$$scope={dirty:_,ctx:m}),a6.$set(n8);const LPe={};_&2&&(LPe.$$scope={dirty:_,ctx:m}),A6.$set(LPe);const yPe={};_&2&&(yPe.$$scope={dirty:_,ctx:m}),y6.$set(yPe);const s8={};_&2&&(s8.$$scope={dirty:_,ctx:m}),J6.$set(s8);const xPe={};_&2&&(xPe.$$scope={dirty:_,ctx:m}),Z6.$set(xPe);const $Pe={};_&2&&($Pe.$$scope={dirty:_,ctx:m}),e7.$set($Pe);const l8={};_&2&&(l8.$$scope={dirty:_,ctx:m}),r7.$set(l8);const kPe={};_&2&&(kPe.$$scope={dirty:_,ctx:m}),a7.$set(kPe);const SPe={};_&2&&(SPe.$$scope={dirty:_,ctx:m}),s7.$set(SPe);const i8={};_&2&&(i8.$$scope={dirty:_,ctx:m}),P7.$set(i8);const RPe={};_&2&&(RPe.$$scope={dirty:_,ctx:m}),I7.$set(RPe);const PPe={};_&2&&(PPe.$$scope={dirty:_,ctx:m}),W7.$set(PPe);const d8={};_&2&&(d8.$$scope={dirty:_,ctx:m}),H7.$set(d8);const BPe={};_&2&&(BPe.$$scope={dirty:_,ctx:m}),dL.$set(BPe);const IPe={};_&2&&(IPe.$$scope={dirty:_,ctx:m}),mL.$set(IPe);const c8={};_&2&&(c8.$$scope={dirty:_,ctx:m}),ML.$set(c8);const NPe={};_&2&&(NPe.$$scope={dirty:_,ctx:m}),CL.$set(NPe);const qPe={};_&2&&(qPe.$$scope={dirty:_,ctx:m}),BL.$set(qPe);const m8={};_&2&&(m8.$$scope={dirty:_,ctx:m}),NL.$set(m8);const jPe={};_&2&&(jPe.$$scope={dirty:_,ctx:m}),UL.$set(jPe);const DPe={};_&2&&(DPe.$$scope={dirty:_,ctx:m}),JL.$set(DPe);const f8={};_&2&&(f8.$$scope={dirty:_,ctx:m}),ly.$set(f8);const GPe={};_&2&&(GPe.$$scope={dirty:_,ctx:m}),dy.$set(GPe);const OPe={};_&2&&(OPe.$$scope={dirty:_,ctx:m}),by.$set(OPe);const g8={};_&2&&(g8.$$scope={dirty:_,ctx:m}),Fy.$set(g8);const VPe={};_&2&&(VPe.$$scope={dirty:_,ctx:m}),xy.$set(VPe);const XPe={};_&2&&(XPe.$$scope={dirty:_,ctx:m}),ky.$set(XPe);const h8={};_&2&&(h8.$$scope={dirty:_,ctx:m}),Ry.$set(h8);const zPe={};_&2&&(zPe.$$scope={dirty:_,ctx:m}),By.$set(zPe);const QPe={};_&2&&(QPe.$$scope={dirty:_,ctx:m}),qy.$set(QPe);const u8={};_&2&&(u8.$$scope={dirty:_,ctx:m}),Dy.$set(u8);const WPe={};_&2&&(WPe.$$scope={dirty:_,ctx:m}),Oy.$set(WPe)},i(m){Eto||(E(d.$$.fragment,m),E(Ja.$$.fragment,m),E(Ax.$$.fragment,m),E(Lx.$$.fragment,m),E(qf.$$.fragment,m),E(yx.$$.fragment,m),E(xx.$$.fragment,m),E(Sx.$$.fragment,m),E(mu.$$.fragment,m),E(Rx.$$.fragment,m),E(Px.$$.fragment,m),E(Bx.$$.fragment,m),E(qx.$$.fragment,m),E(Hu.$$.fragment,m),E(jx.$$.fragment,m),E(Dx.$$.fragment,m),E(Gx.$$.fragment,m),E(Xx.$$.fragment,m),E(Gp.$$.fragment,m),E(Op.$$.fragment,m),E(zx.$$.fragment,m),E(Qx.$$.fragment,m),E(Wx.$$.fragment,m),E(Jx.$$.fragment,m),E(h_.$$.fragment,m),E(u_.$$.fragment,m),E(Yx.$$.fragment,m),E(Zx.$$.fragment,m),E(Kx.$$.fragment,m),E(o$.$$.fragment,m),E(b_.$$.fragment,m),E(r$.$$.fragment,m),E(qb.$$.fragment,m),E(t$.$$.fragment,m),E(a$.$$.fragment,m),E(s$.$$.fragment,m),E(Db.$$.fragment,m),E(l$.$$.fragment,m),E(I2.$$.fragment,m),E(i$.$$.fragment,m),E(d$.$$.fragment,m),E(m$.$$.fragment,m),E(q2.$$.fragment,m),E(f$.$$.fragment,m),E(yv.$$.fragment,m),E(g$.$$.fragment,m),E(h$.$$.fragment,m),E(p$.$$.fragment,m),E($v.$$.fragment,m),E(_$.$$.fragment,m),E(_F.$$.fragment,m),E(b$.$$.fragment,m),E(v$.$$.fragment,m),E(T$.$$.fragment,m),E(vF.$$.fragment,m),E(M$.$$.fragment,m),E(GF.$$.fragment,m),E(E$.$$.fragment,m),E(C$.$$.fragment,m),E(A$.$$.fragment,m),E(VF.$$.fragment,m),E(L$.$$.fragment,m),E(QT.$$.fragment,m),E(y$.$$.fragment,m),E(x$.$$.fragment,m),E(k$.$$.fragment,m),E(UT.$$.fragment,m),E(S$.$$.fragment,m),E(yM.$$.fragment,m),E(R$.$$.fragment,m),E(P$.$$.fragment,m),E(I$.$$.fragment,m),E($M.$$.fragment,m),E(N$.$$.fragment,m),E(jM.$$.fragment,m),E(q$.$$.fragment,m),E(j$.$$.fragment,m),E(G$.$$.fragment,m),E(GM.$$.fragment,m),E(O$.$$.fragment,m),E(xE.$$.fragment,m),E(V$.$$.fragment,m),E(X$.$$.fragment,m),E(Q$.$$.fragment,m),E(kE.$$.fragment,m),E(W$.$$.fragment,m),E(A4.$$.fragment,m),E(U$.$$.fragment,m),E(H$.$$.fragment,m),E(Y$.$$.fragment,m),E(y4.$$.fragment,m),E(Z$.$$.fragment,m),E(k4.$$.fragment,m),E(K$.$$.fragment,m),E(ek.$$.fragment,m),E(rk.$$.fragment,m),E(R4.$$.fragment,m),E(tk.$$.fragment,m),E(q4.$$.fragment,m),E(ak.$$.fragment,m),E(nk.$$.fragment,m),E(lk.$$.fragment,m),E(D4.$$.fragment,m),E(ik.$$.fragment,m),E(tC.$$.fragment,m),E(dk.$$.fragment,m),E(ck.$$.fragment,m),E(fk.$$.fragment,m),E(nC.$$.fragment,m),E(gk.$$.fragment,m),E(iC.$$.fragment,m),E(hk.$$.fragment,m),E(uk.$$.fragment,m),E(_k.$$.fragment,m),E(cC.$$.fragment,m),E(bk.$$.fragment,m),E(gC.$$.fragment,m),E(vk.$$.fragment,m),E(Fk.$$.fragment,m),E(Mk.$$.fragment,m),E(uC.$$.fragment,m),E(Ek.$$.fragment,m),E(bC.$$.fragment,m),E(Ck.$$.fragment,m),E(wk.$$.fragment,m),E(Lk.$$.fragment,m),E(FC.$$.fragment,m),E(yk.$$.fragment,m),E(kC.$$.fragment,m),E(xk.$$.fragment,m),E($k.$$.fragment,m),E(Sk.$$.fragment,m),E(RC.$$.fragment,m),E(Rk.$$.fragment,m),E(DC.$$.fragment,m),E(Pk.$$.fragment,m),E(Bk.$$.fragment,m),E(Nk.$$.fragment,m),E(OC.$$.fragment,m),E(qk.$$.fragment,m),E(e3.$$.fragment,m),E(jk.$$.fragment,m),E(Dk.$$.fragment,m),E(Ok.$$.fragment,m),E(r3.$$.fragment,m),E(Vk.$$.fragment,m),E(l3.$$.fragment,m),E(Xk.$$.fragment,m),E(zk.$$.fragment,m),E(Wk.$$.fragment,m),E(d3.$$.fragment,m),E(Uk.$$.fragment,m),E(p3.$$.fragment,m),E(Hk.$$.fragment,m),E(Jk.$$.fragment,m),E(Zk.$$.fragment,m),E(b3.$$.fragment,m),E(Kk.$$.fragment,m),E(C3.$$.fragment,m),E(eS.$$.fragment,m),E(oS.$$.fragment,m),E(tS.$$.fragment,m),E(A3.$$.fragment,m),E(aS.$$.fragment,m),E(S3.$$.fragment,m),E(nS.$$.fragment,m),E(sS.$$.fragment,m),E(iS.$$.fragment,m),E(P3.$$.fragment,m),E(dS.$$.fragment,m),E(N3.$$.fragment,m),E(cS.$$.fragment,m),E(mS.$$.fragment,m),E(gS.$$.fragment,m),E(j3.$$.fragment,m),E(hS.$$.fragment,m),E(Q3.$$.fragment,m),E(uS.$$.fragment,m),E(pS.$$.fragment,m),E(bS.$$.fragment,m),E(U3.$$.fragment,m),E(vS.$$.fragment,m),E(Y3.$$.fragment,m),E(FS.$$.fragment,m),E(TS.$$.fragment,m),E(ES.$$.fragment,m),E(K3.$$.fragment,m),E(CS.$$.fragment,m),E(r5.$$.fragment,m),E(wS.$$.fragment,m),E(AS.$$.fragment,m),E(yS.$$.fragment,m),E(a5.$$.fragment,m),E(xS.$$.fragment,m),E(n0.$$.fragment,m),E($S.$$.fragment,m),E(kS.$$.fragment,m),E(RS.$$.fragment,m),E(l0.$$.fragment,m),E(PS.$$.fragment,m),E(k0.$$.fragment,m),E(BS.$$.fragment,m),E(IS.$$.fragment,m),E(qS.$$.fragment,m),E(R0.$$.fragment,m),E(jS.$$.fragment,m),E(U0.$$.fragment,m),E(DS.$$.fragment,m),E(GS.$$.fragment,m),E(VS.$$.fragment,m),E(J0.$$.fragment,m),E(XS.$$.fragment,m),E(nw.$$.fragment,m),E(zS.$$.fragment,m),E(QS.$$.fragment,m),E(US.$$.fragment,m),E(lw.$$.fragment,m),E(HS.$$.fragment,m),E(mw.$$.fragment,m),E(JS.$$.fragment,m),E(YS.$$.fragment,m),E(KS.$$.fragment,m),E(gw.$$.fragment,m),E(eR.$$.fragment,m),E(Pw.$$.fragment,m),E(oR.$$.fragment,m),E(rR.$$.fragment,m),E(aR.$$.fragment,m),E(Iw.$$.fragment,m),E(nR.$$.fragment,m),E(Ww.$$.fragment,m),E(sR.$$.fragment,m),E(lR.$$.fragment,m),E(dR.$$.fragment,m),E(Hw.$$.fragment,m),E(cR.$$.fragment,m),E(EA.$$.fragment,m),E(mR.$$.fragment,m),E(fR.$$.fragment,m),E(hR.$$.fragment,m),E(wA.$$.fragment,m),E(uR.$$.fragment,m),E(VA.$$.fragment,m),E(pR.$$.fragment,m),E(_R.$$.fragment,m),E(vR.$$.fragment,m),E(zA.$$.fragment,m),E(FR.$$.fragment,m),E(UA.$$.fragment,m),E(MR.$$.fragment,m),E(ER.$$.fragment,m),E(wR.$$.fragment,m),E(JA.$$.fragment,m),E(AR.$$.fragment,m),E(ZA.$$.fragment,m),E(LR.$$.fragment,m),E(yR.$$.fragment,m),E($R.$$.fragment,m),E(e6.$$.fragment,m),E(kR.$$.fragment,m),E(r6.$$.fragment,m),E(SR.$$.fragment,m),E(RR.$$.fragment,m),E(BR.$$.fragment,m),E(a6.$$.fragment,m),E(IR.$$.fragment,m),E(A6.$$.fragment,m),E(NR.$$.fragment,m),E(qR.$$.fragment,m),E(DR.$$.fragment,m),E(y6.$$.fragment,m),E(GR.$$.fragment,m),E(J6.$$.fragment,m),E(OR.$$.fragment,m),E(VR.$$.fragment,m),E(zR.$$.fragment,m),E(Z6.$$.fragment,m),E(QR.$$.fragment,m),E(e7.$$.fragment,m),E(WR.$$.fragment,m),E(UR.$$.fragment,m),E(JR.$$.fragment,m),E(r7.$$.fragment,m),E(YR.$$.fragment,m),E(a7.$$.fragment,m),E(ZR.$$.fragment,m),E(KR.$$.fragment,m),E(oP.$$.fragment,m),E(s7.$$.fragment,m),E(rP.$$.fragment,m),E(P7.$$.fragment,m),E(tP.$$.fragment,m),E(aP.$$.fragment,m),E(sP.$$.fragment,m),E(I7.$$.fragment,m),E(lP.$$.fragment,m),E(W7.$$.fragment,m),E(iP.$$.fragment,m),E(dP.$$.fragment,m),E(mP.$$.fragment,m),E(H7.$$.fragment,m),E(fP.$$.fragment,m),E(dL.$$.fragment,m),E(gP.$$.fragment,m),E(hP.$$.fragment,m),E(pP.$$.fragment,m),E(mL.$$.fragment,m),E(_P.$$.fragment,m),E(ML.$$.fragment,m),E(bP.$$.fragment,m),E(vP.$$.fragment,m),E(TP.$$.fragment,m),E(CL.$$.fragment,m),E(MP.$$.fragment,m),E(BL.$$.fragment,m),E(EP.$$.fragment,m),E(CP.$$.fragment,m),E(AP.$$.fragment,m),E(NL.$$.fragment,m),E(LP.$$.fragment,m),E(UL.$$.fragment,m),E(yP.$$.fragment,m),E(xP.$$.fragment,m),E(kP.$$.fragment,m),E(JL.$$.fragment,m),E(SP.$$.fragment,m),E(ly.$$.fragment,m),E(RP.$$.fragment,m),E(PP.$$.fragment,m),E(IP.$$.fragment,m),E(dy.$$.fragment,m),E(NP.$$.fragment,m),E(by.$$.fragment,m),E(qP.$$.fragment,m),E(jP.$$.fragment,m),E(GP.$$.fragment,m),E(Fy.$$.fragment,m),E(OP.$$.fragment,m),E(xy.$$.fragment,m),E(VP.$$.fragment,m),E(XP.$$.fragment,m),E(QP.$$.fragment,m),E(ky.$$.fragment,m),E(WP.$$.fragment,m),E(Ry.$$.fragment,m),E(UP.$$.fragment,m),E(HP.$$.fragment,m),E(YP.$$.fragment,m),E(By.$$.fragment,m),E(ZP.$$.fragment,m),E(qy.$$.fragment,m),E(eB.$$.fragment,m),E(oB.$$.fragment,m),E(tB.$$.fragment,m),E(Dy.$$.fragment,m),E(aB.$$.fragment,m),E(Oy.$$.fragment,m),Eto=!0)},o(m){C(d.$$.fragment,m),C(Ja.$$.fragment,m),C(Ax.$$.fragment,m),C(Lx.$$.fragment,m),C(qf.$$.fragment,m),C(yx.$$.fragment,m),C(xx.$$.fragment,m),C(Sx.$$.fragment,m),C(mu.$$.fragment,m),C(Rx.$$.fragment,m),C(Px.$$.fragment,m),C(Bx.$$.fragment,m),C(qx.$$.fragment,m),C(Hu.$$.fragment,m),C(jx.$$.fragment,m),C(Dx.$$.fragment,m),C(Gx.$$.fragment,m),C(Xx.$$.fragment,m),C(Gp.$$.fragment,m),C(Op.$$.fragment,m),C(zx.$$.fragment,m),C(Qx.$$.fragment,m),C(Wx.$$.fragment,m),C(Jx.$$.fragment,m),C(h_.$$.fragment,m),C(u_.$$.fragment,m),C(Yx.$$.fragment,m),C(Zx.$$.fragment,m),C(Kx.$$.fragment,m),C(o$.$$.fragment,m),C(b_.$$.fragment,m),C(r$.$$.fragment,m),C(qb.$$.fragment,m),C(t$.$$.fragment,m),C(a$.$$.fragment,m),C(s$.$$.fragment,m),C(Db.$$.fragment,m),C(l$.$$.fragment,m),C(I2.$$.fragment,m),C(i$.$$.fragment,m),C(d$.$$.fragment,m),C(m$.$$.fragment,m),C(q2.$$.fragment,m),C(f$.$$.fragment,m),C(yv.$$.fragment,m),C(g$.$$.fragment,m),C(h$.$$.fragment,m),C(p$.$$.fragment,m),C($v.$$.fragment,m),C(_$.$$.fragment,m),C(_F.$$.fragment,m),C(b$.$$.fragment,m),C(v$.$$.fragment,m),C(T$.$$.fragment,m),C(vF.$$.fragment,m),C(M$.$$.fragment,m),C(GF.$$.fragment,m),C(E$.$$.fragment,m),C(C$.$$.fragment,m),C(A$.$$.fragment,m),C(VF.$$.fragment,m),C(L$.$$.fragment,m),C(QT.$$.fragment,m),C(y$.$$.fragment,m),C(x$.$$.fragment,m),C(k$.$$.fragment,m),C(UT.$$.fragment,m),C(S$.$$.fragment,m),C(yM.$$.fragment,m),C(R$.$$.fragment,m),C(P$.$$.fragment,m),C(I$.$$.fragment,m),C($M.$$.fragment,m),C(N$.$$.fragment,m),C(jM.$$.fragment,m),C(q$.$$.fragment,m),C(j$.$$.fragment,m),C(G$.$$.fragment,m),C(GM.$$.fragment,m),C(O$.$$.fragment,m),C(xE.$$.fragment,m),C(V$.$$.fragment,m),C(X$.$$.fragment,m),C(Q$.$$.fragment,m),C(kE.$$.fragment,m),C(W$.$$.fragment,m),C(A4.$$.fragment,m),C(U$.$$.fragment,m),C(H$.$$.fragment,m),C(Y$.$$.fragment,m),C(y4.$$.fragment,m),C(Z$.$$.fragment,m),C(k4.$$.fragment,m),C(K$.$$.fragment,m),C(ek.$$.fragment,m),C(rk.$$.fragment,m),C(R4.$$.fragment,m),C(tk.$$.fragment,m),C(q4.$$.fragment,m),C(ak.$$.fragment,m),C(nk.$$.fragment,m),C(lk.$$.fragment,m),C(D4.$$.fragment,m),C(ik.$$.fragment,m),C(tC.$$.fragment,m),C(dk.$$.fragment,m),C(ck.$$.fragment,m),C(fk.$$.fragment,m),C(nC.$$.fragment,m),C(gk.$$.fragment,m),C(iC.$$.fragment,m),C(hk.$$.fragment,m),C(uk.$$.fragment,m),C(_k.$$.fragment,m),C(cC.$$.fragment,m),C(bk.$$.fragment,m),C(gC.$$.fragment,m),C(vk.$$.fragment,m),C(Fk.$$.fragment,m),C(Mk.$$.fragment,m),C(uC.$$.fragment,m),C(Ek.$$.fragment,m),C(bC.$$.fragment,m),C(Ck.$$.fragment,m),C(wk.$$.fragment,m),C(Lk.$$.fragment,m),C(FC.$$.fragment,m),C(yk.$$.fragment,m),C(kC.$$.fragment,m),C(xk.$$.fragment,m),C($k.$$.fragment,m),C(Sk.$$.fragment,m),C(RC.$$.fragment,m),C(Rk.$$.fragment,m),C(DC.$$.fragment,m),C(Pk.$$.fragment,m),C(Bk.$$.fragment,m),C(Nk.$$.fragment,m),C(OC.$$.fragment,m),C(qk.$$.fragment,m),C(e3.$$.fragment,m),C(jk.$$.fragment,m),C(Dk.$$.fragment,m),C(Ok.$$.fragment,m),C(r3.$$.fragment,m),C(Vk.$$.fragment,m),C(l3.$$.fragment,m),C(Xk.$$.fragment,m),C(zk.$$.fragment,m),C(Wk.$$.fragment,m),C(d3.$$.fragment,m),C(Uk.$$.fragment,m),C(p3.$$.fragment,m),C(Hk.$$.fragment,m),C(Jk.$$.fragment,m),C(Zk.$$.fragment,m),C(b3.$$.fragment,m),C(Kk.$$.fragment,m),C(C3.$$.fragment,m),C(eS.$$.fragment,m),C(oS.$$.fragment,m),C(tS.$$.fragment,m),C(A3.$$.fragment,m),C(aS.$$.fragment,m),C(S3.$$.fragment,m),C(nS.$$.fragment,m),C(sS.$$.fragment,m),C(iS.$$.fragment,m),C(P3.$$.fragment,m),C(dS.$$.fragment,m),C(N3.$$.fragment,m),C(cS.$$.fragment,m),C(mS.$$.fragment,m),C(gS.$$.fragment,m),C(j3.$$.fragment,m),C(hS.$$.fragment,m),C(Q3.$$.fragment,m),C(uS.$$.fragment,m),C(pS.$$.fragment,m),C(bS.$$.fragment,m),C(U3.$$.fragment,m),C(vS.$$.fragment,m),C(Y3.$$.fragment,m),C(FS.$$.fragment,m),C(TS.$$.fragment,m),C(ES.$$.fragment,m),C(K3.$$.fragment,m),C(CS.$$.fragment,m),C(r5.$$.fragment,m),C(wS.$$.fragment,m),C(AS.$$.fragment,m),C(yS.$$.fragment,m),C(a5.$$.fragment,m),C(xS.$$.fragment,m),C(n0.$$.fragment,m),C($S.$$.fragment,m),C(kS.$$.fragment,m),C(RS.$$.fragment,m),C(l0.$$.fragment,m),C(PS.$$.fragment,m),C(k0.$$.fragment,m),C(BS.$$.fragment,m),C(IS.$$.fragment,m),C(qS.$$.fragment,m),C(R0.$$.fragment,m),C(jS.$$.fragment,m),C(U0.$$.fragment,m),C(DS.$$.fragment,m),C(GS.$$.fragment,m),C(VS.$$.fragment,m),C(J0.$$.fragment,m),C(XS.$$.fragment,m),C(nw.$$.fragment,m),C(zS.$$.fragment,m),C(QS.$$.fragment,m),C(US.$$.fragment,m),C(lw.$$.fragment,m),C(HS.$$.fragment,m),C(mw.$$.fragment,m),C(JS.$$.fragment,m),C(YS.$$.fragment,m),C(KS.$$.fragment,m),C(gw.$$.fragment,m),C(eR.$$.fragment,m),C(Pw.$$.fragment,m),C(oR.$$.fragment,m),C(rR.$$.fragment,m),C(aR.$$.fragment,m),C(Iw.$$.fragment,m),C(nR.$$.fragment,m),C(Ww.$$.fragment,m),C(sR.$$.fragment,m),C(lR.$$.fragment,m),C(dR.$$.fragment,m),C(Hw.$$.fragment,m),C(cR.$$.fragment,m),C(EA.$$.fragment,m),C(mR.$$.fragment,m),C(fR.$$.fragment,m),C(hR.$$.fragment,m),C(wA.$$.fragment,m),C(uR.$$.fragment,m),C(VA.$$.fragment,m),C(pR.$$.fragment,m),C(_R.$$.fragment,m),C(vR.$$.fragment,m),C(zA.$$.fragment,m),C(FR.$$.fragment,m),C(UA.$$.fragment,m),C(MR.$$.fragment,m),C(ER.$$.fragment,m),C(wR.$$.fragment,m),C(JA.$$.fragment,m),C(AR.$$.fragment,m),C(ZA.$$.fragment,m),C(LR.$$.fragment,m),C(yR.$$.fragment,m),C($R.$$.fragment,m),C(e6.$$.fragment,m),C(kR.$$.fragment,m),C(r6.$$.fragment,m),C(SR.$$.fragment,m),C(RR.$$.fragment,m),C(BR.$$.fragment,m),C(a6.$$.fragment,m),C(IR.$$.fragment,m),C(A6.$$.fragment,m),C(NR.$$.fragment,m),C(qR.$$.fragment,m),C(DR.$$.fragment,m),C(y6.$$.fragment,m),C(GR.$$.fragment,m),C(J6.$$.fragment,m),C(OR.$$.fragment,m),C(VR.$$.fragment,m),C(zR.$$.fragment,m),C(Z6.$$.fragment,m),C(QR.$$.fragment,m),C(e7.$$.fragment,m),C(WR.$$.fragment,m),C(UR.$$.fragment,m),C(JR.$$.fragment,m),C(r7.$$.fragment,m),C(YR.$$.fragment,m),C(a7.$$.fragment,m),C(ZR.$$.fragment,m),C(KR.$$.fragment,m),C(oP.$$.fragment,m),C(s7.$$.fragment,m),C(rP.$$.fragment,m),C(P7.$$.fragment,m),C(tP.$$.fragment,m),C(aP.$$.fragment,m),C(sP.$$.fragment,m),C(I7.$$.fragment,m),C(lP.$$.fragment,m),C(W7.$$.fragment,m),C(iP.$$.fragment,m),C(dP.$$.fragment,m),C(mP.$$.fragment,m),C(H7.$$.fragment,m),C(fP.$$.fragment,m),C(dL.$$.fragment,m),C(gP.$$.fragment,m),C(hP.$$.fragment,m),C(pP.$$.fragment,m),C(mL.$$.fragment,m),C(_P.$$.fragment,m),C(ML.$$.fragment,m),C(bP.$$.fragment,m),C(vP.$$.fragment,m),C(TP.$$.fragment,m),C(CL.$$.fragment,m),C(MP.$$.fragment,m),C(BL.$$.fragment,m),C(EP.$$.fragment,m),C(CP.$$.fragment,m),C(AP.$$.fragment,m),C(NL.$$.fragment,m),C(LP.$$.fragment,m),C(UL.$$.fragment,m),C(yP.$$.fragment,m),C(xP.$$.fragment,m),C(kP.$$.fragment,m),C(JL.$$.fragment,m),C(SP.$$.fragment,m),C(ly.$$.fragment,m),C(RP.$$.fragment,m),C(PP.$$.fragment,m),C(IP.$$.fragment,m),C(dy.$$.fragment,m),C(NP.$$.fragment,m),C(by.$$.fragment,m),C(qP.$$.fragment,m),C(jP.$$.fragment,m),C(GP.$$.fragment,m),C(Fy.$$.fragment,m),C(OP.$$.fragment,m),C(xy.$$.fragment,m),C(VP.$$.fragment,m),C(XP.$$.fragment,m),C(QP.$$.fragment,m),C(ky.$$.fragment,m),C(WP.$$.fragment,m),C(Ry.$$.fragment,m),C(UP.$$.fragment,m),C(HP.$$.fragment,m),C(YP.$$.fragment,m),C(By.$$.fragment,m),C(ZP.$$.fragment,m),C(qy.$$.fragment,m),C(eB.$$.fragment,m),C(oB.$$.fragment,m),C(tB.$$.fragment,m),C(Dy.$$.fragment,m),C(aB.$$.fragment,m),C(Oy.$$.fragment,m),Eto=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Rf),m&&t(bt),m&&t(Ve),m&&t(He),m&&t(Bf),w(Ja,m),m&&t(Je),m&&t(Ae),m&&t($o),m&&t(Ya),m&&t(ioo),m&&t(pd),w(Ax),m&&t(doo),m&&t(ds),m&&t(coo),w(Lx,m),m&&t(moo),m&&t(BI),m&&t(foo),w(qf,m),m&&t(goo),m&&t(_d),w(yx),m&&t(hoo),m&&t(ko),w(xx),w(Sx),w(mu),w(Rx),m&&t(uoo),m&&t(vd),w(Px),m&&t(poo),m&&t(So),w(Bx),w(qx),w(Hu),w(jx),m&&t(_oo),m&&t(Fd),w(Dx),m&&t(boo),m&&t(Ro),w(Gx),w(Xx),w(Gp),w(Op),w(zx),m&&t(voo),m&&t(Td),w(Qx),m&&t(Foo),m&&t(Po),w(Wx),w(Jx),w(h_),w(u_),w(Yx),m&&t(Too),m&&t(Ed),w(Zx),m&&t(Moo),m&&t(Bo),w(Kx),w(o$),w(b_),w(r$),w(qb),m&&t(Eoo),m&&t(Ad),w(t$),m&&t(Coo),m&&t(Io),w(a$),w(s$),w(Db),w(l$),w(I2),m&&t(woo),m&&t(xd),w(i$),m&&t(Aoo),m&&t(No),w(d$),w(m$),w(q2),w(f$),w(yv),m&&t(Loo),m&&t(Sd),w(g$),m&&t(yoo),m&&t(qo),w(h$),w(p$),w($v),w(_$),w(_F),m&&t(xoo),m&&t(Bd),w(b$),m&&t($oo),m&&t(jo),w(v$),w(T$),w(vF),w(M$),w(GF),m&&t(koo),m&&t(qd),w(E$),m&&t(Soo),m&&t(Do),w(C$),w(A$),w(VF),w(L$),w(QT),m&&t(Roo),m&&t(Gd),w(y$),m&&t(Poo),m&&t(Go),w(x$),w(k$),w(UT),w(S$),w(yM),m&&t(Boo),m&&t(Xd),w(R$),m&&t(Ioo),m&&t(Oo),w(P$),w(I$),w($M),w(N$),w(jM),m&&t(Noo),m&&t(Wd),w(q$),m&&t(qoo),m&&t(Vo),w(j$),w(G$),w(GM),w(O$),w(xE),m&&t(joo),m&&t(Jd),w(V$),m&&t(Doo),m&&t(Xo),w(X$),w(Q$),w(kE),w(W$),w(A4),m&&t(Goo),m&&t(Kd),w(U$),m&&t(Ooo),m&&t(zo),w(H$),w(Y$),w(y4),w(Z$),w(k4),m&&t(Voo),m&&t(rc),w(K$),m&&t(Xoo),m&&t(Qo),w(ek),w(rk),w(R4),w(tk),w(q4),m&&t(zoo),m&&t(sc),w(ak),m&&t(Qoo),m&&t(Wo),w(nk),w(lk),w(D4),w(ik),w(tC),m&&t(Woo),m&&t(dc),w(dk),m&&t(Uoo),m&&t(Uo),w(ck),w(fk),w(nC),w(gk),w(iC),m&&t(Hoo),m&&t(fc),w(hk),m&&t(Joo),m&&t(Ho),w(uk),w(_k),w(cC),w(bk),w(gC),m&&t(Yoo),m&&t(uc),w(vk),m&&t(Zoo),m&&t(Jo),w(Fk),w(Mk),w(uC),w(Ek),w(bC),m&&t(Koo),m&&t(bc),w(Ck),m&&t(ero),m&&t(Yo),w(wk),w(Lk),w(FC),w(yk),w(kC),m&&t(oro),m&&t(Tc),w(xk),m&&t(rro),m&&t(Zo),w($k),w(Sk),w(RC),w(Rk),w(DC),m&&t(tro),m&&t(Cc),w(Pk),m&&t(aro),m&&t(Ko),w(Bk),w(Nk),w(OC),w(qk),w(e3),m&&t(nro),m&&t(Lc),w(jk),m&&t(sro),m&&t(er),w(Dk),w(Ok),w(r3),w(Vk),w(l3),m&&t(lro),m&&t(kc),w(Xk),m&&t(iro),m&&t(or),w(zk),w(Wk),w(d3),w(Uk),w(p3),m&&t(dro),m&&t(Pc),w(Hk),m&&t(cro),m&&t(rr),w(Jk),w(Zk),w(b3),w(Kk),w(C3),m&&t(mro),m&&t(Nc),w(eS),m&&t(fro),m&&t(tr),w(oS),w(tS),w(A3),w(aS),w(S3),m&&t(gro),m&&t(Dc),w(nS),m&&t(hro),m&&t(ar),w(sS),w(iS),w(P3),w(dS),w(N3),m&&t(uro),m&&t(Vc),w(cS),m&&t(pro),m&&t(nr),w(mS),w(gS),w(j3),w(hS),w(Q3),m&&t(_ro),m&&t(Qc),w(uS),m&&t(bro),m&&t(sr),w(pS),w(bS),w(U3),w(vS),w(Y3),m&&t(vro),m&&t(Hc),w(FS),m&&t(Fro),m&&t(lr),w(TS),w(ES),w(K3),w(CS),w(r5),m&&t(Tro),m&&t(Zc),w(wS),m&&t(Mro),m&&t(ir),w(AS),w(yS),w(a5),w(xS),w(n0),m&&t(Ero),m&&t(om),w($S),m&&t(Cro),m&&t(dr),w(kS),w(RS),w(l0),w(PS),w(k0),m&&t(wro),m&&t(am),w(BS),m&&t(Aro),m&&t(cr),w(IS),w(qS),w(R0),w(jS),w(U0),m&&t(Lro),m&&t(lm),w(DS),m&&t(yro),m&&t(mr),w(GS),w(VS),w(J0),w(XS),w(nw),m&&t(xro),m&&t(cm),w(zS),m&&t($ro),m&&t(fr),w(QS),w(US),w(lw),w(HS),w(mw),m&&t(kro),m&&t(hm),w(JS),m&&t(Sro),m&&t(gr),w(YS),w(KS),w(gw),w(eR),w(Pw),m&&t(Rro),m&&t(_m),w(oR),m&&t(Pro),m&&t(hr),w(rR),w(aR),w(Iw),w(nR),w(Ww),m&&t(Bro),m&&t(Fm),w(sR),m&&t(Iro),m&&t(ur),w(lR),w(dR),w(Hw),w(cR),w(EA),m&&t(Nro),m&&t(Em),w(mR),m&&t(qro),m&&t(pr),w(fR),w(hR),w(wA),w(uR),w(VA),m&&t(jro),m&&t(Am),w(pR),m&&t(Dro),m&&t(_r),w(_R),w(vR),w(zA),w(FR),w(UA),m&&t(Gro),m&&t(xm),w(MR),m&&t(Oro),m&&t(br),w(ER),w(wR),w(JA),w(AR),w(ZA),m&&t(Vro),m&&t(Sm),w(LR),m&&t(Xro),m&&t(vr),w(yR),w($R),w(e6),w(kR),w(r6),m&&t(zro),m&&t(Bm),w(SR),m&&t(Qro),m&&t(Fr),w(RR),w(BR),w(a6),w(IR),w(A6),m&&t(Wro),m&&t(qm),w(NR),m&&t(Uro),m&&t(Tr),w(qR),w(DR),w(y6),w(GR),w(J6),m&&t(Hro),m&&t(Gm),w(OR),m&&t(Jro),m&&t(Mr),w(VR),w(zR),w(Z6),w(QR),w(e7),m&&t(Yro),m&&t(Xm),w(WR),m&&t(Zro),m&&t(Er),w(UR),w(JR),w(r7),w(YR),w(a7),m&&t(Kro),m&&t(Wm),w(ZR),m&&t(eto),m&&t(Cr),w(KR),w(oP),w(s7),w(rP),w(P7),m&&t(oto),m&&t(Jm),w(tP),m&&t(rto),m&&t(wr),w(aP),w(sP),w(I7),w(lP),w(W7),m&&t(tto),m&&t(Km),w(iP),m&&t(ato),m&&t(Ar),w(dP),w(mP),w(H7),w(fP),w(dL),m&&t(nto),m&&t(rf),w(gP),m&&t(sto),m&&t(Lr),w(hP),w(pP),w(mL),w(_P),w(ML),m&&t(lto),m&&t(nf),w(bP),m&&t(ito),m&&t(yr),w(vP),w(TP),w(CL),w(MP),w(BL),m&&t(dto),m&&t(df),w(EP),m&&t(cto),m&&t(xr),w(CP),w(AP),w(NL),w(LP),w(UL),m&&t(mto),m&&t(ff),w(yP),m&&t(fto),m&&t($r),w(xP),w(kP),w(JL),w(SP),w(ly),m&&t(gto),m&&t(uf),w(RP),m&&t(hto),m&&t(kr),w(PP),w(IP),w(dy),w(NP),w(by),m&&t(uto),m&&t(bf),w(qP),m&&t(pto),m&&t(Sr),w(jP),w(GP),w(Fy),w(OP),w(xy),m&&t(_to),m&&t(Tf),w(VP),m&&t(bto),m&&t(Rr),w(XP),w(QP),w(ky),w(WP),w(Ry),m&&t(vto),m&&t(Cf),w(UP),m&&t(Fto),m&&t(Pr),w(HP),w(YP),w(By),w(ZP),w(qy),m&&t(Tto),m&&t(Lf),w(eB),m&&t(Mto),m&&t(Br),w(oB),w(tB),w(Dy),w(aB),w(Oy)}}}const AMa={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function LMa($){return uFa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class PMa extends mFa{constructor(g){super();fFa(this,g,LMa,wMa,gFa,{})}}export{PMa as default,AMa as metadata};
